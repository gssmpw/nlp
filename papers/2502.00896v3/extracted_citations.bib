@InProceedings{Oh_2023_CVPR,
  author    = {Oh, Changdae and Hwang, Hyeji and Lee, Hee-young and Lim, YongTaek and Jung, Geunyoung and Jung, Jiyoung and Choi, Hosik and Song, Kyungwoo},
  title     = {BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2023},
  pages     = {24224-24235},
  url       = {https://openaccess.thecvf.com/content/CVPR2023/html/Oh_BlackVIP_Black-Box_Visual_Prompting_for_Robust_Transfer_Learning_CVPR_2023_paper.html}
}

@inproceedings{allen2019can,
  title={Can {SGD} Learn Recurrent Neural Networks with Provable Generalization?},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={10310--10320},
  year={2019}
}

@inproceedings{allen2019convergence,
  title={On the convergence rate of training recurrent neural networks},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao and Wang, Yingyu},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={10031--10041},
  year={2019}
}

@article{allen2020backward,
  title={On the Backward Stability of {SGD} and its Use for Asymptotic Model Selection in Neural Networks},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={21},
  number={190},
  pages={1--50},
  year={2020}
}

@inproceedings{allen2020backward_correction,
  title={Backward feature correction: How deep learning performs deep learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={Proceedings of the 33rd International Conference on Neural Information Processing Systems},
  pages={13540--13550},
  year={2020}
}

@article{bahng2022exploring,
  title={Exploring visual prompts for adapting large-scale models},
  author={Bahng, Hyojin and Jahanian, Ali and Sankaranarayanan, Swami and Isola, Phillip},
  journal={arXiv preprint arXiv:2203.17274},
  year={2022}
}

@article{cai2010singular,
  title={Singular value thresholding algorithm for matrix completion},
  author={Cai, Jian-Feng and others},
  journal={SIAM Journal on Optimization},
  year={2010}
}

@inproceedings{caisample,
  title={Sample-specific Masks for Visual Reprogramming-based Prompting},
  author={Cai, Chengyi and Ye, Zesheng and Feng, Lei and Qi, Jianzhong and Liu, Feng},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@inproceedings{chen2023understanding,
  title={Understanding and improving visual prompting: A label-mapping perspective},
  author={Chen, Aochuan and Yao, Yuguang and Chen, Pin-Yu and Zhang, Yihua and Liu, Sijia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19133--19143},
  year={2023}
}

@inproceedings{ghorbani2020neural,
  title={Neural Networks Are More Expressive Than Kernel Methods: A Representational Perspective},
  author={Ghorbani, Amirata and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{grasedyck2013low,
  title={Low-rank tensor approximation techniques},
  author={Grasedyck, Lars and others},
  journal={SIAM Journal on Matrix Analysis and Applications},
  year={2013}
}

@inproceedings{han2023svdiff,
  title={Svdiff: Compact parameter space for diffusion fine-tuning},
  author={Han, Ligong and Li, Yinxiao and Zhang, Han and Milanfar, Peyman and Metaxas, Dimitris and Yang, Feng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7323--7334},
  year={2023}
}

@inproceedings{han2024proxedit,
  title={Proxedit: Improving tuning-free real image editing with proximal guidance},
  author={Han, Ligong and Wen, Song and Chen, Qi and Zhang, Zhixing and Song, Kunpeng and Ren, Mengwei and Gao, Ruijiang and Stathopoulos, Anastasis and He, Xiaoxiao and Chen, Yuxiao and others},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={4291--4301},
  year={2024}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{jin2023visual,
  title={Visual prompting upgrades neural network sparsification: A data-model perspective},
  author={Jin, Can and Huang, Tianjin and Zhang, Yihua and Pechenizkiy, Mykola and Liu, Sijia and Liu, Shiwei and Chen, Tianlong},
  journal={arXiv preprint arXiv:2312.01397},
  year={2023}
}

@inproceedings{khodak2021initialization,
  title={Initialization and regularization of factorized neural layers},
  author={Khodak, Mikhail and Macko, David and De Sa, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@inproceedings{li2016lora,
  title={Low-rank adaptation of large neural networks},
  author={Li, Xiang and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2016}
}

@inproceedings{li2018learning,
  title={Learning overparameterized neural networks via stochastic gradient descent on structured data},
  author={Li, Yuanzhi and Liang, Yingyu},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={8157--8166},
  year={2018}
}

@article{li2018low,
  title={Low-rank matrix recovery},
  author={Li, Xiang and others},
  journal={Foundations and TrendsÂ® in Machine Learning},
  year={2018}
}

@inproceedings{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={4582--4597},
  year={2021}
}

@article{liu2022few,
  title={Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning},
  author={Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1950--1965},
  year={2022}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{oymak2019generalization,
  title={Generalization guarantees for neural networks via harnessing the low-rank structure of the jacobian},
  author={Oymak, Samet and Fabian, Zalan and Li, Mingchen and Soltanolkotabi, Mahdi},
  journal={arXiv preprint arXiv:1906.05392},
  year={2019}
}

@inproceedings{sainath2013low,
  title={Low-rank matrix factorization for deep neural network training with high-dimensional output targets},
  author={Sainath, Tara N and Kingsbury, Brian and Saon, George and Soltau, Hagen and Mohamed, Abdel-rahman and Dahl, George E and Ramabhadran, Bhuvana},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={6655--6659},
  year={2013},
  organization={IEEE}
}

@inproceedings{shin-etal-2020-autoprompt,
    title = "{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with {A}utomatically {G}enerated {P}rompts",
    author = "Shin, Taylor  and
      Razeghi, Yasaman  and
      Logan IV, Robert L.  and
      Wallace, Eric  and
      Singh, Sameer",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.346",
    doi = "10.18653/v1/2020.emnlp-main.346",
    pages = "4222--4235",
    abstract = "The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.",
}

@inproceedings{tsai2020reprogramming,
  title={Transfer Learning Without Knowing: Reprogramming Black-Box Machine Learning Models with Scarce Data and Limited Resources},
  author={Tsai, Yun-Yun and Chen, Pin-Yu and Ho, Tsung-Yi},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020},
  organization={PMLR},
  url={https://proceedings.mlr.press/v119/tsai20a.html}
}

@inproceedings{tsao2024autovp,
  title={{AutoVP: An Automated Visual Prompting Framework and Benchmark}}, 
  author = {Hsi-Ai Tsao and Lei Hsiung and Pin-Yu Chen and Sijia Liu and Tsung-Yi Ho},
  booktitle={The Twelfth International Conference on Learning Representations},
  year = {2024}
}

@inproceedings{wu2022learning,
  title={Learning to Augment Graph Structure for both Homophily and Heterophily Graphs},
  author={Wu, Lirong and Tan, Cheng and Liu, Zicheng and Gao, Zhangyang and Lin, Haitao and Li, Stan Z.},
  booktitle={Proceedings of the European Conference on Machine Learning (ECML)},
  year={2022},
  url={https://link.springer.com/article/10.1007/s10994-022-06190-9}
}

@inproceedings{yang-etal-2023-prompt,
  title = "Prompt Tuning for Unified Multimodal Pretrained Models",
  author = "Yang, Hao  and Lin, Junyang  and Yang, An  and Wang, Peng  and Zhou, Chang",
  booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
  year = "2023",
  month = jul,
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.findings-acl.27",
  doi = "10.18653/v1/2023.findings-acl.27",
  pages = "402--416"
}

@article{yeh2023lora,
  title={LoRA: A Unified Low-Rank Adaptation Framework for Stable Diffusion},
  author={Yeh, et al.},
  journal={arXiv preprint arXiv:2409.14983},
  year={2023}
}

@inproceedings{zhang2014facial,
  title={Facial landmark detection by deep multi-task learning},
  author={Zhang, Zhifei and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},
  booktitle={European conference on computer vision},
  pages={94--108},
  year={2014},
  organization={Springer}
}

@article{zhang2023svd,
  title={SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression},
  author={Zhang, et al.},
  journal={arXiv preprint arXiv:2403.07378},
  year={2023}
}

@inproceedings{zhao2016energy,
  title={Energy-efficient image classification on low-power IoT devices},
  author={Zhao, Menglong and Ouyang, Wanli and Li, Xiaogang and Wang, Xiaowei},
  booktitle={IEEE Transactions on Circuits and Systems for Video Technology},
  pages={205--215},
  year={2016},
  organization={IEEE}
}

