\section{Related Works}
\subsection{Visual Prompting}
The concept of prompting originated in the field of NLP as a technique for adapting pre-trained models to downstream tasks ____. This design philosophy was later extended to CV by ____, who introduced tunable parameters directly into input images
% , thus creating a prompted image, referred to as a Visual Prompt (VP). 
 to create what is known as a Visual Prompt (VP). 
A typical VP framework consists of two primary modules: input design and output transformation ____. 
% Several approaches have been proposed for constructing prompted images. 
Various strategies have been proposed for constructing VPs.
For instance, ____ modify input images by adding a frame of visual prompting parameters, whereas ____ incorporate the visual prompting parameters around resized images. ____ 
% investigate methods to efficiently generate
explore efficient methods for generating visual prompts that enhance performance across different tasks, and ____ develop visual prompts designed for adapting models to black-box, inaccessible models. Since the output logits of pre-trained models remain in the source domain, an additional output transformation (e.g., label mapping) is required to accurately predict the targets. A simple approach is to randomly map source labels (RLM) onto target labels. ____ propose a frequency-based label mapping (FLM) technique, which derives the mapping based on frequency statistics. ____ further introduces iterative label mapping (ILM), which improves the performance of visual prompting. ____ proposes a semantics-based label mapping approach that aligns source and target classes based on semantic similarity. Additionally, ____ introduces full mapping (FM), utilizing an automated system to select the most appropriate label mapping (LM) method to optimize performance across diverse downstream tasks.

\subsection{Low-Rank Structures in Deep Learning}

Low-rank structures are widely observed in machine learning, as many problems inherently exhibit low-rank properties ____. It has been found that for numerous deep learning tasks, especially those involving heavily over-parameterized neural networks, the resulting models tend to exhibit low-rank characteristics after training ____. Some prior work has explicitly integrated low-rank constraints during the training process of neural networks ____. From a theoretical perspective, neural networks have been shown to outperform classical learning methods, including finite-width neural tangent kernels, when the underlying concept class has a low-rank structure ____. Additionally, ____ highlight that low-rank adaptations can be beneficial in adversarial training scenarios. The LoRA method, introduced by ____, along with its variants ____, is particularly noteworthy for not introducing additional inference burdens, thus improving the parameter efficiency of adapting large pre-trained models. These methods employ low-rank matrices to approximate weight updates during fine-tuning, enabling a seamless integration with pre-trained weights prior to inference.