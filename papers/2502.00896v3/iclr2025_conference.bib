@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{ridnik1imagenet,
  title={ImageNet-21K Pretraining for the Masses},
  author={Ridnik, Tal and Ben-Baruch, Emanuel and Noy, Asaf and Zelnik-Manor, Lihi},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
  year={2021}
}

@inproceedings{chen2023understanding,
  title={Understanding and improving visual prompting: A label-mapping perspective},
  author={Chen, Aochuan and Yao, Yuguang and Chen, Pin-Yu and Zhang, Yihua and Liu, Sijia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19133--19143},
  year={2023}
}

@article{le2015tiny,
  title={Tiny imagenet visual recognition challenge},
  author={Le, Ya and Yang, Xuan},
  year={2015}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and others},
  year={2009}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{bahng2022exploring,
  title={Exploring visual prompts for adapting large-scale models},
  author={Bahng, Hyojin and Jahanian, Ali and Sankaranarayanan, Swami and Isola, Phillip},
  journal={arXiv preprint arXiv:2203.17274},
  year={2022}
}

@inproceedings{hulora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={International Conference on Learning Representations}
}

@inproceedings{hendrycks2021many,
  title={The many faces of robustness: A critical analysis of out-of-distribution generalization},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8340--8349},
  year={2021}
}

@article{wang2019learning,
  title={Learning robust global representations by penalizing local predictive power},
  author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@inproceedings{akata2016multi,
  title={Multi-cue zero-shot learning with strong supervision},
  author={Akata, Zeynep and Malinowski, Mateusz and Fritz, Mario and Schiele, Bernt},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={59--68},
  year={2016}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@inproceedings{recht2019imagenet,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={International conference on machine learning},
  pages={5389--5400},
  year={2019},
  organization={PMLR}
}

@inproceedings{hendrycks2021natural,
  title={Natural adversarial examples},
  author={Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={15262--15271},
  year={2021}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{tsai2020transfer,
  title={Transfer learning without knowing: Reprogramming black-box machine learning models with scarce data and limited resources},
  author={Tsai, Yun-Yun and Chen, Pin-Yu and Ho, Tsung-Yi},
  booktitle={International Conference on Machine Learning},
  pages={9614--9624},
  year={2020},
  organization={PMLR}
}

@inproceedings{tsao2024autovp,
  title={{AutoVP: An Automated Visual Prompting Framework and Benchmark}}, 
  author = {Hsi-Ai Tsao and Lei Hsiung and Pin-Yu Chen and Sijia Liu and Tsung-Yi Ho},
  booktitle={The Twelfth International Conference on Learning Representations},
  year = {2024}
}

@inproceedings{aghajanyan2021intrinsic,
  title={Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning},
  author={Aghajanyan, Armen and Gupta, Sonal and Zettlemoyer, Luke},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={7319--7328},
  year={2021}
}

@inproceedings{arif2023reprogrammable,
  title={Reprogrammable-fl: Improving utility-privacy tradeoff in federated learning via model reprogramming},
  author={Arif, Huzaifa and Gittens, Alex and Chen, Pin-Yu},
  booktitle={2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)},
  pages={197--209},
  year={2023},
  organization={IEEE}
}

@inproceedings{NEURIPS2020_1457c0d6,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{liu2022few,
  title={Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning},
  author={Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1950--1965},
  year={2022}
}

@inproceedings{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={4582--4597},
  year={2021}
}

@inproceedings{caisample,
  title={Sample-specific Masks for Visual Reprogramming-based Prompting},
  author={Cai, Chengyi and Ye, Zesheng and Feng, Lei and Qi, Jianzhong and Liu, Feng},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{zheng2022prompt,
  title={Prompt Vision Transformer for Domain Generalization},
  author={Zheng, Zangwei and Yue, Xiangyu and Wang, Kai and You, Yang},
  journal={arXiv preprint arXiv:2208.08914},
  year={2022}
}

@article{yang2024fine,
  title={Fine-grained visual prompting},
  author={Yang, Lingfeng and Wang, Yueze and Li, Xiang and Wang, Xinlong and Yang, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{shin-etal-2020-autoprompt,
    title = "{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with {A}utomatically {G}enerated {P}rompts",
    author = "Shin, Taylor  and
      Razeghi, Yasaman  and
      Logan IV, Robert L.  and
      Wallace, Eric  and
      Singh, Sameer",
    editor = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.346",
    doi = "10.18653/v1/2020.emnlp-main.346",
    pages = "4222--4235",
    abstract = "The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.",
}

@article{jiang-etal-2020-know,
  title = "How Can We Know What Language Models Know?",
  author = "Jiang, Zhengbao and Xu, Frank F. and Araki, Jun and Neubig, Graham",
  journal = "Transactions of the Association for Computational Linguistics",
  volume = "8",
  year = "2020",
  pages = "423--438",
  publisher = "MIT Press",
  url = "https://aclanthology.org/2020.tacl-1.28",
  doi = "10.1162/tacl_a_00324"
}

@inproceedings{liu-etal-2022-p,
  title = "{P}-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks",
  author = "Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng and Du, Zhengxiao and Yang, Zhilin and Tang, Jie",
  booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
  month = may,
  year = "2022",
  address = "Dublin, Ireland",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2022.acl-short.8",
  doi = "10.18653/v1/2022.acl-short.8",
  pages = "61--68"
}

@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa and Liang, Percy",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    year = "2021",
    pages = "4582--4597",
    url = "https://aclanthology.org/2021.acl-long.353",
    doi = "10.18653/v1/2021.acl-long.353",
    publisher = "Association for Computational Linguistics",
    address = "Online"
}

@inproceedings{lester-etal-2021-power,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian and Al-Rfou, Rami and Constant, Noah",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    year = "2021",
    pages = "3045--3059",
    url = "https://aclanthology.org/2021.emnlp-main.243",
    doi = "10.18653/v1/2021.emnlp-main.243",
    publisher = "Association for Computational Linguistics",
    address = "Online and Punta Cana, Dominican Republic"
}

@inproceedings{jia2022visual,
  title={Visual Prompt Tuning},
  author={Menglin Jia and Luming Tang and Bor-Chun Chen and Claire Cardie and Serge Belongie and Bharath Hariharan and Ser-Nam Lim},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2022},
  url={https://arxiv.org/abs/2203.12119}
}

@InProceedings{Liu_2023_CVPR,
    author    = {Liu, Weihuang and Shen, Xi and Pun, Chi-Man and Cun, Xiaodong},
    title     = {Explicit Visual Prompting for Low-Level Structure Segmentations},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {19434-19445},
    doi       = {},
    url       = {https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Explicit_Visual_Prompting_for_Low-Level_Structure_Segmentations_CVPR_2023_paper.html}
}

@inproceedings{zheng-etal-2022-ueca,
    title = "{UECA}-Prompt: Universal Prompt for Emotion Cause Analysis",
    author = "Zheng, Xiaopeng and Liu, Zhiyue and Zhang, Zizhen and Wang, Zhaoyang and Wang, Jiahai",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    year = "2022",
    pages = "7031--7041",
    publisher = "ACL Anthology",
    url = "https://aclanthology.org/2022.coling-main.597"
}

@misc{zhang2022neural,
  title={Neural Prompt Search},
  author={Yuanhan Zhang and Kaiyang Zhou and Ziwei Liu},
  year={2022},
  eprint={2206.04673},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@article{zang2022unified,
  title={Unified Vision and Language Prompt Learning},
  author={Yuhang Zang and Wei Li and Kaiyang Zhou and Chen Huang and Chen Change Loy},
  journal={arXiv preprint arXiv:2210.07225},
  year={2022},
  url={https://arxiv.org/abs/2210.07225}
}

@inproceedings{zhou2022learning,
  title={Learning to Prompt for Vision-Language Models},
  author={Kaiyang Zhou and Jingkang Yang and Chen Change Loy and Ziwei Liu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022},
  pages={16816-16825},
  publisher={IEEE}
}

@inproceedings{zhou2022conditional,
  title={Conditional Prompt Learning for Vision-Language Models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022},
  pages={16795--16804},
  doi={10.1109/CVPR52688.2022.01631}
}


@inproceedings{tsai2020reprogramming,
  title={Transfer Learning Without Knowing: Reprogramming Black-Box Machine Learning Models with Scarce Data and Limited Resources},
  author={Tsai, Yun-Yun and Chen, Pin-Yu and Ho, Tsung-Yi},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020},
  organization={PMLR},
  url={https://proceedings.mlr.press/v119/tsai20a.html}
}

@inproceedings{elsayed2019adversarial,
  title={Adversarial Reprogramming of Neural Networks},
  author={Elsayed, Gamaleldin F and Goodfellow, Ian and Sohl-Dickstein, Jascha},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019},
  url={https://arxiv.org/abs/1806.11146}
}

@inproceedings{wu2022learning,
  title={Learning to Augment Graph Structure for both Homophily and Heterophily Graphs},
  author={Wu, Lirong and Tan, Cheng and Liu, Zicheng and Gao, Zhangyang and Lin, Haitao and Li, Stan Z.},
  booktitle={Proceedings of the European Conference on Machine Learning (ECML)},
  year={2022},
  url={https://link.springer.com/article/10.1007/s10994-022-06190-9}
}

@InProceedings{Oh_2023_CVPR,
  author    = {Oh, Changdae and Hwang, Hyeji and Lee, Hee-young and Lim, YongTaek and Jung, Geunyoung and Jung, Jiyoung and Choi, Hosik and Song, Kyungwoo},
  title     = {BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2023},
  pages     = {24224-24235},
  url       = {https://openaccess.thecvf.com/content/CVPR2023/html/Oh_BlackVIP_Black-Box_Visual_Prompting_for_Robust_Transfer_Learning_CVPR_2023_paper.html}
}

@inproceedings{yang-etal-2023-prompt,
  title = "Prompt Tuning for Unified Multimodal Pretrained Models",
  author = "Yang, Hao  and Lin, Junyang  and Yang, An  and Wang, Peng  and Zhou, Chang",
  booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
  year = "2023",
  month = jul,
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.findings-acl.27",
  doi = "10.18653/v1/2023.findings-acl.27",
  pages = "402--416"
}

@inproceedings{liao-etal-2023-parameter,
  title = "Parameter-Efficient Fine-Tuning without Introducing New Latency",
  author = "Liao, Baohao and Meng, Yan and Monz, Christof",
  booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  year = "2023",
  month = jul,
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2023.acl-long.233",
  doi = "10.18653/v1/2023.acl-long.233",
  pages = "4242--4260"
}

@article{chen2023transfer,
  title={Transfer visual prompt generator across large language models},
  author={Chen, Chi and Qin, Ruoyu and Luo, Fuwen and Mi, Xiaoyue and Li, Peng and Sun, Maosong and Yao, Yuan and Ji, Wei and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2305.01278},
  year={2023}
}

@article{sun2023structural,
  title={Structural-aware motif-based prompt tuning for graph clustering},
  author={Sun, Mingchen and Yang, Mengduo and Li, Yingji and Mu, Dongmei and Wang, Xin and Wang, Ying},
  journal={Information Sciences},
  volume={649},
  pages={119643},
  year={2023},
  publisher={Elsevier},
  doi={10.1016/j.ins.2023.119643}
}

@article{loedeman2022prompt,
  title={Prompt Generation Networks for Efficient Adaptation of Frozen Vision Transformers},
  author={Loedeman, Jochem and Stol, Maarten and Han, Tengda and Asano, Yuki M.},
  journal={arXiv preprint arXiv:2210.06466},
  year={2022}
}

@article{sohn2023styledrop,
  title={StyleDrop: Text-to-Image Generation in Any Style},
  author={Sohn, Kihyuk and Ruiz, Nataniel and Lee, Kimin and Castro, Daniel and Blok, Irina and Chang, Huiwen and Barber, Jarred and Jiang, Lu and Entis, Glenn and Li, Yuanzhen and Hao, Yuan and Essa, Irfan and Rubinstein, Michael and Krishnan, Dilip},
  journal={arXiv preprint arXiv:2306.00983},
  year={2023}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@inproceedings{li2016lora,
  title={Low-rank adaptation of large neural networks},
  author={Li, Xiang and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2016}
}

@article{cai2010singular,
  title={Singular value thresholding algorithm for matrix completion},
  author={Cai, Jian-Feng and others},
  journal={SIAM Journal on Optimization},
  year={2010}
}

@article{li2018low,
  title={Low-rank matrix recovery},
  author={Li, Xiang and others},
  journal={Foundations and Trends® in Machine Learning},
  year={2018}
}

@article{grasedyck2013low,
  title={Low-rank tensor approximation techniques},
  author={Grasedyck, Lars and others},
  journal={SIAM Journal on Matrix Analysis and Applications},
  year={2013}
}

@article{oymak2019generalization,
  title={Generalization guarantees for neural networks via harnessing the low-rank structure of the jacobian},
  author={Oymak, Samet and Fabian, Zalan and Li, Mingchen and Soltanolkotabi, Mahdi},
  journal={arXiv preprint arXiv:1906.05392},
  year={2019}
}

@inproceedings{sainath2013low,
  title={Low-rank matrix factorization for deep neural network training with high-dimensional output targets},
  author={Sainath, Tara N and Kingsbury, Brian and Saon, George and Soltau, Hagen and Mohamed, Abdel-rahman and Dahl, George E and Ramabhadran, Bhuvana},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={6655--6659},
  year={2013},
  organization={IEEE}
}

@inproceedings{povey2018kaldi,
  title={The Kaldi speech recognition toolkit},
  author={Povey, Daniel and others},
  booktitle={IEEE Signal Processing Society},
  year={2018},
  organization={IEEE}
}

@inproceedings{zhang2014facial,
  title={Facial landmark detection by deep multi-task learning},
  author={Zhang, Zhifei and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},
  booktitle={European conference on computer vision},
  pages={94--108},
  year={2014},
  organization={Springer}
}

@inproceedings{jaderberg2014deep,
  title={Deep structured output learning for unconstrained text recognition},
  author={Jaderberg, Max and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2014}
}

@inproceedings{zhao2016energy,
  title={Energy-efficient image classification on low-power IoT devices},
  author={Zhao, Menglong and Ouyang, Wanli and Li, Xiaogang and Wang, Xiaowei},
  booktitle={IEEE Transactions on Circuits and Systems for Video Technology},
  pages={205--215},
  year={2016},
  organization={IEEE}
}

@inproceedings{khodak2021initialization,
  title={Initialization and regularization of factorized neural layers},
  author={Khodak, Mikhail and Macko, David and De Sa, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2021}
}

@inproceedings{denil2014predicting,
  title={Predicting parameters in deep learning},
  author={Denil, Misha and Shakibi, Babak and Dinh, Laurent and de Freitas, Nando},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={2148--2156},
  year={2014}
}

@inproceedings{allen2019convergence,
  title={On the convergence rate of training recurrent neural networks},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao and Wang, Yingyu},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={10031--10041},
  year={2019}
}

@inproceedings{li2018learning,
  title={Learning overparameterized neural networks via stochastic gradient descent on structured data},
  author={Li, Yuanzhi and Liang, Yingyu},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={8157--8166},
  year={2018}
}

@inproceedings{ghorbani2020neural,
  title={Neural Networks Are More Expressive Than Kernel Methods: A Representational Perspective},
  author={Ghorbani, Amirata and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@inproceedings{allen2019can,
  title={Can {SGD} Learn Recurrent Neural Networks with Provable Generalization?},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={10310--10320},
  year={2019}
}

@article{allen2020backward,
  title={On the Backward Stability of {SGD} and its Use for Asymptotic Model Selection in Neural Networks},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={21},
  number={190},
  pages={1--50},
  year={2020}
}

@inproceedings{allen2020backward_correction,
  title={Backward feature correction: How deep learning performs deep learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={Proceedings of the 33rd International Conference on Neural Information Processing Systems},
  pages={13540--13550},
  year={2020}
}

@article{zhang2023svd,
  title={SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression},
  author={Zhang, et al.},
  journal={arXiv preprint arXiv:2403.07378},
  year={2023}
}

@article{liu2023factorization,
  title={AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning},
  author={Liu, Qiu, et al.},
  journal={arXiv preprint arXiv:2303.10512},
  year={2023}
}

@article{yeh2023lora,
  title={LoRA: A Unified Low-Rank Adaptation Framework for Stable Diffusion},
  author={Yeh, et al.},
  journal={arXiv preprint arXiv:2409.14983},
  year={2023}
}

@inproceedings{Hyeon-WooYO22,
  title = {FedPara: Low-rank Hadamard Product for Communication-Efficient Federated Learning},
  author = {Nam Hyeon-Woo and Moon Ye-Bin and Tae-Hyun Oh},
  booktitle = {Proceedings of the Tenth International Conference on Learning Representations (ICLR)},
  year = {2022},
  url = {https://openreview.net/forum?id=Gqw8HOgZkA7},
}

@inproceedings{renduchintala2024tiedlora,
  title={Tied-LoRA: Enhancing parameter efficiency of LoRA with Weight Tying},
  author={Adithya Renduchintala and Tugrul Konuk and Oleksii Kuchaiev},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  year={2024},
  month={June},
  address={Mexico City, Mexico},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2024.naacl-long.481},
  doi={10.18653/v1/2024.naacl-long.481},
  pages={8694--8705}
}

@article{ponti2022combining,
  title={Combining modular skills in multitask learning},
  author={Ponti, Edoardo M and Sordoni, Alessandro and Bengio, Yoshua and Reddy, Siva},
  journal={arXiv preprint arXiv:2202.13914},
  year={2022}
}

@inproceedings{kopiczko2024vera,
  title={VeRA: Vector-based Random Matrix Adaptation},
  author={Dawid Jan Kopiczko and Tijmen Blankevoort and Yuki M. Asano},
  booktitle={The Twelfth International Conference on Learning Representations (ICLR)},
  year={2024},
  url={https://openreview.net/forum?id=NjNfLdxr3A}
}

@article{xue2022clip,
  title={Clip-vip: Adapting pre-trained image-text model to video-language representation alignment},
  author={Xue, Hongwei and Sun, Yuchong and Liu, Bei and Fu, Jianlong and Song, Ruihua and Li, Houqiang and Luo, Jiebo},
  journal={arXiv preprint arXiv:2209.06430},
  year={2022}
}


@article{bochkovskiy2020yolov4,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@inproceedings{chen2018encoder,
  title={Encoder-decoder with atrous separable convolution for semantic image segmentation},
  author={Chen, Liang-Chieh and Zhu, Yukun and Papandreou, George and Schroff, Florian and Adam, Hartwig},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={801--818},
  year={2018}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@inproceedings{peng2024maxk,
  title={Maxk-gnn: Extremely fast gpu kernel design for accelerating graph neural networks training},
  author={Peng, Hongwu and Xie, Xi and Shivdikar, Kaustubh and Hasan, Md Amit and Zhao, Jiahui and Huang, Shaoyi and Khan, Omer and Kaeli, David and Ding, Caiwen},
  booktitle={Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
  pages={683--698},
  year={2024}
}

@inproceedings{han2023svdiff,
  title={Svdiff: Compact parameter space for diffusion fine-tuning},
  author={Han, Ligong and Li, Yinxiao and Zhang, Han and Milanfar, Peyman and Metaxas, Dimitris and Yang, Feng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7323--7334},
  year={2023}
}


@inproceedings{han2024proxedit,
  title={Proxedit: Improving tuning-free real image editing with proximal guidance},
  author={Han, Ligong and Wen, Song and Chen, Qi and Zhang, Zhixing and Song, Kunpeng and Ren, Mengwei and Gao, Ruijiang and Stathopoulos, Anastasis and He, Xiaoxiao and Chen, Yuxiao and others},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={4291--4301},
  year={2024}
}

@article{jin2023visual,
  title={Visual prompting upgrades neural network sparsification: A data-model perspective},
  author={Jin, Can and Huang, Tianjin and Zhang, Yihua and Pechenizkiy, Mykola and Liu, Sijia and Liu, Shiwei and Chen, Tianlong},
  journal={arXiv preprint arXiv:2312.01397},
  year={2023}
}