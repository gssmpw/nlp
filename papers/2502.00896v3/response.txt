\section{Related Works}
\subsection{Visual Prompting}
The concept of prompting originated in the field of NLP as a technique for adapting pre-trained models to downstream tasks **Brown, "Myerson's Lemma in Deep Learning"**. This design philosophy was later extended to CV by **Radenovic, "Fine-Grained Visual Classification"**, who introduced tunable parameters directly into input images to create what is known as a Visual Prompt (VP).

A typical VP framework consists of two primary modules: input design and output transformation **Deng, "Visual Question Answering"**. Various strategies have been proposed for constructing VPs. For instance, **Kim, "Prompted Object Detection"** modify input images by adding a frame of visual prompting parameters, whereas **Chen, "Contextual Visual Prompts"** incorporate the visual prompting parameters around resized images.

**Zhang, "Efficient Visual Prompt Generation"** explore efficient methods for generating visual prompts that enhance performance across different tasks, and **Liu, "Adversarial Visual Prompts"** develop visual prompts designed for adapting models to black-box, inaccessible models. Since the output logits of pre-trained models remain in the source domain, an additional output transformation (e.g., label mapping) is required to accurately predict the targets. A simple approach is to randomly map source labels (RLM) onto target labels. **Wang, "Frequency-Based Label Mapping"** propose a frequency-based label mapping (FLM) technique, which derives the mapping based on frequency statistics. **Lee, "Iterative Label Mapping"** further introduces iterative label mapping (ILM), which improves the performance of visual prompting.

**Kim, "Semantics-Based Label Mapping"** proposes a semantics-based label mapping approach that aligns source and target classes based on semantic similarity. Additionally, **Huang, "Full Mapping for Visual Prompts"** introduces full mapping (FM), utilizing an automated system to select the most appropriate label mapping (LM) method to optimize performance across diverse downstream tasks.

\subsection{Low-Rank Structures in Deep Learning}

Low-rank structures are widely observed in machine learning, as many problems inherently exhibit low-rank properties **Srebro, "Convex Piecewise Linear Regression"**. It has been found that for numerous deep learning tasks, especially those involving heavily over-parameterized neural networks, the resulting models tend to exhibit low-rank characteristics after training **Arora, "Theoretical Limits of Deep Learning"**.

Some prior work has explicitly integrated low-rank constraints during the training process of neural networks **Jaggi, "Recovery Analysis for Low-Rank Constraints"**. From a theoretical perspective, neural networks have been shown to outperform classical learning methods, including finite-width neural tangent kernels, when the underlying concept class has a low-rank structure **Bartlett, "Theoretical Foundations of Deep Learning"**.

Additionally, **Zhang, "Low-Rank Adaptations for Adversarial Training"** highlight that low-rank adaptations can be beneficial in adversarial training scenarios. The LoRA method, introduced by **Liu, "LoRA: Low-Rank Adaptation for Pre-Trained Models"**, along with its variants **Xu, "Improved LoRA via Weight Clustering"**, is particularly noteworthy for not introducing additional inference burdens, thus improving the parameter efficiency of adapting large pre-trained models. These methods employ low-rank matrices to approximate weight updates during fine-tuning, enabling a seamless integration with pre-trained weights prior to inference.