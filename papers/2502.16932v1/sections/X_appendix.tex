\clearpage
\newpage
\begin{appendix}




\subsection{Policy Training and Implementation Details}
\label{sec:appendix-policy}

We select 3D Diffusion Policy (DP3)~\cite{ze20243d} as the visuomotor policy used for real-world and simulated experiments. We compare its performance against 2D Diffusion Policy (DP)~\cite{chi2023diffusion_policy} in the empirical study in Sec.~\ref{sec:empirical}. We list the training and implementation details as follows.

\vspace{0.2cm}\subsubsection{Details for Policy Training} 
\label{sec:appendix-policy-training}
For a fair comparison, we fix the total training steps counted by observation-action pairs to be $2\mathrm{M}$ for all evaluated settings, resulting in an equal training cost regardless of the dataset size. 
To stabilize the training process, we use AdamW~\cite{loshchilov2017decoupled} optimizer and set the learning rate to be $1\mathrm{e}^{-4}$ with a $500$ step warmup.

In real-world experiments, we use the DBSCAN~\cite{ester1996density} clustering algorithm to discard the outlier points and downsample the number of points in the point cloud observations to $1024$. In the simulator, we skip the clustering stage and downsample the point clouds to $512$ points.

We follow the notation in the Diffusion Policy~\cite{chi2023diffusion_policy} paper, where $T_\mathrm{o}$ denotes the observation horizon, $T_\mathrm{p}$ as the action prediction horizon, and $T_\mathrm{a}$ denotes the action execution horizon. 
In real-world experiments, we set $T_\mathrm{o}=2,\,T_\mathrm{p}=8,\,T_\mathrm{a}=5$. We run the visuomotor policy at $10\mathrm{Hz}$. Since $T_\mathrm{a}$ indicates the steps of actions executed on the robot without re-planning, our horizon settings result in a closed-loop re-planning latency of $0.5$ seconds, responsive enough for conducting dexterous retrying behaviors and disturbance resistance.
In the simulator, since the tasks are simpler, we set $T_\mathrm{o}=2,\,T_\mathrm{p}=4,\,T_\mathrm{a}=3$.

\vspace{0.2cm}\subsubsection{Pre-Trained Encoders for Diffusion Policies} 
\label{sec:appendix-policy-pretrain}
To replace the train-from-scratch ResNet18~\cite{he2016deep} visual encoder in the original Diffusion Policy architecture, we consider $3$ representative pre-trained encoders: R3M~\cite{nair2023r3m}, DINOv2~\cite{oquab2023dinov2}, and CLIP~\cite{radford2021learning}.
R3M utilizes a ResNet~\cite{he2016deep} architecture and is pre-trained on robotics-specific tasks. DINOv2 and CLIP employ ViT~\cite{dosovitskiy2021an} architectures and are pre-trained on open-world vision tasks. These encoders are widely used in previous works~\cite{chi2024umi,lin2024data} to enhance policy performance.

\subsection{Spatial Generalization Empirical Study Details}
\label{sec:appendix-empirical}

In Sec.~\ref{sec:empirical}, we conducted an empirical study on the spatial generalization capability of visuomotor policies. In this section, we provide more detailed analysis of the study's results.

\vspace{0.2cm}\subsubsection{More Analysis on the Visualization Results in Fig.~\ref{fig:spatial_gen_vis}}
\label{sec:appendix-empirical-visualize}
The results suggest that visuomotor policies exhibit some degree of spatial interpolation capability. Specifically, the green-colored effective range in the \texttt{sparse} setting with $9$ demonstrations is significantly larger than $9$ times the effective range in the \texttt{single} setting. However, increased precision requirements would make it harder to interpolate, as indicated by comparing the two task variants under the \texttt{sparse} setting.

Meanwhile, extrapolation proves to be more challenging. Although the number of demonstrations in the \texttt{dense} setting is much larger than in the \texttt{sparse} setting, the contours of the effective range remain similar across both cases. This suggests more demonstrations near the center of the workspace do not significantly extend the effective range to more distant areas.

On the whole, the spatial generalization range of visuomotor policies can be roughly approximated by the union of the adjacent areas around the object configurations in the provided demonstrations. The extent of the adjacent regions is influenced by the fault tolerance level required for manipulation.

% \vspace{0.2cm} \noindent\textbf{Benchmarking Spatial Generalization Capability.} 
\vspace{0.2cm}\subsubsection{More Analysis on the Benchmarking Results in Fig.~\ref{fig:spatial_gen_benchmark}} 
\label{sec:appendix-empirical-benchmark}
On visuomotor policies, we find DP3 exhibits the highest spatial generalization capacity compared to all 2D-based counterparts. Additionally, models utilizing CLIP and DINOv2 representations achieve competitive results, significantly surpassing the train-from-scratch baseline. This highlights the value of pre-training on open-world vision tasks in enhancing spatial reasoning capabilities for robotic manipulation. Notably, while prior studies~\cite{chi2024universal,lin2024data,burns2023makes,zhu2024point} have emphasized the benefits of 3D and pre-trained encoders for visual generalization, our findings extend these insights to spatial generalization, offering a complementary perspective on encoder selection strategies.

On object randomization range, our experiments with \texttt{half} and \texttt{fixed} settings demonstrate that high precision requirements alone do not necessarily produce challenging tasks unless the object positions are fully randomized. This suggests that precision requirements and spatial randomization both contribute to the task difficulty.

On the number of demonstrations, while task performance generally improves with an increased number of demonstrations, the effect diminishes beyond a certain threshold. For instance, in the \texttt{full} workspace setting with DP3 as the policy, a $50$ demonstrations increase from $100$ to $150$ enhances the performance by $37\%$, but the increase from $150$ to $200$ only improves the performance by $6\%$.
This finding also highlights the inherent difficulty in achieving near-perfect success rates in robot learning systems.


\vspace{0.2cm}\subsubsection{The Precise-Peg-Insertion Task} 
\label{sec:appendix-empirical-task}
We construct a T-shaped peg, whose upper end has a cross-section of $6\,\textrm{cm} \times 6\,\textrm{cm}$, and the bottom end has a cross-section of $3\,\textrm{cm} \times 3\,\textrm{cm}$. The hole in the green socket has a cross-section of $4\,\textrm{cm} \times 4\,\textrm{cm}$. This shape enforces a strict fault tolerance of $1\,\textrm{cm}$ during both the picking and insertion stages, asking for millimeter-level precision. Both objects are randomized in a $40\,\mathrm{cm} \times 20\,\mathrm{cm}$ workspace in the \texttt{full} setting. The randomization range is halved into $20\,\mathrm{cm} \times 10\,\mathrm{cm}$ in the \texttt{half} setting.


\begin{figure}[h]
    \centering
    \vspace{-0.1cm}
    \includegraphics[width=\linewidth]{figs/crop_precise-peg-insertion.pdf}
    \caption{\textbf{The Precise-Peg-Insertion task.} A total of $3$ workspace sizes is considered. Purple and sky-blue rectangles mark the workspaces for demonstration and evaluation, respectively.}
    \label{fig:precise-peg-insertion}
\end{figure}




\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/appendix-dice-final.pdf}
    \caption{\textbf{Visualization of the policy performance trained on human-collected datasets.} (Upper row) The demonstrated configurations. (Bottom row) The spatial heatmaps with success rates averaged on $5$ trials.}
    \label{fig:source-demo-heatmap}
\end{figure*}



\subsection{Increased Human-Collected Demonstrations}
\label{sec:appendix-increase-source}

In Tab.~\ref{table:real-spatial-result}, we compare the \method-generated dataset against $3$ human-collected source demonstrations. 
In Fig.~\ref{fig:source-baseline}, we provide a reference on how the increase of source demonstrations leads to the enhancement of policy performance on the Dex-Cube task. 
To further understand the policy capacity enabled by human-collected demonstrations, we visualize the spatial heatmaps of human-collected datasets in Fig.~\ref{fig:source-demo-heatmap}. 
By comparing the demonstrated configurations and the spatial effective range of the resulting policies, we found the policy capacity is upper-bounded by the demonstrated configurations.
This is in line with the findings in the empirical study.


\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figs/crop_source-demo-baseline-v4.pdf}
    \caption{\textbf{Real-world comparison between \method-generated and human-collected datasets.} The \method-generated dataset is based on $3$ source demonstrations.}
    \label{fig:source-baseline}
\end{figure}


\subsection{Detailed Analysis of the Bimanual Humanoid Experiment}
\label{sec:appendix-humanoid}

The orientational augmentations share the same visual mismatch problem as translational augmentation. The policy performs as expected when the generated orientations are close to the orientation in the source demonstration. As the orientational difference increases, we observed the policy might react to the orientation in the current visual observation with actions for mismatched orientations.

% Therefore, from the perspective of method usage, we maintain the same viewpoint as with translational spatial augmentation: if the precision requirements for the task are not high, then using one source demonstration combined with generated demonstrations can yield good results. However, for tasks with higher precision requirements, a better approach would be to use a few source demonstrations as stem states and employ demo generation to extend the coverage outward from these stem states into the broader space. In either case, our demo generation method can effectively help reduce the amount of human effort required to collect demonstrations.


Additionally, we found the spatial generalization problem persists in mobile manipulation scenarios. This is mainly due to the physical constraints of real-world environments, such as kitchen countertops or fruit stands, as demonstrated in our experiments, where terrain limitations prevent the base from approaching objects at arbitrary distances. Consequently, the base typically moves to a fixed point at a specific distance from the object, after which the robot conducts a standard non-mobile manipulation process at the fixed base position.



\subsection{Disturbance Resistance Experiments Details}
\label{sec:appendix-disturb}
\subsubsection{Evaluation Metrics}
\label{sec:appendix-disturb-metric}
The sauce coverage score is computed as follows. First, we distinguish between green background and red sauce in the HSV color space. The identified background is set to black, the sauce is set to red, and the rest which should be the uncovered crust is set to white. Second, due to the highlights on the sauce liquid, some small fragmented points of the sauce may be identified as the crust. To address this, we apply smoothing filtering followed by dilation and erosion, where the kernel size is $9\times 9$. Finally, the coverage is calculated as the ratio of red areas (sauce) over non-black areas (sauce + uncovered crust). 
% Examples of the processing results are shown in the top row in Fig.~\ref{fig:sauce-raw-results}. 

\vspace{0.2cm}
\subsubsection{Raw Evaluation Results}
\label{sec:appendix-disturb-raw}
For quantitative evaluation, we perform $5$ repetitions for each of the $5$ disturbance directions, resulting in $25$ trials for both strategies. 

\end{appendix}


\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/appendix-sauce-final.pdf}
    \caption{\textbf{Raw evaluation results in the Sauce-Spreading task.} (Top) Examples of the processing results for metric calculation. (Bottom) Compared with the regular \method, the policy trained with the ADR strategy better spreads the sauce to cover the crust under external disturbance.}
    \label{fig:sauce-raw-results}
    \vspace{-0.2cm}
\end{figure}





\subsection{Randomization Ranges for Simulated Tasks}
\label{sec:appendix-sim-range}


\input{tabs/sim-object-range}

In Fig.~\ref{fig:sim-tasks}, we illustrated the simulated tasks for the evaluation on spatial generalization. To strengthen the significance of spatial generalization, we enlarge the original object randomization ranges in the MetaWorld~\cite{yu2020metaworld} tasks. For demonstration generation, we select a slightly larger range than the evaluation workspace to avoid performance degradation near the workspace boundaries. The detailed workspace sizes are listed in Tab.~\ref{table:sim-range}.



\subsection{Task Descriptions for Real-World Tasks}
In Fig.~\ref{fig:real-spatial-tasks}, we illustrated the real-world tasks for the evaluation on spatial generalization. We describe these tasks in the text as follows, where we mark the verbs for  \textcolor{myorange}{motion} and \textcolor{myblue}{skill} actions in the corresponding colors.

\label{sec:appendix-task-real}
\begin{enumerate}
    \item \textbf{Spatula-Egg.} The gripper holds a spatula in hand. The robot maneuvers the spatula to first \textcolor{myorange}{move} toward the fried egg and then 1) \textcolor{myblue}{slide} beneath the egg, 2) \textcolor{myblue}{lift} the egg leveraging the contact with the plate's rim, 3) \textcolor{myblue}{carry} the egg and maintain stable suspension.
    \item \textbf{Flower-Vase.} The gripper \textcolor{myorange}{moves} toward the flower, \textcolor{myblue}{picks} it up, \textcolor{myorange}{reorients} it in the air while \textcolor{myorange}{transferring} toward the vase, and finally \textcolor{myblue}{inserts} it into the vase.
    \item \textbf{Mug-Rack.} The gripper \textcolor{myorange}{moves} toward the mug, \textcolor{myblue}{picks} it up, \textcolor{myorange}{reorients} it in the air while \textcolor{myorange}{transferring} toward the rack, and \textcolor{myblue}{hangs} it onto the rack.
    \item \textbf{Dex-Cube.} The dexterous hand \textcolor{myorange}{moves} toward the cube and \textcolor{myblue}{grasps} up the cube.
    \item \textbf{Dex-Rollup.} The dexterous hand \textcolor{myorange}{moves} toward a piece of plasticine and \textcolor{myblue}{wraps} it multiple times until it is fully coiled. The required times of the wrapping motion may vary due to the distinct plasticity of every hand-molded piece of plasticine.
    \item \textbf{Dex-Drill.} The dexterous hand \textcolor{myorange}{moves} toward the drill, \textcolor{myblue}{grasps} it up, \textcolor{myorange}{transfers} it toward the cube, and finally \textcolor{myblue}{touches} the cube with the drill. 
    \item \textbf{Dex-Coffee.} The dexterous hand \textcolor{myorange}{moves} toward the kettle, \textcolor{myblue}{grasps} it up, \textcolor{myorange}{transfers} it toward the coffee filter, and finally \textcolor{myblue}{pours} water into the filter.
\end{enumerate}

\subsection{Visualization of \method-Generated Trajectories}
\label{sec:appendix-vis-traj}
In Fig.~\ref{fig:method-traj}, we gave a concrete example of the trajectory of synthetic visual observations. We provide more examples in Fig.~\ref{fig:traj-examples} by showcasing the key frames of source and generated demonstrations.








\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figs/appendix-traj-final.pdf}
    \caption{\textbf{More examples of the trajectories consisting of synthetic visual observations.} }
    \label{fig:traj-examples}
\end{figure*}