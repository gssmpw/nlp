\section{Discussions}
as a data generation method, decoupled with the policy learning method. can also be applied to offline RL, VLA.

scale up with \method. the effects will be magnified

Q: if planning can solve the task, then why train IL policy? A: we use a closed-loop IL policy to distill the knowledge of TAMP. the strength of IL is emergent retry and replan according to observation and external disturbance.

Q: why not one source demo for all tasks? A: Due to visual mismatch, \method cannot solve all the tasks from only one source demo. empirically, we find the capability upper-bound of \method-generated demos from one source demo is to obtain the same performance as around 25 source demos. That is, the effects of \method is roughly to reduce the need for human collected demonstrations by around 25x. 

Q: can \method be used on tasks requiring very high precision? A: yes, but those tasks often require a large number of source demonstrations. so one source demo is not enough for \method to solve these tasks.
