\subsection{Measuring the privacy of quantized models}
\label{ssec:algo}

To estimate the security of an algorithm $\gA_{\gQ}$ using~\autoref{thm:seqQ}, we must compute the loss gaps $\mkn{k}$ between the best quantized model and all possible quantizers in $\Bar{\Theta}$.
However, this is computationally infeasible, as even a simple quantizer like 1-bit quantization leads to an exponentially large $\Bar{\Theta}$ with respect to the number of parameters.
We address this intractability by observing that only a few quantizers dominate the estimation of $\qcertif$.
Specifically, $\qcertif$ depends on:
\begin{itemize}
\item The two lowest average quantized losses $m_{\thetaq_1}$ and $m_{\thetaq_2}$.
\item The values $\liminf{n}\pp{\mkn{2}/\mkn{k}}^2(\sigma_k^n)^2$ which measure the trade-off between the mean loss gap and the per-sample variance of quantized models.
\end{itemize}
Crucially, $\max_k\liminf{n}\pp{\mkn{2}/\mkn{k}}^2(\sigma_k^n)^2$ is empirically dominated by low-loss quantizers (see~\autoref{subsec:eval_privacy}), suggesting that exploring the entire set $\Bar{\Theta}$ is unnecessary, as focusing on low-loss quantizers is sufficient to estimate $\qcertif$.
% Crucially, $\max_k{\Lambda_{k,k}}$ is empirically dominated by low-loss quantizers (see~\autoref{subsec:eval_privacy}), suggesting that exploring the entire set $\Bar{\Theta}$ is unnecessary, as focusing on low-loss quantizers is sufficient to estimate $\qcertif$.

We thus propose estimating using quantized models derived from the training trajectory of $\hat{\theta}_n$.
Since $\hat{\theta}_n$ is optimized to minimize $\ell$, the quantizers with the lowest loss likely reside near this trajectory.
This justifies our focus on the training trajectory, which efficiently captures critical quantizers.
The complete procedure is outlined in Algorithm~\ref{algo:main}.
We propose an implementation of Algorithm~\ref{algo:main} as a wrapper of Pytorch Lightning's ``LightningModule" class~\cite{Falcon_PyTorch_Lightning_2019}, as well as the code to replicate all experiments.\footnote{\url{https://anonymous.4open.science/r/Mol_Downstream-B3DB/README.md}}

%To estimate the value of $\qcertif$ using a subset of $\Bar{\Theta}$, we propose to focus on the quantized models obtained by quantizing $\theta_n$ at each epoch of its training.
%As $\theta_n$ is trained to optimize $l$, the quantized model achieving the minimal values $m_{\thetaq_1}$ and $m_{\thetaq_2}$ most likely lies close to its training trajectory.
%On the other hand, $\max_{k}{\Lambda_{k,k}}$ is controled by a trade-off between how close the loss of the quantized models are to $\thetaq_1$ looking at their mean, and yet how different they are on every samples, as measured by the variances $\sigma_k^n = Var\pp{l\pp{\thetaq_k,\rz} - l\pp{\thetaq_1,\rz}}$.
%If the maximum was to be obtained on a quantized model with a high average loss, following the training trajectory of $\theta_n$ might not provide the best estimate of $\qcertif$.
%However, we show in~\autoref{subsec:eval_privacy} that ${\max_k{\Lambda_{k,k}}}$ is consistently achieved for quantized models with among the lowest average loss.
%We propose in~\autoref{algo:main} the complete estimation procedure of $\qcertif$.

\begin{algorithm}
    \caption{Estimation of $\qcertif$}
    \label{algo:main}
    \begin{algorithmic}[1]
        \STATE \textbf{Input:} A training dataset $\gD_n$, a validation dataset $\gD_{\textrm{val}}$, a learning algorithm $\gA$, a quantizer $\gQ$, an initialized model $\theta$, a number of epochs $K$.
        \STATE \textbf{Output:} An estimate of $\qcertif$.
        \STATE \textbf{Initialization:} Set the list of all quantized loss $\Ls_{\textrm{val}} = \{\}$, of all average quantized losses $m_{\textrm{val}} = \{\}$, and of all variances $\sigma_{\textrm{val}}^2 = \{\}$.
        \FOR{$k=1$ to $K$}
            \STATE $\theta \leftarrow \gA(\theta, \gD_n)$.
            \STATE $\thetaq \leftarrow \gQ(\theta)$.
            \STATE $\Ls_k \leftarrow \{\ell(\thetaq, \rz) : \rz\in\gD_{\textrm{val}}\}$.
            \STATE $m_k \leftarrow \frac{1}{|\gD_{\textrm{val}}|}\sum_{\rz\in\gD_{\textrm{val}}}\ell(\thetaq, \rz)$.
            \STATE $\Ls_{\text{val}}[k] \leftarrow \Ls_k$.
        \ENDFOR
        \STATE $\text{idx} \leftarrow \text{argsort}(m_{\text{val}})$.
        \STATE $m_{\textrm{val}} \leftarrow m_{\textrm{val}}[\text{idx}]$.
        \STATE $\Ls_{\textrm{val}} \leftarrow \Ls_{\textrm{val}}[\text{idx}]$.
        \FOR{$k=2$ to K}
            \STATE $\sigma_{\textrm{val}}^2[k] \leftarrow \textrm{Var}\pp{\Ls_{\text{val}}[k] - \Ls_{\text{val}}[1]}$.
        \ENDFOR
        \STATE $r_{\gQ} \leftarrow \frac{1}{2}\cc{\underset{2\leq k\leq K}\max{\left(\sigma_{\text{val}}^2[k] \times \pp{\frac{m_{\text{val}}[2] - m_{\text{val}}[1]}{m_{\text{val}}[k] - m_{\text{val}}[1]}}^2\right)}}^{-1}$.
        \STATE \textbf{return} $\qcertif = r_{\gQ} \pp{m_{\text{val}}[2] - m_{\text{val}}[1]}^2$.

    \end{algorithmic}
\end{algorithm}


\subsection{Baseline estimation of the MIS}
\label{ssec:baseline_estimation}
Inferring membership of $\Tilde{\rz}$ by an MIA can naturally be considered as a statistical test,
\begin{equation*}
\left\{
    \begin{array}{ll}
  H_0: &``\Tilde{\rz}{\text{ belongs to the training dataset}}".  \\
  H_1: & ``\Tilde{\rz}{\text{ does not belong to the training dataset}}".
\end{array}\right.
\end{equation*}
Under the mathematical setting presented in Appendix \ref{ssec:math-sett}, these hypotheses can be apprehended as deciding whether $\hat{\theta}_n$ is independent or not to $\Tilde{\rz}$. Specifically, testing $H_0$ against $H_1$ is equivalent to testing $H_0'$ against $H_1'$, where
\begin{equation}
\left\{
    \begin{array}{ll}
    H_0': & (\hat{\theta}_n, \Tilde{\rz})\sim P_{\pp{\hat{\theta}_n,\rz_1}}. \\
    H_1': & (\hat{\theta}_n,\Tilde{\rz})\sim P_{\hat{\theta}_n}\otimes P.
\end{array}\right. 
\end{equation}
For any dominating measure $\zeta$ on $P_{\pp{\hat{\theta}_n,\rz_1}}$ (and $P_{\hat{\theta}_n}\otimes P$), denoting by $f$ (resp. $g$) the density of  $P_{\pp{\hat{\theta}_n,\rz_1}}$ (resp. $P_{\hat{\theta}_n}\otimes P$) with respect to $\zeta$, we have that $\phi^*(\theta, z) = \mathbbm{1}\left\{\frac{f(\theta,z)}{g(\theta,z)} \geq1\right\}$ satisfies:
\begin{equation}
    \underset{\phi}{\sup}\;{\text{Acc}}_n(\phi; P,\gA ) = {\text{Acc}}_n(\phi^*; P,\gA ).
\end{equation}
\noindent The function $\phi^*$ is the Neyman-Pearson test for $H_0'$ against $H_1'$. This suggests that evaluating empirically the MIS of an algorithm amounts down to training a discriminator, and evaluate it.
% Specifically, Lemma \ref{lem:np} states that to accurately quantify the security level of an algorithm $\gA$, one has to estimate the optimal discriminator between $H_0'$ and $H_1'$. Additionally, denoting by $\|\cdot\|_{TV}$ the total variation distance, we may rewrite the MIS as ${\text{MIS}}_n\left(P,\gA\right) = 1-\Delta_n(P,\gA)$ \cite{aubinais2023fundamental} where 
% \begin{equation}
% \label{eq:delta_def}
%     \Delta_n(P,\gA)\coloneqq \|P_{\left(\hat{\theta}_n,\rz_1\right)} - P_{\hat{\theta}_n}\otimes P\|_{TV}.
% \end{equation}
% Under the mathematical setting presented in \autoref{ssec:math-sett}, and based on the work of \cite{aubinais2023fundamental}, 
% Under the mathematical setting presented in \autoref{ssec:math-sett}, \autoref{eq:mis_delta} states that,
% \begin{equation}
% \label{eq:delta_tv}
%     {\MIS}_n(P, \gA) = 1 - \|P_{(\thetan,\rz_1)} - P_{\thetan}\otimes P\|_{TV},
% \end{equation}
% for any distribution $P$ and any algorithm $\gA$, where $\|\cdot\|_{TV}$ is the total variation distance. In particular, it holds for any (Size-Adaptive) quantized algorithm. For any dominating measure $\zeta$ on $P_{(\thetan,\rz_1)}$ (and $P_{\thetan}\otimes P$), denoting by $f$ (resp. $g$) the densities with respect to $\zeta$ of $P_{(\thetan,\rz_1)}$ (resp. $P_{\thetan}\otimes P$) we have that
% \begin{equation}
%     \|P_{(\thetan,\rz_1)} - P_{\thetan}\otimes P\|_{TV} = \mathbb{P}\pp{\frac{f(\thetan,\rz)}{g(\thetan,\rz)} \geq 1},
% \end{equation}
% from the definition of the total variation distance. Here, the probability $\mathbb{P}$ is taken with respect to $(\hat{\theta}_n,\rz)\sim P_{\thetan}\otimes P$.
The baseline approach therefore consists in training a binary classifier $\bsl: \Theta \times \mathbb{R}^d \times \mathbb{R} \rightarrow [0,1]$ to distinguish between samples $z$ sampled from the training set of a given $\thetan$ and sampled from the product distribution $P_{\thetan}\otimes P$, and evaluate its accuracy.
For a sample $z=(x,y)\sim P$, where $x\in \mathbb{R}^d$ is the input and $y$ its corresponding label, and a model $\thetan$, the discriminator minimizes the binary cross-entropy loss:
\[
    \ell_{\textrm{DISC}}(\thetan, z) = \text{BinaryCE}\left(\bsl(\thetan, x, y), \mathbbm{1}_{z\in \mathcal{D}_{\textrm{train}}(\thetan)}\right),
\]
where $\mathcal{D}_{\textrm{train}}(\thetan)$ is the training set of $\thetan$.

The discriminator is implemented as a feed-forward neural network that takes as input: $x$ the input data, the flattened parameters of $\thetan$ and the loss of the model $\thetan$ on $x,y$.
For instance, if the model $\thetan$ is a binary classifier, $\bsl$ is a neural network with input $x\in \mathbb{R}^d$, $\thetan$ and the binary cross-entropy loss of $\thetan$ on $(x,y)$.

We train the discriminator using a set of models, $\{\thetan{_ i}\}_{i\in\{1,\ldots,k_{\text{run}}\}}$ where each $\thetan{_ i}$ is trained on an independent dataset $\{z_{i,1},\ldots, z_{i,n}\} \sim P$ of $n$ i.i.d. samples.
To generate negative samples, we independently sample additional sets, $z^{\textrm{neg}}_{i,1},\ldots,z^{\textrm{neg}}_{i,n} \sim P$, ensuring no overlap with the training sets of any models, or between the negative samples of different models.
This independence between datasets is critical for preventing information leakage but may be restrictive in practice due to high data requirements.


A key drawback of this approach arises when $\thetan$ contains multiple layers.
Different permutations of the weights of the hidden units can represent identical models, but the discriminator $\bsl$, which relies on flattened parameters, is not invariant to such permutations.
