We provide in this section the main theoretical results on the MIS of quantized algorithms. For the results of \autoref{sec:theo_res} and \autoref{sec:algo} to hold, it is mandatory to give a proper mathematical setting, although not required for the reader to pursue. We therefore refer to \autoref{ssec:math-sett} for a formal mathematical setting.

\subsection{Fixed Quantizer}
We start off by giving a simple result. Let $\gQ$ be a fixed quantizer, then under mild additional assumptions presented in \autoref{ssec:fq-add-ass}, the following result holds.
\begin{theorem} 
\label{thm:fixed_pos}
There exists a constant $C_P^1 > 0$ satisfying 
\begin{equation}
    \liminf{n}-\frac{1}{n}\log\pp{1-{\MIS}_n(P, \gA_\gQ)} \geq C_P^1.
\end{equation}
\end{theorem}
Importantly, the constant \( C_P^1 \) depends solely on the distribution of \( \ell(\theta, \rz) \) for all \( \theta \in \Bar{\Theta} \), where $\rz$ has for distribution $P$. The detailed formulation of the theorem can be found in \autoref{thm:main_fixed_quant}. This theorem establishes that the MIS is of order \( 1 - e^{-n C_P^1 (1 + o(1))} \) for some constant \( C_P^1 > 0 \) for a given algorithm. The result suggests that the approximation holds as the dataset size approaches infinity, assuming the architecture size remains fixed. However, in practice, when developing machine learning models, it is common to adjust the architecture based on the dataset, particularly its size.


%Importantly, the constant $C_P^1$ only depends on the distribution of $l(\theta,\rz)$ for all $\theta\in\Bar{\Theta}$. The details of the theorem are given in Theorem \ref{thm:main_fixed_quant} in Appendix ??. Theorem \ref{thm:main_fixed_quant} states that the MIS is of order $1 - e^{-nC_P^1(1+o(1))}$ for some constant $C_P^1>0$ for a given algorithm. The limit suggests that this result is accurate when the dataset size grow to infinity, without the architecture size to adapt to it. However, when building machine learning models, it is natural to adapt the architecture to the dataset, specifically to its size. 


\subsection{Size-Adaptive Quantizers}
\label{subsec:Qn}

As an example, it is common to over-parameterize models relative to the dataset size, as seen in the case of LLMs. 
Therefore, \autoref{thm:fixed_pos} may not provide an accurate approximation for very large datasets. 
We now let our quantizer \( \gQ_n  \) (and therefore the number of quantized values $K_n$ and $\Thetaq_n\coloneqq\{\thetaq_1,\cdots,\thetaq_{K_n}\}$) be \textit{Size-Adaptive}, i.e. depends on the sample size. Let $\delta_k^n\coloneqq m_{\thetaq^n_k}-m_{\thetaq^n_1}$ be the \textbf{loss gaps} and  $\pp{\sigma_k^n}^2 = \textrm{Var}\big(\ell\pp{\thetaq^n_k,\rz} - \ell\pp{\thetaq^n_1,\rz} \big)$ be the \textbf{loss variabilities}, which corresponds to the variance of the difference of the losses between $\thetaq^n_k$ and $\thetaq^n_1$. 

The dependence of \( \gQ_n \) on the dataset size \( n \) formalizes at least two scenarios: either the quantization procedure remains the same, but the architecture size adapts to the training dataset, or the architecture size is fixed while the quantization procedure changes. Specifically, the first interpretation can be seen as the common practice in machine learning to scale models to the dataset size.
\begin{example}[Scaling Architecture]
Let the number of parameters of our original models follow a scaling law~\cite{hoffmann2022trainingcomputeoptimallargelanguage, kaplan2020scalinglawsneurallanguage} $f$ such that its number of parameters is: $f(n)$. Let the quantization method be fixed to a 1-bit quantization (mapping each parameter to its sign for instance).
Then, following Example~\ref{ex:BNN}, for a dataset size $n$, the size of $\Thetaq_n$ is $K_n=2^{f(n)}$.
\end{example}
Under some mild assumptions outlined in Appendix \ref{ssec:saq-add-ass}, we obtain the following result.
\begin{theorem}\label{thm:seqQ} Assume that ${\sqrt{n}\mkn{2}\toinf{n}\infty}$ and ${\mkn{2}\toinf{n}0}$. Then, we have
\begin{equation}
    \liminf{n}-\frac{1}{n\pp{\mkn{2}}^2}\log\big(1-\MIS_n(P, \gA_{\gQ_n})\big)\geq \frac{1}{2\sigma^2},
\end{equation}
where $\sigma^2 = \underset{k}{\max} \liminf{n} \pp{\mkn{2}/\mkn{k}}^2\pp{\sigma_k^n}^2$.
\end{theorem}



For a size-adaptive Quantizer $\gQ\coloneqq (\gQ_n)$, let $r_{\gQ}^n\coloneqq \pp{\delta_2^n}^2/(2\sigma^2)$ be the constant of \autoref{thm:seqQ} multiplied by the square of the minimal loss gap. \autoref{thm:seqQ} then stipulates that the MIS of a quantized algorithm, whose quantization $\gQ$ is Size-Adaptive, is of order $1 - e^{-nr_\gQ^n(1+o(1))}$ which by hypothesis converges to $1$ as $n$ grows to infinity, ensuring asymptotic security.
Furthermore, \autoref{thm:seqQ} suggests that for two size-adaptive Quantizers $\gQ$ and $\gR$,  $r_\gQ^n \geq r_\gR^n$ implies that $\gA_{\gQ}$ produces more secure parameters than $\gA_{\gR}$ (asymptotically). \autoref{thm:seqQ} then proposes to use $r_\gQ^n$ as a measure to compare different quantizers. Most importantly, this quantity wholly relies upon the asymptotic expectations and variances of the random variables $\ell(\thetaq_k^n,\rz) - \ell(\thetaq_1^n,\rz)$. 




% \textcolor{blue}{
% In the following sections, we will call $\qcertif = \pp{\delta_{\gQ,2}^n}^2r_{\gQ}$, the metric we  aim to estimate to compare the privacy level of different embedders.
% }


% \subsection{Discussion}
\begin{remark}
The theoretical setting of \autoref{subsec:Qn} encompasses modern architectures and habits of machine learning designs. This setting enables us to explicit the quantity $r_\gQ^n$ controlling the asymptotic MIS of a quantized algorithm. The most vital point of \autoref{thm:seqQ} is that this result holds for all attacks, including currently unknown (and possibly more powerful) attacks. 
% This comes at the drawback of requiring few mild assumptions, and being an asymptotic result.
% The method we propose in \autoref{ssec:algo} to approximate $r_\gQ^n$ demonstrates a high correlation with the baseline method as shown in \autoref{fig:scatterplot_synth}. This ensures, although being an asymptotic result, that $r_\gQ^n$ is a sufficiently accurate privacy measure.
The following sections focus on empirically demonstrating that the estimate of $r_\gQ^n$ is adequate to rank quantizers by their privacy level.   
\end{remark}

