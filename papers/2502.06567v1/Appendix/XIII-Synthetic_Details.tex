\newpage

\section{Synthetic experiments}
\label{app:synthetic_details}

\begin{wrapfigure}[28]{r}{0.53\linewidth}
   % \vspace{-4cm}
    \centering
    \includegraphics[width=\linewidth]{Figures/synth_figs/barplot_dperfs_vs_rdelta}
    \caption{
        Evolution of $\qcertif$ with the quantized model's performance as the ratio of the original model's training accuracy (line) for various quantizers in our synthetic setup.
    }
    \label{fig:barplot_synth}
\end{wrapfigure}

\subsection{Trade-off between privacy and performance}

In this section, we provide additional details on the synthetic experiments conducted to evaluate the trade-off between privacy and performance of quantized models.
This trade-off is illustrated in~\autoref{fig:barplot_synth}, where we plot the evolution of the quantification certificate $\qcertif$ with the model's performance as the ratio of the original model's training accuracy.
We find that the trade-off between privacy and performance is less pronounced compared to the real-world experiments.
In particular, while the least private quantizers do preserve most of the original performance, the more private quantizers seem to achieve similar performances on some data distribution (in particular, when $\sigma = 3$).
This could be explained by the low performances of the trained models on such distribtuions as illustrated in~\autoref{tab:synth_perf}.
Furthermore, simple mixture of Gaussians might not be relevant to capture the complexity of real-world data distributions, and we therefore decided to focus our analysis of the performance-privacy trade-off on real-world applications.

\begin{table}
    \centering
    \caption{
        Description of the quantizers used in the synthetic experiments.
    }
    \label{tab:synth_perf}
    \resizebox{\linewidth}{!}{\input{Tables/synth/classification}}
\end{table}


%\FloatBarrier

\subsection{Stability and Computational Complexity}
\label{ssec:stability}

\begin{figure}[h]
        \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/bsl_corr_rank}
        \caption{
            Baseline MIS
        }
        \label{fig:bsl_corr_rank}
    \end{subfigure}
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/rdelta_corr_rank}
        \caption{
            $\qcertif$
        }
        \label{fig:rdelta_corr_rank}
    \end{subfigure}
    \caption{
        Correlation between the rankings obtained with the baseline MIS method (resp. $\qcertif$) at a given number of run, with the ranking obtained with the baseline MIS method (resp. $\qcertif$) at 300 runs.
    }
    \label{fig:rank_corr}
\end{figure}

As explained in~\autoref{ssec:baseline_estimation}, the baseline approach consists in training a discriminator to distinguish between samples from the training set of a given $\thetan$ and samples from the product distribution $P_{\thetan}\otimes P$.
Similarly the $\qcertif$-based approach relies on the traing of multiple models to average the values of $\qcertif$ obtained.

The computational overhead induced by the $\qcertif$-based approach, namely computing the validation loss of the quantized models, is negligible compared to the total training time (1s against 4m).
Similarly, the training of the discriminator takes only about 40m.

As a result, training multiple models $\thetan$ over multiple runs is the computational bottleneck of our privacy evaluations.
To properly evaluate the time required to obtain both rankings, one would have to answer the following question: 'How many runs do i need to launch to ensure the ranking I obtained is stable?'

\autoref{fig:rank_corr} shows how after $15$ runs, the rankings obtained with $\qcertif$ are already highly correlated with the rankings obtained with 300 runs, while the rankings obtained with the baseline MIS method require $150$ runs to reach the same level of correlation.
As a result, the time required to obtain stable rankings with $\qcertif$ is significantly lower (\(\approx 1\)h) than with the baseline MIS method (\(\approx 10\)h).


\subsection{Visualization of the datasets}

We provide in~\autoref{fig:synth_datasets} a visualization of the synthetic datasets used in the experiments, through a PCA projection in dimension 2.
This visualization helps understand how different data distribution might result in different empirical results, as some datasets are more challenging than others, such as the dataset with $n_{\textrm{cluster}} = 6$ and $\sigma = 1.5$, for whom the labels of the datapoints are easily separable, while $n_{\textrm{cluster}} = 16$ and $\sigma = 3$ provides a more challenging dataset, with overlapping clusters.

\begin{figure}[ht]
    \centering
    %%% 6
    \begin{subfigure}{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/datasets/6-1.5}
        \caption{
            $n_{\textrm{cluster}} = 6, \sigma = 1.5$
        }
        \label{fig:6-1.5}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/datasets/6-2}
        \caption{
            $n_{\textrm{cluster}} = 6, \sigma = 2$
        }
        \label{fig:6-2}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/datasets/6-3}
        \caption{
            $n_{\textrm{cluster}} = 6, \sigma = 3$
        }
        \label{fig:6-3}
    \end{subfigure}
    %%% 8
        \begin{subfigure}{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/datasets/8-1.5}
        \caption{
            $n_{\textrm{cluster}} = 8, \sigma = 1.5$
        }
        \label{fig:8-1.5}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/datasets/8-2}
        \caption{
            $n_{\textrm{cluster}} = 8, \sigma = 2$
        }
        \label{fig:8-2}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/datasets/8-3}
        \caption{
            $n_{\textrm{cluster}} = 8, \sigma = 3$
        }
        \label{fig:8-3}
    \end{subfigure}
    %%% 16
    \begin{subfigure}{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/datasets/16-1.5}
        \caption{
            $n_{\textrm{cluster}} = 16, \sigma = 1.5$
        }
        \label{fig:16-1.5}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/datasets/16-2}
        \caption{
            $n_{\textrm{cluster}} = 16, \sigma = 2$
        }
        \label{fig:16-2}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/synth_figs/datasets/16-3}
        \caption{
            $n_{\textrm{cluster}} = 16, \sigma = 3$
        }
        \label{fig:16-3}
    \end{subfigure}
    \caption{
        Visualization of the synthetic datasets used in the experiments, through a PCA projection in dimension 2 (the original space is $\mathbb{R}^{128}$).
    }
    \label{fig:synth_datasets}
\end{figure}


\FloatBarrier