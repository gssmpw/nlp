\section{Experiment}
\label{sec4:experiment}
% es edit
\begin{figure*}
\centering
\includegraphics[width=0.90\linewidth]{fig3.voc_result_2.pdf}
\caption{Visualization of experimental results. DV3Res50 is used as the source model and images of first column are clean images and adversarial examples generated by PGD~\cite{mkadry2017towards}, SegPGD~\cite{gu2022segpgd}, CosPGD~\cite{agnihotri2024cospgd}, and FSPGD (Ours). second column is ground truth of input images. And other columns are predictions of target models. }
\label{fig:visual}
\end{figure*}
% \setlength{\textfloatsep}{5pt}  % 표와 본문 사이 여백 조절

\subsection{Experimental Setup}
\label{sec4.1:Experimental Setup}
\textbf{Datasets}. We use two popular semantic segmentation datasets in our experiments: PASCAL VOC 2012~\cite{pascal-voc-2012}, Cityscapes~\cite{cordts2016cityscapes}. The VOC dataset includes 20 object classes and one background class, containing 1,464 images for training and 1,499 for validation. Following the standard protocol~\cite{hariharan2015hypercolumns}, the training set is expanded to 10,582 images. The Cityscapes dataset, focused on urban scene understanding, comprises 19 categories with high-quality pixel-level annotations, including 2,975 images for training and 500 for validation. In our experiments, attack performance is evaluated using the validation set of each dataset.
% The ADE20K semantic segmentation dataset contains scene-centered images consisting of 25,574 training datasets and 2000 validation datasets, with 150 semantic categories including individual objects.


\noindent
\textbf{Models}. In this paper, we employ popular semantic segmentation models, \ie PSPNet-ResNet50, DeepLabv3-ResNet50~\cite{chen2017rethinking}, SegFormer-MiT B0~\cite{xie2021segformer}, and Mask2Former-Swin S~\cite{cheng2022masked} as our source and target models, with FCN-VGG16~\cite{long2015fully} additionally used as target model. We conduct cross-validation by alternating source and target models to demonstrate the transferability of the proposed method. For instance, when PSPNet-ResNet50 is used as the source model, we measure attack performance on DeepLabv3-ResNet101, PSPNet-ResNet101, FCN-VGG16.

\noindent\noindent\textbf{Parameters}. Each comparison experiment follows the $l_\infty$-norm, setting the maximum perturbation value $\epsilon$ to 8/255. The step size $\alpha$ is set to 2/255 and the total iteration $T$ is set to 20. The proposed method has a user parameter $\tau$ which acts the threshold value in Eq.~\ref{eq7}. In our experiments, we set $\tau$ value as cos($\pi/3$). The reason we set the threshold value as a cosine value is as follows: since $\textrm{M}(p,q)$ is calculated through the inner product of two vectors with a magnitude of 1, its value represents the cosine of the angle $\theta$ between two vectors. Therefore, we choose the threshold value based on the cosine value. 

\noindent
\textbf{Metrics}. To assess the adversarial robustness of segmentation models, we use the standard metric, mean Intersection over Union (mIoU). Lower mIoU indicate greater attack performance. We report mIoU (\%) scores for both clean images and adversarial examples.



\subsection{Experimental Results}
\label{sec4.2:Expresult}
% es edit - transformer model
We first compare the attack performance on conventional methods~\cite{agnihotri2024cospgd, gu2022segpgd, mkadry2017towards, xie2017adversarial, lin2019nesterov, xie2019improving, dong2019evading} with the proposed method. The experimental results are summarized in Tables~\ref{table1} and ~\ref{table2}. \textit{PSPResX} and \textit{DV3ResX} indicate the PSPNet~\cite{zhao2017pyramid} and DeepLabV3~\cite{chen2017rethinking} with ResNet50~\cite{he2016deep} (or ResNet101~\cite{he2016deep}) encoder, respectively. In the Cityscapes, SegFormer~\cite{xie2021segformer} with a MiT-B0~\cite{xie2021segformer} encoder and Mask2Former~\cite{cheng2022masked} with a Swin-S~\cite{liu2021swin} encoder are used as transformer-based source models.
The proposed method shows high attack performance on the source model compared to conventional methods, excluding CosPGD~\cite{agnihotri2024cospgd} which is designed for white-box attack. To evaluate transferability, we measure mIoU on various target models. In this study, we select target models such that the encoders (\textit{e.g.} ResNet50 and ResNet101) do not overlap between source and target models. As shown in Tables~\ref{table1} and~\ref{table2}, the proposed method exhibits significantly superior transferability compared to conventional methods. In particular, it shows strong attack performance not only on target models using ResNet-based encoders but also on substantially different models based on transformer in Table~\ref{table2}. These results indicate that the proposed method is better suited for real-world scenarios compared to traditional methods. Due to page limitations, we compare the performance of only a few source models in Tables~\ref{table1} and ~\ref{table2}. Additional experimental results comparing a wider range of conventional methods are described in the supplementary material.

For qualitative evaluation, we visualize adversarial examples along with their corresponding prediction results. In our experiments, we set DeepLabV3-ResNet50 as the source model. PSPNet with Resnet50 (and Resnet101)and DeepLabV3 with Resnet50 (and Resent101) set as the target model. As shown in Fig.~\ref{fig:visual}, prediction results of conventional methods are similar to the results on clean images, indicating weak transferability. In contrast, the proposed method successfully attacks target models, demonstrating strong transferability. Based on these results, we conclude that the proposed method achieves the state-of-the-art transferability performance. Additional images of attack results are provided in the supplementary material. 
% es edit
% ----------tau---------
\subsection{Ablation Studies}


\label{sec4.3:Ablation}
% tau, LEX/LIN 각각, Layer위치 
\begin{figure}
\centering
\includegraphics[width=0.97\linewidth]{fig4.tau_graph_v2.pdf}
\caption{mIoU performance across different loss terms. (S) and (T) indicate the source and target models, respectively.}
\label{fig:fig4}
\end{figure}
The proposed method incorporates a user-defined variable $\tau$ for binarizing M. To determine the optimal $\tau$ value, we conduct ablation studies on Pascal VOC 2012 dataset. To select the $\tau$ value that maximizes transferability, we conduct experiments with all other variables fixed by setting $\tau$ to $cos(\pi/3)$, $cos(\pi/4)$, and $cos(\pi/6)$ and Fig.~\ref{fig:fig4} presents the results. Since the average mIoU value was the lowest when $\tau$ was set to $cos(\pi/3)$, we selected $cos(\pi/3)$ in our study. As shown in Table~\ref{table1} and Fig.~\ref{fig:fig4}, the proposed method outperforms existing methods, regardless of the $\tau$ value. Therefore, we believe that, despite having a user-defined parameter, the proposed method offers the advantage of superior performance compared to existing methods. 
% ----------lambda---------
The proposed loss function consists of two components: $L_{ex}$ and $L_{in}$. To evaluate the effect of each loss term, we conduct an ablation study with five different configurations. First, we consider using only the external loss term $L_{ex}$, and second, using only the internal loss term $L_{in}$. Third,  we explore a fixed weight combination of the two losses, where $L_{ex}$ + $\lambda_t L_{in}$  is used with a constant $\lambda$ (e.g. 0.1, 0.5, 1.0). Finally, we employ an adaptive weighting strategy in which both losses are dynamically adjusted using $\lambda$ at each iteration, following the formulation $\lambda_tL_{ex}$ + $(\lambda_t-1) L_{in}$. As shown in Fig.~\ref{fig:fig5}, we observe that the experiment using the dynamic lambda strategy achieved better attack performance compared to other loss combinations. Hence, we employ the dynamic lambda strategy.
% -------------
% Furthermore, we conduct ablation studies to identify the most effective feature extraction locations within the source model. For each source model, We perform experiments on the encoder layers including ResNet-50, ResNet-101, MiT-B0, and Swin-Small. Through experiments, we identified the optimal layer that maximizes transferability. Specifically, for ResNet-50, we found that the second layer of conv3\_x in the architecture referenced in ~\cite{he2016deep} was the most effective, while for ResNet-101, the tenth layer of conv3\_x yielded the best results. Additionally, for transformer-based models, we experimentally determined that the optimal layers were the first layer of Transformer Block 1 in MiT-B0~\cite{xie2021segformer} and the fisrt layer of Stage 2 in Swin-Small~\cite{cheng2022masked}. All of ablation studies are shown in the supplementary material.

Furthermore, we conduct ablation studies to determine the most effective feature extraction layers in various source models. Trough conducting extensive experiments, we determine the optimal layers are Layer 2 of Conv3\_x in ResNet-50, Layer 1 of Transformer block 1 in MiT-B0, and Layer 1 of Stage 2 in Swin-S. Detailed results are provided in the Supplemental Material.

% Additionally, we conducted ablation studies to determine the optimal feature extraction locations in the source model. As shown in Fig.~\ref{fig:fig4}, we measured mIoU performance across various locations. The layer names indicate the feature map extraction points within the encoder (\ie, ResNet50 and ResNet101). For instance, the layer name 2\_1 refers to the output of the first block in the ResNet Conv2\_x layer. As shown in the graph, selecting a middle layer in the encoder for the attack is more effective than using either the early or late layers. Based on these observations, we determined the location with the lowest average mIoU for use in our experiments (layer name 3\_2 in ResNet-50 and layer name 3\_10 in ResNet-101).


% Furthermore, we conduct ablation studies to identify the most effective feature extraction locations within the source model. The results display mIoU performance across different extraction points. The layer names specify feature map extraction locations within the encoder (specifically, ResNet50 and ResNet101). For example, the notation `layer name 2\_1' refers to the output of the first block within the ResNet Conv2\_1 layer. As shown in the graph, selecting an intermediate layer within the encoder for the attack yields better results compared to using either the early layers or the later layers. Based on these findings, we identify the extraction points with the lowest average mIoU for our experiments, which are layer name 3\_2 in ResNet50 and layer name 3\_10 in ResNet101. 
 

% \begin{figure}
% \centering
% \includegraphics[width=1.0\linewidth]{fig3.pdf}
% \caption{mIoU performance across different $\tau$ values. (S) and (T) indicate the source and target models, respectively.}
% \label{fig:fig3}
% \end{figure}


% \begin{figure}
% \centering
% \includegraphics[width=1.0\linewidth]{figure4.pdf}
% \caption{mIoU performance across different loss terms. (S) and (T) indicate the source and target models, respectively.}
% \label{fig:fig4}
% \end{figure}