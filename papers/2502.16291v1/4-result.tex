\section{A Tale of Two AIs: Workflow Mimicry Versus Generative Exploration}
\label{sec:genai-vs-ai}
As we investigated the recent advancement of AI-assisted research tools, we noticed a subtle shift in the philosophy behind AI-powered research tools. Traditional AI/ML systems are designed to enhance established research workflows by automating well-defined tasks. For example, the Analogical Search Engine~\cite{AnalogicalSearchEngine} employs a token-level ranking algorithm to retrieve articles with similar ``purposes'' and ``mechanisms'', while tools like SenseMate~\cite{sensemate} and Scholastic~\cite{scholastic} focus on organizing data and semi-automating qualitative coding -- all while keeping the researcher in control. Similarly, Threddy~\cite{threddy} utilizes various ML models to parse and structure PDF content. In contrast, LLM-powered tools such as CoQuest~\cite{CoQuest}, IdeaSynth~\cite{IdeaSynth}, and Synergi~\cite{synergi} are gradually shifting the emphasis towards generative exploration. These systems leverage the vast knowledge embedded in LLMs to generate novel content, suggest alternative directions, and even reframe research problems, requiring users to select and refine AI-generated options to actively advance their investigation. Although this transition is still in its early stages, it marks a notable turning point in how support is provided: traditional systems mimic existing workflows with deterministic assistance, whereas LLM-enabled tools encourage dynamic, exploratory engagement. This evolving prospect invites further discussion on balancing the design of research tools that not only streamline tasks but also enrich cognitive engagement, ensuring that researchers remain actively involved and creatively challenged throughout the discovery process.