\section{Design Space}
\label{sec:design-space}

% \subsection{Is the User Actively Engaged with the Tool?}

A fundamental challenge in integrating AI-powered research tools is ensuring that users remain cognitively ``in the loop'' rather than passively accepting AI-generated output. While automation promises efficiency and rapid idea generation, it also risks encouraging users to rely too heavily on system outputs, which can diminish human critical thinking and decision-making processes. We explore four design dimensions critical to navigating this tension.

% We explore 4 design dimensions that inform cognitive engagement when developing AI-assisted research tools: User Agency \& Control, Divergent \& Convergent Thinking, Adaptability, and Accuracy. In doing so, we highlight design patterns that promote meaningful human-AI collaboration while identifying potential pitfalls that could limit researcher agency, cognitive engagement, or trust in AI-driven insights.

% We expect a tool with good user agency that allows users to intervene, override, or refine AI outputs. They take an active role in evaluating and steering the research process. This active involvement forces researchers to check the validity of automated suggestions. It helps to strengthen their critical thinking and decision-making. For example, systems like CoQuest require users to constantly evaluate AI outputs and guide the research process \cite{CoQuest}

% The balance of AI contribution in divergent and convergent thinking affects cognition by guiding how researchers balance searching for new ideas with refining those ideas. The tools should support both creative exploration and systematic analysis. This dual approach keeps users mentally agile and engaged. In brainwriting sessions, participants must justify their choices and debate various ideas, which reinforces both divergent and convergent modes of thought \cite{brainwriting}. Similarly, IdeaSynth uses clarifying questions to prompt deeper idea refinement \cite{IdeaSynth}.

% We define adaptability as a tool’s flexibility to support different research tasks and user preferences. A tool that adapts to diverse approaches aligns with a user’s natural cognitive strategies. This design enhances various problem-solving styles. It lets users work in a way that suits their thinking patterns.

% Lastly, accuracy is a crucial consideration for building trust in a system. A tool must deliver reliable and contextually relevant information. When researchers trust the tool, they integrate its insights with confidence. For example, Paperweaver directly provide the transparency on all relevant information that researchers can depend on \cite{paperweaver}. This trust leads to more profound results and focuses cognitive effort on meaningful analysis rather than refining LLM-generated outputs. 

% These dimensions create a framework that continuously shapes cognitive engagement through design and functionality. LLM tool designs must balance these factors to enhance human cognition. Their goal is to keep users active and critical throughout the research process. The following subsections will examine all existing tools under each dimension and discuss how they contribute to overall cognitive engagement.


% "is user actively engaged in the work"
% We want to discuss how current tools engage users, passively or actively. The design challenge is to ensure that users remain cognitively “in the loop,” regardless of the automation level, especially on critical/high-stake intersections.

% TODO: we don't need this many example; a couple of high-level ones would be enough; we will mainly use the rest of the dimensions to articulate the appropriate amount of cognitive engagement.


% \subsubsection{Example of good use cases}
% \begin{itemize}
%     \item \cite{AnalogicalSearchEngine} The core design principle of the system is to surface articles that are \textit{analogically} relevant, potentially from very different domains. The fact that user need to be cognitively active to search for relavant article. And engaged in search results and refine the search query again.
    
%     \item \cite{brainwriting} Convergence Stage: The discussion and selection process necessitates active cognitive engagement. Participants must justify their choices, debate the merits of different ideas, and synthesize information from both human and AI sources.
    
%     \item \cite{CoQuest} RQ Flow Editor: The user is constantly required to evaluate the AI's output, provide feedback, and make decisions about the direction of the RQ development. This is not a passive consumption of AI-generated content; it's an active, intellectually demanding process. The user must remain "in the loop" to guide the AI.

%     \item \cite{CoQuest} AI Thoughts Panel: is specifically design for explaining LLM's reasoning and rationale. This is to engage user actively, and make sense of system's decision making process. Also, the wait time introduced, indirectly force user to engage with other component/interaction, further increase Cognitive Engagement.

%     \item \cite{IdeaSynth} Node-Based Canvas Visualization (Fig. 2, 4): The canvas interface with interconnected nodes provides a visual representation of the research idea's structure and development. his externalizes the user's thought process, making it easier to see connections, identify gaps, and explore different variations. It promotes active cognitive engagement by requiring users to organize and structure their ideas. The visual representation can reduce cognitive load compared to a purely text-based approach.

%     \item \cite{IdeaSynth} Clarifying Questions from AI (Fig 4, 5): The AI prompts users to clarify aspects of their ideas. This forces users to actively think about the details and nuances of their ideas, promoting deeper cognitive engagement. It's not just passive reception of suggestions; it's an interactive process of refinement.

%     \item \cite{paperweaver} This directly addresses cognitive engagement by providing concise, relevant information. It helps users quickly assess relevance without reading the full abstract, addressing the problem of information overload highlighted in the paper's introduction and formative study. It moves beyond simple keyword matching to provide a more semantically meaningful connection.

%     \item \cite{scholastic} Document Map: The Document Map encourages active cognitive engagement. Users are not passively presented with results; they must actively explore the clusters, hover for information, and make decisions about which documents to sample. The visual metaphor of a map encourages exploration and the formation of mental models. (Section 6.1)

%     \item \cite{scholastic} Document Reader: The Document Reader promotes active engagement through the coding process. Highlighting text and selecting keywords requires careful reading and interpretation. The ability to add memos further encourages reflection and documentation of the user's reasoning. (Section 6.2)

%     \item \cite{scholastic} Code Examiner: The Code Examiner encourages active engagement by requiring users to navigate the hierarchical word clusters and make decisions about which documents to sample based on their codes. The ability to refine codes and categories further promotes reflection and iterative analysis. (Section 6.3)

%     \item \cite{synergi} Combined PDF Viewer and Highlighter. Requires active reading and selection of relevant text. (Section 3.1 and shown in Figure 3A). Highlighting is an active reading strategy. The user must constantly evaluate the text for relevance to their research question.

%     \item \cite{synergi} Drag-and-Drop Outline Editor: Requires the user to actively synthesize and organize information. (Section 4.4 and Figure 5) This is not a passive activity. The user must make decisions about the structure of their outline, the relevance of different threads, and the overall narrative of their literature review.

%     \item \cite{threddy} Active Reading and Highlighting: The core interaction of Threddy – highlighting text and extracting references – requires active reading and engagement with the source material. Users are not passively consuming; they are actively selecting and curating.

%     \item \cite{threddy} Thread Organization: The drag-and-drop interface for organizing threads forces users to actively consider the relationships between different pieces of information and construct a mental model. This promotes deeper understanding.


% \end{itemize}

% \subsubsection{Mixed}
% \begin{itemize}
%     \item \cite{CoQuest}Paper Graph Visualizer: provides the tools for cognitive engagement (access to papers, summaries, citation links), but it doesn't actively enforce or guide users towards critical thinking. It relies on the user's own initiative and research skills to avoid the pitfalls you've mentioned. This is a significant difference. It's a good tool, but it's not inherently good for cognitive engagement if used passively. Fail to consider alternative perspectives: The tool might present a biased or incomplete view of the literature. Users might not actively seek out papers outside the Tool's suggestions. Skip deep reading because it's readily accessible: User might engage superficially, and think they have fully understood the main idea, while skipping deeper cognitive engagement.

%     \item \cite{disciplink} By presenting EQs rather than definitive answers, the system encourages users to think critically about different perspectives. The theme extraction and information scent features help users process information efficiently without getting lost in details. But passively present papers may be risk. 


%     \item \cite{IdeaSynth} Edge-Based Connection Validation (Fig.4): User can expand the edge between two nodes, and see how the connection can be improved. 

%     \cite{threddy} Recommendation: While recommendations are presented, the user must actively evaluate their relevance. This requires cognitive engagement, but the limited control over the recommendation criteria means this engagement might be less efficient or focused than it could be. The "FOMO" expressed by one participant (Section 6.2) suggests that the recommendations, while engaging, might also be overwhelming.
% \end{itemize}

% \subsubsection{Example of bad use cases}
% \begin{itemize}
%     \item \cite{brainwriting} Divergence stage: risk of over-reliance on the LLM, leading to passive acceptance of its suggestions. If users become "prompt engineers" rather than "idea generators," their cognitive engagement shifts from understanding the problem domain to understanding the LLM's quirks. 
%     \item 
% \end{itemize}

\subsection{User Agency and Control}
\label{sec:agency}

Human-AI collaboration systems aim to improve productivity and creativity by offloading certain tasks from humans to AI systems while keeping the user in the driver's seat. Providing user agency and control via source material participation, the ability to refine AI output, and the ability to reject and override automated actions are crucial to maintaining cognitive engagement from the user.

\subsubsection{Engagement with source material.} For tools aimed at making sense of existing text content (such as qualitative coding, thematic analysis, or literature reviews), there is a delicate balance to be struck between AI assistance and user agency. While recent advancements in LLM capabilities show promise in processing and summarizing large amounts of text, users still have to engage with the source text to build their own understanding and avoid model overreliance. One way to foster engagement is for user-selected text highlights to drive content generation. Systems such as Synergi~\cite{synergi} and Threddy~\cite{threddy} integrate PDF readers that transform user-selected highlights into seeds for AI-driven research thread generation, while Relatedly~\cite{Relatedly} further refine this process by organizing and highlighting overlapping research themes. Meanwhile, platforms like Scholastic~\cite{scholastic} and SenseMate~\cite{sensemate} scaffold existing analysis methods with cluster suggestions and strategic sampling. The role of AI in these systems (such as Scholastic~\cite{scholastic} and SenseMate~\cite{sensemate}) is to scaffold existing analysis methods with cluster suggestions and strategic sampling.

\subsubsection{Refining AI output.} Human-centric AI tool design assumes the user is the expert, giving them the power to modify the output provided by the AI system. Most tools we reviewed allow users to edit and refine AI-generated artifacts to ensure that they meet the user's goals. In Threddy~\cite{threddy}, for example, users can manually clean up errors in references and links extracted from a paper snippet. Beyond fixing errors, user editing can be designed into human-AI sensemaking systems to varying degrees. Arranging AI outputs into a more interpretable structure (such as node-link diagrams~\cite{IdeaSynth, CoQuest} or outlines~\cite{synergi}) can foster deeper engagement with suggestions. Finally, iterating on prompts and queries can help users gradually incorporate new ideas and discoveries into AI output. This is notably useful in cases such as the Analogical Search Engine~\cite{AnalogicalSearchEngine}, where users may not know exactly how to initially prompt but can gain and apply new information with each re-prompt. 

% Systems can provide the user with multiple ways of engaging with and refining AI suggestions. In Synergi~\cite{synergi}, for instance, users extract clips from papers which are then used to recommend research threads that map to the broader literature. The resulting threads can be curated and reorganized into new research outlines in an iterative process.

\subsubsection{Rejection and overriding.} One aspect of control that merits further consideration is the ability of users to reject, override, or ignore model output. Rejection can manifest in systems implicitly. For example, editing or curating AI output implies rejection of the original content in part or whole. However, most of the research papers we reviewed had AI assistance embedded in the system, with minimal ability to ``turn off'' AI suggestions. One notable exception is SenseMate, which explicitly aims to provide AI theme suggestions on demand rather than by default~\cite{sensemate}. In SenseMate, AI suggestions are hidden by default; users can also see the reasoning for the theme suggestions and explicitly reject them. Similarly, Scholastic's text clustering algorithm does not impose keywords on clusters. Instead, users have the option of either developing internal mental models of the meaning of the cluster or providing the algorithm with explicit codes that can be iterated on~\cite{scholastic}.

\begin{designRecom}{Provide User Agency and Control}
\textit{Design Insight:} Users should have meaningful control and agency within AI-assisted systems to ensure that they remain the primary decision-makers. Users should be able to engage with the source text and edit, refine, or reject AI output.
\smallskip

\textit{Implications:} 
\begin{itemize} 
\item \textbf{Customizable AI Assistance:} Users should have control over when and how AI assistance is applied, including the ability to disable suggestions when not needed.
\item \textbf{Iterative Refinement:} Enabling users to edit and refine AI output can lead to more relevant and intentional output.
\item \textbf{Engage the User:} Support user understanding and agency by giving users control over the structure of collaboratively generated insights and providing access to source text where relevant.
\end{itemize}

% \textit{Recommendation example:} Disciplink~\cite{disciplink} highlights a limitation where users can guide the generation of new exploratory research questions but cannot directly edit existing ones. Expanding user control to include full-text editing would enhance agency, foster iterative refinement, and enable LLM suggestions to evolve alongside the user's understanding and mental model.
\end{designRecom}

% \begin{itemize}
%     \item \cite{AnalogicalSearchEngine} The search system gives the user full freedom to continue progressing, user does not need to rely only on this search result.
%     \item \cite{brainwriting} The freeform and plug-and-play LLM usage gives full control to the user. Also, in the Convergence Stage: The selection process is entirely human-driven. The LLM is used as a tool for further development after humans have made the key decisions about which ideas are worth pursuing. This maintains a high level of user agency, as the humans are "calling the shots" on which direction the ideation process takes.
%     \item \cite{IdeaSynth} Facet Node Creation and Editing (Fig. 5): Users can create, title, and edit the content of idea facet nodes (Problem Description, Solution, Evaluation, Contribution). Users are in full control of expressing their ideas within the defined facets. This allows for personalized input and avoids the feeling of being dictated to by the AI.
%     \item \cite{IdeaSynth} Manual Node Linking (Fig. 5)Users can manually link nodes to create relationships between idea facets. This is a good use case. This empowers users to define the structure of their research idea, representing their mental model. It's not forced by the AI, giving the user ultimate control over the conceptual relationships.

%     \item \cite{IdeaSynth} Adopting or Rejecting AI Suggestions (Fig. 4, 5): Users can choose to accept, modify, or ignore AI-generated suggestions for node content, alternatives, and expansions. User is not forced to accept AI output. The system acts as an assistant, offering options, but the user makes the final decision. This prevents overreliance on the AI and maintains user control over the ideation process.

%     \item \cite{IdeaSynth} Literature Search and Collection Management (Fig 3): User can search for relevant scientific papers, add to personal collection, and remove papers from collection, or get AI recommendation if needed. User decide what literature background is relevant to the current ideation context.

%     \item \cite{paperweaver} Suggested Topic Description (Section 4.2.1): The system allow user's direct input for folder description, or generate an default one using LLM. They can override the suggestion, refining it to better reflect their interests.

%     \item \cite{scholastic} Document Sampling (Breadth-First - Document Map): Users can choose to sample randomly (initial exploration) or strategically based on the visualization of document clusters (geographical treemap). They control the granularity of the clusters using a slider. The ability to hover for titles and right-click for previews gives users control over which documents to examine further. The system does not force a particular sampling method. This aligns well with interpretive research, where the researcher's judgment is important.

%     \item \cite{scholastic} Document Sampling (Depth-First - Code Examiner): The Code Examiner allows depth-first sampling based on user-defined codes and categories. Users select codes, and the system presents documents ranked by relevance to those codes (using the underlying model). This provides high agency, as the sampling is directly driven by the researcher's evolving understanding. (Section 6.3, Figure 6) This reinforces user control by allowing them to directly leverage their coding schema to find relevant documents. It's a form of querying the corpus based on the user's interpretive framework.

%     \item \cite{sensemate} Theme Recommendations (On-Demand): AI suggests themes for each unit of analysis (snippet of text). These are not automatically applied. Users must explicitly choose to view and then accept, reject, or mark them as unsure. The system presents themes one at a time to encourage thoughtful review. Note: SenseMate is designed to help users apply this existing codebook more efficiently and consistently, not to develop a new one from scratch. The focus is on deductive coding, where a pre-defined codebook is used, rather than inductive coding, where codes are developed from the data. The authors state: "High rates of intercoder reliability are especially helpful during deductive coding where sensemakers start with a predefined set of thematic codes, which are assigned to qualitative data. The AI support in SenseMate can help users stay grounded in the codebook and minimize coding errors, which can speed up the analysis." (Page 12)

%     \item \cite{sensemate} Rationale Explanations: For each theme recommendation, users can click a "View Reason" button to see why the AI suggested that theme. The rationale is presented as bolded words within the original text snippet (Figure 3). 

%     \item \cite{sensemate}  Feedback Mechanisms (Quick Questions \& Highlighting): If a user rejects a recommendation, they are presented with up to five yes/no questions about whether specific phrases in the rationale are relevant (Figure 4). Users can select or deselect words within the rationale to indicate which parts are relevant or irrelevant (Figure 5). This allows for more nuanced feedback than simple acceptance/rejection. (page 8). feedback system is excellent for several reasons. It increases user agency by allowing them to directly influence the model's behavior (although retraining wasn't implemented in this version). It's adaptable because it provides different levels of feedback granularity (quick questions vs. highlighting). It fosters cognitive engagement by making users actively participate in refining the AI's understanding. \textbf{also in cog engagement (user engage in refining / enhance models), adaptability (provides different levels of feedback granularity (quick questions vs. highlighting), accuracy (refine existing coding to enhance model accuracy))}

    
%     \item \cite{synergi} Outline Editor: The user can drag and drop threads, edit labels, remove irrelevant information, and add their own insights. This allows for direct manipulation and customization, restoring agency after the relatively low-agency thread generation step.

%     \item \cite{threddy} Highlighting and Selection: Threddy allows users to highlight text and areas within PDFs, triggering the extraction of references. This gives users direct control over the starting point of thread creation. The user actively chooses what content is relevant. (Section 4, "Highlighting and Selection")

%     \item \cite{threddy} Reference Deselection: Within the holding tank, users can "deselect any reference they do not want to include or to fix any extraction error." (Section 4) This provides fine-grained control over the automatically extracted information, allowing users to curate the input to the thread.

%     \item \cite{threddy} Thread Creation and Organization: Users can create new threads, add content to existing threads, and (re-)organize threads using drag-and-drop. This offers significant control over the structure and content of their knowledge organization. (Section 4, "Organization")
    

% \end{itemize}

% \subsubsection{Mixed use cases}
% \begin{itemize}
%     \item \cite{CoQuest} The user has direct input at multiple stages. They initiate the process with keywords, provide feedback to refine AI suggestions, and can directly edit the structure of the RQ flow by adding, deleting, or moving nodes. The concern of artificially limiting the expansion of related RQ can be mitigated by re-prompting and re-generating. However, users may still experience unintentional bias from LLM-recommended RQs, and users do not have the option to override manually.
    
%     \item \cite{disciplink} The lack of direct EQ editing, addition, and deletion is a limitation. The user's control is primarily through influencing the generation of new EQs, not manipulating existing ones. This is less agency than a system that would allow full text editing of EQs.

%     \item \cite{scholastic} Coding (Document Reader): Users have high agency in applying codes. They highlight text, apply existing codes, or create new ones. They can also add memos, which is crucial for interpretive research. The "in vivo" keyword selection, while offering some automation, is still under user control (they choose which keywords to select). But user cannot apply multiple code at the same time on a single selection, it is acknowledge as a limitation by original author.

%     \item \cite{synergi} Loopy Belief Propagation (LBP) for Retrieval: The user sets the starting point, but the algorithm determines the expansion. There's no mention of parameters the user can adjust to tune the LBP process (e.g., weighting factors, stopping criteria). This lack of transparency and fine-grained control reduces agency. (Fig 1-B, Section 4.1)

%     \item \cite{synergi} Hierarchical Thread Generation:  The user receives a pre-structured hierarchy generated by GPT-4. While useful for overview, the user has limited input on how this hierarchy is created. The user doesn't choose the clustering method, similarity thresholds, or summarization prompts. This is a "black box" from the user's perspective. It's efficient, but the lack of control could lead to issues if the generated hierarchy doesn't align with the user's mental model. (Fig 1-C, Section 4.2)

%     \item \cite{threddy} Thread Selector Suggestions: The thread selector uses an algorithm to suggest the most relevant thread for new content. (Appendix A). While helpful, this is a recommendation, not a forced action. The user retains the ultimate choice. However, the algorithm's reliance on similarity metrics (and the potential for "high dispersion, low cohesion" as noted in Appendix A) could lead to less-than-ideal suggestions, subtly nudging users in certain directions.


% \end{itemize}
% \subsubsection{Example of bad use cases}
% \begin{itemize}
%     \item \cite{brainwriting} the LLM only suggests relevant diverging topics, without clear reason on the process. If it produces redundant, irrelevant, or biased output (as some students reported), the users can only try different prompts – they can't "debug" the AI's reasoning. Prone to automation bias.
%     \item \cite{disciplink} While users have control over EQs, the process of query generation is somewhat opaque. Section 4.2.2 describes query expansion using LLMs, but the user doesn't directly see or modify these queries. This is a potential limitation, as users might want more transparency or control over the search terms used, especially in unfamiliar disciplines.

%     \item \cite{threddy} Recommendation Control: The "Overview and Discovery" panel provides recommendations based on citation coverage. While users can click "Refresh" to regenerate recommendations, they have limited direct control over the recommendation criteria. The paper mentions a desire for "additional mechanisms for specifying which context is personally more important" (Section 7.1), acknowledging this limitation. The user can only accept or reject recommendations, not shape how they are generated. This is a significant weakness. They can't, for example, prioritize recency, specific authors, or keywords.
% \end{itemize}

\subsection{Divergent and Convergent Thinking}
\label{sec:divergent-convergent}
% Talk about when AI tool helps in divergent thinking (to expand space) and convergent thinking (to filter and narrow down). We try to show that AI can be useful to take over more work in divergent stages, so users can be exposed to more previously unknown knowledge, but it is less okay if we are in convergent stages where the user should be taking charge in terms of direction and criteria.

% CoQuest: divergent thinking: balanced cognitive engagement, effective for both divergent and convergent tasks

% Alalogical Search engine: more cognitive engagement, user are asked to actively adpat and apply ideas from analogical articles, the ai are maining focused on divergent thinking 

% brainswriting: the system fosters collaboration and critical engagement with AI, it is designed to help users to generate many idea, which is AI partcipated in a divergent thinking

% Disciplink: divergent thinking, DiscipLink generates diverse exploratory questions (EQs) from various disciplines, and crafts queries to broaden the search, users can create their own EQs based on findings.

% ideasynth: ai contribute into divergent thinking, it helps users generate and connect research ideas by using AI to suggest alternative ideas and connections, AI gives suggestions on improving the idea. It also helps users refine their research questions. 
% also provides some convergent thinking, provides literature analysis to summarize and connect papers with the nodes.

% luminate: divergent thinking, users diverge by generating multiple responses from a single prompt, the system is designed to help with the generation of the design space rather than individual artifacts

% paperweaver: mixed approach, PaperWeaver surfaces connections between papers that may be relevant to the user, which helps to expand their view of the literature (divergent), and then the system provides contextualized descriptions and helps users decide which papers are worth saving (convergent)

% personalFlow: divergent thinking from ai, uses ai generated personas with different expertise, which helps users explore diverse perspectives and direction. then user can refine their research questions after evaluating personas. The ability to customize personas promotes better engagement with the system and helps users feel in control.

% scholastic: 

% sensemate: convergent thinking from ai, AI is used for semi-automating qualitative coding and supports transparency and modification. 

% synergi: divergent thinking, increase cursitisity from engagement, very good for broadening perspectives with citation graphs and LLM to epand and structure research threads.

% threddy: supports divergent thinking by helping users to expand their understanding of a research area through the discovery of new connections and threads of research, human are the ones that do convergent thinking by organizing information into threads, consolidate their knowledge and identity key themes.

% sensecape: mixed thinking, in the divergent phase, the AI generates a wide range of subtopics and questions that allows users to expand their understanding of a topic, in the convergent phase, the AI organizes these ideas into a hierarchical structure, which helps users filter and make sense of the information
\subsubsection{Divergent Thinking}
 Divergent thinking is essential for expanding the horizons of research. AI tools support this by generating exploratory questions and novel insights that researchers may not have thought about. For example, the Analogical Search Engine~\cite{AnalogicalSearchEngine}, DiscipLink~\cite{disciplink}, and IdeaSynth~\cite{IdeaSynth} provide functionalities to explore creative connections in seemingly unrelated fields. However, when using an AI tool for divergent thinking is used in isolation, this approach can overwhelm users with many novel ideas without providing the guidance necessary to narrow them down or refine them effectively.
\subsubsection{Convergent Thinking}
In convergent thinking, AI tools transform raw data into clear and structured insights, acting as intelligent partners that help researchers distill complex information into coherent narratives. These systems guide scholars in filtering and organizing diverse inputs so that essential themes emerge with clarity and precision. 

For example, SenseMate~\cite{sensemate} leverages rationale extraction models to generate transparent theme recommendations and human-interpretable explanations for qualitative coding. By grounding its suggestions in data-driven rationale rather than relying on large language models, SenseMate empowers even novice users to engage deeply with the source material while retaining full control over their coding decisions. Focusing on the same task, CollabCoder~\cite{CollabCoder} utilizes LLMs to automatically generate qualitative code suggestions and facilitate structured group discussions, thereby bridging individual insights into a collective consensus. Complementing these approaches, Scholastic~\cite{scholastic} employs advanced visual analytics to help teams organize and interpret complex datasets, while PaperWeaver~\cite{paperweaver} presents contextualized links that highlight the most relevant insights. These convergent functionalities make thematic grouping and filtering more efficient and transparent. 

\subsubsection{Mixed-Thinking}
Some tools strike a balance by supporting both divergent and convergent thinking. Threddy~\cite{threddy}, for example, allows users to input various requests so that LLM systems can organize ideas into coherent themes. They also leverage hierarchical structures to discover new connections based on user input. Similarly, Synergi~\cite{synergi} uses citation graphs and language models to expand research threads and consolidate them. However, these mixed-thinking approaches often leave users with limited control over the balance between exploration and refinement, which may hinder effective sensemaking. So while too much convergence might stifle creative exploration, too much divergence can cause cognitive overload. A well-designed research tool should support either or both modalities, but its user-facing capabilities should be made transparent. In the design space of research tools, allowing users to control the levels of divergent and convergent functionality is key to researcher autonomy.


\begin{designRecom}{Enabling Divergent and Convergent Thinking}
\textit{Design Insight:} Consider how users may need different types of support during the research process. Users may need more creative support from GenAI when they are discovering a new research area to help them understand the space. Following this, GenAI should provide guidance and structure when users are converging their existing research material.
\smallskip

\textit{Implications:} Future systems should be engineered with a design space that considers:

\begin{itemize}
\item \textbf{Transparency of AI Contributions:} Users should clearly understand whether the AI is supporting divergent exploration, convergent refinement, or both.  
\item \textbf{User Control Over AI Assistance:} Users should be able to adjust the level of AI support for idea generation and refinement based on their needs.  
\end{itemize}

% \textit{Recommendation example:} 
% CoQuest\cite{CoQuest} guides users through both expansive idea generation and systematic refinement.  The tool provides functionality for divergent thinking by generating exploratory questions and provides analogical search outputs to expose users to diverse research perspectives. CoQuest aggregates and refines these outputs in a convergent manner to help researchers critically evaluate and select the most relevant information.

\end{designRecom}


\subsection{Adaptability}
\label{sec:adaptability}
% "is there enough variation/ways  this tool can be used for?"
% We want to discuss how the research tools are adopting a flexible design philosophy, aiming to create systems that support different types of tasks, different workflows, and different personal preferences. It asks whether the tool can adjust its mode of operation depending on the context—say, leaning more on machine initiative when the task is exploratory and the user lacks domain expertise, but shifting to a mode that grants more manual control when the task requires careful evaluation or detailed refinement.
% \subsubsection{Example of good use cases}
% \begin{itemize}
%     \item \cite{AnalogicalSearchEngine} The fact of a search-based system makes it adaptable for a lot of unknown scenarios, and using "purposes" and "mechanisms" as a goal to prioritize make it even more adaptable, as the goal and way of doing will be captured for different research projects.
%     \item \cite{brainwriting} Since the process are entirely driven by user, including main topics, key diverging and converging steps. And it is not subject/process specific, user can plug-in and get additional AI assistance when needed.
%     \item \cite{CoQuest} RQ Flow Editor: The system doesn't restrict the user to predefined categories or specific input formats. This allows it to be used for a variety of research topics and at different stages of the research process. The user can start with a vague idea and gradually refine it, demonstrating adaptability to different user needs and workflows.

%     \item \cite{IdeaSynth} Literature-Based vs. Idea-Based Exploration: The system supports both literature-driven exploration (through paper recommendations and summaries) and idea-driven exploration (through facet generation and refinement) (section 4.1). 
%     \item \cite{IdeaSynth} Prompt Customization (Fig 5): The ability to customize prompts for AI suggestions allows for some adaptation to user needs.

%     \item \cite{scholastic} Support for different tasks and free workflow:  The tool is designed to support a complete qualitative analysis workflow, from initial exploration to the development of a refined coding schema. The tool allows for flexible workflows. Users can move freely between the Document Map, Document Reader, and Code Examiner. They can start with random sampling and then move to strategic sampling, or vice versa. They can code and categorize iteratively.

%     \item \cite{synergi} Mixed-Initiative Workflow: The system supports both bottom-up (starting from specific papers) and top-down (exploring the generated hierarchy) approaches.

%     \item \cite{synergi} Input Flexibility: user can focus and tag different part of the paper, depending on the interest and research goal. And thus can be expanded to facilitate different research need.

%     \item \cite{threddy} Multiple Entry Points: Users can start from any PDF and build threads from there. They are not forced into a specific starting point or workflow. This supports diverse research approaches.

%     \item \cite{threddy} Flexible Thread Structure: The nested thread structure, combined with the ability to reorganize threads, allows for a high degree of flexibility in how users organize their knowledge. This can adapt to different research styles and evolving mental models.
%  \end{itemize}

% \subsubsection{Mixed use cases}
% \begin{itemize}
%     \item \cite{disciplink} The system's ability to generate EQs from multiple disciplines is a core strength, directly addressing the needs of interdisciplinary information seeking (IIS). The ability to refine the exploration based on user input shows responsiveness to the user's evolving understanding. But the paper acknowledges limitations in adaptability. Section 7.3 discusses the need for more nuanced understanding of user contexts, including research phase and preferences (e.g., "why" vs. "what" questions). While DiscipLink adapts to user input during a session, it doesn't seem to learn user preferences across sessions. Also, it does not allow users to set a specific range of discipline to start with.
%     \item \cite{IdeaSynth} The system's core functionality is built around a specific model of research. While prompt customization offers some flexibility, it doesn't fundamentally change the underlying structure. A truly adaptable system would need to be able to handle different types of research questions, different forms of evidence, and different ways of structuring arguments. The lack of explicit support for different research paradigms limits its adaptability.
% \end{itemize}
    
    

% \subsubsection{Example of bad use cases}
% \begin{itemize}
%     \item  \cite{AnalogicalSearchEngine} The system treats all users and all search tasks the same way. It does not adapt to individual research styles, levels of expertise, or specific project goals. The lack of personalization and customization makes the system a "one-size-fits-all" tool, limiting its ability to support diverse.
% \end{itemize}

Adaptability in AI-assisted research tools refers to a system’s capacity to support the diversity of tasks, workflows, and preferences of researchers. Ways this could be supported in tooling include flexible input mechanisms; fluid, nonlinear workflows; and context-sensitive design.

\subsubsection{Flexible Input \& Customization} Systems that prioritize flexible input mechanisms empower users to tailor the tool’s behavior from the outset. For example, the Analogical Search Engine~\cite{AnalogicalSearchEngine} leverages a custom ranking algorithm that focuses on user-defined “purposes” and “mechanisms” to modulate search results according to varying research objectives, allowing researchers to specify the kind of analogical relationships they are seeking. Similarly, the Brainwriting tool~\cite{brainwriting} allows users to dictate main topics in addition to divergent and convergent steps through a user-agnostic approach. These approaches underscore the importance of customization as a means of preserving user agency and aligning system outputs with specific investigative goals.

\subsubsection{Fluid, Non-Linear Workflows} A second facet of adaptability is found in tools that support non-linear, iterative workflows. The RQ Flow Editor in CoQuest~\cite{CoQuest} exemplifies this by eschewing predefined categories and instead promoting continuous refinement of ideas through a mixed-initiative interaction where AI suggests new research questions and users can provide feedback. Likewise, IdeaSynth~\cite{IdeaSynth} supports both literature-driven and idea-driven explorations through dynamic facet generation and prompt customization, enabling users to decompose an initial idea into finer-grained aspects and explore variations of them. Tools like Scholastic~\cite{scholastic} further demonstrate adaptability by allowing researchers to shift seamlessly between exploration, strategic sampling, and coding — highlighting the value of fluid transitions in non-linear research processes via its interactive document and word clustering.

\subsubsection{Mixed-Initiative \& Context-Sensitive Design} 
Adaptability also manifests in systems that accommodate varied research approaches through mixed-initiative interactions and context-sensitive features. For instance, Synergi~\cite{synergi} offers a mixed-initiative workflow that caters to both bottom-up and top-down strategies, allowing users to engage with content according to their preferred mode of inquiry and seamlessly combine machine-generated summaries and user-curated threads. Interdisciplinary platforms like DiscipLink~\cite{disciplink} contribute to this design space by facilitating the generation and refinement of research questions across multiple disciplines, albeit with some limitations regarding persistent user customization.

% Collectively, these examples emphasize a design space in which adaptability is achieved through varied strategies that maintain user agency while supporting a wide range of research tasks. By enabling flexible inputs, fluid workflows, and context-sensitive interactions, these tools foster environments where researchers can tailor system behavior to their evolving needs. This design philosophy is essential not only for accommodating diverse research paradigms but also for promoting deep cognitive engagement and innovative inquiry.

\begin{designRecom}{Ensure Adaptability and Workflow Flexibility} \textit{Design Insight:}
Research tools must provide flexible workflows and customizable interfaces to address varied researcher needs.

\smallskip

\textit{Implications:}
Future systems should be engineered with a design space that considers:
\begin{itemize}
\item \textbf{Flexible Input \& Customization:}
Enable users to tailor key parameters and input formats to align system behavior with their individual research goals.
\item \textbf{Fluid, Non-Linear Workflows:} Provide multiple entry points and modular interfaces that allow researchers to navigate, reorganize, and iteratively refine their inquiry as new insights emerge.
\item \textbf{Mixed-Initiative \& Context-Sensitive Design:}  Implement context-aware features that respond to shifts in research focus, ensuring a balanced mix of automated support and user control.
\end{itemize}

% \textit{Recommendation Example:}
% The Analogical Search Engine~\cite{AnalogicalSearchEngine} currently relies on a token-level ranking algorithm that identifies `purposes' (the problems addressed) and `mechanisms' (the solutions offered) across research articles. While effective for large-scale analogical reasoning, this uniform approach limits search flexibility. By enabling configurable search options -- such as toggling between analogical ranking, concept-based similarity matching, and methodological pattern exploration -- the system can better accommodate diverse research interests and methodologies.
\end{designRecom}

\subsection{Accuracy} 
\label{sec:accuracy} 
Ensuring that users receive accurate, unbiased, and contextually relevant information is paramount in AI-assisted research tools. To address challenges such as hallucination and contextual drift inherent to large language models, researchers have developed multifaceted strategies that combine human oversight, contextual grounding, and carefully managed efficiency-accuracy trade-offs.

\subsubsection{Interactive Interfaces for Accuracy Validation} A key design pattern embeds interactive mechanisms that enable real-time verification of AI outputs by linking inferences directly to their original sources. For instance, SenseMate \cite{sensemate} employs a ``View Reason'' feature that highlights source phrases underlying a theme recommendation, thus promoting local explainability and inviting critical evaluation rather than passive acceptance. Similarly, Synergi~\cite{synergi} and PaperWeaver~\cite{paperweaver} enhance their LLM-generated summaries by providing citation contexts and contextualized descriptions. Synergi groups related information to offer clear reference, while PaperWeaver uses aspect-based summaries (e.g., problem, method, findings) alongside paper comparisons to help researchers quickly assess the relevance of new publications.

\subsubsection{Iterative Refinement and Human-in-the-Loop Strategies} Complementing interactive validation, iterative refinement processes further emphasize human oversight. Scholastic~\cite{scholastic} demonstrates this approach by utilizing a machine-in-the-loop framework for qualitative text coding, wherein user feedback continuously refines coding decisions through rationale extraction models that enhance transparency and trust. Likewise, Threddy~\cite{threddy} and IdeaSynth~\cite{IdeaSynth} empower researchers to actively shape AI outputs. Threddy facilitates the extraction and iterative organization of research threads, while IdeaSynth leverages LLMs to propose new ideas that users can further refine. Together, these strategies enable researchers to combine automated suggestions with their own expert judgment.

% Collectively, these design strategies both ensure output accuracy and facilitate a reflective, engaged research practice. By integrating interactive validation and iterative human-centered refinement, AI-assisted research tools can minimize misinformation while promoting critical interrogation of outputs, which further reinforces the core principles of human-centered AI design \cite{shneiderman2020human}. In doing so, these systems encourage researchers to actively integrate practices that promote accuracy through ongoing validation and refinement, ensuring that their work remains reliable and contextually grounded throughout the ideation and sensemaking process.


\begin{designRecom}{Prioritize Transparency and Accuracy} \textit{Design Insight:} In scientific research, accuracy is non-negotiable. Systems must balance automation with robust mechanisms that empower users to verify AI outputs.

\textit{Implications:} 
\begin{itemize} 
\item \textbf{Transparent Rationale Explanations:} Allow users to understand the underlying reasoning behind AI outputs. 
\item \textbf{Citation Contexts:} Provide direct access to source materials, enabling quick cross-referencing and validation. 
\item \textbf{Human-in-the-Loop Reviews:} Facilitate iterative feedback that mitigates risks such as hallucinations and inadvertent biases. 
\end{itemize}

% \textit{Recommendation:} Avoid relying solely on fully automated LLM summarization for mission-critical tasks. As illustrated by PaperWeaver~\cite{paperweaver}, while summarization can quickly surface key insights, it also introduces uncertainty that may lead to misinformation or automation bias. A preferable approach, as demonstrated in Synergi~\cite{synergi}, employs recursive summarization techniques that preserve meaning across layers and present exact text snippets from original sources. This strategy enhances transparency and facilitates easier, more reliable validation by researchers. 
\end{designRecom}