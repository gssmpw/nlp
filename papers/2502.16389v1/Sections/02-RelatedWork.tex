\section{Related work}
\label{sec:related_work}
Anomaly detection, also known as outlier detection or novelty detection, is an important problem that has been studied within diverse research areas and application domains~\citep{chandola2009anomaly,chalapathy2019deep}. The problem of traffic AD bares similarities with the disciplines of robot AD and AD for surveillance cameras. In this section, we briefly review the related research and introduce common techniques in ensemble deep learning.

Recent research efforts have made noteworthy progress in developing learning-based AD algorithms for robots and mechanical systems. \cite{malhotra2016lstm} introduces an LSTM-based encoder-decoder scheme for multi-sensor AD (EncDec-AD) that learns to reconstruct normal data and uses reconstruction error to detect anomalies. \cite{park2018multimodal} proposes an LSTM-based variational autoencoder (VAE) that fuses sensory signals and reconstructs their expected distribution. The detector then reports an anomaly when a reconstruction-based anomaly score is higher than a state-based threshold. \cite{feng2022unsupervised} attacks multimodal AD with missing sources at any modality. A group of autoencoders (AEs) first restore missing sources to construct complete modalities, and then a skip-connected AE reconstructs the complete signal. Although similar in ideas, these approaches were proposed for low-dimensional signals (e.g., accelerations and pressures) and have not shown effective on high-dimensional data (e.g., images).

AD for robot navigation often involves complex perception signals from cameras and LiDARs in order to understand the environment. \cite{ji2020multi} proposes a supervised VAE (SVAE) model, which utilizes the representational power of VAE for supervised learning tasks, to identify anomalous patterns in 2D LiDAR point clouds during robot navigation. The predictive model proposed in LaND~\citep{kahn2021land} takes as input an image and a sequence of future control actions to predict probabilities of collision for each time step within the prediction horizon. \cite{schreiber2023attentional} further enhances the robot perception capability with the fusion of RGB images and LiDAR point clouds using an attention-based recurrent neural network, achieving improved AD performance on field robots. Different from these supervised-learning-based methods, \cite{wellhausen2020safe} uses normalizing flow models to learn distributions of normal samples of multimodal images, in order to realize safe robot navigation in novel environments. However, driving scenarios have additional complexities than field environments. While road environments are more structured than field environments, additional hazards arise from the presence of and interactions between dynamic road participants, which pose extra challenges on AD algorithms.

Another widely explored research area that is relevant to our work is AD for surveillance cameras, which mainly focuses on detecting the start and end time of anomalous events within a video. Under the category of frame-level methods, \cite{hasan2016learning} proposes a convolutional autoencoder to detect anomalous events by reconstructing stacked images. \cite{chong2017abnormal} and~\cite{luo2017remembering} extend such an idea by learning spatial features and the temporal evolution of the spatial features separately using convolution layers and ConvLSTM layers~\citep{shi2015convolutional}, respectively. Instead of reconstructing frames, \cite{liu2018future} trains a fully convolutional network to predict future frames based on past observations and uses the Peak Signal to Noise Ratio of the predicted frame as the anomaly score. \cite{gong2019memorizing} develops an autoencoder with a memory module, called memory-augmented autoencoder, to limit the generalization capability of the network on reconstructing anomalies. To focus more on small anomalous regions, patch-level methods generate the anomaly score of a frame as the max pooling of patch errors in the image rather than the averaged pixel error used in frame-level methods~\citep{wang2023memory}. In addition, object-level approaches have also been explored, which often focus on modeling normal object motions either through extracted features (e.g., human skeletons)~\citep{morais2019learning} or raw pixel values within bounding boxes~\citep{liu2021hybrid}. Although these methods have achieved promising results on surveillance cameras, the performance is often compromised in egocentric driving scenarios due to moving cameras and complex scenes~\citep{yao2022dota}.

In the domain of traffic AD in first-person videos, pioneering works borrow ideas from surveillance camera applications and detect abnormality by reconstructing motion features at frame level~\citep{yuan2016anomaly}. However, to overcome the issues introduced by rapid motions of cameras and thus backgrounds, object-centric methods are becoming increasingly popular. One of the most representative works by~\cite{yao2019unsupervised} proposes a recurrent encoder-decoder framework to predict future trajectories of an object in the image plane based on the object's past trajectories, spatiotemporal features, and ego motions. The accuracy and consistency of the predictions are then used to generate anomaly scores. One critical problem of such a method is the inevitable miss detection in the absence of traffic participants. As a result, ensemble methods emerge recently to combine the strengths of frame-level and object-centric methods. For example, ~\cite{yao2022dota} fuses the object location prediction model with the frame prediction model to achieve all-scenario detection capability and ~\cite{fang2022traffic} monitors the temporal consistency of frames, object locations, and spatial relation structures of scenes for AD. In this work, we derive each module and the corresponding learning objective in the ensemble based on a comprehensive analysis on anomaly patterns in egocentric driving videos. In particular, an interaction module is introduced to monitor anomalous interactions between road participants. The scores from each module are then fed as observations of a Kalman filter, from which the final anomaly score is obtained.

In this paper, we introduce an ensemble of detectors to capture different classes of anomalies.
We take inspiration from recent advances in ensemble deep learning, which aims to improve the generalization performance of a learning system by combing several individual deep learning models~\citep{ganaie2022ensemble} and has been applied to different application domains, such as speech recognition~\citep{li2017semi},  image classification~\citep{wang2020particle}, forecasting~\citep{singla2022ensemble}, and fault diagnosis~\citep{wen2022new}. Out of different classes of ensemble deep learning approaches, the most similar work to Xen is the heterogeneous ensemble (HEE), in which the components are trained on the same dataset but use different algorithms/architectures~\citep{li2018heterogeneous,tabik2020mnist}. However, each component in an HEE is usually trained with an identical learning objective, while each expert in Xen is assigned with different learning tasks. In terms of result fusion strategies, unweighted model averaging is one of the most popular approaches in the literature~\citep{ganaie2022ensemble}, which simply averages the outcomes of the base learners to get the final prediction of the ensemble model. By contrast, we exploit a Kalman filter to further combat the noise in scores from different components in a time-series task, and the unweighted model averaging can be viewed as a special case of such a method at a point along the time axis.