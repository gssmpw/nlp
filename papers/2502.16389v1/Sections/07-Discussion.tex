\section{Discussion and limitations}
The results presented in Section~\ref{sec:experiments} show that compared to baseline methods, Xen provides a more effective solution that can enable an autonomous car to detect on-road anomalies in diverse driving scenarios using a single monocular camera. Despite the advantages, our work also encompasses several limitations.

Object detection plays an important role in Xen, as the interaction and behavior expert work under the assumption that anomalous objects can be reliably detected for trajectory reconstruction and prediction, respectively. However, the perception capability of monocular cameras is largely limited when the visibility is poor, such as at night and under inclement weather conditions. To alleviate the issue, camera-LiDAR fusion has been proposed and shown more effective than unimodal approaches in computer vision tasks~\citep{cui2021deep,chen2017multi,sindagi2019mvx}. With an additional sensor modality, object detection and thus anomaly detection can be made more robust in different environments. Furthermore, as noted in Section~\ref{subsec:bm}, perspective projection onto the image plane distorts the motion characteristics of objects (e.g., a proximate object appears to move faster than a distant object even though the two objects have the same speed in reality), which challenges efficient modeling of normal motion patterns. 3D object detection enabled by point clouds from LiDAR has the potential to resolve the issue by projecting bounding boxes to bird's eye view (BEV) and thus eliminating the negative effect of perspective projection on learning object motions.

Another common failure case of Xen results from large scene motions in normal scenarios, e.g., when the ego car executes an aggressive lane change or moves fast in complex urban areas. Frame prediction becomes difficult in such cases due to large motions of the ego car, and the resulting increase of score is indistinguishable from that caused by an anomaly. It has been shown recently in video prediction literature that camera poses are helpful in rendering high-quality images~\citep{ak2021robust}. As a result, given that additional onboard vehicle state is available, ego motions can be exploited to create a more robust scene expert. Another similar issue that can cause false positives in Xen is discussed in supplemental materials.

Anomaly detection is an active research topic both in robotics and computer vision. At a more general level, we hope that the analysis in this work, especially those in Section~\ref{sec:overview}, provides insights on a unified framework for anomaly detection in related areas. More specifically, an anomaly detector can be designed based on Figure~\ref{fig:anomaly-patterns} with necessary modifications for different applications. For example, for AD on field robots which operate in autonomous farms without human labors, only the edge between the ego agent and the environment needs to be monitored as the robot often performs a task individually; for AD with surveillance cameras, the two edges with one of the ends being the ego agent can be ignored as the surveillance camera is fixed and will never participate in an anomaly; and for AD on mobile robots that navigate through human crowds, the whole graph needs to be considered if non-ego involved anomalies also affect robot decisions. With the high-level framework determined, each expert can then be designed specifically for each type of edge based on the characteristics of different anomalies. Validating the generalization capability of Xen in other application domains is left as future work.

Another possible direction is to evaluate the efficacy of more complex architectures, such as foundation models, for anomaly detection. Large visual language models (LVLMs) have been shown powerful in a variety of application areas, including image captioning, content generation, and conversational AI~\citep{jiang2024effectiveness}. In the domain of autonomous driving, LVLMs have also been explored for tasks of visual question-answering~\citep{xu2024drivegpt4}, trajectory prediction~\citep{wu2023language}, path planning~\citep{mao2023language}, and decision-making and control~\citep{wen2023road}. These recent research advancements suggest that incorporating foundation models into on-road anomaly detection is a promising direction.

Although powerful, LVLMs are currently limited in efficiency due to billions of parameters~\citep{brohan2022rt,brohan2023rt,padalkar2023open}. Furthermore, proprietary models, such as GPT-4V, must be queried over the cloud, further increasing inference time~\citep{achiam2023gpt}. To ensure both accuracy and efficiency of on-road anomaly detection with limited onboard resources, a combination of LVLMs and lightweight models is necessary. One integration method is to retrieve intermediate embeddings of images through the LVLM, which can then be provided as an additional context to lightweight anomaly detectors for inference. The embeddings from the LVLM can be updated periodically for efficiency. Such a method, however, requires access to the hidden states of the LVLM, which most proprietary models do not allow. Alternatively, LVLMs can be used as an additional anomaly detection expert, which can then be incorporated into Xen through the Kalman filter. While the three original experts update the system states of Kalman filter at a high frequency, the LVLM can be queried at a low frequency and updates the system states asynchronously in a similar manner. With such an approach, we are able to benefit from both the efficiency of lightweight models and the accuracy and generalization ability of LVLMs.