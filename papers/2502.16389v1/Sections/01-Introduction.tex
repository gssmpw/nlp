\section{Introduction}
Autonomous driving is at a critical stage in revolutionizing transportation systems and reshaping societal norms. More than 1,400 self-driving cars, trucks, and other vehicles are currently in operation or testing in the U.S.~\citep{etherington2019over}, and 4.5 million autonomous vehicles are expected to run on U.S. roads by 2030~\citep{meyer2023safety}. While autonomous driving is promising in improving traffic efficiency and personal mobility, safety is a prerequisite of all possible achievements and is becoming the first priority in practice~\citep{du2020online}. In October 2023, Cruise, one of the leading autonomous driving companies, was ordered by California to stop operations of driverless cars in the state after one of Cruise's cars struck a pedestrian in San Francisco~\citep{dara2023california}. The rare incident involved a woman who was first hit by a human driver and then thrown onto the road in front of a Cruise vehicle. The Cruise vehicle then rolled over the pedestrian and finally stopped on top of her, causing serious injuries. Such an accident reflects one of the greatest challenges in autonomous driving: the safety of an autonomous car is largely determined by the ability to detect and react to rare scenarios rather than common normal situations, which have been well considered during development. Although rare in a long-tailed distribution, unusual driving scenarios do happen and can have large impact on driving safety.

To mitigate the impact of abnormal ego behaviors when outside the design domains, a detection system for anomalous driving scenarios is necessary, the output of which can be potentially used as a high-level decision for motion planning. Recently, deep-learning based anomaly detection (AD) algorithms have been widely adopted in robotic applications where rare events are closely related to safety concerns~\citep{chalapathy2019deep}. Many previous works approached the AD problem using supervised learning~\citep{kahn2021land,ji2020multi,ji2022proactive,schreiber2023attentional}. Such methods directly output probabilities of encountering anomalies based on onboard sensory signals by training on binary ground truth labels indicating the presence or absence of anomalies. While labels can be automatically obtained during data collection (e.g., whether or not a mobile robot encounters an anomaly during navigation is indicated by if the human supervisor disengages the autonomy), abundant positive data are required to train a model that can generalize well to unseen scenarios. However, each anomaly in autonomous driving imposes significant risk due to potential accidents and thus is much more expensive than that in other low-risk robotic applications. Furthermore, driving scenarios are complex with diverse road appearances and traffic participants, leading to a large variance of anomalies. It is almost impossible to collect sufficient labeled data for traffic AD. Moreover, there are no guarantees on the completeness of observed anomalies in training data as novel anomaly can always occur in the real world~\citep{liu2018future}.

An alternative solution is unsupervised anomaly detection and/or out-of-distribution detection, which models normal scenarios by training only on negative data without any anomalies. During test time, a high anomaly score, indicating a high probability of anomalies happening, is produced when an observation does not fit the learned distribution. Such unsupervised approaches do not require expensive positive data and can potentially capture any type of anomalous events, even those not previously observed before deployment~\citep{nayak2021comprehensive}. Unsupervised AD has been widely explored in AD tasks for static surveillance cameras~\citep{luo2017revisit,hasan2016learning,morais2019learning,wang2023memory}. However, these methods do not generalize to AD in robotics or autonomous driving as they assume a static camera and thus struggle from rapid camera movement.

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{\linewidth}
    \captionsetup{justification=centering}
    \includegraphics[width=\linewidth]{Figures/fig1a_small_region_eg.pdf}
    \caption{A lateral collision in the distance at high speed.}
    \label{subfig:motivations-small-region}
  \end{subfigure}
  \begin{subfigure}[b]{\linewidth}
    \captionsetup{justification=centering}
    \includegraphics[width=\linewidth]{Figures/fig1b_smooth_motion_eg.pdf}
    \caption{A lateral collision in the proximity at low speed.}
    \label{subfig:motivations-smooth-motion}
  \end{subfigure}
  \caption{\textbf{Challenging examples of anomalies.} Sample frames are ordered in time. Bounding boxes in each frame mark the anomaly participants.}
  \label{fig:motivations}
\end{figure}

In the domain of on-road/traffic AD in egocentric videos, two different classes of approaches are mainly adopted by learning features at different scales. Frame-level methods, which are borrowed from AD for static cameras, train a deep neural network to reconstruct or predict video frames and declare an anomaly whenever the reconstruction or prediction error is large~\citep{liu2018future,hasan2016learning}. However, in addition to the difficulty introduced by moving cameras, anomalous regions can be too small to increase the frame-level error noticeably (Figure~\ref{subfig:motivations-small-region}), leading to miss detection. To overcome this problem, object-centric methods were proposed for on-road AD, which predicts future locations of traffic participants over a short horizon and monitors the accuracy or consistency of the predictions as evidence of anomalies~\citep{yao2019unsupervised}. However, such methods can completely fail in some ego involved anomalies where no other road participants are detected. Furthermore, anomalies featuring mild motions at low speed can also be missed as object's motion appears smooth and can be predicted consistently with small errors (Figure~\ref{subfig:motivations-smooth-motion}). A natural idea is to combine frame-level and object-centric methods to take advantage of the strengths, which has also been explored in recent works with pseudo anomaly score map fusion~\citep{yao2022dota} and cascaded score addition with min-max normalization~\citep{fang2022traffic}. However, how to design and fuse different models effectively in an ensemble remains an open problem for AD in complex driving scenarios.

In this paper, we provide a framework for robot AD module design by performing a holistic analysis on common anomaly patterns. Based on the characteristics of each anomaly type in driving scenarios, we propose three different experts for detecting anomalous scenes, interactions, and behaviors, respectively. The scene expert inherits the advantages of frame-level methods by modeling normal scenes and scene motions and raises an alarm whenever the observed global appearance is out of distribution. Both frame prediction and reconstruction are incorporated to enhance the AD capability. The interaction expert complements existing object-centric methods by focusing on \textit{relative} motions between two road participants and triggers high anomaly scores whenever abnormal interactions (e.g., collisions of cars at both high and low speed) emerge. Inspired by prior works, the behavior expert predicts future locations of objects and monitors the prediction consistency for AD. However, important modifications are made to the existing anomaly score computation to faithfully reflect the probability of an anomalous behavior present in a scene.

To make use of all the modules, we introduce an e\textbf{X}pert \textbf{en}semble, which we call Xen, that fuses anomaly scores from each expert using a Kalman filter. We view each expert score as a \textit{noisy} observation of a ground truth metric quantifying the likelihood of a specific type of anomaly happening and retrieve the final anomaly score as one of the states in the Kalman filter. A new evaluation protocol is also proposed to reflect more realistic performance of AD methods by removing the video-wise min-max normalization of anomaly scores.

Our contributions can be summarized as follows:
\begin{enumerate}
\item
We categorize anomaly patterns for autonomous systems according to the types of involved actors to derive learning objectives of the anomaly detector.
\item
Three experts are proposed to model different normal patterns for autonomous driving (i.e., driving scenes, object interactions, and object behaviors) and to produce high anomaly scores whenever an observation is out of distribution.
\item
We realize expert ensemble through a Kalman filter, one of whose states is the final anomaly score after fusion, to combat against the noise in individual expert scores.
\item
Our proposed detector Xen outperforms existing methods in anomaly detection performance on a large-scale real-world dataset for traffic AD with a newly introduced evaluation protocol for realistic model performance.
\end{enumerate}