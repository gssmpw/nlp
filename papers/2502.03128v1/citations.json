[
  {
    "index": 0,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, A",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "chang2022maskgit",
        "author": "Chang, Huiwen and Zhang, Han and Jiang, Lu and Liu, Ce and Freeman, William T",
        "title": "Maskgit: Masked generative image transformer"
      },
      {
        "key": "chang2023muse",
        "author": "Chang, Huiwen and Zhang, Han and Barber, Jarred and Maschinot, AJ and Lezama, Jose and Jiang, Lu and Yang, Ming-Hsuan and Murphy, Kevin and Freeman, William T and Rubinstein, Michael and others",
        "title": "Muse: Text-to-image generation via masked generative transformers"
      },
      {
        "key": "xie2024show",
        "author": "Xie, Jinheng and Mao, Weijia and Bai, Zechen and Zhang, David Junhao and Wang, Weihao and Lin, Kevin Qinghong and Gu, Yuchao and Chen, Zhijie and Yang, Zhenheng and Shou, Mike Zheng",
        "title": "Show-o: One single transformer to unify multimodal understanding and generation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "yu2023magvit",
        "author": "Yu, Lijun and Cheng, Yong and Sohn, Kihyuk and Lezama, Jos{\\'e} and Zhang, Han and Chang, Huiwen and Hauptmann, Alexander G and Yang, Ming-Hsuan and Hao, Yuan and Essa, Irfan and others",
        "title": "Magvit: Masked generative video transformer"
      },
      {
        "key": "yu2023language",
        "author": "Yu, Lijun and Lezama, Jos{\\'e} and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Gupta, Agrim and Gu, Xiuye and Hauptmann, Alexander G and others",
        "title": "Language Model Beats Diffusion--Tokenizer is Key to Visual Generation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "borsos2023soundstorm",
        "author": "Borsos, Zal{\\'a}n and Sharifi, Matt and Vincent, Damien and Kharitonov, Eugene and Zeghidour, Neil and Tagliasacchi, Marco",
        "title": "Soundstorm: Efficient parallel audio generation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "borsos2023audiolm",
        "author": "Borsos, Zal{\\'a}n and Marinier, Rapha{\\\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others",
        "title": "Audiolm: a language modeling approach to audio generation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "zeghidour2021soundstream",
        "author": "Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco",
        "title": "Soundstream: An end-to-end neural audio codec"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "ju2024naturalspeech",
        "author": "Ju, Zeqian and Wang, Yuancheng and Shen, Kai and Tan, Xu and Xin, Detai and Yang, Dongchao and Liu, Yanqing and Leng, Yichong and Song, Kaitao and Tang, Siliang and others",
        "title": "NaturalSpeech 3: Zero-shot speech synthesis with factorized codec and diffusion models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wang2024maskgct",
        "author": "Wang, Yuancheng and Zhan, Haoyue and Liu, Liwei and Zeng, Ruihong and Guo, Haotian and Zheng, Jiachen and Zhang, Qiang and Zhang, Shunsi and Wu, Zhizheng",
        "title": "MaskGCT: Zero-shot text-to-speech with masked generative codec transformer"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "li2024masksr",
        "author": "Li, Xu and Wang, Qirui and Liu, Xiaoyu",
        "title": "MaskSR: Masked Language Model for Full-band Speech Restoration"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "yang2023uniaudio",
        "author": "Yang, Dongchao and Tian, Jinchuan and Tan, Xu and Huang, Rongjie and Liu, Songxiang and Chang, Xuankai and Shi, Jiatong and Zhao, Sheng and Bian, Jiang and Wu, Xixin and others",
        "title": "Uniaudio: An audio foundation model toward universal audio generation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wang2024speechx",
        "author": "Wang, Xiaofei and Thakker, Manthan and Chen, Zhuo and Kanda, Naoyuki and Eskimez, Sefik Emre and Chen, Sanyuan and Tang, Min and Liu, Shujie and Li, Jinyu and Yoshioka, Takuya",
        "title": "Speechx: Neural codec language model as a versatile speech transformer"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "le2024voicebox",
        "author": "Le, Matthew and Vyas, Apoorv and Shi, Bowen and Karrer, Brian and Sari, Leda and Moritz, Rashel and Williamson, Mary and Manohar, Vimal and Adi, Yossi and Mahadeokar, Jay and others",
        "title": "Voicebox: Text-guided multilingual universal speech generation at scale"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "vyas2023audiobox",
        "author": "Vyas, Apoorv and Shi, Bowen and Le, Matthew and Tjandra, Andros and Wu, Yi-Chiao and Guo, Baishan and Zhang, Jiemin and Zhang, Xinyue and Adkins, Robert and Ngan, William and others",
        "title": "Audiobox: Unified audio generation with natural language prompts"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "liu2023generative",
        "author": "Liu, Alexander H and Le, Matt and Vyas, Apoorv and Shi, Bowen and Tjandra, Andros and Hsu, Wei-Ning",
        "title": "Generative pre-training for speech with flow matching"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "lipman2022flow",
        "author": "Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt",
        "title": "Flow matching for generative modeling"
      }
    ]
  }
]