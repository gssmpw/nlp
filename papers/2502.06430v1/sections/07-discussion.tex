\section{Discussion}

\subsection{Redesigning Mobile Email Replies with Content-Driven Local Response}
Our first research question asked: \textit{How might we redesign the mobile email reply UI for flexible and optional AI involvement?} We proposed to \revision{build on} microtasking \revision{UI} principles with our concept of \modeourstxt. Here, we reflect on two key aspects of this solution strategy. 

\subsubsection{\revision{Responding (with AI) Directly While Reading}}
A key benefit of our \modeours{} design is that it turns the email content into a UI to locally trigger responses. As our results show, users leveraged this to keep the email in view while responding (\cref{fig:time_spent_on_screens_barplot}). \revision{One way of looking at this is through the lens of} the usability principle of ``recognition over recall''~\cite{Nielsen1994usabilityheuristics}: Users can \revision{respond and/or} delegate tasks to the AI at the very moment of recognising a line in the email as relevant. In contrast, reading a whole email first, to then transition to a draft view (AI-based or manual) requires recalling the email's information -- or scrolling/swiping back and forth, at least on a mobile screen that does not fit email and draft in parallel. \revision{This seems more important for complex emails and less relevant for short ones. Our results support this (local response was less likely to be skipped for longer emails, see \cref{sec:results_workflows}) and motivate a dedicated future study on microtasking UIs for emails of varying complexity. That said, mobile interaction is prone to attentional demands and interruptions~\cite{oulasvirta2005bursts}, which might make it more likely to forget about a relevant aspect not only for very long emails.}

\revision{In another lens}, \modeours{} responds to the call by \citet{Tankelevitch2024metacognitive} for UIs that reduce metacognitive demands of generative AI, for example, when deciding when and what to delegate to AI. 
Our concept was successful here, as echoed by participants' comments. For example, P24\oldId{P1297} said ``[I could] organize my ideas better using the sentence replies within the email.'' Similarly, P8\oldId{P1277} found that ``This was definitely helpful in breaking down the email and specifically answering the important key points of the original message.''

Put as a design recommendation: Enable people to immediately act in the local context of a recognised need for AI support, when the relevant information for that task delegation is present. %







\subsubsection{Designing for AI Integration by Supporting Decision-Moments Explicitly in the UI} 
\modeours{} facilitates local responses by \textit{both} user and AI. 
For the user, traditional email UIs offer a two-step workflow -- read the email, then write a reply. However, the actual workflow has more steps: Users need to identify relevant information, think about their response, and compose a coherent reply. The sentence-wise nature of \modeours{} makes these steps explicit in the UI. Work on microtasking shows that splitting up writing tasks and presenting them in context is beneficial for mobile users~\cite{august2020microwriting, iqbal2018playwrite}.

In our design this additionally supports prompting the AI (see \cref{sec:discussion_prompting}).
We believe that this solution strategy is relevant more broadly: Generative AI is often added ``on top'' of existing UIs (\cref{sec:related_work_current_products}). In contrast, we propose to identify relevant (micro) decisions and response moments in the task, redesign the UI so that users can express these through interaction (here: select sentence), and then integrate AI specifically at these moments.
















\subsection{Empirical Characteristics of \modeours}\label{sec:discussion_results_overview}

Our empirical research questions asked: \textit{How do users perceive and interact with \modeours?} and \textit{What are the specific advantages and drawbacks?}
Here, we reflect on this in comparison to the other UIs in our study.


\subsubsection{\modeours{} Offers Flexible Workflows}
Our study revealed how \modeours{} grants users high flexibility. Concretely, people achieve different workflows by varying their use of local responses in combination with AI support features. We identified three clusters (\cref{fig:workflow_scatterplot}). This demonstrates that people have varying preferences when responding to emails with AI, even in a controlled study setting, which \modeours{} was able to support.
\revision{Concretely,} the observed workflows differed in when and how people transitioned from the local response view to the ``global'' draft view (\cref{sec:results_workflows}). %


\subsubsection{\modeours{} has a Lower ``AI Footprint''}
All AI features across \modeours{} and \modemail{} shared these significant influences: reduced manual typing and error rates, with increased reply lengths and reduced semantic and lexical diversity. 

Despite these shared influences, \modeours{} showed a lower ``AI footprint''.
As estimated with our statistical models, with \modemail{} (compared to \modeours) people finished their replies even faster (-\secs{66}), with even fewer manual keystrokes (-\pct{20}), while producing even longer replies (+\pct{28}). Producing more, faster, with less input indicates a dearth of human intention in writing, as recently highlighted by \citet{kreminski2024dearthauthor}. Indeed, \modemail{} resulted in the lowest diversity between emails.
Together with our subjective inspection of the emails (\cref{sec:result_quality}), this paints the picture of somewhat bloated replies with full reply generation (\modemail). This is in line with the finding by \citet{fu2024texttoself} that verbosity is a key drawback noticed by users of AI tools for communication. As our study shows, people could keep this under control better with \modeours{}. In summary, \modeours{} allows users to benefit from AI in a more nuanced and controlled manner.










\subsubsection{Optional Message-Level Support Partly Bridges the Differences}
Manual control might not always be the user's main concern. \modeours{} also accounts for workflows with stronger delegation to AI, as shown by clustering the workflows (\cref{fig:workflow_scatterplot}) and by factoring out the impact of the \imppass{} feature. If it was used, it narrowed the differences between \modeours{} and \modemail{} along several metrics (\cref{tab:lmm_overview}), \revision{which fits to the literature that compared} sentence-level vs message-level AI support~\cite{Fu2023sentencevsmessage}. %
In conclusion, by making use of the optional \imppass{} in \modeours{}, users can situationally vary the described tradeoffs between \modemail{} and our local response design.



\subsection{\revision{Deciding Between Sentence- and Message-level Support (\modeours{} vs \modemail)}}
Participants' reasonings for their favourite UI (\cref{sec:results_fav_mode}) \revision{help us understand which types of tasks might benefit from which type of AI support}. 
\revision{When favouring \modemail}, they referred to aspects of efficiency in the majority of their comments, in line with quantitative results. \revision{This indicates that this type of support might be favourable for communication tasks in which users deem the speed of their reply to be more relevant than the exact wording (e.g. decision-focused emails, such as accepting or declining a time-sensitive request).}

In contrast, \revision{for \modeours, participants} emphasised quality and control aspects relatively more frequently. \revision{Thus, this type of support lends itself to communication tasks that require more careful and/or personal wording. Concretely,  \citet{Robertson2021cantreply} identified relevant themes in emailing for this, such as caring about personal authenticity, semantic and tonal coherence, relationship types, and norms and culture. Related, \citet{Mieczkowski2022thesis} identified dimensions of agency in AIMC. Our \modeours{} design and participants' comments on it fit to their findings about people's strategic thinking for maintaining agency (e.g. ability for choosing, editing, replacing, not-sending AI text, and/or seeing its changes due to own input).} 

\revision{Supporting this interpretation}, comments by those who did not pick a favourite, such as P19\oldId{P1290}, described that the choice depends on contextual factors, such as using \modemail{} under time pressure, while using \modeours{} when a ``tailored'' reply was needed.

\revision{Related}, we found evidence that the value of local responses is higher for longer emails (\cref{sec:results_workflows}). Future work could investigate the underlying factors in detail. For example, the value of the local response step \revision{(and thus sentence-level support)} might depend not only on the length but also on aspects of complexity of the incoming email \revision{(e.g. emails with multiple questions or describing a complex ``history'' of a situation as background for a request)}.

\revision{Finally,} while we separated the concepts for our comparative study, a real email app could combine the UIs for \modeours{} and \modemail. %
Note that our CDLR design already supports a message-level workflow by skipping to screen 2 and using the \imppass{} feature. %
It was sometimes already used in this way (\cref{sec:results_workflows}), as discussed next.




\subsection{Combined Sentence- and Message-level Support Offers Nuanced Control over AI Involvement}

Evaluating our \modeours{} concept also allowed us to gain insights into the \textit{combination} of different levels of writing support, not studied so far in the literature. 
While related work addressed AI on either sentence-level or message-level~\cite{Fu2023sentencevsmessage, Chen2019smartcompose, Kannan2016smartreply}, we explored the design space in between, with a flexible mix. %
We found that this combination gives users more nuanced control over how they involve AI. 

Concretely, the way people mixed the different degrees of engaging with AI  in \modeours{} (\cref{sec:results_workflows}) had a meaningful impact on metrics of interaction and outcome (\cref{sec:discussion_results_overview}). 
Fittingly, people appreciated \modeours{} particularly for aspects related to control and quality (\cref{sec:results_perception}). %
In summary, we thus conclude that offering optional AI support on different levels is accepted by users in this context and provides more nuanced control over AI involvement and its impact. %




Our design partly contradicts product trends, which generate complete replies and focus on workflows that assume that people want to start by delegating more to the AI (\cref{sec:related_work_current_products}). In fact, participants in our study expressed diverging preferences on this, both in behaviour (\cref{sec:results_workflows}) and reflection (\cref{sec:results_fav_mode}). In this context, our findings highlight a variety in workflows that motivates further exploration of flexible designs. Here, our concept of \modeours{} provides inspiration for offering different levels of optional AI support, to improve various response workflows or writing workflows in general. %




\subsection{Reflections on Methodology}\label{sec:discussion_methods}

Many suggestions in the formative study were accepted without input (\cref{sec:formative_study_results}), potentially to satisfice, that is, to finish the study faster even with less than ideal results. We thus added briefings in the main study (\cref{sec:procedure_email_tasks}), which provided topic-specific data about how to reply (e.g. unavailable on day X, not selling below a certain price). We did \textit{not} give these to the LLM, since we did not want to simulate a ``mindreading'' system. %
    
Interestingly, the ratio of emails that did not cover the briefings' key aspects was \pct{5} higher for \modeours{} than for \modemailtxt, and \pct{10} higher than for manual writing (\cref{sec:results_briefing}). 
We explain this as follows: Typing manually, people might as well enter a reply in line with the briefing. In contrast, they might accept AI text, if available, to be fast without checking too closely. 

Our data supports this: 
We found the lowest briefing conformity (\pct{50}, \cref{sec:results_briefing}) among replies written without investing in prompts, and thus fully optimised for speed, in both \modeours{} and \modemail{}. This lack of entering prompts had a much larger impact on conformity than the UI in general (\cref{tab:lmm_overview2}, row 1). In this light, the \pct{5} difference between \modeours{} and \modemail{} might be attributed to the fact that \modemail{} only had full response generation, with no other features for users to consider instead of focusing on the one generated text. Additionally, \modeours{} automatically loads suggestions once a sentence is selected, which might make satisficing more tempting. 

\revision{More broadly, in a paid online study such as ours, participants likely feel the incentive to complete the task quickly. While real mobile emailing contexts also include situations with time pressure, our study had no negative consequences of writing a less than ideal email. Therefore, the willingness to accept suggestions might be inflated in the study. That said, in real life, people might also have reasons to vary their investment (e.g. based on the importance of the email), which is supported by the flexibility of \modeours. Overall, the timings and thoughtful responses to our (optional) open questions indicate that participants did not merely ``skip'' through the study.} %
\revision{Supporting this,} the majority of emails per UI (>\pct{76}) indeed included the key information from the briefings (\cref{sec:results_briefing}), and the subjective quality of the writing was high (even when not briefing conform) across all UIs (\cref{sec:result_quality}).

In summary, we found evidence that the presence of AI automation features for a study task reduces task adherence, possibly because people then choose different speed-performance tradeoffs \revision{for the study and/or} monitor their results and performance less closely. This is consistent with findings in related work that people believe that AI improves their performance, even when it does not~\cite{Kloft2024placeborobust}.
A future dedicated study could investigate this in more detail since this is potentially relevant for many human-AI interaction studies. 


\revision{Finally, such studies could let participants themselves or third parties assess the quality of produced texts to capture self-perception and external perception. Following research interests in AI-mediated communication (cf.~\cite{fu2024texttoself, Hancock2020aimc}), this would focus not only on the sender's interaction, as in our case here, but also capture the perception of the receivers.}




\subsection{Reflections on Prompting: Co-creative Chain-of-Thought Prompting}\label{sec:discussion_prompting}
We use \textit{Chain-of-Thought (CoT)} as a lens to reflect on our prompting.
CoT instructs an LLM to generate intermediate steps~\cite{wei2022chain} (e.g. by adding``Let's think step by step''~\cite{kojima2022large}). 
In \modeours{}, users prompt intermediate generation steps by selecting text in the email, while our \imppass{} feature then prompts the LLM to generate a full reply from these texts when used at the end. 
In this view, the user contributes to the intermediate steps on the way to the final result. Thus, this prompting workflow could be seen as a kind of user-involved CoT, or \textit{Co-creative CoT (Co-CoT).}

This is reflected in people's comments on prompting: ``[\modeours] was the best to express opinions in a way that isn't just one single prompt, creating a more real feeling of thoughts behind it that AI tends to lack in single prompt emails.'' (P117\oldId{P1424}) %
We believe that this concept is useful more broadly: Rather than only writing a meta-instruction such as ``Let's think step by step'', the user actively contributes to this step-wise ``thinking'' along the way.
