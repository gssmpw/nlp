\section{Discussion}

\revision{In this section, we discuss the comparison to adversarial image-based techniques and address several challenges associated with real-world deployment.}

\revision{\noindent \textbf{Comparison to Adversarial Attacks.} Adversarial image-based techniques typically rely on the addition of carefully crafted noise to images. However, recent studies~\cite{wei2022towards} indicate that these methods often lack transferability and can be easily defeated by a novel LLM with enhanced visual capabilities. Our experimental results demonstrating the LLM's effectiveness in identifying adversarial images is available on our website~\cite{ourwebsite}.}

\revision{\noindent \textbf{Challenge of Cross-cultural Adaptability.} Our experiments reveal that individuals from different countries and age groups may exhibit varying abilities in identifying illusionary images due to cultural differences. To mitigate this issue, we propose incorporating common, everyday images—such as those of fruits, restaurants, and landscapes—to create illusionary images that are universally recognizable. By leveraging familiar objects, we aim to minimize the impact of cultural differences and ensure a consistent user experience across diverse demographics.}

\revision{\noindent \textbf{Challenge of Image Copyright.} In real-world deployment, copyright concerns may render certain images or terms (e.g., \textit{Mickey Mouse}) unsuitable for use. To mitigate these issues, we plan to employ a local AI system to generate images while carefully avoiding problematic words. This approach enables the creation of copyright-free images, thereby ensuring smoother and more compliant deployment in practical scenarios.}