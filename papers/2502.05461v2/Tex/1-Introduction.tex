\section{Introduction} 
CAPTCHAs (Completely Automated Public Turing tests to tell Computers and Humans Apart)~\cite{von2003captcha} are tools designed to distinguish human users from automated bots on websites. They ingeniously capitalize on the unique cognitive abilities of humans, assigning tasks that are simple for people but difficult for machines. These tasks typically involve recognizing distorted text~\cite{von2003captcha}, selecting specific images~\cite{gossweiler2009s,matthews2010scene}, or identifying patternsâ€”activities that rely on human perception and intuition. Therefore, traditinoal CAPTCHAs can be categorized into two types: text-based and image-based. CAPTCHAs leverage the gap between human cognitive skills and the current limitations of AI, making them an essential tool in online security and ensuring the integrity of web interactions. 

In the era of AI, techniques bring the possibilities of automating CAPTCHA solving~\cite{ye2018yet,noury2020deep,teoh2024phishdecloaker}. Early CAPTCHAs, such as text-based and image-based challenges, rely on tasks of text recognition and basic image identification which challenge the unique visual and cognitive abilities of humans. However, modern deep-learning models can now easily solve these types of challenges. In response to this, reasoning-based CAPTCHAs~\cite{gao2021research} that requires more logical reasoning and common sense emerges. 
More recently, the evolution of Large Language Models(LLMs) has brought substantial improvements in both reasoning capabilities and multimodal processing~\cite{achiam2023gpt,team2023gemini}. This technique has been applied to the development of new approaches to tackle reasoning-based CAPTCHAs~\cite{deng2024oedipus}. However, there remains a gap in research: no study has systematically investigated the performance of multimodal LLMs across the full spectrum of CAPTCHA types.

In this paper, we first investigate the performance of multimodal LLMs on the task of CATPCHA solving. We evaluate two state-of-the-art models, GPT-4o~\cite{GPT4-o} and Gemini 1.5 pro 2.0~\cite{team2023gemini}, across different types of CAPTCHAs (e.g., text-based, image-based, and reasoning-based CAPTCHAs). We employ Zero-Shot prompting~\cite{pourpanah2022review} and the Chain-of-Thought (CoT) prompting~\cite{wei2022chain} as our primary methodologies. Additionally, we conducted a user study to assess how many attempts human users typically need to successfully pass these CAPTCHAs, which has not been considered in any papers before~\cite{deng2024oedipus,searles2023empirical}. 

The results of our investigation reveal four key insights: (1) LLMs perform better on text-based CAPTCHAs compared to image-based and reasoning-based CAPTCHAs. (2) While LLMs struggle with complex reasoning CAPTCHAs, their performance improves when using the CoT prompting, suggesting that with reasoning chains, LLMs have the potential to solve such challenges. This indicates that current CAPTCHAs may no longer be as secure as intended. (3) Our user study shows that although reasoning-based CAPTCHAs are difficult for AI to solve, they are also challenging for human users. These challenges can even frustrate users, diminishing their patience during attempts. (4) Finally, our study reveals that human users often make the same mistakes as LLMs, underscoring the need to develop methods that can effectively differentiate between LLMs and human users.

The empirical study prompts us to explore the design of a new CAPTCHA that is AI-hard and human-easy. Specifically, we aim to create CAPTCHAs that more effectively differentiate between humans and bots. To this end, we propose IllusionCAPTCHA, which employs images embedded with visual illusions - challenging for AI models to interpret, but easier for humans to perceive. These illusions take advantage of the human brain's unique ability to process visual and cognitive discrepancies, a capability that AI struggles to replicate. Additionally, to further improve the distinction between human users and bots, we incorporate a step-by-step question structure that prompts bots to make predictable errors. This design ensures that human users can easily pass these CAPTCHAs, while bots are more likely to fail by making consistent, recognizable mistakes.

The efficiency of IllusionCAPTCHA was evaluated using two advanced multimodal LLMs (GPT-4o and Gemini 1.5 pro 2.0). Through experiments, we find that these LLMs are unable to successfully pass our CAPTCHA implementation, and the step-by-step question structure effectively tricks them. Furthermore, the user study reveals that human participants are able to solve the CAPTCHA on their first attempt. These findings demonstrate that IllusionCAPTCHA offers a higher level of security compared to traditional challenges. Additionally, it is easier for humans to solve than reasoning-based CAPTCHAs, while still maintaining a robust defense against AI models.

To summarize, we make the following contributions: 
\begin{itemize}[leftmargin=*]
    \setlength\itemsep{0pt}
    \item We conducted a systematic empirical study to investigate the effectiveness of LLMs on CAPTCHAs and found that current CAPTCHAs are no longer secure. Furthermore, our user study reveals that, in most circumstances, users are unable to pass the current CAPTCHAs on their first attempt. To the best of our knowledge, this is the first study that systematically surveys LLM effectiveness on CAPTCHAs.
    
    \item We introduce IllusionCAPTCHA, the first illusion-based CAPTCHA that leverages the unique ability of the human brain to process visual information. Additionally, our step-by-step questioning approach effectively encourages bots to make predictable mistakes.
    
    \item We evaluate our method using two state-of-the-art models, GPT-4o and Gemini 1.5 pro 2.0. The experimental results demonstrate that our strategy effectively presents challenges for AI models to solve the generated CAPTCHAs, rendering it AI-hard, while simultaneously remaining accessible and straightforward for human users to navigate. This dual capability ensures that our CAPTCHA not only enhances security against automated attacks but also provides a user-friendly experience, bridging the gap between robust security measures and usability.
\end{itemize}

\revision{\noindent \textbf{Ethical Considerations.} We emphasize that our research and experiments on LLMs' effectiveness in solving CAPTCHAs were not conducted for unethical purposes or financial gain, and the user study we designed raises no ethical concerns. Unlike many studies that focus on developing CAPTCHA solvers, our proposed IllusionCAPTCHA is intended to enhance web security by effectively defending against modern LLM-based CAPTCHA attacks. Further details about our ethical declaration are available on our website~\cite{ourwebsite}.}











