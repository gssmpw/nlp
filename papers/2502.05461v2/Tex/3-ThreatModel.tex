\section{Threat Model}
In this paper, we outline our assumptions regarding the goals and capabilities of attackers.

\noindent\textbf{Attacker goals.} We assume that the adversary aims to automatically solve CAPTCHAs without human interactions, which could potentially lead to these results~\cite{che2021augmented,shi2020text}:
(1) Automating Actions: Gaining unauthorized access to websites, applications, or services to automate tasks (e.g. account creation, data scraping, or spamming). (2) Credential Harvesting: Exploiting CAPTCHA weaknesses to gain access to user accounts by defeating login protections. (3) Fraudulent Activities: Engaging in malicious activities like ticket scalping, purchasing limited-edition items, or bypassing purchase limits imposed by websites. (4) Disruption of Services: Creating bot networks that can flood websites with traffic, breaking CAPTCHAs to disrupt normal operations.


\noindent\textbf{Attacker capabilities.} We assume the attacker is restricted to interacting with the CAPTCHA through the graphical interface, without using techniques such as reverse engineering, JavaScript decompiling, or direct code analysis. In this work, we primarily consider that the adversary abuses the capabilities of multimodal LLMs with their reasoning capabilities and object recognition capabilities. These LLMs can be utilized not only to solve CAPTCHAs but also to automate the entire attack process—from selecting target websites to registering accounts—enabling a highly efficient and scalable attack pipeline.

