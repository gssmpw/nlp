\section{Related Works on Exploring Rashomon Sets}
\label{sec:related_works}

Beyond predictive performance, other model properties, such as fairness and sparsity, are often desirable. Since these properties are typically not aligned with maximizing predictive performance, it is necessary to tolerate a small drop in performance, quantified as \smash{$\epsilon$}, to search for alternative models \smash{$\h_\text{alt}$} satisfying \smash{$\emploss{\data}{\h_{\text{alt}}} \leq \emploss{\data}{\h_{\data}} + \epsilon$}.  The set of such alternative models is referred to as the \emph{Rashomon set}____, defined as:
\begin{align}
    \Rashomon := \{\h\in \H : \emploss{\data}{\h}\leq \emploss{\data}{\h_{\data}}+\epsilon\}.
\end{align}
Rashomon sets have been studied in the context of \emph{predictive multiplicity}, demonstrating that 
different models can have conflicting predictions on a substantial subset of data____. 
A key result from ____ establishes that for any alternative $\h_{\text{alt}}\in \Rashomon$, the following tight bound holds:
\smash{$\frac{1}{\nexamples}\sum_{\example=1}^\nexamples \indicatorfunction[\h_{\text{alt}}(\attributes[\example])\neq \h_{\data}(\attributes[\example])]\leq 2\emploss{\data}
{\h_{\data}}+\epsilon$}.
This implies that even with a small $\epsilon$, models within the Rashomon set can differ significantly in their predictions whenever the empirical loss \smash{$\emploss{\data}{\h_{\data}}$} is non-zero. For instance, if \smash{$\h_{\data}$} has an empirical loss of 10\%, alternative models in the Rashomon set could disagree with \smash{$\h_{\data}$} on up to 20\% of the dataset. Similarly, for a predictor \smash{$\h_{\data}$} with a 25\% empirical loss, disagreements with alternative models could extend to 50\% of the dataset. These substantial differences emphasize that models within the Rashomon set, despite achieving nearly equivalent predictive performance, can vary markedly in their predictions. This variability has important implications for fairness, as fairness metrics such as statistical parity (Equation~(\ref{eq:sp})) and equal opportunity (Equation~(\ref{eq:eo})) are aggregates of predictions across demographic subgroups. Consequently, the Rashomon set may contain alternative models with more desirable fairness or sparsity properties. However, identifying such models efficiently remains a significant challenge. Existing methods for exploring the Rashomon set can be categorized into two main approaches: \emph{enumeration-based} and \emph{enumeration-free}.

Enumeration-based methods sample all models within the Rashomon set (or a substantial subset thereof). Existing approaches have applied enumeration to the Rashomon sets of rule lists____, rule sets____, and decision trees____ using branch-and-bound techniques. These methods explore the combinatorial hypothesis space $\H$ while leveraging error lower bounds to prune the search space efficiently. These past works have shown that competing models exhibit different fairness properties. However, a key limitation of these methods is their reliance on enumerating (and storing) a large number of models.

\input{related_works_rashomon_sets}

Alternatively, enumeration-free methods focus on the identification of models within the Rashomon set that achieve the extreme values of a specific functional \smash{$\property: \H \rightarrow \R$}.
This approach allows targeted exploration of the Rashomon set by optimizing for particular properties without exhaustive enumeration. Previous work has investigated the min-max range of the functional $\property(\h)=\h(\attributes[])$ for 
linear models with the hinge-loss ____ and the logistic loss ____. 
Other studies have explored the extreme values of feature importance scores for linear models under the squared or hinge loss ____, or Generalized Additive Models (GAMs) under the logistic loss ____. 
Finally, the min-max range of the functional $\property$ underlying fairness metrics (cf. Equations (\ref{eq:sp}) \& (\ref{eq:eo})) has been characterized for linear models with logistic loss ____. 
Table~\ref{tab:rashomon} summarizes these previous works. Building on this, our study:
\begin{itemize}
    \item explores the range of unfairness within the Rashomon sets using the ``true'' $0/1$ loss, whereas previous works relied on convex upper bounds such as the logistic or hinge loss;
    \item characterizes the effect of sparsity constraints on the range of possible disparities within the Rashomon set;
    \item provides a framework applicable to many hypothesis classes $\H$
    provided their learning process can be formulated as a mathematical optimization problem.
\end{itemize}