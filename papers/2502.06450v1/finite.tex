% !TeX root = article.tex
% !TeX spellcheck = en_US
%% We are now ready to introduce transducers.

\subsection{Transducers and Regular Relations}

For any finite set $A$, called an alphabet, we denote $A^*$ the set of finite words over $A$, that is $A^* = \biguplus_{k \geq 0} A^k$. % $ = \{(k,(a_1,\dots,a_k))\mid k \geq 0, \forall 1 \leq i \leq k, a_i \in A\}$. 
We write a word $w = w_1\dots w_k \in A^*$, $|w|$ for its size $k$ and $\epsilon$ for the empty word. 
The concatenation of two words $u$ and $v$, respectively of size $n$ and $m$, is denoted $uv$ and has size $n+m$. 
A subset of $A^*$ is called a language over the alphabet $A$. A \textbf{uniform relation} between two alphabets $A$ and $B$, denoted $\mathcal{R}:A^*\to B^*$, is a language over the product alphabet $A\times B$, equivalently, it's a relation between $A^* $ and $B^* $ only relating words of the same size, \textit{i.e.} $u~\R~v $ implies $|u|=|v|$.

The product of two uniform relations $A^* \to B^* $ and $C^* \to D^* $ is formally a relation $A^* \times C^* \to B^* \times D^* $ but to maintain the uniformity constraints, we choose to restrict it to a uniform relation $(A\times C)^* \to (B\times D)^* $. 
While of course $(A\times B)^* \neq A^* \times B^*$ as sets, we will identify the two as long as all relations involved are uniform. In other words, uniform relations are ignoring the elements of $A^* \times B^* $ that are not in $(A\times B)^*$. We keep the notation $\R \times \S$ for this uniform product, even if it is no longer a Cartesian product. Uniform relations are preserved by composition and (uniform) product, and include identities, as well as cups and caps. Similarly to \bfup{FinRel}, they form a compact closed strict symmetric monoidal\footnote{Note that the monoidal unit of \bfup{UniRel} is $\one^*$, that is the words over the singleton alphabet, which is isomorphic to $\mathbb{N}$.} category called \bfup{UniRel}, meaning we can use the exact same graphical representation for them. 

\begin{definition}[Transducer]
	A (non-deterministic finite) transducer is a tuple $(\T, A, B, Q, I, F)$ where $A$ is a finite set representing the \emph{input alphabet}, $B$ is a finite set representing the \emph{output alphabet}, $Q$ is a finite set representing the \emph{states}, $\T: A\times Q \to B\times Q$ the \emph{transition relation}, ${I} \subseteq Q$ the \emph{initial states} and ${F} \subseteq Q$ the \emph{final states}.
\end{definition}

Similarly to non-deterministic finite automata, we write $q \xrightarrow[b]{a} q'$ whenever $((a,q),(b,q'))$ is a transition of $\T$. A \textbf{run} of length $k$ within a transducer is a sequence
\[ q_0 \xrightarrow[b_1]{a_1} q_1 \xrightarrow[b_2]{a_2} \dots \xrightarrow[b_k]{a_k} q_k \]
such that $q_0 \in I$ and $q_k \in F$. When such a run exists, we say that the transducer can transform the word $a_1\dots a_k$ into $b_1\dots b_k$. The \emph{behavior} of the transducer, written $\L(\T, A, B, Q, I, F)$, is the uniform relation from $A^*$ to $B^*$ which relates $w$ to $v$ whenever the transducer can transform $w$ into $v$. 

A transducer with only inputs, said otherwise $B=\one$, is exactly a non-determinisitic finite automaton. Alternatively, every transducer from $A$ to $B$ can be seen as a non-deterministic finite automaton over $A \times B$. We recall that a \textbf{regular language}, is a language recognized by a finite automaton. 
A \textbf{regular relation} is a uniform relation $A^* \to B^* $ which is a regular language when seen as a subset of $(A\times B)^*$, which is the case if and only if it is the behavior of a transducer. 

\begin{proposition}\label{prop:RegRel-is-cat}
	Regular relations are preserved by composition and product. We call \bfup{RegRel} the subcategory of \bfup{UniRel} of regular relations.
\end{proposition}

The proof is based on standard construction of products and composition of transducers.

%\begin{proof}
%	Given two transducers $(\T,A,B,Q,I,F)$ and $(\S,C,D,P,J,G)$, we can build their product as $(\R,A \times C,B \times D,Q \times P, I \times J, F \times G)$ where $((a,c),(q,p))~\R~((b,d),(q',p'))$ whenever $(a,q)~\R~(b,q')$ and $(c,p)~\R~(d,p')$. Its behavior is exactly the product of the two behaviors. 
%	Assuming $B=C$, we can build their composition as $(\U,A,D,Q \times P,I \times J, F \times G)$ where  $(a,(q,p))~\U~(d,(q',p'))$ whenever there exists $b \in B$ such that  $(a,q)~\R~(b,q')$ and $(b,p)~\R~(d,p')$.	 Its behavior is exactly the composition of the two behaviors.
%\end{proof}

Any relation $\mathcal{R}:A\to B$ can be lifted to a regular\footnote{The corresponding transducer has only one state which is accepting and initial and its transition relation is directly $\mathcal{R}$ seen as having type $A\times \one \to B\times \one $.} relation $\mathcal{R}^* : A^* \to B^* $ defined letter by letter: $\mathcal{R}^* = \{ (u,v) \mid |u| = |v|, \forall 1 \leq i \leq |u|, (u_i,v_i) \in \R\}$. Categorically, this lift is a faithful strong symmetric monoidal functor from \bfup{FinRel} to \bfup{RegRel}, which means:

\begin{description}
	\item[Functoriality] $(\S \circ \R)^* = \S^* \circ \R^*$ and $(\id_A)^* = \id_{A^*}$.
	\item[Strong Monoidality] $(\R \times \S)^*$ can be identified with $\R^* \times \S^*$ within \bfup{RegRel}.
	\item[Symmetric] $(\gamma_{A,B})^* = \gamma_{A^*,B^*}$.
	\item[Faithfullness] If $\R^* = \S^*$, then necessarily $\R = \S$.
\end{description}

This notion of transducers and regular relations appeared early in the history of theoretical computer science, one can find similar definitions, though in a different form in \cite{DBLP:journals/ibmrd/ElgotM65}.

\subsection{Diagrammatic Representation of Transducers}

Looking at $\R : \Pi_{i=1}^n A_i \to \Pi_{j=1}^m B_j$, we can see its lifted relation $\R^*$ as going from $\Pi_{i=1}^n A_i^*$ to $\Pi_{j=1}^m B_j^*$, since $(\Pi_{i=1}^n A_i)^*$ is identified with $\Pi_{i=1}^n A_i^*$ (we are only working with uniform relations here).
Diagrammatically, this allows us to apply $\_^*$ to individual wires:
\[ \tikzfig{rel-lifted}\]

When looking at uniform relations over words, one such regular\footnote{It is the behavior of the transducer $(\gamma_{A,A},A,A,A,I,F)$.} relation will be particularly useful, the \textbf{finite shift}  $\shift{I}{F}_A : A^* \to A^*$ for a finite set $A$ and two subsets $I,F \subseteq A$, defined as $\{ (w,v) \mid \exists i \in I, \exists f \in F, iw = vf \}$. Said otherwise, $w$ and $v$ are related by the shift if either both are empty and $I \cap F \neq \varnothing$, or if neither are empty and the first letter of $v$ is in $I$, the last letter of $w$ is in $F$, and the remaining letters satisfy $w_k = v_{k+1}$. Diagrammatically, we represent the shift and its transposed:
$\tikzfig{rel-shift-finite}$.

The shift allow to obtain the behavior of a transducer in a compositional way.

\begin{proposition}[Proved in \Cref{app:transducer-fin}]\label{prop:transducer-fin}
	For every transducer $(\T, A, B, Q, I,F)$, its behavior can be obtained by lifting $\T$ and using the shift as follows:
	\[ \tikzfig{rel-trans-fin} \]
\end{proposition}

\subsection{Diagrammatic Language for Transducers}\label{sec:diagrams-blue}

\begin{wrapfigure}{r}{0.2\textwidth}
		\tikzfig{graph-from-trans-fin}
\end{wrapfigure}
This is however not the only way to represent transducers using relations. Another approach is to start from the category \bfup{FinRel} and freely add a feedback, state that a transducer $(\T,Q,B,Q,I,F)$ should be able to be represented by the diagram on the right, and then find additional equations ensuring that this feedback operator behaves exactly as transducers do.

Formally, we define a graphical language \bfup{Trans}, so a syntactical construct, where the diagrams are seen as mathematical objects distinct from the relations they represent -- which is a category where the objects are finite sets, and where the morphisms are generated by composing sequentially and in parallel the generators below together with the usual equations of a strict symmetric monoidal category (see \Cref{appfig:rel-equations-fin} in the appendix for a reminder), the equations of a feedback  category\footnote{Some authors, like in \cite{Katis09}, have an additional equation which allows to slide isomorphisms through the feedback. While we do not have this equation, it is actually a special case of \Cref{fig:graph-slide}, which is part of the completed equational theory.} (see \Cref{fig:graph-feedback}), and some equations ensuring we faithfully embed \bfup{FinRel} (see \Cref{fig:graph-finrel}).
%\begin{figure*}[!h]
	\[\tikzfig{graph-generators}\]
%	\caption{Generators of \bfup{Trans}.}
%	\label{fig:graph-generators}
%\end{figure*}

\begin{figure*}
	\tikzfig{graph-feedback}
	\caption{Equations for a Feedback Category.}
	\label{fig:graph-feedback}
\end{figure*}

\begin{figure*}
	\tikzfig{graph-finrel}
	\caption{Equations for Faithfully Embedding \bfup{FinRel}.}
	\label{fig:graph-finrel}
\end{figure*}

Let us point a couple of facts about this language:
\begin{itemize}
	\item A bundle of wires labeled $A_1,\dots,A_n$ is the same as a single wire labeled $\Pi_{i=1}^n A_i$.
	\item The wires and syntactical constructs are in \bfup{\blue{thick blue}}, to distinguish them from actual relations. $\R$ refers to an actual relation while $\bR$ refers to an element of our language.
	\item Double-line boxes denote the generator, while single-line boxes denote any diagram potentially constituted of many generators, including feedbacks.
	\item The arrows on the feedback are a reminders that those are not the same as the cup and cap of \Cref{sec:relations}.
	\item Within \Cref{fig:graph-feedback}, the gray lines correspond to bracketing, and similarly to the equations of a strict symmetric monoidal category, the overall consequences of those equations is that bracketing can be safely ignored. Additionally, compared to the literature, those equations had to be adapted to the presence of labels on the feedback.
	\item The equations of \Cref{fig:graph-finrel} ensures that if a diagram does not contain any instance of the ``feedback'' generator, we can merge all the generators into a single double-line box.
	\item The current equational theory is incomplete, additional equations will be added in \Cref{fig:fin-simulation-principle} to obtain completeness.
\end{itemize}

In order to ensure that the equations are not contradictory\footnote{Which would lead to the trivial category where all the diagrams are equal to one another.}, we provide a semantics and prove soundness of our equations. The semantics is a strong symmetric monoidal functor from \bfup{Trans} to \bfup{UniRel}, which we write $\binterp{-}$, and is actually simply ``removing the color and adding a $\_^*$ everywhere''. We provide an explicit definition in the appendix (see \Cref{appfig:fin-interp}). Soundness means that if one rewrites a diagram $\bR$ into $\bS$ using any of the listed equations, we still have $\binterp{\bR} = \binterp{\bS}$.
Completeness would be the other way around, whenever $\binterp{\bR} = \binterp{\bS}$ then we could rewrite $\bR$ into $\bS$ (in other words,  $\binterp{-}$ would be faithful).
While not having completeness yet, we still have a quasi-normal form, and universality for regular relations.
		
\begin{proposition}[Quasi-Normal Form]\label{prop:normal-form-fin}~\\
	\begin{tabular}{@{ }p{11cm}l@{ }}
	Any diagram of $\bR \in \bfup{Trans}$ from $A$ to $B$ can be put in the form on the right for some finite set $Q$ and $\T \in \bfup{FinRel}$.&\tikzfig{graph-from-trans-fin}
	\end{tabular}
\end{proposition}

\begin{proof}
	We start by using the first equation of \Cref{fig:graph-feedback} from right to left to push all the feedbacks at the bottom of the diagram. Then, we use the equations of \Cref{fig:graph-finrel} to merge all the non-feedback into a single box. Lastly, we use the last equation of \Cref{fig:graph-feedback} to merge all the feedbacks into a single feedback.
\end{proof}
\begin{theorem}[Universality]\label{thm:universality-fin}
	For all $\bS \in \bfup{Trans}$, $\binterp{\bS}$ is a regular relation. For all regular relation $\R$, there exists $\bS \in \bfup{Trans}$ such that $\binterp{\bS} = \R$.
\end{theorem}
\begin{proof}
	This follows from \Cref{prop:normal-form-fin} and \Cref{prop:transducer-fin}. 
\end{proof}


\subsection{Simulation Principle and Completeness}\label{sec:completeness-fin}

We claim that we can complete our equational theory by adding a single equation, the simulation principle of \Cref{fig:fin-simulation-principle}.

\begin{figure}[!h]
	\[\tikzfig{fin-simulation-principle}\]
	\caption{Simulation Principle for Finite Words.}
	\label{fig:fin-simulation-principle}
\end{figure}

The core idea behind this principle is that a finite run can be see as a diagram starting with $I$, followed by a finite number of applications of $\R$ and finally ends with $F$. In such diagram, $I$ can turn into $J$ by "spawning" a $\S$, which can then move through $\R$, turning it into $\T$, and finally be absorbed by $F$ to turn it into $G$, proving the equivalence with a run in the second transducer. This principle is sound with respect to $\binterp{-}$ (this is proved formally in \Cref{app:fin-simulation-principle}). The principle directly implies the sliding rule \Cref{fig:graph-slide} allowing in particular to equate transducers with isomorphic sets of states. Notice that \Cref{fig:graph-slide} allows for a $\bR$ that might itself include some feedbacks.

\begin{figure}[h]
	\[\tikzfig{graph-slide}\]
	\caption{Sliding.}
	\label{fig:graph-slide}
\end{figure}

%We will now prove the following completeness theorem.
\begin{theorem}[Completeness]\label{thm:completeness-fin} For $\bR$ and $\bT$ two diagrams of \bfup{Trans} from $A$ to $B$. Whenever $\binterp{\bR} = \binterp{\bT}$, we can rewrite $\bR$ into $\bT$ by using only the rules of \bfup{Trans} and \Cref{fig:fin-simulation-principle}.
\end{theorem}

The core idea of the proof is diagrammatically mimic the determinization and minimization from automata theory. We recall that a finite automaton is simply a transducer with $\one$ for output alphabet, so we start by studying completeness in the case where $B = \one$.

\begin{definition}[Determinization]
	Let $(\T,A,Q,I,F)$ be a finite automaton. We write $\xrightarrow[\text{\small $\T$}]{}$ for the transitions within that automaton. Its determinization is the automata \[(\P(\T), A, \P^{\textup{acc}}(Q), \{I\}, \P^{\textup{acc}}_{\cap F \neq \varnothing}(Q))\]
	More precisely, we start by recalling that $\P(Q)$ is the set of all subsets of $Q$. We use $x,y$ for elements of $Q$, and $X$,$Y$ for elements of $\P(Q)$.  Then, we define the function\footnote{We consider functions to be a special case of relations.} $\P(\T): A \times \P(Q) \to \P(Q)$ as 
	$ \P(\T)(a,X)=\{y\in Q ~|~ \exists x\in X,~  x \xrightarrow[\text{\small $\T$}]{a} y \} $.
	We then consider the set $\P^{\textup{acc}}(Q)$ of subsets of $Q$ accessible by iteration of that function, starting from $I$. We can now restrict $\P(\T)$ to a function $A \mapsto \P^{\textup{acc}}(Q) \to \P^{\textup{acc}}(Q)$. Lastly, $\P^{\textup{acc}}_{\cap F \neq \varnothing}(Q)$ is the set of accessible subsets of $Q$ that have a non-empty intersection with $F$.
\end{definition}

\begin{proposition}\label{prop:determinization}
	For all finite automata $(\T,A,Q,I,F)$, we have
	\[ \tikzfig{fin-determinization}\]
	where $\ni : \P^{\textup{acc}}(Q) \to Q$ is the usual ``contains'' relation, that is $X \ni x$ whenever $x \in X$.
\end{proposition}
\begin{proof}
	Using the logical reasoning as in \Cref{sec:logic}, we can rewrite the equation as the following. We are looking at $\forall a\in A,~ \forall X\in \P^{\textup{acc}}(Q),~\forall y\in Q,~$
	
	\[ \left(\exists x\in Q,~ (x\in X) \land (x \xrightarrow[\text{\small$\T$}]{a} y)\right) ~\Leftrightarrow~ \left(\exists Y\in \P^{\textup{acc}}(Q),~   (X \xrightarrow[\text{\small$\P(\T)$}]{a} Y) \land (y\in Y)\right)\]
	We start by reformulating the right side of the equivalence, as $\P(\T)$ is a function, we can remove the $\exists$ and write $y \in \P(\T)(a,X)$. Then, using the definition of $ \P(\T)$, we obtain that it is equivalent to $\exists x \in X, x \xrightarrow[\text{\small$\T$}]{a} y$, which is exactly the left side of the equivalence.
\end{proof}

Rephrased in our graphical language and applyin the simulation principle, this gives:
\begin{corollary}\label{cor:determinization}
	For any finite automaton $(\T,A,Q,I,F)$, using \Cref{fig:fin-simulation-principle}, we have
	\[ \tikzfig{fin-determinization-conclusion}\]
\end{corollary}

Another key element of our completeness result is the minimization of automata.
\begin{definition}[Minimization]	
	Let $(\D,A,Q,\{i\},F)$ be a \textbf{deterministic} finite automaton where every state is accessible from the initial state. We write $\xrightarrow[\text{\small $\D$}]{}$ for the transitions within that automaton. We write  $\xrightarrow[\text{\small $\D$}]{w}$ with $w$ a word of size $n$ for its iterated transition $\xrightarrow[\text{\small $\D$}]{w_1}\dots \xrightarrow[\text{\small $\D$}]{w_n}$. Its minimization is the deterministic automata 
	$ (L_\D,A,L_{A^*},L_{\epsilon},L_{A^*}^{\ni \epsilon}) $.\\
	More precisely, we write $L_w = \{ v \in A^* \mid \exists f \in F, i \xrightarrow[\text{\small $\D$}]{wv} f\}$, and remark that whenever $L_w = L_u$, then for all $a \in A$ we also have $L_{wa} = L_{ua}$. We then define $L_{A^*} = \{ L_w \mid w \in A^*\}$ note that a single element of this set might correspond to multiple distinct $w$, and in fact $L_{A^*}$ is actually smaller or equal to $Q$ in cardinality. We defined its restriction $L_{A^*}^{\ni \epsilon} = \{ L_w \mid w \in A^*, \epsilon \in L_w\}$. Lastly, we define the transition function as $L_\D(a,L_w) =  L_{wa}$.
\end{definition}

This minimization is well known in the literature \cite{DBLP:books/daglib/0016921}, and yields the unique smallest deterministic automaton equivalent to the starting one.

\begin{proposition}\label{prop:minimization}
	For any deterministic finite automaton $(\D,A,Q,\{i\},F)$ where every state is accessible from the initial state, we have
	\[ \tikzfig{fin-minimization}\]
	where $\L : Q \to L_{A^*}$ relates $p \in Q$ to $\ell \in L_{A^*}$ whenever $\ell = \{ v \mid \exists f \in F, p \xrightarrow[\text{\small$\D$}]{v} f\}$. We note that since every state is accessible, there exists $w \in A^*$ such that the later is equal to $L_w$.
\end{proposition}

The core idea is similar to \Cref{prop:determinization}: we express both sides of the equality as equations relating transitions of the transducers, and prove their equivalence using standard argument of automata minimization.
Again the simulation principle can be applied to conclude that the behavior of an automata and its minimization are the same.

\begin{corollary}\label{cor:minimization}
	For any deterministic finite automaton $(\D,A,Q,\{i\},F)$ where every state is accessible from the initial state, using \Cref{fig:fin-simulation-principle}, we have
	\[ \tikzfig{fin-minimization-conclusion}\]
\end{corollary}

We can now provide a proof of the completeness result.

\begin{proof}[Proof of \Cref{thm:completeness-fin}]
	We start with two diagrams $\bR,\bS$ of \bfup{Trans} from $A$ to $B$ and assume $\binterp{\bR} = \binterp{\bS}$. We start by focusing on $\bR$. We combine it with the cup $\epsilon_B$ to bend its output into an input, and we then use \Cref{prop:normal-form-fin} to put the result in quasi-normal form. Then, we use \Cref{cor:determinization} followed by \Cref{cor:minimization} to obtain:
	\[ \tikzfig{fin-compl-epsilon} \quad = \quad \tikzfig{fin-compl-normal-form} \quad=\quad \tikzfig{fin-compl-minimal} \]
	For convenience, we name $(\R_M,B \times A,Q_M,I_M,F_M)$ the resulting minimal automaton. We do the same for $\S$ and write $(\S_N,B \times A,Q_N,I_N,F_N)$ for the resulting minimal automaton. Since $\binterp{\bR} = \binterp{\bS}$ and by soundness of the equations, we obtain that:
	\[ \binterp{\tikzfig{fin-compl-minimal-M}} \qquad = \qquad \binterp{\tikzfig{fin-compl-minimal-N}} \]
	Using the definition of $\binterp{-}$ and \Cref{prop:transducer-fin}, it follows that $(\R_M,B \times A,Q_M,I_M,F_M)$ and $(\S_N,B \times A,Q_N,I_N,F_N)$ recognize the same language, hence by uniqueness of the minimal automaton (see \cite{DBLP:books/daglib/0016921}) we obtain that the two automata are equal up to an isomorphism $\iota : Q_M \to Q_N$, hence using the simulation principle with this $\iota$, we obtain
	\[   \tikzfig{fin-compl-epsilon}  =  \tikzfig{fin-compl-minimal-M}  = \tikzfig{fin-compl-minimal-N}  =  \tikzfig{fin-compl-epsilon-bis} \]
%	Which leads to
%	\[\tikzfig{fin-compl-epsilon} \qquad = \qquad \tikzfig{fin-compl-epsilon-bis}   \]
	By combining with the cap $\eta_B$ to bend the input $B$ into an output, and using the the fact that $(\id_B \times \epsilon_B) \circ (\eta_B \times \id_B) = \id_B$, we obtain $\bR = \bS$.
\end{proof}

The simulation principle requires to find a well chosen relation between the state spaces of two automata for the language equality to follow.
This is reminiscent of the well studied simulation techniques in automata theory, and it is not a coincidence. 
In fact, the simulation principles also holds in the case where we only want language inclusion, simply by replacing every ``='' of \Cref{fig:fin-simulation-principle} by $\subseteq$ (for a backward-simulation) or by $\supseteq$  (for a forward-simulation). Thus, the simulation principle can be reinterpreted as asking to find a simulation which is at the same time forward and backward, the fact that finding a backward-forward simulations implies language equivalence has already appeared in the literature \cite{lynch1995forward}.
