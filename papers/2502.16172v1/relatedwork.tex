\section{Literature Review}
Propensity Score Matching (PSM) and Instrumental Variable (IV) were two commonly used methods in causal inference before. PSM matches treatment and control groups by estimating the probability of individuals being treated, reducing selection bias. However, it relies on the accuracy of the model, cannot control unobservable confounding factors, and may degrade matching quality in high-dimensional data. The IV method addresses endogeneity by introducing instrumental variables that are correlated with the treatment variable but only with the outcome variable through the treatment variable. However, selecting instrumental variables and meeting exogeneity assumptions can be challenging, and weak instrument problems may affect the validity of estimates. Therefore, despite their significant applications in controlling confounding and endogeneity, researchers must carefully consider the limitations of PSM and IV. To address these shortcomings of traditional methods, DML models have emerged (Fuhr, Berens, \& Papies, 2024).

Chernozhukov et al. (2018) proposed the Double Machine Learning (DML) method, which is used to estimate treatment effects and structural parameters in causal inference for high-dimensional data. By combining machine learning with semi-parametric methods, DML can eliminate model bias, providing more accurate and unbiased estimates. They also demonstrated the application of this method in econometrics, particularly in addressing parameter estimation issues in policy evaluation and economic models.

Bach et al. (2022) introduced a Python open-source library for double machine learning (DML), designed to achieve robust causal inference through Neyman orthogonality, machine learning methods, and sample partitioning. It adopts object-oriented programming (OOP), supports various causal models (such as partially linear regression and instrumental variable regression), and provides a flexible API for extensible functionality. Compared to EconML and CausalML, DML places greater emphasis on the validity of orthogonality conditions and statistical inference.

Chernozhukov et al. (2024) further proposed the Double Machine Learning (DML) method, which combines the orthogonality of Neyman and cross-fitting to reduce the impact of high-dimensional interference parameter estimation errors on causal inference, achieving $\sqrt{N}$ convergence in target parameter estimation while maintaining statistical inference validity. DML is applicable to partial linear regression, instrumental variable models, and treatment effect estimation, providing a robust methodological foundation for high-dimensional causal inference.

Based on the theory and practice of modern DML, Flores \& Chernozhukov (2018) established an open-source code library for the GitHub project, demonstrating how to implement DML in Python for causal inference and effect estimation. It provides detailed documentation and examples, integrating machine learning methods such as random forests and Lasso regression, and supports model evaluation and result visualization, making it suitable for causal inference analysis of high-dimensional data.