\section{Iterative Data-based V-model}\label{03_Methodology}

Even though the existing development and V\&V frameworks for emerging complex systems, particularly automated vehicles, differ in their terminology, methodological specifics, and different emphasis, there is a general common sense that arises from the inherent nature of the engineering processes. Furthermore, while corresponding safety assurance is crucial for approval, it is highly dependent on the system and the environment, which is also referred to as ODD. Therefore, the overall methodology should be decoupled from the application-specific safety assurance, generalized across existing frameworks, and formalized along the transitions between simulation and the real world, while striving to support and enable safety argumentation along the resulting iterative process reference model in a general form. This requires, similar to the classical V-model, a certain level of abstraction for widespread applicability. Therefore, a detailed, fully-fledged safety case that leads to direct release cannot be provided. Consequently, the iterative data-based V-model is introduced to build on the generality of the classical V-model, bridging existing frameworks while simultaneously addressing the challenges of emerging systems and technologies in a sophisticated manner. Thereby, a particular emphasis is laid on cognitive cyber-physical systems of the real world that are safety critical to adress challenges of arising autonomous technologies.

\subsection{Fundamental Principles}
Adressing emerging autonomous technologies in a general manner highlights the criticality of a generic scneario-based approach \cite{riedmaier2020survey, elster2021fundamental, VVMOverall}, as corresponding database generation could be exhaustive and costly. Consequently, this would limit the suitability of the methodology towards solid technological applications that justify the efforts. Elsewise, a silent testing \cite{Tesla_shadow, templeton2019} approach for corresponding data acquisition, as scenario database equivalent, is also limited by the fact that dedicated systems and applications must already be operating on a large scale in the target environment. Beyond that, direct data collection in the real world might also be inappropriate, as it could lead to hazards and does not provide the necessary scale of datasets. As a consequence, the general methodology of the emerging autonomous systems is based on systematically generated data on a large scale through simulation. This observation is inline with the project series AI Family \cite{KIFamilie} that covers a range of sub-projects on AI assurance \cite{KIAbsicherungSynData}, transfer \& scaling \cite{KIDeltaSynData}, data tooling \cite{KIDataTooling}, and the hybridization of knowledge and data for automated driving applications \cite{KIWissen_D1_D4, KIWissen_D2}. Although the project series dealt with core topics such as the exploitation of simulation and real data, an overarching reference process has not been established. 

\subsection{General Methodology}\label{sec:methodo}
The proposed iterative data-based V-model builds on the VVM \cite{VVM} project by taking up the general V-model structure that is enhanced by a consistent alignment of the ODD along the V-stages. Beyond the application of automated driving, the ODD is interpreted as a generic concept that systematically defines the environment and context of the respective system. In addition, the iterative data-based V-model reflects Waymo's dynamic lifecycle approach \cite{favaro2023building}. In this way, the open world associated challenges as well as systematic gaps are addressed in a natural, iterative and continuous refinement manner. While the approach focuses on the product and provides guidance through the reference process, the chosen level of abstraction also allows for underlying process refinement along the safety argumentation. In addition, the iterative data-based V-model generalizes the scenario-based database approach. Furthermore, the iterative data-based V-model considers AI-specific development aspects and takes up ideas of the data engine \cite{karpathy_cvpr21} to increase efficiency. However, a central part remains a V\&V that is adapted to the challenge of the targeted use of simulation and the real world. Along a systematic consideration of the strengths of innovative frameworks while addressing existing limitations when applied to complex systems, as discussed in Section (\ref{sec:diff}). This results in an iterative data-based V-model, which is outlined in Figure \ref{fig:ours}. The individual aspects are described in more detail below. 

\textbf{Operational Design Domain:} The cycle initially starts with the definition of the ODD. Here, the ODD states an application independent foundation for defining the system's context, e.g. the environment and operating conditions. Besides that, the ODD represents the top-level target designation and belonging requirements specification. Moreover, the ODD provides guidance for the requirement definition of subordinate systems and functions. Thus, taking into account the system ODD independently of the granularity of the functionality or component to be developed ensures top-level aligment.

\textbf{Function-specific ODD:} Here, the specific functionality of the system, subsystem, or component to be developed is specified by means of a dedicated ODD. Thereby, following the top-down decomposition, the relevant top-level targets of the ODD are stringently broken down and transferred to the respective function-specific ODD. Moreover, specifics such as the desired behavior of the functionality that does not result directly from the top-level targets is included. Accordingly, the explicit function-specific ODD compactly defines the requirements specification while simultaneously minimizing specification uncertainties \cite{burton2023closing} through its alignment with the ODD.

\textbf{Data-specific ODD:} In this context, the previously outlined requirements specification is transfered into a data perspective. In this way, the data-specific ODD accounts for the fact that the availability, quality, and nature of the data can have a direct impact on how the system performs the task at hand. Thus, the definition of the data-specific ODD is responsible
for transforming the function-specific ODD requirements into the data-based representation. Making this transformation explicit within the framework should minimize the systematic gaps. In particular, the fact that development and V\&V are data-driven highlights the importance of a precise translation of the formally defined specifications and requirements into a data-specific representation.

\begin{figure*}[]
	\centering	
	\includegraphics[width=0.7\linewidth]{img/LRT_UL_X_3.png}
	\caption{The iterative data-based V-model, which formalizes and merges the various existing methods. The initial loop starts with the definition of the ODD. The explicit formalization of the process from the real world to simulation and back and the data-based characteristic address the challenges of complex systems that embrace AI. The iterative approach, on the other hand, addresses the challenges of open world complexity and offers continuous system and confidence improvement in an intuitive way.}
	\label{fig:ours}
\end{figure*} 

Consequently, the data-specific ODD, which is responsible for the syntactic transition into the data domain while preserving the semantics to meet required demands, constitutes an interface. In more detail, the data-specific ODD represents an handover area between system domain experts and funtion experts (e.g. AI experts), who use different terminologies (linguistic gap) and have different understanding (knowledge gap) due to different backgrounds (specialization gap). This entails the risk that the semantics of the requirements are not fully translated and usually leads to a specification gap. The framework aims to tackle and minimize this risk, which has already been described as specification uncertainties \cite{burton2023closing} that lead to specification insufficiencies \cite{burton2023addressing} and result in a semantic gap. The goal of the data-specific ODD is to enhance the efficiency and effectiveness of developing and ultimately safeguarding emerging complex systems that incorporate AI. This target-oriented addressing of the semantic gap can lead to overarching improved performance, reliability, and robustness.

\textbf{Architectural Design Domain / Data Design Domain:}  The two components of this stage address the transition to development. The architectural design domain defines a framework of possible architectures of the system to be developed on basis of the data-specific ODD. Thus, on the one hand, this step defines requirements for the architecture while on the other hand first assumptions of the design process that constitute from the data-specific ODD are made explicit. Thus, this stage represents a design abstrachtion layer for general descisions during the development and improvement processes.

In parallel, the definition of the data design domain transfers the requirements of the data-specific ODD into the requirements for
generating the data. However, the generation of data is not part of this stage. This deliberate separation of the definition of a design domain from the realization is an integral part of the framework and aims at the explicit separation, formulation, and documentation of requirements and assumptions while at the same time disclosing process related
uncertainties. In addition, this enables a decoupled validation of the design domains and the implementation via the continuous refinement process and indicates the need for action. For example, if deficiencies are identified during monitoring, it is possible to check whether the data design domain was valid and the problem arises from the incompleteness of the dataset in relation to it, or whether a refinement of the previous specifications and assumptions is necessary. 

\textbf{Architecture Definition / Sim. Dataset Generation:} This stage represents a deliberated engineering stage that focus on both the architecture setup as well as the simulation based data generation. The architectural definition selects a certain architectur within the corresponding architectural design domain and determines the specifics like parameters. 

The simulation data generation characterizes the systematic synthesis of data with respect to the data design domain. While the architecture selects a dedicated realization from the set of possible architectures, the creation of the dataset aims at completeness. In line with other frameworks like \cite{VVMOverall, favaro2023building, karpathy_cvpr21} and standards such as SOTIF \cite{iso21448}, the iterative data-based V-model refers to a complete coverage of the whole space by a sufficient decomposition through trigger constraints, yet in a data-based way. Moreover, the strategic generation of synthetic data offers the possibility of uncovering trigger conditions at an early stage and countering the challenge of "unknown unknowns". For example, logical inference based on existing trigger conditions can be used for this purpose.  

\textbf{System Development:}  This level represents the final implementation, which takes up and connects the previously decoupled paths of the architecture and data, and yields to a resulting system. Thereby, the system can consider individual dedicated (AI) models up to a system of systems, depending on the task. In addition, with regard to the overall process reference model, the system development phase completes the left leg of the V, which represents the design phase, and forms the intersection with the V\&V phase, the right leg of the V that is integral to the iterative data-based V-model.

\textbf{System Evaluation:} The first evaluation stage within the V\&V phase is represented by system evaluation. Here, the previously stipulated (functional) requirements are verified on the basis of the test split of the generated simulation data. Accordingly, this first evaluation stage can also be referred to as a virtual system testing. In more detail, this simulative performance evaluation is carried out using specified trigger conditions provided in terms of the dataset and assesses performance through corresponding indicators and acceptance criteria, which have to be derived from the individually customizable safety argumentation. 

\textbf{Real World Dataset Generation:} In this context, real-world data is generated. Data generation takes place in accordance with the data design domain. For safety reasons, the real world dataset represents a subset of the simulation dataset. Moreover, the effort in the real world can be limited for reasons of cost-effectiveness if this is permitted by the safety argument. As a consequence, the dedicated requirement for the scope of the real world dataset depends on the individual functionality to be developed and the corresponding safety argumentation and assurance. Therefore, a general specification cannot be provided by the process reference model.

\textbf{System Transfer:}  In order to counteract the gap between simulation and real world, the system transfer stage is introduced explicitly. The systems functionality can thus be adapted on the basis of the real data from the previous stage.

\textbf{Transfer Evaluation:} This second evaluation stage within the V\&V phase constitutes the transfer evaluation of the system. Here, the previously stipulated requirements are verified on the basis of the test split of the generated real world data. Consequently, this second evaluation stage can also be described as a simulation-based system test, which is carried out by means of real world data. The procedure as well as the performance indicators and acceptance criteria can be adopted from the first evaluation stage, the system evaluation, as the main difference is the changed origin of the data. Consequently, the desired functionality of the system and the associated quality and assessment criteria can be adopted.

\textbf{Open-Loop Evaluation (Silent Testing):}  This is the third evaluation stage, which marks the transition back to the real world. More precisely, the developed system is evaluated in the real world with the real input, whilst the system output is not applied in the real world. This open-loop evaluation thus represents a first step in the gradual return to the real world. In recent years, the open-loop evaluation has received increasing attention and can also be interpreted as silent testing \cite{wang2021online}, shadow mode, and virtual assessment of automation in field operation (VAAFO) \cite{wang2020reduction}.

\textbf{Closed-Loop Evaluation:} In the context of the fourth evaluation stage, the term closed-loop refers to the previous open-loop, which is now closed, meaning that the evaluation formalizes the system-based feedback into the real world. Here, the functionality is initially verified in the real world. Furthermore, this closed-loop evaluation phase is best viewed as a real world system test or, with regard to the application of automated driving, as a vehicle-in-the-loop (VIL). In the case of automated driving, this system evaluation can be carried out on the proving ground, for example. 

\textbf{Field Operation Evaluation:} The fifth and final evaluation phase is carried out in the real world on a larger scale than the previous one and aims to validate the system in the real world. It can be seen that V\&V, which was mostly considered jointly, is separate in the real world. While verification in the real world is possible on the proving ground, for example, validation requires further operation in the field. In principle, this kind of evaluation setting matches the consideration of on-the-road tests in automated driving applications.

\textbf{Deployment - System Operation \& Monitoring:} Once the system has successfully passed all evaluations, the acceptance criteria stipulated by the safety argumentation are fulfilled and the system can be depolyed. Continuous trust building arise in the course of system operation and ongoing monitoring. Furthermore, intelligent data harvesting can be performed during operation. In automated driving, for example, each individual vehicle can collect and select local data such that the cumulative gain can be used for subsequent refinement measures. 

\textbf{Detection of Deficiencies:} By means of the safety argumentation, corresponding acceptance criteria, and system specific performance indicators, deficiencies can be detected. If, e.g., an "unknown unknown" is detected at the overall level, which can have or has had catastrophic consequences, the approval of the systems must be withdrawn and the development and assurance process must cycled again from the beginning, taking into account the adapted requirements. While this is defined here in a structured way, we can see a very similar approach in practice today in the example of Cruise LCC in the USA, according to the incident of hitting a pedestrian \cite{equipmentrecallreport, NHTSARecall23E, NHTSARecallLetter}.

\textbf{Continuous Refinement:} In case of insufficencies, the overall loop is reinitiated by starting with a refinement of the ODD. A continuous transfer of the acquired findings back into the simulation and a step-by-step return to the real world is an integral part of the framework. Even in the long term, the use of synthetically generated data is targeted for safety, and efficiency reasons. In terms of trigger conditions, real world data might be limited to uncovered trigger conditions, while synthetic data allows the consideration of conceivable but unseen trigger conditions. Thus, the use of exclusively real data represents a subspace of imaginable trigger conditions and is therefore only effective in combination with synthetically augmented data. Accordingly, synthetic data can increase safety and efficiency in the development process. In general, moreover, the continuous refinement of the framework leverages the iterative nature of error analysis and specification adaptation, which increases safety and efficiency throughout the entire product lifecycle.

\textbf{Failure Handling:} Only the forward-looking transitions are indicated in Figure \ref{fig:ours}. Nevertheless, a large number of subordinate feedback flows are present, which have been omitted for the sake of clarity. Dealing with failed evaluations is of particular importance, which is why this is described in more general terms. 

On the one hand, an error can be caused by the design and realization of the functionality. On the other hand, it can be caused by gaps in the data used. Analyzing the error case can provide more information about the underlying cause. If an error case is caused by data and the data is within the data design domain, there is an error in the dataset generation. However, if the error case data is part of the data-specific ODD but not the data design domain, there is a gap in the specification of the data design domain. Otherwise, if the error case data is neither part of the data-specific ODD, the data-specific ODD definition itself must be adapted. An adaptation of a specification, e.g., the data-specific ODD or the data design domain, always requires stepping back to this level and revising the subsequent levels.

However, the functionality itself can also be the source of an error. If the selected function is within the architectural design domain, it is conceivable that the choice of architecture, although permissible, was not appropriate. If the realized functionality falls within the data-specific ODD but is not covered by the architectural design domain, the architectural design domain must be updated. If the function causes a behavior that does not correspond to the data-specific ODD but does correspond to the function-specific ODD, the data-specific ODD must be updated. Ultimately, gaps in the function-specific ODD can also lead to a subsequent error, which may require this specification to be updated. Furthermore, it is generally assumed that the assessments are conducted within the ODD. Otherwise, an ODD refinement is deemed to take place.

\textbf{Safety Argumentation Decoupling:} Along the process outlined above, the safety argumentation and safety assessment are customizable. While the VVM project \cite{VVMOverall} and Waymo's safety determination lifecycle \cite{favaro2023building} specify the absence of unreasonable risk in detail with respect to the system, this is omitted by the iterative data-based V-model, analogous to the classical V-model \cite{brohl1993v}. Nevertheless, it is evident that distinct evaluation stages throughout the V\&V process outlined above require the definition of acceptance criteria based on a system-specific safety argumentation. In this way, Waymo's case credibility assessment \cite{favaro2023building} is built-in by design, albeit with greater flexibility. This is due to the fact that the safety argumentation is not predefined. Therefore, to achieve the overall objectives, the framework enforces the creation, evaluation, and refinement of the safety argumentation. In particular, this customizability of the safety argumentation within the proposed framework implicitly leads to reasonableness, confidence, and coverage assessments along the interative refinement and the corresponding approval, similar to Waymo's case credibility assessment. Since the safety argumentation depends on the system as well as its environment and context, in other words specific on the ODD, and is also subject to application-specific standards and regulations, the safety argumentation is required to be decoupled and customizable to achive the desired generality of the methodology.


\subsection{Classification and Delimitation of the Methodology}\label{sec:classi}

The framework of the proposed iterative data-based V-model takes up existing further developments of the V-model \cite{VVMOverall} as well as innovative frameworks \cite{favaro2023building, karpathy_cvpr21} for handling complex systems. It addresses the characteristics of complex systems that integrate AI. This is illustrated by the use of data-based methods and the separate consideration of the architecture. In particular, complex systems are handled by means of dedicated stages and the formalized exploitation of simulation and real data. Central aspects from the AI Family project \cite{KIFamilie}, in particular the two sub-projects AI Delta Learning \cite{KIDeltaSynData} and AI Data Tooling \cite{KIDataTooling}, are thus taken up and formally integrated into an overall perspective. At the same time, the iterative data-based V-model offers the opportunity to take the results of the above-mentioned projects \cite{KIFamilie, KIDeltaSynData, KIDataTooling} into account. For instance, the stringent safety argumentation that was developed for a pedestrian detection AI \cite{KIAbsicherungSynMethoden, KIAbsicherungSynAbsicherung} can be considered. In addition, approaches for generating synthetic data \cite{KIAbsicherungSynData, KIDeltaSynData} can also be incorporated. This illustrates the generic and unifying character of the iterative data-based V-model framework. Moreover, the framework offers the possibility of using the emerging imaginative intelligence \cite{wang2024does, li2024sora} in the development process and is therefore also equipped for future developments.

Furthermore, the transition from a scenario-based approach to a general data-based approach opens up the broad applicability of the methodology. Additionally, the present approach enables scalability by the consideration of different levels of granularity of a system and, thus, also the system complexity. Thereby, the methodology addresses the architecture layer, the behavioral layer, as well as the in-service operational layer of Waymo \cite{karpathy_cvpr21} or the capability, engineering, and real world layer of the VVM project \cite{VVMAPerspectives}. Due to the claim of a generic framework and the necessity of individual performance measures and acceptance criteria, the framework does not claim to be a comprehensive framework for safety assessment and assurance. Nevertheless, Waymo's Case Credibility Assessment \cite{favaro2023building} approach is inherently integrated. This is due to the fact that the individual definition of the safety argumentation and thus the acceptance criteria and performance indicators require a suitability assessment, while the multiple assessments under increasingly realistic conditions require to address the coverage assessment. The iterative approach implies a process refinement within the structure defined by the framework. Hence, a native implementation of credibility \cite{koopman2019credible} can be envisioned. In particular, with increasing time and scale of the system, validation of the process and product takes place, thus addressing trust and credibility. This analysis of the proposed framework in relation to the improved V-model \cite{VVMOverall} of the VVM project, the safety determination lifecycle \cite{favaro2023building} of Waymo, and the data engine \cite{karpathy_cvpr21} of Tesla demonstrates that the iterative data-based V-model specifically combines the various methods and perspectives and formalizes them at the macro process level in order to maintain the generality of the classical V-model \cite{brohl1993v}.

While the framework does not explicitly address safety assessment and assurance, it opens up the possibility of data-driven functional safety assurance along with the potential to incorporate the results of current research from projects such as SUNRISE \cite{SUNRISE} and V4SAFETY \cite{V4SAFETY}. While allowing for statistical assurance of AI systems, the framework can also be applied to more traditional approaches. Ultimately, this leaves space for the use of different concepts. This is particularly important with regard to safety and explainability of AI systems, as research in this area is still raising open questions and different solutions are conceivable \cite{neto2022safety}. The future applicability of the process reference model is therefore addressed by the safety argumentation flexibility.

For an extended analysis of the iterative data-based V-model in relation to the previously analyzed process reference frameworks from Section \ref{02_New}, major characteristics are compared in Table \ref{tab:compare_frameworks}. Thereby, the advantages and disadvantages of the individual frameworks are illustrated in a compact and abstract manner while demonstrating that the iterative data-based V-model is able to unite the various frameworks except for the safety assessment, which is purposefully detached in accordance with the classical V-model. The individual criteria in Table \ref{tab:compare_frameworks} result from the analysis of the innovative development processes from Section \ref{02_New}, in particular from the discussion as well as the fundamental principles from Section \ref{03_Methodology}.

More specifically, the proposed framework extends the improved V-model specifically towards a continuous integration process that allows to respond to changes in the real world and address the open long-tail distribution challenge over time. Along with this standardization of the different frameworks, there is also a simplification. As discussed above, compared to VVM and Waymo, due to the chosen abstraction of the process, only one perspective is required to address different levels of system's granularity and complexity. Likewise, data-based processes, such as the one of Tesla's data engine, can be considered upfront, whilst a variety of system types, such as traditional or and mixed systems, can be considered in parallel. This is supplemented in Table \ref{tab:compare_frameworks}, which contains a more detailed assessment of the proposed framework in relation to previously investigated process reference frameworks. 

\newcommand\RotText[1]{\rotatebox{90}{\parbox{3.9cm}{\raggedright#1}}}

\begin{table}[]
	\centering
	\caption{Comparison of the previously analyzed process reference frameworks with the established iterative data-based V-model.}
	\begin{tabularx}{\linewidth}{l *{5}{>{\raggedright\arraybackslash}X}}
		\toprule
		& \RotText{Classical V-model} & \RotText{Improved V-model \quad \quad \quad \quad \quad  \tiny(VVM Project)} & \RotText{Safety Determination Lifecycle \tiny(Waymo)} & \RotText{Data Engine \quad \quad \quad \quad \quad \quad \quad \quad } & \RotText{Iterative data-based V-model \tiny(proposed)} \\
		\midrule
		Design phase & \cmark & \cmark & (\cmark) & \cmark & \cmark \\
		V\&V phase & \cmark & \cmark & \cmark & \cmark & \cmark \\
		Application independence & \cmark & \xmark & (\cmark) & (\cmark) & \cmark \\
		\midrule
		Generic across system granularities & \cmark & \xmark & \xmark & (\xmark) & \cmark \\
		Use of specific databases & \xmark & \cmark & (\cmark) & \cmark & \cmark \\
		Use of generic databases & \xmark & \xmark & (\xmark) & \xmark & \cmark \\
		Formalized simulation exploitation & \xmark & \xmark & \xmark & \xmark & \cmark \\
		\midrule
		Iterative product refinement & \xmark & \xmark & \cmark & \cmark & \cmark \\
		Iterative process refinement & \xmark & \xmark & \cmark & (\xmark) & (\cmark) \\
		Continuous trust building & \xmark & \xmark & \cmark & (\xmark) & \cmark \\
		\midrule
		System monitoring & \xmark & \xmark & \cmark & \cmark & \cmark \\
		Safety assessment (e.g. w.r.t. residual risk) & \xmark & \cmark & \cmark & \xmark & \xmark \\
		Safety argumentation customizability & \cmark & \xmark & \xmark & (\xmark) & \cmark \\
		\midrule
		Appropriate for traditional systems & \cmark & \cmark & \cmark & \xmark & \cmark \\
		Appropriate for AI systems & \xmark & (\cmark) & (\cmark) & \cmark & \cmark \\
		Appropriate for complex systems incl. AI & \xmark & (\cmark) & \cmark & (\cmark) & \cmark \\
		\midrule
		Overall generality and transferability & \cmark & (\xmark) & (\cmark) & (\cmark) & \cmark \\
		Overall suitability for emerging AI systems & \xmark & (\cmark) & (\cmark) & (\xmark) & \cmark \\
		\bottomrule
	\end{tabularx}%
	\label{tab:compare_frameworks}
\end{table}%

\subsection{Summary and Discussion of the Proposed Framework}

Consequently, it can be summarized that the iterative data-based V-model
\begin{itemize}
	\item represents a systematic update of the classical V-model,
	\item recognises the data-driven AI development and V\&V,
	\item generalizes across innovative development frameworks,
	\item thus formalizes a unifying process reference model.
\end{itemize}

Therefore, like the classical V-model, the iterative data-based V-model
\begin{itemize}
	\item decouples the process from specific safety assurance,
	\item unites multiple perspectives and approaches into a single,
	\item applies across different levels of system granularities,
	\item thus enables the desired generality and transferability.
\end{itemize}

In addition, the various advantages of the different innovative development processes are taken into account by the iterative data-based V-model, that 
\begin{itemize}
	\item considers system environment/context through the ODD,
	\item maps the open world in a managable (trigger) datasets,
	\item accounts for the prospective and retrospective view,
	\item enables iterative refinement throughout the lifecycle,
	\item thus harmonizes advantages of existing methodologies.
\end{itemize}

Furthermore, the data-based iterative V-model also addresses respective disadvantages of existing process reference models, as it
\begin{itemize}
	\item relaxes assumptions w.r.t. databases or hardware,
	\item formalizes the exploitation of simulation and real world,
	\item applies to traditional, AI-based, or mixed systems,
	\item represents an application-agnostic methodology,
	\item and overcomes limitations of existing frameworks.
\end{itemize}

The iterative data-based V-model harmonizes the respective advantages from Table \ref{tab:compare_frameworks_ad_disad} while counteracting the disadvantages from Table \ref{tab:compare_frameworks_ad_disad}. Thereby, the classical V-model is deliberately extended to the needs of complex systems incorporating AI. 

The proposed framework also has some implications. Particularly, while decoupling the framework from safety assessment and argumentation enables broad applicability, it does not inherently ensure the development of safe systems. Therefore, for safety-critical applications, individual safety assessments and arguments are necessary. However, the framework provides the desired flexibility and adaptability. Morover, among other things, the harmonization of different approaches has a specific implication on the formalization of the process, which is illustrated in Figure \ref{fig:ours}. This formalization explicitly addresses various data sources, from synthetic to real data. In particular, the systematic consideration of synthetic data facilitates the early uncovering of trigger conditions and counteracts the challenge of “unknown unknowns”. The framework thus enables greater efficiency and safety through the systematic consideration of synthetic data. Furthermore, the continuous refinement provided by the framework and thus the iterative nature of error analysis and specification adaptation throughout the entire product lifecycle ensures and increases safety.

Beyond that, the formalization also entails the separation in the depth of the design domain and design implementation as well as in the separation in the breadth of the architecture and the parameterizing data, in order to systematically close gaps in development phase. Overall, a unique feature of the framework is its ability to cover different types of systems, levels of granularity and complexity, and application areas from a unified perspective. The property to adapt to varying system levels and complexities is illustrated abstractly in the following.







