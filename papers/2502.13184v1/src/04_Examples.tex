\section{Sketch of Possible Applicatons of the Iterative Data-based V-model}\label{04_Examples}

In this section, the application of the proposed iterative data-based V-model is illustrated by means of automated driving at various levels of granularity, thus also the system's complexity. Thereby, the application illustration does not represent practical examples. Rather, the illustration serves as an academic explanation of the usability and possible practical application of the introduced process reference framework. Consequently, the focus is on the description of the process, i.e., how to proceed according to the process reference framework, and not on the result of a specific example. Moreover, a comprehensive description of a practical application would entail a detailed description of the system requirements, the database, etc., which would go way beyond the scope of this paper and impair clarity. As a result, this section concentrates on the application illustration of the process.

In this context, the generally described functionality and the usability across different system levels is sketched. The following Table \ref{tab:exampl_design} illustrates the design phase, while continued Table \ref{tab:exampl_VV} focuses on the V\&V phase of the iterative data-based V-model. These examples outlined in the Table \ref{tab:exampl_design} and continued part of Table \ref{tab:exampl_VV} provide high-level considerations and do not claim to be exhaustive. Rather, the purpose of these illustrations is to provide a clear and understandable intuition for the application of the methodology outlined in Section \ref{03_Methodology}. The application of automated driving within a highway operation ODD is used for this purpose. Subsequently, the levels considered comprise the overall system, here the automated driving (AD) stack, a dedicated subsystem of the overal system, namely the perception and the lidar detector component as one of the sensor components for automated driving.

On the one hand, this demonstrates how the framework can be applied at different levels of granularity. On the other hand, it illustrates that Waymo's layered approach \cite{webb2020waymo} and the multi-perspective approach \cite{VVMAPerspectives} of the VVM project are implicitly taken into account in an application-independent single-perspective methodology. This is reflected, for instance, in the closed-loop evaluation at the system and component level, which enables the identification of necessary improvements at the overall system level. Apart from this particular case, it can also be seen in general how, in addition to refinement within a system level, refinement is organized across different system levels.

\begin{table*}[p!]
	\centering
	\caption{Potential application of the Iterative Data-based V-model to Automated Driving Applications at different Levels of Granularity.}
	\begin{tabularx}{\linewidth}{p{3.6cm} *{3}{>{\raggedright\arraybackslash}X}}
		\toprule
		\diagbox[width=4cm, height=1.5cm]{\textbf{Stages}\\\textbf{of the iterative} \\ \textbf{data-based V-model}}{\textbf{Automated driving at}\\\textbf{different levels of}\\\textbf{granularity}} & \multicolumn{1}{c}{\textbf{AD Stack}} & \multicolumn{1}{c}{\textbf{Perception}}  & \multicolumn{1}{c}{\textbf{Lidar Detector}} \\
		\toprule
		\textbf{Operational Design Domain (ODD)} &
		\multicolumn{3}{>{\hsize=\dimexpr3\hsize+4\tabcolsep+\arrayrulewidth\relax}X}{ $\bullet$ German highways; $\bullet$ ego vehicle speed of up to 120 km/h; $\bullet$ other road users speed of up to 160 km/h; $\bullet$ from traffic jams to high-speed traffic; $\bullet$ varying traffic densities and weather conditions;}\\
		\midrule
		\textbf{Function-specific ODD} 
		& $\bullet$ requirement specification of sensing, planning and acting functionalities within the ODD; $\bullet$ maneuvers (overtaking, lane changing, merging, exiting) within the ODD and legal requirements; $\bullet$ different conditions (varying weather, traffic jams, emergency vehicles, pedestrians along the highway ODD);  
		& $\bullet$ object detection, classification and tracking within the ODD; $\bullet$ obstacle and lost cargo detection; $\bullet$ lane and free space detection; $\bullet$ detection and classification of traffic signs and traffic lights;
		& $\bullet$ object and free space detection within the ODD; \\
		\midrule
		\textbf{Data-specific ODD} 
		& $\bullet$ requires perception data with a range of at least 200 meters to the front and rear and 100 meters to the left and right; $\bullet$ vehicle state estimates (position in global coordinates, velocities, accelerations in the navigation coordinates, heading and yaw rate relative to the navigation coordinate system); $\bullet$ highway HD maps; $\bullet$ information processing at a rate of 10 Hz; 
		& $\bullet$ requires vehicle state estimation in standard signal rates and and characteristic signal noise; $\bullet$ provide an environment model for the region of interest in order to make informed behavioral decisions; $\bullet$ information processing at a rate of 10 Hz; 
		& $\bullet$ requires lidar raw data with characteristic signal noise and a range coverage of 150 meters; $\bullet$ provide object and free space detections at a rate of 10 Hz; \\
		\midrule
		\textbf{Architectural Design Domain} 
		&$\bullet$ domain of possible AD stack architectures (classic architectures with dedicated interfaces between individual submodules, architectures with orchestrators that take control of the interface, architectures that are fully end-to-end learned); 
		& $\bullet$ domain of possible perception architectures (permanent 360-degree perception, situation dependent perception); 
		& $\bullet$ domain of possible lidar detector architectures (range of deep neural network architectures); \\
		\midrule
		\textbf{Architecture Definition} 
		& $\bullet$ definition includes a specific instance from the range of possible architectures (e.g. an innovative architecture based on an orchestrator); $\bullet$ deployment plan on individual ECUs; 
		& $\bullet$ definition represents a specific case from the spectrum of possible architectures (e.g. situation dependent perception); $\bullet$ consideration of the use on individual ECUs; 
		& $\bullet$ definition determines the choice of  the deep neural network architecture within the given spectrum; $\bullet$ includes architecture-specific definitions (layers, activation functions, properties of the head, e.g., deterministic or probabilistic outputs);  \\
		\midrule
		\textbf{Data Design Domain} 
		& $\bullet$ defines general requirements for the creation of datasets both in simulation and the real world; $\bullet$ requires the generation of data according to the data-specific ODD; $\bullet$ covering different velocities, traffic densities, various times of day, and changing environmental conditions; $\bullet$ data from traffic jams, emergency situations, pedestrians within the ODD, corner cases (e.g. accidents, animals on the road); $\bullet$ defines train test split;
		& $\bullet$ demands the generation of sensor and state estimation data according to the data-specific ODD; $\bullet$ coverage of different velocities, traffic densities, different times of day, changing environmental conditions; $\bullet$ data from traffic jams, emergency situations, pedestrians within the ODD, corner cases; $\bullet$ defines train test split;
		& $\bullet$ specifies the sensor type, the field of view, the amount of layers and the mounting position to fulfill the data-specific ODD; $\bullet$ specifies lidar resolution, frame rate, and latency; $\bullet$ coverage of various environmental conditions (weather, traffic) within the ODD; $\bullet$ defines train test split;\\
		\midrule
		\textbf{Sim. Dataset Generation} 
		& $\bullet$ involves systematically generating simulation data considering, sensor specifics, vehicle dynamics, traffic simulation, scenario generation; $\bullet$ generates data with specific resolution, frame rate, and latency; $\bullet$ required to ensure the scenario coverage matches the requirements of the data design domain;
		& $\bullet$ generates simulation data by means of a simulation software considering, realistic objects, obstacles, lanes, free spaces and sensor models; $\bullet$ generates data with ground truth annotations, defined resolution, frame rate, and latency; $\bullet$ covers cases according to the requirements specification of the data design domain;
		& $\bullet$ generates data according to the data design domain with a specific scan frequency; $\bullet$ consideres physics of lidar sensors, including laser beam emission, reflection, and reception, to generate accurate point cloud representations; $\bullet$ accounts for sensor noise and environmental influences (fog, rain and blending);
		\\
		\midrule
		\textbf{System Development} 
		& $\bullet$ realization of the automated driving stack including various submodules with respect to the architecture definition; $\bullet$ use of the created simulation scenarios and corresponding data obtained from the sim. dataset generation;
		& $\bullet$ implementation and realization of the selected perception architecture; $\bullet$ use of the created simulation and corresponding data derived from the sim. dataset generation;
		& $\bullet$ parameterization and implementation of a selected lidar detector neural network according to the architecture definition; $\bullet$ training of the neural network using the data from the sim. dataset generation; \\
		\bottomrule	
	\end{tabularx}
	\label{tab:exampl_design}
\end{table*}


\begin{table*}[h!]
	\ContinuedFloat
	\centering
	\caption{Potential application of the Iterative Data-based V-model to Automated Driving Applications at different Levels of Granularity (continued).}
	\begin{tabularx}{\linewidth}{p{3.6cm} *{3}{>{\raggedright\arraybackslash}X}}
		\toprule
		\diagbox[width=4cm, height=1.5cm]{\textbf{Stages}\\\textbf{of the iterative} \\ \textbf{data-based V-model}}{\textbf{Automated driving at}\\\textbf{different levels of}\\\textbf{granularity}}&	\multicolumn{1}{c}{\textbf{AD Stack}} & \multicolumn{1}{c}{\textbf{Perception}}  & \multicolumn{1}{c}{\textbf{Lidar Detector}} \\
		\toprule
		\multirow{2}{*}{\textbf{System Evaluation}}
		& $\bullet$ performs evaluation on the test dataset split defined within the data design domain definition; $\bullet$ considers among others, functional testing of the realized automated driving stack, scenario testing, regulatrory compliance testing, etc.; 
		& $\bullet$ evaluates realized perception on the test dataset; $\bullet$ analysis of object detection accuracy on divers objects under various conditions; 
		& $\bullet$ evaluates object and free space detections under various ODD-specific circumstances; \\
		\cline{2-4}
		&\multicolumn{3}{>{\hsize=\dimexpr3\hsize+4\tabcolsep+\arrayrulewidth\relax}X}{
			$\bullet$ entails the simulative performance assessment based on performance indicators and acceptance criteria derived from the individual safety argumentation; $\bullet$ evaluates trigger conditions according to the specification of the data design domain and correspondingly generated data;
		} \\
		\midrule
		\textbf{Real World Dataset Generation} 
		& $\bullet$ gathering of relevant real world measurement data, vehicle dynamics characteristics, system latencies and actuator properties;
		& $\bullet$ collecting real raw sensor data required to create the environment model along specified real world state estimates;
		& $\bullet$ acquisition of real world data via a dedicated sensor module that meets the requirements; \\
		\cline{2-4}
			&\multicolumn{3}{>{\hsize=\dimexpr3\hsize+4\tabcolsep+\arrayrulewidth\relax}X}{ $\bullet$ generates data from the real world corresponding to the respective data design domain; $\bullet$ coverage of the data design domain is defined system dependant according to the individual safety argumentation that considers risks and costs of generating real world data, particularly with regard to corner cases and hazardous situations;
		} \\
		\midrule
		\textbf{System Transfer} 
		& $\bullet$ adjusting individual (sub-)modules of the automated driving stack and their interaction by means of acquired real-world data to compensate the gap between simulation and real world;
		& $\bullet$ specifics within the chosen perception architecture are adjusted using generated real world data; 
		& $\bullet$ parameterization of the lidar detector's neural network is adapted, e.g. by fine-tuning using real data;  \\
		\midrule
		\textbf{Transfer Evaluation}	
		& $\bullet$ performance assessment evaluation of adapted automated driving stack system using real data in alignment with the individual safety argumentation as in the previous evaluation; 
		& $\bullet$ evaluation of the performance of object detection, classification, tracking, obstacle detection, lost cargo detection etc. using the respective real world test dataset split; & $\bullet$ evaluation of the performance of the lidar detector based on the test split of the generated real data; \\
		\midrule
		\textbf{Open-Loop Evaluation (Silent Testing)} 
		& $\bullet$ evaluation of sensing, planning, acting and interactions of functionalities on real hardware in the real world in partial separation to prevent deployment in the real world while still being able to evaluate the capabilities of the AD stack;
		& $\bullet$ evaluation of the perception systems object detection, classification, tracking etc. in the real world without feeding the output back into the overall system;
		& $\bullet$ evaluation of the lidar detector in the real world without further use of the output in other functionalities; \\
		\midrule
		\textbf{Closed-Loop Evaluation} 
		& $\bullet$ evaluation of sensing, planning, acting functionalities on real hardware in the real world in full functional interplay and sytem's interaction with the real world; $\bullet$ limited to operations within the proving ground; 
		&\multicolumn{2}{>{\hsize=\dimexpr2\hsize+3\tabcolsep+\arrayrulewidth\relax}X}{
			$\bullet$ evaluation is limited to operation within the proving ground; $\bullet$ perception and lidar detection, unlike planning, is usually open-loop and therefore should not lead to changes; $\bullet$ if this closed-loop evaluation differs from the open-loop evaluation from the previous step, it indicates that related components within the automated vehicle stack need to be refined;
		} \\
		\midrule
		\textbf{Field Operation Evaluation} &\multicolumn{3}{>{\hsize=\dimexpr3\hsize+4\tabcolsep+\arrayrulewidth\relax}X}{ $\bullet$ previous restriction to the proving ground is removed; $\bullet$ performance assessment takes place in field operation within the ODD; $\bullet$ enables a broader coverage of possible test scenarios and influences; 
		} \\
		\midrule
		\textbf{Deployment - System Operation \& Monitoring} &	\multicolumn{3}{>{\hsize=\dimexpr3\hsize+4\tabcolsep+\arrayrulewidth\relax}X}{ $\bullet$ with increasing time and scale of use, continuous trust builds up in the system; $\bullet$ continuous observation and analysis of system performance; $\bullet$ conducting intelligent data harvesting during operation; 
		} \\
		\midrule
		\textbf{Detection of Deficiencies} &	\multicolumn{3}{>{\hsize=\dimexpr3\hsize+4\tabcolsep+\arrayrulewidth\relax}X}{ $\bullet$ detection of deficiencies on the basis of a strong link between system observation and safety argument \& acceptance criteria based identification; $\bullet$ uncovering of "unknown unknowns"; $\bullet$ withdrawal of approval, if necessary; $\bullet$ design and V\&V cycle reinitiation 
		} \\
		\midrule
		\textbf{Continious Refinement} &	\multicolumn{3}{>{\hsize=\dimexpr3\hsize+4\tabcolsep+\arrayrulewidth\relax}X}{ $\bullet$ deficiencies uncovered during operation are fed back into the process and the product via a new overall cycle; $\bullet$ findings are transferred to the simulation, the product is refined and gradually reintroduced into the real world; $\bullet$ exploits the safety and efficiency-related benefits of simulation; $\bullet$ ensures uniform safety standards in every development and improvement cycle;
		} \\
		\bottomrule	\end{tabularx}
	\label{tab:exampl_VV}
\end{table*}



