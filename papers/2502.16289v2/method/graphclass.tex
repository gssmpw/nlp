\subsection{Graph-based Classification} \label{sec:graphclass}

As noted by \citet{campsvalls2007}, many graph-based algorithms involve computing and manipulating large kernel matrices that include both labeled and unlabeled data. For an image with \( n \) pixels, the corresponding graph Laplacian matrix has a size of \( n \times n \), and its inversion via singular value decomposition has a computational complexity of \( O(n^3) \), making it impractical for large-scale applications. To mitigate this issue, instead of representing each pixel as a graph node, we use superpixels as nodes, significantly reducing the node count since \( K \ll n \). This approach allows efficient matrix operations without requiring approximations while also improving classification accuracy by defining meaningful local regions within the data.

Using the extracted features and the superpixel-based node set, we construct a weighted, undirected graph \( G = (V, E, W) \). The edge weight between adjacent superpixels \( S_i \) and \( S_j \) is defined using two Gaussian kernels:  
\begin{equation} \label{equ:graph_weight}
    w_{ij} = s_{ij}l_{ij},
\end{equation}  
where the individual components are given by:  
\begin{equation} \label{equ:sigma_s}
    s_{ij} = \exp\left(\frac{(\beta-1)\|\overline{S}_i^w - \overline{S}_j^w\|_2^2 - \beta\|\overline{S}_i^m - \overline{S}_j^m\|_2^2}{\sigma_s^2}\right),
\end{equation}  
\begin{equation} \label{equ:sigma_l}
    l_{ij} = \exp\left(\frac{-\|\overline{S}_i^p - \overline{S}_j^p\|_2^2}{\sigma_l^2}\right),
\end{equation}  
where \( \beta \) controls the balance between mean and weighted feature contributions, while \( \sigma_s \) and \( \sigma_l \) define the widths of the Gaussian kernels. The resulting weights range between 0 and 1, where a value of 1 indicates maximum similarity. The graph edges are determined using a \( k \)-nearest neighbors (KNN) approach, with edge weights defined as:  
\begin{equation} \label{equ:knn_graph}
    W_{ij} = \begin{cases}
    w_{ij}, & \text{if } i \text{ is one of the } k \text{ nearest neighbors of } j, \\
    & \text{or vice versa}, \\
    0,       & \text{otherwise}.
    \end{cases}
\end{equation}  

During training, a subset of labeled spectral pixels is randomly selected from the original hyperspectral image. The initial label of each superpixel is assigned as the average of the labels of its constituent pixels. If no labeled pixels exist within a superpixel, it remains unassigned initially. The label information is stored in a matrix \( Y \in \mathbb{R}^{K \times c} \), where \( c \) is the number of classes and \( K \) is the total number of superpixels. The entry \( Y_{vl} \) represents the seed label \( l \) for node \( v \). 

The weight matrix and initial labels are then processed using the Local and Global Consistency (LGC) algorithm \citep{zhou2004lgc}, a graph-based semi-supervised learning method that enforces smoothness over the graph structure by minimizing a cost function. The final label matrix \( F \in \mathbb{R}^{K \times c} \) is obtained by minimizing:  
\begin{equation} \label{equ:lcg_loss}
    Q(F) = \frac{1}{2} \sum_{i,j=1}^n W_{ij} \left\|\frac{F_i}{\sqrt{D_{ii}}} - \frac{F_j}{\sqrt{D_{jj}}}\right\|^2 + \frac{\mu}{2} \sum_{i=1}^n \sum_{c=1}^C -y_{ic} \log f_{ic},
\end{equation}  
where \( F^* = \arg\min Q(F) \) represents the optimal label assignment.

\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{method/images/mgn_embeddings_with_edges.pdf}
    \caption{Graph construction visualization for the INDIAN dataset, with node placement based on TSNE embeddings of node features and node labels from GCN inference.}
    \label{fig:indian_graph}
\end{figure*}

