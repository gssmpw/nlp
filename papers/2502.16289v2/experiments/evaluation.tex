\subsection{Evaluation Procotol} \label{sec:evaluation}

Our implementation is done with PyTorch Geometric \citep{pytorch} \citep{pytorchgeometric}, and is available at \url{https://github.com/HySonLab/MultiscaleHSI}. We use the MGN implementation proposed by \cite{hy2019covariant}, with the GCN implementation by \citep{pytorchgeometric}. All experiments were carried out on Google Collaboration, using its T4 GPU with 15 GB of VRAM for hardware acceleration. The environment also featured a dual-core Intel Xeon CPU @ 2.20GHz and 12.72 GB of available system RAM, offering sufficient resources for efficient training and evaluation.

For all experiments, each MOB-GCN model was trained 10 times, and the mean and standard deviation of the results are reported. The optimal number of principal components for the model was selected to retain 99.9\% of the variance in the original image. The performance of each HSI classifier was assessed using three standard evaluation metrics: \textbf{Overall Accuracy (OA)}, \textbf{Average Accuracy (AA)}, and the \textbf{Kappa Coefficient (KA)}.

Our study focuses on answering whether multiscale learning improves learning performance for graph-based hyperspectral classification, so we only validate and compare between a single-scale GCN (with 2 convolution layers, proposed by \citep{kipf2016} and implemented by Pytorch Geometric \cite{pytorchgeometric}), and a multiresolutional graph neural network model, proposed by \citep{Hy_2023}. In addition, we discuss the implications and improvements of our MOB-GCN approach in classifying hyperspectral images.