

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Generalized Approximate Message Passing algorithms}\label{app:sec:gamps}
In this section we present a general version of the multi-dimensional Generalized Approximate Message Passing (GAMP) algorithm \cite{rangan2011generalized}, defined as the iterations
\begin{align}\label{app:def:eq:GAMP_Omega}
    \bOmega^t &= \rdmmat{X} \boldf_{in}^t(\mat{B}^t) - \gout^{t-1}(\bOmega^{t-1},\by)\bV^T_t,\\\label{app:def:eq:GAMP_B}
    \mat{B}^{t+1} &= \rdmmat{X}^T\gout^t(\bOmega^{t},\by) - \boldf_{in}^t(\mat{B}^t)\bA^T_t
\end{align}
and $\matwhat^{t+1} = \boldf_{in}^{t+1}(\mat{B}^{t+1})$.
The {\it denoiser} functions $\boldf_{in}^t:\R^{p}\to\R^{p}$ and $\gout^t:\R^{p}\times\R\to\R^{p}$ are vector-valued mappings acting row-wise respectively on $\vect{b}_j\in\R^p=\mat{B}_{j.}$ and $\bomega_i\in\R^p = \bOmega_{i.}$ and the {\it Onsager terms} are given by
\begin{equation}
    \bA_t = \frac{1}{d}\sum_{i=1}^n \grad_{\bomega_i}\gout^t(\bomega_i,y_i),\quad\quad\bV_t = \frac{1}{d}\sum_{j=1}^d \grad_{\vect{b}_j}\boldf_{in}^t(\vect{b}_j). 
\end{equation}
Therefore, the algorithm is uniquely determined by the choice of denoisers. For instance, the optimal GAMP for Gaussian multi-index models, derived in \cite{aubin2018committee}, is given by 
\begin{equation}\label{app:def:optimal_gamp}
    \gout^t(\bomega, y) = \bV_t^{-1}\E_{\rdmvect{z}\sim\ndist(\bomega,\bV_t)}[(\rdmvect{z}-\bomega)\mathsf{P}(y|\rdmvect{z})],\quad\quad\boldf_{in}^t(\vect{b}) = \left(\bI_p - \frac{1}{d}\sum_{i=1}^n\grad_{\bomega_i}\bg^t_{\rm out}(\bomega_i^t,y_i)\right)^{-1}\vect{b},
\end{equation}
\subsection{Linear GAMP}\label{app:sec:linear_GAMP}
In this manuscript we focus on a special type of GAMP algorithms that have linear denoiser functions
\begin{equation}
    \gout^t(\bomega,y)=\mat{G}^t(y)\bomega,\quad\boldf_{in}^t(\bb) = \bV^t\bb,
\end{equation}
namely
\begin{align}\label{app:eq:linear_AMP_Omega}
    \bOmega^t &= \rdmmat{X}\matwhat^t - \tens{G}^{t-1}\cdot\bOmega^{t-1}\bV^T_t,\\\label{app:eq:linear_AMP_W}
    \matwhat^{t+1} &= \left(\rdmmat{X}^T\tens{G}\cdot\bOmega^t - \matwhat^t\bA_t^T\right)\bV_{t+1}^T, 
\end{align}
where $G_{ikjh} = \delta_{ij}[\mat{G}(y_i)]_{kh}$ and 
\begin{equation}
    \bA = d^{-1}\sum_{i\in\integset{n}}\mat{G}(y_i)\xrightarrow{n,d\to\infty} \alpha \E_{\rdm{y}\sim\Zout}[\mat{G}(\rdm{y})].
\end{equation}
A particular example of Linear GAMP is the one obtained linearizing the denoiser functions (\ref{app:def:optimal_gamp}) around the uninformed fixed point of the algorithm $\bb =  0$, $\bomega = \bzero$ and $\bV = \bI$. We obtain a Linear GAMP with 
\begin{equation}
    \mat{G}(y) = \Cov[\rdmvect{z}\big|y]-\bI,\quad \bV = \bI
\end{equation}
and 
\begin{equation}\label{app:eq:A_zero}
    \bA = \alpha \E_{\rdm{y}\sim\Zout}[\dgout(\rdm{y})] =
    \alpha\E_{\rdm{y}\sim\Py}\E[\rdmvect{z}\rdmvect{z}^T\big|\rdm{y}] - \alpha\bI =\alpha\E_{\rdmvect{z}\sim\ndist(\bzero,\bI)}[\rdmvect{z}\rdmvect{z}^T] -\alpha\bI = \bzero. 
\end{equation}
\subsection{State Evolution of Linear GAMP}\label{app:sec:SE_LGAMP}
One of the main advantages provided by the Approximate Message Passing algorithm is the possibility to track the value of low-dimensional functions of the iterates at all finite times, in the high-dimensional limit, through a set of iterative equations denoted as \textit{state evolution} \cite{javanmard2013state}. In particular, we are interested to the following overlap matrices
\begin{equation}\label{eq:app:def:overlaps_amp}
    \mat{M}^t \coloneqq \frac{1}{d}\left(\matwhat^t\right)^T\bW_\star,\quad\mat{Q}^t\coloneqq \frac{1}{d}\left(\matwhat^t\right)^T\matwhat^t,
\end{equation}
that characterize respectively the alignment between $\matwhat^t$ and the weights $\mat{W}_\star$ and the norm of $\matwhat^t$. In this appendix we present the state evolution equations for the GAMP algorithm (\ref{app:eq:linear_AMP_Omega}, \ref{app:eq:linear_AMP_W}) with linear denoiser functions, while we refer to \cite{aubin2018committee} for a complete derivation in more general settings:
\begin{equation}
    \bM^{t+1} = \bV_t\hat{\bM}^t,\quad\quad
    \bQ^{t+1} = \bV_t\left(\hat{\bM}^t(\hat{\bM}^t)^T + \hat{\bQ}^t\right)\bV_t^T,
\end{equation}
with the auxiliary matrices given by
\begin{align}
    \hat{\bM}^t &= \alpha \E_{\rdm{y}\sim\Zout}\left[\mat{G}(\rdm{y})\bM^t(\Cov[\rdmvect{z}|y]-\bI)\right],\\
    \hat{\bQ}^t &= \alpha \left(\E_{\rdm{y}\sim\Zout}\left[\mat{G}(\rdm{y})\bM^t(\Cov[\rdmvect{z}|y]-\bI)\bM^T\mat{G}(\rdm{y})^T\right] + \E_{\rdm{y}\sim\Zout}\left[\mat{G}(\rdm{y})\bQ^t\mat{G}(\rdm{y})^T\right]\right).
\end{align}
\section{Derivation of the main results - Asymmetric spectral method}\label{app:derivation_asymmetric}
Consider the following generalized power iteration algorithm
\begin{align}\label{app:eq:sp_gamp}
    \bOmega^{t} &= \gamma^{-1}\tens{L}\cdot\bOmega^{t-1},\\
    \matwhat^{t+1} &= \gamma^{-1}\rdmmat{X}^T\tens{G}\cdot\bOmega^t,
\end{align}
with $\tens{G}$ defined in eq. (\ref{eq:def:tensor_G}).
Given the principal eigenpair $\gamma_1,\bOmega_1$ of $\tens{L}$, the spectral estimator defined in Definition \ref{eq:def:spectral_asymmetric} is a fixed point of this algorithm for $\gamma = \gamma_1$ and $\bOmega \propto\bOmega_1 \frac{\gamma_1\sqrt{d}}{||\rdmmat{X}^T\tens{G}\cdot\bOmega_1||}$. Interestingly, the above algorithm is a linear GAMP, with denoiser functions $\gout^t(\bomega, y) = (\Cov[\rdmvect{z}|y]-\bI)\bomega$ and $\boldf_{in}^t(\vect{b}) = \gamma^{-1}\vect{b}$, $\forall t$, and Onsager terms
\begin{align}
    \bA_t \xrightarrow{n\to\infty}&\alpha\E_{\rdm{y}\sim\Zout}\E[\rdmvect{z}\rdmvect{z}^T\big|\rdm{y}] - \alpha\bI = \bzero,
\end{align}
as already shown in (\ref{app:eq:A_zero}), and $\bV_t = \gamma^{-1}\bI$. In fact, we can rewrite the generalized power iteration algorithm as
\begin{align}
    \bOmega^{t} &= \gamma^{-1}(\rdmmat{X}\rdmmat{X}^T-\bI_n)\tens{G}\cdot\bOmega^{t-1} = \rdmmat{X}(\gamma^{-1}\mat{B}^t) - \gamma^{-1}\tens{G}\cdot\bOmega^{t-1},\\
    \mat{B}^{t+1} &= \rdmmat{X}^T\tens{G}\cdot\bOmega^t,\\
    \matwhat^{t+1} &= \gamma^{-1}\mat{B}^{t+1}.
\end{align}
This algorithm does not offer any particular advantage for the practical computation of the spectral estimator compared to other algorithms for estimating the principal eigenvector. However, as an Approximate Message Passing algorithm, it enables to track low-dimensional functions of the iterate $\matwhat^t$ via the associated state evolution. Specifically, we will analyze the weak recovery properties of the spectral method by studying the convergence of the state evolution equations

\begin{align}\label{app:eq:se_sp_gamp_M}
    \mat{M}^{t+1} &= \frac{\alpha}{\gamma}\cF(\mat{M}^t)\\
    \mat{Q}^{t+1} &= \mat{M}^t(\mat{M}^t)^T + \frac{\alpha}{\gamma^2}\left(\cG(\mat{M}^t) + \cF(\mat{Q}^{t}) \right) \label{app:eq:se_sp_gamp_Q}
\end{align}
where
\begin{align}\label{app:eq:def:operator_F}\cF(\mat{M}) &\coloneqq \E_{y}[(\Cov[\rdmvect{z}\big|y]-\bI)\mat{M} (\Cov[\rdmvect{z}\big|y]-\bI)],\\
\cG(\mat{M}) &\coloneqq \E_{y}[(\Cov[\rdmvect{z}\big|y]-\bI)\mat{M} (\Cov[\rdmvect{z}\big|y]-\bI)\mat{M}^T (\Cov[\rdmvect{z}\big|y]-\bI)].
\end{align}
The linear operator $\cF:\R^{p\times p}\to\R^{p \times p}$ is symmetric, therefore it admits $p^2$ eigenpairs $(\nu_k\in\R,\mat{M}_k)_{k\in[p^2]}$ such that $\cF(\mat{M}_k)=\nu_k\mat{M}_k$ and the (matrix) eigenvectors are an orthonormal basis of $\R^{p\times p}$. In particular, Lemma \ref{lemma:critical_sample_complexity} implies that $\nu_1 \coloneqq \max_{k}\nu_k > 0$ and $\mat{M}_1\in\mathbb{S}^p_+$. This eigenvalue corresponds to the inverse of the critical sample complexity $\alpha_c$, defined in \ref{def:critical_alpha}.
We can distinguish between two kind of fixed points:
\begin{enumerate}
    \item {\bf Informed fixed points.} For $\gamma = \alpha \nu_k$ ($\nu_k\neq 0$), $\mat{M}\propto\mat{M}_k$, is a non-zero fixed point for eq. (\ref{app:eq:se_sp_gamp_M}).
    In particular, we are interested to the fixed point correspondent to the largest $\gamma$, {\it i.e.} $\bM\propto\bM_1$. For $\alpha > \alpha_c$ and $\gamma = \nicefrac{\alpha}{\alpha_c} > 1$, the largest eigenvalue of $\alpha\cF(\cdot)$ is equal to one and any $\bM\propto\bM_1$ is a stable fixed point. Moreover, eq. (\ref{app:eq:se_sp_gamp_Q}) at convergence:
    \begin{align}
        &\mat{Q} = \mat{M}^2 + \frac{\alpha_c^2}{\alpha} (m^2\cG(\mat{M}) + \cF(\mat{Q})) \implies\\
        &\Tr(\mat{Q}) = \normf{\mat{M}}^2\left( 1 +  \frac{\alpha_c^2}{\alpha} \underbrace{\Tr\left(\cG\left(\frac{\mat{M}}{\normf{\mat{M}}}\right)\right)}_{\geq 0}\right)+ \frac{\alpha_c^2}{\alpha} \underbrace{\Tr(\cF(\mat{Q}))}_{\leq \nu_{1}\Tr(\mat{Q})} \implies \label{app:eq:Q_trace_fixed_point}\\
        &\normf{\mat{M}}^2 \geq \left(1 - \frac{\alpha_c}{\alpha}\right)\Tr(\mat{Q})\left( 1 +  \frac{\alpha_c^2}{\alpha} {\Tr\left(\cG\left(\frac{\mat{M}}{\normf{\mat{M}}}\right)\right)}\right)^{-1} > 0,
    \end{align}
    where in eq. (\ref{app:eq:Q_trace_fixed_point}) we used
    \begin{equation}
        \Tr\cF\left(\bQ=\sum_{k\in\integset{p^2}}c_k\bM_k\right) = \Tr\sum_{k\in\integset{p^2}}c_k\nu_k\bM_k\leq \nu_1 \Tr \bQ. 
    \end{equation}
    Therefore, the correspondent estimator weakly recovers $\mat{W}_\star$.
    \item {\bf Uninformed fixed point.} Initializing GAMP in a subspace orthogonal to the signal, {\it i.e.} $\mat{M}^0 = \bzero$,
    \begin{equation}
        \mat{Q} = \gamma^{-2}\alpha\cF(\mat{Q}),
    \end{equation}
    therefore, for $\gamma = \sqrt{\alpha\nu_1}$, $\mat{M} = \bzero$, $\mat{Q} = \mat{M}_1\in\mathbb{S}_+^p \setminus \{\bzero\}$ is a fixed point of the state evolution. Note that, since the largest eigenvalue of $\alpha\cF(\cdot)$ is larger than one, such fixed point is unstable. Since the proposed GAMP is equivalent to a generalized power iteration algorithm, normalized by the constant $\gamma\in\R$, it converges only if $\gamma$ corresponds to the absolute value of the eigenvalue with largest magnitude in the subspace of initialization.
\end{enumerate}
\section{Derivation of the main results - Symmetric spectral method}\label{app:derivation_simmetric}
Similarly to what we have done in the previous section, we introduce a GAMP algorithm that will serve as a framework to study the properties of the spectral estimator defined in (\ref{eq:def:spectral_symmetric}).
\begin{definition}
    Consider the Generalized Approximate Message Passing algorithm defined by the denoiser functions
    \begin{equation}
        \gout^t(\rdm{y},\bomega) = \bcT(y)\bV_t^T(a_t\bI - \bV_t\bcT(y)\bV_t^T)^{-1}\bomega,\quad\quad\boldf_{in}^t(\bb) = (\gamma_t\bV_t^T-\bA_t)^{-1}\bb,
    \end{equation}
    where $\bcT(y)$ is the preprocessing function defined in (\ref{eq:def:preprocessing}) and $a_t$, $\gamma_t$ parameters to be fixed.
\end{definition}
Dropping the time index for the fixed-point variables and parameters, and defining $\tens{T}_{\bV}$ as
\begin{align}
\tens{T}_{\bV}\cdot\bOmega &= \bV\tens{T}\cdot\bOmega,
\end{align}
the fixed points satisfy
\begin{align}
    &\bOmega = \mat{X}\matwhat - \tens{T}_{\bV}\cdot\bOmega\implies\bOmega = \left(\tens{I}+\tens{T}_{\bV}\right)^{-1}\cdot(\mat{X}\matwhat),\\
    &\matwhat(\gamma_t\bV-\bA^T) = \rdmmat{X}X^T \tens{T}\cdot\left(\left(\tens{I}+\tens{T}_{\bV}\right)^{-1}\cdot(\rdmmat{X}\matwhat)\right) - \matwhat\bA^T\implies a\gamma_t\matwhat\bV = \tens{T}\cdot(\matwhat\bV),
\end{align}
where we used
\begin{align}           
    [\tens{T}\cdot(\left(\tens{I}+\tens{T}_{\bV}\right)^{-1}\cdot\bOmega)]_{i.} &= \bcT(y)\bV^T(a\bI - \bV\bcT(y)\bV^T)^{-1}[\left(\tens{I}+\tens{T}_{\bV}\right)^{-1}\bOmega]_{i.}\\
    &= \bcT(y)\bV^T(a\bI - \bV\bcT(y)\bV^T)^{-1} \left(\bI + \bV\bcT(y)\bV^T(a\bI - \bV\bcT(y)\bV^T)^{-1}\right)^{-1}\bOmega_{i.}\\
    &=\bcT(y)\bV^T\left(a\bI - \bV\bcT(y)\bV^T+\bV\bcT(y)\bV^T\right)^{-1}\bOmega_{i.}\\
    &= a^{-1}\bcT(y)\bV^T\bOmega_{i.}
\end{align}
Therefore, $\matwhat = \matwhat_{\tens{T}}\bV^{-1}$ is a fixed point of the algorithm, for $a_t$ and $\gamma_t$ appropriately chosen, with eigenvalue given by $a_t\gamma_t$ at convergence.\footnote{Note that the overlap matrices for this algorithm refer to $\matwhat_{\tens{T}}\bV^{-1}$ and not directly to the spectral estimator itself. However, if $\normf{\bM} > 0$, the weak recovery condition is satisfied.}
\subsection{State Evolution}\label{app:symmetric_state_evolution}
The state evolution equations of the overlap matrices are
\begin{align}
        \bM^{t+1} &= \alpha\cF(\bM^t;a_t,\bV_t)\\
        \bQ^{t+1} &= \bM^t(\bM^t)^T + \alpha (\cG(\bM^t;a_t,\bV_t) + \Tilde{\cF}(\bQ^t;a_t,\bV_t)) \\
        \bV_{t+1} &= (\gamma_t\bV_t^T - \bA_t)^{-1},\\
        \bA_t &= \alpha \E_{\rdm{y}\sim \Py(\rdm{y})}\left[\bcT(\rdm{y})\bV_t^{T}(a_t -\bV_t\bcT(\rdm{y}) \bV^T_t)^{-1}\right]
\end{align}
with
\begin{align}
    \cF(\bM;a,\bV) &\coloneqq\E_{\rdm{y}\sim \Py}\left[\bV\bcT(\rdm{y})\bV^{T}(a-\bV\bcT(\rdm{y}) \bV^T)^{-1}\bM(\Cov[\rdmvect{z}|y]-\bI)\right] ,
    \\ \label{app:eq:def:tilde_cF}
    \Tilde{\cF}(\bQ;a,\bV) &\coloneqq \E_{\rdm{y}\sim \Py}\left[\bV\bcT(\rdm{y})\bV^{T}(a-\bV\bcT(\rdm{y}) \bV^T)^{-1}\bQ(a-\bV\bcT(\rdm{y}) \bV^T)^{-1}\bV\bcT(\rdm{y})\bV^T\right] \\\label{app:eq:def:G_operator}
    \cG(\bM;a,\bV) &\coloneqq   \E_{\rdm{y}\sim \Py}\left[\bV\bcT(\rdm{y})\bV^{T}(a-\bV\bcT(\rdm{y}) \bV^T)^{-1}\bM(\Cov[\rdmvect{z}|y]-\bI)\bM^T(a-\bV\bcT(\rdm{y}) \bV^T)^{-1}\bV\bcT(\rdm{y})\bV^T\right].
\end{align}
Note that $\cF(\:\cdot\;;a,\bV)$ is a symmetric linear operator on the space of $p\times p$ matrices, with respect to the inner product $\langle\bM,\bM'\rangle\coloneqq\Tr(\bM^T\bM')$:
\begin{align}
    \langle\cF(\bM; a, \bV),\bM'\rangle &= \E_{\rdm{y}\sim \Py}\Tr\left[(\Cov[\rdmvect{z}|y]-\bI)\bM^T(a-\bV\bcT(\rdm{y}) \bV^T)^{-1}\bV\bcT(\rdm{y})\bV^{T} \bM'\right] \\
    &= \E_{\rdm{y}\sim \Py}\Tr\left[(a-\bV\bcT(\rdm{y}) \bV^T)^{-1}\bV\bcT(\rdm{y})\bV^{T} \bM'(\Cov[\rdmvect{z}|y]-\bI)\bM^T\right] \\
    &= \Tr \E_{\rdm{y}\sim \Py}\left[\bV\bcT(\rdm{y})\bV^{T} (a-\bV\bcT(\rdm{y}) \bV^T)^{-1}\bM'(\Cov[\rdmvect{z}|y]-\bI)\bM^T\right] \\
    &=\langle\cF(\bM'; a,\bV),\bM\rangle.
\end{align}
This implies that, for $a,\bV$ fixed, $\cF(\:\cdot\;;a,\bV)$ has $p^2$ real eigenvalues $\{\nu_k(a,\bV)\}_{k\in\integset{p^2}}$ and admits an orthonormal basis $\{\bM_k(a,\bV)\}_{k\in\integset{p^2}}$ of eigenvectors in $\R^{p\times p}$. Moreover, note that from the state evolution iterations, we can verify that $\bV_t = \bV_t^T \implies \bV_{t+1} = \bV_{t+1}^T$, therefore, we consider the matrix $\bV_t$ to be symmetric at all times. From the state evolution equations at convergence
\begin{equation}
    \bV = \sqrt{\gamma^{-1}}\left(\bI + \alpha \E_{\rdm{y}\sim\Zout}\left[\bV\bcT(\rdm{y})\bV\left(a - \bV\bcT(\rdm{y})\bV\right)^{-1}\right]\right)^{\nicefrac{1}{2}}\implies \bV\succ \bzero.
\end{equation}
Furthermore, in order to bound the operator norm of $\bV$, we choose $\gamma_t$ such that $\normop{\bV_{t+1}} = 1$.\\
We can distinguish the following cases:
\begin{itemize}
    \item \textbf{Informed fixed points.} Choosing $a_t$ such that 
    \begin{equation}        
    \max\left\{\lim_{t\to\infty}\nu_k(a_t,\bV_t):k\in\integset{p^2}\right\} = \alpha^{-1},
    \end{equation}
    then $\exists\bM\neq\bzero$ stable fixed point of the state evolution, and, for $\alpha > \alpha_c$ $(a > 1)$
    \begin{align}
        &\Tr(\bQ) = \normf{\bM}^2 + \alpha \normf{\bM}^2\Tr\left(\cG\left(\frac{\bM}{\normf{\bM}};a,\bV\right)\right) + \alpha\Tr(\Tilde{\cF}(\bQ;a,\bV)) \implies\\
        &\normf{\bM}\geq \Tr(\bQ) - \alpha\Tr(\tilde{\cF}(\bQ;a,\bV)) > 0,\label{app:eq:symmetric_weak_recovery}
    \end{align}
where we used, introducing the auxiliary notation $\cL(y,a,\bV) = (\Cov[\rdmvect{z}|y](a\bV^{-1}- \bV)+\bV)^{-1}$
    \begin{align*}
       \Tr(\Tilde{\cF}(\bQ;a,\bV)) &=  \E_{\rdm{y}\sim \Py}\Tr\left[\bV\bcT(\rdm{y})\bV(a-\bV\bcT(\rdm{y}) \bV)^{-1}\bQ(a-\bV\bcT(\rdm{y}) \bV)^{-1}\bV\bcT(\rdm{y})\bV\right] \\
    &= \E_{\rdm{y}} \Tr\left[\bV\bcT(\rdm{y})\bV(a-\bV\bcT(\rdm{y}) \bV)^{-1}\bQ\bV(\Cov[\rdmvect{z}|y]-\bI)\cL(\rdm{y}, a, \bV)^T\right] \\
    &\leq \E_{\rdm{y}}\Tr\left[\bV\bcT(\rdm{y})\bV(a-\bV\bcT(\rdm{y}) \bV)^{-1}\bQ\bV(\Cov[\rdmvect{z}|y]-\bI)\right]\underbrace{\Tr\left[\cL(\rdm{y}, a, \bV)^T\right]}_{<\Tr\left[\cL(\rdm{y}, 1, \bV)^T\right]\leq 1}\\
    &< \Tr\E_{\rdm{y}}\left[\bV\bcT(\rdm{y})\bV(a-\bV\bcT(\rdm{y}) \bV)^{-1}\bQ\bV(\Cov[\rdmvect{z}|y]-\bI)\right] \\&= \Tr(\cF(\bQ\bV; a, \bV))\\
    &\leq \alpha^{-1} \normop{\bV^{\nicefrac{1}{2}}}^2\Tr(\bQ) = \alpha^{-1}\Tr(\bQ),.
    %&\stackrel{(a)}{\leq} \E_{\rdm{y}\sim \Py} \normop{\bcT(\rdm{y})\bV^{T}(a-\bV\bcT(\rdm{y}) \bV^T)^{-1}}^2\Tr(\bQ)\\
    \end{align*}
    together with $\Cov[\rdmvect{z}|\rdm{y}]\succ \bzero$ (a.s. over $\rdm{y}\sim\Py$) and $\normop{\bV} = 1$.
    \item \textbf{Uninformed fixed points.} Initializing GAMP with $\mat{M}^0 = \bzero$, which is a fixed point of the state evolution,
    \begin{equation}
        \mat{Q} = \alpha\tilde{\cF}(\mat{Q};, \bV),.
    \end{equation}
    Similarly to $\cF(\;\cdot\;;a,\bV)$, the symmetric operator $\tilde{\cF}(\;\cdot\;;a,\bV)$ has $p^2$ real eigenvalues. Defining $\nu_1^{\tilde{\cF}}(a)$ as its largest one, we notice that $\nu_1^{\tilde{\cF}}(1) = \alpha_c^{-1}$ and $\nu_1^{\tilde{\cF}}(a\to\infty)\to0$. Therefore, for $\alpha>\alpha_c$, $\exists a>1$ such that $\nu_1^{\tilde{\cF}}=\alpha^{-1}$ and the state evolution has a fixed point $\bM = \bzero$, $\bQ \in \mathbb{S}_+^p \setminus \{\bzero\}$. Moreover, for such $a$, the largest eigenvalue of $\cF(\;\cdot\;;a,\bV)$ is larger than $\alpha^{-1}$, hence the uninformed fixed point is unstable for $\alpha > \alpha_c$. This can be shown repeating a similar argument as the one we have applied in eq. (\ref{app:eq:symmetric_weak_recovery}). Since the GAMP convergence equations correspond to a generalized power iteration of $\tens{T}$, normalized by the eigenvalue $a\gamma$, the instability of the uninformed fixed point implies that it is associated to an eigenvector smaller than $\lambda_s$ defined in Lemma \ref{result:3}.
\end{itemize}




\section{Details on examples - Asymmetric spectral method}\label{app:example_details}
\subsection{Single-index models}
The case of single-index models ($p=1$) allows for significant simplifications, as 
\begin{align}
    \cF(M\in\R) &= M\E_{\rdm{y}\sim\Zout}\left[\left(\Var[z\big|y] - 1\right)^2\right],\\
    \cG(M\in\R) &= M^2\E_{\rdm{y}\sim\Zout}\left[\left(\Var[z\big|y] - 1\right)^3\right]. 
\end{align}
This leads to the well known expression for the critical weak recovery threshold \cite{Barbier2019, mondelli18a,Lu2019,maillard22a,damian24a}
\begin{equation}
    \alpha_c^{-1} = \E_{\rdm{y}\sim\Zout}\left[\left(\Var[z\big|y] - 1\right)^2\right],
\end{equation}
and to the following result for the overlap parameter $m = \nicefrac{M}{\sqrt{Q}}$
\begin{equation}
    m^2 = \begin{cases}
        \begin{array}{ll}
          (\alpha - \alpha_c)\left(\alpha + \alpha_c^2\E_{\rdm{y}\sim\Zout}\left[\left(\Var[z\big|y] - 1\right)^3\right]\right)^{-1},   & \alpha\geq\alpha_c \\
           0,  & \alpha<\alpha_c
        \end{array}
    \end{cases}.
\end{equation}
\subsection{$\Cov[\mathbf{z}|y]$ jointly diagonalizable $\forall y$}\label{app:examples_joinlty_diag}
In this section, we consider the ensemble of link functions $g$ corresponding to a matrix $\Cov[\rdmvect{z}\big|y]$ that can be diagonalized with respect to the same basis of eigenvectors for all $y$: there exists an orthogonal matrix $\bU\in\R^{p\times p} = (\vect{u}_1, \ldots, \vect{u}_p)$ independent of $\rdm{y}$ and real numbers $\lambda_k(y)$ such that 
\begin{equation}
    (\Cov[\rdmvect{z}\big|y]-\bI)\vect{u}_k = \lambda_k(y)\vect{u}_k, \quad k \in\integset{p}.
\end{equation}
Consider a separate link function $\overline g$ defined as $\overline g(\bZ) \coloneqq g(\bU\bz),\;\forall\bz\in\R^p$. It is easy to show that $g$ and $\overline g$ share the same weak recovery properties, including the sample complexity threshold. Indeed, introducing temporarily the notations $\overline\Zout(y)$, $\overline{\mathsf{P}}(y|\;\cdot\;)$, $\overline{\alpha}_c$, for the quantities related to $\overline g$, we have that
\begin{align}
    \overline\Zout(y) &= (2\pi)^{-p/2}\int_{\R^p} e^{-\nicefrac{1}{2}\bz^T\bz}\delta(y-g(\bU\bz)){\rm d}\bz\\
        &\stackrel{(\bz' = \bU\bz)}{=}(2\pi)^{-p/2}\int_{\R^p} e^{-\nicefrac{1}{2}\bz'^T\bU\bU^T\bz'}\delta(y-g(\bU\bz')){\rm d}\bz' = \Zout(y),
\end{align}
and similarly
\begin{align}
   \E_{\rdmvect{z}}[\rdmvect{z}\overline{\mathsf{P}}(y|\rdmvect{z})] &= \bU^T\E_{\rdmvect{z}}[\rdmvect{z}{\mathsf{P}}(y|\rdmvect{z})], \\
    \E_{\rdmvect{z}}[\rdmvect{z}\rdmvect{z}^T\overline{\mathsf{P}}(y|\rdmvect{z})] &= \bU^T\E_{\rdmvect{z}}[\rdmvect{z}\rdmvect{z}^T{\mathsf{P}}(y|\rdmvect{z})]\bU = \bU^T\Cov[\rdmvect{z}\big|y]\bU\quad\text{(diagonal)}.
\end{align}
If $\E_{\rdmvect{z}}[\rdmvect{z}{\mathsf{P}}(\rdm{y}|\rdmvect{z})] = \bzero$ almost surely for $\rdm{y}\sim\Zout$, the same applies to $\E_{\rdmvect{z}}[\rdmvect{z}\overline{\mathsf{P}}(\rdm{y}|\rdmvect{z})]$, and both problems are non-trivial. In this case
\begin{align}
        \overline\alpha_c^{-1} &= \max_{\normf{\bM}=1}\normf{\E_{y\sim\overline\Zout}[ \left(\E_{\rdmvect{z}}[\rdmvect{z}\rdmvect{z}^T\overline{\mathsf{P}}(y|\rdmvect{z})]-\bI\right)\bM \left(\E_{\rdmvect{z}}[\rdmvect{z}\rdmvect{z}^T\overline{\mathsf{P}}(y|\rdmvect{z})]-\bI\right)]}\\
        & = \max_{\normf{\bM}=1}\normf{\E_{y\sim\Zout}[ \left(\Cov[\rdmvect{z}\big|y]-\bI\right)\bU\bM\bU^T \left(\Cov[\rdmvect{z}\big|y]-\bI\right)]}\\
        &= \max_{\normf{\bM'}=1}\normf{\E_{y\sim\Zout}[ \left(\Cov[\rdmvect{z}\big|y]-\bI\right)\bM' \left(\Cov[\rdmvect{z}\big|y]-\bI\right)]}=\alpha_c^{-1}.
    \end{align}
Therefore, whenever we are in this setting, we can consider without loss of generality $(\Cov[\rdmvect{z}\big|y]-\bI) = \operatorname{diag}(\lambda_1(y), \ldots, \lambda_p(y))$. The eigenpairs of the operator $\cF$ eq. (\ref{app:eq:def:operator_F}) are given by 
\begin{equation}
    \nu_{(k,h)} = \E_{y}[\lambda_k(y)\lambda_h(y)],\quad\mat{M}_{(k,h)}\text{ with }[\mat{M}_{(k,h)}]_{\mu\nu} = \delta_{k\mu}\delta_{h\nu},\quad\forall k,h\in\integset{p},  
\end{equation}
with the critical sample complexity $\alpha_c^{-1} = \nu_1 \coloneqq \max_{k\in\integset{p}}\nu_{(k,k)}$ \footnote{Note that $\forall k, h\in\integset{p^2}$, $\nu_{(k,h)} \leq\max(\nu_{(k,k)},\nu_{(h,h)})$.}. If the maximum is achieved by more than one pair of indices, we expect that the matrix $\tens{L}$ principal eigenvalue is degenerate, with degeneracy given by the cardinality of the set $\cI = \{(k,h)\in\{1,...,p\}^2|\nu_{(k,h)} = \alpha_c^{-1}\}$. Note that $\forall k,h$, $\nu_{(k,h)} = \nu_{(h,k)}$ and if $\nu_{(k,h)} = \max_{\mu\in\{k,h\}}\nu_{\mu\mu}\implies\nu_{(k,k)}=\nu_{(h,h)}$.\footnote{Without loss of generality $\nu_{(h,h)}\leq\nu_{(k,k)}$ and $\nu_{(k,k)}=\nu_{(k,h)}\leq \sqrt{\nu_{(k,k)}\nu_{(h,h)}}\implies \nu_{(k,k)}\leq\nu_{(h,h)}$. Therefore $\nu_{(k,k)}=\nu_{(h,h)}$.}\\
The generic principal eigenvector of $\cF$
is given by $\mat{M} = ||\bM||_F\sum_{(k,h)\in\cI} c_{(k,h)}\mat{M}_{(k,h)}$ with $\sum c_{(k,h)}^2 = 1$. We introduce the ansatz: $\mat{Q}$ s.t. $\mat{Q}_{kk} \neq 0$ iff $(k,k)\in\cI$; this implies $\Tr(\cF(\mat{Q})) = \sum_{k} \E[\lambda_k(y)^2] Q_{kk} = \alpha_c^{-1}\Tr(\mat{Q})$. Eq. (\ref{app:eq:Q_trace_fixed_point}) becomes

\begin{align}
    &\Tr(\mat{Q}) = \normf{\mat{M}}^2\left( 1 +  \frac{\alpha_c^2}{\alpha}\sum_{(k,h)\in\cI} c_{(k,h)}^2 \Tr(\cG(\mat{M}_{(k,h)}))\right)+ \frac{\alpha_c^2}{\alpha} {\Tr(\cF(\mat{Q}))} \implies\\
    &\Tr(\mat{Q}) = \normf{\mat{M}}^2 \left( 1 +  \frac{\alpha_c^2}{\alpha}\sum_{(k,h)\in\cI} c_{(k,h)}^2 \E_{y}[\lambda_k(y)^2\lambda_h(y)]\right)+ \frac{\alpha_c}{\alpha}\Tr(\mat{Q})\implies\\
    &\frac{\normf{\mat{M}}^2}{\Tr(\mat{Q})} = \left(1-\frac{\alpha_c}{\alpha}\right)\left( 1 +  \frac{\alpha_c^2}{\alpha}\sum_{(k,h)\in\cI} c_{(k,h)}^2 \E_{y}[\lambda_k(y)^2\lambda_h(y)]\right)^{-1}\label{app:eq:M_norm_diagonal_case}
\end{align}
As a special case, we consider the example $\lambda_k(y)=\lambda_h(y)$ for all $h,k$ such that $\nu_{(k,k)} = \nu_{(h,h)} = \nu_1$. One instance for this case is given by the link function $g(\bz) = p^{-1}\sum_{k\in\integset{p}}z_k^2$.
Then, defining $\lambda^{(3)} = \E_\rdm{y}[\lambda_k(\rdm{y})^3]$ for any $k|(k,k)\in\cI$, the solution for $m^2$ does not depend on the coefficients $c_{(k,h)}$ and simplifies to 
\begin{equation}\label{app:eq:M_norm_degenerate_case}
    \frac{\normf{\mat{M}}^2}{\Tr(\mat{Q})} = \left(1-\frac{\alpha_c}{\alpha}\right)\left( 1 +  \frac{\alpha_c^2}{\alpha}\lambda^{(3)}\right)^{-1}.
\end{equation}
The above expression does not depend on the coefficients $c_{(k,h)}$, therefore it is valid for all the degenerate directions in the principal eigenspace.\\
We consider now specific cases of link functions that are such that $\Cov[\rdmvect{z}\big|y]$ is jointly diagonalizable $\forall y$. We refer to \cite{troiani2024fundamental} for the derivation of the expressions of $\Zout(y)$ and $\Cov[\rdmvect{z}\big|y]$ in all the examples contained in this Appendix \ref{app:examples_joinlty_diag}.
\subsubsection{$g(z_1,\ldots,z_p) = p^{-1}\sum_{k\in\integset{p}}z_k^2$}
\begin{equation}
    \Zout(y) = \frac{e^{-\frac{p y}{2}}}{y 2^{p/2}\Gamma\left(\frac{p}{2}\right)}  \,(p \rdm{y})^{p/2},\quad\quad\Cov[\rdmvect{z}\big|y]  = y\bI.
\end{equation}
For a generic $\mat{M}\in\R^{p\times p}$
\begin{align}
    \cF(\mat{M}) &= \mat{M} \int_0^\infty \Zout(y)(y-1)^2\de y = \frac{2}{p}\mat{M},\\
    \cG(\mat{M}) &= \mat{M}\mat{M}^T\int_0^\infty \Zout(y)(y-1)^3\de y = \frac{8}{p^2}\mat{M}\mat{M}^T,
\end{align}
therefore $\alpha_c = \nicefrac{p}{2}$ and $\lambda^{(3)} = 8 / p^3$. Plugging these quantities in eq. (\ref{app:eq:M_norm_degenerate_case}), the overlap matrices at convergence satisfy
\begin{equation}
    \frac{\normf{\mat{M}}^2}{\Tr(\mat{Q})} = \begin{cases}\begin{array}{ll}
       \frac{1}{2}(2\alpha-p)(\alpha+2)^{-1}  &  \alpha\geq\nicefrac{p}{2}\\
       0  & \alpha<\nicefrac{p}{2}
    \end{array}
    \end{cases}
\end{equation}
\subsubsection{$g(z_1,z_2) =\operatorname{sign}(z_1z_2)$}
\begin{equation}
    \Zout(y) = \frac{1}{2},\quad\quad\Cov[\rdmvect{z}\big|y]  = \frac{2 y}{\pi}\left(\begin{array}{cc}
       0  & 1 \\
        1 & 0
    \end{array}\right) + \bI.
\end{equation}
The matrix $(\Cov[\rdmvect{z}\big|y]-\bI)$ is jointly diagonalizable $\forall y$, with eigenvalues $\lambda_1(y) = 2\rdm{y}\pi^{-1}$ and $\lambda_2(\rdm{y}) = -2\rdm{y}\pi^{-1}$. Therefore, the eigenvalues of $\cF$ are given by
\begin{equation}
    \alpha_c^{-1} = \nu_{(1,1)} = \nu_{(2,2)} = \frac{4}{\pi^2},\quad\quad \nu_{(1,2)} = -\frac{4}{\pi^2},
\end{equation}
and
\begin{equation}
    \E_y[\lambda_1(y)^3] = -\E_y[\lambda_2(\rdm{y})^3] = \frac{8}{\pi^3}\sum_{y=\pm1}y^3 = 0.
\end{equation}
Leveraging eq. (\ref{app:eq:M_norm_diagonal_case}), the overlap matrices $\mat{M}$ and $\mat{Q}$ at convergence satisfy
\begin{equation}
    \frac{\normf{\mat{M}}^2}{\Tr(\mat{Q})} = \begin{cases}
        \begin{array}{ll}
           1-\frac{\pi^2}{4}\alpha^{-1},  & \alpha \geq \nicefrac{\pi^2}{4} \\
           0,  & \alpha < \nicefrac{\pi^2}{4}
        \end{array}
    \end{cases}
\end{equation}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{plots/signz1z2_n5000_alpha14_alpha7_eigenvalues_horiz.pdf}
    \caption{Distribution of the eigenvalues (dots) $\lambda\in\mathbb C$ of $\tens{L}$ at finite $n = 5\cdot10^3$, for $g(z_1,z_2) = \operatorname{sign}(z_1z_2)$,  $\alpha_c =\nicefrac{\pi^2}{4}$. (\textbf{Left}) $\alpha = 1.4 < \alpha_c$. (\textbf{Right}) $\alpha = 7 > \alpha_c$. The dashed blue circle has radius equal to $\sqrt{\nicefrac{\alpha}{\alpha_c}}$, {\it i.e.} the value $\gamma_b$ predicted in Lemma \ref{result:2}. The dashed orange vertical line corresponds to $\operatorname{Re}\lambda = \nicefrac{\alpha}{\alpha_c}$, the eigenvalue $\gamma_s$ defined in Lemma \ref{result:1}. As predicted by the state evolution equations for this problem, two significant eigenvalues (highlighted in orange) are observed near this vertical line. Additionally, one can observe that our framework predicts other two degenerate eigenvalues at $-\gamma_s$, here highlighted in cyan.}
    \label{fig:app:sign:lamp}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{plots/signz1z2_eig_distr_TAP_d5000_light.pdf}
    \caption{Distribution of the eigenvalues of $\tens{T}$, $d = 10^4$, for the link function $g(z_1,z_2)=\operatorname{sign}(z_1z_2)$. The critical threshold in $\alpha_c = \nicefrac{\pi^2}{4}$. The distribution is truncated on the left. (\textbf{Left}) $\alpha =  \alpha_c$. (\textbf{Right}) $\alpha = 7 > \alpha_c$. As predicted by the state evolution framework, in this regime we observe two eigenvalues separated from the main bulk, centered around $\lambda_s$ (green vertical line) obtained in Lemma \ref{result:3}. The vertical purple line correspond to the value $\lambda_b$ provided in Lemma \ref{result:4} as a bound for the bulk.}
    \label{fig:app:sign:tap}
\end{figure}
\subsubsection{$g(z_1,\ldots,z_p)=\prod_{k=1}^pz_k$}
For $p = 2$
\begin{equation}
    \Zout(y) = \frac{K_0(|y|)}{\pi},\quad\quad\Cov[\rdmvect{z}\big|y] = \left(
    \begin{array}{cc}
      |y|\frac{K_1(|y|)}{K_0(|y|)}    & \rdm{y} \\
       \rdm{y}  & |y|\frac{K_1(|y|)}{K_0(|y|)}  
    \end{array}\right),
\end{equation}
where $K_n(\rdm{y})$ is the modified Bessel function of the second kind. The matrix $\dgout(y)$ is jointly diagonalizable for all $\rdm{y}$, with eigenvalues $\lambda_1(y) = |y|\frac{K_1(|y|)}{K_0(|y|)} +\rdm{y}- 1$ and $\lambda_2(\rdm{y}) = |y|\frac{K_1(|y|)}{K_0(|y|)} -\rdm{y}- 1$. Therefore, the eigenvalues of $\cF$ are given by\footnote{In what follows, we use $\lambda_1(y) = \lambda_2(-\rdm{y})$, the parity of $\Zout(y)$ and the symmetry of the integration domain.}
\begin{equation}
    \alpha_c^{-1}=\nu_{(1,1)} = \nu_{(2,2)} = \E_{\rdm{y}}[\lambda_1(y)^2],\quad\quad\nu_{(1,2)}=\E_{\rdm{y}}[\lambda_1(y)\lambda_1(-\rdm{y})]<\nu_{(1,1)},
\end{equation}
and
\begin{equation}
    \E_y[\lambda_1(y)^3] = \E_y[\lambda_2(\rdm{y})^3].
\end{equation}
Leveraging eq. (\ref{app:eq:M_norm_diagonal_case}), the overlap matrices $\mat{M}$ and $\mat{Q}$ at convergence satisfy
\begin{equation}
    \frac{\normf{\mat{M}}^2}{\Tr(\mat{Q})} = \begin{cases}
        \begin{array}{ll}
          (\alpha-\alpha_c)\left(\alpha + \alpha_c^2\E_{\rdm{y}\sim\Zout}\left[\lambda_1(y)^3\right]\right)^{-1},   & \alpha \geq \alpha_c\\
           0,  & \alpha < \alpha_c
        \end{array}
    \end{cases}
\end{equation}
If instead $p \geq 3$,
\begin{equation}
    \Zout(y) = \frac{1}{(2\pi)^{p/2}}G^{p, 0}_{0, p} \left( \frac{y^2}{2^p} \, \bigg| \, \begin{array}{c}
0 \\
0, 0, \ldots, 0
\end{array} \right),\quad\quad\Cov[\rdmvect{z}\big|y] = (\lambda(y) + 1)\bI,
\end{equation}
where 
\begin{equation}
    \lambda(y) = 2 G^{p, 0}_{0, p} \left( \frac{y^2}{2^p} \, \bigg| \, \begin{array}{c}
0 \\
0, 0, \ldots, 0, 1
\end{array} \right) / G^{p, 0}_{0, p} \left( \frac{y^2}{2^p} \, \bigg| \, \begin{array}{c}
0 \\
0, 0, \ldots, 0
\end{array} \right) - 1,
\end{equation}
and the previous expression are written in terms of the Meijer $G$-function. 
Therefore $\alpha_c^{-1} = \E_{\rdm{y}}[\lambda(\rdm{y})^2]$ and, leveraging eq. (\ref{app:eq:M_norm_degenerate_case}), we obtain
\begin{equation}
    \frac{\normf{\mat{M}}^2}{\Tr(\mat{Q})} = \begin{cases}
        \begin{array}{ll}
          (\alpha-\alpha_c)\left(\alpha + \alpha_c^2\E_{\rdm{y}\sim\Zout}\left[\lambda(\rdm{y})^3\right]\right)^{-1},   & \alpha \geq \alpha_c\\
           0,  & \alpha < \alpha_c
        \end{array}
    \end{cases}
\end{equation}



\subsection{A non-jointly diagonalizable case: $g(z_1,z_2) = z_1/z_2$}
If the matrix $\dgout(y)$ is not jointly diagonalizable $\forall y$, there is not a general simplification for equations (\ref{app:eq:se_sp_gamp_M},\ref{app:eq:se_sp_gamp_Q}), and each example needs to be treated separately. \\
In this section we consider the Gaussian multi-index model with link function $g(z_1,z_2) = \nicefrac{z_1}{z_2}$.
\begin{align}
    \Zout(y) &= \frac{1}{2\pi}\int_{\R^2}e^{-\nicefrac{1}{2}(z_1^2+z_2^2)}\delta\left(y - \frac{z_1}{z_2}\right)\de z_1\de z_2\\
    &=\frac{1}{2\pi}\int_{\R^2}|z_2|e^{-\nicefrac{1}{2}(s^2z_2^2+z_2^2)}\delta\left(y - s\right)\de s\de z_2\\
    &=\frac{1}{2\pi}\int_{\R}|z|e^{-\nicefrac{1}{2}(y^2+1)z^2}\de z = \frac{1}{\pi(y^2+1)}
\end{align}
In order to verify that both directions are not {\it trivial}, we need to compute $\E[\rdmvect{z}|\rdm{y}]$ and verify that is zero almost surely over $\rdm{y}\sim\Py$:
\begin{align}
    \E_{\rdmvect{z}}[\rdmvect{z}|y] &\propto\int_{\R^2}\bz e^{-\nicefrac{1}{2}(z_1^2+z_2^2)}\delta\left(y - \frac{z_1}{z_2}\right)\de z_1\de z_2\\
    &=\int_{\R}\left(\begin{array}{c}
         yz  \\
         z 
    \end{array}\right)|z|e^{-\nicefrac{1}{2}(y^2+1)z^2}\de z = \bzero,
\end{align}
where the last equality is the result of the integral of an odd function over a symmetric domain. In order to study the perfomance of the spectral method, we compute
\begin{align}
   \Cov[\rdmvect{z}\big|y] &= \frac{1}{2\pi\Py(y)}\int_{\R^2}\bz\bz^T e^{-\nicefrac{1}{2}(z_1^2+z_2^2)}\delta\left(\rdm{y} - \frac{z_1}{z_2}\right)\de z_1\de z_2\\
    &=\frac{1}{2\pi\Py(y)}\left(\begin{array}{cc}
         y^2 & y  \\
         y & 1
    \end{array}\right)\int_{\R}|z|^3e^{-\nicefrac{1}{2}(y^2+1)z^2}\de z  \\
    &=\frac{1}{1+y^2}\left(
    \begin{array}{cc}
      y^2-1  & 2y \\
       2y  & 1-y^2 
    \end{array}\right) + \bI.
\end{align}
The eigenpairs of $(\Cov[\rdmvect{z}\big|y] - \bI)$ are $\lambda_1(y) = 1$, with eigenvector $({y}, 1)^T$, and $\lambda_2({y})=-1$ with eigenvector $(-1, {y})^T$, which depends on $y$.
Considering a generic $\mat{M} = \left(\begin{array}{cc}
   m_1  & m_2 \\
    m_3 & m_4
\end{array}\right)$, we have that
\begin{equation}\label{app:eq:z1_over_z2_F}
    \cF(\mat{M})= \frac{\Tr(\mat{M})}{2}\bI + \frac{m_2-m_3}{2}\left(\begin{array}{cc}
        0 & -1 \\
        1 & 0
    \end{array}\right),
\end{equation}
therefore, the eigenpairs of $\cF$ are
\begin{align}
    &\nu_1 = 1,\;\mat{M}_1 = \bI;&\nu_2=0,\;\mat{M}_2=\left(\begin{array}{cc}
        1 & 0 \\
        0 & -1
    \end{array}\right);
    \\&\nu_3=0,\;\mat{M}_3=\left(\begin{array}{cc}
        0 & 1 \\
        1 & 0
    \end{array}\right);&\nu_4=-1,\;\mat{M}_4=\left(\begin{array}{cc}
        0 & -1 \\
        1 & 0
    \end{array}\right),
\end{align}
and $\alpha_c = 1$. Moreover, one could easily verify that $\cG(\mat{M}_1) = \bzero$.
The overlap of the spectral estimator with the signal is therefore $\mat{M}\propto \bI$, and, from the state evolution eq. (\ref{app:eq:se_sp_gamp_Q}) at convergence, we have that
\begin{equation}
    \frac{\normf{\mat{M}}^2}{\Tr(\mat{Q})} = \begin{cases}\begin{array}{ll}
       1 - \alpha^{-1},  & \alpha\geq 1 \\
        0, & \alpha < 1
    \end{array}
    \end{cases}
\end{equation}
where we leverage the symmetry of $\mat{Q}$ in eq. (\ref{app:eq:z1_over_z2_F}) to write $\cF(\mat{Q}) = 2^{-1}\Tr(\mat{Q})\bI\implies\Tr(\cF(\mat{Q}))=\Tr(\mat{Q})$.
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{plots/z1_over_z2_n5000_overlap_LAMP.pdf}
    \caption{Overlap $\normf{\bM}^2 / \Tr(\bQ)$ as a function of the sample complexity $\alpha$. The dots represent numerical simulation results, computed for $n = 5000$ (for the asymmetric method) or $d = 5000$ (for the symmetric method) and averaging over $10$ instances. The link function is $g(z_1,z_2) = z_1/z_2$. Solid lines are obtained from state evolution predictions. Dashed vertical line at $\alpha_c = 1$.}
    \label{fig:app:fraction}
\end{figure}
\section{Details on examples - Symmetric spectral method}\label{app:details_examples_symmetric}
In all the considered examples with $p \geq 2$, the matrix $\Cov[\rdmvect{z}\big|y]$ admits a unique orthonormal basis of eigenvectors independent of $y$. Therefore, the state evolution equations can be significantly simplified following the same considerations applied in Appendix \ref{app:examples_joinlty_diag}, to which we refer for the notation adopted in this appendix. 
Additionally, for all these examples, the eigenvalues $\lambda_k(y)$ of $(\Cov[\rdmvect{z}\big|y] - \bI)$ satisfy the additional conditions
\begin{equation}
    \forall k,h\in\integset{p},\;\;\lambda_k(y)=\lambda_h(y)\text{ or }\begin{cases}
        \lambda_k(y) = \lambda_h(-y),\\
        \Zout(y)\text{ even and defined on a symmetric domain}
    \end{cases}
\end{equation}
Additionally
\begin{equation}
  \forall k,h\in\integset{p},\;\;\E_{\rdm{y}}[\lambda_k(\rdm{y})\lambda_h(\rdm{y})] \geq  \E_{\rdm{y}}[\lambda_k(\rdm{y})^2] = \E_{\rdm{y}}[\lambda_h(\rdm{y})^2].
\end{equation}
It is easy to verify that these conditions implies that $\bV = \bI$, and the state evolution admits stable fixed point $\bM,\bQ\propto\bI$, where the proportionality constants can be numerically computed through one-dimensional integrals, expressed in terms of $\lambda_1(y)$ (the choice of the eigenvalue is arbitrary in this setting) and given in eq. (\ref{eq:examples_symmetric_general}).

\section{Proof of Proposition \ref{proposition:maillard}}\label{app:proof_proposition} \begin{enumerate}
    \item By definition $\tens{L}\cdot\bOmega = \gamma_{\tens{L}}\bOmega$. Applying on the right of both sides $\rdmmat{X}^T\tens{G}\cdot ((\gamma_{\tens{L}}\tens{I}+\tens{G})^{-1}\;\cdot\;)$
    \begin{equation}
        \rdmmat{X}^T\tens{G}\cdot ((\gamma_{\tens{L}}\tens{I}+\tens{G})^{-1}\cdot(\tens{L}\cdot\bOmega))=\gamma_{\tens{L}}\rdmmat{X}^T\tens{G}\cdot ((\gamma_{\tens{L}}\tens{I}+\tens{G})^{-1}\cdot\bOmega).
    \end{equation} 
Recalling the definition of $\tens{L}$ (\ref{eq:def:spectral_asymmetric})
    \begin{align}
         &\rdmmat{X}^T\tens{G}\cdot ((\tens{I}+\tens{G})^{-1}\cdot(\rdmmat{X}\rdmmat{X}^T\tens{G}\bOmega) = \rdmmat{X}^T\tens{G}\bOmega\\ \implies&
        \rdmmat{X}^T\tens{G}\cdot((\tens{G}+\gamma_{\tens{L}}\tens{I})^{-1}\cdot(\rdmmat{X}\bW)) = \bW
    \end{align}
    \item Defining $ \bOmega := (\tens{I} + \tens{G})^{-1}\cdot(\rdmmat{X}\bW)$, we have that
    \begin{align}
        \tens{L}\cdot\bOmega &= (\rdmmat{X}\rdmmat{X}^T-\I_n)\tens{G}\cdot((\tens{I} + \tens{G}^{-1}\cdot(\rdmmat{X}\bW))\\
        &= \rdmmat{X}\tens{T}\cdot\bW - \tens{G}\bOmega\\
        &= \gamma_{\tens{T}} (\tens{I} +\tens{G})\cdot\bOmega  - \tens{G}\cdot\bOmega\\
        &= \gamma_{\tens{T}}\bOmega + (\gamma_{\tens{T}}-1)\tens{G}\cdot\bOmega.
    \end{align}
\end{enumerate}
