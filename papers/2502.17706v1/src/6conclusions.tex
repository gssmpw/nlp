\section{Conclusions}
This paper presents a two-pass image blending pipeline, \textit{IBURD}, to generate synthetic images with a given background using source objects and their annotations which can be obtained semi-automatically for underwater debris detection. 
Our approach provides pixel-level annotations for each synthetic image, eliminating the labor-intensive dataset annotation process. 
IBURD can blend transparent source object images without creating artificial borders between the object and background. 
Also, our blurriness score-based blending method can dynamically synthesize source and target background images, resulting in more realistic synthetic images than previous methods.
The results demonstrate that our pipeline enables training of object detection and instance segmentation networks suitable for the data-scarce underwater debris detection problem. 

We plan to extend the pipeline in multiple directions. 
We are looking to refine our approach for scenarios where objects overlap each other or are partially occluded to address more complex scenes.
We are also developing an approach to decide the desired locations of source objects in target background images by considering the correlation between the semantic information of the background and objects. 
Lastly, we intend to improve the blurriness evaluation algorithm by enabling selective evaluation of regions of interest for partially blurry target background images. 