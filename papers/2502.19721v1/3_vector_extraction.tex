\section{Finding a Steering Vector}
\label{sec:extract-vector}
Our goal is to derive a steering vector that captures how the concept of gender is encoded in a model's representation and that allows us to manipulate the internal representation's gender signal in a controlled way. In this section, we introduce a method for extracting candidate vectors (\autoref{sec:extracting}) and an efficient approach for selecting the steering vector (\autoref{sec:selecting}). \autoref{sec:apply-steering} discusses how we apply that steering vector at inference time.

\subsection{Extracting Candidate Vectors}\label{sec:extracting}
Let $A$ and $B$ denote two contrasting concepts (e.g., \textit{femaleness} and \textit{maleness}) each of which can be identified by an associated set of tokens. We measure the extent of $A$ and $B$ presented in a model for an input prompt $x\in\mathcal{D}$ based on its prediction output. We define the disparity score between the two concepts for an input $x$ as:
\[
    s_x = P_x(A)-P_x(B)
\]
where $P_x(A)$ is the probability of predicting concept $A$ in the last token position output of $x$, aggregated over tokens for $A$. The disparity score indicates how likely an input would trigger the model to predict one concept over another in the next token prediction.

Let $f$ denote a function that maps each prompt $x\in\mathcal{D}$ to a partition as follows:
\begin{align*} 
  f(x) = \begin{cases}
        \mathcal{D}_A & \text{if } s_x > \delta \\
        \mathcal{D}_B & \text{if } s_x < -\delta \\
        \mathcal{D}_o & \text{otherwise} \quad\quad (|s_x| \leq \delta)
    \end{cases}
\end{align*}
where $\delta$ is a score threshold that determines which concept the input is more likely associated with. Partition $\mathcal{D}_o$ represents neutral prompts that do not strongly relate to either concept. 

In contrast to difference-in-means, which computes the activation mean difference between $\mathcal{D}_A$ and $\mathcal{D}_B$, we incorporate neutral prompts with probability weighting to filter out signals unrelated to the target concepts. This allows the vector to capture a better representation of $A$ and $B$.
%, which can be applied to inputs from other distributions. 

Suppose the average activation of neutral inputs $\mathcal{D}_o$ is $\Vec{\bar{h}}^{(l)}_o$. For each layer $l\in L$, a candidate vector is computed as the weighted mean activation difference with respect to the neutral representations: 
\begin{align}\label{eq:dataset-map}
    \Vec{v}^{(l)} &= \unitvec{v}_{A}^{(l)} -\unitvec{v}_{B}^{(l)} \\
    \textrm{where}\quad \Vec{v}_{A}^{(l)} &= \frac{\sum_{x\in \mathcal{D}_A} s_x (\Vec{h}^{(l)}_x-\Vec{\bar{h}}^{(l)}_o)}{\sum_{x\in \mathcal{D}_A} s_x}
\end{align}
We denote $\Vec{h}^{(l)}_x$ as the activation of input $x$ in the last token position at layer $l$. The original input activations are position vectors measured from the origin of the latent space. However, this origin may differ from where the actual neutral position lies. To resolve this, we first offset each input activation $\Vec{h}^{(l)}_x$ by the average neutral activations $\Vec{\bar{h}}^{(l)}_o$. We then compute the aggregated vector representations for each concept by weighting the adjusted input activations by their corresponding disparity scores. The resulting candidate vector, $\Vec{v}^{(l)}$, is simply the unit vector representation difference between $A$ and $B$. 

\subsection{Selecting a Steering Vector}\label{sec:selecting}
We assume that the ideal vector would reflect the desired concept signal in both its \textit{direction} and \textit{magnitude}. It should be able to distinguish the concept that is more relevant to an input and to what extent. Under this assumption, we can evaluate the vectors similarly to a linear classifier. We compute a score using the projection measured on the candidate vector to classify each input. Given a separate set of prompts, $\mathcal{D}^{\prime}$, drawn from the same distribution as $\mathcal{D}$. We assess the linear separability of each candidate vector $\Vec{v}\in\{\Vec{v}^{(l)}\}_{l\in L}$ by the root mean square error (RMSE) as:
\[
    \mathrm{RMSE}_{\Vec{v}} = \sqrt{\frac{1}{|\mathcal{D}^{\prime}|}\sum_{x\in\mathcal{D}^{\prime}} \mathbb{I}_{\mathbf{sign}} (\lVert \proj{v}{x} \rVert \not=s_x) \,s_x^2}
\]
where $\proj{v}{x}$ is the vector projection of latent state activations $\Vec{h}^{(l)}_x$ on vector $\Vec{v}$ given input $x$. The indicator function $\mathbb{I}_{\mathbf{sign}}(\cdot)$ returns 0 if the scalar projection and disparity score of an input have the same sign,  and $1$ if they have different signs. A vector $\Vec{v}$ perfectly differentiates the concepts in direction when $\mathrm{RMSE}_{\Vec{v}}=0$.

To evaluate how well a candidate vector captures the desired property, we compute the Pearson correlation between the scalar projection $\lVert\proj{v}{x}\rVert$ and the disparity score $s_x$ for each $x\in\mathcal{D}^{\prime}$. We select the final steering vector at the layer with the lowest RMSE score, excluding the 5\% of the layers that are closest to the output~\citep{arditi2024refusal}.

\begin{figure*}[tb]
\centering
    \includegraphics[width=\linewidth]{figs/proj-corr-and-rmse.pdf}
\caption{Candidate vector performance across model layers. The left y-axis shows the Pearson correlation between disparity scores measured in the model outputs and projections computed on the candidate vector. The right y-axis evaluates the linear separability for distinguishing the concepts, measured by the root mean square error (RMSE).}
\label{fig:layer-perfomance}
\end{figure*}


\subsection{Experimental Setup}
We test whether our method can find a steering vector that represents the concept of gender encoded in a model and is more effective than the prevailing method, difference-in-means (MD), in capturing this concept. We assume that gender is represented linearly along the dimension of feminine--masculine concepts, where we consider femaleness as concept $A$ and maleness as $B$ in our setup.

\shortsection{Dataset}
The \textit{gendered language dataset} consists of sentences generated by ChatGPT with gender-coded lexicons~\citep{soundararajan2023using}, including adjectives that reflect stereotypical traits or characteristics of a certain gender~\citep{gaucher2011evidence,cryan2020detecting}. Each sentence is labeled with the gender described and whether it is consistent with or contradictory to the gender stereotypes. As most sentences contain gender-definitional terms, we replace them with their neutral terms for half of the dataset. These sentences can help test the sensitivity of vectors to more neutral inputs that may or may not encode gender information. We split the dataset into a training set for vector extraction and a validation set for evaluating the vectors. 

\shortsection{Models} We conduct the experiments with several popular open-source chat models (\model{Qwen-1.8B} and 7B, \model{Llama-2-13B}) and instruction models (\model{Llama-3.1-8B}, \model{Granite-3.1-8B}, \model{Ministral-8B}, \model{Mistral-Nemo-12B}, and \model{OLMo-2-7B}). \autoref{app:model-card} provides information about the references and model cards.

Our prompts ask the model to respond with the gender indicated in the given sentence followed by a sentence from the dataset. Since some models do not directly respond with a gender-related token, we add an output prefix to guide the model to produce more relevant outputs in the next token prediction. For each gender concept, we randomly sample 800 prompts that satisfy the requirements of \autoref{eq:dataset-map} for extracting the candidate vectors. The number of neutral prompts varies by model, but we subsample them if the size is larger than either the set of female or male prompts. The default score threshold $\delta$ is set to 0.05, but we compare results using different $\delta$ values in \autoref{sec:bias-threshold}. \autoref{app:dataset} provides more details, including the gender tokens used for computing the disparity scores.

\subsection{Results}
\label{sec:extract-results}

We evaluate the quality of candidate vectors extracted using our proposed weighted mean difference method (WMD) with the prior \textit{difference-in-means} (MD) approach. 

\autoref{fig:layer-perfomance} shows the candidate vector performance on the validation set across all model layers, measured by RMSE and the projection correlation. Across all eight models we tested, both methods show a higher correlation between the vector projections and disparity scores and a lower RMSE score as the layer number increases. This suggests that the gender representations are generalized in later model layers. This aligns with previous findings that high-level concepts tend to emerge in middle to later layers~\citep{zou2023transparency,rimsky-etal-2024-steering}. Results for other models are provided in \autoref{app:vector-performance}.

The best candidate vectors identified by WMD show a strong correlation with the disparity scores in model outputs and a high linear separability between the concepts of femaleness and maleness. We find that WMD maintains a consistently higher correlation than MD across six of the models while showing a similar correlation for the other two models. The two methods show the largest performance gap for \model{Qwen-7B} model where the projection correlation of WMD is around 0.28\% higher than the optimal layer of MD (\autoref{tab:steering-performance}). While both methods can identify layers with a low $\mathrm{RMSE}\approx0$, the scores for WMD remain consistently lower than MD at layers with the highest correlation.

\begin{figure}[tb]
\centering
    \begin{subfigure}[b]{\linewidth}
        \includegraphics[width=0.495\linewidth]{figs/mistral-nemo-proj-MD.pdf}
        \includegraphics[width=0.495\linewidth]{figs/mistral-nemo-proj-WMD.pdf}
        \caption{\model{Mistral-Nemo-12B-Instruct}}
        \vspace{0.03cm}
    \end{subfigure}
    \vfill
    \begin{subfigure}[b]{\linewidth}
        \includegraphics[width=0.495\linewidth]{figs/qwen-7b-proj-MD.pdf}
        \includegraphics[width=0.495\linewidth]{figs/qwen-7b-proj-WMD.pdf}
        \caption{\model{Qwen-7B-Chat}}
        \label{fig:projection-qwen7b}
    \end{subfigure}
\caption{Disparity score and scalar projection measured for each input from the validation set. We evaluate at the layer where the vector has the lowest RMSE.}
\label{fig:projection}
\end{figure}

\input{tables/steering_performance}

\autoref{fig:projection} compares the disparity scores and scalar projections measured for each input prompt with the steering vector selected at the optimal layer. Ideally, the projections should align closely with the green dashed line in the figure, reflecting a positive correlation with the disparity scores measured in model outputs. Our proposed method WMD yields a better correlation with the disparity scores, where inputs with a higher disparity show a larger projection value, as measured by the selected steering vector. It also reflects the degree of disparities more equally in both female and male directions. While MD does capture the gender representations to some extent, it poorly reflects with inputs more associated with the maleness concept where $s_x<0$, as shown in \autoref{fig:projection-qwen7b} for \model{Qwen-7B} model. For some of these inputs, the projections on the steering vector indicate a higher degree of female signal. This imbalance in generalization may impact their steering performance, which we demonstrate this results in the next section.

