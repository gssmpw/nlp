\section{Analysis}
This section analyzes the impact of disparity score distribution and the choice of score threshold $\lambda$ on the resulting steering vectors' quality and intervention performance.

\subsection{Impact of Disparity Score Distribution}

\begin{figure}[bt]
    \centering
    \includegraphics[width=\linewidth]{figs/bias-distribution-1.pdf}
    \caption{Probability distribution of disparity scores over the entire training set from which the prompts used for extracting vectors are sampled.}
    \label{fig:bias-distribution}
\end{figure}

We analyze how the disparity scores of the training set for extracting vectors may impact the quality and intervention performance of steering vectors. \autoref{fig:bias-distribution} (and \autoref{fig:bias-distribution-2} in \autoref{app:bias-distribution}) shows the disparity score probability distribution over the entire training set for each model. Most models exhibit a similar tri-modal distribution pattern with three distinct peaks located around -1, 0, and 1, except for \model{Qwen-1.8B} which shows a unimodal distribution (see \autoref{fig:bias-distribution-2}).  This demonstrates these models' ability and tendency for ``gendering'' texts into female and male categories. We compute the mode intervals of the distribution using the SkinnyDip algorithm~\citep{maurus2016skinny}, based on the dip test of unimodality~\citep{hartigan1985dip}, as shown by the shaded areas in \autoref{fig:bias-distribution}. Our results suggest that models with a wider center modal interval, like \model{Llama-3.1-8B} and \model{OLMo-2-7B}, show less effective debiasing performance with steering (\autoref{tab:steering-performance}). Furthermore, we find that models with less prominent peaks in their distribution, such as \model{Llama-2-13B} and \model{Qwen} in \autoref{fig:bias-distribution-2}, also show a lower projection correlation in their steering vectors.


\subsection{Varying Disparity Score Threshold}
\label{sec:bias-threshold}

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{figs/threshold_test.pdf}
    \caption{Bias scores after intervention using steering vectors computed by eight different threshold scores for constructing the training set, where $\delta=[0.01,0.3]$.}
    \label{fig:varying-threshold}
\end{figure}

Results shown in both \autoref{sec:extract-results} and \autoref{sec:steering-results} are based on the same score threshold $\delta$ of 0.05. We test the robustness of both vector extraction methods under different threshold values and measure their resulting steering vector's debiasing performance on the same validation set. We use eight different values of $\delta$ from 0.01 to 0.3 with increasing increments. \autoref{fig:varying-threshold} shows the range of RMS bias scores after debiasing under different $\delta$ across all eight models. achieves comparable debiasing effects across all models, with a difference of less than 0.05 in bias scores for the same model. MD exhibits the largest discrepancy in bias scores for the \model{Llama-3.1-8B} model, with a difference of 0.1. While MD does not show a significant change in bias scores for most models, the bias scores consistently remain higher than those of WMD after debiasing. 

