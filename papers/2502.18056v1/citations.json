[
  {
    "index": 0,
    "papers": [
      {
        "key": "dosovitskiy_image_2021",
        "author": "Dosovitskiy, Alexey",
        "title": "An image is worth 16x16 words: Transformers for image recognition at scale"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "hubel_receptive_1959",
        "author": "Hubel, D. H. and Wiesel, T. N.",
        "title": "Receptive fields of single neurones in the cat's striate cortex"
      },
      {
        "key": "fukushima_neocognitron_1988",
        "author": "Fukushima, Kunihiko",
        "title": "Neocognitron: {A} hierarchical neural network capable of visual pattern recognition"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wu_cvt_2021",
        "author": "Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei",
        "title": "{CvT}: {Introducing} {Convolutions} to {Vision} {Transformers}"
      },
      {
        "key": "chen_visformer_2021",
        "author": "Chen, Zhengsu and Xie, Lingxi and Niu, Jianwei and Liu, Xuefeng and Wei, Longhui and Tian, Qi",
        "title": "Visformer: {The} {Vision}-friendly {Transformer}"
      },
      {
        "key": "yuan_incorporating_2021",
        "author": "Yuan, Kun and Guo, Shaopeng and Liu, Ziwei and Zhou, Aojun and Yu, Fengwei and Wu, Wei",
        "title": "Incorporating {Convolution} {Designs} into {Visual} {Transformers}"
      },
      {
        "key": "graham_levit_2021",
        "author": "Graham, Benjamin and El-Nouby, Alaaeldin and Touvron, Hugo and Stock, Pierre and Joulin, Armand and J{\\'e}gou, Herv{\\'e} and Douze, Matthijs",
        "title": "Levit: a vision transformer in convnet's clothing for faster inference"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "dosovitskiy_image_2021",
        "author": "Dosovitskiy, Alexey",
        "title": "An image is worth 16x16 words: Transformers for image recognition at scale"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "he2016deep",
        "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian",
        "title": "Deep residual learning for image recognition"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "xiao2021early",
        "author": "Xiao, Tete and Singh, Mannat and Mintun, Eric and Darrell, Trevor and Doll{\\'a}r, Piotr and Girshick, Ross",
        "title": "Early convolutions help transformers see better"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "hassani_escaping_2022",
        "author": "Hassani, Ali and Walton, Steven and Shah, Nikhil and Abuduweili, Abulikemu and Li, Jiachen and Shi, Humphrey",
        "title": "Escaping the big data paradigm with compact transformers"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "liu_sparse_2015",
        "author": "Liu, Baoyuan and Wang, Min and Foroosh, Hassan and Tappen, Marshall and Penksy, Marianna",
        "title": "Sparse {Convolutional} {Neural} {Networks}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "tian_designing_2023",
        "author": "Tian, Keyu and Jiang, Yi and Diao, Qishuai and Lin, Chen and Wang, Liwei and Yuan, Zehuan",
        "title": "Designing bert for convolutional networks: Sparse and hierarchical masked modeling"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "bao2021beit",
        "author": "Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu",
        "title": "Beit: Bert pre-training of image transformers"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "Devlin_BERTPO",
        "author": "Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova",
        "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "he2022masked",
        "author": "He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\\'a}r, Piotr and Girshick, Ross",
        "title": "Masked autoencoders are scalable vision learners"
      },
      {
        "key": "xie2020unsupervised",
        "author": "Xie, Qizhe and Dai, Zihang and Hovy, Eduard and Luong, Thang and Le, Quoc",
        "title": "Unsupervised data augmentation for consistency training"
      },
      {
        "key": "xie_simmim_2022",
        "author": "Xie, Zhenda and Zhang, Zheng and Cao, Yue and Lin, Yutong and Bao, Jianmin and Yao, Zhuliang and Dai, Qi and Hu, Han",
        "title": "{SimMIM}: a {Simple} {Framework} for {Masked} {Image} {Modeling}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "bao2021beit",
        "author": "Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu",
        "title": "Beit: Bert pre-training of image transformers"
      },
      {
        "key": "peng_beitv2_2022",
        "author": "Peng, Zhiliang and Dong, Li and Bao, Hangbo and Ye, Qixiang and Wei, Furu",
        "title": "Beit v2: Masked image modeling with vector-quantized visual tokenizers"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "zhou2021ibot",
        "author": "Zhou, Jinghao and Wei, Chen and Wang, Huiyu and Shen, Wei and Xie, Cihang and Yuille, Alan and Kong, Tao",
        "title": "ibot: Image bert pre-training with online tokenizer"
      },
      {
        "key": "oquab_dinov2_2024",
        "author": "Oquab, Maxime and Darcet, Timoth\u00e9e and Moutakanni, Th\u00e9o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Assran, Mahmoud and Ballas, Nicolas and Galuba, Wojciech and Howes, Russell and Huang, Po-Yao and Li, Shang-Wen and Misra, Ishan and Rabbat, Michael and Sharma, Vasu and Synnaeve, Gabriel and Xu, Hu and Jegou, Herv\u00e9 and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr",
        "title": "{DINOv2}: {Learning} {Robust} {Visual} {Features} without {Supervision}"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "assran2023self",
        "author": "Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas",
        "title": "Self-supervised learning from images with a joint-embedding predictive architecture"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "huang_self-supervised_2023",
        "author": "Huang, Shih-Cheng and Pareek, Anuj and Jensen, Malte and Lungren, Matthew P. and Yeung, Serena and Chaudhari, Akshay S.",
        "title": "Self-supervised learning for medical image classification: a systematic review and implementation guidelines"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "assran2023self",
        "author": "Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas",
        "title": "Self-supervised learning from images with a joint-embedding predictive architecture"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "he2022masked",
        "author": "He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\\'a}r, Piotr and Girshick, Ross",
        "title": "Masked autoencoders are scalable vision learners"
      }
    ]
  }
]