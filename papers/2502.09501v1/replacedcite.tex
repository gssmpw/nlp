\section{Related Work}
\textbf{Generalized Category Discovery (GCD)} draws similarity with novel category discovery (NCD) in both containing labeled and unlabeled images and aiming to discover novel categories in the unlabeled set. Initial GCD method____ learns representations by self-supervised contrastive learning on all data, along with supervised contrastive learning on labeled subset. SimGCD____ constructs an effective baseline using parametric classifier. A later variant $\mu$GCD____ improves SimGCD by using a teacher network to provide supervision for self-augmented image pairs. More recently, SPTNet____ learns spatial prompts as an alternative to adapt data for better alignment with the model. DCCL____ proposes to mine sample relations by generating dynamic conceptions using improved Infomap clustering____, followed by conception and instance-level contrastive learning. Similarly, GPC____ also estimates prototypes by Gaussian mixture model and a split-and-merge to take labeled instances into account. PromptCAL____ improves the ViT backbone by learning auxiliary prompts, as well as affinity propagation on KNN graph to estimate instance relation. Although labeled data is exploited to assist clustering in these methods, it is often taken as a pre- or post-clustering refinement. As such, the potential benefit of labeled instances are not fully exploited.  As a comparison, we fully incorporate the labeled data prior during every step of the association process, empowering reliable association of unlabeled data by taking advantage of the labeled instances as bridges. 



\noindent\textbf{Prototypical Contrastive Learning (PCL).}
In recent years, contrastive learning____ has proven as an effective technique for self-supervised learning____ and other settings____. In particular, prototypical contrastive learning compares instances with a set of prototypes encoding class-specific semantic structure, leading to discriminative embedding space. As such, many vision tasks have exploited PCL for method design. ProtoNCE____ combines instance-wise contrastive learning and multi-grained PCL for transfer learning. ____ adopt iterative clustering based PCL for object re-ID. A few methods____ in GCD have also considered PCL to learn discriminative representation. The critical issue for prototypical contrast is how to obtain representative prototypes, which then comes down to designing effective association strategy. Our method also adopts PCL, however, our better utilization of prior and design of semi-supervised association lead to more reliable prototypes, which in turn facilitates learning better representation.


\noindent\textbf{Data Clustering and Association.}
Clustering has long been used as a way to discover potential semantic groups within the data. Unsupervised clustering methods like K-Means____, DBSCAN____ and hierarchical clustering____ are widely used in many applications____. Semi-supervised clustering is also studied in some works____. Basu \textit{et al.}____ propose constrained K-Means by enforcing that labeled instances are assigned to their own cluster during K-Means iteration. COP-Kmeans____ modifies K-Means to make sure no constraints are violated when assigning instances. Constrained DBSCAN____ and hierarchical clustering____ are also considered. Metric-based methods____ modify the pairwise distance such that two instances with a "must-link" constraint have a lower distance, and those with a "cannot-link" constraint have a larger distance. Our proposed association is also constraint-based, but the constraints are enforced during a threshold-based group merging process, during which new categories are allowed to be discovered.