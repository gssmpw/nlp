\section{Related Works}
\label{sec:related-work}

We review related works in domain adaptation and Stein discrepancy, particularly the applications of the latter to machine learning and computational statistics. We refer the reader to \citep{liu2022deep} and \citep{anastasiou_steins_2023} for more comprehensive reviews of these topics.

\subsection{Domain Adaptation}

Foundational work for domain adaptation from \cite{ben-david_analysis_2007, ben-david_theory_2010} proved an upper bound for the generalization error in the target domain that depends on the error in the source domain and the distance between the source and target distributions.
% This aligns with an intuitive understanding of domain adaptation: if a model performs poorly on a dataset for which it has labels, it will likely perform poorly on a similar, unlabeled dataset.
% In addition, given a model trained on one dataset, we expect to get better results applying it to a similar dataset than to a totally unrelated one.
This bound motivated a large class of domain adaptation methods focused on feature alignment, learning feature representations that are invariant between domains but informative for classification.
The original bound used $\gH$-divergence to measure the distance between domains, but
$\gH$-divergence is difficult to estimate in practice, so later algorithms used other distances between distributions, including Wasserstein distance \citep{courty_joint_2017}, Jensen-Shannon divergence \citep{shui_novel_2022}, $\alpha$-R\'enyi distance \citep{mansour2009multiple}, and KL divergence \citep{nguyenkl}.
\Ac{mmd} was used for several \ac{uda} methods \citep{long_learning_2015, long_deep_2017, rozantsev2018beyond}, and is of particular interest because of connections between \ac{mmd} and \ac{ksd}.
Several methods also took an adversarial approach to domain adaptation \citep{ganin_unsupervised_2015,liu_coupled_2016, zhang_bridging_2019},
% Adversarial methods are formulated as a competition between a generator, which generates domain-invariant features, and a domain discriminator, which attempts to classify a sample as coming from the source or target domain, 
and they were later extended to conditional adversarial methods, inspired by conditional GANs \citep{long_conditional_2018}.
f-domain adversarial learning (FDAL) uses f-divergences to measure the distance between domains as part of an adversarial approach \cite{acuna2021f}.
% Conditional Domain Adversarial Networks (CDAN), inspired by conditional GANs, conditions the discriminator on cross-covariance of feature representations with classifier predictions, to capture which information is discriminative for the classifier \citep{long_conditional_2018}.
% In DANN, the same classifier is used for source and target samples, but other methods, such as Coupled Generative Adversarial Networks (CoGAN), propose decoupling some of the parameters between the source and target classifiers \citep{liu_coupled_2016}.
% Margin disparity discrepancy seeks to maximize the margin between each sample and the classification boundary \citep{zhang_bridging_2019}.
While adversarial methods are popular, challenges such as unstable training remain.
% Even with the same hyperparameters, adversarial models often achieve different levels of accuracy when retrained multiple times; to ameliorate this instability, the reported accuracy is often averaged over three training runs \citep{tllib, jiang2022transferability}.

There exist other types of domain adaptation methods, which can often be paired with feature alignment methods to boost accuracy.
Early but successful techniques included importance weighting, which emphasizes source samples that are similar to the target distribution \citep{pmlr-v28-gong13, Long_2014_CVPR}. % other references in confidence calibration paper
Another effective technique is pseudo-labeling target samples before training a classifier on the target domain \citep{sohn2020fixmatch}.
% another method with pseudo-labeling, Confidenc eregularized self-training, by Zou et al, 2019
% Li et. al propose minimizing class confusion to improve accuracy in both domains \cite{MCC}.
% Domain Adapted Neural Architecture Search (DA-NAS) proposed replacing the pre-trained neural networks that most methods use as feature extractors, such as ResNet, by an architecture tailored to extract transferable features \citep{li_da-nas_2024}.
Gradient harmonization, which seeks to resolve or reduce conflicts between the direction of the gradients from the two optimization goals, minimizing classification error and distance between domains, can boost performance by several percentage points on benchmark datasets \citep{huang_gradient_2024}.
Graph-based methods represent the source and target features as graphs and align the source and target domains by aligning characteristics of their graphs; graph spectral alignment (SPA) method attempts to align the graph spectra \citep{xiao2024spa}.

There are several other common domain adaptation settings besides \ac{uda}.
Semi-supervised domain adaptation has access to a small number of labels for the target distribution.
Multi-source domain adaptation attempts to leverage information from several source domains at once, while multi-target attempts to improve performance over several target domains \citep{zhao2020multisourcedomainadaptationdeep}.
Open set domain adaptation allows new classes in the target dataset that are not part of the source dataset \citep{panareda_busto_open_2017}.
Finally, domain generalization and few-shot learning are both similar to the scarce target setting for \ac{uda}.
Domain generalization extends multi-source \ac{uda} by assuming that there is no access to the target data set; the goal is to learn features that are invariant to unseen distributions \citep{wang_generalizing_2022}.
Domain generalization can be viewed as an extreme version of the scarce target setting, with no target data available, but does not leverage target information when it is available.
Few-shot learning can refer to a broad class of methods focused on learning from few data points; however, unlike the scarce target setting, the data in few-shot learning is usually labeled \citep{parnami2022learning}.


\subsection{Stein Discrepancy}

Stein's method was introduced to bound distances between probability distributions \citep{stein1972bound}. \citet{gorham_measuring_2015} built on this by formalizing Stein discrepancy as a measure of distributional difference, particularly for assessing approximate MCMC samples. Its key advantage is applicability to unnormalized distributions, making it valuable for Bayesian inference. Since then, Stein discrepancies have gained popularity in machine learning and statistics. 
Originally, computing Stein discrepancies involved a maximization step, 
but
\citet{liu_kernelized_2016}, \citet{chwialkowski_kernel_2016}, and \citet{gorham2017measuring} 
independently developed the \ac{ksd}, which provides a closed-form solution using \ac{rkhs}. \citet{gorham2017measuring} also established theoretical conditions under which convergence in \ac{ksd} guarantees weak convergence between distributions.
They demonstrated that in dimensions $d \geq 3$, commonly used kernels such as Gaussian and Mat√©rn fail to detect when a sample is not converging to the target, highlighting the importance of kernel choice in practical applications. 
Stein discrepancies have been widely adopted for constructing sample approximations, leading to influential methods such as Stein Variational Gradient Descent (SVGD) \citep{liu_stein_2019}, which iteratively updates sample locations; Stein points \citep{chen2018stein}, which constructs sample sets sequentially; and Stein thinning \citep{riabiz2022optimal}, which compresses existing samples, all aiming to minimize \ac{ksd}. 
More recently, \ac{ksd} has been extended to non-parametric settings, where the score function of an implicit model is estimated. This extension has enabled the development of two-sample tests for implicit generative models, a crucial tool in machine learning. Since such models can generate unlimited synthetic data while real datasets remain limited, these tests must handle unbalanced sample sizes \citep{xu_kernelised_2022}. This imbalance is analogous to our scarce target setting, where target domain samples are also limited compared to the source domain.