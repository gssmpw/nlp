[
  {
    "index": 0,
    "papers": [
      {
        "key": "o1card",
        "author": "OpenAI",
        "title": "O1 System Card"
      },
      {
        "key": "o3minicard",
        "author": "OpenAI",
        "title": "O3 Mini System Card"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "o1card",
        "author": "OpenAI",
        "title": "O1 System Card"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "o3minicard",
        "author": "OpenAI",
        "title": "O3 Mini System Card"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wang2023not",
        "author": "Wang, Yuxia and Li, Haonan and Han, Xudong and Nakov, Preslav and Baldwin, Timothy",
        "title": "Do-not-answer: A dataset for evaluating safeguards in llms"
      },
      {
        "key": "bhatt2024cyberseceval",
        "author": "Bhatt, Manish and Chennabasappa, Sahana and Li, Yue and Nikolaidis, Cyrus and Song, Daniel and Wan, Shengye and Ahmad, Faizan and Aschermann, Cornelius and Chen, Yaohui and Kapil, Dhaval and others",
        "title": "Cyberseceval 2: A wide-ranging cybersecurity evaluation suite for large language models"
      },
      {
        "key": "wan2024cyberseceval",
        "author": "Wan, Shengye and Nikolaidis, Cyrus and Song, Daniel and Molnar, David and Crnkovich, James and Grace, Jayson and Bhatt, Manish and Chennabasappa, Sahana and Whitman, Spencer and Ding, Stephanie and others",
        "title": "Cyberseceval 3: Advancing the evaluation of cybersecurity risks and capabilities in large language models"
      },
      {
        "key": "li2024salad",
        "author": "Li, Lijun and Dong, Bowen and Wang, Ruohui and Hu, Xuhao and Zuo, Wangmeng and Lin, Dahua and Qiao, Yu and Shao, Jing",
        "title": "Salad-bench: A hierarchical and comprehensive safety benchmark for large language models"
      },
      {
        "key": "xie2024sorry",
        "author": "Xie, Tinghao and Qi, Xiangyu and Zeng, Yi and Huang, Yangsibo and Sehwag, Udari Madhushani and Huang, Kaixuan and He, Luxi and Wei, Boyi and Li, Dacheng and Sheng, Ying and others",
        "title": "Sorry-bench: Systematically evaluating large language model safety refusal behaviors"
      },
      {
        "key": "zeng2024air",
        "author": "Zeng, Yi and Yang, Yu and Zhou, Andy and Tan, Jeffrey Ziwei and Tu, Yuheng and Mai, Yifan and Klyman, Kevin and Pan, Minzhou and Jia, Ruoxi and Song, Dawn and others",
        "title": "Air-bench 2024: A safety benchmark based on risk categories from regulations and policies"
      },
      {
        "key": "andriushchenko2024agentharm",
        "author": "Andriushchenko, Maksym and Souly, Alexandra and Dziemian, Mateusz and Duenas, Derek and Lin, Maxwell and Wang, Justin and Hendrycks, Dan and Zou, Andy and Kolter, Zico and Fredrikson, Matt and others",
        "title": "Agentharm: A benchmark for measuring harmfulness of llm agents"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "rottger2023xstest",
        "author": "R{\\\"o}ttger, Paul and Kirk, Hannah Rose and Vidgen, Bertie and Attanasio, Giuseppe and Bianchi, Federico and Hovy, Dirk",
        "title": "Xstest: A test suite for identifying exaggerated safety behaviours in large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wan2024cyberseceval",
        "author": "Wan, Shengye and Nikolaidis, Cyrus and Song, Daniel and Molnar, David and Crnkovich, James and Grace, Jayson and Bhatt, Manish and Chennabasappa, Sahana and Whitman, Spencer and Ding, Stephanie and others",
        "title": "Cyberseceval 3: Advancing the evaluation of cybersecurity risks and capabilities in large language models"
      },
      {
        "key": "bhatt2024cyberseceval",
        "author": "Bhatt, Manish and Chennabasappa, Sahana and Li, Yue and Nikolaidis, Cyrus and Song, Daniel and Wan, Shengye and Ahmad, Faizan and Aschermann, Cornelius and Chen, Yaohui and Kapil, Dhaval and others",
        "title": "Cyberseceval 2: A wide-ranging cybersecurity evaluation suite for large language models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "andriushchenko2024agentharm",
        "author": "Andriushchenko, Maksym and Souly, Alexandra and Dziemian, Mateusz and Duenas, Derek and Lin, Maxwell and Wang, Justin and Hendrycks, Dan and Zou, Andy and Kolter, Zico and Fredrikson, Matt and others",
        "title": "Agentharm: A benchmark for measuring harmfulness of llm agents"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "yi2023benchmarking",
        "author": "Yi, Jingwei and Xie, Yueqi and Zhu, Bin and Kiciman, Emre and Sun, Guangzhong and Xie, Xing and Wu, Fangzhao",
        "title": "Benchmarking and defending against indirect prompt injection attacks on large language models"
      },
      {
        "key": "zhan2024injecagent",
        "author": "Zhan, Qiusi and Liang, Zhixiang and Ying, Zifan and Kang, Daniel",
        "title": "Injecagent: Benchmarking indirect prompt injections in tool-integrated large language model agents"
      },
      {
        "key": "zhang2024agent",
        "author": "Zhang, Hanrong and Huang, Jingyuan and Mei, Kai and Yao, Yifei and Wang, Zhenting and Zhan, Chenlu and Wang, Hongwei and Zhang, Yongfeng",
        "title": "Agent security bench (asb): Formalizing and benchmarking attacks and defenses in llm-based agents"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wei2024jailbroken",
        "author": "Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob",
        "title": "Jailbroken: How does llm safety training fail?"
      },
      {
        "key": "jiang2024wildteaming",
        "author": "Jiang, Liwei and Rao, Kavel and Han, Seungju and Ettinger, Allyson and Brahman, Faeze and Kumar, Sachin and Mireshghallah, Niloofar and Lu, Ximing and Sap, Maarten and Choi, Yejin and others",
        "title": "WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models"
      },
      {
        "key": "zhu2024autodan",
        "author": "Zhu, Sicheng and Zhang, Ruiyi and An, Bang and Wu, Gang and Barrow, Joe and Wang, Zichao and Huang, Furong and Nenkova, Ani and Sun, Tong",
        "title": "AutoDAN: interpretable gradient-based adversarial attacks on large language models"
      },
      {
        "key": "li2024llm",
        "author": "Li, Nathaniel and Han, Ziwen and Steneker, Ian and Primack, Willow and Goodside, Riley and Zhang, Hugh and Wang, Zifan and Menghini, Cristina and Yue, Summer",
        "title": "Llm defenses are not robust to multi-turn human jailbreaks yet"
      },
      {
        "key": "liu2024autodan",
        "author": "Liu, Xiaogeng and Li, Peiran and Suh, Edward and Vorobeychik, Yevgeniy and Mao, Zhuoqing and Jha, Somesh and McDaniel, Patrick and Sun, Huan and Li, Bo and Xiao, Chaowei",
        "title": "Autodan-turbo: A lifelong agent for strategy self-exploration to jailbreak llms"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zou2023universal",
        "author": "Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      },
      {
        "key": "liao2024amplegcg",
        "author": "Liao, Zeyi and Sun, Huan",
        "title": "Amplegcg: Learning a universal and transferable generative model of adversarial suffixes for jailbreaking both open and closed llms"
      }
    ]
  }
]