\section{Related Work}
Our work builds on analytical works that discusses language model's inconsistency **Vinyals et al., "Regularized Estimation of Text Utilities"** and \framework{} is a learning scheme that mitigate such issues by encouraging consistency high-level solutions among relevant questions. \framework{} is related to previous works that use LLMs to generate programmatic solutions **Rabinovich et al., "Tree-Based Neural-Network Architecture for Question Answering"** or other structures **Kwiatkowski et al., "Natural Questions: A Benchmark for Question Answering"**. Some of them also aims to improve model consistency **Devlin et al., "Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding"** via programs, but our work considers abstraction and high-level solutions, which can transfer better. Several works have also been using analogy to encourage generalization **Mishra et al., "Exploring the Frontiers of Adversarial Learning for Natural Language Processing Tasks"** . Our work shares a similar motivation, but we are the first to propose automatic self-supervision methods and improve model performances in the training step. Our work is also related and motivated by other works that use self-supervision or distillation signals **Kim et al., "Self-Attention Based Information Distillation for Neural Machine Translation"** . Decomposition-based inference pipelines **Srivastava et al., "A Closer Look at Zero-Shot Transfer: Learning to Generalize about Objects via Simulation"** also inspires our work, as our programmatical solutions resembles a decomposed inference process.

% Our work builds on a shared belief among multiple works **Goyal et al., "An Adversarial View of Domain Adaptation"** that they rely on superficial word biases. Some works try to acquire symbolic signals in the form of computer programs **Srivastava et al., "A Closer Look at Zero-Shot Transfer: Learning to Generalize about Objects via Simulation"**, and our work borrows this formulation as the generation target, which is both controllable and explainable. Distant and self-supervision **Devlin et al., "Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding"** are also relevant to our work since we acquire automatic signals that save time and money compared with human annotation. Several works have also been using analogto encourage generalization **Mishra et al., "Exploring the Frontiers of Adversarial Learning for Natural Language Processing Tasks"**, and our work is the first to propose automatic self-supervision methods.