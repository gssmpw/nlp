\section{Limitations}

One limitation of \tdd is that it is mined from 12 popular Python
repositories, so our findings may not apply to other programming
languages and repositories.  We note that SWE-bench, despite having
the same limitation, has been impactful, and one of the findings in
the SWE-bench paper is that ``difficulty does not correlate with issue
resolution date'', indicating that contamination problems (if any) are
minor~\cite{jimenezswe}.  Our results on data contamination
(\S\ref{sec:rq7}) indicate the same thing.
% We did not see such co-relation in our experiment also.
A limitation of \solx is that it considers only one test file and
generates only one block of code.  In real-world projects, test code
can be spread across multiple files or blocks of code.
% \solx  cannot generate tests that must be written across multiple files.
Despite that, \solx exceeded the state-of-the-art performance, so we
leave further improvements to future work.  We use the Python
\texttt{\small coverage} package for computing test coverage, but this
package can fail for various reasons, such as permission issues,
version incompatibility, or configuration problems. In \solx, we
computed coverage for all projects, including SymPy. However, upon
manual validation, we found the coverage information for SymPy to be
unreliable. Therefore, we removed coverage from the final
$\mathit{tddScore}$ metric for SymPy instances ($<\!\!15\%$ of the
total instances).  Note that coverage does not affect the reported
fail-to-pass scores.
% Given that coverage for fail-to-pass tests was consistently above 0.9 and fewer than 15\% of instances came from SymPy, this likely makes $<1.5$\% difference for the results.
