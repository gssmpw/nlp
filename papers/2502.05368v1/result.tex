\section{Evaluation}

We conducted an extensive set of empirical studies, evaluating the effectiveness
of our approach (\S\ref{sec:rq1}) and the components of \solx and \soly
(\S\ref{sec:rq2}), comparing our approach against existing techniques
(\S\ref{sec:rq3}), and investigating the cost effectiveness of \solx
(\S\ref{sec:rq4}), characteristics of the generated tests (\S\ref{sec:rq5}),
usefulness of the generated tests in supporting automated program repair
(\S\ref{sec:rq6}), and possible effects of data contamination (\S\ref{sec:rq7}).

\subsection{Experiment Setup}
\label{sec:setup}

The evaluation used the closed-source GPT-4o~(gpt-4o-2024-08-06)
and the open-source Mistral-large model~(123 billion parameters).
All experiments used greedy decoding. For each instance, \solx makes 7--11 LLM
calls for T1. \soly makes one additional call for each of the other four tests (T2-T5) after the
localization stage. To evaluate using the generated tests for SWE agents, we conducted a large-scale
experiment with 22 systems from the SWE-Bench leaderboard. We ran \mbox{22 × 449 × 5 =
49,390 Docker} containers or tests (one Docker container per test) to report the
results.


\subsection{Effectiveness of \solx, \soly, and the Baseline}
\label{sec:rq1}

\cref{tbl:otter} shows that GPT-4o-based \solx and \soly perform well on test
generation, creating fail-to-pass tests for 31.4\% and 37\% of the instances,
respectively, whereas the baseline produced such tests for 18.7\% of the
instances. The improvements are also reflected in $\mathit{tddScore}$,
a metric that blends fail-to-pass rate with coverage~\cite{ahmed2024tdd}. We
observe similar performance improvements with Mistral-large. The pass@5 rate
(where one of the five tests is fail-to-pass) for \soly is 44\% for GPT-4o and 37\%
for Mistral-large.


\begin{table}[t]
\centering
\caption{Performance of \solx, \soly, and baseline technique on TDD-Bench-Verified.}
\vskip 0.05in
\resizebox{.8\columnwidth}{!}{%
\renewcommand{\arraystretch}{1.2}% Tighter
\begin{tabular}{llrrr}
\toprule
\multicolumn{1}{c}{Model}      & \multicolumn{1}{c}{Approach} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\# of fail-to-pass\\ test\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\# of fail-to-pass\\ test in (\%)\end{tabular}} & \multicolumn{1}{c}{tddScore} \\ \midrule
\multirow{3}{*}{Mistral-Large} & Zero-shot                    & 57                                                                                   & 12.7                                                                                          & 11.8                         \\
                               & \solx                       & 121                                                                                   & 26.9                                                                                          & 25.1                          \\
                               & \soly                     & 144                                                                                   & 32.1                                                                                          & 28.6                        \\ \midrule
                              % & \soly (pass@5)                     & 170                                                                                   & 37.9                                                                                          & -                        \\ \midrule

\multirow{3}{*}{GPT-4o}         & Zero-shot                    & 99                                                                                    & 18.7                                                                                         & 17.2                         \\
                               & \solx                       & 141                                                                                   & 31.4                                                                                          & 29.4                          \\
                                & \soly                      & 166                                                                                   & 37.0                                                                                          & 32.4          \\  \bottomrule    
                                
                                %& \soly (pass@5)                       & 197                                                                                   & 43.9                                                                                         & -          \\ \bottomrule              
\end{tabular}}
\label{tbl:otter}
%\vspace{-15pt}
\end{table}


\subsection{Ablation Study}
\label{sec:rq2}

\cref{tbl:ablation} shows the ablation study for \solx (T1). We also present the
individual performance for the other four tests~(T2--T5) produced by \soly. We
can see that all the components contribute to \solx's performance. Without
action planning, we lose more than 14\%--20\% of fail-to-pass tests for GPT-4o
and 21\%--36\% of the tests for Mistral-large.

%\begin{table*}[t]
%\centering
%\caption{Contribution of each component of \solx.}
%\vskip 0.15in
%\resizebox{.75\textwidth}{!}{%
%\renewcommand{\arraystretch}{1.2}% Tighter
%\begin{tabular}{lrrrrrr}
%\toprule
%\multicolumn{1}{c}{\multirow{2}{*}{Appraoch}} & \multicolumn{3}{c}{GPT-4o}                                                                                                                                        & \multicolumn{3}{c}{Mistral-Large}                                                                                                                                \\
%\multicolumn{1}{c}{}                          & \multicolumn{1}{c}{\# of fail-to-pass} & \multicolumn{1}{c}{tddScore} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Change in\\  tddScore in (\%)\end{tabular}} & \multicolumn{1}{c}{\# of fail-to-pass} & \multicolumn{1}{c}{tddScore} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Change in\\ tddScore in (\%)\end{tabular}} \\ \midrule
%\solx (T1)                                        & 141                                    & 29.4                         & NA                                                                                        & 121                                    & 25.7                         & NA                                                                                       \\
%\solx - Action Planning* (T2)                     & 110                                    & 23.6                         & -19.7                                                                                     & 96                                     & 20.2                         & -21.4                                                                                    \\
%\solx - Focal Localization* (T3)                   & 115                                    & 25.2                         & -14.3                                                                                     & 96                                     & 20.2                         & -21.4                                                                                    \\
%\solx - Test Localization*  (T4)                 & 107                                    & 24.2                         & -17.7                                                                                     & 77                                     & 16.5                         & -35.8                                                                                    \\
%\solx -  Focal \& Test Localization* (T5)         & 110                                    & 24.2                         & -17.7                                                                                     & 81                                     & 17.2                         & -33.1                                                                                    \\
%\solx - Fixing Import                         & 128                                    & 26.7                         & -9.2                                                                                      & 117                                    & 24.6                         & -4.3                                                                                     \\
%\solx - Imports at Generation                 & 130                                    & 26.7                         & -9.2                                                                                      & 114                                    & 23.7                         & -7.8                                                                                     \\ \bottomrule
%\multicolumn{7}{l}{* is not followed by action planning}                                                                                                                                                                                                                                                                                                                          
%\end{tabular}}
%\label{tbl:ablation}
%\end{table*}

%\multicolumn{4}{l}{* is not followed by action planning}   

\begin{table}[t]
\centering
\caption{Contribution of each component of \solx.}
\vskip 0.05in
\resizebox{.95\columnwidth}{!}{%
\renewcommand{\arraystretch}{1.2}% Tighter
\begin{tabular}{llrrr}
\toprule
\multicolumn{1}{c}{Model}      & \multicolumn{1}{c}{Approach}         & \multicolumn{1}{c}{\# of fail-to-pass} & \multicolumn{1}{c}{tddScore} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Change in  \\ tddScore\%\end{tabular}} \\ \midrule
\multirow{7}{*}{Mistral-large} & Otter (T1)                                & 121                                    & 25.7                         & NA                                                                                   \\
                               & Otter -- Action Planning* (T2)                & 96                                     & 20.2                         & -21.4                                                                                \\
                               & Otter -- Focal Localization* (T3)           & 96                                     & 20.2                         & -21.4                                                                                \\
                               & Otter -- Test Localization* (T4)            & 77                                     & 16.5                         & -35.8                                                                                \\
                               & Other -  Focal \& Test Localization* (T5)   & 81                                     & 17.2                         & -33.1                                                                                \\
                               & Otter -- Fixing Import                & 117                                    & 24.6                         & -4.3                                                                                 \\
                               & Otter -- Imports at Generation        & 114                                    & 23.7                         & -7.8                                                                                 \\ \midrule
\multirow{7}{*}{GPT-4o}        & Otter (T1)                                 & 141                                    & 29.4                         & NA                                                                                   \\
                               & Otter -- Action Planning* (T2)              & 110                                    & 23.6                         & -19.7                                                                                \\
                               & Otter -- Focal Localization* (T3)          & 115                                    & 25.2                         & -14.3                                                                                \\
                               & Otter -- Test Localization* (T4)            & 107                                    & 24.2                         & -17.7                                                                                \\
                               & Other -  Focal \& Test Localization* (T5)  & 110                                    & 24.2                         & -17.7                                                                                \\
                               & Otter -- Fixing Import                & 128                                    & 26.7                         & -9.2                                                                                 \\
                               & Otter -- Imports at Generation        & 130                                    & 26.7                         & -9.2         \\ \bottomrule        
                               \multicolumn{4}{l}{* is not followed by action planning}                                                                   
\end{tabular}}
\label{tbl:ablation}
%\vspace{-12pt}
\end{table}



\subsection{Comparison with the Approaches of M{\"u}ndler \etal}
\label{sec:rq3}

\citet{mundler2024swtbench} proposed a set of approaches for
generating fail-to-pass tests. We ran \solx and \soly on their dataset to study
how the approaches compare. They also evaluated zero-shot approaches, which
differ from our zero-shot baseline. Instead of generating a complete function,
all of their approaches (including the zero-shot ones) instruct the model to
generate a specific form of ``diff''. Two of their approaches use a golden patch
in the prompt. M{\"u}ndler \etal's SWE-agent and SWE-agent+ approaches are
derived from SWE-Agent, which was originally designed for generating golden code
patches~\cite{sweagent2}. \cref{tbl:swt} shows the results. \solx and \soly
perform better than their best-performing approach, generating 70 (25.4\%) and
80 (29.0\%) fail-to-pass tests compared to 53 (19.2\%) fail-to-pass tests
generated by SWE-agent+.


\begin{table}[t]
\centering
\caption{Comparing with approaches proposed by M{\"u}ndler
  \etal~\cite{mundler2024swtbench} on the 276 instances of SWT-Lite.}
%(not \tdd).}
\vskip 0.05in
\resizebox{.7\columnwidth}{!}{%
\renewcommand{\arraystretch}{1.2}% Tighter
\begin{tabular}{lrr}
\toprule
\multicolumn{1}{c}{Approach} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\# of Fail-to-pass \\ Tests\end{tabular}} & \multicolumn{1}{c}{in (\%)} \\ \midrule
ZeroShot                     & 16                                                                                          & 5.8                        \\
ZeroShotPlus*                & 28                                                                                         & 10.1                        \\
LIBRO*                      & 42                                                                                         & 15.2                         \\
AutoCodeRover                & 25                                                                                         & 9.1                         \\
SWE-Agent                    & 46                                                                                         & 16.7                         \\
SWE-Agent+                   & 53                                                                                         & 19.2                       \\ \midrule
\textbf{\solx} (GPT-4o)                     & \textbf{70}                                                                                         & \textbf{25.4}  \\
\textbf{\soly}  (GPT-4o)                     & \textbf{80}                                                                                         & \textbf{29.0}  \\  \bottomrule
%\textbf{\soly (pass@5)}                      & \textbf{105}                                                                                         & \textbf{38.0}  \\ \bottomrule
\multicolumn{3}{l}{* follows ``write first, test later'' approach} 
\end{tabular}
}
\label{tbl:swt}
%\vspace{-15pt}
\end{table}


\subsection{Cost Effectiveness of \solx}
\label{sec:rq4}

\cref{tbl:cost} presents the cost for invoking the GPT-4o model to process 449
instances with \solx. Each sample requires an average of \$0.06.
%Note that apart from the ``Reflect and Improve the Plan'' step, we make a total of 6 calls. 
The ``reflect and improve the plan'' step can make 1--5 LLM
calls. \cref{fig:turn} shows that, for more than 80\% of the instances, both
GPT-4o and Mistral are satisfied within two calls. Therefore, the total calls
vary from 7--8 for most instances. The cost is very low because we do not
accumulate context from prior calls in subsequent calls.
%However, the models generate fail-to-pass tests even with more than 2 turns at the ``reflect and Improve the plan'' steps. 
We do not discuss the cost for Mistral-large because the model was
hosted locally.  \soly makes additional four calls and reuses the output from
localizers. The total cost for \soly~(which includes \solx) is \$0.09 per instance.



\begin{table}[t]
\centering
\caption{Cost for running \solx and \soly with GPT-4o.}
\vskip 0.05in
\resizebox{.7\columnwidth}{!}{%
\renewcommand{\arraystretch}{1.2}% Tighter
\begin{tabular}{lrr}
\toprule
\multicolumn{1}{c}{Component} & \multicolumn{1}{c}{Cost} & \multicolumn{1}{c}{Cost/Sample} \\ \midrule
Focal Localization            & \$8.61                   & \$0.02                          \\
Test Localization             & \$9.63                   & \$0.02                          \\
Action + Generate             & \$10.94                  & \$0.02                          \\
\textbf{Total for \solx}               & \textbf{\$29.18}                  & \textbf{\$0.06}                          \\ \midrule
Additional Tests (T2-T5)      & \$11.20                  & \$0.02                          \\
\textbf{Total for \soly}             & \textbf{\$40.38}                  & \textbf{\$0.09}           \\ \bottomrule               
\end{tabular}}
\label{tbl:cost}
%\vspace{-10pt}
\end{table}




\begin{figure}[!htp]
    \centering
    \includegraphics[width=\columnwidth]{turn.pdf}
    \vspace{-10pt}
    \caption{Number of turns taken in the ``Reflect and Improve the Plan'' step.}
    \label{fig:turn}
    %\vspace{-15pt}
\end{figure}


\subsection{Characteristics of the Generated Tests}
\label{sec:rq5}

\paragraph{Coverage of the generated tests.}

We compared the coverage achieved by the \solx-generates tests and the golden
tests written by developers. We observe that, for the fail-to-pass tests,
\solx-generated and golden tests have very similar and high coverage---more than
90\% with both models (\cref{tbl:coverage}). However, for the other tests, the
coverage is quite low for \solx. This indicates that tests with higher coverage
are more likely to be fail-to-pass tests.

\begin{table}[t]
\centering
\caption{Comparing the coverage of model-generated and developer-written tests.}
\vskip 0.05in
\resizebox{.7\columnwidth}{!}{%
\renewcommand{\arraystretch}{1.2}% Tighter
\begin{tabular}{llrr}
\toprule
\multicolumn{1}{c}{Model}      & \multicolumn{1}{c}{Is Fail-to-pass?} & \multicolumn{1}{c}{Otter} & \multicolumn{1}{c}{Golden test} \\ \midrule

\multirow{2}{*}{Mistral-large} & Yes                                  & 93.1                      & 95.5                            \\
                               & No                                   & 63.8                      & 93.4                 \\  \midrule
                               
 \multirow{2}{*}{GPT-4o}        & Yes                                  & 93.7                      & 95.6                            \\
                               & No                                   & 60.0                      & 93.3                            \\                              
                               
                               
                               \bottomrule           
\end{tabular}}
\label{tbl:coverage}
%\vspace{-10pt}
\end{table}







\paragraph{Prompts complementarity.}

\cref{fig:venn} presents the overlap among instances for which fail-to-pass
tests could be generated by different prompts using the GPT-4 model. Overall,
each of the prompts is successful on some instances on which the other prompts
fail, with T1 (\solx with GPT-4o) achieving the most success in this
respect---producing fail-to-pass tests for 24 instances on which none of the
other prompts succeeded in generating such tests. Thus, combining the results
from the different prompts increases the fail-to-pass rate to 44\% (38\% for
Mistral) at pass@5. This indicates the benefit of incorporating different
prompts for test generation.


\begin{figure}[t]
    \centering
    \includegraphics[width=.8\columnwidth]{venn5.pdf}
    \vspace{-10pt}
    \caption{Number of instances with fail-to-pass tests generated by different prompts.}
    %\vspace{-15pt}
    \label{fig:venn}
\end{figure}





% \subsection{Test generation and Code Repair}
\subsection{Test Generation and SWE Agents}
\label{sec:rq6}

%\subsubsection{Filtering Code Fixes with Tests }

The tests generated by our approach can be used for filtering bad code patches and
increasing the precision of solutions proposed by different systems from the
SWE-bench Verified leaderboard. We take the top 22 systems from the leaderboard
and run the five tests generated by \soly. We filter out a code patch if all the
tests fail on it. Figure~\ref{fig:precision} shows that we have achieved a
precision of 65\% to 92\% while maintaining a decent recall of 30\%-41\%, except
for one system where the precision increased by 22\% to 167\%. Note that
M{\"u}ndler \etal~\cite{mundler2024swtbench} achieved 47.8\% precision at 20\%
recall on SWE-Agent.
Using tests generated by \soly achieved much higher precision while maintaining
greater recall with 22 systems.

\begin{figure}[!t]
    \centering
    \includegraphics[width=\columnwidth]{precision.pdf}
    \vspace{-10pt}
    \caption{Precision of all 22 systems from the leaderboard. Recall is also mentioned at the top of each bar.}
    %\vspace{-5pt}
    \label{fig:precision}
\end{figure}


%\subsubsection{TBM: Ensemble on Lederboard}
%\subsubsection{Correlation between Test Generation and Code Repair}





\subsection{Effect of Data Contamination}
\label{sec:rq7}

As TDD-Bench-Verified is based on historic GitHub issues, they may be included
in the pre-training data of the LLMs we use. To see whether the model simply
generates memorizes tests, we performed two different experiments.

%\subsubsection{Based on Model Data Cut-off Date} 
\paragraph{Model data cut-off date.}

The cutoff date for the GPT-4o model is October 2023. Unfortunately, we have
only one sample dated post-cutoff and could not compare the two groups.  Popular
GitHub repositories evolve quickly. It is likely that only the snapshot taken
during the data collection process was seen by the model and that it performed
well on a specific year of data.  \cref{fig:year} shows the total and
fail-to-pass test distribution by year.  We did not observe any pattern in
performance among the distributions by year.  For example, for 2020, 2021, and
2023, we have very similar performance by the model.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{Year.pdf}
    \vspace{-15pt}
    \caption{Sample distribution of total and fail-to-pass tests by year.}
    %\vspace{-15pt}
    \label{fig:year}
\end{figure}


%\subsubsection{Based on Test Similarity}
\paragraph{Test similarity.}

We conducted another experiment following the approach of
\citet{schafer2023empirical}. We take the generated test from Otter and compute
the similarity score with the most similar test from the repository. We compute
the score between the generated test and all existing tests as follows: $max_{tp
  \in TP}(1-\frac{dis(t^{*},t_{p})}{max(len(t^{*}),len(t_{p}))})$, where $TP$ is
the set of test functions and $t^*$ is the generated test.
Figure~\ref{fig:write_contamination} shows the similarity scores for new
tests. For 90\% of the instances, the similarity score is less than 0.6. We
share some samples with more than 0.5 similarity in
Table~\ref{tbl:similarity_example} (in the appendix) to give the reader some
idea. From our observation, even at similarity score of 0.7, the tests are
significantly different. As expected, for modified tests, the similarity is
higher. However, we did not observe any difference between fail-to-pass tests
and other tests (see Appendix for figures). Therefore, we believe that the model
is not simply generating memorized tests.


\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{write_contamination.pdf}
    \vspace{-10pt}
    \caption{Cumulative percentage of \solx-generated new tests, using
      GPT-4o, with maximum similarity less than the similarity value
      shown on the x-axis.}
    %\vspace{-10pt}
    \label{fig:write_contamination}
\end{figure}














































%\begin{enumerate}
%
%
%\item Coverage comparison between generated test patch \& golden test patch on the leaderboard
%\item Correlation of Test Generation and Code Repair
%\item Effect of Issue Description Length
%\item Method Complimentarity
%
%\item Precision increase
%\item Ensemble from the leaderboard
%
%\item data contamination *** Refer to swt-bench
%\end{enumerate}












