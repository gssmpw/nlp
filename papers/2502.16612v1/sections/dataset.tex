\section{Dataset}
\label{sec:dataset}
% \todo[inline]{Arid/Firoj}
% \noindent
\subsection{ArMeme}
The ArMeme dataset aimed to address the scarcity of Arabic-language datasets for multimodal propaganda detection. It comprises approximately $\sim$6k Arabic memes collected from various social media platforms, each manually annotated to identify propagandistic content \cite{alam-etal-2024-armeme}. This dataset has been collected from different social media platforms, filtered, cleaned and manually annotated with four labels such as \textit{Not propaganda}, \textit{Propaganda}, \textit{Not-meme} and \textit{Other}. Table \ref{tab:data_split_stat} provides the distribution of the data splits. The memes with ``Not propaganda'' category covers over half of the dataset ($\sim$66\%), followed by ``Propaganda'' and the distribution of ``Not-meme`` and ``Other`` classes are significantly smaller. This distribution highlights a substantial class imbalance, particularly between ``Not propaganda'' and the other categories. 

% By providing this resource, the authors aim to enhance media literacy and support the development of AI-based automatic systems tailored for medium to low-resource languages.
% \firoj{@Arid, please add label distribution...}

\begin{table}[h]
\centering
\setlength{\tabcolsep}{3pt} 
\scalebox{0.95}{%
\begin{tabular}{@{}lrrrr@{}}
\toprule
\multicolumn{1}{c}{\textbf{Class label}} & \multicolumn{1}{c}{\textbf{Train}} & \multicolumn{1}{c}{\textbf{Dev}} & \multicolumn{1}{c}{\textbf{Test}} & \multicolumn{1}{c}{\textbf{Total}} \\ \midrule
Not propaganda & 2,634 & 384 & 746 & 3,764 \\
Propaganda & 972 & 141 & 275 & 1,388 \\
Not-meme & 199 & 30 & 57 & 286 \\
Other & 202 & 29 & 56 & 287 \\ \midrule
\textbf{Total} & \textbf{4,007} & \textbf{584} & \textbf{1,134} & \textbf{5,725} \\ \bottomrule
\end{tabular}
}
\caption{Data splits for ArMeme datasets.}
\label{tab:data_split_stat}
\end{table}


\subsection{Hateful Meme}
% The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes
The Hateful Memes dataset~\cite{kiela2020hateful}, is a benchmark designed to evaluate multimodal hate speech detection. It consists of $\sim$12k memes, combining both text and images, carefully curated to ensure that effective classification requires an understanding of both modalities. The dataset was created using a mix of synthetically generated memes and real-world examples, sourced from social media, while ensuring a balanced distribution of hateful and non-hateful content. A key feature of this dataset is the inclusion of benign confounders, where individual elements of a hateful meme—either the image or the text—are altered to make it non-hateful. This approach prevents unimodal models (which rely only on text or images) from achieving high performance, reinforcing the need for true multimodal understanding. In Table \ref{tab:data_stat_hateful_meme}, we report the distribution of hateful meme dataset used for this study. Note that hateful meme dataset consists of two other splits (dev-seen and test-seen), here, we used unseen versions. 


% \firoj{@Arid, please add label distribution...}
% Each meme is labeled as hateful or non-hateful, and the dataset is split into training (8,500 samples), validation (500 samples), and test (1,000 samples) sets. The authors also provide human performance benchmarks, showing that humans achieve an accuracy of 84.7\%, while even strong multimodal models lag behind, indicating the complexity of the task.

\begin{table}[h]
\centering
\setlength{\tabcolsep}{3pt} 
\scalebox{0.9}{%
\begin{tabular}{@{}lrrrr@{}}
\toprule
\multicolumn{1}{c}{\textbf{Class Label}} & \multicolumn{1}{c}{\textbf{Train}} & \multicolumn{1}{c}{\textbf{Dev-seen}} & \multicolumn{1}{c}{\textbf{Test-seen}} & \multicolumn{1}{c}{\textbf{Total}} \\ \midrule
Not Hateful & 5,481 & 253 & 510 & 6,244 \\
Hateful & 3,019 & 247 & 490 & 3,756 \\ \midrule
\textbf{Total} & \textbf{8,500} & \textbf{500} & \textbf{1000} & \textbf{10,000} \\ \bottomrule
\end{tabular}
}
\vspace{-0.2cm}
\caption{Distribution of hateful meme dataset.}
\label{tab:data_stat_hateful_meme}
\vspace{-0.3cm}
\end{table}
