\section{Related Work}
\noindent\textbf{Tools for Java Projects.} We first focus on two state-of-the-art tools for refactoring detection in Java projects: RefDetect~\cite{ieeeAccess21refdetect} and RefactoringMiner 3~\cite{tosem24refactoringMiner3}. RefDetect's authors compared their tool to RefactoringMiner 2 \cite{tse20refactoringMiner2} and report a slightly better performance. In RefDetect, each class is summarized using a string. Strings representing successive commits are aligned using the FOGSAA algorithm~\cite{nature13stringAlignmentAlgorithm}. The aligned strings are then used to match parts of two commits. RefDetect can also find refactorings in C++ projects, however, the tool is not publicly available \cite{RefDetectWebsite}. %So, despite RefDetect's reported accuracy and C++ support, we had to search for a new solution. We open-sourced this solution, so software maintainers, instructors, and the research community can use it.

RefDetect's number of parameters can also be considered as a drawback \cite{tse20refactoringMiner2}. The FOGSAA algorithm has three parameters, while the rest of the refactoring detection algorithm requires setting six threshold values for tweaking detection sensitivity. The RefDetect authors offer defaults for these settings, however, ``it is very difficult to derive \emph{universal} threshold values that can work well for all projects'' \cite{tse20refactoringMiner2}.
Calibration also requires an extensive dataset of refactorings. While such data exist for Java projects (e.g., \cite{icse18refactoringMiner,tse20refactoringMiner2}), it does not yet seem to be the case for C++ \cite{ieeeAccess21refdetect}. % ieeeAccess21refdetect: "To the best of our knowledge, there is no public refactoring dataset for C++ applications like the one avail-able for Java applications [35]."
As our tool is based on RefactoringMiner, it does not require such settings \cite{tosem24refactoringMiner3}.

Furthermore, RefDetect is restricted to 27 object-oriented refactoring types, but does not cover low-level refactorings such as renaming variables \cite{ieeeAccess21refdetect}.
% RefDetect: "and our approach only deals with the object-oriented constructs of these languages." AND "We also restricted the dataset to the 27 refactoring types shown in Table 1. Specifically, we exclude some low-level refactoring types such as those related to variables (e.g. Rename/Inline Variable, etc.) and those related to annotations (e.g. Add/Remove Parameter, Class Annotation, etc.) which are not supported by our tool, and are in any case less inter-esting refactorings." AND "Currently, the implemented tool supports the detection of 27 refactoring types (including composite ones) as illustrated in Table 1. These form a representative subset of the common set of refactorings proposed by Fowler [33]."
RefactoringMiner 3.0, on the other hand, can detect more than 100 refactoring types---even some which are unrelated to classes \cite{tosem24refactoringMiner3}. While a part of the supported refactoring types are Java-specific, we expect many to carry over to C++.% if we have space: "carry over seamlessly" instead of just "carry over"

As RefDetect, RefactoringMiner 3 was compared to version 2 of RefactoringMiner. The new version outperforms its predecessor in terms of matching parts of two commits. Large performance differences were observed in cases with one-to-many mappings and in connection with refactorings. Reasons for the increased performance are the addition of many refactoring types, an enhanced matching algorithm, and the new abstract syntax tree differencing (AST diff) feature. AST diff allows RefactoringMiner 3 to perform more fine-grained code comparisons. Being refactoring-aware and language-specific, the AST diff feature of RefactoringMiner 3 outperforms even state-of-the-art AST diff tools \cite{tosem24refactoringMiner3} such as GumTree \cite{tose32gumtree3,icse24gumtree3}. RefactoringMiner's authors propose their tool's extension to other programming languages as future research topic \cite{tosem24refactoringMiner3}. Our work addresses this research gap. We chose C++, which shares many characteristics with Java. For instance, both are statically and strongly typed and offer object-orientation with inheritance.

\noindent\textbf{Other languages.} By replacing the language-dependent part of RefDetect, it can be adapted to new programming languages. C++ was chosen by the RefDetect developers as the second language and they report an F\textsubscript{1} score of $0.95$ on an unpublished dataset with refactoring commits created %\textbf{\color{red} is this dataset available?} % Aleks: No. They mention a a first dataset on page 86711. This dataset is made by the authors to check edge cases while developing RefDetect. To evaluate their tool, they use the second dataset (the one created by students). The authors don't mention that they published the datasets (neither in the paper nor on the tool's website).
by students \cite{ieeeAccess21refdetect}. RefDetect's authors acknowledge that the dataset used for evaluation is not comprehensive and limited to object-oriented refactoring operations. C++, however, also allows for other programming styles, such as structured programming or template metaprogramming \cite{meyers05effectiveCpp}.

While promising results with an F\textsubscript{1} score of $0.84$ were also reported for an extension of RefDetect to the Kotlin language, its authors also highlight differences between Kotlin and Java, RefDetect's primary language \cite{saner24kotlinWithRefDetect}. Language incompatibilities also affect the RefDetect extension for Python and, thus, this tool lacks support for many Python features, such as list comprehensions, module imports, decorators, properties, and multiple inheritance \cite{bscThesis24pythonWithRefDetect}.

There has also been work on extending RefactoringMiner 2 to other languages, such as Python ~\cite{pythonAdaptedRefactoringMiner} and Kotlin \cite{ase21javaKotlinRefactoringInJetBrainsIde}. % kotlinRMiner
Python-adapted RefactoringMiner uses Jython to bring Python programs to the Java Virtual Machine, where they can be analyzed by RefactoringMiner. The reported 29 \cite{pythonAdaptedRefactoringMiner} % 29 is not mentioned in the paper, but the github page mentioned in the paper lists 29 refactoring types.
and 19 \cite{ase21javaKotlinRefactoringInJetBrainsIde} supported refactoring types do not reach the 40 refactoring types RefactoringMiner 2 can detect.

Another refactoring detector for Python is PyRef \cite{pyref}. Instead of using RefactoringMiner, it implements RefactoringMiner's algorithm in Python. PyRef outperforms Python-adapted RefactoringMiner, but is restricted to nine method-related refactoring types.

In our approach, a modification of RefactoringMiner 3 is used.

\noindent\textbf{Datasets for Tool Evaluation.} While some works on refactoring detection tools don't include an evaluation of the tool's accuracy at all (e.g., \cite{ase21javaKotlinRefactoringInJetBrainsIde}), other authors evaluate their tool on a dataset comprising commits with a ground truth of applied refactorings for each commit. Such a dataset is sometimes generated by collecting refactoring operations performed by students (e.g., \cite{ieeeMsr17refdiff,ieeeAccess21refdetect}). An advantage of this approach is that the ground truth is known. However, these \emph{seeded} refactorings do not necessarily reflect real-world development practice and may be too easy to detect \cite{tse20refactoringMiner2}.

A different approach to constructing a refactoring dataset is to mine commits of open-source projects and identify the refactorings contained in these commits. This process is labor-intensive, as it requires experts to determine the ground truth of applied refactorings. %The datasets published by the research group developing RefactoringMiner \cite{icse18refactoringMiner,tse20refactoringMiner2} fall into this category.
A common limitation incurred when evaluating tools on such datasets is the lack of independent experts who shape the ground truth, thus, potentially causing experimenter bias \cite{tse20refactoringMiner2,ieeeAccess21refdetect}. Nonetheless, such datasets are invaluable---due to their size and because they reflect the refactoring practices in the collected projects.

Usually, the first step to produce such a dataset involves running multiple refactoring detectors on a set of commits (e.g., \cite{pyref,saner24kotlinWithRefDetect,icse18refactoringMiner,tse20refactoringMiner2}). Refactorings reported by any of the used tools form the list of candidates. This list is then scrutinized by experts to determine which candidates are actual refactorings. Due to the lack of other publicly available C++ refactoring detectors, this approach to build an evaluation dataset is infeasible. Instead, we compare our tool to its Java counterpart. For this comparison, we generate a small seeded dataset of equivalent refactorings in C++ and Java using a large language model (LLM).



% --------------------------------------------------------