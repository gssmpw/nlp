\section{Related works}
PINNs~\cite{raissi2019physics} have gained significant attention as a powerful and flexible framework for solving differential equations, and have been widely adopted in various fields, including epidemic modeling~\cite{kharazmi2021identifiability,yazdani2020systems}, fluid mechanics~\cite{cai2021physics,raissi2020hidden,raissi2019physics,jin2021nsfnets}, finance~\cite{wang2023deep,bai2022application}, and biomedical engineering~\cite{kissas2020machine,sahli2020physics}, where understanding the underlying physical models is crucial.

To find a solution to differential equations in the framework of PINNs, we train a neural network to minimize a loss function comprising initial and boundary conditions as well as residual terms derived from the governing equations. However, the training results are highly sensitive to the choice of boundary condition settings, requiring the introduction of a penalty coefficient to balance the boundary loss term. While heuristic adjustments to the penalty coefficient can accelerate convergence, improper values may lead to inaccurate solutions. To address these challenges, adaptive methods have been developed. For instance, the authors of~\cite{wang2021understanding} proposed a learning rate annealing algorithm that adaptively assigns weights to each term in the loss function. PINNs with adaptive weighted loss functions have been introduced for the efficient training of Hamilton–Jacobi (HJ) equations~\cite{liu2022physics}. To further enhance the stability of PINNs, the authors of~\cite{wang2022and} proposed an adaptive training strategy that ensures stable convergence through the lens of NTK theory~\cite{jacot2018neural}. Recently, the failure of PINNs in stiff ODE systems was observed~\cite{ji2021stiff}, and stiff-PINN was proposed for improvement. Subsequently, various methods have been introduced, such as self-adaptive PINNs~\cite{mcclenny2023self} and variable-scaling PINNs~\cite{VS-PINN}. Among these methods, we employ the variable scaling technique~\cite{VS-PINN}, as it is simple and effective.

While PINNs have been successfully applied to a wide range of differential equation problems, their application to optimal control, particularly in solving Hamilton–Jacobi–Bellman (HJB) equations, remains relatively underexplored. The key challenge lies in ensuring stability and accuracy when approximating value functions and control policies. This has motivated recent studies investigating the interplay between deep learning and optimal control, aiming to develop computationally efficient methods that leverage the advantages of PINNs for solving PDE and optimal control problems.

There is a rich body of literature exploring the interplay between PINNs and optimal control. By leveraging the ability of PINNs to solve PDEs and the scalability of deep neural networks, researchers have developed computationally efficient methods for solving optimal control problems. For instance, a training procedure for obtaining optimal control in PDE-constrained problems was presented in~\cite{mowlavi2023optimal}. Similarly, the authors of~\cite{meng2024physics} utilized a Lyapunov-type PDE for efficient policy iteration in control-affine problems. Slightly later, a deep operator learning framework was introduced to solve high-dimensional optimal control problems~\cite{lee2024hamilton}, building on the policy-iteration scheme developed in~\cite{tang2023policy}. Most recently,~\cite{yin2023optimal} demonstrated the application of deep learning in controlled epidemic models.

Building on these advancements, our work focuses on leveraging PINNs for solving optimal control problems, specifically in the context of SIR models with vaccination strategies. The proposed approach not only provides an effective approximation of the minimum eradication time but also facilitates the synthesis of optimal control policies in a computationally efficient manner.