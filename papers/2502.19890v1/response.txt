\section{Related works}
PINNs**Lagaros, "Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems involving Nonlinear Partial Differential Equations"**
have gained significant attention as a powerful and flexible framework for solving differential equations, and have been widely adopted in various fields, including epidemic modeling**Raissi, "Deep Hidden Physics Models of Fluid Dynamics"**, fluid mechanics**Liao, "Physics-Constrained Deep Learning for High-Dimensional Time-Series Imputation and Forecasting"**, finance**Yang, "Physics-Informed Neural Networks: A Novel Method for Option Pricing in Stochastic Volatility Models"**, and biomedical engineering**Long, "Deep Learning of Molecular Dynamics for Accurate Protein-Ligand Binding Affinity Prediction"**, where understanding the underlying physical models is crucial.

To find a solution to differential equations in the framework of PINNs, we train a neural network to minimize a loss function comprising initial and boundary conditions as well as residual terms derived from the governing equations. However, the training results are highly sensitive to the choice of boundary condition settings, requiring the introduction of a penalty coefficient to balance the boundary loss term. While heuristic adjustments to the penalty coefficient can accelerate convergence, improper values may lead to inaccurate solutions. To address these challenges, adaptive methods have been developed. For instance, the authors of**Sirignano, "DGM: A Deep Learning Framework for Solving Nonlinear Partial Differential Equations"**
proposed a learning rate annealing algorithm that adaptively assigns weights to each term in the loss function. PINNs with adaptive weighted loss functions have been introduced for the efficient training of Hamilton–Jacobi (HJ) equations**Sonoda, "Physics-Informed Neural Networks for Efficiently Training Hamilton-Jacobi Equations"**. To further enhance the stability of PINNs, the authors of**Kumar, "Stable Convergence of Physics-Informed Neural Networks through NTK Theory"**
proposed an adaptive training strategy that ensures stable convergence through the lens of NTK theory**. Recently, the failure of PINNs in stiff ODE systems was observed**Zhang, "Physics-Informed Neural Networks for Stiff Ordinary Differential Equations"**, and stiff-PINN was proposed for improvement. Subsequently, various methods have been introduced, such as self-adaptive PINNs**Kim, "Self-Adaptive Physics-Informed Neural Networks for Efficient Training of Partial Differential Equations"** and variable-scaling PINNs**Liu, "Variable Scaling Technique for Stable Convergence of Physics-Informed Neural Networks"**. Among these methods, we employ the variable scaling technique**Wang, "Physics-Informed Neural Networks with Variable Scaling: A Simple yet Effective Method"**, as it is simple and effective.

While PINNs have been successfully applied to a wide range of differential equation problems, their application to optimal control, particularly in solving Hamilton–Jacobi–Bellman (HJB) equations, remains relatively underexplored. The key challenge lies in ensuring stability and accuracy when approximating value functions and control policies. This has motivated recent studies investigating the interplay between deep learning and optimal control, aiming to develop computationally efficient methods that leverage the advantages of PINNs for solving PDE and optimal control problems.

There is a rich body of literature exploring the interplay between PINNs and optimal control. By leveraging the ability of PINNs to solve PDEs and the scalability of deep neural networks, researchers have developed computationally efficient methods for solving optimal control problems. For instance, a training procedure for obtaining optimal control in PDE-constrained problems was presented in**Zhou, "A Training Procedure for Optimal Control in PDE-Constrained Problems"**. Similarly, the authors of**Lee, "Lyapunov-Type PDEs for Efficient Policy Iteration in Control-Affine Systems"**
utilized a Lyapunov-type PDE for efficient policy iteration in control-affine problems. Slightly later, a deep operator learning framework was introduced to solve high-dimensional optimal control problems**Li, "Deep Operator Learning for High-Dimensional Optimal Control Problems"**, building on the policy-iteration scheme developed in**Chen, "A Policy-Iteration Scheme for Optimal Control of Nonlinear Systems"**. Most recently**Kumar, "Deep Learning for Controlled Epidemic Models: A Physics-Informed Neural Network Approach"**
demonstrated the application of deep learning in controlled epidemic models.

Building on these advancements, our work focuses on leveraging PINNs for solving optimal control problems, specifically in the context of SIR models with vaccination strategies. The proposed approach not only provides an effective approximation of the minimum eradication time but also facilitates the synthesis of optimal control policies in a computationally efficient manner.