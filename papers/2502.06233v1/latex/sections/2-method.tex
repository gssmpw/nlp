\section{Notations}

We consider an auto-regressive language model $M$ with parameters $\theta$. We use $p_\theta(\cdot \vert x)$ to denote $M$'s distribution over the next token given the provided context $x$. 
Given a question $q$ (e.g., \nl{Jane had 4 apples and ate half of her apples. How many apples she has now?}), we denote the model's response as $(\textbf{r}, \textbf{a})$,
where $\textbf{a}$ is the answer (e.g., \nl{2}) and $\textbf{r}$ is a \emph{reasoning path} (or chain-of-thought),  a sequence of logical steps supposedly leading up to this answer (e.g., \nl{If Jane ate half her apples, this means she ate 2 apples. 4 minus 2 is 2.}).

\section{Confidence-Informed Self-Consistency}
\label{sec:cisc}

In this section we present \textit{Confidence-Informed Self-Consistency} (CISC). 
When designing CISC, we hypothesized that it is possible to reduce self-consistency's computational costs by generating a \emph{confidence score} for each reasoning path, and performing a weighted majority vote.

As an intuitive example, consider a hypothetical setting where there exist only two possible answers, one correct and one incorrect. For a model that responds with the correct answer $60\%$ of the time, standard majority voting will require \emph{40 samples} to reach $90\%$ accuracy\footnote{Calculated using the binomial distribution. All the technical details are included in Appendix \ref{appendix:example}}. However, a weighted majority vote that weights correct answers twice as much as incorrect ones, will achieve 90\% accuracy with less than \emph{10 samples}. 

With this motivation in mind, we build on recent findings suggesting that LLMs are capable of judging the correctness of their own outputs \cite{kadavath2022language, tian2023just, zhang2024small}, and incorporate the modelâ€™s self-assessment of its reasoning paths into the final answer selection:

\begin{definition}[Confidence-Informed Self-Consistency]
\label{def:cisc}
Given a question $q$ and responses $\{(\textbf{r}_1, \textbf{a}_1), \dots, (\textbf{r}_m, \textbf{a}_m) \}$, CISC involves:

\begin{itemize}
    \item \textbf{Confidence Extraction}: A self-assessed confidence score $c_i\in\R$ is derived for each $(\textbf{r}_i, \textbf{a}_i)$.
    \item \textbf{Confidence Normalization}: The confidence scores are normalized
    using Softmax: $\tilde{c}_i = \frac{\exp\!\bigl(\frac{c_i}{T}\bigr)}{\sum_{j=1}^m \exp\!\bigl(\tfrac{c_j}{T}\bigr)}$, where $T$ is a tunable temperature hyper-parameter (see discussion below).
    \item \textbf{Aggregation}:  The final answer is selected using a confidence-weighted majority vote: $\hat{a}_{CISC} = \arg\max_a\sum_{i=1}^m \textbf{1}[\textbf{a}_i = a]\cdot \tilde{c}_i$. 
\end{itemize}
\end{definition}

The temperature parameter $T$ controls the relative importance of the answer frequency versus the confidence scores. Namely, as $T\to \infty$, the distribution of normalized confidence scores approaches the uniform distribution, and CISC collapses to vanilla self-consistency. Conversely, as $T\to 0$,  the softmax normalization approaches the hard maximum function, prioritizing the single response with the highest confidence and disregarding the overall frequency of answers. This may lead CISC to select a different answer than self-consistency (see Figure \ref{fig:high-level}). 
