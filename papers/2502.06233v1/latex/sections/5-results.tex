\section{Main Results}

\label{sec:results}

\begin{table*}[!ht]
\centering
\begin{tabular}{lcccc}
\toprule
&  \multicolumn{2}{c}{Cost Reduction} & \multicolumn{2}{c}{Acc Improvement} \\
\cmidrule(lr){2-3} \cmidrule(l){4-5} 
Confidence Method & Budget 5 & Budget 10 & Budget 5 & Budget 10 \\
\midrule
Verbal Binary & 18\% \small{(6.1)} & 10\% \small{(11.1)} & 0.4\% & 0.2\% \\[4pt]
Verbal 1-100 & 22\% \small{(6.4)} & 30\% \small{(14.4)} & 0.8\% & 0.4\% \\[4pt]
Response Probability & 22\% \small{(6.5)} & 31\% \small{(14.6)} & 1.1\% & 0.8\% \\[4pt]
P(True) & \textbf{41\% \small{(8.4)}} & \textbf{46\% \small{(18.6)}} & \textbf{1.6\%} & \textbf{1.1\%} \\
\bottomrule
\end{tabular}
\caption{\textbf{CISC performance (macro-averaged over all datasets and models) per confidence method.}  
CISC performs better than standard self-consistency in terms of both efficiency gains and accuracy improvements across all confidence methods. Specifically, the \textbf{P-True} method achieves the best results. For instance, self-consistency must use 18.6 sampled responses on average to match the accuracy obtained by CISC using only 10 samples, representing a 46\% reduction in computational costs. }
\label{table:aggregated-results}
\end{table*}

This section demonstrates CISC's (\S\ref{def:cisc}) substantial performance advantage over self-consistency. We compare CISC, using fixed compute budgets of 5 and 10 responses per question, based on the metrics defined in \S\ref{sec:metrics}.

\paragraph{CISC outperforms self-consistency across virtually all models and datasets.}
Table \ref{table:aggregated-results} presents 
the \textit{Cost Reduction} and \textit{Accuracy Improvement} (see \S\ref{sec:metrics}) achieved by CISC with each confidence method. The results are macro-averaged across all models and datasets. CISC outperforms self-consistency with every confidence method.  

The \textit{P(True)} method yields the best results, achieving an average Cost Reduction of 41\% and 46\% with budgets of 5 and 10 responses, respectively. Figure \ref{fig:intrinsic-binary-results} presents a detailed breakdown of CISC's performance using \textit{P(True)} across all models and datasets. Notably, CISC is effective across nearly all configurations, with some exceeding 67\% cost reduction.

We provide additional results in Appendix \ref{sec:appendix-more-results}. In particular, Table \ref{tab:apendix-all-results} shows a per-dataset breakdown of Table \ref{table:aggregated-results}, and Table \ref{table:micro-results} shows the Accuracy Improvement metric micro-averaged across configurations, which enables the computation of confidence intervals. These demonstrate that the observed improvements of CISC (for each confidence method examined) are strongly statistically significant.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{latex/figures/breakdown-map-hor.pdf}
    \caption{Results breakdown for CISC using the P(True) method and a budget of 10 responses per question. Each cell is annotated with the Cost Reduction (Percentage; \S\ref{sec:metrics}) of CISC compared to self-consistency. As can be seen, CISC improves performance across almost all model families and datasets. In many cases, even 30 samples are not enough for self-consistency to reach CISC performance, leading to Cost Reduction of over 67\%. }.
    \label{fig:intrinsic-binary-results}
\end{figure}

\paragraph{Confidence Normalization improves CISC's performance.} We drill down into the importance of the within-question confidence normalization step in CISC. In Table \ref{table:norm-table}, we compare CISC's performance with and without confidence normalization. We see that for every confidence method examined, CISC with normalization (softmax with a tunable temperature value) outperforms its unnormalized counterpart. However, as shown in Supplementary Table \ref{table:norm-table-ext}, normalization is effective only when using appropriate temperature hyper-parameters. Because different confidence extraction methods produce scores on different scales, their optimal temperatures vary considerably (values are provided in Supplementary Figure \ref{fig:temperatures-map}). For instance, the P(True) method yields confidence values with high similarity, thus requiring lower temperatures to distinguish between them.

\begin{table}[h]
\centering
\small
\begin{tabular}{lc}
\toprule
Confidence Method & \makecell{Cost Reduction @ 10} \\
\toprule
P(True) (w/o normalization) & 32\% \small{(14.8)} \\
P(True) (w/ normalization) & \textbf{46\% \small{(18.6)}} \\
\midrule
SP (w/o normalization) & 24\% \small{(13.1)} \\
SP (w/ normalization) & \textbf{31\% \small{(14.6)}} \\
\midrule
Verbal (w/o normalization) & 20\% \small{(12.5)} \\
Verbal (w/ normalization) & \textbf{30\% \small{(14.4)}} \\
\bottomrule
\end{tabular}
\caption{\textbf{CISC performance with and without confidence normalization} (bottom and top rows, respectively). We see that while  
CISC demonstrates substantial cost reductions even without normalization, employing normalization (Softmax and temperature scaling) significantly enhances performance, across all three confidence methods.}
\label{table:norm-table}
\end{table}