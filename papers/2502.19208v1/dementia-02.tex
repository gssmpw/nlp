\section{Related work}
\label{sec:related}

To provide the necessary context for the unified Alzheimer's detection dataset introduced in this paper, we discuss cognitive tasks used for Alzheimer's detection, datasets, and computational approaches.

\subsection{Cognitive Task Analysis in Alzheimer's Detection}
    
Cognitive Task Analysis is an essential method used in AD studies to evaluate various aspects of communication, memory, executive function, and overall cognitive ability as the disease progresses \cite{Guarino2019Aging}. Boston Diagnostic Aphasia Examination (BDAE) is a well-known method for assessing linguistic abilities and language impairments through tasks such as word fluency tests, sentence construction, and narrative storytelling, helping clinicians and researchers understand how language deficits manifest in different stages of Alzheimer's \cite{Goodglass:1972:Book}. One widely used component of the BDAE is the \textbf{Cookie Theft Picture} (CTP) \cite{Cummings2019Describing}, an image depicting a busy kitchen scene where participants are asked to describe the situation in detail. This task assesses a person's ability to produce coherent speech and reveals cognitive and language dysfunctions, such as difficulties in organizing thoughts or recalling key details from memory.
Another prominent task is \textbf{Story Recall}, where participants are instructed to memorize the short story to be told, and are asked to recall the story when it ends \cite{Wechsler:2009:Book}. Additionally, \textbf{Verbal Fluency Tests} are commonly used to evaluate an individual’s lexical retrieval and executive function \cite{lezak2004neuropsychological}. These tasks require participants to generate as many words as possible within a time limit, either from a specific letter (e.g., F, A, S) or a semantic category (e.g., animals, fruits). The \textbf{Semantic Fluency Task} is also widely employed in clinical settings to identify challenges in speech production, executive functioning, and semantic memory performance \cite{lezak2004neuropsychological}. In this task, participants are asked to produce as many words as possible in a given semantic category (e.g., animals) and time frame. 


  



\begin{table*}[ht]
  \centering
  \caption{Overview of datasets used in this study. Tasks: (PD) Picture Description, (FT) Fluency Task, (SR) Story Retelling, (FC) Free Conversation, (NA) Narrative. Labels: (DM) Dementia, (AD) Alzheimer’s Disease, (MCI) Mild Cognitive Impairment, (HC) Healthy Control.  
   }
   \captionshrink
    \begin{tabular}{cl|cc|ccccc|cccc}
    \toprule
    \multirow{2}{*}{\textbf{Language}} & \multirow{2}{*}{\textbf{Source}} & \multicolumn{2}{c|}{\textbf{Modality}} & \multicolumn{5}{c|}{\textbf{Task}} & \multicolumn{4}{c}{\textbf{Labels}}    \\
      &       & Text  & Audio & PD    & FT    & SR    & FC    & NA    & DM    & AD    & MCI   & HC    \\
    \midrule
    \multirow{8}[2]{*}{English} & Pitt  & \cmark      & \cmark     & \cmark     & \ding{55}      & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}     & 255   & 42    & 243      \\
          & Lu    & \cmark     & \cmark     & \cmark     & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}     & 6     & 16    & 2     & 27     \\
          & VAS   & \cmark     & \cmark     &   \ding{55}    & \ding{55}     & \ding{55}     & \cmark     & \ding{55}     & 30    & \ding{55}     & 35    & 36      \\
          & Baycrest & \cmark     & \cmark     &  \ding{55}     &  \ding{55}     &   \cmark    &   \ding{55}      &   \ding{55}    & \ding{55}     & 3     & 7     & \ding{55}       \\
          & Kempler & \cmark     & \cmark     & \cmark     & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}     & 7     & \ding{55}     & \ding{55}       \\
          & WLS   & \cmark     & \cmark     & \cmark     & \cmark     & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}    & 263    & \ding{55}     & 1106  \\
          & Delware & \cmark     & \cmark     & \cmark     & \ding{55}     & \ding{55}     & \ding{55}     & \cmark     & \ding{55}     & \ding{55}     & 61    & 34     \\
          & Taukdial & \ding{55}     & \cmark     & \cmark     & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}     & 95    & 74     \\
    \midrule
    \multirow{2}[2]{*}{Spanish} & Ivanova & \cmark     & \cmark     &  \ding{55}      &   \ding{55}    &    \ding{55}    &  \ding{55}      &   \cmark    & \ding{55}     & 74    & 90    & 197     \\
          & PerLA & \cmark     & \ding{55}     & \cmark     & \cmark     & \ding{55}     & \cmark     & \ding{55}     & \ding{55}     & 21    & \ding{55}     & \ding{55}       \\
    \midrule
    \multirow{2}[2]{*}{Chineas} & NCMMSE & \ding{55}     & \cmark     & \cmark     & \cmark     & \ding{55}     & \cmark     & \ding{55}     & \ding{55}     & 79    & 93    & 108     \\
          & iFkyTek & \cmark     & \ding{55}     & \cmark     & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}     & \ding{55}     & 68    & 144   & 111     \\
    \midrule
    \multirow{4}[2]{*}{Greek} & DS3   &   \ding{55}    &  \cmark     &    \cmark   &   \cmark    &    \ding{55}   &  \ding{55}     &      \ding{55} & \ding{55}     & 76    & \ding{55}     & 19     \\
          & DS5   &    \ding{55}   &    \cmark    &    \cmark    &   \cmark     &    \ding{55}   &   \ding{55}    &   \ding{55}    & \ding{55}     & 26    & 35    & 31      \\
          & DS7   &    \ding{55}    &   \cmark     &   \cmark     &   \cmark     &   \ding{55}     &   \ding{55}     &   \ding{55}     & \ding{55}     & 27    & 35    & 2       \\
          & ADReSS-M &   \ding{55}    &   \cmark     &    \cmark    &  \ding{55}     &\ding{55}&  \ding{55}     &    \ding{55}   & \ding{55}     & 22    & \ding{55}     & 24     \\
    \bottomrule
    \end{tabular}%
  \label{tab:datasetdescription}%
\end{table*}%

\subsection{Datasets}

The dataset developed in this study is multilingual, comprising four languages:  Chinese, Spanish, English, and Greek, sourced from multiple countries and regions. The combined multilingual dataset includes participants from North America (United States), Europe (Spain, Greece), and Asia (China). This selection of languages ensures that the dataset captures a broad spectrum of speech patterns and cognitive variations seen in different linguistic groups. 

To build this diverse dataset, data were sourced from 16 publicly available resources that provide conversational speech related to AD. This corpus incorporates both audio and text formats. All datasets utilized in this study, with the exception of two Chinese datasets, are publicly accessible through DementiaBank, representing the most prominent publicly available datasets for Alzheimer's detection.
Access to DementiaBank is restricted to members of the DementiaBank consortium and is password-protected. Established researchers and clinicians specializing in dementia may apply for membership to gain access. The two Chinese datasets are available in the following GitHub repositories: \url{https://github.com/lzy1012/Alzheimer-s-disease-datasets} and \url{https://github.com/lzl32947/NCMMSC2021_AD_Competition}. 

The participant groups included in these datasets consist of individuals with dementia (DM), AD, MCI, and HC. Among these, only the two English datasets, Lu and VAS, contain data for dementia. It is important to note that dementia encompasses various types of diseases, including AD, Parkinson's disease, vascular dementia, and others. Table~\ref{tab:dataset_transcript} presents small parts from picture description conversations in the Pitt and Taukdial datasets. The Taukdial transcripts were originally in audio format and were converted to text using automatic transcription.

\begin{table}[t]
    \caption{Excerpts from transcripts of picture descriptions from the Pitt and Taukdial datasets. ``INT'' and ``PAR'' denote interviewer and participant utterances in the Pitt corpus; Taukdial has only participant-side utterances.}
    \centering
    \begin{tabular}{|p{1cm}|p{7cm}|}  %
        \hline
        \multicolumn{1}{|c|}{\textbf{Dataset}} & \multicolumn{1}{c|}{\textbf{Transcript}} \\  
        \hline
        Pitt & INT: just tell me everything that you see happening in that picture. PAR: alright. there's \&-um a young boy that's getting a cookie jar. PAR: and it he's \&-uh in bad shape because \&-uh the thing is PAR: and in the picture the mother is washin(g) dishes and doesn't see [\dots] \\  
        \hline
        Taukdial & What I see is a young lady was riding her tricycle with her cat, and somehow the cat got up in the tree. Her dog is trying to chase the cat, can't get up the tree. Her father climbed the tree and is sitting on the limb [\dots] \\  
        \hline
    \end{tabular}\label{tab:dataset_transcript}
\end{table}

Table~\ref{tab:datasetdescription} provides an overview of all datasets, followed by a detailed description of each dataset below.


\begin{table*}[t]
  \centering
  \caption{Summary of related work in Alzheimer's detection.  
  }
  \captionshrink
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{lllll}
    \toprule
    \textbf{Reference} & \textbf{Dataset} & \textbf{Categories} & \textbf{Accuracy} & \textbf{Method} \\
    \midrule
    \cite{chen2023cross} & ADRReSS-M & AD, HC & 69.6\% & Acoustic, linguistic, and para-linguistic features and SVM \\
    \cite{duan2024pre} & Taukdial & MCI, HC &  77.5\% & Linguistic, acoustic, and data augmentation \\
\cite{fraser2019multilingual} & Pitt + Swedish dataset & MCI, HC & 63\% (Pitt)  & Multilingual word embeddings \\
    & & & 72\% (Swedish) & \\
\cite{jain2021exploring} & Pitt & AD, HC &  90.6\% & Domain-specific FastText word embeddings and 1D-CNN + BLSTM \\     
    \cite{kurtz2023early} & VAS & DM, MCI, HC & 74.7\% & Linguistic and acoustic features and ML classifiers \\
\cite{liu2022improving} & iFkyTek & AD, HC & 83.7\% & Transformer \\
\cite{orozco2024automatic} & Ivanova & AD, MCI, HC & 73.03\% & Data augmentation on audio files and CNN \\
\cite{sadeghian2021towards}& A custom conversational AD dataset&AD, HC&95.8\%& Linguistic, acoustic and ANN\\
    
\cite{Tamm2023Cross-Lingual}&ADReSS-M&AD, HC&82.6\%&Acouistic features and ANN\\
     \cite{wen2023revealing}
&A corpus from DementiaBank&AD, HC&92.2\%&PoS features and a transformer model\\

    
          
    \cite{ying2023multimodal} & NCMMSE & AD, MCI, HC & 89.1\% & Linguistic and acoustic features and SVM \\
    
     
     
     

    \bottomrule
    \hline
  \end{tabular}}
  \label{tab:related_work}
\end{table*}


\begin{itemize}
    \item \textbf{Pitt corpus}~\cite{becker1994dementia} is part of DementiaBank, a multimedia database designed to facilitate the study of individuals with dementia, supported by grants NIA AG03705 and AG05133. This dataset encompasses various types of conversational data, including tasks such as the Cookie Theft picture (CTP) description \cite{goodglass2001bdae}, fluency tasks, story recall, and sentence construction. For this study, data were exclusively drawn from Probable AD, PossibleAD, MCI, and HC participants for the CTP task.
    \item \textbf{Lu}~\cite{lanzi2023dementiabank} is an English-language dataset from DementiaBank, comprising conversations from 26 HC participants and 28 individuals with dementia, specifically focusing on CTP conversations from the United States.
    \item \textbf{VAS}~\cite{liang2022evaluating} consists of voice commands collected from 40 older adults, aged 65 or older, who were either HC participants or MCI participants. These participants were grouped based on their Montreal Cognitive Assessment (MoCA) \cite{hobson2015montreal} scores. The data was collected through Amazon Alexa, a Voice-Assistant System, and includes daily spontaneous voice commands issued by users to seek assistance with everyday tasks. 
    \item \textbf{Baycrest}~\cite{johnston2023spectral} includes retellings of the Cinderella story and other discourse tasks. For the Cinderella task, participants were provided with a storybook featuring Disney illustrations of the tale. The text was obscured, and pages deemed less relevant were taped together to prevent visibility.
    \item \textbf{Kempler}~\cite{kempler1987syntactic} originally was collected from individuals diagnosed with probable AD at the UCLA Geriatric Outpatient Clinic and the West Los Angeles Veterans Administration Hospital. This dataset contains  conversations from individuals with MCI, focusing on topics such as family, profession, personal history, and questions from a neuropsychological interview \cite{kempler1987syntactic}.
    \item \textbf{WLS} (The Wisconsin Longitudinal Study)~\cite{herd2014cohort} follows a random sample of Wisconsin high school graduates from 1957 (N = 10,317), born between 1938 and 1940. Initially focused on educational and occupational aspirations, later surveys in 1964, 1975, 1992, 2004, and 2011 increasingly focused on health and life course experiences as participants aged \cite{herd2014cohort}. 
    \item \textbf{Delaware}~\cite{lanzi2023dementiabank}, part of DementiaBank, investigates cognitive-linguistic features in neurotypical adults and individuals with MCI due to possible AD. It employs the DementiaBank discourse protocol, which includes picture description, story narrative, procedural discourse, and personal narrative tasks. 
    \item \textbf{Taukdial}~\cite{luz2024connected} consists of spontaneous speech samples from cognitively normal subjects and individuals with MCI, recorded while describing pictures. The dataset includes English and Chinese audio recordings.
    \item \textbf{Ivanova}~\cite{ivanova2022discriminating} comprises recordings from participants over 60 years old, all native European Spanish speakers with at least six years of primary education, ensuring literacy and minimizing cognitive load during a reading task. 
    \item \textbf{PerLA}~\cite{suarez2024alzheimer} is part of the Clinical Linguistics PERLACH Corpus. %
    Collected between 2012 and 2014, it includes 27 transcriptions from conversations with 21 AD patients, some interviewed twice.
    \item \textbf{Lu}~\cite{macwhinney2011aphasiabank}, available through DementiaBank, consists of interview recordings from 52 Mandarin-speaking AD patients. These recordings include tasks such as the CTP description, category fluency, and picture naming exercises \cite{qi2023noninvasive}.
    \item \textbf{NCMMSE}~\cite{ortiz2024deep}, from the National Conference on Man-Machine Speech Communication (NCMMSC), consists of audio recordings where participants engage in various tasks, such as picture descriptions and fluency exercises. It features 79 subjects with AD, 93 with MCI, and 108 HC. %
    \item \textbf{IFlytek}~\cite{liu2021spontaneous}, derived from the Predictive Challenge of AD in 2019, comprises transcripts of spontaneous speech collected during CTP description tasks, a common diagnostic tool for neurological disorders \cite{liu2021spontaneous}. Participants, ranging in age from 41 to 98, included 68 individuals with AD, 144 with MCI, and 111 healthy controls.
    \item \textbf{Dem@Care}~\cite{karakostas2016care} datasets consist of data collected through lab and home-based experiments conducted at the Greek Alzheimer’s Association for Dementia and Related Disorders in Thessaloniki, Greece, and participants' homes. These datasets include video and audio recordings alongside data from physiological sensors. Additionally, it incorporates data from sleep, motion, and plug sensors, offering a comprehensive view of participants' behavioral and physiological patterns. We used the Ds3, Ds5, and Ds7 darasets from Dem@Care project.
    \item \textbf{ADReSS-M}~\cite{luz2023multilingual} comprises spontaneous speech samples from cognitively normal individuals and AD patients. The training set includes English audio recordings of participants describing the CTP from the Boston Diagnostic Aphasia Examination. The test set features speech samples in Greek, where participants describe a different picture. For this study, we utilized only the test set including 24 HC, 22 AD, as the dataset creator advises against using the training set alongside other English datasets from DementiaBank due to potential overlap.
\end{itemize}


\subsection{Computational Approaches to Alzheimer's Detection}

Numerous studies have explored cognitive task-based approaches for Alzheimer’s detection, using speech and language analysis as key indicators of cognitive decline. These methods consider linguistic and paralinguistic features, such as lexical richness, syntactic complexity, fluency, and acoustic properties, to differentiate between AD, MCI, and HC across various languages and datasets \cite{shakeri2025natural}. We review related work focusing on single-language and multilingual conversation-based Alzheimer’s detection for both binary and multiclass classification, which are summarized in Table~\ref{tab:related_work}.


For binary AD detection, \citet{duan2024pre} analyze the multilingual Taukdial dataset, extracting language-agnostic speech features to classify MCI and HC. \citet{fraser2019multilingual} show that multilingual approaches outperform monolingual ones, achieving up to 72\% accuracy in MCI detection using narrative speech in English and Swedish. \citet{jain2021exploring} demonstrate that domain-specific word embeddings improve AD vs. HC classification on the Pitt corpus.

Regarding multiclass AD detection, \citet{orozco2024automatic} address the underrepresentation of Spanish speakers, using a CNN model on the Ivanova dataset from DementiaBank and achieving 73.03\% accuracy. Due to data limitations, they augmented the training set with synthetic samples. \citet{kurtz2023early} utilize the VAS dataset, achieving 74.7\% accuracy in differentiating DM, MCI, and HC, highlighting the potential of voice assistant systems for passive monitoring. \citet{ying2023multimodal} integrate acoustic and linguistic features from Wav2Vec2.0 and BERT for early AD detection in Chinese (NCMMSC dataset), achieving 89.1\% accuracy.



\citet{liu2022improving} propose a transformer-based model with a feature purification network, finding that semantic features generalize well across English and French. \citet{chen2023cross} show that paralinguistic features outperform pre-trained ones in cross-lingual AD detection, achieving 69.6\% accuracy when training on English and testing on Greek. \citet{Tamm2023Cross-Lingual} integrate acoustic features with demographic covariates, achieving 82.6\% accuracy for AD classification. \citet{wen2023revealing} identify 12 PoS features distinguishing AD from HC, reaching 92.2\% accuracy. Finally, \citet{sadeghian2021towards} propose a non-invasive, speech-based diagnostic tool for AD detection in clinical and home settings.
