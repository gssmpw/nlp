\section{Experiments}

This section details the experiments conducted on the unified MultiConAD  dataset. We explored two classification tasks: binary and multiclass classification. In the binary classification setting, the MCI group was excluded, concentrating on the distinction between HC and AD. The multiclass classification, which addresses a research gap identified in our recent literature review \cite{shakeri2025natural}, involved classifying instances into HC, MCI, and AD categories. To investigate multilingual patterns related to AD pathology, all classification models were trained on three different variants of the dataset---monolingual, combined-multilingual, and combined-translated---as described in Section~\ref{sec:dataset:variants}. %


\subsection{Research Questions}

We address the following research questions.

\begin{itemize}
    \item \textbf{RQ1}: How does the performance of Alzheimer's detection models differ when framed as a binary classification problem (AD vs. HC) compared to a multiclass problem (AD vs. MCI vs. HC)?

    \item \textbf{RQ2}: For multiclass classification, do the confusion matrices of the models reveal specific challenges in distinguishing between different stages of cognitive decline (AD vs. MCI)?

    \item \textbf{RQ3}: Does training language-specific models on a combined dataset in multiple languages (combined-multilingual) improve overall performance compared to training only on a single language (monolingual)?

    \item \textbf{RQ4}: How does the performance of models trained on translated and combined data (combined-translated) compare to models trained on the original language (monolingual) and on the combined dataset without translation (combined-multilingual)?

\end{itemize}


\begin{table*}[t]
  \centering
  \caption{Binary classification (AD vs. HC) results comparing Sparse and Dense text representations and classifiers (DT, RF, SVM, LR) across dataset variations. Best results are in boldface. The arrows denote a performance improvement \goodarrow~~ or degradation \badarrow~~ relative to the Monolingual setting.}
  \captionshrink
 \begin{tabular}{lcccccrccccrccccc}
    \toprule
    \multirow{2}{*}{\textbf{Language}} & \textbf{Text} & \multicolumn{4}{c}{\textbf{Monolingual}} && \multicolumn{4}{c}{\textbf{Combined-Multilingual}} && \multicolumn{4}{c}{\textbf{Combined-Translated}} \\
    \cline{3-6} \cline{8-11} \cline{13-16}
          &  \textbf{Repr.} 
          & DT    & RF    & SVM   & LR & 
          & DT    & RF    & SVM   & LR &
          & DT    & RF    & SVM   & LR \\
    \midrule
    \multirow{2}{*}{Spanish} & Sparse 
        & 0.73  & 0.73  & \textbf{0.78}  & 0.78 & 
        & 0.80 \goodarrow & 0.76 \goodarrow& 0.66 \badarrow & \textbf{0.80}\goodarrow & 
        & 0.75\goodarrow&\textbf{0.80}\goodarrow &0.75 \badarrow &0.73 \badarrow \\
      & Dense 
      & 0.71  & 0.71  & \textbf{0.80} & 0.80 & 
      & 0.66 \badarrow & 0.78 \goodarrow& 0.66 \badarrow & \textbf{0.80} \nochange&
      & 0.59 \badarrow& 0.76\goodarrow&\textbf{0.78}\badarrow &0.76\badarrow  \\
    \midrule
    \multirow{2}{*}{Chinese} & Sparse 
    & 0.67  & 0.69  & \textbf{0.70}  & 0.70 & 
    & 0.67\nochange  & \textbf{0.69}\nochange & 0.67 \badarrow & \textbf{0.69}\badarrow& 
    & 0.70\goodarrow &\textbf{0.90} \goodarrow&0.89 \goodarrow&0.84  \goodarrow \\
   & Dense 
   & 0.69  & 0.76  & \textbf{0.83} & 0.80  & 
   & 0.76 \goodarrow &\textbf{ 0.86} \goodarrow & 0.67\badarrow & 0.81 \goodarrow&
   & 0.66 \badarrow&\textbf{0.84}\goodarrow &0.80 \badarrow&0.84 \goodarrow \\
    \midrule
    \multirow{2}{*}{Greek} & Sparse 
    & 0.68  & \textbf{0.78} & 0.77  & 0.78 & 
    & 0.68 \nochange & \textbf{0.76} \badarrow& 0.60 \badarrow & 0.73 \badarrow&
    & 0.58 \badarrow&0.67 \badarrow &\textbf{0.69} \badarrow& 0.51\badarrow \\
    & Dense 
    & 0.65  & 0.75  & \textbf{0.78} & 0.77 & 
    & 0.64  \badarrow& \textbf{0.75} \nochange & 0.75\badarrow & 0.73 \badarrow& 
    & 0.62\badarrow&0.66\badarrow  &\textbf{0.70} \badarrow &0.64 \badarrow  \\
    \midrule
    \multirow{2}{*}{English} & Sparse 
    & 0.73  & \textbf{0.78}        & 0.77 & 0.75  & 
    & 0.67 \badarrow & 0.74 \badarrow & 0.58&\textbf{0.75}&
    & 0.73 \nochange&0.74 \badarrow &\textbf{0.76} &0.61 \badarrow\\
     & Dense
     & 0.65  & 0.75  & \textbf{0.81} & 0.79  & 
     & 0.67 \goodarrow & \textbf{0.77}\goodarrow  & 0.58 \badarrow& 0.67 \badarrow &
     & 0.71\goodarrow& 0.73\badarrow &\textbf{0.83}\goodarrow &0.70 \badarrow\\
    \bottomrule
    \end{tabular}%
  \label{tab:Binary-class_Classification_Result}%
\end{table*}%






\begin{table*}[t]
  \centering  
  \caption{Multiclass classification (AD vs. MCI vs. HC) results comparing Sparse and Dense text representations and classifiers (DT, RF, SVM, LR) across dataset variations. Best results are in boldface. The arrows denote a performance improvement \goodarrow~~ or degradation \badarrow~~ relative to the Monolingual setting.}
  \captionshrink
    \begin{tabular}{lcccccrccccrccccc}
    \toprule
    \multirow{2}{*}{\textbf{Language}} & \textbf{Text} & \multicolumn{4}{c}{\textbf{Monolingual}} && \multicolumn{4}{c}{\textbf{Combined-Multilingual}} && \multicolumn{4}{c}{\textbf{Combined-Translated}} \\
    \cline{3-6} \cline{8-11} \cline{13-16}
          &  \textbf{Repr.} 
          & DT    & RF    & SVM   & LR & 
          & DT    & RF    & SVM   & LR &
          & DT    & RF    & SVM   & LR \\
    \midrule
    \multirow{2}{*}{Spanish} & Sparse 
        & 0.61 & 0.60 & \textbf{0.61} & 0.61 &
        & 0.51 \badarrow & \textbf{0.62} \goodarrow & 0.51 \badarrow & 0.58 \badarrow &
        & 0.47 \badarrow & \textbf{0.58} \badarrow & 0.56 \badarrow & 0.56 \badarrow \\
    & Dense 
        & 0.52 & 0.61  & \textbf{0.61} & 0.61 & 
        & 0.47 \badarrow & \textbf{0.61} \nochange & 0.61 \nochange & 0.57 \badarrow &
        & \textbf{0.60} \goodarrow & 0.58 \badarrow & 0.56 \badarrow & 0.51\badarrow  \\
    \midrule
    \multirow{2}{*}{Chinese} & Sparse 
        & 0.36 & 0.35 & \textbf{0.40} & 0.39 &
        & \textbf{0.42} \goodarrow & 0.39 \goodarrow &0.39 \badarrow & 0.40 \goodarrow & 
        & 0.45 \goodarrow & 0.59 \goodarrow & \textbf{0.68} \goodarrow & 0.62 \goodarrow\\
    & Dense 
        & 0.51 & 0.58  & \textbf{0.59} & 0.56 &
        & 0.43 \badarrow & \textbf{0.62}\goodarrow & 0.60  \goodarrow& 0.60 \goodarrow& 
        & 0.43 \badarrow & \textbf{0.64}\goodarrow & 0.60 \goodarrow& 0.45 \badarrow \\
    \midrule
    \multirow{2}{*}{Greek} & Sparse 
        & 0.59 & \textbf{0.74} & 0.67 & 0.71 &
        & 0.57 \badarrow & \textbf{0.71} \badarrow& 0.53 \badarrow& 0.66 \badarrow&
        & 0.64 \goodarrow & 0.65 \badarrow & \textbf{0.69}\goodarrow & 0.60 \badarrow \\
    & Dense 
        & 0.54 & 0.66  & \textbf{0.73} & 0.73 &
        & 0.54  \nochange & 0.66 \nochange& 0.65 \badarrow & \textbf{0.67} \badarrow & 
        & \textbf{0.62} \goodarrow & 0.61 \badarrow & 0.60 \badarrow & 0.42 \badarrow  \\
    \midrule
    \multirow{2}{*}{English} & Sparse 
        & 0.59 & 0.62 & \textbf{0.65} & 0.65 &
        & 0.59 \nochange & 0.58 \badarrow& 0.41 \badarrow& \textbf{0.66} \goodarrow&
        & 0.50 \badarrow & 0.61 \badarrow& \textbf{0.66}\goodarrow & 0.64 \badarrow \\
    & Dense 
        & 0.51 & 0.62 & \textbf{0.65} & 0.63 &
        & 0.50 \badarrow & 0.62 \nochange & \textbf{0.65} \nochange & 0.63 \nochange& 
        & 0.50 \badarrow & 0.57 \badarrow  & \textbf{0.66} \goodarrow& 0.41 \badarrow \\
    \bottomrule
    \end{tabular}%
  \label{tab:multiclass_Classification_Result}%
\end{table*}%




\subsection{Baseline methods}
\label{sec:baselines}

We consider two text representations, sparse and dense, and a diverse set of established classification algorithms.
We chose a TF-IDF weighting for sparse representation due to its effectiveness in highlighting less common, more informative words. This approach has been utilized in similar studies, such as \cite{adhikari2022exploiting,searle2020comparing,martinc2020tackling,Shakeri2024ICAPAI}. We conducted experiments on all datasets both with and without stopword removal. However, we observed that eliminating stopwords led to a decline in model performance. Based on this finding, we decided to forgo stopword removal in our final approach. For dense representation, we employ a multilingual embedding model multilingual \texttt{intfloat/multilingual-e5-large} \cite{wang2024multilingual}, which is initialized from xlm-roberta-large and trained on a mixture of multilingual datasets. It supports 100 languages from xlm-roberta. The e5-large model, based on XLM-RoBERTa, features 24 layers, 16 attention heads, and a 1024 hidden size. It uses GELU activation, 0.1 dropout, and a 250,002-token vocabulary, with a 4096 intermediate size for capturing complex linguistic structures.

After obtaining feature representations through the aforementioned sparse and dense approaches, the resulting features were fed into four machine learning classifiers: Decision Tree (DT), Random Forest (RF), Support Vector Machine (SVM), and Logistic Regression (LR). To optimize the performance of classifiers, we employed grid search in combination with 5-fold cross-validation to evaluate various hyperparameter configurations. DT was tuned for different depths (max\_depth: 10, 20, 30), while the RF was evaluated with varying numbers of estimators (n\_estimators: 50, 100, 200). For SVM, we experimented with different regularization strengths (C: 0.1, 1, 10) and kernel types (linear, rbf). Similarly, LR was tested with different C values (0.1, 1, 10) to control regularization. The best hyperparameters were chosen based on accuracy, and the final model was trained on the full training set. %


\subsection{Results}




\begin{figure*}[t]
    \centering    
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Combined-Multilingual_Spanish.png}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Combined-Multilingual_Chinese.png}
        \caption{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Combined-Multilingual_Greek.png}
        \caption{}
    \end{subfigure}
\begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Combined-Translated_English.png}
        \caption{}
    \end{subfigure}
    \hfill
    \caption{Confusion matrices for multiclass classification using the best-performing dataset variant and classifier for each language.}
      \label{confusion matrices}
\end{figure*}







\subsubsection{Binary vs. Multiclass Classifiation}

We first ask how the performance of the models compare when Alzheimer's detection is framed as a binary vs. multiclass classification problem (RQ1). Tables \ref{tab:Binary-class_Classification_Result} 
 and \ref{tab:multiclass_Classification_Result} present the results of binary and multiclass classification based on both dense and sparse representations, evaluated across the monolingual, multilingual-combined, and combined-translated settings. The experimental results indicate that AD detection is a significantly easier problem when formulated as a binary classification task (AD vs. HC) compared to a multiclass classification (AD vs. MCI vs. HC). Across all models and datasets, binary classification consistently yields higher accuracy, with peak performance reaching 0.90 on the combined-translated dataset (Chinese, sparse, RF). In contrast, multiclass classification demonstrates a decline in performance, with the highest observed accuracy not exceeding 0.74 on the monolingual dataset (Greek, sparse, RF). These findings suggest that distinguishing between AD and HC is relatively straightforward, whereas differentiating between AD, MCI, and HC presents greater challenges. The reduced performance in the multiclass setting is likely attributable to the clinical and cognitive overlap between MCI and both AD and HC, leading to increased misclassification rates. This is reflected in the consistently lower accuracy observed in multiclass classification compared to the binary classification scenario.

In classification tasks, predictions made by a machine-learned classifier are subject to error, which manifests as two primary types: Type I error (false positives) and Type II error (false negatives). In AD detection, a Type I error means incorrectly classifying a HC individual as having AD, while a Type II error means incorrectly classifying an individual with AD as healthy. While both types of error are undesirable, the consequences of a Type II error in a clinical setting are far more severe. Missing a diagnosis of AD (a Type II error) delays potential treatment and intervention, potentially leading to worse patient outcomes. Conversely, a Type I error, while still causing concern and requiring further testing, allows for proactive monitoring and reduces the risk of undetected disease progression. Therefore, while we acknowledge both error types, this study prioritizes Type II error, which we measure in terms of \emph{false negative rate}:
the proportion of non-HC participants incorrectly classified as HC, relative to the total number of HC participants (i.e., FN/(FN+TP)). Table \ref{tab:Mis_Classification_Result} presents the false negative rates for the best-performing classifier across all languages using the dense representation model for multiclass classification. The results for monolingual and combined-translated models are based on SVM, while the Multilingual-Combined model results are based on the RF classifier. In multiclass classification, Spanish has the highest error (0.78), followed by English (0.37), while Greek (0.06) and Chinese (0.24) perform better. The combined-multilingual dataset reduces errors, especially in Spanish (0.63) and Greek (0.01), but translation increases errors in some cases. Overall, false negative rate is high in the multiclass setting, particularly due to the difficulty of distinguishing MCI from HC, while multilingual training provides inconsistent improvements across languages.


\begin{table}[t]
  \centering  
  \caption{False negative rate in multiclass classification using SVM for Monolingual and Combined-Translated, and RF for Combined-Multilingual. The arrows denote a performance improvement \goodarrow~~ or degradation \badarrow~~ relative to the Monolingual setting.}
  \captionshrink
  \begin{tabular}{lccc}
    \toprule
    \multirow{2}{*}{\textbf{Language}}  & \multirow{2}{*}{\textbf{Monolingual}} & \textbf{Combined-} & \textbf{Combined-} \\ 
    & & \textbf{Multilingual} & \textbf{Translated} \\
    \midrule
    Spanish  & 0.78 &  0.63 \goodarrow & 0.71 \goodarrow \\
    Chinese &  0.24 &  0.20 \goodarrow & 0.31 \badarrow  \\
    Greek  &   0.06 &  0.01 \goodarrow & 0.13 \badarrow  \\
    English  &    0.37 &  0.48 \badarrow &  0.33 \goodarrow \\
    \bottomrule
  \end{tabular}
  \label{tab:Mis_Classification_Result}%
\end{table}



\subsubsection{Different Stages of Cognitive Decline}

Next, we take a closer look at the difficulty of in differentiating between various stages of cognitive decline in the multiclass setting.
Figure~\ref{confusion matrices} presents the confusion matrices for the four languages, using the models with the lowest false negative rate for each language, as shown in Table~\ref{tab:Mis_Classification_Result}. Specifically, Spanish, Chinese, and Greek are based on combined-multilingual with RF, while English is based on Translated-Combined with SVM. A common issue across all models is the misclassification of MCI, which is frequently confused with either HC or AD, highlighting the progressive and overlapping nature of cognitive decline. In the Spanish model, HC cases are classified with high accuracy, but distinguishing MCI and AD remains problematic. Similarly, in the Chinese model, a substantial number of HC cases are misclassified as MCI, and while MCI is relatively well classified, some cases are incorrectly labeled as AD. The Greek model exhibits the most significant challenge in HC classification, with HC cases frequently misclassified as AD, suggesting potential dataset imbalances or language-specific difficulties in speech-based diagnosis. In contrast, AD cases in Greek are classified with high accuracy, indicating clearer distinguishing features at later disease stages. The English model, trained on the combined-translated dataset, demonstrates strong performance in identifying HC cases but struggles to distinguish MCI, with a considerable number of MCI cases being misclassified as HC or AD. Overall, the results underscore the inherent difficulty in differentiating MCI from both HC and AD, with varying degrees of classification accuracy across languages.

Another key observation is that the Spanish model predominantly predicts HC across all true labels, indicating a strong bias that limits its ability to distinguish MCI and AD cases. In contrast, the Greek model exhibits severe misclassification toward AD, suggesting overconfidence in AD predictions while misclassifying HC and MCI cases. This pattern may result from class imbalance or insufficient training data, which could be influencing the modelâ€™s decision-making process.


\subsubsection{Monolingual vs. Multilingual Dataset}
Tables \ref{tab:Binary-class_Classification_Result} and \ref{tab:multiclass_Classification_Result} highlight the results from the best-performing classifier in bold for each language and dataset variant. 
In binary classification, the impact of multilingual training varies across languages, with some benefiting while others experience a decline. The best-performing model for Chinese shows a notable improvement when trained on the combined-multilingual dataset, increasing accuracy from 0.83 to 0.86. However, Spanish sees no change, maintaining a peak accuracy of 0.80 in both monolingual and multilingual settings. In contrast, Greek and English experience declines, with Greek dropping from 0.78 to 0.76 and English decreasing from 0.81 to 0.77. These results indicate that multilingual training does not consistently enhance binary classification performance and that its effectiveness is highly language dependent.

For multiclass classification, training language-specific models on the combined-multilingual dataset generally leads to performance improvements, except for Greek. Spanish achieves a slight increase in accuracy, improving from 0.61 in the monolingual setting to 0.62 in the multilingual setting. Similarly, Chinese benefits from a boost from 0.59 to 0.62, while English sees a marginal gain from 0.65 to 0.66. However, Greek, which performs best in a monolingual setting with an accuracy of 0.74, drops to 0.71 when trained in a multilingual setting. This suggests that while multilingual training is beneficial for certain languages in multiclass classification, it does not universally enhance performance across all cases.\\

 




\subsubsection{Translated Dataset}


In binary classification, training on the combined-translated dataset has varying effects across languages, occasionally boosting performance but often leading to declines. The best-performing model for English benefits from translation-based augmentation, increasing accuracy to 0.83 compared to 0.81 in the monolingual setting and 0.77 in the combined-multilingual setting. Chinese experiences a raise, increasing from 0.86 with combined-multilingual training and 0.83 in monolingual to 0.90 with combined-translation. Greek sees the most significant decline, falling from 0.78 in the monolingual setting and 0.76 in the combined-multilingual setting to just 0.70 with translation-combined. Spanish remains stable at 0.80 across all datasets, indicating that translation does not provide additional value for this language.


In multiclass classification, training on the combined-translated dataset enhances accuracy for Chinese, increasing to 0.68 compared to 0.59 in the monolingual setting and 0.62 in the combined-multilingual setting. English maintains its performance at 0.66, matching the combined-multilingual setting and slightly improving over the 0.65 accuracy in the monolingual setting. However, Spanish sees a slight decline (0.60 vs. 0.61 monolingual, 0.62 combined-multilingual), while Greek experiences a more noticeable drop (0.69 vs. 0.74 monolingual, 0.71 combined-multilingual), suggesting that translation does not provide uniform benefits across languages.








