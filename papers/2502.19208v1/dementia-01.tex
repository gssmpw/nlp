
\section{Introduction}
  
Dementia is a progressive clinical cognitive decline that impairs daily activities and independence~\cite{grasset2018evolution}. Cases are expected to rise from 57 million in 2019 to 152 million by 2050~\cite{guo2024trajectory}. According to the World Health Organization, in 2019, it was the seventh leading cause of death globally and the second in high-income countries~\cite{johnsen2023incidence}. Alzheimer’s disease (AD) accounts for 50\%–75\% of cases with prevalence roughly doubling every five years after the age 65~\cite{lane2018alzheimer}. The lack of effective medical treatments underscores the need for early dementia and prevention~\cite{guo2024trajectory}.


Traditional clinical methods for AD detection, including MRI, PET imaging, and cerebrospinal fluid analysis, are costly, time-consuming, and impractical for large-scale early screening. This has led to efforts to find more accessible and cost-effective alternatives~\cite{yang2022deep}. Recent studies have increasingly identified language dysfunction as an early indicator of cognitive decline, making speech and language features as valuable biomarkers for the early detection of dementia~\cite{petti2020systematic, Language2024}. This growing body of research suggests that analyzing conversational patterns can provide critical insights into the onset of AD and other forms of dementia. However, a major limitation of existing studies is their reliance on single-language datasets, predominantly in English~\cite{perez2022alzheimer, NCMMSC2021, Agbavor2022plos}, with frequently utilized datasets including DementiaBank’s Pitt corpus, ADReSS, and ADReSSo.  This focus on only one language restricts the cross-linguistic generalizability of findings, making it difficult to apply these methods in multilingual or culturally diverse settings. Furthermore, the lack of multilingual datasets poses challenges for developing diagnostic tools that can be used globally~\cite{fraseretal2019multilingual}.
Expanding this scope, the recent Interspeech TAUKADIAL Challenge aims to investigate speech as a marker of cognitive function in a global health context~\cite{Benjamin2024}. This initiative provides data in two major languages, Chinese and English, to enhance understanding of the relationship between speech and cognition across diverse linguistic settings.
The Signal Processing Grand Challenge (SPGC) is another effort aimed at exploring the transferability of speech features across languages (English and Greek) for AD prediction~\cite{luz2023multilingual}. %
Despite these efforts, cross-linguistic speech-based detection of AD remains an open gap in the field. Additionally, most prior research has framed AD detection as a binary classification problem (AD vs. Healthy Controls (HC)), limiting the ability to identify Mild Cognitive Impairment (MCI)---a crucial intermediate stage for early intervention~\cite{shakeri2025natural}. Detecting MCI is particularly important because individuals at this stage have a higher likelihood of progressing to AD, yet timely interventions can potentially slow or prevent further decline~\cite{Knopman2014mayo}. However, the lack of datasets with labeled MCI cases has restricted the development of models that can distinguish between these three cognitive states.

To address this significant gap, we present MultiConAD, a unified, multilingual conversational dataset for Alzheimer's detection. MultiConAD consolidates 16 publicly available dementia-related conversational datasets across four languages: English, Spanish, Chinese, and Greek. These languages represent some of the most widely spoken languages in the world, with Mandarin Chinese and Spanish being the most spoken, followed by English~\cite{shakeri2025natural}. The corpus incorporates both audio and text modalities; most datasets include both, while a few contain only audio or only text. Crucially, these datasets feature a diverse range of cognitive assessment tasks, such as picture descriptions, story recall tasks, and verbal and semantic fluency tests.
As our second contribution, we perform a more nuanced classification approach at a finer level of granularity by considering MCI as an intermediate category between AD and HC. Third, we conduct extensive experiments on variants of the dataset (monolingual, multilingual, and translated) using different text representations and classification algorithms. The overarching objective of this research is to investigate the impact of classification approach (binary vs. multiclass), language, and dataset composition (monolingual, multilingual, translated) on the performance of Alzheimer's detection models using conversational data.



Our results reveal interesting language-specific trends: while some languages benefit from multilingual training, suggesting shared markers of cognitive decline, other languages perform better when trained separately, indicating unique language-dependent patterns. 
These findings highlight the importance of tailoring AD detection models to specific language while also demonstrating the potential advantages of leveraging multilingual training for improved generalization. 
Beyond these immediate findings, MultiConAD faciliates future research in several key areas, including optimizing language-specific models through deeper linguistic analysis and leveraging cross-lingual transfer learning.

In summary, this paper presents the following contributions: (1) we introduce and release a unified multilingual conversational dataset for early Alzheimer’s detection; (2) we experimentally evaluate and compare various approaches for leveraging monolingual, multilingual, and translated datasets for both binary and multiclass classification tasks; and (3) we offer a thorough analysis of the results, emphasizing the key challenges associated with this problem. All resources developed in this study, including instructions on how to obtain the dataset and model implementations, are publicly accessible at \url{https://github.com/ArezoShakeri/MultiConAD}.










