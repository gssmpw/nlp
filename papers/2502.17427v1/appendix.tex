\appendix

\clearpage

\section*{Organization}

The Appendix is organized as follows.


\begin{itemize}
    \item \Cref{app:proof-noncontextual} contains proofs of our noncontextual method's convergence.
    \item \Cref{app:confidence} discusses confidence interval guarantees for adaptive IPW estimators induced by our design.
    \item \Cref{app:multigroup} presents the general multigroup adaptive design framework and proves its efficiency guarantees.
    \item \Cref{app:datasets} describes additional empirical results. 
\end{itemize}



\section{Non-Contextual Setting: Proof of Theorem~\ref{thm:regret} and of Lemma~\ref{lemma:l2deviation}}\label{app:proof-noncontextual}

\subsection{Neyman Regret Analysis for \ClipOGDSC: Proof of Theorem~\ref{thm:regret}}

We establish \Cref{thm:regret} via a sequence of claims.

\begin{claim}[Optimal Probability Bounds; Lemma C.2 of \citet{dai2023clip}] \label{claim:pstar}
    The optimal fixed probability $p^*_T$ for any time horizon $T$ satisfies, under \cref{ass:bounds}, the following inequality, defining the constant $A = 1 + C/ c \geq 2$:
    \[
    \frac{1}{A} \leq p^*_T \leq 1 - \frac{1}{A}.
    \]
\end{claim}

\begin{claim}[How Quickly Optimal Probability Enters Admissible Region] \label{claim:pstartime}
    Under \Cref{ass:bounds}, let $A = 1 + C/ c \geq 2$. Then, for any time horizon $T$, the optimal probability $p^*_T$ will satisfy:
    \[
    t \geq t^* \implies p^*_T \in [\delta_t, 1-\delta_t], \quad \text{ where } t^* := \hinv(A).
    \]
\end{claim}
\begin{proof}
    With \ref{claim:pstar} in hand, we have that as soon as $\delta_t \leq 1/A$, the optimal probability $p^*_T$ (for any $T$) is guaranteed to be in the admissible interval $[\delta_t, 1-\delta_t]$. This is equivalent to requiring $h(t) \geq A$, which by definition of $\hinv$ and by the strictly increasing nature of $h$ is equivalent to $t \geq \hinv(A)$.
\end{proof}

\begin{claim}[Gradient Raw Moment Bounds] \label{claim:moments}
    Under \Cref{ass:bounds}, for every $t \geq 1$ we have the following bounds in expectation wrt.\ the design's randomness: \[\E[|g_t|] \leq 2 C^2 h(t)^2, \quad \E[g_t^2] \leq 2 C^4 h(t)^5.\]
\end{claim}
\begin{proof}
    The bounds follow as shown in Lemma C.5 of \citet{dai2023clip}, by just expanding out the first and second raw absolute moment of the gradient estimator defined above; we will get $\E[|g_t|] \sim \delta^{-2}_t (y_t(1)^2 + y_t(0)^2)$, and $\E[g_t^2] \sim \delta^{-5}_t (y_t(1)^4 + y_t(0)^4)$, so the statement follows from our \Cref{ass:bounds}, or from \citet{dai2023clip}'s assumption on the boundedness of the second and fourth moments of the two populations.
\end{proof}

\begin{claim}[Strong Convexity of Objective] \label{claim:strong}
For any round $t \geq 1$, and for any $p, p' \in (0, 1)$, the objective function will satisfy:
\[
f_t(p) - f_t(p') \leq f'(p) \cdot (p - p') - c^2 (p-p')^2.
\]
\end{claim}
\begin{proof}
    To show this, it suffices to establish $2c^2$-strong convexity of $f_t(p) = \frac{y_t(0)^2}{p} + \frac{y_t(1)^2}{1-p}$, and we will do so by verifying that $f''(p) \geq 2c^2$ for all $p \in (0, 1)$. Indeed, note that $f''(p) = 2 \left(\frac{y_t(0)^2}{p^3} + \frac{y_t(1)^2}{(1-p)^3} \right) \geq 2(y_t(0)^2 + y_t(1)^2) \geq 2c^2$ since $p \in (0, 1)$ and by definition of $c$ in \Cref{ass:bounds}.
\end{proof}

\begin{claim} \label{claim:onestep}
    For any $t \geq 1$, any setting of $\eta_t > 0$, $\delta_t = 1/h(t)$, and for any point $p^* \in \{p^*_t\}_{t\geq 1}$, we have in expectation over the randomness of the design:
    \begin{align*}
       \E[f_t(p_t) - f_t(p^*)] \leq \left(\frac{1}{2\eta_t} - c^2\right) \E[(p_t - p^*)^2] - \frac{1}{2 \eta_t} \E[(p_{t+1}-p^*)^2] + \eta_t \cdot (C h(t))^5  \\+ 2 \cdot 1[t \leq t^*] \cdot \left(\frac{1}{\eta_t \cdot h(t)} + (C h(t))^2\right).
    \end{align*}
\end{claim}
\begin{proof}
    By \Cref{claim:strong} applied to $p = p_t$ and $p' = p^*$, we have $f_t(p_t) - f_t(p^*) \leq f'(p_t) \cdot (p_t - p^*) - c^2 (p_t-p^*)^2$. Now, we can bound the first term on the right-hand side as follows. 

    First, start with the inequality: $|p_{t+1} - p^*| \leq |p_t - \eta_t g_t - p^*| + \delta_t \cdot 1[p^* \not\in [\delta_t, 1-\delta_t]]$, which follows by Lemma C.1 in \citet{dai2023clip}. By \Cref{claim:pstartime}, we have that $1[p^* \not\in [\delta_t, 1-\delta_t]] = 0$ for all $t \geq t^*$, implying that $1[p^* \not\in [\delta_t, 1-\delta_t]] \leq 1[t \leq t^*]$. Thus, we have $|p_{t+1} - p^*| \leq |p_t - \eta_t g_t - p^*| + \delta_t \cdot 1[t \leq t^*]$. Squaring this inequality, we arrive, after rearranging terms and using the triangle inequality, at
    \[
    (p_{t+1} - p^*)^2 \leq (p_t-p^*)^2 + \eta_t^2 g_t^2 - 2 \eta_t g_t (p_t - p^*) + 4 \cdot 1[t \leq t^*] \cdot \eta_t \cdot \delta_t \left(\frac{1}{\eta_t} + \frac{|g_t|}{2}\right).
    \]
    Rearranging terms once again, we get:
    \[
    2 \eta_t g_t (p_t - p^*)  \leq (p_t-p^*)^2 + \eta_t^2 g_t^2 - (p_{t+1} - p^*)^2 + 4 \cdot 1[t \leq t^*] \cdot \eta_t \cdot \delta_t \left(\frac{1}{\eta_t} + \frac{|g_t|}{2}\right).
    \]
    Dividing this by $\eta_t > 0$, we get:
    \[
    2 g_t (p_t - p^*)  \leq \frac{1}{\eta_t} \left((p_t-p^*)^2 - (p_{t+1} - p^*)^2\right) + \eta_t g_t^2  + 4 \cdot 1[t \leq t^*] \cdot \delta_t \left(\frac{1}{\eta_t} + \frac{|g_t|}{2}\right).
    \]
    Noting that $\E[g_t | \cF_t] = f'_t(p_t)$ by definition of $g_t$, as well as using the bounds on the expected gradient moments from \Cref{claim:moments}, we can take the expectation of the last inequality to obtain:
    \begin{align*}
        2 f'_t(p_t) (p_t - p^*) &\leq \frac{1}{\eta_t} \left((p_t-p^*)^2 - \E[(p_{t+1} - p^*)^2 | \cF_t] \right) + \eta_t \E[g_t^2 | \cF_t]  + 4 \cdot 1[t \leq t^*] \cdot \delta_t \left(\frac{1}{\eta_t} + \frac{\E[|g_t| | \cF_t]}{2}\right) \\
        &\leq \frac{1}{\eta_t} \left((p_t-p^*)^2 - \E[(p_{t+1} - p^*)^2 | \cF_t]\right) + \eta_t \cdot 2C^4 h(t)^5  + 4 \cdot 1[t \leq t^*] \cdot \delta_t \left(\frac{1}{\eta_t} + C^2 h(t)^2\right).
    \end{align*}

    Returning to the strong convexity-induced inequality above, we thus have:
    \begin{align*}
        f_t(p_t) - f_t(p^*) &\leq f'(p_t) \cdot (p_t - p^*) - c^2 (p_t-p^*)^2\\
        &\leq \frac{1}{2\eta_t} \left((p_t-p^*)^2 - \E[(p_{t+1} - p^*)^2 | \cF_t]\right) + \eta_t \cdot C^4 h(t)^5  \\
        &\qquad + 2 \cdot 1[t \leq t^*] \cdot \delta_t \left(\frac{1}{\eta_t} + C^2 h(t)^2\right) - c^2 (p_t-p^*)^2\\
        &= \left(\frac{1}{2\eta_t} - c^2\right) (p_t - p^*)^2 - \frac{1}{2 \eta_t} \E[(p_{t+1}-p^*)^2 | \cF_t] + \eta_t \cdot C^4 h(t)^5  \\
        &\qquad+ 2 \cdot 1[t \leq t^*] \cdot \delta_t \cdot \left(\frac{1}{\eta_t} + C^2 h(t)^2\right).
    \end{align*}

    Now, taking expectation again, now with respect to the randomness up through $\cF_t$, we obtain the statement of this claim.
\end{proof}

\begin{claim}[Convergence Bound] \label{claim:summingterms}
    For any time horizon $T$, and any $p^* \in \{p^*_t\}_{t\geq 1}$, we have:
    \begin{align*}
        &\sum_{t=1}^T \E[f_t(p_t) - f_t(p^*)] \\ 
        &\leq - c^2 (T+1) \E[(p_{T+1} - p^*)^2] + \frac{C^5}{2c^2} h(T)^5(\log (T+1) + 1)  + 2 C^2 \left(1 + \frac{C}{c} \right)^2 \hinv\left(1+\frac{C}{c}\right) \\ 
        &\qquad+ 2c^2 \left(\hinv\left(1+\frac{C}{c}\right) + 1\right)^2.
    \end{align*}
\end{claim}
\begin{proof}
    Summing the inequality in \Cref{claim:onestep} from $t=1$ to $t=T$, we obtain via telescoping sums:
    \begin{align*}
        &\sum_{t=1}^T \E[f_t(p_t) - f_t(p^*)] \\
        &\leq \sum_{t=1}^T \left(\frac{1}{2\eta_t} - c^2\right) \E[(p_t - p^*)^2] - \sum_{t=1}^T \frac{1}{2 \eta_t} \E[(p_{t+1}-p^*)^2] + \sum_{t=1}^T \eta_t \cdot (C h(t))^5  \\ 
        &\qquad + \sum_{t=1}^T 2 \cdot 1[t \leq t^*] \cdot \left(\frac{1}{\eta_t \cdot h(t)} + (C h(t))^2\right) \\
        &\leq \sum_{t=1}^T \left(\frac{1}{2\eta_t} - c^2\right) \E[(p_t - p^*)^2] - \sum_{t=1}^T \frac{1}{2 \eta_t} \E[(p_{t+1}-p^*)^2] + \sum_{t=1}^T \eta_t \cdot (C h(t))^5  \\ 
        &\qquad+ 2 \sum_{t=1}^{t^*} \left(\frac{1}{\eta_t \cdot h(t)} + (C h(t))^2\right) \\
        &\leq \sum_{t=1}^T \left(\frac{1}{2\eta_t} - c^2\right) \E[(p_t - p^*)^2] - \sum_{t=1}^T \frac{1}{2 \eta_t} \E[(p_{t+1}-p^*)^2] \\ &\qquad + (C h(T))^5 \sum_{t=1}^T \eta_t  + 2 t^* \cdot (C h(t^*))^2 + 2 \sum_{t=1}^{t^*} \frac{1}{\eta_t \cdot h(t)} \\
        &= \left(\frac{1}{2\eta_1}-c^2 \right)\E[(p_1 - p^*)^2] - \frac{1}{2\eta_{T+1}} \E[(p_{T+1} - p^*)^2] \\
        &+ \sum_{t=2}^T \left(\frac{1}{2\eta_t} - \frac{1}{2\eta_{t-1}} - c^2\right) \E[(p_t - p^*)^2] + (C h(T))^5 \sum_{t=1}^T \eta_t  + 2 t^* \cdot (C h(t^*))^2 + 2 \sum_{t=1}^{t^*} \frac{1}{\eta_t \cdot h(t)} \\
        &\leq - c^2 (T+1) \E[(p_{T+1} - p^*)^2] + \frac{(C h(T))^5}{2c^2} (\log (T+1) + 1)  + 2 t^* \cdot (C h(t^*))^2 + 4c^2 \sum_{t=1}^{t^*} \frac{t}{h(t)}.
    \end{align*}
    Finally, recalling the definition of $t^* = \hinv(A) = \hinv(1+C/c)$ and substituting it in, we obtain the desired claim.
\end{proof}

Finally, with the result of \Cref{claim:summingterms} in hand, we observe that (1) the term $- c^2 (T+1) \E[(p_{T+1} - p^*)^2]$ is nonpositive and can thus be ignored, (2) the second term on the right hand side is asymptotically $O((h(T))^2 \cdot \log T)$, and (3) the third and fourth terms on the right hand side are constant with respect to $T$ and only a function of the constants $C, c$ of the problem. This gives the desired result.

\subsection{Convergence of Treatment Probabilities of \ClipOGDSC: Proof of Lemma~\ref{lemma:l2deviation}}

We will make use of \Cref{claim:summingterms} from the previous subsection. Simply rearranging the terms, we obtain the following bound for the deterministic setting:
    \[
    c^2 (T+1) \E[(p_{T+1} - p^*_T)^2] \leq - \sum_{t=1}^T \E[f_t(p_t) - f_t(p^*_T)] + \frac{C^2}{2c^2} h(T)^2(\log (T+1) + 1)  + O(1),
    \]
    where the $O(1)$ term hides terms in the bound that do not depend on $T$. Dividing through by $c^2 \cdot (T+1)$ and reindexing for convenience, we obtain the desired result:
    \[
        \E[(p_{T} - p^*_T)^2] \leq -\Theta\left(\frac{\E[\Reg_T]}{T}\right) + O\left(\frac{(h(T))^2 \log T}{T}\right). \qedhere
    \]


\section{Confidence Interval Guarantees: Proof Sketch for Theorem~\ref{thm:confidence}} \label{app:confidence}

\begin{remark}[Chebyshev vs.\ Wald Confidence Intervals]
As \citet{dai2023clip} point out, it appears that ClipOGD may lead to an asymptotically normal distribution of the IPW estimator. If this were true, that would allow us to get Wald-type confidence intervals for the IPW estimator based on the variance estimator $\Varhat$, which would be narrower than Chebyshev-type ones. Through some simulations, we observed that asymptotically, the z-score of the IPW estimator induced by our adaptive scheme appears to satisfy asymptotic normality. However, below we only prove the validity of Chebyshev-type confidence intervals, and leave Wald-type CIs to be explored in future work. \qed
\end{remark}

We will convince ourselves that the techniques employed in \citet{dai2023clip} for proving the validity of this variance estimator apply to a broad class of adaptive sampling schemes. \citet{dai2023clip} state this result for their particular adaptive design but mention that it may apply to other learning rate and clipping rate settings. And indeed, we find that while their approach does depend on the adaptive design having sufficiently slowly decaying clipping rate and vanishing Neyman regret, it is oblivious to hyperparameters such as the learning rate. Moreover, we find that the condition of having asymptotically nonnegative Neyman regret, which \citet{dai2023clip} impose on the design, is also not necessary to ensure that the variance estimator $\Varhat$ is conservatively valid.

For easier tracking of the relevant quantities, recall the notation: $S_T(i) := \sqrt{\frac{1}{T} \sum_{t=1}^T y_t(i)^2} \text{ for } i \in \{0, 1\}.$ Following \citep{dai2023clip}, we define the quantities $A_T(1) = (S_T(1))^2, A_T(0) = (S_T(0))^2$, as well as the quantities $\widehat{A_T(1)} = \frac{1}{T} \sum_t y_t(1)^2 \frac{Z_t}{p_t}$, $\widehat{A_T(0)} = \frac{1}{T} \sum_t y_t(0)^2 \frac{1-Z_t}{1 - p_t}$ that estimate them in an unbiased way. Recalling that the variance of the optimal nonadaptive design (i.e., the variance of the IPW estimator that uses $p^*_T$ as its fixed sampling probability on all rounds $t=1\ldots T$) is \[ \frac{2}{T} (1+\rho) S_T(1) S_T(0) \leq \mathrm{VB} := \frac{4}{T} \sqrt{A_T(1) A_T(0)},\] we can see that $\Varhat = \frac{4}{T} \sqrt{\Aone \Azero}$ simply aims to approximate the upper bound $\mathrm{VB}$ on the optimal fixed-probability sampling scheme's variance. And given that our design has a no-regret guarantee with respect to this benchmark, $\Varhat$ thus also asymptotically approximates the upper bound on our (and any other such) design's induced IPW estimator variance $\Varalg$. This is the blueprint of the proof, and we will now briefly revisit the technical steps in \citet{dai2023clip} that make this blueprint argument work.

    First, Proposition D.1 of \citet{dai2023clip} proves that
    \[
    \left| \E[\Aone \Azero] - A_T(1) A_T(0) \right| \leq \frac{C^4}{T},
    \]
    which by tracking the proof can be seen to not depend on the sampling scheme.

    Second, by generalizing the result and steps of Proposition D.2 of \citet{dai2023clip}, we can bound the variance of the (normalized version of the) estimator $\Varhat$ as:
    \[
    \Var(\Aone \Azero) \leq \frac{C^8 \cdot h(T)}{T} + \frac{C^8 \cdot (h(T))^2}{T^2} \leq \frac{2 C^8 \cdot h(T)}{T}.
    \]
    Thus, applying Chebyshev's inequality to this variance bound and using the preceding in-expectation bound, we conclude that $\Aone \Azero \to A_T(1) A_T(0)$ in probability at the rate $O_p((h(T)/T)^{1/2})$.

    Now, as in the proof of Theorem 5.1 of \citet{dai2023clip}, we can observe that a Continuous Mapping Theorem can be applied to this in-probability convergence result to give the implication that $\sqrt{\Aone \Azero} \to \sqrt{A_T(1) A_T(0)}$ at the same asymptotic rate $O_p((h(T)/T)^{1/2})$. Indeed, since the target random variable $A_T(1) A_T(0)$ is bounded below by $c^2$ by \Cref{ass:bounds}, the square root transformation will be Lipschitz on the relevant range (i.e., away from zero).

    Finally, to establish the validity of the Chebyshev-type confidence intervals given above, it suffices to look at the z-score statistic $\zeta = \frac{\tau_T - \hat{\tau}_T}{\sqrt{\Var(\hat{\tau}_T)}}$ and the estimated z-score statistic $\zeta' = \frac{\tau_T - \hat{\tau}_T}{\sqrt{\Varhat}}$ and establish that $\zeta$ stochastically dominates $\zeta'$. Towards this, note as in \citet{dai2023clip} that:
    \[
    \zeta' = \zeta \cdot \left( \sqrt{\frac{\Var(\hat{\tau}_T)}{\mathrm{VB}}} \cdot \sqrt{\frac{T \cdot \mathrm{VB}}{T \cdot \Varhat}} \right).
    \]
    First, since the estimator $\hat{\tau}_T$ is induced by a no-regret adaptive design and since $\mathrm{VB}$ is an upper bound on the variance of the best fixed SRS scheme (which serves as the benchmark of the design's regret performance), we have that $\limsup_{T\to \infty} \frac{\Var(\hat{\tau}_T)}{\mathrm{VB}} \leq 1$. Second, from what we just obtained, $T \cdot \Varhat \to T \cdot \mathrm{VB}$ in probability, which in view of $T \cdot \Varhat$ being lower-bounded by a constant by \Cref{ass:bounds} implies by the Continuous Mapping Theorem that $\sqrt{\frac{T \cdot \mathrm{VB}}{T \cdot \Varhat}}$ converges to $1$ in probability. By Slutsky's theorem, this proves the desired stochastic domination and thus implies that the proposed confidence interval construction is asymptotically (conservatively) valid.


\section{Multigroup Adaptive Design: Proofs and Details} \label{app:multigroup}


\subsection{OLO Primitives} \label{app:multigroup-se}

Our multigroup design will rely on a sequence of reductions, derived with the help of some online learning machinery: a recent reduction of \citet{SleepingExpertsOrabona} and scale-free algorithms by \citet{orabona2018scale}.
First, we spell out the algorithmic primitives that we will require.

\begin{definition}[OLO algorithm; OLO regret]
    An \emph{OLO (online linear optimization) algorithm} $\cA$ over domain $V \subseteq \R^d$, where $d \geq 1$ is the dimension of the problem, sequentially receives vectors $\ell_t \in \R^d$, $t = 1, 2, \ldots$. Each $\ell_t$ is interpreted as the ``gradient'', or the ``loss'', that $\cA$ suffers at round $t$.
    
    Each round, before seeing $\ell_t$, algorithm $\cA$ outputs iterate $v_t \in V$ as a function of past history. The algorithm's \emph{regret} at any time $T$ is defined as the total loss incurred by its iterates minus the total loss of the best-in-hindsight admissible solution:
    \[
    \Reg_T(\cA) := \max_{v \in V} \Reg_T(\cA; v), \quad \text{where } \Reg_T(\cA; v) = \sum_{t=1}^T \langle \ell_t, v_t - v \rangle \text{ for } v \in V.
    \]
\end{definition}

\begin{definition}[Sleeping Experts algorithm; SE regret]
    A \emph{sleeping experts (SE) algorithm} $\cA$ over domain $V \subseteq \R^d$, where $d \geq 1$ is the number of ``sleeping experts'', sequentially receives vectors $a_t \in \{0, 1\}^d$ and $\ell_t \in \R^d$ at rounds $t = 1, 2, \ldots$. The vector $a_t$ has the interpretation that $a_{t, i} \in \{0, 1\}$ (for each $i \in [d]$) denotes whether expert $i$ is ``active'' (1) or ``inactive'' (0) in round $t$. The vector $\ell_t$ has the interpretation that at any round $t$, for all active experts $i$ (i.e., $a_{t, i} = 1$), expert $i$'s loss is $\ell_{t, i}$, while for all inactive experts $i$ the loss coordinate $\ell_{t, i}$ is (arbitrarily) equal to $0$.
    
    Each round, after seeing $a_t$ but before seeing $\ell_t$ (i.e., after seeing which experts are active but before seeing their losses), the algorithm outputs a distribution $v_t \in \Delta_d$ as a function of past history, such that $v_{t, i} = 0$ for all inactive experts (i.e., for all $i$ such that $a_{t, i} = 0$). In words, at each round the algorithm is required to output a distribution $v_t$ over the currently active experts only. 
    
    The algorithm's \emph{Sleeping Experts regret} at any time $T$ is defined as the upper bound, over all experts $i \in [d]$, on its performance relative to expert $i$ over those rounds $t$ \emph{on which $i$ was active}:
    \[
    \RegSE_T(\cA) := \max_{i \in [d]} \sum_{t=1}^T a_{t, i} \cdot (\langle \ell_t, v_t \rangle - \ell_{t, i}).
    \]
\end{definition}

\paragraph{Scale-Free OLO} We will make use of a \emph{scale-free} OLO algorithm \citep{orabona2018scale} to design a base algorithm for our multigroup regret algorithm. The property of any such algorithm is that its regret bound does not require the norms of the gradients $\ell_t$ to be bounded in $[0, 1]$ for some norm (like standard OLO methods typically require).

\begin{fact}[Theorem 1 of~\citep{orabona2018scale}] \label{fact:scale-free}
   Fix any norm $\norm{\cdot}$ and its dual norm $\norm{\cdot}_*$. Then, \cref{alg:SOLO_original} called SOLO FTRL  achieves, for any convex closed set $V \subseteq \R^d$, the following regret bound \emph{to any point $v \in V$} that scales with the magnitude of the losses/gradients:
   \[
   \Reg_T(\mathrm{SOLO \ FTRL}; v) \leq \left(R(v) + 2.75\right) \sqrt{\sum_{t=1}^T \norm{\ell_t}^2_* } + 3.5 \min \left\{ \sqrt{T-1}, \mathrm{diam}(V) \right\} \max_{t \in [T]} \norm{\ell_t}_*.
   \]
   where $\mathrm{diam}(V) = \sup_{v_1, v_2 \in V} \norm{v_1-v_2}$, and where SOLO FTRL is parameterized by an arbitrary nonnegative continuous $1$-strongly-convex regularizer $R: V \to \R$.
\end{fact}

\begin{algorithm}
\caption{$\cA_{SOLO}$: SOLO FTRL \citep{orabona2018scale}}
\label{alg:SOLO_original}

\begin{algorithmic}
\STATE Receive domain $V \subseteq \R^d$ base regularizer $R(w)$, and norm $\norm{\cdot}$.
\STATE Initialize $L_0 \gets \textbf{0}^d, q_0 \gets 0$.
\FOR{$t = 1, 2, \ldots$}
    \STATE Compute new weights $w_t \gets \argmin\limits_{w \in V} \left\{\langle L_{t-1}, w \rangle + R_t(w) \right\}$, where $R_t(w) = \sqrt{q_{t-1}} \cdot R(w)$.
    \STATE Receive loss vector $\ell_t$.
    \STATE Set $L_t \gets L_{t-1} + \ell_t$.
    \STATE Set $q_t \gets q_{t-1} + \norm{\ell_{t}}^2_*$.
\ENDFOR
\end{algorithmic}
\end{algorithm}


\subsection{Designing a Scale-Free Sleeping Experts Algorithm}

Now, let us instantiate the above \cref{fact:scale-free} appropriately. First, set the norm for the regret bound to be the $2$-norm: $\norm{\cdot} = \norm{\cdot}_* = \norm{\cdot}_2$. Second, set the regularizer to be $R(v) := \norm{v}^2_2$ for $v \in V$, which is $1$-convex with respect to the $2$-norm. Third, set the domain of the algorithm to be the non-negative orthant: $V = \R^d_{\geq 0}$. 
We then arrive at the following guarantee.

\begin{corollary}[of Fact~\ref{fact:scale-free}] \label{cor:SOLO}
    With the nonnegative orthant $V = \R^d_{\geq 0}$ as domain and the squared $L_2$-norm as regularizer, SOLO FTRL achieves the following scale-free regret bound for all $v \in V$:
    \[
    \Reg_T(\mathrm{SOLO \ FTRL}; v) \leq \left(\norm{v}^2_2 + 6.25\right) \max_{t \in [T]} \norm{\ell_t}_2 \sqrt{T}.
    \]
%
    The instantiation of SOLO FTRL for these specific choices is given in Algorithm~\ref{alg:SOLO}.
\end{corollary}

\begin{algorithm}
\caption{$\cA_{SOLO}$: Instantiation for scale-free sleeping experts}
\label{alg:SOLO}

\begin{algorithmic}[1]
\STATE Initialize $L_0 \gets \textbf{0}^d, q_0 \gets 0$.
\FOR{$t = 1, 2, \ldots$}
    \STATE Set weights $w_t \gets \max \left\{ \textbf{0}^d , - \frac{1}{\sqrt{q_{t-1}}}L_{t-1} \right\}$ (coordinate-wise maximum).
    \STATE Receive loss vector $\ell_t \in \R^d_{\geq 0}$.
    \STATE Set $L_t \gets L_{t-1} + \ell_t$.
    \STATE Set $q_t \gets q_{t-1} + \norm{\ell_{t}}^2_2$.
\ENDFOR
\end{algorithmic}
\end{algorithm}

We note that the update for $w_t$ in \cref{alg:SOLO} is the solution to the original argmax problem in \cref{alg:SOLO_original}, with the nonnegative orthant as domain and the rescaled $L_2$-norm as regularizer.

\paragraph{Scale-Free Sleeping Experts} Now, we will turn this just obtained scale-free OLO regret guarantee into a scale-free sleeping experts regret guarantee. We will utilize a recent black-box reduction mechanism of \citet{SleepingExpertsOrabona}, which proceeds as follows.

\begin{fact}[Sleeping Experts to OLO Reduction~\citep{SleepingExpertsOrabona}]
    Consider a sleeping experts setting with $d$ experts. Define any base OLO algorithm $\cA$ with nonnegative orthant $V = \R^d_{\geq 0}$ as the domain. Then Algorithm~\ref{alg:SE-OLO-Red}, which we refer to as $\cA_{OLO\to SE}$, constructs a sequence $v_1, v_2, \ldots$ of distributions over active experts that attains the following sleeping experts regret bound:
    \[
    \RegSE_T(\cA_{OLO\to SE}) = \max_{v \in \mathrm{SB}(\R^d)}\Reg_T \left( \cA \left( \left\{\widetilde{\ell}_t \right\}_{t \in [T]} \right); v \right).
    \]
    Here, $\mathrm{SB}(\R^d)$ as the collection of the $d$ standard basis (unit) vectors of $\R^d$; 
    and the vectors $\{\widetilde{\ell}_t\}_{t \in [T]}$, defined in Algorithm~\ref{alg:SE-OLO-Red}, are surrogate loss vectors. Note that these surrogate losses satisfy $\norm{\widetilde{\ell}_t}_\infty \leq 2 \norm{\ell_t}_\infty$ relative to the original losses $\{\ell_t\}_{t \in [T]}$.
\end{fact}

\begin{algorithm}[ht]
\begin{algorithmic}
\STATE Initialize any base OLO algorithm $\cA$ with nonnegative orthant $V = \R^d_{\geq 0}$ as domain.
\FOR{$t=1, 2, \ldots$}
    \STATE Get unscaled prediction $w_t \in \R^d_{\geq 0}$ from $\cA$.
    \STATE Receive indicator vector describing which experts are active: $a_t \in \{0, 1\}^d$.
    \STATE Construct distribution $v_t \in \Delta_d$ as: $v_{t, i} = \frac{a_{t, i} w_{t, i}}{\langle a_t, w_t \rangle}$ for $i \in [d]$.
    \STATE Receive loss vector $\ell_t \in \R^d$.
    \STATE Construct surrogate loss vector $\widetilde{\ell}_t$ as $\widetilde{\ell}_{t, i} = a_{t, i} (\ell_{t, i} - \langle \ell_t, v_t \rangle)$ for $i \in [d]$, and send it to $\cA$.
\ENDFOR
\end{algorithmic}
\caption{$\cA_{OLO\to SE}$: Sleeping Experts to OLO Reduction~\citep{SleepingExpertsOrabona}}
\label{alg:SE-OLO-Red}
\end{algorithm}


To obtain sleeping experts regret bounds scaling with the norm of the losses, we can implement this reduction with the scale-free \cref{alg:SOLO} at its base. Formally, we have the following statement.

\begin{theorem}[Scale-Free Sleeping Experts Algorithm] \label{thm:scalefree-SE}
    Consider a sleeping experts setting with $d$ experts. Initialize Algorithm~\ref{alg:SE-OLO-Red} using \cref{alg:SOLO} (an instance of SOLO FTRL with settings described in Corollary~\ref{cor:SOLO}) as its base OLO subroutine. Call the resulting sleeping experts algorithm $\cA_\text{SOLO SE}$, with the pseudocode given in \cref{alg:SE}. Then, SOLO SE obtains the following sleeping experts regret bound on any sequence of losses $\{\ell_t\}_{t \in [T]}$:
    \[
    \RegSE_T \left(\cA_\text{SOLO SE} \left(\{\ell_t\}_{t \in [T]}\right) \right) \leq 15 \max_{t \in [T]} \norm{\ell_t}_\infty \sqrt{d T}.
    \]
\end{theorem}

\begin{algorithm}[ht]
\caption{$\cA_\mathrm{SOLO \ SE}$: Sleeping Experts Algorithm}
\label{alg:SE}

\begin{algorithmic}[1]
\STATE Initialize $\cA_{SOLO}$, an instance of Algorithm~\ref{alg:SOLO}.
\FOR{$t=1, 2, \ldots$}
    \STATE Receive unscaled weights $w_t \in \R^d_{\geq 0}$ from $\cA_{SOLO}$.
    \STATE Receive indicator vector describing which experts are active: $a_t \in \{0, 1\}^d$.
    \STATE Set rescaled weights $v_t \in \Delta_d$ as: $v_{t, i} = \frac{a_{t, i} w_{t, i}}{\langle a_t, w_t \rangle}$ for $i \in [d]$.
    \STATE Receive loss vector $\ell_t \in \R^d$.
    \STATE Set surrogate loss vector $\widetilde{\ell}_t$ as $\widetilde{\ell}_{t, i} = a_{t, i} (\ell_{t, i} - \langle \ell_t, v_t \rangle)$ for $i \in [d]$.
    \STATE Send $\widetilde{\ell}_t$ to $\cA_{SOLO}$.
\ENDFOR
\end{algorithmic}
\end{algorithm}


\subsection{First-Order Neyman Regret Minimization} \label{app:multigroup-first_order}

We now formalize (and generalize) how the ClipOGD design operates. This formalization will define the scope of noncontextual adaptive designs that can be used to estimate group propensities for all groups in our multigroup design.

\begin{definition}[First-order Neyman Regret Minimization] \label{def:first_order_ATE}
Recall the Neyman objectives: $f_t(p) = \frac{y_t(1)^2}{p} + \frac{y_t(0)^2}{1-p}$ for $p \in (0, 1)$, $t \geq 1$, where .$\{(y_t(1), y_t(0))\}_{t \geq 1}$ are the potential outcomes. 

A first-order Neyman regret minimization algorithm $\cA_\mathrm{ATE}$ follows the following protocol for sequential ATE estimation: At each round $t = 1, 2, \ldots$, $\cA_\mathrm{ATE}$ decides on a treatment probability $p_t \in (1/h(t), 1-1/h(t))$, where $h: \mathbb{N}_+ \to \R_{> 0}$ is a strictly increasing clipping function. After that, $\cA_\mathrm{ATE}$ receives \emph{first-order feedback} $\widetilde{g}_t$ from the environment, which is a random variable that satisfies the following properties: (1) It is adapted to the natural filtration $\{\cF_t\}_{t \geq 1}$ of the process, i.e., the distribution of $\widetilde{g}_t$ is determined by all prior history up to and including determining $p_t$; (2) It is an unbiased estimator of $f'_t(p_t)$, in that $\E[ \widetilde{g}_t | \cF_{t-1}] = f'_t(p_t) = - \frac{y_t(1)^2}{p_t^2} + \frac{y_t(0)^2}{(1-p_t)^2}$. 
\end{definition}
%
It is easy to observe that \Cref{alg:strong} conforms to Definition~\ref{def:first_order_ATE}.  \Cref{alg:strong} is written as requiring direct access to the selected outcome $Y_t$, but this outcome is only used to compute the unbiased gradient estimator $f'_t(p_t)$.


\subsection{Multigroup-Adaptive Design via Sleeping Experts} \label{app:multigroup_general}


We are now ready to present a context-aware algorithm for online ATE estimation. It uses scale-free sleeping experts as derived above, as well first-order Neyman regret minimization algorithms as base learners. The following theorem states its most general guarantees (as well as the specific instantiation that gives MGATE). The proof is presented in the next subsection.


\begin{theorem}[Guarantees for Algorithm~\ref{alg:multigroup_general}] \label{thm:multigroup_general}
    Consider any first-order Neyman regret minimization algorithm $\cA_\mathrm{ATE}$ and any scale-free sleeping experts algorithm $\cA_\mathrm{SE}$. Fix any context space $\cX$ and any finite group family $\cG \subseteq 2^\cX$. If the base learners for all $G \in \cG$ are copies of $\cA_\mathrm{ATE}$, Algorithm~\ref{alg:multigroup_general}'s expected multigroup regret will be bounded for all $G \in \cG$ as:
    \begin{align*}
        &\E \left[\RegVar_T(\cA; G) \right]
        \leq \E \left[\RegSE_T(\cA_\mathrm{SE}) \right] + \E \left[\RegVar_T(\cA_\mathrm{ATE}(G)) \right].
    \end{align*}
    Moreover, Algorithm~\ref{alg:multigroup_general} is \emph{anytime}, as it does not require advance knowledge of the time horizon $T$.
    
    Instantiate Algorithm~\ref{alg:multigroup_general} using $h$-clipped \ClipOGDSC as the base ATE algorithm, for some strictly increasing $h$, and use $\cA_\text{SOLO SE}$ (\cref{alg:SE}) as the scale-free SE algorithm. Then, we obtain the MGATE design (\Cref{alg:AMGATE}) that simultaneously offers the following guarantees for all $G \in \cG$:
    \[
    \E \left[\RegVar_T(\cA; G) \right] = O \left( \sqrt{|\cG|} \cdot (h(T))^5 \cdot \sqrt{T} \right).
    \]
\end{theorem}


\begin{algorithm}[ht]
\begin{algorithmic}
\STATE \textbf{Input:} First-order Neyman regret minimization algorithm $\cA_\mathrm{ATE}$.
\STATE \textbf{Input:} Scale-free Sleeping Experts algorithm $\cA_\mathrm{SE}$.
\STATE \textbf{Input:} Feature space $\cX$, group family $\cG \subseteq 2^\cX$.
\STATE Initialize $|\cG|$ copies of $\cA_\mathrm{ATE}$: $\{\cA_\mathrm{ATE}(G)\}_{G \in \cG}$.
\FOR{$t=1, 2, \ldots$}
    \STATE Get context $x_t \in \cX$, let $\cG_t = \{G \in \cG : x_t \in G \}$.
    \FOR{active groups $G \in \cG_t$}
        \STATE Get group-specific advice $p_{t, G}$ from $\cA_\mathrm{ATE}(G)$.
    \ENDFOR
    \STATE Get weights $\{w_{t, G}\}_{G \in \cG_t}$ of active groups from $\cA_\mathrm{SE}$.
    \STATE Set treatment probability: $p_{t, \mathrm{eff}} \gets \sum_{G \in \cG_t} w_{t, G} \cdot p_{t, G}$.
    \STATE Set treatment decision: $Z_{t} \sim \mathrm{Bernoulli}(p_{t, \mathrm{eff}})$.
    \STATE Observe realized outcome: $Y_t \gets y_t(Z_{t})$.
    \FOR{active groups $G \in \cG_t$}
        \STATE Set estimated loss of $\cA_\mathrm{ATE}(G)$ as: 
        $\widetilde{\ell}_{t, G} \gets Y_t^2 \left( \frac{Z_{t}}{p_{t, \mathrm{eff}}} + \frac{1-Z_{t}}{1-p_{t, \mathrm{eff}}} \right) \left( \frac{Z_{t}}{p_{t, G}} + \frac{1-Z_{t}}{1-p_{t, G}} \right)$.
        \STATE Set estimated gradient of $\cA_\mathrm{ATE}(G)$ as:
        $\widetilde{g}_{t, G} \gets Y_t^2 \left( \frac{Z_{t}}{p_{t, \mathrm{eff}}} + \frac{1-Z_{t}}{1-p_{t, \mathrm{eff}}} \right) \left( - \frac{Z_{t}}{p_{t, G}^2} + \frac{1-Z_{t}}{(1-p_{t, G})^2} \right)$.
        \STATE Send estimated gradient $\widetilde{g}_{t, G}$ back to $\cA_\mathrm{ATE}(G)$.
    \ENDFOR   
    \STATE Send estimated losses $\{\widetilde{\ell}_{t, G}\}_{G \in \cG_t}$ back to $\cA_\mathrm{SE}$.
\ENDFOR
\end{algorithmic}
\caption{General Multigroup Adaptive Design}
\label{alg:multigroup_general}
\end{algorithm}










\subsection{Proof of Theorem~\ref{thm:multigroup_general}} \label{app:multigroup-proof}

    First, note that with the Neyman objective defined, as always, via $f_t(p) = \frac{y_t(1)^2}{p} + \frac{y_t(0)^2}{1-p}$ for $p \in (0, 1)$, we have for any group $G \in \cG$:
    \begin{align*}
        \RegVar_T(\cA; G) &= \sum_{t=1}^T \mathbbm{1}[x_t \in G] \left( f_t(p_{t, \mathrm{eff}}) - f_t(p^*_{T, G}) \right) \\
        &= \sum_{t=1}^T \mathbbm{1}[x_t \in G] \left( f_t \left(\sum_{G' \in \cG_t} w_{t, G'} \cdot p_{t, G'} \right) - f_t(p^*_{T, G}) \right) \\
        &\leq \sum_{t=1}^T \mathbbm{1}[x_t \in G] \left( \sum_{G' \in \cG_t} w_{t, G'} \cdot f_t \left(p_{t, G'} \right) - f_t(p^*_{T, G}) \right) \\
        &= \underbrace{\sum_{t=1}^T \mathbbm{1}[x_t \in G] \left( \sum_{G' \in \cG_t} w_{t, G'} \cdot f_t \left(p_{t, G'} \right) - f_t(p_{t, G}) \right)}_\text{Term 1: Sleeping Experts Regret of Aggregation Scheme}
        \\&\qquad + \underbrace{\sum_{t=1}^T \mathbbm{1}[x_t \in G] \left( f_t(p_{t, G}) - f_t(p^*_{T, G}) \right)}_\text{Term 2: ATE Neyman regret on Group $G$}.
    \end{align*}
    Here, $p^*_{T, G}$ denotes the best-in-hindsight static treatment allocation probability on the set of rounds up to round $T$ that correspond to group $G$. The inequality holds by convexity of the objective $f_t$.

    What we just did is partition the multigroup regret expression into two terms. The expectation of the second term is bounded by the expected regret of the group-specific ATE Neyman regret minimization algorithm: $\E[\text{Term 2}] \leq \E \left[\RegVar_T(\cA_\mathrm{ATE}) \right]$. The first term will be bounded by the sleeping experts regret of the aggregation algorithm.  
    
    To continue the analysis, we first collect the properties of the estimated outcomes, losses, and gradients. Namely, we have for any round $t$ and for any group $G \in \cG_t$:
    \begin{itemize}
        \item $\E \left[\widetilde{\ell}_{t, G} \, \Big|  \, \{Z_\tau\}_1^{t-1} \right] 
        = p_{t, \mathrm{eff}} \cdot \frac{(y_t(1))^2}{p_{t, \mathrm{eff}} \cdot p_{t, G}} + (1 - p_{t, \mathrm{eff}}) \cdot \frac{(y_t(0))^2}{(1 - p_{t, \mathrm{eff}}) \cdot (1-p_{t, G})} 
        = f_t(p_{t, G})$;
        \item $ \norm{\widetilde{\ell}_{t}}_\infty = \max_{G \in \cG_t} \left| \widetilde{\ell}_{t, G} \right| 
        \leq \max_{G \in \cG_t} \max\left\{ \frac{(y_t(1))^2}{p_{t, \mathrm{eff}} \cdot p_{t, G}}, \frac{(y_t(0))^2}{(1 - p_{t, \mathrm{eff}}) \cdot (1-p_{t, G})} \right\} 
        \leq C^2 h(t)^2$; 
        \item $\E \left[\widetilde{g}_{t, G} \, \Big|  \, \{Z_\tau\}_1^{t-1} \right] 
        = (1 - p_{t, \mathrm{eff}}) \cdot \frac{(y_t(0))^2}{(1 - p_{t, \mathrm{eff}}) \cdot (1-p_{t, G})^2} 
        - p_{t, \mathrm{eff}} \cdot \frac{(y_t(1))^2}{p_{t, \mathrm{eff}} \cdot p^2_{t, G}} 
        = f'_t(p_{t, G})$;
        \item $\E \left[|\widetilde{g}_{t, G}| \, \Big|  \, \{Z_\tau\}_1^{t-1} \right] 
        = (1 - p_{t, \mathrm{eff}}) \cdot \frac{(y_t(0))^2}{(1 - p_{t, \mathrm{eff}}) \cdot (1-p_{t, G})^2} 
        + p_{t, \mathrm{eff}} \cdot \frac{(y_t(1))^2}{p_{t, \mathrm{eff}} \cdot p^2_{t, G}} 
        \leq 2 C^2 h(t)^2$;
        \item $\E \left[\widetilde{g}_{t, G}^2 \, \Big|  \, \{Z_\tau\}_1^{t-1} \right] 
        = (1 - p_{t, \mathrm{eff}}) \cdot \left( \frac{(y_t(0))^2}{(1 - p_{t, \mathrm{eff}}) \cdot (1-p_{t, G})^2} \right)^2
        + p_{t, \mathrm{eff}} \cdot \left( \frac{(y_t(1))^2}{p_{t, \mathrm{eff}} \cdot p^2_{t, G}} \right)^2
        \leq 2C^4 h(t)^5$.
    \end{itemize}
    The last calculation holds owing to the fact that at any round $t$, the aggregated probability $p_{t, \mathrm{eff}}$ is a convex combination of the probabilities $p_{t, G}$ for all $G \in \cG_t$. Indeed that implies 
    \[\min\left\{p_{t, \mathrm{eff}}, \left(1-p_{t, \mathrm{eff}} \right)\right\} \geq \min_{G \in \cG_t} \left\{p_{t, G}, \left(1-p_{t, G} \right)\right\} \geq 1/h(t),\] 
    leading to the bound $\max \{1/p_{t, \mathrm{eff}}, 1/ \left(1-p_{t, \mathrm{eff}} \right)\} \leq h(t)$.

    By the first of these properties, we can bound the expectation of Term~1 as follows:
    \begin{align*}
        \E[\text{Term 1}] &= \E \left[\sum_{t=1}^T \mathbbm{1}[x_t \in G] \left( \sum_{G' \in \cG_t}  w_{t, G'} \cdot f_t \left(p_{t, G'} \right) - f_t \left(p_{t, G} \right) \right) \right] \\
        &= \E \left[\sum_{t=1}^T \mathbbm{1}[x_t \in G] \left( \sum_{G' \in \cG_t}  w_{t, G'} \cdot \E\left[\widetilde{\ell}_{t, G'} \, \Big|  \, \{Z_\tau\}_1^{t-1} \right] - \E\left[ \widetilde{\ell}_{t, G} \, \Big|  \, \{Z_\tau\}_1^{t-1} \right] \right) \right] \\
        &= \E \left[\sum_{t=1}^T \mathbbm{1}[x_t \in G] \cdot \E\left[ \sum_{G' \in \cG_t}  w_{t, G'} \cdot \widetilde{\ell}_{t, G'} - \widetilde{\ell}_{t, G} \, \Big|  \, \{Z_\tau\}_1^{t-1} \right] \right] \\
        &= \E \left[\sum_{t=1}^T \mathbbm{1}[x_t \in G] \cdot \E\left[ \langle  w_t, \widetilde{\ell}_t \rangle - \widetilde{\ell}_{t, G} \, \Big|  \, \{Z_\tau\}_1^{t-1} \right] \right] \\
        &= \sum_{t=1}^T \mathbbm{1}[x_t \in G] \cdot \E \left[ \E\left[ \langle  w_t, \widetilde{\ell}_t \rangle - \widetilde{\ell}_{t, G} \, \Big|  \, \{Z_\tau\}_1^{t-1} \right] \right] \\
        &= \E \left[ \sum_{t=1}^T \mathbbm{1}[x_t \in G] \left(\langle  w_t, \widetilde{\ell}_t \rangle - \widetilde{\ell}_{t, G} \right) \right] \\
        &\leq \E \left[\RegSE_T(\cA_\mathrm{SE}) \right].
    \end{align*}
    Thus, in combination with the above we indeed have:
    \[\E \left[\RegVarMG_T(\cA; \cG) \right] \leq \E \left[\RegSE_T(\cA_\mathrm{SE}) \right] + \E \left[\RegVar_T(\cA_\mathrm{ATE}) \right].\]

    We are now going to instantiate this regret bound with the following concrete choices. $\cA_\mathrm{SE}$ will be instantiated as the scale-free sleeping experts Algorithm~\ref{alg:SE}. For each copy of the first-order ATE Neyman regret minimization method, we will use the modification of \ClipOGDSC which uses, instead of its originally specified gradient estimator $g_t$, the gradient estimator $\widetilde{g}_t$ specified in our multigroup \cref{alg:multigroup_general}.

    Our specific choice of $\cA_\mathrm{SE}$ thus leads, by \Cref{thm:scalefree-SE} with our above bound on $\norm{\widetilde{\ell}_{t}}_\infty$ plugged in, to the following bound:
    \[
    \E \left[\RegSE_T(\cA_\mathrm{SE}) \right] \leq 15 \max_{t \in [T]} \norm{\ell_t}_\infty \sqrt{d T} \leq 15 C^2 \sqrt{|\cG|} \cdot (h(T))^2 T^{1/2}. 
    \]

    Now we update the regret bound of \ClipOGDSC to use $\widetilde{g}_t$ instead of $g_t$ at each round $t$.
    From the analysis of \Cref{claim:onestep} and \Cref{claim:summingterms} in the proof of \Cref{thm:regret}, we can distill the following inequality holding for \emph{any} unbiased gradient estimators $\{\widetilde{g}_t\}_{t \geq 1}$ and for the optimal $p^*$:
    \[
    \E[\RegVar_T(\cA_\mathrm{ATE})] = \sum_{t=1}^T \E[f_t(p_t) - f_t(p^*)] \leq
    \sum_{t=1}^T \eta_t \cdot \E[ \widetilde{g}_t^2 | \cF_{t-1}]  + 2 \sum_{t=1}^{t^*} \left(\frac{1}{\eta_t \cdot h(t)} + \E[ |\widetilde{g}_t| | \cF_{t-1}] \right).
    \]
    So it suffices to bound the first and second absolute raw moment of $\widetilde{g}_t$ in terms of the overlap function $h$ in order to obtain concrete regret bounds. From the facts established above, we have at any time horizon $T$ of the multigroup algorithm: $\E \left[\widetilde{g}_{t, G}^2 \, \Big|  \, \{Z_{\tau}\}_1^{t-1} \right] \leq 2C^4 h(t)^4 h(T)$, and $\E \left[|\widetilde{g}_{t, G}| \, \Big|  \, \{Z_{\tau}\}_1^{t-1} \right] \leq 2 C^2 h(t) h(T)$. Plugging this in and recalling the learning rate setting $\eta_t = \frac{1}{2 c^2 t}$, we obtain:
    \begin{align*}
        &\E[\RegVar_T(\cA_\mathrm{ATE})] \leq \frac{(C h(T))^5}{2c^2} (\log (T+1) + 1)  + 2 t^* \cdot C^2 h(t^*) h(T) + 4c^2 \sum_{t=1}^{t^*} \frac{t}{h(t)} \\
        &\leq \frac{(C h(T))^5}{2c^2} (\log (T+1) + 1) + 2 C^2 \left(1 + \frac{C}{c} \right) \hinv\left(1+\frac{C}{c}\right) \cdot h(T) + 2c^2 \left(\hinv\left(1+\frac{C}{c}\right) + 1\right)^2 \\
        &= O \left( (h(T))^5 \log T \right).
    \end{align*}
    Thus, asymptotically in $T$ this modification of \ClipOGDSC obtains the same rate. The only difference is non-asymptotic; we now acquire an additional term that depends on $T$ in a low-order way: $2C^2 (1+C/c) \, \hinv(1+C/c) \cdot h(T)$, which formerly had an additional factor of $(1+C/c)$ instead of $h(T)$. Even though this term is lower-order in $T$, but nonetheless it merits a mention, as here $h(T)$ coexists with the inverse clipping rate mapping, $\hinv$, being evaluated at a ``critical point'' $1+C/c$. Since the inverse mapping $\hinv$ will grow fast when $h$ grows slowly, this term can practically speaking become influential in the regret bound if the problem is not well-conditioned (if $C/c$ is very large). Thus, in practice this term may merit a tradeoff in choosing $h$ to not be too slowly-growing.

    To conclude the proof, note by collecting the above two bounds that:
    \begin{align*}
        \E \left[\RegVarMG_T(\cA; \cG) \right] &\leq \E \left[\RegSE_T(\cA_\mathrm{SE}) \right] + \E \left[\RegVar_T(\cA_\mathrm{ATE}) \right] \\
        &\leq 15 C^2 \sqrt{|\cG|} \cdot (h(T))^2 T^{1/2} + O \left( (h(T))^5 \log T \right) \\
        &\leq O \left( \sqrt{|\cG|} \cdot (h(T))^5 \cdot \sqrt{T} \right)
    \end{align*}



\section{Additional Experimental Results} \label{app:datasets}

In this section, we present experiments on additional real-world dataset. We list them below along with their descriptions.
We then turn to the description of the results.

\subsection{Task and Dataset Descriptions}

\paragraph{Large Language Model Benchmarking}
We test our methods on (a subset of) large language model (LLM) benchmarking data that was examined by \citet{fogliato2024precise}, and includes BigBench \citep{srivastava2022beyond}, MedMCQA \citep{pal2022medmcqa}, XCOPA \citep{ponti2020xcopa}, HellaSwag \citep{zellers2019hellaswag}, MMLU \citep{hoffmann2022training}, and XNLI \citep{conneau2018xnli}. Multiple LLMs are compared on these datasets, with each model producing a vector of logits for each data point. These logits are turned into probability vectors. Since each task is supervised, we know the correct answers. We select two models—Mistral-7B-Instruct-v0.2 \citep{jiang2023mistral} (treatment) and Google Gemma-2b \citep{team2024gemma} (control)—and build two parallel outcome sequences using the model accuracies. More specifically, for each data point, the model's chosen answer is the class with the highest predicted probability, and we define accuracy as 1 if this chosen class matches the correct answer and 0 otherwise.


\paragraph{ASOS Digital Dataset} 
We use the sequential experiments dataset from \citet{liu2021datasets}, gathered by ASOS.com between 2019 and 2020. It has 24{,}153 rows from 78 online controlled experiments. Each row represents a group of users who arrived during a certain time span and shows the average treatment and control outcomes for those users. Across all experiments, there are 99 different treatments and one control. The dataset tracks 4 consistent metrics; each row focuses on one of these metrics. This structure naturally creates 4 subsets of rows (each with about 6{,}000 rows). We treat each subset as a separate dataset and feed each of these 4 pairs of treatment and control outcome sequences into \ClipOGDSC and ClipOGD$^0$. This setup keeps outcome definitions consistent within each subset, while mixing different experiments and thus providing a varied environment for evaluating sequential ATE estimation methods.


\subsection{Experimental Results}

\subsubsection{LLM Benchmarking}

\Cref{fig:llbench} shows the experimental results across these six tasks (BigBench–MC, HellaSwag, MedMCQA, MMLU, XCOPA, XNLI). The top row shows that the treatment probabilities of ClipOGD\textsuperscript{0} (orange) fluctuate more, while the treatment probabilities of ClipOGD\textsuperscript{SC} (blue) settle closer to a stable value. Although our algorithm's assigned probabilities may initially jump around more because of the more aggressive clipping rate, they also stabilize more quickly. The second row shows the variances and tells a similar story: the variance ClipOGD\textsuperscript{SC} is smaller and decreases faster compared to that of ClipOGD\textsuperscript{0}. As seen in the bottom row, the Neyman regret of ClipOGD\textsuperscript{0} stays away from zero, whereas the regret of ClipOGD\textsuperscript{SC} shrinks toward zero or remains lower throughout. This pattern suggests that ClipOGD\textsuperscript{SC} converges to the Neyman-optimal probabilities with less fluctuation and lower regret than ClipOGD\textsuperscript{0}.


\begin{figure*}[ht]
    \includegraphics[width=0.99\textwidth]{plots/llmbench.pdf}
    \caption{
         \textbf{Treatment probabilities, variance of the ATE, and Neyman regret of ClipOGD on LLM benchmarking data}. The solid black line in the treatment probabilities indicates the Neyman optimal probability.
         }
        \label{fig:llbench}
        \vspace{-1em}
\end{figure*}


Additionally, we show the per-group Neyman regret of MGATE and ClipOGD in the contextual experiments. 
\begin{figure*}[ht]
    \includegraphics[width=0.99\textwidth]{plots/llmbench_multigroup_regret.pdf}
    \caption{
         \textbf{Group-conditional Neyman regret of ClipOGD and MGATE on the LLM Benchmarking data}. 
         }
        \label{fig:llbench_multigroup}
        \vspace{-1em}
\end{figure*}

\clearpage

\subsubsection{ASOS Digital Dataset}

\Cref{fig:asos} shows the Neyman regret on this dataset.  Across all four metrics, ClipOGD\textsuperscript{SC} (blue) steadily reduces Neyman regret, whereas ClipOGD\textsuperscript{0} (orange) remains higher or grows over time. Although the regret levels vary by metric,  
ClipOGD\textsuperscript{SC} consistently converges closer to the Neyman-optimal probabilities as shown by the shrinking regret.

\begin{figure*}[ht]
    \includegraphics[width=0.99\textwidth]{plots/asos.pdf}
    \caption{
         \textbf{Neyman regret of ClipOGD on the ASOS Digital Dataset}. 
         }
        \label{fig:asos}
        \vspace{-1em}
\end{figure*}

Additionally, we show the per-group Neyman regret of MGATE and ClipOGD in the contextual experiments. Here we observe that MGATE and ClipOGD$^\textrm{SC}$ attain close to optimal Neyman regret guarantees on all groups.
\begin{figure*}[ht]
    \includegraphics[width=0.99\textwidth]{plots/asos_multigroup_regret.pdf}
    \caption{
         \textbf{Group-conditional Neyman regret of ClipOGD and AMGATE on the ASOS Digital Dataset}. 
         }
        \label{fig:asos_multigroup}
        \vspace{-1em}
\end{figure*}