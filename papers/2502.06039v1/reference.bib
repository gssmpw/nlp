@misc{anonymous_2024_13922020,
  author       = {Anonymous},
  title        = {Secure Prompt Benchmark},
  month        = oct,
  year         = 2024,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.13922020},
  url          = {https://doi.org/10.5281/zenodo.13922020}
}

@misc{anonymous_2024_13923340,
  author       = {Anonymous},
  title        = {Security-Aware ChatGPT},
  month        = oct,
  year         = 2024,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.13923340},
  url          = {https://doi.org/10.5281/zenodo.13923340}
}

@misc{sahoo2024systematicsurveypromptengineering,
      title={A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications}, 
      author={Pranab Sahoo and Ayush Kumar Singh and Sriparna Saha and Vinija Jain and Samrat Mondal and Aman Chadha},
      year={2024},
      eprint={2402.07927},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2402.07927}, 
}

@inproceedings{Perry_2023, series={CCS ’23},
   title={Do Users Write More Insecure Code with AI Assistants?},
   url={http://dx.doi.org/10.1145/3576915.3623157},
   DOI={10.1145/3576915.3623157},
   booktitle={Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
   publisher={ACM},
   author={Perry, Neil and Srivastava, Megha and Kumar, Deepak and Boneh, Dan},
   year={2023},
   month=nov, collection={CCS ’23}
}

@article{Fu2023SecurityWO,
  title={Security Weaknesses of Copilot Generated Code in GitHub},
  author={Yujia Fu and Peng Liang and Amjed Tahir and Zengyang Li and Mojtaba Shahin and Jiaxin Yu},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.02059},
  url={https://api.semanticscholar.org/CorpusID:263609212}
}

@misc{firouzi2024timeseparatestackoverflowmatch,
      title={Time to Separate from StackOverflow and Match with ChatGPT for Encryption}, 
      author={Ehsan Firouzi and Mohammad Ghafari},
      year={2024},
      eprint={2406.06164},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2406.06164}, 
}

@online{noauthor_weggli-rsweggli_2024,
	title = {weggli-rs/weggli},
	rights = {Apache-2.0},
	url = {https://github.com/weggli-rs/weggli},
	abstract = {weggli is a fast and robust semantic search tool for C and C++ codebases. It is designed to help security researchers identify interesting functionality in large codebases.},
	publisher = {weggli-rs},
	urldate = {2024-10-12},
	date = {2024-10-09},
	note = {original-date: 2021-09-30T16:06:12Z},
}

@article{Tony2023LLMSecEvalAD,
  title={LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations},
  author={Catherine Tony and Markus Mutas and Nicol'as E. D'iaz Ferreyra and Riccardo Scandariato},
  journal={2023 IEEE/ACM 20th International Conference (MSR)},
  year={2023},
  pages={588-592},
  url={https://api.semanticscholar.org/CorpusID:257557620}
}

@software{LLMSecEvalGit,
author = {Tony, Catherine and Mutas, Markus and Díaz Ferreyra, Nicolas and Scandariato, Riccardo},
doi = {10.5281/zenodo.7565965},
month = jan,
title = {{LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations}},
url = {https://github.com/tuhh-softsec/LLMSecEval},
version = {1.0},
year = {2023}
}

@misc{sun2022blackboxtuninglanguagemodelasaservice,
      title={Black-Box Tuning for Language-Model-as-a-Service}, 
      author={Tianxiang Sun and Yunfan Shao and Hong Qian and Xuanjing Huang and Xipeng Qiu},
      year={2022},
      eprint={2201.03514},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.03514}, 
}

@article{Bhatt2023PurpleLC,
  title={Purple Llama CyberSecEval: A Secure Coding Benchmark for Language Models},
  author={Manish Bhatt and Sahana Chennabasappa and Cyrus Nikolaidis and Shengye Wan and Ivan Evtimov and Dominik Gabi and Daniel Song and Faizan Ahmad and Cornelius Aschermann and Lorenzo Fontana and Sasha Frolov and Ravi Prakash Giri and Dhaval Kapil and Yiannis Kozyrakis and David LeBlanc and James Milazzo and Aleksandar Straumann and Gabriel Synnaeve and Varun Vontimitta and Spencer Whitman and Joshua Saxe},
  journal={ArXiv},
  year={2023},
  volume={abs/2312.04724},
  url={https://api.semanticscholar.org/CorpusID:266149921}
}

@INPROCEEDINGS{pearce2022asleep,
  author={Pearce, Hammond and Ahmad, Baleegh and Tan, Benjamin and Dolan-Gavitt, Brendan and Karri, Ramesh},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)}, 
  title={Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions}, 
  year={2022},
  volume={},
  number={},
  pages={754-768},
  keywords={Privacy;Codes;Computational modeling;Keyboards;Computer crime;Open source software;Software development management;Cybersecurity;Artificial Intelligence (AI);code generation;Common Weakness Enumerations (CWEs)},
  doi={10.1109/SP46214.2022.9833571}
}

@article{Kavian2024LLMSG,
  title={LLM Security Guard for Code},
  author={Arya Kavian and Mohammad Mehdi Pourhashem Kallehbasti and Sajjad Kazemi and Ehsan Firouzi and Mohammad Ghafari},
  journal={Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:269502004}
}

@inproceedings{SecurityEval,
    author = {Siddiq, Mohammed Latif and Santos, Joanna C. S.},
    title = {SecurityEval dataset: mining vulnerability examples to evaluate machine learning-based code generation techniques},
    year = {2022},
    isbn = {9781450394574},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3549035.3561184},
    doi = {10.1145/3549035.3561184},
    abstract = {Automated source code generation is currently a popular machine-learning-based task. It can be helpful for software developers to write functionally correct code from a given context. However, just like human developers, a code generation model can produce vulnerable code, which the developers can mistakenly use. For this reason, evaluating the security of a code generation model is a must. In this paper, we describe SecurityEval, an evaluation dataset to fulfill this purpose. It contains 130 samples for 75 vulnerability types, which are mapped to the Common Weakness Enumeration (CWE). We also demonstrate using our dataset to evaluate one open-source (i.e., InCoder) and one closed-source code generation model (i.e., GitHub Copilot).},
    booktitle = {Proceedings of the 1st International Workshop on Mining Software Repositories Applications for Privacy and Security},
    pages = {29–33},
    numpages = {5},
    keywords = {code generation, common weakness enumeration, dataset, security},
    location = {Singapore, Singapore},
    series = {MSR4P{\&}S 2022}
}

@misc{securityevalinitialcommit,
  author       = {S2E Lab},
  title        = {SecurityEval - A repository for evaluating the security of code generation models},
  year         = {2022},
  howpublished = {\url{https://github.com/s2e-lab/SecurityEval/commit/c6a272b9f66203bbe4fce5fe3cd42a34d027d933}},
  note         = {Commit c6a272b, committed on July 4, 2022},
}


@misc{ztjhzBet72:online,
author = {Jing Hua},
title = {BetterChatGPT},
howpublished = {\url{https://github.com/ztjhz/BetterChatGPT}},
month = {},
year = {},
note = {(Accessed on 10/11/2024)}
}

@misc{noauthor_github_2024,
    key = {Github Inc.},
	title = {{GitHub} {Copilot} {Chat} and pull request summaries are now powered by {GPT}-4o · {GitHub} {Changelog}},
	url = {https://github.blog/changelog/2024-07-31-github-copilot-chat-and-pull-request-summaries-are-now-powered-by-gpt-4o/},
	abstract = {GitHub Copilot Chat and pull request summaries are now powered by GPT-4o},
	language = {en-US},
	urldate = {2024-10-11},
	journal = {The GitHub Blog},
	month = jul,
	year = {2024},
}

@misc{MetaCodeShield,
  author       = {Meta},
  title        = {PurpleLlama CodeShield},
  year         = {2023},
  howpublished = {\url{https://github.com/meta-llama/PurpleLlama/tree/main/CodeShield}},
  note         = "[Online; accessed 11-Oct-2024]"
}

@online{mitre_cwe,
	title = {{CWE} - Common Weakness Enumeration},
	url = {https://cwe.mitre.org/},
	urldate = {2024-10-12},
}

@article{Chen2021EvaluatingLL,
  title={Evaluating Large Language Models Trained on Code},
  author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde and Jared Kaplan and Harrison Edwards and Yura Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and David W. Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William H. Guss and Alex Nichol and Igor Babuschkin and Suchir Balaji and Shantanu Jain and Andrew Carr and Jan Leike and Joshua Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew M. Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.03374},
  url={https://api.semanticscholar.org/CorpusID:235755472}
}

@article{Khoury2023HowSI,
  title={How Secure is Code Generated by ChatGPT?},
  author={Rapha{\"e}l Khoury and Anderson R. Avila and Jacob Brunelle and Baba Mamadou Camara},
  journal={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  year={2023},
  pages={2445-2451},
  url={https://api.semanticscholar.org/CorpusID:258212971}
}

@misc{tony2024promptingtechniquessecurecode,
  title={Prompting Techniques for Secure Code Generation: A Systematic Investigation}, 
  author={Catherine Tony and Nicolás E. Díaz Ferreyra and Markus Mutas and Salem Dhiff and Riccardo Scandariato},
  year={2024},
  eprint={2407.07064},
  archivePrefix={arXiv},
  primaryClass={cs.SE},
  url={https://arxiv.org/abs/2407.07064}, 
}

@online{Semgrep,
  title        = {semgrep/semgrep: Lightweight static analysis for many languages. Find bug variants with patterns that look like source code.},
  organization       = {Semgrep, Inc.},
  year         = 2024,
  url          = {https://github.com/semgrep/semgrep},
  urldate      = {2024-07-21}
}

@online{CodeQL,
  title        = {About CodeQL},
  author       = {GitHub, Inc.},
  year         = 2024,
  url          = {https://codeql.github.com/docs/codeql-overview/about-codeql/},
  urldate      = {2024-07-25}
}

@misc{openai_docs_models,
  title = {OpenAI Platform Documentation - Models},
  author = {OpenAI},
  year = {2024},
  howpublished = {\url{https://platform.openai.com/docs/models}},
  note = {Accessed: 2024-12-04}
}

@inproceedings{Firouzi2024b,
author = {Firouzi, Ehsan and Ghafari, Mohammad and Ebrahimi, Mike},
title = {ChatGPT’s Potential in Cryptography Misuse Detection: A Comparative Analysis with Static Analysis Tools},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3695408},
doi = {10.1145/3674805.3695408},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {582–588},
numpages = {7},
keywords = {ChatGPT, Java cryptography, security, static program analysis},
location = {Barcelona, Spain},
series = {ESEM '24}
}