@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}


% RepE
@article{zou2023representation,
  title={Representation engineering: A top-down approach to ai transparency},
  author={Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others},
  journal={arXiv preprint arXiv:2310.01405},
  year={2023}
}

% ctrla
@article{liu2024ctrla,
  title={CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control},
  author={Liu, Huanshuo and Zhang, Hao and Guo, Zhijiang and Dong, Kuicai and Li, Xiangyang and Lee, Yi Quan and Zhang, Cong and Liu, Yong},
  journal={arXiv preprint arXiv:2405.18727},
  year={2024}
}


@inproceedings{he2021efficient,
  title={Efficient Nearest Neighbor Language Models},
  author={He, Junxian and Neubig, Graham and Berg-Kirkpatrick, Taylor},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={5703--5714},
  year={2021}
}

@inproceedings{drozdov2022you,
  title={You canâ€™t pick your neighbors, or can you? When and How to Rely on Retrieval in the kNN-LM},
  author={Drozdov, Andrew and Wang, Shufan and Rahimi, Razieh and Mccallum, Andrew and Zamani, Hamed and Iyyer, Mohit},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={2997--3007},
  year={2022}
}

@article{liu2023bolaa,
  title={Bolaa: Benchmarking and orchestrating llm-augmented autonomous agents},
  author={Liu, Zhiwei and Yao, Weiran and Zhang, Jianguo and Xue, Le and Heinecke, Shelby and Murthy, Rithesh and Feng, Yihao and Chen, Zeyuan and Niebles, Juan Carlos and Arpit, Devansh and others},
  journal={arXiv preprint arXiv:2308.05960},
  year={2023}
}

@inproceedings{chen2023agentverse,
  title={Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors},
  author={Chen, Weize and Su, Yusheng and Zuo, Jingwei and Yang, Cheng and Yuan, Chenfei and Chan, Chi-Min and Yu, Heyang and Lu, Yaxi and Hung, Yi-Hsin and Qian, Chen and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{liu2024toolace,
  title={ToolACE: Winning the Points of LLM Function Calling},
  author={Liu, Weiwen and Huang, Xu and Zeng, Xingshan and Hao, Xinlong and Yu, Shuai and Li, Dexun and Wang, Shuai and Gan, Weinan and Liu, Zhengying and Yu, Yuanqing and others},
  journal={arXiv preprint arXiv:2409.00920},
  year={2024}
}

@inproceedings{liuapigen,
  title={APIGen: Automated PIpeline for Generating Verifiable and Diverse Function-Calling Datasets},
  author={Liu, Zuxin and Hoang, Thai Quoc and Zhang, Jianguo and Zhu, Ming and Lan, Tian and Kokane, Shirley and Tan, Juntao and Yao, Weiran and Liu, Zhiwei and Feng, Yihao and others},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024}
}
    
@misc{berkeley-function-calling-leaderboard,
    title={Berkeley Function Calling Leaderboard}, 
    author={Fanjia Yan and Huanzhi Mao and Charlie Cheng-Jie Ji
    and Tianjun Zhang and Shishir G. Patil and Ion Stoica and Joseph E.
    Gonzalez},
    howpublished={\url{https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html}},
    year={2024}
}

@inproceedings{li2023comprehensive,
  title={A comprehensive benchmark for tool-augmented LLMs},
  author={Li, Minghao and Zhao, Yingxiu and Yu, Bowen and Song, Feifan and Li, Hangyu and Yu, Haiyang and Li, Zhoujun and Huang, Fei and API-bank, Yongbin Li},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={3102--3116},
  year={2023}
}

@article{guo2024stabletoolbench,
  title={StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models},
  author={Guo, Zhicheng and Cheng, Sijie and Wang, Hao and Liang, Shihao and Qin, Yujia and Li, Peng and Liu, Zhiyuan and Sun, Maosong and Liu, Yang},
  journal={arXiv preprint arXiv:2403.07714},
  year={2024}
}

@article{ren2023investigating,
  title={Investigating the factual knowledge boundary of large language models with retrieval augmentation},
  author={Ren, Ruiyang and Wang, Yuhao and Qu, Yingqi and Zhao, Wayne Xin and Liu, Jing and Tian, Hao and Wu, Hua and Wen, Ji-Rong and Wang, Haifeng},
  journal={arXiv preprint arXiv:2307.11019},
  year={2023}
}

@article{vu2023freshllms,
  title={Freshllms: Refreshing large language models with search engine augmentation},
  author={Vu, Tu and Iyyer, Mohit and Wang, Xuezhi and Constant, Noah and Wei, Jerry and Wei, Jason and Tar, Chris and Sung, Yun-Hsuan and Zhou, Denny and Le, Quoc and others},
  journal={arXiv preprint arXiv:2310.03214},
  year={2023}
}

@article{izacard2023atlas,
  title={Atlas: Few-shot learning with retrieval augmented language models},
  author={Izacard, Gautier and Lewis, Patrick and Lomeli, Maria and Hosseini, Lucas and Petroni, Fabio and Schick, Timo and Dwivedi-Yu, Jane and Joulin, Armand and Riedel, Sebastian and Grave, Edouard},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={251},
  pages={1--43},
  year={2023}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{JiSurvey,
author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
title = {Survey of Hallucination in Natural Language Generation},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3571730},
doi = {10.1145/3571730},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {248},
numpages = {38},
}

@article{asai2023self,
  title={Self-rag: Learning to retrieve, generate, and critique through self-reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.11511},
  year={2023}
}

@article{jiang2023active,
  title={Active retrieval augmented generation},
  author={Jiang, Zhengbao and Xu, Frank F and Gao, Luyu and Sun, Zhiqing and Liu, Qian and Dwivedi-Yu, Jane and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  journal={arXiv preprint arXiv:2305.06983},
  year={2023}
}

@article{ding2024retrieve,
  title={Retrieve only when it needs: Adaptive retrieval augmentation for hallucination mitigation in large language models},
  author={Ding, Hanxing and Pang, Liang and Wei, Zihao and Shen, Huawei and Cheng, Xueqi},
  journal={arXiv preprint arXiv:2402.10612},
  year={2024}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@inproceedings{jawahar,
  TITLE = {{What does BERT learn about the structure of language?}},
  AUTHOR = {Jawahar, Ganesh and Sagot, Beno{\^i}t and Seddah, Djam{\'e}},
  URL = {https://inria.hal.science/hal-02131630},
  BOOKTITLE = {{ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics}},
  ADDRESS = {Florence, Italy},
  YEAR = {2019},
  MONTH = Jul,
  PDF = {https://inria.hal.science/hal-02131630v1/file/intbert_acl19paper-3.pdf},
  HAL_ID = {hal-02131630},
  HAL_VERSION = {v1},
}

@article{peters2018dissecting,
  title={Dissecting contextual word embeddings: Architecture and representation},
  author={Peters, Matthew E and Neumann, Mark and Zettlemoyer, Luke and Yih, Wen-tau},
  journal={arXiv preprint arXiv:1808.08949},
  year={2018}
}

@article{li2022probing,
  title={Probing via prompting},
  author={Li, Jiaoda and Cotterell, Ryan and Sachan, Mrinmaya},
  journal={arXiv preprint arXiv:2207.01736},
  year={2022}
}

@article{zhao2024explainability,
  title={Explainability for large language models: A survey},
  author={Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={2},
  pages={1--38},
  year={2024},
  publisher={ACM New York, NY}
}

@article{antverg2021pitfalls,
  title={On the pitfalls of analyzing individual neurons in language models},
  author={Antverg, Omer and Belinkov, Yonatan},
  journal={arXiv preprint arXiv:2110.07483},
  year={2021}
}

@article{bills2023language,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  journal={URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)},
  volume={2},
  year={2023}
}


% existing tool use papers
% maths
@article{he2023solving,
  title={Solving math word problems by combining language models with symbolic solvers},
  author={He-Yueya, Joy and Poesia, Gabriel and Wang, Rose E and Goodman, Noah D},
  journal={arXiv preprint arXiv:2304.09102},
  year={2023}
}

% search engine 
@article{komeili2021internet,
  title={Internet-augmented dialogue generation},
  author={Komeili, M},
  journal={arXiv preprint arXiv:2107.07566},
  year={2021}
}

% weather and map
@article{tang2023toolalpaca,
  title={Toolalpaca: Generalized tool learning for language models with 3000 simulated cases},
  author={Tang, Qiaoyu and Deng, Ziliang and Lin, Hongyu and Han, Xianpei and Liang, Qiao and Cao, Boxi and Sun, Le},
  journal={arXiv preprint arXiv:2306.05301},
  year={2023}
}

@article{yang2023foundation,
  title={Foundation models for decision making: Problems, methods, and opportunities},
  author={Yang, Sherry and Nachum, Ofir and Du, Yilun and Wei, Jason and Abbeel, Pieter and Schuurmans, Dale},
  journal={arXiv preprint arXiv:2303.04129},
  year={2023}
}

@inproceedings{gao2023pal,
  title={Pal: Program-aided language models},
  author={Gao, Luyu and Madaan, Aman and Zhou, Shuyan and Alon, Uri and Liu, Pengfei and Yang, Yiming and Callan, Jamie and Neubig, Graham},
  booktitle={International Conference on Machine Learning},
  pages={10764--10799},
  year={2023},
  organization={PMLR}
}

@article{lu2024chameleon,
  title={Chameleon: Plug-and-play compositional reasoning with large language models},
  author={Lu, Pan and Peng, Baolin and Cheng, Hao and Galley, Michel and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Gao, Jianfeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{schick2024toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

% enhance the number of tools
@article{qin2023toolllm,
  title={Toolllm: Facilitating large language models to master 16000+ real-world apis},
  author={Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and others},
  journal={arXiv preprint arXiv:2307.16789},
  year={2023}
}
@article{hao2024toolkengpt,
  title={Toolkengpt: Augmenting frozen language models with massive tools via tool embeddings},
  author={Hao, Shibo and Liu, Tianyang and Wang, Zhen and Hu, Zhiting},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

% how to use the tool more effectively
@article{patil2023gorilla,
  title={Gorilla: Large language model connected with massive apis},
  author={Patil, Shishir G and Zhang, Tianjun and Wang, Xin and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2305.15334},
  year={2023}
}

@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@article{shen2024hugginggpt,
  title={Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

% survey on tool use
@article{qu2024tool,
  title={Tool Learning with Large Language Models: A Survey},
  author={Qu, Changle and Dai, Sunhao and Wei, Xiaochi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Xu, Jun and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2405.17935},
  year={2024}
}

@article{wang2024survey,
  title={A survey on large language model based autonomous agents},
  author={Wang, Lei and Ma, Chen and Feng, Xueyang and Zhang, Zeyu and Yang, Hao and Zhang, Jingsen and Chen, Zhiyuan and Tang, Jiakai and Chen, Xu and Lin, Yankai and others},
  journal={Frontiers of Computer Science},
  volume={18},
  number={6},
  pages={186345},
  year={2024},
  publisher={Springer}
}

@inproceedings{wurepoformer,
  title={Repoformer: Selective Retrieval for Repository-Level Code Completion},
  author={Wu, Di and Ahmad, Wasi Uddin and Zhang, Dejiao and Ramanathan, Murali Krishna and Ma, Xiaofei},
  booktitle={Forty-first International Conference on Machine Learning},
year={2024}
}

@article{huang2023metatool,
  title   = {MetaTool Benchmark: Deciding Whether to Use Tools and Which to Use},
  author  = {Yue Huang and Jiawen Shi and Yuan Li and Chenrui Fan and Siyuan Wu and Qihui Zhang and Yixin Liu and Pan Zhou and Yao Wan and Neil Zhenqiang Gong and Lichao Sun},
  year    = {2023},
  journal = {arXiv preprint arXiv: 2310.03128}
}

@misc{openai_chatgpt_plugins,
    author       = {OpenAI},
    title        = {ChatGPT Plugins},
    year         = {2023},
    url          = {https://openai.com/index/chatgpt-plugins/},
    note         = {Accessed: 2023-3-23}
}

@article{liu2023aligning,
  title={Aligning large language models with human preferences through representation engineering},
  author={Liu, Wenhao and Wang, Xiaohua and Wu, Muling and Li, Tianlong and Lv, Changze and Ling, Zixuan and Zhu, Jianhao and Zhang, Cenyuan and Zheng, Xiaoqing and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2312.15997},
  year={2023}
}

@article{Levinstein_2024,
   title={Still no lie detector for language models: probing empirical and conceptual roadblocks},
   ISSN={1573-0883},
   url={http://dx.doi.org/10.1007/s11098-023-02094-3},
   DOI={10.1007/s11098-023-02094-3},
   journal={Philosophical Studies},
   publisher={Springer Science and Business Media LLC},
   author={Levinstein, Benjamin A. and Herrmann, Daniel A.},
   year={2024},
   month=feb }

@article{bricken2023monosemanticity,
title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and Lasenby, Robert and Wu, Yifan and Kravec, Shauna and Schiefer, Nicholas and Maxwell, Tim and Joseph, Nicholas and Hatfield-Dodds, Zac and Tamkin, Alex and Nguyen, Karina and McLean, Brayden and Burke, Josiah E and Hume, Tristan and Carter, Shan and Henighan, Tom and Olah, Christopher},
year={2023},
journal={Transformer Circuits Thread},
url={https://transformer-circuits.pub/2023/monosemantic-features/index.html}
}

% pca
@article{mackiewicz1993principal,
  title={Principal components analysis (PCA)},
  author={Ma{\'c}kiewicz, Andrzej and Ratajczak, Waldemar},
  journal={Computers \& Geosciences},
  volume={19},
  number={3},
  pages={303--342},
  year={1993},
  publisher={Elsevier}
}

% cot
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

% cot, reasoning inconsistency
@inproceedings{lyu2023faithful,
  title={Faithful Chain-of-Thought Reasoning},
  author={Lyu, Qing and Havaldar, Shreya and Stein, Adam and Zhang, Li and Rao, Delip and Wong, Eric and Apidianaki, Marianna and Callison-Burch, Chris},
  booktitle={Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={305--329},
  year={2023}
}






