\section{Related Work}
\label{sec:related-work}

\subsection{Valuation of Explanation Strategies in AI-assisted Decision-making}
\label{sec:related-work-exp}

Evaluating post-hoc explanations in the form of text has gained much attention as it provides rationales on AI-based decisions and impacts users' perceived trust and understandability  ____. Such explanations incorporating a variety of strategies and logics vary by techniques ____ including feature importance or nearest neighbors or logics/strategies such as contrastive ____, counterfactual ____ explanations in social and cognitive science, and case-based explanations from expert system studies ____. 

However, recent XAI research has produced contradictory findings regarding the effect of explanation strategies. For example, providing such explanations in AI-assisted decision were found to help justify the decision and increase users' trust when compared with no explanation provided in some contexts such as medical chatbot ____ or self-driving context ____. On the other hand, they tend to be distracting or lead to either overreliance ____ or cognitive overload ____ for lay users without a careful design of how explanations are presented ____. 
The impact of different explanation strategies in AI-assisted decision-making is also diverging. For example, complete explanations with a greater information complexity, for example, were proved to gain trust better in medical diagnosis ____ while they led to over-reliance on AI in medical diagnosis in ____. Contrastive explanations known as intuitive and human-friendly were helpful in improving decision quality with semantic evidence in emotion recognition task ____, while it was found to fail to calibrate the trust of AI in human perception in ____.

A recent XAI study ____ has advanced the discussion on making explanations more selective. The proposed framework draws on literature exploring how humans produce explanations selectively, focusing on aspects such as abnormality ____, relevance ____, and changeability ____. Empirical results from this study suggest that allowing users to contribute to the generation of explanations reduces over-reliance on automated systems.

In this study, we pursue a deeper and comprehensive understanding of users' valuation on explanations strategies. By conducting a survey-based experiment, we find that the valuation process is a complex interplay of individual and contextual factors, highlighting the importance of personalizing the degree of explainability carefully based on individual traits and cognitive abilities.


\subsection{Individual and Cognitive Dimension of Explanatory Process}
\label{sec:related-work-cognition}

When making sense of a social situation such as interpersonal communication or decision-making processes, individuals go through certain cognitive processes to analyze, interpret, and remember information ____. Previous studies found that these process are influenced by individualsâ€™ own cognitive tendency or given contexts. For example, people tend to have their own decision-making style ____ -- whether they rely on hunches or a thorough search for information. According to the Motivation-Opportunity-Ability (MOA) model ____, individuals are either empowered or hindered in exhibiting behavioral changes or attributing decisions when making sense of their success and failure in their careers or education ____. These cognitive processes can further influence the degree to which individuals seek more information to reason about situations, manifest in either spontaneous or deliberate modes within the dual processing theory ____.

A number of studies ____ have found that all these cognitive traits are highly dependent on their demographics. For example, older adults rely more on emotions and experience rather than being rational due to aging cognitive ability ____. The level of education also influences the cognitive load, intelligence, thinking, and working memory ____.  Rational thinkers tend to actively seek explanations when finding the best recommendations than intuitive thinkers. 

Despite these findings, there is limited understanding of the complex cognitive dimensions that affect individuals' willingness to seek explanations and their valuation of specific explanation strategies in AI-assisted decision-making. Our study explores these connections, highlighting the need for careful designed explanations that consider these cognitive processes. 


\subsection{Evaluating Explanations in Various AI-assisted Decision Contexts}
\label{sec:related-work-context}

The effectiveness of various explanation types in enhancing trust and understanding has been studied across diverse AI-assisted decision contexts, including human-robot interaction ____, self-driving technologies ____, and medical diagnosis ____.

For instance, in medical context, providing explanations helped improve health awareness, facilitate learning, and aid decision-making by offering patients new information about their symptoms ____ or help laypeople understand complex medical concepts during cancer diagnosis ____. In self-driving contexts, explanations provided in a timely manner during sequential driving scenes have been found to improve understanding ____.

Despite all these studies highlighting the impact of various explanation styles within a certain context, it remains uncertain how different explanation types affect the levels of trust, understandability, and other aspects of user perceived values across multiple contexts. While previous studies ____ have conceptually examined that AI transparency is entangled with sociotechnical contexts, our research empirically demonstrates that the effectiveness of explanations varies based on the application context, highlighting the need for context-aware design in explainable AI systems.