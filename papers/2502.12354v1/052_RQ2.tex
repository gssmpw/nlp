\subsection{Which aspects and properties of explanations are linked to the distinct valuation of those explanation strategies?}
Based on the analysis of open-ended responses, we examine participants' detailed rationale on what aspects and properties of explanations made them prefer certain explanations over the others. We find evidence on all facets of explanation strategies listed in Table \ref{tab:comp_strategies} including contrastive strategies (how and what/who to compare) and information selectivity (information complexity and alignment) as well as general expectations over AI systems' explainability as follows. 

\subsubsection{Participants appreciate different types of explanatory properties, mostly pertaining to information complexity.}
\label{sec:exp-properties}
First, most of the participants (524/698, 75.1\%) tended to evaluate explanation strategies based on a variety of explanatory properties to further elaborate on their preferences in the quantitative results. The five most frequent properties across all explanation styles were easy (126 times), clear (66), relevant (38), specific (36), and detailed (34). 

\begin{figure}[H]%
% \vspace{-1em}
\centering
\includegraphics[width=.8\columnwidth]{figures/exp-properties.pdf}
% \vspace{-2.5em}
\caption{The most frequent explanatory properties in association with the explanation strategies.}
\label{fig:exp-properties}
\end{figure}

It was noticeable that the top explanatory properties in each explanation type were mostly pertaining to information complexity such as detailed, simple, or brief. The lists of top-10 most associated properties in favor of each explanation strategy (Fig. \ref{fig:exp-properties}) were extracted based on FREX score (FRequency and EXclusivity) \cite{bischof2012summarizingfrex}, which identifies words that are both frequent in and exclusive to a topic of interest, regarding each explanation style. Specifically, \comp was perceived as comprehensive and detailed as it described ``\textit{every aspect of why the decision was made}'' and the comprehensive information allowed them to``\textit{form a big picture in [their] mind.}.'' \cbho was appreciated for not only being thorough but also its comparative characteristic, ``\textit{being detailed and comparative would help to highlight the urgency of the situation.}'' On the other hand, contrastive explanations (including \cto and \ctt, and \cf) were commonly appreciated by virtue of their clear, brief, and short information representation as it gives them ``\textit{the most exact and particular reason what the key problem is to improve}''.

On the other hand, contrastive/counterfactual explanations were preferred due to both comparative strategies. For example, \cto and \cf were received more actionable because it helps ``\textit{take away something from and apply it to my life.}'' due to being descriptive of their status in contrast to  the ones with the opposite outcome. On the other hand, \ctt explanations contrasting with previous state of the user were regarded as more relevant as it ``\textit{relates to me more and compares less with others.}''


\subsubsection{Participants favor explanations they can readily accept based on their prior knowledge or beliefs.}
\label{sec:selective}
In the 135 responses (19.3\%), participants expressed preferences for explanation styles when the explanation mentioned one or more feature(s) they perceived as critical or unnecessary in the decision-making. 

These feature-oriented valuation, spanning 34 types of features for 205 times, varied across decision contexts but appeared mainly in less knowledge-intensive decision-making contexts. For instance, in the loan approval context, participants often confidently referred to employment (\loanN: 17) or annual income (\loanN: 17) as critical factors of loan approval based on their beliefs or prior experiences as commented, ``\textit{income matters.}'' or ``\textit{not being employed is the most critical problem. There is no other reason that matters.}''. In movie recommendations, the browsing history was often considered as a critical factor (\recomN: 30, \recomP: 23) because this feature ``\textit{made the most sense}'' and they feel ``\textit{this will give me the best choice for movies.}'' The movie genre (\recomN: 9, \recomP: 7) was also often perceived as an understandable and important feature to the given recommendations, ``\textit{the relation to the genre and my previous recommendations make it the best and easiest to understand.}'' On the other hand, the least frequent contexts were medical diagnosis (\mediN: 10, \mediP: 12) with mentions of some features such as blood pressure (\mediN: 2, \mediP: 3) or cholesterol (\mediN: 2, \mediP: 1). This suggests that, while some participants prefer explanations that seem more plausible to them, possibly due to their prior beliefs and knowledge, this preference may vary depending on the level of professional knowledge required for the decision context.


On the other hand, some features, especially those related to demographics, also provoked negative preferences over explanations. A number of participants (\recomN: 15, \recomP: 12, \loanN: 5) considered all demographic-related features (such as gender, marriage, or age) as not useful, necessary, or relevant to the AI's decision. Some of them raised their concerns about privacy or profiling issues of collecting and processing personal data. 

\input{tables/tab_comparative_strategies}

\subsubsection{Rather than simply contrastive, human-friendly explanations depend on whether, what, and how to compare.}
\label{sec:contrastive}
77 participants (11.0\%) showed diverse user preferences over different types of comparisons, based on factors like what or whom is being compared against their own status. In Table \ref{tab:comp_strategies}, explanations are presented based on their average ranking over a group of participants and highlighting liked (red) or disliked (blue) strategies. 

We found that some participants did not want any types of comparisons and preferred \comp over all others (+: \comp; -: all others). They preferred explanations to ``\textit{focus on themselves}'' rather than others because ``\textit{everyone has different personal context}'' but AI may not consider all contexts when making comparisons. Another group of participants did not like being compared to others but rather to their own previous or hypothetical state (+: \cf, \ctt; -: all others). On the other hand, others preferred certain comparative explanations. For example, a group of participants favored comparison with typical or similar others (+: \cbho, \cbhe; -: all others) or those with opposite outcome (+: \cto, \ctt; -: all others).

\subsubsection{Participants have different expectations over AI explainability.}
\label{sec:ai-system}

Participants' expectations about the role of explanations in AI systems varied significantly across the 25 responses (3.5\%). First, some expressed their views on the objectives of XAI systems. Ten participants, for instance, anticipated that AI systems would provide professional information or be used for complex tasks. Notably, eight participants preferred explanations that included more statistics and numbers, citing that such information ``{\it helps [in] visualizing the status.}'' Two participants mentioned that AI systems should present professional information that could provide more learning opportunities, as opposed to merely presenting well-known terms and factors such as BMI or blood pressure.

Second, four participants argued that AI systems should do less, suggesting that the use of XAI should be limited or restricted to human experts. They voiced concerns such as, ``{\it I [would] rather hear this from a human [than AI]; it is useful when used [alongside] doctors}'' and ``{\it AI is just for diagnosing; to tell me whether I should go to a doctor.}''