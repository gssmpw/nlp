
@article{Domainspecificpreferencesintuitiondeliberationdecision,
	title = {Domain-specific preferences for intuition and deliberation in decision making.},
	volume = {4},
	copyright = {http://www.apa.org/pubs/journals/resources/open-access.aspx},
	issn = {2211-369X, 2211-3681},
	url = {https://doi.apa.org/doi/10.1016/j.jarmac.2015.07.006},
	doi = {10.1016/j.jarmac.2015.07.006},
	abstract = {There is evidence for reliable individual differences in the tendency to use an intuitive (i.e., spontaneous, affect-based) and a deliberative (i.e., effortful, planned, and analytic) decision mode. Even though other individual characteristics in decision making (e.g., risk attitude) seem to be domain-speciﬁc, it is commonly assumed that a person’s decision style is relatively stable across decision domains. Using a domain-speciﬁc extension of the Uniﬁed Scale to Assess Individual Differences in Intuition and Deliberation (USID), we found that preference for intuition and preference for deliberation showed considerable variability across domains (e.g., choosing a dress vs. choosing a doctor). In addition, domain-speciﬁc preferences for intuition were consistently correlated with self-rated expertise in making decisions in the respective domain. Our results indicate that a person’s domain-general decision style does not necessarily generalize across decision domains, and that the domain-speciﬁcity of preferences for intuition seems to be driven partly by differences in expertise.},
	language = {en},
	number = {3},
	urldate = {2024-05-13},
	journal = {Journal of Applied Research in Memory and Cognition},
	author = {Pachur, Thorsten and Spaar, Melanie},
	month = sep,
	year = {2015},
	pages = {303--311},
}

@article{SocialCognition,
	title = {Social {Cognition}},
	language = {en},
	journal = {Routledge},
	author = {Pennington, Donald C},
	year = {2012},
}

@inproceedings{salinas_unequal_2023,
	address = {Boston MA USA},
	title = {The {Unequal} {Opportunities} of {Large} {Language} {Models}: {Examining} {Demographic} {Biases} in {Job} {Recommendations} by {ChatGPT} and {LLaMA}},
	isbn = {9798400703812},
	shorttitle = {The {Unequal} {Opportunities} of {Large} {Language} {Models}},
	url = {https://dl.acm.org/doi/10.1145/3617694.3623257},
	doi = {10.1145/3617694.3623257},
	abstract = {Warning: This paper discusses and contains content that is offensive or upsetting. Large Language Models (LLMs) have seen widespread deployment in various real-world applications. Understanding these biases is crucial to comprehend the potential downstream consequences when using LLMs to make decisions, particularly for historically disadvantaged groups. In this work, we propose a simple method for analyzing and comparing demographic bias in LLMs, through the lens of job recommendations. We demonstrate the effectiveness of our method by measuring intersectional biases within ChatGPT and LLaMA, two cutting-edge LLMs. Our experiments primarily focus on uncovering gender identity and nationality bias; however, our method can be extended to examine biases associated with any intersection of demographic identities. We identify distinct biases in both models toward various demographic identities, such as both models consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women. Our study highlights the importance of measuring the bias of LLMs in downstream applications to understand the potential for harm and inequitable outcomes. Our code is available at https://github. com/Abel2Code/Unequal-Opportunities-of-LLMs.},
	language = {en},
	urldate = {2024-04-22},
	booktitle = {Equity and {Access} in {Algorithms}, {Mechanisms}, and {Optimization}},
	publisher = {ACM},
	author = {Salinas, Abel and Shah, Parth and Huang, Yuzhong and McCormack, Robert and Morstatter, Fred},
	month = oct,
	year = {2023},
	pages = {1--15},
}

@article{veldanda_investigating_nodate,
	title = {Investigating {Hiring} {Bias} in {Large} {Language} {Models}},
	abstract = {Large Language Models (LLMs) such as GPT-3.5, Bard, and Claude exhibit applicability across numerous tasks. One domain of interest is their use in algorithmic hiring, specifically in matching resumes with job categories. Yet, this introduces issues of bias on protected attributes like gender, race and maternity status. The seminal work of [4] set the gold-standard for identifying hiring bias via field experiments where the response rate for identical resumes that differ only in protected attributes, e.g., racially suggestive names such as Emily or Lakisha, is compared. We replicate this experiment on state-of-art LLMs to evaluate bias (or lack thereof) on gender, race, maternity status, pregnancy status, and political affiliation. We evaluate LLMs on two tasks: (1) matching resumes to job categories; and (2) summarizing resumes with employment relevant information. Overall, LLMs are robust across race and gender. They differ in their performance on pregnancy status and political affiliation. We use contrastive input decoding on open-source LLMs to uncover potential sources of bias.},
	language = {en},
	author = {Veldanda, Akshaj Kumar and Grob, Fabian and Thakur, Shailja and Pearce, Hammond and Tan, Benjamin and Karri, Ramesh and Garg, Siddharth},
	keywords = {fair},
}

@misc{durante_agent_2024,
	title = {Agent {AI}: {Surveying} the {Horizons} of {Multimodal} {Interaction}},
	shorttitle = {Agent {AI}},
	url = {http://arxiv.org/abs/2401.03568},
	abstract = {Multi-modal AI systems will likely become a ubiquitous presence in our everyday lives. A promising approach to making these systems more interactive is to embody them as agents within physical and virtual environments. At present, systems leverage existing foundation models as the basic building blocks for the creation of embodied agents. Embedding agents within such environments facilitates the ability of models to process and interpret visual and contextual data, which is critical for the creation of more sophisticated and context-aware AI systems. For example, a system that can perceive user actions, human behavior, environmental objects, audio expressions, and the collective sentiment of a scene can be used to inform and direct agent responses within the given environment. To accelerate research on agent-based multimodal intelligence, we define "Agent AI" as a class of interactive systems that can perceive visual stimuli, language inputs, and other environmentally-grounded data, and can produce meaningful embodied actions. In particular, we explore systems that aim to improve agents based on next-embodied action prediction by incorporating external knowledge, multi-sensory inputs, and human feedback. We argue that by developing agentic AI systems in grounded environments, one can also mitigate the hallucinations of large foundation models and their tendency to generate environmentally incorrect outputs. The emerging field of Agent AI subsumes the broader embodied and agentic aspects of multimodal interactions. Beyond agents acting and interacting in the physical world, we envision a future where people can easily create any virtual reality or simulated scene and interact with agents embodied within the virtual environment.},
	urldate = {2024-03-15},
	publisher = {arXiv},
	author = {Durante, Zane and Huang, Qiuyuan and Wake, Naoki and Gong, Ran and Park, Jae Sung and Sarkar, Bidipta and Taori, Rohan and Noda, Yusuke and Terzopoulos, Demetri and Choi, Yejin and Ikeuchi, Katsushi and Vo, Hoi and Fei-Fei, Li and Gao, Jianfeng},
	month = jan,
	year = {2024},
	note = {arXiv:2401.03568 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, survey},
}

@article{volek_czech_2023,
	title = {Czech {Readers} between {Benefits} and {Threats} of the {Algorithmic} {News} {Personalization}},
	volume = {17},
	copyright = {Copyright (c) 2023 Jaromír Jaroslav Volek, Alžběta Krausová},
	issn = {1646-5954},
	url = {https://obs.obercom.pt/index.php/obs/article/view/2063},
	doi = {10.15847/obsOBS17120232063},
	abstract = {The paper describes how news consumers imagine an ideal state of personalization and which improvements they suggest. Our analysis shows that they primarily perceive the phenomenon of news personalization as a loss of control over search mechanisms and information delivery. They perceive themselves as a weaker part of a relationship characterized by an increasing information asymmetry. We base this finding on our qualitative analysis of respondents’ attitudes towards news personalization. Its goal was threefold: to understand how news personalization affects consumers’ trust in this technology, identify the reasons for potential consumers’ mistrust, and describe what needs and competencies news consumers perceive as necessary for protecting their personal data. Respondents expressed doubts about personalization credibility and described the respective algorithms as a “black box.” The data shows that personalized news consumers are concerned about personal data management. They are also very skeptical about the possibility of exercising their rights with the help of existing regulations. The paper formulates recommendations for the best practices in providing personalized news that considers the shared responsibility of providers and consumers of online content.},
	language = {en},
	number = {1},
	urldate = {2024-02-18},
	journal = {Observatorio (OBS*)},
	author = {Volek, Jaromír Jaroslav and Krausová, Alžběta and Moravec, Vaclav},
	month = mar,
	year = {2023},
	note = {Number: 1},
	keywords = {artificial intelligence, informational self-determination, journalism, news, news personalization, subversive defense tactics},
}

@inproceedings{devos_toward_2022,
	address = {New Orleans LA USA},
	title = {Toward {User}-{Driven} {Algorithm} {Auditing}: {Investigating} users’ strategies for uncovering harmful algorithmic behavior},
	isbn = {978-1-4503-9157-3},
	shorttitle = {Toward {User}-{Driven} {Algorithm} {Auditing}},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517441},
	doi = {10.1145/3491102.3517441},
	language = {en},
	urldate = {2024-02-08},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {DeVos, Alicia and Dhabalia, Aditi and Shen, Hong and Holstein, Kenneth and Eslami, Motahhare},
	month = apr,
	year = {2022},
	pages = {1--19},
}

@inproceedings{yuan_contextualizing_2023,
	address = {Hamburg Germany},
	title = {Contextualizing {User} {Perceptions} about {Biases} for {Human}-{Centered} {Explainable} {Artificial} {Intelligence}},
	isbn = {978-1-4503-9421-5},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580945},
	doi = {10.1145/3544548.3580945},
	abstract = {Biases in Artifcial Intelligence (AI) systems or their results are one important issue that demands AI explainability. Despite the prevalence of AI applications, the general public are not necessarily equipped with the ability to understand how the black-box algorithms work and how to deal with biases. To inform designs for explainable AI (XAI), we conducted in-depth interviews with major stakeholders, both end-users (n = 24) and engineers (n = 15), to investigate how they made sense of AI applications and the associated biases according to situations of high and low stakes. We discussed users’ perceptions and attributions about AI biases and their desired levels and types of explainability. We found that personal relevance and boundaries as well as the level of stake are two major dimensions for developing user trust especially during biased situations and informing XAI designs.},
	language = {en},
	urldate = {2024-02-08},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yuan, Chien Wen (Tina) and Bi, Nanyi and Lin, Ya-Fang and Tseng, Yuen-Hsien},
	month = apr,
	year = {2023},
	pages = {1--15},
}

@misc{aridor_deconstructing_2020,
	title = {Deconstructing the {Filter} {Bubble}: {User} {Decision}-{Making} and {Recommender} {Systems}},
	shorttitle = {Deconstructing the {Filter} {Bubble}},
	url = {http://arxiv.org/abs/1904.10527},
	abstract = {We study a model of user decision-making in the context of recommender systems via numerical simulation. Our model provides an explanation for the findings of Nguyen, et. al (2014), where, in environments where recommender systems are typically deployed, users consume increasingly similar items over time even without recommendation. We find that recommendation alleviates these natural filter-bubble effects, but that it also leads to an increase in homogeneity across users, resulting in a trade-off between homogenizing across-user consumption and diversifying within-user consumption. Finally, we discuss how our model highlights the importance of collecting data on user beliefs and their evolution over time both to design better recommendations and to further understand their impact.},
	urldate = {2024-02-07},
	publisher = {arXiv},
	author = {Aridor, Guy and Goncalves, Duarte and Sikdar, Shan},
	month = jul,
	year = {2020},
	note = {arXiv:1904.10527 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Information Retrieval},
}

@article{young_young_2023,
	title = {Young {Adults}’ {Folk} {Theories} of {How} {Social} {Media} {Harms} {Its} {Users}},
	volume = {26},
	issn = {1520-5436, 1532-7825},
	url = {https://www.tandfonline.com/doi/full/10.1080/15205436.2021.1970186},
	doi = {10.1080/15205436.2021.1970186},
	abstract = {The age of digital, and especially social, media has increased the volume of information users encounter and the mediated interactions users are involved in or observe. This study analyzes young adults’ understanding of harmful content online to identify folk theories, the explanations and predictions users develop to help guide their judgments and behavior. In 494 free responses, college students identified 12 online speech acts or trends as harmful. Subjects primarily identified individuals as the ones harmed, the ones responsible for causing harm, and the ones responsible for solving the problem of harms. Content caused harm through a range of mechanisms, such as normalizing hatred, misinforming citizens, or prompting incessant social comparison. Young adults perceive offensive online speech as a pervasive problem, but with limited personal investment in solutions and little hope for mitigating harm. In decades of research on media effects, there’s been extensive developing and testing of expert theories and less qualitative research on how people make sense of media influence. Our study demonstrates that users’ folk theories are cohesive across a range of content types, focused on the actions and experiences of individual users, and emphasize individual solutions to the large-scale issue of social media effects.},
	language = {en},
	number = {1},
	urldate = {2024-02-04},
	journal = {Mass Communication and Society},
	author = {Young, Rachel and Kananovich, Volha and Johnson, Brett G.},
	month = jan,
	year = {2023},
	pages = {23--46},
}

@misc{ghori_how_2021,
	title = {How does the {User}'s {Knowledge} of the {Recommender} {Influence} their {Behavior}?},
	url = {http://arxiv.org/abs/2109.00982},
	abstract = {Recommender systems have become a ubiquitous part of modern web applications. They help users discover new and relevant items. Today's users, through years of interaction with these systems have developed an inherent understanding of how recommender systems function, what their objectives are, and how the user might manipulate them. We describe this understanding as the Theory of the Recommender. In this study, we conducted semi-structured interviews with forty recommender system users to empirically explore the relevant factors influencing user behavior. Our findings, based on a rigorous thematic analysis of the collected data, suggest that users possess an intuitive and sophisticated understanding of the recommender system's behavior. We also found that users, based upon their understanding, attitude, and intentions change their interactions to evoke desired recommender behavior. Finally, we discuss the potential implications of such user behavior on recommendation performance.},
	urldate = {2024-02-04},
	publisher = {arXiv},
	author = {Ghori, Muheeb Faizan and Dehpanah, Arman and Gemmell, Jonathan and Qahri-Saremi, Hamed and Mobasher, Bamshad},
	month = sep,
	year = {2021},
	note = {arXiv:2109.00982 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Information Retrieval, rec},
}

@article{feezell_exploring_2021,
	title = {Exploring the effects of algorithm-driven news sources on political behavior and polarization},
	volume = {116},
	issn = {07475632},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0747563220303733},
	doi = {10.1016/j.chb.2020.106626},
	abstract = {Do algorithm-driven news sources have different effects on political behavior when compared to non-algorithmic news sources? Media companies compete for our scarce time and attention; one way they do this is by leveraging algorithms to select the most appealing content for each user. While algorithm-driven sites are increasingly popular sources of information, we know very little about the effects of algorithmically determined news at the individual level. The objective of this paper is to define and measure the effects of algorithmically generated news. We begin by developing a taxonomy of news delivery by distinguishing between two types of algorithmically generated news, socially driven and user-driven, and contrasting these with non-algorithmic news. We follow with an exploratory analysis of the effects of these news delivery modes on political behavior, specifically political participation and polarization. Using two nationally representative surveys, one of young adults and one of the general population, we find that getting news from sites that use socially driven or user-driven algorithms to generate content corresponds with higher levels of political participation, but that getting news from nonalgorithmic sources does not. We also find that neither non-algorithmic nor algorithmically determined news contribute to higher levels of partisan polarization. This research helps identify important variation in the consequences of news consumption contingent on the mode of delivery.},
	language = {en},
	urldate = {2024-01-28},
	journal = {Computers in Human Behavior},
	author = {Feezell, Jessica T. and Wagner, John K. and Conroy, Meredith},
	month = mar,
	year = {2021},
	keywords = {news},
	pages = {106626},
}

@misc{noauthor_generalised_nodate,
	title = {Generalised scepticism: how people navigate news on social media},
	shorttitle = {Generalised scepticism},
	url = {https://www.tandfonline.com/doi/epdf/10.1080/1369118X.2018.1450887?needAccess=true},
	language = {en},
	urldate = {2024-01-28},
	note = {ISSN: 1369-118X},
	keywords = {news},
}

@article{eg_scoping_2023,
	title = {A scoping review of personalized user experiences on social media: {The} interplay between algorithms and human factors},
	volume = {9},
	issn = {24519588},
	shorttitle = {A scoping review of personalized user experiences on social media},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2451958822000872},
	doi = {10.1016/j.chbr.2022.100253},
	abstract = {No social media user sees the same feed. These platforms are personalized to the individual with the aid of algorithms that filter and prioritize content based on users’ demographic profiles and personal data. On the one hand, this personalization aids the user by making the service more relevant, for instance by curating information of interest. On the other hand, personalization introduces potential risks associated with privacy concerns, lack of autonomy and control, as well as limited diversity of information. This scoping review presents an overview of the current state of knowledge of social media personalization from different research domains, providing insight on social media users’ algorithmic awareness, their customization habits, their interactions with curated content, and the debate on how algorithms may create closed information outlets. It also provides a condensed overview of the different terminology used across domains, in the form of a glossary.},
	language = {en},
	urldate = {2024-01-28},
	journal = {Computers in Human Behavior Reports},
	author = {Eg, Ragnhild and Demirkol Tønnesen, Özlem and Tennfjord, Merete Kolberg},
	month = mar,
	year = {2023},
	keywords = {news},
	pages = {100253},
}

@inproceedings{wu_designing_2023,
	address = {Singapore},
	title = {Designing, {Evaluating}, and {Learning} from {Humans} {Interacting} with {NLP} {Models}},
	url = {https://aclanthology.org/2023.emnlp-tutorial.3},
	doi = {10.18653/v1/2023.emnlp-tutorial.3},
	abstract = {The rapid advancement of natural language processing (NLP) research has led to various applications spanning a wide range of domains that require models to interact with humans – e.g., chatbots responding to human inquiries, machine translation systems assisting human translators, designers prompting Large Language Models for co-creation or prototyping AI-infused applications, etc. In these cases, humans interaction is key to the success of NLP applications; any potential misconceptions or differences might lead to error cascades at the subsequent stages. Such interaction involves a lot of design choices around models, e.g. the sensitivity of interfaces, the impact of design choice and evaluation questions, etc. This tutorial aims to provide a systematic and up-to-date overview of key considerations and effective approaches for studying human-NLP model interactions. Our tutorial will focus specifically on the scenario where end users – lay people and domain experts who have access to NLP models but are less familiar with NLP techniques – use or collaborate with deployed models. Throughout the tutorial, we will use five case studies (on classifier-assisted decision making, machine-aided translation, dialog systems, and prompting) to cover three major themes: (1) how to conduct human-in-the-loop usability evaluations to ensure that models are capable of interacting with humans; (2) how to design user interfaces (UIs) and interaction mechanisms that provide end users with easy access to NLP models; (3) how to learn and improve NLP models through the human interactions. We will use best practices from HCI to ground our discussion, and will highlight current challenges and future directions.},
	urldate = {2024-01-26},
	booktitle = {Proceedings of the 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}: {Tutorial} {Abstracts}},
	publisher = {Association for Computational Linguistics},
	author = {Wu, Tongshuang and Yang, Diyi and Santy, Sebastin},
	editor = {Zhang, Qi and Sajjad, Hassan},
	month = dec,
	year = {2023},
	keywords = {llm},
	pages = {13--18},
}

@misc{zeng_how_2024,
	title = {How {Johnny} {Can} {Persuade} {LLMs} to {Jailbreak} {Them}: {Rethinking} {Persuasion} to {Challenge} {AI} {Safety} by {Humanizing} {LLMs}},
	shorttitle = {How {Johnny} {Can} {Persuade} {LLMs} to {Jailbreak} {Them}},
	url = {http://arxiv.org/abs/2401.06373},
	abstract = {Most traditional AI safety research has approached AI models as machines and centered on algorithm-focused attacks developed by security experts. As large language models (LLMs) become increasingly common and competent, non-expert users can also impose risks during daily interactions. This paper introduces a new perspective on jailbreaking LLMs as human-like communicators to explore this overlooked intersection between everyday language interaction and AI safety. Specifically, we study how to persuade LLMs to jailbreak them. First, we propose a persuasion taxonomy derived from decades of social science research. Then we apply the taxonomy to automatically generate interpretable persuasive adversarial prompts (PAP) to jailbreak LLMs. Results show that persuasion significantly increases the jailbreak performance across all risk categories: PAP consistently achieves an attack success rate of over 92\% on Llama 2-7b Chat, GPT-3.5, and GPT-4 in 10 trials, surpassing recent algorithm-focused attacks. On the defense side, we explore various mechanisms against PAP, find a significant gap in existing defenses, and advocate for more fundamental mitigation for highly interactive LLMs 1.},
	language = {en},
	urldate = {2024-01-26},
	publisher = {arXiv},
	author = {Zeng, Yi and Lin, Hongpeng and Zhang, Jingwen and Yang, Diyi and Jia, Ruoxi and Shi, Weiyan},
	month = jan,
	year = {2024},
	note = {arXiv:2401.06373 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{noauthor_research_nodate,
	title = {Research},
	url = {https://www.anthropic.com/research},
	abstract = {Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.},
	language = {en},
	urldate = {2024-01-26},
}

@misc{feng_pretraining_2023,
	title = {From {Pretraining} {Data} to {Language} {Models} to {Downstream} {Tasks}: {Tracking} the {Trails} of {Political} {Biases} {Leading} to {Unfair} {NLP} {Models}},
	shorttitle = {From {Pretraining} {Data} to {Language} {Models} to {Downstream} {Tasks}},
	url = {http://arxiv.org/abs/2305.08283},
	abstract = {Language models (LMs) are pretrained on diverse data sources, including news, discussion forums, books, and online encyclopedias. A significant portion of this data includes opinions and perspectives which, on one hand, celebrate democracy and diversity of ideas, and on the other hand are inherently socially biased. Our work develops new methods to (1) measure political biases in LMs trained on such corpora, along social and economic axes, and (2) measure the fairness of downstream NLP models trained on top of politically biased LMs. We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks. Our findings reveal that pretrained LMs do have political leanings that reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and misinformation detectors. We discuss the implications of our findings for NLP research and propose future directions to mitigate unfairness.},
	urldate = {2024-01-26},
	publisher = {arXiv},
	author = {Feng, Shangbin and Park, Chan Young and Liu, Yuhan and Tsvetkov, Yulia},
	month = jul,
	year = {2023},
	note = {arXiv:2305.08283 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{bubeck_sparks_2023,
	title = {Sparks of {Artificial} {General} {Intelligence}: {Early} experiments with {GPT}-4},
	shorttitle = {Sparks of {Artificial} {General} {Intelligence}},
	url = {http://arxiv.org/abs/2303.12712},
	abstract = {Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.},
	urldate = {2024-01-17},
	publisher = {arXiv},
	author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
	month = apr,
	year = {2023},
	note = {arXiv:2303.12712 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{kaur_sensible_2022,
	address = {Seoul Republic of Korea},
	title = {Sensible {AI}: {Re}-imagining {Interpretability} and {Explainability} using {Sensemaking} {Theory}},
	isbn = {978-1-4503-9352-2},
	shorttitle = {Sensible {AI}},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533135},
	doi = {10.1145/3531146.3533135},
	language = {en},
	urldate = {2024-01-13},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Kaur, Harmanpreet and Adar, Eytan and Gilbert, Eric and Lampe, Cliff},
	month = jun,
	year = {2022},
	keywords = {sensemaking, xai},
	pages = {702--714},
}

@article{lam_end-user_2022,
	title = {End-{User} {Audits}: {A} {System} {Empowering} {Communities} to {Lead} {Large}-{Scale} {Investigations} of {Harmful} {Algorithmic} {Behavior}},
	volume = {6},
	issn = {2573-0142},
	shorttitle = {End-{User} {Audits}},
	url = {https://dl.acm.org/doi/10.1145/3555625},
	doi = {10.1145/3555625},
	abstract = {Because algorithm audits are conducted by technical experts, audits are necessarily limited to the hypotheses that experts think to test. End users hold the promise to expand this purview, as they inhabit spaces and witness algorithmic impacts that auditors do not. In pursuit of this goal, we propose end-user audits-system-scale audits led by non-technical users-and present an approach that scaffolds end users in hypothesis generation, evidence identification, and results communication. Today, performing a system-scale audit requires substantial user effort to label thousands of system outputs, so we introduce a collaborative filtering technique that leverages the algorithmic system's own disaggregated training data to project from a small number of end user labels onto the full test set. Our end-user auditing tool, IndieLabel, employs these predicted labels so that users can rapidly explore where their opinions diverge from the algorithmic system's outputs. By highlighting topic areas where the system is under-performing for the user and surfacing sets of likely error cases, the tool guides the user in authoring an audit report. In an evaluation of end-user audits on a popular comment toxicity model with 17 non-technical participants, participants both replicated issues that formal audits had previously identified and also raised previously underreported issues such as under-flagging on veiled forms of hate that perpetuate stigma and over-flagging of slurs that have been reclaimed by marginalized communities.},
	language = {en},
	number = {CSCW2},
	urldate = {2024-01-12},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lam, Michelle S. and Gordon, Mitchell L. and Metaxa, Danaë and Hancock, Jeffrey T. and Landay, James A. and Bernstein, Michael S.},
	month = nov,
	year = {2022},
	keywords = {audit},
	pages = {1--34},
}

@misc{liu_human-centered_2023,
	title = {Human-centered {NLP} {Fact}-checking: {Co}-{Designing} with {Fact}-checkers using {Matchmaking} for {AI}},
	shorttitle = {Human-centered {NLP} {Fact}-checking},
	url = {http://arxiv.org/abs/2308.07213},
	abstract = {A key challenge in professional fact-checking is its limited scalability in relation to the magnitude of false information. While many Natural Language Processing (NLP) tools have been proposed to enhance fact-checking efficiency and scalability, both academic research and fact-checking organizations report limited adoption of such tooling due to insufficient alignment with fact-checker practices, values, and needs. To address this gap, we investigate a co-design method, Matchmaking for AI, which facilitates fact-checkers, designers, and NLP researchers to collaboratively discover what fact-checker needs should be addressed by technology and how. Our co-design sessions with 22 professional fact-checkers yielded a set of 11 novel design ideas. They assist in information searching, processing, and writing tasks for efficient and personalized fact-checking; help fact-checkers proactively prepare for future misinformation; monitor their potential biases; and support internal organization collaboration. Our work offers implications for human-centered fact-checking research and practice and AI co-design research.},
	language = {en},
	urldate = {2024-01-10},
	publisher = {arXiv},
	author = {Liu, Houjiang and Das, Anubrata and Boltz, Alexander and Zhou, Didi and Pinaroc, Daisy and Lease, Matthew and Lee, Min Kyung},
	month = aug,
	year = {2023},
	note = {arXiv:2308.07213 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, codesign},
}

@misc{ConstitutionMakerInteractivelyCritiquingLargeLanguage,
	title = {{ConstitutionMaker}: {Interactively} {Critiquing} {Large} {Language} {Models} by {Converting} {Feedback} into {Principles}},
	shorttitle = {{ConstitutionMaker}},
	url = {http://arxiv.org/abs/2310.15428},
	abstract = {Large language model (LLM) prompting is a promising new approach for users to create and customize their own chatbots. However, current methods for steering a chatbot's outputs, such as prompt engineering and fine-tuning, do not support users in converting their natural feedback on the model's outputs to changes in the prompt or model. In this work, we explore how to enable users to interactively refine model outputs through their feedback, by helping them convert their feedback into a set of principles (i.e. a constitution) that dictate the model's behavior. From a formative study, we (1) found that users needed support converting their feedback into principles for the chatbot and (2) classified the different principle types desired by users. Inspired by these findings, we developed ConstitutionMaker, an interactive tool for converting user feedback into principles, to steer LLM-based chatbots. With ConstitutionMaker, users can provide either positive or negative feedback in natural language, select auto-generated feedback, or rewrite the chatbot's response; each mode of feedback automatically generates a principle that is inserted into the chatbot's prompt. In a user study with 14 participants, we compare ConstitutionMaker to an ablated version, where users write their own principles. With ConstitutionMaker, participants felt that their principles could better guide the chatbot, that they could more easily convert their feedback into principles, and that they could write principles more efficiently, with less mental demand. ConstitutionMaker helped users identify ways to improve the chatbot, formulate their intuitive responses to the model into feedback, and convert this feedback into specific and clear principles. Together, these findings inform future tools that support the interactive critiquing of LLM outputs.},
	language = {en},
	urldate = {2023-11-23},
	publisher = {arXiv},
	author = {Petridis, Savvas and Wedin, Ben and Wexler, James and Donsbach, Aaron and Pushkarna, Mahima and Goyal, Nitesh and Cai, Carrie J. and Terry, Michael},
	month = oct,
	year = {2023},
	note = {arXiv:2310.15428 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, hci, llm},
}

@article{MeasuringOccupationalImpactAITasks,
	title = {Measuring the {Occupational} {Impact} of {AI}: {Tasks}, {Cognitive} {Abilities} and {AI} {Benchmarks}},
	volume = {71},
	issn = {1076-9757},
	shorttitle = {Measuring the {Occupational} {Impact} of {AI}},
	url = {https://www.jair.org/index.php/jair/article/view/12647},
	doi = {10.1613/jair.1.12647},
	abstract = {In this paper we develop a framework for analysing the impact of Artificial Intelligence (AI) on occupations. This framework maps 59 generic tasks from worker surveys and an occupational database to 14 cognitive abilities (that we extract from the cognitive science literature) and these to a comprehensive list of 328 AI benchmarks used to evaluate research intensity across a broad range of different AI areas. The use of cognitive abilities as an intermediate layer, instead of mapping work tasks to AI benchmarks directly, allows for an identification of potential AI exposure for tasks for which AI applications have not been explicitly created. An application of our framework to occupational databases gives insights into the abilities through which AI is most likely to affect jobs and allows for a ranking of occupations with respect to AI exposure. Moreover, we show that some jobs that were not known to be affected by previous waves of automation may now be subject to higher AI exposure. Finally, we find that some of the abilities where AI research is currently very intense are linked to tasks with comparatively limited labour input in the labour markets of advanced economies (e.g., visual and auditory processing using deep learning, and sensorimotor interaction through (deep) reinforcement learning).},
	language = {en},
	urldate = {2023-12-02},
	journal = {Journal of Artificial Intelligence Research},
	author = {Tolan, Songül and Pesole, Annarosa and Martínez-Plumed, Fernando and Fernández-Macías, Enrique and Hernández-Orallo, José and Gómez, Emilia},
	month = jun,
	year = {2021},
	pages = {191--236},
}

@inproceedings{RecommenderSystemsAlgorithmicHate,
	address = {Seattle WA USA},
	title = {Recommender {Systems} and {Algorithmic} {Hate}},
	isbn = {978-1-4503-9278-5},
	url = {https://dl.acm.org/doi/10.1145/3523227.3551480},
	doi = {10.1145/3523227.3551480},
	language = {en},
	urldate = {2023-11-20},
	booktitle = {Proceedings of the 16th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Smith, Jessie J. and Jayne, Lucia and Burke, Robin},
	month = sep,
	year = {2022},
	keywords = {rec},
	pages = {592--597},
}

@article{Makingsenserecommendations,
	title = {Making sense of recommendations},
	volume = {32},
	issn = {0894-3257, 1099-0771},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/bdm.2118},
	doi = {10.1002/bdm.2118},
	abstract = {Computer algorithms are increasingly being used to predict people's preferences and make recommendations. Although people frequently encounter these algorithms because they are cheap to scale, we do not know how they compare to human judgment. Here, we compare computer recommender systems to human recommenders in a domain that affords humans many advantages: predicting which jokes people will find funny. We find that recommender systems outperform humans, whether strangers, friends, or family. Yet people are averse to relying on these recommender systems. This aversion partly stems from the fact that people believe the human recommendation process is easier to understand. It is not enough for recommender systems to be accurate, they must also be understood.},
	language = {en},
	number = {4},
	urldate = {2023-11-20},
	journal = {Journal of Behavioral Decision Making},
	author = {Yeomans, Michael and Shah, Anuj and Mullainathan, Sendhil and Kleinberg, Jon},
	month = oct,
	year = {2019},
	keywords = {rec},
	pages = {403--414},
}

@misc{05pdf,
	title = {05.pdf},
	url = {https://drive.google.com/file/d/1Qwuhez0Ml6fNDxv5s4ikX37waaftK0hw/view?usp=drive_link&usp=embed_facebook},
	urldate = {2023-11-19},
	journal = {Google Docs},
	keywords = {causal, generative, vis},
}

@article{improvinguserawarenesssearchengineb,
	title = {Towards improving user awareness of search engine biases: {A} participatory design approach},
	issn = {2330-1635, 2330-1643},
	shorttitle = {Towards improving user awareness of search engine biases},
	url = {https://asistdl.onlinelibrary.wiley.com/doi/10.1002/asi.24826},
	doi = {10.1002/asi.24826},
	abstract = {Bias in news search engines has been shown to influence users' perceptions of a news topic and contribute to the polarisation of society. As a result, there is a need for news search engines that increase user awareness of biases in the search results. While technical approaches have been developed to mitigate biases in search, very few studies have investigated user preferences in interface designs for potentially raising their awareness of biases in news search engines. In this study, we utilized a participatory design methodology to develop eight prototypes with different features that could potentially be used to raise user awareness of biases in news search engines. We conducted three user studies, involving 132 participants with Computer Science backgrounds, to evaluate these prototypes. Our findings indicate the importance of news search engines that (a) inform users of possible biases in the results (bias visualization approach) and (b) allow users to access alternative search results (resultsreranking approach). Our study provides further insights into the strengths and possible risks of each approach, which are important for future research on designing interfaces for raising user awareness of biases in news search engines.},
	language = {en},
	urldate = {2023-11-17},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Paramita, Monica Lestari and Kasinidou, Maria and Kleanthous, Styliani and Rosso, Paolo and Kuflik, Tsvi and Hopfgartner, Frank},
	month = sep,
	year = {2023},
	pages = {asi.24826},
}

@misc{CounterfactualExplanationsAlgorithmicRecoursesMachine,
	title = {Counterfactual {Explanations} and {Algorithmic} {Recourses} for {Machine} {Learning}: {A} {Review}},
	shorttitle = {Counterfactual {Explanations} and {Algorithmic} {Recourses} for {Machine} {Learning}},
	url = {http://arxiv.org/abs/2010.10596},
	abstract = {Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine learning based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this paper, we seek to review and categorize research on counterfactual explanations, a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.},
	language = {en},
	urldate = {2023-12-15},
	publisher = {arXiv},
	author = {Verma, Sahil and Boonsanong, Varich and Hoang, Minh and Hines, Keegan E. and Dickerson, John P. and Shah, Chirag},
	month = nov,
	year = {2022},
	note = {arXiv:2010.10596 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, counterfactual},
}

@misc{GPTsareGPTsEarlyLook,
	title = {{GPTs} are {GPTs}: {An} {Early} {Look} at the {Labor} {Market} {Impact} {Potential} of {Large} {Language} {Models}},
	shorttitle = {{GPTs} are {GPTs}},
	url = {http://arxiv.org/abs/2303.10130},
	abstract = {We investigate the potential implications of large language models (LLMs), such as Generative Pretrained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80\% of the U.S. workforce could have at least 10\% of their work tasks affected by the introduction of LLMs, while approximately 19\% of workers may see at least 50\% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15\% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56\% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.},
	language = {en},
	urldate = {2023-12-10},
	publisher = {arXiv},
	author = {Eloundou, Tyna and Manning, Sam and Mishkin, Pamela and Rock, Daniel},
	month = aug,
	year = {2023},
	note = {arXiv:2303.10130 [cs, econ, q-fin]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Economics - General Economics},
}

@inproceedings{DoesAIQualifyJobBidirectional,
	address = {New York NY USA},
	title = {Does {AI} {Qualify} for the {Job}?: {A} {Bidirectional} {Model} {Mapping} {Labour} and {AI} {Intensities}},
	isbn = {978-1-4503-7110-0},
	shorttitle = {Does {AI} {Qualify} for the {Job}?},
	url = {https://dl.acm.org/doi/10.1145/3375627.3375831},
	doi = {10.1145/3375627.3375831},
	abstract = {In this paper we present a setting for examining the relation between the distribution of research intensity in AI research and the relevance for a range of work tasks (and occupations) in current and simulated scenarios. We perform a mapping between labour and AI using a set of cognitive abilities as an intermediate layer. This setting favours a two-way interpretation to analyse (1) what impact current or simulated AI research activity has or would have on labour-related tasks and occupations, and (2) what areas of AI research activity would be responsible for a desired or undesired effect on specific labour tasks and occupations. Concretely, in our analysis we map 59 generic labour-related tasks from several worker surveys and databases to 14 cognitive abilities from the cognitive science literature, and these to a comprehensive list of 328 AI benchmarks used to evaluate progress in AI techniques. We provide this model and its implementation as a tool for simulations. We also show the effectiveness of our setting with some illustrative examples.},
	language = {en},
	urldate = {2024-01-05},
	booktitle = {Proceedings of the {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Martínez-Plumed, Fernando and Tolan, Songül and Pesole, Annarosa and Hernández-Orallo, José and Fernández-Macías, Enrique and Gómez, Emilia},
	month = feb,
	year = {2020},
	pages = {94--100},
}

@article{IdealHumanExpectationsAITeammates,
	title = {"{An} {Ideal} {Human}": {Expectations} of {AI} {Teammates} in {Human}-{AI} {Teaming}},
	volume = {4},
	issn = {2573-0142},
	shorttitle = {"{An} {Ideal} {Human}"},
	url = {https://dl.acm.org/doi/10.1145/3432945},
	doi = {10.1145/3432945},
	abstract = {Driven by state-of-the-art AI technologies, human-AI collaboration has become an important area in computer-supported teamwork research. While human-AI collaboration has been investigated in various domains, more research is needed to explore human perceptions and expectations of AI teammates in human-AI teaming. To achieve an in-depth understanding of how people perceive AI teammates and what they expect from AI teammates in human-AI teaming, we conducted a survey with 213 participants and a follow-up interview with 20 participants. Considering the context-dependency of teamwork, we chose to study human-AI teaming in the context of multiplayer online games as a case study. This study shows that people have mixed feelings toward AI teammates but hold a positive attitude toward future collaboration with AI teammates in general. Our findings highlight people's expectations for AI teammates in a rapidly changing collaborative environment (e.g., instrumental skills for in-game tasks, shared understanding between humans and AI, communication capabilities, human-like behaviors and performance), as well as factors that impact people's willingness to team up with AI teammates (e.g., pre-existing attitudes toward AI, previous collaboration experience with humans). We contribute to CSCW by shedding light on how AI should be structured in human-AI teaming to support highly complex collaborative activities in CSCW environments.},
	language = {en},
	number = {CSCW3},
	urldate = {2024-01-04},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Zhang, Rui and McNeese, Nathan J. and Freeman, Guo and Musick, Geoff},
	month = jan,
	year = {2021},
	keywords = {collaboration},
	pages = {1--25},
}

@article{TaxonomyHumanMLStrengthsDecisionMaking,
	title = {A {Taxonomy} of {Human} and {ML} {Strengths} in {Decision}-{Making} to {Investigate} {Human}-{ML} {Complementarity}},
	volume = {11},
	issn = {2769-1349, 2769-1330},
	url = {https://ojs.aaai.org/index.php/HCOMP/article/view/27554},
	doi = {10.1609/hcomp.v11i1.27554},
	abstract = {Hybrid human-ML systems increasingly make consequential decisions in a wide range of domains. These systems are often introduced with the expectation that the combined humanML system will achieve complementary performance, that is, the combined decision-making system will be an improvement compared with either decision-making agent in isolation. However, empirical results have been mixed, and existing research rarely articulates the sources and mechanisms by which complementary performance is expected to arise. Our goal in this work is to provide conceptual tools to advance the way researchers reason and communicate about humanML complementarity. Drawing upon prior literature in human psychology, machine learning, and human-computer interaction, we propose a taxonomy characterizing distinct ways in which human and ML-based decision-making can differ. In doing so, we conceptually map potential mechanisms by which combining human and ML decision-making may yield complementary performance, developing a language for the research community to reason about design of hybrid systems in any decision-making domain. To illustrate how our taxonomy can be used to investigate complementarity, we provide a mathematical aggregation framework to examine enabling conditions for complementarity. Through synthetic simulations, we demonstrate how this framework can be used to explore specific aspects of our taxonomy and shed light on the optimal mechanisms for combining human-ML judgments.},
	language = {en},
	number = {1},
	urldate = {2024-01-04},
	journal = {Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
	author = {Rastogi, Charvi and Leqi, Liu and Holstein, Kenneth and Heidari, Hoda},
	month = nov,
	year = {2023},
	keywords = {collaboration, complementarity},
	pages = {127--139},
}

@article{ComprehensiveTaxonomyTasksAssessingImpact,
	title = {A {Comprehensive} {Taxonomy} of {Tasks} for {Assessing} the {Impact} of {New} {Technologies} on {Work}},
	volume = {159},
	issn = {0303-8300, 1573-0921},
	url = {https://link.springer.com/10.1007/s11205-021-02768-7},
	doi = {10.1007/s11205-021-02768-7},
	abstract = {In recent years, the increasing concern about the labour market implications of technological change has led economists to look in more detail at the structure of work content and job tasks. Incorporating insights from other traditions of task analysis, in particular from the labour process approach, as well as from recent research on skills, work organisation and occupational change, in this paper we propose a comprehensive and detailed taxonomy of tasks. Going beyond existing broad classifications, our taxonomy aims at connecting the substantive content of work with its organisational context by answering two key questions: what do people do at work and how do they do their work? For illustrative purposes, we show how our approach allows a better understanding of the impact of new technologies on work, by accounting for relevant ongoing transformations such as the diffusion of artificial intelligence and the unfolding of digital labour platforms.},
	language = {en},
	number = {2},
	urldate = {2023-12-24},
	journal = {Social Indicators Research},
	author = {Fernández-Macías, Enrique and Bisello, Martina},
	month = jan,
	year = {2022},
	pages = {821--841},
}

@inproceedings{RecRecAlgorithmicRecourseRecommenderSystemsa,
	title = {{RecRec}: {Algorithmic} {Recourse} for {Recommender} {Systems}},
	shorttitle = {{RecRec}},
	url = {http://arxiv.org/abs/2308.14916},
	doi = {10.1145/3583780.3615181},
	abstract = {Recommender systems play an essential role in the choices people make in domains such as entertainment, shopping, food, news, employment, and education. The machine learning models underlying these recommender systems are often enormously large and black-box in nature for users, content providers, and system developers alike. It is often crucial for all stakeholders to understand the model's rationale behind making certain predictions and recommendations. This is especially true for the content providers whose livelihoods depend on the recommender system. Drawing motivation from the practitioners' need, in this work, we propose a recourse framework for recommender systems, targeted towards the content providers. Algorithmic recourse in the recommendation setting is a set of actions that, if executed, would modify the recommendations (or ranking) of an item in the desired manner. A recourse suggests actions of the form: "if a feature changes X to Y, then the ranking of that item for a set of users will change to Z." Furthermore, we demonstrate that RecRec is highly effective in generating valid, sparse, and actionable recourses through an empirical evaluation of recommender systems trained on three real-world datasets. To the best of our knowledge, this work is the first to conceptualize and empirically test a generalized framework for generating recourses for recommender systems.},
	urldate = {2023-12-13},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	author = {Verma, Sahil and Singh, Ashudeep and Boonsanong, Varich and Dickerson, John P. and Shah, Chirag},
	month = oct,
	year = {2023},
	note = {arXiv:2308.14916 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Machine Learning, counterfactual, rec},
	pages = {4325--4329},
}

@inproceedings{GAMCoachInteractiveUsercenteredAlgorithmic,
	address = {Hamburg Germany},
	title = {{GAM} {Coach}: {Towards} {Interactive} and {User}-centered {Algorithmic} {Recourse}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {{GAM} {Coach}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580816},
	doi = {10.1145/3544548.3580816},
	language = {en},
	urldate = {2023-12-13},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wang, Zijie J. and Wortman Vaughan, Jennifer and Caruana, Rich and Chau, Duen Horng},
	month = apr,
	year = {2023},
	keywords = {counterfactual, explanation},
	pages = {1--20},
}

@inproceedings{RecRecAlgorithmicRecourseRecommenderSystems,
	address = {Birmingham United Kingdom},
	title = {{RecRec}: {Algorithmic} {Recourse} for {Recommender} {Systems}},
	isbn = {9798400701245},
	shorttitle = {{RecRec}},
	url = {https://dl.acm.org/doi/10.1145/3583780.3615181},
	doi = {10.1145/3583780.3615181},
	abstract = {Recommender systems play an essential role in the choices people make in domains such as entertainment, shopping, food, news, employment, and education. The machine learning models underlying these recommender systems are often enormously large and black-box in nature for users, content providers, and system developers alike. It is often crucial for all stakeholders to understand the model’s rationale behind making certain predictions and recommendations. This is especially true for the content providers whose livelihoods depend on the recommender system. Drawing motivation from the practitioners’ need, in this work, we propose a recourse framework for recommender systems, targeted towards the content providers. Algorithmic recourse in the recommendation setting is a set of actions that, if executed, would modify the recommendations (or ranking) of an item in the desired manner. A recourse suggests actions of the form: “if a feature changes 𝑋 to 𝑌 , then the ranking of that item for a set of users will change to 𝑍 .” Furthermore, we demonstrate that RecRec is highly effective in generating valid, sparse, and actionable recourses through an empirical evaluation of recommender systems trained on three realworld datasets. To the best of our knowledge, this work is the first to conceptualize and empirically test a generalized framework for generating recourses for recommender systems. Full version of the paper is available at http://arxiv.org/abs/2308.14916.},
	language = {en},
	urldate = {2023-12-13},
	booktitle = {Proceedings of the 32nd {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Verma, Sahil and Singh, Ashudeep and Boonsanong, Varich and Dickerson, John P. and Shah, Chirag},
	month = oct,
	year = {2023},
	keywords = {counterfactual},
	pages = {4325--4329},
}

@article{HowEvaluateTrustAIAssistedDecision,
	title = {How to {Evaluate} {Trust} in {AI}-{Assisted} {Decision} {Making}? {A} {Survey} of {Empirical} {Methodologies}},
	volume = {5},
	issn = {2573-0142},
	shorttitle = {How to {Evaluate} {Trust} in {AI}-{Assisted} {Decision} {Making}?},
	url = {https://dl.acm.org/doi/10.1145/3476068},
	doi = {10.1145/3476068},
	abstract = {The spread of AI-embedded systems involved in human decision making makes studying human trust in these systems critical. However, empirically investigating trust is challenging. One reason is the lack of standard protocols to design trust experiments. In this paper, we present a survey of existing methods to empirically investigate trust in AI-assisted decision making and analyse the corpus along the constitutive elements of an experimental protocol. We find that the definition of trust is not commonly integrated in experimental protocols, which can lead to findings that are overclaimed or are hard to interpret and compare across studies. Drawing from empirical practices in social and cognitive studies on human-human trust, we provide practical guidelines to improve the methodology of studying Human-AI trust in decision-making contexts. In addition, we bring forward research opportunities of two types: one focusing on further investigation regarding trust methodologies and the other on factors that impact Human-AI trust.},
	language = {en},
	number = {CSCW2},
	urldate = {2023-12-03},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Vereschak, Oleksandra and Bailly, Gilles and Caramiaux, Baptiste},
	month = oct,
	year = {2021},
	keywords = {ai, hci, trust},
	pages = {1--39},
}

@misc{lin_how_2023,
	title = {How {Can} {Recommender} {Systems} {Benefit} from {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {How {Can} {Recommender} {Systems} {Benefit} from {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2306.05817},
	abstract = {Recommender systems (RS) play important roles to match users' information needs for Internet applications. In natural language processing (NLP) domains, large language model (LLM) has shown astonishing emergent abilities (e.g., instruction following, reasoning), thus giving rise to the promising research direction of adapting LLM to RS for performance enhancements and user experience improvements. In this paper, we conduct a comprehensive survey on this research direction from an application-oriented view. We first summarize existing research works from two orthogonal perspectives: where and how to adapt LLM to RS. For the "WHERE" question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, and pipeline controller. For the "HOW" question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLMs or not, and whether to involve conventional recommendation model (CRM) for inference. Detailed analysis and general development trajectories are provided for both questions, respectively. Then, we highlight key challenges in adapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and ethics. Finally, we summarize the survey and discuss the future prospects. We also actively maintain a GitHub repository for papers and other related resources in this rising direction: https://github.com/CHIANGEL/Awesome-LLM-for-RecSys.},
	urldate = {2023-11-11},
	publisher = {arXiv},
	author = {Lin, Jianghao and Dai, Xinyi and Xi, Yunjia and Liu, Weiwen and Chen, Bo and Li, Xiangyang and Zhu, Chenxu and Guo, Huifeng and Yu, Yong and Tang, Ruiming and Zhang, Weinan},
	month = jun,
	year = {2023},
	note = {arXiv:2306.05817 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, rec},
}

@inproceedings{lyons_algorithmic_2023,
	address = {New York, NY, USA},
	series = {{FAccT} '23},
	title = {Algorithmic {Decisions}, {Desire} for {Control}, and the {Preference} for {Human} {Review} over {Algorithmic} {Review}},
	isbn = {9798400701924},
	url = {https://doi.org/10.1145/3593013.3594041},
	doi = {10.1145/3593013.3594041},
	abstract = {In this paper, we explore why decision subjects generally express a preference for human reviewers of algorithmic decisions over algorithmic reviewers. We theorise that decision subjects desire control over the decision-making process in order to increase their chance of receiving a favourable outcome. To this end, human reviewers will be seen as easier to influence than algorithmic reviewers, thus providing more control. Using an online study we find that: (1) people who have a greater Desire for Control over their lives exhibit a stronger preference for human review; (2) interaction with a reviewer is important because it enables influence and ensures understanding; and (3) the higher the impact of a decision, the greater the incentive to influence the outcome, and the greater the preference for human review. Our qualitative results confirm that outcome favourability is a driver for reviewer preference, but so is the desire to be treated with dignity.},
	urldate = {2023-11-11},
	booktitle = {Proceedings of the 2023 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Lyons, Henrietta and Miller, Tim and Velloso, Eduardo},
	month = jun,
	year = {2023},
	keywords = {accountability, algorithmic decision-making, algorithmic fairness, and transparency, contestability, reviewability},
	pages = {764--774},
}

@article{BriefSurveyTextMining,
	title = {A {Brief} {Survey} of {Text} {Mining}: {Classification}, {Clustering} and {Extraction} {Techniques}},
	shorttitle = {A {Brief} {Survey} of {Text} {Mining}},
	url = {http://arxiv.org/abs/1707.02919},
	abstract = {The amount of text that is generated every day is increasing dramatically. This tremendous volume of mostly unstructured text cannot be simply processed and perceived by computers. Therefore, efficient and effective techniques and algorithms are required to discover useful patterns. Text mining is the task of extracting meaningful information from text, which has gained significant attentions in recent years. In this paper, we describe several of the most fundamental text mining tasks and techniques including text pre-processing, classification and clustering. Additionally, we briefly explain text mining in biomedical and health care domains.},
	language = {en},
	urldate = {2019-12-28},
	journal = {arXiv:1707.02919 [cs]},
	author = {Allahyari, Mehdi and Pouriyeh, Seyedamin and Assefi, Mehdi and Safaei, Saied and Trippe, Elizabeth D. and Gutierrez, Juan B. and Kochut, Krys},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.02919},
	keywords = {dm, survey},
}

@article{SurveyHallucinationNaturalLanguageGeneration,
	title = {Survey of {Hallucination} in {Natural} {Language} {Generation}},
	issn = {0360-0300, 1557-7341},
	url = {http://arxiv.org/abs/2202.03629},
	doi = {10.1145/3571730},
	abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before. In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions; and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, machine translation, and visual-language generation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
	urldate = {2023-02-26},
	journal = {ACM Computing Surveys},
	author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Yejin and Dai, Wenliang and Madotto, Andrea and Fung, Pascale},
	month = nov,
	year = {2022},
	note = {arXiv:2202.03629 [cs]},
	keywords = {Computer Science - Computation and Language, llm, nlp},
	pages = {3571730},
}

@misc{FeaturesExplainabilityHowusersunderstand,
	title = {Features of {Explainability}: {How} users understand counterfactual and causal explanations for categorical and continuous features in {XAI}},
	shorttitle = {Features of {Explainability}},
	url = {http://arxiv.org/abs/2204.10152},
	abstract = {Counterfactual explanations are increasingly used to address interpretability, recourse, and bias in AI decisions. However, we do not know how well counterfactual explanations help users to understand a systems decisions, since no large scale user studies have compared their efficacy to other sorts of explanations such as causal explanations (which have a longer track record of use in rule based and decision tree models). It is also unknown whether counterfactual explanations are equally effective for categorical as for continuous features, although current methods assume they do. Hence, in a controlled user study with 127 volunteer participants, we tested the effects of counterfactual and causal explanations on the objective accuracy of users predictions of the decisions made by a simple AI system, and participants subjective judgments of satisfaction and trust in the explanations. We discovered a dissociation between objective and subjective measures: counterfactual explanations elicit higher accuracy of predictions than no-explanation control descriptions but no higher accuracy than causal explanations, yet counterfactual explanations elicit greater satisfaction and trust than causal explanations. We also found that users understand explanations referring to categorical features more readily than those referring to continuous features. We discuss the implications of these findings for current and future counterfactual methods in XAI.},
	urldate = {2023-02-17},
	publisher = {arXiv},
	author = {Warren, Greta and Keane, Mark T. and Byrne, Ruth M. J.},
	month = apr,
	year = {2022},
	note = {arXiv:2204.10152 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, exp},
}

@article{ExplanationMethodsDeepLearninga,
	title = {Explanation {Methods} in {Deep} {Learning}: {Users}, {Values}, {Concerns} and {Challenges}},
	shorttitle = {Explanation {Methods} in {Deep} {Learning}},
	url = {http://arxiv.org/abs/1803.07517},
	abstract = {Issues regarding explainable AI involve four components: users, laws \& regulations, explanations and algorithms. Together these components provide a context in which explanation methods can be evaluated regarding their adequacy. The goal of this chapter is to bridge the gap between expert users and lay users. Diﬀerent kinds of users are identiﬁed and their concerns revealed, relevant statements from the General Data Protection Regulation are analyzed in the context of Deep Neural Networks (DNNs), a taxonomy for the classiﬁcation of existing explanation methods is introduced, and ﬁnally, the various classes of explanation methods are analyzed to verify if user concerns are justiﬁed. Overall, it is clear that (visual) explanations can be given about various aspects of the inﬂuence of the input on the output. However, it is noted that explanation methods or interfaces for lay users are missing and we speculate which criteria these methods / interfaces should satisfy. Finally it is noted that two important concerns are diﬃcult to address with explanation methods: the concern about bias in datasets that leads to biased DNNs, as well as the suspicion about unfair outcomes.},
	language = {en},
	urldate = {2019-05-23},
	journal = {arXiv:1803.07517 [cs, stat]},
	author = {Ras, Gabrielle and van Gerven, Marcel and Haselager, Pim},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.07517},
	keywords = {Statistics - Machine Learning},
}

@misc{EfficientDataRepresentationSelectingPrototypes,
	title = {Efficient {Data} {Representation} by {Selecting} {Prototypes} with {Importance} {Weights}},
	url = {http://arxiv.org/abs/1707.01212},
	abstract = {In this paper we propose an eﬃcient algorithm ProtoDash for selecting prototypical examples from complex datasets. Our work builds on top of the learn to criticize (L2C) work by [12] and generalizes it to not only select prototypes for a given sparsity level m but also to associate nonnegative weights with each of them indicative of the importance of each prototype. Unlike in the case of L2C, this extension provides a single coherent framework under which both prototypes and criticisms (i.e. lowest weighted prototypes) can be found. Furthermore, our framework works for any symmetric positive deﬁnite kernel thus addressing one of the open questions laid out in [12]. Our additional requirement of learning non-negative weights introduces technical challenges as the objective is no longer submodular as in the previous work. However, we show that the problem is weakly submodular and derive approximation guarantees for our fast ProtoDash algorithm. Moreover, ProtoDash can not only ﬁnd prototypical examples for a dataset X, but it can also ﬁnd (weighted) prototypical examples from X(2) that best represent another dataset X(1), where X(1) and X(2) belong to the same feature space. We demonstrate the efﬁcacy of our method on diverse domains namely; retail, digit recognition (MNIST) and on the latest publicly available 40 health questionnaires obtained from the Center for Disease Control (CDC) website maintained by the US Dept. of Health. We validate the results quantitatively as well as qualitatively based on expert feedback and recently published scientiﬁc studies on public health.},
	language = {en},
	urldate = {2022-10-18},
	publisher = {arXiv},
	author = {Gurumoorthy, Karthik S. and Dhurandhar, Amit and Cecchi, Guillermo and Aggarwal, Charu},
	month = aug,
	year = {2019},
	note = {arXiv:1707.01212 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{DesignPatternsTradeOffsResponsiveVisualization,
	title = {Design {Patterns} and {Trade}-{Offs} in {Responsive} {Visualization} for {Communication}},
	volume = {40},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14321},
	doi = {10.1111/cgf.14321},
	abstract = {Increased access to mobile devices motivates the need to design communicative visualizations that are responsive to varying screen sizes. However, relatively little design guidance or tooling is currently available to authors. We contribute a detailed characterization of responsive visualization strategies in communication-oriented visualizations, identifying 76 total strategies by analyzing 378 pairs of large screen (LS) and small screen (SS) visualizations from online articles and reports. Our analysis distinguishes between the Targets of responsive visualization, referring to what elements of a design are changed and Actions representing how targets are changed. We identify key trade-offs related to authors' need to maintain graphical density, referring to the amount of information per pixel, while also maintaining the “message” or intended takeaways for users of a visualization. We discuss implications of our findings for future visualization tool design to support responsive transformation of visualization designs, including requirements for automated recommenders for communication-oriented responsive visualizations.},
	language = {en},
	number = {3},
	urldate = {2023-08-14},
	journal = {Computer Graphics Forum},
	author = {Kim, Hyeok and Moritz, Dominik and Hullman, Jessica},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14321},
	keywords = {CCS Concepts, Visualization design and evaluation methods, vis},
	pages = {459--470},
}

@article{raza_news_2022,
	title = {News recommender system: a review of recent progress, challenges, and opportunities},
	volume = {55},
	issn = {0269-2821, 1573-7462},
	shorttitle = {News recommender system},
	url = {https://link.springer.com/10.1007/s10462-021-10043-x},
	doi = {10.1007/s10462-021-10043-x},
	abstract = {Nowadays, more and more news readers read news online where they have access to millions of news articles from multiple sources. In order to help users find the right and relevant content, news recommender systems (NRS) are developed to relieve the information overload problem and suggest news items that might be of interest for the news readers. In this paper, we highlight the major challenges faced by the NRS and identify the possible solutions from the state-of-the-art. Our discussion is divided into two parts. In the first part, we present an overview of the recommendation solutions, datasets, evaluation criteria beyond accuracy and recommendation platforms being used in the NRS. We also talk about two popular classes of models that have been successfully used in recent years. In the second part, we focus on the deep neural networks as solutions to build the NRS. Different from previous surveys, we study the effects of news recommendations on user behaviors and try to suggest possible remedies to mitigate those effects. By providing the state-ofthe-art knowledge, this survey can help researchers and professional practitioners have a better understanding of the recent developments in news recommendation algorithms. In addition, this survey sheds light on the potential new directions.},
	language = {en},
	number = {1},
	urldate = {2023-11-03},
	journal = {Artificial Intelligence Review},
	author = {Raza, Shaina and Ding, Chen},
	month = jan,
	year = {2022},
	keywords = {news},
	pages = {749--800},
}

@misc{InvolvingEndusersInteractiveHumanintheloopAI,
	title = {Towards {Involving} {End}-users in {Interactive} {Human}-in-the-loop {AI} {Fairness}},
	url = {http://arxiv.org/abs/2204.10464},
	abstract = {Ensuring fairness in artificial intelligence (AI) is important to counteract bias and discrimination in far-reaching applications. Recent work has started to investigate how humans judge fairness and how to support machine learning (ML) experts in making their AI models fairer. Drawing inspiration from an Explainable AI (XAI) approach called {\textbackslash}emph\{explanatory debugging\} used in interactive machine learning, our work explores designing interpretable and interactive human-in-the-loop interfaces that allow ordinary end-users without any technical or domain background to identify potential fairness issues and possibly fix them in the context of loan decisions. Through workshops with end-users, we co-designed and implemented a prototype system that allowed end-users to see why predictions were made, and then to change weights on features to "debug" fairness issues. We evaluated the use of this prototype system through an online study. To investigate the implications of diverse human values about fairness around the globe, we also explored how cultural dimensions might play a role in using this prototype. Our results contribute to the design of interfaces to allow end-users to be involved in judging and addressing AI fairness through a human-in-the-loop approach.},
	urldate = {2022-10-11},
	publisher = {arXiv},
	author = {Nakao, Yuri and Stumpf, Simone and Ahmed, Subeida and Naseer, Aisha and Strappelli, Lorenzo},
	month = apr,
	year = {2022},
	note = {arXiv:2204.10464 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, codesign, fair, hci, vis},
}

@article{van_den_bogaert_putting_2022,
	title = {Putting a {Human} {Face} on the {Algorithm}: {Co}-{Designing} {Recommender} {Personae} to {Democratize} {News} {Recommender} {Systems}},
	issn = {2167-0811, 2167-082X},
	shorttitle = {Putting a {Human} {Face} on the {Algorithm}},
	url = {https://www.tandfonline.com/doi/full/10.1080/21670811.2022.2097101},
	doi = {10.1080/21670811.2022.2097101},
	language = {en},
	urldate = {2023-10-09},
	journal = {Digital Journalism},
	author = {Van Den Bogaert, Lawrence and Geerts, David and Harambam, Jaron},
	month = jul,
	year = {2022},
	keywords = {codesign, rec},
	pages = {1--21},
}

@inproceedings{sonboli_fairness_2021,
	address = {Utrecht Netherlands},
	title = {Fairness and {Transparency} in {Recommendation}: {The} {Users}’ {Perspective}},
	isbn = {978-1-4503-8366-0},
	shorttitle = {Fairness and {Transparency} in {Recommendation}},
	url = {https://dl.acm.org/doi/10.1145/3450613.3456835},
	doi = {10.1145/3450613.3456835},
	language = {en},
	urldate = {2023-10-09},
	booktitle = {Proceedings of the 29th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Sonboli, Nasim and Smith, Jessie J. and Cabral Berenfus, Florencia and Burke, Robin and Fiesler, Casey},
	month = jun,
	year = {2021},
	keywords = {codesign},
	pages = {274--279},
}

@inproceedings{caraban_23_2019,
	address = {Glasgow Scotland Uk},
	title = {23 {Ways} to {Nudge}: {A} {Review} of {Technology}-{Mediated} {Nudging} in {Human}-{Computer} {Interaction}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {23 {Ways} to {Nudge}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300733},
	doi = {10.1145/3290605.3300733},
	language = {en},
	urldate = {2023-10-07},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Caraban, Ana and Karapanos, Evangelos and Gonçalves, Daniel and Campos, Pedro},
	month = may,
	year = {2019},
	pages = {1--15},
}

@inproceedings{ImprovingUserExperienceColdStart,
	address = {Vienna Austria},
	title = {Improving the {User} {Experience} during {Cold} {Start} through {Choice}-{Based} {Preference} {Elicitation}},
	isbn = {978-1-4503-3692-5},
	url = {https://dl.acm.org/doi/10.1145/2792838.2799681},
	doi = {10.1145/2792838.2799681},
	abstract = {We studied an alternative choice-based interface for preference elicitation during the cold start phase and compared it directly with a standard rating-based interface. In this alternative interface users started from a diverse set covering all movies and iteratively narrowed down through a matrix factorization latent feature space to smaller sets of items based on their choices. The results show that compared to a rating-based interface, the choice-based interface requires less effort and results in more satisfying recommendations, showing that it might be a promising candidate for alleviating the cold start problem of new users.},
	language = {en},
	urldate = {2023-10-04},
	booktitle = {Proceedings of the 9th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Graus, Mark P. and Willemsen, Martijn C.},
	month = sep,
	year = {2015},
	keywords = {cold-start},
	pages = {273--276},
}

@inproceedings{SemiPersonalizedSystemUserColdStarta,
	address = {Virtual Event Singapore},
	title = {A {Semi}-{Personalized} {System} for {User} {Cold} {Start} {Recommendation} on {Music} {Streaming} {Apps}},
	isbn = {978-1-4503-8332-5},
	url = {https://dl.acm.org/doi/10.1145/3447548.3467110},
	doi = {10.1145/3447548.3467110},
	abstract = {Music streaming services heavily rely on recommender systems to improve their users’ experience, by helping them navigate through a large musical catalog and discover new songs, albums or artists. However, recommending relevant and personalized content to new users, with few to no interactions with the catalog, is challenging. This is commonly referred to as the user cold start problem. In this applied paper, we present the system recently deployed on the music streaming service Deezer to address this problem. The solution leverages a semi-personalized recommendation strategy, based on a deep neural network architecture and on a clustering of users from heterogeneous sources of information. We extensively show the practical impact of this system and its effectiveness at predicting the future musical preferences of cold start users on Deezer, through both offline and online large-scale experiments. Besides, we publicly release our code as well as anonymized usage data from our experiments. We hope that this release of industrial resources will benefit future research on user cold start recommendation.},
	language = {en},
	urldate = {2023-10-04},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Briand, Léa and Salha-Galvan, Guillaume and Bendada, Walid and Morlon, Mathieu and Tran, Viet-Anh},
	month = aug,
	year = {2021},
	keywords = {cold-start},
	pages = {2601--2609},
}

@article{psychologyawarepreferenceconstructionrecommendersystems,
	title = {Towards psychology-aware preference construction in recommender systems: {Overview} and research issues},
	volume = {57},
	issn = {0925-9902, 1573-7675},
	shorttitle = {Towards psychology-aware preference construction in recommender systems},
	url = {https://link.springer.com/10.1007/s10844-021-00674-5},
	doi = {10.1007/s10844-021-00674-5},
	abstract = {User preferences are a crucial input needed by recommender systems to determine relevant items. In single-shot recommendation scenarios such as content-based filtering and collaborative filtering, user preferences are represented, for example, as keywords, categories, and item ratings. In conversational recommendation approaches such as constraint-based and critiquing-based recommendation, user preferences are often represented on the semantic level in terms of item attribute values and critiques. In this article, we provide an overview of preference representations used in different types of recommender systems. In this context, we take into account the fact that preferences aren’t stable but are rather constructed within the scope of a recommendation process. In which way preferences are determined and adapted is influenced by various factors such as personality traits, emotional states, and cognitive biases. We summarize preference construction related research and also discuss aspects of counteracting cognitive biases.},
	language = {en},
	number = {3},
	urldate = {2023-10-04},
	journal = {Journal of Intelligent Information Systems},
	author = {Atas, Müslüm and Felfernig, Alexander and Polat-Erdeniz, Seda and Popescu, Andrei and Tran, Thi Ngoc Trang and Uta, Mathias},
	month = dec,
	year = {2021},
	keywords = {cold-start},
	pages = {467--489},
}

@inproceedings{briand_semi-personalized_2021,
	address = {Virtual Event Singapore},
	title = {A {Semi}-{Personalized} {System} for {User} {Cold} {Start} {Recommendation} on {Music} {Streaming} {Apps}},
	isbn = {978-1-4503-8332-5},
	url = {https://dl.acm.org/doi/10.1145/3447548.3467110},
	doi = {10.1145/3447548.3467110},
	language = {en},
	urldate = {2023-10-04},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Briand, Léa and Salha-Galvan, Guillaume and Bendada, Walid and Morlon, Mathieu and Tran, Viet-Anh},
	month = aug,
	year = {2021},
	pages = {2601--2609},
}

@misc{arawjo_chainforge_2023,
	title = {{ChainForge}: {A} {Visual} {Toolkit} for {Prompt} {Engineering} and {LLM} {Hypothesis} {Testing}},
	shorttitle = {{ChainForge}},
	url = {http://arxiv.org/abs/2309.09128},
	abstract = {Evaluating outputs of large language models (LLMs) is challenging, requiring making -- and making sense of -- many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.},
	urldate = {2023-09-23},
	publisher = {arXiv},
	author = {Arawjo, Ian and Swoopes, Chelse and Vaithilingam, Priyan and Wattenberg, Martin and Glassman, Elena},
	month = sep,
	year = {2023},
	note = {arXiv:2309.09128 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, H.5.2, I.2, generative, llm, vis},
}

@misc{wang_aligning_2023,
	title = {Aligning {Large} {Language} {Models} with {Human}: {A} {Survey}},
	shorttitle = {Aligning {Large} {Language} {Models} with {Human}},
	url = {http://arxiv.org/abs/2307.12966},
	abstract = {Large Language Models (LLMs) trained on extensive textual corpora have emerged as leading solutions for a broad array of Natural Language Processing (NLP) tasks. Despite their notable performance, these models are prone to certain limitations such as misunderstanding human instructions, generating potentially biased content, or factually incorrect (hallucinated) information. Hence, aligning LLMs with human expectations has become an active area of interest within the research community. This survey presents a comprehensive overview of these alignment technologies, including the following aspects. (1) Data collection: the methods for effectively collecting high-quality instructions for LLM alignment, including the use of NLP benchmarks, human annotations, and leveraging strong LLMs. (2) Training methodologies: a detailed review of the prevailing training methods employed for LLM alignment. Our exploration encompasses Supervised Fine-tuning, both Online and Offline human preference training, along with parameter-efficient training mechanisms. (3) Model Evaluation: the methods for evaluating the effectiveness of these human-aligned LLMs, presenting a multifaceted approach towards their assessment. In conclusion, we collate and distill our findings, shedding light on several promising future research avenues in the field. This survey, therefore, serves as a valuable resource for anyone invested in understanding and advancing the alignment of LLMs to better suit human-oriented tasks and expectations. An associated GitHub link collecting the latest papers is available at https://github.com/GaryYufei/AlignLLMHumanSurvey.},
	urldate = {2023-09-23},
	publisher = {arXiv},
	author = {Wang, Yufei and Zhong, Wanjun and Li, Liangyou and Mi, Fei and Zeng, Xingshan and Huang, Wenyong and Shang, Lifeng and Jiang, Xin and Liu, Qun},
	month = jul,
	year = {2023},
	note = {arXiv:2307.12966 [cs]},
	keywords = {Computer Science - Computation and Language, generative, hci, llm, survey},
}

@inproceedings{zamfirescu-pereira_why_2023,
	address = {Hamburg Germany},
	title = {Why {Johnny} {Can}’t {Prompt}: {How} {Non}-{AI} {Experts} {Try} (and {Fail}) to {Design} {LLM} {Prompts}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {Why {Johnny} {Can}’t {Prompt}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581388},
	doi = {10.1145/3544548.3581388},
	language = {en},
	urldate = {2023-09-23},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
	month = apr,
	year = {2023},
	keywords = {generative, hci, llm},
	pages = {1--21},
}

@misc{ceneda_heuristic_2023,
	title = {A {Heuristic} {Approach} for {Dual} {Expert}/{End}-{User} {Evaluation} of {Guidance} in {Visual} {Analytics}},
	url = {http://arxiv.org/abs/2308.13052},
	abstract = {Guidance can support users during the exploration and analysis of complex data. Previous research focused on characterizing the theoretical aspects of guidance in visual analytics and implementing guidance in different scenarios. However, the evaluation of guidance-enhanced visual analytics solutions remains an open research question. We tackle this question by introducing and validating a practical evaluation methodology for guidance in visual analytics. We identify eight quality criteria to be fulfilled and collect expert feedback on their validity. To facilitate actual evaluation studies, we derive two sets of heuristics. The first set targets heuristic evaluations conducted by expert evaluators. The second set facilitates end-user studies where participants actually use a guidance-enhanced system. By following such a dual approach, the different quality criteria of guidance can be examined from two different perspectives, enhancing the overall value of evaluation studies. To test the practical utility of our methodology, we employ it in two studies to gain insight into the quality of two guidance-enhanced visual analytics solutions, one being a work-in-progress research prototype, and the other being a publicly available visualization recommender system. Based on these two evaluations, we derive good practices for conducting evaluations of guidance in visual analytics and identify pitfalls to be avoided during such studies.},
	urldate = {2023-09-23},
	publisher = {arXiv},
	author = {Ceneda, Davide and Collins, Christopher and El-Assady, Mennatallah and Miksch, Silvia and Tominski, Christian and Arleo, Alessio},
	month = aug,
	year = {2023},
	note = {arXiv:2308.13052 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, eval, vis},
}

@misc{hou_large_2023,
	title = {Large {Language} {Models} are {Zero}-{Shot} {Rankers} for {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2305.08845},
	abstract = {Recently, large language models (LLMs) (e.g. GPT-4) have demonstrated impressive general-purpose task-solving abilities, including the potential to approach recommendation tasks. Along this line of research, this work aims to investigate the capacity of LLMs that act as the ranking model for recommender systems. To conduct our empirical study, we first formalize the recommendation problem as a conditional ranking task, considering sequential interaction histories as conditions and the items retrieved by the candidate generation model as candidates. We adopt a specific prompting approach to solving the ranking task by LLMs: we carefully design the prompting template by including the sequential interaction history, the candidate items, and the ranking instruction. We conduct extensive experiments on two widely-used datasets for recommender systems and derive several key findings for the use of LLMs in recommender systems. We show that LLMs have promising zero-shot ranking abilities, even competitive to or better than conventional recommendation models on candidates retrieved by multiple candidate generators. We also demonstrate that LLMs struggle to perceive the order of historical interactions and can be affected by biases like position bias, while these issues can be alleviated via specially designed prompting and bootstrapping strategies. The code to reproduce this work is available at https://github.com/RUCAIBox/LLMRank.},
	urldate = {2023-09-23},
	publisher = {arXiv},
	author = {Hou, Yupeng and Zhang, Junjie and Lin, Zihan and Lu, Hongyu and Xie, Ruobing and McAuley, Julian and Zhao, Wayne Xin},
	month = may,
	year = {2023},
	note = {arXiv:2305.08845 [cs]},
	keywords = {llm, rec},
}

@misc{StudyFairnessTrustPerceptionsAutomated,
	title = {A {Study} on {Fairness} and {Trust} {Perceptions} in {Automated} {Decision} {Making}},
	url = {http://arxiv.org/abs/2103.04757},
	abstract = {Automated decision systems are increasingly used for consequential decision making -- for a variety of reasons. These systems often rely on sophisticated yet opaque models, which do not (or hardly) allow for understanding how or why a given decision was arrived at. This is not only problematic from a legal perspective, but non-transparent systems are also prone to yield undesirable (e.g., unfair) outcomes because their sanity is difficult to assess and calibrate in the first place. In this work, we conduct a study to evaluate different attempts of explaining such systems with respect to their effect on people's perceptions of fairness and trustworthiness towards the underlying mechanisms. A pilot study revealed surprising qualitative insights as well as preliminary significant effects, which will have to be verified, extended and thoroughly discussed in the larger main study.},
	urldate = {2023-09-11},
	publisher = {arXiv},
	author = {Schoeffer, Jakob and Machowski, Yvette and Kuehl, Niklas},
	month = mar,
	year = {2021},
	note = {arXiv:2103.04757 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, explanation, fair},
}

@inproceedings{CALVICriticalThinkingAssessmentLiteracy,
	address = {Hamburg Germany},
	title = {{CALVI}: {Critical} {Thinking} {Assessment} for {Literacy} in {Visualizations}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {{CALVI}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581406},
	doi = {10.1145/3544548.3581406},
	language = {en},
	urldate = {2023-09-11},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ge, Lily W. and Cui, Yuan and Kay, Matthew},
	month = apr,
	year = {2023},
	keywords = {literacy, vis},
	pages = {1--18},
}

@article{ConceptualisingContestabilityPerspectivesContestingAlgorithmic,
	title = {Conceptualising {Contestability}: {Perspectives} on {Contesting} {Algorithmic} {Decisions}},
	volume = {5},
	issn = {2573-0142},
	shorttitle = {Conceptualising {Contestability}},
	url = {http://arxiv.org/abs/2103.01774},
	doi = {10.1145/3449180},
	abstract = {As the use of algorithmic systems in high-stakes decision-making increases, the ability to contest algorithmic decisions is being recognised as an important safeguard for individuals. Yet, there is little guidance on what `contestability'--the ability to contest decisions--in relation to algorithmic decision-making requires. Recent research presents different conceptualisations of contestability in algorithmic decision-making. We contribute to this growing body of work by describing and analysing the perspectives of people and organisations who made submissions in response to Australia's proposed `AI Ethics Framework', the first framework of its kind to include `contestability' as a core ethical principle. Our findings reveal that while the nature of contestability is disputed, it is seen as a way to protect individuals, and it resembles contestability in relation to human decision-making. We reflect on and discuss the implications of these findings.},
	number = {CSCW1},
	urldate = {2023-09-15},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lyons, Henrietta and Velloso, Eduardo and Miller, Tim},
	month = apr,
	year = {2021},
	note = {arXiv:2103.01774 [cs]},
	keywords = {Computer Science - Computers and Society, contestability, fair, fatml},
	pages = {1--25},
}

@inproceedings{BreakingFilterBubbleReinforcementLearning,
	address = {Austin TX USA},
	title = {Breaking {Filter} {Bubble}: {A} {Reinforcement} {Learning} {Framework} of {Controllable} {Recommender} {System}},
	isbn = {978-1-4503-9416-1},
	shorttitle = {Breaking {Filter} {Bubble}},
	url = {https://dl.acm.org/doi/10.1145/3543507.3583856},
	doi = {10.1145/3543507.3583856},
	language = {en},
	urldate = {2023-09-11},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2023},
	publisher = {ACM},
	author = {Li, Zhenyang and Dong, Yancheng and Gao, Chen and Zhao, Yizhou and Li, Dong and Hao, Jianye and Zhang, Kai and Li, Yong and Wang, Zhi},
	month = apr,
	year = {2023},
	keywords = {filter-bubble, rec},
	pages = {4041--4049},
}

@inproceedings{WhyAmNotSeeingItb,
	address = {Seoul Republic of Korea},
	title = {Why {Am} {I} {Not} {Seeing} {It}? {Understanding} {Users}’ {Needs} for {Counterfactual} {Explanations} in {Everyday} {Recommendations}},
	isbn = {978-1-4503-9352-2},
	shorttitle = {Why {Am} {I} {Not} {Seeing} {It}?},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533189},
	doi = {10.1145/3531146.3533189},
	language = {en},
	urldate = {2023-09-11},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Shang, Ruoxi and Feng, K. J. Kevin and Shah, Chirag},
	month = jun,
	year = {2022},
	keywords = {counterfactual, explanation},
	pages = {1330--1340},
}

@article{BiasFriendFoeUserAcceptance,
	title = {Bias: {Friend} or {Foe}? {User} {Acceptance} of {Gender} {Stereotypes} in {Automated} {Career} {Recommendations}},
	abstract = {Currently, there is a surge of interest in fair Artiﬁcial Intelligence (AI) and Machine Learning (ML) research which aims to mitigate discriminatory bias in AI algorithms, e.g. along lines of gender, age, and race. While most research in this domain focuses on developing fair AI algorithms, in this work, we show that a fair AI algorithm on its own may be insufﬁcient to achieve its intended results in the real world. Using career recommendation as a case study, we build a fair AI career recommender by employing gender debiasing machine learning techniques. Our ofﬂine evaluation showed that the debiased recommender makes fairer career recommendations without sacriﬁcing its accuracy. Nevertheless, an online user study of more than 200 college students revealed that participants on average prefer the original biased system over the debiased system. Speciﬁcally, we found that perceived gender disparity is a determining factor for the acceptance of a recommendation. In other words, our results demonstrate we cannot fully address the gender bias issue in AI recommendations without addressing the gender bias in humans.},
	language = {en},
	author = {Wang, Clarice and Wang, Kathryn and Bian, Andrew and Islam, Rashidul and Keya, Kamrun Naher and Pan, Shimei},
	keywords = {fair, perception, rec, stereotype},
}

@inproceedings{EffectInformationPresentationFairnessPerceptions,
	address = {Yokohama Japan},
	title = {Effect of {Information} {Presentation} on {Fairness} {Perceptions} of {Machine} {Learning} {Predictors}},
	isbn = {978-1-4503-8096-6},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445365},
	doi = {10.1145/3411764.3445365},
	language = {en},
	urldate = {2023-09-15},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Van Berkel, Niels and Goncalves, Jorge and Russo, Daniel and Hosio, Simo and Skov, Mikael B.},
	month = may,
	year = {2021},
	keywords = {explanation, fair},
	pages = {1--13},
}

@article{SurveyBiasFairnessMachine,
	title = {A {Survey} on {Bias} and {Fairness} in {Machine} {Learning}},
	url = {http://arxiv.org/abs/1908.09635},
	abstract = {With the widespread use of AI systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in machine learning, natural language processing, and deep learning that addresses such challenges in different subdomains. With the commercialization of these systems, researchers are becoming aware of the biases that these applications can contain and have attempted to address them. In this survey we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined in order to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and how they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
	urldate = {2020-01-16},
	journal = {arXiv:1908.09635 [cs]},
	author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
	month = sep,
	year = {2019},
	note = {arXiv: 1908.09635},
	keywords = {comps-dm, fair, fatml, survey, xai},
}

@techreport{ItReducingHumanBeing,
	type = {preprint},
	title = {'{It}'s {Reducing} a {Human} {Being} to a {Percentage}'; {Perceptions} of {Justice} in {Algorithmic} {Decisions}},
	url = {https://osf.io/9wqxr},
	abstract = {Data-driven decision-making consequential to individuals raises important questions of accountability and justice. Indeed, European law provides individuals limited rights to ‘meaningful information about the logic’ behind significant, autonomous decisions such as loan approvals, insurance quotes, and CV filtering. We undertake three experimental studies examining people’s perceptions of justice in algorithmic decision-making under different scenarios and explanation styles. Dimensions of justice previously observed in response to human decision-making appear similarly engaged in response to algorithmic decisions. Qualitative analysis identified several concerns and heuristics involved in justice perceptions including arbitrariness, generalisation, and (in)dignity. Quantitative analysis indicates that explanation styles primarily matter to justice perceptions only when subjects are exposed to multiple different styles—under repeated exposure of one style, scenario effects obscure any explanation effects. Our results suggests there may be no ‘best’ approach to explaining algorithmic decisions, and that reflection on their automated nature both implicates and mitigates justice dimensions.},
	language = {en},
	urldate = {2020-11-05},
	institution = {SocArXiv},
	author = {Binns, Reuben and Van Kleek, Max and Veale, Michael and Lyngs, Ulrik and Zhao, Jun and Shadbolt, Nigel},
	month = jan,
	year = {2018},
	doi = {10.31235/osf.io/9wqxr},
	keywords = {explanation, fair, fatml},
}

@misc{WhenElectronicRecommendationAgentsBackfire,
	title = {When {Electronic} {Recommendation} {Agents} {Backfire}: {Negative} {Effects} on {Choice} {Satisfaction}, {Attitudes}, and {Purchase} {Intentions}: (621072012-030)},
	shorttitle = {When {Electronic} {Recommendation} {Agents} {Backfire}},
	url = {http://doi.apa.org/get-pe-doi.cfm?doi=10.1037/e621072012-030},
	doi = {10.1037/e621072012-030},
	abstract = {Many websites provide electronic recommendation agents that ask users questions about individual factors and their preferences for product attributes, and then rate and rank order the available products. Previous research has hailed these agents as rescuing consumers from choice overload. However, we report the results of an experiment in which use of an electronic recommendation agent negatively impacted participants’ choice satisfaction, attitudes, and purchase intentions over a period of between one and two weeks. The data support our hypothesis that use of an electronic recommendation agent leads consumers to overweight utilitarian product attributes and underweight hedonic product attributes in choice.},
	language = {en},
	urldate = {2021-06-29},
	publisher = {American Psychological Association},
	author = {Lajos, Joseph and Chattopadhyay, Amitava and Sengupta, Kishore},
	year = {2010},
}

@misc{PriceFairnessLocationBasedAdvertising,
	title = {The {Price} of {Fairness} in {Location} {Based} {Advertising}},
	url = {http://scholarworks.boisestate.edu/fatrec/2017/1/5},
	doi = {10.18122/B2MD8C},
	abstract = {Firms use massive amounts of personal data to decide which advertisements to show to an individual, raising concerns of fairness and algorithmic bias. Previous work has proposed techniques to make machine learning more fair through awareness of the protected attributes of user data. However, these studies have either focused on specific tasks, been primarily theoretical, or have ignored the highly important domain of location-based advertising.},
	language = {en},
	urldate = {2019-03-07},
	publisher = {Boise State University},
	author = {Riederer, Christopher and Chaintreau, Augustin},
	keywords = {fair, fatml},
}

@misc{BalancedNeighborhoodsFairnessAwareCollaborativeRecommendation,
	title = {Balanced {Neighborhoods} for {Fairness}-{Aware} {Collaborative} {Recommendation}},
	url = {http://scholarworks.boisestate.edu/fatrec/2017/1/3},
	doi = {10.18122/B2GQ53},
	abstract = {Recent work on fairness in machine learning has begun to be extended to recommender systems. While there is a tension between the goals of fairness and of personalization, there are contexts in which a global evaluations of outcomes is possible and where equity across such outcomes is a desirable goal. In this paper, we introduce the concept of a balanced neighborhood as a mechanism to preserve personalization in recommendation while enhancing the fairness of recommendation outcomes. We show that a modified version of the SLIM algorithm can be used to improve the balance of user neighborhoods, with the result of achieving greater outcome fairness in a real-world dataset with minimal loss in ranking performance.},
	language = {en},
	urldate = {2019-03-07},
	publisher = {Boise State University},
	author = {Burke, Robin and Sonboli, Nasim and Mansoury, Masoud and Ordonez-Gauger, Aldo},
	keywords = {fair, fatml},
}

@misc{SurveyFairnessRecommenderSystems,
	title = {A {Survey} on the {Fairness} of {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2206.03761},
	abstract = {Recommender systems are an essential tool to relieve the information overload challenge and play an important role in people's daily lives. Since recommendations involve allocations of social resources (e.g., job recommendation), an important issue is whether recommendations are fair. Unfair recommendations are not only unethical but also harm the long-term interests of the recommender system itself. As a result, fairness issues in recommender systems have recently attracted increasing attention. However, due to multiple complex resource allocation processes and various fairness definitions, the research on fairness in recommendation is scattered. To fill this gap, we review over 60 papers published in top conferences/journals, including TOIS, SIGIR, and WWW. First, we summarize fairness definitions in the recommendation and provide several views to classify fairness issues. Then, we review recommendation datasets and measurements in fairness studies and provide an elaborate taxonomy of fairness methods in the recommendation. Finally, we conclude this survey by outlining some promising future directions.},
	urldate = {2022-07-02},
	publisher = {arXiv},
	author = {Wang, Yifan and Ma, Weizhi and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
	month = jun,
	year = {2022},
	note = {arXiv:2206.03761 [cs]},
	keywords = {Computer Science - Information Retrieval},
}

@misc{ConceptExplainerUnderstandingMentalModelDeep,
	title = {{ConceptExplainer}: {Understanding} the {Mental} {Model} of {Deep} {Learning} {Algorithms} via {Interactive} {Concept}-based {Explanations}},
	shorttitle = {{ConceptExplainer}},
	url = {http://arxiv.org/abs/2204.01888},
	abstract = {Traditional deep learning interpretability methods which are suitable for non-expert users cannot explain network behaviors at the global level and are inflexible at providing fine-grained explanations. As a solution, concept-based explanations are gaining attention due to their human intuitiveness and their flexibility to describe both global and local model behaviors. Concepts are groups of similarly meaningful pixels that express a notion, embedded within the network's latent space and have primarily been hand-generated, but have recently been discovered by automated approaches. Unfortunately, the magnitude and diversity of discovered concepts makes it difficult for non-experts to navigate and make sense of the concept space, and lack of easy-to-use software also makes concept explanations inaccessible to many non-expert users. Visual analytics can serve a valuable role in bridging these gaps by enabling structured navigation and exploration of the concept space to provide concept-based insights of model behavior to users. To this end, we design, develop, and validate ConceptExplainer, a visual analytics system that enables non-expert users to interactively probe and explore the concept space to explain model behavior at the instance/class/global level. The system was developed via iterative prototyping to address a number of design challenges that non-experts face in interpreting the behavior of deep learning models. Via a rigorous user study, we validate how ConceptExplainer supports these challenges. Likewise, we conduct a series of usage scenarios to demonstrate how the system supports the interactive analysis of model behavior across a variety of tasks and explanation granularities, such as identifying concepts that are important to classification, identifying bias in training data, and understanding how concepts can be shared across diverse and seemingly dissimilar classes.},
	urldate = {2022-06-24},
	publisher = {arXiv},
	author = {Huang, Jinbin and Mishra, Aditi and Kwon, Bum-Chul and Bryan, Chris},
	month = apr,
	year = {2022},
	note = {arXiv:2204.01888 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, ESCAPE, concept, misclassification, uu},
}

@misc{SpotlightGeneralMethodDiscoveringSystematicb,
	title = {The {Spotlight}: {A} {General} {Method} for {Discovering} {Systematic} {Errors} in {Deep} {Learning} {Models}},
	shorttitle = {The {Spotlight}},
	url = {http://arxiv.org/abs/2107.00758},
	abstract = {Supervised learning models often make systematic errors on rare subsets of the data. When these subsets correspond to explicit labels in the data (e.g., gender, race) such poor performance can be identified straightforwardly. This paper introduces a method for discovering systematic errors that do not correspond to such explicitly labelled subgroups. The key idea is that similar inputs tend to have similar representations in the final hidden layer of a neural network. We leverage this structure by "shining a spotlight" on this representation space to find contiguous regions where the model performs poorly. We show that the spotlight surfaces semantically meaningful areas of weakness in a wide variety of existing models spanning computer vision, NLP, and recommender systems.},
	urldate = {2022-06-24},
	publisher = {arXiv},
	author = {d'Eon, Greg and d'Eon, Jason and Wright, James R. and Leyton-Brown, Kevin},
	month = oct,
	year = {2021},
	note = {arXiv:2107.00758 [cs, stat]},
	keywords = {Computer Science - Machine Learning, ESCAPE, Statistics - Machine Learning, misclassification, uu},
}

@misc{NeuralActivationPatternsNAPsVisual,
	title = {Neural {Activation} {Patterns} ({NAPs}): {Visual} {Explainability} of {Learned} {Concepts}},
	shorttitle = {Neural {Activation} {Patterns} ({NAPs})},
	url = {http://arxiv.org/abs/2206.10611},
	abstract = {A key to deciphering the inner workings of neural networks is understanding what a model has learned. Promising methods for discovering learned features are based on analyzing activation values, whereby current techniques focus on analyzing high activation values to reveal interesting features on a neuron level. However, analyzing high activation values limits layer-level concept discovery. We present a method that instead takes into account the entire activation distribution. By extracting similar activation profiles within the high-dimensional activation space of a neural network layer, we find groups of inputs that are treated similarly. These input groups represent neural activation patterns (NAPs) and can be used to visualize and interpret learned layer concepts. We release a framework with which NAPs can be extracted from pre-trained models and provide a visual introspection tool that can be used to analyze NAPs. We tested our method with a variety of networks and show how it complements existing methods for analyzing neural network activation values.},
	urldate = {2022-09-17},
	publisher = {arXiv},
	author = {Bäuerle, Alex and Jönsson, Daniel and Ropinski, Timo},
	month = jun,
	year = {2022},
	note = {arXiv:2206.10611 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, concept, dm, xai},
}

@misc{ExplainingMachineLearningModelsNatural,
	title = {Explaining {Machine} {Learning} {Models} in {Natural} {Conversations}: {Towards} a {Conversational} {XAI} {Agent}},
	shorttitle = {Explaining {Machine} {Learning} {Models} in {Natural} {Conversations}},
	url = {http://arxiv.org/abs/2209.02552},
	abstract = {The goal of Explainable AI (XAI) is to design methods to provide insights into the reasoning process of black-box models, such as deep neural networks, in order to explain them to humans. Social science research states that such explanations should be conversational, similar to human-to-human explanations. In this work, we show how to incorporate XAI in a conversational agent, using a standard design for the agent comprising natural language understanding and generation components. We build upon an XAI question bank which we extend by quality-controlled paraphrases to understand the user's information needs. We further systematically survey the literature for suitable explanation methods that provide the information to answer those questions, and present a comprehensive list of suggestions. Our work is the first step towards truly natural conversations about machine learning models with an explanation agent. The comprehensive list of XAI questions and the corresponding explanation methods may support other researchers in providing the necessary information to address users' demands.},
	urldate = {2022-09-17},
	publisher = {arXiv},
	author = {Nguyen, Van Bach and Schlötterer, Jörg and Seifert, Christin},
	month = sep,
	year = {2022},
	note = {arXiv:2209.02552 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, nlp, xai},
}

@misc{FairFuseInteractiveVisualSupportFair,
	title = {{FairFuse}: {Interactive} {Visual} {Support} for {Fair} {Consensus} {Ranking}},
	shorttitle = {{FairFuse}},
	url = {http://arxiv.org/abs/2207.07765},
	abstract = {Fair consensus building combines the preferences of multiple rankers into a single consensus ranking, while ensuring any ranked candidate group defined by a protected attribute (such as race or gender) is not disadvantaged compared to other groups. Manually generating a fair consensus ranking is time-consuming and impractical -- even for a fairly small number of candidates. While algorithmic approaches for auditing and generating fair consensus rankings have been developed recently, these have not been operationalized in interactive systems. To bridge this gap, we introduce FairFuse, a visualization-enabled tool for generating, analyzing, and auditing fair consensus rankings. In developing FairFuse, we construct a data model which includes several base rankings entered by rankers, augmented with measures of group fairness, algorithms for generating consensus rankings with varying degrees of fairness, and other fairness and rank-related capabilities. We design novel visualizations that encode these measures in a parallel-coordinates style rank visualization, with interactive capabilities for generating and exploring fair consensus rankings. We provide case studies in which FairFuse supports a decision-maker in ranking scenarios in which fairness is important. Finally, we discuss emerging challenges for future efforts supporting fairness-oriented rank analysis; including handling intersectionality, defined by multiple protected attributes, and the need for user studies targeting peoples' perceptions and use of fairness oriented visualization systems. Code and demo videos available at https://osf.io/hd639/.},
	language = {en},
	urldate = {2022-07-21},
	publisher = {arXiv},
	author = {Shrestha, Hilson and Cachel, Kathleen and Alkhathlan, Mallak and Rundensteiner, Elke and Harrison, Lane},
	month = jul,
	year = {2022},
	note = {arXiv:2207.07765 [cs]},
	keywords = {Computer Science - Human-Computer Interaction},
}

@misc{Finegrainedpredictionfoodinsecurityusing,
	title = {Fine-grained prediction of food insecurity using news streams},
	url = {http://arxiv.org/abs/2111.15602},
	abstract = {Anticipating the outbreak of a food crisis is crucial to efficiently allocate emergency relief and reduce human suffering. However, existing food insecurity early warning systems rely on risk measures that are often delayed, outdated, or incomplete. Here, we leverage recent advances in deep learning to extract high-frequency precursors to food crises from the text of a large corpus of news articles about fragile states published between 1980 and 2020. Our text features are causally grounded, interpretable, validated by existing data, and allow us to predict 32\% more food crises than existing models up to three months ahead of time at the district level across 15 fragile states. These results could have profound implications on how humanitarian aid gets allocated and open new avenues for machine learning to improve decision making in data-scarce environments.},
	language = {en},
	urldate = {2022-07-09},
	publisher = {arXiv},
	author = {Balashankar, Ananth and Subramanian, Lakshminarayanan and Fraiberger, Samuel P.},
	month = nov,
	year = {2021},
	note = {arXiv:2111.15602 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{AIChainsTransparentControllableHumanAI,
	title = {{AI} {Chains}: {Transparent} and {Controllable} {Human}-{AI} {Interaction} by {Chaining} {Large} {Language} {Model} {Prompts}},
	shorttitle = {{AI} {Chains}},
	url = {http://arxiv.org/abs/2110.01691},
	abstract = {Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by "unit-testing" sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications},
	urldate = {2022-09-28},
	publisher = {arXiv},
	author = {Wu, Tongshuang and Terry, Michael and Cai, Carrie J.},
	month = mar,
	year = {2022},
	note = {arXiv:2110.01691 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, chi, hci, nlp},
}

@misc{ExposureInequalityPeopleRecommenderSystems,
	title = {Exposure {Inequality} in {People} {Recommender} {Systems}: {The} {Long}-{Term} {Effects}},
	shorttitle = {Exposure {Inequality} in {People} {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2112.08237},
	abstract = {People recommender systems may affect the exposure that users receive in social networking platforms, influencing attention dynamics and potentially strengthening pre-existing inequalities that disproportionately affect certain groups. In this paper we introduce a model to simulate the feedback loop created by multiple rounds of interactions between users and a link recommender in a social network. This allows us to study the long-term consequences of those particular recommendation algorithms. Our model is equipped with several parameters to control (i) the level of homophily in the network, (ii) the relative size of the groups, (iii) the choice among several state-of-the-art link recommenders, and (iv) the choice among three different user behavior models, that decide which recommendations are accepted or rejected. Our extensive experimentation with the proposed model shows that a minority group, if homophilic enough, can get a disproportionate advantage in exposure from all link recommenders. Instead, when it is heterophilic, it gets under-exposed. Moreover, while the homophily level of the minority affects the speed of the growth of the disparate exposure, the relative size of the minority affects the magnitude of the effect. Finally, link recommenders strengthen exposure inequalities at the individual level, exacerbating the "rich-get-richer" effect: this happens for both the minority and the majority class and independently of their level of homophily.},
	urldate = {2022-09-21},
	publisher = {arXiv},
	author = {Fabbri, Francesco and Croci, Maria Luisa and Bonchi, Francesco and Castillo, Carlos},
	month = dec,
	year = {2021},
	note = {arXiv:2112.08237 [cs]},
	keywords = {Computer Science - Social and Information Networks, dm, rec},
}

@misc{AIChainsTransparentControllableHumanAIa,
	title = {{AI} {Chains}: {Transparent} and {Controllable} {Human}-{AI} {Interaction} by {Chaining} {Large} {Language} {Model} {Prompts}},
	shorttitle = {{AI} {Chains}},
	url = {http://arxiv.org/abs/2110.01691},
	abstract = {Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by "unit-testing" sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications},
	urldate = {2022-09-20},
	publisher = {arXiv},
	author = {Wu, Tongshuang and Terry, Michael and Cai, Carrie J.},
	month = mar,
	year = {2022},
	note = {arXiv:2110.01691 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, hci, nlp, xai},
}

@misc{LanguageTechnologyPowerCriticalSurvey,
	title = {Language ({Technology}) is {Power}: {A} {Critical} {Survey} of "{Bias}" in {NLP}},
	shorttitle = {Language ({Technology}) is {Power}},
	url = {http://arxiv.org/abs/2005.14050},
	abstract = {We survey 146 papers analyzing "bias" in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing "bias" is an inherently normative process. We further find that these papers' proposed quantitative techniques for measuring or mitigating "bias" are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing "bias" in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of "bias"---i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements---and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.},
	urldate = {2022-10-04},
	publisher = {arXiv},
	author = {Blodgett, Su Lin and Barocas, Solon and Daumé III, Hal and Wallach, Hanna},
	month = may,
	year = {2020},
	note = {arXiv:2005.14050 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, fair, nlp, survey},
}

@misc{WomanWorkedBabysitterBiasesLanguage,
	title = {The {Woman} {Worked} as a {Babysitter}: {On} {Biases} in {Language} {Generation}},
	shorttitle = {The {Woman} {Worked} as a {Babysitter}},
	url = {http://arxiv.org/abs/1909.01326},
	abstract = {We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.},
	urldate = {2022-10-03},
	publisher = {arXiv},
	author = {Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
	month = oct,
	year = {2019},
	note = {arXiv:1909.01326 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, fair, nlp},
}

@misc{UniversalAdversarialTriggersAttackingAnalyzing,
	title = {Universal {Adversarial} {Triggers} for {Attacking} and {Analyzing} {NLP}},
	url = {http://arxiv.org/abs/1908.07125},
	abstract = {Adversarial examples highlight model vulnerabilities and are useful for evaluation and interpretation. We define universal adversarial triggers: input-agnostic sequences of tokens that trigger a model to produce a specific prediction when concatenated to any input from a dataset. We propose a gradient-guided search over tokens which finds short trigger sequences (e.g., one word for classification and four words for language modeling) that successfully trigger the target prediction. For example, triggers cause SNLI entailment accuracy to drop from 89.94\% to 0.55\%, 72\% of "why" questions in SQuAD to be answered "to kill american people", and the GPT-2 language model to spew racist output even when conditioned on non-racial contexts. Furthermore, although the triggers are optimized using white-box access to a specific model, they transfer to other models for all tasks we consider. Finally, since triggers are input-agnostic, they provide an analysis of global model behavior. For instance, they confirm that SNLI models exploit dataset biases and help to diagnose heuristics learned by reading comprehension models.},
	urldate = {2022-10-03},
	publisher = {arXiv},
	author = {Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
	month = jan,
	year = {2021},
	note = {arXiv:1908.07125 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, bias, controllable, fatml, nlp},
}

@misc{DiverseHumansHumanAIInteractionWhat,
	title = {Diverse {Humans} and {Human}-{AI} {Interaction}: {What} {Cognitive} {Style} {Disaggregation} {Reveals}},
	shorttitle = {Diverse {Humans} and {Human}-{AI} {Interaction}},
	url = {http://arxiv.org/abs/2108.00588},
	abstract = {Although guidelines for human-AI interaction (HAI) are providing important advice on how to help improve user experiences with AI products, little is known about HAI for diverse users' experiences with such systems. Without understanding how diverse users' experiences with AI products differ, designers lack information they need to make AI products that serve users equitably. To investigate, we disaggregated data from 1,016 human participants according to five cognitive styles -- their attitudes toward risk, their motivations, their learning styles (by process vs. by tinkering), their information processing styles, and their computer self-efficacy. Our results revealed situations in which applying existing HAI guidelines helped these cognitively diverse participants equitably, where applying them helped participants inequitably, and where stubborn inequity problems persisted despite applying the guidelines.The results also revealed that these situations pervaded across 15 of the 16 experiments; and also that they arose for all five of the cognitive style spectra. Finally, the results revealed what the cognitive style disaggregation's impacts were by participants' demographics -- showing statistical clusterings not only by gender, but also clusterings for intersectional gender-age groups.},
	urldate = {2022-09-28},
	publisher = {arXiv},
	author = {Anderson, Andrew and Li, Tianyi and Vorvoreanu, Mihaela and Burnett, Margaret},
	month = aug,
	year = {2022},
	note = {arXiv:2108.00588 [cs]
version: 2},
	keywords = {Computer Science - Human-Computer Interaction, hai, hci},
}

@misc{SurveyControllableTextGenerationusing,
	title = {A {Survey} of {Controllable} {Text} {Generation} using {Transformer}-based {Pre}-trained {Language} {Models}},
	url = {http://arxiv.org/abs/2201.05337},
	abstract = {Controllable Text Generation (CTG) is emerging area in the field of natural language generation (NLG). It is regarded as crucial for the development of advanced text generation technologies that are more natural and better meet the specific constraints in practical applications. In recent years, methods using large-scale pre-trained language models (PLMs), in particular the widely used transformer-based PLMs, have become a new paradigm of NLG, allowing generation of more diverse and fluent text. However, due to the lower level of interpretability of deep neural networks, the controllability of these methods need to be guaranteed. To this end, controllable text generation using transformer-based PLMs has become a rapidly growing yet challenging new research hotspot. A diverse range of approaches have emerged in the recent 3-4 years, targeting different CTG tasks which may require different types of controlled constraints. In this paper, we present a systematic critical review on the common tasks, main approaches and evaluation methods in this area. Finally, we discuss the challenges that the field is facing, and put forward various promising future directions. To the best of our knowledge, this is the first survey paper to summarize CTG techniques from the perspective of PLMs. We hope it can help researchers in related fields to quickly track the academic frontier, providing them with a landscape of the area and a roadmap for future research.},
	urldate = {2022-10-11},
	publisher = {arXiv},
	author = {Zhang, Hanqing and Song, Haolin and Li, Shaoyu and Zhou, Ming and Song, Dawei},
	month = jan,
	year = {2022},
	note = {arXiv:2201.05337 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{SandboxToolBiasStressTest,
	title = {A {Sandbox} {Tool} to {Bias}({Stress})-{Test} {Fairness} {Algorithms}},
	url = {http://arxiv.org/abs/2204.10233},
	abstract = {Motivated by the growing importance of reducing unfairness in ML predictions, Fair-ML researchers have presented an extensive suite of algorithmic "fairness-enhancing" remedies. Most existing algorithms, however, are agnostic to the sources of the observed unfairness. As a result, the literature currently lacks guiding frameworks to specify conditions under which each algorithmic intervention can potentially alleviate the underpinning cause of unfairness. To close this gap, we scrutinize the underlying biases (e.g., in the training data or design choices) that cause observational unfairness. We present a bias-injection sandbox tool to investigate fairness consequences of various biases and assess the effectiveness of algorithmic remedies in the presence of specific types of bias. We call this process the bias(stress)-testing of algorithmic interventions. Unlike existing toolkits, ours provides a controlled environment to counterfactually inject biases in the ML pipeline. This stylized setup offers the distinct capability of testing fairness interventions beyond observational data and against an unbiased benchmark. In particular, we can test whether a given remedy can alleviate the injected bias by comparing the predictions resulting after the intervention in the biased setting with true labels in the unbiased regime -- that is, before any bias injection. We illustrate the utility of our toolkit via a proof-of-concept case study on synthetic data. Our empirical analysis showcases the type of insights that can be obtained through our simulations.},
	urldate = {2022-10-07},
	publisher = {arXiv},
	author = {Akpinar, Nil-Jana and Nagireddy, Manish and Stapleton, Logan and Cheng, Hao-Fei and Zhu, Haiyi and Wu, Steven and Heidari, Hoda},
	month = apr,
	year = {2022},
	note = {arXiv:2204.10233 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, fair, vis},
}

@misc{SurveyControllableTextGenerationusinga,
	title = {A {Survey} of {Controllable} {Text} {Generation} using {Transformer}-based {Pre}-trained {Language} {Models}},
	url = {http://arxiv.org/abs/2201.05337},
	abstract = {Controllable Text Generation (CTG) is emerging area in the field of natural language generation (NLG). It is regarded as crucial for the development of advanced text generation technologies that are more natural and better meet the specific constraints in practical applications. In recent years, methods using large-scale pre-trained language models (PLMs), in particular the widely used transformer-based PLMs, have become a new paradigm of NLG, allowing generation of more diverse and fluent text. However, due to the lower level of interpretability of deep neural networks, the controllability of these methods need to be guaranteed. To this end, controllable text generation using transformer-based PLMs has become a rapidly growing yet challenging new research hotspot. A diverse range of approaches have emerged in the recent 3-4 years, targeting different CTG tasks which may require different types of controlled constraints. In this paper, we present a systematic critical review on the common tasks, main approaches and evaluation methods in this area. Finally, we discuss the challenges that the field is facing, and put forward various promising future directions. To the best of our knowledge, this is the first survey paper to summarize CTG techniques from the perspective of PLMs. We hope it can help researchers in related fields to quickly track the academic frontier, providing them with a landscape of the area and a roadmap for future research.},
	urldate = {2022-10-06},
	publisher = {arXiv},
	author = {Zhang, Hanqing and Song, Haolin and Li, Shaoyu and Zhou, Ming and Song, Dawei},
	month = jan,
	year = {2022},
	note = {arXiv:2201.05337 [cs]},
	keywords = {Computer Science - Computation and Language, controllable, nlp, survey},
}

@misc{CTRLConditionalTransformerLanguageModel,
	title = {{CTRL}: {A} {Conditional} {Transformer} {Language} {Model} for {Controllable} {Generation}},
	shorttitle = {{CTRL}},
	url = {http://arxiv.org/abs/1909.05858},
	abstract = {Large-scale language models show promising text generation capabilities, but users cannot easily control particular aspects of the generated text. We release CTRL, a 1.63 billion-parameter conditional transformer language model, trained to condition on control codes that govern style, content, and task-specific behavior. Control codes were derived from structure that naturally co-occurs with raw text, preserving the advantages of unsupervised learning while providing more explicit control over text generation. These codes also allow CTRL to predict which parts of the training data are most likely given a sequence. This provides a potential method for analyzing large amounts of data via model-based source attribution. We have released multiple full-sized, pretrained versions of CTRL at https://github.com/salesforce/ctrl.},
	urldate = {2022-10-04},
	publisher = {arXiv},
	author = {Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav R. and Xiong, Caiming and Socher, Richard},
	month = sep,
	year = {2019},
	note = {arXiv:1909.05858 [cs]},
	keywords = {Computer Science - Computation and Language, conditional, nlp},
}

@misc{ControllableDialogueGenerationDisentangledMultigrained,
	title = {Controllable {Dialogue} {Generation} with {Disentangled} {Multi}-grained {Style} {Specification} and {Attribute} {Consistency} {Reward}},
	url = {http://arxiv.org/abs/2109.06717},
	abstract = {Controllable text generation is an appealing but challenging task, which allows users to specify particular attributes of the generated outputs. In this paper, we propose a controllable dialogue generation model to steer response generation under multi-attribute constraints. Specifically, we define and categorize the commonly used control attributes into global and local ones, which possess different granularities of effects on response generation. Then, we significantly extend the conventional seq2seq framework by introducing a novel two-stage decoder, which first uses a multi-grained style specification layer to impose the stylistic constraints and determine word-level control states of responses based on the attributes, and then employs a response generation layer to generate final responses maintaining both semantic relevancy to the contexts and fidelity to the attributes. Furthermore, we train our model with an attribute consistency reward to promote response control with explicit supervision signals. Extensive experiments and in-depth analyses on two datasets indicate that our model can significantly outperform competitive baselines in terms of response quality, content diversity and controllability.},
	urldate = {2022-10-11},
	publisher = {arXiv},
	author = {Hu, Zhe and Cao, Zhiwei and Chan, Hou Pong and Liu, Jiachen and Xiao, Xinyan and Su, Jinsong and Wu, Hua},
	month = sep,
	year = {2021},
	note = {arXiv:2109.06717 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, controllable, nlp},
}

@misc{RecipesSafetyOpendomainChatbots,
	title = {Recipes for {Safety} in {Open}-domain {Chatbots}},
	url = {http://arxiv.org/abs/2010.07079},
	abstract = {Models trained on large unlabeled corpora of human interactions will learn patterns and mimic behaviors therein, which include offensive or otherwise toxic behavior and unwanted biases. We investigate a variety of methods to mitigate these issues in the context of open-domain generative dialogue models. We introduce a new human-and-model-in-the-loop framework for both training safer models and for evaluating them, as well as a novel method to distill safety considerations inside generative models without the use of an external classifier at deployment time. We conduct experiments comparing these methods and find our new techniques are (i) safer than existing models as measured by automatic and human evaluations while (ii) maintaining usability metrics such as engagingness relative to the state of the art. We then discuss the limitations of this work by analyzing failure cases of our models.},
	urldate = {2022-10-11},
	publisher = {arXiv},
	author = {Xu, Jing and Ju, Da and Li, Margaret and Boureau, Y.-Lan and Weston, Jason and Dinan, Emily},
	month = aug,
	year = {2021},
	note = {arXiv:2010.07079 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{ExploringControllableTextGenerationTechniques,
	title = {Exploring {Controllable} {Text} {Generation} {Techniques}},
	url = {http://arxiv.org/abs/2005.01822},
	abstract = {Neural controllable text generation is an important area gaining attention due to its plethora of applications. Although there is a large body of prior work in controllable text generation, there is no unifying theme. In this work, we provide a new schema of the pipeline of the generation process by classifying it into five modules. The control of attributes in the generation process requires modification of these modules. We present an overview of different techniques used to perform the modulation of these modules. We also provide an analysis on the advantages and disadvantages of these techniques. We further pave ways to develop new architectures based on the combination of the modules described in this paper.},
	urldate = {2022-10-12},
	publisher = {arXiv},
	author = {Prabhumoye, Shrimai and Black, Alan W. and Salakhutdinov, Ruslan},
	month = oct,
	year = {2020},
	note = {arXiv:2005.01822 [cs]},
	keywords = {Computer Science - Computation and Language, controllable, generation, nlp},
}

@misc{QueensarePowerfultooMitigating,
	title = {Queens are {Powerful} too: {Mitigating} {Gender} {Bias} in {Dialogue} {Generation}},
	shorttitle = {Queens are {Powerful} too},
	url = {http://arxiv.org/abs/1911.03842},
	abstract = {Models often easily learn biases present in the training data, and their predictions directly reflect this bias. We analyze gender bias in dialogue data, and examine how this bias is actually amplified in subsequent generative chit-chat dialogue models. We measure gender bias in six existing dialogue datasets, and focus on the most biased one, the multi-player text-based fantasy adventure dataset LIGHT, as a testbed for our bias mitigation techniques. The LIGHT dataset is highly imbalanced with respect to gender, containing predominantly male characters, likely because it is entirely collected by crowdworkers and reflects common biases that exist in fantasy or medieval settings. We consider three techniques to mitigate gender bias: counterfactual data augmentation, targeted data collection, and bias controlled training. We show that our proposed techniques mitigate gender bias in LIGHT by balancing the genderedness of generated dialogue utterances and are particularly effective in combination. We quantify performance using various evaluation methods---such as quantity of gendered words, a dialogue safety classifier, and human studies---all of which show that our models generate less gendered, but equally engaging chit-chat responses.},
	urldate = {2022-10-12},
	publisher = {arXiv},
	author = {Dinan, Emily and Fan, Angela and Williams, Adina and Urbanek, Jack and Kiela, Douwe and Weston, Jason},
	month = apr,
	year = {2020},
	note = {arXiv:1911.03842 [cs]},
	keywords = {Computer Science - Computation and Language, fair, nlp},
}

@misc{WordcraftHumanAICollaborativeEditorStory,
	title = {Wordcraft: a {Human}-{AI} {Collaborative} {Editor} for {Story} {Writing}},
	shorttitle = {Wordcraft},
	url = {http://arxiv.org/abs/2107.07430},
	abstract = {As neural language models grow in effectiveness, they are increasingly being applied in real-world settings. However these applications tend to be limited in the modes of interaction they support. In this extended abstract, we propose Wordcraft, an AI-assisted editor for story writing in which a writer and a dialog system collaborate to write a story. Our novel interface uses few-shot learning and the natural affordances of conversation to support a variety of interactions. Our editor provides a sandbox for writers to probe the boundaries of transformer-based language models and paves the way for future human-in-the-loop training pipelines and novel evaluation methods.},
	urldate = {2022-10-12},
	publisher = {arXiv},
	author = {Coenen, Andy and Davis, Luke and Ippolito, Daphne and Reif, Emily and Yuan, Ann},
	month = jul,
	year = {2021},
	note = {arXiv:2107.07430 [cs]},
	keywords = {Computer Science - Computation and Language, collaboration, nlp},
}

@misc{ExploringControllableTextGenerationTechniquesa,
	title = {Exploring {Controllable} {Text} {Generation} {Techniques}},
	url = {http://arxiv.org/abs/2005.01822},
	abstract = {Neural controllable text generation is an important area gaining attention due to its plethora of applications. Although there is a large body of prior work in controllable text generation, there is no unifying theme. In this work, we provide a new schema of the pipeline of the generation process by classifying it into five modules. The control of attributes in the generation process requires modification of these modules. We present an overview of different techniques used to perform the modulation of these modules. We also provide an analysis on the advantages and disadvantages of these techniques. We further pave ways to develop new architectures based on the combination of the modules described in this paper.},
	urldate = {2022-10-11},
	publisher = {arXiv},
	author = {Prabhumoye, Shrimai and Black, Alan W. and Salakhutdinov, Ruslan},
	month = oct,
	year = {2020},
	note = {arXiv:2005.01822 [cs]},
	keywords = {Computer Science - Computation and Language, controllable, nlp},
}

@misc{FairnessRecommendationSurvey,
	title = {Fairness in {Recommendation}: {A} {Survey}},
	shorttitle = {Fairness in {Recommendation}},
	url = {http://arxiv.org/abs/2205.13619},
	abstract = {As one of the most pervasive applications of machine learning, recommender systems are playing an important role on assisting human decision making. The satisfaction of users and the interests of platforms are closely related to the quality of the generated recommendation results. However, as a highly data-driven system, recommender system could be affected by data or algorithmic bias and thus generate unfair results, which could weaken the reliance of the systems. As a result, it is crucial to address the potential unfairness problems in recommendation settings. Recently, there has been growing attention on fairness considerations in recommender systems with more and more literature on approaches to promote fairness in recommendation. However, the studies are rather fragmented and lack a systematic organization, thus making it difficult to penetrate for new researchers to the domain. This motivates us to provide a systematic survey of existing works on fairness in recommendation. This survey focuses on the foundations for fairness in recommendation literature. It first presents a brief introduction about fairness in basic machine learning tasks such as classification and ranking in order to provide a general overview of fairness research, as well as introduce the more complex situations and challenges that need to be considered when studying fairness in recommender systems. After that, the survey will introduce fairness in recommendation with a focus on the taxonomies of current fairness definitions, the typical techniques for improving fairness, as well as the datasets for fairness studies in recommendation. The survey also talks about the challenges and opportunities in fairness research with the hope of promoting the fair recommendation research area and beyond.},
	urldate = {2022-10-16},
	publisher = {arXiv},
	author = {Li, Yunqi and Chen, Hanxiong and Xu, Shuyuan and Ge, Yingqiang and Tan, Juntao and Liu, Shuchang and Zhang, Yongfeng},
	month = jun,
	year = {2022},
	note = {arXiv:2205.13619 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Machine Learning, fair, rec, survey, xai},
}

@misc{CounterfactualStoryReasoningGeneration,
	title = {Counterfactual {Story} {Reasoning} and {Generation}},
	url = {http://arxiv.org/abs/1909.04076},
	abstract = {Counterfactual reasoning requires predicting how alternative events, contrary to what actually happened, might have resulted in different outcomes. Despite being considered a necessary component of AI-complete systems, few resources have been developed for evaluating counterfactual reasoning in narratives. In this paper, we propose Counterfactual Story Rewriting: given an original story and an intervening counterfactual event, the task is to minimally revise the story to make it compatible with the given counterfactual event. Solving this task will require deep understanding of causal narrative chains and counterfactual invariance, and integration of such story reasoning capabilities into conditional language generation models. We present TimeTravel, a new dataset of 29,849 counterfactual rewritings, each with the original story, a counterfactual event, and human-generated revision of the original story compatible with the counterfactual event. Additionally, we include 80,115 counterfactual "branches" without a rewritten storyline to support future work on semi- or un-supervised approaches to counterfactual story rewriting. Finally, we evaluate the counterfactual rewriting capacities of several competitive baselines based on pretrained language models, and assess whether common overlap and model-based automatic metrics for text generation correlate well with human scores for counterfactual rewriting.},
	urldate = {2022-10-13},
	publisher = {arXiv},
	author = {Qin, Lianhui and Bosselut, Antoine and Holtzman, Ari and Bhagavatula, Chandra and Clark, Elizabeth and Choi, Yejin},
	month = sep,
	year = {2019},
	note = {arXiv:1909.04076 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, counterfactual, generation, nlp},
}

@misc{EffectiveExposureAmortizingFairTopk,
	title = {Effective {Exposure} {Amortizing} for {Fair} {Top}-k {Recommendation}},
	url = {http://arxiv.org/abs/2204.03046},
	abstract = {Result ranking often affects customer satisfaction as well as the amount of exposure each product receives in recommendation systems (RecSys). Myopically maximizing customer satisfaction by ranking products only according to relevance will lead to unfair distribution of exposure for products, followed by unfair opportunities and economic gains for product producers. This unfairness will force producers to leave the system, and discourage new producers from coming in. Eventually, fewer purchase options would be left for customers and the overall transaction rates on e-commerce platforms would decrease. Thus, how to maintain a balance between ranking relevance and fairness is important to both producers and customers. In this paper, we focus on the task of exposure fairness in offline recommendation setting. We demonstrate that existing methods for amortized fairness optimization are suboptimal for offline recommendation because they fail to utilize the prior knowledge of customers. We further propose a novel fair recommendation algorithm to reach a better balance between exposure fairness and recommendation performance. Extensive experiments on three real-world datasets demonstrate that our method significantly outperforms the state-of-the-art fair ranking algorithm in terms of fairness-performance trade off from both individual level and group level.},
	language = {en},
	urldate = {2022-10-18},
	publisher = {arXiv},
	author = {Yang, Tao and Xu, Zhichao and Ai, Qingyao},
	month = apr,
	year = {2022},
	note = {arXiv:2204.03046 [cs]},
	keywords = {Computer Science - Information Retrieval, H.3.3},
}

@misc{EffectiveExposureAmortizingFairTopka,
	title = {Effective {Exposure} {Amortizing} for {Fair} {Top}-k {Recommendation}},
	url = {http://arxiv.org/abs/2204.03046},
	abstract = {Result ranking often affects customer satisfaction as well as the amount of exposure each product receives in recommendation systems (RecSys). Myopically maximizing customer satisfaction by ranking products only according to relevance will lead to unfair distribution of exposure for products, followed by unfair opportunities and economic gains for product producers. This unfairness will force producers to leave the system, and discourage new producers from coming in. Eventually, fewer purchase options would be left for customers and the overall transaction rates on e-commerce platforms would decrease. Thus, how to maintain a balance between ranking relevance and fairness is important to both producers and customers. In this paper, we focus on the task of exposure fairness in offline recommendation setting. We demonstrate that existing methods for amortized fairness optimization are suboptimal for offline recommendation because they fail to utilize the prior knowledge of customers. We further propose a novel fair recommendation algorithm to reach a better balance between exposure fairness and recommendation performance. Extensive experiments on three real-world datasets demonstrate that our method significantly outperforms the state-of-the-art fair ranking algorithm in terms of fairness-performance trade off from both individual level and group level.},
	language = {en},
	urldate = {2022-10-18},
	publisher = {arXiv},
	author = {Yang, Tao and Xu, Zhichao and Ai, Qingyao},
	month = apr,
	year = {2022},
	note = {arXiv:2204.03046 [cs]},
	keywords = {Computer Science - Information Retrieval, H.3.3},
}

@misc{DisentangledRepresentationCausalConstraintsCounterfactual,
	title = {Disentangled {Representation} with {Causal} {Constraints} for {Counterfactual} {Fairness}},
	url = {http://arxiv.org/abs/2208.09147},
	abstract = {Much research has been devoted to the problem of learning fair representations; however, they do not explicitly the relationship between latent representations. In many real-world applications, there may be causal relationships between latent representations. Furthermore, most fair representation learning methods focus on group-level fairness and are based on correlations, ignoring the causal relationships underlying the data. In this work, we theoretically demonstrate that using the structured representations enable downstream predictive models to achieve counterfactual fairness, and then we propose the Counterfactual Fairness Variational AutoEncoder (CF-VAE) to obtain structured representations with respect to domain knowledge. The experimental results show that the proposed method achieves better fairness and accuracy performance than the benchmark fairness methods.},
	language = {en},
	urldate = {2022-10-17},
	publisher = {arXiv},
	author = {Xu, Ziqi and Liu, Jixue and Cheng, Debo and Li, Jiuyong and Liu, Lin and Wang, Ke},
	month = aug,
	year = {2022},
	note = {arXiv:2208.09147 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
}

@misc{InterpretableCounterfactualExplanationsGuidedPrototypesa,
	title = {Interpretable {Counterfactual} {Explanations} {Guided} by {Prototypes}},
	url = {http://arxiv.org/abs/1907.02584},
	abstract = {We propose a fast, model agnostic method for finding interpretable counterfactual explanations of classifier predictions by using class prototypes. We show that class prototypes, obtained using either an encoder or through class specific k-d trees, significantly speed up the the search for counterfactual instances and result in more interpretable explanations. We introduce two novel metrics to quantitatively evaluate local interpretability at the instance level. We use these metrics to illustrate the effectiveness of our method on an image and tabular dataset, respectively MNIST and Breast Cancer Wisconsin (Diagnostic). The method also eliminates the computational bottleneck that arises because of numerical gradient evaluation for \${\textbackslash}textit\{black box\}\$ models.},
	language = {en},
	urldate = {2022-10-17},
	publisher = {arXiv},
	author = {Van Looveren, Arnaud and Klaise, Janis},
	month = feb,
	year = {2020},
	note = {arXiv:1907.02584 [cs, stat]},
	keywords = {counterfactual, explanation, interpretable, prototype},
}

@misc{CounterfactualExplanationsMachineLearningChallenges,
	title = {Counterfactual {Explanations} for {Machine} {Learning}: {Challenges} {Revisited}},
	shorttitle = {Counterfactual {Explanations} for {Machine} {Learning}},
	url = {http://arxiv.org/abs/2106.07756},
	abstract = {Counterfactual explanations (CFEs) are an emerging technique under the umbrella of interpretability of machine learning (ML) models. They provide ``what if'' feedback of the form ``if an input datapoint were \$x'\$ instead of \$x\$, then an ML model's output would be \$y'\$ instead of \$y\$.'' Counterfactual explainability for ML models has yet to see widespread adoption in industry. In this short paper, we posit reasons for this slow uptake. Leveraging recent work outlining desirable properties of CFEs and our experience running the ML wing of a model monitoring startup, we identify outstanding obstacles hindering CFE deployment in industry.},
	urldate = {2022-10-19},
	publisher = {arXiv},
	author = {Verma, Sahil and Dickerson, John and Hines, Keegan},
	month = jun,
	year = {2021},
	note = {arXiv:2106.07756 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, counterfactual, hci, vis},
}

@misc{CounterfactualExplanationsMachineLearningReview,
	title = {Counterfactual {Explanations} for {Machine} {Learning}: {A} {Review}},
	shorttitle = {Counterfactual {Explanations} for {Machine} {Learning}},
	url = {http://arxiv.org/abs/2010.10596},
	abstract = {Machine learning plays a role in many deployed decision systems, often in ways that are difficult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machine-learning-based systems. A burgeoning body of research seeks to define the goals and methods of explainability in machine learning. In this paper, we seek to review and categorize research on counterfactual explanations, a specific class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to fielded systems in high-impact areas such as finance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently-proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this field. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.},
	urldate = {2022-10-19},
	publisher = {arXiv},
	author = {Verma, Sahil and Dickerson, John and Hines, Keegan},
	month = oct,
	year = {2020},
	note = {arXiv:2010.10596 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, counterfactual, hci, vis},
}

@misc{ProblemsShapleyvaluebasedexplanationsfeatureimportance,
	title = {Problems with {Shapley}-value-based explanations as feature importance measures},
	url = {http://arxiv.org/abs/2002.11097},
	abstract = {Game-theoretic formulations of feature importance have become popular as a way to "explain" machine learning models. These methods define a cooperative game between the features of a model and distribute influence among these input elements using some form of the game's unique Shapley values. Justification for these methods rests on two pillars: their desirable mathematical properties, and their applicability to specific motivations for explanations. We show that mathematical problems arise when Shapley values are used for feature importance and that the solutions to mitigate these necessarily induce further complexity, such as the need for causal reasoning. We also draw on additional literature to argue that Shapley values do not provide explanations which suit human-centric goals of explainability.},
	urldate = {2022-10-26},
	publisher = {arXiv},
	author = {Kumar, I. Elizabeth and Venkatasubramanian, Suresh and Scheidegger, Carlos and Friedler, Sorelle},
	month = jun,
	year = {2020},
	note = {arXiv:2002.11097 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, explainable, shap, xai},
}

@misc{Maintainingfairnessdistributionshiftwe,
	title = {Maintaining fairness across distribution shift: do we have viable solutions for real-world applications?},
	shorttitle = {Maintaining fairness across distribution shift},
	url = {http://arxiv.org/abs/2202.01034},
	abstract = {Fairness and robustness are often considered as orthogonal dimensions when evaluating machine learning models. However, recent work has revealed interactions between fairness and robustness, showing that fairness properties are not necessarily maintained under distribution shift. In healthcare settings, this can result in e.g. a model that performs fairly according to a selected metric in "hospital A" showing unfairness when deployed in "hospital B". While a nascent field has emerged to develop provable fair and robust models, it typically relies on strong assumptions about the shift, limiting its impact for real-world applications. In this work, we explore the settings in which recently proposed mitigation strategies are applicable by referring to a causal framing. Using examples of predictive models in dermatology and electronic health records, we show that real-world applications are complex and often invalidate the assumptions of such methods. Our work hence highlights technical, practical, and engineering gaps that prevent the development of robustly fair machine learning models for real-world applications. Finally, we discuss potential remedies at each step of the machine learning pipeline.},
	urldate = {2022-10-20},
	publisher = {arXiv},
	author = {Schrouff, Jessica and Harris, Natalie and Koyejo, Oluwasanmi and Alabdulmohsin, Ibrahim and Schnider, Eva and Opsahl-Ong, Krista and Brown, Alex and Roy, Subhrajit and Mincu, Diana and Chen, Christina and Dieng, Awa and Liu, Yuan and Natarajan, Vivek and Karthikesalingam, Alan and Heller, Katherine and Chiappa, Silvia and D'Amour, Alexander},
	month = feb,
	year = {2022},
	note = {arXiv:2202.01034 [cs, stat]},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Machine Learning, fair, shift},
}

@misc{QuantitativeEvaluationsCounterfactuals,
	title = {On {Quantitative} {Evaluations} of {Counterfactuals}},
	url = {http://arxiv.org/abs/2111.00177},
	abstract = {As counterfactual examples become increasingly popular for explaining decisions of deep learning models, it is essential to understand what properties quantitative evaluation metrics do capture and equally important what they do not capture. Currently, such understanding is lacking, potentially slowing down scientific progress. In this paper, we consolidate the work on evaluating visual counterfactual examples through an analysis and experiments. We find that while most metrics behave as intended for sufficiently simple datasets, some fail to tell the difference between good and bad counterfactuals when the complexity increases. We observe experimentally that metrics give good scores to tiny adversarial-like changes, wrongly identifying such changes as superior counterfactual examples. To mitigate this issue, we propose two new metrics, the Label Variation Score and the Oracle score, which are both less vulnerable to such tiny changes. We conclude that a proper quantitative evaluation of visual counterfactual examples should combine metrics to ensure that all aspects of good counterfactuals are quantified.},
	urldate = {2022-10-20},
	publisher = {arXiv},
	author = {Hvilshøj, Frederik and Iosifidis, Alexandros and Assent, Ira},
	month = oct,
	year = {2021},
	note = {arXiv:2111.00177 [cs]},
	keywords = {Computer Science - Machine Learning, counterfactual, fair},
}

@misc{Personalizedexplanationmachinelearningconceptualization,
	title = {Personalized explanation in machine learning: {A} conceptualization},
	shorttitle = {Personalized explanation in machine learning},
	url = {http://arxiv.org/abs/1901.00770},
	abstract = {Explanation in machine learning and related fields such as artificial intelligence aims at making machine learning models and their decisions understandable to humans. Existing work suggests that personalizing explanations might help to improve understandability. In this work, we derive a conceptualization of personalized explanation by defining and structuring the problem based on prior work on machine learning explanation, personalization (in machine learning) and concepts and techniques from other domains such as privacy and knowledge elicitation. We perform a categorization of explainee data used in the process of personalization as well as describing means to collect this data. We also identify three key explanation properties that are amendable to personalization: complexity, decision information and presentation. We also enhance existing work on explanation by introducing additional desiderata and measures to quantify the quality of personalized explanations.},
	urldate = {2022-11-14},
	publisher = {arXiv},
	author = {Schneider, Johanes and Handali, Joshua},
	month = apr,
	year = {2019},
	note = {arXiv:1901.00770 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{PersonalizedCounterfactualFairnessRecommendation,
	title = {Personalized {Counterfactual} {Fairness} in {Recommendation}},
	url = {http://arxiv.org/abs/2105.09829},
	doi = {10.1145/3404835.3462966},
	abstract = {Recommender systems are gaining increasing and critical impacts on human and society since a growing number of users use them for information seeking and decision making. Therefore, it is crucial to address the potential unfairness problems in recommendations. Just like users have personalized preferences on items, users' demands for fairness are also personalized in many scenarios. Therefore, it is important to provide personalized fair recommendations for users to satisfy their personalized fairness demands. Besides, previous works on fair recommendation mainly focus on association-based fairness. However, it is important to advance from associative fairness notions to causal fairness notions for assessing fairness more properly in recommender systems. Based on the above considerations, this paper focuses on achieving personalized counterfactual fairness for users in recommender systems. To this end, we introduce a framework for achieving counterfactually fair recommendations through adversary learning by generating feature-independent user embeddings for recommendation. The framework allows recommender systems to achieve personalized fairness for users while also covering non-personalized situations. Experiments on two real-world datasets with shallow and deep recommendation algorithms show that our method can generate fairer recommendations for users with a desirable recommendation performance.},
	urldate = {2022-11-12},
	author = {Li, Yunqi and Chen, Hanxiong and Xu, Shuyuan and Ge, Yingqiang and Zhang, Yongfeng},
	month = nov,
	year = {2021},
	note = {arXiv:2105.09829 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Machine Learning, counterfactual, fair, rec},
}

@misc{InterpretableCounterfactualExplanationsGuidedPrototypes,
	title = {Interpretable {Counterfactual} {Explanations} {Guided} by {Prototypes}},
	url = {http://arxiv.org/abs/1907.02584},
	abstract = {We propose a fast, model agnostic method for finding interpretable counterfactual explanations of classifier predictions by using class prototypes. We show that class prototypes, obtained using either an encoder or through class specific k-d trees, significantly speed up the the search for counterfactual instances and result in more interpretable explanations. We introduce two novel metrics to quantitatively evaluate local interpretability at the instance level. We use these metrics to illustrate the effectiveness of our method on an image and tabular dataset, respectively MNIST and Breast Cancer Wisconsin (Diagnostic). The method also eliminates the computational bottleneck that arises because of numerical gradient evaluation for \${\textbackslash}textit\{black box\}\$ models.},
	urldate = {2022-11-08},
	publisher = {arXiv},
	author = {Van Looveren, Arnaud and Klaise, Janis},
	month = feb,
	year = {2020},
	note = {arXiv:1907.02584 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, counterfactual, prototype},
}

@misc{Crankvolumepreferencebiasamplification,
	title = {Crank up the volume: preference bias amplification in collaborative recommendation},
	shorttitle = {Crank up the volume},
	url = {http://arxiv.org/abs/1909.06362},
	abstract = {Recommender systems are personalized: we expect the results given to a particular user to reflect that user's preferences. Some researchers have studied the notion of calibration, how well recommendations match users' stated preferences, and bias disparity the extent to which mis-calibration affects different user groups. In this paper, we examine bias disparity over a range of different algorithms and for different item categories and demonstrate significant differences between model-based and memory-based algorithms.},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Lin, Kun and Sonboli, Nasim and Mobasher, Bamshad and Burke, Robin},
	month = sep,
	year = {2019},
	note = {arXiv:1909.06362 [cs, stat]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Statistics - Machine Learning, rec, stereotype},
}

@misc{DominoDiscoveringSystematicErrorsCrossModal,
	title = {Domino: {Discovering} {Systematic} {Errors} with {Cross}-{Modal} {Embeddings}},
	shorttitle = {Domino},
	url = {http://arxiv.org/abs/2203.14960},
	abstract = {Machine learning models that achieve high overall accuracy often make systematic errors on important subsets (or slices) of data. Identifying underperforming slices is particularly challenging when working with high-dimensional inputs (e.g. images, audio), where important slices are often unlabeled. In order to address this issue, recent studies have proposed automated slice discovery methods (SDMs), which leverage learned model representations to mine input data for slices on which a model performs poorly. To be useful to a practitioner, these methods must identify slices that are both underperforming and coherent (i.e. united by a human-understandable concept). However, no quantitative evaluation framework currently exists for rigorously assessing SDMs with respect to these criteria. Additionally, prior qualitative evaluations have shown that SDMs often identify slices that are incoherent. In this work, we address these challenges by first designing a principled evaluation framework that enables a quantitative comparison of SDMs across 1,235 slice discovery settings in three input domains (natural images, medical images, and time-series data). Then, motivated by the recent development of powerful cross-modal representation learning approaches, we present Domino, an SDM that leverages cross-modal embeddings and a novel error-aware mixture model to discover and describe coherent slices. We find that Domino accurately identifies 36\% of the 1,235 slices in our framework - a 12 percentage point improvement over prior methods. Further, Domino is the first SDM that can provide natural language descriptions of identified slices, correctly generating the exact name of the slice in 35\% of settings.},
	urldate = {2022-11-16},
	publisher = {arXiv},
	author = {Eyuboglu, Sabri and Varma, Maya and Saab, Khaled and Delbrouck, Jean-Benoit and Lee-Messer, Christopher and Dunnmon, Jared and Zou, James and Ré, Christopher},
	month = may,
	year = {2022},
	note = {arXiv:2203.14960 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, slice},
}

@misc{SpotlightGeneralMethodDiscoveringSystematic,
	title = {The {Spotlight}: {A} {General} {Method} for {Discovering} {Systematic} {Errors} in {Deep} {Learning} {Models}},
	shorttitle = {The {Spotlight}},
	url = {http://arxiv.org/abs/2107.00758},
	abstract = {Supervised learning models often make systematic errors on rare subsets of the data. When these subsets correspond to explicit labels in the data (e.g., gender, race) such poor performance can be identified straightforwardly. This paper introduces a method for discovering systematic errors that do not correspond to such explicitly labelled subgroups. The key idea is that similar inputs tend to have similar representations in the final hidden layer of a neural network. We leverage this structure by "shining a spotlight" on this representation space to find contiguous regions where the model performs poorly. We show that the spotlight surfaces semantically meaningful areas of weakness in a wide variety of existing models spanning computer vision, NLP, and recommender systems.},
	urldate = {2022-11-15},
	publisher = {arXiv},
	author = {d'Eon, Greg and d'Eon, Jason and Wright, James R. and Leyton-Brown, Kevin},
	month = oct,
	year = {2021},
	note = {arXiv:2107.00758 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, dm, uu},
}

@misc{MinorityMattersDiversityPromotingCollaborativeMetric,
	title = {The {Minority} {Matters}: {A} {Diversity}-{Promoting} {Collaborative} {Metric} {Learning} {Algorithm}},
	shorttitle = {The {Minority} {Matters}},
	url = {http://arxiv.org/abs/2209.15292},
	abstract = {Collaborative Metric Learning (CML) has recently emerged as a popular method in recommendation systems (RS), closing the gap between metric learning and Collaborative Filtering. Following the convention of RS, existing methods exploit unique user representation in their model design. This paper focuses on a challenging scenario where a user has multiple categories of interests. Under this setting, we argue that the unique user representation might induce preference bias, especially when the item category distribution is imbalanced. To address this issue, we propose a novel method called {\textbackslash}textit\{Diversity-Promoting Collaborative Metric Learning\} (DPCML), with the hope of considering the commonly ignored minority interest of the user. The key idea behind DPCML is to include a multiple set of representations for each user in the system. Based on this embedding paradigm, user preference toward an item is aggregated from different embeddings by taking the minimum item-user distance among the user embedding set. Furthermore, we observe that the diversity of the embeddings for the same user also plays an essential role in the model. To this end, we propose a {\textbackslash}textit\{diversity control regularization\} term to accommodate the multi-vector representation strategy better. Theoretically, we show that DPCML could generalize well to unseen test data by tackling the challenge of the annoying operation that comes from the minimum value. Experiments over a range of benchmark datasets speak to the efficacy of DPCML.},
	urldate = {2022-12-05},
	publisher = {arXiv},
	author = {Bao, Shilong and Xu, Qianqian and Yang, Zhiyong and He, Yuan and Cao, Xiaochun and Huang, Qingming},
	month = sep,
	year = {2022},
	note = {arXiv:2209.15292 [cs]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, diversity, minority, rec},
}

@misc{BiasDisparityCollaborativeRecommendationAlgorithmic,
	title = {Bias {Disparity} in {Collaborative} {Recommendation}: {Algorithmic} {Evaluation} and {Comparison}},
	shorttitle = {Bias {Disparity} in {Collaborative} {Recommendation}},
	url = {http://arxiv.org/abs/1908.00831},
	abstract = {Research on fairness in machine learning has been recently extended to recommender systems. One of the factors that may impact fairness is bias disparity, the degree to which a group's preferences on various item categories fail to be reflected in the recommendations they receive. In some cases biases in the original data may be amplified or reversed by the underlying recommendation algorithm. In this paper, we explore how different recommendation algorithms reflect the tradeoff between ranking quality and bias disparity. Our experiments include neighborhood-based, model-based, and trust-aware recommendation algorithms.},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Mansoury, Masoud and Mobasher, Bamshad and Burke, Robin and Pechenizkiy, Mykola},
	month = aug,
	year = {2019},
	note = {arXiv:1908.00831 [cs]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Computer Science - Social and Information Networks, rec, stereotype},
}

@misc{ScalableRealisticRecommendationDatasetsFractal,
	title = {Scalable {Realistic} {Recommendation} {Datasets} through {Fractal} {Expansions}},
	url = {http://arxiv.org/abs/1901.08910},
	abstract = {Recommender System research suffers currently from a disconnect between the size of academic data sets and the scale of industrial production systems. In order to bridge that gap we propose to generate more massive user/item interaction data sets by expanding pre-existing public data sets. User/item incidence matrices record interactions between users and items on a given platform as a large sparse matrix whose rows correspond to users and whose columns correspond to items. Our technique expands such matrices to larger numbers of rows (users), columns (items) and non zero values (interactions) while preserving key higher order statistical properties. We adapt the Kronecker Graph Theory to user/item incidence matrices and show that the corresponding fractal expansions preserve the fat-tailed distributions of user engagements, item popularity and singular value spectra of user/item interaction matrices. Preserving such properties is key to building large realistic synthetic data sets which in turn can be employed reliably to benchmark Recommender Systems and the systems employed to train them. We provide algorithms to produce such expansions and apply them to the MovieLens 20 million data set comprising 20 million ratings of 27K movies by 138K users. The resulting expanded data set has 10 billion ratings, 864K items and 2 million users in its smaller version and can be scaled up or down. A larger version features 655 billion ratings, 7 million items and 17 million users.},
	urldate = {2022-12-22},
	publisher = {arXiv},
	author = {Belletti, Francois and Lakshmanan, Karthik and Krichene, Walid and Chen, Yi-Fan and Anderson, John},
	month = feb,
	year = {2019},
	note = {arXiv:1901.08910 [cs, stat]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, H.3.3, I.2.6, Statistics - Machine Learning, dm, expansion},
}

@misc{PinkPrincessesBlueSuperheroesNeed,
	title = {Pink for {Princesses}, {Blue} for {Superheroes}: {The} {Need} to {Examine} {Gender} {Stereotypes} in {Kid}'s {Products} in {Search} and {Recommendations}},
	shorttitle = {Pink for {Princesses}, {Blue} for {Superheroes}},
	url = {http://arxiv.org/abs/2105.09296},
	abstract = {In this position paper, we argue for the need to investigate if and how gender stereotypes manifest in search and recommender systems.As a starting point, we particularly focus on how these systems may propagate and reinforce gender stereotypes through their results in learning environments, a context where teachers and children in their formative stage regularly interact with these systems. We provide motivating examples supporting our concerns and outline an agenda to support future research addressing the phenomena.},
	urldate = {2022-12-20},
	publisher = {arXiv},
	author = {Raj, Amifa and Milton, Ashlee and Ekstrand, Michael D.},
	month = may,
	year = {2021},
	note = {arXiv:2105.09296 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Information Retrieval, rec, sterotype},
}

@misc{SEALInteractiveToolSystematicError,
	title = {{SEAL} : {Interactive} {Tool} for {Systematic} {Error} {Analysis} and {Labeling}},
	shorttitle = {{SEAL}},
	url = {http://arxiv.org/abs/2210.05839},
	abstract = {With the advent of Transformers, large language models (LLMs) have saturated well-known NLP benchmarks and leaderboards with high aggregate performance. However, many times these models systematically fail on tail data or rare groups not obvious in aggregate evaluation. Identifying such problematic data groups is even more challenging when there are no explicit labels (e.g., ethnicity, gender, etc.) and further compounded for NLP datasets due to the lack of visual features to characterize failure modes (e.g., Asian males, animals indoors, waterbirds on land, etc.). This paper introduces an interactive Systematic Error Analysis and Labeling ({\textbackslash}seal) tool that uses a two-step approach to first identify high error slices of data and then, in the second step, introduce methods to give human-understandable semantics to those underperforming slices. We explore a variety of methods for coming up with coherent semantics for the error groups using language models for semantic labeling and a text-to-image model for generating visual features. SEAL toolkit and demo screencast is available at https://huggingface.co/spaces/nazneen/seal.},
	urldate = {2022-12-08},
	publisher = {arXiv},
	author = {Rajani, Nazneen and Liang, Weixin and Chen, Lingjiao and Mitchell, Meg and Zou, James},
	month = oct,
	year = {2022},
	note = {arXiv:2210.05839 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
}

@misc{MeasuringRecommenderSystemEffectsSimulated,
	title = {Measuring {Recommender} {System} {Effects} with {Simulated} {Users}},
	url = {http://arxiv.org/abs/2101.04526},
	abstract = {Imagine a food recommender system -- how would we check if it is {\textbackslash}emph\{causing\} and fostering unhealthy eating habits or merely reflecting users' interests? How much of a user's experience over time with a recommender is caused by the recommender system's choices and biases, and how much is based on the user's preferences and biases? Popularity bias and filter bubbles are two of the most well-studied recommender system biases, but most of the prior research has focused on understanding the system behavior in a single recommendation step. How do these biases interplay with user behavior, and what types of user experiences are created from repeated interactions? In this work, we offer a simulation framework for measuring the impact of a recommender system under different types of user behavior. Using this simulation framework, we can (a) isolate the effect of the recommender system from the user preferences, and (b) examine how the system performs not just on average for an "average user" but also the extreme experiences under atypical user behavior. As part of the simulation framework, we propose a set of evaluation metrics over the simulations to understand the recommender system's behavior. Finally, we present two empirical case studies -- one on traditional collaborative filtering in MovieLens and one on a large-scale production recommender system -- to understand how popularity bias manifests over time.},
	urldate = {2022-12-05},
	publisher = {arXiv},
	author = {Yao, Sirui and Halpern, Yoni and Thain, Nithum and Wang, Xuezhi and Lee, Kang and Prost, Flavien and Chi, Ed H. and Chen, Jilin and Beutel, Alex},
	month = jan,
	year = {2021},
	note = {arXiv:2101.04526 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Information Retrieval, Computer Science - Machine Learning, rec},
}

@misc{ExplainableRecommendationsAttentiveMultiPersonaCollaborative,
	title = {Explainable {Recommendations} via {Attentive} {Multi}-{Persona} {Collaborative} {Filtering}},
	url = {http://arxiv.org/abs/2010.07042},
	abstract = {Two main challenges in recommender systems are modeling users with heterogeneous taste, and providing explainable recommendations. In this paper, we propose the neural Attentive Multi-Persona Collaborative Filtering (AMP-CF) model as a unified solution for both problems. AMP-CF breaks down the user to several latent 'personas' (profiles) that identify and discern the different tastes and inclinations of the user. Then, the revealed personas are used to generate and explain the final recommendation list for the user. AMP-CF models users as an attentive mixture of personas, enabling a dynamic user representation that changes based on the item under consideration. We demonstrate AMP-CF on five collaborative filtering datasets from the domains of movies, music, video games and social networks. As an additional contribution, we propose a novel evaluation scheme for comparing the different items in a recommendation list based on the distance from the underlying distribution of "tastes" in the user's historical items. Experimental results show that AMP-CF is competitive with other state-of-the-art models. Finally, we provide qualitative results to showcase the ability of AMP-CF to explain its recommendations.},
	urldate = {2022-12-05},
	publisher = {arXiv},
	author = {Barkan, Oren and Fuchs, Yonatan and Caciularu, Avi and Koenigstein, Noam},
	month = sep,
	year = {2020},
	note = {arXiv:2010.07042 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Machine Learning, persona, prototype, rec},
}

@misc{Fairnessrepresentationquantifyingstereotypingrepresentational,
	title = {Fairness in representation: quantifying stereotyping as a representational harm},
	shorttitle = {Fairness in representation},
	url = {http://arxiv.org/abs/1901.09565},
	abstract = {While harms of allocation have been increasingly studied as part of the subfield of algorithmic fairness, harms of representation have received considerably less attention. In this paper, we formalize two notions of stereotyping and show how they manifest in later allocative harms within the machine learning pipeline. We also propose mitigation strategies and demonstrate their effectiveness on synthetic datasets.},
	urldate = {2022-12-28},
	publisher = {arXiv},
	author = {Abbasi, Mohsen and Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh},
	month = jan,
	year = {2019},
	note = {arXiv:1901.09565 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, stereotype},
}

@misc{ImpactPopularityBiasFairnessCalibration,
	title = {The {Impact} of {Popularity} {Bias} on {Fairness} and {Calibration} in {Recommendation}},
	url = {http://arxiv.org/abs/1910.05755},
	abstract = {Recently there has been a growing interest in fairness-aware recommender systems, including fairness in providing consistent performance across di erent users or groups of users. A recommender system could be considered unfair if the recommendations do not fairly represent the tastes of a certain group of users while other groups receive recommendations that are consistent with their preferences. In this paper, we use a metric called miscalibration for measuring how a recommendation algorithm is responsive to users’ true preferences and we consider how various algorithms may result in di erent degrees of miscalibration. A well-known type of bias in recommendation is popularity bias where few popular items are over-represented in recommendations, while the majority of other items do not get signi cant exposure. We conjecture that popularity bias is one important factor leading to miscalibration in recommendation. Our experimental results using two real-world datasets show that there is a strong correlation between how different user groups are a ected by algorithmic popularity bias and their level of interest in popular items. Moreover, we show that the more a group is a ected by the algorithmic popularity bias, the more their recommendations are miscalibrated. Finally, we show that the algorithms with greater popularity bias ampli cation tend to have greater overall miscalibration.},
	language = {en},
	urldate = {2022-12-26},
	publisher = {arXiv},
	author = {Abdollahpouri, Himan and Mansoury, Masoud and Burke, Robin and Mobasher, Bamshad},
	month = oct,
	year = {2019},
	note = {arXiv:1910.05755 [cs]},
	keywords = {Computer Science - Information Retrieval},
}

@misc{COFFEECounterfactualFairnessPersonalizedText,
	title = {{COFFEE}: {Counterfactual} {Fairness} for {Personalized} {Text} {Generation} in {Explainable} {Recommendation}},
	shorttitle = {{COFFEE}},
	url = {http://arxiv.org/abs/2210.15500},
	abstract = {Personalized text generation has broad industrial applications, such as explanation generation for recommendations, conversational systems, etc. Personalized text generators are usually trained on user written text, e.g., reviews collected on e-commerce platforms. However, due to historical, social, or behavioral reasons, there may exist bias that associates certain linguistic quality of user written text with the users’ protected attributes such as gender, race, etc. The generators can identify and inherit these correlations and generate texts discriminately w.r.t. the users’ protected attributes. Without proper intervention, such bias can adversarially influence the users’ trust and reliance on the system. From a broader perspective, bias in auto-generated contents can reinforce the social stereotypes about how online users write through interactions with the users.},
	language = {en},
	urldate = {2022-12-26},
	publisher = {arXiv},
	author = {Wang, Nan and Nie, Shaoliang and Wang, Qifan and Wang, Yi-Chia and Sanjabi, Maziar and Liu, Jingzhou and Firooz, Hamed and Wang, Hongning},
	month = oct,
	year = {2022},
	note = {arXiv:2210.15500 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Information Retrieval, Computer Science - Machine Learning},
}

@misc{ExplanationOntologyModelExplanationsUserCentered,
	title = {Explanation {Ontology}: {A} {Model} of {Explanations} for {User}-{Centered} {AI}},
	shorttitle = {Explanation {Ontology}},
	url = {http://arxiv.org/abs/2010.01479},
	abstract = {Explainability has been a goal for Artificial Intelligence (AI) systems since their conception, with the need for explainability growing as more complex AI models are increasingly used in critical, high-stakes settings such as healthcare. Explanations have often added to an AI system in a non-principled, post-hoc manner. With greater adoption of these systems and emphasis on user-centric explainability, there is a need for a structured representation that treats explainability as a primary consideration, mapping end user needs to specific explanation types and the system's AI capabilities. We design an explanation ontology to model both the role of explanations, accounting for the system and user attributes in the process, and the range of different literature-derived explanation types. We indicate how the ontology can support user requirements for explanations in the domain of healthcare. We evaluate our ontology with a set of competency questions geared towards a system designer who might use our ontology to decide which explanation types to include, given a combination of users' needs and a system's capabilities, both in system design settings and in real-time operations. Through the use of this ontology, system designers will be able to make informed choices on which explanations AI systems can and should provide.},
	urldate = {2022-12-24},
	publisher = {arXiv},
	author = {Chari, Shruthi and Seneviratne, Oshani and Gruen, Daniel M. and Foreman, Morgan A. and Das, Amar K. and McGuinness, Deborah L.},
	month = oct,
	year = {2020},
	note = {arXiv:2010.01479 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, explanation},
}

@misc{HumanCenteredExplainableAIXAIAlgorithms,
	title = {Human-{Centered} {Explainable} {AI} ({XAI}): {From} {Algorithms} to {User} {Experiences}},
	shorttitle = {Human-{Centered} {Explainable} {AI} ({XAI})},
	url = {http://arxiv.org/abs/2110.10790},
	abstract = {In recent years, the field of explainable AI (XAI) has produced a vast collection of algorithms, providing a useful toolbox for researchers and practitioners to build XAI applications. With the rich application opportunities, explainability is believed to have moved beyond a demand by data scientists or researchers to comprehend the models they develop, to an essential requirement for people to trust and adopt AI deployed in numerous domains. However, explainability is an inherently human-centric property and the field is starting to embrace human-centered approaches. Human-computer interaction (HCI) research and user experience (UX) design in this area are becoming increasingly important. In this chapter, we begin with a high-level overview of the technical landscape of XAI algorithms, then selectively survey our own and other recent HCI works that take human-centered approaches to design, evaluate, and provide conceptual and methodological tools for XAI. We ask the question "what are human-centered approaches doing for XAI" and highlight three roles that they play in shaping XAI technologies by helping navigate, assess and expand the XAI toolbox: to drive technical choices by users' explainability needs, to uncover pitfalls of existing XAI methods and inform new methods, and to provide conceptual frameworks for human-compatible XAI.},
	urldate = {2023-01-03},
	publisher = {arXiv},
	author = {Liao, Q. Vera and Varshney, Kush R.},
	month = apr,
	year = {2022},
	note = {arXiv:2110.10790 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, cognitive, explanation},
}

@misc{InfluenceCognitiveStylesUsersUnderstandinga,
	title = {On the {Influence} of {Cognitive} {Styles} on {Users}' {Understanding} of {Explanations}},
	url = {http://arxiv.org/abs/2210.02123},
	abstract = {Artificial intelligence (AI) is becoming increasingly complex, making it difficult for users to understand how the AI has derived its prediction. Using explainable AI (XAI)-methods, researchers aim to explain AI decisions to users. So far, XAI-based explanations pursue a technology-focused approach - neglecting the influence of users' cognitive abilities and differences in information processing on the understanding of explanations. Hence, this study takes a human-centered perspective and incorporates insights from cognitive psychology. In particular, we draw on the psychological construct of cognitive styles that describe humans' characteristic modes of processing information. Applying a between-subject experiment design, we investigate how users' rational and intuitive cognitive styles affect their objective and subjective understanding of different types of explanations provided by an AI. Initial results indicate substantial differences in users' understanding depending on their cognitive style. We expect to contribute to a more nuanced view of the interrelation of human factors and XAI design.},
	urldate = {2023-01-03},
	publisher = {arXiv},
	author = {Riefle, Lara and Hemmer, Patrick and Benz, Carina and Vössing, Michael and Pries, Jannik},
	month = oct,
	year = {2022},
	note = {arXiv:2210.02123 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, cognitive, explanation},
}

@misc{InfluenceCognitiveStylesUsersUnderstanding,
	title = {On the {Influence} of {Cognitive} {Styles} on {Users}' {Understanding} of {Explanations}},
	url = {http://arxiv.org/abs/2210.02123},
	abstract = {Artificial intelligence (AI) is becoming increasingly complex, making it difficult for users to understand how the AI has derived its prediction. Using explainable AI (XAI)-methods, researchers aim to explain AI decisions to users. So far, XAI-based explanations pursue a technology-focused approach - neglecting the influence of users' cognitive abilities and differences in information processing on the understanding of explanations. Hence, this study takes a human-centered perspective and incorporates insights from cognitive psychology. In particular, we draw on the psychological construct of cognitive styles that describe humans' characteristic modes of processing information. Applying a between-subject experiment design, we investigate how users' rational and intuitive cognitive styles affect their objective and subjective understanding of different types of explanations provided by an AI. Initial results indicate substantial differences in users' understanding depending on their cognitive style. We expect to contribute to a more nuanced view of the interrelation of human factors and XAI design.},
	urldate = {2023-01-01},
	publisher = {arXiv},
	author = {Riefle, Lara and Hemmer, Patrick and Benz, Carina and Vössing, Michael and Pries, Jannik},
	month = oct,
	year = {2022},
	note = {arXiv:2210.02123 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, cognitive, decision-making, explanation},
}

@misc{WhyMyClassifierDiscriminatory,
	title = {Why {Is} {My} {Classifier} {Discriminatory}?},
	url = {http://arxiv.org/abs/1805.12002},
	abstract = {Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.},
	urldate = {2022-12-31},
	publisher = {arXiv},
	author = {Chen, Irene and Johansson, Fredrik D. and Sontag, David},
	month = dec,
	year = {2018},
	note = {arXiv:1805.12002 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, fair},
}

@misc{FairnessRecommendationSurveya,
	title = {Fairness in {Recommendation}: {A} {Survey}},
	shorttitle = {Fairness in {Recommendation}},
	url = {http://arxiv.org/abs/2205.13619},
	abstract = {As one of the most pervasive applications of machine learning, recommender systems are playing an important role on assisting human decision making. The satisfaction of users and the interests of platforms are closely related to the quality of the generated recommendation results. However, as a highly data-driven system, recommender system could be affected by data or algorithmic bias and thus generate unfair results, which could weaken the reliance of the systems. As a result, it is crucial to address the potential unfairness problems in recommendation settings. Recently, there has been growing attention on fairness considerations in recommender systems with more and more literature on approaches to promote fairness in recommendation. However, the studies are rather fragmented and lack a systematic organization, thus making it difficult to penetrate for new researchers to the domain. This motivates us to provide a systematic survey of existing works on fairness in recommendation. This survey focuses on the foundations for fairness in recommendation literature. It first presents a brief introduction about fairness in basic machine learning tasks such as classification and ranking in order to provide a general overview of fairness research, as well as introduce the more complex situations and challenges that need to be considered when studying fairness in recommender systems. After that, the survey will introduce fairness in recommendation with a focus on the taxonomies of current fairness definitions, the typical techniques for improving fairness, as well as the datasets for fairness studies in recommendation. The survey also talks about the challenges and opportunities in fairness research with the hope of promoting the fair recommendation research area and beyond.},
	urldate = {2022-12-29},
	publisher = {arXiv},
	author = {Li, Yunqi and Chen, Hanxiong and Xu, Shuyuan and Ge, Yingqiang and Tan, Juntao and Liu, Shuchang and Zhang, Yongfeng},
	month = jun,
	year = {2022},
	note = {arXiv:2205.13619 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Machine Learning, rec},
}

@misc{UnifiedTheoryDiversityEnsembleLearning,
	title = {A {Unified} {Theory} of {Diversity} in {Ensemble} {Learning}},
	url = {http://arxiv.org/abs/2301.03962},
	abstract = {We present a theory of ensemble diversity, explaining the nature and effect of diversity for a wide range of supervised learning scenarios. This challenge, of understanding ensemble diversity, has been referred to as the holy grail of ensemble learning, an open question for over 30 years. Our framework reveals that diversity is in fact a hidden dimension in the bias-variance decomposition of an ensemble. In particular, we prove a family of exact bias-variance-diversity decompositions, for both classification and regression losses, e.g., squared, and cross-entropy. The framework provides a methodology to automatically identify the combiner rule enabling such a decomposition, specific to the loss. The formulation of diversity is therefore dependent on just two design choices: the loss, and the combiner. For certain choices (e.g., 0-1 loss with majority voting) the effect of diversity is necessarily dependent on the target label. Experiments illustrate how we can use our framework to understand the diversity-encouraging mechanisms of popular ensemble methods: Bagging, Boosting, and Random Forests.},
	urldate = {2023-01-24},
	publisher = {arXiv},
	author = {Wood, Danny and Mu, Tingting and Webb, Andrew and Reeve, Henry and Lujan, Mikel and Brown, Gavin},
	month = jan,
	year = {2023},
	note = {arXiv:2301.03962 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, bias-variance},
}

@misc{DefenceVisualAnalyticsSystemsReplies,
	title = {In {Defence} of {Visual} {Analytics} {Systems}: {Replies} to {Critics}},
	shorttitle = {In {Defence} of {Visual} {Analytics} {Systems}},
	url = {http://arxiv.org/abs/2201.09772},
	abstract = {The last decade has witnessed many visual analytics (VA) systems that make successful applications to wide-ranging domains like urban analytics and explainable AI. However, their research rigor and contributions have been extensively challenged within the visualization community. We come in defence of VA systems by contributing two interview studies for gathering critics and responses to those criticisms. First, we interview 24 researchers to collect criticisms the review comments on their VA work. Through an iterative coding and refinement process, the interview feedback is summarized into a list of 36 common criticisms. Second, we interview 17 researchers to validate our list and collect their responses, thereby discussing implications for defending and improving the scientific values and rigor of VA systems. We highlight that the presented knowledge is deep, extensive, but also imperfect, provocative, and controversial, and thus recommend reading with an inclusive and critical eye. We hope our work can provide thoughts and foundations for conducting VA research and spark discussions to promote the research field forward more rigorously and vibrantly.},
	urldate = {2023-01-17},
	publisher = {arXiv},
	author = {Wu, Aoyu and Deng, Dazhen and Cheng, Furui and Wu, Yingcai and Liu, Shixia and Qu, Huamin},
	month = aug,
	year = {2022},
	note = {arXiv:2201.09772 [cs]},
	keywords = {Computer Science - Graphics, Computer Science - Human-Computer Interaction, vis},
}

@misc{OverconfidencePrejudice,
	title = {Overconfidence and {Prejudice}},
	url = {http://arxiv.org/abs/1909.08497},
	abstract = {We explore conclusions a person draws from observing society when he allows for the possibility that individuals' outcomes are affected by group-level discrimination. Injecting a single non-classical assumption, that the agent is overconfident about himself, we explain key observed patterns in social beliefs, and make a number of additional predictions. First, the agent believes in discrimination against any group he is in more than an outsider does, capturing widely observed self-centered views of discrimination. Second, the more group memberships the agent shares with an individual, the more positively he evaluates the individual. This explains one of the most basic facts about social judgments, in-group bias, as well as "legitimizing myths" that justify an arbitrary social hierarchy through the perceived superiority of the privileged group. Third, biases are sensitive to how the agent divides society into groups when evaluating outcomes. This provides a reason why some ethnically charged questions should not be asked, as well as a potential channel for why nation-building policies might be effective. Fourth, giving the agent more accurate information about himself increases all his biases. Fifth, the agent is prone to substitute biases, implying that the introduction of a new outsider group to focus on creates biases against the new group but lowers biases vis a vis other groups. Sixth, there is a tendency for the agent to agree more with those in the same groups. As a microfoundation for our model, we provide an explanation for why an overconfident agent might allow for potential discrimination in evaluating outcomes, even when he initially did not conceive of this possibility.},
	urldate = {2023-01-09},
	publisher = {arXiv},
	author = {Heidhues, Paul and Kőszegi, Botond and Strack, Philipp},
	month = sep,
	year = {2019},
	note = {arXiv:1909.08497 [econ]},
	keywords = {Economics - Theoretical Economics, stereotype},
}

@misc{RethinkingBiasVarianceTradeoffGeneralizationNeural,
	title = {Rethinking {Bias}-{Variance} {Trade}-off for {Generalization} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/2002.11328},
	abstract = {The classical bias-variance trade-off predicts that bias decreases and variance increase with model complexity, leading to a U-shaped risk curve. Recent work calls this into question for neural networks and other over-parameterized models, for which it is often observed that larger models generalize better. We provide a simple explanation for this by measuring the bias and variance of neural networks: while the bias is monotonically decreasing as in the classical theory, the variance is unimodal or bell-shaped: it increases then decreases with the width of the network. We vary the network architecture, loss function, and choice of dataset and confirm that variance unimodality occurs robustly for all models we considered. The risk curve is the sum of the bias and variance curves and displays different qualitative shapes depending on the relative scale of bias and variance, with the double descent curve observed in recent literature as a special case. We corroborate these empirical results with a theoretical analysis of two-layer linear networks with random first layer. Finally, evaluation on out-of-distribution data shows that most of the drop in accuracy comes from increased bias while variance increases by a relatively small amount. Moreover, we find that deeper models decrease bias and increase variance for both in-distribution and out-of-distribution data.},
	urldate = {2023-01-08},
	publisher = {arXiv},
	author = {Yang, Zitong and Yu, Yaodong and You, Chong and Steinhardt, Jacob and Ma, Yi},
	month = dec,
	year = {2020},
	note = {arXiv:2002.11328 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, bias-variance},
}

@misc{DaisyRecBenchmarkingRecommendationRigorousEvaluation,
	title = {{DaisyRec} 2.0: {Benchmarking} {Recommendation} for {Rigorous} {Evaluation}},
	shorttitle = {{DaisyRec} 2.0},
	url = {http://arxiv.org/abs/2206.10848},
	abstract = {Recently, one critical issue looms large in the field of recommender systems -- there are no effective benchmarks for rigorous evaluation -- which consequently leads to unreproducible evaluation and unfair comparison. We, therefore, conduct studies from the perspectives of practical theory and experiments, aiming at benchmarking recommendation for rigorous evaluation. Regarding the theoretical study, a series of hyper-factors affecting recommendation performance throughout the whole evaluation chain are systematically summarized and analyzed via an exhaustive review on 141 papers published at eight top-tier conferences within 2017-2020. We then classify them into model-independent and model-dependent hyper-factors, and different modes of rigorous evaluation are defined and discussed in-depth accordingly. For the experimental study, we release DaisyRec 2.0 library by integrating these hyper-factors to perform rigorous evaluation, whereby a holistic empirical study is conducted to unveil the impacts of different hyper-factors on recommendation performance. Supported by the theoretical and experimental studies, we finally create benchmarks for rigorous evaluation by proposing standardized procedures and providing performance of ten state-of-the-arts across six evaluation metrics on six datasets as a reference for later study. Overall, our work sheds light on the issues in recommendation evaluation, provides potential solutions for rigorous evaluation, and lays foundation for further investigation.},
	urldate = {2023-02-12},
	publisher = {arXiv},
	author = {Sun, Zhu and Fang, Hui and Yang, Jie and Qu, Xinghua and Liu, Hongyang and Yu, Di and Ong, Yew-Soon and Zhang, Jie},
	month = jun,
	year = {2022},
	note = {arXiv:2206.10848 [cs]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, rec},
}

@misc{CollaborativeFilteringStability,
	title = {Collaborative {Filtering} with {Stability}},
	url = {http://arxiv.org/abs/1811.02198},
	abstract = {Collaborative filtering (CF) is a popular technique in today's recommender systems, and matrix approximation-based CF methods have achieved great success in both rating prediction and top-N recommendation tasks. However, real-world user-item rating matrices are typically sparse, incomplete and noisy, which introduce challenges to the algorithm stability of matrix approximation, i.e., small changes in the training data may significantly change the models. As a result, existing matrix approximation solutions yield low generalization performance, exhibiting high error variance on the training data, and minimizing the training error may not guarantee error reduction on the test data. This paper investigates the algorithm stability problem of matrix approximation methods and how to achieve stable collaborative filtering via stable matrix approximation. We present a new algorithm design framework, which (1) introduces new optimization objectives to guide stable matrix approximation algorithm design, and (2) solves the optimization problem to obtain stable approximation solutions with good generalization performance. Experimental results on real-world datasets demonstrate that the proposed method can achieve better accuracy compared with state-of-the-art matrix approximation methods and ensemble methods in both rating prediction and top-N recommendation tasks.},
	urldate = {2023-02-12},
	publisher = {arXiv},
	author = {Li, Dongsheng and Chen, Chao and Lv, Qin and Yan, Junchi and Shang, Li and Chu, Stephen M.},
	month = nov,
	year = {2018},
	note = {arXiv:1811.02198 [cs, stat]
version: 1},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Statistics - Machine Learning, rec},
}

@misc{HumanAISymbiosisSurveyCurrentApproaches,
	title = {Human-{AI} {Symbiosis}: {A} {Survey} of {Current} {Approaches}},
	shorttitle = {Human-{AI} {Symbiosis}},
	url = {http://arxiv.org/abs/2103.09990},
	abstract = {In this paper, we aim at providing a comprehensive outline of the different threads of work in human-AI collaboration. By highlighting various aspects of works on the human-AI team such as the flow of complementing, task horizon, model representation, knowledge level, and teaming goal, we make a taxonomy of recent works according to these dimensions. We hope that the survey will provide a more clear connection between the works in the human-AI team and guidance to new researchers in this area.},
	urldate = {2023-02-11},
	publisher = {arXiv},
	author = {Zahedi, Zahra and Kambhampati, Subbarao},
	month = mar,
	year = {2021},
	note = {arXiv:2103.09990 [cs]},
	keywords = {Computer Science - Artificial Intelligence, fatml, survey, xai},
}

@misc{ExploringDataSplittingStrategiesEvaluation,
	title = {Exploring {Data} {Splitting} {Strategies} for the {Evaluation} of {Recommendation} {Models}},
	url = {http://arxiv.org/abs/2007.13237},
	abstract = {Effective methodologies for evaluating recommender systems are critical, so that such systems can be compared in a sound manner. A commonly overlooked aspect of recommender system evaluation is the selection of the data splitting strategy. In this paper, we both show that there is no standard splitting strategy and that the selection of splitting strategy can have a strong impact on the ranking of recommender systems. In particular, we perform experiments comparing three common splitting strategies, examining their impact over seven state-of-the-art recommendation models for two datasets. Our results demonstrate that the splitting strategy employed is an important confounding variable that can markedly alter the ranking of state-of-the-art systems, making much of the currently published literature non-comparable, even when the same dataset and metrics are used.},
	urldate = {2023-02-10},
	publisher = {arXiv},
	author = {Meng, Zaiqiao and McCreadie, Richard and Macdonald, Craig and Ounis, Iadh},
	month = jul,
	year = {2020},
	note = {arXiv:2007.13237 [cs]},
	keywords = {Computer Science - Information Retrieval, rec},
}

@misc{ChartingSociotechnicalGapExplainableAI,
	title = {Charting the {Sociotechnical} {Gap} in {Explainable} {AI}: {A} {Framework} to {Address} the {Gap} in {XAI}},
	shorttitle = {Charting the {Sociotechnical} {Gap} in {Explainable} {AI}},
	url = {http://arxiv.org/abs/2302.00799},
	doi = {10.1145/3579467},
	abstract = {Explainable AI (XAI) systems are sociotechnical in nature; thus, they are subject to the sociotechnical gap--divide between the technical affordances and the social needs. However, charting this gap is challenging. In the context of XAI, we argue that charting the gap improves our problem understanding, which can reflexively provide actionable insights to improve explainability. Utilizing two case studies in distinct domains, we empirically derive a framework that facilitates systematic charting of the sociotechnical gap by connecting AI guidelines in the context of XAI and elucidating how to use them to address the gap. We apply the framework to a third case in a new domain, showcasing its affordances. Finally, we discuss conceptual implications of the framework, share practical considerations in its operationalization, and offer guidance on transferring it to new contexts. By making conceptual and practical contributions to understanding the sociotechnical gap in XAI, the framework expands the XAI design space.},
	urldate = {2023-02-09},
	author = {Ehsan, Upol and Saha, Koustuv and De Choudhury, Munmun and Riedl, Mark O.},
	month = feb,
	year = {2023},
	note = {arXiv:2302.00799 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, framework, xai},
}

@misc{DaisyRecBenchmarkingRecommendationRigorousEvaluationa,
	title = {{DaisyRec} 2.0: {Benchmarking} {Recommendation} for {Rigorous} {Evaluation}},
	shorttitle = {{DaisyRec} 2.0},
	url = {http://arxiv.org/abs/2206.10848},
	abstract = {Recently, one critical issue looms large in the field of recommender systems -- there are no effective benchmarks for rigorous evaluation -- which consequently leads to unreproducible evaluation and unfair comparison. We, therefore, conduct studies from the perspectives of practical theory and experiments, aiming at benchmarking recommendation for rigorous evaluation. Regarding the theoretical study, a series of hyper-factors affecting recommendation performance throughout the whole evaluation chain are systematically summarized and analyzed via an exhaustive review on 141 papers published at eight top-tier conferences within 2017-2020. We then classify them into model-independent and model-dependent hyper-factors, and different modes of rigorous evaluation are defined and discussed in-depth accordingly. For the experimental study, we release DaisyRec 2.0 library by integrating these hyper-factors to perform rigorous evaluation, whereby a holistic empirical study is conducted to unveil the impacts of different hyper-factors on recommendation performance. Supported by the theoretical and experimental studies, we finally create benchmarks for rigorous evaluation by proposing standardized procedures and providing performance of ten state-of-the-arts across six evaluation metrics on six datasets as a reference for later study. Overall, our work sheds light on the issues in recommendation evaluation, provides potential solutions for rigorous evaluation, and lays foundation for further investigation.},
	urldate = {2023-02-19},
	publisher = {arXiv},
	author = {Sun, Zhu and Fang, Hui and Yang, Jie and Qu, Xinghua and Liu, Hongyang and Yu, Di and Ong, Yew-Soon and Zhang, Jie},
	month = jun,
	year = {2022},
	note = {arXiv:2206.10848 [cs]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, rec},
}

@misc{ShouldWeTrustAIDesign,
	title = {Should {We} {Trust} ({X}){AI}? {Design} {Dimensions} for {Structured} {Experimental} {Evaluations}},
	shorttitle = {Should {We} {Trust} ({X}){AI}?},
	url = {http://arxiv.org/abs/2009.06433},
	abstract = {This paper systematically derives design dimensions for the structured evaluation of explainable artificial intelligence (XAI) approaches. These dimensions enable a descriptive characterization, facilitating comparisons between different study designs. They further structure the design space of XAI, converging towards a precise terminology required for a rigorous study of XAI. Our literature review differentiates between comparative studies and application papers, revealing methodological differences between the fields of machine learning, human-computer interaction, and visual analytics. Generally, each of these disciplines targets specific parts of the XAI process. Bridging the resulting gaps enables a holistic evaluation of XAI in real-world scenarios, as proposed by our conceptual model characterizing bias sources and trust-building. Furthermore, we identify and discuss the potential for future work based on observed research gaps that should lead to better coverage of the proposed model.},
	urldate = {2023-02-16},
	publisher = {arXiv},
	author = {Sperrle, Fabian and El-Assady, Mennatallah and Guo, Grace and Chau, Duen Horng and Endert, Alex and Keim, Daniel},
	month = sep,
	year = {2020},
	note = {arXiv:2009.06433 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, vis, xai},
}

@misc{ExploringDataSplittingStrategiesEvaluationa,
	title = {Exploring {Data} {Splitting} {Strategies} for the {Evaluation} of {Recommendation} {Models}},
	url = {http://arxiv.org/abs/2007.13237},
	abstract = {Effective methodologies for evaluating recommender systems are critical, so that such systems can be compared in a sound manner. A commonly overlooked aspect of recommender system evaluation is the selection of the data splitting strategy. In this paper, we both show that there is no standard splitting strategy and that the selection of splitting strategy can have a strong impact on the ranking of recommender systems. In particular, we perform experiments comparing three common splitting strategies, examining their impact over seven state-of-the-art recommendation models for two datasets. Our results demonstrate that the splitting strategy employed is an important confounding variable that can markedly alter the ranking of state-of-the-art systems, making much of the currently published literature non-comparable, even when the same dataset and metrics are used.},
	urldate = {2023-02-15},
	publisher = {arXiv},
	author = {Meng, Zaiqiao and McCreadie, Richard and Macdonald, Craig and Ounis, Iadh},
	month = jul,
	year = {2020},
	note = {arXiv:2007.13237 [cs]},
	keywords = {Computer Science - Information Retrieval, rec},
}

@misc{MentalModelCentricLandscapeHumanAISymbiosis,
	title = {A {Mental}-{Model} {Centric} {Landscape} of {Human}-{AI} {Symbiosis}},
	url = {http://arxiv.org/abs/2202.09447},
	abstract = {There has been significant recent interest in developing AI agents capable of effectively interacting and teaming with humans. While each of these works try to tackle a problem quite central to the problem of human-AI interaction, they tend to rely on myopic formulations that obscure the possible inter-relatedness and complementarity of many of these works. The human-aware AI framework was a recent effort to provide a unified account for human-AI interaction by casting them in terms of their relationship to various mental models. Unfortunately, the current accounts of human-aware AI are insufficient to explain the landscape of the work doing in the space of human-AI interaction due to their focus on limited settings. In this paper, we aim to correct this shortcoming by introducing a significantly general version of human-aware AI interaction scheme, called generalized human-aware interaction (GHAI), that talks about (mental) models of six types. Through this paper, we will see how this new framework allows us to capture the various works done in the space of human-AI interaction and identify the fundamental behavioral patterns supported by these works. We will also use this framework to identify potential gaps in the current literature and suggest future research directions to address these shortcomings.},
	urldate = {2023-02-15},
	publisher = {arXiv},
	author = {Zahedi, Zahra and Sreedharan, Sarath and Kambhampati, Subbarao},
	month = feb,
	year = {2022},
	note = {arXiv:2202.09447 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, hai},
}

@inproceedings{CoDesignPerspectivesAlgorithmTransparencyReporting,
	address = {Chicago IL USA},
	title = {Co-{Design} {Perspectives} on {Algorithm} {Transparency} {Reporting}: {Guidelines} and {Prototypes}},
	isbn = {9798400701924},
	shorttitle = {Co-{Design} {Perspectives} on {Algorithm} {Transparency} {Reporting}},
	url = {https://dl.acm.org/doi/10.1145/3593013.3594064},
	doi = {10.1145/3593013.3594064},
	language = {en},
	urldate = {2023-08-05},
	booktitle = {2023 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Luria, Michal},
	month = jun,
	year = {2023},
	keywords = {codesign},
	pages = {1076--1087},
}

@misc{IEEEXploreFullTextPDFa,
	title = {{IEEE} {Xplore} {Full}-{Text} {PDF}:},
	url = {https://ieeexplore-ieee-org.pitt.idm.oclc.org/stamp/stamp.jsp?tp=&arnumber=9229116},
	urldate = {2023-08-05},
	keywords = {codesign},
}

@inproceedings{ExploringEffectsInteractiveDialogueImproving,
	address = {New Orleans LA USA},
	title = {Exploring the {Effects} of {Interactive} {Dialogue} in {Improving} {User} {Control} for {Explainable} {Online} {Symptom} {Checkers}},
	isbn = {978-1-4503-9156-6},
	url = {https://dl.acm.org/doi/10.1145/3491101.3519668},
	doi = {10.1145/3491101.3519668},
	language = {en},
	urldate = {2023-07-17},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} {Extended} {Abstracts}},
	publisher = {ACM},
	author = {Sun, Yuan and Sundar, S. Shyam},
	month = apr,
	year = {2022},
	pages = {1--7},
}

@misc{PromptAidPromptExplorationPerturbationTesting,
	title = {{PromptAid}: {Prompt} {Exploration}, {Perturbation}, {Testing} and {Iteration} using {Visual} {Analytics} for {Large} {Language} {Models}},
	shorttitle = {{PromptAid}},
	url = {http://arxiv.org/abs/2304.01964},
	abstract = {Large Language Models (LLMs) have gained widespread popularity due to their ability to perform ad-hoc Natural Language Processing (NLP) tasks with a simple natural language prompt. Part of the appeal for LLMs is their approachability to the general public, including individuals with no prior technical experience in NLP techniques. However, natural language prompts can vary significantly in terms of their linguistic structure, context, and other semantics. Modifying one or more of these aspects can result in significant differences in task performance. Non-expert users may find it challenging to identify the changes needed to improve a prompt, especially when they lack domain-specific knowledge and lack appropriate feedback. To address this challenge, we present PromptAid, a visual analytics system designed to interactively create, refine, and test prompts through exploration, perturbation, testing, and iteration. PromptAid uses multiple, coordinated visualizations which allow users to improve prompts by using the three strategies: keyword perturbations, paraphrasing perturbations, and obtaining the best set of in-context few-shot examples. PromptAid was designed through an iterative prototyping process involving NLP experts and was evaluated through quantitative and qualitative assessments for LLMs. Our findings indicate that PromptAid helps users to iterate over prompt template alterations with less cognitive overhead, generate diverse prompts with help of recommendations, and analyze the performance of the generated prompts while surpassing existing state-of-the-art prompting interfaces in performance.},
	urldate = {2023-04-10},
	publisher = {arXiv},
	author = {Mishra, Aditi and Soni, Utkarsh and Arunkumar, Anjana and Huang, Jinbin and Kwon, Bum Chul and Bryan, Chris},
	month = apr,
	year = {2023},
	note = {arXiv:2304.01964 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, llm, vis},
}

@misc{RethinkingBiasVarianceTradeoffGeneralizationNeurala,
	title = {Rethinking {Bias}-{Variance} {Trade}-off for {Generalization} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/2002.11328},
	abstract = {The classical bias-variance trade-off predicts that bias decreases and variance increase with model complexity, leading to a U-shaped risk curve. Recent work calls this into question for neural networks and other over-parameterized models, for which it is often observed that larger models generalize better. We provide a simple explanation for this by measuring the bias and variance of neural networks: while the bias is monotonically decreasing as in the classical theory, the variance is unimodal or bell-shaped: it increases then decreases with the width of the network. We vary the network architecture, loss function, and choice of dataset and confirm that variance unimodality occurs robustly for all models we considered. The risk curve is the sum of the bias and variance curves and displays different qualitative shapes depending on the relative scale of bias and variance, with the double descent curve observed in recent literature as a special case. We corroborate these empirical results with a theoretical analysis of two-layer linear networks with random first layer. Finally, evaluation on out-of-distribution data shows that most of the drop in accuracy comes from increased bias while variance increases by a relatively small amount. Moreover, we find that deeper models decrease bias and increase variance for both in-distribution and out-of-distribution data.},
	urldate = {2023-02-26},
	publisher = {arXiv},
	author = {Yang, Zitong and Yu, Yaodong and You, Chong and Steinhardt, Jacob and Ma, Yi},
	month = feb,
	year = {2020},
	note = {arXiv:2002.11328 [cs, stat]
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{ShepherdCriticLanguageModelGeneration,
	title = {Shepherd: {A} {Critic} for {Language} {Model} {Generation}},
	shorttitle = {Shepherd},
	url = {http://arxiv.org/abs/2308.04592},
	abstract = {As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs. In this work, we introduce Shepherd, a language model specifically tuned to critique responses and suggest refinements, extending beyond the capabilities of an untuned model to identify diverse errors and provide suggestions to remedy them. At the core of our approach is a high quality feedback dataset, which we curate from community feedback and human annotations. Even though Shepherd is small (7B parameters), its critiques are either equivalent or preferred to those from established models including ChatGPT. Using GPT-4 for evaluation, Shepherd reaches an average win-rate of 53-87\% compared to competitive alternatives. In human evaluation, Shepherd strictly outperforms other models and on average closely ties with ChatGPT.},
	urldate = {2023-08-14},
	publisher = {arXiv},
	author = {Wang, Tianlu and Yu, Ping and Tan, Xiaoqing Ellen and O'Brien, Sean and Pasunuru, Ramakanth and Dwivedi-Yu, Jane and Golovneva, Olga and Zettlemoyer, Luke and Fazel-Zarandi, Maryam and Celikyilmaz, Asli},
	month = aug,
	year = {2023},
	note = {arXiv:2308.04592 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, generative},
}

@misc{DesignSpaceGenerativeModels,
	title = {The {Design} {Space} of {Generative} {Models}},
	url = {http://arxiv.org/abs/2304.10547},
	abstract = {Card et al.'s classic paper "The Design Space of Input Devices" established the value of design spaces as a tool for HCI analysis and invention. We posit that developing design spaces for emerging pre-trained, generative AI models is necessary for supporting their integration into human-centered systems and practices. We explore what it means to develop an AI model design space by proposing two design spaces relating to generative AI models: the first considers how HCI can impact generative models (i.e., interfaces for models) and the second considers how generative models can impact HCI (i.e., models as an HCI prototyping material).},
	urldate = {2023-08-14},
	publisher = {arXiv},
	author = {Morris, Meredith Ringel and Cai, Carrie J. and Holbrook, Jess and Kulkarni, Chinmay and Terry, Michael},
	month = apr,
	year = {2023},
	note = {arXiv:2304.10547 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, generative, hci, vis},
}

@article{Predictingfoodcrisesusingnews,
	title = {Predicting food crises using news streams},
	volume = {9},
	issn = {2375-2548},
	url = {https://www.science.org/doi/10.1126/sciadv.abm3449},
	doi = {10.1126/sciadv.abm3449},
	abstract = {Anticipating food crisis outbreaks is crucial to efficiently allocate emergency relief and reduce human suffering. However, existing predictive models rely on risk measures that are often delayed, outdated, or incomplete. Using the text of 11.2 million news articles focused on food-insecure countries and published between 1980 and 2020, we leverage recent advances in deep learning to extract high-frequency precursors to food crises that are both interpretable and validated by traditional risk indicators. We demonstrate that over the period from July 2009 to July 2020 and across 21 food-insecure countries, news indicators substantially improve the district-level predictions of food insecurity up to 12 months ahead relative to baseline models that do not include text information. These results could have profound implications on how humanitarian aid gets allocated and open previously unexplored avenues for machine learning to improve decision-making in data-scarce environments.
          , 
            Text indicators extracted from news articles using machine learning help predict food crises in data-scarce environments.},
	language = {en},
	number = {9},
	urldate = {2023-08-13},
	journal = {Science Advances},
	author = {Balashankar, Ananth and Subramanian, Lakshminarayanan and Fraiberger, Samuel P.},
	month = mar,
	year = {2023},
	pages = {eabm3449},
}

@article{DesignMethodsArtificialIntelligenceFairness,
	title = {Design {Methods} for {Artificial} {Intelligence} {Fairness} and {Transparency}},
	abstract = {Fairness and transparency in artificial intelligence (AI) continue to become more prevalent as topics for research, design and development. General principles and guidelines for designing ethical and responsible AI systems have been proposed, yet there is a lack of design methods for these kinds of systems. In this paper, we present CoFAIR, a novel method to design user interfaces for exploring fairness, consisting of series of co-design workshops, and wider evaluation. This method can be readily applied in practice by researchers, designers and developers to create responsible and ethical AI systems.},
	language = {en},
	author = {Stumpf, Simone and Strappelli, Lorenzo and Ahmed, Subeida and Nakao, Yuri and Naseer, Aisha and Gamba, Giulia Del and Regoli, Daniele},
}

@misc{GhostingMachineJudicialResistanceRecidivism,
	title = {Ghosting the {Machine}: {Judicial} {Resistance} to a {Recidivism} {Risk} {Assessment} {Instrument}},
	shorttitle = {Ghosting the {Machine}},
	url = {http://arxiv.org/abs/2306.06573},
	abstract = {Recidivism risk assessment instruments are presented as an 'evidence-based' strategy for criminal justice reform - a way of increasing consistency in sentencing, replacing cash bail, and reducing mass incarceration. In practice, however, AI-centric reforms can simply add another layer to the sluggish, labyrinthine machinery of bureaucratic systems and are met with internal resistance. Through a community-informed interview-based study of 23 criminal judges and other criminal legal bureaucrats in Pennsylvania, I find that judges overwhelmingly ignore a recently-implemented sentence risk assessment instrument, which they disparage as "useless," "worthless," "boring," "a waste of time," "a non-thing," and simply "not helpful." I argue that this algorithm aversion cannot be accounted for by individuals' distrust of the tools or automation anxieties, per the explanations given by existing scholarship. Rather, the instrument's non-use is the result of an interplay between three organizational factors: county-level norms about pre-sentence investigation reports; alterations made to the instrument by the Pennsylvania Sentencing Commission in response to years of public and internal resistance; and problems with how information is disseminated to judges. These findings shed new light on the important role of organizational influences on professional resistance to algorithms, which helps explain why algorithm-centric reforms can fail to have their desired effect. This study also contributes to an empirically-informed argument against the use of risk assessment instruments: they are resource-intensive and have not demonstrated positive on-the-ground impacts.},
	urldate = {2023-08-14},
	publisher = {arXiv},
	author = {Pruss, Dasha},
	month = jun,
	year = {2023},
	note = {arXiv:2306.06573 [cs]},
	keywords = {Computer Science - Computers and Society, fatml},
}

@misc{SearchVerifiabilityExplanationsRarelyEnable,
	title = {In {Search} of {Verifiability}: {Explanations} {Rarely} {Enable} {Complementary} {Performance} in {AI}-{Advised} {Decision} {Making}},
	shorttitle = {In {Search} of {Verifiability}},
	url = {http://arxiv.org/abs/2305.07722},
	abstract = {The current literature on AI-advised decision making -- involving explainable AI systems advising human decision makers -- presents a series of inconclusive and confounding results. To synthesize these findings, we propose a simple theory that elucidates the frequent failure of AI explanations to engender appropriate reliance and complementary decision making performance. We argue explanations are only useful to the extent that they allow a human decision maker to verify the correctness of an AI's prediction, in contrast to other desiderata, e.g., interpretability or spelling out the AI's reasoning process. Prior studies find in many decision making contexts AI explanations do not facilitate such verification. Moreover, most tasks fundamentally do not allow easy verification, regardless of explanation method, limiting the potential benefit of any type of explanation. We also compare the objective of complementary performance with that of appropriate reliance, decomposing the latter into the notions of outcome-graded and strategy-graded reliance.},
	urldate = {2023-08-14},
	publisher = {arXiv},
	author = {Fok, Raymond and Weld, Daniel S.},
	month = jun,
	year = {2023},
	note = {arXiv:2305.07722 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, explanation, fatml},
}

@misc{FLASKFinegrainedLanguageModelEvaluation,
	title = {{FLASK}: {Fine}-grained {Language} {Model} {Evaluation} based on {Alignment} {Skill} {Sets}},
	shorttitle = {{FLASK}},
	url = {http://arxiv.org/abs/2307.10928},
	abstract = {Evaluation of Large Language Models (LLMs) is challenging because aligning to human values requires the composition of multiple skills and the required set of skills varies depending on the instruction. Recent studies have evaluated the performance of LLMs in two ways, (1) automatic evaluation on several independent benchmarks and (2) human or machined-based evaluation giving an overall score to the response. However, both settings are coarse-grained evaluations, not considering the nature of user instructions that require instance-wise skill composition, which limits the interpretation of the true capabilities of LLMs. In this paper, we introduce FLASK (Fine-grained Language Model Evaluation based on Alignment SKill Sets), a fine-grained evaluation protocol that can be used for both model-based and human-based evaluation which decomposes coarse-level scoring to an instance-wise skill set-level. Specifically, we define 12 fine-grained skills needed for LLMs to follow open-ended user instructions and construct an evaluation set by allocating a set of skills for each instance. Additionally, by annotating the target domains and difficulty level for each instance, FLASK provides a holistic view with a comprehensive analysis of a model's performance depending on skill, domain, and difficulty. Through using FLASK, we compare multiple open-sourced and proprietary LLMs and observe highly-correlated findings between model-based and human-based evaluations. FLASK enables developers to more accurately measure the model performance and how it can be improved by analyzing factors that make LLMs proficient in particular skills. For practitioners, FLASK can be used to recommend suitable models for particular situations through comprehensive comparison among various LLMs. We release the evaluation data and code implementation at https://github.com/kaistAI/FLASK.},
	urldate = {2023-08-14},
	publisher = {arXiv},
	author = {Ye, Seonghyeon and Kim, Doyoung and Kim, Sungdong and Hwang, Hyeonbin and Kim, Seungone and Jo, Yongrae and Thorne, James and Kim, Juho and Seo, Minjoon},
	month = jul,
	year = {2023},
	note = {arXiv:2307.10928 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, evaluation, generative},
}

@misc{DISSECTDisentangledSimultaneousExplanationsConcept,
	title = {{DISSECT}: {Disentangled} {Simultaneous} {Explanations} via {Concept} {Traversals}},
	shorttitle = {{DISSECT}},
	url = {http://arxiv.org/abs/2105.15164},
	abstract = {Explaining deep learning model inferences is a promising venue for scientific understanding, improving safety, uncovering hidden biases, evaluating fairness, and beyond, as argued by many scholars. One of the principal benefits of counterfactual explanations is allowing users to explore "what-if" scenarios through what does not and cannot exist in the data, a quality that many other forms of explanation such as heatmaps and influence functions are inherently incapable of doing. However, most previous work on generative explainability cannot disentangle important concepts effectively, produces unrealistic examples, or fails to retain relevant information. We propose a novel approach, DISSECT, that jointly trains a generator, a discriminator, and a concept disentangler to overcome such challenges using little supervision. DISSECT generates Concept Traversals (CTs), defined as a sequence of generated examples with increasing degrees of concepts that influence a classifier's decision. By training a generative model from a classifier's signal, DISSECT offers a way to discover a classifier's inherent "notion" of distinct concepts automatically rather than rely on user-predefined concepts. We show that DISSECT produces CTs that (1) disentangle several concepts, (2) are influential to a classifier's decision and are coupled to its reasoning due to joint training (3), are realistic, (4) preserve relevant information, and (5) are stable across similar inputs. We validate DISSECT on several challenging synthetic and realistic datasets where previous methods fall short of satisfying desirable criteria for interpretability and show that it performs consistently well and better than existing methods. Finally, we present experiments showing applications of DISSECT for detecting potential biases of a classifier and identifying spurious artifacts that impact predictions.},
	urldate = {2023-08-14},
	publisher = {arXiv},
	author = {Ghandeharioun, Asma and Kim, Been and Li, Chun-Liang and Jou, Brendan and Eoff, Brian and Picard, Rosalind W.},
	month = mar,
	year = {2022},
	note = {arXiv:2105.15164 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, concept, explanation},
}

@misc{FLamEFewshotLearningNaturalLanguage,
	title = {{FLamE}: {Few}-shot {Learning} from {Natural} {Language} {Explanations}},
	shorttitle = {{FLamE}},
	url = {http://arxiv.org/abs/2306.08042},
	abstract = {Natural language explanations have the potential to provide rich information that in principle guides model reasoning. Yet, recent work by Lampinen et al. (2022) has shown limited utility of natural language explanations in improving classification. To effectively learn from explanations, we present FLamE, a two-stage few-shot learning framework that first generates explanations using GPT-3, and then finetunes a smaller model (e.g., RoBERTa) with generated explanations. Our experiments on natural language inference demonstrate effectiveness over strong baselines, increasing accuracy by 17.6\% over GPT-3 Babbage and 5.7\% over GPT-3 Davinci in e-SNLI. Despite improving classification performance, human evaluation surprisingly reveals that the majority of generated explanations does not adequately justify classification decisions. Additional analyses point to the important role of label-specific cues (e.g., "not know" for the neutral label) in generated explanations.},
	urldate = {2023-08-14},
	publisher = {arXiv},
	author = {Zhou, Yangqiaoyu and Zhang, Yiming and Tan, Chenhao},
	month = jun,
	year = {2023},
	note = {arXiv:2306.08042 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, explanation, few-shot},
}

@misc{MachineExplanationsHumanUnderstanding,
	title = {Machine {Explanations} and {Human} {Understanding}},
	url = {http://arxiv.org/abs/2202.04092},
	abstract = {Explanations are hypothesized to improve human understanding of machine learning models and achieve a variety of desirable outcomes, ranging from model debugging to enhancing human decision making. However, empirical studies have found mixed and even negative results. An open question, therefore, is under what conditions explanations can improve human understanding and in what way. Using adapted causal diagrams, we provide a formal characterization of the interplay between machine explanations and human understanding, and show how human intuitions play a central role in enabling human understanding. Specifically, we identify three core concepts of interest that cover all existing quantitative measures of understanding in the context of human-AI decision making: task decision boundary, model decision boundary, and model error. Our key result is that without assumptions about task-specific intuitions, explanations may potentially improve human understanding of model decision boundary, but they cannot improve human understanding of task decision boundary or model error. To achieve complementary human-AI performance, we articulate possible ways on how explanations need to work with human intuitions. For instance, human intuitions about the relevance of features (e.g., education is more important than age in predicting a person's income) can be critical in detecting model error. We validate the importance of human intuitions in shaping the outcome of machine explanations with empirical human-subject studies. Overall, our work provides a general framework along with actionable implications for future algorithmic development and empirical experiments of machine explanations.},
	urldate = {2023-08-14},
	publisher = {arXiv},
	author = {Chen, Chacha and Feng, Shi and Sharma, Amit and Tan, Chenhao},
	month = may,
	year = {2023},
	note = {arXiv:2202.04092 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, explanation, fatml},
}

@article{CausalSupportModelingCausalInferences,
	title = {Causal {Support}: {Modeling} {Causal} {Inferences} with {Visualizations}},
	volume = {28},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Causal {Support}},
	url = {https://ieeexplore.ieee.org/document/9552187/},
	doi = {10.1109/TVCG.2021.3114824},
	abstract = {Analysts often make visual causal inferences about possible data-generating models. However, visual analytics (VA) software tends to leave these models implicit in the mind of the analyst, which casts doubt on the statistical validity of informal visual “insights”. We formally evaluate the quality of causal inferences from visualizations by adopting causal support—a Bayesian cognition model that learns the probability of alternative causal explanations given some data—as a normative benchmark for causal inferences. We contribute two experiments assessing how well crowdworkers can detect (1) a treatment effect and (2) a confounding relationship. We ﬁnd that chart users’ causal inferences tend to be insensitive to sample size such that they deviate from our normative benchmark. While interactively cross-ﬁltering data in visualizations can improve sensitivity, on average users do not perform reliably better with common visualizations than they do with textual contingency tables. These experiments demonstrate the utility of causal support as an evaluation framework for inferences in VA and point to opportunities to make analysts’ mental models more explicit in VA software.},
	language = {en},
	number = {1},
	urldate = {2023-08-14},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kale, Alex and Wu, Yifan and Hullman, Jessica},
	month = jan,
	year = {2022},
	keywords = {causal, vis},
	pages = {1150--1160},
}

@book{ReimaginingUniversityAssessmentDigitalWorld,
	address = {Cham},
	series = {The {Enabling} {Power} of {Assessment}},
	title = {Re-imagining {University} {Assessment} in a {Digital} {World}},
	volume = {7},
	isbn = {978-3-030-41955-4 978-3-030-41956-1},
	url = {https://link.springer.com/10.1007/978-3-030-41956-1},
	language = {en},
	urldate = {2023-08-14},
	publisher = {Springer International Publishing},
	editor = {Bearman, Margaret and Dawson, Phillip and Ajjawi, Rola and Tai, Joanna and Boud, David},
	year = {2020},
	doi = {10.1007/978-3-030-41956-1},
	keywords = {cognitive, explanation},
}

@misc{DecisionFocusedSummarization,
	title = {Decision-{Focused} {Summarization}},
	url = {http://arxiv.org/abs/2109.06896},
	abstract = {Relevance in summarization is typically defined based on textual information alone, without incorporating insights about a particular decision. As a result, to support risk analysis of pancreatic cancer, summaries of medical notes may include irrelevant information such as a knee injury. We propose a novel problem, decision-focused summarization, where the goal is to summarize relevant information for a decision. We leverage a predictive model that makes the decision based on the full text to provide valuable insights on how a decision can be inferred from text. To build a summary, we then select representative sentences that lead to similar model decisions as using the full text while accounting for textual non-redundancy. To evaluate our method (DecSum), we build a testbed where the task is to summarize the first ten reviews of a restaurant in support of predicting its future rating on Yelp. DecSum substantially outperforms text-only summarization methods and model-based explanation methods in decision faithfulness and representativeness. We further demonstrate that DecSum is the only method that enables humans to outperform random chance in predicting which restaurant will be better rated in the future.},
	urldate = {2023-08-14},
	publisher = {arXiv},
	author = {Hsu, Chao-Chun and Tan, Chenhao},
	month = sep,
	year = {2021},
	note = {arXiv:2109.06896 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, decision, summarization},
}

@article{AutomatedApproachReasoningTaskOrientedInsights,
	title = {An {Automated} {Approach} to {Reasoning} {About} {Task}-{Oriented} {Insights} in {Responsive} {Visualization}},
	volume = {28},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2021.3114782},
	abstract = {Authors often transform a large screen visualization for smaller displays through rescaling, aggregation and other techniques when creating visualizations for both desktop and mobile devices (i.e., responsive visualization). However, transformations can alter relationships or patterns implied by the large screen view, requiring authors to reason carefully about what information to preserve while adjusting their design for the smaller display. We propose an automated approach to approximating the loss of support for task-oriented visualization insights (identification, comparison, and trend) in responsive transformation of a source visualization. We operationalize identification, comparison, and trend loss as objective functions calculated by comparing properties of the rendered source visualization to each realized target (small screen) visualization. To evaluate the utility of our approach, we train machine learning models on human ranked small screen alternative visualizations across a set of source visualizations. We find that our approach achieves an accuracy of 84\% (random forest model) in ranking visualizations. We demonstrate this approach in a prototype responsive visualization recommender that enumerates responsive transformations using Answer Set Programming and evaluates the preservation of task-oriented insights using our loss measures. We discuss implications of our approach for the development of automated and semi-automated responsive visualization recommendation.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, Hyeok and Rossi, Ryan and Sarma, Abhraneel and Moritz, Dominik and Hullman, Jessica},
	month = jan,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Data visualization, Economic indicators, Encoding, Loss measurement, Market research, Task analysis, Task-oriented insight preservation, Visualization, responsive visualization, vis},
	pages = {129--139},
}

@article{ScienceVisualDataCommunicationWhat,
	title = {The {Science} of {Visual} {Data} {Communication}: {What} {Works}},
	volume = {22},
	issn = {1529-1006},
	shorttitle = {The {Science} of {Visual} {Data} {Communication}},
	url = {https://doi.org/10.1177/15291006211051956},
	doi = {10.1177/15291006211051956},
	abstract = {Effectively designed data visualizations allow viewers to use their powerful visual systems to understand patterns in data across science, education, health, and public policy. But ineffectively designed visualizations can cause confusion, misunderstanding, or even distrust?especially among viewers with low graphical literacy. We review research-backed guidelines for creating effective and intuitive visualizations oriented toward communicating data to students, coworkers, and the general public. We describe how the visual system can quickly extract broad statistics from a display, whereas poorly designed displays can lead to misperceptions and illusions. Extracting global statistics is fast, but comparing between subsets of values is slow. Effective graphics avoid taxing working memory, guide attention, and respect familiar conventions. Data visualizations can play a critical role in teaching and communication, provided that designers tailor those visualizations to their audience.},
	number = {3},
	urldate = {2023-08-14},
	journal = {Psychological Science in the Public Interest},
	author = {Franconeri, Steven L. and Padilla, Lace M. and Shah, Priti and Zacks, Jeffrey M. and Hullman, Jessica},
	month = dec,
	year = {2021},
	note = {Publisher: SAGE Publications Inc},
	keywords = {vis},
	pages = {110--161},
}

@misc{AITransparencyAgeLLMsHumanCentered,
	title = {{AI} {Transparency} in the {Age} of {LLMs}: {A} {Human}-{Centered} {Research} {Roadmap}},
	shorttitle = {{AI} {Transparency} in the {Age} of {LLMs}},
	url = {http://arxiv.org/abs/2306.01941},
	abstract = {The rise of powerful large language models (LLMs) brings about tremendous opportunities for innovation but also looming risks for individuals and society at large. We have reached a pivotal moment for ensuring that LLMs and LLM-infused applications are developed and deployed responsibly. However, a central pillar of responsible AI -- transparency -- is largely missing from the current discourse around LLMs. It is paramount to pursue new approaches to provide transparency for LLMs, and years of research at the intersection of AI and human-computer interaction (HCI) highlight that we must do so with a human-centered perspective: Transparency is fundamentally about supporting appropriate human understanding, and this understanding is sought by different stakeholders with different goals in different contexts. In this new era of LLMs, we must develop and design approaches to transparency by considering the needs of stakeholders in the emerging LLM ecosystem, the novel types of LLM-infused applications being built, and the new usage patterns and challenges around LLMs, all while building on lessons learned about how people process, interact with, and make use of information. We reflect on the unique challenges that arise in providing transparency for LLMs, along with lessons learned from HCI and responsible AI research that has taken a human-centered perspective on AI transparency. We then lay out four common approaches that the community has taken to achieve transparency -- model reporting, publishing evaluation results, providing explanations, and communicating uncertainty -- and call out open questions around how these approaches may or may not be applied to LLMs. We hope this provides a starting point for discussion and a useful roadmap for future research.},
	urldate = {2023-08-16},
	publisher = {arXiv},
	author = {Liao, Q. Vera and Vaughan, Jennifer Wortman},
	month = aug,
	year = {2023},
	note = {arXiv:2306.01941 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, generative, llm, transparency},
}

@inproceedings{AlgorithmicImprint,
	title = {The {Algorithmic} {Imprint}},
	url = {http://arxiv.org/abs/2206.03275},
	doi = {10.1145/3531146.3533186},
	abstract = {When algorithmic harms emerge, a reasonable response is to stop using the algorithm to resolve concerns related to fairness, accountability, transparency, and ethics (FATE). However, just because an algorithm is removed does not imply its FATE-related issues cease to exist. In this paper, we introduce the notion of the "algorithmic imprint" to illustrate how merely removing an algorithm does not necessarily undo or mitigate its consequences. We operationalize this concept and its implications through the 2020 events surrounding the algorithmic grading of the General Certificate of Education (GCE) Advanced (A) Level exams, an internationally recognized UK-based high school diploma exam administered in over 160 countries. While the algorithmic standardization was ultimately removed due to global protests, we show how the removal failed to undo the algorithmic imprint on the sociotechnical infrastructures that shape students', teachers', and parents' lives. These events provide a rare chance to analyze the state of the world both with and without algorithmic mediation. We situate our case study in Bangladesh to illustrate how algorithms made in the Global North disproportionately impact stakeholders in the Global South. Chronicling more than a year-long community engagement consisting of 47 inter-views, we present the first coherent timeline of "what" happened in Bangladesh, contextualizing "why" and "how" they happened through the lenses of the algorithmic imprint and situated algorithmic fairness. Analyzing these events, we highlight how the contours of the algorithmic imprints can be inferred at the infrastructural, social, and individual levels. We share conceptual and practical implications around how imprint-awareness can (a) broaden the boundaries of how we think about algorithmic impact, (b) inform how we design algorithms, and (c) guide us in AI governance.},
	urldate = {2023-08-14},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	author = {Ehsan, Upol and Singh, Ranjit and Metcalf, Jacob and Riedl, Mark O.},
	month = jun,
	year = {2022},
	note = {arXiv:2206.03275 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, fatml},
	pages = {1305--1317},
}

@article{VisualReasoningStrategiesEffectSize,
	title = {Visual {Reasoning} {Strategies} for {Effect} {Size} {Judgments} and {Decisions}},
	volume = {27},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2020.3030335},
	abstract = {Uncertainty visualizations often emphasize point estimates to support magnitude estimates or decisions through visual comparison. However, when design choices emphasize means, users may overlook uncertainty information and misinterpret visual distance as a proxy for effect size. We present findings from a mixed design experiment on Mechanical Turk which tests eight uncertainty visualization designs: 95\% containment intervals, hypothetical outcome plots, densities, and quantile dotplots, each with and without means added. We find that adding means to uncertainty visualizations has small biasing effects on both magnitude estimation and decision-making, consistent with discounting uncertainty. We also see that visualization designs that support the least biased effect size estimation do not support the best decision-making, suggesting that a chart user's sense of effect size may not necessarily be identical when they use the same information for different tasks. In a qualitative analysis of users' strategy descriptions, we find that many users switch strategies and do not employ an optimal strategy when one exists. Uncertainty visualizations which are optimally designed in theory may not be the most effective in practice because of the ways that users satisfice with heuristics, suggesting opportunities to better understand visualization effectiveness by modeling sets of potential strategies.},
	number = {2},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kale, Alex and Kay, Matthew and Hullman, Jessica},
	month = feb,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Data visualization, Decision making, Estimation, Task analysis, Uncertainty, Uncertainty visualization, Visualization, data cognition, graphical perception, vis},
	pages = {272--282},
}

@incollection{StereotypeMeasurementPoliticalDecisionMaking,
	title = {Stereotype {Measurement} in {Political} {Decision} {Making}},
	isbn = {978-0-19-022863-7},
	url = {https://oxfordre.com/politics/view/10.1093/acrefore/9780190228637.001.0001/acrefore-9780190228637-e-775},
	abstract = {Stereotypes are a set of beliefs a person holds about the personal attributes of a group of people. The beliefs are commonly held and understood, which allows people to use them as automatic shortcuts when making evaluations and decisions. Because the beliefs are so broadly understood and easily accessible, they can subconsciously influence opinion formation. In the realm of politics, citizens may use stereotypes to guide evaluations of candidates from stereotyped groups (such as African Americans or women) or as they formulate opinions about a policy that may have a particular group as its perceived beneficiary.},
	language = {en},
	urldate = {2023-08-20},
	booktitle = {Oxford {Research} {Encyclopedia} of {Politics}},
	publisher = {Oxford University Press},
	author = {Bos, Angela L. and Madonia, Heather and Schneider, Monica C.},
	collaborator = {Bos, Angela L. and Madonia, Heather and Schneider, Monica C.},
	month = oct,
	year = {2018},
	doi = {10.1093/acrefore/9780190228637.013.775},
	keywords = {stereotype},
}

@inproceedings{SituatedParticipatoryDesignMethodSitu,
	address = {Hamburg Germany},
	title = {Situated {Participatory} {Design}: {A} {Method} for {In} {Situ} {Design} of {Robotic} {Interaction} with {Older} {Adults}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {Situated {Participatory} {Design}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580893},
	doi = {10.1145/3544548.3580893},
	language = {en},
	urldate = {2023-08-17},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Stegner, Laura and Senft, Emmanuel and Mutlu, Bilge},
	month = apr,
	year = {2023},
	keywords = {co-design},
	pages = {1--15},
}

@inproceedings{ParticipatoryDesignAISystemsOpportunities,
	address = {New Orleans LA USA},
	title = {Participatory {Design} of {AI} {Systems}: {Opportunities} and {Challenges} {Across} {Diverse} {Users}, {Relationships}, and {Application} {Domains}},
	isbn = {978-1-4503-9156-6},
	shorttitle = {Participatory {Design} of {AI} {Systems}},
	url = {https://dl.acm.org/doi/10.1145/3491101.3516506},
	doi = {10.1145/3491101.3516506},
	abstract = {Participatory design (PD) for Artificially Intelligent (AI) systems has gained in popularity in recent years across multiple application domains, both within the private and public sectors. PD methods broadly enable stakeholders of diverse backgrounds to inform new use cases for AI and the design of AI-based technologies that directly impact people’s lives. Such participation can be vital for mitigating adverse implications of AI on society that are becoming increasingly apparent and pursuing more positive impact, especially to vulnerable populations. This panel brings together researchers who have, or are, conducting participatory design of AI systems across diverse subject areas. The goal of the panel is to elucidate similarities and differences, as well as successes and challenges, in how PD methods can be applied to Artificially Intelligent systems in practical and meaningful ways. The panel serves as an opportunity for the HCI research community to collectively reflect on opportunities for PD of AI to facilitate collaboration amongst stakeholders, as well as persistent challenges to participatory AI design.},
	language = {en},
	urldate = {2023-08-16},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} {Extended} {Abstracts}},
	publisher = {ACM},
	author = {Zytko, Douglas and J. Wisniewski, Pamela and Guha, Shion and P. S. Baumer, Eric and Lee, Min Kyung},
	month = apr,
	year = {2022},
	keywords = {participatory-design},
	pages = {1--4},
}

@inproceedings{JudgmentCallGameUsingValue,
	address = {San Diego CA USA},
	title = {Judgment {Call} the {Game}: {Using} {Value} {Sensitive} {Design} and {Design} {Fiction} to {Surface} {Ethical} {Concerns} {Related} to {Technology}},
	isbn = {978-1-4503-5850-7},
	shorttitle = {Judgment {Call} the {Game}},
	url = {https://dl.acm.org/doi/10.1145/3322276.3323697},
	doi = {10.1145/3322276.3323697},
	language = {en},
	urldate = {2023-08-16},
	booktitle = {Proceedings of the 2019 on {Designing} {Interactive} {Systems} {Conference}},
	publisher = {ACM},
	author = {Ballard, Stephanie and Chappell, Karen M. and Kennedy, Kristen},
	month = jun,
	year = {2019},
	keywords = {evaluation, method, value-sensitive-design},
	pages = {421--433},
}

@inproceedings{ScienceHumanAIDecisionMakingOverview,
	address = {Chicago IL USA},
	title = {Towards a {Science} of {Human}-{AI} {Decision} {Making}: {An} {Overview} of {Design} {Space} in {Empirical} {Human}-{Subject} {Studies}},
	isbn = {9798400701924},
	shorttitle = {Towards a {Science} of {Human}-{AI} {Decision} {Making}},
	url = {https://dl.acm.org/doi/10.1145/3593013.3594087},
	doi = {10.1145/3593013.3594087},
	language = {en},
	urldate = {2023-08-16},
	booktitle = {2023 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Lai, Vivian and Chen, Chacha and Smith-Renner, Alison and Liao, Q. Vera and Tan, Chenhao},
	month = jun,
	year = {2023},
	keywords = {decision},
	pages = {1369--1385},
}

@article{CellsGeneratorsLensesDesignFramework,
	title = {Cells, {Generators}, and {Lenses}: {Design} {Framework} for {Object}-{Oriented} {Interaction} with {Large} {Language} {Models}},
	language = {en},
	author = {Kim, Tae Soo and Chang, Minsuk and Lee, Yoonjoo and Kim, Juho},
	year = {2023},
	keywords = {generative, hci, llm},
}

@inproceedings{IncreasingDiversityMaintainingAccuracyText,
	address = {Toronto, Canada},
	title = {Increasing {Diversity} {While} {Maintaining} {Accuracy}: {Text} {Data} {Generation} with {Large} {Language} {Models} and {Human} {Interventions}},
	shorttitle = {Increasing {Diversity} {While} {Maintaining} {Accuracy}},
	url = {https://aclanthology.org/2023.acl-long.34},
	doi = {10.18653/v1/2023.acl-long.34},
	abstract = {Large language models (LLMs) can be used to generate text data for training and evaluating other models. However, creating high-quality datasets with LLMs can be challenging. In this work, we explore human-AI partnerships to facilitate high diversity and accuracy in LLM-based text data generation. We first examine two approaches to diversify text generation: 1) logit suppression, which minimizes the generation of languages that have already been frequently generated, and 2) temperature sampling, which flattens the token sampling probability. We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain). To address this issue, we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user's domain of interest or to which no considered label applies. With oracle studies, we found that LR increases the absolute accuracy of models trained with diversified datasets by 14.4\%. Moreover, we found that some models trained with data generated with LR interventions outperformed LLM-based few-shot classification. In contrast, OOSF was not effective in increasing model accuracy, implying the need for future work in human-in-the-loop text data generation.},
	urldate = {2023-08-22},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chung, John and Kamar, Ece and Amershi, Saleema},
	month = jul,
	year = {2023},
	keywords = {diversity, generative, hil, llm},
	pages = {575--593},
}

@inproceedings{BringingTransparencyDesignPractice,
	address = {Tokyo Japan},
	title = {Bringing {Transparency} {Design} into {Practice}},
	isbn = {978-1-4503-4945-1},
	url = {https://dl.acm.org/doi/10.1145/3172944.3172961},
	doi = {10.1145/3172944.3172961},
	language = {en},
	urldate = {2023-08-21},
	booktitle = {23rd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Eiband, Malin and Schneider, Hanna and Bilandzic, Mark and Fazekas-Con, Julian and Haug, Mareike and Hussmann, Heinrich},
	month = mar,
	year = {2018},
	keywords = {mental-model, transparency},
	pages = {211--223},
}

@inproceedings{HeuristicEvaluationConversationalAgents,
	address = {Yokohama Japan},
	title = {Heuristic {Evaluation} of {Conversational} {Agents}},
	isbn = {978-1-4503-8096-6},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445312},
	doi = {10.1145/3411764.3445312},
	language = {en},
	urldate = {2023-08-21},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Langevin, Raina and Lordon, Ross J and Avrahami, Thi and Cowan, Benjamin R. and Hirsch, Tad and Hsieh, Gary},
	month = may,
	year = {2021},
	keywords = {chatbot, generative, llm},
	pages = {1--15},
}

@inproceedings{FormalizingTrustArtificialIntelligencePrerequisites,
	address = {Virtual Event Canada},
	title = {Formalizing {Trust} in {Artificial} {Intelligence}: {Prerequisites}, {Causes} and {Goals} of {Human} {Trust} in {AI}},
	isbn = {978-1-4503-8309-7},
	shorttitle = {Formalizing {Trust} in {Artificial} {Intelligence}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445923},
	doi = {10.1145/3442188.3445923},
	language = {en},
	urldate = {2023-08-21},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Jacovi, Alon and Marasović, Ana and Miller, Tim and Goldberg, Yoav},
	month = mar,
	year = {2021},
	keywords = {trust},
	pages = {624--635},
}

@misc{PromptAidPromptExplorationPerturbationTestinga,
	title = {{PromptAid}: {Prompt} {Exploration}, {Perturbation}, {Testing} and {Iteration} using {Visual} {Analytics} for {Large} {Language} {Models}},
	shorttitle = {{PromptAid}},
	url = {http://arxiv.org/abs/2304.01964},
	abstract = {Large Language Models (LLMs) have gained widespread popularity due to their ability to perform ad-hoc Natural Language Processing (NLP) tasks with a simple natural language prompt. Part of the appeal for LLMs is their approachability to the general public, including individuals with no prior technical experience in NLP techniques. However, natural language prompts can vary significantly in terms of their linguistic structure, context, and other semantics. Modifying one or more of these aspects can result in significant differences in task performance. Non-expert users may find it challenging to identify the changes needed to improve a prompt, especially when they lack domain-specific knowledge and lack appropriate feedback. To address this challenge, we present PromptAid, a visual analytics system designed to interactively create, refine, and test prompts through exploration, perturbation, testing, and iteration. PromptAid uses multiple, coordinated visualizations which allow users to improve prompts by using the three strategies: keyword perturbations, paraphrasing perturbations, and obtaining the best set of in-context few-shot examples. PromptAid was designed through an iterative prototyping process involving NLP experts and was evaluated through quantitative and qualitative assessments for LLMs. Our findings indicate that PromptAid helps users to iterate over prompt template alterations with less cognitive overhead, generate diverse prompts with help of recommendations, and analyze the performance of the generated prompts while surpassing existing state-of-the-art prompting interfaces in performance.},
	urldate = {2023-08-23},
	publisher = {arXiv},
	author = {Mishra, Aditi and Soni, Utkarsh and Arunkumar, Anjana and Huang, Jinbin and Kwon, Bum Chul and Bryan, Chris},
	month = apr,
	year = {2023},
	note = {arXiv:2304.01964 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, llm, prompt, vis},
}

@inproceedings{DisentanglingFairnessPerceptionsAlgorithmicDecisionMaking,
	address = {Hamburg Germany},
	title = {Disentangling {Fairness} {Perceptions} in {Algorithmic} {Decision}-{Making}: the {Effects} of {Explanations}, {Human} {Oversight}, and {Contestability}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {Disentangling {Fairness} {Perceptions} in {Algorithmic} {Decision}-{Making}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581161},
	doi = {10.1145/3544548.3581161},
	language = {en},
	urldate = {2023-08-23},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yurrita, Mireia and Draws, Tim and Balayn, Agathe and Murray-Rust, Dave and Tintarev, Nava and Bozzon, Alessandro},
	month = apr,
	year = {2023},
	pages = {1--21},
}

@inproceedings{CodePromptTaskAgnosticPrefixTuningProgram,
	address = {Toronto, Canada},
	title = {{CodePrompt}: {Task}-{Agnostic} {Prefix} {Tuning} for {Program} and {Language} {Generation}},
	shorttitle = {{CodePrompt}},
	url = {https://aclanthology.org/2023.findings-acl.325},
	doi = {10.18653/v1/2023.findings-acl.325},
	abstract = {In order to solve the inefficient parameter update and storage issues of fine-tuning in Natural Language Generation (NLG) tasks, prompt-tuning methods have emerged as lightweight alternatives.Furthermore, efforts to reduce the gap between pre-training and fine-tuning have shown successful results in low-resource settings.As large Pre-trained Language Models (PLMs) for Program and Language Generation (PLG) tasks are constantly being developed, prompt tuning methods are necessary for the tasks.However, due to the gap between pre-training and fine-tuning different from PLMs for natural language, a prompt tuning method that reflects the traits of PLM for program language is needed.In this paper, we propose a Task-Agnostic prompt tuning method for the PLG tasks, CodePrompt, that combines Input-Dependent Prompt Template (to bridge the gap between pre-training and fine-tuning of PLMs for program and language) and Corpus-Specific Prefix Tuning (to update the parameters of PLMs for program and language efficiently).Also, we propose a method to provide richer prefix word information for limited prefix lengths. We prove that our method is effective in three PLG tasks, not only in the full-data setting but also in the low-resource setting and cross-domain setting.},
	urldate = {2023-08-23},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Choi, YunSeok and Lee, Jee-Hyong},
	month = jul,
	year = {2023},
	keywords = {generative, prompt},
	pages = {5282--5297},
}

@article{EffectsAILogicStyleExplanationsUsers,
	title = {Effects of {AI} and {Logic}-{Style} {Explanations} on {Users}’ {Decisions} under {Different} {Levels} of {Uncertainty}},
	issn = {2160-6455, 2160-6463},
	url = {https://dl.acm.org/doi/10.1145/3588320},
	doi = {10.1145/3588320},
	abstract = {Existing eXplainable Artificial Intelligence (XAI) techniques support people in interpreting AI advice. However, while previous work evaluates the users’ understanding of explanations, factors influencing the decision support are largely overlooked in the literature. This paper addresses this gap by studying the impact of
              user uncertainty
              ,
              AI correctness
              , and the interaction between
              AI uncertainty
              and
              explanation logic-styles
              , for classification tasks. We conducted two separate studies: one requesting participants to recognise hand-written digits and one to classify the sentiment of reviews. To assess the decision making, we analysed the
              task performance, agreement
              with the AI suggestion, and the user’s
              reliance
              on the XAI interface elements. Participants make their decision relying on three pieces of information in the XAI interface (image or text instance, AI prediction, and explanation). Participants were shown one explanation style (between-participants design): according to three styles of logical reasoning (inductive, deductive, and abductive). This allowed us to study how different levels of AI uncertainty influence the effectiveness of different explanation styles. The results show that user uncertainty and AI correctness on predictions significantly affected users’ classification decisions considering the analysed metrics. In both domains (images and text), users relied mainly on the instance to decide. Users were usually overconfident about their choices, and this evidence was more pronounced for text. Furthermore, the inductive style explanations led to over-reliance on the AI advice in both domains – it was the most persuasive, even when the AI was incorrect. The abductive and deductive styles have complex effects depending on the domain and the AI uncertainty levels.},
	language = {en},
	urldate = {2023-08-22},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Cau, Federico Maria and Hauptmann, Hanna and Spano, Lucio Davide and Tintarev, Nava},
	month = mar,
	year = {2023},
	keywords = {explanation},
	pages = {3588320},
}

@misc{LargeLanguageModelsAreHumanLevel,
	title = {Large {Language} {Models} {Are} {Human}-{Level} {Prompt} {Engineers}},
	url = {http://arxiv.org/abs/2211.01910},
	abstract = {By conditioning on natural language instructions, large language models (LLMs) have displayed impressive capabilities as general-purpose computers. However, task performance depends significantly on the quality of the prompt used to steer the model, and most effective prompts have been handcrafted by humans. Inspired by classical program synthesis and the human approach to prompt engineering, we propose Automatic Prompt Engineer (APE) for automatic instruction generation and selection. In our method, we treat the instruction as the "program," optimized by searching over a pool of instruction candidates proposed by an LLM in order to maximize a chosen score function. To evaluate the quality of the selected instruction, we evaluate the zero-shot performance of another LLM following the selected instruction. Experiments on 24 NLP tasks show that our automatically generated instructions outperform the prior LLM baseline by a large margin and achieve better or comparable performance to the instructions generated by human annotators on 19/24 tasks. We conduct extensive qualitative and quantitative analyses to explore the performance of APE. We show that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts. Please check out our webpage at https://sites.google.com/view/automatic-prompt-engineer.},
	language = {en},
	urldate = {2023-08-23},
	publisher = {arXiv},
	author = {Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
	month = mar,
	year = {2023},
	note = {arXiv:2211.01910 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{PromptMiddlewareMappingPromptsLarge,
	title = {Prompt {Middleware}: {Mapping} {Prompts} for {Large} {Language} {Models} to {UI} {Affordances}},
	shorttitle = {Prompt {Middleware}},
	url = {http://arxiv.org/abs/2307.01142},
	abstract = {To help users do complex work, researchers have developed techniques to integrate AI and human intelligence into user interfaces (UIs). With the recent introduction of large language models (LLMs), which can generate text in response to a natural language prompt, there are new opportunities to consider how to integrate LLMs into UIs. We present Prompt Middleware, a framework for generating prompts for LLMs based on UI affordances. These include prompts that are predefined by experts (static prompts), generated from templates with fill-in options in the UI (template-based prompts), or created from scratch (free-form prompts). We demonstrate this framework with FeedbackBuffet, a writing assistant that automatically generates feedback based on a user's text input. Inspired by prior research showing how templates can help non-experts perform more like experts, FeedbackBuffet leverages template-based prompt middleware to enable feedback seekers to specify the types of feedback they want to receive as options in a UI. These options are composed using a template to form a feedback request prompt to GPT-3. We conclude with a discussion about how Prompt Middleware can help developers integrate LLMs into UIs.},
	urldate = {2023-08-23},
	publisher = {arXiv},
	author = {MacNeil, Stephen and Tran, Andrew and Kim, Joanne and Huang, Ziheng and Bernstein, Seth and Mogil, Dan},
	month = jul,
	year = {2023},
	note = {arXiv:2307.01142 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, prompt},
}

@inproceedings{EVLifeCounterfactualDashboardReducing,
	address = {Helsinki Finland},
	title = {{EV} {Life}: {A} {Counterfactual} {Dashboard} {Towards} {Reducing} {Carbon} {Emissions} of {Automotive} {Behaviors}},
	isbn = {978-1-4503-9145-0},
	shorttitle = {{EV} {Life}},
	url = {https://dl.acm.org/doi/10.1145/3490100.3516451},
	doi = {10.1145/3490100.3516451},
	language = {en},
	urldate = {2023-08-29},
	booktitle = {27th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Shamma, David A. and Lee, Matthew L. and Filipowicz, Alexandre L. S. and Denoue, Laurent and Glazko, Kate and Murakami, Kalani and Lyons, Kent},
	month = mar,
	year = {2022},
	keywords = {counterfactual, self-driving},
	pages = {46--49},
}

@book{MachineLearningGuidedOutlookGlobal,
	series = {Policy {Research} {Working} {Papers}},
	title = {Machine {Learning} {Guided} {Outlook} of {Global} {Food} {Insecurity} {Consistent} with {Macroeconomic} {Forecasts}},
	url = {http://elibrary.worldbank.org/doi/book/10.1596/1813-9450-10202},
	language = {en},
	urldate = {2023-08-27},
	publisher = {The World Bank},
	author = {Andree, Bo Pieter Johannes},
	month = oct,
	year = {2022},
	doi = {10.1596/1813-9450-10202},
	keywords = {food},
}

@inproceedings{LetMeExplainImpactPersonal,
	address = {Glasgow Scotland Uk},
	title = {Let {Me} {Explain}: {Impact} of {Personal} and {Impersonal} {Explanations} on {Trust} in {Recommender} {Systems}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Let {Me} {Explain}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300717},
	doi = {10.1145/3290605.3300717},
	language = {en},
	urldate = {2023-08-29},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kunkel, Johannes and Donkers, Tim and Michael, Lisa and Barbu, Catalin-Mihai and Ziegler, Jürgen},
	month = may,
	year = {2019},
	keywords = {counterfactual, explanation, hci},
	pages = {1--12},
}

@article{Nudgingnewsdiversitytheoreticalframework,
	title = {Nudging towards news diversity: {A} theoretical framework for facilitating diverse news consumption through recommender design},
	issn = {1461-4448, 1461-7315},
	shorttitle = {Nudging towards news diversity},
	url = {http://journals.sagepub.com/doi/10.1177/14614448221104413},
	doi = {10.1177/14614448221104413},
	abstract = {Growing concerns about the democratic impact of automatically curated news platforms urge us to reconsider how such platforms should be designed. We propose a theoretical framework for personalised diversity nudges that can stimulate diverse news consumption at the individual level. To examine the potential benefits and limitations of existing diversity nudges, we conduct an interdisciplinary literature review that synthesises theoretical work on news selection mechanisms with hands-on tools and implementations from the fields of computer science and recommender systems. Based on this, we propose five diversity nudges that researchers and practitioners can build on. We provide a theoretical motivation of why, when and for whom such nudges could be effective, critically reflect on their potential backfire effects and the need for algorithmic transparency, and present a research agenda for diversity-aware news recommender design. Thereby, we develop concrete, theoretically grounded avenues for facilitating diverse news consumption on algorithmically curated platforms.},
	language = {en},
	urldate = {2023-08-29},
	journal = {New Media \& Society},
	author = {Mattis, Nicolas and Masur, Philipp and Möller, Judith and Van Atteveldt, Wouter},
	month = jun,
	year = {2022},
	pages = {146144482211044},
}

@article{Knowingmeknowingyoupersonalized,
	title = {“{Knowing} me, knowing you”: personalized explanations for a music recommender system},
	volume = {32},
	issn = {0924-1868, 1573-1391},
	shorttitle = {“{Knowing} me, knowing you”},
	url = {https://link.springer.com/10.1007/s11257-021-09304-9},
	doi = {10.1007/s11257-021-09304-9},
	abstract = {Due to the prominent role of recommender systems in our daily lives, it is increasingly important to inform users why certain items are recommended and personalize these explanations to the user. In this study, we explored how explanations in a music recommender system should be designed to fit the preference of different personal characteristics. More specifically, we investigated three personal characteristics that influence the perception of explanations in music recommender system interfaces: need for cognition, musical sophistication, and openness. For each of these personal characteristics, we designed explanations for users with lower and higher levels of the personal characteristic. Afterward, we conducted for each personal characteristic a within-subject user study in which we compared the two explanations. Based on the results of these user studies, we provide design suggestions to adapt explanations to different levels of these three personal characteristics. In general, we suggest providing explanations up-front for all recommendations at once. For users low in need for cognition, displaying these explanations must be optional. To support users with low musical sophistication, we suggest providing brief explanations that do not require domain knowledge. For users with low openness, we suggest providing explanations with a lower number of explanation elements.},
	language = {en},
	number = {1-2},
	urldate = {2023-08-29},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Martijn, Millecamp and Conati, Cristina and Verbert, Katrien},
	month = apr,
	year = {2022},
	pages = {215--252},
}

@article{Visualanalyticspotentialdropoutbehavior,
	title = {Visual analytics of potential dropout behavior patterns in online learning based on counterfactual explanation},
	volume = {26},
	issn = {1343-8875, 1875-8975},
	url = {https://link.springer.com/10.1007/s12650-022-00899-8},
	doi = {10.1007/s12650-022-00899-8},
	abstract = {Online learning is gradually becoming a popular way of learning due to the high ﬂexibility in time and space. Reducing the high dropout rate is important to promote the further development of smart education. However, learners’ learning is a dynamic temporal process, which is inﬂuenced by multiple factors synergistically. How to identify the key inﬂuencing factors of dropout in an interpretable way is still a challenging problem. In this paper, we propose a pattern identiﬁcation method of dropout behavior, including the prediction of the dropout probability and the mining of potential impact factors, to gain a comprehensive insight into the dropout behavior hidden in the data. A CNN-LSTM model for dropout prediction is constructed, which can automatically extract features and learn the temporal dependence of dropout behavior. By introducing the counterfactual explanation, the dropout impacts of different learning behavior can be revealed quantitatively. Moreover, we design and develop an interactive visual analytics system, DropoutVis, for exploring learning behavior, extracting the various dropout patterns and providing a basis for formulating strategies. The effectiveness and usefulness of DropoutVis have been demonstrated through case studies with a real dataset.},
	language = {en},
	number = {3},
	urldate = {2023-08-29},
	journal = {Journal of Visualization},
	author = {Zhang, Huijie and Dong, Jialu and Lv, Cheng and Lin, Yiming and Bai, Jinghan},
	month = jun,
	year = {2023},
	pages = {723--741},
}

@article{FoodinsufficiencyTwitteremotionspandemica,
	title = {Food insufficiency and {Twitter} emotions during a pandemic},
	volume = {45},
	issn = {2040-5790, 2040-5804},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/aepp.13258},
	doi = {10.1002/aepp.13258},
	abstract = {The COVID-19 pandemic initially caused worldwide concerns about food insecurity. Tweets analyzed in real-time may help food assistance providers target food supplies to where they are most urgently needed. In this exploratory study, we use natural language processing to extract sentiments and emotions expressed in food security-related tweets early in the pandemic in U.S. states. The emotion joy dominated in these tweets nationally, but only anger, disgust, and fear were also statistically correlated with contemporaneous food insufficiency rates reported in the Household Pulse Survey; more nuanced and statistically stronger correlations are detected within states, including a negative correlation with joy.},
	language = {en},
	number = {2},
	urldate = {2023-09-02},
	journal = {Applied Economic Perspectives and Policy},
	author = {Goetz, Stephan J. and Heaton, Connor and Imran, Muhammad and Pan, Yuxuan and Tian, Zheng and Schmidt, Claudia and Qazi, Umair and Ofli, Ferda and Mitra, Prasenjit},
	month = jun,
	year = {2023},
	pages = {1189--1210},
}

@article{Anticipatingdroughtrelatedfoodsecuritychanges,
	title = {Anticipating drought-related food security changes},
	volume = {5},
	issn = {2398-9629},
	url = {https://www.nature.com/articles/s41893-022-00962-0},
	doi = {10.1038/s41893-022-00962-0},
	language = {en},
	number = {11},
	urldate = {2023-09-02},
	journal = {Nature Sustainability},
	author = {Krishnamurthy R, P. Krishna and Fisher, Joshua B. and Choularton, Richard J. and Kareiva, Peter M.},
	month = sep,
	year = {2022},
	pages = {956--964},
}

@article{MachinelearningfoodsecurityPrinciplesa,
	title = {Machine learning for food security: {Principles} for transparency and usability},
	volume = {44},
	issn = {2040-5804},
	shorttitle = {Machine learning for food security},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aepp.13214},
	doi = {10.1002/aepp.13214},
	abstract = {Machine learning (ML) holds potential to predict hunger crises before they occur. Yet, ML models embed crucial choices that affect their utility. We develop a prototype model to predict food insecurity across three countries in sub-Saharan Africa. Readily available data on prices, assets, and weather all influence our model predictions. Our model obtains 55\%–84\% accuracy, substantially outperforming both a logit and ML models using only time and location. We highlight key principles for transparency and demonstrate how modeling choices between recall and accuracy can be tailored to policy-maker needs. Our work provides a path for future modeling efforts in this area.},
	language = {en},
	number = {2},
	urldate = {2023-09-02},
	journal = {Applied Economic Perspectives and Policy},
	author = {Zhou, Yujun and Lentz, Erin and Michelson, Hope and Kim, Chungmann and Baylis, Kathy},
	year = {2022},
	keywords = {food policy, food security, machine learning, remote-sensing, sub-Saharan Africa},
	pages = {893--910},
}

@book{FoundationsIntelligentSystems26thInternational,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Foundations of {Intelligent} {Systems}: 26th {International} {Symposium}, {ISMIS} 2022, {Cosenza}, {Italy}, {October} 3–5, 2022, {Proceedings}},
	volume = {13515},
	isbn = {978-3-031-16563-4 978-3-031-16564-1},
	shorttitle = {Foundations of {Intelligent} {Systems}},
	url = {https://link.springer.com/10.1007/978-3-031-16564-1},
	language = {en},
	urldate = {2023-09-02},
	publisher = {Springer International Publishing},
	editor = {Ceci, Michelangelo and Flesca, Sergio and Masciari, Elio and Manco, Giuseppe and Raś, Zbigniew W.},
	year = {2022},
	doi = {10.1007/978-3-031-16564-1},
}

@inproceedings{Explainingfoodsecuritywarningsignals,
	address = {Limassol Cyprus},
	title = {Explaining food security warning signals with {YouTube} transcriptions and local news articles},
	isbn = {978-1-4503-9284-6},
	url = {https://dl.acm.org/doi/10.1145/3524458.3547240},
	doi = {10.1145/3524458.3547240},
	abstract = {Food security is a major concern in many countries all over the world. After a relatively long period characterized by a positive trend, the number and severity of food insecurity situations has been growing again in recent years, with alarming projections for the near future. While several Early Warning Systems (EWS) exist to monitor this phenomenon and guide the interventions of governments and ONGs, such systems rely on a narrow set of data types, i.e., mainly satellite imagery and survey data. These data can explain just a limited number of the multiple factors that impact on food security, thus producing an incomplete picture of the real scenario. In this work, we propose a spatio-temporal analysis of unconventional textual data (i.e., YouTube transcriptions and articles from local news papers) to support the explanatory process of food insecurity situations. This data, being completely exogenous to the one used in currently active EWS, can offer a different and complementary perspective on the causes of such crises. We focus on the area of West Africa, which has been at the center of many humanitarian crisis since the beginning of this century. By exploiting state of the art text mining techniques on a corpus of textual documents in French (including video transcriptions extracted from the YouTube channels of four West African news broadcasters and news articles obtained from the online versions of two local newspapers of Burkina Faso) we will analyze food security situations in different regions of the study area in recent years, by also proposing a food security indicator based on textual data, namely T XT -FS.},
	language = {en},
	urldate = {2023-09-02},
	booktitle = {Proceedings of the 2022 {ACM} {Conference} on {Information} {Technology} for {Social} {Good}},
	publisher = {ACM},
	author = {Ba, Cheick Tidiane and Choquet, Chloé and Interdonato, Roberto and Roche, Mathieu},
	month = sep,
	year = {2022},
	pages = {315--322},
}

@article{ArmedConflictsFoodInsecurityEvidence,
	title = {Armed {Conflicts} and {Food} {Insecurity}: {Evidence} from {Boko} {Haram}'s {Attacks}},
	volume = {102},
	issn = {1467-8276},
	shorttitle = {Armed {Conflicts} and {Food} {Insecurity}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1093/ajae/aaz039},
	doi = {10.1093/ajae/aaz039},
	abstract = {More than half of the 815 million undernourished people in the world live in countries struggling with conflict, violence and fragility. Conflict can impact food security conditions by destroying agricultural production, distribution and markets, hindering economic growth and increasing unemployment levels. By spatially joining the general household survey (GHS) panel data for Nigeria with Boko Haram terrorist incident data, we estimate the impact of Boko Haram attacks on food security conditions. We find that an increase in conflict intensity, measured by number of fatalities, increases the number of days where the household had to (1) rely on less preferred foods, (2) limit the variety of foods eaten, and (3) limit the portion size of meals consumed. However, the number of days that households went without eating anything, a more severe measure of food insecurity, was not affected. The food consumption score is also negatively affected by conflict. We also find that the conflict-driven food insecurity is mainly materialized through agricultural input and income shocks.},
	language = {en},
	number = {1},
	urldate = {2023-08-31},
	journal = {American Journal of Agricultural Economics},
	author = {George, Justin and Adelaja, Adesoji and Weatherspoon, Dave},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1093/ajae/aaz039},
	keywords = {Armed conflict, Boko Haram, dietary diversity, food, food insecurity, terrorism},
	pages = {114--131},
}

@inproceedings{Explainingmachinelearningclassifiersdiversea,
	address = {Barcelona Spain},
	title = {Explaining machine learning classifiers through diverse counterfactual explanations},
	isbn = {978-1-4503-6936-7},
	url = {https://dl.acm.org/doi/10.1145/3351095.3372850},
	doi = {10.1145/3351095.3372850},
	language = {en},
	urldate = {2023-08-30},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
	month = jan,
	year = {2020},
	keywords = {counterfactual, diverse},
	pages = {607--617},
}

@inproceedings{ExploringMentalModelsTransparentControllable,
	address = {Genoa Italy},
	title = {Exploring {Mental} {Models} for {Transparent} and {Controllable} {Recommender} {Systems}: {A} {Qualitative} {Study}},
	isbn = {978-1-4503-6861-2},
	shorttitle = {Exploring {Mental} {Models} for {Transparent} and {Controllable} {Recommender} {Systems}},
	url = {https://dl.acm.org/doi/10.1145/3340631.3394841},
	doi = {10.1145/3340631.3394841},
	language = {en},
	urldate = {2023-08-29},
	booktitle = {Proceedings of the 28th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Ngo, Thao and Kunkel, Johannes and Ziegler, Jürgen},
	month = jul,
	year = {2020},
	keywords = {mental-model, rec},
	pages = {183--191},
}

@inproceedings{WhatUserPersonalisingTransparencyMusic,
	address = {Genoa Italy},
	title = {What's in a {User}? {Towards} {Personalising} {Transparency} for {Music} {Recommender} {Interfaces}},
	isbn = {978-1-4503-6861-2},
	shorttitle = {What's in a {User}?},
	url = {https://dl.acm.org/doi/10.1145/3340631.3394844},
	doi = {10.1145/3340631.3394844},
	language = {en},
	urldate = {2023-08-29},
	booktitle = {Proceedings of the 28th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Millecamp, Martijn and Htun, Nyi Nyi and Conati, Cristina and Verbert, Katrien},
	month = jul,
	year = {2020},
	keywords = {explanation, interactive, rec},
	pages = {173--182},
}

@article{WhyWhyNotEffectJustification,
	title = {Why or {Why} {Not}? {The} {Effect} of {Justification} {Styles} on {Chatbot} {Recommendations}},
	volume = {39},
	issn = {1046-8188, 1558-2868},
	shorttitle = {Why or {Why} {Not}?},
	url = {https://dl.acm.org/doi/10.1145/3441715},
	doi = {10.1145/3441715},
	abstract = {Chatbots or conversational recommenders have gained increasing popularity as a new paradigm for Recommender Systems (RS). Prior work on RS showed that providing explanations can improve transparency and trust, which are critical for the adoption of RS. Their interactive and engaging nature makes conversational recommenders a natural platform to not only provide recommendations but also justify the recommendations through explanations. The recent surge of interest inexplainable AI enables diverse styles of justification, and also invites questions on how styles of justification impact user perception. In this article, we explore the effect of “why” justifications and “why not” justifications on users’ perceptions of explainability and trust. We developed and tested a movie-recommendation chatbot that provides users with different types of justifications for the recommended items. Our online experiment (
              n
              = 310) demonstrates that the “why” justifications (but not the “why not” justifications) have a significant impact on users’ perception of the conversational recommender. Particularly, “why” justifications increase users’ perception of system transparency, which impacts perceived control, trusting beliefs and in turn influences users’ willingness to depend on the system’s advice. Finally, we discuss the design implications for decision-assisting chatbots.},
	language = {en},
	number = {4},
	urldate = {2023-08-29},
	journal = {ACM Transactions on Information Systems},
	author = {Wilkinson, Daricia and Alkan, Öznur and Liao, Q. Vera and Mattetti, Massimiliano and Vejsbjerg, Inge and Knijnenburg, Bart P. and Daly, Elizabeth},
	month = oct,
	year = {2021},
	keywords = {explanation, rec},
	pages = {1--21},
}

@inproceedings{AddressingMarketingBiasProductRecommendations,
	address = {Houston TX USA},
	title = {Addressing {Marketing} {Bias} in {Product} {Recommendations}},
	isbn = {978-1-4503-6822-3},
	url = {https://dl.acm.org/doi/10.1145/3336191.3371855},
	doi = {10.1145/3336191.3371855},
	language = {en},
	urldate = {2023-08-20},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Wan, Mengting and Ni, Jianmo and Misra, Rishabh and McAuley, Julian},
	month = jan,
	year = {2020},
	keywords = {rec},
	pages = {618--626},
}

@inproceedings{ImpactEvaluationFrameworkPersonalizedNews,
	title = {An {Impact} {Evaluation} {Framework} of {Personalized} {News} {Aggregation} and {Recommendation} {Systems}},
	doi = {10.1109/WIIAT50758.2020.00136},
	abstract = {There are mounting concerns that personalized recommenders contribute to population differentiation and polarization by creating “information cocoons” that insulate people from opposing views. Despite the vast amount of research devoting to design new algorithms to improve the performance of recommendation systems, the evaluation mostly focuses on recommendation quality. Little attention is paid to the social impact of recommendation systems. On the other hand, it is noted in the literature that the users of recommendation systems suffer from “partial information blindness”, i.e. only exposed to the like-minded content information cocoon or filter bubble. Therefore, in this paper, we propose an impact evaluation framework of recommendation systems, comprising of five constructs, namely, diversity, objectivity, information cocoon, affect cocoon, and intentionality. The evaluation is conducted in a “black-box” way based on the empirical interaction data between the recommender and its individual users. To enable the individual level evaluation, we propose a lightweight agent-based simulation to collect individual’s interaction data with recommenders in the complex real-world scenarios. Furthermore, we illustrate the effectiveness of the proposed methodology with a case study in Toutiao and Baidu News, which are the top two news aggregator apps in China. The results show that both applications demonstrate a periodic information cocoon of about 7-day time interval, the news recommended through these two apps bear distinct differences: Toutiao has better captured the user’s reading preference and the quality of the recommended articles, while Baidu News demonstrate a higher affect cocoon and intentionality in the recommended articles, with average perceived difficulty of the recommended articles 2.9\% higher than Toutiao, and average perceived persuasiveness 9.6\% higher than Toutiao.},
	booktitle = {2020 {IEEE}/{WIC}/{ACM} {International} {Joint} {Conference} on {Web} {Intelligence} and {Intelligent} {Agent} {Technology} ({WI}-{IAT})},
	author = {Zhao, Yunwei and Wang, Can and Han, Han and Shu, Min and Wang, Wenlei},
	month = dec,
	year = {2020},
	keywords = {Data models, Information filters, Intelligent agents, Sociology, Statistics, Web and internet services, evaluation framework, news, personalized recommendation, rec, social impact},
	pages = {893--900},
}

@article{Attributingchangesfoodinsecuritychanging,
	title = {Attributing changes in food insecurity to a changing climate},
	volume = {12},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-08696-x},
	doi = {10.1038/s41598-022-08696-x},
	abstract = {Abstract
            
              It is generally accepted that climate change is having a negative impact on food security. However, most of the literature variously focuses on the complex and many mechanisms linking climate stressors; the links with food production or productivity rather than food security; and future rather than current effects. In contrast, we investigate the extent to which current changes in food insecurity can be plausibly attributed to climate change. We combine food insecurity data for 83 countries from the FAO food insecurity experience scale (FIES) with reanalysed climate data from ERA5-Land, and use a panel data regression with time-varying coefficients. This framework allows us to estimate whether the relationship between food insecurity and temperature anomaly is changing over time. We also control for Human Development Index, and drought measured by six-month Standardized Precipitation Index. Our empirical findings suggest that for every 1 
              
                
                  \$\${\textasciicircum}\{{\textbackslash}circ \}{\textbackslash}hbox \{C\}\$\$
                  
                    
                      
                        
                        ∘
                      
                      C
                    
                  
                
              
              of temperature anomaly, severe global food insecurity has increased by 1.4\% (95\% CI 1.3–1.47) in 2014 but by 1.64\% (95\% CI 1.6–1.65) in 2019. This impact is higher in the case of moderate to severe food insecurity, with a 1 
              
                
                  \$\${\textasciicircum}\{{\textbackslash}circ \}{\textbackslash}hbox \{C\}\$\$
                  
                    
                      
                        
                        ∘
                      
                      C
                    
                  
                
              
              increase in temperature anomaly resulting in a 1.58\% (95\% CI 1.48–1.68) increase in 2014 but a 2.14\% (95\% CI 2.08–2.20) increase in 2019. Thus, the results show that the temperature anomaly has not only increased the probability of food insecurity, but the magnitude of this impact has increased over time. Our counterfactual analysis suggests that climate change has been responsible for reversing some of the improvements in food security that would otherwise have been realised, with the highest impact in Africa. Our analysis both provides more evidence of the costs of climate change, and as such the benefits of mitigation, and also highlights the importance of targeted and efficient policies to reduce food insecurity. These policies are likely to need to take into account local contexts, and might include efforts to increase crop yields, targeted safety nets, and behavioural programs to promote household resilience.},
	language = {en},
	number = {1},
	urldate = {2023-08-31},
	journal = {Scientific Reports},
	author = {Dasgupta, Shouro and Robinson, Elizabeth J. Z.},
	month = mar,
	year = {2022},
	pages = {4709},
}

@inproceedings{ModelAgnosticCounterfactualExplanationsRecommendations,
	address = {Utrecht Netherlands},
	title = {Model-{Agnostic} {Counterfactual} {Explanations} of {Recommendations}},
	isbn = {978-1-4503-8366-0},
	url = {https://dl.acm.org/doi/10.1145/3450613.3456846},
	doi = {10.1145/3450613.3456846},
	language = {en},
	urldate = {2023-08-30},
	booktitle = {Proceedings of the 29th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Kaffes, Vassilis and Sacharidis, Dimitris and Giannopoulos, Giorgos},
	month = jun,
	year = {2021},
	keywords = {counterfactual, explanation, rec},
	pages = {280--285},
}

@inproceedings{NewsVizDepictingControllingPreferenceProfiles,
	address = {Genoa Italy},
	title = {{NewsViz}: {Depicting} and {Controlling} {Preference} {Profiles} {Using} {Interactive} {Treemaps} in {News} {Recommender} {Systems}},
	isbn = {978-1-4503-6861-2},
	shorttitle = {{NewsViz}},
	url = {https://dl.acm.org/doi/10.1145/3340631.3394869},
	doi = {10.1145/3340631.3394869},
	language = {en},
	urldate = {2023-08-29},
	booktitle = {Proceedings of the 28th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Kunkel, Johannes and Schwenger, Claudia and Ziegler, Jürgen},
	month = jul,
	year = {2020},
	keywords = {interactive, news, rec, vis},
	pages = {126--135},
}

@inproceedings{DesigningAITrustCollaborationTimeConstrained,
	address = {Yokohama Japan},
	title = {Designing {AI} for {Trust} and {Collaboration} in {Time}-{Constrained} {Medical} {Decisions}: {A} {Sociotechnical} {Lens}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Designing {AI} for {Trust} and {Collaboration} in {Time}-{Constrained} {Medical} {Decisions}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445385},
	doi = {10.1145/3411764.3445385},
	language = {en},
	urldate = {2023-06-20},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Jacobs, Maia and He, Jeffrey and F. Pradier, Melanie and Lam, Barbara and Ahn, Andrew C. and McCoy, Thomas H. and Perlis, Roy H. and Doshi-Velez, Finale and Gajos, Krzysztof Z.},
	month = may,
	year = {2021},
	keywords = {codesign},
	pages = {1--14},
}

@misc{ExplainableAIDeadLongLive,
	title = {Explainable {AI} is {Dead}, {Long} {Live} {Explainable} {AI}! {Hypothesis}-driven decision support},
	url = {http://arxiv.org/abs/2302.12389},
	abstract = {In this paper, we argue for a paradigm shift from the current model of explainable artificial intelligence (XAI), which may be counter-productive to better human decision making. In early decision support systems, we assumed that we could give people recommendations and that they would consider them, and then follow them when required. However, research found that people often ignore recommendations because they do not trust them; or perhaps even worse, people follow them blindly, even when the recommendations are wrong. Explainable artificial intelligence mitigates this by helping people to understand how and why models give certain recommendations. However, recent research shows that people do not always engage with explainability tools enough to help improve decision making. The assumption that people will engage with recommendations and explanations has proven to be unfounded. We argue this is because we have failed to account for two things. First, recommendations (and their explanations) take control from human decision makers, limiting their agency. Second, giving recommendations and explanations does not align with the cognitive processes employed by people making decisions. This position paper proposes a new conceptual framework called Evaluative AI for explainable decision support. This is a machine-in-the-loop paradigm in which decision support tools provide evidence for and against decisions made by people, rather than provide recommendations to accept or reject. We argue that this mitigates issues of over- and under-reliance on decision support tools, and better leverages human expertise in decision making.},
	urldate = {2023-07-13},
	publisher = {arXiv},
	author = {Miller, Tim},
	month = mar,
	year = {2023},
	note = {arXiv:2302.12389 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, explanation},
}

@inproceedings{Proxytaskssubjectivemeasurescan,
	address = {Cagliari Italy},
	title = {Proxy tasks and subjective measures can be misleading in evaluating explainable {AI} systems},
	isbn = {978-1-4503-7118-6},
	url = {https://dl.acm.org/doi/10.1145/3377325.3377498},
	doi = {10.1145/3377325.3377498},
	language = {en},
	urldate = {2023-07-13},
	booktitle = {Proceedings of the 25th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Buçinca, Zana and Lin, Phoebe and Gajos, Krzysztof Z. and Glassman, Elena L.},
	month = mar,
	year = {2020},
	keywords = {explanation, well-written},
	pages = {454--464},
}

@article{WeNeedTalkChatGPTFuture,
	title = {“{We} {Need} {To} {Talk} {About} {ChatGPT}”: {The} {Future} of {AI} and {Higher} {Education}},
	abstract = {On November 30th, 2022, OpenAI released the large language model ChatGPT, an extension of GPT-3. The AI chatbot provides real-time communication in response to users’ requests. The quality of ChatGPT’s natural speaking answers marks a major shift in how we will use AI-generated information in our day-to-day lives. For a software engineering student, the use cases for ChatGPT are manifold: assessment preparation, translation, and creation of specified source code, to name a few. It can even handle more complex aspects of scientific writing, such as summarizing literature and paraphrasing text. Hence, this position paper addresses the need for discussion of potential approaches for integrating ChatGPT into higher education. Therefore, we focus on articles that address the effects of ChatGPT on higher education in the areas of software engineering and scientific writing. As ChatGPT was only recently released, there have been no peer-reviewed articles on the subject. Thus, we performed a structured grey literature review using Google Scholar to identify preprints of primary studies. In total, five out of 55 preprints are used for our analysis. Furthermore, we held informal discussions and talks with other lecturers and researchers and took into account the authors’ test results from using ChatGPT. We present five challenges and three opportunities for the higher education context that emerge from the release of ChatGPT. The main contribution of this paper is a proposal for how to integrate ChatGPT into higher education in four main areas.},
	language = {en},
	author = {Neumann, Michael and Rauschenberger, Maria and Schon, Eva-Maria},
}

@misc{NextStepsHumanCenteredGenerativeAI,
	title = {Next {Steps} for {Human}-{Centered} {Generative} {AI}: {A} {Technical} {Perspective}},
	shorttitle = {Next {Steps} for {Human}-{Centered} {Generative} {AI}},
	url = {http://arxiv.org/abs/2306.15774},
	abstract = {Through iterative, cross-disciplinary discussions, we define and propose next-steps for Human-centered Generative AI (HGAI) from a technical perspective. We contribute a roadmap that lays out future directions of Generative AI spanning three levels: Aligning with human values; Accommodating humans' expression of intents; and Augmenting humans' abilities in a collaborative workflow. This roadmap intends to draw interdisciplinary research teams to a comprehensive list of emergent ideas in HGAI, identifying their interested topics while maintaining a coherent big picture of the future work landscape.},
	urldate = {2023-06-30},
	publisher = {arXiv},
	author = {Chen, Xiang 'Anthony' and Burke, Jeff and Du, Ruofei and Hong, Matthew K. and Jacobs, Jennifer and Laban, Philippe and Li, Dingzeyu and Peng, Nanyun and Willis, Karl D. D. and Wu, Chien-Sheng and Zhou, Bolei},
	month = jun,
	year = {2023},
	note = {arXiv:2306.15774 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, generative, hci},
}

@inproceedings{SelectiveMutableDialogicXAIReview,
	address = {Hamburg Germany},
	title = {On {Selective}, {Mutable} and {Dialogic} {XAI}: a {Review} of {What} {Users} {Say} about {Different} {Types} of {Interactive} {Explanations}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {On {Selective}, {Mutable} and {Dialogic} {XAI}},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581314},
	doi = {10.1145/3544548.3581314},
	language = {en},
	urldate = {2023-07-03},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bertrand, Astrid and Viard, Tiphaine and Belloum, Rafik and Eagan, James R. and Maxwell, Winston},
	month = apr,
	year = {2023},
	keywords = {explanation, review},
	pages = {1--21},
}

@inproceedings{DesigningResponsibleTrustAISystems,
	address = {Seoul Republic of Korea},
	title = {Designing for {Responsible} {Trust} in {AI} {Systems}: {A} {Communication} {Perspective}},
	isbn = {978-1-4503-9352-2},
	shorttitle = {Designing for {Responsible} {Trust} in {AI} {Systems}},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533182},
	doi = {10.1145/3531146.3533182},
	language = {en},
	urldate = {2023-06-20},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Liao, Q.Vera and Sundar, S. Shyam},
	month = jun,
	year = {2022},
	keywords = {explanation},
	pages = {1257--1268},
}

@article{Drugdiscoveryexplainableartificialintelligence,
	title = {Drug discovery with explainable artificial intelligence},
	volume = {2},
	copyright = {2020 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-020-00236-4},
	doi = {10.1038/s42256-020-00236-4},
	abstract = {Deep learning bears promise for drug discovery, including advanced image analysis, prediction of molecular structure and function, and automated generation of innovative chemical entities with bespoke properties. Despite the growing number of successful prospective applications, the underlying mathematical models often remain elusive to interpretation by the human mind. There is a demand for ‘explainable’ deep learning methods to address the need for a new narrative of the machine language of the molecular sciences. This Review summarizes the most prominent algorithmic concepts of explainable artificial intelligence, and forecasts future opportunities, potential applications as well as several remaining challenges. We also hope it encourages additional efforts towards the development and acceptance of explainable artificial intelligence techniques.},
	language = {en},
	number = {10},
	urldate = {2023-07-08},
	journal = {Nature Machine Intelligence},
	author = {Jiménez-Luna, José and Grisoni, Francesca and Schneider, Gisbert},
	month = oct,
	year = {2020},
	note = {Number: 10
Publisher: Nature Publishing Group},
	keywords = {Cheminformatics, Computational science, Drug discovery and development, explanation, xai},
	pages = {573--584},
}

@article{ProgressiveDisclosureWhenWhyHow,
	title = {Progressive {Disclosure}: {When}, {Why}, and {How} {Do} {Users} {Want} {Algorithmic} {Transparency} {Information}?},
	volume = {10},
	issn = {2160-6455, 2160-6463},
	shorttitle = {Progressive {Disclosure}},
	url = {https://dl.acm.org/doi/10.1145/3374218},
	doi = {10.1145/3374218},
	abstract = {It is essential that users understand how algorithmic decisions are made, as we increasingly delegate important decisions to intelligent systems. Prior work has often taken a techno-centric approach, focusing on new computational techniques to support transparency. In contrast, this article employs empirical methods to better understand user reactions to transparent systems to motivate user-centric designs for transparent systems. We assess user reactions to transparency feedback in four studies of an emotional analytics system. In Study 1, users anticipated that a transparent system would perform better but unexpectedly retracted this evaluation after experience with the system. Study 2 offers an explanation for this paradox by showing that the benefits of transparency are context dependent. On the one hand, transparency can help users form a model of the underlying algorithm's operation. On the other hand, positive accuracy perceptions may be undermined when transparency reveals algorithmic errors. Study 3 explored real-time reactions to transparency. Results confirmed Study 2, in showing that users are both more likely to consult transparency information and to experience greater system insights when formulating a model of system operation. Study 4 used qualitative methods to explore real-time user reactions to motivate transparency design principles. Results again suggest that users may benefit from initially simplified feedback that hides potential system errors and assists users in building working heuristics about system operation. We use these findings to motivate new progressive disclosure principles for transparency in intelligent systems and discuss theoretical implications.},
	language = {en},
	number = {4},
	urldate = {2021-08-24},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Springer, Aaron and Whittaker, Steve},
	month = dec,
	year = {2020},
	keywords = {codesign, explanation, transparency, well-written},
	pages = {1--32},
}

@inproceedings{WaitWhyAssessingBehaviorExplanation,
	address = {College Station TX USA},
	title = {Wait, {But} {Why}?: {Assessing} {Behavior} {Explanation} {Strategies} for {Real}-{Time} {Strategy} {Games}},
	isbn = {978-1-4503-8017-1},
	shorttitle = {Wait, {But} {Why}?},
	url = {https://dl.acm.org/doi/10.1145/3397481.3450699},
	doi = {10.1145/3397481.3450699},
	language = {en},
	urldate = {2023-06-20},
	booktitle = {26th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Robertson, Justus and Kokkinakis, Athanasios Vasileios and Hook, Jonathan and Kirman, Ben and Block, Florian and Ursu, Marian F and Patra, Sagarika and Demediuk, Simon and Drachen, Anders and Olarewaju, Oluseyi},
	month = apr,
	year = {2021},
	keywords = {explanation},
	pages = {32--42},
}

@inproceedings{CheXplainEnablingPhysiciansExploreUnderstand,
	address = {Honolulu HI USA},
	title = {{CheXplain}: {Enabling} {Physicians} to {Explore} and {Understand} {Data}-{Driven}, {AI}-{Enabled} {Medical} {Imaging} {Analysis}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{CheXplain}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376807},
	doi = {10.1145/3313831.3376807},
	language = {en},
	urldate = {2023-06-20},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Xie, Yao and Chen, Melody and Kao, David and Gao, Ge and Chen, Xiang 'Anthony'},
	month = apr,
	year = {2020},
	keywords = {codesign, explanation},
	pages = {1--13},
}

@inproceedings{UnderstandingBenefitsChallengesDeployingConversationala,
	address = {Hamburg Germany},
	title = {Understanding the {Benefits} and {Challenges} of {Deploying} {Conversational} {AI} {Leveraging} {Large} {Language} {Models} for {Public} {Health} {Intervention}},
	isbn = {978-1-4503-9421-5},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581503},
	doi = {10.1145/3544548.3581503},
	abstract = {Recent large language models (LLMs) have advanced the quality of open-ended conversations with chatbots. Although LLM-driven chatbots have the potential to support public health interventions by monitoring populations at scale through empathetic interactions, their use in real-world settings is underexplored. We thus examine the case of CareCall, an open-domain chatbot that aims to support socially isolated individuals via check-up phone calls and monitoring by teleoperators. Through focus group observations and interviews with 34 people from three stakeholder groups, including the users, the teleoperators, and the developers, we found CareCall ofered a holistic understanding of each individual while ofoading the public health workload and helped mitigate loneliness and emotional burdens. However, our fndings highlight that traits of LLM-driven chatbots led to challenges in supporting public and personal health needs. We discuss considerations of designing and deploying LLM-driven chatbots for public health intervention, including tensions among stakeholders around system expectations.},
	language = {en},
	urldate = {2023-06-13},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Jo, Eunkyung and Epstein, Daniel A. and Jung, Hyunhoon and Kim, Young-Ho},
	month = apr,
	year = {2023},
	keywords = {hci, llm},
	pages = {1--16},
}

@inproceedings{Toomuchtoolittlejust,
	address = {San Jose, CA, USA},
	title = {Too much, too little, or just right? {Ways} explanations impact end users' mental models},
	isbn = {978-1-4799-0369-6},
	shorttitle = {Too much, too little, or just right?},
	url = {https://ieeexplore.ieee.org/document/6645235},
	doi = {10.1109/VLHCC.2013.6645235},
	abstract = {Research is emerging on how end users can correct mistakes their intelligent agents make, but before users can correctly “debug” an intelligent agent, they need some degree of understanding of how it works. In this paper we consider ways intelligent agents should explain themselves to end users, especially focusing on how the soundness and completeness of the explanations impacts the fidelity of end users’ mental models. Our findings suggest that completeness is more important than soundness: increasing completeness via certain information types helped participants’ mental models and, surprisingly, their perception of the cost/benefit tradeoff of attending to the explanations. We also found that oversimplification, as per many commercial agents, can be a problem: when soundness was very low, participants experienced more mental demand and lost trust in the explanations, thereby reducing the likelihood that users will pay attention to such explanations at all.},
	language = {en},
	urldate = {2023-06-12},
	booktitle = {2013 {IEEE} {Symposium} on {Visual} {Languages} and {Human} {Centric} {Computing}},
	publisher = {IEEE},
	author = {Kulesza, Todd and Stumpf, Simone and Burnett, Margaret and Yang, Sherry and Kwan, Irwin and Wong, Weng-Keen},
	month = sep,
	year = {2013},
	pages = {3--10},
}

@article{TrustThinkCognitiveForcingFunctions,
	title = {To {Trust} or to {Think}: {Cognitive} {Forcing} {Functions} {Can} {Reduce} {Overreliance} on {AI} in {AI}-assisted {Decision}-making},
	volume = {5},
	issn = {2573-0142},
	shorttitle = {To {Trust} or to {Think}},
	url = {https://dl.acm.org/doi/10.1145/3449287},
	doi = {10.1145/3449287},
	abstract = {People supported by AI-powered decision support tools frequently overrely on the AI: they accept an AI's suggestion even when that suggestion is wrong. Adding explanations to the AI decisions does not appear to reduce the overreliance and some studies suggest that it might even increase it. Informed by the dual-process theory of cognition, we posit that people rarely engage analytically with each individual AI recommendation and explanation, and instead develop general heuristics about whether and when to follow the AI suggestions. Building on prior research on medical decision-making, we designed three cognitive forcing interventions to compel people to engage more thoughtfully with the AI-generated explanations. We conducted an experiment (N=199), in which we compared our three cognitive forcing designs to two simple explainable AI approaches and to a no-AI baseline. The results demonstrate that cognitive forcing significantly reduced overreliance compared to the simple explainable AI approaches. However, there was a trade-off: people assigned the least favorable subjective ratings to the designs that reduced the overreliance the most. To audit our work for intervention-generated inequalities, we investigated whether our interventions benefited equally people with different levels of Need for Cognition (i.e., motivation to engage in effortful mental activities). Our results show that, on average, cognitive forcing interventions benefited participants higher in Need for Cognition more. Our research suggests that human cognitive motivation moderates the effectiveness of explainable AI solutions.},
	language = {en},
	number = {CSCW1},
	urldate = {2023-06-10},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Buçinca, Zana and Malaya, Maja Barbara and Gajos, Krzysztof Z.},
	month = apr,
	year = {2021},
	pages = {1--21},
}

@article{Predictingpovertywealthmobilephone,
	title = {Predicting poverty and wealth from mobile phone metadata},
	volume = {350},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aac4420},
	doi = {10.1126/science.aac4420},
	language = {en},
	number = {6264},
	urldate = {2023-06-07},
	journal = {Science},
	author = {Blumenstock, Joshua and Cadamuro, Gabriel and On, Robert},
	month = nov,
	year = {2015},
	pages = {1073--1076},
}

@article{FoodsecurityconflictEmpiricalchallenges,
	title = {Food security and conflict: {Empirical} challenges and future opportunities for research and policy making on food security and conflict},
	volume = {119},
	issn = {0305750X},
	shorttitle = {Food security and conflict},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0305750X18302407},
	doi = {10.1016/j.worlddev.2018.07.011},
	abstract = {During the previous decade, there has been an increased focus on the role of food security in processes of armed conﬂict, both in the academic and policy communities. While the policy community has pushed forward with new programs, the academic debate about the causal linkages between food security and conﬂict remains contested. This article examines the endogeneity that characterizes the coupling between food (in)security and conﬂict and makes three contributions. First, we deﬁne conﬂict and food security using the Uppsala Conﬂict Data Program and the FAO databases, and illustrate how intervening factors inﬂuence the relationship between conﬂict and food security at the micro and macro levels. Second, we provide a comprehensive review of the literature on the linkages between food security and conﬂict, focusing on ﬁndings that account for endogeneity issues and have a causal interpretation. Third, we highlight key data issues related to conﬂict and food security, and chart ways forward to collect new and better data that can help to ﬁll existing academic gaps and support policymaking.},
	language = {en},
	urldate = {2023-06-06},
	journal = {World Development},
	author = {Martin-Shields, Charles P. and Stojetz, Wolfgang},
	month = jul,
	year = {2019},
	pages = {150--164},
}

@article{CausalStructureLearningFaminePrediction,
	title = {Causal {Structure} {Learning} for {Famine} {Prediction}},
	abstract = {Food shortages are increasing in many areas of the world. In this paper, we consider the problem of understanding the causal relationships between socioeconomic factors in a developing-world household and their risk of experiencing famine. We analyse the extent to which it is possible to predict famine in a household based on these factors, looking at a data collected from 5404 households in Uganda. To do this we use a set of causal structure learning algorithms, employed as a committee that votes on the causal relationships between the variables. We contrast prediction accuracy of famine based on feature sets suggested by our prior knowledge and by the models we learn.},
	language = {en},
	author = {Mwebaze, Ernest and Okori, Washington and Quinn, John A},
	keywords = {food, insecurity},
}

@article{Foodsecuritysustainabilitycanonea,
	title = {Food security and sustainability: can one exist without the other?},
	volume = {18},
	issn = {1368-9800, 1475-2727},
	shorttitle = {Food security and sustainability},
	url = {https://www.cambridge.org/core/product/identifier/S136898001500021X/type/journal_article},
	doi = {10.1017/S136898001500021X},
	abstract = {Objective: To position the concept of sustainability within the context of food security. Design: An overview of the interrelationships between food security and sustainability based on a non-systematic literature review and informed discussions based principally on a quasi-historical approach from meetings and reports. Setting: International and global food security and nutrition.
Results: The Rome Declaration on World Food Security in 1996 deﬁned its three basic dimensions as: availability, accessibility and utilization, with a focus on nutritional well-being. It also stressed the importance of sustainable management of natural resources and the elimination of unsustainable patterns of food consumption and production. In 2009, at the World Summit on Food Security, the concept of stability/vulnerability was added as the short-term time indicator of the ability of food systems to withstand shocks, whether natural or man-made, as part of the Five Rome Principles for Sustainable Global Food Security. More recently, intergovernmental processes have emphasized the importance of sustainability to preserve the environment, natural resources and agro-ecosystems (and thus the overlying social system), as well as the importance of food security as part of sustainability and vice versa.
Conclusions: Sustainability should be considered as part of the long-term time dimension in the assessment of food security. From such a perspective the concept of sustainable diets can play a key role as a goal and a way of maintaining nutritional well-being and health, while ensuring the sustainability for future food security. Without integrating sustainability as an explicit (ﬁfth?) dimension of food security, today’s policies and programmes could become the very cause of increased food insecurity in the future.},
	language = {en},
	number = {13},
	urldate = {2023-06-06},
	journal = {Public Health Nutrition},
	author = {Berry, Elliot M and Dernini, Sandro and Burlingame, Barbara and Meybeck, Alexandre and Conforti, Piero},
	month = sep,
	year = {2015},
	keywords = {food, insecurity},
	pages = {2293--2302},
}

@article{Combiningsatelliteimagerymachinelearning,
	title = {Combining satellite imagery and machine learning to predict poverty},
	volume = {353},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aaf7894},
	doi = {10.1126/science.aaf7894},
	abstract = {Measuring consumption and wealth remotely
            
              Nighttime lighting is a rough proxy for economic wealth, and nighttime maps of the world show that many developing countries are sparsely illuminated. Jean
              et al.
              combined nighttime maps with high-resolution daytime satellite images (see the Perspective by Blumenstock). With a bit of machine-learning wizardry, the combined images can be converted into accurate estimates of household consumption and assets, both of which are hard to measure in poorer countries. Furthermore, the night- and day-time data are publicly available and nonproprietary.
            
            
              Science
              , this issue p.
              790
              ; see also p.
              753
            
          , 
            Satellites collect data that can be used to measure income and wealth.
          , 
            Reliable data on economic livelihoods remain scarce in the developing world, hampering efforts to study these outcomes and to design policies that improve them. Here we demonstrate an accurate, inexpensive, and scalable method for estimating consumption expenditure and asset wealth from high-resolution satellite imagery. Using survey and satellite data from five African countries—Nigeria, Tanzania, Uganda, Malawi, and Rwanda—we show how a convolutional neural network can be trained to identify image features that can explain up to 75\% of the variation in local-level economic outcomes. Our method, which requires only publicly available data, could transform efforts to track and target poverty in developing countries. It also demonstrates how powerful machine learning techniques can be applied in a setting with limited training data, suggesting broad potential application across many scientific domains.},
	language = {en},
	number = {6301},
	urldate = {2023-06-06},
	journal = {Science},
	author = {Jean, Neal and Burke, Marshall and Xie, Michael and Davis, W. Matthew and Lobell, David B. and Ermon, Stefano},
	month = aug,
	year = {2016},
	pages = {790--794},
}

@article{PrioritizingClimateChangeAdaptationNeeds,
	title = {Prioritizing {Climate} {Change} {Adaptation} {Needs} for {Food} {Security} in 2030},
	volume = {319},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.1152339},
	doi = {10.1126/science.1152339},
	abstract = {Investments aimed at improving agricultural adaptation to climate change inevitably favor some crops and regions over others. An analysis of climate risks for crops in 12 food-insecure regions was conducted to identify adaptation priorities, based on statistical crop models and climate projections for 2030 from 20 general circulation models. Results indicate South Asia and Southern Africa as two regions that, without sufficient adaptation measures, will likely suffer negative impacts on several crops that are important to large food-insecure human populations. We also find that uncertainties vary widely by crop, and therefore priorities will depend on the risk attitudes of investment institutions.},
	language = {en},
	number = {5863},
	urldate = {2023-06-06},
	journal = {Science},
	author = {Lobell, David B. and Burke, Marshall B. and Tebaldi, Claudia and Mastrandrea, Michael D. and Falcon, Walter P. and Naylor, Rosamond L.},
	month = feb,
	year = {2008},
	keywords = {food, insecurity},
	pages = {607--610},
}

@misc{SurveyLargeLanguageModels,
	title = {A {Survey} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2303.18223},
	abstract = {Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.},
	urldate = {2023-04-28},
	publisher = {arXiv},
	author = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and Du, Yifan and Yang, Chen and Chen, Yushuo and Chen, Zhipeng and Jiang, Jinhao and Ren, Ruiyang and Li, Yifan and Tang, Xinyu and Liu, Zikang and Liu, Peiyu and Nie, Jian-Yun and Wen, Ji-Rong},
	month = apr,
	year = {2023},
	note = {arXiv:2303.18223 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, llm, nlp},
}

@misc{ReprintFoodsecurityviolentconflict,
	title = {Reprint of: {Food} security and violent conflict: {Introduction} to the special issue {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Reprint of},
	url = {https://reader.elsevier.com/reader/sd/pii/S0305750X19300798?token=DAABB6D6561444A90AA187B7BCCBEC65CF2F9346DB2B5CBBBCA32EBCC43F5CE31699D42182AE10224EDE5AC66A3ECF2A&originRegion=us-east-1&originCreation=20230511115830},
	language = {en},
	urldate = {2023-05-11},
	doi = {10.1016/j.worlddev.2019.04.006},
	keywords = {food, insecurity},
}

@article{endtoendassessmentextremeweatherimpacts,
	title = {An end-to-end assessment of extreme weather impacts on food security},
	volume = {5},
	issn = {1758-678X, 1758-6798},
	url = {http://www.nature.com/articles/nclimate2747},
	doi = {10.1038/nclimate2747},
	language = {en},
	number = {11},
	urldate = {2023-05-11},
	journal = {Nature Climate Change},
	author = {Chavez, Erik and Conway, Gordon and Ghil, Michael and Sadler, Marc},
	month = nov,
	year = {2015},
	pages = {997--1001},
}

@article{forecastabilityfoodinsecurity,
	title = {On the forecastability of food insecurity},
	volume = {13},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-29700-y},
	doi = {10.1038/s41598-023-29700-y},
	abstract = {Abstract
            Food insecurity, defined as the lack of physical or economic access to safe, nutritious and sufficient food, remains one of the main challenges included in the 2030 Agenda for Sustainable Development. Near real-time data on the food insecurity situation collected by international organizations such as the World Food Programme can be crucial to monitor and forecast time trends of insufficient food consumption levels in countries at risk. Here, using food consumption observations in combination with secondary data on conflict, extreme weather events and economic shocks, we build a forecasting model based on gradient boosted regression trees to create predictions on the evolution of insufficient food consumption trends up to 30 days in to the future in 6 countries (Burkina Faso, Cameroon, Mali, Nigeria, Syria and Yemen). Results show that the number of available historical observations is a key element for the forecasting model performance. Among the 6 countries studied in this work, for those with the longest food insecurity time series, that is Syria and Yemen, the proposed forecasting model allows to forecast the prevalence of people with insufficient food consumption up to 30 days into the future with higher accuracy than a naive approach based on the last measured prevalence only. The framework developed in this work could provide decision makers with a tool to assess how the food insecurity situation will evolve in the near future in countries at risk. Results clearly point to the added value of continuous near real-time data collection at sub-national level.},
	language = {en},
	number = {1},
	urldate = {2023-05-03},
	journal = {Scientific Reports},
	author = {Foini, Pietro and Tizzoni, Michele and Martini, Giulia and Paolotti, Daniela and Omodei, Elisa},
	month = mar,
	year = {2023},
	pages = {2793},
}

@article{ShortcutLensVisualAnalyticsApproachExploring,
	title = {{ShortcutLens}: {A} {Visual} {Analytics} {Approach} for {Exploring} {Shortcuts} in {Natural} {Language} {Understanding} {Dataset}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{ShortcutLens}},
	url = {http://arxiv.org/abs/2208.08010},
	doi = {10.1109/TVCG.2023.3236380},
	abstract = {Benchmark datasets play an important role in evaluating Natural Language Understanding (NLU) models. However, shortcuts -- unwanted biases in the benchmark datasets -- can damage the effectiveness of benchmark datasets in revealing models' real capabilities. Since shortcuts vary in coverage, productivity, and semantic meaning, it is challenging for NLU experts to systematically understand and avoid them when creating benchmark datasets. In this paper, we develop a visual analytics system, ShortcutLens, to help NLU experts explore shortcuts in NLU benchmark datasets. The system allows users to conduct multi-level exploration of shortcuts. Specifically, Statistics View helps users grasp the statistics such as coverage and productivity of shortcuts in the benchmark dataset. Template View employs hierarchical and interpretable templates to summarize different types of shortcuts. Instance View allows users to check the corresponding instances covered by the shortcuts. We conduct case studies and expert interviews to evaluate the effectiveness and usability of the system. The results demonstrate that ShortcutLens supports users in gaining a better understanding of benchmark dataset issues through shortcuts, inspiring them to create challenging and pertinent benchmark datasets.},
	urldate = {2023-04-25},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Jin, Zhihua and Wang, Xingbo and Cheng, Furui and Sun, Chunhui and Liu, Qun and Qu, Huamin},
	year = {2023},
	note = {arXiv:2208.08010 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
	pages = {1--15},
}

@inproceedings{ConceptualizingAlgorithmicStigmatization,
	address = {Hamburg Germany},
	title = {Conceptualizing {Algorithmic} {Stigmatization}},
	isbn = {978-1-4503-9421-5},
	url = {https://dl.acm.org/doi/10.1145/3544548.3580970},
	doi = {10.1145/3544548.3580970},
	language = {en},
	urldate = {2023-04-24},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Andalibi, Nazanin and Pyle, Cassidy and Barta, Kristen and Xian, Lu and Jacobs, Abigail Z. and Ackerman, Mark S.},
	month = apr,
	year = {2023},
	keywords = {fair, stereotype},
	pages = {1--18},
}

@misc{GenerativeAgentsInteractiveSimulacraHuman,
	title = {Generative {Agents}: {Interactive} {Simulacra} of {Human} {Behavior}},
	shorttitle = {Generative {Agents}},
	url = {http://arxiv.org/abs/2304.03442},
	abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture--observation, planning, and reflection--each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
	urldate = {2023-04-11},
	publisher = {arXiv},
	author = {Park, Joon Sung and O'Brien, Joseph C. and Cai, Carrie J. and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
	month = apr,
	year = {2023},
	note = {arXiv:2304.03442 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, generative, hci},
}

@misc{ChallengingLongTailRecommendation,
	title = {Challenging the {Long} {Tail} {Recommendation}},
	url = {http://arxiv.org/abs/1205.6700},
	abstract = {The success of "infinite-inventory" retailers such as Amazon.com and Netflix has been largely attributed to a "long tail" phenomenon. Although the majority of their inventory is not in high demand, these niche products, unavailable at limited-inventory competitors, generate a significant fraction of total revenue in aggregate. In addition, tail product availability can boost head sales by offering consumers the convenience of "one-stop shopping" for both their mainstream and niche tastes. However, most of existing recommender systems, especially collaborative filter based methods, can not recommend tail products due to the data sparsity issue. It has been widely acknowledged that to recommend popular products is easier yet more trivial while to recommend long tail products adds more novelty yet it is also a more challenging task. In this paper, we propose a novel suite of graph-based algorithms for the long tail recommendation. We first represent user-item information with undirected edge-weighted graph and investigate the theoretical foundation of applying Hitting Time algorithm for long tail item recommendation. To improve recommendation diversity and accuracy, we extend Hitting Time and propose efficient Absorbing Time algorithm to help users find their favorite long tail items. Finally, we refine the Absorbing Time algorithm and propose two entropy-biased Absorbing Cost algorithms to distinguish the variation on different user-item rating pairs, which further enhances the effectiveness of long tail recommendation. Empirical experiments on two real life datasets show that our proposed algorithms are effective to recommend long tail items and outperform state-of-the-art recommendation techniques.},
	urldate = {2023-04-10},
	publisher = {arXiv},
	author = {Yin, Hongzhi and Cui, Bin and Li, Jing and Yao, Junjie and Chen, Chen},
	month = may,
	year = {2012},
	note = {arXiv:1205.6700 [cs]},
	keywords = {Computer Science - Databases, diversity, rec},
}

@misc{ExploringAIEthicsChatGPTDiagnostic,
	title = {Exploring {AI} {Ethics} of {ChatGPT}: {A} {Diagnostic} {Analysis}},
	shorttitle = {Exploring {AI} {Ethics} of {ChatGPT}},
	url = {http://arxiv.org/abs/2301.12867},
	abstract = {Recent breakthroughs in natural language processing (NLP) have permitted the synthesis and comprehension of coherent text in an open-ended way, therefore translating the theoretical algorithms into practical applications. The large language-model (LLM) has significantly impacted businesses such as report summarization softwares and copywriters. Observations indicate, however, that LLMs may exhibit social prejudice and toxicity, posing ethical and societal dangers of consequences resulting from irresponsibility. Large-scale benchmarks for accountable LLMs should consequently be developed. Although several empirical investigations reveal the existence of a few ethical difficulties in advanced LLMs, there is no systematic examination and user study of the ethics of current LLMs use. To further educate future efforts on constructing ethical LLMs responsibly, we perform a qualitative research method on OpenAI's ChatGPT to better understand the practical features of ethical dangers in recent LLMs. We analyze ChatGPT comprehensively from four perspectives: 1) {\textbackslash}textit\{Bias\} 2) {\textbackslash}textit\{Reliability\} 3) {\textbackslash}textit\{Robustness\} 4) {\textbackslash}textit\{Toxicity\}. In accordance with our stated viewpoints, we empirically benchmark ChatGPT on multiple sample datasets. We find that a significant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies. In addition, we examine the implications of our findings on the AI ethics of ChatGPT, as well as future problems and practical design considerations for LLMs. We believe that our findings may give light on future efforts to determine and mitigate the ethical hazards posed by machines in LLM applications.},
	urldate = {2023-05-11},
	publisher = {arXiv},
	author = {Zhuo, Terry Yue and Huang, Yujin and Chen, Chunyang and Xing, Zhenchang},
	month = feb,
	year = {2023},
	note = {arXiv:2301.12867 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Software Engineering, fair, generative},
}

@misc{EthicalsocialrisksharmLanguage,
	title = {Ethical and social risks of harm from {Language} {Models}},
	url = {http://arxiv.org/abs/2112.04359},
	abstract = {This paper aims to help structure the risk landscape associated with large-scale Language Models (LMs). In order to foster advances in responsible innovation, an in-depth understanding of the potential risks posed by these models is needed. A wide range of established and anticipated risks are analysed in detail, drawing on multidisciplinary expertise and literature from computer science, linguistics, and social sciences. We outline six specific risk areas: I. Discrimination, Exclusion and Toxicity, II. Information Hazards, III. Misinformation Harms, V. Malicious Uses, V. Human-Computer Interaction Harms, VI. Automation, Access, and Environmental Harms. The first area concerns the perpetuation of stereotypes, unfair discrimination, exclusionary norms, toxic language, and lower performance by social group for LMs. The second focuses on risks from private data leaks or LMs correctly inferring sensitive information. The third addresses risks arising from poor, false or misleading information including in sensitive domains, and knock-on risks such as the erosion of trust in shared information. The fourth considers risks from actors who try to use LMs to cause harm. The fifth focuses on risks specific to LLMs used to underpin conversational agents that interact with human users, including unsafe use, manipulation or deception. The sixth discusses the risk of environmental harm, job automation, and other challenges that may have a disparate effect on different social groups or communities. In total, we review 21 risks in-depth. We discuss the points of origin of different risks and point to potential mitigation approaches. Lastly, we discuss organisational responsibilities in implementing mitigations, and the role of collaboration and participation. We highlight directions for further research, particularly on expanding the toolkit for assessing and evaluating the outlined risks in LMs.},
	urldate = {2023-05-11},
	publisher = {arXiv},
	author = {Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and Kenton, Zac and Brown, Sasha and Hawkins, Will and Stepleton, Tom and Biles, Courtney and Birhane, Abeba and Haas, Julia and Rimell, Laura and Hendricks, Lisa Anne and Isaac, William and Legassick, Sean and Irving, Geoffrey and Gabriel, Iason},
	month = dec,
	year = {2021},
	note = {arXiv:2112.04359 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, fair, generative, responsible},
}

@article{Violentconflictexacerbateddroughtrelatedfood,
	title = {Violent conflict exacerbated drought-related food insecurity between 2009 and 2019 in sub-{Saharan} {Africa}},
	volume = {2},
	issn = {2662-1355},
	url = {https://www.nature.com/articles/s43016-021-00327-4},
	doi = {10.1038/s43016-021-00327-4},
	language = {en},
	number = {8},
	urldate = {2023-05-15},
	journal = {Nature Food},
	author = {Anderson, Weston and Taylor, Charles and McDermid, Sonali and Ilboudo-Nébié, Elisabeth and Seager, Richard and Schlenker, Wolfram and Cottier, Fabien and De Sherbinin, Alex and Mendeloff, Dara and Markey, Kelsey},
	month = aug,
	year = {2021},
	pages = {603--615},
}

@book{EstimatingFoodPriceInflationPartial,
	series = {Policy {Research} {Working} {Papers}},
	title = {Estimating {Food} {Price} {Inflation} from {Partial} {Surveys}},
	url = {http://elibrary.worldbank.org/doi/book/10.1596/1813-9450-9886},
	language = {en},
	urldate = {2023-05-15},
	publisher = {The World Bank},
	author = {Andree, Bo Pieter Johannes},
	month = dec,
	year = {2021},
	doi = {10.1596/1813-9450-9886},
}

@misc{ChatGPTgoodopportunitieschallengeslarge,
	title = {{ChatGPT} for good? {On} opportunities and challenges of large language models for education {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{ChatGPT} for good?},
	url = {https://reader.elsevier.com/reader/sd/pii/S1041608023000195?token=393D0283770E1C02316AB9393DA524EEE9BFFFA4AB4D85EA4FE8B285CF8A147455851F460E2D0732344C9234A00F1E3D&originRegion=us-east-1&originCreation=20230511145048},
	language = {en},
	urldate = {2023-05-11},
	doi = {10.1016/j.lindif.2023.102274},
	keywords = {chatgpt, education},
}

@article{Machinelearningcanguidefood,
	title = {Machine learning can guide food security efforts when primary data are not available},
	volume = {3},
	issn = {2662-1355},
	url = {https://www.nature.com/articles/s43016-022-00587-8},
	doi = {10.1038/s43016-022-00587-8},
	language = {en},
	number = {9},
	urldate = {2023-05-11},
	journal = {Nature Food},
	author = {Martini, Giulia and Bracci, Alberto and Riches, Lorenzo and Jaiswal, Sejal and Corea, Matteo and Rivers, Jonathan and Husain, Arif and Omodei, Elisa},
	month = sep,
	year = {2022},
	pages = {716--728},
}

@article{GrainexportrestrictionsCOVID19risk,
	title = {Grain export restrictions during {COVID}-19 risk food insecurity in many low- and middle-income countries},
	volume = {2},
	issn = {2662-1355},
	url = {https://www.nature.com/articles/s43016-020-00211-7},
	doi = {10.1038/s43016-020-00211-7},
	language = {en},
	number = {1},
	urldate = {2023-05-11},
	journal = {Nature Food},
	author = {Falkendal, Theresa and Otto, Christian and Schewe, Jacob and Jägermeyr, Jonas and Konar, Megan and Kummu, Matti and Watkins, Ben and Puma, Michael J.},
	month = jan,
	year = {2021},
	pages = {11--14},
}

@misc{ImpactExplanationsUnderstandingAlgorithmicDecisionMaking,
	title = {On the {Impact} of {Explanations} on {Understanding} of {Algorithmic} {Decision}-{Making}},
	url = {http://arxiv.org/abs/2302.08264},
	abstract = {Ethical principles for algorithms are gaining importance as more and more stakeholders are affected by "high-risk" algorithmic decision-making (ADM) systems. Understanding how these systems work enables stakeholders to make informed decisions and to assess the systems' adherence to ethical values. Explanations are a promising way to create understanding, but current explainable artificial intelligence (XAI) research does not always consider theories on how understanding is formed and evaluated. In this work, we aim to contribute to a better understanding of understanding by conducting a qualitative task-based study with 30 participants, including "users" and "affected stakeholders". We use three explanation modalities (textual, dialogue, and interactive) to explain a "high-risk" ADM system to participants and analyse their responses both inductively and deductively, using the "six facets of understanding" framework by Wiggins \& McTighe. Our findings indicate that the "six facets" are a fruitful approach to analysing participants' understanding, highlighting processes such as "empathising" and "self-reflecting" as important parts of understanding. We further introduce the "dialogue" modality as a valid alternative to increase participant engagement in ADM explanations. Our analysis further suggests that individuality in understanding affects participants' perceptions of algorithmic fairness, confirming the link between understanding and ADM assessment that previous studies have outlined. We posit that drawing from theories on learning and understanding like the "six facets" and leveraging explanation modalities can guide XAI research to better suit explanations to learning processes of individuals and consequently enable their assessment of ethical values of ADM systems.},
	urldate = {2023-05-17},
	publisher = {arXiv},
	author = {Schmude, Timothée and Koesten, Laura and Möller, Torsten and Tschiatschek, Sebastian},
	month = mar,
	year = {2023},
	note = {arXiv:2302.08264 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, explanation, xai},
}

@article{landscapeconflictIDPsaidlanduse,
	title = {The landscape of conflict: {IDPs}, aid and land-use change in {Darfur}},
	volume = {13},
	issn = {1468-2702},
	shorttitle = {The landscape of conflict},
	url = {https://www.jstor.org/stable/26155414},
	abstract = {Abstract This article examines spatial changes in production in the presence of civil conflict. A simple model predicts land abandonment which increases with proximity to insecurity, and welfare losses to rural land owners. The model also predicts that food aid can buffer the land-use change impacts generated by war. Spatial data on land use, violent events, displaced populations and aid from 2001–2007 corroborate these predictions in Darfur, Sudan. The results suggest large disruptions in short-term production, with abandonment of agriculture far from the cities, and intensification of land use on their periphery.},
	number = {4},
	urldate = {2023-05-23},
	journal = {Journal of Economic Geography},
	author = {Alix-Garcia, Jennifer and Bartlett, Anne and Saah, David},
	year = {2013},
	note = {Publisher: Oxford University Press},
	keywords = {food, insecurity},
	pages = {589--617},
}

@article{WarConflictFoodInsecurity,
	title = {War, {Conflict}, and {Food} {Insecurity}},
	volume = {14},
	issn = {1941-1340, 1941-1359},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-resource-111920-021918},
	doi = {10.1146/annurev-resource-111920-021918},
	abstract = {This article reviews the literature at the intersection of war, armed conflict, and food security, focusing on intergroup violent conflicts such as interstate conflict, civil war, insurgencies, state violence toward civilians, riots, and nonstate conflict. We briefly discuss recent trends in conflict and food security and note the channels through which conflict may impact food security in developing countries. Next, we review the quantitative literature, studying the pathways between conflict and food security and their effects on child health and household coping strategies, displacement, changes in factors of production, market and travel restrictions, and insurgent predation. The effect of food insecurity on conflict, related to limited access to land and shocks to commodity prices, is discussed. We briefly survey the effects of aid and assistance programs and then discuss the connection between climate change, conflict, and food security. The review concludes by identifying topics in this field that are ripe for future research.},
	language = {en},
	number = {1},
	urldate = {2023-05-22},
	journal = {Annual Review of Resource Economics},
	author = {Shemyakina, Olga},
	month = oct,
	year = {2022},
	pages = {313--332},
}

@article{Viewpointcasesixdimensionalfoodsecurity,
	title = {Viewpoint: {The} case for a six-dimensional food security framework},
	volume = {106},
	issn = {03069192},
	shorttitle = {Viewpoint},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306919221001445},
	doi = {10.1016/j.foodpol.2021.102164},
	abstract = {The definition of food security has evolved and changed over the past 50 years, including the introduction of the four commonly cited pillars of food security: availability, access, utilization, and stability, which have been important in shaping policy. In this article, we make the case that it is time for a formal update to our definition of food security to include two additional dimensions proposed by the High Level Panel of Experts on Food Security and Nutrition: agency and sustainability. We show that the impact of widening food system inequalities and growing awareness of the intricate connections between ecological systems and food systems highlight the importance of these additional dimensions to the concept. We further outline the ways in which international policy guidance on the right to food already implies both agency and sustainability alongside the more estab­ lished four pillars, making it a logical next step to adopt a six dimensional framework for food security in both policy and scholarly settings. We also show that advances have already been made with respect to providing measurements of agency and sustainability as they relate to food insecurity.},
	language = {en},
	urldate = {2023-05-22},
	journal = {Food Policy},
	author = {Clapp, Jennifer and Moseley, William G. and Burlingame, Barbara and Termine, Paola},
	month = jan,
	year = {2022},
	pages = {102164},
}

@article{ExplanationsCanReduceOverrelianceAI,
	title = {Explanations {Can} {Reduce} {Overreliance} on {AI} {Systems} {During} {Decision}-{Making}},
	volume = {7},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3579605},
	doi = {10.1145/3579605},
	abstract = {Prior work has identified a resilient phenomenon that threatens the performance of human-AI decision-making teams: overreliance, when people agree with an AI, even when it is incorrect. Surprisingly, overreliance does not reduce when the AI produces explanations for its predictions, compared to only providing predictions. Some have argued that overreliance results from cognitive biases or uncalibrated trust, attributing overreliance to an inevitability of human cognition. By contrast, our paper argues that people strategically choose whether or not to engage with an AI explanation, demonstrating empirically that there are scenarios where AI explanations reduce overreliance. To achieve this, we formalize this strategic choice in a cost-benefit framework, where the costs and benefits of engaging with the task are weighed against the costs and benefits of relying on the AI. We manipulate the costs and benefits in a maze task, where participants collaborate with a simulated AI to find the exit of a maze. Through 5 studies (N = 731), we find that costs such as task difficulty (Study 1), explanation difficulty (Study 2, 3), and benefits such as monetary compensation (Study 4) affect overreliance. Finally, Study 5 adapts the Cognitive Effort Discounting paradigm to quantify the utility of different explanations, providing further support for our framework. Our results suggest that some of the null effects found in literature could be due in part to the explanation not sufficiently reducing the costs of verifying the AI's prediction.},
	language = {en},
	number = {CSCW1},
	urldate = {2023-05-17},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Vasconcelos, Helena and Jörke, Matthew and Grunde-McLaughlin, Madeleine and Gerstenberg, Tobias and Bernstein, Michael S. and Krishna, Ranjay},
	month = apr,
	year = {2023},
	keywords = {explanation, overreliance},
	pages = {1--38},
}

@article{SynthesisFindingsSixCaseStudies,
	title = {Synthesis of {Findings} from {Six} {Case} {Studies}},
	language = {en},
	author = {Maxwell, Daniel and Hailey, Peter},
}

@misc{SelectiveExplanationsLeveragingHumanInput,
	title = {Selective {Explanations}: {Leveraging} {Human} {Input} to {Align} {Explainable} {AI}},
	shorttitle = {Selective {Explanations}},
	url = {http://arxiv.org/abs/2301.09656},
	abstract = {While a vast collection of explainable AI (XAI) algorithms have been developed in recent years, they are often criticized for significant gaps with how humans produce and consume explanations. As a result, current XAI techniques are often found to be hard to use and lack effectiveness. In this work, we attempt to close these gaps by making AI explanations selective -- a fundamental property of human explanations -- by selectively presenting a subset from a large set of model reasons based on what aligns with the recipient's preferences. We propose a general framework for generating selective explanations by leveraging human input on a small sample. This framework opens up a rich design space that accounts for different selectivity goals, types of input, and more. As a showcase, we use a decision-support task to explore selective explanations based on what the decision-maker would consider relevant to the decision task. We conducted two experimental studies to examine three out of a broader possible set of paradigms based on our proposed framework: in Study 1, we ask the participants to provide their own input to generate selective explanations, with either open-ended or critique-based input. In Study 2, we show participants selective explanations based on input from a panel of similar users (annotators). Our experiments demonstrate the promise of selective explanations in reducing over-reliance on AI and improving decision outcomes and subjective perceptions of the AI, but also paint a nuanced picture that attributes some of these positive effects to the opportunity to provide one's own input to augment AI explanations. Overall, our work proposes a novel XAI framework inspired by human communication behaviors and demonstrates its potentials to encourage future work to better align AI explanations with human production and consumption of explanations.},
	urldate = {2023-05-26},
	publisher = {arXiv},
	author = {Lai, Vivian and Zhang, Yiming and Chen, Chacha and Liao, Q. Vera and Tan, Chenhao},
	month = may,
	year = {2023},
	note = {arXiv:2301.09656 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
}

@article{endtoendassessmentextremeweatherimpactsa,
	title = {An end-to-end assessment of extreme weather impacts on food security},
	volume = {5},
	issn = {1758-678X, 1758-6798},
	url = {https://www.nature.com/articles/nclimate2747},
	doi = {10.1038/nclimate2747},
	language = {en},
	number = {11},
	urldate = {2023-06-06},
	journal = {Nature Climate Change},
	author = {Chavez, Erik and Conway, Gordon and Ghil, Michael and Sadler, Marc},
	month = nov,
	year = {2015},
	pages = {997--1001},
}

@article{Extremeclimateeventsincreaserisk,
	title = {Extreme climate events increase risk of global food insecurity and adaptation needs},
	volume = {2},
	issn = {2662-1355},
	url = {https://www.nature.com/articles/s43016-021-00335-4},
	doi = {10.1038/s43016-021-00335-4},
	language = {en},
	number = {8},
	urldate = {2023-06-06},
	journal = {Nature Food},
	author = {Hasegawa, Tomoko and Sakurai, Gen and Fujimori, Shinichiro and Takahashi, Kiyoshi and Hijioka, Yasuaki and Masui, Toshihiko},
	month = aug,
	year = {2021},
	pages = {587--595},
}

@article{ImpactsCOVID19pandemicenvironmentsociety,
	title = {Impacts of {COVID}-19 pandemic on environment, society, and food security},
	issn = {1614-7499},
	url = {https://link.springer.com/10.1007/s11356-023-25714-1},
	doi = {10.1007/s11356-023-25714-1},
	abstract = {Coronavirus disease (COVID)-19 is a viral and transferable disease caused by severe respiratory syndrome-coronavirus-2. It can spread through breathing droplets in human beings. It caused 5.32 million deaths around the world at the end of 2021. COVID-19 has caused several positive impacts as well, such as a reduction in air, water, and noise pollution. However, its negative impacts are by far critical such as increased death rate, increased release of microcontaminants (pesticides, biocides, pharmaceuticals, surfactants, polycyclic aromatic hydrocarbons (PAHs), flame retardants, and heavy metals), increased biomedical waste generation due to excessive use of safety equipment and its disposal, and municipal solid waste generation. Environmental pollution was significantly reduced due to lockdown during the COVID-19 period. Therefore, the quality of air and water improved. COVID-19 affected all sections of the population, particularly the most vulnerable members of society, and thus pushed more people into poverty. At the world level, it increased risks to food safety by increasing prices and lowering revenues, forcing households to reduce their food consumption in terms of quantity and quality. COVID19 also upset various exercises e.g., horticulture, fisheries, domesticated animals, and agribusiness hence prohibiting the development of merchandise for poor-country ranchers. Most of the patients can self-recover from COVID-19 if they do not have any other diseases like high blood pressure, diabetes, and heart problems. Predictably, the appropriate execution of the proposed approaches (vaccination, wearing face masks, social distancing, sustainable industrialization) is helpful for worldwide environmental sustainability.},
	language = {en},
	urldate = {2023-05-25},
	journal = {Environmental Science and Pollution Research},
	author = {Hammad, Hafiz Mohkum and Nauman, Hafiz Muhammad Fasihuddin and Abbas, Farhat and Jawad, Rashid and Farhad, Wajid and Shahid, Muhammad and Bakhat, Hafiz Faiq and Farooque, Aitazaz A. and Mubeen, Muhammad and Fahad, Shah and Cerda, Artemi},
	month = feb,
	year = {2023},
}

@article{Foodsecuritysustainabilitycanone,
	title = {Food security and sustainability: can one exist without the other?},
	volume = {18},
	issn = {1368-9800, 1475-2727},
	shorttitle = {Food security and sustainability},
	url = {https://www.cambridge.org/core/product/identifier/S136898001500021X/type/journal_article},
	doi = {10.1017/S136898001500021X},
	abstract = {Objective: To position the concept of sustainability within the context of food security. Design: An overview of the interrelationships between food security and sustainability based on a non-systematic literature review and informed discussions based principally on a quasi-historical approach from meetings and reports. Setting: International and global food security and nutrition.
Results: The Rome Declaration on World Food Security in 1996 deﬁned its three basic dimensions as: availability, accessibility and utilization, with a focus on nutritional well-being. It also stressed the importance of sustainable management of natural resources and the elimination of unsustainable patterns of food consumption and production. In 2009, at the World Summit on Food Security, the concept of stability/vulnerability was added as the short-term time indicator of the ability of food systems to withstand shocks, whether natural or man-made, as part of the Five Rome Principles for Sustainable Global Food Security. More recently, intergovernmental processes have emphasized the importance of sustainability to preserve the environment, natural resources and agro-ecosystems (and thus the overlying social system), as well as the importance of food security as part of sustainability and vice versa.
Conclusions: Sustainability should be considered as part of the long-term time dimension in the assessment of food security. From such a perspective the concept of sustainable diets can play a key role as a goal and a way of maintaining nutritional well-being and health, while ensuring the sustainability for future food security. Without integrating sustainability as an explicit (ﬁfth?) dimension of food security, today’s policies and programmes could become the very cause of increased food insecurity in the future.},
	language = {en},
	number = {13},
	urldate = {2023-05-23},
	journal = {Public Health Nutrition},
	author = {Berry, Elliot M and Dernini, Sandro and Burlingame, Barbara and Meybeck, Alexandre and Conforti, Piero},
	month = sep,
	year = {2015},
	pages = {2293--2302},
}

@article{MeasuringHouseholdFoodInsecurityWhy,
	title = {Measuring {Household} {Food} {Insecurity}: {Why} {It}'s {So} {Important} and {Yet} {So} {Difficult} to {Do}},
	volume = {136},
	issn = {00223166},
	shorttitle = {Measuring {Household} {Food} {Insecurity}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022316622082633},
	doi = {10.1093/jn/136.5.1404S},
	abstract = {Food insecurity is a daily reality for hundreds of millions of people around the world. Although its most extreme manifestations are often obvious, many other households facing constraints in their access to food are less identiﬁable. Operational agencies lack a method for differentiating households at varying degrees of food insecurity in order to target and evaluate their interventions. This chapter provides an overview of a set of papers associated with a research initiative that seeks to identify more precise, yet simple, measures of household food insecurity. The overview highlights three main conceptual developments associated with practical approaches to measuring constraints in access to food: 1) a shift from using measures of food availability and utilization to measuring ‘‘inadequate access’’; 2) a shift from a focus on objective to subjective measures; and 3) a growing emphasis on fundamental measurement as opposed to reliance on distal, proxy measures. Further research is needed regarding 1) how well measures of household food insecurity designed for chronically food-insecure contexts capture the processes leading to, and experience of, acute food insecurity, 2) the impact of short-term shocks, such as major ﬂoods or earthquake, on household behaviors that determine responses to food security questions, 3) better measurement of the interaction between severity and frequency of household food insecurity behaviors, and 4) the determination of whether an individual’s response to survey questions can be representative of the food insecurity experiences of all members of the household. J. Nutr. 136: 1404S–1408S, 2006.},
	language = {en},
	number = {5},
	urldate = {2023-05-23},
	journal = {The Journal of Nutrition},
	author = {Webb, Patrick and Coates, Jennifer and Frongillo, Edward A and Rogers, Beatrice Lorge and Swindale, Anne and Bilinsky, Paula},
	month = may,
	year = {2006},
	pages = {1404S--1408S},
}

@article{datadrivenapproachimprovesfoodinsecurity,
	title = {A data-driven approach improves food insecurity crisis prediction},
	volume = {122},
	issn = {0305750X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0305750X19301603},
	doi = {10.1016/j.worlddev.2019.06.008},
	abstract = {Globally, over 800 million people are food insecure. Current methods for identifying food insecurity crises are not based on statistical models and fail to systematically incorporate readily available data on prices, weather, and demographics. As a result, policymakers cannot rapidly identify food insecure populations. These problems delay responses to mitigate hunger. We develop a replicable, near real-time model incorporating spatially and temporally granular market data, remotely-sensed rainfall and geographic data, and demographic characteristics. We train the model on 2010–2011 data from Malawi and forecast 2013 food security. Our model correctly identiﬁes the food security status of 83 to 99\% of the most food insecure village clusters in 2013, depending on the food security measure, while the prevailing approach correctly identiﬁes between 0 and 10\%. Our results show the power of modeling food insecurity to provide early warning and suggest model-driven approaches could dramatically improve food insecurity crisis response.},
	language = {en},
	urldate = {2023-05-23},
	journal = {World Development},
	author = {Lentz, E.C. and Michelson, H. and Baylis, K. and Zhou, Y.},
	month = oct,
	year = {2019},
	pages = {399--409},
}

@article{LibRecJavaLibraryRecommenderSystems,
	title = {{LibRec}: {A} {Java} {Library} for {Recommender} {Systems}},
	abstract = {The large array of recommendation algorithms proposed over the years brings a challenge in reproducing and comparing their performance. This paper introduces an open-source Java library that implements a suite of state-of-the-art algorithms as well as a series of evaluation metrics. We empirically ﬁnd that LibRec performs faster than other such libraries, while achieving competitive evaluative performance.},
	language = {en},
	author = {Guo, Guibing and Zhang, Jie and Sun, Zhu and Yorke-Smith, Neil},
}

@misc{EvaluatingSystemicErrorDetectionMethods,
	title = {Evaluating {Systemic} {Error} {Detection} {Methods} using {Synthetic} {Images}},
	url = {http://arxiv.org/abs/2207.04104},
	abstract = {We introduce SpotCheck, a framework for generating synthetic datasets to use for evaluating methods for discovering blindspots (i.e., systemic errors) in image classifiers. We use SpotCheck to run controlled studies of how various factors influence the performance of blindspot discovery methods. Our experiments reveal several shortcomings of existing methods, such as relatively poor performance in settings with multiple blindspots and sensitivity to hyperparameters. Further, we find that a method based on dimensionality reduction, PlaneSpot, is competitive with existing methods, which has promising implications for the development of interactive tools.},
	urldate = {2022-12-08},
	publisher = {arXiv},
	author = {Plumb, Gregory and Johnson, Nari and Cabrera, Ángel Alexander and Ribeiro, Marco Tulio and Talwalkar, Ameet},
	month = jul,
	year = {2022},
	note = {arXiv:2207.04104 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, dm, uu},
}

@inproceedings{Improvingrecommendationliststopicdiversification,
	address = {Chiba, Japan},
	title = {Improving recommendation lists through topic diversification},
	isbn = {978-1-59593-046-0},
	url = {http://portal.acm.org/citation.cfm?doid=1060745.1060754},
	doi = {10.1145/1060745.1060754},
	language = {en},
	urldate = {2023-04-10},
	booktitle = {Proceedings of the 14th international conference on {World} {Wide} {Web}  - {WWW} '05},
	publisher = {ACM Press},
	author = {Ziegler, Cai-Nicolas and McNee, Sean M. and Konstan, Joseph A. and Lausen, Georg},
	year = {2005},
	keywords = {diversity, rec},
	pages = {22},
}

@misc{InvestigatingPotentialFactorsAssociatedGender,
	title = {Investigating {Potential} {Factors} {Associated} with {Gender} {Discrimination} in {Collaborative} {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2002.07786},
	abstract = {The proliferation of personalized recommendation technologies has raised concerns about discrepancies in their recommendation performance across different genders, age groups, and racial or ethnic populations. This varying degree of performance could impact users' trust in the system and may pose legal and ethical issues in domains where fairness and equity are critical concerns, like job recommendation. In this paper, we investigate several potential factors that could be associated with discriminatory performance of a recommendation algorithm for women versus men. We specifically study several characteristics of user profiles and analyze their possible associations with disparate behavior of the system towards different genders. These characteristics include the anomaly in rating behavior, the entropy of users' profiles, and the users' profile size. Our experimental results on a public dataset using four recommendation algorithms show that, based on all the three mentioned factors, women get less accurate recommendations than men indicating an unfair nature of recommendation algorithms across genders.},
	urldate = {2023-02-28},
	publisher = {arXiv},
	author = {Mansoury, Masoud and Abdollahpouri, Himan and Smith, Jessie and Dehpanah, Arman and Pechenizkiy, Mykola and Mobasher, Bamshad},
	month = feb,
	year = {2020},
	note = {arXiv:2002.07786 [cs]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Social and Information Networks, rec},
}

@inproceedings{WhyNotExplainEffectsExplanations,
	title = {Why {Not} {Explain}? {Effects} of {Explanations} on {Human} {Perceptions} of {Autonomous} {Driving}},
	shorttitle = {Why {Not} {Explain}?},
	doi = {10.1109/ARSO51874.2021.9542835},
	abstract = {Autonomous vehicles (AVs) have the potential to change the way we commute, travel, and transport our goods. The deployment of AVs in society, however, requires that people understand, accept, and trust them. Intelligible explanations can help different AV stakeholders to assess AVs' behaviours, and in turn, increase their confidence and foster trust. In a user study (N = 101), we examined different explanation types (based on investigatory queries) provided by an AV and their effect on people using the trust determinant factors. Our quantitative and qualitative analysis shows that explanations with causal attributions improved task performance and understanding when assessing driving events but did not directly improve perceived trust. This underlines the potential need for additional measures and research to enhance trust in AVs.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Advanced} {Robotics} and {Its} {Social} {Impacts} ({ARSO})},
	author = {Omeiza, Daniel and Kollnig, Konrad and Web, Helena and Jirotka, Marina and Kunze, Lars},
	month = jul,
	year = {2021},
	note = {ISSN: 2162-7576},
	keywords = {Atmospheric measurements, Autonomous vehicles, Conferences, Particle measurements, Prototypes, Stakeholders, Task analysis, exp, self-driving},
	pages = {194--199},
}

@article{VarianceBiasGeneralLossFunctions,
	title = {Variance and {Bias} for {General} {Loss} {Functions}},
	abstract = {When using squared error loss, bias and variance and their decomposition of prediction error are well understood and widely used concepts. However, there is no universally accepted deﬁnition for other loss functions. Numerous attempts have been made to extend these concepts beyond squared error loss. Most approaches have focused solely on 0-1 loss functions and have produced signiﬁcantly different deﬁnitions. These differences stem from disagreement as to the essential characteristics that variance and bias should display. This paper suggests an explicit list of rules that we feel any “reasonable” set of deﬁnitions should satisfy. Using this framework, bias and variance deﬁnitions are produced which generalize to any symmetric loss function. We illustrate these statistics on several loss functions with particular emphasis on 0-1 loss. We conclude with a discussion of the various deﬁnitions that have been proposed in the past as well as a method for estimating these quantities on real data sets.},
	language = {en},
	author = {James, Gareth M},
}

@inproceedings{HowDifferentGroupsPrioritizeEthical,
	address = {Seoul Republic of Korea},
	title = {How {Different} {Groups} {Prioritize} {Ethical} {Values} for {Responsible} {AI}},
	isbn = {978-1-4503-9352-2},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533097},
	doi = {10.1145/3531146.3533097},
	language = {en},
	urldate = {2023-01-05},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Jakesch, Maurice and Buçinca, Zana and Amershi, Saleema and Olteanu, Alexandra},
	month = jun,
	year = {2022},
	keywords = {fair, rec, responsible},
	pages = {310--323},
}

@article{VISAtlasImagebasedExplorationQuerySystem,
	title = {{VISAtlas}: {An} {Image}-based {Exploration} and {Query} {System} for {Large} {Visualization} {Collections} via {Neural} {Image} {Embedding}},
	issn = {1941-0506},
	shorttitle = {{VISAtlas}},
	doi = {10.1109/TVCG.2022.3229023},
	abstract = {High-quality visualization collections are beneficial for a variety of applications including visualization reference and data-driven visualization design. The visualization community has created many visualization collections, and developed interactive exploration systems for the collections. However, the systems are mainly based on extrinsic attributes like authors and publication years, whilst neglect intrinsic property (i.e., visual appearance) of visualizations, hindering visual comparison and query of visualization designs. This paper presents VISAtlas, an image-based approach empowered by neural image embedding, to facilitate exploration and query for visualization collections. To improve embedding accuracy, we create a comprehensive collection of synthetic and real-world visualizations, and use it to train a convolutional neural network (CNN) model with a triplet loss for taxonomical classification of visualizations. Next, we design a coordinated multiple view (CMV) system that enables multi-perspective exploration and design retrieval based on visualization embeddings. Specifically, we design a novel embedding overview that leverages contextual layout framework to preserve the context of the embedding vectors with the associated visualization taxonomies, and density plot and sampling techniques to address the overdrawing problem. We demonstrate in three case studies and one user study the effectiveness of VISAtlas in supporting comparative analysis of visualization collections, exploration of composite visualizations, and image-based retrieval of visualization designs. The studies reveal that real-world visualization collections (e.g., Beagle and VIS30K) better accord with the richness and diversity of visualization designs than synthetic collections (e.g., Data2Vis), inspiring composite visualizations are identified in real-world collections, and distinct design patterns exist in visualizations from different sources.},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ye, Yilin and Huang, Rong and Zeng, Wei},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Data visualization, Feature extraction, Layout, Semantics, Task analysis, Taxonomy, Visualization, Visualization collection, design pattern, embedding, image embedding, image visualization, vis, visual query},
	pages = {1--15},
}

@article{ExplanationCaseBasedReasoningPerspectivesGoals,
	title = {Explanation in {Case}-{Based} {Reasoning}–{Perspectives} and {Goals}},
	volume = {24},
	issn = {0269-2821, 1573-7462},
	url = {http://link.springer.com/10.1007/s10462-005-4607-7},
	doi = {10.1007/s10462-005-4607-7},
	abstract = {We present an overview of different theories of explanation from the philosophy and cognitive science communities. Based on these theories, as well as models of explanation from the knowledge-based systems area, we present a framework for explanation in case-based reasoning (CBR) based on explanation goals. We propose ways that the goals of the user and system designer should be taken into account when deciding what is a good explanation for a given CBR system. Some general types of goals relevant to many CBR systems are identiﬁed, and used to survey existing methods of explanation in CBR. Finally, we identify some future challenges.},
	language = {en},
	number = {2},
	urldate = {2022-12-24},
	journal = {Artificial Intelligence Review},
	author = {Sørmo, Frode and Cassens, Jörg and Aamodt, Agnar},
	month = oct,
	year = {2005},
	keywords = {case-based, explanation},
	pages = {109--143},
}

@book{EvaluationUsefulnessCaseBasedExplanationa,
	title = {An {Evaluation} of the {Usefulness} of {Case}-{Based} {Explanation}},
	abstract = {One of the perceived benefits of Case-Based Reasoning (CBR) is the potential to use retrieved cases to explain predictions. Surprisingly, this aspect of CBR has not been much researched. There has been some early work on knowledge-intensive approaches to CBR where the cases contain explanation patterns (e.g. SWALE). However, a more knowledge-light approach where the case similarity is the basis for explanation has received little attention. To explore this, we have developed a CBR system for predicting blood-alcohol level. We compare explanations of predictions produced with this system with alternative rule-based explanations. The casebased explanations fare very well in this evaluation and score significantly better than the rule-based alternative.},
	author = {Cunningham, Padraig and Doyle, Dónal and Loughrey, John},
	month = jun,
	year = {2003},
	doi = {10.1007/3-540-45006-8_12},
	note = {Journal Abbreviation: Lecture Notes in Computer Science
Publication Title: Lecture Notes in Computer Science},
	keywords = {case-based, explanation},
}

@inproceedings{UsercontrollableRecommendationFilterBubbles,
	address = {Madrid Spain},
	title = {User-controllable {Recommendation} {Against} {Filter} {Bubbles}},
	isbn = {978-1-4503-8732-3},
	url = {https://dl.acm.org/doi/10.1145/3477495.3532075},
	doi = {10.1145/3477495.3532075},
	abstract = {Recommender systems usually face the issue of filter bubbles: overrecommending homogeneous items based on user features and historical interactions. Filter bubbles will grow along the feedback loop and inadvertently narrow user interests. Existing work usually mitigates filter bubbles by incorporating objectives apart from accuracy such as diversity and fairness. However, they typically sacrifice accuracy, hurting model fidelity and user experience. Worse still, users have to passively accept the recommendation strategy and influence the system in an inefficient manner with high latency, e.g., keeping providing feedback (e.g., like and dislike) until the system recognizes the user intention.},
	language = {en},
	urldate = {2023-02-24},
	booktitle = {Proceedings of the 45th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Wang, Wenjie and Feng, Fuli and Nie, Liqiang and Chua, Tat-Seng},
	month = jul,
	year = {2022},
	keywords = {bias, rec},
	pages = {1251--1261},
}

@article{Analyzingdatasystematicbias,
	title = {Analyzing data with systematic bias},
	volume = {20},
	issn = {1551-9031},
	url = {https://dl.acm.org/doi/10.1145/3572885.3572890},
	doi = {10.1145/3572885.3572890},
	abstract = {In many data analysis problems, we only have access to biased data due to some
              systematic bias
              of the data collection procedure. In this letter, we present a general formulation of systematic bias in data as well as our recent results on how to handle two very fundamental types of systematic bias that arise frequently in econometric studies:
              truncation bias
              and
              self-selection bias.},
	language = {en},
	number = {1},
	urldate = {2023-02-24},
	journal = {ACM SIGecom Exchanges},
	author = {Zampetakis, Manolis},
	month = jul,
	year = {2022},
	pages = {55--63},
}

@article{SurveyAlgorithmicRecourseContrastiveExplanationsa,
	title = {A {Survey} of {Algorithmic} {Recourse}: {Contrastive} {Explanations} and {Consequential} {Recommendations}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	shorttitle = {A {Survey} of {Algorithmic} {Recourse}},
	url = {https://dl.acm.org/doi/10.1145/3527848},
	doi = {10.1145/3527848},
	abstract = {Machine learning is increasingly used to inform decision making in sensitive situations where decisions have consequential effects on individuals’ lives. In these settings, in addition to requiring models to be accurate and robust, socially relevant values such as fairness, privacy, accountability, and explainability play an important role in the adoption and impact of said technologies. In this work, we focus on
              algorithmic recourse
              , which is concerned with providing explanations and recommendations to individuals who are unfavorably treated by automated decision-making systems. We first perform an extensive literature review, and align the efforts of many authors by presenting unified definitions, formulations, and solutions to recourse. Then, we provide an overview of the prospective research directions toward which the community may engage, challenging existing assumptions and making explicit connections to other ethical challenges such as security, privacy, and fairness.},
	language = {en},
	number = {5},
	urldate = {2023-02-22},
	journal = {ACM Computing Surveys},
	author = {Karimi, Amir-Hossein and Barthe, Gilles and Schölkopf, Bernhard and Valera, Isabel},
	month = may,
	year = {2023},
	pages = {1--29},
}

@article{Exploitingpersonalizedcalibrationmetricsfairness,
	title = {Exploiting personalized calibration and metrics for fairness recommendation},
	volume = {181},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417421005534},
	doi = {10.1016/j.eswa.2021.115112},
	abstract = {Recommendation systems are used to suggest items that users can be interested in. These systems are based on the user preference historic to create a recommendation list with items that have the higher similarity with the user’s interests, in order to achieve the best possible user’s satisfaction, which is usually measured as recom­ mendation precision. However, the search for the best precision can cause some side effects such as over­ specialization, few diversity and miscalibration of genres, classes and niches. Calibration provides fairer recommendations, which respect the genre proportionality on the user’s preferences, avoiding over­ specialization. This article aims to explore ways to balance the trade-off weight between precision and cali­ bration based on divergence measures, as well as to propose metrics to evaluate the calibration in the suggested list. The proposed system works in a post-processing step and does not depend on a specific recommender al­ gorithm or workflow. For this purpose, we evaluate six recommender algorithms applied in the movie domain, analyzing variations of three fairness measures, two personalized trade-off weights and eleven constant weights. To understand the results we use the precision, the reciprocal rank and two proposed metrics. The results indicate that the trade-off formulation of personalized weights obtains better results when used to compare the recom­ mendation lists using matrix factorization-based approaches on Movielens dataset. In addition, the calibration also impacts the precision and fairness of all considered algorithms used in evaluation.},
	language = {en},
	urldate = {2023-02-20},
	journal = {Expert Systems with Applications},
	author = {da Silva, Diego Corrêa and Manzato, Marcelo Garcia and Durão, Frederico Araújo},
	month = nov,
	year = {2021},
	pages = {115112},
}

@article{InvestigatingHowPractitionersUseHumanAI,
	title = {Investigating {How} {Practitioners} {Use} {Human}-{AI} {Guidelines}:  {A} {Case} {Study} on the {People} + {AI} {Guidebook}},
	abstract = {Artificial intelligence (AI) presents new challenges for the user experience (UX) of products and services. Recently, practitionerfacing resources and design guidelines have become available to ease some of these challenges. However, little research has investigated if and how these guidelines are used, and how they impact practice. In this paper, we investigated how industry practitioners use the People + AI Guidebook. We conducted interviews with 31 practitioners (i.e., designers, product managers) to understand how they use human-AI guidelines when designing AI-enabled products. Our findings revealed that practitioners use the guidebook not only for addressing AI’s design challenges, but also for education, cross-functional communication, and for developing internal resources. We uncovered that practitioners desire more support for early phase ideation and problem formulation to avoid AI product failures. We discuss the implications for future resources aiming to help practitioners in designing AI products.},
	language = {en},
	author = {Yildirim, Nur and Pushkarna, Mahima and Goyal, Nitesh and Wattenberg, Martin and Viégas, Fernanda},
	year = {2023},
}

@inproceedings{CounterfactualExplanationsPredictionDiagnosisXAI,
	address = {Oxford United Kingdom},
	title = {Counterfactual {Explanations} for {Prediction} and {Diagnosis} in {XAI}},
	isbn = {978-1-4503-9247-1},
	url = {https://dl.acm.org/doi/10.1145/3514094.3534144},
	doi = {10.1145/3514094.3534144},
	abstract = {We compared two sorts of explanations for decisions made by an AI system: counterfactual explanations about how an outcome could have been different in the past, and prefactual explanations about how it could be different in the future. We examined the effects of these alternative explanation strategies on the accuracy of users’ judgments about the AI app’s predictions about an outcome (inferred from information about the causes), compared to the accuracy of their judgments about the app’s diagnoses of a cause (inferred from information about the outcome). The tasks were based on a simulated SmartAgriculture decision support system for grass growth outcomes on dairy farms in Experiment 1, and for an analogous alien planet domain in Experiment 2. The two experiments, with 243 participants, also tested users’ confidence in their decisions, and their satisfaction with the explanations. Users made more accurate diagnoses of the presence of causes based on information about their outcome, compared to predictions of an outcome given information about the presence of causes. Their predictions and diagnoses were helped equally by counterfactual explanations and prefactual ones.},
	language = {en},
	urldate = {2023-02-17},
	booktitle = {Proceedings of the 2022 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Dai, Xinyue and Keane, Mark T. and Shalloo, Laurence and Ruelle, Elodie and Byrne, Ruth M.J.},
	month = jul,
	year = {2022},
	pages = {215--226},
}

@inproceedings{LearningRecommendAccurateDiverseItems,
	address = {Perth Australia},
	title = {Learning to {Recommend} {Accurate} and {Diverse} {Items}},
	isbn = {978-1-4503-4913-0},
	url = {https://dl.acm.org/doi/10.1145/3038912.3052585},
	doi = {10.1145/3038912.3052585},
	abstract = {In this study, we investigate diversiﬁed recommendation problem by supervised learning, seeking signiﬁcant improvement in diversity while maintaining accuracy. In particular, we regard each user as a training instance, and heuristically choose a subset of accurate and diverse items as groundtruth for each user. We then represent each user or item as a vector resulted from the factorization of the user-item rating matrix. In our paper, we try to discover a factorization for matching the following supervised learning task. In doing this, we deﬁne two coupled optimization problems, parameterized matrix factorization and structural learning, to formulate our task. And we propose a diversiﬁed collaborative ﬁltering algorithm (DCF) to solve the coupled problems. We also introduce a new pairwise accuracy metric and a normalized topic coverage diversity metric to measure the performance of accuracy and diversity respectively. Extensive experiments on benchmark datasets show the performance gains of DCF in comparison with the state-of-the-art algorithms.},
	language = {en},
	urldate = {2023-03-02},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Cheng, Peizhe and Wang, Shuaiqiang and Ma, Jun and Sun, Jiankai and Xiong, Hui},
	month = apr,
	year = {2017},
	keywords = {diversity, rec},
	pages = {183--192},
}

@inproceedings{hitsnicheshowpopularartists,
	address = {Las Vegas Nevada},
	title = {From hits to niches?: or how popular artists can bias music recommendation and discovery},
	isbn = {978-1-60558-265-8},
	shorttitle = {From hits to niches?},
	url = {https://dl.acm.org/doi/10.1145/1722149.1722154},
	doi = {10.1145/1722149.1722154},
	abstract = {This paper presents some experiments to analyse the popularity eﬀect in music recommendation. Popularity is measured in terms of total playcounts, and the Long Tail model is used in order to rank music artists. Furthermore, metrics derived from complex network analysis are used to detect the inﬂuence of the most popular artists in the network of similar artists.},
	language = {en},
	urldate = {2023-03-01},
	booktitle = {Proceedings of the 2nd {KDD} {Workshop} on {Large}-{Scale} {Recommender} {Systems} and the {Netflix} {Prize} {Competition}},
	publisher = {ACM},
	author = {Celma, Òscar and Cano, Pedro},
	month = aug,
	year = {2008},
	keywords = {bias, popularity, rec},
	pages = {1--8},
}

@article{EvaluatingStereotypeNonStereotypeRecommenderSystems,
	title = {Evaluating {Stereotype} and {Non}-{Stereotype} {Recommender} {Systems}},
	abstract = {Stereotype-based user modeling was proposed by Elaine Rich in 1979 and has been applied to recommender systems on numerous instances since its conception. The key motivations for application of stereotyping in user modeling are resolution of the new user problem and space efficiency. Several claims have been made in the literature related to the effectiveness of stereotyping but only a few studies have validated them empirically. Furthermore, to the best of our knowledge, there has been no empirical study of itembased stereotype models for recommender systems. Our research empirically substantiates the efficacy of using stereotypes in item modeling and user modeling when compared with non-utilization of stereotypes. The empirical evaluation was performed with a stateof-the-art machine learning algorithm (gradient boosted decision forests) applied to two datasets integrating MovieLens, IMDb and TMDB movie data.},
	language = {en},
	author = {ALRossais, Nourah A and Kudenko, Daniel},
}

@inproceedings{PowerFewAnalyzingImpactInfluential,
	address = {Larnaca Cyprus},
	title = {Power of the {Few}: {Analyzing} the {Impact} of {Influential} {Users} in {Collaborative} {Recommender} {Systems}},
	isbn = {978-1-4503-6021-0},
	shorttitle = {Power of the {Few}},
	url = {https://dl.acm.org/doi/10.1145/3320435.3320464},
	doi = {10.1145/3320435.3320464},
	abstract = {Like other social systems, in collaborative filtering a small number of “influential” users may have a large impact on the recommendations of other users, thus affecting the overall behavior of the system. Identifying influential users and studying their impact on other users is an important problem because it provides insight into how small groups can inadvertently or intentionally affect the behavior of the system as a whole. Modeling these influences can also shed light on patterns and relationships that would otherwise be difficult to discern, hopefully leading to more transparency in how the system generates personalized content. In this work we first formalize the notion of “influence” in collaborative filtering using an Influence Discrimination Model. We then empirically identify and characterize influential users and analyze their impact on the system under different underlying recommendation algorithms and across three different recommendation domains: job, movie and book recommendations. Insights from these experiments can help in designing systems that are not only optimized for accuracy, but are also tuned to mitigate the impact of influential users when it might lead to potential imbalance or unfairness in the system’s outcomes.},
	language = {en},
	urldate = {2023-02-28},
	booktitle = {Proceedings of the 27th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Eskandanian, Farzad and Sonboli, Nasim and Mobasher, Bamshad},
	month = jun,
	year = {2019},
	pages = {225--233},
}

@inproceedings{AllCoolKidsHowThey,
	title = {All {The} {Cool} {Kids}, {How} {Do} {They} {Fit} {In}?: {Popularity} and {Demographic} {Biases} in {Recommender} {Evaluation} and {Effectiveness}},
	shorttitle = {All {The} {Cool} {Kids}, {How} {Do} {They} {Fit} {In}?},
	url = {https://proceedings.mlr.press/v81/ekstrand18b.html},
	abstract = {In the research literature, evaluations of recommender system effectiveness typically report results over a given data set, providing an aggregate measure of effectiveness over each instance (e.g. user) in the data set. Recent advances in information retrieval evaluation, however, demonstrate the importance of considering the distribution of effectiveness across diverse groups of varying sizes. For example, do users of different ages or genders obtain similar utility from the system, particularly if their group is a relatively small subset of the user base? We apply this consideration to recommender systems, using offline evaluation and a utility-based metric of recommendation effectiveness to explore whether different user demographic groups experience similar recommendation accuracy. We find demographic differences in measured recommender effectiveness across two data sets containing different types of feedback in different domains; these differences sometimes, but not always, correlate with the size of the user group in question. Demographic effects also have a complex—and likely detrimental—interaction with popularity bias, a known deficiency of recommender evaluation. These results demonstrate the need for recommender system evaluation protocols that explicitly quantify the degree to which the system is meeting the information needs of all its users, as well as the need for researchers and operators to move beyond naïve evaluations that favor the needs of larger subsets of the user population while ignoring smaller subsets.},
	language = {en},
	urldate = {2023-02-28},
	booktitle = {Proceedings of the 1st {Conference} on {Fairness}, {Accountability} and {Transparency}},
	publisher = {PMLR},
	author = {Ekstrand, Michael D. and Tian, Mucun and Azpiazu, Ion Madrazo and Ekstrand, Jennifer D. and Anuyah, Oghenemaro and McNeill, David and Pera, Maria Soledad},
	month = jan,
	year = {2018},
	note = {ISSN: 2640-3498},
	keywords = {bias, fair, popularity, rec},
	pages = {172--186},
}

@inproceedings{Exploringauthorgenderbookrating,
	address = {Vancouver British Columbia Canada},
	title = {Exploring author gender in book rating and recommendation},
	isbn = {978-1-4503-5901-6},
	url = {https://dl.acm.org/doi/10.1145/3240323.3240373},
	doi = {10.1145/3240323.3240373},
	abstract = {Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of the patterns in rating datasets reflect important real-world differences between the various users and items in the data; other patterns may be irrelevant or possibly undesirable for social or ethical reasons, particularly if they reflect undesired discrimination, such as gender or ethnic discrimination in publishing. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to a dimension of social concern, namely content creator gender. Using publicly-available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms differ in the gender distribution of their recommendation lists, and in the relationship of that output distribution to user profile distribution.},
	language = {en},
	urldate = {2023-02-26},
	booktitle = {Proceedings of the 12th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Ekstrand, Michael D. and Tian, Mucun and Kazi, Mohammed R. Imran and Mehrpouyan, Hoda and Kluver, Daniel},
	month = sep,
	year = {2018},
	keywords = {fair, rec},
	pages = {242--250},
}

@article{DiversityMachineLearning,
	title = {Diversity in {Machine} {Learning}},
	volume = {7},
	issn = {2169-3536},
	url = {http://arxiv.org/abs/1807.01477},
	doi = {10.1109/ACCESS.2019.2917620},
	abstract = {Machine learning methods have achieved good performance and been widely applied in various real-world applications. They can learn the model adaptively and be better fit for special requirements of different tasks. Generally, a good machine learning system is composed of plentiful training data, a good model training process, and an accurate inference. Many factors can affect the performance of the machine learning process, among which the diversity of the machine learning process is an important one. The diversity can help each procedure to guarantee a total good machine learning: diversity of the training data ensures that the training data can provide more discriminative information for the model, diversity of the learned model (diversity in parameters of each model or diversity among different base models) makes each parameter/model capture unique or complement information and the diversity in inference can provide multiple choices each of which corresponds to a specific plausible local optimal result. Even though the diversity plays an important role in machine learning process, there is no systematical analysis of the diversification in machine learning system. In this paper, we systematically summarize the methods to make data diversification, model diversification, and inference diversification in the machine learning process, respectively. In addition, the typical applications where the diversity technology improved the machine learning performance have been surveyed, including the remote sensing imaging tasks, machine translation, camera relocalization, image segmentation, object detection, topic modeling, and others. Finally, we discuss some challenges of the diversity technology in machine learning and point out some directions in future work.},
	urldate = {2023-03-07},
	journal = {IEEE Access},
	author = {Gong, Zhiqiang and Zhong, Ping and Hu, Weidong},
	year = {2019},
	note = {arXiv:1807.01477 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, diversity},
	pages = {64323--64350},
}

@inproceedings{BalancedNeighborhoodsMultisidedFairnessRecommendation,
	title = {Balanced {Neighborhoods} for {Multi}-sided {Fairness} in {Recommendation}},
	url = {https://proceedings.mlr.press/v81/burke18a.html},
	abstract = {Fairness has emerged as an important category of analysis for machine learning systems in some application areas. In extending the concept of fairness to recommender systems, there is an essential tension between the goals of fairness and those of personalization. However, there are contexts in which  equity across recommendation outcomes is a desirable goal. It is also the case that in some applications fairness may be a multisided concept, in which the impacts on multiple groups of individuals must be considered. In this paper, we examine two different cases of fairness-aware recommender systems: consumer-centered and provider-centered. We  explore the concept of a balanced neighborhood as a mechanism to preserve personalization in recommendation while enhancing the fairness of recommendation outcomes. We show that a modified version of the Sparse Linear Method (SLIM) can be used to improve the balance of user and item neighborhoods, with the result of achieving greater outcome fairness in real-world datasets with minimal loss in ranking performance.},
	language = {en},
	urldate = {2023-03-05},
	booktitle = {Proceedings of the 1st {Conference} on {Fairness}, {Accountability} and {Transparency}},
	publisher = {PMLR},
	author = {Burke, Robin and Sonboli, Nasim and Ordonez-Gauger, Aldo},
	month = jan,
	year = {2018},
	note = {ISSN: 2640-3498},
	keywords = {multi-sided, rec},
	pages = {202--214},
}

@inproceedings{Howalgorithmicconfoundingrecommendationsystems,
	address = {Vancouver British Columbia Canada},
	title = {How algorithmic confounding in recommendation systems increases homogeneity and decreases utility},
	isbn = {978-1-4503-5901-6},
	url = {https://dl.acm.org/doi/10.1145/3240323.3240370},
	doi = {10.1145/3240323.3240370},
	abstract = {Recommendation systems are ubiquitous and impact many domains; they have the potential to in�uence product consumption, individuals’ perceptions of the world, and life-altering decisions. These systems are often evaluated or trained with data from users already exposed to algorithmic recommendations; this creates a pernicious feedback loop. Using simulations, we demonstrate how using data confounded in this way homogenizes user behavior without increasing utility.},
	language = {en},
	urldate = {2023-03-05},
	booktitle = {Proceedings of the 12th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Chaney, Allison J. B. and Stewart, Brandon M. and Engelhardt, Barbara E.},
	month = sep,
	year = {2018},
	keywords = {feedback-loop, rec},
	pages = {224--232},
}

@misc{Exposureideologicallydiversenewsopinion,
	title = {Exposure to ideologically diverse news and opinion on {Facebook}},
	url = {https://www.science.org/doi/epdf/10.1126/science.aaa1160},
	urldate = {2023-03-05},
	keywords = {bias, rec},
}

@inproceedings{UnderstandingEchoChambersEcommerceRecommender,
	address = {Virtual Event China},
	title = {Understanding {Echo} {Chambers} in {E}-commerce {Recommender} {Systems}},
	isbn = {978-1-4503-8016-4},
	url = {https://dl.acm.org/doi/10.1145/3397271.3401431},
	doi = {10.1145/3397271.3401431},
	abstract = {Personalized recommendation benefits users in accessing contents of interests effectively. Current research on recommender systems mostly focuses on matching users with proper items based on user interests. However, significant efforts are missing to understand how the recommendations influence user preferences and behaviors, e.g., if and how recommendations result in echo chambers. Extensive efforts have been made in examining the phenomenon in online media and social network systems. Meanwhile, there are growing concerns that recommender systems might lead to the self-reinforcing of user’s interests due to narrowed exposure of items, which may be the potential cause of echo chamber. In this paper, we aim to analyze the echo chamber phenomenon in Alibaba Taobao — one of the largest e-commerce platforms in the world.},
	language = {en},
	urldate = {2023-03-05},
	booktitle = {Proceedings of the 43rd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Ge, Yingqiang and Zhao, Shuya and Zhou, Honglu and Pei, Changhua and Sun, Fei and Ou, Wenwu and Zhang, Yongfeng},
	month = jul,
	year = {2020},
	keywords = {bias, rec},
	pages = {2261--2270},
}

@inproceedings{Exploringfilterbubbleeffectusing,
	address = {Seoul Korea},
	title = {Exploring the filter bubble: the effect of using recommender systems on content diversity},
	isbn = {978-1-4503-2744-2},
	shorttitle = {Exploring the filter bubble},
	url = {https://dl.acm.org/doi/10.1145/2566486.2568012},
	doi = {10.1145/2566486.2568012},
	abstract = {Eli Pariser coined the term ‘ﬁlter bubble’ to describe the potential for online personalization to eﬀectively isolate people from a diversity of viewpoints or content. Online recommender systems - built on algorithms that attempt to predict which items users will most enjoy consuming - are one family of technologies that potentially suﬀers from this effect. Because recommender systems have become so prevalent, it is important to investigate their impact on users in these terms. This paper examines the longitudinal impacts of a collaborative ﬁltering-based recommender system on users. To the best of our knowledge, it is the ﬁrst paper to measure the ﬁlter bubble eﬀect in terms of content diversity at the individual level. We contribute a novel metric to measure content diversity based on information encoded in user-generated tags, and we present a new set of methods to examine the temporal eﬀect of recommender systems on the user experience. We do ﬁnd that recommender systems expose users to a slightly narrowing set of items over time. However, we also see evidence that users who actually consume the items recommended to them experience lessened narrowing eﬀects and rate items more positively.},
	language = {en},
	urldate = {2023-03-05},
	booktitle = {Proceedings of the 23rd international conference on {World} wide web},
	publisher = {ACM},
	author = {Nguyen, Tien T. and Hui, Pik-Mai and Harper, F. Maxwell and Terveen, Loren and Konstan, Joseph A.},
	month = apr,
	year = {2014},
	keywords = {bias, rec},
	pages = {677--686},
}

@incollection{CollaborationMachineAgeTrustworthyHumanAI,
	address = {Cham},
	title = {Collaboration in the {Machine} {Age}: {Trustworthy} {Human}-{AI} {Collaboration}},
	volume = {24},
	isbn = {978-3-030-93051-6 978-3-030-93052-3},
	shorttitle = {Collaboration in the {Machine} {Age}},
	url = {https://link.springer.com/10.1007/978-3-030-93052-3_14},
	abstract = {Collaboration in the machine age will increasingly involve collaboration with Artificial Intelligence (AI) technologies. This chapter aims to provide insights in the state of the art of AI developments in relation to human-AI collaboration. It presents a brief historic overview of developments in AI, three different forms of human-AI collaboration (e.g. conversational agents) and introduces the main areas of research in relation to human-AI collaboration and potential pitfalls. The chapter discusses the emergent multifaceted role of AI for collaboration in organizations and introduces the concept of trustworthy human-AI collaboration.},
	language = {en},
	urldate = {2023-03-03},
	booktitle = {Advances in {Selected} {Artificial} {Intelligence} {Areas}},
	publisher = {Springer International Publishing},
	author = {Razmerita, Liana and Brun, Armelle and Nabeth, Thierry},
	editor = {Virvou, Maria and Tsihrintzis, George A. and Jain, Lakhmi C.},
	year = {2022},
	doi = {10.1007/978-3-030-93052-3_14},
	note = {Series Title: Learning and Analytics in Intelligent Systems},
	pages = {333--356},
}

@inproceedings{RepSysFrameworkInteractiveEvaluationRecommendera,
	address = {Seattle WA USA},
	title = {{RepSys}: {Framework} for {Interactive} {Evaluation} of {Recommender} {Systems}},
	isbn = {978-1-4503-9278-5},
	shorttitle = {{RepSys}},
	url = {https://dl.acm.org/doi/10.1145/3523227.3551469},
	doi = {10.1145/3523227.3551469},
	abstract = {Making recommender systems more transparent and auditable is crucial for the future adoption of these systems. Available tools typically present mostly errors of models aggregated over all test users, which is often insufficient to uncover hidden biases and problems. Moreover, the emphasis is primarily on the accuracy of recommendations but less on other important metrics, such as the diversity of recommended items, the extent of catalog coverage, or the opportunity to discover novel items at bestsellers’ expense. In this work, we propose RepSys, a framework for evaluating recommender systems. Our work offers a set of highly interactive approaches for investigating various scenario recommendations, analyzing a dataset, and evaluating distributions of various metrics that combine visualization techniques with existing offline evaluation methods. RepSys framework is available under an open-source license to other researchers.},
	language = {en},
	urldate = {2023-03-02},
	booktitle = {Sixteenth {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Šafařík, Jan and Vančura, Vojtěch and Kordík, Pavel},
	month = sep,
	year = {2022},
	pages = {636--639},
}

@techreport{DRAVAAligningHumanConceptsMachine,
	type = {preprint},
	title = {{DRAVA}: {Aligning} {Human} {Concepts} with {Machine} {Learning} {Latent} {Dimensions} for the {Visual} {Exploration} of {Small} {Multiples}},
	shorttitle = {{DRAVA}},
	url = {https://osf.io/gzu27},
	abstract = {This paper proposes Drava, a novel method that utilizes Disentangled Representation learning as A Visual Analytics approach for concept-driven exploration of small multiples. While latent vectors extracted by machine learning models are widely used to organize and explore data (e.g., layout data items based on their latent vectors in a 2D space using t-SNE), they usually suffer from a lack of interpretability. Disentangled representation learning (DRL) alleviates this issue by learning vectors that encode concepts in separated dimensions and are therefore more interpretable. Even though promising, it can be challenging to apply these disentangled vectors due to the imperfections of algorithms and our limited understanding of how to support DRL-based visual exploration. To address this problem, we propose a three-step workflow where users 1) understand ML-learned concepts, 2) refine and align ML concepts with human concepts, and 3) generate new knowledge about the analyzed data through concept-driven exploration. We support this three-step workflow by providing a set of interactions based on visual piles and enhancing the DRL model with a concept adaptor that fine-tunes concept quality based on human feedback. Interactive visual piles enable users to effectively organize, summarize, and compare groups of items based on human-readable concepts. The concept adaptor assists users in modifying potential imperfect semantic vectors and better facilitates concept-driven exploration. We demonstrate the usability of Drava using four usage scenarios with different datasets. Our experiments show that the semantic latent vectors can capture human-readable concepts and the concept adaptor can further improve these semantic concepts using human feedback.},
	language = {en},
	urldate = {2023-03-16},
	institution = {Open Science Framework},
	author = {Wang, Qianwen and L'Yi, Sehi and Gehlenborg, Nils},
	month = apr,
	year = {2022},
	doi = {10.31219/osf.io/gzu27},
	keywords = {concept, interpretable, vis},
}

@article{ResponsibleAIDesignSpaceExploration,
	title = {Towards {Responsible} {AI}: {A} {Design} {Space} {Exploration} of {Human}-{Centered} {Artificial} {Intelligence} {User} {Interfaces} to {Investigate} {Fairness}},
	issn = {1044-7318, 1532-7590},
	shorttitle = {Towards {Responsible} {AI}},
	url = {https://www.tandfonline.com/doi/full/10.1080/10447318.2022.2067936},
	doi = {10.1080/10447318.2022.2067936},
	abstract = {With Artificial intelligence (AI) to aid or automate decision-making advancing rapidly, a particular concern is its fairness. In order to create reliable, safe and trustworthy systems through humancentred artificial intelligence (HCAI) design, recent efforts have produced user interfaces (UIs) for AI experts to investigate the fairness of AI models. In this work, we provide a design space exploration that supports not only data scientists but also domain experts to investigate AI fairness. Using loan applications as an example, we held a series of workshops with loan officers and data scientists to elicit their requirements. We instantiated these requirements into FairHIL, a UI to support human-in-the-loop fairness investigations, and describe how this UI could be generalized to other use cases. We evaluated FairHIL through a think-aloud user study. Our work contributes better designs to investigate an AI model’s fairness—and move closer towards responsible AI.},
	language = {en},
	urldate = {2023-03-15},
	journal = {International Journal of Human–Computer Interaction},
	author = {Nakao, Yuri and Strappelli, Lorenzo and Stumpf, Simone and Naseer, Aisha and Regoli, Daniele and Gamba, Giulia Del},
	month = may,
	year = {2022},
	keywords = {fair, vis},
	pages = {1--27},
}

@inproceedings{ModelAgnosticCounterfactualReasoningEliminatingPopularity,
	address = {Virtual Event Singapore},
	title = {Model-{Agnostic} {Counterfactual} {Reasoning} for {Eliminating} {Popularity} {Bias} in {Recommender} {System}},
	isbn = {978-1-4503-8332-5},
	url = {https://dl.acm.org/doi/10.1145/3447548.3467289},
	doi = {10.1145/3447548.3467289},
	language = {en},
	urldate = {2023-03-22},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Wei, Tianxin and Feng, Fuli and Chen, Jiawei and Wu, Ziwei and Yi, Jinfeng and He, Xiangnan},
	month = aug,
	year = {2021},
	keywords = {fair, rec},
	pages = {1791--1800},
}

@book{biasvarianceanalysisensemblelearningclassification,
	title = {A bias-variance analysis of ensemble learning for classification},
	abstract = {A decomposition of the expected prediction error into bias and variance components is useful when investigating the accuracy of a predictor. However, in classification such a decomposition is not as straightforward as in the case of squared-error loss in regression. As a result various definitions of bias and variance for classification can be found in the literature. In this paper these definitions are reviewed and an empirical study of a particular bias-variance decomposition is presented for ensemble classifiers.},
	author = {Pretorius, Arnu and Bierman, Surette and Steel, Sarel},
	month = dec,
	year = {2016},
	keywords = {bias-variance},
}

@misc{Biasvariancedecompositionabsoluteerrorsdiagnosing,
	title = {Bias-variance decomposition of absolute errors for diagnosing regression models of continuous data {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S2666389921001525?token=9FB2C0AAAC7FC6EDBCD4B478C72183E694B48BD1C5C30F92F81F6F9C08B383297E542567F1B6FD42FE319F5C55EB5E4E&originRegion=us-east-1&originCreation=20230112200720},
	language = {en},
	urldate = {2023-01-12},
	doi = {10.1016/j.patter.2021.100309},
	keywords = {bias-variance},
}

@article{PsychologicalStudiesCausalCounterfactualReasoning,
	title = {1 1 {Psychological} {Studies} of {Causal} and {Counterfactual} {Reasoning} },
	abstract = {This paper explores some interconnections between studies of causal and counterfactual reasoning conducted by psychologists and treatments of causation and counterfactuals in the philosophical literature. Among the issues discussed are the following: (1) the di erent understandings of counterfactual reasoning employed by psychologists and philosophers, including the status of the distinction between counterfactuals and future hypotheticals; (2) whether there is a developmental transition with respect to the capacity for counterfactual thinking that occurs around 3–4 years and the possible implications of this for the relationship between causal and counterfactual reasoning; (3) the variety of di erent ways in which causal and counterfactual claims may be connected, including the use of counterfactuals to elucidate the di erences between casual and correlational claims, to elucidate the di erences between causes and conditions, and to elucidate actual cause judgments; (4) whether, as a psychological matter, causal reasoning sometimes or always involves assessment of counterfactuals; and (5) whether and under what circumstances counterfactual reasoning may be regarded as implicit.},
	language = {en},
	author = {Woodward, James},
}

@inproceedings{FrameworkUnderstandingSourcesHarmthroughout,
	address = {-- NY USA},
	title = {A {Framework} for {Understanding} {Sources} of {Harm} throughout the {Machine} {Learning} {Life} {Cycle}},
	isbn = {978-1-4503-8553-4},
	url = {https://dl.acm.org/doi/10.1145/3465416.3483305},
	doi = {10.1145/3465416.3483305},
	abstract = {As machine learning (ML) increasingly affects people and society, awareness of its potential unwanted consequences has also grown. To anticipate, prevent, and mitigate undesirable downstream consequences, it is critical that we understand when and how harm might be introduced throughout the ML life cycle. In this paper, we provide a framework that identifies seven distinct potential sources of downstream harm in machine learning, spanning data collection, development, and deployment. In doing so, we aim to facilitate more productive and precise communication around these issues, as well as more direct, application-grounded ways to mitigate them.},
	language = {en},
	urldate = {2023-01-10},
	booktitle = {Equity and {Access} in {Algorithms}, {Mechanisms}, and {Optimization}},
	publisher = {ACM},
	author = {Suresh, Harini and Guttag, John},
	month = oct,
	year = {2021},
	keywords = {dm, stereotype},
	pages = {1--9},
}

@article{ImplicationsDistinguishingUnexplainedVarianceThat,
	title = {Some {Implications} of {Distinguishing} {Between} {Unexplained} {Variance} {That} {Is} {Systematic} or {Random}},
	volume = {78},
	issn = {0013-1644},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6096465/},
	doi = {10.1177/0013164417691573},
	abstract = {Because error variance alternatively can be considered to be the sum of
systematic variance associated with unknown variables and randomness, a
tripartite assumption is proposed that total variance in the dependent variable
can be partitioned into three variance components. These are variance in the
dependent variable that is explained by the independent variable, variance in
the dependent variable that is unexplained but systematic (associated with
variance in unknown variables), and random variance. Based on the tripartite
assumption, classical measurement theory, and simple mathematics, it is shown
that these components can be estimated using observable data. Mathematical and
computer simulations illustrate some of the important issues and
implications.},
	number = {3},
	urldate = {2023-01-10},
	journal = {Educational and Psychological Measurement},
	author = {Trafimow, David},
	month = jun,
	year = {2018},
	pmid = {30140103},
	pmcid = {PMC6096465},
	keywords = {bias-variance},
	pages = {482--503},
}

@article{Stereotypes,
	title = {Stereotypes*},
	volume = {131},
	issn = {0033-5533, 1531-4650},
	url = {https://academic.oup.com/qje/article/131/4/1753/2468882},
	doi = {10.1093/qje/qjw029},
	abstract = {Abstract
            We present a model of stereotypes based on Kahneman and Tversky’s representativeness heuristic. A decision maker assesses a target group by overweighting its representative types, defined as the types that occur more frequently in that group than in a baseline reference group. Stereotypes formed this way contain a “kernel of truth”: they are rooted in true differences between groups. Because stereotypes focus on differences, they cause belief distortions, particularly when groups are similar. Stereotypes are also context dependent: beliefs about a group depend on the characteristics of the reference group. In line with our predictions, beliefs in the lab about abstract groups and beliefs in the field about political groups are context dependent and distorted in the direction of representative types.},
	language = {en},
	number = {4},
	urldate = {2023-01-09},
	journal = {The Quarterly Journal of Economics},
	author = {Bordalo, Pedro and Coffman, Katherine and Gennaioli, Nicola and Shleifer, Andrei},
	month = nov,
	year = {2016},
	keywords = {stereotype},
	pages = {1753--1794},
}

@article{BiasVarianceDecompositionsLikelihoodBasedEstimators,
	title = {Bias/{Variance} {Decompositions} for {Likelihood}-{Based} {Estimators}},
	volume = {10},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/10/6/1425-1433/6183},
	doi = {10.1162/089976698300017232},
	abstract = {The bias variance decomposition of mean-squared error is well understood and relatively straightforward. In this note a similar simple decomposition is derived, valid for any kind of error measure that, when using the appropriate probability model, can be derived from a Kullback-Leibler divergence or loglikelihood.},
	language = {en},
	number = {6},
	urldate = {2023-01-08},
	journal = {Neural Computation},
	author = {Heskes, Tom},
	month = aug,
	year = {1998},
	pages = {1425--1433},
}

@article{PromisesChallengesArtificialIntelligenceTeachers,
	title = {The {Promises} and {Challenges} of {Artificial} {Intelligence} for {Teachers}: a {Systematic} {Review} of {Research}},
	volume = {66},
	issn = {8756-3894, 1559-7075},
	shorttitle = {The {Promises} and {Challenges} of {Artificial} {Intelligence} for {Teachers}},
	url = {https://link.springer.com/10.1007/s11528-022-00715-y},
	doi = {10.1007/s11528-022-00715-y},
	abstract = {This study provides an overview of research on teachers’ use of artificial intelligence (AI) applications and machine learning methods to analyze teachers’ data. Our analysis showed that AI offers teachers several opportunities for improved planning (e.g., by defining students’ needs and familiarizing teachers with such needs), implementation (e.g., through immediate feedback and teacher intervention), and assessment (e.g., through automated essay scoring) of their teaching. We also found that teachers have various roles in the development of AI technology. These roles include acting as models for training AI algorithms and participating in AI development by checking the accuracy of AI automated assessment systems. Our findings further underlined several challenges in AI implementation in teaching practice, which provide guidelines for developing the field.},
	language = {en},
	number = {4},
	urldate = {2023-01-28},
	journal = {TechTrends},
	author = {Celik, Ismail and Dindar, Muhterem and Muukkonen, Hanni and Järvelä, Sanna},
	month = jul,
	year = {2022},
	pages = {616--630},
}

@article{ImpactAITeachingLearningHigher,
	title = {The {Impact} of {AI} on {Teaching} and {Learning} in {Higher} {Education} {Technology}},
	volume = {12},
	issn = {21583595},
	url = {http://ezproxy.msu.edu/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=eft&AN=159989843&site=ehost-live&scope=site},
	abstract = {Thanks to AI, students may now study whenever and wherever they like. Personalized feedback on assignments, quizzes, and other assessments can be generated using AI algorithms and utilised as a teaching tool to help students succeed. This study examined the impact of artificial intelligence in higher education teaching and learning. This study focuses on the impact of new technologies on student learning and educational institutions. With the rapid adoption of new technologies in higher education, as well as recent technological advancements, it is possible to forecast the future of higher education in a world where artificial intelligence is ubiquitous. Administration, student support, teaching, and learning can all benefit from the use of these technologies; we identify some challenges that higher education institutions and students may face, and we consider potential research directions.},
	number = {13},
	urldate = {2023-01-27},
	journal = {Journal of Higher Education Theory \& Practice},
	author = {Singh, Satya Vir and Hiran, Kamal Kant},
	month = oct,
	year = {2022},
	keywords = {Artificial intelligence, Educational technology, Higher education, Technological innovations, Technology education, edu},
	pages = {135--148},
}

@article{innermusesHowaffectivetemperament,
	title = {The inner muses: {How} affective temperament traits, gender and age predict film genre preference},
	volume = {178},
	issn = {01918869},
	shorttitle = {The inner muses},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S019188692100252X},
	doi = {10.1016/j.paid.2021.110877},
	abstract = {The aim of this study is to assess whether different affective temperaments, age and gender are associated with specific film genre preference. An online survey was administered to 689 adult subjects. We assessed the film genre preference on a Likert scale and affective temperament traits using the self-report questionnaire Temperament Evaluation of Memphis, Pisa, Paris and San Diego (TEMPS-A) short-version scale.},
	language = {en},
	urldate = {2023-01-25},
	journal = {Personality and Individual Differences},
	author = {Infortuna, Carmenrita and Battaglia, Fortunato and Freedberg, David and Mento, Carmela and Zoccali, Rocco Antonio and Muscatello, Maria Rosaria Anna and Bruno, Antonio},
	month = aug,
	year = {2021},
	pages = {110877},
}

@article{FACTORSTHATDETERMINEFILMGENRE,
	title = {{FACTORS} {THAT} {DETERMINE} {FILM} {GENRE} {PREFERENCE} {OF} {AUDIENCES}: {THE} {CASE} {OF} {THREE} {SELECTED} {GOVERNMENT} {OWNED} {CINEMAS} {IN} {ADDIS} {ABABA}},
	language = {en},
	author = {Mohammed, Yesuf},
}

@article{GeneralizationsBiasVarianceDecompositionPrediction,
	title = {Generalizations of the {Bias}/{Variance} {Decomposition} for {Prediction} {Error}},
	abstract = {The bias and variance of a real valued random variable, using squared error loss, are well understood. However because of recent developments in classi cation techniques it has become desirable to extend these concepts to general random variables and loss functions. The 0-1 (misclassi cation) loss function with categorical random variables has been of particular interest. We explore the concepts of variance and bias and develop a decomposition of the prediction error into functions of the systematic and variable parts of our predictor. After providing some examples we conclude with a discussion of the various de nitions that have been proposed.},
	language = {en},
	author = {James, Gareth and Hastie, Trevor},
}

@misc{MindMeetsMachineCognitiveScience,
	title = {Mind {Meets} {Machine}: {Towards} a {Cognitive} {Science} of {Human}-{Machine} {Interactions} {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Mind {Meets} {Machine}},
	url = {https://reader.elsevier.com/reader/sd/pii/S1364661320302977?token=F6A80F9E6AB790857D0BE7C6100B799CADE652FC927C3184A0E75D5CCFBF4ABD1427E5A98BF0F4780E99A417BB79CE73&originRegion=us-east-1&originCreation=20230211144206},
	language = {en},
	urldate = {2023-02-11},
	doi = {10.1016/j.tics.2020.11.009},
}

@article{Interplayupsamplingregularizationproviderfairness,
	title = {Interplay between upsampling and regularization for provider fairness in recommender systems},
	volume = {31},
	issn = {0924-1868, 1573-1391},
	url = {https://link.springer.com/10.1007/s11257-021-09294-8},
	doi = {10.1007/s11257-021-09294-8},
	abstract = {Considering the impact of recommendations on item providers is one of the duties of multi-sided recommender systems. Item providers are key stakeholders in online platforms, and their earnings and plans are influenced by the exposure their items receive in recommended lists. Prior work showed that certain minority groups of providers, characterized by a common sensitive attribute (e.g., gender or race), are being disproportionately affected by indirect and unintentional discrimination. Our study in this paper handles a situation where (i) the same provider is associated with multiple items of a list suggested to a user, (ii) an item is created by more than one provider jointly, and (iii) predicted user–item relevance scores are biasedly estimated for items of provider groups. Under this scenario, we assess disparities in relevance, visibility, and exposure, by simulating diverse representations of the minority group in the catalog and the interactions. Based on emerged unfair outcomes, we devise a treatment that combines observation upsampling and loss regularization, while learning user–item relevance scores. Experiments on real-world data demonstrate that our treatment leads to lower disparate relevance. The resulting recommended lists show fairer visibility and exposure, higher minority item coverage, and negligible loss in recommendation utility.},
	language = {en},
	number = {3},
	urldate = {2023-02-09},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Boratto, Ludovico and Fenu, Gianni and Marras, Mirko},
	month = jul,
	year = {2021},
	pages = {421--455},
}

@book{impactArtificialIntelligencelearningteaching,
	address = {LU},
	title = {The impact of {Artificial} {Intelligence} on learning, teaching, and education.},
	url = {https://data.europa.eu/doi/10.2760/12297},
	abstract = {This report describes the current state of the art in artificial intelligence (AI) and its potential impact for learning, teaching, and education. It provides conceptual foundations for well-informed policy-oriented work, research, and forward-looking activities that address the opportunities and challenges created by recent developments in AI. The report is aimed for policy developers, but it also makes contributions that are of interest for AI technology developers and researchers studying the impact of AI on economy, society, and the future of education and learning.},
	language = {en},
	urldate = {2023-02-09},
	publisher = {Publications Office},
	author = {{European Commission. Joint Research Centre.}},
	year = {2018},
}

@inproceedings{PossibilitiesApprehensionsLandscapeArtificialIntelligence,
	title = {Possibilities and {Apprehensions} in the {Landscape} of {Artificial} {Intelligence} in {Education}},
	doi = {10.1109/ICCICA52458.2021.9697272},
	abstract = {Artificial intelligence (AI) may be utilized outside of traditional computer settings and is also readily available in low-cost smart devices, making AI easily accessible to general population. Built-in capabilities for conducting complicated computer operations (edge computing), cloud-based services for collaboratively addressing difficult issues, access to huge quantities of open and closed data resources, and conciliatory accession for agile network connections are all available on these low-cost devices. Education is helped by AI in at least two ways: (1) the educational process – assistance and modifications to pedagogy and educator's routine function; and (2) the educational ambit and content – what kind of education is needed. Author, in this article, explores the challenges and potentialities that AI offers in the field of education. While the focus is on AI's participation, it may be difficult to differentiate it from other technological advancements, especially when it comes to work life. Author conclude that AI (and associated technological advancements) will substitute some professions (didactics will not be required), that other professions will transform impressively (didactic materials will need to be updated), and that a significant number of novel vocations will be created (new-fangled didactics must be constituted). In educational operations – the task itself – AI will be a reformer as well as a facilitator, altering the characteristics and division of labor.},
	booktitle = {2021 {International} {Conference} on {Computational} {Intelligence} and {Computing} {Applications} ({ICCICA})},
	author = {Alam, Ashraf},
	month = nov,
	year = {2021},
	keywords = {Artificial Intelligence, Artificial intelligence, Education, Educational Technology, Expert Systems, ICT in Education, Intelligent Systems, Machine Learning, Smart devices, Sociology, Statistics, Task analysis, Teaching, Transforms, edu},
	pages = {1--8},
}

@inproceedings{RepSysFrameworkInteractiveEvaluationRecommender,
	address = {Seattle WA USA},
	title = {{RepSys}: {Framework} for {Interactive} {Evaluation} of {Recommender} {Systems}},
	isbn = {978-1-4503-9278-5},
	shorttitle = {{RepSys}},
	url = {https://dl.acm.org/doi/10.1145/3523227.3551469},
	doi = {10.1145/3523227.3551469},
	abstract = {Making recommender systems more transparent and auditable is crucial for the future adoption of these systems. Available tools typically present mostly errors of models aggregated over all test users, which is often insufficient to uncover hidden biases and problems. Moreover, the emphasis is primarily on the accuracy of recommendations but less on other important metrics, such as the diversity of recommended items, the extent of catalog coverage, or the opportunity to discover novel items at bestsellers’ expense. In this work, we propose RepSys, a framework for evaluating recommender systems. Our work offers a set of highly interactive approaches for investigating various scenario recommendations, analyzing a dataset, and evaluating distributions of various metrics that combine visualization techniques with existing offline evaluation methods. RepSys framework is available under an open-source license to other researchers.},
	language = {en},
	urldate = {2023-02-08},
	booktitle = {Sixteenth {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Šafařík, Jan and Vančura, Vojtěch and Kordík, Pavel},
	month = sep,
	year = {2022},
	pages = {636--639},
}

@inproceedings{UncoveringHeterogeneousEffectsPreferenceDiversity,
	address = {Washington DC USA},
	title = {Uncovering the {Heterogeneous} {Effects} of {Preference} {Diversity} on {User} {Activeness}: {A} {Dynamic} {Mixture} {Model}},
	isbn = {978-1-4503-9385-0},
	shorttitle = {Uncovering the {Heterogeneous} {Effects} of {Preference} {Diversity} on {User} {Activeness}},
	url = {https://dl.acm.org/doi/10.1145/3534678.3539033},
	doi = {10.1145/3534678.3539033},
	abstract = {Preference diversity arouses much research attention in recent years, as it is believed to be closely related to many profound problems such as user activeness in social media or recommendation systems. However, due to the lack of large-scale data with comprehensive user behavior log and accurate content labels, the real quantitative effect of preference diversity on user activeness is still largely unknown. This paper studies the heterogeneous effect of preference diversity on user activeness in social media. We examine large-scale real-world datasets collected from two of the most popular video-sharing social platforms in China, including the behavior logs of more than 787 thousand users and 1.95 million videos, with accurate content category information. We investigate the distribution and evolution of preference diversity, and find rich heterogeneity in the effect of preference diversity on the dynamic activeness. Furthermore, we discover the divergence of preference diversity mechanisms for the same user under different usage scenarios, such as active (where users actively seek information) and passive (where users passively receive information) modes. Unlike existing qualitative studies, we propose a universal mixture model with the capability of accurately fitting dynamic activeness curves while reflecting the heterogeneous patterns of preference diversity. To our best knowledge, this is the first quantitative model that incorporates the effect of preference diversity on user activeness. With the modeling parameters, we are able to make accurate churn and activeness predictions and provide decision support for increasing user activity through the intervention of diversity. Our findings and model comprehensively reveal the significance of preference diversity and provide potential implications for the design of future recommendation systems and social media.},
	language = {en},
	urldate = {2023-02-12},
	booktitle = {Proceedings of the 28th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Lu, Yunfei and Cui, Peng and Yu, Linyun and Li, Lei and Zhu, Wenwu},
	month = aug,
	year = {2022},
	pages = {3458--3467},
}

@article{PDVizVisualAnalyticsApproachState,
	title = {{PDViz}: {A} {Visual} {Analytics} {Approach} for {State} {Policy} {Data}},
	volume = {n/a},
	issn = {1467-8659},
	shorttitle = {{PDViz}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14732},
	doi = {10.1111/cgf.14732},
	abstract = {Sub-national governments across the United States implement a variety of policies to address large societal problems and needs. Many policies are picked up or adopted in other states. This process is called policy diffusion and allows researchers to analyse and compare the social, political, and contextual characteristics that lead to adopting certain policies, as well as the efficacy of these policies once adopted. In this paper, we introduce PDViz, a visual analytics approach that allows social scientists to dynamically analyse the policy diffusion history and underlying patterns. It is designed for analysing and answering a list of research questions and tasks posed by social scientists in prior work. To evaluate our system, we present two usage scenarios and conduct interviews with domain experts in political science. The interviews highlight that PDViz provides the result of policy diffusion patterns that align with their domain knowledge as well as the potential to be a learning tool for students to understand the concept of policy diffusion.},
	language = {en},
	number = {n/a},
	urldate = {2023-02-11},
	journal = {Computer Graphics Forum},
	author = {Han, Dongyun and Nayeem, Abdullah-Al-Raihan and Windett, Jason and Cho, Isaac},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14732},
	keywords = {information systems applications, social science, visual analytics},
}

@inproceedings{PlanningTrustHumanRobotCollaboration,
	address = {Chicago IL USA},
	title = {Planning with {Trust} for {Human}-{Robot} {Collaboration}},
	isbn = {978-1-4503-4953-6},
	url = {https://dl.acm.org/doi/10.1145/3171221.3171264},
	doi = {10.1145/3171221.3171264},
	abstract = {Trust is essential for human-robot collaboration and user adoption of autonomous systems, such as robot assistants. This paper introduces a computational model which integrates trust into robot decision-making. Specifically, we learn from data a partially observable Markov decision process (POMDP) with human trust as a latent variable. The trust-POMDP model provides a principled approach for the robot to (i) infer the trust of a human teammate through interaction, (ii) reason about the effect of its own actions on human behaviors, and (iii) choose actions that maximize team performance over the long term. We validated the model through human subject experiments on a table-clearing task in simulation (201 participants) and with a real robot (20 participants). The results show that the trust-POMDP improves human-robot team performance in this task. They further suggest that maximizing trust in itself may not improve team performance.},
	language = {en},
	urldate = {2023-02-15},
	booktitle = {Proceedings of the 2018 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Chen, Min and Nikolaidis, Stefanos and Soh, Harold and Hsu, David and Srinivasa, Siddhartha},
	month = feb,
	year = {2018},
	keywords = {hai, robot},
	pages = {307--315},
}

@article{Effectsexplanationtypesperceivedriska,
	title = {Effects of explanation types and perceived risk on trust in autonomous vehicles},
	volume = {73},
	issn = {13698478},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1369847820304587},
	doi = {10.1016/j.trf.2020.06.021},
	abstract = {Despite technological advances, trust still remains as a major issue facing autonomous vehicles. Existing studies have reported that explanations of the status of automation systems can be an effective strategy to increase trust, but these effects can differ depending on the forms of explanations and autonomous driving situations. To address this issue, this study examines the effects of explanation types and perceived risk on trust in autonomous vehicles. Three types of explanations (i.e., no, simple, and attributional explanations) are designed based on attribution theory. Additionally, four autonomous driving situations with different levels of risk are designed based on a simulator program. Results show that explanation type signiﬁcantly affects trust in autonomous vehicles, and the perceived risk of driving situations signiﬁcantly moderates the effect of the explanation type. At a high level of perceived risk, attributional explanations and no explanations lead to the lowest and highest values in trust, respectively. However, at a low level of perceived risk, these effects reverse.},
	language = {en},
	urldate = {2023-02-16},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {Ha, Taehyun and Kim, Sangyeon and Seo, Donghak and Lee, Sangwon},
	month = aug,
	year = {2020},
	pages = {271--280},
}

@inproceedings{CogitoergoquidEffectCognitive,
	address = {Genoa Italy},
	title = {Cogito ergo quid? {The} {Effect} of {Cognitive} {Style} in a {Transparent} {Mobile} {Music} {Recommender} {System}},
	isbn = {978-1-4503-6861-2},
	shorttitle = {Cogito ergo quid?},
	url = {https://dl.acm.org/doi/10.1145/3340631.3394871},
	doi = {10.1145/3340631.3394871},
	abstract = {An increasing body of research indicates that transparency in recommender systems affects trust of users. Additionally, a vast amount of studies already showed that personality impacts the way users perceive a recommender system. However, only recently, research has begun to investigate the effects of cognitive style on the perception of recommender systems. Furthermore, it is still unclear whether this cognitive style also affects the interaction strategies of users, and whether the reason why and when users want transparency is affected by this cognitive style. Additionally, despite the ubiquitous presence of recommender systems on mobile environments, no study has investigated the effect of transparency for mobile music recommender systems. In this paper, we report the results of a within-subject study (N=25) on a mobile music recommender system where we investigated the effect of cognitive styles on three different aspects: the interaction strategies with the different applications, the reasons why and when users want transparency and the effect of transparency on the trust of users. The results show that users with a rational thinking style put more effort in seeking the best recommendations and that they want scrutable explanations to adjust the recommendation. In contrast, intuitive thinkers only need explanations when they search for a very specific kind of music.},
	language = {en},
	urldate = {2023-01-03},
	booktitle = {Proceedings of the 28th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Millecamp, Martijn and Haveneers, Robin and Verbert, Katrien},
	month = jul,
	year = {2020},
	keywords = {explanation.cognitive},
	pages = {323--327},
}

@article{ImpactCognitiveStylesInformationSystem,
	title = {The {Impact} of {Cognitive} {Styles} on {Information} {System} {Design}},
	volume = {2},
	issn = {02767783},
	url = {https://www.jstor.org/stable/248940?origin=crossref},
	doi = {10.2307/248940},
	abstract = {This article expiores the nature of cognitive styies and the effects of cognitive styie differences on information system usage and design. Some ideas are presented for clarifying the nature of cognitive styles, and a number of cognitive styie models are discussed which are applicable to information system design and research. Suggestions are presented for assisting information system analysts in incorporating the users' cognitive styies differences into information systems design and some probiems are indicated which could arise during implementation. Finally, experimental design factors are outlined for improving research into the cognitive styies area.},
	language = {en},
	number = {2},
	urldate = {2023-01-03},
	journal = {MIS Quarterly},
	author = {Benbasat, Izak and Taylor, Ronald N.},
	month = jun,
	year = {1978},
	keywords = {cognitive, explanation},
	pages = {43},
}

@incollection{UserSpecificDeterminantsConversationalAgentUsage,
	title = {User-{Specific} {Determinants} of {Conversational} {Agent} {Usage}: {A} {Review} and {Potential} for {Future} {Research}},
	isbn = {978-3-030-86796-6},
	shorttitle = {User-{Specific} {Determinants} of {Conversational} {Agent} {Usage}},
	abstract = {Conversational agents (CAs) have become integral parts of providers’ service offerings, yet their potential is not fully exploited as users’ acceptance and usage of CAs are often limited. Whereas previous research is rather technology-oriented, our study takes a user-centric perspective on the phenomenon. We conduct a systematic literature review to summarize the determinants of individuals’ acceptance, adoption, and usage of CAs that have been examined in extant research, followed by an interview study to identify potential for further research. In particular, five concepts are proposed for further research: personality, risk aversion, cognitive style, self-efficacy, and desire for control. Empirical studies are encouraged to assess the impact of these user-specific concepts on individuals’ decision to use CAs to eventually inform the design of CAs that facilitate users’ acceptance, adoption, and use. This paper intends to contribute to the body of knowledge about the determinants of CA usage.},
	author = {Riefle, Lara and Benz, Carina},
	month = oct,
	year = {2021},
	doi = {10.1007/978-3-030-86797-3_8},
	keywords = {cognitive, explanation},
	pages = {115--129},
}

@article{DecisionmakingstylesreallifedecisionChoosing,
	title = {Decision-making styles in a real-life decision: {Choosing} a college major},
	volume = {41},
	issn = {01918869},
	shorttitle = {Decision-making styles in a real-life decision},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0191886906001206},
	doi = {10.1016/j.paid.2006.03.003},
	abstract = {Undergraduate students were surveyed at the beginning stages of a potentially life-framing decision: choosing a college major. We investigated the relationships among individual diﬀerence variables (decision-making styles, planning proclivities, and epistemological orientations), cognitive measures of performance (e.g., amount of information gathered and considered); and aﬀective reactions to, and descriptive ratings of, the decision-making process. There were few signiﬁcant relationships between individual diﬀerences and performance measures. However, there were signiﬁcant relationships found between individual diﬀerences measures and aﬀective reactions to, or descriptive ratings of, the decision-making process. We suggest that stylistic measures have their eﬀects in the way individuals frame the decision-making process rather than in the way they go about gathering or structuring information.},
	language = {en},
	number = {4},
	urldate = {2023-01-02},
	journal = {Personality and Individual Differences},
	author = {Galotti, Kathleen M. and Ciner, Elizabeth and Altenbaumer, Hope E. and Geerts, Heather J. and Rupp, Allison and Woulfe, Julie},
	month = sep,
	year = {2006},
	pages = {629--639},
}

@book{AttributionalTheoryMotivationEmotion,
	title = {An {Attributional} {Theory} of {Motivation} and {Emotion}},
	isbn = {978-1-4612-4948-1},
	abstract = {For a long time I have had the gnawing desire to convey the broad motivational sig nificance of the attributional conception that I have espoused and to present fully the argument that this framework has earned a rightful place alongside other leading theories of motivation. Furthermore, recent investigations have yielded insights into the attributional determinants of affect, thus providing the impetus to embark upon a detailed discussion of emotion and to elucidate the relation between emotion and motivation from an attributional perspective. The presentation of a unified theory of motivation and emotion is the goal of this book. My more specific aims in the chapters to follow are to: 1) Outline the basic princi ples that I believe characterize an adequate theory of motivation; 2) Convey what I perceive to be the conceptual contributions of the perspective advocated by my col leagues and me; 3) Summarize the empirical relations, reach some definitive con clusions, and point out the more equivocal empirical associations based on hypotheses derived from our particular attribution theory; and 4) Clarify questions that have been raised about this conception and provide new material for still further scrutiny. In so doing, the building blocks (if any) laid down by the attributional con ception will be readily identified and unknown juries of present and future peers can then better determine the value of this scientific product.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Weiner, Bernard},
	month = dec,
	year = {2012},
	note = {Google-Books-ID: E7JeBAAAQBAJ},
	keywords = {Psychology / Applied Psychology, Psychology / Industrial \& Organizational Psychology, Social Science / Sociology / General, attribution},
}

@book{EvolutionCognitiveLoadTheoryMeasurement,
	title = {The {Evolution} of {Cognitive} {Load} {Theory} and the {Measurement} of {Its} {Intrinsic}, {Extraneous} and {Germane} {Loads}: {A} {Review}},
	isbn = {978-3-030-14272-8},
	shorttitle = {The {Evolution} of {Cognitive} {Load} {Theory} and the {Measurement} of {Its} {Intrinsic}, {Extraneous} and {Germane} {Loads}},
	abstract = {Cognitive Load Theory has been conceived for supporting instructional design through the use of the construct of cognitive load. This is believed to be built upon three types of load: intrinsic, extraneous and germane. Although Cognitive Load Theory and its assumptions are clear and well-known, its three types of load have been going through a continuous investigation and re-definition. Additionally, it is still not clear whether these are independent and can be added to each other towards an overall measure of load. The purpose of this research is to inform the reader about the theoretical evolution of Cognitive Load Theory as well as the measurement techniques and measures emerged for its cognitive load types. It also synthesises the main critiques of scholars and the scientific value of the theory from a rationalist and structuralist perspective.},
	author = {Orru, Giuliano and Longo, Luca},
	month = feb,
	year = {2019},
	doi = {10.1007/978-3-030-14273-5_3},
	note = {Pages: 48},
	keywords = {cognitive, cognitive-load},
}

@inproceedings{Symptomscognitiveloadinteractionsdialogue,
	address = {Boulder Colorado},
	title = {Symptoms of cognitive load in interactions with a dialogue system},
	isbn = {978-1-4503-6072-2},
	url = {https://dl.acm.org/doi/10.1145/3279810.3279851},
	doi = {10.1145/3279810.3279851},
	abstract = {Humans adapt their behaviour to the perceived cognitive load of their dialogue partner, for example, delaying non-essential information. We propose that spoken dialogue systems should do the same, particularly in high-stakes scenarios, such as emergency response. In this paper, we provide a summary of the prosodic, turn-taking and other linguistic symptoms of cognitive load analysed in the literature. We then apply these features to a single corpus in the restaurant-finding domain and propose new symptoms that are evidenced through interaction with the dialogue system, including utterance entropy, speech recognition confidence, as well as others based on dialogue acts.},
	language = {en},
	urldate = {2022-12-31},
	booktitle = {Proceedings of the {Workshop} on {Modeling} {Cognitive} {Processes} from {Multimodal} {Data}},
	publisher = {ACM},
	author = {Lopes, José and Lohan, Katrin and Hastie, Helen},
	month = oct,
	year = {2018},
	keywords = {cognitive-load, explanation},
	pages = {1--5},
}

@inproceedings{HumanPerceptionsMoralResponsibilityAI,
	title = {Human {Perceptions} on {Moral} {Responsibility} of {AI}: {A} {Case} {Study} in {AI}-{Assisted} {Bail} {Decision}-{Making}},
	shorttitle = {Human {Perceptions} on {Moral} {Responsibility} of {AI}},
	url = {http://arxiv.org/abs/2102.00625},
	doi = {10.1145/3411764.3445260},
	abstract = {How to attribute responsibility for autonomous artificial intelligence (AI) systems' actions has been widely debated across the humanities and social science disciplines. This work presents two experiments (\$N\$=200 each) that measure people's perceptions of eight different notions of moral responsibility concerning AI and human agents in the context of bail decision-making. Using real-life adapted vignettes, our experiments show that AI agents are held causally responsible and blamed similarly to human agents for an identical task. However, there was a meaningful difference in how people perceived these agents' moral responsibility; human agents were ascribed to a higher degree of present-looking and forward-looking notions of responsibility than AI agents. We also found that people expect both AI and human decision-makers and advisors to justify their decisions regardless of their nature. We discuss policy and HCI implications of these findings, such as the need for explainable AI in high-stakes scenarios.},
	urldate = {2022-12-25},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Lima, Gabriel and Grgić-Hlača, Nina and Cha, Meeyoung},
	month = may,
	year = {2021},
	note = {arXiv:2102.00625 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, explanation, fatml},
	pages = {1--17},
}

@article{Individualdifferencesadultdecisionmakingcompetence,
	title = {Individual differences in adult decision-making competence.},
	volume = {92},
	issn = {1939-1315, 0022-3514},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0022-3514.92.5.938},
	doi = {10.1037/0022-3514.92.5.938},
	abstract = {The authors evaluated the reliability and validity of a set of 7 behavioral decision-making tasks, measuring different aspects of the decision-making process. The tasks were administered to individuals from diverse populations. Participants showed relatively consistent performance within and across the 7 tasks, which were then aggregated into an Adult Decision-Making Competence (A-DMC) index that showed good reliability. The validity of the 7 tasks and of overall A-DMC emerges in significant relationships with measures of socioeconomic status, cognitive ability, and decision-making styles. Participants who performed better on the A-DMC were less likely to report negative life events indicative of poor decision making, as measured by the Decision Outcomes Inventory. Significant predictive validity remains when controlling for demographic measures, measures of cognitive ability, and constructive decision-making styles. Thus, A-DMC appears to be a distinct construct relevant to adults’ real-world decisions.},
	language = {en},
	number = {5},
	urldate = {2023-01-02},
	journal = {Journal of Personality and Social Psychology},
	author = {Bruine de Bruin, Wändi and Parker, Andrew M. and Fischhoff, Baruch},
	month = may,
	year = {2007},
	keywords = {cognitive, decision-making},
	pages = {938--956},
}

@inproceedings{Calibratedrecommendations,
	address = {Vancouver British Columbia Canada},
	title = {Calibrated recommendations},
	isbn = {978-1-4503-5901-6},
	url = {https://dl.acm.org/doi/10.1145/3240323.3240372},
	doi = {10.1145/3240323.3240372},
	abstract = {When a user has watched, say, 70 romance movies and 30 action movies, then it is reasonable to expect the personalized list of recommended movies to be comprised of about 70\% romance and 30\% action movies as well. This important property is known as calibration, and recently received renewed attention in the context of fairness in machine learning. In the recommended list of items, calibration ensures that the various (past) areas of interest of a user are reflected with their corresponding proportions. Calibration is especially important in light of the fact that recommender systems optimized toward accuracy (e.g., ranking metrics) in the usual offline-setting can easily lead to recommendations where the lesser interests of a user get crowded out by the user’s main interests–which we show empirically as well as in thought-experiments. This can be prevented by calibrated recommendations. To this end, we outline metrics for quantifying the degree of calibration, as well as a simple yet effective re-ranking algorithm for post-processing the output of recommender systems.},
	language = {en},
	urldate = {2022-12-26},
	booktitle = {Proceedings of the 12th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Steck, Harald},
	month = sep,
	year = {2018},
	pages = {154--162},
}

@inproceedings{CausalInterventionLeveragingPopularityBias,
	address = {Virtual Event Canada},
	title = {Causal {Intervention} for {Leveraging} {Popularity} {Bias} in {Recommendation}},
	isbn = {978-1-4503-8037-9},
	url = {https://dl.acm.org/doi/10.1145/3404835.3462875},
	doi = {10.1145/3404835.3462875},
	abstract = {Recommender system usually faces popularity bias issues: from the data perspective, items exhibit uneven (usually long-tail) distribution on the interaction frequency; from the method perspective, collaborative filtering methods are prone to amplify the bias by over-recommending popular items. It is undoubtedly critical to consider popularity bias in recommender systems, and existing work mainly eliminates the bias effect with propensity-based unbiased learning or causal embeddings. However, we argue that not all biases in the data are bad, i.e., some items demonstrate higher popularity because of their better intrinsic quality. Blindly pursuing unbiased learning may remove the beneficial patterns in the data, degrading the recommendation accuracy and user satisfaction.},
	language = {en},
	urldate = {2022-12-26},
	booktitle = {Proceedings of the 44th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Zhang, Yang and Feng, Fuli and He, Xiangnan and Wei, Tianxin and Song, Chonggang and Ling, Guohui and Zhang, Yongdong},
	month = jul,
	year = {2021},
	pages = {11--20},
}

@article{FairnessExplanationAIInformedDecisionMakinga,
	title = {Fairness and {Explanation} in {AI}-{Informed} {Decision} {Making}},
	volume = {4},
	issn = {2504-4990},
	url = {https://www.mdpi.com/2504-4990/4/2/26},
	doi = {10.3390/make4020026},
	abstract = {AI-assisted decision-making that impacts individuals raises critical questions about transparency and fairness in artiﬁcial intelligence (AI). Much research has highlighted the reciprocal relationships between the transparency/explanation and fairness in AI-assisted decision-making. Thus, considering their impact on user trust or perceived fairness simultaneously beneﬁts responsible use of socio-technical AI systems, but currently receives little attention. In this paper, we investigate the effects of AI explanations and fairness on human-AI trust and perceived fairness, respectively, in speciﬁc AI-based decision-making scenarios. A user study simulating AI-assisted decision-making in two health insurance and medical treatment decision-making scenarios provided important insights. Due to the global pandemic and restrictions thereof, the user studies were conducted as online surveys. From the participant’s trust perspective, fairness was found to affect user trust only under the condition of a low fairness level, with the low fairness level reducing user trust. However, adding explanations helped users increase their trust in AI-assisted decision-making. From the perspective of perceived fairness, our work found that low levels of introduced fairness decreased users’ perceptions of fairness, while high levels of introduced fairness increased users’ perceptions of fairness. The addition of explanations deﬁnitely increased the perception of fairness. Furthermore, we found that application scenarios inﬂuenced trust and perceptions of fairness. The results show that the use of AI explanations and fairness statements in AI applications is complex: we need to consider not only the type of explanations and the degree of fairness introduced, but also the scenarios in which AI-assisted decision-making is used.},
	language = {en},
	number = {2},
	urldate = {2022-12-26},
	journal = {Machine Learning and Knowledge Extraction},
	author = {Angerschmid, Alessa and Zhou, Jianlong and Theuermann, Kevin and Chen, Fang and Holzinger, Andreas},
	month = jun,
	year = {2022},
	pages = {556--579},
}

@inproceedings{DeconfoundedRecommendationAlleviatingBiasAmplificationa,
	address = {Virtual Event Singapore},
	title = {Deconfounded {Recommendation} for {Alleviating} {Bias} {Amplification}},
	isbn = {978-1-4503-8332-5},
	url = {https://dl.acm.org/doi/10.1145/3447548.3467249},
	doi = {10.1145/3447548.3467249},
	abstract = {Recommender systems usually amplify the biases in the data. The model learned from historical interactions with imbalanced item distribution will amplify the imbalance by over-recommending items from the majority groups. Addressing this issue is essential for a healthy ecosystem of recommendation in the long run. Existing work applies bias control to the ranking targets (e.g., calibration, fairness, and diversity), but ignores the true reason for bias amplification and trades off the recommendation accuracy. In this work, we scrutinize the cause-effect factors for bias amplification, identifying the main reason lies in the confounding effect of imbalanced item distribution on user representation and prediction score. The existence of such confounder pushes us to go beyond merely modeling the conditional probability and embrace the causal modeling for recommendation. Towards this end, we propose a Deconfounded Recommender System (DecRS), which models the causal effect of user representation on the prediction score. The key to eliminating the impact of the confounder lies in backdoor adjustment, which is however difficult to do due to the infinite sample space of the confounder. For this challenge, we contribute an approximation operator for backdoor adjustment which can be easily plugged into most recommender models. Lastly, we devise an inference strategy to dynamically regulate backdoor adjustment according to user status. We instantiate DecRS on two representative models FM [32] and NFM [16], and conduct extensive experiments over two benchmarks to validate the superiority of our proposed DecRS.},
	language = {en},
	urldate = {2022-12-26},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Wang, Wenjie and Feng, Fuli and He, Xiangnan and Wang, Xiang and Chua, Tat-Seng},
	month = aug,
	year = {2021},
	pages = {1717--1725},
}

@article{BiasVarianceDecompositionBayesianDeepLearninga,
	title = {A {Bias}-{Variance} {Decomposition} for {Bayesian} {Deep} {Learning}},
	abstract = {We exhibit a decomposition of the Kullback-Leibler divergence into terms corresponding to bias, variance, and irreducible error. Our particular focus in this work is Bayesian deep learning and in this domain we illustrate the application of this decomposition to adversarial example identiﬁcation, to image segmentation, and to malware detection. We empirically demonstrate qualitative similarities between the variance decomposition and mutual information.},
	language = {en},
	author = {Brofos, James and Shu, Rui and Lederman, Roy R},
}

@article{highbiaslowvarianceintroductionMachineLearning,
	title = {A high-bias, low-variance introduction to {Machine} {Learning} for physicists},
	volume = {810},
	issn = {0370-1573},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6688775/},
	doi = {10.1016/j.physrep.2019.03.001},
	abstract = {Machine Learning (ML) is one of the most exciting and dynamic areas of modern research and application. The purpose of this review is to provide an introduction to the core concepts and tools of machine learning in a manner easily understood and intuitive to physicists. The review begins by covering fundamental concepts in ML and modern statistics such as the bias-variance tradeoff, overfitting, regularization, generalization, and gradient descent before moving on to more advanced topics in both supervised and unsupervised learning. Topics covered in the review include ensemble models, deep learning and neural networks, clustering and data visualization, energy-based models (including MaxEnt models and Restricted Boltzmann Machines), and variational methods. Throughout, we emphasize the many natural connections between ML and statistical physics. A notable aspect of the review is the use of Python Jupyter notebooks to introduce modern ML/statistical packages to readers using physics-inspired datasets (the Ising Model and Monte-Carlo simulations of supersymmetric decays of proton-proton collisions). We conclude with an extended outlook discussing possible uses of machine learning for furthering our understanding of the physical world as well as open problems in ML where physicists may be able to contribute.},
	urldate = {2022-12-28},
	journal = {Physics reports},
	author = {Mehta, Pankaj and Wang, Ching-Hao and Day, Alexandre G. R. and Richardson, Clint and Bukov, Marin and Fisher, Charles K. and Schwab, David J.},
	month = may,
	year = {2019},
	pmid = {31404441},
	pmcid = {PMC6688775},
	keywords = {bias-variance},
	pages = {1--124},
}

@article{AdultCOMPASFairMultiClassPrediction,
	title = {Beyond {Adult} and {COMPAS}: {Fair} {Multi}-{Class} {Prediction} via {Information} {Projection}},
	abstract = {We consider the problem of producing fair probabilistic classifiers for multi-class classification tasks. We formulate this problem in terms of “projecting” a pretrained (and potentially unfair) classifier onto the set of models that satisfy target group-fairness requirements. The new, projected model is given by post-processing the outputs of the pre-trained classifier by a multiplicative factor. We provide a parallelizable, iterative algorithm for computing the projected classifier and derive both sample complexity and convergence guarantees. Comprehensive numerical comparisons with state-of-the-art benchmarks demonstrate that our approach maintains competitive performance in terms of accuracy-fairness trade-off curves, while achieving favorable runtime on large datasets. We also evaluate our method at scale on an open dataset with multiple classes, multiple intersectional groups, and over 1M samples.},
	language = {en},
	author = {Alghamdi, Wael and Hsu, Hsiang and Jeong, Haewon and Wang, Hao and Michalak, P Winston and Asoodeh, Shahab and Calmon, Flavio P},
	keywords = {fair, multi-class, multi-group},
}

@inproceedings{AnticipatedUserStereotypesSystematicallyAffect,
	address = {Tallinn Estonia},
	title = {Anticipated {User} {Stereotypes} {Systematically} {Affect} the {Social} {Acceptability} of {Mobile} {Devices}},
	isbn = {978-1-4503-7579-5},
	url = {https://dl.acm.org/doi/10.1145/3419249.3420113},
	doi = {10.1145/3419249.3420113},
	abstract = {Understanding social perception is crucial when designing socially accepted mobile devices. Using the stereotype content model (SCM), recent work showed that mobile devices systematically attract stereotypical users’ warmth and competence. It was concluded that the SCM can predict a device’s social acceptability. There is, however, no empirical evidence for the assumption that the SCM can predict social acceptability and it also unclear what causes a device’s stereotypical perception. In this paper, we first verify that the SCM’s dimensions strongly correlate with social acceptance and show that social acceptance can be explained through stereotypical perception. In a second study, we independently asked participants to assess the warmth and competence of mobile devices, human stereotypes, and the probability that human stereotypes use the devices. We found that warmth and competence of anticipated stereotypical users predict a device’s position in the SCM. The combined results of both studies show that the stereotypical perception of anticipated users can explain the social acceptability of mobile devices.},
	language = {en},
	urldate = {2022-12-28},
	booktitle = {Proceedings of the 11th {Nordic} {Conference} on {Human}-{Computer} {Interaction}: {Shaping} {Experiences}, {Shaping} {Society}},
	publisher = {ACM},
	author = {Schwind, Valentin and Henze, Niels},
	month = oct,
	year = {2020},
	pages = {1--12},
}

@article{FeatureNoiseInducesLossDiscrepancy,
	title = {Feature {Noise} {Induces} {Loss} {Discrepancy} {Across} {Groups}},
	abstract = {The performance of standard learning procedures has been observed to differ widely across groups. Recent studies usually attribute this loss discrepancy to an information deﬁciency for one group (e.g., one group has less data). In this work, we point to a more subtle source of loss discrepancy—feature noise. Our main result is that even when there is no information deﬁciency speciﬁc to one group (e.g., both groups have inﬁnite data), adding the same amount of feature noise to all individuals leads to loss discrepancy. For linear regression, we thoroughly characterize the effect of feature noise on loss discrepancy in terms of the amount of noise, the difference between moments of the two groups, and whether group information is used or not. We then show this loss discrepancy does not vanish immediately if a shift in distribution causes the groups to have similar moments. On three real-world datasets, we show feature noise increases the loss discrepancy if groups have different distributions, while it does not affect the loss discrepancy on datasets where groups have similar distributions.},
	language = {en},
	author = {Khani, Fereshte and Liang, Percy},
}

@article{FeatureNoiseInducesLossDiscrepancya,
	title = {Feature {Noise} {Induces} {Loss} {Discrepancy} {Across} {Groups}},
	abstract = {The performance of standard learning procedures has been observed to differ widely across groups. Recent studies usually attribute this loss discrepancy to an information deﬁciency for one group (e.g., one group has less data). In this work, we point to a more subtle source of loss discrepancy—feature noise. Our main result is that even when there is no information deﬁciency speciﬁc to one group (e.g., both groups have inﬁnite data), adding the same amount of feature noise to all individuals leads to loss discrepancy. For linear regression, we thoroughly characterize the effect of feature noise on loss discrepancy in terms of the amount of noise, the difference between moments of the two groups, and whether group information is used or not. We then show this loss discrepancy does not vanish immediately if a shift in distribution causes the groups to have similar moments. On three real-world datasets, we show feature noise increases the loss discrepancy if groups have different distributions, while it does not affect the loss discrepancy on datasets where groups have similar distributions.},
	language = {en},
	author = {Khani, Fereshte and Liang, Percy},
	keywords = {fair, group-difference},
}

@inproceedings{Debiasingbiasmeasurement,
	address = {Seoul Republic of Korea},
	title = {De-biasing “bias” measurement},
	isbn = {978-1-4503-9352-2},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533105},
	doi = {10.1145/3531146.3533105},
	language = {en},
	urldate = {2022-12-28},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Lum, Kristian and Zhang, Yunfeng and Bower, Amanda},
	month = jun,
	year = {2022},
	pages = {379--389},
}

@inproceedings{CounterfactualsExplainableArtificialIntelligenceXAI,
	address = {Macao, China},
	title = {Counterfactuals in {Explainable} {Artificial} {Intelligence} ({XAI}): {Evidence} from {Human} {Reasoning}},
	isbn = {978-0-9992411-4-1},
	shorttitle = {Counterfactuals in {Explainable} {Artificial} {Intelligence} ({XAI})},
	url = {https://www.ijcai.org/proceedings/2019/876},
	doi = {10.24963/ijcai.2019/876},
	abstract = {Counterfactuals about what could have happened are increasingly used in an array of Artificial Intelligence (AI) applications, and especially in explainable AI (XAI). Counterfactuals can aid the provision of interpretable models to make the decisions of inscrutable systems intelligible to developers and users. However, not all counterfactuals are equally helpful in assisting human comprehension. Discoveries about the nature of the counterfactuals that humans create are a helpful guide to maximize the effectiveness of counterfactual use in AI.},
	language = {en},
	urldate = {2022-12-30},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Byrne, Ruth M. J.},
	month = aug,
	year = {2019},
	keywords = {counterfactual, explanation},
	pages = {6276--6282},
}

@article{CounterfactualModelsFairAdequateExplanations,
	title = {Counterfactual {Models} for {Fair} and {Adequate} {Explanations}},
	volume = {4},
	issn = {2504-4990},
	url = {https://www.mdpi.com/2504-4990/4/2/14},
	doi = {10.3390/make4020014},
	abstract = {Recent efforts have uncovered various methods for providing explanations that can help interpret the behavior of machine learning programs. Exact explanations with a rigorous logical foundation provide valid and complete explanations, but they have an epistemological problem: they are often too complex for humans to understand and too expensive to compute even with automated reasoning methods. Interpretability requires good explanations that humans can grasp and can compute. We take an important step toward specifying what good explanations are by analyzing the epistemically accessible and pragmatic aspects of explanations. We characterize sufﬁciently good, or fair and adequate, explanations in terms of counterfactuals and what we call the conundra of the explainee, the agent that requested the explanation. We provide a correspondence between logical and mathematical formulations for counterfactuals to examine the partiality of counterfactual explanations that can hide biases; we deﬁne fair and adequate explanations in such a setting. We provide formal results about the algorithmic complexity of fair and adequate explanations. We then detail two sophisticated counterfactual models, one based on causal graphs, and one based on transport theories. We show transport based models have several theoretical advantages over the competition as explanation frameworks for machine learning algorithms.},
	language = {en},
	number = {2},
	urldate = {2022-12-30},
	journal = {Machine Learning and Knowledge Extraction},
	author = {Asher, Nicholas and De Lara, Lucas and Paul, Soumya and Russell, Chris},
	month = mar,
	year = {2022},
	pages = {316--349},
}

@inproceedings{worstbothworldscomparativeanalysis,
	title = {The worst of both worlds: {A} comparative analysis of errors in learning from data in psychology and machine learning},
	shorttitle = {The worst of both worlds},
	url = {http://arxiv.org/abs/2203.06498},
	doi = {10.1145/3514094.3534196},
	abstract = {Recent arguments that machine learning (ML) is facing a reproducibility and replication crisis suggest that some published claims in ML research cannot be taken at face value. These concerns inspire analogies to the replication crisis affecting the social and medical sciences. They also inspire calls for the integration of statistical approaches to causal inference and predictive modeling. A deeper understanding of what reproducibility concerns in supervised ML research have in common with the replication crisis in experimental science puts the new concerns in perspective, and helps researchers avoid "the worst of both worlds," where ML researchers begin borrowing methodologies from explanatory modeling without understanding their limitations and vice versa. We contribute a comparative analysis of concerns about inductive learning that arise in causal attribution as exemplified in psychology versus predictive modeling as exemplified in ML. We identify themes that re-occur in reform discussions, like overreliance on asymptotic theory and non-credible beliefs about real-world data generating processes. We argue that in both fields, claims from learning are implied to generalize outside the specific environment studied (e.g., the input dataset or subject sample, modeling implementation, etc.) but are often impossible to refute due to undisclosed sources of variance in the learning pipeline. In particular, errors being acknowledged in ML expose cracks in long-held beliefs that optimizing predictive accuracy using huge datasets absolves one from having to consider a true data generating process or formally represent uncertainty in performance claims. We conclude by discussing risks that arise when sources of errors are misdiagnosed and the need to acknowledge the role of human inductive biases in learning and reform.},
	urldate = {2022-12-28},
	booktitle = {Proceedings of the 2022 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	author = {Hullman, Jessica and Kapoor, Sayash and Nanayakkara, Priyanka and Gelman, Andrew and Narayanan, Arvind},
	month = jul,
	year = {2022},
	note = {arXiv:2203.06498 [cs]},
	keywords = {Computer Science - Machine Learning},
	pages = {335--348},
}

@inproceedings{Debiasingbiasmeasurementa,
	title = {De-biasing "bias" measurement},
	url = {http://arxiv.org/abs/2205.05770},
	doi = {10.1145/3531146.3533105},
	abstract = {When a model's performance differs across socially or culturally relevant groups--like race, gender, or the intersections of many such groups--it is often called "biased." While much of the work in algorithmic fairness over the last several years has focused on developing various definitions of model fairness (the absence of group-wise model performance disparities) and eliminating such "bias," much less work has gone into rigorously measuring it. In practice, it important to have high quality, human digestible measures of model performance disparities and associated uncertainty quantification about them that can serve as inputs into multi-faceted decision-making processes. In this paper, we show both mathematically and through simulation that many of the metrics used to measure group-wise model performance disparities are themselves statistically biased estimators of the underlying quantities they purport to represent. We argue that this can cause misleading conclusions about the relative group-wise model performance disparities along different dimensions, especially in cases where some sensitive variables consist of categories with few members. We propose the "double-corrected" variance estimator, which provides unbiased estimates and uncertainty quantification of the variance of model performance across groups. It is conceptually simple and easily implementable without statistical software package or numerical optimization. We demonstrate the utility of this approach through simulation and show on a real dataset that while statistically biased estimators of group-wise model performance disparities indicate statistically significant differences, when accounting for statistical bias in the estimator, the estimated between-group disparities are no longer statistically significant.},
	urldate = {2022-12-28},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	author = {Lum, Kristian and Zhang, Yunfeng and Bower, Amanda},
	month = jun,
	year = {2022},
	note = {arXiv:2205.05770 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Statistics - Methodology, fair},
	pages = {379--389},
}

@techreport{Structurelearningprinciplesstereotypechange,
	type = {preprint},
	title = {Structure learning principles of stereotype change},
	url = {https://osf.io/52f9c},
	abstract = {Why, when, and how do stereotypes change? This paper develops a computational account based on the principles of structure learning: stereotypes are governed by probabilistic beliefs about the assignment of individuals to groups. Two aspects of this account are particularly important. First, groups are ﬂexibly constructed based on the distribution of traits across individuals. This allows the model to explain the phenomenon of subtyping, whereby deviant individuals are segregated from a group, thus protecting the group’s stereotype. Second, groups are hierarchically structured, such that groups can be nested. This allows the model to explain the phenomenon of subgrouping, whereby a collection of deviant individuals is organized into a reﬁnement of the group. The structure learning account also sheds light on several factors that determine stereotype change, including perceived group variability, individual typicality, cognitive load, and sample size.},
	language = {en},
	urldate = {2022-12-28},
	institution = {PsyArXiv},
	author = {Gershman, Samuel J. and Cikara, Mina},
	month = aug,
	year = {2021},
	doi = {10.31234/osf.io/52f9c},
}

@inproceedings{RelatableExplainableAIPerceptualProcess,
	address = {New Orleans LA USA},
	title = {Towards {Relatable} {Explainable} {AI} with the {Perceptual} {Process}},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3501826},
	doi = {10.1145/3491102.3501826},
	abstract = {Machine learning models need to provide contrastive explanations, since people often seek to understand why a puzzling prediction occurred instead of some expected outcome. Current contrastive explanations are rudimentary comparisons between examples or raw features, which remain difficult to interpret, since they lack semantic meaning. We argue that explanations must be more relatable to other concepts, hypotheticals, and associations. Inspired by the perceptual process from cognitive psychology, we propose the XAI Perceptual Processing Framework and RexNet model for relatable explainable AI with Contrastive Saliency, Counterfactual Synthetic, and Contrastive Cues explanations. We investigated the application of vocal emotion recognition, and implemented a modular multi-task deep neural network to predict and explain emotions from speech. From think-aloud and controlled studies, we found that counterfactual explanations were useful and further enhanced with semantic cues, but not saliency explanations. This work provides insights into providing and evaluating relatable contrastive explainable AI for perception applications.},
	language = {en},
	urldate = {2022-12-30},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhang, Wencan and Lim, Brian Y},
	month = apr,
	year = {2022},
	keywords = {contrastive, explanation},
	pages = {1--24},
}

@article{SurveyAlgorithmicRecourseContrastiveExplanations,
	title = {A {Survey} of {Algorithmic} {Recourse}: {Contrastive} {Explanations} and {Consequential} {Recommendations}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	shorttitle = {A {Survey} of {Algorithmic} {Recourse}},
	url = {https://dl.acm.org/doi/10.1145/3527848},
	doi = {10.1145/3527848},
	abstract = {Machine learning is increasingly used to inform decision making in sensitive situations where decisions have consequential effects on individuals’ lives. In these settings, in addition to requiring models to be accurate and robust, socially relevant values such as fairness, privacy, accountability, and explainability play an important role in the adoption and impact of said technologies. In this work, we focus on
              algorithmic recourse
              , which is concerned with providing explanations and recommendations to individuals who are unfavorably treated by automated decision-making systems. We first perform an extensive literature review, and align the efforts of many authors by presenting unified definitions, formulations, and solutions to recourse. Then, we provide an overview of the prospective research directions toward which the community may engage, challenging existing assumptions and making explicit connections to other ethical challenges such as security, privacy, and fairness.},
	language = {en},
	number = {5},
	urldate = {2022-12-30},
	journal = {ACM Computing Surveys},
	author = {Karimi, Amir-Hossein and Barthe, Gilles and Schölkopf, Bernhard and Valera, Isabel},
	month = jun,
	year = {2023},
	keywords = {algorithmic-recourse},
	pages = {1--29},
}

@article{CognitiveArchitectureInstructionalDesign,
	title = {Cognitive {Architecture} and {Instructional} {Design}},
	language = {en},
	author = {Sweller, John},
}

@article{Exposingimplicitbiasesstereotypeshuman,
	title = {Exposing implicit biases and stereotypes in human and artificial intelligence: state of the art and challenges with a focus on gender},
	issn = {0951-5666, 1435-5655},
	shorttitle = {Exposing implicit biases and stereotypes in human and artificial intelligence},
	url = {https://link.springer.com/10.1007/s00146-022-01474-3},
	doi = {10.1007/s00146-022-01474-3},
	abstract = {Biases in cognition are ubiquitous. Social psychologists suggested biases and stereotypes serve a multifarious set of cognitive goals, while at the same time stressing their potential harmfulness. Recently, biases and stereotypes became the purview of heated debates in the machine learning community too. Researchers and developers are becoming increasingly aware of the fact that some biases, like gender and race biases, are entrenched in the algorithms some AI applications rely upon. Here, taking into account several existing approaches that address the problem of implicit biases and stereotypes, we propose that a strategy to cope with this phenomenon is to unmask those found in AI systems by understanding their cognitive dimension, rather than simply trying to correct algorithms. To this extent, we present a discussion bridging together findings from cognitive science and insights from machine learning that can be integrated in a state-of-the-art semantic network. Remarkably, this resource can be of assistance to scholars (e.g., cognitive and computer scientists) while at the same time contributing to refine AI regulations affecting social life. We show how only through a thorough understanding of the cognitive processes leading to biases, and through an interdisciplinary effort, we can make the best of AI technology.},
	language = {en},
	urldate = {2022-12-19},
	journal = {AI \& SOCIETY},
	author = {Marinucci, Ludovica and Mazzuca, Claudia and Gangemi, Aldo},
	month = may,
	year = {2022},
}

@inproceedings{DelayanalysisCBRtrafficstaticpriority,
	address = {Sydney,NSW,Australia},
	title = {Delay analysis for {CBR} traffic in static-priority scheduling: single-node and heterogeneous {CBR} traffic case},
	volume = {2},
	isbn = {978-0-7803-4984-1},
	shorttitle = {Delay analysis for {CBR} traffic in static-priority scheduling},
	url = {http://ieeexplore.ieee.org/document/776922/},
	doi = {10.1109/GLOCOM.1998.776922},
	abstract = {In the integrated service networks, the real-time trafﬁc and the non-real-time trafﬁc share the network resources so that one can affect the quality of another and vice versa. In this context, it is very crucial to develop some mechanism to guarantee the quality-of-service (QoS) required by the real-time trafﬁc.},
	language = {en},
	urldate = {2022-12-18},
	booktitle = {{IEEE} {GLOBECOM} 1998 ({Cat}. {NO}. {98CH36250})},
	publisher = {IEEE},
	author = {Iida, K. and Takine, T. and Sunahara, H. and Oie, Y.},
	year = {1998},
	keywords = {case-based, heterogeneous},
	pages = {1256--1263},
}

@incollection{MappingGoalsKindsExplanationsKnowledge,
	address = {Berlin, Heidelberg},
	title = {Mapping {Goals} and {Kinds} of {Explanations} to the {Knowledge} {Containers} of {Case}-{Based} {Reasoning} {Systems}},
	volume = {3620},
	isbn = {978-3-540-28174-0 978-3-540-31855-2},
	url = {http://link.springer.com/10.1007/11536406_35},
	abstract = {Research on explanation in Case-Based Reasoning (CBR) is a topic that gains momentum. In this context, fundamental issues on what are and to which end do we use explanations have to be reconsidered. This article presents a prelimenary outline of the combination of two recently proposed classiﬁcations of explanations based on the type of the explanation itself and user goals which should be fulﬁlled. Further on, the contribution of the diﬀerent knowledge containers for modeling the necessary knowledge is examined.},
	language = {en},
	urldate = {2022-12-18},
	booktitle = {Case-{Based} {Reasoning} {Research} and {Development}},
	publisher = {Springer Berlin Heidelberg},
	author = {Roth-Berghofer, Thomas R. and Cassens, Jörg},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Muñoz-Ávila, Héctor and Ricci, Francesco},
	year = {2005},
	doi = {10.1007/11536406_35},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {451--464},
}

@article{FairnessExplanationAIInformedDecisionMaking,
	title = {Fairness and {Explanation} in {AI}-{Informed} {Decision} {Making}},
	volume = {4},
	issn = {2504-4990},
	url = {https://www.mdpi.com/2504-4990/4/2/26},
	doi = {10.3390/make4020026},
	abstract = {AI-assisted decision-making that impacts individuals raises critical questions about transparency and fairness in artiﬁcial intelligence (AI). Much research has highlighted the reciprocal relationships between the transparency/explanation and fairness in AI-assisted decision-making. Thus, considering their impact on user trust or perceived fairness simultaneously beneﬁts responsible use of socio-technical AI systems, but currently receives little attention. In this paper, we investigate the effects of AI explanations and fairness on human-AI trust and perceived fairness, respectively, in speciﬁc AI-based decision-making scenarios. A user study simulating AI-assisted decision-making in two health insurance and medical treatment decision-making scenarios provided important insights. Due to the global pandemic and restrictions thereof, the user studies were conducted as online surveys. From the participant’s trust perspective, fairness was found to affect user trust only under the condition of a low fairness level, with the low fairness level reducing user trust. However, adding explanations helped users increase their trust in AI-assisted decision-making. From the perspective of perceived fairness, our work found that low levels of introduced fairness decreased users’ perceptions of fairness, while high levels of introduced fairness increased users’ perceptions of fairness. The addition of explanations deﬁnitely increased the perception of fairness. Furthermore, we found that application scenarios inﬂuenced trust and perceptions of fairness. The results show that the use of AI explanations and fairness statements in AI applications is complex: we need to consider not only the type of explanations and the degree of fairness introduced, but also the scenarios in which AI-assisted decision-making is used.},
	language = {en},
	number = {2},
	urldate = {2022-12-18},
	journal = {Machine Learning and Knowledge Extraction},
	author = {Angerschmid, Alessa and Zhou, Jianlong and Theuermann, Kevin and Chen, Fang and Holzinger, Andreas},
	month = jun,
	year = {2022},
	pages = {556--579},
}

@incollection{Reasoningreasonscasebasedcomparisons,
	address = {Berlin, Heidelberg},
	title = {Reasoning with reasons in case-based comparisons},
	volume = {1010},
	isbn = {978-3-540-60598-0 978-3-540-48446-2},
	url = {http://link.springer.com/10.1007/3-540-60598-3_13},
	abstract = {In this work, we are interested in how rational decision makers reason with and about reasons in a domain, practical ethics, where they appear to reason about reasons symbolically in terms of both abstract moral principles and case comparisons. The challenge for reasoners, human and artificial, is to use abstract knowledge of reasons and principles to inform decisions about the salience of similarities and differences among cases while still accounting for a case's or problem's specific contextual circumstances. TRUTH-TELLER is a program we have developed and tested that compares pairs of cases presenting ethical dilemmas about whether to tell the truth. The program's methods for reasoning about reasons help it to make context sensitive assessments of the salience of similarities and differences.},
	language = {en},
	urldate = {2022-12-18},
	booktitle = {Case-{Based} {Reasoning} {Research} and {Development}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ashley, Kevin D. and McLaren, Bruce M.},
	editor = {Carbonell, Jaime G. and Siekmann, Jörg and Goos, G. and Hartmanis, J. and van Leeuwen, J. and Veloso, Manuela and Aamodt, Agnar},
	year = {1995},
	doi = {10.1007/3-540-60598-3_13},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {133--144},
}

@article{SurveyCBRApplicationAreas,
	title = {Survey of {CBR} {Application} {Areas}},
	language = {en},
	author = {Watson, Ian},
	year = {1999},
}

@inproceedings{HeterogeneityontologybasedCBRsystems,
	title = {Heterogeneity in ontology-based {CBR} systems},
	doi = {10.1109/IRI.2009.5211573},
	abstract = {This paper presents our knowledge-intensive case-based reasoning platform for diagnosis, COBRA. We work currently on the diagnosis of safety barrier failures at industrial sites. COBRA allows to author and reuse past experiences in order to diagnose new failure situations. It integrates domain knowledge along with cases in an ontological structure, which enhances its semantic reasoning capacities. We aim to make this platform as generic as possible so that it accepts different domains of application. Thus, the case structure (attributes) is defined dynamically by users at run time, which leads to a heterogeneous case base. In this paper, we present the platform architecture, the knowledge models, and the problems encountered when working with a heterogeneous case base.},
	booktitle = {2009 {IEEE} {International} {Conference} on {Information} {Reuse} \& {Integration}},
	author = {Assali, Amjad Abou and Lenne, Dominique and Debray, Bruno},
	month = aug,
	year = {2009},
	keywords = {Case-based reasoning, Gas detectors, Hazards, Heterogeneous case base, Industrial control, Industrial plants, Leak detection, OWL, Object oriented modeling, Ontologies, Ontology, Problem-solving, Safety, case-based, explanation},
	pages = {324--329},
}

@article{CaseBasedReasoningCaseRepresentation,
	title = {Case {Based} {Reasoning}: {Case} {Representation} {Methodologies}},
	volume = {6},
	issn = {21565570, 2158107X},
	shorttitle = {Case {Based} {Reasoning}},
	url = {http://thesai.org/Publications/ViewPaper?Volume=6&Issue=11&Code=ijacsa&SerialNo=26},
	doi = {10.14569/IJACSA.2015.061126},
	abstract = {Case Based Reasoning (CBR) is an important technique in artificial intelligence, which has been applied to various kinds of problems in a wide range of domains. Selecting case representation formalism is critical for the proper operation of the overall CBR system. In this paper, we survey and evaluate all of the existing case representation methodologies. Moreover, the case retrieval and future challenges for effective CBR are explained. Case representation methods are grouped in to knowledge-intensive approaches and traditional approaches. The first group overweight the second one. The first methods depend on ontology and enhance all CBR processes including case representation, retrieval, storage, and adaptation. By using a proposed set of qualitative metrics, the existing methods based on ontology for case representation are studied and evaluated in details. All these systems have limitations. No approach exceeds 53\% of the specified metrics. The results of the survey explain the current limitations of CBR systems. It shows that ontology usage in case representation needs improvements to achieve semantic representation and semantic retrieval in CBR system.},
	language = {en},
	number = {11},
	urldate = {2022-12-18},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {H., Shaker and Elmogy, Mohammed},
	year = {2015},
	keywords = {case-based, explanation},
}

@inproceedings{StereotypingProblemCollaborativelyFilteredRecommender,
	address = {-- NY USA},
	title = {The {Stereotyping} {Problem} in {Collaboratively} {Filtered} {Recommender} {Systems}},
	isbn = {978-1-4503-8553-4},
	url = {https://dl.acm.org/doi/10.1145/3465416.3483298},
	doi = {10.1145/3465416.3483298},
	abstract = {Recommender systems play a crucial role in mediating our access to online information. We show that such algorithms induce a particular kind of stereotyping: if preferences for a set of items are anti-correlated in the general user population, then those items may not be recommended together to a user, regardless of that user’s preferences and rating history. First, we introduce a notion of joint accessibility, which measures the extent to which a set of items can jointly be accessed by users. We then study joint accessibility under the standard factorization-based collaborative filtering framework, and provide theoretical necessary and sufficient conditions when joint accessibility is violated. Moreover, we show that these conditions can easily be violated when the users are represented by a single feature vector. To improve joint accessibility, we further propose an alternative modelling fix, which is designed to capture the diverse multiple interests of each user using a multi-vector representation. We conduct extensive experiments on real and simulated datasets, demonstrating the stereotyping problem with standard single-vector matrix factorization models.},
	language = {en},
	urldate = {2022-12-22},
	booktitle = {Equity and {Access} in {Algorithms}, {Mechanisms}, and {Optimization}},
	publisher = {ACM},
	author = {Guo, Wenshuo and Krauth, Karl and Jordan, Michael and Garg, Nikhil},
	month = oct,
	year = {2021},
	pages = {1--10},
}

@article{RacialBiasPerceptionsSizeStrength,
	title = {Racial {Bias} in {Perceptions} of {Size} and {Strength}: {The} {Impact} of {Stereotypes} and {Group} {Differences}},
	volume = {30},
	issn = {0956-7976, 1467-9280},
	shorttitle = {Racial {Bias} in {Perceptions} of {Size} and {Strength}},
	url = {http://journals.sagepub.com/doi/10.1177/0956797619827529},
	doi = {10.1177/0956797619827529},
	abstract = {Recent research has shown that race can influence perceptions of men’s size and strength. Across two studies (Study 1: N = 1,032, Study 2: N = 303) examining men and women from multiple racial groups (Asian, Black, and White adults), we found that although race does impact judgments of size and strength, raters’ judgments primarily track targets’ objective physical features. In some cases, racial stereotypes actually improved group-level accuracy, as these stereotypes aligned with racial-group differences in size and strength according to nationally representative data. We conclude that individuals primarily rely on individuating information when making physical judgments but do not completely discount racial stereotypes, which reflect a combination of real group-level differences and culturally transmitted beliefs.},
	language = {en},
	number = {4},
	urldate = {2022-12-22},
	journal = {Psychological Science},
	author = {Johnson, David J. and Wilson, John Paul},
	month = apr,
	year = {2019},
	pages = {553--562},
}

@misc{MovieLens1BSyntheticDataset,
	title = {{MovieLens} {1B} {Synthetic} {Dataset}},
	url = {https://grouplens.org/datasets/movielens/movielens-1b/},
	abstract = {MovieLens 1B is a synthetic dataset that is expanded from the 20 million real-world ratings from ML-20M, distributed in support of MLPerf. Note that these data are distributed as .npz files, which …},
	language = {en},
	urldate = {2022-12-21},
	journal = {GroupLens},
	month = apr,
	year = {2019},
}

@article{TearsFearsComparingGenderStereotypes,
	title = {Tears or {Fears}? {Comparing} {Gender} {Stereotypes} about {Movie} {Preferences} to {Actual} {Preferences}},
	volume = {8},
	issn = {1664-1078},
	shorttitle = {Tears or {Fears}?},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2017.00428/full},
	doi = {10.3389/fpsyg.2017.00428},
	abstract = {This study investigated the accuracy of gender-speciﬁc stereotypes about movie-genre preferences for 17 genres. In Study 1, female and male participants rated the extent to which 17 movie genres are preferred by women or men. In Study 2, another sample of female and male participants rated their own preference for each genre. There were three notable results. First, Study 1 revealed the existence of gender stereotypes for the majority of genres (i.e., for 15 of 17 genres). Second, Study 2 revealed the existence of actual gender differences in preferences for the majority of genres (i.e., for 11 of 17 genres). Third, in order to assess the accuracy of gender stereotypes on movie preferences, we compared the results of both studies and found that the majority of gender stereotypes were accurate in direction, but inaccurate in size. In particular, the stereotypes overestimated actual gender differences for the majority of movie genres (i.e., 10 of 17). Practical and theoretical implications of these ﬁndings are discussed.},
	language = {en},
	urldate = {2022-12-21},
	journal = {Frontiers in Psychology},
	author = {Wühr, Peter and Lange, Benjamin P. and Schwarz, Sascha},
	month = mar,
	year = {2017},
}

@article{StereotypesStereotypingMoralAnalysis,
	title = {Stereotypes {And} {Stereotyping}: {A} {Moral} {Analysis}},
	volume = {33},
	issn = {0556-8641, 1996-8523},
	shorttitle = {Stereotypes {And} {Stereotyping}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/05568640409485143},
	doi = {10.1080/05568640409485143},
	abstract = {Stereotypes are false or misleading generalizations about groups held in a manner that renders them largely, though not entirely, immune to counterevidence. In doing so, stereotypes powerfully shape the stereotyper's perception of stereotyped groups, seeing the stereotypic characteristics when they are not present, failing to see the contrary of· those characteristics when they are,. and generally homogenizing the group. A stereotyper associates a certain characteristic with the stereotyped.\_group--forexample Blacks with being athletic-but may do so with a form of cognitive investment in tha( as·sociation that does not rise to the level of a belief in the generalization that Blacks are athletic. The cognitive distortions involved in stereotyping lead to various forms of moral distortion, to which moral philosophers have paid inadequate attention. Some moral distortions are common to all stereotypes-moral distancing, failing to see members of the stereotyped group as individuals, and failing to see diversity within that. group. Other moral distortions vary with the stereotype. Some stereotypes attribute a desirable characteristic to a group (being good students, for example) and, ceteris paribus, are less objectionable than ones. that attribute undesirable characteristics. Yet the larger historical and social context may attach undesirable characteristics to the desirable ones-being boring and overfocused on academic pursuits, for example. The popular film The Passion of the Christ purveys negative stereotypes of Jews that have been historically powerful and damaging along with negative portrayals of Romans that have not.},
	language = {en},
	number = {3},
	urldate = {2022-12-20},
	journal = {Philosophical Papers},
	author = {Blum, Lawrence},
	month = nov,
	year = {2004},
	pages = {251--289},
}

@article{ApplyingMotivationOpportunityAbilityMOA,
	title = {Applying the {Motivation}, {Opportunity}, {Ability} ({MOA}) {Model}, and {Self}-{Efficacy} ({S}-{E}) to {Better} {Understand} {Student} {Engagement} on {Undergraduate} {Event} {Management} {Programs}},
	volume = {22},
	issn = {1525-9951},
	url = {https://www.ingentaconnect.com/content/10.3727/152599518X15173356116718},
	doi = {10.3727/152599518X15173356116718},
	abstract = {Considering the Motivation, Opportunity, Ability (MOA) Model (Hung et al 2011) and the SelfEfficacy (S-E) component of Bandura’s (1986) Social Cognitive Theory (SCT), this paper aims to examine through a series of four research questions whether such models can help to determine how students engage with their programme of study. Furthermore, the paper will determine factors which influence student engagement in event management (EM) degree programmes and seek to understand how EM students engage with their reading and interact within classroom based environments. In doing so, the paper will contribute to the existing debates on inclusive teaching and learning in higher education (HE), and provide a link towards creating more professional and employable graduates. Self-efficacy refers to beliefs in one’s capabilities to learn or perform at designated levels (Bandura, 1986; 1997). Much research has demonstrated that self-efficacy influences academic motivation, learning, and achievement; particularly within science, technology, English and mathematics (STEM) subjects. With this in mind, this research aims to investigate the frame conditions mentioned which surround both self and group efficacy and seeks to reveal whether the above models can be used to better understand the engagement and subsequent performance of undergraduate EM students. This analysis will enable academics to better understand the role of MOA and S-E, how these develop over a programme of study and thereby provide a boost to student self-efficacy. By doing so, the best possible educational experience and results in Higher Education can be achieved.},
	language = {en},
	number = {2},
	urldate = {2022-12-24},
	journal = {Event Management},
	author = {Jepson, Allan and Ryan, W. Gerard},
	month = apr,
	year = {2018},
	pages = {271--285},
}

@article{DecisionMakingStyleDevelopmentAssessmentNew,
	title = {Decision-{Making} {Style}: {The} {Development} and {Assessment} of a {New} {Measure}},
	volume = {55},
	issn = {0013-1644, 1552-3888},
	shorttitle = {Decision-{Making} {Style}},
	url = {http://journals.sagepub.com/doi/10.1177/0013164495055005017},
	doi = {10.1177/0013164495055005017},
	abstract = {A multistage, four sample study was conducted to develop a conceptually consistent and psychometrically sound measure of decision-making style. Construct definitions were developed from prior theory, and items were written to assess rational, avoidant, intuitive, and dependent decision-making styles. A series of principal-axis factor analyses with varimax rotation and subsequent item analyses were conducted to develop four conceptually distinct scales with acceptable internal consistency (alpha ranging from .68 to .94) and a stable factor structure. In the process of scale development, a fifth style (spontaneous) was identified. Tests for independence among the five decision-making style scales and concurrent validity analyses were conducted. Finally, discussion of the new instrument with reference to the extant literature is provided.},
	language = {en},
	number = {5},
	urldate = {2022-12-24},
	journal = {Educational and Psychological Measurement},
	author = {Scott, Susanne G. and Bruce, Reginald A.},
	month = oct,
	year = {1995},
	pages = {818--831},
}

@article{CognitiveLoadTheoryFormatInstruction,
	title = {Cognitive {Load} {Theory} and the {Format} of {Instruction}},
	volume = {8},
	issn = {0737-0008, 1532-690X},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s1532690xci0804_2},
	doi = {10.1207/s1532690xci0804_2},
	language = {en},
	number = {4},
	urldate = {2022-12-18},
	journal = {Cognition and Instruction},
	author = {Chandler, Paul and Sweller, John},
	month = dec,
	year = {1991},
	keywords = {cognitive, explanation},
	pages = {293--332},
}

@misc{ReviewCaseBasedDecisionTheory,
	title = {A {Review} of {Case}-{Based} {Decision} {Theory}},
	url = {https://www.scirp.org/html/7-2121379_89826.htm?pagespeed=noscript###},
	urldate = {2022-12-18},
	keywords = {case-based, explanation},
}

@book{RecommenderSystemsHandbook,
	address = {Boston, MA},
	title = {Recommender {Systems} {Handbook}},
	isbn = {978-1-4899-7636-9 978-1-4899-7637-6},
	url = {http://link.springer.com/10.1007/978-1-4899-7637-6},
	language = {en},
	urldate = {2022-12-18},
	publisher = {Springer US},
	editor = {Ricci, Francesco and Rokach, Lior and Shapira, Bracha},
	year = {2015},
	doi = {10.1007/978-1-4899-7637-6},
}

@article{Similaritymeasuresattributeselectioncasebased,
	title = {Similarity measures and attribute selection for case-based reasoning in transcatheter aortic valve implantation},
	volume = {15},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0238463},
	doi = {10.1371/journal.pone.0238463},
	abstract = {In a clinical decision support system, the purpose of case-based reasoning is to help clinicians make convenient decisions for diagnoses or interventional gestures. Past experience, which is represented by a case-base of previous patients, is exploited to solve similar current problems using four steps—retrieve, reuse, revise, and retain. The proposed casebased reasoning has been focused on transcatheter aortic valve implantation to respond to clinical issues pertaining vascular access and prosthesis choices. The computation of a relevant similarity measure is an essential processing step employed to obtain a set of retrieved cases from a case-base. A hierarchical similarity measure that is based on a clinical decision tree is proposed to better integrate the clinical knowledge, especially in terms of case representation, case selection and attributes weighting. A case-base of 138 patients is used to evaluate the case-based reasoning performance, and retrieve- and reuse-based criteria have been considered. The sensitivity for the vascular access and the prosthesis choice is found to 0.88 and 0.94, respectively, with the use of the hierarchical similarity measure as opposed to 0.53 and 0.79 for the standard similarity measure. Ninety percent of the suggested solutions are correctly classified for the proposed metric when four cases are retrieved. Using a dedicated similarity measure, with relevant and weighted attributes selected through a clinical decision tree, the set of retrieved cases, and consequently, the decision suggested by the case-based reasoning are substantially improved over state-ofthe-art similarity measures.},
	language = {en},
	number = {9},
	urldate = {2022-12-18},
	journal = {PLOS ONE},
	author = {Feuillâtre, Hélène and Auffret, Vincent and Castro, Miguel and Lalys, Florent and Le Breton, Hervé and Garreau, Mireille and Haigron, Pascal},
	editor = {Son, Le Hoang},
	month = sep,
	year = {2020},
	pages = {e0238463},
}

@article{ImprovingVisualizationInterpretationUsingCounterfactualsb,
	title = {Improving {Visualization} {Interpretation} {Using} {Counterfactuals}},
	volume = {28},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {http://arxiv.org/abs/2107.10309},
	doi = {10.1109/TVCG.2021.3114779},
	abstract = {Complex, high-dimensional data is used in a wide range of domains to explore problems and make decisions. Analysis of high-dimensional data, however, is vulnerable to the hidden inﬂuence of confounding variables, especially as users apply ad hoc ﬁltering operations to visualize only speciﬁc subsets of an entire dataset. Thus, visual data-driven analysis can mislead users and encourage mistaken assumptions about causality or the strength of relationships between features. This work introduces a novel visual approach designed to reveal the presence of confounding variables via counterfactual possibilities during visual data analysis. It is implemented in CoFact, an interactive visualization prototype that determines and visualizes counterfactual subsets to better support user exploration of feature relationships. Using publicly available datasets, we conducted a controlled user study to demonstrate the effectiveness of our approach; the results indicate that users exposed to counterfactual visualizations formed more careful judgments about feature-to-outcome relationships.},
	language = {en},
	number = {1},
	urldate = {2022-12-10},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kaul, Smiti and Borland, David and Cao, Nan and Gotz, David},
	month = jan,
	year = {2022},
	note = {arXiv:2107.10309 [cs]},
	keywords = {Computer Science - Human-Computer Interaction},
	pages = {998--1008},
}

@inproceedings{UnequalRepresentationGenderStereotypesImage,
	address = {Seoul Republic of Korea},
	title = {Unequal {Representation} and {Gender} {Stereotypes} in {Image} {Search} {Results} for {Occupations}},
	isbn = {978-1-4503-3145-6},
	url = {https://dl.acm.org/doi/10.1145/2702123.2702520},
	doi = {10.1145/2702123.2702520},
	abstract = {Information environments have the power to affect people’s perceptions and behaviors. In this paper, we present the results of studies in which we characterize the gender bias present in image search results for a variety of occupations. We experimentally evaluate the effects of bias in image search results on the images people choose to represent those careers and on people’s perceptions of the prevalence of men and women in each occupation. We find evidence for both stereotype exaggeration and systematic underrepresentation of women in search results. We also find that people rate search results higher when they are consistent with stereotypes for a career, and shifting the representation of gender in image search results can shift people’s perceptions about real-world distributions. We also discuss tensions between desires for high-quality results and broader societal goals for equality of representation in this space.},
	language = {en},
	urldate = {2022-11-30},
	booktitle = {Proceedings of the 33rd {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kay, Matthew and Matuszek, Cynthia and Munson, Sean A.},
	month = apr,
	year = {2015},
	pages = {3819--3828},
}

@inproceedings{CalibrationCollaborativeFilteringRecommenderSystems,
	address = {Virtual Event USA},
	title = {Calibration in {Collaborative} {Filtering} {Recommender} {Systems}: a {User}-{Centered} {Analysis}},
	isbn = {978-1-4503-7098-1},
	shorttitle = {Calibration in {Collaborative} {Filtering} {Recommender} {Systems}},
	url = {https://dl.acm.org/doi/10.1145/3372923.3404793},
	doi = {10.1145/3372923.3404793},
	abstract = {Recommender systems learn from past user preferences in order to predict future user interests and provide users with personalized suggestions. Previous research has demonstrated that biases in user profiles in the aggregate can influence the recommendations to users who do not share the majority preference. One consequence of this bias propagation effect is miscalibration, a mismatch between the types or categories of items that a user prefers and the items provided in recommendations. In this paper, we conduct a systematic analysis aimed at identifying key characteristics in user profiles that might lead to miscalibrated recommendations. We consider several categories of profile characteristics, including similarity to the average user, propensity towards popularity, profile diversity, and preference intensity. We develop predictive models of miscalibration and use these models to identify the most important features correlated with miscalibration, given different algorithms and dataset characteristics. Our analysis is intended to help system designers predict miscalibration effects and to develop recommendation algorithms with improved calibration properties.},
	language = {en},
	urldate = {2022-12-03},
	booktitle = {Proceedings of the 31st {ACM} {Conference} on {Hypertext} and {Social} {Media}},
	publisher = {ACM},
	author = {Lin, Kun and Sonboli, Nasim and Mobasher, Bamshad and Burke, Robin},
	month = jul,
	year = {2020},
	keywords = {diversity, minority, rec, stereotype},
	pages = {197--206},
}

@article{QuestioningRacialGenderBiasAIbased,
	title = {Questioning {Racial} and {Gender} {Bias} in {AI}-based {Recommendations}: {Do} {Espoused} {National} {Cultural} {Values} {Matter}?},
	issn = {1387-3326, 1572-9419},
	shorttitle = {Questioning {Racial} and {Gender} {Bias} in {AI}-based {Recommendations}},
	url = {https://link.springer.com/10.1007/s10796-021-10156-2},
	doi = {10.1007/s10796-021-10156-2},
	abstract = {One realm of AI, recommender systems have attracted significant research attention due to concerns about its devastating effects to society’s most vulnerable and marginalised communities. Both media press and academic literature provide compelling evidence that AI-based recommendations help to perpetuate and exacerbate racial and gender biases. Yet, there is limited knowledge about the extent to which individuals might question AI-based recommendations when perceived as biased. To address this gap in knowledge, we investigate the effects of espoused national cultural values on AI questionability, by examining how individuals might question AI-based recommendations due to perceived racial or gender bias. Data collected from 387 survey respondents in the United States indicate that individuals with espoused national cultural values associated to collectivism, masculinity and uncertainty avoidance are more likely to question biased AI-based recommendations. This study advances understanding of how cultural values affect AI questionability due to perceived bias and it contributes to current academic discourse about the need to hold AI accountable.},
	language = {en},
	urldate = {2022-12-03},
	journal = {Information Systems Frontiers},
	author = {Gupta, Manjul and Parra, Carlos M. and Dennehy, Denis},
	month = jun,
	year = {2021},
}

@article{GenderstereotypereinforcementMeasuringgender,
	title = {Gender stereotype reinforcement: {Measuring} the gender bias conveyed by ranking algorithms},
	volume = {57},
	issn = {03064573},
	shorttitle = {Gender stereotype reinforcement},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306457320308724},
	doi = {10.1016/j.ipm.2020.102377},
	abstract = {Search Engines (SE) have been shown to perpetuate well-known gender stereotypes identified in psychology literature and to influence users accordingly. Similar biases were found encoded in Word Embeddings (WEs) learned from large online corpora. In this context, we propose the Gender Stereotype Reinforcement (GSR) measure, which quantifies the tendency of a SE to support gender stereotypes, leveraging gender-related information encoded in WEs.},
	language = {en},
	number = {6},
	urldate = {2022-12-03},
	journal = {Information Processing \& Management},
	author = {Fabris, Alessandro and Purpura, Alberto and Silvello, Gianmaria and Susto, Gian Antonio},
	month = nov,
	year = {2020},
	pages = {102377},
}

@article{StereotypeMostPopularRecommendationsDigitalLibrary,
	title = {Stereotype and {Most}-{Popular} {Recommendations} in the {Digital} {Library} {Sowiport}},
	language = {en},
	author = {Beel, Joeran},
	pages = {13},
}

@inproceedings{ConnectionPopularityBiasCalibrationFairness,
	address = {Virtual Event Brazil},
	title = {The {Connection} {Between} {Popularity} {Bias}, {Calibration}, and {Fairness} in {Recommendation}},
	isbn = {978-1-4503-7583-2},
	url = {https://dl.acm.org/doi/10.1145/3383313.3418487},
	doi = {10.1145/3383313.3418487},
	abstract = {Recently there has been a growing interest in fairness-aware recommender systems including fairness in providing consistent performance across different users or groups of users. A recommender system could be considered unfair if the recommendations do not fairly represent the tastes of a certain group of users while other groups receive recommendations that are consistent with their preferences. In this paper, we use a metric called miscalibration for measuring how a recommendation algorithm is responsive to users’ true preferences and we consider how various algorithms may result in different degrees of miscalibration for different users. In particular, we conjecture that popularity bias which is a wellknown phenomenon in recommendation is one important factor leading to miscalibration in recommendation. Our experimental results using two real-world datasets show that there is a connection between how different user groups are affected by algorithmic popularity bias and their level of interest in popular items. Moreover, we show that the more a group is affected by the algorithmic popularity bias, the more their recommendations are miscalibrated.},
	language = {en},
	urldate = {2022-12-03},
	booktitle = {Fourteenth {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Abdollahpouri, Himan and Mansoury, Masoud and Burke, Robin and Mobasher, Bamshad},
	month = sep,
	year = {2020},
	keywords = {bias, miscalibration, popularity, rec},
	pages = {726--731},
}

@article{WhatDidMyAILearn,
	title = {What {Did} {My} {AI} {Learn}? {How} {Data} {Scientists} {Make} {Sense} of {Model} {Behavior}},
	issn = {1073-0516, 1557-7325},
	shorttitle = {What {Did} {My} {AI} {Learn}?},
	url = {https://dl.acm.org/doi/10.1145/3542921},
	doi = {10.1145/3542921},
	abstract = {Data scientists require rich mental models of how AI systems behave to effectively train, debug, and work with them. Despite the prevalence of AI analysis tools, there is no general theory describing how people make sense of what their models have learned. We frame this process as a form of sensemaking and derive a framework describing how data scientists develop mental models of AI behavior. To evaluate the framework, we show how existing AI analysis tools fit into this sensemaking process and use it to design AIFinnity, a system for analyzing image-and-text models. Lastly, we explored how data scientists use a tool developed with the framework through a think-aloud study with 10 data scientists tasked with using AIFinnity to pick an image captioning model. We found that AIFinnity’s sensemaking workflow reflected participants’ mental processes and enabled them to discover and validate diverse AI behaviors. CCS Concepts: • Human-centered computing → HCI theory, concepts and models; Visualization systems and tools; • Computing methodologies → Artificial intelligence; Computer vision.},
	language = {en},
	urldate = {2022-12-08},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Cabrera, Ángel Alexander and Ribeiro, Marco Tulio and Lee, Bongshin and DeLine, Rob and Perer, Adam and Drucker, Steven M.},
	month = jun,
	year = {2022},
	pages = {3542921},
}

@inproceedings{CalibrationUncertaintyNeuralLearningRank,
	address = {Online},
	title = {On the {Calibration} and {Uncertainty} of {Neural} {Learning} to {Rank} {Models} for {Conversational} {Search}},
	url = {https://aclanthology.org/2021.eacl-main.12},
	abstract = {According to the Probability Ranking Principle (PRP), ranking documents in decreasing order of their probability of relevance leads to an optimal document ranking for ad-hoc retrieval. The PRP holds when two conditions are met: [C1] the models are well calibrated, and, [C2] the probabilities of relevance are reported with certainty. We know however that deep neural networks (DNNs) are often not well calibrated and have several sources of uncertainty, and thus [C1] and [C2] might not be satisfied by neural rankers. Given the success of neural Learning to Rank (LTR) approaches—and here, especially BERT-based approaches—we first analyze under which circumstances deterministic neural rankers are calibrated for conversational search problems. Then, motivated by our findings we use two techniques to model the uncertainty of neural rankers leading to the proposed stochastic rankers, which output a predictive distribution of relevance as opposed to point estimates. Our experimental results on the ad-hoc retrieval task of conversation response ranking reveal that (i) BERT-based rankers are not robustly calibrated and that stochastic BERT-based rankers yield better calibration; and (ii) uncertainty estimation is beneficial for both risk-aware neural ranking, i.e. taking into account the uncertainty when ranking documents, and for predicting unanswerable conversational contexts.},
	urldate = {2021-08-01},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Penha, Gustavo and Hauff, Claudia},
	month = apr,
	year = {2021},
	pages = {160--170},
}

@book{SocialNavigationInformationSpacea,
	address = {London},
	series = {Computer {Supported} {Cooperative} {Work}},
	title = {Social {Navigation} of {Information} {Space}},
	isbn = {978-1-85233-090-3 978-1-4471-0837-5},
	url = {http://link.springer.com/10.1007/978-1-4471-0837-5},
	language = {en},
	urldate = {2021-07-02},
	publisher = {Springer London},
	editor = {Munro, Alan J. and Höök, Kristina and Benyon, David and Diaper, Dan and Sanger, Colston},
	year = {1999},
	doi = {10.1007/978-1-4471-0837-5},
	keywords = {comps-sc},
}

@inproceedings{ExplanationsMechanismsSupportingAlgorithmicTransparency,
	address = {Montreal QC Canada},
	title = {Explanations as {Mechanisms} for {Supporting} {Algorithmic} {Transparency}},
	isbn = {978-1-4503-5620-6},
	url = {https://dl.acm.org/doi/10.1145/3173574.3173677},
	doi = {10.1145/3173574.3173677},
	abstract = {Transparency can empower users to make informed choices about how they use an algorithmic decision-making system and judge its potential consequences. However, transparency is often conceptualized by the outcomes it is intended to bring about, not the speciﬁcs of mechanisms to achieve those outcomes. We conducted an online experiment focusing on how different ways of explaining Facebook’s News Feed algorithm might affect participants’ beliefs and judgments about the News Feed. We found that all explanations caused participants to become more aware of how the system works, and helped them to determine whether the system is biased and if they can control what they see. The explanations were less effective for helping participants evaluate the correctness of the system’s output, and form opinions about how sensible and consistent its behavior is. We present implications for the design of transparency mechanisms in algorithmic decision-making systems based on these results.},
	language = {en},
	urldate = {2021-08-08},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Rader, Emilee and Cotter, Kelley and Cho, Janghee},
	month = apr,
	year = {2018},
	pages = {1--13},
}

@inproceedings{FitsStartsEnterpriseUseAutoML,
	address = {Yokohama Japan},
	title = {Fits and {Starts}: {Enterprise} {Use} of {AutoML} and the {Role} of {Humans} in the {Loop}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Fits and {Starts}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445775},
	doi = {10.1145/3411764.3445775},
	abstract = {AutoML systems can speed up routine data science work and make machine learning available to those without expertise in statistics and computer science. These systems have gained traction in enterprise settings where pools of skilled data workers are limited. In this study, we conduct interviews with 29 individuals from organizations of different sizes to characterize how they currently use, or intend to use, AutoML systems in their data science work. Our investigation also captures how data visualization is used in conjunction with AutoML systems. Our findings identify three usage scenarios for AutoML that resulted in a framework summarizing the level of automation desired by data workers with different levels of expertise. We surfaced the tension between speed and human oversight and found that data visualization can do a poor job balancing the two. Our findings have implications for the design and implementation of human-in-the-loop visual analytics approaches.},
	language = {en},
	urldate = {2021-08-08},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Crisan, Anamaria and Fiore-Gartland, Brittany},
	month = may,
	year = {2021},
	pages = {1--15},
}

@article{humanAIrelationshipdecisionmaking,
	title = {The human-{AI} relationship in decision-making:},
	language = {en},
	author = {Ferreira, Juliana Jansen and Monteiro, Mateus},
	pages = {9},
}

@inproceedings{FaithfulCustomizableExplanationsBlackBox,
	address = {Honolulu HI USA},
	title = {Faithful and {Customizable} {Explanations} of {Black} {Box} {Models}},
	isbn = {978-1-4503-6324-2},
	url = {https://dl.acm.org/doi/10.1145/3306618.3314229},
	doi = {10.1145/3306618.3314229},
	abstract = {As predictive models increasingly assist human experts (e.g., doctors) in day-to-day decision making, it is crucial for experts to be able to explore and understand how such models behave in different feature subspaces in order to know if and when to trust them. To this end, we propose Model Understanding through Subspace Explanations (MUSE), a novel model agnostic framework which facilitates understanding of a given black box model by explaining how it behaves in subspaces characterized by certain features of interest. Our framework provides end users (e.g., doctors) with the flexibility of customizing the model explanations by allowing them to input the features of interest. The construction of explanations is guided by a novel objective function that we propose to simultaneously optimize for fidelity to the original model, unambiguity and interpretability of the explanation. More specifically, our objective allows us to learn, with optimality guarantees, a small number of compact decision sets each of which captures the behavior of a given black box model in unambiguous, well-defined regions of the feature space. Experimental evaluation with real-world datasets and user studies demonstrate that our approach can generate customizable, highly compact, easy-to-understand, yet accurate explanations of various kinds of predictive models compared to state-of-the-art baselines.},
	language = {en},
	urldate = {2021-08-04},
	booktitle = {Proceedings of the 2019 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
	month = jan,
	year = {2019},
	pages = {131--138},
}

@article{LEAFAGEExamplebasedFeatureimportancebasedExplanationsfor,
	title = {{LEAFAGE}: {Example}-based and {Feature} importance-based {Explanationsfor} {Black}-box {ML} models},
	shorttitle = {{LEAFAGE}},
	url = {http://arxiv.org/abs/1812.09044},
	abstract = {As machine learning models become more accurate, they typically become more complex and uninterpretable by humans. The black-box character of these models holds back its acceptance in practice, especially in high-risk domains where the consequences of failure could be catastrophic such as health-care or defense. Providing understandable and useful explanations behind ML models or predictions can increase the trust of the user. Example-based reasoning, which entails leveraging previous experience with analogous tasks to make a decision, is a well known strategy for problem solving and justification. This work presents a new explanation extraction method called LEAFAGE, for a prediction made by any black-box ML model. The explanation consists of the visualization of similar examples from the training set and the importance of each feature. Moreover, these explanations are contrastive which aims to take the expectations of the user into account. LEAFAGE is evaluated in terms of fidelity to the underlying black-box model and usefulness to the user. The results showed that LEAFAGE performs overall better than the current state-of-the-art method LIME in terms of fidelity, on ML models with non-linear decision boundary. A user-study was conducted which focused on revealing the differences between example-based and feature importance-based explanations. It showed that example-based explanations performed significantly better than feature importance-based explanation, in terms of perceived transparency, information sufficiency, competence and confidence. Counter-intuitively, when the gained knowledge of the participants was tested, it showed that they learned less about the black-box model after seeing a feature importance-based explanation than seeing no explanation at all. The participants found feature importance-based explanation vague and hard to generalize it to other instances.},
	urldate = {2021-08-04},
	journal = {arXiv:1812.09044 [cs]},
	author = {Adhikari, Ajaya and Tax, D. M. J. and Satta, Riccardo and Fath, Matthias},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.09044
version: 1},
	keywords = {explanation, xai},
}

@inproceedings{DefiningExplanationAIContexta,
	address = {Online},
	title = {Defining {Explanation} in an {AI} {Context}},
	url = {https://aclanthology.org/2020.blackboxnlp-1.29},
	doi = {10.18653/v1/2020.blackboxnlp-1.29},
	abstract = {With the increase in the use of AI systems, a need for explanation systems arises. Building an explanation system requires a definition of explanation. However, the natural language term explanation is difficult to define formally as it includes multiple perspectives from different domains such as psychology, philosophy, and cognitive sciences. We study multiple perspectives and aspects of explainability of recommendations or predictions made by AI systems, and provide a generic definition of explanation. The proposed definition is ambitious and challenging to apply. With the intention to bridge the gap between theory and application, we also propose a possible architecture of an automated explanation system based on our definition of explanation.},
	urldate = {2021-08-01},
	booktitle = {Proceedings of the {Third} {BlackboxNLP} {Workshop} on {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Verma, Tejaswani and Lingenfelder, Christoph and Klakow, Dietrich},
	month = nov,
	year = {2020},
	pages = {314--322},
}

@inproceedings{RationalizationNeuralMachineTranslationApproach,
	address = {New Orleans LA USA},
	title = {Rationalization: {A} {Neural} {Machine} {Translation} {Approach} to {Generating} {Natural} {Language} {Explanations}},
	isbn = {978-1-4503-6012-8},
	shorttitle = {Rationalization},
	url = {https://dl.acm.org/doi/10.1145/3278721.3278736},
	doi = {10.1145/3278721.3278736},
	abstract = {We introduce AI rationalization, an approach for generating explanations of autonomous system behavior as if a human had performed the behavior. We describe a rationalization technique that uses neural machine translation to translate internal state-action representations of an autonomous agent into natural language. We evaluate our technique in the Frogger game environment, training an autonomous game playing agent to rationalize its action choices using natural language. A natural language training corpus is collected from human players thinking out loud as they play the game. We motivate the use of rationalization as an approach to explanation generation and show the results of two experiments evaluating the effectiveness of rationalization. Results of these evaluations show that neural machine translation is able to accurately generate rationalizations that describe agent behavior, and that rationalizations are more satisfying to humans than other alternative methods of explanation.},
	language = {en},
	urldate = {2021-08-11},
	booktitle = {Proceedings of the 2018 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Ehsan, Upol and Harrison, Brent and Chan, Larry and Riedl, Mark O.},
	month = dec,
	year = {2018},
	keywords = {explanation, xai},
	pages = {81--87},
}

@article{RationalizationConcepts,
	title = {Rationalization through {Concepts}},
	url = {http://arxiv.org/abs/2105.04837},
	abstract = {Automated predictions require explanations to be interpretable by humans. One type of explanation is a rationale, i.e., a selection of input features such as relevant text snippets from which the model computes the outcome. However, a single overall selection does not provide a complete explanation, e.g., weighing several aspects for decisions. To this end, we present a novel self-interpretable model called ConRAT. Inspired by how human explanations for high-level decisions are often based on key concepts, ConRAT extracts a set of text snippets as concepts and infers which ones are described in the document. Then, it explains the outcome with a linear aggregation of concepts. Two regularizers drive ConRAT to build interpretable concepts. In addition, we propose two techniques to boost the rationale and predictive performance further. Experiments on both single- and multi-aspect sentiment classification tasks show that ConRAT is the first to generate concepts that align with human rationalization while using only the overall label. Further, it outperforms state-of-the-art methods trained on each aspect label independently.},
	urldate = {2021-08-11},
	journal = {arXiv:2105.04837 [cs]},
	author = {Antognini, Diego and Faltings, Boi},
	month = may,
	year = {2021},
	note = {arXiv: 2105.04837},
	keywords = {explanation, xai},
}

@inproceedings{TransparencyLanguageGenerationLevelsAutomation,
	address = {Bilbao Spain},
	title = {Transparency in {Language} {Generation}: {Levels} of {Automation}},
	isbn = {978-1-4503-7544-3},
	shorttitle = {Transparency in {Language} {Generation}},
	url = {https://dl.acm.org/doi/10.1145/3405755.3406136},
	doi = {10.1145/3405755.3406136},
	abstract = {Language models and conversational systems are growing increasingly advanced, creating outputs that may be mistaken for humans. Consumers may thus be misled by advertising, media reports, or vagueness regarding the role of automation in the production of language. We propose a taxonomy of language automation, based on the SAE levels of driving automation, to establish a shared set of terms for describing automated language. It is our hope that the proposed taxonomy can increase transparency in this rapidly advancing field.},
	language = {en},
	urldate = {2021-08-08},
	booktitle = {Proceedings of the 2nd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {ACM},
	author = {Edwards, Justin and Perrone, Allison and Doyle, Philip R.},
	month = jul,
	year = {2020},
	pages = {1--3},
}

@article{InterpretabilityMachineLearningModelsRepresentations,
	title = {Interpretability of {Machine} {Learning} {Models} and {Representations}: an {Introduction}},
	abstract = {Interpretability is often a major concern in machine learning. Although many authors agree with this statement, interpretability is often tackled with intuitive arguments, distinct (yet related) terms and heuristic quantiﬁcations. This short survey aims to clarify the concepts related to interpretability and emphasises the distinction between interpreting models and representations, as well as heuristic-based and user-based approaches.},
	language = {en},
	author = {Bibal, Adrien and Frénay, Benoît},
	pages = {7},
}

@article{ExplanationSciencea,
	title = {Explanation in {Science}},
	abstract = {Scientiﬁc explanation is an important goal of scientiﬁc practise. Philosophers have proposed a striking diversity of seemingly incompatible accounts of explanation, from deductive-nomological to statistical relevance, uniﬁcation, pragmatic, causalmechanical, mechanistic, causal intervention, asymptotic, and model-based accounts. In this dissertation I apply two novel methods to reexamine our evidence about scientiﬁc explanation in practise and thereby address the fragmentation of philosophical accounts. I start by collecting a data set of 781 articles from one year of the journal Science. Using automated text mining techniques I measure the frequency and distribution of several groups of philosophically interesting words, such as “explain”, “cause”, “evidence”, “theory”, “law”, “mechanism”, and “model”. I show that “explain” words are much more common in scientiﬁc writing than in other genres, occurring in roughly half of all articles, and that their use is very often qualiﬁed or negated. These results about the use of words complement traditional conceptual analysis. Next I use random samples from the data set to develop a large number of small case studies across a wide range of scientiﬁc disciplines. I use a sample of “explain” sentences to develop and defend a new general philosophical account of scientiﬁc explanation, and then test my account against a larger set of randomly sampled sentences and abstracts. Five coarse categories can classify the explanans and explananda of my cases: data, entities, kinds, models, and theories. The pair of the categories of the explanans and explanandum indicates the “form” of an explanation. The explain-relation supports counterfactual reasoning about the dependence of qualities of the explanandum on qualities of the explanans. But for each form there is a diﬀerent “core relation” between explanans and explanandum that supports the explain-relation. Causation, modelling, and argument are the core relations for diﬀerent forms of scientiﬁc explanation between diﬀerent categories of explanans and explananda. This ﬂexibility allows me to resolve some of the fragmentation in the philosophical literature. I provide empirical evidence to show that my general philosophical account successfully describes a wide range of scientiﬁc practise across a large number of scientiﬁc disciplines.},
	language = {en},
	author = {Overton, James A},
	pages = {288},
}

@inproceedings{ClusterbasedPredictionUserRatingsStylistic,
	address = {Gothenburg, Sweden},
	title = {Cluster-based {Prediction} of {User} {Ratings} for {Stylistic} {Surface} {Realisation}},
	url = {https://aclanthology.org/E14-1074},
	doi = {10.3115/v1/E14-1074},
	urldate = {2021-08-21},
	booktitle = {Proceedings of the 14th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Dethlefs, Nina and Cuayáhuitl, Heriberto and Hastie, Helen and Rieser, Verena and Lemon, Oliver},
	month = apr,
	year = {2014},
	keywords = {explanation, generation, xai},
	pages = {702--711},
}

@article{TheoryExplanationsHumanRobotCollaboration,
	title = {Towards a {Theory} of {Explanations} for {Human}–{Robot} {Collaboration}},
	volume = {33},
	issn = {0933-1875, 1610-1987},
	url = {http://link.springer.com/10.1007/s13218-019-00616-y},
	doi = {10.1007/s13218-019-00616-y},
	abstract = {This paper makes two contributions towards enabling a robot to provide explanatory descriptions of its decisions, the underlying knowledge and beliefs, and the experiences that informed these beliefs. First, we present a theory of explanations comprising (i) claims about representing, reasoning with, and learning domain knowledge to support the construction of explanations; (ii) three fundamental axes to characterize explanations; and (iii) a methodology for constructing these explanations. Second, we describe an architecture for robots that implements this theory and supports scalability to complex domains and explanations. We demonstrate the architecture’s capabilities in the context of a simulated robot (a) moving target objects to desired locations or people; or (b) following recipes to bake biscuits.},
	language = {en},
	number = {4},
	urldate = {2021-08-21},
	journal = {KI - Künstliche Intelligenz},
	author = {Sridharan, Mohan and Meadows, Ben},
	month = dec,
	year = {2019},
	keywords = {explanation, robot, xai},
	pages = {331--342},
}

@inproceedings{PersuasionGoodPersonalizedPersuasiveDialogue,
	address = {Florence, Italy},
	title = {Persuasion for {Good}: {Towards} a {Personalized} {Persuasive} {Dialogue} {System} for {Social} {Good}},
	shorttitle = {Persuasion for {Good}},
	url = {https://aclanthology.org/P19-1566},
	doi = {10.18653/v1/P19-1566},
	abstract = {Developing intelligent persuasive conversational agents to change people's opinions and actions for social good is the frontier in advancing the ethical development of automated dialogue systems. To do so, the first step is to understand the intricate organization of strategic disclosures and appeals employed in human persuasion conversations. We designed an online persuasion task where one participant was asked to persuade the other to donate to a specific charity. We collected a large dataset with 1,017 dialogues and annotated emerging persuasion strategies from a subset. Based on the annotation, we built a baseline classifier with context information and sentence-level features to predict the 10 persuasion strategies used in the corpus. Furthermore, to develop an understanding of personalized persuasion processes, we analyzed the relationships between individuals' demographic and psychological backgrounds including personality, morality, value systems, and their willingness for donation. Then, we analyzed which types of persuasion strategies led to a greater amount of donation depending on the individuals' personal backgrounds. This work lays the ground for developing a personalized persuasive dialogue system.},
	urldate = {2021-08-17},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Xuewei and Shi, Weiyan and Kim, Richard and Oh, Yoojung and Yang, Sijia and Zhang, Jingwen and Yu, Zhou},
	month = jul,
	year = {2019},
	keywords = {explanation, xai},
	pages = {5635--5649},
}

@article{ImprovingVisualizationInterpretationUsingCounterfactualsa,
	title = {Improving {Visualization} {Interpretation} {Using} {Counterfactuals}},
	url = {http://arxiv.org/abs/2107.10309},
	abstract = {Complex, high-dimensional data is used in a wide range of domains to explore problems and make decisions. Analysis of high-dimensional data, however, is vulnerable to the hidden influence of confounding variables, especially as users apply ad hoc filtering operations to visualize only specific subsets of an entire dataset. Thus, visual data-driven analysis can mislead users and encourage mistaken assumptions about causality or the strength of relationships between features. This work introduces a novel visual approach designed to reveal the presence of confounding variables via counterfactual possibilities during visual data analysis. It is implemented in CoFact, an interactive visualization prototype that determines and visualizes {\textbackslash}textit\{counterfactual subsets\} to better support user exploration of feature relationships. Using publicly available datasets, we conducted a controlled user study to demonstrate the effectiveness of our approach; the results indicate that users exposed to counterfactual visualizations formed more careful judgments about feature-to-outcome relationships.},
	urldate = {2021-08-15},
	journal = {arXiv:2107.10309 [cs]},
	author = {Kaul, Smiti and Borland, David and Cao, Nan and Gotz, David},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.10309},
	keywords = {explanation, vis, xai},
}

@inproceedings{FairnessAccountabilityDesignNeedsAlgorithmica,
	address = {Montreal QC Canada},
	title = {Fairness and {Accountability} {Design} {Needs} for {Algorithmic} {Support} in {High}-{Stakes} {Public} {Sector} {Decision}-{Making}},
	isbn = {978-1-4503-5620-6},
	url = {https://dl.acm.org/doi/10.1145/3173574.3174014},
	doi = {10.1145/3173574.3174014},
	abstract = {Calls for heightened consideration of fairness and accountability in algorithmically-informed public decisions—like taxation, justice, and child protection—are now commonplace. How might designers support such human values? We interviewed 27 public sector machine learning practitioners across 5 OECD countries regarding challenges understanding and imbuing public values into their work. The results suggest a disconnect between organisational and institutional realities, constraints and needs, and those addressed by current research into usable, transparent and ‘discrimination-aware’ machine learning—absences likely to undermine practical initiatives unless addressed. We see design opportunities in this disconnect, such as in supporting the tracking of concept drift in secondary data sources, and in building usable transparency tools to identify risks and incorporate domain knowledge, aimed both at managers and at the ‘street-level bureaucrats’ on the frontlines of public service. We conclude by outlining ethical challenges and future directions for collaboration in these high-stakes applications.},
	language = {en},
	urldate = {2021-08-24},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Veale, Michael and Van Kleek, Max and Binns, Reuben},
	month = apr,
	year = {2018},
	keywords = {well-written},
	pages = {1--14},
}

@article{HighStakesDecisionMakingNormative,
	title = {High {Stakes} {Decision} {Making}: {Normative}, {Descriptive} and {Prescriptive} {Considerations}},
	volume = {13},
	issn = {0923-0645, 1573-059X},
	shorttitle = {High {Stakes} {Decision} {Making}},
	url = {http://link.springer.com/10.1023/A:1020287225409},
	doi = {10.1023/A:1020287225409},
	abstract = {This paper reviews the state of the art of research on individual decision-making in high-stakes, lowprobability settings. A central theme of the discussion is that optimally resolving high-stakes decisions poses a formidable challenge not only to naïve decision makers, but also to users of more sophisticated tools such as decision analysis.. Such problems are difficult to resolve because precise information about probabilities is not available, and the dynamics of the decision are complex. When faced with such problems, naïve decision-makers fall prey to a wide range of potentially harmful biases, such as not recognizing a high-stakes problem, ignoring the information about probabilities that does exist, and responding to complexity by accepting the status quo. We offer an agenda for future research focusing on how the process and outcomes of high-stakes decision making might be improved.},
	language = {en},
	number = {3},
	urldate = {2021-08-24},
	journal = {Marketing Letters},
	author = {Kunreuther, Howard and Meyer, Robert and Zeckhauser, Richard and Slovic, Paul and Schwartz, Barry and Schade, Christian and Luce, Mary Frances and Lippman, Steven and Krantz, David and Kahn, Barbara and Hogarth, Robin},
	month = aug,
	year = {2002},
	pages = {259--268},
}

@inproceedings{humanbodyblackboxsupporting,
	address = {Barcelona Spain},
	title = {"{The} human body is a black box": supporting clinical decision-making with deep learning},
	isbn = {978-1-4503-6936-7},
	shorttitle = {"{The} human body is a black box"},
	url = {https://dl.acm.org/doi/10.1145/3351095.3372827},
	doi = {10.1145/3351095.3372827},
	language = {en},
	urldate = {2021-08-24},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Sendak, Mark and Elish, Madeleine Clare and Gao, Michael and Futoma, Joseph and Ratliff, William and Nichols, Marshall and Bedoya, Armando and Balu, Suresh and O'Brien, Cara},
	month = jan,
	year = {2020},
	pages = {99--109},
}

@article{Howavoidmachinelearningpitfallsa,
	title = {How to avoid machine learning pitfalls: a guide for academic researchers},
	shorttitle = {How to avoid machine learning pitfalls},
	url = {http://arxiv.org/abs/2108.02497},
	abstract = {This document gives a concise outline of some of the common mistakes that occur when using machine learning techniques, and what can be done to avoid them. It is intended primarily as a guide for research students, and focuses on issues that are of particular concern within academic research, such as the need to do rigorous comparisons and reach valid conclusions. It covers five stages of the machine learning process: what to do before model building, how to reliably build models, how to robustly evaluate models, how to compare models fairly, and how to report results.},
	urldate = {2021-08-24},
	journal = {arXiv:2108.02497 [cs]},
	author = {Lones, Michael A.},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.02497},
	keywords = {general, ml},
}

@inproceedings{FairnessAccountabilityDesignNeedsAlgorithmic,
	address = {Montreal QC Canada},
	title = {Fairness and {Accountability} {Design} {Needs} for {Algorithmic} {Support} in {High}-{Stakes} {Public} {Sector} {Decision}-{Making}},
	isbn = {978-1-4503-5620-6},
	url = {https://dl.acm.org/doi/10.1145/3173574.3174014},
	doi = {10.1145/3173574.3174014},
	abstract = {Calls for heightened consideration of fairness and accountability in algorithmically-informed public decisions—like taxation, justice, and child protection—are now commonplace. How might designers support such human values? We interviewed 27 public sector machine learning practitioners across 5 OECD countries regarding challenges understanding and imbuing public values into their work. The results suggest a disconnect between organisational and institutional realities, constraints and needs, and those addressed by current research into usable, transparent and ‘discrimination-aware’ machine learning—absences likely to undermine practical initiatives unless addressed. We see design opportunities in this disconnect, such as in supporting the tracking of concept drift in secondary data sources, and in building usable transparency tools to identify risks and incorporate domain knowledge, aimed both at managers and at the ‘street-level bureaucrats’ on the frontlines of public service. We conclude by outlining ethical challenges and future directions for collaboration in these high-stakes applications.},
	language = {en},
	urldate = {2021-08-29},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Veale, Michael and Van Kleek, Max and Binns, Reuben},
	month = apr,
	year = {2018},
	keywords = {fair, xai},
	pages = {1--14},
}

@article{PosthocInterpretabilityNeuralNLPSurveya,
	title = {Post-hoc {Interpretability} for {Neural} {NLP}: {A} {Survey}},
	shorttitle = {Post-hoc {Interpretability} for {Neural} {NLP}},
	url = {http://arxiv.org/abs/2108.04840},
	abstract = {Natural Language Processing (NLP) models have become increasingly more complex and widespread. With recent developments in neural networks, a growing concern is whether it is responsible to use these models. Concerns such as safety and ethics can be partially addressed by providing explanations. Furthermore, when models do fail, providing explanations is paramount for accountability purposes. To this end, interpretability serves to provide these explanations in terms that are understandable to humans. Central to what is understandable is how explanations are communicated. Therefore, this survey provides a categorization of how recent interpretability methods communicate explanations and discusses the methods in depth. Furthermore, the survey focuses on post-hoc methods, which provide explanations after a model is learned and generally model-agnostic. A common concern for this class of methods is whether they accurately reflect the model. Hence, how these post-hoc methods are evaluated is discussed throughout the paper.},
	urldate = {2021-08-28},
	journal = {arXiv:2108.04840 [cs]},
	author = {Madsen, Andreas and Reddy, Siva and Chandar, Sarath},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.04840},
	keywords = {nlp, xai},
}

@incollection{TextualExplanationsSelfDrivingVehiclesa,
	address = {Cham},
	title = {Textual {Explanations} for {Self}-{Driving} {Vehicles}},
	volume = {11206},
	isbn = {978-3-030-01215-1 978-3-030-01216-8},
	url = {http://link.springer.com/10.1007/978-3-030-01216-8_35},
	language = {en},
	urldate = {2021-08-25},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Kim, Jinkyu and Rohrbach, Anna and Darrell, Trevor and Canny, John and Akata, Zeynep},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	doi = {10.1007/978-3-030-01216-8_35},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {explanation, xai},
	pages = {577--593},
}

@book{HumanLikeMachineIntelligence,
	edition = {1},
	title = {Human-{Like} {Machine} {Intelligence}},
	isbn = {978-0-19-886253-6 978-0-19-189533-3},
	url = {https://oxford.universitypressscholarship.com/view/10.1093/oso/9780198862536.001.0001/oso-9780198862536},
	abstract = {In recent years there has been increasing excitement concerning the potential of Artificial Intelligence to transform human society. This book addresses the leading edge of research in this area. The research described aims to address present incompatibilities of Human and Machine reasoning and learning approaches. According to the influential US funding agency DARPA (originator of the Internet and Self-Driving Cars) this new area represents the Third Wave of Artificial Intelligence (3AI, 2020s–2030s), and is being actively investigated in the US, Europe and China. The EPSRC’s UK network on
              Human-Like Computing
              (HLC) was one of the first internationally to initiate and support research specifically in this area. Starting activities in 2018, the network represents around sixty leading UK groups Artificial Intelligence and Cognitive Scientists involved in the development of the inter-disciplinary area of HLC. The research of network groups aims to address key unsolved problems at the interface between Psychology and Computer Science. The chapters of this book have been authored by a mixture of these UK and other international specialists based on recent workshops and discussions at the Machine Intelligence 20 and 21 workshops (2016,2019) and the Third Wave Artificial Intelligence workshop (2019). Some of the key questions addressed by the Human-Like Computing programme include how AI systems might 1) explain their decisions effectively, 2) interact with human beings in natural language, 3) learn from small numbers of examples and 4) learn with minimal supervision. Solving such fundamental problems involves new foundational research in both the Psychology of perception and interaction as well as the development of novel algorithmic approaches in Artificial Intelligence.},
	language = {en},
	urldate = {2021-08-24},
	publisher = {Oxford University Press},
	editor = {Muggleton, Stephen and Chater, Nicholas},
	month = jul,
	year = {2021},
	doi = {10.1093/oso/9780198862536.001.0001},
}

@article{ImpactsTimePressureEmotionInformation,
	title = {The {Impacts} of {Time} {Pressure} and {Emotion} on the {Information} {Behavior} of {High} {Stakes}},
	language = {en},
	author = {Landry, Carol F},
	pages = {258},
}

@article{FOCUSFlexibleOptimizableCounterfactualExplanations,
	title = {{FOCUS}: {Flexible} {Optimizable} {Counterfactual} {Explanations} for {Tree} {Ensembles}},
	shorttitle = {{FOCUS}},
	url = {http://arxiv.org/abs/1911.12199},
	abstract = {Counterfactual explanations help users understand why machine learned models make certain decisions, and more speciﬁcally, how these decisions can be changed. In this work, we frame the problem of ﬁnding counterfactual explanations – the minimal perturbation to an input such that the prediction changes – as an optimization task. Previously, optimization techniques for generating counterfactual examples could only be applied to differentiable models, or alternatively via query access to the model by estimating gradients from randomly sampled perturbations. In order to accommodate non-differentiable models such as tree ensembles, we propose using probabilistic model approximations in the optimization framework. We introduce a novel approximation technique that is effective for ﬁnding counterfactual explanations while also closely approximating the original model. Our results show that our method is able to produce counterfactual examples that are closer to the original instance in terms of Euclidean, Cosine, and Manhattan distance compared to other methods speciﬁcally designed for tree ensembles.},
	language = {en},
	urldate = {2021-09-01},
	journal = {arXiv:1911.12199 [cs]},
	author = {Lucic, Ana and Oosterhuis, Harrie and Haned, Hinda and de Rijke, Maarten},
	month = oct,
	year = {2020},
	note = {arXiv: 1911.12199},
}

@article{VBridgeConnectingDotsFeaturesExplanations,
	title = {{VBridge}: {Connecting} the {Dots} {Between} {Features}, {Explanations}, and {Data} for {Healthcare} {Models}},
	shorttitle = {{VBridge}},
	url = {http://arxiv.org/abs/2108.02550},
	abstract = {Machine learning (ML) is increasingly applied to Electronic Health Records (EHRs) to solve clinical prediction tasks. Although many ML models perform promisingly, issues with model transparency and interpretability limit their adoption in clinical practice. Directly using existing explainable ML techniques in clinical settings can be challenging. Through literature surveys and collaborations with six clinicians with an average of 17 years of clinical experience, we identified three key challenges, including clinicians' unfamiliarity with ML features, lack of contextual information, and the need for cohort-level evidence. Following an iterative design process, we further designed and developed VBridge, a visual analytics tool that seamlessly incorporates ML explanations into clinicians' decision-making workflow. The system includes a novel hierarchical display of contribution-based feature explanations and enriched interactions that connect the dots between ML features, explanations, and data. We demonstrated the effectiveness of VBridge through two case studies and expert interviews with four clinicians, showing that visually associating model explanations with patients' situational records can help clinicians better interpret and use model predictions when making clinician decisions. We further derived a list of design implications for developing future explainable ML tools to support clinical decision-making.},
	urldate = {2021-08-31},
	journal = {arXiv:2108.02550 [cs]},
	author = {Cheng, Furui and Liu, Dongyu and Du, Fan and Lin, Yanna and Zytek, Alexandra and Li, Haomin and Qu, Huamin and Veeramachaneni, Kalyan},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.02550},
	keywords = {explanation, vis, xai},
}

@article{ImprovingVisualizationInterpretationUsingCounterfactuals,
	title = {Improving {Visualization} {Interpretation} {Using} {Counterfactuals}},
	url = {http://arxiv.org/abs/2107.10309},
	abstract = {Complex, high-dimensional data is used in a wide range of domains to explore problems and make decisions. Analysis of high-dimensional data, however, is vulnerable to the hidden influence of confounding variables, especially as users apply ad hoc filtering operations to visualize only specific subsets of an entire dataset. Thus, visual data-driven analysis can mislead users and encourage mistaken assumptions about causality or the strength of relationships between features. This work introduces a novel visual approach designed to reveal the presence of confounding variables via counterfactual possibilities during visual data analysis. It is implemented in CoFact, an interactive visualization prototype that determines and visualizes {\textbackslash}textit\{counterfactual subsets\} to better support user exploration of feature relationships. Using publicly available datasets, we conducted a controlled user study to demonstrate the effectiveness of our approach; the results indicate that users exposed to counterfactual visualizations formed more careful judgments about feature-to-outcome relationships.},
	urldate = {2021-08-31},
	journal = {arXiv:2107.10309 [cs]},
	author = {Kaul, Smiti and Borland, David and Cao, Nan and Gotz, David},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.10309},
	keywords = {counterfactual, vis, xai},
}

@inproceedings{DefiningExplanationAIContext,
	address = {Online},
	title = {Defining {Explanation} in an {AI} {Context}},
	url = {https://aclanthology.org/2020.blackboxnlp-1.29},
	doi = {10.18653/v1/2020.blackboxnlp-1.29},
	abstract = {With the increase in the use of AI systems, a need for explanation systems arises. Building an explanation system requires a definition of explanation. However, the natural language term explanation is difficult to define formally as it includes multiple perspectives from different domains such as psychology, philosophy, and cognitive sciences. We study multiple perspectives and aspects of explainability of recommendations or predictions made by AI systems, and provide a generic definition of explanation. The proposed definition is ambitious and challenging to apply. With the intention to bridge the gap between theory and application, we also propose a possible architecture of an automated explanation system based on our definition of explanation.},
	urldate = {2021-08-30},
	booktitle = {Proceedings of the {Third} {BlackboxNLP} {Workshop} on {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Verma, Tejaswani and Lingenfelder, Christoph and Klakow, Dietrich},
	month = nov,
	year = {2020},
	keywords = {explanation, xai},
	pages = {314--322},
}

@article{ExplainableMachineLearningPriorKnowledge,
	title = {Explainable {Machine} {Learning} with {Prior} {Knowledge}: {An} {Overview}},
	shorttitle = {Explainable {Machine} {Learning} with {Prior} {Knowledge}},
	url = {http://arxiv.org/abs/2105.10172},
	abstract = {This survey presents an overview of integrating prior knowledge into machine learning systems in order to improve explainability. The complexity of machine learning models has elicited research to make them more explainable. However, most explainability methods cannot provide insight beyond the given data, requiring additional information about the context. We propose to harness prior knowledge to improve upon the explanation capabilities of machine learning models. In this paper, we present a categorization of current research into three main categories which either integrate knowledge into the machine learning pipeline, into the explainability method or derive knowledge from explanations. To classify the papers, we build upon the existing taxonomy of informed machine learning and extend it from the perspective of explainability. We conclude with open challenges and research directions.},
	urldate = {2021-09-02},
	journal = {arXiv:2105.10172 [cs]},
	author = {Beckh, Katharina and Müller, Sebastian and Jakobs, Matthias and Toborek, Vanessa and Tan, Hanxiao and Fischer, Raphael and Welke, Pascal and Houben, Sebastian and von Rueden, Laura},
	month = may,
	year = {2021},
	note = {arXiv: 2105.10172},
	keywords = {explanation, xai},
}

@article{TeachMeExplainReviewDatasets,
	title = {Teach {Me} to {Explain}: {A} {Review} of {Datasets} for {Explainable} {NLP}},
	shorttitle = {Teach {Me} to {Explain}},
	url = {http://arxiv.org/abs/2102.12060},
	abstract = {Explainable NLP (ExNLP) has increasingly focused on collecting human-annotated explanations. These explanations are used downstream in three ways: as data augmentation to improve performance on a predictive task, as a loss signal to train models to produce explanations for their predictions, and as a means to evaluate the quality of model-generated explanations. In this review, we identify three predominant classes of explanations (highlights, free-text, and structured), organize the literature on annotating each type, point to what has been learned to date, and give recommendations for collecting ExNLP datasets in the future.},
	urldate = {2021-09-02},
	journal = {arXiv:2102.12060 [cs]},
	author = {Wiegreffe, Sarah and Marasović, Ana},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.12060},
	keywords = {explanation, generation, xai},
}

@article{FACEFeasibleActionableCounterfactualExplanations,
	title = {{FACE}: {Feasible} and {Actionable} {Counterfactual} {Explanations}},
	shorttitle = {{FACE}},
	url = {http://arxiv.org/abs/1909.09369},
	doi = {10.1145/3375627.3375850},
	abstract = {Work in Counterfactual Explanations tends to focus on the principle of "the closest possible world" that identifies small changes leading to the desired outcome. In this paper we argue that while this approach might initially seem intuitively appealing it exhibits shortcomings not addressed in the current literature. First, a counterfactual example generated by the state-of-the-art systems is not necessarily representative of the underlying data distribution, and may therefore prescribe unachievable goals(e.g., an unsuccessful life insurance applicant with severe disability may be advised to do more sports). Secondly, the counterfactuals may not be based on a "feasible path" between the current state of the subject and the suggested one, making actionable recourse infeasible (e.g., low-skilled unsuccessful mortgage applicants may be told to double their salary, which may be hard without first increasing their skill level). These two shortcomings may render counterfactual explanations impractical and sometimes outright offensive. To address these two major flaws, first of all, we propose a new line of Counterfactual Explanations research aimed at providing actionable and feasible paths to transform a selected instance into one that meets a certain goal. Secondly, we propose FACE: an algorithmically sound way of uncovering these "feasible paths" based on the shortest path distances defined via density-weighted metrics. Our approach generates counterfactuals that are coherent with the underlying data distribution and supported by the "feasible paths" of change, which are achievable and can be tailored to the problem at hand.},
	urldate = {2021-09-01},
	journal = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
	author = {Poyiadzi, Rafael and Sokol, Kacper and Santos-Rodriguez, Raul and De Bie, Tijl and Flach, Peter},
	month = feb,
	year = {2020},
	note = {arXiv: 1909.09369},
	keywords = {explanation, xai},
	pages = {344--350},
}

@article{ActionableInterpretabilityOptimizableCounterfactualExplanations,
	title = {Actionable {Interpretability} through {Optimizable} {Counterfactual} {Explanations} for {Tree} {Ensembles}},
	shorttitle = {{FOCUS}},
	url = {http://arxiv.org/abs/1911.12199},
	abstract = {Counterfactual explanations help users understand why machine learned models make certain decisions, and more speciﬁcally, how these decisions can be changed. In this work, we frame the problem of ﬁnding counterfactual explanations – the minimal perturbation to an input such that the prediction changes – as an optimization task. Previously, optimization techniques for generating counterfactual examples could only be applied to differentiable models, or alternatively via query access to the model by estimating gradients from randomly sampled perturbations. In order to accommodate non-differentiable models such as tree ensembles, we propose using probabilistic model approximations in the optimization framework. We introduce a novel approximation technique that is effective for ﬁnding counterfactual explanations while also closely approximating the original model. Our results show that our method is able to produce counterfactual examples that are closer to the original instance in terms of Euclidean, Cosine, and Manhattan distance compared to other methods speciﬁcally designed for tree ensembles.},
	language = {en},
	urldate = {2021-09-01},
	journal = {arXiv:1911.12199 [cs]},
	author = {Lucic, Ana and Oosterhuis, Harrie and Haned, Hinda and de Rijke, Maarten},
	month = oct,
	year = {2020},
	note = {arXiv: 1911.12199},
}

@misc{Levelsexplainableartificialintelligencehumanaligned,
	title = {Levels of explainable artificial intelligence for human-aligned conversational explanations {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S000437022100076X?token=46A856152FEA5B4EAEC05B1659E0C32DC537AEDCF82FAD5337757089E35031203C287BEE7697766DBD0356BED2AEA349&originRegion=us-east-1&originCreation=20210904190315},
	language = {en},
	urldate = {2021-09-04},
	doi = {10.1016/j.artint.2021.103525},
}

@article{SocietalBiasesLanguageGenerationProgress,
	title = {Societal {Biases} in {Language} {Generation}: {Progress} and {Challenges}},
	shorttitle = {Societal {Biases} in {Language} {Generation}},
	url = {http://arxiv.org/abs/2105.04054},
	abstract = {Technology for language generation has advanced rapidly, spurred by advancements in pre-training large models on massive amounts of data and the need for intelligent agents to communicate in a natural manner. While techniques can effectively generate fluent text, they can also produce undesirable societal biases that can have a disproportionately negative impact on marginalized populations. Language generation presents unique challenges for biases in terms of direct user interaction and the structure of decoding techniques. To better understand these challenges, we present a survey on societal biases in language generation, focusing on how data and techniques contribute to biases and progress towards reducing biases. Motivated by a lack of studies on biases from decoding techniques, we also conduct experiments to quantify the effects of these techniques. By further discussing general trends and open challenges, we call to attention promising directions for research and the importance of fairness and inclusivity considerations for language generation applications.},
	urldate = {2021-09-04},
	journal = {arXiv:2105.04054 [cs]},
	author = {Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
	month = jun,
	year = {2021},
	note = {arXiv: 2105.04054},
	keywords = {fair, nlp, xai},
}

@article{GLUCOSEGeneraLizedCOntextualizedStoryExplanations,
	title = {{GLUCOSE}: {GeneraLized} and {COntextualized} {Story} {Explanations}},
	shorttitle = {{GLUCOSE}},
	url = {http://arxiv.org/abs/2009.07758},
	abstract = {When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal mini-theories about the world, each grounded in a narrative context. To construct GLUCOSE, we drew on cognitive psychology to identify ten dimensions of causal explanation, focusing on events, states, motivations, and emotions. Each GLUCOSE entry includes a story-specific causal statement paired with an inference rule generalized from the statement. This paper details two concrete contributions. First, we present our platform for effectively crowdsourcing GLUCOSE data at scale, which uses semi-structured templates to elicit causal explanations. Using this platform, we collected a total of {\textasciitilde}670K specific statements and general rules that capture implicit commonsense knowledge about everyday situations. Second, we show that existing knowledge resources and pretrained language models do not include or readily predict GLUCOSE's rich inferential content. However, when state-of-the-art neural models are trained on this knowledge, they can start to make commonsense inferences on unseen stories that match humans' mental models.},
	urldate = {2021-09-04},
	journal = {arXiv:2009.07758 [cs]},
	author = {Mostafazadeh, Nasrin and Kalyanpur, Aditya and Moon, Lori and Buchanan, David and Berkowitz, Lauren and Biran, Or and Chu-Carroll, Jennifer},
	month = oct,
	year = {2020},
	note = {arXiv: 2009.07758},
	keywords = {explanation, generation, xai},
}

@article{AligningFaithfulInterpretationstheirSocial,
	title = {Aligning {Faithful} {Interpretations} with their {Social} {Attribution}},
	volume = {9},
	issn = {2307-387X},
	url = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00367/98620/Aligning-Faithful-Interpretations-with-their},
	doi = {10.1162/tacl_a_00367},
	abstract = {We find that the requirement of model interpretations to be faithful is vague and incomplete. With interpretation by textual highlights as a case study, we present several failure cases. Borrowing concepts from social science, we identify that the problem is a misalignment between the causal chain of decisions (causal attribution) and the attribution of human behavior to the interpretation (social attribution). We reformulate faithfulness as an accurate attribution of causality to the model, and introduce the concept of aligned faithfulness: faithful causal chains that are aligned with their expected social behavior. The two steps of causal attribution and social attribution together complete the process of explaining behavior. With this formalization, we characterize various failures of misaligned faithful highlight interpretations, and propose an alternative causal chain to remedy the issues. Finally, we implement highlight explanations of the proposed causal format using contrastive explanations.},
	language = {en},
	urldate = {2021-09-04},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Jacovi, Alon and Goldberg, Yoav},
	month = mar,
	year = {2021},
	keywords = {contrative, explanation, generation, xai},
	pages = {294--310},
}

@article{ExplainingNLPModelsMinimalContrastive,
	title = {Explaining {NLP} {Models} via {Minimal} {Contrastive} {Editing} ({MiCE})},
	url = {http://arxiv.org/abs/2012.13985},
	abstract = {Humans have been shown to give contrastive explanations, which explain why an observed event happened rather than some other counterfactual event (the contrast case). Despite the influential role that contrastivity plays in how humans explain, this property is largely missing from current methods for explaining NLP models. We present Minimal Contrastive Editing (MiCE), a method for producing contrastive explanations of model predictions in the form of edits to inputs that change model outputs to the contrast case. Our experiments across three tasks--binary sentiment classification, topic classification, and multiple-choice question answering--show that MiCE is able to produce edits that are not only contrastive, but also minimal and fluent, consistent with human contrastive edits. We demonstrate how MiCE edits can be used for two use cases in NLP system development--debugging incorrect model outputs and uncovering dataset artifacts--and thereby illustrate that producing contrastive explanations is a promising research direction for model interpretability.},
	urldate = {2021-09-04},
	journal = {arXiv:2012.13985 [cs]},
	author = {Ross, Alexis and Marasović, Ana and Peters, Matthew E.},
	month = jun,
	year = {2021},
	note = {arXiv: 2012.13985},
	keywords = {explanation, generation, nlp, xai},
}

@inproceedings{OntologyDesignPatternDefineExplanations,
	address = {Palisades NY USA},
	title = {An {Ontology} {Design} {Pattern} to {Define} {Explanations}},
	isbn = {978-1-4503-3849-3},
	url = {https://dl.acm.org/doi/10.1145/2815833.2815844},
	doi = {10.1145/2815833.2815844},
	abstract = {In this paper, we propose an ontology design pattern for the concept of “explanation”. The motivation behind this work comes from our research, which focuses on automatically identifying explanations for data patterns. If we want to produce explanations from data agnostically from the application domain, we ﬁrst need a formal deﬁnition of what an explanation is, i.e. which are its components, their roles or their interactions. We analysed and surveyed works from the disciplines grouped under the name of Cognitive Sciences, with the aim of identifying diﬀerences and commonalities in the way their researchers intend the concept of explanation. We then produced not only an ontology design pattern to model it, but also the instantiations of this in each of the analysed disciplines. Besides those contributions, the paper presents how the proposed ontology design pattern can be used to analyse the validity of the explanations produced by our, and other, frameworks.},
	language = {en},
	urldate = {2021-09-03},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Knowledge} {Capture}},
	publisher = {ACM},
	author = {Tiddi, Ilaria and d'Aquin, Mathieu and Motta, Enrico},
	month = oct,
	year = {2015},
	keywords = {explanation, xai},
	pages = {1--8},
}

@article{LearningFaithfullyRationalizeConstruction,
	title = {Learning to {Faithfully} {Rationalize} by {Construction}},
	url = {http://arxiv.org/abs/2005.00115},
	abstract = {In many settings it is important for one to be able to understand why a model made a particular prediction. In NLP this often entails extracting snippets of an input text `responsible for' corresponding model output; when such a snippet comprises tokens that indeed informed the model's prediction, it is a faithful explanation. In some settings, faithfulness may be critical to ensure transparency. Lei et al. (2016) proposed a model to produce faithful rationales for neural text classification by defining independent snippet extraction and prediction modules. However, the discrete selection over input tokens performed by this method complicates training, leading to high variance and requiring careful hyperparameter tuning. We propose a simpler variant of this approach that provides faithful explanations by construction. In our scheme, named FRESH, arbitrary feature importance scores (e.g., gradients from a trained model) are used to induce binary labels over token inputs, which an extractor can be trained to predict. An independent classifier module is then trained exclusively on snippets provided by the extractor; these snippets thus constitute faithful explanations, even if the classifier is arbitrarily complex. In both automatic and manual evaluations we find that variants of this simple framework yield predictive performance superior to `end-to-end' approaches, while being more general and easier to train. Code is available at https://github.com/successar/FRESH},
	urldate = {2021-09-04},
	journal = {arXiv:2005.00115 [cs]},
	author = {Jain, Sarthak and Wiegreffe, Sarah and Pinter, Yuval and Wallace, Byron C.},
	month = apr,
	year = {2020},
	note = {arXiv: 2005.00115},
}

@article{HumanintheloopExtractionInterpretableConceptsDeepa,
	title = {Human-in-the-loop {Extraction} of {Interpretable} {Concepts} in {Deep} {Learning} {Models}},
	url = {http://arxiv.org/abs/2108.03738},
	abstract = {The interpretation of deep neural networks (DNNs) has become a key topic as more and more people apply them to solve various problems and making critical decisions. Concept-based explanations have recently become a popular approach for post-hoc interpretation of DNNs. However, identifying human-understandable visual concepts that affect model decisions is a challenging task that is not easily addressed with automatic approaches. We present a novel human-in-the-loop approach to generate user-defined concepts for model interpretation and diagnostics. Central to our proposal is the use of active learning, where human knowledge and feedback are combined to train a concept extractor with very little human labeling effort. We integrate this process into an interactive system, ConceptExtract. Through two case studies, we show how our approach helps analyze model behavior and extract human-friendly concepts for different machine learning tasks and datasets and how to use these concepts to understand the predictions, compare model performance and make suggestions for model refinement. Quantitative experiments show that our active learning approach can accurately extract meaningful visual concepts. More importantly, by identifying visual concepts that negatively affect model performance, we develop the corresponding data augmentation strategy that consistently improves model performance.},
	urldate = {2021-09-07},
	journal = {arXiv:2108.03738 [cs]},
	author = {Zhao, Zhenge and Xu, Panpan and Scheidegger, Carlos and Ren, Liu},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.03738},
}

@article{TrustingXAIEffectsdifferenttypes,
	title = {Trusting the {X} in {XAI}: {Effects} of different types of explanations by a self-driving car on trust, explanation satisfaction and mental models},
	volume = {64},
	issn = {2169-5067, 1071-1813},
	shorttitle = {Trusting the {X} in {XAI}},
	url = {http://journals.sagepub.com/doi/10.1177/1071181320641077},
	doi = {10.1177/1071181320641077},
	abstract = {There is an increasing demand for opaque intelligent systems to explain themselves to humans, in order to increase user trust and the formation of adequate mental models. Previous research has shown effects of different types of explanations on user preferences and performance. However, this research has not addressed the differential effects of intentional and causal explanations on both users’ trust and mental models, nor has it employed multiple trust measurement scales at multiple points in time. In the current research, the effects of three types of explanations (causal, intentional, mixed) on trust development, mental models, and user satisfaction were investigated in the context of a self-driving car. Results showed that participants were least satisfied with causal explanations, that intentional explanations were most effective in establishing high levels of trust, and that mixed explanations led to the best functional understanding of the system and resulted in the least changes in trust over time.},
	language = {en},
	number = {1},
	urldate = {2021-09-06},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Schraagen, Jan Maarten and Elsasser, Pia and Fricke, Hanna and Hof, Marleen and Ragalmuto, Fabyen},
	month = dec,
	year = {2020},
	pages = {339--343},
}

@article{examinationgeneraldecisionmakingstylea,
	title = {An examination of the general decision making style questionnaire in two {UK} samples},
	volume = {20},
	issn = {0268-3946},
	url = {https://www.emerald.com/insight/content/doi/10.1108/02683940510579777/full/html},
	doi = {10.1108/02683940510579777},
	abstract = {Purpose – To examine the psychometric properties and construct validity of the general decision making style (GDMS) questionnaire in two UK samples. Design/methodology/approach – The GDMS takes the form of a self-report questionnaire which identiﬁes ﬁve decision making styles: rational, intuitive, dependent, avoidant, and spontaneous. It was administered to samples of business studies undergraduates in two UK business schools. Analyses included scale reliabilities, test-re-test reliability, and both exploratory and conﬁrmatory factor analyses.},
	language = {en},
	number = {2},
	urldate = {2021-09-06},
	journal = {Journal of Managerial Psychology},
	author = {Spicer, David P. and Sadler‐Smith, Eugene},
	month = mar,
	year = {2005},
	pages = {137--149},
}

@article{PromptingContrastiveExplanationsCommonsenseReasoning,
	title = {Prompting {Contrastive} {Explanations} for {Commonsense} {Reasoning} {Tasks}},
	url = {http://arxiv.org/abs/2106.06823},
	abstract = {Many commonsense reasoning NLP tasks involve choosing between one or more possible answers to a question or prompt based on knowledge that is often implicit. Large pretrained language models (PLMs) can achieve near-human performance on such tasks, while providing little human-interpretable evidence of the underlying reasoning they use. In this work, we show how to use these same models to generate such evidence: inspired by the contrastive nature of human explanations, we use PLMs to complete explanation prompts which contrast alternatives according to the key attribute(s) required to justify the correct answer (for example, peanuts are usually salty while raisins are sweet). Conditioning model decisions on these explanations improves performance on two commonsense reasoning benchmarks, as compared to previous non-contrastive alternatives. These explanations are also judged by humans to be more relevant for solving the task, and facilitate a novel method to evaluate explanation faithfulfness.},
	urldate = {2021-09-05},
	journal = {arXiv:2106.06823 [cs]},
	author = {Paranjape, Bhargavi and Michael, Julian and Ghazvininejad, Marjan and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.06823},
	keywords = {explanation, generation, xai},
}

@misc{doi101016paid2004,
	title = {doi:10.1016/j.paid.2004.03.020 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {doi},
	url = {https://reader.elsevier.com/reader/sd/pii/S0191886904000819?token=8F0EFFD8E99BB5FB7A848AC6350CF16B5B14669FAF125C905C547A9F609EABAA18DD49F329898B254EEB8E38E2BA9691&originRegion=us-east-1&originCreation=20210905171738},
	language = {en},
	urldate = {2021-09-05},
	doi = {10.1016/j.paid.2004.03.020},
}

@misc{doi101016paid2006,
	title = {doi:10.1016/j.paid.2006.03.003 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {doi},
	url = {https://reader.elsevier.com/reader/sd/pii/S0191886906001206?token=0FA1593FBCBE2D065C7EA055F71644DDC150B07EDD20690EE8E31F6B2024E727C0608F16531A80E89F47F6DBF5FE1D59&originRegion=us-east-1&originCreation=20210905171327},
	language = {en},
	urldate = {2021-09-05},
	doi = {10.1016/j.paid.2006.03.003},
}

@article{PreliminaryLogicbasedApproachExplanationGeneration,
	title = {A {Preliminary} {Logic}-based {Approach} for {Explanation} {Generation}},
	abstract = {In an explanation generation problem, an agent needs to identify and explain the reasons for its decisions to another agent. Existing work in this area is mostly conﬁned to planning-based systems that use automated planning approaches to solve the problem. In this paper, we approach this problem from a new perspective, where we propose a general logic-based framework for explanation generation. In particular, given a knowledge base KB1 that entails a formula φ and a second knowledge base KB2 that does not entail φ, we seek to identify an explanation that is a subset of KB1 such that the union of KB2 and entails φ. We deﬁne two types of explanations, model- and proof-theoretic explanations, and use cost functions to reﬂect preferences between explanations. Further, we present our algorithm implemented for propositional logic that compute such explanations and empirically evaluate it in random knowledge bases and a planning domain.},
	language = {en},
	author = {Vasileiou, Stylianos L and Yeoh, William and Son, Tran Cao},
	keywords = {explanation, generation},
	pages = {9},
}

@inproceedings{GeneratingEffectiveExplanationsLogicalFormulas,
	address = {Dublin, Ireland},
	title = {Towards {Generating} {Effective} {Explanations} of {Logical} {Formulas}: {Challenges} and {Strategies}},
	shorttitle = {Towards {Generating} {Effective} {Explanations} of {Logical} {Formulas}},
	url = {https://aclanthology.org/2020.nl4xai-1.9},
	abstract = {While the problem of natural language generation from logical formulas has a long tradition, thus far little attention has been paid to ensuring that the generated explanations are optimally effective for the user. We discuss issues related to deciding what such output should look like and strategies for addressing those issues. We stress the importance of informing generation of NL explanations of logical formulas through reader studies and findings on the comprehension of logic from Pragmatics and Cognitive Science. We then illustrate the discussed issues and potential ways of addressing them using a simple demo system's output generated from a propositional logic formula.},
	urldate = {2021-09-08},
	booktitle = {2nd {Workshop} on {Interactive} {Natural} {Language} {Technology} for {Explainable} {Artificial} {Intelligence}},
	publisher = {Association for Computational Linguistics},
	author = {Mayn, Alexandra and van Deemter, Kees},
	month = nov,
	year = {2020},
	pages = {39--43},
}

@inproceedings{SurveyStateExplainableAINatural,
	address = {Suzhou, China},
	title = {A {Survey} of the {State} of {Explainable} {AI} for {Natural} {Language} {Processing}},
	url = {https://aclanthology.org/2020.aacl-main.46},
	abstract = {Recent years have seen important advances in the quality of state-of-the-art models, but this has come at the expense of models becoming less interpretable. This survey presents an overview of the current state of Explainable AI (XAI), considered within the domain of Natural Language Processing (NLP). We discuss the main categorization of explanations, as well as the various ways explanations can be arrived at and visualized. We detail the operations and explainability techniques currently available for generating explanations for NLP model predictions, to serve as a resource for model developers in the community. Finally, we point out the current gaps and encourage directions for future work in this important research area.},
	urldate = {2021-09-08},
	booktitle = {Proceedings of the 1st {Conference} of the {Asia}-{Pacific} {Chapter} of the {Association} for {Computational} {Linguistics} and the 10th {International} {Joint} {Conference} on {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Danilevsky, Marina and Qian, Kun and Aharonov, Ranit and Katsis, Yannis and Kawas, Ban and Sen, Prithviraj},
	month = dec,
	year = {2020},
	pages = {447--459},
}

@inproceedings{ExplanationGamePredictionExplainabilitySparse,
	address = {Online},
	title = {The {Explanation} {Game}: {Towards} {Prediction} {Explainability} through {Sparse} {Communication}},
	shorttitle = {The {Explanation} {Game}},
	url = {https://www.aclweb.org/anthology/2020.blackboxnlp-1.10},
	doi = {10.18653/v1/2020.blackboxnlp-1.10},
	abstract = {Explainability is a topic of growing importance in NLP. In this work, we provide a uniﬁed perspective of explainability as a communication problem between an explainer and a layperson about a classiﬁer’s decision. We use this framework to compare several explainers, including gradient methods, erasure, and attention mechanisms, in terms of their communication success. In addition, we reinterpret these methods in the light of classical feature selection, and use this as inspiration for new embedded explainers, through the use of selective, sparse attention. Experiments in text classiﬁcation and natural language inference, using different conﬁgurations of explainers and laypeople (including both machines and humans), reveal an advantage of attention-based explainers over gradient and erasure methods, and show that selective attention is a simpler alternative to stochastic rationalizers. Human experiments show strong results on text classiﬁcation with post-hoc explainers trained to optimize communication success.},
	language = {en},
	urldate = {2021-09-09},
	booktitle = {Proceedings of the {Third} {BlackboxNLP} {Workshop} on {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Treviso, Marcos and Martins, André F. T.},
	year = {2020},
	pages = {107--118},
}

@inproceedings{Generatingjustificationsnormrelatedagentdecisions,
	address = {Tokyo, Japan},
	title = {Generating justifications for norm-related agent decisions},
	url = {https://www.aclweb.org/anthology/W19-8660},
	doi = {10.18653/v1/W19-8660},
	abstract = {We present an approach to generating natural language justiﬁcations of decisions derived from norm-based reasoning. Assuming an agent which maximally satisﬁes a set of rules speciﬁed in an object-oriented temporal logic, the user can ask factual questions (about the agent’s rules, actions, and the extent to which the agent violated the rules) as well as “why” questions that require the agent comparing actual behavior to counterfactual trajectories with respect to these rules. To produce natural-sounding explanations, we focus on the subproblem of producing natural language clauses from statements in a fragment of temporal logic, and then describe how to embed these clauses into explanatory sentences. We use a human judgment evaluation on a testbed task to compare our approach to variants in terms of intelligibility, mental model and perceived trust.},
	language = {en},
	urldate = {2021-09-09},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Natural} {Language} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Kasenberg, Daniel and Roque, Antonio and Thielstrom, Ravenna and Chita-Tegmark, Meia and Scheutz, Matthias},
	year = {2019},
	keywords = {explanation, generation},
	pages = {484--493},
}

@inproceedings{UsingSyntacticInformationImprovingWhyQuestion,
	address = {Manchester, UK},
	title = {Using {Syntactic} {Information} for {Improving} {Why}-{Question} {Answering}},
	url = {https://aclanthology.org/C08-1120},
	urldate = {2021-09-08},
	booktitle = {Proceedings of the 22nd {International} {Conference} on {Computational} {Linguistics} ({Coling} 2008)},
	publisher = {Coling 2008 Organizing Committee},
	author = {Verberne, Suzan and Boves, Lou and Oostdijk, Nelleke and Coppen, Peter-Arno},
	month = aug,
	year = {2008},
	keywords = {explanation, generation},
	pages = {953--960},
}

@inproceedings{QA2ExplanationGeneratingEvaluatingExplanationsQuestion,
	address = {Online},
	title = {{QA2Explanation}: {Generating} and {Evaluating} {Explanations} for {Question} {Answering} {Systems} over {Knowledge} {Graph}},
	shorttitle = {{QA2Explanation}},
	url = {https://aclanthology.org/2020.intexsempar-1.1},
	doi = {10.18653/v1/2020.intexsempar-1.1},
	abstract = {In the era of Big Knowledge Graphs, Question Answering (QA) systems have reached a milestone in their performance and feasibility. However, their applicability, particularly in specific domains such as the biomedical domain, has not gained wide acceptance due to their “black box” nature, which hinders transparency, fairness, and accountability of QA systems. Therefore, users are unable to understand how and why particular questions have been answered, whereas some others fail. To address this challenge, in this paper, we develop an automatic approach for generating explanations during various stages of a pipeline-based QA system. Our approach is a supervised and automatic approach which considers three classes (i.e., success, no answer, and wrong answer) for annotating the output of involved QA components. Upon our prediction, a template explanation is chosen and integrated into the output of the corresponding component. To measure the effectiveness of the approach, we conducted a user survey as to how non-expert users perceive our generated explanations. The results of our study show a significant increase in the four dimensions of the human factor from the Human-computer interaction community.},
	urldate = {2021-09-08},
	booktitle = {Proceedings of the {First} {Workshop} on {Interactive} and {Executable} {Semantic} {Parsing}},
	publisher = {Association for Computational Linguistics},
	author = {Shekarpour, Saeedeh and Nadgeri, Abhishek and Singh, Kuldeep},
	month = nov,
	year = {2020},
	keywords = {explanation, generation, kg},
	pages = {1--11},
}

@article{SpanishvalidationGeneralDecisionMakingStyle,
	title = {Spanish validation of {General} {Decision}-{Making} {Style} scale: {Sex} invariance, sex diﬀerences and relationships with personality and coping styles},
	abstract = {The General Decision-Making Styles (GDMS) scale measures ﬁve decision-making styles: rational, intuitive, dependent, avoidant and spontaneous. GDMS has been related to coping and some personality factors and sex-diﬀerences has been described. In spite of its usefulness, there is not a validated Spanish translation. The aim of this study is to translate to Spanish and provide psychometric evidence considering sex diﬀerences and the relationships between GDMS, personality and coping variables. Two samples were used for this study; the ﬁrst sample composed by 300 participants who completed the GDMS and the Rational-Experiential Inventory (REI), and the second sample of 361 participants who completed the GDMS, the Ten Item Personality Trait Inventory and the brief COPE scales. Participants from second sample ﬁlled in GDMS a second time (137 participants) after eight weeks from the ﬁrst data collection. Conﬁrmatory factor analyses showed a ﬁve-factor composition of GDMS with equivalence across sex using invariance analyses. Moreover, GDMS showed acceptable internal consistency and temporal stability. Finally, rational and intuitive styles were related to healthier coping patterns and emotional stability, while dependent, avoidant and spontaneous styles were associated with unhealthy coping patterns and emotional instability.},
	language = {en},
	journal = {Judgment and Decision Making},
	author = {Alacreu-Crespo, Adrián and Fuentes, María C and Abad-Tortosa, Diana and Cano-Lopez, Irene and González, Esperanza and Serrano, Miguel Ángel},
	keywords = {decision-making},
	pages = {13},
}

@article{ControllingUserPerceptionsLinguisticStyle,
	title = {Controlling {User} {Perceptions} of {Linguistic} {Style}: {Trainable} {Generation} of {Personality} {Traits}},
	volume = {37},
	shorttitle = {Controlling {User} {Perceptions} of {Linguistic} {Style}},
	url = {https://aclanthology.org/J11-3002},
	doi = {10.1162/COLI_a_00063},
	number = {3},
	urldate = {2021-09-11},
	journal = {Computational Linguistics},
	author = {Mairesse, François and Walker, Marilyn A.},
	year = {2011},
	pages = {455--488},
}

@inproceedings{GeneratingExplanationsActionFailuresCognitive,
	address = {Dublin, Ireland},
	title = {Generating {Explanations} of {Action} {Failures} in a {Cognitive} {Robotic} {Architecture}},
	url = {https://aclanthology.org/2020.nl4xai-1.14},
	abstract = {We describe an approach to generating explanations about why robot actions fail, focusing on the considerations of robots that are run by cognitive robotic architectures. We define a set of Failure Types and Explanation Templates, motivating them by the needs and constraints of cognitive architectures that use action scripts and interpretable belief states, and describe content realization and surface realization in this context. We then describe an evaluation that can be extended to further study the effects of varying the explanation templates.},
	urldate = {2021-09-10},
	booktitle = {2nd {Workshop} on {Interactive} {Natural} {Language} {Technology} for {Explainable} {Artificial} {Intelligence}},
	publisher = {Association for Computational Linguistics},
	author = {Thielstrom, Ravenna and Roque, Antonio and Chita-Tegmark, Meia and Scheutz, Matthias},
	month = nov,
	year = {2020},
	pages = {67--72},
}

@article{SituationalFactorsIntuitiveDecisionStyle,
	title = {Situational {Factors} and {Intuitive} {Decision} {Style} among {Academicians}},
	volume = {1},
	abstract = {Decision making is the process of deciding something which is important by a group of people or an organization. An empirical study was carried out to analyze intuitive decision making style among academicians at five different faculties in a Malaysian public university. Its objectives are: to identify intuitive decision making style among academicians; to identify differences in intuitive decision making style based on age, gender, race, working experiences, professional level and field of expert; and lastly, to examine relationship between intuitive decision making style and situational factors. There were 94 academicians of five different faculties were involved in this study. Survey data were collected using questionnaire and SPSS was used for data analysis. The findings show that out of four situational factors, two of them, i.e. information and risk factors were found to have significant positive relationship with intuitive decision making style. Recommendations of the study are highlighted and further research discussions are also suggested.},
	language = {en},
	number = {7},
	journal = {International Journal of Humanities and Social Science},
	author = {Hon-Tat, Huam and Ai-Chin, Thoo and Hooi, Poon Sun and Rasli, Amran and Abdullah, Muhammad Madi Bin and Chye, Lee Thean},
	keywords = {dm, theory},
	pages = {6},
}

@article{BaselinesBigramsSimpleGoodSentiment,
	title = {Baselines and {Bigrams}: {Simple}, {Good} {Sentiment} and {Topic} {Classification}},
	abstract = {Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classiﬁcation, but their performance varies greatly depending on the model variant, features used and task/ dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level.},
	language = {en},
	author = {Wang, Sida and Manning, Christopher D},
	keywords = {dm, nlp},
	pages = {5},
}

@inproceedings{Neuralsentencegenerationformalsemantics,
	address = {Tilburg University, The Netherlands},
	title = {Neural sentence generation from formal semantics},
	url = {https://aclanthology.org/W18-6549},
	doi = {10.18653/v1/W18-6549},
	abstract = {Sequence-to-sequence models have shown strong performance in a wide range of NLP tasks, yet their applications to sentence generation from logical representations are underdeveloped. In this paper, we present a sequence-to-sequence model for generating sentences from logical meaning representations based on event semantics. We use a semantic parsing system based on Combinatory Categorial Grammar (CCG) to obtain data annotated with logical formulas. We augment our sequence-to-sequence model with masking for predicates to constrain output sentences. We also propose a novel evaluation method for generation using Recognizing Textual Entailment (RTE). Combining parsing and generation, we test whether or not the output sentence entails the original text and vice versa. Experiments showed that our model outperformed a baseline with respect to both BLEU scores and accuracies in RTE.},
	urldate = {2021-09-09},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Natural} {Language} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Manome, Kana and Yoshikawa, Masashi and Yanaka, Hitomi and Martínez-Gómez, Pascual and Mineshima, Koji and Bekki, Daisuke},
	month = nov,
	year = {2018},
	pages = {408--414},
}

@article{Evaluatingeverydayexplanations,
	title = {Evaluating everyday explanations},
	volume = {24},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-017-1258-z},
	doi = {10.3758/s13423-017-1258-z},
	abstract = {People frequently rely on explanations provided by others to understand complex phenomena. A fair amount of attention has been devoted to the study of scientific explanation, and less on understanding how people evaluate naturalistic, everyday explanations. Using a corpus of diverse explanations from Reddit’s BExplain Like I’m Five{\textasciicircum} and other online sources, we assessed how well a variety of explanatory criteria predict judgments of explanation quality. We find that while some criteria previously identified as explanatory virtues do predict explanation quality in naturalistic settings, other criteria, such as simplicity, do not. Notably, we find that people have a preference for complex explanations that invoke more causal mechanisms to explain an effect. We propose that this preference for complexity is driven by a desire to identify enough causes to make the effect seem inevitable.},
	language = {en},
	number = {5},
	urldate = {2021-09-12},
	journal = {Psychonomic Bulletin \& Review},
	author = {Zemla, Jeffrey C. and Sloman, Steven and Bechlivanidis, Christos and Lagnado, David A.},
	month = oct,
	year = {2017},
	keywords = {explanation, xai},
	pages = {1488--1500},
}

@article{Variationsdecisionmakingprofilesagegender,
	title = {Variations in decision-making profiles by age and gender: {A} cluster-analytic approach},
	volume = {85},
	issn = {01918869},
	shorttitle = {Variations in decision-making profiles by age and gender},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0191886915002974},
	doi = {10.1016/j.paid.2015.04.034},
	abstract = {Using cluster-analysis, we investigated whether rational, intuitive, spontaneous, dependent, and avoidant styles of decision making (Scott \& Bruce, 1995) combined to form distinct decision-making proﬁles that differed by age and gender. Self-report survey data were collected from 1075 members of RAND’s American Life Panel (56.2\% female, 18–93 years, Mage = 53.49). Three decision-making proﬁles were identiﬁed: affective/experiential, independent/self-controlled, and an interpersonally-oriented dependent proﬁle. Older people were less likely to be in the affective/experiential proﬁle and more likely to be in the independent/self-controlled proﬁle. Women were less likely to be in the affective/experiential proﬁle and more likely to be in the interpersonally-oriented dependent proﬁle. Interpersonally-oriented proﬁles are discussed as an overlooked but important dimension of how people make important decisions.},
	language = {en},
	urldate = {2021-09-11},
	journal = {Personality and Individual Differences},
	author = {Delaney, Rebecca and Strough, JoNell and Parker, Andrew M. and Bruine de Bruin, Wandi},
	month = oct,
	year = {2015},
	keywords = {decision-making},
	pages = {19--24},
}

@inproceedings{CommonsenseJustificationActionExplanation,
	address = {Brussels, Belgium},
	title = {Commonsense {Justification} for {Action} {Explanation}},
	url = {https://aclanthology.org/D18-1283},
	doi = {10.18653/v1/D18-1283},
	abstract = {To enable collaboration and communication between humans and agents, this paper investigates learning to acquire commonsense evidence for action justification. In particular, we have developed an approach based on the generative Conditional Variational Autoencoder(CVAE) that models object relations/attributes of the world as latent variables and jointly learns a performer that predicts actions and an explainer that gathers commonsense evidence to justify the action. Our empirical results have shown that, compared to a typical attention-based model, CVAE achieves significantly higher performance in both action prediction and justification. A human subject study further shows that the commonsense evidence gathered by CVAE can be communicated to humans to achieve a significantly higher common ground between humans and agents.},
	urldate = {2021-09-11},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Yang, Shaohua and Gao, Qiaozi and Sadiya, Sari and Chai, Joyce},
	month = oct,
	year = {2018},
	keywords = {explanation, generation},
	pages = {2627--2637},
}

@article{CommentaryShouldGenderDifferencesbe,
	title = {Commentary: {Should} {Gender} {Differences} be {Included} in the {Evolutionary} {Upgrade} to {Cognitive} {Load} {Theory}?},
	volume = {29},
	issn = {1040-726X, 1573-336X},
	shorttitle = {Commentary},
	url = {http://link.springer.com/10.1007/s10648-016-9362-6},
	doi = {10.1007/s10648-016-9362-6},
	abstract = {Recent upgrades to cognitive load theory suggest that evolutionary processes have shaped the way that working memory processes cultural and social information. According to evolutionarily educational psychologists, some forms of information are processed with lower working memory loads than other forms. The former are evolutionarily salient and the latter historically recent and evolutionarily novel. Sex differences in evolutionary pressures have resulted in some differences in aspects of associated working memory systems that are relevant to cognitive load theory. For this reason this paper suggests that gender differences in information processing via evolutionary processes is an important consideration that should be added to current theory.},
	language = {en},
	number = {1},
	urldate = {2021-09-13},
	journal = {Educational Psychology Review},
	author = {Bevilacqua, Andy},
	month = mar,
	year = {2017},
	keywords = {cognitive-load},
	pages = {189--194},
}

@article{CognitiveLoadeCommerceApplicationsMeasurement,
	title = {Cognitive {Load} in {eCommerce} {Applications}—{Measurement} and {Effects} on {User} {Satisfaction}},
	volume = {2009},
	issn = {1687-5893, 1687-5907},
	url = {http://www.hindawi.com/journals/ahci/2009/121494/},
	doi = {10.1155/2009/121494},
	abstract = {Guidelines for designing usable interfaces recommend reducing short term memory load. Cognitive load, that is, working memory demands during problem solving, reasoning, or thinking, may affect users' general satisfaction and performance when completing complex tasks. Whereas in design guidelines numerous ways of reducing cognitive load in interactive systems are described, not many attempts have been made to measure cognitive load in Web applications, and few techniques exist. In this study participants' cognitive load was measured while they were engaged in searching for several products in four different online book stores. NASA-TLX and dual-task methodology were used to measure subjective and objective mental workload. The dual-task methodology involved searching for books as the primary task and a visual monitoring task as the secondary task. NASA-TLX scores differed significantly among the shops. Secondary task reaction times showed no significant differences between the four shops. Strong correlations between NASA-TLX, primary task completion time, and general satisfaction suggest that NASA-TLX can be used as a valuable additional measure of efficiency. Furthermore, strong correlations were found between browse/search preference and NASA-TLX as well as between search/browse preference and user satisfaction. Thus we suggest browse/search preference as a promising heuristic assessment method of cognitive load.},
	language = {en},
	urldate = {2021-09-13},
	journal = {Advances in Human-Computer Interaction},
	author = {Schmutz, Peter and Heinz, Silvia and Métrailler, Yolanda and Opwis, Klaus},
	year = {2009},
	pages = {1--9},
}

@article{Websearchstrategieshumanindividual,
	title = {Web search strategies and human individual differences: {Cognitive} and demographic factors, {Internet} attitudes, and approaches},
	volume = {56},
	issn = {1532-2890},
	shorttitle = {Web search strategies and human individual differences},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.20168},
	doi = {10.1002/asi.20168},
	abstract = {The research reported here was an exploratory study that sought to discover the effects of human individual differences on Web search strategy. These differences consisted of (a) study approaches, (b) cognitive and demographic features, and (c) perceptions of and preferred approaches to Web-based information seeking. Sixty-eight master's students used AltaVista to search for information on three assigned search topics graded in terms of complexity. Five hundred seven search queries were factor analyzed to identify relationships between the individual difference variables and Boolean and best-match search strategies. A number of consistent patterns of relationship were found. As task complexity increased, a number of strategic shifts were also observed on the part of searchers possessing particular combinations of characteristics. A second article (published in this issue of JASIST; Ford, Miller, \& Moss, 2005) presents a combined analyses of the data including a series of regression analyses.},
	language = {en},
	number = {7},
	urldate = {2021-09-13},
	journal = {Journal of the American Society for Information Science and Technology},
	author = {Ford, Nigel and Miller, David and Moss, Nicola},
	year = {2005},
	note = {\_eprint: https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/asi.20168},
	keywords = {verbal},
	pages = {741--756},
}

@misc{PIIS0001691801000348Elsevier,
	title = {{PII}: {S0001}-6918(01)00034-8 {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {{PII}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0001691801000348?token=3D32F7A6D5E9C0FF689AE49AD990A8953F596C9C571A0B02DE493F0D58E13C34FD8379C633D11F1F9940ACA9292D23E2&originRegion=us-east-1&originCreation=20210913031523},
	language = {en},
	urldate = {2021-09-13},
	doi = {10.1016/S0001-6918(01)00034-8},
}

@article{WhoExplainableAIHowAI,
	title = {The {Who} in {Explainable} {AI}: {How} {AI} {Background} {Shapes} {Perceptions} of {AI} {Explanations}},
	shorttitle = {The {Who} in {Explainable} {AI}},
	url = {http://arxiv.org/abs/2107.13509},
	abstract = {Explainability of AI systems is critical for users to take informed actions and hold systems accountable. While "opening the opaque box" is important, understanding who opens the box can govern if the Human-AI interaction is effective. In this paper, we conduct a mixed-methods study of how two different groups of whos--people with and without a background in AI--perceive different types of AI explanations. These groups were chosen to look at how disparities in AI backgrounds can exacerbate the creator-consumer gap. We quantitatively share what the perceptions are along five dimensions: confidence, intelligence, understandability, second chance, and friendliness. Qualitatively, we highlight how the AI background influences each group's interpretations and elucidate why the differences might exist through the lenses of appropriation and cognitive heuristics. We find that (1) both groups had unwarranted faith in numbers, to different extents and for different reasons, (2) each group found explanatory values in different explanations that went beyond the usage we designed them for, and (3) each group had different requirements of what counts as humanlike explanations. Using our findings, we discuss potential negative consequences such as harmful manipulation of user trust and propose design interventions to mitigate them. By bringing conscious awareness to how and why AI backgrounds shape perceptions of potential creators and consumers in XAI, our work takes a formative step in advancing a pluralistic Human-centered Explainable AI discourse.},
	urldate = {2021-09-12},
	journal = {arXiv:2107.13509 [cs]},
	author = {Ehsan, Upol and Passi, Samir and Liao, Q. Vera and Chan, Larry and Lee, I.-Hsiang and Muller, Michael and Riedl, Mark O.},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.13509},
	keywords = {explanation},
}

@article{Doeshighereducationhonecognitive,
	title = {Does higher education hone cognitive functioning and learning efficacy? {Findings} from a large and diverse sample},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {Does higher education hone cognitive functioning and learning efficacy?},
	url = {https://dx.plos.org/10.1371/journal.pone.0182276},
	doi = {10.1371/journal.pone.0182276},
	language = {en},
	number = {8},
	urldate = {2021-09-13},
	journal = {PLOS ONE},
	author = {Guerra-Carrillo, Belén and Katovich, Kiefer and Bunge, Silvia A.},
	editor = {Dalby, Andrew R.},
	month = aug,
	year = {2017},
	pages = {e0182276},
}

@article{Ageexecutivefunctioningdecisionmakingstyles,
	title = {Age, executive functioning, and decision-making styles in adults: a moderated mediation model},
	volume = {27},
	issn = {1382-5585, 1744-4128},
	shorttitle = {Age, executive functioning, and decision-making styles in adults},
	url = {https://www.tandfonline.com/doi/full/10.1080/13825585.2019.1614142},
	doi = {10.1080/13825585.2019.1614142},
	abstract = {The current study aimed to assess: i) whether executive functioning (EF) mediates the association of age with diﬀerent decision-making (DM) styles in adults, and ii) whether these mediational associations change with age in adulthood. Our sample included 195 adults (110 young adults and 85 middle-aged adults; 95 males) selected from diﬀerent government, semi-government, and private sector organizations. They were assessed on a self-report measure of General Decision-making Styles and on two EF tests: the Design Fluency Test and the Color-Word Interference Test from the Delis–Kaplan Executive Functions System. Results indicated that EF mediated the association of age with three decision-making styles including dependent, avoidant, and spontaneous DM. However, a conditional indirect eﬀect of EF was signiﬁcant only for spontaneous DM, indicating stronger indirect eﬀects for middle-aged adults than for young adults. The ﬁndings highlight the idea that EF is an important factor in DM, particularly during middle adulthood.},
	language = {en},
	number = {3},
	urldate = {2021-09-13},
	journal = {Aging, Neuropsychology, and Cognition},
	author = {Fatima, Shameem and Khan, Manoor and Rosselli, Monica and Ardila, Alfredo},
	month = may,
	year = {2020},
	keywords = {cognitive-load},
	pages = {338--350},
}

@article{GenderDifferencesCognitiveLoadsAttitudes,
	title = {Gender {Differences} in {Cognitive} {Loads}, {Attitudes}, and {Academic} {Achievements} in {Mobile} {English} {Learning}},
	volume = {17},
	abstract = {Studies on gender differences in mobile English learning are in their initial stages. College English IV, designed by a number of professors and engineers in a university in China, serves as a mobile English learning platform. This study aims to determine gender differences in cognitive loads, attitudes, and academic achievements in English language learning assisted with this mobile English learning platform. Through a mixed research design, 79 randomly selected participants join the research, together with interviews and posts to collect qualitative data. Cognitive loads, attitudes, and academic achievements are measured through related scales to collect quantitative data. It is concluded that there are significant gender differences in cognitive loads, attitudes, and academic achievements in English language learning assisted with the mobile learning platform. Future research on gender differences in mobile English learning should also examine relationships between gender differences, learner motivation, achievement goals, and learning outcomes.},
	language = {en},
	number = {4},
	journal = {International Journal of Distance Education Technologies},
	author = {Yu, Zhonggen},
	year = {2019},
	pages = {16},
}

@article{ExplanationHumanAISystemsLiteratureMetaReview,
	title = {Explanation in {Human}-{AI} {Systems}: {A} {Literature} {Meta}-{Review}, {Synopsis} of {Key} {Ideas} and {Publications}, and {Bibliography} for {Explainable} {AI}},
	shorttitle = {Explanation in {Human}-{AI} {Systems}},
	url = {http://arxiv.org/abs/1902.01876},
	abstract = {This is an integrative review that address the question, "What makes for a good explanation?" with reference to AI systems. Pertinent literatures are vast. Thus, this review is necessarily selective. That said, most of the key concepts and issues are expressed in this Report. The Report encapsulates the history of computer science efforts to create systems that explain and instruct (intelligent tutoring systems and expert systems). The Report expresses the explainability issues and challenges in modern AI, and presents capsule views of the leading psychological theories of explanation. Certain articles stand out by virtue of their particular relevance to XAI, and their methods, results, and key points are highlighted. It is recommended that AI/XAI researchers be encouraged to include in their research reports fuller details on their empirical or experimental methods, in the fashion of experimental psychology research reports: details on Participants, Instructions, Procedures, Tasks, Dependent Variables (operational definitions of the measures and metrics), Independent Variables (conditions), and Control Conditions.},
	urldate = {2021-09-19},
	journal = {arXiv:1902.01876 [cs]},
	author = {Mueller, Shane T. and Hoffman, Robert R. and Clancey, William and Emrey, Abigail and Klein, Gary},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.01876},
}

@article{Simplicityprobabilitycausalexplanation,
	title = {Simplicity and probability in causal explanation},
	volume = {55},
	issn = {00100285},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028506000739},
	doi = {10.1016/j.cogpsych.2006.09.006},
	abstract = {What makes some explanations better than others? This paper explores the roles of simplicity and probability in evaluating competing causal explanations. Four experiments investigate the hypothesis that simpler explanations are judged both better and more likely to be true. In all experiments, simplicity is quantiWed as the number of causes invoked in an explanation, with fewer causes corresponding to a simpler explanation. Experiment 1 conWrms that all else being equal, both simpler and more probable explanations are preferred. Experiments 2 and 3 examine how explanations are evaluated when simplicity and probability compete. The data suggest that simpler explanations are assigned a higher prior probability, with the consequence that disproportionate probabilistic evidence is required before a complex explanation will be favored over a simpler alternative. Moreover, committing to a simple but unlikely explanation can lead to systematic overestimation of the prevalence of the cause invoked in the simple explanation. Finally, Experiment 4 Wnds that the preference for simpler explanations can be overcome when probability information unambiguously supports a complex explanation over a simpler alternative. Collectively, these Wndings suggest that simplicity is used as a basis for evaluating explanations and for assigning prior probabilities when unambiguous probability information is absent. More broadly, evaluating explanations may operate as a mechanism for generating estimates of subjective probability.},
	language = {en},
	number = {3},
	urldate = {2021-09-19},
	journal = {Cognitive Psychology},
	author = {Lombrozo, T},
	month = nov,
	year = {2007},
	pages = {232--257},
}

@article{ExplanationBasedHumanDebuggingNLPModels,
	title = {Explanation-{Based} {Human} {Debugging} of {NLP} {Models}: {A} {Survey}},
	shorttitle = {Explanation-{Based} {Human} {Debugging} of {NLP} {Models}},
	url = {http://arxiv.org/abs/2104.15135},
	abstract = {To fix a bug in a program, we need to locate where the bug is, understand why it causes the problem, and patch the code accordingly. This process becomes harder when the program is a trained machine learning model and even harder for opaque deep learning models. In this survey, we review papers that exploit explanations to enable humans to debug NLP models. We call this problem explanation-based human debugging (EBHD). In particular, we categorize and discuss existing works along three main dimensions of EBHD (the bug context, the workflow, and the experimental setting), compile findings on how EBHD components affect human debuggers, and highlight open problems that could be future research directions.},
	urldate = {2021-09-15},
	journal = {arXiv:2104.15135 [cs]},
	author = {Lertvittayakumjorn, Piyawat and Toni, Francesca},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.15135},
	keywords = {explanation, nlp},
}

@article{EffectsTimePressureBehaviouralDecision,
	title = {Effects of {Time} {Pressure} on {Behavioural} {Decision} {Making} in {Natural} {Disasters}: {Based} on an {Online} {Experimental} {System}},
	volume = {08},
	issn = {21670587},
	shorttitle = {Effects of {Time} {Pressure} on {Behavioural} {Decision} {Making} in {Natural} {Disasters}},
	url = {https://www.omicsonline.org/open-access/effects-of-time-pressure-on-behavioural-decision-making-in-natural-disasters-based-on-an-online-experimental-system-2167-0587-1000220-101930.html},
	doi = {10.4172/2167-0587.1000220},
	abstract = {This paper aims to examine the effects of time pressure on the behavioral decision-making process and outcome to responding a natural disaster, via an online experimental system with simulated typhoon disaster scenario. As decision strategies determine the cognitive processing of decision, we set up a simple approach to recognize them according to previous researches. After investigating with emergency personnel, we develop the disaster decision making system and conduct experiments. Sixty participants (by two groups) make an emergency relief decision via the system with/ without time pressure. Based on process tracing technology of Information Display Board, decision strategies and cognitive load are measured to make comparisons between different conditions. The results show that time pressure has a bad impact on decision performance and makes participants use more decision strategies by attribute-based rule to avoid conflicts between attributes of each alternative. With comparisons of variation for cognitive load, we find that time pressure occupies the cognitive resource of emergency decision makers, who are forced to monitor and cope with it. Therefore, they have to reduce cognitive effort on decision-making process, leading to dissatisfactory decision results. Besides, the effects of time pressure on different decision strategies are also discussed in this paper.},
	language = {en},
	number = {01},
	urldate = {2021-09-15},
	journal = {Journal of Geography \& Natural Disasters},
	author = {M, Yu and T, Zhu and S, Donaldson},
	year = {2018},
	keywords = {cognitive-load, decision-making},
}

@article{Developmentinstrumentmeasuringdifferenttypes,
	title = {Development of an instrument for measuring different types of cognitive load},
	volume = {45},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-013-0334-1},
	doi = {10.3758/s13428-013-0334-1},
	abstract = {According to cognitive load theory, instructions can impose three types of cognitive load on the learner: intrinsic load, extraneous load, and germane load. Proper measurement of the different types of cognitive load can help us understand why the effectiveness and efficiency of learning environments may differ as a function of instructional formats and learner characteristics. In this article, we present a ten-item instrument for the measurement of the three types of cognitive load. Principal component analysis on data from a lecture in statistics for PhD students (n = 56) in psychology and health sciences revealed a threecomponent solution, consistent with the types of load that the different items were intended to measure. This solution was confirmed by a confirmatory factor analysis of data from three lectures in statistics for different cohorts of bachelor students in the social and health sciences (ns = 171, 136, and 148), and received further support from a randomized experiment with university freshmen in the health sciences (n = 58).},
	language = {en},
	number = {4},
	urldate = {2021-09-15},
	journal = {Behavior Research Methods},
	author = {Leppink, Jimmie and Paas, Fred and Van der Vleuten, Cees P. M. and Van Gog, Tamara and Van Merriënboer, Jeroen J. G.},
	month = dec,
	year = {2013},
	keywords = {cognitive-load},
	pages = {1058--1072},
}

@article{Workingmemorylimitedimprovingknowledge,
	title = {Working memory is limited: improving knowledge transfer by optimising simulation through cognitive load theory},
	volume = {2},
	issn = {2056-6697},
	shorttitle = {Working memory is limited},
	url = {https://stel.bmj.com/lookup/doi/10.1136/bmjstel-2015-000098},
	doi = {10.1136/bmjstel-2015-000098},
	abstract = {This analysis explores how to optimise knowledge transfer in healthcare simulation by applying cognitive load theory to curriculum design and delivery for both novice and expert learners. This is particularly relevant for interprofessional learning which is team-based, as each participant comes to the simulation experience with different levels of expertise. Healthcare simulation can offer opportunities to create complex and dynamic experiences that replicate real clinical situations. Understanding Cognitive Load Theory can foster the acquisition of complex knowledge, skills and abilities required to deliver excellence in patient care without overwhelming a learner’s ability to handle new materials due to working memory limitations. The 2 aspects of working memory that will be explored in this paper are intrinsic load and extrinsic load. These will be addressed in terms of the learner’s level of expertise and how to consider these elements to enhance the learning environment in simulation scenario development and delivery. By applying the concepts of Cognitive Load Theory, this paper offers educators a method to tailor their curricula to navigate working memory and optimise the opportunity for knowledge transfer.},
	language = {en},
	number = {4},
	urldate = {2021-09-14},
	journal = {BMJ Simulation and Technology Enhanced Learning},
	author = {Meguerdichian, Michael and Walker, Katie and Bajaj, Komal},
	month = nov,
	year = {2016},
	pages = {131--138},
}

@article{lureseductivedetailslecturelearning,
	title = {The lure of seductive details during lecture learning.},
	volume = {111},
	issn = {1939-2176, 0022-0663},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/edu0000301},
	doi = {10.1037/edu0000301},
	abstract = {We examined how interesting but peripheral information in lecture instruction— known as “seductive details”—impacts students’ lecture learning. In a low-stakes learning environment, we replicated previous findings showing that seductive details harm learning. However, when students were provided with a video lecture in a high-stakes learning environment, no learning decrements emerged. Furthermore, when prior knowledge was considered, low prior knowledge students surprisingly showed learning gains in a high-stakes environment with seductive details. These findings show that the common practice of using “interest catching devices” in the form of peripheral anecdotes and facts may be an effective pedagogical strategy for students who need the most assistance: those with low prior knowledge in high-stakes learning contexts.},
	language = {en},
	number = {4},
	urldate = {2021-09-14},
	journal = {Journal of Educational Psychology},
	author = {Fries, Laura and DeCaro, Marci S. and Ramirez, Gerardo},
	month = may,
	year = {2019},
	keywords = {cognitive-load, context},
	pages = {736--749},
}

@article{Deconstructingclimatemisinformationidentifyreasoning,
	title = {Deconstructing climate misinformation to identify reasoning errors},
	volume = {13},
	issn = {1748-9326},
	url = {https://iopscience.iop.org/article/10.1088/1748-9326/aaa49f},
	doi = {10.1088/1748-9326/aaa49f},
	abstract = {Misinformation can have signiﬁcant societal consequences. For example, misinformation about climate change has confused the public and stalled support for mitigation policies. When people lack the expertise and skill to evaluate the science behind a claim, they typically rely on heuristics such as substituting judgment about something complex (i.e. climate science) with judgment about something simple (i.e. the character of people who speak about climate science) and are therefore vulnerable to misleading information. Inoculation theory offers one approach to effectively neutralize the inﬂuence of misinformation. Typically, inoculations convey resistance by providing people with information that counters misinformation. In contrast, we propose inoculating against misinformation by explaining the fallacious reasoning within misleading denialist claims. We offer a strategy based on critical thinking methods to analyse and detect poor reasoning within denialist claims. This strategy includes detailing argument structure, determining the truth of the premises, and checking for validity, hidden premises, or ambiguous language. Focusing on argument structure also facilitates the identiﬁcation of reasoning fallacies by locating them in the reasoning process. Because this reason-based form of inoculation is based on general critical thinking methods, it offers the distinct advantage of being accessible to those who lack expertise in climate science. We applied this approach to 42 common denialist claims and ﬁnd that they all demonstrate fallacious reasoning and fail to refute the scientiﬁc consensus regarding anthropogenic global warming. This comprehensive deconstruction and refutation of the most common denialist claims about climate change is designed to act as a resource for communicators and educators who teach climate science and/or critical thinking.},
	language = {en},
	number = {2},
	urldate = {2021-09-22},
	journal = {Environmental Research Letters},
	author = {Cook, John and Ellerton, Peter and Kinkead, David},
	month = feb,
	year = {2018},
	pages = {024018},
}

@article{FunctionalTheoryCounterfactualThinking,
	title = {The {Functional} {Theory} of {Counterfactual} {Thinking}},
	volume = {12},
	issn = {1088-8683},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2408534/},
	doi = {10.1177/1088868308316091},
	abstract = {Counterfactuals are thoughts about alternatives to past events, that is, thoughts of what might have been. This article provides an updated account of the functional theory of counterfactual thinking, suggesting that such thoughts are best explained in terms of their role in behavior regulation and performance improvement. The article reviews a wide range of cognitive experiments indicating that counterfactual thoughts may influence behavior by either of two routes: a content-specific pathway (which involves specific informational effects on behavioral intentions, which then influence behavior) and a content-neutral pathway (which involves indirect effects via affect, mind-sets, or motivation). The functional theory is particularly useful in organizing recent findings regarding counterfactual thinking and mental health. The article concludes by considering the connections to other theoretical conceptions, especially recent advances in goal cognition.},
	number = {2},
	urldate = {2021-09-22},
	journal = {Personality and social psychology review : an official journal of the Society for Personality and Social Psychology, Inc},
	author = {Epstude, Kai and Roese, Neal J.},
	month = may,
	year = {2008},
	pmid = {18453477},
	pmcid = {PMC2408534},
	keywords = {counterfactual, key},
	pages = {168--192},
}

@inproceedings{GenerateNeuralTemplateExplanationsRecommendation,
	address = {Virtual Event Ireland},
	title = {Generate {Neural} {Template} {Explanations} for {Recommendation}},
	isbn = {978-1-4503-6859-9},
	url = {https://dl.acm.org/doi/10.1145/3340531.3411992},
	doi = {10.1145/3340531.3411992},
	abstract = {Personalized recommender systems are important to assist user decision-making in the era of information overload. Meanwhile, explanations of the recommendations further help users to better understand the recommended items so as to make informed choices, which gives rise to the importance of explainable recommendation research. Textual sentence-based explanation has been an important form of explanations for recommender systems due to its advantage in communicating rich information to users. However, current approaches to generating sentence explanations are either limited to predefined sentence templates, which restricts the sentence expressiveness, or opt for free-style sentence generation, which makes it difficult for sentence quality control. In an attempt to benefit both sentence expressiveness and quality, we propose a Neural Template (NETE) explanation generation framework, which brings the best of both worlds by learning sentence templates from data and generating template-controlled sentences that comment about specific features. Experimental results on real-world datasets show that NETE consistently outperforms state-of-the-art explanation generation approaches in terms of sentence quality and expressiveness. Further analysis on case study also shows the advantages of NETE on generating diverse and controllable explanations.},
	language = {en},
	urldate = {2021-09-22},
	booktitle = {Proceedings of the 29th {ACM} {International} {Conference} on {Information} \& {Knowledge} {Management}},
	publisher = {ACM},
	author = {Li, Lei and Zhang, Yongfeng and Chen, Li},
	month = oct,
	year = {2020},
	pages = {755--764},
}

@article{ExplainableNLPGenerativeExplanationFramework,
	title = {Towards {Explainable} {NLP}: {A} {Generative} {Explanation} {Framework} for {Text} {Classification}},
	shorttitle = {Towards {Explainable} {NLP}},
	url = {http://arxiv.org/abs/1811.00196},
	abstract = {Building explainable systems is a critical problem in the field of Natural Language Processing (NLP), since most machine learning models provide no explanations for the predictions. Existing approaches for explainable machine learning systems tend to focus on interpreting the outputs or the connections between inputs and outputs. However, the fine-grained information is often ignored, and the systems do not explicitly generate the human-readable explanations. To better alleviate this problem, we propose a novel generative explanation framework that learns to make classification decisions and generate fine-grained explanations at the same time. More specifically, we introduce the explainable factor and the minimum risk training approach that learn to generate more reasonable explanations. We construct two new datasets that contain summaries, rating scores, and fine-grained reasons. We conduct experiments on both datasets, comparing with several strong neural network baseline systems. Experimental results show that our method surpasses all baselines on both datasets, and is able to generate concise explanations at the same time.},
	urldate = {2021-09-15},
	journal = {arXiv:1811.00196 [cs]},
	author = {Liu, Hui and Yin, Qingyu and Wang, William Yang},
	month = jun,
	year = {2019},
	note = {arXiv: 1811.00196},
	keywords = {explanation, nlp, well-written},
}

@inproceedings{LearningExplainGeneratingStableExplanations,
	address = {Online},
	title = {Learning to {Explain}: {Generating} {Stable} {Explanations} {Fast}},
	shorttitle = {Learning to {Explain}},
	url = {https://aclanthology.org/2021.acl-long.415},
	doi = {10.18653/v1/2021.acl-long.415},
	abstract = {The importance of explaining the outcome of a machine learning model, especially a black-box model, is widely acknowledged. Recent approaches explain an outcome by identifying the contributions of input features to this outcome. In environments involving large black-box models or complex inputs, this leads to computationally demanding algorithms. Further, these algorithms often suffer from low stability, with explanations varying significantly across similar examples. In this paper, we propose a Learning to Explain (L2E) approach that learns the behaviour of an underlying explanation algorithm simultaneously from all training examples. Once the explanation algorithm is distilled into an explainer network, it can be used to explain new instances. Our experiments on three classification tasks, which compare our approach to six explanation algorithms, show that L2E is between 5 and 7.5{\textbackslash}mbox\${\textbackslash}times\$10{\textasciicircum}4 times faster than these algorithms, while generating more stable explanations, and having comparable faithfulness to the black-box model.},
	urldate = {2021-09-24},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Situ, Xuelin and Zukerman, Ingrid and Paris, Cecile and Maruf, Sameen and Haffari, Gholamreza},
	month = aug,
	year = {2021},
	keywords = {explanation, generation},
	pages = {5340--5355},
}

@article{GeneratingCounterfactualExplanationsNaturalLanguagea,
	title = {Generating {Counterfactual} {Explanations} with {Natural} {Language}},
	url = {http://arxiv.org/abs/1806.09809},
	abstract = {Natural language explanations of deep neural network decisions provide an intuitive way for a AI agent to articulate a reasoning process. Current textual explanations learn to discuss class discriminative features in an image. However, it is also helpful to understand which attributes might change a classiﬁcation decision if present in an image (e.g., “This is not a Scarlet Tanager because it does not have black wings.”) We call such textual explanations counterfactual explanations, and propose an intuitive method to generate counterfactual explanations by inspecting which evidence in an input is missing, but might contribute to a different classiﬁcation decision if present in the image. To demonstrate our method we consider a ﬁne-grained image classiﬁcation task in which we take as input an image and a counterfactual class and output text which explains why the image does not belong to a counterfactual class. We then analyze our generated counterfactual explanations both qualitatively and quantitatively using proposed automatic metrics.},
	language = {en},
	urldate = {2021-09-24},
	journal = {arXiv:1806.09809 [cs]},
	author = {Hendricks, Lisa Anne and Hu, Ronghang and Darrell, Trevor and Akata, Zeynep},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.09809},
}

@inproceedings{GeneratingNaturalCounterfactualVisualExplanations,
	address = {Yokohama, Japan},
	title = {Generating {Natural} {Counterfactual} {Visual} {Explanations}},
	isbn = {978-0-9992411-6-5},
	url = {https://www.ijcai.org/proceedings/2020/742},
	doi = {10.24963/ijcai.2020/742},
	abstract = {Counterfactual explanations help users to understand the behaviors of machine learning models by changing the inputs for the existing outputs. For an image classiﬁcation task, an example counterfactual visual explanation explains: ”for an example that belongs to class A, what changes do we need to make to the input so that the output is more inclined to class B.” Our research considers changing the attribute description text of class A on the basis of the attributes of class B and generating counterfactual images on the basis of the modiﬁed text. We can use the prediction results of the model on counterfactual images to ﬁnd the attributes that have the greatest effect when the model is predicting classes A and B. We applied our method to a ﬁne-grained image classiﬁcation dataset and used the generative adversarial network to generate natural counterfactual visual explanations. To evaluate these explanations, we used them to assist crowdsourcing workers in an image classiﬁcation task. We found that, within a speciﬁc range, they improved classiﬁcation accuracy.},
	language = {en},
	urldate = {2021-09-24},
	booktitle = {Proceedings of the {Twenty}-{Ninth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Zhao, Wenqi and Oyama, Satoshi and Kurihara, Masahito},
	month = jul,
	year = {2020},
	pages = {5204--5205},
}

@article{LearningNeuralTemplatesTextGeneration,
	title = {Learning {Neural} {Templates} for {Text} {Generation}},
	url = {http://arxiv.org/abs/1808.10122},
	abstract = {While neural, encoder-decoder models have had significant empirical success in text generation, there remain several unaddressed problems with this style of generation. Encoder-decoder models are largely (a) uninterpretable, and (b) difficult to control in terms of their phrasing or content. This work proposes a neural generation system using a hidden semi-markov model (HSMM) decoder, which learns latent, discrete templates jointly with learning to generate. We show that this model learns useful templates, and that these templates make generation both more interpretable and controllable. Furthermore, we show that this approach scales to real data sets and achieves strong performance nearing that of encoder-decoder text generation models.},
	urldate = {2021-09-24},
	journal = {arXiv:1808.10122 [cs]},
	author = {Wiseman, Sam and Shieber, Stuart M. and Rush, Alexander M.},
	month = jun,
	year = {2019},
	note = {arXiv: 1808.10122},
	keywords = {explanation, generation},
}

@article{SurveyContrastiveCounterfactualExplanationGenerationa,
	title = {A {Survey} of {Contrastive} and {Counterfactual} {Explanation} {Generation} {Methods} for {Explainable} {Artificial} {Intelligence}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3051315},
	abstract = {A number of algorithms in the field of artificial intelligence offer poorly interpretable decisions. To disclose the reasoning behind such algorithms, their output can be explained by means of so-called evidence-based (or factual) explanations. Alternatively, contrastive and counterfactual explanations justify why the output of the algorithms is not any different and how it could be changed, respectively. It is of crucial importance to bridge the gap between theoretical approaches to contrastive and counterfactual explanation and the corresponding computational frameworks. In this work we conduct a systematic literature review which provides readers with a thorough and reproducible analysis of the interdisciplinary research field under study. We first examine theoretical foundations of contrastive and counterfactual accounts of explanation. Then, we report the state-of-the-art computational frameworks for contrastive and counterfactual explanation generation. In addition, we analyze how grounded such frameworks are on the insights from the inspected theoretical approaches. As a result, we highlight a variety of properties of the approaches under study and reveal a number of shortcomings thereof. Moreover, we define a taxonomy regarding both theoretical and practical approaches to contrastive and counterfactual explanation.},
	journal = {IEEE Access},
	author = {Stepin, Ilia and Alonso, Jose M. and Catala, Alejandro and Pereira-Fariña, Martín},
	year = {2021},
	note = {Conference Name: IEEE Access},
	pages = {11974--12001},
}

@inproceedings{E2ENLGChallengeSubmissionControllable,
	address = {Tilburg University, The Netherlands},
	title = {{E2E} {NLG} {Challenge} {Submission}: {Towards} {Controllable} {Generation} of {Diverse} {Natural} {Language}},
	shorttitle = {{E2E} {NLG} {Challenge} {Submission}},
	url = {https://aclanthology.org/W18-6556},
	doi = {10.18653/v1/W18-6556},
	abstract = {In natural language generation (NLG), the task is to generate utterances from a more abstract input, such as structured data. An added challenge is to generate utterances that contain an accurate representation of the input, while reflecting the fluency and variety of human-generated text. In this paper, we report experiments with NLG models that can be used in task oriented dialogue systems. We explore the use of additional input to the model to encourage diversity and control of outputs. While our submission does not rank highly using automated metrics, qualitative investigation of generated utterances suggests the use of additional information in neural network NLG systems to be a promising research direction.},
	urldate = {2021-09-23},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Natural} {Language} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Elder, Henry and Gehrmann, Sebastian and O'Connor, Alexander and Liu, Qun},
	month = nov,
	year = {2018},
	keywords = {explanation, generation},
	pages = {457--462},
}

@article{Howavoidmachinelearningpitfalls,
	title = {How to avoid machine learning pitfalls: a guide for academic researchers},
	shorttitle = {How to avoid machine learning pitfalls},
	url = {http://arxiv.org/abs/2108.02497},
	abstract = {This document gives a concise outline of some of the common mistakes that occur when using machine learning techniques, and what can be done to avoid them. It is intended primarily as a guide for research students, and focuses on issues that are of particular concern within academic research, such as the need to do rigorous comparisons and reach valid conclusions. It covers five stages of the machine learning process: what to do before model building, how to reliably build models, how to robustly evaluate models, how to compare models fairly, and how to report results.},
	urldate = {2021-09-23},
	journal = {arXiv:2108.02497 [cs]},
	author = {Lones, Michael A.},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.02497},
	keywords = {general},
}

@article{DualProcessTheoriesHigherCognitionAdvancing,
	title = {Dual-{Process} {Theories} of {Higher} {Cognition}: {Advancing} the {Debate}},
	volume = {8},
	issn = {1745-6916},
	shorttitle = {Dual-{Process} {Theories} of {Higher} {Cognition}},
	url = {https://doi.org/10.1177/1745691612460685},
	doi = {10.1177/1745691612460685},
	abstract = {Dual-process and dual-system theories in both cognitive and social psychology have been subjected to a number of recently published criticisms. However, they have been attacked as a category, incorrectly assuming there is a generic version that applies to all. We identify and respond to 5 main lines of argument made by such critics. We agree that some of these arguments have force against some of the theories in the literature but believe them to be overstated. We argue that the dual-processing distinction is supported by much recent evidence in cognitive science. Our preferred theoretical approach is one in which rapid autonomous processes (Type 1) are assumed to yield default responses unless intervened on by distinctive higher order reasoning processes (Type 2). What defines the difference is that Type 2 processing supports hypothetical thinking and load heavily on working memory.},
	number = {3},
	urldate = {2021-09-25},
	journal = {Perspectives on Psychological Science},
	author = {Evans, Jonathan St. B. T. and Stanovich, Keith E.},
	month = may,
	year = {2013},
	note = {Publisher: SAGE Publications Inc},
	keywords = {cognitive, explanation, well-written},
	pages = {223--241},
}

@article{DeepEnsembleModelSlotAlignment,
	title = {A {Deep} {Ensemble} {Model} with {Slot} {Alignment} for {Sequence}-to-{Sequence} {Natural} {Language} {Generation}},
	url = {http://arxiv.org/abs/1805.06553},
	abstract = {Natural language generation lies at the core of generative dialogue systems and conversational agents. We describe an ensemble neural language generator, and present several novel methods for data representation and augmentation that yield improved results in our model. We test the model on three datasets in the restaurant, TV and laptop domains, and report both objective and subjective evaluations of our best model. Using a range of automatic metrics, as well as human evaluators, we show that our approach achieves better results than state-of-the-art models on the same datasets.},
	urldate = {2021-09-24},
	journal = {arXiv:1805.06553 [cs]},
	author = {Juraska, Juraj and Karagiannis, Panagiotis and Bowden, Kevin K. and Walker, Marilyn A.},
	month = may,
	year = {2018},
	note = {arXiv: 1805.06553},
	keywords = {explanation, generation},
}

@inproceedings{E2ENLGChallengeNeuralModels,
	address = {Tilburg University, The Netherlands},
	title = {{E2E} {NLG} {Challenge}: {Neural} {Models} vs. {Templates}},
	shorttitle = {{E2E} {NLG} {Challenge}},
	url = {https://aclanthology.org/W18-6557},
	doi = {10.18653/v1/W18-6557},
	abstract = {E2E NLG Challenge is a shared task on generating restaurant descriptions from sets of key-value pairs. This paper describes the results of our participation in the challenge. We develop a simple, yet effective neural encoder-decoder model which produces fluent restaurant descriptions and outperforms a strong baseline. We further analyze the data provided by the organizers and conclude that the task can also be approached with a template-based model developed in just a few hours.},
	urldate = {2021-09-24},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Natural} {Language} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Puzikov, Yevgeniy and Gurevych, Iryna},
	month = nov,
	year = {2018},
	keywords = {explanation, generation},
	pages = {463--471},
}

@article{WeightEvidenceBasisHumanOrientedExplanations,
	title = {Weight of {Evidence} as a {Basis} for {Human}-{Oriented} {Explanations}},
	url = {http://arxiv.org/abs/1910.13503},
	abstract = {Interpretability is an elusive but highly sought-after characteristic of modern machine learning methods. Recent work has focused on interpretability via \${\textbackslash}textit\{explanations\}\$, which justify individual model predictions. In this work, we take a step towards reconciling machine explanations with those that humans produce and prefer by taking inspiration from the study of explanation in philosophy, cognitive science, and the social sciences. We identify key aspects in which these human explanations differ from current machine explanations, distill them into a list of desiderata, and formalize them into a framework via the notion of \${\textbackslash}textit\{weight of evidence\}\$ from information theory. Finally, we instantiate this framework in two simple applications and show it produces intuitive and comprehensible explanations.},
	urldate = {2021-09-24},
	journal = {arXiv:1910.13503 [cs, stat]},
	author = {Alvarez-Melis, David and Daumé III, Hal and Vaughan, Jennifer Wortman and Wallach, Hanna},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.13503},
	keywords = {explanation, generation},
}

@inproceedings{RoleDemographicsTrustComputerSelfefficacy,
	address = {Menlo Park and San Jose CA USA},
	title = {The {Role} of {Demographics}, {Trust}, {Computer} {Self}-efficacy, and {Ease} of {Use} in the {Sharing} {Economy}},
	isbn = {978-1-4503-5816-3},
	url = {https://dl.acm.org/doi/10.1145/3209811.3209816},
	doi = {10.1145/3209811.3209816},
	abstract = {The digital sharing economy has introduced opportunities for economic growth, productivity, and technological innovation. However, the adoption of sharing economy applications may be inaccessible to certain demographics, including older adults, low-income adults, and individuals who are not college educated. This research investigates how the demographic factors: trust, computer self-efficacy, and perceived ease of use, impact participation in the sharing economy. Drawing on survey data with 508 participants, we found that trust in institutions, computer self-efficacy, and perceived ease of use positively correlate to individuals’ past use of and willingness to pay for future sharing economy services, but age is negatively correlated. Surprisingly, we do not find that sharing economy users are more likely to have higher trust in strangers, higher incomes, or more education. We compare our findings to existing research, discuss why institutional trust might negate other concerns about sharing economy use, and explore opportunities to support broader participation in the sharing economy.},
	language = {en},
	urldate = {2021-09-27},
	booktitle = {Proceedings of the 1st {ACM} {SIGCAS} {Conference} on {Computing} and {Sustainable} {Societies}},
	publisher = {ACM},
	author = {Hsiao, Joey Chiao-Yin and Moser, Carol and Schoenebeck, Sarita and Dillahunt, Tawanna R.},
	month = jun,
	year = {2018},
	keywords = {cognitive, self-efficacy},
	pages = {1--11},
}

@article{AnalogicalComparisonPromotesTheoryofMindDevelopment,
	title = {Analogical {Comparison} {Promotes} {Theory}-of-{Mind} {Development}},
	volume = {44},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12891},
	doi = {10.1111/cogs.12891},
	abstract = {Theory-of-mind (ToM) is an integral part of social cognition, but how it develops remains a critical question. There is evidence that children can gain insight into ToM through experience, including language training and explanatory interactions. But this still leaves open the question of how children gain these insights—what processes drive this learning? We propose that analogical comparison is a key mechanism in the development of ToM. In Experiment 1, children were shown true- and false-belief scenarios and prompted to engage in multiple comparisons (e.g., belief vs. world). In Experiments 2a, 2b, and 3, children saw a series of true- and false-belief events, varying in order and in their alignability. Across these experiments, we found that providing support for comparing true- and false-belief scenarios led to increased performance on false-belief tests. These findings show that analogical comparison can support ToM learning.},
	language = {en},
	number = {9},
	urldate = {2021-09-27},
	journal = {Cognitive Science},
	author = {Hoyos, Christian and Horton, William S. and Simms, Nina K. and Gentner, Dedre},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12891},
	keywords = {social-cognition},
	pages = {e12891},
}

@article{ImprovingHumanDecisionMakingCaseBased,
	title = {Improving {Human} {Decision} {Making} through {Case}-{Based} {Decision} {Aiding}},
	language = {en},
	author = {Kolodner, Janet L},
	pages = {17},
}

@article{RelatingDecisionMakingStylesSocial,
	title = {Relating {Decision}‐{Making} {Styles} to {Social} {Orientation} and {Time} {Approach}},
	volume = {31},
	issn = {0894-3257},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6032938/},
	doi = {10.1002/bdm.2066},
	abstract = {Research on decision‐making styles has shown that stylistic differences matter for real‐life outcomes, but less research has explored how styles relate to other differences between individuals. Heeding a call for a more systematic and theoretically sound understanding of decision‐making styles, we investigated the relation between decision‐making styles and specific aspects of social orientation and approach to time in two samples (students, n = 118, and police investigators, n = 90). The results of regression analyses showed that decision‐making styles are related to specific differences in social orientation and time approach. Furthermore, results of structural equation model analyses suggested possible adjustments to the proposed two‐factor model for decision‐making styles (Dewberry, Juanchich, \& Narendran, ). © 2017 The Authors Journal of Behavioral Decision Making Published by John Wiley \& Sons Ltd.},
	number = {3},
	urldate = {2021-09-27},
	journal = {Journal of Behavioral Decision Making},
	author = {Geisler, Martin and Allwood, Carl Martin},
	month = jul,
	year = {2018},
	pmid = {30008515},
	pmcid = {PMC6032938},
	keywords = {explanation},
	pages = {415--429},
}

@article{ThinkingFastSlowCBRPerspective,
	title = {Thinking {Fast} and {Slow}: {A} {CBR} {Perspective}},
	volume = {34},
	issn = {2334-0762},
	shorttitle = {Thinking {Fast} and {Slow}},
	url = {https://journals.flvc.org/FLAIRS/article/view/128572},
	doi = {10.32473/flairs.v34i1.128572},
	abstract = {In a path-breaking work, Kahneman characterized human cognition as a result of two modes of operation, Fast Thinking and Slow Thinking. Fast thinking involves quick, intuitive decision making and slow thinking is deliberative conscious reasoning. In this paper, for the ﬁrst time, we draw parallels between this dichotomous model of human cognition and decision making in Case-based Reasoning (CBR). We observe that fast thinking can be operationalized computationally as the fast decision making by a trained machine learning model, or a parsimonious CBR system that uses few attributes. On the other hand, a full-ﬂedged CBR system may be seen as similar to the slow thinking process. We operationalize such computational models of fast and slow thinking and switching strategies, as Models 1 and 2. Further, we explore the adaptation process in CBR as a slow thinking manifestation, leading to Model 3. Through an extensive set of experiments on real-world datasets, we show that such realizations of fast and slow thinking are useful in practice, leading to improved accuracies in decision-making tasks.},
	language = {en},
	number = {1},
	urldate = {2021-09-26},
	journal = {The International FLAIRS Conference Proceedings},
	author = {Kaurav, Srashti and Ganesan, Devi and P, Deepak and Chakraborti, Sutanu},
	month = apr,
	year = {2021},
}

@article{DREXDialogueRelationExtractionExplanations,
	title = {D-{REX}: {Dialogue} {Relation} {Extraction} with {Explanations}},
	shorttitle = {D-{REX}},
	url = {http://arxiv.org/abs/2109.05126},
	abstract = {Existing research studies on cross-sentence relation extraction in long-form multi-party conversations aim to improve relation extraction without considering the explainability of such methods. This work addresses that gap by focusing on extracting explanations that indicate that a relation exists while using only partially labeled data. We propose our model-agnostic framework, D-REX, a policy-guided semi-supervised algorithm that explains and ranks relations. We frame relation extraction as a re-ranking task and include relation- and entity-specific explanations as an intermediate step of the inference process. We find that about 90\% of the time, human annotators prefer D-REX's explanations over a strong BERT-based joint relation extraction and explanation model. Finally, our evaluations on a dialogue relation extraction dataset show that our method is simple yet effective and achieves a state-of-the-art F1 score on relation extraction, improving upon existing methods by 13.5\%.},
	urldate = {2021-09-30},
	journal = {arXiv:2109.05126 [cs]},
	author = {Albalak, Alon and Embar, Varun and Tuan, Yi-Lin and Getoor, Lise and Wang, William Yang},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.05126},
}

@article{LocalExplanationDialogueResponseGeneration,
	title = {Local {Explanation} of {Dialogue} {Response} {Generation}},
	url = {http://arxiv.org/abs/2106.06528},
	abstract = {In comparison to the interpretation of classification models, the explanation of sequence generation models is also an important problem, however it has seen little attention. In this work, we study model-agnostic explanations of a representative text generation task -- dialogue response generation. Dialog response generation is challenging with its open-ended sentences and multiple acceptable responses. To gain insights into the reasoning process of a generation model, we propose anew method, local explanation of response generation (LERG) that regards the explanations as the mutual interaction of segments in input and output sentences. LERG views the sequence prediction as uncertainty estimation of a human response and then creates explanations by perturbing the input and calculating the certainty change over the human response. We show that LERG adheres to desired properties of explanations for text generation including unbiased approximation, consistency and cause identification. Empirically, our results show that our method consistently improves other widely used methods on proposed automatic- and human- evaluation metrics for this new task by 4.4-12.8\%. Our analysis demonstrates that LERG can extract both explicit and implicit relations between input and output segments.},
	urldate = {2021-09-30},
	journal = {arXiv:2106.06528 [cs, stat]},
	author = {Tuan, Yi-Lin and Pryor, Connor and Chen, Wenhu and Getoor, Lise and Wang, William Yang},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.06528},
	keywords = {explanation, generation},
}

@inproceedings{EndtoEndContentPlanSelectionDatatoText,
	address = {Tilburg University, The Netherlands},
	title = {End-to-{End} {Content} and {Plan} {Selection} for {Data}-to-{Text} {Generation}},
	url = {https://aclanthology.org/W18-6505},
	doi = {10.18653/v1/W18-6505},
	abstract = {Learning to generate fluent natural language from structured data with neural networks has become an common approach for NLG. This problem can be challenging when the form of the structured data varies between examples. This paper presents a survey of several extensions to sequence-to-sequence models to account for the latent content selection process, particularly variants of copy attention and coverage decoding. We further propose a training method based on diverse ensembling to encourage models to learn distinct sentence templates during training. An empirical evaluation of these techniques shows an increase in the quality of generated text across five automated metrics, as well as human evaluation.},
	urldate = {2021-09-30},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Natural} {Language} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Gehrmann, Sebastian and Dai, Falcon and Elder, Henry and Rush, Alexander},
	month = nov,
	year = {2018},
	keywords = {explanation, generation},
	pages = {46--56},
}

@article{RELATIONSHIPSELFEFFICACYDECISIONMAKING,
	title = {{THE} {RELATIONSHIP} {BETWEEN} {SELF} {EFFICACY} {AND} {DECISION} {MAKING} {ON} {ACADEMIC} {PERFORMANCE} {OF} {ADOLESCENTS}},
	abstract = {The aim of the study is to analyze the relationship between self efficacy and decision making skills and Academic Performance of secondary education students and to find out whether there is a significant difference in adolescent’s decision-making behaviors, from the aspect of some socio-demographic variables(gender, age, school type and education level of the parents). For this purpose, 50 subjects (male and female) from secondary education students were given The Scale of Decision Making Behaviors (Radford, Mann,) and also Bundara Self Efficacy scale. This research aims at looking at the combined impact of Decision making and Self Efficacy on scholastic academic achievement of students in the context of urban India. The findings could act as an eye opener for school authorities who generally do not accord much importance to these factors.},
	language = {en},
	author = {Rai, Sujata},
	pages = {4},
}

@article{Visualizationpatentspapersterahertztechnology,
	title = {Visualization of patents and papers in terahertz technology: a comparative study},
	volume = {94},
	issn = {0138-9130, 1588-2861},
	shorttitle = {Visualization of patents and papers in terahertz technology},
	url = {http://link.springer.com/10.1007/s11192-012-0782-x},
	doi = {10.1007/s11192-012-0782-x},
	abstract = {Terahertz technology is one of the most promising research areas in the 21st century. In this work, we intend to compare the research status quo on terahertz technology between 1990 and 2010 using knowledge domain visualization techniques. Our data consists of 633 patents retrieved from Aureka management platform and 10,344 journal articles indexed in the ISI web of knowledge. Our analysis is a combination of two information visualization tools for analysis, Aureka and CiteSpace. Aureka is allowed for the analysis of patents ﬁled/granted each year, priority country, inventors, assignees, citation counting, and cluster analysis, while networks of co-authors, countries, institutions, document co-citation networks and document co-citation clusters, are performed by CiteSpace. This research provides a comprehensive domain visualization map of innovation and knowledge in the area of terahertz technology. Our result shows that Aureka and CiteSpace are two promising visualization approaches to analyze patents and papers in any given ﬁeld.},
	language = {en},
	number = {3},
	urldate = {2021-10-01},
	journal = {Scientometrics},
	author = {Liu, Guifeng},
	month = mar,
	year = {2013},
	keywords = {vis},
	pages = {1037--1056},
}

@article{Project412ConnectBridgingStudentsCommunitiesa,
	title = {Project {412Connect}: {Bridging} {Students} and {Communities}},
	issn = {1556-5068},
	shorttitle = {Project {412Connect}},
	url = {https://www.ssrn.com/abstract=3923036},
	doi = {10.2139/ssrn.3923036},
	abstract = {In this work, we describe some of the challenges Black-owned businesses face in the United States and specifically in the city of Pittsburgh. Taking into account local dynamics and the communicated desires of Black-owned businesses in the Pittsburgh region, we determine that university students represent an under-utilized market for these businesses. We investigate the root causes for this inefficiency and design and implement a platform, 412Connect (https://www.412connect.org/), to increase online support for Pittsburgh Black-owned businesses from students in the Pittsburgh university community.},
	language = {en},
	urldate = {2021-09-30},
	journal = {SSRN Electronic Journal},
	author = {DiChristofano, Alex and Hamilton, Michael and Linardi, Sera and McCloud, Mara},
	year = {2021},
}

@article{ChallengesDatatoDocumentGenerationa,
	title = {Challenges in {Data}-to-{Document} {Generation}},
	url = {http://arxiv.org/abs/1707.08052},
	abstract = {Recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records. In this work, we suggest a slightly more difficult data-to-text generation task, and investigate how effective current approaches are on this task. In particular, we introduce a new, large-scale corpus of data records paired with descriptive documents, propose a series of extractive evaluation methods for analyzing performance, and obtain baseline results using current neural generation methods. Experiments show that these models produce fluent text, but fail to convincingly approximate human-generated documents. Moreover, even templated baselines exceed the performance of these neural models on some metrics, though copy- and reconstruction-based extensions lead to noticeable improvements.},
	urldate = {2021-09-30},
	journal = {arXiv:1707.08052 [cs]},
	author = {Wiseman, Sam and Shieber, Stuart M. and Rush, Alexander M.},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.08052},
	keywords = {explanation, generation},
}

@article{HumanintheloopExtractionInterpretableConceptsDeep,
	title = {Human-in-the-loop {Extraction} of {Interpretable} {Concepts} in {Deep} {Learning} {Models}},
	url = {http://arxiv.org/abs/2108.03738},
	abstract = {The interpretation of deep neural networks (DNNs) has become a key topic as more and more people apply them to solve various problems and making critical decisions. Concept-based explanations have recently become a popular approach for post-hoc interpretation of DNNs. However, identifying human-understandable visual concepts that affect model decisions is a challenging task that is not easily addressed with automatic approaches. We present a novel human-in-the-loop approach to generate user-defined concepts for model interpretation and diagnostics. Central to our proposal is the use of active learning, where human knowledge and feedback are combined to train a concept extractor with very little human labeling effort. We integrate this process into an interactive system, ConceptExtract. Through two case studies, we show how our approach helps analyze model behavior and extract human-friendly concepts for different machine learning tasks and datasets and how to use these concepts to understand the predictions, compare model performance and make suggestions for model refinement. Quantitative experiments show that our active learning approach can accurately extract meaningful visual concepts. More importantly, by identifying visual concepts that negatively affect model performance, we develop the corresponding data augmentation strategy that consistently improves model performance.},
	urldate = {2021-09-30},
	journal = {arXiv:2108.03738 [cs]},
	author = {Zhao, Zhenge and Xu, Panpan and Scheidegger, Carlos and Ren, Liu},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.03738},
	keywords = {ESCAPE, interpretable, vis},
}

@article{DatatoTextGenerationContentSelectionPlanning,
	title = {Data-to-{Text} {Generation} with {Content} {Selection} and {Planning}},
	url = {http://arxiv.org/abs/1809.00582},
	abstract = {Recent advances in data-to-text generation have led to the use of large-scale datasets and neural network models which are trained end-to-end, without explicitly modeling what to say and in what order. In this work, we present a neural network architecture which incorporates content selection and planning without sacrificing end-to-end training. We decompose the generation task into two stages. Given a corpus of data records (paired with descriptive documents), we first generate a content plan highlighting which information should be mentioned and in which order and then generate the document while taking the content plan into account. Automatic and human-based evaluation experiments show that our model outperforms strong baselines improving the state-of-the-art on the recently released RotoWire dataset.},
	urldate = {2021-09-30},
	journal = {arXiv:1809.00582 [cs]},
	author = {Puduppully, Ratish and Dong, Li and Lapata, Mirella},
	month = apr,
	year = {2019},
	note = {arXiv: 1809.00582},
	keywords = {explanation, generation},
}

@article{WhenLikelyUnlikelyInvestigatingVariability,
	title = {When is {Likely} {Unlikely}: {Investigating} the {Variability} of {Vagueness}},
	abstract = {An important part of explaining how people communicate is to understand how people relate language to entities in the world. In describing measurements, people prefer to use qualitative words like ‘tall’ without precise applicability conditions, also known as vague words. The use of vague language varies widely across contexts, individuals, and tasks (single reference vs. comparisons between targets), but despite this variability, is used quite successfully. A potential strategy for using vague language is to leverage the set of alternative descriptors to settle on the best option. To determine whether people use this strategy, we conducted an experiment where participants picked vague words from sets of alternatives to describe either probability or color values. We varied the set of alternatives from which participants could choose. Empirical evidence supports the hypothesis that people use the set of available options to pick vague descriptors. The theoretical implications of this work are discussed.},
	language = {en},
	author = {Persaud, Kimele and McMahan, Brian and Alikhani, Malihe and Pei, Kevin and Hemmer, Pernille and Stone, Matthew},
	keywords = {explanation, generation},
	pages = {6},
}

@article{ProceedingsLREC2018Workshop1st,
	title = {Proceedings of the {LREC} 2018 {Workshop} 1st {Workshop} on {Language} {Resources} and {Technologies} for the {Legal} {Knowledge} {Graph}},
	language = {en},
	author = {Rehm, Edited Georg and Rodríguez-Doncel, Víctor and Moreno-Schneider, Julián},
	keywords = {vis},
	pages = {56},
}

@article{Documentvisualizationoverviewcurrentresearch,
	title = {Document visualization: an overview of current research},
	volume = {6},
	issn = {1939-0068},
	shorttitle = {Document visualization},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1285},
	doi = {10.1002/wics.1285},
	abstract = {As the number of sources and quantity of document information explodes, efficient and intuitive visualization tools are desperately needed to assist users in understanding the contents and features of a document, while discovering hidden information. This overview introduces fundamental concepts of and designs for document visualization, a number of representative methods in the field, and challenges as well as promising directions of future development. The focus is on explaining the rationale and characteristics of representative document visualization methods for each category. A discussion of the limitations of our classification and a comparison of reviewed methods are presented at the end. This overview also aims to point out theoretical and practical challenges in document visualization. WIREs Comput Stat 2014, 6:19–36. doi: 10.1002/wics.1285 This article is categorized under: Algorithms and Computational Methods {\textgreater} Computer Graphics Statistical Learning and Exploratory Methods of the Data Sciences {\textgreater} Text Mining},
	language = {en},
	number = {1},
	urldate = {2021-10-01},
	journal = {WIREs Computational Statistics},
	author = {Gan, Qihong and Zhu, Min and Li, Mingzhao and Liang, Ting and Cao, Yu and Zhou, Baoyao},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1285},
	pages = {19--36},
}

@article{NatureEverydayProspectionReviewTheoretical,
	title = {On the {Nature} of {Everyday} {Prospection}: {A} {Review} and {Theoretical} {Integration} of {Research} on {Mind}-{Wandering}, {Future} {Thinking}, and {Prospective} {Memory}},
	volume = {24},
	issn = {1089-2680},
	shorttitle = {On the {Nature} of {Everyday} {Prospection}},
	url = {https://doi.org/10.1177/1089268020918843},
	doi = {10.1177/1089268020918843},
	abstract = {The ability to imagine and simulate events that may happen in the future has been studied in several related but independent research areas (e.g., episodic future thinking, mind-wandering, prospective memory), with a newly emerging field of involuntary future thinking focusing primarily on the spontaneous occurrence of such thoughts. In this article, we review evidence from these diverse fields to address important questions about why do people think about the future, what are the typical and most frequent contents of such thoughts, and how do these thoughts occur (are they spontaneous or constructed deliberately). Results of the literature review provide support for the pragmatic theory of prospection, by showing that when people engage in prospective thought naturally, without being explicitly instructed to do so, they predominantly think about their upcoming tasks and planned activities instead of simulating plausible but novel hypothetical scenarios. Moreover, prospective thoughts are more often spontaneous than deliberate and effortful, and their occurrence seems to increase the likelihood of planned activities being completed in the future. The findings are discussed in the context of a new ?pragmatic dual process account? of future thinking, and new avenues for future research on prospection are outlined.},
	number = {3},
	urldate = {2021-10-02},
	journal = {Review of General Psychology},
	author = {Kvavilashvili, Lia and Rummel, Jan},
	month = sep,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	keywords = {attribution},
	pages = {210--237},
}

@article{examinationgeneraldecisionmakingstyle,
	title = {An examination of the general decision making style questionnaire in two {UK} samples},
	volume = {20},
	issn = {0268-3946},
	url = {https://www.emerald.com/insight/content/doi/10.1108/02683940510579777/full/html},
	doi = {10.1108/02683940510579777},
	abstract = {Purpose – To examine the psychometric properties and construct validity of the general decision making style (GDMS) questionnaire in two UK samples. Design/methodology/approach – The GDMS takes the form of a self-report questionnaire which identiﬁes ﬁve decision making styles: rational, intuitive, dependent, avoidant, and spontaneous. It was administered to samples of business studies undergraduates in two UK business schools. Analyses included scale reliabilities, test-re-test reliability, and both exploratory and conﬁrmatory factor analyses.},
	language = {en},
	number = {2},
	urldate = {2021-10-02},
	journal = {Journal of Managerial Psychology},
	author = {Spicer, David P. and Sadler‐Smith, Eugene},
	month = mar,
	year = {2005},
	pages = {137--149},
}

@article{DualProcessingAccountsReasoningJudgmentSocial,
	title = {Dual-{Processing} {Accounts} of {Reasoning}, {Judgment}, and {Social} {Cognition}},
	volume = {59},
	issn = {0066-4308, 1545-2085},
	url = {http://www.annualreviews.org/doi/10.1146/annurev.psych.59.103006.093629},
	doi = {10.1146/annurev.psych.59.103006.093629},
	abstract = {This article reviews a diverse set of proposals for dual processing in higher cognition within largely disconnected literatures in cognitive and social psychology. All these theories have in common the distinction between cognitive processes that are fast, automatic, and unconscious and those that are slow, deliberative, and conscious. A number of authors have recently suggested that there may be two architecturally (and evolutionarily) distinct cognitive systems underlying these dual-process accounts. However, it emerges that (a) there are multiple kinds of implicit processes described by different theorists and (b) not all of the proposed attributes of the two kinds of processing can be sensibly mapped on to two systems as currently conceived. It is suggested that while some dual-process theories are concerned with parallel competing processes involving explicit and implicit knowledge systems, others are concerned with the inﬂuence of preconscious processes that contextualize and shape deliberative reasoning and decision-making.},
	language = {en},
	number = {1},
	urldate = {2021-10-02},
	journal = {Annual Review of Psychology},
	author = {Evans, Jonathan St. B. T.},
	month = jan,
	year = {2008},
	pages = {255--278},
}

@article{Spontaneousdeliberatefuturethinkingdual,
	title = {Spontaneous and deliberate future thinking: a dual process account},
	volume = {85},
	issn = {0340-0727, 1430-2772},
	shorttitle = {Spontaneous and deliberate future thinking},
	url = {http://link.springer.com/10.1007/s00426-019-01262-7},
	doi = {10.1007/s00426-019-01262-7},
	abstract = {In this article, we address an apparent paradox in the literature on mental time travel and mind-wandering: How is it possible that future thinking is both constructive, yet often experienced as occurring spontaneously? We identify and describe two ‘routes’ whereby episodic future thoughts are brought to consciousness, with each of the ‘routes’ being associated with separable cognitive processes and functions. Voluntary future thinking relies on controlled, deliberate and slow cognitive processing. The other, termed involuntary or spontaneous future thinking, relies on automatic processes that allows ‘fullyfledged’ episodic future thoughts to freely come to mind, often triggered by internal or external cues. To unravel the paradox, we propose that the majority of spontaneous future thoughts are ‘pre-made’ (i.e., each spontaneous future thought is a reiteration of a previously constructed future event), and therefore based on simple, well-understood, memory processes. We also propose that the pre-made hypothesis explains why spontaneous future thoughts occur rapidly, are similar to involuntary memories, and predominantly about upcoming tasks and goals. We also raise the possibility that spontaneous future thinking is the default mode of imagining the future. This dual process approach complements and extends standard theoretical approaches that emphasise constructive simulation, and outlines novel opportunities for researchers examining voluntary and spontaneous forms of future thinking.},
	language = {en},
	number = {2},
	urldate = {2021-10-02},
	journal = {Psychological Research},
	author = {Cole, Scott and Kvavilashvili, Lia},
	month = mar,
	year = {2021},
	keywords = {attribution},
	pages = {464--479},
}

@article{comparisonthreemeasurescognitiveload,
	title = {A comparison of three measures of cognitive load: {Evidence} for separable measures of intrinsic, extraneous, and germane load.},
	volume = {100},
	issn = {1939-2176, 0022-0663},
	shorttitle = {A comparison of three measures of cognitive load},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0022-0663.100.1.223},
	doi = {10.1037/0022-0663.100.1.223},
	abstract = {Understanding how to measure cognitive load is a fundamental challenge for cognitive load theory. In 2 experiments, 155 college students (ages ϭ 17 to 22; 49 men and 106 women) with low domain knowledge learned from a multimedia lesson on electric motors. At 8 points during learning, their cognitive load was measured via self-report scales (mental effort ratings) and response time to a secondary visual monitoring task, and they completed a difficulty rating scale at the end of the lesson. Correlations among the three measures were generally low. Analyses of variance indicated that the response time measure was most sensitive to manipulations of extraneous processing (created by adding redundant text), effort ratings were most sensitive to manipulations of intrinsic processing (created by sentence complexity), and difficulty ratings were most sensitive to indications of germane processing (reflected by transfer test performance). Results are consistent with a triarchic theory of cognitive load in which different aspects of cognitive load may be tapped by different measures of cognitive load.},
	language = {en},
	number = {1},
	urldate = {2021-10-02},
	journal = {Journal of Educational Psychology},
	author = {DeLeeuw, Krista E. and Mayer, Richard E.},
	year = {2008},
	pages = {223--234},
}

@article{theoryoutofdistributionlearning,
	title = {Towards a theory of out-of-distribution learning},
	url = {http://arxiv.org/abs/2109.14501},
	abstract = {What is learning? 20 century formalizations of learning theory -- which precipitated revolutions in artificial intelligence -- focus primarily on {\textbackslash}textit\{in-distribution\} learning, that is, learning under the assumption that the training data are sampled from the same distribution as the evaluation distribution. This assumption renders these theories inadequate for characterizing 21\${\textasciicircum}\{st\}\$ century real world data problems, which are typically characterized by evaluation distributions that differ from the training data distributions (referred to as out-of-distribution learning). We therefore make a small change to existing formal definitions of learnability by relaxing that assumption. We then introduce {\textbackslash}textbf\{learning efficiency\} (LE) to quantify the amount a learner is able to leverage data for a given problem, regardless of whether it is an in- or out-of-distribution problem. We then define and prove the relationship between generalized notions of learnability, and show how this framework is sufficiently general to characterize transfer, multitask, meta, continual, and lifelong learning. We hope this unification helps bridge the gap between empirical practice and theoretical guidance in real world problems. Finally, because biological learning continues to outperform machine learning algorithms on certain OOD challenges, we discuss the limitations of this framework vis-{\textbackslash}'a-vis its ability to formalize biological learning, suggesting multiple avenues for future research.},
	urldate = {2021-10-02},
	journal = {arXiv:2109.14501 [cs, stat]},
	author = {Geisa, Ali and Mehta, Ronak and Helm, Hayden S. and Dey, Jayanta and Eaton, Eric and Priebe, Carey E. and Vogelstein, Joshua T.},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.14501
version: 1},
	keywords = {ESCAPE, ood, uu},
}

@article{FindingContextuallyConsistentInformationUnits,
	title = {Finding {Contextually} {Consistent} {Information} {Units} in {Legal} {Text}},
	abstract = {Terms in the laws of a legislature can be highly contextual: especially for corpora of codified laws and regulations where the reader has to be aware of the correct context when the corpus lacks a single level of hierarchy. The goal of this work is to assist professionals when reading legal text within a codified corpus by finding contextually consistent information units. To achieve this, we combine NLP and data mining techniques to develop novel methodology that can find these information units in an unsupervised manner. Our method draws on expert experience and is modeled to emulate the “contextualization process” of experienced readers of legal content. We experimentally evaluate our method by comparing it to multiple expert-annotated datasets and find that our method achieves near perfect performance on four state corpora and high precision on one federal corpus.},
	language = {en},
	journal = {San Diego},
	author = {Seyler, Dominic and Bruin, Paul and Bayyapu, Pavan and Zhai, ChengXiang},
	year = {2020},
	pages = {4},
}

@article{ChallengesDatatoDocumentGeneration,
	title = {Challenges in {Data}-to-{Document} {Generation}},
	url = {http://arxiv.org/abs/1707.08052},
	abstract = {Recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records. In this work, we suggest a slightly more difficult data-to-text generation task, and investigate how effective current approaches are on this task. In particular, we introduce a new, large-scale corpus of data records paired with descriptive documents, propose a series of extractive evaluation methods for analyzing performance, and obtain baseline results using current neural generation methods. Experiments show that these models produce fluent text, but fail to convincingly approximate human-generated documents. Moreover, even templated baselines exceed the performance of these neural models on some metrics, though copy- and reconstruction-based extensions lead to noticeable improvements.},
	urldate = {2021-10-03},
	journal = {arXiv:1707.08052 [cs]},
	author = {Wiseman, Sam and Shieber, Stuart M. and Rush, Alexander M.},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.08052},
	keywords = {data-to-text, explanation, generation},
}

@article{attributionalStyleQuestionnaire,
	title = {The attributional {Style} {Questionnaire}},
	volume = {6},
	issn = {0147-5916, 1573-2819},
	url = {http://link.springer.com/10.1007/BF01173577},
	doi = {10.1007/BF01173577},
	language = {en},
	number = {3},
	urldate = {2021-10-03},
	journal = {Cognitive Therapy and Research},
	author = {Peterson, Christopher and Semmel, Amy and von Baeyer, Carl and Abramson, Lyn Y. and Metalsky, Gerald I. and Seligman, Martin E. P.},
	month = sep,
	year = {1982},
	pages = {287--299},
}

@misc{Howdistinctareintuitiondeliberation,
	title = {How distinct are intuition and deliberation? {An} eye-tracking analysis of instruction-induced decision modes},
	url = {http://journal.sjdm.org/9323/jdm9323.html},
	urldate = {2021-10-10},
	keywords = {explanation, eye-tracking},
}

@article{Generatingexplanationsanalogicalcomparison,
	title = {Generating explanations via analogical comparison},
	volume = {24},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-017-1289-5},
	doi = {10.3758/s13423-017-1289-5},
	language = {en},
	number = {5},
	urldate = {2021-10-10},
	journal = {Psychonomic Bulletin \& Review},
	author = {Hoyos, Christian and Gentner, Dedre},
	month = oct,
	year = {2017},
	pages = {1364--1374},
}

@inproceedings{CognitiveAbilitySusceptibilityFakeNews,
	address = {Honolulu HI USA},
	title = {Beyond {Cognitive} {Ability}: {Susceptibility} to {Fake} {News} {Is} {Also} {Explained} by {Associative} {Inference}},
	isbn = {978-1-4503-6819-3},
	shorttitle = {Beyond {Cognitive} {Ability}},
	url = {https://dl.acm.org/doi/10.1145/3334480.3383077},
	doi = {10.1145/3334480.3383077},
	abstract = {We conducted a preliminary online study (N=261) investigating whether people’s susceptibility to fake news on social media depends on how fake news are associated with real news that they viewed previously, as well as individuals’ cognitive ability. Across two phases, we varied the association in three between-subjects conditions, i.e., associative inference, repetition, and irrelevant (control). Our study results showed limited impact of association type on participants of low cognitive ability. In contrast, for participants of high cognitive ability, their discrimination of fake news from real news tended to be worse for the associative inference condition than for the other two conditions. Thus, our ﬁndings suggest that individuals of high cognitive ability are likely to be susceptible to form the belief of fake news, but differently from those of low cognitive ability.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Extended {Abstracts} of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lee, Sian and Forrest, Joshua P. and Strait, Jessica and Seo, Haeseung and Lee, Dongwon and Xiong, Aiping},
	month = apr,
	year = {2020},
	pages = {1--8},
}

@inproceedings{JustifyingRecommendationsusingDistantlyLabeledReviews,
	address = {Hong Kong, China},
	title = {Justifying {Recommendations} using {Distantly}-{Labeled} {Reviews} and {Fine}-{Grained} {Aspects}},
	url = {https://www.aclweb.org/anthology/D19-1018},
	doi = {10.18653/v1/D19-1018},
	abstract = {Several recent works have considered the problem of generating reviews (or ‘tips’) as a form of explanation as to why a recommendation might match a user’s interests. While promising, we demonstrate that existing approaches struggle (in terms of both quality and content) to generate justiﬁcations that are relevant to users’ decision-making process. We seek to introduce new datasets and methods to address this recommendation justiﬁcation task. In terms of data, we ﬁrst propose an ‘extractive’ approach to identify review segments which justify users’ intentions; this approach is then used to distantly label massive review corpora and construct largescale personalized recommendation justiﬁcation datasets. In terms of generation, we design two personalized generation models with this data: (1) a reference-based Seq2Seq model with aspect-planning which can generate justiﬁcations covering different aspects, and (2) an aspect-conditional masked language model which can generate diverse justiﬁcations based on templates extracted from justiﬁcation histories. We conduct experiments on two real-world datasets which show that our model is capable of generating convincing and diverse justiﬁcations.},
	language = {en},
	urldate = {2021-10-07},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Ni, Jianmo and Li, Jiacheng and McAuley, Julian},
	year = {2019},
	keywords = {explanation, generation},
	pages = {188--197},
}

@article{ControllablePersonalizedReviewGeneration,
	title = {Towards {Controllable} and {Personalized} {Review} {Generation}},
	url = {http://arxiv.org/abs/1910.03506},
	abstract = {In this paper, we propose a novel model RevGAN that automatically generates controllable and personalized user reviews based on the arbitrarily given sentimental and stylistic information. RevGAN utilizes the combination of three novel components, including self-attentive recursive autoencoders, conditional discriminators, and personalized decoders. We test its performance on the several real-world datasets, where our model significantly outperforms state-of-the-art generation models in terms of sentence quality, coherence, personalization and human evaluations. We also empirically show that the generated reviews could not be easily distinguished from the organically produced reviews and that they follow the same statistical linguistics laws.},
	urldate = {2021-10-06},
	journal = {arXiv:1910.03506 [cs, stat]},
	author = {Li, Pan and Tuzhilin, Alexander},
	month = jan,
	year = {2020},
	note = {arXiv: 1910.03506},
	keywords = {explanation, generation},
}

@article{PsychometricpropertiesSpontaneousDeliberateMind,
	title = {Psychometric properties of the {Spontaneous} and {Deliberate} {Mind} {Wandering} {Scales}},
	volume = {35},
	copyright = {© 2018, Hogrefe Publishing},
	issn = {1015-5759},
	url = {http://www.proquest.com/docview/2061182996/abstract/ECAB7D83F4094A31PQ/1},
	doi = {http://dx.doi.org.pitt.idm.oclc.org/10.1027/1015-5759/a000470},
	abstract = {Thinking about task-unrelated matters (mind wandering) is related to cognition and well-being. However, the relations between mind wandering and other psychological variables may depend on whether the former commence spontaneously or deliberately. The current two studies investigated the psychometric properties of the Spontaneous and Deliberate Mind Wandering Scales (SDMWS; Carriere, Seli, \& Smilek, 2013). Study 1 evaluated the stability of the scales over 2 weeks (N = 284 at Time 1), whereas Study 2 (N = 323) evaluated their relations to Generalized anxiety disorder symptoms, Openness, Social desirability, and experience-sampling reports of intentional and unintentional mind wandering during an online cognitive task. The results indicated that the SDMWS were better fitted with a two-factor than a one-factor solution, although the fit was improved with the exclusion of one item. The scales exhibited strong measurement invariance across gender and time, and moderately high test-retest reliability. Spontaneous mind wandering predicted Generalized anxiety disorder and experience-sampling reports of unintentional mind wandering, whereas Deliberate mind wandering predicted Openness and experience-sampling reports of intentional mind wandering. Furthermore, Spontaneous mind wandering showed a negative association with social desirability of weak-to-medium strength. In sum, the scales generally showed favorable psychometric properties. (PsycINFO Database Record (c) 2019 APA, all rights reserved) (Source: journal abstract)},
	language = {English},
	number = {6},
	urldate = {2021-10-05},
	journal = {European Journal of Psychological Assessment},
	author = {Marcusson-Clavertz, David and Kjell, Oscar N. E.},
	year = {2019},
	note = {Num Pages: 878-890
Publisher: Hogrefe Publishing
(Germany)},
	pages = {878--890},
}

@article{GeneratingCounterfactualExplanationsNaturalLanguage,
	title = {Generating {Counterfactual} {Explanations} with {Natural} {Language}},
	abstract = {Natural language explanations of deep neural network decisions provide an intuitive way for a AI agent to articulate a reasoning process. Current textual explanations learn to discuss class discriminative features in an image. However, it is also helpful to understand which attributes might change a classiﬁcation decision if present in an image (e.g., “This is not a Scarlet Tanager because it does not have black wings.”) We call such textual explanations counterfactual explanations, and propose an intuitive method to generate counterfactual explanations by inspecting which evidence in an input is missing, but might contribute to a different classiﬁcation decision if present in the image. To demonstrate our method we consider a ﬁne-grained image classiﬁcation task in which we take as input an image and a counterfactual class and output text which explains why the image does not belong to a counterfactual class. We then analyze our generated counterfactual explanations both qualitatively and quantitatively using proposed automatic metrics.},
	language = {en},
	author = {Hendricks, Lisa Anne and Hu, Ronghang and Darrell, Trevor and Akata, Zeynep},
	keywords = {counterfactual, explanation, generation},
	pages = {4},
}

@article{KG4VisKnowledgeGraphBasedApproachVisualization,
	title = {{KG4Vis}: {A} {Knowledge} {Graph}-{Based} {Approach} for {Visualization} {Recommendation}},
	shorttitle = {{KG4Vis}},
	url = {http://arxiv.org/abs/2107.12548},
	abstract = {Visualization recommendation or automatic visualization generation can significantly lower the barriers for general users to rapidly create effective data visualizations, especially for those users without a background in data visualizations. However, existing rule-based approaches require tedious manual specifications of visualization rules by visualization experts. Other machine learning-based approaches often work like black-box and are difficult to understand why a specific visualization is recommended, limiting the wider adoption of these approaches. This paper fills the gap by presenting KG4Vis, a knowledge graph (KG)-based approach for visualization recommendation. It does not require manual specifications of visualization rules and can also guarantee good explainability. Specifically, we propose a framework for building knowledge graphs, consisting of three types of entities (i.e., data features, data columns and visualization design choices) and the relations between them, to model the mapping rules between data and effective visualizations. A TransE-based embedding technique is employed to learn the embeddings of both entities and relations of the knowledge graph from existing dataset-visualization pairs. Such embeddings intrinsically model the desirable visualization rules. Then, given a new dataset, effective visualizations can be inferred from the knowledge graph with semantically meaningful rules. We conducted extensive evaluations to assess the proposed approach, including quantitative comparisons, case studies and expert interviews. The results demonstrate the effectiveness of our approach.},
	urldate = {2021-10-03},
	journal = {arXiv:2107.12548 [cs]},
	author = {Li, Haotian and Wang, Yong and Zhang, Songheng and Song, Yangqiu and Qu, Huamin},
	month = aug,
	year = {2021},
	note = {arXiv: 2107.12548},
	keywords = {kg, vis},
}

@article{ItMadMadWorldUsing,
	title = {It's a {Mad}, {Mad} {World}: {Using} {Emotion} {Inductions} in a {Survey}},
	volume = {2},
	issn = {2052-2630, 2052-2649},
	shorttitle = {It's a {Mad}, {Mad} {World}},
	url = {https://www.cambridge.org/core/product/identifier/S2052263015000056/type/journal_article},
	doi = {10.1017/XPS.2015.5},
	abstract = {Recent research has uncovered a dynamic role for emotion in political decision-making. Anger in particular has increased in importance as scholars uncover its role in motivating participation and partisanship. One method for examining these effects is to use an induction to invoke an emotion, though such techniques are often limited to the laboratory. We discuss pertinent psychological research on induction, test several methods, and make practical recommendations for political science survey research. Using a unique research design which varies the way anger is invoked, we ﬁrst ﬁnd signiﬁcant effects using a scenario induction. We replicate these ﬁndings with an adult sample and extend the results to political inductions. We are able to offer practical advice to scholars interested in replicating the effects of angry campaign ads or better understanding the effects of anger arousal on political behavior.},
	language = {en},
	number = {2},
	urldate = {2021-10-11},
	journal = {Journal of Experimental Political Science},
	author = {Searles, Kathleen and Mattes, Kyle},
	year = {2015},
	keywords = {experiment,cognitive,emotion-induction},
	pages = {172--182},
}

@article{SimplePessimismEffectsSadnessAnger,
	title = {Beyond {Simple} {Pessimism}: {Effects} of {Sadness} and {Anger} on {Social} {Perception}},
	language = {en},
	author = {Keltner, Dacher and Ellsworth, Phoebe C and Edwards, Kari},
	keywords = {explanation},
	pages = {13},
}

@article{DualSingleProcessModelsThinking,
	title = {On {Dual}- and {Single}-{Process} {Models} of {Thinking}},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691620964172},
	doi = {10.1177/1745691620964172},
	abstract = {Popular dual process models of thinking have long conceived intuition and deliberation as two qualitatively different processes. Single process model proponents claim that the difference is a matter of degree and not of kind. Psychologists have been debating the dual vs single process question for at least 30 years. In the present paper I argue that it is time to leave the debate behind us. I present a critical evaluation of the key arguments and critiques and show that—pace both dual and single model proponents—there is currently no good evidence that allows us to decide the debate. Moreover, I clarify that even if the debate were to be solved, it would be irrelevant for psychologists because it does not advance our understanding of the processing mechanisms underlying human thinking.},
	language = {en},
	urldate = {2021-10-10},
	journal = {Perspectives on Psychological Science},
	author = {De Neys, Wim},
	month = feb,
	year = {2021},
	pages = {174569162096417},
}

@article{Zebraintensivecareunitmetacognitive,
	title = {Zebra in the intensive care unit: a metacognitive reflection on misdiagnosis},
	volume = {14},
	shorttitle = {Zebra in the intensive care unit},
	abstract = {Misdiagnosis of the cause of illness in critically ill patients is common, and a major cause of morbidity and mortality. We reflect upon a misdiagnosis that occurred in the intensive care unit of a metropolitan teaching hospital, and highlight the susceptibility of medical decision making to error. We examine recent advances in cognitive theory and how these apply to diagnosis. We discuss the vulnerability of such processes and - with particular reference to our case - why even knowledgeable and diligent clinicians are prone to misdiagnose. Finally, we review potential solutions, both educational and systemic, that may guard against the inevitable failings of the human mind, especially in a busy modern intensive care setting.},
	journal = {Critical care and resuscitation : journal of the Australasian Academy of Critical Care Medicine},
	author = {Gillon, Stuart and Radford, Sam},
	month = sep,
	year = {2012},
	keywords = {explanation},
	pages = {216--20},
}

@book{Clinicalreasoninghealthprofessions,
	address = {Edinburgh London New York},
	edition = {Fourth edition},
	title = {Clinical reasoning in the health professions},
	isbn = {978-0-7506-8885-7 978-0-7020-6224-7},
	language = {en},
	publisher = {Elsevier},
	editor = {Higgs, Joy and Jensen, Gail M. and Loftus, Stephen and Christensen, Nicole},
	year = {2019},
}

@article{BridgingTextVisualizationMiningTaskDriven,
	title = {Bridging {Text} {Visualization} and {Mining}: {A} {Task}-{Driven} {Survey}},
	volume = {25},
	issn = {1941-0506},
	shorttitle = {Bridging {Text} {Visualization} and {Mining}},
	doi = {10.1109/TVCG.2018.2834341},
	abstract = {Visual text analytics has recently emerged as one of the most prominent topics in both academic research and the commercial world. To provide an overview of the relevant techniques and analysis tasks, as well as the relationships between them, we comprehensively analyzed 263 visualization papers and 4,346 mining papers published between 1992-2017 in two fields: visualization and text mining. From the analysis, we derived around 300 concepts (visualization techniques, mining techniques, and analysis tasks) and built a taxonomy for each type of concept. The co-occurrence relationships between the concepts were also extracted. Our research can be used as a stepping-stone for other researchers to 1) understand a common set of concepts used in this research topic; 2) facilitate the exploration of the relationships between visualization techniques, mining techniques, and analysis tasks; 3) understand the current practice in developing visual text analytics tools; 4) seek potential research opportunities by narrowing the gulf between visualization and mining techniques based on the analysis tasks; and 5) analyze other interdisciplinary research areas in a similar way. We have also contributed a web-based visualization tool for analyzing and understanding research trends and opportunities in visual text analytics.},
	number = {7},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Shixia and Wang, Xiting and Collins, Christopher and Dou, Wenwen and Ouyang, Fangxin and El-Assady, Mennatallah and Jiang, Liu and Keim, Daniel A.},
	month = jul,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {survey, text, vis},
	pages = {2482--2504},
}

@article{GroundingEmotionSituatedConceptualization,
	title = {Grounding {Emotion} in {Situated} {Conceptualization}},
	volume = {49},
	issn = {0028-3932},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3078178/},
	doi = {10.1016/j.neuropsychologia.2010.12.032},
	abstract = {According to the Conceptual Act Theory of Emotion, the situated conceptualization used to construe a situation determines the emotion experienced. A neuroimaging experiment tested two core hypotheses of this theory: (1) different situated conceptualizations produce different forms of the same emotion in different situations, (2) the composition of a situated conceptualization emerges from shared multimodal circuitry distributed across the brain that produces emotional states generally. To test these hypotheses, the situation in which participants experienced an emotion was manipulated. On each trial, participants immersed themselves in a physical danger or social evaluation situation and then experienced fear or anger. According to Hypothesis 1, the brain activations for the same emotion should differ as a function of the preceding situation (after removing activations that arose while constructing the situation). According to Hypothesis 2, the critical activations should reflect conceptual processing relevant to the emotion in the current situation, drawn from shared multimodal circuitry underlying emotion. The results supported these predictions and demonstrated the compositional process that produces situated conceptualizations dynamically.},
	number = {5},
	urldate = {2021-10-12},
	journal = {Neuropsychologia},
	author = {Wilson-Mendenhall, Christine D. and Barrett, Lisa Feldman and Simmons, W. Kyle and Barsalou, Lawrence W.},
	month = apr,
	year = {2011},
	pmid = {21192959},
	pmcid = {PMC3078178},
	keywords = {explanation},
	pages = {1105--1127},
}

@article{IntuitiveCognitionModelsHumanAutomation,
	title = {Intuitive {Cognition} and {Models} of {Human}–{Automation}                     {Interaction}},
	volume = {59},
	issn = {0018-7208},
	url = {https://doi.org/10.1177/0018720816659796},
	doi = {10.1177/0018720816659796},
	abstract = {Objective:The aim of this study was to provide an analysis of the implications of the dominance of intuitive cognition in human reasoning and decision making for conceptualizing models and taxonomies of human?automation interaction, focusing on the Parasuraman et al. model and taxonomy.Background:Knowledge about how humans reason and make decisions, which has been shown to be largely intuitive, has implications for the design of future human?machine systems.Method:One hundred twenty articles and books cited in other works as well as those obtained from an Internet search were reviewed. Works were deemed eligible if they were published within the past 50 years and common to a given literature.Results:Analysis shows that intuitive cognition dominates human reasoning and decision making in all situations examined. The implications of the dominance of intuitive cognition for the Parasuraman et al. model and taxonomy are discussed. A taxonomy of human?automation interaction that incorporates intuitive cognition is suggested.Application:Understanding the ways in which human reasoning and decision making is intuitive can provide insight for future models and taxonomies of human?automation interaction.},
	number = {1},
	urldate = {2021-10-12},
	journal = {Human Factors},
	author = {Patterson, Robert Earl},
	month = feb,
	year = {2017},
	note = {Publisher: SAGE Publications Inc},
	keywords = {cognitive, explanation},
	pages = {101--115},
}

@article{DidthatScareYouTips,
	title = {Did that {Scare} {You}? {Tips} on {Creating} {Emotion} in {Experimental} {Subjects}},
	volume = {24},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Did that {Scare} {You}?},
	url = {https://www.cambridge.org/core/product/identifier/S1047198700014182/type/journal_article},
	doi = {10.1093/pan/mpw022},
	abstract = {The appropriateness of experiments for studying causal mechanisms is well established. However, the ability of an experiment to isolate the effect of emotion has received less attention, and in this letter we lay out a guide to manipulating and tracing the impact of emotions. Some experimental manipulations are straightforward. Manipulating an emotion like anxiety is less obvious. There is no magic “political anxiety pill” and placebo that can be randomly assigned to participants. While the magic political anxiety pill is still elusive, we advocate using multiple manipulations, extensive pretesting, and mediation models. These approaches have allowed us to situate a discrete emotional experience in a complex political environment.},
	language = {en},
	number = {4},
	urldate = {2021-10-11},
	journal = {Political Analysis},
	author = {Albertson, Bethany and Gadarian, Shana Kushner},
	year = {2016},
	keywords = {cognitive, emotion-induction},
	pages = {485--491},
}

@article{EffectsEmotionMedicalDecisionsInvolving,
	title = {Effects of {Emotion} on {Medical} {Decisions} {Involving} {Tradeoffs}},
	volume = {38},
	issn = {0272-989X},
	url = {https://doi.org/10.1177/0272989X18806493},
	doi = {10.1177/0272989X18806493},
	abstract = {Risk perceptions for a disease can motivate use of medications that reduce disease risk. However, these medications are often accompanied by elevated risks for other adverse health effects, and perceived risk of these side effects may also influence decisions. Emotions experienced at the time of a decision influence risk judgments and decision making, and they may be important to examine in these tradeoff contexts. This study examined the effect of experimentally induced fear and anger on risk perceptions and willingness to use a hypothetical medical treatment that attenuates risk of one condition but increases the risk for another. Participants (N = 1948) completed an induction of fear, anger, or neutral emotion and then read about a hypothetical medication that reduced risk for one health condition but increased risk for another, and they indicated their willingness to use it. Deliberative, experiential, and affective risk perceptions about both health conditions were measured, conditional on taking and not taking the medication. Fear condition participants were more willing to take the medication than those in the neutral condition (? = 0.14; P = 0.009; 95\% confidence interval, 0.036?0.25). Fear also increased deliberative, experiential, and affective risk when conditioned on not using the medication, Ps {\textless} 0.05. In contrast, anger did not influence willingness to use the medication (P = 0.22) and increased deliberative and affective risk of side effects when conditioned on using the medication (P {\textless} 0.05). As one of the first studies to examine how emotion influences tradeoff decision making, these findings extend our understanding of how fear and anger influence such decisions.},
	number = {8},
	urldate = {2021-10-11},
	journal = {Medical Decision Making},
	author = {Ellis, Erin M. and Klein, William M.P. and Orehek, Edward and Ferrer, Rebecca A.},
	month = nov,
	year = {2018},
	note = {Publisher: SAGE Publications Inc STM},
	keywords = {cognitive, emotion-induction},
	pages = {1027--1039},
}

@inproceedings{SynthesizingAspectDrivenRecommendationExplanationsReviews,
	address = {Yokohama, Japan},
	title = {Synthesizing {Aspect}-{Driven} {Recommendation} {Explanations} from {Reviews}},
	isbn = {978-0-9992411-6-5},
	url = {https://www.ijcai.org/proceedings/2020/336},
	doi = {10.24963/ijcai.2020/336},
	abstract = {Explanations help to make sense of recommendations, increasing the likelihood of adoption. However, existing approaches to explainable recommendations tend to rely on rigid, standardized templates, customized only via ﬁll-in-the-blank aspect sentiments. For more ﬂexible, literate, and varied explanations covering various aspects of interest, we synthesize an explanation by selecting snippets from reviews, while optimizing for representativeness and coherence. To ﬁt target users’ aspect preferences, we contextualize the opinions based on a compatible explainable recommendation model. Experiments on datasets of several product categories showcase the efﬁcacies of our method as compared to baselines based on templates, review summarization, selection, and text generation.},
	language = {en},
	urldate = {2021-10-22},
	booktitle = {Proceedings of the {Twenty}-{Ninth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Le, Trung-Hoang and Lauw, Hady W.},
	month = jul,
	year = {2020},
	keywords = {explanation, generation},
	pages = {2427--2434},
}

@article{VERBVisualizingInterpretingBiasMitigation,
	title = {{VERB}: {Visualizing} and {Interpreting} {Bias} {Mitigation} {Techniques} for {Word} {Representations}},
	shorttitle = {{VERB}},
	url = {http://arxiv.org/abs/2104.02797},
	abstract = {Word vector embeddings have been shown to contain and amplify biases in data they are extracted from. Consequently, many techniques have been proposed to identify, mitigate, and attenuate these biases in word representations. In this paper, we utilize interactive visualization to increase the interpretability and accessibility of a collection of state-of-the-art debiasing techniques. To aid this, we present Visualization of Embedding Representations for deBiasing system ("VERB"), an open-source web-based visualization tool that helps the users gain a technical understanding and visual intuition of the inner workings of debiasing techniques, with a focus on their geometric properties. In particular, VERB offers easy-to-follow use cases in exploring the effects of these debiasing techniques on the geometry of high-dimensional word vectors. To help understand how various debiasing techniques change the underlying geometry, VERB decomposes each technique into interpretable sequences of primitive transformations and highlights their effect on the word vectors using dimensionality reduction and interactive visual exploration. VERB is designed to target natural language processing (NLP) practitioners who are designing decision-making systems on top of word embeddings, and also researchers working with fairness and ethics of machine learning systems in NLP. It can also serve as a visual medium for education, which helps an NLP novice to understand and mitigate biases in word embeddings.},
	urldate = {2021-10-15},
	journal = {arXiv:2104.02797 [cs]},
	author = {Rathore, Archit and Dev, Sunipa and Phillips, Jeff M. and Srikumar, Vivek and Zheng, Yan and Yeh, Chin-Chia Michael and Wang, Junpeng and Zhang, Wei and Wang, Bei},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.02797},
	keywords = {fair},
}

@article{Learningsituatedemotions,
	title = {Learning situated emotions},
	volume = {145},
	issn = {00283932},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0028393218300083},
	doi = {10.1016/j.neuropsychologia.2018.01.008},
	abstract = {From the perspective of constructivist theories, emotion results from learning assemblies of relevant perceptual, cognitive, interoceptive, and motor processes in specific situations. Across emotional experiences over time, learned assemblies of processes accumulate in memory that later underlie emotional experiences in similar situations. A neuroimaging experiment guided participants to experience (and thus learn) situated forms of emotion, and then assessed whether participants tended to experience situated forms of the emotion later. During the initial learning phase, some participants immersed themselves in vividly imagined fear and anger experiences involving physical harm, whereas other participants immersed themselves in vividly imagined fear and anger experiences involving negative social evaluation. In the subsequent testing phase, both learning groups experienced fear and anger while their neural activity was assessed with functional magnetic resonance imaging (fMRI). A variety of results indicated that the physical and social learning groups incidentally learned different situated forms of a given emotion. Consistent with constructivist theories, these findings suggest that learning plays a central role in emotion, with emotion adapted to the situations in which it is experienced.},
	language = {en},
	urldate = {2021-10-14},
	journal = {Neuropsychologia},
	author = {Lebois, Lauren A.M. and Wilson-Mendenhall, Christine D. and Simmons, W. Kyle and Barrett, Lisa Feldman and Barsalou, Lawrence W.},
	month = aug,
	year = {2020},
	pages = {106637},
}

@article{ConstructiveVisualAnalyticsTextSimilarity,
	title = {Constructive {Visual} {Analytics} for {Text} {Similarity} {Detection}},
	volume = {36},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12798},
	doi = {10.1111/cgf.12798},
	abstract = {Detecting similarity between texts is a frequently encountered text mining task. Because the measurement of similarity is typically composed of a number of metrics, and some measures are sensitive to subjective interpretation, a generic detector obtained using machine learning often has difficulties balancing the roles of different metrics according to the semantic context exhibited in a specific collection of texts. In order to facilitate human interaction in a visual analytics process for text similarity detection, we first map the problem of pairwise sequence comparison to that of image processing, allowing patterns of similarity to be visualized as a 2D pixelmap. We then devise a visual interface to enable users to construct and experiment with different detectors using primitive metrics, in a way similar to constructing an image processing pipeline. We deployed this new approach for the identification of commonplaces in 18th-century literary and print culture. Domain experts were then able to make use of the prototype system to derive new scholarly discoveries and generate new hypotheses.},
	number = {1},
	urldate = {2021-10-24},
	journal = {Computer Graphics Forum},
	author = {Abdul-Rahman, A. and Roe, G. and Olsen, M. and Gladstone, C. and Whaling, R. and Cronk, N. and Morrissey, R. and Chen, M.},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12798},
	pages = {237--248},
}

@article{VarifocalReaderInDepthVisualAnalysisLarge,
	title = {{VarifocalReader} — {In}-{Depth} {Visual} {Analysis} of {Large} {Text} {Documents}},
	volume = {20},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2014.2346677},
	abstract = {Interactive visualization provides valuable support for exploring, analyzing, and understanding textual documents. Certain tasks, however, require that insights derived from visual abstractions are verified by a human expert perusing the source text. So far, this problem is typically solved by offering overview-detail techniques, which present different views with different levels of abstractions. This often leads to problems with visual continuity. Focus-context techniques, on the other hand, succeed in accentuating interesting subsections of large text documents but are normally not suited for integrating visual abstractions. With VarifocalReader we present a technique that helps to solve some of these approaches' problems by combining characteristics from both. In particular, our method simplifies working with large and potentially complex text documents by simultaneously offering abstract representations of varying detail, based on the inherent structure of the document, and access to the text itself. In addition, VarifocalReader supports intra-document exploration through advanced navigation concepts and facilitates visual analysis tasks. The approach enables users to apply machine learning techniques and search mechanisms as well as to assess and adapt these techniques. This helps to extract entities, concepts and other artifacts from texts. In combination with the automatic generation of intermediate text levels through topic segmentation for thematic orientation, users can test hypotheses or develop interesting new research questions. To illustrate the advantages of our approach, we provide usage examples from literature studies.},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Koch, Steffen and John, Markus and Wörner, Michael and Müller, Andreas and Ertl, Thomas},
	month = dec,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {structured, text},
	pages = {1723--1732},
}

@inproceedings{DocuCompassEffectiveexplorationdocumentlandscapes,
	title = {{DocuCompass}: {Effective} exploration of document landscapes},
	shorttitle = {{DocuCompass}},
	doi = {10.1109/VAST.2016.7883507},
	abstract = {The creation of interactive visualization to analyze text documents has gained an impressive momentum in recent years. This is not surprising in the light of massive and still increasing amounts of available digitized texts. Websites, social media, news wire, and digital libraries are just few examples of the diverse text sources whose visual analysis and exploration offers new opportunities to effectively mine and manage the information and knowledge hidden within them. A popular visualization method for large text collections is to represent each document by a glyph in 2D space. These landscapes can be the result of optimizing pairwise distances in 2D to represent document similarities, or they are provided directly as meta data, such as geo-locations. For well-defined information needs, suitable interaction methods are available for these spatializations. However, free exploration and navigation on a level of abstraction between a labeled document spatialization and reading single documents is largely unsupported. As a result, vital foraging steps for task-tailored actions, such as selecting subgroups of documents for detailed inspection, or subsequent sense-making steps are hampered. To fill in this gap, we propose DocuCompass, a focus+context approach based on the lens metaphor. It comprises multiple methods to characterize local groups of documents, and to efficiently guide exploration based on users' requirements. DocuCompass thus allows for effective interactive exploration of document landscapes without disrupting the mental map of users by changing the layout itself. We discuss the suitability of multiple navigation and characterization methods for different spatializations and texts. Finally, we provide insights generated through user feedback and discuss the effectiveness of our approach.},
	booktitle = {2016 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	author = {Heimerl, Florian and John, Markus and Han, Qi and Koch, Steffen and Ertl, Thomas},
	month = oct,
	year = {2016},
	pages = {11--20},
}

@article{InteractiveExplorationImplicitExplicitRelations,
	title = {Interactive {Exploration} of {Implicit} and {Explicit} {Relations} in {Faceted} {Datasets}},
	volume = {19},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2013.167},
	abstract = {Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Zhao, Jian and Collins, Christopher and Chevalier, Fanny and Balakrishnan, Ravin},
	month = dec,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	pages = {2080--2089},
}

@inproceedings{RelativeNgramsignaturesDocumentvisualization,
	title = {Relative {N}-gram signatures: {Document} visualization at the level of character {N}-grams},
	shorttitle = {Relative {N}-gram signatures},
	doi = {10.1109/VAST.2012.6400484},
	abstract = {The Common N-Gram (CNG) classifier is a text classification algorithm based on the comparison of frequencies of character n-grams (strings of characters of length n) that are the most common in the considered documents and classes of documents. We present a text analytic visualization system that employs the CNG approach for text classification and uses the differences in frequency values of common n-grams in order to visually compare documents at the sub-word level. The visualization method provides both an insight into n-gram characteristics of documents or classes of documents and a visual interpretation of the workings of the CNG classifier.},
	booktitle = {2012 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	author = {Jankowska, Magdalena and Kešelj, Vlado and Milios, Evangelos},
	month = oct,
	year = {2012},
	keywords = {structured, vis},
	pages = {103--112},
}

@article{DocuBurstVisualizingDocumentContentusing,
	title = {{DocuBurst}: {Visualizing} {Document} {Content} using {Language} {Structure}},
	volume = {28},
	issn = {1467-8659},
	shorttitle = {{DocuBurst}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01439.x},
	doi = {10.1111/j.1467-8659.2009.01439.x},
	abstract = {Textual data is at the forefront of information management problems today. One response has been the development of visualizations of text data. These visualizations, commonly based on simple attributes such as relative word frequency, have become increasingly popular tools. We extend this direction, presenting the first visualization of document content which combines word frequency with the human-created structure in lexical databases to create a visualization that also reflects semantic content. DocuBurst is a radial, space-filling layout of hyponymy (the IS-A relation), overlaid with occurrence counts of words in a document of interest to provide visual summaries at varying levels of granularity. Interactive document analysis is supported with geometric and semantic zoom, selectable focus on individual words, and linked access to source text.},
	language = {en},
	number = {3},
	urldate = {2021-10-23},
	journal = {Computer Graphics Forum},
	author = {Collins, Christopher and Carpendale, Sheelagh and Penn, Gerald},
	year = {2009},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2009.01439.x},
	pages = {1039--1046},
}

@inproceedings{Compusvisualizationanalysisstructureddocuments,
	address = {San Antonio, Texas, United States},
	title = {Compus: visualization and analysis of structured documents for understanding social life in the 16th century},
	isbn = {978-1-58113-231-1},
	shorttitle = {Compus},
	url = {http://portal.acm.org/citation.cfm?doid=336597.336632},
	doi = {10.1145/336597.336632},
	abstract = {This article describes the Compus visualization system that assists in the exploration and analysis of structured document corpora encoded in XML. Compus has been developed for and applied to a corpus of 100 French manuscript letters of the 16th century, transcribed and encoded for scholarly analysis using the recommendations of the Text Encoding Initiative. By providing a synoptic visualization of a corpus and allowing for dynamic queries and structural transformations, Compus assists researchers in finding regularities or discrepancies, leading to a higher level analysis of historic source. Compus can be used with other richly encoded text corpora as well.},
	language = {en},
	urldate = {2021-10-23},
	booktitle = {Proceedings of the fifth {ACM} conference on {Digital} libraries  - {DL} '00},
	publisher = {ACM Press},
	author = {Fekete, Jean-Daniel and Dufournaud, Nicole},
	year = {2000},
	keywords = {structured, vis},
	pages = {47--55},
}

@article{PhraseBERTImprovedPhraseEmbeddingsBERT,
	title = {Phrase-{BERT}: {Improved} {Phrase} {Embeddings} from {BERT} with an {Application} to {Corpus} {Exploration}},
	abstract = {Phrase representations derived from BERT often do not exhibit complex phrasal compositionality, as the model relies instead on lexical similarity to determine semantic relatedness. In this paper, we propose a contrastive ﬁne-tuning objective that enables BERT to produce more powerful phrase embeddings. Our approach (Phrase-BERT) relies on a dataset of diverse phrasal paraphrases, which is automatically generated using a paraphrase generation model, as well as a large-scale dataset of phrases in context mined from the Books3 corpus. Phrase-BERT outperforms baselines across a variety of phrase-level similarity tasks, while also demonstrating increased lexical diversity between nearest neighbors in the vector space. Finally, as a case study, we show that Phrase-BERT embeddings can be easily integrated with a simple autoencoder to build a phrase-based neural topic model that interprets topics as mixtures of words and phrases by performing a nearest neighbor search in the embedding space. Crowdsourced evaluations demonstrate that this phrase-based topic model produces more coherent and meaningful topics than baseline word and phrase-level topic models, further validating the utility of Phrase-BERT.},
	language = {en},
	author = {Wang, Shufan and Thompson, Laure and Iyyer, Mohit},
	pages = {15},
}

@article{RulebasedVisualMappingsCaseStudy,
	title = {Rule-based {Visual} {Mappings} - with a {Case} {Study} on {Poetry} {Visualization}},
	volume = {32},
	issn = {01677055},
	url = {http://pitt.idm.oclc.org/login?url=https://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,uid&db=bth&AN=88800221&scope=site},
	doi = {10.1111/cgf.12125},
	abstract = {In this paper, we present a user-centered design study on poetry visualization. We develop a rule-based solution to address the conflicting needs for maintaining the flexibility of visualizing a large set of poetic variables and for reducing the tedium and cognitive load in interacting with the visual mapping control panel. We adopt Munzner's nested design model to maintain high-level interactions with the end users in a closed loop. In addition, we examine three design options for alleviating the difficulty in visualizing poems latitudinally. We present several example uses of poetry visualization in scholarly research on poetry.},
	number = {3pt4},
	urldate = {2021-10-24},
	journal = {Computer Graphics Forum},
	author = {Abdul‐Rahman, A. and Lein, J. and Coles, K. and Maguire, E. and Meyer, M. and Wynne, M. and Johnson, C. R. and Trefethen, A. and Chen, M.},
	month = dec,
	year = {2013},
	note = {Publisher: Wiley-Blackwell},
	keywords = {poem, structured, text, vis},
	pages = {381--390},
}

@article{VisualExplorationNeuralDocumentEmbedding,
	title = {Visual {Exploration} of {Neural} {Document} {Embedding} in {Information} {Retrieval}: {Semantics} and {Feature} {Selection}},
	volume = {25},
	issn = {1941-0506},
	shorttitle = {Visual {Exploration} of {Neural} {Document} {Embedding} in {Information} {Retrieval}},
	doi = {10.1109/TVCG.2019.2903946},
	abstract = {Neural embeddings are widely used in language modeling and feature generation with superior computational power. Particularly, neural document embedding - converting texts of variable-length to semantic vector representations - has shown to benefit widespread downstream applications, e.g., information retrieval (IR). However, the black-box nature makes it difficult to understand how the semantics are encoded and employed. We propose visual exploration of neural document embedding to gain insights into the underlying embedding space, and promote the utilization in prevalent IR applications. In this study, we take an IR application-driven view, which is further motivated by biomedical IR in healthcare decision-making, and collaborate with domain experts to design and develop a visual analytics system. This system visualizes neural document embeddings as a configurable document map and enables guidance and reasoning; facilitates to explore the neural embedding space and identify salient neural dimensions (semantic features) per task and domain interest; and supports advisable feature selection (semantic analysis) along with instant visual feedback to promote IR performance. We demonstrate the usefulness and effectiveness of this system and present inspiring findings in use cases. This work will help designers/developers of downstream applications gain insights and confidence in neural document embedding, and exploit that to achieve more favorable performance in application domains.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ji, Xiaonan and Shen, Han-Wei and Ritter, Alan and Machiraju, Raghu and Yen, Po-Yin},
	month = jun,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	pages = {2181--2192},
}

@article{NaturePrejudiceAutomaticControlledProcesses,
	title = {On the {Nature} of {Prejudice}: {Automatic} and {Controlled} {Processes}},
	volume = {33},
	issn = {00221031},
	shorttitle = {On the {Nature} of {Prejudice}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022103197913317},
	doi = {10.1006/jesp.1997.1331},
	language = {en},
	number = {5},
	urldate = {2021-11-03},
	journal = {Journal of Experimental Social Psychology},
	author = {Dovidio, John F. and Kawakami, Kerry and Johnson, Craig and Johnson, Brenda and Howard, Adaiah},
	month = sep,
	year = {1997},
	pages = {510--540},
}

@article{Attitudebehaviourrelationsroleingroupnorms,
	title = {Attitude-behaviour relations: {The} role of in-group norms and mode of behavioural decision-making},
	volume = {39},
	issn = {2044-8309},
	shorttitle = {Attitude-behaviour relations},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1348/014466600164534},
	doi = {10.1348/014466600164534},
	abstract = {Two experiments provided support for the central hypothesis - derived from social identity self-categorization theories - that attitudes would be most likely to predict behaviour when they were supported by a congruent in-group norm. In the first experiment, norm congruency and mode of behavioural decision-making (spontaneous or deliberative) were orthogonally manipulated in a between-subjects study of career choice in psychology. Participants exposed to an attitudinally congruent in-group norm towards their preferred career choice were more likely to display attitude-behaviour consistency than those exposed to an attitudinally inconsistent group norm, an effect that was evident under both spontaneous and deliberative decision-making conditions. Using a mockjury paradigm, Expt 2 replicated and extended the first experiment by including a manipulation of in-group salience. As predicted, participants exposed to an incongruent norm displayed greater attitude-behaviour inconsistency than those exposed to a congruent norm. Contrary to predictions, this effect did not vary as a function of group salience, nor did the effects of group norms for high and low salience participants vary as a function of mode of behavioural decision-making. However, there was evidence that perceived identification with the group moderated the influence of norms on attitude-behaviour consistency.},
	language = {en},
	number = {3},
	urldate = {2021-11-03},
	journal = {British Journal of Social Psychology},
	author = {Terry, Deborah J. and Hogg, Michael A. and McKimmie, Blake M.},
	year = {2000},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1348/014466600164534},
	pages = {337--361},
}

@article{NeuroCartographyScalableAutomaticVisualSummarization,
	title = {{NeuroCartography}: {Scalable} {Automatic} {Visual} {Summarization} of {Concepts} in {Deep} {Neural} {Networks}},
	shorttitle = {{NeuroCartography}},
	url = {http://arxiv.org/abs/2108.12931},
	abstract = {Existing research on making sense of deep neural networks often focuses on neuron-level interpretation, which may not adequately capture the bigger picture of how concepts are collectively encoded by multiple neurons. We present NeuroCartography, an interactive system that scalably summarizes and visualizes concepts learned by neural networks. It automatically discovers and groups neurons that detect the same concepts, and describes how such neuron groups interact to form higher-level concepts and the subsequent predictions. NeuroCartography introduces two scalable summarization techniques: (1) neuron clustering groups neurons based on the semantic similarity of the concepts detected by neurons (e.g., neurons detecting "dog faces" of different breeds are grouped); and (2) neuron embedding encodes the associations between related concepts based on how often they co-occur (e.g., neurons detecting "dog face" and "dog tail" are placed closer in the embedding space). Key to our scalable techniques is the ability to efficiently compute all neuron pairs' relationships, in time linear to the number of neurons instead of quadratic time. NeuroCartography scales to large data, such as the ImageNet dataset with 1.2M images. The system's tightly coordinated views integrate the scalable techniques to visualize the concepts and their relationships, projecting the concept associations to a 2D space in Neuron Projection View, and summarizing neuron clusters and their relationships in Graph View. Through a large-scale human evaluation, we demonstrate that our technique discovers neuron groups that represent coherent, human-meaningful concepts. And through usage scenarios, we describe how our approaches enable interesting and surprising discoveries, such as concept cascades of related and isolated concepts. The NeuroCartography visualization runs in modern browsers and is open-sourced.},
	urldate = {2021-10-30},
	journal = {arXiv:2108.12931 [cs]},
	author = {Park, Haekyu and Das, Nilaksh and Duggal, Rahul and Wright, Austin P. and Shaikh, Omar and Hohman, Fred and Chau, Duen Horng},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.12931},
	keywords = {vis, xai},
}

@article{LawLargeDocumentsUnderstandingStructure,
	title = {The {Law} of {Large} {Documents}: {Understanding} the {Structure} of {Legal} {Contracts} {Using} {Visual} {Cues}},
	abstract = {Large, pre-trained transformer models like BERT have achieved state-of-the-art results on document understanding tasks, but most implementations can only consider 512 tokens at a time. For many real-world applications, documents can be much longer, and the segmentation strategies typically used on longer documents miss out on document structure and contextual information, hurting their results on downstream tasks. In our work on legal agreements, we find that visual cues such as layout, style, and placement of text in a document are strong features that are crucial to achieving an acceptable level of accuracy on long documents. We measure the impact of incorporating such visual cues, obtained via computer vision methods, on the accuracy of document understanding tasks including document segmentation, entity extraction, and attribute classification. Our method of segmenting documents based on structural metadata out-performs existing methods on four long-document understanding tasks as measured on the Contract Understanding Atticus Dataset.},
	language = {en},
	year = {2021},
	pages = {9},
}

@inproceedings{DiversityPromotingObjectiveFunctionNeuralConversationa,
	address = {San Diego, California},
	title = {A {Diversity}-{Promoting} {Objective} {Function} for {Neural} {Conversation} {Models}},
	url = {http://aclweb.org/anthology/N16-1014},
	doi = {10.18653/v1/N16-1014},
	abstract = {Sequence-to-sequence neural network models for generation of conversational responses tend to generate safe, commonplace responses (e.g., I don’t know) regardless of the input. We suggest that the traditional objective function, i.e., the likelihood of output (response) given input (message) is unsuited to response generation tasks. Instead we propose using Maximum Mutual Information (MMI) as the objective function in neural models. Experimental results demonstrate that the proposed MMI models produce more diverse, interesting, and appropriate responses, yielding substantive gains in BLEU scores on two conversational datasets and in human evaluations.},
	language = {en},
	urldate = {2021-10-26},
	booktitle = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill},
	year = {2016},
	pages = {110--119},
}

@article{RepBERTContextualizedTextEmbeddingsFirstStage,
	title = {{RepBERT}: {Contextualized} {Text} {Embeddings} for {First}-{Stage} {Retrieval}},
	shorttitle = {{RepBERT}},
	url = {http://arxiv.org/abs/2006.15498},
	abstract = {Although exact term match between queries and documents is the dominant method to perform first-stage retrieval, we propose a different approach, called RepBERT, to represent documents and queries with fixed-length contextualized embeddings. The inner products of query and document embeddings are regarded as relevance scores. On MS MARCO Passage Ranking task, RepBERT achieves state-of-the-art results among all initial retrieval techniques. And its efficiency is comparable to bag-of-words methods.},
	urldate = {2021-10-25},
	journal = {arXiv:2006.15498 [cs]},
	author = {Zhan, Jingtao and Mao, Jiaxin and Liu, Yiqun and Zhang, Min and Ma, Shaoping},
	month = jul,
	year = {2020},
	note = {arXiv: 2006.15498},
}

@article{VisuallyAnalyzingContextualizedEmbeddings,
	title = {Visually {Analyzing} {Contextualized} {Embeddings}},
	url = {http://arxiv.org/abs/2009.02554},
	abstract = {In this paper we introduce a method for visually analyzing contextualized embeddings produced by deep neural network-based language models. Our approach is inspired by linguistic probes for natural language processing, where tasks are designed to probe language models for linguistic structure, such as parts-of-speech and named entities. These approaches are largely confirmatory, however, only enabling a user to test for information known a priori. In this work, we eschew supervised probing tasks, and advocate for unsupervised probes, coupled with visual exploration techniques, to assess what is learned by language models. Specifically, we cluster contextualized embeddings produced from a large text corpus, and introduce a visualization design based on this clustering and textual structure - cluster co-occurrences, cluster spans, and cluster-word membership - to help elicit the functionality of, and relationship between, individual clusters. User feedback highlights the benefits of our design in discovering different types of linguistic structures.},
	urldate = {2021-10-25},
	journal = {arXiv:2009.02554 [cs]},
	author = {Berger, Matthew},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.02554},
}

@article{CEDRContextualizedEmbeddingsDocumentRanking,
	title = {{CEDR}: {Contextualized} {Embeddings} for {Document} {Ranking}},
	shorttitle = {{CEDR}},
	url = {http://arxiv.org/abs/1904.07094},
	doi = {10.1145/3331184.3331317},
	abstract = {Although considerable attention has been given to neural ranking architectures recently, far less attention has been paid to the term representations that are used as input to these models. In this work, we investigate how two pretrained contextualized language models (ELMo and BERT) can be utilized for ad-hoc document ranking. Through experiments on TREC benchmarks, we find that several existing neural ranking architectures can benefit from the additional context provided by contextualized language models. Furthermore, we propose a joint approach that incorporates BERT's classification vector into existing neural models and show that it outperforms state-of-the-art ad-hoc ranking baselines. We call this joint approach CEDR (Contextualized Embeddings for Document Ranking). We also address practical challenges in using these models for ranking, including the maximum input length imposed by BERT and runtime performance impacts of contextualized language models.},
	urldate = {2021-10-25},
	journal = {Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {MacAvaney, Sean and Yates, Andrew and Cohan, Arman and Goharian, Nazli},
	month = jul,
	year = {2019},
	note = {arXiv: 1904.07094},
	pages = {1101--1104},
}

@article{MultiPerspectiveSimultaneousEmbedding,
	title = {Multi-{Perspective}, {Simultaneous} {Embedding}},
	url = {http://arxiv.org/abs/1909.06485},
	abstract = {We describe MPSE: a Multi-Perspective Simultaneous Embedding method for visualizing high-dimensional data, based on multiple pairwise distances between the data points. Specifically, MPSE computes positions for the points in 3D and provides different views into the data by means of 2D projections (planes) that preserve each of the given distance matrices. We consider two versions of the problem: fixed projections and variable projections. MPSE with fixed projections takes as input a set of pairwise distance matrices defined on the data points, along with the same number of projections and embeds the points in 3D so that the pairwise distances are preserved in the given projections. MPSE with variable projections takes as input a set of pairwise distance matrices and embeds the points in 3D while also computing the appropriate projections that preserve the pairwise distances. The proposed approach can be useful in multiple scenarios: from creating simultaneous embedding of multiple graphs on the same set of vertices, to reconstructing a 3D object from multiple 2D snapshots, to analyzing data from multiple points of view. We provide a functional prototype of MPSE that is based on an adaptive and stochastic generalization of multi-dimensional scaling to multiple distances and multiple variable projections. We provide an extensive quantitative evaluation with datasets of different sizes and using different number of projections, as well as several examples that illustrate the quality of the resulting solutions.},
	urldate = {2021-10-25},
	journal = {arXiv:1909.06485 [cs]},
	author = {Hossain, Md Iqbal and Huroyan, Vahan and Kobourov, Stephen and Navarrete, Raymundo},
	month = aug,
	year = {2020},
	note = {arXiv: 1909.06485},
	keywords = {embedding, vis},
}

@article{DeleteRetrieveGenerateSimpleApproach,
	title = {Delete, {Retrieve}, {Generate}: {A} {Simple} {Approach} to {Sentiment} and {Style} {Transfer}},
	shorttitle = {Delete, {Retrieve}, {Generate}},
	url = {http://arxiv.org/abs/1804.06437},
	abstract = {We consider the task of text attribute transfer: transforming a sentence to alter a speciﬁc attribute (e.g., sentiment) while preserving its attribute-independent content (e.g., changing “screen is just the right size” to “screen is too small”). Our training data includes only sentences labeled with their attribute (e.g., positive or negative), but not pairs of sentences that differ only in their attributes, so we must learn to disentangle attributes from attributeindependent content in an unsupervised way. Previous work using adversarial methods has struggled to produce high-quality outputs. In this paper, we propose simpler methods motivated by the observation that text attributes are often marked by distinctive phrases (e.g., “too small”). Our strongest method extracts content words by deleting phrases associated with the sentence’s original attribute value, retrieves new phrases associated with the target attribute, and uses a neural model to ﬂuently combine these into a ﬁnal output. On human evaluation, our best method generates grammatical and appropriate responses on 22\% more inputs than the best previous system, averaged over three attribute transfer datasets: altering sentiment of reviews on Yelp, altering sentiment of reviews on Amazon, and altering image captions to be more romantic or humorous.},
	language = {en},
	urldate = {2021-11-06},
	journal = {arXiv:1804.06437 [cs]},
	author = {Li, Juncen and Jia, Robin and He, He and Liang, Percy},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.06437},
}

@article{GeneratingLongInformativeReviewsAspectAware,
	title = {Generating {Long} and {Informative} {Reviews} with {Aspect}-{Aware} {Coarse}-to-{Fine} {Decoding}},
	url = {http://arxiv.org/abs/1906.05667},
	doi = {10.18653/v1/P19-1190},
	abstract = {Generating long and informative review text is a challenging natural language generation task. Previous work focuses on word-level generation, neglecting the importance of topical and syntactic characteristics from natural languages. In this paper, we propose a novel review generation model by characterizing an elaborately designed aspect-aware coarse-toﬁne generation process. First, we model the aspect transitions to capture the overall content ﬂow. Then, to generate a sentence, an aspectaware sketch will be predicted using an aspectaware decoder. Finally, another decoder ﬁlls in the semantic slots by generating corresponding words. Our approach is able to jointly utilize aspect semantics, syntactic sketch, and context information. Extensive experiments results have demonstrated the effectiveness of the proposed model.},
	language = {en},
	urldate = {2021-11-06},
	journal = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	author = {Li, Junyi and Zhao, Wayne Xin and Wen, Ji-Rong and Song, Yang},
	year = {2019},
	note = {arXiv: 1906.05667},
	pages = {1969--1979},
}

@article{ApplicationCOMBmodelbarriersfacilitators,
	title = {Application of the {COM}-{B} model to barriers and facilitators to chlamydia testing in general practice for young people and primary care practitioners: a systematic review},
	volume = {13},
	issn = {1748-5908},
	shorttitle = {Application of the {COM}-{B} model to barriers and facilitators to chlamydia testing in general practice for young people and primary care practitioners},
	url = {https://implementationscience.biomedcentral.com/articles/10.1186/s13012-018-0821-y},
	doi = {10.1186/s13012-018-0821-y},
	abstract = {Background: Chlamydia is a major public health concern, with high economic and social costs. In 2016, there were over 200,000 chlamydia diagnoses made in England. The highest prevalence rates are found among young people. Although annual testing for sexually active young people is recommended, many do not receive testing. General practice is one ideal setting for testing, yet attempts to increase testing in this setting have been disappointing.},
	language = {en},
	number = {1},
	urldate = {2021-11-04},
	journal = {Implementation Science},
	author = {McDonagh, Lorraine K and Saunders, John M and Cassell, Jackie and Curtis, Tyrone and Bastaki, Hamad and Hartney, Thomas and Rait, Greta},
	month = dec,
	year = {2018},
	pages = {130},
}

@article{ImprovingManagementRespiratoryTractInfections,
	title = {Improving {Management} of {Respiratory} {Tract} {Infections} in {Community} {Pharmacies} and {Promoting} {Antimicrobial} {Stewardship}: {A} {Cluster} {Randomised} {Control} {Trial} with a {Self}-{Report} {Behavioural} {Questionnaire} and {Process} {Evaluation}},
	volume = {8},
	issn = {2226-4787},
	shorttitle = {Improving {Management} of {Respiratory} {Tract} {Infections} in {Community} {Pharmacies} and {Promoting} {Antimicrobial} {Stewardship}},
	url = {https://www.mdpi.com/2226-4787/8/1/44},
	doi = {10.3390/pharmacy8010044},
	abstract = {In England, 81\% of all antibiotic prescriptions originate in primary care/community settings, of which up to 20\% are thought to be inappropriate. Community pharmacies are often the ﬁrst point of community contact for patients with suspected infections; providing an opportunity for community pharmacy teams to promote antimicrobial stewardship (AMS). The objective of the study was to improve the management of infections and antimicrobial stewardship in community pharmacies. The study methodology included a non-blinded cluster randomised control trial with pharmacy staﬀ in 272 community pharmacies in England. The intervention arm received an AMS webinar and a patient facing respiratory tract infection (RTI) leaﬂet (TARGET TYI-RTI) for use in everyday practice for four weeks. The control arm received a webinar on how to participate in the study. The primary outcome was self-reported referrals to general practitioners (GPs). The secondary outcomes were; provision of self-care advice/ written information to patients, referrals to pharmacists, sign-posting to non-prescription medicines and common barriers and facilitators to advice-giving in community pharmacies. Ethics approval was granted by the Public Health England Research Ethics and Governance Group. 66.91\% (182 of 272) of pharmacies provided 3649 patient consultation data reports across both arms. Use of the leaﬂet was associated with a lower likelihood of referrals to GPs for certain RTIs (p {\textless} 0.05) and a more frequent provision of self-care advice than the control (p = 0.06). Opportunities to deliver self-care advice were limited due to lack of time. Pharmacy staﬀ had good motivation and capability for managing self-limiting infections but the opportunity to do so was a perceived barrier. Use of the TARGET leaﬂet facilitated pharmacy staﬀ to give more self-care advice and decreased referrals to GPs.},
	language = {en},
	number = {1},
	urldate = {2021-11-04},
	journal = {Pharmacy},
	author = {Ashiru-Oredope, Diane and Doble, Anne and Thornley, Tracey and Saei, Ayoub and Gold, Natalie and Sallis, Anna and McNulty, Cliodna A M and Lecky, Donna and Umoh, Eno and Klinger, Chaamala},
	month = mar,
	year = {2020},
	pages = {44},
}

@article{PromotingCriticalThinkingDispositionsUsingProblem,
	title = {Promoting {Critical}-{Thinking} {Dispositions} by {Using} {Problem} {Solving} in {Middle} {School} {Mathematics}},
	volume = {28},
	issn = {1940-4476},
	url = {http://www.tandfonline.com/doi/full/10.1080/19404476.2004.11658174},
	doi = {10.1080/19404476.2004.11658174},
	abstract = {This review of research generates principles for the design of instructional programs that foster critical-thinking dispositions. The dispositional aspect of critical thinking may be considered part of attitudinal memory, readily activated if sufficiently strong. We describe evidence suggesting that ill-structured problem-solving can provide middle schoolers with motivating activities that strengthen critical-thinking dispositions, thus fostering sensitivity to occasions for thinking critically and the inclination for engaging in such practices. The Jasper Series and Decision Making are reviewed as cases of programs for middle level mathematics learning that afford opportunities for ill-structured problem-solving activities that incorporate five important attitudestrengthening elements. Fazio (1995) identified these elements as direct experience, sensory experience, emotional reaction, freely chosen behavior, and attitude rehearsal. We describe how the design of the two mathematics programs incorporates attitude-strengthening elements that can potentially foster critical-thinking dispositions. Based on this review, we present a set of design principles to promote those dispositions.},
	language = {en},
	number = {1},
	urldate = {2021-11-03},
	journal = {RMLE Online},
	author = {Leader, Lars F. and Middleton, James A.},
	month = jan,
	year = {2004},
	pages = {1--13},
}

@book{InternationalEncyclopediaMediaPsychology,
	edition = {1},
	title = {The {International} {Encyclopedia} of {Media} {Psychology}},
	isbn = {978-1-119-01107-1},
	url = {https://onlinelibrary.wiley.com/doi/book/10.1002/9781119011071},
	language = {en},
	urldate = {2021-11-03},
	publisher = {Wiley},
	editor = {Bulck, Jan},
	month = sep,
	year = {2020},
	doi = {10.1002/9781119011071},
}

@article{ControlledAutomaticProcessesWhichDominant,
	title = {Controlled versus {Automatic} {Processes}: {Which} {Is} {Dominant} to {Safety}? {The} {Moderating} {Effect} of {Inhibitory} {Control}},
	volume = {9},
	issn = {1932-6203},
	shorttitle = {Controlled versus {Automatic} {Processes}},
	url = {https://dx.plos.org/10.1371/journal.pone.0087881},
	doi = {10.1371/journal.pone.0087881},
	abstract = {This study explores the precursors of employees’ safety behaviors based on a dual-process model, which suggests that human behaviors are determined by both controlled and automatic cognitive processes. Employees’ responses to a selfreported survey on safety attitudes capture their controlled cognitive process, while the automatic association concerning safety measured by an Implicit Association Test (IAT) reflects employees’ automatic cognitive processes about safety. In addition, this study investigates the moderating effects of inhibition on the relationship between self-reported safety attitude and safety behavior, and that between automatic associations towards safety and safety behavior. The results suggest significant main effects of self-reported safety attitude and automatic association on safety behaviors. Further, the interaction between self-reported safety attitude and inhibition and that between automatic association and inhibition each predict unique variances in safety behavior. Specifically, the safety behaviors of employees with lower level of inhibitory control are influenced more by automatic association, whereas those of employees with higher level of inhibitory control are guided more by self-reported safety attitudes. These results suggest that safety behavior is the joint outcome of both controlled and automatic cognitive processes, and the relative importance of these cognitive processes depends on employees’ individual differences in inhibitory control. The implications of these findings for theoretical and practical issues are discussed at the end.},
	language = {en},
	number = {2},
	urldate = {2021-11-03},
	journal = {PLoS ONE},
	author = {Xu, Yaoshan and Li, Yongjuan and Ding, Weidong and Lu, Fan},
	editor = {Bruce, Amanda},
	month = feb,
	year = {2014},
	pages = {e87881},
}

@article{AttitudeBehaviorProcessesFunctionMotivation,
	title = {Attitude‐{Behavior} {Processes} as a {Function} of {Motivation} and {Opportunity}},
	language = {en},
	author = {Fazio, Russell H},
	pages = {34},
}

@article{KnowledgebasedReviewGenerationCoherenceEnhanced,
	title = {Knowledge-based {Review} {Generation} by {Coherence} {Enhanced} {Text} {Planning}},
	url = {http://arxiv.org/abs/2105.03815},
	abstract = {As a natural language generation task, it is challenging to generate informative and coherent review text. In order to enhance the informativeness of the generated text, existing solutions typically learn to copy entities or triples from knowledge graphs (KGs). However, they lack overall consideration to select and arrange the incorporated knowledge, which tends to cause text incoherence. To address the above issue, we focus on improving entity-centric coherence of the generated reviews by leveraging the semantic structure of KGs. In this paper, we propose a novel Coherence Enhanced Text Planning model (CETP) based on knowledge graphs (KGs) to improve both global and local coherence for review generation. The proposed model learns a two-level text plan for generating a document: (1) the document plan is modeled as a sequence of sentence plans in order, and (2) the sentence plan is modeled as an entity-based subgraph from KG. Local coherence can be naturally enforced by KG subgraphs through intra-sentence correlations between entities. For global coherence, we design a hierarchical selfattentive architecture with both subgraph- and node-level attention to enhance the correlations between subgraphs. To our knowledge, we are the first to utilize a KG-based text planning model to enhance text coherence for review generation. Extensive experiments on three datasets confirm the effectiveness of our model on improving the content coherence of generated texts.},
	language = {en},
	urldate = {2021-11-06},
	journal = {arXiv:2105.03815 [cs]},
	author = {Li, Junyi and Zhao, Wayne Xin and Wei, Zhicheng and Yuan, Nicholas Jing and Wen, Ji-Rong},
	month = may,
	year = {2021},
	note = {arXiv: 2105.03815},
}

@inproceedings{RetrievalAugmentedControllableReviewGenerationa,
	address = {Barcelona, Spain (Online)},
	title = {Retrieval-{Augmented} {Controllable} {Review} {Generation}},
	url = {https://aclanthology.org/2020.coling-main.207},
	doi = {10.18653/v1/2020.coling-main.207},
	abstract = {In this paper, we study review generation given a set of attribute identifiers which are user ID, product ID and rating. This is a difficult subtask of natural language generation since models are limited to the given identifiers, without any specific descriptive information regarding the inputs, when generating the text. The capacity of these models is thus confined and dependent to how well the models can capture vector representations of attributes. We thus propose to additionally leverage references, which are selected from a large pool of texts labeled with one of the attributes, as textual information that enriches inductive biases of given attributes. With these references, we can now pose the problem as an instance of text-to-text generation, which makes the task easier since texts that are syntactically, semantically similar with the output text are provided as input. Using this framework, we address issues such as selecting references from a large candidate set without textual context and improving the model complexity for generation. Our experiments show that our models improve over previous approaches on both automatic and human evaluation metrics.},
	urldate = {2021-11-06},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {International Committee on Computational Linguistics},
	author = {Kim, Jihyeok and Choi, Seungtaek and Amplayo, Reinald Kim and Hwang, Seung-won},
	month = dec,
	year = {2020},
	pages = {2284--2295},
}

@article{GeneratingMoreInterestingResponsesNeural,
	title = {Generating {More} {Interesting} {Responses} in {Neural} {Conversation} {Models} with {Distributional} {Constraints}},
	url = {http://arxiv.org/abs/1809.01215},
	abstract = {Neural conversation models tend to generate safe, generic responses for most inputs. This is due to the limitations of likelihoodbased decoding objectives in generation tasks with diverse outputs, such as conversation. To address this challenge, we propose a simple yet effective approach for incorporating side information in the form of distributional constraints over the generated responses. We propose two constraints that help generate more content rich responses that are based on a model of syntax and topics (Grifﬁths et al., 2005) and semantic similarity (Arora et al., 2016). We evaluate our approach against a variety of competitive baselines, using both automatic metrics and human judgments, showing that our proposed approach generates responses that are much less generic without sacriﬁcing plausibility. A working demo of our code can be found at https://github.com/abaheti95/ DC-NeuralConversation.},
	language = {en},
	urldate = {2021-11-06},
	journal = {arXiv:1809.01215 [cs]},
	author = {Baheti, Ashutosh and Ritter, Alan and Li, Jiwei and Dolan, Bill},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.01215},
}

@article{Visuallegalanalyticsvisualapproach,
	title = {Visual legal analytics – {A} visual approach to analyze law-conflicts of e-{Services} for e-{Mobility} and transportation domain},
	volume = {149},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050919301784},
	doi = {10.1016/j.procs.2019.01.170},
	abstract = {Abstract The impact of the electromobility has next to the automotive industry also an increasing impact on the transportation and logistics dTohme aiminp. aIcnt poaf rtthiceuellaercthroemtodbailyit’ys hstaasrtninexgt stwo itthceheasuttoomeoleticvteroinidcutsrturyckasl/ssocoanotienrclreeaadsintog mimapssaicvteonchtahnegterasnisnpothretatoirognananizdatlioognisatincds pdolamnnain.gIinn pthairsticfiuelladr. tPhuebtloicdafuyn’sdisntagrtoirngtaxswrietdcuhcetsioton feolercetnrovniricontmruecnkts/fsrcieonodtelyr lseoaldutitonms afossrcivees aclhsaongthees ginrotwhethoorfganneiwzamtioonbialintdy panladnntrianngspinortthaitsiofnieslde.rvPiucebsli.cHfouwndeivnegr,otrhteaxvarsetdcuhcatinognesfoirnetnhvisirodnomeanint farniedntdhley hsioglhutinounms bfoercoefs ianlnsovtahteiognrsowofthneowf ntewchnmoolobgilietys and tsrearnvsipceosrtaletiaodns saelrsvoiciensto. Haocwrietvicearl, ltehgeavl ausntccehratanignetys.inThtheiscldaorimficaaintioandofthae lheiggahl nsutamtubserfoorf ainnneowvatteiocnhsnoolfognyewortescehrvniocleogciaens banecdosmereviccoesst lienatdenssaivlseoiinntao daimcreintisciaolnlethgatl uinncpearrttaiicnutlya.r Tshtaertculpasrifciocuatlidonnootf ianvlesgta.lIsntatthuis fpoarpaernwewe theecrhenfolroegiyntoror dsuecrveicaenceawn bapecporomaechcotostidinentetnifsyivaendinanaadlyimzeelnesgioalnctohnaftliicntspbaartsiecduloanr satabrutusipnsescsomuloddneol torinpvleasnt.agInainthsitsepxaispteinrgwleawths.erTehfoerientienntrtoiodnucise tahanteawn eaparplryoacwhatroeniedsesntoifycarintdicalnalelygzael laesgpaelctcocnofulilcdtsenbabseled aonn eaabrluysiandeosps tmioondoelf othr eplpalnanangeadinset revxiicsetintog elanwsusr.eTihtse ilnegteanlittiyo.nOisutrhmataain ceoarnltyribawutaiorenniesssdiostfincgriutischael dleignatlwaosppeacrttsc.oFuilrdstleyn,aablneewanNeoarrmly-gardaopphtivoinsuoaflitzhaetiopnlaanpnperdoascehrvtioceshtowenlaswurseaintsd lleeggaallitays.pOecutrs imnaain ecaosniterribuuntidoenrsitsanddisatbinlegumisahnenderi.nAtwndo pseacrtosn. dFliyr,stalyV, aisunaelwLNegoarlmA-gnraalpyhticvsisaupaplirzoaatciohntoapapnraolayczhe tloegsahlocwonlafwlicstsaned.gl.eognaltahsepbeacstsisinofana beaussiienresusndpelarsntsa.nTdahbeleVmisaunanl eLr.egAanldAsneacloyntidclsy,aappVroisaucahl aLiemgsaltoAnparolyvtidces aapvpirsouaaclhatnoaalynsailsyzinetelerfgaaclecotonfvliacltisdaet.eg.thoen tahuetobmasaitsicoafllya ibduesnintiefisesdplleagnasl. cTohnefliVctisuraelsuLletignagl fAronmalythtiecspraep-proaccehssianigmstatogepwroivthidae garavpishuicaallaonvaelyrvsieswinatebrofuact ethteodvearliivdaattieonthdeowauntotomtahtiecalallwy irdoeontstifained tlheegaolpctioonnfltioctschrecskultihnegofrriogminatlhesopurrec-epsrotocegsesitnfgurstthaegredwetiathilsa. Agrtatphheiceanldoavnearvlyieswt cabnosuot vtheerifdyerciovnatfiloicntsdaoswrnelteovtahnet alanwd roesootslvaenidt bthyeaodpvtainocnintog ceh.ge.ctkhethbeuosrinigeisnsapl lsaonuorcreasstiorrgeeletvfaunrth. eArndevtaailus.atAiotnthpeerefnodrmaendalwysithcalanwsyoevrserhiafys pcroonoffliecdtsoausr raeplpervoaanctha.nd resolve it by advancing e.g. the business plan or as irrelevant. An evaluation performed with lawyers has proofed our approach.},
	language = {en},
	urldate = {2021-11-06},
	journal = {Procedia Computer Science},
	author = {Burkhardt, Dirk and Nazemi, Kawa},
	year = {2019},
	pages = {515--524},
}

@article{PosthocInterpretabilityNeuralNLPSurvey,
	title = {Post-hoc {Interpretability} for {Neural} {NLP}: {A} {Survey}},
	shorttitle = {Post-hoc {Interpretability} for {Neural} {NLP}},
	url = {http://arxiv.org/abs/2108.04840},
	abstract = {Natural Language Processing (NLP) models have become increasingly more complex and widespread. With recent developments in neural networks, a growing concern is whether it is responsible to use these models. Concerns such as safety and ethics can be partially addressed by providing explanations. Furthermore, when models do fail, providing explanations is paramount for accountability purposes. To this end, interpretability serves to provide these explanations in terms that are understandable to humans. Central to what is understandable is how explanations are communicated. Therefore, this survey provides a categorization of how recent interpretability methods communicate explanations and discusses the methods in depth. Furthermore, the survey focuses on post-hoc methods, which provide explanations after a model is learned and generally model-agnostic. A common concern for this class of methods is whether they accurately reﬂect the model. Hence, how these post-hoc methods are evaluated is discussed throughout the paper.},
	language = {en},
	urldate = {2021-11-06},
	journal = {arXiv:2108.04840 [cs]},
	author = {Madsen, Andreas and Reddy, Siva and Chandar, Sarath},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.04840},
}

@article{UnsupervisedAspectawareRecommendationModelExplanation,
	title = {An {Unsupervised} {Aspect}-aware {Recommendation} {Model} with {Explanation} {Text} {Generation}},
	volume = {37},
	language = {en},
	number = {4},
	journal = {J. ACM},
	author = {Sun, Peijie and Wu, Le and Zhang, Kun and Su, Yu and Wang, Meng},
	pages = {29},
}

@inproceedings{ViziTexInteractiveVisualSenseMakingText,
	address = {Online},
	title = {{ViziTex}: {Interactive} {Visual} {Sense}-{Making} of {Text} {Corpora}},
	shorttitle = {{ViziTex}},
	url = {https://aclanthology.org/2021.dash-1.3},
	doi = {10.18653/v1/2021.dash-1.3},
	abstract = {Information visualization is critical to analytical reasoning and knowledge discovery. We present an interactive studio that integrates perceptive visualization techniques with powerful text analytics algorithms to assist humans in sense-making of large complex text corpora. The novel visual representations introduced here encode the features delivered by modern text mining models using advanced metaphors such as hypergraphs, nested topologies and tessellated planes. They enhance human-computer interaction experience for various tasks such as summarization, exploration, organization and labeling of documents. We demonstrate the ability of the visuals to surface the structure, relations and concepts from documents across different domains.},
	urldate = {2021-11-06},
	booktitle = {Proceedings of the {Second} {Workshop} on {Data} {Science} with {Human} in the {Loop}: {Language} {Advances}},
	publisher = {Association for Computational Linguistics},
	author = {Raman, Natraj and Shah, Sameena and Balch, Tucker and Veloso, Manuela},
	month = jun,
	year = {2021},
	pages = {16--23},
}

@inproceedings{ConceptScopeOrganizingVisualizingKnowledgeDocuments,
	address = {Yokohama Japan},
	title = {{ConceptScope}: {Organizing} and {Visualizing} {Knowledge} in {Documents} based on {Domain} {Ontology}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {{ConceptScope}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445396},
	doi = {10.1145/3411764.3445396},
	abstract = {Current text visualization techniques typically provide overviews of document content and structure using intrinsic properties such as term frequencies, co-occurrences, and sentence structures. Such visualizations lack conceptual overviews incorporating domainrelevant knowledge, needed when examining documents such as research articles or technical reports. To address this shortcoming, we present ConceptScope, a technique that utilizes a domain ontology to represent the conceptual relationships in a document in the form of a Bubble Treemap visualization. Multiple coordinated views of document structure and concept hierarchy with text overviews further aid document analysis. ConceptScope facilitates exploration and comparison of single and multiple documents respectively. We demonstrate ConceptScope by visualizing research articles and transcripts of technical presentations in computer science. In a comparative study with DocuBurst, a popular document visualization tool, ConceptScope was found to be more informative in exploring and comparing domain-specifc documents, but less so when it came to documents that spanned multiple disciplines.},
	language = {en},
	urldate = {2021-11-06},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Zhang, Xiaoyu and Chandrasegaran, Senthil and Ma, Kwan-Liu},
	month = may,
	year = {2021},
	pages = {1--13},
}

@inproceedings{CLIELcontextbasedinformationextractioncommercial,
	address = {London United Kingdom},
	title = {{CLIEL}: context-based information extraction from commercial law documents},
	isbn = {978-1-4503-4891-1},
	shorttitle = {{CLIEL}},
	url = {https://dl.acm.org/doi/10.1145/3086512.3086520},
	doi = {10.1145/3086512.3086520},
	abstract = {The e�ectiveness of document Information Extraction (IE) is greatly a�ected by the structure and layout of the documents being considered. In the case of legal documents relating to commercial law, an additional challenge is the many di�erent and varied formats, structures and layouts used. In this paper, we present work on a �exible and scalable IE environment, the CLIEL (Commercial Law Information Extraction based on Layout) environment, for application to commercial law documentation that allows layout rules to be derived and then utilised to support IE. The proposed CLIEL environment operates using NLP (Natural Language Processing) techniques, JAPE (Java Annotation Patterns Engine) rules and some GATE (General Architecture for Text Engineering) modules. The system is fully described and evaluated using a commercial law document corpus. The results demonstrate that considering the layout is bene�cial for extracting data point instances from legal document collections.},
	language = {en},
	urldate = {2021-11-06},
	booktitle = {Proceedings of the 16th edition of the {International} {Conference} on {Articial} {Intelligence} and {Law}},
	publisher = {ACM},
	author = {García-Constantino, Matías and Atkinson, Katie and Bollegala, Danushka and Chapman, Karl and Coenen, Frans and Roberts, Claire and Robson, Katy},
	month = jun,
	year = {2017},
	pages = {79--87},
}

@inproceedings{Dataminingvisualizationlegaldocuments,
	title = {Data mining and visualization on legal documents},
	doi = {10.1109/ReTIS.2011.6146854},
	abstract = {LIRFSS (Legal Information Retrieval and Focused Semantic Search) is a system that performs IR(Information Retrieval) and IE(Information Extraction) on Indian Supreme Court decisions, specifically on criminal cases related to murder and provide focused semantic search results, offering a high potential of assistance for judges, lawyers and citizens in getting access to law. In this paper, development process of LIRFSS is discussed. Appropriate information to be extracted for criminal cases such as date, location of occurrence and IPC (Indian Penal code)[1] sections were determined from a sample set of documents. Better instruments than manual browsing and other search methods are required to make the most out of freely available law on internet, therefore a semantic search is carried out using extracted information and most pertinent cases were returned as a result. As analyzing the vast volumes of data becomes increasingly difficult, so information visualization is also carried out in this paper and a new hypotheses is proposed and verified. From 20 training documents, a satisfactory amount of precision was obtained.},
	booktitle = {2011 {International} {Conference} on {Recent} {Trends} in {Information} {Systems}},
	author = {Gaur, Dhruv},
	month = dec,
	year = {2011},
	pages = {132--136},
}

@misc{gensimTopicModellingPython,
	title = {gensim – {Topic} {Modelling} in {Python}},
	copyright = {LGPL-2.1},
	url = {https://github.com/RaRe-Technologies/gensim/blob/6e362663f23967f3c1931e2cb18d3d25f92aabb5/docs/notebooks/topic_methods.ipynb},
	abstract = {Topic Modelling for Humans},
	urldate = {2021-11-16},
	publisher = {RARE Technologies},
	month = nov,
	year = {2021},
	note = {original-date: 2011-02-10T07:43:04Z},
}

@article{Clinicalcognitiondiagnosticerrorapplications,
	title = {Clinical cognition and diagnostic error: applications of a dual process model of reasoning},
	volume = {14},
	issn = {1382-4996, 1573-1677},
	shorttitle = {Clinical cognition and diagnostic error},
	url = {http://link.springer.com/10.1007/s10459-009-9182-2},
	doi = {10.1007/s10459-009-9182-2},
	abstract = {Both systemic and individual factors contribute to missed or delayed diagnoses. Among the multiple factors that impact clinical performance of the individual, the caliber of cognition is perhaps the most relevant and deserves our attention and understanding. In the last few decades, cognitive psychologists have gained substantial insights into the processes that underlie cognition, and a new, universal model of reasoning and decision making has emerged, Dual Process Theory. The theory has immediate application to medical decision making and provides an overall schema for understanding the variety of theoretical approaches that have been taken in the past. The model has important practical applications for decision making across the multiple domains of healthcare, and may be used as a template for teaching decision theory, as well as a platform for future research. Importantly, speciﬁc operating characteristics of the model explain how diagnostic failure occurs.},
	language = {en},
	number = {S1},
	urldate = {2021-11-13},
	journal = {Advances in Health Sciences Education},
	author = {Croskerry, Pat},
	month = sep,
	year = {2009},
	pages = {27--35},
}

@article{EnhancingMeasuringConsumersMotivationOpportunity,
	title = {Enhancing and {Measuring} {Consumers}' {Motivation}, {Opportunity}, and {Ability} to {Process} {Brand} {Information} from {Ads}},
	volume = {55},
	issn = {00222429},
	url = {https://www.jstor.org/stable/1251955?origin=crossref},
	doi = {10.2307/1251955},
	language = {en},
	number = {4},
	urldate = {2021-11-13},
	journal = {Journal of Marketing},
	author = {MacInnis, Deborah J. and Moorman, Christine and Jaworski, Bernard J.},
	month = oct,
	year = {1991},
	pages = {32},
}

@article{Howcognitivepsychologychangedface,
	title = {How cognitive psychology changed the face of medical education research},
	volume = {25},
	issn = {1382-4996, 1573-1677},
	url = {http://link.springer.com/10.1007/s10459-020-10011-0},
	doi = {10.1007/s10459-020-10011-0},
	abstract = {In this article, the contributions of cognitive psychology to research and development of medical education are assessed. The cognitive psychology of learning consists of activation of prior knowledge while processing new information and elaboration on the resulting new knowledge to facilitate storing in long-term memory. This process is limited by the size of working memory. Six interventions based on cognitive theory that facilitate learning and expertise development are discussed: (1) Fostering self-explanation, (2) elaborative discussion, and (3) distributed practice; (4) help with decreasing cognitive load, (5) promoting retrieval practice, and (6) supporting interleaving practice. These interventions contribute in different measure to various instructional methods in use in medical education: problem-based learning, team-based learning, worked examples, mixed practice, serial-cue presentation, and deliberate reflection. The article concludes that systematic research into the applicability of these ideas to the practice of medical education presently is limited and should be intensified.},
	language = {en},
	number = {5},
	urldate = {2021-11-13},
	journal = {Advances in Health Sciences Education},
	author = {Schmidt, Henk G. and Mamede, Silvia},
	month = dec,
	year = {2020},
	pages = {1025--1043},
}

@article{DeliberationautomaticitydecisionmakingWhich,
	title = {Deliberation versus automaticity in decision making: {Which} presentation format features facilitate automatic decision making?},
	volume = {8},
	abstract = {The idea of automatic decision making approximating normatively optimal decisions without necessitating much cognitive effort is intriguing. Whereas recent ﬁndings support the notion that such fast, automatic processes explain empirical data well, little is known about the conditions under which such processes are selected rather than more deliberate stepwise strategies. We investigate the role of the format of information presentation, focusing explicitly on the ease of information acquisition and its inﬂuence on information integration processes. In a probabilistic inference task, the standard matrix employed in prior research was contrasted with a newly created map presentation format and additional variations of both presentation formats. Across three experiments, a robust presentation format effect emerged: Automatic decision making was more prevalent in the matrix (with high information accessibility), whereas sequential decision strategies prevailed when the presentation format demanded more information acquisition effort. Further scrutiny of the effect showed that it is not driven by the presentation format as such, but rather by the extent of information search induced by a format. Thus, if information is accessible with minimal need for information search, information integration is likely to proceed in a perception-like, holistic manner. In turn, a moderate demand for information search decreases the likelihood of behavior consistent with the assumptions of automatic decision making.},
	language = {en},
	number = {3},
	journal = {Judgment and Decision Making},
	author = {Söllner, Anke and Bröder, Arndt and Hilbig, Benjamin E},
	year = {2013},
	pages = {21},
}

@article{Deliberativespontaneouscognitiveprocessesassociated,
	title = {Deliberative and spontaneous cognitive processes associated with {HIV} risk behavior},
	volume = {36},
	issn = {0160-7715},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3465482/},
	doi = {10.1007/s10865-012-9404-6},
	abstract = {Dual process models of decision-making suggest that behavior is mediated by a spontaneous behavior selection process or by a more deliberative evaluation of behavioral options. We examined whether the deliberative system moderates the influence of spontaneous cognition on HIV-risk behaviors. A measure of spontaneous sex-related associations (word association), a measure of deliberative working memory capacity (operation span), and two measures of sexual behavior (condom use and multiple partners) were assessed in a cross-sectional study among 490 adult drug offenders. Significant effects were observed among men but not among women in two latent interaction models. In a novel finding, the accessibility of spontaneous safe sex-related associations was significantly more predictive of condom use among men with higher working memory capacity than among men with lower capacity. These results have implications for the design of interventions to promote safe sex practices.},
	number = {1},
	urldate = {2021-11-09},
	journal = {Journal of behavioral medicine},
	author = {Grenard, Jerry L. and Ames, Susan L. and Stacy, Alan W.},
	month = feb,
	year = {2013},
	pmid = {22331437},
	pmcid = {PMC3465482},
	pages = {95--107},
}

@inproceedings{Softwaretoolsvisualizationdefinitionnetworks,
	address = {Rome, Italy},
	title = {Software tools for the visualization of definition networks in legal contracts},
	isbn = {978-1-4503-2080-1},
	url = {http://dl.acm.org/citation.cfm?doid=2514601.2514625},
	doi = {10.1145/2514601.2514625},
	abstract = {This paper describes the development of prototype software-based tools for visualizing deﬁnitions within legal contracts. The tools demonstrate visualization techniques for enhancing the readability and comprehension of deﬁnitions and their associated characteristics. This contributes to more accurate and efﬁcient drafting or reading of contracts through the exploration of the meaning and use of deﬁnitions including via word clouds, multilayer navigation, adjacency matrix and graph tree representations.},
	language = {en},
	urldate = {2021-11-08},
	booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Artificial} {Intelligence} and {Law} - {ICAIL} '13},
	publisher = {ACM Press},
	author = {Curtotti, Michael and McCreath, Eric and Sridharan, Srinivas},
	year = {2013},
	pages = {192},
}

@article{VisualizingLawNormGraphVisualizationApproach,
	title = {Visualizing {Law} - {A} {Norm}-{Graph} {Visualization} {Approach} based on {Semantic} {Legal} {Data}},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/2543729},
	doi = {10.5281/ZENODO.2543729},
	abstract = {Laws or in general legal documents regulate a wide range of our daily life and also define the borders of business models and commercial services. However, legal text and laws are almost hard to understand. From other domains it is already known that visualizations can help understanding complex aspects easier. In fact, in this paper we introduce a new approach to visualize legal texts in a Norm-graph visualization. In the developed Norm-graph visualization it is possible to show major aspects of laws and make it easier for users to understand it. The Norm-graph is based on semantic legal data, a so called Legal-Concept-Ontology.},
	language = {en},
	urldate = {2021-11-08},
	author = {Burkhardt, Dirk and Nazemi, Kawa},
	month = sep,
	year = {2018},
	note = {Publisher: Zenodo
Version Number: v1},
	keywords = {Decision Support Systems, E-Government, Information Visualization, Law Visualization, Norm-graph, Policy Modeling, Semantic Data, Semantic Web},
}

@article{EnhancingVisualizationLaw,
	title = {Enhancing the {Visualization} of {Law}},
	issn = {1556-5068},
	url = {http://www.ssrn.com/abstract=2160614},
	doi = {10.2139/ssrn.2160614},
	language = {en},
	urldate = {2021-11-08},
	journal = {SSRN Electronic Journal},
	author = {Curtotti, Michael and McCreath, Eric},
	year = {2012},
}

@inproceedings{TransformingLegalDocumentsVisualizationAnalysis,
	address = {Galway Ireland},
	title = {Transforming {Legal} {Documents} for {Visualization} and {Analysis}},
	isbn = {978-1-4503-5421-9},
	url = {https://dl.acm.org/doi/10.1145/3209415.3209424},
	doi = {10.1145/3209415.3209424},
	language = {en},
	urldate = {2021-11-08},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Theory} and {Practice} of {Electronic} {Governance}},
	publisher = {ACM},
	author = {Carvalho, Nuno Ramos and Barbosa, Luís Soares},
	month = apr,
	year = {2018},
	pages = {23--26},
}

@article{ComparisonDiverseDecodingMethodsConditional,
	title = {Comparison of {Diverse} {Decoding} {Methods} from {Conditional} {Language} {Models}},
	url = {http://arxiv.org/abs/1906.06362},
	abstract = {While conditional language models have greatly improved in their ability to output high-quality natural language, many NLP applications benefit from being able to generate a diverse set of candidate sequences. Diverse decoding strategies aim to, within a given-sized candidate list, cover as much of the space of high-quality outputs as possible, leading to improvements for tasks that re-rank and combine candidate outputs. Standard decoding methods, such as beam search, optimize for generating high likelihood sequences rather than diverse ones, though recent work has focused on increasing diversity in these methods. In this work, we perform an extensive survey of decoding-time strategies for generating diverse outputs from conditional language models. We also show how diversity can be improved without sacrificing quality by over-sampling additional candidates, then filtering to the desired number.},
	urldate = {2021-11-27},
	journal = {arXiv:1906.06362 [cs]},
	author = {Ippolito, Daphne and Kriz, Reno and Kustikova, Maria and Sedoc, João and Callison-Burch, Chris},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.06362},
	keywords = {Computer Science - Computation and Language, beam-search, conditional-decoder},
}

@article{ImportanceSearchEvaluationStrategiesNeural,
	title = {Importance of {Search} and {Evaluation} {Strategies} in {Neural} {Dialogue} {Modeling}},
	url = {http://arxiv.org/abs/1811.00907},
	abstract = {We investigate the impact of search strategies in neural dialogue modeling. We first compare two standard search algorithms, greedy and beam search, as well as our newly proposed iterative beam search which produces a more diverse set of candidate responses. We evaluate these strategies in realistic full conversations with humans and propose a model-based Bayesian calibration to address annotator bias. These conversations are analyzed using two automatic metrics: log-probabilities assigned by the model and utterance diversity. Our experiments reveal that better search algorithms lead to higher rated conversations. However, finding the optimal selection mechanism to choose from a more diverse set of candidates is still an open question.},
	urldate = {2021-11-27},
	journal = {arXiv:1811.00907 [cs]},
	author = {Kulikov, Ilia and Miller, Alexander H. and Cho, Kyunghyun and Weston, Jason},
	month = nov,
	year = {2019},
	note = {arXiv: 1811.00907
version: 3},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, conditional-decoder},
}

@inproceedings{RetrievalAugmentedControllableReviewGeneration,
	address = {Barcelona, Spain (Online)},
	title = {Retrieval-{Augmented} {Controllable} {Review} {Generation}},
	url = {https://aclanthology.org/2020.coling-main.207},
	doi = {10.18653/v1/2020.coling-main.207},
	abstract = {In this paper, we study review generation given a set of attribute identifiers which are user ID, product ID and rating. This is a difficult subtask of natural language generation since models are limited to the given identifiers, without any specific descriptive information regarding the inputs, when generating the text. The capacity of these models is thus confined and dependent to how well the models can capture vector representations of attributes. We thus propose to additionally leverage references, which are selected from a large pool of texts labeled with one of the attributes, as textual information that enriches inductive biases of given attributes. With these references, we can now pose the problem as an instance of text-to-text generation, which makes the task easier since texts that are syntactically, semantically similar with the output text are provided as input. Using this framework, we address issues such as selecting references from a large candidate set without textual context and improving the model complexity for generation. Our experiments show that our models improve over previous approaches on both automatic and human evaluation metrics.},
	urldate = {2021-11-27},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {International Committee on Computational Linguistics},
	author = {Kim, Jihyeok and Choi, Seungtaek and Amplayo, Reinald Kim and Hwang, Seung-won},
	month = dec,
	year = {2020},
	pages = {2284--2295},
}

@article{DYPLOCDynamicPlanningContentUsing,
	title = {{DYPLOC}: {Dynamic} {Planning} of {Content} {Using} {Mixed} {Language} {Models} for {Text} {Generation}},
	shorttitle = {{DYPLOC}},
	url = {http://arxiv.org/abs/2106.00791},
	abstract = {We study the task of long-form opinion text generation, which faces at least two distinct challenges. First, existing neural generation models fall short of coherence, thus requiring efficient content planning. Second, diverse types of information are needed to guide the generator to cover both subjective and objective content. To this end, we propose DYPLOC, a generation framework that conducts dynamic planning of content while generating the output based on a novel design of mixed language models. To enrich the generation with diverse content, we further propose to use large pre-trained models to predict relevant concepts and to generate claims. We experiment with two challenging tasks on newly collected datasets: (1) argument generation with Reddit ChangeMyView, and (2) writing articles using New York Times' Opinion section. Automatic evaluation shows that our model significantly outperforms competitive comparisons. Human judges further confirm that our generations are more coherent with richer content.},
	language = {en},
	urldate = {2021-11-27},
	journal = {arXiv:2106.00791 [cs]},
	author = {Hua, Xinyu and Sreevatsa, Ashwin and Wang, Lu},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.00791},
	keywords = {Computer Science - Computation and Language},
}

@article{SequencetoSequenceLearningBeamSearchOptimization,
	title = {Sequence-to-{Sequence} {Learning} as {Beam}-{Search} {Optimization}},
	url = {http://arxiv.org/abs/1606.02960},
	abstract = {Sequence-to-Sequence (seq2seq) modeling has rapidly become an important general-purpose NLP tool that has proven effective for many text-generation and sequence-labeling tasks. Seq2seq builds on deep neural language modeling and inherits its remarkable accuracy in estimating local, next-word distributions. In this work, we introduce a model and beam-search training scheme, based on the work of Daume III and Marcu (2005), that extends seq2seq to learn global sequence scores. This structured approach avoids classical biases associated with local training and unifies the training loss with the test-time usage, while preserving the proven model architecture of seq2seq and its efficient training approach. We show that our system outperforms a highly-optimized attention-based seq2seq system and other baselines on three different sequence to sequence tasks: word ordering, parsing, and machine translation.},
	urldate = {2021-11-27},
	journal = {arXiv:1606.02960 [cs, stat]},
	author = {Wiseman, Sam and Rush, Alexander M.},
	month = nov,
	year = {2016},
	note = {arXiv: 1606.02960},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning, beam-search},
}

@article{DiversityPromotingObjectiveFunctionNeuralConversation,
	title = {A {Diversity}-{Promoting} {Objective} {Function} for {Neural} {Conversation} {Models}},
	url = {http://arxiv.org/abs/1510.03055},
	abstract = {Sequence-to-sequence neural network models for generation of conversational responses tend to generate safe, commonplace responses (e.g., "I don't know") regardless of the input. We suggest that the traditional objective function, i.e., the likelihood of output (response) given input (message) is unsuited to response generation tasks. Instead we propose using Maximum Mutual Information (MMI) as the objective function in neural models. Experimental results demonstrate that the proposed MMI models produce more diverse, interesting, and appropriate responses, yielding substantive gains in BLEU scores on two conversational datasets and in human evaluations.},
	urldate = {2021-11-27},
	journal = {arXiv:1510.03055 [cs]},
	author = {Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill},
	month = jun,
	year = {2016},
	note = {arXiv: 1510.03055},
	keywords = {Computer Science - Computation and Language, conditional-decoder},
}

@inproceedings{GraphEmbeddingsFrameIdentification,
	address = {Varna, Bulgaria},
	title = {Graph {Embeddings} for {Frame} {Identification}},
	url = {https://aclanthology.org/R19-1109},
	doi = {10.26615/978-954-452-056-4_109},
	abstract = {Lexical resources such as WordNet (Miller, 1995) and FrameNet (Baker et al., 1998) are organized as graphs, where relationships between words are made explicit via the structure of the resource. This work explores how structural information from these lexical resources can lead to gains in a downstream task, namely frame identification. While much of the current work in frame identification uses various neural architectures to predict frames, those neural architectures only use representations of frames based on annotated corpus data. We demonstrate how incorporating knowledge directly from the FrameNet graph structure improves the performance of a neural network-based frame identification system. Specifically, we construct a bidirectional LSTM with a loss function that incorporates various graph- and corpus-based frame embeddings for learning and ultimately achieves strong performance gains with the graph-based embeddings over corpus-based embeddings alone.},
	urldate = {2021-11-26},
	booktitle = {Proceedings of the {International} {Conference} on {Recent} {Advances} in {Natural} {Language} {Processing} ({RANLP} 2019)},
	publisher = {INCOMA Ltd.},
	author = {Popov, Alexander and Sikos, Jennifer},
	month = sep,
	year = {2019},
	pages = {939--948},
}

@inproceedings{HafezInteractivePoetryGenerationSystem,
	address = {Vancouver, Canada},
	title = {Hafez: an {Interactive} {Poetry} {Generation} {System}},
	shorttitle = {Hafez},
	url = {https://aclanthology.org/P17-4008},
	urldate = {2021-11-23},
	booktitle = {Proceedings of {ACL} 2017, {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Ghazvininejad, Marjan and Shi, Xing and Priyadarshi, Jay and Knight, Kevin},
	month = jul,
	year = {2017},
	pages = {43--48},
}

@article{LearningWriteCooperativeDiscriminators,
	title = {Learning to {Write} with {Cooperative} {Discriminators}},
	url = {http://arxiv.org/abs/1805.06087},
	abstract = {Recurrent Neural Networks (RNNs) are powerful autoregressive sequence models, but when used to generate natural language their output tends to be overly generic, repetitive, and self-contradictory. We postulate that the objective function optimized by RNN language models, which amounts to the overall perplexity of a text, is not expressive enough to capture the notion of communicative goals described by linguistic principles such as Grice's Maxims. We propose learning a mixture of multiple discriminative models that can be used to complement the RNN generator and guide the decoding process. Human evaluation demonstrates that text generated by our system is preferred over that of baselines by a large margin and significantly enhances the overall coherence, style, and information content of the generated text.},
	urldate = {2021-11-23},
	journal = {arXiv:1805.06087 [cs]},
	author = {Holtzman, Ari and Buys, Jan and Forbes, Maxwell and Bosselut, Antoine and Golub, David and Choi, Yejin},
	month = may,
	year = {2018},
	note = {arXiv: 1805.06087},
	keywords = {Computer Science - Computation and Language},
}

@article{VisuallyConnectingHistoricalFiguresEvent,
	title = {Visually {Connecting} {Historical} {Figures} {Through} {Event} {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2109.09380},
	abstract = {Knowledge graphs store information about historical figures and their relationships indirectly through shared events. We developed a visualization system, VisKonnect, for analyzing the intertwined lives of historical figures based on the events they participated in. A user's query is parsed for identifying named entities, and related data is retrieved from an event knowledge graph. While a short textual answer to the query is generated using the GPT-3 language model, various linked visualizations provide context, display additional information related to the query, and allow exploration.},
	urldate = {2021-11-21},
	journal = {arXiv:2109.09380 [cs]},
	author = {Latif, Shahid and Agarwal, Shivam and Gottschalk, Simon and Chrosch, Carina and Feit, Felix and Jahn, Johannes and Braun, Tobias and Tchenko, Yanick Christian and Demidova, Elena and Beck, Fabian},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.09380},
	keywords = {Computer Science - Human-Computer Interaction, kg},
}

@article{KGECLContrastiveLearningKnowledgeGraph,
	title = {{KGE}-{CL}: {Contrastive} {Learning} of {Knowledge} {Graph} {Embeddings}},
	shorttitle = {{KGE}-{CL}},
	url = {http://arxiv.org/abs/2112.04871},
	abstract = {Learning the embeddings of knowledge graphs is vital in artificial intelligence, and can benefit various downstream applications, such as recommendation and question answering. In recent years, many research efforts have been proposed for knowledge graph embedding. However, most previous knowledge graph embedding methods ignore the semantic similarity between the related entities and entity-relation couples in different triples since they separately optimize each triple with the scoring function. To address this problem, we propose a simple yet efficient contrastive learning framework for knowledge graph embeddings, which can shorten the semantic distance of the related entities and entity-relation couples in different triples and thus improve the expressiveness of knowledge graph embeddings. We evaluate our proposed method on three standard knowledge graph benchmarks. It is noteworthy that our method can yield some new state-of-the-art results, achieving 51.2\% MRR, 46.8\% Hits@1 on the WN18RR dataset, and 59.1\% MRR, 51.8\% Hits@1 on the YAGO3-10 dataset.},
	urldate = {2021-12-17},
	journal = {arXiv:2112.04871 [cs]},
	author = {Xu, Wentao and Luo, Zhiping and Liu, Weiqing and Bian, Jiang and Yin, Jian and Liu, Tie-Yan},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.04871},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, contrastive, kg},
}

@article{WriterForcingGeneratingmoreinterestingstory,
	title = {{WriterForcing}: {Generating} more interesting story endings},
	shorttitle = {{WriterForcing}},
	url = {http://arxiv.org/abs/1907.08259},
	abstract = {We study the problem of generating interesting endings for stories. Neural generative models have shown promising results for various text generation problems. Sequence to Sequence (Seq2Seq) models are typically trained to generate a single output sequence for a given input sequence. However, in the context of a story, multiple endings are possible. Seq2Seq models tend to ignore the context and generate generic and dull responses. Very few works have studied generating diverse and interesting story endings for a given story context. In this paper, we propose models which generate more diverse and interesting outputs by 1) training models to focus attention on important keyphrases of the story, and 2) promoting generation of non-generic words. We show that the combination of the two leads to more diverse and interesting endings.},
	language = {en},
	urldate = {2021-12-13},
	journal = {arXiv:1907.08259 [cs, stat]},
	author = {Gupta, Prakhar and Kumar, Vinayshekhar Bannihatti and Bhutani, Mukul and Black, Alan W.},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.08259},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning, conditional, decoder},
}

@inproceedings{LengthbiasEncoderDecoderModelsa,
	address = {Austin, Texas},
	title = {Length bias in {Encoder} {Decoder} {Models} and a {Case} for {Global} {Conditioning}},
	url = {https://aclanthology.org/D16-1158},
	doi = {10.18653/v1/D16-1158},
	urldate = {2021-12-12},
	booktitle = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Sountsov, Pavel and Sarawagi, Sunita},
	month = nov,
	year = {2016},
	keywords = {decoder, length},
	pages = {1516--1525},
}

@article{WhatAveragesNotTellPredicting,
	title = {What {Averages} {Do} {Not} {Tell} -- {Predicting} {Real} {Life} {Processes} with {Sequential} {Deep} {Learning}},
	url = {http://arxiv.org/abs/2110.10225},
	abstract = {Deep Learning is proven to be an effective tool for modeling sequential data as shown by the success in Natural Language, Computer Vision and Signal Processing. Process Mining concerns discovering insights on business processes from their execution data that are logged by supporting information systems. The logged data (event log) is formed of event sequences (traces) that correspond to executions of a process. Many Deep Learning techniques have been successfully adapted for predictive Process Mining that aims to predict process outcomes, remaining time, the next event, or even the suffix of running traces. Traces in Process Mining are multimodal sequences and very differently structured than natural language sentences or images. This may require a different approach to processing. So far, there has been little focus on these differences and the challenges introduced. Looking at suffix prediction as the most challenging of these tasks, the performance of Deep Learning models was evaluated only on average measures and for a small number of real-life event logs. Comparing the results between papers is difficult due to different pre-processing and evaluation strategies. Challenges that may be relevant are the skewness of trace-length distribution and the skewness of the activity distribution in real-life event logs. We provide an end-to-end framework which enables to compare the performance of seven state-of-the-art sequential architectures in common settings. Results show that sequence modeling still has a lot of room for improvement for majority of the more complex datasets. Further research and insights are required to get consistent performance not just in average measures but additionally over all the prefixes.},
	urldate = {2021-12-12},
	journal = {arXiv:2110.10225 [cs]},
	author = {Ketykó, István and Mannhardt, Felix and Hassani, Marwan and van Dongen, Boudewijn},
	month = oct,
	year = {2021},
	note = {arXiv: 2110.10225},
	keywords = {Computer Science - Machine Learning, decoder, length},
}

@inproceedings{LearningGenerateProductReviewsAttributes,
	address = {Valencia, Spain},
	title = {Learning to {Generate} {Product} {Reviews} from {Attributes}},
	url = {https://aclanthology.org/E17-1059},
	abstract = {Automatically generating product reviews is a meaningful, yet not well-studied task in sentiment analysis. Traditional natural language generation methods rely extensively on hand-crafted rules and predefined templates. This paper presents an attention-enhanced attribute-to-sequence model to generate product reviews for given attribute information, such as user, product, and rating. The attribute encoder learns to represent input attributes as vectors. Then, the sequence decoder generates reviews by conditioning its output on these vectors. We also introduce an attention mechanism to jointly generate reviews and align words with input attributes. The proposed model is trained end-to-end to maximize the likelihood of target product reviews given the attributes. We build a publicly available dataset for the review generation task by leveraging the Amazon book reviews and their metadata. Experiments on the dataset show that our approach outperforms baseline methods and the attention mechanism significantly improves the performance of our model.},
	urldate = {2021-12-07},
	booktitle = {Proceedings of the 15th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Volume} 1, {Long} {Papers}},
	publisher = {Association for Computational Linguistics},
	author = {Dong, Li and Huang, Shaohan and Wei, Furu and Lapata, Mirella and Zhou, Ming and Xu, Ke},
	month = apr,
	year = {2017},
	pages = {623--632},
}

@article{ControllingOutputLengthNeuralEncoderDecoders,
	title = {Controlling {Output} {Length} in {Neural} {Encoder}-{Decoders}},
	url = {http://arxiv.org/abs/1609.09552},
	abstract = {Neural encoder-decoder models have shown great success in many sequence generation tasks. However, previous work has not investigated situations in which we would like to control the length of encoder-decoder outputs. This capability is crucial for applications such as text summarization, in which we have to generate concise summaries with a desired length. In this paper, we propose methods for controlling the output sequence length for neural encoder-decoder models: two decoding-based methods and two learning-based methods. Results show that our learning-based methods have the capability to control length without degrading summary quality in a summarization task.},
	urldate = {2021-12-05},
	journal = {arXiv:1609.09552 [cs]},
	author = {Kikuchi, Yuta and Neubig, Graham and Sasano, Ryohei and Takamura, Hiroya and Okumura, Manabu},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.09552},
	keywords = {Computer Science - Computation and Language},
}

@article{OnceTimeVisualizationUnderstandingUse,
	title = {Once {Upon} {A} {Time} {In} {Visualization}: {Understanding} the {Use} of {Textual} {Narratives} for {Causality}},
	volume = {27},
	issn = {1941-0506},
	shorttitle = {Once {Upon} {A} {Time} {In} {Visualization}},
	doi = {10.1109/TVCG.2020.3030358},
	abstract = {Causality visualization can help people understand temporal chains of events, such as messages sent in a distributed system, cause and effect in a historical conflict, or the interplay between political actors over time. However, as the scale and complexity of these event sequences grows, even these visualizations can become overwhelming to use. In this paper, we propose the use of textual narratives as a data-driven storytelling method to augment causality visualization. We first propose a design space for how textual narratives can be used to describe causal data. We then present results from a crowdsourced user study where participants were asked to recover causality information from two causality visualizations-causal graphs and Hasse diagrams-with and without an associated textual narrative. Finally, we describe Causeworks, a causality visualization system for understanding how specific interventions influence a causal model. The system incorporates an automatic textual narrative mechanism based on our design space. We validate Causeworks through interviews with experts who used the system for understanding complex events.},
	number = {2},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Choudhry, Arjun and Sharma, Mandar and Chundury, Pramod and Kapler, Thomas and Gray, Derek W. S. and Ramakrishnan, Naren and Elmqvist, Niklas},
	month = feb,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Causality visualization, Correlation, Data visualization, Natural languages, Pipelines, Task analysis, Tools, Visualization, data-driven storytelling, natural language generation, nlp, quantitative studies, temporal data, vis},
	pages = {1332--1342},
}

@article{CUADExpertAnnotatedNLPDatasetLegal,
	title = {{CUAD}: {An} {Expert}-{Annotated} {NLP} {Dataset} for {Legal} {Contract} {Review}},
	shorttitle = {{CUAD}},
	url = {http://arxiv.org/abs/2103.06268},
	abstract = {Many specialized domains remain untouched by deep learning, as large labeled datasets require expensive expert annotators. We address this bottleneck within the legal domain by introducing the Contract Understanding Atticus Dataset (CUAD), a new dataset for legal contract review. CUAD was created with dozens of legal experts from The Atticus Project and consists of over 13,000 annotations. The task is to highlight salient portions of a contract that are important for a human to review. We find that Transformer models have nascent performance, but that this performance is strongly influenced by model design and training dataset size. Despite these promising results, there is still substantial room for improvement. As one of the only large, specialized NLP benchmarks annotated by experts, CUAD can serve as a challenging research benchmark for the broader NLP community.},
	urldate = {2021-11-29},
	journal = {arXiv:2103.06268 [cs]},
	author = {Hendrycks, Dan and Burns, Collin and Chen, Anya and Ball, Spencer},
	month = nov,
	year = {2021},
	note = {arXiv: 2103.06268},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, dataset, legal},
}

@article{DistantSupervisionKnowledgeGraphs,
	title = {Distant {Supervision} from {Knowledge} {Graphs}},
	language = {en},
	author = {Smirnova, Alisa and Audiffren, Julien and Cudre-Mauroux, Philippe},
	keywords = {kg, survey},
	pages = {9},
}

@article{UnderstandingEffectOutofdistributionExamplesInteractive,
	title = {Understanding the {Effect} of {Out}-of-distribution {Examples} and {Interactive} {Explanations} on {Human}-{AI} {Decision} {Making}},
	volume = {5},
	issn = {2573-0142},
	url = {http://arxiv.org/abs/2101.05303},
	doi = {10.1145/3479552},
	abstract = {Although AI holds promise for improving human decision making in societally critical domains, it remains an open question how human-AI teams can reliably outperform AI alone and human alone in challenging prediction tasks (also known as complementary performance). We explore two directions to understand the gaps in achieving complementary performance. First, we argue that the typical experimental setup limits the potential of human-AI teams. To account for lower AI performance out-of-distribution than in-distribution because of distribution shift, we design experiments with different distribution types and investigate human performance for both in-distribution and out-of-distribution examples. Second, we develop novel interfaces to support interactive explanations so that humans can actively engage with AI assistance. Using virtual pilot studies and large-scale randomized experiments across three tasks, we demonstrate a clear difference between in-distribution and out-of-distribution, and observe mixed results for interactive explanations: while interactive explanations improve human perception of AI assistance's usefulness, they may reinforce human biases and lead to limited performance improvement. Overall, our work points out critical challenges and future directions towards enhancing human performance with AI assistance.},
	number = {CSCW2},
	urldate = {2022-01-05},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Liu, Han and Lai, Vivian and Tan, Chenhao},
	month = oct,
	year = {2021},
	note = {arXiv: 2101.05303},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, fatml, ood, uu, xai},
	pages = {1--45},
}

@article{UnderstandingEffectOutofdistributionExamplesInteractivea,
	title = {Understanding the {Effect} of {Out}-of-distribution {Examples} and {Interactive} {Explanations} on {Human}-{AI} {Decision} {Making}},
	volume = {5},
	issn = {2573-0142},
	url = {http://arxiv.org/abs/2101.05303},
	doi = {10.1145/3479552},
	abstract = {Although AI holds promise for improving human decision making in societally critical domains, it remains an open question how human-AI teams can reliably outperform AI alone and human alone in challenging prediction tasks (also known as complementary performance). We explore two directions to understand the gaps in achieving complementary performance. First, we argue that the typical experimental setup limits the potential of human-AI teams. To account for lower AI performance out-of-distribution than in-distribution because of distribution shift, we design experiments with different distribution types and investigate human performance for both in-distribution and out-of-distribution examples. Second, we develop novel interfaces to support interactive explanations so that humans can actively engage with AI assistance. Using virtual pilot studies and large-scale randomized experiments across three tasks, we demonstrate a clear difference between in-distribution and out-of-distribution, and observe mixed results for interactive explanations: while interactive explanations improve human perception of AI assistance's usefulness, they may reinforce human biases and lead to limited performance improvement. Overall, our work points out critical challenges and future directions towards enhancing human performance with AI assistance.},
	language = {en},
	number = {CSCW2},
	urldate = {2022-01-05},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Liu, Han and Lai, Vivian and Tan, Chenhao},
	month = oct,
	year = {2021},
	note = {arXiv: 2101.05303},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
	pages = {1--45},
}

@inproceedings{WhyChicagodeceptiveBuildingModelDriven,
	address = {Honolulu HI USA},
	title = {"{Why} is '{Chicago}' deceptive?" {Towards} {Building} {Model}-{Driven} {Tutorials} for {Humans}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {"{Why} is '{Chicago}' deceptive?},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376873},
	doi = {10.1145/3313831.3376873},
	abstract = {To support human decision making with machine learning models, we often need to elucidate patterns embedded in the models that are unsalient, unknown, or counterintuitive to humans. While existing approaches focus on explaining machine predictions with real-time assistance, we explore model-driven tutorials to help humans understand these patterns in a training phase. We consider both tutorials with guidelines from scientiﬁc papers, analogous to current practices of science communication, and automatically selected examples from training data with explanations. We use deceptive review detection as a testbed and conduct large-scale, randomized human-subject experiments to examine the effectiveness of such tutorials. We ﬁnd that tutorials indeed improve human performance, with and without real-time assistance. In particular, although deep learning provides superior predictive performance than simple models, tutorials and explanations from simple models are more useful to humans. Our work suggests future directions for human-centered tutorials and explanations towards a synergy between humans and AI.},
	language = {en},
	urldate = {2022-01-05},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lai, Vivian and Liu, Han and Tan, Chenhao},
	month = apr,
	year = {2020},
	keywords = {fatml, xai},
	pages = {1--13},
}

@article{ScienceHumanAIDecisionMakingSurvey,
	title = {Towards a {Science} of {Human}-{AI} {Decision} {Making}: {A} {Survey} of {Empirical} {Studies}},
	language = {en},
	author = {Lai, Vivian and Chen, Chacha and Liao, Q Vera and Smith-Renner, Alison and Tan, Chenhao},
	keywords = {fatml, xai},
	pages = {36},
}

@article{ScienceHumanAIDecisionMakingSurveya,
	title = {Towards a {Science} of {Human}-{AI} {Decision} {Making}: {A} {Survey} of {Empirical} {Studies}},
	language = {en},
	author = {Lai, Vivian and Chen, Chacha and Liao, Q Vera and Smith-Renner, Alison and Tan, Chenhao},
	pages = {36},
}

@article{NaturalLanguageInterfacesDataVisualizationa,
	title = {Towards {Natural} {Language} {Interfaces} for {Data} {Visualization}: {A} {Survey}},
	shorttitle = {Towards {Natural} {Language} {Interfaces} for {Data} {Visualization}},
	url = {http://arxiv.org/abs/2109.03506},
	abstract = {Utilizing Visualization-oriented Natural Language Interfaces (V-NLI) as a complementary input modality to direct manipulation for visual analytics can provide an engaging user experience. It enables users to focus on their tasks rather than worrying about operating the interface to visualization tools. In the past two decades, leveraging advanced natural language processing technologies, numerous V-NLI systems have been developed both within academic research and commercial software, especially in recent years. In this article, we conduct a comprehensive review of the existing V-NLIs. In order to classify each paper, we develop categorical dimensions based on a classic information visualization pipeline with the extension of a V-NLI layer. The following seven stages are used: query understanding, data transformation, visual mapping, view transformation, human interaction, context management, and presentation. Finally, we also shed light on several promising directions for future work in the community.},
	language = {en},
	urldate = {2021-12-24},
	journal = {arXiv:2109.03506 [cs]},
	author = {Shen, Leixian and Shen, Enya and Luo, Yuyu and Yang, Xiaocong and Hu, Xuming and Zhang, Xiongshuai and Tai, Zhiwei and Wang, Jianmin},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.03506},
	keywords = {Computer Science - Human-Computer Interaction},
}

@article{LengthbiasEncoderDecoderModels,
	title = {Length bias in {Encoder} {Decoder} {Models} and a {Case} for {Global} {Conditioning}},
	url = {http://arxiv.org/abs/1606.03402},
	abstract = {Encoder-decoder networks are popular for modeling sequences probabilistically in many applications. These models use the power of the Long Short-Term Memory (LSTM) architecture to capture the full dependence among variables, unlike earlier models like CRFs that typically assumed conditional independence among non-adjacent variables. However in practice encoder-decoder models exhibit a bias towards short sequences that surprisingly gets worse with increasing beam size.},
	language = {en},
	urldate = {2021-12-24},
	journal = {arXiv:1606.03402 [cs]},
	author = {Sountsov, Pavel and Sarawagi, Sunita},
	month = sep,
	year = {2016},
	note = {arXiv: 1606.03402},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, conditional-decoder},
}

@article{NaturalLanguageInterfacesDataVisualization,
	title = {Towards {Natural} {Language} {Interfaces} for {Data} {Visualization}: {A} {Survey}},
	shorttitle = {Towards {Natural} {Language} {Interfaces} for {Data} {Visualization}},
	url = {http://arxiv.org/abs/2109.03506},
	abstract = {Utilizing Visualization-oriented Natural Language Interfaces (V-NLI) as a complementary input modality to direct manipulation for visual analytics can provide an engaging user experience. It enables users to focus on their tasks rather than worrying about operating the interface to visualization tools. In the past two decades, leveraging advanced natural language processing technologies, numerous V-NLI systems have been developed both within academic research and commercial software, especially in recent years. In this article, we conduct a comprehensive review of the existing V-NLIs. In order to classify each paper, we develop categorical dimensions based on a classic information visualization pipeline with the extension of a V-NLI layer. The following seven stages are used: query understanding, data transformation, visual mapping, view transformation, human interaction, context management, and presentation. Finally, we also shed light on several promising directions for future work in the community.},
	language = {en},
	urldate = {2021-12-24},
	journal = {arXiv:2109.03506 [cs]},
	author = {Shen, Leixian and Shen, Enya and Luo, Yuyu and Yang, Xiaocong and Hu, Xuming and Zhang, Xiongshuai and Tai, Zhiwei and Wang, Jianmin},
	month = sep,
	year = {2021},
	note = {arXiv: 2109.03506},
	keywords = {Computer Science - Human-Computer Interaction},
}

@article{Query2QuestionTranslatingVisualizationInteractionNatural,
	title = {{Query2Question}: {Translating} {Visualization} {Interaction} into {Natural} {Language}},
	volume = {21},
	issn = {1941-0506},
	shorttitle = {{Query2Question}},
	doi = {10.1109/TVCG.2015.2396062},
	abstract = {Richly interactive visualization tools are increasingly popular for data exploration and analysis in a wide variety of domains. Existing systems and techniques for recording provenance of interaction focus either on comprehensive automated recording of low-level interaction events or on idiosyncratic manual transcription of high-level analysis activities. In this paper, we present the architecture and translation design of a query-to-question (Q2Q) system that automatically records user interactions and presents them semantically using natural language (written English). Q2Q takes advantage of domain knowledge and uses natural language generation (NLG) techniques to translate and transcribe a progression of interactive visualization states into a visual log of styled text that complements and effectively extends the functionality of visualization tools. We present Q2Q as a means to support a cross-examination process in which questions rather than interactions are the focus of analytic reasoning and action. We describe the architecture and implementation of the Q2Q system, discuss key design factors and variations that effect question generation, and present several visualizations that incorporate Q2Q for analysis in a variety of knowledge domains.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Nafari, Maryam and Weaver, Chris},
	month = jun,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Cognition, Coordinated multiple views, Data visualization, Games, History, Manuals, Natural languages, Visualization, interaction translation, natural language generation, nlp, vis, visualization provenance},
	pages = {756--769},
}

@article{ContrastiveIdentificationCovariateShiftImagea,
	title = {Contrastive {Identification} of {Covariate} {Shift} in {Image} {Data}},
	url = {http://arxiv.org/abs/2108.08000},
	abstract = {Identifying covariate shift is crucial for making machine learning systems robust in the real world and for detecting training data biases that are not reflected in test data. However, detecting covariate shift is challenging, especially when the data consists of high-dimensional images, and when multiple types of localized covariate shift affect different subspaces of the data. Although automated techniques can be used to detect the existence of covariate shift, our goal is to help human users characterize the extent of covariate shift in large image datasets with interfaces that seamlessly integrate information obtained from the detection algorithms. In this paper, we design and evaluate a new visual interface that facilitates the comparison of the local distributions of training and test data. We conduct a quantitative user study on multi-attribute facial data to compare two different learned low-dimensional latent representations (pretrained ImageNet CNN vs. density ratio) and two user analytic workflows (nearest-neighbor vs. cluster-to-cluster). Our results indicate that the latent representation of our density ratio model, combined with a nearest-neighbor comparison, is the most effective at helping humans identify covariate shift.},
	language = {en},
	urldate = {2022-01-24},
	journal = {arXiv:2108.08000 [cs]},
	author = {Olson, Matthew L. and Nguyen, Thuy-Vy and Dixit, Gaurav and Ratzlaff, Neale and Wong, Weng-Keen and Kahng, Minsuk},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.08000},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
}

@article{MotivationopportunityabilityUnderstandingnew,
	title = {Motivation, opportunity, and ability: {Understanding} new habits and changes adopted for weight management},
	volume = {41},
	issn = {1470-6431},
	shorttitle = {Motivation, opportunity, and ability},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/ijcs.12340},
	doi = {10.1111/ijcs.12340},
	abstract = {As obesity rates continue to rise, both effective prevention and treatment programs are urgently required. Combating obesity requires weight management programs that are accessible and scalable to large numbers of people. There is growing evidence that commercial programs, which combine behavior change techniques with the key motivators for changing habits, are effective as the first line in helping people adopt healthier dietary and activity patterns. In particular, digital programs have the potential to provide a service to large numbers of people, be widely accessible and cost effective for the individual. However, to date, digital programs have been relatively under-utilized and under-evaluated. There is little published evidence on the performance of programs on a large scale, outside of partnerships with primary care, where participants self-refer and pay a nominal fee. The purpose of the following study was to examine the interrelated effect of motivation, opportunity, and ability on the behavioral outcomes of a digital commercial weight management program. To address this aim, a thematic content analysis of participants' qualitative responses to habits learned and changes adopted was conducted. Findings reveal that habits learned and changes adopted as a result of participating in the program influence not only weight loss outcomes but other health and well-being outcomes as well.},
	language = {en},
	number = {3},
	urldate = {2022-01-06},
	journal = {International Journal of Consumer Studies},
	author = {Willmott, Taylor and Parkinson, Joy},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ijcs.12340},
	pages = {291--298},
}

@article{SampleSizeCalculation,
	title = {Sample {Size} {Calculation}},
	language = {en},
	author = {Williamson, Mark},
	keywords = {stat},
	pages = {106},
}

@article{DiversityLimitsHumanExplanations,
	title = {On the {Diversity} and {Limits} of {Human} {Explanations}},
	url = {http://arxiv.org/abs/2106.11988},
	abstract = {A growing effort in NLP aims to build datasets of human explanations. However, the term explanation encompasses a broad range of notions, each with different properties and ramifications. Our goal is to provide an overview of diverse types of explanations and human limitations, and discuss implications for collecting and using explanations in NLP. Inspired by prior work in psychology and cognitive sciences, we group existing human explanations in NLP into three categories: proximal mechanism, evidence, and procedure. These three types differ in nature and have implications for the resultant explanations. For instance, procedure is not considered explanations in psychology and connects with a rich body of work on learning from instructions. The diversity of explanations is further evidenced by proxy questions that are needed for annotators to interpret and answer open-ended why questions. Finally, explanations may require different, often deeper, understandings than predictions, which casts doubt on whether humans can provide useful explanations in some tasks.},
	urldate = {2022-01-05},
	journal = {arXiv:2106.11988 [cs]},
	author = {Tan, Chenhao},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.11988},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, explanation},
}

@incollection{EpistemicContextualism,
	edition = {Spring 2021},
	title = {Epistemic {Contextualism}},
	url = {https://plato.stanford.edu/archives/spr2021/entries/contextualism-epistemology/},
	abstract = {Epistemic Contextualism (EC) is a recent and hotly debated position. EC is roughly the view that what is expressed by a knowledge attribution — a claim to the effect that S “knows” that p — depends partly on something in the context of the attributor, and hence the view is often called ‘attributor contextualism’. Because such an utterance is context-dependent, so too is whether the attribution is true. The typical EC view identifies the pivotal contextual features as the attributor’s practical stake in the truth of p, or the prominence in the attributor’s situation of skeptical doubts about knowledge. The typical EC view has it that as the stakes rise or the skeptical doubts become more serious, the contextual standard gets more demanding. It requires S to be in a better position if the attributor’s claim, “S knows that p”, is to express a truth. In contrast, Invariantists about knowledge hold that such factors in the attributor’s context do not affect the standards that must be met by a true “knowledge” attribution., In addition to marking an important departure from traditional epistemological assumptions, EC is claimed to provide a novel resolution to certain puzzles about knowledge—not least, skeptical ones—as well as to best comport with our everyday “knowledge”-attributing practices. What follows describes the leading forms of EC, so understood, as well as the principal arguments for and major objections to EC. Along the way, EC is situated with respect to certain other views, both kindred and competing.},
	urldate = {2022-02-07},
	booktitle = {The {Stanford} {Encyclopedia} of {Philosophy}},
	publisher = {Metaphysics Research Lab, Stanford University},
	author = {Rysiew, Patrick},
	editor = {Zalta, Edward N.},
	year = {2021},
	keywords = {epistemic paradoxes, epistemology, explanation, knowledge: analysis of, skepticism, testimony: epistemological problems of},
}

@article{ExplanatoryRelevanceContrastiveExplanation,
	title = {Explanatory {Relevance} and {Contrastive} {Explanation}},
	volume = {85},
	issn = {0031-8248, 1539-767X},
	url = {https://www.cambridge.org/core/journals/philosophy-of-science/article/explanatory-relevance-and-contrastive-explanation/14A0777C82503E6601A403EBD99847F1},
	doi = {10.1086/699715},
	abstract = {A pluralist about explanation posits many explanatory relevance relations, while an invariantist denies any substantial role for context in fixing genuine explanation. This article summarizes one approach to combining pluralism and invariantism that emphasizes the contrastive nature of explanation. If explanations always take contrasts as their objects and contrasts come in types, then the role for the context in which an explanation is given can be minimized. This approach is illustrated using a classic debate between natural theology and natural selection about the structure of bees’ honeycombs.},
	language = {en},
	number = {5},
	urldate = {2022-02-07},
	journal = {Philosophy of Science},
	author = {Pincock, Christopher},
	month = dec,
	year = {2018},
	note = {Publisher: Cambridge University Press},
	keywords = {explanation},
	pages = {806--818},
}

@article{AIHealthcareSystemInterfaceExplanation,
	title = {{AI} {Healthcare} {System} {Interface}: {Explanation} {Design} for {Non}-{Expert} {User} {Trust}},
	abstract = {Research indicates that non-expert users tend to either over-trust or distrust AI systems. This raises concerns when AI is applied to healthcare, where a patient trusting the advice of an unreliable system, or completely distrusting a reliable one, can lead to fatal incidents or missed healthcare opportunities. Previous research indicated that explanations can help users to make appropriate judgements on AI Systems’ trust, but how to design AI explanation interfaces for non-expert users in a medical support scenarios is still an open research challenge. This paper explores a stage-based participatory design process to develop a trustworthy explanation interface for non-experts in an AI medical support scenario. A trustworthy explanation is an explanation that helps users to make considered judgments on trusting (or not) and AI system for their healthcare. The objective of this paper was to identify the explanation components that can effectively inform the design of a trustworthy explanation interface. To achieve that, we undertook three data collections, examining experts’ and non-experts’ perceptions of AI medical support system’s explanations. We then developed a User Mental Model, an Expert Mental Model, and a Target Mental Model of explanation, describing how non-expert and experts understand explanations, how their understandings differ, and how it can be combined. Based on the Target Mental Model, we then propose a set of 14 explanation design guidelines for trustworthy AI Healthcare System explanation, that take into account non-expert users needs, medical experts practice, and AI experts understanding.},
	language = {en},
	author = {Larasati, Retno and Liddo, Anna De and Motta, Enrico},
	pages = {11},
}

@article{DeepLearningMultidimensionalProjections,
	title = {Deep {Learning} {Multidimensional} {Projections}},
	url = {http://arxiv.org/abs/1902.07958},
	abstract = {Dimensionality reduction methods, also known as projections, are frequently used for exploring multidimensional data in machine learning, data science, and information visualization. Among these, t-SNE and its variants have become very popular for their ability to visually separate distinct data clusters. However, such methods are computationally expensive for large datasets, suffer from stability problems, and cannot directly handle out-of-sample data. We propose a learning approach to construct such projections. We train a deep neural network based on a collection of samples from a given data universe, and their corresponding projections, and next use the network to infer projections of data from the same, or similar, universes. Our approach generates projections with similar characteristics as the learned ones, is computationally two to three orders of magnitude faster than SNE-class methods, has no complex-to-set user parameters, handles out-of-sample data in a stable manner, and can be used to learn any projection technique. We demonstrate our proposal on several real-world high dimensional datasets from machine learning.},
	urldate = {2022-02-02},
	journal = {arXiv:1902.07958 [cs, stat]},
	author = {Espadoto, Mateus and Hirata, Nina S. T. and Telea, Alexandru C.},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.07958},
	keywords = {dim\_red, vis},
}

@article{HumanCenteredMachineLearningInteractiveVisualization,
	title = {Human-{Centered} {Machine} {Learning} {Through} {Interactive} {Visualization}: {Review} and {Open} {Challenges}},
	abstract = {The goal of visual analytics (VA) systems is to solve complex problems by integrating automated data analysis methods, such as machine learning (ML) algorithms, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and makes the crucial interplay between automated algorithms and interactive visualizations more concrete. The framework is illustrated through several examples. We derive three open research challenges at the intersection of ML and visualization research that will lead to more effective data analysis.},
	language = {en},
	journal = {Computational Intelligence},
	author = {Sacha, Dominik and Sedlmair, Michael and Zhang, Leishi and Lee, John Aldo and Weiskopf, Daniel and North, Stephen and Keim, Daniel},
	year = {2016},
	keywords = {hci, survey, vis},
	pages = {8},
}

@article{IterativeHumanintheLoopDiscoveryUnknownUnknowns,
	title = {Iterative {Human}-in-the-{Loop} {Discovery} of {Unknown} {Unknowns} in {Image} {Datasets}},
	abstract = {Automatic predictions (e.g., recognizing objects in images) may result in systematic errors if certain classes are not well represented by training instances (these errors are called unknowns). When a model assigns high conﬁdence scores to these wrong predictions (this type of error is called unknown unknowns), it becomes challenging to automatically identify them. In this paper, we present the ﬁrst work on leveraging human intelligence to discover unknown unknowns (UUs) in an iterative way. The proposed methodology ﬁrst differentiates the feature space generated by crowd workers labelling instances (e.g., images) in an active learning fashion from the space learned by the prediction model over a batch training phase, and thus identiﬁes the predictions most likely to be UUs. Next, we add crowd labels collected for these discovered UUs to the training set and re-train the model with this extended dataset. This process is then repeated iteratively to discover more instances of both unknown and underrepresented classes. Our experimental results show that the proposed methodology is able to (i) efﬁciently discover UUs, (ii) signiﬁcantly improve the quality of model predictions, and (iii) to push UUs into known unknowns (i.e., the model makes mistakes but at least its classiﬁcation conﬁdence on those instances is low so those predictions can be discarded or post-processed) for further investigation. We additionally discuss the trade-off between prediction quality improvements and the human effort required to achieve those improvements. Our results bear implications on building cost-effective systems to discover UUs with humans in the loop.},
	language = {en},
	author = {Han, Lei and Dong, Xiao and Demartini, Gianluca},
	keywords = {ESCAPE, uu},
	pages = {12},
}

@article{ContrastiveIdentificationCovariateShiftImage,
	title = {Contrastive {Identification} of {Covariate} {Shift} in {Image} {Data}},
	url = {http://arxiv.org/abs/2108.08000},
	abstract = {Identifying covariate shift is crucial for making machine learning systems robust in the real world and for detecting training data biases that are not reflected in test data. However, detecting covariate shift is challenging, especially when the data consists of high-dimensional images, and when multiple types of localized covariate shift affect different subspaces of the data. Although automated techniques can be used to detect the existence of covariate shift, our goal is to help human users characterize the extent of covariate shift in large image datasets with interfaces that seamlessly integrate information obtained from the detection algorithms. In this paper, we design and evaluate a new visual interface that facilitates the comparison of the local distributions of training and test data. We conduct a quantitative user study on multi-attribute facial data to compare two different learned low-dimensional latent representations (pretrained ImageNet CNN vs. density ratio) and two user analytic workflows (nearest-neighbor vs. cluster-to-cluster). Our results indicate that the latent representation of our density ratio model, combined with a nearest-neighbor comparison, is the most effective at helping humans identify covariate shift.},
	language = {en},
	urldate = {2022-01-24},
	journal = {arXiv:2108.08000 [cs]},
	author = {Olson, Matthew L. and Nguyen, Thuy-Vy and Dixit, Gaurav and Ratzlaff, Neale and Wong, Weng-Keen and Kahng, Minsuk},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.08000},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, ESCAPE, uu, vis},
}

@article{Project412ConnectBridgingStudentsCommunities,
	title = {Project {412Connect}: {Bridging} {Students} and {Communities}},
	shorttitle = {Project {412Connect}},
	url = {http://arxiv.org/abs/2109.06287},
	abstract = {In this work, we describe some of the challenges Black-owned businesses face in the United States, and specifically in the city of Pittsburgh. Taking into account local dynamics and the communicated desires of Black-owned businesses in the Pittsburgh region, we determine that university students represent an under-utilized market for these businesses. We investigate the root causes for this inefficiency and design and implement a platform, 412Connect (https://www.412connect.org/), to increase online support for Pittsburgh Black-owned businesses from students in the Pittsburgh university community. The site operates by coordinating interactions between student users and participating businesses via targeted recommendations. For platform designers, we describe the project from its conception, paying special attention to our motivation and design choices. Our design choices are aided by two simple, novel models for badge design and recommendation systems that may be of theoretical interest. Along the way we highlight challenges and lessons from coordinating a grassroots volunteer project working in conjunction with community partners, and the opportunities and pitfalls of engaged scholarship.},
	urldate = {2022-02-14},
	journal = {arXiv:2109.06287 [cs]},
	author = {DiChristofano, Alex and Hamilton, Michael L. and Linardi, Sera and McCloud, Mara F.},
	month = oct,
	year = {2021},
	note = {arXiv: 2109.06287},
	keywords = {Computer Science - Computers and Society},
}

@phdthesis{Visualanalysisrelationalpatternsmultidimensional,
	address = {Clear Water Bay, Kowloon, Hong Kong},
	type = {Ph.{D}.},
	title = {Visual analysis of relational patterns in multidimensional data},
	url = {http://lbezone.ust.hk/bib/b1198602},
	language = {en},
	urldate = {2022-02-13},
	school = {The Hong Kong University of Science and Technology},
	author = {Cao, Nan},
	year = {2012},
	doi = {10.14711/thesis-b1198602},
	note = {Pages: b1198602},
}

@inproceedings{UnderstandingVisualizingDataIterationMachine,
	address = {Honolulu HI USA},
	title = {Understanding and {Visualizing} {Data} {Iteration} in {Machine} {Learning}},
	isbn = {978-1-4503-6708-0},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376177},
	doi = {10.1145/3313831.3376177},
	abstract = {Successful machine learning (ML) applications require iterations on both modeling and the underlying data. While prior visualization tools for ML primarily focus on modeling, our interviews with 23 ML practitioners reveal that they improve model performance frequently by iterating on their data (e.g., collecting new data, adding labels) rather than their models. We also identify common types of data iterations and associated analysis tasks and challenges. To help attribute data iterations to model performance, we design a collection of interactive visualizations and integrate them into a prototype, CHAMELEON, that lets users compare data features, training/testing splits, and performance across data versions. We present two case studies where developers apply CHAMELEON to their own evolving datasets on production ML projects. Our interface helps them verify data collection efforts, ﬁnd failure cases stretching across data versions, capture data processing changes that impacted performance, and identify opportunities for future data iterations.},
	language = {en},
	urldate = {2022-02-13},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Hohman, Fred and Wongsuphasawat, Kanit and Kery, Mary Beth and Patel, Kayur},
	month = apr,
	year = {2020},
	pages = {1--13},
}

@misc{Contrastscounterfactualscauses,
	title = {Contrasts, counterfactuals, and causes},
	abstract = {ejt.sagepub.com},
	author = {Grynaviski, Eric},
	keywords = {contrastive, counterfactual, explanation},
}

@article{InfluencingPreferencesDifferentTypesCausal,
	title = {Influencing {Preferences} for {Different} {Types} of {Causal} {Explanation} of {Complex} {Events}},
	volume = {56},
	issn = {0018-7208},
	url = {https://doi.org/10.1177/0018720814530427},
	doi = {10.1177/0018720814530427},
	abstract = {Objective:We examined preferences for different forms of causal explanations for indeterminate situations.Background:Klein and Hoffman distinguished several forms of causal explanations for indeterminate, complex situations: single-cause explanations, lists of causes, and explanations that interrelate several causes. What governs our preferences for single-cause (simple) versus multiple-cause (complex) explanations?Method:In three experiments, we examined the effect of target audience, explanatory context, participant nationality, and explanation type. All participants were college students. Participants were given two scenarios, one regarding the U.S. economic collapse in 2007 to 2008 and the other about the sudden success of the U.S. military in Iraq in 2007. The participants were asked to assess various types of causal explanations for each of the scenarios, with reference to one or more purposes or audience for the explanations.Results:Participants preferred simple explanations for presentation to less sophisticated audiences. Malaysian students of Chinese ethnicity preferred complex explanations more than did American students. The form of presentation made a difference: Participants preferred complex to simple explanations when given a chance to compare the two, but the preference for simple explanations increased when there was no chance for comparison, and the difference between Americans and Malaysians disappeared.Conclusions:Preferences for explanation forms can vary with the context and with the audience, and they depend on the nature of the alternatives that are provided.Application:Guidance for decision-aiding technology and training systems that provide explanations need to involve consideration of the form and depth of the accounts provided as well as the intended audience.},
	number = {8},
	urldate = {2022-02-07},
	journal = {Human Factors},
	author = {Klein, Gary and Rasmussen, Louise and Lin, Mei-Hua and Hoffman, Robert R. and Case, Jason},
	year = {2014},
	note = {Publisher: SAGE Publications Inc},
	keywords = {explanation},
	pages = {1380--1400},
}

@inproceedings{WorkflowVisualDiagnosticsBinaryClassifiers,
	title = {A {Workflow} for {Visual} {Diagnostics} of {Binary} {Classifiers} using {Instance}-{Level} {Explanations}},
	doi = {10.1109/VAST.2017.8585720},
	abstract = {Human-in-the-loop data analysis applications necessitate greater transparency in machine learning models for experts to understand and trust their decisions. To this end, we propose a visual analytics workflow to help data scientists and domain experts explore, diagnose, and understand the decisions made by a binary classifier. The approach leverages “instance-level explanations”, measures of local feature relevance that explain single instances, and uses them to build a set of visual representations that guide the users in their investigation. The workflow is based on three main visual representations and steps: one based on aggregate statistics to see how data distributes across correct / incorrect decisions; one based on explanations to understand which features are used to make these decisions; and one based on raw data, to derive insights on potential root causes for the observed patterns. The workflow is derived from a long-term collaboration with a group of machine learning and healthcare professionals who used our method to make sense of machine learning models they developed. The case study from this collaboration demonstrates that the proposed workflow helps experts derive useful knowledge about the model and the phenomena it describes, thus experts can generate useful hypotheses on how a model can be improved.},
	booktitle = {2017 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	author = {Krause, Josua and Dasgupta, Aritra and Swartz, Jordan and Aphinyanaphongs, Yindalon and Bertini, Enrico},
	month = oct,
	year = {2017},
	keywords = {Analytical models, Collaboration, Data models, Interpretation, Machine Learning, Machine learning, Predictive models, Visual Analytics, Visual analytics, explanation, vis},
	pages = {162--172},
}

@article{SeeingToolkitHowToolkitsEnvision,
	title = {Seeing {Like} a {Toolkit}: {How} {Toolkits} {Envision} the {Work} of {AI} {Ethics}},
	language = {en},
	author = {Wong, Richmond Y and Madaio, Michael A and Merrill, Nick},
	pages = {21},
}

@article{DeepLearningCaseBasedReasoningPrototypes,
	title = {Deep {Learning} for {Case}-{Based} {Reasoning} through {Prototypes}: {A} {Neural} {Network} that {Explains} {Its} {Predictions}},
	shorttitle = {Deep {Learning} for {Case}-{Based} {Reasoning} through {Prototypes}},
	url = {http://arxiv.org/abs/1710.04806},
	abstract = {Deep neural networks are widely used for classification. These deep models often suffer from a lack of interpretability -- they are particularly difficult to understand because of their non-linear nature. As a result, neural networks are often treated as "black box" models, and in the past, have been trained purely to optimize the accuracy of predictions. In this work, we create a novel network architecture for deep learning that naturally explains its own reasoning for each prediction. This architecture contains an autoencoder and a special prototype layer, where each unit of that layer stores a weight vector that resembles an encoded training input. The encoder of the autoencoder allows us to do comparisons within the latent space, while the decoder allows us to visualize the learned prototypes. The training objective has four terms: an accuracy term, a term that encourages every prototype to be similar to at least one encoded input, a term that encourages every encoded input to be close to at least one prototype, and a term that encourages faithful reconstruction by the autoencoder. The distances computed in the prototype layer are used as part of the classification process. Since the prototypes are learned during training, the learned network naturally comes with explanations for each prediction, and the explanations are loyal to what the network actually computes.},
	urldate = {2022-02-19},
	journal = {arXiv:1710.04806 [cs, stat]},
	author = {Li, Oscar and Liu, Hao and Chen, Chaofan and Rudin, Cynthia},
	month = nov,
	year = {2017},
	note = {arXiv: 1710.04806},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, dm, xai},
}

@article{DiscoveringValidatingAIErrorsCrowdsourced,
	title = {Discovering and {Validating} {AI} {Errors} {With} {Crowdsourced} {Failure} {Reports}},
	volume = {5},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3479569},
	doi = {10.1145/3479569},
	language = {en},
	number = {CSCW2},
	urldate = {2022-02-18},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Cabrera, Ángel Alexander and Druck, Abraham J. and Hong, Jason I. and Perer, Adam},
	month = oct,
	year = {2021},
	keywords = {ESCAPE, well-written},
	pages = {1--22},
}

@article{InvestigatingHumanMachineComplementarityRecidivism,
	title = {Investigating {Human} + {Machine} {Complementarity} for {Recidivism} {Predictions}},
	url = {http://arxiv.org/abs/1808.09123},
	abstract = {When might human input help (or not) when assessing risk in fairness domains? Dressel and Farid (2018) asked Mechanical Turk workers to evaluate a subset of defendants in the ProPublica COMPAS data for risk of recidivism, and concluded that COMPAS predictions were no more accurate or fair than predictions made by humans. We delve deeper into this claim to explore differences in human and algorithmic decision making. We construct a Human Risk Score based on the predictions made by multiple Turk workers, characterize the features that determine agreement and disagreement between COMPAS and Human Scores, and construct hybrid Human+Machine models to predict recidivism. Our key ﬁnding is that on this data set, Human and COMPAS decision making differed, but not in ways that could be leveraged to signiﬁcantly improve ground-truth prediction. We present the results of our analyses and suggestions for data collection best practices to leverage complementary strengths of human and machines in the fairness domain.},
	language = {en},
	urldate = {2022-02-18},
	journal = {arXiv:1808.09123 [cs, stat]},
	author = {Tan, Sarah and Adebayo, Julius and Inkpen, Kori and Kamar, Ece},
	month = dec,
	year = {2018},
	note = {arXiv: 1808.09123},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{UnknownExamplesMachineLearningModel,
	title = {Unknown {Examples} \& {Machine} {Learning} {Model} {Generalization}},
	url = {http://arxiv.org/abs/1808.08294},
	abstract = {Most machine learning (ML) technology assumes that the data for training an ML model has the same distribution as the test data to which the model will be applied. However, due to sample selection bias or, more generally, covariate shift, there exist potential training examples that are unknown to the modeler—“unknown unknowns”. The resulting discrepancy between training and testing distributions leads to poor generalization performance of the ML model and hence biased predictions. Existing techniques use test data to detect and ameliorate such discrepancies, but in many real-world situations such test data is unavailable at training time. We exploit the fact that training data often comes from multiple overlapping sources, and combine species-estimation techniques with datadriven methods for estimating the feature values for the unknown unknowns. This information can then be used to correct the training set, prior to seeing any test data. Experiments on a variety of ML models and datasets indicate that our novel techniques can improve generalization performance and increase ML model robustness.},
	language = {en},
	urldate = {2022-02-18},
	journal = {arXiv:1808.08294 [cs, stat]},
	author = {Chung, Yeounoh and Haas, Peter J. and Upfal, Eli and Kraska, Tim},
	month = oct,
	year = {2019},
	note = {arXiv: 1808.08294},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, dm, uu},
}

@article{DeconfoundedRecommendationAlleviatingBiasAmplification,
	title = {Deconfounded {Recommendation} for {Alleviating} {Bias} {Amplification}},
	url = {http://arxiv.org/abs/2105.10648},
	doi = {10.1145/3447548.3467249},
	abstract = {Recommender systems usually amplify the biases in the data. The model learned from historical interactions with imbalanced item distribution will amplify the imbalance by over-recommending items from the major groups. Addressing this issue is essential for a healthy ecosystem of recommendation in the long run. Existing works apply bias control to the ranking targets (e.g., calibration, fairness, and diversity), but ignore the true reason for bias amplification and trade-off the recommendation accuracy. In this work, we scrutinize the cause-effect factors for bias amplification, identifying the main reason lies in the confounder effect of imbalanced item distribution on user representation and prediction score. The existence of such confounder pushes us to go beyond merely modeling the conditional probability and embrace the causal modeling for recommendation. Towards this end, we propose a Deconfounded Recommender System (DecRS), which models the causal effect of user representation on the prediction score. The key to eliminating the impact of the confounder lies in backdoor adjustment, which is however difficult to do due to the infinite sample space of the confounder. For this challenge, we contribute an approximation operator for backdoor adjustment which can be easily plugged into most recommender models. Lastly, we devise an inference strategy to dynamically regulate backdoor adjustment according to user status. We instantiate DecRS on two representative models FM and NFM, and conduct extensive experiments over two benchmarks to validate the superiority of our proposed DecRS.},
	urldate = {2022-04-06},
	journal = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
	author = {Wang, Wenjie and Feng, Fuli and He, Xiangnan and Wang, Xiang and Chua, Tat-Seng},
	month = aug,
	year = {2021},
	note = {arXiv: 2105.10648},
	keywords = {Computer Science - Information Retrieval, fair, rec},
	pages = {1717--1725},
}

@article{surveyvisualanalyticstechniquesmachine,
	title = {A survey of visual analytics techniques for machine learning},
	volume = {7},
	issn = {2096-0433, 2096-0662},
	url = {http://link.springer.com/10.1007/s41095-020-0191-7},
	doi = {10.1007/s41095-020-0191-7},
	abstract = {Visual analytics for machine learning has recently evolved as one of the most exciting areas in the ﬁeld of visualization. To better identify which research topics are promising and to learn how to apply relevant techniques in visual analytics, we systematically review 259 papers published in the last ten years together with representative works before 2010. We build a taxonomy, which includes three ﬁrst-level categories: techniques before model building, techniques during modeling building, and techniques after model building. Each category is further characterized by representative analysis tasks, and each task is exempliﬁed by a set of recent inﬂuential works. We also discuss and highlight research challenges and promising potential future research opportunities useful for visual analytics researchers.},
	language = {en},
	number = {1},
	urldate = {2022-03-31},
	journal = {Computational Visual Media},
	author = {Yuan, Jun and Chen, Changjian and Yang, Weikai and Liu, Mengchen and Xia, Jiazhi and Liu, Shixia},
	month = mar,
	year = {2021},
	pages = {3--36},
}

@article{InterpretableConvolutionalNeuralNetworks,
	title = {Interpretable {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1710.00935},
	abstract = {This paper proposes a method to modify traditional convolutional neural networks (CNNs) into interpretable CNNs, in order to clarify knowledge representations in high conv-layers of CNNs. In an interpretable CNN, each filter in a high conv-layer represents a certain object part. We do not need any annotations of object parts or textures to supervise the learning process. Instead, the interpretable CNN automatically assigns each filter in a high conv-layer with an object part during the learning process. Our method can be applied to different types of CNNs with different structures. The clear knowledge representation in an interpretable CNN can help people understand the logics inside a CNN, i.e., based on which patterns the CNN makes the decision. Experiments showed that filters in an interpretable CNN were more semantically meaningful than those in traditional CNNs.},
	urldate = {2022-03-29},
	journal = {arXiv:1710.00935 [cs]},
	author = {Zhang, Quanshi and Wu, Ying Nian and Zhu, Song-Chun},
	month = feb,
	year = {2018},
	note = {arXiv: 1710.00935},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, cnn, interpretable},
}

@article{Behaviouralevidencetransparencyefficiencytradeoff,
	title = {Behavioural evidence for a transparency–efficiency tradeoff in human–machine cooperation},
	volume = {1},
	issn = {2522-5839},
	url = {http://www.nature.com/articles/s42256-019-0113-5},
	doi = {10.1038/s42256-019-0113-5},
	language = {en},
	number = {11},
	urldate = {2022-02-27},
	journal = {Nature Machine Intelligence},
	author = {Ishowo-Oloko, Fatimah and Bonnefon, Jean-François and Soroye, Zakariyah and Crandall, Jacob and Rahwan, Iyad and Rahwan, Talal},
	month = nov,
	year = {2019},
	keywords = {explanation, well-written},
	pages = {517--521},
}

@article{SquaresSupportingInteractivePerformanceAnalysisa,
	title = {Squares: {Supporting} {Interactive} {Performance} {Analysis} for {Multiclass} {Classifiers}},
	volume = {23},
	issn = {1941-0506},
	shorttitle = {Squares},
	doi = {10.1109/TVCG.2016.2598828},
	abstract = {Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ren, Donghao and Amershi, Saleema and Lee, Bongshin and Suh, Jina and Williams, Jason D.},
	month = jan,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Analytical models, Data models, Data visualization, Debugging, Measurement, Performance analysis, Visualization, classification, ml, usable machine learning, vis},
	pages = {61--70},
}

@misc{SquaresSupportinginteractiveperformanceanalysis,
	title = {Squares: {Supporting} interactive performance analysis for multiclass classifiers - {Google} 검색},
	url = {https://www.google.com/search?q=Squares%3A+Supporting+interactive+performance+analysis+for+multiclass+classifiers&oq=Squares%3A+Supporting+interactive+performance+analysis+for+multiclass+classifiers&aqs=chrome..69i57j69i58.273j0j1&sourceid=chrome&ie=UTF-8},
	urldate = {2022-02-25},
}

@inproceedings{Visualexplorationmachinelearningresults,
	address = {San Francisco, California},
	title = {Visual exploration of machine learning results using data cube analysis},
	isbn = {978-1-4503-4207-0},
	url = {http://dl.acm.org/citation.cfm?doid=2939502.2939503},
	doi = {10.1145/2939502.2939503},
	abstract = {As complex machine learning systems become more widely adopted, it becomes increasingly challenging for users to understand models or interpret the results generated from the models. We present our ongoing work on developing interactive and visual approaches for exploring and understanding machine learning results using data cube analysis. We propose MLCube, a data cube inspired framework that enables users to deﬁne instance subsets using feature conditions and computes aggregate statistics and evaluation metrics over the subsets. We also design MLCube Explorer, an interactive visualization tool for comparing models’ performances over the subsets. Users can interactively specify operations, such as drilling down to speciﬁc instance subsets, to perform more in-depth exploration. Through a usage scenario, we demonstrate how MLCube Explorer works with a public advertisement click log data set, to help a user build new advertisement click prediction models that advance over an existing model.},
	language = {en},
	urldate = {2022-02-22},
	booktitle = {Proceedings of the {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics} - {HILDA} '16},
	publisher = {ACM Press},
	author = {Kahng, Minsuk and Fang, Dezhi and Chau, Duen Horng (Polo)},
	year = {2016},
	keywords = {ESCAPE, debugging, vis},
	pages = {1--6},
}

@article{DesigningAlternativeRepresentationsConfusionMatricesa,
	title = {Designing {Alternative} {Representations} of {Confusion} {Matrices} to {Support} {Non}-{Expert} {Public} {Understanding} of {Algorithm} {Performance}},
	volume = {4},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3415224},
	doi = {10.1145/3415224},
	language = {en},
	number = {CSCW2},
	urldate = {2022-02-22},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Shen, Hong and Jin, Haojian and Cabrera, Ángel Alexander and Perer, Adam and Zhu, Haiyi and Hong, Jason I.},
	month = oct,
	year = {2020},
	keywords = {confusion, vis},
	pages = {1--22},
}

@article{ConfusionFlowModelAgnosticVisualizationTemporalAnalysis,
	title = {{ConfusionFlow}: {A} {Model}-{Agnostic} {Visualization} for {Temporal} {Analysis} of {Classifier} {Confusion}},
	volume = {28},
	issn = {1941-0506},
	shorttitle = {{ConfusionFlow}},
	doi = {10.1109/TVCG.2020.3012063},
	abstract = {Classifiers are among the most widely used supervised machine learning algorithms. Many classification models exist, and choosing the right one for a given task is difficult. During model selection and debugging, data scientists need to assess classifiers' performances, evaluate their learning behavior over time, and compare different models. Typically, this analysis is based on single-number performance measures such as accuracy. A more detailed evaluation of classifiers is possible by inspecting class errors. The confusion matrix is an established way for visualizing these class errors, but it was not designed with temporal or comparative analysis in mind. More generally, established performance analysis systems do not allow a combined temporal and comparative analysis of class-level information. To address this issue, we propose ConfusionFlow, an interactive, comparative visualization tool that combines the benefits of class confusion matrices with the visualization of performance characteristics over time. ConfusionFlow is model-agnostic and can be used to compare performances for different model types, model architectures, and/or training and test datasets. We demonstrate the usefulness of ConfusionFlow in a case study on instance selection strategies in active learning. We further assess the scalability of ConfusionFlow and present a use case in the context of neural network pruning.},
	number = {2},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Hinterreiter, Andreas and Ruch, Peter and Stitz, Holger and Ennemoser, Martin and Bernard, Jürgen and Strobelt, Hendrik and Streit, Marc},
	month = feb,
	year = {2022},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Adaptation models, Analytical models, Classification, Data models, Data visualization, Task analysis, Tools, Training, information visualization, machine learning, ml, performance analysis, quality assessment, time series visualization, vis},
	pages = {1222--1236},
}

@inproceedings{AILAAttentiveInteractiveLabelingAssistant,
	address = {Glasgow Scotland Uk},
	title = {{AILA}: {Attentive} {Interactive} {Labeling} {Assistant} for {Document} {Classification} through {Attention}-{Based} {Deep} {Neural} {Networks}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {{AILA}},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300460},
	doi = {10.1145/3290605.3300460},
	language = {en},
	urldate = {2022-06-24},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Choi, Minsuk and Park, Cheonbok and Yang, Soyoung and Kim, Yonggyu and Choo, Jaegul and Hong, Sungsoo Ray},
	month = may,
	year = {2019},
	pages = {1--12},
}

@article{ConceptsplattersExplorationlatentspaces,
	title = {Concept splatters: {Exploration} of latent spaces based on human interpretable concepts},
	issn = {00978493},
	shorttitle = {Concept splatters},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0097849322000656},
	doi = {10.1016/j.cag.2022.04.013},
	abstract = {Similarity maps show dimensionality-reduced activation vectors of a high number of data points and thereby can help to understand which features a neural network has learned from the data. However, similarity maps have severely limited expressiveness for large datasets with hundreds of thousands of data instances and thousands of labels, such as ImageNet or word2vec. In this work, we present “concept splatters” as a scalable method to interactively explore similarities between data instances as learned by the machine through the lens of human-understandable semantics. Our approach enables interactive exploration of large latent spaces on multiple levels of abstraction. We present a web-based implementation that supports interactive exploration of tens of thousands of word vectors of word2vec and CNN feature vectors of ImageNet. In a qualitative study, users could effectively discover spurious learning strategies of the network, ambiguous labels, and could characterize reasons for potential confusion.},
	language = {en},
	urldate = {2022-05-05},
	journal = {Computers \& Graphics},
	author = {Grossmann, Nicolas and Gröller, Eduard and Waldner, Manuela},
	month = apr,
	year = {2022},
	keywords = {concept, vis, xai},
	pages = {S0097849322000656},
}

@article{Talk2DataHighLevelQuestionDecompositionDataOriented,
	title = {{Talk2Data}: {High}-{Level} {Question} {Decomposition} for {Data}-{Oriented} {Question} and {Answering}},
	shorttitle = {{Talk2Data}},
	url = {http://arxiv.org/abs/2107.14420},
	abstract = {Through a data-oriented question and answering system, users can directly "ask" the system for the answers to their analytical questions about the input tabular data. This process greatly improves user experience and lowers the technical barriers of data analysis. Existing techniques focus on providing a concrete query for users or untangling the ambiguities in a specific question so that the system could better understand questions and provide more correct and precise answers. However, when users have little knowledge about the data, it is difficult for them to ask concrete questions. Instead, high-level questions are frequently asked, which cannot be easily solved with the existing techniques. To address the issue, in this paper, we introduce Talk2Data, a data-oriented online question and answering system that supports answering both low-level and high-level questions. It leverages a novel deep-learning model to resolve high-level questions into a series of low-level questions that can be answered by data facts. These low-level questions could be used to gradually elaborate the users' requirements. We design a set of annotated and captioned visualizations to represent the answers in a form that supports interpretation and narration. We evaluate the effectiveness of the Talk2Data system via a series of evaluations including case studies, performance validation, and a controlled user study. The results show the power of the system.},
	urldate = {2022-04-22},
	journal = {arXiv:2107.14420 [cs]},
	author = {Shi, Danqing and Guo, Yi and Guo, Mingjuan and Wu, Yanqiu and Chen, Qing and Cao, Nan},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.14420},
	keywords = {Computer Science - Human-Computer Interaction, nlp, vis},
}

@incollection{UnsupervisedLearningSaliencyConceptsNatural,
	address = {Berlin, Heidelberg},
	title = {Unsupervised {Learning} of {Saliency} {Concepts} for {Natural} {Image} {Classification} and {Retrieval}},
	volume = {5197},
	isbn = {978-3-540-85919-2 978-3-540-85920-8},
	url = {http://link.springer.com/10.1007/978-3-540-85920-8_21},
	abstract = {In this paper, a novel multi-scale, statistical approach for natural image representation is presented. The approach selects, at different scales, sets of features that represent exclusively the most typical visual elements of several natural scene categories, disregarding other non-characteristic, clutter, elements. Such features provide also a robust image visual signature, useful for scene understanding, image classiﬁcation and retrieval. The approach lies upon a structured generative model eﬃciently trained through variational learning. Results regarding image classiﬁcation and retrieval prove the goodness of the approach.},
	language = {en},
	urldate = {2022-04-12},
	booktitle = {Progress in {Pattern} {Recognition}, {Image} {Analysis} and {Applications}},
	publisher = {Springer Berlin Heidelberg},
	author = {Perina, A. and Cristani, M. and Murino, V.},
	editor = {Ruiz-Shulcloper, José and Kropatsch, Walter G.},
	year = {2008},
	doi = {10.1007/978-3-540-85920-8_21},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {concept, dm, image},
	pages = {169--177},
}

@inproceedings{CoOccurrenceNeuralNetwork,
	address = {Long Beach, CA, USA},
	title = {Co-{Occurrence} {Neural} {Network}},
	isbn = {978-1-72813-293-8},
	url = {https://ieeexplore.ieee.org/document/8953405/},
	doi = {10.1109/CVPR.2019.00493},
	abstract = {Convolutional Neural Networks (CNNs) became a very popular tool for image analysis. Convolutions are fast to compute and easy to store, but they also have some limitations. First, they are shift-invariant and, as a result, they do not adapt to different regions of the image. Second, they have a ﬁxed spatial layout, so small geometric deformations in the layout of a patch will completely change the ﬁlter response. For these reasons, we need multiple ﬁlters to handle the different parts and variations in the input.},
	language = {en},
	urldate = {2022-04-10},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Shevlev, Irina and Avidan, Shai},
	month = jun,
	year = {2019},
	pages = {4792--4799},
}

@article{ConceptWhiteningInterpretableImageRecognition,
	title = {Concept {Whitening} for {Interpretable} {Image} {Recognition}},
	volume = {2},
	issn = {2522-5839},
	url = {http://arxiv.org/abs/2002.01650},
	doi = {10.1038/s42256-020-00265-z},
	abstract = {What does a neural network encode about a concept as we traverse through the layers? Interpretability in machine learning is undoubtedly important, but the calculations of neural networks are very challenging to understand. Attempts to see inside their hidden layers can either be misleading, unusable, or rely on the latent space to possess properties that it may not have. In this work, rather than attempting to analyze a neural network posthoc, we introduce a mechanism, called concept whitening (CW), to alter a given layer of the network to allow us to better understand the computation leading up to that layer. When a concept whitening module is added to a CNN, the axes of the latent space are aligned with known concepts of interest. By experiment, we show that CW can provide us a much clearer understanding for how the network gradually learns concepts over layers. CW is an alternative to a batch normalization layer in that it normalizes, and also decorrelates (whitens) the latent space. CW can be used in any layer of the network without hurting predictive performance.},
	number = {12},
	urldate = {2022-04-07},
	journal = {Nature Machine Intelligence},
	author = {Chen, Zhi and Bei, Yijie and Rudin, Cynthia},
	month = dec,
	year = {2020},
	note = {arXiv: 2002.01650},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, dl, xai},
	pages = {772--782},
}

@book{DASHVisualAnalyticsDebiasingImage,
	title = {{DASH}: {Visual} {Analytics} for {Debiasing} {Image} {Classification} via {User}-{Driven} {Synthetic} {Data} {Augmentation}},
	shorttitle = {{DASH}},
	abstract = {Figure 1: An overview of DASH: (A) Projection View shows the latent space representation of images using t-SNE; (B) Mosaic View summarizes the performance differences between two previously trained classifiers; (C) Trace View shows how the two classifiers predict individual images differently (red: incorrect to correct, blue: correct to incorrect); (D) Grad-CAM View shows the feature importance of images as heatmaps; (E) Image View shows a list of selected images; (F) Cluster GAN View shows clustering results which can be used to translate visual features of images to other images using XploreGAN; (G) Augmented Image View shows newly created images for retraining and (H) shows the summary of the new images; (I) Classifier Board shows the performance of different classifiers. Abstract Image classification models often learn to predict a class based on irrelevant co-occurrences between input features and an output class in training data. We call the unwanted correlations "data biases," and the visual features causing data biases "bias factors." It is challenging to identify and mitigate biases automatically without human intervention. Therefore, we conducted a design study to find a human-in-the-loop solution. First, we identified user tasks that capture the bias mitigation process for image classification models with three experts. Then, to support the tasks, we developed a visual analytics system called DASH that allows users to visually identify bias factors, to iteratively generate synthetic images using a state-of-the-art image-to-image translation model, and to supervise the model training process for improving the classification accuracy. Our quantitative evaluation and qualitative study with ten participants demonstrate the usefulness of DASH and provide lessons for future work.},
	author = {Kwon, Bum Chul and Lee, Jungsoo and Chung, Chaeyeon and Lee, Nyoungwoo and Choi, Ho-Jin and Choo, Jaegul},
	month = jul,
	year = {2022},
	doi = {10.2312/evs.20221099},
	keywords = {ESCAPE, fair, uu, vis},
}

@article{UnderstandingLocalNewsSocialCoverage,
	title = {Understanding {Local} {News} {Social} {Coverage} and {Engagement} at {Scale} during the {COVID}-19 {Pandemic}},
	volume = {16},
	copyright = {Copyright (c) 2022 Association for the Advancement of Artificial Intelligence},
	issn = {2334-0770},
	url = {https://ojs.aaai.org/index.php/ICWSM/article/view/19315},
	abstract = {During the COVID-19 pandemic, local news organizations have played an important role in keeping communities informed about the spread and impact of the virus. We explore how political, social media, and economic factors impacted the way local media reported on COVID-19 developments at a national scale between January 2020 and July 2021. We construct and make available a dataset of over 10,000 local news organizations and their social media handles across the U.S. We use social media data to estimate the population reach of outlets (their “localness”), and capture underlying content relationships between them. Building on this data, we analyze how local and national media covered four key COVID-19 news topics: Statistics and Case Counts, Vaccines and Testing, Public Health Guidelines, and Economic Effects. Our results show that news outlets with higher population reach reported proportionally more on COVID-19 than more local outlets. Separating the analysis by topic, we expose more nuanced trends, for example that outlets with a smaller population reach covered the Statistics and Case Counts topic proportionally more, and the Economic Effects topic proportionally less. Our analysis further shows that people engaged proportionally more and used stronger reactions when COVID-19 news were posted by outlets with a smaller population reach. Finally, we demonstrate that COVID-19 posts in Republican-leaning counties generally received more comments and fewer likes than in Democratic counties, perhaps indicating controversy.},
	language = {en},
	urldate = {2022-07-26},
	journal = {Proceedings of the International AAAI Conference on Web and Social Media},
	author = {Quéré, Marianne Aubin Le and Chiang, Ting-Wei and Naaman, Mor},
	month = may,
	year = {2022},
	keywords = {Social network analysis, communities identification, dm, expertise and authority discovery, social-media, well-written},
	pages = {560--572},
}

@book{PredictingFoodCrises,
	title = {Predicting {Food} {Crises}},
	url = {http://hdl.handle.net/10986/34510},
	language = {en},
	urldate = {2022-07-09},
	publisher = {World Bank, Washington, DC},
	author = {Andree, Bo Pieter Johannes and Chamorro, Andres and Kraay, Aart and Spencer, Phoebe and Wang, Dieter},
	month = sep,
	year = {2020},
	doi = {10.1596/1813-9450-9412},
}

@misc{Humancenteredexplainabilitylifescienceshealthcare,
	title = {Human-centered explainability for life sciences, healthcare, and medical informatics {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S2666389922000782?token=8437BBF1170D2771225883D3178CE8C717529054859C2767F7C5107078D05981967B7EC8A51D19B451CDF223CCBB43FA&originRegion=us-east-1&originCreation=20220708200144},
	language = {en},
	urldate = {2022-07-08},
	doi = {10.1016/j.patter.2022.100493},
}

@inproceedings{AttentionExplanationIntroductionDebate,
	address = {Dublin, Ireland},
	title = {Is {Attention} {Explanation}? {An} {Introduction} to the {Debate}},
	shorttitle = {Is {Attention} {Explanation}?},
	url = {https://aclanthology.org/2022.acl-long.269},
	doi = {10.18653/v1/2022.acl-long.269},
	abstract = {The performance of deep learning models in NLP and other fields of machine learning has led to a rise in their popularity, and so the need for explanations of these models becomes paramount. Attention has been seen as a solution to increase performance, while providing some explanations. However, a debate has started to cast doubt on the explanatory power of attention in neural networks. Although the debate has created a vast literature thanks to contributions from various areas, the lack of communication is becoming more and more tangible. In this paper, we provide a clear overview of the insights on the debate by critically confronting works from these different areas. This holistic vision can be of great interest for future works in all the communities concerned by this debate. We sum up the main challenges spotted in these areas, and we conclude by discussing the most promising future avenues on attention as an explanation.},
	urldate = {2022-06-30},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Bibal, Adrien and Cardon, Rémi and Alfter, David and Wilkens, Rodrigo and Wang, Xiaoou and François, Thomas and Watrin, Patrick},
	month = may,
	year = {2022},
	keywords = {explainable, fatml, nlp},
	pages = {3889--3900},
}

@article{SquaresSupportingInteractivePerformanceAnalysis,
	title = {Squares: {Supporting} {Interactive} {Performance} {Analysis} for {Multiclass} {Classifiers}},
	volume = {23},
	issn = {1941-0506},
	shorttitle = {Squares},
	doi = {10.1109/TVCG.2016.2598828},
	abstract = {Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ren, Donghao and Amershi, Saleema and Lee, Bongshin and Suh, Jina and Williams, Jason D.},
	month = jan,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Analytical models, Data models, Data visualization, Debugging, ESCAPE, Measurement, Performance analysis, Visualization, classification, usable machine learning, vis},
	pages = {61--70},
}

@article{TribeNotCriticalInspectionGroup,
	title = {Tribe or {Not}? {Critical} {Inspection} of {Group} {Differences} {Using} {TribalGram}},
	volume = {12},
	issn = {2160-6455, 2160-6463},
	shorttitle = {Tribe or {Not}?},
	url = {https://dl.acm.org/doi/10.1145/3484509},
	doi = {10.1145/3484509},
	abstract = {With the rise of AI and data mining techniques, group profiling and group-level analysis have been increasingly used in many domains, including policy making and direct marketing. In some cases, the statistics extracted from data may provide insights to a group’s shared characteristics; in others, the group-level analysis can lead to problems, including stereotyping and systematic oppression. How can analytic tools facilitate a more conscientious process in group analysis? In this work, we identify a set of
              accountable group analytics
              design guidelines to explicate the needs for group differentiation and preventing overgeneralization of a group. Following the design guidelines, we develop
              
                TribalGram
              
              , a visual analytic suite that leverages interpretable machine learning algorithms and visualization to offer inference assessment, model explanation, data corroboration, and sense-making. Through the interviews with domain experts, we showcase how our design and tools can bring a richer understanding of “groups” mined from the data.},
	language = {en},
	number = {1},
	urldate = {2022-09-08},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Ahn, Yongsu and Yan, Muheng and Lin, Yu-Ru and Chung, Wen-Ting and Hwa, Rebecca},
	month = mar,
	year = {2022},
	keywords = {accountability, fatml, hci, vis},
	pages = {1--34},
}

@article{TribeNotCriticalInspectionGroupa,
	title = {Tribe or {Not}? {Critical} {Inspection} of {Group} {Differences} {Using} {TribalGram}},
	volume = {12},
	issn = {2160-6455, 2160-6463},
	shorttitle = {Tribe or {Not}?},
	url = {https://dl.acm.org/doi/10.1145/3484509},
	doi = {10.1145/3484509},
	abstract = {With the rise of AI and data mining techniques, group profiling and group-level analysis have been increasingly used in many domains, including policy making and direct marketing. In some cases, the statistics extracted from data may provide insights to a group’s shared characteristics; in others, the group-level analysis can lead to problems, including stereotyping and systematic oppression. How can analytic tools facilitate a more conscientious process in group analysis? In this work, we identify a set of
              accountable group analytics
              design guidelines to explicate the needs for group differentiation and preventing overgeneralization of a group. Following the design guidelines, we develop
              
                TribalGram
              
              , a visual analytic suite that leverages interpretable machine learning algorithms and visualization to offer inference assessment, model explanation, data corroboration, and sense-making. Through the interviews with domain experts, we showcase how our design and tools can bring a richer understanding of “groups” mined from the data.},
	language = {en},
	number = {1},
	urldate = {2022-09-08},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Ahn, Yongsu and Yan, Muheng and Lin, Yu-Ru and Chung, Wen-Ting and Hwa, Rebecca},
	month = mar,
	year = {2022},
	keywords = {accountability, fatml, vis},
	pages = {1--34},
}

@article{WeBuildAIParticipatoryFrameworkAlgorithmicGovernance,
	title = {{WeBuildAI}: {Participatory} {Framework} for {Algorithmic} {Governance}},
	volume = {3},
	issn = {2573-0142},
	shorttitle = {{WeBuildAI}},
	url = {https://dl.acm.org/doi/10.1145/3359283},
	doi = {10.1145/3359283},
	abstract = {Algorithms increasingly govern societal functions, impacting multiple stakeholders and social groups. How can we design these algorithms to balance varying interests in a moral, legitimate way? As one answer to this question, we present WeBuildAI, a collective participatory framework that enables people to build algorithmic policy for their communities. The key idea of the framework is to enable stakeholders to construct a computational model that represents their views and to have those models vote on their behalf to create algorithmic policy. As a case study, we applied this framework to a matching algorithm that operates an on-demand food donation transportation service in order to adjudicate equity and efficiency trade-offs. The service's stakeholders--donors, volunteers, recipient organizations, and nonprofit employees--used the framework to design the algorithm through a series of studies in which we researched their experiences. Our findings suggest that the framework successfully enabled participants to build models that they felt confident represented their own beliefs. Participatory algorithm design also improved both procedural fairness and the distributive outcomes of the algorithm, raised participants' algorithmic awareness, and helped identify inconsistencies in human decision-making in the governing organization. Our work demonstrates the feasibility, potential and challenges of community involvement in algorithm design.},
	language = {en},
	number = {CSCW},
	urldate = {2022-08-16},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lee, Min Kyung and Kusbit, Daniel and Kahng, Anson and Kim, Ji Tae and Yuan, Xinran and Chan, Allissa and See, Daniel and Noothigattu, Ritesh and Lee, Siheon and Psomas, Alexandros and Procaccia, Ariel D.},
	month = nov,
	year = {2019},
	keywords = {fatml, hci, participatory},
	pages = {1--35},
}

@inproceedings{ImportanceModelingSocialFactorsLanguage,
	address = {Online},
	title = {The {Importance} of {Modeling} {Social} {Factors} of {Language}: {Theory} and {Practice}},
	shorttitle = {The {Importance} of {Modeling} {Social} {Factors} of {Language}},
	url = {https://aclanthology.org/2021.naacl-main.49},
	doi = {10.18653/v1/2021.naacl-main.49},
	abstract = {Natural language processing (NLP) applications are now more powerful and ubiquitous than ever before. With rapidly developing (neural) models and ever-more available data, current NLP models have access to more information than any human speaker during their life. Still, it would be hard to argue that NLP models have reached human-level capacity. In this position paper, we argue that the reason for the current limitations is a focus on information content while ignoring language’s social factors. We show that current NLP systems systematically break down when faced with interpreting the social factors of language. This limits applications to a subset of information-related tasks and prevents NLP from reaching human-level performance. At the same time, systems that incorporate even a minimum of social factors already show remarkable improvements. We formalize a taxonomy of seven social factors based on linguistic theory and exemplify current failures and emerging successes for each of them. We suggest that the NLP community address social factors to get closer to the goal of humanlike language understanding.},
	language = {en},
	urldate = {2022-08-10},
	booktitle = {Proceedings of the 2021 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Hovy, Dirk and Yang, Diyi},
	year = {2021},
	pages = {588--602},
}

@article{RECASTEnablingUserRecourseInterpretability,
	title = {{RECAST}: {Enabling} {User} {Recourse} and {Interpretability} of {Toxicity} {Detection} {Models} with {Interactive} {Visualization}},
	volume = {5},
	issn = {2573-0142},
	shorttitle = {{RECAST}},
	url = {http://arxiv.org/abs/2102.04427},
	doi = {10.1145/3449280},
	abstract = {With the widespread use of toxic language online, platforms are increasingly using automated systems that leverage advances in natural language processing to automatically flag and remove toxic comments. However, most automated systems -- when detecting and moderating toxic language -- do not provide feedback to their users, let alone provide an avenue of recourse for these users to make actionable changes. We present our work, RECAST, an interactive, open-sourced web tool for visualizing these models' toxic predictions, while providing alternative suggestions for flagged toxic language. Our work also provides users with a new path of recourse when using these automated moderation tools. RECAST highlights text responsible for classifying toxicity, and allows users to interactively substitute potentially toxic phrases with neutral alternatives. We examined the effect of RECAST via two large-scale user evaluations, and found that RECAST was highly effective at helping users reduce toxicity as detected through the model. Users also gained a stronger understanding of the underlying toxicity criterion used by black-box models, enabling transparency and recourse. In addition, we found that when users focus on optimizing language for these models instead of their own judgement (which is the implied incentive and goal of deploying automated models), these models cease to be effective classifiers of toxicity compared to human annotations. This opens a discussion for how toxicity detection models work and should work, and their effect on the future of online discourse.},
	number = {CSCW1},
	urldate = {2022-08-10},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Wright, Austin P. and Shaikh, Omar and Park, Haekyu and Epperson, Will and Ahmed, Muhammed and Pinel, Stephane and Chau, Duen Horng and Yang, Diyi},
	month = apr,
	year = {2021},
	note = {arXiv:2102.04427 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Computer Science - Social and Information Networks, hci, nlp, toxic, vis},
	pages = {1--26},
}

@article{SlippingExtremeMixedMethodExplain,
	title = {Slipping to the {Extreme}: {A} {Mixed} {Method} to {Explain} {How} {Extreme} {Opinions} {Infiltrate} {Online} {Discussions}},
	abstract = {Qualitative research provides methodological guidelines for observing and studying communities and cultures on online social media platforms. However, such methods demand considerable manual effort from researchers and can be overly focused and narrowed to certain online groups. This work proposes a complete solution to accelerate the qualitative analysis of problematic online speech, focusing on opinions emerging from online communities by leveraging machine learning algorithms. First, we employ qualitative methods of deep observation for understanding problematic online speech. This initial qualitative study constructs an ontology of problematic speech, which contains social media postings annotated with their underlying opinions. The qualitative study dynamically constructs the set of opinions, simultaneous with labeling the postings. Next, we use keywords to collect a large dataset from three online social media platforms (Facebook, Twitter, and Youtube). Finally, we introduce an iterative data exploration procedure to augment the dataset. It alternates between a data sampler — which balances exploration and exploitation of unlabeled data — the automatic labeling of the sampled data, the manual inspection by the qualitative mapping team, and, ﬁnally, the retraining of the automatic opinion classiﬁers. We present both qualitative and quantitative results. First, we show that our human-in-the-loop method successfully augments the initial qualitatively labeled and narrowly focused dataset and constructs a more encompassing dataset. Next, we present detailed case studies of the dynamics of problematic speech in a far-right Facebook group, exemplifying its mutation from conservative to extreme. Finally, we examine the dynamics of opinion emergence and co-occurrence, and we hint at some pathways through which extreme opinions creep into the mainstream online discourse.},
	language = {en},
	author = {Kong, Quyu and Booth, Emily and Bailo, Francesco and Johns, Amelia and Rizoiu, Marian-Andrei},
	keywords = {dm, hil},
	pages = {12},
}

@article{MappingTopics100000RealLife,
	title = {Mapping {Topics} in 100,000 {Real}-{Life} {Moral} {Dilemmas}},
	volume = {16},
	copyright = {Copyright (c) 2022 Association for the Advancement of Artificial Intelligence},
	issn = {2334-0770},
	url = {https://ojs.aaai.org/index.php/ICWSM/article/view/19327},
	abstract = {Moral dilemmas play an important role in theorizing both about ethical norms and moral psychology. Yet thought experiments borrowed from the philosophical literature often lack the nuances and complexity of real life. We leverage 100,000 threads—the largest collection to date—from Reddit’s r/AmItheAsshole to examine the features of everyday moral dilemmas. Combining topic modeling with evaluation from both expert and crowd-sourced workers, we discover 47 fine-grained, meaningful topics and group them into five meta-categories. We show that most dilemmas combine at least two topics, such as family and money. We also observe that the pattern of topic co-occurrence carries interesting information about the structure of everyday moral concerns: for example, the generation of moral dilemmas from nominally neutral topics, and interaction effects in which final verdicts do not line up with the moral concerns in the original stories in any simple way. Our analysis demonstrates the utility of a fine-grained data-driven approach to online moral dilemmas, and provides a valuable resource for researchers aiming to explore the intersection of practical and theoretical ethics.},
	language = {en},
	urldate = {2022-08-02},
	journal = {Proceedings of the International AAAI Conference on Web and Social Media},
	author = {Nguyen, Tuan Dung and Lyall, Georgiana and Tran, Alasdair and Shin, Minjeong and Carroll, Nicholas George and Klein, Colin and Xie, Lexing},
	month = may,
	year = {2022},
	keywords = {Credibility of online content},
	pages = {699--710},
}

@misc{09071815FrustratinglyEasyDomain,
	title = {[0907.1815] {Frustratingly} {Easy} {Domain} {Adaptation}},
	url = {https://arxiv.org/abs/0907.1815},
	urldate = {2022-09-20},
	keywords = {dm},
}

@article{LSTMVisToolVisualAnalysisHidden,
	title = {{LSTMVis}: {A} {Tool} for {Visual} {Analysis} of {Hidden} {State} {Dynamics} in {Recurrent} {Neural} {Networks}},
	volume = {24},
	issn = {1941-0506},
	shorttitle = {{LSTMVis}},
	doi = {10.1109/TVCG.2017.2744158},
	abstract = {Recurrent neural networks, and in particular long short-term memory (LSTM) networks, are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis, a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows users to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with structural annotations from their domain. We show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis. We characterize the domain, the different stakeholders, and their goals and tasks. Long-term usage data after putting the tool online revealed great interest in the machine learning community.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Strobelt, Hendrik and Gehrmann, Sebastian and Pfister, Hanspeter and Rush, Alexander M.},
	month = jan,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Computational modeling, Data models, LSTM, Machine Learning, Pattern matching, Recurrent Neural Networks, Recurrent neural networks, Tools, Visualization, dl, vis},
	pages = {667--676},
}

@article{Seq2seqVisVisualDebuggingToolSequencetoSequence,
	title = {Seq2seq-{Vis}: {A} {Visual} {Debugging} {Tool} for {Sequence}-to-{Sequence} {Models}},
	volume = {25},
	issn = {1941-0506},
	shorttitle = {Seq2seq-{Vis}},
	doi = {10.1109/TVCG.2018.2865044},
	abstract = {Neural sequence-to-sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work with a five-stage blackbox pipeline that begins with encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction and “what if”-style exploration of trained sequence-to-sequence models through each stage of the translation process. The aim is to identify which patterns have been learned, to detect model errors, and to probe the model with counterfactual scenario. We demonstrate the utility of our tool through several real-world sequence-to-sequence use cases on large-scale models.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Strobelt, Hendrik and Gehrmann, Sebastian and Behrisch, Michael and Perer, Adam and Pfister, Hanspeter and Rush, Alexander M.},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Analytical models, Atmosphere, Data models, Deep Learning, ESCAPE, Explainable AI, Machine Learning, Machine learning, NLP, Predictive models, Tools, Visual Analytics, Visual Debugging, Visualization, dl, vis},
	pages = {353--363},
}

@article{DesigningAlternativeRepresentationsConfusionMatrices,
	title = {Designing {Alternative} {Representations} of {Confusion} {Matrices} to {Support} {Non}-{Expert} {Public} {Understanding} of {Algorithm} {Performance}},
	volume = {4},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3415224},
	doi = {10.1145/3415224},
	language = {en},
	number = {CSCW2},
	urldate = {2022-09-10},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Shen, Hong and Jin, Haojian and Cabrera, Ángel Alexander and Perer, Adam and Zhu, Haiyi and Hong, Jason I.},
	month = oct,
	year = {2020},
	keywords = {confusion-matrix, vis},
	pages = {1--22},
}

@article{AnalyzingTrainingProcessesDeepGenerative,
	title = {Analyzing the {Training} {Processes} of {Deep} {Generative} {Models}},
	volume = {24},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2017.2744938},
	abstract = {Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Mengchen and Shi, Jiaxin and Cao, Kelei and Zhu, Jun and Liu, Shixia},
	month = jan,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Analytical models, ESCAPE, Neurons, Time series analysis, Tools, Training, Visual analytics, blue noise sampling, credit assignment, deep generative models, deep learning, dl, vis},
	pages = {77--87},
}

@inproceedings{SelfKGSelfSupervisedEntityAlignmentKnowledge,
	address = {Virtual Event, Lyon France},
	title = {{SelfKG}: {Self}-{Supervised} {Entity} {Alignment} in {Knowledge} {Graphs}},
	isbn = {978-1-4503-9096-5},
	shorttitle = {{SelfKG}},
	url = {https://dl.acm.org/doi/10.1145/3485447.3511945},
	doi = {10.1145/3485447.3511945},
	abstract = {Entity alignment, aiming to identify equivalent entities across different knowledge graphs (KGs), is a fundamental problem for constructing Web-scale KGs. Over the course of its development, the label supervision has been considered necessary for accurate alignments. Inspired by the recent progress of self-supervised learning, we explore the extent to which we can get rid of supervision for entity alignment. Commonly, the label information (positive entity pairs) is used to supervise the process of pulling the aligned entities in each positive pair closer. However, our theoretical analysis suggests that the learning of entity alignment can actually benefit more from pushing unlabeled negative pairs far away from each other than pulling labeled positive pairs close. By leveraging this discovery, we develop the self-supervised learning objective for entity alignment. We present SelfKG with efficient strategies to optimize this objective for aligning entities without label supervision. Extensive experiments on benchmark datasets demonstrate that SelfKG without supervision can match or achieve comparable results with state-of-the-art supervised baselines. The performance of SelfKG suggests that self-supervised learning offers great potential for entity alignment in KGs. The code and data are available at https://github.com/THUDM/SelfKG.},
	language = {en},
	urldate = {2022-09-29},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2022},
	publisher = {ACM},
	author = {Liu, Xiao and Hong, Haoyun and Wang, Xinghao and Chen, Zeyi and Kharlamov, Evgeny and Dong, Yuxiao and Tang, Jie},
	month = apr,
	year = {2022},
	keywords = {kg, self-supervised},
	pages = {860--870},
}

@inproceedings{AccountabilityProvidingIntelligibleExplanationsAutonomous,
	address = {Nagoya, Japan},
	title = {Towards {Accountability}: {Providing} {Intelligible} {Explanations} in {Autonomous} {Driving}},
	isbn = {978-1-72815-394-0},
	shorttitle = {Towards {Accountability}},
	url = {https://ieeexplore.ieee.org/document/9575917/},
	doi = {10.1109/IV48863.2021.9575917},
	abstract = {The safe deployment of autonomous vehicles (AVs) in real world scenarios requires that AVs are accountable. One way of ensuring accountability is through the provision of explanations for what the vehicles have ‘seen’, done and might do in a given scenario. Intelligible explanations can help developers and regulators to assess AVs’ behaviour, and in turn, uphold accountability. In this paper, we propose an interpretable (tree-based) and user-centric approach for explaining autonomous driving behaviours. In a user study, we examined different explanation types instigated by investigatory queries. We conducted an experiment to identify scenarios that require explanations and the corresponding appropriate explanation types for such scenarios. Our ﬁndings show that an explanation type matters mostly in emergency and collision driving conditions. Also, providing intelligible explanations (especially contrastive types) with causal attributions can improve accountability in autonomous driving. The proposed interpretable approach can help realise such intelligible explanations with causal attributions.},
	language = {en},
	urldate = {2022-09-29},
	booktitle = {2021 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	publisher = {IEEE},
	author = {Omeiza, Daniel and Web, Helena and Jirotka, Marina and Kunze, Lars},
	month = jul,
	year = {2021},
	keywords = {explanation, self-driving},
	pages = {231--237},
}

@inproceedings{SelfKGSelfSupervisedEntityAlignmentKnowledgea,
	address = {Virtual Event, Lyon France},
	title = {{SelfKG}: {Self}-{Supervised} {Entity} {Alignment} in {Knowledge} {Graphs}},
	isbn = {978-1-4503-9096-5},
	shorttitle = {{SelfKG}},
	url = {https://dl.acm.org/doi/10.1145/3485447.3511945},
	doi = {10.1145/3485447.3511945},
	abstract = {Entity alignment, aiming to identify equivalent entities across different knowledge graphs (KGs), is a fundamental problem for constructing Web-scale KGs. Over the course of its development, the label supervision has been considered necessary for accurate alignments. Inspired by the recent progress of self-supervised learning, we explore the extent to which we can get rid of supervision for entity alignment. Commonly, the label information (positive entity pairs) is used to supervise the process of pulling the aligned entities in each positive pair closer. However, our theoretical analysis suggests that the learning of entity alignment can actually benefit more from pushing unlabeled negative pairs far away from each other than pulling labeled positive pairs close. By leveraging this discovery, we develop the self-supervised learning objective for entity alignment. We present SelfKG with efficient strategies to optimize this objective for aligning entities without label supervision. Extensive experiments on benchmark datasets demonstrate that SelfKG without supervision can match or achieve comparable results with state-of-the-art supervised baselines. The performance of SelfKG suggests that self-supervised learning offers great potential for entity alignment in KGs. The code and data are available at https://github.com/THUDM/SelfKG.},
	language = {en},
	urldate = {2022-09-28},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2022},
	publisher = {ACM},
	author = {Liu, Xiao and Hong, Haoyun and Wang, Xinghao and Chen, Zeyi and Kharlamov, Evgeny and Dong, Yuxiao and Tang, Jie},
	month = apr,
	year = {2022},
	pages = {860--870},
}

@inproceedings{BOLDDatasetMetricsMeasuringBiasesa,
	address = {Virtual Event Canada},
	title = {{BOLD}: {Dataset} and {Metrics} for {Measuring} {Biases} in {Open}-{Ended} {Language} {Generation}},
	isbn = {978-1-4503-8309-7},
	shorttitle = {{BOLD}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445924},
	doi = {10.1145/3442188.3445924},
	abstract = {Recent advances in deep learning techniques have enabled machines to generate cohesive open-ended text when prompted with a sequence of words as context. While these models now empower many downstream applications from conversation bots to automatic storytelling, they have been shown to generate texts that exhibit social biases. To systematically study and benchmark social biases in open-ended language generation, we introduce the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that consists of 23,679 English text generation prompts for bias benchmarking across five domains: profession, gender, race, religion, and political ideology. We also propose new automated metrics for toxicity, psycholinguistic norms, and text gender polarity to measure social biases in open-ended text generation from multiple angles. An examination of text generated from three popular language models reveals that the majority of these models exhibit a larger social bias than human-written Wikipedia text across all domains. With these results we highlight the need to benchmark biases in open-ended language generation and caution users of language generation models on downstream tasks to be cognizant of these embedded prejudices.},
	language = {en},
	urldate = {2022-10-05},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
	month = mar,
	year = {2021},
	pages = {862--872},
}

@inproceedings{BOLDDatasetMetricsMeasuringBiases,
	address = {Virtual Event Canada},
	title = {{BOLD}: {Dataset} and {Metrics} for {Measuring} {Biases} in {Open}-{Ended} {Language} {Generation}},
	isbn = {978-1-4503-8309-7},
	shorttitle = {{BOLD}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445924},
	doi = {10.1145/3442188.3445924},
	abstract = {Recent advances in deep learning techniques have enabled machines to generate cohesive open-ended text when prompted with a sequence of words as context. While these models now empower many downstream applications from conversation bots to automatic storytelling, they have been shown to generate texts that exhibit social biases. To systematically study and benchmark social biases in open-ended language generation, we introduce the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that consists of 23,679 English text generation prompts for bias benchmarking across five domains: profession, gender, race, religion, and political ideology. We also propose new automated metrics for toxicity, psycholinguistic norms, and text gender polarity to measure social biases in open-ended text generation from multiple angles. An examination of text generated from three popular language models reveals that the majority of these models exhibit a larger social bias than human-written Wikipedia text across all domains. With these results we highlight the need to benchmark biases in open-ended language generation and caution users of language generation models on downstream tasks to be cognizant of these embedded prejudices.},
	language = {en},
	urldate = {2022-10-05},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
	month = mar,
	year = {2021},
	keywords = {fair, nlg, nlp},
	pages = {862--872},
}

@inproceedings{TexarModularizedVersatileExtensibleToolkit,
	address = {Florence, Italy},
	title = {Texar: {A} {Modularized}, {Versatile}, and {Extensible} {Toolkit} for {Text} {Generation}},
	shorttitle = {Texar},
	url = {https://aclanthology.org/P19-3027},
	doi = {10.18653/v1/P19-3027},
	abstract = {We introduce Texar, an open-source toolkit aiming to support the broad set of text generation tasks that transform any inputs into natural language, such as machine translation, summarization, dialog, content manipulation, and so forth. With the design goals of modularity, versatility, and extensibility in mind, Texar extracts common patterns underlying the diverse tasks and methodologies, creates a library of highly reusable modules and functionalities, and allows arbitrary model architectures and algorithmic paradigms. In Texar, model architecture, inference, and learning processes are properly decomposed. Modules at a high concept level can be freely assembled or plugged in/swapped out. Texar is thus particularly suitable for researchers and practitioners to do fast prototyping and experimentation. The versatile toolkit also fosters technique sharing across different text generation tasks. Texar supports both TensorFlow and PyTorch, and is released under Apache License 2.0 at https://www.texar.io.},
	urldate = {2022-10-04},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Hu, Zhiting and Shi, Haoran and Tan, Bowen and Wang, Wentao and Yang, Zichao and Zhao, Tiancheng and He, Junxian and Qin, Lianhui and Wang, Di and Ma, Xuezhe and Liu, Zhengzhong and Liang, Xiaodan and Zhu, Wanrong and Sachan, Devendra and Xing, Eric},
	month = jul,
	year = {2019},
	keywords = {hci, nlg, nlp},
	pages = {159--164},
}

@inproceedings{GLTRStatisticalDetectionVisualizationGenerated,
	address = {Florence, Italy},
	title = {{GLTR}: {Statistical} {Detection} and {Visualization} of {Generated} {Text}},
	shorttitle = {{GLTR}},
	url = {https://aclanthology.org/P19-3019},
	doi = {10.18653/v1/P19-3019},
	abstract = {The rapid improvement of language models has raised the specter of abuse of text generation systems. This progress motivates the development of simple methods for detecting generated text that can be used by non-experts. In this work, we introduce GLTR, a tool to support humans in detecting whether a text was generated by a model. GLTR applies a suite of baseline statistical methods that can detect generation artifacts across multiple sampling schemes. In a human-subjects study, we show that the annotation scheme provided by GLTR improves the human detection-rate of fake text from 54\% to 72\% without any prior training. GLTR is open-source and publicly deployed, and has already been widely used to detect generated outputs.},
	urldate = {2022-10-04},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Gehrmann, Sebastian and Strobelt, Hendrik and Rush, Alexander},
	month = jul,
	year = {2019},
	keywords = {hci, nlg, nlp, vis},
	pages = {111--116},
}

@inproceedings{JiugeHumanMachineCollaborativeChineseClassical,
	address = {Florence, Italy},
	title = {Jiuge: {A} {Human}-{Machine} {Collaborative} {Chinese} {Classical} {Poetry} {Generation} {System}},
	shorttitle = {Jiuge},
	url = {https://aclanthology.org/P19-3005},
	doi = {10.18653/v1/P19-3005},
	abstract = {Research on the automatic generation of poetry, the treasure of human culture, has lasted for decades. Most existing systems, however, are merely model-oriented, which input some user-specified keywords and directly complete the generation process in one pass, with little user participation. We believe that the machine, being a collaborator or an assistant, should not replace human beings in poetic creation. Therefore, we proposed Jiuge, a human-machine collaborative Chinese classical poetry generation system. Unlike previous systems, Jiuge allows users to revise the unsatisfied parts of a generated poem draft repeatedly. According to the revision, the poem will be dynamically updated and regenerated. After the revision and modification procedure, the user can write a satisfying poem together with Jiuge system collaboratively. Besides, Jiuge can accept multi-modal inputs, such as keywords, plain text or images. By exposing the options of poetry genres, styles and revision modes, Jiuge, acting as a professional assistant, allows constant and active participation of users in poetic creation.},
	urldate = {2022-10-04},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Zhipeng, Guo and Yi, Xiaoyuan and Sun, Maosong and Li, Wenhao and Yang, Cheng and Liang, Jiannan and Chen, Huimin and Zhang, Yuhui and Li, Ruoyu},
	month = jul,
	year = {2019},
	keywords = {hci, nlg, nlp},
	pages = {25--30},
}

@inproceedings{ThereNotEnoughInformationEffectsa,
	address = {Seoul Republic of Korea},
	title = {“{There} {Is} {Not} {Enough} {Information}”: {On} the {Effects} of {Explanations} on {Perceptions} of {Informational} {Fairness} and {Trustworthiness} in {Automated} {Decision}-{Making}},
	isbn = {978-1-4503-9352-2},
	shorttitle = {“{There} {Is} {Not} {Enough} {Information}”},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533218},
	doi = {10.1145/3531146.3533218},
	abstract = {Automated decision systems (ADS) are increasingly used for consequential decision-making. These systems often rely on sophisticated yet opaque machine learning models, which do not allow for understanding how a given decision was arrived at. In this work, we conduct a human subject study to assess people’s perceptions of informational fairness (i.e., whether people think they are given adequate information on and explanation of the process and its outcomes) and trustworthiness of an underlying ADS when provided with varying types of information about the system. More specifically, we instantiate an ADS in the area of automated loan approval and generate different explanations that are commonly used in the literature. We randomize the amount of information that study participants get to see by providing certain groups of people with the same explanations as others plus additional explanations. From our quantitative analyses, we observe that different amounts of information as well as people’s (self-assessed) AI literacy significantly influence the perceived informational fairness, which, in turn, positively relates to perceived trustworthiness of the ADS. A comprehensive analysis of qualitative feedback sheds light on people’s desiderata for explanations, among which are (i) consistency (both with people’s expectations and across different explanations), (ii) disclosure of monotonic relationships between features and outcome, and (iii) actionability of recommendations.},
	language = {en},
	urldate = {2022-10-05},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Schoeffer, Jakob and Kuehl, Niklas and Machowski, Yvette},
	month = jun,
	year = {2022},
	pages = {1616--1628},
}

@inproceedings{ReviewTaxonomiesExplainableArtificialIntelligence,
	address = {Seoul Republic of Korea},
	title = {A {Review} of {Taxonomies} of {Explainable} {Artificial} {Intelligence} ({XAI}) {Methods}},
	isbn = {978-1-4503-9352-2},
	url = {https://dl.acm.org/doi/10.1145/3531146.3534639},
	doi = {10.1145/3531146.3534639},
	abstract = {The recent surge in publications related to explainable artificial intelligence (XAI) has led to an almost insurmountable wall if one wants to get started or stay up to date with XAI. For this reason, articles and reviews that present taxonomies of XAI methods seem to be a welcomed way to get an overview of the field. Building on this idea, there is currently a trend of producing such taxonomies, leading to several competing approaches to construct them. In this paper, we will review recent approaches to constructing taxonomies of XAI methods and discuss general challenges concerning them as well as their individual advantages and limitations. Our review is intended to help scholars be aware of challenges current taxonomies face. As we will argue, when charting the field of XAI, it may not be sufficient to rely on one of the approaches we found. To amend this problem, we will propose and discuss three possible solutions: a new taxonomy that incorporates the reviewed ones, a database of XAI methods, and a decision tree to help choose fitting methods.},
	language = {en},
	urldate = {2022-10-05},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Speith, Timo},
	month = jun,
	year = {2022},
	keywords = {explainable, explanation, fatml},
	pages = {2239--2250},
}

@inproceedings{ControllableExplanationGenerationRecommenderSystems,
	address = {Taipei Taiwan},
	title = {Towards {Controllable} {Explanation} {Generation} for {Recommender} {Systems} via {Neural} {Template}},
	isbn = {978-1-4503-7024-0},
	url = {https://dl.acm.org/doi/10.1145/3366424.3383540},
	doi = {10.1145/3366424.3383540},
	abstract = {It has been commonly agreed that the explanation associated with recommendation can be effective in increasing the recommender systems (RS)’s transparency and thus users’ satisfaction and acceptance. Among the various types of explanation in RS, the commonly used textual explanation can be roughly classified into two categories, i.e., template-based and generation-based. As for the former, the fixed template may lose flexibility, while, though the latter may enrich the explanation, it may produce less useful content due to the lack of controllability. In this work, we combine the advantages of the two types of method by developing a neural generation approach named Neural Template (NETE) whose explanations are not only flexible but also controllable and useful. Our human evaluation results confirm that the explanations from our model are perceived helpful by users. Furthermore, our case study illustrates that the explanation generation process is controllable. To demonstrate the controllability of our model, we present a demo that can be easily viewed on a Web browser.},
	language = {en},
	urldate = {2022-10-05},
	booktitle = {Companion {Proceedings} of the {Web} {Conference} 2020},
	publisher = {ACM},
	author = {Li, Lei and Chen, Li and Zhang, Yongfeng},
	month = apr,
	year = {2020},
	pages = {198--202},
}

@inproceedings{ImprovingPersonalizedExplanationGenerationVisualization,
	address = {Dublin, Ireland},
	title = {Improving {Personalized} {Explanation} {Generation} through {Visualization}},
	url = {https://aclanthology.org/2022.acl-long.20},
	doi = {10.18653/v1/2022.acl-long.20},
	abstract = {In modern recommender systems, there are usually comments or reviews from users that justify their ratings for different items. Trained on such textual corpus, explainable recommendation models learn to discover user interests and generate personalized explanations. Though able to provide plausible explanations, existing models tend to generate repeated sentences for different items or empty sentences with insufficient details. This begs an interesting question: can we immerse the models in a multimodal environment to gain proper awareness of real-world concepts and alleviate above shortcomings? To this end, we propose a visually-enhanced approach named METER with the help of visualization generation and text–image matching discrimination: the explainable recommendation model is encouraged to visualize what it refers to while incurring a penalty if the visualization is incongruent with the textual explanation. Experimental results and a manual assessment demonstrate that our approach can improve not only the text quality but also the diversity and explainability of the generated explanations.},
	urldate = {2022-10-05},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Geng, Shijie and Fu, Zuohui and Ge, Yingqiang and Li, Lei and de Melo, Gerard and Zhang, Yongfeng},
	month = may,
	year = {2022},
	keywords = {nlg, nlp, personalization},
	pages = {244--255},
}

@article{contrastiveaccountexplanationgeneration,
	title = {A contrastive account of explanation generation},
	volume = {24},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-017-1349-x},
	doi = {10.3758/s13423-017-1349-x},
	abstract = {In this article, we propose a contrastive account of explanation generation. Though researchers have long wrestled with the concepts of explanation and understanding, as well as with the procedures by which we might evaluate explanations, less attention has been paid to the initial generation stages of explanation. Before an explainer can answer a question, he or she must come to some understanding of the explanandum—what the question is asking—and of the explanatory form and content called for by the context. Here candidate explanations are constructed to respond to the particular interpretation of the question, which, according to the pragmatic approach to explanation, is constrained by a contrast class—a set of related but nonoccurring alternatives to the topic that emerge from the surrounding context and the explainer’s prior knowledge. In this article, we suggest that generating an explanation involves two operations: one that homes in on an interpretation of the question, and a second one that locates an answer. We review empirical work that supports this account, consider the implications of these contrastive processes, and identify areas for future study.},
	language = {en},
	number = {5},
	urldate = {2022-10-05},
	journal = {Psychonomic Bulletin \& Review},
	author = {Chin-Parker, Seth and Bradner, Alexandra},
	month = oct,
	year = {2017},
	keywords = {cognitive, explanation},
	pages = {1387--1397},
}

@article{CausalRepresentationLearning,
	title = {Causal {Representation} {Learning}},
	abstract = {Although the field of causality has developed separately from machine learning, it has proven in recent years to be a useful tool for addressing many fundamental questions in machine learning, from robustness to distribution shift, explainability to fairness. In this review, we discuss existing work in causal representation learning and structure learning. First, we define a causal representation as one which satisfies properties of causal variables and survey existing works to build causal representations. We describe methods for building causal representations which utilize data from multiple environments, as well as methods which only assume access to samples from a single environment. We then describe approaches for learning the structure of a causal graph. Finally, we provide closing thoughts on potential future directions based on existing works.},
	language = {en},
	author = {Lotfi, Sanae and Makino, Taro and Zhang, Lily},
	keywords = {causal, nlp, scm},
	pages = {11},
}

@article{CausalLensControllableTextGeneration,
	title = {A {Causal} {Lens} for {Controllable} {Text} {Generation}},
	abstract = {Controllable text generation concerns two fundamental tasks of wide applications, namely generating text of given attributes (i.e., attribute-conditional generation), and minimally editing existing text to possess desired attributes (i.e., text attribute transfer). Extensive prior work has largely studied the two problems separately, and developed different conditional models which, however, are prone to producing biased text (e.g., various gender stereotypes). This paper proposes to formulate controllable text generation from a principled causal perspective which models the two tasks with a uniﬁed framework. A direct advantage of the causal formulation is the use of rich causality tools to mitigate generation biases and improve control. We treat the two tasks as interventional and counterfactual causal inference based on a structural causal model, respectively. We then apply the framework to the challenging practical setting where confounding factors (that induce spurious correlations) are observable only on a small fraction of data. Experiments show signiﬁcant superiority of the causal approach over previous conditional models for improved control accuracy and reduced bias.},
	language = {en},
	author = {Hu, Zhiting and Li, Li Erran},
	pages = {15},
}

@inproceedings{MappingDesignSpaceHumanAIInteraction,
	address = {Seattle, United States},
	title = {Mapping the {Design} {Space} of {Human}-{AI} {Interaction} in {Text} {Summarization}},
	url = {https://aclanthology.org/2022.naacl-main.33},
	doi = {10.18653/v1/2022.naacl-main.33},
	abstract = {Automatic text summarization systems commonly involve humans for preparing data or evaluating model performance, yet, there lacks a systematic understanding of humans' roles, experience, and needs when interacting with or being assisted by AI. From a human-centered perspective, we map the design opportunities and considerations for human-AI interaction in text summarization and broader text generation tasks. We first conducted a systematic literature review of 70 papers, developing a taxonomy of five interactions in AI-assisted text generation and relevant design dimensions. We designed text summarization prototypes for each interaction. We then interviewed 16 users, aided by the prototypes, to understand their expectations, experience, and needs regarding efficiency, control, and trust with AI in text summarization and propose design considerations accordingly.},
	urldate = {2022-10-07},
	booktitle = {Proceedings of the 2022 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Cheng, Ruijia and Smith-Renner, Alison and Zhang, Ke and Tetreault, Joel and Jaimes-Larrarte, Alejandro},
	month = jul,
	year = {2022},
	pages = {431--455},
}

@article{DecidingFastSlowRoleCognitiveb,
	title = {Deciding {Fast} and {Slow}: {The} {Role} of {Cognitive} {Biases} in {AI}-assisted {Decision}-making},
	volume = {6},
	issn = {2573-0142},
	shorttitle = {Deciding {Fast} and {Slow}},
	url = {https://dl.acm.org/doi/10.1145/3512930},
	doi = {10.1145/3512930},
	abstract = {Several strands of research have aimed to bridge the gap between artificial intelligence (AI) and human decision-makers in AI-assisted decision-making, where humans are the consumers of AI model predictions and the ultimate decision-makers in high-stakes applications. However, people's perception and understanding are often distorted by their cognitive biases, such as confirmation bias, anchoring bias, availability bias, to name a few. In this work, we use knowledge from the field of cognitive science to account for cognitive biases in the human-AI collaborative decision-making setting, and mitigate their negative effects on collaborative performance. To this end, we mathematically model cognitive biases and provide a general framework through which researchers and practitioners can understand the interplay between cognitive biases and human-AI accuracy. We then focus specifically on anchoring bias, a bias commonly encountered in human-AI collaboration. We implement a time-based de-anchoring strategy and conduct our first user experiment that validates its effectiveness in human-AI collaborative decision-making. With this result, we design a time allocation strategy for a resource-constrained setting that achieves optimal human-AI collaboration under some assumptions. We, then, conduct a second user experiment which shows that our time allocation strategy with explanation can effectively de-anchor the human and improve collaborative performance when the AI model has low confidence and is incorrect.},
	language = {en},
	number = {CSCW1},
	urldate = {2022-10-12},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Rastogi, Charvi and Zhang, Yunfeng and Wei, Dennis and Varshney, Kush R. and Dhurandhar, Amit and Tomsett, Richard},
	month = mar,
	year = {2022},
	pages = {1--22},
}

@inproceedings{HowCognitiveBiasesAffectXAIassisted,
	address = {Oxford United Kingdom},
	title = {How {Cognitive} {Biases} {Affect} {XAI}-assisted {Decision}-making: {A} {Systematic} {Review}},
	isbn = {978-1-4503-9247-1},
	shorttitle = {How {Cognitive} {Biases} {Affect} {XAI}-assisted {Decision}-making},
	url = {https://dl.acm.org/doi/10.1145/3514094.3534164},
	doi = {10.1145/3514094.3534164},
	abstract = {The field of eXplainable Artificial Intelligence (XAI) aims to bring transparency to complex AI systems. Although it is usually considered an essentially technical field, effort has been made recently to better understand users’ human explanation methods and cognitive constraints. Despite these advances, the community lacks a general vision of what and how cognitive biases affect explainability systems. To address this gap, we present a heuristic map which matches human cognitive biases with explainability techniques from the XAI literature, structured around XAI-aided decision-making. We identify four main ways cognitive biases affect or are affected by XAI systems: 1) cognitive biases affect how XAI methods are designed, 2) they can distort how XAI techniques are evaluated in user studies, 3) some cognitive biases can be successfully mitigated by XAI techniques, and, on the contrary, 4) some cognitive biases can be exacerbated by XAI techniques. We construct this heuristic map through the systematic review of 37 papers—drawn from a corpus of 285—that reveal cognitive biases in XAI systems, including the explainability method and the user and task types in which they arise. We use the findings from our review to structure directions for future XAI systems to better align with people’s cognitive processes.},
	language = {en},
	urldate = {2022-10-12},
	booktitle = {Proceedings of the 2022 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Bertrand, Astrid and Belloum, Rafik and Eagan, James R. and Maxwell, Winston},
	month = jul,
	year = {2022},
	pages = {78--91},
}

@inproceedings{HowCognitiveBiasesAffectXAIassisteda,
	address = {Oxford United Kingdom},
	title = {How {Cognitive} {Biases} {Affect} {XAI}-assisted {Decision}-making: {A} {Systematic} {Review}},
	isbn = {978-1-4503-9247-1},
	shorttitle = {How {Cognitive} {Biases} {Affect} {XAI}-assisted {Decision}-making},
	url = {https://dl.acm.org/doi/10.1145/3514094.3534164},
	doi = {10.1145/3514094.3534164},
	abstract = {The field of eXplainable Artificial Intelligence (XAI) aims to bring transparency to complex AI systems. Although it is usually considered an essentially technical field, effort has been made recently to better understand users’ human explanation methods and cognitive constraints. Despite these advances, the community lacks a general vision of what and how cognitive biases affect explainability systems. To address this gap, we present a heuristic map which matches human cognitive biases with explainability techniques from the XAI literature, structured around XAI-aided decision-making. We identify four main ways cognitive biases affect or are affected by XAI systems: 1) cognitive biases affect how XAI methods are designed, 2) they can distort how XAI techniques are evaluated in user studies, 3) some cognitive biases can be successfully mitigated by XAI techniques, and, on the contrary, 4) some cognitive biases can be exacerbated by XAI techniques. We construct this heuristic map through the systematic review of 37 papers—drawn from a corpus of 285—that reveal cognitive biases in XAI systems, including the explainability method and the user and task types in which they arise. We use the findings from our review to structure directions for future XAI systems to better align with people’s cognitive processes.},
	language = {en},
	urldate = {2022-10-12},
	booktitle = {Proceedings of the 2022 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Bertrand, Astrid and Belloum, Rafik and Eagan, James R. and Maxwell, Winston},
	month = jul,
	year = {2022},
	pages = {78--91},
}

@article{DecidingFastSlowRoleCognitivec,
	title = {Deciding {Fast} and {Slow}: {The} {Role} of {Cognitive} {Biases} in {AI}-assisted {Decision}-making},
	volume = {6},
	issn = {2573-0142},
	shorttitle = {Deciding {Fast} and {Slow}},
	url = {https://dl.acm.org/doi/10.1145/3512930},
	doi = {10.1145/3512930},
	abstract = {Several strands of research have aimed to bridge the gap between artificial intelligence (AI) and human decision-makers in AI-assisted decision-making, where humans are the consumers of AI model predictions and the ultimate decision-makers in high-stakes applications. However, people's perception and understanding are often distorted by their cognitive biases, such as confirmation bias, anchoring bias, availability bias, to name a few. In this work, we use knowledge from the field of cognitive science to account for cognitive biases in the human-AI collaborative decision-making setting, and mitigate their negative effects on collaborative performance. To this end, we mathematically model cognitive biases and provide a general framework through which researchers and practitioners can understand the interplay between cognitive biases and human-AI accuracy. We then focus specifically on anchoring bias, a bias commonly encountered in human-AI collaboration. We implement a time-based de-anchoring strategy and conduct our first user experiment that validates its effectiveness in human-AI collaborative decision-making. With this result, we design a time allocation strategy for a resource-constrained setting that achieves optimal human-AI collaboration under some assumptions. We, then, conduct a second user experiment which shows that our time allocation strategy with explanation can effectively de-anchor the human and improve collaborative performance when the AI model has low confidence and is incorrect.},
	language = {en},
	number = {CSCW1},
	urldate = {2022-10-12},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Rastogi, Charvi and Zhang, Yunfeng and Wei, Dennis and Varshney, Kush R. and Dhurandhar, Amit and Tomsett, Richard},
	month = mar,
	year = {2022},
	keywords = {cognitive-bias, decision-making},
	pages = {1--22},
}

@inproceedings{FairnessExplanationQualityEvaluatingDisparities,
	title = {Fairness via {Explanation} {Quality}: {Evaluating} {Disparities} in the {Quality} of {Post} hoc {Explanations}},
	shorttitle = {Fairness via {Explanation} {Quality}},
	url = {http://arxiv.org/abs/2205.07277},
	doi = {10.1145/3514094.3534159},
	abstract = {As post hoc explanation methods are increasingly being leveraged to explain complex models in high-stakes settings, it becomes critical to ensure that the quality of the resulting explanations is consistently high across various population subgroups including the minority groups. For instance, it should not be the case that explanations associated with instances belonging to a particular gender subgroup (e.g., female) are less accurate than those associated with other genders. However, there is little to no research that assesses if there exist such group-based disparities in the quality of the explanations output by state-of-the-art explanation methods. In this work, we address the aforementioned gaps by initiating the study of identifying group-based disparities in explanation quality. To this end, we first outline the key properties which constitute explanation quality and where disparities can be particularly problematic. We then leverage these properties to propose a novel evaluation framework which can quantitatively measure disparities in the quality of explanations output by state-of-the-art methods. Using this framework, we carry out a rigorous empirical analysis to understand if and when group-based disparities in explanation quality arise. Our results indicate that such disparities are more likely to occur when the models being explained are complex and highly non-linear. In addition, we also observe that certain post hoc explanation methods (e.g., Integrated Gradients, SHAP) are more likely to exhibit the aforementioned disparities. To the best of our knowledge, this work is the first to highlight and study the problem of group-based disparities in explanation quality. In doing so, our work sheds light on previously unexplored ways in which explanation methods may introduce unfairness in real world decision making.},
	urldate = {2022-10-12},
	booktitle = {Proceedings of the 2022 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	author = {Dai, Jessica and Upadhyay, Sohini and Aivodji, Ulrich and Bach, Stephen H. and Lakkaraju, Himabindu},
	month = jul,
	year = {2022},
	note = {arXiv:2205.07277 [cs]},
	keywords = {Computer Science - Machine Learning, explanation, fair, fatml},
	pages = {203--214},
}

@inproceedings{ExplainableFairnessRecommendation,
	title = {Explainable {Fairness} in {Recommendation}},
	url = {http://arxiv.org/abs/2204.11159},
	doi = {10.1145/3477495.3531973},
	abstract = {Existing research on fairness-aware recommendation has mainly focused on the quantification of fairness and the development of fair recommendation models, neither of which studies a more substantial problem--identifying the underlying reason of model disparity in recommendation. This information is critical for recommender system designers to understand the intrinsic recommendation mechanism and provides insights on how to improve model fairness to decision makers. Fortunately, with the rapid development of Explainable AI, we can use model explainability to gain insights into model (un)fairness. In this paper, we study the problem of explainable fairness, which helps to gain insights about why a system is fair or unfair, and guides the design of fair recommender systems with a more informed and unified methodology. Particularly, we focus on a common setting with feature-aware recommendation and exposure unfairness, but the proposed explainable fairness framework is general and can be applied to other recommendation settings and fairness definitions. We propose a Counterfactual Explainable Fairness framework, called CEF, which generates explanations about model fairness that can improve the fairness without significantly hurting the performance.The CEF framework formulates an optimization problem to learn the "minimal" change of the input features that changes the recommendation results to a certain level of fairness. Based on the counterfactual recommendation result of each feature, we calculate an explainability score in terms of the fairness-utility trade-off to rank all the feature-based explanations, and select the top ones as fairness explanations.},
	urldate = {2022-10-15},
	booktitle = {Proceedings of the 45th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	author = {Ge, Yingqiang and Tan, Juntao and Zhu, Yan and Xia, Yinglong and Luo, Jiebo and Liu, Shuchang and Fu, Zuohui and Geng, Shijie and Li, Zelong and Zhang, Yongfeng},
	month = jul,
	year = {2022},
	note = {arXiv:2204.11159 [cs]},
	keywords = {Computer Science - Information Retrieval, counterfactual, fair, rec},
	pages = {681--691},
}

@article{MultidisciplinarySurveyFrameworkDesignEvaluation,
	title = {A {Multidisciplinary} {Survey} and {Framework} for {Design} and {Evaluation} of {Explainable} {AI} {Systems}},
	volume = {11},
	issn = {2160-6455, 2160-6463},
	url = {https://dl.acm.org/doi/10.1145/3387166},
	doi = {10.1145/3387166},
	abstract = {The need for interpretable and accountable intelligent systems grows along with the prevalence of
              artificial intelligence
              (
              AI
              ) applications used in everyday life.
              Explainable AI
              (
              XAI
              ) systems are intended to self-explain the reasoning behind system decisions and predictions. Researchers from different disciplines work together to define, design, and evaluate explainable systems. However, scholars from different disciplines focus on different objectives and fairly independent topics of XAI research, which poses challenges for identifying appropriate design and evaluation methodology and consolidating knowledge across efforts. To this end, this article presents a survey and framework intended to share knowledge and experiences of XAI design and evaluation methods across multiple disciplines. Aiming to support diverse design goals and evaluation methods in XAI research, after a thorough review of XAI related papers in the fields of machine learning, visualization, and human-computer interaction, we present a categorization of XAI design goals and evaluation methods. Our categorization presents the mapping between design goals for different XAI user groups and their evaluation methods. From our findings, we develop a framework with step-by-step design guidelines paired with evaluation methods to close the iterative design and evaluation cycles in multidisciplinary XAI teams. Further, we provide summarized ready-to-use tables of evaluation methods and recommendations for different goals in XAI research.},
	language = {en},
	number = {3-4},
	urldate = {2022-10-15},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Mohseni, Sina and Zarei, Niloofar and Ragan, Eric D.},
	month = dec,
	year = {2021},
	keywords = {survey, vis, xai},
	pages = {1--45},
}

@article{DecidingFastSlowRoleCognitive,
	title = {Deciding {Fast} and {Slow}: {The} {Role} of {Cognitive} {Biases} in {AI}-assisted {Decision}-making},
	volume = {6},
	issn = {2573-0142},
	shorttitle = {Deciding {Fast} and {Slow}},
	url = {https://dl.acm.org/doi/10.1145/3512930},
	doi = {10.1145/3512930},
	abstract = {Several strands of research have aimed to bridge the gap between artificial intelligence (AI) and human decision-makers in AI-assisted decision-making, where humans are the consumers of AI model predictions and the ultimate decision-makers in high-stakes applications. However, people's perception and understanding are often distorted by their cognitive biases, such as confirmation bias, anchoring bias, availability bias, to name a few. In this work, we use knowledge from the field of cognitive science to account for cognitive biases in the human-AI collaborative decision-making setting, and mitigate their negative effects on collaborative performance. To this end, we mathematically model cognitive biases and provide a general framework through which researchers and practitioners can understand the interplay between cognitive biases and human-AI accuracy. We then focus specifically on anchoring bias, a bias commonly encountered in human-AI collaboration. We implement a time-based de-anchoring strategy and conduct our first user experiment that validates its effectiveness in human-AI collaborative decision-making. With this result, we design a time allocation strategy for a resource-constrained setting that achieves optimal human-AI collaboration under some assumptions. We, then, conduct a second user experiment which shows that our time allocation strategy with explanation can effectively de-anchor the human and improve collaborative performance when the AI model has low confidence and is incorrect.},
	language = {en},
	number = {CSCW1},
	urldate = {2022-10-13},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Rastogi, Charvi and Zhang, Yunfeng and Wei, Dennis and Varshney, Kush R. and Dhurandhar, Amit and Tomsett, Richard},
	month = mar,
	year = {2022},
	keywords = {cogitive-bias, xai},
	pages = {1--22},
}

@article{DecidingFastSlowRoleCognitivea,
	title = {Deciding {Fast} and {Slow}: {The} {Role} of {Cognitive} {Biases} in {AI}-assisted {Decision}-making},
	volume = {6},
	issn = {2573-0142},
	shorttitle = {Deciding {Fast} and {Slow}},
	url = {https://dl.acm.org/doi/10.1145/3512930},
	doi = {10.1145/3512930},
	abstract = {Several strands of research have aimed to bridge the gap between artificial intelligence (AI) and human decision-makers in AI-assisted decision-making, where humans are the consumers of AI model predictions and the ultimate decision-makers in high-stakes applications. However, people's perception and understanding are often distorted by their cognitive biases, such as confirmation bias, anchoring bias, availability bias, to name a few. In this work, we use knowledge from the field of cognitive science to account for cognitive biases in the human-AI collaborative decision-making setting, and mitigate their negative effects on collaborative performance. To this end, we mathematically model cognitive biases and provide a general framework through which researchers and practitioners can understand the interplay between cognitive biases and human-AI accuracy. We then focus specifically on anchoring bias, a bias commonly encountered in human-AI collaboration. We implement a time-based de-anchoring strategy and conduct our first user experiment that validates its effectiveness in human-AI collaborative decision-making. With this result, we design a time allocation strategy for a resource-constrained setting that achieves optimal human-AI collaboration under some assumptions. We, then, conduct a second user experiment which shows that our time allocation strategy with explanation can effectively de-anchor the human and improve collaborative performance when the AI model has low confidence and is incorrect.},
	language = {en},
	number = {CSCW1},
	urldate = {2022-10-13},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Rastogi, Charvi and Zhang, Yunfeng and Wei, Dennis and Varshney, Kush R. and Dhurandhar, Amit and Tomsett, Richard},
	month = mar,
	year = {2022},
	pages = {1--22},
}

@inproceedings{WhyAmNotSeeingIt,
	address = {Seoul Republic of Korea},
	title = {Why {Am} {I} {Not} {Seeing} {It}? {Understanding} {Users}’ {Needs} for {Counterfactual} {Explanations} in {Everyday} {Recommendations}},
	isbn = {978-1-4503-9352-2},
	shorttitle = {Why {Am} {I} {Not} {Seeing} {It}?},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533189},
	doi = {10.1145/3531146.3533189},
	abstract = {Intelligent everyday applications typically rely on automated Recommender Systems (RS) to generate recommendations that help users make decisions among a large number of options. Due to the increasing complexity of RS and the lack of transparency in its algorithmic decision-making, researchers have recognized the need to support users with explanations. While many traditional Explainable AI methods fall short in disclosing the internal intricacy of recommender systems, counterfactual explanations provide many desirable explainable features by offering human-like explanations that contrast an existing recommendation with alternatives. However, there is a lack of empirical research in understanding users’ needs of counterfactual explanations in their usage of everyday intelligent applications. In this paper, we investigate whether and when to provide counterfactual explanations to support people’s decision-making with everyday recommendations through a question-driven approach. We conducted a preliminary survey study and an interview study to understand how existing explanations might be insufficient to support users and elicit the triggers that prompt them to ask why not questions and seek additional explanations. The findings reveal that the utility of decision is a primary factor that may affect their counterfactual information needs. We then conducted an online scenario-based survey to quantify the correlation between utility and explanation needs and found significant correlations between the measured variables.},
	language = {en},
	urldate = {2022-10-17},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Shang, Ruoxi and Feng, K. J. Kevin and Shah, Chirag},
	month = jun,
	year = {2022},
	keywords = {counterfactual, explanation, fair, rec},
	pages = {1330--1340},
}

@inproceedings{SelectiveFairnessRecommendationPromptsa,
	address = {Madrid Spain},
	title = {Selective {Fairness} in {Recommendation} via {Prompts}},
	isbn = {978-1-4503-8732-3},
	url = {https://dl.acm.org/doi/10.1145/3477495.3531913},
	doi = {10.1145/3477495.3531913},
	abstract = {Recommendation fairness has attracted great attention recently. In real-world systems, users usually have multiple sensitive attributes (e.g. age, gender, and occupation), and users may not want their recommendation results influenced by those attributes. Moreover, which of and when these user attributes should be considered in fairness-aware modeling should depend on users’ specific demands. In this work, we define the selective fairness task, where users can flexibly choose which sensitive attributes should the recommendation model be bias-free. We propose a novel parameter-efficient prompt-based fairness-aware recommendation (PFRec) framework, which relies on attribute-specific prompt-based bias eliminators with adversarial training, enabling selective fairness with different attribute combinations on sequential recommendation. Both task-specific and user-specific prompts are considered. We conduct extensive evaluations to verify PFRec’s superiority in selective fairness. The source codes are released in https://github.com/wyqing20/PFRec.},
	language = {en},
	urldate = {2022-10-17},
	booktitle = {Proceedings of the 45th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Wu, Yiqing and Xie, Ruobing and Zhu, Yongchun and Zhuang, Fuzhen and Xiang, Ao and Zhang, Xu and Lin, Leyu and He, Qing},
	month = jul,
	year = {2022},
	pages = {2657--2662},
}

@incollection{ConsumerFairnessRecommenderSystemsContextualizing,
	title = {Consumer {Fairness} in {Recommender} {Systems}: {Contextualizing} {Definitions} and {Mitigations}},
	volume = {13185},
	shorttitle = {Consumer {Fairness} in {Recommender} {Systems}},
	url = {http://arxiv.org/abs/2201.08614},
	abstract = {Enabling non-discrimination for end-users of recommender systems by introducing consumer fairness is a key problem, widely studied in both academia and industry. Current research has led to a variety of notions, metrics, and unfairness mitigation procedures. The evaluation of each procedure has been heterogeneous and limited to a mere comparison with models not accounting for fairness. It is hence hard to contextualize the impact of each mitigation procedure w.r.t. the others. In this paper, we conduct a systematic analysis of mitigation procedures against consumer unfairness in rating prediction and top-n recommendation tasks. To this end, we collected 15 procedures proposed in recent top-tier conferences and journals. Only 8 of them could be reproduced. Under a common evaluation protocol, based on two public data sets, we then studied the extent to which recommendation utility and consumer fairness are impacted by these procedures, the interplay between two primary fairness notions based on equity and independence, and the demographic groups harmed by the disparate impact. Our study finally highlights open challenges and future directions in this field. The source code is available at https://github.com/jackmedda/C-Fairness-RecSys.},
	urldate = {2022-10-17},
	author = {Boratto, Ludovico and Fenu, Gianni and Marras, Mirko and Medda, Giacomo},
	year = {2022},
	doi = {10.1007/978-3-030-99736-6_37},
	note = {arXiv:2201.08614 [cs]},
	keywords = {Computer Science - Information Retrieval, fair, rec},
	pages = {552--566},
}

@inproceedings{FairnessAwareRankingSearchRecommendationSystems,
	address = {Anchorage AK USA},
	title = {Fairness-{Aware} {Ranking} in {Search} \& {Recommendation} {Systems} with {Application} to {LinkedIn} {Talent} {Search}},
	isbn = {978-1-4503-6201-6},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330691},
	doi = {10.1145/3292500.3330691},
	abstract = {We present a framework for quantifying and mitigating algorithmic bias in mechanisms designed for ranking individuals, typically used as part of web-scale search and recommendation systems. We first propose complementary measures to quantify bias with respect to protected attributes such as gender and age. We then present algorithms for computing fairness-aware re-ranking of results. For a given search or recommendation task, our algorithms seek to achieve a desired distribution of top ranked results with respect to one or more protected attributes. We show that such a framework can be tailored to achieve fairness criteria such as equality of opportunity and demographic parity depending on the choice of the desired distribution. We evaluate the proposed algorithms via extensive simulations over different parameter choices, and study the effect of fairness-aware ranking on both bias and utility measures. We finally present the online A/B testing results from applying our framework towards representative ranking in LinkedIn Talent Search, and discuss the lessons learned in practice. Our approach resulted in tremendous improvement in the fairness metrics (nearly three fold increase in the number of search queries with representative results) without affecting the business metrics, which paved the way for deployment to 100\% of LinkedIn Recruiter users worldwide. Ours is the first large-scale deployed framework for ensuring fairness in the hiring domain, with the potential positive impact for more than 630M LinkedIn members.},
	language = {en},
	urldate = {2022-10-17},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Geyik, Sahin Cem and Ambler, Stuart and Kenthapadi, Krishnaram},
	month = jul,
	year = {2019},
	pages = {2221--2231},
}

@article{CausalConceptionsFairnesstheirConsequences,
	title = {Causal {Conceptions} of {Fairness} and their {Consequences}},
	abstract = {Recent work highlights the role of causality in designing equitable decision-making algorithms. It is not immediately clear, however, how existing causal conceptions of fairness relate to one another, or what the consequences are of using these definitions as design principles. Here, we first assemble and categorize popular causal definitions of algorithmic fairness into two broad families: (1) those that constrain the effects of decisions on counterfactual disparities; and (2) those that constrain the effects of legally protected characteristics, like race and gender, on decisions. We then show, analytically and empirically, that both families of definitions almost always—in a measure theoretic sense—result in strongly Pareto dominated decision policies, meaning there is an alternative, unconstrained policy favored by every stakeholder with preferences drawn from a large, natural class. For example, in the case of college admissions decisions, policies constrained to satisfy causal fairness definitions would be disfavored by every stakeholder with neutral or positive preferences for both academic preparedness and diversity. Indeed, under a prominent definition of causal fairness, we prove the resulting policies require admitting all students with the same probability, regardless of academic qualifications or group membership. Our results highlight formal limitations and potential adverse consequences of common mathematical notions of causal fairness.},
	language = {en},
	author = {Nilforoshan, Hamed and Gaebler, Johann and Shroff, Ravi and Goel, Sharad},
	pages = {40},
}

@inproceedings{ViCEvisualcounterfactualexplanationsmachine,
	address = {Cagliari Italy},
	title = {{ViCE}: visual counterfactual explanations for machine learning models},
	isbn = {978-1-4503-7118-6},
	shorttitle = {{ViCE}},
	url = {https://dl.acm.org/doi/10.1145/3377325.3377536},
	doi = {10.1145/3377325.3377536},
	abstract = {The continued improvements in the predictive accuracy of machine learning models have allowed for their widespread practical application. Yet, many decisions made with seemingly accurate models still require verification by domain experts. In addition, end-users of a model also want to understand the reasons behind specific decisions. Thus, the need for interpretability is increasingly paramount. In this paper we present an interactive visual analytics tool, ViCE, that generates counterfactual explanations to contextualize and evaluate model decisions. Each sample is assessed to identify the minimal set of changes needed to flip the model’s output. These explanations aim to provide end-users with personalized actionable insights with which to understand, and possibly contest or improve, automated decisions. The results are effectively displayed in a visual interface where counterfactual explanations are highlighted and interactive methods are provided for users to explore the data and model. The functionality of the tool is demonstrated by its application to a home equity line of credit dataset.},
	language = {en},
	urldate = {2022-10-17},
	booktitle = {Proceedings of the 25th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Gomez, Oscar and Holter, Steffen and Yuan, Jun and Bertini, Enrico},
	month = mar,
	year = {2020},
	pages = {531--535},
}

@inproceedings{PersonalizedFairnessbasedCausalNotion,
	address = {Virtual Event Canada},
	title = {Towards {Personalized} {Fairness} based on {Causal} {Notion}},
	isbn = {978-1-4503-8037-9},
	url = {https://dl.acm.org/doi/10.1145/3404835.3462966},
	doi = {10.1145/3404835.3462966},
	abstract = {Recommender systems are gaining increasing and critical impacts on human and society since a growing number of users use them for information seeking and decision making. Therefore, it is crucial to address the potential unfairness problems in recommendations. Just like users have personalized preferences on items, users’ demands for fairness are also personalized in many scenarios. Therefore, it is important to provide personalized fair recommendations for users to satisfy their personalized fairness demands. Besides, previous works on fair recommendation mainly focus on associationbased fairness. However, it is important to advance from associative fairness notions to causal fairness notions for assessing fairness more properly in recommender systems. Based on the above considerations, this paper focuses on achieving personalized counterfactual fairness for users in recommender systems. To this end, we introduce a framework for achieving counterfactually fair recommendations through adversary learning by generating featureindependent user embeddings for recommendation. The framework allows recommender systems to achieve personalized fairness for users while also covering non-personalized situations. Experiments on two real-world datasets with shallow and deep recommendation algorithms show that our method can generate fairer recommendations for users with a desirable recommendation performance.},
	language = {en},
	urldate = {2022-10-17},
	booktitle = {Proceedings of the 44th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Li, Yunqi and Chen, Hanxiong and Xu, Shuyuan and Ge, Yingqiang and Zhang, Yongfeng},
	month = jul,
	year = {2021},
	pages = {1054--1063},
}

@inproceedings{SelectiveFairnessRecommendationPrompts,
	address = {Madrid Spain},
	title = {Selective {Fairness} in {Recommendation} via {Prompts}},
	isbn = {978-1-4503-8732-3},
	url = {https://dl.acm.org/doi/10.1145/3477495.3531913},
	doi = {10.1145/3477495.3531913},
	abstract = {Recommendation fairness has attracted great attention recently. In real-world systems, users usually have multiple sensitive attributes (e.g. age, gender, and occupation), and users may not want their recommendation results influenced by those attributes. Moreover, which of and when these user attributes should be considered in fairness-aware modeling should depend on users’ specific demands. In this work, we define the selective fairness task, where users can flexibly choose which sensitive attributes should the recommendation model be bias-free. We propose a novel parameter-efficient prompt-based fairness-aware recommendation (PFRec) framework, which relies on attribute-specific prompt-based bias eliminators with adversarial training, enabling selective fairness with different attribute combinations on sequential recommendation. Both task-specific and user-specific prompts are considered. We conduct extensive evaluations to verify PFRec’s superiority in selective fairness. The source codes are released in https://github.com/wyqing20/PFRec.},
	language = {en},
	urldate = {2022-10-17},
	booktitle = {Proceedings of the 45th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Wu, Yiqing and Xie, Ruobing and Zhu, Yongchun and Zhuang, Fuzhen and Xiang, Ao and Zhang, Xu and Lin, Leyu and He, Qing},
	month = jul,
	year = {2022},
	pages = {2657--2662},
}

@article{CausalFairnessFieldGuidePerspectivesa,
	title = {The {Causal} {Fairness} {Field} {Guide}: {Perspectives} {From} {Social} and {Formal} {Sciences}},
	volume = {5},
	issn = {2624-909X},
	shorttitle = {The {Causal} {Fairness} {Field} {Guide}},
	url = {https://www.frontiersin.org/articles/10.3389/fdata.2022.892837/full},
	doi = {10.3389/fdata.2022.892837},
	abstract = {Over the past several years, multiple different methods to measure the causal fairness of machine learning models have been proposed. However, despite the growing number of publications and implementations, there is still a critical lack of literature that explains the interplay of causality-based fairness notions with the social sciences of philosophy, sociology, and law. We hope to remedy this issue by accumulating and expounding upon the thoughts and discussions of causality-based fairness notions produced by both social and formal (speciﬁcally machine learning) sciences in this ﬁeld guide. In addition to giving the mathematical backgrounds of several popular causality-based fair machine learning notions, we explain their connection to and interplay with the ﬁelds of philosophy and law. Further, we explore several criticisms of the current approaches to causality-based fair machine learning from a sociological viewpoint as well as from a technical standpoint. It is our hope that this ﬁeld guide will help fair machine learning practitioners better understand how their causality-based fairness notions align with important humanistic values (such as fairness) and how we can, as a ﬁeld, design methods and metrics to better serve oppressed and marginalized populaces.},
	language = {en},
	urldate = {2022-10-17},
	journal = {Frontiers in Big Data},
	author = {Carey, Alycia N. and Wu, Xintao},
	month = apr,
	year = {2022},
	keywords = {causal, fair, survey},
	pages = {892837},
}

@inproceedings{SilvaInteractivelyAssessingMachineLearninga,
	address = {Honolulu HI USA},
	title = {Silva: {Interactively} {Assessing} {Machine} {Learning} {Fairness} {Using} {Causality}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {Silva},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376447},
	doi = {10.1145/3313831.3376447},
	abstract = {Machine learning models risk encoding unfairness on the part of their developers or data sources. However, assessing fairness is challenging as analysts might misidentify sources of bias, fail to notice them, or misapply metrics. In this paper we introduce Silva, a system for exploring potential sources of unfairness in datasets or machine learning models interactively. Silva directs user attention to relationships between attributes through a global causal view, provides interactive recommendations, presents intermediate results, and visualizes metrics. We describe the implementation of Silva, identify salient design and technical challenges, and provide an evaluation of the tool in comparison to an existing fairness optimization tool.},
	language = {en},
	urldate = {2022-10-18},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yan, Jing Nathan and Gu, Ziwei and Lin, Hubert and Rzeszotarski, Jeffrey M.},
	month = apr,
	year = {2020},
	pages = {1--13},
}

@article{FairnessRecommenderSystemsResearchLandscapea,
	title = {Fairness in {Recommender} {Systems}: {Research} {Landscape} and {Future} {Directions}},
	abstract = {Recommender systems can strongly influence which information we see online, e.g, on social media, and thus impact our beliefs, decisions, and actions. At the same time, these systems can create substantial business value for different stakeholders. Given the growing potential impact of such AI-based systems on individuals, organizations, and society, questions of fairness have gained increased attention in recent years. However, research on fairness in recommender systems is still a developing area. In this survey, we first review the fundamental concepts and notions of fairness that were put forward in the area in the recent past. Afterwards, we provide a survey of how research in this area is currently operationalized, for example, in terms of the general research methodology, fairness metrics, and algorithmic approaches. Overall, our analysis of recent works points to certain research gaps. In particular, we find that in many research works in computer science very abstract problem operationalizations are prevalent, which circumvent the fundamental and important question of what represents a fair recommendation in the context of a given application.},
	language = {en},
	author = {Deldjoo, Yashar and Jannach, Dietmar and Bellogin, Alejandro and Zanzonelli, Dario},
	pages = {41},
}

@inproceedings{F2VAEframeworkmitigatinguserunfairness,
	address = {Virtual Event},
	title = {{F2VAE}: a framework for mitigating user unfairness in recommendation systems},
	isbn = {978-1-4503-8713-2},
	shorttitle = {{F2VAE}},
	url = {https://dl.acm.org/doi/10.1145/3477314.3507152},
	doi = {10.1145/3477314.3507152},
	abstract = {Recommendation algorithms are widely used nowadays, especially in scenarios of information overload (i.e., when users have too many options to choose from), due to their ability to suggest potentially relevant items to users in a personalized fashion. Users, nevertheless, might be considered as separated in groups according to sensitive attributes, such as age, gender or nationality, and the recommendation process might be biased towards one of these groups. If observed, this bias has to be mitigated actively, or it can propagate and be amplified over time. Here, we consider a relevant difference of recommendation quality among groups as unfair, and we argue that this difference should be maintained as low as possible. We propose a framework named F2VAE for mitigating user-oriented unfairness in recommender systems. The framework is based on Variational Autoencoders (VAE) and it introduces two extra terms in VAE’s standard loss function, one associated to fair representation and another one associated to fair recommendation. The conflicting objectives associated to these terms are discussed in details in a series of experiments considering the bias associated to the users’ nationality in a music consumption dataset. We recall recent works proposed for generating fair representations in the context of classification, and we adapt one of these methods to the recommendation task. F2VAE was able to increase the precision by approximately 1\% while reducing the unfairness by 21\% when compared to standard VAE.},
	language = {en},
	urldate = {2022-10-17},
	booktitle = {Proceedings of the 37th {ACM}/{SIGAPP} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Borges, Rodrigo and Stefanidis, Kostas},
	month = apr,
	year = {2022},
	pages = {1391--1398},
}

@inproceedings{ProtoMFPrototypebasedMatrixFactorizationEffective,
	address = {Seattle WA USA},
	title = {{ProtoMF}: {Prototype}-based {Matrix} {Factorization} for {Effective} and {Explainable} {Recommendations}},
	isbn = {978-1-4503-9278-5},
	shorttitle = {{ProtoMF}},
	url = {https://dl.acm.org/doi/10.1145/3523227.3546756},
	doi = {10.1145/3523227.3546756},
	abstract = {Recent studies show the benefits of reformulating common machine learning models through the concept of prototypes – representatives of the underlying data, used to calculate the prediction score as a linear combination of similarities of a data point to prototypes. Such prototype-based formulation of a model, in addition to preserving (sometimes enhancing) the performance, enables explainability of the model’s decisions, as the prediction can be linearly broken down into the contributions of distinct definable prototypes. Following this direction, we extend the idea of prototypes to the recommender system domain by introducing ProtoMF, a novel collaborative filtering algorithm. ProtoMF learns sets of user/item prototypes that represent the general consumption characteristics of users/items in the underlying dataset. Using these prototypes, ProtoMF then represents users and items as vectors of similarities to the corresponding prototypes. These user/item representations are ultimately leveraged to make recommendations that are both effective in terms of accuracy metrics, and explainable through the interpretation of prototypes’ contributions to the affinity scores. We conduct experiments on three datasets to assess both the effectiveness and the explainability of ProtoMF. Addressing the former, we show that ProtoMF exhibits higher Hit Ratio and NDCG compared to other relevant collaborative filtering approaches. As for the latter, we qualitatively show how ProtoMF can provide explainable recommendations and how its explanation capabilities can expose the existence of statistical biases in the learned representations, which we exemplify for the case of gender bias.},
	language = {en},
	urldate = {2022-10-17},
	booktitle = {Sixteenth {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Melchiorre, Alessandro B. and Rekabsaz, Navid and Ganhör, Christian and Schedl, Markus},
	month = sep,
	year = {2022},
	pages = {246--256},
}

@article{RecommendersystemsEuropeanAIregulations,
	title = {Recommender systems under {European} {AI} regulations},
	volume = {65},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3512728},
	doi = {10.1145/3512728},
	language = {en},
	number = {4},
	urldate = {2022-10-17},
	journal = {Communications of the ACM},
	author = {Di Noia, Tommaso and Tintarev, Nava and Fatourou, Panagiota and Schedl, Markus},
	month = apr,
	year = {2022},
	pages = {69--73},
}

@article{DecisionBoundaryVisualizationCounterfactualReasoning,
	title = {Decision {Boundary} {Visualization} for {Counterfactual} {Reasoning}},
	volume = {n/a},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14650},
	doi = {10.1111/cgf.14650},
	abstract = {Machine learning algorithms are widely applied to create powerful prediction models. With increasingly complex models, humans' ability to understand the decision function (that maps from a high-dimensional input space) is quickly exceeded. To explain a model's decisions, black-box methods have been proposed that provide either non-linear maps of the global topology of the decision boundary, or samples that allow approximating it locally. The former loses information about distances in input space, while the latter only provides statements about given samples, but lacks a focus on the underlying model for precise ‘What-If'-reasoning. In this paper, we integrate both approaches and propose an interactive exploration method using local linear maps of the decision space. We create the maps on high-dimensional hyperplanes—2D-slices of the high-dimensional parameter space—based on statistical and personal feature mutability and guided by feature importance. We complement the proposed workflow with established model inspection techniques to provide orientation and guidance. We demonstrate our approach on real-world datasets and illustrate that it allows identification of instance-based decision boundary structures and can answer multi-dimensional ‘What-If'-questions, thereby identifying counterfactual scenarios visually.},
	language = {en},
	number = {n/a},
	urldate = {2022-10-18},
	journal = {Computer Graphics Forum},
	author = {Sohns, Jan-Tobias and Garth, Christoph and Leitte, Heike},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14650},
	keywords = {counterfactual, inverse multi-dimensional projection, machine learning explanation, vis, visual model evaluation},
}

@inproceedings{SilvaInteractivelyAssessingMachineLearning,
	address = {Honolulu HI USA},
	title = {Silva: {Interactively} {Assessing} {Machine} {Learning} {Fairness} {Using} {Causality}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {Silva},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376447},
	doi = {10.1145/3313831.3376447},
	abstract = {Machine learning models risk encoding unfairness on the part of their developers or data sources. However, assessing fairness is challenging as analysts might misidentify sources of bias, fail to notice them, or misapply metrics. In this paper we introduce Silva, a system for exploring potential sources of unfairness in datasets or machine learning models interactively. Silva directs user attention to relationships between attributes through a global causal view, provides interactive recommendations, presents intermediate results, and visualizes metrics. We describe the implementation of Silva, identify salient design and technical challenges, and provide an evaluation of the tool in comparison to an existing fairness optimization tool.},
	language = {en},
	urldate = {2022-10-18},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yan, Jing Nathan and Gu, Ziwei and Lin, Hubert and Rzeszotarski, Jeffrey M.},
	month = apr,
	year = {2020},
	pages = {1--13},
}

@article{CausalFairnessFieldGuidePerspectives,
	title = {The {Causal} {Fairness} {Field} {Guide}: {Perspectives} {From} {Social} and {Formal} {Sciences}},
	volume = {5},
	issn = {2624-909X},
	shorttitle = {The {Causal} {Fairness} {Field} {Guide}},
	url = {https://www.frontiersin.org/articles/10.3389/fdata.2022.892837/full},
	doi = {10.3389/fdata.2022.892837},
	abstract = {Over the past several years, multiple different methods to measure the causal fairness of machine learning models have been proposed. However, despite the growing number of publications and implementations, there is still a critical lack of literature that explains the interplay of causality-based fairness notions with the social sciences of philosophy, sociology, and law. We hope to remedy this issue by accumulating and expounding upon the thoughts and discussions of causality-based fairness notions produced by both social and formal (speciﬁcally machine learning) sciences in this ﬁeld guide. In addition to giving the mathematical backgrounds of several popular causality-based fair machine learning notions, we explain their connection to and interplay with the ﬁelds of philosophy and law. Further, we explore several criticisms of the current approaches to causality-based fair machine learning from a sociological viewpoint as well as from a technical standpoint. It is our hope that this ﬁeld guide will help fair machine learning practitioners better understand how their causality-based fairness notions align with important humanistic values (such as fairness) and how we can, as a ﬁeld, design methods and metrics to better serve oppressed and marginalized populaces.},
	language = {en},
	urldate = {2022-10-18},
	journal = {Frontiers in Big Data},
	author = {Carey, Alycia N. and Wu, Xintao},
	month = apr,
	year = {2022},
	pages = {892837},
}

@inproceedings{NeoGeneralizingConfusionMatrixVisualization,
	title = {Neo: {Generalizing} {Confusion} {Matrix} {Visualization} to {Hierarchical} and {Multi}-{Output} {Labels}},
	shorttitle = {Neo},
	url = {http://arxiv.org/abs/2110.12536},
	doi = {10.1145/3491102.3501823},
	abstract = {The confusion matrix, a ubiquitous visualization for helping people evaluate machine learning models, is a tabular layout that compares predicted class labels against actual class labels over all data instances. We conduct formative research with machine learning practitioners at Apple and find that conventional confusion matrices do not support more complex data-structures found in modern-day applications, such as hierarchical and multi-output labels. To express such variations of confusion matrices, we design an algebra that models confusion matrices as probability distributions. Based on this algebra, we develop Neo, a visual analytics system that enables practitioners to flexibly author and interact with hierarchical and multi-output confusion matrices, visualize derived metrics, renormalize confusions, and share matrix specifications. Finally, we demonstrate Neo's utility with three model evaluation scenarios that help people better understand model performance and reveal hidden confusions.},
	urldate = {2022-10-20},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	author = {Görtler, Jochen and Hohman, Fred and Moritz, Dominik and Wongsuphasawat, Kanit and Ren, Donghao and Nair, Rahul and Kirchner, Marc and Patel, Kayur},
	month = apr,
	year = {2022},
	note = {arXiv:2110.12536 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, H.2.m, I.7.m, hci, vis},
	pages = {1--13},
}

@article{DBIASCausalityBasedHumanintheLoopSystemTackling,
	title = {D-{BIAS}: {A} {Causality}-{Based} {Human}-in-the-{Loop} {System} for {Tackling} {Algorithmic} {Bias}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {D-{BIAS}},
	url = {https://ieeexplore.ieee.org/document/9903601/},
	doi = {10.1109/TVCG.2022.3209484},
	abstract = {With the rise of AI, algorithms have become better at learning underlying patterns from the training data including ingrained social biases based on gender, race, etc. Deployment of such algorithms to domains such as hiring, healthcare, law enforcement, etc. has raised serious concerns about fairness, accountability, trust and interpretability in machine learning algorithms. To alleviate this problem, we propose D-BIAS, a visual interactive tool that embodies human-in-the-loop AI approach for auditing and mitigating social biases from tabular datasets. It uses a graphical causal model to represent causal relationships among different features in the dataset and as a medium to inject domain knowledge. A user can detect the presence of bias against a group, say females, or a subgroup, say black females, by identifying unfair causal relationships in the causal network and using an array of fairness metrics. Thereafter, the user can mitigate bias by reﬁning the causal model and acting on the unfair causal edges. For each interaction, say weakening/deleting a biased causal edge, the system uses a novel method to simulate a new (debiased) dataset based on the current causal model while ensuring a minimal change from the original dataset. Users can visually assess the impact of their interactions on different fairness metrics, utility metrics, data distortion, and the underlying data distribution. Once satisﬁed, they can download the debiased dataset and use it for any downstream application for fairer predictions. We evaluate D-BIAS by conducting experiments on 3 datasets and also a formal user study. We found that D-BIAS helps reduce bias signiﬁcantly compared to the baseline debiasing approach across different fairness metrics while incurring little data distortion and a small loss in utility. Moreover, our human-in-the-loop based approach signiﬁcantly outperforms an automated approach on trust, interpretability and accountability.},
	language = {en},
	urldate = {2022-10-19},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ghai, Bhavya and Mueller, Klaus},
	year = {2022},
	keywords = {causal, counterfactual, fair, hci, vis},
	pages = {1--10},
}

@article{OutcomeExplorerCausalityGuidedInteractiveVisual,
	title = {Outcome-{Explorer}: {A} {Causality} {Guided} {Interactive} {Visual} {Interface} for {Interpretable} {Algorithmic} {Decision} {Making}},
	issn = {1941-0506},
	shorttitle = {Outcome-{Explorer}},
	doi = {10.1109/TVCG.2021.3102051},
	abstract = {The widespread adoption of algorithmic decision-making systems has brought about the necessity to interpret the reasoning behind these decisions. The majority of these systems are complex black box models, and auxiliary models are often used to approximate and then explain their behavior. However, recent research suggests that such explanations are not overly accessible to lay users with no specific expertise in machine learning and this can lead to an incorrect interpretation of the underlying model. In this paper, we show that a predictive and interactive model based on causality is inherently interpretable, does not require any auxiliary model, and allows both expert and non-expert users to understand the model comprehensively. To demonstrate our method we developed Outcome Explorer, a causality guided interactive interface, and evaluated it by conducting think-aloud sessions with three expert users and a user study with 18 non-expert users. All three expert users found our tool to be comprehensive in supporting their explanation needs while the non-expert users were able to understand the inner workings of a model easily.},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Hoque, Md Naimul and Mueller, Klaus},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Biological system modeling, Causality, Computational modeling, Data models, Decision making, Explainable AI, Human-Computer Interaction, Machine learning, Predictive models, Tools, Visual Analytics},
	pages = {1--1},
}

@article{ShapEnhancedCounterfactualExplanationsRecommendations,
	title = {Shap-{Enhanced} {Counterfactual} {Explanations} for {Recommendations}},
	abstract = {Explanations in recommender systems help users better understand why a recommendation (or a list of recommendations) is generated. Explaining recommendations has become an important requirement for enhancing users’ trust and satisfaction. However, explanation methods vary across different recommender models, increasing engineering costs. As recommender systems become ever more inscrutable, directly explaining recommender systems sometimes becomes impossible. Post-hoc explanation methods that do not elucidate internal mechanisms of recommender systems are popular approaches. State-of-art post-hoc explanation methods such as SHAP can generate explanations by building simpler surrogate models to approximate the original models. However, directly applying such methods has several concerns. First of all, post-hoc explanations may not be faithful to the original recommender systems since the internal mechanisms of recommender systems are not elucidated. Another concern is that the outputs returned by methods such as SHAP are not trivial for plain users to understand since background mathematical knowledge is required. In this work, we present an explanation method enhanced by SHAP that can generate easily understandable explanations with high fidelity.},
	language = {en},
	author = {Zhong, Jinfeng and Negre, Elsa},
	year = {2022},
	pages = {8},
}

@article{CounterfactualShapleyAdditiveExplanations,
	title = {Counterfactual {Shapley} {Additive} {Explanations}},
	abstract = {Feature attributions are a common paradigm for model explanations due to their simplicity in assigning a single numeric score for each input feature to a model. In the actionable recourse setting, wherein the goal of the explanations is to improve outcomes for model consumers, it is often unclear how feature attributions should be correctly used. With this work, we aim to strengthen and clarify the link between actionable recourse and feature attributions. Concretely, we propose a variant of SHAP, Counterfactual SHAP (CFSHAP), that incorporates counterfactual information to produce a background dataset for use within the marginal (a.k.a. interventional) Shapley value framework. We motivate the need within the actionable recourse setting for careful consideration of background datasets when using Shapley values for feature attributions with numerous synthetic examples. Moreover, we demonstrate the efficacy of CF-SHAP by proposing and justifying a quantitative score for feature attributions, counterfactual-ability, showing that as measured by this metric, CF-SHAP is superior to existing methods when evaluated on public datasets using tree ensembles.},
	language = {en},
	author = {Albini, Emanuele and Long, Jason and Dervovic, Danial and Magazzeni, Daniele},
	year = {2022},
	pages = {17},
}

@inproceedings{CounterfactualShapleyAdditiveExplanationsa,
	address = {Seoul Republic of Korea},
	title = {Counterfactual {Shapley} {Additive} {Explanations}},
	isbn = {978-1-4503-9352-2},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533168},
	doi = {10.1145/3531146.3533168},
	abstract = {Feature attributions are a common paradigm for model explanations due to their simplicity in assigning a single numeric score for each input feature to a model. In the actionable recourse setting, wherein the goal of the explanations is to improve outcomes for model consumers, it is often unclear how feature attributions should be correctly used. With this work, we aim to strengthen and clarify the link between actionable recourse and feature attributions. Concretely, we propose a variant of SHAP, Counterfactual SHAP (CFSHAP), that incorporates counterfactual information to produce a background dataset for use within the marginal (a.k.a. interventional) Shapley value framework. We motivate the need within the actionable recourse setting for careful consideration of background datasets when using Shapley values for feature attributions with numerous synthetic examples. Moreover, we demonstrate the efficacy of CF-SHAP by proposing and justifying a quantitative score for feature attributions, counterfactual-ability, showing that as measured by this metric, CF-SHAP is superior to existing methods when evaluated on public datasets using tree ensembles.},
	language = {en},
	urldate = {2022-10-27},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Albini, Emanuele and Long, Jason and Dervovic, Danial and Magazzeni, Daniele},
	month = jun,
	year = {2022},
	pages = {1054--1070},
}

@inproceedings{Shapenhancedcounterfactualexplanationsrecommendations,
	address = {Virtual Event},
	title = {Shap-enhanced counterfactual explanations for recommendations},
	isbn = {978-1-4503-8713-2},
	url = {https://dl.acm.org/doi/10.1145/3477314.3507029},
	doi = {10.1145/3477314.3507029},
	abstract = {Explanations in recommender systems help users better understand why a recommendation (or a list of recommendations) is generated. Explaining recommendations has become an important requirement for enhancing users’ trust and satisfaction. However, explanation methods vary across different recommender models, increasing engineering costs. As recommender systems become ever more inscrutable, directly explaining recommender systems sometimes becomes impossible. Post-hoc explanation methods that do not elucidate internal mechanisms of recommender systems are popular approaches. State-of-art post-hoc explanation methods such as SHAP can generate explanations by building simpler surrogate models to approximate the original models. However, directly applying such methods has several concerns. First of all, post-hoc explanations may not be faithful to the original recommender systems since the internal mechanisms of recommender systems are not elucidated. Another concern is that the outputs returned by methods such as SHAP are not trivial for plain users to understand since background mathematical knowledge is required. In this work, we present an explanation method enhanced by SHAP that can generate easily understandable explanations with high fidelity.},
	language = {en},
	urldate = {2022-10-26},
	booktitle = {Proceedings of the 37th {ACM}/{SIGAPP} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Zhong, Jinfeng and Negre, Elsa},
	month = apr,
	year = {2022},
	pages = {1365--1372},
}

@article{VisualConceptProgrammingVisualAnalytics,
	title = {Visual {Concept} {Programming}: {A} {Visual} {Analytics} {Approach} to {Injecting} {Human} {Intelligence} {At} {Scale}},
	issn = {1941-0506},
	shorttitle = {Visual {Concept} {Programming}},
	doi = {10.1109/TVCG.2022.3209466},
	abstract = {Data-centric AI has emerged as a new research area to systematically engineer the data to land AI models for real-world applications. As a core method for data-centric AI, data programming helps experts inject domain knowledge into data and label data at scale using carefully designed labeling functions (e.g., heuristic rules, logistics). Though data programming has shown great success in the NLP domain, it is challenging to program image data because of a) the challenge to describe images using visual vocabulary without human annotations and b) lacking efficient tools for data programming of images. We present Visual Concept Programming, a first-of-its-kind visual analytics approach of using visual concepts to program image data at scale while requiring a few human efforts. Our approach is built upon three unique components. It first uses a self-supervised learning approach to learn visual representation at the pixel level and extract a dictionary of visual concepts from images without using any human annotations. The visual concepts serve as building blocks of labeling functions for experts to inject their domain knowledge. We then design interactive visualizations to explore and understand visual concepts and compose labeling functions with concepts without writing code. Finally, with the composed labeling functions, users can label the image data at scale and use the labeled data to refine the pixel-wise visual representation and concept quality. We evaluate the learned pixel-wise visual representation for the downstream task of semantic segmentation to show the effectiveness and usefulness of our approach. In addition, we demonstrate how our approach tackles real-world problems of image retrieval for autonomous driving.},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Hoque, Md Naimul and He, Wenbin and Shekar, Arvind Kumar and Gou, Liang and Ren, Liu},
	year = {2022},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Artificial intelligence, Data models, Labeling, Programming, Task analysis, Visual analytics, Visual concept programming, Visualization, concept, data programming, data-centric AI, image, self-supervised learning, semantic segmentation, vis},
	pages = {1--10},
}

@article{Artificialintelligencemasspersonalizationcommunication,
	title = {Artificial intelligence and mass personalization of communication content—{An} ethical and literacy perspective},
	volume = {24},
	issn = {1461-4448, 1461-7315},
	url = {http://journals.sagepub.com/doi/10.1177/14614448211022702},
	doi = {10.1177/14614448211022702},
	abstract = {Artificial intelligence (AI) is (re)shaping communication and contributes to (commercial and informational) need satisfaction by means of mass personalization. However, the substantial personalization and targeting opportunities do not come without ethical challenges. Following an AI-for-social-good perspective, the authors systematically scrutinize the ethical challenges of deploying AI for mass personalization of communication content from a multi-stakeholder perspective. The conceptual analysis reveals interdependencies and tensions between ethical principles, which advocate the need of a basic understanding of AI inputs, functioning, agency, and outcomes. By this form of AI literacy, individuals could be empowered to interact with and treat masspersonalized content in a way that promotes individual and social good while preventing harm.},
	language = {en},
	number = {5},
	urldate = {2022-11-12},
	journal = {New Media \& Society},
	author = {Hermann, Erik},
	month = may,
	year = {2022},
	pages = {1258--1277},
}

@inproceedings{AlgorithmicRecourseCounterfactualExplanationsInterventions,
	address = {Virtual Event Canada},
	title = {Algorithmic {Recourse}: from {Counterfactual} {Explanations} to {Interventions}},
	isbn = {978-1-4503-8309-7},
	shorttitle = {Algorithmic {Recourse}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445899},
	doi = {10.1145/3442188.3445899},
	abstract = {As machine learning is increasingly used to inform consequential decision-making (e.g., pre-trial bail and loan approval), it becomes important to explain how the system arrived at its decision, and also suggest actions to achieve a favorable decision. Counterfactual explanations –“how the world would have (had) to be different for a desirable outcome to occur”– aim to satisfy these criteria. Existing works have primarily focused on designing algorithms to obtain counterfactual explanations for a wide range of settings. However, it has largely been overlooked that ultimately, one of the main objectives is to allow people to act rather than just understand. In layman’s terms, counterfactual explanations inform an individual where they need to get to, but not how to get there. In this work, we rely on causal reasoning to caution against the use of counterfactual explanations as a recommendable set of actions for recourse. Instead, we propose a shift of paradigm from recourse via nearest counterfactual explanations to recourse through minimal interventions, shifting the focus from explanations to interventions.},
	language = {en},
	urldate = {2022-11-08},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Karimi, Amir-Hossein and Schölkopf, Bernhard and Valera, Isabel},
	month = mar,
	year = {2021},
	pages = {353--362},
}

@inproceedings{Explainingmachinelearningclassifiersdiverse,
	address = {Barcelona Spain},
	title = {Explaining machine learning classifiers through diverse counterfactual explanations},
	isbn = {978-1-4503-6936-7},
	url = {https://dl.acm.org/doi/10.1145/3351095.3372850},
	doi = {10.1145/3351095.3372850},
	abstract = {Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at https://github.com/microsoft/DiCE.},
	language = {en},
	urldate = {2022-10-30},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
	month = jan,
	year = {2020},
	pages = {607--617},
}

@inproceedings{ActionableRecourseLinearClassification,
	address = {Atlanta GA USA},
	title = {Actionable {Recourse} in {Linear} {Classification}},
	isbn = {978-1-4503-6125-5},
	url = {https://dl.acm.org/doi/10.1145/3287560.3287566},
	doi = {10.1145/3287560.3287566},
	abstract = {Classi�cation models are often used to make decisions that a�ect humans: whether to approve a loan application, extend a job o�er, or provide insurance. In such applications, individuals should have the ability to change the decision of the model. When a person is denied a loan by a credit scoring model, for example, they should be able to change the input variables of the model in a way that will guarantee approval. Otherwise, this person will be denied the loan so long as the model is deployed, and – more importantly –will lack agency over a decision that a�ects their livelihood.},
	language = {en},
	urldate = {2022-10-27},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Ustun, Berk and Spangher, Alexander and Liu, Yang},
	month = jan,
	year = {2019},
	keywords = {counterfactual, fatml},
	pages = {10--19},
}

@article{SurveyContrastiveCounterfactualExplanationGeneration,
	title = {A {Survey} of {Contrastive} and {Counterfactual} {Explanation} {Generation} {Methods} for {Explainable} {Artificial} {Intelligence}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9321372/},
	doi = {10.1109/ACCESS.2021.3051315},
	abstract = {A number of algorithms in the ﬁeld of artiﬁcial intelligence offer poorly interpretable decisions. To disclose the reasoning behind such algorithms, their output can be explained by means of so-called evidence-based (or factual) explanations. Alternatively, contrastive and counterfactual explanations justify why the output of the algorithms is not any different and how it could be changed, respectively. It is of crucial importance to bridge the gap between theoretical approaches to contrastive and counterfactual explanation and the corresponding computational frameworks. In this work we conduct a systematic literature review which provides readers with a thorough and reproducible analysis of the interdisciplinary research ﬁeld under study. We ﬁrst examine theoretical foundations of contrastive and counterfactual accounts of explanation. Then, we report the state-of-the-art computational frameworks for contrastive and counterfactual explanation generation. In addition, we analyze how grounded such frameworks are on the insights from the inspected theoretical approaches. As a result, we highlight a variety of properties of the approaches under study and reveal a number of shortcomings thereof. Moreover, we deﬁne a taxonomy regarding both theoretical and practical approaches to contrastive and counterfactual explanation.},
	language = {en},
	urldate = {2022-10-27},
	journal = {IEEE Access},
	author = {Stepin, Ilia and Alonso, Jose M. and Catala, Alejandro and Pereira-Farina, Martin},
	year = {2021},
	pages = {11974--12001},
}

@inproceedings{SpotlightGeneralMethodDiscoveringSystematica,
	address = {Seoul Republic of Korea},
	title = {The {Spotlight}: {A} {General} {Method} for {Discovering} {Systematic} {Errors} in {Deep} {Learning} {Models}},
	isbn = {978-1-4503-9352-2},
	shorttitle = {The {Spotlight}},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533240},
	doi = {10.1145/3531146.3533240},
	abstract = {Supervised learning models often make systematic errors on rare subsets of the data. When these subsets correspond to explicit labels in the data (e.g., gender, race) such poor performance can be identified straightforwardly. This paper introduces a method for discovering systematic errors that do not correspond to such explicitly labelled subgroups. The key idea is that similar inputs tend to have similar representations in the final hidden layer of a neural network. We leverage this structure by “shining a spotlight” on this representation space to find contiguous regions in which the model performs poorly. We show that the Spotlight surfaces semantically meaningful areas of weakness in a wide variety of existing models spanning computer vision, NLP, and recommender systems, and we verify its performance through quantitative experiments.},
	language = {en},
	urldate = {2022-11-14},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {d'Eon, Greg and d'Eon, Jason and Wright, James R. and Leyton-Brown, Kevin},
	month = jun,
	year = {2022},
	pages = {1962--1981},
}

@inproceedings{PuttingUsersControltheirRecommendations,
	address = {Vienna Austria},
	title = {Putting {Users} in {Control} of their {Recommendations}},
	isbn = {978-1-4503-3692-5},
	url = {https://dl.acm.org/doi/10.1145/2792838.2800179},
	doi = {10.1145/2792838.2800179},
	abstract = {The essence of a recommender system is that it can recommend items personalized to the preferences of an individual user. But typically users are given no explicit control over this personalization, and are instead left guessing about how their actions a↵ect the resulting recommendations. We hypothesize that any recommender algorithm will better ﬁt some users’ expectations than others, leaving opportunities for improvement. To address this challenge, we study a recommender that puts some control in the hands of users. Speciﬁcally, we build and evaluate a system that incorporates user-tuned popularity and recency modiﬁers, allowing users to express concepts like “show more popular items”. We ﬁnd that users who are given these controls evaluate the resulting recommendations much more positively. Further, we ﬁnd that users diverge in their preferred settings, conﬁrming the importance of giving control to users.},
	language = {en},
	urldate = {2022-11-13},
	booktitle = {Proceedings of the 9th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Harper, F. Maxwell and Xu, Funing and Kaur, Harmanpreet and Condiff, Kyle and Chang, Shuo and Terveen, Loren},
	month = sep,
	year = {2015},
	pages = {3--10},
}

@inproceedings{Recommendationsuseragencyreachabilitycollaborativelyfiltered,
	address = {Barcelona Spain},
	title = {Recommendations and user agency: the reachability of collaboratively-filtered information},
	isbn = {978-1-4503-6936-7},
	shorttitle = {Recommendations and user agency},
	url = {https://dl.acm.org/doi/10.1145/3351095.3372866},
	doi = {10.1145/3351095.3372866},
	abstract = {Recommender systems often rely on models which are trained to maximize accuracy in predicting user preferences. When the systems are deployed, these models determine the availability of content and information to different users. The gap between these objectives gives rise to a potential for unintended consequences, contributing to phenomena such as filter bubbles and polarization. In this work, we consider directly the information availability problem through the lens of user recourse. Using ideas of reachability, we propose a computationally efficient audit for top-N linear recommender models. Furthermore, we describe the relationship between model complexity and the effort necessary for users to exert control over their recommendations. We use this insight to provide a novel perspective on the user cold-start problem. Finally, we demonstrate these concepts with an empirical investigation of a state-of-the-art model trained on a widely used movie ratings dataset.},
	language = {en},
	urldate = {2022-11-13},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Dean, Sarah and Rich, Sarah and Recht, Benjamin},
	month = jan,
	year = {2020},
	pages = {436--445},
}

@inproceedings{FairnessTransparencyRecommendationUsersPerspective,
	address = {Utrecht Netherlands},
	title = {Fairness and {Transparency} in {Recommendation}: {The} {Users}’ {Perspective}},
	isbn = {978-1-4503-8366-0},
	shorttitle = {Fairness and {Transparency} in {Recommendation}},
	url = {https://dl.acm.org/doi/10.1145/3450613.3456835},
	doi = {10.1145/3450613.3456835},
	abstract = {Though recommender systems are defined by personalization, recent work has shown the importance of additional, beyond-accuracy objectives, such as fairness. Because users often expect their recommendations to be purely personalized, these new algorithmic objectives must be communicated transparently in a fairness-aware recommender system. While explanation has a long history in recommender systems research, there has been little work that attempts to explain systems that use a fairness objective. Even though the previous work in other branches of AI has explored the use of explanations as a tool to increase fairness, this work has not been focused on recommendation. Here, we consider user perspectives of fairness-aware recommender systems and techniques for enhancing their transparency. We describe the results of an exploratory interview study that investigates user perceptions of fairness, recommender systems, and fairness-aware objectives. We propose three features – informed by the needs of our participants – that could improve user understanding of and trust in fairness-aware recommender systems.},
	language = {en},
	urldate = {2022-11-12},
	booktitle = {Proceedings of the 29th {ACM} {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Sonboli, Nasim and Smith, Jessie J. and Cabral Berenfus, Florencia and Burke, Robin and Fiesler, Casey},
	month = jun,
	year = {2021},
	pages = {274--279},
}

@article{VisualAnalysisDiscriminationMachineLearning,
	title = {Visual {Analysis} of {Discrimination} in {Machine} {Learning}},
	volume = {27},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2020.3030471},
	abstract = {The growing use of automated decision-making in critical applications, such as crime prediction and college admission, has raised questions about fairness in machine learning. How can we decide whether different treatments are reasonable or discriminatory? In this paper, we investigate discrimination in machine learning from a visual analytics perspective and propose an interactive visualization tool, DiscriLens, to support a more comprehensive analysis. To reveal detailed information on algorithmic discrimination, DiscriLens identifies a collection of potentially discriminatory itemsets based on causal modeling and classification rules mining. By combining an extended Euler diagram with a matrix-based visualization, we develop a novel set visualization to facilitate the exploration and interpretation of discriminatory itemsets. A user study shows that users can interpret the visually encoded information in DiscriLens quickly and accurately. Use cases demonstrate that DiscriLens provides informative guidance in understanding and reducing algorithmic discrimination.},
	number = {2},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wang, Qianwen and Xu, Zhenhua and Chen, Zhutian and Wang, Yong and Liu, Shixia and Qu, Huamin},
	month = feb,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {Data Visualization, Data models, Data visualization, Discrimination, Itemsets, Machine Learning, Machine learning, Predictive models, Tools, Visualization, fair, vis},
	pages = {1470--1480},
}

@article{OvercomingBlindSpotsRealWorld,
	title = {Overcoming {Blind} {Spots} in the {Real} {World}: {Leveraging} {Complementary} {Abilities} for {Joint} {Execution}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Overcoming {Blind} {Spots} in the {Real} {World}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/4571},
	doi = {10.1609/aaai.v33i01.33016137},
	abstract = {Simulators are being increasingly used to train agents before deploying them in real-world environments. While training in simulation provides a cost-effective way to learn, poorly modeled aspects of the simulator can lead to costly mistakes, or blind spots. While humans can help guide an agent towards identifying these error regions, humans themselves have blind spots and noise in execution. We study how learning about blind spots of both can be used to manage hand-off decisions when humans and agents jointly act in the real-world in which neither of them are trained or evaluated fully. The formulation assumes that agent blind spots result from representational limitations in the simulation world, which leads the agent to ignore important features that are relevant for acting in the open world. Our approach for blind spot discovery combines experiences collected in simulation with limited human demonstrations. The ﬁrst step applies imitation learning to demonstration data to identify important features that the human is using but that the agent is missing. The second step uses noisy labels extracted from action mismatches between the agent and the human across simulation and demonstration data to train blind spot models. We show through experiments on two domains that our approach is able to learn a succinct representation that accurately captures blind spot regions and avoids dangerous errors in the real world through transfer of control between the agent and the human.},
	language = {en},
	number = {01},
	urldate = {2022-11-29},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Ramakrishnan, Ramya and Kamar, Ece and Nushi, Besmira and Dey, Debadeepta and Shah, Julie and Horvitz, Eric},
	month = jul,
	year = {2019},
	keywords = {uu},
	pages = {6137--6145},
}

@inproceedings{ContextualizationExplorationLocalFeatureImportance,
	address = {Helsinki Finland},
	title = {Contextualization and {Exploration} of {Local} {Feature} {Importance} {Explanations} to {Improve} {Understanding} and {Satisfaction} of {Non}-{Expert} {Users}},
	isbn = {978-1-4503-9144-3},
	url = {https://dl.acm.org/doi/10.1145/3490099.3511139},
	doi = {10.1145/3490099.3511139},
	abstract = {The increasing usage of complex Machine Learning models for decision-making has raised interest in explainable artificial intelligence (XAI). In this work, we focus on the effects of providing accessible and useful explanations to non-expert users. More specifically, we propose generic XAI design principles for contextualizing and allowing the exploration of explanations based on local feature importance. To evaluate the effectiveness of these principles for improving users’ objective understanding and satisfaction, we conduct a controlled user study with 80 participants using 4 different versions of our XAI system, in the context of an insurance scenario. Our results show that the contextualization principles we propose significantly improve user’s satisfaction and is close to have a significant impact on user’s objective understanding. They also show that the exploration principles we propose improve user’s satisfaction. On the other hand, the interaction of these principles does not appear to bring improvement on both dimensions of users’ understanding.},
	language = {en},
	urldate = {2022-11-30},
	booktitle = {27th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Bove, Clara and Aigrain, Jonathan and Lesot, Marie-Jeanne and Tijus, Charles and Detyniecki, Marcin},
	month = mar,
	year = {2022},
	keywords = {explanation},
	pages = {807--819},
}

@article{RuleMatrixVisualizingUnderstandingClassifiersa,
	title = {{RuleMatrix}: {Visualizing} and {Understanding} {Classifiers} with {Rules}},
	shorttitle = {{RuleMatrix}},
	url = {http://arxiv.org/abs/1807.06228},
	abstract = {With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. We design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.},
	language = {en},
	urldate = {2018-11-25},
	journal = {arXiv:1807.06228 [cs, stat]},
	author = {Ming, Yao and Qu, Huamin and Bertini, Enrico},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.06228},
	keywords = {ESCAPE, eval, fatml, vis},
}

@article{VisualizingSurrogateDecisionTrees,
	title = {Visualizing surrogate decision trees of convolutional neural networks},
	issn = {1343-8875, 1875-8975},
	url = {http://link.springer.com/10.1007/s12650-019-00607-z},
	doi = {10.1007/s12650-019-00607-z},
	abstract = {Interpreting the decision-making of black boxes in machine learning becomes urgent nowadays due to their lack of transparency. One effective way to interpret these models is to transform them into interpretable surrogate models such as decision trees and rule lists. Compared with other methods that open the black boxes, rule extraction is a universal method which can theoretically extend to any black boxes. However, in practice, it is not appropriate for deep learning models such as convolutional neural networks (CNNs), since the extracted rules or decision trees are too large to interpret and the rules are not at the semantic level. These two drawbacks limit the usability of rule extraction for deep learning models. In this paper, we adopt a new strategy to solve the problem. We ﬁrst decompose a CNN into a feature extractor and a classiﬁer. Then extract the decision tree only from the classiﬁer. Then, we leverage lots of segmented labeled images to learn the concepts of each feature. This method can extract human-readable decision trees from CNNs. Finally, we build CNN2DT, a visual analysis system to enable users to explore the surrogate decision trees. Use cases show that CNN2DT provides global and local interpretations of the CNN decision process. Besides, users can easily ﬁnd the misclassiﬁcation reasons for single images and the discriminating capacity of different models. A user study has demonstrated the effectiveness of CNN2DT on AlexNet and VGG16 for image classiﬁcation.},
	language = {en},
	urldate = {2019-12-28},
	journal = {Journal of Visualization},
	author = {Jia, Shichao and Lin, Peiwen and Li, Zeyu and Zhang, Jiawan and Liu, Shixia},
	month = nov,
	year = {2019},
	keywords = {ESCAPE, rw-uu-vis-ml, vis},
}

@article{DeepVIDDeepVisualInterpretation,
	title = {{DeepVID}: {Deep} {Visual} {Interpretation} and {Diagnosis} for {Image} {Classifiers} via {Knowledge} {Distillation}},
	volume = {25},
	issn = {1941-0506},
	shorttitle = {{DeepVID}},
	doi = {10.1109/TVCG.2019.2903943},
	abstract = {Deep Neural Networks (DNNs) have been extensively used in multiple disciplines due to their superior performance. However, in most cases, DNNs are considered as black-boxes and the interpretation of their internal working mechanism is usually challenging. Given that model trust is often built on the understanding of how a model works, the interpretation of DNNs becomes more important, especially in safety-critical applications (e.g., medical diagnosis, autonomous driving). In this paper, we propose DeepVID, a Deep learning approach to Visually Interpret and Diagnose DNN models, especially image classifiers. In detail, we train a small locally-faithful model to mimic the behavior of an original cumbersome DNN around a particular data instance of interest, and the local model is sufficiently simple such that it can be visually interpreted (e.g., a linear model). Knowledge distillation is used to transfer the knowledge from the cumbersome DNN to the small model, and a deep generative model (i.e., variational auto-encoder) is used to generate neighbors around the instance of interest. Those neighbors, which come with small feature variances and semantic meanings, can effectively probe the DNN's behaviors around the interested instance and help the small model to learn those behaviors. Through comprehensive evaluations, as well as case studies conducted together with deep learning experts, we validate the effectiveness of DeepVID.},
	number = {6},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wang, Junpeng and Gou, Liang and Zhang, Wei and Yang, Hao and Shen, Han-Wei},
	month = jun,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {ESCAPE, dl, rw-uu-vis-ml, vis},
	pages = {2168--2180},
}

@inproceedings{ShapeShopUnderstandingDeepLearning,
	address = {Denver, Colorado, USA},
	title = {{ShapeShop}: {Towards} {Understanding} {Deep} {Learning} {Representations} via {Interactive} {Experimentation}},
	isbn = {978-1-4503-4656-6},
	shorttitle = {{ShapeShop}},
	url = {http://dl.acm.org/citation.cfm?doid=3027063.3053103},
	doi = {10.1145/3027063.3053103},
	abstract = {Deep learning is the driving force behind many recent technologies; however, deep neural networks are often viewed as “black-boxes” due to their internal complexity that is hard to understand. Little research focuses on helping people explore and understand the relationship between a user’s data and the learned representations in deep learning models. We present our ongoing work, ShapeShop, an interactive system for visualizing and understanding what semantics a neural network model has learned. Built using standard web technologies, ShapeShop allows users to experiment with and compare deep learning models to help explore the robustness of image classiﬁers.},
	language = {en},
	urldate = {2020-06-15},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}  - {CHI} {EA} '17},
	publisher = {ACM Press},
	author = {Hohman, Fred and Hodas, Nathan and Chau, Duen Horng},
	year = {2017},
	keywords = {ESCAPE, dl, rw-uu-vis-ml, vis},
	pages = {1694--1699},
}

@article{DeepEyesProgressiveVisualAnalytics,
	title = {{DeepEyes}: {Progressive} {Visual} {Analytics} for {Designing} {Deep} {Neural} {Networks}},
	volume = {24},
	issn = {1077-2626},
	shorttitle = {{DeepEyes}},
	url = {http://ieeexplore.ieee.org/document/8019872/},
	doi = {10.1109/TVCG.2017.2744358},
	abstract = {Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classiﬁers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of ﬁlters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identiﬁcation of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identiﬁcation of problems, such as superﬂuous ﬁlters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems.},
	language = {en},
	number = {1},
	urldate = {2020-06-18},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Pezzotti, Nicola and Hollt, Thomas and Van Gemert, Jan and Lelieveldt, Boudewijn P.F. and Eisemann, Elmar and Vilanova, Anna},
	month = jan,
	year = {2018},
	keywords = {ESCAPE, dl, elir, fatml, rw-uu-vis-ml, vis, xai},
	pages = {98--108},
}

@article{ManifoldModelAgnosticFrameworkInterpretation,
	title = {Manifold: {A} {Model}-{Agnostic} {Framework} for {Interpretation} and {Diagnosis} of {Machine} {Learning} {Models}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Manifold},
	url = {http://arxiv.org/abs/1808.00196},
	doi = {10.1109/TVCG.2018.2864499},
	abstract = {Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a speciﬁc model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workﬂow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and reﬁnement (veriﬁcation). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models’ outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classiﬁcation and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied.},
	language = {en},
	number = {1},
	urldate = {2019-06-10},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Zhang, Jiawei and Wang, Yang and Molino, Piero and Li, Lezhi and Ebert, David S.},
	month = jan,
	year = {2019},
	note = {arXiv: 1808.00196},
	keywords = {ESCAPE, fatml, vis},
	pages = {364--373},
}

@article{VisualMethodsAnalyzingProbabilistic,
	title = {Visual {Methods} for {Analyzing} {Probabilistic} {Classification} {Data}},
	volume = {20},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/6875957/},
	doi = {10.1109/TVCG.2014.2346660},
	abstract = {Multi-class classiﬁers often compute scores for the classiﬁcation samples describing probabilities to belong to different classes. In order to improve the performance of such classiﬁers, machine learning experts need to analyze classiﬁcation results for a large number of labeled samples to ﬁnd possible reasons for incorrect classiﬁcation. Confusion matrices are widely used for this purpose. However, they provide no information about classiﬁcation scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classiﬁers. Our methods provide insight into different aspects of the classiﬁcation results for a large number of samples. One visualization emphasizes at which probabilities these samples were classiﬁed and how these probabilities correlate with classiﬁcation error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classiﬁcations. We demonstrate the insight gained using our technique in a benchmarking classiﬁcation dataset, and show how it enables improving classiﬁcation performance by interactively deﬁning and evaluating post-classiﬁcation rules.},
	language = {en},
	number = {12},
	urldate = {2019-12-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Alsallakh, Bilal and Hanbury, Allan and Hauser, Helwig and Miksch, Silvia and Rauber, Andreas},
	month = dec,
	year = {2014},
	keywords = {ESCAPE, vis},
	pages = {1703--1712},
}

@inproceedings{CrowdsourcingBasedHumanintheLoopFramework,
	title = {A {Crowdsourcing} {Based} {Human}-in-the-{Loop} {Framework} for {Denoising} {UUs} in {Relation} {Extraction} {Tasks}},
	doi = {10.1109/IJCNN.2019.8851951},
	abstract = {In relation extraction tasks, distant supervision methods expand dataset by aligning entity pairs in different knowledge bases and completing the relations between two entities. However, these methods ignore the fact that sentences labels generated by distant supervision methods with high confidence are often incorrect in the real world called Unknown Unknowns (UUs). To deal with this challenge, we propose a crowdsourcing based human-in-the-loop denoising framework which iteratively discovers UUs and corrects them by crowdsourcing to better extract relations. During each epoch of iterations, we choose one sentence bag and repeat two steps: Firstly, attention based Long Short-Term Memory network is applied as a selector to discover potential UUs. Secondly, these UUs are annotated by crowdsourcing with two answer collecting strategies and fed back into selector as positive samples. Until the accuracy of selector reaches a threshold, all annotated samples are added into relation classifier as cleaned train set and framework moves on to next epoch with new sentence bags. The experiments on the New York Times dataset and analysis of potential UUs demonstrate that our framework denoise the dataset and outperforms all the baselines on distant supervision relation extraction tasks.},
	booktitle = {2019 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Li, M. and Jin, J. and Wu, W. and Yang, Y. and He, L. and Yang, J.},
	month = jul,
	year = {2019},
	note = {ISSN: 2161-4407},
	keywords = {ESCAPE, fatml, reliable, rw-uu-uu, uu},
	pages = {1--8},
}

@inproceedings{HybridHumanAIWorkflowsUnknown,
	address = {Taipei Taiwan},
	title = {Towards {Hybrid} {Human}-{AI} {Workflows} for {Unknown} {Unknown} {Detection}},
	isbn = {978-1-4503-7023-3},
	url = {https://dl.acm.org/doi/10.1145/3366423.3380306},
	doi = {10.1145/3366423.3380306},
	language = {en},
	urldate = {2020-06-20},
	booktitle = {Proceedings of {The} {Web} {Conference} 2020},
	publisher = {ACM},
	author = {Liu, Anthony and Guerra, Santiago and Fung, Isaac and Matute, Gabriel and Kamar, Ece and Lasecki, Walter},
	month = apr,
	year = {2020},
	keywords = {ESCAPE, rw-uu-uu, uu, well-written},
	pages = {2432--2442},
}

@article{ContradictMachineHybridApproach,
	title = {Contradict the {Machine}: {A} {Hybrid} {Approach} to {Identifying} {Unknown} {Unknowns}},
	abstract = {Machine predictions that are highly confident yet incorrect, i.e. unknown unknowns, are crucial errors to identify, especially in high-stakes settings like medicine or law. We describe a hybrid approach to identifying unknown unknowns that combines the previous algorithmic and crowdsourcing strategies. Our method uses a set of decision rules to approximate how the model makes high confidence predictions. We present the rules to crowd workers, and challenge them to generate instances that contradict the rules. To select the most promising rule to next present to workers, we use a multi-armed bandit algorithm. We evaluate our method by conducting a user study on Amazon Mechanical Turk. Experimental results on three datasets indicate that our approach discovers unknown unknowns more efficiently than state-of-the-art baselines.},
	language = {en},
	author = {Vandenhof, Colin and Law, Edith},
	year = {2019},
	keywords = {ESCAPE, rw-uu-uu, uu},
	pages = {3},
}

@article{TopoActVisuallyExploringShape,
	title = {{TopoAct}: {Visually} {Exploring} the {Shape} of {Activations} in {Deep} {Learning}},
	shorttitle = {{TopoAct}},
	url = {http://arxiv.org/abs/1912.06332},
	abstract = {Deep neural networks such as GoogLeNet and ResNet have achieved impressive performance in tasks like image classification. To understand how such performance is achieved, we can probe a trained deep neural network by studying neuron activations, i. e., combinations of neuron firings, at any layer of the network in response to a particular input. With a large number of inputs, we aim to obtain a global view of what neurons detect by studying their activations. We ask the following questions: What is the shape of the activation space? What is the organizational principle behind neuron activations? How are the activations related within a layer and across layers? Applying tools from topological data analysis, we present TopoAct, a visual exploration system to study topological summaries of activation vectors for a single layer as well as the evolution of such summaries across multiple layers. We present exploration scenarios using TopoAct that provide valuable insights towards learned representations of an image classifier. We expect TopoAct to give a topological perspective that enriches the current toolbox of neural network analysis, and to provide a basis for network architecture diagnosis and data anomaly detection.},
	urldate = {2020-10-01},
	journal = {arXiv:1912.06332 [cs]},
	author = {Rathore, Archit and Chalapathi, Nithin and Palande, Sourabh and Wang, Bei},
	month = jul,
	year = {2020},
	note = {arXiv: 1912.06332},
	keywords = {ESCAPE, dl, rw-uu-vis-ml, vis},
}

@article{BeatMachineChallengingHumans,
	title = {Beat the {Machine}: {Challenging} {Humans} to {Find} a {Predictive} {Model}'s “{Unknown} {Unknowns}”},
	volume = {6},
	issn = {1936-1955, 1936-1963},
	shorttitle = {Beat the {Machine}},
	url = {https://dl.acm.org/doi/10.1145/2700832},
	doi = {10.1145/2700832},
	language = {en},
	number = {1},
	urldate = {2020-08-02},
	journal = {Journal of Data and Information Quality},
	author = {Attenberg, Joshua and Ipeirotis, Panos and Provost, Foster},
	month = mar,
	year = {2015},
	keywords = {ESCAPE, rw-uu-uu, uu},
	pages = {1--17},
}

@article{CoverageBasedUtilityModelIdentifying,
	title = {A {Coverage}-{Based} {Utility} {Model} for {Identifying} {Unknown} {Unknowns}},
	abstract = {A classiﬁer’s low conﬁdence in prediction is often indicative of whether its prediction will be wrong; in this case, inputs are called known unknowns. In contrast, unknown unknowns (UUs) are inputs on which a classiﬁer makes a high conﬁdence mistake. Identifying UUs is especially important in safety-critical domains like medicine (diagnosis) and law (recidivism prediction). Previous work by Lakkaraju et al. (2017) on identifying unknown unknowns assumes that the utility of each revealed UU is independent of the others, rather than considering the set holistically. While this assumption yields an efﬁcient discovery algorithm, we argue that it produces an incomplete understanding of the classiﬁer’s limitations. In response, this paper proposes a new class of utility models that rewards how well the discovered UUs cover (or “explain”) a sample distribution of expected queries. Although choosing an optimal cover is intractable, even if the UUs were known, our utility model is monotone submodular, affording a greedy discovery strategy. Experimental results on four datasets show that our method outperforms bandit-based approaches and achieves within 60.9\% utility of an omniscient, tractable upper bound.},
	language = {en},
	author = {Bansal, Gagan and Weld, Daniel S},
	keywords = {ESCAPE, rw-uu-uu, uu},
	pages = {8},
}

@article{SimpleScalablePredictiveUncertaintya,
	title = {Simple and {Scalable} {Predictive} {Uncertainty} {Estimation} using {Deep} {Ensembles}},
	url = {http://arxiv.org/abs/1612.01474},
	abstract = {Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.},
	urldate = {2020-07-08},
	journal = {arXiv:1612.01474 [cs, stat]},
	author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
	month = nov,
	year = {2017},
	note = {arXiv: 1612.01474},
	keywords = {ESCAPE, fatml, reliable, unknown-unknowns, uu},
}

@article{OoDAnalyzerInteractiveAnalysisOutofDistribution,
	title = {{OoDAnalyzer}: {Interactive} {Analysis} of {Out}-of-{Distribution} {Samples}},
	shorttitle = {{OoDAnalyzer}},
	url = {http://arxiv.org/abs/2002.03103},
	abstract = {One major cause of performance degradation in predictive models is that the test samples are not well covered by the training data. Such not well-represented samples are called OoD samples. In this paper, we propose OoDAnalyzer, a visual analysis approach for interactively identifying OoD samples and explaining them in context. Our approach integrates an ensemble OoD detection method and a grid-based visualization. The detection method is improved from deep ensembles by combining more features with algorithms in the same family. To better analyze and understand the OoD samples in context, we have developed a novel kNN-based grid layout algorithm motivated by Hall’s theorem. The algorithm approximates the optimal layout and has O(kN2) time complexity, faster than the grid layout algorithm with overall best performance but O(N3) time complexity. Quantitative evaluation and case studies were performed on several datasets to demonstrate the effectiveness and usefulness of OoDAnalyzer.},
	language = {en},
	urldate = {2020-07-07},
	journal = {arXiv:2002.03103 [cs]},
	author = {Chen, Changjian and Yuan, Jun and Lu, Yafeng and Liu, Yang and Su, Hang and Yuan, Songtao and Liu, Shixia},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.03103},
	keywords = {ESCAPE, fatml, reliable, rw-uu-vis-ml, vis},
}

@article{AutomaticConceptbasedExplanations,
	title = {Towards {Automatic} {Concept}-based {Explanations}},
	url = {http://arxiv.org/abs/1902.03129},
	abstract = {Interpretability has become an important topic of research as more machine learning (ML) models are deployed and widely used to make important decisions. Most of the current explanation methods provide explanations through feature importance scores, which identify features that are important for each individual input. However, how to systematically summarize and interpret such per sample feature importance scores itself is challenging. In this work, we propose principles and desiderata for concept based explanation, which goes beyond per-sample features to identify higher level human-understandable concepts that apply across the entire dataset. We develop a new algorithm, ACE, to automatically extract visual concepts. Our systematic experiments demonstrate that ACE discovers concepts that are human-meaningful, coherent and important for the neural network’s predictions.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1902.03129 [cs, stat]},
	author = {Ghorbani, Amirata and Wexler, James and Zou, James and Kim, Been},
	month = oct,
	year = {2019},
	note = {arXiv: 1902.03129},
	keywords = {core, fatml, xai},
}

@article{InterpretabilityFeatureAttributionTesting,
	title = {Interpretability beyond feature attribution: {Testing} with {Concept} {Activation} {Vectors} {TCAV}},
	language = {en},
	author = {Kim, Been},
	keywords = {core, fatml, xai},
	pages = {54},
}

@article{PartneringPeopleDeepLearning,
	title = {Partnering {People} with {Deep} {Learning} {Systems}: {Human} {Cognitive} {Effects} of {Explanations}},
	language = {en},
	author = {Dougherty, Sean},
	keywords = {dissertation, explanation, fatml, thesis, xai},
	pages = {231},
}

@article{DynamicsConflictsWikipedia,
	title = {Dynamics of {Conflicts} in {Wikipedia}},
	volume = {7},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0038869},
	doi = {10.1371/journal.pone.0038869},
	abstract = {In this work we study the dynamical features of editorial wars in Wikipedia (WP). Based on our previously established algorithm, we build up samples of controversial and peaceful articles and analyze the temporal characteristics of the activity in these samples. On short time scales, we show that there is a clear correspondence between conflict and burstiness of activity patterns, and that memory effects play an important role in controversies. On long time scales, we identify three distinct developmental patterns for the overall behavior of the articles. We are able to distinguish cases eventually leading to consensus from those cases where a compromise is far from achievable. Finally, we analyze discussion networks and conclude that edit wars are mainly fought by few editors only.},
	language = {en},
	number = {6},
	urldate = {2021-07-24},
	journal = {PLoS ONE},
	author = {Yasseri, Taha and Sumi, Robert and Rung, András and Kornai, András and Kertész, János},
	editor = {Szolnoki, Attila},
	month = jun,
	year = {2012},
	keywords = {wikipedia},
	pages = {e38869},
}

@inproceedings{ExplainableSoftwareAnalytics,
	address = {Gothenburg Sweden},
	title = {Explainable software analytics},
	isbn = {978-1-4503-5662-6},
	url = {https://dl.acm.org/doi/10.1145/3183399.3183424},
	doi = {10.1145/3183399.3183424},
	abstract = {Software analytics has been the subject of considerable recent attention but is yet to receive significant industry traction. One of the key reasons is that software practitioners are reluctant to trust predictions produced by the analytics machinery without understanding the rationale for those predictions. While complex models such as deep learning and ensemble methods improve predictive performance, they have limited explainability. In this paper, we argue that making software analytics models explainable to software practitioners is as important as achieving accurate predictions. Explainability should therefore be a key measure for evaluating software analytics models. We envision that explainability will be a key driver for developing software analytics models that are useful in practice. We outline a research roadmap for this space, building on social science, explainable artificial intelligence and software engineering.},
	language = {en},
	urldate = {2021-07-28},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Software} {Engineering}: {New} {Ideas} and {Emerging} {Results}},
	publisher = {ACM},
	author = {Dam, Hoa Khanh and Tran, Truyen and Ghose, Aditya},
	month = may,
	year = {2018},
	pages = {53--56},
}

@inproceedings{DomainAgnosticContrastiveLearning,
	title = {Towards {Domain}-{Agnostic} {Contrastive} {Learning}},
	url = {http://proceedings.mlr.press/v139/verma21a.html},
	language = {en},
	urldate = {2021-07-27},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Verma, Vikas and Luong, Thang and Kawaguchi, Kenji and Pham, Hieu and Le, Quoc},
	month = jul,
	year = {2021},
	note = {ISSN: 2640-3498},
	keywords = {XAI, fatml},
	pages = {10530--10541},
}

@inproceedings{InvestigatingDecisionMakingBehaviorMaximizers,
	address = {Singapore Singapore},
	title = {Investigating the {Decision}-{Making} {Behavior} of {Maximizers} and {Satisficers} in the {Presence} of {Recommendations}},
	isbn = {978-1-4503-5589-6},
	url = {https://dl.acm.org/doi/10.1145/3209219.3209252},
	doi = {10.1145/3209219.3209252},
	abstract = {Psychological theory distinguishes between maximizing and satisficing decision-making styles. Maximizers tend to explore more or all alternatives when making a choice, while satisficers evaluate options until they find one that is good enough. There is limited research that examines how the existence of a recommender influences the choice process and decisions of different types of decisionmakers. We report the results of a controlled study, in which we monitored the choice process of participants when provided with automated recommendations and different types of additional information regarding available options. Our analyses show that none of the differences that were expected based on the literature manifested itself in the experiment. Maximizers neither inspected more items, nor invested more time to study them. Instead, like satisficers, they mostly picked one of the top-ranked items recommended by the system, which emphasizes the value of recommenders in particular for maximizers, who would otherwise face a more challenging decision problem. The analysis of the preferences of participants over different types of additional information revealed that highlighting key pros and cons was perceived as particularly helpful for the maximizers, an insight that can be used for the design of explanation approaches for recommenders.},
	language = {en},
	urldate = {2021-07-25},
	booktitle = {Proceedings of the 26th {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Jugovac, Michael and Nunes, Ingrid and Jannach, Dietmar},
	month = jul,
	year = {2018},
	pages = {279--283},
}

@inproceedings{EffectsPersonalCharacteristicsMusic,
	address = {Vancouver British Columbia Canada},
	title = {Effects of personal characteristics on music recommender systems with different levels of controllability},
	isbn = {978-1-4503-5901-6},
	url = {https://dl.acm.org/doi/10.1145/3240323.3240358},
	doi = {10.1145/3240323.3240358},
	abstract = {Previous research has found that enabling users to control the recommendation process increases user satisfaction. However, providing additional controls also increases cognitive load, and different users have different needs for control. Therefore, in this study, we investigate the effect of two personal characteristics: musical sophistication and visual memory capacity. We designed a visual user interface, on top of a commercial music recommender, with different controls: interactions with recommendations (i.e., the output of a recommender system), the user profile (i.e., the top listened songs), and algorithm parameters (i.e., weights in an algorithm). We created eight experimental settings with combinations of these three user controls and conducted a between-subjects study (N=240), to explore the effect on cognitive load and recommendation acceptance for different personal characteristics. We found that controlling recommendations is the most favorable single control element. In addition, controlling user profile and algorithm parameters was the most beneficial setting with multiple controls. Moreover, the participants with high musical sophistication perceived recommendations to be of higher quality, which in turn lead to higher recommendation acceptance. However, we found no effect of visual working memory on either cognitive load or recommendation acceptance. This work contributes an understanding of how to design control that hits the sweet spot between the perceived quality of recommendations and acceptable cognitive load.},
	language = {en},
	urldate = {2021-07-25},
	booktitle = {Proceedings of the 12th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Jin, Yucheng and Tintarev, Nava and Verbert, Katrien},
	month = sep,
	year = {2018},
	pages = {13--21},
}

@incollection{UserGroupsDifferentLevels,
	address = {Cham},
	title = {User {Groups} and {Different} {Levels} of {Control} in {Recommender} {Systems}},
	volume = {10286},
	isbn = {978-3-319-58462-1 978-3-319-58463-8},
	url = {https://link.springer.com/10.1007/978-3-319-58463-8_26},
	abstract = {The aspect of control in recommender systems has already been extensively researched in the past. Quite a number of studies performed by various researchers reported that an increase in control had a positive effect for example on user satisfaction with a system, or recommendation accuracy. Recent studies investigated whether this positive effect of control applies to all users, or finer distinctions have to be made between different user groups, which in turn require different levels of control. Those studies identified several characteristics, along which users could be divided into groups: expertise in recommender systems, domain knowledge, trusting propensity, persistence. They reported different needs of control for different user groups. However, the effect of those characteristics has not been systematically examined with regard to all three recommendation phases introduced earlier by Pu and Zhang, namely initial preference elicitation, preference refinement, result display. This paper suggests, that for different levels of expertise and trust, different levels of control are necessary during preference elicitation, whereas persistence does not play a prevalent role in this phase. Further assumptions are made for preference refinement and result display. In addition to the three phases, context, type of information required and visualization of control methods are identified as factors influencing the request of users for control.},
	language = {en},
	urldate = {2021-07-25},
	booktitle = {Digital {Human} {Modeling}. {Applications} in {Health}, {Safety}, {Ergonomics}, and {Risk} {Management}: {Ergonomics} and {Design}},
	publisher = {Springer International Publishing},
	author = {Mendez, Christine and Lukarov, Vlatko and Greven, Christoph and Calero Valdez, André and Dietze, Felix and Schroeder, Ulrik and Ziefle, Martina},
	editor = {Duffy, Vincent G.},
	year = {2017},
	doi = {10.1007/978-3-319-58463-8_26},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {308--323},
}

@article{DecisionMakingStrategiesDifer,
	title = {Decision {Making} {Strategies} {Difer} in the {Presence} of {Collaborative} {Explanations}: {Two} {Conjoint} {Studies}},
	abstract = {Rating-based summary statistics are ubiquitous in e-commerce, and often are crucial components in personalized recommendation mechanisms. Especially visual rating summarizations have been identiied as important means to explain, why an item is presented or proposed to an user. Largely left unexplored, however, is the issue to what extent the descriptives of these rating summary statistics inluence decision making of the online consumer. Therefore, we conducted a series of two conjoint experiments to explore how diferent summarizations of rating distributions (i.e., in the form of number of ratings, mean, variance, skewness, bimodality, or origin of the ratings) impact users’ decision making. In a irst study with over 200 participants, we identiied that users are primarily guided by the mean and the number of ratings, and ś to lesser degree ś by the variance and origin of a rating. When probing the maximizing behavioral tendencies of our participants, other sensitivities regarding the summary of rating distributions became apparent. We thus instrumented a follow-up eye-tracking study to explore in more detail, how the choices of participants vary in terms of their decision making strategies. This second round with over 40 additional participants supported our hypothesis that users, who usually experience higher decision diiculty, follow compensatory decision strategies, and focus more on the decisions they make. We conclude by outlining how the results of these studies can guide algorithm development, and counterbalance presumable biases in implicit user feedback.},
	language = {en},
	author = {Coba, Ludovik and Rook, Laurens and Zanker, Markus and Symeonidis, Panagiotis},
	year = {2019},
	pages = {12},
}

@inproceedings{PrinciplesExplanatoryDebuggingPersonalizeb,
	address = {Atlanta Georgia USA},
	title = {Principles of {Explanatory} {Debugging} to {Personalize} {Interactive} {Machine} {Learning}},
	isbn = {978-1-4503-3306-1},
	url = {https://dl.acm.org/doi/10.1145/2678025.2701399},
	doi = {10.1145/2678025.2701399},
	abstract = {How can end users efﬁciently inﬂuence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging, an approach in which the system explains to users how it made each of its predictions, and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants’ understanding of the learning system by 52\% and allowed participants to correct its mistakes up to twice as efﬁciently as participants using a traditional learning system.},
	language = {en},
	urldate = {2021-07-28},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Kulesza, Todd and Burnett, Margaret and Wong, Weng-Keen and Stumpf, Simone},
	month = mar,
	year = {2015},
	pages = {126--137},
}

@article{ImpactExplanationFacilitiesUser,
	title = {The {Impact} of {Explanation} {Facilities} on {User} {Acceptance} of {Expert} {Systems} {Advice}},
	volume = {19},
	issn = {0276-7783},
	url = {https://www.jstor.org/stable/249686},
	doi = {10.2307/249686},
	abstract = {Providing explanations for recommended actions is deemed one of the most important capabilities of expert systems (ES). There is little empirical evidence, however, that explanation facilities indeed influence user confidence in, and acceptance of, ES-based decisions and recommendations. This paper investigates the impact of ES explanations on changes in user beliefs toward ES-generated conclusions. Grounded on a theoretical model of argument, three alternative types of ES explanations-trace, justification, and strategy-were provided in a simulated diagnostic expert system performing auditing tasks. Twenty practicing auditors evaluated the outputs of the system in a laboratory setting. The results indicate that explanation facilities can make ES-generated advice more acceptable to users and that justification is the most effective type of explanation to bring about changes in user attitudes toward the system. These findings are expected to be generalizable to application domains that exhibit similar characteristics to those of auditing: domains in which decision making tends to be judgmental and yet highly consequential, and the correctness or validity of such decisions cannot be readily verified.},
	number = {2},
	urldate = {2021-07-28},
	journal = {MIS Quarterly},
	author = {Ye, L. Richard and Johnson, Paul E.},
	year = {1995},
	note = {Publisher: Management Information Systems Research Center, University of Minnesota},
	pages = {157--172},
}

@inproceedings{CouldYouDefineThat,
	address = {Denver Colorado USA},
	title = {"{Could} {You} {Define} {That} in {Bot} {Terms}"?: {Requesting}, {Creating} and {Using} {Bots} on {Reddit}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {"{Could} {You} {Define} {That} in {Bot} {Terms}"?},
	url = {https://dl.acm.org/doi/10.1145/3025453.3025830},
	doi = {10.1145/3025453.3025830},
	abstract = {Bots are estimated to account for well over half of all web traffic, yet they remain an understudied topic in HCI. In this paper we present the findings of an analysis of 2284 submissions across three discussion groups dedicated to the request, creation and discussion of bots on Reddit. We set out to examine the qualities and functionalities of bots and the practical and social challenges surrounding their creation and use. Our findings highlight the prevalence of misunderstandings around the capabilities of bots, misalignments in discourse between novices who request and more expert members who create them, and the prevalence of requests that are deemed to be inappropriate for the Reddit community. In discussing our findings, we suggest future directions for the design and development of tools that support more carefully guided and reflective approaches to bot development for novices, and tools to support exploring the consequences of contextuallyinappropriate bot ideas.},
	language = {en},
	urldate = {2021-07-13},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Long, Kiel and Vines, John and Sutton, Selina and Brooker, Phillip and Feltwell, Tom and Kirman, Ben and Barnett, Julie and Lawson, Shaun},
	month = may,
	year = {2017},
	pages = {3488--3500},
}

@inproceedings{EffectModeratorBotsAbusive,
	address = {Union, NJ, USA},
	title = {The {Effect} of {Moderator} {Bots} on {Abusive} {Language} {Use}},
	isbn = {978-1-4503-6482-9},
	url = {http://dl.acm.org/citation.cfm?doid=3243250.3243257},
	doi = {10.1145/3243250.3243257},
	abstract = {Moderator bots are widely used on forums and social media. On Internet forums, moderator bots play an important role in automatically monitoring the content of images and the text present on the forum as well as providing repetitive information without the need for interaction with an administrator. The increasing use of moderator bots inspired me to study the performance of moderator bots. To date, research investigating the effect of moderator bots has not been conducted. Herein, we analyzed Reddit, a popular U.S. social news aggregation platform, which uses a moderator bot (AutoModerator) to mitigate the invalid comments occurring in discussion groups. This has thus become an ideal research opportunity for this study. We implemented a regression discontinuity design and interrupted time-series analysis to estimate the effect of AutoModerator on word-quality improvement. We observed an abrupt and significant decrease in the rate of abusive posts to which AutoModerator was attached. These results suggest that AutoModerator has been effective in controlling the word quality.},
	language = {en},
	urldate = {2021-07-21},
	booktitle = {Proceedings of the {International} {Conference} on {Pattern} {Recognition} and {Artificial} {Intelligence} - {PRAI} 2018},
	publisher = {ACM Press},
	author = {Young, Li-Yin},
	year = {2018},
	pages = {133--137},
}

@article{InformationQualityWikipediaEffects,
	title = {Information {Quality} in {Wikipedia}: {The} {Effects} of {Group} {Composition} and {Task} {Conflict}},
	volume = {27},
	issn = {0742-1222, 1557-928X},
	shorttitle = {Information {Quality} in {Wikipedia}},
	url = {https://www.tandfonline.com/doi/full/10.2753/MIS0742-1222270403},
	doi = {10.2753/MIS0742-1222270403},
	language = {en},
	number = {4},
	urldate = {2021-07-21},
	journal = {Journal of Management Information Systems},
	author = {Arazy, Ofer and Nov, Oded and Patterson, Raymond and Yeo, Lisa},
	month = apr,
	year = {2011},
	pages = {71--98},
}

@inproceedings{ExplAInYourselfTransparencyPositive,
	address = {Yokohama Japan},
	title = {{ExplAIn} {Yourself}! {Transparency} for {Positive} {UX} in {Autonomous} {Driving}},
	isbn = {978-1-4503-8096-6},
	url = {https://dl.acm.org/doi/10.1145/3411764.3446647},
	doi = {10.1145/3411764.3446647},
	abstract = {In a fully autonomous driving situation, passengers hand over the steering control to a highly automated system. Autonomous driving behaviour may lead to confusion and negative user experience. When establishing such new technology, the user’s acceptance and understanding are crucial factors regarding success and failure. Using a driving simulator and a mobile application, we evaluated if system transparency during and after the interaction can increase the user experience and subjective feeling of safety and control. We contribute an initial guideline for autonomous driving experience design, bringing together the areas of user experience, explainable artifcial intelligence and autonomous driving. The AVAM questionnaire, UEQ-S and interviews show that explanations during or after the ride help turn a negative user experience into a neutral one, which might be due to the increased feeling of control. However, we did not detect an efect for combining explanations during and after the ride.},
	language = {en},
	urldate = {2021-07-20},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Schneider, Tobias and Hois, Joana and Rosenstein, Alischa and Ghellal, Sabiha and Theofanou-Fülbier, Dimitra and Gerlicher, Ansgar R.S.},
	month = may,
	year = {2021},
	keywords = {self-driving-car},
	pages = {1--12},
}

@article{PerformanceClassificationModelsUser,
	title = {Performance of classification models from a user perspective},
	volume = {51},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016792361100042X},
	doi = {10.1016/j.dss.2011.01.013},
	abstract = {This paper proposes a complete framework to assess the overall performance of classiﬁcation models from a user perspective in terms of accuracy, comprehensibility, and justiﬁability. A review is provided of accuracy and comprehensibility measures, and a novel metric is introduced that allows one to measure the justiﬁability of classiﬁcation models. Furthermore, taxonomy of domain constraints is introduced, and an overview of the existing approaches to impose constraints and include domain knowledge in data mining techniques is presented. Finally, justiﬁability metric is applied to a credit scoring and customer churn prediction case.},
	language = {en},
	number = {4},
	urldate = {2021-07-20},
	journal = {Decision Support Systems},
	author = {Martens, David and Vanthienen, Jan and Verbeke, Wouter and Baesens, Bart},
	month = nov,
	year = {2011},
	keywords = {fatml, xai},
	pages = {782--793},
}

@article{InterpretabilityMachineLearningModelsa,
	title = {Interpretability of {Machine} {Learning} {Models} and {Representations}: an {Introduction}},
	abstract = {Interpretability is often a major concern in machine learning. Although many authors agree with this statement, interpretability is often tackled with intuitive arguments, distinct (yet related) terms and heuristic quantiﬁcations. This short survey aims to clarify the concepts related to interpretability and emphasises the distinction between interpreting models and representations, as well as heuristic-based and user-based approaches.},
	language = {en},
	author = {Bibal, Adrien and Frénay, Benoît},
	pages = {7},
}

@article{URankExploringDocumentRecommendations,
	title = {{uRank}: {Exploring} {Document} {Recommendations} through an {Interactive} {User}-{Driven} {Approach}},
	abstract = {Whenever we gather or organize knowledge, the task of searching inevitably takes precedence. As exploration unfolds, it becomes cumbersome to reorganize resources along new interests, as any new search brings new results. Despite huge advances in retrieval and recommender systems from the algorithmic point of view, many real-world interfaces have remained largely unchanged: results appear in an inﬁnite list ordered by relevance with respect to the current query. We introduce uRank, a user-driven visual tool for exploration and discovery of textual document recommendations. It includes a view summarizing the content of the recommendation set, combined with interactive methods for understanding, reﬁning and reorganizing documents on-the-ﬂy as information needs evolve. We provide a formal experiment showing that uRank users can browse the document collection and efﬁciently gather items relevant to particular topics of interest with signiﬁcantly lower cognitive load compared to traditional list-based representations.},
	language = {en},
	author = {di Sciascio, Cecilia and Sabol, Vedran and Veas, Eduardo},
	pages = {8},
}

@article{OperationalizingConflictCooperationAutomated,
	title = {Operationalizing {Conflict} and {Cooperation} between {Automated} {Software} {Agents} in {Wikipedia}: {A} {Replication} and {Expansion} of ``{Even} {Good} {Bots} {Fight}''},
	volume = {1},
	language = {en},
	number = {2},
	author = {Geiger, R Stuart and Halfaker, Aaron},
	pages = {33},
}

@article{ResolvingConflictSituationsReddit,
	title = {Resolving {Conflict} {Situations} in {Reddit} {Community} {Driven} {Discussion} {Platform}},
	abstract = {The subject of conflict nature of the Reddit community driven discussion platform has been considered. The Reddit section entitled “Unpopular Opinion” has been selected, as it is a base for the most conflicting users’ comments. The comments to the conflict situations have been discovered by means of linguistic markers and manipulative contexts. Phrases and sentences marked with manipulative, implicit or explicit nature of utterance have been found and grouped. The algorithm of sequence of step analysis concerning the Reddit social network comment system has been considered. The linguistic markers of the most contradictory posts have been analyzed using Linguistic Inquiry and Word Count (LIWC).},
	language = {en},
	author = {Albota, Solomiia},
	pages = {12},
}

@inproceedings{RoleInformationVisibilityNetwork,
	address = {Portland Oregon USA},
	title = {The {Role} of {Information} {Visibility} in {Network} {Gatekeeping}: {Information} {Aggregation} on {Reddit} during {Crisis} {Events}},
	isbn = {978-1-4503-4335-0},
	shorttitle = {The {Role} of {Information} {Visibility} in {Network} {Gatekeeping}},
	url = {https://dl.acm.org/doi/10.1145/2998181.2998299},
	doi = {10.1145/2998181.2998299},
	abstract = {As social media platforms witness more and more contributions from participants during developing crisis events, some platforms provide affordances that support visibility for specific pieces of information. However, the design of information visibility, especially in the context of controlling information flows (through gatekeeping), may shape how participants collect and share up-to-date information in these systems. This paper looks at the field site of reddit.com through trace ethnography methods to understand how the design of reddit’s platform (from algorithms to user roles) impacts the visibility of information and subsequently how participants aggregate information in response to ongoing events. Through trace ethnographic analysis, we illustrate three themes related to tensions around visibility – behavioral, structural, and relational – and show how visibility shapes the work of producing information about crises in social news sites.},
	language = {en},
	urldate = {2021-07-21},
	booktitle = {Proceedings of the 2017 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} and {Social} {Computing}},
	publisher = {ACM},
	author = {Leavitt, Alex and Robinson, John J.},
	month = feb,
	year = {2017},
	pages = {1246--1261},
}

@article{StochasticGradientBoosting,
	title = {Stochastic gradient boosting},
	volume = {38},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947301000652},
	doi = {10.1016/S0167-9473(01)00065-2},
	abstract = {Gradient boosting constructs additive regression models by sequentially ÿtting a simple parameterized function (base learner) to current “pseudo”-residuals by least squares at each iteration. The pseudo-residuals are the gradient of the loss functional being minimized, with respect to the model values at each training data point evaluated at the current step. It is shown that both the approximation accuracy and execution speed of gradient boosting can be substantially improved by incorporating randomization into the procedure. Speciÿcally, at each iteration a subsample of the training data is drawn at random (without replacement) from the full training data set. This randomly selected subsample is then used in place of the full sample to ÿt the base learner and compute the model update for the current iteration. This randomized approach also increases robustness against overcapacity of the base learner. c 2002 Elsevier Science B.V. All rights reserved.},
	language = {en},
	number = {4},
	urldate = {2021-07-10},
	journal = {Computational Statistics \& Data Analysis},
	author = {Friedman, Jerome H.},
	month = feb,
	year = {2002},
	pages = {367--378},
}

@inproceedings{XGBoostScalableTreeBoosting,
	address = {San Francisco California USA},
	title = {{XGBoost}: {A} {Scalable} {Tree} {Boosting} {System}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {{XGBoost}},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939785},
	doi = {10.1145/2939672.2939785},
	abstract = {Tree boosting is a highly eﬀective and widely used machine learning method. In this paper, we describe a scalable endto-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
	language = {en},
	urldate = {2021-07-10},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Chen, Tianqi and Guestrin, Carlos},
	month = aug,
	year = {2016},
	pages = {785--794},
}

@inproceedings{KnowledgeableExplanationsRecommenderSystems,
	title = {Knowledgeable explanations for recommender systems},
	volume = {1},
	booktitle = {2010 {IEEE}/{WIC}/{ACM} {International} {Conference} on {Web} {Intelligence} and {Intelligent} {Agent} {Technology}},
	publisher = {IEEE},
	author = {Zanker, Markus and Ninaus, Daniel},
	year = {2010},
	pages = {657--660},
}

@inproceedings{VisualizingRecommendationsSupportExploration,
	title = {Visualizing recommendations to support exploration, transparency and controllability},
	booktitle = {Proceedings of the 2013 international conference on {Intelligent} user interfaces},
	author = {Verbert, Katrien and Parra, Denis and Brusilovsky, Peter and Duval, Erik},
	year = {2013},
	pages = {351--362},
}

@article{EffectsRecommendationsPresentationPersuasion,
	title = {The effects of recommendations’ presentation on persuasion and satisfaction in a movie recommender system},
	volume = {16},
	issn = {0942-4962, 1432-1882},
	url = {http://link.springer.com/10.1007/s00530-010-0190-0},
	doi = {10.1007/s00530-010-0190-0},
	abstract = {The explosive growth of Internet applications and content, during the last decade, has revealed an increasing need for information ﬁltering and recommendation. Most research in the area of recommendation systems has focused on designing and implementing efﬁcient algorithms that provide accurate recommendations. However, the selection of appropriate recommendation content and the presentation of information are equally important in creating successful recommender applications. This paper addresses issues related to the presentation of recommendations in the movies domain. The current work reviews previous research approaches and popular recommender systems, and focuses on user persuasion and satisfaction. In our experiments, we compare different presentation methods in terms of recommendations’ organization in a list (i.e. top N-items list and structured overview) and recommendation modality (i.e. simple text, combination of text and image, and combination of text and video). The most efﬁcient presentation methods, regarding user persuasion and satisfaction, proved to be the ‘‘structured overview’’ and the ‘‘text and video’’ interfaces, while a strong positive correlation was also found between user satisfaction and persuasion in all experimental conditions.},
	language = {en},
	number = {4-5},
	urldate = {2021-07-10},
	journal = {Multimedia Systems},
	author = {Nanou, Theodora and Lekakos, George and Fouskas, Konstantinos},
	month = aug,
	year = {2010},
	pages = {219--230},
}

@article{IdealHumanExpectationsAIa,
	title = {"{An} {Ideal} {Human}": {Expectations} of {AI} {Teammates} in {Human}-{AI} {Teaming}},
	volume = {4},
	issn = {2573-0142},
	shorttitle = {"{An} {Ideal} {Human}"},
	url = {https://dl.acm.org/doi/10.1145/3432945},
	doi = {10.1145/3432945},
	abstract = {Driven by state-of-the-art AI technologies, human-AI collaboration has become an important area in computer-supported teamwork research. While human-AI collaboration has been investigated in various domains, more research is needed to explore human perceptions and expectations of AI teammates in human-AI teaming. To achieve an in-depth understanding of how people perceive AI teammates and what they expect from AI teammates in human-AI teaming, we conducted a survey with 213 participants and a follow-up interview with 20 participants. Considering the context-dependency of teamwork, we chose to study human-AI teaming in the context of multiplayer online games as a case study. This study shows that people have mixed feelings toward AI teammates but hold a positive attitude toward future collaboration with AI teammates in general. Our findings highlight people's expectations for AI teammates in a rapidly changing collaborative environment (e.g., instrumental skills for in-game tasks, shared understanding between humans and AI, communication capabilities, human-like behaviors and performance), as well as factors that impact people's willingness to team up with AI teammates (e.g., pre-existing attitudes toward AI, previous collaboration experience with humans). We contribute to CSCW by shedding light on how AI should be structured in human-AI teaming to support highly complex collaborative activities in CSCW environments.},
	language = {en},
	number = {CSCW3},
	urldate = {2021-07-10},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Zhang, Rui and McNeese, Nathan J. and Freeman, Guo and Musick, Geoff},
	month = jan,
	year = {2021},
	pages = {1--25},
}

@inproceedings{TransparencyLanguageGenerationLevels,
	address = {Bilbao Spain},
	title = {Transparency in {Language} {Generation}: {Levels} of {Automation}},
	isbn = {978-1-4503-7544-3},
	shorttitle = {Transparency in {Language} {Generation}},
	url = {https://dl.acm.org/doi/10.1145/3405755.3406136},
	doi = {10.1145/3405755.3406136},
	abstract = {Language models and conversational systems are growing increasingly advanced, creating outputs that may be mistaken for humans. Consumers may thus be misled by advertising, media reports, or vagueness regarding the role of automation in the production of language. We propose a taxonomy of language automation, based on the SAE levels of driving automation, to establish a shared set of terms for describing automated language. It is our hope that the proposed taxonomy can increase transparency in this rapidly advancing field.},
	language = {en},
	urldate = {2021-07-09},
	booktitle = {Proceedings of the 2nd {Conference} on {Conversational} {User} {Interfaces}},
	publisher = {ACM},
	author = {Edwards, Justin and Perrone, Allison and Doyle, Philip R.},
	month = jul,
	year = {2020},
	pages = {1--3},
}

@article{AmbulatoryMovementsTeamDynamics,
	title = {Ambulatory {Movements}, {Team} {Dynamics} and {Interactions} during {Robot}-{Assisted} {Surgery}},
	volume = {118},
	issn = {1464-4096},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5748883/},
	doi = {10.1111/bju.13426},
	abstract = {Objective
To analyze ambulatory movements and team dynamics during robot-assisted surgery (RAS), and investigate whether congestion of the physical space associated with RA technology led to workflow challenges, or predisposed to errors and adverse events.

Methods
With IRB approval, we retrospectively reviewed 10 recorded RA radical prostatectomies in a single operating room (OR). OR was divided into 8 zones, and all movement were tracked and described in terms of start and end zones, duration, personnel, and purpose. Movement were further classified into avoidable (can be eliminated/improved) and unavoidable (necessary for completion of the procedure).

Results
Mean operative time was 166 minutes, of which ambulation constituted 27 minutes (16\%). A total of 2,896 ambulatory movements were identified (mean=290 ambulatory movements/procedure). Most of movements were procedure-related (31\%), and were performed by the circulating nurse. We identified 11 main pathways in the OR (); the heaviest traffic was between the Circulating Nurse Zone, Transit Zone and Supply-1 Zone. Fifty percent of ambulatory movements were found to be avoidable.

Conclusion
More than half of the movements during RAS can be eliminated with an improved OR setting. More studies are needed to design an evidence-based OR layout that enhances access, workflow and patient safety.},
	number = {1},
	urldate = {2021-07-08},
	journal = {BJU international},
	author = {Ahmad, Nabeeha and Hussein, Ahmed A. and Cavuoto, Lora and Sharif, Mohamed and Allers, Jenna C. and Hinata, Nobuyuki and Ahmad, Basel and Kozlowski, Justen G. and Hashmi, Zishan and Bisantz, Ann and Guru, Khurshid A.},
	month = jul,
	year = {2016},
	pmid = {26800347},
	pmcid = {PMC5748883},
	pages = {132--139},
}

@article{FeatureBasedExplanationsDonHelpa,
	title = {Feature-{Based} {Explanations} {Don}'t {Help} {People} {Detect} {Misclassifications} of {Online} {Toxicity}},
	abstract = {We present an experimental assessment of the impact of feature attribution-style explanations on human performance in predicting the consensus toxicity of social media posts with advice from an unreliable machine learning model. By doing so we add to a small but growing body of literature inspecting the utility of interpretable machine learning in terms of human outcomes. We also evaluate interpretable machine learning for the ﬁrst time in the important domain of online toxicity, where fully-automated methods have faced criticism as being inadequate as a measure of toxic behavior.},
	language = {en},
	author = {Carton, Samuel and Mei, Qiaozhu and Resnick, Paul},
	pages = {12},
}

@inproceedings{MiningAdministrativeDataSpur,
	address = {Sydney NSW Australia},
	title = {Mining {Administrative} {Data} to {Spur} {Urban} {Revitalization}},
	isbn = {978-1-4503-3664-2},
	url = {https://dl.acm.org/doi/10.1145/2783258.2788568},
	doi = {10.1145/2783258.2788568},
	abstract = {After decades of urban investment dominated by sprawl and outward growth, municipal governments in the United States are responsible for the upkeep of urban neighborhoods that have not received suﬃcient resources or maintenance in many years. One of city governments’ biggest challenges is to revitalize decaying neighborhoods given only limited resources. In this paper, we apply data science techniques to administrative data to help the City of Memphis, Tennessee improve distressed neighborhoods. We develop new methods to eﬃciently identify homes in need of rehabilitation and to predict the impacts of potential investments on neighborhoods. Our analyses allow Memphis to design neighborhood-improvement strategies that generate greater impacts on communities. Since our work uses data that most US cities already collect, our models and methods are highly portable and inexpensive to implement. We also discuss the challenges we encountered while analyzing government data and deploying our tools, and highlight important steps to improve future data-driven eﬀorts in urban policy.},
	language = {en},
	urldate = {2021-07-08},
	booktitle = {Proceedings of the 21th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Green, Ben and Caro, Alejandra and Conway, Matthew and Manduca, Robert and Plagge, Tom and Miller, Abby},
	month = aug,
	year = {2015},
	pages = {1829--1838},
}

@inproceedings{CorpusBasedStudyEditCategories,
	address = {Mumbai, India},
	title = {A {Corpus}-{Based} {Study} of {Edit} {Categories} in {Featured} and {Non}-{Featured} {Wikipedia} {Articles}},
	url = {https://aclanthology.org/C12-1044},
	urldate = {2021-07-08},
	booktitle = {Proceedings of {COLING} 2012},
	publisher = {The COLING 2012 Organizing Committee},
	author = {Daxenberger, Johannes and Gurevych, Iryna},
	month = dec,
	year = {2012},
	pages = {711--726},
}

@inproceedings{FindingSocialRolesWikipediaa,
	address = {Seattle Washington USA},
	title = {Finding social roles in {Wikipedia}},
	isbn = {978-1-4503-0121-3},
	url = {https://dl.acm.org/doi/10.1145/1940761.1940778},
	doi = {10.1145/1940761.1940778},
	abstract = {This paper investigates some of the social roles people play in the online community of Wikipedia. We start from qualitative comments posted on community oriented pages, wiki project memberships, and user talk pages in order to identify a sample of editors who represent four key roles: substantive experts, technical editors, vandal fighters, and social networkers. Patterns in edit histories and egocentric network visualizations suggest potential “structural signatures” that could be used as quantitative indicators of role adoption. Using simple metrics based on edit histories we compare two samples of Wikipedians: a collection of long term dedicated editors, and a cohort of editors from a one month window of new arrivals. According to these metrics, we find that the proportions of editor types in the new cohort are similar those observed in the sample of dedicated contributors. The number of new editors playing helpful roles in a single month’s cohort nearly equal the number found in the dedicated sample. This suggests that informal socialization has the potential provide sufficient role related labor despite growth and change in Wikipedia. These results are preliminary, and we describe several ways that the method can be improved, including the expansion and refinement of role signatures and identification of other important social roles.},
	language = {en},
	urldate = {2021-07-05},
	booktitle = {Proceedings of the 2011 {iConference}},
	publisher = {ACM},
	author = {Welser, Howard T. and Cosley, Dan and Kossinets, Gueorgi and Lin, Austin and Dokshin, Fedor and Gay, Geri and Smith, Marc},
	month = feb,
	year = {2011},
	keywords = {hci},
	pages = {122--129},
}

@article{VisualizingSignaturesSocialRolesa,
	title = {Visualizing the {Signatures} of {Social} {Roles} in {Online} {Discussion} {Groups}},
	abstract = {Social roles in online discussion forums can be described by patterned characteristics of communication between network members which we conceive of as ‘structural signatures.' This paper uses visualization methods to reveal these structural signatures and regression analysis to confirm the relationship between these signatures and their associated roles in Usenet newsgroups. Our analysis focuses on distinguishing the signatures of one role from others, the role of “answer people." Answer people are individuals whose dominant behavior is to respond to questions posed by other users. We found that answer people predominantly contribute one or a few messages to discussions initiated by others, are disproportionately tied to relative isolates, have few intense ties and have few triangles in their local networks. OLS regression shows that these signatures are strongly correlated with role behavior and, in combination, provide a strongly predictive model for identifying role behavior (R2=.72). To conclude, we consider strategies for further improving the identification of role behavior in online discussion settings and consider how the development of a taxonomy of author types could be extended to a taxonomy of newsgroups in particular and discussion systems in general.},
	language = {en},
	author = {Welser, Howard T and Gleave, Eric and Fisher, Danyel and Smith, Marc},
	pages = {32},
}

@inproceedings{FunctionalRolesCareerPaths,
	title = {Functional roles and career paths in {Wikipedia}},
	booktitle = {Proceedings of the 18th {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} \& {Social} {Computing}},
	author = {Arazy, Ofer and Ortega, Felipe and Nov, Oded and Yeo, Lisa and Balila, Adam},
	year = {2015},
	pages = {1092--1105},
}

@inproceedings{WhatMineMineTerritoriality,
	address = {Boston, MA, USA},
	title = {What's mine is mine: territoriality in collaborative authoring},
	isbn = {978-1-60558-246-7},
	shorttitle = {What's mine is mine},
	url = {http://dl.acm.org/citation.cfm?doid=1518701.1518925},
	doi = {10.1145/1518701.1518925},
	abstract = {Territoriality, the expression of ownership towards an object, can emerge when social actors occupy a shared social space. In the case of Wikipedia, the prevailing cultural norm is one that warns against ownership of one’s work. However, we observe the emergence of territoriality in online space with respect to a subset of articles that have been tagged with the Maintained template through a qualitative study of 15 editors who have self-designated as Maintainers. Our participants communicated ownership, demarcated boundaries and asserted their control over artifacts for the sake of quality by appropriating existing features of Wikipedia. We then suggest design strategies to support these behaviors in the proper context within collaborative authoring systems more generally.},
	language = {en},
	urldate = {2021-07-08},
	booktitle = {Proceedings of the 27th international conference on {Human} factors in computing systems - {CHI} 09},
	publisher = {ACM Press},
	author = {Thom-Santelli, Jennifer and Cosley, Dan R. and Gay, Geri},
	year = {2009},
	pages = {1481},
}

@article{TrustAutomationDesigningAppropriate,
	title = {Trust in {Automation}: {Designing} for {Appropriate} {Reliance}},
	volume = {46},
	issn = {0018-7208},
	shorttitle = {Trust in {Automation}},
	url = {https://journals.sagepub.com/doi/abs/10.1518/hfes.46.1.50_30392},
	doi = {10.1518/hfes.46.1.50_30392},
	abstract = {Automation is often problematic because people fail to rely upon it appropriately. Because people respond to technology socially, trust influences reliance on automation. In particular, trust guides reliance when complexity and unanticipated situations make a complete understanding of the automation impractical. This review considers trust from the organizational, sociological, interpersonal, psychological, and neurological perspectives. It considers how the context, automation characteristics, and cognitive processes affect the appropriateness of trust. The context in which the automation is used influences automation performance and provides a goal-oriented perspective to assess automation characteristics along a dimension of attributional abstraction. These characteristics can influence trust through analytic, analogical, and affective processes. The challenges of extrapolating the concept of trust in people to trust in automation are discussed. A conceptual model integrates research regarding trust in automation and describes the dynamics of trust, the role of context, and the influence of display characteristics. Actual or potential applications of this research include improved designs of systems that require people to manage imperfect automation.},
	number = {1},
	urldate = {2021-07-08},
	journal = {Human Factors},
	author = {Lee, John D. and See, Katrina A.},
	month = mar,
	year = {2004},
	note = {Publisher: SAGE Publications Inc},
	pages = {50--80},
}

@article{RealTimeImageSaliency,
	title = {Real {Time} {Image} {Saliency} for {Black} {Box} {Classifiers}},
	url = {http://arxiv.org/abs/1705.07857},
	abstract = {In this work we develop a fast saliency detection method that can be applied to any differentiable image classiﬁer. We train a masking model to manipulate the scores of the classiﬁer by masking salient parts of the input image. Our model generalises well to unseen images and requires a single forward pass to perform saliency detection, therefore suitable for use in real-time systems. We test our approach on CIFAR-10 and ImageNet datasets and show that the produced saliency maps are easily interpretable, sharp, and free of artifacts. We suggest a new metric for saliency and test our method on the ImageNet object localisation task. We achieve results outperforming other weakly supervised methods.},
	language = {en},
	urldate = {2021-07-07},
	journal = {arXiv:1705.07857 [stat]},
	author = {Dabkowski, Piotr and Gal, Yarin},
	month = may,
	year = {2017},
	note = {arXiv: 1705.07857},
}

@article{PerceptionMeasurementHumanrobotTrust,
	title = {The perception and measurement of human-robot trust},
	author = {Schaefer, Kristin},
	year = {2013},
}

@article{RoleTrustAutomationReliance,
	title = {The role of trust in automation reliance},
	volume = {58},
	issn = {10715819},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581903000387},
	doi = {10.1016/S1071-5819(03)00038-7},
	abstract = {A recent and dramatic increase in the use of automation has not yielded comparable improvements in performance. Researchers have found human operators often underutilize (disuse) and overly rely on (misuse) automated aids (Parasuraman and Riley, 1997). Three studies were performed with Cameron University students to explore the relationship among automation reliability, trust, and reliance. With the assistance of an automated decision aid, participants viewed slides of Fort Sill terrain and indicated the presence or absence of a camouﬂaged soldier. Results from the three studies indicate that trust is an important factor in understanding automation reliance decisions. Participants initially considered the automated decision aid trustworthy and reliable. After observing the automated aid make errors, participants distrusted even reliable aids, unless an explanation was provided regarding why the aid might err. Knowing why the aid might err increased trust in the decision aid and increased automation reliance, even when the trust was unwarranted. Our studies suggest a need for future research focused on understanding automation use, examining individual differences in automation reliance, and developing valid and reliable self-report measures of trust in automation.},
	language = {en},
	number = {6},
	urldate = {2021-07-07},
	journal = {International Journal of Human-Computer Studies},
	author = {Dzindolet, Mary T. and Peterson, Scott A. and Pomranky, Regina A. and Pierce, Linda G. and Beck, Hall P.},
	month = jun,
	year = {2003},
	pages = {697--718},
}

@article{AxiomaticAttributionDeepNetworks,
	title = {Axiomatic {Attribution} for {Deep} {Networks}},
	abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms—Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisﬁed by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modiﬁcation to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
	language = {en},
	author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	pages = {10},
}

@article{SmoothGradRemovingNoiseAdding,
	title = {{SmoothGrad}: removing noise by adding noise},
	shorttitle = {{SmoothGrad}},
	url = {http://arxiv.org/abs/1706.03825},
	abstract = {Explaining the output of a deep network remains a challenge. In the case of an image classiﬁer, one type of explanation is to identify pixels that strongly inﬂuence the ﬁnal decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SMOOTHGRAD, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.},
	language = {en},
	urldate = {2021-07-07},
	journal = {arXiv:1706.03825 [cs, stat]},
	author = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Viégas, Fernanda and Wattenberg, Martin},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.03825},
}

@inproceedings{InterpretableExplanationsBlackBoxesb,
	address = {Venice},
	title = {Interpretable {Explanations} of {Black} {Boxes} by {Meaningful} {Perturbation}},
	isbn = {978-1-5386-1032-9},
	url = {http://ieeexplore.ieee.org/document/8237633/},
	doi = {10.1109/ICCV.2017.371},
	abstract = {As machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks “look” in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints.},
	language = {en},
	urldate = {2021-07-07},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Fong, Ruth C. and Vedaldi, Andrea},
	month = oct,
	year = {2017},
	pages = {3449--3457},
}

@article{DeepConvolutionalNetworksVisualising,
	title = {Deep {Inside} {Convolutional} {Networks}: {Visualising} {Image} {Classification} {Models} and {Saliency} {Maps}},
	shorttitle = {Deep {Inside} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1312.6034},
	abstract = {This paper addresses the visualisation of image classiﬁcation models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The ﬁrst one generates an image, which maximises the class score [5], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, speciﬁc to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classiﬁcation ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [13].},
	language = {en},
	urldate = {2021-07-07},
	journal = {arXiv:1312.6034 [cs]},
	author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
	month = apr,
	year = {2014},
	note = {arXiv: 1312.6034},
}

@article{AllModelsAreWrong,
	title = {All {Models} are {Wrong}, but {Many} are {Useful}: {Learning} a {Variable}’s {Importance} by {Studying} an {Entire} {Class} of {Prediction} {Models} {Simultaneously}},
	abstract = {Variable importance (VI) tools describe how much covariates contribute to a prediction model’s accuracy. However, important variables for one well-performing model (for example, a linear model f (x) = xT β with a ﬁxed coeﬃcient vector β) may be unimportant for another model. In this paper, we propose model class reliance (MCR) as the range of VI values across all well-performing model in a prespeciﬁed class. Thus, MCR gives a more comprehensive description of importance by accounting for the fact that many prediction models, possibly of diﬀerent parametric forms, may ﬁt the data well. In the process of deriving MCR, we show several informative results for permutation-based VI estimates, based on the VI measures used in Random Forests. Speciﬁcally, we derive connections between permutation importance estimates for a single prediction model, U-statistics, conditional variable importance, conditional causal eﬀects, and linear model coeﬃcients. We then give probabilistic bounds for MCR, using a novel, generalizable technique. We apply MCR to a public data set of Broward County criminal records to study the reliance of recidivism prediction models on sex and race. In this application, MCR can be used to help inform VI for unknown, proprietary models.},
	language = {en},
	author = {Fisher, Aaron and Rudin, Cynthia and Dominici, Francesca},
	pages = {81},
}

@inproceedings{BrilliantAIDoctorRural,
	address = {Yokohama Japan},
	title = {“{Brilliant} {AI} {Doctor}” in {Rural} {Clinics}: {Challenges} in {AI}-{Powered} {Clinical} {Decision} {Support} {System} {Deployment}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {“{Brilliant} {AI} {Doctor}” in {Rural} {Clinics}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445432},
	doi = {10.1145/3411764.3445432},
	abstract = {Artifcial intelligence (AI) technology has been increasingly used in the implementation of advanced Clinical Decision Support Systems (CDSS). Research demonstrated the potential usefulness of AI-powered CDSS (AI-CDSS) in clinical decision making scenarios. However, post-adoption user perception and experience remain understudied, especially in developing countries. Through observations and interviews with 22 clinicians from 6 rural clinics in China, this paper reports the various tensions between the design of an AI-CDSS system (“Brilliant Doctor”) and the rural clinical context, such as the misalignment with local context and workfow, the technical limitations and usability barriers, as well as issues related to transparency and trustworthiness of AI-CDSS. Despite these tensions, all participants expressed positive attitudes toward the future of AI-CDSS, especially acting as “a doctor’s AI assistant” to realize a Human-AI Collaboration future in clinical settings. Finally we draw on our fndings to discuss implications for designing AI-CDSS interventions for rural clinical contexts in developing countries.},
	language = {en},
	urldate = {2021-07-07},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wang, Dakuo and Wang, Liuping and Zhang, Zhan and Wang, Ding and Zhu, Haiyi and Gao, Yvonne and Fan, Xiangmin and Tian, Feng},
	month = may,
	year = {2021},
	pages = {1--18},
}

@article{HumanAIInteractionHealthcareThree,
	title = {Human-{AI} {Interaction} in {Healthcare}: {Three} {Case} {Studies} {About} {How} {Patient}(s) {And} {Doctors} {Interact} with {AI} in a {Multi}-{Tiers} {Healthcare} {Network}},
	abstract = {This position paper presents three ongoing research projects that aim to study how to design, develop, and evaluate the systems supporting human-AI interaction in the healthcare domain. Collaborating with the local government administrators, hospitals, clinics and doctors, we get a valuable opportunity to study and improve how AI-empowered technologies are changing people's life in providing or receiving healthcare services in a suburb district in Beijing, China. We hope this work will ground the discussion with other participants in the workshop and build further collaborations with the health informatics community.},
	language = {en},
	author = {Li, Yunzhi and Wang, Liuping and Ma, Shuai and Fan, Xiangmin and Wang, Zijun and Jiao, Junfeng and Wang, Dakuo},
	pages = {6},
}

@inproceedings{IdentifyingChallengesOpportunitiesHumanAI,
	address = {Austin TX USA},
	title = {Identifying {Challenges} and {Opportunities} in {Human}-{AI} {Collaboration} in {Healthcare}},
	isbn = {978-1-4503-6692-2},
	url = {https://dl.acm.org/doi/10.1145/3311957.3359433},
	doi = {10.1145/3311957.3359433},
	language = {en},
	urldate = {2021-07-07},
	booktitle = {Conference {Companion} {Publication} of the 2019 on {Computer} {Supported} {Cooperative} {Work} and {Social} {Computing}},
	publisher = {ACM},
	author = {Park, Sun Young and Kuo, Pei-Yi and Barbarin, Andrea and Kaziunas, Elizabeth and Chow, Astrid and Singh, Karandeep and Wilcox, Lauren and Lasecki, Walter S.},
	month = nov,
	year = {2019},
	pages = {506--510},
}

@inproceedings{CapturingTrendsApplicationsIssues,
	address = {Yokohama Japan},
	title = {Capturing the {Trends}, {Applications}, {Issues}, and {Potential} {Strategies} of {Designing} {Transparent} {AI} {Agents}},
	isbn = {978-1-4503-8095-9},
	url = {https://dl.acm.org/doi/10.1145/3411763.3451819},
	doi = {10.1145/3411763.3451819},
	abstract = {With the increasing prevalence of Artifcial Intelligence (AI) agents, the transparency of agents becomes vital in addressing the interaction issues (e.g., explainability and trust). The existing body of research provides valuable theoretical and practical studies in this feld. However, determining the transparency of AI agents requires the systematic consideration of the application categories and automation level, which is hardly considered by the prior literature. We thus apply the bibliometric analysis to gain insights from the published literature. Our work outlines the trend of how the number of studies about AI agent transparency increased over the years. We also identify the major application topics and issues in designing transparent AI agents. Furthermore, we categorize the identifed applications according to the specifc dimensions (risk and timeliness) and put forward potential strategies for designing diferent agents. Besides, we suggest the possible transparency degree corresponding to the automation level.},
	language = {en},
	urldate = {2021-07-06},
	booktitle = {Extended {Abstracts} of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Sun, Lingyun and Li, Zhuoshu and Zhang, Yuyang and Liu, Yanzhen and Lou, Shanghua and Zhou, Zhibin},
	month = may,
	year = {2021},
	keywords = {comps-dm, fatml, xai},
	pages = {1--8},
}

@inproceedings{NegativeRelevanceFeedbackExploratorya,
	address = {Limassol Cyprus},
	title = {Negative {Relevance} {Feedback} for {Exploratory} {Search} with {Visual} {Interactive} {Intent} {Modeling}},
	isbn = {978-1-4503-4348-0},
	url = {https://dl.acm.org/doi/10.1145/3025171.3025222},
	doi = {10.1145/3025171.3025222},
	abstract = {In difﬁcult information seeking tasks, the majority of topranked documents for an initial query may be non-relevant, and negative relevance feedback may then help ﬁnd relevant documents. Traditional negative relevance feedback has been studied on document results; we introduce a system and interface for negative feedback in a novel exploratory search setting, where continuous-valued feedback is directly given to keyword features of an inferred probabilistic user intent model. The introduced system allows both positive and negative feedback directly on an interactive visual interface, by letting the user manipulate keywords on an optimized visualization of modeled user intent. Feedback on the interactive intent model lets the user direct the search: Relevance of keywords is estimated from feedback by Bayesian inference, inﬂuence of feedback is increased by a novel propagation step, documents are retrieved by likelihoods of relevant versus non-relevant intents, and the most relevant keywords (having the highest upper conﬁdence bounds of relevance) and the most non-relevant ones (having the smallest lower conﬁdence bounds of relevance) are shown as options for further feedback. We carry out task-based information seeking experiments with real users on difﬁcult real tasks; we compare the system to the nearest state of the art baseline allowing positive feedback only, and show negative feedback signiﬁcantly improves the quality of retrieved information and user satisfaction for difﬁcult tasks.},
	language = {en},
	urldate = {2021-07-04},
	booktitle = {Proceedings of the 22nd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Peltonen, Jaakko and Strahl, Jonathan and Floréen, Patrik},
	month = mar,
	year = {2017},
	pages = {149--159},
}

@article{StateArtEnhancingTrust,
	title = {The {State} of the {Art} in {Enhancing} {Trust} in {Machine} {Learning} {Models} with the {Use} of {Visualizations}},
	volume = {39},
	issn = {0167-7055, 1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.14034},
	doi = {10.1111/cgf.14034},
	abstract = {Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We deﬁne and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key ﬁndings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneﬁcial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with conﬁdence and conveying meaning to their data.},
	language = {en},
	number = {3},
	urldate = {2021-07-02},
	journal = {Computer Graphics Forum},
	author = {Chatzimparmpas, A. and Martins, R. M. and Jusufi, I. and Kucher, K. and Rossi, F. and Kerren, A.},
	month = jun,
	year = {2020},
	pages = {713--756},
}

@article{DataOthersEyesImpacta,
	title = {Data {Through} {Others}' {Eyes}: {The} {Impact} of {Visualizing} {Others}' {Expectations} on {Visualization} {Interpretation}},
	volume = {24},
	issn = {1941-0506},
	shorttitle = {Data {Through} {Others}' {Eyes}},
	doi = {10.1109/TVCG.2017.2745240},
	abstract = {In addition to visualizing input data, interactive visualizations have the potential to be social artifacts that reveal other people's perspectives on the data. However, how such social information embedded in a visualization impacts a viewer's interpretation of the data remains unknown. Inspired by recent interactive visualizations that display people's expectations of data against the data, we conducted a controlled experiment to evaluate the effect of showing social information in the form of other people's expectations on people's ability to recall the data, the degree to which they adjust their expectations to align with the data, and their trust in the accuracy of the data. We found that social information that exhibits a high degree of consensus lead participants to recall the data more accurately relative to participants who were exposed to the data alone. Additionally, participants trusted the accuracy of the data less and were more likely to maintain their initial expectations when other people's expectations aligned with their own initial expectations but not with the data. We conclude by characterizing the design space for visualizing others' expectations alongside data.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, Yea-Seul and Reinecke, Katharina and Hullman, Jessica},
	month = jan,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	pages = {760--769},
}

@inproceedings{FootprintsHistoryrichToolsInformation,
	address = {Pittsburgh, Pennsylvania, United States},
	title = {Footprints: history-rich tools for information foraging},
	isbn = {978-0-201-48559-2},
	shorttitle = {Footprints},
	url = {http://portal.acm.org/citation.cfm?doid=302979.303060},
	doi = {10.1145/302979.303060},
	abstract = {Inspired by Hill and Hollan’s original work [7], we have been developing a theory of interaction history and building tools to apply this theory to navigation in a complex information space. We have built a series of tools - map, paths, annotations and signposts - based on a physical-world navigation metaphor. These tools have been in use for over a year. Our user study involved a controlled browse task and showed that users were able to get the same amount of work done with significantly less effort.},
	language = {en},
	urldate = {2021-07-05},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems the {CHI} is the limit - {CHI} '99},
	publisher = {ACM Press},
	author = {Wexelblat, Alan and Maes, Pattie},
	year = {1999},
	pages = {270--277},
}

@inproceedings{FindingSocialRolesWikipedia,
	address = {Seattle Washington USA},
	title = {Finding social roles in {Wikipedia}},
	isbn = {978-1-4503-0121-3},
	url = {https://dl.acm.org/doi/10.1145/1940761.1940778},
	doi = {10.1145/1940761.1940778},
	abstract = {This paper investigates some of the social roles people play in the online community of Wikipedia. We start from qualitative comments posted on community oriented pages, wiki project memberships, and user talk pages in order to identify a sample of editors who represent four key roles: substantive experts, technical editors, vandal fighters, and social networkers. Patterns in edit histories and egocentric network visualizations suggest potential “structural signatures” that could be used as quantitative indicators of role adoption. Using simple metrics based on edit histories we compare two samples of Wikipedians: a collection of long term dedicated editors, and a cohort of editors from a one month window of new arrivals. According to these metrics, we find that the proportions of editor types in the new cohort are similar those observed in the sample of dedicated contributors. The number of new editors playing helpful roles in a single month’s cohort nearly equal the number found in the dedicated sample. This suggests that informal socialization has the potential provide sufficient role related labor despite growth and change in Wikipedia. These results are preliminary, and we describe several ways that the method can be improved, including the expansion and refinement of role signatures and identification of other important social roles.},
	language = {en},
	urldate = {2021-07-05},
	booktitle = {Proceedings of the 2011 {iConference}},
	publisher = {ACM},
	author = {Welser, Howard T. and Cosley, Dan and Kossinets, Gueorgi and Lin, Austin and Dokshin, Fedor and Gay, Geri and Smith, Marc},
	month = feb,
	year = {2011},
	pages = {122--129},
}

@article{ModelAgnosticInterpretabilityMachineLearning,
	title = {Model-{Agnostic} {Interpretability} of {Machine} {Learning}},
	url = {http://arxiv.org/abs/1606.05386},
	abstract = {Understanding why machine learning models behave the way they do empowers both system designers and end-users in many ways: in model selection, feature engineering, in order to trust and act upon the predictions, and in more intuitive user interfaces. Thus, interpretability has become a vital concern in machine learning, and work in the area of interpretable models has found renewed interest. In some applications, such models are as accurate as non-interpretable ones, and thus are preferred for their transparency. Even when they are not accurate, they may still be preferred when interpretability is of paramount importance. However, restricting machine learning to interpretable models is often a severe limitation. In this paper we argue for explaining machine learning predictions using model-agnostic approaches. By treating the machine learning models as black-box functions, these approaches provide crucial flexibility in the choice of models, explanations, and representations, improving debugging, comparison, and interfaces for a variety of users and models. We also outline the main challenges for such methods, and review a recently-introduced model-agnostic explanation approach (LIME) that addresses these challenges.},
	language = {en},
	urldate = {2021-07-05},
	journal = {arXiv:1606.05386 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.05386},
}

@article{SurveyHumanCenteredEvaluationsHumanCentered,
	title = {A {Survey} of {Human}-{Centered} {Evaluations} in {Human}-{Centered} {Machine} {Learning}},
	volume = {40},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14329},
	doi = {10.1111/cgf.14329},
	abstract = {Visual analytics systems integrate interactive visualizations and machine learning to enable expert users to solve complex analysis tasks. Applications combine techniques from various fields of research and are consequently not trivial to evaluate. The result is a lack of structure and comparability between evaluations. In this survey, we provide a comprehensive overview of evaluations in the field of human-centered machine learning. We particularly focus on human-related factors that influence trust, interpretability, and explainability. We analyze the evaluations presented in papers from top conferences and journals in information visualization and human-computer interaction to provide a systematic review of their setup and findings. From this survey, we distill design dimensions for structured evaluations, identify evaluation gaps, and derive future research opportunities.},
	language = {en},
	number = {3},
	urldate = {2021-07-04},
	journal = {Computer Graphics Forum},
	author = {Sperrle, F. and El-Assady, M. and Guo, G. and Borgo, R. and Chau, D. Horng and Endert, A. and Keim, D.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14329},
	keywords = {survey, xai},
	pages = {543--567},
}

@inproceedings{DecisionMakingBidirectionalCommunicationSequential,
	address = {Cambridge United Kingdom},
	title = {Decision-{Making} for {Bidirectional} {Communication} in {Sequential} {Human}-{Robot} {Collaborative} {Tasks}},
	isbn = {978-1-4503-6746-2},
	url = {https://dl.acm.org/doi/10.1145/3319502.3374779},
	doi = {10.1145/3319502.3374779},
	abstract = {Communication is critical to collaboration; however, too much of it can degrade performance. Motivated by the need for effective use of a robot’s communication modalities, in this work, we present a computational framework that decides if, when, and what to communicate during human-robot collaboration. The framework, titled CommPlan, consists of a model specification process and an execution-time POMDP planner. To address the challenge of collecting interaction data, the model specification process is hybrid: where part of the model is learned from data, while the remainder is manually specified. Given the model, the robot’s decision-making is performed computationally during interaction and under partial observability of human’s mental states. We implement CommPlan for a shared workspace task, in which the robot has multiple communication options and needs to reason within a short time. Through experiments with human participants, we confirm that CommPlan results in the effective use of communication capabilities and improves human-robot collaboration.},
	language = {en},
	urldate = {2021-07-04},
	booktitle = {Proceedings of the 2020 {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {ACM},
	author = {Unhelkar, Vaibhav V. and Li, Shen and Shah, Julie A.},
	month = mar,
	year = {2020},
	keywords = {comps-sc, hmi, sc},
	pages = {329--341},
}

@article{TagsplanationsExplainingRecommendationsUsing,
	title = {Tagsplanations: {Explaining} {Recommendations} {Using} {Tags}},
	abstract = {While recommender systems tell users what items they might like, explanations of recommendations reveal why they might like them. Explanations provide many beneﬁts, from improving user satisfaction to helping users make better decisions. This paper introduces tagsplanations, which are explanations based on community tags. Tagsplanations have two key components: tag relevance, the degree to which a tag describes an item, and tag preference, the user’s sentiment toward a tag. We develop novel algorithms for estimating tag relevance and tag preference, and we conduct a user study exploring the roles of tag relevance and tag preference in promoting effective tagsplanations. We also examine which types of tags are most useful for tagsplanations.},
	language = {en},
	author = {Vig, Jesse and Sen, Shilad and Riedl, John},
	pages = {10},
}

@inproceedings{StudyingCooperationConflictAuthors,
	address = {Vienna, Austria},
	title = {Studying cooperation and conflict between authors with \textit{history flow} visualizations},
	isbn = {978-1-58113-702-6},
	url = {http://portal.acm.org/citation.cfm?doid=985692.985765},
	doi = {10.1145/985692.985765},
	abstract = {The Internet has fostered an unconventional and powerful style of collaboration: “wiki” web sites, where every visitor has the power to become an editor. In this paper we investigate the dynamics of Wikipedia, a prominent, thriving wiki. We make three contributions. First, we introduce a new exploratory data analysis tool, the history flow visualization, which is effective in revealing patterns within the wiki context and which we believe will be useful in other collaborative situations as well. Second, we discuss several collaboration patterns highlighted by this visualization tool and corroborate them with statistical analysis. Third, we discuss the implications of these patterns for the design and governance of online collaborative social spaces. We focus on the relevance of authorship, the value of community surveillance in ameliorating antisocial behavior, and how authors with competing perspectives negotiate their differences.},
	language = {en},
	urldate = {2020-10-25},
	booktitle = {Proceedings of the 2004 conference on {Human} factors in computing systems  - {CHI} '04},
	publisher = {ACM Press},
	author = {Viégas, Fernanda B. and Wattenberg, Martin and Dave, Kushal},
	year = {2004},
	keywords = {comps-sc, iml},
	pages = {575--582},
}

@inproceedings{ClassifyingDiscriminating,
	title = {Classifying without discriminating},
	doi = {10.1109/IC4.2009.4909197},
	abstract = {Classification models usually make predictions on the basis of training data. If the training data is biased towards certain groups or classes of objects, e.g., there is racial discrimination towards black people, the learned model will also show discriminatory behavior towards that particular community. This partial attitude of the learned model may lead to biased outcomes when labeling future unlabeled data objects. Often, however, impartial classification results are desired or even required by law for future data objects in spite of having biased training data. In this paper, we tackle this problem by introducing a new classification scheme for learning unbiased models on biased training data. Our method is based on massaging the dataset by making the least intrusive modifications which lead to an unbiased dataset. On this modified dataset we then learn a non-discriminating classifier. The proposed method has been implemented and experimental results on a credit approval dataset show promising results: in all experiments our method is able to reduce the prejudicial behavior for future classification significantly without loosing too much predictive accuracy.},
	booktitle = {Control and {Communication} 2009 2nd {International} {Conference} on {Computer}},
	author = {Kamiran, Faisal and Calders, Toon},
	month = feb,
	year = {2009},
	keywords = {comps-dm, fair, fatml, vis},
	pages = {1--6},
}

@inproceedings{ShouldCollegeDropoutPrediction,
	address = {Virtual Event Germany},
	title = {Should {College} {Dropout} {Prediction} {Models} {Include} {Protected} {Attributes}?},
	isbn = {978-1-4503-8215-1},
	url = {https://dl.acm.org/doi/10.1145/3430895.3460139},
	doi = {10.1145/3430895.3460139},
	abstract = {Early identiﬁcation of college dropouts can provide tremendous value for improving student success and institutional effectiveness, and predictive analytics are increasingly used for this purpose. However, ethical concerns have emerged about whether including protected attributes in these prediction models discriminates against underrepresented student groups and exacerbates existing inequities. We examine this issue in the context of a large U.S. research university with both residential and fully online degree-seeking students. Based on comprehensive institutional records for the entire student population across multiple years (N = 93,457), we build machine learning models to predict student dropout after one academic year of study and compare the overall performance and fairness of model predictions with or without four protected attributes (gender, URM, ﬁrst-generation student, and high ﬁnancial need). We ﬁnd that including protected attributes does not impact the overall prediction performance and it only marginally improves the algorithmic fairness of predictions. These ﬁndings suggest that including protected attributes is preferable. We offer guidance on how to evaluate the impact of including protected attributes in a local context, where institutional stakeholders seek to leverage predictive analytics to support student success.},
	language = {en},
	urldate = {2021-07-04},
	booktitle = {Proceedings of the {Eighth} {ACM} {Conference} on {Learning} @ {Scale}},
	publisher = {ACM},
	author = {Yu, Renzhe and Lee, Hansol and Kizilcec, René F.},
	month = jun,
	year = {2021},
	pages = {91--100},
}

@article{AccurateFairPredictionCollege,
	title = {Towards {Accurate} and {Fair} {Prediction} of {College} {Success}: {Evaluating} {Different} {Sources} of {Student} {Data}},
	abstract = {In higher education, predictive analytics can provide actionable insights to diverse stakeholders such as administrators, instructors, and students. Separate feature sets are typically used for diﬀerent prediction tasks, e.g., student activity logs for predicting in-course performance and registrar data for predicting long-term college success. However, little is known about the overall utility of diﬀerent data sources across prediction tasks and the fairness of their predictions with respect to diﬀerent subpopulations. Using data from over 2,000 college students at a large public university, we examined the utility of institutional data, learning management system (LMS) data, and survey data for accurately and fairly predicting short-term and long-term student success. We found that institutional data and LMS data both have decent predictive power, but survey data shows very little predictive utility. Combining institutional data with LMS data leads to even higher accuracy than using either alone. In terms of fairness, using institutional data consistently underestimates historically disadvantaged student subpopulations more than their peers, whereas LMS data tend to overestimate some of these groups more often. Combining the two data sources does not fully neutralize the biases and still leads to high rates of underestimation among disadvantaged groups. Moreover, algorithmic biases aﬀect not only demographic minorities but also students with acquired disadvantages. These analyses serve to inform more cost-eﬀective and equitable use of student data for predictive analytics applications in higher education.},
	language = {en},
	author = {Yu, Renzhe and Li, Qiujie and Fischer, Christian},
	year = {2020},
	pages = {10},
}

@article{AlgorithmicFairness,
	title = {Algorithmic {Fairness}},
	volume = {108},
	issn = {2574-0768},
	url = {https://www.jstor.org/stable/26452698},
	urldate = {2021-07-04},
	journal = {AEA Papers and Proceedings},
	author = {Kleinberg, Jon and Ludwig, Jens and Mullainathan, Sendhil and Rambachan, Ashesh},
	year = {2018},
	note = {Publisher: American Economic Association},
	pages = {22--27},
}

@article{DoesMitigatingMLImpact,
	title = {Does mitigating {ML}'s impact disparity require treatment disparity?},
	abstract = {Following precedent in employment discrimination law, two notions of disparity are widely-discussed in papers on fairness and ML. Algorithms exhibit treatment disparity if they formally treat members of protected subgroups differently; algorithms exhibit impact disparity when outcomes differ across subgroups (even unintentionally). Naturally, we can achieve impact parity through purposeful treatment disparity. One line of papers aims to reconcile the two parities proposing disparate learning processes (DLPs). Here, the sensitive feature is used during training but a group-blind classiﬁer is produced. In this paper, we show that: (i) when sensitive and (nominally) nonsensitive features are correlated, DLPs will indirectly implement treatment disparity, undermining the policy desiderata they are designed to address; (ii) when group membership is partly revealed by other features, DLPs induce within-class discrimination; and (iii) in general, DLPs provide suboptimal trade-offs between accuracy and impact parity. Experimental results on several real-world datasets highlight the practical consequences of applying DLPs.},
	language = {en},
	author = {Lipton, Zachary and McAuley, Julian and Chouldechova, Alexandra},
	pages = {11},
}

@inproceedings{AlgorithmicDecisionMakingCost,
	address = {Halifax NS Canada},
	title = {Algorithmic {Decision} {Making} and the {Cost} of {Fairness}},
	isbn = {978-1-4503-4887-4},
	url = {https://dl.acm.org/doi/10.1145/3097983.3098095},
	doi = {10.1145/3097983.3098095},
	abstract = {Algorithms are now regularly used to decide whether defendants awaiting trial are too dangerous to be released back into the community. In some cases, black defendants are substantially more likely than white defendants to be incorrectly classi ed as high risk. To mitigate such disparities, several techniques have recently been proposed to achieve algorithmic fairness. Here we reformulate algorithmic fairness as constrained optimization: the objective is to maximize public safety while satisfying formal fairness constraints designed to reduce racial disparities. We show that for several past de nitions of fairness, the optimal algorithms that result require detaining defendants above race-speci c risk thresholds. We further show that the optimal unconstrained algorithm requires applying a single, uniform threshold to all defendants. e unconstrained algorithm thus maximizes public safety while also satisfying one important understanding of equality: that all individuals are held to the same standard, irrespective of race. Because the optimal constrained and unconstrained algorithms generally di er, there is tension between improving public safety and satisfying prevailing notions of algorithmic fairness. By examining data from Broward County, Florida, we show that this trade-o can be large in practice. We focus on algorithms for pretrial release decisions, but the principles we discuss apply to other domains, and also to human decision makers carrying out structured decision rules.},
	language = {en},
	urldate = {2021-07-04},
	booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Corbett-Davies, Sam and Pierson, Emma and Feller, Avi and Goel, Sharad and Huq, Aziz},
	month = aug,
	year = {2017},
	pages = {797--806},
}

@article{ThreeNaiveBayesApproachesa,
	title = {Three naive {Bayes} approaches for discrimination-free classification},
	volume = {21},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-010-0190-x},
	doi = {10.1007/s10618-010-0190-x},
	abstract = {In this paper, we investigate how to modify the naive Bayes classiﬁer in order to perform classiﬁcation that is restricted to be independent with respect to a given sensitive attribute. Such independency restrictions occur naturally when the decision process leading to the labels in the data-set was biased; e.g., due to gender or racial discrimination. This setting is motivated by many cases in which there exist laws that disallow a decision that is partly based on discrimination. Naive application of machine learning techniques would result in huge ﬁnes for companies. We present three approaches for making the naive Bayes classiﬁer discrimination-free: (i) modifying the probability of the decision being positive, (ii) training one model for every sensitive attribute value and balancing them, and (iii) adding a latent variable to the Bayesian model that represents the unbiased label and optimizing the model parameters for likelihood using expectation maximization. We present experiments for the three approaches on both artiﬁcial and real-life data.},
	language = {en},
	number = {2},
	urldate = {2021-07-02},
	journal = {Data Mining and Knowledge Discovery},
	author = {Calders, Toon and Verwer, Sicco},
	month = sep,
	year = {2010},
	keywords = {comps-dm, dm, fair},
	pages = {277--292},
}

@article{VariationalFairAutoencoder,
	title = {The {Variational} {Fair} {Autoencoder}},
	url = {http://arxiv.org/abs/1511.00830},
	abstract = {We investigate the problem of learning representations that are invariant to certain nuisance or sensitive factors of variation in the data while retaining as much of the remaining information as possible. Our model is based on a variational autoencoding architecture with priors that encourage independence between sensitive and latent factors of variation. Any subsequent processing, such as classification, can then be performed on this purged latent representation. To remove any remaining dependencies we incorporate an additional penalty term based on the "Maximum Mean Discrepancy" (MMD) measure. We discuss how these architectures can be efficiently trained on data and show in experiments that this method is more effective than previous work in removing unwanted sources of variation while maintaining informative latent representations.},
	urldate = {2021-07-02},
	journal = {arXiv:1511.00830 [cs, stat]},
	author = {Louizos, Christos and Swersky, Kevin and Li, Yujia and Welling, Max and Zemel, Richard},
	month = aug,
	year = {2017},
	note = {arXiv: 1511.00830},
	keywords = {comps-dm, dm, fair},
}

@article{REVISEToolMeasuringMitigating,
	title = {{REVISE}: {A} {Tool} for {Measuring} and {Mitigating} {Bias} in {Visual} {Datasets}},
	shorttitle = {{REVISE}},
	url = {http://arxiv.org/abs/2004.07999},
	abstract = {Machine learning models are known to perpetuate and even amplify the biases present in the data. However, these data biases frequently do not become apparent until after the models are deployed. To tackle this issue and to enable the preemptive analysis of large-scale dataset, we present our tool. REVISE (REvealing VIsual biaSEs) is a tool that assists in the investigation of a visual dataset, surfacing potential biases currently along three dimensions: (1) object-based, (2) gender-based, and (3) geography-based. Object-based biases relate to size, context, or diversity of object representation. Gender-based metrics aim to reveal the stereotypical portrayal of people of different genders. Geography-based analyses consider the representation of different geographic locations. REVISE sheds light on the dataset along these dimensions; the responsibility then lies with the user to consider the cultural and historical context, and to determine which of the revealed biases may be problematic. The tool then further assists the user by suggesting actionable steps that may be taken to mitigate the revealed biases. Overall, the key aim of our work is to tackle the machine learning bias problem early in the pipeline. REVISE is available at https://github.com/princetonvisualai/revise-tool},
	urldate = {2021-07-02},
	journal = {arXiv:2004.07999 [cs]},
	author = {Wang, Angelina and Narayanan, Arvind and Russakovsky, Olga},
	month = aug,
	year = {2020},
	note = {arXiv: 2004.07999},
	keywords = {comps-dm, fair, hci},
}

@article{RelationAccuracyFairnessBinary,
	title = {On the relation between accuracy and fairness in binary classification},
	url = {http://arxiv.org/abs/1505.05723},
	abstract = {Our study revisits the problem of accuracy-fairness tradeoff in binary classification. We argue that comparison of non-discriminatory classifiers needs to account for different rates of positive predictions, otherwise conclusions about performance may be misleading, because accuracy and discrimination of naive baselines on the same dataset vary with different rates of positive predictions. We provide methodological recommendations for sound comparison of non-discriminatory classifiers, and present a brief theoretical and empirical analysis of tradeoffs between accuracy and non-discrimination.},
	urldate = {2021-07-04},
	journal = {arXiv:1505.05723 [cs]},
	author = {Zliobaite, Indre},
	month = may,
	year = {2015},
	note = {arXiv: 1505.05723},
}

@article{ProblemInframarginalityOutcomeTests,
	title = {The problem of infra-marginality in outcome tests for discrimination},
	volume = {11},
	issn = {1932-6157},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-11/issue-3/The-problem-of-infra-marginality-in-outcome-tests-for-discrimination/10.1214/17-AOAS1058.full},
	doi = {10.1214/17-AOAS1058},
	language = {en},
	number = {3},
	urldate = {2021-07-04},
	journal = {The Annals of Applied Statistics},
	author = {Simoiu, Camelia and Corbett-Davies, Sam and Goel, Sharad},
	month = sep,
	year = {2017},
	keywords = {vis},
}

@article{AvoidingDiscriminationCausalReasoning,
	title = {Avoiding {Discrimination} through {Causal} {Reasoning}},
	url = {http://arxiv.org/abs/1706.02744},
	abstract = {Recent work on fairness in machine learning has focused on various statistical discrimination criteria and how they trade off. Most of these criteria are observational: They depend only on the joint distribution of predictor, protected attribute, features, and outcome. While convenient to work with, observational criteria have severe inherent limitations that prevent them from resolving matters of fairness conclusively. Going beyond observational criteria, we frame the problem of discrimination based on protected attributes in the language of causal reasoning. This viewpoint shifts attention from "What is the right fairness criterion?" to "What do we want to assume about the causal data generating process?" Through the lens of causality, we make several contributions. First, we crisply articulate why and when observational criteria fail, thus formalizing what was before a matter of opinion. Second, our approach exposes previously ignored subtleties and why they are fundamental to the problem. Finally, we put forward natural causal non-discrimination criteria and develop algorithms that satisfy them.},
	urldate = {2021-07-03},
	journal = {arXiv:1706.02744 [cs, stat]},
	author = {Kilbertus, Niki and Rojas-Carulla, Mateo and Parascandolo, Giambattista and Hardt, Moritz and Janzing, Dominik and Schölkopf, Bernhard},
	month = jan,
	year = {2018},
	note = {arXiv: 1706.02744},
	keywords = {comps-dm, fair, fatml},
}

@inproceedings{ModelingReviewComments,
	title = {Modeling review comments},
	booktitle = {Proceedings of the 50th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Long} {Papers}-{Volume} 1},
	publisher = {Association for Computational Linguistics},
	author = {Mukherjee, Arjun and Liu, Bing},
	year = {2012},
	pages = {320--329},
}

@inproceedings{SemEval2016TaskDetectingStance,
	title = {{SemEval}-2016 {Task} 6: {Detecting} {Stance} in {Tweets}.},
	shorttitle = {{SemEval}-2016 {Task} 6},
	booktitle = {{SemEval}@ {NAACL}-{HLT}},
	author = {Mohammad, Saif and Kiritchenko, Svetlana and Sobhani, Parinaz and Zhu, Xiao-Dan and Cherry, Colin},
	year = {2016},
	pages = {31--41},
}

@article{SurveyInformationVisualizationRecent,
	title = {A survey on information visualization: recent advances and challenges},
	volume = {30},
	issn = {0178-2789, 1432-2315},
	shorttitle = {A survey on information visualization},
	url = {http://link.springer.com/10.1007/s00371-013-0892-3},
	doi = {10.1007/s00371-013-0892-3},
	language = {en},
	number = {12},
	urldate = {2017-11-22},
	journal = {The Visual Computer},
	author = {Liu, Shixia and Cui, Weiwei and Wu, Yingcai and Liu, Mengchen},
	month = dec,
	year = {2014},
	pages = {1373--1393},
}

@inproceedings{ProceedingsFirstWorkshopArgumentation,
	title = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	booktitle = {Proceedings of the {First} {Workshop} on {Argumentation} {Mining}},
	author = {Green, Nancy and Ashley, Kevin and Litman, Diane and Reed, Chris and Walker, Vern},
	year = {2014},
}

@article{HierarchicalAggregationInformationVisualizationb,
	title = {Hierarchical {Aggregation} for {Information} {Visualization}: {Overview}, {Techniques}, and {Design} {Guidelines}},
	volume = {16},
	issn = {1077-2626},
	shorttitle = {Hierarchical {Aggregation} for {Information} {Visualization}},
	url = {http://ieeexplore.ieee.org/document/5184827/},
	doi = {10.1109/TVCG.2009.84},
	number = {3},
	urldate = {2017-11-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Elmqvist, N. and Fekete, J.-D.},
	month = may,
	year = {2010},
	keywords = {vis},
	pages = {439--454},
}

@article{DomainsUncertaintyVisualizationResearch,
	title = {Domains of uncertainty visualization research: a visual summary approach},
	volume = {44},
	issn = {1523-0406, 1545-0465},
	shorttitle = {Domains of uncertainty visualization research},
	url = {https://www.tandfonline.com/doi/full/10.1080/15230406.2016.1154804},
	doi = {10.1080/15230406.2016.1154804},
	language = {en},
	number = {4},
	urldate = {2017-11-24},
	journal = {Cartography and Geographic Information Science},
	author = {Smith Mason, Jennifer and Retchless, David and Klippel, Alexander},
	month = jul,
	year = {2017},
	keywords = {vis},
	pages = {296--309},
}

@article{ChronodesInteractiveMultifocusExploration,
	title = {Chronodes: {Interactive} {Multi}-focus {Exploration} of {Event} {Sequences}},
	shorttitle = {Chronodes},
	journal = {arXiv preprint arXiv:1609.08535},
	author = {Polack Jr, Peter J. and Chen, Shang-Tse and Kahng, Minsuk and de Barbaro, Kaya and Sharmin, Moushumi and Basole, Rahul and Chau, Duen Horng},
	year = {2016},
	keywords = {vis},
}

@inproceedings{SupportOpposeClassifyingPositions,
	title = {Support or oppose?: classifying positions in online debates from reply activities and opinion expressions},
	shorttitle = {Support or oppose?},
	booktitle = {Proceedings of the 23rd {International} {Conference} on {Computational} {Linguistics}: {Posters}},
	publisher = {Association for Computational Linguistics},
	author = {Murakami, Akiko and Raymond, Rudy},
	year = {2010},
	pages = {869--875},
}

@article{DimensionProjectionMatrixTreea,
	title = {Dimension projection matrix/tree: {Interactive} subspace visual exploration and analysis of high dimensional data},
	volume = {19},
	shorttitle = {Dimension projection matrix/tree},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Yuan, Xiaoru and Ren, Donghao and Wang, Zuchao and Guo, Cong},
	year = {2013},
	keywords = {vis},
	pages = {2625--2633},
}

@article{MeasuringFairnessRankedOutputs,
	title = {Measuring {Fairness} in {Ranked} {Outputs}},
	url = {http://arxiv.org/abs/1610.08559},
	abstract = {Ranking and scoring are ubiquitous. We consider the setting in which an institution, called a ranker, evaluates a set of individuals based on demographic, behavioral or other characteristics. The final output is a ranking that represents the relative quality of the individuals. While automatic and therefore seemingly objective, rankers can, and often do, discriminate against individuals and systematically disadvantage members of protected groups. This warrants a careful study of the fairness of a ranking scheme. In this paper we propose fairness measures for ranked outputs. We develop a data generation procedure that allows us to systematically control the degree of unfairness in the output, and study the behavior of our measures on these datasets. We then apply our proposed measures to several real datasets, and demonstrate cases of unfairness. Finally, we show preliminary results of incorporating our ranked fairness measures into an optimization framework, and show potential for improving fairness of ranked outputs while maintaining accuracy.},
	urldate = {2017-11-23},
	journal = {arXiv:1610.08559 [cs]},
	author = {Yang, Ke and Stoyanovich, Julia},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.08559},
	keywords = {fatml, ranking},
}

@article{RankingFairnessConstraints,
	title = {Ranking with {Fairness} {Constraints}},
	url = {http://arxiv.org/abs/1704.06840},
	abstract = {The problem of ranking a set of items is a fundamental algorithmic task in today's data-driven world. Ranking algorithms lie at the core of applications such as search engines, news feeds, and recommendation systems. However, recent events and studies show that bias exists in the output of such applications. This results in unfairness or decreased diversity in the presentation of the content and can exacerbate stereotypes and manipulate perceptions. Motivated by these concerns, in this paper we introduce a framework for incorporating fairness in ranking problems. In our model, we are given a collection of items along with 1) the value of placing an item at a particular position, 2) the collection of possibly non-disjoint attributes (e.g., gender and ethnicity or genre and price point depending on the context) of each item and 3) a collection of fairness constraints that bound the number of items with each attribute that are allowed to appear in the top positions of the ranking. The goal is to output a ranking that maximizes value while respecting the fairness constraints. We present algorithms along with complementary hardness results which, together, come close to settling the complexity of this constrained ranking maximization problem.},
	urldate = {2017-11-23},
	journal = {arXiv:1704.06840 [cs]},
	author = {Celis, L. Elisa and Straszak, Damian and Vishnoi, Nisheeth K.},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.06840},
	keywords = {fatml, ranking},
}

@article{ThemismlFairnessawareMachineLearning,
	title = {Themis-ml: {A} {Fairness}-aware {Machine} {Learning} {Interface} for {End}-to-end {Discrimination} {Discovery} and {Mitigation}},
	shorttitle = {Themis-ml},
	url = {http://arxiv.org/abs/1710.06921},
	abstract = {As more industries integrate machine learning into socially sensitive decision processes like hiring, loan-approval, and parole-granting, we are at risk of perpetuating historical and contemporary socioeconomic disparities. This is a critical problem because on the one hand, organizations who use but do not understand the discriminatory potential of such systems will facilitate the widening of social disparities under the assumption that algorithms are categorically objective. On the other hand, the responsible use of machine learning can help us measure, understand, and mitigate the implicit historical biases in socially sensitive data by expressing implicit decision-making mental models in terms of explicit statistical models. In this paper we specify, implement, and evaluate a "fairness-aware" machine learning interface called themis-ml, which is intended for use by individual data scientists and engineers, academic research teams, or larger product teams who use machine learning in production systems.},
	urldate = {2017-11-23},
	journal = {arXiv:1710.06921 [cs]},
	author = {Bantilan, Niels},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.06921},
	keywords = {fatml, vis},
}

@article{ExposureIdeologicallyDiverseNews,
	title = {Exposure to ideologically diverse news and opinion on {Facebook}},
	volume = {348},
	number = {6239},
	journal = {Science},
	author = {Bakshy, Eytan and Messing, Solomon and Adamic, Lada A.},
	year = {2015},
	keywords = {diverse, fatml, ranking},
	pages = {1130--1132},
}

@article{MultidisciplinarySurveyDiscriminationAnalysis,
	title = {A multidisciplinary survey on discrimination analysis},
	volume = {29},
	issn = {0269-8889, 1469-8005},
	url = {http://www.journals.cambridge.org/abstract_S0269888913000039},
	doi = {10.1017/S0269888913000039},
	language = {en},
	number = {05},
	urldate = {2017-11-27},
	journal = {The Knowledge Engineering Review},
	author = {Romei, Andrea and Ruggieri, Salvatore},
	month = nov,
	year = {2014},
	keywords = {fatml, xai},
	pages = {582--638},
}

@article{FalsePositivesFalseNegatives,
	title = {False {Positives}, {False} {Negatives}, and {False} {Analyses}: {A} {Rejoinder} to {Machine} {Bias}: {There}'s {Software} {Used} across the {Country} to {Predict} {Future} {Criminals}. {And} {It}'s {Biased} against {Blacks}},
	volume = {80},
	shorttitle = {False {Positives}, {False} {Negatives}, and {False} {Analyses}},
	journal = {Fed. Probation},
	author = {Flores, Anthony W. and Bechtel, Kristin and Lowenkamp, Christopher T.},
	year = {2016},
	keywords = {fatml, xai},
	pages = {38},
}

@article{SurveyMeasuringIndirectDiscrimination,
	title = {A survey on measuring indirect discrimination in machine learning},
	url = {http://arxiv.org/abs/1511.00148},
	abstract = {Nowadays, many decisions are made using predictive models built on historical data.Predictive models may systematically discriminate groups of people even if the computing process is fair and well-intentioned. Discrimination-aware data mining studies how to make predictive models free from discrimination, when historical data, on which they are built, may be biased, incomplete, or even contain past discriminatory decisions. Discrimination refers to disadvantageous treatment of a person based on belonging to a category rather than on individual merit. In this survey we review and organize various discrimination measures that have been used for measuring discrimination in data, as well as in evaluating performance of discrimination-aware predictive models. We also discuss related measures from other disciplines, which have not been used for measuring discrimination, but potentially could be suitable for this purpose. We computationally analyze properties of selected measures. We also review and discuss measuring procedures, and present recommendations for practitioners. The primary target audience is data mining, machine learning, pattern recognition, statistical modeling researchers developing new methods for non-discriminatory predictive modeling. In addition, practitioners and policy makers would use the survey for diagnosing potential discrimination by predictive models.},
	urldate = {2017-11-27},
	journal = {arXiv:1511.00148 [cs, stat]},
	author = {Zliobaite, Indre},
	month = oct,
	year = {2015},
	note = {arXiv: 1511.00148},
	keywords = {fair, fatml, survey, xai},
}

@inproceedings{StudyTopkMeasuresDiscrimination,
	title = {A study of top-k measures for discrimination discovery},
	booktitle = {Proceedings of the 27th {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {ACM},
	author = {Pedreschi, Dino and Ruggieri, Salvatore and Turini, Franco},
	year = {2012},
	keywords = {fair, fatml, ranking, xai},
	pages = {126--131},
}

@article{ComparingTopLists,
	title = {Comparing top k lists},
	volume = {17},
	number = {1},
	journal = {SIAM Journal on discrete mathematics},
	author = {Fagin, Ronald and Kumar, Ravi and Sivakumar, Dakshinamurthi},
	year = {2003},
	keywords = {fatml, ranking, xai},
	pages = {134--160},
}

@article{DeeperUnderstandingVisualizationKeyword,
	title = {Toward a deeper understanding of {Visualization} through keyword analysis},
	journal = {arXiv preprint arXiv:1408.3297},
	author = {Isenberg, Petra and Isenberg, Tobias and Sedlmair, Michael and Chen, Jian and Möller, Torsten},
	year = {2014},
	keywords = {vis},
}

@article{LineupVisualAnalysisMultiattribute,
	title = {Lineup: {Visual} analysis of multi-attribute rankings},
	volume = {19},
	shorttitle = {Lineup},
	number = {12},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Gratzl, Samuel and Lex, Alexander and Gehlenborg, Nils and Pfister, Hanspeter and Streit, Marc},
	year = {2013},
	keywords = {vis},
	pages = {2277--2286},
}

@phdthesis{StanceDetectionAnalysisSocial,
	title = {Stance {Detection} and {Analysis} in {Social} {Media}},
	school = {Université d'Ottawa/University of Ottawa},
	author = {Sobhani, Parinaz},
	year = {2017},
}

@article{AlgebraicProcessVisualizationDesign,
	title = {An {Algebraic} {Process} for {Visualization} {Design}},
	volume = {20},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/6875930/},
	doi = {10.1109/TVCG.2014.2346325},
	number = {12},
	urldate = {2017-11-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kindlmann, Gordon and Scheidegger, Carlos},
	month = dec,
	year = {2014},
	keywords = {vis},
	pages = {2181--2190},
}

@article{DominoExtractingComparingManipulatinga,
	title = {Domino: {Extracting}, {Comparing}, and {Manipulating} {Subsets} {Across} {Multiple} {Tabular} {Datasets}},
	volume = {20},
	issn = {1077-2626},
	shorttitle = {Domino},
	url = {http://ieeexplore.ieee.org/document/6875920/},
	doi = {10.1109/TVCG.2014.2346260},
	number = {12},
	urldate = {2017-11-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Gratzl, Samuel and Gehlenborg, Nils and Lex, Alexander and Pfister, Hanspeter and Streit, Marc},
	month = dec,
	year = {2014},
	keywords = {vis},
	pages = {2023--2032},
}

@article{CommunityDiscoveryDynamicNetworks,
	title = {Community {Discovery} in {Dynamic} {Networks}: a {Survey}},
	shorttitle = {Community {Discovery} in {Dynamic} {Networks}},
	journal = {arXiv preprint arXiv:1707.03186},
	author = {Rossetti, Giulio and Cazabet, Rémy},
	year = {2017},
	keywords = {dm-clustering},
}

@inproceedings{FAIRFairTopk,
	title = {{FA}*{IR}: {A} {Fair} {Top}-k {Ranking} {Algorithm}},
	isbn = {978-1-4503-4918-5},
	shorttitle = {{FA}*{IR}},
	url = {http://dl.acm.org/citation.cfm?doid=3132847.3132938},
	doi = {10.1145/3132847.3132938},
	language = {en},
	urldate = {2017-11-24},
	publisher = {ACM Press},
	author = {Zehlike, Meike and Bonchi, Francesco and Castillo, Carlos and Hajian, Sara and Megahed, Mohamed and Baeza-Yates, Ricardo},
	year = {2017},
	keywords = {comps-dm, fatml, ranking},
	pages = {1569--1578},
}

@article{RankExplorerVisualizationRankingChanges,
	title = {{RankExplorer}: {Visualization} of ranking changes in large time series data},
	volume = {18},
	shorttitle = {{RankExplorer}},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Shi, Conglei and Cui, Weiwei and Liu, Shixia and Xu, Panpan and Chen, Wei and Qu, Huamin},
	year = {2012},
	keywords = {ranking, vis},
	pages = {2669--2678},
}

@inproceedings{UnbiasedLearningtoRankBiasedFeedback,
	title = {Unbiased {Learning}-to-{Rank} with {Biased} {Feedback}},
	isbn = {978-1-4503-4675-7},
	url = {http://dl.acm.org/citation.cfm?doid=3018661.3018699},
	doi = {10.1145/3018661.3018699},
	language = {en},
	urldate = {2018-01-19},
	publisher = {ACM Press},
	author = {Joachims, Thorsten and Swaminathan, Adith and Schnabel, Tobias},
	year = {2017},
	keywords = {fatml, ranking},
	pages = {781--789},
}

@article{DesigningFairRankingSchemes,
	title = {Designing {Fair} {Ranking} {Schemes}},
	url = {http://arxiv.org/abs/1712.09752},
	abstract = {Items from a database are often ranked based on a combination of multiple criteria. Often, a user may have flexibility to accept combinations that weight these criteria differently, within limits. On the other hand, this choice of weights can greatly affect the fairness of the ranking produced. In this paper, we develop a system that helps users choose criterion weights that lead to greater fairness. We consider ranking functions that compute the score of each item as a weighted sum of (numeric) attribute values, and then sort items on their score. Each ranking function can then be expressed as a vector of weights, or a point in a multi-dimensional space. For a broad range of fairness criteria, we show how to efficiently identify regions in this space that satisfy these criteria. Using this identification, our system is able to tell users whether their proposed ranking function satisfies the desired fairness criteria and if it does not, to suggest the smallest modification which does. Our extensive experiments on real datasets demonstrate that our methods are able to find solutions that satisfy fairness criteria effectively and efficiently.},
	urldate = {2018-01-04},
	journal = {arXiv:1712.09752 [cs]},
	author = {Asudehy, Abolfazl and Jagadishy, H. V. and Stoyanovichz, Julia and Das, Gautam},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.09752},
	keywords = {fair, fatml, ranking, xai},
}

@article{ThreeNaiveBayesApproaches,
	title = {Three naive {Bayes} approaches for discrimination-free classification},
	volume = {21},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-010-0190-x},
	doi = {10.1007/s10618-010-0190-x},
	language = {en},
	number = {2},
	urldate = {2017-11-28},
	journal = {Data Mining and Knowledge Discovery},
	author = {Calders, Toon and Verwer, Sicco},
	month = sep,
	year = {2010},
	keywords = {fatml, xai},
	pages = {277--292},
}

@article{MarginsOpportunity,
	title = {Margins and opportunity},
	journal = {Submitted to AAAI/AIES},
	author = {Kaul, Shiva and Gordon, G.},
	year = {2018},
	keywords = {fair, fatml},
}

@article{NonDiscriminatoryMachineLearningConvex,
	title = {Non-{Discriminatory} {Machine} {Learning} through {Convex} {Fairness} {Criteria}},
	author = {Goel, Naman and Yaghini, Mohammad and Faltings, Boi},
	year = {2018},
	keywords = {fatml},
}

@inproceedings{ControllingPopularityBiasLearningtoRank,
	title = {Controlling {Popularity} {Bias} in {Learning}-to-{Rank} {Recommendation}},
	booktitle = {Proceedings of the {Eleventh} {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Abdollahpouri, Himan and Burke, Robin and Mobasher, Bamshad},
	year = {2017},
	keywords = {fatml, xai},
	pages = {42--46},
}

@article{RankingSocialCuesIntegrating,
	title = {Ranking with social cues: {Integrating} online review scores and popularity information},
	shorttitle = {Ranking with social cues},
	journal = {arXiv preprint arXiv:1704.01213},
	author = {Analytis, Pantelis P. and Delfino, Alexia and Kämmer, Juliane and Moussaïd, Mehdi and Joachims, Thorsten},
	year = {2017},
	keywords = {fatml},
}

@inproceedings{UnbiasedRankingEvaluationBudget,
	title = {Unbiased {Ranking} {Evaluation} on a {Budget}},
	isbn = {978-1-4503-3473-0},
	url = {http://dl.acm.org/citation.cfm?doid=2740908.2742565},
	doi = {10.1145/2740908.2742565},
	language = {en},
	urldate = {2018-01-19},
	publisher = {ACM Press},
	author = {Schnabel, Tobias and Swaminathan, Adith and Joachims, Thorsten},
	year = {2015},
	keywords = {fatml},
	pages = {935--937},
}

@article{LearningRankInformationRetrieval,
	title = {Learning to {Rank} for {Information} {Retrieval}},
	volume = {3},
	issn = {1554-0669, 1554-0677},
	url = {http://www.nowpublishers.com/article/Details/INR-016},
	doi = {10.1561/1500000016},
	language = {en},
	number = {3},
	urldate = {2018-01-04},
	journal = {Foundations and Trends® in Information Retrieval},
	author = {Liu, Tie-Yan},
	year = {2007},
	keywords = {fatml, ranking, xai},
	pages = {225--331},
}

@inproceedings{PageRankMachineLearningStatic,
	title = {Beyond {PageRank}: machine learning for static ranking},
	shorttitle = {Beyond {PageRank}},
	booktitle = {Proceedings of the 15th international conference on {World} {Wide} {Web}},
	publisher = {ACM},
	author = {Richardson, Matthew and Prakash, Amit and Brill, Eric},
	year = {2006},
	keywords = {fatml, xai},
	pages = {707--715},
}

@inproceedings{OptimizingSearchEnginesUsing,
	title = {Optimizing search engines using clickthrough data},
	booktitle = {Proceedings of the eighth {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	publisher = {ACM},
	author = {Joachims, Thorsten},
	year = {2002},
	keywords = {dm, vis},
	pages = {133--142},
}

@article{EnablingSelfAwarenessKnowledgeWorkers,
	title = {Enabling {Self}-{Awareness} for {Knowledge} {Workers} {Through} {Visualization} of {Instrumentation} {Data}},
	author = {Thakur, Sidharth and Jones, Paul and Cox, Steve},
	keywords = {vis},
}

@article{PodiumRankingDataUsing,
	title = {Podium: {Ranking} data using mixed-initiative visual analytics},
	shorttitle = {Podium},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wall, Emily and Das, Subhajit and Chawla, Ravish and Kalidindi, Bharath and Brown, Eli T. and Endert, Alex},
	year = {2017},
	keywords = {vis},
}

@article{ExploringEvolvingMediaDiscourse,
	title = {Exploring evolving media discourse through event cueing},
	volume = {22},
	number = {1},
	journal = {IEEE transactions on visualization and computer graphics},
	author = {Lu, Yafeng and Steptoe, Michael and Burke, Sarah and Wang, Hong and Tsai, Jiun-Yi and Davulcu, Hasan and Montgomery, Douglas and Corman, Steven R. and Maciejewski, Ross},
	year = {2016},
	keywords = {vis},
	pages = {220--229},
}

@article{ImPossibilityFairness,
	title = {On the (im)possibility of fairness},
	url = {http://arxiv.org/abs/1609.07236},
	abstract = {What does it mean for an algorithm to be fair? Different papers use different notions of algorithmic fairness, and although these appear internally consistent, they also seem mutually incompatible. We present a mathematical setting in which the distinctions in previous papers can be made formal. In addition to characterizing the spaces of inputs (the "observed" space) and outputs (the "decision" space), we introduce the notion of a construct space: a space that captures unobservable, but meaningful variables for the prediction. We show that in order to prove desirable properties of the entire decision-making process, different mechanisms for fairness require different assumptions about the nature of the mapping from construct space to decision space. The results in this paper imply that future treatments of algorithmic fairness should more explicitly state assumptions about the relationship between constructs and observations.},
	urldate = {2018-01-15},
	journal = {arXiv:1609.07236 [cs, stat]},
	author = {Friedler, Sorelle A. and Scheidegger, Carlos and Venkatasubramanian, Suresh},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.07236},
	keywords = {Statistics - Machine Learning, comps-dm, fatml, ranking},
}

@article{EqualityOpportunityRankings,
	title = {Equality of {Opportunity} in {Rankings}},
	author = {Singh, Ashudeep and Joachims, Thorsten},
	keywords = {fatml, ranking, topic},
}

@article{HowHierarchicalTopicsEvolve,
	title = {How {Hierarchical} {Topics} {Evolve} in {Large} {Text} {Corpora}},
	volume = {20},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/6875938/},
	doi = {10.1109/TVCG.2014.2346433},
	abstract = {Using a sequence of topic trees to organize documents is a popular way to represent hierarchical and evolving topics in text corpora. However, following evolving topics in the context of topic trees remains difﬁcult for users. To address this issue, we present an interactive visual text analysis approach to allow users to progressively explore and analyze the complex evolutionary patterns of hierarchical topics. The key idea behind our approach is to exploit a tree cut to approximate each tree and allow users to interactively modify the tree cuts based on their interests. In particular, we propose an incremental evolutionary tree cut algorithm with the goal of balancing 1) the ﬁtness of each tree cut and the smoothness between adjacent tree cuts; 2) the historical and new information related to user interests. A time-based visualization is designed to illustrate the evolving topics over time. To preserve the mental map, we develop a stable layout algorithm. As a result, our approach can quickly guide users to progressively gain profound insights into evolving hierarchical topics. We evaluate the effectiveness of the proposed method on Amazon’s Mechanical Turk and real-world news data. The results show that users are able to successfully analyze evolving topics in text data.},
	language = {en},
	number = {12},
	urldate = {2018-05-03},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cui, Weiwei and Liu, Shixia and Wu, Zhuofeng and Wei, Hao},
	month = dec,
	year = {2014},
	keywords = {hierarchy, seq, topic, vis},
	pages = {2281--2290},
}

@article{VoilaVisualAnomalyDetection,
	title = {Voila: {Visual} {Anomaly} {Detection} and {Monitoring} with {Streaming} {Spatiotemporal} {Data}},
	volume = {24},
	issn = {1077-2626},
	shorttitle = {Voila},
	url = {http://ieeexplore.ieee.org/document/8022952/},
	doi = {10.1109/TVCG.2017.2744419},
	language = {en},
	number = {1},
	urldate = {2018-05-03},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cao, Nan and Lin, Chaoguang and Zhu, Qiuhan and Lin, Yu-Ru and Teng, Xian and Wen, Xidao},
	month = jan,
	year = {2018},
	keywords = {vis},
	pages = {23--33},
}

@article{Cite2vecCitationDrivenDocumentExploration,
	title = {cite2vec: {Citation}-{Driven} {Document} {Exploration} via {Word} {Embeddings}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {cite2vec},
	url = {http://ieeexplore.ieee.org/document/7539398/},
	doi = {10.1109/TVCG.2016.2598667},
	abstract = {Effectively exploring and browsing document collections is a fundamental problem in visualization. Traditionally, document visualization is based on a data model that represents each document as the set of its comprised words, effectively characterizing what the document is. In this paper we take an alternative perspective: motivated by the manner in which users search documents in the research process, we aim to visualize documents via their usage, or how documents tend to be used. We present a new visualization scheme – cite2vec – that allows the user to dynamically explore and browse documents via how other documents use them, information that we capture through citation contexts in a document collection. Starting from a usage-oriented word-document 2D projection, the user can dynamically steer document projections by prescribing semantic concepts, both in the form of phrase/document compositions and document:phrase analogies, enabling the exploration and comparison of documents by their use. The user interactions are enabled by a joint representation of words and documents in a common high-dimensional embedding space where user-speciﬁed concepts correspond to linear operations of word and document vectors. Our case studies, centered around a large document corpus of computer vision research papers, highlight the potential for usage-based document visualization.},
	language = {en},
	number = {1},
	urldate = {2018-05-03},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Berger, Matthew and McDonough, Katherine and Seversky, Lee M.},
	month = jan,
	year = {2017},
	keywords = {emb, vis},
	pages = {691--700},
}

@article{ExploringExploitingSocialEthical,
	title = {Exploring or {Exploiting}? {Social} and {Ethical} {Implications} of {Autonomous} {Experimentation} in {AI}},
	abstract = {In the ﬁeld of computer science, large-scale experimentation on users is not new. However, driven by advances in artiﬁcial intelligence, novel autonomous systems for experimentation are emerging that raise complex, unanswered questions for the ﬁeld. Some of these questions are computational, while others relate to the social and ethical implications of these systems. We see these normative questions as urgent because they pertain to critical infrastructure upon which large populations depend, such as transportation and healthcare. Although experimentation on widely used online platforms like Facebook has stoked controversy in recent years, the unique risks posed by autonomous experimentation have not received suﬃcient attention, even though such techniques are being trialled on a massive scale. In this paper, we identify several questions about the social and ethical implications of autonomous experimentation systems. These questions concern the design of such systems, their eﬀects on users, and their resistance to some common mitigations.},
	language = {en},
	author = {Bird, Sarah and Barocas, Solon and Crawford, Kate},
	keywords = {fatml, xai},
	pages = {4},
}

@inproceedings{MobiSegInteractiveRegionSegmentation,
	title = {{MobiSeg}: {Interactive} region segmentation using heterogeneous mobility data},
	isbn = {978-1-5090-5738-2},
	shorttitle = {{MobiSeg}},
	url = {http://ieeexplore.ieee.org/document/8031583/},
	doi = {10.1109/PACIFICVIS.2017.8031583},
	language = {en},
	urldate = {2018-05-03},
	publisher = {IEEE},
	author = {Wu, Wenchao and Zheng, Yixian and Cao, Nan and Zeng, Haipeng and Ni, Bing and Qu, Huamin and Ni, Lionel M.},
	month = apr,
	year = {2017},
	keywords = {vis},
	pages = {91--100},
}

@article{InferringPolicyDiffusionNetworks,
	title = {Inferring {Policy} {Diffusion} {Networks} in the {American} {States}},
	author = {Desmarais, Bruce and Harden, Jeffrey J. and Boehmke, Frederick J.},
	year = {2013},
}

@article{GeographyMoneyPoliticsPopulation,
	title = {The geography of money and politics: {Population} density, social networks, and political contributions},
	volume = {4},
	shorttitle = {The geography of money and politics},
	number = {4},
	journal = {Research \& Politics},
	author = {Lin, Yu-Ru and Kennedy, Ryan and Lazer, David},
	year = {2017},
	keywords = {dm},
	pages = {2053168017742015},
}

@article{InferringNetworksDiffusionInfluence,
	title = {Inferring {Networks} of {Diffusion} and {Influence}},
	volume = {5},
	issn = {15564681},
	url = {http://dl.acm.org/citation.cfm?doid=2086737.2086741},
	doi = {10.1145/2086737.2086741},
	language = {en},
	number = {4},
	urldate = {2018-03-09},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Gomez-Rodriguez, Manuel and Leskovec, Jure and Krause, Andreas},
	month = feb,
	year = {2012},
	keywords = {network-inference, r-policyflow},
	pages = {1--37},
}

@article{PersistentPolicyPathwaysInferring,
	title = {Persistent {Policy} {Pathways}: {Inferring} {Diffusion} {Networks} in the {American} {States}},
	volume = {109},
	issn = {0003-0554, 1537-5943},
	shorttitle = {Persistent {Policy} {Pathways}},
	url = {http://www.journals.cambridge.org/abstract_S0003055415000040},
	doi = {10.1017/S0003055415000040},
	language = {en},
	number = {02},
	urldate = {2018-03-09},
	journal = {American Political Science Review},
	author = {Desmarais, Bruce A. and Harden, Jeffrey J. and Boehmke, Frederick J.},
	month = may,
	year = {2015},
	keywords = {network-inference, r-policyflow},
	pages = {392--406},
}

@inproceedings{TrajRankExploringTravelBehaviour,
	title = {{TrajRank}: {Exploring} travel behaviour on a route by trajectory ranking},
	shorttitle = {{TrajRank}},
	doi = {10.1109/PACIFICVIS.2015.7156392},
	abstract = {In this paper, we propose a novel visual analysis method TrajRank to study the travel behaviour of vehicles along one route. We focus on the spatial-temporal distribution of travel time, i.e., the time spent on each road segment and the travel time variation in rush/non-rush hours. TrajRank first allows users to interactively select a route, and segment it into several road segments. Then trajectories passing this route are automatically extracted. These trajectories are ranked on each road segment according to travel time and further clustered according to the rankings on all road segments. Based on the above ranking analysis, we provide a temporal distribution view showing the temporal distribution of travel time and a ranking diagram view showing the spatial variation of travel time. With real taxi GPS data, we present three use cases and an informal user study to show the effectiveness and usability of our method.},
	booktitle = {2015 {IEEE} {Pacific} {Visualization} {Symposium} ({PacificVis})},
	author = {Lu, M. and Wang, Z. and Yuan, X.},
	month = apr,
	year = {2015},
	keywords = {vis},
	pages = {311--318},
}

@article{VisualAnalysisAirPollution,
	title = {Visual {Analysis} of the {Air} {Pollution} {Problem} in {Hong} {Kong}},
	volume = {13},
	abstract = {We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector ﬁelds formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.},
	language = {en},
	number = {6},
	journal = {IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS},
	author = {Qu, Huamin and Lau, Kai-Hon and Guo, Ping},
	year = {2007},
	keywords = {vis},
	pages = {8},
}

@article{ConceptInformationOverloadReview,
	title = {The {Concept} of {Information} {Overload}: {A} {Review} of {Literature} from {Organization} {Science}, {Accounting}, {Marketing}, {MIS}, and {Related} {Disciplines}},
	volume = {20},
	issn = {0197-2243, 1087-6537},
	shorttitle = {The {Concept} of {Information} {Overload}},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01972240490507974},
	doi = {10.1080/01972240490507974},
	language = {en},
	number = {5},
	urldate = {2018-03-09},
	journal = {The Information Society},
	author = {Eppler, Martin J. and Mengis, Jeanne},
	month = nov,
	year = {2004},
	keywords = {infosci},
	pages = {325--344},
}

@article{ExploitingAnalysisHistorySupport,
	title = {Exploiting {Analysis} {History} to {Support} {Collaborative} {Data} {Analysis}},
	abstract = {Coordination is critical in distributed collaborative analysis of multidimensional data. Collaborating analysts need to understand what each person has done and what avenues of analysis remain uninvestigated in order to effectively coordinate their efforts. Although visualization history has the potential to communicate such information, common history representations typically show sequential lists of past work, making it difficult to understand the analytic coverage of the data dimension space (i.e. which data dimensions have been investigated and in what combinations). This makes it difficult for collaborating analysts to plan their next steps, particularly when the number of dimensions is large and team members are distributed. We introduce the notion of representing past analysis history from a dimension coverage perspective to enable analysts to see which data dimensions have been explored in which combinations. Through two user studies, we investigated whether 1) a dimension oriented view improves understanding of past coverage information, and 2) the addition of dimension coverage information aids coordination. Our findings demonstrate that a representation of dimension coverage reduces the time required to identify and investigate unexplored regions and increases the accuracy of this understanding. In addition, it results in a larger overall coverage of the dimension space, one element of effective team coordination.},
	language = {en},
	author = {Sarvghad, Ali and Tory, Melanie},
	keywords = {collaborative, vis, vis-collaborative-system},
	pages = {8},
}

@article{SupportingHandoffAsynchronousCollaborative,
	title = {Supporting {Handoff} in {Asynchronous} {Collaborative} {Sensemaking} {Using} {Knowledge}-{Transfer} {Graphs}},
	volume = {24},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/8017596/},
	doi = {10.1109/TVCG.2017.2745279},
	abstract = {During asynchronous collaborative analysis, handoff of partial ﬁndings is challenging because externalizations produced by analysts may not adequately communicate their investigative process. To address this challenge, we developed techniques to automatically capture and help encode tacit aspects of the investigative process based on an analyst’s interactions, and streamline explicit authoring of handoff annotations. We designed our techniques to mediate awareness of analysis coverage, support explicit communication of progress and uncertainty with annotation, and implicit communication through playback of investigation histories. To evaluate our techniques, we developed an interactive visual analysis system, KTGraph, that supports an asynchronous investigative document analysis task. We conducted a two-phase user study to characterize a set of handoff strategies and to compare investigative performance with and without our techniques. The results suggest that our techniques promote the use of more effective handoff strategies, help increase an awareness of prior investigative process and insights, as well as improve ﬁnal investigative outcomes.},
	language = {en},
	number = {1},
	urldate = {2018-06-25},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Zhao, Jian and Glueck, Michael and Isenberg, Petra and Chevalier, Fanny and Khan, Azam},
	month = jan,
	year = {2018},
	keywords = {collaborative, comps-sc, vis, vis-collaborative-system},
	pages = {340--350},
}

@article{VisualizingDataflowGraphsDeep,
	title = {Visualizing {Dataflow} {Graphs} of {Deep} {Learning} {Models} in {TensorFlow}},
	volume = {24},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/8019861/},
	doi = {10.1109/TVCG.2017.2744878},
	abstract = {We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataﬂow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model’s modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users ﬁnd the visualizer useful for understanding, debugging, and sharing the structures of their models.},
	language = {en},
	number = {1},
	urldate = {2018-06-04},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wongsuphasawat, Kanit and Smilkov, Daniel and Wexler, James and Wilson, Jimbo and Mane, Dandelion and Fritz, Doug and Krishnan, Dilip and Viegas, Fernanda B. and Wattenberg, Martin},
	month = jan,
	year = {2018},
	keywords = {case-study, eval, expert-interview, vis},
	pages = {1--12},
}

@article{VisualAnalysisDisseminationScientific,
	title = {Visual {Analysis} and {Dissemination} of {Scientific} {Literature} {Collections} with {SurVis}},
	volume = {22},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/7192633/},
	doi = {10.1109/TVCG.2015.2467757},
	abstract = {Bibliographic data such as collections of scientiﬁc articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve speciﬁc publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to ﬁlter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, ﬁltering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts conﬁrms that SurVis meets the initially formulated requirements.},
	language = {en},
	number = {1},
	urldate = {2018-06-04},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Beck, Fabian and Koch, Sebastian and Weiskopf, Daniel},
	month = jan,
	year = {2016},
	keywords = {vis},
	pages = {180--189},
}

@article{ZGlyphVisualizingOutliersMultivariate,
	title = {Z-{Glyph}: {Visualizing} outliers in multivariate data},
	volume = {17},
	issn = {1473-8716, 1473-8724},
	shorttitle = {Z-{Glyph}},
	url = {http://journals.sagepub.com/doi/10.1177/1473871616686635},
	doi = {10.1177/1473871616686635},
	abstract = {Outlier analysis techniques are extensively used in many domains such as intrusion detection. Today, even with the most advanced statistical learning techniques, human judgment still plays an important role in outlier analysis tasks due to the difficulty of defining and collecting outlier examples. This work seeks to tackle this problem by introducing a new visualization design, ‘‘Z-Glyph,’’ a family of glyphs designed to facilitate human judgment in outlier analysis of multivariate data. By employing a location-scale transformation, a ZGlyph represents the ‘‘normal’’ data using regular shapes (e.g. straight line and circle), such that the abnormal data can be revealed when deviating from the regular shapes. Extensive controlled experiment and case studies based on real-world datasets indicate the superior performance of the Z-Glyph family, compared with the baselines, suggesting that the proposed design is able to leverage human perceptional features with statistical characterization. This study contributes to a more fundamental understanding about designing visual representations for revealing outliers in multivariate data, which can be applied as a building block in many domain-specific anomaly detection applications.},
	language = {en},
	number = {1},
	urldate = {2018-05-03},
	journal = {Information Visualization},
	author = {Cao, Nan and Lin, Yu-Ru and Gotz, David and Du, Fan},
	month = jan,
	year = {2018},
	keywords = {vis},
	pages = {22--40},
}

@article{FairnessReinforcementLearning,
	title = {Fairness in {Reinforcement} {Learning}},
	abstract = {We initiate the study of fairness in reinforcement learning, where the actions of a learning algorithm may aﬀect its environment and future rewards. Our fairness constraint requires that an algorithm never prefers one action over another if the long-term (discounted) reward of choosing the latter action is higher. Our ﬁrst result is negative: despite the fact that fairness is consistent with the optimal policy, any learning algorithm satisfying fairness must take time exponential in the number of states to achieve non-trivial approximation to the optimal policy. We then provide a provably fair polynomial time algorithm under an approximate notion of fairness, thus establishing an exponential gap between exact and approximate fairness.},
	language = {en},
	author = {Jabbari, Shahin and Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Roth, Aaron},
	keywords = {fair, fatml},
	pages = {23},
}

@article{RankingConstraints,
	title = {Ranking {Constraints}},
	abstract = {We need to reason about rankings of objects in a wide variety of domains including information retrieval, sports tournaments, bibliometrics, and statistics. We propose a global constraint therefore for modeling rankings. One important application for rankings is in reasoning about the correlation or uncorrelation between sequences. For example, we might wish to have consecutive delivery schedules correlated to make it easier for clients and employees, or uncorrelated to avoid predictability and complacence. We therefore also consider global correlation constraints between rankings. For both ranking and correlation constraints, we propose efﬁcient ﬁltering algorithms and decompositions, and report experimental results demonstrating the promise of our proposed approach.},
	language = {en},
	author = {Bessière, Christian and Hébrard, Emmanuel and Katsirelos, George and Walsh, Toby and Kiziltan, Zeynep},
	keywords = {fair, fatml},
	pages = {8},
}

@inproceedings{CertifyingRemovingDisparateImpact,
	title = {Certifying and {Removing} {Disparate} {Impact}},
	isbn = {978-1-4503-3664-2},
	url = {http://dl.acm.org/citation.cfm?doid=2783258.2783311},
	doi = {10.1145/2783258.2783311},
	abstract = {What does it mean for an algorithm to be biased? In U.S. law, unintentional bias is encoded via disparate impact, which occurs when a selection process has widely different outcomes for different groups, even as it appears to be neutral. This legal determination hinges on a deﬁnition of a protected class (ethnicity, gender) and an explicit description of the process.},
	language = {en},
	urldate = {2018-05-03},
	publisher = {ACM Press},
	author = {Feldman, Michael and Friedler, Sorelle A. and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
	year = {2015},
	keywords = {fair, fatml, xai},
	pages = {259--268},
}

@inproceedings{FairnessAwarenessa,
	title = {Fairness through awareness},
	isbn = {978-1-4503-1115-1},
	url = {http://dl.acm.org/citation.cfm?doid=2090236.2090255},
	doi = {10.1145/2090236.2090255},
	abstract = {We study fairness in classiﬁcation, where individuals are classiﬁed, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classiﬁer (the university). The main conceptual contribution of this paper is a framework for fair classiﬁcation comprising (1) a (hypothetical) task-speciﬁc metric for determining the degree to which individuals are similar with respect to the classiﬁcation task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of “fair aﬃrmative action,” which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classiﬁcation are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of diﬀerential privacy may be applied to fairness.},
	language = {en},
	urldate = {2018-05-03},
	publisher = {ACM Press},
	author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
	year = {2012},
	keywords = {fair, fatml},
	pages = {214--226},
}

@article{DelayedImpactFairMachine,
	title = {Delayed {Impact} of {Fair} {Machine} {Learning}},
	abstract = {Fairness in machine learning has predominantly been studied in static classiﬁcation settings without concern for how decisions change the underlying population over time. Conventional wisdom suggests that fairness criteria promote the long-term well-being of those groups they aim to protect.},
	language = {en},
	author = {Liu, Lydia T and Dean, Sarah and Rolf, Esther and Simchowitz, Max and Hardt, Moritz},
	keywords = {fair, fatml, xai},
	pages = {37},
}

@inproceedings{TCalUnderstandingTeamConversational,
	title = {T-{Cal}: {Understanding} {Team} {Conversational} {Data} with {Calendar}-based {Visualization}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {T-{Cal}},
	url = {http://dl.acm.org/citation.cfm?doid=3173574.3174074},
	doi = {10.1145/3173574.3174074},
	abstract = {Understanding team communication and collaboration patterns is critical for improving work efﬁciency in organizations. This paper presents an interactive visualization system, T-Cal, that supports the analysis of conversation data from modern team messaging platforms (e.g., Slack). T-Cal employs a user-familiar visual interface, a calendar, to enable seamless multi-scale browsing of data from different perspectives. T-Cal also incorporates a number of analytical techniques for disentangling interleaving conversations, extracting keywords, and estimating sentiment. The design of T-Cal is based on an iterative user-centered design process including interview studies, requirements gathering, initial prototypes demonstration, and evaluation with domain users. The resulting two case studies indicate the effectiveness and usefulness of T-Cal in real-world applications, including daily conversations within an industry research lab and student group chats in a MOOC.},
	language = {en},
	urldate = {2018-06-25},
	publisher = {ACM Press},
	author = {Fu, Siwei and Zhao, Jian and Cheng, Hao Fei and Zhu, Haiyi and Marlow, Jennifer},
	year = {2018},
	keywords = {collaborative, seq, vis},
	pages = {1--13},
}

@article{NutritionalLabelRankings,
	title = {A {Nutritional} {Label} for {Rankings}},
	url = {http://arxiv.org/abs/1804.07890},
	doi = {10.1145/3183713.3193568},
	abstract = {Algorithmic decisions often result in scoring and ranking individuals to determine credit worthiness, qualifications for college admissions and employment, and compatibility as dating partners. While automatic and seemingly objective, ranking algorithms can discriminate against individuals and protected groups, and exhibit low diversity. Furthermore, ranked results are often unstable —small changes in the input data or in the ranking methodology may lead to drastic changes in the output, making the result uninformative and easy to manipulate. Similar concerns apply in cases where items other than individuals are ranked, including colleges, academic departments, or products.},
	language = {en},
	urldate = {2018-08-08},
	journal = {arXiv:1804.07890 [cs]},
	author = {Yang, Ke and Stoyanovich, Julia and Asudeh, Abolfazl and Howe, Bill and Jagadish, H. V. and Miklau, Gerome},
	year = {2018},
	note = {arXiv: 1804.07890},
	keywords = {fatml, ranking, vis},
	pages = {1773--1776},
}

@article{EquityAttentionAmortizingIndividual,
	title = {Equity of {Attention}: {Amortizing} {Individual} {Fairness} in {Rankings}},
	shorttitle = {Equity of {Attention}},
	url = {http://arxiv.org/abs/1805.01788},
	doi = {10.1145/3209978.3210063},
	abstract = {Rankings of people and items are at the heart of selection-making, match-making, and recommender systems, ranging from employment sites to sharing economy platforms. As ranking positions influence the amount of attention the ranked subjects receive, biases in rankings can lead to unfair distribution of opportunities and resources such as jobs or income. This paper proposes new measures and mechanisms to quantify and mitigate unfairness from a bias inherent to all rankings, namely, the position bias which leads to disproportionately less attention being paid to low-ranked subjects. Our approach differs from recent fair ranking approaches in two important ways. First, existing works measure unfairness at the level of subject groups while our measures capture unfairness at the level of individual subjects, and as such subsume group unfairness. Second, as no single ranking can achieve individual attention fairness, we propose a novel mechanism that achieves amortized fairness, where attention accumulated across a series of rankings is proportional to accumulated relevance. We formulate the challenge of achieving amortized individual fairness subject to constraints on ranking quality as an online optimization problem and show that it can be solved as an integer linear program. Our experimental evaluation reveals that unfair attention distribution in rankings can be substantial, and demonstrates that our method can improve individual fairness while retaining high ranking quality.},
	language = {en},
	urldate = {2018-08-01},
	journal = {arXiv:1805.01788 [cs]},
	author = {Biega, Asia J. and Gummadi, Krishna P. and Weikum, Gerhard},
	year = {2018},
	note = {arXiv: 1805.01788},
	keywords = {fatml, ranking},
	pages = {405--414},
}

@article{RiseFallPatternsInformation,
	title = {Rise and {Fall} {Patterns} of {Information} {Diffusion}: {Model} and {Implications}},
	abstract = {The recent explosion in the adoption of search engines and new media such as blogs and Twitter have facilitated faster propagation of news and rumors. How quickly does a piece of news spread over these media? How does its popularity diminish over time? Does the rising and falling pattern follow a simple universal law? In this paper, we propose SpikeM, a concise yet ﬂexible analytical model for the rise and fall patterns of inﬂuence propagation. Our model has the following advantages: (a) uniﬁcation power: it generalizes and explains earlier theoretical models and empirical observations; (b) practicality: it matches the observed behavior of diverse sets of real data; (c) parsimony: it requires only a handful of parameters; and (d) usefulness: it enables further analytics tasks such as forecasting, spotting anomalies, and interpretation by reverseengineering the system parameters of interest (e.g. quality of news, count of interested bloggers, etc.).},
	language = {en},
	author = {Matsubara, Yasuko and Sakurai, Yasushi and Prakash, B Aditya and Li, Lei and Faloutsos, Christos},
	keywords = {diffusion},
	pages = {9},
}

@article{PolicyDiffusionSevenLessons,
	title = {Policy {Diffusion}: {Seven} {Lessons} for {Scholars} and {Practitioners}},
	volume = {72},
	issn = {00333352},
	shorttitle = {Policy {Diffusion}},
	url = {http://doi.wiley.com/10.1111/j.1540-6210.2012.02610.x},
	doi = {10.1111/j.1540-6210.2012.02610.x},
	language = {en},
	number = {6},
	urldate = {2018-08-09},
	journal = {Public Administration Review},
	author = {Shipan, Charles R. and Volden, Craig},
	month = nov,
	year = {2012},
	keywords = {diffusion},
	pages = {788--796},
}

@article{IntroductionVariableFeatureSelection,
	title = {An {Introduction} to {Variable} and {Feature} {Selection}},
	abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-eﬀective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better deﬁnition of the objective function, feature construction, feature ranking, multivariate feature selection, eﬃcient search methods, and feature validity assessment methods.},
	language = {en},
	author = {Guyon, Isabelle and Elisseeﬀ, Andre},
	keywords = {dm, ml-basic},
	pages = {26},
}

@article{FairnessConstraintsMechanismsFair,
	title = {Fairness {Constraints}: {Mechanisms} for {Fair} {Classification}},
	shorttitle = {Fairness {Constraints}},
	url = {http://arxiv.org/abs/1507.05259},
	abstract = {Algorithmic decision making systems are ubiquitous across a wide variety of online as well as oﬄine services. These systems rely on complex learning methods and vast amounts of data to optimize the service functionality, satisfaction of the end user and proﬁtability. However, there is a growing concern that these automated decisions can lead, even in the absence of intent, to a lack of fairness, i.e., their outcomes can disproportionately hurt (or, beneﬁt) particular groups of people sharing one or more sensitive attributes (e.g., race, sex). In this paper, we introduce a ﬂexible mechanism to design fair classiﬁers by leveraging a novel intuitive measure of decision boundary (un)fairness. We instantiate this mechanism with two well-known classiﬁers, logistic regression and support vector machines, and show on real-world data that our mechanism allows for a ﬁne-grained control on the degree of fairness, often at a small cost in terms of accuracy.},
	language = {en},
	urldate = {2018-08-01},
	journal = {arXiv:1507.05259 [cs, stat]},
	author = {Zafar, Muhammad Bilal and Valera, Isabel and Rodriguez, Manuel Gomez and Gummadi, Krishna P.},
	month = jul,
	year = {2015},
	note = {arXiv: 1507.05259},
	keywords = {fair, fatml},
}

@inproceedings{UnifiedApproachQuantifyingAlgorithmic,
	address = {London, United Kingdom},
	title = {A {Unified} {Approach} to {Quantifying} {Algorithmic} {Unfairness}: {Measuring} {Individual} \&{Group} {Unfairness} via {Inequality} {Indices}},
	isbn = {978-1-4503-5552-0},
	shorttitle = {A {Unified} {Approach} to {Quantifying} {Algorithmic} {Unfairness}},
	url = {http://dl.acm.org/citation.cfm?doid=3219819.3220046},
	doi = {10.1145/3219819.3220046},
	language = {en},
	urldate = {2018-09-06},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '18},
	publisher = {ACM Press},
	author = {Speicher, Till and Heidari, Hoda and Grgic-Hlaca, Nina and Gummadi, Krishna P. and Singla, Adish and Weller, Adrian and Zafar, Muhammad Bilal},
	year = {2018},
	keywords = {fair, fatml, xai},
	pages = {2239--2248},
}

@misc{VisualExplorationSpatialTemporal,
	title = {Visual {Exploration} of {Spatial} and {Temporal} {Variations} of {Tweet} {Topic} {Popularity}},
	url = {https://diglib.eg.org/handle/10.2312/eurova20181105},
	abstract = {We present a visual analytical approach to exploring variation of topic popularity in social media (such as Twitter) over space and time. Our approach includes an analytical pipeline and a multi-view visualization tool. As attempts of topic extraction from very short texts like tweets may not produce meaningful results, we aggregate the texts prior to applying topic modelling techniques. Interactive visualisations support detection of burst events in social media posting activities at different locations, show the spatial, temporal, quantitative, and semantic aspects of these events, and enable the user to explore how popularity of topics varies over cities and time. A case study has been conducted using a real-world tweet dataset.},
	language = {en},
	urldate = {2018-09-08},
	publisher = {The Eurographics Association},
	author = {Li, Jie and Chen, Siming and Andrienko, Gennady and Andrienko, Natalia},
	year = {2018},
	doi = {10.2312/eurova.20181105},
	keywords = {seq, topic, vis},
}

@article{VisForumVisualAnalysisSystem,
	title = {{VisForum}: {A} {Visual} {Analysis} {System} for {Exploring} {User} {Groups} in {Online} {Forums}},
	volume = {8},
	issn = {21606455},
	shorttitle = {{VisForum}},
	url = {http://dl.acm.org/citation.cfm?doid=3185338.3162075},
	doi = {10.1145/3162075},
	language = {en},
	number = {1},
	urldate = {2018-09-08},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Fu, Siwei and Wang, Yong and Yang, Yi and Bi, Qingqing and Guo, Fangzhou and Qu, Huamin},
	month = feb,
	year = {2018},
	keywords = {comps-iui, seq, topic, vis},
	pages = {1--21},
}

@inproceedings{HowIdeasFlowMultiple,
	address = {Baltimore, MD, USA},
	title = {How ideas flow across multiple social groups},
	isbn = {978-1-5090-5661-3},
	url = {http://ieeexplore.ieee.org/document/7883511/},
	doi = {10.1109/VAST.2016.7883511},
	language = {en},
	urldate = {2018-09-08},
	booktitle = {2016 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Wang, Xiting and Liu, Shixia and Chen, Yang and Peng, Tai-Quan and Su, Jing and Yang, Jing and Guo, Baining},
	month = oct,
	year = {2016},
	keywords = {seq, topic, vis},
	pages = {51--60},
}

@inproceedings{UsingEmbeddedFormativeAssessment,
	address = {Sydney, New South Wales, Australia},
	title = {Using embedded formative assessment to predict state summative test scores},
	isbn = {978-1-4503-6400-3},
	url = {http://dl.acm.org/citation.cfm?doid=3170358.3170392},
	doi = {10.1145/3170358.3170392},
	abstract = {If we wish to embed assessment for accountability within instruction, we need to better understand the relative contribution of different types of learner data to statistical models that predict scores on assessments used for accountability purposes. The present work scales up and extends predictive models of math test scores from existing literature and specifies six categories of models that incorporate information about student prior knowledge, socio-demographics, and performance within the MATHia intelligent tutoring system. Linear regression and random forest models are learned within each category and generalized over a sample of 23,000+ learners in Grades 6, 7, and 8 over three academic years in Miami-Dade County Public Schools. After briefly exploring hierarchical models of this data, we discuss a variety of technical and practical applications, limitations, and open questions related to this work, especially concerning to the potential use of instructional platforms like MATHia as a replacement for timeconsuming standardized tests.},
	language = {en},
	urldate = {2018-09-06},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Learning} {Analytics} and {Knowledge}  - {LAK} '18},
	publisher = {ACM Press},
	author = {Fancsali, Stephen E. and Zheng, Guoguo and Tan, Yanyan and Ritter, Steven and Berman, Susan R. and Galyardt, April},
	year = {2018},
	keywords = {dm},
	pages = {161--170},
}

@inproceedings{DiscoveryTemporalAnalysisLatent,
	address = {Sydney, New South Wales, Australia},
	title = {Discovery and temporal analysis of latent study patterns in {MOOC} interaction sequences},
	isbn = {978-1-4503-6400-3},
	url = {http://dl.acm.org/citation.cfm?doid=3170358.3170388},
	doi = {10.1145/3170358.3170388},
	abstract = {Capturing students’ behavioral patterns through analysis of sequential interaction logs is an important task in educational data mining and could enable more effective and personalized support during the learning processes. This study aims at discovery and temporal analysis of learners’ study patterns in MOOC assessment periods. We propose two different methods to achieve this goal. First, following a hypothesis-driven approach, we identify learners’ study patterns based on their interaction with lectures and assignments. Through clustering of study pattern sequences, we capture different longitudinal activity profiles among learners and describe their properties. Second, we propose a temporal clustering pipeline for unsupervised discovery of latent patterns in learners’ interaction data. We model and cluster activity sequences at each time step and perform cluster matching to enable tracking learning behaviours over time. Our proposed pipeline is general and applicable in different learning environments such as MOOC and ITS. Moreover, it allows for modeling and temporal analysis of interaction data at different levels of actions granularity and time resolution. We demonstrate the application of this method for detecting latent study patterns in a MOOC course.},
	language = {en},
	urldate = {2018-09-06},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Learning} {Analytics} and {Knowledge}  - {LAK} '18},
	publisher = {ACM Press},
	author = {Boroujeni, Mina Shirvani and Dillenbourg, Pierre},
	year = {2018},
	keywords = {dm},
	pages = {206--215},
}

@inproceedings{SequencingContentAdaptiveTesting,
	address = {Vancouver, British Columbia, Canada},
	title = {Sequencing content in an adaptive testing system: the role of choice},
	isbn = {978-1-4503-4870-6},
	shorttitle = {Sequencing content in an adaptive testing system},
	url = {http://dl.acm.org/citation.cfm?doid=3027385.3027412},
	doi = {10.1145/3027385.3027412},
	abstract = {The effect of choice on student achievement and engagement has been an extensively researched area of learning analytics. Current research findings suggest a positive relationship between choice and varied outcome measures, but little has been reported to indicate whether these findings hold in the context of Intelligent Tutoring Systems (ITS). In this paper, we report the results of a randomized controlled experiment in which we investigate the effect of student choice on assignment completion and future achievement in an ITS. The experimental design uses three conditions to observe the effect of choice. In the first condition, students are able to choose the order in which to complete assignments, while in the second condition, students are prescribed an intuitive order in which to complete assignments. Those in the third condition were prescribed a counter-intuitive order in which to complete assignments. Results indicate that allowing students to choose the order in which to work on assignments leads to higher completion rates and better achievement at posttest. A post-hoc analysis also revealed that even considering students with similar completion rates, those given choice had higher posttest scores than those observed in any other condition. These results seem to support the many theories of the positive effect of choice on student achievement.},
	language = {en},
	urldate = {2018-09-06},
	booktitle = {Proceedings of the {Seventh} {International} {Learning} {Analytics} \& {Knowledge} {Conference} on - {LAK} '17},
	publisher = {ACM Press},
	author = {Adjei, Seth A. and Botelho, Anthony F. and Heffernan, Neil T.},
	year = {2017},
	keywords = {dm},
	pages = {178--182},
}

@inproceedings{ApplyingClassificationTechniquesTemporal,
	address = {Edinburgh, United Kingdom},
	title = {Applying classification techniques on temporal trace data for shaping student behavior models},
	isbn = {978-1-4503-4190-5},
	url = {http://dl.acm.org/citation.cfm?doid=2883851.2883926},
	doi = {10.1145/2883851.2883926},
	abstract = {Differences in learners’ behavior have a deep impact on their educational performance. Consequently, there is a need to detect and identify these differences and build suitable learner models accordingly. In this paper, we report on the results from an alternative approach for dynamic student behavioral modeling based on the analysis of time-based student-generated trace data. The goal was to unobtrusively classify students according to their time-spent behavior. We applied 5 different supervised learning classification algorithms on these data, using as target values (class labels) the students’ performance score classes during a Computer-Based Assessment (CBA) process, and compared the obtained results. The proposed approach has been explored in a study with 259 undergraduate university participant students. The analysis of the findings revealed that a) the low misclassification rates are indicative of the accuracy of the applied method and b) the ensemble learning (treeBagger) method provides better classification results compared to the others. These preliminary results are encouraging, indicating that a time-spent driven description of the students’ behavior could have an added value towards dynamically reshaping the respective models.},
	language = {en},
	urldate = {2018-09-06},
	booktitle = {Proceedings of the {Sixth} {International} {Conference} on {Learning} {Analytics} \& {Knowledge} - {LAK} '16},
	publisher = {ACM Press},
	author = {Papamitsiou, Zacharoula and Karapistoli, Eirini and Economides, Anastasios A.},
	year = {2016},
	keywords = {dm},
	pages = {299--303},
}

@inproceedings{LearningPulseMachineLearning,
	address = {Vancouver, British Columbia, Canada},
	title = {Learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data},
	isbn = {978-1-4503-4870-6},
	shorttitle = {Learning pulse},
	url = {http://dl.acm.org/citation.cfm?doid=3027385.3027447},
	doi = {10.1145/3027385.3027447},
	abstract = {Learning Pulse explores whether using a machine learning approach on multimodal data such as heart rate, step count, weather condition and learning activity can be used to predict learning performance in self-regulated learning settings. An experiment was carried out lasting eight weeks involving PhD students as participants, each of them wearing a Fitbit HR wristband and having their application on their computer recorded during their learning and working activities throughout the day. A software infrastructure for collecting multimodal learning experiences was implemented. As part of this infrastructure a Data Processing Application was developed to pre-process, analyse and generate predictions to provide feedback to the users about their learning performance. Data from diﬀerent sources were stored using the xAPI standard into a cloud-based Learning Record Store. The participants of the experiment were asked to rate their learning experience through an Activity Rating Tool indicating their perceived level of productivity, stress, challenge and abilities. These self-reported performance indicators were used as markers to train a Linear Mixed Eﬀect Model to generate learner-speciﬁc predictions of the learning performance. We discuss the advantages and the limitations of the used approach, highlighting further development points.},
	language = {en},
	urldate = {2018-09-06},
	booktitle = {Proceedings of the {Seventh} {International} {Learning} {Analytics} \& {Knowledge} {Conference} on - {LAK} '17},
	publisher = {ACM Press},
	author = {Di Mitri, Daniele and Scheffel, Maren and Drachsler, Hendrik and Börner, Dirk and Ternier, Stefaan and Specht, Marcus},
	year = {2017},
	keywords = {dm},
	pages = {188--197},
}

@inproceedings{UnderstandingStudentLearningTrajectories,
	address = {Vancouver, British Columbia, Canada},
	title = {Understanding student learning trajectories using multimodal learning analytics within an embodied-interaction learning environment},
	isbn = {978-1-4503-4870-6},
	url = {http://dl.acm.org/citation.cfm?doid=3027385.3027429},
	doi = {10.1145/3027385.3027429},
	abstract = {The aim of this paper is to show how multimodal learning analytics (MMLA) can help understand how elementary students explore the concept of feedback loops while controlling an embodied simulation of a predator-prey ecosystem using hand movements as an interface with the computer simulation. We represent student motion patterns from fine-grained logs of hands and gaze data, and then map these observed motion patterns against levels of student performance to make inferences about how embodiment plays a role in the learning process. Results show five distinct motion sequences in students’ embodied interactions, and these motion patterns are statistically associated with initial and post-tutorial levels of students’ understanding of feedback loops. Analysis of student gaze also shows distinctive patterns as to how low- and high-performing students attended to information presented in the simulation. Using MMLA, we show how students’ explanations of feedback loops look differently according to cluster membership, which provides evidence that embodiment interacts with conceptual understanding.},
	language = {en},
	urldate = {2018-09-06},
	booktitle = {Proceedings of the {Seventh} {International} {Learning} {Analytics} \& {Knowledge} {Conference} on - {LAK} '17},
	publisher = {ACM Press},
	author = {Andrade, Alejandro},
	year = {2017},
	keywords = {dm},
	pages = {70--79},
}

@article{LearningGraphRepresentationsEmbedding,
	title = {Learning {Graph} {Representations} with {Embedding} {Propagation}},
	abstract = {We propose Embedding Propagation (EP), an unsupervised learning framework for graph-structured data. EP learns vector representations of graphs by passing two types of messages between neighboring nodes. Forward messages consist of label representations such as representations of words and other attributes associated with the nodes. Backward messages consist of gradients that result from aggregating the label representations and applying a reconstruction loss. Node representations are ﬁnally computed from the representation of their labels. With signiﬁcantly fewer parameters and hyperparameters an instance of EP is competitive with and often outperforms state of the art unsupervised and semi-supervised learning methods on a range of benchmark data sets.},
	language = {en},
	author = {García-Durán, Alberto and Niepert, Mathias},
	keywords = {dm, repr-n-emb},
	pages = {12},
}

@article{MenAlsoShoppingReducing,
	title = {Men {Also} {Like} {Shopping}: {Reducing} {Gender} {Bias} {Amplification} using {Corpus}-level {Constraints}},
	shorttitle = {Men {Also} {Like} {Shopping}},
	url = {http://arxiv.org/abs/1707.09457},
	abstract = {Language is increasingly being used to deﬁne rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora. In this work, we study data and models associated with multilabel object classiﬁcation and visual semantic role labeling. We ﬁnd that (a) datasets for these tasks contain signiﬁcant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33\% more likely to involve females than males in a training set, and a trained model further ampliﬁes the disparity to 68\% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias ampliﬁcation by 47.5\% and 40.5\% for multilabel classiﬁcation and visual semantic role labeling, respectively.},
	language = {en},
	urldate = {2018-09-06},
	journal = {arXiv:1707.09457 [cs, stat]},
	author = {Zhao, Jieyu and Wang, Tianlu and Yatskar, Mark and Ordonez, Vicente and Chang, Kai-Wei},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.09457},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{FairMachineLearning,
	title = {Fair {Machine} {Learning}},
	abstract = {The nascent ﬁeld of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last several years, three formal deﬁnitions of fairness have gained prominence: (1) anti-classiﬁcation, meaning that protected attributes—like race, gender, and their proxies—are not explicitly used to make decisions; (2) classiﬁcation parity, meaning that common measures of predictive performance (e.g., false positive and false negative rates) are equal across groups deﬁned by the protected attributes; and (3) calibration, meaning that conditional on risk estimates, outcomes are independent of protected attributes. Here we show that all three of these fairness deﬁnitions su↵er from signiﬁcant statistical limitations. Requiring anticlassiﬁcation or classiﬁcation parity can, perversely, harm the very groups they were designed to protect; and calibration, though generally desirable, provides little guarantee that decisions are equitable. In contrast to these formal fairness criteria, we argue that it is often preferable to treat similarly risky people similarly, based on the most statistically accurate estimates of risk that one can produce. Such a strategy, while not universally applicable, often aligns well with policy objectives; notably, this strategy will typically violate both anti-classiﬁcation and classiﬁcation parity. In practice, it requires signiﬁcant e↵ort to construct suitable risk estimates. One must carefully deﬁne and measure the targets of prediction to avoid retrenching biases in the data. But, importantly, one cannot generally address these di culties by requiring that algorithms satisfy popular mathematical formalizations of fairness. By highlighting these challenges in the foundation of fair machine learning, we hope to help researchers and practitioners productively advance the area.},
	language = {en},
	author = {Corbett-Davies, Sam and Goel, Sharad},
	keywords = {fair, fatml},
	pages = {25},
}

@article{VisualizationRecommendationLargeImage,
	title = {Visualization and recommendation of large image collections toward effective sensemaking},
	volume = {16},
	issn = {1473-8716, 1473-8724},
	url = {http://journals.sagepub.com/doi/10.1177/1473871616630778},
	doi = {10.1177/1473871616630778},
	abstract = {In our daily lives, images are among the most commonly found data which we need to handle. We present iGraph, a graph-based approach for visual analytics of large image collections and their associated text information. Given such a collection, we compute the similarity between images, the distance between texts, and the connection between image and text to construct iGraph, a compound graph representation which encodes the underlying relationships among these images and texts. To enable effective visual navigation and comprehension of iGraph with tens of thousands of nodes and hundreds of millions of edges, we present a progressive solution that offers collection overview, node comparison, and visual recommendation. Our solution not only allows users to explore the entire collection with representative images and keywords but also supports detailed comparison for understanding and intuitive guidance for navigation. The visual exploration of iGraph is further enhanced with the implementation of bubble sets to highlight group memberships of nodes, suggestion of abnormal keywords or time periods based on text outlier detection, and comparison of four different recommendation solutions. For performance speedup, multiple graphics processing units and central processing units are utilized for processing and visualization in parallel. We experiment with two image collections and leverage a cluster driving a display wall of nearly 50 million pixels. We show the effectiveness of our approach by demonstrating experimental results and conducting a user study.},
	language = {en},
	number = {1},
	urldate = {2018-09-08},
	journal = {Information Visualization},
	author = {Gu, Yi and Wang, Chaoli and Ma, Jun and Nemiroff, Robert J and Kao, David L and Parra, Denis},
	month = jan,
	year = {2017},
	keywords = {topic, vis},
	pages = {21--47},
}

@article{TaskDrivenComparisonTopicModels,
	title = {Task-{Driven} {Comparison} of {Topic} {Models}},
	volume = {22},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/7194832/},
	doi = {10.1109/TVCG.2015.2467618},
	abstract = {Topic modeling, a method of statistically extracting thematic content from a large collection of texts, is used for a wide variety of tasks within text analysis. Though there are a growing number of tools and techniques for exploring single models, comparisons between models are generally reduced to a small set of numerical metrics. These metrics may or may not reﬂect a model’s performance on the analyst’s intended task, and can therefore be insufﬁcient to diagnose what causes differences between models. In this paper, we explore task-centric topic model comparison, considering how we can both provide detail for a more nuanced understanding of differences and address the wealth of tasks for which topic models are used. We derive comparison tasks from single-model uses of topic models, which predominantly fall into the categories of understanding topics, understanding similarity, and understanding change. Finally, we provide several visualization techniques that facilitate these tasks, including buddy plots, which combine color and position encodings to allow analysts to readily view changes in document similarity.},
	language = {en},
	number = {1},
	urldate = {2018-09-08},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Alexander, Eric and Gleicher, Michael},
	month = jan,
	year = {2016},
	keywords = {seq, topic, vis},
	pages = {320--329},
}

@article{TopicLensEfficientMultiLevelVisuala,
	title = {{TopicLens}: {Efficient} {Multi}-{Level} {Visual} {Topic} {Exploration} of {Large}-{Scale} {Document} {Collections}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {{TopicLens}},
	url = {http://ieeexplore.ieee.org/document/7539597/},
	doi = {10.1109/TVCG.2016.2598445},
	abstract = {Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its signiﬁcant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workﬂow. Instead, most such systems are limited to utilizing a ﬁxed, initial set of topics. Motivated by this gap in the literature, we propose a novel interaction technique called TopicLens that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efﬁciently computed on the ﬂy. To support this interaction in real time while maintaining view consistency, we propose a novel efﬁcient topic modeling method and a semi-supervised 2D embedding algorithm. Our work is based on improving state-of-the-art methods such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding. Furthermore, we have built a web-based visual analytics system integrated with TopicLens. We use this system to measure the performance and the visualization quality of our proposed methods. We provide several scenarios showcasing the capability of TopicLens using real-world datasets.},
	language = {en},
	number = {1},
	urldate = {2018-09-08},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, Minjeong and Kang, Kyeongpil and Park, Deokgun and Choo, Jaegul and Elmqvist, Niklas},
	month = jan,
	year = {2017},
	keywords = {repr-n-emb, topic, vis},
	pages = {151--160},
}

@article{ThemeDeltaDynamicSegmentationsTemporal,
	title = {{ThemeDelta}: {Dynamic} {Segmentations} over {Temporal} {Topic} {Models}},
	volume = {21},
	issn = {1077-2626},
	shorttitle = {{ThemeDelta}},
	url = {http://ieeexplore.ieee.org/document/7001093/},
	doi = {10.1109/TVCG.2014.2388208},
	abstract = {We present ThemeDelta, a visual analytics system for extracting and visualizing temporal trends, clustering, and reorganization in time-indexed textual datasets. ThemeDelta is supported by a dynamic temporal segmentation algorithm that integrates with topic modeling algorithms to identify change points where signiﬁcant shifts in topics occur. This algorithm detects not only the clustering and associations of keywords in a time period, but also their convergence into topics (groups of keywords) that may later diverge into new groups. The visual representation of ThemeDelta uses sinuous, variable-width lines to show this evolution on a timeline, utilizing color for categories, and line width for keyword strength. We demonstrate how interaction with ThemeDelta helps capture the rise and fall of topics by analyzing archives of historical newspapers, of U.S. presidential campaign speeches, and of social messages collected through iNeighbors, a web-based social website. ThemeDelta is evaluated using a qualitative expert user study involving three researchers from rhetoric and history using the historical newspapers corpus.},
	language = {en},
	number = {5},
	urldate = {2018-09-08},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Gad, Samah and Javed, Waqas and Ghani, Sohaib and Elmqvist, Niklas and Ewing, Tom and Hampton, Keith N. and Ramakrishnan, Naren},
	month = may,
	year = {2015},
	keywords = {seq, topic, vis},
	pages = {672--685},
}

@article{VisualExplorationLatentRanking,
	title = {Visual exploration of latent ranking evolutions in time series},
	volume = {19},
	issn = {1343-8875, 1875-8975},
	url = {http://link.springer.com/10.1007/s12650-016-0349-7},
	doi = {10.1007/s12650-016-0349-7},
	abstract = {Rankings are everywhere in the world and they change constantly. Detecting and analyzing ranking changes in a ranked list is of great importance for recommendation and information retrieval tasks. Common to existing approaches is that the latent correlations and trends of ranked lists are not taken into account. This paper introduces RankEvo, an integration of rank structuring and visualization techniques, for detecting and analyzing latent evolutions in ranking time series. We characterize the ranking changes by computing the similarities among the time series of ranked items and organizing similar items into itemsets, and further forming ranking evolutions. The integrated RankEvo system provides visualization and intuitive interactions for exploring correlated itemsets, concurrent ranking evolutions, as well as outlier items of ranked lists. The system also employs additional information windows on demand for evolution elaboration and veriﬁcation. Case studies are conducted to demonstrate the effectiveness and usability of the RankEvo system in assisting users to understand ranking changes.},
	language = {en},
	number = {4},
	urldate = {2018-09-08},
	journal = {Journal of Visualization},
	author = {Lei, Hui and Xia, Jing and Guo, Fangzhou and Zou, Yaoyao and Chen, Wei and Liu, Zhen},
	month = nov,
	year = {2016},
	keywords = {ranking, seq, topic, vis},
	pages = {783--795},
}

@article{InteractiveTopicHierarchyRevision,
	title = {Interactive topic hierarchy revision for exploring a collection of online conversations},
	issn = {1473-8716, 1473-8724},
	url = {http://journals.sagepub.com/doi/10.1177/1473871618757228},
	doi = {10.1177/1473871618757228},
	abstract = {In the last decade, there has been an exponential growth of asynchronous online conversations (e.g. blogs), thanks to the rise of social media. Analyzing and gaining insights from such discussions can be quite challenging for a user, especially when the user deals with hundreds of comments that are scattered around multiple different conversations. A promising solution to this problem is to automatically mine the major topics from conversations and organize them into a hierarchical structure. However, the resultant topic hierarchy can be noisy and/or it may not match the user’s current information needs. To address this problem, we introduce a novel human-in-the-loop approach that allows the user to revise the topic hierarchy based on her feedback. We incorporate this approach within a visual text analytics system that helps users in analyzing and getting insights from conversations by exploring and revising the topic hierarchy. We evaluated the resulting system with real users in a lab-based study. The results from the user study, when compared to its counterpart that does not support interactive revisions of a hierarchical topic model, provide empirical evidence of the potential utility of our system in terms of both performance and subjective measures. Finally, we summarize generalizable lessons for introducing human-in-the-loop computation within a visual text analytics system.},
	language = {en},
	urldate = {2018-09-08},
	journal = {Information Visualization},
	author = {Hoque, Enamul and Carenini, Giuseppe},
	month = feb,
	year = {2018},
	keywords = {conversation, hierarchy, seq, topic, vis},
	pages = {147387161875722},
}

@inproceedings{CollaborativeFilteringEuclideanEmbedding,
	address = {Barcelona, Spain},
	title = {Collaborative filtering via euclidean embedding},
	isbn = {978-1-60558-906-0},
	url = {http://portal.acm.org/citation.cfm?doid=1864708.1864728},
	doi = {10.1145/1864708.1864728},
	abstract = {Recommendation systems suggest items based on user preferences. Collaborative ﬁltering is a popular approach in which recommending is based on the rating history of the system. One of the most accurate and scalable collaborative ﬁltering algorithms is matrix factorization, which is based on a latent factor model. We propose a novel Euclidean embedding method as an alternative latent factor model to implement collaborative ﬁltering. In this method, users and items are embedded in a uniﬁed Euclidean space where the distance between a user and an item is inversely proportional to the rating. This model is comparable to matrix factorization in terms of both scalability and accuracy while providing several advantages. First, the result of Euclidean embedding is more intuitively understandable for humans, allowing useful visualizations. Second, the neighborhood structure of the uniﬁed Euclidean space allows very eﬃcient recommendation queries. Finally, the method facilitates online implementation requirements such as mapping new users or items in an existing model. Our experimental results conﬁrm these advantages and show that collaborative ﬁltering via Euclidean embedding is a promising approach for online recommender systems.},
	language = {en},
	urldate = {2018-09-08},
	booktitle = {Proceedings of the fourth {ACM} conference on {Recommender} systems - {RecSys} '10},
	publisher = {ACM Press},
	author = {Khoshneshin, Mohammad and Street, W. Nick},
	year = {2010},
	keywords = {dm, dm-topic},
	pages = {87},
}

@article{RecommendationVisualizationSimilarMovies,
	title = {Recommendation and visualization of similar movies using minimum spanning dendrograms},
	volume = {12},
	issn = {1473-8716, 1473-8724},
	url = {http://journals.sagepub.com/doi/10.1177/1473871612439644},
	doi = {10.1177/1473871612439644},
	abstract = {Exploration of graph structures is an important topic in data mining and data visualization. This work presents a novel technique for visualizing neighbourhood and cluster relationships in graphs; we also show how this methodology can be used within the setting of a recommendation system. Our technique works by projecting the original object distances onto two dimensions while carefully retaining the ‘backbone’ of important distances. Cluster information is also overlayed on the same projected space. A significant advantage of our approach is that it can accommodate both metric and non-metric distance functions. Our methodology is applied to a visual recommender system for movies to allow easy exploration of the actor–movie bipartite graph. The work offers intuitive movie recommendations based on a selected pivot movie and allows the interactive discovery of related movies based on both textual and semantic features.},
	language = {en},
	number = {1},
	urldate = {2018-09-08},
	journal = {Information Visualization},
	author = {Vlachos, Michail and Svonava, Daniel},
	month = jan,
	year = {2013},
	keywords = {dm, dm-topic},
	pages = {85--101},
}

@inproceedings{IntegratingVisualSemanticContexts,
	address = {Santorini, Fira, Greece},
	title = {Integrating visual and semantic contexts for topic network generation and word sense disambiguation},
	isbn = {978-1-60558-480-5},
	url = {http://portal.acm.org/citation.cfm?doid=1646396.1646440},
	doi = {10.1145/1646396.1646440},
	abstract = {To support more eﬀective searches in large-scale weaklytagged image collections, we have developed a novel algorithm to integrate both the visual similarity contexts between the images and the semantic similarity contexts between their tags for topic network generation and word sense disambiguation. First, a topic network is generated to characterize both the semantic similarity contexts and the visual similarity contexts between the image topics more sufﬁciently. By organizing large numbers of image topics according to their cross-modal inter-topic similarity contexts, our topic network can make the semantics behind the tag space more explicit, so that users can gain deep insights rapidly and formulate their queries more precisely. Second, our word sense disambiguation algorithm can integrate the topic network to exploit both the visual similarity contexts between the images and the semantic similarity contexts between their tags for addressing the issues of polysemes and synonyms more eﬀectively, thus it can signiﬁcantly improve the precision and recall rates for image retrieval. Our experiments on large-scale Flickr and LabelMe image collections have provided very positive results.},
	language = {en},
	urldate = {2018-09-08},
	booktitle = {Proceeding of the {ACM} {International} {Conference} on {Image} and {Video} {Retrieval} - {CIVR} '09},
	publisher = {ACM Press},
	author = {Fan, Jianping and Luo, Hangzai and Shen, Yi and Yang, Chunlei},
	year = {2009},
	keywords = {dm, dm-topic},
	pages = {1},
}

@article{LongitudinalStudyTopicClassification,
	title = {A {Longitudinal} {Study} of {Topic} {Classification} on {Twitter}},
	abstract = {Twitter represents a massively distributed information source over a kaleidoscope of topics ranging from social and political events to entertainment and sports news. While recent work has suggested that variations on standard classiﬁers can be effectively trained as topical ﬁlters (Lin, Snow, and Morgan 2011; Yang et al. 2014; Magdy and Elsayed 2014), there remain many open questions about the efﬁcacy of such classiﬁcation-based ﬁltering approaches. For example, over a year or more after training, how well do such classiﬁers generalize to future novel topical content, and are such results stable across a range of topics? Furthermore, what features and feature classes are most critical for longterm classiﬁer performance? To answer these questions, we collected a corpus of over 800 million English Tweets via the Twitter streaming API during 2013 and 2014 and learned topic classiﬁers for 10 diverse themes ranging from social issues to celebrity deaths to the “Iran nuclear deal”. The results of this long-term study of topic classiﬁer performance provide a number of important insights, among them that (1) such classiﬁers can indeed generalize to novel topical content with high precision over a year or more after training and (2) simple terms and locations are the most informative feature classes (despite training on classes labeled via hashtags).},
	language = {en},
	author = {Iman, Zahra and Sanner, Scott and Bouadjenek, Mohamed Reda and Xie, Lexing},
	keywords = {dm, dm-topic},
	pages = {4},
}

@incollection{ModellingAnalysisUserBehaviour,
	address = {Berlin, Heidelberg},
	title = {Modelling and {Analysis} of {User} {Behaviour} in {Online} {Communities}},
	volume = {7031},
	isbn = {978-3-642-25072-9 978-3-642-25073-6},
	url = {http://link.springer.com/10.1007/978-3-642-25073-6_3},
	abstract = {Understanding and forecasting the health of an online community is of great value to its owners and managers who have vested interests in its longevity and success. Nevertheless, the association between community evolution and the behavioural patterns and trends of its members is not clearly understood, which hinders our ability of making accurate predictions of whether a community is ﬂourishing or diminishing. In this paper we use statistical analysis, combined with a semantic model and rules for representing and computing behaviour in online communities. We apply this model on a number of forum communities from Boards.ie to categorise behaviour of community members over time, and report on how diﬀerent behaviour compositions correlate with positive and negative community growth in these forums.},
	language = {en},
	urldate = {2018-09-08},
	booktitle = {The {Semantic} {Web} – {ISWC} 2011},
	publisher = {Springer Berlin Heidelberg},
	author = {Angeletou, Sofia and Rowe, Matthew and Alani, Harith},
	editor = {Aroyo, Lora and Welty, Chris and Alani, Harith and Taylor, Jamie and Bernstein, Abraham and Kagal, Lalana and Noy, Natasha and Blomqvist, Eva},
	year = {2011},
	doi = {10.1007/978-3-642-25073-6_3},
	keywords = {info, info-behavior, infosci-info-behavior},
	pages = {35--50},
}

@inproceedings{InteractingPredictionsVisualInspectionb,
	address = {Santa Clara, California, USA},
	title = {Interacting with {Predictions}: {Visual} {Inspection} of {Black}-box {Machine} {Learning} {Models}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Interacting with {Predictions}},
	url = {http://dl.acm.org/citation.cfm?doid=2858036.2858529},
	doi = {10.1145/2858036.2858529},
	abstract = {Understanding predictive models, in terms of interpreting and identifying actionable insights, is a challenging task. Often the importance of a feature in a model is only a rough estimate condensed into one number. However, our research goes beyond these na¨ıve estimates through the design and implementation of an interactive visual analytics system, Prospector. By providing interactive partial dependence diagnostics, data scientists can understand how features affect the prediction overall. In addition, our support for localized inspection allows data scientists to understand how and why speciﬁc datapoints are predicted as they are, as well as support for tweaking feature values and seeing how the prediction responds. Our system is then evaluated using a case study involving a team of data scientists improving predictive models for detecting the onset of diabetes from electronic medical records.},
	language = {en},
	urldate = {2018-09-08},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '16},
	publisher = {ACM Press},
	author = {Krause, Josua and Perer, Adam and Ng, Kenney},
	year = {2016},
	keywords = {fatml, interpretable, vis, xai},
	pages = {5686--5697},
}

@article{MeetingVisVisualNarrativesAssist,
	title = {{MeetingVis}: {Visual} {Narratives} to {Assist} in {Recalling} {Meeting} {Context} and {Content}},
	volume = {24},
	issn = {1077-2626},
	shorttitle = {{MeetingVis}},
	url = {https://ieeexplore.ieee.org/document/8320320/},
	doi = {10.1109/TVCG.2018.2816203},
	abstract = {In team-based workplaces, reviewing and reﬂecting on the content from a previously held meeting can lead to better planning and preparation. However, ineffective meeting summaries can impair this process, especially when participants have difﬁculty remembering what was said and what its context was. To assist with this process, we introduce MeetingVis, a visual narrative-based approach to meeting summarization. MeetingVis is composed of two primary components: (1) a data pipeline that processes the spoken audio from a group discussion, and (2) a visual-based interface that efﬁciently displays the summarized content. To design MeetingVis, we create a taxonomy of relevant meeting data points, identifying salient elements to promote recall and reﬂection. These are mapped to an augmented storyline visualization, which combines the display of participant activities, topic evolutions, and task assignments. For evaluation, we conduct a qualitative user study with ﬁve groups. Feedback from the study indicates that MeetingVis effectively triggers the recall of subtle details from prior meetings: all study participants were able to remember new details, points, and tasks compared to an unaided, memory-only baseline. This visual-based approaches can also potentially enhance the productivity of both individuals and the whole team.},
	language = {en},
	number = {6},
	urldate = {2018-09-08},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Shi, Yang and Bryan, Chris and Bhamidipati, Sridatt and Zhao, Ying and Zhang, Yaoxue and Ma, Kwan-Liu},
	month = jun,
	year = {2018},
	keywords = {seq, topic, vis},
	pages = {1918--1929},
}

@inproceedings{ImprovingUserTopicInterest,
	address = {Florence, Italy},
	title = {Improving {User} {Topic} {Interest} {Profiles} by {Behavior} {Factorization}},
	isbn = {978-1-4503-3469-3},
	url = {http://dl.acm.org/citation.cfm?doid=2736277.2741656},
	doi = {10.1145/2736277.2741656},
	abstract = {Many recommenders aim to provide relevant recommendations to users by building personal topic interest proﬁles and then using these proﬁles to ﬁnd interesting contents for the user. In social media, recommender systems build user proﬁles by directly combining users’ topic interest signals from a wide variety of consumption and publishing behaviors, such as social media posts they authored, commented on, +1’d or liked. Here we propose to separately model users’ topical interests that come from these various behavioral signals in order to construct better user proﬁles.},
	language = {en},
	urldate = {2018-09-08},
	booktitle = {Proceedings of the 24th {International} {Conference} on {World} {Wide} {Web} - {WWW} '15},
	publisher = {ACM Press},
	author = {Zhao, Zhe and Cheng, Zhiyuan and Hong, Lichan and Chi, Ed H.},
	year = {2015},
	keywords = {dm, dm-topic},
	pages = {1406--1416},
}

@article{StateArtSentimentVisualization,
	title = {The {State} of the {Art} in {Sentiment} {Visualization}: {The} {State} of the {Art} in {Sentiment} {Visualization}},
	volume = {37},
	issn = {01677055},
	shorttitle = {The {State} of the {Art} in {Sentiment} {Visualization}},
	url = {http://doi.wiley.com/10.1111/cgf.13217},
	doi = {10.1111/cgf.13217},
	abstract = {Visualization of sentiments and opinions extracted from or annotated in texts has become a prominent topic of research over the last decade. From basic pie and bar charts used to illustrate customer reviews to extensive visual analytics systems involving novel representations, sentiment visualization techniques have evolved to deal with complex multidimensional data sets, including temporal, relational and geospatial aspects. This contribution presents a survey of sentiment visualization techniques based on a detailed categorization. We describe the background of sentiment analysis, introduce a categorization for sentiment visualization techniques that includes 7 groups with 35 categories in total, and discuss 132 techniques from peer-reviewed publications together with an interactive web-based survey browser. Finally, we discuss insights and opportunities for further research in sentiment visualization. We expect this survey to be useful for visualization researchers whose interests include sentiment or other aspects of text data as well as researchers and practitioners from other disciplines in search of efﬁcient visualization techniques applicable to their tasks and data.},
	language = {en},
	number = {1},
	urldate = {2018-09-08},
	journal = {Computer Graphics Forum},
	author = {Kucher, Kostiantyn and Paradis, Carita and Kerren, Andreas},
	month = feb,
	year = {2018},
	keywords = {vis, vis-sentiment},
	pages = {71--96},
}

@article{InferringSocialNetworkUser,
	title = {Inferring social network user profiles using a partial social graph},
	volume = {47},
	issn = {0925-9902, 1573-7675},
	url = {http://link.springer.com/10.1007/s10844-016-0402-y},
	doi = {10.1007/s10844-016-0402-y},
	abstract = {User proﬁle inference on online social networks is a key task for targeted advertising and building recommender systems that rely on social network data. However, current algorithms for user proﬁling suffer from one or more of the following limitations: (1) assuming that the full social graph or a large training set of crawled data is available for training, (2) not exploiting the rich information that is available in social networks such as group memberships and likes, (3) treating numeric attributes as nominal attributes, and (4) not assessing the certainty of their predictions. In this paper, to address these limitations, we propose an algorithm named Partial Graph Proﬁle Inference+ (PGPI+). The PGPI+ algorithm can accurately infer user proﬁles under the constraint of a partial social graph. PGPI+ does not require training, and it lets the user select the trade-oﬀ between the amount of information to be crawled for inferring a user proﬁle and the accuracy the inference. Besides, PGPI+ is designed to use rich information about users when available: user proﬁles, friendship links, group memberships, and the ”views” and ”likes” from social networks such as Facebook. Moreover, to also address limitations 3 and 4, PGPI+ considers numeric attributes in addition to nominal attributes, and can evaluate the certainty of its predictions. An experimental evaluation with 31,247 user proﬁles from the Facebook and Pokec social networks shows that PGPI+ predicts user proﬁles with a higher accuracy than several start-of-the-art algorithms, and by accessing (crawling) less information from the social graph. Furthermore, an interesting result is that some proﬁle attributes such as the status (student/professor) and genre can be predicted with more than 95 \% accuracy using PGPI+.},
	language = {en},
	number = {2},
	urldate = {2018-09-11},
	journal = {Journal of Intelligent Information Systems},
	author = {Dougnon, Raïssa Yapan and Fournier-Viger, Philippe and Lin, Jerry Chun-Wei and Nkambou, Roger},
	month = oct,
	year = {2016},
	keywords = {dm},
	pages = {313--344},
}

@inproceedings{WhatAreYouKnown,
	address = {Shinjuku, Tokyo, Japan},
	title = {What {Are} {You} {Known} {For}?: {Learning} {User} {Topical} {Profiles} with {Implicit} and {Explicit} {Footprints}},
	isbn = {978-1-4503-5022-8},
	shorttitle = {What {Are} {You} {Known} {For}?},
	url = {http://dl.acm.org/citation.cfm?doid=3077136.3080820},
	doi = {10.1145/3077136.3080820},
	abstract = {User interests and expertise are valuable but o en hidden resources on social media. For example, Twi er Lists and LinkedIn’s Skill Tags provide a partial perspective on what users are known for (by aggregating crowd tagging knowledge), but the vast majority of users are untagged; their interests and expertise are essentially hidden from important applications such as personalized recommendation, community detection, and expert mining. A natural approach to overcome these limitations is to intelligently learn user topical pro les by exploiting information from multiple, heterogeneous footprints: for instance, Twi er users who post similar hashtags may have similar interests, and YouTube users who upvote the same videos may have similar preferences. And yet identifying “similar” users by exploiting similarity in such a footprint space o en provides con icting evidence, leading to poor-quality user pro les. In this paper, we propose a uni ed model for learning user topical pro les that simultaneously considers multiple footprints. We show how these footprints can be embedded in a generalized optimization framework that takes into account pairwise relations among all footprints for robustly learning user pro les. rough extensive experiments, we nd the proposed model is capable of learning high-quality user topical pro les, and leads to a 10-15\% improvement in precision and mean average error versus a crosstriadic factorization state-of-the-art baseline.},
	language = {en},
	urldate = {2018-09-11},
	booktitle = {Proceedings of the 40th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}  - {SIGIR} '17},
	publisher = {ACM Press},
	author = {Cao, Cheng and Ge, Hancheng and Lu, Haokai and Hu, Xia and Caverlee, James},
	year = {2017},
	keywords = {dm, repr-n-emb, topic},
	pages = {743--752},
}

@inproceedings{AnalyzingInformationSharingStrategies,
	address = {San Francisco, CA, USA},
	title = {Analyzing information sharing strategies of users in online social networks},
	isbn = {978-1-5090-2846-7},
	url = {http://ieeexplore.ieee.org/document/7752242/},
	doi = {10.1109/ASONAM.2016.7752242},
	abstract = {User information sharing is an important behavior in online social networks. Understanding such behavior could help in various applications such as user modeling, information cascade analysis, viral marketing, etc. In this paper, we aim to understand the strategies users employ to make retweet decision. We are interested in investigating whether these strategies in online social network contain signiﬁcant information about users and can be used to further characterize users. We propose a ﬂexible model that captures a number of behavior signals affecting user’s retweet decision. Our empirical results show that the inferred strategies can help increase the performance of retweet prediction.},
	language = {en},
	urldate = {2018-09-11},
	booktitle = {2016 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining} ({ASONAM})},
	publisher = {IEEE},
	author = {Nguyen, Dong-Anh and Tan, Shulong and Ramanathan, Ram and Yan, Xifeng},
	month = aug,
	year = {2016},
	keywords = {dm, info, info-behavior},
	pages = {247--254},
}

@inproceedings{UsingWordEmbeddingEvaluate,
	address = {Pisa, Italy},
	title = {Using {Word} {Embedding} to {Evaluate} the {Coherence} of {Topics} from {Twitter} {Data}},
	isbn = {978-1-4503-4069-4},
	url = {http://dl.acm.org/citation.cfm?doid=2911451.2914729},
	doi = {10.1145/2911451.2914729},
	abstract = {Scholars often seek to understand topics discussed on Twitter using topic modelling approaches. Several coherence metrics have been proposed for evaluating the coherence of the topics generated by these approaches, including the pre-calculated Pointwise Mutual Information (PMI) of word pairs and the Latent Semantic Analysis (LSA) word representation vectors. As Twitter data contains abbreviations and a number of peculiarities (e.g. hashtags), it can be challenging to train eﬀective PMI data or LSA word representation. Recently, Word Embedding (WE) has emerged as a particularly eﬀective approach for capturing the similarity among words. Hence, in this paper, we propose new Word Embedding-based topic coherence metrics. To determine the usefulness of these new metrics, we compare them with the previous PMI/LSA-based metrics. We also conduct a large-scale crowdsourced user study to determine whether the new Word Embedding-based metrics better align with human preferences. Using two Twitter datasets, our results show that the WE-based metrics can capture the coherence of topics in tweets more robustly and eﬃciently than the PMI/LSA-based ones.},
	language = {en},
	urldate = {2018-09-11},
	booktitle = {Proceedings of the 39th {International} {ACM} {SIGIR} conference on {Research} and {Development} in {Information} {Retrieval} - {SIGIR} '16},
	publisher = {ACM Press},
	author = {Fang, Anjie and Macdonald, Craig and Ounis, Iadh and Habel, Philip},
	year = {2016},
	keywords = {dm, repr-n-emb},
	pages = {1057--1060},
}

@inproceedings{DynamicEmbeddingsUserProfiling,
	address = {London, United Kingdom},
	title = {Dynamic {Embeddings} for {User} {Profiling} in {Twitter}},
	isbn = {978-1-4503-5552-0},
	url = {http://dl.acm.org/citation.cfm?doid=3219819.3220043},
	doi = {10.1145/3219819.3220043},
	abstract = {In this paper, we study the problem of dynamic user profiling in Twitter. We address the problem by proposing a dynamic user and word embedding model (DUWE), a scalable black-box variational inference algorithm, and a streaming keyword diversification model (SKDM). DUWE dynamically tracks the semantic representations of users and words over time and models their embeddings in the same space so that their similarities can be effectively measured. Our inference algorithm works with a convex objective function that ensures the robustness of the learnt embeddings. SKDM aims at retrieving top-K relevant and diversified keywords to profile users’ dynamic interests. Experiments on a Twitter dataset demonstrate that our proposed embedding algorithms outperform state-of-theart non-dynamic and dynamic embedding and topic models.},
	language = {en},
	urldate = {2018-09-11},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '18},
	publisher = {ACM Press},
	author = {Liang, Shangsong and Zhang, Xiangliang and Ren, Zhaochun and Kanoulas, Evangelos},
	year = {2018},
	keywords = {dm},
	pages = {1764--1773},
}

@article{CARLContentAwareRepresentationLearning,
	title = {{CARL}: {Content}-{Aware} {Representation} {Learning} for {Heterogeneous} {Networks}},
	shorttitle = {{CARL}},
	url = {http://arxiv.org/abs/1805.04983},
	abstract = {Heterogeneous networks not only present a challenge of heterogeneity in the types of nodes and relations, but also the attributes and content associated with the nodes. While recent works have looked at representation learning on homogeneous and heterogeneous networks, there is no work that has collectively addressed the following challenges: (a) the heterogeneous structural information of the network consisting of multiple types of nodes and relations; (b) the unstructured semantic content (e.g., text) associated with nodes; and (c) online updates due to incoming new nodes in growing network. We address these challenges by developing a Content-Aware Representation Learning model (CARL). CARL performs joint optimization of heterogeneous SkipGram and deep semantic encoding for capturing both heterogeneous structural closeness and unstructured semantic relations among all nodes, as function of node content, that exist in the network. Furthermore, an additional online update module is proposed for efficiently learning representations of incoming nodes. Extensive experiments demonstrate that CARL outperforms state-of-the-art baselines in various heterogeneous network mining tasks, such as link prediction, document retrieval, node recommendation and relevance search. We also demonstrate the effectiveness of the CARL’s online update module through a category visualization study.},
	language = {en},
	urldate = {2018-09-11},
	journal = {arXiv:1805.04983 [cs]},
	author = {Zhang, Chuxu and Swami, Ananthram and Chawla, Nitesh V.},
	month = may,
	year = {2018},
	note = {arXiv: 1805.04983},
	keywords = {dm},
}

@inproceedings{DynamicTopicModels,
	address = {Pittsburgh, Pennsylvania},
	title = {Dynamic topic models},
	isbn = {978-1-59593-383-6},
	url = {http://portal.acm.org/citation.cfm?doid=1143844.1143859},
	doi = {10.1145/1143844.1143859},
	abstract = {A family of probabilistic time series models is developed to analyze the time evolution of topics in large document collections. The approach is to use state space models on the natural parameters of the multinomial distributions that represent the topics. Variational approximations based on Kalman ﬁlters and nonparametric wavelet regression are developed to carry out approximate posterior inference over the latent topics. In addition to giving quantitative, predictive models of a sequential corpus, dynamic topic models provide a qualitative window into the contents of a large document collection. The models are demonstrated by analyzing the OCR’ed archives of the journal Science from 1880 through 2000.},
	language = {en},
	urldate = {2018-09-08},
	booktitle = {Proceedings of the 23rd international conference on {Machine} learning  - {ICML} '06},
	publisher = {ACM Press},
	author = {Blei, David M. and Lafferty, John D.},
	year = {2006},
	keywords = {dm, dm-topic},
	pages = {113--120},
}

@article{EarlyIdentificationPersonalizedTrending,
	title = {Early {Identification} of {Personalized} {Trending} {Topics} in {Microblogging}},
	abstract = {Social media has become a primary platform for the spread of information. Trending topics, which are breaking news and immediately popular stories, have become an attractive data source facilitating the spread of emerging issues. Motivated by the diverse trending topics covering from sports to politics, it is essential to help users ﬁnd personalized trending topics. Since a topic in social media may start trending and get obsoleted quickly, the personalization would be more valuable to a user if the trending topic can be recommended before it is outdated. In order to identify personalized trending topics at an early stage, we propose to identify and exploit the auxiliary information. In particular, through collectively modeling content of similar users with social network information, we identify additional past contents that can enrich the training data of trending topics and users. The key insight is that though most posts of a user may be irrelevant, a few key posts can be signals revealing interests towards a particular topic. Experiments on real-world data demonstrate that our proposed approach effectively personalizes trending topics when they just start trending.},
	language = {en},
	author = {Wu, Liang and Hu, Xia and Liu, Huan},
	keywords = {dm, dm-topic},
	pages = {5},
}

@article{UserStudyEffectAggregating,
	title = {A {User} {Study} on the {Effect} of {Aggregating} {Explanations} for {Interpreting} {Machine} {Learning} {Models}},
	abstract = {Recently, there is growing consensus of the critical need to have better techniques to explain machine learning models. However, many of the popular techniques are instance-level explanations, which explain the model from the point of view of a single data point. While local explanations may be misleading, they are also not human-scale, as it is impossible for users to read explanations for how the model behaves on all of their data points. Our work-in-progress paper explores the effectiveness of providing instance-level explanations in aggregate, by demonstrating that such aggregated explanations have a significant impact on users’ ability to detect biases in data. This is achieved by comparing meaningful subsets, such as differences between ground truth labels, predicted labels, and correct and incorrect predictions, which provide necessary navigation to explain machine learning models.},
	language = {en},
	author = {Krause, Josua and Perer, Adam and Bertini, Enrico},
	year = {2018},
	keywords = {fatml, interpretable, key, vis, xai},
	pages = {9},
}

@article{DataDecisionsTheoreticalImplications,
	title = {Data {Decisions} and {Theoretical} {Implications} when {Adversarially} {Learning} {Fair} {Representations}},
	url = {http://arxiv.org/abs/1707.00075},
	abstract = {How can we learn a classi er that is “fair” for a protected or sensitive group, when we do not know if the input to the classi er belongs to the protected group? How can we train such a classi er when data on the protected group is di cult to a ain? In many settings, nding out the sensitive input a ribute can be prohibitively expensive even during model training, and sometimes impossible during model serving. For example, in recommender systems, if we want to predict if a user will click on a given recommendation, we o en do not know many a ributes of the user, e.g., race or age, and many a ributes of the content are hard to determine, e.g., the language or topic. us, it is not feasible to use a di erent classi er calibrated based on knowledge of the sensitive a ribute.},
	language = {en},
	urldate = {2018-09-11},
	journal = {arXiv:1707.00075 [cs]},
	author = {Beutel, Alex and Chen, Jilin and Zhao, Zhe and Chi, Ed H.},
	month = jun,
	year = {2017},
	note = {arXiv: 1707.00075},
	keywords = {fair, fatml, xai},
}

@article{SurveyNetworkEmbedding,
	title = {A {Survey} on {Network} {Embedding}},
	issn = {1041-4347},
	url = {https://ieeexplore.ieee.org/document/8392745/},
	doi = {10.1109/TKDE.2018.2849727},
	abstract = {Network embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a signiﬁcant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We ﬁrst summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information and the advanced information preserving network embedding methods.},
	language = {en},
	urldate = {2018-09-13},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Cui, Peng and Wang, Xiao and Pei, Jian and Zhu, Wenwu},
	year = {2018},
	keywords = {dm, network, repr-n-emb},
	pages = {1--1},
}

@book{SocialCulturalBehavioralModeling,
	address = {New York, NY},
	title = {Social, cultural, and behavioral modeling},
	isbn = {978-3-319-93371-9},
	language = {en},
	publisher = {Springer Berlin Heidelberg},
	year = {2018},
	keywords = {dm, topic},
}

@inproceedings{MemetrackingDynamicsNewsCycle,
	address = {Paris, France},
	title = {Meme-tracking and the dynamics of the news cycle},
	isbn = {978-1-60558-495-9},
	url = {http://portal.acm.org/citation.cfm?doid=1557019.1557077},
	doi = {10.1145/1557019.1557077},
	abstract = {Tracking new topics, ideas, and “memes” across the Web has been an issue of considerable interest. Recent work has developed methods for tracking topic shifts over long time scales, as well as abrupt spikes in the appearance of particular named entities. However, these approaches are less well suited to the identiﬁcation of content that spreads widely and then fades over time scales on the order of days — the time scale at which we perceive news and events.},
	language = {en},
	urldate = {2018-09-11},
	booktitle = {Proceedings of the 15th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '09},
	publisher = {ACM Press},
	author = {Leskovec, Jure and Backstrom, Lars and Kleinberg, Jon},
	year = {2009},
	keywords = {diffusion, dm},
	pages = {497},
}

@article{DeepSentenceEmbeddingUsing,
	title = {Deep {Sentence} {Embedding} {Using} {Long} {Short}-{Term} {Memory} {Networks}: {Analysis} and {Application} to {Information} {Retrieval}},
	volume = {24},
	issn = {2329-9290, 2329-9304},
	shorttitle = {Deep {Sentence} {Embedding} {Using} {Long} {Short}-{Term} {Memory} {Networks}},
	url = {http://arxiv.org/abs/1502.06922},
	doi = {10.1109/TASLP.2016.2520371},
	abstract = {This paper develops a model that addresses sentence embedding, a hot topic in current natural language processing research, using recurrent neural networks (RNN) with Long Short-Term Memory (LSTM) cells. The proposed LSTM-RNN model sequentially takes each word in a sentence, extracts its information, and embeds it into a semantic vector. Due to its ability to capture long term memory, the LSTM-RNN accumulates increasingly richer information as it goes through the sentence, and when it reaches the last word, the hidden layer of the network provides a semantic representation of the whole sentence. In this paper, the LSTM-RNN is trained in a weakly supervised manner on user click-through data logged by a commercial web search engine. Visualization and analysis are performed to understand how the embedding process works. The model is found to automatically attenuate the unimportant words and detects the salient keywords in the sentence. Furthermore, these detected keywords are found to automatically activate different cells of the LSTMRNN, where words belonging to a similar topic activate the same cell. As a semantic representation of the sentence, the embedding vector can be used in many different applications. These automatic keyword detection and topic allocation abilities enabled by the LSTM-RNN allow the network to perform document retrieval, a difﬁcult language processing task, where the similarity between the query and documents can be measured by the distance between their corresponding sentence embedding vectors computed by the LSTM-RNN. On a web search task, the LSTM-RNN embedding is shown to signiﬁcantly outperform several existing state of the art methods. We emphasize that the proposed model generates sentence embedding vectors that are specially useful for web document retrieval tasks. A comparison with a well known general sentence embedding method, the Paragraph Vector, is performed. The results show that the proposed method in this paper signiﬁcantly outperforms it for web document retrieval task.},
	language = {en},
	number = {4},
	urldate = {2018-09-11},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Palangi, Hamid and Deng, Li and Shen, Yelong and Gao, Jianfeng and He, Xiaodong and Chen, Jianshu and Song, Xinying and Ward, Rabab},
	month = apr,
	year = {2016},
	note = {arXiv: 1502.06922},
	keywords = {dl, dm, repr-n-emb},
	pages = {694--707},
}

@article{RepresentationLearningGraphsMethods,
	title = {Representation {Learning} on {Graphs}: {Methods} and {Applications}},
	shorttitle = {Representation {Learning} on {Graphs}},
	url = {http://arxiv.org/abs/1709.05584},
	abstract = {Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is ﬁnding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-deﬁned heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a uniﬁed framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.},
	language = {en},
	urldate = {2018-09-11},
	journal = {arXiv:1709.05584 [cs]},
	author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.05584},
	keywords = {dm, network, repr-n-emb, survey},
}

@article{NetworkRepresentationLearningRich,
	title = {Network {Representation} {Learning} with {Rich} {Text} {Information}},
	abstract = {Representation learning has shown its effectiveness in many tasks such as image classiﬁcation and text mining. Network representation learning aims at learning distributed vector representation for each vertex in a network, which is also increasingly recognized as an important aspect for network analysis. Most network representation learning methods investigate network structures for learning. In reality, network vertices contain rich information (such as text), which cannot be well applied with algorithmic frameworks of typical representation learning methods. By proving that DeepWalk, a state-ofthe-art network representation method, is actually equivalent to matrix factorization (MF), we propose text-associated DeepWalk (TADW). TADW incorporates text features of vertices into network representation learning under the framework of matrix factorization. We evaluate our method and various baseline methods by applying them to the task of multi-class classiﬁcation of vertices. The experimental results show that, our method outperforms other baselines on all three datasets, especially when networks are noisy and training ratio is small. The source code of this paper can be obtained from https://github.com/albertyang33/TADW.},
	language = {en},
	author = {Yang, Cheng and Liu, Zhiyuan and Zhao, Deli and Sun, Maosong and Chang, Edward Y},
	keywords = {dm, network, repr-n-emb},
	pages = {7},
}

@inproceedings{QuestionsQuestionsEmpiricalAnalysis,
	address = {Rio de Janeiro, Brazil},
	title = {Questions about questions: an empirical analysis of information needs on {Twitter}},
	isbn = {978-1-4503-2035-1},
	shorttitle = {Questions about questions},
	url = {http://dl.acm.org/citation.cfm?doid=2488388.2488523},
	doi = {10.1145/2488388.2488523},
	abstract = {Conventional studies of online information seeking behavior usually focus on the use of search engines or question answering (Q\&A) websites. Recently, the fast growth of online social platforms such as Twitter and Facebook has made it possible for people to utilize them for information seeking by asking questions to their friends or followers. We anticipate a better understanding of Web users’ information needs by investigating research questions about these questions. How are they distinctive from daily tweeted conversations? How are they related to search queries? Can users’ information needs on one platform predict those on the other? In this study, we take the initiative to extract and analyze information needs from billions of online conversations collected from Twitter. With an automatic text classiﬁer, we can accurately detect real questions in tweets (i.e., tweets conveying real information needs). We then present a comprehensive analysis of the large-scale collection of information needs we extracted. We found that questions being asked on Twitter are substantially diﬀerent from the topics being tweeted in general. Information needs detected on Twitter have a considerable power of predicting the trends of Google queries. Many interesting signals emerge through longitudinal analysis of the volume, spikes, and entropy of questions on Twitter, which provide insights to the understanding of the impact of real world events and user behavioral patterns in social platforms.},
	language = {en},
	urldate = {2018-09-11},
	booktitle = {Proceedings of the 22nd international conference on {World} {Wide} {Web} - {WWW} '13},
	publisher = {ACM Press},
	author = {Zhao, Zhe and Mei, Qiaozhu},
	year = {2013},
	keywords = {dm, info, info-needs},
	pages = {1545--1556},
}

@inproceedings{ModelingTaskRelationshipsMultitask,
	address = {London, United Kingdom},
	title = {Modeling {Task} {Relationships} in {Multi}-task {Learning} with {Multi}-gate {Mixture}-of-{Experts}},
	isbn = {978-1-4503-5552-0},
	url = {http://dl.acm.org/citation.cfm?doid=3219819.3220007},
	doi = {10.1145/3219819.3220007},
	abstract = {Neural-based multi-task learning has been successfully used in many real-world large-scale applications such as recommendation systems. For example, in movie recommendations, beyond providing users movies which they tend to purchase and watch, the system might also optimize for users liking the movies afterwards. With multi-task learning, we aim to build a single model that learns these multiple goals and tasks simultaneously. However, the prediction quality of commonly used multi-task models is often sensitive to the relationships between tasks. It is therefore important to study the modeling tradeo s between task-speci c objectives and inter-task relationships.},
	language = {en},
	urldate = {2018-09-11},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '18},
	publisher = {ACM Press},
	author = {Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Chen, Jilin and Hong, Lichan and Chi, Ed H.},
	year = {2018},
	keywords = {dl, dm},
	pages = {1930--1939},
}

@article{SentimentdrivenCommunityProfilingDetection,
	title = {Sentiment-driven {Community} {Profiling} and {Detection} on {Social} {Media}},
	url = {http://arxiv.org/abs/1805.04191},
	doi = {10.1145/3209542.3209565},
	abstract = {Web 2.0 helps to expand the range and depth of conversation on many issues and facilitates the formation of online communities. Online communities draw various individuals together based on their common opinions on a core set of issues. Most existing community detection methods merely focus on discovering communities without providing any insight regarding the collective opinions of community members and the motives behind the formation of communities. Several efforts have been made to tackle this problem by presenting a set of keywords as a community profile. However, they neglect the positions of community members towards keywords, which play an important role for understanding communities in the highly polarized atmosphere of social media. To this end, we present a sentiment-driven community profiling and detection framework which aims to provide community profiles presenting positive and negative collective opinions of community members separately. With this regard, our framework initially extracts key expressions in users’ messages as representative of issues and then identifies users’ positive/negative attitudes towards these key expressions. Next, it uncovers a low-dimensional latent space in order to cluster users according to their opinions and social interactions (i.e., retweets). We demonstrate the effectiveness of our framework through quantitative and qualitative evaluations.},
	language = {en},
	urldate = {2018-09-11},
	journal = {Proceedings of the 29th on Hypertext and Social Media  - HT '18},
	author = {Salehi, Amin and Ozer, Mert and Davulcu, Hasan},
	year = {2018},
	note = {arXiv: 1805.04191},
	keywords = {dm, topic},
	pages = {229--237},
}

@article{ProbablyApproximatelyMetricFairLearning,
	title = {Probably {Approximately} {Metric}-{Fair} {Learning}},
	url = {http://arxiv.org/abs/1803.03242},
	abstract = {The seminal work of Dwork et al. [ITCS 2012] introduced a metric-based notion of individual fairness. Given a task-speciﬁc similarity metric, their notion required that every pair of similar individuals should be treated similarly. In the context of machine learning, however, individual fairness does not generalize from a training set to the underlying population. We show that this can lead to computational intractability even for simple fair-learning tasks.},
	language = {en},
	urldate = {2018-09-11},
	journal = {arXiv:1803.03242 [cs]},
	author = {Rothblum, Guy N. and Yona, Gal},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.03242},
	keywords = {fair, fatml, xai},
}

@article{ActiVisVisualExplorationIndustryScale,
	title = {{ActiVis}: {Visual} {Exploration} of {Industry}-{Scale} {Deep} {Neural} {Network} {Models}},
	shorttitle = {{ActiVis}},
	url = {http://arxiv.org/abs/1704.01942},
	abstract = {While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ACTIVIS, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance- and subset-level. ACTIVIS has been deployed on Facebook’s machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ACTIVIS may work with different models.},
	language = {en},
	urldate = {2018-09-13},
	journal = {arXiv:1704.01942 [cs, stat]},
	author = {Kahng, Minsuk and Andrews, Pierre Y. and Kalro, Aditya and Chau, Duen Horng},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.01942},
	keywords = {dl, vis},
}

@article{EmbeddingProjectorInteractiveVisualization,
	title = {Embedding {Projector}: {Interactive} {Visualization} and {Interpretation} of {Embeddings}},
	shorttitle = {Embedding {Projector}},
	url = {http://arxiv.org/abs/1611.05469},
	abstract = {Embeddings are ubiquitous in machine learning, appearing in recommender systems, NLP, and many other applications. Researchers and developers often need to explore the properties of a speciﬁc embedding, and one way to analyze embeddings is to visualize them. We present the Embedding Projector, a tool for interactive visualization and interpretation of embeddings.},
	language = {en},
	urldate = {2018-09-13},
	journal = {arXiv:1611.05469 [cs, stat]},
	author = {Smilkov, Daniel and Thorat, Nikhil and Nicholson, Charles and Reif, Emily and Viégas, Fernanda B. and Wattenberg, Martin},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.05469},
	keywords = {emb, repr-n-emb, vis},
}

@book{Proceedings2018SIAMInternational,
	address = {Philadelphia, PA},
	title = {Proceedings of the 2018 {SIAM} {International} {Conference} on {Data} {Mining}},
	isbn = {978-1-61197-532-1},
	url = {https://epubs.siam.org/doi/book/10.1137/1.9781611975321},
	abstract = {Populating ontology graphs represents a long-standing problem for the Semantic Web community. Recent advances in translation-based graph embedding methods for populating instance-level knowledge graphs lead to promising new approaching for the ontology population problem. However, unlike instance-level graphs, the majority of relation facts in ontology graphs come with comprehensive semantic relations, which often include the properties of transitivity and symmetry, as well as hierarchical relations. These comprehensive relations are often too complex for existing graph embedding methods, and direct application of such methods is not feasible. Hence, we propose On2Vec, a novel translationbased graph embedding method for ontology population. On2Vec integrates two model components that eﬀectively characterize comprehensive relation facts in ontology graphs. The ﬁrst is the Component-speciﬁc Model that encodes concepts and relations into lowdimensional embedding spaces without a loss of relational properties; the second is the Hierarchy Model that performs focused learning of hierarchical relation facts. Experiments on several well-known ontology graphs demonstrate the promising capabilities of On2Vec in predicting and verifying new relation facts. These promising results also make possible signiﬁcant improvements in related methods.},
	language = {en},
	urldate = {2018-09-13},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Ester, Martin and Pedreschi, Dino},
	month = may,
	year = {2018},
	doi = {10.1137/1.9781611975321},
	keywords = {dm},
}

@inproceedings{RealtimePersonalizationUsingEmbeddings,
	address = {London, United Kingdom},
	title = {Real-time {Personalization} using {Embeddings} for {Search} {Ranking} at {Airbnb}},
	isbn = {978-1-4503-5552-0},
	url = {http://dl.acm.org/citation.cfm?doid=3219819.3219885},
	doi = {10.1145/3219819.3219885},
	abstract = {Search Ranking and Recommendations are fundamental problems of crucial interest to major Internet companies, including web search engines, content publishing websites and marketplaces. However, despite sharing some common characteristics a one-size-fitsall solution does not exist in this space. Given a large difference in content that needs to be ranked, personalized and recommended, each marketplace has a somewhat unique challenge. Correspondingly, at Airbnb, a short-term rental marketplace, search and recommendation problems are quite unique, being a two-sided marketplace in which one needs to optimize for host and guest preferences, in a world where a user rarely consumes the same item twice and one listing can accept only one guest for a certain set of dates. In this paper we describe Listing and User Embedding techniques we developed and deployed for purposes of Real-time Personalization in Search Ranking and Similar Listing Recommendations, two channels that drive 99\% of conversions. The embedding models were specifically tailored for Airbnb marketplace, and are able to capture guest’s short-term and long-term interests, delivering effective home listing recommendations. We conducted rigorous offline testing of the embedding models, followed by successful online tests before fully deploying them into production.},
	language = {en},
	urldate = {2018-09-13},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '18},
	publisher = {ACM Press},
	author = {Grbovic, Mihajlo and Cheng, Haibin},
	year = {2018},
	keywords = {dl, dm, repr-n-emb},
	pages = {311--320},
}

@inproceedings{DeepAttributedNetworkEmbedding,
	address = {Stockholm, Sweden},
	title = {Deep {Attributed} {Network} {Embedding}},
	isbn = {978-0-9992411-2-7},
	url = {https://www.ijcai.org/proceedings/2018/467},
	doi = {10.24963/ijcai.2018/467},
	abstract = {Network embedding has attracted a surge of attention in recent years. It is to learn the lowdimensional representation for nodes in a network, which beneﬁts downstream tasks such as node classiﬁcation and link prediction. Most of the existing approaches learn node representations only based on the topological structure, yet nodes are often associated with rich attributes in many real-world applications. Thus, it is important and necessary to learn node representations based on both the topological structure and node attributes. In this paper, we propose a novel deep attributed network embedding approach, which can capture the high nonlinearity and preserve various proximities in both topological structure and node attributes. At the same time, a novel strategy is proposed to guarantee the learned node representation can encode the consistent and complementary information from the topological structure and node attributes. Extensive experiments on benchmark datasets have veriﬁed the effectiveness of our proposed approach.},
	language = {en},
	urldate = {2018-09-13},
	booktitle = {Proceedings of the {Twenty}-{Seventh} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Gao, Hongchang and Huang, Heng},
	month = jul,
	year = {2018},
	keywords = {dl, dm, repr-n-emb},
	pages = {3364--3370},
}

@article{GraphEmbeddingTechniquesApplications,
	title = {Graph {Embedding} {Techniques}, {Applications}, and {Performance}: {A} {Survey}},
	volume = {151},
	issn = {09507051},
	shorttitle = {Graph {Embedding} {Techniques}, {Applications}, and {Performance}},
	url = {http://arxiv.org/abs/1705.02801},
	doi = {10.1016/j.knosys.2018.03.022},
	abstract = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and diﬀerent patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We ﬁrst introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We ﬁnally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a uniﬁed interface to foster and facilitate research on the topic.},
	language = {en},
	urldate = {2018-09-13},
	journal = {Knowledge-Based Systems},
	author = {Goyal, Palash and Ferrara, Emilio},
	month = jul,
	year = {2018},
	note = {arXiv: 1705.02801},
	keywords = {dl, dm, network, repr-n-emb},
	pages = {78--94},
}

@inproceedings{HierarchicalTaxonomyAwareNetwork,
	address = {London, United Kingdom},
	title = {Hierarchical {Taxonomy} {Aware} {Network} {Embedding}},
	isbn = {978-1-4503-5552-0},
	url = {http://dl.acm.org/citation.cfm?doid=3219819.3220062},
	doi = {10.1145/3219819.3220062},
	abstract = {Network embedding learns the low-dimensional representations for vertices, while preserving the inter-vertex similarity reflected by the network structure. The neighborhood structure of a vertex is usually closely related with an underlying hierarchical taxonomy—the vertices are associated with successively broader categories that can be organized hierarchically. The categories of different levels reflects similarity of different granularity. The hierarchy of the taxonomy therefore requires that the learned representations support multiple levels of granularity. Moreover, the hierarchical taxonomy enables the information to flow between vertices via their common categories, and thus provides an effective mechanism for alleviating data scarcity. However, incorporating the hierarchical taxonomy into network embedding poses a great challenge (since the taxonomy is generally unknown), and it is neglected by the existing approaches. In this paper, we propose NetHiex, a NETwork embedding model that captures the latent HIErarchical taXonomy. In our model, a vertex representation consists of multiple components that are associated with categories of different granularity. The representations of both the vertices and the categories are co-regularized. We employ the nested Chinese restaurant process to guide the search of the most plausible hierarchical taxonomy. The network structure is then recovered from the latent representations via a Bernoulli distribution. The whole model is unified within a nonparametric probabilistic framework. A scalable expectation-maximization algorithm is derived for optimization. Empirical results demonstrate that NetHiex achieves significant performance gain over the state-of-arts.},
	language = {en},
	urldate = {2018-09-13},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '18},
	publisher = {ACM Press},
	author = {Ma, Jianxin and Cui, Peng and Wang, Xiao and Zhu, Wenwu},
	year = {2018},
	keywords = {dl, dm, network, repr-n-emb},
	pages = {1920--1929},
}

@article{Hyperdoc2vecDistributedRepresentationsHypertext,
	title = {hyperdoc2vec: {Distributed} {Representations} of {Hypertext} {Documents}},
	shorttitle = {hyperdoc2vec},
	url = {http://arxiv.org/abs/1805.03793},
	abstract = {Hypertext documents, such as web pages and academic papers, are of great importance in delivering information in our daily life. Although being effective on plain documents, conventional text embedding methods suffer from information loss if directly adapted to hyper-documents. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several competitors on two tasks, i.e., paper classiﬁcation and citation recommendation, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other models w.r.t. the four criteria.},
	language = {en},
	urldate = {2018-09-13},
	journal = {arXiv:1805.03793 [cs]},
	author = {Han, Jialong and Song, Yan and Zhao, Wayne Xin and Shi, Shuming and Zhang, Haisong},
	month = may,
	year = {2018},
	note = {arXiv: 1805.03793},
	keywords = {dl, dm, network, repr-n-emb},
}

@incollection{Paper2vecCombiningGraphText,
	address = {Cham},
	title = {Paper2vec: {Combining} {Graph} and {Text} {Information} for {Scientific} {Paper} {Representation}},
	volume = {10193},
	isbn = {978-3-319-56607-8 978-3-319-56608-5},
	shorttitle = {Paper2vec},
	url = {http://link.springer.com/10.1007/978-3-319-56608-5_30},
	abstract = {We present Paper2vec, a novel neural network embedding based approach for creating scientiﬁc paper representations which make use of both textual and graph-based information. An academic citation network can be viewed as a graph where individual nodes contain rich textual information. With the current trend of open-access to most scientiﬁc literature, we presume that this full text of a scientiﬁc article contain vital source of information which aids in various recommendation and prediction tasks concerning this domain. To this end, we propose an approach, Paper2vec, which comprises of information from both the modalities and results in a rich representation for scientiﬁc papers. Over the recent past representation learning techniques have been studied extensively using neural networks. However, they are modeled independently for text and graph data. Paper2vec leverages recent research in the broader ﬁeld of unsupervised feature learning from both graphs and text documents. We demonstrate the eﬃcacy of our representations on three real world academic datasets in two tasks - node classiﬁcation and link prediction where Paper2vec is able to outperform state-of-the-art by a considerable margin.},
	language = {en},
	urldate = {2018-09-13},
	booktitle = {Advances in {Information} {Retrieval}},
	publisher = {Springer International Publishing},
	author = {Ganguly, Soumyajit and Pudi, Vikram},
	editor = {Jose, Joemon M and Hauff, Claudia and Altıngovde, Ismail Sengor and Song, Dawei and Albakour, Dyaa and Watt, Stuart and Tait, John},
	year = {2017},
	doi = {10.1007/978-3-319-56608-5_30},
	keywords = {dm, repr-n-emb},
	pages = {383--395},
}

@article{LearningFairRepresentations,
	title = {Learning {Fair} {Representations}},
	abstract = {We propose a learning algorithm for fair classiﬁcation that achieves both group fairness (the proportion of members in a protected group receiving positive classiﬁcation is identical to the proportion in the population as a whole), and individual fairness (similar individuals should be treated similarly). We formulate fairness as an optimization problem of ﬁnding a good representation of the data with two competing goals: to encode the data as well as possible, while simultaneously obfuscating any information about membership in the protected group. We show positive results of our algorithm relative to other known techniques, on three datasets. Moreover, we demonstrate several advantages to our approach. First, our intermediate representation can be used for other classiﬁcation tasks (i.e., transfer learning is possible); secondly, we take a step toward learning a distance metric which can ﬁnd important dimensions of the data for classiﬁcation.},
	language = {en},
	author = {Zemel, Richard},
	keywords = {comps-dm, fair, fatml},
	pages = {9},
}

@article{ChronAtlasVisualizationDynamicTopic,
	title = {{ChronAtlas}: {A} {Visualization} for {Dynamic} {Topic} {Exploration}},
	abstract = {Documents in rich text corpora such as digital libraries and social media often contain complex information. These data resources are huge in amount, dynamic in nature and contain multifaceted information. This poster presents ChronAtlas, a visual analytic technique for visually exploring topics in multifaceted dynamic data. ChronAtlas simultaneously visualizes the topic distribution of the underlying entities from one facet together with keyword distributions that convey the semantic deﬁnition of each cluster along a secondary facet. ChronAtlas combines several visual techniques including 1) topic contour clusters and interactive multifaceted keyword topic rings, 2) a global layout optimization algorithm that aligns each topic cluster with its corresponding keywords, and 3) an optimal temporal network summarization and clustering algorithm that renders evolution trends of clusters.},
	language = {en},
	author = {Cao, Nan and Lin, Yu-Ru and Gotz, David and Sun, Jimeng and Qu, Huamin},
	keywords = {seq, topic, vis},
	pages = {2},
}

@article{VisualAnalyticsTopicsTwitter,
	title = {Visual analytics of topics in {Twitter} in connection with political debates},
	language = {en},
	author = {de Carvalho, Eder José},
	keywords = {thesis, topic, vis},
	pages = {83},
}

@article{FairnessExposureRankings,
	title = {Fairness of {Exposure} in {Rankings}},
	url = {http://arxiv.org/abs/1802.07281},
	abstract = {Rankings are ubiquitous in the online world today. As we have transitioned from finding books in libraries to ranking products, jobs, job applicants, opinions and potential romantic partners, there is a substantial precedent that ranking systems have a responsibility not only to their users but also to the items being ranked. To address these often conflicting responsibilities, we propose a conceptual and computational framework that allows the formulation of fairness constraints on rankings. As part of this framework, we develop efficient algorithms for finding rankings that maximize the utility for the user while satisfying fairness constraints for the items. Since fairness goals can be application specific, we show how a broad range of fairness constraints can be implemented in our framework, including forms of demographic parity, disparate treatment, and disparate impact constraints. We illustrate the effect of these constraints by providing empirical results on two ranking problems.},
	language = {en},
	urldate = {2018-10-06},
	journal = {arXiv:1802.07281 [cs]},
	author = {Singh, Ashudeep and Joachims, Thorsten},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.07281},
	keywords = {fatml, ranking},
}

@article{HowBeFairDiverse,
	title = {How to be {Fair} and {Diverse}?},
	url = {http://arxiv.org/abs/1610.07183},
	abstract = {Due to the recent cases of algorithmic bias in datadriven decision-making, machine learning methods are being put under the microscope in order to understand the root cause of these biases and how to correct them. Here, we consider a basic algorithmic task that is central in machine learning: subsampling from a large data set. Subsamples are used both as an end-goal in data summarization (where fairness could either be a legal, political or moral requirement) and to train algorithms (where biases in the samples are often a source of bias in the resulting model). Consequently, there is a growing eﬀort to modify either the subsampling methods or the algorithms themselves in order to ensure fairness. However, in doing so, a question that seems to be overlooked is whether it is possible to produce fair subsamples that are also adequately representative of the feature space of the data set – an important and classic requirement in machine learning. Can diversity and fairness be simultaneously ensured? We start by noting that, in some applications, guaranteeing one does not necessarily guarantee the other, and a new approach is required. Subsequently, we present an algorithmic framework which allows us to produce both fair and diverse samples. Our experimental results on an image summarization task show marked improvements in fairness without compromising feature diversity by much, giving us the best of both the worlds.},
	language = {en},
	urldate = {2018-10-06},
	journal = {arXiv:1610.07183 [cs]},
	author = {Celis, L. Elisa and Deshpande, Amit and Kathuria, Tarun and Vishnoi, Nisheeth K.},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.07183},
	keywords = {diverse, fatml, ranking},
}

@article{ConceptVectorTextVisualAnalytics,
	title = {{ConceptVector}: {Text} {Visual} {Analytics} via {Interactive} {Lexicon} {Building} {Using} {Word} {Embedding}},
	volume = {24},
	issn = {1077-2626},
	shorttitle = {{ConceptVector}},
	url = {http://ieeexplore.ieee.org/document/8023823/},
	doi = {10.1109/TVCG.2017.2744478},
	abstract = {Central to many text analysis methods is the notion of a concept: a set of semantically related keywords characterizing a speciﬁc object, phenomenon, or theme. Advances in word embedding allow building such concepts from a small set of seed terms. However, naive application of such techniques may result in false positive errors because of the polysemy of human language. To mitigate this problem, we present a visual analytics system called ConceptVector that guides the user in building such concepts and then using them to analyze documents. Document-analysis case studies with real-world datasets demonstrate the ﬁne-grained analysis provided by ConceptVector. To support the elaborate modeling of concepts using user seed terms, we introduce a bipolar concept model and support for irrelevant words. We validate the interactive lexicon building interface via a user study and expert reviews. The quantitative evaluation shows that the bipolar lexicon generated with our methods is comparable to human-generated ones.},
	language = {en},
	number = {1},
	urldate = {2018-10-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Park, Deokgun and Kim, Seungyeon and Lee, Jurim and Choo, Jaegul and Diakopoulos, Nicholas and Elmqvist, Niklas},
	month = jan,
	year = {2018},
	keywords = {emb, text, vis},
	pages = {361--370},
}

@article{TopicalityImpactSocialMedia,
	title = {Topicality and {Impact} in {Social} {Media}: {Diverse} {Messages}, {Focused} {Messengers}},
	volume = {10},
	issn = {1932-6203},
	shorttitle = {Topicality and {Impact} in {Social} {Media}},
	url = {http://dx.plos.org/10.1371/journal.pone.0118410},
	doi = {10.1371/journal.pone.0118410},
	language = {en},
	number = {2},
	urldate = {2018-09-26},
	journal = {PLOS ONE},
	author = {Weng, Lilian and Menczer, Filippo},
	editor = {Lambiotte, Renaud},
	month = feb,
	year = {2015},
	pages = {e0118410},
}

@inproceedings{DeepWalkOnlineLearningSocial,
	address = {New York, New York, USA},
	title = {{DeepWalk}: online learning of social representations},
	isbn = {978-1-4503-2956-9},
	shorttitle = {{DeepWalk}},
	url = {http://dl.acm.org/citation.cfm?doid=2623330.2623732},
	doi = {10.1145/2623330.2623732},
	abstract = {We present DeepWalk, a novel approach for learning latent representations of vertices in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. DeepWalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs.},
	language = {en},
	urldate = {2018-09-22},
	booktitle = {Proceedings of the 20th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '14},
	publisher = {ACM Press},
	author = {Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
	year = {2014},
	keywords = {dm},
	pages = {701--710},
}

@inproceedings{InterpretationNetworkEmbeddingTaxonomy,
	address = {London, United Kingdom},
	title = {On {Interpretation} of {Network} {Embedding} via {Taxonomy} {Induction}},
	isbn = {978-1-4503-5552-0},
	url = {http://dl.acm.org/citation.cfm?doid=3219819.3220001},
	doi = {10.1145/3219819.3220001},
	abstract = {Network embedding has been increasingly used in many network analytics applications to generate low-dimensional vector representations, so that many off-the-shelf models can be applied to solve a wide variety of data mining tasks. However, similar to many other machine learning methods, network embedding results remain hard to be understood by users. Each dimension in the embedding space usually does not have any specific meaning, thus it is difficult to comprehend how the embedding instances are distributed in the reconstructed space. In addition, heterogeneous content information may be incorporated into network embedding, so it is challenging to specify which source of information is effective in generating the embedding results. In this paper, we investigate the interpretation of network embedding, aiming to understand how instances are distributed in embedding space, as well as explore the factors that lead to the embedding results. We resort to the posthoc interpretation scheme, so that our approach can be applied to different types of embedding methods. Specifically, the interpretation of network embedding is presented in the form of a taxonomy. Effective objectives and corresponding algorithms are developed towards building the taxonomy. We also design several metrics to evaluate interpretation results. Experiments on real-world datasets from different domains demonstrate that, by comparing with the state-of-the-art alternatives, our approach produces effective and meaningful interpretation to embedding results.},
	language = {en},
	urldate = {2018-09-21},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '18},
	publisher = {ACM Press},
	author = {Liu, Ninghao and Huang, Xiao and Li, Jundong and Hu, Xia},
	year = {2018},
	pages = {1812--1820},
}

@article{RCLensInteractiveRareCategory,
	title = {{RCLens}: {Interactive} {Rare} {Category} {Exploration} and {Identification}},
	volume = {24},
	issn = {1077-2626},
	shorttitle = {{RCLens}},
	url = {https://ieeexplore.ieee.org/document/7939996/},
	doi = {10.1109/TVCG.2017.2711030},
	abstract = {Rare category identiﬁcation is an important task in many application domains, ranging from network security, to ﬁnancial fraud detection, to personalized medicine. These are all applications which require the discovery and characterization of sets of rare but structurally-similar data entities which are obscured within a larger but structurally different dataset. This paper introduces RCLens, a visual analytics system designed to support user-guided rare category exploration and identiﬁcation. RCLens adopts a novel active learning-based algorithm to iteratively identify more accurate rare categories in response to user-provided feedback. The algorithm is tightly integrated with an interactive visualization-based interface which supports a novel and effective workﬂow for rare category identiﬁcation. This paper (1) deﬁnes RCLens’ underlying active-learning algorithm; (2) describes the visualization and interaction designs, including a discussion of how the designs support user-guided rare category identiﬁcation; and (3) presents results from an evaluation demonstrating RCLens’ ability to support the rare category identiﬁcation process.},
	language = {en},
	number = {7},
	urldate = {2018-09-20},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Lin, Hanfei and Gao, Siyuan and Gotz, David and Du, Fan and He, Jingrui and Cao, Nan},
	month = jul,
	year = {2018},
	pages = {2223--2237},
}

@article{SkyLensVisualAnalysisSkyline,
	title = {{SkyLens}: {Visual} {Analysis} of {Skyline} on {Multi}-{Dimensional} {Data}},
	volume = {24},
	issn = {1077-2626},
	shorttitle = {{SkyLens}},
	url = {http://ieeexplore.ieee.org/document/8019873/},
	doi = {10.1109/TVCG.2017.2744738},
	abstract = {Skyline queries have wide-ranging applications in ﬁelds that involve multi-criteria decision making, including tourism, retail industry, and human resources. By automatically removing incompetent candidates, skyline queries allow users to focus on a subset of superior data items (i.e., the skyline), thus reducing the decision-making overhead. However, users are still required to interpret and compare these superior items manually before making a successful choice. This task is challenging because of two issues. First, people usually have fuzzy, unstable, and inconsistent preferences when presented with multiple candidates. Second, skyline queries do not reveal the reasons for the superiority of certain skyline points in a multi-dimensional space. To address these issues, we propose SkyLens, a visual analytic system aiming at revealing the superiority of skyline points from different perspectives and at different scales to aid users in their decision making. Two scenarios demonstrate the usefulness of SkyLens on two datasets with a dozen of attributes. A qualitative study is also conducted to show that users can efﬁciently accomplish skyline understanding and comparison tasks with SkyLens.},
	language = {en},
	number = {1},
	urldate = {2018-10-09},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Zhao, Xun and Wu, Yanhong and Cui, Weiwei and Du, Xinnan and Chen, Yuan and Wang, Yong and Lee, Dik Lun and Qu, Huamin},
	month = jan,
	year = {2018},
	keywords = {vis},
	pages = {246--255},
}

@incollection{ScalableDetectionViralMemes,
	address = {Cham},
	title = {Scalable {Detection} of {Viral} {Memes} from {Diffusion} {Patterns}},
	isbn = {978-3-319-77331-5 978-3-319-77332-2},
	url = {http://link.springer.com/10.1007/978-3-319-77332-2_11},
	abstract = {Social media and social networking platforms have ﬂourished with the rapid development of mobile technology and the ubiquitous use of the Internet. As a result, memes, or pieces of information spreading from person to person, can be reshared among users quickly and gain huge popularity. As viral memes have tremendous social and economic impact, detecting these viral memes at their early stages of spread is a worthy, yet challenging problem. Here we review the literature on predicting viral memes, and present empirical results from Twitter and Tumblr datasets. We demonstrate how diffusion patterns of memes, in the context of network communities, play an important role in predicting virality. We show that it is feasible to obtain predictive features based on community structure even at the massive scales that common social media services need to process. Our results may not only enable practitioners to make predictions about meme diffusion, but also help researchers understand how and why different factors, in particular diffusion patterns in communities, affect online virality.},
	language = {en},
	urldate = {2018-09-26},
	booktitle = {Complex {Spreading} {Phenomena} in {Social} {Systems}},
	publisher = {Springer International Publishing},
	author = {Hui, Pik-Mai and Weng, Lilian and Sahami Shirazi, Alireza and Ahn, Yong-Yeol and Menczer, Filippo},
	editor = {Lehmann, Sune and Ahn, Yong-Yeol},
	year = {2018},
	doi = {10.1007/978-3-319-77332-2_11},
	pages = {197--211},
}

@article{HowReadVisualizationResearch,
	title = {How to {Read} a {Visualization} {Research} {Paper}: {Extracting} the {Essentials}},
	volume = {31},
	issn = {0272-1716},
	shorttitle = {How to {Read} a {Visualization} {Research} {Paper}},
	url = {http://ieeexplore.ieee.org/document/5754296/},
	doi = {10.1109/MCG.2011.44},
	abstract = {PhD students or researchers starting a new research project or initiating work in an unfamiliar research direction often undertake a scientiﬁc literature search in order to inform themselves with respect to a chosen topic. This start-up phase involves wading through and reading scores, if not hundreds, of research papers that have already been published in the area of interest. Reading a large quantity of scientiﬁc papers and capturing the essential information from them is a very challenging task. Furthermore, this difﬁculty only increases with the passage of time as the complexity of literature increases as well as the quantity of publications.},
	language = {en},
	number = {3},
	urldate = {2018-10-16},
	journal = {IEEE Computer Graphics and Applications},
	author = {Laramee, R S},
	month = may,
	year = {2011},
	keywords = {vis},
	pages = {78--82},
}

@article{QualityMetricsInformationVisualization,
	title = {Quality {Metrics} for {Information} {Visualization}},
	volume = {37},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/cgf.13446},
	doi = {10.1111/cgf.13446},
	abstract = {The visualization community has developed to date many intuitions and understandings of how to judge the quality of views in visualizing data. The computation of a visualization’s quality and usefulness ranges from measuring clutter and overlap, up to the existence and perception of speciﬁc (visual) patterns. This survey attempts to report, categorize and unify the diverse understandings and aims to establish a common vocabulary that will enable a wide audience to understand their differences and subtleties. For this purpose, we present a commonly applicable quality metric formalization that should detail and relate all constituting parts of a quality metric. We organize our corpus of reviewed research papers along the data types established in the information visualization community: multi- and high-dimensional, relational, sequential, geospatial and text data. For each data type, we select the visualization subdomains in which quality metrics are an active research ﬁeld and report their ﬁndings, reason on the underlying concepts, describe goals and outline the constraints and requirements. One central goal of this survey is to provide guidance on future research opportunities for the ﬁeld and outline how different visualization communities could beneﬁt from each other by applying or transferring knowledge to their respective subdomain. Additionally, we aim to motivate the visualization community to compare computed measures to the perception of humans.},
	language = {en},
	number = {3},
	urldate = {2018-10-16},
	journal = {Computer Graphics Forum},
	author = {Behrisch, M. and Blumenschein, M. and Kim, N. W. and Shao, L. and El-Assady, M. and Fuchs, J. and Seebacher, D. and Diehl, A. and Brandes, U. and Pfister, H. and Schreck, T. and Weiskopf, D. and Keim, D. A.},
	month = jun,
	year = {2018},
	keywords = {eval, vis},
	pages = {625--662},
}

@article{VisualizingIncompletePartiallyRanked,
	title = {Visualizing {Incomplete} and {Partially} {Ranked} {Data}},
	volume = {14},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/4658150/},
	doi = {10.1109/TVCG.2008.181},
	abstract = {Ranking data, which result from m raters ranking n items, are difﬁcult to visualize due to their discrete algebraic structure, and the computational difﬁculties associated with them when n is large. This problem becomes worse when raters provide tied rankings or not all items are ranked. We develop an approach for the visualization of ranking data for large n which is intuitive, easy to use, and computationally efﬁcient. The approach overcomes the structural and computational difﬁculties by utilizing a natural measure of dissimilarity for raters, and projecting the raters into a low dimensional vector space where they are viewed. The visualization techniques are demonstrated using voting data, jokes, and movie preferences.},
	language = {en},
	number = {6},
	urldate = {2018-10-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kidwell, P. and Lebanon, G. and Cleveland, W.S.},
	month = nov,
	year = {2008},
	keywords = {ranking, vis},
	pages = {1356--1363},
}

@article{QualityMetricsHighDimensionalData,
	title = {Quality {Metrics} in {High}-{Dimensional} {Data} {Visualization}: {An} {Overview} and {Systematization}},
	volume = {17},
	issn = {1077-2626},
	shorttitle = {Quality {Metrics} in {High}-{Dimensional} {Data} {Visualization}},
	url = {http://ieeexplore.ieee.org/document/6064985/},
	doi = {10.1109/TVCG.2011.229},
	abstract = {In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reﬂections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reﬂections on implications of our model for future research.},
	language = {en},
	number = {12},
	urldate = {2018-10-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bertini, E. and Tatu, Andrada and Keim, Daniel},
	month = dec,
	year = {2011},
	keywords = {eval, vis},
	pages = {2203--2212},
}

@inproceedings{ScalableGraphExplorationVisualization,
	address = {Jeju, South Korea},
	title = {Scalable graph exploration and visualization: {Sensemaking} challenges and opportunities},
	isbn = {978-1-4799-7303-3},
	shorttitle = {Scalable graph exploration and visualization},
	url = {http://ieeexplore.ieee.org/document/7072812/},
	doi = {10.1109/35021BIGCOMP.2015.7072812},
	abstract = {Making sense of large graph datasets is a fundamental and challenging process that advances science, education and technology. We survey research on graph exploration and visualization approaches aimed at addressing this challenge. Different from existing surveys, our investigation highlights approaches that have strong potential in handling large graphs, algorithmically, visually, or interactively; we also explicitly connect relevant works from multiple research ﬁelds – data mining, machine learning, human-computer ineraction, information visualization, information retrieval, and recommender systems – to underline their parallel and complementary contributions to graph sensemaking.},
	language = {en},
	urldate = {2018-10-16},
	booktitle = {2015 {International} {Conference} on {Big} {Data} and {Smart} {Computing} ({BIGCOMP})},
	publisher = {IEEE},
	author = {Pienta, Robert and Abello, James and Kahng, Minsuk and Chau, Duen Horng},
	month = feb,
	year = {2015},
	keywords = {network, survey, vis},
	pages = {271--278},
}

@article{VisualAnalyticsDeepLearning,
	title = {Visual {Analytics} in {Deep} {Learning}: {An} {Interrogative} {Survey} for the {Next} {Frontiers}},
	shorttitle = {Visual {Analytics} in {Deep} {Learning}},
	url = {http://arxiv.org/abs/1801.06889},
	abstract = {Deep learning has recently seen rapid development and received signiﬁcant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W’s and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.},
	language = {en},
	urldate = {2018-10-16},
	journal = {arXiv:1801.06889 [cs, stat]},
	author = {Hohman, Fred and Kahng, Minsuk and Pienta, Robert and Chau, Duen Horng},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.06889},
	keywords = {dl, vis},
}

@article{EmpiricalStudiesInformationVisualization,
	title = {Empirical {Studies} in {Information} {Visualization}: {Seven} {Scenarios}},
	volume = {18},
	issn = {1077-2626},
	shorttitle = {Empirical {Studies} in {Information} {Visualization}},
	url = {http://ieeexplore.ieee.org/document/6095544/},
	doi = {10.1109/TVCG.2011.279},
	abstract = {We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one’s own study.},
	language = {en},
	number = {9},
	urldate = {2018-10-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Lam, H. and Bertini, E. and Isenberg, P. and Plaisant, C. and Carpendale, S.},
	month = sep,
	year = {2012},
	keywords = {eval, user-study, vis},
	pages = {1520--1536},
}

@article{SystematicReviewPracticeEvaluating,
	title = {A {Systematic} {Review} on the {Practice} of {Evaluating} {Visualization}},
	volume = {19},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/6634108/},
	doi = {10.1109/TVCG.2013.126},
	language = {en},
	number = {12},
	urldate = {2018-10-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Isenberg, Tobias and Isenberg, Petra and {Jian Chen} and Sedlmair, Michael and Moller, Torsten},
	month = dec,
	year = {2013},
	keywords = {eval, vis, vis-evaluation},
	pages = {2818--2827},
}

@article{SemanticbasedMethodVisualizingLarge,
	title = {A {Semantic}-based {Method} for {Visualizing} {Large} {Image} {Collections}},
	issn = {1077-2626},
	url = {https://ieeexplore.ieee.org/document/8358974/},
	doi = {10.1109/TVCG.2018.2835485},
	abstract = {Interactive visualization of large image collections is important and useful in many applications, such as personal album management and user proﬁling on images. However, most prior studies focus on using low-level visual features of images, such as texture and color histogram, to create visualizations without considering the more important semantic information embedded in images. This paper proposes a novel visual analytic system to analyze images in a semantic-aware manner. The system mainly comprises two components: a semantic information extractor and a visual layout generator. The semantic information extractor employs an image captioning technique based on convolutional neural network (CNN) to produce descriptive captions for images, which can be transformed into semantic keywords. The layout generator employs a novel co-embedding model to project images and the associated semantic keywords to the same 2D space. Inspired by the galaxy metaphor, we further turn the projected 2D space to a galaxy visualization of images, in which semantic keywords and images are visually encoded as stars and planets. Our system naturally supports multi-scale visualization and navigation, in which users can immediately see a semantic overview of an image collection and drill down for detailed inspection of a certain group of images. Users can iteratively reﬁne the visual layout by integrating their domain knowledge into the co-embedding process. Two task-based evaluations are conducted to demonstrate the effectiveness of our system.},
	language = {en},
	urldate = {2018-10-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Xie, Xiao and Cai, Xiwen and Zhou, Junpei and Cao, Nan and Wu, Yingcai},
	year = {2018},
	keywords = {emb, vis},
	pages = {1--1},
}

@article{MovingLeastSquaresBased,
	title = {A {Moving} {Least} {Squares} {Based} {Approach} for {Contour} {Visualization} of {Multi}-{Dimensional} {Data}},
	url = {http://arxiv.org/abs/1408.0677},
	abstract = {Analysis of high dimensional data is a common task. Often, small multiples are used to visualize 1 or 2 dimensions at a time, such as in a scatterplot matrix. Associating data points between different views can be difﬁcult though, as the points are not ﬁxed. Other times, dimensional reduction techniques are employed to summarize the whole dataset in one image, but individual dimensions are lost in this view. In this paper, we present a means of augmenting a dimensional reduction plot with isocontours to reintroduce the original dimensions. By applying this to each dimension in the original data, we create multiple views where the points are consistent, which facilitates their comparison. Our approach employs a combination of a novel, graph-based projection technique with a GPU accelerated implementation of moving least squares to interpolate space between the points. We also present evaluations of this approach both with a case study and with a user study.},
	language = {en},
	urldate = {2018-10-16},
	journal = {arXiv:1408.0677 [cs]},
	author = {Muelder, Chris W. and Leaf, Nick and Sigovan, Carmen and Ma, Kwan-Liu},
	month = aug,
	year = {2014},
	note = {arXiv: 1408.0677},
	keywords = {vis},
}

@article{NestedModelVisualizationDesign,
	title = {A {Nested} {Model} for {Visualization} {Design} and {Validation}},
	volume = {15},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/5290695/},
	doi = {10.1109/TVCG.2009.111},
	abstract = {We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efﬁciently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.},
	language = {en},
	number = {6},
	urldate = {2018-10-16},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Munzner, Tamara},
	month = nov,
	year = {2009},
	keywords = {vis},
	pages = {921--928},
}

@article{HowWriteVisualizationResearch,
	title = {How to {Write} a {Visualization} {Research} {Paper}: {The} {Art} and {Mechanics}},
	abstract = {This paper attempts to explain the mechanics of writing a research paper in visualization. This serves as a useful starting point for those who have never written a research paper before or have very little previous experience. Afterall, no one is born knowing how to write one. And yet, there are certain elements, a commonality, that should be found in virtually all good visualization research papers. We give our recommendations as to each section a good research paper consists of as well as what each section contains. This manuscript itself follows our recommended structure.},
	language = {en},
	author = {Laramee, Robert S},
	keywords = {vis},
	pages = {8},
}

@article{DiscoveringCommunitiesAnomaliesAttributed,
	title = {Discovering {Communities} and {Anomalies} in {Attributed} {Graphs}: {Interactive} {Visual} {Exploration} and {Summarization}},
	volume = {12},
	issn = {15564681},
	shorttitle = {Discovering {Communities} and {Anomalies} in {Attributed} {Graphs}},
	url = {http://dl.acm.org/citation.cfm?doid=3178544.3139241},
	doi = {10.1145/3139241},
	language = {en},
	number = {2},
	urldate = {2018-10-16},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Perozzi, Bryan and Akoglu, Leman},
	month = jan,
	year = {2018},
	keywords = {vis, vis-network},
	pages = {1--40},
}

@article{VisualWordAmbiguity,
	title = {Visual {Word} {Ambiguity}},
	volume = {32},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/5128909/},
	doi = {10.1109/TPAMI.2009.132},
	abstract = {This paper studies automatic image classiﬁcation by modeling soft-assignment in the popular codebook model. The codebook model describes an image as a bag of discrete visual words selected from a vocabulary, where the frequency distributions of visual words in an image allow classiﬁcation. One inherent component of the codebook model is the assignment of discrete visual words to continuous image features. Despite the clear mismatch of this hard assignment with the nature of continuous features, the approach has been applied successfully for some years. In this paper we investigate four types of soft-assignment of visual words to image features. We demonstrate that explicitly modeling visual word assignment ambiguity improves classiﬁcation performance compared to the hard-assignment of the traditional codebook model. The traditional codebook model is compared against our method for ﬁve well-known datasets: 15 natural scenes, Caltech-101, Caltech256, and Pascal VOC 2007/2008. We demonstrate that large codebook vocabulary sizes completely deteriorate the performance of the traditional model, whereas the proposed model performs consistently. Moreover, we show that our method proﬁts in high-dimensional feature spaces and reaps higher beneﬁts when increasing the number of image categories.},
	language = {en},
	number = {7},
	urldate = {2018-10-16},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {van Gemert, Jan C and Veenman, Cor J and Smeulders, Arnold W M and Geusebroek, Jan-Mark},
	month = jul,
	year = {2010},
	keywords = {vis},
	pages = {1271--1283},
}

@article{SURVEYVISUALIZATIONEXPLAINABLECLASSIFIERSa,
	title = {A {SURVEY} {ON} {VISUALIZATION} {FOR} {EXPLAINABLE} {CLASSIFIERS}},
	abstract = {Classiﬁcation is a fundamental problem in machine learning, data mining, and computer vision. In practice, interpretability is a desirable property of classiﬁcation models (classiﬁers) in critical areas, such as security, medicine, and ﬁnance. For instance, a quantitative trader may prefer a more interpretable model with less expected return due to its predictability and low risk. Unfortunately, the best-performing classiﬁers in many applications (e.g., deep neural networks) are complex machines whose predictions are difﬁcult to explain. Thus, there is a growing interest in using visualization to understand, diagnose and explain intelligent systems in both academia and in industry. Many challenges need to be addressed in the formalization of explainability, and the design principles and evaluation of explainable intelligent systems.},
	language = {en},
	author = {Ming, Yao},
	keywords = {fatml, vis},
	pages = {39},
}

@article{FairnessDiversityRandomnessAlgorithmic,
	title = {On {Fairness}, {Diversity} and {Randomness} in {Algorithmic} {Decision} {Making}},
	url = {http://arxiv.org/abs/1706.10208},
	abstract = {Consider a binary decision making process where a single machine learning classifier replaces a multitude of humans. We raise questions about the resulting loss of diversity in the decision making process. We study the potential benefits of using random classifier ensembles instead of a single classifier in the context of fairness-aware learning and demonstrate various attractive properties: (i) an ensemble of fair classifiers is guaranteed to be fair, for several different measures of fairness, (ii) an ensemble of unfair classifiers can still achieve fair outcomes, and (iii) an ensemble of classifiers can achieve better accuracy-fairness trade-offs than a single classifier. Finally, we introduce notions of distributional fairness to characterize further potential benefits of random classifier ensembles.},
	language = {en},
	urldate = {2018-10-27},
	journal = {arXiv:1706.10208 [cs, stat]},
	author = {Grgić-Hlača, Nina and Zafar, Muhammad Bilal and Gummadi, Krishna P. and Weller, Adrian},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.10208},
	keywords = {Statistics - Machine Learning, fatml},
}

@article{FairnessAwareRecommendationInformationCurators,
	title = {Fairness-{Aware} {Recommendation} of {Information} {Curators}},
	url = {http://arxiv.org/abs/1809.03040},
	abstract = {This paper highlights our ongoing efforts to create effective information curator recommendation models that can be personalized for individual users, while maintaining important fairness properties. Concretely, we introduce the problem of information curator recommendation, provide a high-level overview of a fairness-aware recommender, and introduce some preliminary experimental evidence over a real-world Twitter dataset. We conclude with some thoughts on future directions.},
	language = {en},
	urldate = {2018-10-27},
	journal = {arXiv:1809.03040 [cs]},
	author = {Zhu, Ziwei and Wang, Jianling and Zhang, Yin and Caverlee, James},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.03040},
	keywords = {fair, fatml, topic},
}

@article{FairnessTestingTestingSoftware,
	title = {Fairness {Testing}: {Testing} {Software} for {Discrimination}},
	shorttitle = {Fairness {Testing}},
	url = {http://arxiv.org/abs/1709.03221},
	doi = {10.1145/3106237.3106277},
	abstract = {This paper defines software fairness and discrimination and develops a testing-based method for measuring if and how much software discriminates, focusing on causality in discriminatory behavior. Evidence of software discrimination has been found in modern software systems that recommend criminal sentences, grant access to financial products, and determine who is allowed to participate in promotions. Our approach, Themis, generates efficient test suites to measure discrimination. Given a schema describing valid system inputs, Themis generates discrimination tests automatically and does not require an oracle. We evaluate Themis on 20 software systems, 12 of which come from prior work with explicit focus on avoiding discrimination. We find that (1) Themis is effective at discovering software discrimination, (2) state-of-the-art techniques for removing discrimination from algorithms fail in many situations, at times discriminating against as much as 98\% of an input subdomain, (3) Themis optimizations are effective at producing efficient test suites for measuring discrimination, and (4) Themis is more efficient on systems that exhibit more discrimination. We thus demonstrate that fairness testing is a critical aspect of the software development cycle in domains with possible discrimination and provide initial tools for measuring software discrimination.},
	language = {en},
	urldate = {2018-10-27},
	journal = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering  - ESEC/FSE 2017},
	author = {Galhotra, Sainyam and Brun, Yuriy and Meliou, Alexandra},
	year = {2017},
	note = {arXiv: 1709.03221},
	keywords = {fair, fatml},
	pages = {498--510},
}

@article{MultisidedFairnessRecommendation,
	title = {Multisided {Fairness} for {Recommendation}},
	url = {http://arxiv.org/abs/1707.00093},
	abstract = {Recent work on machine learning has begun to consider issues of fairness. In this paper, we extend the concept of fairness to recommendation. In particular, we show that in some recommendation contexts, fairness may be a multisided concept, in which fair outcomes for multiple individuals need to be considered. Based on these considerations, we present a taxonomy of classes of fairness-aware recommender systems and suggest possible fairness-aware recommendation architectures.},
	language = {en},
	urldate = {2018-10-27},
	journal = {arXiv:1707.00093 [cs]},
	author = {Burke, Robin},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.00093},
	keywords = {fair, fatml},
}

@article{FairTransparentAccountableAlgorithmic,
	title = {Fair, {Transparent}, and {Accountable} {Algorithmic} {Decision}-making {Processes}: {The} {Premise}, the {Proposed} {Solutions}, and the {Open} {Challenges}},
	issn = {2210-5433, 2210-5441},
	shorttitle = {Fair, {Transparent}, and {Accountable} {Algorithmic} {Decision}-making {Processes}},
	url = {http://link.springer.com/10.1007/s13347-017-0279-x},
	doi = {10.1007/s13347-017-0279-x},
	language = {en},
	urldate = {2018-10-27},
	journal = {Philosophy \& Technology},
	author = {Lepri, Bruno and Oliver, Nuria and Letouzé, Emmanuel and Pentland, Alex and Vinck, Patrick},
	month = aug,
	year = {2017},
	keywords = {fair, fatml},
}

@incollection{ExploratoryAnalysisRankingData,
	address = {New York, NY},
	title = {Exploratory {Analysis} of {Ranking} {Data}},
	isbn = {978-1-4939-1470-8 978-1-4939-1471-5},
	url = {http://link.springer.com/10.1007/978-1-4939-1471-5_2},
	language = {en},
	urldate = {2018-10-27},
	booktitle = {Statistical {Methods} for {Ranking} {Data}},
	publisher = {Springer New York},
	author = {Alvo, Mayer and Yu, Philip L. H.},
	collaborator = {Alvo, Mayer and Yu, Philip L.H.},
	year = {2014},
	doi = {10.1007/978-1-4939-1471-5_2},
	keywords = {dm, ranking},
	pages = {7--21},
}

@article{MeasuringBiasOnlineInformation,
	title = {On {Measuring} {Bias} in {Online} {Information}},
	url = {http://arxiv.org/abs/1704.05730},
	abstract = {Bias in online information has recently become a pressing issue, with search engines, social networks and recommendation services being accused of exhibiting some form of bias. In this vision paper, we make the case for a systematic approach towards measuring bias. To this end, we discuss formal measures for quantifying the various types of bias, we outline the system components necessary for realizing them, and we highlight the related research challenges and open problems.},
	language = {en},
	urldate = {2018-10-27},
	journal = {arXiv:1704.05730 [cs]},
	author = {Pitoura, Evaggelia and Tsaparas, Panayiotis and Flouris, Giorgos and Fundulaki, Irini and Papadakos, Panagiotis and Abiteboul, Serge and Weikum, Gerhard},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.05730},
	keywords = {fair, fatml, topic},
}

@article{OrdinalDistanceMetricLearning,
	title = {Ordinal {Distance} {Metric} {Learning} for {Image} {Ranking}},
	volume = {26},
	issn = {2162-237X, 2162-2388},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6881672},
	doi = {10.1109/TNNLS.2014.2339100},
	abstract = {Recently, distance metric learning (DML) has attracted much attention in image retrieval, but most previous methods only work for image classiﬁcation and clustering tasks. In this brief, we focus on designing ordinal DML algorithms for image ranking tasks, by which the rank levels among the images can be well measured. We ﬁrst present a linear ordinal Mahalanobis DML model that tries to preserve both the local geometry information and the ordinal relationship of the data. Then, we develop a nonlinear DML method by kernelizing the above model, considering of real-world image data with nonlinear structures. To further improve the ranking performance, we ﬁnally derive a multiple kernel DML approach inspired by the idea of multiple-kernel learning that performs different kernel operators on different kinds of image features. Extensive experiments on four benchmarks demonstrate the power of the proposed algorithms against some related state-of-the-art methods.},
	language = {en},
	number = {7},
	urldate = {2018-10-27},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Li, Changsheng and Liu, Qingshan and Liu, Jing and Lu, Hanqing},
	month = jul,
	year = {2015},
	keywords = {dm, ranking},
	pages = {1551--1559},
}

@article{ActiveRankingUsingPairwise,
	title = {Active {Ranking} using {Pairwise} {Comparisons}},
	abstract = {This paper examines the problem of ranking a collection of objects using pairwise comparisons (rankings of two objects). In general, the ranking of n objects can be identiﬁed by standard sorting methods using n log2 n pairwise comparisons. We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer pairwise comparisons. Speciﬁcally, we assume that the objects can be embedded into a d-dimensional Euclidean space and that the rankings reﬂect their relative distances from a common reference point in Rd. We show that under this assumption the number of possible rankings grows like n2d and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than d log n adaptively selected pairwise comparisons, on average. If instead the comparisons are chosen at random, then almost all pairwise comparisons must be made in order to identify any ranking. In addition, we propose a robust, error-tolerant algorithm that only requires that the pairwise comparisons are probably correct. Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis.},
	language = {en},
	author = {Jamieson, Kevin G and Nowak, Robert},
	keywords = {dm, ranking},
	pages = {9},
}

@article{RankconstrainedOptimizationItsApplications,
	title = {Rank-constrained optimization and its applications},
	volume = {82},
	issn = {00051098},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0005109817302339},
	doi = {10.1016/j.automatica.2017.04.039},
	abstract = {This paper investigates an iterative approach to solve the general rank-constrained optimization problems (RCOPs) defined to optimize a convex objective function subject to a set of convex constraints and rank constraints on unknown rectangular matrices. In addition, rank minimization problems (RMPs) are introduced and equivalently transformed into RCOPs by introducing a quadratic matrix equality constraint. The rank function is discontinuous and nonconvex, thus the general RCOPs are classified as NP-hard in most of the cases. An iterative rank minimization (IRM) method, with convex formulation at each iteration, is proposed to gradually approach the constrained rank. The proposed IRM method aims at solving RCOPs with rank inequalities constrained by upper or lower bounds, as well as rank equality constraints. Proof of the convergence to a local minimizer with at least a sublinear convergence rate is provided. Four representative applications of RCOPs and RMPs, including system identification, output feedback stabilization, and structured H2 controller design problems, are presented with comparative simulation results to verify the feasibility and improved performance of the proposed IRM method.},
	language = {en},
	urldate = {2018-10-27},
	journal = {Automatica},
	author = {Sun, Chuangchuang and Dai, Ran},
	month = aug,
	year = {2017},
	keywords = {dm, ranking},
	pages = {128--136},
}

@article{IFairLearningIndividuallyFair,
	title = {{iFair}: {Learning} {Individually} {Fair} {Data} {Representations} for {Algorithmic} {Decision} {Making}},
	shorttitle = {{iFair}},
	url = {http://arxiv.org/abs/1806.01059},
	abstract = {People are rated and ranked, towards algorithmic decision making in an increasing number of applications, typically based on machine learning. Research on how to incorporate fairness into such tasks has prevalently pursued the paradigm of group fairness: ensuring that each ethnic or social group receives its fair share in the outcome of classiﬁers and rankings. In contrast, the alternative paradigm of individual fairness has received relatively little attention. This paper introduces a method for probabilistically clustering user records into a lowrank representation that captures individual fairness yet also achieves high accuracy in classiﬁcation and regression models. Our notion of individual fairness requires that users who are similar in all task-relevant attributes such as job qualiﬁcation, and disregarding all potentially discriminating attributes such as gender, should have similar outcomes. Since the case for fairness is ubiquitous across many tasks, we aim to learn general representations that can be applied to arbitrary downstream usecases. We demonstrate the versatility of our method by applying it to classiﬁcation and learning-to-rank tasks on two real-world datasets. Our experiments show substantial improvements over the best prior work for this setting.},
	language = {en},
	urldate = {2018-10-27},
	journal = {arXiv:1806.01059 [cs, stat]},
	author = {Lahoti, Preethi and Weikum, Gerhard and Gummadi, Krishna P.},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.01059},
	keywords = {fair, fatml},
}

@article{ReducingDisparateExposureRanking,
	title = {Reducing {Disparate} {Exposure} in {Ranking}: {A} {Learning} {To} {Rank} {Approach}},
	shorttitle = {Reducing {Disparate} {Exposure} in {Ranking}},
	url = {http://arxiv.org/abs/1805.08716},
	abstract = {In this paper we consider a ranking problem in which we would like to order a set of items by utility or relevance, while also considering the visibility of different groups of items. To solve this problem, we adopt a supervised learning to rank approach that learns a ranking function from a set of training examples, which are queries and ranked lists of documents for each query. We consider that the elements to be ranked are divided into two groups: protected and non-protected. Following long-standing empirical observations showing that users of information retrieval systems rarely look past the first few results, we consider that some items receive more exposure than others. Our objective is to produce a ranker that is able to reproduce the ordering of the training set, which is the standard objective in learning to rank, but that additionally gives protected elements sufficient exposure, compared to non-protected elements. We demonstrate how to describe this objective formally, how to achieve it effectively and implement it, and present an experimental study describing how large differences in exposure can be reduced without having to introduce large distortions in the ranking utility.},
	language = {en},
	urldate = {2018-10-27},
	journal = {arXiv:1805.08716 [cs]},
	author = {Zehlike, Meike and Castillo, Carlos},
	month = may,
	year = {2018},
	note = {arXiv: 1805.08716},
	keywords = {fatml, ranking},
}

@article{AuditingBlackboxModelsIndirect,
	title = {Auditing {Black}-box {Models} for {Indirect} {Influence}},
	url = {http://arxiv.org/abs/1602.07043},
	abstract = {Data-trained predictive models see widespread use, but for the most part they are used as black boxes which output a prediction or score. It is therefore hard to acquire a deeper understanding of model behavior, and in particular how different features inﬂuence the model prediction. This is important when interpreting the behavior of complex models, or asserting that certain problematic attributes (like race or gender) are not unduly inﬂuencing decisions.},
	language = {en},
	urldate = {2018-10-30},
	journal = {arXiv:1602.07043 [cs, stat]},
	author = {Adler, Philip and Falk, Casey and Friedler, Sorelle A. and Rybeck, Gabriel and Scheidegger, Carlos and Smith, Brandon and Venkatasubramanian, Suresh},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.07043},
	keywords = {fair, fatml},
}

@article{LearningItemEmbeddingsUsing,
	title = {Learning item embeddings using biased feedback},
	abstract = {Learning item embeddings from browsing logs of recommender systems provides intriguing opportunities for understanding user preferences. However, such log data can be severely biased because recommendations imply a selection bias on the number of clicks an item receives. This selection bias can lead to learned embeddings that are distorted by past recommendations and that do not reﬂect the true semantic similarity one would like to capture. To overcome this problem, we formulate the task of learning embeddings as a counterfactual learning problem: how would the user have clicked, if the recommendation algorithm had not interfered? To demonstrate effectiveness and promise of this approach, we present synthetic experiments that illustrate how the counterfactual learning approach can recover the true embeddings despite biased data.},
	language = {en},
	author = {Singh, Ashudeep and Joachims, Thorsten},
	keywords = {dm},
	pages = {10},
}

@inproceedings{FindingSimilarExercisesOnline,
	address = {London, United Kingdom},
	title = {Finding {Similar} {Exercises} in {Online} {Education} {Systems}},
	isbn = {978-1-4503-5552-0},
	url = {http://dl.acm.org/citation.cfm?doid=3219819.3219960},
	doi = {10.1145/3219819.3219960},
	abstract = {In online education systems, finding similar exercises is a fundamental task of many applications, such as exercise retrieval and student modeling. Several approaches have been proposed for this task by simply using the specific textual content (e.g. the same knowledge concepts or the similar words) in exercises. However, the problem of how to systematically exploit the rich semantic information embedded in multiple heterogenous data (e.g. texts and images) to precisely retrieve similar exercises remains pretty much open. To this end, in this paper, we develop a novel Multimodal Attention-based N eural N etwork (MANN) framework for finding similar exercises in large-scale online education systems by learning a unified semantic representation from the heterogenous data. In MANN, given exercises with texts, images and knowledge concepts, we first apply a convolutional neural network to extract image representations and use an embedding layer for representing concepts. Then, we design an attention-based long short-term memory network to learn a unified semantic representation of each exercise in a multimodal way. Here, two attention strategies are proposed to capture the associations of texts and images, texts and knowledge concepts, respectively. Moreover, with a Similarity Attention, the similar parts in each exercise pair are also measured. Finally, we develop a pairwise training strategy for returning similar exercises. Extensive experimental results on real-world data clearly validate the effectiveness and the interpretation power of MANN.},
	language = {en},
	urldate = {2018-10-27},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '18},
	publisher = {ACM Press},
	author = {Liu, Qi and Huang, Zai and Huang, Zhenya and Liu, Chuanren and Chen, Enhong and Su, Yu and Hu, Guoping},
	year = {2018},
	keywords = {dm},
	pages = {1821--1830},
}

@article{JointEmbeddingHierarchicalCategories,
	title = {Joint {Embedding} of {Hierarchical} {Categories} and {Entities} for {Concept} {Categorization} and {Dataless} {Classification}},
	abstract = {Existing work learning distributed representations of knowledge base entities has largely failed to incorporate rich categorical structure, and is unable to induce category representations. We propose a new framework that embeds entities and categories jointly into a semantic space, by integrating structured knowledge and taxonomy hierarchy from large knowledge bases. Our framework enables to compute meaningful semantic relatedness between entities and categories in a principled way, and can handle both single-word and multiple-word concepts. Our method shows signiﬁcant improvement on the tasks of concept categorization and dataless hierarchical classiﬁcation.},
	language = {en},
	author = {Li, Yuezhang and Zheng, Ronghuo and Tian, Tian and Hu, Zhiting and Iyer, Rahul and Sycara, Katia},
	keywords = {dm},
	pages = {11},
}

@article{AdaptingRankingSVMDocument,
	title = {Adapting {Ranking} {SVM} to {Document} {Retrieval}},
	abstract = {The paper is concerned with applying learning to rank to document retrieval. Ranking SVM is a typical method of learning to rank. We point out that there are two factors one must consider when applying Ranking SVM, in general a “learning to rank” method, to document retrieval. First, correctly ranking documents on the top of the result list is crucial for an Information Retrieval system. One must conduct training in a way that such ranked results are accurate. Second, the number of relevant documents can vary from query to query. One must avoid training a model biased toward queries with a large number of relevant documents. Previously, when existing methods that include Ranking SVM were applied to document retrieval, none of the two factors was taken into consideration. We show it is possible to make modifications in conventional Ranking SVM, so it can be better used for document retrieval. Specifically, we modify the “Hinge Loss” function in Ranking SVM to deal with the problems described above. We employ two methods to conduct optimization on the loss function: gradient descent and quadratic programming. Experimental results show that our method, referred to as Ranking SVM for IR, can outperform the conventional Ranking SVM and other existing methods for document retrieval on two datasets.},
	language = {en},
	author = {Cao, Yunbo and Xu, Jun and Liu, Tie-Yan and Li, Hang and Huang, Yalou and Hon, Hsiao-Wuen},
	keywords = {dm, ranking},
	pages = {8},
}

@article{ValidityIssuesUseSociala,
	title = {Validity {Issues} in the {Use} of {Social} {Network} {Analysis} with {Digital} {Trace} {Data}},
	volume = {12},
	issn = {15369323},
	url = {http://aisel.aisnet.org/jais/vol12/iss12/2/},
	doi = {10.17705/1jais.00282},
	abstract = {There is an exciting natural match between social network analysis methods and the growth of data sources produced by social interactions via information technologies, from online communities to corporate information systems. Information Systems researchers have not been slow to embrace this combination of method and data. Such systems increasingly provide “digital trace data” that provide new research opportunities. Yet digital trace data are substantively different from the survey and interview data for which network analysis measures and interpretations were originally developed. This paper examines 10 validity issues associated with the combination of digital trace data and social network analysis methods, with examples from the IS literature, to provide recommendations for improving the validity of future research.},
	language = {en},
	number = {12},
	urldate = {2018-11-21},
	journal = {Journal of the Association for Information Systems},
	author = {{University of Texas at Austin} and Howison, James and Wiggins, Andrea and {Syracuse University} and Crowston, Kevin and {Syracuse University}},
	month = dec,
	year = {2011},
	pages = {767--797},
}

@article{ValidityIssuesUseSocial,
	title = {Validity {Issues} in the {Use} of {Social} {Network} {Analysis} for the {Study} of {Online} {Communities}},
	abstract = {There is a natural match between studies of online communities and social network analysis (SNA). Information Systems research, in particular, has drawn heavily on the growing data sources available as a by-product of increased online social interaction, conducting social network analyses with this “trace data”. However, this type of data has properties that are distinct from the data upon which researchers in Sociology and Anthropology have typically developed social network measures and their interpretations. This paper examines validity issues deriving from the use of trace data in IS studies of online communities, arguing that more attention needs to be paid to the chain of logic linking data collection, construct development, operationalization and measure interpretation. Four issues are elaborated and illustrated from the literature: 1) unexpected reliability concerns, 2) the need to argue and test the link from ‘found data’ to theoretical constructs, 3) validity problems arising from the stability of the constructs over time and 4) counter-intuitive validity issues deriving from the data being near-complete records of communities’ activities. The paper concludes with recommendations for researchers and reviewers designed to increase the rigor and relevance of SNA research in Information Systems.},
	language = {en},
	author = {Howison, James and Wiggins, Andrea and Crowston, Kevin},
	pages = {28},
}

@article{ExposureDiversityDesignPrinciple,
	title = {Exposure diversity as a design principle for recommender systems},
	volume = {21},
	issn = {1369-118X, 1468-4462},
	url = {https://www.tandfonline.com/doi/full/10.1080/1369118X.2016.1271900},
	doi = {10.1080/1369118X.2016.1271900},
	abstract = {Personalized recommendations in search engines, social media and also in more traditional media increasingly raise concerns over potentially negative consequences for diversity and the quality of public discourse. The algorithmic filtering and adaption of online content to personal preferences and interests is often associated with a decrease in the diversity of information to which users are exposed. Notwithstanding the question of whether these claims are correct or not, this article discusses whether and how recommendations can also be designed to stimulate more diverse exposure to information and to break potential ‘filter bubbles’ rather than create them. Combining insights from democratic theory, computer science and law, the article makes suggestions for design principles and explores the potential and possible limits of ‘diversity sensitive design’.},
	language = {en},
	number = {2},
	urldate = {2018-11-20},
	journal = {Information, Communication \& Society},
	author = {Helberger, Natali and Karppinen, Kari and D’Acunto, Lucia},
	month = feb,
	year = {2018},
	pages = {191--207},
}

@article{ImprovingRecommendationDiversitya,
	title = {Improving {Recommendation} {Diversity}},
	abstract = {Recommender systems oﬀer users a more intelligent and personalised mechanism to seek out new information. Content-based recommender systems generally prefer to retrieve a set of items maximally similar to a users’ query and/or proﬁle. We argue that as new types of recommendation domains and tasks emerge, this blind faith in the similarity assumption begins to seem ﬂawed. We show that very often recommendation diversity is important and that traditional recommendation systems are marred by poor diversity characteristics. We evaluate a new class of diversity-preserving algorithm capable of addressing this without compromising similarity or eﬃciency.},
	language = {en},
	author = {Bradley, Keith and Smyth, Barry},
	pages = {10},
}

@article{ExperimentalQuasiExperimentalDesignsGeneralized,
	title = {Experimental and {Quasi}-{Experimental} {Designs} for {Generalized} {Causal} {Inference}},
	language = {en},
	author = {Cook, ThomasD and Campbell, Donald T},
	pages = {81},
}

@article{PublicationBiasSocialSciences,
	title = {Publication bias in the social sciences: {Unlocking} the file drawer},
	volume = {345},
	issn = {0036-8075, 1095-9203},
	shorttitle = {Publication bias in the social sciences},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1255484},
	doi = {10.1126/science.1255484},
	language = {en},
	number = {6203},
	urldate = {2018-11-21},
	journal = {Science},
	author = {Franco, A. and Malhotra, N. and Simonovits, G.},
	month = sep,
	year = {2014},
	pages = {1502--1505},
}

@article{NaturalSelectionBadScience,
	title = {The natural selection of bad science},
	volume = {3},
	issn = {2054-5703},
	url = {http://rsos.royalsocietypublishing.org/lookup/doi/10.1098/rsos.160384},
	doi = {10.1098/rsos.160384},
	language = {en},
	number = {9},
	urldate = {2018-11-21},
	journal = {Royal Society Open Science},
	author = {Smaldino, Paul E. and McElreath, Richard},
	month = sep,
	year = {2016},
	pages = {160384},
}

@article{BigDataNewTricks,
	title = {Big {Data}: {New} {Tricks} for {Econometrics}},
	volume = {28},
	issn = {0895-3309},
	shorttitle = {Big {Data}},
	url = {http://pubs.aeaweb.org/doi/10.1257/jep.28.2.3},
	doi = {10.1257/jep.28.2.3},
	language = {en},
	number = {2},
	urldate = {2018-11-21},
	journal = {Journal of Economic Perspectives},
	author = {Varian, Hal R.},
	month = may,
	year = {2014},
	pages = {3--28},
}

@article{SocialDataBiasesMethodological,
	title = {Social {Data}: {Biases}, {Methodological} {Pitfalls}, and {Ethical} {Boundaries}},
	issn = {1556-5068},
	shorttitle = {Social {Data}},
	url = {https://www.ssrn.com/abstract=2886526},
	doi = {10.2139/ssrn.2886526},
	abstract = {Social data in digital form, which includes user-generated content, expressed or implicit relationships between people, and behavioral traces, are at the core of many popular applications and platforms, and drive the research agenda of many researchers. The promises of social data are many, including understanding “what the world thinks” about a social issue, brand, product, celebrity, or other entity, as well as enabling better decision making in a variety of ﬁelds including public policy, healthcare, and economics. Many academics and practitioners have warned against the na¨ıve usage of social data. There are biases and inaccuracies at the source of the data, but also introduced during processing. There are methodological limitations and pitfalls, as well as ethical boundaries and unexpected consequences that are often overlooked. This survey recognizes that the rigor with which these issues are addressed by different researchers varies across a wide range. We present a framework for identifying a broad range of menaces in the research and practices around social data.},
	language = {en},
	urldate = {2018-11-21},
	journal = {SSRN Electronic Journal},
	author = {Olteanu, Alexandra and Castillo, Carlos and Diaz, Fernando and Kiciman, Emre},
	year = {2016},
}

@article{AlgorithmsTransparencyViewNew,
	title = {Algorithms and {Transparency} in {View} of the {New} {General} {Data} {Protection} {Regulation}},
	volume = {3},
	issn = {23642831, 2364284X},
	url = {http://edpl.lexxion.eu/article/EDPL/2017/4/9},
	doi = {10.21552/edpl/2017/4/9},
	language = {en},
	number = {4},
	urldate = {2018-11-21},
	journal = {European Data Protection Law Review},
	author = {Temme, M.},
	year = {2017},
	pages = {473--485},
}

@article{BigDataDisparateImpacta,
	title = {Big {Data}'s {Disparate} {Impact}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=2477899},
	doi = {10.2139/ssrn.2477899},
	language = {en},
	urldate = {2018-11-21},
	journal = {SSRN Electronic Journal},
	author = {Barocas, Solon and Selbst, Andrew D.},
	year = {2016},
	keywords = {comps-dm, fair, fatml},
}

@article{DeductiveApproachCausalInference,
	title = {The {Deductive} {Approach} to {Causal} {Inference}},
	volume = {2},
	issn = {2193-3677, 2193-3685},
	url = {https://www.degruyter.com/view/j/jci.2014.2.issue-2/jci-2014-0016/jci-2014-0016.xml},
	doi = {10.1515/jci-2014-0016},
	abstract = {This paper reviews concepts, principles, and tools that have led to a coherent mathematical theory that unifies the graphical, structural, and potential outcome approaches to causal inference. The theory provides solutions to a number of pending problems in causal analysis, including questions of confounding control, policy analysis, mediation, missing data, and the integration of data from diverse studies.},
	language = {en},
	number = {2},
	urldate = {2018-11-21},
	journal = {Journal of Causal Inference},
	author = {Pearl, Judea},
	month = jan,
	year = {2014},
}

@book{CausalityModelsReasoningInference,
	address = {Cambridge},
	edition = {2},
	title = {Causality: {Models}, {Reasoning}, and {Inference}},
	isbn = {978-0-511-80316-1},
	shorttitle = {Causality},
	url = {http://ebooks.cambridge.org/ref/id/CBO9780511803161},
	language = {en},
	urldate = {2018-11-21},
	publisher = {Cambridge University Press},
	author = {Pearl, Judea},
	year = {2009},
	doi = {10.1017/CBO9780511803161},
}

@article{MeasuringDiscriminationAlgorithmicDecision,
	title = {Measuring discrimination in algorithmic decision making},
	volume = {31},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-017-0506-1},
	doi = {10.1007/s10618-017-0506-1},
	abstract = {Society is increasingly relying on data-driven predictive models for automated decision making. This is not by design, but due to the nature and noisiness of observational data, such models may systematically disadvantage people belonging to certain categories or groups, instead of relying solely on individual merits. This may happen even if the computing process is fair and well-intentioned. Discriminationaware data mining studies of how to make predictive models free from discrimination, when the historical data, on which they are built, may be biased, incomplete, or even contain past discriminatory decisions. Discrimination-aware data mining is an emerging research discipline, and there is no ﬁrm consensus yet of how to measure the performance of algorithms. The goal of this survey is to review various discrimination measures that have been used, analytically and computationally analyze their performance, and highlight implications of using one or another measure. We also describe measures from other disciplines, which have not been used for measuring discrimination, but potentially could be suitable for this purpose. This survey is primarily intended for researchers in data mining and machine learning as a step towards producing a unifying view of performance criteria when developing new algorithms for non-discriminatory predictive modeling. In addition, practitioners and policy makers could use this study when diagnosing potential discrimination by predictive models.},
	language = {en},
	number = {4},
	urldate = {2018-11-21},
	journal = {Data Mining and Knowledge Discovery},
	author = {Žliobaitė, Indrė},
	month = jul,
	year = {2017},
	pages = {1060--1089},
}

@article{HumanDecisionsMachinePredictions,
	title = {Human {Decisions} and {Machine} {Predictions}*},
	issn = {0033-5533, 1531-4650},
	url = {http://academic.oup.com/qje/article/doi/10.1093/qje/qjx032/4095198/Human-Decisions-and-Machine-Predictions},
	doi = {10.1093/qje/qjx032},
	language = {en},
	urldate = {2018-11-21},
	journal = {The Quarterly Journal of Economics},
	author = {Kleinberg, Jon and Lakkaraju, Himabindu and Leskovec, Jure and Ludwig, Jens and Mullainathan, Sendhil},
	month = aug,
	year = {2017},
}

@article{ManifestoReproducibleScience,
	title = {A manifesto for reproducible science},
	volume = {1},
	issn = {2397-3374},
	url = {http://www.nature.com/articles/s41562-016-0021},
	doi = {10.1038/s41562-016-0021},
	language = {en},
	number = {1},
	urldate = {2018-11-21},
	journal = {Nature Human Behaviour},
	author = {Munafò, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V. M. and Button, Katherine S. and Chambers, Christopher D. and Percie du Sert, Nathalie and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J. and Ioannidis, John P. A.},
	month = jan,
	year = {2017},
	pages = {0021},
}

@inproceedings{CausalDiscoverySocialMedia,
	address = {Washington D.C., District of Columbia},
	title = {Causal discovery in social media using quasi-experimental designs},
	isbn = {978-1-4503-0217-3},
	url = {http://portal.acm.org/citation.cfm?doid=1964858.1964859},
	doi = {10.1145/1964858.1964859},
	abstract = {Social media systems have become increasingly attractive to both users and companies providing those systems. Eﬃcient management of these systems is essential and requires knowledge of cause-and-eﬀect relationships within the system. Online experimentation can be used to discover causal knowledge; however, this ignores the observational data that is already being collected for operational purposes. Quasiexperimental designs (QEDs) are commonly used in social sciences to discover causal knowledge from observational data, and QEDs can be exploited to discover causal knowledge about social media systems. In this paper, we apply three diﬀerent QEDs to demonstrate how one can gain a causal understanding of a social media system. The conclusions drawn from using a QED can have threats to their validity, but we show how one can carefully construct sophisticated designs to overcome some of those threats.},
	language = {en},
	urldate = {2018-11-21},
	booktitle = {Proceedings of the {First} {Workshop} on {Social} {Media} {Analytics} - {SOMA} '10},
	publisher = {ACM Press},
	author = {Oktay, Hüseyin and Taylor, Brian J. and Jensen, David D.},
	year = {2010},
	keywords = {user-study},
	pages = {1--9},
}

@article{LoyalTrackerVisualizingLoyaltyDynamics,
	title = {{LoyalTracker}: {Visualizing} {Loyalty} {Dynamics} in {Search} {Engines}},
	volume = {20},
	issn = {1077-2626},
	shorttitle = {{LoyalTracker}},
	url = {http://ieeexplore.ieee.org/document/6876038/},
	doi = {10.1109/TVCG.2014.2346912},
	abstract = {The huge amount of user log data collected by search engine providers creates new opportunities to understand user loyalty and defection behavior at an unprecedented scale. However, this also poses a great challenge to analyze the behavior and glean insights into the complex, large data. In this paper, we introduce LoyalTracker, a visual analytics system to track user loyalty and switching behavior towards multiple search engines from the vast amount of user log data. We propose a new interactive visualization technique (ﬂow view) based on a ﬂow metaphor, which conveys a proper visual summary of the dynamics of user loyalty of thousands of users over time. Two other visualization techniques, a density map and a word cloud, are integrated to enable analysts to gain further insights into the patterns identiﬁed by the ﬂow view. Case studies and the interview with domain experts are conducted to demonstrate the usefulness of our technique in understanding user loyalty and switching behavior in search engines.},
	language = {en},
	number = {12},
	urldate = {2018-06-04},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Shi, Conglei and Wu, Yingcai and Liu, Shixia and Zhou, Hong and Qu, Huamin},
	month = dec,
	year = {2014},
	keywords = {user-study},
	pages = {1733--1742},
}

@article{HowChineseGovernmentFabricates,
	title = {How the {Chinese} {Government} {Fabricates} {Social} {Media} {Posts} for {Strategic} {Distraction}, {Not} {Engaged} {Argument}},
	volume = {111},
	issn = {0003-0554, 1537-5943},
	url = {https://www.cambridge.org/core/product/identifier/S0003055417000144/type/journal_article},
	doi = {10.1017/S0003055417000144},
	language = {en},
	number = {03},
	urldate = {2018-11-21},
	journal = {American Political Science Review},
	author = {King, Gary and Pan, Jennifer and Roberts, Margaret E.},
	month = aug,
	year = {2017},
	keywords = {user-study},
	pages = {484--501},
}

@inproceedings{IterativeIntegrationVisualInsights,
	title = {Iterative integration of visual insights during patent search and analysis},
	isbn = {978-1-4244-5283-5},
	url = {http://ieeexplore.ieee.org/document/5333564/},
	doi = {10.1109/VAST.2009.5333564},
	abstract = {Patents are an important economic factor in today’s globalized markets. Therefore, the analysis of patent information has become an inevitable task for a variety of interest groups. The retrieval of relevant patent information is an integral part of almost every patent analysis scenario. Unfortunately, the complexity of patent material inhibits a straightforward retrieval of all relevant patent documents and leads to iterative, time-consuming approaches in practice. With ‘PatViz’, a new system for interactive analysis of patent information has been developed to leverage iterative query reﬁnement. PatViz supports users in building complex queries visually and in exploring patent result sets interactively. Thereby, the visual query module introduces an abstraction layer that provides uniform access to different retrieval systems and relieves users of the burden to learn different complex query languages. By establishing an integrated environment it allows for interactive reintegration of insights gained from visual result set exploration into the visual query representation. We expect that the approach we have taken is also suitable to improve iterative query reﬁnement in other Visual Analytics systems.},
	language = {en},
	urldate = {2018-06-04},
	publisher = {IEEE},
	author = {Koch, Steffen and Bosch, Harald and Giereth, Mark and Ertl, Thomas},
	year = {2009},
	keywords = {user-study},
	pages = {203--210},
}

@article{DeconfoundedRecommenderCausalInference,
	title = {The {Deconfounded} {Recommender}: {A} {Causal} {Inference} {Approach} to {Recommendation}},
	shorttitle = {The {Deconfounded} {Recommender}},
	url = {http://arxiv.org/abs/1808.06581},
	abstract = {The goal of a recommender system is to show its users items that they will like. In forming its prediction, the recommender system tries to answer: “what would the rating be if we ‘forced’ the user to watch the movie?” This is a question about an intervention in the world, a causal question, and so traditional recommender systems are doing causal inference from observational data. This paper develops a causal inference approach to recommendation. Traditional recommenders are likely biased by unobserved confounders, variables that aﬀect both the “treatment assignments” (which movies the users watch) and the “outcomes” (how they rate them). We develop the deconfounded recommender, a strategy to leverage classical recommendation models for causal predictions. The deconfounded recommender uses Poisson factorization on which movies users watched to infer latent confounders in the data; it then augments common recommendation models to correct for potential confounding bias. The deconfounded recommender improves recommendation and it enjoys stable performance against interventions on test sets.},
	language = {en},
	urldate = {2018-11-21},
	journal = {arXiv:1808.06581 [cs, stat]},
	author = {Wang, Yixin and Liang, Dawen and Charlin, Laurent and Blei, David M.},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.06581},
	keywords = {Statistics - Machine Learning},
}

@article{WorkflowVisualDiagnosticsBinary,
	title = {A {Workﬂow} for {Visual} {Diagnostics} of {Binary} {Classiﬁers} using {Instance}-{Level} {Explanations}},
	abstract = {Human-in-the-loop data analysis applications necessitate greater transparency in machine learning models for experts to understand and trust their decisions. To this end, we propose a visual analytics workﬂow to help data scientists and domain experts explore, diagnose, and understand the decisions made by a binary classiﬁer. The approach leverages “instance-level explanations”, measures of local feature relevance that explain single instances, and uses them to build a set of visual representations that guide the users in their investigation. The workﬂow is based on three main visual representations and steps: one based on aggregate statistics to see how data distributes across correct / incorrect decisions; one based on explanations to understand which features are used to make these decisions; and one based on raw data, to derive insights on potential root causes for the observed patterns. The workﬂow is derived from a long-term collaboration with a group of machine learning and healthcare professionals who used our method to make sense of machine learning models they developed. The case study from this collaboration demonstrates that the proposed workﬂow helps experts derive useful knowledge about the model and the phenomena it describes, thus experts can generate useful hypotheses on how a model can be improved.},
	language = {en},
	author = {Krause, Josua and Dasgupta, Aritra and Swartz, Jordan and Aphinyanaphongs, Yindalon and Bertini, Enrico},
	keywords = {fatml, vis},
	pages = {11},
}

@inproceedings{InterpretingBlackBoxClassifiersUsinga,
	address = {Chicago, IL, USA},
	title = {Interpreting {Black}-{Box} {Classifiers} {Using} {Instance}-{Level} {Visual} {Explanations}},
	isbn = {978-1-4503-5029-7},
	url = {http://dl.acm.org/citation.cfm?doid=3077257.3077260},
	doi = {10.1145/3077257.3077260},
	abstract = {To realize the full potential of machine learning in diverse realworld domains, it is necessary for model predictions to be readily interpretable and actionable for the human in the loop. Analysts, who are the users but not the developers of machine learning models, often do not trust a model because of the lack of transparency in associating predictions with the underlying data space. To address this problem, we propose Rivelo, a visual analytics interface that enables analysts to understand the causes behind predictions of binary classi ers by interactively exploring a set of instance-level explanations. These explanations are model-agnostic, treating a model as a black box, and they help analysts in interactively probing the high-dimensional binary data space for detecting features relevant to predictions. We demonstrate the utility of the interface with a case study analyzing a random forest model on the sentiment of Yelp reviews about doctors.},
	language = {en},
	urldate = {2018-11-25},
	booktitle = {Proceedings of the 2nd {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics}  - {HILDA}'17},
	publisher = {ACM Press},
	author = {Tamagnini, Paolo and Krause, Josua and Dasgupta, Aritra and Bertini, Enrico},
	year = {2017},
	keywords = {fatml, vis},
	pages = {1--6},
}

@inproceedings{HeuristicsInformationVisualizationEvaluation,
	address = {Venice, Italy},
	title = {Heuristics for information visualization evaluation},
	isbn = {978-1-59593-562-5},
	url = {http://portal.acm.org/citation.cfm?doid=1168149.1168162},
	doi = {10.1145/1168149.1168162},
	abstract = {Heuristic evaluation is a well known discount evaluation technique in human-computer interaction (HCI) but has not been utilized in information visualization (InfoVis) to the same extent. While several sets of heuristics have been used or proposed for InfoVis, it is not yet known what kind of heuristics are useful for ﬁnding general InfoVis problems. We performed a meta-analysis with the goal of exploring the issues of heuristic evaluation for InfoVis. This meta-analysis concentrates on issues pertaining to the selection and organization of heuristics, and the process itself. For this purpose, we used three sets of previously published heuristics to assess a visual decision support system that is used to examine simulation data. The meta-analysis shows that the evaluation process and results have a high dependency on the heuristics and the types of evaluators chosen. We describe issues related to interpretation, redundancy, and conﬂict in heuristics. We also provide a discussion of generalizability and categorization of these heuristics.},
	language = {en},
	urldate = {2018-11-22},
	booktitle = {Proceedings of the 2006 {AVI} workshop on {BEyond} time and errors novel evaluation methods for information visualization - {BELIV} '06},
	publisher = {ACM Press},
	author = {Zuk, Torre and Schlesier, Lothar and Neumann, Petra and Hancock, Mark S. and Carpendale, Sheelagh},
	year = {2006},
	keywords = {user-study, vis},
	pages = {1},
}

@inproceedings{EvaluatingVisualAnalyticsSystems,
	address = {Atlantic City, NJ, USA},
	title = {Evaluating visual analytics systems for investigative analysis: {Deriving} design principles from a case study},
	isbn = {978-1-4244-5283-5},
	shorttitle = {Evaluating visual analytics systems for investigative analysis},
	url = {http://ieeexplore.ieee.org/document/5333878/},
	doi = {10.1109/VAST.2009.5333878},
	abstract = {Despite the growing number of systems providing visual analytic support for investigative analysis, few empirical studies of the potential beneﬁts of such systems have been conducted, particularly controlled, comparative evaluations. Determining how such systems foster insight and sensemaking is important for their continued growth and study, however. Furthermore, studies that identify how people use such systems and why they beneﬁt (or not) can help inform the design of new systems in this area. We conducted an evaluation of the visual analytics system Jigsaw employed in a small investigative sensemaking exercise, and we compared its use to three other more traditional methods of analysis. Sixteen participants performed a simulated intelligence analysis task under one of the four conditions. Experimental results suggest that Jigsaw assisted participants to analyze the data and identify an embedded threat. We describe different analysis strategies used by study participants and how computational support (or the lack thereof) inﬂuenced the strategies. We then illustrate several characteristics of the sensemaking process identiﬁed in the study and provide design implications for investigative analysis tools based thereon. We conclude with recommendations for metrics and techniques for evaluating other visual analytics investigative analysis tools.},
	language = {en},
	urldate = {2018-11-22},
	booktitle = {2009 {IEEE} {Symposium} on {Visual} {Analytics} {Science} and {Technology}},
	publisher = {IEEE},
	author = {Kang, Youn-ah and Gorg, Carsten and Stasko, John},
	year = {2009},
	keywords = {user-study, vis},
	pages = {139--146},
}

@article{MeasuringVisualizationInsight,
	title = {Toward measuring visualization insight},
	volume = {26},
	issn = {0272-1716},
	url = {http://ieeexplore.ieee.org/document/1626178/},
	doi = {10.1109/MCG.2006.70},
	language = {en},
	number = {3},
	urldate = {2018-11-22},
	journal = {IEEE Computer Graphics and Applications},
	author = {North, C.},
	month = may,
	year = {2006},
	keywords = {user-study, vis},
	pages = {6--9},
}

@article{ViDXVisualDiagnosticsAssembly,
	title = {{ViDX}: {Visual} {Diagnostics} of {Assembly} {Line} {Performance} in {Smart} {Factories}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {{ViDX}},
	url = {http://ieeexplore.ieee.org/document/7536610/},
	doi = {10.1109/TVCG.2016.2598664},
	abstract = {Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefﬁciencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey’s graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories.},
	language = {en},
	number = {1},
	urldate = {2018-06-04},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Xu, Panpan and Mei, Honghui and Ren, Liu and Chen, Wei},
	month = jan,
	year = {2017},
	keywords = {case-study, eval, expert-interview, user-study},
	pages = {291--300},
}

@article{SmartAdPVisualAnalyticsLargescale,
	title = {{SmartAdP}: {Visual} {Analytics} of {Large}-scale {Taxi} {Trajectories} for {Selecting} {Billboard} {Locations}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {{SmartAdP}},
	url = {http://ieeexplore.ieee.org/document/7534856/},
	doi = {10.1109/TVCG.2016.2598432},
	abstract = {The problem of formulating solutions immediately and comparing them rapidly for billboard placements has plagued advertising planners for a long time, owing to the lack of efﬁcient tools for in-depth analyses to make informed decisions. In this study, we attempt to employ visual analytics that combines the state-of-the-art mining and visualization techniques to tackle this problem using large-scale GPS trajectory data. In particular, we present SmartAdP, an interactive visual analytics system that deals with the two major challenges including ﬁnding good solutions in a huge solution space and comparing the solutions in a visual and intuitive manner. An interactive framework that integrates a novel visualization-driven data mining model enables advertising planners to effectively and efﬁciently formulate good candidate solutions. In addition, we propose a set of coupled visualizations: a solution view with metaphor-based glyphs to visualize the correlation between different solutions; a location view to display billboard locations in a compact manner; and a ranking view to present multi-typed rankings of the solutions. This system has been demonstrated using case studies with a real-world dataset and domain-expert interviews. Our approach can be adapted for other location selection problems such as selecting locations of retail stores or restaurants using trajectory data.},
	language = {en},
	number = {1},
	urldate = {2018-06-04},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Dongyu and Weng, Di and Li, Yuhong and Bao, Jie and Zheng, Yu and Qu, Huamin and Wu, Yingcai},
	month = jan,
	year = {2017},
	keywords = {eval, user-study},
	pages = {1--10},
}

@article{VisualizingDimensionalityReductionArtifacts,
	title = {Visualizing {Dimensionality} {Reduction} {Artifacts}: {An} {Evaluation}},
	shorttitle = {Visualizing {Dimensionality} {Reduction} {Artifacts}},
	url = {http://arxiv.org/abs/1705.05283},
	abstract = {Multidimensional scaling allows visualizing high-dimensional data as 2D maps with the premise that insights in 2D reveal valid information in high-dimensions, but the resulting projections always suffer from artifacts such as false neighborhoods and tears. These artifacts can be revealed by interactively coloring the projection according to the original dissimilarities relative to a reference item. However, it is not clear if conveying these dissimilarities using color and displaying only local information really helps to overcome the projections artifacts. We conducted a controlled experiment to investigate the relevance of this interactive technique using several datasets. We compared the bare projection with the interactive coloring of the original dissimilarities on different visual analysis tasks involving outliers and clusters. Results indicate that the interactive coloring is effective for local tasks as it is robust to projection artifacts whereas using the bare projection alone is error prone.},
	language = {en},
	urldate = {2019-01-08},
	journal = {arXiv:1705.05283 [cs]},
	author = {Heulot, Nicolas and Fekete, Jean-Daniel and Aupetit, Michael},
	month = may,
	year = {2017},
	note = {arXiv: 1705.05283},
	keywords = {H.5.2, evalutation, vis},
}

@inproceedings{InsightTaskbasedMethodologyEvaluating,
	address = {Paris, France},
	title = {An insight- and task-based methodology for evaluating spatiotemporal visual analytics},
	isbn = {978-1-4799-6227-3},
	url = {http://ieeexplore.ieee.org/document/7042482/},
	doi = {10.1109/VAST.2014.7042482},
	abstract = {We present a method for evaluating visualizations using both tasks and exploration, and demonstrate this method in a study of spatiotemporal network designs for a visual analytics system. The method is well suited for studying visual analytics applications in which users perform both targeted data searches and analyses of broader patterns. In such applications, an effective visualization design is one that helps users complete tasks accurately and efﬁciently, and supports hypothesis generation during open-ended exploration. To evaluate both of these aims in a single study, we developed an approach called layered insight- and taskbased evaluation (LITE) that interposes several prompts for observations about the data model between sequences of predeﬁned search tasks. We demonstrate the evaluation method in a user study of four network visualizations for spatiotemporal data in a visual analytics application. Results include ﬁndings that might have been difﬁcult to obtain in a single experiment using a different methodology. For example, with one dataset we studied, we found that on average participants were faster on search tasks using a force-directed layout than using our other designs; at the same time, participants found this design least helpful in understanding the data. Our contributions include a novel evaluation method that combines well-deﬁned tasks with exploration and observation, an evaluation of network visualization designs for spatiotemporal visual analytics, and guidelines for using this evaluation method.},
	language = {en},
	urldate = {2019-01-08},
	booktitle = {2014 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Gomez, Steven R. and Guo, Hua and Ziemkiewicz, Caroline and Laidlaw, David H.},
	month = oct,
	year = {2014},
	keywords = {vis-evaluation},
	pages = {63--72},
}

@inproceedings{ValuedrivenEvaluationVisualizations,
	address = {Paris, France},
	title = {Value-driven evaluation of visualizations},
	isbn = {978-1-4503-3209-5},
	url = {http://dl.acm.org/citation.cfm?doid=2669557.2669579},
	doi = {10.1145/2669557.2669579},
	abstract = {Existing evaluations of data visualizations often employ a series of low-level, detailed questions to be answered or benchmark tasks to be performed. While that methodology can be helpful to determine a visualization’s usability, such evaluations overlook the key benefits that visualization uniquely provides over other data analysis methods. I propose a value-driven evaluation of visualizations in which a person illustrates a system’s value through four important capabilities: minimizing the time to answer diverse questions, spurring the generation of insights and insightful questions, conveying the essence of the data, and generating confidence and knowledge about the data’s domain and context. Additionally, I explain how interaction is instrumental in creating much of the value that can be found in visualizations.},
	language = {en},
	urldate = {2019-01-08},
	booktitle = {Proceedings of the {Fifth} {Workshop} on {Beyond} {Time} and {Errors} {Novel} {Evaluation} {Methods} for {Visualization} - {BELIV} '14},
	publisher = {ACM Press},
	author = {Stasko, John},
	year = {2014},
	keywords = {evaluation, vis},
	pages = {46--53},
}

@article{InsightBasedMethodologyEvaluatingBioinformatics,
	title = {An {Insight}-{Based} {Methodology} for {Evaluating} {Bioinformatics} {Visualizations}},
	volume = {11},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/1432690/},
	doi = {10.1109/TVCG.2005.53},
	abstract = {High-throughput experiments, such as gene expression microarrays in the life sciences, result in very large data sets. In response, a wide variety of visualization tools have been created to facilitate data analysis. A primary purpose of these tools is to provide biologically relevant insight into the data. Typically, visualizations are evaluated in controlled studies that measure user performance on predetermined tasks or using heuristics and expert reviews. To evaluate and rank bioinformatics visualizations based on real-world data analysis scenarios, we developed a more relevant evaluation method that focuses on data insight. This paper presents several characteristics of insight that enabled us to recognize and quantify it in open-ended user tests. Using these characteristics, we evaluated five microarray visualization tools on the amount and types of insight they provide and the time it takes to acquire it. The results of the study guide biologists in selecting a visualization tool based on the type of their microarray data, visualization designers on the key role of user interaction techniques, and evaluators on a new approach for evaluating the effectiveness of visualizations for providing insight. Though we used the method to analyze bioinformatics visualizations, it can be applied to other domains.},
	language = {en},
	number = {4},
	urldate = {2019-01-08},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Saraiya, P. and North, C. and Duca, K.},
	month = jul,
	year = {2005},
	keywords = {evaluation, vis},
	pages = {443--456},
}

@article{DiversityRecommenderSystemsSurvey,
	title = {Diversity in recommender systems – {A} survey},
	volume = {123},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705117300680},
	doi = {10.1016/j.knosys.2017.02.009},
	abstract = {Diversiﬁcation has become one of the leading topics of recommender system research not only as a way to solve the over-ﬁtting problem but also an approach to increasing the quality of the user’s experience with the recommender system. This article aims to provide an overview of research done on this topic from one of the ﬁrst mentions of diversity in 2001 until now. The articles ,and research, have been divided into three sub-topics for a better overview of the work done in the ﬁeld of recommendation diversiﬁcation: the deﬁnition and evaluation of diversity; the impact of diversiﬁcation on the quality of recommendation results and the development of diversiﬁcation algorithms themselves. In this way, the article aims both to offer a good overview to a researcher looking for the state-of-the-art on this topic and to help a new developer get familiar with the topic.},
	language = {en},
	urldate = {2018-12-07},
	journal = {Knowledge-Based Systems},
	author = {Kunaver, Matevž and Požrl, Tomaž},
	month = may,
	year = {2017},
	keywords = {diversity, fatml},
	pages = {154--162},
}

@article{LiteratureSurveyEarlyTime,
	title = {A {Literature} {Survey} of {Early} {Time} {Series} {Classiﬁcation} and {Deep} {Learning}},
	abstract = {This paper provides an overview of current literature on time series classiﬁcation approaches, in particular of early time series classiﬁcation.},
	language = {en},
	author = {Santos, Tiago and Kern, Roman},
	keywords = {dm},
	pages = {7},
}

@article{ClusteringCommunityDetectionDirected,
	title = {Clustering and {Community} {Detection} in {Directed} {Networks}: {A} {Survey}},
	volume = {533},
	issn = {03701573},
	shorttitle = {Clustering and {Community} {Detection} in {Directed} {Networks}},
	url = {http://arxiv.org/abs/1308.0971},
	doi = {10.1016/j.physrep.2013.08.002},
	abstract = {Networks (or graphs) appear as dominant structures in diverse domains, including sociology, biology, neuroscience and computer science. In most of the aforementioned cases graphs are directed – in the sense that there is directionality on the edges, making the semantics of the edges non symmetric as the source node transmits some property to the target one but not vice versa. An interesting feature that real networks present is the clustering or community structure property, under which the graph topology is organized into modules commonly called communities or clusters. The essence here is that nodes of the same community are highly similar while on the contrary, nodes across communities present low similarity. Revealing the underlying community structure of directed complex networks has become a crucial and interdisciplinary topic with a plethora of relevant application domains. Therefore, naturally there is a recent wealth of research production in the area of mining directed graphs – with clustering being the primary method sought and the primary tool for community detection and evaluation. The goal of this paper is to oﬀer an in-depth comparative review of the methods presented so far for clustering directed networks along with the relevant necessary methodological background and also related applications. The survey commences by oﬀering a concise review of the fundamental concepts and methodological base on which graph clustering algorithms capitalize on. Then we present the relevant work along two orthogonal classiﬁcations. The ﬁrst one is mostly concerned with the methodological principles of the clustering algorithms, while the second one approaches the methods from the viewpoint regarding the properties of a good cluster in a directed network. Further, we present methods and metrics for evaluating graph clustering results, demonstrate interesting application domains and provide promising future research directions.},
	language = {en},
	number = {4},
	urldate = {2019-01-31},
	journal = {Physics Reports},
	author = {Malliaros, Fragkiskos D. and Vazirgiannis, Michalis},
	month = dec,
	year = {2013},
	note = {arXiv: 1308.0971},
	keywords = {Physics - Physics and Society, dm},
	pages = {95--142},
}

@article{EarlyClassificationTimeSeries,
	title = {Early classification on time series},
	volume = {31},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-011-0400-x},
	doi = {10.1007/s10115-011-0400-x},
	abstract = {In this paper, we formulate the problem of early classiﬁcation of time series data, which is important in some time-sensitive applications such as health informatics. We introduce a novel concept of MPL (minimum prediction length) and develop ECTS (early classiﬁcation on time series), an effective 1-nearest neighbor classiﬁcation method. ECTS makes early predictions and at the same time retains the accuracy comparable with that of a 1NN classiﬁer using the full-length time series. Our empirical study using benchmark time series data sets shows that ECTS works well on the real data sets where 1NN classiﬁcation is effective.},
	language = {en},
	number = {1},
	urldate = {2019-01-31},
	journal = {Knowledge and Information Systems},
	author = {Xing, Zhengzheng and Pei, Jian and Yu, Philip S.},
	month = apr,
	year = {2012},
	keywords = {dm},
	pages = {105--127},
}

@article{PatternsVisualizationEvaluation,
	title = {Patterns for {Visualization} {Evaluation}},
	abstract = {We propose a patterns-based approach to evaluating data visualization: a set of general and reusable solutions to commonly occurring problems in evaluating visualization tools, techniques, and systems. Patterns have had signiﬁcant impact in a wide array of disciplines, particularly software engineering, and we believe that they provide a powerful lens for characterizing visualization evaluation practices by offering practical, tried-and-tested tips and tricks that can be adopted immediately. The 20 patterns presented here have also been added to a freely editable Wiki repository. The motivation for creating this evaluation pattern language is to (a) capture and formalize “dark” practices for visualization evaluation not currently recorded in the literature; (b) disseminate these hard-won experiences to researchers and practitioners alike; (c) provide a standardized vocabulary for designing visualization evaluation; and to (d) invite the community to add new evaluation patterns to a growing repository of patterns.},
	language = {en},
	author = {Elmqvist, Niklas and Yi, Ji Soo},
	pages = {22},
}

@article{PreventingFairnessGerrymanderingAuditinga,
	title = {Preventing {Fairness} {Gerrymandering}: {Auditing} and {Learning} for {Subgroup} {Fairness}},
	abstract = {The most prevalent notions of fairness in machine learning are statistical deﬁnitions: they ﬁx a small collection of high-level, pre-deﬁned groups (such as race or gender), and then ask for approximate parity of some statistic of the classiﬁer (like positive classiﬁcation rate or false positive rate) across these groups. Constraints of this form are susceptible to (intentional or inadvertent) fairness gerrymandering, in which a classiﬁer appears to be fair on each individual group, but badly violates the fairness constraint on one or more structured subgroups deﬁned over the protected attributes (such as certain combinations of protected attribute values). We propose instead to demand statistical notions of fairness across exponentially (or inﬁnitely) many subgroups, deﬁned by a structured class of functions over the protected attributes. This interpolates between statistical deﬁnitions of fairness, and recently proposed individual notions of fairness, but it raises several computational challenges. It is no longer clear how to even check or audit a ﬁxed classiﬁer to see if it satisﬁes such a strong deﬁnition of fairness. We prove that the computational problem of auditing subgroup fairness for both equality of false positive rates and statistical parity is equivalent to the problem of weak agnostic learning — which means it is computationally hard in the worst case, even for simple structured subclasses. However, it also suggests that common heuristics for learning can be applied to successfully solve the auditing problem in practice.},
	language = {en},
	author = {Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},
	keywords = {fair, fatml},
	pages = {32},
}

@article{GeneralFrameworkAnalysingDiversity,
	title = {A general framework for analysing diversity in science, technology and society},
	volume = {4},
	issn = {1742-5689, 1742-5662},
	url = {http://rsif.royalsocietypublishing.org/cgi/doi/10.1098/rsif.2007.0213},
	doi = {10.1098/rsif.2007.0213},
	language = {en},
	number = {15},
	urldate = {2018-12-10},
	journal = {Journal of The Royal Society Interface},
	author = {Stirling, Andy},
	month = aug,
	year = {2007},
	keywords = {diverse, fatml},
	pages = {707--719},
}

@inproceedings{SelectiveLabelsProblemEvaluating,
	address = {Halifax, NS, Canada},
	title = {The {Selective} {Labels} {Problem}: {Evaluating} {Algorithmic} {Predictions} in the {Presence} of {Unobservables}},
	isbn = {978-1-4503-4887-4},
	shorttitle = {The {Selective} {Labels} {Problem}},
	url = {http://dl.acm.org/citation.cfm?doid=3097983.3098066},
	doi = {10.1145/3097983.3098066},
	abstract = {Evaluating whether machines improve on human performance is one of the central questions of machine learning. However, there are many domains where the data is selectively labeled in the sense that the observed outcomes are themselves a consequence of the existing choices of the human decision-makers. For instance, in the context of judicial bail decisions, we observe the outcome of whether a defendant fails to return for their court appearance only if the human judge decides to release the defendant on bail. is selective labeling makes it harder to evaluate predictive models as the instances for which outcomes are observed do not represent a random sample of the population. Here we propose a novel framework for evaluating the performance of predictive models on selectively labeled data. We develop an approach called contraction which allows us to compare the performance of predictive models and human decision-makers without resorting to counterfactual inference. Our methodology harnesses the heterogeneity of human decision-makers and facilitates e ective evaluation of predictive models even in the presence of unmeasured confounders (unobservables) which in uence both human decisions and the resulting outcomes. Experimental results on real world datasets spanning diverse domains such as health care, insurance, and criminal justice demonstrate the utility of our evaluation metric in comparing human decisions and machine predictions.},
	language = {en},
	urldate = {2018-11-28},
	booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}  - {KDD} '17},
	publisher = {ACM Press},
	author = {Lakkaraju, Himabindu and Kleinberg, Jon and Leskovec, Jure and Ludwig, Jens and Mullainathan, Sendhil},
	year = {2017},
	keywords = {fair, fatml},
	pages = {275--284},
}

@inproceedings{FairnessRankingProcedurePairwise,
	address = {Wuhan, China},
	title = {The {Fairness} of {Ranking} {Procedure} in {Pair}-wise {Preference} {Learning}},
	isbn = {978-0-7803-9361-5},
	url = {http://ieeexplore.ieee.org/document/1598842/},
	doi = {10.1109/NLPKE.2005.1598842},
	abstract = {In pair-wise preference learning, a crucial point is how to decode the predictions of the pair-wise preference to a final preference order-a ranking procedure. Simple voting, iterated choice, and Slater-optimal ranking are usual techniques, but their ranking results are usually very different from each other. Hitherto, experimentation is the main method of estimating the ranking approaches, and the formal estimation is still an open question. The main contribution of this paper is the definition of a framework to import the fairness theory of preference aggregation to estimate the ranking procedure, where every pair-wise preference learner is seen as an agent and the ranking procedure is seen as a special case of multiple agents' preferences aggregation. In addition, by transformed into a special aggregation case of RANK voting rule, if there are at least three labels, then simple voting and iterated choice are proved to be not fair for their dependence to irrelevant alternatives.},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {2005 {International} {Conference} on {Natural} {Language} {Processing} and {Knowledge} {Engineering}},
	publisher = {IEEE},
	author = {{Zhizheng Zhang} and {Hancheng Xing} and {Zhenzhen Wang} and {Qingjian Ni}},
	year = {2005},
	keywords = {fair, fatml},
	pages = {780--784},
}

@article{UsingGapChartsVisualize,
	title = {Using {Gap} {Charts} to {Visualize} the {Temporal} {Evolution} of {Ranks} and {Scores}},
	volume = {36},
	issn = {0272-1716},
	url = {http://ieeexplore.ieee.org/document/7579406/},
	doi = {10.1109/MCG.2016.100},
	abstract = {We present Gap Charts, a novel class of line charts designed for visualizing the evolution of rankings over time, with a particular focus on sports data. Gap Charts show entries, e. g., teams participating in a competition, that are ranked over time according to a performance metric like a growing number of points or a score. The main advantages of Gap Charts are that 1) tied entries never overlap—only changes in rank generate limited overlap between time-steps; and 2) gaps between entries show the magnitude of their score difference. We evaluate the effectiveness of Gap Charts for performing different types of tasks, and ﬁnd that they outperform standard time-dependent ranking visualizations for tasks that involve identifying and understanding evolutions in both ranks and scores. Finally, we show that Gap Charts are a generic and scalable class of line charts by applying them to a variety of different datasets.},
	language = {en},
	number = {5},
	urldate = {2019-01-31},
	journal = {IEEE Computer Graphics and Applications},
	author = {Perin, Charles and Boy, Jeremy and Vernier, Frederic},
	month = sep,
	year = {2016},
	keywords = {dm},
	pages = {38--49},
}

@article{VisualizingRankTimeSeries,
	title = {Visualizing {Rank} {Time} {Series} of {Wikipedia} {Top}-{Viewed} {Pages}},
	volume = {37},
	issn = {0272-1716},
	url = {http://ieeexplore.ieee.org/document/7879127/},
	doi = {10.1109/MCG.2017.21},
	language = {en},
	number = {2},
	urldate = {2019-01-31},
	journal = {IEEE Computer Graphics and Applications},
	author = {Xia, Jing and Hou, Yumeng and Chen, Yingjie Victor and Qian, Zhenyu Cheryl and Ebert, David S. and Chen, Wei},
	month = mar,
	year = {2017},
	keywords = {dm},
	pages = {42--53},
}

@inproceedings{MiningSequenceClassifiersEarly,
	title = {Mining {Sequence} {Classifiers} for {Early} {Prediction}},
	isbn = {978-0-89871-654-2 978-1-61197-278-8},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611972788.59},
	doi = {10.1137/1.9781611972788.59},
	abstract = {Supervised learning on sequence data, also known as sequence classiﬁcation, has been well recognized as an important data mining task with many signiﬁcant applications. Since temporal order is important in sequence data, in many critical applications of sequence classiﬁcation such as medical diagnosis and disaster prediction, early prediction is a highly desirable feature of sequence classiﬁers. In early prediction, a sequence classiﬁer should use a preﬁx of a sequence as short as possible to make a reasonably accurate prediction. To the best of our knowledge, early prediction on sequence data has not been studied systematically.},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {Proceedings of the 2008 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Xing, Zhengzheng and Pei, Jian and Dong, Guozhu and Yu, Philip S.},
	month = apr,
	year = {2008},
	keywords = {dm},
	pages = {644--655},
}

@inproceedings{VisualReRankingMultiAspectInformation,
	address = {Oslo, Norway},
	title = {Visual {Re}-{Ranking} for {Multi}-{Aspect} {Information} {Retrieval}},
	isbn = {978-1-4503-4677-1},
	url = {http://dl.acm.org/citation.cfm?doid=3020165.3020174},
	doi = {10.1145/3020165.3020174},
	abstract = {We present visual re-ranking, an interactive visualization technique for multi-aspect information retrieval. In multi-aspect search, the information need of the user consists of more than one aspect or query simultaneously. While visualization and interactive search user interface techniques for improving user interpretation of search results have been proposed, the current research lacks understanding on how useful these are for the user: whether they lead to quantiﬁable beneﬁts in perceiving the result space and allow faster, and more precise retrieval. Our technique visualizes relevance and document density on a two-dimensional map with respect to the query phrases. Pointing to a location on the map speciﬁes a weight distribution of the relevance to each of the query phrases, according to which search results are re-ranked. User experiments compared our technique to a uni-dimensional search interface with typed query and ranked result list, in perception and retrieval tasks. Visual reranking yielded improved accuracy in perception, higher precision in retrieval and overall faster task execution. Our ﬁndings demonstrate the utility of visual re-ranking, and can help designing search user interfaces that support multi-aspect search.},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {Proceedings of the 2017 {Conference} on {Conference} {Human} {Information} {Interaction} and {Retrieval} - {CHIIR} '17},
	publisher = {ACM Press},
	author = {Klouche, Khalil and Ruotsalo, Tuukka and Micallef, Luana and Andolina, Salvatore and Jacucci, Giulio},
	year = {2017},
	keywords = {dm},
	pages = {57--66},
}

@article{StackedGraphsGeometryAesthetics,
	title = {Stacked {Graphs} – {Geometry} \& {Aesthetics}},
	volume = {14},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/4658136/},
	doi = {10.1109/TVCG.2008.166},
	abstract = {In February 2008, the New York Times published an unusual chart of box ofﬁce revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the ﬁrst author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different “energy function”. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.},
	language = {en},
	number = {6},
	urldate = {2019-01-31},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Byron, L. and Wattenberg, M.},
	month = nov,
	year = {2008},
	keywords = {dm},
	pages = {1245--1252},
}

@article{BriefSurveySequenceClassification,
	title = {A brief survey on sequence classification},
	volume = {12},
	issn = {19310145},
	url = {http://portal.acm.org/citation.cfm?doid=1882471.1882478},
	doi = {10.1145/1882471.1882478},
	abstract = {Sequence classiﬁcation has a broad range of applications such as genomic analysis, information retrieval, health informatics, ﬁnance, and abnormal detection. Diﬀerent from the classiﬁcation task on feature vectors, sequences do not have explicit features. Even with sophisticated feature selection techniques, the dimensionality of potential features may still be very high and the sequential nature of features is diﬃcult to capture. This makes sequence classiﬁcation a more challenging task than classiﬁcation on feature vectors. In this paper, we present a brief review of the existing work on sequence classiﬁcation. We summarize the sequence classiﬁcation in terms of methodologies and application domains. We also provide a review on several extensions of the sequence classiﬁcation problem, such as early classiﬁcation on sequences and semi-supervised learning on sequences.},
	language = {en},
	number = {1},
	urldate = {2019-01-31},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Xing, Zhengzheng and Pei, Jian and Keogh, Eamonn},
	month = nov,
	year = {2010},
	keywords = {dm},
	pages = {40},
}

@article{VisualComparisonInformationVisualization,
	title = {Visual comparison for information visualization},
	volume = {10},
	issn = {1473-8716, 1473-8724},
	url = {http://journals.sagepub.com/doi/10.1177/1473871611416549},
	doi = {10.1177/1473871611416549},
	abstract = {Data analysis often involves the comparison of complex objects. With the ever increasing amounts and complexity of data, the demand for systems to help with these comparisons is also growing. Increasingly, information visualization tools support such comparisons explicitly, beyond simply allowing a viewer to examine each object individually. In this paper, we argue that the design of information visualizations of complex objects can, and should, be studied in general, that is independently of what those objects are. As a first step in developing this general understanding of comparison, we propose a general taxonomy of visual designs for comparison that groups designs into three basic categories, which can be combined. To clarify the taxonomy and validate its completeness, we provide a survey of work in information visualization related to comparison. Although we find a great diversity of systems and approaches, we see that all designs are assembled from the building blocks of juxtaposition, superposition and explicit encodings. This initial exploration shows the power of our model, and suggests future challenges in developing a general understanding of comparative visualization and facilitating the development of more comparative visualization tools.},
	language = {en},
	number = {4},
	urldate = {2019-01-31},
	journal = {Information Visualization},
	author = {Gleicher, Michael and Albers, Danielle and Walker, Rick and Jusufi, Ilir and Hansen, Charles D. and Roberts, Jonathan C.},
	month = oct,
	year = {2011},
	keywords = {vis},
	pages = {289--309},
}

@article{TextFlowBetterUnderstandingEvolving,
	title = {{TextFlow}: {Towards} {Better} {Understanding} of {Evolving} {Topics} in {Text}},
	volume = {17},
	issn = {1077-2626},
	shorttitle = {{TextFlow}},
	url = {http://ieeexplore.ieee.org/document/6065008/},
	doi = {10.1109/TVCG.2011.239},
	abstract = {Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We ﬁrst extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users reﬁne the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data. Index Terms—Text visualization, Topic evolution, Hierarchical Dirichlet process, Critical event.},
	language = {en},
	number = {12},
	urldate = {2019-01-31},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {{Weiwei Cui} and {Shixia Liu} and {Li Tan} and {Conglei Shi} and {Yangqiu Song} and {Zekai Gao} and {Huamin Qu} and {Xin Tong}},
	month = dec,
	year = {2011},
	keywords = {dm, topic, vis},
	pages = {2412--2421},
}

@article{PathSpecificCounterfactualFairness,
	title = {Path-{Specific} {Counterfactual} {Fairness}},
	url = {http://arxiv.org/abs/1802.08139},
	abstract = {We consider the problem of learning fair decision systems in complex scenarios in which a sensitive attribute might affect the decision along both fair and unfair pathways. We introduce a causal approach to disregard effects along unfair pathways that simpliﬁes and generalizes previous literature. Our method corrects observations adversely affected by the sensitive attribute, and uses these to form a decision. This avoids disregarding fair information, and does not require an often intractable computation of the path-speciﬁc effect. We leverage recent developments in deep learning and approximate inference to achieve a solution that is widely applicable to complex, non-linear scenarios.},
	language = {en},
	urldate = {2019-01-31},
	journal = {arXiv:1802.08139 [stat]},
	author = {Chiappa, Silvia and Gillam, Thomas P. S.},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.08139},
	keywords = {Statistics - Machine Learning, fair, fatml},
}

@article{ControllableInvarianceAdversarialFeature,
	title = {Controllable {Invariance} through {Adversarial} {Feature} {Learning}},
	abstract = {Learning meaningful representations that maintain the content necessary for a particular task while ﬁltering away detrimental variations is a problem of great interest in machine learning. In this paper, we tackle the problem of learning representations invariant to a speciﬁc factor or trait of data. The representation learning process is formulated as an adversarial minimax game. We analyze the optimal equilibrium of such a game and ﬁnd that it amounts to maximizing the uncertainty of inferring the detrimental factor given the representation while maximizing the certainty of making task-speciﬁc predictions. On three benchmark tasks, namely fair and bias-free classiﬁcation, language-independent generation, and lighting-independent image classiﬁcation, we show that the proposed framework induces an invariant representation, and leads to better generalization evidenced by the improved performance.},
	language = {en},
	author = {Xie, Qizhe and Dai, Zihang and Du, Yulun and Hovy, Eduard and Neubig, Graham},
	keywords = {fatml, xai},
	pages = {12},
}

@article{CounterfactualFairness,
	title = {Counterfactual {Fairness}},
	url = {http://arxiv.org/abs/1703.06856},
	abstract = {Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our deﬁnition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it is the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school.},
	language = {en},
	urldate = {2019-01-31},
	journal = {arXiv:1703.06856 [cs, stat]},
	author = {Kusner, Matt J. and Loftus, Joshua R. and Russell, Chris and Silva, Ricardo},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.06856},
	keywords = {fair, fatml},
}

@inproceedings{VisualizingDifferencesWebSearch,
	address = {Raleigh, North Carolina, USA},
	title = {Visualizing differences in web search algorithms using the expected weighted hoeffding distance},
	isbn = {978-1-60558-799-8},
	url = {http://portal.acm.org/citation.cfm?doid=1772690.1772785},
	doi = {10.1145/1772690.1772785},
	abstract = {We introduce a new dissimilarity function for ranked lists, the expected weighted Hoeﬀding distance, that has several advantages over current dissimilarity measures for ranked search results. First, it is easily customized for users who pay varying degrees of attention to websites at diﬀerent ranks. Second, unlike existing measures such as generalized Kendall’s tau, it is based on a true metric, preserving meaningful embeddings when visualization techniques like multi-dimensional scaling are applied. Third, our measure can eﬀectively handle partial or missing rank information while retaining a probabilistic interpretation. Finally, the measure can be made computationally tractable and we give a highly eﬃcient algorithm for computing it. We then apply our new metric with multi-dimensional scaling to visualize and explore relationships between the result sets from different search engines, showing how the weighted Hoeﬀding distance can distinguish important diﬀerences in search engine behavior that are not apparent with other rank-distance metrics. Such visualizations are highly eﬀective at summarizing and analyzing insights on which search engines to use, what search strategies users can employ, and how search results evolve over time. We demonstrate our techniques using a collection of popular search engines, a representative set of queries, and frequently used query manipulation methods.},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {Proceedings of the 19th international conference on {World} wide web - {WWW} '10},
	publisher = {ACM Press},
	author = {Sun, Mingxuan and Lebanon, Guy and Collins-Thompson, Kevyn},
	year = {2010},
	keywords = {vis},
	pages = {931},
}

@inproceedings{HumanCenteredApproachAlgorithmicServices,
	address = {Denver, Colorado, USA},
	title = {A {Human}-{Centered} {Approach} to {Algorithmic} {Services}: {Considerations} for {Fair} and {Motivating} {Smart} {Community} {Service} {Management} that {Allocates} {Donations} to {Non}-{Profit} {Organizations}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {A {Human}-{Centered} {Approach} to {Algorithmic} {Services}},
	url = {http://dl.acm.org/citation.cfm?doid=3025453.3025884},
	doi = {10.1145/3025453.3025884},
	abstract = {Algorithms are increasingly being incorporated into diverse services that orchestrate multiple stakeholders’ needs and interests. How can we design these algorithmic services to make decisions that are not only efficient, but also fair and motivating? We take a human-centered approach to identify and address challenges in building human-centered algorithmic services. We are in the process of building an allocation algorithm for 412 Food Rescue, an organization that matches food donations with non-profit organizations. As part of this ongoing project, we conducted interviews with multiple stakeholders in the service—organization staff, donors, volunteers, recipient non-profits and their clients, and everyday citizens—in order to understand how the allocation algorithm, interfaces, and surrounding work practices should be designed. The findings suggest that we need to understand and account for varying fairness notions held by stakeholders; consider people, contexts, and interfaces for algorithms to work fairly in the real world; and preserve meaningfulness and social interaction in automation in order to build fair and motivating algorithmic services.},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '17},
	publisher = {ACM Press},
	author = {Lee, Min Kyung and Kim, Ji Tae and Lizarondo, Leah},
	year = {2017},
	keywords = {vis},
	pages = {3365--3376},
}

@article{RankingVisualizationsCorrelationUsing,
	title = {Ranking {Visualizations} of {Correlation} {Using} {Weber}'s {Law}},
	volume = {20},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/6875978/},
	doi = {10.1109/TVCG.2014.2346979},
	abstract = {Despite years of research yielding systems and guidelines to aid visualization design, practitioners still face the challenge of identifying the best visualization for a given dataset and task. One promising approach to circumvent this problem is to leverage perceptual laws to quantitatively evaluate the effectiveness of a visualization design. Following previously established methodologies, we conduct a large scale (n=1687) crowdsourced experiment to investigate whether the perception of correlation in nine commonly used visualizations can be modeled using Weber’s law. The results of this experiment contribute to our understanding of information visualization by establishing that: 1) for all tested visualizations, the precision of correlation judgment could be modeled by Weber’s law, 2) correlation judgment precision showed striking variation between negatively and positively correlated data, and 3) Weber models provide a concise means to quantify, compare, and rank the perceptual precision afforded by a visualization.},
	language = {en},
	number = {12},
	urldate = {2019-01-31},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Harrison, Lane and Yang, Fumeng and Franconeri, Steven and Chang, Remco},
	month = dec,
	year = {2014},
	keywords = {dm},
	pages = {1943--1952},
}

@article{AggreSetRichScalableSet,
	title = {{AggreSet}: {Rich} and {Scalable} {Set} {Exploration} using {Visualizations} of {Element} {Aggregations}},
	volume = {22},
	issn = {1077-2626},
	shorttitle = {{AggreSet}},
	url = {http://ieeexplore.ieee.org/document/7194854/},
	doi = {10.1109/TVCG.2015.2467051},
	abstract = {Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university.},
	language = {en},
	number = {1},
	urldate = {2019-01-31},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Yalcin, M. Adil and Elmqvist, Niklas and Bederson, Benjamin B.},
	month = jan,
	year = {2016},
	keywords = {aggr, vis},
	pages = {688--697},
}

@inproceedings{TrendsTrajectoriesExplainableAccountable,
	address = {Montreal QC, Canada},
	title = {Trends and {Trajectories} for {Explainable}, {Accountable} and {Intelligible} {Systems}: {An} {HCI} {Research} {Agenda}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {Trends and {Trajectories} for {Explainable}, {Accountable} and {Intelligible} {Systems}},
	url = {http://dl.acm.org/citation.cfm?doid=3173574.3174156},
	doi = {10.1145/3173574.3174156},
	abstract = {Advances in artificial intelligence, sensors and big data management have far-reaching societal impacts. As these systems augment our everyday lives, it becomes increasingly important for people to understand them and remain in control. We investigate how HCI researchers can help to develop accountable systems by performing a literature analysis of 289 core papers on explanations and explainable systems, as well as 12,412 citing papers. Using topic modeling, co-occurrence and network analysis, we mapped the research space from diverse domains, such as algorithmic accountability, interpretable machine learning, context-awareness, cognitive psychology, and software learnability. We reveal fading and burgeoning trends in explainable systems, and identify domains that are closely connected or mostly isolated. The time is ripe for the HCI community to ensure that the powerful new autonomous systems have intelligible interfaces built-in. From our results, we propose several implications and directions for future research towards this goal.},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Abdul, Ashraf and Vermeulen, Jo and Wang, Danding and Lim, Brian Y. and Kankanhalli, Mohan},
	year = {2018},
	keywords = {fatml, key, survey, xai},
	pages = {1--18},
}

@article{SemanticsDerivedAutomaticallyLanguage,
	title = {Semantics derived automatically from language corpora necessarily contain human biases},
	abstract = {Artiﬁcial intelligence and machine learning are in a period of astounding growth. However, there are concerns that these technologies may be used, either with or without intention, to perpetuate the prejudice and unfairness that unfortunately characterizes many human institutions. Here we show for the ﬁrst time that human-like semantic biases result from the application of standard machine learning to ordinary language—the same sort of language humans are exposed to every day. We replicate a spectrum of standard human biases as exposed by the Implicit Association Test and other well-known psychological studies. We replicate these using a widely used, purely statistical machine-learning model—namely, the GloVe word embedding—trained on a corpus of text from the Web. Our results indicate that language itself contains recoverable and accurate imprints of our historic biases, whether these are morally neutral as towards insects or ﬂowers, problematic as towards race or gender, or even simply veridical, reﬂecting the status quo for the distribution of gender with respect to careers or ﬁrst names. These regularities are captured by machine learning along with the rest of semantics. In addition to our empirical ﬁndings concerning language, we also contribute new methods for evaluating bias in text, the Word Embedding Association Test (WEAT) and the Word Embedding Factual Association Test (WEFAT). Our results have implications not only for AI and machine learning, but also for the ﬁelds of psychology, sociology, and human ethics, since they raise the possibility that mere exposure to everyday language can account for the biases we replicate here.},
	language = {en},
	author = {Caliskan-Islam, Aylin and Bryson, Joanna J and Narayanan, Arvind},
	keywords = {fatml, xai},
	pages = {14},
}

@article{HumanPerceptionsFairnessAlgorithmica,
	title = {Human {Perceptions} of {Fairness} in {Algorithmic} {Decision} {Making}: {A} {Case} {Study} of {Criminal} {Risk} {Prediction}},
	shorttitle = {Human {Perceptions} of {Fairness} in {Algorithmic} {Decision} {Making}},
	url = {http://arxiv.org/abs/1802.09548},
	abstract = {As algorithms are increasingly used to make important decisions that affect human lives, ranging from social benefit assignment to predicting risk of criminal recidivism, concerns have been raised about the fairness of algorithmic decision making. Most prior works on algorithmic fairness normatively prescribe how fair decisions ought to be made. In contrast, here, we descriptively survey users for how they perceive and reason about fairness in algorithmic decision making.},
	language = {en},
	urldate = {2019-01-31},
	journal = {arXiv:1802.09548 [cs, stat]},
	author = {Grgić-Hlača, Nina and Redmiles, Elissa M. and Gummadi, Krishna P. and Weller, Adrian},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.09548},
	keywords = {Statistics - Machine Learning, comps-dm, fair, fatml},
}

@article{ExplainableAIDesignersHumanCentered,
	title = {Explainable {AI} for {Designers}: {A} {Human}-{Centered} {Perspective} on {Mixed}-{Initiative} {Co}-{Creation}},
	abstract = {Growing interest in eXplainable Artiﬁcial Intelligence (XAI) aims to make AI and machine learning more understandable to human users. However, most existing work focuses on new algorithms, and not on usability, practical interpretability and efﬁcacy on real users. In this vision paper, we propose a new research area of eXplainable AI for Designers (XAID), speciﬁcally for game designers. By focusing on a speciﬁc user group, their needs and tasks, we propose a human-centered approach for facilitating game designers to co-create with AI/ML techniques through XAID. We illustrate our initial XAID framework through three use cases, which require an understanding both of the innate properties of the AI techniques and users’ needs, and we identify key open challenges.},
	language = {en},
	author = {Zhu, Jichen and Liapis, Antonios and Risi, Sebastian and Bidarra, Rafael and Youngblood, G Michael},
	keywords = {fatml, xai},
	pages = {8},
}

@article{PenalizingUnfairnessBinaryClassification,
	title = {Penalizing {Unfairness} in {Binary} {Classification}},
	url = {http://arxiv.org/abs/1707.00044},
	abstract = {We present a new approach for mitigating unfairness in learned classiﬁers. In particular, we focus on binary classiﬁcation tasks over individuals from two populations, where, as our criterion for fairness, we wish to achieve similar false positive rates in both populations, and similar false negative rates in both populations. As a proof of concept, we implement our approach and empirically evaluate its ability to achieve both fairness and accuracy, using datasets from the ﬁelds of criminal risk assessment, credit, lending, and college admissions.},
	language = {en},
	urldate = {2019-01-31},
	journal = {arXiv:1707.00044 [cs, stat]},
	author = {Bechavod, Yahav and Ligett, Katrina},
	month = jun,
	year = {2017},
	note = {arXiv: 1707.00044},
	keywords = {Statistics - Machine Learning, fair, fatml},
}

@article{FairnessDisparateTreatmentDisparate,
	title = {Fairness {Beyond} {Disparate} {Treatment} \& {Disparate} {Impact}: {Learning} {Classification} without {Disparate} {Mistreatment}},
	shorttitle = {Fairness {Beyond} {Disparate} {Treatment} \& {Disparate} {Impact}},
	url = {http://arxiv.org/abs/1610.08452},
	doi = {10.1145/3038912.3052660},
	abstract = {Automated data-driven decision making systems are increasingly being used to assist, or even replace humans in many settings. These systems function by learning from historical decisions, often taken by humans. In order to maximize the utility of these systems (or, classiﬁers), their training involves minimizing the errors (or, misclassiﬁcations) over the given historical data. However, it is quite possible that the optimally trained classiﬁer makes decisions for people belonging to diﬀerent social groups with diﬀerent misclassiﬁcation rates (e.g., misclassiﬁcation rates for females are higher than for males), thereby placing these groups at an unfair disadvantage. To account for and avoid such unfairness, in this paper, we introduce a new notion of unfairness, disparate mistreatment, which is deﬁned in terms of misclassiﬁcation rates. We then propose intuitive measures of disparate mistreatment for decision boundary-based classiﬁers, which can be easily incorporated into their formulation as convex-concave constraints. Experiments on synthetic as well as real world datasets show that our methodology is effective at avoiding disparate mistreatment, often at a small cost in terms of accuracy.},
	language = {en},
	urldate = {2019-01-31},
	journal = {Proceedings of the 26th International Conference on World Wide Web - WWW '17},
	author = {Zafar, Muhammad Bilal and Valera, Isabel and Rodriguez, Manuel Gomez and Gummadi, Krishna P.},
	year = {2017},
	note = {arXiv: 1610.08452},
	keywords = {fair, fatml},
	pages = {1171--1180},
}

@article{DiscriminationOnlineAdDelivery,
	title = {Discrimination in {Online} {Ad} {Delivery}},
	language = {en},
	author = {Sweeney, Latanya},
	keywords = {fair, fatml, xai},
	pages = {36},
}

@article{ExplanationArtificialIntelligenceInsights,
	title = {Explanation in {Artificial} {Intelligence}: {Insights} from the {Social} {Sciences}},
	shorttitle = {Explanation in {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/1706.07269},
	abstract = {There has been a recent resurgence in the area of explainable artiﬁcial intelligence as researchers and practitioners seek to make their algorithms more understandable. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artiﬁcial intelligence. However, it is fair to say that most work in explainable artiﬁcial intelligence uses only the researchers’ intuition of what constitutes a ‘good’ explanation. There exists vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people deﬁne, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations towards the explanation process. This paper argues that the ﬁeld of explainable artiﬁcial intelligence should build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important ﬁndings, and discusses ways that these can be infused with work on explainable artiﬁcial intelligence.},
	language = {en},
	urldate = {2019-01-31},
	journal = {arXiv:1706.07269 [cs]},
	author = {Miller, Tim},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.07269},
	keywords = {comps-dm, explainable, fatml, key, theory, xai},
}

@book{LookingInformationSurveyResearch,
	address = {Amsterdam ; Boston},
	edition = {2nd ed},
	series = {Library and information science},
	title = {Looking for information: a survey of research on information seeking, needs, and behavior},
	isbn = {978-0-12-369430-0},
	shorttitle = {Looking for information},
	language = {en},
	publisher = {Elsevier/Academic Press},
	author = {Case, Donald Owen},
	year = {2007},
	note = {OCLC: 71951939},
	keywords = {Human information processing, Information retrieval, Research},
}

@book{AccidentalInformationDiscoveryCultivating,
	address = {Cambridge, MA},
	series = {Chandos information professional series},
	title = {Accidental information discovery: cultivating serendipity in the digital age},
	isbn = {978-1-84334-750-7},
	shorttitle = {Accidental information discovery},
	language = {en},
	publisher = {Elsevier : Chandos Publishing},
	editor = {Race, Tammera M. and Makri, Stephann},
	year = {2016},
	note = {OCLC: ocn885228780},
	keywords = {Bibliothek, Inhaltserschliessung, Serendipity},
}

@inproceedings{QuantifyingVisualConcretenessWords,
	address = {New Orleans, Louisiana},
	title = {Quantifying the {Visual} {Concreteness} of {Words} and {Topics} in {Multimodal} {Datasets}},
	url = {http://aclweb.org/anthology/N18-1199},
	doi = {10.18653/v1/N18-1199},
	abstract = {Multimodal machine learning algorithms aim to learn visual-textual correspondences. Previous work suggests that concepts with concrete visual manifestations may be easier to learn than concepts with abstract ones. We give an algorithm for automatically computing the visual concreteness of words and topics within multimodal datasets. We apply the approach in four settings, ranging from image captions to images/text scraped from historical books. In addition to enabling explorations of concepts in multimodal datasets, our concreteness scores predict the capacity of machine learning algorithms to learn textual/visual relationships. We ﬁnd that 1) concrete concepts are indeed easier to learn; 2) the large number of algorithms we consider have similar failure cases; 3) the precise positive relationship between concreteness and performance varies between datasets. We conclude with recommendations for using concreteness scores to facilitate future multimodal research.},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of           the {Association} for {Computational} {Linguistics}: {Human} {Language}           {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hessel, Jack and Mimno, David and Lee, Lillian},
	year = {2018},
	keywords = {dm},
	pages = {2194--2205},
}

@article{InformationseekingBehaviorSocialSciences,
	title = {Information-seeking {Behavior} of {Social} {Sciences} and {Humanities} {Researchers} in the {Internet} {Age}},
	language = {en},
	author = {Ge, Xuemei},
	pages = {92},
}

@article{UseTheoryInformationScience,
	title = {The {Use} of {Theory} in {Information} {Science} {Research}},
	language = {en},
	author = {Pettigrew, Karen E},
	pages = {12},
}

@article{MiningEventOrientedTopicsMicroblog,
	title = {Mining {Event}-{Oriented} {Topics} in {Microblog} {Stream} with {Unsupervised} {Multi}-{View} {Hierarchical} {Embedding}},
	volume = {20},
	issn = {15564681},
	url = {http://dl.acm.org/citation.cfm?doid=3178546.3173044},
	doi = {10.1145/3173044},
	language = {en},
	number = {3},
	urldate = {2019-01-31},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Peng, Min and Zhu, Jiahui and Wang, Hua and Li, Xuhui and Zhang, Yanchun and Zhang, Xiuzhen and Tian, Gang},
	month = apr,
	year = {2018},
	keywords = {dm},
	pages = {1--26},
}

@article{FactorsInfluencingUsersInformation,
	title = {Factors {Influencing} {Users}’ {Information} {Requests}: {Medium}, {Target}, and {Extra}-{Topical} {Dimension}},
	volume = {36},
	issn = {10468188},
	shorttitle = {Factors {Influencing} {Users}’ {Information} {Requests}},
	url = {http://dl.acm.org/citation.cfm?doid=3211967.3209624},
	doi = {10.1145/3209624},
	language = {en},
	number = {4},
	urldate = {2019-01-31},
	journal = {ACM Transactions on Information Systems},
	author = {Arguello, Jaime and Choi, Bogeum and Capra, Robert},
	month = jul,
	year = {2018},
	pages = {1--37},
}

@article{SurveyMetricLearningFeature,
	title = {A {Survey} on {Metric} {Learning} for {Feature} {Vectors} and {Structured} {Data}},
	url = {http://arxiv.org/abs/1306.6709},
	abstract = {The need for appropriate ways to measure the distance or similarity between data is ubiquitous in machine learning, pattern recognition and data mining, but handcrafting such good metrics for speciﬁc problems is generally diﬃcult. This has led to the emergence of metric learning, which aims at automatically learning a metric from data and has attracted a lot of interest in machine learning and related ﬁelds for the past ten years. This survey paper proposes a systematic review of the metric learning literature, highlighting the pros and cons of each approach. We pay particular attention to Mahalanobis distance metric learning, a well-studied and successful framework, but additionally present a wide range of methods that have recently emerged as powerful alternatives, including nonlinear metric learning, similarity learning and local metric learning. Recent trends and extensions, such as semi-supervised metric learning, metric learning for histogram data and the derivation of generalization guarantees, are also covered. Finally, this survey addresses metric learning for structured data, in particular edit distance learning, and attempts to give an overview of the remaining challenges in metric learning for the years to come.},
	language = {en},
	urldate = {2019-01-31},
	journal = {arXiv:1306.6709 [cs, stat]},
	author = {Bellet, Aurélien and Habrard, Amaury and Sebban, Marc},
	month = jun,
	year = {2013},
	note = {arXiv: 1306.6709},
	keywords = {dm, metric-learning},
}

@article{SurveyDistanceMetricLearning,
	title = {Survey on distance metric learning and dimensionality reduction in data mining},
	volume = {29},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-014-0356-z},
	doi = {10.1007/s10618-014-0356-z},
	abstract = {Distance metric learning is a fundamental problem in data mining and knowledge discovery. Many representative data mining algorithms, such as k-nearest neighbor classiﬁer, hierarchical clustering and spectral clustering, heavily rely on the underlying distance metric for correctly measuring relations among input data. In recent years, many studies have demonstrated, either theoretically or empirically, that learning a good distance metric can greatly improve the performance of classiﬁcation, clustering and retrieval tasks. In this survey, we overview existing distance metric learning approaches according to a common framework. Speciﬁcally, depending on the available supervision information during the distance metric learning process, we categorize each distance metric learning algorithm as supervised, unsupervised or semi-supervised. We compare those different types of metric learning methods, point out their strength and limitations. Finally, we summarize open challenges in distance metric learning and propose future directions for distance metric learning.},
	language = {en},
	number = {2},
	urldate = {2019-01-31},
	journal = {Data Mining and Knowledge Discovery},
	author = {Wang, Fei and Sun, Jimeng},
	month = mar,
	year = {2015},
	keywords = {dim-reduction, dm, metric-learning},
	pages = {534--564},
}

@article{LargeMarginTaxonomyEmbedding,
	title = {Large {Margin} {Taxonomy} {Embedding} with an {Application} to {Document} {Categorization}},
	abstract = {Applications of multi-class classiﬁcation, such as document categorization, often appear in cost-sensitive settings. Recent work has signiﬁcantly improved the state of the art by moving beyond “ﬂat” classiﬁcation through incorporation of class hierarchies [4]. We present a novel algorithm that goes beyond hierarchical classiﬁcation and estimates the latent semantic space that underlies the class hierarchy. In this space, each class is represented by a prototype and classiﬁcation is done with the simple nearest neighbor rule. The optimization of the semantic space incorporates large margin constraints that ensure that for each instance the correct class prototype is closer than any other. We show that our optimization is convex and can be solved efﬁciently for large data sets. Experiments on the OHSUMED medical journal data base yield state-of-the-art results on topic categorization.},
	language = {en},
	author = {Weinberger, Kilian and Chapelle, Olivier},
	keywords = {dm, repr-n-emb},
	pages = {8},
}

@article{FairnessVeilIgnoranceWelfare,
	title = {Fairness {Behind} a {Veil} of {Ignorance}: {A} {Welfare} {Analysis} for {Automated} {Decision} {Making}},
	shorttitle = {Fairness {Behind} a {Veil} of {Ignorance}},
	url = {http://arxiv.org/abs/1806.04959},
	abstract = {We draw attention to an important, yet largely overlooked aspect of evaluating fairness for automated decision making systems—namely risk and welfare considerations. Our proposed family of measures corresponds to the long-established formulations of cardinal social welfare in economics. We come to this proposal by taking the perspective of a rational, risk-averse individual who is going to be subject to algorithmic decision making and is faced with the task of choosing between several algorithmic alternatives behind a Rawlsian veil of ignorance. The convex formulation of our measures allows us to integrate them as a constraint into any convex loss minimization pipeline. Our empirical analysis reveals interesting trade-oﬀs between our proposal and (a) prediction accuracy, (b) group discrimination, and (c) Dwork et al.’s notion of individual fairness. Furthermore and perhaps most importantly, our work provides both theoretical and empirical evidence suggesting that a lower-bound on our measures often leads to bounded inequality in algorithmic outcomes; hence presenting the ﬁrst computationally feasible mechanism for bounding individual-level (un)fairness.},
	language = {en},
	urldate = {2019-01-31},
	journal = {arXiv:1806.04959 [cs]},
	author = {Heidari, Hoda and Ferrari, Claudio and Gummadi, Krishna P. and Krause, Andreas},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.04959},
	keywords = {fair, fatml},
}

@article{InteractiveTopicModeling,
	title = {Interactive topic modeling},
	volume = {95},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/10.1007/s10994-013-5413-0},
	doi = {10.1007/s10994-013-5413-0},
	abstract = {Topic models are a useful and ubiquitous tool for understanding large corpora. However, topic models are not perfect, and for many users in computational social science, digital humanities, and information studies—who are not machine learning experts—existing models and frameworks are often a “take it or leave it” proposition. This paper presents a mechanism for giving users a voice by encoding users’ feedback to topic models as correlations between words into a topic model. This framework, interactive topic modeling (ITM), allows untrained users to encode their feedback easily and iteratively into the topic models. Because latency in interactive systems is crucial, we develop more efﬁcient inference algorithms for tree-based topic models. We validate the framework both with simulated and real users.},
	language = {en},
	number = {3},
	urldate = {2019-01-31},
	journal = {Machine Learning},
	author = {Hu, Yuening and Boyd-Graber, Jordan and Satinoff, Brianna and Smith, Alison},
	month = jun,
	year = {2014},
	keywords = {dm, topic},
	pages = {423--469},
}

@article{TopicalWordEmbeddings,
	title = {Topical {Word} {Embeddings}},
	abstract = {Most word embedding models typically represent each word using a single vector, which makes these models indiscriminative for ubiquitous homonymy and polysemy. In order to enhance discriminativeness, we employ latent topic models to assign topics for each word in the text corpus, and learn topical word embeddings (TWE) based on both words and their topics. In this way, contextual word embeddings can be ﬂexibly obtained to measure contextual word similarity. We can also build document representations, which are more expressive than some widely-used document models such as latent topic models. In the experiments, we evaluate the TWE models on two tasks, contextual word similarity and text classiﬁcation. The experimental results show that our models outperform typical word embedding models including the multi-prototype version on contextual word similarity, and also exceed latent topic models and other representative document models on text classiﬁcation. The source code of this paper can be obtained from https://github.com/largelymfs/ topical word embeddings.},
	language = {en},
	author = {Liu, Yang and Liu, Zhiyuan and Chua, Tat-Seng and Sun, Maosong},
	keywords = {dm, topic},
	pages = {7},
}

@article{GeneralEmbeddingFrameworkHeterogeneous,
	title = {A {General} {Embedding} {Framework} for {Heterogeneous} {Information} {Learning} in {Large}-{Scale} {Networks}},
	volume = {12},
	issn = {15564681},
	url = {http://dl.acm.org/citation.cfm?doid=3271478.3241063},
	doi = {10.1145/3241063},
	language = {en},
	number = {6},
	urldate = {2019-01-31},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Huang, Xiao and Li, Jundong and Zou, Na and Hu, Xia},
	month = oct,
	year = {2018},
	keywords = {dm, repr-n-emb},
	pages = {1--24},
}

@inproceedings{RepresentingTextJointEmbedding,
	address = {Lisbon, Portugal},
	title = {Representing {Text} for {Joint} {Embedding} of {Text} and {Knowledge} {Bases}},
	url = {http://aclweb.org/anthology/D15-1174},
	doi = {10.18653/v1/D15-1174},
	abstract = {Models that learn to represent textual and knowledge base relations in the same continuous latent space are able to perform joint inferences among the two kinds of relations and obtain high accuracy on knowledge base completion (Riedel et al., 2013). In this paper we propose a model that captures the compositional structure of textual relations, and jointly optimizes entity, knowledge base, and textual relation representations. The proposed model signiﬁcantly improves performance over a model that does not share parameters among textual relations with common sub-structure.},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Toutanova, Kristina and Chen, Danqi and Pantel, Patrick and Poon, Hoifung and Choudhury, Pallavi and Gamon, Michael},
	year = {2015},
	keywords = {dm, repr-n-emb},
	pages = {1499--1509},
}

@article{OpinionFlowVisualAnalysisOpinion,
	title = {{OpinionFlow}: {Visual} {Analysis} of {Opinion} {Diffusion} on {Social} {Media}},
	volume = {20},
	issn = {1077-2626},
	shorttitle = {{OpinionFlow}},
	url = {http://ieeexplore.ieee.org/document/6876032/},
	doi = {10.1109/TVCG.2014.2346920},
	abstract = {It is important for many different applications such as government and business intelligence to analyze and explore the diffusion of public opinions on social media. However, the rapid propagation and great diversity of public opinions on social media pose great challenges to effective analysis of opinion diffusion. In this paper, we introduce a visual analysis system called OpinionFlow to empower analysts to detect opinion propagation patterns and glean insights. Inspired by the information diffusion model and the theory of selective exposure, we develop an opinion diffusion model to approximate opinion propagation among Twitter users. Accordingly, we design an opinion ﬂow visualization that combines a Sankey graph with a tailored density map in one view to visually convey diffusion of opinions among many users. A stacked tree is used to allow analysts to select topics of interest at different levels. The stacked tree is synchronized with the opinion ﬂow visualization to help users examine and compare diffusion patterns across topics. Experiments and case studies on Twitter data demonstrate the effectiveness and usability of OpinionFlow.},
	language = {en},
	number = {12},
	urldate = {2019-01-31},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wu, Yingcai and Liu, Shixia and Yan, Kai and Liu, Mengchen and Wu, Fangzhao},
	month = dec,
	year = {2014},
	keywords = {diffusion, vis},
	pages = {1763--1772},
}

@article{InterpretableClassificationFrameworkInformation,
	title = {An {Interpretable} {Classification} {Framework} for {Information} {Extraction} from {Online} {Healthcare} {Forums}},
	volume = {2017},
	issn = {2040-2295, 2040-2309},
	url = {https://www.hindawi.com/journals/jhe/2017/2460174/},
	doi = {10.1155/2017/2460174},
	language = {en},
	urldate = {2019-01-31},
	journal = {Journal of Healthcare Engineering},
	author = {Gao, Jun and Liu, Ninghao and Lawley, Mark and Hu, Xia},
	year = {2017},
	keywords = {dm, fatml, interpretable},
	pages = {1--12},
}

@article{DatalessHierarchicalTextClassification,
	title = {On {Dataless} {Hierarchical} {Text} {Classification}},
	abstract = {In this paper, we systematically study the problem of dataless hierarchical text classiﬁcation. Unlike standard text classiﬁcation schemes that rely on supervised training, dataless classiﬁcation depends on understanding the labels of the sought after categories and requires no labeled data. Given a collection of text documents and a set of labels, we show that understanding the labels can be used to accurately categorize the documents. This is done by embedding both labels and documents in a semantic space that allows one to compute meaningful semantic similarity between a document and a potential label. We show that this scheme can be used to support accurate multiclass classiﬁcation without any supervision. We study several semantic representations and show how to improve the classiﬁcation using bootstrapping. Our results show that bootstrapped dataless classiﬁcation is competitive with supervised classiﬁcation with thousands of labeled examples.},
	language = {en},
	author = {Song, Yangqiu and Roth, Dan},
	keywords = {dm},
	pages = {7},
}

@incollection{HolisticConceptRepresentationsEmbedding,
	address = {Cham},
	title = {Towards {Holistic} {Concept} {Representations}: {Embedding} {Relational} {Knowledge}, {Visual} {Attributes}, and {Distributional} {Word} {Semantics}},
	volume = {10587},
	isbn = {978-3-319-68287-7 978-3-319-68288-4},
	shorttitle = {Towards {Holistic} {Concept} {Representations}},
	url = {http://link.springer.com/10.1007/978-3-319-68288-4_41},
	abstract = {Knowledge Graphs (KGs) effectively capture explicit relational knowledge about individual entities. However, visual attributes of those entities, like their shape and color and pragmatic aspects concerning their usage in natural language are not covered. Recent approaches encode such knowledge by learning latent representations (‘embeddings’) separately: In computer vision, visual object features are learned from large image collections and in computational linguistics, word embeddings are extracted from huge text corpora which capture their distributional semantics. We investigate the potential of complementing the relational knowledge captured in KG embeddings with knowledge from text documents and images by learning a shared latent representation that integrates information across those modalities. Our empirical results show that a joined concept representation provides measurable beneﬁts for i) semantic similarity benchmarks, since it shows a higher correlation with the human notion of similarity than unior bi-modal representations, and ii) entity-type prediction tasks, since it clearly outperforms plain KG embeddings. These ﬁndings encourage further research towards capturing types of knowledge that go beyond today’s KGs.},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {The {Semantic} {Web} – {ISWC} 2017},
	publisher = {Springer International Publishing},
	author = {Thoma, Steffen and Rettinger, Achim and Both, Fabian},
	editor = {d'Amato, Claudia and Fernandez, Miriam and Tamma, Valentina and Lecue, Freddy and Cudré-Mauroux, Philippe and Sequeda, Juan and Lange, Christoph and Heflin, Jeff},
	year = {2017},
	doi = {10.1007/978-3-319-68288-4_41},
	keywords = {dm},
	pages = {694--710},
}

@article{WhisperTracingSpatiotemporalProcess,
	title = {Whisper: {Tracing} the {Spatiotemporal} {Process} of {Information} {Diffusion} in {Real} {Time}},
	volume = {18},
	issn = {1077-2626},
	shorttitle = {Whisper},
	url = {http://ieeexplore.ieee.org/document/6327271/},
	doi = {10.1109/TVCG.2012.291},
	abstract = {When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, “Whisper”, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunﬂower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efﬁcient ﬂux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identiﬁed even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today’s information consumption and dispersion in the wild.},
	language = {en},
	number = {12},
	urldate = {2019-01-31},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {{Nan Cao} and {Yu-Ru Lin} and {Xiaohua Sun} and Lazer, D. and {Shixia Liu} and {Huamin Qu}},
	month = dec,
	year = {2012},
	keywords = {comps-sc, diffusion, vis},
	pages = {2649--2658},
}

@article{DistanceMetricLearningComprehensive,
	title = {Distance {Metric} {Learning}: {A} {Comprehensive} {Survey}},
	language = {en},
	author = {Yang, Liu and Jin, Rong},
	keywords = {dm, metric-learning},
	pages = {51},
}

@article{MetricLearningSurvey,
	title = {Metric {Learning}: {A} {Survey}},
	volume = {5},
	issn = {1935-8237, 1935-8245},
	shorttitle = {Metric {Learning}},
	url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-machine-learning/MAL-019},
	doi = {10.1561/2200000019},
	language = {en},
	number = {4},
	urldate = {2019-01-31},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Kulis, Brian},
	year = {2013},
	keywords = {dm, metric-learning},
	pages = {287--364},
}

@article{PolicyEntrepreneursDiffusionInnovation,
	title = {Policy {Entrepreneurs} and the {Diffusion} of {Innovation}},
	volume = {41},
	issn = {00925853},
	url = {https://www.jstor.org/stable/2111674?origin=crossref},
	doi = {10.2307/2111674},
	language = {en},
	number = {3},
	urldate = {2019-02-24},
	journal = {American Journal of Political Science},
	author = {Mintrom, Michael},
	month = jul,
	year = {1997},
	pages = {738},
}

@inproceedings{DMapVisualAnalysisEgocentric,
	address = {Baltimore, MD, USA},
	title = {D-{Map}: {Visual} analysis of ego-centric information diffusion patterns in social media},
	isbn = {978-1-5090-5661-3},
	shorttitle = {D-{Map}},
	url = {http://ieeexplore.ieee.org/document/7883510/},
	doi = {10.1109/VAST.2016.7883510},
	language = {en},
	urldate = {2019-01-31},
	booktitle = {2016 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Chen, Siming and Chen, Shuai and Wang, Zhenhuang and Liang, Jie and Yuan, Xiaoru and Cao, Nan and Wu, Yadong},
	month = oct,
	year = {2016},
	keywords = {diffusion, seq, vis},
	pages = {41--50},
}

@article{CiteRiversVisualAnalyticsCitation,
	title = {{CiteRivers}: {Visual} {Analytics} of {Citation} {Patterns}},
	volume = {22},
	issn = {1077-2626},
	shorttitle = {{CiteRivers}},
	url = {http://ieeexplore.ieee.org/document/7192685/},
	doi = {10.1109/TVCG.2015.2467621},
	abstract = {The exploration and analysis of scientiﬁc literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientiﬁc documents, and combine it with a new and ﬂexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback.},
	language = {en},
	number = {1},
	urldate = {2019-01-31},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Heimerl, Florian and Han, Qi and Koch, Steffen and Ertl, Thomas},
	month = jan,
	year = {2016},
	keywords = {diffusion, seq, vis},
	pages = {190--199},
}

@article{CharterSchoolPolicyImplementation,
	title = {Charter {School} {Policy}, {Implementation}, and {Diffusion} {Across} the {United} {States}},
	volume = {78},
	issn = {0038-0407, 1939-8573},
	url = {http://journals.sagepub.com/doi/10.1177/003804070507800404},
	doi = {10.1177/003804070507800404},
	language = {en},
	number = {4},
	urldate = {2019-02-24},
	journal = {Sociology of Education},
	author = {Renzulli, Linda A. and Roscigno, Vincent J.},
	month = oct,
	year = {2005},
	pages = {344--366},
}

@article{StateLocalNexusPolicyInnovation,
	title = {The {State}-{Local} {Nexus} in {Policy} {Innovation} {Diffusion}: {The} {Case} of {School} {Choice}},
	language = {en},
	journal = {The State},
	author = {Mintrom, Michael},
	year = {1997},
	keywords = {app, diffusion},
	pages = {20},
}

@article{FramingMoralityPolicyIssues,
	title = {Framing morality policy issues: state legislative debates on abortion restrictions},
	issn = {0032-2687, 1573-0891},
	shorttitle = {Framing morality policy issues},
	url = {http://link.springer.com/10.1007/s11077-018-9336-2},
	doi = {10.1007/s11077-018-9336-2},
	abstract = {Scholars of “morality policies” have often assumed a signature characteristic of such policies is that advocates will frame them as clashes between fundamental moral and religious principles. Recent studies of issues typically considered under the “morality policy” rubric have found that advocates often frame these issues along multiple dimensions and that they do not necessarily favor frames that emphasize moral principles over other considerations. This paper examines this issue for abortion policy. We analyze verbatim records of debates over 26 recent proposals to restrict abortion rights in the 16 states for which data are available. We found that both sides in debates over abortion restrictions framed the issue along several dimensions with no single frame dominating most of the debates. While there is some empirical support for the morality policy perspective, the frequency that advocates employed morality frames was less than we expected given the disproportionately high levels of evangelical Protestant membership in the states we examined. Rather than simply casting the debate as one over irreconcilable moral principles, the two sides’ strategies often converged by framing the issue in terms of various consequences of abortion and abortion restrictions for women. Advocates propensity to frame the issue in terms of “right to life” versus “woman’s choice” principles rose when one side or the other escalated rhetoric about “life” or “choice” principles (inducing the other to respond in kind). Our data thus conform to the logic of a game of tit-for-tat in which individuals follow a strategy of “retaliation” if their opponents frame issues in highly moralized, judgmental terms, or they “cooperate” by emphasizing how their preferred policy will promote some widely shared value (like women’s welfare or the authoritativeness of medical research). “Morality talk” was also more prevalent when the debates were about bans on abortion rather than other types of restrictions. The broad implication of our findings is that the propensity of advocates to frame issues in terms of fundamental moral principles has less to do with the general subject matter or issue area (e.g., abortion) and more to do with the context of debate and strategic considerations.},
	language = {en},
	urldate = {2019-03-01},
	journal = {Policy Sciences},
	author = {Mucciaroni, Gary and Ferraiolo, Kathleen and Rubado, Meghan E.},
	month = oct,
	year = {2018},
	keywords = {app, diffusion},
}

@article{InnovationDiffusionHeterogeneousPopulations,
	title = {Innovation {Diffusion} in {Heterogeneous} {Populations}: {Contagion}, {Social} {Influence}, and {Social} {Learning}},
	volume = {99},
	issn = {0002-8282},
	shorttitle = {Innovation {Diffusion} in {Heterogeneous} {Populations}},
	url = {http://pubs.aeaweb.org/doi/10.1257/aer.99.5.1899},
	doi = {10.1257/aer.99.5.1899},
	language = {en},
	number = {5},
	urldate = {2019-03-01},
	journal = {American Economic Review},
	author = {Young, H. Peyton},
	month = dec,
	year = {2009},
	keywords = {app, diffusion},
	pages = {1899--1924},
}

@article{MODELCOMPRESSIONDISTILLATIONQUANTIZATION,
	title = {{MODEL} {COMPRESSION} {VIA} {DISTILLATION} {AND} {QUANTIZATION}},
	abstract = {Deep neural networks (DNNs) continue to make signiﬁcant advances, solving tasks from image classiﬁcation to translation or reinforcement learning. One aspect of the ﬁeld receiving considerable attention is efﬁciently executing deep models in resource-constrained environments, such as mobile or embedded devices. This paper focuses on this problem, and proposes two new compression methods, which jointly leverage weight quantization and distillation of larger networks, called “teachers,” into compressed “student” networks. The ﬁrst method we propose is called quantized distillation and leverages distillation during the training process, by incorporating distillation loss, expressed with respect to the teacher network, into the training of a smaller student network whose weights are quantized to a limited set of levels. The second method, differentiable quantization, optimizes the location of quantization points through stochastic gradient descent, to better ﬁt the behavior of the teacher model. We validate both methods through experiments on convolutional and recurrent architectures. We show that quantized shallow students can reach similar accuracy levels to state-of-the-art full-precision teacher models, while providing up to order of magnitude compression, and inference speedup that is almost linear in the depth reduction. In sum, our results enable DNNs for resource-constrained environments to leverage architecture and accuracy advances developed on more powerful devices.},
	language = {en},
	author = {Polino, Antonio and Alistarh, Dan and Pascanu, Razvan},
	year = {2018},
	keywords = {distillation, fatml, xai},
	pages = {21},
}

@article{VisualizingDeepNeuralNetwork,
	title = {Visualizing {Deep} {Neural} {Network} {Decisions}: {Prediction} {Difference} {Analysis}},
	shorttitle = {Visualizing {Deep} {Neural} {Network} {Decisions}},
	url = {http://arxiv.org/abs/1702.04595},
	abstract = {This article presents the prediction difference analysis method for visualizing the response of a deep neural network to a speciﬁc input. When classifying images, the method highlights areas in a given input image that provide evidence for or against a certain class. It overcomes several shortcoming of previous methods and provides great additional insight into the decision making process of classiﬁers. Making neural network decisions interpretable through visualization is important both to improve models and to accelerate the adoption of black-box classiﬁers in application areas such as medicine. We illustrate the method in experiments on natural images (ImageNet data), as well as medical images (MRI brain scans).},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1702.04595 [cs]},
	author = {Zintgraf, Luisa M. and Cohen, Taco S. and Adel, Tameem and Welling, Max},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.04595},
	keywords = {fatml, xai},
}

@article{HumanAlgorithmInteractionBiasesBig,
	title = {Human-{Algorithm} {Interaction} {Biases} in the {Big} {Data} {Cycle}: {A} {Markov} {Chain} {Iterated} {Learning} {Framework}},
	shorttitle = {Human-{Algorithm} {Interaction} {Biases} in the {Big} {Data} {Cycle}},
	url = {http://arxiv.org/abs/1608.07895},
	abstract = {Early supervised machine learning algorithms have relied on reliable expert labels to build predictive models. However, the gates of data generation have recently been opened to a wider base of users who started participating increasingly with casual labeling, rating, annotating, etc. The increased online presence and participation of humans has led not only to a democratization of unchecked inputs to algorithms, but also to a wide democratization of the “consumption” of machine learning algorithms’ outputs by general users. Hence, these algorithms, many of which are becoming essential building blocks of recommender systems and other information ﬁlters, started interacting with users at unprecedented rates. The result is machine learning algorithms that consume more and more data that is unchecked, or at the very least, not ﬁtting conventional assumptions made by various machine learning algorithms. These include biased samples, biased labels, diverging training and testing sets, and cyclical interaction between algorithms, humans, information consumed by humans, and data consumed by algorithms. Yet, the continuous interaction between humans and algorithms is rarely taken into account in machine learning algorithm design and analysis. In this paper, we present a preliminary theoretical model and analysis of the mutual interaction between humans and algorithms, based on an iterated learning framework that is inspired from the study of human language evolution. We also deﬁne the concepts of human and algorithm blind spots and outline machine learning approaches to mend iterated bias through two novel notions: antidotes and reactive learning.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1608.07895 [cs]},
	author = {Nasraoui, Olfa and Shafto, Patrick},
	month = aug,
	year = {2016},
	note = {arXiv: 1608.07895},
	keywords = {fatml, hci},
}

@article{HumanAttentionVisualQuestion,
	title = {Human {Attention} in {Visual} {Question} {Answering}: {Do} {Humans} and {Deep} {Networks} {Look} at the {Same} {Regions}?},
	shorttitle = {Human {Attention} in {Visual} {Question} {Answering}},
	url = {http://arxiv.org/abs/1606.03556},
	abstract = {We conduct large-scale studies on ‘human attention’ in Visual Question Answering (VQA) to understand where humans choose to look to answer questions about images. We design and test multiple game-inspired novel attention-annotation interfaces that require the subject to sharpen regions of a blurred image to answer a question. Thus, we introduce the VQA-HAT (Human ATtention) dataset. We evaluate attention maps generated by state-of-the-art VQA models against human attention both qualitatively (via visualizations) and quantitatively (via rank-order correlation). Overall, our experiments show that current attention models in VQA do not seem to be looking at the same regions as humans.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1606.03556 [cs]},
	author = {Das, Abhishek and Agrawal, Harsh and Zitnick, C. Lawrence and Parikh, Devi and Batra, Dhruv},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.03556},
	keywords = {fatml, xai},
}

@article{PredictionExplanationSocialSystems,
	title = {Prediction and explanation in social systems},
	volume = {355},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aal3856},
	doi = {10.1126/science.aal3856},
	language = {en},
	number = {6324},
	urldate = {2019-03-07},
	journal = {Science},
	author = {Hofman, Jake M. and Sharma, Amit and Watts, Duncan J.},
	month = feb,
	year = {2017},
	keywords = {fatml, xai},
	pages = {486--488},
}

@article{WHAIWEIBULLHYBRIDAUTOENCODING,
	title = {{WHAI}: {WEIBULL} {HYBRID} {AUTOENCODING} {INFERENCE} {FOR} {DEEP} {TOPIC} {MODELING}},
	abstract = {To train an inference network jointly with a deep generative topic model, making it both scalable to big corpora and fast in out-of-sample prediction, we develop Weibull hybrid autoencoding inference (WHAI) for deep latent Dirichlet allocation, which infers posterior samples via a hybrid of stochastic-gradient MCMC and autoencoding variational Bayes. The generative network of WHAI has a hierarchy of gamma distributions, while the inference network of WHAI is a Weibull upward-downward variational autoencoder, which integrates a deterministicupward deep neural network, and a stochastic-downward deep generative model based on a hierarchy of Weibull distributions. The Weibull distribution can be used to well approximate a gamma distribution with an analytic Kullback-Leibler divergence, and has a simple reparameterization via the uniform noise, which help efﬁciently compute the gradients of the evidence lower bound with respect to the parameters of the inference network. The effectiveness and efﬁciency of WHAI are illustrated with experiments on big corpora.},
	language = {en},
	author = {Zhang, Hao and Chen, Bo and Guo, Dandan and Zhou, Mingyuan},
	year = {2018},
	keywords = {fatml, xai},
	pages = {15},
}

@article{HIERARCHICALDENSITYORDEREMBEDDINGS,
	title = {{HIERARCHICAL} {DENSITY} {ORDER} {EMBEDDINGS}},
	abstract = {By representing words with probability densities rather than point vectors, probabilistic word embeddings can capture rich and interpretable semantic information and uncertainty (Vilnis \& McCallum, 2014; Athiwaratkun \& Wilson, 2017). The uncertainty information can be particularly meaningful in capturing entailment relationships – whereby general words such as “entity” correspond to broad distributions that encompass more speciﬁc words such as “animal” or “instrument”. We introduce density order embeddings, which learn hierarchical representations through encapsulation of probability distributions. In particular, we propose simple yet effective loss functions and distance metrics, as well as graph-based schemes to select negative samples to better learn hierarchical probabilistic representations. Our approach provides state-of-the-art performance on the WORDNET hypernym relationship prediction task and the challenging HYPERLEX lexical entailment dataset – while retaining a rich and interpretable probabilistic representation.},
	language = {en},
	author = {Athiwaratkun, Ben and Wilson, Andrew Gordon},
	year = {2018},
	keywords = {dm, fatml, hierarchy, xai},
	pages = {15},
}

@article{LEARNINGHOWEXPLAINNEURAL,
	title = {{LEARNING} {HOW} {TO} {EXPLAIN} {NEURAL} {NETWORKS}: {PATTERNNET} {AND} {PATTERNATTRIBUTION}},
	abstract = {DeConvNet, Guided BackProp, LRP, were invented to better understand deep neural networks. We show that these methods do not produce the theoretically correct explanation for a linear model. Yet they are used on multi-layer networks with millions of parameters. This is a cause for concern since linear models are simple neural networks. We argue that explanation methods for neural nets should work reliably in the limit of simplicity, the linear models. Based on our analysis of linear models we propose a generalization that yields two explanation techniques (PatternNet and PatternAttribution) that are theoretically sound for linear models and produce improved explanations for deep networks.},
	language = {en},
	author = {Kindermans, Pieter-Jan},
	keywords = {fatml, xai},
	pages = {16},
}

@article{FaithfulCustomizableExplanationsBlacka,
	title = {Faithful and {Customizable} {Explanations} of {Black} {Box} {Models}},
	abstract = {As predictive models increasingly assist human experts (e.g., doctors) in day-to-day decision making, it is crucial for experts to be able to explore and understand how such models behave in different feature subspaces in order to know if and when to trust them. To this end, we propose Model Understanding through Subspace Explanations (MUSE), a novel model agnostic framework which facilitates understanding of a given black box model by explaining how it behaves in subspaces characterized by certain features of interest. Our framework provides end users (e.g., doctors) with the ﬂexibility of customizing the model explanations by allowing them to input the features of interest. The construction of explanations is guided by a novel objective function that we propose to simultaneously optimize for ﬁdelity to the original model, unambiguity and interpretability of the explanation. More speciﬁcally, our objective allows us to learn, with optimality guarantees, a small number of compact decision sets each of which captures the behavior of a given black box model in unambiguous, well-deﬁned regions of the feature space. Experimental evaluation with real-world datasets and user studies demonstrate that our approach can generate customizable, highly compact, easy-to-understand, yet accurate explanations of various kinds of predictive models compared to state-of-the-art baselines.},
	language = {en},
	author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
	keywords = {explainable, fatml, framework, key, xai},
	pages = {11},
}

@article{SoftClassifiersHardDecisions,
	title = {From {Soft} {Classifiers} to {Hard} {Decisions}: {How} fair can we be?},
	shorttitle = {From {Soft} {Classifiers} to {Hard} {Decisions}},
	url = {http://arxiv.org/abs/1810.02003},
	abstract = {A popular methodology for building binary decision-making classiﬁers in the presence of imperfect information is to ﬁrst construct a calibrated non-binary “scoring” classiﬁer, and then to post-process this score to obtain a binary decision. We study various group fairness properties of this methodology, when the non-binary scores are calibrated over all protected groups, and with a variety of post-processing algorithms. Speciﬁcally, we show: • There does not exist a general way to post-process a calibrated classiﬁer to equalize protected groups’ positive or negative predictive value (PPV or NPV). For certain “nice” calibrated classiﬁers, either PPV or NPV can be equalized when the post-processor uses diﬀerent thresholds across protected groups. Still, when the post-processing consists of a single global threshold across all groups, natural fairness properties, such as equalizing PPV in a nontrivial way, do not hold even for “nice” classiﬁers.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1810.02003 [cs, stat]},
	author = {Canetti, Ran and Cohen, Aloni and Dikkala, Nishanth and Ramnarayan, Govind and Scheffler, Sarah and Smith, Adam},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.02003},
	keywords = {fair, fatml, interpretable},
}

@article{SimplicityCreatesInequityImplications,
	title = {Simplicity {Creates} {Inequity}: {Implications} for {Fairness}, {Stereotypes}, and {Interpretability}},
	shorttitle = {Simplicity {Creates} {Inequity}},
	url = {http://arxiv.org/abs/1809.04578},
	abstract = {Algorithmic predictions are increasingly used to aid, or in some cases supplant, human decision-making, and this development has placed new demands on the outputs of machine learning procedures. To facilitate human interaction, we desire that they output prediction functions that are in some fashion simple or interpretable. And because they inﬂuence consequential decisions, we also desire equitable prediction functions, ones whose allocations beneﬁt (or at the least do not harm) disadvantaged groups.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1809.04578 [cs, stat]},
	author = {Kleinberg, Jon and Mullainathan, Sendhil},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.04578},
	keywords = {Statistics - Machine Learning, fair, fatml},
}

@article{ProfessionalGenderGapsUS,
	title = {Professional {Gender} {Gaps} {Across} {US} {Cities}},
	url = {http://arxiv.org/abs/1801.09429},
	abstract = {Gender imbalances in work environments have been a long-standing concern. Identifying the existence of such imbalances is key to designing policies to help overcome them. In this work, we study gender trends in employment across various dimensions in the United States. This is done by analyzing anonymous, aggregate statistics that were extracted from LinkedIn's advertising platform. The data contain the number of male and female LinkedIn users with respect to (i) location, (ii) age, (iii) industry and (iv) certain skills. We studied which of these categories correlate the most with high relative male or female presence on LinkedIn. In addition to examining the summary statistics of the LinkedIn data, we model the gender balance as a function of the different employee features using linear regression. Our results suggest that the gender gap varies across all feature types, but the differences are most profound among industries and skills. A high correlation between gender ratios of people in our LinkedIn data set and data provided by the US Bureau of Labor Statistics serves as external validation for our results.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1801.09429 [cs]},
	author = {Haranko, Karri and Zagheni, Emilio and Garimella, Kiran and Weber, Ingmar},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.09429},
	keywords = {fatml, xai},
}

@inproceedings{LearningCredibleModels,
	address = {London, United Kingdom},
	title = {Learning {Credible} {Models}},
	isbn = {978-1-4503-5552-0},
	url = {http://dl.acm.org/citation.cfm?doid=3219819.3220070},
	doi = {10.1145/3219819.3220070},
	abstract = {In many settings, it is important that a model be capable of providing reasons for its predictions (i.e., the model must be interpretable). However, the model’s reasoning may not conform with well-established knowledge. In such cases, while interpretable, the model lacks credibility. In this work, we formally define credibility in the linear setting and focus on techniques for learning models that are both accurate and credible. In particular, we propose a regularization penalty, expert yielded estimates (EYE), that incorporates expert knowledge about well-known relationships among covariates and the outcome of interest. We give both theoretical and empirical results comparing our proposed method to several other regularization techniques. Across a range of settings, experiments on both synthetic and real data show that models learned using the EYE penalty are significantly more credible than those learned using other penalties. Applied to two large-scale patient risk stratification task, our proposed technique results in a model whose top features overlap significantly with known clinical risk factors, while still achieving good predictive performance.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '18},
	publisher = {ACM Press},
	author = {Wang, Jiaxuan and Oh, Jeeheh and Wang, Haozhu and Wiens, Jenna},
	year = {2018},
	keywords = {fatml, xai},
	pages = {2417--2426},
}

@article{ExplainableArtificialIntelligenceUnderstanding,
	title = {Explainable {Artificial} {Intelligence}: {Understanding}, {Visualizing} and {Interpreting} {Deep} {Learning} {Models}},
	shorttitle = {Explainable {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/1708.08296},
	abstract = {With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classiﬁcation, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artiﬁcial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this ﬁeld and makes a plea for more interpretability in artiﬁcial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classiﬁcation tasks.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1708.08296 [cs, stat]},
	author = {Samek, Wojciech and Wiegand, Thomas and Müller, Klaus-Robert},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.08296},
	keywords = {dl, fatml, key, survey, xai},
}

@article{BiasDisparityRecommendationSystems,
	title = {Bias {Disparity} in {Recommendation} {Systems}},
	url = {http://arxiv.org/abs/1811.01461},
	abstract = {Recommender systems have been applied successfully in a number of di erent domains, such as, entertainment, commerce, and employment. eir success lies in their ability to exploit the collective behavior of users in order to deliver highly targeted, personalized recommendations. Given that recommenders learn from user preferences, they incorporate di erent biases [8] that users exhibit in the input data. More importantly, there are cases where recommenders may amplify such biases, leading to the phenomenon of bias disparity. In this short paper, we present a preliminary experimental study on synthetic data, where we investigate di erent conditions under which a recommender exhibits bias disparity, and the long-term e ect of recommendations on data bias. We also consider a simple re-ranking algorithm for reducing bias disparity, and present some observations for data disparity on real data.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1811.01461 [cs]},
	author = {Tsintzou, Virginia and Pitoura, Evaggelia and Tsaparas, Panayiotis},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.01461},
	keywords = {fair, fatml},
}

@article{LOCALEXPLANATIONMETHODSDEEP,
	title = {{LOCAL} {EXPLANATION} {METHODS} {FOR} {DEEP} {NEURAL} {NETWORKS} {LACK} {SENSITIVITY} {TO} {PARAMETER} {VAL}-},
	abstract = {Explaining the output of a complicated machine learning model like a deep neural network (DNN) is a central challenge in machine learning. Several proposed local explanation methods address this issue by identifying what dimensions of a single input are most responsible for a DNN’s output. The goal of this work is to assess the sensitivity of local explanations to DNN parameter values. Somewhat surprisingly, we ﬁnd that DNNs with randomly-initialized weights produce explanations that are both visually and quantitatively similar to those produced by DNNs with learned weights. Our conjecture is that this phenomenon occurs because these explanations are dominated by the lower level features of a DNN, and that a DNN’s architecture provides a strong prior which signiﬁcantly affects the representations learned at these lower layers. NOTE: This work is now subsumed by our recent manuscript, Sanity Checks for Saliency Maps (to appear NIPS 2018), where we expand on ﬁndings and address concerns raised in Sundararajan \& Taly (2018).},
	language = {en},
	author = {Adebayo, Julius and Gilmer, Justin and Goodfellow, Ian and Kim, Been},
	year = {2018},
	keywords = {explainable, fatml, instance, xai},
	pages = {10},
}

@article{HumanCenteredArtificialIntelligenceMachine,
	title = {Human-{Centered} {Artificial} {Intelligence} and {Machine} {Learning}},
	url = {http://arxiv.org/abs/1901.11184},
	abstract = {Humans are increasingly coming into contact with artiﬁcial intelligence and machine learning systems. Human-centered artiﬁcial intelligence is a perspective on AI and ML that algorithms must be designed with awareness that they are part of a larger system consisting of humans. We lay forth an argument that human-centered artiﬁcial intelligence can be broken down into two aspects: (1) AI systems that understand humans from a sociocultural perspective, and (2) AI systems that help humans understand them. We further argue that issues of social responsibility such as fairness, accountability, interpretability, and transparency.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1901.11184 [cs]},
	author = {Riedl, Mark O.},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.11184},
	keywords = {fatml, hci, xai},
}

@article{PleaseStopExplainingBlack,
	title = {Please {Stop} {Explaining} {Black} {Box} {Models} for {High} {Stakes} {Decisions}},
	url = {http://arxiv.org/abs/1811.10154},
	abstract = {Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains. People have hoped that creating methods for explaining these black box models will alleviate some of these problems, but trying to explain black box models, rather than creating models that are interpretable in the ﬁrst place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. There is a way forward – it is to design models that are inherently interpretable.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1811.10154 [cs, stat]},
	author = {Rudin, Cynthia},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.10154},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{InterpretableModelGloballyConsistent,
	title = {An {Interpretable} {Model} with {Globally} {Consistent} {Explanations} for {Credit} {Risk}},
	url = {http://arxiv.org/abs/1811.12615},
	abstract = {We propose a possible solution to a public challenge posed by the Fair Isaac Corporation (FICO), which is to provide an explainable model for credit risk assessment. Rather than present a black box model and explain it afterwards, we provide a globally interpretable model that is as accurate as other neural networks. Our "two-layer additive risk model" is decomposable into subscales, where each node in the second layer represents a meaningful subscale, and all of the nonlinearities are transparent. We provide three types of explanations that are simpler than, but consistent with, the global model. One of these explanation methods involves solving a minimum set cover problem to find high-support globally-consistent explanations. We present a new online visualization tool to allow users to explore the global model and its explanations.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1811.12615 [cs, stat]},
	author = {Chen, Chaofan and Lin, Kangcheng and Rudin, Cynthia and Shaposhnik, Yaron and Wang, Sijia and Wang, Tong},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.12615},
	keywords = {fatml, interpretable, xai},
}

@article{SparsityTreeRegularizationDeep,
	title = {Beyond {Sparsity}: {Tree} {Regularization} of {Deep} {Models} for {Interpretability}},
	shorttitle = {Beyond {Sparsity}},
	url = {http://arxiv.org/abs/1711.06178},
	abstract = {The lack of interpretability remains a key barrier to the adoption of deep models in many applications. In this work, we explicitly regularize deep models so human users might step through the process behind their predictions in little time. Speciﬁcally, we train deep time-series models so their classprobability predictions have high accuracy while being closely modeled by decision trees with few nodes. Using intuitive toy examples as well as medical tasks for treating sepsis and HIV, we demonstrate that this new tree regularization yields models that are easier for humans to simulate than simpler L1 or L2 penalties without sacriﬁcing predictive power.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1711.06178 [cs, stat]},
	author = {Wu, Mike and Hughes, Michael C. and Parbhoo, Sonali and Zazzi, Maurizio and Roth, Volker and Doshi-Velez, Finale},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.06178},
	keywords = {dl, fatml, interpretable, xai},
}

@article{AuditingSearchEnginesDifferential,
	title = {Auditing {Search} {Engines} for {Differential} {Satisfaction} {Across} {Demographics}},
	url = {http://arxiv.org/abs/1705.10689},
	doi = {10.1145/3041021.3054197},
	abstract = {Many online services, such as search engines, social media platforms, and digital marketplaces, are advertised as being available to any user, regardless of their age, gender, or other demographic factors. However, there are growing concerns that these services may systematically underserve some groups of users. In this paper, we present a framework for internally auditing such services for diﬀerences in user satisfaction across demographic groups, using search engines as a case study. We ﬁrst explain the pitfalls of na¨ıvely comparing the behavioral metrics that are commonly used to evaluate search engines. We then propose three methods for measuring latent diﬀerences in user satisfaction from observed diﬀerences in evaluation metrics. To develop these methods, we drew on ideas from the causal inference literature and the multilevel modeling literature. Our framework is broadly applicable to other online services, and provides general insight into interpreting their evaluation metrics.},
	language = {en},
	urldate = {2019-03-07},
	journal = {Proceedings of the 26th International Conference on World Wide Web Companion  - WWW '17 Companion},
	author = {Mehrotra, Rishabh and Anderson, Ashton and Diaz, Fernando and Sharma, Amit and Wallach, Hanna and Yilmaz, Emine},
	year = {2017},
	note = {arXiv: 1705.10689},
	keywords = {fair, fatml, xai},
	pages = {626--633},
}

@inproceedings{PrCPPrerecommendationCounterPolarization,
	address = {Seville, Spain},
	title = {{PrCP}: {Pre}-recommendation {Counter}-{Polarization}:},
	isbn = {978-989-758-330-8},
	shorttitle = {{PrCP}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006938702820289},
	doi = {10.5220/0006938702820289},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the 10th {International} {Joint} {Conference} on {Knowledge} {Discovery}, {Knowledge} {Engineering} and {Knowledge} {Management}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Badami, Mahsa and Nasraoui, Olfa and Shafto, Patrick},
	year = {2018},
	keywords = {fatml, xai},
	pages = {282--289},
}

@article{VisualAnalyticsExplainableDeepa,
	title = {Visual {Analytics} for {Explainable} {Deep} {Learning}},
	volume = {38},
	issn = {0272-1716, 1558-1756},
	url = {https://ieeexplore.ieee.org/document/8402187/},
	doi = {10.1109/MCG.2018.042731661},
	language = {en},
	number = {4},
	urldate = {2019-03-07},
	journal = {IEEE Computer Graphics and Applications},
	author = {Choo, Jaegul and Liu, Shixia},
	month = jul,
	year = {2018},
	keywords = {fatml, key, xai},
	pages = {84--92},
}

@article{MediaBiasMonitorQuantifying,
	title = {Media {Bias} {Monitor}: {Quantifying} {Biases} of {Social} {Media} {News} {Outlets} at {Large}-{Scale}},
	abstract = {As Internet users increasingly rely on social media sites like Facebook and Twitter to receive news, they are faced with a bewildering number of news media choices. For example, thousands of Facebook pages today are registered and categorized as some form of news media outlets. Inferring the bias (or slant) of these media pages poses a difﬁcult challenge for media watchdog organizations that traditionally rely on content analysis.},
	language = {en},
	author = {Ribeiro, Filipe N and Henrique, Lucas and Benevenuto, Fabricio and Chakraborty, Abhijnan and Kulshrestha, Juhi and Babaei, Mahmoudreza and Gummadi, Krishna P},
	keywords = {fair, fatml},
	pages = {10},
}

@article{UnderstandingEffectAccuracyTrust,
	title = {Understanding the {Effect} of {Accuracy} on {Trust} in {Machine} {Learning} {Models}},
	abstract = {We address a relatively under-explored aspect of human–computer interaction: people’s abilities to understand the relationship between a machine learning model’s stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized humansubject experiments to examine whether laypeople’s trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on the model’s stated accuracy on held-out data and on its observed accuracy in practice. We find that people’s trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline.},
	language = {en},
	author = {Yin, Ming and Vaughan, Jennifer Wortman and Wallach, Hanna},
	year = {2019},
	keywords = {fatml, xai},
	pages = {12},
}

@article{BayesianFrameworkLearningRule,
	title = {A {Bayesian} {Framework} for {Learning} {Rule} {Sets} for {Interpretable} {Classiﬁcation}},
	abstract = {We present a machine learning algorithm for building classiﬁers that are comprised of a small number of short rules. These are restricted disjunctive normal form models. An example of a classiﬁer of this form is as follows: If X satisﬁes (condition A AND condition B) OR (condition C) OR · · · , then Y = 1. Models of this form have the advantage of being interpretable to human experts since they produce a set of rules that concisely describe a speciﬁc class. We present two probabilistic models with prior parameters that the user can set to encourage the model to have a desired size and shape, to conform with a domain-speciﬁc deﬁnition of interpretability. We provide a scalable MAP inference approach and develop theoretical bounds to reduce computation by iteratively pruning the search space. We apply our method (Bayesian Rule Sets – BRS) to characterize and predict user behavior with respect to in-vehicle context-aware personalized recommender systems. Our method has a major advantage over classical associative classiﬁcation methods and decision trees in that it does not greedily grow the model.},
	language = {en},
	author = {Wang, Tong and Rudin, Cynthia and Doshi-Velez, Finale and Liu, Yimin and Klampﬂ, Erica and MacNeille, Perry},
	keywords = {fatml, global, interpretable, xai},
	pages = {37},
}

@article{UnifiedApproachInterpretingModel,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction’s accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a uniﬁed framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identiﬁcation of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class uniﬁes six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this uniﬁcation, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	language = {en},
	author = {Lundberg, Scott M and Lee, Su-In},
	keywords = {fatml, interpretable, xai},
	pages = {10},
}

@article{DiscoveringInterpretableRepresentationsBoth,
	title = {Discovering {Interpretable} {Representations} for {Both} {Deep} {Generative} and {Discriminative} {Models}},
	abstract = {Interpretability of representations in both deep generative and discriminative models is highly desirable. Current methods jointly optimize an objective combining accuracy and interpretability. However, this may reduce accuracy, and is not applicable to already trained models. We propose two interpretability frameworks. First, we provide an interpretable lens for an existing model. We use a generative model which takes as input the representation in an existing (generative or discriminative) model, weakly supervised by limited side information. Applying a ﬂexible and invertible transformation to the input leads to an interpretable representation with no loss in accuracy. We extend the approach using an active learning strategy to choose the most useful side information to obtain, allowing a human to guide what “interpretable” means. Our second framework relies on joint optimization for a representation which is both maximally informative about the side information and maximally compressive about the non-interpretable data factors. This leads to a novel perspective on the relationship between compression and regularization. We also propose a new interpretability evaluation metric based on our framework. Empirically, we achieve state-of-the-art results on three datasets using the two proposed algorithms.},
	language = {en},
	author = {Adel, Tameem and Ghahramani, Zoubin and Weller, Adrian},
	keywords = {fatml, interpretable, xai},
	pages = {10},
}

@inproceedings{BiasBiosCaseStudy,
	address = {Atlanta, GA, USA},
	title = {Bias in {Bios}: {A} {Case} {Study} of {Semantic} {Representation} {Bias} in a {High}-{Stakes} {Setting}},
	isbn = {978-1-4503-6125-5},
	shorttitle = {Bias in {Bios}},
	url = {http://dl.acm.org/citation.cfm?doid=3287560.3287572},
	doi = {10.1145/3287560.3287572},
	abstract = {We present a large-scale study of gender bias in occupation classification, a task where the use of machine learning may lead to negative outcomes on peoples’ lives. We analyze the potential allocation harms that can result from semantic representation bias. To do so, we study the impact on occupation classification of including explicit gender indicators—such as first names and pronouns—in different semantic representations of online biographies. Additionally, we quantify the bias that remains when these indicators are “scrubbed,” and describe proxy behavior that occurs in the absence of explicit gender indicators. As we demonstrate, differences in true positive rates between genders are correlated with existing gender imbalances in occupations, which may compound these imbalances.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}  - {FAT}* '19},
	publisher = {ACM Press},
	author = {De-Arteaga, Maria and Romanov, Alexey and Wallach, Hanna and Chayes, Jennifer and Borgs, Christian and Chouldechova, Alexandra and Geyik, Sahin and Kenthapadi, Krishnaram and Kalai, Adam Tauman},
	year = {2019},
	keywords = {fair, fatml},
	pages = {120--128},
}

@article{SurveyInterpretabilityExplainabilityHumanAgent,
	title = {A {Survey} of {Interpretability} and {Explainability} in {Human}-{Agent} {Systems}},
	abstract = {This paper presents a taxonomy of interpretability in Human-Agent Systems. We consider four fundamental questions, “Why, what, when, and how” about interpretability. First, we consider why interpretability is needed in the system. Second, once interpretability is established as being needed, we consider what explanations can be generated to meet this need. Third, we consider when the user should be presented this information. Fourth, we consider the level of detail needed within explanations. Last, we consider how objective and subjective measures can be used to evaluate the entire system including the four fundamental questions regarding interpretability.},
	language = {en},
	author = {Richardson, Ariella and Rosenfeld, Avi},
	keywords = {fatml, iml, key, survey, xai},
	pages = {7},
}

@article{PeekingBlackBoxSurveyExplainable,
	title = {Peeking {Inside} the {Black}-{Box}: {A} {Survey} on {Explainable} {Artificial} {Intelligence} ({XAI})},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {Peeking {Inside} the {Black}-{Box}},
	url = {https://ieeexplore.ieee.org/document/8466590/},
	doi = {10.1109/ACCESS.2018.2870052},
	abstract = {At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artiﬁcial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research ﬁeld holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.},
	language = {en},
	urldate = {2019-03-07},
	journal = {IEEE Access},
	author = {Adadi, Amina and Berrada, Mohammed},
	year = {2018},
	keywords = {explainable, fatml, key, survey, xai},
	pages = {52138--52160},
}

@article{CaseProcessFairnessLearning,
	title = {The {Case} for {Process} {Fairness} in {Learning}: {Feature} {Selection} for {Fair} {Decision} {Making}},
	abstract = {Machine learning methods are increasingly being used to inform, or sometimes even directly to make, important decisions about humans. A number of recent works have focussed on the fairness of the outcomes of such decisions, particularly on avoiding decisions that affect users of different sensitive groups (e.g., race, gender) disparately. In this paper, we propose to consider the fairness of the process of decision making. Process fairness can be measured by estimating the degree to which people consider various features to be fair to use when making an important legal decision. We examine the task of predicting whether or not a prisoner is likely to commit a crime again once released by analyzing the dataset considered by ProPublica relating to the COMPAS system. We introduce new measures of people’s discomfort with using various features, show how these measures can be estimated, and consider the effect of removing the uncomfortable features on prediction accuracy and on outcome fairness. Our empirical analysis suggests that process fairness may be achieved with little cost to outcome fairness, but that some loss of accuracy is unavoidable.},
	language = {en},
	author = {Grgic-Hlacˇa, Nina and Zafar, Muhammad Bilal and Gummadi, Krishna P and Weller, Adrian},
	keywords = {fatml},
	pages = {11},
}

@inproceedings{FairnessAwareTensorBasedRecommendation,
	address = {Torino, Italy},
	title = {Fairness-{Aware} {Tensor}-{Based} {Recommendation}},
	isbn = {978-1-4503-6014-2},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3271795},
	doi = {10.1145/3269206.3271795},
	abstract = {Tensor-based methods have shown promise in improving upon traditional matrix factorization methods for recommender systems. But tensors may achieve improved recommendation quality while worsening the fairness of the recommendations. Hence, we propose a novel fairness-aware tensor recommendation framework that is designed to maintain quality while dramatically improving fairness. Four key aspects of the proposed framework are: (i) a new sensitive latent factor matrix for isolating sensitive features; (ii) a sensitive information regularizer that extracts sensitive information which can taint other latent factors; (iii) an effective algorithm to solve the proposed optimization model; and (iv) extension to multi-feature and multi-category cases which previous efforts have not addressed. Extensive experiments on real-world and synthetic datasets show that the framework enhances recommendation fairness while preserving recommendation quality in comparison with state-of-the-art alternatives.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Zhu, Ziwei and Hu, Xia and Caverlee, James},
	year = {2018},
	keywords = {fair, fatml, interpretable},
	pages = {1153--1162},
}

@article{InteractiveMachineLearningHealth,
	title = {Interactive machine learning for health informatics: when do we need the human-in-the-loop?},
	volume = {3},
	issn = {2198-4018, 2198-4026},
	shorttitle = {Interactive machine learning for health informatics},
	url = {http://link.springer.com/10.1007/s40708-016-0042-6},
	doi = {10.1007/s40708-016-0042-6},
	language = {en},
	number = {2},
	urldate = {2019-03-07},
	journal = {Brain Informatics},
	author = {Holzinger, Andreas},
	month = jun,
	year = {2016},
	keywords = {fatml, iml, xai},
	pages = {119--131},
}

@article{BETTERUNDERSTANDINGGRADIENTBASEDATTRIBUTION,
	title = {{TOWARDS} {BETTER} {UNDERSTANDING} {OF} {GRADIENT}-{BASED} {ATTRIBUTION} {METHODS} {FOR} {DEEP} {NEURAL} {NETWORKS}},
	abstract = {Understanding the ﬂow of information in Deep Neural Networks (DNNs) is a challenging problem that has gain increasing attention over the last few years. While several methods have been proposed to explain network predictions, there have been only a few attempts to compare them from a theoretical perspective. What is more, no exhaustive empirical comparison has been performed in the past. In this work, we analyze four gradient-based attribution methods and formally prove conditions of equivalence and approximation between them. By reformulating two of these methods, we construct a uniﬁed framework which enables a direct comparison, as well as an easier implementation. Finally, we propose a novel evaluation metric, called Sensitivity-n and test the gradient-based attribution methods alongside with a simple perturbation-based attribution method on several datasets in the domains of image and text classiﬁcation, using various network architectures.},
	language = {en},
	author = {Ancona, Marco and Öztireli, Cengiz and Ceolini, Enea and Gross, Markus},
	year = {2018},
	keywords = {fatml, vis, xai},
	pages = {16},
}

@inproceedings{EmpiricalStudyRichSubgroup,
	address = {Atlanta, GA, USA},
	title = {An {Empirical} {Study} of {Rich} {Subgroup} {Fairness} for {Machine} {Learning}},
	isbn = {978-1-4503-6125-5},
	url = {http://dl.acm.org/citation.cfm?doid=3287560.3287592},
	doi = {10.1145/3287560.3287592},
	abstract = {Kearns, Neel, Roth, and Wu [ICML 2018] recently proposed a notion of rich subgroup fairness intended to bridge the gap between statistical and individual notions of fairness. Rich subgroup fairness picks a statistical fairness constraint (say, equalizing false positive rates across protected groups), but then asks that this constraint hold over an exponentially or infinitely large collection of subgroups defined by a class of functions with bounded VC dimension. They give an algorithm guaranteed to learn subject to this constraint, under the condition that it has access to oracles for perfectly learning absent a fairness constraint. In this paper, we undertake an extensive empirical evaluation of the algorithm of Kearns et al. On four real datasets for which fairness is a concern, we investigate the basic convergence of the algorithm when instantiated with fast heuristics in place of learning oracles, measure the tradeoffs between fairness and accuracy, and compare this approach with the recent algorithm of Agarwal, Beygelzeimer, Dudik, Langford, and Wallach [ICML 2018], which implements weaker and more traditional marginal fairness constraints defined by individual protected attributes. We find that in general, the Kearns et al. algorithm converges quickly, large gains in fairness can be obtained with mild costs to accuracy, and that optimizing accuracy subject only to marginal fairness leads to classifiers with substantial subgroup unfairness. We also provide a number of analyses and visualizations of the dynamics and behavior of the Kearns et al. algorithm. Overall we find this algorithm to be effective on real data, and rich subgroup fairness to be a viable notion in practice.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}  - {FAT}* '19},
	publisher = {ACM Press},
	author = {Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},
	year = {2019},
	keywords = {fair, fatml},
	pages = {100--109},
}

@article{GroupFairnessAllocationIndivisible,
	title = {Group {Fairness} for the {Allocation} of {Indivisible} {Goods}},
	abstract = {We consider the problem of fairly dividing a collection of indivisible goods among a set of players. Much of the existing literature on fair division focuses on notions of individual fairness. For instance, envy-freeness requires that no player prefer the set of goods allocated to another player to her own allocation. We observe that an algorithm satisfying such individual fairness notions can still treat groups of players unfairly, with one group desiring the goods allocated to another. Our main contribution is a notion of group fairness, which implies most existing notions of individual fairness. Group fairness (like individual fairness) cannot be satisﬁed exactly with indivisible goods. Thus, we introduce two “up to one good” style relaxations. We show that, somewhat surprisingly, certain local optima of the Nash welfare function satisfy both relaxations and can be computed in pseudo-polynomial time by local search. Our experiments reveal faster computation and stronger fairness guarantees in practice.},
	language = {en},
	author = {Conitzer, Vincent and Freeman, Rupert and Shah, Nisarg and Vaughan, Jennifer Wortman},
	keywords = {fair, fatml},
	pages = {8},
}

@article{ExplanationsTemporalRecommendations,
	title = {Explanations for {Temporal} {Recommendations}},
	url = {http://arxiv.org/abs/1807.06161},
	abstract = {Recommendation systems are an integral part of Artiﬁcial Intelligence (AI) and have become increasingly important in the growing age of commercialization in AI. Deep learning (DL) techniques for recommendation systems (RS) provide powerful latent-feature models for effective recommendation but suffer from the major drawback of being non-interpretable. In this paper we describe a framework for explainable temporal recommendations in a DL model. We consider an LSTM based Recurrent Neural Network (RNN) architecture for recommendation and a neighbourhoodbased scheme for generating explanations in the model. We demonstrate the effectiveness of our approach through experiments on the Netﬂix dataset by jointly optimizing for both prediction accuracy and explainability.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1807.06161 [cs]},
	author = {Bharadhwaj, Homanga and Joshi, Shruti},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.06161},
	keywords = {explainable, fatml, rec, xai},
}

@article{InteractiveInterpretableMachineLearninga,
	title = {Interactive and {Interpretable} {Machine} {Learning} {Models} for {Human} {Machine} {Collaboration}},
	abstract = {I envision a system that enables successful collaborations between humans and machine learning models by harnessing the relative strength to accomplish what neither can do alone. Machine learning techniques and humans have skills that complement each other — machine learning techniques are good at computation on data at the lowest level of granularity, whereas people are better at abstracting knowledge from their experience, and transferring the knowledge across domains. The goal of this thesis is to develop a framework for human-in-the-loop machine learning that enables people to interact eﬀectively with machine learning models to make better decisions, without requiring in-depth knowledge about machine learning techniques. Many of us interact with machine learning systems everyday. Systems that mine data for product recommendations, for example, are ubiquitous. However these systems compute their output without end-user involvement, and there are typically no life or death consequences in the case the machine learning result is not acceptable to the user. In contrast, domains where decisions can have serious consequences (e.g., emergency response panning, medical decision-making), require the incorporation of human experts’ domain knowledge. These systems also must be transparent to earn experts’ trust and be adopted in their workﬂow. The challenge addressed in this thesis is that traditional machine learning systems are not designed to extract domain experts’ knowledge from natural workﬂow, or to provide pathways for the human domain expert to directly interact with the algorithm to interject their knowledge or to better understand the system output. For machine learning systems to make a real-world impact in these important domains, these systems must be able to communicate with highly skilled human experts to leverage their judgment and expertise, and share useful information or patterns from the data.},
	language = {en},
	author = {Kim, Been},
	keywords = {fatml, iml, thesis, xai},
	pages = {143},
}

@article{DiscriminationOnlineAdvertisingMultidisciplinary,
	title = {Discrimination in {Online} {Advertising} {A} {Multidisciplinary} {Inquiry}},
	abstract = {We explore ways in which discrimination may arise in the targeting of job-related advertising, noting the potential for multiple parties to contribute to its occurrence. We then examine the statutes and case law interpreting the prohibition on advertisements that indicate a preference based on protected class, and consider its application to online advertising. We focus on its interaction with Section 230 of the Communications Decency Act, which provides interactive computer services with immunity for providing access to information created by a third party. We argue that such services can lose that immunity if they target ads toward or away from protected classes without explicit instructions from advertisers to do so.},
	language = {en},
	author = {Datta, Amit and Datta, Anupam and Makagon, Jael and Mulligan, Deirdre K and Tschantz, Michael Carl},
	keywords = {fair, fatml, xai},
	pages = {15},
}

@inproceedings{FairMarketplaceCounterfactualEvaluation,
	address = {Torino, Italy},
	title = {Towards a {Fair} {Marketplace}: {Counterfactual} {Evaluation} of the trade-off between {Relevance}, {Fairness} \& {Satisfaction} in {Recommendation} {Systems}},
	isbn = {978-1-4503-6014-2},
	shorttitle = {Towards a {Fair} {Marketplace}},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3272027},
	doi = {10.1145/3269206.3272027},
	abstract = {Two-sided marketplaces are platforms that have customers not only on the demand side (e.g. users), but also on the supply side (e.g. retailer, artists). While traditional recommender systems focused specifically towards increasing consumer satisfaction by providing relevant content to consumers, two-sided marketplaces face the problem of additionally optimizing for supplier preferences, and visibility. Indeed, the suppliers would want a fair opportunity to be presented to users. Blindly optimizing for consumer relevance may have a detrimental impact on supplier fairness. Motivated by this problem, we focus on the trade-off between objectives of consumers and suppliers in the case of music streaming services, and consider the trade-off between relevance of recommendations to the consumer (i.e. user) and fairness of representation of suppliers (i.e. artists) and measure their impact on consumer satisfaction.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Mehrotra, Rishabh and McInerney, James and Bouchard, Hugues and Lalmas, Mounia and Diaz, Fernando},
	year = {2018},
	keywords = {fair, fatml},
	pages = {2243--2251},
}

@article{BalancedNeighborhoodsMultisidedFairness,
	title = {Balanced {Neighborhoods} for {Multi}-sided {Fairness} in {Recommendation}},
	abstract = {Fairness has emerged as an important category of analysis for machine learning systems in some application areas. In extending the concept of fairness to recommender systems, there is an essential tension between the goals of fairness and those of personalization. However, there are contexts in which equity across recommendation outcomes is a desirable goal. It is also the case that in some applications fairness may be a multisided concept, in which the impacts on multiple groups of individuals must be considered. In this paper, we examine two diﬀerent cases of fairness-aware recommender systems: consumer-centered and provider-centered. We explore the concept of a balanced neighborhood as a mechanism to preserve personalization in recommendation while enhancing the fairness of recommendation outcomes. We show that a modiﬁed version of the Sparse Linear Method (SLIM) can be used to improve the balance of user and item neighborhoods, with the result of achieving greater outcome fairness in real-world datasets with minimal loss in ranking performance.},
	language = {en},
	author = {Burke, Robin and Sonboli, Nasim and Ordonez-Gauger, Aldo},
	keywords = {fair, fatml},
	pages = {13},
}

@article{MindGapGenerativeApproach,
	title = {Mind the {Gap}: {A} {Generative} {Approach} to {Interpretable} {Feature} {Selection} and {Extraction}},
	abstract = {We present the Mind the Gap Model (MGM), an approach for interpretable feature extraction and selection. By placing interpretability criteria directly into the model, we allow for the model to both optimize parameters related to interpretability and to directly report a global set of distinguishable dimensions to assist with further data exploration and hypothesis generation. MGM extracts distinguishing features on real-world datasets of animal features, recipes ingredients, and disease co-occurrence. It also maintains or improves performance when compared to related approaches. We perform a user study with domain experts to show the MGM’s ability to help with dataset exploration.},
	language = {en},
	author = {Kim, Been and Shah, Julie and Doshi-Velez, Finale},
	keywords = {fatml, interpretable, xai},
	pages = {10},
}

@inproceedings{IteratedAlgorithmicBiasInteractive,
	address = {Seville, Spain},
	title = {Iterated {Algorithmic} {Bias} in the {Interactive} {Machine} {Learning} {Process} of {Information} {Filtering}:},
	isbn = {978-989-758-330-8},
	shorttitle = {Iterated {Algorithmic} {Bias} in the {Interactive} {Machine} {Learning} {Process} of {Information} {Filtering}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006938301100118},
	doi = {10.5220/0006938301100118},
	abstract = {Information Retrieval, Machine Learning, Bias, Iterative Learning.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the 10th {International} {Joint} {Conference} on {Knowledge} {Discovery}, {Knowledge} {Engineering} and {Knowledge} {Management}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Sun, Wenlong and Nasraoui, Olfa and Shafto, Patrick},
	year = {2018},
	keywords = {fatml, iml, xai},
	pages = {110--118},
}

@article{InteractiveMachineLearningExperimental,
	title = {Interactive machine learning: experimental evidence for the human in the algorithmic loop: {A} case study on {Ant} {Colony} {Optimization}},
	issn = {0924-669X, 1573-7497},
	shorttitle = {Interactive machine learning},
	url = {http://link.springer.com/10.1007/s10489-018-1361-5},
	doi = {10.1007/s10489-018-1361-5},
	abstract = {Recent advances in automatic machine learning (aML) allow solving problems without any human intervention. However, sometimes a human-in-the-loop can be beneficial in solving computationally hard problems. In this paper we provide new experimental insights on how we can improve computational intelligence by complementing it with human intelligence in an interactive machine learning approach (iML). For this purpose, we used the Ant Colony Optimization (ACO) framework, because this fosters multi-agent approaches with human agents in the loop. We propose unification between the human intelligence and interaction skills and the computational power of an artificial system. The ACO framework is used on a case study solving the Traveling Salesman Problem, because of its many practical implications, e.g. in the medical domain. We used ACO due to the fact that it is one of the best algorithms used in many applied intelligence problems. For the evaluation we used gamification, i.e. we implemented a snake-like game called Traveling Snakesman with the MAX–MIN Ant System (MMAS) in the background. We extended the MMAS–Algorithm in a way, that the human can directly interact and influence the ants. This is done by “traveling” with the snake across the graph. Each time the human travels over an ant, the current pheromone value of the edge is multiplied by 5. This manipulation has an impact on the ant’s behavior (the probability that this edge is taken by the ant increases). The results show that the humans performing one tour through the graphs have a significant impact on the shortest path found by the MMAS. Consequently, our experiment demonstrates that in our case human intelligence can positively influence machine intelligence. To the best of our knowledge this is the first study of this kind.},
	language = {en},
	urldate = {2019-03-07},
	journal = {Applied Intelligence},
	author = {Holzinger, Andreas and Plass, Markus and Kickmeier-Rust, Michael and Holzinger, Katharina and Crişan, Gloria Cerasela and Pintea, Camelia-M. and Palade, Vasile},
	month = dec,
	year = {2018},
	keywords = {fatml, iml, xai},
}

@article{CanYouVerifiThis,
	title = {Can {You} {Veriﬁ} {This}? {Studying} {Uncertainty} and {Decision}-{Making} {About} {Misinformation} using {Visual} {Analytics}},
	abstract = {We describe a novel study of decision-making processes around misinformation on social media. Using a custom-built visual analytic system, we presented users with news content from social media accounts from a variety of news outlets, including outlets engaged in distributing misinformation. We conducted controlled experiments to study decision-making regarding the veracity of these news outlets and tested the role of conﬁrmation bias (the tendency to ignore contradicting information) and uncertainty of information on human decision-making processes. Our ﬁndings reveal that the presence of conﬂicting information, presented to users in the form of cues, impacts the ability to judge the veracity of news in systematic ways. We also ﬁnd that even instructing participants to explicitly disconﬁrm given hypotheses does not signiﬁcantly impact their decision-making regarding misinformation when compared to a control condition. Our ﬁndings have the potential to inform the design of visual analytics systems so that they may be used to mitigate the effects of cognitive biases and stymie the spread of misinformation on social media.},
	language = {en},
	author = {Karduni, Alireza and Wesslen, Ryan and Santhanam, Sashank and Cho, Isaac and Volkova, Svitlana and Arendt, Dustin and Shaikh, Samira and Dou, Wenwen},
	keywords = {fatml, uncertainty, vis, xai},
	pages = {10},
}

@article{MethodsInterpretingUnderstandingDeep,
	title = {Methods for interpreting and understanding deep neural networks},
	volume = {73},
	issn = {10512004},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1051200417302385},
	doi = {10.1016/j.dsp.2017.10.011},
	abstract = {This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. As a tutorial paper, the set of methods covered here is not exhaustive, but suﬃciently representative to discuss a number of questions in interpretability, technical challenges, and possible applications. The second part of the tutorial focuses on the recently proposed layer-wise relevance propagation (LRP) technique, for which we provide theory, recommendations, and tricks, to make most eﬃcient use of it on real data.},
	language = {en},
	urldate = {2019-03-07},
	journal = {Digital Signal Processing},
	author = {Montavon, Grégoire and Samek, Wojciech and Müller, Klaus-Robert},
	month = feb,
	year = {2018},
	keywords = {explainable, fatml},
	pages = {1--15},
}

@article{ExamplesAreNotEnough,
	title = {Examples are not {Enough}, {Learn} to {Criticize}! {Criticism} for {Interpretability}},
	abstract = {Example-based explanations are widely used in the effort to improve the interpretability of highly complex distributions. However, prototypes alone are rarely sufﬁcient to represent the gist of the complexity. In order for users to construct better mental models and understand complex data distributions, we also need criticism to explain what are not captured by prototypes. Motivated by the Bayesian model criticism framework, we develop MMD-critic which efﬁciently learns prototypes and criticism, designed to aid human interpretability. A human subject pilot study shows that the MMD-critic selects prototypes and criticism that are useful to facilitate human understanding and reasoning. We also evaluate the prototypes selected by MMD-critic via a nearest prototype classiﬁer, showing competitive performance compared to baselines.},
	language = {en},
	author = {Kim, Been and Khanna, Rajiv and Koyejo, Oluwasanmi},
	keywords = {explainable, fatml, interpretable, key, xai},
	pages = {11},
}

@article{InterpretableWhomRolebasedModela,
	title = {Interpretable to {Whom}? {A} {Role}-based {Model} for {Analyzing} {Interpretable} {Machine} {Learning} {Systems}},
	abstract = {Several researchers have argued that a machine learning system’s interpretability should be deﬁned in relation to a speciﬁc agent or task: we should not ask if the system is interpretable, but to whom is it interpretable. We describe a model intended to help answer this question, by identifying different roles that agents can fulﬁll in relation to the machine learning system. We illustrate the use of our model in a variety of scenarios, exploring how an agent’s role inﬂuences its goals, and the implications for deﬁning interpretability. Finally, we make suggestions for how our model could be useful to interpretability researchers, system developers, and regulatory bodies auditing machine learning systems.},
	language = {en},
	author = {Tomsett, Richard and Braines, Dave and Harborne, Dan and Preece, Alun and Chakraborty, Supriyo},
	keywords = {fatml, interpretable, xai},
	pages = {7},
}

@article{InterpretableClassificationModelsRecidivism,
	title = {Interpretable {Classification} {Models} for {Recidivism} {Prediction}},
	volume = {180},
	issn = {09641998},
	url = {http://arxiv.org/abs/1503.07810},
	doi = {10.1111/rssa.12227},
	abstract = {We investigate a long-debated question, which is how to create predictive models of recidivism that are sufﬁciently accurate, transparent, and interpretable to use for decision-making. This question is complicated as these models are used to support different decisions, from sentencing, to determining release on probation, to allocating preventative social services. Each case might have an objective other than classiﬁcation accuracy, such as a desired true positive rate (TPR) or false positive rate (FPR). Each (TPR, FPR) pair is a point on the receiver operator characteristic (ROC) curve. We use popular machine learning methods to create models along the full ROC curve on a wide range of recidivism prediction problems. We show that many methods (SVM, SGB, Ridge Regression) produce equally accurate models along the full ROC curve. However, methods that designed for interpretability (CART, C5.0) cannot be tuned to produce models that are accurate and/or interpretable. To handle this shortcoming, we use a recent method called Supersparse Linear Integer Models (SLIM) to produce accurate, transparent, and interpretable scoring systems along the full ROC curve. These scoring systems can be used for decision-making for many different use cases, since they are just as accurate as the most powerful black-box machine learning models for many applications, but completely transparent, and highly interpretable.},
	language = {en},
	number = {3},
	urldate = {2019-03-07},
	journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
	author = {Zeng, Jiaming and Ustun, Berk and Rudin, Cynthia},
	month = jun,
	year = {2017},
	note = {arXiv: 1503.07810},
	keywords = {fatml, interpretable, xai},
	pages = {689--722},
}

@article{ImprovingFairnessMachineLearning,
	title = {Improving fairness in machine learning systems: {What} do industry practitioners need?},
	shorttitle = {Improving fairness in machine learning systems},
	url = {http://arxiv.org/abs/1812.05239},
	doi = {10.1145/3290605.3300830},
	abstract = {The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of realworld needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams’ challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners’ needs.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1812.05239 [cs]},
	author = {Holstein, Kenneth and Vaughan, Jennifer Wortman and Daumé III, Hal and Dudík, Miro and Wallach, Hanna},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.05239},
	keywords = {fatml},
}

@article{LearningCertifiablyOptimalRule,
	title = {Learning {Certifiably} {Optimal} {Rule} {Lists} for {Categorical} {Data}},
	url = {http://arxiv.org/abs/1704.01701},
	abstract = {We present the design and implementation of a custom discrete optimization technique for building rule lists over a categorical feature space. Our algorithm produces rule lists with optimal training performance, according to the regularized empirical risk, with a certiﬁcate of optimality. By leveraging algorithmic bounds, eﬃcient data structures, and computational reuse, we achieve several orders of magnitude speedup in time and a massive reduction of memory consumption. We demonstrate that our approach produces optimal rule lists on practical problems in seconds. Our results indicate that it is possible to construct optimal sparse rule lists that are approximately as accurate as the COMPAS proprietary risk prediction tool on data from Broward County, Florida, but that are completely interpretable. This framework is a novel alternative to CART and other decision tree methods for interpretable modeling.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1704.01701 [cs, stat]},
	author = {Angelino, Elaine and Larus-Stone, Nicholas and Alabi, Daniel and Seltzer, Margo and Rudin, Cynthia},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.01701},
	keywords = {fatml, interpretable, xai},
}

@article{InstanceLevelExplanationsFraudDetection,
	title = {Instance-{Level} {Explanations} for {Fraud} {Detection}: {A} {Case} {Study}},
	shorttitle = {Instance-{Level} {Explanations} for {Fraud} {Detection}},
	url = {http://arxiv.org/abs/1806.07129},
	abstract = {Fraud detection is a difﬁcult problem that can beneﬁt from predictive modeling. However, the veriﬁcation of a prediction is challenging; for a single insurance policy, the model only provides a prediction score. We present a case study where we reﬂect on different instance-level model explanation techniques to aid a fraud detection team in their work. To this end, we designed two novel dashboards combining various state-of-the-art explanation techniques. These enable the domain expert to analyze and understand predictions, dramatically speeding up the process of ﬁltering potential fraud cases. Finally, we discuss the lessons learned and outline open research issues.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1806.07129 [cs, stat]},
	author = {Collaris, Dennis and Vink, Leo M. and van Wijk, Jarke J.},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.07129},
	keywords = {explainable, fatml, xai},
}

@inproceedings{ImpactsTrustHealthcareAI,
	address = {New Orleans, LA, USA},
	title = {Impacts on {Trust} of {Healthcare} {AI}},
	isbn = {978-1-4503-6012-8},
	url = {http://dl.acm.org/citation.cfm?doid=3278721.3278771},
	doi = {10.1145/3278721.3278771},
	abstract = {Artificial Intelligence and robotics are rapidly moving into healthcare, playing key roles in specific medical functions, including diagnosis and clinical treatment. Much of the focus in the technology development has been on human-machine interactions, leading to a host of related technology-centric questions. In this paper, we focus instead on the impact of these technologies on human-human interactions and relationships within the healthcare domain. In particular, we argue that trust plays a central role for relationships in the healthcare domain, and the introduction of healthcare AI can potentially have significant impacts on those relations of trust. We contend that healthcare AI systems ought to be treated as assistive technologies that go beyond the usual functions of medical devices. As a result, we need to rethink regulation of healthcare AI systems to ensure they advance relevant values. We propose three distinct guidelines that can be universalized across federal regulatory boards to ensure that patient-doctor trust is not detrimentally affected by the deployment and widespread adoption of healthcare AI technologies.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the 2018 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}  - {AIES} '18},
	publisher = {ACM Press},
	author = {LaRosa, Emily and Danks, David},
	year = {2018},
	keywords = {fatml, health, xai},
	pages = {210--215},
}

@inproceedings{MeasuringBiasesThatMatter,
	address = {Atlanta, GA, USA},
	title = {Measuring the {Biases} that {Matter}: {The} {Ethical} and {Casual} {Foundations} for {Measures} of {Fairness} in {Algorithms}},
	isbn = {978-1-4503-6125-5},
	shorttitle = {Measuring the {Biases} that {Matter}},
	url = {http://dl.acm.org/citation.cfm?doid=3287560.3287573},
	doi = {10.1145/3287560.3287573},
	abstract = {Measures of algorithmic bias can be roughly classified into four categories, distinguished by the conditional probabilistic dependencies to which they are sensitive. First, measures of “procedural bias” diagnose bias when the score returned by an algorithm is probabilistically dependent on a sensitive class variable (e.g. race or sex). Second, measures of “outcome bias” capture probabilistic dependence between class variables and the outcome for each subject (e.g. parole granted or loan denied). Third, measures of “behavior-relative error bias” capture probabilistic dependence between class variables and the algorithmic score, conditional on target behaviors (e.g. recidivism or loan default). Fourth, measures of “score-relative error bias” capture probabilistic dependence between class variables and behavior, conditional on score. Several recent discussions have demonstrated a tradeoff between these different measures of algorithmic bias, and at least one recent paper has suggested conditions under which tradeoffs may be minimized.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}  - {FAT}* '19},
	publisher = {ACM Press},
	author = {Glymour, Bruce and Herington, Jonathan},
	year = {2019},
	keywords = {fair, fatml},
	pages = {269--278},
}

@inproceedings{AnalyzingBiasesPerceptionTruth,
	address = {Atlanta, GA, USA},
	title = {Analyzing {Biases} in {Perception} of {Truth} in {News} {Stories} and {Their} {Implications} for {Fact} {Checking}},
	isbn = {978-1-4503-6125-5},
	url = {http://dl.acm.org/citation.cfm?doid=3287560.3287581},
	doi = {10.1145/3287560.3287581},
	abstract = {Recently, social media sites like Facebook and Twitter have been severely criticized by policy makers, and media watchdog groups for allowing fake news stories to spread unchecked on their platforms.In response, these sites are encouraging their users to report any news story they encounter on the site, which they perceive as fake.Stories that are reported as fake by a large number of users are prioritized for fact checking by (human) experts at fact checking organizations like Snopes and PolitiFact. Thus, social media sites today are relying on their users’ perceptions of the truthfulness of news stories to select stories to fact check.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}  - {FAT}* '19},
	publisher = {ACM Press},
	author = {Babaei, Mahmoudreza and Chakraborty, Abhijnan and Kulshrestha, Juhi and Redmiles, Elissa M. and Cha, Meeyoung and Gummadi, Krishna P.},
	year = {2019},
	keywords = {fair, fatml, xai},
	pages = {139--139},
}

@inproceedings{RacialCategoriesMachineLearning,
	address = {Atlanta, GA, USA},
	title = {Racial categories in machine learning},
	isbn = {978-1-4503-6125-5},
	url = {http://dl.acm.org/citation.cfm?doid=3287560.3287575},
	doi = {10.1145/3287560.3287575},
	abstract = {Controversies around race and machine learning have sparked debate among computer scientists over how to design machine learning systems that guarantee fairness. These debates rarely engage with how racial identity is embedded in our social experience, making for sociological and psychological complexity. This complexity challenges the paradigm of considering fairness to be a formal property of supervised learning with respect to protected personal attributes. Racial identity is not simply a personal subjective quality. For people labeled “Black” it is an ascribed political category that has consequences for social differentiation embedded in systemic patterns of social inequality achieved through both social and spatial segregation. In the United States, racial classification can best be understood as a system of inherently unequal status categories that places whites as the most privileged category while signifying the Negro/black category as stigmatized. Social stigma is reinforced through the unequal distribution of societal rewards and goods along racial lines that is reinforced by state, corporate, and civic institutions and practices. This creates a dilemma for society and designers: be blind to racial group disparities and thereby reify racialized social inequality by no longer measuring systemic inequality, or be conscious of racial categories in a way that itself reifies race. We propose a third option. By preceding group fairness interventions with unsupervised learning to dynamically detect patterns of segregation, machine learning systems can mitigate the root cause of social disparities, social segregation and stratification, without further anchoring status categories of disadvantage.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}  - {FAT}* '19},
	publisher = {ACM Press},
	author = {Benthall, Sebastian and Haynes, Bruce D.},
	year = {2019},
	keywords = {fair, fatml},
	pages = {289--298},
}

@inproceedings{ExplainingExplanationsAI,
	address = {Atlanta, GA, USA},
	title = {Explaining {Explanations} in {AI}},
	isbn = {978-1-4503-6125-5},
	url = {http://dl.acm.org/citation.cfm?doid=3287560.3287574},
	doi = {10.1145/3287560.3287574},
	abstract = {Recent work on interpretability in machine learning and AI has focused on the building of simplified models that approximate the true criteria used to make decisions. These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break. However, when considering any such model it’s important to remember Box’s maxim that "All models are wrong but some are useful." We focus on the distinction between these models and explanations in philosophy and sociology. These models can be understood as a "do it yourself kit" for explanations, allowing a practitioner to directly answer "what if questions" or generate contrastive explanations without external assistance. Although a valuable ability, giving these models as explanations appears more difficult than necessary, and other forms of explanation may not have the same trade-offs. We contrast the different schools of thought on what makes an explanation, and suggest that machine learning might benefit from viewing the problem more broadly.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}  - {FAT}* '19},
	publisher = {ACM Press},
	author = {Mittelstadt, Brent and Russell, Chris and Wachter, Sandra},
	year = {2019},
	keywords = {explainable, fatml, key, xai},
	pages = {279--288},
}

@inproceedings{FairnessAwareGroupRecommendationParetoEfficiency,
	address = {Como, Italy},
	title = {Fairness-{Aware} {Group} {Recommendation} with {Pareto}-{Efficiency}},
	isbn = {978-1-4503-4652-8},
	url = {http://dl.acm.org/citation.cfm?doid=3109859.3109887},
	doi = {10.1145/3109859.3109887},
	abstract = {Group recommendation has attracted signiﬁcant research efforts for its importance in beneﬁting a group of users. This paper investigates the Group Recommendation problem from a novel aspect, which tries to maximize the satisfaction of each group member while minimizing the unfairness between them. In this work, we present several semantics of the individual utility and propose two concepts of social welfare and fairness for modeling the overall utilities and the balance between group members. We formulate the problem as a multiple objective optimization problem and show that it is NPHard in diﬀerent semantics. Given the multiple-objective nature of fairness-aware group recommendation problem, we provide an optimization framework for fairness-aware group recommendation from the perspective of Pareto Eﬃciency. We conduct extensive experiments on real-world datasets and evaluate our algorithm in terms of standard accuracy metrics. The results indicate that our algorithm achieves superior performances and considering fairness in group recommendation can enhance the recommendation accuracy.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Eleventh} {ACM} {Conference} on {Recommender} {Systems}  - {RecSys} '17},
	publisher = {ACM Press},
	author = {Xiao, Lin and Min, Zhang and Yongfeng, Zhang and Zhaoquan, Gu and Yiqun, Liu and Shaoping, Ma},
	year = {2017},
	keywords = {fair, fatml, rec},
	pages = {107--115},
}

@inproceedings{DeepLearningRecommenderSystems,
	address = {Como, Italy},
	title = {Deep {Learning} for {Recommender} {Systems}},
	isbn = {978-1-4503-4652-8},
	url = {http://dl.acm.org/citation.cfm?doid=3109859.3109933},
	doi = {10.1145/3109859.3109933},
	abstract = {Deep Learning is one of the next big things in Recommendation Systems technology. The past few years have seen the tremendous success of deep neural networks in a number of complex machine learning tasks such as computer vision, natural language processing and speech recognition. After its relatively slow uptake by the recommender systems community, deep learning for recommender systems became widely popular in 2016.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Eleventh} {ACM} {Conference} on {Recommender} {Systems}  - {RecSys} '17},
	publisher = {ACM Press},
	author = {Karatzoglou, Alexandros and Hidasi, Balázs},
	year = {2017},
	keywords = {dl, dm, fatml, rec, xai},
	pages = {396--397},
}

@inproceedings{DisparateInteractionsAlgorithmintheLoopAnalysis,
	address = {Atlanta, GA, USA},
	title = {Disparate {Interactions}: {An} {Algorithm}-in-the-{Loop} {Analysis} of {Fairness} in {Risk} {Assessments}},
	isbn = {978-1-4503-6125-5},
	shorttitle = {Disparate {Interactions}},
	url = {http://dl.acm.org/citation.cfm?doid=3287560.3287563},
	doi = {10.1145/3287560.3287563},
	abstract = {Despite vigorous debates about the technical characteristics of risk assessments being deployed in the U.S. criminal justice system, remarkably little research has studied how these tools a�ect actual decision-making processes. After all, risk assessments do not make de�nitive decisions—they inform judges, who are the �nal arbiters. It is therefore essential that considerations of risk assessments be informed by rigorous studies of how judges actually interpret and use them. This paper takes a �rst step toward such research on human interactions with risk assessments through a controlled experimental study on Amazon Mechanical Turk. We found several behaviors that call into question the supposed e�cacy and fairness of risk assessments: our study participants 1) underperformed the risk assessment even when presented with its predictions, 2) could not e�ectively evaluate the accuracy of their own or the risk assessment’s predictions, and 3) exhibited behaviors fraught with “disparate interactions,” whereby the use of risk assessments led to higher risk predictions about black defendants and lower risk predictions about white defendants. These results suggest the need for a new “algorithm-in-the-loop” framework that places machine learning decision-making aids into the sociotechnical context of improving human decisions rather than the technical context of generating the best prediction in the abstract. If risk assessments are to be used at all, they must be grounded in rigorous evaluations of their real-world impacts instead of in their theoretical potential.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}  - {FAT}* '19},
	publisher = {ACM Press},
	author = {Green, Ben and Chen, Yiling},
	year = {2019},
	keywords = {fair, fatml, iml},
	pages = {90--99},
}

@article{RobustnessInterpretabilityMethods,
	title = {On the {Robustness} of {Interpretability} {Methods}},
	url = {http://arxiv.org/abs/1806.08049},
	abstract = {We argue that robustness of explanations---i.e., that similar inputs should give rise to similar explanations---is a key desideratum for interpretability. We introduce metrics to quantify robustness and demonstrate that current methods do not perform well according to these metrics. Finally, we propose ways that robustness can be enforced on existing interpretability approaches.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1806.08049 [cs, stat]},
	author = {Alvarez-Melis, David and Jaakkola, Tommi S.},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.08049},
	keywords = {fatml, interpretable, xai},
}

@inproceedings{HumanPredictionsExplanationsPredictions,
	address = {Atlanta, GA, USA},
	title = {On {Human} {Predictions} with {Explanations} and {Predictions} of {Machine} {Learning} {Models}: {A} {Case} {Study} on {Deception} {Detection}},
	isbn = {978-1-4503-6125-5},
	shorttitle = {On {Human} {Predictions} with {Explanations} and {Predictions} of {Machine} {Learning} {Models}},
	url = {http://dl.acm.org/citation.cfm?doid=3287560.3287590},
	doi = {10.1145/3287560.3287590},
	abstract = {Humans are the final decision makers in critical tasks that involve ethical and legal concerns, ranging from recidivism prediction, to medical diagnosis, to fighting against fake news. Although machine learning models can sometimes achieve impressive performance in these tasks, these tasks are not amenable to full automation. To realize the potential of machine learning for improving human decisions, it is important to understand how assistance from machine learning models affects human performance and human agency. In this paper, we use deception detection as a testbed and investigate how we can harness explanations and predictions of machine learning models to improve human performance while retaining human agency. We propose a spectrum between full human agency and full automation, and develop varying levels of machine assistance along the spectrum that gradually increase the influence of machine predictions. We find that without showing predicted labels, explanations alone slightly improve human performance in the end task. In comparison, human performance is greatly improved by showing predicted labels ({\textgreater}20\% relative improvement) and can be further improved by explicitly suggesting strong machine performance. Interestingly, when predicted labels are shown, explanations of machine predictions induce a similar level of accuracy as an explicit statement of strong machine performance. Our results demonstrate a tradeoff between human performance and human agency and show that explanations of machine predictions can moderate this tradeoff.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}  - {FAT}* '19},
	publisher = {ACM Press},
	author = {Lai, Vivian and Tan, Chenhao},
	year = {2019},
	keywords = {fatml, iml, xai},
	pages = {29--38},
}

@article{OptimizedScoringSystemsTrust,
	title = {Optimized {Scoring} {Systems}: {Toward} {Trust} in {Machine} {Learning} for {Healthcare} and {Criminal} {Justice}},
	volume = {48},
	issn = {0092-2102, 1526-551X},
	shorttitle = {Optimized {Scoring} {Systems}},
	url = {http://pubsonline.informs.org/doi/10.1287/inte.2018.0957},
	doi = {10.1287/inte.2018.0957},
	language = {en},
	number = {5},
	urldate = {2019-03-07},
	journal = {Interfaces},
	author = {Rudin, Cynthia and Ustun, Berk},
	month = oct,
	year = {2018},
	keywords = {fair, fatml, xai},
	pages = {449--466},
}

@inproceedings{InterpretationRecommenderSystemsSorted,
	address = {Singapore},
	title = {Towards {Interpretation} of {Recommender} {Systems} with {Sorted} {Explanation} {Paths}},
	isbn = {978-1-5386-9159-5},
	url = {https://ieeexplore.ieee.org/document/8594891/},
	doi = {10.1109/ICDM.2018.00082},
	abstract = {Despite the wide application in recent years, most recommender systems are not capable of providing interpretations together with recommendation results, which impedes both deployers and customers from understanding or trusting the results. Recent advances in recommendation models, such as deep learning models, usually involve extracting latent representations of users and items. However, the representation space is not directly comprehensible since each dimension usually does not have any speciﬁc meaning. In addition, recommender systems incorporate various sources of information, such as user behaviors, item information, and other side content information. Properly organizing different types of information, as well as effectively selecting important information for interpretation, is challenging and has not been fully tackled by conventional interpretation methods. In this paper, we propose a post-hoc method called Sorted Explanation Paths (SEP) to interpret recommendation results. Speciﬁcally, we ﬁrst build a uniﬁed heterogeneous information network to incorporate multiple types of objects and relations based on representations from the recommender system and information from the dataset. Then, we search for explanation paths between given recommendation pairs, and use the set of simple paths to construct semantic explanations. Next, three heuristic metrics, i.e., credibility, readability and diversity, are designed to measure the validity of each explanation path, and to sort all the paths comprehensively. The top-ranked explanation paths are selected as the ﬁnal interpretation. After that, practical issues on computation and efﬁciency of the proposed SEP method are also handled by corresponding approaches. Finally, we conduct experiments on three real-world benchmark datasets, and demonstrate the applicability and effectiveness of the proposed SEP method.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {2018 {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Yang, Fan and Liu, Ninghao and Wang, Suhang and Hu, Xia},
	month = nov,
	year = {2018},
	keywords = {fatml, interpretable, key, rec, xai},
	pages = {667--676},
}

@inproceedings{EqualityVoiceFairRepresentation,
	address = {Atlanta, GA, USA},
	title = {Equality of {Voice}: {Towards} {Fair} {Representation} in {Crowdsourced} {Top}-{K} {Recommendations}},
	isbn = {978-1-4503-6125-5},
	shorttitle = {Equality of {Voice}},
	url = {http://dl.acm.org/citation.cfm?doid=3287560.3287570},
	doi = {10.1145/3287560.3287570},
	abstract = {To help their users to discover important items at a particular time, major websites like Twitter, Yelp, TripAdvisor or NYTimes provide Top-K recommendations (e.g., 10 Trending Topics, Top 5 Hotels in Paris or 10 Most Viewed News Stories), which rely on crowdsourced popularity signals to select the items. However, diferent sections of a crowd may have diferent preferences, and there is a large silent majority who do not explicitly express their opinion. Also, the crowd often consists of actors like bots, spammers, or people running orchestrated campaigns. Recommendation algorithms today largely do not consider such nuances, hence are vulnerable to strategic manipulation by small but hyper-active user groups.},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}  - {FAT}* '19},
	publisher = {ACM Press},
	author = {Chakraborty, Abhijnan and Patro, Gourab K. and Ganguly, Niloy and Gummadi, Krishna P. and Loiseau, Patrick},
	year = {2019},
	keywords = {fatml, ranking, rec},
	pages = {129--138},
}

@article{TechniquesInterpretableMachineLearninga,
	title = {Techniques for {Interpretable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1808.00033},
	abstract = {Interpretable machine learning tackles the important problem that humans cannot understand the behaviors of complex machine learning models and how these models arrive at a particular decision. Although many approaches have been proposed, a comprehensive understanding of the achievements and challenges is still lacking. We provide a survey covering existing techniques to increase the interpretability of machine learning models. We also discuss crucial issues that the community should consider in future work such as designing user-friendly explanations and developing comprehensive evaluation metrics to further push forward the area of interpretable machine learning.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1808.00033 [cs, stat]},
	author = {Du, Mengnan and Liu, Ninghao and Hu, Xia},
	month = jul,
	year = {2018},
	note = {arXiv: 1808.00033},
	keywords = {fatml, interpretable, survey, xai},
}

@article{SurveyEvaluationMethodsMeasures,
	title = {A {Survey} of {Evaluation} {Methods} and {Measures} for {Interpretable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1811.11839},
	abstract = {The need for interpretable and accountable intelligent system gets sensible as artiﬁcial intelligence plays more role in human life. Explainable artiﬁcial intelligence systems can be a solution by self-explaining the reasoning behind the decisions and predictions of the intelligent system. Researchers from different disciplines work together to deﬁne, design and evaluate interpretable intelligent systems for the user. Our work supports the different evaluation goals in interpretable machine learning research by a thorough review of evaluation methodologies used in machine-explanation research across the ﬁelds of human-computer interaction, visual analytics, and machine learning. We present a 2D categorization of interpretable machine learning evaluation methods and show a mapping between user groups and evaluation measures. Further, we address the essential factors and steps for a right evaluation plan by proposing a nested model for design and evaluation of explainable artiﬁcial intelligence systems.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1811.11839 [cs]},
	author = {Mohseni, Sina and Zarei, Niloofar and Ragan, Eric D.},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.11839},
	keywords = {comps-dm, fatml, interpretable, key, survey, xai},
}

@article{EnslavingAlgorithmRightExplanation,
	title = {Enslaving the {Algorithm}: {From} a “{Right} to an {Explanation}” to a “{Right} to {Better} {Decisions}”?},
	volume = {16},
	issn = {1540-7993, 1558-4046},
	shorttitle = {Enslaving the {Algorithm}},
	url = {https://ieeexplore.ieee.org/document/8395080/},
	doi = {10.1109/MSP.2018.2701152},
	language = {en},
	number = {3},
	urldate = {2019-03-07},
	journal = {IEEE Security \& Privacy},
	author = {Edwards, Lilian and Veale, Michael},
	month = may,
	year = {2018},
	keywords = {fatml, xai},
	pages = {46--54},
}

@article{DoctorJustWonAccept,
	title = {The {Doctor} {Just} {Won}'t {Accept} {That}!},
	url = {http://arxiv.org/abs/1711.08037},
	abstract = {Calls to arms to build interpretable models express a well-founded discomfort with machine learning. Should a software agent that does not even know what a loan is decide who qualifies for one? Indeed, we ought to be cautious about injecting machine learning (or anything else, for that matter) into applications where there may be a significant risk of causing social harm. However, claims that stakeholders "just won't accept that!" do not provide a sufficient foundation for a proposed field of study. For the field of interpretable machine learning to advance, we must ask the following questions: What precisely won't various stakeholders accept? What do they want? Are these desiderata reasonable? Are they feasible? In order to answer these questions, we'll have to give real-world problems and their respective stakeholders greater consideration.},
	language = {en},
	urldate = {2019-03-07},
	journal = {arXiv:1711.08037 [stat]},
	author = {Lipton, Zachary C.},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.08037},
	keywords = {fatml, interpretable, xai},
}

@article{InterpretableActiveLearninga,
	title = {Interpretable {Active} {Learning}∗},
	abstract = {Active learning has long been a topic of study in machine learning. However, as increasingly complex and opaque models have become standard practice, the process of active learning, too, has become more opaque. There has been little investigation into interpreting what speciﬁc trends and patterns an active learning strategy may be exploring. This work expands on the Local Interpretable Model-agnostic Explanations framework (LIME) to provide explanations for active learning recommendations. We demonstrate how LIME can be used to generate locally faithful explanations for an active learning strategy, and how these explanations can be used to understand how diﬀerent models and datasets explore a problem space over time.},
	language = {en},
	author = {Phillips, Richard L and Chang, Kyu Hyun and Friedler, Sorelle A},
	keywords = {fatml, interpretable, xai},
	pages = {13},
}

@article{INTERPRETINGDEEPCLASSIFIERSVISUAL,
	title = {{INTERPRETING} {DEEP} {CLASSIFIERS} {BY} {VISUAL} {DISTILLATION} {OF} {DARK} {KNOWLEDGE}},
	language = {en},
	author = {Schacherer, Daniela},
	keywords = {fatml, interpretable, xai},
	pages = {35},
}

@article{UnifyingRecommendationActiveLearning,
	title = {Unifying recommendation and active learning for human-algorithm interactions},
	abstract = {The enormous scale of the available information and products on the Internet has necessitated the development of algorithms that intermediate between options and human users. These algorithms do not select information at random, but attempt to provide the user with relevant information. In doing so, the algorithms may incur potential negative consequences related to, for example, “ﬁlter bubbles.” Building from existing algorithms, we introduce a parametrized model that uniﬁes and interpolates between recommending relevant information and active learning. In a concept learning paradigm, we illustrate the trade-offs of optimizing prediction and recommendation, show that there is a broad parameter region of stable performance that optimizes for both, identify a speciﬁc regime that is most robust to human variability, and identify the cause of this optimized performance. We conclude by discussing implications for the cognitive science of concept learning and the practice of machine learning in the real world.},
	language = {en},
	author = {Yang, Scott Cheng-Hsin and Nasraoui, Olfa},
	keywords = {fatml, iml, xai},
	pages = {7},
}

@incollection{HumanintheLoopEmpoweringEndUsersTransparent,
	address = {Cham},
	title = {Beyond {Human}-in-the-{Loop}: {Empowering} {End}-{Users} with {Transparent} {Machine} {Learning}},
	isbn = {978-3-319-90402-3 978-3-319-90403-0},
	shorttitle = {Beyond {Human}-in-the-{Loop}},
	url = {http://link.springer.com/10.1007/978-3-319-90403-0_3},
	abstract = {Advances in data analytics and human computation are transforming how researchers conduct science in domains like bioinformatics, computational social science, and digital humanities. However, data analytics requires signiﬁcant programming knowledge or access to technical experts, while human computation requires in-depth knowledge of crowd management and is error-prone due to lack of scientiﬁc domain expertise. The goal of this research is to empower a broader range of scientists and end-users to conduct data analytics by adopting the End-User Development (EUD) models commonly found in today’s commercial software platforms like Microsoft Excel, Wikipedia and WordPress. These EUD platforms enable people to focus on producing content rather than struggling with a development environment and new programming syntax or relying on disciplinary non-experts for essential technical help. This research explores a similar paradigm for scientists and endusers that can be thought of as End-User Data Analytics (EUDA), or Transparent Machine Learning (TML).},
	language = {en},
	urldate = {2019-03-07},
	booktitle = {Human and {Machine} {Learning}},
	publisher = {Springer International Publishing},
	author = {Shih, Patrick C.},
	editor = {Zhou, Jianlong and Chen, Fang},
	year = {2018},
	doi = {10.1007/978-3-319-90403-0_3},
	keywords = {fatml, iml, key, xai},
	pages = {37--54},
}

@article{ReviewUserInterfaceDesigna,
	title = {A {Review} of {User} {Interface} {Design} for {Interactive} {Machine} {Learning}},
	volume = {8},
	issn = {21606455},
	url = {http://dl.acm.org/citation.cfm?doid=3232718.3185517},
	doi = {10.1145/3185517},
	language = {en},
	number = {2},
	urldate = {2019-03-07},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Dudley, John J. and Kristensson, Per Ola},
	month = jun,
	year = {2018},
	keywords = {fatml, iml, interactive, key, survey, xai},
	pages = {1--37},
}

@article{EmbeddingLogicalQueriesKnowledge,
	title = {Embedding {Logical} {Queries} on {Knowledge} {Graphs}},
	abstract = {Learning low-dimensional embeddings of knowledge graphs is a powerful approach used to predict unobserved or missing edges between entities. However, an open challenge in this area is developing techniques that can go beyond simple edge prediction and handle more complex logical queries, which might involve multiple unobserved edges, entities, and variables. For instance, given an incomplete biological knowledge graph, we might want to predict what drugs are likely to target proteins involved with both diseases X and Y?—a query that requires reasoning about all possible proteins that might interact with diseases X and Y. Here we introduce a framework to efﬁciently make predictions about conjunctive logical queries—a ﬂexible but tractable subset of ﬁrst-order logic—on incomplete knowledge graphs. In our approach, we embed graph nodes in a low-dimensional space and represent logical operators as learned geometric operations (e.g., translation, rotation) in this embedding space. By performing logical operations within a low-dimensional embedding space, our approach achieves a time complexity that is linear in the number of query variables, compared to the exponential complexity required by a naive enumeration-based approach. We demonstrate the utility of this framework in two application studies on real-world datasets with millions of relations: predicting logical relationships in a network of drug-gene-disease interactions and in a graph-based representation of social interactions derived from a popular web forum.},
	language = {en},
	author = {Hamilton, Will and Bajaj, Payal and Zitnik, Marinka and Jurafsky, Dan and Leskovec, Jure},
	keywords = {kg},
	pages = {12},
}

@article{NOUSConstructionQueryingDynamic,
	title = {{NOUS}: {Construction} and {Querying} of {Dynamic} {Knowledge} {Graphs}},
	shorttitle = {{NOUS}},
	url = {http://arxiv.org/abs/1606.02314},
	abstract = {The ability to construct domain speciﬁc knowledge graphs (KG) and perform question-answering or hypothesis generation is a transformative capability. Despite their value, automated construction of knowledge graphs remains an expensive technical challenge that is beyond the reach for most enterprises and academic institutions. We propose an end-to-end framework for developing custom knowledge graph driven analytics for arbitrary application domains. The uniqueness of our system lies A) in its combination of curated KGs along with knowledge extracted from unstructured text, B) support for advanced trending and explanatory questions on a dynamic KG, and C) the ability to answer queries where the answer is embedded across multiple data sources.},
	language = {en},
	urldate = {2019-03-09},
	journal = {arXiv:1606.02314 [cs]},
	author = {Choudhury, Sutanay and Agarwal, Khushbu and Purohit, Sumit and Zhang, Baichuan and Pirrung, Meg and Smith, Will and Thomas, Mathew},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.02314},
	keywords = {kg},
}

@article{SemanticRoleLabelingKnowledge,
	title = {Semantic {Role} {Labeling} for {Knowledge} {Graph} {Extraction} from {Text}},
	url = {http://arxiv.org/abs/1811.01409},
	abstract = {This paper introduces TakeFive, a new semantic role labeling method that transforms a text into a frame-oriented knowledge graph. It performs dependency parsing, identiﬁes the words that evoke lexical frames, locates the roles and ﬁllers for each frame, runs coercion techniques, and formalises the results as a knowledge graph. This formal representation complies with the frame semantics used in Framester, a factual-linguistic linked data resource. The obtained precision, recall and F1 values indicate that TakeFive is competitive with other existing methods such as SEMAFOR, Pikes, PathLSTM and FRED. We ﬁnally discuss how to combine TakeFive and FRED, obtaining higher values of precision, recall and F1.},
	language = {en},
	urldate = {2019-03-09},
	journal = {arXiv:1811.01409 [cs]},
	author = {Alam, Mehwish and Gangemi, Aldo and Presutti, Valentina and Recupero, Diego Reforgiato},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.01409},
	keywords = {kg},
}

@article{KnowledgebasedTransferLearningExplanation,
	title = {Knowledge-based {Transfer} {Learning} {Explanation}},
	url = {http://arxiv.org/abs/1807.08372},
	abstract = {Machine learning explanation can signiﬁcantly boost machine learning’s application in decision making, but the usability of current methods is limited in humancentric explanation, especially for transfer learning, an important machine learning branch that aims at utilizing knowledge from one learning domain (i.e., a pair of dataset and prediction task) to enhance prediction model training in another learning domain. In this paper, we propose an ontology-based approach for humancentric explanation of transfer learning. Three kinds of knowledge-based explanatory evidence, with different granularities, including general factors, particular narrators and core contexts are ﬁrst proposed and then inferred with both local ontologies and external knowledge bases. The evaluation with US ﬂight data and DBpedia has presented their conﬁdence and availability in explaining the transferability of feature representation in ﬂight departure delay forecasting.},
	language = {en},
	urldate = {2019-03-09},
	journal = {arXiv:1807.08372 [cs]},
	author = {Chen, Jiaoyan and Lecue, Freddy and Pan, Jeff Z. and Horrocks, Ian and Chen, Huajun},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.08372},
	keywords = {kg},
}

@article{LearningStructuredEmbeddingsKnowledge,
	title = {Learning {Structured} {Embeddings} of {Knowledge} {Bases}},
	abstract = {Many Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigid symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like natural language processing (word-sense disambiguation, natural language understanding, ...), vision (scene classiﬁcation, image semantic annotation, ...) or collaborative ﬁltering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more ﬂexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent machine learning methods for prediction and information retrieval. We illustrate our method on WordNet and Freebase and also present a way to adapt it to knowledge extraction from raw text.},
	language = {en},
	author = {Bordes, Antoine and Weston, Jason and Collobert, Ronan and Bengio, Yoshua},
	keywords = {kg},
	pages = {6},
}

@article{LearningKnowledgeBaseEmbeddingsRecommendation,
	title = {Learning over {Knowledge}-{Base} {Embeddings} for {Recommendation}},
	volume = {11},
	issn = {1999-4893},
	url = {http://arxiv.org/abs/1803.06540},
	doi = {10.3390/a11090137},
	abstract = {State-of-the-art recommendation algorithms – especially the collaborative ltering (CF) based approaches with shallow or deep models – usually work with various unstructured information sources for recommendation, such as textual reviews, visual images, and various implicit or explicit feedbacks. ough structured knowledge bases were considered in content-based approaches, they have been largely neglected recently due to the availability of vast amount of data, and the learning power of many complex models.},
	language = {en},
	number = {9},
	urldate = {2019-03-09},
	journal = {Algorithms},
	author = {Zhang, Yongfeng and Ai, Qingyao and Chen, Xu and Wang, Pengfei},
	month = sep,
	year = {2018},
	note = {arXiv: 1803.06540},
	keywords = {kg},
	pages = {137},
}

@article{LearningHeterogeneousKnowledgeBasea,
	title = {Learning {Heterogeneous} {Knowledge} {Base} {Embeddings} for {Explainable} {Recommendation}},
	volume = {11},
	issn = {1999-4893},
	url = {http://arxiv.org/abs/1805.03352},
	doi = {10.3390/a11090137},
	abstract = {Providing model-generated explanations in recommender systems is important to user experience. State-of-the-art recommendation algorithms — especially the collaborative ﬁltering (CF)-based approaches with shallow or deep models — usually work with various unstructured information sources for recommendation, such as textual reviews, visual images, and various implicit or explicit feedbacks. Though structured knowledge bases were considered in content-based approaches, they have been largely ignored recently due to the availability of vast amounts of data and the learning power of many complex models. However, structured knowledge bases exhibit unique advantages in personalized recommendation systems. When the explicit knowledge about users and items is considered for recommendation, the system could provide highly customized recommendations based on users’ historical behaviors and the knowledge is helpful for providing informed explanations regarding the recommended items. A great challenge for using knowledge bases for recommendation is how to integrate large-scale structured and unstructured data, while taking advantage of collaborative ﬁltering for highly accurate performance. Recent achievements in knowledge-base embedding (KBE) sheds light on this problem, which makes it possible to learn user and item representations while preserving the structure of their relationship with external knowledge for explanation. In this work, we propose to explain knowledge-base embeddings for explainable recommendation. Speciﬁcally, we propose a knowledge-base representation learning framework to embed heterogeneous entities for recommendation, and based on the embedded knowledge base, a soft matching algorithm is proposed to generate personalized explanations for the recommended items. Experimental results on real-world e-commerce datasets veriﬁed the superior recommendation performance and the explainability power of our approach compared with state-of-the-art baselines.},
	language = {en},
	number = {9},
	urldate = {2019-03-09},
	journal = {Algorithms},
	author = {Ai, Qingyao and Azizi, Vahid and Chen, Xu and Zhang, Yongfeng},
	month = sep,
	year = {2018},
	note = {arXiv: 1805.03352},
	keywords = {kg},
	pages = {137},
}

@incollection{LearningKnowledgeGraphEmbeddings,
	address = {Cham},
	title = {Learning {Knowledge} {Graph} {Embeddings} via {Generalized} {Hyperplanes}},
	volume = {10860},
	isbn = {978-3-319-93697-0 978-3-319-93698-7},
	url = {http://link.springer.com/10.1007/978-3-319-93698-7_48},
	abstract = {For knowledge graph completion, translation-based methods such as Trans(E and H) are promising, which embed knowledge graphs into continuous vector spaces and construct translation operation between head and tail entities. However, TransE and TransH still have limitations in preserving mapping properties of complex relation facts for knowledge graphs. In this paper, we propose a novel translation-based method called translation on generalized hyperplanes (TransGH), which extends TransH by deﬁning a generalized hyperplane for entities projection. TransGH projects head and tail embeddings from a triplet into a generalized relation-speciﬁc hyperplane determined by a set of basis vectors, and then fulﬁlls translation operation on the hyperplane. Compared with TransH, TransGH can capture more fertile interactions between entities and relations, and simultaneously has strong expression in mapping properties for knowledge graphs. Experimental results on two tasks, link prediction and triplet classiﬁcation, show that TransGH can signiﬁcantly outperform the state-of-the-art embedding methods.},
	language = {en},
	urldate = {2019-03-09},
	booktitle = {Computational {Science} – {ICCS} 2018},
	publisher = {Springer International Publishing},
	author = {Zhu, Qiannan and Zhou, Xiaofei and Tan, JianLong and Liu, Ping and Guo, Li},
	editor = {Shi, Yong and Fu, Haohuan and Tian, Yingjie and Krzhizhanovskaya, Valeria V. and Lees, Michael Harold and Dongarra, Jack and Sloot, Peter M. A.},
	year = {2018},
	doi = {10.1007/978-3-319-93698-7_48},
	keywords = {kg},
	pages = {624--638},
}

@article{ExplainableEntitybasedRecommendationsKnowledge,
	title = {Explainable {Entity}-based {Recommendations} with {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/1707.05254},
	abstract = {Explainable recommendation is an important task. Many methods have been proposed which generate explanations from the content and reviews written for items. When review text is unavailable, generating explanations is still a hard problem. In this paper, we illustrate how explanations can be generated in such a scenario by leveraging external knowledge in the form of knowledge graphs. Our method jointly ranks items and knowledge graph entities using a Personalized PageRank procedure to produce recommendations together with their explanations.},
	language = {en},
	urldate = {2019-03-09},
	journal = {arXiv:1707.05254 [cs]},
	author = {Catherine, Rose and Mazaitis, Kathryn and Eskenazi, Maxine and Cohen, William},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.05254},
	keywords = {kg},
}

@inproceedings{CollaborativeKnowledgeBaseEmbedding,
	address = {San Francisco, California, USA},
	title = {Collaborative {Knowledge} {Base} {Embedding} for {Recommender} {Systems}},
	isbn = {978-1-4503-4232-2},
	url = {http://dl.acm.org/citation.cfm?doid=2939672.2939673},
	doi = {10.1145/2939672.2939673},
	abstract = {Among different recommendation techniques, collaborative ﬁltering usually suffer from limited performance due to the sparsity of user-item interactions. To address the issues, auxiliary information is usually used to boost the performance. Due to the rapid collection of information on the web, the knowledge base provides heterogeneous information including both structured and unstructured data with different semantics, which can be consumed by various applications. In this paper, we investigate how to leverage the heterogeneous information in a knowledge base to improve the quality of recommender systems. First, by exploiting the knowledge base, we design three components to extract items’ semantic representations from structural content, textual content and visual content, respectively. To be speciﬁc, we adopt a heterogeneous network embedding method, termed as TransR, to extract items’ structural representations by considering the heterogeneity of both nodes and relationships. We apply stacked denoising auto-encoders and stacked convolutional auto-encoders, which are two types of deep learning based embedding techniques, to extract items’ textual representations and visual representations, respectively. Finally, we propose our ﬁnal integrated framework, which is termed as Collaborative Knowledge Base Embedding (CKE), to jointly learn the latent representations in collaborative ﬁltering as well as items’ semantic representations from the knowledge base. To evaluate the performance of each embedding component as well as the whole system, we conduct extensive experiments with two realworld datasets from different scenarios. The results reveal that our approaches outperform several widely adopted state-of-the-art recommendation methods.},
	language = {en},
	urldate = {2019-03-09},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} - {KDD} '16},
	publisher = {ACM Press},
	author = {Zhang, Fuzheng and Yuan, Nicholas Jing and Lian, Defu and Xie, Xing and Ma, Wei-Ying},
	year = {2016},
	keywords = {kg},
	pages = {353--362},
}

@article{KnowledgeGraphsTheoryPractice,
	title = {Knowledge {Graphs}: {In} {Theory} and {Practice}},
	language = {en},
	author = {Aggarwal, Nitish and Shekarpour, Saeedeh and Bhatia, Sumit and Sheth, Amit},
	year = {2017},
	keywords = {kg},
	pages = {5},
}

@article{SSPSemanticSpaceProjection,
	title = {{SSP}: {Semantic} {Space} {Projection} for {Knowledge} {Graph} {Embedding} with {Text} {Descriptions}},
	language = {en},
	author = {Xiao, Han and Huang, Minlie and Meng, Lian and Zhu, Xiaoyan},
	keywords = {kg},
	pages = {7},
}

@inproceedings{ShortTextEntityLinking,
	address = {Torino, Italy},
	title = {Short {Text} {Entity} {Linking} with {Fine}-grained {Topics}},
	isbn = {978-1-4503-6014-2},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3271809},
	doi = {10.1145/3269206.3271809},
	abstract = {A wide range of web corpora are in the form of short text, such as QA queries, search queries and news titles. Entity linking for these short texts is quite important. Most of supervised approaches are not effective for short text entity linking. The training data for supervised approaches are not suitable for short text and insufficient for low-resourced languages. Previous unsupervised methods are incapable of handling the sparsity and noisy problem of short text. We try to solve the problem by mapping the sparse short text to a topic space. We notice that the concepts of entities have rich topic information and characterize entities in a very fine-grained granularity. Hence, we use the concepts of entities as topics to explicitly represent the context, which helps improve the performance of entity linking for short text. We leverage our linking approach to segment the short text semantically, and build a system for short entity text recognition and linking. Our entity linking approach exhibits the state-of-the-art performance on several datasets for the realistic short text entity linking problem.},
	language = {en},
	urldate = {2019-03-09},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Chen, Lihan and Liang, Jiaqing and Xie, Chenhao and Xiao, Yanghua},
	year = {2018},
	keywords = {kg},
	pages = {457--466},
}

@inproceedings{SharedEmbeddingBasedNeural,
	address = {Torino, Italy},
	title = {Shared {Embedding} {Based} {Neural} {Networks} for {Knowledge} {Graph} {Completion}},
	isbn = {978-1-4503-6014-2},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3271704},
	doi = {10.1145/3269206.3271704},
	abstract = {Knowledge Graphs (KGs) have facilitated many real-world applications (e.g., vertical search and intelligent question answering). However, they are usually incomplete, which affects the performance of such KG based applications. To alleviate this problem, a number of Knowledge Graph Completion (KGC) methods have been developed to predict those implicit triples. Tensor/matrix based methods and translation based methods have attracted great attention for a long time. Recently, neural network has been introduced into KGC due to its extensive superiority in many fields (e.g., natural language processing and computer vision), and achieves promising results. In this paper, we propose a Shared Embedding based Neural Network (SENN) model for KGC. It integrates the prediction tasks of head entities, relations and tail entities into a neural network based framework with shared embeddings of entities and relations, while explicitly considering the differences among these prediction tasks. Moreover, we propose an adaptively weighted loss mechanism, which dynamically adjusts the weights of losses according to the mapping properties of relations, and the prediction tasks. Since relation prediction usually performs better than head and tail entity predictions, we further extend SENN to SENN+ by employing it to assist head and tail entity predictions. Experiments on benchmark datasets validate the effectiveness and merits of the proposed SENN and SENN+ methods. The shared embeddings and the adaptively weighted loss mechanism are also testified to be effective.},
	language = {en},
	urldate = {2019-03-09},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Guan, Saiping and Jin, Xiaolong and Wang, Yuanzhuo and Cheng, Xueqi},
	year = {2018},
	keywords = {kg},
	pages = {247--256},
}

@inproceedings{RippleNetPropagatingUserPreferences,
	address = {Torino, Italy},
	title = {{RippleNet}: {Propagating} {User} {Preferences} on the {Knowledge} {Graph} for {Recommender} {Systems}},
	isbn = {978-1-4503-6014-2},
	shorttitle = {{RippleNet}},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3271739},
	doi = {10.1145/3269206.3271739},
	abstract = {To address the sparsity and cold start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve recommendation performance. This paper considers the knowledge graph as the source of side information. To address the limitations of existing embeddingbased and path-based methods for knowledge-graph-aware recommendation, we propose RippleNet, an end-to-end framework that naturally incorporates the knowledge graph into recommender systems. Similar to actual ripples propagating on the water, RippleNet stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user’s potential interests along links in the knowledge graph. The multiple "ripples" activated by a user’s historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item, which could be used for predicting the final clicking probability. Through extensive experiments on real-world datasets, we demonstrate that RippleNet achieves substantial gains in a variety of scenarios, including movie, book and news recommendation, over several state-of-the-art baselines.},
	language = {en},
	urldate = {2019-03-09},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Wang, Hongwei and Zhang, Fuzheng and Wang, Jialin and Zhao, Miao and Li, Wenjie and Xie, Xing and Guo, Minyi},
	year = {2018},
	keywords = {kg},
	pages = {417--426},
}

@inproceedings{PersonalizedRecommendationsUsingKnowledge,
	address = {Boston, Massachusetts, USA},
	title = {Personalized {Recommendations} using {Knowledge} {Graphs}: {A} {Probabilistic} {Logic} {Programming} {Approach}},
	isbn = {978-1-4503-4035-9},
	shorttitle = {Personalized {Recommendations} using {Knowledge} {Graphs}},
	url = {http://dl.acm.org/citation.cfm?doid=2959100.2959131},
	doi = {10.1145/2959100.2959131},
	abstract = {Improving the performance of recommender systems using knowledge graphs is an important task. There have been many hybrid systems proposed in the past that use a mix of content-based and collaborative ﬁltering techniques to boost the performance. More recently, some work has focused on recommendations that use external knowledge graphs (KGs) to supplement content-based recommendation.},
	language = {en},
	urldate = {2019-03-09},
	booktitle = {Proceedings of the 10th {ACM} {Conference} on {Recommender} {Systems} - {RecSys} '16},
	publisher = {ACM Press},
	author = {Catherine, Rose and Cohen, William},
	year = {2016},
	keywords = {kg},
	pages = {325--332},
}

@inproceedings{ExplainableNetworkedPrediction,
	address = {Torino, Italy},
	title = {Towards {Explainable} {Networked} {Prediction}},
	isbn = {978-1-4503-6014-2},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3269276},
	doi = {10.1145/3269206.3269276},
	abstract = {Networked prediction has attracted lots of research attention in recent years. Compared with the traditional learning setting, networked prediction is even harder to understand due to its coupled, multi-level nature. The learning process propagates top-down through the underlying network from the macro level (the entire learning system), to meso level (learning tasks), and to micro level (individual learning examples). In the meanwhile, the networked prediction setting also o ers rich context to explain the learning process through the lens of multi-aspect, including training examples (e.g., what are the most in uential examples), the learning tasks (e.g., which tasks are most important) and the task network (e.g., which task connections are the keys). Thus, we propose a multiaspect, multi-level approach to explain networked prediction. The key idea is to e ciently quantify the in uence on di erent levels of the learning system due to the perturbation of various aspects. The proposed method o ers two distinctive advantages: (1) multi-aspect, multi-level: it is able to explain networked prediction from multiple aspects (i.e., example-task-network) at multiple levels (i.e., macromeso-micro); (2) e ciency: it has a linear complexity by e ciently evaluating the in uences of changes to the networked prediction without retraining.},
	language = {en},
	urldate = {2019-03-09},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Li, Liangyue and Tong, Hanghang and Liu, Huan},
	year = {2018},
	keywords = {kg},
	pages = {1819--1822},
}

@inproceedings{IntentsKBKnowledgeBaseEntityOriented,
	address = {Torino, Italy},
	title = {{IntentsKB}: {A} {Knowledge} {Base} of {Entity}-{Oriented} {Search} {Intents}},
	isbn = {978-1-4503-6014-2},
	shorttitle = {{IntentsKB}},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3269257},
	doi = {10.1145/3269206.3269257},
	abstract = {We address the problem of constructing a knowledge base of entityoriented search intents. Search intents are defined on the level of entity types, each comprising of a high-level intent category (property, website, service, or other), along with a cluster of query terms used to express that intent. These machine-readable statements can be leveraged in various applications, e.g., for generating entity cards or query recommendations. By structuring service-oriented search intents, we take one step towards making entities actionable. The main contribution of this paper is a pipeline of components we develop to construct a knowledge base of entity intents. We evaluate performance both component-wise and end-to-end, and demonstrate that our approach is able to generate high-quality data.},
	language = {en},
	urldate = {2019-03-09},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Garigliotti, Darío and Balog, Krisztian},
	year = {2018},
	keywords = {kg},
	pages = {1659--1662},
}

@inproceedings{RecommendingSerendipitousItemsUsing,
	address = {Torino, Italy},
	title = {Recommending {Serendipitous} {Items} using {Transfer} {Learning}},
	isbn = {978-1-4503-6014-2},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3269268},
	doi = {10.1145/3269206.3269268},
	abstract = {Most recommender algorithms are designed to suggest relevant items, but suggesting these items does not always result in user satisfaction. Therefore, the efforts in recommender systems recently shifted towards serendipity, but generating serendipitous recommendations is difficult due to the lack of training data. To the best of our knowledge, there are many large datasets containing relevance scores (relevance oriented) and only one publicly available dataset containing a relatively small number of serendipity scores (serendipity oriented). This limits the learning capabilities of serendipity oriented algorithms. Therefore, in the absence of any known deep learning algorithms for recommending serendipitous items and the lack of large serendipity oriented datasets, we introduce SerRec our novel transfer learning method to recommend serendipitous items. SerRec uses transfer learning to firstly train a deep neural network for relevance scores using a large dataset and then tunes it for serendipity scores using a smaller dataset. Our method shows benefits of transfer learning for recommending serendipitous items as well as performance gains over the state-of-the-art serendipity oriented algorithms.},
	language = {en},
	urldate = {2019-03-09},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Pandey, Gaurav and Kotkov, Denis and Semenov, Alexander},
	year = {2018},
	keywords = {kg},
	pages = {1771--1774},
}

@article{DifferentiatingConceptsInstancesKnowledgea,
	title = {Differentiating {Concepts} and {Instances} for {Knowledge} {Graph} {Embedding}},
	abstract = {Concepts, which represent a group of different instances sharing common properties, are essential information in knowledge representation. Most conventional knowledge embedding methods encode both entities (concepts and instances) and relations as vectors in a low dimensional semantic space equally, ignoring the difference between concepts and instances. In this paper, we propose a novel knowledge graph embedding model named TransC by differentiating concepts and instances. Speciﬁcally, TransC encodes each concept in knowledge graph as a sphere and each instance as a vector in the same semantic space. We use the relative positions to model the relations between concepts and instances (i.e., instanceOf), and the relations between concepts and sub-concepts (i.e., subClassOf). We evaluate our model on both link prediction and triple classiﬁcation tasks on the dataset based on YAGO. Experimental results show that TransC outperforms state-of-the-art methods, and captures the semantic transitivity for instanceOf and subClassOf relation. Our codes and datasets can be obtained from https:// github.com/davidlvxin/TransC.},
	language = {en},
	author = {Lv, Xin and Hou, Lei and Li, Juanzi and Liu, Zhiyuan},
	keywords = {kg},
	pages = {9},
}

@inproceedings{GenerativeDiscoveryStructuredMedical,
	address = {London, United Kingdom},
	title = {On the {Generative} {Discovery} of {Structured} {Medical} {Knowledge}},
	isbn = {978-1-4503-5552-0},
	url = {http://dl.acm.org/citation.cfm?doid=3219819.3220010},
	doi = {10.1145/3219819.3220010},
	abstract = {Online healthcare services can provide the general public with ubiquitous access to medical knowledge and reduce medical information access cost for both individuals and societies. However, expanding the scale of high-quality yet structured medical knowledge usually comes with tedious efforts in data preparation and human annotation. To promote the benefits while minimizing the data requirement in expanding medical knowledge, we introduce a generative perspective to study the relational medical entity pair discovery problem. A generative model named Conditional Relationship Variational Autoencoder is proposed to discover meaningful and novel medical entity pairs by purely learning from the expression diversity in the existing relational medical entity pairs. Unlike discriminative approaches where high-quality contexts and candidate medical entity pairs are carefully prepared to be examined by the model, the proposed model generates novel entity pairs directly by sampling from a learned latent space without further data requirement. The proposed model explores the generative modeling capacity for medical entity pairs while incorporating deep learning for hands-free feature engineering. It is not only able to generate meaningful medical entity pairs that are not yet observed, but also can generate entity pairs for a specific medical relationship. The proposed model adjusts the initial representations of medical entities by addressing their relational commonalities. Quantitative and qualitative evaluations on real-world relational medical entity pairs demonstrate the effectiveness of the proposed method in generating relational medical entity pairs that are meaningful and novel.},
	language = {en},
	urldate = {2019-04-03},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '18},
	publisher = {ACM Press},
	author = {Zhang, Chenwei and Li, Yaliang and Du, Nan and Fan, Wei and Yu, Philip S.},
	year = {2018},
	keywords = {kg},
	pages = {2720--2728},
}

@article{EnhancingGroupRecommendationKnowledge,
	title = {Enhancing group recommendation by knowledge graph},
	abstract = {With the rapid development of IT, more and more information/knowledge sharing and discovery activities are moved from offline to online and many online groups have been created to facilitate such activities. However, due to the information asymmetric and information overload problems, information/knowledge holders face difficulty disseminating their information/knowledge to online groups whose members are of interests. It is also difficult for groups of users to find the most related information/knowledge. Traditional individual recommendation techniques cannot solve this problem effectively because they cannot capture the preferences of a group of users. To generate recommendations for a group of users, this paper proposes a knowledge graph-enhanced group recommendation method in which knowledge graph is used to construct comprehensive profiles for groups and information/knowledge to be recommended. The proposed group recommendation method is evaluated with realworld data and the evaluation results demonstrate the effectiveness of the proposed method.},
	language = {en},
	author = {Deng, Weiwei and Zhu, Peihu and Ma, Jian},
	year = {2018},
	keywords = {kg},
	pages = {9},
}

@article{LearningEvaluatingContentStructure,
	title = {Learning and {Evaluating} the {Content} and {Structure} of a {Term} {Taxonomy}},
	abstract = {In this paper, we describe a weakly supervised bootstraping algorithm that reads Web texts and learns taxonomy terms. The bootstrapping algorithm starts with two seed words (a seed hypernym (Root concept) and a seed hyponym) that are inserted into a doubly anchored hyponym pattern. In alternating rounds, the algorithm learns new hyponym terms and new hypernym terms that are subordinate to the Root concept. We conducted an extensive evaluation with human annotators to evaluate the learned hyponym and hypernym terms for two categories: animals and people.},
	language = {en},
	author = {Kozareva, Zornitsa and Hovy, Eduard and Riloff, Ellen},
	keywords = {kg},
	pages = {8},
}

@inproceedings{MultiEMultiTaskEmbeddingKnowledge,
	address = {Torino, Italy},
	title = {{MultiE}: {Multi}-{Task} {Embedding} for {Knowledge} {Base} {Completion}},
	isbn = {978-1-4503-6014-2},
	shorttitle = {{MultiE}},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3269295},
	doi = {10.1145/3269206.3269295},
	abstract = {Completing knowledge bases (KBs) with missing facts is of great importance, since most existing KBs are far from complete. To this end, many knowledge base completion (KBC) methods have been proposed. However, most existing methods embed each relation into a vector separately, while ignoring the correlations among different relations. Actually, in large-scale KBs, there always exist some relations that are semantically related, and we believe this can help to facilitate the knowledge sharing when learning the embedding of related relations simultaneously. Along this line, we propose a novel KBC model by Multi-Task Embedding, named MultiE. In this model, semantically related relations are first clustered into the same group, and then learning the embedding of each relation can leverage the knowledge among different relations. Moreover, we propose a three-layer network to predict the missing values of incomplete knowledge triples. Finally, experiments on three popular benchmarks FB15k, FB15k-237 and WN18 are conducted to demonstrate the effectiveness of MultiE against some state-ofthe-art baseline competitors.},
	language = {en},
	urldate = {2019-04-03},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Zhang, Zhao and Zhuang, Fuzhen and Niu, Zheng-Yu and Wang, Deqing and He, Qing},
	year = {2018},
	keywords = {kg},
	pages = {1715--1718},
}

@article{LectureNotesMetricEmbeddings,
	title = {Lecture notes on metric embeddings},
	language = {en},
	author = {Matouˇsek, Jirˇı},
	keywords = {dm, metric},
	pages = {125},
}

@article{AdvancesMetricEmbeddingTheory,
	title = {Advances in {Metric} {Embedding} {Theory}},
	abstract = {Metric Embedding plays an important role in a vast range of application areas such as computer vision, computational biology, machine learning, networking, statistics, and mathematical psychology, to name a few. The mathematical theory of metric embedding is well studied in both pure and applied analysis and has more recently been the a source of interest for computer scientists as well. Most of this work is focused on the development of bi-Lipschitz mappings between metric spaces. In this paper we present new concepts in metric embeddings as well as new embedding methods for metric spaces. We focus on ﬁnite metric spaces, however some of the concepts and methods are applicable in other settings as well.},
	language = {en},
	author = {Abraham, Ittai and Bartal, Yair and Neiman, Ofer},
	keywords = {dm, metric},
	pages = {100},
}

@article{PersonalizedRankingMetricEmbedding,
	title = {Personalized {Ranking} {Metric} {Embedding} for {Next} {New} {POI} {Recommendation}},
	abstract = {The rapidly growing of Location-based Social Networks (LBSNs) provides a vast amount of check-in data, which enables many services, e.g., point-ofinterest (POI) recommendation. In this paper, we study the next new POI recommendation problem in which new POIs with respect to users’ current location are to be recommended. The challenge lies in the difﬁculty in precisely learning users’ sequential information and personalizing the recommendation model. To this end, we resort to the Metric Embedding method for the recommendation, which avoids drawbacks of the Matrix Factorization technique. We propose a personalized ranking metric embedding method (PRME) to model personalized check-in sequences. We further develop a PRME-G model, which integrates sequential information, individual preference, and geographical inﬂuence, to improve the recommendation performance. Experiments on two real-world LBSN datasets demonstrate that our new algorithm outperforms the stateof-the-art next POI recommendation methods.},
	language = {en},
	author = {Feng, Shanshan and Li, Xutao and Zeng, Yifeng and Cong, Gao and Chee, Yeow Meng and Yuan, Quan},
	keywords = {dm, metric},
	pages = {7},
}

@article{KnowledgeGraphCompletionComplexa,
	title = {Knowledge {Graph} {Completion} via {Complex} {Tensor} {Factorization}},
	language = {en},
	author = {Trouillon, Theo},
	keywords = {kg},
	pages = {38},
}

@inproceedings{ExplicitSemanticRankingAcademic,
	address = {Perth, Australia},
	title = {Explicit {Semantic} {Ranking} for {Academic} {Search} via {Knowledge} {Graph} {Embedding}},
	isbn = {978-1-4503-4913-0},
	url = {http://dl.acm.org/citation.cfm?doid=3038912.3052558},
	doi = {10.1145/3038912.3052558},
	abstract = {This paper introduces Explicit Semantic Ranking (ESR), a new ranking technique that leverages knowledge graph embedding. Analysis of the query log from our academic search engine, SemanticScholar.org, reveals that a major error source is its inability to understand the meaning of research concepts in queries. To addresses this challenge, ESR represents queries and documents in the entity space and ranks them based on their semantic connections from their knowledge graph embedding. Experiments demonstrate ESR’s ability in improving Semantic Scholar’s online production system, especially on hard queries where word-based ranking fails.},
	language = {en},
	urldate = {2019-04-03},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web} - {WWW} '17},
	publisher = {ACM Press},
	author = {Xiong, Chenyan and Power, Russell and Callan, Jamie},
	year = {2017},
	keywords = {kg},
	pages = {1271--1279},
}

@article{DocumentEmbeddingParagraphVectors,
	title = {Document {Embedding} with {Paragraph} {Vectors}},
	url = {http://arxiv.org/abs/1507.07998},
	abstract = {Paragraph Vectors has been recently proposed as an unsupervised method for learning distributed representations for pieces of texts. In their work, the authors showed that the method can learn an embedding of movie review texts which can be leveraged for sentiment analysis. That proof of concept, while encouraging, was rather narrow. Here we consider tasks other than sentiment analysis, provide a more thorough comparison of Paragraph Vectors to other document modelling algorithms such as Latent Dirichlet Allocation, and evaluate performance of the method as we vary the dimensionality of the learned representation. We benchmarked the models on two document similarity data sets, one from Wikipedia, one from arXiv. We observe that the Paragraph Vector method performs signiﬁcantly better than other methods, and propose a simple improvement to enhance embedding quality. Somewhat surprisingly, we also show that much like word embeddings, vector operations on Paragraph Vectors can perform useful semantic results.},
	language = {en},
	urldate = {2019-04-14},
	journal = {arXiv:1507.07998 [cs]},
	author = {Dai, Andrew M. and Olah, Christopher and Le, Quoc V.},
	month = jul,
	year = {2015},
	note = {arXiv: 1507.07998},
	keywords = {dm},
}

@article{RepresentationLearningReviewNew,
	title = {Representation {Learning}: {A} {Review} and {New} {Perspectives}},
	shorttitle = {Representation {Learning}},
	url = {http://arxiv.org/abs/1206.5538},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, auto-encoders, manifold learning, and deep networks. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.},
	language = {en},
	urldate = {2019-04-10},
	journal = {arXiv:1206.5538 [cs]},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.5538},
	keywords = {dm},
}

@inproceedings{PredictingSocialLinksNew,
	address = {Dallas, TX, USA},
	title = {Predicting {Social} {Links} for {New} {Users} across {Aligned} {Heterogeneous} {Social} {Networks}},
	isbn = {978-0-7695-5108-1},
	url = {http://ieeexplore.ieee.org/document/6729636/},
	doi = {10.1109/ICDM.2013.134},
	abstract = {Online social networks have gained great success in recent years and many of them involve multiple kinds of nodes and complex relationships. Among these relationships, social links among users are of great importance. Many existing link prediction methods focus on predicting social links that will appear in the future among all users based upon a snapshot of the social network. In real-world social networks, many new users are joining in the service every day. Predicting links for new users are more important. Different from conventional link prediction problems, link prediction for new users are more challenging due to the following reasons: (1) differences in information distributions between new users and the existing active users (i.e., old users); (2) lack of information from the new users in the network. In order to solve the above problems, we need to accommodate the differences in information distributions between old users and new users within the network and transfer additional information from other sources for the new users. We notice that users nowadays are normally involved in multiple social networks to enjoy more online services at the same time, such as Facebook, Twitter and Foursquare. New users in one social network (e.g., Foursquares) might have already joined and been active in another network (e.g., Twitter) for a long time. We propose a link prediction method called SCANPS (Supervised Cross Aligned Networks link prediction with Personalized Sampling), to solve the link prediction problem for new users with information transferred from both the existing active users in the target network and other source networks through aligned accounts. We proposed a within-target-network personalized sampling method to process the existing active users’ information in order to accommodate the differences in information distributions before the intra-network knowledge transfer. SCAN-PS can also exploit information in other source networks, where the user accounts are aligned with the target network. In this way, SCAN-PS could solve the cold start problem when information of these new users is total absent in the target network. Extensive experiments conducted on Twitter and Foursquare, two real-world aligned heterogeneous social networks, demonstrate that SCAN-PS outperforms other link prediction methods for new users under different degrees of newness consistently and works well with the cold start problems.},
	language = {en},
	urldate = {2019-04-06},
	booktitle = {2013 {IEEE} 13th {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Zhang, Jiawei and Kong, Xiangnan and Yu, Philip S.},
	month = dec,
	year = {2013},
	pages = {1289--1294},
}

@article{SocialNetworkFusionMining,
	title = {Social {Network} {Fusion} and {Mining}: {A} {Survey}},
	shorttitle = {Social {Network} {Fusion} and {Mining}},
	url = {http://arxiv.org/abs/1804.09874},
	abstract = {Looking from a global perspective, the landscape of online social networks is highly fragmented. A large number of online social networks have appeared, which can provide users with various types of services. Generally, the information available in these online social networks is of diverse categories, which can be represented as heterogeneous social networks (HSN) formally. Meanwhile, in such an age of online social media, users usually participate in multiple online social networks simultaneously to enjoy more social networks services, who can act as bridges connecting diﬀerent networks together. So multiple HSNs not only represent information in single network, but also fuse information from multiple networks.},
	language = {en},
	urldate = {2019-04-04},
	journal = {arXiv:1804.09874 [cs]},
	author = {Zhang, Jiawei},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.09874},
}

@inproceedings{ECGLensInteractiveVisualExploration,
	address = {Montreal QC, Canada},
	title = {{ECGLens}: {Interactive} {Visual} {Exploration} of {Large} {Scale} {ECG} {Data} for {Arrhythmia} {Detection}},
	isbn = {978-1-4503-5620-6},
	shorttitle = {{ECGLens}},
	url = {http://dl.acm.org/citation.cfm?doid=3173574.3174237},
	doi = {10.1145/3173574.3174237},
	abstract = {The Electrocardiogram (ECG) is commonly used to detect arrhythmias. Traditionally, a single ECG observation is used for diagnosis, making it difﬁcult to detect irregular arrhythmias. Recent technology developments, however, have made it cost-effective to collect large amounts of raw ECG data over time. This promises to improve diagnosis accuracy, but the large data volume presents new challenges for cardiologists. This paper introduces ECGLens, an interactive system for arrhythmia detection and analysis using large-scale ECG data. Our system integrates an automatic heartbeat classiﬁcation algorithm based on convolutional neural network, an outlier detection algorithm, and a set of rich interaction techniques. We also introduce A-glyph, a novel glyph designed to improve the readability and comparison of ECG signals. We report results from a comprehensive user study showing that A-glyph improves the efﬁciency in arrhythmia detection, and demonstrate the effectiveness of ECGLens in arrhythmia detection through two expert interviews.},
	language = {en},
	urldate = {2019-04-04},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Xu, Ke and Guo, Shunan and Cao, Nan and Gotz, David and Xu, Aiwen and Qu, Huamin and Yao, Zhenjie and Chen, Yixin},
	year = {2018},
	keywords = {health, vis},
	pages = {1--12},
}

@article{TaskorientedWordEmbeddingText,
	title = {Task-oriented {Word} {Embedding} for {Text} {Classification}},
	abstract = {Distributed word representation plays a pivotal role in various natural language processing tasks. In spite of its success, most existing methods only consider contextual information, which is suboptimal when used in various tasks due to a lack of task-speciﬁc features. The rational word embeddings should have the ability to capture both the semantic features and task-speciﬁc features of words. In this paper, we propose a task-oriented word embedding method and apply it to the text classiﬁcation task. With the function-aware component, our method regularizes the distribution of words to enable the embedding space to have a clear classiﬁcation boundary. We evaluate our method using ﬁve text classiﬁcation datasets. The experiment results show that our method signiﬁcantly outperforms the state-of-the-art methods.},
	language = {en},
	author = {Liu, Qian and Huang, Heyan and Gao, Yang and Wei, Xiaochi and Tian, Yuxin and Liu, Luyang},
	keywords = {dm},
	pages = {10},
}

@article{RelevancebasedWordEmbedding,
	title = {Relevance-based {Word} {Embedding}},
	url = {http://arxiv.org/abs/1705.03556},
	abstract = {Learning a high-dimensional dense representation for vocabulary terms, also known as a word embedding, has recently a racted much a ention in natural language processing and information retrieval tasks. e embedding vectors are typically learned based on term proximity in a large corpus. is means that the objective in well-known word embedding algorithms, e.g., word2vec, is to accurately predict adjacent word(s) for a given word or context. However, this objective is not necessarily equivalent to the goal of many information retrieval (IR) tasks. e primary objective in various IR tasks is to capture relevance instead of term proximity, syntactic, or even semantic similarity. is is the motivation for developing unsupervised relevance-based word embedding models that learn word representations based on query-document relevance information. In this paper, we propose two learning models with di erent objective functions; one learns a relevance distribution over the vocabulary set for each query, and the other classi es each term as belonging to the relevant or non-relevant class for each query. To train our models, we used over six million unique queries and the top ranked documents retrieved in response to each query, which are assumed to be relevant to the query. We extrinsically evaluate our learned word representation models using two IR tasks: query expansion and query classi cation. Both query expansion experiments on four TREC collections and query classi cation experiments on the KDD Cup 2005 dataset suggest that the relevance-based word embedding models signi cantly outperform state-of-the-art proximity-based embedding models, such as word2vec and GloVe.},
	language = {en},
	urldate = {2019-04-14},
	journal = {arXiv:1705.03556 [cs]},
	author = {Zamani, Hamed and Croft, W. Bruce},
	month = may,
	year = {2017},
	note = {arXiv: 1705.03556},
	keywords = {dm},
}

@article{ConceptMiningEmbedding,
	title = {Concept {Mining} via {Embedding}},
	abstract = {In this work, we study the problem of concept mining, which serves as the ﬁrst step in transforming unstructured text into structured information, and supports downstream analytical tasks such as information extraction, organization, recommendation and search. Previous work mainly relies on statistical signals, existing knowledge bases, or predeﬁned linguistic patterns. In this work, we propose a novel approach that mines concepts based on their occurrence contexts, by learning embedding vector representations that summarize the context information for each possible candidates, and use these embeddings to evaluate the concept’s global quality and their ﬁtness to each local context. Experiments over several realworld corpora demonstrate the superior performance of our method. A publicly available implementation is provided at https://github.com/kleeeeea/ECON.},
	language = {en},
	author = {Li, Keqian and Zha, Hanwen and Su, Yu and Yan, Xifeng},
	keywords = {dm},
	pages = {10},
}

@article{PixelSNEVisualizingFastJust,
	title = {{PixelSNE}: {Visualizing} {Fast} with {Just} {Enough} {Precision} via {Pixel}-{Aligned} {Stochastic} {Neighbor} {Embedding}},
	shorttitle = {{PixelSNE}},
	url = {http://arxiv.org/abs/1611.02568},
	abstract = {Embedding and visualizing large-scale high-dimensional data in a two-dimensional space is an important problem since such visualization can reveal deep insights out of complex data. Most of the existing embedding approaches, however, run on an excessively high precision, ignoring the fact that at the end, embedding outputs are mapped into coarse-grained pixel coordinates in a limited screen space. Motivated by this observation and directly considering it in an embedding algorithm, we accelerate Barnes-Hut tree-based t-distributed stochastic neighbor embedding (BH-SNE), known as a state-of-the-art 2D embedding method, and propose a novel alternative called PixelSNE, a highly-e cient, screen resolution-driven 2D embedding method with a linear computational complexity in terms of the number of data items. Our experimental results show the signi cantly fast running time of PixelSNE by a large margin against BH-SNE, while maintaining the comparable embedding quality. Finally, the source code of our method is publicly available at h ps://github.com/awesome-davian/pixelsne.},
	language = {en},
	urldate = {2019-04-14},
	journal = {arXiv:1611.02568 [cs]},
	author = {Kim, Minjeong and Choi, Minsuk and Lee, Sunwoong and Tang, Jian and Park, Haesun and Choo, Jaegul},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.02568},
	keywords = {dm},
}

@inproceedings{LocalDiscriminantEmbeddingIts,
	address = {San Diego, CA, USA},
	title = {Local {Discriminant} {Embedding} and {Its} {Variants}},
	volume = {2},
	isbn = {978-0-7695-2372-9},
	url = {http://ieeexplore.ieee.org/document/1467531/},
	doi = {10.1109/CVPR.2005.216},
	abstract = {We present a new approach, called local discriminant embedding (LDE), to manifold learning and pattern classiﬁcation. In our framework, the neighbor and class relations of data are used to construct the embedding for classiﬁcation problems. The proposed algorithm learns the embedding for the submanifold of each class by solving an optimization problem. After being embedded into a low-dimensional subspace, data points of the same class maintain their intrinsic neighbor relations, whereas neighboring points of different classes no longer stick to one another. Via embedding, new test data are thus more reliably classiﬁed by the nearest neighbor rule, owing to the locally discriminating nature. We also describe two useful variants: twodimensional LDE and kernel LDE. Comprehensive comparisons and extensive experiments on face recognition are included to demonstrate the effectiveness of our method.},
	language = {en},
	urldate = {2019-04-14},
	booktitle = {2005 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}'05)},
	publisher = {IEEE},
	author = {{Hwann-Tzong Chen} and {Huang-Wei Chang} and {Tyng-Luh Liu}},
	year = {2005},
	keywords = {dm},
	pages = {846--853},
}

@inproceedings{EstimatingEmbeddingVectorsQueries,
	address = {Newark, Delaware, USA},
	title = {Estimating {Embedding} {Vectors} for {Queries}},
	isbn = {978-1-4503-4497-5},
	url = {http://dl.acm.org/citation.cfm?doid=2970398.2970403},
	doi = {10.1145/2970398.2970403},
	abstract = {The dense vector representation of vocabulary terms, also known as word embeddings, have been shown to be highly eﬀective in many natural language processing tasks. Word embeddings have recently begun to be studied in a number of information retrieval (IR) tasks. One of the main steps in leveraging word embeddings for IR tasks is to estimate the embedding vectors of queries. This is a challenging task, since queries are not always available during the training phase of word embedding vectors. Previous work has considered the average or sum of embedding vectors of all query terms (AWE) to model the query embedding vectors, but no theoretical justiﬁcation has been presented for such a model. In this paper, we propose a theoretical framework for estimating query embedding vectors based on the individual embedding vectors of vocabulary terms. We then provide a number of diﬀerent implementations of this framework and show that the AWE method is a special case of the proposed framework. We also introduce pseudo query vectors, the query embedding vectors estimated using pseudo-relevant documents. We further extrinsically evaluate the proposed methods using two well-known IR tasks: query expansion and query classiﬁcation. The estimated query embedding vectors are evaluated via query expansion experiments over three newswire and web TREC collections as well as query classiﬁcation experiments over the KDD Cup 2005 test set. The experiments show that the introduced pseudo query vectors signiﬁcantly outperform the AWE method.},
	language = {en},
	urldate = {2019-04-14},
	booktitle = {Proceedings of the 2016 {ACM} {International} {Conference} on the {Theory} of {Information} {Retrieval} - {ICTIR} '16},
	publisher = {ACM Press},
	author = {Zamani, Hamed and Croft, W. Bruce},
	year = {2016},
	keywords = {dm},
	pages = {123--132},
}

@inproceedings{TEMTreeenhancedEmbeddingModel,
	address = {Lyon, France},
	title = {{TEM}: {Tree}-enhanced {Embedding} {Model} for {Explainable} {Recommendation}},
	isbn = {978-1-4503-5639-8},
	shorttitle = {{TEM}},
	url = {http://dl.acm.org/citation.cfm?doid=3178876.3186066},
	doi = {10.1145/3178876.3186066},
	abstract = {While collaborative filtering is the dominant technique in personalized recommendation, it models user-item interactions only and cannot provide concrete reasons for a recommendation. Meanwhile, the rich side information affiliated with user-item interactions (e.g., user demographics and item attributes), which provide valuable evidence that why a recommendation is suitable for a user, has not been fully explored in providing explanations.},
	language = {en},
	urldate = {2019-04-14},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference} on {World} {Wide} {Web}  - {WWW} '18},
	publisher = {ACM Press},
	author = {Wang, Xiang and He, Xiangnan and Feng, Fuli and Nie, Liqiang and Chua, Tat-Seng},
	year = {2018},
	keywords = {dm},
	pages = {1543--1552},
}

@inproceedings{SemanticVisualizationShortTexts,
	address = {Melbourne, Australia},
	title = {Semantic {Visualization} for {Short} {Texts} with {Word} {Embeddings}},
	isbn = {978-0-9992411-0-3},
	url = {https://www.ijcai.org/proceedings/2017/288},
	doi = {10.24963/ijcai.2017/288},
	abstract = {Semantic visualization integrates topic modeling and visualization, such that every document is associated with a topic distribution as well as visualization coordinates on a low-dimensional Euclidean space. We address the problem of semantic visualization for short texts. Such documents are increasingly common, including tweets, search snippets, news headlines, or status updates. Due to their short lengths, it is difﬁcult to model semantics as the word co-occurrences in such a corpus are very sparse. Our approach is to incorporate auxiliary information, such as word embeddings from a larger corpus, to supplement the lack of co-occurrences. This requires the development of a novel semantic visualization model that seamlessly integrates visualization coordinates, topic distributions, and word vectors. We propose a model called GaussianSV, which outperforms pipelined baselines that derive topic models and visualization coordinates as disjoint steps, as well as semantic visualization baselines that do not consider word embeddings.},
	language = {en},
	urldate = {2019-04-14},
	booktitle = {Proceedings of the {Twenty}-{Sixth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Le, Tuan M. V. and Lauw, Hady W.},
	month = aug,
	year = {2017},
	keywords = {dm},
	pages = {2074--2080},
}

@article{ImprovingLatentUserModels,
	title = {Improving {Latent} {User} {Models} in {Online} {Social} {Media}},
	url = {http://arxiv.org/abs/1711.11124},
	abstract = {Modern social platforms are characterized by the presence of rich user-behavior data associated with the publication, sharing and consumption of textual content. Users interact with content and with each other in a complex and dynamic social environment while simultaneously evolving over time. In order to e ectively characterize users and predict their future behavior in such a se ing, it is necessary to overcome several challenges. Content heterogeneity and temporal inconsistency of behavior data result in severe sparsity at the user level. In this paper, we propose a novel mutualenhancement framework to simultaneously partition and learn latent activity pro les of users. We propose a exible user partitioning approach to e ectively discover rare behaviors and tackle user-level sparsity. We extensively evaluate the proposed framework on massive datasets from real-world platforms including Q\&A networks and interactive online courses (MOOCs). Our results indicate signi cant gains over state-of-the-art behavior models ( 15\% avg ) in a varied range of tasks and our gains are further magni ed for users with limited interaction data. e proposed algorithms are amenable to parallelization, scale linearly in the size of datasets, and provide exibility to model diverse facets of user behavior.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1711.11124 [cs]},
	author = {Krishnan, Adit and Sharma, Ashish and Sundaram, Hari},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.11124},
	keywords = {dm},
}

@incollection{IdentificationInfluentialUsersBased,
	address = {Cham},
	title = {Identification of {Influential} {Users} {Based} on {Topic}-{Behavior} {Influence} {Tree} in {Social} {Networks}},
	volume = {10619},
	isbn = {978-3-319-73617-4 978-3-319-73618-1},
	url = {http://link.springer.com/10.1007/978-3-319-73618-1_40},
	abstract = {Identifying inﬂuential users in social networks is of signiﬁcant interest, as it can help improve the propagation of ideas or innovations. Various factors can aﬀect the relationships and the formulation of inﬂuence between users. Although many studies have researched this domain, the eﬀect of the correlation between messages and behaviors in measuring users’ inﬂuence in social networks has not been adequately focused on. As a result, inﬂuential users can not be accurately evaluated. Thus, we propose a topic-behavior inﬂuence tree algorithm that identiﬁes inﬂuential users using six types of relationships in the following factors: message content, hashtag titles, retweets, replies, and mentions. By maximizing the number of aﬀected users and minimizing the propagation path, we can improve the accuracy of identifying inﬂuential users. The experimental results compared with state-of-the-art algorithms on various datasets and visualization on TUAW dataset validate the eﬀectiveness of the proposed algorithm.},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {Natural {Language} {Processing} and {Chinese} {Computing}},
	publisher = {Springer International Publishing},
	author = {Wu, Jianjun and Sha, Ying and Li, Rui and Liang, Qi and Jiang, Bo and Tan, Jianlong and Wang, Bin},
	editor = {Huang, Xuanjing and Jiang, Jing and Zhao, Dongyan and Feng, Yansong and Hong, Yu},
	year = {2018},
	doi = {10.1007/978-3-319-73618-1_40},
	keywords = {dm},
	pages = {477--489},
}

@article{PresentationSelfElectronicLife,
	title = {The {Presentation} of {Self} in {Electronic} {Life}: {Goffman} on the {Internet}},
	language = {en},
	author = {Miller, Hugh},
	keywords = {dm},
	pages = {9},
}

@article{PresentationSelfOnlineWorld,
	title = {‘{The} presentation of self in the online world’: {Goffman} and the study of online identities},
	volume = {39},
	issn = {0165-5515, 1741-6485},
	shorttitle = {‘{The} presentation of self in the online world’},
	url = {http://journals.sagepub.com/doi/10.1177/0165551512470051},
	doi = {10.1177/0165551512470051},
	abstract = {This paper presents an exemplification and discussion of the contemporaneity of Erving Goffman’s work and of its applicability to the analysis of identity and presentation of self in the blogging and Second Life (SL) contexts. An analysis of online identity and interaction practices in 10 different cases of bloggers and SL inhabitants and of their online spaces is presented in terms of: expressions given; embellishment as a minor form of persona adoption; dividing the self; conforming and ‘fitting in’; and masking, anonymity and pseudonimity. The key finding of the research is that, contrary to engaging with the process of whole persona adoption, participants were keen to re-create their offline self online, but engaged in editing facets of self. This emphasizes the key premise in Goffman’s work that, when in ‘front stage’, people deliberately chose to project a given identity. It is concluded that Goffman’s original framework is of great usefulness as an explanatory framework for understanding identity through interaction and the presentation of self in the online world. Equally, the online environment, with its enhanced potential for editing the self, can offer opportunities to contribute to the further development of the Goffman framework.},
	language = {en},
	number = {1},
	urldate = {2019-04-17},
	journal = {Journal of Information Science},
	author = {Bullingham, Liam and Vasconcelos, Ana C.},
	month = feb,
	year = {2013},
	keywords = {dm},
	pages = {101--112},
}

@article{PersonalizingProductRankingsUsing,
	title = {Personalizing {Product} {Rankings} {Using} {Collaborative} {Filtering} on {Opinion}-{Derived} {Topic} {Profiles}},
	abstract = {Product review sites such as TripAdvisor, Yelp or Amazon provide a single, non personalized ranking of products. The sparse review data makes personalizing recommendations difﬁcult. Topic Proﬁle Collaborative Filtering exploits review texts to identify user proﬁles as a basis for similarity. We show that careful use of the available data and separating users into classes can greatly improve the performance of such techniques. We signiﬁcantly improve MAE, RMSE, and Kendall tau, compared to the previous best results. In addition, we show that personalization does not beneﬁt all the users to the same extent. We propose switching between a personalized and a non personalized method based on the user opinion proﬁle. We show that the user’s opinionatedness is a good indicator of whether the personalization will work or not.},
	language = {en},
	author = {Musat, Claudiu Cristian and Faltings, Boi},
	keywords = {dm},
	pages = {7},
}

@article{AntisocialBehaviorOnlineDiscussion,
	title = {Antisocial {Behavior} in {Online} {Discussion} {Communities}},
	abstract = {User contributions in the form of posts, comments, and votes are essential to the success of online communities. However, allowing user participation also invites undesirable behavior such as trolling. In this paper, we characterize antisocial behavior in three large online discussion communities by analyzing users who were banned from these communities. We ﬁnd that such users tend to concentrate their efforts in a small number of threads, are more likely to post irrelevantly, and are more successful at garnering responses from other users. Studying the evolution of these users from the moment they join a community up to when they get banned, we ﬁnd that not only do they write worse than other users over time, but they also become increasingly less tolerated by the community. Further, we discover that antisocial behavior is exacerbated when community feedback is overly harsh. Our analysis also reveals distinct groups of users with different levels of antisocial behavior that can change over time. We use these insights to identify antisocial users early on, a task of high practical importance to community maintainers.},
	language = {en},
	author = {Cheng, Justin and Danescu-Niculescu-Mizil, Cristian and Leskovec, Jure},
	keywords = {dm},
	pages = {10},
}

@inproceedings{InterpretationNodeEmbeddings,
	address = {Lyon, France},
	title = {Towards {Interpretation} of {Node} {Embeddings}},
	isbn = {978-1-4503-5640-4},
	url = {http://dl.acm.org/citation.cfm?doid=3184558.3191523},
	doi = {10.1145/3184558.3191523},
	abstract = {Recently there have been a large number of studies on embedding large-scale information networks using low-dimensional, neighborhood and community aware node representations. Though the performance of these embedding models have been better than traditional methods for graph mining applications, little is known about what these representations encode, or why a particular node representation works better for certain tasks. Our work presented here constitutes the first step in decoding the black-box of vector embeddings of nodes by evaluating their effectiveness in encoding elementary properties of a node such as page rank, degree, closeness centrality, clustering coefficient, etc.},
	language = {en},
	urldate = {2019-04-14},
	booktitle = {Companion of the {The} {Web} {Conference} 2018 on {The} {Web} {Conference} 2018  - {WWW} '18},
	publisher = {ACM Press},
	author = {Dalmia, Ayushi and J, Ganesh and Gupta, Manish},
	year = {2018},
	keywords = {dm},
	pages = {945--952},
}

@article{UnfoldingSentimentalBehavioralTendencies,
	title = {Unfolding {Sentimental} and {Behavioral} {Tendencies} of {Learners}' {Concerned} {Topics} {From} {Course} {Reviews} in a {MOOC}},
	issn = {0735-6331, 1541-4140},
	url = {http://journals.sagepub.com/doi/ 10.1177/0735633118757181},
	doi = {10.1177/0735633118757181},
	abstract = {Course reviews, which is designed as an interactive feedback channel in Massive Open Online Courses, has promoted the generation of large-scale text comments. These data, which contain not only learners’ concerns, opinions and feelings toward courses, instructors, and platforms but also learners’ interactions (e.g., post, reply), are generally subjective and extremely valuable for online instruction. The purpose of this study is to automatically reveal these potential information from 50 online courses by an improved unified topic model Behavior-Sentiment Topic Mixture, which is validated and effective for detecting frequent topics learners discuss most, topics-oriented sentimental tendency as well as how learners interact with these topics. The results show that learners focus more on the topics about course-related content with positive sentiment, as well as the topics about course logistics and video production with negative sentiment. Moreover, the distributions of behaviors associated with these topics have some differences.},
	language = {en},
	urldate = {2019-04-17},
	journal = {Journal of Educational Computing Research},
	author = {Liu, Sannyuya and Peng, Xian and Cheng, Hercy N. H. and Liu, Zhi and Sun, Jianwen and Yang, Chongyang},
	month = mar,
	year = {2018},
	keywords = {dm},
	pages = {073563311875718},
}

@article{MythosModelInterpretability,
	title = {The {Mythos} of {Model} {Interpretability}},
	url = {http://arxiv.org/abs/1606.03490},
	abstract = {Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but interpretable. And yet the task of interpretation appears underspeciﬁed. Papers provide diverse and sometimes non-overlapping motivations for interpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim interpretability axiomatically, absent further explanation. In this paper, we seek to reﬁne the discourse on interpretability. First, we examine the motivations underlying interest in interpretability, ﬁnding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1606.03490 [cs, stat]},
	author = {Lipton, Zachary C.},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.03490},
	keywords = {fatml, interpretable, key, survey, xai},
}

@inproceedings{ParticipantSelectionInformationDiffusion,
	address = {Hong Kong, China},
	title = {Participant {Selection} for {Information} {Diffusion} {Based} on {Topic} and {Emotion} {Preference} {Learning}},
	isbn = {978-1-5090-6517-2},
	url = {http://ieeexplore.ieee.org/document/7947028/},
	doi = {10.1109/SMARTCOMP.2017.7947028},
	abstract = {The rapid development of social networks has woven themselves into people’s daily life and become indispensable platforms with superior commercial and scientiﬁc values. Both companies and governments have discovered the potential effectiveness of employing social network users for information diffusion. Rather than only selecting a group of users who are interested in target topic, it is more beneﬁcial to choose users with desired emotion preference to help diffuse information under certain emotional expectation. In this paper, we propose an emotional participant selection system that not only considers user’s topic preference, but also more importantly takes user’s emotional inﬂuence into account. Speciﬁcally, a dynamic forgetting mechanism is applied to learn user’s topic preference, and independent cascade model is leveraged to construct emotional inﬂuence. Combining these two features, we develop an algorithm that can accomplish the task for emotional participant selection. Experimental results on a real-world data set validate the effectiveness of our proposed method.},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {2017 {IEEE} {International} {Conference} on {Smart} {Computing} ({SMARTCOMP})},
	publisher = {IEEE},
	author = {Yu, Zhiwen and Yi, Fei and Ma, Chao and Guo, Bin and Wang, Zhu},
	month = may,
	year = {2017},
	keywords = {dm},
	pages = {1--8},
}

@article{RigorousScienceInterpretableMachinea,
	title = {Towards {A} {Rigorous} {Science} of {Interpretable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1702.08608},
	abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1702.08608 [cs, stat]},
	author = {Doshi-Velez, Finale and Kim, Been},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.08608},
	keywords = {eval, fatml, interpretable, key, xai},
}

@article{RuleMatrixVisualizingUnderstandingClassifiers,
	title = {{RuleMatrix}: {Visualizing} and {Understanding} {Classifiers} with {Rules}},
	shorttitle = {{RuleMatrix}},
	url = {http://arxiv.org/abs/1807.06228},
	abstract = {With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand, diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models. By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior. We design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. We evaluate the effectiveness of RuleMatrix via two use cases and a usability study.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1807.06228 [cs, stat]},
	author = {Ming, Yao and Qu, Huamin and Bertini, Enrico},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.06228},
	keywords = {fatml, rw-uu-vis-ml, vis},
}

@inproceedings{InterpretingBlackBoxClassifiersUsing,
	address = {Chicago, IL, USA},
	title = {Interpreting {Black}-{Box} {Classifiers} {Using} {Instance}-{Level} {Visual} {Explanations}},
	isbn = {978-1-4503-5029-7},
	url = {http://dl.acm.org/citation.cfm?doid=3077257.3077260},
	doi = {10.1145/3077257.3077260},
	abstract = {To realize the full potential of machine learning in diverse realworld domains, it is necessary for model predictions to be readily interpretable and actionable for the human in the loop. Analysts, who are the users but not the developers of machine learning models, often do not trust a model because of the lack of transparency in associating predictions with the underlying data space. To address this problem, we propose Rivelo, a visual analytics interface that enables analysts to understand the causes behind predictions of binary classi ers by interactively exploring a set of instance-level explanations. These explanations are model-agnostic, treating a model as a black box, and they help analysts in interactively probing the high-dimensional binary data space for detecting features relevant to predictions. We demonstrate the utility of the interface with a case study analyzing a random forest model on the sentiment of Yelp reviews about doctors.},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {Proceedings of the 2nd {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics}  - {HILDA}'17},
	publisher = {ACM Press},
	author = {Tamagnini, Paolo and Krause, Josua and Dasgupta, Aritra and Bertini, Enrico},
	year = {2017},
	keywords = {fatml, vis},
	pages = {1--6},
}

@article{ImprovingRecommendationDiversity,
	title = {Improving {Recommendation} {Diversity}},
	abstract = {Recommender systems oﬀer users a more intelligent and personalised mechanism to seek out new information. Content-based recommender systems generally prefer to retrieve a set of items maximally similar to a users’ query and/or proﬁle. We argue that as new types of recommendation domains and tasks emerge, this blind faith in the similarity assumption begins to seem ﬂawed. We show that very often recommendation diversity is important and that traditional recommendation systems are marred by poor diversity characteristics. We evaluate a new class of diversity-preserving algorithm capable of addressing this without compromising similarity or eﬃciency.},
	language = {en},
	author = {Bradley, Keith and Smyth, Barry},
	keywords = {diverse, fatml, rec, xai},
	pages = {10},
}

@inproceedings{ClusteringApproachPersonalizingDiversity,
	address = {Bratislava, Slovakia},
	title = {A {Clustering} {Approach} for {Personalizing} {Diversity} in {Collaborative} {Recommender} {Systems}},
	isbn = {978-1-4503-4635-1},
	url = {http://dl.acm.org/citation.cfm?doid=3079628.3079699},
	doi = {10.1145/3079628.3079699},
	abstract = {Much of the focus of recommender systems research has been on the accurate prediction of users’ ratings for unseen items. Recent work has suggested that objectives such as diversity and novelty in recommendations are also important factors in the e ectiveness of a recommender system. However, methods that a empt to increase diversity of recommendation lists for all users without considering each user’s preference or tolerance for diversity may lead to monotony for some users and to poor recommendations for others. Our goal in this research is to evaluate the hypothesis that users’ propensity towards diversity varies greatly and that the diversity of recommendation lists should be consistent with the level of user interest in diverse recommendations. We propose a pre- ltering clustering approach to group users with similar levels of tolerance for diversity. Our contributions are twofold. First, we propose a method for personalizing diversity by performing collaborative ltering independently on di erent segments of users based on the degree of diversity in their pro les. Secondly, we investigate the accuracy-diversity tradeo s using the proposed method across di erent user segments. As part of this evaluation we propose new metrics, adapted from information retrieval, that help us measure the e ectiveness of our approach in personalizing diversity. Our experimental evaluation is based on two di erent datasets: MovieLens movie ratings, and Yelp restaurant reviews.},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {Proceedings of the 25th {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}  - {UMAP} '17},
	publisher = {ACM Press},
	author = {Eskandanian, Farzad and Mobasher, Bamshad and Burke, Robin},
	year = {2017},
	keywords = {diverse, fatml, rec, xai},
	pages = {280--284},
}

@article{FairnessawareHybridRecommenderSystem,
	title = {A {Fairness}-aware {Hybrid} {Recommender} {System}},
	url = {http://arxiv.org/abs/1809.09030},
	abstract = {Recommender systems are used in variety of domains affecting people’s lives. This has raised concerns about possible biases and discrimination that such systems might exacerbate. There are two primary kinds of biases inherent in recommender systems: observation bias and bias stemming from imbalanced data. Observation bias exists due to a feedback loop which causes the model to learn to only predict recommendations similar to previous ones. Imbalance in data occurs when systematic societal, historical, or other ambient bias is present in the data. In this paper, we address both biases by proposing a hybrid fairness-aware recommender system. Our model provides efﬁcient and accurate recommendations by incorporating multiple user-user and item-item similarity measures, content, and demographic information, while addressing recommendation biases. We implement our model using a powerful and expressive probabilistic programming language called probabilistic soft logic. We experimentally evaluate our approach on a popular movie recommendation dataset, showing that our proposed model can provide more accurate and fairer recommendations, compared to a state-of-the art fair recommender system.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1809.09030 [cs, stat]},
	author = {Farnadi, Golnoosh and Kouki, Pigi and Thompson, Spencer K. and Srinivasan, Sriram and Getoor, Lise},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.09030},
	keywords = {fair, fatml, rec, xai},
}

@inproceedings{UserCentricDiversityDesignRecommender,
	address = {Lyon, France},
	title = {A {User}-{Centric} {Diversity} by {Design} {Recommender} {System} for the {Movie} {Application} {Domain}},
	isbn = {978-1-4503-5640-4},
	url = {http://dl.acm.org/citation.cfm?doid=3184558.3191580},
	doi = {10.1145/3184558.3191580},
	abstract = {Recommender systems (RS) have seen widespread adoption across the Internet. However, by emphasizing personalization through the optimization of accuracy-focused metrics, over-personalization may emerge, with negative effects on the user experience. A countermeasure to the problem is to diversify recommendations. In this paper, we present a solution that addresses the problem in the context of a movie application domain. The solution enhances diversity on four related dimensions, namely global coverage, local coverage, novelty, and redundancy. The proposed solution is designed to diversify users profiles, modeled on categorical preferences, within the same group in the recommendation filtering. We evaluate our approach on the Movielens dataset and show that our algorithm yields better results compared to random selection distant neighbors and performs comparably to one of the current state of the art solutions.},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {Companion of the {The} {Web} {Conference} 2018 on {The} {Web} {Conference} 2018  - {WWW} '18},
	publisher = {ACM Press},
	author = {Zanitti, Michele and Kosta, Sokol and Sørensen, Jannick},
	year = {2018},
	keywords = {diverse, fatml, rec, xai},
	pages = {1381--1389},
}

@article{ExplainingExplanationsOverviewInterpretabilityb,
	title = {Explaining {Explanations}: {An} {Overview} of {Interpretability} of {Machine} {Learning}},
	shorttitle = {Explaining {Explanations}},
	url = {http://arxiv.org/abs/1806.00069},
	abstract = {There has recently been a surge of work in explanatory artiﬁcial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we provide our deﬁnition of explainability and show how it can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufﬁcient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artiﬁcial intelligence.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1806.00069 [cs, stat]},
	author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
	month = may,
	year = {2018},
	note = {arXiv: 1806.00069},
	keywords = {explainable, fatml, xai},
}

@inproceedings{NoveltyDiversityInformationRetrieval,
	address = {Singapore, Singapore},
	title = {Novelty and diversity in information retrieval evaluation},
	isbn = {978-1-60558-164-4},
	url = {http://portal.acm.org/citation.cfm?doid=1390334.1390446},
	doi = {10.1145/1390334.1390446},
	abstract = {Evaluation measures act as objective functions to be optimized by information retrieval systems. Such objective functions must accurately reﬂect user requirements, particularly when tuning IR systems and learning ranking functions. Ambiguity in queries and redundancy in retrieved documents are poorly reﬂected by current evaluation measures. In this paper, we present a framework for evaluation that systematically rewards novelty and diversity. We develop this framework into a speciﬁc evaluation measure, based on cumulative gain. We demonstrate the feasibility of our approach using a test collection based on the TREC question answering track.},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {Proceedings of the 31st annual international {ACM} {SIGIR} conference on {Research} and development in information retrieval - {SIGIR} '08},
	publisher = {ACM Press},
	author = {Clarke, Charles L.A. and Kolla, Maheedhar and Cormack, Gordon V. and Vechtomova, Olga and Ashkan, Azin and Büttcher, Stefan and MacKinnon, Ian},
	year = {2008},
	keywords = {fatml},
	pages = {659},
}

@article{UsingSentimentRepresentationLearning,
	title = {Using {Sentiment} {Representation} {Learning} to {Enhance} {Gender} {Classification} for {User} {Profiling}},
	url = {http://arxiv.org/abs/1810.06645},
	abstract = {User proﬁling means exploiting the technology of machine learning to predict attributes of users, such as demographic attributes, hobby attributes, preference attributes, etc. It’s a powerful data support of precision marketing. Existing methods mainly study network behavior, personal preferences, post texts to build user proﬁle. Through our data analysis of micro-blog, we ﬁnd that females show more positive and have richer emotions than males in online social platform. This diﬀerence is very conducive to the distinction between genders. Therefore, we argue that sentiment context is important as well for user proﬁling.This paper focuses on exploiting microblog user posts to predict one of the demographic labels: gender. We propose a Sentiment Representation Learning based Multi-Layer Perceptron(SRL-MLP) model to classify gender. First we build a sentiment polarity classiﬁer in advance by training Long Short-Term Memory(LSTM) model on e-commerce review corpus. Next we transfer sentiment representation to a basic MLP network. Last we conduct experiments on gender classiﬁcation by sentiment representation. Experimental results show that our approach can improve gender classiﬁcation accuracy by 5.53\%, from 84.20\% to 89.73\%.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1810.06645 [cs]},
	author = {Zheng, Yunpei and Li, Lin and Zhong, Luo and Zhang, Jianwei and Liu, Jinhang},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.06645},
	keywords = {kg},
}

@article{TaxonomySurveyDynamicGraph,
	title = {A {Taxonomy} and {Survey} of {Dynamic} {Graph} {Visualization}: {A} {Taxonomy} and {Survey} of {Dynamic} {Graph} {Visualization}},
	volume = {36},
	issn = {01677055},
	shorttitle = {A {Taxonomy} and {Survey} of {Dynamic} {Graph} {Visualization}},
	url = {http://doi.wiley.com/10.1111/cgf.12791},
	doi = {10.1111/cgf.12791},
	abstract = {Dynamic graph visualization focuses on the challenge of representing the evolution of relationships between entities in readable, scalable, and effective diagrams. This work surveys the growing number of approaches in this discipline. We derive a hierarchical taxonomy of techniques by systematically categorizing and tagging publications. While static graph visualizations are often divided into node-link and matrix representations, we identify the representation of time as the major distinguishing feature for dynamic graph visualizations: either graphs are represented as animated diagrams or as static charts based on a timeline. Evaluations of animated approaches focus on dynamic stability for preserving the viewer’s mental map or, in general, compare animated diagrams to timeline-based ones. A bibliographic analysis provides insights into the organization and development of the ﬁeld and its community. Finally, we identify and discuss challenges for future research. We also provide feedback from experts, collected with a questionnaire, which gives a broad perspective of these challenges and the current state of the ﬁeld.},
	language = {en},
	number = {1},
	urldate = {2019-04-17},
	journal = {Computer Graphics Forum},
	author = {Beck, Fabian and Burch, Michael and Diehl, Stephan and Weiskopf, Daniel},
	month = jan,
	year = {2017},
	keywords = {network, vis},
	pages = {133--159},
}

@inproceedings{PairFacEventAnalyticsDiscriminant,
	address = {Indianapolis, Indiana, USA},
	title = {{PairFac}: {Event} {Analytics} through {Discriminant} {Tensor} {Factorization}},
	isbn = {978-1-4503-4073-1},
	shorttitle = {{PairFac}},
	url = {http://dl.acm.org/citation.cfm?doid=2983323.2983837},
	doi = {10.1145/2983323.2983837},
	abstract = {The study of disaster events and their impact in the urban space has been traditionally conducted through manual collections and analysis of surveys, questionnaires and authority documents. While there have been increasingly rich troves of human behavioral data related to the events of interest, the ability to obtain hindsight following a disaster event has not been scaled up. In this paper, we propose a novel approach for analyzing events called PairFac. PairFac utilizes discriminant tensor analysis to automatically discover the impact of a major event from rich human behavioral data. Our method aims to (i) uncover the persistent patterns across multiple interrelated aspects of urban behavior (e.g., when, where and what citizens do in a city) and at the same time (ii) identify the salient changes following a potentially impactful event. We show the eﬀectiveness of PairFac in comparison with previous methods through extensive experiments. We also demonstrate the advantages of our approach through case studies with real-world traﬃc sensor data and social media streams surrounding the 2015 terrorist attacks in Paris. Our work has both methodological contributions in studying the impact of an external stimulus on a system as well as practical implications in the area of disaster event analysis and assessment.},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {Proceedings of the 25th {ACM} {International} on {Conference} on {Information} and {Knowledge} {Management} - {CIKM} '16},
	publisher = {ACM Press},
	author = {Wen, Xidao and Lin, Yu-Ru and Pelechrinis, Konstantinos},
	year = {2016},
	keywords = {kg},
	pages = {519--528},
}

@article{IntroductionTensorDecompositionsTheir,
	title = {Introduction to {Tensor} {Decompositions} and their {Applications} in {Machine} {Learning}},
	url = {http://arxiv.org/abs/1711.10781},
	abstract = {Tensors are multidimensional arrays of numerical values and therefore generalize matrices to multiple dimensions. While tensors rst emerged in the psychometrics community in the 20th century, they have since then spread to numerous other disciplines, including machine learning. Tensors and their decompositions are especially bene cial in unsupervised learning settings, but are gaining popularity in other sub-disciplines like temporal and multi-relational data analysis, too. The scope of this paper is to give a broad overview of tensors, their decompositions, and how they are used in machine learning. As part of this, we are going to introduce basic tensor concepts, discuss why tensors can be considered more rigid than matrices with respect to the uniqueness of their decomposition, explain the most important factorization algorithms and their properties, provide concrete examples of tensor decomposition applications in machine learning, conduct a case study on tensor-based estimation of mixture models, talk about the current state of research, and provide references to available software libraries.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1711.10781 [cs, stat]},
	author = {Rabanser, Stephan and Shchur, Oleksandr and Günnemann, Stephan},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.10781},
	keywords = {Statistics - Machine Learning, kg},
}

@article{RNNbowVisualizingLearningBackpropagation,
	title = {{RNNbow}: {Visualizing} {Learning} via {Backpropagation} {Gradients} in {Recurrent} {Neural} {Networks}},
	language = {en},
	author = {Cashman, Dylan and Patterson, Genevieve and Mosca, Abigail and Chang, Remco and Watts, Nathan and Robinson, Shannon},
	keywords = {fatml, rw-uu-vis-ml, vis},
	pages = {10},
}

@article{RepresentationLearningEntitiesDocuments,
	title = {Representation {Learning} of {Entities} and {Documents} from {Knowledge} {Base} {Descriptions}},
	url = {http://arxiv.org/abs/1806.02960},
	abstract = {In this paper, we describe TextEnt, a neural network model that learns distributed representations of entities and documents directly from a knowledge base (KB). Given a document in a KB consisting of words and entity annotations, we train our model to predict the entity that the document describes and map the document and its target entity close to each other in a continuous vector space. Our model is trained using a large number of documents extracted from Wikipedia. The performance of the proposed model is evaluated using two tasks, namely ﬁne-grained entity typing and multiclass text classiﬁcation. The results demonstrate that our model achieves stateof-the-art performance on both tasks. The code and the trained representations are made available online for further academic research.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1806.02960 [cs]},
	author = {Yamada, Ikuya and Shindo, Hiroyuki and Takefuji, Yoshiyasu},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.02960},
	keywords = {kg},
}

@inproceedings{LearningGeoSocialUserTopical,
	address = {Ann Arbor, MI, USA},
	title = {Learning {Geo}-{Social} {User} {Topical} {Profiles} with {Bayesian} {Hierarchical} {User} {Factorization}},
	isbn = {978-1-4503-5657-2},
	url = {http://dl.acm.org/citation.cfm?doid=3209978.3210044},
	doi = {10.1145/3209978.3210044},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {The 41st {International} {ACM} {SIGIR} {Conference} on {Research} \& {Development} in {Information} {Retrieval}  - {SIGIR} '18},
	publisher = {ACM Press},
	author = {Lu, Haokai and Niu, Wei and Caverlee, James},
	year = {2018},
	keywords = {kg},
	pages = {205--214},
}

@inproceedings{InterpretableExplanationsBlackBoxesa,
	address = {Venice},
	title = {Interpretable {Explanations} of {Black} {Boxes} by {Meaningful} {Perturbation}},
	isbn = {978-1-5386-1032-9},
	url = {http://ieeexplore.ieee.org/document/8237633/},
	doi = {10.1109/ICCV.2017.371},
	abstract = {As machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks “look” in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints.},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Fong, Ruth C. and Vedaldi, Andrea},
	month = oct,
	year = {2017},
	keywords = {explainable, fatml, xai},
	pages = {3449--3457},
}

@article{PeekBlackBoxExploring,
	title = {A peek into the black box: exploring classifiers by randomization},
	volume = {28},
	issn = {1384-5810, 1573-756X},
	shorttitle = {A peek into the black box},
	url = {http://link.springer.com/10.1007/s10618-014-0368-8},
	doi = {10.1007/s10618-014-0368-8},
	abstract = {Classiﬁers are often opaque and cannot easily be inspected to gain understanding of which factors are of importance. We propose an efﬁcient iterative algorithm to ﬁnd the attributes and dependencies used by any classiﬁer when making predictions. The performance and utility of the algorithm is demonstrated on two synthetic and 26 real-world datasets, using 15 commonly used learning algorithms to generate the classiﬁers. The empirical investigation shows that the novel algorithm is indeed able to ﬁnd groupings of interacting attributes exploited by the different classiﬁers. These groupings allow for ﬁnding similarities among classiﬁers for a single dataset as well as for determining the extent to which different classiﬁers exploit such interactions in general.},
	language = {en},
	number = {5-6},
	urldate = {2019-04-17},
	journal = {Data Mining and Knowledge Discovery},
	author = {Henelius, Andreas and Puolamäki, Kai and Boström, Henrik and Asker, Lars and Papapetrou, Panagiotis},
	month = sep,
	year = {2014},
	keywords = {fatml, xai},
	pages = {1503--1529},
}

@article{WhyShouldTrustYou,
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	url = {http://arxiv.org/abs/1602.04938},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classiﬁer in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the ﬂexibility of these methods by explaining diﬀerent models for text (e.g. random forests) and image classiﬁcation (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classiﬁer, and identifying why a classiﬁer should not be trusted.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1602.04938 [cs, stat]},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.04938},
	keywords = {explainable, fatml, instance, key, xai},
}

@article{CanonicalTensorDecompositionKnowledge,
	title = {Canonical {Tensor} {Decomposition} for {Knowledge} {Base} {Completion}},
	url = {http://arxiv.org/abs/1806.07297},
	abstract = {The problem of Knowledge Base Completion can be framed as a 3rd-order binary tensor completion problem. In this light, the Canonical Tensor Decomposition (CP) (Hitchcock, 1927) seems like a natural solution; however, current implementations of CP on standard Knowledge Base Completion benchmarks are lagging behind their competitors. In this work, we attempt to understand the limits of CP for knowledge base completion. First, we motivate and test a novel regularizer, based on tensor nuclear p-norms. Then, we present a reformulation of the problem that makes it invariant to arbitrary choices in the inclusion of predicates or their reciprocals in the dataset. These two methods combined allow us to beat the current state of the art on several datasets with a CP decomposition, and obtain even better results using the more advanced ComplEx model.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1806.07297 [cs, stat]},
	author = {Lacroix, Timothée and Usunier, Nicolas and Obozinski, Guillaume},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.07297},
	keywords = {Statistics - Machine Learning, kg},
}

@article{KnowledgeGraphCompletionComplex,
	title = {Knowledge {Graph} {Completion} via {Complex} {Tensor} {Factorization}},
	url = {http://arxiv.org/abs/1702.06879},
	abstract = {In statistical relational learning, knowledge graph completion deals with automatically understanding the structure of large knowledge graphs---labeled directed graphs---and predicting missing relationships---labeled edges. State-of-the-art embedding models propose different trade-offs between modeling expressiveness, and time and space complexity. We reconcile both expressiveness and complexity through the use of complex-valued embeddings and explore the link between such complex-valued embeddings and unitary diagonalization. We corroborate our approach theoretically and show that all real square matrices---thus all possible relation/adjacency matrices---are the real part of some unitarily diagonalizable matrix. This results opens the door to a lot of other applications of square matrices factorization. Our approach based on complex embeddings is arguably simple, as it only involves a Hermitian dot product, the complex counterpart of the standard dot product between real vectors, whereas other methods resort to more and more complicated composition functions to increase their expressiveness. The proposed complex embeddings are scalable to large data sets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.},
	language = {en},
	urldate = {2019-04-17},
	journal = {arXiv:1702.06879 [cs, math, stat]},
	author = {Trouillon, Théo and Dance, Christopher R. and Welbl, Johannes and Riedel, Sebastian and Gaussier, Éric and Bouchard, Guillaume},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.06879},
	keywords = {Statistics - Machine Learning, kg},
}

@inproceedings{LocalTopicDiscoveryBoosted,
	address = {Melbourne, Australia},
	title = {Local {Topic} {Discovery} via {Boosted} {Ensemble} of {Nonnegative} {Matrix} {Factorization}},
	isbn = {978-0-9992411-0-3},
	url = {https://www.ijcai.org/proceedings/2017/699},
	doi = {10.24963/ijcai.2017/699},
	abstract = {Nonnegative matrix factorization (NMF) has been increasingly popular for topic modeling of large-scale documents. However, the resulting topics often represent only general, thus redundant information about the data rather than minor, but potentially meaningful information to users. To tackle this problem, we propose a novel ensemble model of nonnegative matrix factorization for discovering high-quality local topics. Our method leverages the idea of an ensemble model to successively perform NMF given a residual matrix obtained from previous stages and generates a sequence of topic sets. The novelty of our method lies in the fact that it utilizes the residual matrix inspired by a state-of-the-art gradient boosting model and applies a sophisticated local weighting scheme on the given matrix to enhance the locality of topics, which in turn delivers high-quality, focused topics of interest to users.},
	language = {en},
	urldate = {2019-04-17},
	booktitle = {Proceedings of the {Twenty}-{Sixth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Suh, Sangho and Choo, Jaegul and Lee, Joonseok and Reddy, Chandan K.},
	month = aug,
	year = {2017},
	keywords = {kg},
	pages = {4944--4948},
}

@article{VisualBackPropEfficientVisualizationCNNs,
	title = {{VisualBackProp}: efficient visualization of {CNNs}},
	shorttitle = {{VisualBackProp}},
	url = {http://arxiv.org/abs/1611.05418},
	abstract = {This paper proposes a new method, that we call VisualBackProp, for visualizing which sets of pixels of the input image contribute most to the predictions made by the convolutional neural network (CNN). The method heavily hinges on exploring the intuition that the feature maps contain less and less irrelevant information to the prediction decision when moving deeper into the network. The technique we propose was developed as a debugging tool for CNN-based systems for steering self-driving cars and is therefore required to run in real-time, i.e. it was designed to require less computations than a forward propagation. This makes the presented visualization method a valuable debugging tool which can be easily used during both training and inference. We furthermore justify our approach with theoretical arguments and theoretically conﬁrm that the proposed method identiﬁes sets of input pixels, rather than individual pixels, that collaboratively contribute to the prediction. Our theoretical ﬁndings stand in agreement with the experimental results. The empirical evaluation shows the plausibility of the proposed approach on the road video data as well as in other applications and reveals that it compares favorably to the layer-wise relevance propagation approach, i.e. it obtains similar visualization results and simultaneously achieves order of magnitude speed-ups.},
	language = {en},
	urldate = {2019-04-20},
	journal = {arXiv:1611.05418 [cs]},
	author = {Bojarski, Mariusz and Choromanska, Anna and Choromanski, Krzysztof and Firner, Bernhard and Jackel, Larry and Muller, Urs and Zieba, Karol},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.05418},
	keywords = {fatml, xai},
}

@article{NewMethodVisualizeDeep,
	title = {A {New} {Method} to {Visualize} {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1603.02518},
	abstract = {We present a method for visualising the response of a deep neural network to a speciﬁc input. For image data for instance our method will highlight areas that provide evidence in favor of, and against choosing a certain class. The method overcomes several shortcomings of previous methods and provides great additional insight into the decision making process of convolutional networks, which is important both to improve models and to accelerate the adoption of such methods in e.g. medicine. In experiments on ImageNet data, we illustrate how the method works and can be applied in different ways to understand deep neural nets.},
	language = {en},
	urldate = {2019-04-20},
	journal = {arXiv:1603.02518 [cs]},
	author = {Zintgraf, Luisa M. and Cohen, Taco S. and Welling, Max},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.02518},
	keywords = {dl, fatml, xai},
}

@article{BuildingMoreExplainableArtificial,
	title = {Building {More} {Explainable} {Artificial} {Intelligence} with {Argumentation}},
	abstract = {Currently, much of machine learning is opaque, just like a “black box”. However, in order for humans to understand, trust and effectively manage the emerging AI systems, an AI needs to be able to explain its decisions and conclusions. In this paper, I propose an argumentation-based approach to explainable AI, which has the potential to generate more comprehensive explanations than existing approaches.},
	language = {en},
	author = {Zeng, Zhiwei and Miao, Chunyan and Leung, Cyril and Jih, Chin Jing},
	keywords = {fatml, xai},
	pages = {2},
}

@article{ExplainingInstanceClassificationsInteractions,
	title = {Explaining instance classifications with interactions of subsets of feature values},
	volume = {68},
	issn = {0169023X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169023X09000056},
	doi = {10.1016/j.datak.2009.01.004},
	abstract = {In this paper, we present a novel method for explaining the decisions of an arbitrary classiﬁer, independent of the type of classiﬁer. The method works at the instance level, decomposing the model’s prediction for an instance into the contributions of the attributes’ values. We use several artiﬁcial data sets and several diﬀerent types of models to show that the generated explanations reﬂect the decision-making properties of the explained model and approach the concepts behind the data set as the prediction quality of the model increases. The usefulness of the method is justiﬁed by a successful application on a real-world breast cancer recurrence prediction problem.},
	language = {en},
	number = {10},
	urldate = {2019-04-20},
	journal = {Data \& Knowledge Engineering},
	author = {Štrumbelj, E. and Kononenko, I. and Robnik Šikonja, M.},
	month = oct,
	year = {2009},
	keywords = {explainable, fatml, instance, xai},
	pages = {886--904},
}

@article{KnowledgeBasedTransferLearningExplanation,
	title = {Knowledge-{Based} {Transfer} {Learning} {Explanation}},
	abstract = {Machine learning explanation can signiﬁcantly boost machine learning’s application, but the usability of current methods is limited in human-centric explanation, especially for transfer learning, an important machine learning branch that aims at utilizing knowledge from one learning domain (i.e., a pair of dataset and prediction task) to enhance prediction model training in another learning domain. In this paper, we propose an ontology-based approach for human-centric explanation of transfer learning. Three kinds of knowledgebased explanatory evidence, with different granularities, including general factors, particular narrators and core contexts are ﬁrst proposed and then inferred with both local ontologies and external knowledge bases. The evaluation with US ﬂight data and DBpedia has presented their conﬁdence and availability in explaining the transferability of feature representation in ﬂight departure delay forecasting.},
	language = {en},
	author = {Chen, Jiaoyan and Lecue, Freddy and Pan, Jeff Z and Horrocks, Ian and Chen, Huajun},
	keywords = {explainable, fatml, xai},
	pages = {10},
}

@article{SequentialFeatureExplanationsAnomalya,
	title = {Sequential {Feature} {Explanations} for {Anomaly} {Detection}},
	volume = {13},
	issn = {15564681},
	url = {http://dl.acm.org/citation.cfm?doid=3301280.3230666},
	doi = {10.1145/3230666},
	language = {en},
	number = {1},
	urldate = {2019-04-20},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Siddiqui, Md Amran and Fern, Alan and Dietterich, Thomas G. and Wong, Weng-Keen},
	month = jan,
	year = {2019},
	keywords = {explainable, explanation, fatml, instance, sequential, xai},
	pages = {1--22},
}

@inproceedings{AdvancedLinguisticExplanationsClassifier,
	address = {Sofia, Bulgaria},
	title = {Advanced linguistic explanations of classifier decisions for users' annotation support},
	isbn = {978-1-5090-1354-8},
	url = {http://ieeexplore.ieee.org/document/7737455/},
	doi = {10.1109/IS.2016.7737455},
	abstract = {We propose several new concepts for providing enhanced explanations of classiﬁer decisions in linguistic (human readable) form. These are intended to help operators to better understand the decision process and support them during sample annotation to improve their certainty and consistency in successive labeling cycles. This is expected to lead to better, more consistent data sets (streams) for use in training and updating classiﬁers. The enhanced explanations are composed of 1) grounded reasons for classiﬁcation decisions, represented as linguistically readable fuzzy rules, 2) a classiﬁer’s level of uncertainty in relation to its decisions and possible alternative suggestions, 3) the degree of novelty of current samples and 4) the levels of impact of the input features on the current classiﬁcation response. The last of these are also used to reduce the lengths of the rules to a maximum of 3 to 4 antecedent parts to ensure readability for operators and users. The proposed techniques were embedded within an annotation GUI and applied to a realworld application scenario from the ﬁeld of visual inspection. The usefulness of the proposed linguistic explanations was evaluated based on experiments conducted with six operators. The results indicate that there is approximately an 80\% chance that operator/user labeling behavior improves signiﬁcantly when enhanced linguistic explanations are provided, whereas this chance drops to 10\% when only the classiﬁer responses are shown.},
	language = {en},
	urldate = {2019-04-20},
	booktitle = {2016 {IEEE} 8th {International} {Conference} on {Intelligent} {Systems} ({IS})},
	publisher = {IEEE},
	author = {Lughofer, Edwin and Richter, Roland and Neissl, Ulrich and Heidl, Wolfgang and Eitzinger, Christian and Radauer, Thomas},
	month = sep,
	year = {2016},
	keywords = {explainable, fatml, instance, key, xai},
	pages = {421--432},
}

@book{HumanMachineLearning,
	address = {New York, NY},
	title = {Human and machine learning},
	isbn = {978-3-319-90402-3},
	language = {en},
	publisher = {Springer Berlin Heidelberg},
	year = {2018},
	keywords = {fatml, iml, xai},
}

@article{MAGIXModelAgnosticGlobally,
	title = {{MAGIX}: {Model} {Agnostic} {Globally} {Interpretable} {Explanations}},
	shorttitle = {{MAGIX}},
	url = {http://arxiv.org/abs/1706.07160},
	abstract = {Explaining the behavior of a black box machine learning model at the instance level is useful for building trust. However, it is also important to understand how the model behaves globally. Such an understanding provides insight into both the data on which the model was trained and the patterns that it learned. We present here an approach that learns if-then rules to globally explain the behavior of black box machine learning models that have been used to solve classiﬁcation problems. The approach works by ﬁrst extracting conditions that were important at the instance level and then evolving rules through a genetic algorithm with an appropriate ﬁtness function. Collectively, these rules represent the patterns followed by the model for decisioning and are useful for understanding its behavior. We demonstrate the validity and usefulness of the approach by interpreting black box models created using publicly available data sets as well as a private digital marketing data set.},
	language = {en},
	urldate = {2019-04-20},
	journal = {arXiv:1706.07160 [cs]},
	author = {Puri, Nikaash and Gupta, Piyush and Agarwal, Pratiksha and Verma, Sukriti and Krishnamurthy, Balaji},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.07160},
	keywords = {explainable, fatml, global, key, xai},
}

@article{ConcretenessAbstractionEverydayExplanation,
	title = {Concreteness and abstraction in everyday explanation},
	volume = {24},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-017-1299-3},
	doi = {10.3758/s13423-017-1299-3},
	abstract = {A number of philosophers argue for the value of abstraction in explanation. According to these prescriptive theories, an explanation becomes superior when it leaves out details that make no difference to the occurrence of the event one is trying to explain (the explanandum). Abstract explanations are not frugal placeholders for improved, detailed future explanations but are more valuable than their concrete counterparts because they highlight the factors that do the causal work, the factors in the absence of which the explanandum would not occur. We present several experiments that test whether people follow this prescription (i.e., whether people prefer explanations with abstract difference makers over explanations with concrete details and explanations that omit descriptively accurate but causally irrelevant information). Contrary to the prescription, we found a preference for concreteness and detail. Participants rated explanations with concrete details higher than their abstract counterparts and in many cases they did not penalize the presence of causally irrelevant details. Nevertheless, causality still constrained participants’ preferences: They downgraded concrete explanations that did not communicate the critical causal properties.},
	language = {en},
	number = {5},
	urldate = {2019-04-20},
	journal = {Psychonomic Bulletin \& Review},
	author = {Bechlivanidis, Christos and Lagnado, David A. and Zemla, Jeffrey C. and Sloman, Steven},
	month = oct,
	year = {2017},
	keywords = {everyday, explainable, explanation, fatml, key, theory, xai},
	pages = {1451--1464},
}

@article{ContrastiveExplanationStructuralModelApproach,
	title = {Contrastive {Explanation}: {A} {Structural}-{Model} {Approach}},
	shorttitle = {Contrastive {Explanation}},
	url = {http://arxiv.org/abs/1811.03163},
	abstract = {The topic of causal explanation in artiﬁcial intelligence has gathered interest in recent years as researchers and practitioners aim to increase trust and understanding of intelligent decision-making and action. While diﬀerent sub-ﬁelds have looked into this problem with a sub-ﬁeld-speciﬁc view, there are few models that aim to capture explanation in AI more generally. One general model is based on structural causal models. It deﬁnes an explanation as a fact that, if found to be true, would constitute an actual cause of a speciﬁc event. However, research in philosophy and social sciences shows that explanations are contrastive: that is, when people ask for an explanation of an event – the fact — they (sometimes implicitly) are asking for an explanation relative to some contrast case; that is, “Why P rather than Q ?”. In this paper, we extend the structural causal model approach to deﬁne two complementary notions of contrastive explanation, and demonstrate them on two classical AI problems: classiﬁcation and planning. We believe that this model can be used to deﬁne contrastive explanation of other subﬁeld-speciﬁc AI models.},
	language = {en},
	urldate = {2019-04-20},
	journal = {arXiv:1811.03163 [cs]},
	author = {Miller, Tim},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.03163},
	keywords = {explainable, fatml, key, theory, xai},
}

@article{DesigningTheoryDrivenUserCentricExplainable,
	title = {Designing {Theory}-{Driven} {User}-{Centric} {Explainable} {AI}},
	abstract = {From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical applicationspecific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building humancentered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development.},
	language = {en},
	author = {Wang, Danding and Yang, Qian and Abdul, Ashraf and Lim, Brian Y},
	keywords = {explainable, fatml, key, survey, xai},
	pages = {15},
}

@article{ExplainingClassificationsIndividualInstances,
	title = {Explaining {Classifications} {For} {Individual} {Instances}},
	volume = {20},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/4407709/},
	doi = {10.1109/TKDE.2007.190734},
	abstract = {We present a method for explaining predictions for individual instances. The presented approach is general and can be used with all classiﬁcation models that output probabilities. It is based on decomposition of a model’s predictions on individual contributions of each attribute. Our method works for so called black box models such as support vector machines, neural networks, and nearest neighbor algorithms as well as for ensemble methods, such as boosting and random forests. We demonstrate that the generated explanations closely follow the learned models and present a visualization technique which shows the utility of our approach and enables the comparison of different prediction methods.},
	language = {en},
	number = {5},
	urldate = {2019-04-20},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Robnik-Sikonja, M. and Kononenko, I.},
	month = may,
	year = {2008},
	keywords = {explainable, fatml, instance, key, xai},
	pages = {589--600},
}

@article{LogicCounterfactualAnalysisCasestudy,
	title = {The logic of counterfactual analysis in case-study explanation},
	volume = {70},
	issn = {00071315},
	url = {http://doi.wiley.com/10.1111/1468-4446.12340},
	doi = {10.1111/1468-4446.12340},
	abstract = {In this paper, we develop a set-theoretic and possible worlds approach to counterfactual analysis in case-study explanation. Using this approach, we ﬁrst consider four kinds of counterfactuals: necessary condition counterfactuals, SUIN condition counterfactuals, sufﬁcient condition counterfactuals, and INUS condition counterfactuals. We explore the distinctive causal claims entailed in each, and conclude that necessary condition and SUIN condition counterfactuals are the most useful types for hypothesis assessment in case-study research. We then turn attention to the development of a rigorous understanding of the ‘minimal-rewrite’ rule, linking this rule to insights from set theory about the relative importance of necessary conditions. We show why, logically speaking, a comparative analysis of two necessary condition counterfactuals will tend to favour small events and contingent happenings. A third section then presents new tools for specifying the level of generality of the events in a counterfactual. We show why and how the goals of formulating empirically important versus empirically plausible counterfactuals stand in tension with one another. Finally, we use our framework to link counterfactual analysis to causal sequences, which in turn provides advantages for conducting counterfactual projections.},
	language = {en},
	number = {1},
	urldate = {2019-04-20},
	journal = {The British Journal of Sociology},
	author = {Mahoney, James and Barrenechea, Rodrigo},
	month = jan,
	year = {2019},
	keywords = {counterfactual, explainable, fatml, xai},
	pages = {306--338},
}

@inproceedings{GlassBoxExplainingAIDecisions,
	address = {Stockholm, Sweden},
	title = {Glass-{Box}: {Explaining} {AI} {Decisions} {With} {Counterfactual} {Statements} {Through} {Conversation} {With} a {Voice}-enabled {Virtual} {Assistant}},
	isbn = {978-0-9992411-2-7},
	shorttitle = {Glass-{Box}},
	url = {https://www.ijcai.org/proceedings/2018/865},
	doi = {10.24963/ijcai.2018/865},
	abstract = {The prevalence of automated decision making, inﬂuencing important aspects of our lives – e.g., school admission, job market, insurance and banking – has resulted in increasing pressure from society and regulators to make this process more transparent and ensure its explainability, accountability and fairness. We demonstrate a prototype voiceenabled device, called Glass-Box, which users can question to understand automated decisions and identify the underlying model’s biases and errors. Our system explains algorithmic predictions with class-contrastive counterfactual statements (e.g., “Had a number of conditions been different:. . . the prediction would change. . . ”), which show a difference in a particular scenario that causes an algorithm to “change its mind”. Such explanations do not require any prior technical knowledge to understand, hence are suitable for a lay audience, who interact with the system in a natural way – through an interactive dialogue. We demonstrate the capabilities of the device by allowing users to impersonate a loan applicant who can question the system to understand the automated decision that he received.},
	language = {en},
	urldate = {2019-04-20},
	booktitle = {Proceedings of the {Twenty}-{Seventh} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Sokol, Kacper and Flach, Peter},
	month = jul,
	year = {2018},
	keywords = {explainable, fatml, key, xai},
	pages = {5868--5870},
}

@article{MeaningfulExplanationsBlackBox,
	title = {Meaningful {Explanations} of {Black} {Box} {AI} {Decision} {Systems}},
	abstract = {Black box AI systems for automated decision making, often based on machine learning over (big) data, map a user’s features into a class or a score without exposing the reasons why. This is problematic not only for lack of transparency, but also for possible biases inherited by the algorithms from human prejudices and collection artifacts hidden in the training data, which may lead to unfair or wrong decisions. We focus on the urgent open challenge of how to construct meaningful explanations of opaque AI/ML systems, introducing the localto-global framework for black box explanation, articulated along three lines: (i) the language for expressing explanations in terms of logic rules, with statistical and causal interpretation; (ii) the inference of local explanations for revealing the decision rationale for a speciﬁc case, by auditing the black box in the vicinity of the target instance; (iii), the bottom-up generalization of many local explanations into simple global ones, with algorithms that optimize for quality and comprehensibility. We argue that the local-ﬁrst approach opens the door to a wide variety of alternative solutions along different dimensions: a variety of data sources (relational, text, images, etc.), a variety of learning problems (multi-label classiﬁcation, regression, scoring, ranking), a variety of languages for expressing meaningful explanations, a variety of means to audit a black box.},
	language = {en},
	author = {Pedreschi, D and Giannotti, F and Guidotti, R and Monreale, A and Ruggieri, S and Turini, F},
	keywords = {explainable, explanation, fatml, local-to-global, xai},
	pages = {5},
}

@article{ExplainingExplanationExplainableAi,
	title = {Explaining {Explanation} {For} “{Explainable} {Ai}”},
	volume = {62},
	issn = {1541-9312},
	url = {http://journals.sagepub.com/doi/10.1177/1541931218621047},
	doi = {10.1177/1541931218621047},
	abstract = {What makes for an explanation of "black box" AI systems such as Deep Nets? We reviewed the pertinent literatures on explanation and derived key ideas. This set the stage for our empirical inquiries, which include conceptual cognitive modeling, the analysis of a corpus of cases of "naturalistic explanation" of computational systems, computational cognitive modeling, and the development of measures for performance evaluation. The purpose of our work is to contribute to the program of research on “Explainable AI.” In this report we focus on our initial synthetic modeling activities and the development of measures for the evaluation of explainability in human-machine work systems.},
	language = {en},
	number = {1},
	urldate = {2019-04-20},
	journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
	author = {Hoffman, Robert R. and Klein, Gary and Mueller, Shane T.},
	month = sep,
	year = {2018},
	keywords = {explainable, fatml, key, xai},
	pages = {197--201},
}

@article{NaturalLanguageInteractionExplainable,
	title = {Natural {Language} {Interaction} with {Explainable} {AI} {Models}},
	url = {http://arxiv.org/abs/1903.05720},
	abstract = {This paper presents an explainable AI (XAI) system that provides explanations for its predictions. The system consists of two key components – namely, the prediction And-Or graph (AOG) model for recognizing and localizing concepts of interest in input data, and the XAI model for providing explanations to the user about the AOG’s predictions. In this work, we focus on the XAI model speciﬁed to interact with the user in natural language, whereas the AOG’s predictions are considered given and represented by the corresponding parse graphs (pg’s) of the AOG. Our XAI model takes pg’s as input and provides answers to the user’s questions using the following types of reasoning: direct evidence (e.g., detection scores), part-based inference (e.g., detected parts provide evidence for the concept asked), and other evidences from spatiotemporal context (e.g., constraints from the spatiotemporal surround). We identify several correlations between user’s questions and the XAI answers using Youtube Action dataset.},
	language = {en},
	urldate = {2019-04-20},
	journal = {arXiv:1903.05720 [cs]},
	author = {Akula, Arjun R. and Todorovic, Sinisa and Chai, Joyce Y. and Zhu, Song-Chun},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.05720},
	keywords = {explainable, explanation, fatml, question, text, xai},
}

@article{LocalRuleBasedExplanationsBlack,
	title = {Local {Rule}-{Based} {Explanations} of {Black} {Box} {Decision} {Systems}},
	url = {http://arxiv.org/abs/1805.10820},
	abstract = {The recent years have witnessed the rise of accurate but obscure decision systems which hide the logic of their internal decision processes to the users. The lack of explanations for the decisions of black box systems is a key ethical issue, and a limitation to the adoption of machine learning components in socially sensitive and safety-critical contexts. In this paper we focus on the problem of black box outcome explanation, i.e., explaining the reasons of the decision taken on a specific instance. We propose LORE, an agnostic method able to provide interpretable and faithful explanations. LORE first leans a local interpretable predictor on a synthetic neighborhood generated by a genetic algorithm. Then it derives from the logic of the local interpretable predictor a meaningful explanation consisting of: a decision rule, which explains the reasons of the decision; and a set of counterfactual rules, suggesting the changes in the instance’s features that lead to a different outcome. Wide experiments show that LORE outperforms existing methods and baselines both in the quality of explanations and in the accuracy in mimicking the black box.},
	language = {en},
	urldate = {2019-04-20},
	journal = {arXiv:1805.10820 [cs]},
	author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Pedreschi, Dino and Turini, Franco and Giannotti, Fosca},
	month = may,
	year = {2018},
	note = {arXiv: 1805.10820},
	keywords = {explainable, explanation, fatml, local, xai},
}

@article{InterpretableCreditApplicationPredictions,
	title = {Interpretable {Credit} {Application} {Predictions} {With} {Counterfactual} {Explanations}},
	url = {http://arxiv.org/abs/1811.05245},
	abstract = {We predict credit applications with off-the-shelf, interchangeable black-box classiﬁers and we explain single predictions with counterfactual explanations. Counterfactual explanations expose the minimal changes required on the input data to obtain a different result e.g., approved vs rejected application. Despite their effectiveness, counterfactuals are mainly designed for changing an undesired outcome of a prediction i.e. loan rejected. Counterfactuals, however, can be difﬁcult to interpret, especially when a high number of features are involved in the explanation. Our contribution is two-fold: i) we propose positive counterfactuals, i.e. we adapt counterfactual explanations to also explain accepted loan applications, and ii) we propose two weighting strategies to generate more interpretable counterfactuals. Experiments on the HELOC loan applications dataset show that our contribution outperforms the baseline counterfactual generation strategy, by leading to smaller and hence more interpretable counterfactuals.},
	language = {en},
	urldate = {2019-04-20},
	journal = {arXiv:1811.05245 [cs]},
	author = {Grath, Rory Mc and Costabello, Luca and Van, Chan Le and Sweeney, Paul and Kamiab, Farbod and Shen, Zhao and Lecue, Freddy},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.05245},
	keywords = {counterfactual, explainable, explanation, fatml, xai},
}

@incollection{ExplanationsNonAcceptableArguments,
	address = {Cham},
	title = {On {Explanations} for {Non}-{Acceptable} {Arguments}},
	volume = {9524},
	isbn = {978-3-319-28459-0 978-3-319-28460-6},
	url = {http://link.springer.com/10.1007/978-3-319-28460-6_7},
	abstract = {Argumentation has the unique advantage of giving explanations to reasoning processes and results. Recent work studied how to give explanations for arguments that are acceptable, in terms of arguments defending it. This paper studies the counterpart of this problem by formalising explanations for arguments that are not acceptable. We give two diﬀerent views (an argument-view and an attack-view) in explaining the non-acceptability of an argument and show the computation of explanations with debate trees.},
	language = {en},
	urldate = {2019-04-20},
	booktitle = {Theory and {Applications} of {Formal} {Argumentation}},
	publisher = {Springer International Publishing},
	author = {Fan, Xiuyi and Toni, Francesca},
	editor = {Black, Elizabeth and Modgil, Sanjay and Oren, Nir},
	year = {2015},
	doi = {10.1007/978-3-319-28460-6_7},
	keywords = {explainable, explanation, fatml, non-acceptable, xai},
	pages = {112--127},
}

@inproceedings{DiscriminativeFeaturesIdentifyingInterpreting,
	address = {Chicago, IL},
	title = {Discriminative features for identifying and interpreting outliers},
	isbn = {978-1-4799-2555-1},
	url = {http://ieeexplore.ieee.org/document/6816642/},
	doi = {10.1109/ICDE.2014.6816642},
	abstract = {We consider the problem of outlier detection and interpretation. While most existing studies focus on the ﬁrst problem, we simultaneously address the equally important challenge of outlier interpretation. We propose an algorithm that uncovers outliers in subspaces of reduced dimensionality in which they are well discriminated from regular objects while at the same time retaining the natural local structure of the original data to ensure the quality of outlier explanation. Our algorithm takes a mathematically appealing approach from the spectral graph embedding theory and we show that it achieves the globally optimal solution for the objective of subspace learning. By using a number of real-world datasets, we demonstrate its appealing performance not only w.r.t. the outlier detection rate but also w.r.t. the discriminative human-interpretable features. This is the ﬁrst approach to exploit discriminative features for both outlier detection and interpretation, leading to better understanding of how and why the hidden outliers are exceptional.},
	language = {en},
	urldate = {2019-04-20},
	booktitle = {2014 {IEEE} 30th {International} {Conference} on {Data} {Engineering}},
	publisher = {IEEE},
	author = {{Xuan Hong Dang} and Assent, Ira and Ng, Raymond T. and Zimek, Arthur and Schubert, Erich},
	month = mar,
	year = {2014},
	keywords = {explainable, fatml, xai},
	pages = {88--99},
}

@article{TwoFormsExplanationsComputational,
	title = {Two {Forms} of {Explanations} in {Computational} {Assumption}-based {Argumentation} ({Extended} {Abstract})},
	abstract = {Table 1: Student Candidate Admission Data.},
	language = {en},
	author = {Fan, Xiuyi and Liu, Siyuan and Zhang, Huiguo and Miao, Chunyan and Leung, Cyril},
	keywords = {explainable, fatml, xai},
	pages = {3},
}

@article{ExplainableMultiattributeDecisionModel,
	title = {An explainable multi-attribute decision model based on argumentation},
	volume = {117},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417418306158},
	doi = {10.1016/j.eswa.2018.09.038},
	abstract = {We present a multi-attribute decision model and a method for explaining the decisions it recommends based on an argumentative reformulation of the model. Speciﬁcally, (i) we deﬁne a notion of best (i.e., minimally redundant) decisions amounting to achieving as many goals as possible and exhibiting as few redundant attributes as possible, and (ii) we generate explanations for why a decision is best or better than or as good as another, using a mapping between the given decision model and an argumentation framework, such that best decisions correspond to admissible sets of arguments. Concretely, natural language explanations are generated automatically from dispute trees sanctioning the admissibility of arguments. Throughout, we illustrate the power of our approach within a legal reasoning setting, where best decisions amount to past cases that are most similar to a given new, open case. Finally, we conduct an empirical evaluation of our method with legal practitioners, conﬁrming that our method is effective for the choice of most similar past cases and helpful to understand automatically generated recommendations .},
	language = {en},
	urldate = {2019-04-20},
	journal = {Expert Systems with Applications},
	author = {Zhong, Qiaoting and Fan, Xiuyi and Luo, Xudong and Toni, Francesca},
	month = mar,
	year = {2019},
	keywords = {explainable, fatml, xai},
	pages = {42--61},
}

@article{HowExplainIndividualClassificationb,
	title = {How to {Explain} {Individual} {Classiﬁcation} {Decisions}},
	abstract = {After building a classiﬁer with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data. Thus, we get an answer to the question what is the most likely label of a given unseen data point. However, most methods will provide no answer why the model predicted a particular label for a single instance and what features were most inﬂuential for that particular instance. The only method that is currently able to provide such explanations are decision trees. This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of any classiﬁcation method.},
	language = {en},
	author = {Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja},
	keywords = {explainable, fatml, xai},
	pages = {29},
}

@article{ExplanationScience,
	title = {Explanation in {Science}},
	abstract = {Scientiﬁc explanation is an important goal of scientiﬁc practise. Philosophers have proposed a striking diversity of seemingly incompatible accounts of explanation, from deductive-nomological to statistical relevance, uniﬁcation, pragmatic, causalmechanical, mechanistic, causal intervention, asymptotic, and model-based accounts. In this dissertation I apply two novel methods to reexamine our evidence about scientiﬁc explanation in practise and thereby address the fragmentation of philosophical accounts. I start by collecting a data set of 781 articles from one year of the journal Science. Using automated text mining techniques I measure the frequency and distribution of several groups of philosophically interesting words, such as “explain”, “cause”, “evidence”, “theory”, “law”, “mechanism”, and “model”. I show that “explain” words are much more common in scientiﬁc writing than in other genres, occurring in roughly half of all articles, and that their use is very often qualiﬁed or negated. These results about the use of words complement traditional conceptual analysis. Next I use random samples from the data set to develop a large number of small case studies across a wide range of scientiﬁc disciplines. I use a sample of “explain” sentences to develop and defend a new general philosophical account of scientiﬁc explanation, and then test my account against a larger set of randomly sampled sentences and abstracts. Five coarse categories can classify the explanans and explananda of my cases: data, entities, kinds, models, and theories. The pair of the categories of the explanans and explanandum indicates the “form” of an explanation. The explain-relation supports counterfactual reasoning about the dependence of qualities of the explanandum on qualities of the explanans. But for each form there is a diﬀerent “core relation” between explanans and explanandum that supports the explain-relation. Causation, modelling, and argument are the core relations for diﬀerent forms of scientiﬁc explanation between diﬀerent categories of explanans and explananda. This ﬂexibility allows me to resolve some of the fragmentation in the philosophical literature. I provide empirical evidence to show that my general philosophical account successfully describes a wide range of scientiﬁc practise across a large number of scientiﬁc disciplines.},
	language = {en},
	author = {Overton, James A},
	keywords = {fatml, key},
	pages = {288},
}

@article{ChoosingPredictionExplanationPsychologya,
	title = {Choosing {Prediction} {Over} {Explanation} in {Psychology}: {Lessons} {From} {Machine} {Learning}},
	volume = {12},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Choosing {Prediction} {Over} {Explanation} in {Psychology}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691617693393},
	doi = {10.1177/1745691617693393},
	abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology’s near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
	language = {en},
	number = {6},
	urldate = {2019-05-23},
	journal = {Perspectives on Psychological Science},
	author = {Yarkoni, Tal and Westfall, Jacob},
	month = nov,
	year = {2017},
	pages = {1100--1122},
}

@article{ExplainableRecommendationSurveyNewb,
	title = {Explainable {Recommendation}: {A} {Survey} and {New} {Perspectives}},
	shorttitle = {Explainable {Recommendation}},
	url = {http://arxiv.org/abs/1804.11192},
	abstract = {Explainable Recommendation refers to the personalized recommendation algorithms that address the problem of why - they not only provide users with the recommendations, but also provide explanations to make the user or system designer aware of why such items are recommended. In this way, it helps to improve the effectiveness, efficiency, persuasiveness, and user satisfaction of recommendation systems. In recent years, a large number of explainable recommendation approaches -- especially model-based explainable recommendation algorithms -- have been proposed and adopted in real-world systems. In this survey, we review the work on explainable recommendation that has been published in or before the year of 2018. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation itself in terms of three aspects: 1) We provide a chronological research line of explanations in recommender systems, including the user study approaches in the early years, as well as the more recent model-based approaches. 2) We provide a taxonomy for explainable recommendation algorithms, including user-based, item-based, model-based, and post-model explanations. 3) We summarize the application of explainable recommendation in different recommendation tasks, including product recommendation, social recommendation, POI recommendation, etc. We devote a section to discuss the explanation perspectives in the broader IR and machine learning settings, as well as their relationship with explainable recommendation research. We end the survey by discussing potential future research directions to promote the explainable recommendation research area.},
	language = {en},
	urldate = {2019-05-23},
	journal = {arXiv:1804.11192 [cs]},
	author = {Zhang, Yongfeng and Chen, Xu},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.11192},
}

@article{AuditingTransparencyContentPersonalizationa,
	title = {Auditing for {Transparency} in {Content} {Personalization} {Systems}},
	abstract = {Do we have a right to transparency when we use content personalization systems? Building on prior work in discrimination detection in data mining, I propose algorithm auditing as a compatible ethical duty for providers of content personalization systems to maintain the transparency of political discourse. I explore barriers to auditing that reveal the practical limitations on the ethical duties of service providers. Content personalization systems can function opaquely and resist auditing. However, the belief that highly complex algorithms, such as bots using machine learning, are incomprehensible to human users should not be an excuse to surrender high quality political discourse. Auditing is recommended as a way to map and redress algorithmic political exclusion in practice. However, the opacity of algorithmic decision making poses a significant challenge to the implementation of auditing.},
	language = {en},
	author = {Mittelstadt, Brent},
	year = {2016},
	pages = {12},
}

@article{CounterfactualFairnessTextClassification,
	title = {Counterfactual {Fairness} in {Text} {Classification} through {Robustness}},
	url = {http://arxiv.org/abs/1809.10610},
	abstract = {In this paper, we study counterfactual fairness in text classiﬁcation, which asks the question: How would the prediction change if the sensitive attribute referenced in the example were different? Toxicity classiﬁers demonstrate a counterfactual fairness issue by predicting that “Some people are gay” is toxic while “Some people are straight” is nontoxic. We offer a metric, counterfactual token fairness (CTF), for measuring this particular form of fairness in text classiﬁers, and describe its relationship with group fairness. Further, we offer three approaches, blindness, counterfactual augmentation, and counterfactual logit pairing (CLP), for optimizing counterfactual token fairness during training, bridging the robustness and fairness literature. Empirically, we ﬁnd that blindness and CLP address counterfactual token fairness. The methods do not harm classiﬁer performance, and have varying tradeoffs with group fairness. These approaches, both for measurement and optimization, provide a new path forward for addressing fairness concerns in text classiﬁcation.},
	language = {en},
	urldate = {2019-04-20},
	journal = {arXiv:1809.10610 [cs, stat]},
	author = {Garg, Sahaj and Perot, Vincent and Limtiaco, Nicole and Taly, Ankur and Chi, Ed H. and Beutel, Alex},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.10610},
	keywords = {explainable, fair, fatml},
}

@article{FairnessDecisionMakingCausalExplanation,
	title = {Fairness in {Decision}-{Making} -- {The} {Causal} {Explanation} {Formula}},
	abstract = {AI plays an increasingly prominent role in society since decisions that were once made by humans are now delegated to automated systems. These systems are currently in charge of deciding bank loans, criminals’ incarceration, and the hiring of new employees, and it’s not difﬁcult to envision that they will in the future underpin most of the decisions in society. Despite the high complexity entailed by this task, there is still not much understanding of basic properties of such systems. For instance, we currently cannot detect (neither explain nor correct) whether an AI system is operating fairly (i.e., is abiding by the decision-constraints agreed by society) or it is reinforcing biases and perpetuating a preceding prejudicial practice. Issues of discrimination have been discussed extensively in legal circles, but there exists still not much understanding of the formal conditions that a system must adhere to be deemed fair. In this paper, we use the language of structural causality (Pearl, 2000) to ﬁll in this gap. We start by introducing three new ﬁne-grained measures of transmission of change from stimulus to effect, which we called counterfactual direct (Ctf-DE), indirect (Ctf-IE), and spurious (Ctf-SE) effects. We then derive the causal explanation formula, which allows the AI designer to quantitatively evaluate fairness and explain the total observed disparity of decisions through different discriminatory mechanisms. We apply these results to various discrimination analysis tasks and run extensive simulations, including detection, evaluation, and optimization of decision-making under fairness constraints. We conclude studying the trade-off between different types of fairness criteria (outcome and procedural), and provide a quantitative approach to policy implementation and the design of fair decision-making systems.},
	language = {en},
	author = {Zhang, Junzhe and Bareinboim, Elias},
	keywords = {explainable, fair, fatml},
	pages = {9},
}

@article{AccountabilityAILawRole,
	title = {Accountability of {AI} {Under} the {Law}: {The} {Role} of {Explanation}},
	shorttitle = {Accountability of {AI} {Under} the {Law}},
	url = {http://arxiv.org/abs/1711.01134},
	abstract = {The ubiquity of systems using artiﬁcial intelligence or “AI” has brought increasing attention to how those systems should be regulated. The choice of how to regulate AI systems will require care. AI systems have the potential to synthesize large amounts of data, allowing for greater levels of personalization and precision than ever before—applications range from clinical decision support to autonomous driving and predictive policing. That said, our AIs continue to lag in common sense reasoning [McCarthy, 1960], and thus there exist legitimate concerns about the intentional and unintentional negative consequences of AI systems [Bostrom, 2003, Amodei et al., 2016, Sculley et al., 2014].},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1711.01134 [cs, stat]},
	author = {Doshi-Velez, Finale and Kortz, Mason and Budish, Ryan and Bavitz, Chris and Gershman, Sam and O'Brien, David and Schieber, Stuart and Waldo, James and Weinberger, David and Wood, Alexandra},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.01134},
	keywords = {explainable, explanation, fatml, xai},
}

@article{HumanLoopNewDirections,
	title = {The human is the loop: new directions for visual analytics},
	volume = {43},
	issn = {0925-9902, 1573-7675},
	shorttitle = {The human is the loop},
	url = {http://link.springer.com/10.1007/s10844-014-0304-9},
	doi = {10.1007/s10844-014-0304-9},
	abstract = {Visual analytics is the science of marrying interactive visualizations and analytic algorithms to support exploratory knowledge discovery in large datasets. We argue for a shift from a ‘human in the loop’ philosophy for visual analytics to a ‘human is the loop’ viewpoint, where the focus is on recognizing analysts’ work processes, and seamlessly fitting analytics into that existing interactive process. We survey a range of projects that provide visual analytic support contextually in the sensemaking loop, and outline a research agenda along with future challenges.},
	language = {en},
	number = {3},
	urldate = {2019-05-29},
	journal = {Journal of Intelligent Information Systems},
	author = {Endert, Alex and Hossain, M. Shahriar and Ramakrishnan, Naren and North, Chris and Fiaux, Patrick and Andrews, Christopher},
	month = dec,
	year = {2014},
	keywords = {fatml, key, xai},
	pages = {411--435},
}

@article{ContrastiveExplanationsLocalFoil,
	title = {Contrastive {Explanations} with {Local} {Foil} {Trees}},
	url = {http://arxiv.org/abs/1806.07470},
	abstract = {Recent advances in interpretable Machine Learning (iML) and eXplainable AI (XAI) construct explanations based on the importance of features in classification tasks. However, in a high-dimensional feature space this approach may become unfeasible without restraining the set of important features. We propose to utilize the human tendency to ask questions like "Why this output (the fact) instead of that output (the foil)?" to reduce the number of features to those that play a main role in the asked contrast. Our proposed method utilizes locally trained one-versus-all decision trees to identify the disjoint set of rules that causes the tree to classify data points as the foil and not as the fact. In this study we illustrate this approach on three benchmark classification tasks.},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1806.07470 [cs, stat]},
	author = {van der Waa, Jasper and Robeer, Marcel and van Diggelen, Jurriaan and Brinkhuis, Matthieu and Neerincx, Mark},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.07470},
	keywords = {contrastive, explainable, fatml, key, local, xai},
}

@article{ChoosingPredictionExplanationPsychology,
	title = {Choosing {Prediction} {Over} {Explanation} in {Psychology}: {Lessons} {From} {Machine} {Learning}},
	volume = {12},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Choosing {Prediction} {Over} {Explanation} in {Psychology}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691617693393},
	doi = {10.1177/1745691617693393},
	abstract = {Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology’s near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.},
	language = {en},
	number = {6},
	urldate = {2019-05-29},
	journal = {Perspectives on Psychological Science},
	author = {Yarkoni, Tal and Westfall, Jacob},
	month = nov,
	year = {2017},
	keywords = {explainable, fatml, hci, key, theory, xai},
	pages = {1100--1122},
}

@article{AnalysisMachineHumanAnalyticsClassification,
	title = {An {Analysis} of {Machine}- and {Human}-{Analytics} in {Classification}},
	volume = {23},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/7539314/},
	doi = {10.1109/TVCG.2016.2598829},
	abstract = {In this work, we present a study that traces the technical and cognitive processes in two visual analytics applications to a common theoretic model of soft knowledge that may be added into a visual analytics process for constructing a decision-tree model. Both case studies involved the development of classiﬁcation models based on the “bag of features” approach. Both compared a visual analytics approach using parallel coordinates with a machine-learning approach using information theory. Both found that the visual analytics approach had some advantages over the machine learning approach, especially when sparse datasets were used as the ground truth. We examine various possible factors that may have contributed to such advantages, and collect empirical evidence for supporting the observation and reasoning of these factors. We propose an information-theoretic model as a common theoretic basis to explain the phenomena exhibited in these two case studies. Together we provide interconnected empirical and theoretical evidence to support the usefulness of visual analytics.},
	language = {en},
	number = {1},
	urldate = {2019-05-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Tam, Gary K. L. and Kothari, Vivek and Chen, Min},
	month = jan,
	year = {2017},
	keywords = {fatml, iml, xai},
	pages = {71--80},
}

@inproceedings{XRankExplainableRankingComplexa,
	address = {Torino, Italy},
	title = {X-{Rank}: {Explainable} {Ranking} in {Complex} {Multi}-{Layered} {Networks}},
	isbn = {978-1-4503-6014-2},
	shorttitle = {X-{Rank}},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3269224},
	doi = {10.1145/3269206.3269224},
	abstract = {In this paper we present a web-based prototype for an explainable ranking algorithm in multi-layered networks, incorporating both network topology and knowledge information. While traditional ranking algorithms such as PageRank and HITS are important tools for exploring the underlying structure of networks, they have two fundamental limitations in their efforts to generate high accuracy rankings. First, they are primarily focused on network topology, leaving out additional sources of information (e.g. attributes, knowledge). Secondly, most algorithms do not provide explanations to the end-users on why the algorithm gives the specific ranking results, hindering the usability of the ranking information. We developed X-Rank, an explainable ranking tool, to address these drawbacks. Empirical results indicate that our explainable ranking method not only improves ranking accuracy, but facilitates user understanding of the ranking by exploring the top influential elements in multi-layered networks. The web-based prototype (X-Rank: http://www.x-rank.net) is currently online—we believe it will assist both researchers and practitioners looking to explore and exploit multi-layered network data.},
	language = {en},
	urldate = {2019-05-23},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Kang, Jian and Freitas, Scott and Yu, Haichao and Xia, Yinglong and Cao, Nan and Tong, Hanghang},
	year = {2018},
	pages = {1959--1962},
}

@article{VisuallyExplainableRecommendationa,
	title = {Visually {Explainable} {Recommendation}},
	url = {http://arxiv.org/abs/1801.10288},
	abstract = {Images account for a significant part of user decisions in many application scenarios, such as product images in e-commerce, or user image posts in social networks. It is intuitive that user preferences on the visual patterns of image (e.g., hue, texture, color, etc) can be highly personalized, and this provides us with highly discriminative features to make personalized recommendations.},
	language = {en},
	urldate = {2019-05-23},
	journal = {arXiv:1801.10288 [cs]},
	author = {Chen, Xu and Zhang, Yongfeng and Xu, Hongteng and Cao, Yixin and Qin, Zheng and Zha, Hongyuan},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.10288},
}

@article{ExplanationMethodsDeepLearning,
	title = {Explanation {Methods} in {Deep} {Learning}: {Users}, {Values}, {Concerns} and {Challenges}},
	shorttitle = {Explanation {Methods} in {Deep} {Learning}},
	url = {http://arxiv.org/abs/1803.07517},
	abstract = {Issues regarding explainable AI involve four components: users, laws \& regulations, explanations and algorithms. Together these components provide a context in which explanation methods can be evaluated regarding their adequacy. The goal of this chapter is to bridge the gap between expert users and lay users. Diﬀerent kinds of users are identiﬁed and their concerns revealed, relevant statements from the General Data Protection Regulation are analyzed in the context of Deep Neural Networks (DNNs), a taxonomy for the classiﬁcation of existing explanation methods is introduced, and ﬁnally, the various classes of explanation methods are analyzed to verify if user concerns are justiﬁed. Overall, it is clear that (visual) explanations can be given about various aspects of the inﬂuence of the input on the output. However, it is noted that explanation methods or interfaces for lay users are missing and we speculate which criteria these methods / interfaces should satisfy. Finally it is noted that two important concerns are diﬃcult to address with explanation methods: the concern about bias in datasets that leads to biased DNNs, as well as the suspicion about unfair outcomes.},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1803.07517 [cs, stat]},
	author = {Ras, Gabrielle and van Gerven, Marcel and Haselager, Pim},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.07517},
	keywords = {dl, explainable, fatml, xai},
}

@article{CounterfactualExplanationsOpeningBlacka,
	title = {Counterfactual {Explanations} {Without} {Opening} the {Black} {Box}: {Automated} {Decisions} and the {GDPR}},
	issn = {1556-5068},
	shorttitle = {Counterfactual {Explanations} {Without} {Opening} the {Black} {Box}},
	url = {https://www.ssrn.com/abstract=3063289},
	doi = {10.2139/ssrn.3063289},
	language = {en},
	urldate = {2019-05-29},
	journal = {SSRN Electronic Journal},
	author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
	year = {2017},
	keywords = {counterfactual, explainable, explanation, fatml, key, xai},
}

@article{ExplainingPredictionModelsIndividual,
	title = {Explaining prediction models and individual predictions with feature contributions},
	volume = {41},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-013-0679-x},
	doi = {10.1007/s10115-013-0679-x},
	abstract = {We present a sensitivity analysis-based method for explaining prediction models that can be applied to any type of classiﬁcation or regression model. Its advantage over existing general methods is that all subsets of input features are perturbed, so interactions and redundancies between features are taken into account. Furthermore, when explaining an additive model, the method is equivalent to commonly used additive model-speciﬁc methods. We illustrate the method’s usefulness with examples from artiﬁcial and real-world data sets and an empirical analysis of running times. Results from a controlled experiment with 122 participants suggest that the method’s explanations improved the participants’ understanding of the model.},
	language = {en},
	number = {3},
	urldate = {2019-05-29},
	journal = {Knowledge and Information Systems},
	author = {Štrumbelj, Erik and Kononenko, Igor},
	month = dec,
	year = {2014},
	keywords = {explainable, fatml, xai},
	pages = {647--665},
}

@article{EfficientSearchDiverseCoherent,
	title = {Efficient {Search} for {Diverse} {Coherent} {Explanations}},
	url = {http://arxiv.org/abs/1901.04909},
	abstract = {This paper proposes new search algorithms for counterfactual explanations based upon mixed integer programming. We are concerned with complex data in which variables may take any value from a contiguous range or an additional set of discrete states. We propose a novel set of constraints that we refer to as a “mixed polytope” and show how this can be used with an integer programming solver to efficiently find coherent counterfactual explanations i.e. solutions that are guaranteed to map back onto the underlying data structure, while avoiding the need for brute-force enumeration. We also look at the problem of diverse explanations and show how these can be generated within our framework.},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1901.04909 [cs, stat]},
	author = {Russell, Chris},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.04909},
	keywords = {explainable, explanation, fatml, key, xai},
}

@article{AuditingTransparencyContentPersonalization,
	title = {Auditing for {Transparency} in {Content} {Personalization} {Systems}},
	abstract = {Do we have a right to transparency when we use content personalization systems? Building on prior work in discrimination detection in data mining, I propose algorithm auditing as a compatible ethical duty for providers of content personalization systems to maintain the transparency of political discourse. I explore barriers to auditing that reveal the practical limitations on the ethical duties of service providers. Content personalization systems can function opaquely and resist auditing. However, the belief that highly complex algorithms, such as bots using machine learning, are incomprehensible to human users should not be an excuse to surrender high quality political discourse. Auditing is recommended as a way to map and redress algorithmic political exclusion in practice. However, the opacity of algorithmic decision making poses a significant challenge to the implementation of auditing.},
	language = {en},
	author = {Mittelstadt, Brent},
	year = {2016},
	keywords = {explainable, fatml},
	pages = {12},
}

@article{VisuallyExplainableRecommendation,
	title = {Visually {Explainable} {Recommendation}},
	url = {http://arxiv.org/abs/1801.10288},
	abstract = {Images account for a significant part of user decisions in many application scenarios, such as product images in e-commerce, or user image posts in social networks. It is intuitive that user preferences on the visual patterns of image (e.g., hue, texture, color, etc) can be highly personalized, and this provides us with highly discriminative features to make personalized recommendations.},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1801.10288 [cs]},
	author = {Chen, Xu and Zhang, Yongfeng and Xu, Hongteng and Cao, Yixin and Qin, Zheng and Zha, Hongyuan},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.10288},
	keywords = {explainable, fatml, key, rec, xai},
}

@article{TransparentExplainableAccountableAI,
	title = {Transparent, explainable, and accountable {AI} for robotics},
	volume = {2},
	issn = {2470-9476},
	url = {http://robotics.sciencemag.org/lookup/doi/10.1126/scirobotics.aan6080},
	doi = {10.1126/scirobotics.aan6080},
	language = {en},
	number = {6},
	urldate = {2019-05-29},
	journal = {Science Robotics},
	author = {Wachter, Sandra and Mittelstadt, Brent and Floridi, Luciano},
	month = may,
	year = {2017},
	keywords = {fatml, robotics, xai},
	pages = {eaan6080},
}

@inproceedings{XRankExplainableRankingComplex,
	address = {Torino, Italy},
	title = {X-{Rank}: {Explainable} {Ranking} in {Complex} {Multi}-{Layered} {Networks}},
	isbn = {978-1-4503-6014-2},
	shorttitle = {X-{Rank}},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3269224},
	doi = {10.1145/3269206.3269224},
	abstract = {In this paper we present a web-based prototype for an explainable ranking algorithm in multi-layered networks, incorporating both network topology and knowledge information. While traditional ranking algorithms such as PageRank and HITS are important tools for exploring the underlying structure of networks, they have two fundamental limitations in their efforts to generate high accuracy rankings. First, they are primarily focused on network topology, leaving out additional sources of information (e.g. attributes, knowledge). Secondly, most algorithms do not provide explanations to the end-users on why the algorithm gives the specific ranking results, hindering the usability of the ranking information. We developed X-Rank, an explainable ranking tool, to address these drawbacks. Empirical results indicate that our explainable ranking method not only improves ranking accuracy, but facilitates user understanding of the ranking by exploring the top influential elements in multi-layered networks. The web-based prototype (X-Rank: http://www.x-rank.net) is currently online—we believe it will assist both researchers and practitioners looking to explore and exploit multi-layered network data.},
	language = {en},
	urldate = {2019-05-29},
	booktitle = {Proceedings of the 27th {ACM} {International} {Conference} on {Information} and {Knowledge} {Management}  - {CIKM} '18},
	publisher = {ACM Press},
	author = {Kang, Jian and Freitas, Scott and Yu, Haichao and Xia, Yinglong and Cao, Nan and Tong, Hanghang},
	year = {2018},
	keywords = {explainable, fatml, key, ranking, xai},
	pages = {1959--1962},
}

@article{InterpretableMachineLearningHealthcarea,
	title = {Interpretable {Machine} {Learning} in {Healthcare}},
	abstract = {The drive towards greater penetration of machine learning in healthcare is being accompanied by increased calls for machine learning and AI based systems to be regulated and held accountable in healthcare. Interpretable machine learning models can be instrumental in holding machine learning systems accountable. Healthcare offers unique challenges for machine learning where the demands for explainability, model ﬁdelity and performance in general are much higher as compared to most other domains. In this paper we review the notion of interpretability within the context of healthcare, the various nuances associated with it, challenges related to interpretability which are unique to healthcare and the future of interpretability in healthcare.},
	language = {en},
	author = {Ahmad, Muhammad Aurangzeb and Eckert, Carly and Teredesai, Ankur and McKelvey, Greg},
	year = {2018},
	pages = {7},
}

@article{ContrastiveAlgorithmicFairnessParta,
	title = {Contrastive {Algorithmic} {Fairness}: {Part} 1 ({Theory})},
	shorttitle = {Contrastive {Algorithmic} {Fairness}},
	url = {http://arxiv.org/abs/1905.07360},
	abstract = {Was it fair that Harry was hired but not Barry? Was it fair that Pam was ﬁred instead of Sam? How to ensure fairness when an intelligent algorithm takes these decisions instead of a human? How to ensure that the decisions were taken based on merit and not on protected attributes like race or sex? These are the questions that must be answered now that many decisions in real life can be made through machine learning. However research in fairness of algorithms has focused on the counterfactual questions "what if?" or "why?", whereas in real life most subjective questions of consequence are contrastive: "why this but not that?". We introduce concepts and mathematical tools using causal inference to address contrastive fairness in algorithmic decision-making with illustrative thought examples.},
	language = {en},
	urldate = {2019-06-01},
	journal = {arXiv:1905.07360 [cs, stat]},
	author = {Chakraborti, Tapabrata and Patra, Arijit and Noble, Alison},
	month = may,
	year = {2019},
	note = {arXiv: 1905.07360},
	keywords = {Statistics - Machine Learning},
}

@article{WhyUnderstandingExplainableArtificiala,
	title = {"{But} why?": understanding explainable artificial intelligence},
	volume = {25},
	issn = {15284972},
	shorttitle = {"{But} why?},
	url = {http://dl.acm.org/citation.cfm?doid=3325198.3313107},
	doi = {10.1145/3313107},
	language = {en},
	number = {3},
	urldate = {2019-06-01},
	journal = {XRDS: Crossroads, The ACM Magazine for Students},
	author = {Miller, Tim},
	month = apr,
	year = {2019},
	pages = {20--25},
}

@article{ExplainableRecommendationSurveyNewa,
	title = {Explainable {Recommendation}: {A} {Survey} and {New} {Perspectives}},
	shorttitle = {Explainable {Recommendation}},
	url = {http://arxiv.org/abs/1804.11192},
	abstract = {Explainable Recommendation refers to the personalized recommendation algorithms that address the problem of why - they not only provide users with the recommendations, but also provide explanations to make the user or system designer aware of why such items are recommended. In this way, it helps to improve the effectiveness, efficiency, persuasiveness, and user satisfaction of recommendation systems. In recent years, a large number of explainable recommendation approaches -- especially model-based explainable recommendation algorithms -- have been proposed and adopted in real-world systems. In this survey, we review the work on explainable recommendation that has been published in or before the year of 2018. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation itself in terms of three aspects: 1) We provide a chronological research line of explanations in recommender systems, including the user study approaches in the early years, as well as the more recent model-based approaches. 2) We provide a taxonomy for explainable recommendation algorithms, including user-based, item-based, model-based, and post-model explanations. 3) We summarize the application of explainable recommendation in different recommendation tasks, including product recommendation, social recommendation, POI recommendation, etc. We devote a section to discuss the explanation perspectives in the broader IR and machine learning settings, as well as their relationship with explainable recommendation research. We end the survey by discussing potential future research directions to promote the explainable recommendation research area.},
	language = {en},
	urldate = {2019-05-29},
	journal = {arXiv:1804.11192 [cs]},
	author = {Zhang, Yongfeng and Chen, Xu},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.11192},
	keywords = {explainable, fatml, key, rec, xai},
}

@article{LearningHeterogeneousKnowledgeBase,
	title = {Learning {Heterogeneous} {Knowledge} {Base} {Embeddings} for {Explainable} {Recommendation}},
	volume = {11},
	issn = {1999-4893},
	url = {http://www.mdpi.com/1999-4893/11/9/137},
	doi = {10.3390/a11090137},
	abstract = {Providing model-generated explanations in recommender systems is important to user experience. State-of-the-art recommendation algorithms—especially the collaborative filtering (CF)-based approaches with shallow or deep models—usually work with various unstructured information sources for recommendation, such as textual reviews, visual images, and various implicit or explicit feedbacks. Though structured knowledge bases were considered in content-based approaches, they have been largely ignored recently due to the availability of vast amounts of data and the learning power of many complex models. However, structured knowledge bases exhibit unique advantages in personalized recommendation systems. When the explicit knowledge about users and items is considered for recommendation, the system could provide highly customized recommendations based on users’ historical behaviors and the knowledge is helpful for providing informed explanations regarding the recommended items. A great challenge for using knowledge bases for recommendation is how to integrate large-scale structured and unstructured data, while taking advantage of collaborative filtering for highly accurate performance. Recent achievements in knowledge-base embedding (KBE) sheds light on this problem, which makes it possible to learn user and item representations while preserving the structure of their relationship with external knowledge for explanation. In this work, we propose to explain knowledge-base embeddings for explainable recommendation. Specifically, we propose a knowledge-base representation learning framework to embed heterogeneous entities for recommendation, and based on the embedded knowledge base, a soft matching algorithm is proposed to generate personalized explanations for the recommended items. Experimental results on real-world e-commerce datasets verified the superior recommendation performance and the explainability power of our approach compared with state-of-the-art baselines.},
	language = {en},
	number = {9},
	urldate = {2019-05-29},
	journal = {Algorithms},
	author = {Ai, Qingyao and Azizi, Vahid and Chen, Xu and Zhang, Yongfeng},
	month = sep,
	year = {2018},
	keywords = {fatml, interpretable, kg, xai},
	pages = {137},
}

@article{BagRecurrencePatternsRepresentationa,
	title = {Bag of recurrence patterns representation for time-series classification},
	issn = {1433-7541, 1433-755X},
	url = {http://link.springer.com/10.1007/s10044-018-0703-6},
	doi = {10.1007/s10044-018-0703-6},
	abstract = {Time-series classification (TSC) has attracted a lot of attention in pattern recognition, because wide range of applications from different domains such as finance and health informatics deal with time-series signals. Bag-of-features (BoF) model has achieved a great success in TSC task by summarizing signals according to the frequencies of “feature words” of a data-learned dictionary. This paper proposes embedding the recurrence plots (RP), a visualization technique for analysis of dynamic systems, in the BoF model for TSC. While the traditional BoF approach extracts features from 1D signal segments, this paper uses the RP to transform time-series into 2D texture images and then applies the BoF on them. Image representation of time-series enables us to explore different visual descriptors that are not available for 1D signals and to treat TSC task as a texture recognition problem. Experimental results on the UCI time-series classification archive demonstrates a significant accuracy boost by the proposed bag of recurrence patterns, compared not only to the existing BoF models, but also to the state-of-the art algorithms.},
	language = {en},
	urldate = {2019-06-07},
	journal = {Pattern Analysis and Applications},
	author = {Hatami, Nima and Gavet, Yann and Debayle, Johan},
	month = apr,
	year = {2018},
	keywords = {dm, eeg-key, ts},
}

@article{SemanticExplanationsPredictionsa,
	title = {Semantic {Explanations} of {Predictions}},
	url = {http://arxiv.org/abs/1805.10587},
	abstract = {The main objective of explanations is to transmit knowledge to humans. This work proposes to construct informative explanations for predictions made from machine learning models. Motivated by the observations from social sciences, our approach selects data points from the training sample that exhibit special characteristics crucial for explanation, for instance, ones contrastive to the classiﬁcation prediction and ones representative of the models. Subsequently, semantic concepts are derived from the selected data points through the use of domain ontologies. These concepts are ﬁltered and ranked to produce informative explanations that improves human understanding. The main features of our approach are that (1) knowledge about explanations is captured in the form of ontological concepts, (2) explanations include contrastive evidences in addition to normal evidences, and (3) explanations are user relevant.},
	language = {en},
	urldate = {2019-06-01},
	journal = {arXiv:1805.10587 [cs]},
	author = {Lecue, Freddy and Wu, Jiewen},
	month = may,
	year = {2018},
	note = {arXiv: 1805.10587},
}

@article{UnsupervisedMotionPatternLearning,
	title = {Unsupervised motion pattern learning for motion segmentation},
	abstract = {This paper proposes a novel method for automated generation of motion segmentation models for full body motion monitoring. The method generates, in an unsupervised manner, a motion template for a dynamic warping approach from a short training sequence, i.e., from very few data. Therefore it ﬁrst automatically detects motif candidates, i.e. the recurring patterns in the training sequence. Then it uses the detected motifs to construct the model. This novel method is able to automatically ﬁnd motifs in a multivariate time series and generate a model which is capable of segmenting the series in a real-time system. The technology is evaluated in the context of a personalized virtual rehabilitation trainer application during a clinical study. The novel motion capturing dataset is publicly available.},
	language = {en},
	author = {Weber, Markus and Bleser, Gabriele and Liwicki, Marcus and Stricker, Didier},
	keywords = {dm, ts},
	pages = {4},
}

@inproceedings{ContextlearningBasedElectroencephalogramAnalysis,
	address = {Washington, DC, USA},
	title = {Context-learning based electroencephalogram analysis for epileptic seizure detection},
	isbn = {978-1-4673-6799-8},
	url = {http://ieeexplore.ieee.org/document/7359702/},
	doi = {10.1109/BIBM.2015.7359702},
	abstract = {Epileptic seizure is a serious health problem in the world and there is a huge population suffering from it every year. If an algorithm could automatically detect seizures and deliver the patient therapy or notify the hospital, that would be of great assistance. Analyzing the scalp EEG is the most common way to detect the onset of a seizure. In this paper, we proposed the context-learning based EEG analysis for seizure detection (Context-EEG) algorithm. The proposed method aims at extracting both the hidden inherent features within EEG fragments and the temporal features from EEG contexts. First, we segment the EEG signals into EEG fragments of fixed length. Second, we learn the hidden inherent features from each fragment and reduce the dimensionality of the original data. Third, we translate each EEG fragment to an EEG word so that the EEG context can provide us with temporal information. And finally, we concatenate the hidden feature and the temporal feature together to train a binary classifier. The experiment result shows the proposed model is highly effective in detecting seizure.},
	language = {en},
	urldate = {2019-06-07},
	booktitle = {2015 {IEEE} {International} {Conference} on {Bioinformatics} and {Biomedicine} ({BIBM})},
	publisher = {IEEE},
	author = {Xun, Guangxu and Jia, Xiaowei and Zhang, Aidong},
	month = nov,
	year = {2015},
	keywords = {dm, ts},
	pages = {325--330},
}

@article{LatentTimeSeriesMotifs,
	title = {Latent {Time}-{Series} {Motifs}},
	volume = {11},
	issn = {15564681},
	url = {http://dl.acm.org/citation.cfm?doid=2974720.2940329},
	doi = {10.1145/2940329},
	language = {en},
	number = {1},
	urldate = {2019-06-07},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Grabocka, Josif and Schilling, Nicolas and Schmidt-Thieme, Lars},
	month = jul,
	year = {2016},
	keywords = {dm, ts},
	pages = {1--20},
}

@inproceedings{MatrixProfileGenericTechnique,
	address = {Halifax, NS, Canada},
	title = {Matrix {Profile} {V}: {A} {Generic} {Technique} to {Incorporate} {Domain} {Knowledge} into {Motif} {Discovery}},
	isbn = {978-1-4503-4887-4},
	shorttitle = {Matrix {Profile} {V}},
	url = {http://dl.acm.org/citation.cfm?doid=3097983.3097993},
	doi = {10.1145/3097983.3097993},
	abstract = {Time series motif discovery has emerged as perhaps the most used primitive for time series data mining, and has seen applications to domains as diverse as robotics, medicine and climatology. There has been recent significant progress on the scalability of motif discovery. However, we believe that the current definitions of motif discovery are limited, and can create a mismatch between the user’s intent/expectations, and the motif discovery search outcomes. In this work, we explain the reasons behind these issues, and introduce a novel and general framework to address them. Our ideas can be used with current state-of-the-art algorithms with virtually no time or space overhead, and are fast enough to allow real-time interaction and hypotheses testing on massive datasets. We demonstrate the utility of our ideas on domains as diverse as seismology and epileptic seizure monitoring.},
	language = {en},
	urldate = {2019-06-07},
	booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}  - {KDD} '17},
	publisher = {ACM Press},
	author = {Dau, Hoang Anh and Keogh, Eamonn},
	year = {2017},
	keywords = {dm, ts},
	pages = {125--134},
}

@article{UnsupervisedLearningSequenceRepresentations,
	title = {Unsupervised {Learning} of {Sequence} {Representations} by {Autoencoders}},
	url = {http://arxiv.org/abs/1804.00946},
	abstract = {Sequence data is challenging for machine learning approaches, because the lengths of the sequences may vary between samples. In this paper, we present an unsupervised learning model for sequence data, called the Integrated Sequence Autoencoder (ISA), to learn a ﬁxed-length vectorial representation by minimizing the reconstruction error. Speciﬁcally, we propose to integrate two classical mechanisms for sequence reconstruction which takes into account both the global silhouette information and the local temporal dependencies. Furthermore, we propose a stop feature that serves as a temporal stamp to guide the reconstruction process, which results in a higher-quality representation. The learned representation is able to eﬀectively summarize not only the apparent features, but also the underlying and high-level style information. Take for example a speech sequence sample: our ISA model can not only recognize the spoken text (apparent feature), but can also discriminate the speaker who utters the audio (more high-level style). One promising application of the ISA model is that it can be readily used in the semi-supervised learning scenario, in which a large amount of unlabeled data is leveraged to extract high-quality sequence representations and thus to improve the performance of the subsequent supervised learning tasks on limited labeled data.},
	language = {en},
	urldate = {2019-06-07},
	journal = {arXiv:1804.00946 [cs]},
	author = {Pei, Wenjie and Tax, David M. J.},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.00946},
	keywords = {dm, ts},
}

@article{DeepLearningBioinformatics,
	title = {Deep {Learning} in {Bioinformatics}},
	abstract = {In the era of big data, transformation of biomedical big data into valuable knowledge has been one of the most important challenges in bioinformatics. Deep learning has advanced rapidly since the early 2000s and now demonstrates state-of-the-art performance in various fields. Accordingly, application of deep learning in bioinformatics to gain insight from data has been emphasized in both academia and industry. Here, we review deep learning in bioinformatics, presenting examples of current research. To provide a useful and comprehensive perspective, we categorize research both by the bioinformatics domain (i.e., omics, biomedical imaging, biomedical signal processing) and deep learning architecture (i.e., deep neural networks, convolutional neural networks, recurrent neural networks, emergent architectures) and present brief descriptions of each study. Additionally, we discuss theoretical and practical issues of deep learning in bioinformatics and suggest future research directions. We believe that this review will provide valuable insights and serve as a starting point for researchers to apply deep learning approaches in their bioinformatics studies.},
	language = {en},
	author = {Min, Seonwoo and Lee, Byunghan and Yoon, Sungroh},
	keywords = {dm, ts},
	pages = {46},
}

@techreport{DeepLearningApproachPattern,
	type = {preprint},
	title = {A deep learning approach to pattern recognition for short {DNA} sequences: {Supplementary} {Materials}},
	shorttitle = {A deep learning approach to pattern recognition for short {DNA} sequences},
	url = {http://biorxiv.org/lookup/doi/10.1101/353474},
	abstract = {Sequence-to-sequence alignment is a widely-used analysis method in bioinformatics. One common use of sequence alignment is to infer information about an unknown query sequence from the annotations of similar sequences in a database, such as predicting the function of a novel protein sequence by aligning to a database of protein families or predicting the presence/absence of species in a metagenomics sample by aligning reads to a database of reference genomes. In this work we describe a deep learning approach to solve such problems in a single step by training a deep neural network (DNN) to predict the database-derived labels directly from the query sequence. We demonstrate the value of this DNN approach on a hard problem of practical importance: determining the species of origin of next-generation sequencing reads from 16S ribosomal DNA. In particular, we show that when trained on 16S sequences from more than 13,000 distinct species, our DNN can predict the species of origin of individual reads more accurately than existing machine learning baselines and alignment-based methods like BWA or BLAST, achieving absolute performance within 2.0\% of perfect memorization of the training inputs. Moreover, the DNN remains accurate and outperforms read alignment approaches when the query sequences are especially noisy or ambiguous. Finally, these DNN models can be used to assess metagenomic community composition on a variety of experimental 16S read datasets. Our results are a first step towards our long-term goal of developing a general-purpose deep learning model that can learn to predict any type of label from short biological sequences.},
	language = {en},
	urldate = {2019-06-07},
	institution = {Bioinformatics},
	author = {Busia, Akosua and Dahl, George E. and Fannjiang, Clara and Alexander, David H. and Dorfman, Elizabeth and Poplin, Ryan and McLean, Cory Y. and Chang, Pi-Chuan and DePristo, Mark},
	month = jun,
	year = {2018},
	doi = {10.1101/353474},
	keywords = {dm, ts},
}

@article{CodeFailurePredictionPattern,
	title = {Code {Failure} {Prediction} and {Pattern} {Extraction} using {LSTM} {Networks}},
	url = {http://arxiv.org/abs/1812.05237},
	abstract = {In this paper, we use a well-known Deep Learning technique called Long Short Term Memory (LSTM) recurrent neural networks to ﬁnd sessions that are prone to code failure in applications that rely on telemetry data for system health monitoring. We also use LSTM networks to extract telemetry patterns that lead to a speciﬁc code failure. For code failure prediction, we treat the telemetry events, sequence of telemetry events and the outcome of each sequence as words, sentence and sentiment in the context of sentiment analysis, respectively. Our proposed method is able to process a large set of data and can automatically handle edge cases in code failure prediction. We take advantage of Bayesian optimization technique to ﬁnd the optimal hyper parameters as well as the type of LSTM cells that leads to the best prediction performance. We then introduce the Contributors and Blockers concepts. In this paper, contributors are the set of events that casue a code failure, while blockers are the set of events that each of them individually prevents a code failure from happening, even in presence of one or multiple contributor(s). Once the proposed LSTM model is trained, we use a greedy approach to ﬁnd the contributors and blockers. To develop and test our proposed method, we use synthetic (simulated) data in the ﬁrst step. The synthetic data is generated using a number of rules for code failures, as well as a number of rules for preventing a code failure from happening. The trained LSTM model shows over 99\% accuracy for detecting code failures in the synthetic data. The results from the proposed method outperform the classical learning models such as Decision Tree and Random Forest. Using the proposed greedy method, we are able to ﬁnd the contributors and blockers in the synthetic data in more than 90\% of the cases, with a performance better than sequential rule and pattern mining algorithms. In the next step, we train and test our proposed LSTM method on real data that we collected from sequences of activities performed by millions of Microsoft Ofﬁce customers.},
	language = {en},
	urldate = {2019-06-07},
	journal = {arXiv:1812.05237 [cs]},
	author = {Hajiaghayi, Mahdi and Vahedi, Ehsan},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.05237},
	keywords = {dm, ts},
}

@article{Wave2VecDeepRepresentationLearning,
	title = {{Wave2Vec}: {Deep} representation learning for clinical temporal data},
	volume = {324},
	issn = {09252312},
	shorttitle = {{Wave2Vec}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S092523121830626X},
	doi = {10.1016/j.neucom.2018.03.074},
	abstract = {Representation learning for time series has gained increasing attention in healthcare domain. The recent advancement in semantic learning allows researcher to learn meaningful deep representations of clinical medical concepts from Electronic Health Records (EHRs). However, existing models cannot deal with continuous physiological records, which are often included in EHRs. The major challenges for this task are to model non-obvious representations from observed high-resolution biosignals, and to interpret the learned features. To address these issues, we propose Wave2Vec, an end-to-end deep representation learning model, to bridge the gap between biosignal processing and semantic learning. Wave2Vec not only jointly learns both inherent and temporal representations of biosignals, but also allows us to interpret the learned representations reasonably over time. We propose two embedding mechanisms to capture the temporal knowledge within signals, and discover latent knowledge from signals in timefrequency domain, namely component-based motifs. To validate the effectiveness of our model in clinical task, we carry out experiments on two real-world benchmark biosignal datasets. Experimental results demonstrate that the proposed Wave2Vec model outperforms six feature learning baselines in biosignal processing. Analytical results show that the proposed model can incorporate both motif co-occurrence information and time series information of biosignals, and hence provides clinically meaningful interpretation.},
	language = {en},
	urldate = {2019-06-07},
	journal = {Neurocomputing},
	author = {Yuan, Ye and Xun, Guangxu and Suo, Qiuling and Jia, Kebin and Zhang, Aidong},
	month = jan,
	year = {2019},
	keywords = {dm, ts},
	pages = {31--42},
}

@inproceedings{ModelingLongShortTermTemporal,
	address = {Ann Arbor, MI, USA},
	title = {Modeling {Long}- and {Short}-{Term} {Temporal} {Patterns} with {Deep} {Neural} {Networks}},
	isbn = {978-1-4503-5657-2},
	url = {http://dl.acm.org/citation.cfm?doid=3209978.3210006},
	doi = {10.1145/3209978.3210006},
	abstract = {Multivariate time series forecasting is an important machine learning problem across many domains, including predictions of solar plant energy output, electricity consumption, and traffic jam situation. Temporal data arise in these real-world applications often involves a mixture of long-term and short-term patterns, for which traditional approaches such as Autoregressive models and Gaussian Process may fail. In this paper, we proposed a novel deep learning framework, namely Long- and Short-term Time-series network (LSTNet), to address this open challenge. LSTNet uses the Convolution Neural Network (CNN) and the Recurrent Neural Network (RNN) to extract short-term local dependency patterns among variables and to discover long-term patterns for time series trends. Furthermore, we leverage traditional autoregressive model to tackle the scale insensitive problem of the neural network model. In our evaluation on real-world data with complex mixtures of repetitive patterns, LSTNet achieved significant performance improvements over that of several state-of-the-art baseline methods. All the data and experiment codes are available online.},
	language = {en},
	urldate = {2019-06-07},
	booktitle = {The 41st {International} {ACM} {SIGIR} {Conference} on {Research} \& {Development} in {Information} {Retrieval}  - {SIGIR} '18},
	publisher = {ACM Press},
	author = {Lai, Guokun and Chang, Wei-Cheng and Yang, Yiming and Liu, Hanxiao},
	year = {2018},
	keywords = {dm, ts},
	pages = {95--104},
}

@article{DetectionBurstSuppressionPatterns,
	title = {Detection of {Burst} {Suppression} {Patterns} in {EEG} {Using} {Recurrence} {Rate}},
	volume = {2014},
	issn = {2356-6140, 1537-744X},
	url = {http://www.hindawi.com/journals/tswj/2014/295070/},
	doi = {10.1155/2014/295070},
	abstract = {Burst suppression is a unique electroencephalogram (EEG) pattern commonly seen in cases of severely reduced brain activity such as overdose of general anesthesia. It is important to detect burst suppression reliably during the administration of anesthetic or sedative agents, especially for cerebral-protective treatments in various neurosurgical diseases. This study investigates recurrent plot (RP) analysis for the detection of the burst suppression pattern (BSP) in EEG. The RP analysis is applied to EEG data containing BSPs collected from 14 patients. Firstly we obtain the best selection of parameters for RP analysis. Then, the recurrence rate (RR), determinism (DET), and entropy (ENTR) are calculated. Then RR was selected as the best BSP index one-way analysis of variance (ANOVA) and multiple comparison tests. Finally, the performance of RR analysis is compared with spectral analysis, bispectral analysis, approximate entropy, and the nonlinear energy operator (NLEO). ANOVA and multiple comparison tests showed that the RR could detect BSP and that it was superior to other measures with the highest sensitivity of suppression detection (96.49\%,
              
                 
                P
                =
                0.03
              
              ). Tracking BSP patterns is essential for clinical monitoring in critically ill and anesthetized patients. The purposed RR may provide an effective burst suppression detector for developing new patient monitoring systems.},
	language = {en},
	urldate = {2019-06-25},
	journal = {The Scientific World Journal},
	author = {Liang, Zhenhu and Wang, Yinghua and Ren, Yongshao and Li, Duan and Voss, Logan and Sleigh, Jamie and Li, Xiaoli},
	year = {2014},
	keywords = {dm, ts},
	pages = {1--11},
}

@article{ExplainScientificDiscourse,
	title = {“{Explain}” in scientific discourse},
	volume = {190},
	issn = {0039-7857, 1573-0964},
	url = {http://link.springer.com/10.1007/s11229-012-0109-8},
	doi = {10.1007/s11229-012-0109-8},
	abstract = {The philosophical literature on scientific explanation contains a striking diversity of accounts. I use novel empirical methods to address this fragmentation and assess the importance and generality of explanation in science. My evidence base is a set of 781 articles from one year of the journal Science , and I begin by applying text mining techniques to discover patterns in the usage of "explain" and other words of philosophical interest. I then use random sampling from the data set to develop and test a classification scheme for scientific explanation. My results show that explanation and inference to the best explanation are ubiquitous in science, that they occur across a wide range of scientific disciplines, and that they are a goal of scientific practise.},
	language = {en},
	number = {8},
	urldate = {2019-06-25},
	journal = {Synthese},
	author = {Overton, James A.},
	month = may,
	year = {2013},
	keywords = {fatml, key, xai},
	pages = {1383--1405},
}

@article{UnsupervisedFeatureExtractionTime,
	title = {Unsupervised {Feature} {Extraction} for {Time} {Series} {Clustering} {Using} {Orthogonal} {Wavelet} {Transform}},
	language = {en},
	author = {Zhang, Hui and Ho, Tu and Zhang, Yang and Lin, Mao-Song},
	keywords = {dm, ts},
	pages = {15},
}

@article{ClusteringTimeseriesSubsequencesMeaningless,
	title = {Clustering of time-series subsequences is meaningless: implications for previous and future research},
	volume = {8},
	issn = {0219-1377, 0219-3116},
	shorttitle = {Clustering of time-series subsequences is meaningless},
	url = {http://link.springer.com/10.1007/s10115-004-0172-7},
	doi = {10.1007/s10115-004-0172-7},
	abstract = {Given the recent explosion of interest in streaming data and online algorithms, clustering of time-series subsequences, extracted via a sliding window, has received much attention. In this work, we make a surprising claim. Clustering of time-series subsequences is meaningless. More concretely, clusters extracted from these time series are forced to obey a certain constraint that is pathologically unlikely to be satisﬁed by any dataset, and because of this, the clusters extracted by any clustering algorithm are essentially random. While this constraint can be intuitively demonstrated with a simple illustration and is simple to prove, it has never appeared in the literature. We can justify calling our claim surprising because it invalidates the contribution of dozens of previously published papers. We will justify our claim with a theorem, illustrative examples, and a comprehensive set of experiments on reimplementations of previous work. Although the primary contribution of our work is to draw attention to the fact that an apparent solution to an important problem is incorrect and should no longer be used, we also introduce a novel method that, based on the concept of time-series motifs, is able to meaningfully cluster subsequences on some time-series datasets.},
	language = {en},
	number = {2},
	urldate = {2019-06-24},
	journal = {Knowledge and Information Systems},
	author = {Keogh, Eamonn and Lin, Jessica},
	month = aug,
	year = {2005},
	keywords = {dm, eeg-key, subseq-clustering, ts},
	pages = {154--177},
}

@inproceedings{FeatureInsightVisualSupportErrordriven,
	address = {Chicago, IL, USA},
	title = {{FeatureInsight}: {Visual} support for error-driven feature ideation in text classification},
	isbn = {978-1-4673-9783-4},
	shorttitle = {{FeatureInsight}},
	url = {http://ieeexplore.ieee.org/document/7347637/},
	doi = {10.1109/VAST.2015.7347637},
	abstract = {Machine learning requires an effective combination of data, features, and algorithms. While many tools exist for working with machine learning data and algorithms, support for thinking of new features, or feature ideation, remains poor. In this paper, we investigate two general approaches to support feature ideation: visual summaries and sets of errors. We present FeatureInsight, an interactive visual analytics tool for building new dictionary features (semantically related groups of words) for text classification problems. FeatureInsight supports an error-driven feature ideation process and provides interactive visual summaries of sets of misclassified documents. We conducted a controlled experiment evaluating both visual summaries and sets of errors in FeatureInsight. Our results show that visual summaries significantly improve feature ideation, especially in combination with sets of errors. Users preferred visual summaries over viewing raw data, and only preferred examining sets when visual summaries were provided. We discuss extensions of both approaches to data types other than text, and point to areas for future research.},
	language = {en},
	urldate = {2019-06-10},
	booktitle = {2015 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Brooks, Michael and Amershi, Saleema and Lee, Bongshin and Drucker, Steven M. and Kapoor, Ashish and Simard, Patrice},
	month = oct,
	year = {2015},
	keywords = {fatml, vis},
	pages = {105--112},
}

@inproceedings{InteractingPredictionsVisualInspectiona,
	address = {Santa Clara, California, USA},
	title = {Interacting with {Predictions}: {Visual} {Inspection} of {Black}-box {Machine} {Learning} {Models}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Interacting with {Predictions}},
	url = {http://dl.acm.org/citation.cfm?doid=2858036.2858529},
	doi = {10.1145/2858036.2858529},
	abstract = {Understanding predictive models, in terms of interpreting and identifying actionable insights, is a challenging task. Often the importance of a feature in a model is only a rough estimate condensed into one number. However, our research goes beyond these na¨ıve estimates through the design and implementation of an interactive visual analytics system, Prospector. By providing interactive partial dependence diagnostics, data scientists can understand how features affect the prediction overall. In addition, our support for localized inspection allows data scientists to understand how and why speciﬁc datapoints are predicted as they are, as well as support for tweaking feature values and seeing how the prediction responds. Our system is then evaluated using a case study involving a team of data scientists improving predictive models for detecting the onset of diabetes from electronic medical records.},
	language = {en},
	urldate = {2019-06-10},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '16},
	publisher = {ACM Press},
	author = {Krause, Josua and Perer, Adam and Ng, Kenney},
	year = {2016},
	keywords = {fatml, vis},
	pages = {5686--5697},
}

@article{DecisionMakingVisualizationsCognitivea,
	title = {Decision making with visualizations: a cognitive framework across disciplines},
	volume = {3},
	issn = {2365-7464},
	shorttitle = {Decision making with visualizations},
	url = {https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-018-0120-9},
	doi = {10.1186/s41235-018-0120-9},
	abstract = {Visualizations—visual representations of information, depicted in graphics—are studied by researchers in numerous ways, ranging from the study of the basic principles of creating visualizations, to the cognitive processes underlying their use, as well as how visualizations communicate complex information (such as in medical risk or spatial patterns). However, findings from different domains are rarely shared across domains though there may be domaingeneral principles underlying visualizations and their use. The limited cross-domain communication may be due to a lack of a unifying cognitive framework. This review aims to address this gap by proposing an integrative model that is grounded in models of visualization comprehension and a dual-process account of decision making. We review empirical studies of decision making with static two-dimensional visualizations motivated by a wide range of research goals and find significant direct and indirect support for a dual-process account of decision making with visualizations. Consistent with a dual-process model, the first type of visualization decision mechanism produces fast, easy, and computationally light decisions with visualizations. The second facilitates slower, more contemplative, and effortful decisions with visualizations. We illustrate the utility of a dual-process account of decision making with visualizations using four cross-domain findings that may constitute universal visualization principles. Further, we offer guidance for future research, including novel areas of exploration and practical recommendations for visualization designers based on cognitive theory and empirical findings.},
	language = {en},
	number = {1},
	urldate = {2019-06-10},
	journal = {Cognitive Research: Principles and Implications},
	author = {Padilla, Lace M. and Creem-Regehr, Sarah H. and Hegarty, Mary and Stefanucci, Jeanine K.},
	month = dec,
	year = {2018},
	keywords = {vis},
	pages = {29},
}

@inproceedings{KronoMinerUsingMultifociNavigation,
	address = {Vancouver, BC, Canada},
	title = {{KronoMiner}: using multi-foci navigation for the visual exploration of time-series data},
	isbn = {978-1-4503-0228-9},
	shorttitle = {{KronoMiner}},
	url = {http://dl.acm.org/citation.cfm?doid=1978942.1979195},
	doi = {10.1145/1978942.1979195},
	abstract = {The need for pattern discovery in long time-series data led researchers to develop interactive visualization tools and analytical algorithms for gaining insight into the data. Most of the literature on time-series data visualization either focus on a small number of tasks or a speciﬁc domain. We propose KronoMiner, a tool that embeds new interaction and visualization techniques as well as analytical capabilities for the visual exploration of time-series data. The interface’s design has been iteratively reﬁned based on feedback from expert users. Qualitative evaluation with an expert user not involved in the design process indicates that our prototype is promising for further research.},
	language = {en},
	urldate = {2019-06-07},
	booktitle = {Proceedings of the 2011 annual conference on {Human} factors in computing systems - {CHI} '11},
	publisher = {ACM Press},
	author = {Zhao, Jian and Chevalier, Fanny and Balakrishnan, Ravin},
	year = {2011},
	keywords = {dm, ts},
	pages = {1737},
}

@inproceedings{MatrixProfileIIIMatrix,
	address = {Barcelona},
	title = {Matrix {Profile} {III}: {The} {Matrix} {Profile} {Allows} {Visualization} of {Salient} {Subsequences} in {Massive} {Time} {Series}},
	isbn = {978-1-5090-5473-2},
	shorttitle = {Matrix {Profile} {III}},
	url = {http://ieeexplore.ieee.org/document/7837882/},
	doi = {10.1109/ICDM.2016.0069},
	abstract = {Multidimensional Scaling (MDS) is one of the most versatile tools used for exploratory data mining. It allows a first glimpse of possible structure in the data, which can inform the choice of analyses used. Its uses are multiple. It can give the user an idea as to the clusterability or linear separability of the data. It can help spot outliers, or can hint at the intrinsic dimensionality of the data. Moreover, it can sometimes reveal unexpected latent dimensions in the data. With all these uses, MDS is increasingly used in areas as diverse as marketing, medicine, genetics, music and linguistics. One of the strengths of MDS is that it is essentially agnostic to data type, as we can use any distance measure to create the distance matrix, which is the only required input to the MDS algorithm. In spite of this generality, we make the following claim. MDS is not (well) defined for an increasingly important data type, time series subsequences. In this work we explain why this is the case, and we propose a scalable solution. We demonstrate the utility of our ideas on several diverse real-world datasets. At the core of our approach is a novel Minimum Description Length (MDL) subsequence extraction algorithm. Beyond MDS visualization, this subsequence extraction subroutine may be a useful tool in its own right.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Yeh, Chin-Chia Michael and Herle, Helga Van and Keogh, Eamonn},
	month = dec,
	year = {2016},
	keywords = {dm, ts},
	pages = {579--588},
}

@article{ImplementationEpilepticEEGUsing,
	title = {Implementation of {Epileptic} {EEG} using {Recurrent} {Neural} {Network}},
	abstract = {The ambulant EEG (electroencephalogram) signal plays an important role in the diagnosis of epilepsy but data recordings generate very lengthy data in the detection of epilepsy which is very time consuming. The traditional method of analysis being tedious, many automated diagnostic systems for epilepsy has emerged in recent years. This paper proposes reason for epilepsy, different type of seizures, stage of epilepsy in patient and how it can be implemented using Artificial Neural Network naming Elman Neural Networks. We know that the value of the ApEn drops sharply during an epileptic seizure so we used it as an input feature. ApEn is a statistical parameter that measures the predictability of the current amplitude values of a physiological signal based on its previous amplitude values. ApEn is used for the first time in the proposed system for the implementation of epilepsy using neural networks.},
	language = {en},
	author = {Gayatri, M and Kumar, Arun and Janghu, Manish and Kaur, Mandeep and Prasad, Dr T V},
	year = {2010},
	keywords = {dm, ts},
	pages = {8},
}

@article{Wave2VecVectorizingElectroencephalographyBioSignal,
	title = {{Wave2Vec}: {Vectorizing} {Electroencephalography} {Bio}-{Signal} for {Prediction} of {Brain} {Disease}},
	volume = {15},
	issn = {1660-4601},
	shorttitle = {{Wave2Vec}},
	url = {http://www.mdpi.com/1660-4601/15/8/1750},
	doi = {10.3390/ijerph15081750},
	abstract = {Interest in research involving health-medical information analysis based on artiﬁcial intelligence, especially for deep learning techniques, has recently been increasing. Most of the research in this ﬁeld has been focused on searching for new knowledge for predicting and diagnosing disease by revealing the relation between disease and various information features of data. These features are extracted by analyzing various clinical pathology data, such as EHR (electronic health records), and academic literature using the techniques of data analysis, natural language processing, etc. However, still needed are more research and interest in applying the latest advanced artiﬁcial intelligence-based data analysis technique to bio-signal data, which are continuous physiological records, such as EEG (electroencephalography) and ECG (electrocardiogram). Unlike the other types of data, applying deep learning to bio-signal data, which is in the form of time series of real numbers, has many issues that need to be resolved in preprocessing, learning, and analysis. Such issues include leaving feature selection, learning parts that are black boxes, difﬁculties in recognizing and identifying effective features, high computational complexities, etc. In this paper, to solve these issues, we provide an encoding-based Wave2vec time series classiﬁer model, which combines signal-processing and deep learning-based natural language processing techniques. To demonstrate its advantages, we provide the results of three experiments conducted with EEG data of the University of California Irvine, which are a real-world benchmark bio-signal dataset. After converting the bio-signals (in the form of waves), which are a real number time series, into a sequence of symbols or a sequence of wavelet patterns that are converted into symbols, through encoding, the proposed model vectorizes the symbols by learning the sequence using deep learning-based natural language processing. The models of each class can be constructed through learning from the vectorized wavelet patterns and training data. The implemented models can be used for prediction and diagnosis of diseases by classifying the new data. The proposed method enhanced data readability and intuition of feature selection and learning processes by converting the time series of real number data into sequences of symbols. In addition, it facilitates intuitive and easy recognition, and identiﬁcation of inﬂuential patterns. Furthermore, real-time large-capacity data analysis is facilitated, which is essential in the development of real-time analysis diagnosis systems, by drastically reducing the complexity of calculation without deterioration of analysis performance by data simpliﬁcation through the encoding process.},
	language = {en},
	number = {8},
	urldate = {2019-06-25},
	journal = {International Journal of Environmental Research and Public Health},
	author = {Kim, Seonho and Kim, Jungjoon and Chun, Hong-Woo},
	month = aug,
	year = {2018},
	keywords = {dm, eeg-key, ts},
	pages = {1750},
}

@inproceedings{HowExtractMeaningfulShapes,
	address = {Singapore, Singapore},
	title = {How to extract meaningful shapes from noisy time-series subsequences?},
	isbn = {978-1-4673-5895-8},
	url = {http://ieeexplore.ieee.org/document/6597219/},
	doi = {10.1109/CIDM.2013.6597219},
	abstract = {A method for extracting and classifying shapes from noisy time series is proposed. The method consists of two steps. The ﬁrst step is to perform a noise test on each subsequence extracted from the series using a sliding window. All the subsequences recognised as noise are removed from further analysis, and the shapes are extracted from the remaining nonnoise subsequences. The second step is to cluster these extracted shapes. Although extracted from subsequences, these shapes form a non-overlapping set of time series subsequences and are hence amenable to meaningful clustering. The method is primarily designed for extracting and classifying shapes from very noisy real-world time series. Tests using artiﬁcial data with different levels of white noise and the red noise, and the real-world atmospheric turbulence data naturally characterised by strong red noise show that the method is able to correctly extract and cluster shapes from artiﬁcial data and that it has great potential for locating shapes in very noisy real-world time series.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {2013 {IEEE} {Symposium} on {Computational} {Intelligence} and {Data} {Mining} ({CIDM})},
	publisher = {IEEE},
	author = {Kang, Yanfei and Smith-Miles, Kate and Belusic, Danijel},
	month = apr,
	year = {2013},
	keywords = {dm, eeg-key, ts},
	pages = {65--72},
}

@inproceedings{ExactDiscoveryTimeSeries,
	title = {Exact {Discovery} of {Time} {Series} {Motifs}},
	isbn = {978-0-89871-682-5 978-1-61197-279-5},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611972795.41},
	doi = {10.1137/1.9781611972795.41},
	abstract = {Time series motifs are pairs of individual time series, or subsequences of a longer time series, which are very similar to each other. As with their discrete analogues in computational biology, this similarity hints at structure which has been conserved for some reason and may therefore be of interest. Since the formalism of time series motifs in 2002, dozens of researchers have used them for diverse applications in many different domains.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Proceedings of the 2009 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Mueen, Abdullah and Keogh, Eamonn and Zhu, Qiang and Cash, Sydney and Westover, Brandon},
	month = apr,
	year = {2009},
	keywords = {dm, ts},
	pages = {473--484},
}

@article{SIMITSubjectivelyInterestingMotifs,
	title = {{SIMIT}: {Subjectively} {Interesting} {Motifs} in {Time} {Series}},
	volume = {21},
	issn = {1099-4300},
	shorttitle = {{SIMIT}},
	url = {https://www.mdpi.com/1099-4300/21/6/566},
	doi = {10.3390/e21060566},
	abstract = {Numerical time series data are pervasive, originating from sources as diverse as wearable devices, medical equipment, to sensors in industrial plants. In many cases, time series contain interesting information in terms of subsequences that recur in approximate form, so-called motifs. Major open challenges in this area include how one can formalize the interestingness of such motifs and how the most interesting ones can be found. We introduce a novel approach that tackles these issues. We formalize the notion of such subsequence patterns in an intuitive manner and present an information-theoretic approach for quantifying their interestingness with respect to any prior expectation a user may have about the time series. The resulting interestingness measure is thus a subjective measure, enabling a user to ﬁnd motifs that are truly interesting to them. Although ﬁnding the best motif appears computationally intractable, we develop relaxations and a branch-and-bound approach implemented in a constraint programming solver. As shown in experiments on synthetic data and two real-world datasets, this enables us to mine interesting patterns in small or mid-sized time series.},
	language = {en},
	number = {6},
	urldate = {2019-06-25},
	journal = {Entropy},
	author = {Deng, Junning and Lijffijt, Jefrey and Kang, Bo and Bie, Tijl De},
	month = jun,
	year = {2019},
	keywords = {dm, ts},
	pages = {566},
}

@inproceedings{DEEPMOTIFDASHBOARDVISUALIZING,
	address = {Kohala Coast, Hawaii, USA},
	title = {{DEEP} {MOTIF} {DASHBOARD}: {VISUALIZING} {AND} {UNDERSTANDING} {GENOMIC} {SEQUENCES} {USING} {DEEP} {NEURAL} {NETWORKS}},
	isbn = {978-981-320-780-6 978-981-320-781-3},
	shorttitle = {{DEEP} {MOTIF} {DASHBOARD}},
	url = {http://www.worldscientific.com/doi/abs/10.1142/9789813207813_0025},
	doi = {10.1142/9789813207813_0025},
	abstract = {Deep neural network (DNN) models have recently obtained state-of-the-art prediction accuracy for the transcription factor binding (TFBS) site classification task. However, it remains unclear how these approaches identify meaningful DNA sequence signals and give insights as to why TFs bind to certain locations. In this paper, we propose a toolkit called the Deep Motif Dashboard (DeMo Dashboard) which provides a suite of visualization strategies to extract motifs, or sequence patterns from deep neural network models for TFBS classification. We demonstrate how to visualize and understand three important DNN models: convolutional, recurrent, and convolutional-recurrent networks. Our first visualization method is finding a test sequence’s saliency map which uses first-order derivatives to describe the importance of each nucleotide in making the final prediction. Second, considering recurrent models make predictions in a temporal manner (from one end of a TFBS sequence to the other), we introduce temporal output scores, indicating the prediction score of a model over time for a sequential input. Lastly, a class-specific visualization strategy finds the optimal input sequence for a given TFBS positive class via stochastic gradient optimization. Our experimental results indicate that a convolutional-recurrent architecture performs the best among the three architectures. The visualization techniques indicate that CNN-RNN makes predictions by modeling both motifs as well as dependencies among them.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Biocomputing 2017},
	publisher = {WORLD SCIENTIFIC},
	author = {Lanchantin, Jack and Singh, Ritambhara and Wang, Beilun and Qi, Yanjun},
	month = jan,
	year = {2017},
	keywords = {dm, ts},
	pages = {254--265},
}

@article{MatrixProfileIVUsing,
	title = {Matrix profile {IV}: using weakly labeled time series to predict outcomes},
	volume = {10},
	issn = {21508097},
	shorttitle = {Matrix profile {IV}},
	url = {http://dl.acm.org/citation.cfm?doid=3137765.3137784},
	doi = {10.14778/3137765.3137784},
	abstract = {In academic settings over the last decade, there has been significant progress in time series classification. However, much of this work makes assumptions that are simply unrealistic for deployed industrial applications. Examples of these unrealistic assumptions include the following: assuming that data subsequences have a single fixed-length, are precisely extracted from the data, and are correctly labeled according to their membership in a set of equalsize classes. In real-world industrial settings, these patterns can be of different lengths, the class annotations may only belong to a general region of the data, may contain errors, and finally, the class distribution is typically highly skewed. Can we learn from such weakly labeled data? In this work, we introduce SDTS, a scalable algorithm that can learn in such challenging settings. We demonstrate the utility of our ideas by learning from diverse datasets with millions of datapoints. As we shall demonstrate, our domain-agnostic parameter-free algorithm can be competitive with domain-specific algorithms used in neuroscience and entomology, even when those algorithms have been tuned by domain experts to incorporate domain knowledge.},
	language = {en},
	number = {12},
	urldate = {2019-06-25},
	journal = {Proceedings of the VLDB Endowment},
	author = {Yeh, Chin-Chia Michael and Kavantzas, Nickolas and Keogh, Eamonn},
	month = aug,
	year = {2017},
	keywords = {dm, ts},
	pages = {1802--1812},
}

@inproceedings{MatrixProfileAllPairs,
	address = {Barcelona, Spain},
	title = {Matrix {Profile} {I}: {All} {Pairs} {Similarity} {Joins} for {Time} {Series}: {A} {Unifying} {View} {That} {Includes} {Motifs}, {Discords} and {Shapelets}},
	isbn = {978-1-5090-5473-2},
	shorttitle = {Matrix {Profile} {I}},
	url = {http://ieeexplore.ieee.org/document/7837992/},
	doi = {10.1109/ICDM.2016.0179},
	abstract = {The all-pairs-similarity-search (or similarity join) problem has been extensively studied for text and a handful of other datatypes. However, surprisingly little progress has been made on similarity joins for time series subsequences. The lack of progress probably stems from the daunting nature of the problem. For even modest sized datasets the obvious nested-loop algorithm can take months, and the typical speed-up techniques in this domain (i.e., indexing, lower-bounding, triangularinequality pruning and early abandoning) at best produce one or two orders of magnitude speedup. In this work we introduce a novel scalable algorithm for time series subsequence all-pairssimilarity-search. For exceptionally large datasets, the algorithm can be trivially cast as an anytime algorithm and produce highquality approximate solutions in reasonable time. The exact similarity join algorithm computes the answer to the time series motif and time series discord problem as a side-effect, and our algorithm incidentally provides the fastest known algorithm for both these extensively-studied problems. We demonstrate the utility of our ideas for many time series data mining problems, including motif discovery, novelty discovery, shapelet discovery, semantic segmentation, density estimation, and contrast set mining.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Yeh, Chin-Chia Michael and Zhu, Yan and Ulanova, Liudmila and Begum, Nurjahan and Ding, Yifei and Dau, Hoang Anh and Silva, Diego Furtado and Mueen, Abdullah and Keogh, Eamonn},
	month = dec,
	year = {2016},
	keywords = {dm, ts},
	pages = {1317--1322},
}

@inproceedings{FeatureExtractionStackedAutoencoders,
	address = {Chicago, IL},
	title = {Feature extraction with stacked autoencoders for epileptic seizure detection},
	isbn = {978-1-4244-7929-0},
	url = {http://ieeexplore.ieee.org/document/6944546/},
	doi = {10.1109/EMBC.2014.6944546},
	abstract = {Scalp electroencephalogram (EEG), a recording of the brain’s electrical activity, has been used to diagnose and detect epileptic seizures for a long time. However, most researchers have implemented seizure detectors by manually hand-engineering features from observed EEG data, and used them in seizure detection, which might not scale well to new patterns of seizures. In this paper, we investigate the possibility of utilising unsupervised feature learning, the recent development of deep learning, to automatically learn features from raw, unlabelled EEG data that are representative enough to be used in seizure detection. We develop patient-speciﬁc seizure detectors by using stacked autoencoders and logistic classiﬁers. A two-step training consisting of the greedy layerwise and the global ﬁne-tuning was used to train our detectors. The evaluation was performed by using labelled dataset from the CHB-MIT database, and the results showed that all of the test seizures were detected with a mean latency of 3.36 seconds, and a low false detection rate.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {2014 36th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
	publisher = {IEEE},
	author = {Supratak, Akara and {Ling Li} and {Yike Guo}},
	month = aug,
	year = {2014},
	keywords = {dm, ts},
	pages = {4184--4187},
}

@article{SurveyTimeSeriesMotif,
	title = {Survey on time series motif discovery: {Time} series motif discovery},
	volume = {7},
	issn = {19424787},
	shorttitle = {Survey on time series motif discovery},
	url = {http://doi.wiley.com/10.1002/widm.1199},
	doi = {10.1002/widm.1199},
	language = {en},
	number = {2},
	urldate = {2019-06-25},
	journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
	author = {Torkamani, Sahar and Lohweg, Volker},
	month = mar,
	year = {2017},
	keywords = {dm, eeg-key, ts},
	pages = {e1199},
}

@article{TimeSeriesMotifDiscovery,
	title = {Time series motif discovery: dimensions and applications: {Time} series motif discovery},
	volume = {4},
	issn = {19424787},
	shorttitle = {Time series motif discovery},
	url = {http://doi.wiley.com/10.1002/widm.1119},
	doi = {10.1002/widm.1119},
	language = {en},
	number = {2},
	urldate = {2019-06-25},
	journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
	author = {Mueen, Abdullah},
	month = mar,
	year = {2014},
	keywords = {dm, eeg-key, ts},
	pages = {152--159},
}

@article{ReviewSubsequenceTimeSeries,
	title = {A {Review} of {Subsequence} {Time} {Series} {Clustering}},
	volume = {2014},
	issn = {2356-6140, 1537-744X},
	url = {http://www.hindawi.com/journals/tswj/2014/312521/},
	doi = {10.1155/2014/312521},
	abstract = {Clustering of subsequence time series remains an open issue in time series clustering. Subsequence time series clustering is used in different fields, such as e-commerce, outlier detection, speech recognition, biological systems, DNA recognition, and text mining. One of the useful fields in the domain of subsequence time series clustering is pattern recognition. To improve this field, a sequence of time series data is used. This paper reviews some definitions and backgrounds related to subsequence time series clustering. The categorization of the literature reviews is divided into three groups: preproof, interproof, and postproof period. Moreover, various state-of-the-art approaches in performing subsequence time series clustering are discussed under each of the following categories. The strengths and weaknesses of the employed methods are evaluated as potential issues for future studies.},
	language = {en},
	urldate = {2019-06-25},
	journal = {The Scientific World Journal},
	author = {Zolhavarieh, Seyedjamal and Aghabozorgi, Saeed and Teh, Ying Wah},
	year = {2014},
	keywords = {dm, eeg-key, subseq-clustering, ts},
	pages = {1--19},
}

@article{Hdi117GocePetersEecs,
	title = {§hdi117, goce, peters@eecs.northwestern.edu ¶xwang, eamonn@cs.ucr.edu {Northwestern} {University} {University} of {California}, {Riverside} {Evanston}, {IL} 60208 {Riverside}, {CA} 92517},
	abstract = {The last decade has witnessed a tremendous growths of interests in applications that deal with querying and mining of time series data. Numerous representation methods for dimensionality reduction and similarity measures geared towards time series have been introduced. Each individual work introducing a particular method has made speciﬁc claims and, aside from the occasional theoretical justiﬁcations, provided quantitative experimental observations. However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the beneﬁts of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive validation, we conducted an extensive set of time series experiments re-implementing 8 diﬀerent representation methods and 9 similarity measures and their variants, and testing their eﬀectiveness on 38 time series data sets from a wide variety of application domains. In this paper, we give an overview of these diﬀerent techniques and present our comparative experimental ﬁndings regarding their eﬀectiveness. Our experiments have provided both a uniﬁed validation of some of the existing achievements, and in some cases, suggested that certain claims in the literature may be unduly optimistic.},
	language = {en},
	author = {Ding, Hui and Trajcevski, Goce and Scheuermann, Peter and Wang, Xiaoyue and Keogh, Eamonn},
	keywords = {dm, ts},
	pages = {11},
}

@inproceedings{TimeSeriesShapeletsNew,
	address = {Paris, France},
	title = {Time series shapelets: a new primitive for data mining},
	isbn = {978-1-60558-495-9},
	shorttitle = {Time series shapelets},
	url = {http://portal.acm.org/citation.cfm?doid=1557019.1557122},
	doi = {10.1145/1557019.1557122},
	abstract = {Classification of time series has been attracting great interest over the past decade. Recent empirical evidence has strongly suggested that the simple nearest neighbor algorithm is very difficult to beat for most time series problems. While this may be considered good news, given the simplicity of implementing the nearest neighbor algorithm, there are some negative consequences of this. First, the nearest neighbor algorithm requires storing and searching the entire dataset, resulting in a time and space complexity that limits its applicability, especially on resource-limited sensors. Second, beyond mere classification accuracy, we often wish to gain some insight into the data.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Proceedings of the 15th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '09},
	publisher = {ACM Press},
	author = {Ye, Lexiang and Keogh, Eamonn},
	year = {2009},
	keywords = {dm, ts},
	pages = {947},
}

@inproceedings{ProbabilisticDiscoveryTimeSeries,
	address = {Washington, D.C.},
	title = {Probabilistic discovery of time series motifs},
	isbn = {978-1-58113-737-8},
	url = {http://portal.acm.org/citation.cfm?doid=956750.956808},
	doi = {10.1145/956750.956808},
	abstract = {Several important time series data mining problems reduce to the core task of finding approximately repeated subsequences in a longer time series. In an earlier work, we formalized the idea of approximately repeated subsequences by introducing the notion of time series motifs. Two limitations of this work were the poor scalability of the motif discovery algorithm, and the inability to discover motifs in the presence of noise.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Proceedings of the ninth {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining  - {KDD} '03},
	publisher = {ACM Press},
	author = {Chiu, Bill and Keogh, Eamonn and Lonardi, Stefano},
	year = {2003},
	keywords = {dm, ts},
	pages = {493},
}

@inproceedings{OnlineDiscoveryTopkSimilar,
	title = {Online {Discovery} of {Top}-k {Similar} {Motifs} in {Time} {Series} {Data}},
	isbn = {978-0-89871-992-5 978-1-61197-281-8},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611972818.86},
	doi = {10.1137/1.9781611972818.86},
	abstract = {A motif is a pair of non-overlapping sequences with very similar shapes in a time series. We study the online topk most similar motif discovery problem. A special case of this problem corresponding to k = 1 was investigated in the literature by Mueen and Keogh [2]. We generalize the problem to any k and propose space-eﬃcient algorithms for solving it. We show that our algorithms are optimal in term of space. In the particular case when k = 1, our algorithms achieve better performance both in terms of space and time consumption than the algorithm of Mueen and Keogh. We demonstrate our results by both theoretical analysis and extensive experiments with both synthetic and real-life data. We also show possible application of the top-k similar motifs discovery problem.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Proceedings of the 2011 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Lam, Hoang Thanh and Pham, Ninh Dang and Calders, Toon},
	month = apr,
	year = {2011},
	keywords = {dm, ts},
	pages = {1004--1015},
}

@inproceedings{MatrixProfileXISCRIMP,
	address = {Singapore},
	title = {Matrix {Profile} {XI}: {SCRIMP}++: {Time} {Series} {Motif} {Discovery} at {Interactive} {Speeds}},
	isbn = {978-1-5386-9159-5},
	shorttitle = {Matrix {Profile} {XI}},
	url = {https://ieeexplore.ieee.org/document/8594908/},
	doi = {10.1109/ICDM.2018.00099},
	abstract = {Time series motif discovery is an important primitive for time series analytics, and is used in domains as diverse as neuroscience, music and sports analytics. In recent years, algorithmic advances (coupled with hardware improvements) have greatly expanded the purview of motif discovery. Nevertheless, we argue that there is an insatiable need for further scalability. This is because more than most types of analytics, motif discovery benefits from interactivity. The two state-of-the-art algorithms to find motifs are STOMP, which requires O(n2) time, and STAMP, which, despite being an O(logn) factor slower, is the preferred solution for most applications, as it is a fast converging anytime algorithm. In favorable scenarios STAMP needs only to be run to a small fraction of completion to provide a very accurate approximation of the top-k motifs. In this work we introduce SCRIMP++, an O(n2) time algorithm that is also an anytime algorithm, combining the best features of STOMP and STAMP. As we shall show, SCRIMP++ maintains all the desirable properties of the original algorithms, but converges much faster, in almost all scenarios producing the correct output after spending a tiny fraction of the full computation time. We argue that for many end-users, this allows motif discovery to be performed in interactive sessions. Moreover, this interactivity can be game changing in terms of the analytics that can be performed.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {2018 {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Zhu, Yan and Yeh, Chin-Chia Michael and Zimmerman, Zachary and Kamgar, Kaveh and Keogh, Eamonn},
	month = nov,
	year = {2018},
	keywords = {dm, ts},
	pages = {837--846},
}

@article{ExperiencingSAXNovelSymbolic,
	title = {Experiencing {SAX}: a novel symbolic representation of time series},
	volume = {15},
	issn = {1384-5810, 1573-756X},
	shorttitle = {Experiencing {SAX}},
	url = {http://link.springer.com/10.1007/s10618-007-0064-z},
	doi = {10.1007/s10618-007-0064-z},
	abstract = {Many high level representations of time series have been proposed for data mining, including Fourier transforms, wavelets, eigenwaves, piecewise polynomial models etc. Many researchers have also considered symbolic representations of time series, noting that such representations would potentiality allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities. While many symbolic representations of time series have been introduced over the past decades, they all suffer from two fatal flaws. Firstly, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Secondly, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series.},
	language = {en},
	number = {2},
	urldate = {2019-06-25},
	journal = {Data Mining and Knowledge Discovery},
	author = {Lin, Jessica and Keogh, Eamonn and Wei, Li and Lonardi, Stefano},
	month = aug,
	year = {2007},
	keywords = {dm, ts},
	pages = {107--144},
}

@article{EfficientDiscoveryVariablelengthTime,
	title = {Efficient {Discovery} of {Variable}-length {Time} {Series} {Motifs} with {Large} {Length} {Range} in {Million} {Scale} {Time} {Series}},
	url = {http://arxiv.org/abs/1802.04883},
	abstract = {Detecting repeated variable-length patterns, also called variable-length motifs, has received a great amount of attention in recent years. Current state-of-the-art algorithm utilizes ﬁxed-length motif discovery algorithm as a subroutine to enumerate variable-length motifs. As a result, it may take hours or days to execute when enumeration range is large. In this work, we introduce an approximate algorithm called HierarchIcal based Motif Enumeration (HIME) to detect variable-length motifs with a large enumeration range in million-scale time series. We show in the experiments that the scalability of the proposed algorithm is signiﬁcantly better than that of the state-of-theart algorithm. Moreover, the motif length range detected by HIME is considerably larger than previous sequence-matching based approximate variable-length motif discovery approach. We demonstrate that HIME can efﬁciently detect meaningful variable-length motifs in long, real world time series.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1802.04883 [cs]},
	author = {Gao, Yifeng and Lin, Jessica},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.04883},
	keywords = {dm, ts},
}

@article{InterpretableMachineLearningHealthcare,
	title = {Interpretable {Machine} {Learning} in {Healthcare}},
	abstract = {The drive towards greater penetration of machine learning in healthcare is being accompanied by increased calls for machine learning and AI based systems to be regulated and held accountable in healthcare. Interpretable machine learning models can be instrumental in holding machine learning systems accountable. Healthcare offers unique challenges for machine learning where the demands for explainability, model ﬁdelity and performance in general are much higher as compared to most other domains. In this paper we review the notion of interpretability within the context of healthcare, the various nuances associated with it, challenges related to interpretability which are unique to healthcare and the future of interpretability in healthcare.},
	language = {en},
	author = {Ahmad, Muhammad Aurangzeb and Eckert, Carly and Teredesai, Ankur and McKelvey, Greg},
	year = {2018},
	keywords = {fatml, xai},
	pages = {7},
}

@inproceedings{ConversationalExplanationsMachineLearning,
	address = {Stockholm, Sweden},
	title = {Conversational {Explanations} of {Machine} {Learning} {Predictions} {Through} {Class}-contrastive {Counterfactual} {Statements}},
	isbn = {978-0-9992411-2-7},
	url = {https://www.ijcai.org/proceedings/2018/836},
	doi = {10.24963/ijcai.2018/836},
	abstract = {Machine learning models have become pervasive in our everyday life; they decide on important matters inﬂuencing our education, employment and judicial system. Many of these predictive systems are commercial products protected by trade secrets, hence their decision-making is opaque. Therefore, in our research we address interpretability and explainability of predictions made by machine learning models. Our work draws heavily on human explanation research in social sciences: contrastive and exemplar explanations provided through a dialogue. This user-centric design, focusing on a lay audience rather than domain experts, applied to machine learning allows explainees to drive the explanation to suit their needs instead of being served a precooked template.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Proceedings of the {Twenty}-{Seventh} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Sokol, Kacper and Flach, Peter},
	month = jul,
	year = {2018},
	keywords = {fatml, xai},
	pages = {5785--5786},
}

@article{VINEVisualizingStatisticalInteractions,
	title = {{VINE}: {Visualizing} {Statistical} {Interactions} in {Black} {Box} {Models}},
	shorttitle = {{VINE}},
	url = {http://arxiv.org/abs/1904.00561},
	abstract = {As machine learning becomes more pervasive, there is an urgent need for interpretable explanations of predictive models. Prior work has developed effective methods for visualizing global model behavior, as well as generating local (instance-speciﬁc) explanations. However, relatively little work has addressed regional explanations - how groups of similar instances behave in a complex model, and the related issue of visualizing statistical feature interactions. The lack of utilities available for these analytical needs hinders the development of models that are mission-critical, transparent, and align with social goals. We present VINE (Visual INteraction Effects), a novel algorithm to extract and visualize statistical interaction effects in black box models. We also present a novel evaluation metric for visualizations in the interpretable ML space.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1904.00561 [cs, stat]},
	author = {Britton, Matthew},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.00561},
	keywords = {fatml, vis, xai},
}

@article{TimeSeriesVisualizationBased,
	title = {Time series visualization based on shape features},
	volume = {41},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705112003577},
	doi = {10.1016/j.knosys.2012.12.011},
	abstract = {Time series visualization is one of the most fundamental tasks, which is often used to discover patterns by a user interface. Many increasing interests in time series visualization in the last decade have resulted in the development of various state-of-the-art visualization techniques. In most cases, time series visualization is based on one of the representation frameworks which not only reduce the dimensionality, but sufﬁciently reﬂect the shapes of the raw time series as well. In this paper, a new time series visualization based on shape features is proposed to discover surprising patterns and mine frequent trends (motifs discovery). Since the shape features validly summarize both the global and local structures of time series and often use the slopes (or the angles) of the changeable values over time to describe the trends of time series, part of the work is to extract the important shape features and transform them into symbol string. After dimensionality reduction and symbol representation, a circle plotted by the visualization technique is split into many small sectors which simultaneously represent substring patterns of unequal length by multi-resolution function. Since the overall shape features of time series are based on data point importance, the surprising patterns and frequent trends can be accurately discovered even under a high compress ratio. The reﬁned results of patterns discovery and frequent trends mining on ﬁnancial and other time series datasets indicate that the proposed approach is an effective visualization tool for time series mining.},
	language = {en},
	urldate = {2019-06-25},
	journal = {Knowledge-Based Systems},
	author = {Li, Hailin and Yang, Libin},
	month = mar,
	year = {2013},
	keywords = {dm, ts, vis},
	pages = {43--53},
}

@article{ExplainingExplanationPartDeep,
	title = {Explaining {Explanation}, {Part} 4: {A} {Deep} {Dive} on {Deep} {Nets}},
	volume = {33},
	issn = {1541-1672, 1941-1294},
	shorttitle = {Explaining {Explanation}, {Part} 4},
	url = {https://ieeexplore.ieee.org/document/8423529/},
	doi = {10.1109/MIS.2018.033001421},
	language = {en},
	number = {3},
	urldate = {2019-06-25},
	journal = {IEEE Intelligent Systems},
	author = {Hoffman, Robert and Miller, Tim and Mueller, Shane T. and Klein, Gary and Clancey, William J.},
	month = may,
	year = {2018},
	keywords = {fatml, xai},
	pages = {87--95},
}

@article{ContrastiveAlgorithmicFairnessPart,
	title = {Contrastive {Algorithmic} {Fairness}: {Part} 1 ({Theory})},
	shorttitle = {Contrastive {Algorithmic} {Fairness}},
	url = {http://arxiv.org/abs/1905.07360},
	abstract = {Was it fair that Harry was hired but not Barry? Was it fair that Pam was ﬁred instead of Sam? How to ensure fairness when an intelligent algorithm takes these decisions instead of a human? How to ensure that the decisions were taken based on merit and not on protected attributes like race or sex? These are the questions that must be answered now that many decisions in real life can be made through machine learning. However research in fairness of algorithms has focused on the counterfactual questions "what if?" or "why?", whereas in real life most subjective questions of consequence are contrastive: "why this but not that?". We introduce concepts and mathematical tools using causal inference to address contrastive fairness in algorithmic decision-making with illustrative thought examples.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1905.07360 [cs, stat]},
	author = {Chakraborti, Tapabrata and Patra, Arijit and Noble, Alison},
	month = may,
	year = {2019},
	note = {arXiv: 1905.07360},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{CanWeBetterExplanationsa,
	title = {Can we do better explanations? {A} proposal of {User}-{Centered} {Explainable} {AI}},
	abstract = {Artificial Intelligence systems are spreading to multiple applications and they are used by a more diverse audience. With this change of the use scenario, AI users will increasingly require explanations. The first part of this paper makes a review of the state of the art of Explainable AI and highlights how the current research is not paying enough attention to whom the explanations are targeted. In the second part of the paper, it is suggested a new explainability pipeline, where users are classified in three main groups (developers or AI researchers, domain experts and lay users). Inspired by the cooperative principles of conversations, it is discussed how creating different explanations for each of the targeted groups can overcome some of the difficulties related to creating good explanations and evaluating them.},
	language = {en},
	journal = {Los Angeles},
	author = {Ribera, Mireia and Lapedriza, Agata},
	year = {2019},
	keywords = {fatml, hci, xai},
	pages = {7},
}

@article{WhyUnderstandingExplainableArtificial,
	title = {"{But} why?": understanding explainable artificial intelligence},
	volume = {25},
	issn = {15284972},
	shorttitle = {"{But} why?},
	url = {http://dl.acm.org/citation.cfm?doid=3325198.3313107},
	doi = {10.1145/3313107},
	language = {en},
	number = {3},
	urldate = {2019-06-25},
	journal = {XRDS: Crossroads, The ACM Magazine for Students},
	author = {Miller, Tim},
	month = apr,
	year = {2019},
	keywords = {fatml, theory, xai},
	pages = {20--25},
}

@article{SurrogateDecisionTreeVisualization,
	title = {Surrogate {Decision} {Tree} {Visualization}},
	language = {en},
	author = {Castro, Federica Di and Bertini, Enrico},
	keywords = {fatml, vis, xai},
	pages = {5},
}

@article{VisualizingDiscoveringNonTrivialPatterns,
	title = {Visualizing and {Discovering} {Non}-{Trivial} {Patterns} in {Large} {Time} {Series} {Databases}},
	volume = {4},
	issn = {1473-8716, 1473-8724},
	url = {http://journals.sagepub.com/doi/10.1057/palgrave.ivs.9500089},
	doi = {10.1057/palgrave.ivs.9500089},
	abstract = {Data visualization techniques are very important for data analysis, since the human eye has been frequently advocated as the ultimate data-mining tool. However, there has been surprisingly little work on visualizing massive time series datasets. To this end, we developed VizTree, a time series pattern discovery and visualization system based on augmenting suffix trees. VizTree visually summarizes both the global and local structures of time series data at the same time. In addition, it provides novel interactive solutions to many pattern discovery problems, including the discovery of frequently occurring patterns (motif discovery), surprising patterns (anomaly detection), and query by content. VizTree works by transforming the time series into a symbolic representation, and encoding the data in a modified suffix tree in which the frequency and other properties of patterns are mapped onto colors and other visual properties. We demonstrate the utility of our system by comparing it with state-ofthe-art batch algorithms on several real and synthetic datasets. Based on the tree structure, we further device a coefficient which measures the dissimilarity between any two time series. This coefficient is shown to be competitive with the well-known Euclidean distance.},
	language = {en},
	number = {2},
	urldate = {2019-06-25},
	journal = {Information Visualization},
	author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano},
	month = jun,
	year = {2005},
	keywords = {dm, ts},
	pages = {61--82},
}

@article{TimeFrequencyBasedMethodsNonStationary,
	title = {Time-{Frequency} {Based} {Methods} for {Non}-{Stationary} {Signal} {Analysis} with {Application} {To} {EEG} {Signals}},
	language = {en},
	author = {Feltane, Amal},
	keywords = {dm, ts},
	pages = {176},
}

@article{MultitaskLearningBenchmarkingClinical,
	title = {Multitask {Learning} and {Benchmarking} with {Clinical} {Time} {Series} {Data}},
	url = {http://arxiv.org/abs/1703.07771},
	abstract = {Health care is one of the most exciting frontiers in data mining and machine learning. Successful adoption of electronic health records (EHRs) created an explosion in digital clinical data available for analysis, but progress in machine learning for healthcare research has been difﬁcult to measure because of the absence of publicly available benchmark data sets. To address this problem, we propose four clinical prediction benchmarks using data derived from the publicly available Medical Information Mart for Intensive Care (MIMIC-III) database. These tasks cover a range of clinical problems including modeling risk of mortality, forecasting length of stay, detecting physiologic decline, and phenotype classiﬁcation. We propose strong linear and neural baselines for all four tasks and evaluate the effect of deep supervision, multitask training and data-speciﬁc architectural modiﬁcations on the performance of neural models.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1703.07771 [cs, stat]},
	author = {Harutyunyan, Hrayr and Khachatrian, Hrant and Kale, David C. and Steeg, Greg Ver and Galstyan, Aram},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.07771},
	keywords = {fatml, xai},
}

@article{AnchorsHighPrecisionModelAgnostic,
	title = {Anchors: {High} {Precision} {Model}-{Agnostic} {Explanations}},
	abstract = {We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules called anchors, representing local, “sufﬁcient” conditions for predictions. We propose an algorithm to efﬁciently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the ﬂexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision, as compared to existing linear explanations or no explanations.},
	language = {en},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	keywords = {explainable, fatml, xai},
	pages = {9},
}

@inproceedings{InteractingPredictionsVisualInspection,
	address = {Santa Clara, California, USA},
	title = {Interacting with {Predictions}: {Visual} {Inspection} of {Black}-box {Machine} {Learning} {Models}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Interacting with {Predictions}},
	url = {http://dl.acm.org/citation.cfm?doid=2858036.2858529},
	doi = {10.1145/2858036.2858529},
	abstract = {Understanding predictive models, in terms of interpreting and identifying actionable insights, is a challenging task. Often the importance of a feature in a model is only a rough estimate condensed into one number. However, our research goes beyond these na¨ıve estimates through the design and implementation of an interactive visual analytics system, Prospector. By providing interactive partial dependence diagnostics, data scientists can understand how features affect the prediction overall. In addition, our support for localized inspection allows data scientists to understand how and why speciﬁc datapoints are predicted as they are, as well as support for tweaking feature values and seeing how the prediction responds. Our system is then evaluated using a case study involving a team of data scientists improving predictive models for detecting the onset of diabetes from electronic medical records.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '16},
	publisher = {ACM Press},
	author = {Krause, Josua and Perer, Adam and Ng, Kenney},
	year = {2016},
	keywords = {fatml, vis},
	pages = {5686--5697},
}

@article{SemanticExplanationsPredictions,
	title = {Semantic {Explanations} of {Predictions}},
	url = {http://arxiv.org/abs/1805.10587},
	abstract = {The main objective of explanations is to transmit knowledge to humans. This work proposes to construct informative explanations for predictions made from machine learning models. Motivated by the observations from social sciences, our approach selects data points from the training sample that exhibit special characteristics crucial for explanation, for instance, ones contrastive to the classiﬁcation prediction and ones representative of the models. Subsequently, semantic concepts are derived from the selected data points through the use of domain ontologies. These concepts are ﬁltered and ranked to produce informative explanations that improves human understanding. The main features of our approach are that (1) knowledge about explanations is captured in the form of ontological concepts, (2) explanations include contrastive evidences in addition to normal evidences, and (3) explanations are user relevant.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1805.10587 [cs]},
	author = {Lecue, Freddy and Wu, Jiewen},
	month = may,
	year = {2018},
	note = {arXiv: 1805.10587},
	keywords = {explainable, explanation, fatml, xai},
}

@inproceedings{InterpretableDecisionSetsJointa,
	address = {San Francisco, California, USA},
	title = {Interpretable {Decision} {Sets}: {A} {Joint} {Framework} for {Description} and {Prediction}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {Interpretable {Decision} {Sets}},
	url = {http://dl.acm.org/citation.cfm?doid=2939672.2939874},
	doi = {10.1145/2939672.2939874},
	abstract = {One of the most important obstacles to deploying predictive models is the fact that humans do not understand and trust them. Knowing which variables are important in a model’s prediction and how they are combined can be very powerful in helping people understand and trust automatic decision making systems.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining} - {KDD} '16},
	publisher = {ACM Press},
	author = {Lakkaraju, Himabindu and Bach, Stephen H. and Leskovec, Jure},
	year = {2016},
	keywords = {fatml, xai},
	pages = {1675--1684},
}

@article{HowHumansUnderstandExplanations,
	title = {How do {Humans} {Understand} {Explanations} from {Machine} {Learning} {Systems}? {An} {Evaluation} of the {Human}-{Interpretability} of {Explanation}},
	shorttitle = {How do {Humans} {Understand} {Explanations} from {Machine} {Learning} {Systems}?},
	url = {http://arxiv.org/abs/1802.00682},
	abstract = {Recent years have seen a boom in interest in machine learning systems that can provide a human-understandable rationale for their predictions or decisions. However, exactly what kinds of explanation are truly human-interpretable remains poorly understood. This work advances our understanding of what makes explanations interpretable in the speciﬁc context of veriﬁcation. Suppose we have a machine learning system that predicts X, and we provide rationale for this prediction X. Given an input, an explanation, and an output, is the output consistent with the input and the supposed rationale? Via a series of user-studies, we identify what kinds of increases in complexity have the greatest effect on the time it takes for humans to verify the rationale, and which seem relatively insensitive.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1802.00682 [cs]},
	author = {Narayanan, Menaka and Chen, Emily and He, Jeffrey and Kim, Been and Gershman, Sam and Doshi-Velez, Finale},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.00682},
	keywords = {fatml, hci, key, xai},
}

@inproceedings{FairnessAccountabilityDesignNeeds,
	address = {Montreal QC, Canada},
	title = {Fairness and {Accountability} {Design} {Needs} for {Algorithmic} {Support} in {High}-{Stakes} {Public} {Sector} {Decision}-{Making}},
	isbn = {978-1-4503-5620-6},
	url = {http://dl.acm.org/citation.cfm?doid=3173574.3174014},
	doi = {10.1145/3173574.3174014},
	abstract = {Calls for heightened consideration of fairness and accountability in algorithmically-informed public decisions—like taxation, justice, and child protection—are now commonplace. How might designers support such human values? We interviewed 27 public sector machine learning practitioners across 5 OECD countries regarding challenges understanding and imbuing public values into their work. The results suggest a disconnect between organisational and institutional realities, constraints and needs, and those addressed by current research into usable, transparent and ‘discrimination-aware’ machine learning—absences likely to undermine practical initiatives unless addressed. We see design opportunities in this disconnect, such as in supporting the tracking of concept drift in secondary data sources, and in building usable transparency tools to identify risks and incorporate domain knowledge, aimed both at managers and at the ‘street-level bureaucrats’ on the frontlines of public service. We conclude by outlining ethical challenges and future directions for collaboration in these high-stakes applications.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '18},
	publisher = {ACM Press},
	author = {Veale, Michael and Van Kleek, Max and Binns, Reuben},
	year = {2018},
	keywords = {fatml, hci, xai},
	pages = {1--14},
}

@incollection{ExplanationsCaseBasedReasoningFoundationala,
	address = {Berlin, Heidelberg},
	title = {Explanations and {Case}-{Based} {Reasoning}: {Foundational} {Issues}},
	volume = {3155},
	isbn = {978-3-540-22882-0 978-3-540-28631-8},
	shorttitle = {Explanations and {Case}-{Based} {Reasoning}},
	url = {http://link.springer.com/10.1007/978-3-540-28631-8_29},
	abstract = {By design, Case-Based Reasoning (CBR) systems do not need deep general knowledge. In contrast to (rule-based) expert systems, CBR systems can already be used with just some initial knowledge. Further knowledge can then be added manually or learned over time. CBR systems are not addressing a special group of users. Expert systems, on the other hand, are intended to solve problems similar to human experts. Because of the complexity and diﬃculty of building and using expert systems, research in this area addressed generating explanations right from the beginning. But for knowledge-intensive CBR applications, the demand for explanations is also growing. This paper is a ﬁrst pass on examining issues concerning explanations produced by CBR systems from the knowledge containers perspective. It discusses what naturally can be explained by each of the four knowledge containers (vocabulary, similarity measures, adaptation knowledge, and case base) in relation to scientiﬁc, conceptual, and cognitive explanations.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Advances in {Case}-{Based} {Reasoning}},
	publisher = {Springer Berlin Heidelberg},
	author = {Roth-Berghofer, Thomas R.},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Funk, Peter and González Calero, Pedro A.},
	year = {2004},
	doi = {10.1007/978-3-540-28631-8_29},
	keywords = {fatml, theory, xai},
	pages = {389--403},
}

@article{DecisionMakingVisualizationsCognitive,
	title = {Decision making with visualizations: a cognitive framework across disciplines},
	volume = {3},
	issn = {2365-7464},
	shorttitle = {Decision making with visualizations},
	url = {https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-018-0120-9},
	doi = {10.1186/s41235-018-0120-9},
	abstract = {Visualizations—visual representations of information, depicted in graphics—are studied by researchers in numerous ways, ranging from the study of the basic principles of creating visualizations, to the cognitive processes underlying their use, as well as how visualizations communicate complex information (such as in medical risk or spatial patterns). However, findings from different domains are rarely shared across domains though there may be domaingeneral principles underlying visualizations and their use. The limited cross-domain communication may be due to a lack of a unifying cognitive framework. This review aims to address this gap by proposing an integrative model that is grounded in models of visualization comprehension and a dual-process account of decision making. We review empirical studies of decision making with static two-dimensional visualizations motivated by a wide range of research goals and find significant direct and indirect support for a dual-process account of decision making with visualizations. Consistent with a dual-process model, the first type of visualization decision mechanism produces fast, easy, and computationally light decisions with visualizations. The second facilitates slower, more contemplative, and effortful decisions with visualizations. We illustrate the utility of a dual-process account of decision making with visualizations using four cross-domain findings that may constitute universal visualization principles. Further, we offer guidance for future research, including novel areas of exploration and practical recommendations for visualization designers based on cognitive theory and empirical findings.},
	language = {en},
	number = {1},
	urldate = {2019-06-25},
	journal = {Cognitive Research: Principles and Implications},
	author = {Padilla, Lace M. and Creem-Regehr, Sarah H. and Hegarty, Mary and Stefanucci, Jeanine K.},
	month = dec,
	year = {2018},
	keywords = {fatml, vis},
	pages = {29},
}

@article{TEDTeachingAIExplain,
	title = {{TED}: {Teaching} {AI} to {Explain} its {Decisions}},
	shorttitle = {{TED}},
	url = {http://arxiv.org/abs/1811.04896},
	abstract = {Artiﬁcial intelligence systems are being increasingly deployed due to their potential to increase the efﬁciency, scale, consistency, fairness, and accuracy of decisions. However, as many of these systems are opaque in their operation, there is a growing demand for such systems to provide explanations for their decisions. Conventional approaches to this problem attempt to expose or discover the inner workings of a machine learning model with the hope that the resulting explanations will be meaningful to the consumer. In contrast, this paper suggests a new approach to this problem. It introduces a simple, practical framework, called Teaching Explanations for Decisions (TED), that provides meaningful explanations that match the mental model of the consumer. We illustrate the generality and effectiveness of this approach with two different examples, resulting in highly accurate explanations with no loss of prediction accuracy for these two examples.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1811.04896 [cs]},
	author = {Hind, Michael and Wei, Dennis and Campbell, Murray and Codella, Noel C. F. and Dhurandhar, Amit and Mojsilović, Aleksandra and Ramamurthy, Karthikeyan Natesan and Varshney, Kush R.},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.04896},
	keywords = {fatml, xai},
}

@inproceedings{FastShapeletsScalableAlgorithm,
	title = {Fast {Shapelets}: {A} {Scalable} {Algorithm} for {Discovering} {Time} {Series} {Shapelets}},
	isbn = {978-1-61197-262-7 978-1-61197-283-2},
	shorttitle = {Fast {Shapelets}},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611972832.74},
	doi = {10.1137/1.9781611972832.74},
	abstract = {Time series shapelets are a recent promising concept in time series data mining. Shapelets are time series snippets that can be used to classify unlabeled time series. Shapelets not only provide interpretable results, which are useful for domain experts and developers alike, but shapelet-based classifiers have been shown by several independent research groups to have superior accuracy on many datasets. Moreover, shapelets can be seen as generalizing the lazy nearest neighbor classifier to an eager classifier. Thus, as a deployed classification tool, shapelets can be many orders of magnitude faster than any rival with comparable accuracy.},
	language = {en},
	urldate = {2019-06-26},
	booktitle = {Proceedings of the 2013 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Rakthanmanon, Thanawin and Keogh, Eamonn},
	month = may,
	year = {2013},
	keywords = {dm, ts},
	pages = {668--676},
}

@inproceedings{TooMuchTooLittlea,
	address = {San Jose, CA, USA},
	title = {Too much, too little, or just right? {Ways} explanations impact end users' mental models},
	isbn = {978-1-4799-0369-6},
	shorttitle = {Too much, too little, or just right?},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6645235},
	doi = {10.1109/VLHCC.2013.6645235},
	abstract = {Research is emerging on how end users can correct mistakes their intelligent agents make, but before users can correctly “debug” an intelligent agent, they need some degree of understanding of how it works. In this paper we consider ways intelligent agents should explain themselves to end users, especially focusing on how the soundness and completeness of the explanations impacts the fidelity of end users’ mental models. Our findings suggest that completeness is more important than soundness: increasing completeness via certain information types helped participants’ mental models and, surprisingly, their perception of the cost/benefit tradeoff of attending to the explanations. We also found that oversimplification, as per many commercial agents, can be a problem: when soundness was very low, participants experienced more mental demand and lost trust in the explanations, thereby reducing the likelihood that users will pay attention to such explanations at all.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {2013 {IEEE} {Symposium} on {Visual} {Languages} and {Human} {Centric} {Computing}},
	publisher = {IEEE},
	author = {Kulesza, Todd and Stumpf, Simone and Burnett, Margaret and Yang, Sherry and Kwan, Irwin and Wong, Weng-Keen},
	month = sep,
	year = {2013},
	keywords = {fatml, iml, xai},
	pages = {3--10},
}

@article{UnderstandingDecisionMakingCritical,
	title = {Understanding {Decision} {Making} in {Critical} {Care}},
	volume = {13},
	issn = {1539-4182, 1554-6179},
	url = {http://www.clinmedres.org/cgi/doi/10.3121/cmr.2015.1289},
	doi = {10.3121/cmr.2015.1289},
	language = {en},
	number = {3-4},
	urldate = {2019-06-25},
	journal = {Clinical Medicine \& Research},
	author = {Lighthall, G. K. and Vazquez-Guillamet, C.},
	month = dec,
	year = {2015},
	keywords = {fatml, xai},
	pages = {156--168},
}

@inproceedings{RoleExplanationsTrustReliancea,
	address = {Dallas, TX, USA},
	title = {The {Role} of {Explanations} on {Trust} and {Reliance} in {Clinical} {Decision} {Support} {Systems}},
	isbn = {978-1-4673-9548-9},
	url = {http://ieeexplore.ieee.org/document/7349687/},
	doi = {10.1109/ICHI.2015.26},
	abstract = {Clinical decision support systems (CDSS) are increasingly used by healthcare professionals for evidence-based diagnosis and treatment support. However, research has suggested that users often over-rely on system suggestions – even if the suggestions are wrong. Providing explanations could potentially mitigate misplaced trust in the system and overreliance. In this paper, we explore how explanations are related to user trust and reliance, as well as what information users would find helpful to better understand the reliability of a system's decision-making. We investigated these questions through an exploratory user study in which healthcare professionals were observed using a CDSS prototype to diagnose hypothetic cases using fictional patients suffering from a balancerelated disorder. Our results show that the amount of system confidence had only a slight effect on trust and reliance. More importantly, giving a fuller explanation of the facts used in making a diagnosis had a positive effect on trust but also led to over-reliance issues, whereas less detailed explanations made participants question the system's reliability and led to selfreliance problems. To help them in their assessment of the reliability of the system's decisions, study participants wanted better explanations to help them interpret the system's confidence, to verify that the disorder fit the suggestion, to better understand the reasoning chain of the decision model, and to make differential diagnoses. Our work is a first step toward improved CDSS design that better supports clinicians in making correct diagnoses.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {2015 {International} {Conference} on {Healthcare} {Informatics}},
	publisher = {IEEE},
	author = {Bussone, Adrian and Stumpf, Simone and O'Sullivan, Dympna},
	month = oct,
	year = {2015},
	keywords = {fatml, hci, vis, xai},
	pages = {160--169},
}

@inproceedings{PrinciplesExplanatoryDebuggingPersonalizea,
	address = {Atlanta, Georgia, USA},
	title = {Principles of {Explanatory} {Debugging} to {Personalize} {Interactive} {Machine} {Learning}},
	isbn = {978-1-4503-3306-1},
	url = {http://dl.acm.org/citation.cfm?doid=2678025.2701399},
	doi = {10.1145/2678025.2701399},
	abstract = {How can end users eﬃciently inﬂuence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging, an approach in which the system explains to users how it made each of its predictions, and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants’ understanding of the learning system by 52\% and allowed participants to correct its mistakes up to twice as eﬃciently as participants using a traditional learning system.},
	language = {en},
	urldate = {2019-06-25},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '15},
	publisher = {ACM Press},
	author = {Kulesza, Todd and Burnett, Margaret and Wong, Weng-Keen and Stumpf, Simone},
	year = {2015},
	keywords = {fatml, hci, xai},
	pages = {126--137},
}

@article{NJoinCourtenayNjoinComa,
	title = {n-{Join} courtenay@n-join.com},
	abstract = {We present a survey of the research concerning explanation and justiﬁcation in the Machine Learning literature and several adjacent ﬁelds. Within Machine Learning, we differentiate between two main branches of current research: interpretable models, and prediction interpretation and justiﬁcation.},
	language = {en},
	author = {Cotton, Courtenay},
	keywords = {fatml, xai},
	pages = {6},
}

@article{WhatWeNeedBuild,
	title = {What do we need to build explainable {AI} systems for the medical domain?},
	url = {http://arxiv.org/abs/1712.09923},
	abstract = {Artiﬁcial intelligence (AI) generally and machine learning (ML) speciﬁcally demonstrate impressive practical success in many diﬀerent application domains, e.g. in autonomous driving, speech recognition, or recommender systems. Deep learning approaches, trained on extremely large data sets or using reinforcement learning methods have even exceeded human performance in visual tasks, particularly on playing games such as Atari, or mastering the game of Go. Even in the medical domain there are remarkable results. However, the central problem of such models is that they are regarded as black-box models and even if we understand the underlying mathematical principles of such models they lack an explicit declarative knowledge representation, hence have diﬃculty in generating the underlying explanatory structures. This calls for systems enabling to make decisions transparent, understandable and explainable. A huge motivation for our approach are rising legal and privacy aspects. The new European General Data Protection Regulation (GDPR and ISO/IEC 27001) entering into force on May 25th 2018, will make black-box approaches diﬃcult to use in business. This does not imply a ban on automatic learning approaches or an obligation to explain everything all the time, however, there must be a possibility to make the results re-traceable on demand. This is beneﬁcial, e.g. for general understanding, for teaching, for learning, for research, and it can be helpful in court. In this paper we outline some of our research topics in the context of the relatively new area of explainable-AI with a focus on the application in medicine, which is a very special domain. This is due to the fact that medical professionals are working mostly with distributed heterogeneous and complex sources of data. In this paper we concentrate on three sources: images, *omics data and text. We argue that research in explainable-AI would generally help to facilitate the implementation of AI/ML in the medical domain, and speciﬁcally help to facilitate transparency and trust.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1712.09923 [cs, stat]},
	author = {Holzinger, Andreas and Biemann, Chris and Pattichis, Constantinos S. and Kell, Douglas B.},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.09923},
	keywords = {fatml, health, xai},
}

@article{VisualInterpretabilityDeepLearning,
	title = {Visual {Interpretability} for {Deep} {Learning}: a {Survey}},
	shorttitle = {Visual {Interpretability} for {Deep} {Learning}},
	url = {http://arxiv.org/abs/1802.00614},
	abstract = {This paper reviews recent studies in understanding neural-network representations and learning neural networks with interpretable/disentangled middlelayer representations. Although deep neural networks have exhibited superior performance in various tasks, the interpretability is always the Achilles’ heel of deep neural networks. At present, deep neural networks obtain high discrimination power at the cost of low interpretability of their black-box representations. We believe that high model interpretability may help people to break several bottlenecks of deep learning, e.g. learning from very few annotations, learning via humancomputer communications at the semantic level, and semantically debugging network representations. We focus on convolutional neural networks (CNNs), and we revisit the visualization of CNN representations, methods of diagnosing representations of pre-trained CNNs, approaches for disentangling pre-trained CNN representations, learning of CNNs with disentangled representations, and middle-to-end learning based on model interpretability. Finally, we discuss prospective trends in explainable artiﬁcial intelligence.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1802.00614 [cs]},
	author = {Zhang, Quanshi and Zhu, Song-Chun},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.00614},
	keywords = {dl, fatml, survey, vis},
}

@article{StructureFunctionExplanationsa,
	title = {The structure and function of explanations},
	volume = {10},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661306002117},
	doi = {10.1016/j.tics.2006.08.004},
	language = {en},
	number = {10},
	urldate = {2019-06-25},
	journal = {Trends in Cognitive Sciences},
	author = {Lombrozo, Tania},
	month = oct,
	year = {2006},
	keywords = {fatml, theory, xai},
	pages = {464--470},
}

@article{RationalizingNeuralPredictions,
	title = {Rationalizing {Neural} {Predictions}},
	url = {http://arxiv.org/abs/1606.04155},
	abstract = {Prediction without justification has limited applicability. As a remedy, we learn to extract pieces of input text as justifications -- rationales -- that are tailored to be short and coherent, yet sufficient for making the same prediction. Our approach combines two modular components, generator and encoder, which are trained to operate well together. The generator specifies a distribution over text fragments as candidate rationales and these are passed through the encoder for prediction. Rationales are never given during training. Instead, the model is regularized by desiderata for rationales. We evaluate the approach on multi-aspect sentiment analysis against manually annotated test cases. Our approach outperforms attention-based baseline by a significant margin. We also successfully illustrate the method on the question retrieval task.},
	language = {en},
	urldate = {2019-06-25},
	journal = {arXiv:1606.04155 [cs]},
	author = {Lei, Tao and Barzilay, Regina and Jaakkola, Tommi},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.04155},
	keywords = {dl, fatml, xai},
}

@inproceedings{DrainingDataSwampSimilaritybaseda,
	address = {Houston, TX, USA},
	title = {Draining the {Data} {Swamp}: {A} {Similarity}-based {Approach}},
	isbn = {978-1-4503-5827-9},
	shorttitle = {Draining the {Data} {Swamp}},
	url = {http://dl.acm.org/citation.cfm?doid=3209900.3209911},
	doi = {10.1145/3209900.3209911},
	abstract = {While hierarchical namespaces such as filesystems and repositories have long been used to organize data, the rapid increase in data production places increasing strain on users who wish to make use of the data. So called “data lakes” embrace the storage of data in its natural form, integrating and organizing in a Pay-as-you-go fashion. While this model defers the upfront cost of integration, the result is that data is unusable for discovery or analysis until it is processed. Thus, data scientists are forced to spend significant time and energy on mundane tasks such as data discovery, cleaning, integration, and management – when this is neglected, “data lakes” become “data swamps.” Prior work suggests that pure computational methods for resolving issues with the data discovery and management components are insufficient. Here, we provide evidence to confirm this hypothesis, showing that methods such as automated file clustering are unable to extract the necessary features from repositories to provide useful information to end-user data scientists, or make effective data management decisions on their behalf. We argue that the combination of frameworks for specifying file similarity and human-in-the-loop interaction is needed to aid automated organization. We propose an initial step here, classifying several dimensions by which items may be considered similar: the data, its origin, and its current characteristics. We initially consider this model in the context of identifying data that can be integrated or managed collectively. We additionally explore how current methods can be used to automate decision making using real-world data repository and file systems, and suggest how an online user study could be developed to further validate this hypothesis. ACM Reference format: Will Brackenbury, Rui Liu, Mainack Mondal, Aaron J. Elmore, Blase Ur, Kyle Chard, Michael J. Franklin . 2018. Draining the Data Swamp: A Similaritybased Approach. In Proceedings of HILDA ’18, Houston, TX, USA, June 10, 2018, 7 pages.},
	language = {en},
	urldate = {2019-07-02},
	booktitle = {Proceedings of the {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics}  - {HILDA}'18},
	publisher = {ACM Press},
	author = {Brackenbury, Will and Liu, Rui and Mondal, Mainack and Elmore, Aaron J. and Ur, Blase and Chard, Kyle and Franklin, Michael J.},
	year = {2018},
	keywords = {fatml, iml, xai},
	pages = {1--7},
}

@article{HelixAcceleratingHumanintheloopMachinea,
	title = {Helix: {Accelerating} {Human}-in-the-loop {Machine} {Learning}},
	volume = {11},
	issn = {21508097},
	shorttitle = {Helix},
	url = {http://arxiv.org/abs/1808.01095},
	doi = {10.14778/3229863.3236234},
	abstract = {Data application developers and data scientists spend an inordinate amount of time iterating on machine learning (ML) workﬂows—by modifying the data pre-processing, model training, and postprocessing steps—via trial-and-error to achieve the desired model performance. Existing work on accelerating machine learning focuses on speeding up one-shot execution of workﬂows, failing to address the incremental and dynamic nature of typical ML development. We propose HELIX, a declarative machine learning system that accelerates iterative development by optimizing workﬂow execution end-to-end and across iterations. HELIX minimizes the runtime per iteration via program analysis and intelligent reuse of previous results, which are selectively materialized—trading off the cost of materialization for potential future beneﬁts—to speed up future iterations. Additionally, HELIX offers a graphical interface to visualize workﬂow DAGs and compare versions to facilitate iterative development. Through two ML applications, in classiﬁcation and in structured prediction, attendees will experience the succinctness of HELIX’s programming interface and the speed and ease of iterative development using HELIX. In our evaluations, HELIX achieved up to an order of magnitude reduction in cumulative run time compared to state-of-the-art machine learning tools.},
	language = {en},
	number = {12},
	urldate = {2019-07-02},
	journal = {Proceedings of the VLDB Endowment},
	author = {Xin, Doris and Ma, Litian and Liu, Jialin and Macke, Stephen and Song, Shuchen and Parameswaran, Aditya},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.01095},
	keywords = {fatml, iml, vis},
	pages = {1958--1961},
}

@article{InteractiveKnowledgeDiscoveryDoctorintheloopa,
	title = {Interactive knowledge discovery with the doctor-in-the-loop: a practical example of cerebral aneurysms research},
	volume = {3},
	issn = {2198-4018, 2198-4026},
	shorttitle = {Interactive knowledge discovery with the doctor-in-the-loop},
	url = {http://link.springer.com/10.1007/s40708-016-0038-2},
	doi = {10.1007/s40708-016-0038-2},
	language = {en},
	number = {3},
	urldate = {2019-07-02},
	journal = {Brain Informatics},
	author = {Girardi, Dominic and Küng, Josef and Kleiser, Raimund and Sonnberger, Michael and Csillag, Doris and Trenkler, Johannes and Holzinger, Andreas},
	month = sep,
	year = {2016},
	keywords = {fatml, iml, xai},
	pages = {133--143},
}

@article{HumanCenteredMachineLearningInteractivea,
	title = {Human-{Centered} {Machine} {Learning} {Through} {Interactive} {Visualization}: {Review} and {Open} {Challenges}},
	abstract = {The goal of visual analytics (VA) systems is to solve complex problems by integrating automated data analysis methods, such as machine learning (ML) algorithms, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and makes the crucial interplay between automated algorithms and interactive visualizations more concrete. The framework is illustrated through several examples. We derive three open research challenges at the intersection of ML and visualization research that will lead to more effective data analysis.},
	language = {en},
	journal = {Computational Intelligence},
	author = {Sacha, Dominik and Sedlmair, Michael and Zhang, Leishi and Lee, John Aldo and Weiskopf, Daniel and North, Stephen and Keim, Daniel},
	year = {2016},
	keywords = {fatml, survey, vis, xai},
	pages = {7},
}

@article{OntologybasedInferenceCausalExplanationa,
	title = {Ontology-based inference for causal explanation},
	url = {http://arxiv.org/abs/1004.4801},
	abstract = {We deﬁne an inference system to capture explanations based on causal statements, using an ontology in the form of an IS-A hierarchy. We ﬁrst introduce a simple logical language which makes it possible to express that a fact causes another fact and that a fact explains another fact. We present a set of formal inference patterns from causal statements to explanation statements. We introduce an elementary ontology which gives greater expressiveness to the system while staying close to propositional reasoning. We provide an inference system that captures the patterns discussed, ﬁrstly in a purely propositional framework, then in a datalog (limited predicate) framework.},
	language = {en},
	urldate = {2019-07-02},
	journal = {arXiv:1004.4801 [cs]},
	author = {Besnard, Philippe and Cordier, Marie-Odile and Moinard, Yves},
	month = apr,
	year = {2010},
	note = {arXiv: 1004.4801},
	keywords = {fatml, xai},
}

@inproceedings{PALMMachineLearningExplanationsa,
	address = {Chicago, IL, USA},
	title = {{PALM}: {Machine} {Learning} {Explanations} {For} {Iterative} {Debugging}},
	isbn = {978-1-4503-5029-7},
	shorttitle = {{PALM}},
	url = {http://dl.acm.org/citation.cfm?doid=3077257.3077271},
	doi = {10.1145/3077257.3077271},
	abstract = {When a Deep Neural Network makes a misprediction, it can be challenging for a developer to understand why. While there are many models for interpretability in terms of predictive features, it may be more natural to isolate a small set of training examples that have the greatest inﬂuence on the prediction. However, it is often the case that every training example contributes to a prediction in some way but with varying degrees of responsibility. We present Partition Aware Local Model (PALM), which is a tool that learns and summarizes this responsibility structure to aide machine learning debugging. PALM approximates a complex model (e.g., a deep neural network) using a two-part surrogate model: a meta-model that partitions the training data, and a set of sub-models that approximate the patterns within each partition. These sub-models can be arbitrarily complex to capture intricate local patterns. However, the metamodel is constrained to be a decision tree. This way the user can examine the structure of the meta-model, determine whether the rules match intuition, and link problematic test examples to responsible training data efﬁciently. Queries to PALM are nearly 30x faster than nearest neighbor queries for identifying relevant data, which is a key property for interactive applications.},
	language = {en},
	urldate = {2019-07-02},
	booktitle = {Proceedings of the 2nd {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics}  - {HILDA}'17},
	publisher = {ACM Press},
	author = {Krishnan, Sanjay and Wu, Eugene},
	year = {2017},
	keywords = {fatml, vis, xai},
	pages = {1--6},
}

@article{UnifiedRepresentationInsightHumanintheLoopa,
	title = {Towards a {Unified} {Representation} of {Insight} in {Human}-in-the-{Loop} {Analytics}: {A} {User} {Study}},
	abstract = {Understanding what insights people draw from data visualizations is critical for human-in-the loop analytics systems to facilitate mixed-initiative analysis. In this paper we present results from a large user study on insights extracted from commonly used charts. We report several patterns of insights we observed and analyze their semantic structure to identify key considerations towards a unified formal representation of insight, human or computer generated. We also present a model of insight generation process, where humans and computers work cooperatively, building on each other’s knowledge, where a common representation acts as the currency of interaction. While not going as far as proposing a formalism, we point to a few potential directions for representing insight. We believe our findings could also inform the design of novel human-in-the-loop analytics systems.},
	language = {en},
	author = {Kandogan, Eser and Engelke, Ulrich},
	year = {2018},
	keywords = {fatml, iml, xai},
	pages = {7},
}

@article{PowerPeopleRoleHumans,
	title = {Power to the {People}: {The} {Role} of {Humans} in {Interactive} {Machine} {Learning}},
	volume = {35},
	issn = {0738-4602, 0738-4602},
	shorttitle = {Power to the {People}},
	url = {https://aaai.org/ojs/index.php/aimagazine/article/view/2513},
	doi = {10.1609/aimag.v35i4.2513},
	abstract = {These examples illustrate the rapid, focused, and incremental interaction cycles fundamental to interactive machine learning; it is these cycles that facilitate end-user involvement in the machine-learning process. These cycles also result in a tight coupling between the user and the system, making it impossible to study the system in isolation from the user. This necessitates an increased focus on studying how users can effectively influence the machine-learning system and how the learning system can appropriately influence the users. The following section examines how explicitly studying end users can challenge assumptions of traditional machine learning and better inform the development of interactive machine-learning systems. Many of the case studies to follow additionally consider less traditional types of input and output, moving beyond labeled examples and observations of learner predictions.},
	language = {en},
	number = {4},
	urldate = {2019-07-02},
	journal = {AI Magazine},
	author = {Amershi, Saleema and Cakmak, Maya and Knox, William Bradley and Kulesza, Todd},
	month = dec,
	year = {2014},
	keywords = {comps-iui, fatml, iml, xai},
	pages = {105},
}

@article{LSTMFullyConvolutionalNetworks,
	title = {{LSTM} {Fully} {Convolutional} {Networks} for {Time} {Series} {Classification}},
	volume = {6},
	issn = {2169-3536},
	url = {http://ieeexplore.ieee.org/document/8141873/},
	doi = {10.1109/ACCESS.2017.2779939},
	abstract = {Fully convolutional neural networks (FCNs) have been shown to achieve the state-of-theart performance on the task of classifying time series sequences. We propose the augmentation of fully convolutional networks with long short term memory recurrent neural network (LSTM RNN) sub-modules for time series classiﬁcation. Our proposed models signiﬁcantly enhance the performance of fully convolutional networks with a nominal increase in model size and require minimal preprocessing of the data set. The proposed long short term memory fully convolutional network (LSTM-FCN) achieves the state-of-theart performance compared with others. We also explore the usage of attention mechanism to improve time series classiﬁcation with the attention long short term memory fully convolutional network (ALSTM-FCN). The attention mechanism allows one to visualize the decision process of the LSTM cell. Furthermore, we propose reﬁnement as a method to enhance the performance of trained models. An overall analysis of the performance of our model is provided and compared with other techniques.},
	language = {en},
	urldate = {2019-06-26},
	journal = {IEEE Access},
	author = {Karim, Fazle and Majumdar, Somshubra and Darabi, Houshang and Chen, Shun},
	year = {2018},
	keywords = {dm, ts},
	pages = {1662--1669},
}

@inproceedings{VALMODSuiteEasyExact,
	address = {Houston, TX, USA},
	title = {{VALMOD}: {A} {Suite} for {Easy} and {Exact} {Detection} of {Variable} {Length} {Motifs} in {Data} {Series}},
	isbn = {978-1-4503-4703-7},
	shorttitle = {{VALMOD}},
	url = {http://dl.acm.org/citation.cfm?doid=3183713.3193556},
	doi = {10.1145/3183713.3193556},
	abstract = {Data series motif discovery represents one of the most useful primitives for data series mining, with applications to many domains, such as robotics, entomology, seismology, medicine, and climatology, and others. The state-of-the-art motif discovery tools still require the user to provide the motif length. Yet, in several cases, the choice of motif length is critical for their detection. Unfortunately, the obvious brute-force solution, which tests all lengths within a given range, is computationally untenable, and does not provide any support for ranking motifs at different resolutions (i.e., lengths). We demonstrate VALMOD, our scalable motif discovery algorithm that efficiently finds all motifs in a given range of lengths, and outputs a length-invariant ranking of motifs. Furthermore, we support the analysis process by means of a newly proposed meta-data structure that helps the user to select the most promising pattern length. This demo aims at illustrating in detail the steps of the proposed approach, showcasing how our algorithm and corresponding graphical insights enable users to efficiently identify the correct motifs.},
	language = {en},
	urldate = {2019-06-26},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data}  - {SIGMOD} '18},
	publisher = {ACM Press},
	author = {Linardi, Michele and Zhu, Yan and Palpanas, Themis and Keogh, Eamonn},
	year = {2018},
	keywords = {dm, ts},
	pages = {1757--1760},
}

@inproceedings{LogicalshapeletsExpressivePrimitiveTime,
	address = {San Diego, California, USA},
	title = {Logical-shapelets: an expressive primitive for time series classification},
	isbn = {978-1-4503-0813-7},
	shorttitle = {Logical-shapelets},
	url = {http://dl.acm.org/citation.cfm?doid=2020408.2020587},
	doi = {10.1145/2020408.2020587},
	abstract = {Time series shapelets are small, local patterns in a time series that are highly predictive of a class and are thus very useful features for building classiﬁers and for certain visualization and summarization tasks. While shapelets were introduced only recently, they have already seen signiﬁcant adoption and extension in the community.},
	language = {en},
	urldate = {2019-06-26},
	booktitle = {Proceedings of the 17th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '11},
	publisher = {ACM Press},
	author = {Mueen, Abdullah and Keogh, Eamonn and Young, Neal},
	year = {2011},
	keywords = {dm, ts},
	pages = {1154},
}

@inproceedings{ShapeletTransformTimeSeries,
	address = {Beijing, China},
	title = {A shapelet transform for time series classification},
	isbn = {978-1-4503-1462-6},
	url = {http://dl.acm.org/citation.cfm?doid=2339530.2339579},
	doi = {10.1145/2339530.2339579},
	abstract = {The problem of time series classiﬁcation (TSC), where we consider any real-valued ordered data a time series, presents a speciﬁc machine learning challenge as the ordering of variables is often crucial in ﬁnding the best discriminating features. One of the most promising recent approaches is to ﬁnd shapelets within a data set. A shapelet is a time series subsequence that is identiﬁed as being representative of class membership. The original research in this ﬁeld embedded the procedure of ﬁnding shapelets within a decision tree. We propose disconnecting the process of ﬁnding shapelets from the classiﬁcation algorithm by proposing a shapelet transformation. We describe a means of extracting the k best shapelets from a data set in a single pass, and then use these shapelets to transform data by calculating the distances from a series to each shapelet. We demonstrate that transformation into this new data space can improve classiﬁcation accuracy, whilst retaining the explanatory power provided by shapelets.},
	language = {en},
	urldate = {2019-06-26},
	booktitle = {Proceedings of the 18th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '12},
	publisher = {ACM Press},
	author = {Lines, Jason and Davis, Luke M. and Hills, Jon and Bagnall, Anthony},
	year = {2012},
	keywords = {dm, eeg-key, ts},
	pages = {289},
}

@inproceedings{LearningTimeseriesShapelets,
	address = {New York, New York, USA},
	title = {Learning time-series shapelets},
	isbn = {978-1-4503-2956-9},
	url = {http://dl.acm.org/citation.cfm?doid=2623330.2623613},
	doi = {10.1145/2623330.2623613},
	abstract = {Shapelets are discriminative sub-sequences of time series that best predict the target variable. For this reason, shapelet discovery has recently attracted considerable interest within the time-series research community. Currently shapelets are found by evaluating the prediction qualities of numerous candidates extracted from the series segments. In contrast to the state-of-the-art, this paper proposes a novel perspective in terms of learning shapelets. A new mathematical formalization of the task via a classiﬁcation objective function is proposed and a tailored stochastic gradient learning algorithm is applied. The proposed method enables learning nearto-optimal shapelets directly without the need to try out lots of candidates. Furthermore, our method can learn true top-K shapelets by capturing their interaction. Extensive experimentation demonstrates statistically signiﬁcant improvement in terms of wins and ranks against 13 baselines over 28 time-series datasets.},
	language = {en},
	urldate = {2019-07-04},
	booktitle = {Proceedings of the 20th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining - {KDD} '14},
	publisher = {ACM Press},
	author = {Grabocka, Josif and Schilling, Nicolas and Wistuba, Martin and Schmidt-Thieme, Lars},
	year = {2014},
	keywords = {dm, eeg-key, ts},
	pages = {392--401},
}

@inproceedings{KShapeEfficientAccurateClustering,
	address = {Melbourne, Victoria, Australia},
	title = {k-{Shape}: {Efficient} and {Accurate} {Clustering} of {Time} {Series}},
	isbn = {978-1-4503-2758-9},
	shorttitle = {k-{Shape}},
	url = {http://dl.acm.org/citation.cfm?doid=2723372.2737793},
	doi = {10.1145/2723372.2737793},
	abstract = {The proliferation and ubiquity of temporal data across many disciplines has generated substantial interest in the analysis and mining of time series. Clustering is one of the most popular data mining methods, not only due to its exploratory power, but also as a preprocessing step or subroutine for other techniques. In this paper, we present k-Shape, a novel algorithm for time-series clustering. k-Shape relies on a scalable iterative reﬁnement procedure, which creates homogeneous and well-separated clusters. As its distance measure, k-Shape uses a normalized version of the cross-correlation measure in order to consider the shapes of time series while comparing them. Based on the properties of that distance measure, we develop a method to compute cluster centroids, which are used in every iteration to update the assignment of time series to clusters. To demonstrate the robustness of k-Shape, we perform an extensive experimental evaluation of our approach against partitional, hierarchical, and spectral clustering methods, with combinations of the most competitive distance measures. k-Shape outperforms all scalable approaches in terms of accuracy. Furthermore, k-Shape also outperforms all non-scalable (and hence impractical) combinations, with one exception that achieves similar accuracy results. However, unlike k-Shape, this combination requires tuning of its distance measure and is two orders of magnitude slower than k-Shape. Overall, k-Shape emerges as a domain-independent, highly accurate, and highly eﬃcient clustering approach for time series with broad applications.},
	language = {en},
	urldate = {2019-07-04},
	booktitle = {Proceedings of the 2015 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data} - {SIGMOD} '15},
	publisher = {ACM Press},
	author = {Paparrizos, John and Gravano, Luis},
	year = {2015},
	keywords = {dm, eeg-key, subseq-clustering, ts},
	pages = {1855--1870},
}

@inproceedings{InterpretableClusteringDiscriminativeRectangle,
	address = {Barcelona, Spain},
	title = {Interpretable {Clustering} via {Discriminative} {Rectangle} {Mixture} {Model}},
	isbn = {978-1-5090-5473-2},
	url = {http://ieeexplore.ieee.org/document/7837910/},
	doi = {10.1109/ICDM.2016.0097},
	abstract = {Clustering is a technique that is usually applied as a tool for exploratory data analysis. Because of the exploratory nature of this task, it would be beneﬁcial if a clustering method generates interpretable results, and allows incorporating domain knowledge. This motivates us to develop a probabilistic discriminative model that learns a rectangular decision rule for each cluster, we call Discriminative Rectangle Mixture (DReaM) model. DReaM gives interpretable clustering results, because the rectangular decision rules discovered explicitly illustrate how one cluster is deﬁned and differs from other clusters. It also facilitates us to take advantage of existing rules because we can choose informative prior distributions for the rectangular rules. Moreover, DReaM allows that the features for generating rules do not have to be the same as the features for discovering cluster structure. We approximate the distribution for the rules discovered via variational inference. Experimental results demonstrate that DReaM gives more interpretable clustering results, and yet its performance is comparable to existing clustering methods when solving traditional clustering. Furthermore, in real applications, DReaM is able to effectively take advantage of domain knowledge, and to generate reasonable clustering results.},
	language = {en},
	urldate = {2019-07-04},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Chen, Junxiang and Chang, Yale and Hobbs, Brian and Castaldi, Peter and Cho, Michael and Silverman, Edwin and Dy, Jennifer},
	month = dec,
	year = {2016},
	keywords = {dm, eeg-key, ts},
	pages = {823--828},
}

@inproceedings{CostSensitiveDeepActiveLearning,
	address = {Washington, DC, USA},
	title = {Cost-{Sensitive} {Deep} {Active} {Learning} for {Epileptic} {Seizure} {Detection}},
	isbn = {978-1-4503-5794-4},
	url = {http://dl.acm.org/citation.cfm?doid=3233547.3233566},
	doi = {10.1145/3233547.3233566},
	abstract = {The analysis of electroencephalogram (EEG) signal plays a crucial role in epileptic seizure detection. Researchers have proposed many machine learning and deep learning based automatic epileptic seizure detection methods. However, these schemes, especially the deep learning based ones, suﬀer from labeling huge amounts of training data. Moreover, in epileptic seizure detection, physicians pay more attention to abnormal signals than normal signals, and thus the misclassiﬁcation cost for them should be diﬀerent. To address these issues, we propose a cost-sensitive deep active learning scheme to detect the epileptic seizure. In particular, we develop a new generic double-deep neural network (double-DNN) to obtain the cost-sensitive utility for the samples selection strategy in the labeling process. We further employ three types of fundamental neural networks, i.e., one-dimensional convolutional neural networks (1D CNNs), recurrent neural networks with long short-term memory (LSTM) units, and recurrent neural networks with gated recurrent units (GRU), in the doubleDNN and evaluate their performances. Experiment results show that the proposed scheme can reduce the amount of labeled samples by up to 33\% and 80\% compared with uncertainty sampling and random sampling, respectively.},
	language = {en},
	urldate = {2019-07-02},
	booktitle = {Proceedings of the 2018 {ACM} {International} {Conference} on {Bioinformatics}, {Computational} {Biology}, and {Health} {Informatics}  - {BCB} '18},
	publisher = {ACM Press},
	author = {Chen, Xuhui and Ji, Jinlong and Ji, Tianxi and Li, Pan},
	year = {2018},
	keywords = {dm, ts},
	pages = {226--235},
}

@article{BurstsuppressionRatioUnderestimatesAbsolute,
	title = {Burst-suppression ratio underestimates absolute duration of electroencephalogram suppression compared with visual analysis of intraoperative electroencephalogram},
	volume = {118},
	issn = {00070912},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0007091217313363},
	doi = {10.1093/bja/aex054},
	abstract = {Background. Machine-generated indices based on quantitative electroencephalography (EEG), such as the patient state index (PSITM) and burst-suppression ratio (BSR), are increasingly being used to monitor intraoperative depth of anaesthesia in the endeavour to improve postoperative neurological outcomes, such as postoperative delirium (POD). However, the accuracy of the BSR compared with direct visualization of the EEG trace with regard to the prediction of POD has not been evaluated previously.
Methods. Forty-one consecutive patients undergoing non-cardiac, non-intracranial surgery with general anaesthesia wore a SedLineVR monitor during surgery and were assessed after surgery for the presence of delirium with the Confusion Assessment Method. The intraoperative EEG was scanned for absolute minutes of EEG suppression and correlated with the incidence of POD. The BSR and PSITM were compared between patients with and without POD.
Results. Visual analysis of the EEG by neurologists and the SedLineVR -generated BSR provided a signiﬁcantly different distribution of estimated minutes of EEG suppression (P¼0.037). The SedlineVR system markedly underestimated the amount of EEG suppression. The number of minutes of suppression assessed by visual analysis of the EEG was signiﬁcantly associated with POD (P¼0.039), whereas the minutes based on the BSR generated by SedLineVR were not associated with POD (P¼0.275).
Conclusions. Our ﬁndings suggest that SedLineVR (machine)-generated indices might underestimate the minutes of EEG suppression, thereby reducing the sensitivity for detecting patients at risk for POD. Thus, the monitoring of machine-generated BSR and PSITM might beneﬁt from the addition of a visual tracing of the EEG to achieve a more accurate and real-time guidance of anaesthesia depth monitoring and the ultimate goal, to reduce the risk of POD.},
	language = {en},
	number = {5},
	urldate = {2019-07-02},
	journal = {British Journal of Anaesthesia},
	author = {Muhlhofer, W.G. and Zak, R. and Kamal, T. and Rizvi, B. and Sands, L.P. and Yuan, M. and Zhang, X. and Leung, J.M.},
	month = may,
	year = {2017},
	keywords = {dm, ts},
	pages = {755--761},
}

@inproceedings{ClusteringTimeSeriesUsinga,
	address = {Brussels, Belgium},
	title = {Clustering {Time} {Series} {Using} {Unsupervised}-{Shapelets}},
	isbn = {978-1-4673-4649-8 978-0-7695-4905-7},
	url = {http://ieeexplore.ieee.org/document/6413851/},
	doi = {10.1109/ICDM.2012.26},
	abstract = {Time series clustering has become an increasingly important research topic over the past decade. Most existing methods for time series clustering rely on distances calculated from the entire raw data using the Euclidean distance or Dynamic Time Warping distance as the distance measure. However, the presence of significant noise, dropouts, or extraneous data can greatly limit the accuracy of clustering in this domain. Moreover, for most real world problems, we cannot expect objects from the same class to be equal in length. As a consequence, most work on time series clustering only considers the clustering of individual time series “behaviors,” e.g., individual heart beats or individual gait cycles, and contrives the time series in some way to make them all equal in length. However, contriving the data in such a way is often a harder problem than the clustering itself.},
	language = {en},
	urldate = {2019-07-02},
	booktitle = {2012 {IEEE} 12th {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Zakaria, Jesin and Mueen, Abdullah and Keogh, Eamonn},
	month = dec,
	year = {2012},
	keywords = {dm, eeg-key, ts},
	pages = {785--794},
}

@article{ExploringShapeletTransformationTime,
	title = {Exploring shapelet transformation for time series classification in decision trees},
	volume = {112},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705116303033},
	doi = {10.1016/j.knosys.2016.08.028},
	abstract = {In data mining tasks, time series classiﬁcation has been widely investigated. Recent studies using nonsymbolic learning algorithms have reported signiﬁcant results in terms of classiﬁcation accuracy. However, in applications related to decision-making processes it is necessary to understand of reasoning used in the classiﬁcation process. To take this into account, the shapelet primitive has been proposed in the literature as a descriptor of local morphological characteristics. On the other hand, most of the existing work related to shapelets has been dedicated to the development of more effective approaches in terms of time and accuracy, disregarding the need for the classiﬁers interpretation. In this work, we propose the construction of symbolic models for time series classiﬁcation using shapelet transformation. Moreover, we develop strategies to improve the representation quality of the shapelet transformation, using feature selection algorithms. We performed experimental evaluations comparing our proposal with the state-of-the-art algorithms present in the time series classiﬁcation literature. Based upon the experimental results, we argue that the improvement in shapelet representation can contribute to the construction of more interpretable and competitive classiﬁers in comparison to non-symbolic methods.},
	language = {en},
	urldate = {2019-07-02},
	journal = {Knowledge-Based Systems},
	author = {Zalewski, Willian and Silva, Fabiano and Maletzke, A.G. and Ferrero, C.A.},
	month = nov,
	year = {2016},
	keywords = {dm, eeg-key, ts},
	pages = {80--91},
}

@article{AcceleratingDiscoveryUnsupervisedshapelets,
	title = {Accelerating the discovery of unsupervised-shapelets},
	volume = {30},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-015-0411-4},
	doi = {10.1007/s10618-015-0411-4},
	language = {en},
	number = {1},
	urldate = {2019-07-02},
	journal = {Data Mining and Knowledge Discovery},
	author = {Zakaria, Jesin and Mueen, Abdullah and Keogh, Eamonn and Young, Neal},
	month = jan,
	year = {2016},
	keywords = {dm, subseq-clustering, ts},
	pages = {243--281},
}

@incollection{LearningDTWPreservingShapelets,
	address = {Cham},
	title = {Learning {DTW}-{Preserving} {Shapelets}},
	volume = {10584},
	isbn = {978-3-319-68764-3 978-3-319-68765-0},
	url = {http://link.springer.com/10.1007/978-3-319-68765-0_17},
	abstract = {Dynamic Time Warping (DTW) is one of the best similarity measures for time series, and it has extensively been used in retrieval, classiﬁcation or mining applications. It is a costly measure, and applying it to numerous and/or very long times series is diﬃcult in practice. Recently, Shapelet Transform (ST) proved to enable accurate supervised classiﬁcation of time series. ST learns small subsequences that well discriminate classes, and transforms the time series into vectors lying in a metric space. In this paper, we adopt the ST framework in a novel way: we focus on learning, without class label information, shapelets such that Euclidean distances in the ST-space approximate well the true DTW. Our approach leads to an ubiquitous representation of time series in a metric space, where any machine learning method (supervised or unsupervised) and indexing system can operate eﬃciently.},
	language = {en},
	urldate = {2019-07-02},
	booktitle = {Advances in {Intelligent} {Data} {Analysis} {XVI}},
	publisher = {Springer International Publishing},
	author = {Lods, Arnaud and Malinowski, Simon and Tavenard, Romain and Amsaleg, Laurent},
	editor = {Adams, Niall and Tucker, Allan and Weston, David},
	year = {2017},
	doi = {10.1007/978-3-319-68765-0_17},
	keywords = {dm, eeg-key, ts},
	pages = {198--209},
}

@inproceedings{TimeSeriesEpenthesisClusteringa,
	address = {Vancouver, BC, Canada},
	title = {Time {Series} {Epenthesis}: {Clustering} {Time} {Series} {Streams} {Requires} {Ignoring} {Some} {Data}},
	isbn = {978-1-4577-2075-8 978-0-7695-4408-3},
	shorttitle = {Time {Series} {Epenthesis}},
	url = {http://ieeexplore.ieee.org/document/6137259/},
	doi = {10.1109/ICDM.2011.146},
	abstract = {Given the pervasiveness of time series data in all human endeavors, and the ubiquity of clustering as a data mining application, it is somewhat surprising that the problem of time series clustering from a single stream remains largely unsolved. Most work on time series clustering considers the clustering of individual time series, e.g., gene expression profiles, individual heartbeats or individual gait cycles. The few attempts at clustering time series streams have been shown to be objectively incorrect in some cases, and in other cases shown to work only on the most contrived datasets by carefully adjusting a large set of parameters. In this work, we make two fundamental contributions. First, we show that the problem definition for time series clustering from streams currently used is inherently flawed, and a new definition is necessary. Second, we show that the Minimum Description Length (MDL) framework offers an efficient, effective and essentially parameter-free method for time series clustering. We show that our method produces objectively correct results on a wide variety of datasets from medicine, zoology and industrial process analyses.},
	language = {en},
	urldate = {2019-07-02},
	booktitle = {2011 {IEEE} 11th {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Rakthanmanon, Thanawin and Keogh, Eamonn J. and Lonardi, Stefano and Evans, Scott},
	month = dec,
	year = {2011},
	keywords = {dm, eeg-key, subseq-clustering, ts},
	pages = {547--556},
}

@article{DimensionalityReductionTimeSeries,
	title = {Dimensionality reduction for time series data},
	url = {http://arxiv.org/abs/1406.3711},
	abstract = {Despite the fact that they do not consider the temporal nature of data, classic dimensionality reduction techniques, such as PCA, are widely applied to time series data. In this paper, we introduce a factor decomposition speciﬁc for time series that builds upon the Bayesian multivariate autoregressive model and hence evades the assumption that data points are mutually independent. The key is to ﬁnd a low-rank estimation of the autoregressive matrices. As in the probabilistic version of other factor models, this induces a latent lowdimensional representation of the original data. We discuss some possible generalisations and alternatives, with the most relevant being a technique for simultaneous smoothing and dimensionality reduction. To illustrate the potential applications, we apply the model on a synthetic data set and different types of neuroimaging data (EEG and ECoG).},
	language = {en},
	urldate = {2019-07-02},
	journal = {arXiv:1406.3711 [stat]},
	author = {Vidaurre, Diego and Rezek, Iead and Harrison, Samuel L. and Smith, Stephen S. and Woolrich, Mark},
	month = jun,
	year = {2014},
	note = {arXiv: 1406.3711},
	keywords = {Statistics - Machine Learning, dm, ts},
}

@inproceedings{ExtractionInterpretableMultivariatePatterns,
	address = {Dallas, TX, USA},
	title = {Extraction of {Interpretable} {Multivariate} {Patterns} for {Early} {Diagnostics}},
	isbn = {978-0-7695-5108-1},
	url = {http://ieeexplore.ieee.org/document/6729504/},
	doi = {10.1109/ICDM.2013.19},
	abstract = {Leveraging temporal observations to predict a patient’s health state at a future period is a very challenging task. Providing such a prediction early and accurately allows for designing a more successful treatment that starts before a disease completely develops. Information for this kind of early diagnosis could be extracted by use of temporal data mining methods for handling complex multivariate time series. However, physicians usually prefer to use interpretable models that can be easily explained, rather than relying on more complex black-box approaches. In this study, a temporal data mining method is proposed for extracting interpretable patterns from multivariate time series data, which can be used to assist in providing interpretable early diagnosis. The problem is formulated as an optimizationbased binary classiﬁcation task addressed in three steps. First, the time series data is transformed into a binary matrix representation suitable for application of classiﬁcation methods. Second, a novel convex-concave optimization problem is deﬁned to extract multivariate patterns from the constructed binary matrix. Then, a mixed integer discrete optimization formulation is provided to reduce the dimensionality and extract interpretable multivariate patterns. Finally, those interpretable multivariate patterns are used for early classiﬁcation in challenging clinical applications. In the conducted experiments on two human viral infection datasets and a larger myocardial infarction dataset, the proposed method was more accurate and provided classiﬁcations earlier than three alternative state-of-the-art methods.},
	language = {en},
	urldate = {2019-07-02},
	booktitle = {2013 {IEEE} 13th {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Ghalwash, Mohamed F. and Radosavljevic, Vladan and Obradovic, Zoran},
	month = dec,
	year = {2013},
	keywords = {dm, eeg-key, ts},
	pages = {201--210},
}

@article{ExplainableAITreesLocala,
	title = {Explainable {AI} for {Trees}: {From} {Local} {Explanations} to {Global} {Understanding}},
	shorttitle = {Explainable {AI} for {Trees}},
	url = {http://arxiv.org/abs/1905.04610},
	abstract = {Tree-based machine learning models such as random forests, decision trees, and gradient boosted trees are the most popular non-linear predictive models used in practice today, yet comparatively little attention has been paid to explaining their predictions. Here we signiﬁcantly improve the interpretability of tree-based models through three main contributions: 1) The ﬁrst polynomial time algorithm to compute optimal explanations based on game theory. 2) A new type of explanation that directly measures local feature interaction eﬀects. 3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to i) identify high magnitude but low frequency non-linear mortality risk factors in the general US population, ii) highlight distinct population sub-groups with shared risk characteristics, iii) identify non-linear interaction eﬀects among risk factors for chronic kidney disease, and iv) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model’s performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.},
	language = {en},
	urldate = {2019-07-06},
	journal = {arXiv:1905.04610 [cs, stat]},
	author = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
	month = may,
	year = {2019},
	note = {arXiv: 1905.04610},
	keywords = {fatml, vis, xai},
}

@article{NJoinCourtenayNjoinCom,
	title = {n-{Join} courtenay@n-join.com},
	abstract = {We present a survey of the research concerning explanation and justiﬁcation in the Machine Learning literature and several adjacent ﬁelds. Within Machine Learning, we differentiate between two main branches of current research: interpretable models, and prediction interpretation and justiﬁcation.},
	language = {en},
	author = {Cotton, Courtenay},
	keywords = {fatml, survey, xai},
	pages = {6},
}

@article{TaxonomyGeneratingExplanationsRecommender,
	title = {A {Taxonomy} for {Generating} {Explanations} in {Recommender} {Systems}},
	volume = {32},
	issn = {0738-4602, 0738-4602},
	url = {https://aaai.org/ojs/index.php/aimagazine/article/view/2365},
	doi = {10.1609/aimag.v32i3.2365},
	abstract = {In recommender systems, explanations serve as an additional type of information that can help users to better understand the system's output and promote objectives such as trust, confidence in decision making or utility. This article proposes a taxonomy to categorize and review the research in the area of explanations. It provides a unified view on the different recommendation paradigms, allowing similarities and differences to be clearly identified. Finally, the authors present their view on open research issues and opportunities for future work on this topic.},
	language = {en},
	number = {3},
	urldate = {2019-07-06},
	journal = {AI Magazine},
	author = {Friedrich, Gerhard and Zanker, Markus},
	month = jun,
	year = {2011},
	keywords = {fatml, xai},
	pages = {90},
}

@article{ExplainableMachinelearningPredictionsPreventiona,
	title = {Explainable machine-learning predictions for the prevention of hypoxaemia during surgery},
	volume = {2},
	issn = {2157-846X},
	url = {http://www.nature.com/articles/s41551-018-0304-0},
	doi = {10.1038/s41551-018-0304-0},
	language = {en},
	number = {10},
	urldate = {2019-07-06},
	journal = {Nature Biomedical Engineering},
	author = {Lundberg, Scott M. and Nair, Bala and Vavilala, Monica S. and Horibe, Mayumi and Eisses, Michael J. and Adams, Trevor and Liston, David E. and Low, Daniel King-Wai and Newman, Shu-Fang and Kim, Jerry and Lee, Su-In},
	month = oct,
	year = {2018},
	keywords = {fatml, vis, xai},
	pages = {749--760},
}

@article{ConsistentIndividualizedFeatureAttributiona,
	title = {Consistent {Individualized} {Feature} {Attribution} for {Tree} {Ensembles}},
	url = {http://arxiv.org/abs/1802.03888},
	abstract = {Interpreting predictions from tree ensemble methods such as gradient boosting machines and random forests is important, yet feature attribution for trees is often heuristic and not individualized for each prediction. Here we show that popular feature attribution methods are inconsistent, meaning they can lower a feature’s assigned importance when the true impact of that feature actually increases. This is a fundamental problem that casts doubt on any comparison between features. To address it we turn to recent applications of game theory and develop fast exact tree solutions for SHAP (SHapley Additive exPlanation) values, which are the unique consistent and locally accurate attribution values. We then extend SHAP values to interaction effects and define SHAP interaction values. We propose a rich visualization of individualized feature attributions that improves over classic attribution summaries and partial dependence plots, and a unique “supervised” clustering (clustering based on feature attributions). We demonstrate better agreement with human intuition through a user study, exponential improvements in run time, improved clustering performance, and better identification of influential features. An implementation of our algorithm has also been merged into XGBoost and LightGBM, see http://github.com/slundberg/shap for details.},
	language = {en},
	urldate = {2019-07-06},
	journal = {arXiv:1802.03888 [cs, stat]},
	author = {Lundberg, Scott M. and Erion, Gabriel G. and Lee, Su-In},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.03888},
	keywords = {fatml, xai},
}

@article{ExplanationCaseBasedReasoningPerspectives,
	title = {Explanation in {Case}-{Based} {Reasoning}–{Perspectives} and {Goals}},
	volume = {24},
	issn = {0269-2821, 1573-7462},
	url = {http://link.springer.com/10.1007/s10462-005-4607-7},
	doi = {10.1007/s10462-005-4607-7},
	abstract = {We present an overview of different theories of explanation from the philosophy and cognitive science communities. Based on these theories, as well as models of explanation from the knowledge-based systems area, we present a framework for explanation in case-based reasoning (CBR) based on explanation goals. We propose ways that the goals of the user and system designer should be taken into account when deciding what is a good explanation for a given CBR system. Some general types of goals relevant to many CBR systems are identiﬁed, and used to survey existing methods of explanation in CBR. Finally, we identify some future challenges.},
	language = {en},
	number = {2},
	urldate = {2019-07-06},
	journal = {Artificial Intelligence Review},
	author = {Sørmo, Frode and Cassens, Jörg and Aamodt, Agnar},
	month = oct,
	year = {2005},
	keywords = {fatml, xai},
	pages = {109--143},
}

@article{FaithfulCustomizableExplanationsBlack,
	title = {Faithful and {Customizable} {Explanations} of {Black} {Box} {Models}},
	abstract = {As predictive models increasingly assist human experts (e.g., doctors) in day-to-day decision making, it is crucial for experts to be able to explore and understand how such models behave in different feature subspaces in order to know if and when to trust them. To this end, we propose Model Understanding through Subspace Explanations (MUSE), a novel model agnostic framework which facilitates understanding of a given black box model by explaining how it behaves in subspaces characterized by certain features of interest. Our framework provides end users (e.g., doctors) with the ﬂexibility of customizing the model explanations by allowing them to input the features of interest. The construction of explanations is guided by a novel objective function that we propose to simultaneously optimize for ﬁdelity to the original model, unambiguity and interpretability of the explanation. More speciﬁcally, our objective allows us to learn, with optimality guarantees, a small number of compact decision sets each of which captures the behavior of a given black box model in unambiguous, well-deﬁned regions of the feature space. Experimental evaluation with real-world datasets and user studies demonstrate that our approach can generate customizable, highly compact, easy-to-understand, yet accurate explanations of various kinds of predictive models compared to state-of-the-art baselines.},
	language = {en},
	author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
	keywords = {fatml, xai},
	pages = {11},
}

@inproceedings{LinearTimeComplexityTime,
	address = {New Orleans, LA},
	title = {Linear {Time} {Complexity} {Time} {Series} {Classification} with {Bag}-of-{Pattern}-{Features}},
	isbn = {978-1-5386-3835-4},
	url = {http://ieeexplore.ieee.org/document/8215500/},
	doi = {10.1109/ICDM.2017.37},
	abstract = {Time series classiﬁcation has attracted much attention due to the ubiquity of time series. With the advance of technologies, the volume of available time series data becomes huge and the content is changing rapidly. This requires time series data mining methods to have low computational complexities. In this paper, we propose a parameter-free time series classiﬁcation method that has a linear time complexity. The approach is evaluated on all the 85 datasets in the well-known UCR time series classiﬁcation archive. The results show that the new method achieves better overall classiﬁcation accuracy performance than the widely used benchmark, i.e. 1-nearest neighbor with dynamic time warping, while consuming orders of magnitude less running time. The proposed method is also applied on a large real-world bird sounds dataset to verify its effectiveness.},
	language = {en},
	urldate = {2019-07-04},
	booktitle = {2017 {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Li, Xiaosheng and Lin, Jessica},
	month = nov,
	year = {2017},
	keywords = {dm, eeg-key, ts},
	pages = {277--286},
}

@inproceedings{FastTimeSeriesClassification,
	address = {Boca Raton, FL, USA},
	title = {Fast {Time} {Series} {Classification} {Based} on {Infrequent} {Shapelets}},
	isbn = {978-1-4673-4651-1 978-0-7695-4913-2},
	url = {http://ieeexplore.ieee.org/document/6406571/},
	doi = {10.1109/ICMLA.2012.44},
	abstract = {Time series shapelets are small and local time series subsequences which are in some sense maximally representative of a class. E.Keogh uses distance of the shapelet to classify objects. Even though shapelet classiﬁcation can be interpretable and more accurate than many state-of-the-art classiﬁers, there is one main limitation of shapelets, i.e. shapelet classiﬁcation training process is ofﬂine, and uses subsequence early abandon and admissible entropy pruning strategies, the time to compute is still signiﬁcant. In this work, we address the later problem by introducing a novel algorithm that ﬁnds time series shapelet in signiﬁcantly less time than the current methods by extracting infrequent time series shapelet candidates. Subsequences that are distinguishable are usually infrequent compared to other subsequences. The algorithm called ISDT (Infrequent Shapelet Decision Tree) uses infrequent shapelet candidates extracting to ﬁnd shapelet. Experiments demonstrate the efﬁciency of ISDT algorithm on several benchmark time series datasets. The result shows that ISDT signiﬁcantly outperforms the current shapelet algorithm.},
	language = {en},
	urldate = {2019-07-04},
	booktitle = {2012 11th {International} {Conference} on {Machine} {Learning} and {Applications}},
	publisher = {IEEE},
	author = {He, Qing and {Zhidong} and Zhuang, Fuzhen and Shang, Tianfeng and Shi, Zhongzhi},
	month = dec,
	year = {2012},
	keywords = {dm, ts},
	pages = {215--219},
}

@article{ReviewDistanceBasedTime,
	title = {A review on distance based time series classification},
	volume = {33},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-018-0596-4},
	doi = {10.1007/s10618-018-0596-4},
	abstract = {Time series classiﬁcation is an increasing research topic due to the vast amount of time series data that is being created over a wide variety of ﬁelds. The particularity of the data makes it a challenging task and different approaches have been taken, including the distance based approach. 1-NN has been a widely used method within distance based time series classiﬁcation due to its simplicity but still good performance. However, its supremacy may be attributed to being able to use speciﬁc distances for time series within the classiﬁcation process and not to the classiﬁer itself. With the aim of exploiting these distances within more complex classiﬁers, new approaches have arisen in the past few years that are competitive or which outperform the 1-NN based approaches. In some cases, these new methods use the distance measure to transform the series into feature vectors, bridging the gap between time series and traditional classiﬁers. In other cases, the distances are employed to obtain a time series kernel and enable the use of kernel methods for time series classiﬁcation. One of the main challenges is that a kernel function must be positive semi-deﬁnite, a matter that is also addressed within this review. The presented review includes a taxonomy of all those methods that aim to classify time series using a distance based approach, as well as a discussion of the strengths and weaknesses of each method.},
	language = {en},
	number = {2},
	urldate = {2019-07-04},
	journal = {Data Mining and Knowledge Discovery},
	author = {Abanda, Amaia and Mori, Usue and Lozano, Jose A.},
	month = mar,
	year = {2019},
	keywords = {dm, eeg-key, ts},
	pages = {378--412},
}

@article{AddressingBigDataTime,
	title = {Addressing {Big} {Data} {Time} {Series}: {Mining} {Trillions} of {Time} {Series} {Subsequences} {Under} {Dynamic} {Time} {Warping}},
	volume = {7},
	issn = {15564681},
	shorttitle = {Addressing {Big} {Data} {Time} {Series}},
	url = {http://dl.acm.org/citation.cfm?doid=2513092.2500489},
	doi = {10.1145/2513092.2500489},
	language = {en},
	number = {3},
	urldate = {2019-07-04},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Rakthanmanon, Thanawin and Campana, Bilson and Mueen, Abdullah and Batista, Gustavo and Westover, Brandon and Zhu, Qiang and Zakaria, Jesin and Keogh, Eamonn},
	month = sep,
	year = {2013},
	keywords = {dm, ts},
	pages = {1--31},
}

@article{UnsupervisedFeatureLearningTime,
	title = {Unsupervised {Feature} {Learning} from {Time} {Series}},
	abstract = {In this paper we study the problem of learning discriminative features (segments), often referred to as shapelets [Ye and Keogh, 2009] of time series, from unlabeled time series data. Discovering shapelets for time series classiﬁcation has been widely studied, where many search-based algorithms are proposed to efﬁciently scan and select segments from a pool of candidates. However, such types of search-based algorithms may incur high time cost when the segment candidate pool is large. Alternatively, a recent work [Grabocka et al., 2014] uses regression learning to directly learn, instead of searching for, shapelets from time series. Motivated by the above observations, we propose a new Unsupervised Shapelet Learning Model (USLM) to efﬁciently learn shapelets from unlabeled time series data. The corresponding learning function integrates the strengths of pseudo-class label, spectral analysis, shapelets regularization term and regularized least-squares to auto-learn shapelets, pseudo-class labels and classiﬁcation boundaries simultaneously. A coordinate descent algorithm is used to iteratively solve the learning function. Experiments show that USLM outperforms searchbased algorithms on real-world time series data.},
	language = {en},
	author = {Zhang, Qin and Wu, Jia and Yang, Hong and Tian, Yingjie and Zhang, Chengqi},
	keywords = {dm, ts},
	pages = {7},
}

@article{PatternbasedTimeseriesSubsequenceClustering,
	title = {Pattern-based time-series subsequence clustering using radial distribution functions},
	volume = {18},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-008-0125-7},
	doi = {10.1007/s10115-008-0125-7},
	abstract = {Clustering of time series subsequence data commonly produces results that are unspeciﬁc to the data set. This paper introduces a clustering algorithm, that creates clusters exclusively from those subsequences that occur more frequently in a data set than would be expected by random chance. As such, it partially adopts a pattern mining perspective into clustering. When subsequences are being labeled based on such clusters, they may remain without label. In fact, if the clustering was done on an unrelated time series it is expected that the subsequences should not receive a label. We show that pattern-based clusters are indeed speciﬁc to the data set for 7 out of 10 real-world sets we tested, and for window-lengths up to 128 time points. While kernel-density-based clustering can be used to ﬁnd clusters with similar properties for window sizes of 8–16 time points, its performance degrades fast for increasing window sizes.},
	language = {en},
	number = {1},
	urldate = {2019-07-14},
	journal = {Knowledge and Information Systems},
	author = {Denton, Anne M. and Besemann, Christopher A. and Dorr, Dietmar H.},
	month = jan,
	year = {2009},
	pages = {1--27},
}

@article{SimilarityPreservingRepresentationLearning,
	title = {Similarity {Preserving} {Representation} {Learning} for {Time} {Series} {Clustering}},
	url = {http://arxiv.org/abs/1702.03584},
	abstract = {A considerable amount of clustering algorithms take instance-feature matrices as their inputs. As such, they cannot directly analyze time series data due to its temporal nature, usually unequal lengths, and complex properties. This is a great pity since many of these algorithms are effective, robust, efﬁcient, and easy to use. In this paper, we bridge this gap by proposing an efﬁcient representation learning framework that is able to convert a set of time series with various lengths to an instance-feature matrix. In particular, we guarantee that the pairwise similarities between time series are well preserved after the transformation, thus the learned feature representation is particularly suitable for the time series clustering task. Given a set of n time series, we ﬁrst construct an n × n partially-observed similarity matrix by randomly sampling O(n log n) pairs of time series and computing their pairwise similarities. We then propose an efﬁcient algorithm that solves a non-convex and NP-hard problem to learn new features based on the partially-observed similarity matrix. By conducting extensive empirical studies, we show that the proposed framework is more effective, efﬁcient, and ﬂexible, compared to other state-of-the-art time series clustering methods.},
	language = {en},
	urldate = {2019-07-14},
	journal = {arXiv:1702.03584 [cs]},
	author = {Lei, Qi and Yi, Jinfeng and Vaculin, Roman and Wu, Lingfei and Dhillon, Inderjit S.},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.03584},
}

@article{SelectiveSubsequenceTimeSeries,
	title = {Selective {Subsequence} {Time} {Series} clustering},
	volume = {35},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705112001189},
	doi = {10.1016/j.knosys.2012.04.022},
	abstract = {Subsequence Time Series (STS) Clustering is a time series mining task used to discover clusters of interesting subsequences in time series data. Many research works had used this algorithm as a subroutine in rule discovery, indexing, classiﬁcation and anomaly detection. Unfortunately, recent work has demonstrated that almost all of the STS clustering algorithms give meaningless results, as their outputs are always produced in sine wave form, and do not associate with actual patterns of the input data. Consequently, algorithms that use the results from the STS clustering as their input will fail to produce its meaningful output. In this work, we propose a new STS clustering framework for time series data called Selective Subsequence Time Series (SSTS) clustering which provides meaningful results by using an idea of data encoding to cluster only essential subsequences. Furthermore, our algorithm also automatically determines an appropriate number of clusters without user’s intervention.},
	language = {en},
	urldate = {2019-07-14},
	journal = {Knowledge-Based Systems},
	author = {Rodpongpun, Sura and Niennattrakul, Vit and Ratanamahatana, Chotirat Ann},
	month = nov,
	year = {2012},
	pages = {361--368},
}

@article{OutcomePredictionPostanoxicComa,
	title = {Outcome {Prediction} in {Postanoxic} {Coma} {With} {Deep} {Learning}:},
	issn = {0090-3493},
	shorttitle = {Outcome {Prediction} in {Postanoxic} {Coma} {With} {Deep} {Learning}},
	url = {http://Insights.ovid.com/crossref?an=00003246-900000000-95915},
	doi = {10.1097/CCM.0000000000003854},
	language = {en},
	urldate = {2019-07-14},
	journal = {Critical Care Medicine},
	author = {Tjepkema-Cloostermans, Marleen C. and da Silva Lourenço, Catarina and Ruijter, Barry J. and Tromp, Selma C. and Drost, Gea and Kornips, Francois H. M. and Beishuizen, Albertus and Bosch, Frank H. and Hofmeijer, Jeannette and van Putten, Michel J. A. M.},
	month = jun,
	year = {2019},
	pages = {1},
}

@article{VisOHCDesigningVisualAnalytics,
	title = {{VisOHC}: {Designing} {Visual} {Analytics} for {Online} {Health} {Communities}},
	volume = {22},
	issn = {1077-2626},
	shorttitle = {{VisOHC}},
	url = {http://ieeexplore.ieee.org/document/7192683/},
	doi = {10.1109/TVCG.2015.2467555},
	abstract = {Through online health communities (OHCs), patients and caregivers exchange their illness experiences and strategies for overcoming the illness, and provide emotional support. To facilitate healthy and lively conversations in these communities, their members should be continuously monitored and nurtured by OHC administrators. The main challenge of OHC administrators’ tasks lies in understanding the diverse dimensions of conversation threads that lead to productive discussions in their communities. In this paper, we present a design study in which three domain expert groups participated, an OHC researcher and two OHC administrators of online health communities, which was conducted to ﬁnd with a visual analytic solution. Through our design study, we characterized the domain goals of OHC administrators and derived tasks to achieve these goals. As a result of this study, we propose a system called VisOHC, which visualizes individual OHC conversation threads as collapsed boxes–a visual metaphor of conversation threads. In addition, we augmented the posters’ reply authorship network with marks and/or beams to show conversation dynamics within threads. We also developed unique measures tailored to the characteristics of OHCs, which can be encoded for thread visualizations at the users’ requests. Our observation of the two administrators while using VisOHC showed that it supports their tasks and reveals interesting insights into online health communities. Finally, we share our methodological lessons on probing visual designs together with domain experts by allowing them to freely encode measurements into visual variables.},
	language = {en},
	number = {1},
	urldate = {2019-07-12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kwon, Bum Chul and Kim, Sung-Hee and Lee, Sukwon and Choo, Jaegul and Huh, Jina and Yi, Ji Soo},
	month = jan,
	year = {2016},
	keywords = {community, vis, vis-related-work-vis-for-online-communities},
	pages = {71--80},
}

@article{FairnessPrecisionMedicine,
	title = {Fairness in {Precision} {Medicine}},
	language = {en},
	author = {Ferryman, Kadija and Pitcan, Mikaela},
	keywords = {fair},
	pages = {54},
}

@article{TopicLensEfficientMultiLevelVisual,
	title = {{TopicLens}: {Efficient} {Multi}-{Level} {Visual} {Topic} {Exploration} of {Large}-{Scale} {Document} {Collections}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {{TopicLens}},
	url = {http://ieeexplore.ieee.org/document/7539597/},
	doi = {10.1109/TVCG.2016.2598445},
	abstract = {Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its signiﬁcant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workﬂow. Instead, most such systems are limited to utilizing a ﬁxed, initial set of topics. Motivated by this gap in the literature, we propose a novel interaction technique called TopicLens that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efﬁciently computed on the ﬂy. To support this interaction in real time while maintaining view consistency, we propose a novel efﬁcient topic modeling method and a semi-supervised 2D embedding algorithm. Our work is based on improving state-of-the-art methods such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding. Furthermore, we have built a web-based visual analytics system integrated with TopicLens. We use this system to measure the performance and the visualization quality of our proposed methods. We provide several scenarios showcasing the capability of TopicLens using real-world datasets.},
	language = {en},
	number = {1},
	urldate = {2019-07-12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, Minjeong and Kang, Kyeongpil and Park, Deokgun and Choo, Jaegul and Elmqvist, Niklas},
	month = jan,
	year = {2017},
	keywords = {topic, vis},
	pages = {151--160},
}

@inproceedings{DemographicVisAnalyzingDemographicInformation,
	address = {Chicago, IL, USA},
	title = {{DemographicVis}: {Analyzing} demographic information based on user generated content},
	isbn = {978-1-4673-9783-4},
	shorttitle = {{DemographicVis}},
	url = {http://ieeexplore.ieee.org/document/7347631/},
	doi = {10.1109/VAST.2015.7347631},
	language = {en},
	urldate = {2019-07-12},
	booktitle = {2015 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Dou, Wenwen and Cho, Isaac and ElTayeby, Omar and Choo, Jaegul and Wang, Xiaoyu and Ribarsky, William},
	month = oct,
	year = {2015},
	keywords = {community, vis},
	pages = {57--64},
}

@article{UserbasedVisualAnalyticsWorkflow,
	title = {A {User}-based {Visual} {Analytics} {Workﬂow} for {Exploratory} {Model} {Analysis}},
	abstract = {Many visual analytics systems allow users to interact with machine learning models towards the goals of data exploration and insight generation on a given dataset. However, in some situations, insights may be less important than the production of an accurate predictive model for future use. In that case, users are more interested in generating of diverse and robust predictive models, verifying their performance on holdout data, and selecting the most suitable model for their usage scenario. In this paper, we consider the concept of Exploratory Model Analysis (EMA), which is deﬁned as the process of discovering and selecting relevant models that can be used to make predictions on a data source. We delineate the differences between EMA and the well-known term exploratory data analysis in terms of the desired outcome of the analytic process: insights into the data or a set of deployable models. The contributions of this work are a visual analytics system workﬂow for EMA, a user study, and two use cases validating the effectiveness of the workﬂow. We found that our system workﬂow enabled users to generate complex models, to assess them for various qualities, and to select the most relevant model for their task.},
	language = {en},
	author = {Cashman, Dylan and Humayoun, Shah Rukh and Heimerl, Florian and Park, Kendall and Das, Subhajit and Thompson, John and Saket, Bahador and Mosca, Abigail and Stasko, John and Endert, Alex and Gleicher, Mike and Chang, Remco},
	year = {2019},
	keywords = {fatml, vis, xai},
	pages = {14},
}

@inproceedings{HumanCenteredToolsCopingImperfecta,
	address = {Glasgow, Scotland Uk},
	title = {Human-{Centered} {Tools} for {Coping} with {Imperfect} {Algorithms} {During} {Medical} {Decision}-{Making}},
	isbn = {978-1-4503-5970-2},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300234},
	doi = {10.1145/3290605.3300234},
	abstract = {Machin e lear nin g (ML) is incr easingly being use d in image retrieval systems for medical decision making. On e app lication of ML is to retrieve visually similar medical images from pas t patients (e.g. tissue from biops ies) to reference whe n making a medical decision with a new pat ient. Howeve r, no algorithm can perfectly captu re an expert ' s ideal notion of similarity for every case: an image th at is algorithmi cally determin ed to be similar may not be medically relevant to a doctor' s specific diagnostic needs. In this pape r, we identified the needs of patho logists whe n searchin g for similar images retrieved usin g a deep lear nin g algorithm , and develope d tools that empower use rs to cope with the search algorithm on-the -fly, communi cating what types of similarity are most import ant at different moment s in time. In two evaluations with path ologists, we found th at th ese refinement tools increased the diagnos tic utility of images found and increased user trus t in the algorithm. Th e tools we re preferred over a traditi onal interface, without a loss in diagnostic accuracy. We also observe d that users adopted new str ategies whe n using refinement tools, re-purpos ing th em to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken togethe r, these findings inform futur e hum an-ML collabo rative systems for expe rt decision-m aking.},
	language = {en},
	urldate = {2019-07-06},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '19},
	publisher = {ACM Press},
	author = {Cai, Carrie J. and Stumpe, Martin C. and Terry, Michael and Reif, Emily and Hegde, Narayan and Hipp, Jason and Kim, Been and Smilkov, Daniel and Wattenberg, Martin and Viegas, Fernanda and Corrado, Greg S.},
	year = {2019},
	keywords = {fatml, hci, vis, xai},
	pages = {1--14},
}

@incollection{OntologyGuidedPrincipalComponentAnalysis,
	address = {Cham},
	title = {Ontology-{Guided} {Principal} {Component} {Analysis}: {Reaching} the {Limits} of the {Doctor}-in-the-{Loop}},
	volume = {9832},
	isbn = {978-3-319-43948-8 978-3-319-43949-5},
	shorttitle = {Ontology-{Guided} {Principal} {Component} {Analysis}},
	url = {http://link.springer.com/10.1007/978-3-319-43949-5_2},
	abstract = {Biomedical research requires deep domain expertise to perform analyses of complex data sets, assisted by mathematical expertise provided by data scientists who design and develop sophisticated methods and tools. Such methods and tools not only require preprocessing of the data, but most of all a meaningful input selection. Usually, data scientists do not have suﬃcient background knowledge about the origin of the data and the biomedical problems to be solved, consequently a doctor-in-the-loop can be of great help here. In this paper we revise the viability of integrating an analysis guided visualization component in an ontology-guided data infrastructure, exempliﬁed by the principal component analysis. We evaluated this approach by examining the potential for intelligent support of medical experts on the case of cerebral aneurysms research.},
	language = {en},
	urldate = {2019-07-06},
	booktitle = {Information {Technology} in {Bio}- and {Medical} {Informatics}},
	publisher = {Springer International Publishing},
	author = {Wartner, Sandra and Girardi, Dominic and Wiesinger-Widi, Manuela and Trenkler, Johannes and Kleiser, Raimund and Holzinger, Andreas},
	editor = {Renda, M. Elena and Bursa, Miroslav and Holzinger, Andreas and Khuri, Sami},
	year = {2016},
	doi = {10.1007/978-3-319-43949-5_2},
	keywords = {fatml, iml, xai},
	pages = {22--33},
}

@article{AugmentedPathologistChallengesExplainableAIa,
	title = {Towards the {Augmented} {Pathologist}: {Challenges} of {Explainable}-{AI} in {Digital} {Pathology}},
	shorttitle = {Towards the {Augmented} {Pathologist}},
	url = {http://arxiv.org/abs/1712.06657},
	abstract = {Digital pathology is not only one of the most promising ﬁelds of diagnostic medicine, but at the same time a hot topic for fundamental research. Digital pathology is not just the transfer of histopathological slides into digital representations. The combination of diﬀerent data sources (images, patient records, and *omics data) together with current advances in artiﬁcial intelligence/machine learning enable to make novel information accessible and quantiﬁable to a human expert, which is not yet available and not exploited in current medical settings. The grand goal is to reach a level of usable intelligence to understand the data in the context of an application task, thereby making machine decisions transparent, interpretable and explainable. The foundation of such an ”augmented pathologist” needs an integrated approach: While machine learning algorithms require many thousands of training examples, a human expert is often confronted with only a few data points. Interestingly, humans can learn from such few examples and are able to instantly interpret complex patterns. Consequently, the grand goal is to combine the possibilities of artiﬁcial intelligence with human intelligence and to ﬁnd a well-suited balance between them to enable what neither of them could do on their own. This can raise the quality of education, diagnosis, prognosis and prediction of cancer and other diseases. In this paper we describe some (incomplete) research issues which we believe should be addressed in an integrated and concerted eﬀort for paving the way towards the augmented pathologist.},
	language = {en},
	urldate = {2019-07-06},
	journal = {arXiv:1712.06657 [cs, stat]},
	author = {Holzinger, Andreas and Malle, Bernd and Kieseberg, Peter and Roth, Peter M. and Müller, Heimo and Reihs, Robert and Zatloukal, Kurt},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.06657},
	keywords = {fatml, iml, xai},
}

@article{BagofwordsRepresentationBiomedicalTime,
	title = {Bag-of-words representation for biomedical time series classification},
	volume = {8},
	issn = {17468094},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S174680941300089X},
	doi = {10.1016/j.bspc.2013.06.004},
	abstract = {Automatic analysis of biomedical time series such as electroencephalogram (EEG) and electrocardiographic (ECG) signals has attracted great interest in the community of biomedical engineering due to its important applications in medicine. In this work, a simple yet effective bag-of-words representation that is able to capture both local and global structure similarity information is proposed for biomedical time series representation. In particular, similar to the bag-of-words model used in text document domain, the proposed method treats a time series as a text document and extracts local segments from the time series as words. The biomedical time series is then represented as a histogram of codewords, each entry of which is the count of a codeword appeared in the time series. Although the temporal order of the local segments is ignored, the bag-of-words representation is able to capture high-level structural information because both local and global structural information are well utilized. The performance of the bag-of-words model is validated on three datasets extracted from real EEG and ECG signals. The experimental results demonstrate that the proposed method is not only insensitive to parameters of the bag-of-words model such as local segment length and codebook size, but also robust to noise.},
	language = {en},
	number = {6},
	urldate = {2019-08-28},
	journal = {Biomedical Signal Processing and Control},
	author = {Wang, Jin and Liu, Ping and She, Mary F.H. and Nahavandi, Saeid and Kouzani, Abbas},
	month = nov,
	year = {2013},
	pages = {634--644},
}

@article{ExplanationConjunctionUnification,
	title = {Explanation, {Conjunction}, and {Unification}},
	volume = {73},
	issn = {0022362X},
	url = {http://www.pdcnet.org/oom/service?url_ver=Z39.88-2004&rft_val_fmt=&rft.imuse_id=jphil_1976_0073_0008_0207_0212&svc_id=info:www.pdcnet.org/collection},
	doi = {10.2307/2025559},
	language = {en},
	number = {8},
	urldate = {2019-07-14},
	journal = {The Journal of Philosophy},
	author = {Kitcher, Philip},
	month = apr,
	year = {1976},
	keywords = {fatml, xai},
	pages = {207},
}

@article{AnatomyExplanationPartSequential,
	title = {On the {Anatomy} of {Explanation}: {Part} 3. {Sequential} and {Hierarchical} {Description}},
	language = {en},
	author = {Ghent, Arthur W},
	keywords = {fatml, xai},
	pages = {14},
}

@article{JudgmentUncertaintyHeuristicsBiases,
	title = {Judgment under {Uncertainty}: {Heuristics} and {Biases}},
	volume = {185},
	language = {en},
	year = {1974},
	keywords = {fatml, xai},
	pages = {9},
}

@article{MakingClusteringDelayvectorSpacea,
	title = {Making clustering in delay-vector space meaningful},
	volume = {11},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-006-0042-6},
	doi = {10.1007/s10115-006-0042-6},
	abstract = {Sequential time series clustering is a technique used to extract important features from time series data. The method can be shown to be the process of clustering in the delay-vector space formalism used in the Dynamical Systems literature. Recently, the startling claim was made that sequential time series clustering is meaningless. This has important consequences for a signiﬁcant amount of work in the literature, since such a claim invalidates these work’s contribution. In this paper, we show that sequential time series clustering is not meaningless, and that the problem highlighted in these works stem from their use of the Euclidean distance metric as the distance measure in the delay-vector space. As a solution, we consider quite a general class of time series, and propose a regime based on two types of similarity that can exist between delay vectors, giving rise naturally to an alternative distance measure to Euclidean distance in the delay-vector space. We show that, using this alternative distance measure, sequential time series clustering can indeed be meaningful. We repeat a key experiment in the work on which the “meaningless” claim was based, and show that our method leads to a successful clustering outcome.},
	language = {en},
	number = {3},
	urldate = {2019-07-14},
	journal = {Knowledge and Information Systems},
	author = {Chen, Jason R.},
	month = apr,
	year = {2007},
	pages = {369--385},
}

@article{MultiScaleConvolutionalNeuralNetworks,
	title = {Multi-{Scale} {Convolutional} {Neural} {Networks} for {Time} {Series} {Classification}},
	url = {http://arxiv.org/abs/1603.06995},
	abstract = {Time series classiﬁcation (TSC), the problem of predicting class labels of time series, has been around for decades within the community of data mining and machine learning, and found many important applications such as biomedical engineering and clinical prediction. However, it still remains challenging and falls short of classiﬁcation accuracy and efﬁciency. Traditional approaches typically involve extracting discriminative features from the original time series using dynamic time warping (DTW) or shapelet transformation, based on which an oﬀ-the-shelf classiﬁer can be applied. These methods are ad-hoc and separate the feature extraction part with the classiﬁcation part, which limits their accuracy performance. Plus, most existing methods fail to take into account the fact that time series often have features at diﬀerent time scales. To address these problems, we propose a novel end-to-end neural network model, Multi-scale Convolutional Neural Network (MCNN), which incorporates feature extraction and classiﬁcation in a single framework. Leveraging a novel multi-branch layer and learnable convolutional layers, MCNN automatically extracts features at diﬀerent scales and frequencies, leading to superior feature representation. MCNN is also computationally eﬃcient, as it naturally leverages GPU computing. We conduct comprehensive empirical evaluation with various existing methods on a large number of benchmark datasets, and show that MCNN advances the state-of-the-art by achieving superior accuracy performance than other leading methods.},
	language = {en},
	urldate = {2019-07-14},
	journal = {arXiv:1603.06995 [cs]},
	author = {Cui, Zhicheng and Chen, Wenlin and Chen, Yixin},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.06995},
}

@article{HierarchyCausationExplanationUbiquity,
	title = {Hierarchy, causation and explanation: ubiquity, locality and pluralism},
	volume = {2},
	issn = {2042-8898, 2042-8901},
	shorttitle = {Hierarchy, causation and explanation},
	url = {http://rsfs.royalsocietypublishing.org/cgi/doi/10.1098/rsfs.2011.0064},
	doi = {10.1098/rsfs.2011.0064},
	language = {en},
	number = {1},
	urldate = {2019-07-14},
	journal = {Interface Focus},
	author = {Love, A. C.},
	month = feb,
	year = {2012},
	keywords = {fatml, xai},
	pages = {115--125},
}

@inproceedings{SearchMeaningTimeSeries,
	address = {Arlington, Virginia, USA},
	title = {In search of meaning for time series subsequence clustering: matching algorithms based on a new distance measure},
	isbn = {978-1-59593-433-8},
	shorttitle = {In search of meaning for time series subsequence clustering},
	url = {http://portal.acm.org/citation.cfm?doid=1183614.1183666},
	doi = {10.1145/1183614.1183666},
	language = {en},
	urldate = {2019-07-14},
	booktitle = {Proceedings of the 15th {ACM} international conference on {Information} and knowledge management  - {CIKM} '06},
	publisher = {ACM Press},
	author = {Goldin, Dina and Mardales, Ricardo and Nagy, George},
	year = {2006},
	pages = {347},
}

@article{MakingClusteringDelayvectorSpace,
	title = {Making clustering in delay-vector space meaningful},
	volume = {11},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-006-0042-6},
	doi = {10.1007/s10115-006-0042-6},
	abstract = {Sequential time series clustering is a technique used to extract important features from time series data. The method can be shown to be the process of clustering in the Delay-Vector space formalism used in the Dynamical systems literature. Recently, the startling claim was made that sequential time series clustering is meaningless. This has important consequences for a signiﬁcant amount of work in the literature, since such a claim invalidates these work’s contribution. In this paper, we show that sequential time series clustering is not meaningless, and that the problem highlighted in these works stem from their use of the Euclidean distance metric as the distance measure in the delay vector space. As a solution, we consider quite a general class of time series, and propose a regime based on two types of similarity that can exist between delay vectors, which give rise naturally to an alternative distance measure to Euclidean distance in the delay vector space. We show that, using this alternative distance measure, sequential time series clustering can indeed be meaningful.},
	language = {en},
	number = {3},
	urldate = {2019-07-14},
	journal = {Knowledge and Information Systems},
	author = {Chen, Jason R.},
	month = apr,
	year = {2007},
	pages = {369--385},
}

@article{UnfoldingPreprocessingMeaningfulTime,
	title = {Unfolding preprocessing for meaningful time series clustering},
	volume = {19},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608006000864},
	doi = {10.1016/j.neunet.2006.05.020},
	abstract = {Clustering methods are commonly applied to time series, either as a preprocessing stage for other methods or in their own right. In this paper it is explained why time series clustering may sometimes be considered as meaningless. This problematic situation is illustrated for various raw time series. The unfolding preprocessing methodology is then introduced. The usefulness of unfolding preprocessing is illustrated for various time series. The experimental results show the meaningfulness of the clustering when applied on adequately unfolded time series.},
	language = {en},
	number = {6-7},
	urldate = {2019-07-14},
	journal = {Neural Networks},
	author = {Simon, Geoffroy and Lee, John A. and Verleysen, Michel},
	month = jul,
	year = {2006},
	pages = {877--888},
}

@article{UsefulClusteringOutcomesMeaningful,
	title = {Useful {Clustering} {Outcomes} from {Meaningful} {Time} {Series} {Clustering}},
	abstract = {Clustering time series data using the popular subsequence (STS) technique has been widely used in the data mining and wider communities. Recently the conclusion was made that it is meaningless, based on the ﬁndings that it produces (a) clustering outcomes for distinct time series that are not distinguishable from one another, and (b) cluster centroids that are smoothed. More recent work has since showed that (a) could be solved by introducing a lag in the subsequence vector construction process, however we show in this paper that such an approach does not solve (b). Motivating the terminology that a clustering method which overcomes (a) is meaningful, while one which overcomes (a) and (b) is useful, we propose an approach that produces useful time series clustering. The approach is based on restricting the clustering space to extend only over the region visited by the time series in the subsequence vector space. We test the approach on a set of 12 diverse real-world and synthetic data sets and ﬁnd that (a) one can distinguish between the clusterings of these time series, and (b) that the centroids produced in each case retain the character of the underlying series from which they came.},
	language = {en},
	author = {Chen, Jason R},
	pages = {10},
}

@article{UserCenteredActiveLearningAlgorithmsa,
	title = {Towards {User}-{Centered} {Active} {Learning} {Algorithms}},
	volume = {37},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/cgf.13406},
	doi = {10.1111/cgf.13406},
	abstract = {The labeling of data sets is a time-consuming task, which is, however, an important prerequisite for machine learning and visual analytics. Visual-interactive labeling (VIAL) provides users an active role in the process of labeling, with the goal to combine the potentials of humans and machines to make labeling more efﬁcient. Recent experiments showed that users apply different strategies when selecting instances for labeling with visual-interactive interfaces. In this paper, we contribute a systematic quantitative analysis of such user strategies. We identify computational building blocks of user strategies, formalize them, and investigate their potentials for different machine learning tasks in systematic experiments. The core insights of our experiments are as follows. First, we identiﬁed that particular user strategies can be used to considerably mitigate the bootstrap (cold start) problem in early labeling phases. Second, we observed that they have the potential to outperform existing active learning strategies in later phases. Third, we analyzed the identiﬁed core building blocks, which can serve as the basis for novel selection strategies. Overall, we observed that data-based user strategies (clusters, dense areas) work considerably well in early phases, while model-based user strategies (e.g., class separation) perform better during later phases. The insights gained from this work can be applied to develop novel active learning approaches as well as to better guide users in visual interactive labeling.},
	language = {en},
	number = {3},
	urldate = {2019-08-28},
	journal = {Computer Graphics Forum},
	author = {Bernard, Jürgen and Zeppelzauer, Matthias and Lehmann, Markus and Müller, Martin and Sedlmair, Michael},
	month = jun,
	year = {2018},
	keywords = {dm},
	pages = {121--132},
}

@article{ArguingMachinesHumanSupervision,
	title = {Arguing {Machines}: {Human} {Supervision} of {Black} {Box} {AI} {Systems} {That} {Make} {Life}-{Critical} {Decisions}},
	abstract = {We consider the paradigm of a black box AI system that makes life-critical decisions. We propose an “arguing machines” framework that pairs the primary AI system with a secondary one that is independently trained to perform the same task. We show that disagreement between the two systems, without any knowledge of underlying system design or operation, is su cient to arbitrarily improve the accuracy of the overall decision pipeline given human supervision over disagreements. We demonstrate this system in two applications: (1) an illustrative example of image classi cation and (2) on large-scale real-world semi-autonomous driving data. For the rst application, we apply this framework to image classi cation achieving a reduction from 8.0\% to 2.8\% top-5 error on ImageNet. For the second application, we apply this framework to Tesla Autopilot and demonstrate the ability to predict 90.4\% of system disengagements that were labeled by human annotators as challenging and needing human supervision.},
	language = {en},
	author = {Fridman, Lex},
	keywords = {fatml, xai},
	pages = {11},
}

@inproceedings{ExploringEfficiencyBatchActivea,
	address = {Lyon, France},
	title = {Exploring the {Efficiency} of {Batch} {Active} {Learning} for {Human}-in-the-{Loop} {Relation} {Extraction}},
	isbn = {978-1-4503-5640-4},
	url = {http://dl.acm.org/citation.cfm?doid=3184558.3191546},
	doi = {10.1145/3184558.3191546},
	abstract = {Domain-specific relation extraction requires training data for supervised learning models, and thus, significant labeling effort. Distant supervision is often leveraged for creating large annotated corpora however these methods require handling the inherent noise. On the other hand, active learning approaches can reduce the annotation cost by selecting the most beneficial examples to label in order to learn a good model. The choice of examples can be performed sequentially, i.e. select one example in each iteration, or in batches, i.e. select a set of examples in each iteration. The optimization of the batch size is a practical problem faced in every real-world application of active learning, however it is often treated as a parameter decided in advance. In this work, we study the trade-off between model performance, the number of requested labels in a batch and the time spent in each round for real-time, domain specific relation extraction. Our results show that the use of an appropriate batch size produces competitive performance, even compared to a fully sequential strategy, while reducing the training time dramatically.},
	language = {en},
	urldate = {2019-08-28},
	booktitle = {Companion of the {The} {Web} {Conference} 2018 on {The} {Web} {Conference} 2018  - {WWW} '18},
	publisher = {ACM Press},
	author = {Lourentzou, Ismini and Gruhl, Daniel and Welch, Steve},
	year = {2018},
	keywords = {dm},
	pages = {1131--1138},
}

@article{HumanCenteredAutonomousVehicleSystems,
	title = {Human-{Centered} {Autonomous} {Vehicle} {Systems}: {Principles} of {E} ective {Shared} {Autonomy}},
	abstract = {Building e ective, enjoyable, and safe autonomous vehicles is a lot harder than has historically been considered. e reason is that, simply put, an autonomous vehicle must interact with human beings. is interaction is not a robotics problem nor a machine learning problem nor a psychology problem nor an economics problem nor a policy problem. It is all of these problems put into one. It challenges our assumptions about the limitations of human beings at their worst and the capabilities of arti cial intelligence systems at their best. is work proposes a set of principles for designing and building autonomous vehicles in a human-centered way that does not run away from the complexity of human nature but instead embraces it. We describe our development of the Human-Centered Autonomous Vehicle (HCAV) as an illustrative case study of implementing these principles in practice.},
	language = {en},
	author = {Fridman, Lex},
	keywords = {fatml, xai},
	pages = {9},
}

@article{IterativeMachineTeachinga,
	title = {Iterative {Machine} {Teaching}},
	abstract = {In this paper, we consider the problem of machine teaching, the inverse problem of machine learning. Different from traditional machine teaching which views the learners as batch algorithms, we study a new paradigm where the learner uses an iterative algorithm and a teacher can feed examples sequentially and intelligently based on the current performance of the learner. We show that the teaching complexity in the iterative case is very different from that in the batch case. Instead of constructing a minimal training set for learners, our iterative machine teaching focuses on achieving fast convergence in the learner model. Depending on the level of information the teacher has from the learner model, we design teaching algorithms which can provably reduce the number of teaching examples and achieve faster convergence than learning without teachers. We also validate our theoretical ﬁndings with extensive experiments on different data distribution and real image datasets.},
	language = {en},
	author = {Liu, Weiyang and Dai, Bo and Humayun, Ahmad and Tay, Charlene and Yu, Chen and Smith, Linda B and Rehg, James M and Song, Le},
	keywords = {fatml, xai},
	pages = {23},
}

@article{ExplainableDeeplearningAlgorithmDetection,
	title = {An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets},
	volume = {3},
	issn = {2157-846X},
	url = {http://www.nature.com/articles/s41551-018-0324-9},
	doi = {10.1038/s41551-018-0324-9},
	language = {en},
	number = {3},
	urldate = {2019-08-28},
	journal = {Nature Biomedical Engineering},
	author = {Lee, Hyunkwang and Yune, Sehyo and Mansouri, Mohammad and Kim, Myeongchan and Tajmir, Shahein H. and Guerrier, Claude E. and Ebert, Sarah A. and Pomerantz, Stuart R. and Romero, Javier M. and Kamalian, Shahmir and Gonzalez, Ramon G. and Lev, Michael H. and Do, Synho},
	month = mar,
	year = {2019},
	pages = {173--182},
}

@inproceedings{InterpretableSteerableSequenceLearning,
	address = {Anchorage, AK, USA},
	title = {Interpretable and {Steerable} {Sequence} {Learning} via {Prototypes}},
	isbn = {978-1-4503-6201-6},
	url = {http://dl.acm.org/citation.cfm?doid=3292500.3330908},
	doi = {10.1145/3292500.3330908},
	abstract = {One of the major challenges in machine learning nowadays is to provide predictions with not only high accuracy but also user-friendly explanations. Although in recent years we have witnessed increasingly popular use of deep neural networks for sequence modeling, it is still challenging to explain the rationales behind the model outputs, which is essential for building trust and supporting the domain experts to validate, critique and refine the model.},
	language = {en},
	urldate = {2019-08-28},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}  - {KDD} '19},
	publisher = {ACM Press},
	author = {Ming, Yao and Xu, Panpan and Qu, Huamin and Ren, Liu},
	year = {2019},
	pages = {903--913},
}

@inproceedings{IntegratingMultifeaturesMultipleKernel,
	address = {Beijing, China},
	title = {Integrating multi-features by multiple kernel learning to better classify images},
	isbn = {978-1-4244-4590-5},
	url = {http://ieeexplore.ieee.org/document/5348522/},
	doi = {10.1109/ICBNMT.2009.5348522},
	abstract = {Most recent methods for image classification focus on how to formulate different types of features effectively in a uniform formula. Although these features take on different importance for image classification, most previous work gives the same weight to the features when they are combined. In this paper, we propose an approach to integrate multi-features by following the multiple kernel learning (MKL) framework. By using distinct kernels, we propose to combine different similarity measures for each feature type, that is, the feature fusion is calculated at kernellevel. We employ the SimpleMKL algorithm to solve the MKL problem. As illustrated in the experiments on the images extracted from Corel, Caltech-101 and Flickr 18, our approach outperforms the usual fusion schemes in terms of prediction accuracy.},
	language = {en},
	urldate = {2019-08-28},
	booktitle = {2009 2nd {IEEE} {International} {Conference} on {Broadband} {Network} \& {Multimedia} {Technology}},
	publisher = {IEEE},
	author = {Lei, Zhang and Jun, Ma},
	month = oct,
	year = {2009},
	pages = {491--495},
}

@article{IncorporatingPriorKnowledgeFeatures,
	title = {Incorporating {Prior} {Knowledge} on {Features} into {Learning}},
	abstract = {In the standard formulation of supervised learning the input is represented as a vector of features. However, in most real-life problems, we also have additional information about each of the features. This information can be represented as a set of properties, referred to as meta-features. For instance, in an image recognition task, where the features are pixels, the meta-features can be the (x, y) position of each pixel. We propose a new learning framework that incorporates metafeatures. In this framework we assume that a weight is assigned to each feature, as in linear discrimination, and we use the meta-features to de ne a prior on the weights. This prior is based on a Gaussian process and the weights are assumed to be a smooth function of the meta-features. Using this framework we derive a practical algorithm that improves generalization by using meta-features and discuss the theoretical advantages of incorporating them into the learning. We apply our framework to design a new kernel for handwritten digit recognition. We obtain higher accuracy with lower computational complexity in the primal representation. Finally, we discuss the applicability of this framework to biological neural networks.},
	language = {en},
	author = {Krupka, Eyal and Tishby, Naftali},
	keywords = {key},
	pages = {8},
}

@article{PrototypebasedClassification,
	title = {Prototype-based classification},
	volume = {28},
	issn = {0924-669X, 1573-7497},
	url = {http://link.springer.com/10.1007/s10489-007-0064-0},
	doi = {10.1007/s10489-007-0064-0},
	abstract = {Image-based diagnostic tools are important tools for the determination of diseases in many medical applications. The interpretation of these images is often done manually, based on prototypical images. Consequently, only a few images collected into an image catalogue are initially available as a basis for the development of an automatic imageinterpretation system. In this paper we study the question if it is possible to build up an image-interpretation system based on such an image catalogue. We call the system catalogue-based image classiﬁer. The system is provided with feature-subset selection, feature weighting, and prototype selection. The performance of the catalogue-based classiﬁer is assessed by studying the accuracy and the reduction of the prototypes after applying a prototype-selection algorithm. We describe the results that could be achieved and give an outlook for further developments on a cataloguebased classiﬁer.},
	language = {en},
	number = {3},
	urldate = {2019-08-28},
	journal = {Applied Intelligence},
	author = {Perner, Petra},
	month = jun,
	year = {2008},
	pages = {238--246},
}

@article{PrototypeBasedDiscriminativeFeatureLearning,
	title = {Prototype-{Based} {Discriminative} {Feature} {Learning} for {Kinship} {Verification}},
	volume = {45},
	issn = {2168-2267, 2168-2275},
	url = {http://ieeexplore.ieee.org/document/6981937/},
	doi = {10.1109/TCYB.2014.2376934},
	abstract = {In this paper, we propose a new prototype-based discriminative feature learning (PDFL) method for kinship veriﬁcation. Unlike most previous kinship veriﬁcation methods which employ low-level hand-crafted descriptors such as local binary pattern and Gabor features for face representation, this paper aims to learn discriminative mid-level features to better characterize the kin relation of face images for kinship veriﬁcation. To achieve this, we construct a set of face samples with unlabeled kin relation from the labeled face in the wild dataset as the reference set. Then, each sample in the training face kinship dataset is represented as a mid-level feature vector, where each entry is the corresponding decision value from one support vector machine hyperplane. Subsequently, we formulate an optimization function by minimizing the intraclass samples (with a kin relation) and maximizing the neighboring interclass samples (without a kin relation) with the mid-level features. To better use multiple lowlevel features for mid-level feature learning, we further propose a multiview PDFL method to learn multiple mid-level features to improve the veriﬁcation performance. Experimental results on four publicly available kinship datasets show the superior performance of the proposed methods over both the state-of-the-art kinship veriﬁcation methods and human ability in our kinship veriﬁcation task.},
	language = {en},
	number = {11},
	urldate = {2019-08-28},
	journal = {IEEE Transactions on Cybernetics},
	author = {Yan, Haibin and Lu, Jiwen and Zhou, Xiuzhuang},
	month = nov,
	year = {2015},
	keywords = {vis},
	pages = {2535--2545},
}

@article{WeightedSequenceMotifsImproved,
	title = {Weighted sequence motifs as an improved seeding step in {microRNA} target prediction algorithms},
	volume = {11},
	issn = {1355-8382},
	url = {http://www.rnajournal.org/cgi/doi/10.1261/rna.7290705},
	doi = {10.1261/rna.7290705},
	language = {en},
	number = {7},
	urldate = {2019-08-28},
	journal = {RNA},
	author = {SAeTROM, O.},
	month = jul,
	year = {2005},
	pages = {995--1003},
}

@article{WeSeerVisualAnalysisBetter,
	title = {{WeSeer}: {Visual} {Analysis} for {Better} {Information} {Cascade} {Prediction} of {WeChat} {Articles}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{WeSeer}},
	url = {https://ieeexplore.ieee.org/document/8451903/},
	doi = {10.1109/TVCG.2018.2867776},
	abstract = {Social media, such as Facebook and WeChat, empowers millions of users to create, consume, and disseminate online information on an unprecedented scale. The abundant information on social media intensiﬁes the competition of WeChat Public Ofﬁcial Articles (i.e., posts) for gaining user attention due to the zero-sum nature of attention. Therefore, only a small portion of information tends to become extremely popular while the rest remains unnoticed or quickly disappears. Such a typical “long-tail” phenomenon is very common in social media. Thus, recent years have witnessed a growing interest in predicting the future trend in the popularity of social media posts and understanding the factors that inﬂuence the popularity of the posts. Nevertheless, existing predictive models either rely on cumbersome feature engineering or sophisticated parameter tuning, which are difﬁcult to understand and improve. In this paper, we study and enhance a point process-based model by incorporating visual reasoning to support communication between the users and the predictive model for a better prediction result. The proposed system supports users to uncover the working mechanism behind the model and improve the prediction accuracy accordingly based on the insights gained. We use realistic WeChat articles to demonstrate the effectiveness of the system and verify the improved model on a large scale of WeChat articles. We also elicit and summarize the feedback from WeChat domain experts.},
	language = {en},
	urldate = {2019-08-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Li, Quan and Wu, Ziming and Yi, Lingling and Njotoprawiro, Kristanto Sean and Qu, Huamin and Ma, Xiaojuan},
	year = {2018},
	keywords = {vis},
	pages = {1--1},
}

@article{SurveyMethodsTimeSeries,
	title = {A survey of methods for time series change point detection},
	volume = {51},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-016-0987-z},
	doi = {10.1007/s10115-016-0987-z},
	abstract = {Change points are abrupt variations in time series data. Such abrupt changes may represent transitions that occur between states. Detection of change points is useful in modelling and prediction of time series and is found in application areas such as medical condition monitoring, climate change detection, speech and image analysis, and human activity analysis. This survey article enumerates, categorizes, and compares many of the methods that have been proposed to detect change points in time series. The methods examined include both supervised and unsupervised algorithms that have been introduced and evaluated. We introduce several criteria to compare the algorithms. Finally, we present some grand challenges for the community to consider.},
	language = {en},
	number = {2},
	urldate = {2019-08-29},
	journal = {Knowledge and Information Systems},
	author = {Aminikhanghahi, Samaneh and Cook, Diane J.},
	month = may,
	year = {2017},
	pages = {339--367},
}

@article{DeepTemporalClusteringFullya,
	title = {Deep {Temporal} {Clustering} : {Fully} {Unsupervised} {Learning} of {Time}-{Domain} {Features}},
	shorttitle = {Deep {Temporal} {Clustering}},
	url = {http://arxiv.org/abs/1802.01059},
	abstract = {Unsupervised learning of time series data, also known as temporal clustering, is a challenging problem in machine learning. Here we propose a novel algorithm, Deep Temporal Clustering (DTC), to naturally integrate dimensionality reduction and temporal clustering into a single end-to-end learning framework, fully unsupervised. The algorithm utilizes an autoencoder for temporal dimensionality reduction and a novel temporal clustering layer for cluster assignment. Then it jointly optimizes the clustering objective and the dimensionality reduction objective. Based on requirement and application, the temporal clustering layer can be customized with any temporal similarity metric. Several similarity metrics and state-of-the-art algorithms are considered and compared. To gain insight into temporal features that the network has learned for its clustering, we apply a visualization method that generates a region of interest heatmap for the time series. The viability of the algorithm is demonstrated using time series data from diverse domains, ranging from earthquakes to spacecraft sensor data. In each case, we show that the proposed algorithm outperforms traditional methods. The superior performance is attributed to the fully integrated temporal dimensionality reduction and clustering criterion.},
	language = {en},
	urldate = {2019-08-29},
	journal = {arXiv:1802.01059 [cs, stat]},
	author = {Madiraju, Naveen Sai and Sadat, Seid M. and Fisher, Dimitry and Karimabadi, Homa},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.01059},
	keywords = {Statistics - Machine Learning},
}

@inproceedings{ClusteringTimeSeriesUsing,
	address = {Brussels, Belgium},
	title = {Clustering {Time} {Series} {Using} {Unsupervised}-{Shapelets}},
	isbn = {978-1-4673-4649-8 978-0-7695-4905-7},
	url = {http://ieeexplore.ieee.org/document/6413851/},
	doi = {10.1109/ICDM.2012.26},
	abstract = {Time series clustering has become an increasingly important research topic over the past decade. Most existing methods for time series clustering rely on distances calculated from the entire raw data using the Euclidean distance or Dynamic Time Warping distance as the distance measure. However, the presence of significant noise, dropouts, or extraneous data can greatly limit the accuracy of clustering in this domain. Moreover, for most real world problems, we cannot expect objects from the same class to be equal in length. As a consequence, most work on time series clustering only considers the clustering of individual time series “behaviors,” e.g., individual heart beats or individual gait cycles, and contrives the time series in some way to make them all equal in length. However, contriving the data in such a way is often a harder problem than the clustering itself.},
	language = {en},
	urldate = {2019-08-29},
	booktitle = {2012 {IEEE} 12th {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Zakaria, Jesin and Mueen, Abdullah and Keogh, Eamonn},
	month = dec,
	year = {2012},
	pages = {785--794},
}

@article{AugmentedPathologistChallengesExplainableAI,
	title = {Towards the {Augmented} {Pathologist}: {Challenges} of {Explainable}-{AI} in {Digital} {Pathology}},
	shorttitle = {Towards the {Augmented} {Pathologist}},
	url = {http://arxiv.org/abs/1712.06657},
	abstract = {Digital pathology is not only one of the most promising ﬁelds of diagnostic medicine, but at the same time a hot topic for fundamental research. Digital pathology is not just the transfer of histopathological slides into digital representations. The combination of diﬀerent data sources (images, patient records, and *omics data) together with current advances in artiﬁcial intelligence/machine learning enable to make novel information accessible and quantiﬁable to a human expert, which is not yet available and not exploited in current medical settings. The grand goal is to reach a level of usable intelligence to understand the data in the context of an application task, thereby making machine decisions transparent, interpretable and explainable. The foundation of such an ”augmented pathologist” needs an integrated approach: While machine learning algorithms require many thousands of training examples, a human expert is often confronted with only a few data points. Interestingly, humans can learn from such few examples and are able to instantly interpret complex patterns. Consequently, the grand goal is to combine the possibilities of artiﬁcial intelligence with human intelligence and to ﬁnd a well-suited balance between them to enable what neither of them could do on their own. This can raise the quality of education, diagnosis, prognosis and prediction of cancer and other diseases. In this paper we describe some (incomplete) research issues which we believe should be addressed in an integrated and concerted eﬀort for paving the way towards the augmented pathologist.},
	language = {en},
	urldate = {2019-08-28},
	journal = {arXiv:1712.06657 [cs, stat]},
	author = {Holzinger, Andreas and Malle, Bernd and Kieseberg, Peter and Roth, Peter M. and Müller, Heimo and Reihs, Robert and Zatloukal, Kurt},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.06657},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{HowScientificModelsCan,
	title = {How scientific models can explain},
	volume = {180},
	issn = {0039-7857, 1573-0964},
	url = {http://link.springer.com/10.1007/s11229-009-9565-1},
	doi = {10.1007/s11229-009-9565-1},
	abstract = {Scientiﬁc models invariably involve some degree of idealization, abstraction, or ﬁctionalization of their target system. Nonetheless, I argue that there are circumstances under which such false models can offer genuine scientiﬁc explanations. After reviewing three different proposals in the literature for how models can explain, I shall introduce a more general account of what I call model explanations, which specify the conditions under which models can be counted as explanatory. I shall illustrate this new framework by applying it to the case of Bohr’s model of the atom, and conclude by drawing some distinctions between phenomenological models, explanatory models, and ﬁctional models.},
	language = {en},
	number = {1},
	urldate = {2019-08-28},
	journal = {Synthese},
	author = {Bokulich, Alisa},
	month = may,
	year = {2011},
	keywords = {fatml, xai},
	pages = {33--45},
}

@article{TamperproofAuditControlSystem,
	title = {A tamper-proof audit and control system for the doctor in the loop},
	volume = {3},
	issn = {2198-4018, 2198-4026},
	url = {http://link.springer.com/10.1007/s40708-016-0046-2},
	doi = {10.1007/s40708-016-0046-2},
	abstract = {The ‘‘doctor in the loop’’ is a new paradigm in information-driven medicine, picturing the doctor as authority inside a loop supplying an expert system with information on actual patients, treatment results, and possible additional (side-)effects, including general information in order to enhance data-driven medical science, as well as giving back treatment advice to the doctor himself. While this approach can be very beneﬁcial for new medical approaches like P4 medicine (personal, predictive, preventive, and participatory), it also relies heavily on the authenticity of the data and thus increases the need for secure and reliable databases. In this paper, we propose a solution in order to protect the doctor in the loop against responsibility derived from manipulated data, thus enabling this new paradigm to gain acceptance in the medical community. This work is an extension of the conference paper Kieseberg et al. (Brain Informatics and Health, 2015), which includes extensions to the original concept.},
	language = {en},
	number = {4},
	urldate = {2019-08-28},
	journal = {Brain Informatics},
	author = {Kieseberg, Peter and Malle, Bernd and Frühwirt, Peter and Weippl, Edgar and Holzinger, Andreas},
	month = dec,
	year = {2016},
	keywords = {fatml, xai},
	pages = {269--279},
}

@article{KnowledgeGraphProgrammingHumanintheLoop,
	title = {Knowledge {Graph} {Programming} with a {Human}-in-the-{Loop}: {Preliminary} {Results}},
	abstract = {In this paper we introduce knowledge graph programming, a new method for writing extremely succinct programs. This method allows programmers to save work by writing programs that are brief but also underspecified and underconstrained; a human-inthe-loop “data compiler” then automatically fills in missing values without the programmer’s explicit help. It uses modern data quality mechanisms such as information extraction, data integration, and crowdsourcing. The language encourages users to mention knowledge graph entities in their programs, thus enabling the data compiler to exploit the extensive factual and type structure present in modern KGs. We describe the knowledge graph programming user experience, explain its conceptual steps and data model, describe our prototype KGP system, and present some preliminary experimental results.},
	language = {en},
	author = {Lou, Yuze and Uddin, Mahfus and Brown, Nathaniel and Cafarella, Michael},
	year = {2019},
	keywords = {iterative, kg},
	pages = {7},
}

@article{SURVEYVISUALIZATIONEXPLAINABLECLASSIFIERS,
	title = {A {SURVEY} {ON} {VISUALIZATION} {FOR} {EXPLAINABLE} {CLASSIFIERS}},
	abstract = {Classiﬁcation is a fundamental problem in machine learning, data mining, and computer vision. In practice, interpretability is a desirable property of classiﬁcation models (classiﬁers) in critical areas, such as security, medicine, and ﬁnance. For instance, a quantitative trader may prefer a more interpretable model with less expected return due to its predictability and low risk. Unfortunately, the best-performing classiﬁers in many applications (e.g., deep neural networks) are complex models whose predictions are difﬁcult to explain. Thus, there is a growing interest in using visualization to understand, diagnose and explain intelligent systems in both academia and industry. Many challenges need to be addressed in the formalization of explainability, and the design principles and evaluation of explainable intelligent systems.},
	language = {en},
	author = {Ming, Yao},
	keywords = {fatml, xai},
	pages = {37},
}

@article{LearningHealthKnowledgeGraph,
	title = {Learning a {Health} {Knowledge} {Graph} from {Electronic} {Medical} {Records}},
	volume = {7},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-017-05778-z},
	doi = {10.1038/s41598-017-05778-z},
	language = {en},
	number = {1},
	urldate = {2019-08-28},
	journal = {Scientific Reports},
	author = {Rotmensch, Maya and Halpern, Yoni and Tlimat, Abdulhakim and Horng, Steven and Sontag, David},
	month = dec,
	year = {2017},
	keywords = {kg},
	pages = {5994},
}

@article{RevisedCerebralRecoveryIndex,
	title = {The revised {Cerebral} {Recovery} {Index} improves predictions of neurological outcome after cardiac arrest},
	volume = {129},
	issn = {13882457},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1388245718312586},
	doi = {10.1016/j.clinph.2018.10.004},
	abstract = {Objective: Analysis of the electroencephalogram (EEG) background pattern helps predicting neurological outcome of comatose patients after cardiac arrest (CA). Visual analysis may not extract all discriminative information. We present predictive values of the revised Cerebral Recovery Index (rCRI), based on continuous extraction and combination of a large set of evolving quantitative EEG (qEEG) features and machine learning techniques.
Methods: We included 551 subsequent patients from a prospective cohort study on continuous EEG after CA in two hospitals. Outcome at six months was classiﬁed as good (Cerebral Performance Category (CPC) 1-2) or poor (CPC 3-5). Forty-four qEEG features (from time, frequency and entropy domain) were selected by the least absolute shrinkage and selection operator (LASSO) method and used in a Random Forests classiﬁcation system. We trained and evaluated the system with 10-fold cross validation. For poor outcome prediction, the sensitivity at 100\% speciﬁcity (Se100) and the area under the receiver operator curve (AUC) were used as performance of the prediction model. For good outcome, we used the sensitivity at 95\% speciﬁcity (Se95).
Results: Two hundred ﬁfty-six (47\%) patients had a good outcome. The rCRI predicted poor outcome with AUC = 0.94 (95\% CI: 0.83–0.91), Se100 = 0.66 (0.65–0.78), and AUC = 0.88 (0.78–0.93), Se100 = 0.60 (0.51–0.75) at 12 and 24 h after CA, respectively. The rCRI predicted good outcome with Se95 = 0.72 (0.61–0.85) and 0.40 (0.30–0.51) at 12 and 24 h after CA, respectively.
Conclusions: Results obtained in this study suggest that with machine learning algorithms and large set of qEEG features, it is possible to efﬁciently monitor patient outcome after CA. We also demonstrate the importance of selection of optimal performance metric to train a classiﬁer model for outcome prediction. Signiﬁcance: The rCRI is a sensitive, reliable predictor of neurological outcome of comatose patients after CA.},
	language = {en},
	number = {12},
	urldate = {2019-08-28},
	journal = {Clinical Neurophysiology},
	author = {Nagaraj, Sunil B. and Tjepkema-Cloostermans, Marleen C. and Ruijter, Barry J. and Hofmeijer, Jeannette and van Putten, Michel J.A.M.},
	month = dec,
	year = {2018},
	pages = {2557--2566},
}

@inproceedings{NoveltyInterestingnessMeasuresDesignspace,
	address = {Amsterdam, The Netherlands},
	title = {Novelty and interestingness measures for design-space exploration},
	isbn = {978-1-4503-1963-8},
	url = {http://dl.acm.org/citation.cfm?doid=2463372.2463557},
	doi = {10.1145/2463372.2463557},
	abstract = {Measures of novelty and interestingness are frequently encountered in the context of developmental robotics, being derived from human psychology. This work addresses these measures from the viewpoint of enhancing design-space exploration in black-box optimization. We provide a unifying notational and naming scheme with the intent of facilitating comparison, implementation, and application in the domain of design optimization. Initial analysis shows a promising interestingness measure for being tried on real-world design problems.},
	language = {en},
	urldate = {2019-08-28},
	booktitle = {Proceeding of the fifteenth annual conference on {Genetic} and evolutionary computation conference - {GECCO} '13},
	publisher = {ACM Press},
	author = {Reehuis, Edgar and Olhofer, Markus and Emmerich, Michael and Sendhoff, Bernhard and Bäck, Thomas},
	year = {2013},
	keywords = {fatml, xai},
	pages = {1541},
}

@article{GENDERTWITTERSTYLESSTANCES,
	title = {{GENDER} {IN} {TWITTER}: {STYLES}, {STANCES}, {AND} {SOCIAL} {NETWORKS}},
	abstract = {We present a study of the relationship between gender, linguistic style, and social networks, using a novel corpus of 14,000 users of Twitter. Prior quantitative work on gender often treats this social variable as a binary; we argue for a more nuanced approach. By clustering Twitter feeds, we find a range of styles and interests that reflects the multifaceted interaction between gender and language. Some styles mirror the aggregated language-gender statistics, while others contradict them. Next, we investigate individuals whose language better matches the other gender. We find that such individuals have social networks that include significantly more individuals from the other gender, and that in general, social network homophily is correlated with the use of same-gender language markers. Pairing computational methods and social theory thus offers a new perspective on how gender emerges as individuals position themselves relative to audiences, topics, and mainstream gender norms.},
	language = {en},
	author = {Bamman, David and Eisenstein, Jacob and Schnoebelen, Tyler},
	pages = {42},
}

@article{WhoTweetsDerivingDemographica,
	title = {Who {Tweets}? {Deriving} the {Demographic} {Characteristics} of {Age}, {Occupation} and {Social} {Class} from {Twitter} {User} {Meta}-{Data}},
	volume = {10},
	issn = {1932-6203},
	shorttitle = {Who {Tweets}?},
	url = {https://dx.plos.org/10.1371/journal.pone.0115545},
	doi = {10.1371/journal.pone.0115545},
	language = {en},
	number = {3},
	urldate = {2019-09-23},
	journal = {PLOS ONE},
	author = {Sloan, Luke and Morgan, Jeffrey and Burnap, Pete and Williams, Matthew},
	editor = {Preis, Tobias},
	month = mar,
	year = {2015},
	pages = {e0115545},
}

@article{GreysanatomyYankeesDemographicsHashtag,
	title = {\#\#greysanatomy versus \#\#yankees: {Demographics} and {Hashtag} {Use} on {Twitter}},
	abstract = {Demographics, in particular, gender, age, and race, are a key predictor of human behavior. Despite the signiﬁcant effect that demographics plays, most scientiﬁc studies using online social media do not consider this factor, mainly due to the lack of such information. In this work, we use state-of-theart face analysis software to infer gender, age, and race from proﬁle images of 350K Twitter users from New York. For the period from November 1, 2014 to October 31, 2015, we study which hashtags are used by different demographic groups. Though we ﬁnd considerable overlap for the most popular hashtags, there are also many group-speciﬁc hashtags.},
	language = {en},
	author = {An, Jisun and Weber, Ingmar},
	pages = {4},
}

@article{ImprovingTwitterCommunityDetection,
	title = {Improving {Twitter} {Community} {Detection} through {Contextual} {Sentiment} {Analysis}},
	abstract = {Works on Twitter community detection have yielded new ways to extract valuable insights from social media. Through this technique, Twitter users can be grouped into different types of communities such as those who have the same interests, those who interact a lot, or those who have similar sentiments about certain topics. Computationally, information is represented as a graph, and community detection is the problem of partitioning the graph such that each community is more densely connected to each other than to the rest of the network. It has been shown that incorporating sentiment analysis can improve community detection when looking for sentiment-based communities. However, such works only perform sentiment analysis in isolation without considering the tweet’s various contextual information. Examples of these contextual information are social network structure, and conversational, author, and topic contexts. Disregarding these information poses a problem because at times, context is needed to clearly infer the sentiment of a tweet. Thus, this research aims to improve detection of sentiment-based communities on Twitter by performing contextual sentiment analysis.},
	language = {en},
	author = {Lam, Alron Jan},
	pages = {7},
}

@article{WomenAreWarmerNo,
	title = {Women are {Warmer} but {No} {Less} {Assertive} than {Men}: {Gender} and {Language} on {Facebook}},
	volume = {11},
	issn = {1932-6203},
	shorttitle = {Women are {Warmer} but {No} {Less} {Assertive} than {Men}},
	url = {http://dx.plos.org/10.1371/journal.pone.0155885},
	doi = {10.1371/journal.pone.0155885},
	abstract = {Using a large social media dataset and open-vocabulary methods from computational linguistics, we explored differences in language use across gender, affiliation, and assertiveness. In Study 1, we analyzed topics (groups of semantically similar words) across 10 million messages from over 52,000 Facebook users. Most language differed little across gender. However, topics most associated with self-identified female participants included friends, family, and social life, whereas topics most associated with self-identified male participants included swearing, anger, discussion of objects instead of people, and the use of argumentative language. In Study 2, we plotted male- and female-linked language topics along two interpersonal dimensions prevalent in gender research: affiliation and assertiveness. In a sample of over 15,000 Facebook users, we found substantial gender differences in the use of affiliative language and slight differences in assertive language. Language used more by self-identified females was interpersonally warmer, more compassionate, polite, and—contrary to previous findings—slightly more assertive in their language use, whereas language used more by self-identified males was colder, more hostile, and impersonal. Computational linguistic analysis combined with methods to automatically label topics offer means for testing psychological theories unobtrusively at large scale.},
	language = {en},
	number = {5},
	urldate = {2019-09-23},
	journal = {PLOS ONE},
	author = {Park, Gregory and Yaden, David Bryce and Schwartz, H. Andrew and Kern, Margaret L. and Eichstaedt, Johannes C. and Kosinski, Michael and Stillwell, David and Ungar, Lyle H. and Seligman, Martin E. P.},
	editor = {Danforth, Christopher M.},
	month = may,
	year = {2016},
	pages = {e0155885},
}

@inproceedings{DevelopingAgeGenderPredictive,
	address = {Doha, Qatar},
	title = {Developing {Age} and {Gender} {Predictive} {Lexica} over {Social} {Media}},
	url = {http://aclweb.org/anthology/D14-1121},
	doi = {10.3115/v1/D14-1121},
	abstract = {Demographic lexica have potential for widespread use in social science, economic, and business applications. We derive predictive lexica (words and weights) for age and gender using regression and classiﬁcation models from word usage in Facebook, blog, and Twitter data with associated demographic labels. The lexica, made publicly available,1 achieved state-of-the-art accuracy in language based age and gender prediction over Facebook and Twitter, and were evaluated for generalization across social media genres as well as in limited message situations.},
	language = {en},
	urldate = {2019-09-23},
	booktitle = {Proceedings of the 2014 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Sap, Maarten and Park, Gregory and Eichstaedt, Johannes and Kern, Margaret and Stillwell, David and Kosinski, Michal and Ungar, Lyle and Schwartz, Hansen Andrew},
	year = {2014},
	pages = {1146--1151},
}

@inproceedings{ClassifyingLatentUserAttributes,
	address = {Toronto, ON, Canada},
	title = {Classifying latent user attributes in twitter},
	isbn = {978-1-4503-0386-6},
	url = {http://portal.acm.org/citation.cfm?doid=1871985.1871993},
	doi = {10.1145/1871985.1871993},
	abstract = {Social media outlets such as Twitter have become an important forum for peer interaction. Thus the ability to classify latent user attributes, including gender, age, regional origin, and political orientation solely from Twitter user language or similar highly informal content has important applications in advertising, personalization, and recommendation. This paper includes a novel investigation of stacked-SVM-based classiﬁcation algorithms over a rich set of original features, applied to classifying these four user attributes. It also includes extensive analysis of features and approaches that are eﬀective and not eﬀective in classifying user attributes in Twitter-style informal written genres as distinct from the other primarily spoken genres previously studied in the userproperty classiﬁcation literature. Our models, singly and in ensemble, signiﬁcantly outperform baseline models in all cases. A detailed analysis of model components and features provides an often entertaining insight into distinctive language-usage variation across gender, age, regional origin and political orientation in modern informal communication.},
	language = {en},
	urldate = {2019-09-23},
	booktitle = {Proceedings of the 2nd international workshop on {Search} and mining user-generated contents - {SMUC} '10},
	publisher = {ACM Press},
	author = {Rao, Delip and Yarowsky, David and Shreevats, Abhishek and Gupta, Manaswi},
	year = {2010},
	pages = {37},
}

@article{RealMenDonSay,
	title = {Real {Men} {Don}’t {Say} “{Cute}”: {Using} {Automatic} {Language} {Analysis} to {Isolate} {Inaccurate} {Aspects} of {Stereotypes}},
	volume = {8},
	issn = {1948-5506, 1948-5514},
	shorttitle = {Real {Men} {Don}’t {Say} “{Cute}”},
	url = {http://journals.sagepub.com/doi/10.1177/1948550616671998},
	doi = {10.1177/1948550616671998},
	abstract = {People associate certain behaviors with certain social groups. These stereotypical beliefs consist of both accurate and inaccurate associations. Using large-scale, data-driven methods with social media as a context, we isolate stereotypes by using verbal expression. Across four social categories—gender, age, education level, and political orientation—we identify words and phrases that lead people to incorrectly guess the social category of the writer. Although raters often correctly categorize authors, they overestimate the importance of some stereotype-congruent signal. Findings suggest that data-driven approaches might be a valuable and ecologically valid tool for identifying even subtle aspects of stereotypes and highlighting the facets that are exaggerated or misapplied.},
	language = {en},
	number = {3},
	urldate = {2019-09-23},
	journal = {Social Psychological and Personality Science},
	author = {Carpenter, Jordan and Preotiuc-Pietro, Daniel and Flekova, Lucie and Giorgi, Salvatore and Hagan, Courtney and Kern, Margaret L. and Buffone, Anneke E. K. and Ungar, Lyle and Seligman, Martin E. P.},
	month = apr,
	year = {2017},
	pages = {310--322},
}

@article{AgeGroupsClassificationSocial,
	title = {Age {Groups} {Classification} in {Social} {Network} {Using} {Deep} {Learning}},
	volume = {5},
	issn = {2169-3536},
	url = {http://ieeexplore.ieee.org/document/7932459/},
	doi = {10.1109/ACCESS.2017.2706674},
	abstract = {Social networks have a large amount of data available, but often, people do not provide some of their personal data, such as age, gender, and other demographics. Although the sentiment analysis uses such data to develop useful applications in people’s daily lives, there are still failures in this type of analysis, either by the restricted number of words contained in the word dictionaries or because they do not consider the most diverse parameters that can inﬂuence the sentiments in a sentence; thus, more reliable results can be obtained, if the users proﬁle information and their writing characteristics are considered. This research suggests that one of the most relevant parameter contained in the user proﬁle is the age group, showing that there are typical behaviors among users of the same age group, speciﬁcally, when these users write about the same topic. A detailed analysis with 7000 sentences was performed to determine which characteristics are relevant, such as, the use of punctuation, number of characters, media sharing, topics, among others; and which ones can be disregarded for the age groups classiﬁcation. Different learning machine algorithms are tested for the classiﬁcation of the teenager and adult age group, and the deep convolutional neural network had the best performance, reaching a precision of 0.95 in the validation tests. Furthermore, in order to validate the usefulness of the proposed model for classifying age groups, it is implemented into the enhanced sentiment metric (eSM). In the performance validation, subjective tests are performed and the eSM with the proposed model reached a root mean square error and a Pearson correlation coefﬁcient of 0.25 and 0.94, respectively, outperforming the eSM metric, when the age group information is not available.},
	language = {en},
	urldate = {2019-09-23},
	journal = {IEEE Access},
	author = {Guimaraes, Rita Georgina and Rosa, Renata L. and De Gaetano, Denise and Rodriguez, Demostenes Z. and Bressan, Graca},
	year = {2017},
	pages = {10805--10816},
}

@article{RaceEthnicityNationalOriginbased,
	title = {Race, {Ethnicity} and {National} {Origin}-based {Discrimination} in {Social} {Media} and {Hate} {Crimes} {Across} 100 {U}.{S}. {Cities}},
	abstract = {We study malicious online content via a speciﬁc type of hate speech: race, ethnicity and national-origin based discrimination in social media, alongside hate crimes motivated by those characteristics, in 100 cities across the United States. We develop a spatially-diverse training dataset and classiﬁcation pipeline to delineate targeted and self-narration of discrimination on social media, accounting for language across geographies. Controlling for census parameters, we ﬁnd that the proportion of discrimination that is targeted is associated with the number of hate crimes. Finally, we explore the linguistic features of discrimination Tweets in relation to hate crimes by city, features used by users who Tweet different amounts of discrimination, and features of discrimination compared to non-discrimination Tweets. Findings from this spatial study can inform future studies of how discrimination in physical and virtual worlds vary by place, or how physical and virtual world discrimination may synergize.},
	language = {en},
	author = {Relia, Kunal and Li, Zhengyi and Cook, Stephanie H and Chunara, Rumi},
	pages = {11},
}

@article{DataFusionMatrixFactorization,
	title = {Data {Fusion} by {Matrix} {Factorization}},
	volume = {37},
	issn = {0162-8828, 2160-9292},
	url = {http://ieeexplore.ieee.org/document/6867358/},
	doi = {10.1109/TPAMI.2014.2343973},
	abstract = {For most problems in science and engineering we can obtain data sets that describe the observed system from various perspectives and record the behavior of its individual components. Heterogeneous data sets can be collectively mined by data fusion. Fusion can focus on a speciﬁc target relation and exploit directly associated data together with contextual data and data about system’s constraints. In the paper we describe a data fusion approach with penalized matrix tri-factorization (DFMF) that simultaneously factorizes data matrices to reveal hidden associations. The approach can directly consider any data that can be expressed in a matrix, including those from feature-based representations, ontologies, associations and networks. We demonstrate the utility of DFMF for gene function prediction task with eleven different data sources and for prediction of pharmacologic actions by fusing six data sources. Our data fusion algorithm compares favorably to alternative data integration approaches and achieves higher accuracy than can be obtained from any single data source alone.},
	language = {en},
	number = {1},
	urldate = {2019-09-22},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Zitnik, Marinka and Zupan, Blaz},
	month = jan,
	year = {2015},
	pages = {41--53},
}

@article{LanguageModelsKnowledgeBasesa,
	title = {Language {Models} as {Knowledge} {Bases}?},
	url = {http://arxiv.org/abs/1909.01066},
	abstract = {Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as “ﬁllin-the-blank” cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without ﬁne-tuning) in a wide range of state-of-theart pretrained language models. We ﬁnd that (i) without ﬁne-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any ﬁne-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https: //github.com/facebookresearch/LAMA.},
	language = {en},
	urldate = {2019-09-22},
	journal = {arXiv:1909.01066 [cs]},
	author = {Petroni, Fabio and Rocktäschel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H. and Riedel, Sebastian},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.01066},
	keywords = {kg},
}

@inproceedings{HowDoesTwitterUser,
	address = {Vancouver, Canada},
	title = {How {Does} {Twitter} {User} {Behavior} {Vary} {Across} {Demographic} {Groups}?},
	url = {http://aclweb.org/anthology/W17-2912},
	doi = {10.18653/v1/W17-2912},
	abstract = {Demographically-tagged social media messages are a common source of data for computational social science. While these messages can indicate differences in beliefs and behaviors between demographic groups, we do not have a clear understanding of how different demographic groups use platforms such as Twitter. This paper presents a preliminary analysis of how groups’ differing behaviors may confound analyses of the groups themselves. We analyzed one million Twitter users by ﬁrst inferring demographic attributes, and then measuring several indicators of Twitter behavior. We ﬁnd differences in these indicators across demographic groups, suggesting that there may be underlying differences in how different demographic groups use Twitter.},
	language = {en},
	urldate = {2019-09-23},
	booktitle = {Proceedings of the {Second} {Workshop} on {NLP} and {Computational} {Social} {Science}},
	publisher = {Association for Computational Linguistics},
	author = {Wood-Doughty, Zach and Smith, Michael and Broniatowski, David and Dredze, Mark},
	year = {2017},
	pages = {83--89},
}

@article{PersonalityGenderAgeLanguage,
	title = {Personality, {Gender}, and {Age} in the {Language} of {Social} {Media}: {The} {Open}-{Vocabulary} {Approach}},
	volume = {8},
	issn = {1932-6203},
	shorttitle = {Personality, {Gender}, and {Age} in the {Language} of {Social} {Media}},
	url = {https://dx.plos.org/10.1371/journal.pone.0073791},
	doi = {10.1371/journal.pone.0073791},
	abstract = {We analyzed 700 million words, phrases, and topic instances collected from the Facebook messages of 75,000 volunteers, who also took standard personality tests, and found striking variations in language with personality, gender, and age. In our open-vocabulary technique, the data itself drives a comprehensive exploration of language that distinguishes people, finding connections that are not captured with traditional closed-vocabulary word-category analyses. Our analyses shed new light on psychosocial processes yielding results that are face valid (e.g., subjects living in high elevations talk about the mountains), tie in with other research (e.g., neurotic people disproportionately use the phrase ‘sick of’ and the word ‘depressed’), suggest new hypotheses (e.g., an active life implies emotional stability), and give detailed insights (males use the possessive ‘my’ when mentioning their ‘wife’ or ‘girlfriend’ more often than females use ‘my’ with ‘husband’ or ’boyfriend’). To date, this represents the largest study, by an order of magnitude, of language and personality.},
	language = {en},
	number = {9},
	urldate = {2019-09-23},
	journal = {PLoS ONE},
	author = {Schwartz, H. Andrew and Eichstaedt, Johannes C. and Kern, Margaret L. and Dziurzynski, Lukasz and Ramones, Stephanie M. and Agrawal, Megha and Shah, Achal and Kosinski, Michal and Stillwell, David and Seligman, Martin E. P. and Ungar, Lyle H.},
	editor = {Preis, Tobias},
	month = sep,
	year = {2013},
	pages = {e73791},
}

@inproceedings{InferringPerceivedDemographicsUser,
	address = {Berlin, Germany},
	title = {Inferring {Perceived} {Demographics} from {User} {Emotional} {Tone} and {User}-{Environment} {Emotional} {Contrast}},
	url = {http://aclweb.org/anthology/P16-1148},
	doi = {10.18653/v1/P16-1148},
	abstract = {We examine communications in a social network to study user emotional contrast – the propensity of users to express different emotions than those expressed by their neighbors. Our analysis is based on a large Twitter dataset, consisting of the tweets of 123,513 users from the USA and Canada. Focusing on Ekman’s basic emotions, we analyze differences between the emotional tone expressed by these users and their neighbors of different types, and correlate these differences with perceived user demographics. We demonstrate that many perceived demographic traits correlate with the emotional contrast between users and their neighbors. Unlike other approaches on inferring user attributes that rely solely on user communications, we explore the network structure and show that it is possible to accurately predict a range of perceived demographic traits based solely on the emotions emanating from users and their neighbors.},
	language = {en},
	urldate = {2019-09-23},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Volkova, Svitlana and Bachrach, Yoram},
	year = {2016},
	pages = {1567--1578},
}

@article{DetectionUserDemographicsSocial,
	title = {Detection of {User} {Demographics} on {Social} {Media}: {A} {Review} of {Methods} and {Recommendations} for {Best} {Practices}},
	abstract = {Researchers in fields such as sociology, demography and public health, have used data from social media to explore a diversity of questions. In public health, researchers use data from social media to monitor disease spread, assess population attitudes toward health-related issues, and to better understand the relationship between behavioral changes and population health. However, a major limitation of the use of these data for population health research is a lack of key demographic indicators such as, age, race and gender. Several studies have proposed methods for automated detection of social media users’ demographic characteristics. These range from facial recognition to classic supervised and unsupervised machine learning methods. We seek to provide a review of existing approaches to automated detection of demographic characteristics of social media users. We also address the applicability of these methods to public health research; focusing on the challenge of working with highly dynamical, large scale data to study health trends. Furthermore, we provide an overview of work that emphasizes scalability and efficiency in data acquisition and processing, and make best practice recommendations.},
	language = {en},
	author = {Cesare, Nina and Grant, Christan and Nsoesie, Elaine O},
	pages = {18},
}

@article{PredictingDemographicsMoralFoundations,
	title = {Predicting {Demographics}, {Moral} {Foundations}, and {Human} {Values} from {Digital} {Behaviors}},
	volume = {92},
	issn = {07475632},
	url = {http://arxiv.org/abs/1712.01930},
	doi = {10.1016/j.chb.2018.11.024},
	abstract = {Personal electronic devices including smartphones give access to behavioural signals that can be used to learn about the characteristics and preferences of individuals. In this study, we explore the connection between demographic and psychological attributes and the digital behavioural records, for a cohort of 7,633 people, closely representative of the US population with respect to gender, age, geographical distribution, education, and income. Along with the demographic data, we collected self-reported assessments on validated psychometric questionnaires for moral traits and basic human values, and combined this information with passively collected multi-modal digital data from web browsing behaviour and smartphone usage. A machine learning framework was then designed to infer both the demographic and psychological attributes from the behavioural data. In a cross-validated setting, our models predicted demographic attributes with good accuracy as measured by the weighted AUROC score (Area Under the Receiver Operating Characteristic), but were less performant for the moral traits and human values. These results call for further investigation, since they are still far from unveiling individuals’ psychological fabric. This connection, along with the most predictive features that we provide for each attribute, might prove useful for designing personalised services, communication strategies, and interventions, and can be used to sketch a portrait of people with similar worldview.},
	language = {en},
	urldate = {2019-09-23},
	journal = {Computers in Human Behavior},
	author = {Kalimeri, Kyriaki and Beiro, Mariano G. and Delfino, Matteo and Raleigh, Robert and Cattuto, Ciro},
	month = mar,
	year = {2019},
	note = {arXiv: 1712.01930},
	pages = {428--445},
}

@article{PredictingDemographicsAffectSocial,
	title = {Predicting {Demographics} and {Aﬀect} in {Social} {Networks}},
	language = {en},
	author = {Volkova, Svitlana},
	pages = {367},
}

@inproceedings{PersonalityDrivenDifferencesParaphrase,
	address = {Vancouver, Canada},
	title = {Personality {Driven} {Differences} in {Paraphrase} {Preference}},
	url = {http://aclweb.org/anthology/W17-2903},
	doi = {10.18653/v1/W17-2903},
	abstract = {Personality plays a decisive role in how people behave in different scenarios, including online social media. Researchers have used such data to study how personality can be predicted from language use. In this paper, we study phrase choice as a particular stylistic linguistic difference, as opposed to the mostly topical differences identiﬁed previously. Building on previous work on demographic preferences, we quantify differences in paraphrase choice from a massive Facebook data set with posts from over 115,000 users. We quantify the predictive power of phrase choice in user proﬁling and use phrase choice to study psycholinguistic hypotheses. This work is relevant to future applications that aim to personalize text generation to speciﬁc personality types.},
	language = {en},
	urldate = {2019-09-23},
	booktitle = {Proceedings of the {Second} {Workshop} on {NLP} and {Computational} {Social} {Science}},
	publisher = {Association for Computational Linguistics},
	author = {Preoţiuc-Pietro, Daniel and Carpenter, Jordan and Ungar, Lyle},
	year = {2017},
	pages = {17--26},
}

@article{MachineLearningApproachTwitter,
	title = {A {Machine} {Learning} {Approach} to {Twitter} {User} {Classification}},
	abstract = {This paper addresses the task of user classiﬁcation in social media, with an application to Twitter. We automatically infer the values of user attributes such as political orientation or ethnicity by leveraging observable information such as the user behavior, network structure and the linguistic content of the user’s Twitter feed. We employ a machine learning approach which relies on a comprehensive set of features derived from such user information. We report encouraging experimental results on 3 tasks with different characteristics: political afﬁliation detection, ethnicity identiﬁcation and detecting afﬁnity for a particular business. Finally, our analysis shows that rich linguistic features prove consistently valuable across the 3 tasks and show great promise for additional user classiﬁcation needs.},
	language = {en},
	author = {Pennacchiotti, Marco and Popescu, Ana-Maria},
	pages = {8},
}

@article{PredictingAgeGroupsTwitter,
	title = {Predicting age groups of {Twitter} users based on language and metadata features},
	volume = {12},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0183537},
	doi = {10.1371/journal.pone.0183537},
	abstract = {Health organizations are increasingly using social media, such as Twitter, to disseminate health messages to target audiences. Determining the extent to which the target audience (e.g., age groups) was reached is critical to evaluating the impact of social media education campaigns. The main objective of this study was to examine the separate and joint predictive validity of linguistic and metadata features in predicting the age of Twitter users. We created a labeled dataset of Twitter users across different age groups (youth, young adults, adults) by collecting publicly available birthday announcement tweets using the Twitter Search application programming interface. We manually reviewed results and, for each age-labeled handle, collected the 200 most recent publicly available tweets and user handles’ metadata. The labeled data were split into training and test datasets. We created separate models to examine the predictive validity of language features only, metadata features only, language and metadata features, and words/phrases from another age-validated dataset. We estimated accuracy, precision, recall, and F1 metrics for each model. An L1-regularized logistic regression model was conducted for each age group, and predicted probabilities between the training and test sets were compared for each age group. Cohen’s d effect sizes were calculated to examine the relative importance of significant features. Models containing both Tweet language features and metadata features performed the best (74\% precision, 74\% recall, 74\% F1) while the model containing only Twitter metadata features were least accurate (58\% precision, 60\% recall, and 57\% F1 score). Top predictive features included use of terms such as “school” for youth and “college” for young adults. Overall, it was more challenging to predict older adults accurately. These results suggest that examining linguistic and Twitter metadata features to predict youth and young adult Twitter users may be helpful for informing public health surveillance and evaluation research.},
	language = {en},
	number = {8},
	urldate = {2019-09-23},
	journal = {PLOS ONE},
	author = {Morgan-Lopez, Antonio A. and Kim, Annice E. and Chew, Robert F. and Ruddle, Paul},
	editor = {Costello, Kaitlin},
	month = aug,
	year = {2017},
	pages = {e0183537},
}

@article{YourAgeNoSecret,
	title = {Your {Age} {Is} {No} {Secret}: {Inferring} {Microbloggers}' {Ages} via {Content} and {Interaction} {Analysis}},
	abstract = {Microblogging systems such as Twitter have seen explosive use in public and private sectors. The age information of microbloggers can be very useful for many applications such as viral marketing and social studies/surveys. Current microblogging systems, however, have very sparse age information. In this paper, we present MAIF, a novel framework that explores public content and interaction information in microblogging systems to explore the hidden ages of microbloggers. We thoroughly evaluate the accuracy of MAIF with a real-world dataset with 54,879 Twitter users. Our results show that MAIF can achieve up to 81.38\% inference accuracy and outperforms the state of the art by 9.15\%. We also discuss some countermeasures to alleviate the possible privacy concerns caused by MAIF.},
	language = {en},
	author = {Zhang, Jinxue and Hu, Xia and Zhang, Yanchao and Liu, Huan},
	pages = {10},
}

@article{InferringGenderContentTweets,
	title = {Inferring {Gender} from the {Content} of {Tweets}: {A} {Region} {Specific} {Example}},
	abstract = {There is growing interest in using social networking sites such as Twitter to gather real-time data on the reactions and opinions of a region's population, including locations in the developing world where social media has played an important role in recent events, such as the 2011 Arab Spring. However, many interesting and important opinions and reactions may differ significantly within a given region depending on the demographics of the subpopulation, including such categories as gender and ethnicity. This information may not be explicitly available in user content or metadata, however, and automated methods are required to infer such hidden attributes. In this paper we describe a method to infer the gender of Twitter users from only the content of their tweets. Looking at Twitter users from the West African nation of Nigeria, we applied supervised machine learning using features derived from the content of user tweets to train a classifier. Using unigram features alone, we obtained an accuracy of 80\% for predicting gender, suggesting that content alone can be a good predictor of gender. An analysis of the highest weighted features shows some interesting distinctions between men and women both topically and emotionally. We argue that approaches such as the one described here can give us a clearer picture of who is utilizing social media when certain user attributes are unreliable or not available.},
	language = {en},
	author = {Fink, Clay and Kopecky, Jonathon and Morawski, Maksym},
	pages = {4},
}

@article{HowWellCanMachine,
	title = {How well can machine learning predict demographics of social media users?},
	abstract = {The wide use of social media sites and other digital technologies have resulted in an unprecedented availability of digital data that are being used to study human behavior across research domains. Although unsolicited opinions and sentiments are available on these platforms, demographic details are usually missing. Demographic information is pertinent in fields such as demography and public health, where significant differences can exist across sex, racial and socioeconomic groups. In an attempt to address this shortcoming, a number of academic studies have proposed methods for inferring the demographics of social media users using details such as names, usernames, and network characteristics. Gender is the easiest trait to accurately infer, with measures of accuracy higher than 90\% in some studies. Race, ethnicity and age tend to be more challenging to predict for a variety of reasons including the novelty of social media to certain age groups and a lack of significant deviations in user details across racial/ethnic groups. Although the endeavor to predict user’ demographics is plagued with ethical questions regarding privacy and data ownership, knowing the demographics in a data sample can aid in addressing issues of bias and population representation, so that existing societal inequalities are not exacerbated.},
	language = {en},
	author = {Cesare, Nina},
	pages = {25},
}

@inproceedings{UserInterfacesExplorationHierarchical,
	address = {Baltimore, MD},
	title = {User {Interfaces} for the {Exploration} of {Hierarchical} {Multi}-dimensional {Data}},
	isbn = {978-1-4244-0591-6},
	url = {https://ieeexplore.ieee.org/document/4035763/},
	doi = {10.1109/VAST.2006.261422},
	abstract = {A variety of user interfaces have been developed to support the querying of hierarchical multi-dimensional data in an OLAP setting such as pivot tables and more recently Polaris. They are used to regularly check portions of a dataset and to explore a new dataset for the first time. In this paper, we establish criteria for OLAP user interface capabilities to facilitate comparison. Two criteria are the number of displayed dimensions along which comparisons can be made and the number of dimensions that are viewable at once—visual comparison depth and width. We argue that interfaces with greater visual comparison depth support regular checking of known data by users that know roughly where to look, while interfaces with greater comparison width support exploration of new data by users that have no apriori starting point and need to scan all dimensions. Pivot tables and Polaris are examples of the former. The main contribution of this paper is to introduce a new scalable interface that uses parallel dimension axis which supports the latter, greater visual comparison width. We compare our approach to both recent table based and parallel coordinate based interfaces. We present an implementation of our interface SGViewer, user scenarios and provide an evaluation that supports the usability of our interface.},
	language = {en},
	urldate = {2019-09-24},
	booktitle = {2006 {IEEE} {Symposium} {On} {Visual} {Analytics} {Science} {And} {Technology}},
	publisher = {IEEE},
	author = {Sifer, Mark},
	month = oct,
	year = {2006},
	keywords = {vis},
	pages = {175--182},
}

@article{HierarchicalAggregationInformationVisualizationa,
	title = {Hierarchical {Aggregation} for {Information} {Visualization}: {Overview}, {Techniques}, and {Design} {Guidelines}},
	volume = {16},
	issn = {1077-2626},
	shorttitle = {Hierarchical {Aggregation} for {Information} {Visualization}},
	url = {http://ieeexplore.ieee.org/document/5184827/},
	doi = {10.1109/TVCG.2009.84},
	abstract = {We present a model for building, visualizing, and interacting with multiscale representations of information visualization techniques using hierarchical aggregation. The motivation for this work is to make visual representations more visually scalable and less cluttered. The model allows for augmenting existing techniques with multiscale functionality, as well as for designing new visualization and interaction techniques that conform to this new class of visual representations. We give some examples of how to use the model for standard information visualization techniques such as scatterplots, parallel coordinates, and node-link diagrams, and discuss existing techniques that are based on hierarchical aggregation. This yields a set of design guidelines for aggregated visualizations. We also present a basic vocabulary of interaction techniques suitable for navigating these multiscale visualizations.},
	language = {en},
	number = {3},
	urldate = {2019-09-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Elmqvist, N. and Fekete, J.-D.},
	month = may,
	year = {2010},
	keywords = {vis},
	pages = {439--454},
}

@article{SupportingAnalysisDimensionalityReduction,
	title = {Supporting {Analysis} of {Dimensionality} {Reduction} {Results} with {Contrastive} {Learning}},
	url = {http://arxiv.org/abs/1905.03911},
	abstract = {Dimensionality reduction (DR) is frequently used for analyzing and visualizing high-dimensional data as it provides a good ﬁrst glance of the data. However, to interpret the DR result for gaining useful insights from the data, it would take additional analysis effort such as identifying clusters and understanding their characteristics. While there are many automatic methods (e.g., density-based clustering methods) to identify clusters, effective methods for understanding a cluster’s characteristics are still lacking. A cluster can be mostly characterized by its distribution of feature values. Reviewing the original feature values is not a straightforward task when the number of features is large. To address this challenge, we present a visual analytics method that effectively highlights the essential features of a cluster in a DR result. To extract the essential features, we introduce an enhanced usage of contrastive principal component analysis (cPCA). Our method, called ccPCA (contrasting clusters in PCA), can calculate each feature’s relative contribution to the contrast between one cluster and other clusters. With ccPCA, we have created an interactive system including a scalable visualization of clusters’ feature contributions. We demonstrate the effectiveness of our method and system with case studies using several publicly available datasets.},
	language = {en},
	urldate = {2019-09-24},
	journal = {arXiv:1905.03911 [cs, stat]},
	author = {Fujiwara, Takanori and Kwon, Oh-Hyun and Ma, Kwan-Liu},
	month = may,
	year = {2019},
	note = {arXiv: 1905.03911},
	keywords = {vis},
}

@article{ClusterawareArrangementParallelCoordinatea,
	title = {Cluster-aware arrangement of the parallel coordinate plots},
	volume = {46},
	issn = {1045926X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1045926X17301921},
	doi = {10.1016/j.jvlc.2017.10.003},
	abstract = {The dimension ordering of parallel coordinate plots has been widely studied, aiming at the insightful exploration of multi-dimensional data. However, few works focus on the category distributions across dimensions and construct an effective dimension ordering to enable the visual exploration of clusters. Therefore, we propose a cluster-aware arrangement method of the parallel coordinate plots and design a visualization framework for the multi-dimensional data exploration. Firstly, a hierarchical clustering scheme is employed to identify the categories of interest across different dimensions. Then we design a group of icicle views to present the hierarchies of dimensions, the colors of which also indicate the relationships between different categories. A cluster-aware correlation is deﬁned to measure the relationships between different attribute axes, based on the distributions of categories. Furthermore, a matrix map is designed to present the relationships between dimensions, and the MDS method is employed to transform the dimensions into 2D coordinates, in which the correlations among the dimensions are conserved. At last, we solve the Traveling Salesman Problem (TSP) and achieve an automated dimension ordering of the parallel coordinate plots, which largely highlights the relations of categories across dimensions. A set of convenient interactions are also integrated in the visualization system, allowing users to get insights into the multi-dimensional data from various perspectives. A large number of experimental results and the credible user studies further demonstrate the usefulness of the cluster-aware arrangement of the parallel coordinate plots.},
	language = {en},
	urldate = {2019-09-24},
	journal = {Journal of Visual Languages \& Computing},
	author = {Zhou, Zhiguang and Ye, Zhifei and Yu, Jiajun and Chen, Weifeng},
	month = jun,
	year = {2018},
	keywords = {vis},
	pages = {43--52},
}

@article{VASABIHierarchicalUserProfiles,
	title = {{VASABI}: {Hierarchical} {User} {Profiles} for {Interactive} {Visual} {User} {Behaviour} {Analytics}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{VASABI}},
	url = {https://ieeexplore.ieee.org/document/8807354/},
	doi = {10.1109/TVCG.2019.2934609},
	abstract = {User behaviour analytics (UBA) systems offer sophisticated models that capture users’ behaviour over time with an aim to identify fraudulent activities that do not match their proﬁles. Motivated by the challenges in the interpretation of UBA models, this paper presents a visual analytics approach to help analysts gain a comprehensive understanding of user behaviour at multiple levels, namely individual and group level. We take a user-centred approach to design a visual analytics framework supporting the analysis of collections of users and the numerous sessions of activities they conduct within digital applications. The framework is centred around the concept of hierarchical user proﬁles that are built based on features derived from sessions, as well as on user tasks extracted using a topic modelling approach to summarise and stratify user behaviour. We externalise a series of analysis goals and tasks, and evaluate our methods through use cases conducted with experts. We observe that with the aid of interactive visual hierarchical user proﬁles, analysts are able to conduct exploratory and investigative analysis effectively, and able to understand the characteristics of user behaviour to make informed decisions whilst evaluating suspicious users and activities.},
	language = {en},
	urldate = {2019-09-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Nguyen, Phong H. and Henkin, Rafael and Chen, Siming and Andrienko, Natalia and Andrienko, Gennady and Thonnard, Olivier and Turkay, Cagatay},
	year = {2019},
	pages = {1--1},
}

@article{ImportanceUXMachineTeaching,
	title = {The {Importance} of {UX} for {Machine} {Teaching}},
	abstract = {In this position paper, we argue that UX designers should take an increasing responsibility for the process and tools used in the generation of training data for machine learning algorithms. We provide a number of annotated examples from our UX practice within the medical imaging domain to highlight different ways that a UX approach can help to select training data set, facilitate initial generation and ensure that the ﬁnal systems become self-sufﬁcient on training data, so that the systems can efﬁciently improve performance over time.},
	language = {en},
	author = {Lindvall, Martin and Molin, Jesper and Lowgren, Jonas},
	keywords = {mt},
	pages = {4},
}

@article{TELEGAMCombiningVisualizationVerbalizationb,
	title = {{TELEGAM}: {Combining} {Visualization} and {Verbalization} for {Interpretable} {Machine} {Learning}},
	abstract = {While machine learning (ML) continues to ﬁnd success in solving previously-thought hard problems, interpreting and exploring ML models remains challenging. Recent work has shown that visualizations are a powerful tool to aid debugging, analyzing, and interpreting ML models. However, depending on the complexity of the model (e.g., number of features), interpreting these visualizations can be difﬁcult and may require additional expertise. Alternatively, textual descriptions, or verbalizations, can be a simple, yet effective way to communicate or summarize key aspects about a model, such as the overall trend in a model’s predictions or comparisons between pairs of data instances. With the potential beneﬁts of visualizations and verbalizations in mind, we explore how the two can be combined to aid ML interpretability. Speciﬁcally, we present a prototype system, TELEGAM, that demonstrates how visualizations and verbalizations can collectively support interactive exploration of ML models, for example, generalized additive models (GAMs). We describe TELEGAM’s interface and underlying heuristics to generate the verbalizations. We conclude by discussing how TELEGAM can serve as a platform to conduct future studies for understanding user expectations and designing novel interfaces for interpretable ML.},
	language = {en},
	author = {Hohman, Fred and Srinivasan, Arjun and Drucker, Steven M},
	keywords = {vis},
	pages = {5},
}

@article{ExploringLinearProjectionsRevealinga,
	title = {Exploring linear projections for revealing clusters, outliers, and trends in subsets of multi-dimensional datasets},
	volume = {48},
	issn = {1045926X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1045926X18301289},
	doi = {10.1016/j.jvlc.2018.08.003},
	abstract = {Identifying patterns in 2D linear projections is important in understanding multi-dimensional datasets. However, local patterns, which are composed of partial data points, are usually obscured by noises and missed in traditional quality measure approaches that measure the whole dataset. In this paper, we propose an interactive interface to explore 2D linear projections with visual patterns on subsets. First, we propose a voting-based algorithm to recommend optimal projection, in which the identiﬁed pattern looks the most salient. Speciﬁcally, we propose three kinds of point-wise quality metrics of 2D linear projections for outliers, clusterings, and trends, respectively. For each sampled projection, we measure its importance by accumulating the metrics of selected points. The projection with the highest importance is recommended. Second, we design an exploring interface with a scatterplot, a projection trail map, and a control panel. Our interface allows users to explore projections by specifying interested data subsets. At last, we employ three datasets and demonstrate the eﬀectiveness of our approach through three case studies of exploring clusters, outliers, and trends.},
	language = {en},
	urldate = {2019-09-24},
	journal = {Journal of Visual Languages \& Computing},
	author = {Xia, Jiazhi and Gao, Le and Kong, Kezhi and Zhao, Ying and Chen, Yi and Kui, Xiaoyan and Liang, Yixiong},
	month = oct,
	year = {2018},
	keywords = {vis},
	pages = {52--60},
}

@article{MachineTeachingInverseProblem,
	title = {Machine {Teaching}: an {Inverse} {Problem} to {Machine} {Learning} and an {Approach} {Toward} {Optimal} {Education}},
	abstract = {I draw the reader’s attention to machine teaching, the problem of ﬁnding an optimal training set given a machine learning algorithm and a target model. In addition to generating fascinating mathematical questions for computer scientists to ponder, machine teaching holds the promise of enhancing education and personnel training. The Socratic dialogue style aims to stimulate critical thinking.},
	language = {en},
	author = {Zhu, Xiaojin},
	keywords = {mt},
	pages = {5},
}

@article{OverviewMachineTeaching,
	title = {An {Overview} of {Machine} {Teaching}},
	url = {http://arxiv.org/abs/1801.05927},
	abstract = {In this paper we try to organize machine teaching as a coherent set of ideas. Each idea is presented as varying along a dimension. The collection of dimensions then form the problem space of machine teaching, such that existing teaching problems can be characterized in this space. We hope this organization allows us to gain deeper understanding of individual teaching problems, discover connections among them, and identify gaps in the ﬁeld.},
	language = {en},
	urldate = {2019-09-24},
	journal = {arXiv:1801.05927 [cs]},
	author = {Zhu, Xiaojin and Singla, Adish and Zilles, Sandra and Rafferty, Anna N.},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.05927},
	keywords = {mt},
}

@inproceedings{CoclusteringDocumentsWordsUsing,
	address = {San Francisco, California},
	title = {Co-clustering documents and words using bipartite spectral graph partitioning},
	isbn = {978-1-58113-391-2},
	url = {http://portal.acm.org/citation.cfm?doid=502512.502550},
	doi = {10.1145/502512.502550},
	language = {en},
	urldate = {2019-09-24},
	booktitle = {Proceedings of the seventh {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining  - {KDD} '01},
	publisher = {ACM Press},
	author = {Dhillon, Inderjit S.},
	year = {2001},
	keywords = {clustering, dm, elir, key},
	pages = {269--274},
}

@article{LargeScaleMultiViewSpectralClustering,
	title = {Large-{Scale} {Multi}-{View} {Spectral} {Clustering} via {Bipartite} {Graph}},
	abstract = {In this paper, we address the problem of large-scale multi-view spectral clustering. In many real-world applications, data can be represented in various heterogeneous features or views. Different views often provide different aspects of information that are complementary to each other. Several previous methods of clustering have demonstrated that better accuracy can be achieved using integrated information of all the views than just using each view individually. One important class of such methods is multi-view spectral clustering, which is based on graph Laplacian. However, existing methods are not applicable to large-scale problem for their high computational complexity. To this end, we propose a novel large-scale multi-view spectral clustering approach based on the bipartite graph. Our method uses local manifold fusion to integrate heterogeneous features. To improve efﬁciency, we approximate the similarity graphs using bipartite graphs. Furthermore, we show that our method can be easily extended to handle the out-of-sample problem. Extensive experimental results on ﬁve benchmark datasets demonstrate the effectiveness and efﬁciency of the proposed method, where our method runs up to nearly 3000 times faster than the state-of-the-art methods.},
	language = {en},
	author = {Li, Yeqing and Nie, Feiping and Huang, Heng and Huang, Junzhou},
	keywords = {clustering, dm},
	pages = {7},
}

@inproceedings{SpectralClusteringMultitypeRelational,
	address = {Pittsburgh, Pennsylvania},
	title = {Spectral clustering for multi-type relational data},
	isbn = {978-1-59593-383-6},
	url = {http://portal.acm.org/citation.cfm?doid=1143844.1143918},
	doi = {10.1145/1143844.1143918},
	abstract = {Clustering on multi-type relational data has attracted more and more attention in recent years due to its high impact on various important applications, such as Web mining, e-commerce and bioinformatics. However, the research on general multi-type relational data clustering is still limited and preliminary. The contribution of the paper is three-fold. First, we propose a general model, the collective factorization on related matrices, for multi-type relational data clustering. The model is applicable to relational data with various structures. Second, under this model, we derive a novel algorithm, the spectral relational clustering, to cluster multi-type interrelated data objects simultaneously. The algorithm iteratively embeds each type of data objects into low dimensional spaces and beneﬁts from the interactions among the hidden structures of different types of data objects. Extensive experiments demonstrate the promise and effectiveness of the proposed algorithm. Third, we show that the existing spectral clustering algorithms can be considered as the special cases of the proposed model and algorithm. This demonstrates the good theoretic generality of the proposed model and algorithm.},
	language = {en},
	urldate = {2019-09-24},
	booktitle = {Proceedings of the 23rd international conference on {Machine} learning  - {ICML} '06},
	publisher = {ACM Press},
	author = {Long, Bo and Zhang, Zhongfei (Mark) and Wú, Xiaoyun and Yu, Philip S.},
	year = {2006},
	keywords = {clustering, dm},
	pages = {585--592},
}

@article{ArtScienceMachineLearninga,
	title = {On the {Art} and {Science} of {Machine} {Learning} {Explanations}},
	url = {http://arxiv.org/abs/1810.02909},
	abstract = {This text discusses several popular explanatory methods that go beyond the error measurements and plots traditionally used to assess machine learning models. Some of the explanatory methods are accepted tools of the trade while others are rigorously derived and backed by long-standing theory. The methods, decision tree surrogate models, individual conditional expectation (ICE) plots, local interpretable model-agnostic explanations (LIME), partial dependence plots, and Shapley explanations, vary in terms of scope, fidelity, and suitable application domain. Along with descriptions of these methods, this text presents real-world usage recommendations supported by a use case and public, in-depth software examples for reproducibility.},
	language = {en},
	urldate = {2019-09-26},
	journal = {arXiv:1810.02909 [cs, stat]},
	author = {Hall, Patrick},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.02909},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{CategorisationPosthocExplanationsPredictive,
	title = {A {Categorisation} of {Post}-hoc {Explanations} for {Predictive} {Models}},
	url = {http://arxiv.org/abs/1904.02495},
	abstract = {The ubiquity of machine learning based predictive models in modern society naturally leads people to ask how trustworthy those models are? In predictive modeling, it is quite common to induce a trade-off between accuracy and interpretability. For instance, doctors would like to know how effective some treatment will be for a patient or why the model suggested a particular medication for a patient exhibiting those symptoms? We acknowledge that the necessity for interpretability is a consequence of an incomplete formalisation of the problem, or more precisely of multiple meanings adhered to a particular concept. For certain problems, it is not enough to get the answer (what), the model also has to provide an explanation of how it came to that conclusion (why), because a correct prediction, only partially solves the original problem. In this article we extend existing categorisation of techniques to aid model interpretability and test this categorisation.},
	language = {en},
	urldate = {2019-09-26},
	journal = {arXiv:1904.02495 [cs]},
	author = {Mitros, John and Mac Namee, Brian},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.02495},
	keywords = {fatml, xai},
}

@article{GuidelinesResponsibleHumanCenteredUse,
	title = {Guidelines for {Responsible} and {Human}-{Centered} {Use} of {Explainable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1906.03533},
	abstract = {Explainable machine learning (ML) has been implemented in numerous open source and proprietary software packages and explainable ML is an important aspect of commercial predictive modeling. However, explainable ML can be misused, particularly as a faulty safeguard for harmful black-boxes, e.g. fairwashing, and for other malevolent purposes like model stealing. This text discusses definitions, examples, and guidelines that promote a holistic and human-centered approach to ML which includes interpretable (i.e. white-box ) models and explanatory, debugging, and disparate impact analysis techniques.},
	language = {en},
	urldate = {2019-09-26},
	journal = {arXiv:1906.03533 [cs, stat]},
	author = {Hall, Patrick},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.03533},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@inproceedings{CasualVisualExplorationLarge,
	address = {Konstanz},
	title = {Casual {Visual} {Exploration} of {Large} {Bipartite} {Graphs} {Using} {Hierarchical} {Aggregation} and {Filtering}},
	isbn = {978-1-5386-9194-6},
	url = {https://ieeexplore.ieee.org/document/8533894/},
	doi = {10.1109/BDVA.2018.8533894},
	abstract = {Bipartite graphs are typically visualized using linked lists or matrices. However, these classic visualization techniques do not scale well with the number of nodes. Biclustering has been used to aggregate edges, but not to create linked lists with thousands of nodes. In this paper, we present a new casual exploration interface for large, weighted bipartite graphs, which allows for multi-scale exploration through hierarchical aggregation of nodes and edges using biclustering in linked lists. We demonstrate the usefulness of the technique using two data sets: a database of media advertising expenses of public authorities and author-keyword co-occurrences from the IEEE Visualization Publication collection. Through an insight-based study with lay users, we show that the biclustering interface leads to longer exploration times, more insights, and more unexpected ﬁndings than a baseline interface using only ﬁltering. However, users also perceive the biclustering interface as more complex.},
	language = {en},
	urldate = {2019-09-24},
	booktitle = {2018 {International} {Symposium} on {Big} {Data} {Visual} and {Immersive} {Analytics} ({BDVA})},
	publisher = {IEEE},
	author = {Steinbock, Daniel and Groller, Eduard and Waldner, Manuela},
	month = oct,
	year = {2018},
	keywords = {vis},
	pages = {1--10},
}

@article{OntoPlotNovelVisualisationNonhierarchical,
	title = {{OntoPlot}: {A} {Novel} {Visualisation} for {Non}-hierarchical {Associations} in {Large} {Ontologies}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{OntoPlot}},
	url = {https://ieeexplore.ieee.org/document/8809833/},
	doi = {10.1109/TVCG.2019.2934557},
	language = {en},
	urldate = {2019-09-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Yang, Yang and Wybrow, Michael and Li, Yuan-Fang and Czauderna, Tobias and He, Yongqun},
	year = {2019},
	keywords = {vis},
	pages = {1--1},
}

@article{EffectEdgeBundlingSeriation,
	title = {The {Effect} of {Edge} {Bundling} and {Seriation} on {Sensemaking} of {Biclusters} in {Bipartite} {Graphs}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/8423100/},
	doi = {10.1109/TVCG.2018.2861397},
	abstract = {Exploring coordinated relationships (e.g., shared relationships between two sets of entities) is an important analytics task in a variety of real-world applications, such as discovering similarly behaved genes in bioinformatics, detecting malware collusions in cyber security, and identifying products bundles in marketing analysis. Coordinated relationships can be formalized as biclusters. In order to support visual exploration of biclusters, bipartite graphs based visualizations have been proposed, and edge bundling is used to show biclusters. However, it suffers from edge crossings due to possible overlaps of biclusters, and lacks in-depth understanding of its impact on user exploring biclusters in bipartite graphs. To address these, we propose a novel bicluster-based seriation technique that can reduce edge crossings in bipartite graphs drawing and conducted a user experiment to study the effect of edge bundling and this proposed technique on visualizing biclusters in bipartite graphs. We found that they both had impact on reducing entity visits for users exploring biclusters, and edge bundles helped them ﬁnd more justiﬁed answers. Moreover, we identiﬁed four key trade-offs that inform the design of future bicluster visualizations. The study results suggest that edge bundling is critical for exploring biclusters in bipartite graphs, which helps to reduce low-level perceptual problems and support high-level inferences.},
	language = {en},
	number = {10},
	urldate = {2019-09-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Sun, Maoyuan and Zhao, Jian and Wu, Hao and Luther, Kurt and North, Chris and Ramakrishnan, Naren},
	month = oct,
	year = {2019},
	keywords = {vis},
	pages = {2983--2998},
}

@inproceedings{DimScannerRelationbasedVisualExploration,
	address = {Baltimore, MD, USA},
	title = {{DimScanner}: {A} relation-based visual exploration approach towards data dimension inspection},
	isbn = {978-1-5090-5661-3},
	shorttitle = {{DimScanner}},
	url = {http://ieeexplore.ieee.org/document/7883514/},
	doi = {10.1109/VAST.2016.7883514},
	language = {en},
	urldate = {2019-09-24},
	booktitle = {2016 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {{Jing Xia} and {Wei Chen} and {Yumeng Hou} and {Wanqi Hu} and {Xinxin Huang} and Ebertk, David S.},
	month = oct,
	year = {2016},
	keywords = {vis},
	pages = {81--90},
}

@article{DimensionProjectionMatrixTree,
	title = {Dimension {Projection} {Matrix}/{Tree}: {Interactive} {Subspace} {Visual} {Exploration} and {Analysis} of {High} {Dimensional} {Data}},
	volume = {19},
	issn = {1077-2626},
	shorttitle = {Dimension {Projection} {Matrix}/{Tree}},
	url = {http://ieeexplore.ieee.org/document/6634155/},
	doi = {10.1109/TVCG.2013.150},
	abstract = {For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The ﬁrst is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node’s dimensions or a subset of the parent node’s data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.},
	language = {en},
	number = {12},
	urldate = {2019-09-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {{Xiaoru Yuan} and {Donghao Ren} and {Zuchao Wang} and {Cong Guo}},
	month = dec,
	year = {2013},
	keywords = {vis},
	pages = {2625--2633},
}

@article{WhatIfToolInteractiveProbinga,
	title = {The {What}-{If} {Tool}: {Interactive} {Probing} of {Machine} {Learning} {Models}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {The {What}-{If} {Tool}},
	url = {https://ieeexplore.ieee.org/document/8807255/},
	doi = {10.1109/TVCG.2019.2934619},
	abstract = {A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.},
	language = {en},
	urldate = {2019-09-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wexler, James and Pushkarna, Mahima and Bolukbasi, Tolga and Wattenberg, Martin and Viegas, Fernanda and Wilson, Jimbo},
	year = {2019},
	keywords = {vis},
	pages = {1--1},
}

@article{LDAEnsemblesInteractiveExploration,
	title = {{LDA} {Ensembles} for {Interactive} {Exploration} and {Categorization} of {Behaviors}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/8663312/},
	doi = {10.1109/TVCG.2019.2904069},
	abstract = {We deﬁne behavior as a set of actions performed by some actor during a period of time. We consider the problem of analyzing a large collection of behaviors by multiple actors, more speciﬁcally, identifying typical behaviors and spotting anomalous behaviors. We propose an approach leveraging topic modeling techniques – LDA (Latent Dirichlet Allocation) Ensembles – to represent categories of typical behaviors by topics that are obtained through topic modeling a behavior collection. When such methods are applied to text in natural languages, the quality of the extracted topics are usually judged based on the semantic relatedness of the terms pertinent to the topics. This criterion, however, is not necessarily applicable to topics extracted from non-textual data, such as action sets, since relationships between actions may not be obvious. We have developed a suite of visual and interactive techniques supporting the construction of an appropriate combination of topics based on other criteria, such as distinctiveness and coverage of the behavior set. Two case studies on analyzing operation behaviors in the security management system and visiting behaviors in an amusement park, and the expert evaluation of the ﬁrst case study demonstrate the effectiveness of our approach.},
	language = {en},
	urldate = {2019-09-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Chen, Siming and Andrienko, Natalia and Andrienko, Gennady and Adilova, Linara and Barlet, Jeremie and Kindermann, Joerg and Nguyen, Phong Hai and Thonnard, Olivier and Turkay, Cagatay},
	year = {2019},
	keywords = {vis},
	pages = {1--1},
}

@article{SolarViewLowDistortionRadial,
	title = {{SolarView}: {Low} {Distortion} {Radial} {Embedding} with a {Focus}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{SolarView}},
	url = {https://ieeexplore.ieee.org/document/8434356/},
	doi = {10.1109/TVCG.2018.2865361},
	abstract = {We propose a novel type of low distortion radial embedding which focuses on one speciﬁc entity and its closest neighbors. Our embedding preserves near-exact distances to the focus entity and aims to minimize distortion between the other entities. We present an interactive exploration tool SolarView which places the focus entity at the center of a “solar system” and embeds its neighbors guided by concentric circles. SolarView provides an implementation of our novel embedding and several state-of-the-art dimensionality reduction and embedding techniques, which we adapted to our setting in various ways. We experimentally evaluated our embedding and compared it to these state-of-the-art techniques. The results show that our embedding competes with these techniques and achieves low distortion in practice. Our method performs particularly well when the visualization, and hence the embedding, adheres to the solar system design principle of our application. Nonetheless—as with all dimensionality reduction techniques—the distortion may be high. We leverage interaction techniques to give clear visual cues that allow users to accurately judge distortion. We illustrate the use of SolarView by exploring the high-dimensional metric space of bibliographic entity similarities.},
	language = {en},
	number = {10},
	urldate = {2019-09-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Castermans, Thom and Verbeek, Kevin and Speckmann, Bettina and Westenberg, Michel A. and Koopman, Rob and Wang, Shenghui and van den Berg, Hein and Betti, Arianna},
	month = oct,
	year = {2019},
	keywords = {vis},
	pages = {2969--2982},
}

@article{KnowledgeGraphFactPrediction,
	title = {Knowledge {Graph} {Fact} {Prediction} via {Knowledge}-{Enriched} {Tensor} {Factorization}},
	url = {http://arxiv.org/abs/1902.03077},
	abstract = {We present a family of novel methods for embedding knowledge graphs into real-valued tensors. These tensor-based embeddings capture the ordered relations that are typical in the knowledge graphs represented by semantic web languages like RDF. Unlike many previous models, our methods can easily use prior background knowledge provided by users or extracted automatically from existing knowledge graphs. In addition to providing more robust methods for knowledge graph embedding, we provide a provably-convergent, linear tensor factorization algorithm. We demonstrate the efﬁcacy of our models for the task of predicting new facts across eight different knowledge graphs, achieving between 5\% and 50\% relative improvement over existing state-of-the-art knowledge graph embedding techniques. Our empirical evaluation shows that all of the tensor decomposition models perform well when the average degree of an entity in a graph is high, with constraint-based models doing better on graphs with a small number of highly similar relations and regularization-based models dominating for graphs with relations of varying degrees of similarity.},
	language = {en},
	urldate = {2019-11-14},
	journal = {arXiv:1902.03077 [cs, stat]},
	author = {Padia, Ankur and Kalpakis, Kostantinos and Ferraro, Francis and Finin, Tim},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.03077},
	keywords = {Statistics - Machine Learning, kg},
}

@article{DifferentiatingConceptsInstancesKnowledge,
	title = {Differentiating {Concepts} and {Instances} for {Knowledge} {Graph} {Embedding}},
	url = {http://arxiv.org/abs/1811.04588},
	abstract = {Concepts, which represent a group of different instances sharing common properties, are essential information in knowledge representation. Most conventional knowledge embedding methods encode both entities (concepts and instances) and relations as vectors in a low dimensional semantic space equally, ignoring the difference between concepts and instances. In this paper, we propose a novel knowledge graph embedding model named TransC by differentiating concepts and instances. Speciﬁcally, TransC encodes each concept in knowledge graph as a sphere and each instance as a vector in the same semantic space. We use the relative positions to model the relations between concepts and instances (i.e., instanceOf), and the relations between concepts and sub-concepts (i.e., subClassOf). We evaluate our model on both link prediction and triple classiﬁcation tasks on the dataset based on YAGO. Experimental results show that TransC outperforms state-of-the-art methods, and captures the semantic transitivity for instanceOf and subClassOf relation. Our codes and datasets can be obtained from https:// github.com/davidlvxin/TransC.},
	language = {en},
	urldate = {2019-11-14},
	journal = {arXiv:1811.04588 [cs]},
	author = {Lv, Xin and Hou, Lei and Li, Juanzi and Liu, Zhiyuan},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.04588},
	keywords = {kg},
}

@article{KnowledgeGraphEmbeddingIterative,
	title = {Knowledge {Graph} {Embedding} with {Iterative} {Guidance} from {Soft} {Rules}},
	abstract = {Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of current research. Combining such an embedding model with logic rules has recently attracted increasing attention. Most previous attempts made a one-time injection of logic rules, ignoring the interactive nature between embedding learning and logical inference. And they focused only on hard rules, which always hold with no exception and usually require extensive manual effort to create or validate. In this paper, we propose Rule-Guided Embedding (RUGE), a novel paradigm of KG embedding with iterative guidance from soft rules. RUGE enables an embedding model to learn simultaneously from 1) labeled triples that have been directly observed in a given KG, 2) unlabeled triples whose labels are going to be predicted iteratively, and 3) soft rules with various conﬁdence levels extracted automatically from the KG. In the learning process, RUGE iteratively queries rules to obtain soft labels for unlabeled triples, and integrates such newly labeled triples to update the embedding model. Through this iterative procedure, knowledge embodied in logic rules may be better transferred into the learned embeddings. We evaluate RUGE in link prediction on Freebase and YAGO. Experimental results show that: 1) with rule knowledge injected iteratively, RUGE achieves signiﬁcant and consistent improvements over state-of-the-art baselines; and 2) despite their uncertainties, automatically extracted soft rules are highly beneﬁcial to KG embedding, even those with moderate conﬁdence levels. The code and data used for this paper can be obtained from https://github.com/iieir-km/RUGE.},
	language = {en},
	author = {Guo, Shu and Wang, Quan and Wang, Lihong and Wang, Bin and Guo, Li},
	keywords = {iterative, kg},
	pages = {8},
}

@article{ExplainingExplanationsOverviewInterpretabilitya,
	title = {Explaining {Explanations}: {An} {Overview} of {Interpretability} of {Machine} {Learning}},
	shorttitle = {Explaining {Explanations}},
	url = {http://arxiv.org/abs/1806.00069},
	abstract = {There has recently been a surge of work in explanatory artiﬁcial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufﬁcient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artiﬁcial intelligence.},
	language = {en},
	urldate = {2019-09-26},
	journal = {arXiv:1806.00069 [cs, stat]},
	author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
	month = may,
	year = {2018},
	note = {arXiv: 1806.00069},
	keywords = {fatml, xai},
}

@article{ModelAgnosticInterpretabilityShapleyValues,
	title = {Model-{Agnostic} {Interpretability} with {Shapley} {Values}},
	abstract = {The ability to explain in understandable terms, why a machine learning model makes a certain prediction is becoming immensely important, as it ensures trust and transparency in the decision process of the model. Complex models, such as ensemble or deep learning models, are hard to interpret. Various methods have been proposed that deal with this matter. Shapley values provide accurate explanations, as they assign each feature an importance value for a particular prediction. However, the exponential complexity of their calculation is dealt efﬁciently only in decision tree-based models. Another method is surrogate models, which emulate a black-box model’s behavior and provide explanations effortlessly, since they are constructed to be interpretable. Surrogate models are model-agnostic, but they produce only approximate explanations, which cannot always be trusted. We propose a method that combines these two approaches, so that we can take advantage of the model-agnostic part of the surrogate models, as well as the explanatory power of the Shapley values. We introduce a new metric, TopjSimilarity, that measures the similitude of two given explanations, produced by Shapley values, in order to evaluate our work. Finally, we recommend ways on how this method could be improved further.},
	language = {en},
	author = {Messalas, Andreas and Kanellopoulos, Yiannis and Makris, Christos},
	keywords = {fatml, xai},
	pages = {7},
}

@article{CanTrustYouMore,
	title = {Can {I} trust you more? {Model}-{Agnostic} {Hierarchical} {Explanations}},
	shorttitle = {Can {I} trust you more?},
	url = {http://arxiv.org/abs/1812.04801},
	abstract = {Interactions such as double negation in sentences and scene interactions in images are common forms of complex dependencies captured by state-of-the-art machine learning models. We propose Mahe´, a novel approach to provide Model-agnostic hierarchical e´xplanations of how powerful machine learning models, such as deep neural networks, capture these interactions as either dependent on or free of the context of data instances. Speciﬁcally, Mahe´ provides context-dependent explanations by a novel local interpretation algorithm that effectively captures any-order interactions, and obtains context-free explanations through generalizing contextdependent interactions to explain global behaviors. Experimental results show that Mah´e obtains improved local interaction interpretations over state-of-the-art methods and successfully explains interactions that are context-free.},
	language = {en},
	urldate = {2019-09-26},
	journal = {arXiv:1812.04801 [cs, stat]},
	author = {Tsang, Michael and Sun, Youbang and Ren, Dongxu and Liu, Yan},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.04801},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{ManyShapleyValuesModel,
	title = {The many {Shapley} values for model explanation},
	url = {http://arxiv.org/abs/1908.08474},
	abstract = {The Shapley value has become a popular method to attribute the prediction of a machine-learning model on an input to its base features. The Shapley value [1] is known to be the unique method that satisfies certain desirable properties, and this motivates its use. Unfortunately, despite this uniqueness result, there are a multiplicity of Shapley values used in explaining a model’s prediction. This is because there are many ways to apply the Shapley value that differ in how they reference the model, the training data, and the explanation context.},
	language = {en},
	urldate = {2019-09-26},
	journal = {arXiv:1908.08474 [cs, econ]},
	author = {Sundararajan, Mukund and Najmi, Amir},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.08474},
	keywords = {fatml, xai},
}

@article{FairVisVisualAnalyticsDiscovering,
	title = {{FairVis}: {Visual} {Analytics} for {Discovering} {Intersectional} {Bias} in {Machine} {Learning}},
	shorttitle = {{FairVis}},
	url = {http://arxiv.org/abs/1904.05419},
	abstract = {The growing capability and accessibility of machine learning has led to its application to many real-world domains and data about people. Despite the benefits algorithmic systems may bring, models can reflect, inject, or exacerbate implicit and explicit societal biases into their outputs, disadvantaging certain demographic subgroups. Discovering which biases a machine learning model has introduced is a great challenge, due to the numerous definitions of fairness and the large number of potentially impacted subgroups. We present FairVis, a mixed-initiative visual analytics system that integrates a novel subgroup discovery technique for users to audit the fairness of machine learning models. Through FairVis, users can apply domain knowledge to generate and investigate known subgroups, and explore suggested and similar subgroups. FairVis' coordinated views enable users to explore a high-level overview of subgroup performance and subsequently drill down into detailed investigation of specific subgroups. We show how FairVis helps to discover biases in two real datasets used in predicting income and recidivism. As a visual analytics system devoted to discovering bias in machine learning, FairVis demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems.},
	language = {en},
	urldate = {2019-09-26},
	journal = {arXiv:1904.05419 [cs, stat]},
	author = {Cabrera, Ángel Alexander and Epperson, Will and Hohman, Fred and Kahng, Minsuk and Morgenstern, Jamie and Chau, Duen Horng},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.05419},
	keywords = {fair, fatml, vis},
}

@article{SemanticConceptSpacesGuided,
	title = {Semantic {Concept} {Spaces}: {Guided} {Topic} {Model} {Refinement} using {Word}-{Embedding} {Projections}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Semantic {Concept} {Spaces}},
	url = {https://ieeexplore.ieee.org/document/8807224/},
	doi = {10.1109/TVCG.2019.2934654},
	abstract = {We present a framework that allows users to incorporate the semantics of their domain knowledge for topic model reﬁnement while remaining model-agnostic. Our approach enables users to (1) understand the semantic space of the model, (2) identify regions of potential conﬂicts and problems, and (3) readjust the semantic relation of concepts based on their understanding, directly inﬂuencing the topic modeling. These tasks are supported by an interactive visual analytics workspace that uses word-embedding projections to deﬁne concept regions which can then be reﬁned. The user-reﬁned concepts are independent of a particular document collection and can be transferred to related corpora. All user interactions within the concept space directly affect the semantic relations of the underlying vector space model, which, in turn, change the topic modeling. In addition to direct manipulation, our system guides the users’ decisionmaking process through recommended interactions that point out potential improvements. This targeted reﬁnement aims at minimizing the feedback required for an efﬁcient human-in-the-loop process. We conﬁrm the improvements achieved through our approach in two user studies that show topic model quality improvements through our visual knowledge externalization and learning process.},
	language = {en},
	urldate = {2019-09-26},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {El-Assady, Mennatallah and Kehlbeck, Rebecca and Collins, Christopher and Keim, Daniel and Deussen, Oliver},
	year = {2019},
	keywords = {vis},
	pages = {1--1},
}

@article{ExplAInerVisualAnalyticsFramework,
	title = {{explAIner}: {A} {Visual} {Analytics} {Framework} for {Interactive} and {Explainable} {Machine} {Learning}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{explAIner}},
	url = {https://ieeexplore.ieee.org/document/8807299/},
	doi = {10.1109/TVCG.2019.2934629},
	abstract = {We propose a framework for interactive and explainable machine learning that enables users to (1) understand machine learning models; (2) diagnose model limitations using different explainable AI methods; as well as (3) reﬁne and optimize the models. Our framework combines an iterative XAI pipeline with eight global monitoring and steering mechanisms, including quality monitoring, provenance tracking, model comparison, and trust building. To operationalize the framework, we present explAIner, a visual analytics system for interactive and explainable machine learning that instantiates all phases of the suggested pipeline within the commonly used TensorBoard environment. We performed a user-study with nine participants across different expertise levels to examine their perception of our workﬂow and to collect suggestions to ﬁll the gap between our system and framework. The evaluation conﬁrms that our tightly integrated system leads to an informed machine learning process while disclosing opportunities for further extensions.},
	language = {en},
	urldate = {2019-09-26},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Spinner, Thilo and Schlegel, Udo and Schafer, Hanna and El-Assady, Mennatallah},
	year = {2019},
	keywords = {vis},
	pages = {1--1},
}

@article{UsingEntropyEnhancingVisualization,
	title = {Using {Entropy} in {Enhancing} {Visualization} of {High} {Dimensional} {Categorical} {Data}},
	abstract = {The discrete nature of categorical data often confounds the direct application of existing multidimensional visualization techniques. To harness such discrete nature, we propose to utilize entropy related measures to enhance the visualization of categorical data. The entropy information is employed to guide the analysis, ordering, and ﬁltering in visualizations of Scatter Plot Matrix and a variation of Parallel Sets.},
	language = {en},
	author = {Alsakran, Jamal and Zhao, Ye and Huang, Xiaoke and Midget, Alex and Yang, Jing},
	keywords = {parallel-sets, vis},
	pages = {2},
}

@article{UsingParallelSetsVisualizing,
	title = {Using {Parallel} {Sets} for {Visualizing} {Results} of {Machine} {Learning} {Based} {Plausibility} {Checks} in {Product} {Costing}},
	language = {en},
	author = {Vosough, Zana and Vasyutynskyy, Volodymyr},
	keywords = {parallel-sets, vis},
	pages = {8},
}

@article{VisualAnalysisHighDimensionalEventa,
	title = {Visual {Analysis} of {High}-{Dimensional} {Event} {Sequence} {Data} via {Dynamic} {Hierarchical} {Aggregation}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {http://arxiv.org/abs/1906.07617},
	doi = {10.1109/TVCG.2019.2934661},
	abstract = {Temporal event data are collected across a broad range of domains, and a variety of visual analytics techniques have been developed to empower analysts working with this form of data. These techniques generally display aggregate statistics computed over sets of event sequences that share common patterns. Such techniques are often hindered, however, by the high-dimensionality of many real-world event sequence datasets which can prevent effective aggregation. A common coping strategy for this challenge is to group event types together prior to visualization, as a pre-process, so that each group can be represented within an analysis as a single event type. However, computing these event groupings as a pre-process also places signiﬁcant constraints on the analysis. This paper presents a new visual analytics approach for dynamic hierarchical dimension aggregation. The approach leverages a predeﬁned hierarchy of dimensions to computationally quantify the informativeness, with respect to a measure of interest, of alternative levels of grouping within the hierarchy at runtime. This information is then interactively visualized, enabling users to dynamically explore the hierarchy to select the most appropriate level of grouping to use at any individual step within an analysis. Key contributions include an algorithm for interactively determining the most informative set of event groupings for a speciﬁc analysis context, and a scented scatter-plus-focus visualization design with an optimization-based layout algorithm that supports interactive hierarchical exploration of alternative event type groupings. We apply these techniques to high-dimensional event sequence data from the medical domain and report ﬁndings from domain expert interviews.},
	language = {en},
	urldate = {2019-11-22},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Gotz, David and Zhang, Jonathan and Wang, Wenyuan and Shrestha, Joshua and Borland, David},
	year = {2019},
	note = {arXiv: 1906.07617},
	keywords = {parallel-sets, vis},
	pages = {1--1},
}

@article{TaggleCombiningOverviewDetails,
	title = {Taggle: {Combining} {Overview} and {Details} in {Tabular} {Data} {Visualizations}},
	shorttitle = {Taggle},
	url = {http://arxiv.org/abs/1712.05944},
	abstract = {Most tabular data visualization techniques focus on overviews, yet many practical analysis tasks are concerned with investigating individual items of interest. At the same time, relating an item to the rest of a potentially large table is important. In this work we present Taggle, a tabular visualization technique for exploring and presenting large and complex tables. Taggle takes an item-centric, spreadsheet-like approach, visualizing each row in the source data individually using visual encodings for the cells. At the same time, Taggle introduces data-driven aggregation of data subsets. The aggregation strategy is complemented by interaction methods tailored to answer speciﬁc analysis questions, such as sorting based on multiple columns and rich data selection and ﬁltering capabilities. We demonstrate Taggle using a case study conducted by a domain expert on complex genomics data analysis for the purpose of drug discovery.},
	language = {en},
	urldate = {2019-11-22},
	journal = {arXiv:1712.05944 [cs]},
	author = {Furmanova, Katarina and Gratzl, Samuel and Stitz, Holger and Zichner, Thomas and Jaresova, Miroslava and Lex, Alexander and Streit, Marc},
	month = sep,
	year = {2019},
	note = {arXiv: 1712.05944},
	keywords = {parallel-sets, vis},
}

@inproceedings{IntegratingClusterFormationCluster,
	address = {Vini\&\#269;n\&\#233;, Slovak Republic},
	title = {Integrating cluster formation and cluster evaluation in interactive visual analysis},
	isbn = {978-1-4503-1978-2},
	url = {http://dl.acm.org/citation.cfm?doid=2461217.2461234},
	doi = {10.1145/2461217.2461234},
	abstract = {Cluster analysis is a popular method for data investigation where data items are structured into groups called clusters. This analysis involves two sequential steps, namely cluster formation and cluster evaluation. In this paper, we propose the tight integration of cluster formation and cluster evaluation in interactive visual analysis in order to overcome the challenges that relate to the black-box nature of clustering algorithms. We present our conceptual framework in the form of an interactive visual environment. In this realization of our framework, we build upon general concepts such as cluster comparison, clustering tendency, cluster stability and cluster coherence. Additionally, we showcase our framework on the cluster analysis of mixed lipid bilayers.},
	language = {en},
	urldate = {2019-11-22},
	booktitle = {Proceedings of the 27th {Spring} {Conference} on {Computer} {Graphics} - {SCCG} '11},
	publisher = {ACM Press},
	author = {Turkay, Cagatay and Parulek, Julius and Reuter, Nathalie and Hauser, Helwig},
	year = {2013},
	keywords = {parallel-sets, vis},
	pages = {77},
}

@article{T2KGEndtoEndSystemCreating,
	title = {{T2KG}: {An} {End}-to-{End} {System} for {Creating} {Knowledge} {Graph} from {Unstructured} {Text}},
	abstract = {Knowledge Graph (KG) plays a crucial role in many modern applications. Nevertheless, constructing KG from unstructured text is a challenging problem due to its nature. Consequently, many approaches propose to transform unstructured text to structured text in order to create a KG. Such approaches cannot yet provide reasonable results for mapping an extracted predicate to its identical predicate in another KG. Predicate mapping is an essential procedure because it can reduce the heterogeneity problem and increase searchability over a KG. In this paper, we propose T2KG system, an endto-end system with keeping such problem into consideration. In the system, a hybrid combination of a rule-based approach and a similarity-based approach is presented for mapping a predicate to its identical predicate in a KG. Based on preliminary experimental results, the hybrid approach improves the recall by 10.02\% and the F-measure by 6.56\% without reducing the precision in the predicate mapping task. Furthermore, although the KG creation is conducted in open domains, the system still achieves approximately 50\% of F-measure for generating triples in the KG creation task.},
	language = {en},
	author = {Kertkeidkachorn, Natthawut and Ichise, Ryutaro},
	keywords = {kg},
	pages = {7},
}

@article{RelationClassificationRecurrentNeural,
	title = {Relation {Classification} via {Recurrent} {Neural} {Network}},
	url = {http://arxiv.org/abs/1508.01006},
	abstract = {Deep learning has gained much success in sentence-level relation classiﬁcation. For example, convolutional neural networks (CNN) have delivered competitive performance without much effort on feature engineering as the conventional patternbased methods. Thus a lot of works have been produced based on CNN structures. However, a key issue that has not been well addressed by the CNN-based method is the lack of capability to learn temporal features, especially long-distance dependency between nominal pairs. In this paper, we propose a simple framework based on recurrent neural networks (RNN) and compare it with CNN-based model. To show the limitation of popular used SemEval-2010 Task 8 dataset, we introduce another dataset reﬁned from MIMLRE(Angeli et al., 2014). Experiments on two different datasets strongly indicates that the RNN-based model can deliver better performance on relation classiﬁcation, and it is particularly capable of learning long-distance relation patterns. This makes it suitable for real-world applications where complicated expressions are often involved.},
	language = {en},
	urldate = {2019-11-14},
	journal = {arXiv:1508.01006 [cs]},
	author = {Zhang, Dongxu and Wang, Dong},
	month = dec,
	year = {2015},
	note = {arXiv: 1508.01006},
	keywords = {kg},
}

@article{RelationClassificationConvolutionalDeep,
	title = {Relation {Classification} via {Convolutional} {Deep} {Neural} {Network}},
	abstract = {The state-of-the-art methods used for relation classiﬁcation are primarily based on statistical machine learning, and their performance strongly depends on the quality of the extracted features. The extracted features are often derived from the output of pre-existing natural language processing (NLP) systems, which leads to the propagation of the errors in the existing tools and hinders the performance of these systems. In this paper, we exploit a convolutional deep neural network (DNN) to extract lexical and sentence level features. Our method takes all of the word tokens as input without complicated pre-processing. First, the word tokens are transformed to vectors by looking up word embeddings1. Then, lexical level features are extracted according to the given nouns. Meanwhile, sentence level features are learned using a convolutional approach. These two level features are concatenated to form the ﬁnal extracted feature vector. Finally, the features are fed into a softmax classiﬁer to predict the relationship between two marked nouns. The experimental results demonstrate that our approach signiﬁcantly outperforms the state-of-the-art methods.},
	language = {en},
	author = {Zeng, Daojian and Liu, Kang and Lai, Siwei and Zhou, Guangyou and Zhao, Jun},
	keywords = {kg},
	pages = {10},
}

@article{ConstructionIndustrialKnowledgeGraph,
	title = {Construction of an {Industrial} {Knowledge} {Graph} for {Unstructured} {Chinese} {Text} {Learning}},
	volume = {9},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/9/13/2720},
	doi = {10.3390/app9132720},
	abstract = {The industrial 4.0 era is the fourth industrial revolution and is characterized by network penetration; therefore, traditional manufacturing and value creation will undergo revolutionary changes. Artiﬁcial intelligence will drive the next industrial technology revolution, and knowledge graphs comprise the main foundation of this revolution. The intellectualization of industrial information is an important part of industry 4.0, and we can efﬁciently integrate multisource heterogeneous industrial data and realize the intellectualization of information through the powerful semantic association of knowledge graphs. Knowledge graphs have been increasingly applied in the ﬁelds of deep learning, social network, intelligent control and other artiﬁcial intelligence areas. The objective of this present study is to combine traditional NLP (natural language processing) and deep learning methods to automatically extract triples from large unstructured Chinese text and construct an industrial knowledge graph in the automobile ﬁeld.},
	language = {en},
	number = {13},
	urldate = {2019-11-14},
	journal = {Applied Sciences},
	author = {Zhao, Mingxiong and Wang, Han and Guo, Jin and Liu, Di and Xie, Cheng and Liu, Qing and Cheng, Zhibo},
	month = jul,
	year = {2019},
	keywords = {kg},
	pages = {2720},
}

@inproceedings{MultilingualKnowledgeGraphEmbeddings,
	address = {Melbourne, Australia},
	title = {Multilingual {Knowledge} {Graph} {Embeddings} for {Cross}-lingual {Knowledge} {Alignment}},
	isbn = {978-0-9992411-0-3},
	url = {https://www.ijcai.org/proceedings/2017/209},
	doi = {10.24963/ijcai.2017/209},
	abstract = {Many recent works have demonstrated the beneﬁts of knowledge graph embeddings in completing monolingual knowledge graphs. Inasmuch as related knowledge bases are built in several different languages, achieving cross-lingual knowledge alignment will help people in constructing a coherent knowledge base, and assist machines in dealing with different expressions of entity relationships across diverse human languages. Unfortunately, achieving this highly desirable crosslingual alignment by human labor is very costly and error-prone. Thus, we propose MTransE, a translation-based model for multilingual knowledge graph embeddings, to provide a simple and automated solution. By encoding entities and relations of each language in a separated embedding space, MTransE provides transitions for each embedding vector to its cross-lingual counterparts in other spaces, while preserving the functionalities of monolingual embeddings. We deploy three different techniques to represent cross-lingual transitions, namely axis calibration, translation vectors, and linear transformations, and derive ﬁve variants for MTransE using different loss functions. Our models can be trained on partially aligned graphs, where just a small portion of triples are aligned with their cross-lingual counterparts. The experiments on cross-lingual entity matching and triple-wise alignment veriﬁcation show promising results, with some variants consistently outperforming others on different tasks. We also explore how MTransE preserves the key properties of its monolingual counterpart TransE.},
	language = {en},
	urldate = {2019-11-14},
	booktitle = {Proceedings of the {Twenty}-{Sixth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Chen, Muhao and Tian, Yingtao and Yang, Mohan and Zaniolo, Carlo},
	month = aug,
	year = {2017},
	keywords = {kg},
	pages = {1511--1517},
}

@article{SurveyKnowledgeReasoningBased,
	title = {A {Survey} of {Knowledge} {Reasoning} based on {KG}},
	volume = {569},
	issn = {1757-899X},
	url = {https://iopscience.iop.org/article/10.1088/1757-899X/569/5/052058},
	doi = {10.1088/1757-899X/569/5/052058},
	abstract = {Knowledge Reasoning(KR) has become the core issue in the field of Artificial Intelligence(AI) and even Natural Language Processing(NLP). KR based on Knowledge Graph(KG) is based on existing KG’s facts. It uses some inference models and algorithms to infer new unknown knowledge and targets at improving the completeness and accuracy of KG. This article presents a brief overview of KR based on KG, expounds the connotation and research scope of it, judges the two main research directions(Knowledge Graph Completion(KGC) and Question Answering over Knowledge Graph (QA-KG)) of current KR and summarizes the four main technical methods. A series of latest results of current research on KR are also listed in this paper . Finally, we look forward to the future improvement of KR.},
	language = {en},
	urldate = {2019-11-14},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Lu, Rui and Cai, Zhiping and Zhao, Shan},
	month = aug,
	year = {2019},
	keywords = {kg},
	pages = {052058},
}

@inproceedings{NovelEmbeddingModelKnowledge,
	address = {New Orleans, Louisiana},
	title = {A {Novel} {Embedding} {Model} for {Knowledge} {Base} {Completion} {Based} on {Convolutional} {Neural} {Network}},
	url = {http://aclweb.org/anthology/N18-2053},
	doi = {10.18653/v1/N18-2053},
	abstract = {In this paper, we propose a novel embedding model, named ConvKB, for knowledge base completion. Our model ConvKB advances state-of-the-art models by employing a convolutional neural network, so that it can capture global relationships and transitional characteristics between entities and relations in knowledge bases. In ConvKB, each triple (head entity, relation, tail entity) is represented as a 3column matrix where each column vector represents a triple element. This 3-column matrix is then fed to a convolution layer where multiple ﬁlters are operated on the matrix to generate different feature maps. These feature maps are then concatenated into a single feature vector representing the input triple. The feature vector is multiplied with a weight vector via a dot product to return a score. This score is then used to predict whether the triple is valid or not. Experiments show that ConvKB achieves better link prediction performance than previous state-of-the-art embedding models on two benchmark datasets WN18RR and FB15k-237.},
	language = {en},
	urldate = {2019-11-14},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of           the {Association} for {Computational} {Linguistics}: {Human} {Language}           {Technologies}, {Volume} 2 ({Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Nguyen, Dai Quoc and Nguyen, Tu Dinh and Nguyen, Dat Quoc and Phung, Dinh},
	year = {2018},
	keywords = {kg},
	pages = {327--333},
}

@article{LogicENNNeuralBasedKnowledge,
	title = {{LogicENN}: {A} {Neural} {Based} {Knowledge} {Graphs} {Embedding} {Model} with {Logical} {Rules}},
	shorttitle = {{LogicENN}},
	url = {http://arxiv.org/abs/1908.07141},
	abstract = {Knowledge graph embedding models have gained signiﬁcant attention in AI research. Recent works have shown that the inclusion of background knowledge, such as logical rules, can improve the performance of embeddings in downstream machine learning tasks. However, so far, most existing models do not allow the inclusion of rules. We address the challenge of including rules and present a new neural based embedding model (LogicENN). We prove that LogicENN can learn every ground truth of encoded rules in a knowledge graph. To the best of our knowledge, this has not been proved so far for the neural based family of embedding models. Moreover, we derive formulae for the inclusion of various rules, including (anti-)symmetric, inverse, irreﬂexive and transitive, implication, composition, equivalence and negation. Our formulation allows to avoid grounding for implication and equivalence relations. Our experiments show that LogicENN outperforms the state-of-the-art models in link prediction.},
	language = {en},
	urldate = {2019-11-14},
	journal = {arXiv:1908.07141 [cs]},
	author = {Nayyeri, Mojtaba and Xu, Chengjin and Lehmann, Jens and Yazdi, Hamed Shariat},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.07141},
	keywords = {kg},
}

@article{VisualizationTechniquesHeterogeneousMultidimensional,
	title = {Visualization techniques for heterogeneous and multidimensional simulated building performance data sets},
	abstract = {The architecture, environment and construction industry is facing, on the one hand, ambitious environmental regulations for low carbon and net zero energy buildings, and on the other hand, the emergence of new techniques such as parametric assessment and cloud computing. As a result, there is a dramatic increase of performance analysis and collected data during the building design phase. However, previous research highlighted major weaknesses of current building performance simulation -BPS- software regarding its ability to represent and explore input and output data, to interact with it, and to extract valuable data patterns and analyses. Therefore, this research aims to identify suitable visualization techniques that might increase the usability and the knowledge extracted from building simulation dataset.},
	language = {en},
	author = {Jusselme, Thomas and Tuor, Raphaël and Lalanne, Denis and Rey, Emmanuel},
	year = {2017},
	keywords = {parallel-sets, vis},
	pages = {14},
}

@article{ParallelHierarchiesVisualizationCrosstabulating,
	title = {Parallel hierarchies: {A} visualization for cross-tabulating hierarchical categories},
	volume = {76},
	issn = {00978493},
	shorttitle = {Parallel hierarchies},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0097849318301080},
	doi = {10.1016/j.cag.2018.07.009},
	abstract = {The visualization of categorical datasets is an open ﬁeld of research. While a number of standard diagramming techniques exist to investigate data distributions across multiple properties, these are rarely geared to take advantage of additional data properties – either given or derived. As a result, the data display is not as expressive as it could be when incorporating these properties, and it misses out on the potential of leveraging these properties for the data’s interactive exploration. In this paper, we present the visualization technique Parallel Hierarchies that is speciﬁcally tailored to take hierarchical categorizations into account. With Parallel Hierarchies, it is possible to individually adjust the desired level of detail for each categorical data property through drill-down and roll-up operations. This enables the analyst to selectively change levels of detail as the data analysis progresses and new questions arise. We illustrate the utility of Parallel Hierarchies with a demographic and a biological use case, and we report on a qualitative user study evaluating this visualization technique in an industrial scenario.},
	language = {en},
	urldate = {2019-11-22},
	journal = {Computers \& Graphics},
	author = {Vosough, Zana and Hogräfer, Marius and Royer, Loïc A. and Groh, Rainer and Schulz, Hans-Jörg},
	month = nov,
	year = {2018},
	keywords = {parallel-sets, vis},
	pages = {1--17},
}

@article{OutlierPreservingFocusContextVisualization,
	title = {Outlier-{Preserving} {Focus}+{Context} {Visualization} in {Parallel} {Coordinates}},
	volume = {12},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/4015444/},
	doi = {10.1109/TVCG.2006.170},
	abstract = {Focus+context visualization integrates a visually accentuated representation of selected data items in focus (more details, more opacity, etc.) with a visually deemphasized representation of the rest of the data, i.e., the context. The role of context visualization is to provide an overview of the data for improved user orientation and improved navigation. A good overview comprises the representation of both outliers and trends. Up to now, however, context visualization not really treated outliers sufﬁciently. In this paper we present a new approach to focus+context visualization in parallel coordinates which is truthful to outliers in the sense that small-scale features are detected before visualization and then treated specially during context visualization. Generally, we present a solution which enables context visualization at several levels of abstraction, both for the representation of outliers and trends. We introduce outlier detection and context generation to parallel coordinates on the basis of a binned data representation. This leads to an output-oriented visualization approach which means that only those parts of the visualization process are executed which actually affect the ﬁnal rendering. Accordingly, the performance of this solution is much more dependent on the visualization size than on the data size which makes it especially interesting for large datasets. Previous approaches are outperformed, the new solution was successfully applied to datasets with up to 3 million data records and up to 50 dimensions.},
	language = {en},
	number = {5},
	urldate = {2019-11-22},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Novotny, Matej and Hauser, Helwig},
	month = sep,
	year = {2006},
	keywords = {parallel-sets, vis},
	pages = {893--900},
}

@phdthesis{VisualClusteringParallelCoordinates,
	address = {Clear Water Bay, Kowloon, Hong Kong},
	type = {Ph.{D}.},
	title = {Visual clustering in parallel coordinates and graphs},
	url = {http://lbezone.ust.hk/bib/b1071130},
	language = {en},
	urldate = {2019-11-22},
	school = {The Hong Kong University of Science and Technology},
	author = {Zhou, Hong},
	year = {2009},
	doi = {10.14711/thesis-b1071130},
	keywords = {parallel-sets, vis},
}

@article{InteractiveVisualExplorationRefinement,
	title = {Interactive visual exploration and refinement of cluster assignments},
	volume = {18},
	issn = {1471-2105},
	url = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1813-7},
	doi = {10.1186/s12859-017-1813-7},
	abstract = {Background: With ever-increasing amounts of data produced in biology research, scientists are in need of efficient data analysis methods. Cluster analysis, combined with visualization of the results, is one such method that can be used to make sense of large data volumes. At the same time, cluster analysis is known to be imperfect and depends on the choice of algorithms, parameters, and distance measures. Most clustering algorithms don’t properly account for ambiguity in the source data, as records are often assigned to discrete clusters, even if an assignment is unclear. While there are metrics and visualization techniques that allow analysts to compare clusterings or to judge cluster quality, there is no comprehensive method that allows analysts to evaluate, compare, and refine cluster assignments based on the source data, derived scores, and contextual data.
Results: In this paper, we introduce a method that explicitly visualizes the quality of cluster assignments, allows comparisons of clustering results and enables analysts to manually curate and refine cluster assignments. Our methods are applicable to matrix data clustered with partitional, hierarchical, and fuzzy clustering algorithms. Furthermore, we enable analysts to explore clustering results in context of other data, for example, to observe whether a clustering of genomic data results in a meaningful differentiation in phenotypes.
Conclusions: Our methods are integrated into Caleydo StratomeX, a popular, web-based, disease subtype analysis tool. We show in a usage scenario that our approach can reveal ambiguities in cluster assignments and produce improved clusterings that better differentiate genotypes and phenotypes.},
	language = {en},
	number = {1},
	urldate = {2019-11-22},
	journal = {BMC Bioinformatics},
	author = {Kern, Michael and Lex, Alexander and Gehlenborg, Nils and Johnson, Chris R.},
	month = dec,
	year = {2017},
	keywords = {parallel-sets, vis},
	pages = {406},
}

@inproceedings{ExploringProportionsComparativeVisualization,
	address = {Providence, RI, USA},
	title = {Exploring proportions: {Comparative} visualization of categorical data},
	isbn = {978-1-4673-0014-8 978-1-4673-0015-5},
	shorttitle = {Exploring proportions},
	url = {http://ieeexplore.ieee.org/document/6102481/},
	doi = {10.1109/VAST.2011.6102481},
	abstract = {This poster describes an approach to facilitate comparisons in multi-dimensional categorical data. The key idea is to represent over- or under-proportional relationships explicitly. On an overview level, the visualization of various measures conveys pair-wise relationships between categorical dimensions. For more details, interaction supports to relate a single category to all categories of multiple dimensions. We discuss methods for representing relationships and visualization-driven strategies for ordering dimensions and categories, and we illustrate the approach by means of data from a social survey.},
	language = {en},
	urldate = {2019-11-22},
	booktitle = {2011 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Piringer, Harald and Buchetics, Matthias},
	month = oct,
	year = {2011},
	keywords = {parallel-sets, vis},
	pages = {295--296},
}

@article{AssociationRuleBasedApproacha,
	title = {An association rule based approach to reducing visual clutter in parallel sets},
	volume = {3},
	issn = {2468502X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2468502X1930021X},
	doi = {10.1016/j.visinf.2019.03.006},
	abstract = {Although Parallel Sets, a popular categorical data visualization technique, intuitively reveals the frequency based relationships in details, a high-dimensional categorical dataset brings a cluttered visual display that seriously obscures the relationship explorations. Association rule mining is a popular approach to discovering relationships among categorical variables. It could complement Parallel Sets to group ribbons in a meaningful way. However, it is di cult to understand a larger number of rules discovered from a high-dimensional categorical dataset. In this paper, we integrate the two approaches into a visual analytics system for exploring high-dimensional categorical data with dichotomous outcome. The system not only helps users interpret association rules intuitively, but also provides an e↵ective dimension and category reduction approach towards a less clustered and more organized visualization. The e↵ectiveness and e ciency of our approach are illustrated by a set of user studies and experiments with benchmark datasets.},
	language = {en},
	number = {1},
	urldate = {2019-11-22},
	journal = {Visual Informatics},
	author = {Zhang, Chong and Chen, Yang and Yang, Jing and Yin, Zhengcong},
	month = mar,
	year = {2019},
	keywords = {parallel-sets, vis},
	pages = {48--57},
}

@article{GraphsAreNotEnough,
	title = {Graphs {Are} {Not} {Enough}: {Using} {Interactive} {Visual} {Analytics} in {Storage} {Research}},
	abstract = {Storage researchers have always been interested in understanding the complex behavior of storage systems with the help of statistics, machine learning, and simple visualization techniques. However, when a system’s behavior is affected by hundreds or even thousands of factors, existing approaches break down. Results are often difﬁcult to interpret, and it can be challenging for humans to apply domain knowledge to a complex system. We propose to enhance storage system analysis by applying interactive visual analytics, which can address the aforementioned limitations. We have devised a suitable Interactive Conﬁguration Explorer (ICE), and conducted several case studies on a typical storage system, to demonstrate its beneﬁts for storage system researchers and designers. We found that ICE makes it easy to explore a large parameter space, identify critical parameters, and quickly zero in on optimal parameter settings.},
	language = {en},
	author = {Cao, Zhen and Kuenning, Geoff and Mueller, Klaus and Tyagi, Anjul and Zadok, Erez},
	keywords = {parallel-sets, vis},
	pages = {8},
}

@article{StateoftheArtSetVisualizationStateoftheArt,
	title = {The {State}-of-the-{Art} of {Set} {Visualization}: {The} {State}-of-the-{Art} of {Set} {Visualization}},
	volume = {35},
	issn = {01677055},
	shorttitle = {The {State}-of-the-{Art} of {Set} {Visualization}},
	url = {http://doi.wiley.com/10.1111/cgf.12722},
	doi = {10.1111/cgf.12722},
	abstract = {Sets comprise a generic data model that has been used in a variety of data analysis problems. Such problems involve analysing and visualizing set relations between multiple sets deﬁned over the same collection of elements. However, visualizing sets is a non-trivial problem due to the large number of possible relations between them. We provide a systematic overview of state-of-the-art techniques for visualizing different kinds of set relations. We classify these techniques into six main categories according to the visual representations they use and the tasks they support. We compare the categories to provide guidance for choosing an appropriate technique for a given problem. Finally, we identify challenges in this area that need further research and propose possible directions to address these challenges. Further resources on set visualization are available at http://www.setviz.net.},
	language = {en},
	number = {1},
	urldate = {2019-11-22},
	journal = {Computer Graphics Forum},
	author = {Alsallakh, Bilal and Micallef, Luana and Aigner, Wolfgang and Hauser, Helwig and Miksch, Silvia and Rodgers, Peter},
	month = feb,
	year = {2016},
	keywords = {parallel-sets, vis},
	pages = {234--260},
}

@article{VisualinteractiveExplorationInterestingMultivariate,
	title = {Visual-interactive {Exploration} of {Interesting} {Multivariate} {Relations} in {Mixed} {Research} {Data} {Sets}: {Visual}-interactive {Exploration} of {Interesting} {Multivariate} {Relations} in {Mixed} {Research} {Data} {Sets}},
	volume = {33},
	issn = {01677055},
	shorttitle = {Visual-interactive {Exploration} of {Interesting} {Multivariate} {Relations} in {Mixed} {Research} {Data} {Sets}},
	url = {http://doi.wiley.com/10.1111/cgf.12385},
	doi = {10.1111/cgf.12385},
	abstract = {The analysis of research data plays a key role in data-driven areas of science. Varieties of mixed research data sets exist and scientists aim to derive or validate hypotheses to ﬁnd undiscovered knowledge. Many analysis techniques identify relations of an entire dataset only. This may level the characteristic behavior of different subgroups in the data. Like automatic subspace clustering, we aim at identifying interesting subgroups and attribute sets. We present a visual-interactive system that supports scientists to explore interesting relations between aggregated bins of multivariate attributes in mixed data sets. The abstraction of data to bins enables the application of statistical dependency tests as the measure of interestingness. An overview matrix view shows all attributes, ranked with respect to the interestingness of bins. Complementary, a node-link view reveals multivariate bin relations by positioning dependent bins close to each other. The system supports information drill-down based on both expert knowledge and algorithmic support. Finally, visual-interactive subset clustering assigns multivariate bin relations to groups. A list-based cluster result representation enables the scientist to communicate multivariate ﬁndings at a glance. We demonstrate the applicability of the system with two case studies from the earth observation domain and the prostate cancer research domain. In both cases, the system enabled us to identify the most interesting multivariate bin relations, to validate already published results, and, moreover, to discover unexpected relations.},
	language = {en},
	number = {3},
	urldate = {2019-11-22},
	journal = {Computer Graphics Forum},
	author = {Bernard, Jürgen and Steiger, Martin and Widmer, Sven and Lücke-Tieke, Hendrik and May, Thorsten and Kohlhammer, Jörn},
	month = jun,
	year = {2014},
	keywords = {parallel-sets, vis},
	pages = {291--300},
}

@article{EnablingHierarchicalExplorationLargeScale,
	title = {Enabling {Hierarchical} {Exploration} for {Large}-{Scale} {Multidimensional} {Data} with {Abstract} {Parallel} {Coordinates}},
	abstract = {As data collection grows more common in various domains, there is a call for adapted or newer methods of visualization to tackle magnitudes exceeding the number of available pixels on screens and challenging interactivity. Exploratory visualization of large data present two major challenges: perceptual scalability and processing scalability. The first is concerned with overcoming the fundamental limitation of screens and human perception. The second deals with efficiently processing large volumes of data to achieve responsive interactions. Multiscale visualizations are an effective technique for solving the first challenge that builds on several levels of data abstraction to provide the user with an initial overview and subsequent incremental detail. The focus of this paper is on multidimensional data, a ubiquitous form of data among large-scale data sets, and parallel coordinates, a representation largely used for this type of data. For this representation, defining abstractions and interactively generating levels is not straightforward. Building upon several previous aggregated parallel coordinates representations, we propose a unifying and thinking model for conceiving and describing multiscale parallel coordinates and their interactions. Using this formalism, we present a focus+context representation which bounds the number of visual items with a fixed resolution parameter while supporting exploration up to the item-level. Processing scalability is addressed by carrying out computation in a distributed manner on a remote data-intensive infrastructure. Bounding the visual items ensures perceptual scalability but also bounds the data transfer between this infrastructure and the rendering client.},
	language = {en},
	author = {Richer, Gaëlle and Sansen, Joris and Lalanne, Frédéric and Auber, David and Bourqui, Romain},
	keywords = {parallel-sets, vis},
	pages = {9},
}

@inproceedings{AggregatedParallelCoordinatesIntegrating,
	address = {Graz, Austria},
	title = {Aggregated parallel coordinates: integrating hierarchical dimensions into parallel coordinates visualisations},
	isbn = {978-1-4503-3721-2},
	shorttitle = {Aggregated parallel coordinates},
	url = {http://dl.acm.org/citation.cfm?doid=2809563.2809588},
	doi = {10.1145/2809563.2809588},
	abstract = {Aggregated Parallel Coordinates (APC) are an extension of standard parallel coordinates, which supports the visualisation and exploration of hierarchies within numerical dimensions. Such datasets can occur when data is available at several granularities and these can be grouped or aggregated in some way (mean, sum, max) to form higher levels of abstraction. While existing parallel coordinates techniques can be used to visualise individual dimensions of such data, they have no provision for interactively expanding and collapsing such hierarchically aggregated dimensions.},
	language = {en},
	urldate = {2019-11-22},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Knowledge} {Technologies} and {Data}-driven {Business} - i-{KNOW} '15},
	publisher = {ACM Press},
	author = {Andrews, Keith and Osmić, Majda and Schagerl, Gerhard},
	year = {2015},
	keywords = {parallel-sets, vis},
	pages = {1--4},
}

@article{ExplainableArtificialIntelligenceXAIb,
	title = {Explainable artificial intelligence ({XAI}), the goodness criteria and the grasp-ability test},
	url = {http://arxiv.org/abs/1810.09598},
	abstract = {This paper introduces the “grasp-ability test” as a “goodness” criteria by which to compare which explanation is more or less meaningful than others for users to understand the automated algorithmic data processing.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1810.09598 [cs]},
	author = {Kim, Tae Wan},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.09598},
	keywords = {fatml, xai},
}

@article{GeneratingCounterfactualExplanationsNatural,
	title = {Generating {Counterfactual} {Explanations} with {Natural} {Language}},
	url = {http://arxiv.org/abs/1806.09809},
	abstract = {Natural language explanations of deep neural network decisions provide an intuitive way for a AI agent to articulate a reasoning process. Current textual explanations learn to discuss class discriminative features in an image. However, it is also helpful to understand which attributes might change a classiﬁcation decision if present in an image (e.g., “This is not a Scarlet Tanager because it does not have black wings.”) We call such textual explanations counterfactual explanations, and propose an intuitive method to generate counterfactual explanations by inspecting which evidence in an input is missing, but might contribute to a different classiﬁcation decision if present in the image. To demonstrate our method we consider a ﬁne-grained image classiﬁcation task in which we take as input an image and a counterfactual class and output text which explains why the image does not belong to a counterfactual class. We then analyze our generated counterfactual explanations both qualitatively and quantitatively using proposed automatic metrics.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1806.09809 [cs]},
	author = {Hendricks, Lisa Anne and Hu, Ronghang and Darrell, Trevor and Akata, Zeynep},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.09809},
	keywords = {fatml, xai},
}

@article{ContextStyleExplanationRecommender,
	title = {Context {Style} {Explanation} for {Recommender} {Systems}},
	volume = {27},
	issn = {1882-6652},
	url = {https://www.jstage.jst.go.jp/article/ipsjjip/27/0/27_720/_article},
	doi = {10.2197/ipsjjip.27.720},
	abstract = {Recommender systems support users by helping them choose items, and explanations for the recommendations further enhance such support. Previous explanation styles were based on information about users and items, such as the demographics of users and contents of items. Contexts, such as “usage scenarios” and “accompanying persons,” have not been used for explanations, although they inﬂuence user’s choice of items. In this paper, we propose a context style explanation method, presenting contexts suitable for consuming the recommended items. The expected impacts of context style explanations are as follows: 1) persuasiveness: recognition of a suitable context for usage motivates users to consume items, and 2) usefulness: envisioning a context helps users to make the right choices because the values of items depend on contexts. We evaluate the persuasiveness and usefulness of the context-style explanation by a crowdsourcing-based user study in a restaurant recommendation setting. The context style explanation is compared to the demographic and content style explanations. We also combine the context style and other explanation styles, conﬁrming that hybrid styles improve the persuasiveness and usefulness of the explanation. Further, we investigate the personal preferences for explanation styles and reveal how gender and age relate to such preferences. The contributions of this paper are: the proposal of the novel context style explanation method, the demonstration of the persuasiveness and usefulness of the proposed method by a user study, and the ﬁndings of gender- and age-dependence of explanation style preferences.},
	language = {en},
	number = {0},
	urldate = {2019-12-13},
	journal = {Journal of Information Processing},
	author = {Sato, Masahiro and Nagatani, Koki and Sonoda, Takashi and Zhang, Qian and Ohkuma, Tomoko},
	year = {2019},
	keywords = {fatml, xai},
	pages = {720--729},
}

@article{WhatMakesGoodExplanation,
	title = {What makes a good explanation? {Cognitive} dimensions of explaining intelligent machines},
	language = {en},
	author = {Confalonieri, Roberto and Besold, Tarek R and Weyde, Tillman and Creel, Kathleen and Lombrozo, Tania and Mueller, Shane and Shafto, Patrick},
	keywords = {fatml, xai},
	pages = {3},
}

@article{EmergenceChildrenCausalExplanations,
	title = {The {Emergence} of {Children}'s {Causal} {Explanations} and {Theories}: {Evidence} {From} {Everyday} {Conversation}},
	language = {en},
	author = {Hickling, Anne K and Wellman, Henry M},
	keywords = {fatml, xai},
	pages = {16},
}

@article{ReasoningExplanationbasedDecisionMaking,
	title = {Reasoning in explanation-based decision making},
	volume = {49},
	issn = {00100277},
	url = {https://linkinghub.elsevier.com/retrieve/pii/001002779390038W},
	doi = {10.1016/0010-0277(93)90038-W},
	abstract = {A general theory of explanation-based decision making is outlined and the multiple roles of inference processes in the theory are indicated. A typology of formal and informal inference forms, originally proposed by Collins (1978a, 1978b), is introduced as an appropriate framework to represent inferences that occur in the overarching explanation-based process. Results from the analysis of verbal reports of decision processes are presented to demonstrate the centrality and systematic character of reasoning in a representative legal decision-making task.},
	language = {en},
	number = {1-2},
	urldate = {2019-12-13},
	journal = {Cognition},
	author = {Pennington, N},
	month = nov,
	year = {1993},
	keywords = {fatml, xai},
	pages = {123--163},
}

@article{InteractiveContextAwareAnomalyDetection,
	title = {Interactive {Context}-{Aware} {Anomaly} {Detection} {Guided} by {User} {Feedback}},
	volume = {49},
	issn = {2168-2291, 2168-2305},
	url = {https://ieeexplore.ieee.org/document/8760260/},
	doi = {10.1109/THMS.2019.2925195},
	abstract = {Automatic anomaly detection techniques have been extensively used to support decision making in abnormal situations. However, existing approaches are limited in their capacity of effectively identifying anomalies due to the complexity of the real-world environment, the uncertainty of the data input, and the unavailability of ground truth. In this paper, we propose an interactive context-aware anomaly detection algorithm framework that incorporates human judgment in searching for anomalous regions within a large geographic environment. In speciﬁc, our framework, 1) estimates a focal region and detect anomalous situations in real time, through which the user can observe and analyze suspicious entities, 2) leverages user feedback to reﬁne results and guide further analysis, and 3) tolerates potential fault feedback provided by the users and resignal dubious anomalous points. Based on the framework, we propose two algorithm implementations, respectively, employ Bayes’ theorem and metric learning. We demonstrate the effectiveness of the proposed framework and corresponding implementations through two controlled user studies and a case study with a domain expert.},
	language = {en},
	number = {6},
	urldate = {2019-12-13},
	journal = {IEEE Transactions on Human-Machine Systems},
	author = {Shi, Yang and Xu, Maoran and Zhao, Rongwen and Fu, Hao and Wu, Tongshuang and Cao, Nan},
	month = dec,
	year = {2019},
	keywords = {vis},
	pages = {550--559},
}

@article{TaskOrientedOptimalSequencingVisualization,
	title = {Task-{Oriented} {Optimal} {Sequencing} of {Visualization} {Charts}},
	url = {http://arxiv.org/abs/1908.02502},
	abstract = {A chart sequence is used to describe a series of visualization charts generated in the exploratory analysis by data analysts. It provides information details in each chart as well as a logical relationship among charts. While existing research targets on generating chart sequences that match human’s perceptions, little attention has been paid to formulate task-oriented connections between charts in a chart design space. We present a novel chart sequencing method based on reinforcement learning to capture the connections between charts in the context of three major analysis tasks, including correlation analysis, anomaly detection, and cluster analysis. The proposed method formulates a chart sequencing procedure as an optimization problem, which seeks an optimal policy to sequencing charts for the speciﬁc analysis task. In our method, a novel reward function is introduced, which takes both the analysis task and the factor of human cognition into consideration. We conducted one case study and two user studies to evaluate the effectiveness of our method under the application scenarios of visualization demonstration, sequencing charts for reasoning analysis results, and making a chart design choice. The study results showed the power of our method.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1908.02502 [cs]},
	author = {Shi, Danqing and Shi, Yang and Xu, Xinyue and Chen, Nan and Fu, Siwei and Wu, Hongjin and Cao, Nan},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.02502},
	keywords = {vis},
}

@article{InterpretabilityFeatureAttributionQuantitative,
	title = {Interpretability {Beyond} {Feature} {Attribution}: {Quantitative} {Testing} with {Concept} {Activation} {Vectors} ({TCAV})},
	shorttitle = {Interpretability {Beyond} {Feature} {Attribution}},
	url = {http://arxiv.org/abs/1711.11279},
	abstract = {The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classiﬁers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net’s internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-deﬁned concept is important to a classiﬁcation result–for example, how sensitive a prediction of zebra is to the presence of stripes. Using the domain of image classiﬁcation as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classiﬁcation network as well as a medical application.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1711.11279 [stat]},
	author = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and Sayres, Rory},
	month = jun,
	year = {2018},
	note = {arXiv: 1711.11279},
	keywords = {Statistics - Machine Learning, comps-dm, fatml, xai},
}

@article{RecentResearchAdvancesInteractivea,
	title = {Recent {Research} {Advances} on {Interactive} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1811.04548},
	abstract = {Interactive Machine Learning (IML) is an iterative learning process that tightly couples a human with a machine learner, which is widely used by researchers and practitioners to effectively solve a wide variety of real-world application problems. Although recent years have witnessed the proliferation of IML in the ﬁeld of visual analytics, most recent surveys either focus on a speciﬁc area of IML or aim to summarize a visualization ﬁeld that is too generic for IML. In this paper, we systematically review the recent literature on IML and classify them into a task-oriented taxonomy built by us. We conclude the survey with a discussion of open challenges and research opportunities that we believe are inspiring for future work in IML.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1811.04548 [cs, stat]},
	author = {Jiang, Liu and Liu, Shixia and Chen, Changjian},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.04548},
	keywords = {vis},
}

@article{SupportingIterativeCohortConstruction,
	title = {Supporting {Iterative} {Cohort} {Construction} with {Visual} {Temporal} {Queries}},
	volume = {22},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/7192665/},
	doi = {10.1109/TVCG.2015.2467622},
	abstract = {Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difﬁcult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to ﬁll this gap, we designed COQUITO, a visual interface that assists users deﬁning cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.},
	language = {en},
	number = {1},
	urldate = {2019-12-06},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Krause, Josua and Perer, Adam and Stavropoulos, Harry},
	month = jan,
	year = {2016},
	keywords = {clustering, vis},
	pages = {91--100},
}

@article{C2ACrowdConsensusAnalyticsa,
	title = {{C2A}: {Crowd} {Consensus} {Analytics} for {Virtual} {Colonoscopy}},
	shorttitle = {{C2A}},
	url = {http://arxiv.org/abs/1810.09012},
	doi = {10.1109/VAST.2016.7883508},
	abstract = {We present a medical crowdsourcing visual analytics platform called C\{\${\textasciicircum}2\$\}A to visualize, classify and filter crowdsourced clinical data. More specifically, C\${\textasciicircum}2\$A is used to build consensus on a clinical diagnosis by visualizing crowd responses and filtering out anomalous activity. Crowdsourcing medical applications have recently shown promise where the non-expert users (the crowd) were able to achieve accuracy similar to the medical experts. This has the potential to reduce interpretation/reading time and possibly improve accuracy by building a consensus on the findings beforehand and letting the medical experts make the final diagnosis. In this paper, we focus on a virtual colonoscopy (VC) application with the clinical technicians as our target users, and the radiologists acting as consultants and classifying segments as benign or malignant. In particular, C\${\textasciicircum}2\$A is used to analyze and explore crowd responses on video segments, created from fly-throughs in the virtual colon. C\${\textasciicircum}2\$A provides several interactive visualization components to build crowd consensus on video segments, to detect anomalies in the crowd data and in the VC video segments, and finally, to improve the non-expert user's work quality and performance by A/B testing for the optimal crowdsourcing platform and application-specific parameters. Case studies and domain experts feedback demonstrate the effectiveness of our framework in improving workers' output quality, the potential to reduce the radiologists' interpretation time, and hence, the potential to improve the traditional clinical workflow by marking the majority of the video segments as benign based on the crowd consensus.},
	language = {en},
	urldate = {2019-12-04},
	journal = {2016 IEEE Conference on Visual Analytics Science and Technology (VAST)},
	author = {Park, Ji Hwan and Nadeem, Saad and Mirhosseini, Seyedkoosha and Kaufman, Arie},
	month = oct,
	year = {2016},
	note = {arXiv: 1810.09012},
	pages = {21--30},
}

@inproceedings{ExplainabilityScenariosScenariobasedXAI,
	address = {Marina del Ray, California},
	title = {Explainability scenarios: towards scenario-based {XAI} design},
	isbn = {978-1-4503-6272-6},
	shorttitle = {Explainability scenarios},
	url = {http://dl.acm.org/citation.cfm?doid=3301275.3302317},
	doi = {10.1145/3301275.3302317},
	abstract = {Integral to the adoption and uptake of AI systems in real-world settings is the ability for people to make sense of and evaluate such systems, a growing area of development and design efforts known as XAI (Explainable AI). Recent work has advanced the state of the art, yet a key challenge remains in understanding unique requirements that might arise when XAI systems are deployed into complex settings of use. In helping envision such requirements, this paper turns to scenario-based design, a method that anticipates and leverages scenarios of possible use early on in system development. To demonstrate the value of the scenario-based design method to XAI design, this paper presents a case study of aging-in-place monitoring. Introducing the concept of “explainability scenarios” as resources in XAI design, this paper sets out a forward-facing agenda for further attention to the emergent requirements of explainability-in-use.},
	language = {en},
	urldate = {2019-12-13},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '19},
	publisher = {ACM Press},
	author = {Wolf, Christine T.},
	year = {2019},
	keywords = {fatml, xai},
	pages = {252--257},
}

@article{ExplanatoryPreferencesShapeLearning,
	title = {Explanatory {Preferences} {Shape} {Learning} and {Inference}},
	volume = {20},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S136466131630105X},
	doi = {10.1016/j.tics.2016.08.001},
	language = {en},
	number = {10},
	urldate = {2019-12-13},
	journal = {Trends in Cognitive Sciences},
	author = {Lombrozo, Tania},
	month = oct,
	year = {2016},
	keywords = {fatml, xai},
	pages = {748--759},
}

@article{WhyDidYouThat,
	title = {``{Why} {Did} {You} {Do} {That}?'' {Explainable} {Intelligent} {Robots}},
	abstract = {As autonomous intelligent systems become more widespread, society is beginning to ask: “What are the machines up to?”. Various forms of artiﬁcial intelligence control our latest cars, load balance components of our power grids, dictate much of the movement in our stock markets and help doctors diagnose and treat our ailments. As they become increasingly able to learn and model more complex phenomena, so the ability of human users to understand the reasoning behind their decisions often decreases. It becomes very difﬁcult to ensure that the robot will perform properly and that it is possible to correct errors.},
	language = {en},
	author = {Sheh, Raymond},
	keywords = {fatml, xai},
	pages = {7},
}

@article{ExplainableArtificialIntelligenceXAIa,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, {Taxonomies}, {Opportunities} and {Challenges} toward {Responsible} {AI}},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {http://arxiv.org/abs/1910.10045},
	abstract = {In the last few years, Artiﬁcial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the ﬁeld. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) ﬁeld, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the ﬁeld of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to deﬁne explainability in Machine Learning, establishing a novel deﬁnition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this deﬁnition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artiﬁcial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the ﬁeld of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the beneﬁts of AI in their activity sectors, without any prior bias for its lack of interpretability.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1910.10045 [cs]},
	author = {Arrieta, Alejandro Barredo and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and García, Salvador and Gil-López, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.10045},
	keywords = {fatml, xai},
}

@article{TrepanReloadedKnowledgedrivenApproach,
	title = {Trepan {Reloaded}: {A} {Knowledge}-driven {Approach} to {Explaining} {Artificial} {Neural} {Networks}},
	shorttitle = {Trepan {Reloaded}},
	url = {http://arxiv.org/abs/1906.08362},
	abstract = {Explainability in Artiﬁcial Intelligence has been revived as a topic of active research by the need of conveying safety and trust to users in the ‘how’ and ‘why’ of automated decision-making. Whilst a plethora of approaches have been developed for post-hoc explainability, only a few focus on how to use domain knowledge, and how this inﬂuences the understandability of an explanation from the users’ perspective. In this paper we show how ontologies help the understandability of interpretable machine learning models, such as decision trees. In particular, we build on Trepan, an algorithm that explains artiﬁcial neural networks by means of decision trees, and we extend it to include ontologies modeling domain knowledge in the process of generating explanations. We present the results of a user study that measures the understandability of decision trees in domains where explanations are critical, namely, in ﬁnance and medicine. Our study shows that decision trees taking into account domain knowledge during generation are more understandable than those generated without the use of ontologies.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1906.08362 [cs]},
	author = {Confalonieri, Roberto and Weyde, Tillman and Besold, Tarek R. and Martín, Fermín Moscoso del Prado},
	month = nov,
	year = {2019},
	note = {arXiv: 1906.08362},
	keywords = {fatml, xai},
}

@article{FlexiblyFairRepresentationLearninga,
	title = {Flexibly {Fair} {Representation} {Learning} by {Disentanglement}},
	url = {http://arxiv.org/abs/1906.02589},
	abstract = {We consider the problem of learning representations that achieve group and subgroup fairness with respect to multiple sensitive attributes. Taking inspiration from the disentangled representation learning literature, we propose an algorithm for learning compact representations of datasets that are useful for reconstruction and prediction, but are also ﬂexibly fair, meaning they can be easily modiﬁed at test time to achieve subgroup demographic parity with respect to multiple sensitive attributes and their conjunctions. We show empirically that the resulting encoder—which does not require the sensitive attributes for inference—enables the adaptation of a single representation to a variety of fair classiﬁcation tasks with new target labels and subgroup deﬁnitions.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1906.02589 [cs, stat]},
	author = {Creager, Elliot and Madras, David and Jacobsen, Jörn-Henrik and Weis, Marissa A. and Swersky, Kevin and Pitassi, Toniann and Zemel, Richard},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.02589},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{EuropeanUnionRegulationsAlgorithmic,
	title = {European {Union} {Regulations} on {Algorithmic} {Decision}-{Making} and a “{Right} to {Explanation}”},
	volume = {38},
	issn = {2371-9621, 0738-4602},
	url = {https://www.aaai.org/ojs/index.php/aimagazine/article/view/2741},
	doi = {10.1609/aimag.v38i3.2741},
	abstract = {We summarize the potential impact that the European Union’s new General Data Protection Regulation will have on the routine use of machine learning algorithms. Slated to take effect as law across the EU in 2018, it will restrict automated individual decision-making (that is, algorithms that make decisions based on user-level predictors) which “significantly affect” users. The law will also effectively create a “right to explanation,” whereby a user can ask for an explanation of an algorithmic decision that was made about them. We argue that while this law will pose large challenges for industry, it highlights opportunities for computer scientists to take the lead in designing algorithms and evaluation frameworks which avoid discrimination and enable explanation.},
	language = {en},
	number = {3},
	urldate = {2019-12-13},
	journal = {AI Magazine},
	author = {Goodman, Bryce and Flaxman, Seth},
	month = oct,
	year = {2017},
	keywords = {fatml, xai},
	pages = {50--57},
}

@article{EvaluatingExplanationGroundTruth,
	title = {Evaluating {Explanation} {Without} {Ground} {Truth} in {Interpretable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1907.06831},
	abstract = {Interpretable Machine Learning (IML) has become increasingly important in many real-world applications, such as autonomous cars and medical diagnosis, where explanations are signiﬁcantly preferred to help people better understand how machine learning systems work and further enhance their trust towards systems. However, due to the diversiﬁed scenarios and subjective nature of explanations, we rarely have the ground truth for benchmark evaluation in IML on the quality of generated explanations. Having a sense of explanation quality not only matters for assessing system boundaries, but also helps to realize the true beneﬁts to human users in practical settings. To benchmark the evaluation in IML, in this article, we rigorously deﬁne the problem of evaluating explanations, and systematically review the existing eﬀorts from state-of-the-arts. Speciﬁcally, we summarize three general aspects of explanation (i.e., generalizability, ﬁdelity and persuasibility) with formal deﬁnitions, and respectively review the representative methodologies for each of them under diﬀerent tasks. Further, a uniﬁed evaluation framework is designed according to the hierarchical needs from developers and end-users, which could be easily adopted for diﬀerent scenarios in practice. In the end, open problems are discussed, and several limitations of current evaluation techniques are raised for future explorations.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1907.06831 [cs, stat]},
	author = {Yang, Fan and Du, Mengnan and Hu, Xia},
	month = aug,
	year = {2019},
	note = {arXiv: 1907.06831},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{DLIMEDeterministicLocalInterpretable,
	title = {{DLIME}: {A} {Deterministic} {Local} {Interpretable} {Model}-{Agnostic} {Explanations} {Approach} for {Computer}-{Aided} {Diagnosis} {Systems}},
	shorttitle = {{DLIME}},
	url = {http://arxiv.org/abs/1906.10263},
	abstract = {Local Interpretable Model-Agnostic Explanations (LIME) is a popular technique used to increase the interpretability and explainability of black box Machine Learning (ML) algorithms. LIME typically generates an explanation for a single prediction by any ML model by learning a simpler interpretable model (e.g. linear classifier) around the prediction through generating simulated data around the instance by random perturbation, and obtaining feature importance through applying some form of feature selection. While LIME and similar local algorithms have gained popularity due to their simplicity, the random perturbation and feature selection methods result in instability in the generated explanations, where for the same prediction, different explanations can be generated. This is a critical issue that can prevent deployment of LIME in a Computer-Aided Diagnosis (CAD) system, where stability is of utmost importance to earn the trust of medical professionals. In this paper, we propose a deterministic version of LIME. Instead of random perturbation, we utilize agglomerative Hierarchical Clustering (HC) to group the training data together and K-Nearest Neighbour (KNN) to select the relevant cluster of the new instance that is being explained. After finding the relevant cluster, a linear model is trained over the selected cluster to generate the explanations. Experimental results on three different medical datasets show the superiority for Deterministic Local Interpretable Model-Agnostic Explanations (DLIME), where we quantitatively determine the stability of DLIME compared to LIME utilizing the Jaccard similarity among multiple generated explanations.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1906.10263 [cs, stat]},
	author = {Zafar, Muhammad Rehman and Khan, Naimul Mefraz},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.10263},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{ConceptTreeHighLevelRepresentation,
	title = {Concept {Tree}: {High}-{Level} {Representation} of {Variables} for {More} {Interpretable} {Surrogate} {Decision} {Trees}},
	shorttitle = {Concept {Tree}},
	url = {http://arxiv.org/abs/1906.01297},
	abstract = {Interpretable surrogates of black-box predictors trained on high-dimensional tabular datasets can struggle to generate comprehensible explanations in the presence of correlated variables. We propose a model-agnostic interpretable surrogate that provides global and local explanations of black-box classiﬁers to address this issue. We introduce the idea of concepts as intuitive groupings of variables that are either deﬁned by a domain expert or automatically discovered using correlation coefﬁcients. Concepts are embedded in a surrogate decision tree to enhance its comprehensibility. First experiments on FRED-MD, a macroeconomic database with 134 variables, show improvement in humaninterpretability while accuracy and ﬁdelity of the surrogate model are preserved.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1906.01297 [cs, stat]},
	author = {Renard, Xavier and Woloszko, Nicolas and Aigrain, Jonathan and Detyniecki, Marcin},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.01297},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{PreferenceInformedFairness,
	title = {Preference-{Informed} {Fairness}},
	url = {http://arxiv.org/abs/1904.01793},
	abstract = {In this work, we study notions of fairness in decision-making systems when individuals have diverse preferences over the possible outcomes of the decisions. Our starting point is the seminal work of Dwork et al. [ITCS 2012] which introduced a notion of individual fairness (IF): given a task-speciﬁc similarity metric, every pair of individuals who are similarly qualiﬁed according to the metric should receive similar outcomes. We show that when individuals have diverse preferences over outcomes, requiring IF may unintentionally lead to less-preferred outcomes for the very individuals that IF aims to protect (e.g. a protected minority group). A natural alternative to IF is the classic notion of fair division, envy-freeness (EF): no individual should prefer another individual’s outcome over their own. Although EF allows for solutions where all individuals receive a highly-preferred outcome, EF may also be overly-restrictive for the decision-maker. For instance, if many individuals agree on the best outcome, then if any individual receives this outcome, they all must receive it, regardless of each individual’s underlying qualiﬁcations for the outcome.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1904.01793 [cs, stat]},
	author = {Kim, Michael P. and Korolova, Aleksandra and Rothblum, Guy N. and Yona, Gal},
	month = sep,
	year = {2019},
	note = {arXiv: 1904.01793},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@article{AreWeWhatWe,
	title = {Are we what we do? {Exploring} group behaviour through user-defined event-sequence similarity},
	volume = {13},
	issn = {1473-8716, 1473-8724},
	shorttitle = {Are we what we do?},
	url = {http://journals.sagepub.com/doi/10.1177/1473871613477852},
	doi = {10.1177/1473871613477852},
	abstract = {The study of human activity in space and time is an inherent part of human geography. In order to perform such studies, data on the time use of individuals, in terms of sequence and timing of performed activities, are collected and analysed. A common assumption when analysing individuals’ time use is that groups that exhibit similar background and demographic characteristics also display similarities in how they use their time to structure their daily lives. In this article, we set out to investigate the correctness of such assumptions. We propose a visual analytics process based on sequence similarity measures tailored to event-based data such as performed activity sequences. The process allows an analyst to retrieve similarly behaving records according to user-selected similarity preferences and interactively explore aspects of this similarity in a multiple linked-view environment.},
	language = {en},
	number = {3},
	urldate = {2019-12-13},
	journal = {Information Visualization},
	author = {Vrotsou, Katerina and Ynnerman, Anders and Cooper, Matthew},
	month = jul,
	year = {2014},
	keywords = {vis},
	pages = {232--247},
}

@article{VisualAnalysisSubgroupsDynamic,
	title = {Visual {Analysis} for {Subgroups} in a {Dynamic} {Network}},
	abstract = {The VAST 2018 company communication dataset reﬂects current challenges in analyzing speciﬁc sub-group within a large dynamic network. We apply multiple visual analytic techniques. This also includes a traceability system, a custom visualization tool enable tracing a focused group on multivariate dynamic networks. We manage to tackle the tasks of abstracting group structural features and discovering other groups tied closely.},
	language = {en},
	author = {Ma, Qi and Wei, Xueshi and Xie, Liwenhan and Yin, Zhiyi and Yuan, Xiaoru and Liu, Yiping and Huang, Chuanming},
	keywords = {vis},
	pages = {2},
}

@inproceedings{ComDiaInteractiveVisualAnalytics,
	address = {Bangkok, Thailand},
	title = {{ComDia}+: {An} {Interactive} {Visual} {Analytics} {System} for {Comparing}, {Diagnosing}, and {Improving} {Multiclass} {Classifiers}},
	isbn = {978-1-5386-9226-4},
	shorttitle = {{ComDia}+},
	url = {https://ieeexplore.ieee.org/document/8781593/},
	doi = {10.1109/PacificVis.2019.00044},
	language = {en},
	urldate = {2019-12-13},
	booktitle = {2019 {IEEE} {Pacific} {Visualization} {Symposium} ({PacificVis})},
	publisher = {IEEE},
	author = {Park, Chanhee and Lee, Jina and Han, Hyunwoo and Lee, Kyungwon},
	month = apr,
	year = {2019},
	keywords = {vis},
	pages = {313--317},
}

@article{CarePreIntelligentClinicalDecision,
	title = {{CarePre}: {An} {Intelligent} {Clinical} {Decision} {Assistance} {System}},
	shorttitle = {{CarePre}},
	url = {http://arxiv.org/abs/1811.02218},
	abstract = {Clinical decision support systems (CDSS) are widely used to assist with medical decision making. However, CDSS typically require manually curated rules and other data which are difﬁcult to maintain and keep up-to-date. Recent systems leverage advanced deep learning techniques and electronic health records (EHR) to provide a more timely and precise results. Many of these techniques have been developed with a common focus on predicting upcoming medical events. However, while the prediction results from these approaches are promising, their value is limited by their lack of interpretability. To address this challenge, we introduce CarePre , an intelligent clinical decision assistance system. The system extends a state-of-the-art deep learning model to predict upcoming diagnosis events for a focal patient based on his/her historical medical records. The system includes an interactive framework together with intuitive visualizations designed to support diagnosis, treatment outcome analysis, and the interpretation of the analysis results. We demonstrate the effectiveness and usefulness of CarePre system by reporting results from a quantities evaluation of the prediction algorithm and a case study and three interviews with senior physicians.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1811.02218 [cs]},
	author = {Jin, Zhuochen and Yang, Jingshun and Cui, Shuyuan and Gotz, David and Sun, Jimeng and Cao, Nan},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.02218},
	keywords = {vis},
}

@article{ExplainableArtificialIntelligenceBayesian,
	title = {Explainable {Artiﬁcial} {Intelligence} via {Bayesian} {Teaching}},
	abstract = {Modern machine learning methods are increasingly powerful and opaque. This opaqueness is a concern across a variety of domains in which algorithms are making important decisions that should be scrutable. The explainabilty of machine learning systems is therefore of increasing interest. We propose an explanation-byexamples approach that builds on our recent research in Bayesian teaching in which we aim to select a small subset of the data that would lead the learner to similar conclusions as the entire dataset. We discuss this approach, explicating several key advantages. First, the ability to cover any model with a probabilistic interpretation including supervised, unsupervised, and reinforcement learning (including deep learning). Second, we discuss the empirical foundations of this approach in the cognitive science of learning from other agents. Third, we outline challenges to full realization of the promise of this approach. We conclude by discussing implications for machine learning and applications to real-world problems.},
	language = {en},
	author = {Yang, Scott Cheng-Hsin and Shafto, Patrick},
	keywords = {fatml, xai},
	pages = {11},
}

@article{ExplainableArtificialIntelligenceXAI,
	title = {Explainable {Artificial} {Intelligence} ({XAI})},
	language = {en},
	author = {Gunning, David},
	keywords = {fatml, xai},
	pages = {36},
}

@article{FocusedConceptMinerFCM,
	title = {Focused {Concept} {Miner} ({FCM}): {Interpretable} {Deep} {Learning} for {Text} {Exploration}},
	issn = {1556-5068},
	shorttitle = {Focused {Concept} {Miner} ({FCM})},
	url = {https://www.ssrn.com/abstract=3304756},
	doi = {10.2139/ssrn.3304756},
	abstract = {We introduce the Focused Concept Miner (FCM), an interpretable deep learning text mining algorithm to (1) automatically extract interpretable high-level concepts from text data, (2) focus the mined concepts to explain user-speciﬁed business outcomes, such as conversion (linked to read-reviews) or crowdfunding success (linked to project descriptions), and (3) quantify the correlational relative importance of each concept for business outcomes against one another and to other explanatory variables. Compared to 4 interpretable and 4 prediction-focused baselines that partially achieve FCM’s goals, FCM attains higher interpretability, as measured by a variety of metrics (e.g., automated, human-judged), while achieving competitive predictive performance even when compared to prediction-focused blackbox algorithms.},
	language = {en},
	urldate = {2019-12-13},
	journal = {SSRN Electronic Journal},
	author = {Lee, Dokyun (DK) and Manzoor, Emaad and Cheng, Zhaoqi},
	year = {2018},
	keywords = {fatml, xai},
}

@article{C2ACrowdConsensusAnalytics,
	title = {{C2A}: {Crowd} {Consensus} {Analytics} for {Virtual} {Colonoscopy}},
	shorttitle = {{C2A}},
	url = {http://arxiv.org/abs/1810.09012},
	doi = {10.1109/VAST.2016.7883508},
	abstract = {We present a medical crowdsourcing visual analytics platform called C\{\${\textasciicircum}2\$\}A to visualize, classify and filter crowdsourced clinical data. More specifically, C\${\textasciicircum}2\$A is used to build consensus on a clinical diagnosis by visualizing crowd responses and filtering out anomalous activity. Crowdsourcing medical applications have recently shown promise where the non-expert users (the crowd) were able to achieve accuracy similar to the medical experts. This has the potential to reduce interpretation/reading time and possibly improve accuracy by building a consensus on the findings beforehand and letting the medical experts make the final diagnosis. In this paper, we focus on a virtual colonoscopy (VC) application with the clinical technicians as our target users, and the radiologists acting as consultants and classifying segments as benign or malignant. In particular, C\${\textasciicircum}2\$A is used to analyze and explore crowd responses on video segments, created from fly-throughs in the virtual colon. C\${\textasciicircum}2\$A provides several interactive visualization components to build crowd consensus on video segments, to detect anomalies in the crowd data and in the VC video segments, and finally, to improve the non-expert user's work quality and performance by A/B testing for the optimal crowdsourcing platform and application-specific parameters. Case studies and domain experts feedback demonstrate the effectiveness of our framework in improving workers' output quality, the potential to reduce the radiologists' interpretation time, and hence, the potential to improve the traditional clinical workflow by marking the majority of the video segments as benign based on the crowd consensus.},
	language = {en},
	urldate = {2019-12-13},
	journal = {2016 IEEE Conference on Visual Analytics Science and Technology (VAST)},
	author = {Park, Ji Hwan and Nadeem, Saad and Mirhosseini, Seyedkoosha and Kaufman, Arie},
	month = oct,
	year = {2016},
	note = {arXiv: 1810.09012},
	keywords = {vis},
	pages = {21--30},
}

@article{VisualExplorationCommonBehaviors,
	title = {Visual {Exploration} of {Common} {Behaviors} for {Developmental} {Health}},
	abstract = {Detecting early signs of developmental issues in a child is critical for successful interventions. Using behavior capture technologies such as video cameras, microphones and wearable sensors, it is increasingly possible to record and analyze human behavior in unprecedented detail. However, the analysis of such rich and complex dataset poses new challenges for developmental psychologists. We present the initial design of a visualization tool aimed at supporting the exploration of digitally captured behavioral data for studying developmental health.},
	language = {en},
	author = {Han, Yi and Rozga, Agata and Stasko, John and Abowd, Gregory D},
	keywords = {vis},
	pages = {4},
}

@article{ComprehensibleClassificationModelsPosition,
	title = {Comprehensible {Classification} {Models} – a position paper},
	volume = {15},
	abstract = {The vast majority of the literature evaluates the performance of classification models using only the criterion of predictive accuracy. This paper reviews the case for considering also the comprehensibility (interpretability) of classification models, and discusses the interpretability of five types of classification models, namely decision trees, classification rules, decision tables, nearest neighbors and Bayesian network classifiers. We discuss both interpretability issues which are specific to each of those model types and more generic interpretability issues, namely the drawbacks of using model size as the only criterion to evaluate the comprehensibility of a model, and the use of monotonicity constraints to improve the comprehensibility and acceptance of classification models by users.},
	language = {en},
	number = {1},
	author = {Freitas, Alex A and Freitas, A A},
	keywords = {vis},
	pages = {10},
}

@article{XAIStructuringProcessesExplanations,
	title = {Towards {XAI}: {Structuring}  the {Processes} of {Explanations}},
	abstract = {Explainable Artificial Intelligence describes a process to reveal the logical propagation of operations that transform a given input to a certain output. In this paper, we investigate the design space of explanation processes based on factors gathered from six research areas, namely, Pedagogy, Storytelling, Argumentation, Programming, Trust-Building, and Gamification. We contribute a conceptual model describing the building blocks of explanation processes, including a comprehensive overview of explanation and verification phases, pathways, mediums, and strategies. We further argue for the importance of studying effective methods of explainable machine learning, and discuss open research challenges and opportunities.},
	language = {en},
	author = {El-Assady, Mennatallah and Jentner, Wolfgang and Kehlbeck, Rebecca and Schlegel, Udo and Sevastjanova, Rita and Sperrle, Fabian and Spinner, Thilo and Keim, Daniel},
	year = {2019},
	keywords = {fatml, xai},
	pages = {13},
}

@article{WordSenseClusteringClusterability,
	title = {Word {Sense} {Clustering} and {Clusterability}},
	volume = {42},
	issn = {0891-2017, 1530-9312},
	url = {http://www.mitpressjournals.org/doi/10.1162/COLI_a_00247},
	doi = {10.1162/COLI_a_00247},
	language = {en},
	number = {2},
	urldate = {2019-12-13},
	journal = {Computational Linguistics},
	author = {McCarthy, Diana and Apidianaki, Marianna and Erk, Katrin},
	month = jun,
	year = {2016},
	keywords = {dm},
	pages = {245--275},
}

@inproceedings{InteractiveVisualCoclusterAnalysis,
	address = {Taipei, Taiwan},
	title = {Interactive visual co-cluster analysis of bipartite graphs},
	isbn = {978-1-5090-1451-4},
	url = {http://ieeexplore.ieee.org/document/7465248/},
	doi = {10.1109/PACIFICVIS.2016.7465248},
	language = {en},
	urldate = {2019-12-13},
	booktitle = {2016 {IEEE} {Pacific} {Visualization} {Symposium} ({PacificVis})},
	publisher = {IEEE},
	author = {Xu, Panpan and Cao, Nan and Qu, Huamin and Stasko, John},
	month = apr,
	year = {2016},
	keywords = {vis},
	pages = {32--39},
}

@article{SystematicCombinationDimensionReduction,
	title = {Towards a {Systematic} {Combination} of {Dimension} {Reduction} and {Clustering} in {Visual} {Analytics}},
	volume = {24},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/8019882/},
	doi = {10.1109/TVCG.2017.2745258},
	abstract = {Dimension reduction algorithms and clustering algorithms are both frequently used techniques in visual analytics. Both families of algorithms assist analysts in performing related tasks regarding the similarity of observations and ﬁnding groups in datasets. Though initially used independently, recent works have incorporated algorithms from each family into the same visualization systems. However, these algorithmic combinations are often ad hoc or disconnected, working independently and in parallel rather than integrating some degree of interdependence. A number of design decisions must be addressed when employing dimension reduction and clustering algorithms concurrently in a visualization system, including the selection of each algorithm, the order in which they are processed, and how to present and interact with the resulting projection. This paper contributes an overview of combining dimension reduction and clustering into a visualization system, discussing the challenges inherent in developing a visualization system that makes use of both families of algorithms.},
	language = {en},
	number = {1},
	urldate = {2019-12-13},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wenskovitch, John and Crandell, Ian and Ramakrishnan, Naren and House, Leanna and Leman, Scotland and North, Chris},
	month = jan,
	year = {2018},
	keywords = {vis},
	pages = {131--141},
}

@article{AutoweightedMultiviewCoclusteringBipartite,
	title = {Auto-weighted multi-view co-clustering with bipartite graphs},
	volume = {512},
	issn = {00200255},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025519309302},
	doi = {10.1016/j.ins.2019.09.079},
	abstract = {Co-clustering aims to explore coherent patterns by simultaneously clustering samples and features of data. Several co-clustering methods have been proposed in the past decades. However, in real-world applications, datasets are often with multiple modalities or composed of multiple representations (i.e., views), which provide different yet complementary information. Hence, it is essential to develop multi-view co-clustering models to solve the multi-view application problems. In this paper, a novel multi-view co-clustering method based on bipartite graphs is proposed. To make use of the duality between samples and features of multi-view data, a bipartite graph for each view is constructed such that the cooccurring structure of data can be extracted. The key point of utilizing the bipartite graphs to deal with the multi-view co-clustering task is to reasonably integrate these bipartite graphs and obtain an optimal consensus one. As for this point, the proposed method can learn an optimal weight for each bipartite graph automatically without introducing an additive parameter as previous methods do. Furthermore, an eﬃcient algorithm is proposed to optimize this model with theoretically guaranteed convergence. Extensive experimental results on both toy data and several benchmark datasets have demonstrated the effectiveness of the proposed model.},
	language = {en},
	urldate = {2019-12-13},
	journal = {Information Sciences},
	author = {Huang, Shudong and Xu, Zenglin and Tsang, Ivor W. and Kang, Zhao},
	month = feb,
	year = {2020},
	keywords = {dm},
	pages = {18--30},
}

@article{21PUBLICATIONS306CITATIONS,
	title = {21 {PUBLICATIONS} 306 {CITATIONS} {SEE} {PROFILE}},
	abstract = {This paper presents the Institute for Web Science and Technology's contribution to the TREC2011 Microblog Track. The goal of the Microblog Track is to address the user's information need in which a user wishes to see not only the most recent but also the most interesting and relevant information to a query in Twitter. In this paper we present the LiveTweet system, submitted by the Institute for Web Science and Technologies (WeST) from the University of Koblenz-Landau. The system addresses two issues of microblog media: sparsity and its e ect on document length normalization, as well as the problem of assessing content quality. We provide the following approaches to overcome these issues: ignoring length normalization and using interestingness as a static quality measure to  nd the most recent and interesting tweets related to a given query topic. The results in similar settings have shown that deliberately ignoring length normalization yields better retrieval results in general and that interestingness improves retrieval for underspeci ed queries.},
	language = {en},
	author = {Kunegis, Jérôme and Gottron, Thomas and Koblenz-Landau, Universität and Naveed, Nasir},
	keywords = {vis},
	pages = {14},
}

@article{GeonoClusterInteractiveVisualCluster,
	title = {Geono-{Cluster}: {Interactive} {Visual} {Cluster} {Analysis} for {Biologists}},
	shorttitle = {Geono-{Cluster}},
	url = {http://arxiv.org/abs/1911.00988},
	abstract = {Biologists often perform clustering analysis to derive meaningful patterns, relationships, and structures from data instances and attributes. Though clustering plays a pivotal role in biologists’ data exploration, it takes non-trivial efforts for biologists to ﬁnd the best grouping in their data using existing tools. Visual cluster analysis is currently performed either programmatically or through menus and dialogues in many tools, which require parameter adjustments over several steps of trial-and-error. In this paper, we introduce Geono-Cluster, a novel visual analysis tool designed to support cluster analysis for biologists who do not have formal data science training. Geono-Cluster enables biologists to apply their domain expertise into clustering results by visually demonstrating how their expected clustering outputs should look like with a small sample of data instances. The system then predicts users’ intentions and generates potential clustering results. Our study follows the design study protocol to derive biologists’ tasks and requirements, design the system, and evaluate the system with experts on their own dataset. Results of our study with six biologists provide initial evidence that Geono-Cluster enables biologists to create, reﬁne, and evaluate clustering results to effectively analyze their data and gain data-driven insights. At the end, we discuss lessons learned and implications of our study.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1911.00988 [cs]},
	author = {Saket, Bahador and Das, Subhajit and Kwon, Bum Chul and Endert, Alex},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.00988},
	keywords = {vis},
}

@article{ClustrophileGuidedVisualClustering,
	title = {Clustrophile 2: {Guided} {Visual} {Clustering} {Analysis}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Clustrophile 2},
	url = {https://ieeexplore.ieee.org/document/8440035/},
	doi = {10.1109/TVCG.2018.2864477},
	abstract = {Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to deﬁne an optimal solution, thus requiring user judgment to establish what can be considered a satisﬁable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce Clustrophile 2, a new interactive tool for guided clustering analysis. Clustrophile 2 guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, Clustrophile 2 contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate Clustrophile 2 through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson’s disease patients. Results suggest that Clustrophile 2 improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.},
	language = {en},
	number = {1},
	urldate = {2019-12-13},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cavallo, Marco and Demiralp, Cagatay},
	month = jan,
	year = {2019},
	keywords = {clustering, vis},
	pages = {267--276},
}

@article{OutflowVisualizingPatientFlow,
	title = {Outﬂow: {Visualizing} {Patient} {Flow} by {Symptoms} and {Outcome}},
	abstract = {Electronic Medical Record (EMR) databases contain a large amount of temporal events such as diagnosis dates for various symptoms. Analyzing disease progression pathways in terms of these observed events can provide important insights into how diseases evolve over time. Moreover, connecting these pathways to the eventual outcomes of the corresponding patients can help clinicians understand how certain progression paths may lead to better or worse outcomes. In this paper, we describe the Outﬂow visualization technique, designed to summarize temporal event data that has been extracted from the EMRs of a cohort of patients. We include sample analyses to show examples of the insights that can be learned from this visualization.},
	language = {en},
	author = {Wongsuphasawat, Krist and Gotz, David H},
	keywords = {vis},
	pages = {4},
}

@article{ClustervisionVisualSupervisionUnsupervised,
	title = {Clustervision: {Visual} {Supervision} of {Unsupervised} {Clustering}},
	volume = {24},
	issn = {1077-2626},
	shorttitle = {Clustervision},
	url = {http://ieeexplore.ieee.org/document/8019866/},
	doi = {10.1109/TVCG.2017.2745085},
	abstract = {Clustering, the process of grouping together similar items into distinct partitions, is a common type of unsupervised machine learning that can be useful for summarizing and aggregating complex multi-dimensional data. However, data can be clustered in many ways, and there exist a large body of algorithms designed to reveal different patterns. While having access to a wide variety of algorithms is helpful, in practice, it is quite difﬁcult for data scientists to choose and parameterize algorithms to get the clustering results relevant for their dataset and analytical tasks. To alleviate this problem, we built Clustervision, a visual analytics tool that helps ensure data scientists ﬁnd the right clustering among the large amount of techniques and parameters available. Our system clusters data using a variety of clustering techniques and parameters and then ranks clustering results utilizing ﬁve quality metrics. In addition, users can guide the system to produce more relevant results by providing task-relevant constraints on the data. Our visual user interface allows users to ﬁnd high quality clustering results, explore the clusters using several coordinated visualization techniques, and select the cluster result that best suits their task. We demonstrate this novel approach using a case study with a team of researchers in the medical domain and showcase that our system empowers users to choose an effective representation of their complex data.},
	language = {en},
	number = {1},
	urldate = {2019-12-13},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kwon, Bum Chul and Eysenbach, Ben and Verma, Janu and Ng, Kenney and De Filippi, Christopher and Stewart, Walter F. and Perer, Adam},
	month = jan,
	year = {2018},
	keywords = {clustering, vis},
	pages = {142--151},
}

@article{RetainVisVisualAnalyticsInterpretable,
	title = {{RetainVis}: {Visual} {Analytics} with {Interpretable} and {Interactive} {Recurrent} {Neural} {Networks} on {Electronic} {Medical} {Records}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{RetainVis}},
	url = {https://ieeexplore.ieee.org/document/8440842/},
	doi = {10.1109/TVCG.2018.2865027},
	language = {en},
	number = {1},
	urldate = {2019-12-13},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kwon, Bum Chul and Choi, Min-Je and Kim, Joanne Taery and Choi, Edward and Kim, Young Bin and Kwon, Soonwook and Sun, Jimeng and Choo, Jaegul},
	month = jan,
	year = {2019},
	keywords = {vis},
	pages = {299--309},
}

@article{RegressionExplorerInteractiveExplorationLogistic,
	title = {{RegressionExplorer}: {Interactive} {Exploration} of {Logistic} {Regression} {Models} with {Subgroup} {Analysis}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{RegressionExplorer}},
	url = {https://ieeexplore.ieee.org/document/8464305/},
	doi = {10.1109/TVCG.2018.2865043},
	abstract = {We present RegressionExplorer, a Visual Analytics tool for the interactive exploration of logistic regression models. Our application domain is Clinical Biostatistics, where models are derived from patient data with the aim to obtain clinically meaningful insights and consequences. Development and interpretation of a proper model requires domain expertise and insight into model characteristics. Because of time constraints, often a limited number of candidate models is evaluated. RegressionExplorer enables experts to quickly generate, evaluate, and compare many different models, taking the workﬂow for model development as starting point. Global patterns in parameter values of candidate models can be explored effectively. In addition, experts are enabled to compare candidate models across multiple subpopulations. The insights obtained can be used to formulate new hypotheses or to steer model development. The effectiveness of the tool is demonstrated for two uses cases: prediction of a cardiac conduction disorder in patients after receiving a heart valve implant and prediction of hypernatremia in critically ill patients.},
	language = {en},
	number = {1},
	urldate = {2019-12-13},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Dingen, Dennis and van't Veer, Marcel and Houthuizen, Patrick and Mestrom, Eveline H. J. and Korsten, Erik H.H.M. and Bouwman, Arthur R.A. and van Wijk, Jarke},
	month = jan,
	year = {2019},
	keywords = {vis},
	pages = {246--255},
}

@inproceedings{CrowdScapeInteractivelyVisualizingUsera,
	address = {Cambridge, Massachusetts, USA},
	title = {{CrowdScape}: interactively visualizing user behavior and output},
	isbn = {978-1-4503-1580-7},
	shorttitle = {{CrowdScape}},
	url = {http://dl.acm.org/citation.cfm?doid=2380116.2380125},
	doi = {10.1145/2380116.2380125},
	abstract = {Crowdsourcing has become a powerful paradigm for accomplishing work quickly and at scale, but involves significant challenges in quality control. Researchers have developed algorithmic quality control approaches based on either worker outputs (such as gold standards or worker agreement) or worker behavior (such as task fingerprinting), but each approach has serious limitations, especially for complex or creative work. Human evaluation addresses these limitations but does not scale well with increasing numbers of workers. We present CrowdScape, a system that supports the human evaluation of complex crowd work through interactive visualization and mixed initiative machine learning. The system combines information about worker behavior with worker outputs, helping users to better understand and harness the crowd. We describe the system and discuss its utility through grounded case studies. We explore other contexts where CrowdScape’s visualizations might be useful, such as in user studies.},
	language = {en},
	urldate = {2019-12-13},
	booktitle = {Proceedings of the 25th annual {ACM} symposium on {User} interface software and technology - {UIST} '12},
	publisher = {ACM Press},
	author = {Rzeszotarski, Jeffrey and Kittur, Aniket},
	year = {2012},
	keywords = {vis},
	pages = {55},
}

@article{AnchorVizFacilitatingSemanticData,
	title = {{AnchorViz}: {Facilitating} {Semantic} {Data} {Exploration} and {Concept} {Discovery} for {Interactive} {Machine} {Learning}},
	volume = {10},
	issn = {21606455},
	shorttitle = {{AnchorViz}},
	url = {http://dl.acm.org/citation.cfm?doid=3352585.3241379},
	doi = {10.1145/3241379},
	language = {en},
	number = {1},
	urldate = {2019-12-14},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Suh, Jina and Ghorashi, Soroush and Ramos, Gonzalo and Chen, Nan-Chen and Drucker, Steven and Verwey, Johan and Simard, Patrice},
	month = aug,
	year = {2019},
	keywords = {comps-iui, vis},
	pages = {1--38},
}

@article{GuidanceHumanMachineAnalyticsa,
	title = {Guidance in the human–machine analytics process},
	volume = {2},
	issn = {2468502X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2468502X1830041X},
	doi = {10.1016/j.visinf.2018.09.003},
	abstract = {In this paper, we list the goals for and the pros and cons of guidance, and we discuss the role that it can play not only in key low-level visualization tasks but also the more sophisticated model-generation tasks of visual analytics. Recent advances in artificial intelligence, particularly in machine learning, have led to high hopes regarding the possibilities of using automatic techniques to perform some of the tasks that are currently done manually using visualization by data analysts. However, visual analytics remains a complex activity, combining many different subtasks. Some of these tasks are relatively low-level, and it is clear how automation could play a role—for example, classification and clustering of data. Other tasks are much more abstract and require significant human creativity, for example, linking insights gleaned from a variety of disparate and heterogeneous data artifacts to build support for decision making. In this paper, we outline the potential applications of guidance, as well as the inputs to guidance. We discuss challenges in implementing guidance, including the inputs to guidance systems and how to provide guidance to users. We propose potential methods for evaluating the quality of guidance at different phases in the analytic process and introduce the potential negative effects of guidance as a source of bias in analytic decision making.},
	language = {en},
	number = {3},
	urldate = {2019-12-14},
	journal = {Visual Informatics},
	author = {Collins, Christopher and Andrienko, Natalia and Schreck, Tobias and Yang, Jing and Choo, Jaegul and Engelke, Ulrich and Jena, Amit and Dwyer, Tim},
	month = sep,
	year = {2018},
	keywords = {vis},
	pages = {166--180},
}

@article{AugmentingExploratoryDataAnalysis,
	title = {Augmenting {Exploratory} {Data} {Analysis} with {Visualization} {Recommendation}},
	language = {en},
	author = {Wongsuphasawat, Kanit},
	keywords = {mt},
	pages = {163},
}

@inproceedings{BecomingExpertInteractiveMulticlass,
	address = {Boston, MA, USA},
	title = {Becoming the expert - interactive multi-class machine teaching},
	isbn = {978-1-4673-6964-0},
	url = {http://ieeexplore.ieee.org/document/7298877/},
	doi = {10.1109/CVPR.2015.7298877},
	abstract = {Compared to machines, humans are extremely good at classifying images into categories, especially when they possess prior knowledge of the categories at hand. If this prior information is not available, supervision in the form of teaching images is required. To learn categories more quickly, people should see important and representative images ﬁrst, followed by less important images later – or not at all. However, image-importance is individual-speciﬁc, i.e. a teaching image is important to a student if it changes their overall ability to discriminate between classes. Further, students keep learning, so while image-importance depends on their current knowledge, it also varies with time.},
	language = {en},
	urldate = {2019-12-14},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Johns, Edward and Aodha, Oisin Mac and Brostow, Gabriel J.},
	month = jun,
	year = {2015},
	keywords = {mt},
	pages = {2616--2624},
}

@inproceedings{WillYouAcceptImperfect,
	address = {Glasgow, Scotland Uk},
	title = {Will {You} {Accept} an {Imperfect} {AI}?: {Exploring} {Designs} for {Adjusting} {End}-user {Expectations} of {AI} {Systems}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Will {You} {Accept} an {Imperfect} {AI}?},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300641},
	doi = {10.1145/3290605.3300641},
	language = {en},
	urldate = {2019-12-14},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '19},
	publisher = {ACM Press},
	author = {Kocielnik, Rafal and Amershi, Saleema and Bennett, Paul N.},
	year = {2019},
	keywords = {mt},
	pages = {1--14},
}

@article{KnowledgeGenerationModelVisual,
	title = {Knowledge {Generation} {Model} for {Visual} {Analytics}},
	volume = {20},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/6875967/},
	doi = {10.1109/TVCG.2014.2346481},
	abstract = {Visual analytics enables us to analyze huge information spaces in order to support complex decision making and data exploration. Humans play a central role in generating knowledge from the snippets of evidence emerging from visual data analysis. Although prior research provides frameworks that generalize this process, their scope is often narrowly focused so they do not encompass different perspectives at different levels. This paper proposes a knowledge generation model for visual analytics that ties together these diverse frameworks, yet retains previously developed models (e.g., KDD process) to describe individual segments of the overall visual analytic processes. To test its utility, a real world visual analytics system is compared against the model, demonstrating that the knowledge generation process model provides a useful guideline when developing and evaluating such systems. The model is used to effectively compare different data analysis systems. Furthermore, the model provides a common language and description of visual analytic processes, which can be used for communication between researchers. At the end, our model reﬂects areas of research that future researchers can embark on.},
	language = {en},
	number = {12},
	urldate = {2019-12-14},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Sacha, Dominik and Stoffel, Andreas and Stoffel, Florian and Kwon, Bum Chul and Ellis, Geoffrey and Keim, Daniel A.},
	month = dec,
	year = {2014},
	keywords = {vis},
	pages = {1604--1613},
}

@article{InteractiveMachineLearningHeuristics,
	title = {Interactive {Machine} {Learning} {Heuristics}},
	abstract = {End-user interaction with machine learning based systems will result in new usability challenges for the ﬁeld of human computer interaction. Machine learning algorithms are often complicated to the point of being literal black boxes, presenting a unique challenge in the context of interaction with and understanding by end-users. In order to address these challenges, the most relied upon usability inspection method, the heuristic evaluation, must be adapted for the unique end-user experiences that interactive machine learning presents. To address this gap, this paper introduces ten heuristics for interactive machine learning. These heuristics have been developed by distilling design principles from interactive machine learning literature.},
	language = {en},
	author = {Corbett, Eric and Saul, Nathaniel and Pirrung, Meg},
	keywords = {reading-list-191228, vis},
	pages = {5},
}

@article{NudgingNeuralConversationalModel,
	title = {Nudging {Neural} {Conversational} {Model} with {Domain} {Knowledge}},
	url = {http://arxiv.org/abs/1811.06630},
	abstract = {Neural conversation models are attractive because one can train a model directly on dialog examples with minimal labeling. With a small amount of data, however, they often fail to generalize over test data since they tend to capture spurious features instead of semantically meaningful domain knowledge. To address this issue, we propose a novel approach that allows any human teachers to transfer their domain knowledge to the conversation model in the form of natural language rules. We tested our method with three different dialog datasets. The improved performance across all domains demonstrates the efﬁcacy of our proposed method.},
	language = {en},
	urldate = {2019-12-14},
	journal = {arXiv:1811.06630 [cs]},
	author = {Lee, Sungjin},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.06630},
	keywords = {key, mt},
}

@article{IterativeMachineTeaching,
	title = {Iterative {Machine} {Teaching}},
	url = {http://arxiv.org/abs/1705.10470},
	abstract = {In this paper, we consider the problem of machine teaching, the inverse problem of machine learning. Different from traditional machine teaching which views the learners as batch algorithms, we study a new paradigm where the learner uses an iterative algorithm and a teacher can feed examples sequentially and intelligently based on the current performance of the learner. We show that the teaching complexity in the iterative case is very different from that in the batch case. Instead of constructing a minimal training set for learners, our iterative machine teaching focuses on achieving fast convergence in the learner model. Depending on the level of information the teacher has from the learner model, we design teaching algorithms which can provably reduce the number of teaching examples and achieve faster convergence than learning without teachers. We also validate our theoretical ﬁndings with extensive experiments on different data distribution and real image datasets.},
	language = {en},
	urldate = {2019-12-14},
	journal = {arXiv:1705.10470 [cs, stat]},
	author = {Liu, Weiyang and Dai, Bo and Humayun, Ahmad and Tay, Charlene and Yu, Chen and Smith, Linda B. and Rehg, James M. and Song, Le},
	month = nov,
	year = {2017},
	note = {arXiv: 1705.10470},
	keywords = {Statistics - Machine Learning, mt},
}

@article{ClusterCanonicalCorrelationAnalysis,
	title = {Cluster {Canonical} {Correlation} {Analysis}},
	abstract = {In this paper we present cluster canonical correlation analysis (cluster-CCA) for joint dimensionality reduction of two sets of data points. Unlike the standard pairwise correspondence between the data points, in our problem each set is partitioned into multiple clusters or classes, where the class labels deﬁne correspondences between the sets. Cluster-CCA is able to learn discriminant low dimensional representations that maximize the correlation between the two sets while segregating the different classes on the learned space. Furthermore, we present a kernel extension, kernel cluster canonical correlation analysis (cluster-KCCA) that extends clusterCCA to account for non-linear relationships. Cluster-(K)CCA is shown to be computationally efﬁcient, the complexity being similar to standard (K)CCA. By means of experimental evaluation on benchmark datasets, cluster-(K)CCA is shown to achieve state of the art performance for cross-modal retrieval tasks.},
	language = {en},
	author = {Rasiwasia, Nikhil and Mahajan, Dhruv and Mahadevan, Vijay and Aggarwal, Gaurav},
	keywords = {dm},
	pages = {9},
}

@inproceedings{CoclusteringSigned3partiteGraphs,
	address = {San Francisco, CA, USA},
	title = {Co-clustering signed 3-partite graphs},
	isbn = {978-1-5090-2846-7},
	url = {http://ieeexplore.ieee.org/document/7752353/},
	doi = {10.1109/ASONAM.2016.7752353},
	abstract = {In this paper, we propose a new algorithm, called STRICLUSTER, to ﬁnd tri-clusters from signed 3-partite graphs. The dataset contains three different types of nodes. Hyperedges connecting three nodes from three different partitions represent either positive or negative relations among those nodes. The aim of our algorithm is to ﬁnd clusters with strong positive relations among its nodes. Moreover, negative relations up to a certain threshold is also allowed. Also, the clusters can have no overlapping hyperedges. We show the effectiveness of our algorithm via several experiments.},
	language = {en},
	urldate = {2019-12-13},
	booktitle = {2016 {IEEE}/{ACM} {International} {Conference} on {Advances} in {Social} {Networks} {Analysis} and {Mining} ({ASONAM})},
	publisher = {IEEE},
	author = {Koc, Sefa Sahin and Toroslu, Ismail Hakki and Davulcu, Hasan},
	month = aug,
	year = {2016},
	keywords = {dm},
	pages = {945--948},
}

@article{ModelAgnosticContrastiveExplanationsa,
	title = {Model {Agnostic} {Contrastive} {Explanations} for {Structured} {Data}},
	url = {http://arxiv.org/abs/1906.00117},
	abstract = {Recently, a method [7] was proposed to generate contrastive explanations for differentiable models such as deep neural networks, where one has complete access to the model. In this work, we propose a method, Model Agnostic Contrastive Explanations Method (MACEM), to generate contrastive explanations for any classiﬁcation model where one is able to only query the class probabilities for a desired input. This allows us to generate contrastive explanations for not only neural networks, but models such as random forests, boosted trees and even arbitrary ensembles that are still amongst the state-of-the-art when learning on structured data [13]. Moreover, to obtain meaningful explanations we propose a principled approach to handle real and categorical features leading to novel formulations for computing pertinent positives and negatives that form the essence of a contrastive explanation. A detailed treatment of the different data types of this nature was not performed in the previous work, which assumed all features to be positive real valued with zero being indicative of the least interesting value. We part with this strong implicit assumption and generalize these methods so as to be applicable across a much wider range of problem settings. We quantitatively and qualitatively validate our approach over 5 public datasets covering diverse domains.},
	language = {en},
	urldate = {2019-12-13},
	journal = {arXiv:1906.00117 [cs, stat]},
	author = {Dhurandhar, Amit and Pedapati, Tejaswini and Balakrishnan, Avinash and Chen, Pin-Yu and Shanmugam, Karthikeyan and Puri, Ruchir},
	month = may,
	year = {2019},
	note = {arXiv: 1906.00117},
	keywords = {Statistics - Machine Learning, fatml, xai},
}

@inproceedings{InterpretableExplanationsBlackBoxes,
	address = {Venice},
	title = {Interpretable {Explanations} of {Black} {Boxes} by {Meaningful} {Perturbation}},
	isbn = {978-1-5386-1032-9},
	url = {http://ieeexplore.ieee.org/document/8237633/},
	doi = {10.1109/ICCV.2017.371},
	abstract = {As machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks “look” in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints.},
	language = {en},
	urldate = {2019-12-13},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Fong, Ruth C. and Vedaldi, Andrea},
	month = oct,
	year = {2017},
	keywords = {fatml, xai},
	pages = {3449--3457},
}

@article{HowPeopleExplainAction,
	title = {How {People} {Explain} {Action} (and {Autonomous} {Intelligent} {Systems} {Should} {Too})},
	abstract = {To make Autonomous Intelligent Systems (AIS), such as virtual agents and embodied robots, “explainable” we need to understand how people respond to such systems and what expectations they have of them. Our thesis is that people will regard most AIS as intentional agents and apply the conceptual framework and psychological mechanisms of human behavior explanation to them. We present a wellsupported theory of how people explain human behavior and sketch what it would take to implement the underlying framework of explanation in AIS. The benefits will be considerable: When an AIS is able to explain its behavior in ways that people find comprehensible, people are more likely to form correct mental models of such a system and calibrate their trust in the system.},
	language = {en},
	keywords = {fatml, xai},
	pages = {8},
}

@article{TextAnalysisColexificationClusters,
	title = {Text analysis with colexiﬁcation clusters},
	abstract = {Text analysis methods are used in many applications. Handcrafted databases have been used by both linguistics scholars and data scientists to develop new analysis methods. Although they have been proved to work for extracting meaning, analyzing emotions, performing disambiguations and many other applications, manual and supervised methods lack scalability, while unsupervised methods often are not properly validated or capture patterns without linguistic interpretation. We propose a novel method to analyze texts that uses only translation databases. The method is based on the linguistic phenomenon of colexiﬁcation, identifying relations between words through their translations. This results in a network that we analyze to reveal colexiﬁcation clusters in which words share meanings. We apply this method to a corpus of texts, ﬁnding that it displays topical consistencies within documents and that the diversity of clusters distinguishes literary genres.},
	language = {en},
	author = {Natale, Anna Di},
	pages = {10},
}

@article{NaturalLanguageProcessingNLP,
	title = {Natural {Language} {Processing} ({NLP}) and {Visualization} {Techniques} for {Cross}-{Linguistic} {Effects} {Investigation} and {Mitigation}},
	abstract = {This Ph.D. proposal describes cross-linguistic effects faced by nonnative English speakers; and it outlines different categories of these effects where data driven techniques can be applied to provide tools for both language experts and learners. These different categories are linguistic features, language level, and phonological level. In this document, I discuss the application of NLP and visualization techniques for language pattern analysis using writing samples of learners, and other language specific resources, such as, word frequency lists and dictionaries. Finally, I explain my plan to leverage these techniques and resources to implement three different projects to address cross-linguistic effects at each of the aforementioned categories. In the following sections, I further discuss the proposed projects, theoretical foundation, some existing related work, my progress up-to-date and my proposed timeline for completing the dissertation.},
	language = {en},
	author = {Shimabukuro, Mariana Akemi},
	pages = {46},
}

@incollection{SemanticMapsTypologyColexification,
	address = {Amsterdam},
	title = {Semantic maps and the typology of colexification: {Intertwining} polysemous networks across languages},
	volume = {106},
	isbn = {978-90-272-0573-5 978-90-272-9032-8},
	shorttitle = {Semantic maps and the typology of colexification},
	url = {https://benjamins.com/catalog/slcs.106.09fra},
	abstract = {Building upon the model of Semantic Maps (Haspelmath 2003), which typologists have designed mainly for grammatical semantics, this chapter discusses methodological issues for a model in lexical typology.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Studies in {Language} {Companion} {Series}},
	publisher = {John Benjamins Publishing Company},
	author = {François, Alexandre},
	editor = {Vanhove, Martine},
	year = {2008},
	doi = {10.1075/slcs.106.09fra},
	pages = {163--215},
}

@article{FairSightVisualAnalyticsFairness,
	title = {{FairSight}: {Visual} {Analytics} for {Fairness} in {Decision} {Making}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{FairSight}},
	url = {http://arxiv.org/abs/1908.00176},
	doi = {10.1109/TVCG.2019.2934262},
	abstract = {Data-driven decision making related to individuals has become increasingly pervasive, but the issue concerning the potential discrimination has been raised by recent studies. In response, researchers have made efforts to propose and implement fairness measures and algorithms, but those efforts have not been translated to the real-world practice of data-driven decision making. As such, there is still an urgent need to create a viable tool to facilitate fair decision making. We propose FairSight, a visual analytic system to address this need; it is designed to achieve different notions of fairness in ranking decisions through identifying the required actions -- understanding, measuring, diagnosing and mitigating biases -- that together lead to fairer decision making. Through a case study and user study, we demonstrate that the proposed visual analytic and diagnostic modules in the system are effective in understanding the fairness-aware decision pipeline and obtaining more fair outcomes.},
	urldate = {2019-12-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ahn, Yongsu and Lin, Yu-Ru},
	year = {2019},
	note = {arXiv: 1908.00176},
	keywords = {fatml, xai},
	pages = {1--1},
}

@article{ExplainableAIBewareInmatesa,
	title = {Explainable {AI}: {Beware} of {Inmates} {Running} the {Asylum} {Or}: {How} {I} {Learnt} to {Stop} {Worrying} and {Love} the {Social} and {Behavioural} {Sciences}},
	shorttitle = {Explainable {AI}},
	url = {http://arxiv.org/abs/1712.00547},
	abstract = {In his seminal book The Inmates are Running the Asylum: Why High-Tech Products Drive Us Crazy And How To Restore The Sanity [2004, Sams Indianapolis, IN, USA], Alan Cooper argues that a major reason why software is often poorly designed (from a user perspective) is that programmers are in charge of design decisions, rather than interaction designers. As a result, programmers design software for themselves, rather than for their target audience; a phenomenon he refers to as the ‘inmates running the asylum’. This paper argues that explainable AI risks a similar fate. While the reemergence of explainable AI is positive, this paper argues most of us as AI researchers are building explanatory agents for ourselves, rather than for the intended users. But explainable AI is more likely to succeed if researchers and practitioners understand, adopt, implement, and improve models from the vast and valuable bodies of research in philosophy, psychology, and cognitive science; and if evaluation of these models is focused more on people than on technology. From a light scan of literature, we demonstrate that there is considerable scope to infuse more results from the social and behavioural sciences into explainable AI, and present some key results from these ﬁelds that are relevant to explainable AI.},
	language = {en},
	urldate = {2019-12-28},
	journal = {arXiv:1712.00547 [cs]},
	author = {Miller, Tim and Howe, Piers and Sonenberg, Liz},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.00547},
	keywords = {fatml, xai},
}

@article{CLICS2ImprovedDatabaseCrosslinguistic,
	title = {{CLICS2}: {An} improved database of cross-linguistic colexifications assembling lexical data with the help of cross-linguistic data formats},
	volume = {22},
	issn = {1613-415X},
	shorttitle = {{CLICS2}},
	url = {http://www.degruyter.com/view/j/lity.2018.22.issue-2/lingty-2018-0010/lingty-2018-0010.xml},
	doi = {10.1515/lingty-2018-0010},
	abstract = {The Database of Cross-Linguistic Colexiﬁcations (CLICS), has established a computer-assisted framework for the interactive representation of crosslinguistic colexiﬁcation patterns. In its current form, it has proven to be a useful tool for various kinds of investigation into cross-linguistic semantic associations, ranging from studies on semantic change, patterns of conceptualization, and linguistic paleontology. But CLICS has also been criticized for obvious shortcomings, ranging from the underlying dataset, which still contains many errors, up to the limits of cross-linguistic colexiﬁcation studies in general. Building on recent standardization efforts reﬂected in the Cross-Linguistic Data Formats initiative (CLDF) and novel approaches for fast, efﬁcient, and reliable data aggregation, we have created a new database for cross-linguistic colexiﬁcations, which not only supersedes the original CLICS database in terms of coverage but also offers a much more principled procedure for the creation, curation and aggregation of datasets. The paper presents the new database and discusses its major features.},
	language = {en},
	number = {2},
	urldate = {2019-12-28},
	journal = {Linguistic Typology},
	author = {List, Johann-Mattis and Greenhill, Simon J. and Anderson, Cormac and Mayer, Thomas and Tresoldi, Tiago and Forkel, Robert},
	month = aug,
	year = {2018},
	pages = {277--306},
}

@article{VIS4MLOntologyVisualAnalytics,
	title = {{VIS4ML}: {An} {Ontology} for {Visual} {Analytics} {Assisted} {Machine} {Learning}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{VIS4ML}},
	url = {https://ieeexplore.ieee.org/document/8440124/},
	doi = {10.1109/TVCG.2018.2864838},
	abstract = {While many VA workﬂows make use of machine-learned models to support analytical tasks, VA workﬂows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely “VA-assisted ML”. The purpose of VIS4ML is to describe and understand existing VA workﬂows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the speciﬁcation, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workﬂows. We introduce necessary deﬁnitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workﬂows where VA is used to assist in ML. It is consistent with the established VA concepts and will continue to evolve along with the future developments in VA and ML. While this ontology is an effort for building the theoretical foundation of VA, it can be used by practitioners in real-world applications to optimize model-development workﬂows by systematically examining the potential beneﬁts that can be brought about by either machine or human capabilities. Meanwhile, VIS4ML is intended to be extensible and will continue to be updated to reﬂect future advancements in using VA for building high-quality data-analytical models or for building such models rapidly.},
	language = {en},
	number = {1},
	urldate = {2019-12-14},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Sacha, Dominik and Kraus, Matthias and Keim, Daniel A. and Chen, Min},
	month = jan,
	year = {2019},
	keywords = {vis},
	pages = {385--395},
}

@article{SpeculativeExecutionGuidedVisual,
	title = {Speculative {Execution} for {Guided} {Visual} {Analytics}},
	abstract = {We propose the concept of Speculative Execution for Visual Analytics and discuss its effectiveness for model exploration and optimization. Speculative Execution enables the automatic generation of alternative, competing model conﬁgurations that do not alter the current model state unless explicitly conﬁrmed by the user. These alternatives are computed based on either user interactions or model quality measures and can be explored using delta-visualizations. By automatically proposing modeling alternatives, systems employing Speculative Execution can shorten the gap between users and models, reduce the conﬁrmation bias and speed up optimization processes. In this paper, we have assembled ﬁve application scenarios showcasing the potential of Speculative Execution, as well as a potential for further research.},
	language = {en},
	author = {Sperrle, Fabian and Sedlmair, Michael},
	keywords = {vis},
	pages = {8},
}

@article{WhatYouSeeWhat,
	title = {What you see is what you can change: {Human}-centered machine learning by interactive visualization},
	volume = {268},
	issn = {09252312},
	shorttitle = {What you see is what you can change},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231217307609},
	doi = {10.1016/j.neucom.2017.01.105},
	abstract = {Visual analytics (VA) systems help data analysts solve complex problems interactively, by integrating automated data analysis and mining, such as machine learning (ML) based methods, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and that puts the central relationship between automated algorithms and interactive visualizations into sharp focus. The framework is illustrated with several examples and we further elaborate on the interactive ML process by identifying key scenarios where ML methods are combined with human feedback through interactive visualization. We derive ﬁve open research challenges at the intersection of ML and visualization research, whose solution should lead to more effective data analysis.},
	language = {en},
	urldate = {2019-12-14},
	journal = {Neurocomputing},
	author = {Sacha, Dominik and Sedlmair, Michael and Zhang, Leishi and Lee, John A. and Peltonen, Jaakko and Weiskopf, Daniel and North, Stephen C. and Keim, Daniel A.},
	month = dec,
	year = {2017},
	keywords = {vis},
	pages = {164--175},
}

@article{BidirectionalPipelineSemanticInteraction,
	title = {A {Bidirectional} {Pipeline} for {Semantic} {Interaction}},
	abstract = {Semantic interaction techniques in visual analytics tools allow analysts to indirectly adjust model parameters by directly manipulating the visual output of the models. Many existing tools that support semantic interaction do so with a number of similar features, including using a set of mathematical models that are composed within a pipeline, having a semantic interaction be interpreted by an inverse computation of one or more mathematical models, and using an underlying bidirectional structure within the pipeline. We propose a new visual analytics pipeline that captures these necessary features of semantic interactions. To demonstrate how this pipeline can be used, we represent existing visual analytics tools and their semantic interactions within this pipeline. We also explore a series of new visual analytics tools with semantic interaction to highlight how the new pipeline can represent new research as well.},
	language = {en},
	author = {Dowling, Michelle and Wenskovitch, John and Hauck, Peter and Binford, Adam and Polys, Nicholas and North, Chris},
	keywords = {vis},
	pages = {11},
}

@article{MultiViewLearningWordEmbeddings,
	title = {Multi-{View} {Learning} of {Word} {Embeddings} via {CCA}},
	abstract = {Recently, there has been substantial interest in using large amounts of unlabeled data to learn word representations which can then be used as features in supervised classiﬁers for NLP tasks. However, most current approaches are slow to train, do not model the context of the word, and lack theoretical grounding. In this paper, we present a new learning method, Low Rank Multi-View Learning (LR-MVL) which uses a fast spectral method to estimate low dimensional context-speciﬁc word representations from unlabeled data. These representation features can then be used with any supervised learner. LR-MVL is extremely fast, gives guaranteed convergence to a global optimum, is theoretically elegant, and achieves state-ofthe-art performance on named entity recognition (NER) and chunking problems.},
	language = {en},
	author = {Dhillon, Paramveer S and Foster, Dean and Ungar, Lyle},
	keywords = {dm},
	pages = {9},
}

@inproceedings{HDSKGHarvestingDomainSpecific,
	address = {Klagenfurt, Austria},
	title = {{HDSKG}: {Harvesting} domain specific knowledge graph from content of webpages},
	isbn = {978-1-5090-5501-2},
	shorttitle = {{HDSKG}},
	url = {http://ieeexplore.ieee.org/document/7884609/},
	doi = {10.1109/SANER.2017.7884609},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {2017 {IEEE} 24th {International} {Conference} on {Software} {Analysis}, {Evolution} and {Reengineering} ({SANER})},
	publisher = {IEEE},
	author = {Zhao, Xuejiao and Xing, Zhenchang and Kabir, Muhammad Ashad and Sawada, Naoya and Li, Jing and Lin, Shang-Wei},
	month = feb,
	year = {2017},
	keywords = {kg},
	pages = {56--67},
}

@incollection{TransTTypeBasedMultipleEmbedding,
	address = {Cham},
	title = {{TransT}: {Type}-{Based} {Multiple} {Embedding} {Representations} for {Knowledge} {Graph} {Completion}},
	volume = {10534},
	isbn = {978-3-319-71248-2 978-3-319-71249-9},
	shorttitle = {{TransT}},
	url = {http://link.springer.com/10.1007/978-3-319-71249-9_43},
	abstract = {Knowledge graph completion with representation learning predicts new entity-relation triples from the existing knowledge graphs by embedding entities and relations into a vector space. Most existing methods focus on the structured information of triples and maximize the likelihood of them. However, they neglect semantic information contained in most knowledge graphs and the prior knowledge indicated by the semantic information. To overcome this drawback, we propose an approach that integrates the structured information and entity types which describe the categories of entities. Our approach constructs relation types from entity types and utilizes type-based semantic similarity of the related entities and relations to capture prior distributions of entities and relations. With the type-based prior distributions, our approach generates multiple embedding representations of each entity in di↵erent contexts and estimates the posterior probability of entity and relation prediction. Extensive experiments show that our approach outperforms previous semantics-based methods. The source code of this paper can be obtained from https://github.com/shh/transt.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {Springer International Publishing},
	author = {Ma, Shiheng and Ding, Jianhui and Jia, Weijia and Wang, Kun and Guo, Minyi},
	editor = {Ceci, Michelangelo and Hollmén, Jaakko and Todorovski, Ljupčo and Vens, Celine and Džeroski, Sašo},
	year = {2017},
	doi = {10.1007/978-3-319-71249-9_43},
	keywords = {kg},
	pages = {717--733},
}

@article{IterativelyLearningEmbeddingsRules,
	title = {Iteratively {Learning} {Embeddings} and {Rules} for {Knowledge} {Graph} {Reasoning}},
	url = {http://arxiv.org/abs/1903.08948},
	abstract = {Reasoning is essential for the development of large knowledge graphs, especially for completion, which aims to infer new triples based on existing ones. Both rules and embeddings can be used for knowledge graph reasoning and they have their own advantages and difficulties. Rule-based reasoning is accurate and explainable but rule learning with searching over the graph always suffers from efficiency due to huge search space. Embedding-based reasoning is more scalable and efficient as the reasoning is conducted via computation between embeddings, but it has difficulty learning good representations for sparse entities because a good embedding relies heavily on data richness. Based on this observation, in this paper we explore how embedding and rule learning can be combined together and complement each other's difficulties with their advantages. We propose a novel framework IterE iteratively learning embeddings and rules, in which rules are learned from embeddings with proper pruning strategy and embeddings are learned from existing triples and new triples inferred by rules. Evaluations on embedding qualities of IterE show that rules help improve the quality of sparse entity embeddings and their link prediction results. We also evaluate the efficiency of rule learning and quality of rules from IterE compared with AMIE+, showing that IterE is capable of generating high quality rules more efficiently. Experiments show that iteratively learning embeddings and rules benefit each other during learning and prediction.},
	language = {en},
	urldate = {2019-12-28},
	journal = {arXiv:1903.08948 [cs]},
	author = {Zhang, Wen and Paudel, Bibek and Wang, Liang and Chen, Jiaoyan and Zhu, Hai and Zhang, Wei and Bernstein, Abraham and Chen, Huajun},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.08948},
	keywords = {iterative, kg},
}

@article{LogicRulesPoweredKnowledge,
	title = {Logic {Rules} {Powered} {Knowledge} {Graph} {Embedding}},
	url = {http://arxiv.org/abs/1903.03772},
	abstract = {Large scale knowledge graph embedding has attracted much attention from both academia and industry in the ﬁeld of Artiﬁcial Intelligence. However, most existing methods concentrate solely on fact triples contained in the given knowledge graph. Inspired by the fact that logic rules can provide a ﬂexible and declarative language for expressing rich background knowledge, it is natural to integrate logic rules into knowledge graph embedding, to transfer human knowledge to entity and relation embedding, and strengthen the learning process. In this paper, we propose a novel logic rule-enhanced method which can be easily integrated with any translation based knowledge graph embedding model, such as TransE [3]. We ﬁrst introduce a method to automatically mine the logic rules and corresponding conﬁdences from the triples. And then, to put both triples and mined logic rules within the same semantic space, all triples in the knowledge graph are represented as ﬁrst-order logic. Finally, we deﬁne several operations on the ﬁrstorder logic and minimize a global loss over both of the mined logic rules and the transformed ﬁrst-order logics. We conduct extensive experiments for link prediction and triple classiﬁcation on three datasets: WN18, FB166, and FB15K. Experiments show that the rule-enhanced method can signiﬁcantly improve the performance of several baselines. The highlight of our model is that the ﬁltered Hits@1, which is a pivotal evaluation in the knowledge inference task, has a signiﬁcant improvement (up to 700\% improvement).},
	language = {en},
	urldate = {2019-12-28},
	journal = {arXiv:1903.03772 [cs]},
	author = {Wang, Pengwei and Dou, Dejing and Wu, Fangzhao and de Silva, Nisansa and Jin, Lianwen},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.03772},
	keywords = {kg},
}

@article{MulticontextLearningApproachEEG,
	title = {A multi-context learning approach for {EEG} epileptic seizure detection},
	volume = {12},
	issn = {1752-0509},
	url = {https://bmcsystbiol.biomedcentral.com/articles/10.1186/s12918-018-0626-2},
	doi = {10.1186/s12918-018-0626-2},
	abstract = {Background: Epilepsy is a neurological disease characterized by unprovoked seizures in the brain. The recent advances in sensor technologies allow researchers to analyze the collected biological records to improve the treatment of epilepsy. Electroencephalogram (EEG) is the most commonly used biological measurement to effectively capture the abnormalities of different brain areas during the EEG seizures. To avoid manual visual inspection from long-term EEG readings, automatic epileptic EEG seizure detection has become an important research issue in bioinformatics.
Results: We present a multi-context learning approach to automatically detect EEG seizures by incorporating a feature fusion strategy. We generate EEG scalogram sequences from the EEG records by utilizing waveform transform to describe the frequency content over time. We propose a multi-stage unsupervised model that integrates the features extracted from the global handcrafted engineering, channel-wise deep learning, and EEG embeddings, respectively. The learned multi-context features are subsequently merged to train a seizure detector.
Conclusions: To validate the effectiveness of the proposed approach, extensive experiments against several baseline methods are carried out on two benchmark biological datasets. The experimental results demonstrate that the representative context features from multiple perspectives can be learned by the proposed model, and further improve the performance for the task of EEG seizure detection.},
	language = {en},
	number = {S6},
	urldate = {2019-12-28},
	journal = {BMC Systems Biology},
	author = {Yuan, Ye and Xun, Guangxu and Jia, Kebin and Zhang, Aidong},
	month = nov,
	year = {2018},
	pages = {107},
}

@article{InterpretableTimeSeriesClassification,
	title = {Interpretable {Time} {Series} {Classification} using {All}-{Subsequence} {Learning} and {Symbolic} {Representations} in {Time} and {Frequency} {Domains}},
	url = {http://arxiv.org/abs/1808.04022},
	abstract = {The time series classiﬁcation literature has expanded rapidly over the last decade, with many new classiﬁcation approaches published each year. The research focus has mostly been on improving the accuracy and eﬃciency of classiﬁers, while their interpretability has been somewhat neglected. Classiﬁer interpretability has become a critical constraint for many application domains and the introduction of the ’right to explanation’ GDPR EU legislation in May 2018 is likely to further emphasize the importance of explainable learning algorithms. In this work we analyse the state-of-the-art for time series classiﬁcation, and propose new algorithms that aim to maintain the classiﬁer accuracy and eﬃciency, but keep interpretability as a key design constraint. We present new time series classiﬁcation algorithms that advance the state-of-the-art by implementing the following three key ideas: (1) Multiple resolutions of symbolic approximations: we combine symbolic representations obtained using diﬀerent parameters, rather than one ﬁxed representation (e.g., multiple SAX representations); (2) Multiple domain representations: we combine symbolic approximations in time (e.g., SAX) and frequency (e.g., SFA) domains, to be more robust across problem domains; (3) Eﬃcient navigation of a huge symbolic-words space: we adapt a symbolic sequence classiﬁer named SEQL, to make it work with multiple domain representations (e.g., SAX-SEQL, SFA-SEQL), and use its greedy feature selection strategy to eﬀectively ﬁlter the best features for each representation. We show that a multi-resolution multi-domain linear classiﬁer, SAX-SFA-SEQL, achieves a similar accuracy to the state-of-the-art COTE ensemble, and to a recent deep learning method (FCN), but uses a fraction of the time required by either COTE or FCN. We discuss the accuracy, eﬃciency and interpretability of our proposed algorithms. To further analyse the interpretability aspect of our classiﬁers, we present a case study on an ecology benchmark.},
	language = {en},
	urldate = {2019-12-28},
	journal = {arXiv:1808.04022 [cs, stat]},
	author = {Nguyen, Thach Le and Gsponer, Severin and Ilie, Iulia and Ifrim, Georgiana},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.04022},
}

@article{HowMindExplainsBehaviora,
	title = {How the {Mind} {Explains} {Behavior}},
	language = {en},
	author = {Malle, Bertram F},
	keywords = {fatml, xai},
	pages = {31},
}

@article{KnowledgeGraphEmbeddingHyperrelational,
	title = {Knowledge graph embedding for hyper-relational data},
	volume = {22},
	issn = {1007-0214},
	url = {https://ieeexplore.ieee.org/document/7889640/},
	doi = {10.23919/TST.2017.7889640},
	abstract = {Knowledge graph representation has been a long standing goal of artiﬁcial intelligence. In this paper, we consider a method for knowledge graph embedding of hyper-relational data, which are commonly found in knowledge graphs. Previous models such as Trans (E, H, R) and CTransR are either insufﬁcient for embedding hyper-relational data or focus on projecting an entity into multiple embeddings, which might not be effective for generalization nor accurately reﬂect real knowledge. To overcome these issues, we propose the novel model TransHR, which transforms the hyper-relations in a pair of entities into an individual vector, serving as a translation between them. We experimentally evaluate our model on two typical tasks—link prediction and triple classiﬁcation. The results demonstrate that TransHR signiﬁcantly outperforms Trans (E, H, R) and CTransR, especially for hyperrelational data.},
	language = {en},
	number = {2},
	urldate = {2019-12-28},
	journal = {Tsinghua Science and Technology},
	author = {Zhang, Chunhong and Zhou, Miao and Han, Xiao and Hu, Zheng and Ji, Yang},
	month = apr,
	year = {2017},
	keywords = {kg},
	pages = {185--197},
}

@article{ProjEEmbeddingProjectionKnowledge,
	title = {{ProjE}: {Embedding} {Projection} for {Knowledge} {Graph} {Completion}},
	abstract = {With the large volume of new information created every day, determining the validity of information in a knowledge graph and ﬁlling in its missing parts are crucial tasks for many researchers and practitioners. To address this challenge, a number of knowledge graph completion methods have been developed using low-dimensional graph embeddings. Although researchers continue to improve these models using an increasingly complex feature space, we show that simple changes in the architecture of the underlying model can outperform state-of-the-art models without the need for complex feature engineering. In this work, we present a shared variable neural network model called ProjE that ﬁlls-in missing information in a knowledge graph by learning joint embeddings of the knowledge graph’s entities and edges, and through subtle, but important, changes to the standard loss function. In doing so, ProjE has a parameter size that is smaller than 11 out of 15 existing methods while performing 37\% better than the current-best method on standard datasets. We also show, via a new fact checking task, that ProjE is capable of accurately determining the veracity of many declarative statements.},
	language = {en},
	author = {Shi, Baoxu and Weninger, Tim},
	keywords = {kg},
	pages = {7},
}

@article{ComprehensiveSurveyGraphNeural,
	title = {A {Comprehensive} {Survey} on {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1901.00596},
	abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classiﬁcation and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed signiﬁcant challenges on existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this survey, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning ﬁelds. We propose a new taxonomy to divide the state-of-the-art graph neural networks into four categories, namely recurrent graph neural networks, convolutional graph neural networks, graph autoencoders and spatial-temporal graph neural networks. We further discuss the applications of graph neural networks across various domains and summarize the open source codes and benchmarks of the existing algorithms on different learning tasks. Finally, we propose potential research directions in this rapidly growing ﬁeld.},
	language = {en},
	urldate = {2019-12-28},
	journal = {arXiv:1901.00596 [cs, stat]},
	author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
	month = dec,
	year = {2019},
	note = {arXiv: 1901.00596},
	keywords = {kg},
}

@inproceedings{CollectivePredictionMultipleTypes,
	address = {Shenzhen, China},
	title = {Collective {Prediction} of {Multiple} {Types} of {Links} in {Heterogeneous} {Information} {Networks}},
	isbn = {978-1-4799-4302-9 978-1-4799-4303-6},
	url = {http://ieeexplore.ieee.org/document/7023322/},
	doi = {10.1109/ICDM.2014.25},
	abstract = {Link prediction has become an important and active research topic in recent years, which is prevalent in many realworld applications. Current research on link prediction focuses on predicting one single type of links, such as friendship links in social networks, or predicting multiple types of links independently. However, many real-world networks involve more than one type of links, and different types of links are not independent, but related with complex dependencies among them. In such networks, the prediction tasks for different types of links are also correlated and the links of different types should be predicted collectively. In this paper, we study the problem of collective prediction of multiple types of links in heterogeneous information networks. To address this problem, we introduce the linkage homophily principle and design a relatedness measure, called RM, between different types of objects to compute the existence probability of a link. We also extend conventional proximity measures to heterogeneous links. Furthermore, we propose an iterative framework for heterogeneous collective link prediction, called HCLP, to predict multiple types of links collectively by exploiting diverse and complex linkage information in heterogeneous information networks. Empirical studies on real-world tasks demonstrate that the proposed collective link prediction approach can effectively boost link prediction performances in heterogeneous information networks.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {2014 {IEEE} {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Cao, Bokai and Kong, Xiangnan and Yu, Philip S.},
	month = dec,
	year = {2014},
	keywords = {dm},
	pages = {50--59},
}

@inproceedings{WhoAmPersonalityDetection,
	address = {Kansas City, MO},
	title = {Who {Am} {I}? {Personality} {Detection} {Based} on {Deep} {Learning} for {Texts}},
	isbn = {978-1-5386-3180-5},
	shorttitle = {Who {Am} {I}?},
	url = {https://ieeexplore.ieee.org/document/8422105/},
	doi = {10.1109/ICC.2018.8422105},
	abstract = {Recently, personality detection based on texts from online social networks has attracted more and more attentions. However, most related models are based on letter, word or phrase, which is not sufﬁcient to get good results. In this paper, we present our preliminary but interesting and useful research results to show that the structure of texts can be also an important feature in the study of personality detection from texts. We propose a model named 2CLSTM, which is a bidirectional LSTMs (Long Short Term Memory networks) concatenated with CNN (Convolutional Neural Network), to detect users personality using structures of texts. Besides, a concept, Latent Sentence Group (LSG), is put forward to express the abstract feature combination based on closely connected sentences and we use our model to capture it. To the best of our knowledge, most related works only conducted their experiments on one data set, which may not well explain the versatility of their models. We implement our evaluations on two different kinds of datasets, containing long texts and short texts. Evaluations on both datasets have achieved better results, which demonstrate that our model can efﬁciently learn valid text structure features to accomplish the task.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {2018 {IEEE} {International} {Conference} on {Communications} ({ICC})},
	publisher = {IEEE},
	author = {Sun, Xiangguo and Liu, Bo and Cao, Jiuxin and Luo, Junzhou and Shen, Xiaojun},
	month = may,
	year = {2018},
	keywords = {dl, related-work, tribal},
	pages = {1--6},
}

@article{TopicPanoramaFullPictureRelevant,
	title = {{TopicPanorama}: {A} {Full} {Picture} of {Relevant} {Topics}},
	volume = {22},
	issn = {1077-2626},
	shorttitle = {{TopicPanorama}},
	url = {http://ieeexplore.ieee.org/document/7374750/},
	doi = {10.1109/TVCG.2016.2515592},
	abstract = {This paper presents a visual analytics approach to analyzing a full picture of relevant topics discussed in multiple sources, such as news, blogs, or micro-blogs. The full picture consists of a number of common topics covered by multiple sources, as well as distinctive topics from each source. Our approach models each textual corpus as a topic graph. These graphs are then matched using a consistent graph matching method. Next, we develop a level-of-detail (LOD) visualization that balances both readability and stability. Accordingly, the resulting visualization enhances the ability of users to understand and analyze the matched graph from multiple perspectives. By incorporating metric learning and feature selection into the graph matching algorithm, we allow users to interactively modify the graph matching result based on their information needs. We have applied our approach to various types of data, including news articles, tweets, and blog data. Quantitative evaluation and real-world case studies demonstrate the promise of our approach, especially in support of examining a topic-graph-based full picture at different levels of detail.},
	language = {en},
	number = {12},
	urldate = {2019-12-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wang, Xiting and Liu, Shixia and Liu, Junlin and Chen, Jianfei and Zhu, Jun and Guo, Baining},
	month = dec,
	year = {2016},
	keywords = {vis},
	pages = {2508--2521},
}

@article{PoorOutcomePredictionBursta,
	title = {Poor outcome prediction by burst suppression ratio in adults with post-anoxic coma without hypothermia},
	volume = {36},
	issn = {0161-6412, 1743-1328},
	url = {http://www.tandfonline.com/doi/full/10.1179/1743132814Y.0000000346},
	doi = {10.1179/1743132814Y.0000000346},
	language = {en},
	number = {5},
	urldate = {2019-12-28},
	journal = {Neurological Research},
	author = {Yang, Qinglin and Su, Yingying and Hussain, Mohammed and Chen, Weibi and Ye, Hong and Gao, Daiquan and Tian, Fei},
	month = may,
	year = {2014},
	pages = {453--460},
}

@article{DissertationSubmittedPartialFulfillmenta,
	title = {A dissertation submitted in partial fulﬁllment of the requirements for the degree of {Doctor} of {Philosophy}},
	language = {en},
	author = {Lalithsena, Sarasi},
	keywords = {kg},
	pages = {138},
}

@article{GRANOInteractiveGraphbasedRoot,
	title = {{GRANO}: interactive graph-based root cause analysis for cloud-native distributed data platform},
	volume = {12},
	issn = {21508097},
	shorttitle = {{GRANO}},
	url = {http://dl.acm.org/citation.cfm?doid=3352063.3360421},
	doi = {10.14778/3352063.3352105},
	abstract = {We demonstrate Grano1, an end-to-end anomaly detection and root cause analysis (or RCA for short) system for cloud-native distributed data platform by providing a holistic view of the system component topology, alarms and application events. Grano provides: a Detection Layer to process large amount of time-series monitoring data to detect anomalies at logical and physical system components; an Anomaly Graph Layer with novel graph modeling and algorithms for leveraging system topology data and detection results to identify the root cause relevance at the system component level; and an Application Layer that automatically notiﬁes on-call personnel and presents real-time and on-demand RCA support through an interactive graph interface. The system is deployed and evaluated using eBay’s production data to help on-call personnel to shorten the identiﬁcation of root cause from hours to minutes.},
	language = {en},
	number = {12},
	urldate = {2019-12-28},
	journal = {Proceedings of the VLDB Endowment},
	author = {Wang, Hanzhang and Nguyen, Phuong and Li, Jun and Kopru, Selcuk and Zhang, Gene and Katariya, Sanjeev and Ben-Romdhane, Sami},
	month = aug,
	year = {2019},
	pages = {1942--1945},
}

@article{DeepMultiViewLearningTaskOptimal,
	title = {Deep {Multi}-{View} {Learning} via {Task}-{Optimal} {CCA}},
	url = {http://arxiv.org/abs/1907.07739},
	abstract = {Canonical Correlation Analysis (CCA) is widely used for multimodal data analysis and, more recently, for discriminative tasks such as multi-view learning; however, it makes no use of class labels. Recent CCA methods have started to address this weakness but are limited in that they do not simultaneously optimize the CCA projection for discrimination and the CCA projection itself, or they are linear only. We address these deﬁciencies by simultaneously optimizing a CCA-based and a task objective in an end-to-end manner. Together, these two objectives learn a non-linear CCA projection to a shared latent space that is highly correlated and discriminative. Our method shows a signiﬁcant improvement over previous stateof-the-art (including deep supervised approaches) for cross-view classiﬁcation, regularization with a second view, and semi-supervised learning on real data.},
	language = {en},
	urldate = {2019-12-28},
	journal = {arXiv:1907.07739 [cs, stat]},
	author = {Couture, Heather D. and Kwitt, Roland and Marron, J. S. and Troester, Melissa and Perou, Charles M. and Niethammer, Marc},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.07739},
	keywords = {dm},
}

@article{EfficientInferenceLearningLargea,
	title = {Efficient inference and learning in a large knowledge base: {Reasoning} with extracted information using a locally groundable first-order probabilistic logic},
	volume = {100},
	issn = {0885-6125, 1573-0565},
	shorttitle = {Efficient inference and learning in a large knowledge base},
	url = {http://link.springer.com/10.1007/s10994-015-5488-x},
	doi = {10.1007/s10994-015-5488-x},
	language = {en},
	number = {1},
	urldate = {2019-12-28},
	journal = {Machine Learning},
	author = {Wang, William Yang and Mazaitis, Kathryn and Lao, Ni and Cohen, William W.},
	month = jul,
	year = {2015},
	keywords = {kg},
	pages = {101--126},
}

@article{DataShotAutomaticGenerationFact,
	title = {{DataShot}: {Automatic} {Generation} of {Fact} {Sheets} from {Tabular} {Data}},
	volume = {26},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{DataShot}},
	url = {https://ieeexplore.ieee.org/document/8805442/},
	doi = {10.1109/TVCG.2019.2934398},
	abstract = {Fact sheets with vivid graphical design and intriguing statistical insights are prevalent for presenting raw data. They help audiences understand data-related facts effectively and make a deep impression. However, designing a fact sheet requires both data and design expertise and is a laborious and time-consuming process. One needs to not only understand the data in depth but also produce intricate graphical representations. To assist in the design process, we present DataShot which, to the best of our knowledge, is the ﬁrst automated system that creates fact sheets automatically from tabular data. First, we conduct a qualitative analysis of 245 infographic examples to explore general infographic design space at both the sheet and element levels. We identify common infographic structures, sheet layouts, fact types, and visualization styles during the study. Based on these ﬁndings, we propose a fact sheet generation pipeline, consisting of fact extraction, fact composition, and presentation synthesis, for the auto-generation workﬂow. To validate our system, we present use cases with three real-world datasets. We conduct an in-lab user study to understand the usage of our system. Our evaluation results show that DataShot can efﬁciently generate satisfactory fact sheets to support further customization and data presentation.},
	language = {en},
	number = {1},
	urldate = {2019-12-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wang, Yun and Sun, Zhida and Zhang, Haidong and Cui, Weiwei and Xu, Ke and Ma, Xiaojuan and Zhang, Dongmei},
	month = jan,
	year = {2020},
	pages = {895--905},
}

@inproceedings{ExtractingTopKInsightsMultidimensional,
	address = {Chicago, Illinois, USA},
	title = {Extracting {Top}-{K} {Insights} from {Multi}-dimensional {Data}},
	isbn = {978-1-4503-4197-4},
	url = {http://dl.acm.org/citation.cfm?doid=3035918.3035922},
	doi = {10.1145/3035918.3035922},
	abstract = {OLAP tools have been extensively used by enterprises to make better and faster decisions. Nevertheless, they require users to specify group-by attributes and know precisely what they are looking for. This paper takes the ﬁrst attempt towards automatically extracting top-k insights from multi-dimensional data. This is useful not only for non-expert users, but also reduces the manual effort of data analysts. In particular, we propose the concept of insight which captures interesting observation derived from aggregation results in multiple steps (e.g., rank by a dimension, compute the percentage of measure by a dimension). An example insight is: “Brand B’s rank (across brands) falls along the year, in terms of the increase in sales”. Our problem is to compute the top-k insights by a score function. It poses challenges on (i) the effectiveness of the result and (ii) the efﬁciency of computation. We propose a meaningful scoring function for insights to address (i). Then, we contribute a computation framework for top-k insights, together with a suite of optimization techniques (i.e., pruning, ordering, specialized cube, and computation sharing) to address (ii). Our experimental study on both real data and synthetic data veriﬁes the effectiveness and efﬁciency of our proposed solution.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Conference} on {Management} of {Data} - {SIGMOD} '17},
	publisher = {ACM Press},
	author = {Tang, Bo and Han, Shi and Yiu, Man Lung and Ding, Rui and Zhang, Dongmei},
	year = {2017},
	pages = {1509--1524},
}

@article{CanonicalCorrelationAnalysisCCA,
	title = {Canonical {Correlation} {Analysis} ({CCA}) {Based} {Multi}-{View} {Learning}: {An} {Overview}},
	shorttitle = {Canonical {Correlation} {Analysis} ({CCA}) {Based} {Multi}-{View} {Learning}},
	url = {http://arxiv.org/abs/1907.01693},
	abstract = {Multi-view learning (MVL) is a strategy for fusing data from different sources or subsets. Canonical correlation analysis (CCA) is very important in MVL, whose main idea is to map data from different views onto a common space with the maximum correlation. The traditional CCA can only be used to calculate the linear correlation between two views. Moreover, it is unsupervised, and the label information is wasted in supervised learning tasks. Many nonlinear, supervised, or generalized extensions have been proposed to overcome these limitations. However, to our knowledge, there is no up-to-date overview of these approaches. This paper ﬁlls this gap, by providing a comprehensive overview of many classical and latest CCA approaches, and describing their typical applications in pattern recognition, multi-modal retrieval and classiﬁcation, and multi-view embedding.},
	language = {en},
	urldate = {2019-12-28},
	journal = {arXiv:1907.01693 [cs, stat]},
	author = {Guo, Chenfeng and Wu, Dongrui},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.01693},
	keywords = {dm},
}

@article{ReviewEEGMEGEpileptic,
	title = {A {Review} of {EEG} and {MEG} {Epileptic} {Spike} {Detection} {Algorithms}},
	volume = {6},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8489863/},
	doi = {10.1109/ACCESS.2018.2875487},
	abstract = {Epilepsy is one of the most serious disorders that affect patients’ daily lives. When seizures occur, patients cannot control their behaviors, which can lead to serious injuries. With the great advances in recording both electroencephalogram (EEG) and magnetoencephalography (MEG) signals, it has become possible to analyze these signals in an automated manner for information extraction to help in seizure detection and prediction. Both EEG and MEG recordings of epilepsy patients contain spikes that can be used for the localization of epileptogenic zones, efﬁcient onset detection, and even, in some cases, prediction. In this paper, we consider the characteristics of EEG and MEG spikes, present a discussion of the importance of spike detection in both signal modalities, and provide a review of spike detection algorithms. Since EEG signals have been widely used for decades, most of the algorithms presented in this paper cover the EEG spike detection methods. Few works in the literature are dedicated to MEG spike detection. Nevertheless, we assert that with some modiﬁcations, a considerable number of EEG spike detection algorithms can be applied to MEG signals. We classify the spike detection algorithms according to the domain used for processing the signal. Finally, we conclude with future research directions and open problems in this area.},
	language = {en},
	urldate = {2019-12-28},
	journal = {IEEE Access},
	author = {Abd El-Samie, Fathi E. and Alotaiby, Turky N. and Khalid, Muhammad Imran and Alshebeili, Saleh A. and Aldosari, Saeed A.},
	year = {2018},
	keywords = {dm},
	pages = {60673--60688},
}

@article{SimpleAlgorithmsPeakDetectiona,
	title = {Simple {Algorithms} for {Peak} {Detection} in {Time}-{Series}},
	abstract = {Identifying and analyzing peaks (or spikes) in a given time-series is important in many applications. Peaks indicate significant events such as sudden increase in price/volume, sharp rise in demand, bursts in data traffic etc. While it is easy to visually identify peaks in a small univariate time-series, there is a need to formalize the notion of a peak to avoid subjectivity and to devise algorithms to automatically detect peaks in any given time-series. The latter is important in applications such as data center monitoring where thousands of large time-series indicating CPU/memory utilization need to be analyzed in real-time. A data point in a time-series is a local peak if (a) it is a large and locally maximum value within a window, which is not necessarily large nor globally maximum in the entire time-series; and (b) it is isolated i.e., not too many points in the window have similar values. Not all local peaks are true peaks; a local peak is a true peak if it is a reasonably large value even in the global context. We offer different formalizations of the notion of a peak and propose corresponding algorithms to detect peaks in the given time-series. We experimentally compare the effectiveness of these algorithms.},
	language = {en},
	author = {Palshikar, Girish Keshav},
	pages = {13},
}

@incollection{ShapeIdentificationTemporalData,
	address = {London},
	title = {Shape {Identification} in {Temporal} {Data} {Sets}},
	isbn = {978-1-4471-2803-8 978-1-4471-2804-5},
	url = {http://link.springer.com/10.1007/978-1-4471-2804-5_17},
	abstract = {Shapes are a concise way to describe temporal variable behaviors. Some commonly used shapes are spikes, sinks, rises, and drops. A spike describes a set of variable values that rapidly increase, then immediately rapidly decrease. The variable may be the value of a stock or a person’s blood sugar levels. Shapes are abstract. Details such as the height of spike or its rate increase, are lost in the abstraction. These hidden details make it difﬁcult to deﬁne shapes and compare one to another. For example, what attributes of a spike determine its “spikiness”? The ability to deﬁne and compare shapes is important because it allows shapes to be identiﬁed and ranked, according to an attribute of interest. Work has been done in the area of shape identiﬁcation through pattern matching and other data mining techniques, but ideas combining the identiﬁcation and comparison of shapes have received less attention. This paper ﬁlls the gap by presenting a set of shapes and the attributes by which they can identiﬁed, compared, and ranked. Neither the set of shapes, nor their attributes presented in this paper are exhaustive, but it provides an example of how a shape’s attributes can be used for identiﬁcation and comparison. The intention of this paper is not to replace any particular mathematical method of identifying a particular behavior, but to provide a toolset for knowledge discovery and an intuitive method of data mining for novices. Spikes, sinks, rises, drops, lines, plateaus, valleys, and gaps are the shapes presented in this paper. Several attributes for each shape are deﬁned. These attributes will be the basis for constructing deﬁnitions that allow the shapes to be identiﬁed and ranked. The second contribution is an information visualization tool, TimeSearcher: Shape Search Edition (SSE), which allows users to explore data sets using the identiﬁcation and ranking ideas in this paper.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Expanding the {Frontiers} of {Visual} {Analytics} and {Visualization}},
	publisher = {Springer London},
	author = {Gregory, Machon and Shneiderman, Ben},
	editor = {Dill, John and Earnshaw, Rae and Kasik, David and Vince, John and Wong, Pak Chung},
	year = {2012},
	doi = {10.1007/978-1-4471-2804-5_17},
	pages = {305--321},
}

@article{KalmanFilterBasedMethodology,
	title = {A {Kalman} filter based methodology for {EEG} spike enhancement},
	volume = {85},
	issn = {01692607},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169260706002422},
	doi = {10.1016/j.cmpb.2006.10.003},
	abstract = {In this work, we present a methodology for spike enhancement in electroencephalographic (EEG) recordings. Our approach takes advantage of the non-stationarity nature of the EEG signal using a time-varying autoregressive model. The time-varying coefﬁcients of autoregressive model are estimated using the Kalman ﬁlter. The results show considerable improvement in signal-to-noise ratio and signiﬁcant reduction of the number of false positives.},
	language = {en},
	number = {2},
	urldate = {2019-12-28},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Oikonomou, V.P. and Tzallas, A.T. and Fotiadis, D.I.},
	month = feb,
	year = {2007},
	pages = {101--108},
}

@inproceedings{WordsPredictingUserPersonality,
	address = {Cambridge, United Kingdom},
	title = {Beyond the {Words}: {Predicting} {User} {Personality} from {Heterogeneous} {Information}},
	isbn = {978-1-4503-4675-7},
	shorttitle = {Beyond the {Words}},
	url = {http://dl.acm.org/citation.cfm?doid=3018661.3018717},
	doi = {10.1145/3018661.3018717},
	abstract = {An incisive understanding of user personality is not only essential to many scientiﬁc disciplines, but also has a profound business impact on practical applications such as digital marketing, personalized recommendation, mental diagnosis, and human resources management. Previous studies have demonstrated that language usage in social media is effective in personality prediction. However, except for single language features, a less researched direction is how to leverage the heterogeneous information on social media to have a better understanding of user personality. In this paper, we propose a Heterogeneous Information Ensemble framework, called HIE, to predict users’ personality traits by integrating heterogeneous information including self-language usage, avatar, emoticon, and responsive patterns. In our framework, to improve the performance of personality prediction, we have designed different strategies extracting semantic representations to fully leverage heterogeneous information on social media. We evaluate our methods with extensive experiments based on a real-world data covering both personality survey results and social media usage from thousands of volunteers. The results reveal that our approaches significantly outperform several widely adopted state-of-the-art baseline methods. To ﬁgure out the utility of HIE in a real-world interactive setting, we also present DiPsy, a personalized chatbot to predict user personality through heterogeneous information in digital traces and conversation logs.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Proceedings of the {Tenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining} - {WSDM} '17},
	publisher = {ACM Press},
	author = {Wei, Honghao and Zhang, Fuzheng and Yuan, Nicholas Jing and Cao, Chuan and Fu, Hao and Xie, Xing and Rui, Yong and Ma, Wei-Ying},
	year = {2017},
	keywords = {dl, related-work, tribal},
	pages = {305--314},
}

@article{UsingHeterogeneousFeaturesScientific,
	title = {Using {Heterogeneous} {Features} for {Scientific} {Citation} {Classification}},
	url = {http://rgdoi.net/10.13140/2.1.2737.2484},
	doi = {10.13140/2.1.2737.2484},
	abstract = {Quickly identifying relevant documents from a massive network of documents available on line is a challenging task. This work aims at helping readers to navigate through document networks by discovering structures from these networks via link type analysis. As a ﬁrst step, we propose to utilise textual and extra-textual features local to the links, as well as network structural features, to perform link classiﬁcation. We report on statistical and experimental results using citation networks which demonstrate that although individually these features are potentially useful, combining these heterogeneous features is challenging.},
	language = {en},
	urldate = {2019-12-28},
	author = {Xu, Han and Martin, Eric and Ashesh Mahidadia},
	year = {2013},
}

@article{UTOPIANUserDrivenTopicModeling,
	title = {{UTOPIAN}: {User}-{Driven} {Topic} {Modeling} {Based} on {Interactive} {Nonnegative} {Matrix} {Factorization}},
	volume = {19},
	issn = {1077-2626},
	shorttitle = {{UTOPIAN}},
	url = {http://ieeexplore.ieee.org/document/6634167/},
	doi = {10.1109/TVCG.2013.212},
	abstract = {Topic modeling has been widely used for analyzing text document collections. Recently, there have been signiﬁcant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and ﬂexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.},
	language = {en},
	number = {12},
	urldate = {2019-12-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {{Jaegul Choo} and {Changhyun Lee} and Reddy, Chandan K. and Park, Haesun},
	month = dec,
	year = {2013},
	keywords = {vis},
	pages = {1992--2001},
}

@inproceedings{HeterogeneousFeaturesModelSelection,
	address = {Dallas, Texas, USA},
	title = {Heterogeneous features and model selection for event-based media classification},
	isbn = {978-1-4503-2033-7},
	url = {http://dl.acm.org/citation.cfm?doid=2461466.2461493},
	doi = {10.1145/2461466.2461493},
	abstract = {With the rapid development of social media sites, a lot of user generated content is being shared in the Web, leading to new challenges for traditional media retrieval techniques. An event describes the happening at a speciﬁc time and place in real-world, and it is one of the most important cues for people to recall past memories. The reminder value of an event makes it extremely helpful in organizing human life. Thus, organizing media by events has recently drawn much attention within the multimedia research community. In this paper, we focus on two fundamental problems related to event based social media analysis: the study of feature importance for modeling the relation between events and media, and how to deal with missing and erroneous metadata often present in social media data. These issues are studied within an event-based media classiﬁcation framework. Different learning approaches are employed to train the event models on diﬀerent features. We ﬁnd, through experiments on a large set of events, that the best discriminant features are tags, spatial and temporal feature. We address the missing value problem by extending the feature with an extra attribute to indicate if the values are missing. Promising results are achieved demonstrating the eﬀectiveness of the proposed method.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Proceedings of the 3rd {ACM} conference on {International} conference on multimedia retrieval - {ICMR} '13},
	publisher = {ACM Press},
	author = {Liu, Xueliang and Huet, Benoit},
	year = {2013},
	keywords = {dm},
	pages = {151},
}

@inproceedings{UserProfilingDeepMultimodal,
	address = {Marina Del Rey, CA, USA},
	title = {User {Profiling} through {Deep} {Multimodal} {Fusion}},
	isbn = {978-1-4503-5581-0},
	url = {http://dl.acm.org/citation.cfm?doid=3159652.3159691},
	doi = {10.1145/3159652.3159691},
	abstract = {User profiling in social media has gained a lot of attention due to its varied set of applications in advertising, marketing, recruiting, and law enforcement. Among the various techniques for user modeling, there is fairly limited work on how to merge multiple sources or modalities of user data – such as text, images, and relations – to arrive at more accurate user profiles. In this paper, we propose a deep learning approach that extracts and fuses information across different modalities. Our hybrid user profiling framework utilizes a shared representation between modalities to integrate three sources of data at the feature level, and combines the decision of separate networks that operate on each combination of data sources at the decision level. Our experimental results on more than 5K Facebook users demonstrate that our approach outperforms competing approaches for inferring age, gender and personality traits of social media users. We get highly accurate results with AUC values of more than 0.9 for the task of age prediction and 0.95 for the task of gender prediction.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Proceedings of the {Eleventh} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining} - {WSDM} '18},
	publisher = {ACM Press},
	author = {Farnadi, Golnoosh and Tang, Jie and De Cock, Martine and Moens, Marie-Francine},
	year = {2018},
	keywords = {dm},
	pages = {171--179},
}

@inproceedings{ParallelTopicsProbabilisticApproachExploring,
	address = {Providence, RI, USA},
	title = {{ParallelTopics}: {A} probabilistic approach to exploring document collections},
	isbn = {978-1-4673-0014-8 978-1-4673-0015-5},
	shorttitle = {{ParallelTopics}},
	url = {http://ieeexplore.ieee.org/document/6102461/},
	doi = {10.1109/VAST.2011.6102461},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {2011 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Dou, Wenwen and Wang, Xiaoyu and Chang, Remco and Ribarsky, William},
	month = oct,
	year = {2011},
	keywords = {vis},
	pages = {231--240},
}

@article{IVisClusteringInteractiveVisualDocument,
	title = {{iVisClustering}: {An} {Interactive} {Visual} {Document} {Clustering} via {Topic} {Modeling}},
	volume = {31},
	issn = {01677055},
	shorttitle = {{iVisClustering}},
	url = {http://doi.wiley.com/10.1111/j.1467-8659.2012.03108.x},
	doi = {10.1111/j.1467-8659.2012.03108.x},
	abstract = {Clustering plays an important role in many large-scale data analyses providing users with an overall understanding of their data. Nonetheless, clustering is not an easy task due to noisy features and outliers existing in the data, and thus the clustering results obtained from automatic algorithms often do not make clear sense. To remedy this problem, automatic clustering should be complemented with interactive visualization strategies. This paper proposes an interactive visual analytics system for document clustering, called iVisClustering, based on a widelyused topic modeling method, latent Dirichlet allocation (LDA). iVisClustering provides a summary of each cluster in terms of its most representative keywords and visualizes soft clustering results in parallel coordinates. The main view of the system provides a 2D plot that visualizes cluster similarities and the relation among data items with a graph-based representation. iVisClustering provides several other views, which contain useful interaction methods. With help of these visualization modules, we can interactively reﬁne the clustering results in various ways. Keywords can be adjusted so that they characterize each cluster better. In addition, our system can ﬁlter out noisy data and re-cluster the data accordingly. Cluster hierarchy can be constructed using a tree structure and for this purpose, the system supports cluster-level interactions such as sub-clustering, removing unimportant clusters, merging the clusters that have similar meanings, and moving certain clusters to any other node in the tree structure. Furthermore, the system provides document-level interactions such as moving mis-clustered documents to another cluster and removing useless documents. Finally, we present how interactive clustering is performed via iVisClustering by using real-world document data sets.},
	language = {en},
	number = {3pt3},
	urldate = {2019-12-28},
	journal = {Computer Graphics Forum},
	author = {Lee, Hanseung and Kihm, Jaeyeon and Choo, Jaegul and Stasko, John and Park, Haesun},
	month = jun,
	year = {2012},
	keywords = {vis},
	pages = {1155--1164},
}

@article{TemporalSummaryImagesApproach,
	title = {Temporal {Summary} {Images}: {An} {Approach} to {Narrative} {Visualization} via {Interactive} {Annotation} {Generation} and {Placement}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {Temporal {Summary} {Images}},
	url = {http://ieeexplore.ieee.org/document/7539294/},
	doi = {10.1109/TVCG.2016.2598876},
	abstract = {Visualization is a powerful technique for analysis and communication of complex, multidimensional, and time-varying data. However, it can be difﬁcult to manually synthesize a coherent narrative in a chart or graph due to the quantity of visualized attributes, a variety of salient features, and the awareness required to interpret points of interest (POIs). We present Temporal Summary Images (TSIs) as an approach for both exploring this data and creating stories from it. As a visualization, a TSI is composed of three common components: (1) a temporal layout, (2) comic strip-style data snapshots, and (3) textual annotations. To augment user analysis and exploration, we have developed a number of interactive techniques that recommend relevant data features and design choices, including an automatic annotations workﬂow. As the analysis and visual design processes converge, the resultant image becomes appropriate for data storytelling. For validation, we use a prototype implementation for TSIs to conduct two case studies with large-scale, scientiﬁc simulation datasets.},
	language = {en},
	number = {1},
	urldate = {2019-12-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bryan, Chris and Ma, Kwan-Liu and Woodring, Jonathan},
	month = jan,
	year = {2017},
	pages = {511--520},
}

@article{VisualDiagnosisTreeBoosting,
	title = {Visual {Diagnosis} of {Tree} {Boosting} {Methods}},
	volume = {24},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/8017582/},
	doi = {10.1109/TVCG.2017.2744378},
	abstract = {Tree boosting, which combines weak learners (typically decision trees) to generate a strong learner, is a highly effective and widely used machine learning method. However, the development of a high performance tree boosting model is a time-consuming process that requires numerous trial-and-error experiments. To tackle this issue, we have developed a visual diagnosis tool, BOOSTVis, to help experts quickly analyze and diagnose the training process of tree boosting. In particular, we have designed a temporal confusion matrix visualization, and combined it with a t-SNE projection and a tree visualization. These visualization components work together to provide a comprehensive overview of a tree boosting model, and enable an effective diagnosis of an unsatisfactory training process. Two case studies that were conducted on the Otto Group Product Classiﬁcation Challenge dataset demonstrate that BOOSTVis can provide informative feedback and guidance to improve understanding and diagnosis of tree boosting algorithms. Index Terms—tree boosting, model analysis, temporal confusion matrix, tree visualization.},
	language = {en},
	number = {1},
	urldate = {2019-12-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Shixia and Xiao, Jiannan and Liu, Junlin and Wang, Xiting and Wu, Jing and Zhu, Jun},
	month = jan,
	year = {2018},
	keywords = {vis},
	pages = {163--173},
}

@article{SquaresSupportingInteractivePerformance,
	title = {Squares: {Supporting} {Interactive} {Performance} {Analysis} for {Multiclass} {Classifiers}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {Squares},
	url = {http://ieeexplore.ieee.org/document/7539404/},
	doi = {10.1109/TVCG.2016.2598828},
	abstract = {Performance analysis is critical in applied machine learning because it inﬂuences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classiﬁcation problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance signiﬁcantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.},
	language = {en},
	number = {1},
	urldate = {2019-12-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ren, Donghao and Amershi, Saleema and Lee, Bongshin and Suh, Jina and Williams, Jason D.},
	month = jan,
	year = {2017},
	pages = {61--70},
}

@article{BetterAnalysisDeepConvolutionala,
	title = {Towards {Better} {Analysis} of {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1604.07043},
	abstract = {Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classiﬁcation. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and reﬁning deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.},
	language = {en},
	urldate = {2019-12-28},
	journal = {arXiv:1604.07043 [cs]},
	author = {Liu, Mengchen and Shi, Jiaxin and Li, Zhen and Li, Chongxuan and Zhu, Jun and Liu, Shixia},
	month = may,
	year = {2016},
	note = {arXiv: 1604.07043},
}

@article{BetterAnalysisMachineLearning,
	title = {Towards better analysis of machine learning models: {A} visual analytics perspective},
	volume = {1},
	issn = {2468502X},
	shorttitle = {Towards better analysis of machine learning models},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2468502X17300086},
	doi = {10.1016/j.visinf.2017.01.006},
	abstract = {Interactive model analysis, the process of understanding, diagnosing, and refining a machine learning model with the help of interactive visualization, is very important for users to efficiently solve real-world artificial intelligence and data mining problems. Dramatic advances in big data analytics have led to a wide variety of interactive model analysis tasks. In this paper, we present a comprehensive analysis and interpretation of this rapidly developing area. Specifically, we classify the relevant work into three categories: understanding, diagnosis, and refinement. Each category is exemplified by recent influential work. Possible future research opportunities are also explored and discussed.},
	language = {en},
	number = {1},
	urldate = {2019-12-28},
	journal = {Visual Informatics},
	author = {Liu, Shixia and Wang, Xiting and Liu, Mengchen and Zhu, Jun},
	month = mar,
	year = {2017},
	keywords = {vis},
	pages = {48--56},
}

@article{DeepConvolutionalNeuralNetwork,
	title = {A deep convolutional neural network model for automated identification of abnormal {EEG} signals},
	issn = {0941-0643, 1433-3058},
	url = {http://link.springer.com/10.1007/s00521-018-3889-z},
	doi = {10.1007/s00521-018-3889-z},
	abstract = {Electroencephalogram (EEG) is widely used to monitor the brain activities. The manual examination of these signals by experts is strenuous and time consuming. Hence, machine learning techniques can be used to improve the accuracy of detection. Nowadays, deep learning methodologies have been used in medical ﬁeld to diagnose the health conditions precisely and aid the clinicians. In this study, a new deep one-dimensional convolutional neural network (1D CNN) model is proposed for the automatic recognition of normal and abnormal EEG signals. The proposed model is a complete end-toend structure which classiﬁes the EEG signals without requiring any feature extraction. In this study, we have used the EEG signals from temporal to occipital (T5–O1) single channel obtained from Temple University Hospital EEG Abnormal Corpus (v2.0.0) EEG dataset to develop the 1D CNN model. Our developed model has yielded the classiﬁcation error rate of 20.66\% in classifying the normal and abnormal EEG signals.},
	language = {en},
	urldate = {2019-12-28},
	journal = {Neural Computing and Applications},
	author = {Yıldırım, Özal and Baloglu, Ulas Baran and Acharya, U. Rajendra},
	month = nov,
	year = {2018},
}

@article{SimpleMethodSimultaneouslyDetect,
	title = {A {Simple} {Method} to {Simultaneously} {Detect} and {Identify} {Spikes} from {Raw} {Extracellular} {Recordings}},
	volume = {9},
	issn = {1662-453X},
	url = {http://journal.frontiersin.org/Article/10.3389/fnins.2015.00452/abstract},
	doi = {10.3389/fnins.2015.00452},
	language = {en},
	urldate = {2019-12-28},
	journal = {Frontiers in Neuroscience},
	author = {Petrantonakis, Panagiotis C. and Poirazi, Panayiota},
	month = dec,
	year = {2015},
}

@inproceedings{AutomaticSelectionNeuronalSpike,
	address = {San Diego, CA, USA},
	title = {Automatic selection of neuronal spike detection threshold via smoothed {Teager} energy histogram},
	isbn = {978-1-4673-1969-0},
	url = {http://ieeexplore.ieee.org/document/6696214/},
	doi = {10.1109/NER.2013.6696214},
	abstract = {Spike detection is a prerequisite to analyzing neuronal activity. While simple spike detectors are favorable for hardware implementation, manual setting of spike detection threshold can be tedious and time-consuming, especially for extracellular recordings of multiple neuronal activity. This paper, therefore, investigates and proposes an automatic threshold selection using smoothed Teager energy histogram (STEH), with consideration of signal prewhitening, histogram bin width, and histogram equalization. Results from spikes with signal-to-noise ratio = 0.9-2.6 dB reveals that (1) prewhitening of neural signals can enhance true detection rate (TDR) by 1020\% at constant false alarm (FA) ranging 3-12 spikes/s; (2) Freedman-Diaconis choice of STEH bin width delivers higher TDR (1.52 ± 1.41\%) and FA (0.48 ± 0.25 spikes/s) than squareroot choice; and (3) histogram equalization can raise average TDR by 2.84\% and FA by 1.01 spikes/s. Thresholds determined by STEH with signal prewhitening, Freedman-Diaconis choice or square-root choice of bin width, and histogram equalization fall around knee point of receiver operating characteristic curve, yielding average TDR = 87.88\% and FA = 1.82 spikes/s for Freedman-Diaconis choice, and TDR = 86.49\% and FA = 1.41 spikes/s for square-root choice of STEH bin width.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {2013 6th {International} {IEEE}/{EMBS} {Conference} on {Neural} {Engineering} ({NER})},
	publisher = {IEEE},
	author = {Ng, Andrew Keong and Ang, Kai Keng and Guan, Cuntai},
	month = nov,
	year = {2013},
	pages = {1437--1440},
}

@article{EEGSpikeDetectionTechnique,
	title = {{EEG} {Spike} {Detection} {Technique} {Using} {Output} {Correlation} {Method}: {A} {Kalman} {Filtering} {Approach}},
	volume = {34},
	issn = {0278-081X, 1531-5878},
	shorttitle = {{EEG} {Spike} {Detection} {Technique} {Using} {Output} {Correlation} {Method}},
	url = {http://link.springer.com/10.1007/s00034-015-9982-y},
	doi = {10.1007/s00034-015-9982-y},
	abstract = {This correspondence presents a technique for the electroencephalogram (EEG) spike enhancement and detection, which uses the Kalman ﬁltering (KF) approach based on the output correlation method for the nonstationary signal enhancement. We describe the nonstationary EEG signal in terms of the general Markov model, in which the parameters are considered to be time-varying. In the proposed methodology, neither the process and measurement noise statistics nor the initial Kalman blending factor are stringently required. The EEG epileptic spikes (ESs) are preemphasized using the output correlation method, and subsequently, the detection is performed using the decision threshold based on the output of same adaptive ﬁlter. We have tested the proposed scheme on the synthetic EEG signal corrupted with randomly occurring triangular spikes. The presented simulation results manifest signiﬁcant improvement in the signal-to-noise ratio (SNR) due to the modiﬁed estimation of time-varying parameters of the general Markov model, which in turn leads to the alleviated number of false-positives (FPs). It is apparent that the real-time EEG signal (rat data) can be analyzed using the proposed EEG epileptic spike enhancement and detection adaptive scheme, which outperforms the conventional KF technique under the different SNR conditions. At 10 dB SNR, the output correlation method provides approximately 40 \% reduction in FPs for the triangular spikes in synthetic EEG signal and approximately 27.5 \% reduction in FPs for ESs in the rat data as compared to the conventional KF scheme.},
	language = {en},
	number = {8},
	urldate = {2019-12-28},
	journal = {Circuits, Systems, and Signal Processing},
	author = {Garg, Harish Kumar and Kohli, Amit Kumar},
	month = aug,
	year = {2015},
	pages = {2643--2665},
}

@article{FastEEGSpikeDetection,
	title = {Fast {EEG} spike detection via eigenvalue analysis and clustering of spatial amplitude distribution},
	volume = {15},
	issn = {1741-2560, 1741-2552},
	url = {http://stacks.iop.org/1741-2552/15/i=3/a=036030?key=crossref.96318b507033828fb9aeed87d4a70fd3},
	doi = {10.1088/1741-2552/aab84c},
	abstract = {Objective. In the current study, we tested a proposed method for fast spike detection in electroencephalography (EEG). Approach. We performed eigenvalue analysis in twodimensional space spanned by gradients calculated from two neighboring samples to detect high-amplitude negative peaks. We extracted the spike candidates by imposing restrictions on parameters regarding spike shape and eigenvalues reflecting detection characteristics of individual medical doctors. We subsequently performed clustering, classifying detected peaks by considering the amplitude distribution at 19 scalp electrodes. Clusters with a small number of candidates were excluded. We then defined a score for eliminating spike candidates for which the pattern of detected electrodes differed from the overall pattern in a cluster. Spikes were detected by setting the score threshold. Main results. Based on visual inspection by a psychiatrist experienced in EEG, we evaluated the proposed method using two statistical measures of precision and recall with respect to detection performance. We found that precision and recall exhibited a trade-off relationship. The average recall value was 0.708 in eight subjects with the score threshold that maximized the F-measure, with 58.6  ±  36.2 spikes per subject. Under this condition, the average precision was 0.390, corresponding to a false positive rate 2.09 times higher than the true positive rate. Analysis of the required processing time revealed that, using a general-purpose computer, our method could be used to perform spike detection in 12.1\% of the recording time. The process of narrowing down spike candidates based on shape occupied most of the processing time. Significance. Although the average recall value was comparable with that of other studies, the proposed method significantly shortened the processing time.},
	language = {en},
	number = {3},
	urldate = {2019-12-28},
	journal = {Journal of Neural Engineering},
	author = {Fukami, Tadanori and Shimada, Takamasa and Ishikawa, Bunnoshin},
	month = jun,
	year = {2018},
	pages = {036030},
}

@article{ClustNailsVisualAnalysisSubspace,
	title = {{ClustNails}: {Visual} analysis of subspace clusters},
	volume = {17},
	issn = {1007-0214},
	shorttitle = {{ClustNails}},
	url = {http://ieeexplore.ieee.org/document/6297588/},
	doi = {10.1109/TST.2012.6297588},
	abstract = {Subspace clustering addresses an important problem in clustering multi-dimensional data. In sparse multi-dimensional data, many dimensions are irrelevant and obscure the cluster boundaries. Subspace clustering helps by mining the clusters present in only locally relevant subsets of dimensions. However, understanding the result of subspace clustering by analysts is not trivial. In addition to the grouping information, relevant sets of dimensions and overlaps between groups, both in terms of dimensions and records, need to be analyzed. We introduce a visual subspace cluster analysis system called ClustNails. It integrates several novel visualization techniques with various user interaction facilities to support navigating and interpreting the result of subspace clustering. We demonstrate the effectiveness of the proposed system by applying it to the analysis of real world data and comparing it with existing visual subspace cluster analysis systems.},
	language = {en},
	number = {4},
	urldate = {2019-12-29},
	journal = {Tsinghua Science and Technology},
	author = {Tatu, Andrada and Zhang, Leishi and Bertini, Enrico and Schreck, Tobias and Keim, Daniel and Bremm, Sebastian and von Landesberger, Tatiana},
	month = aug,
	year = {2012},
	keywords = {p-step-set-clustering, vis},
	pages = {419--428},
}

@article{PromotionAnalysisMultidimensionalSpace,
	title = {Promotion analysis in multi-dimensional space},
	volume = {2},
	issn = {21508097},
	url = {http://dl.acm.org/citation.cfm?doid=1687627.1687641},
	doi = {10.14778/1687627.1687641},
	abstract = {Promotion is one of the key ingredients in marketing. It is often desirable to ﬁnd merit in an object (e.g., product, person, organization, or service) and promote it in an appropriate community. In this paper, we propose a novel functionality, called promotion analysis through ranking, for promoting a given object by leveraging highly ranked results. Since the object may not be highly ranked in the global space, our goal is to discover promotive subspaces in which the object becomes prominent. To achieve this goal, the notion of promotiveness is formulated. We show that this functionality is practical and useful in a wide variety of applications such as business intelligence. However, computing promotive subspaces is challenging due to the explosion of search space and high aggregation cost. For efﬁcient computation, we propose a PromoRank framework, and develop three efﬁcient optimization techniques, namely subspace pruning, object pruning, and promotion cube, which are seamlessly integrated into the framework. Our empirical evaluation on two real data sets conﬁrms the effectiveness of promotion analysis, and that our proposed algorithms signiﬁcantly outperform baseline solutions.},
	language = {en},
	number = {1},
	urldate = {2019-12-28},
	journal = {Proceedings of the VLDB Endowment},
	author = {Wu, Tianyi and Xin, Dong and Mei, Qiaozhu and Han, Jiawei},
	month = aug,
	year = {2009},
	keywords = {dd},
	pages = {109--120},
}

@inproceedings{PromotionalSubspaceMiningEProbe,
	address = {Glasgow, Scotland, UK},
	title = {Promotional subspace mining with {EProbe} framework},
	isbn = {978-1-4503-0717-8},
	url = {http://dl.acm.org/citation.cfm?doid=2063576.2063922},
	doi = {10.1145/2063576.2063922},
	abstract = {In multidimensional data, Promotional Subspace Mining (PSM) aims to ﬁnd out outstanding subspaces for a given object, and to discover meaningful rules from them. In PSM, one major research issue is to produce top subspaces efﬁciently given a predeﬁned subspace ranking measure. A common approach is to achieve an exact solution, which searches through the entire subspace search space and evaluate the target object’s rank in every subspace, assisted with possible pruning strategies. In this paper, we propose EProbe, an Efﬁcient Subspace Probing framework. This novel framework strives to initialize the idea of “early stop” of the top subspace search process. The essential goal is to provide a scalable, costeffective, and ﬂexible solution where its accuracy can be traded with the efﬁciency using adjustable parameters. This framework is especially useful when the computation resources are insufﬁcient and only a limited number of candidate subspaces can be evaluated. As a ﬁrst attempt to seek solutions under EProbe framework, we propose two novel algorithms SRatio and SlidingCluster. In our experiments, we illustrate that these two algorithms could produce a more effective subspace traversal order. Being effective, the topk subspaces included in the ﬁnal results are shown to be evaluated in the early stage of the subspace traversal process.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Proceedings of the 20th {ACM} international conference on {Information} and knowledge management - {CIKM} '11},
	publisher = {ACM Press},
	author = {Zhang, Yan and Jia, Yiyu and Jin, Wei},
	year = {2011},
	pages = {2185},
}

@article{GrandTourToolViewing,
	title = {The {Grand} {Tour}: {A} {Tool} for {Viewing} {Multidimensional} {Data}},
	volume = {6},
	issn = {0196-5204, 2168-3417},
	shorttitle = {The {Grand} {Tour}},
	url = {http://epubs.siam.org/doi/10.1137/0906011},
	doi = {10.1137/0906011},
	abstract = {The grand tour is a method for viewing multivariate statistical data via orthogonal projections onto a sequence of two-dimensional subspaces. The sequence of subspaces is chosen so that it is dense in the set of all two-dimensional subspaces. Desirable properties of such sequences of subspaces are considered, and several specific types of sequences are tested for rapidity of becoming dense. Tabulations are provided of the minimum length of a grand tour sequence necessary to achieve various degrees of denseness in dimensions up to 20.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {SIAM Journal on Scientific and Statistical Computing},
	author = {Asimov, Daniel},
	month = jan,
	year = {1985},
	pages = {128--143},
}

@article{1988EvaluatingExplanationsa,
	title = {1988-{Evaluating} {Explanations}},
	abstract = {Explanation-based learning (EBL) is a powerful method for category formation. However, EBL systems are only effective if they start with good explanations. The problem of evaluating candidate explanations has received little attention: Current research usually assumes that a single explanation will be available for any situation, and that this explanation will be appropriate. In the real world many explanations can be generated for a given anomaly, only some of which are reasonable. Thus it is crucial to be able to distinguish between good and bad explanations. In people, the criteria for evaluating explanations are dynamic: they reflect context, the explainer’s current knowledge, and his needs for specific information. I present a theory of how these factors affect evaluation of explanations, and describe its implementation in ACCEPTER, a program to evaluate explanations for anomalies detected during story understanding.},
	language = {en},
	author = {Leake, David B},
	keywords = {fatml, xai},
	pages = {5},
}

@article{GrandTourToolViewinga,
	title = {The {Grand} {Tour}: {A} {Tool} for {Viewing} {Multidimensional} {Data}},
	volume = {6},
	issn = {0196-5204, 2168-3417},
	shorttitle = {The {Grand} {Tour}},
	url = {http://epubs.siam.org/doi/10.1137/0906011},
	doi = {10.1137/0906011},
	abstract = {The grand tour is a method for viewing multivariate statistical data via orthogonal projections onto a sequence of two-dimensional subspaces. The sequence of subspaces is chosen so that it is dense in the set of all two-dimensional subspaces. Desirable properties of such sequences of subspaces are considered, and several specific types of sequences are tested for rapidity of becoming dense. Tabulations are provided of the minimum length of a grand tour sequence necessary to achieve various degrees of denseness in dimensions up to 20.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {SIAM Journal on Scientific and Statistical Computing},
	author = {Asimov, Daniel},
	month = jan,
	year = {1985},
	keywords = {dm},
	pages = {128--143},
}

@article{FRAMEWORKSALGORITHMSSYSTEMSEFFICIENT,
	title = {{FRAMEWORKS}, {ALGORITHMS}, {AND} {SYSTEMS} {FOR} {EFFICIENT} {DISCOVERY} {OF} {DATA}-{BACKED} {FACTS}},
	language = {en},
	author = {Zhang, Gensheng},
	pages = {154},
}

@inproceedings{NewsViewsAutomatedPipelineCreating,
	address = {Toronto, Ontario, Canada},
	title = {{NewsViews}: an automated pipeline for creating custom geovisualizations for news},
	isbn = {978-1-4503-2473-1},
	shorttitle = {{NewsViews}},
	url = {http://dl.acm.org/citation.cfm?doid=2556288.2557228},
	doi = {10.1145/2556288.2557228},
	abstract = {Interactive visualizations add rich, data-based context to online news articles. Geographic maps are currently the most prevalent form of these visualizations. Unfortunately, designers capable of producing high-quality, customized geovisualizations are scarce. We present NewsViews, a novel automated news visualization system that generates interactive, annotated maps without requiring professional designers. NewsViews’ maps support trend identification and data comparisons relevant to a given news article. The NewsViews system leverages text mining to identify key concepts and locations discussed in articles (as well as potential annotations), an extensive repository of “found” databases, and techniques adapted from cartography to identify and create visually “interesting” thematic maps. In this work, we develop and evaluate key criteria in automatic, annotated, map generation and experimentally validate the key features for successful representations (e.g., relevance to context, variable selection, “interestingness” of representation and annotation quality).},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Proceedings of the 32nd annual {ACM} conference on {Human} factors in computing systems - {CHI} '14},
	publisher = {ACM Press},
	author = {Gao, Tong and Hullman, Jessica R. and Adar, Eytan and Hecht, Brent and Diakopoulos, Nicholas},
	year = {2014},
	pages = {3005--3014},
}

@article{AuthoringDataDrivenVideosDataClips,
	title = {Authoring {Data}-{Driven} {Videos} with {DataClips}},
	volume = {23},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/7539370/},
	doi = {10.1109/TVCG.2016.2598647},
	abstract = {Data videos, or short data-driven motion graphics, are an increasingly popular medium for storytelling. However, creating data videos is difficult as it involves pulling together a unique combination of skills. We introduce DataClips, an authoring tool aimed at lowering the barriers to crafting data videos. DataClips allows non-experts to assemble data-driven “clips” together to form longer sequences. We constructed the library of data clips by analyzing the composition of over 70 data videos produced by reputable sources such as The New York Times and The Guardian. We demonstrate that DataClips can reproduce over 90\% of our data videos corpus. We also report on a qualitative study comparing the authoring process and outcome achieved by (1) non-experts using DataClips, and (2) experts using Adobe Illustrator and After Effects to create data-driven clips. Results indicated that non-experts are able to learn and use DataClips with a short training period. In the span of one hour, they were able to produce more videos than experts using a professional editing tool, and their clips were rated similarly by an independent audience.},
	language = {en},
	number = {1},
	urldate = {2019-12-28},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Amini, Fereshteh and Riche, Nathalie Henry and Lee, Bongshin and Monroy-Hernandez, Andres and Irani, Pourang},
	month = jan,
	year = {2017},
	pages = {501--510},
}

@inproceedings{ContextifierAutomaticGenerationAnnotated,
	address = {Paris, France},
	title = {Contextifier: automatic generation of annotated stock visualizations},
	isbn = {978-1-4503-1899-0},
	shorttitle = {Contextifier},
	url = {http://dl.acm.org/citation.cfm?doid=2470654.2481374},
	doi = {10.1145/2470654.2481374},
	abstract = {Online news tools—for aggregation, summarization and automatic generation—are an area of fruitful development as reading news online becomes increasingly commonplace. While textual tools have dominated these developments, annotated information visualizations are a promising way to complement articles based on their ability to add context. But the manual effort required for professional designers to create thoughtful annotations for contextualizing news visualizations is difficult to scale. We describe the design of Contextifier, a novel system that automatically produces custom, annotated visualizations of stock behavior given a news article about a company. Contextifier’s algorithms for choosing annotations is informed by a study of professionally created visualizations and takes into account visual salience, contextual relevance, and a detection of key events in the company’s history. In evaluating our system we find that Contextifier better balances graphical salience and relevance than the baseline.},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '13},
	publisher = {ACM Press},
	author = {Hullman, Jessica and Diakopoulos, Nicholas and Adar, Eytan},
	year = {2013},
	pages = {2707},
}

@article{AuthoringNarrativeVisualizationsEllipsis,
	title = {Authoring {Narrative} {Visualizations} with {Ellipsis}: {Authoring} {Narrative} {Visualizations} with {Ellipsis}},
	volume = {33},
	issn = {01677055},
	shorttitle = {Authoring {Narrative} {Visualizations} with {Ellipsis}},
	url = {http://doi.wiley.com/10.1111/cgf.12392},
	doi = {10.1111/cgf.12392},
	abstract = {Data visualization is now a popular medium for journalistic storytelling. However, current visualization tools either lack support for storytelling or require signiﬁcant technical expertise. Informed by interviews with journalists, we introduce a model of storytelling abstractions that includes state-based scene structure, dynamic annotations and decoupled coordination of multiple visualization components. We instantiate our model in Ellipsis: a system that combines a domain-speciﬁc language (DSL) for storytelling with a graphical interface for story authoring. User interactions are automatically translated into statements in the Ellipsis DSL. By enabling storytelling without programming, the Ellipsis interface lowers the threshold for authoring narrative visualizations. We evaluate Ellipsis through example applications and user studies with award-winning journalists. Study participants ﬁnd Ellipsis to be a valuable prototyping tool that can empower journalists in the creation of interactive narratives.},
	language = {en},
	number = {3},
	urldate = {2019-12-28},
	journal = {Computer Graphics Forum},
	author = {Satyanarayan, Arvind and Heer, Jeffrey},
	month = jun,
	year = {2014},
	pages = {361--370},
}

@inproceedings{MaverickDiscoveringExceptionalFacts,
	address = {Houston, TX, USA},
	title = {Maverick: {Discovering} {Exceptional} {Facts} from {Knowledge} {Graphs}},
	isbn = {978-1-4503-4703-7},
	shorttitle = {Maverick},
	url = {http://dl.acm.org/citation.cfm?doid=3183713.3183730},
	doi = {10.1145/3183713.3183730},
	language = {en},
	urldate = {2019-12-28},
	booktitle = {Proceedings of the 2018 {International} {Conference} on {Management} of {Data} - {SIGMOD} '18},
	publisher = {ACM Press},
	author = {Zhang, Gensheng and Jimenez, Damian and Li, Chengkai},
	year = {2018},
	pages = {1317--1332},
}

@article{VisBricksMultiformVisualizationLarge,
	title = {{VisBricks}: {Multiform} {Visualization} of {Large}, {Inhomogeneous} {Data}},
	volume = {17},
	issn = {1077-2626},
	shorttitle = {{VisBricks}},
	url = {http://ieeexplore.ieee.org/document/6064995/},
	doi = {10.1109/TVCG.2011.250},
	abstract = {Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to ﬁnd and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-ﬁts-all manner. In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents. State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the ﬁeld of biomedicine.},
	language = {en},
	number = {12},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Lex, Alexander and Schulz, Hans-Jorg and Streit, Marc and Partl, Christian and Schmalstieg, Dieter},
	month = dec,
	year = {2011},
	pages = {2291--2300},
}

@article{ReviewGuidanceApproachesVisuala,
	title = {A {Review} of {Guidance} {Approaches} in {Visual} {Data} {Analysis}: {A} {Multifocal} {Perspective}},
	volume = {38},
	issn = {0167-7055, 1467-8659},
	shorttitle = {A {Review} of {Guidance} {Approaches} in {Visual} {Data} {Analysis}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13730},
	doi = {10.1111/cgf.13730},
	abstract = {Visual data analysis can be envisioned as a collaboration of the user and the computational system with the aim of completing a given task. Pursuing an effective system-user integration, in which the system actively helps the user to reach his/her analysis goal has been focus of visualization research for quite some time. However, this problem is still largely unsolved. As a result, users might be overwhelmed by powerful but complex visual analysis systems which also limits their ability to produce insightful results. In this context, guidance is a promising step towards enabling an effective mixed-initiative collaboration to promote the visual analysis. However, the way how guidance should be put into practice is still to be unravelled. Thus, we conducted a comprehensive literature research and provide an overview of how guidance is tackled by different approaches in visual analysis systems. We distinguish between guidance that is provided by the system to support the user, and guidance that is provided by the user to support the system. By identifying open problems, we highlight promising research directions and point to missing factors that are needed to enable the envisioned human-computer collaboration, and thus, promote a more effective visual data analysis.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Computer Graphics Forum},
	author = {Ceneda, Davide and Gschwandtner, Theresia and Miksch, Silvia},
	month = jun,
	year = {2019},
	pages = {861--879},
}

@article{ProjectionsVisualAnalysisMultivariate,
	title = {Projections for {Visual} {Analysis} of {Multivariate} {Data}: {Methods} for {Identification}, {Interpretation}, and {Navigation} of {Patterns}},
	author = {Jäckle, Dominik},
	pages = {193},
}

@article{ForesightRecommendingVisualInsights,
	title = {Foresight: {Recommending} {Visual} {Insights}},
	shorttitle = {Foresight},
	url = {http://arxiv.org/abs/1707.03877},
	abstract = {Current tools for exploratory data analysis (EDA) require users to manually select data attributes, statistical computations and visual encodings. This can be daunting for large-scale, complex data. We introduce Foresight, a system that helps the user rapidly discover visual insights from large high-dimensional datasets. Formally, an “insight” is a strong manifestation of a statistical property of the data, e.g., high correlation between two attributes, high skewness or concentration about the mean of a single attribute, a strong clustering of values, and so on. For each insight type, Foresight initially presents visualizations of the top k instances in the data, based on an appropriate ranking metric. The user can then look at “nearby” insights by issuing “insight queries” containing constraints on insight strengths and data attributes. Thus the user can directly explore the space of insights, rather than the space of data dimensions and visual encodings as in other visual recommender systems. Foresight also provides “global” views of insight space to help orient the user and ensure a thorough exploration process. Furthermore, Foresight facilitates interactive exploration of large datasets through fast, approximate sketching.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1707.03877 [cs]},
	author = {Demiralp, Çağatay and Haas, Peter J. and Parthasarathy, Srinivasan and Pedapati, Tejaswini},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.03877},
}

@article{ConductingInterpretingCanonicalCorrelation,
	title = {Conducting and {Interpreting} {Canonical} {Correlation} {Analysis} in {Personality} {Research}: {A} {User}-{Friendly} {Primer}},
	volume = {84},
	issn = {0022-3891, 1532-7752},
	shorttitle = {Conducting and {Interpreting} {Canonical} {Correlation} {Analysis} in {Personality} {Research}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327752jpa8401_09},
	doi = {10.1207/s15327752jpa8401_09},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {Journal of Personality Assessment},
	author = {Sherry, Alissa and Henson, Robin K.},
	month = feb,
	year = {2005},
	pages = {37--48},
}

@article{HierarchicalAggregationInformationVisualization,
	title = {Hierarchical {Aggregation} for {Information} {Visualization}: {Overview}, {Techniques}, and {Design} {Guidelines}},
	volume = {16},
	issn = {1077-2626},
	shorttitle = {Hierarchical {Aggregation} for {Information} {Visualization}},
	url = {http://ieeexplore.ieee.org/document/5184827/},
	doi = {10.1109/TVCG.2009.84},
	abstract = {We present a model for building, visualizing, and interacting with multiscale representations of information visualization techniques using hierarchical aggregation. The motivation for this work is to make visual representations more visually scalable and less cluttered. The model allows for augmenting existing techniques with multiscale functionality, as well as for designing new visualization and interaction techniques that conform to this new class of visual representations. We give some examples of how to use the model for standard information visualization techniques such as scatterplots, parallel coordinates, and node-link diagrams, and discuss existing techniques that are based on hierarchical aggregation. This yields a set of design guidelines for aggregated visualizations. We also present a basic vocabulary of interaction techniques suitable for navigating these multiscale visualizations.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Elmqvist, N. and Fekete, J.-D.},
	month = may,
	year = {2010},
	pages = {439--454},
}

@article{CombiningClusterOutlierAnalysis,
	title = {Combining {Cluster} and {Outlier} {Analysis}},
	abstract = {Cluster and outlier analysis are two important tasks. Due to their nature these tasks seem to be opposed to each other, i.e., data objects either belong to a cluster structure or a sparsely populated outlier region. In this work, we present a visual analytics tool that allows the combined analysis of clusters and outliers. Users can add multiple clustering and outlier analysis algorithms, compare results visually, and combine the algorithms’ results. The usefulness of the combined analysis is demonstrated using the example of labeling unknown data sets. The usage scenario also shows that identiﬁed clusters and outliers can share joint areas of the data space.},
	language = {en},
	author = {Bernard, J and Dobermann, E and Sedlmair, M and Fellner, D},
	year = {2017},
	pages = {5},
}

@inproceedings{VisualizationToolLearningStatistical,
	address = {Austin, TX, USA},
	title = {A {Visualization} {Tool} for {Learning} {Statistical} {Analysis} in {Multi} {Tabular} {Datasets}},
	isbn = {978-1-4673-9041-5},
	url = {http://ieeexplore.ieee.org/document/7756963/},
	doi = {10.1109/ICALT.2016.13},
	abstract = {The ability of the human mind to perceive visual information makes visualization not only useful, but a powerful tool for information discovery. Answering questions about complex relationships requires the analyst to choose a statistical analysis technique that makes relationships visually discernible. Often the proper technique is dependent on the characteristics of the dataset, such as dependency among variables, sample size, and types of data (ordinal or categorical). In this work, we propose a web based interface approach that visualizes various statistical tests and displays the distributions of data using color coding schemes. With our system, a user can select multiple variables interactively, and the resulting selections will be visualized to help the user understand the data and statistical formulas used to show it. This capability allows a user to quickly evaluate different subsets of a large, complex dataset for statistical correlations. To validate our approach, we performed a controlled user study to evaluate the ease of use of our system, and to test the effectiveness of our interface. We see our system as directly applicable to data analytical tasks, as well as a useful teaching tool for those learning data analytics.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Advanced} {Learning} {Technologies} ({ICALT})},
	publisher = {IEEE},
	author = {Vaishnavi, Kamasan and Kannan, Ashwin and Cline, David and Etemadpour, Ronak},
	month = jul,
	year = {2016},
	pages = {222--226},
}

@inproceedings{InteractionEmbeddingsPredictionExplanationa,
	address = {Melbourne VIC, Australia},
	title = {Interaction {Embeddings} for {Prediction} and {Explanation} in {Knowledge} {Graphs}},
	isbn = {978-1-4503-5940-5},
	url = {http://dl.acm.org/citation.cfm?doid=3289600.3291014},
	doi = {10.1145/3289600.3291014},
	abstract = {Knowledge graph embedding aims to learn distributed representations for entities and relations, and are proven to be effective in many applications. Crossover interactions — bi-directional effects between entities and relations — help select related information when predicting a new triple, but hasn’t been formally discussed before. In this paper, we propose CrossE, a novel knowledge graph embedding which explicitly simulates crossover interactions. It not only learns one general embedding for each entity and relation as in most previous methods, but also generates multiple triple specific embeddings for both of them, named interaction embeddings. We evaluate the embeddings on typical link prediction task and find that CrossE achieves state-of-the-art results on complex and more challenging datasets. Furthermore, we evaluate the embeddings from a new perspective — giving explanations for predicted triples, which is important for real applications. In this work, explanations for a triple are regarded as reliable closed-paths between head and tail entity. Compared to other baselines, we show experimentally that CrossE is more capable of generating reliable explanations to support its predictions, benefiting from interaction embeddings.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the {Twelfth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining} - {WSDM} '19},
	publisher = {ACM Press},
	author = {Zhang, Wen and Paudel, Bibek and Zhang, Wei and Bernstein, Abraham and Chen, Huajun},
	year = {2019},
	pages = {96--104},
}

@inproceedings{CorrelationStudyTimevaryingMultivariate,
	address = {Beijing, China},
	title = {Correlation study of time-varying multivariate climate data sets},
	isbn = {978-1-4244-4404-5},
	url = {http://ieeexplore.ieee.org/document/4906852/},
	doi = {10.1109/PACIFICVIS.2009.4906852},
	abstract = {We present a correlation study of time-varying multivariate volumetric data sets. In most scientiﬁc disciplines, to test hypotheses and discover insights, scientists are interested in looking for connections among different variables, or among different spatial locations within a data ﬁeld. In response, we propose a suite of techniques to analyze the correlations in time-varying multivariate data. Various temporal curves are utilized to organize the data and capture the temporal behaviors. To reveal patterns and ﬁnd connections, we perform data clustering and segmentation using the kmeans clustering and graph partitioning algorithms. We study the correlation structure of a single or a pair of variables using pointwise correlation coefﬁcients and canonical correlation analysis. We demonstrate our approach using results on time-varying multivariate climate data sets.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2009 {IEEE} {Pacific} {Visualization} {Symposium}},
	publisher = {IEEE},
	author = {Sukharev, Jeffrey and Wang, Chaoli and Ma, Kwan-Liu and Wittenberg, Andrew T.},
	month = apr,
	year = {2009},
	pages = {161--168},
}

@article{TypesExplanations,
	title = {Types of {Explanations}.},
	language = {en},
	author = {Kass, Alex and Leake, David},
	pages = {75},
}

@article{1988EvaluatingExplanations,
	title = {1988-{Evaluating} {Explanations}},
	abstract = {Explanation-based learning (EBL) is a powerful method for category formation. However, EBL systems are only effective if they start with good explanations. The problem of evaluating candidate explanations has received little attention: Current research usually assumes that a single explanation will be available for any situation, and that this explanation will be appropriate. In the real world many explanations can be generated for a given anomaly, only some of which are reasonable. Thus it is crucial to be able to distinguish between good and bad explanations. In people, the criteria for evaluating explanations are dynamic: they reflect context, the explainer’s current knowledge, and his needs for specific information. I present a theory of how these factors affect evaluation of explanations, and describe its implementation in ACCEPTER, a program to evaluate explanations for anomalies detected during story understanding.},
	language = {en},
	author = {Leake, David B},
	pages = {5},
}

@inproceedings{RapidInteractiveMachineLearninga,
	address = {Marina del Ray, California},
	title = {Towards rapid interactive machine learning: evaluating tradeoffs of classification without representation},
	isbn = {978-1-4503-6272-6},
	shorttitle = {Towards rapid interactive machine learning},
	url = {http://dl.acm.org/citation.cfm?doid=3301275.3302280},
	doi = {10.1145/3301275.3302280},
	abstract = {Our contribution is the design and evaluation of an interactive machine learning interface that rapidly provides the user with model feedback after every interaction. To address visual scalability, this interface communicates with the user via a “tip of the iceberg” approach, where the user interacts with a small set of recommended instances for each class. To address computational scalability, we developed an O(n) classification algorithm that incorporates user feedback incrementally, and without consulting the data’s underlying representation matrix. Our computational evaluation showed that this algorithm has similar accuracy to several off-the-shelf classification algorithms with small amounts of labeled data. Empirical evaluation revealed that users performed better using our design compared to an equivalent active learning setup.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces}  - {IUI} '19},
	publisher = {ACM Press},
	author = {Arendt, Dustin and Saldanha, Emily and Wesslen, Ryan and Volkova, Svitlana and Dou, Wenwen},
	year = {2019},
	keywords = {vis},
	pages = {591--602},
}

@article{ExplainableMachineLearningDeployment,
	title = {Explainable {Machine} {Learning} in {Deployment}},
	url = {http://arxiv.org/abs/1909.06342},
	abstract = {Explainable machine learning seeks to provide various stakeholders with insights into model behavior via feature importance scores, counterfactual explanations, and inﬂuential samples, among other techniques. Recent advances in this line of work, however, have gone without surveys of how organizations are using these techniques in practice. This study explores how organizations view and use explainability for stakeholder consumption. We ﬁnd that the majority of deployments are not for end users aﬀected by the model but for machine learning engineers, who use explainability to debug the model itself. There is a gap between explainability in practice and the goal of public transparency, since explanations primarily serve internal stakeholders rather than external ones. Our study synthesizes the limitations with current explainability techniques that hamper their use for end users. To facilitate end user interaction, we develop a framework for establishing clear goals for explainability, including a focus on normative desiderata.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1909.06342 [cs, stat]},
	author = {Bhatt, Umang and Xiang, Alice and Sharma, Shubham and Weller, Adrian and Taly, Ankur and Jia, Yunhan and Ghosh, Joydeep and Puri, Ruchir and Moura, José M. F. and Eckersley, Peter},
	month = dec,
	year = {2019},
	note = {arXiv: 1909.06342},
	keywords = {vis},
}

@article{KnowledgeawareAutoencodersExplainableRecommender,
	title = {Knowledge-aware {Autoencoders} for {Explainable} {Recommender} {Sytems}},
	url = {http://arxiv.org/abs/1807.06300},
	abstract = {Recommender Systems have been widely used to help users in finding what they are looking for thus tackling the information overload problem. After several years of research and industrial findings looking after better algorithms to improve accuracy and diversity metrics, explanation services for recommendation are gaining momentum as a tool to provide a human-understandable feedback to results computed, in most of the cases, by black-box machine learning techniques. As a matter of fact, explanations may guarantee users satisfaction, trust, and loyalty in a system. In this paper, we evaluate how different information encoded in a Knowledge Graph are perceived by users when they are adopted to show them an explanation. More precisely, we compare how the use of categorical information, factual one or a mixture of them both in building explanations, affect explanatory criteria for a recommender system. Experimental results are validated through an A/B testing platform which uses a recommendation engine based on a Semantics-Aware Autoencoder to build users profiles which are in turn exploited to compute recommendation lists and to provide an explanation.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1807.06300 [cs]},
	author = {Bellini, Vito and Schiavone, Angelo and Di Noia, Tommaso and Ragone, Azzurra and Di Sciascio, Eugenio},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.06300},
}

@article{InformationTheoreticClusteringUsing,
	title = {Information {Theoretic} {Clustering} using {Kernel} {Density} {Estimation}},
	language = {en},
	author = {Singh, Shashank and Hooi, Bryan},
	pages = {9},
}

@article{AppliedBayesianMultivariateGeostatisticala,
	title = {Applied {Bayesian} {Multivariate} {Geostatistical} {Algorithm} for {Formation} {Permeability} {Modeling}},
	url = {http://rgdoi.net/10.13140/RG.2.1.1914.6727},
	doi = {10.13140/RG.2.1.1914.6727},
	abstract = {Bayesian Model Averaging (BMA) was adopted as an appropriate probabilistic approach of data modeling and parameter selection in formation permeability modeling. The core permeability was modeled given well logs and core porosity in a sandstone reservoir. Model selection process in Bayesian Model Averaging considers model’s posterior probability and Bayesian Information Criterion (BIC). Based on Bayes’ theorem, BMA integrates prior distribution given the observed data in order to produce a posterior distribution of how likely the model is assimilating the data (maximum likelihood). In the computed BMA Occam’s window, the best selected model has maximum posterior probability and minimum BIC; meanwhile, the model subset selection is determined when the probability of a non-zero predictor coeﬃcient is more than 90\% for the best sampled model.},
	language = {en},
	urldate = {2019-12-29},
	author = {Watheq J. Al-Mudhafar and Sarko Hakim},
	year = {2015},
}

@article{ClusteringNonparametricDensityEstimation,
	title = {Clustering via {Nonparametric} {Density} {Estimation}: {The} \textit{{R}} {Package} \textbf{{pdfCluster}}},
	volume = {57},
	issn = {1548-7660},
	shorttitle = {Clustering via {Nonparametric} {Density} {Estimation}},
	url = {http://www.jstatsoft.org/v57/i11/},
	doi = {10.18637/jss.v057.i11},
	abstract = {The R package pdfCluster performs cluster analysis based on a nonparametric estimate of the density of the observed variables. Functions are provided to encompass the whole process of clustering, from kernel density estimation, to clustering itself and subsequent graphical diagnostics. After summarizing the main aspects of the methodology, we describe the features and the usage of the package, and ﬁnally illustrate its application with the aid of two data sets.},
	language = {en},
	number = {11},
	urldate = {2019-12-29},
	journal = {Journal of Statistical Software},
	author = {Azzalini, Adelchi and Menardi, Giovanna},
	year = {2014},
}

@article{ArtifactionsLogTransformationSpeciesAbundance,
	title = {Artifactions in the {Log}-{Transformation} of {Species} {Abundance} {Distributions}},
	volume = {43},
	issn = {1211-9520, 1874-9348},
	url = {http://link.springer.com/10.1007/s12224-008-9020-y},
	doi = {10.1007/s12224-008-9020-y},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Folia Geobotanica},
	author = {Nekola, Jeffrey C. and Šizling, Arnošt L. and Boyer, Alison G. and Storch, David},
	month = sep,
	year = {2008},
	pages = {259--268},
}

@article{WhyorientedEnduserDebuggingNaive,
	title = {Why-oriented end-user debugging of naive {Bayes} text classification},
	volume = {1},
	issn = {21606455},
	url = {http://dl.acm.org/citation.cfm?doid=2030365.2030367},
	doi = {10.1145/2030365.2030367},
	abstract = {D2.5 Machine learning techniques are increasingly used in intelligent assistants, software targeted at and continuously adapting to assisting end users with email, shopping, and other tasks. Examples include desktop SPAM filters, recommender systems, and handwriting recognition. Fixing such intelligent assistants when they learn incorrect behavior, however, has received only limited attention. To directly support end-user “debugging” of assistant behaviors learned via statistical machine learning, we present a Why-oriented approach that allows users to ask questions about how the assistant made its predictions, provides answers to these “why” questions, and allows users to interactively change these answers to “debug” these assistants’ current and future predictions. To understand the strengths and weaknesses of the approach, we conducted an exploratory study to investigate barriers that participants would encounter when debugging an intelligent assistant using our approach, and the information those participants requested to overcome these barriers. To help ensure the inclusiveness of our investigation, we also explored how gender differences played a role in barriers and information needs. We then use these results to consider opportunities for Why-oriented approaches to address the users’ barriers and information needs.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Kulesza, Todd and Stumpf, Simone and Wong, Weng-Keen and Burnett, Margaret M. and Perona, Stephen and Ko, Andrew and Oberst, Ian},
	month = oct,
	year = {2011},
	pages = {1--31},
}

@article{InteractingMeaningfullyMachineLearning,
	title = {Interacting meaningfully with machine learning systems: {Three} experiments},
	volume = {67},
	issn = {10715819},
	shorttitle = {Interacting meaningfully with machine learning systems},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581909000457},
	doi = {10.1016/j.ijhcs.2009.03.004},
	abstract = {Although machine learning is becoming commonly used in today’s software, there has been little research into how end users might interact with machine learning systems, beyond communicating simple "right/wrong" judgments. If the users themselves could work hand-in-hand with machine learning systems, the users’ understanding and trust of the system could improve and the accuracy of learning systems could be improved as well. We conducted three experiments to understand the potential for rich interactions between users and machine learning systems. The first experiment was a think-aloud study that investigated users’ willingness to interact with machine learning reasoning, and what kinds of feedback users might give to machine learning systems. We then investigated the viability of introducing such feedback into machine learning systems, specifically, how to incorporate some of these types of user feedback into machine learning systems, and what their impact was on the accuracy of the system. Taken together, the results of our experiments show that supporting rich interactions between users and machine learning systems is feasible for both user and machine. This shows the potential of rich humancomputer collaboration via on-the-spot interactions as a promising direction for machine learning systems and users to collaboratively share intelligence.},
	language = {en},
	number = {8},
	urldate = {2019-12-29},
	journal = {International Journal of Human-Computer Studies},
	author = {Stumpf, Simone and Rajaram, Vidya and Li, Lida and Wong, Weng-Keen and Burnett, Margaret and Dietterich, Thomas and Sullivan, Erin and Herlocker, Jonathan},
	month = aug,
	year = {2009},
	pages = {639--662},
}

@inproceedings{UXDesignInnovationChallenges,
	address = {Denver, Colorado, USA},
	title = {{UX} {Design} {Innovation}: {Challenges} for {Working} with {Machine} {Learning} as a {Design} {Material}},
	isbn = {978-1-4503-4655-9},
	shorttitle = {{UX} {Design} {Innovation}},
	url = {http://dl.acm.org/citation.cfm?doid=3025453.3025739},
	doi = {10.1145/3025453.3025739},
	abstract = {Machine learning (ML) is now a fairly established technology, and user experience (UX) designers appear regularly to integrate ML services in new apps, devices, and systems. Interestingly, this technology has not experienced a wealth of design innovation that other technologies have, and this might be because it is a new and difficult design material. To better understand why we have witnessed little design innovation, we conducted a survey of current UX practitioners with regards to how new ML services are envisioned and developed in UX practice. Our survey probed on how ML may or may not have been a part of their UX design education, on how they work to create new things with developers, and on the challenges they have faced working with this material. We use the findings from this survey and our review of related literature to present a series of challenges for UX and interaction design research and education. Finally, we discuss areas where new research and new curriculum might help our community unlock the power of design thinking to re-imagine what ML might be and might do.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '17},
	publisher = {ACM Press},
	author = {Dove, Graham and Halskov, Kim and Forlizzi, Jodi and Zimmerman, John},
	year = {2017},
	pages = {278--288},
}

@article{AppliedBayesianMultivariateGeostatistical,
	title = {Applied {Bayesian} {Multivariate} {Geostatistical} {Algorithm} for {Formation} {Permeability} {Modeling}},
	url = {http://rgdoi.net/10.13140/RG.2.1.1914.6727},
	doi = {10.13140/RG.2.1.1914.6727},
	abstract = {Bayesian Model Averaging (BMA) was adopted as an appropriate probabilistic approach of data modeling and parameter selection in formation permeability modeling. The core permeability was modeled given well logs and core porosity in a sandstone reservoir. Model selection process in Bayesian Model Averaging considers model’s posterior probability and Bayesian Information Criterion (BIC). Based on Bayes’ theorem, BMA integrates prior distribution given the observed data in order to produce a posterior distribution of how likely the model is assimilating the data (maximum likelihood). In the computed BMA Occam’s window, the best selected model has maximum posterior probability and minimum BIC; meanwhile, the model subset selection is determined when the probability of a non-zero predictor coeﬃcient is more than 90\% for the best sampled model.},
	language = {en},
	urldate = {2019-12-29},
	author = {Watheq J. Al-Mudhafar and Sarko Hakim},
	year = {2015},
}

@article{LogTransformKernelDensityEstimation,
	title = {Log-{Transform} {Kernel} {Density} {Estimation} of {Income} {Distribution}},
	language = {en},
	author = {Charpentier, Arthur and Flachaire, Emmanuel},
	pages = {25},
}

@article{SemisupervisedEnsembleLearningWeak,
	title = {Semi-supervised {Ensemble} {Learning} with {Weak} {Supervision} for {Biomedical} {Relation} {Extraction}},
	abstract = {Natural language understanding research has recently shifted towards complex Machine Learning and Deep Learning algorithms. Such models often outperform their simpler counterparts signiﬁcantly. However, their performance relies on the availability of large amounts of labeled data, which are rarely available. To tackle this problem, we propose a methodology for extending training datasets to arbitrarily big sizes and training complex, data-hungry models using weak supervision. We apply this methodology on biomedical relation extraction, a task where training datasets are excessively time-consuming and expensive to create, yet has a major impact on downstream applications such as drug discovery. We demonstrate in two small-scale controlled experiments that our method consistently enhances the performance of an LSTM network, with performance improvements comparable to hand-labeled training data. Finally, we discuss the optimal setting for applying weak supervision using this methodology.},
	language = {en},
	author = {Krasakis, Antonios Minas},
	keywords = {fatml, xai},
	pages = {19},
}

@inproceedings{OpenDialKGExplainableConversationalReasoning,
	address = {Florence, Italy},
	title = {{OpenDialKG}: {Explainable} {Conversational} {Reasoning} with {Attention}-based {Walks} over {Knowledge} {Graphs}},
	shorttitle = {{OpenDialKG}},
	url = {https://www.aclweb.org/anthology/P19-1081},
	doi = {10.18653/v1/P19-1081},
	abstract = {We study a conversational reasoning model that strategically traverses through a largescale common fact knowledge graph (KG) to introduce engaging and contextually diverse entities and attributes. For this study, we collect a new Open-ended Dialog ↔ KG parallel corpus called OpenDialKG, where each utterance from 15K human-to-human roleplaying dialogs is manually annotated with ground-truth reference to corresponding entities and paths from a large-scale KG with 1M+ facts. We then propose the DialKG Walker model that learns the symbolic transitions of dialog contexts as structured traversals over KG, and predicts natural entities to introduce given previous dialog contexts via a novel domain-agnostic, attention-based graph path decoder. Automatic and human evaluations show that our model can retrieve more natural and human-like responses than the state-ofthe-art baselines or rule-based models, in both in-domain and cross-domain tasks. The proposed model also generates a KG walk path for each entity retrieved, providing a natural way to explain conversational reasoning.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Moon, Seungwhan and Shah, Pararth and Kumar, Anuj and Subba, Rajen},
	year = {2019},
	keywords = {fatml, xai},
	pages = {845--854},
}

@inproceedings{ChatbotDigitalCounselling,
	title = {Towards a chatbot for digital counselling},
	url = {https://scienceopen.com/document?vid=a0f7da16-a051-4bfb-9dc7-3baa875657c1},
	doi = {10.14236/ewic/HCI2017.24},
	language = {en},
	urldate = {2019-12-29},
	author = {Cameron, Gillian and Cameron, David and Megaw, Gavin and Bond, Raymond and Mulvenna, Maurice and O’Neill, Siobhan and Armour, Cherie and McTear, Michael},
	month = jul,
	year = {2017},
	keywords = {fatml, xai},
}

@article{InteractiveCausalDiscoveryKnowledge,
	title = {Interactive {Causal} {Discovery} in {Knowledge} {Graphs}},
	abstract = {Being able to provide explanations about a domain is a hard task that requires from a probabilistic reasoning’s viewpoint a causal knowledge about the domain variables, allowing one to predict how they can inﬂuence each others. However, causal discovery from data alone remains a challenging question. In this article, we introduce a way to tackle this question by presenting an interactive method to build a probabilistic relational model from any given relevant domain represented by a knowledge graph. Combining both ontological and expert knowledge, we deﬁne a set of constraints translated into a so-called relational schema. Such a relational schema can then be used to learn a probabilistic relational model, which allows causal discovery.},
	language = {en},
	author = {Munch, Melanie and Dibie, Juliette and Wuillemin, Pierre-Henri},
	keywords = {fatml, xai},
	pages = {16},
}

@inproceedings{ExploringImpactTransparencyInteraction,
	address = {Utrecht, Netherlands},
	title = {Exploring the impact of transparency on the interaction with an in-car digital {AI} assistant},
	isbn = {978-1-4503-6920-6},
	url = {http://dl.acm.org/citation.cfm?doid=3349263.3351325},
	doi = {10.1145/3349263.3351325},
	abstract = {Nowadays, intelligent assistants, such as Amazon’s Alexa, are widely available. Unsurprisingly, intelligent assistants find their way into cars, in some cases as a major way to interact with the car. We conducted a user enactment exploring the impact of transparency on a possible future user experience with a digital AI assistant in the car. The focus is on whether tasks should be performed in an opaque way, only involving the user when it is necessary, or in a transparent way, always offering the user insights into what is being done and how. We present initial findings indicating a slight preference towards more transparency.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Automotive} {User} {Interfaces} and {Interactive} {Vehicular} {Applications} {Adjunct} {Proceedings} - {AutomotiveUI} '19},
	publisher = {ACM Press},
	author = {Neuhaus, Robin and Laschke, Matthias and Theofanou-Fülbier, Dimitra and Hassenzahl, Marc and Sadeghian, Shadan},
	year = {2019},
	keywords = {fatml, xai},
	pages = {450--455},
}

@article{HomeownershipSouthernCaliforniaNew,
	title = {Homeownership: {Southern} {California}'s {New} {Political} {Fault} {Line}?},
	volume = {42},
	issn = {1078-0874, 1552-8332},
	shorttitle = {Homeownership},
	url = {http://journals.sagepub.com/doi/10.1177/1078087406292509},
	doi = {10.1177/1078087406292509},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Urban Affairs Review},
	author = {Barreto, Matt A. and Marks, Mara A. and Woods, Nathan D.},
	month = jan,
	year = {2007},
	pages = {315--341},
}

@article{InteractionsGroupsSubgroupsEffects,
	title = {Interactions {Within} {Groups} and {Subgroups}: {The} {Effects} of {Demographic} {Faultlines}},
	volume = {48},
	issn = {0001-4273, 1948-0989},
	shorttitle = {Interactions {Within} {Groups} and {Subgroups}},
	url = {http://journals.aom.org/doi/10.5465/amj.2005.17843943},
	doi = {10.5465/amj.2005.17843943},
	language = {en},
	number = {4},
	urldate = {2019-12-29},
	journal = {Academy of Management Journal},
	author = {Lau, Dora C. and Murnighan, J. Keith},
	month = aug,
	year = {2005},
	pages = {645--659},
}

@inproceedings{InteractionEmbeddingsPredictionExplanation,
	address = {Melbourne VIC, Australia},
	title = {Interaction {Embeddings} for {Prediction} and {Explanation} in {Knowledge} {Graphs}},
	isbn = {978-1-4503-5940-5},
	url = {http://dl.acm.org/citation.cfm?doid=3289600.3291014},
	doi = {10.1145/3289600.3291014},
	abstract = {Knowledge graph embedding aims to learn distributed representations for entities and relations, and are proven to be effective in many applications. Crossover interactions — bi-directional effects between entities and relations — help select related information when predicting a new triple, but hasn’t been formally discussed before. In this paper, we propose CrossE, a novel knowledge graph embedding which explicitly simulates crossover interactions. It not only learns one general embedding for each entity and relation as in most previous methods, but also generates multiple triple specific embeddings for both of them, named interaction embeddings. We evaluate the embeddings on typical link prediction task and find that CrossE achieves state-of-the-art results on complex and more challenging datasets. Furthermore, we evaluate the embeddings from a new perspective — giving explanations for predicted triples, which is important for real applications. In this work, explanations for a triple are regarded as reliable closed-paths between head and tail entity. Compared to other baselines, we show experimentally that CrossE is more capable of generating reliable explanations to support its predictions, benefiting from interaction embeddings.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the {Twelfth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining} - {WSDM} '19},
	publisher = {ACM Press},
	author = {Zhang, Wen and Paudel, Bibek and Zhang, Wei and Bernstein, Abraham and Chen, Huajun},
	year = {2019},
	keywords = {kg},
	pages = {96--104},
}

@article{BriefIntroductionWeaklySupervised,
	title = {A brief introduction to weakly supervised learning},
	volume = {5},
	issn = {2095-5138, 2053-714X},
	url = {https://academic.oup.com/nsr/article/5/1/44/4093912},
	doi = {10.1093/nsr/nwx106},
	abstract = {Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {National Science Review},
	author = {Zhou, Zhi-Hua},
	month = jan,
	year = {2018},
	pages = {44--53},
}

@article{IncorporatingRulesEndtoendDialog,
	title = {Incorporating rules into end-to-end dialog systems},
	abstract = {End-to-end dialog systems are usually brittle when dealing with unexpected input. Since rule-based dialog systems are unable to generate novel utterances in response to a given context, they produce dull interactions with the user. This paper describes a generative system that is less brittle when dealing with novel input by proposing two methods of incorporating rules into end-to-end neural systems. Results show signiﬁcant improvement in per-turn accuracy over baselines. In addition, the models demonstrate faster convergence in training, improved performance in limited data scenarios and higher diversity of output. This approach can be easily incorporated into any model that uses a general encoder-predictor pipeline.},
	language = {en},
	author = {Razumovskaia, Evgeniia and Eskenazi, Maxine},
	keywords = {vis},
	pages = {11},
}

@article{LearningConversationalWebInterfaces,
	title = {Learning {Conversational} {Web} {Interfaces}},
	abstract = {Automating user tasks with natural language instructions, such as booking a movie ticket, while keeping them engaged is a nontrivial and open problem. Previous work has focused on a particular scenario where users need to give entire instructions before a task can be handled. Aside from the difﬁculty of uttering a long instruction, this setup is also less realistic as the instructions could depend on future observations and needs to be delayed. In this work, we introduce the dialogue-based web navigation problem where the objective is to fulﬁll a hidden user goal by having multi-turn conversations with users and navigating a given web page simultaneously. We study joint learning of dialogue and navigation policies using reinforcement learning with actor-critic method. An architecture where user dialogue and web page observations are attentively encoded into policy actions is developed. We build a novel dialogue-based web environment by wrapping a user simulator and the Fandango movie ticket booking website into a single environment. We evaluate the performance of our models and discuss their biases and shortcomings.},
	language = {en},
	author = {Gur, Izzeddin and Yan, Xifeng},
	keywords = {vis},
	pages = {9},
}

@article{ExtendingFaultlineModelGeographically,
	title = {Extending the {Faultline} {Model} to {Geographically} {Dispersed} {Teams}: {How} {Colocated} {Subgroups} can {Impair} {Group} {Functioning}},
	volume = {49},
	issn = {0001-4273, 1948-0989},
	shorttitle = {Extending the {Faultline} {Model} to {Geographically} {Dispersed} {Teams}},
	url = {http://journals.aom.org/doi/10.5465/amj.2006.22083024},
	doi = {10.5465/amj.2006.22083024},
	language = {en},
	number = {4},
	urldate = {2019-12-29},
	journal = {Academy of Management Journal},
	author = {Polzer, Jeffrey T. and Crisp, C. Brad and Jarvenpaa, Sirkka L. and Kim, Jerry W.},
	month = aug,
	year = {2006},
	pages = {679--692},
}

@article{SystematicMethodUnderstandRequirements,
	title = {A {Systematic} {Method} to {Understand} {Requirements} for {Explainable} {AI} ({XAI}) {Systems}},
	abstract = {This paper presents a ﬁve-step systematic method in the development of an explainable AI (XAI) system, to (i) understand speciﬁc explanation requirements, (ii) assess existing explanation capabilities and (iii) steer future research and development in this area. A case study is discussed whereby the method was developed and applied within an industrial context. This paper is a summary of research originally published at the XAI workshop at IJCAI, 2019 [1].},
	language = {en},
	author = {Hall, Mark and Harborne, Daniel and Tomsett, Richard and Galetic, Vedran and Quintana-Amate, Santiago and Nottle, Alistair and Preece, Alun},
	keywords = {fatml, xai},
	pages = {2},
}

@article{AttentionNotExplanation,
	title = {Attention is not {Explanation}},
	url = {http://arxiv.org/abs/1902.10186},
	abstract = {Attention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful “explanations" for predictions. We ﬁnd that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our ﬁndings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do. Code to reproduce all experiments is available at https://github.com/successar/ AttentionExplanation.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1902.10186 [cs]},
	author = {Jain, Sarthak and Wallace, Byron C.},
	month = may,
	year = {2019},
	note = {arXiv: 1902.10186},
	keywords = {fatml, xai},
}

@article{GeneratingVisualExplanations,
	title = {Generating {Visual} {Explanations}},
	url = {http://arxiv.org/abs/1603.08507},
	abstract = {Clearly explaining a rationale for a classiﬁcation decision to an end-user can be as important as the decision itself. Existing approaches for deep visual recognition are generally opaque and do not output any justiﬁcation text; contemporary vision-language models can describe image content but fail to take into account class-discriminative image aspects which justify visual predictions. We propose a new model that focuses on the discriminating properties of the visible object, jointly predicts a class label, and explains why the predicted label is appropriate for the image. We propose a novel loss function based on sampling and reinforcement learning that learns to generate sentences that realize a global sentence property, such as class speciﬁcity. Our results on a ﬁne-grained bird species classiﬁcation dataset show that our model is able to generate explanations which are not only consistent with an image but also more discriminative than descriptions produced by existing captioning methods.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1603.08507 [cs]},
	author = {Hendricks, Lisa Anne and Akata, Zeynep and Rohrbach, Marcus and Donahue, Jeff and Schiele, Bernt and Darrell, Trevor},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.08507},
	keywords = {fatml, xai},
}

@article{ExplainableReasoningKnowledgeGraphs,
	title = {Explainable {Reasoning} over {Knowledge} {Graphs} for {Recommendation}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	url = {http://www.aaai.org/ojs/index.php/AAAI/article/view/4470},
	doi = {10.1609/aaai.v33i01.33015329},
	abstract = {Incorporating knowledge graph into recommender systems has attracted increasing attention in recent years. By exploring the interlinks within a knowledge graph, the connectivity between users and items can be discovered as paths, which provide rich and complementary information to user-item interactions. Such connectivity not only reveals the semantics of entities and relations, but also helps to comprehend a user’s interest. However, existing efforts have not fully explored this connectivity to infer user preferences, especially in terms of modeling the sequential dependencies within and holistic semantics of a path.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Wang, Xiang and Wang, Dingxian and Xu, Canran and He, Xiangnan and Cao, Yixin and Chua, Tat-Seng},
	month = jul,
	year = {2019},
	keywords = {fatml, xai},
	pages = {5329--5336},
}

@inproceedings{ProbabilisticPriorKnowledgeIntegration,
	address = {Vancouver, BC, Canada},
	title = {A probabilistic prior knowledge integration method: {Application} to generative and discriminative models},
	isbn = {978-1-5090-0620-5},
	shorttitle = {A probabilistic prior knowledge integration method},
	url = {http://ieeexplore.ieee.org/document/7727788/},
	doi = {10.1109/IJCNN.2016.7727788},
	abstract = {Prior knowledge integration aims at taking advantage of cheap plentiful data to improve the efﬁciency of supervised learning procedures. For parametric models, however, it is a challenging task. In this contribution, we introduce a novel simple methodology to incorporate prior knowledge into a supervised objective function. We propose to introduce the prior knowledge in the form of joint probability of observations and labels. We discuss the nature of features in discriminative and generative models and hence, differences in priors integration. We illustrate the efﬁciency of the proposed method both by synthetic data sets and by our results on a realistic large-scale sequence labeling task.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2016 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	publisher = {IEEE},
	author = {Sokolovska, Nataliya and Artieres, Thierry},
	month = jul,
	year = {2016},
	keywords = {fatml, xai},
	pages = {4496--4503},
}

@incollection{DefiningProfilingNewType,
	address = {Dordrecht},
	title = {Defining {Profiling}: {A} {New} {Type} of {Knowledge}?},
	isbn = {978-1-4020-6913-0 978-1-4020-6914-7},
	shorttitle = {Defining {Profiling}},
	url = {http://link.springer.com/10.1007/978-1-4020-6914-7_2},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Profiling the {European} {Citizen}},
	publisher = {Springer Netherlands},
	author = {Hildebrandt, Mireille},
	editor = {Hildebrandt, Mireille and Gutwirth, Serge},
	year = {2008},
	doi = {10.1007/978-1-4020-6914-7_2},
	keywords = {fatml, xai},
	pages = {17--45},
}

@article{HumanintheloopActiveCovarianceLearning,
	title = {Human-in-the-loop {Active} {Covariance} {Learning} for {Improving} {Prediction} in {Small} {Data} {Sets}},
	url = {http://arxiv.org/abs/1902.09834},
	abstract = {Learning predictive models from small highdimensional data sets is a key problem in highdimensional statistics. Expert knowledge elicitation can help, and a strong line of work focuses on directly eliciting informative prior distributions for parameters. This either requires considerable statistical expertise or is laborious, as the emphasis has been on accuracy and not on efﬁciency of the process. Another line of work queries about importance of features one at a time, assuming them to be independent and hence missing covariance information. In contrast, we propose eliciting expert knowledge about pairwise feature similarities, to borrow statistical strength in the predictions, and using sequential decision making techniques to minimize the effort of the expert. Empirical results demonstrate improvement in predictive performance on both simulated and real data, in high-dimensional linear regression tasks, where we learn the covariance structure with a Gaussian process, based on sequential elicitation.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1902.09834 [cs, stat]},
	author = {Afrabandpey, Homayun and Peltola, Tomi and Kaski, Samuel},
	month = mar,
	year = {2019},
	note = {arXiv: 1902.09834},
	keywords = {fatml, xai},
}

@article{SupervisedTopicModels,
	title = {Supervised {Topic} {Models}},
	abstract = {We introduce supervised latent Dirichlet allocation (sLDA), a statistical model of labelled documents. The model accommodates a variety of response types. We derive a maximum-likelihood procedure for parameter estimation, which relies on variational approximations to handle intractable posterior expectations. Prediction problems motivate this research: we use the ﬁtted model to predict response values for new documents. We test sLDA on two real-world problems: movie ratings predicted from reviews, and web page popularity predicted from text descriptions. We illustrate the beneﬁts of sLDA versus modern regularized regression, as well as versus an unsupervised LDA analysis followed by a separate regression.},
	language = {en},
	author = {Mcauliffe, Jon D and Blei, David M},
	pages = {8},
}

@article{ExplainingNaturalLanguageArguments,
	title = {Towards {Explaining} {Natural} {Language} {Arguments} with {Background} {Knowledge}},
	abstract = {In this paper, we propose the task of argument explicitation, a task that makes the structure of a natural language argument explicit, as well as the background knowledge the argument is built on, in the form of implicit premises or contextual knowledge. The purpose of argument explicitation is to support the understanding of an argument by providing users with an end-to-end analysis that oﬀers a critical assessment of arguments including identiﬁcation of argument weaknesses. Besides, the results of the argument explicitation process can be used by machines to retrieve similar arguments as well as counter-arguments. We propose a framework for argument explicitation that joins a variety of AI and NLPbased argumentation mining sub-tasks that by now have mostly been treated separately in the literature. We identify the challenges this task entails, while at the same time highlighting the opportunities brought by the recent development of structured, external knowledge sources.},
	language = {en},
	author = {Hulpus, Ioana and Kobbe, Jonathan and Becker, Maria and Opitz, Juri and Hirst, Graeme and Meilicke, Christian and Nastase, Vivi and Stuckenschmidt, Heiner and Frank, Anette},
	keywords = {fatml, xai},
	pages = {16},
}

@article{ExplainableVideoActionReasoning,
	title = {Explainable {Video} {Action} {Reasoning} via {Prior} {Knowledge} and {State} {Transitions}},
	url = {http://arxiv.org/abs/1908.10700},
	abstract = {Human action analysis and understanding in videos is an important and challenging task. Although substantial progress has been made in past years, the explainability of existing methods is still limited. In this work, we propose a novel action reasoning framework that uses prior knowledge to explain semantic-level observations of video state changes. Our method takes advantage of both classical reasoning and modern deep learning approaches. Specifically, prior knowledge is defined as the information of a target video domain, including a set of objects, attributes and relationships in the target video domain, as well as relevant actions defined by the temporal attribute and relationship changes (i.e. state transitions). Given a video sequence, we first generate a scene graph on each frame to represent concerned objects, attributes and relationships. Then those scene graphs are linked by tracking objects across frames to form a spatio-temporal graph (also called video graph), which represents semantic-level video states. Finally, by sequentially examining each state transition in the video graph, our method can detect and explain how those actions are executed with prior knowledge, just like the logical manner of thinking by humans. Compared to previous works, the action reasoning results of our method can be explained by both logical rules and semantic-level observations of video content changes. Besides, the proposed method can be used to detect multiple concurrent actions with detailed information, such as who (particular objects), when (time), where (object locations) and how (what kind of changes). Experiments on a re-annotated dataset CAD-120 show the effectiveness of our method.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1908.10700 [cs]},
	author = {Zhuo, Tao and Cheng, Zhiyong and Zhang, Peng and Wong, Yongkang and Kankanhalli, Mohan},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.10700},
	keywords = {fatml, xai},
}

@article{RegularisingNonlinearModelsUsing,
	title = {Regularising {Non}-linear {Models} {Using} {Feature} {Side}-information},
	url = {http://arxiv.org/abs/1703.02570},
	abstract = {Very often features come with their own vectorial descriptions which provide detailed information about their properties. We refer to these vectorial descriptions as feature side-information. In the standard learning scenario, input is represented as a vector of features and the feature sideinformation is most often ignored or used only for feature selection prior to model ﬁtting. We believe that feature side-information which carries information about features intrinsic property will help improve model prediction if used in a proper way during learning process. In this paper, we propose a framework that allows for the incorporation of the feature side-information during the learning of very general model families to improve the prediction performance. We control the structures of the learned models so that they reﬂect features’ similarities as these are deﬁned on the basis of the side-information. We perform experiments on a number of benchmark datasets which show signiﬁcant predictive performance gains, over a number of baselines, as a result of the exploitation of the side-information.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1703.02570 [cs, stat]},
	author = {Mollaysa, Amina and Strasser, Pablo and Kalousis, Alexandros},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.02570},
	keywords = {fatml, xai},
}

@article{SemanticWebTechnologiesExplainable,
	title = {Semantic {Web} {Technologies} for {Explainable} {Machine} {Learning} {Models}: {A} {Literature} {Review}},
	abstract = {Due to their tremendous potential in predictive tasks, Machine Learning techniques such as Artiﬁcial Neural Networks have received great attention from both research and practice. However, often these models do not provide explainable outcomes which is a crucial requirement in many high stakes domains such as health care or transport. Regarding explainability, Semantic Web Technologies oﬀer semantically interpretable tools which allow reasoning on knowledge bases. Hence, the question arises how Semantic Web Technologies and related concepts can facilitate explanations in Machine Learning systems. To address this topic, we present current approaches of combining Machine Learning with Semantic Web Technologies in the context of model explainability based on a systematic literature review. In doing so, we also highlight domains and applications driving the research ﬁeld and discuss the ways in which explanations are given to the user. Drawing upon these insights, we suggest directions for further research on combining Semantic Web Technologies with Machine Learning.},
	language = {en},
	author = {Seeliger, Arne and Pfaﬀ, Matthias and Krcmar, Helmut},
	keywords = {fatml, xai},
	pages = {16},
}

@article{HumanintheloopPerspectiveAutoMLMilestones,
	title = {A {Human}-in-the-loop {Perspective} on {AutoML}: {Milestones} and the {Road} {Ahead}},
	language = {en},
	author = {Lee, Doris Jung-Lin and Macke, Stephen and Xin, Doris and Lee, Angela and Huang, Silu and Parameswaran, Aditya},
	pages = {12},
}

@article{PoorOutcomePredictionBurst,
	title = {Poor outcome prediction by burst suppression ratio in adults with post-anoxic coma without hypothermia},
	volume = {36},
	issn = {0161-6412, 1743-1328},
	url = {http://www.tandfonline.com/doi/full/10.1179/1743132814Y.0000000346},
	doi = {10.1179/1743132814Y.0000000346},
	language = {en},
	number = {5},
	urldate = {2019-12-29},
	journal = {Neurological Research},
	author = {Yang, Qinglin and Su, Yingying and Hussain, Mohammed and Chen, Weibi and Ye, Hong and Gao, Daiquan and Tian, Fei},
	month = may,
	year = {2014},
	pages = {453--460},
}

@article{EfficientInferenceLearningLarge,
	title = {Efficient inference and learning in a large knowledge base: {Reasoning} with extracted information using a locally groundable first-order probabilistic logic},
	volume = {100},
	issn = {0885-6125, 1573-0565},
	shorttitle = {Efficient inference and learning in a large knowledge base},
	url = {http://link.springer.com/10.1007/s10994-015-5488-x},
	doi = {10.1007/s10994-015-5488-x},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {Machine Learning},
	author = {Wang, William Yang and Mazaitis, Kathryn and Lao, Ni and Cohen, William W.},
	month = jul,
	year = {2015},
	pages = {101--126},
}

@article{DissertationSubmittedPartialFulfillment,
	title = {A dissertation submitted in partial fulﬁllment of the requirements for the degree of {Doctor} of {Philosophy}},
	language = {en},
	author = {Lalithsena, Sarasi},
	pages = {138},
}

@article{CorrelationClusteringBasedEfficient,
	title = {Correlation and {Clustering} based {Efficient} {Feature} {Subset} {Selection}},
	volume = {3},
	abstract = {Feature subset selection is an effective and efficient way for reducing dimensionality, removing irrelevant and redundant data, increasing learning accuracy and thus improving the quality of results in less time. Feature selection composes of identifying a subset of the most important and useful features that produce compatible results as the original entire set of features produces. A feature selection algorithm can be measured from both the efficiency and effectiveness points. The efficiency composes of the time required to find a subset of features, whereas effectiveness is related to the quality of the subset of features finally selected. Based on the above criteria, a Correlation and clustering-based feature selection algorithm, is proposed. The algorithm works in two stages. In the first stage, irrelevant features are removed using correlation between feature and class by using a user defined threshold, then in the second stage with the help of these relevant feature, redundant features are removed by constructing a max heap from the feature set, after that calculation of correlation between the feature - feature set for the edges present in the tree is done. A tree is formed which is divided into clusters, and from each cluster a strong representative feature is selected to give a final subset of feature. The feature of each cluster differs and is relatively independent of each other. The clustering-based technique has a high probability of producing a subset of useful and independent features.},
	language = {en},
	journal = {Journal of Engineering Technology},
	author = {Kumari, Preeti and Rajeswari, K and Vaithiyanathan, Dr V},
	year = {2015},
	keywords = {dm},
	pages = {10},
}

@article{FeatureSelectionCorrelationCoefficient,
	title = {Feature {Selection} via {Correlation} {Coefficient} {Clustering}},
	volume = {5},
	issn = {1796-217X},
	url = {http://ojs.academypublisher.com/index.php/jsw/article/view/3713},
	doi = {10.4304/jsw.5.12.1371-1377},
	abstract = {Feature selection is a fundamental problem in machine learning and data mining. How to choose the most problem-related features from a set of collected features is essential. In this paper, a novel method using correlation coefficient clustering in removing similar/redundant features is proposed. The collected features are grouped into clusters by measuring their correlation coefficient values. The most class-dependent feature in each cluster is retained while others in the same cluster are removed. Thus, the most class-related and mutually unrelated features are identified. The proposed method was applied to two datasets: the disordered protein dataset and the Arrhythmia (ARR) dataset. The experimental results show that the method is superior to other feature selection methods in speed and/or accuracy. Detail discussions are given in the paper.},
	language = {en},
	number = {12},
	urldate = {2019-12-29},
	journal = {Journal of Software},
	author = {Hsu, Hui-Huang and Hsieh, Cheng-Wei},
	month = dec,
	year = {2010},
	keywords = {clustering, dm, feature-selection},
	pages = {1371--1377},
}

@inproceedings{FeatureSelectionClustering,
	address = {Houston, TX, USA},
	title = {On {Feature} {Selection} through {Clustering}},
	isbn = {978-0-7695-2278-4},
	url = {http://ieeexplore.ieee.org/document/1565731/},
	doi = {10.1109/ICDM.2005.106},
	abstract = {We study an algorithm for feature selection that clusters attributes using a special metric and then makes use of the dendrogram of the resulting cluster hierarchy to choose the most relevant attributes. The main interest of our technique resides in the improved understanding of the structure of the analized data and of the relative importance of the attributes for the selection process.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Fifth {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM}'05)},
	publisher = {IEEE},
	author = {Butterworth, R. and Piatetsky-Shapiro, G. and Simovici, D.A.},
	year = {2005},
	keywords = {dm},
	pages = {581--584},
}

@article{CorrelationBasedFeatureSelection,
	title = {Correlation based feature selection with clustering for high dimensional data},
	volume = {5},
	issn = {23147172},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2314717218300059},
	doi = {10.1016/j.jesit.2017.06.004},
	abstract = {Feature selection is an essential technique to reduce the dimensionality problem in data mining task. Traditional feature selection algorithms are fail to scale on large space. This paper proposes a new method to solve dimensionality problem where clustering is integrating with correlation measure to produce good feature subset. First Irrelevant features are eliminated by using k-means clustering method and then non-redundant features are selected by correlation measure from each cluster. The proposed method is evaluate on Microarray and Text datasets and the results are compared with other renowned feature selection methods using Naïve Bayes classiﬁer. To verify the accuracy of the proposed method with different number of relevant features, percentagewise criteria is used. The experimental results reveal the efﬁciency and accuracy of the proposed method.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Journal of Electrical Systems and Information Technology},
	author = {Chormunge, Smita and Jena, Sudarson},
	month = dec,
	year = {2018},
	keywords = {clustering, dm, feature-selection},
	pages = {542--549},
}

@article{AntonymSynonymClassificationBasedNew,
	title = {Antonym-{Synonym} {Classification} {Based} on {New} {Sub}-{Space} {Embeddings}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	url = {http://www.aaai.org/ojs/index.php/AAAI/article/view/4579},
	doi = {10.1609/aaai.v33i01.33016204},
	abstract = {Distinguishing antonyms from synonyms is a key challenge for many NLP applications focused on the lexical-semantic relation extraction. Existing solutions relying on large-scale corpora yield low performance because of huge contextual overlap of antonym and synonym pairs. We propose a novel approach entirely based on pre-trained embeddings. We hypothesize that the pre-trained embeddings comprehend a blend of lexical-semantic information and we may distill the task-speciﬁc information using Distiller, a model proposed in this paper. Later, a classiﬁer is trained based on features constructed from the distilled sub-spaces along with some word level features to distinguish antonyms from synonyms. Experimental results show that the proposed model outperforms existing research on antonym synonym distinction in both speed and performance.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Ali, Muhammad Asif and Sun, Yifang and Zhou, Xiaoling and Wang, Wei and Zhao, Xiang},
	month = jul,
	year = {2019},
	pages = {6204--6211},
}

@article{AssociationRuleBasedApproach,
	title = {An association rule based approach to reducing visual clutter in parallel sets},
	volume = {3},
	issn = {2468502X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2468502X1930021X},
	doi = {10.1016/j.visinf.2019.03.006},
	abstract = {Although Parallel Sets, a popular categorical data visualization technique, intuitively reveals the frequency based relationships in details, a high-dimensional categorical dataset brings a cluttered visual display that seriously obscures the relationship explorations. Association rule mining is a popular approach to discovering relationships among categorical variables. It could complement Parallel Sets to group ribbons in a meaningful way. However, it is difficult to understand a larger number of rules discovered from a high-dimensional categorical dataset. In this paper, we integrate the two approaches into a visual analytics system for exploring high-dimensional categorical data with dichotomous outcome. The system not only helps users interpret association rules intuitively, but also provides an effective dimension and category reduction approach towards a less clustered and more organized visualization. The effectiveness and efficiency of our approach are illustrated by a set of user studies and experiments with benchmark datasets.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {Visual Informatics},
	author = {Zhang, Chong and Chen, Yang and Yang, Jing and Yin, Zhengcong},
	month = mar,
	year = {2019},
	pages = {48--57},
}

@article{ImprovingGenderClassificationBlog,
	title = {Improving {Gender} {Classification} of {Blog} {Authors}},
	abstract = {The problem of automatically classifying the gender of a blog author has important applications in many commercial domains. Existing systems mainly use features such as words, word classes, and POS (part-ofspeech) n-grams, for classification learning. In this paper, we propose two new techniques to improve the current result. The first technique introduces a new class of features which are variable length POS sequence patterns mined from the training data using a sequence pattern mining algorithm. The second technique is a new feature selection method which is based on an ensemble of several feature selection criteria and approaches. Empirical evaluation using a real-life blog data set shows that these two techniques improve the classification accuracy of the current state-ofthe-art methods significantly.},
	language = {en},
	author = {Mukherjee, Arjun and Liu, Bing},
	pages = {11},
}

@article{KnowEduSystemConstructKnowledge,
	title = {{KnowEdu}: {A} {System} to {Construct} {Knowledge} {Graph} for {Education}},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {{KnowEdu}},
	url = {https://ieeexplore.ieee.org/document/8362657/},
	doi = {10.1109/ACCESS.2018.2839607},
	abstract = {Motivated by the vast applications of knowledge graph and the increasing demand in education domain, we propose a system, called KnowEdu, to automatically construct knowledge graph for education. By leveraging on heterogeneous data (e.g., pedagogical data and learning assessment data) from the education domain, this system ﬁrst extracts the concepts of subjects or courses and then identiﬁes the educational relations between the concepts. More speciﬁcally, it adopts the neural sequence labeling algorithm on pedagogical data to extract instructional concepts and employs probabilistic association rule mining on learning assessment data to identify the relations with educational signiﬁcance. We detail all the abovementioned efforts through an exemplary case of constructing a demonstrative knowledge graph for mathematics, where the instructional concepts and their prerequisite relations are derived from curriculum standards and concept-based performance data of students. Evaluation results show that the F1 score for concept extraction exceeds 0.70, and for relation identiﬁcation, the area under the curve and mean average precision achieve 0.95 and 0.87, respectively.},
	language = {en},
	urldate = {2019-12-29},
	journal = {IEEE Access},
	author = {Chen, Penghe and Lu, Yu and Zheng, Vincent W. and Chen, Xiyang and Yang, Boda},
	year = {2018},
	pages = {31553--31563},
}

@article{AIEducationNeedsInterpretable,
	title = {{AI} in {Education} needs interpretable machine learning: {Lessons} from {Open} {Learner} {Modelling}},
	shorttitle = {{AI} in {Education} needs interpretable machine learning},
	url = {http://arxiv.org/abs/1807.00154},
	abstract = {Interpretability of the underlying AI representations is a key raison d'{\textbackslash}{\textasciicircum}\{e\}tre for Open Learner Modelling (OLM) -- a branch of Intelligent Tutoring Systems (ITS) research. OLMs provide tools for 'opening' up the AI models of learners' cognition and emotions for the purpose of supporting human learning and teaching. Over thirty years of research in ITS (also known as AI in Education) produced important work, which informs about how AI can be used in Education to best effects and, through the OLM research, what are the necessary considerations to make it interpretable and explainable for the benefit of learning. We argue that this work can provide a valuable starting point for a framework of interpretable AI, and as such is of relevance to the application of both knowledge-based and machine learning systems in other high-stakes contexts, beyond education.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1807.00154 [cs]},
	author = {Conati, Cristina and Porayska-Pomsta, Kaska and Mavrikis, Manolis},
	month = jun,
	year = {2018},
	note = {arXiv: 1807.00154},
}

@article{CanWeBetterExplanations,
	title = {Can we do better explanations? {A} proposal of {User}-{Centered} {Explainable} {AI}},
	abstract = {Artificial Intelligence systems are spreading to multiple applications and they are used by a more diverse audience. With this change of the use scenario, AI users will increasingly require explanations. The first part of this paper makes a review of the state of the art of Explainable AI and highlights how the current research is not paying enough attention to whom the explanations are targeted. In the second part of the paper, it is suggested a new explainability pipeline, where users are classified in three main groups (developers or AI researchers, domain experts and lay users). Inspired by the cooperative principles of conversations, it is discussed how creating different explanations for each of the targeted groups can overcome some of the difficulties related to creating good explanations and evaluating them.},
	language = {en},
	journal = {Los Angeles},
	author = {Ribera, Mireia and Lapedriza, Agata},
	year = {2019},
	pages = {7},
}

@article{SimpleAlgorithmsPeakDetection,
	title = {Simple {Algorithms} for {Peak} {Detection} in {Time}-{Series}},
	abstract = {Identifying and analyzing peaks (or spikes) in a given time-series is important in many applications. Peaks indicate significant events such as sudden increase in price/volume, sharp rise in demand, bursts in data traffic etc. While it is easy to visually identify peaks in a small univariate time-series, there is a need to formalize the notion of a peak to avoid subjectivity and to devise algorithms to automatically detect peaks in any given time-series. The latter is important in applications such as data center monitoring where thousands of large time-series indicating CPU/memory utilization need to be analyzed in real-time. A data point in a time-series is a local peak if (a) it is a large and locally maximum value within a window, which is not necessarily large nor globally maximum in the entire time-series; and (b) it is isolated i.e., not too many points in the window have similar values. Not all local peaks are true peaks; a local peak is a true peak if it is a reasonably large value even in the global context. We offer different formalizations of the notion of a peak and propose corresponding algorithms to detect peaks in the given time-series. We experimentally compare the effectiveness of these algorithms.},
	language = {en},
	author = {Palshikar, Girish Keshav},
	pages = {14},
}

@article{ImportanceBeingCoherentCategory,
	title = {The importance of being coherent: {Category} coherence, cross-classification, and reasoning☆},
	volume = {54},
	issn = {0749596X},
	shorttitle = {The importance of being coherent},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X05001270},
	doi = {10.1016/j.jml.2005.10.005},
	abstract = {Category-based inference is crucial for using past experiences to make sense of new ones. One challenge to inference of this kind is that most entities in the world belong to multiple categories (e.g., a jogger, a professor, and a vegetarian). We tested the hypothesis that the degree of coherence of a category—the degree to which category features go together in light of prior knowledge—inﬂuences the extent to which one category will be used over another in property inference. The ﬁrst two experiments demonstrate that when multiple social categories are available, high coherence categories are selected and used as the basis of inference more often than less coherent ones. The second two experiments provide evidence that ease of category-based explanation of properties is a viable account for coherence diﬀerences. We conclude that degree of coherence meaningfully applies to natural social categories, and is an important inﬂuence on category use in reasoning.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Journal of Memory and Language},
	author = {Patalano, A and Chinparker, S and Ross, B},
	month = apr,
	year = {2006},
	pages = {407--424},
}

@inproceedings{AttentionFocusingNeuralMachine,
	address = {Melbourne, Australia},
	title = {Attention {Focusing} for {Neural} {Machine} {Translation} by {Bridging} {Source} and {Target} {Embeddings}},
	url = {http://aclweb.org/anthology/P18-1164},
	doi = {10.18653/v1/P18-1164},
	abstract = {In neural machine translation, a source sequence of words is encoded into a vector from which a target sequence is generated in the decoding phase. Differently from statistical machine translation, the associations between source words and their possible target counterparts are not explicitly stored. Source and target words are at the two ends of a long information processing procedure, mediated by hidden states at both the source encoding and the target decoding phases. This makes it possible that a source word is incorrectly translated into a target word that is not any of its admissible equivalent counterparts in the target language.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Kuang, Shaohui and Li, Junhui and Branco, António and Luo, Weihua and Xiong, Deyi},
	year = {2018},
	pages = {1767--1776},
}

@inproceedings{JointlyEmbeddingKnowledgeGraphs,
	address = {Austin, Texas},
	title = {Jointly {Embedding} {Knowledge} {Graphs} and {Logical} {Rules}},
	url = {http://aclweb.org/anthology/D16-1019},
	doi = {10.18653/v1/D16-1019},
	abstract = {Embedding knowledge graphs into continuous vector spaces has recently attracted increasing interest. Most existing methods perform the embedding task using only fact triples. Logical rules, although containing rich background information, have not been well studied in this task. This paper proposes a novel method of jointly embedding knowledge graphs and logical rules. The key idea is to represent and model triples and rules in a uniﬁed framework. Speciﬁcally, triples are represented as atomic formulae and modeled by the translation assumption, while rules represented as complex formulae and modeled by t-norm fuzzy logics. Embedding then amounts to minimizing a global loss over both atomic and complex formulae. In this manner, we learn embeddings compatible not only with triples but also with rules, which will certainly be more predictive for knowledge acquisition and inference. We evaluate our method with link prediction and triple classiﬁcation tasks. Experimental results show that joint embedding brings significant and consistent improvements over stateof-the-art methods. Particularly, it enhances the prediction of new facts which cannot even be directly inferred by pure logical inference, demonstrating the capability of our method to learn more predictive embeddings.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 2016 {Conference} on {Empirical} {Methods} in {Natural}           {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Guo, Shu and Wang, Quan and Wang, Lihong and Wang, Bin and Guo, Li},
	year = {2016},
	pages = {192--202},
}

@article{ExplanationsIntelligentSystemsTheoretical,
	title = {Explanations from {Intelligent} {Systems}: {Theoretical} {Foundations} and {Implications} for {Practice}},
	volume = {23},
	issn = {02767783},
	shorttitle = {Explanations from {Intelligent} {Systems}},
	url = {https://www.jstor.org/stable/249487?origin=crossref},
	doi = {10.2307/249487},
	abstract = {Information systems with an "intelligent" or "knowledge" component are now prevalent and include knowledge-based systems, decision support systems, intelligent agents, and knowledge management systems. These systems are in principle capable of explaining their reasoning or justifying their behavior. There appears to be a lack of understanding, however, of the benefits that can flow from explanation use, and how an explanation function should be constructed.},
	language = {en},
	number = {4},
	urldate = {2019-12-29},
	journal = {MIS Quarterly},
	author = {Gregor, Shirley and Benbasat, Izak},
	month = dec,
	year = {1999},
	pages = {497},
}

@inproceedings{ArgumentationBasedExplanationsRecommenderSystems,
	address = {Singapore, Singapore},
	title = {Argumentation-{Based} {Explanations} in {Recommender} {Systems}: {Conceptual} {Framework} and {Empirical} {Results}},
	isbn = {978-1-4503-5784-5},
	shorttitle = {Argumentation-{Based} {Explanations} in {Recommender} {Systems}},
	url = {http://dl.acm.org/citation.cfm?doid=3213586.3225240},
	doi = {10.1145/3213586.3225240},
	abstract = {Explaining automatically generated recommendations has shown to be an effective means for supporting the user’s decision-making process and increasing system transparency. However, present methods mostly provide non-personalized explanations that are presented in an unstructured manner. We propose a framework based on Toulmin’s model designed to generate explanations in an argumentative style by presenting supportive as well as critical information about recommended items and their features. Existing research suggests that argumentative explanations cannot be assumed as equally effective for everyone. People rather tend to either apply rational or intuitive decision-making styles that determine which kinds of information are preferably taken into account. In an experimental user study, we investigated the effectiveness of argumentative explanations while considering the moderating effect of these two different cognitive styles. The results indicate that argumentative explanations, as compared to baseline methods, lead to, among others, increased perceived explanation quality, information sufficiency and overall satisfaction with the system. However, this seems only to be true for intuitive thinkers who rely more on explanations in complex decision situations as compared to rational thinkers.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Adjunct {Publication} of the 26th {Conference} on {User} {Modeling}, {Adaptation} and {Personalization}  - {UMAP} '18},
	publisher = {ACM Press},
	author = {Naveed, Sidra and Donkers, Tim and Ziegler, Jürgen},
	year = {2018},
	pages = {293--298},
}

@article{HowMindExplainsBehavior,
	title = {How the {Mind} {Explains} {Behavior}},
	language = {en},
	author = {Malle, Bertram F},
	keywords = {fatml, xai},
	pages = {31},
}

@article{ExplainableAIBewareInmates,
	title = {Explainable {AI}: {Beware} of {Inmates} {Running} the {Asylum} {Or}: {How} {I} {Learnt} to {Stop} {Worrying} and {Love} the {Social} and {Behavioural} {Sciences}},
	shorttitle = {Explainable {AI}},
	url = {http://arxiv.org/abs/1712.00547},
	abstract = {In his seminal book The Inmates are Running the Asylum: Why High-Tech Products Drive Us Crazy And How To Restore The Sanity [2004, Sams Indianapolis, IN, USA], Alan Cooper argues that a major reason why software is often poorly designed (from a user perspective) is that programmers are in charge of design decisions, rather than interaction designers. As a result, programmers design software for themselves, rather than for their target audience; a phenomenon he refers to as the ‘inmates running the asylum’. This paper argues that explainable AI risks a similar fate. While the reemergence of explainable AI is positive, this paper argues most of us as AI researchers are building explanatory agents for ourselves, rather than for the intended users. But explainable AI is more likely to succeed if researchers and practitioners understand, adopt, implement, and improve models from the vast and valuable bodies of research in philosophy, psychology, and cognitive science; and if evaluation of these models is focused more on people than on technology. From a light scan of literature, we demonstrate that there is considerable scope to infuse more results from the social and behavioural sciences into explainable AI, and present some key results from these ﬁelds that are relevant to explainable AI.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1712.00547 [cs]},
	author = {Miller, Tim and Howe, Piers and Sonenberg, Liz},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.00547},
	keywords = {fatml, xai},
}

@article{NEWYORKUNIVERSITYTANDON,
	title = {{NEW} {YORK} {UNIVERSITY} {TANDON} {SCHOOL} {OF} {ENGINEERING}},
	language = {en},
	author = {Krause, Josua Walter Hugo},
	pages = {211},
}

@article{RelationalInductiveBiasesDeep,
	title = {Relational inductive biases, deep learning, and graph networks},
	url = {http://arxiv.org/abs/1806.01261},
	abstract = {Artiﬁcial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have ﬁt the natural strengths of deep learning. However, many deﬁning characteristics of human intelligence, which developed under much diﬀerent pressures, remain out of reach for current approaches. In particular, generalizing beyond one’s experiences—a hallmark of human intelligence from infancy—remains a formidable challenge for modern AI.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1806.01261 [cs, stat]},
	author = {Battaglia, Peter W. and Hamrick, Jessica B. and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and Gulcehre, Caglar and Song, Francis and Ballard, Andrew and Gilmer, Justin and Dahl, George and Vaswani, Ashish and Allen, Kelsey and Nash, Charles and Langston, Victoria and Dyer, Chris and Heess, Nicolas and Wierstra, Daan and Kohli, Pushmeet and Botvinick, Matt and Vinyals, Oriol and Li, Yujia and Pascanu, Razvan},
	month = oct,
	year = {2018},
	note = {arXiv: 1806.01261},
}

@article{ExplainingModelsEmpiricalStudy,
	title = {Explaining {Models}: {An} {Empirical} {Study} of {How} {Explanations} {Impact} {Fairness} {Judgment}},
	shorttitle = {Explaining {Models}},
	url = {http://arxiv.org/abs/1901.07694},
	doi = {10.1145/3301275.3302310},
	abstract = {Ensuring fairness of machine learning systems is a human-in-theloop process. It relies on developers, users, and the general public to identify fairness problems and make improvements. To facilitate the process we need effective, unbiased, and user-friendly explanations that people can confidently rely on. Towards that end, we conducted an empirical study with four types of programmatically generated explanations to understand how they impact people’s fairness judgments of ML systems. With an experiment involving more than 160 Mechanical Turk workers, we show that: 1) Certain explanations are considered inherently less fair, while others can enhance people’s confidence in the fairness of the algorithm; 2) Different fairness problems–such as model-wide fairness issues versus casespecific fairness discrepancies–may be more effectively exposed through different styles of explanation; 3) Individual differences, including prior positions and judgment criteria of algorithmic fairness, impact how people react to different styles of explanation. We conclude with a discussion on providing personalized and adaptive explanations to support fairness judgments of ML systems.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Proceedings of the 24th International Conference on Intelligent User Interfaces - IUI '19},
	author = {Dodge, Jonathan and Liao, Q. Vera and Zhang, Yunfeng and Bellamy, Rachel K. E. and Dugan, Casey},
	year = {2019},
	note = {arXiv: 1901.07694},
	pages = {275--285},
}

@article{EffectiveEndUserInteractionMachine,
	title = {Effective {End}-{User} {Interaction} with {Machine} {Learning}},
	abstract = {End-user interactive machine learning is a promising tool for enhancing human productivity and capabilities with large unstructured data sets. Recent work has shown that we can create end-user interactive machine learning systems for specific applications. However, we still lack a generalized understanding of how to design effective end-user interaction with interactive machine learning systems. This work presents three explorations in designing for effective end-user interaction with machine learning in CueFlik, a system developed to support Web image search. These explorations demonstrate that interactions designed to balance the needs of end-users and machine learning algorithms can significantly improve the effectiveness of end-user interactive machine learning.},
	language = {en},
	author = {Amershi, Saleema and Fogarty, James and Kapoor, Ashish and Tan, Desney},
	pages = {4},
}

@inproceedings{HumanguidedMachineLearninga,
	address = {Marina del Ray, California},
	title = {Towards human-guided machine learning},
	isbn = {978-1-4503-6272-6},
	url = {http://dl.acm.org/citation.cfm?doid=3301275.3302324},
	doi = {10.1145/3301275.3302324},
	abstract = {Automated Machine Learning (AutoML) systems are emerging that automatically search for possible solutions from a large space of possible kinds of models. Although fully automated machine learning is appropriate for many applications, users often have knowledge that supplements and constraints the available data and solutions. This paper proposes human-guided machine learning (HGML) as a hybrid approach where a user interacts with an AutoML system and tasks it to explore different problem settings that reflect the user’s knowledge about the data available. We present: 1) a task analysis of HGML that shows the tasks that a user would want to carry out, 2) a characterization of two scientific publications, one in neuroscience and one in political science, in terms of how the authors would search for solutions using an AutoML system, 3) requirements for HGML based on those characterizations, and 4) an assessment of existing AutoML systems in terms of those requirements.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '19},
	publisher = {ACM Press},
	author = {Gil, Yolanda and Honaker, James and Gupta, Shikhar and Ma, Yibo and D'Orazio, Vito and Garijo, Daniel and Gadewar, Shruti and Yang, Qifan and Jahanshad, Neda},
	year = {2019},
	pages = {614--624},
}

@article{OpenKEOpenToolkitKnowledge,
	title = {{OpenKE}: {An} {Open} {Toolkit} for {Knowledge} {Embedding}},
	abstract = {We release an open toolkit for knowledge embedding (OpenKE), which provides a uniﬁed framework and various fundamental models to embed knowledge graphs into a continuous low-dimensional space. OpenKE prioritizes operational efﬁciency to support quick model validation and large-scale knowledge representation learning. Meanwhile, OpenKE maintains sufﬁcient modularity and extensibility to easily incorporate new models into the framework. Besides the toolkit, the embeddings of some existing large-scale knowledge graphs pre-trained by OpenKE are also available, which can be directly applied for many applications including information retrieval, personalized recommendation and question answering. The toolkit, documentation, and pre-trained embeddings are all released on http://openke.thunlp.org/.},
	language = {en},
	author = {Han, Xu and Cao, Shulin and Lv, Xin and Lin, Yankai and Liu, Zhiyuan and Sun, Maosong and Li, Juanzi},
	pages = {6},
}

@article{WomanWorkedBabysitterBiases,
	title = {The {Woman} {Worked} as a {Babysitter}: {On} {Biases} in {Language} {Generation}},
	shorttitle = {The {Woman} {Worked} as a {Babysitter}},
	url = {http://arxiv.org/abs/1909.01326},
	abstract = {We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a deﬁning metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classiﬁer through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1909.01326 [cs]},
	author = {Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
	month = oct,
	year = {2019},
	note = {arXiv: 1909.01326},
}

@article{KnowledgeGraphbasedApproachExploring,
	title = {A {Knowledge} {Graph}-based {Approach} for {Exploring} the {U}.{S}. {Opioid} {Epidemic}},
	url = {http://arxiv.org/abs/1905.11513},
	abstract = {The United States is in the midst of an opioid epidemic with recent estimates indicating that more than 130 people die every day due to drug overdose. The overprescription and addiction to opioid painkillers, heroin, and synthetic opioids, has led to a public health crisis and created a huge social and economic burden. Statistical learning methods that use data from multiple clinical centers across the US to detect opioid over-prescribing trends and predict possible opioid misuse are required. However, the semantic heterogeneity in the representation of clinical data across different centers makes the development and evaluation of such methods difﬁcult and non-trivial. We create the Opioid Drug Knowledge Graph (ODKG) – a network of opioid-related drugs, active ingredients, formulations, combinations, and brand names. We use the ODKG to normalize drug strings in a clinical data warehouse consisting of patient data from over 400 healthcare facilities in 42 different states. We showcase the use of ODKG to generate summary statistics of opioid prescription trends across US regions. These methods and resources can aid the development of advanced and scalable models to monitor the opioid epidemic and to detect illicit opioid misuse behavior. Our work is relevant to policymakers and pain researchers who wish to systematically assess factors that contribute to opioid over-prescribing and iatrogenic opioid addiction in the US.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1905.11513 [cs]},
	author = {Kamdar, Maulik R. and Hamamsy, Tymor and Shelton, Shea and Vala, Ayin and Eftimov, Tome and Zou, James and Tamang, Suzanne},
	month = may,
	year = {2019},
	note = {arXiv: 1905.11513},
}

@article{WeBuildAIParticipatoryFrameworkAlgorithmic,
	title = {{WeBuildAI}: {Participatory} {Framework} for {Algorithmic} {Governance}},
	volume = {3},
	issn = {25730142},
	shorttitle = {{WeBuildAI}},
	url = {http://dl.acm.org/citation.cfm?doid=3371885.3359283},
	doi = {10.1145/3359283},
	language = {en},
	number = {CSCW},
	urldate = {2019-12-29},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lee, Min Kyung and Psomas, Alexandros and Procaccia, Ariel D. and Kusbit, Daniel and Kahng, Anson and Kim, Ji Tae and Yuan, Xinran and Chan, Allissa and See, Daniel and Noothigattu, Ritesh and Lee, Siheon},
	month = nov,
	year = {2019},
	pages = {1--35},
}

@inproceedings{AligningCrossLingualEntitiesMultiAspect,
	address = {Hong Kong, China},
	title = {Aligning {Cross}-{Lingual} {Entities} with {Multi}-{Aspect} {Information}},
	url = {https://www.aclweb.org/anthology/D19-1451},
	doi = {10.18653/v1/D19-1451},
	abstract = {Multilingual knowledge graphs (KGs), such as YAGO and DBpedia, represent entities in different languages. The task of cross-lingual entity alignment is to match entities in a source language with their counterparts in target languages. In this work, we investigate embedding-based approaches to encode entities from multilingual KGs into the same vector space, where equivalent entities are close to each other. Speciﬁcally, we apply graph convolutional networks (GCNs) to combine multiaspect information of entities, including topological connections, relations, and attributes of entities, to learn entity embeddings. To exploit the literal descriptions of entities expressed in different languages, we propose two uses of a pretrained multilingual BERT model to bridge cross-lingual gaps. We further propose two strategies to integrate GCN-based and BERTbased modules to boost performance. Extensive experiments on two benchmark datasets demonstrate that our method signiﬁcantly outperforms existing systems.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Yang, Hsiu-Wei and Zou, Yanyan and Shi, Peng and Lu, Wei and Lin, Jimmy and Sun, Xu},
	year = {2019},
	pages = {4430--4440},
}

@article{StateArtIntegratingMachine,
	title = {The {State} of the {Art} in {Integrating} {Machine} {Learning} into {Visual} {Analytics}},
	volume = {36},
	issn = {01677055},
	url = {http://arxiv.org/abs/1802.07954},
	doi = {10.1111/cgf.13092},
	abstract = {Visual analytics systems combine machine learning or other analytic techniques with interactive data visualization to promote sensemaking and analytical reasoning. It is through such techniques that people can make sense of large, complex data. While progress has been made, the tactful combination of machine learning and data visualization is still under-explored. This state-of-the-art report presents a summary of the progress that has been made by highlighting and synthesizing select research advances. Further, it presents opportunities and challenges to enhance the synergy between machine learning and visual analytics for impactful future research directions.},
	language = {en},
	number = {8},
	urldate = {2019-12-29},
	journal = {Computer Graphics Forum},
	author = {Endert, A. and Ribarsky, W. and Turkay, C. and Wong, W. and Nabney, I. and Blanco, I. Díaz and Rossi, Fabrice},
	month = dec,
	year = {2017},
	note = {arXiv: 1802.07954},
	pages = {458--486},
}

@article{VisualizationMachineLearning,
	title = {Visualization for {Machine} {Learning}},
	language = {en},
	author = {Viégas, Fernanda and Wattenberg, Martin},
	pages = {145},
}

@article{LanguageModelsKnowledgeBases,
	title = {Language {Models} as {Knowledge} {Bases}?},
	url = {http://arxiv.org/abs/1909.01066},
	abstract = {Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as “ﬁllin-the-blank” cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without ﬁne-tuning) in a wide range of state-of-theart pretrained language models. We ﬁnd that (i) without ﬁne-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any ﬁne-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https: //github.com/facebookresearch/LAMA.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1909.01066 [cs]},
	author = {Petroni, Fabio and Rocktäschel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H. and Riedel, Sebastian},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.01066},
}

@article{InterpretablePriorsHyperparametersGaussian,
	title = {Interpretable {Priors} for {Hyperparameters} for {Gaussian} {Random} {Fields}},
	abstract = {Gaussian random ﬁelds (GRFs) are important building blocks in hierarchical models for spatial data, but there is no practically useful, principled approach for selecting the prior on their hyperparameters. The prior is typically chosen in an ad-hoc manner, which lacks theoretical justiﬁcation, despite the fact that we know that the hyperparameters are not consistently estimable from a single realization and that there is sensitivity to the choice of the prior.},
	language = {en},
	author = {Fuglstad, Geir-Arne and Simpson, Daniel and Lindgren, Finn and Rue, Håvard},
	keywords = {fatml, xai},
	pages = {33},
}

@article{FlowSenseNaturalLanguageInterface,
	title = {{FlowSense}: {A} {Natural} {Language} {Interface} for {Visual} {Data} {Exploration} within a {Dataflow} {System}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{FlowSense}},
	url = {https://ieeexplore.ieee.org/document/8807265/},
	doi = {10.1109/TVCG.2019.2934668},
	abstract = {Dataﬂow visualization systems enable ﬂexible visual data exploration by allowing the user to construct a dataﬂow diagram that composes query and visualization modules to specify system functionality. However learning dataﬂow diagram usage presents overhead that often discourages the user. In this work we design FlowSense, a natural language interface for dataﬂow visualization systems that utilizes state-of-the-art natural language processing techniques to assist dataﬂow diagram construction. FlowSense employs a semantic parser with special utterance tagging and special utterance placeholders to generalize to different datasets and dataﬂow diagrams. It explicitly presents recognized dataset and diagram special utterances to the user for dataﬂow context awareness. With FlowSense the user can expand and adjust dataﬂow diagrams more conveniently via plain English. We apply FlowSense to the VisFlow subset-ﬂow visualization system to enhance its usability. We evaluate FlowSense by one case study with domain experts on a real-world data analysis problem and a formal user study.},
	language = {en},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Yu, Bowen and Silva, Claudio T.},
	year = {2019},
	keywords = {vis},
	pages = {1--1},
}

@article{EvaluationHumanInterpretabilityExplanation,
	title = {An {Evaluation} of the {Human}-{Interpretability} of {Explanation}},
	url = {http://arxiv.org/abs/1902.00006},
	abstract = {Recent years have seen a boom in interest in machine learning systems that can provide a human-understandable rationale for their predictions or decisions. However, exactly what kinds of explanation are truly human-interpretable remains poorly understood. This work advances our understanding of what makes explanations interpretable under three speciﬁc tasks that users may perform with machine learning systems: simulation of the response, veriﬁcation of a suggested response, and determining whether the correctness of a suggested response changes under a change to the inputs. Through carefully controlled human-subject experiments, we identify regularizers that can be used to optimize for the interpretability of machine learning systems. Our results show that the type of complexity matters: cognitive chunks (newly deﬁned concepts) affect performance more than variable repetitions, and these trends are consistent across tasks and domains. This suggests that there may exist some common design principles for explanation systems.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1902.00006 [cs, stat]},
	author = {Lage, Isaac and Chen, Emily and He, Jeffrey and Narayanan, Menaka and Kim, Been and Gershman, Sam and Doshi-Velez, Finale},
	month = aug,
	year = {2019},
	note = {arXiv: 1902.00006},
	keywords = {fatml, xai},
}

@inproceedings{SAXNavigatorTimeSeriesa,
	address = {Vancouver, BC, Canada},
	title = {{SAX} {Navigator}: {Time} {Series} {Exploration} through {Hierarchical} {Clustering}},
	isbn = {978-1-72814-941-7},
	shorttitle = {{SAX} {Navigator}},
	url = {https://ieeexplore.ieee.org/document/8933618/},
	doi = {10.1109/VISUAL.2019.8933618},
	abstract = {Comparing many long time series is challenging to do by hand. Clustering time series enables data analysts to discover relevance between and anomalies among multiple time series. However, even after reasonable clustering, analysts have to scrutinize correlations between clusters or similarities within a cluster. We developed SAX Navigator, an interactive visualization tool, that allows users to hierarchically explore global patterns as well as individual observations across large collections of time series data. Our visualization provides a unique way to navigate time series that involves a “vocabulary of patterns” developed by using a dimensionality reduction technique, Symbolic Aggregate approXimation (SAX). With SAX, the time series data clusters efﬁciently and is quicker to query at scale. We demonstrate the ability of SAX Navigator to analyze patterns in large time series data based on three case studies for an astronomy data set. We verify the usability of our system through a think-aloud study with an astronomy domain scientist.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2019 {IEEE} {Visualization} {Conference} ({VIS})},
	publisher = {IEEE},
	author = {Ruta, Nicholas and Sawada, Naoko and McKeough, Katy and Behrisch, Michael and Beyer, Johanna},
	month = oct,
	year = {2019},
	keywords = {vis},
	pages = {236--240},
}

@article{RETHINKINGEXPLAINABLEMACHINESGDPR,
	title = {{RETHINKING} {EXPLAINABLE} {MACHINES}: {THE} {GDPR}’{S} “{RIGHT} {TO} {EXPLANATION}” {DEBATE} {AND} {THE} {RISE} {OF} {ALGORITHMIC} {AUDITS} {IN} {ENTERPRISE}},
	volume = {34},
	abstract = {The public debate surrounding the General Data Protection Regulation’s (GDPR) “right to explanation” has sparked a global conversation of profound social and economic significance. But from a practical perspective, the debate’s participants have gotten ahead of themselves. In their search for a revolutionary new data protection within the provisions of a single chapter of the GDPR, many prominent contributors to the debate have lost sight of the most revolutionary change ushered in by the Regulation: the sweeping new enforcement powers given to European data protection authorities (DPAs) by Chapters 6 and 8 of the Regulation. Unlike the 1995 Data Protection Directive that it replaced, the GDPR’s potent new investigatory, advisory, corrective, and punitive powers granted by Chapters 6 and 8 render DPAs de facto interpretive authorities of the Regulation’s controversial “right to explanation.” Now that the DPAs responsible for enforcing the right have officially weighed in, this Article argues that at least one matter of fierce public debate can be laid to rest. The GDPR provides a muscular “right to explanation” with sweeping legal implications for the design, prototyping, field testing, and deployment of automated data processing systems. The protections enshrined within the right may not mandate transparency in the form of a complete individualized explanation. But a holistic understanding of the interpretation by DPAs reveals that the right’s true power derives from its synergistic effects when combined with the algorithmic auditing and “data protection by design” methodologies codified by the Regulation’s subsequent chapters. Accordingly, this Article predicts that algorithmic auditing and “data protection by design” practices will likely become the new gold standard for enterprises deploying machine learning systems both inside and outside of the European Union.},
	language = {en},
	author = {Casey, Bryan and Farhangi, Ashkon and Vogl, Roland},
	keywords = {fatml, xai},
	pages = {46},
}

@article{GraphRegularizedNonnegativeMatrixa,
	title = {Graph {Regularized} {Nonnegative} {Matrix} {Factorization} for {Data} {Representation}},
	volume = {33},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/5674058/},
	doi = {10.1109/TPAMI.2010.231},
	abstract = {Matrix factorization techniques have been frequently applied in information retrieval, computer vision and pattern recognition. Among them, Non-negative Matrix Factorization (NMF) has received considerable attention due to its psychological and physiological interpretation of naturally occurring data whose representation may be parts-based in the human brain. On the other hand, from the geometric perspective, the data is usually sampled from a low dimensional manifold embedded in a high dimensional ambient space. One hopes then to ﬁnd a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. In this paper, we propose a novel algorithm, called Graph Regularized Non-negative Matrix Factorization (GNMF), for this purpose. In GNMF, an afﬁnity graph is constructed to encode the geometrical information, and we seek a matrix factorization which respects the graph structure. Our empirical study shows encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real world problems.},
	language = {en},
	number = {8},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {{Deng Cai} and {Xiaofei He} and {Jiawei Han} and Huang, T S},
	month = aug,
	year = {2011},
	keywords = {dm},
	pages = {1548--1560},
}

@inproceedings{FactorizationMeetsItemEmbedding,
	address = {Boston, Massachusetts, USA},
	title = {Factorization {Meets} the {Item} {Embedding}: {Regularizing} {Matrix} {Factorization} with {Item} {Co}-occurrence},
	isbn = {978-1-4503-4035-9},
	shorttitle = {Factorization {Meets} the {Item} {Embedding}},
	url = {http://dl.acm.org/citation.cfm?doid=2959100.2959182},
	doi = {10.1145/2959100.2959182},
	abstract = {Matrix factorization (MF) models and their extensions are standard in modern recommender systems. MF models decompose the observed user-item interaction matrix into user and item latent factors. In this paper, we propose a cofactorization model, CoFactor, which jointly decomposes the user-item interaction matrix and the item-item co-occurrence matrix with shared item latent factors. For each pair of items, the co-occurrence matrix encodes the number of users that have consumed both items. CoFactor is inspired by the recent success of word embedding models (e.g., word2vec) which can be interpreted as factorizing the word co-occurrence matrix. We show that this model signiﬁcantly improves the performance over MF models on several datasets with little additional computational overhead. We provide qualitative results that explain how CoFactor improves the quality of the inferred factors and characterize the circumstances where it provides the most signiﬁcant improvements.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 10th {ACM} {Conference} on {Recommender} {Systems} - {RecSys} '16},
	publisher = {ACM Press},
	author = {Liang, Dawen and Altosaar, Jaan and Charlin, Laurent and Blei, David M.},
	year = {2016},
	keywords = {dm},
	pages = {59--66},
}

@inproceedings{MultitypeCoclusteringGeneralHeterogeneous,
	address = {Barcelona, Spain},
	title = {Multi-type {Co}-clustering of {General} {Heterogeneous} {Information} {Networks} via {Nonnegative} {Matrix} {Tri}-{Factorization}},
	isbn = {978-1-5090-5473-2},
	url = {http://ieeexplore.ieee.org/document/7837998/},
	doi = {10.1109/ICDM.2016.0185},
	abstract = {Many kinds of real world data can be modeled by a heterogeneous information network (HIN) which consists of multiple types of objects. Clustering plays an important role in mining knowledge from HIN. Several HIN clustering algorithms have been proposed in recent years. However, these algorithms suffer from one or more of the following problems: (1) inability to model general HINs; (2) inability to simultaneously generate clusters for all types of objects; (3) inability to use similarity information of the objects with the same type. In this paper, we propose a powerful HIN clustering algorithm which can handle general HINs, simultaneously generate clusters for all types of objects, and use the similarity information of the same type of objects. First, we transform a general HIN into a meta-pathencoded relationship set. Second, we propose a nonnegative matrix tri-factorization multi-type co-clustering method, HMFClus, to cluster all types of objects in HIN simultaneously. Third, we integrate the information between the objects with the same type into HMFClus by using a similarity regularization. Extensive experiments on real world datasets show that the proposed algorithm outperforms the state-of-the-art methods.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2016 {IEEE} 16th {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Zhang, Xianchao and Li, Haixin and Liang, Wenxin and Luo, Jiebo},
	month = dec,
	year = {2016},
	keywords = {dm},
	pages = {1353--1358},
}

@inproceedings{RobustClusteringMultitypeRelational,
	address = {Seoul, South Korea},
	title = {Robust clustering of multi-type relational data via a heterogeneous manifold ensemble},
	isbn = {978-1-4799-7964-6},
	url = {http://ieeexplore.ieee.org/document/7113319/},
	doi = {10.1109/ICDE.2015.7113319},
	abstract = {High-Order Co-Clustering (HOCC) methods have attracted high attention in recent years because of their ability to cluster multiple types of objects simultaneously using all available information. During the clustering process, HOCC methods exploit object co-occurrence information, i.e., inter-type relationships amongst different types of objects as well as object afﬁnity information, i.e., intra-type relationships amongst the same types of objects. However, it is difﬁcult to learn accurate intra-type relationships in the presence of noise and outliers. Existing HOCC methods consider the p nearest neighbours based on Euclidean distance for the intra-type relationships, which leads to incomplete and inaccurate intra-type relationships. In this paper, we propose a novel HOCC method that incorporates multiple subspace learning with a heterogeneous manifold ensemble to learn complete and accurate intra-type relationships. Multiple subspace learning reconstructs the similarity between any pair of objects that belong to the same subspace. The heterogeneous manifold ensemble is created based on two-types of intra-type relationships learnt using p-nearest-neighbour graph and multiple subspaces learning. Moreover, in order to make sure the robustness of clustering process, we introduce a sparse error matrix into matrix decomposition and develop a novel iterative algorithm. Empirical experiments show that the proposed method achieves improved results over the state-of-art HOCC methods for FScore and NMI.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2015 {IEEE} 31st {International} {Conference} on {Data} {Engineering}},
	publisher = {IEEE},
	author = {Hou, Jun and Nayak, Richi},
	month = apr,
	year = {2015},
	keywords = {dm},
	pages = {615--626},
}

@article{HowHierarchicalLanguageUse,
	title = {How hierarchical is language use?},
	volume = {279},
	issn = {0962-8452, 1471-2954},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspb.2012.1741},
	doi = {10.1098/rspb.2012.1741},
	language = {en},
	number = {1747},
	urldate = {2019-12-29},
	journal = {Proceedings of the Royal Society B: Biological Sciences},
	author = {Frank, Stefan L. and Bod, Rens and Christiansen, Morten H.},
	month = nov,
	year = {2012},
	keywords = {dm},
	pages = {4522--4531},
}

@incollection{NonnegativeMatrixFactorizationInteractive,
	address = {Cham},
	title = {Nonnegative {Matrix} {Factorization} for {Interactive} {Topic} {Modeling} and {Document} {Clustering}},
	isbn = {978-3-319-09258-4 978-3-319-09259-1},
	url = {http://link.springer.com/10.1007/978-3-319-09259-1_7},
	abstract = {Nonnegative matrix factorization (NMF) approximates a nonnegative matrix by the product of two low-rank nonnegative matrices. Since it gives semantically meaningful result that is easily interpretable in clustering applications, NMF has been widely used as a clustering method especially for document data, and as a topic modeling method.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Partitional {Clustering} {Algorithms}},
	publisher = {Springer International Publishing},
	author = {Kuang, Da and Choo, Jaegul and Park, Haesun},
	editor = {Celebi, M. Emre},
	year = {2015},
	doi = {10.1007/978-3-319-09259-1_7},
	keywords = {dm},
	pages = {215--243},
}

@inproceedings{RelationshipsVariousNonnegativeMatrix,
	address = {Hong Kong, China},
	title = {The {Relationships} {Among} {Various} {Nonnegative} {Matrix} {Factorization} {Methods} for {Clustering}},
	url = {http://ieeexplore.ieee.org/document/4053063/},
	doi = {10.1109/ICDM.2006.160},
	abstract = {The nonnegative matrix factorization (NMF) has been shown recently to be useful for clustering. Various extensions of NMF have also been proposed. In this paper we present an overview and theoretically analyze the relationships among them. In addition, we clarify previously unaddressed issues, such as NMF normalization, cluster posterior probabilty, and NMF algoritm convergence rate. Experiments are also conducted to empirically evaluate and compare various factorization methods.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Sixth {International} {Conference} on {Data} {Mining} ({ICDM}'06)},
	publisher = {IEEE},
	author = {Li, Tao and Ding, Chris},
	month = dec,
	year = {2006},
	keywords = {dm},
	pages = {362--371},
}

@article{D3ClusteringModelsDiscovery,
	title = {D3.2.1 {Clustering} models for discovery of regional and demographic variation},
	language = {en},
	author = {Preotiuc-Pietro, Daniel and Samangooei, Dr Sina and Lampos, Dr Vasileios and Cohn, Dr Trevor and Gibbins, Dr Nicholas and Niranjan, Mahesan},
	keywords = {dm},
	pages = {25},
}

@article{ExplainingExplanationsOverviewInterpretability,
	title = {Explaining {Explanations}: {An} {Overview} of {Interpretability} of {Machine} {Learning}},
	shorttitle = {Explaining {Explanations}},
	url = {http://arxiv.org/abs/1806.00069},
	abstract = {There has recently been a surge of work in explanatory artiﬁcial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufﬁcient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artiﬁcial intelligence.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1806.00069 [cs, stat]},
	author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
	month = feb,
	year = {2019},
	note = {arXiv: 1806.00069},
}

@article{SurveyDeepLearningClass,
	title = {Survey on deep learning with class imbalance},
	volume = {6},
	issn = {2196-1115},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0192-5},
	doi = {10.1186/s40537-019-0192-5},
	abstract = {The purpose of this study is to examine existing deep learning techniques for addressing class imbalanced data. Effective classification with imbalanced data is an important area of research, as high class imbalance is naturally inherent in many real-world applications, e.g., fraud detection and cancer detection. Moreover, highly imbalanced data poses added difficulty, as most learners will exhibit bias towards the majority class, and in extreme cases, may ignore the minority class altogether. Class imbalance has been studied thoroughly over the last two decades using traditional machine learning models, i.e. non-deep learning. Despite recent advances in deep learning, along with its increasing popularity, very little empirical work in the area of deep learning with class imbalance exists. Having achieved record-breaking performance results in several complex domains, investigating the use of deep neural networks for problems containing high levels of class imbalance is of great interest. Available studies regarding class imbalance and deep learning are surveyed in order to better understand the efficacy of deep learning when applied to class imbalanced data. This survey discusses the implementation details and experimental results for each study, and offers additional insight into their strengths and weaknesses. Several areas of focus include: data complexity, architectures tested, performance interpretation, ease of use, big data application, and generalization to other domains. We have found that research in this area is very limited, that most existing work focuses on computer vision tasks with convolutional neural networks, and that the effects of big data are rarely considered. Several traditional methods for class imbalance, e.g. data sampling and cost-sensitive learning, prove to be applicable in deep learning, while more advanced methods that exploit neural network feature learning abilities show promising results. The survey concludes with a discussion that highlights various gaps in deep learning from class imbalanced data for the purpose of guiding future research.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {Journal of Big Data},
	author = {Johnson, Justin M. and Khoshgoftaar, Taghi M.},
	month = dec,
	year = {2019},
	pages = {27},
}

@article{FindingBestClassificationThreshold,
	title = {Finding the {Best} {Classification} {Threshold} in {Imbalanced} {Classification}},
	volume = {5},
	issn = {22145796},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2214579615000611},
	doi = {10.1016/j.bdr.2015.12.001},
	abstract = {Classiﬁcation with imbalanced class distributions is a major problem in machine learning. Researchers have given considerable attention to the applications in many real-world scenarios. Although several works have utilized the area under the receiver operating characteristic (ROC) curve to select potentially optimal classiﬁers in imbalanced classiﬁcations, limited studies have been devoted to ﬁnding the classiﬁcation threshold for testing or unknown datasets. In general, the classiﬁcation threshold is simply set to 0.5, which is usually unsuitable for an imbalanced classiﬁcation. In this study, we analyze the drawbacks of using ROC as the sole measure of imbalance in data classiﬁcation problems. In addition, a novel framework for ﬁnding the best classiﬁcation threshold is proposed. Experiments with SCOP v.1.53 data reveal that, with the default threshold set to 0.5, our proposed framework demonstrated a 20.63\% improvement in terms of F-score compared with that of more commonly used methods. The ﬁndings suggest that the proposed framework is both effective and eﬃcient. A web server and software tools are available via http://datamining.xmu.edu.cn/prht/ or http://prht.sinaapp.com/.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Big Data Research},
	author = {Zou, Quan and Xie, Sifa and Lin, Ziyu and Wu, Meihong and Ju, Ying},
	month = sep,
	year = {2016},
	pages = {2--8},
}

@article{UserLevelRaceEthnicityPredictors,
	title = {User-{Level} {Race} and {Ethnicity} {Predictors} from {Twitter} {Text}},
	abstract = {User demographic inference from social media text has the potential to improve a range of downstream applications, including real-time passive polling or quantifying demographic bias. This study focuses on developing models for user-level race and ethnicity prediction. We introduce a data set of users who self-report their race/ethnicity through a survey, in contrast to previous approaches that use distantly supervised data or perceived labels. We develop predictive models from text which accurately predict the membership of a user to the four largest racial and ethnic groups with up to .884 AUC and make these available to the research community.},
	language = {en},
	author = {Preoţiuc-Pietro, Daniel and Ungar, Lyle},
	pages = {12},
}

@inproceedings{ActiveLinkDeepActiveLearning,
	address = {San Francisco, CA, USA},
	title = {{ActiveLink}: {Deep} {Active} {Learning} for {Link} {Prediction} in {Knowledge} {Graphs}},
	isbn = {978-1-4503-6674-8},
	shorttitle = {{ActiveLink}},
	url = {http://dl.acm.org/citation.cfm?doid=3308558.3313620},
	doi = {10.1145/3308558.3313620},
	abstract = {Neural networks have recently been shown to be highly effective at predicting links for constructing knowledge graphs. Existing research has mainly focused on designing 1) deep neural network models that are expressive in capturing fine-grained semantics, e.g., NTN and ConvE, but that are however less scalable; or 2) shallow models that are scalable, e.g., TransE and DistMult, yet limited in capturing expressive semantic features. In this work, we demonstrate that we can get the best of both worlds while drastically reducing the amount of data needed to train a deep network by leveraging active learning.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {The {World} {Wide} {Web} {Conference} on   - {WWW} '19},
	publisher = {ACM Press},
	author = {Ostapuk, Natalia and Yang, Jie and Cudre-Mauroux, Philippe},
	year = {2019},
	pages = {1398--1408},
}

@article{ThesisAbstractApproved,
	title = {Thesis and {Abstract} {Approved} :},
	language = {en},
	author = {Oates, Dr Tim},
	pages = {92},
}

@inproceedings{InferringUserPoliticalPreferencesa,
	address = {Baltimore, Maryland},
	title = {Inferring {User} {Political} {Preferences} from {Streaming} {Communications}},
	url = {http://aclweb.org/anthology/P14-1018},
	doi = {10.3115/v1/P14-1018},
	abstract = {Existing models for social media personal analytics assume access to thousands of messages per user, even though most users author content only sporadically over time. Given this sparsity, we: (i) leverage content from the local neighborhood of a user; (ii) evaluate batch models as a function of size and the amount of messages in various types of neighborhoods; and (iii) estimate the amount of time and tweets required for a dynamic model to predict user preferences. We show that even when limited or no selfauthored data is available, language from friend, retweet and user mention communications provide sufﬁcient evidence for prediction. When updating models over time based on Twitter, we ﬁnd that political preference can be often be predicted using roughly 100 tweets, depending on the context of user selection, where this could mean hours, or weeks, based on the author’s tweeting frequency.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 52nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Volkova, Svitlana and Coppersmith, Glen and Van Durme, Benjamin},
	year = {2014},
	pages = {186--196},
}

@inproceedings{SocialOceanVisualAnalysisCharacterization,
	address = {Konstanz},
	title = {{SocialOcean}: {Visual} {Analysis} and {Characterization} of {Social} {Media} {Bubbles}},
	isbn = {978-1-5386-9194-6},
	shorttitle = {{SocialOcean}},
	url = {https://ieeexplore.ieee.org/document/8534023/},
	doi = {10.1109/BDVA.2018.8534023},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2018 {International} {Symposium} on {Big} {Data} {Visual} and {Immersive} {Analytics} ({BDVA})},
	publisher = {IEEE},
	author = {Diehl, Alexandra and Hundt, Michael and Haussler, Johannes and Seebacher, Daniel and Chen, Siming and Cilasun, Nida and Keim, Daniel and Shreck, Tobias},
	month = oct,
	year = {2018},
	pages = {1--11},
}

@article{ManComputerProgrammerWomana,
	title = {Man is to {Computer} {Programmer} as {Woman} is to {Homemaker}? {Debiasing} {Word} {Embeddings}},
	abstract = {The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is ﬁrst shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender deﬁnition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms signiﬁcantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.},
	language = {en},
	author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T},
	keywords = {fair},
	pages = {9},
}

@article{LipstickPigDebiasingMethodsa,
	title = {Lipstick on a {Pig}: {Debiasing} {Methods} {Cover} up {Systematic} {Gender} {Biases} in {Word} {Embeddings} {But} do not {Remove} {Them}},
	shorttitle = {Lipstick on a {Pig}},
	url = {http://arxiv.org/abs/1903.03862},
	abstract = {Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reﬂect gender biases in society. This phenomenon is pervasive and consistent across different word embedding models, causing serious concern. Several recent works tackle this problem, and propose methods for signiﬁcantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superﬁcial. While the bias is indeed substantially reduced according to the provided bias deﬁnition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reﬂected in the distances between “gender-neutralized” words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufﬁcient, and should not be trusted for providing gender-neutral modeling.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1903.03862 [cs]},
	author = {Gonen, Hila and Goldberg, Yoav},
	month = sep,
	year = {2019},
	note = {arXiv: 1903.03862},
	keywords = {fair},
}

@incollection{PredictiveAnalysisTwitterTechniques,
	address = {Cham},
	title = {Predictive {Analysis} on {Twitter}: {Techniques} and {Applications}},
	isbn = {978-3-319-94104-2 978-3-319-94105-9},
	shorttitle = {Predictive {Analysis} on {Twitter}},
	url = {http://link.springer.com/10.1007/978-3-319-94105-9_4},
	abstract = {Predictive analysis of social media data has attracted considerable attention from the research community as well as the business world because of the essential and actionable information it can provide. Over the years, extensive experimentation and analysis for insights have been carried out using Twitter data in various domains such as healthcare, public health, politics, social sciences, and demographics. In this chapter, we discuss techniques, approaches and state-of-the-art applications of predictive analysis of Twitter data. Speciﬁcally, we present ﬁne-grained analysis involving aspects such as sentiment, emotion, and the use of domain knowledge in the coarse-grained analysis of Twitter data for making decisions and taking actions, and relate a few success stories.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Emerging {Research} {Challenges} and {Opportunities} in {Computational} {Social} {Network} {Analysis} and {Mining}},
	publisher = {Springer International Publishing},
	author = {Kursuncu, Ugur and Gaur, Manas and Lokala, Usha and Thirunarayan, Krishnaprasad and Sheth, Amit and Arpinar, I. Budak},
	editor = {Agarwal, Nitin and Dokoohaki, Nima and Tokdemir, Serpil},
	year = {2019},
	doi = {10.1007/978-3-319-94105-9_4},
	pages = {67--104},
}

@inproceedings{GuidelinesHumanAIInteraction,
	address = {Glasgow, Scotland Uk},
	title = {Guidelines for {Human}-{AI} {Interaction}},
	isbn = {978-1-4503-5970-2},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300233},
	doi = {10.1145/3290605.3300233},
	abstract = {Advances in artifcial intelligence (AI) frame opportunities and challenges for user interface design. Principles for humanAI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of guidelines for human-AI interaction design.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '19},
	publisher = {ACM Press},
	author = {Amershi, Saleema and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N.},
	year = {2019},
	pages = {1--13},
}

@article{ProtoSteerSteeringDeepSequence,
	title = {{ProtoSteer}: {Steering} {Deep} {Sequence} {Model} with {Prototypes}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {{ProtoSteer}},
	url = {https://ieeexplore.ieee.org/document/8827944/},
	doi = {10.1109/TVCG.2019.2934267},
	abstract = {Recently we have witnessed growing adoption of deep sequence models (e.g. LSTMs) in many application domains, including predictive health care, natural language processing, and log analysis. However, the intricate working mechanism of these models conﬁnes their accessibility to the domain experts. Their black-box nature also makes it a challenging task to incorporate domain-speciﬁc knowledge of the experts into the model. In ProtoSteer (Prototype Steering), we tackle the challenge of directly involving the domain experts to steer a deep sequence model without relying on model developers as intermediaries. Our approach originates in case-based reasoning, which imitates the common human problem-solving process of consulting past experiences to solve new problems. We utilize ProSeNet (Prototype Sequence Network), which learns a small set of exemplar cases (i.e., prototypes) from historical data. In ProtoSteer they serve both as an efﬁcient visual summary of the original data and explanations of model decisions. With ProtoSteer the domain experts can inspect, critique, and revise the prototypes interactively. The system then incorporates user-speciﬁed prototypes and incrementally updates the model. We conduct extensive case studies and expert interviews in application domains including sentiment analysis on texts and predictive diagnostics based on vehicle fault logs. The results demonstrate that involvements of domain users can help obtain more interpretable models with concise prototypes while retaining similar accuracy.},
	language = {en},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Ming, Yao and Xu, Panpan and Cheng, Furui and Qu, Huamin and Ren, Liu},
	year = {2019},
	pages = {1--1},
}

@article{BridgingTextVisualizationMining,
	title = {Bridging {Text} {Visualization} and {Mining}: {A} {Task}-{Driven} {Survey}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Bridging {Text} {Visualization} and {Mining}},
	url = {https://ieeexplore.ieee.org/document/8356097/},
	doi = {10.1109/TVCG.2018.2834341},
	abstract = {Visual text analytics has recently emerged as one of the most prominent topics in both academic research and the commercial world. To provide an overview of the relevant techniques and analysis tasks, as well as the relationships between them, we comprehensively analyzed 263 visualization papers and 4,346 mining papers published between 1992-2017 in two ﬁelds: visualization and text mining. From the analysis, we derived around 300 concepts (visualization techniques, mining techniques, and analysis tasks) and built a taxonomy for each type of concept. The co-occurrence relationships between the concepts were also extracted. Our research can be used as a stepping-stone for other researchers to 1) understand a common set of concepts used in this research topic; 2) facilitate the exploration of the relationships between visualization techniques, mining techniques, and analysis tasks; 3) understand the current practice in developing visual text analytics tools; 4) seek potential research opportunities by narrowing the gulf between visualization and mining techniques based on the analysis tasks; and 5) analyze other interdisciplinary research areas in a similar way. We have also contributed a web-based visualization tool for analyzing and understanding research trends and opportunities in visual text analytics.},
	language = {en},
	number = {7},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Shixia and Wang, Xiting and Collins, Christopher and Dou, Wenwen and Ouyang, Fangxin and El-Assady, Mennatallah and Jiang, Liu and Keim, Daniel A.},
	month = jul,
	year = {2019},
	pages = {2482--2504},
}

@article{LocalizedUserdrivenTopicDiscovery,
	title = {Localized user-driven topic discovery via boosted ensemble of nonnegative matrix factorization},
	volume = {56},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-017-1147-9},
	doi = {10.1007/s10115-017-1147-9},
	abstract = {Nonnegative matrix factorization (NMF) has been widely used in topic modeling of large-scale document corpora, where a set of underlying topics are extracted by a lowrank factor matrix from NMF. However, the resulting topics often convey only general, thus redundant information about the documents rather than information that might be minor, but potentially meaningful to users. To address this problem, we present a novel ensemble method based on nonnegative matrix factorization that discovers meaningful local topics. Our method leverages the idea of an ensemble model, which has shown advantages in supervised learning, into an unsupervised topic modeling context. That is, our model successively performs NMF given a residual matrix obtained from previous stages and generates a sequence of topic sets. The algorithm we employ to update is novel in two aspects. The ﬁrst lies in utilizing the residual matrix inspired by a state-of-the-art gradient boosting model, and the second stems from applying a sophisticated local weighting scheme on the given matrix to enhance the locality of topics, which in turn delivers high-quality, focused topics of interest to users.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Knowledge and Information Systems},
	author = {Suh, Sangho and Shin, Sungbok and Lee, Joonseok and Reddy, Chandan K. and Choo, Jaegul},
	month = sep,
	year = {2018},
	pages = {503--531},
}

@article{LifeDeathTechniquesPrognostication,
	title = {Life {After} {Death}: {Techniques} for the {Prognostication} of {Coma} {Outcomes} after {Cardiac} {Arrest}},
	abstract = {Electroencephalography (EEG) features are known to predict neurological outcomes of patients in coma after cardiac arrest, but the association between EEG features and outcomes is time-dependent. Recent advances in machine learning allow temporally-dependent features to be learned from the EEG waveforms in a fully-automated way, allowing for faster, bettercalibrated and more reliable prognostic predictions. In this thesis, we discuss three major contributions to the problem of coma prognostication after cardiac arrest: (1) the collection of the world's largest multi-center EEG database for patients in coma after cardiac arrest, (2) the development of time-dependent, interpretable, feature-based EEG models that may be used for both risk-scoring and decision support at the bedside, and (3) a careful comparison of the performance and utility of feature-based techniques to that of representation learning models that fully-automate the extraction of time-dependent features for outcome prognostication.},
	language = {en},
	author = {Ghassemi, Mohammad Mahdi},
	pages = {134},
}

@inproceedings{AnalysisUserOccupationalClass,
	address = {Beijing, China},
	title = {An analysis of the user occupational class through {Twitter} content},
	url = {http://aclweb.org/anthology/P15-1169},
	doi = {10.3115/v1/P15-1169},
	abstract = {Social media content can be used as a complementary source to the traditional methods for extracting and studying collective social attributes. This study focuses on the prediction of the occupational class for a public user proﬁle. Our analysis is conducted on a new annotated corpus of Twitter users, their respective job titles, posted textual content and platform-related attributes. We frame our task as classiﬁcation using latent feature representations such as word clusters and embeddings. The employed linear and, especially, non-linear methods can predict a user’s occupational class with strong accuracy for the coarsest level of a standard occupation taxonomy which includes nine classes. Combined with a qualitative assessment, the derived results conﬁrm the feasibility of our approach in inferring a new user attribute that can be embedded in a multitude of downstream applications.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Preoţiuc-Pietro, Daniel and Lampos, Vasileios and Aletras, Nikolaos},
	year = {2015},
	pages = {1754--1764},
}

@article{UnderstandingDemographicsTwitterUsers,
	title = {Understanding the {Demographics} of {Twitter} {Users}},
	abstract = {Every second, the thoughts and feelings of millions of people across the world are recorded in the form of 140-character tweets using Twitter. However, despite the enormous potential presented by this remarkable data source, we still do not have an understanding of the Twitter population itself: Who are the Twitter users? How representative of the overall population are they? In this paper, we take the ﬁrst steps towards answering these questions by analyzing data on a set of Twitter users representing over 1\% of the U.S. population. We develop techniques that allow us to compare the Twitter population to the U.S. population along three axes (geography, gender, and race/ethnicity), and ﬁnd that the Twitter population is a highly non-uniform sample of the population.},
	language = {en},
	author = {Mislove, Alan and Lehmann, Sune},
	pages = {4},
}

@article{LocalizedUserdrivenTopicDiscoverya,
	title = {Localized user-driven topic discovery via boosted ensemble of nonnegative matrix factorization},
	volume = {56},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-017-1147-9},
	doi = {10.1007/s10115-017-1147-9},
	abstract = {Nonnegative matrix factorization (NMF) has been widely used in topic modeling of large-scale document corpora, where a set of underlying topics are extracted by a lowrank factor matrix from NMF. However, the resulting topics often convey only general, thus redundant information about the documents rather than information that might be minor, but potentially meaningful to users. To address this problem, we present a novel ensemble method based on nonnegative matrix factorization that discovers meaningful local topics. Our method leverages the idea of an ensemble model, which has shown advantages in supervised learning, into an unsupervised topic modeling context. That is, our model successively performs NMF given a residual matrix obtained from previous stages and generates a sequence of topic sets. The algorithm we employ to update is novel in two aspects. The ﬁrst lies in utilizing the residual matrix inspired by a state-of-the-art gradient boosting model, and the second stems from applying a sophisticated local weighting scheme on the given matrix to enhance the locality of topics, which in turn delivers high-quality, focused topics of interest to users.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Knowledge and Information Systems},
	author = {Suh, Sangho and Shin, Sungbok and Lee, Joonseok and Reddy, Chandan K. and Choo, Jaegul},
	month = sep,
	year = {2018},
	pages = {503--531},
}

@article{GraphRegularizedNonnegativeMatrix,
	title = {Graph {Regularized} {Nonnegative} {Matrix} {Factorization} for {Data} {Representation}},
	volume = {33},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/5674058/},
	doi = {10.1109/TPAMI.2010.231},
	abstract = {Matrix factorization techniques have been frequently applied in information retrieval, computer vision and pattern recognition. Among them, Non-negative Matrix Factorization (NMF) has received considerable attention due to its psychological and physiological interpretation of naturally occurring data whose representation may be parts-based in the human brain. On the other hand, from the geometric perspective, the data is usually sampled from a low dimensional manifold embedded in a high dimensional ambient space. One hopes then to ﬁnd a compact representation which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. In this paper, we propose a novel algorithm, called Graph Regularized Non-negative Matrix Factorization (GNMF), for this purpose. In GNMF, an afﬁnity graph is constructed to encode the geometrical information, and we seek a matrix factorization which respects the graph structure. Our empirical study shows encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real world problems.},
	language = {en},
	number = {8},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {{Deng Cai} and {Xiaofei He} and {Jiawei Han} and Huang, T S},
	month = aug,
	year = {2011},
	pages = {1548--1560},
}

@article{InferringLatentUserProperties,
	title = {Inferring {Latent} {User} {Properties} from {Texts} {Published} in {Social} {Media}},
	abstract = {We demonstrate an approach to predict latent personal attributes including user demographics, online personality, emotions and sentiments from texts published on Twitter. We rely on machine learning and natural language processing techniques to learn models from user communications. We ﬁrst examine individual tweets to detect emotions and opinions emanating from them, and then analyze all the tweets published by a user to infer latent traits of that individual. We consider various user properties including age, gender, income, education, relationship status, optimism and life satisfaction. We focus on Ekman’s six emotions: anger, joy, surprise, fear, disgust and sadness. Our work can help social network users to understand how others may perceive them based on how they communicate in social media, in addition to its evident applications in online sales and marketing, targeted advertising, large scale polling and healthcare analytics.},
	language = {en},
	author = {Volkova, Svitlana and Bachrach, Yoram and Armstrong, Michael and Sharma, Vijay},
	pages = {2},
}

@article{DemographicsSocialMediaData,
	title = {Demographics in {Social} {Media} {Data} for {Public} {Health} {Research}: {Does} it matter?},
	abstract = {Social media data provides propitious opportunities for public health research. However, studies suggest that disparities may exist in the representation of certain populations (e.g., people of lower socioeconomic status). To quantify and address these disparities in population representation, we need demographic information, which is usually missing from most social media platforms. Here, we propose an ensemble approach for inferring demographics from social media data.},
	language = {en},
	author = {Cesare, Nina and Grant, Christan and Hawkins, Jared B and Brownstein, John S and Nsoesie, Elaine O},
	pages = {8},
}

@inproceedings{AnalyzingBiasesHumanPerception,
	address = {Berlin, Germany},
	title = {Analyzing {Biases} in {Human} {Perception} of {User} {Age} and {Gender} from {Text}},
	url = {http://aclweb.org/anthology/P16-1080},
	doi = {10.18653/v1/P16-1080},
	abstract = {User traits disclosed through written text, such as age and gender, can be used to personalize applications such as recommender systems or conversational agents. However, human perception of these traits is not perfectly aligned with reality. In this paper, we conduct a large-scale crowdsourcing experiment on guessing age and gender from tweets. We systematically analyze the quality and possible biases of these predictions. We identify the textual cues which lead to miss-assessments of traits or make annotators more or less conﬁdent in their choice. Our study demonstrates that differences between real and perceived traits are noteworthy and elucidates inaccurately used stereotypes in human perception.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Flekova, Lucie and Carpenter, Jordan and Giorgi, Salvatore and Ungar, Lyle and Preoţiuc-Pietro, Daniel},
	year = {2016},
	pages = {843--854},
}

@article{SpectralBiclusteringMicroarrayData,
	title = {Spectral {Biclustering} of {Microarray} {Data}: {Coclustering} {Genes} and {Conditions}},
	volume = {13},
	issn = {10889051},
	shorttitle = {Spectral {Biclustering} of {Microarray} {Data}},
	url = {http://www.genome.org/cgi/doi/10.1101/gr.648603},
	doi = {10.1101/gr.648603},
	language = {en},
	number = {4},
	urldate = {2019-12-29},
	journal = {Genome Research},
	author = {Kluger, Y.},
	month = apr,
	year = {2003},
	pages = {703--716},
}

@article{IncrementalDimensionalityReductionMethoda,
	title = {An {Incremental} {Dimensionality} {Reduction} {Method} for {Visualizing} {Streaming} {Multidimensional} {Data}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/8809834/},
	doi = {10.1109/TVCG.2019.2934433},
	abstract = {Dimensionality reduction (DR) methods are commonly used for analyzing and visualizing multidimensional data. However, when data is a live streaming feed, conventional DR methods cannot be directly used because of their computational complexity and inability to preserve the projected data positions at previous time points. In addition, the problem becomes even more challenging when the dynamic data records have a varying number of dimensions as often found in real-world applications. This paper presents an incremental DR solution. We enhance an existing incremental PCA method in several ways to ensure its usability for visualizing streaming multidimensional data. First, we use geometric transformation and animation methods to help preserve a viewer’s mental map when visualizing the incremental results. Second, to handle data dimension variants, we use an optimization method to estimate the projected data positions, and also convey the resulting uncertainty in the visualization. We demonstrate the effectiveness of our design with two case studies using real-world datasets.},
	language = {en},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Fujiwara, Takanori and Chou, Jia-Kai and {Shilpika} and Xu, Panpan and Ren, Liu and Ma, Kwan-Liu},
	year = {2019},
	pages = {1--1},
}

@article{LearningHowExplainNeural,
	title = {Learning how to explain neural networks: {PatternNet} and {PatternAttribution}},
	shorttitle = {Learning how to explain neural networks},
	url = {http://arxiv.org/abs/1705.05598},
	abstract = {DeConvNet, Guided BackProp, LRP, were invented to better understand deep neural networks. We show that these methods do not produce the theoretically correct explanation for a linear model. Yet they are used on multi-layer networks with millions of parameters. This is a cause for concern since linear models are simple neural networks. We argue that explanation methods for neural nets should work reliably in the limit of simplicity, the linear models. Based on our analysis of linear models we propose a generalization that yields two explanation techniques (PatternNet and PatternAttribution) that are theoretically sound for linear models and produce improved explanations for deep networks.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1705.05598 [cs, stat]},
	author = {Kindermans, Pieter-Jan and Schütt, Kristof T. and Alber, Maximilian and Müller, Klaus-Robert and Erhan, Dumitru and Kim, Been and Dähne, Sven},
	month = oct,
	year = {2017},
	note = {arXiv: 1705.05598},
}

@inproceedings{SimultaneousClusteringMultitypeRelational,
	address = {Glasgow, Scotland, UK},
	title = {Simultaneous clustering of multi-type relational data via symmetric nonnegative matrix tri-factorization},
	isbn = {978-1-4503-0717-8},
	url = {http://dl.acm.org/citation.cfm?doid=2063576.2063621},
	doi = {10.1145/2063576.2063621},
	abstract = {The rapid growth of Internet and modern technologies has brought data involving objects of multiple types that are related to each other, called as multi-type relational data. Traditional clustering methods for single-type data rarely work well on them, which calls for more advanced clustering techniques to deal with multiple types of data simultaneously to utilize their interrelatedness. A major challenge in developing simultaneous clustering methods is how to effectively use all available information contained in a multi-type relational data set including inter-type and intra-type relationships. In this paper, we propose a Symmetric Nonnegative Matrix TriFactorization (S-NMTF) framework to cluster multi-type relational data at the same time. The proposed S-NMTF approach employs NMTF to simultaneously cluster different types of data using their inter-type relationships, and incorporate the intra-type information through manifold regularization. In order to deal with the symmetric usage of the factor matrix in S-NMTF, we present a new generic matrix inequality to derive the solution algorithm, which involves a fourth-order matrix polynomial, in a principled way. Promising experimental results have validated the proposed approach.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 20th {ACM} international conference on {Information} and knowledge management - {CIKM} '11},
	publisher = {ACM Press},
	author = {Wang, Hua and Huang, Heng and Ding, Chris},
	year = {2011},
	pages = {279},
}

@article{RobustGraphRegularizedNonnegative,
	title = {Robust {Graph} {Regularized} {Nonnegative} {Matrix} {Factorization} for {Clustering}},
	volume = {11},
	issn = {15564681},
	url = {http://dl.acm.org/citation.cfm?doid=3058790.3003730},
	doi = {10.1145/3003730},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Peng, Chong and Kang, Zhao and Hu, Yunhong and Cheng, Jie and Cheng, Qiang},
	month = mar,
	year = {2017},
	pages = {1--30},
}

@article{RecentResearchAdvancesInteractive,
	title = {Recent research advances on interactive machine learning},
	volume = {22},
	issn = {1343-8875, 1875-8975},
	url = {http://link.springer.com/10.1007/s12650-018-0531-1},
	doi = {10.1007/s12650-018-0531-1},
	abstract = {Interactive machine learning (IML) is an iterative learning process that tightly couples a human with a machine learner, which is widely used by researchers and practitioners to effectively solve a wide variety of real-world application problems. Although recent years have witnessed the proliferation of IML in the ﬁeld of visual analytics, most recent surveys either focus on a speciﬁc area of IML or aim to summarize a visualization ﬁeld that is too generic for IML. In this paper, we systematically review the recent literature on IML and classify them into a task-oriented taxonomy built by us. We conclude the survey with a discussion of open challenges and research opportunities that we believe are inspiring for future work in IML.},
	language = {en},
	number = {2},
	urldate = {2019-12-29},
	journal = {Journal of Visualization},
	author = {Jiang, Liu and Liu, Shixia and Chen, Changjian},
	month = apr,
	year = {2019},
	pages = {401--417},
}

@article{MultiTaskModelFeatureJoint,
	title = {Multi-{Task} {Model} and {Feature} {Joint} {Learning}},
	abstract = {Given several tasks, multi-task learning (MTL) learns multiple tasks jointly by exploring the interdependence between them. The basic assumption in MTL is that those tasks are indeed related. Existing MTL methods model the task relatedness/interdependence in two different ways, either common parameter-sharing or common featuresharing across tasks. In this paper, we propose a novel multi-task learning method to jointly learn shared parameters and shared feature representation. Our objective is to learn a set of common features with which the tasks are related as closely as possible, therefore common parameters shared across tasks can be optimally learned. We present a detailed deviation of our multi-task learning method and propose an alternating algorithm to solve the non-convex optimization problem. We further present a theoretical bound which directly demonstrates that the proposed multi-task learning method can successfully model the relatedness via joint common parameter- and common featurelearning. Extensive experiments are conducted on several real world multi-task learning datasets. All results demonstrate the effectiveness of our multitask model and feature joint learning method.},
	language = {en},
	author = {Li, Ya and Tian, Xinmei and Liu, Tongliang and Tao, Dacheng},
	pages = {7},
}

@article{ReviewUserInterfaceDesign,
	title = {A {Review} of {User} {Interface} {Design} for {Interactive} {Machine} {Learning}},
	volume = {8},
	issn = {21606455},
	url = {http://dl.acm.org/citation.cfm?doid=3232718.3185517},
	doi = {10.1145/3185517},
	language = {en},
	number = {2},
	urldate = {2019-12-29},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Dudley, John J. and Kristensson, Per Ola},
	month = jun,
	year = {2018},
	pages = {1--37},
}

@article{InteractiveInterpretableMachineLearning,
	title = {Interactive and {Interpretable} {Machine} {Learning} {Models} for {Human} {Machine} {Collaboration}},
	abstract = {I envision a system that enables successful collaborations between humans and machine learning models by harnessing the relative strength to accomplish what neither can do alone. Machine learning techniques and humans have skills that complement each other — machine learning techniques are good at computation on data at the lowest level of granularity, whereas people are better at abstracting knowledge from their experience, and transferring the knowledge across domains. The goal of this thesis is to develop a framework for human-in-the-loop machine learning that enables people to interact eﬀectively with machine learning models to make better decisions, without requiring in-depth knowledge about machine learning techniques. Many of us interact with machine learning systems everyday. Systems that mine data for product recommendations, for example, are ubiquitous. However these systems compute their output without end-user involvement, and there are typically no life or death consequences in the case the machine learning result is not acceptable to the user. In contrast, domains where decisions can have serious consequences (e.g., emergency response panning, medical decision-making), require the incorporation of human experts’ domain knowledge. These systems also must be transparent to earn experts’ trust and be adopted in their workﬂow. The challenge addressed in this thesis is that traditional machine learning systems are not designed to extract domain experts’ knowledge from natural workﬂow, or to provide pathways for the human domain expert to directly interact with the algorithm to interject their knowledge or to better understand the system output. For machine learning systems to make a real-world impact in these important domains, these systems must be able to communicate with highly skilled human experts to leverage their judgment and expertise, and share useful information or patterns from the data.},
	language = {en},
	author = {Kim, Been},
	pages = {143},
}

@article{GenderBiasNeuralNatural,
	title = {Gender {Bias} in {Neural} {Natural} {Language} {Processing}},
	url = {http://arxiv.org/abs/1807.11714},
	abstract = {We examine whether neural natural language processing (NLP) systems reﬂect historical biases in training data. We deﬁne a general benchmark to quantify gender bias in a variety of neural NLP tasks. Our empirical evaluation with state-ofthe-art neural coreference resolution and textbook RNN-based language models trained on benchmark data sets ﬁnds signiﬁcant gender bias in how models view occupations. We then mitigate bias with counterfactual data augmentation (CDA): a generic methodology for corpus augmentation via causal interventions that breaks associations between gendered and gender-neutral words. We empirically show that CDA effectively decreases gender bias while preserving accuracy. We also explore the space of mitigation strategies with CDA, a prior approach to word embedding debiasing (WED), and their compositions. We show that CDA outperforms WED, drastically so when word embeddings are trained. For pre-trained embeddings, the two methods can be effectively composed. We also ﬁnd that as training proceeds on the original data set with gradient descent the gender bias grows as the loss reduces, indicating that the optimization encourages bias; CDA mitigates this behavior.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1807.11714 [cs]},
	author = {Lu, Kaiji and Mardziel, Piotr and Wu, Fangjing and Amancharla, Preetam and Datta, Anupam},
	month = may,
	year = {2019},
	note = {arXiv: 1807.11714},
}

@inproceedings{MitigatingGenderBiasNatural,
	address = {Florence, Italy},
	title = {Mitigating {Gender} {Bias} in {Natural} {Language} {Processing}: {Literature} {Review}},
	shorttitle = {Mitigating {Gender} {Bias} in {Natural} {Language} {Processing}},
	url = {https://www.aclweb.org/anthology/P19-1159},
	doi = {10.18653/v1/P19-1159},
	abstract = {As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in popularity, it becomes increasingly vital to recognize the role they play in shaping societal biases and stereotypes. Although NLP models have shown success in modeling various applications, they propagate and may even amplify gender bias found in text corpora. While the study of bias in artiﬁcial intelligence is not new, methods to mitigate gender bias in NLP are relatively nascent. In this paper, we review contemporary studies on recognizing and mitigating gender bias in NLP. We discuss gender bias based on four forms of representation bias and analyze methods recognizing gender bias. Furthermore, we discuss the advantages and drawbacks of existing gender debiasing methods. Finally, we discuss future studies for recognizing and mitigating gender bias in NLP.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Sun, Tony and Gaut, Andrew and Tang, Shirlyn and Huang, Yuxin and ElSherief, Mai and Zhao, Jieyu and Mirza, Diba and Belding, Elizabeth and Chang, Kai-Wei and Wang, William Yang},
	year = {2019},
	pages = {1630--1640},
}

@article{WhatIfToolInteractiveProbing,
	title = {The {What}-{If} {Tool}: {Interactive} {Probing} of {Machine} {Learning} {Models}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {The {What}-{If} {Tool}},
	url = {https://ieeexplore.ieee.org/document/8807255/},
	doi = {10.1109/TVCG.2019.2934619},
	abstract = {A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.},
	language = {en},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Wexler, James and Pushkarna, Mahima and Bolukbasi, Tolga and Wattenberg, Martin and Viegas, Fernanda and Wilson, Jimbo},
	year = {2019},
	pages = {1--1},
}

@article{DesiderataInterpretabilityExplainingDecision,
	title = {Desiderata for {Interpretability}: {Explaining} {Decision} {Tree} {Predictions} with {Counterfactuals}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Desiderata for {Interpretability}},
	url = {https://aaai.org/ojs/index.php/AAAI/article/view/5154},
	doi = {10.1609/aaai.v33i01.330110035},
	abstract = {Explanations in machine learning come in many forms, but a consensus regarding their desired properties is still emerging. In our work we collect and organise these explainability desiderata and discuss how they can be used to systematically evaluate properties and quality of an explainable system using the case of class-contrastive counterfactual statements. This leads us to propose a novel method for explaining predictions of a decision tree with counterfactuals. We show that our model-speciﬁc approach exploits all the theoretical advantages of counterfactual explanations, hence improves decision tree interpretability by decoupling the quality of the interpretation from the depth and width of the tree.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Sokol, Kacper and Flach, Peter},
	month = jul,
	year = {2019},
	pages = {10035--10036},
}

@article{DeepTemporalClusteringFully,
	title = {Deep {Temporal} {Clustering} : {Fully} {Unsupervised} {Learning} of {Time}-{Domain} {Features}},
	shorttitle = {Deep {Temporal} {Clustering}},
	url = {http://arxiv.org/abs/1802.01059},
	abstract = {Unsupervised learning of time series data, also known as temporal clustering, is a challenging problem in machine learning. Here we propose a novel algorithm, Deep Temporal Clustering (DTC), to naturally integrate dimensionality reduction and temporal clustering into a single end-to-end learning framework, fully unsupervised. The algorithm utilizes an autoencoder for temporal dimensionality reduction and a novel temporal clustering layer for cluster assignment. Then it jointly optimizes the clustering objective and the dimensionality reduction objective. Based on requirement and application, the temporal clustering layer can be customized with any temporal similarity metric. Several similarity metrics and state-of-the-art algorithms are considered and compared. To gain insight into temporal features that the network has learned for its clustering, we apply a visualization method that generates a region of interest heatmap for the time series. The viability of the algorithm is demonstrated using time series data from diverse domains, ranging from earthquakes to spacecraft sensor data. In each case, we show that the proposed algorithm outperforms traditional methods. The superior performance is attributed to the fully integrated temporal dimensionality reduction and clustering criterion.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1802.01059 [cs, stat]},
	author = {Madiraju, Naveen Sai and Sadat, Seid M. and Fisher, Dimitry and Karimabadi, Homa},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.01059},
}

@article{MultiFeatureSegmentationClusterBased,
	title = {Multi-{Feature} {Segmentation} and {Cluster} based {Approach} for {Product} {Feature} {Categorization}},
	volume = {8},
	issn = {20749007, 20749015},
	url = {http://www.mecs-press.org/ijitcs/ijitcs-v8-n3/v8n3-4.html},
	doi = {10.5815/ijitcs.2016.03.04},
	abstract = {At a recent time, the web has become a valuable source of online consumer review however as the number of reviews is growing in high speed. It is infeasible for user to read all reviews to make a valuable or satisfying decision because the same features, people can write it contrary words or phrases. To produce a useful summary of domain synonyms words and phrase, need to be a group into same feature group. We focus on feature-based opinion mining problem and this paper mainly studies feature based product categorization from the number of users - generated review available on the different website. First, a multi-feature segmentation method is proposed which segment multi-feature review sentences into the single feature unit. Second part of speech dictionary and context information is used to consider the irrelevant feature identification, sentiment words are used to identify the polarity of feature and finally an unsupervised clustering based product feature categorization method is proposed. Clustering is unsupervised machine learning approach that groups feature that have a high degree of similarity in a same cluster. The proposed approach provides satisfactory results and can achieve 100\% average precision for clustering based product feature categorization task. This approach can be applicable to different product.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {International Journal of Information Technology and Computer Science},
	author = {{School of Computing Science and Engineering, Galgotias University, India} and Singh, Bharat},
	month = mar,
	year = {2016},
	pages = {33--42},
}

@article{WeightedMultiviewClusteringFeature,
	title = {Weighted {Multi}-view {Clustering} with {Feature} {Selection}},
	volume = {53},
	issn = {00313203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320315004665},
	doi = {10.1016/j.patcog.2015.12.007},
	abstract = {In recent years, combining multiple sources or views of datasets for data clustering has been a popular practice for improving clustering accuracy. As different views are different representations of the same set of instances, we can simultaneously use information from multiple views to improve the clustering results generated by the limited information from a single view. Previous studies mainly focus on the relationships between distinct data views, which would get some improvement over the single-view clustering. However, in the case of high-dimensional data, where each view of data is of high dimensionality, feature selection is also a necessity for further improving the clustering results. To overcome this problem, this paper proposes a novel algorithm termed Weighted Multi-view Clustering with Feature Selection (WMCFS) that can simultaneously perform multi-view data clustering and feature selection. Two weighting schemes are designed that respectively weight the views of data points and feature representations in each view, such that the best view and the most representative feature space in each view can be selected for clustering. Experimental results conducted on real-world datasets have validated the effectiveness of the proposed method.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Pattern Recognition},
	author = {Xu, Yu-Meng and Wang, Chang-Dong and Lai, Jian-Huang},
	month = may,
	year = {2016},
	pages = {25--35},
}

@article{TriadicFormalConceptAnalysis,
	title = {Triadic {Formal} {Concept} {Analysis} and triclustering: searching for optimal patterns},
	volume = {101},
	issn = {0885-6125, 1573-0565},
	shorttitle = {Triadic {Formal} {Concept} {Analysis} and triclustering},
	url = {http://link.springer.com/10.1007/s10994-015-5487-y},
	doi = {10.1007/s10994-015-5487-y},
	abstract = {This paper presents several deﬁnitions of “optimal patterns” in triadic data and results of experimental comparison of ﬁve triclustering algorithms on real-world and synthetic datasets. The evaluation is carried over such criteria as resource efﬁciency, noise tolerance and quality scores involving cardinality, density, coverage, and diversity of the patterns. An ideal triadic pattern is a totally dense maximal cuboid (formal triconcept). Relaxations of this notion under consideration are: OAC-triclusters; triclusters optimal with respect to the leastsquare criterion; and graph partitions obtained by using spectral clustering. We show that searching for an optimal tricluster cover is an NP-complete problem, whereas determining the number of such covers is \#P-complete. Our extensive computational experiments lead us to a clear strategy for choosing a solution at a given dataset guided by the principle of Pareto-optimality according to the proposed criteria.},
	language = {en},
	number = {1-3},
	urldate = {2019-12-29},
	journal = {Machine Learning},
	author = {Ignatov, Dmitry I. and Gnatyshak, Dmitry V. and Kuznetsov, Sergei O. and Mirkin, Boris G.},
	month = oct,
	year = {2015},
	pages = {271--302},
}

@article{ArtScienceMachineLearning,
	title = {On the {Art} and {Science} of {Machine} {Learning} {Explanations}},
	url = {http://arxiv.org/abs/1810.02909},
	abstract = {This text discusses several popular explanatory methods that go beyond the error measurements and plots traditionally used to assess machine learning models. Some of the explanatory methods are accepted tools of the trade while others are rigorously derived and backed by long-standing theory. The methods, decision tree surrogate models, individual conditional expectation (ICE) plots, local interpretable model-agnostic explanations (LIME), partial dependence plots, and Shapley explanations, vary in terms of scope, fidelity, and suitable application domain. Along with descriptions of these methods, this text presents real-world usage recommendations supported by a use case and public, in-depth software examples for reproducibility.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1810.02909 [cs, stat]},
	author = {Hall, Patrick},
	month = aug,
	year = {2019},
	note = {arXiv: 1810.02909},
}

@article{MultiViewClusteringDeepMatrix,
	title = {Multi-{View} {Clustering} via {Deep} {Matrix} {Factorization}},
	abstract = {Multi-View Clustering (MVC) has garnered more attention recently since many real-world data are comprised of different representations or views. The key is to explore complementary information to beneﬁt the clustering problem. In this paper, we present a deep matrix factorization framework for MVC, where semi-nonnegative matrix factorization is adopted to learn the hierarchical semantics of multi-view data in a layerwise fashion. To maximize the mutual information from each view, we enforce the non-negative representation of each view in the ﬁnal layer to be the same. Furthermore, to respect the intrinsic geometric structure in each view data, graph regularizers are introduced to couple the output representation of deep structures. As a non-trivial contribution, we provide the solution based on alternating minimization strategy, followed by a theoretical proof of convergence. The superior experimental results on three face benchmarks show the effectiveness of the proposed deep matrix factorization model.},
	language = {en},
	author = {Zhao, Handong and Ding, Zhengming and Fu, Yun},
	pages = {7},
}

@article{BenchmarkExperimentsVisualizationMethods,
	title = {On {Benchmark} {Experiments} and {Visualization} {Methods} for the {Evaluation} and {Interpretation} of {Machine} {Learning} {Models}},
	language = {en},
	author = {Casalicchio, Giuseppe},
	pages = {134},
}

@inproceedings{ExploringDisSimilaritiesEmojiEmotion,
	address = {San Francisco, USA},
	title = {Exploring ({Dis}-){Similarities} in {Emoji}-{Emotion} {Association} on {Twitter} and {Weibo}},
	isbn = {978-1-4503-6675-5},
	url = {http://dl.acm.org/citation.cfm?doid=3308560.3316546},
	doi = {10.1145/3308560.3316546},
	abstract = {Emojis have gained widespread acceptance, globally and crossculturally. However, Emoji use may also be nuanced due to di�erences across cultures, which can play a signi�cant role in shaping emotional life. In this paper, we a) present a methodology to learn latent emotional components of Emojis, b) compare Emoji-Emotion associations across cultures, and c) discuss how they may re�ect emotion expression in these platforms. Speci�cally, we learn vector space embeddings with more than 100 million posts from China (Sina Weibo) and the United States (Twitter), quantify the association of Emojis with 8 basic emotions, demonstrate correlation between visual cues and emotional valence, and discuss pairwise similarities between emotions. Our proposed Emoji-Emotion visualization pipeline for uncovering latent emotional components can potentially be used for downstream applications such as sentiment analysis and personalized text recommendations.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Companion {Proceedings} of {The} 2019 {World} {Wide} {Web} {Conference} on   - {WWW} '19},
	publisher = {ACM Press},
	author = {Li, Mingyang and Guntuku, Sharath and Jakhetiya, Vinit and Ungar, Lyle},
	year = {2019},
	pages = {461--467},
}

@article{TriadicCoclusteringUsersIssues,
	title = {Triadic co-clustering of users, issues and sentiments in political tweets},
	volume = {100},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417418300563},
	doi = {10.1016/j.eswa.2018.01.043},
	abstract = {Social network data contains many hidden relationships. The most well known is the communities formed by users. Moreover, typical social network data, such as Twitter, can also be interpreted in terms of three-dimensional relationships; namely the users, issues discussed by the users, and terminology chosen by the users in these discussions. In this paper, we propose a new problem to generate co-clusters in these three dimensions simultaneously. There are three major differences between our problem and the standard co-clustering problem deﬁnition: a node can be a member of more than one clusters; all the nodes are not necessarily members of some cluster; and edges are signed and cluster are expected to have high density of positive signed edges, and low density of negative signed edges. We apply our method to the tweets of British politicians just before the Brexit referendum. Our motivation is to discover clusters of politicians, issues and the sentimental words politicians use to express their feelings on these issues in their tweets.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Expert Systems with Applications},
	author = {Koç, Sefa Şahin and Özer, Mert and Toroslu, İsmail Hakkı and Davulcu, Hasan and Jordan, Jeremy},
	month = jun,
	year = {2018},
	pages = {79--94},
}

@article{HierarchicalClusteringMultiTaskLearning,
	title = {Hierarchical {Clustering} {Multi}-{Task} {Learning} for {Joint} {Human} {Action} {Grouping} and {Recognition}},
	volume = {39},
	issn = {0162-8828, 2160-9292},
	url = {https://ieeexplore.ieee.org/document/7423818/},
	doi = {10.1109/TPAMI.2016.2537337},
	abstract = {This paper proposes a hierarchical clustering multi-task learning (HC-MTL) method for joint human action grouping and recognition. Speciﬁcally, we formulate the objective function into the group-wise least square loss regularized by low rank and sparsity with respect to two latent variables, model parameters and grouping information, for joint optimization. To handle this non-convex optimization, we decompose it into two sub-tasks, multi-task learning and task relatedness discovery. First, we convert this non-convex objective function into the convex formulation by ﬁxing the latent grouping information. This new objective function focuses on multitask learning by strengthening the shared-action relationship and action-speciﬁc feature learning. Second, we leverage the learned model parameters for the task relatedness measure and clustering. In this way, HC-MTL can attain both optimal action models and group discovery by alternating iteratively. The proposed method is validated on three kinds of challenging datasets, including six realistic action datasets (Hollywood2, YouTube, UCF Sports, UCF50, HMDB51 \& UCF101), two constrained datasets (KTH \& TJU), and two multi-view datasets (MV-TJU \& IXMAS). The extensive experimental results show that: 1) HC-MTL can produce competing performances to the state of the arts for action recognition and grouping; 2) HC-MTL can overcome the difﬁculty in heuristic action grouping simply based on human knowledge; 3) HC-MTL can avoid the possible inconsistency between the subjective action grouping depending on human knowledge and objective action grouping based on the feature subspace distributions of multiple actions. Comparison with the popular clustered multi-task learning further reveals that the discovered latent relatedness by HC-MTL aids inducing the group-wise multi-task learning and boosts the performance. To the best of our knowledge, ours is the ﬁrst work that breaks the assumption that all actions are either independent for individual learning or correlated for joint modeling and proposes HC-MTL for automated, joint action grouping and modeling.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Liu, An-An and Su, Yu-Ting and Nie, Wei-Zhi and Kankanhalli, Mohan},
	month = jan,
	year = {2017},
	pages = {102--114},
}

@inproceedings{LinguisticDiversitiesDemographicGroups,
	address = {Prague, Czech Republic},
	title = {Linguistic {Diversities} of {Demographic} {Groups} in {Twitter}},
	isbn = {978-1-4503-4708-2},
	url = {http://dl.acm.org/citation.cfm?doid=3078714.3078742},
	doi = {10.1145/3078714.3078742},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 28th {ACM} {Conference} on {Hypertext} and {Social} {Media} - {HT} '17},
	publisher = {ACM Press},
	author = {Vikatos, Pantelis and Messias, Johnnatan and Miranda, Manoel and Benevenuto, Fabrício},
	year = {2017},
	pages = {275--284},
}

@article{VisualizingFeatureImportanceBlack,
	title = {Visualizing the {Feature} {Importance} for {Black} {Box} {Models}},
	url = {http://arxiv.org/abs/1804.06620},
	abstract = {In recent years, a large amount of model-agnostic methods to improve the transparency, trustability, and interpretability of machine learning models have been developed. Based on a recent method for model-agnostic global feature importance, we introduce a local feature importance measure for individual observations and propose two visual tools: partial importance (PI) and individual conditional importance (ICI) plots which visualize how changes in a feature aﬀect the model performance on average, as well as for individual observations. Our proposed methods are related to partial dependence (PD) and individual conditional expectation (ICE) plots, but visualize the expected (conditional) feature importance instead of the expected (conditional) prediction. Furthermore, we show that averaging ICI curves across observations yields a PI curve, and integrating the PI curve with respect to the distribution of the considered feature results in the global feature importance. Another contribution of our paper is the Shapley feature importance, which fairly distributes the overall performance of a model among the features according to the marginal contributions and which can be used to compare the feature importance across diﬀerent models.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1804.06620 [cs, stat]},
	author = {Casalicchio, Giuseppe and Molnar, Christoph and Bischl, Bernd},
	month = dec,
	year = {2018},
	note = {arXiv: 1804.06620},
}

@article{SAXNavigatorTimeSeries,
	title = {{SAX} {Navigator}: {Time} {Series} {Exploration} through {Hierarchical} {Clustering}},
	shorttitle = {{SAX} {Navigator}},
	url = {http://arxiv.org/abs/1908.05505},
	abstract = {Comparing many long time series is challenging to do by hand. Clustering time series enables data analysts to discover relevance between and anomalies among multiple time series. However, even after reasonable clustering, analysts have to scrutinize correlations between clusters or similarities within a cluster. We developed SAX Navigator, an interactive visualization tool, that allows users to hierarchically explore global patterns as well as individual observations across large collections of time series data. Our visualization provides a unique way to navigate time series that involves a “vocabulary of patterns” developed by using a dimensionality reduction technique, Symbolic Aggregate approXimation (SAX). With SAX, the time series data clusters efﬁciently and is quicker to query at scale. We demonstrate the ability of SAX Navigator to analyze patterns in large time series data based on three case studies for an astronomy data set. We verify the usability of our system through a think-aloud study with an astronomy domain scientist.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1908.05505 [cs]},
	author = {Ruta, Nicholas and Sawada, Naoko and McKeough, Katy and Behrisch, Michael and Beyer, Johanna},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.05505},
}

@article{FuzzyRadarVisualizationUnderstandingFuzzy,
	title = {{FuzzyRadar}: visualization for understanding fuzzy clusters},
	volume = {22},
	issn = {1343-8875, 1875-8975},
	shorttitle = {{FuzzyRadar}},
	url = {http://link.springer.com/10.1007/s12650-019-00577-2},
	doi = {10.1007/s12650-019-00577-2},
	abstract = {Fuzzy clustering assigns a membership degree (MD) on a datum to a cluster, which reflects real-world clustering scenarios but increases the complexity of understanding fuzzy clusters. Many studies have demonstrated that multidimensional visualization techniques are beneficial to fuzzy clusters analysis. However, empirically, no single existing visualization technique can support most analytical tasks featured by fuzzy clustering. This work proposes a new visualization called FuzzyRadar for understanding fuzzy clusters. Its basic idea is to combine the advantages of radial coordinate visualization (Radviz), which specializes in data-oriented analytical tasks, and parallel coordinate plot (PCP), which performs well in cluster-oriented analytical tasks. First, we adopt a compact and compounded layout to integrate Radviz and PCP into one visualization view. Then, we introduce a strip-edge-bundling method to reduce the visual cluster caused by PCP polylines and a histogram embedding method to facilitate the recognition of MD distribution. We also provide a group of additional visual encodings and a set of lightweight interactions. Finally, we use a case study to demonstrate the usability of FuzzyRadar and conduct a controlled quantitative evaluation to compare the performance of FuzzyRadar, Radviz, PCP, and scatterplot matrix. Result shows that FuzzyRadar supports all the seven examined analytical tasks well and presents a significant capability improvement compared with Radviz and PCP.},
	language = {en},
	number = {5},
	urldate = {2019-12-29},
	journal = {Journal of Visualization},
	author = {Zhou, Fangfang and Bai, Bing and Wu, Yitao and Chen, Minghui and Zhong, Zengsheng and Zhu, Rongchen and Chen, Yi and Zhao, Ying},
	month = oct,
	year = {2019},
	pages = {913--926},
}

@article{SparseUnsupervisedDimensionalityReduction,
	title = {Sparse {Unsupervised} {Dimensionality} {Reduction} for {Multiple} {View} {Data}},
	volume = {22},
	issn = {1051-8215, 1558-2205},
	url = {http://ieeexplore.ieee.org/document/6209403/},
	doi = {10.1109/TCSVT.2012.2202075},
	abstract = {Different kinds of high-dimensional visual features can be extracted from a single image. Images can thus be treated as multiple view data when taking each type of extracted high-dimensional visual feature as a particular understanding of images. In this paper, we propose a framework of sparse unsupervised dimensionality reduction for multiple view data. The goal of our framework is to ﬁnd a low-dimensional optimal consensus representation from multiple heterogeneous features by multiview learning. In this framework, we ﬁrst learn lowdimensional patterns individually from each view, considering the speciﬁc statistical property of each view. We construct a lowdimensional optimal consensus representation from those learned patterns, the goal of which is to leverage the complementary nature of the multiple views. We formulate the construction of the low-dimensional consensus representation to approximate the matrix of patterns by means of a low-dimensional consensus base matrix and a loading matrix. To select the most discriminative features for the spectral embedding of multiple views, we propose to add an 1-norm into the loading matrix’s columns and impose orthogonal constraints on the base matrix. We develop a new alternating algorithm, i.e., spectral sparse multiview embedding, to efﬁciently obtain the solution. Each row of the loading matrix encodes structured information corresponding to multiple patterns. In order to gain ﬂexibility in sharing information across subsets of the views, we impose a novel structured sparsity-inducing norm penalty on the loading matrix’s rows. This penalty makes the loading coefﬁcients adaptively load shared information across subsets of the learned patterns. We call this method structured sparse multiview dimensionality reduction. Experiments on a toy benchmark image data set and two real-world Web image data sets demonstrate the effectiveness of the proposed algorithms.},
	language = {en},
	number = {10},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	author = {{Yahong Han} and {Fei Wu} and {Dacheng Tao} and {Jian Shao} and {Yueting Zhuang} and {Jianmin Jiang}},
	month = oct,
	year = {2012},
	pages = {1485--1496},
}

@book{SIGIR19Proceedings42nd,
	title = {{SIGIR} '19: proceedings of the 42nd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval} : {July} 21-25, 2019, {Paris}, {France}},
	isbn = {978-1-4503-6172-9},
	shorttitle = {{SIGIR} '19},
	language = {en},
	editor = {{SIGIR} and {Association for Computing Machinery} and {Special Interest Group on Information Retrieval}},
	year = {2019},
	note = {OCLC: 1128057307},
}

@inproceedings{PrinciplesExplanatoryDebuggingPersonalize,
	address = {Atlanta, Georgia, USA},
	title = {Principles of {Explanatory} {Debugging} to {Personalize} {Interactive} {Machine} {Learning}},
	isbn = {978-1-4503-3306-1},
	url = {http://dl.acm.org/citation.cfm?doid=2678025.2701399},
	doi = {10.1145/2678025.2701399},
	abstract = {How can end users eﬃciently inﬂuence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging, an approach in which the system explains to users how it made each of its predictions, and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants’ understanding of the learning system by 52\% and allowed participants to correct its mistakes up to twice as eﬃciently as participants using a traditional learning system.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '15},
	publisher = {ACM Press},
	author = {Kulesza, Todd and Burnett, Margaret and Wong, Weng-Keen and Stumpf, Simone},
	year = {2015},
	pages = {126--137},
}

@article{OCTVisOntologybasedComparisonTopic,
	title = {{OCTVis}: {Ontology}-based {Comparison} of {Topic} {Models}},
	language = {en},
	author = {Ge, Amon Dongfang},
	pages = {68},
}

@inproceedings{GroundingInteractiveMachineLearning,
	address = {Hong Kong, China},
	title = {Grounding {Interactive} {Machine} {Learning} {Tool} {Design} in {How} {Non}-{Experts} {Actually} {Build} {Models}},
	isbn = {978-1-4503-5198-0},
	url = {http://dl.acm.org/citation.cfm?doid=3196709.3196729},
	doi = {10.1145/3196709.3196729},
	abstract = {Machine learning (ML) promises data-driven insights and solutions for people from all walks of life, but the skill of crafting these solutions is possessed by only a few. Emerging research addresses this issue by creating ML tools that are easy and accessible to people who are not formally trained in ML (“non-experts”). This work investigated how non-experts build ML solutions for themselves in real life. Our interviews and surveys revealed unique potentials of non-expert ML, as well several pitfalls that non-experts are susceptible to. For example, many perceived percentage accuracy as a sole measure of performance, thus problematic models proceeded to deployment. These observations suggested that, while challenging, making ML easy and robust should both be important goals of designing novice-facing ML tools. To advance on this insight, we discuss design implications and created a sensitizing concept to demonstrate how designers might guide non-experts to easily build robust solutions.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 2018 on {Designing} {Interactive} {Systems} {Conference} 2018  - {DIS} '18},
	publisher = {ACM Press},
	author = {Yang, Qian and Suh, Jina and Chen, Nan-Chen and Ramos, Gonzalo},
	year = {2018},
	pages = {573--584},
}

@inproceedings{EmergingPerspectivesHumanCenteredMachine,
	address = {Glasgow, Scotland Uk},
	title = {Emerging {Perspectives} in {Human}-{Centered} {Machine} {Learning}},
	isbn = {978-1-4503-5971-9},
	url = {http://dl.acm.org/citation.cfm?doid=3290607.3299014},
	doi = {10.1145/3290607.3299014},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Extended {Abstracts} of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} {EA} '19},
	publisher = {ACM Press},
	author = {Ramos, Gonzalo and Suh, Jina and Ghorashi, Soroush and Meek, Christopher and Banks, Richard and Amershi, Saleema and Fiebrink, Rebecca and Smith-Renner, Alison and Bansal, Gagan},
	year = {2019},
	pages = {1--8},
}

@article{MachineTeachingNewParadigm,
	title = {Machine {Teaching}: {A} {New} {Paradigm} for {Building} {Machine} {Learning} {Systems}},
	shorttitle = {Machine {Teaching}},
	url = {http://arxiv.org/abs/1707.06742},
	abstract = {The current processes for building machine learning systems require practitioners with deep knowledge of machine learning. This signiﬁcantly limits the number of machine learning systems that can be created and has led to a mismatch between the demand for machine learning systems and the ability for organizations to build them. We believe that in order to meet this growing demand for machine learning systems we must signiﬁcantly increase the number of individuals that can teach machines. We postulate that we can achieve this goal by making the process of teaching machines easy, fast and above all, universally accessible.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1707.06742 [cs, stat]},
	author = {Simard, Patrice Y. and Amershi, Saleema and Chickering, David M. and Pelton, Alicia Edelman and Ghorashi, Soroush and Meek, Christopher and Ramos, Gonzalo and Suh, Jina and Verwey, Johan and Wang, Mo and Wernsing, John},
	month = aug,
	year = {2017},
	note = {arXiv: 1707.06742},
}

@article{GeneratingCounterfactualContrastiveExplanations,
	title = {Generating {Counterfactual} and {Contrastive} {Explanations} using {SHAP}},
	url = {http://arxiv.org/abs/1906.09293},
	abstract = {With the advent of GDPR, the domain of explainable AI and model interpretability has gained added impetus. Methods to extract and communicate visibility into decision-making models have become legal requirement. Two speciﬁc types of explanations, contrastive and counterfactual have been identiﬁed as suitable for human understanding. In this paper, we propose a model agnostic method and its systemic implementation to generate these explanations using shapely additive explanations (SHAP). We discuss a generative pipeline to create contrastive explanations and use it to further to generate counterfactual datapoints. This pipeline is tested and discussed on the IRIS, Wine Quality \& Mobile Features dataset. Analysis of the results obtained follows.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1906.09293 [cs, stat]},
	author = {Rathi, Shubham},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.09293},
}

@article{MultiviewClusteringSpectralEmbedding,
	title = {Multi-view clustering via spectral embedding fusion},
	volume = {23},
	issn = {1432-7643, 1433-7479},
	url = {http://link.springer.com/10.1007/s00500-018-3184-z},
	doi = {10.1007/s00500-018-3184-z},
	abstract = {Multi-view learning, such as multi-view feature learning and multi-view clustering, has a wide range of applications in machine learning and pattern recognition. Most previous studies employ the multiple data information from various views to improve the performance of learning. The key problem is to integrate the symbiotic part of the different views or datasets. In practical clustering task, the symbiotic part includes two levels: global structure information and local structure information. However, traditional multi-view clustering methods usually ignore the energy of the local structure information. This paper proposes a novel multi-view clustering model to solve this problem, which simultaneously integrates the global structure information and local structure information of all the views. By integrating the fusion of global spectral embedding and the fusion of spectral manifold embedding from multi-view data, we construct an objective function to ﬁnd the ﬁnal fusional embedding and give an iteration method to solve it by using the L2,1 norm. Finally, the K-means clustering method is applied to the obtained ﬁnal fusional embedding. Extensive experimental results on several real multi-view data sets demonstrate the superior performance of our model.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {Soft Computing},
	author = {Yin, Hongwei and Li, Fanzhang and Zhang, Li and Zhang, Zhao},
	month = jan,
	year = {2019},
	pages = {343--356},
}

@article{GeneralizedMultiviewEmbeddingVisual,
	title = {Generalized {Multi}-view {Embedding} for {Visual} {Recognition} and {Cross}-modal {Retrieval}},
	volume = {48},
	issn = {2168-2267, 2168-2275},
	url = {http://arxiv.org/abs/1605.09696},
	doi = {10.1109/TCYB.2017.2742705},
	abstract = {In this paper, the problem of multi-view embedding from different visual cues and modalities is considered. We propose a uniﬁed solution for subspace learning methods using the Rayleigh quotient, which is extensible for multiple views, supervised learning, and non-linear embeddings. Numerous methods including Canonical Correlation Analysis, Partial Least Square regression and Linear Discriminant Analysis are studied using speciﬁc intrinsic and penalty graphs within the same framework. Non-linear extensions based on kernels and (deep) neural networks are derived, achieving better performance than the linear ones. Moreover, a novel Multi-view Modular Discriminant Analysis (MvMDA) is proposed by taking the view difference into consideration. We demonstrate the effectiveness of the proposed multi-view embedding methods on visual object recognition and cross-modal image retrieval, and obtain superior results in both applications compared to related methods.},
	language = {en},
	number = {9},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Cybernetics},
	author = {Cao, Guanqun and Iosifidis, Alexandros and Chen, Ke and Gabbouj, Moncef},
	month = sep,
	year = {2018},
	note = {arXiv: 1605.09696},
	pages = {2542--2555},
}

@article{SpikeSortingBasedShape,
	title = {Spike sorting based on shape, phase, and distribution features, and {K}-{TOPS} clustering with validity and error indices},
	volume = {8},
	issn = {2045-2322},
	url = {http://www.nature.com/articles/s41598-018-35491-4},
	doi = {10.1038/s41598-018-35491-4},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {Scientific Reports},
	author = {Caro-Martín, Carmen Rocío and Delgado-García, José M. and Gruart, Agnès and Sánchez-Campusano, R.},
	month = dec,
	year = {2018},
	pages = {17796},
}

@article{AnalysisNeuronalSpikeTrains,
	title = {Analysis of {Neuronal} {Spike} {Trains}, {Deconstructed}},
	volume = {91},
	issn = {08966273},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627316302501},
	doi = {10.1016/j.neuron.2016.05.039},
	language = {en},
	number = {2},
	urldate = {2019-12-29},
	journal = {Neuron},
	author = {Aljadeff, Johnatan and Lansdell, Benjamin J. and Fairhall, Adrienne L. and Kleinfeld, David},
	month = jul,
	year = {2016},
	pages = {221--259},
}

@article{MultiKernelGaussianProcessesa,
	title = {Multi-{Kernel} {Gaussian} {Processes}},
	abstract = {Multi-task learning remains a difﬁcult yet important problem in machine learning. In Gaussian processes the main challenge is the deﬁnition of valid kernels (covariance functions) able to capture the relationships between different tasks. This paper presents a novel methodology to construct valid multi-task covariance functions (Mercer kernels) for Gaussian processes allowing for a combination of kernels with different forms. The method is based on Fourier analysis and is general for arbitrary stationary covariance functions. Analytical solutions for cross covariance terms between popular forms are provided including Mate´rn, squared exponential and sparse covariance functions. Experiments are conducted with both artiﬁcial and real datasets demonstrating the beneﬁts of the approach.},
	language = {en},
	author = {Melkumyan, Arman and Ramos, Fabio},
	pages = {6},
}

@incollection{HierarchicalTopicModellingApproach,
	address = {Cham},
	title = {A {Hierarchical} {Topic} {Modelling} {Approach} for {Tweet} {Clustering}},
	volume = {10540},
	isbn = {978-3-319-67255-7 978-3-319-67256-4},
	url = {http://link.springer.com/10.1007/978-3-319-67256-4_30},
	abstract = {While social media platforms such as Twitter can provide rich and up-to-date information for a wide range of applications, manually digesting such large volumes of data is diﬃcult and costly. Therefore it is important to automatically infer coherent and discriminative topics from tweets. Conventional topic models and document clustering approaches fail to achieve good results due to the noisy and sparse nature of tweets. In this paper, we explore various ways of tackling this challenge and ﬁnally propose a two-stage hierarchical topic modelling system that is eﬃcient and eﬀective in alleviating the data sparsity problem. We present an extensive evaluation on two datasets, and report our proposed system achieving the best performance in both document clustering performance and topic coherence.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Social {Informatics}},
	publisher = {Springer International Publishing},
	author = {Wang, Bo and Liakata, Maria and Zubiaga, Arkaitz and Procter, Rob},
	editor = {Ciampaglia, Giovanni Luca and Mashhadi, Afra and Yasseri, Taha},
	year = {2017},
	doi = {10.1007/978-3-319-67256-4_30},
	pages = {378--390},
}

@article{GuidanceHumanMachineAnalytics,
	title = {Guidance in the human–machine analytics process},
	volume = {2},
	issn = {2468502X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2468502X1830041X},
	doi = {10.1016/j.visinf.2018.09.003},
	abstract = {In this paper, we list the goals for and the pros and cons of guidance, and we discuss the role that it can play not only in key low-level visualization tasks but also the more sophisticated model-generation tasks of visual analytics. Recent advances in artificial intelligence, particularly in machine learning, have led to high hopes regarding the possibilities of using automatic techniques to perform some of the tasks that are currently done manually using visualization by data analysts. However, visual analytics remains a complex activity, combining many different subtasks. Some of these tasks are relatively low-level, and it is clear how automation could play a role—for example, classification and clustering of data. Other tasks are much more abstract and require significant human creativity, for example, linking insights gleaned from a variety of disparate and heterogeneous data artifacts to build support for decision making. In this paper, we outline the potential applications of guidance, as well as the inputs to guidance. We discuss challenges in implementing guidance, including the inputs to guidance systems and how to provide guidance to users. We propose potential methods for evaluating the quality of guidance at different phases in the analytic process and introduce the potential negative effects of guidance as a source of bias in analytic decision making.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Visual Informatics},
	author = {Collins, Christopher and Andrienko, Natalia and Schreck, Tobias and Yang, Jing and Choo, Jaegul and Engelke, Ulrich and Jena, Amit and Dwyer, Tim},
	month = sep,
	year = {2018},
	pages = {166--180},
}

@article{SurveyMultiViewClustering,
	title = {A {Survey} on {Multi}-{View} {Clustering}},
	url = {http://arxiv.org/abs/1712.06246},
	abstract = {With advances in information acquisition technologies, multi-view data become ubiquitous. Multi-view learning has thus become more and more popular in machine learning and data mining ﬁelds. Multi-view unsupervised or semi-supervised learning, such as co-training, co-regularization has gained considerable attention. Although recently, multi-view clustering (MVC) methods have been developed rapidly, there has not been a survey to summarize and analyze the current progress. Therefore, this paper reviews the common strategies for combining multiple views of data and based on this summary we propose a novel taxonomy of the MVC approaches. We further discuss the relationships between MVC and multi-view representation, ensemble clustering, multi-task clustering, multi-view supervised and semi-supervised learning. Several representative real-world applications are elaborated. To promote future development of MVC, we envision several open problems that may require further investigation and thorough examination.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1712.06246 [cs, stat]},
	author = {Chao, Guoqing and Sun, Shiliang and Bi, Jinbo},
	month = apr,
	year = {2018},
	note = {arXiv: 1712.06246},
}

@article{HierarchicalClusteringHistogramData,
	title = {Hierarchical clustering for histogram data},
	volume = {9},
	issn = {19395108},
	url = {http://doi.wiley.com/10.1002/wics.1405},
	doi = {10.1002/wics.1405},
	language = {en},
	number = {5},
	urldate = {2019-12-29},
	journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
	author = {Billard, L. and Kim, Jaejik},
	month = sep,
	year = {2017},
	pages = {e1405},
}

@article{OnlineMultipleKernelSimilarity,
	title = {Online {Multiple} {Kernel} {Similarity} {Learning} for {Visual} {Search}},
	volume = {36},
	issn = {0162-8828, 2160-9292},
	url = {http://ieeexplore.ieee.org/document/6579606/},
	doi = {10.1109/TPAMI.2013.149},
	abstract = {Recent years have witnessed a number of studies on distance metric learning to improve visual similarity search in ContentBased Image Retrieval (CBIR). Despite their successes, most existing methods on distance metric learning are limited in two aspects. First, they usually assume the target proximity function follows the family of Mahalanobis distances, which limits their capacity of measuring similarity of complex patterns in real applications. Second, they often cannot effectively handle the similarity measure of multi-modal data that may originate from multiple resources. To overcome these limitations, this paper investigates an online kernel similarity learning framework for learning kernel-based proximity functions, which goes beyond the conventional linear distance metric learning approaches. Based on the framework, we propose a novel Online Multiple Kernel Similarity (OMKS) learning method, which learns a ﬂexible nonlinear proximity function with multiple kernels to improve visual similarity search in CBIR. We evaluate the proposed technique for CBIR on a variety of image data sets, in which encouraging results show that OMKS outperforms the state-of-the-art techniques signiﬁcantly.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {{Hao Xia} and Hoi, Steven C. H. and {Rong Jin} and {Peilin Zhao}},
	month = mar,
	year = {2014},
	pages = {536--549},
}

@article{ConvexOptimizationProcedureClustering,
	title = {Convex {Optimization} {Procedure} for {Clustering}: {Theoretical} {Revisit}},
	abstract = {In this paper, we present theoretical analysis of SON – a convex optimization procedure for clustering using a sum-of-norms (SON) regularization recently proposed in [8, 10, 11, 17]. In particular, we show if the samples are drawn from two cubes, each being one cluster, then SON can provably identify the cluster membership provided that the distance between the two cubes is larger than a threshold which (linearly) depends on the size of the cube and the ratio of numbers of samples in each cluster. To the best of our knowledge, this paper is the ﬁrst to provide a rigorous analysis to understand why and when SON works. We believe this may provide important insights to develop novel convex optimization based algorithms for clustering.},
	language = {en},
	author = {Zhu, Changbo and Xu, Huan and Leng, Chenlei and Yan, Shuicheng},
	pages = {9},
}

@article{ExplainableInteractiveDeepLearning,
	title = {Explainable, {Interactive} {Deep} {Learning}},
	language = {en},
	author = {Choo, Jaegul and Liu, Shixia},
	pages = {10},
}

@article{SurveyExperimentalStudyMetric,
	title = {Survey and experimental study on metric learning methods},
	volume = {105},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608018301850},
	doi = {10.1016/j.neunet.2018.06.003},
	abstract = {Distance metric learning has been a hot research spot recently due to its high effectiveness and efficiency in improving the performance of distance related methods, such as k nearest neighbors (kNN). Metric learning aims to learn a data-dependent metric to make intra-class distance smaller and inter-class larger. A large number of methods have been proposed for various applications and a survey to evaluate and compare these methods is imperative. The existing surveys just analyze the algorithms theoretically or compare them experimentally with a narrow time scope. Therefore, the paper reviews classical and influential methods that were proposed between 2003 and 2017 and presents a taxonomy based on the most distinct character of each method. All the methods are categorized into five classes, including pairwise cost, probabilistic framework, boost-like approaches, advantageous variants and specific applications. A comprehensive experimental study is made to compare all the selected methods, exploring the ability in improving accuracy, the relation between distance change and accuracy, the relation between accuracy and kNN neighbor size.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Neural Networks},
	author = {Li, Dewei and Tian, Yingjie},
	month = sep,
	year = {2018},
	pages = {447--462},
}

@inproceedings{AttentionInterpretable,
	address = {Florence, Italy},
	title = {Is {Attention} {Interpretable}?},
	url = {https://www.aclweb.org/anthology/P19-1282},
	doi = {10.18653/v1/P19-1282},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Serrano, Sofia and Smith, Noah A.},
	year = {2019},
	pages = {2931--2951},
}

@inproceedings{ModelingPathsExplainableKnowledge,
	address = {Florence, Italy},
	title = {Modeling {Paths} for {Explainable} {Knowledge} {Base} {Completion}},
	url = {https://www.aclweb.org/anthology/W19-4816},
	doi = {10.18653/v1/W19-4816},
	abstract = {A common approach in knowledge base completion (KBC) is to learn representations for entities and relations in order to infer missing facts by generalizing existing ones. A shortcoming of standard models is that they do not explain their predictions to make them veriﬁable easily to human inspection. In this paper, we propose the context path model (CPM) which generates explanations for new facts in KBC by providing sets of context paths as supporting evidence for these triples. For example, a new triple (Theresa May, nationality, Britain) may be explained by the path (Theresa May, born in, Eastbourne, contained in, Britain). The CPM is formulated as a wrapper that can be applied on top of various existing KBC models. We evaluate it for the well-established TransE model. We observe that its performance remains very close despite the added complexity, and that most of the paths proposed as explanations provide meaningful evidence to assess the correctness.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 2019 {ACL} {Workshop} {BlackboxNLP}: {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Stadelmaier, Josua and Padó, Sebastian},
	year = {2019},
	pages = {147--157},
}

@inproceedings{A2NAttendingNeighborsKnowledge,
	address = {Florence, Italy},
	title = {{A2N}: {Attending} to {Neighbors} for {Knowledge} {Graph} {Inference}},
	shorttitle = {{A2N}},
	url = {https://www.aclweb.org/anthology/P19-1431},
	doi = {10.18653/v1/P19-1431},
	abstract = {State-of-the-art models for knowledge graph completion aim at learning a ﬁxed embedding representation of entities in a multirelational graph which can generalize to infer unseen entity relationships at test time. This can be sub-optimal as it requires memorizing and generalizing to all possible entity relationships using these ﬁxed representations. We thus propose a novel attentionbased method to learn query-dependent representation of entities which adaptively combines the relevant graph neighborhood of an entity leading to more accurate KG completion. The proposed method is evaluated on two benchmark datasets for knowledge graph completion, and experimental results show that the proposed model performs competitively or better than existing state-of-the-art, including recent methods for explicit multi-hop reasoning. Qualitative probing offers insight into how the model can reason about facts involving multiple hops in the knowledge graph, through the use of neighborhood attention.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Bansal, Trapit and Juan, Da-Cheng and Ravi, Sujith and McCallum, Andrew},
	year = {2019},
	pages = {4387--4392},
}

@article{TutorialDistanceMetricLearning,
	title = {A {Tutorial} on {Distance} {Metric} {Learning}: {Mathematical} {Foundations}, {Algorithms} and {Experiments}},
	shorttitle = {A {Tutorial} on {Distance} {Metric} {Learning}},
	url = {http://arxiv.org/abs/1812.05944},
	abstract = {This paper describes the discipline of distance metric learning, a branch of machine learning that aims to learn distances from the data. Distance metric learning can be useful to improve similarity learning algorithms, and also has applications in dimensionality reduction. We describe the distance metric learning problem and analyze its main mathematical foundations. We discuss some of the most popular distance metric learning techniques used in classiﬁcation, showing their goals and the required information to understand and use them. Furthermore, we present a Python package that collects a set of 17 distance metric learning techniques explained in this paper, with some experiments to evaluate the performance of the diﬀerent algorithms. Finally, we discuss several possibilities of future work in this topic.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1812.05944 [cs, stat]},
	author = {Suárez, Juan Luis and García, Salvador and Herrera, Francisco},
	month = dec,
	year = {2019},
	note = {arXiv: 1812.05944},
}

@inproceedings{UsingExplainabilityConstrainedMatrix,
	address = {Como, Italy},
	title = {Using {Explainability} for {Constrained} {Matrix} {Factorization}},
	isbn = {978-1-4503-4652-8},
	url = {http://dl.acm.org/citation.cfm?doid=3109859.3109913},
	doi = {10.1145/3109859.3109913},
	abstract = {Accurate model-based Collaborative Filtering (CF) approaches, such as Matrix Factorization (MF), tend to be black-box machine learning models that lack interpretability and do not provide a straightforward explanation for their outputs. Yet explanations have been shown to improve the transparency of a recommender system by justifying recommendations, and this in turn can enhance the user’s trust in the recommendations. Hence, one main challenge in designing a recommender system is mitigating the trade-o between an explainable technique with moderate prediction accuracy and a more accurate technique with no explainable recommendations. In this paper, we focus on factorization models and further assume the absence of any additional data source, such as item content or user attributes. We propose an explainability constrained MF technique that computes the top-n recommendation list from items that are explainable. Experimental results show that our method is e ective in generating accurate and explainable recommendations.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the {Eleventh} {ACM} {Conference} on {Recommender} {Systems} - {RecSys} '17},
	publisher = {ACM Press},
	author = {Abdollahi, Behnoush and Nasraoui, Olfa},
	year = {2017},
	pages = {79--83},
}

@article{SEMISUPERVISEDDEEPLEARNINGMETRIC,
	title = {{SEMI}-{SUPERVISED} {DEEP} {LEARNING} {BY} {METRIC} {EM}- {BEDDING}},
	abstract = {Deep networks are successfully used as classiﬁcation models yielding state-ofthe-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overﬁt easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The ﬁnal learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classiﬁcation using the labeled samples.},
	language = {en},
	author = {Hoffer, Elad and Ailon, Nir},
	year = {2017},
	keywords = {dm},
	pages = {10},
}

@article{AlgorithmsMetricLearningContrastive,
	title = {Algorithms for metric learning via contrastive embeddings},
	url = {http://arxiv.org/abs/1807.04881},
	abstract = {We study the problem of supervised learning a metric space under discriminative constraints. Given a universe \$X\$ and sets \$\{{\textbackslash}cal S\}, \{{\textbackslash}cal D\}{\textbackslash}subset \{X {\textbackslash}choose 2\}\$ of similar and dissimilar pairs, we seek to find a mapping \$f:X{\textbackslash}to Y\$, into some target metric space \$M=(Y,{\textbackslash}rho)\$, such that similar objects are mapped to points at distance at most \$u\$, and dissimilar objects are mapped to points at distance at least \${\textbackslash}ell\$. More generally, the goal is to find a mapping of maximum accuracy (that is, fraction of correctly classified pairs). We propose approximation algorithms for various versions of this problem, for the cases of Euclidean and tree metric spaces. For both of these target spaces, we obtain fully polynomial-time approximation schemes (FPTAS) for the case of perfect information. In the presence of imperfect information we present approximation algorithms that run in quasipolynomial time (QPTAS). Our algorithms use a combination of tools from metric embeddings and graph partitioning, that could be of independent interest.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1807.04881 [cs]},
	author = {Centurion, Diego Ihara and Mohammadi, Neshat and Sidiropoulos, Anastasios},
	month = mar,
	year = {2019},
	note = {arXiv: 1807.04881},
	keywords = {dm},
}

@article{MultipleKernelLearningAlgorithms,
	title = {Multiple {Kernel} {Learning} {Algorithms}},
	abstract = {In recent years, several methods have been proposed to combine multiple kernels instead of using a single one. These different kernels may correspond to using different notions of similarity or may be using information coming from multiple sources (different representations or different feature subsets). In trying to organize and highlight the similarities and differences between them, we give a taxonomy of and review several multiple kernel learning algorithms. We perform experiments on real data sets for better illustration and comparison of existing algorithms. We see that though there may not be large differences in terms of accuracy, there is difference between them in complexity as given by the number of stored support vectors, the sparsity of the solution as given by the number of used kernels, and training time complexity. We see that overall, using multiple kernels instead of a single one is useful and believe that combining kernels in a nonlinear or data-dependent way seems more promising than linear combination in fusing information provided by simple linear kernels, whereas linear methods are more reasonable when combining complex Gaussian kernels.},
	language = {en},
	author = {Gonen, Mehmet and Alpaydın, Ethem and Tr, Boun Edu and Tr, Boun Edu},
	keywords = {dm},
	pages = {58},
}

@article{MultiKernelGaussianProcesses,
	title = {Multi-{Kernel} {Gaussian} {Processes}},
	language = {en},
	author = {Melkumyan, Arman and Ramos, Fabio},
	keywords = {dm},
	pages = {4},
}

@incollection{DeepMetricLearningHierarchical,
	address = {Cham},
	title = {Deep {Metric} {Learning} with {Hierarchical} {Triplet} {Loss}},
	volume = {11210},
	isbn = {978-3-030-01230-4 978-3-030-01231-1},
	url = {http://link.springer.com/10.1007/978-3-030-01231-1_17},
	abstract = {We present a novel hierarchical triplet loss (HTL) capable of automatically collecting informative training samples (triplets) via a deﬁned hierarchical tree that encodes global context information. This allows us to cope with the main limitation of random sampling in training a conventional triplet loss, which is a central issue for deep metric learning. Our main contributions are two-fold. (i) we construct a hierarchical class-level tree where neighboring classes are merged recursively. The hierarchical structure naturally captures the intrinsic data distribution over the whole dataset. (ii) we formulate the problem of triplet collection by introducing a new violate margin, which is computed dynamically based on the designed hierarchical tree. This allows it to automatically select meaningful hard samples with the guide of global context. It encourages the model to learn more discriminative features from visual similar classes, leading to faster convergence and better performance. Our method is evaluated on the tasks of image retrieval and face recognition, where it can obtain comparable performance with much fewer iterations. It outperforms the standard triplet loss substantially by 1\% − 18\%, and achieves new state-of-the-art performance on a number of benchmarks.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Ge, Weifeng and Huang, Weilin and Dong, Dengke and Scott, Matthew R.},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	doi = {10.1007/978-3-030-01231-1_17},
	keywords = {dm},
	pages = {272--288},
}

@article{SurveyExperimentalStudyMetrica,
	title = {Survey and experimental study on metric learning methods},
	volume = {105},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608018301850},
	doi = {10.1016/j.neunet.2018.06.003},
	abstract = {Distance metric learning has been a hot research spot recently due to its high effectiveness and efficiency in improving the performance of distance related methods, such as k nearest neighbors (kNN). Metric learning aims to learn a data-dependent metric to make intra-class distance smaller and inter-class larger. A large number of methods have been proposed for various applications and a survey to evaluate and compare these methods is imperative. The existing surveys just analyze the algorithms theoretically or compare them experimentally with a narrow time scope. Therefore, the paper reviews classical and influential methods that were proposed between 2003 and 2017 and presents a taxonomy based on the most distinct character of each method. All the methods are categorized into five classes, including pairwise cost, probabilistic framework, boost-like approaches, advantageous variants and specific applications. A comprehensive experimental study is made to compare all the selected methods, exploring the ability in improving accuracy, the relation between distance change and accuracy, the relation between accuracy and kNN neighbor size.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Neural Networks},
	author = {Li, Dewei and Tian, Yingjie},
	month = sep,
	year = {2018},
	keywords = {dm},
	pages = {447--462},
}

@article{UnifiedRepresentationInsightHumanintheLoop,
	title = {Towards a {Unified} {Representation} of {Insight} in {Human}-in-the-{Loop} {Analytics}: {A} {User} {Study}},
	abstract = {Understanding what insights people draw from data visualizations is critical for human-in-the loop analytics systems to facilitate mixed-initiative analysis. In this paper we present results from a large user study on insights extracted from commonly used charts. We report several patterns of insights we observed and analyze their semantic structure to identify key considerations towards a unified formal representation of insight, human or computer generated. We also present a model of insight generation process, where humans and computers work cooperatively, building on each other’s knowledge, where a common representation acts as the currency of interaction. While not going as far as proposing a formalism, we point to a few potential directions for representing insight. We believe our findings could also inform the design of novel human-in-the-loop analytics systems.},
	language = {en},
	author = {Kandogan, Eser and Engelke, Ulrich},
	year = {2018},
	keywords = {vis},
	pages = {7},
}

@article{OntologybasedInferenceCausalExplanation,
	title = {Ontology-based inference for causal explanation},
	url = {http://arxiv.org/abs/1004.4801},
	abstract = {We deﬁne an inference system to capture explanations based on causal statements, using an ontology in the form of an IS-A hierarchy. We ﬁrst introduce a simple logical language which makes it possible to express that a fact causes another fact and that a fact explains another fact. We present a set of formal inference patterns from causal statements to explanation statements. We introduce an elementary ontology which gives greater expressiveness to the system while staying close to propositional reasoning. We provide an inference system that captures the patterns discussed, ﬁrstly in a purely propositional framework, then in a datalog (limited predicate) framework.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1004.4801 [cs]},
	author = {Besnard, Philippe and Cordier, Marie-Odile and Moinard, Yves},
	month = apr,
	year = {2010},
	note = {arXiv: 1004.4801},
	keywords = {vis},
}

@article{HumanintheLoopInterpretabilityPrior,
	title = {Human-in-the-{Loop} {Interpretability} {Prior}},
	url = {http://arxiv.org/abs/1805.11571},
	abstract = {We often desire our models to be interpretable as well as accurate. Prior work on optimizing models for interpretability has relied on easy-to-quantify proxies for interpretability, such as sparsity or the number of operations required. In this work, we optimize for interpretability by directly including humans in the optimization loop. We develop an algorithm that minimizes the number of user studies to ﬁnd models that are both predictive and interpretable and demonstrate our approach on several data sets. Our human subjects results show trends towards different proxy notions of interpretability on different datasets, which suggests that different proxies are preferred on different tasks.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1805.11571 [cs, stat]},
	author = {Lage, Isaac and Ross, Andrew Slavin and Kim, Been and Gershman, Samuel J. and Doshi-Velez, Finale},
	month = oct,
	year = {2018},
	note = {arXiv: 1805.11571},
}

@article{ExplainableMachinelearningPredictionsPrevention,
	title = {Explainable machine-learning predictions for the prevention of hypoxaemia during surgery},
	volume = {2},
	issn = {2157-846X},
	url = {http://www.nature.com/articles/s41551-018-0304-0},
	doi = {10.1038/s41551-018-0304-0},
	language = {en},
	number = {10},
	urldate = {2019-12-29},
	journal = {Nature Biomedical Engineering},
	author = {Lundberg, Scott M. and Nair, Bala and Vavilala, Monica S. and Horibe, Mayumi and Eisses, Michael J. and Adams, Trevor and Liston, David E. and Low, Daniel King-Wai and Newman, Shu-Fang and Kim, Jerry and Lee, Su-In},
	month = oct,
	year = {2018},
	keywords = {fatml, xai},
	pages = {749--760},
}

@article{ExplainableAITreesLocal,
	title = {Explainable {AI} for {Trees}: {From} {Local} {Explanations} to {Global} {Understanding}},
	shorttitle = {Explainable {AI} for {Trees}},
	url = {http://arxiv.org/abs/1905.04610},
	abstract = {Tree-based machine learning models such as random forests, decision trees, and gradient boosted trees are the most popular non-linear predictive models used in practice today, yet comparatively little attention has been paid to explaining their predictions. Here we signiﬁcantly improve the interpretability of tree-based models through three main contributions: 1) The ﬁrst polynomial time algorithm to compute optimal explanations based on game theory. 2) A new type of explanation that directly measures local feature interaction eﬀects. 3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to i) identify high magnitude but low frequency non-linear mortality risk factors in the general US population, ii) highlight distinct population sub-groups with shared risk characteristics, iii) identify non-linear interaction eﬀects among risk factors for chronic kidney disease, and iv) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model’s performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1905.04610 [cs, stat]},
	author = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
	month = may,
	year = {2019},
	note = {arXiv: 1905.04610},
	keywords = {fatml, xai},
}

@article{ConsistentIndividualizedFeatureAttribution,
	title = {Consistent {Individualized} {Feature} {Attribution} for {Tree} {Ensembles}},
	url = {http://arxiv.org/abs/1802.03888},
	abstract = {Interpreting predictions from tree ensemble methods such as gradient boosting machines and random forests is important, yet feature attribution for trees is often heuristic and not individualized for each prediction. Here we show that popular feature attribution methods are inconsistent, meaning they can lower a feature’s assigned importance when the true impact of that feature actually increases. This is a fundamental problem that casts doubt on any comparison between features. To address it we turn to recent applications of game theory and develop fast exact tree solutions for SHAP (SHapley Additive exPlanation) values, which are the unique consistent and locally accurate attribution values. We then extend SHAP values to interaction effects and define SHAP interaction values. We propose a rich visualization of individualized feature attributions that improves over classic attribution summaries and partial dependence plots, and a unique “supervised” clustering (clustering based on feature attributions). We demonstrate better agreement with human intuition through a user study, exponential improvements in run time, improved clustering performance, and better identification of influential features. An implementation of our algorithm has also been merged into XGBoost and LightGBM, see http://github.com/slundberg/shap for details.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1802.03888 [cs, stat]},
	author = {Lundberg, Scott M. and Erion, Gabriel G. and Lee, Su-In},
	month = mar,
	year = {2019},
	note = {arXiv: 1802.03888},
	keywords = {fatml, xai},
}

@article{StructureFunctionExplanations,
	title = {The structure and function of explanations},
	volume = {10},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661306002117},
	doi = {10.1016/j.tics.2006.08.004},
	language = {en},
	number = {10},
	urldate = {2019-12-29},
	journal = {Trends in Cognitive Sciences},
	author = {Lombrozo, Tania},
	month = oct,
	year = {2006},
	keywords = {vis},
	pages = {464--470},
}

@article{VisualExplorationFrequentPatterns,
	title = {Visual exploration of frequent patterns in multivariate time series},
	volume = {11},
	issn = {1473-8716, 1473-8724},
	url = {http://ivi.sagepub.com/lookup/doi/10.1177/1473871611430769},
	doi = {10.1177/1473871611430769},
	abstract = {The detection of frequently occurring patterns, also called motifs, in data streams has been recognized as an important task. To find these motifs, we use an advanced event encoding and pattern discovery algorithm. As a large time series can contain hundreds of motifs, there is a need to support interactive analysis and exploration. In addition, for certain applications, such as data center resource management, service managers want to be able to predict the next day’s power consumption from the previous months’ data. For this purpose, we introduce four novel visual analytics methods: (i) motif layout – using colored rectangles for visualizing the occurrences and hierarchical relationships of motifs; (ii) motif distortion – enlarging or shrinking motifs for visualizing them more clearly; (iii) motif merging – combining a number of identical adjacent motif instances to simplify the display; and (iv) pattern preserving prediction – using a pattern-preserving smoothing and prediction algorithm to provide a reliable prediction for seasonal data. We have applied these methods to three real-world datasets: data center chilling utilization, oil well production, and system resource utilization. The results enable service managers to interactively examine motifs and gain new insights into the recurring patterns to analyze system operations. Using the above methods, we have also predicted both power consumption and server utilization in data centers with an accuracy of 70–80\%.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {Information Visualization},
	author = {Hao, M. C. and Marwah, M. and Janetzko, H. and Dayal, U. and Keim, D. A. and Patnaik, D. and Ramakrishnan, N. and Sharma, R. K.},
	month = jan,
	year = {2012},
	keywords = {vis},
	pages = {71--83},
}

@article{UserBasedVisualAnalytics,
	title = {A {User}‐based {Visual} {Analytics} {Workflow} for {Exploratory} {Model} {Analysis}},
	volume = {38},
	issn = {0167-7055, 1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13681},
	doi = {10.1111/cgf.13681},
	abstract = {Many visual analytics systems allow users to interact with machine learning models towards the goals of data exploration and insight generation on a given dataset. However, in some situations, insights may be less important than the production of an accurate predictive model for future use. In that case, users are more interested in generating of diverse and robust predictive models, verifying their performance on holdout data, and selecting the most suitable model for their usage scenario. In this paper, we consider the concept of Exploratory Model Analysis (EMA), which is deﬁned as the process of discovering and selecting relevant models that can be used to make predictions on a data source. We delineate the differences between EMA and the well-known term exploratory data analysis in terms of the desired outcome of the analytic process: insights into the data or a set of deployable models. The contributions of this work are a visual analytics system workﬂow for EMA, a user study, and two use cases validating the effectiveness of the workﬂow. We found that our system workﬂow enabled users to generate complex models, to assess them for various qualities, and to select the most relevant model for their task.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Computer Graphics Forum},
	author = {Cashman, Dylan and Humayoun, Shah Rukh and Heimerl, Florian and Park, Kendall and Das, Subhajit and Thompson, John and Saket, Bahador and Mosca, Abigail and Stasko, John and Endert, Alex and Gleicher, Michael and Chang, Remco},
	month = jun,
	year = {2019},
	keywords = {vis},
	pages = {185--199},
}

@article{VisualAnalyticsConceptExploration,
	title = {Visual analytics for concept exploration in subspaces of patient groups: {Making} sense of complex datasets with the {Doctor}-in-the-loop},
	volume = {3},
	issn = {2198-4018, 2198-4026},
	shorttitle = {Visual analytics for concept exploration in subspaces of patient groups},
	url = {http://link.springer.com/10.1007/s40708-016-0043-5},
	doi = {10.1007/s40708-016-0043-5},
	language = {en},
	number = {4},
	urldate = {2019-12-29},
	journal = {Brain Informatics},
	author = {Hund, Michael and Böhm, Dominic and Sturm, Werner and Sedlmair, Michael and Schreck, Tobias and Ullrich, Torsten and Keim, Daniel A. and Majnaric, Ljiljana and Holzinger, Andreas},
	month = dec,
	year = {2016},
	keywords = {vis},
	pages = {233--247},
}

@inproceedings{HumanCenteredToolsCopingImperfect,
	address = {Glasgow, Scotland Uk},
	title = {Human-{Centered} {Tools} for {Coping} with {Imperfect} {Algorithms} {During} {Medical} {Decision}-{Making}},
	isbn = {978-1-4503-5970-2},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300234},
	doi = {10.1145/3290605.3300234},
	abstract = {Machin e lear nin g (ML) is incr easingly being use d in image retrieval systems for medical decision making. On e app lication of ML is to retrieve visually similar medical images from pas t patients (e.g. tissue from biops ies) to reference whe n making a medical decision with a new pat ient. Howeve r, no algorithm can perfectly captu re an expert ' s ideal notion of similarity for every case: an image th at is algorithmi cally determin ed to be similar may not be medically relevant to a doctor' s specific diagnostic needs. In this pape r, we identified the needs of patho logists whe n searchin g for similar images retrieved usin g a deep lear nin g algorithm , and develope d tools that empower use rs to cope with the search algorithm on-the -fly, communi cating what types of similarity are most import ant at different moment s in time. In two evaluations with path ologists, we found th at th ese refinement tools increased the diagnos tic utility of images found and increased user trus t in the algorithm. Th e tools we re preferred over a traditi onal interface, without a loss in diagnostic accuracy. We also observe d that users adopted new str ategies whe n using refinement tools, re-purpos ing th em to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken togethe r, these findings inform futur e hum an-ML collabo rative systems for expe rt decision-m aking.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '19},
	publisher = {ACM Press},
	author = {Cai, Carrie J. and Stumpe, Martin C. and Terry, Michael and Reif, Emily and Hegde, Narayan and Hipp, Jason and Kim, Been and Smilkov, Daniel and Wattenberg, Martin and Viegas, Fernanda and Corrado, Greg S.},
	year = {2019},
	keywords = {vis},
	pages = {1--14},
}

@article{PointNetDeepHierarchicalFeature,
	title = {{PointNet}++: {Deep} {Hierarchical} {Feature} {Learning} on {Point} {Sets} in a {Metric} {Space}},
	abstract = {Few prior works study deep learning on point sets. PointNet [20] is a pioneer in this direction. However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize ﬁne-grained patterns and generalizability to complex scenes. In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set. By exploiting metric space distances, our network is able to learn local features with increasing contextual scales. With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. Experiments show that our network called PointNet++ is able to learn deep point set features efﬁciently and robustly. In particular, results signiﬁcantly better than state-of-the-art have been obtained on challenging benchmarks of 3D point clouds.},
	language = {en},
	author = {Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
	pages = {10},
}

@article{UnsupervisedFeatureExtractionTimeContrastive,
	title = {Unsupervised {Feature} {Extraction} by {Time}-{Contrastive} {Learning} and {Nonlinear} {ICA}},
	abstract = {Nonlinear independent component analysis (ICA) provides an appealing framework for unsupervised feature learning, but the models proposed so far are not identiﬁable. Here, we ﬁrst propose a new intuitive principle of unsupervised deep learning from time series which uses the nonstationary structure of the data. Our learning principle, time-contrastive learning (TCL), ﬁnds a representation which allows optimal discrimination of time segments (windows). Surprisingly, we show how TCL can be related to a nonlinear ICA model, when ICA is redeﬁned to include temporal nonstationarities. In particular, we show that TCL combined with linear ICA estimates the nonlinear ICA model up to point-wise transformations of the sources, and this solution is unique — thus providing the ﬁrst identiﬁability result for nonlinear ICA which is rigorous, constructive, as well as very general.},
	language = {en},
	author = {Hyvärinen, Aapo and Morioka, Hiroshi},
	pages = {10},
}

@article{HierarchicalTopicsVisuallyExploringLarge,
	title = {{HierarchicalTopics}: {Visually} {Exploring} {Large} {Text} {Collections} {Using} {Topic} {Hierarchies}},
	volume = {19},
	issn = {1077-2626},
	shorttitle = {{HierarchicalTopics}},
	url = {http://ieeexplore.ieee.org/document/6634160/},
	doi = {10.1109/TVCG.2013.162},
	abstract = {Analyzing large textual collections has become increasingly challenging given the size of the data available and the rate that more data is being generated. Topic-based text summarization methods coupled with interactive visualizations have presented promising approaches to address the challenge of analyzing large text corpora. As the text corpora and vocabulary grow larger, more topics need to be generated in order to capture the meaningful latent themes and nuances in the corpora. However, it is difﬁcult for most of current topic-based visualizations to represent large number of topics without being cluttered or illegible. To facilitate the representation and navigation of a large number of topics, we propose a visual analytics system - HierarchicalTopic (HT). HT integrates a computational algorithm, Topic Rose Tree, with an interactive visual interface. The Topic Rose Tree constructs a topic hierarchy based on a list of topics. The interactive visual interface is designed to present the topic content as well as temporal evolution of topics in a hierarchical fashion. User interactions are provided for users to make changes to the topic hierarchy based on their mental model of the topic space. To qualitatively evaluate HT, we present a case study that showcases how HierarchicalTopics aid expert users in making sense of a large number of topics and discovering interesting patterns of topic groups. We have also conducted a user study to quantitatively evaluate the effect of hierarchical topic structure. The study results reveal that the HT leads to faster identiﬁcation of large number of relevant topics. We have also solicited user feedback during the experiments and incorporated some suggestions into the current version of HierarchicalTopics.},
	language = {en},
	number = {12},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {{Wenwen Dou} and {Li Yu} and {Xiaoyu Wang} and {Zhiqiang Ma} and Ribarsky, William},
	month = dec,
	year = {2013},
	keywords = {vis},
	pages = {2002--2011},
}

@inproceedings{LeadLineInteractiveVisualAnalysis,
	address = {Seattle, WA, USA},
	title = {{LeadLine}: {Interactive} visual analysis of text data through event identification and exploration},
	isbn = {978-1-4673-4753-2 978-1-4673-4752-5},
	shorttitle = {{LeadLine}},
	url = {http://ieeexplore.ieee.org/document/6400485/},
	doi = {10.1109/VAST.2012.6400485},
	abstract = {Figure 4: Topic Cloud with the topic related to mobile device/technology highlighted. Keywords in blue are the time-sensitive keywords in a certain time span. The topics are extracted from CNN news corpora (Aug 15 - Nov 5, 2011).},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2012 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Dou, Wenwen and Wang, Xiaoyu and Skau, Drew and Ribarsky, William and Zhou, Michelle X.},
	month = oct,
	year = {2012},
	keywords = {vis},
	pages = {93--102},
}

@inproceedings{TrendQuerySystemInteractiveExploration,
	address = {San Francisco, California},
	title = {{TrendQuery}: a system for interactive exploration of trends},
	isbn = {978-1-4503-4207-0},
	shorttitle = {{TrendQuery}},
	url = {http://dl.acm.org/citation.cfm?doid=2939502.2939514},
	doi = {10.1145/2939502.2939514},
	abstract = {The surfacing of trends from data collections such as usergenerated content streams and news articles is a popular and important data analysis activity, used in applications such as business intelligence, quantitative stock trading and, social media exploration. Unlike traditional content analysis, trend analysis includes an additional vital time dimension: a trend can be deﬁned as a temporal pattern over a group of semantically related items. The unsupervised discovery of trends is often not suﬃcient, either due to inadequacies in the trend analysis algorithm, or because the data collection itself does not possess all of the information to identify the trend. Thus, it is necessary for an expert human-in-the-loop to be involved in the process of trend analysis.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics} - {HILDA} '16},
	publisher = {ACM Press},
	author = {Kamat, Niranjan and Wu, Eugene and Nandi, Arnab},
	year = {2016},
	keywords = {vis},
	pages = {1--4},
}

@article{InterpretableActiveLearning,
	title = {Interpretable {Active} {Learning}},
	url = {http://arxiv.org/abs/1708.00049},
	abstract = {Active learning has long been a topic of study in machine learning. However, as increasingly complex and opaque models have become standard practice, the process of active learning, too, has become more opaque. There has been little investigation into interpreting what speciﬁc trends and patterns an active learning strategy may be exploring. This work expands on the Local Interpretable Model-agnostic Explanations framework (LIME) to provide explanations for active learning recommendations. We demonstrate how LIME can be used to generate locally faithful explanations for an active learning strategy, and how these explanations can be used to understand how diﬀerent models and datasets explore a problem space over time.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1708.00049 [cs, stat]},
	author = {Phillips, Richard L. and Chang, Kyu Hyun and Friedler, Sorelle A.},
	month = jun,
	year = {2018},
	note = {arXiv: 1708.00049},
	keywords = {dm},
}

@article{HelixAcceleratingHumanintheloopMachine,
	title = {Helix: {Accelerating} {Human}-in-the-loop {Machine} {Learning}},
	volume = {11},
	issn = {21508097},
	shorttitle = {Helix},
	url = {http://arxiv.org/abs/1808.01095},
	doi = {10.14778/3229863.3236234},
	abstract = {Data application developers and data scientists spend an inordinate amount of time iterating on machine learning (ML) workﬂows—by modifying the data pre-processing, model training, and postprocessing steps—via trial-and-error to achieve the desired model performance. Existing work on accelerating machine learning focuses on speeding up one-shot execution of workﬂows, failing to address the incremental and dynamic nature of typical ML development. We propose HELIX, a declarative machine learning system that accelerates iterative development by optimizing workﬂow execution end-to-end and across iterations. HELIX minimizes the runtime per iteration via program analysis and intelligent reuse of previous results, which are selectively materialized—trading off the cost of materialization for potential future beneﬁts—to speed up future iterations. Additionally, HELIX offers a graphical interface to visualize workﬂow DAGs and compare versions to facilitate iterative development. Through two ML applications, in classiﬁcation and in structured prediction, attendees will experience the succinctness of HELIX’s programming interface and the speed and ease of iterative development using HELIX. In our evaluations, HELIX achieved up to an order of magnitude reduction in cumulative run time compared to state-of-the-art machine learning tools.},
	language = {en},
	number = {12},
	urldate = {2019-12-29},
	journal = {Proceedings of the VLDB Endowment},
	author = {Xin, Doris and Ma, Litian and Liu, Jialin and Macke, Stephen and Song, Shuchen and Parameswaran, Aditya},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.01095},
	keywords = {vis},
	pages = {1958--1961},
}

@inproceedings{PALMMachineLearningExplanations,
	address = {Chicago, IL, USA},
	title = {{PALM}: {Machine} {Learning} {Explanations} {For} {Iterative} {Debugging}},
	isbn = {978-1-4503-5029-7},
	shorttitle = {{PALM}},
	url = {http://dl.acm.org/citation.cfm?doid=3077257.3077271},
	doi = {10.1145/3077257.3077271},
	abstract = {When a Deep Neural Network makes a misprediction, it can be challenging for a developer to understand why. While there are many models for interpretability in terms of predictive features, it may be more natural to isolate a small set of training examples that have the greatest inﬂuence on the prediction. However, it is often the case that every training example contributes to a prediction in some way but with varying degrees of responsibility. We present Partition Aware Local Model (PALM), which is a tool that learns and summarizes this responsibility structure to aide machine learning debugging. PALM approximates a complex model (e.g., a deep neural network) using a two-part surrogate model: a meta-model that partitions the training data, and a set of sub-models that approximate the patterns within each partition. These sub-models can be arbitrarily complex to capture intricate local patterns. However, the metamodel is constrained to be a decision tree. This way the user can examine the structure of the meta-model, determine whether the rules match intuition, and link problematic test examples to responsible training data efﬁciently. Queries to PALM are nearly 30x faster than nearest neighbor queries for identifying relevant data, which is a key property for interactive applications.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 2nd {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics} - {HILDA}'17},
	publisher = {ACM Press},
	author = {Krishnan, Sanjay and Wu, Eugene},
	year = {2017},
	keywords = {vis},
	pages = {1--6},
}

@article{SearchShowContextExpand,
	title = {“{Search}, {Show} {Context}, {Expand} on {Demand}”: {Supporting} {Large} {Graph} {Exploration} with {Degree}-of-{Interest}},
	volume = {15},
	issn = {1077-2626},
	shorttitle = {“{Search}, {Show} {Context}, {Expand} on {Demand}”},
	url = {http://ieeexplore.ieee.org/document/5290699/},
	doi = {10.1109/TVCG.2009.108},
	abstract = {A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas’ original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.},
	language = {en},
	number = {6},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {van Ham, F. and Perer, A.},
	month = nov,
	year = {2009},
	keywords = {vis},
	pages = {953--960},
}

@article{InteractiveKnowledgeDiscoveryDoctorintheloop,
	title = {Interactive knowledge discovery with the doctor-in-the-loop: a practical example of cerebral aneurysms research},
	volume = {3},
	issn = {2198-4018, 2198-4026},
	shorttitle = {Interactive knowledge discovery with the doctor-in-the-loop},
	url = {http://link.springer.com/10.1007/s40708-016-0038-2},
	doi = {10.1007/s40708-016-0038-2},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Brain Informatics},
	author = {Girardi, Dominic and Küng, Josef and Kleiser, Raimund and Sonnberger, Michael and Csillag, Doris and Trenkler, Johannes and Holzinger, Andreas},
	month = sep,
	year = {2016},
	keywords = {vis},
	pages = {133--143},
}

@inproceedings{DrainingDataSwampSimilaritybased,
	address = {Houston, TX, USA},
	title = {Draining the {Data} {Swamp}: {A} {Similarity}-based {Approach}},
	isbn = {978-1-4503-5827-9},
	shorttitle = {Draining the {Data} {Swamp}},
	url = {http://dl.acm.org/citation.cfm?doid=3209900.3209911},
	doi = {10.1145/3209900.3209911},
	abstract = {While hierarchical namespaces such as filesystems and repositories have long been used to organize data, the rapid increase in data production places increasing strain on users who wish to make use of the data. So called “data lakes” embrace the storage of data in its natural form, integrating and organizing in a Pay-as-you-go fashion. While this model defers the upfront cost of integration, the result is that data is unusable for discovery or analysis until it is processed. Thus, data scientists are forced to spend significant time and energy on mundane tasks such as data discovery, cleaning, integration, and management – when this is neglected, “data lakes” become “data swamps.” Prior work suggests that pure computational methods for resolving issues with the data discovery and management components are insufficient. Here, we provide evidence to confirm this hypothesis, showing that methods such as automated file clustering are unable to extract the necessary features from repositories to provide useful information to end-user data scientists, or make effective data management decisions on their behalf. We argue that the combination of frameworks for specifying file similarity and human-in-the-loop interaction is needed to aid automated organization. We propose an initial step here, classifying several dimensions by which items may be considered similar: the data, its origin, and its current characteristics. We initially consider this model in the context of identifying data that can be integrated or managed collectively. We additionally explore how current methods can be used to automate decision making using real-world data repository and file systems, and suggest how an online user study could be developed to further validate this hypothesis. ACM Reference format: Will Brackenbury, Rui Liu, Mainack Mondal, Aaron J. Elmore, Blase Ur, Kyle Chard, Michael J. Franklin . 2018. Draining the Data Swamp: A Similaritybased Approach. In Proceedings of HILDA ’18, Houston, TX, USA, June 10, 2018, 7 pages.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the {Workshop} on {Human}-{In}-the-{Loop} {Data} {Analytics} - {HILDA}'18},
	publisher = {ACM Press},
	author = {Brackenbury, Will and Liu, Rui and Mondal, Mainack and Elmore, Aaron J. and Ur, Blase and Chard, Kyle and Franklin, Michael J.},
	year = {2018},
	keywords = {vis},
	pages = {1--7},
}

@article{HumanCenteredMachineLearningInteractive,
	title = {Human-{Centered} {Machine} {Learning} {Through} {Interactive} {Visualization}: {Review} and {Open} {Challenges}},
	abstract = {The goal of visual analytics (VA) systems is to solve complex problems by integrating automated data analysis methods, such as machine learning (ML) algorithms, with interactive visualizations. We propose a conceptual framework that models human interactions with ML components in the VA process, and makes the crucial interplay between automated algorithms and interactive visualizations more concrete. The framework is illustrated through several examples. We derive three open research challenges at the intersection of ML and visualization research that will lead to more effective data analysis.},
	language = {en},
	journal = {Computational Intelligence},
	author = {Sacha, Dominik and Sedlmair, Michael and Zhang, Leishi and Lee, John Aldo and Weiskopf, Daniel and North, Stephen and Keim, Daniel},
	year = {2016},
	keywords = {vis},
	pages = {7},
}

@article{UserCenteredActiveLearningAlgorithms,
	title = {Towards {User}-{Centered} {Active} {Learning} {Algorithms}},
	volume = {37},
	issn = {01677055},
	url = {http://doi.wiley.com/10.1111/cgf.13406},
	doi = {10.1111/cgf.13406},
	abstract = {The labeling of data sets is a time-consuming task, which is, however, an important prerequisite for machine learning and visual analytics. Visual-interactive labeling (VIAL) provides users an active role in the process of labeling, with the goal to combine the potentials of humans and machines to make labeling more efﬁcient. Recent experiments showed that users apply different strategies when selecting instances for labeling with visual-interactive interfaces. In this paper, we contribute a systematic quantitative analysis of such user strategies. We identify computational building blocks of user strategies, formalize them, and investigate their potentials for different machine learning tasks in systematic experiments. The core insights of our experiments are as follows. First, we identiﬁed that particular user strategies can be used to considerably mitigate the bootstrap (cold start) problem in early labeling phases. Second, we observed that they have the potential to outperform existing active learning strategies in later phases. Third, we analyzed the identiﬁed core building blocks, which can serve as the basis for novel selection strategies. Overall, we observed that data-based user strategies (clusters, dense areas) work considerably well in early phases, while model-based user strategies (e.g., class separation) perform better during later phases. The insights gained from this work can be applied to develop novel active learning approaches as well as to better guide users in visual interactive labeling.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Computer Graphics Forum},
	author = {Bernard, Jürgen and Zeppelzauer, Matthias and Lehmann, Markus and Müller, Martin and Sedlmair, Michael},
	month = jun,
	year = {2018},
	keywords = {dm},
	pages = {121--132},
}

@article{RepresentationMappingNovelApproach,
	title = {Representation {Mapping}: {A} {Novel} {Approach} to {Generate} {High}-{Quality} {Multi}-{Lingual} {Emotion} {Lexicons}},
	abstract = {In the past years, sentiment analysis has increasingly shifted attention to representational frameworks more expressive than semantic polarity (being positive, negative or neutral). However, these richer formats (like Basic Emotions or Valence-Arousal-Dominance, and variants therefrom), rooted in psychological research, tend to proliferate the number of representation schemes for emotion encoding. Thus, a large amount of representationally incompatible emotion lexicons has been developed by various research groups adopting one or the other emotion representation format. As a consequence, the reusability of these resources decreases as does the comparability of systems using them. In this paper, we propose to solve this dilemma by methods and tools which map different representation formats onto each other for the sake of mutual compatibility and interoperability of language resources. We present the ﬁrst large-scale investigation of such representation mappings for four typologically diverse languages and ﬁnd evidence that our approach produces (near-)gold quality emotion lexicons, even in crosslingual settings. Finally, we use our models to create new lexicons for eight typologically diverse languages.},
	language = {en},
	author = {Buechel, Sven and Hahn, Udo},
	pages = {9},
}

@inproceedings{MiningValenceArousalDominance,
	address = {Austin, Texas},
	title = {Mining valence, arousal, and dominance: possibilities for detecting burnout and productivity?},
	isbn = {978-1-4503-4186-8},
	shorttitle = {Mining valence, arousal, and dominance},
	url = {http://dl.acm.org/citation.cfm?doid=2901739.2901752},
	doi = {10.1145/2901739.2901752},
	abstract = {Similar to other industries, the software engineering domain is plagued by psychological diseases such as burnout, which lead developers to lose interest, exhibit lower activity and/or feel powerless. Prevention is essential for such diseases, which in turn requires early identiﬁcation of symptoms. The emotional dimensions of Valence, Arousal and Dominance (VAD) are able to derive a person’s interest (attraction), level of activation and perceived level of control for a particular situation from textual communication, such as emails. As an initial step towards identifying symptoms of productivity loss in software engineering, this paper explores the VAD metrics and their properties on 700,000 Jira issue reports containing over 2,000,000 comments, since issue reports keep track of a developer’s progress on addressing bugs or new features. Using a general-purpose lexicon of 14,000 English words with known VAD scores, our results show that issue reports of diﬀerent type (e.g., Feature Request vs. Bug) have a fair variation of Valence, while increase in issue priority (e.g., from Minor to Critical) typically increases Arousal. Furthermore, we show that as an issue’s resolution time increases, so does the arousal of the individual the issue is assigned to. Finally, the resolution of an issue increases valence, especially for the issue Reporter and for quickly addressed issues. The existence of such relations between VAD and issue report activities shows promise that text mining in the future could oﬀer an alternative way for work health assessment surveys.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Proceedings of the 13th {International} {Workshop} on {Mining} {Software} {Repositories} - {MSR} '16},
	publisher = {ACM Press},
	author = {Mäntylä, Mika and Adams, Bram and Destefanis, Giuseppe and Graziotin, Daniel and Ortu, Marco},
	year = {2016},
	pages = {247--258},
}

@inproceedings{ExploringEfficiencyBatchActive,
	address = {Lyon, France},
	title = {Exploring the {Efficiency} of {Batch} {Active} {Learning} for {Human}-in-the-{Loop} {Relation} {Extraction}},
	isbn = {978-1-4503-5640-4},
	url = {http://dl.acm.org/citation.cfm?doid=3184558.3191546},
	doi = {10.1145/3184558.3191546},
	abstract = {Domain-specific relation extraction requires training data for supervised learning models, and thus, significant labeling effort. Distant supervision is often leveraged for creating large annotated corpora however these methods require handling the inherent noise. On the other hand, active learning approaches can reduce the annotation cost by selecting the most beneficial examples to label in order to learn a good model. The choice of examples can be performed sequentially, i.e. select one example in each iteration, or in batches, i.e. select a set of examples in each iteration. The optimization of the batch size is a practical problem faced in every real-world application of active learning, however it is often treated as a parameter decided in advance. In this work, we study the trade-off between model performance, the number of requested labels in a batch and the time spent in each round for real-time, domain specific relation extraction. Our results show that the use of an appropriate batch size produces competitive performance, even compared to a fully sequential strategy, while reducing the training time dramatically.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {Companion of the {The} {Web} {Conference} 2018 on {The} {Web} {Conference} 2018 - {WWW} '18},
	publisher = {ACM Press},
	author = {Lourentzou, Ismini and Gruhl, Daniel and Welch, Steve},
	year = {2018},
	keywords = {dm},
	pages = {1131--1138},
}

@article{NormsValenceArousalDominance,
	title = {Norms of valence, arousal, and dominance for 13,915 {English} lemmas},
	volume = {45},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-012-0314-x},
	doi = {10.3758/s13428-012-0314-x},
	abstract = {Information about the affective meanings of words is used by researchers working on emotions and moods, word recognition and memory, and text-based sentiment analysis. Three components of emotions are traditionally distinguished: valence (the pleasantness of a stimulus), arousal (the intensity of emotion provoked by a stimulus), and dominance (the degree of control exerted by a stimulus). Thus far, nearly all research has been based on the ANEW norms collected by Bradley and Lang (1999) for 1,034 words. We extended that database to nearly 14,000 English lemmas, providing researchers with a much richer source of information, including gender, age, and educational differences in emotion norms. As an example of the new possibilities, we included stimuli from nearly all of the category norms (e.g., types of diseases, occupations, and taboo words) collected by Van Overschelde, Rawson, and Dunlosky (Journal of Memory and Language 50:289-335, 2004), making it possible to include affect in studies of semantic memory.},
	language = {en},
	number = {4},
	urldate = {2019-12-29},
	journal = {Behavior Research Methods},
	author = {Warriner, Amy Beth and Kuperman, Victor and Brysbaert, Marc},
	month = dec,
	year = {2013},
	pages = {1191--1207},
}

@article{AffectiveNorms875Spanish,
	title = {Affective norms of 875 {Spanish} words for five discrete emotional categories and two emotional dimensions},
	volume = {48},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-015-0572-5},
	doi = {10.3758/s13428-015-0572-5},
	abstract = {In the present study, we introduce affective norms for a new set of Spanish words, the Madrid Affective Database for Spanish (MADS), that were scored on two emotional dimensions (valence and arousal) and on five discrete emotional categories (happiness, anger, sadness, fear, and disgust), as well as on concreteness, by 660 Spanish native speakers. Measures of several objective psycholinguistic variables—grammatical class, word frequency, number of letters, and number of syllables—for the words are also included. We observed high split-half reliabilities for every emotional variable and a strong quadratic relationship between valence and arousal. Additional analyses revealed several associations between the affective dimensions and discrete emotions, as well as with some psycholinguistic variables. This new corpus complements and extends prior databases in Spanish and allows for designing new experiments investigating the influence of affective content in language processing under both dimensional and discrete theoretical conceptions of emotion. These norms can be downloaded as supplemental materials for this article from www.dropbox.com/s/o6dpw3irk6utfhy/ Hinojosa\%20et\%20al\_Supplementary\%20materials.xlsx?dl=0.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {Behavior Research Methods},
	author = {Hinojosa, J. A. and Martínez-García, N. and Villalba-García, C. and Fernández-Folgueiras, U. and Sánchez-Carmona, A. and Pozo, M. A. and Montoro, P. R.},
	month = mar,
	year = {2016},
	pages = {272--284},
}

@article{EmotionAnalysisRegressionProblem,
	title = {Emotion {Analysis} as a {Regression} {Problem} \&ndash; {Dimensional} {Models} and {Their} {Implications} on {Emotion} {Representation} and {Metrical} {Evaluation}},
	copyright = {©2016 \&copy; The Authors and IOS Press.},
	issn = {0922-6389},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospressISBN&isbn=978-1-61499-671-2&spage=1114&doi=10.3233/978-1-61499-672-9-1114},
	doi = {10.3233/978-1-61499-672-9-1114},
	abstract = {Emotion analysis (EA) and sentiment analysis are closely related tasks differing in the psychological phenomenon they aim to catch. We address ﬁne-grained models for EA which treat the computation of the emotional status of narrative documents as a regression rather than a classiﬁcation problem, as performed by coarse-grained approaches. We introduce Ekman’s Basic Emotions (BE) and Russell and Mehrabian’s Valence-Arousal-Dominance (VAD) model—two major schemes of emotion representation following opposing lines of psychological research, i.e., categorical and dimensional models—and discuss problems when BEs are used in a regression approach. We present the ﬁrst natural language system thoroughly evaluated for ﬁne-grained emotion analysis using the VAD scheme. Although we only employ simple BOW features, we reach correlation values up until r = .65 with human annotations. Furthermore, we show that the prevailing evaluation methodology relying solely on Pearson’s correlation coefﬁcient r is deﬁcient which leads us to the introduction of a complementary error-based metric. Due to the lack of comparable (VAD-based) systems, we, ﬁnally, introduce a novel method of mapping between VAD and BE emotion representations to create a reasonable basis for comparison. This enables us to evaluate VAD output against human BE judgments and, thus, allows for a more direct comparison with existing BE-based emotion analysis systems. Even with this, admittedly, error-prone transformation step our VAD-based system achieves state-of-the-art performance in three out of six emotion categories, out-performing all existing BE-based systems but one.},
	language = {en},
	urldate = {2019-12-29},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Sven, Buechel and Udo, Hahn},
	year = {2016},
	pages = {1114--1122},
}

@article{FrameworkEmergentEmotionsBased,
	title = {A {Framework} for {Emergent} {Emotions}, {Based} on {Motivation} and {Cognitive} {Modulators}:},
	volume = {3},
	issn = {1947-9093, 1947-9107},
	shorttitle = {A {Framework} for {Emergent} {Emotions}, {Based} on {Motivation} and {Cognitive} {Modulators}},
	url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/jse.2012010104},
	doi = {10.4018/jse.2012010104},
	abstract = {While traditional appraisal models have been successful tools for describing and formalizing the behavior of emotional agents, they have little to say about the functional realization of affect and emotion within the cognitive processing of these agents. The cognitive architecture MicroPsi addresses emotion and motivation by defining pre-requisites over which affective dynamics and goal-seeking emerge. Here, these pre-requisites are explained in detail, along with a possible approach of using them to model personality traits.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {International Journal of Synthetic Emotions},
	author = {Bach, Joscha},
	month = jan,
	year = {2012},
	pages = {43--63},
}

@article{LeastSquareProjectionFast,
	title = {Least {Square} {Projection}: {A} {Fast} {High}-{Precision} {Multidimensional} {Projection} {Technique} and {Its} {Application} to {Document} {Mapping}},
	volume = {14},
	issn = {1077-2626},
	shorttitle = {Least {Square} {Projection}},
	url = {http://ieeexplore.ieee.org/document/4378370/},
	doi = {10.1109/TVCG.2007.70443},
	abstract = {The problem of projecting multidimensional data into lower dimensions has been pursued by many researchers due to its potential application to data analysis of various kinds. This paper presents a novel multidimensional projection technique based on least square approximations. The approximations compute the coordinates of a set of projected points based on the coordinates of a reduced number of control points with defined geometry. We name the technique Least Square Projections (LSP). From an initial projection of the control points, LSP defines the positioning of their neighboring points through a numerical solution that aims at preserving a similarity relationship between the points given by a metric in mD. In order to perform the projection, a small number of distance calculations are necessary, and no repositioning of the points is required to obtain a final solution with satisfactory precision. The results show the capability of the technique to form groups of points by degree of similarity in 2D. We illustrate that capability through its application to mapping collections of textual documents from varied sources, a strategic yet difficult application. LSP is faster and more accurate than other existing high-quality methods, particularly where it was mostly tested, that is, for mapping text sets.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Paulovich, F.V. and Nonato, L.G. and Minghim, R. and Levkowitz, H.},
	month = may,
	year = {2008},
	keywords = {vis},
	pages = {564--575},
}

@article{VAUTVisualAnalyticsSystem,
	title = {{VAUT}: a visual analytics system of spatiotemporal urban topics in reviews},
	volume = {21},
	issn = {1343-8875, 1875-8975},
	shorttitle = {{VAUT}},
	url = {http://link.springer.com/10.1007/s12650-017-0464-0},
	doi = {10.1007/s12650-017-0464-0},
	abstract = {Online review platforms offer customers the opportunities to express valuable feedback and personal views from various aspects on restaurants, products, works of art, or other items. A majority of previous studies on these user-generated reviews are devoted to controversy, bias, and opinion analysis. However, little work has been done to study urban characteristics via topic analysis from the city level in reviews. In this paper, we propose a visual analytics system, to visually explore spatiotemporal urban topics for cultural trend discovery, location mining, and decision making. Specifying a topic by users is supported due to the difference between review text and traditional text, such as news and books, and the diversity of topics and users. Sentiment analysis and statistical analysis are adopted to characterize the temporal trend and sentiment and topic geographical distributions of the user-speciﬁc topic. Our system allows the user to interactively explore the time-evolving frequency trend and characteristic geographical distributions of a topic in reviews. We evaluate the effectiveness and usefulness of our system using three case studies in different domains.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Journal of Visualization},
	author = {Xu, Jin and Tao, Yubo and Yan, Yuyu and Lin, Hai},
	month = jun,
	year = {2018},
	keywords = {vis},
	pages = {471--484},
}

@article{VAiRomaVisualAnalyticsSystem,
	title = {{VAiRoma}: {A} {Visual} {Analytics} {System} for {Making} {Sense} of {Places}, {Times}, and {Events} in {Roman} {History}},
	volume = {22},
	issn = {1077-2626},
	shorttitle = {{VAiRoma}},
	url = {http://ieeexplore.ieee.org/document/7192676/},
	doi = {10.1109/TVCG.2015.2467971},
	abstract = {Learning and gaining knowledge of Roman history is an area of interest for students and citizens at large. This is an example of a subject with great sweep (with many interrelated sub-topics over, in this case, a 3,000 year history) that is hard to grasp by any individual and, in its full detail, is not available as a coherent story. In this paper, we propose a visual analytics approach to construct a data driven view of Roman history based on a large collection of Wikipedia articles. Extracting and enabling the discovery of useful knowledge on events, places, times, and their connections from large amounts of textual data has always been a challenging task. To this aim, we introduce VAiRoma, a visual analytics system that couples state-of-the-art text analysis methods with an intuitive visual interface to help users make sense of events, places, times, and more importantly, the relationships between them. VAiRoma goes beyond textual content exploration, as it permits users to compare, make connections, and externalize the ﬁndings all within the visual interface. As a result, VAiRoma allows users to learn and create new knowledge regarding Roman history in an informed way. We evaluated VAiRoma with 16 participants through a user study, with the task being to learn about roman piazzas through ﬁnding relevant articles and new relationships. Our study results showed that the VAiRoma system enables the participants to ﬁnd more relevant articles and connections compared to Web searches and literature search conducted in a roman library. Subjective feedback on VAiRoma was also very positive. In addition, we ran two case studies that demonstrate how VAiRoma can be used for deeper analysis, permitting the rapid discovery and analysis of a small number of key documents even when the original collection contains hundreds of thousands of documents.},
	language = {en},
	number = {1},
	urldate = {2019-12-29},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Cho, Isaac and Dou, Wewnen and Wang, Derek Xiaoyu and Sauda, Eric and Ribarsky, William},
	month = jan,
	year = {2016},
	keywords = {vis},
	pages = {210--219},
}

@article{ExploringLinearProjectionsRevealing,
	title = {Exploring linear projections for revealing clusters, outliers, and trends in subsets of multi-dimensional datasets},
	volume = {48},
	issn = {1045926X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1045926X18301289},
	doi = {10.1016/j.jvlc.2018.08.003},
	abstract = {Identifying patterns in 2D linear projections is important in understanding multi-dimensional datasets. However, local patterns, which are composed of partial data points, are usually obscured by noises and missed in traditional quality measure approaches that measure the whole dataset. In this paper, we propose an interactive interface to explore 2D linear projections with visual patterns on subsets. First, we propose a voting-based algorithm to recommend optimal projection, in which the identiﬁed pattern looks the most salient. Speciﬁcally, we propose three kinds of point-wise quality metrics of 2D linear projections for outliers, clusterings, and trends, respectively. For each sampled projection, we measure its importance by accumulating the metrics of selected points. The projection with the highest importance is recommended. Second, we design an exploring interface with a scatterplot, a projection trail map, and a control panel. Our interface allows users to explore projections by specifying interested data subsets. At last, we employ three datasets and demonstrate the eﬀectiveness of our approach through three case studies of exploring clusters, outliers, and trends.},
	language = {en},
	urldate = {2020-01-02},
	journal = {Journal of Visual Languages \& Computing},
	author = {Xia, Jiazhi and Gao, Le and Kong, Kezhi and Zhao, Ying and Chen, Yi and Kui, Xiaoyan and Liang, Yixiong},
	month = oct,
	year = {2018},
	pages = {52--60},
}

@article{TELEGAMCombiningVisualizationVerbalizationa,
	title = {{TELEGAM}: {Combining} {Visualization} and {Verbalization} for {Interpretable} {Machine} {Learning}},
	abstract = {While machine learning (ML) continues to ﬁnd success in solving previously-thought hard problems, interpreting and exploring ML models remains challenging. Recent work has shown that visualizations are a powerful tool to aid debugging, analyzing, and interpreting ML models. However, depending on the complexity of the model (e.g., number of features), interpreting these visualizations can be difﬁcult and may require additional expertise. Alternatively, textual descriptions, or verbalizations, can be a simple, yet effective way to communicate or summarize key aspects about a model, such as the overall trend in a model’s predictions or comparisons between pairs of data instances. With the potential beneﬁts of visualizations and verbalizations in mind, we explore how the two can be combined to aid ML interpretability. Speciﬁcally, we present a prototype system, TELEGAM, that demonstrates how visualizations and verbalizations can collectively support interactive exploration of ML models, for example, generalized additive models (GAMs). We describe TELEGAM’s interface and underlying heuristics to generate the verbalizations. We conclude by discussing how TELEGAM can serve as a platform to conduct future studies for understanding user expectations and designing novel interfaces for interpretable ML.},
	language = {en},
	author = {Hohman, Fred and Srinivasan, Arjun and Drucker, Steven M},
	keywords = {rw-uu-vis-ml},
	pages = {5},
}

@article{KnowledgeBasedRecommenderDialogSystem,
	title = {Towards {Knowledge}-{Based} {Recommender} {Dialog} {System}},
	url = {http://arxiv.org/abs/1908.05391},
	abstract = {In this paper, we propose a novel end-to-end framework called KBRD, which stands for Knowledge-Based Recommender Dialog System. It integrates the recommender system and the dialog generation system. The dialog system can enhance the performance of the recommendation system by introducing knowledge-grounded information about users' preferences, and the recommender system can improve that of the dialog generation system by providing recommendation-aware vocabulary bias. Experimental results demonstrate that our proposed model has significant advantages over the baselines in both the evaluation of dialog generation and recommendation. A series of analyses show that the two systems can bring mutual benefits to each other, and the introduced knowledge contributes to both their performances.},
	urldate = {2020-01-02},
	journal = {arXiv:1908.05391 [cs]},
	author = {Chen, Qibin and Lin, Junyang and Zhang, Yichang and Ding, Ming and Cen, Yukuo and Yang, Hongxia and Tang, Jie},
	month = sep,
	year = {2019},
	note = {arXiv: 1908.05391},
	keywords = {kg, rec},
}

@article{AutomaticallyNeutralizingSubjectiveBias,
	title = {Automatically {Neutralizing} {Subjective} {Bias} in {Text}},
	url = {http://arxiv.org/abs/1911.09709},
	abstract = {Texts like news, encyclopedias, and some social media strive for objectivity. Yet bias in the form of inappropriate subjectivity - introducing attitudes via framing, presupposing truth, and casting doubt - remains ubiquitous. This kind of bias erodes our collective trust and fuels social conflict. To address this issue, we introduce a novel testbed for natural language generation: automatically bringing inappropriately subjective text into a neutral point of view ("neutralizing" biased text). We also offer the first parallel corpus of biased language. The corpus contains 180,000 sentence pairs and originates from Wikipedia edits that removed various framings, presuppositions, and attitudes from biased sentences. Last, we propose two strong encoder-decoder baselines for the task. A straightforward yet opaque CONCURRENT system uses a BERT encoder to identify subjective words as part of the generation process. An interpretable and controllable MODULAR algorithm separates these steps, using (1) a BERT-based classifier to identify problematic words and (2) a novel join embedding through which the classifier can edit the hidden states of the encoder. Large-scale human evaluation across four domains (encyclopedias, news headlines, books, and political speeches) suggests that these algorithms are a first step towards the automatic identification and reduction of bias.},
	urldate = {2020-01-02},
	journal = {arXiv:1911.09709 [cs]},
	author = {Pryzant, Reid and Martinez, Richard Diehl and Dass, Nathan and Kurohashi, Sadao and Jurafsky, Dan and Yang, Diyi},
	month = dec,
	year = {2019},
	note = {arXiv: 1911.09709},
	keywords = {fair, xai},
}

@inproceedings{InjectingLogicalBackgroundKnowledge,
	address = {Denver, Colorado},
	title = {Injecting {Logical} {Background} {Knowledge} into {Embeddings} for {Relation} {Extraction}},
	url = {http://aclweb.org/anthology/N15-1118},
	doi = {10.3115/v1/N15-1118},
	abstract = {Matrix factorization approaches to relation extraction provide several attractive features: they support distant supervision, handle open schemas, and leverage unlabeled data. Unfortunately, these methods share a shortcoming with all other distantly supervised approaches: they cannot learn to extract target relations without existing data in the knowledge base, and likewise, these models are inaccurate for relations with sparse data. Rule-based extractors, on the other hand, can be easily extended to novel relations and improved for existing but inaccurate relations, through ﬁrst-order formulae that capture auxiliary domain knowledge. However, usually a large set of such formulae is necessary to achieve generalization. In this paper, we introduce a paradigm for learning low-dimensional embeddings of entity-pairs and relations that combine the advantages of matrix factorization with ﬁrst-order logic domain knowledge. We introduce simple approaches for estimating such embeddings, as well as a novel training algorithm to jointly optimize over factual and ﬁrst-order logic information. Our results show that this method is able to learn accurate extractors with little or no distant supervision alignments, while at the same time generalizing to textual patterns that do not appear in the formulae.},
	language = {en},
	urldate = {2019-12-31},
	booktitle = {Proceedings of the 2015 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Rocktäschel, Tim and Singh, Sameer and Riedel, Sebastian},
	year = {2015},
	keywords = {comps-dm, iterative, kg},
	pages = {1119--1129},
}

@article{WhyShouldTrustInteractive,
	title = {"{Why} {Should} {I} {Trust} {Interactive} {Learners}?" {Explaining} {Interactive} {Queries} of {Classifiers} to {Users}},
	shorttitle = {"{Why} {Should} {I} {Trust} {Interactive} {Learners}?},
	url = {http://arxiv.org/abs/1805.08578},
	abstract = {Although interactive learning puts the user into the loop, the learner remains mostly a black box for the user. Understanding the reasons behind queries and predictions is important when assessing how the learner works and, in turn, trust. Consequently, we propose the novel framework of explanatory interactive learning: in each step, the learner explains its interactive query to the user, and she queries of any active classifier for visualizing explanations of the corresponding predictions. We demonstrate that this can boost the predictive and explanatory powers of and the trust into the learned model, using text (e.g. SVMs) and image classification (e.g. neural networks) experiments as well as a user study.},
	urldate = {2019-12-29},
	journal = {arXiv:1805.08578 [cs, stat]},
	author = {Teso, Stefano and Kersting, Kristian},
	month = may,
	year = {2018},
	note = {arXiv: 1805.08578},
	keywords = {iml, xai},
}

@article{SegmentbasedApproachClusteringMultitopic,
	title = {A segment-based approach to clustering multi-topic documents},
	volume = {34},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-012-0556-z},
	doi = {10.1007/s10115-012-0556-z},
	abstract = {Document clustering has been recognized as a central problem in text data management, and it becomes particularly challenging when documents have multiple topics. In this paper we address the problem of multi-topic document clustering by leveraging the natural composition of documents in text segments, which bear one or more topics on their own. We propose a segment-based document clustering framework, which is designed to induce a classiﬁcation of documents starting from the identiﬁcation of cohesive groups of segment-based portions of the original documents. We empirically give evidence of the signiﬁcance of our approach on diﬀerent, large collections of multi-topic documents.},
	language = {en},
	number = {3},
	urldate = {2019-12-29},
	journal = {Knowledge and Information Systems},
	author = {Tagarelli, Andrea and Karypis, George},
	month = mar,
	year = {2013},
	pages = {563--595},
}

@inproceedings{ParameterfreeSubsequencesTimeSeries,
	address = {Chonburi, Thailand},
	title = {Parameter-free subsequences time series clustering with various-width clusters},
	isbn = {978-1-4673-4853-9 978-1-4673-4850-8 978-1-4673-4852-2},
	url = {http://ieeexplore.ieee.org/document/6512805/},
	doi = {10.1109/KST.2013.6512805},
	abstract = {In time series mining, one of the interesting tasks that attract many researchers is time series clustering which is classified into two main categories. Whole time series clustering considers how to cluster multiple time series, and the other one is Subsequence Time Series (STS) clustering, a clustering of subparts or subsequences within a single time series. Deplorably, STS clustering is not preferable even though it had widely been used as a subroutine in various mining tasks, e.g., rule discovery, anomaly detection, or classification, due to the recent finding a decade ago that STS clustering problem can produce meaningless results. There have been numerous attempts to resolve this problem but seemed to be unsuccessful. Until the two most recent attempts, they seem to accomplish in producing meaningful results; however, their approaches do need some predefined constraint values, such as the width of the subsequences that are in fact quite subjective and sensitive. Thus, we propose a novel parameter-free clustering technique to eliminate this problem by utilizing a motif discovery algorithm and some statistical principles to properly determine these parameters. Our experimental results from well-known datasets demonstrate the effectiveness of the proposed algorithm in selecting the proper subsequence width, and in turn leading to meaningful and highly accurate results.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2013 5th {International} {Conference} on {Knowledge} and {Smart} {Technology} ({KST})},
	publisher = {IEEE},
	author = {Madicar, Navin and Sivaraks, Haemwaan and Rodpongpun, Sura and Ratanamahatana, Chotirat Ann},
	month = jan,
	year = {2013},
	pages = {150--155},
}

@article{SequenceModelingSegmentations,
	title = {Sequence {Modeling} via {Segmentations}},
	url = {http://arxiv.org/abs/1702.07463},
	abstract = {Segmental structure is a common pattern in many types of sequences such as phrases in human languages. In this paper, we present a probabilistic model for sequences via their segmentations.1 The probability of a segmented sequence is calculated as the product of the probabilities of all its segments, where each segment is modeled using existing tools such as recurrent neural networks. Since the segmentation of a sequence is usually unknown in advance, we sum over all valid segmentations to obtain the ﬁnal probability for the sequence. An efﬁcient dynamic programming algorithm is developed for forward and backward computations without resorting to any approximation. We demonstrate our approach on text segmentation and speech recognition tasks. In addition to quantitative results, we also show that our approach can discover meaningful segments in their respective application contexts.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1702.07463 [cs, stat]},
	author = {Wang, Chong and Wang, Yining and Huang, Po-Sen and Mohamed, Abdelrahman and Zhou, Dengyong and Deng, Li},
	month = jul,
	year = {2018},
	note = {arXiv: 1702.07463},
}

@article{DomainKnowledgeAidedExplainable,
	title = {Domain {Knowledge} {Aided} {Explainable} {Artificial} {Intelligence} for {Intrusion} {Detection} and {Response}},
	url = {http://arxiv.org/abs/1911.09853},
	abstract = {Artificial Intelligence (AI) has become an integral part of modern-day security solutions for its capability of learning very complex functions and handling "Big Data". However, the lack of explainability and interpretability of successful AI models is a key stumbling block when trust in a model's prediction is critical. This leads to human intervention, which in turn results in a delayed response or decision. While there have been major advancements in the speed and performance of AI-based intrusion detection systems, the response is still at human speed when it comes to explaining and interpreting a specific prediction or decision. In this work, we infuse popular domain knowledge (i.e., CIA principles) in our model for better explainability and validate the approach on a network intrusion detection test case. Our experimental results suggest that the infusion of domain knowledge provides better explainability as well as a faster decision or response. In addition, the infused domain knowledge generalizes the model to work well with unknown attacks, as well as open the path to adapt to a large stream of network traffic from numerous IoT devices.},
	urldate = {2019-12-29},
	journal = {arXiv:1911.09853 [cs]},
	author = {Islam, Sheikh Rabiul and Eberle, William and Ghafoor, Sheikh K. and Siraj, Ambareen and Rogers, Mike},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.09853},
	keywords = {domain-knowledge},
}

@inproceedings{TimeSeriesEpenthesisClustering,
	address = {Vancouver, BC, Canada},
	title = {Time {Series} {Epenthesis}: {Clustering} {Time} {Series} {Streams} {Requires} {Ignoring} {Some} {Data}},
	isbn = {978-1-4577-2075-8 978-0-7695-4408-3},
	shorttitle = {Time {Series} {Epenthesis}},
	url = {http://ieeexplore.ieee.org/document/6137259/},
	doi = {10.1109/ICDM.2011.146},
	abstract = {Given the pervasiveness of time series data in all human endeavors, and the ubiquity of clustering as a data mining application, it is somewhat surprising that the problem of time series clustering from a single stream remains largely unsolved. Most work on time series clustering considers the clustering of individual time series, e.g., gene expression profiles, individual heartbeats or individual gait cycles. The few attempts at clustering time series streams have been shown to be objectively incorrect in some cases, and in other cases shown to work only on the most contrived datasets by carefully adjusting a large set of parameters. In this work, we make two fundamental contributions. First, we show that the problem definition for time series clustering from streams currently used is inherently flawed, and a new definition is necessary. Second, we show that the Minimum Description Length (MDL) framework offers an efficient, effective and essentially parameter-free method for time series clustering. We show that our method produces objectively correct results on a wide variety of datasets from medicine, zoology and industrial process analyses.},
	language = {en},
	urldate = {2019-12-29},
	booktitle = {2011 {IEEE} 11th {International} {Conference} on {Data} {Mining}},
	publisher = {IEEE},
	author = {Rakthanmanon, Thanawin and Keogh, Eamonn J. and Lonardi, Stefano and Evans, Scott},
	month = dec,
	year = {2011},
	pages = {547--556},
}

@article{TimeSeriesClusteringBased,
	title = {Time series clustering based on the characterisation of segment typologies},
	url = {http://arxiv.org/abs/1810.11624},
	abstract = {Time series clustering is the process of grouping time series with respect to their similarity or characteristics. Previous approaches usually combine a speciﬁc distance measure for time series and a standard clustering method. However, these approaches do not take the similarity of the different subsequences of each time series into account, which can be used to better compare the time series objects of the dataset. In this paper, we propose a novel technique of time series clustering based on two clustering stages. In a ﬁrst step, a least squares polynomial segmentation procedure is applied to each time series, which is based on a growing window technique that returns different-length segments. Then, all the segments are projected into same dimensional space, based on the coefﬁcients of the model that approximates the segment and a set of statistical features. After mapping, a ﬁrst hierarchical clustering phase is applied to all mapped segments, returning groups of segments for each time series. These clusters are used to represent all time series in the same dimensional space, after deﬁning another speciﬁc mapping process. In a second and ﬁnal clustering stage, all the time series objects are grouped. We consider internal clustering quality to automatically adjust the main parameter of the algorithm, which is an error threshold for the segmentation. The results obtained on 84 datasets from the UCR Time Series Classiﬁcation Archive have been compared against two state-of-the-art methods, showing that the performance of this methodology is very promising.},
	language = {en},
	urldate = {2019-12-29},
	journal = {arXiv:1810.11624 [cs, stat]},
	author = {Guijo-Rubio, David and Durán-Rosal, Antonio Manuel and Gutiérrez, Pedro Antonio and Troncoso, Alicia and Hervás-Martínez, César},
	month = oct,
	year = {2018},
	note = {arXiv: 1810.11624},
}

@article{AssessingLocalInterpretabilityMachine,
	title = {Assessing the {Local} {Interpretability} of {Machine} {Learning} {Models}},
	url = {http://arxiv.org/abs/1902.03501},
	abstract = {The increasing adoption of machine learning tools has led to calls for accountability via model interpretability. But what does it mean for a machine learning model to be interpretable by humans, and how can this be assessed? We focus on two definitions of interpretability that have been introduced in the machine learning literature: simulatability (a user's ability to run a model on a given input) and "what if" local explainability (a user's ability to correctly determine a model's prediction under local changes to the input, given knowledge of the model's original prediction). Through a user study with 1,000 participants, we test whether humans perform well on tasks that mimic the definitions of simulatability and "what if" local explainability on models that are typically considered locally interpretable. To track the relative interpretability of models, we employ a simple metric, the runtime operation count on the simulatability task. We find evidence that as the number of operations increases, participant accuracy on the local interpretability tasks decreases. In addition, this evidence is consistent with the common intuition that decision trees and logistic regression models are interpretable and are more interpretable than neural networks.},
	urldate = {2020-01-14},
	journal = {arXiv:1902.03501 [cs, stat]},
	author = {Slack, Dylan and Friedler, Sorelle A. and Scheidegger, Carlos and Roy, Chitradeep Dutta},
	month = aug,
	year = {2019},
	note = {arXiv: 1902.03501},
	keywords = {evaluation, explanation, fatml},
}

@article{BagRecurrencePatternsRepresentation,
	title = {Bag of recurrence patterns representation for time-series classification},
	volume = {22},
	issn = {1433-7541, 1433-755X},
	url = {http://link.springer.com/10.1007/s10044-018-0703-6},
	doi = {10.1007/s10044-018-0703-6},
	abstract = {Time-series classification (TSC) has attracted a lot of attention in pattern recognition, because wide range of applications from different domains such as finance and health informatics deal with time-series signals. Bag-of-features (BoF) model has achieved a great success in TSC task by summarizing signals according to the frequencies of “feature words” of a data-learned dictionary. This paper proposes embedding the recurrence plots (RP), a visualization technique for analysis of dynamic systems, in the BoF model for TSC. While the traditional BoF approach extracts features from 1D signal segments, this paper uses the RP to transform time-series into 2D texture images and then applies the BoF on them. Image representation of time-series enables us to explore different visual descriptors that are not available for 1D signals and to treat TSC task as a texture recognition problem. Experimental results on the UCI time-series classification archive demonstrates a significant accuracy boost by the proposed bag of recurrence patterns, compared not only to the existing BoF models, but also to the state-of-the art algorithms.},
	language = {en},
	number = {3},
	urldate = {2020-01-11},
	journal = {Pattern Analysis and Applications},
	author = {Hatami, Nima and Gavet, Yann and Debayle, Johan},
	month = aug,
	year = {2019},
	pages = {877--887},
}

@article{ExplainingExplanationsSociety,
	title = {Explaining {Explanations} to {Society}},
	url = {http://arxiv.org/abs/1901.06560},
	abstract = {There is a disconnect between explanatory artificial intelligence (XAI) methods and the types of explanations that are useful for and demanded by society (policy makers, government officials, etc.) Questions that experts in artificial intelligence (AI) ask opaque systems provide inside explanations, focused on debugging, reliability, and validation. These are different from those that society will ask of these systems to build trust and confidence in their decisions. Although explanatory AI systems can answer many questions that experts desire, they often don't explain why they made decisions in a way that is precise (true to the model) and understandable to humans. These outside explanations can be used to build trust, comply with regulatory and policy changes, and act as external validation. In this paper, we focus on XAI methods for deep neural networks (DNNs) because of DNNs' use in decision-making and inherent opacity. We explore the types of questions that explanatory DNN systems can answer and discuss challenges in building explanatory systems that provide outside explanations for societal requirements and benefit.},
	urldate = {2020-01-06},
	journal = {arXiv:1901.06560 [cs]},
	author = {Gilpin, Leilani H. and Testart, Cecilia and Fruchter, Nathaniel and Adebayo, Julius},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.06560},
	keywords = {explanation, fatml, xai},
}

@article{ClusteringTreesVisualizationEvaluating,
	title = {Clustering trees: a visualization for evaluating clusterings at multiple resolutions},
	volume = {7},
	issn = {2047-217X},
	shorttitle = {Clustering trees},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6057528/},
	doi = {10.1093/gigascience/giy083},
	abstract = {Clustering techniques are widely used in the analysis of large datasets to group together samples with similar properties. For example, clustering is often used in the field of single-cell RNA-sequencing in order to identify different cell types present in a tissue sample. There are many algorithms for performing clustering, and the results can vary substantially. In particular, the number of groups present in a dataset is often unknown, and the number of clusters identified by an algorithm can change based on the parameters used. To explore and examine the impact of varying clustering resolution, we present clustering trees. This visualization shows the relationships between clusters at multiple resolutions, allowing researchers to see how samples move as the number of clusters increases. In addition, meta-information can be overlaid on the tree to inform the choice of resolution and guide in identification of clusters. We illustrate the features of clustering trees using a series of simulations as well as two real examples, the classical iris dataset and a complex single-cell RNA-sequencing dataset. Clustering trees can be produced using the clustree R package, available from CRAN and developed on GitHub.},
	number = {7},
	urldate = {2020-01-05},
	journal = {GigaScience},
	author = {Zappia, Luke and Oshlack, Alicia},
	month = jul,
	year = {2018},
	pmid = {30010766},
	pmcid = {PMC6057528},
	keywords = {clustering, vis},
}

@article{ExplainabilityHumanAgentSystems,
	title = {Explainability in human–agent systems},
	volume = {33},
	issn = {1387-2532, 1573-7454},
	url = {http://link.springer.com/10.1007/s10458-019-09408-y},
	doi = {10.1007/s10458-019-09408-y},
	abstract = {This paper presents a taxonomy of explainability in human–agent systems. We consider fundamental questions about the Why, Who, What, When and How of explainability. First, we deﬁne explainability, and its relationship to the related terms of interpretability, transparency, explicitness, and faithfulness. These deﬁnitions allow us to answer why explainability is needed in the system, whom it is geared to and what explanations can be generated to meet this need. We then consider when the user should be presented with this information. Last, we consider how objective and subjective measures can be used to evaluate the entire system. This last question is the most encompassing as it will need to evaluate all other issues regarding explainability.},
	language = {en},
	number = {6},
	urldate = {2020-01-06},
	journal = {Autonomous Agents and Multi-Agent Systems},
	author = {Rosenfeld, Avi and Richardson, Ariella},
	month = nov,
	year = {2019},
	keywords = {eval, vis, xai},
	pages = {673--705},
}

@article{BLACKBOXDESIGNINGTRANSPARENCY,
	title = {{INTO} {THE} {BLACK} {BOX}: {DESIGNING} {FOR} {TRANSPARENCY} {IN} {ARTIFICIAL} {INTELLIGENCE}},
	language = {en},
	author = {Vorm, Eric Stephen},
	keywords = {explanation, fatml, thesis, xai},
	pages = {228},
}

@article{StateoftheArtSetVisualization,
	title = {The {State}-of-the-{Art} of {Set} {Visualization}},
	volume = {35},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12722},
	doi = {10.1111/cgf.12722},
	abstract = {Sets comprise a generic data model that has been used in a variety of data analysis problems. Such problems involve analysing and visualizing set relations between multiple sets defined over the same collection of elements. However, visualizing sets is a non-trivial problem due to the large number of possible relations between them. We provide a systematic overview of state-of-the-art techniques for visualizing different kinds of set relations. We classify these techniques into six main categories according to the visual representations they use and the tasks they support. We compare the categories to provide guidance for choosing an appropriate technique for a given problem. Finally, we identify challenges in this area that need further research and propose possible directions to address these challenges. Further resources on set visualization are available at http://www.setviz.net.},
	number = {1},
	urldate = {2020-01-05},
	journal = {Computer Graphics Forum},
	author = {Alsallakh, Bilal and Micallef, Luana and Aigner, Wolfgang and Hauser, Helwig and Miksch, Silvia and Rodgers, Peter},
	year = {2016},
	keywords = {set, survey, vis},
	pages = {234--260},
}

@article{ConfluentDrawingParallelCoordinatesWebBased,
	title = {Confluent-{Drawing} {Parallel} {Coordinates}: {Web}-{Based} {Interactive} {Visual} {Analytics} of {Large} {Multi}-{Dimensional} {Data}},
	shorttitle = {Confluent-{Drawing} {Parallel} {Coordinates}},
	url = {http://arxiv.org/abs/1906.10017},
	abstract = {Parallel coordinates plot is one of the most popular and widely used visualization techniques for multi-dimensional data sets. Its main challenges for large-scale data sets are visual clutter and overplotting which hamper the recognition of patterns and trends in the data. In this paper, we propose a confluent drawing approach of parallel coordinates to support the web-based interactive visual analytics of large multi-dimensional data. The proposed method maps multi-dimensional data to node-link diagrams through the data binning-based clustering for each dimension. It uses density-based confluent drawing to visualize clusters and edges to reduce visual clutter and overplotting. Its rendering time is independent of the number of data items. It supports interactive visualization of large data sets without hardware acceleration in a normal web browser. Moreover, we design interactions to control the data binning process with this approach to support interactive visual analytics of large multi-dimensional data sets. Based on the proposed approach, we implement a web-based visual analytics application. The efficiency of the proposed method is examined through experiments on several data sets. The effectiveness of the proposed method is evaluated through a user study, in which two typical tasks of parallel coordinates plot are performed by participants to compare the proposed method with another parallel coordinates bundling technique. Results show that the proposed method significantly enhances the web-based interactive visual analytics of large multi-dimensional data.},
	urldate = {2020-01-03},
	journal = {arXiv:1906.10017 [cs]},
	author = {Cui, Wenqiang and Strazdins, Girts and Wang, Hao},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.10017},
	keywords = {parallel-coordinates, vis},
}

@article{ClusterawareArrangementParallelCoordinate,
	title = {Cluster-aware arrangement of the parallel coordinate plots},
	volume = {46},
	issn = {1045926X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1045926X17301921},
	doi = {10.1016/j.jvlc.2017.10.003},
	abstract = {The dimension ordering of parallel coordinate plots has been widely studied, aiming at the insightful exploration of multi-dimensional data. However, few works focus on the category distributions across dimensions and construct an effective dimension ordering to enable the visual exploration of clusters. Therefore, we propose a cluster-aware arrangement method of the parallel coordinate plots and design a visualization framework for the multi-dimensional data exploration. Firstly, a hierarchical clustering scheme is employed to identify the categories of interest across different dimensions. Then we design a group of icicle views to present the hierarchies of dimensions, the colors of which also indicate the relationships between different categories. A cluster-aware correlation is deﬁned to measure the relationships between different attribute axes, based on the distributions of categories. Furthermore, a matrix map is designed to present the relationships between dimensions, and the MDS method is employed to transform the dimensions into 2D coordinates, in which the correlations among the dimensions are conserved. At last, we solve the Traveling Salesman Problem (TSP) and achieve an automated dimension ordering of the parallel coordinate plots, which largely highlights the relations of categories across dimensions. A set of convenient interactions are also integrated in the visualization system, allowing users to get insights into the multi-dimensional data from various perspectives. A large number of experimental results and the credible user studies further demonstrate the usefulness of the cluster-aware arrangement of the parallel coordinate plots.},
	language = {en},
	urldate = {2020-01-02},
	journal = {Journal of Visual Languages \& Computing},
	author = {Zhou, Zhiguang and Ye, Zhifei and Yu, Jiajun and Chen, Weifeng},
	month = jun,
	year = {2018},
	keywords = {p-step-md},
	pages = {43--52},
}

@article{DesignEvaluationLineSymbolizations,
	title = {Design and evaluation of line symbolizations for origin–destination flow maps},
	volume = {16},
	issn = {1473-8716, 1473-8724},
	url = {http://journals.sagepub.com/doi/10.1177/1473871616681375},
	doi = {10.1177/1473871616681375},
	abstract = {We present the results of a user study comparing variants of commonly used line symbolizations for directed origin–destination flow maps. Our design and evaluation consisted of five line symbolizations that employ a combination of following visual variables: arrowheads, origin–destination coloring (color hue, and value), line shortening, line width, tapered edges (varying width from wide to narrow, and narrow to wide), and curvature asymmetry and strength. To guide our evaluation, we used a task-by-type typology and chose four representative tasks that are commonly used in flow map reading: identifying dominant direction of flows, flows with the highest magnitude (volume), spatial focusing of long flows toward a destination, and clusters of high netexports (net-outflow). We systematically analyzed user responses and task performance which we measured by task completion time and accuracy. We designed a web-based flow mapping and testing framework and recruited the participants from Amazon Mechanical Turk. To demonstrate the application and user experiment, we used 16 commodity flow data sets in the United States from 2007 and systematically rotated the layouts to evaluate the effect of layout orientation. From this study, we can conclude that there is potential usefulness for all of the five symbolizations we tested; however, the influence of the design on performance and perception depends on the type of the task. Also, we found that data and layout orientation have significant effects on performance and perception of patterns in flow maps which we attribute to the change in visual saliency of node and flow patterns in relation to the way users scan the map. We recommend that the choice of line symbolization should be guided by a task taxonomy which end users are expected to perform. We discuss various design trade-offs and recommendations and potential future work for designing and evaluating line symbolizations for flow mapping.},
	language = {en},
	number = {4},
	urldate = {2020-01-23},
	journal = {Information Visualization},
	author = {Koylu, Caglar and Guo, Diansheng},
	month = oct,
	year = {2017},
	pages = {309--331},
}

@inproceedings{RapidInteractiveMachineLearning,
	title = {Towards {Rapid} {Interactive} {Machine} {Learning}},
	abstract = {Our contribution is the design and evaluation of an interactive machine learning interface that rapidly provides the user with model feedback after every interaction. To address visual scalability, this interface communicates with the user via a “tip of the iceberg” approach, where the user interacts with a small set of recommended instances for each class. To address computational scalability, we developed an O(n) classification algorithm that incorporates user feedback incrementally, and without consulting the data’s underlying representation matrix. Our computational evaluation showed that this algorithm has similar accuracy to several off-the-shelf classification algorithms with small amounts of labeled data. Empirical evaluation revealed that users performed better using our design compared to an equivalent active learning setup.},
	author = {Arendt, Dustin and Northwest, Pacific and Wesslen, Ryan},
	year = {2019},
	keywords = {iml, vis},
}

@article{VisualizingHighDimensionalDataAdvancesa,
	title = {Visualizing {High}-{Dimensional} {Data}: {Advances} in the {Past} {Decade}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {Visualizing {High}-{Dimensional} {Data}},
	url = {http://ieeexplore.ieee.org/document/7784854/},
	doi = {10.1109/TVCG.2016.2640960},
	abstract = {Massive simulations and arrays of sensing devices, in combination with increasing computing resources, have generated large, complex, high-dimensional datasets used to study phenomena across numerous ﬁelds of study. Visualization plays an important role in exploring such datasets. We provide a comprehensive survey of advances in high-dimensional data visualization over the past 15 years. We aim at providing actionable guidance for data practitioners to navigate through a modular view of the recent advances, allowing the creation of new visualizations along the enriched information visualization pipeline and identifying future opportunities for visualization research.},
	language = {en},
	number = {3},
	urldate = {2020-01-19},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Shusen and Maljovec, Dan and Wang, Bei and Bremer, Peer-Timo and Pascucci, Valerio},
	month = mar,
	year = {2017},
	keywords = {vis},
	pages = {1249--1268},
}

@article{VisFlowWebbasedVisualizationFramework,
	title = {{VisFlow} - {Web}-based {Visualization} {Framework} for {Tabular} {Data} with a {Subset} {Flow} {Model}},
	volume = {23},
	issn = {2160-9306},
	doi = {10.1109/TVCG.2016.2598497},
	abstract = {Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Yu, Bowen and Silva, Cláudio T.},
	month = jan,
	year = {2017},
	keywords = {p-step-set-subset, vis},
	pages = {251--260},
}

@article{DataDrivenUserGuidanceMultiAttribute,
	title = {Data-{Driven} {User} {Guidance} in {Multi}-{Attribute} {Data} {Exploration}},
	language = {de},
	author = {Eckelt, Klaus},
	keywords = {vis},
	pages = {122},
}

@inproceedings{SMARTexploreSimplifyingHighDimensionalData,
	address = {Berlin, Germany},
	title = {{SMARTexplore}: {Simplifying} {High}-{Dimensional} {Data} {Analysis} through a {Table}-{Based} {Visual} {Analytics} {Approach}},
	isbn = {978-1-5386-6861-0},
	shorttitle = {{SMARTexplore}},
	url = {https://ieeexplore.ieee.org/document/8802486/},
	doi = {10.1109/VAST.2018.8802486},
	abstract = {We present SMARTEXPLORE, a novel visual analytics technique that simpliﬁes the identiﬁcation and understanding of clusters, correlations, and complex patterns in high-dimensional data. The analysis is integrated into an interactive table-based visualization that maintains a consistent and familiar representation throughout the analysis. The visualization is tightly coupled with pattern matching, subspace analysis, reordering, and layout algorithms. To increase the analyst’s trust in the revealed patterns, SMARTEXPLORE automatically selects and computes statistical measures based on dimension and data properties. While existing approaches to analyzing highdimensional data (e.g., planar projections and Parallel coordinates) have proven effective, they typically have steep learning curves for non-visualization experts. Our evaluation, based on three expert case studies, conﬁrms that non-visualization experts successfully reveal patterns in high-dimensional data when using SMARTEXPLORE.},
	language = {en},
	urldate = {2020-01-19},
	booktitle = {2018 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Blumenschein, Michael and Behrisch, Michael and Schmid, Stefanie and Butscher, Simon and Wahl, Deborah R. and Villinger, Karoline and Renner, Britta and Reiterer, Harald and Keim, Daniel A.},
	month = oct,
	year = {2018},
	keywords = {vis},
	pages = {36--47},
}

@article{VisualizingDynamicHierarchiesGraph,
	title = {Visualizing {Dynamic} {Hierarchies} in {Graph} {Sequences}},
	volume = {22},
	issn = {2160-9306},
	doi = {10.1109/TVCG.2015.2507595},
	abstract = {Graphs are used to model relations between objects, where these objects can be grouped hierarchically based on their connectivity. In many applications, the relations change over time and so does the hierarchical group structure. We developed a visualization technique that supports the analysis of the topology and the hierarchical group structure of a dynamic graph and the tracking of changes over time. Each graph of a sequence is visualized by an adjacency matrix, where the hierarchical group structure is encoded within the matrix using indentation and nested contours, complemented by icicle plots attached to the matrices. The density within and between subgroups of the hierarchy is represented within the matrices using a gray scale. To visualize changes, transitions and dissimilarities between the hierarchically structured graphs are shown using a flow metaphor and color coding. The design of our visualization technique allows us to show more than one hierarchical group structure of the same graph by stacking the sequences, where hierarchy comparison is supported not only within but also between sequences. To improve the readability, we minimize the number of crossing curves within and between sequences based on a sorting algorithm that sweeps through the sequences of hierarchies.},
	number = {10},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Vehlow, Corinna and Beck, Fabian and Weiskopf, Daniel},
	month = oct,
	year = {2016},
	keywords = {set, vis},
	pages = {2343--2357},
}

@article{BiSetSemanticEdgeBundling,
	title = {{BiSet}: {Semantic} {Edge} {Bundling} with {Biclusters} for {Sensemaking}},
	volume = {22},
	issn = {1077-2626},
	shorttitle = {{BiSet}},
	url = {http://ieeexplore.ieee.org/document/7192715/},
	doi = {10.1109/TVCG.2015.2467813},
	abstract = {Identifying coordinated relationships is an important task in data analytics. For example, an intelligence analyst might want to discover three suspicious people who all visited the same four cities. Existing techniques that display individual relationships, such as between lists of entities, require repetitious manual selection and signiﬁcant mental aggregation in cluttered visualizations to ﬁnd coordinated relationships. In this paper, we present BiSet, a visual analytics technique to support interactive exploration of coordinated relationships. In BiSet, we model coordinated relationships as biclusters and algorithmically mine them from a dataset. Then, we visualize the biclusters in context as bundled edges between sets of related entities. Thus, bundles enable analysts to infer task-oriented semantic insights about potentially coordinated activities. We make bundles as ﬁrst class objects and add a new layer, “in-between”, to contain these bundle objects. Based on this, bundles serve to organize entities represented in lists and visually reveal their membership. Users can interact with edge bundles to organize related entities, and vice versa, for sensemaking purposes. With a usage scenario, we demonstrate how BiSet supports the exploration of coordinated relationships in text analytics.},
	language = {en},
	number = {1},
	urldate = {2020-01-19},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Sun, Maoyuan and Mi, Peng and North, Chris and Ramakrishnan, Naren},
	month = jan,
	year = {2016},
	keywords = {set, vis},
	pages = {310--319},
}

@article{OneExplanationDoesNot,
	title = {One {Explanation} {Does} {Not} {Fit} {All}: {A} {Toolkit} and {Taxonomy} of {AI} {Explainability} {Techniques}},
	shorttitle = {One {Explanation} {Does} {Not} {Fit} {All}},
	url = {http://arxiv.org/abs/1909.03012},
	abstract = {As artificial intelligence and machine learning algorithms make further inroads into society, calls are increasing from multiple stakeholders for these algorithms to explain their outputs. At the same time, these stakeholders, whether they be affected citizens, government regulators, domain experts, or system developers, present different requirements for explanations. Toward addressing these needs, we introduce AI Explainability 360 (http://aix360.mybluemix.net/), an open-source software toolkit featuring eight diverse and state-of-the-art explainability methods and two evaluation metrics. Equally important, we provide a taxonomy to help entities requiring explanations to navigate the space of explanation methods, not only those in the toolkit but also in the broader literature on explainability. For data scientists and other users of the toolkit, we have implemented an extensible software architecture that organizes methods according to their place in the AI modeling pipeline. We also discuss enhancements to bring research innovations closer to consumers of explanations, ranging from simplified, more accessible versions of algorithms, to tutorials and an interactive web demo to introduce AI explainability to different audiences and application domains. Together, our toolkit and taxonomy can help identify gaps where more explainability methods are needed and provide a platform to incorporate them as they are developed.},
	urldate = {2020-01-16},
	journal = {arXiv:1909.03012 [cs, stat]},
	author = {Arya, Vijay and Bellamy, Rachel K. E. and Chen, Pin-Yu and Dhurandhar, Amit and Hind, Michael and Hoffman, Samuel C. and Houde, Stephanie and Liao, Q. Vera and Luss, Ronny and Mojsilović, Aleksandra and Mourad, Sami and Pedemonte, Pablo and Raghavendra, Ramya and Richards, John and Sattigeri, Prasanna and Shanmugam, Karthikeyan and Singh, Moninder and Varshney, Kush R. and Wei, Dennis and Zhang, Yunfeng},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.03012},
}

@article{QuestioningAIInformingDesign,
	title = {Questioning the {AI}: {Informing} {Design} {Practices} for {Explainable} {AI} {User} {Experiences}},
	shorttitle = {Questioning the {AI}},
	url = {http://arxiv.org/abs/2001.02478},
	doi = {10.1145/3313831.3376590},
	abstract = {A surge of interest in explainable AI (XAI) has led to a vast collection of algorithmic work on the topic. While many recognize the necessity to incorporate explainability features in AI systems, how to address real-world user needs for understanding AI remains an open question. By interviewing 20 UX and design practitioners working on various AI products, we seek to identify gaps between the current XAI algorithmic work and practices to create explainable AI products. To do so, we develop an algorithm-informed XAI question bank in which user needs for explainability are represented as prototypical questions users might ask about the AI, and use it as a study probe. Our work contributes insights into the design space of XAI, informs efforts to support design practices in this space, and identifies opportunities for future XAI work. We also provide an extended XAI question bank and discuss how it can be used for creating user-centered XAI.},
	urldate = {2020-01-16},
	journal = {arXiv:2001.02478 [cs]},
	author = {Liao, Q. Vera and Gruen, Daniel and Miller, Sarah},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.02478},
	keywords = {explanation, hci, xai},
}

@article{DataAugmentationDiscriminationPrevention,
	title = {Data {Augmentation} for {Discrimination} {Prevention} and {Bias} {Disambiguation}},
	abstract = {Machine learning models are prone to biased decisions due to biases in the datasets they are trained on. In this paper, we introduce a novel data augmentation technique to create a fairer dataset for model training that could also lend itself to understanding the type of bias existing in the dataset i.e. if bias arises from a lack of representation for a particular group (sampling bias) or if it arises because of human bias reflected in the labels (prejudice based bias). Given a dataset involving a protected attribute with a privileged and unprivileged group, we create an “ideal world” dataset: for every data sample, we create a new sample having the same features (except the protected attribute(s)) and label as the original sample but with the opposite protected attribute value. The synthetic data points are sorted in order of their proximity to the original training distribution and added successively to the real dataset to create intermediate datasets. We theoretically show that two different notions of fairness: statistical parity difference (independence) and average odds difference (separation) always change in the same direction using such an augmentation. We also show submodularity of the proposed fairness-aware augmentation approach that enables an efficient greedy algorithm. We empirically study the effect of training models on the intermediate datasets and show that this technique reduces the two bias measures while keeping the accuracy nearly constant for three datasets. We then discuss the implications of this study on the disambiguation of sample bias and prejudice based bias and discuss how pre-processing techniques should be evaluated in general. The proposed method can be used by policy makers—who want to use unbiased datasets to train machine learning models for their applications—to add a subset of synthetic points to an extent that they are comfortable with to mitigate unwanted bias.},
	language = {en},
	author = {Sharma, Shubham and Zhang, Yunfeng and Aliaga, Jesús M Ríos and Bouneffouf, Djallel and Muthusamy, Vinod and Varshney, Kush R},
	pages = {7},
}

@article{HowFairnessDefinitionsFare,
	title = {How {Do} {Fairness} {Definitions} {Fare}? {Examining} {Public} {Attitudes} {Towards} {Algorithmic} {Definitions} of {Fairness}},
	abstract = {What is the best way to deﬁne algorithmic fairness? While many deﬁnitions of fairness have been proposed in the computer science literature, there is no clear agreement over a particular deﬁnition. In this work, we investigate ordinary people’s perceptions of three of these fairness deﬁnitions. Across two online experiments, we test which deﬁnitions people perceive to be the fairest in the context of loan decisions, and whether fairness perceptions change with the addition of sensitive information (i.e., race of the loan applicants). Overall, one deﬁnition (calibrated fairness) tends to be more preferred than the others, and the results also provide support for the principle of afﬁrmative action.},
	language = {en},
	author = {Saxena, Nripsuta and Huang, Karen and DeFilippis, Evan and Radanovic, Goran and Parkes, David C and Liu, Yang},
	keywords = {fairnexx, fatml, xai},
	pages = {11},
}

@article{LocalExplanationsGlobalUnderstanding,
	title = {From local explanations to global understanding with explainable {AI} for trees},
	volume = {2},
	issn = {2522-5839},
	url = {http://www.nature.com/articles/s42256-019-0138-9},
	doi = {10.1038/s42256-019-0138-9},
	language = {en},
	number = {1},
	urldate = {2020-01-26},
	journal = {Nature Machine Intelligence},
	author = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
	month = jan,
	year = {2020},
	keywords = {fatml, xai},
	pages = {56--67},
}

@article{VisualExplorationLargeMultidimensional,
	title = {Visual {Exploration} of {Large} {Multidimensional} {Data} {Using} {Parallel} {Coordinates} on {Big} {Data} {Infrastructure}},
	volume = {4},
	issn = {2227-9709},
	url = {http://www.mdpi.com/2227-9709/4/3/21},
	doi = {10.3390/informatics4030021},
	abstract = {The increase of data collection in various domains calls for an adaptation of methods of visualization to tackle magnitudes exceeding the number of available pixels on screens and challenging interactivity. This growth of datasets size has been supported by the advent of accessible and scalable storage and computing infrastructure. Similarly, visualization systems need perceptual and interactive scalability. We present a complete system, complying with the constraints of aforesaid environment, for visual exploration of large multidimensional data with parallel coordinates. Perceptual scalability is addressed with data abstraction while interactions rely on server-side data-intensive computation and hardware-accelerated rendering on the client-side. The system employs a hybrid computing method to accommodate pre-computing time or space constraints and achieves responsiveness for main parallel coordinates plot interaction tools on billions of records.},
	language = {en},
	number = {3},
	urldate = {2020-01-25},
	journal = {Informatics},
	author = {Sansen, Joris and Richer, Gaëlle and Jourde, Timothée and Lalanne, Frédéric and Auber, David and Bourqui, Romain},
	month = jul,
	year = {2017},
	keywords = {parallel-coordinates, vis},
	pages = {21},
}

@article{TeachingMeaningfulExplanations,
	title = {Teaching {Meaningful} {Explanations}},
	url = {http://arxiv.org/abs/1805.11648},
	abstract = {The adoption of machine learning in high-stakes applications such as healthcare and law has lagged in part because predictions are not accompanied by explanations comprehensible to the domain user, who often holds the ultimate responsibility for decisions and outcomes. In this paper, we propose an approach to generate such explanations in which training data is augmented to include, in addition to features and labels, explanations elicited from domain users. A joint model is then learned to produce both labels and explanations from the input features. This simple idea ensures that explanations are tailored to the complexity expectations and domain knowledge of the consumer. Evaluation spans multiple modeling techniques on a game dataset, a (visual) aesthetics dataset, a chemical odor dataset and a Melanoma dataset showing that our approach is generalizable across domains and algorithms. Results demonstrate that meaningful explanations can be reliably taught to machine learning algorithms, and in some cases, also improve modeling accuracy.},
	urldate = {2020-01-25},
	journal = {arXiv:1805.11648 [cs]},
	author = {Codella, Noel C. F. and Hind, Michael and Ramamurthy, Karthikeyan Natesan and Campbell, Murray and Dhurandhar, Amit and Varshney, Kush R. and Wei, Dennis and Mojsilovic, Aleksandra},
	month = sep,
	year = {2018},
	note = {arXiv: 1805.11648},
	keywords = {explanation, fatml, xai},
}

@book{MachineLearningKnowledgeExtraction,
	address = {New York, NY},
	title = {Machine learning and knowledge extraction},
	isbn = {978-3-319-99739-1},
	language = {en},
	publisher = {Springer Berlin Heidelberg},
	year = {2018},
	keywords = {explanation, fatml, xai},
}

@article{ManipulatingMeasuringModelInterpretabilitya,
	title = {Manipulating and {Measuring} {Model} {Interpretability}},
	url = {http://arxiv.org/abs/1802.07810},
	abstract = {With the increased use of machine learning in decision-making scenarios, there has been a growing interest in creating human-interpretable machine learning models. While many such models have been proposed, there have been relatively few experimental studies of whether these models achieve their intended effects, such as encouraging people to follow the model’s predictions when the model is correct and to deviate when it makes a mistake. We present a series of randomized, pre-registered experiments comprising 3,800 participants in which people were shown functionally identical models that varied only in two factors thought to inﬂuence interpretability: the number of input features and the model transparency (clear or black-box). Predictably, participants who were shown a clear model with a small number of features were better able to simulate the model’s predictions. However, contrary to what one might expect when manipulating interpretability, we found no improvements in the degree to which participants followed the model’s predictions when it was beneﬁcial to do so. Even more surprisingly, increased transparency hampered people’s ability to detect when the model makes a sizable mistake and correct for it, seemingly due to information overload. These counterintuitive results suggest that decision scientists creating interpretable models should harbor a healthy skepticism of their intuitions and empirically verify that interpretable models achieve their intended effects.},
	language = {en},
	urldate = {2020-01-25},
	journal = {arXiv:1802.07810 [cs]},
	author = {Poursabzi-Sangdeh, Forough and Goldstein, Daniel G. and Hofman, Jake M. and Vaughan, Jennifer Wortman and Wallach, Hanna},
	month = nov,
	year = {2019},
	note = {arXiv: 1802.07810},
}

@article{EdgeBundlingInformationVisualization,
	title = {Edge bundling in information visualization},
	volume = {18},
	issn = {1007-0214},
	doi = {10.1109/TST.2013.6509098},
	abstract = {The edge, which can encode relational data in graphs and multidimensional data in parallel coordinates plots, is an important visual primitive for encoding data in information visualization research. However, when data become very large, visualizations often suffer from visual clutter as thousands of edges can easily overwhelm the display and obscure underlying patterns. Many edge-bundling techniques have been proposed to reduce visual clutter in visualizations. In this survey, we briefly introduce the visual-clutter problem in visualizations. Thereafter, we review the cost-based, geometry-based, and image-based edge-bundling methods for graphs, parallel coordinates, and flow maps. We then describe the various visualization applications that use edge-bundling techniques and discuss the evaluation studies concerning the effectiveness of edge-bundling methods. An edge-bundling taxonomy is proposed at the end of this survey.},
	number = {2},
	journal = {Tsinghua Science and Technology},
	author = {Zhou, Hong and Panpan Xu and Yuan, Xiaoru and Qu, Huamin},
	month = apr,
	year = {2013},
	pages = {145--156},
}

@article{HierarchicalEdgeBundlesVisualization,
	title = {Hierarchical edge bundles: {Visualization} of adjacency relations in hierarchical data},
	shorttitle = {Hierarchical edge bundles},
	abstract = {Abstract—A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations.},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Holten, Danny},
	year = {2006},
}

@article{DomainagnosticConstructionDomainSpecificOntologies,
	title = {Domain-agnostic {Construction} of {Domain}-{Speciﬁc} {Ontologies}},
	abstract = {In this poster, we present a novel approach to construct domain-speciﬁc ontologies with minimal user intervention from open data sources. We leverage techniques such as clustering and graph embeddings and show their usefulness in information retrieval tasks, thus reinforcing the idea that knowledge graphs and DL can be complementary technologies.},
	language = {en},
	author = {Uceda-Sosa, Rosario and Mihindukulasooriya, Nandana and Kumar, Atul},
	keywords = {kg},
	pages = {6},
}

@article{OntologybasedInterpretableMachineLearning,
	title = {Ontology-based {Interpretable} {Machine} {Learning} with {Learnable} {Anchors}},
	abstract = {In this paper, we introduce a novel interpreting framework that learns an interpretable model based on an ontology-based sampling technique to explain agnostic prediction models. Different from existing approaches, our algorithm considers contextual correlation among words, described in domain knowledge ontologies, to generate semantic explanations. To narrow down the search space for explanations, which is a major problem of long and complicated text data, we design a learnable anchor algorithm, to better extract explanations locally. A set of regulations is further introduced, regarding combining learned interpretable representations with anchors to generate comprehensible semantic explanations. An extensive experiment conducted on two real-world datasets shows that our approach generates more precise and insightful explanations compared with baseline approaches.},
	language = {en},
	author = {Lai, Phung and Phan, NhatHai and Newman, David and Hu, Han and Badeti, Anuja and Dou, Dejing},
	keywords = {fatml, ontology, xai},
	pages = {16},
}

@article{EnrichingWordEmbeddingsDomain,
	title = {Enriching {Word} {Embeddings} with {Domain} {Knowledge} for {Readability} {Assessment}},
	abstract = {In this paper, we present a method which learns the word embedding for readability assessment. For the existing word embedding models, they typically focus on the syntactic or semantic relations of words, while ignoring the reading difﬁculty, thus they may not be suitable for readability assessment. Hence, we provide the knowledge-enriched word embedding (KEWE), which encodes the knowledge on reading difﬁculty into the representation of words. Speciﬁcally, we extract the knowledge on word-level difﬁculty from three perspectives to construct a knowledge graph, and develop two word embedding models to incorporate the difﬁculty context derived from the knowledge graph to deﬁne the loss functions. Experiments are designed to apply KEWE for readability assessment on both English and Chinese datasets, and the results demonstrate both effectiveness and potential of KEWE.},
	language = {en},
	author = {Jiang, Zhiwei and Gu, Qing and Yin, Yafeng and Chen, Daoxu},
	pages = {13},
}

@article{KnowledgeGraphEmbeddingTranslating,
	title = {Knowledge {Graph} {Embedding} by {Translating} on {Hyperplanes}},
	abstract = {We deal with embedding a large scale knowledge graph composed of entities and relations into a continuous vector space. TransE is a promising method proposed recently, which is very efﬁcient while achieving state-of-the-art predictive performance. We discuss some mapping properties of relations which should be considered in embedding, such as reﬂexive, one-to-many, many-to-one, and many-to-many. We note that TransE does not do well in dealing with these properties. Some complex models are capable of preserving these mapping properties but sacriﬁce efﬁciency in the process. To make a good trade-off between model capacity and efﬁciency, in this paper we propose TransH which models a relation as a hyperplane together with a translation operation on it. In this way, we can well preserve the above mapping properties of relations with almost the same model complexity of TransE. Additionally, as a practical knowledge graph is often far from completed, how to construct negative examples to reduce false negative labels in training is very important. Utilizing the one-to-many/many-to-one mapping property of a relation, we propose a simple trick to reduce the possibility of false negative labeling. We conduct extensive experiments on link prediction, triplet classiﬁcation and fact extraction on benchmark datasets like WordNet and Freebase. Experiments show TransH delivers signiﬁcant improvements over TransE on predictive accuracy with comparable capability to scale up.},
	language = {en},
	author = {Wang, Zhen and Zhang, Jianwen and Feng, Jianlin and Chen, Zheng},
	pages = {8},
}

@article{ViBrVisualizingBipartiteRelations,
	title = {{ViBr}: {Visualizing} {Bipartite} {Relations} at {Scale} with the {Minimum} {Description} {Length} {Principle}},
	volume = {25},
	issn = {2160-9306},
	shorttitle = {{ViBr}},
	doi = {10.1109/TVCG.2018.2864826},
	abstract = {Bipartite graphs model the key relations in many large scale real-world data: customers purchasing items, legislators voting for bills, people's affiliation with different social groups, faults occurring in vehicles, etc. However, it is challenging to visualize large scale bipartite graphs with tens of thousands or even more nodes or edges. In this paper, we propose a novel visual summarization technique for bipartite graphs based on the minimum description length (MDL) principle. The method simultaneously groups the two different set of nodes and constructs aggregated bipartite relations with balanced granularity and precision. It addresses the key trade-off that often occurs for visualizing large scale and noisy data: acquiring a clear and uncluttered overview while maximizing the information content in it. We formulate the visual summarization task as a co-clustering problem and propose an efficient algorithm based on locality sensitive hashing (LSH) that can easily scale to large graphs under reasonable interactive time constraints that previous related methods cannot satisfy. The method leads to the opportunity of introducing a visual analytics framework with multiple levels-of-detail to facilitate interactive data exploration. In the framework, we also introduce a compact visual design inspired by adjacency list representation of graphs as the building block for a small multiples display to compare the bipartite relations for different subsets of data. We showcase the applicability and effectiveness of our approach by applying it on synthetic data with ground truth and performing case studies on real-world datasets from two application domains including roll-call vote record analysis and vehicle fault pattern analysis. Interviews with experts in the political science community and the automotive industry further highlight the benefits of our approach.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Chan, Gromit Yeuk-Yin and Xu, Panpan and Dai, Zeng and Ren, Liu},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {bipartite, vis},
	pages = {321--330},
}

@article{RetrofittingWordVectorsSemantic,
	title = {Retrofitting {Word} {Vectors} to {Semantic} {Lexicons}},
	url = {http://arxiv.org/abs/1411.4166},
	abstract = {Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for refining vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our refinement method outperforms prior techniques for incorporating semantic lexicons into the word vector training algorithms.},
	urldate = {2020-02-02},
	journal = {arXiv:1411.4166 [cs]},
	author = {Faruqui, Manaal and Dodge, Jesse and Jauhar, Sujay K. and Dyer, Chris and Hovy, Eduard and Smith, Noah A.},
	month = mar,
	year = {2015},
	note = {arXiv: 1411.4166},
	keywords = {dm, emb, key, retrofitting},
}

@article{ConceptNetOpenMultilingualGraph,
	title = {{ConceptNet} 5.5: {An} {Open} {Multilingual} {Graph} of {General} {Knowledge}},
	abstract = {Machine learning about language can be improved by supplying it with speciﬁc knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings.},
	language = {en},
	author = {Speer, Robyn and Chin, Joshua and Havasi, Catherine},
	keywords = {commonsense, key, kg},
	pages = {8},
}

@article{ATOMICAtlasMachineCommonsense,
	title = {{ATOMIC}: {An} {Atlas} of {Machine} {Commonsense} for {If}-{Then} {Reasoning}},
	shorttitle = {{ATOMIC}},
	url = {http://arxiv.org/abs/1811.00146},
	abstract = {We present ATOMIC, an atlas of everyday commonsense reasoning, organized through 877k textual descriptions of inferential knowledge. Compared to existing resources that center around taxonomic knowledge, ATOMIC focuses on inferential knowledge organized as typed if-then relations with variables (e.g., “if X pays Y a compliment, then Y will likely return the compliment”). We propose nine if-then relation types to distinguish causes vs. effects, agents vs. themes, voluntary vs. involuntary events, and actions vs. mental states. By generatively training on the rich inferential knowledge described in ATOMIC, we show that neural models can acquire simple commonsense capabilities and reason about previously unseen events. Experimental results demonstrate that multitask models that incorporate the hierarchical structure of if-then relation types lead to more accurate inference compared to models trained in isolation, as measured by both automatic and human evaluation.},
	language = {en},
	urldate = {2020-02-02},
	journal = {arXiv:1811.00146 [cs]},
	author = {Sap, Maarten and LeBras, Ronan and Allaway, Emily and Bhagavatula, Chandra and Lourie, Nicholas and Rashkin, Hannah and Roof, Brendan and Smith, Noah A. and Choi, Yejin},
	month = feb,
	year = {2019},
	note = {arXiv: 1811.00146},
	keywords = {commonsense},
}

@inproceedings{RetrofittingWordVectorsSemantica,
	address = {Denver, Colorado},
	title = {Retrofitting {Word} {Vectors} to {Semantic} {Lexicons}},
	url = {http://aclweb.org/anthology/N15-1184},
	doi = {10.3115/v1/N15-1184},
	abstract = {Vector space word representations are learned from distributional information of words in large corpora. Although such statistics are semantically informative, they disregard the valuable information that is contained in semantic lexicons such as WordNet, FrameNet, and the Paraphrase Database. This paper proposes a method for reﬁning vector space representations using relational information from semantic lexicons by encouraging linked words to have similar vector representations, and it makes no assumptions about how the input vectors were constructed. Evaluated on a battery of standard lexical semantic evaluation tasks in several languages, we obtain substantial improvements starting with a variety of word vector models. Our reﬁnement method outperforms prior techniques for incorporating semantic lexicons into word vector training algorithms.},
	language = {en},
	urldate = {2020-02-02},
	booktitle = {Proceedings of the 2015 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Faruqui, Manaal and Dodge, Jesse and Jauhar, Sujay Kumar and Dyer, Chris and Hovy, Eduard and Smith, Noah A.},
	year = {2015},
	keywords = {dm, emb, retrofitting},
	pages = {1606--1615},
}

@article{DeepLearningGraphsSurvey,
	title = {Deep {Learning} on {Graphs}: {A} {Survey}},
	shorttitle = {Deep {Learning} on {Graphs}},
	url = {http://arxiv.org/abs/1812.04202},
	abstract = {Deep learning has been shown successful in a number of domains, ranging from acoustics, images to natural language processing. However, applying deep learning to the ubiquitous graph data is non-trivial because of the unique characteristics of graphs. Recently, a signiﬁcant amount of research efforts have been devoted to this area, greatly advancing graph analyzing techniques. In this survey, we comprehensively review different kinds of deep learning methods applied to graphs. We divide existing methods into ﬁve categories based on their model architectures: Graph Recurrent Neural Networks, Graph Convolutional Networks, Graph Autoencoders, Graph Reinforcement Learning, and Graph Adversarial Methods. We then provide a comprehensive overview of these methods in a systematic manner mainly following their history of developments. We also analyze the differences and compositionality of different architectures. Finally, we brieﬂy outline their applications and discuss potential future directions.},
	language = {en},
	urldate = {2020-02-01},
	journal = {arXiv:1812.04202 [cs, stat]},
	author = {Zhang, Ziwei and Cui, Peng and Zhu, Wenwu},
	month = nov,
	year = {2019},
	note = {arXiv: 1812.04202},
	keywords = {dl, dm, network},
}

@article{ShowTellNeuralImage,
	title = {Show and {Tell}: {A} {Neural} {Image} {Caption} {Generator}},
	shorttitle = {Show and {Tell}},
	url = {http://arxiv.org/abs/1411.4555},
	abstract = {Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.},
	urldate = {2020-01-27},
	journal = {arXiv:1411.4555 [cs]},
	author = {Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
	month = apr,
	year = {2015},
	note = {arXiv: 1411.4555},
	keywords = {dl, dm, explanation},
}

@article{DeepVisualSemanticAlignmentsGenerating,
	title = {Deep {Visual}-{Semantic} {Alignments} for {Generating} {Image} {Descriptions}},
	abstract = {We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions signiﬁcantly outperform retrieval baselines on both full images and on a new dataset of region-level annotations.},
	language = {en},
	author = {Karpathy, Andrej and Fei-Fei, Li},
	keywords = {dl, dm, explanation},
	pages = {17},
}

@inproceedings{ExplanationArgumentation,
	address = {Southampton, United Kingdom},
	title = {Explanation through {Argumentation}},
	isbn = {978-1-4503-5953-5},
	url = {http://dl.acm.org/citation.cfm?doid=3284432.3284470},
	doi = {10.1145/3284432.3284470},
	abstract = {Computational Argumentation is a logical model of reasoning that has its origins in philosophy and provides a means for organising evidence for (or against) particular claims (or decisions). Argumentation-based Dialogue is a related methodology that is used for structuring interactions between two (or more) agents and has been explored within the Multi-Agent Systems community as an extended form of negotiation where agents can not only exchange claims, but also their reasons for believing (or disbelieving) those claims. Recently, the Artificial Intelligence (AI) community has become intrigued by the notion of “Explainable AI”, in which intelligent systems are able to explain predictions or decisions to (human) users. There is a natural pairing between Explainable AI and Argumentation: the first requires the need to clarify and defend decisions and the second provides a method for linking any decision to the evidence supporting it. In this paper, we describe how the two are connected and illustrate the utility of argumentationbased dialogue as a technique for implementing Explainable AI in a human-robot system.},
	language = {en},
	urldate = {2020-01-26},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Human}-{Agent} {Interaction} - {HAI} '18},
	publisher = {ACM Press},
	author = {Sklar, Elizabeth I. and Azhar, Mohammad Q.},
	year = {2018},
	keywords = {argumentation, explanation, fatml, xai},
	pages = {277--285},
}

@article{DifferentXAIDifferentHRI,
	title = {Different {XAI} for {Different} {HRI}},
	abstract = {Artiﬁcial Intelligence (AI) has become more widespread in critical decision making at all levels of robotics, along with demands that the agent also explain to us humans why they do what they do. This has driven renewed interest in Explainable Artiﬁcial Intelligence (XAI). Much work exists on the Human-Robot Interaction (HRI) challenges of creating and presenting explanations to different human users in different applications but matching these up with AI and Machine Learning (ML) techniques that can provide the underlying explanatory information can still be a challenge. In this short paper, we present a categorisation of explanations that communicate the XAI requirements of various users and applications, and the XAI capabilities of various underlying AI and ML techniques.},
	language = {en},
	author = {Sheh, Raymond K},
	keywords = {app, fatml, xai},
	pages = {4},
}

@article{DefiningExplainableAIRequirementsa,
	title = {Defining {Explainable} {AI} for {Requirements} {Analysis}},
	volume = {32},
	issn = {0933-1875, 1610-1987},
	url = {http://link.springer.com/10.1007/s13218-018-0559-3},
	doi = {10.1007/s13218-018-0559-3},
	abstract = {Explainable artificial intelligence (XAI) has become popular in the last few years. The artificial intelligence (AI) community in general, and the machine learning (ML) community in particular, is coming to the realisation that in many applications, for AI to be trusted, it must not only demonstrate good performance in its decisionmaking, but it also must explain these decisions and convince us that it is making the decisions for the right reasons. However, different applications have different requirements on the information required of the underlying AI system in order to convince us that it is worthy of our trust. How do we define these requirements? In this paper, we present three dimensions for categorising the explanatory requirements of different applications. These are Source, Depth and Scope. We focus on the problem of matching up the explanatory requirements of different applications with the capabilities of underlying ML techniques to provide them. We deliberately avoid including aspects of explanation that are already well-covered by the existing literature and we focus our discussion on ML although the principles apply to AI more broadly.},
	language = {en},
	number = {4},
	urldate = {2020-01-26},
	journal = {KI - Künstliche Intelligenz},
	author = {Sheh, Raymond and Monteath, Isaac},
	month = nov,
	year = {2018},
	pages = {261--266},
}

@article{DefiningExplainableAIRequirements,
	title = {Defining {Explainable} {AI} for {Requirements} {Analysis}},
	volume = {32},
	issn = {0933-1875, 1610-1987},
	url = {http://link.springer.com/10.1007/s13218-018-0559-3},
	doi = {10.1007/s13218-018-0559-3},
	abstract = {Explainable artificial intelligence (XAI) has become popular in the last few years. The artificial intelligence (AI) community in general, and the machine learning (ML) community in particular, is coming to the realisation that in many applications, for AI to be trusted, it must not only demonstrate good performance in its decisionmaking, but it also must explain these decisions and convince us that it is making the decisions for the right reasons. However, different applications have different requirements on the information required of the underlying AI system in order to convince us that it is worthy of our trust. How do we define these requirements? In this paper, we present three dimensions for categorising the explanatory requirements of different applications. These are Source, Depth and Scope. We focus on the problem of matching up the explanatory requirements of different applications with the capabilities of underlying ML techniques to provide them. We deliberately avoid including aspects of explanation that are already well-covered by the existing literature and we focus our discussion on ML although the principles apply to AI more broadly.},
	language = {en},
	number = {4},
	urldate = {2020-01-26},
	journal = {KI - Künstliche Intelligenz},
	author = {Sheh, Raymond and Monteath, Isaac},
	month = nov,
	year = {2018},
	keywords = {eval, fatml, xai},
	pages = {261--266},
}

@article{TUTORIALSUBSPACECLUSTERING,
	title = {A {TUTORIAL} {ON} {SUBSPACE} {CLUSTERING}},
	language = {en},
	author = {Vidal, Rene},
	keywords = {clustering, dm, subspace},
	pages = {17},
}

@article{SurveyVisualAnalyticPipelines,
	title = {A {Survey} of {Visual} {Analytic} {Pipelines}},
	volume = {31},
	issn = {1000-9000, 1860-4749},
	url = {http://link.springer.com/10.1007/s11390-016-1663-1},
	doi = {10.1007/s11390-016-1663-1},
	abstract = {Visual analytics has been widely studied in the past decade. One key to make visual analytics practical for both research and industrial applications is the appropriate deﬁnition and implementation of the visual analytics pipeline which provides eﬀective abstractions for designing and implementing visual analytics systems. In this paper we review the previous work on visual analytics pipelines and individual modules from multiple perspectives: data, visualization, model and knowledge. In each module we discuss various representations and descriptions of pipelines inside the module, and compare the commonalities and the diﬀerences among them.},
	language = {en},
	number = {4},
	urldate = {2020-03-09},
	journal = {Journal of Computer Science and Technology},
	author = {Wang, Xu-Meng and Zhang, Tian-Ye and Ma, Yu-Xin and Xia, Jing and Chen, Wei},
	month = jul,
	year = {2016},
	keywords = {vis},
	pages = {787--804},
}

@article{SmartStripesLookingHoodFeature,
	title = {{SmartStripes} - {Looking} under the {Hood} of {Feature} {Subset} {Selection} {Methods}},
	url = {http://diglib.eg.org/handle/10.2312/PE.EuroVAST.EuroVA11.013-016},
	doi = {10.2312/PE/EUROVAST/EUROVA11/013-016},
	abstract = {We propose a visualization method for the diagnosis and interactive reﬁnement of automatic techniques for feature subset selection. So-called ﬁlter techniques use statistical ranking measures to identify the most useful combination of features for further analysis. Usually a measure is applied to all entities of a data-table. The inﬂuence of atypical entities can distort the result, but this distortion may be masked by the statistical aggregation. Clearly, feature and entity subset selection are highly interdependent. Our technique, SmartStripes, intends to make this interdependency visible.},
	language = {en},
	urldate = {2020-03-09},
	journal = {EuroVA 2011: International Workshop on Visual Analytics},
	author = {May, T. and Davey, J. and Ruppert, T.},
	year = {2011},
	note = {Artwork Size: 4 pages
ISBN: 9783905673821
Publisher: The Eurographics Association},
	pages = {4 pages},
}

@article{Seq2seqVisVisualDebuggingTool,
	title = {Seq2seq-{Vis}: {A} {Visual} {Debugging} {Tool} for {Sequence}-to-{Sequence} {Models}},
	volume = {25},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Seq2seq-{Vis}},
	url = {https://ieeexplore.ieee.org/document/8494828/},
	doi = {10.1109/TVCG.2018.2865044},
	language = {en},
	number = {1},
	urldate = {2020-02-19},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Strobelt, Hendrik and Gehrmann, Sebastian and Behrisch, Michael and Perer, Adam and Pfister, Hanspeter and Rush, Alexander M.},
	month = jan,
	year = {2019},
	keywords = {dl, vis},
	pages = {353--363},
}

@article{ReviewGuidanceApproachesVisual,
	title = {A {Review} of {Guidance} {Approaches} in {Visual} {Data} {Analysis}: {A} {Multifocal} {Perspective}},
	volume = {38},
	issn = {1467-8659},
	shorttitle = {A {Review} of {Guidance} {Approaches} in {Visual} {Data} {Analysis}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13730},
	doi = {10.1111/cgf.13730},
	abstract = {Visual data analysis can be envisioned as a collaboration of the user and the computational system with the aim of completing a given task. Pursuing an effective system-user integration, in which the system actively helps the user to reach his/her analysis goal has been focus of visualization research for quite some time. However, this problem is still largely unsolved. As a result, users might be overwhelmed by powerful but complex visual analysis systems which also limits their ability to produce insightful results. In this context, guidance is a promising step towards enabling an effective mixed-initiative collaboration to promote the visual analysis. However, the way how guidance should be put into practice is still to be unravelled. Thus, we conducted a comprehensive literature research and provide an overview of how guidance is tackled by different approaches in visual analysis systems. We distinguish between guidance that is provided by the system to support the user, and guidance that is provided by the user to support the system. By identifying open problems, we highlight promising research directions and point to missing factors that are needed to enable the envisioned human-computer collaboration, and thus, promote a more effective visual data analysis.},
	language = {en},
	number = {3},
	urldate = {2020-02-16},
	journal = {Computer Graphics Forum},
	author = {Ceneda, Davide and Gschwandtner, Theresia and Miksch, Silvia},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13730},
	keywords = {interaction, survey, vis},
	pages = {861--879},
}

@article{DominoExtractingComparingManipulating,
	title = {Domino: {Extracting}, {Comparing}, and {Manipulating} {Subsets} {Across} {Multiple} {Tabular} {Datasets}},
	volume = {20},
	issn = {2160-9306},
	shorttitle = {Domino},
	doi = {10.1109/TVCG.2014.2346260},
	abstract = {Answering questions about complex issues often requires analysts to take into account information contained in multiple interconnected datasets. A common strategy in analyzing and visualizing large and heterogeneous data is dividing it into meaningful subsets. Interesting subsets can then be selected and the associated data and the relationships between the subsets visualized. However, neither the extraction and manipulation nor the comparison of subsets is well supported by state-of-the-art techniques. In this paper we present Domino, a novel multiform visualization technique for effectively representing subsets and the relationships between them. By providing comprehensive tools to arrange, combine, and extract subsets, Domino allows users to create both common visualization techniques and advanced visualizations tailored to specific use cases. In addition to the novel technique, we present an implementation that enables analysts to manage the wide range of options that our approach offers. Innovative interactive features such as placeholders and live previews support rapid creation of complex analysis setups. We introduce the technique and the implementation using a simple example and demonstrate scalability and effectiveness in a use case from the field of cancer genomics.},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Gratzl, Samuel and Gehlenborg, Nils and Lex, Alexander and Pfister, Hanspeter and Streit, Marc},
	month = dec,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {subset, vis},
	pages = {2023--2032},
}

@article{COGAMMeasuringModeratingCognitive,
	title = {{COGAM}: {Measuring} and {Moderating} {Cognitive} {Load} in {Machine} {Learning} {Model} {Explanations}},
	abstract = {Interpretable machine learning models trade off accuracy for simplicity to make explanations more readable and easier to comprehend. Drawing from cognitive psychology theories in graph comprehension, we formalize readability as visual cognitive chunks to measure and moderate the cognitive load in explanation visualizations. We present Cognitive-GAM (COGAM) to generate explanations with desired cognitive load and accuracy by combining the expressive nonlinear generalized additive models (GAM) with simpler sparse linear models. We calibrated visual cognitive chunks with reading time in a user study, characterized the trade-off between cognitive load and accuracy for four datasets in simulation studies, and evaluated COGAM against baselines with users. We found that COGAM can decrease cognitive load without decreasing accuracy and/or increase accuracy without increasing cognitive load. Our framework and empirical measurement instruments for cognitive load will enable more rigorous assessment of the human interpretability of explainable AI.},
	language = {en},
	author = {Abdul, Ashraf},
	keywords = {explanation, fatml, xai},
	pages = {14},
}

@article{WhyTheseExplanationsSelecting,
	title = {Why these {Explanations}? {Selecting} {Intelligibility} {Types} for {Explanation} {Goals}},
	abstract = {The increasing ubiquity of artificial intelligence (AI) has spurred the development of explainable AI (XAI) to make AI more understandable. Even as novel algorithms for explanation are being developed, researchers have called for more human interpretability. While empirical user studies can be conducted to evaluate explanation effectiveness, it remains unclear why specific explanations are helpful for understanding. We leverage a recently developed conceptual framework for user-centric reasoned XAI that draws from foundational concepts in philosophy, cognitive psychology, and AI to identify pathways for how user reasoning drives XAI needs. We identified targeted strategies for applying XAI facilities to improve understanding, trust and decision performance. We discuss how our framework can be extended and applied to other domains that need usercentric XAI. This position paper seeks to promote the design of XAI features based on human reasoning needs.},
	language = {en},
	journal = {Los Angeles},
	author = {Lim, Brian Y and Yang, Qian and Abdul, Ashraf and Wang, Danding},
	year = {2019},
	keywords = {explanation, fatml, xai},
	pages = {7},
}

@article{PrinciplesLimitsAlgorithmintheLoopDecision,
	title = {The {Principles} and {Limits} of {Algorithm}-in-the-{Loop} {Decision} {Making}},
	volume = {3},
	issn = {25730142},
	url = {http://dl.acm.org/citation.cfm?doid=3371885.3359152},
	doi = {10.1145/3359152},
	language = {en},
	number = {CSCW},
	urldate = {2020-02-09},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Green, Ben and Chen, Yiling},
	month = nov,
	year = {2019},
	keywords = {hci, hil},
	pages = {1--24},
}

@article{FewShotKnowledgeGraphCompletion,
	title = {Few-{Shot} {Knowledge} {Graph} {Completion}},
	url = {http://arxiv.org/abs/1911.11298},
	abstract = {Knowledge graphs (KGs) serve as useful resources for various natural language processing applications. Previous KG completion approaches require a large number of training instances (i.e., head-tail entity pairs) for every relation. The real case is that for most of the relations, very few entity pairs are available. Existing work of one-shot learning limits method generalizability for few-shot scenarios and does not fully use the supervisory information; however, few-shot KG completion has not been well studied yet. In this work, we propose a novel few-shot relation learning model (FSRL) that aims at discovering facts of new relations with few-shot references. FSRL can effectively capture knowledge from heterogeneous graph structure, aggregate representations of few-shot references, and match similar entity pairs of reference set for every relation. Extensive experiments on two public datasets demonstrate that FSRL outperforms the state-of-the-art.},
	urldate = {2020-02-09},
	journal = {arXiv:1911.11298 [cs]},
	author = {Zhang, Chuxu and Yao, Huaxiu and Huang, Chao and Jiang, Meng and Li, Zhenhui and Chawla, Nitesh V.},
	month = nov,
	year = {2019},
	note = {arXiv: 1911.11298},
	keywords = {few-shot, kg},
}

@inproceedings{EmbeddingApproachAnomalyDetection,
	address = {Helsinki, Finland},
	title = {An embedding approach to anomaly detection},
	isbn = {978-1-5090-2020-1},
	url = {http://ieeexplore.ieee.org/document/7498256/},
	doi = {10.1109/ICDE.2016.7498256},
	abstract = {Network anomaly detection has become very popular in recent years because of the importance of discovering key regions of structural inconsistency in the network. In addition to application-speciﬁc information carried by anomalies, the presence of such structural inconsistency is often an impediment to the effective application of data mining algorithms such as community detection and classiﬁcation. In this paper, we study the problem of detecting structurally inconsistent nodes that connect to a number of diverse inﬂuential communities in large social networks. We show that the use of a network embedding approach, together with a novel dimension reduction technique, is an effective tool to discover such structural inconsistencies. We also experimentally show that the detection of such anomalous nodes has signiﬁcant applications: one is the speciﬁc use of detected anomalies, and the other is the improvement of the effectiveness of community detection.},
	language = {en},
	urldate = {2020-02-05},
	booktitle = {2016 {IEEE} 32nd {International} {Conference} on {Data} {Engineering} ({ICDE})},
	publisher = {IEEE},
	author = {Hu, Renjun and Aggarwal, Charu C. and Ma, Shuai and Huai, Jinpeng},
	month = may,
	year = {2016},
	keywords = {anomaly, dm, emb, network},
	pages = {385--396},
}

@inproceedings{VISIONKGTopiccentricVisualizationSystem,
	address = {Houston TX USA},
	title = {{VISION}-{KG}: {Topic}-centric {Visualization} {System} for {Summarizing} {Knowledge} {Graph}},
	isbn = {978-1-4503-6822-3},
	shorttitle = {{VISION}-{KG}},
	url = {http://dl.acm.org/doi/10.1145/3336191.3371863},
	doi = {10.1145/3336191.3371863},
	abstract = {Large scale knowledge graph (KG) has attracted wide attentions in both academia and industry recently. However, due to the complexity of SPARQL syntax and massive volume of real KG, it remains difficult for ordinary users to access KG. In this demo, we present VISION-KG, a topic-centric visualization system to help users navigate KG easily via entity summarization and entity clustering. Given a query entity v0, VISION-KG summarizes the induced subgraph of v0’s neighbor nodes via our proposed facts ranking method that measures importance, relatedness and diversity. Moreover, to achieve conciseness, we split the summarized graph into several topic-centric summarized subgraph according to semantic and structural similarities among entities. We will demonstrate how VISION-KG provides a user-friendly visualization interface for navigating KG.},
	language = {en},
	urldate = {2020-02-05},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Wei, Jiaqi and Han, Shuo and Zou, Lei},
	month = jan,
	year = {2020},
	keywords = {kg, ts-200206, vis},
	pages = {857--860},
}

@inproceedings{GuidingFeatureSubsetSelection,
	title = {Guiding feature subset selection with an interactive visualization},
	doi = {10.1109/VAST.2011.6102448},
	abstract = {We propose a method for the semi-automated refinement of the results of feature subset selection algorithms. Feature subset selection is a preliminary step in data analysis which identifies the most useful subset of features (columns) in a data table. So-called filter techniques use statistical ranking measures for the correlation of features. Usually a measure is applied to all entities (rows) of a data table. However, the differing contributions of subsets of data entities are masked by statistical aggregation. Feature and entity subset selection are, thus, highly interdependent. Due to the difficulty in visualizing a high-dimensional data table, most feature subset selection algorithms are applied as a black box at the outset of an analysis. Our visualization technique, SmartStripes, allows users to step into the feature subset selection process. It enables the investigation of dependencies and interdependencies between different feature and entity subsets. A user may even choose to control the iterations manually, taking into account the ranking measures, the contributions of different entity subsets, as well as the semantics of the features.},
	booktitle = {2011 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	author = {May, Thorsten and Bannach, Andreas and Davey, James and Ruppert, Tobias and Kohlhammer, Jörn},
	month = oct,
	year = {2011},
	keywords = {subset, subspace, vis},
	pages = {111--120},
}

@inproceedings{SubspaceSearchVisualizationMakea,
	address = {Seattle, WA, USA},
	title = {Subspace search and visualization to make sense of alternative clusterings in high-dimensional data},
	isbn = {978-1-4673-4753-2 978-1-4673-4752-5},
	url = {http://ieeexplore.ieee.org/document/6400488/},
	doi = {10.1109/VAST.2012.6400488},
	abstract = {In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufﬁcient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space.},
	language = {en},
	urldate = {2020-04-14},
	booktitle = {2012 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Tatu, Andrada and Maas, Fabian and Farber, Ines and Bertini, Enrico and Schreck, Tobias and Seidl, Thomas and Keim, Daniel},
	month = oct,
	year = {2012},
	keywords = {clustering, subspace, vis},
	pages = {63--72},
}

@article{HighdimensionalDataAnalysisSubspace,
	title = {High-dimensional data analysis with subspace comparison using matrix visualization},
	volume = {18},
	issn = {1473-8716},
	url = {https://doi.org/10.1177/1473871617733996},
	doi = {10.1177/1473871617733996},
	abstract = {Due to the intricate relationship between different dimensions of high-dimensional data, subspace analysis is often conducted to decompose dimensions and give prominence to certain subsets of dimensions, i.e. subspaces. Exploring and comparing subspaces are important to reveal the underlying features of subspaces, as well as to portray the characteristics of individual dimensions. To date, most of the existing high-dimensional data exploration and analysis approaches rely on dimensionality reduction algorithms (e.g. principal component analysis and multi-dimensional scaling) to project high-dimensional data, or their subspaces, to two-dimensional space and employ scatterplots for visualization. However, the dimensionality reduction algorithms are sometimes difficult to fine-tune and scatterplots are not effective for comparative visualization, making subspace comparison hard to perform. In this article, we aggregate high-dimensional data or their subspaces by computing pair-wise distances between all data items and showing the distances with matrix visualizations to present the original high-dimensional data or subspaces. Our approach enables effective visual comparisons among subspaces, which allows users to further investigate the characteristics of individual dimensions by studying their behaviors in similar subspaces. Through subspace comparisons, we identify dominant, similar, and conforming dimensions in different subspace contexts of synthetic and real-world high-dimensional data sets. Additionally, we present a prototype that integrates parallel coordinates plot and matrix visualization for high-dimensional data exploration and incremental dimensionality analysis, which also allows users to further validate the dimension characterization results derived from the subspace comparisons.},
	number = {1},
	urldate = {2020-04-12},
	journal = {Information Visualization},
	author = {Wang, Junpeng and Liu, Xiaotong and Shen, Han-Wei},
	month = jan,
	year = {2019},
	note = {Publisher: SAGE Publications},
	keywords = {p-step-md},
	pages = {94--109},
}

@article{VisualAnalysisHighDimensionalEvent,
	title = {Visual {Analysis} of {High}-{Dimensional} {Event} {Sequence} {Data} via {Dynamic} {Hierarchical} {Aggregation}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {http://arxiv.org/abs/1906.07617},
	doi = {10.1109/TVCG.2019.2934661},
	abstract = {Temporal event data are collected across a broad range of domains, and a variety of visual analytics techniques have been developed to empower analysts working with this form of data. These techniques generally display aggregate statistics computed over sets of event sequences that share common patterns. Such techniques are often hindered, however, by the high-dimensionality of many real-world event sequence datasets which can prevent effective aggregation. A common coping strategy for this challenge is to group event types together prior to visualization, as a pre-process, so that each group can be represented within an analysis as a single event type. However, computing these event groupings as a pre-process also places signiﬁcant constraints on the analysis. This paper presents a new visual analytics approach for dynamic hierarchical dimension aggregation. The approach leverages a predeﬁned hierarchy of dimensions to computationally quantify the informativeness, with respect to a measure of interest, of alternative levels of grouping within the hierarchy at runtime. This information is then interactively visualized, enabling users to dynamically explore the hierarchy to select the most appropriate level of grouping to use at any individual step within an analysis. Key contributions include an algorithm for interactively determining the most informative set of event groupings for a speciﬁc analysis context, and a scented scatter-plus-focus visualization design with an optimization-based layout algorithm that supports interactive hierarchical exploration of alternative event type groupings. We apply these techniques to high-dimensional event sequence data from the medical domain and report ﬁndings from domain expert interviews.},
	language = {en},
	urldate = {2020-04-08},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Gotz, David and Zhang, Jonathan and Wang, Wenyuan and Shrestha, Joshua and Borland, David},
	year = {2019},
	note = {arXiv: 1906.07617},
	pages = {1--1},
}

@inproceedings{NetSetSystematicIntegrationVisualization,
	title = {{NetSet}: {A} systematic integration of visualization for analyzing set intersections with network},
	shorttitle = {{NetSet}},
	doi = {10.1109/PACIFICVIS.2017.8031575},
	abstract = {Many researchers have been studied visualization techniques to represent relationships between sets. However, most recent studies focused on the scalability of visualizing set relations, rather than on set-typed data itself. Although solving such problems is important, understanding the structural context of the entire data is also essential for analyzing data. We propose NetSet, which combines two techniques to resolve the limitations in representing set relationships. First, we construct a network to provide a structural overview of the set system. Then, we place a matrix layout to visualize intersections among sets. Finally, by combining these two techniques, NetSet enables them to complement each other. The combination gives analysts both the overview and specific views of the data. Furthermore, NetSet provides both flexible exploration of a set system and quantitative analysis of set intersections. We conducted a case study to demonstrate how the combination can be successfully applied to real data, namely topic-talks data from the TED organization.},
	booktitle = {2017 {IEEE} {Pacific} {Visualization} {Symposium} ({PacificVis})},
	author = {Heungseok Park and Hongjun Lim and Wonjae Lee and Kyungwon Lee},
	month = apr,
	year = {2017},
	note = {ISSN: 2165-8773},
	keywords = {p-step-set, set, vis},
	pages = {26--30},
}

@article{PowerSetComprehensiveVisualizationSet,
	title = {{PowerSet}: {A} {Comprehensive} {Visualization} of {Set} {Intersections}},
	volume = {23},
	issn = {1941-0506},
	shorttitle = {{PowerSet}},
	doi = {10.1109/TVCG.2016.2598496},
	abstract = {When analyzing a large amount of data, analysts often define groups over data elements that share certain properties. Using these groups as the unit of analysis not only reduces the data volume, but also allows detecting various patterns in the data. This involves analyzing intersection relations between these groups, and how the element attributes vary between these intersections. This kind of set-based analysis has various applications in a variety of domains, due to the generic and powerful notion of sets. However, visualizing intersections relations is challenging because their number grows exponentially with the number of sets. We present a novel technique based on Treemaps to provide a comprehensive overview of non-empty intersections in a set system in a scalable way. It enables gaining insight about how elements are distributed across these intersections as well as performing fine-grained analysis to explore and compare their attributes both in overview and in detail. Interaction allows querying and filtering these elements based on their set memberships. We demonstrate how our technique supports various use cases in data exploration and analysis by providing insights into set-based data, beyond the limits of state-of-the-art techniques.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Alsallakh, Bilal and Ren, Liu},
	month = jan,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {p-step-set, set, vis},
	pages = {361--370},
}

@article{UpSetVisualizationIntersectingSets,
	title = {{UpSet}: {Visualization} of {Intersecting} {Sets}},
	volume = {20},
	issn = {1941-0506},
	shorttitle = {{UpSet}},
	doi = {10.1109/TVCG.2014.2346248},
	abstract = {Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Lex, Alexander and Gehlenborg, Nils and Strobelt, Hendrik and Vuillemot, Romain and Pfister, Hanspeter},
	month = dec,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {p-step-set, set, vis},
	pages = {1983--1992},
}

@article{GrammaticalErrorDetectionUsing,
	title = {Grammatical {Error} {Detection} {Using} {Error}- and {Grammaticality}-{Specific} {Word} {Embeddings}},
	volume = {25},
	issn = {1340-7619, 2185-8314},
	url = {https://www.jstage.jst.go.jp/article/jnlp/25/4/25_421/_article/-char/ja/},
	doi = {10.5715/jnlp.25.421},
	abstract = {In this study, we improve grammatical error detection by learning word embeddings that consider grammaticality and error patterns. Most existing algorithms for learning word embeddings usually model only the syntactic context of words so that classiﬁers treat erroneous and correct words as similar inputs. We address the problem of contextual information by considering learner errors. Speciﬁcally, we propose two models: one model that employs grammatical error patterns and another model that considers grammaticality of the target word. We determine grammaticality of n-gram sequence from the annotated error tags and extract grammatical error patterns for word embeddings from large-scale learner corpora. Experimental results show that a bidirectional long-short term memory model initialized by our word embeddings achieved the state-of-the-art accuracy by a large margin in an English grammatical error detection task on the First Certiﬁcate in English dataset.},
	language = {en},
	number = {4},
	urldate = {2020-03-11},
	journal = {Journal of Natural Language Processing},
	author = {Kaneko, Masahiro and Sakaizawa, Yuya and Komachi, Mamoru},
	month = sep,
	year = {2018},
	keywords = {gec},
	pages = {421--439},
}

@article{DetectingLearnerErrorsChoice,
	title = {Detecting {Learner} {Errors} in the {Choice} of {Content} {Words} {Using} {Compositional} {Distributional} {Semantics}},
	abstract = {We describe a novel approach to error detection in adjective–noun combinations. We present and release a new dataset of annotated errors where the examples are extracted from learner texts and annotated with error types. We show how compositional distributional semantic approaches can be applied to discriminate between correct and incorrect word combinations from learner data. Finally, we show how the output of the compositional distributional semantic models can be used as features in a classiﬁer yielding good precision and accuracy.},
	language = {en},
	author = {Kochmar, Ekaterina and Briscoe, Ted},
	keywords = {gec},
	pages = {12},
}

@article{MeasuringInfluenceL1Learner,
	title = {Measuring the {Inﬂuence} of {L1} on {Learner} {English} {Errors} in {Content} {Words} within {Word} {Embedding} {Models}},
	abstract = {Recent works in Second Language Acquisition Literature and Corpus Linguistics have shown the interference of a person’s ﬁrst language (L1) when they process words in a new language. In this work, we build on the ﬁndings in two recent studies that explore the various differences in the lexico-semantic models of a person’s L1 and L2 (English in their case), and test their hypotheses within the framework of two popular word vector models. This test is carried out by extracting erroneous content word errors from an annotated corpus of essays written by learners of English who belong to 16 different ﬁrst languages. Speciﬁcally, we compare the vectors representations of the incorrect and correct-replacement word pairs in English as well as in the person’s ﬁrst language and ﬁnd a moderate correlation between L1 and English. Additionally, we ﬁnd certain inconsistencies between the two word embedding models when observed under the radar of language typology, suggesting new avenues for future work.},
	language = {en},
	author = {Misra, Kanishka and Devarapalli, Hemanth and Rayz, Julia Taylor},
	pages = {7},
}

@article{ReinventingContingencyWheelScalable,
	title = {Reinventing the {Contingency} {Wheel}: {Scalable} {Visual} {Analytics} of {Large} {Categorical} {Data}},
	volume = {18},
	issn = {1077-2626},
	shorttitle = {Reinventing the {Contingency} {Wheel}},
	url = {http://ieeexplore.ieee.org/document/6327291/},
	doi = {10.1109/TVCG.2012.254},
	abstract = {Contingency tables summarize the relations between categorical variables and arise in both scientiﬁc and business domains. Asymmetrically large two-way contingency tables pose a problem for common visualization methods. The Contingency Wheel has been recently proposed as an interactive visual method to explore and analyze such tables. However, the scalability and readability of this method are limited when dealing with large and dense tables. In this paper we present Contingency Wheel++, new visual analytics methods that overcome these major shortcomings: (1) regarding automated methods, a measure of association based on Pearson’s residuals alleviates the bias of the raw residuals originally used, (2) regarding visualization methods, a frequency-based abstraction of the visual elements eliminates overlapping and makes analyzing both positive and negative associations possible, and (3) regarding the interactive exploration environment, a multi-level overview+detail interface enables exploring individual data items that are aggregated in the visualization or in the table using coordinated views. We illustrate the applicability of these new methods with a use case and show how they enable discovering and analyzing nontrivial patterns and associations in large categorical data.},
	language = {en},
	number = {12},
	urldate = {2020-03-09},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Alsallakh, B. and Aigner, W. and Miksch, S. and Groller, M. E.},
	month = dec,
	year = {2012},
	keywords = {categorical, vis},
	pages = {2849--2858},
}

@inproceedings{DiachronicWordEmbeddingsReveal,
	address = {Berlin, Germany},
	title = {Diachronic {Word} {Embeddings} {Reveal} {Statistical} {Laws} of {Semantic} {Change}},
	url = {http://aclweb.org/anthology/P16-1141},
	doi = {10.18653/v1/P16-1141},
	abstract = {Memory in humans and artiﬁcial intelligence (AI) systems has similar functions—both are responsible for encoding, retrieving, and storing of information. While memory in humans has specialized systems for different functions (e.g., working memory, semantic memory, episodic memory), memory in AI systems is often implicitly represented in the weights of parametric neural networks. Focusing on language processing systems, we argue that this property makes it hard for AI systems to generalize across complex linguistic tasks. We consider the separation of computation and storage as necessary, suggest desired properties of the storage system, and discuss the beneﬁt of integrating different types of human memory (as separate modules) into next-generation language processing systems.},
	language = {en},
	urldate = {2020-04-23},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hamilton, William L. and Leskovec, Jure and Jurafsky, Dan},
	year = {2016},
	keywords = {dl, dm},
	pages = {1489--1501},
}

@inproceedings{LinkPredictionNaryRelational,
	address = {San Francisco, CA, USA},
	title = {Link {Prediction} on {N}-ary {Relational} {Data}},
	isbn = {978-1-4503-6674-8},
	url = {http://dl.acm.org/citation.cfm?doid=3308558.3313414},
	doi = {10.1145/3308558.3313414},
	abstract = {With the overwhelming popularity of Knowledge Graphs (KGs), researchers have poured attention to link prediction to complete KGs for a long time. However, they mainly focus on promoting the performance on binary relational data, where facts are usually represented as triples in the form of (head entity, relation, tail entity). In practice, n-ary relational facts are also ubiquitous. When encountering such facts, existing studies usually decompose them into triples by introducing a multitude of auxiliary virtual entities and additional triples. These conversions result in the complexity of carrying out link prediction concerning more than two arities. It has even proven that they may cause loss of structural information. To overcome these problems, in this paper, without decomposition, we represent each n-ary relational fact as a set of its role-value pairs. We further propose a method to conduct Link Prediction on N-ary relational data, thus called NaLP, which explicitly models the relatedness of all the role-value pairs in the same n-ary relational fact. Experimental results validate the effectiveness and merits of the proposed NaLP method.},
	language = {en},
	urldate = {2020-04-19},
	booktitle = {The {World} {Wide} {Web} {Conference} on   - {WWW} '19},
	publisher = {ACM Press},
	author = {Guan, Saiping and Jin, Xiaolong and Wang, Yuanzhuo and Cheng, Xueqi},
	year = {2019},
	pages = {583--593},
}

@article{TripletsHyperRelationalKnowledgeGraph,
	title = {Beyond {Triplets}: {Hyper}-{Relational} {Knowledge} {Graph} {Embedding} for {Link} {Prediction}},
	abstract = {Knowledge Graph (KG) embeddings are a powerful tool for predicting missing links in KGs. Existing techniques typically represent a KG as a set of triplets, where each triplet (h, r , t) links two entities h and t through a relation r , and learn entity/relation embeddings from such triplets while preserving such a structure. However, this triplet representation oversimplifies the complex nature of the data stored in the KG, in particular for hyper-relational facts, where each fact contains not only a base triplet (h, r , t), but also the associated key-value pairs (k, v). Even though a few recent techniques tried to learn from such data by transforming a hyper-relational fact into an n-ary representation (i.e., a set of key-value pairs only without triplets), they result in suboptimal models as they are unaware of the triplet structure, which serves as the fundamental data structure in modern KGs and preserves the essential information for link prediction. To address this issue, we propose HINGE, a hyper-relational KG embedding model, which directly learns from hyper-relational facts in a KG. HINGE captures not only the primary structural information of the KG encoded in the triplets, but also the correlation between each triplet and its associated key-value pairs. Our extensive evaluation shows the superiority of HINGE on various link prediction tasks over KGs. In particular, HINGE consistently outperforms not only the KG embedding methods learning from triplets only (by 0.81-41.45\% depending on the link prediction tasks and settings), but also the methods learning from hyper-relational facts using the n-ary representation (by 13.2-84.1\%).},
	language = {en},
	author = {Rosso, Paolo and Yang, Dingqi and Cudré-Mauroux, Philippe},
	year = {2020},
	keywords = {kg},
	pages = {11},
}

@article{MinimalSupervisionBERTbasedGrammar,
	title = {Towards {Minimal} {Supervision} {BERT}-based {Grammar} {Error} {Correction}},
	url = {http://arxiv.org/abs/2001.03521},
	abstract = {Current grammatical error correction (GEC) models typically consider the task as sequence generation, which requires large amounts of annotated data and limit the applications in datalimited settings. We try to incorporate contextual information from pre-trained language model to leverage annotation and beneﬁt multilingual scenarios. Results show strong potential of Bidirectional Encoder Representations from Transformers (BERT) in grammatical error correction task.},
	language = {en},
	urldate = {2020-04-16},
	journal = {arXiv:2001.03521 [cs]},
	author = {Li, Yiyuan and Anastasopoulos, Antonios and Black, Alan W.},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.03521},
	keywords = {dm, gec},
}

@article{UnreasonableEffectivenessTransformerLanguage,
	title = {The {Unreasonable} {Effectiveness} of {Transformer} {Language} {Models} in {Grammatical} {Error} {Correction}},
	url = {http://arxiv.org/abs/1906.01733},
	abstract = {Recent work on Grammatical Error Correction (GEC) has highlighted the importance of language modeling in that it is certainly possible to achieve good performance by comparing the probabilities of the proposed edits. At the same time, advancements in language modeling have managed to generate linguistic output, which is almost indistinguishable from that of human-generated text. In this paper, we up the ante by exploring the potential of more sophisticated language models in GEC and offer some key insights on their strengths and weaknesses. We show that, in line with recent results in other NLP tasks, Transformer architectures achieve consistently high performance and provide a competitive baseline for future machine learning models.},
	language = {en},
	urldate = {2020-04-16},
	journal = {arXiv:1906.01733 [cs]},
	author = {Alikaniotis, Dimitrios and Raheja, Vipul},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.01733},
	keywords = {dm, gec},
}

@inproceedings{ConnectingDotsHumanLevelGrammatical,
	address = {Copenhagen, Denmark},
	title = {Connecting the {Dots}: {Towards} {Human}-{Level} {Grammatical} {Error} {Correction}},
	shorttitle = {Connecting the {Dots}},
	url = {http://aclweb.org/anthology/W17-5037},
	doi = {10.18653/v1/W17-5037},
	abstract = {We build a grammatical error correction (GEC) system primarily based on the state-of-the-art statistical machine translation (SMT) approach, using task-speciﬁc features and tuning, and further enhance it with the modeling power of neural network joint models. The SMT-based system is weak in generalizing beyond patterns seen during training and lacks granularity below the word level. To address this issue, we incorporate a character-level SMT component targeting the misspelled words that the original SMT-based system fails to correct. Our ﬁnal system achieves 53.14\% F0.5 score on the benchmark CoNLL-2014 test set, an improvement of 3.62\% F0.5 over the best previous published score.},
	language = {en},
	urldate = {2020-04-16},
	booktitle = {Proceedings of the 12th {Workshop} on {Innovative} {Use} of {NLP} for {Building}           {Educational} {Applications}},
	publisher = {Association for Computational Linguistics},
	author = {Chollampatt, Shamil and Ng, Hwee Tou},
	year = {2017},
	keywords = {gec},
	pages = {327--333},
}

@inproceedings{LanguageModelBasedGrammatical,
	address = {New Orleans, Louisiana},
	title = {Language {Model} {Based} {Grammatical} {Error} {Correction} without {Annotated} {Training} {Data}},
	url = {http://aclweb.org/anthology/W18-0529},
	doi = {10.18653/v1/W18-0529},
	abstract = {Since the end of the CoNLL-2014 shared task on grammatical error correction (GEC), research into language model (LM) based approaches to GEC has largely stagnated. In this paper, we re-examine LMs in GEC and show that it is entirely possible to build a simple system that not only requires minimal annotated data (∼1000 sentences), but is also fairly competitive with several state-of-the-art systems. This approach should be of particular interest for languages where very little annotated training data exists, although we also hope to use it as a baseline to motivate future research.},
	language = {en},
	urldate = {2020-04-16},
	booktitle = {Proceedings of the {Thirteenth} {Workshop} on {Innovative} {Use} of {NLP} for           {Building} {Educational} {Applications}},
	publisher = {Association for Computational Linguistics},
	author = {Bryant, Christopher and Briscoe, Ted},
	year = {2018},
	keywords = {gec},
	pages = {247--253},
}

@inproceedings{LanguageModelBasedGrammaticala,
	address = {New Orleans, Louisiana},
	title = {Language {Model} {Based} {Grammatical} {Error} {Correction} without {Annotated} {Training} {Data}},
	url = {http://aclweb.org/anthology/W18-0529},
	doi = {10.18653/v1/W18-0529},
	abstract = {Since the end of the CoNLL-2014 shared task on grammatical error correction (GEC), research into language model (LM) based approaches to GEC has largely stagnated. In this paper, we re-examine LMs in GEC and show that it is entirely possible to build a simple system that not only requires minimal annotated data (∼1000 sentences), but is also fairly competitive with several state-of-the-art systems. This approach should be of particular interest for languages where very little annotated training data exists, although we also hope to use it as a baseline to motivate future research.},
	language = {en},
	urldate = {2020-04-16},
	booktitle = {Proceedings of the {Thirteenth} {Workshop} on {Innovative} {Use} of {NLP} for           {Building} {Educational} {Applications}},
	publisher = {Association for Computational Linguistics},
	author = {Bryant, Christopher and Briscoe, Ted},
	year = {2018},
	keywords = {gec},
	pages = {247--253},
}

@inproceedings{NeuralGrammaticalErrorCorrection,
	address = {Florence, Italy},
	title = {A {Neural} {Grammatical} {Error} {Correction} {System} {Built} {On} {Better} {Pre}-training and {Sequential} {Transfer} {Learning}},
	url = {https://www.aclweb.org/anthology/W19-4423},
	doi = {10.18653/v1/W19-4423},
	language = {en},
	urldate = {2020-04-16},
	booktitle = {Proceedings of the {Fourteenth} {Workshop} on {Innovative} {Use} of {NLP} for {Building} {Educational} {Applications}},
	publisher = {Association for Computational Linguistics},
	author = {Choe, Yo Joong and Ham, Jiyeon and Park, Kyubyong and Yoon, Yeoil},
	year = {2019},
	keywords = {gec},
	pages = {213--227},
}

@inproceedings{UnsupervisedClickstreamClusteringUser,
	address = {San Jose California USA},
	title = {Unsupervised {Clickstream} {Clustering} for {User} {Behavior} {Analysis}},
	isbn = {978-1-4503-3362-7},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858107},
	doi = {10.1145/2858036.2858107},
	abstract = {Online services are increasingly dependent on user participation. Whether it’s online social networks or crowdsourcing services, understanding user behavior is important yet challenging. In this paper, we build an unsupervised system to capture dominating user behaviors from clickstream data (traces of users’ click events), and visualize the detected behaviors in an intuitive manner. Our system identiﬁes “clusters” of similar users by partitioning a similarity graph (nodes are users; edges are weighted by clickstream similarity). The partitioning process leverages iterative feature pruning to capture the natural hierarchy within user clusters and produce intuitive features for visualizing and understanding captured user behaviors. For evaluation, we present case studies on two large-scale clickstream traces (142 million events) from real social networks. Our system effectively identiﬁes previously unknown behaviors, e.g., dormant users, hostile chatters. Also, our user study shows people can easily interpret identiﬁed behaviors using our visualization tool.},
	language = {en},
	urldate = {2020-05-19},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wang, Gang and Zhang, Xinyi and Tang, Shiliang and Zheng, Haitao and Zhao, Ben Y.},
	month = may,
	year = {2016},
	keywords = {vis},
	pages = {225--236},
}

@inproceedings{CrowdScapeInteractivelyVisualizingUser,
	address = {Cambridge, Massachusetts, USA},
	title = {{CrowdScape}: interactively visualizing user behavior and output},
	isbn = {978-1-4503-1580-7},
	shorttitle = {{CrowdScape}},
	url = {http://dl.acm.org/citation.cfm?doid=2380116.2380125},
	doi = {10.1145/2380116.2380125},
	abstract = {Crowdsourcing has become a powerful paradigm for accomplishing work quickly and at scale, but involves significant challenges in quality control. Researchers have developed algorithmic quality control approaches based on either worker outputs (such as gold standards or worker agreement) or worker behavior (such as task fingerprinting), but each approach has serious limitations, especially for complex or creative work. Human evaluation addresses these limitations but does not scale well with increasing numbers of workers. We present CrowdScape, a system that supports the human evaluation of complex crowd work through interactive visualization and mixed initiative machine learning. The system combines information about worker behavior with worker outputs, helping users to better understand and harness the crowd. We describe the system and discuss its utility through grounded case studies. We explore other contexts where CrowdScape’s visualizations might be useful, such as in user studies.},
	language = {en},
	urldate = {2020-05-19},
	booktitle = {Proceedings of the 25th annual {ACM} symposium on {User} interface software and technology - {UIST} '12},
	publisher = {ACM Press},
	author = {Rzeszotarski, Jeffrey and Kittur, Aniket},
	year = {2012},
	keywords = {vis},
	pages = {55},
}

@inproceedings{BroadlyImprovingUserClassification,
	address = {Atlanta, Georgia},
	title = {Broadly {Improving} {User} {Classification} via {Communication}-{Based} {Name} and {Location} {Clustering} on {Twitter}},
	url = {https://www.aclweb.org/anthology/N13-1121},
	urldate = {2020-05-16},
	booktitle = {Proceedings of the 2013 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Bergsma, Shane and Dredze, Mark and Van Durme, Benjamin and Wilson, Theresa and Yarowsky, David},
	month = jun,
	year = {2013},
	pages = {1010--1019},
}

@article{VisualAnalyticsExplainableDeep,
	title = {Visual {Analytics} for {Explainable} {Deep} {Learning}},
	volume = {38},
	issn = {0272-1716, 1558-1756},
	url = {https://ieeexplore.ieee.org/document/8402187/},
	doi = {10.1109/MCG.2018.042731661},
	language = {en},
	number = {4},
	urldate = {2020-05-04},
	journal = {IEEE Computer Graphics and Applications},
	author = {Choo, Jaegul and Liu, Shixia},
	month = jul,
	year = {2018},
	keywords = {dl, vis},
	pages = {84--92},
}

@article{IterativeCohortAnalysisExploration,
	title = {Iterative cohort analysis and exploration},
	volume = {14},
	issn = {1473-8716, 1473-8724},
	url = {http://journals.sagepub.com/doi/10.1177/1473871614526077},
	doi = {10.1177/1473871614526077},
	abstract = {Cohort analysis is a widely used technique for the investigation of risk factors for groups of people. It is commonly employed to gain insights about interesting subsets of a population in fields such as medicine, bioinformatics, and social science. The nature of these analyses is evolving as larger collections of data about individuals become available. Examples of emerging large-scale data sources include electronic medical record systems and social network datasets. When domain experts perform cohort analyses using such massive datasets, they typically rely on a team of technologists to help manage and process the data. This results in a slow and cumbersome analysis process in which iterative exploration is difficult. To address this challenge, we are exploring technologies designed to help domain experts work more independently and more quickly. This article describes CAVA, a platform for Cohort Analysis via Visual Analytics. We introduce three primary types of artifacts (cohorts, views, and analytics) and an architecture that connects these elements together to provide an interactive exploratory analysis environment designed for domain experts. In addition to the CAVA design, this article presents two use cases from the health-care domain and a domain-expert evaluation to demonstrate the power of our approach.},
	language = {en},
	number = {4},
	urldate = {2020-04-27},
	journal = {Information Visualization},
	author = {Zhang, Zhiyuan and Gotz, David and Perer, Adam},
	month = oct,
	year = {2015},
	keywords = {cohort, group, vis},
	pages = {289--307},
}

@article{VisualAssessmentCohortDivergence,
	title = {Visual {Assessment} of {Cohort} {Divergence} {During} {Iterative} {Cohort} {Selection}},
	abstract = {Large-scale repositories of secondary-use patient data are emerging as a critical resource for both clinical and epidemiological research. Motivated by this opportunity, a variety of interactive visual analysis methods have been developed to make the use of this data more eﬃcient and accessible. These techniques often combine interactive ﬁlters and on-demand computational analysis to allow ad hoc cohort exploration and reﬁnement. This approach has indeed made it possible to quickly select and revise cohorts during analysis. However, the seemingly simple ﬁlters supported by these tools can produce dramatic—and often unseen—confounding eﬀects on the makeup of the cohort across the thousands of variables often found in real-world medical data. This poster presents an approach to measuring and visually conveying to users the degree of drift in representation during iterative visual cohort selection.},
	language = {en},
	author = {Gotz, David and Sun, Shun},
	keywords = {cohort, group, vis},
	pages = {2},
}

@article{MultivariateVisualizationLongitudinalClinical,
	title = {Multivariate {Visualization} of {Longitudinal} {Clinical} {Data}},
	abstract = {Identifying different patterns in longitudinal data (e.g. in laboratory values over time) related to a certain disease and associating them with different outcomes can be an important factor in delivering improved patient-speciﬁc health care. Visualization is often used to help understand complex temporal patterns, however the effectiveness of many temporal visualization techniques is compromised when dealing with temporal data from large numbers of individuals. We present work in progress on a visualization tool for exploring trajectories in longitudinal clinical data and their relationships to other disease factors. Linked views of multivariate features calculated from the longitudinal data, dynamically aggregated longitudinal data, diagnoses, and demographic data are presented, enabling the user to explore the data and identify potential relationships between temporal patterns, diagnoses, and demographics. We describe the various feature of this tool, demonstrate its application to patients diagnosed with diabetes, and discuss future work. Index Terms—Temporal visualization, multivariate visualization, longitudinal data, human computer interaction, electronic health records.},
	language = {en},
	author = {Borland, David and West, Vivian L and Hammond, W Ed},
	keywords = {cohort, group, vis},
	pages = {4},
}

@article{EvaluationClusterIdentificationPerformance,
	title = {Evaluation of {Cluster} {Identification} {Performance} for {Different} {PCP} {Variants}},
	volume = {29},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01666.x},
	doi = {10.1111/j.1467-8659.2009.01666.x},
	abstract = {Parallel coordinate plots (PCPs) are a well-known visualization technique for viewing multivariate data. In the past, various visual modifications to PCPs have been proposed to facilitate tasks such as correlation and cluster identification, to reduce visual clutter, and to increase their information throughput. Most modifications pertain to the use of color and opacity, smooth curves, or the use of animation. Although many of these seem valid improvements, only few user studies have been performed to investigate this, especially with respect to cluster identification. We performed a user study to evaluate cluster identification performance – with respect to response time and correctness – of nine PCP variations, including standard PCPs. To generate the variations, we focused on covering existing techniques as well as possible while keeping testing feasible. This was done by adapting and merging techniques, which led to the following novel variations. The first is an effective way of embedding scatter plots into PCPs. The second is a technique for highlighting fuzzy clusters based on neighborhood density. The third is a spline-based drawing technique to reduce ambiguity. The last is a pair of animation schemes for PCP rotation. We present an overview of the tested PCP variations and the results of our study. The most important result is that a fair number of the seemingly valid improvements, with the exception of scatter plots embedded into PCPs, do not result in significant performance gains.},
	language = {en},
	number = {3},
	urldate = {2020-04-24},
	journal = {Computer Graphics Forum},
	author = {Holten, Danny and Wijk, Jarke J. Van},
	year = {2010},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2009.01666.x},
	keywords = {clustering, parallel-cord, vis},
	pages = {793--802},
}

@article{SocialMediaVisualAnalytics,
	title = {Social {Media} {Visual} {Analytics}},
	volume = {36},
	issn = {1467-8659},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13211},
	doi = {10.1111/cgf.13211},
	abstract = {With the development of social media (e.g. Twitter, Flickr, Foursquare, Sina Weibo, etc.), a large number of people are now using them and post microblogs, messages and multi-media information. The everyday usage of social media results in big open social media data. The data offer fruitful information and reflect social behaviors of people. There is much visualization and visual analytics research on such data. We collect state-of-the-art research and put it into three main categories: social network, spatial temporal information and text analysis. We further summarize the visual analytics pipeline for the social media, combining the above categories and supporting complex tasks. With these techniques, social media analytics can apply to multiple disciplines. We summarize the applications and public tools to further investigate the challenges and trends.},
	language = {en},
	number = {3},
	urldate = {2020-04-23},
	journal = {Computer Graphics Forum},
	author = {Chen, Siming and Lin, Lijing and Yuan, Xiaoru},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13211},
	keywords = {comps-sc, social-media, survey, text, vis},
	pages = {563--587},
}

@article{PredictingTDCSTreatmentOutcomes,
	title = {Predicting {tDCS} treatment outcomes of patients with major depressive disorder using automated {EEG} classification},
	volume = {208},
	issn = {01650327},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165032716310485},
	doi = {10.1016/j.jad.2016.10.021},
	abstract = {Background: Transcranial direct current stimulation (tDCS) is a promising treatment for major depressive disorder (MDD). Standard tDCS treatment involves numerous sessions running over a few weeks. However, not all participants respond to this type of treatment. This study aims to investigate the feasibility of identifying MDD patients that respond to tDCS treatment based on resting-state electroencephalography (EEG) recorded prior to treatment commencing.
Methods: We used machine learning to predict improvement in mood and cognition during tDCS treatment from baseline EEG power spectra. Ten participants with a current diagnosis of MDD were included. Power spectral density was assessed in ﬁve frequency bands: delta (0.5–4 Hz), theta (4–8 Hz), alpha (8–12 Hz), beta (13–30 Hz) and gamma (30–100 Hz). Improvements in mood and cognition were assessed using the Montgomery-Åsberg Depression Rating Scale and Symbol Digit Modalities Test, respectively. We trained the classiﬁers using three algorithms (support vector machine, extreme learning machine and linear discriminant analysis) and a leave-one-out cross-validation approach.
Results: Mood labels were accurately predicted in 8 out of 10 participants using EEG channels FC4-AF8 (accuracy=76\%, p=0.034). Cognition labels were accurately predicted in 10 out of 10 participants using channels pair CPz-CP2 (accuracy=92\%, p=0.004). Limitations: Due to the limited number of participants (n=10), the presented results mainly aim to serve as a proof of concept.
Conclusions: These ﬁnding demonstrate the feasibility of using machine learning to identify patients that will respond to tDCS treatment. These promising results warrant a larger study to determine the clinical utility of this approach.},
	language = {en},
	urldate = {2020-05-25},
	journal = {Journal of Affective Disorders},
	author = {Al-Kaysi, Alaa M. and Al-Ani, Ahmed and Loo, Colleen K. and Powell, Tamara Y. and Martin, Donel M. and Breakspear, Michael and Boonstra, Tjeerd W.},
	month = jan,
	year = {2017},
	pages = {597--603},
}

@article{AutomatedDiagnosisEpilepsyUsing,
	title = {Automated {Diagnosis} of {Epilepsy} {Using} {Key}-{Point}-{Based} {Local} {Binary} {Pattern} of {EEG} {Signals}},
	volume = {21},
	issn = {2168-2208},
	doi = {10.1109/JBHI.2016.2589971},
	abstract = {The electroencephalogram (EEG) signals are commonly used for diagnosis of epilepsy. In this paper, we present a new methodology for EEG-based automated diagnosis of epilepsy. Our method involves detection of key points at multiple scales in EEG signals using a pyramid of difference of Gaussian filtered signals. Local binary patterns (LBPs) are computed at these key points and the histogram of these patterns are considered as the feature set, which is fed to the support vector machine (SVM) for the classification of EEG signals. The proposed methodology has been investigated for the four well-known classification problems namely, 1) normal and epileptic seizure, 2) epileptic seizure and seizure free, 3) normal, epileptic seizure, and seizure free, and 4) epileptic seizure and nonseizure EEG signals using publically available university of Bonn EEG database. Our experimental results in terms of classification accuracies have been compared with existing methods for the classification of the aforementioned problems. Further, performance evaluation on another EEG dataset shows that our approach is effective for classification of seizure and seizure-free EEG signals. The proposed methodology based on the LBP computed at key points is simple and easy to implement for real-time epileptic seizure detection.},
	number = {4},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Tiwari, Ashwani Kumar and Pachori, Ram Bilas and Kanhangad, Vivek and Panigrahi, Bijaya Ketan},
	month = jul,
	year = {2017},
	note = {Conference Name: IEEE Journal of Biomedical and Health Informatics},
	pages = {888--896},
}

@article{EEGbasedOutcomePredictionCardiac,
	title = {{EEG}-based outcome prediction after cardiac arrest with convolutional neural networks: {Performance} and visualization of discriminative features},
	volume = {40},
	issn = {1097-0193},
	shorttitle = {{EEG}-based outcome prediction after cardiac arrest with convolutional neural networks},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.24724},
	doi = {10.1002/hbm.24724},
	abstract = {Prognostication for comatose patients after cardiac arrest is a difficult but essential task. Currently, visual interpretation of electroencephalogram (EEG) is one of the main modality used in outcome prediction. There is a growing interest in computer-assisted EEG interpretation, either to overcome the possible subjectivity of visual interpretation, or to identify complex features of the EEG signal. We used a one-dimensional convolutional neural network (CNN) to predict functional outcome based on 19-channel-EEG recorded from 267 adult comatose patients during targeted temperature management after CA. The area under the receiver operating characteristic curve (AUC) on the test set was 0.885. Interestingly, model architecture and fine-tuning only played a marginal role in classification performance. We then used gradient-weighted class activation mapping (Grad-CAM) as visualization technique to identify which EEG features were used by the network to classify an EEG epoch as favorable or unfavorable outcome, and also to understand failures of the network. Grad-CAM showed that the network relied on similar features than classical visual analysis for predicting unfavorable outcome (suppressed background, epileptiform transients). This study confirms that CNNs are promising models for EEG-based prognostication in comatose patients, and that Grad-CAM can provide explanation for the models' decision-making, which is of utmost importance for future use of deep learning models in a clinical setting.},
	language = {en},
	number = {16},
	urldate = {2020-05-25},
	journal = {Human Brain Mapping},
	author = {Jonas, Stefan and Rossetti, Andrea O. and Oddo, Mauro and Jenni, Simon and Favaro, Paolo and Zubler, Frederic},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.24724},
	pages = {4606--4617},
}

@article{EarlyElectroencephalographyOutcomePrediction,
	title = {Early electroencephalography for outcome prediction of postanoxic coma: {A} prospective cohort study},
	volume = {86},
	issn = {1531-8249},
	shorttitle = {Early electroencephalography for outcome prediction of postanoxic coma},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ana.25518},
	doi = {10.1002/ana.25518},
	abstract = {Objective To provide evidence that early electroencephalography (EEG) allows for reliable prediction of poor or good outcome after cardiac arrest. Methods In a 5-center prospective cohort study, we included consecutive, comatose survivors of cardiac arrest. Continuous EEG recordings were started as soon as possible and continued up to 5 days. Five-minute EEG epochs were assessed by 2 reviewers, independently, at 8 predefined time points from 6 hours to 5 days after cardiac arrest, blinded for patients’ actual condition, treatment, and outcome. EEG patterns were categorized as generalized suppression ({\textless}10 μV), synchronous patterns with ≥50\% suppression, continuous, or other. Outcome at 6 months was categorized as good (Cerebral Performance Category [CPC] = 1–2) or poor (CPC = 3–5). Results We included 850 patients, of whom 46\% had a good outcome. Generalized suppression and synchronous patterns with ≥50\% suppression predicted poor outcome without false positives at ≥6 hours after cardiac arrest. Their summed sensitivity was 0.47 (95\% confidence interval [CI] = 0.42–0.51) at 12 hours and 0.30 (95\% CI = 0.26–0.33) at 24 hours after cardiac arrest, with specificity of 1.00 (95\% CI = 0.99–1.00) at both time points. At 36 hours or later, sensitivity for poor outcome was ≤0.22. Continuous EEG patterns at 12 hours predicted good outcome, with sensitivity of 0.50 (95\% CI = 0.46–0.55) and specificity of 0.91 (95\% CI = 0.88–0.93); at 24 hours or later, specificity for the prediction of good outcome was {\textless}0.90. Interpretation EEG allows for reliable prediction of poor outcome after cardiac arrest, with maximum sensitivity in the first 24 hours. Continuous EEG patterns at 12 hours after cardiac arrest are associated with good recovery. ANN NEUROL 2019;86:203–214},
	language = {en},
	number = {2},
	urldate = {2020-05-25},
	journal = {Annals of Neurology},
	author = {Ruijter, Barry J. and Tjepkema‐Cloostermans, Marleen C. and Tromp, Selma C. and Bergh, Walter M. van den and Foudraine, Norbert A. and Kornips, Francois H. M. and Drost, Gea and Scholten, Erik and Bosch, Frank H. and Beishuizen, Albertus and Putten, Michel J. A. M. van and Hofmeijer, Jeannette},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/ana.25518},
	pages = {203--214},
}

@article{CerebralRecoveryIndexCRI,
	title = {A {Cerebral} {Recovery} {Index} ({CRI}) for early prognosis in patients after cardiac arrest},
	volume = {17},
	issn = {1364-8535},
	url = {http://ccforum.biomedcentral.com/articles/10.1186/cc13078},
	doi = {10.1186/cc13078},
	abstract = {Introduction: Electroencephalogram (EEG) monitoring in patients treated with therapeutic hypothermia after cardiac arrest may assist in early outcome prediction. Quantitative EEG (qEEG) analysis can reduce the time needed to review long-term EEG and makes the analysis more objective. In this study, we evaluated the predictive value of qEEG analysis for neurologic outcome in postanoxic patients.
Methods: In total, 109 patients admitted to the ICU for therapeutic hypothermia after cardiac arrest were included, divided over a training and a test set. Continuous EEG was recorded during the first 5 days or until ICU discharge. Neurologic outcomes were based on the best achieved Cerebral Performance Category (CPC) score within 6 months. Of the training set, 27 of 56 patients (48\%) and 26 of 53 patients (49\%) of the test set achieved good outcome (CPC 1 to 2). In all patients, a 5 minute epoch was selected each hour, and five qEEG features were extracted. We introduced the Cerebral Recovery Index (CRI), which combines these features into a single number.
Results: At 24 hours after cardiac arrest, a CRI {\textless}0.29 was always associated with poor neurologic outcome, with a sensitivity of 0.55 (95\% confidence interval (CI): 0.32 to 0.76) at a specificity of 1.00 (CI, 0.86 to 1.00) in the test set. This results in a positive predictive value (PPV) of 1.00 (CI, 0.73 to 1.00) and a negative predictive value (NPV) of 0.71 (CI, 0.53 to 0.85). At the same time, a CRI {\textgreater}0.69 predicted good outcome, with a sensitivity of 0.25 (CI, 0.10 to 0.14) at a specificity of 1.00 (CI, 0.85 to 1.00) in the test set, and a corresponding NPV of 1.00 (CI, 0.54 to 1.00) and a PPV of 0.55 (CI, 0.38 to 0.70).
Conclusions: We introduced a combination of qEEG measures expressed in a single number, the CRI, which can assist in prediction of both poor and good outcomes in postanoxic patients, within 24 hours after cardiac arrest.},
	language = {en},
	number = {5},
	urldate = {2020-05-25},
	journal = {Critical Care},
	author = {Tjepkema-Cloostermans, Marleen C and van Meulen, Fokke B and Meinsma, Gjerrit and van Putten, Michel JAM},
	year = {2013},
	pages = {R252},
}

@article{CerebralRecoveryIndexReliable,
	title = {Cerebral {Recovery} {Index}: {Reliable} {Help} for {Prediction} of {Neurologic} {Outcome} {After} {Cardiac} {Arrest}},
	volume = {45},
	issn = {0090-3493},
	shorttitle = {Cerebral {Recovery} {Index}},
	url = {http://journals.lww.com/00003246-201708000-00034},
	doi = {10.1097/CCM.0000000000002412},
	language = {en},
	number = {8},
	urldate = {2020-05-25},
	journal = {Critical Care Medicine},
	author = {Tjepkema-Cloostermans, Marleen C. and Hofmeijer, Jeannette and Beishuizen, Albertus and Hom, Harold W. and Blans, Michiel J. and Bosch, Frank H. and van Putten, Michel J. A. M.},
	month = aug,
	year = {2017},
	pages = {e789--e797},
}

@article{InteractiveVisualPatientCohort,
	title = {Interactive {Visual} {Patient} {Cohort} {Analysis}},
	abstract = {Retrospective patient cohort analysis is a widely used technique in many healthcare studies. Due to its data intensive nature, the traditional analytical pipeline requires expertise from several areas, such as databases, data mining, software development, statistics, and domain knowledge. As a result, domain experts often rely on a team of technologists to help perform such studies which can make the process slow and cumbersome. To allow domain experts to perform faster and more flexible analyses, we designed an integrated system that combines visual exploration and data analytics with an intuitive user interface. Our system lets clinicians interactively visualize and refine cohorts, request analytics on those cohorts, and make new discoveries.},
	language = {en},
	author = {Zhang, Zhiyuan and Gotz, David and Perer, Adam},
	keywords = {vis},
	pages = {2},
}

@article{SubpopulationDiscoveryValidationEpidemiological,
	title = {Subpopulation {Discovery} and {Validation} in {Epidemiological} {Data}},
	abstract = {Motivated by identifying subpopulations that share common characteristics (e.g. alcohol consumption) to explain risk factors of diseases in cohort study data, we used subspace clustering to discover such subpopulations. In this paper, we describe our interactive coordinated multiple view system Visual Analytics framework S-ADVIsED for SubpopulAtion Discovery and Validation In Epidemiological Data. S-ADVIsED enables epidemiologists to explore and validate ﬁndings derived from subspace clustering. We investigated the replication of a selected subpopulation in an independent population.},
	language = {en},
	author = {Alemzadeh, S and Hielscher, T and Niemann, U and Cibulski, L and Ittermann, T and Völzke, H and Spiliopoulou, M and Preim, B},
	year = {2017},
	keywords = {vis},
	pages = {6},
}

@article{InteractiveVisualAnalysisImageCentric,
	title = {Interactive {Visual} {Analysis} of {Image}-{Centric} {Cohort} {Study} {Data}},
	volume = {20},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2014.2346591},
	abstract = {Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Klemm, Paul and Oeltze-Jafra, Steffen and Lawonn, Kai and Hegenscheid, Katrin and Völzke, Henry and Preim, Bernhard},
	month = dec,
	year = {2014},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {vis},
	pages = {1673--1682},
}

@inproceedings{CohortComparisonEventSequences,
	address = {Atlanta, Georgia, USA},
	title = {Cohort {Comparison} of {Event} {Sequences} with {Balanced} {Integration} of {Visual} {Analytics} and {Statistics}},
	isbn = {978-1-4503-3306-1},
	url = {http://dl.acm.org/citation.cfm?doid=2678025.2701407},
	doi = {10.1145/2678025.2701407},
	abstract = {Finding the differences and similarities between two datasets is a common analytics task. With temporal event sequence data, this task is complex because of the many ways single events and event sequences can differ between the two datasets (or cohorts) of records: the structure of the event sequences (e.g., event order, co-occurring events, or event frequencies), the attributes of events and records (e.g., patient gender), or metrics about the timestamps themselves (e.g., event duration). In exploratory analyses, running statistical tests to cover all cases is time-consuming and determining which results are signiﬁcant becomes cumbersome. Current analytics tools for comparing groups of event sequences emphasize a purely statistical or purely visual approach for comparison. This paper presents a taxonomy of metrics for comparing cohorts of temporal event sequences, showing that the problem-space is bounded. We also present a visual analytics tool, CoCo (for “Cohort Comparison”), which implements balanced integration of automated statistics with an intelligent user interface to guide users to signiﬁcant, distinguishing features between the cohorts. Lastly, we describe two early case studies: the ﬁrst with a research team studying medical team performance in the emergency department and the second with pharmacy researchers.},
	language = {en},
	urldate = {2020-05-24},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '15},
	publisher = {ACM Press},
	author = {Malik, Sana and Du, Fan and Monroe, Megan and Onukwugha, Eberechukwu and Plaisant, Catherine and Shneiderman, Ben},
	year = {2015},
	keywords = {vis},
	pages = {38--49},
}

@article{DPVisVisualAnalyticsHidden,
	title = {{DPVis}: {Visual} {Analytics} with {Hidden} {Markov} {Models} for {Disease} {Progression} {Pathways}},
	issn = {1941-0506},
	shorttitle = {{DPVis}},
	doi = {10.1109/TVCG.2020.2985689},
	abstract = {Clinical researchers use disease progression models to understand patient status and characterize progression patterns from longitudinal health records. One approach for disease progression modeling is to describe patient status using a small number of states that represent distinctive distributions over a set of observed measures. Hidden Markov models (HMMs) and its variants are a class of models that both discover these states and make inferences of health states for patients. Despite the advantages of using the algorithms for discovering interesting patterns, it still remains challenging for medical experts to interpret model outputs, understand complex modeling parameters, and clinically make sense of the patterns. To tackle these problems, we conducted a design study with clinical scientists, statisticians, and visualization experts, with the goal to investigate disease progression pathways of chronic diseases, namely type 1 diabetes (T1D), Huntington's disease, Parkinson's disease, and chronic obstructive pulmonary disease (COPD). As a result, we introduce DPVis which seamlessly integrates model parameters and outcomes of HMMs into interpretable and interactive visualizations. In this study, we demonstrate that DPVis is successful in evaluating disease progression models, visually summarizing disease states, interactively exploring disease progression patterns, and building, analyzing, and comparing clinically relevant patient subgroups.},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kwon, Bum Chul and Anand, Vibha and Severson, Kristen A and Ghosh, Soumya and Sun, Zhaonan and Frohnert, Brigitte I and Lundgren, Markus and Ng, Kenney},
	year = {2020},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {vis},
	pages = {1--1},
}

@article{TransferLearningTimeSeriesa,
	title = {Transfer learning for time series classification},
	url = {http://arxiv.org/abs/1811.01533},
	doi = {10.1109/BigData.2018.8621990},
	abstract = {Transfer learning for deep neural networks is the process of first training a base network on a source dataset, and then transferring the learned features (the network's weights) to a second network to be trained on a target dataset. This idea has been shown to improve deep neural network's generalization capabilities in many computer vision tasks such as image recognition and object localization. Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community. However, unlike for image recognition problems, transfer learning techniques have not yet been investigated thoroughly for the TSC task. This is surprising as the accuracy of deep learning models for TSC could potentially be improved if the model is fine-tuned from a pre-trained neural network instead of training it from scratch. In this paper, we fill this gap by investigating how to transfer deep CNNs for the TSC task. To evaluate the potential of transfer learning, we performed extensive experiments using the UCR archive which is the largest publicly available TSC benchmark containing 85 datasets. For each dataset in the archive, we pre-trained a model and then fine-tuned it on the other datasets resulting in 7140 different deep neural networks. These experiments revealed that transfer learning can improve or degrade the model's predictions depending on the dataset used for transfer. Therefore, in an effort to predict the best source dataset for a given target dataset, we propose a new method relying on Dynamic Time Warping to measure inter-datasets similarities. We describe how our method can guide the transfer to choose the best source dataset leading to an improvement in accuracy on 71 out of 85 datasets.},
	urldate = {2020-06-05},
	journal = {2018 IEEE International Conference on Big Data (Big Data)},
	author = {Fawaz, Hassan Ismail and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
	month = dec,
	year = {2018},
	note = {arXiv: 1811.01533},
	keywords = {transfer\_learning},
	pages = {1367--1376},
}

@article{BagofFeaturesFrameworkClassifyTime,
	title = {A {Bag}-of-{Features} {Framework} to {Classify} {Time} {Series}},
	volume = {35},
	issn = {0162-8828, 2160-9292},
	url = {http://ieeexplore.ieee.org/document/6497440/},
	doi = {10.1109/TPAMI.2013.72},
	abstract = {Time series classification is an important task with many challenging applications. A nearest neighbor (NN) classifier with dynamic time warping (DTW) distance is a strong solution in this context. On the other hand, feature-based approaches have been proposed as both classifiers and to provide insight into the series, but these approaches have problems handling translations and dilations in local patterns. Considering these shortcomings, we present a framework to classify time series based on a bag-of-features representation (TSBF). Multiple subsequences selected from random locations and of random lengths are partitioned into shorter intervals to capture the local information. Consequently, features computed from these subsequences measure properties at different locations and dilations when viewed from the original series. This provides a feature-based approach that can handle warping (although differently from DTW). Moreover, a supervised learner (that handles mixed data types, different units, etc.) integrates location information into a compact codebook through class probability estimates. Additionally, relevant global features can easily supplement the codebook. TSBF is compared to NN classifiers and other alternatives (bag-ofwords strategies, sparse spatial sample kernels, shapelets). Our experimental results show that TSBF provides better results than competitive methods on benchmark datasets from the UCR time series database.},
	language = {en},
	number = {11},
	urldate = {2020-06-05},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Baydogan, M. G. and Runger, G. and Tuv, E.},
	month = nov,
	year = {2013},
	pages = {2796--2802},
}

@article{TimeSeriesClassificationScratch,
	title = {Time {Series} {Classification} from {Scratch} with {Deep} {Neural} {Networks}: {A} {Strong} {Baseline}},
	shorttitle = {Time {Series} {Classification} from {Scratch} with {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1611.06455},
	abstract = {We propose a simple but strong baseline for time series classiﬁcation from scratch with deep neural networks. Our proposed baseline models are pure end-to-end without any heavy preprocessing on the raw data or feature crafting. The proposed Fully Convolutional Network (FCN) achieves premium performance to other state-of-the-art approaches and our exploration of the very deep neural networks with the ResNet structure is also competitive. The global average pooling in our convolutional model enables the exploitation of the Class Activation Map (CAM) to ﬁnd out the contributing region in the raw data for the speciﬁc labels. Our models provides a simple choice for the real world application and a good starting point for the future research. An overall analysis is provided to discuss the generalization capability of our models, learned features, network structures and the classiﬁcation semantics.},
	language = {en},
	urldate = {2020-06-04},
	journal = {arXiv:1611.06455 [cs, stat]},
	author = {Wang, Zhiguang and Yan, Weizhong and Oates, Tim},
	month = dec,
	year = {2016},
	note = {arXiv: 1611.06455},
}

@inproceedings{FinetuningVisualizationConvolutionalNeural,
	address = {Siem Reap},
	title = {Fine-tuning and visualization of convolutional neural networks},
	isbn = {978-1-5090-6161-7},
	url = {http://ieeexplore.ieee.org/document/8283041/},
	doi = {10.1109/ICIEA.2017.8283041},
	abstract = {Image classiﬁcation is a widely discussed topic in the ﬁeld of computer vision. In recent years, with the application of Convolutional Neural Networks (CNNs), the state-of-the-art in this area has progressed rapidly. To yield a well performed CNN, the advanced GPU and large amount of training data are employed, thus training an entire CNN from scratch is difﬁcult. In practice, ﬁne-tuning a pre-trained CNN is a simple yet effective method to solve a target task. In this paper, we address on the issue of visualizing a ﬁne-tuned CNN, comparing with a small CNN trained from scratch on the same task, to explain how ﬁne-tuning achieve such good performance.},
	language = {en},
	urldate = {2020-06-04},
	booktitle = {2017 12th {IEEE} {Conference} on {Industrial} {Electronics} and {Applications} ({ICIEA})},
	publisher = {IEEE},
	author = {Yin, Xiangnan and Chen, Weihai and Wu, Xingming and Yue, Haosong},
	month = jun,
	year = {2017},
	pages = {1310--1315},
}

@article{ComparisonParametricNonparametricMethods,
	title = {Comparison of parametric and nonparametric methods for outcome prediction using longitudinal data after cardiac arrest},
	volume = {148},
	issn = {03009572},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0300957220300423},
	doi = {10.1016/j.resuscitation.2020.01.020},
	abstract = {Introduction: Predicting outcome after cardiac arrest is challenging. We previously tested group-based trajectory modeling (GBTM) for prognostication based on baseline characteristics and quantitative electroencephalographic (EEG) trajectories. Here, we describe implementation of this method in a freely available software package and test its performance against alternative options.
Methods: We included comatose patients admitted to a single center after resuscitation from cardiac arrest from April 2010 to April 2019 who underwent !6 h of EEG monitoring. We abstracted clinical information from our prospective registry and summarized suppression ratio in 48 hourly epochs. We tested three classes of longitudinal models: frequentist, statistically based GBTMs; non-parametric (i.e. machine learning) k-means models; and Bayesian regression. Our primary outcome of interest was discharge CPC 1À3 (vs unconsciousness or death). We compared sensitivity for detecting poor outcome at a false positive rate (FPR) {\textless}1\%.
Results: Of 1,010 included subjects, 250 (25\%) were awake and alive at hospital discharge. GBTM and k-means derived trajectories, group sizes and group-specific outcomes were comparable. Conditional on an FPR {\textless} 1\%, GBTMs yielded optimal sensitivity (38\%) over 48 h. More sensitive methods had 2À3 \% FPRs.
Conclusion: We explored fundamentally different tools for patient-level predictions based on longitudinal and time-invariant patient data. Of the evaluated methods, GBTM resulted in optimal sensitivity while maintaining a false positive rate {\textless}1\%. The provided code and software of this method provides an easy-to-use implementation for outcome prediction based on GBTMs.},
	language = {en},
	urldate = {2020-05-30},
	journal = {Resuscitation},
	author = {Elmer, Jonathan and Jones, Bobby L. and Nagin, Daniel S.},
	month = mar,
	year = {2020},
	pages = {152--160},
}

@article{PredictingOutcomePatientsModerate,
	title = {Predicting outcome in patients with moderate to severe traumatic brain injury using electroencephalography},
	volume = {23},
	issn = {1364-8535},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6907281/},
	doi = {10.1186/s13054-019-2656-6},
	abstract = {Background
Better outcome prediction could assist in reliable quantification and classification of traumatic brain injury (TBI) severity to support clinical decision-making. We developed a multifactorial model combining quantitative electroencephalography (qEEG) measurements and clinically relevant parameters as proof of concept for outcome prediction of patients with moderate to severe TBI.

Methods
Continuous EEG measurements were performed during the first 7 days of ICU admission. Patient outcome at 12 months was dichotomized based on the Extended Glasgow Outcome Score (GOSE) as poor (GOSE 1–2) or good (GOSE 3–8). Twenty-three qEEG features were extracted. Prediction models were created using a Random Forest classifier based on qEEG features, age, and mean arterial blood pressure (MAP) at 24, 48, 72, and 96 h after TBI and combinations of two time intervals. After optimization of the models, we added parameters from the International Mission for Prognosis And Clinical Trial Design (IMPACT) predictor, existing of clinical, CT, and laboratory parameters at admission. Furthermore, we compared our best models to the online IMPACT predictor.

Results
Fifty-seven patients with moderate to severe TBI were included and divided into a training set (n = 38) and a validation set (n = 19). Our best model included eight qEEG parameters and MAP at 72 and 96 h after TBI, age, and nine other IMPACT parameters. This model had high predictive ability for poor outcome on both the training set using leave-one-out (area under the receiver operating characteristic curve (AUC) = 0.94, specificity 100\%, sensitivity 75\%) and validation set (AUC = 0.81, specificity 75\%, sensitivity 100\%). The IMPACT predictor independently predicted both groups with an AUC of 0.74 (specificity 81\%, sensitivity 65\%) and 0.84 (sensitivity 88\%, specificity 73\%), respectively.

Conclusions
Our study shows the potential of multifactorial Random Forest models using qEEG parameters to predict outcome in patients with moderate to severe TBI.},
	urldate = {2020-05-30},
	journal = {Critical Care},
	author = {Haveman, Marjolein E. and Van Putten, Michel J. A. M. and Hom, Harold W. and Eertman-Meyer, Carin J. and Beishuizen, Albertus and Tjepkema-Cloostermans, Marleen C.},
	month = dec,
	year = {2019},
	pmid = {31829226},
	pmcid = {PMC6907281},
}

@article{DetectionAnalysisEpilepticEEG,
	title = {Detection {Analysis} of {Epileptic} {EEG} {Using} a {Novel} {Random} {Forest} {Model} {Combined} {With} {Grid} {Search} {Optimization}},
	volume = {13},
	issn = {1662-5161},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6393755/},
	doi = {10.3389/fnhum.2019.00052},
	abstract = {In the automatic detection of epileptic seizures, the monitoring of critically ill patients with time varying EEG signals is an essential procedure in intensive care units. There is an increasing interest in using EEG analysis to detect seizure, and in this study we aim to get a better understanding of how to visualize the information in the EEG time-frequency feature, and design and train a novel random forest algorithm for EEG decoding, especially for multiple-levels of illness. Here, we propose an automatic detection framework for epileptic seizure based on multiple time-frequency analysis approaches; it involves a novel random forest model combined with grid search optimization. The short-time Fourier transformation visualizes seizure features after normalization. The dimensionality of features is reduced through principal component analysis before feeding them into the classification model. The training parameters are optimized using grid search optimization to improve detection performance and diagnostic accuracy by in the recognition of three different levels epileptic of conditions (healthy subjects, seizure-free intervals, seizure activity). Our proposed model was used to classify 500 samples of raw EEG data, and multiple cross-validations were adopted to boost the modeling accuracy. Experimental results were evaluated by an accuracy, a confusion matrix, a receiver operating characteristic curve, and an area under the curve. The evaluations indicated that our model achieved the more effective classification than some previous typical methods. Such a scheme for computer-assisted clinical diagnosis of seizures has a potential guiding significance, which not only relieves the suffering of patient with epilepsy to improve quality of life, but also helps neurologists reduce their workload.},
	urldate = {2020-05-30},
	journal = {Frontiers in Human Neuroscience},
	author = {Wang, Xiashuang and Gong, Guanghong and Li, Ni and Qiu, Shi},
	month = feb,
	year = {2019},
	pmid = {30846934},
	pmcid = {PMC6393755},
}

@article{ClassificationEEGSignalsBased,
	title = {Classification of {EEG} {Signals} {Based} on {Pattern} {Recognition} {Approach}},
	volume = {11},
	issn = {1662-5188},
	url = {http://journal.frontiersin.org/article/10.3389/fncom.2017.00103/full},
	doi = {10.3389/fncom.2017.00103},
	abstract = {Feature extraction is an important step in the process of electroencephalogram (EEG) signal classiﬁcation. The authors propose a “pattern recognition” approach that discriminates EEG signals recorded during different cognitive conditions. Wavelet based feature extraction such as, multi-resolution decompositions into detailed and approximate coefﬁcients as well as relative wavelet energy were computed. Extracted relative wavelet energy features were normalized to zero mean and unit variance and then optimized using Fisher’s discriminant ratio (FDR) and principal component analysis (PCA). A high density EEG dataset validated the proposed method (128-channels) by identifying two classiﬁcations: (1) EEG signals recorded during complex cognitive tasks using Raven’s Advance Progressive Metric (RAPM) test; (2) EEG signals recorded during a baseline task (eyes open). Classiﬁers such as, K-nearest neighbors (KNN), Support Vector Machine (SVM), Multi-layer Perceptron (MLP), and Naïve Bayes (NB) were then employed. Outcomes yielded 99.11\% accuracy via SVM classiﬁer for coefﬁcient approximations (A5) of low frequencies ranging from 0 to 3.90 Hz. Accuracy rates for detailed coefﬁcients were 98.57 and 98.39\% for SVM and KNN, respectively; and for detailed coefﬁcients (D5) deriving from the sub-band range (3.90–7.81 Hz). Accuracy rates for MLP and NB classiﬁers were comparable at 97.11–89.63\% and 91.60–81.07\% for A5 and D5 coefﬁcients, respectively. In addition, the proposed approach was also applied on public dataset for classiﬁcation of two cognitive tasks and achieved comparable classiﬁcation results, i.e., 93.33\% accuracy with KNN. The proposed scheme yielded signiﬁcantly higher classiﬁcation performances using machine learning classiﬁers compared to extant quantitative feature extraction. These results suggest the proposed feature extraction method reliably classiﬁes EEG signals recorded during cognitive tasks with a higher degree of accuracy.},
	language = {en},
	urldate = {2020-05-25},
	journal = {Frontiers in Computational Neuroscience},
	author = {Amin, Hafeez Ullah and Mumtaz, Wajid and Subhani, Ahmad Rauf and Saad, Mohamad Naufal Mohamad and Malik, Aamir Saeed},
	month = nov,
	year = {2017},
	pages = {103},
}

@article{InvestigatingEEGBurstSuppression,
	title = {Investigating {EEG} {Burst} {Suppression} for {Coma} {Outcome} {Prediction}},
	abstract = {Every year, over 300,000 incidents of cardiac arrest occur in the United States. Of the people who are successfully resuscitated and brought to the hospital, approximately 80\% remain unconscious for some amount of time Marion [2009]. Predicting whether or not a patient will wake up from coma, as well as the patient’s neurological function after waking up, is an important task in guiding treatment decisions for physicians and family of the patient. This project seeks to improve this prediction process by analyzing features of the patients’ EEG recordings during coma with the aim to determine quantitative metrics which are predictive of patients’ outcome. Speciﬁcally, we focus on the analysis of the similarity of bursts during burst suppression, which has been hypothesized to be linked with poor outcome. Our work conﬁrms that similarity of bursts is indeed linked with poor outcome, and we also ﬁnd that dynamic time warping gives a viable alternative to the previously used method of cross-correlation as a measure of similarity of bursts, with good predictive power for patient outcome.},
	language = {en},
	author = {Zhan, Tiange},
	pages = {101},
}

@article{DenoisingSparseAutoencoderBasedIctal,
	title = {Denoising {Sparse} {Autoencoder}-{Based} {Ictal} {EEG} {Classification}},
	volume = {26},
	issn = {1558-0210},
	doi = {10.1109/TNSRE.2018.2864306},
	abstract = {Automatic seizure detection technology can automatically mark the EEG by using the epileptic detection algorithm, which is helpful to the diagnosis and treatment of epileptic diseases. This paper presents an EEG classification framework based on the denoising sparse autoencoder. The denoising sparse autoencoder (DSAE) is an improved unsupervised deep neural network over sparse autoencoder and denoising autoencoder, which can learn the closest representation of the data. The sparsity constraint applied in the hidden layer of the network makes the expression of data as sparse as possible so as to obtain a more efficient representation of EEG signals. In addition, corrupting operation used in input data help to enhance the robustness of the system and make it suitable for the analysis of non-stationary epileptic EEG signals. In this paper, we first imported the pre-processed training data to the DSAE network and trained the network. A logistic regression classifier was connected to the top of the DSAE. Then, put the test data into the system for classification. Finally, the output results of the overall network were post-processed to obtain the final epilepsy detection results. In the two-class (nonseizure and seizure EEGs) problem, the system has achieved effective results with the average sensitivity of 100\%, specificity of 100\%, and recognition of 100\%, showing that the proposed framework can be efficient for the classification of epileptic EEGs.},
	number = {9},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Qiu, Yang and Zhou, Weidong and Yu, Nana and Du, Peidong},
	month = sep,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	pages = {1717--1726},
}

@article{ClassifyingDepressionPatientsNormal,
	title = {Classifying depression patients and normal subjects using machine learning techniques and nonlinear features from {EEG} signal},
	volume = {109},
	issn = {01692607},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169260712002507},
	doi = {10.1016/j.cmpb.2012.10.008},
	abstract = {Diagnosing depression in the early curable stages is very important and may even save the life of a patient. In this paper, we study nonlinear analysis of EEG signal for discriminating depression patients and normal controls. Forty-ﬁve unmedicated depressed patients and 45 normal subjects were participated in this study. Power of four EEG bands and four nonlinear features including detrended ﬂuctuation analysis (DFA), higuchi fractal, correlation dimension and lyapunov exponent were extracted from EEG signal. For discriminating the two groups, k-nearest neighbor, linear discriminant analysis and logistic regression as the classiﬁers are then used. Highest classiﬁcation accuracy of 83.3\% is obtained by correlation dimension and LR classiﬁer among other nonlinear features. For further improvement, all nonlinear features are combined and applied to classiﬁers. A classiﬁcation accuracy of 90\% is achieved by all nonlinear features and LR classiﬁer. In all experiments, genetic algorithm is employed to select the most important features. The proposed technique is compared and contrasted with the other reported methods and it is demonstrated that by combining nonlinear features, the performance is enhanced. This study shows that nonlinear analysis of EEG can be a useful method for discriminating depressed patients and normal subjects. It is suggested that this analysis may be a complementary tool to help psychiatrists for diagnosing depressed patients.},
	language = {en},
	number = {3},
	urldate = {2020-05-25},
	journal = {Computer Methods and Programs in Biomedicine},
	author = {Hosseinifard, Behshad and Moradi, Mohammad Hassan and Rostami, Reza},
	month = mar,
	year = {2013},
	pages = {339--345},
}

@article{EEGSignalsClassificationUsing,
	title = {{EEG} signals classification using the {K}-means clustering and a multilayer perceptron neural network model},
	volume = {38},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417411006762},
	doi = {10.1016/j.eswa.2011.04.149},
	abstract = {We introduced a multilayer perceptron neural network (MLPNN) based classiﬁcation model as a diagnostic decision support mechanism in the epilepsy treatment. EEG signals were decomposed into frequency sub-bands using discrete wavelet transform (DWT). The wavelet coefﬁcients were clustered using the K-means algorithm for each frequency sub-band. The probability distributions were computed according to distribution of wavelet coefﬁcients to the clusters, and then used as inputs to the MLPNN model. We conducted ﬁve different experiments to evaluate the performance of the proposed model in the classiﬁcations of different mixtures of healthy segments, epileptic seizure free segments and epileptic seizure segments. We showed that the proposed model resulted in satisfactory classiﬁcation accuracy rates.},
	language = {en},
	number = {10},
	urldate = {2020-05-25},
	journal = {Expert Systems with Applications},
	author = {Orhan, Umut and Hekim, Mahmut and Ozer, Mahmut},
	month = sep,
	year = {2011},
	pages = {13475--13481},
}

@article{NovelSignalModelingApproach,
	title = {A {Novel} {Signal} {Modeling} {Approach} for {Classification} of {Seizure} and {Seizure}-{Free} {EEG} {Signals}},
	volume = {26},
	issn = {1558-0210},
	doi = {10.1109/TNSRE.2018.2818123},
	abstract = {This paper presents a signal modeling-based new methodology of automatic seizure detection in EEG signals. The proposed method consists of three stages. First, a multirate filterbank structure is proposed that is constructed using the basis vectors of discrete cosine transform. The proposed filterbank decomposes EEG signals into its respective brain rhythms: delta, theta, alpha, beta, and gamma. Second, these brain rhythms are statistically modeled with the class of self-similar Gaussian random processes, namely, fractional Brownian motion and fractional Gaussian noises. The statistics of these processes are modeled using a single parameter called the Hurst exponent. In the last stage, the value of Hurst exponent and autoregressive moving average parameters are used as features to design a binary support vector machine classifier to classify pre-ictal, inter-ictal (epileptic with seizure free interval), and ictal (seizure) EEG segments. The performance of the classifier is assessed via extensive analysis on two widely used data set and is observed to provide good accuracy on both the data set. Thus, this paper proposes a novel signal model for EEG data that best captures the attributes of these signals and hence, allows to boost the classification accuracy of seizure and seizure-free epochs.},
	number = {5},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Gupta, Anubha and Singh, Pushpendra and Karlekar, Mandar},
	month = may,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	pages = {925--935},
}

@article{HowExplainIndividualClassificationa,
	title = {How to {Explain} {Individual} {Classiﬁcation} {Decisions}},
	abstract = {After building a classiﬁer with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data. Thus, we get an answer to the question what is the most likely label of a given unseen data point. However, most methods will provide no answer why the model predicted a particular label for a single instance and what features were most inﬂuential for that particular instance. The only method that is currently able to provide such explanations are decision trees. This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of any classiﬁcation method.},
	language = {en},
	author = {Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja},
	keywords = {explanation, fatml, xai},
	pages = {29},
}

@article{ExplainableNLPGenerativeExplanation,
	title = {Towards {Explainable} {NLP}: {A} {Generative} {Explanation} {Framework} for {Text} {Classification}},
	shorttitle = {Towards {Explainable} {NLP}},
	url = {http://arxiv.org/abs/1811.00196},
	abstract = {Building explainable systems is a critical problem in the field of Natural Language Processing (NLP), since most machine learning models provide no explanations for the predictions. Existing approaches for explainable machine learning systems tend to focus on interpreting the outputs or the connections between inputs and outputs. However, the fine-grained information is often ignored, and the systems do not explicitly generate the human-readable explanations. To better alleviate this problem, we propose a novel generative explanation framework that learns to make classification decisions and generate fine-grained explanations at the same time. More specifically, we introduce the explainable factor and the minimum risk training approach that learn to generate more reasonable explanations. We construct two new datasets that contain summaries, rating scores, and fine-grained reasons. We conduct experiments on both datasets, comparing with several strong neural network baseline systems. Experimental results show that our method surpasses all baselines on both datasets, and is able to generate concise explanations at the same time.},
	urldate = {2020-06-09},
	journal = {arXiv:1811.00196 [cs]},
	author = {Liu, Hui and Yin, Qingyu and Wang, William Yang},
	month = jun,
	year = {2019},
	note = {arXiv: 1811.00196},
}

@article{ExplainablePredictionMedicalCodes,
	title = {Explainable {Prediction} of {Medical} {Codes} from {Clinical} {Text}},
	url = {http://arxiv.org/abs/1802.05695},
	abstract = {Clinical notes are text documents that are created by clinicians for each patient encounter. They are typically accompanied by medical codes, which describe the diagnosis and treatment. Annotating these codes is labor intensive and error prone; furthermore, the connection between the codes and the text is not annotated, obscuring the reasons and details behind specific diagnoses and treatments. We present an attentional convolutional network that predicts medical codes from clinical text. Our method aggregates information across the document using a convolutional neural network, and uses an attention mechanism to select the most relevant segments for each of the thousands of possible codes. The method is accurate, achieving precision@8 of 0.71 and a Micro-F1 of 0.54, which are both better than the prior state of the art. Furthermore, through an interpretability evaluation by a physician, we show that the attention mechanism identifies meaningful explanations for each code assignment},
	urldate = {2020-06-09},
	journal = {arXiv:1802.05695 [cs, stat]},
	author = {Mullenbach, James and Wiegreffe, Sarah and Duke, Jon and Sun, Jimeng and Eisenstein, Jacob},
	month = apr,
	year = {2018},
	note = {arXiv: 1802.05695},
}

@inproceedings{InteractiveVisualizationManipulationAttentionbased,
	address = {Copenhagen, Denmark},
	title = {Interactive {Visualization} and {Manipulation} of {Attention}-based {Neural} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/D17-2021},
	doi = {10.18653/v1/D17-2021},
	abstract = {While neural machine translation (NMT) provides high-quality translation, it is still hard to interpret and analyze its behavior. We present an interactive interface for visualizing and intervening behavior of NMT, specifically concentrating on the behavior of beam search mechanism and attention component. The tool (1) visualizes search tree and attention and (2) provides interface to adjust search tree and attention weight (manually or automatically) at real-time. We show the tool gives various methods to understand NMT.},
	urldate = {2020-06-09},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Lee, Jaesong and Shin, Joong-Hwi and Kim, Jun-Seok},
	month = sep,
	year = {2017},
	keywords = {attention, explanation},
	pages = {121--126},
}

@techreport{PeaxInteractiveVisualPattern,
	type = {preprint},
	title = {Peax {Interactive} {Visual} {Pattern} {Search} in {Sequential} {Data} {Using} {Unsupervised} {Deep} {Representation} {Learning}},
	url = {http://biorxiv.org/lookup/doi/10.1101/597518},
	abstract = {We present PEAX, a novel feature-based technique for interactive visual pattern search in sequential data, like time series or data mapped to a genome sequence. Visually searching for patterns by similarity is often challenging because of the large search space, the visual complexity of patterns, and the user’s perception of similarity. For example, in genomics, researchers try to link patterns in multivariate sequential data to cellular or pathogenic processes, but a lack of ground truth and high variance makes automatic pattern detection unreliable. We have developed a convolutional autoencoder for unsupervised representation learning of regions in sequential data that can capture more visual details of complex patterns compared to existing similarity measures. Using this learned representation as features of the sequential data, our accompanying visual query system enables interactive feedback-driven adjustments of the pattern search to adapt to the users’ perceived similarity. Using an active learning sampling strategy, PEAX collects user-generated binary relevance feedback. This feedback is used to train a model for binary classiﬁcation, to ultimately ﬁnd other regions that exhibit patterns similar to the search target. We demonstrate PEAX’s features through a case study in genomics and report on a user study with eight domain experts to assess the usability and usefulness of PEAX. Moreover, we evaluate the effectiveness of the learned feature representation for visual similarity search in two additional user studies. We ﬁnd that our models retrieve signiﬁcantly more similar patterns than other commonly used techniques.},
	language = {en},
	urldate = {2020-06-08},
	institution = {Genomics},
	author = {Lekschas, Fritz and Peterson, Brant and Haehn, Daniel and Ma, Eric and Gehlenborg, Nils and Pfister, Hanspeter},
	month = apr,
	year = {2019},
	doi = {10.1101/597518},
}

@article{SequentialFeatureExplanationsAnomaly,
	title = {Sequential {Feature} {Explanations} for {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/1503.00038},
	abstract = {In many applications, an anomaly detection system presents the most anomalous data instance to a human analyst, who then must determine whether the instance is truly of interest (e.g. a threat in a security setting). Unfortunately, most anomaly detectors provide no explanation about why an instance was considered anomalous, leaving the analyst with no guidance about where to begin the investigation. To address this issue, we study the problems of computing and evaluating sequential feature explanations (SFEs) for anomaly detectors. An SFE of an anomaly is a sequence of features, which are presented to the analyst one at a time (in order) until the information contained in the highlighted features is enough for the analyst to make a confident judgement about the anomaly. Since analyst effort is related to the amount of information that they consider in an investigation, an explanation's quality is related to the number of features that must be revealed to attain confidence. One of our main contributions is to present a novel framework for large scale quantitative evaluations of SFEs, where the quality measure is based on analyst effort. To do this we construct anomaly detection benchmarks from real data sets along with artificial experts that can be simulated for evaluation. Our second contribution is to evaluate several novel explanation approaches within the framework and on traditional anomaly detection benchmarks, offering several insights into the approaches.},
	urldate = {2020-06-08},
	journal = {arXiv:1503.00038 [cs, stat]},
	author = {Siddiqui, Md Amran and Fern, Alan and Dietterich, Thomas G. and Wong, Weng-Keen},
	month = feb,
	year = {2015},
	note = {arXiv: 1503.00038},
	keywords = {explanation},
}

@article{TransferLearningVisualCategorization,
	title = {Transfer {Learning} for {Visual} {Categorization}: {A} {Survey}},
	volume = {26},
	issn = {2162-2388},
	shorttitle = {Transfer {Learning} for {Visual} {Categorization}},
	doi = {10.1109/TNNLS.2014.2330900},
	abstract = {Regular machine learning and data mining techniques study the training data for future inferences under a major assumption that the future data are within the same feature space or have the same distribution as the training data. However, due to the limited availability of human labeled training data, training data that stay in the same feature space or have the same distribution as the future data cannot be guaranteed to be sufficient enough to avoid the over-fitting problem. In real-world applications, apart from data in the target domain, related data in a different domain can also be included to expand the availability of our prior knowledge about the target future data. Transfer learning addresses such cross-domain learning problems by extracting useful information from data in a related domain and transferring them for being used in target tasks. In recent years, with transfer learning being applied to visual categorization, some typical problems, e.g., view divergence in action recognition tasks and concept drifting in image classification tasks, can be efficiently solved. In this paper, we survey state-of-the-art transfer learning algorithms in visual categorization applications, such as object recognition, image classification, and human action recognition.},
	number = {5},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Shao, Ling and Zhu, Fan and Li, Xuelong},
	month = may,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Neural Networks and Learning Systems},
	pages = {1019--1034},
}

@article{TransferLearningTimeSeries,
	title = {Transfer learning for time series anomaly detection},
	language = {en},
	author = {Vercruyssen, Vincent and Meert, Wannes and Davis, Jesse},
	pages = {10},
}

@article{CostSensitiveConvolutionBasedNeural,
	title = {Cost-{Sensitive} {Convolution} based {Neural} {Networks} for {Imbalanced} {Time}-{Series} {Classification}},
	url = {http://arxiv.org/abs/1801.04396},
	abstract = {Some deep convolutional neural networks were proposed for time-series classification and class imbalanced problems. However, those models performed degraded and even failed to recognize the minority class of an imbalanced temporal sequences dataset. Minority samples would bring troubles for temporal deep learning classifiers due to the equal treatments of majority and minority class. Until recently, there were few works applying deep learning on imbalanced time-series classification (ITSC) tasks. Here, this paper aimed at tackling ITSC problems with deep learning. An adaptive cost-sensitive learning strategy was proposed to modify temporal deep learning models. Through the proposed strategy, classifiers could automatically assign misclassification penalties to each class. In the experimental section, the proposed method was utilized to modify five neural networks. They were evaluated on a large volume, real-life and imbalanced time-series dataset with six metrics. Each single network was also tested alone and combined with several mainstream data samplers. Experimental results illustrated that the proposed cost-sensitive modified networks worked well on ITSC tasks. Compared to other methods, the cost-sensitive convolution neural network and residual network won out in the terms of all metrics. Consequently, the proposed cost-sensitive learning strategy can be used to modify deep learning classifiers from cost-insensitive to cost-sensitive. Those cost-sensitive convolutional networks can be effectively applied to address ITSC issues.},
	urldate = {2020-06-05},
	journal = {arXiv:1801.04396 [cs]},
	author = {Geng, Yue and Luo, Xinyu},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.04396},
}

@article{SurveyDeepTransferLearning,
	title = {A {Survey} on {Deep} {Transfer} {Learning}},
	url = {http://arxiv.org/abs/1808.01974},
	abstract = {As a new classification platform, deep learning has recently received increasing attention from researchers and has been successfully applied to many domains. In some domains, like bioinformatics and robotics, it is very difficult to construct a large-scale well-annotated dataset due to the expense of data acquisition and costly annotation, which limits its development. Transfer learning relaxes the hypothesis that the training data must be independent and identically distributed (i.i.d.) with the test data, which motivates us to use transfer learning to solve the problem of insufficient training data. This survey focuses on reviewing the current researches of transfer learning by using deep neural network and its applications. We defined deep transfer learning, category and review the recent research works based on the techniques used in deep transfer learning.},
	urldate = {2020-06-05},
	journal = {arXiv:1808.01974 [cs, stat]},
	author = {Tan, Chuanqi and Sun, Fuchun and Kong, Tao and Zhang, Wenchang and Yang, Chao and Liu, Chunfang},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.01974},
}

@article{VisualAnalyticalApproachTransfer,
	title = {A visual analytical approach for transfer learning in classification},
	volume = {390},
	issn = {00200255},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025516301694},
	doi = {10.1016/j.ins.2016.03.021},
	abstract = {Classiﬁcation can be highly challenging when the dataset is extremely large, or when the training data in the underlying domain are diﬃcult to obtain. One feasible solution to this challenge is transfer learning, which extracts the knowledge from source tasks and applies the knowledge to target tasks. Extant transfer learning schemes typically assume that similarities between the source task and the target task to some degree. This assumption does not hold in certain actual applications; analysts unfamiliar with the learning strategy can be frustrated by the complicated transfer relations and the non-intuitive transfer process. This paper presents a suite of visual communication and interaction techniques to support the transfer learning process. Furthermore, a pioneering visual-assisted transfer learning methodology is proposed in the context of classiﬁcation. Our solution includes a visual communication interface that allows for comprehensive exploration of the entire knowledge transfer process and the relevance among tasks. With these techniques and the methodology, the analysts can intuitively choose relevant tasks and data, as well as iteratively incorporate their experience and expertise into the analysis process. We demonstrate the validity and eﬃciency of our visual design and the analysis approach with examples of text classiﬁcation.},
	language = {en},
	urldate = {2020-06-05},
	journal = {Information Sciences},
	author = {Ma, Yuxin and Xu, Jiayi and Wu, Xiangyang and Wang, Fei and Chen, Wei},
	month = jun,
	year = {2017},
	pages = {54--69},
}

@article{DeepLearningAnomalyDetection,
	title = {Deep {Learning} for {Anomaly} {Detection}: {A} {Survey}},
	shorttitle = {Deep {Learning} for {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/1901.03407},
	abstract = {Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.},
	urldate = {2020-06-05},
	journal = {arXiv:1901.03407 [cs, stat]},
	author = {Chalapathy, Raghavendra and Chawla, Sanjay},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.03407},
}

@article{EnhancingTrustMachineLearning,
	title = {Enhancing {Trust} in {Machine} {Learning} {Models} with the {Use} of {Visualizations}},
	abstract = {Machine learning (ML) models are nowadays used in complex applications in various domains, such as medicine, bioinformatics, and other sciences. Due to their black box nature, however, it may sometimes be hard to understand and trust the results they provide. This has increased the demand for reliable visualization tools related to enhancing trust in ML models, which has become a prominent topic of research in the visualization community over the past decades. To provide an overview and present the frontiers of current research on the topic, we present a State-of-the-Art Report (STAR) on enhancing trust in ML models with the use of interactive visualization. We deﬁne and describe the background of the topic, introduce a categorization for visualization techniques that aim to accomplish this goal, and discuss insights and opportunities for future research directions. Among our contributions is a categorization of trust against different facets of interactive ML, expanded and improved from previous research. Our results are investigated from different analytical perspectives: (a) providing a statistical overview, (b) summarizing key ﬁndings, (c) performing topic analyses, and (d) exploring the data sets used in the individual papers, all with the support of an interactive web-based survey browser. We intend this survey to be beneﬁcial for visualization researchers whose interests involve making ML models more trustworthy, as well as researchers and practitioners from other disciplines in their search for effective visualization techniques suitable for solving their tasks with conﬁdence and conveying meaning to their data.},
	language = {en},
	author = {Chatzimparmpas, A and Martins, R M and Jusuﬁ, I and Kucher, K and Rossi, F and Kerren, A},
	year = {2020},
	keywords = {comps-iui, survey, vis},
	pages = {44},
}

@article{InterpretableMachineLearningTransparent,
	title = {Toward {Interpretable} {Machine} {Learning}: {Transparent} {Deep} {Neural} {Networks} and {Beyond}},
	shorttitle = {Toward {Interpretable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/2003.07631},
	abstract = {With the broader and highly successful usage of machine learning in industry and the sciences, there has been a growing demand for explainable AI. Interpretability and explanation methods for gaining a better understanding about the problem solving abilities and strategies of nonlinear Machine Learning such as Deep Learning (DL), LSTMs, and kernel methods are therefore receiving increased attention. In this work we aim to (1) provide a timely overview of this active emerging field and explain its theoretical foundations, (2) put interpretability algorithms to a test both from a theory and comparative evaluation perspective using extensive simulations, (3) outline best practice aspects i.e. how to best include interpretation methods into the standard usage of machine learning and (4) demonstrate successful usage of explainable AI in a representative selection of application scenarios. Finally, we discuss challenges and possible future directions of this exciting foundational field of machine learning.},
	urldate = {2020-06-10},
	journal = {arXiv:2003.07631 [cs, stat]},
	author = {Samek, Wojciech and Montavon, Grégoire and Lapuschkin, Sebastian and Anders, Christopher J. and Müller, Klaus-Robert},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.07631},
	keywords = {comps-dm, dl, fatml, xai},
}

@article{MonoNetInterpretableModelsLearning,
	title = {{MonoNet}: {Towards} {Interpretable} {Models} by {Learning} {Monotonic} {Features}},
	shorttitle = {{MonoNet}},
	url = {http://arxiv.org/abs/1909.13611},
	abstract = {Being able to interpret, or explain, the predictions made by a machine learning model is of fundamental importance. This is especially true when there is interest in deploying data-driven models to make high-stakes decisions, e.g. in healthcare. While recent years have seen an increasing interest in interpretable machine learning research, this field is currently lacking an agreed-upon definition of interpretability, and some researchers have called for a more active conversation towards a rigorous approach to interpretability. Joining this conversation, we claim in this paper that the difficulty of interpreting a complex model stems from the existing interactions among features. We argue that by enforcing monotonicity between features and outputs, we are able to reason about the effect of a single feature on an output independently from other features, and consequently better understand the model. We show how to structurally introduce this constraint in deep learning models by adding new simple layers. We validate our model on benchmark datasets, and compare our results with previously proposed interpretable models.},
	urldate = {2020-06-10},
	journal = {arXiv:1909.13611 [cs, stat]},
	author = {Nguyen, An-phi and Martínez, María Rodríguez},
	month = sep,
	year = {2019},
	note = {arXiv: 1909.13611},
	keywords = {fatml, interpretable, xai},
}

@misc{IEEEXploreFullTextPDF,
	title = {{IEEE} {Xplore} {Full}-{Text} {PDF}:},
	url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883519&casa_token=9bEjrmmVMewAAAAA:ppfd3I1Xl0vE91j236m9Ihe-VbJGA19FYRJtkgWbOfSKlcNaQUnCHaKo29RXAFBNJeo6dW5sCg&tag=1},
	urldate = {2020-06-10},
	keywords = {ts, vis},
}

@article{IntegrationKnowledgeGraphsDeep,
	title = {On the {Integration} of {Knowledge} {Graphs} into {Deep} {Learning} {Models} for a {More} {Comprehensible} {AI}—{Three} {Challenges} for {Future} {Research}},
	volume = {11},
	issn = {2078-2489},
	url = {https://www.mdpi.com/2078-2489/11/2/122},
	doi = {10.3390/info11020122},
	abstract = {Deep learning models contributed to reaching unprecedented results in prediction and classiﬁcation tasks of Artiﬁcial Intelligence (AI) systems. However, alongside this notable progress, they do not provide human-understandable insights on how a speciﬁc result was achieved. In contexts where the impact of AI on human life is relevant (e.g., recruitment tools, medical diagnoses, etc.), explainability is not only a desirable property, but it is -or, in some cases, it will be soon-a legal requirement. Most of the available approaches to implement eXplainable Artiﬁcial Intelligence (XAI) focus on technical solutions usable only by experts able to manipulate the recursive mathematical functions in deep learning algorithms. A complementary approach is represented by symbolic AI, where symbols are elements of a lingua franca between humans and deep learning. In this context, Knowledge Graphs (KGs) and their underlying semantic technologies are the modern implementation of symbolic AI—while being less ﬂexible and robust to noise compared to deep learning models, KGs are natively developed to be explainable. In this paper, we review the main XAI approaches existing in the literature, underlying their strengths and limitations, and we propose neural-symbolic integration as a cornerstone to design an AI which is closer to non-insiders comprehension. Within such a general direction, we identify three speciﬁc challenges for future research—knowledge matching, cross-disciplinary explanations and interactive explanations.},
	language = {en},
	number = {2},
	urldate = {2020-06-10},
	journal = {Information},
	author = {Futia, Giuseppe and Vetrò, Antonio},
	month = feb,
	year = {2020},
	pages = {122},
}

@article{HowEfficiencyShapesHuman,
	title = {How {Efficiency} {Shapes} {Human} {Language}},
	volume = {23},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661319300580},
	doi = {10.1016/j.tics.2019.02.003},
	language = {en},
	number = {5},
	urldate = {2020-06-10},
	journal = {Trends in Cognitive Sciences},
	author = {Gibson, Edward and Futrell, Richard and Piantadosi, Steven P. and Dautriche, Isabelle and Mahowald, Kyle and Bergen, Leon and Levy, Roger},
	month = may,
	year = {2019},
	keywords = {nlp},
	pages = {389--407},
}

@article{TimeseriesExtremeEventForecasting,
	title = {Time-series {Extreme} {Event} {Forecasting} with {Neural} {Networks} at {Uber}},
	abstract = {Accurate time-series forecasting during high variance segments (e.g., holidays), is critical for anomaly detection, optimal resource allocation, budget planning and other related tasks. At Uber accurate prediction for completed trips during special events can lead to a more efﬁcient driver allocation resulting in a decreased wait time for the riders.},
	language = {en},
	author = {Laptev, Nikolay and Yosinski, Jason and Li, Li Erran and Smyl, Slawek},
	pages = {5},
}

@inproceedings{RigorousEvaluationXAIMethods,
	title = {Towards {A} {Rigorous} {Evaluation} {Of} {XAI} {Methods} {On} {Time} {Series}},
	doi = {10.1109/ICCVW.2019.00516},
	abstract = {Explainable Artificial Intelligence (XAI) methods are typically deployed to explain and debug black-box machine learning models. However, most proposed XAI methods are black-boxes themselves and designed for images. Thus, they rely on visual interpretability to evaluate and prove explanations. In this work, we apply XAI methods previously used in the image and text-domain on time series. We present a methodology to test and evaluate various XAI methods on time series by introducing new verification techniques to incorporate the temporal dimension. We further conduct preliminary experiments to assess the quality of selected XAI method explanations with various verification methods on a range of datasets and inspecting quality metrics on it. We demonstrate that in our initial experiments, SHAP works robust for all models, but others like DeepLIFT, LRP, and Saliency Maps work better with specific architectures.},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} {Workshop} ({ICCVW})},
	author = {Schlegel, Udo and Arnout, Hiba and El-Assady, Mennatallah and Oelke, Daniela and Keim, Daniel A.},
	month = oct,
	year = {2019},
	note = {ISSN: 2473-9944},
	keywords = {fatml, survey, ts, xai},
	pages = {4197--4201},
}

@inproceedings{ExplainableDeepNeuralNetworks,
	address = {Macao, China},
	title = {Explainable {Deep} {Neural} {Networks} for {Multivariate} {Time} {Series} {Predictions}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/932},
	doi = {10.24963/ijcai.2019/932},
	abstract = {We demonstrate that CNN deep neural networks can not only be used for making predictions based on multivariate time series data, but also for explaining these predictions. This is important for a number of applications where predictions are the basis for decisions and actions. Hence, conﬁdence in the prediction result is crucial. We design a two stage convolutional neural network architecture which uses particular kernel sizes. This allows us to utilise gradient based techniques for generating saliency maps for both the time dimension and the features. These are then used for explaining which features during which time interval are responsible for a given prediction, as well as explaining during which time intervals was the joint contribution of all features most important for that prediction. We demonstrate our approach for predicting the average energy production of photovoltaic power plants and for explaining these predictions.},
	language = {en},
	urldate = {2020-06-10},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Assaf, Roy and Schumann, Anika},
	month = aug,
	year = {2019},
	pages = {6488--6490},
}

@article{DeepLearningTimeSeries,
	title = {Deep learning for time series classification: a review},
	volume = {33},
	issn = {1384-5810, 1573-756X},
	shorttitle = {Deep learning for time series classification},
	url = {http://link.springer.com/10.1007/s10618-019-00619-1},
	doi = {10.1007/s10618-019-00619-1},
	abstract = {Time Series Classiﬁcation (TSC) is an important and challenging problem in data mining. With the increase of time series data availability, hundreds of TSC algorithms have been proposed. Among these methods, only a few have considered Deep Neural Networks (DNNs) to perform this task. This is surprising as deep learning has seen very successful applications in the last years. DNNs have indeed revolutionized the ﬁeld of computer vision especially with the advent of novel deeper architectures such as Residual and Convolutional Neural Networks. Apart from images, sequential data such as text and audio can also be processed with DNNs to reach state-of-the-art performance for document classiﬁcation and speech recognition. In this article, we study the current state-of-the-art performance of deep learning algorithms for TSC by presenting an empirical study of the most recent DNN architectures for TSC. We give an overview of the most successful deep learning applications in various time series domains under a uniﬁed taxonomy of DNNs for TSC. We also provide an open source deep learning framework to the TSC community where we implemented each of the compared approaches and evaluated them on a univariate TSC benchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By training 8730 deep learning models on 97 time series datasets, we propose the most exhaustive study of DNNs for TSC to date.},
	language = {en},
	number = {4},
	urldate = {2020-06-09},
	journal = {Data Mining and Knowledge Discovery},
	author = {Ismail Fawaz, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
	month = jul,
	year = {2019},
	keywords = {dl, dm, survey, ts},
	pages = {917--963},
}

@inproceedings{SemanticsSketchFlexibilityVisual,
	title = {The semantics of sketch: {Flexibility} in visual query systems for time series data},
	shorttitle = {The semantics of sketch},
	doi = {10.1109/VAST.2016.7883519},
	abstract = {Sketching allows analysts to specify complex and free-form patterns of interest. Visual query systems can make use of sketches to locate these patterns of interest in large datasets. However, sketching is ambiguous: the same drawing could represent a multitude of potential queries. In this work, we investigate these ambiguities as they apply to visual query systems for time series data. We define a class of “invariants” - the properties of a time series that the analyst wishes to ignore when performing a sketch-based query. We present the results of a crowd-sourced study, showing that these invariants are key components of how people rate the strength of match between sketch and target. We adapt a number of algorithms for time series matching to support invariants in sketches. Lastly, we present a web-deployed prototype sketch-based visual query system that relies on these invariants. We apply the prototype to data from finance, the digital humanities, and political science.},
	booktitle = {2016 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	author = {Correll, Michael and Gleicher, Michael},
	month = oct,
	year = {2016},
	keywords = {ts, vis},
	pages = {131--140},
}

@article{UserDemographicsLanguageImplicit,
	title = {User {Demographics} and {Language} in an {Implicit} {Social} {Network}},
	abstract = {We consider the task of predicting the gender of the YouTube1 users and contrast two information sources: the comments they leave and the social environment induced from the afﬁliation graph of users and videos. We propagate gender information through the videos and show that a user’s gender can be predicted from her social environment with the accuracy above 90\%. We also show that the gender can be predicted from language alone (89\%). A surprising result of our study is that the latter predictions correlate more strongly with the gender predominant in the user’s environment than with the sex of the person as reported in the proﬁle. We also investigate how the two views (linguistic and social) can be combined and analyse how prediction accuracy changes over different age groups.},
	language = {en},
	author = {Filippova, Katja},
	pages = {11},
}

@article{GenderIdentityLexicalVariation,
	title = {Gender identity and lexical variation in social media},
	volume = {18},
	issn = {1467-9841},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/josl.12080},
	doi = {10.1111/josl.12080},
	abstract = {We present a study of the relationship between gender, linguistic style, and social networks, using a novel corpus of 14,000 Twitter users. Prior quantitative work on gender often treats this social variable as a female/male binary; we argue for a more nuanced approach. By clustering Twitter users, we find a natural decomposition of the dataset into various styles and topical interests. Many clusters have strong gender orientations, but their use of linguistic resources sometimes directly conflicts with the population-level language statistics. We view these clusters as a more accurate reflection of the multifaceted nature of gendered language styles. Previous corpus-based work has also had little to say about individuals whose linguistic styles defy population-level gender patterns. To identify such individuals, we train a statistical classifier, and measure the classifier confidence for each individual in the dataset. Examining individuals whose language does not match the classifier's model for their gender, we find that they have social networks that include significantly fewer same-gender social connections and that, in general, social network homophily is correlated with the use of same-gender language markers. Pairing computational methods and social theory thus offers a new perspective on how gender emerges as individuals position themselves relative to audiences, topics, and mainstream gender norms.},
	language = {en},
	number = {2},
	urldate = {2020-06-13},
	journal = {Journal of Sociolinguistics},
	author = {Bamman, David and Eisenstein, Jacob and Schnoebelen, Tyler},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/josl.12080},
	pages = {135--160},
}

@article{DiscriminatingGenderTwitter,
	title = {Discriminating gender on {Twitter}},
	abstract = {Accurate prediction of demographic attributes from social media and other informal online content is valuable for marketing, personalization, and legal investigation. This paper describes the construction of a large, multilingual dataset labeled with gender, and investigates statistical models for determining the gender of uncharacterized Twitter users. We explore several different classiﬁer types on this dataset. We show the degree to which classiﬁer accuracy varies based on tweet volumes as well as when various kinds of proﬁle metadata are included in the models. We also perform a large-scale human assessment using Amazon Mechanical Turk. Our methods signiﬁcantly out-perform both baseline models and almost all humans on the same task.},
	language = {en},
	author = {Burger, John D and Henderson, John and Kim, George and Zarrella, Guido},
	pages = {9},
}

@article{WhoTweetsDerivingDemographic,
	title = {Who {Tweets}? {Deriving} the {Demographic} {Characteristics} of {Age}, {Occupation} and {Social} {Class} from {Twitter} {User} {Meta}-{Data}},
	volume = {10},
	issn = {1932-6203},
	shorttitle = {Who {Tweets}?},
	url = {https://dx.plos.org/10.1371/journal.pone.0115545},
	doi = {10.1371/journal.pone.0115545},
	language = {en},
	number = {3},
	urldate = {2020-06-13},
	journal = {PLOS ONE},
	author = {Sloan, Luke and Morgan, Jeffrey and Burnap, Pete and Williams, Matthew},
	editor = {Preis, Tobias},
	month = mar,
	year = {2015},
	pages = {e0115545},
}

@article{ClassifyingPoliticalOrientationTwitter,
	title = {Classifying {Political} {Orientation} on {Twitter}: {It}'s {Not} {Easy}!},
	abstract = {Numerous papers have reported great success at inferring the political orientation of Twitter users. This paper has some unfortunate news to deliver: while past work has been sound and often methodologically novel, we have discovered that reported accuracies have been systemically overoptimistic due to the way in which validation datasets have been collected, reporting accuracy levels nearly 30\% higher than can be expected in populations of general Twitter users.},
	language = {en},
	author = {Cohen, Raviv and Ruths, Derek},
	pages = {9},
}

@article{KeepingDesignersLoopCommunicatinga,
	title = {Keeping {Designers} in the {Loop}: {Communicating} {Inherent} {Algorithmic} {Trade}-offs {Across} {Multiple} {Objectives}},
	abstract = {Artiﬁcial intelligence algorithms have been used to enhance a wide variety of products and services, including assisting human decision making in high-stake contexts. However, these algorithms are complex and have trade-offs, notably between prediction accuracy and fairness to population subgroups. This makes it hard for designers to understand algorithms and design products or services in a way that respects users’ goals, values, and needs. We proposed a method to help designers and users explore algorithms, visualize their trade-offs, and select algorithms with trade-offs consistent with their goals and needs. We evaluated our method on the problem of predicting criminal defendants’ likelihood to re-offend through (i) a large-scale Amazon Mechanical Turk experiment, and (ii) in-depth interviews with domain experts. Our evaluations show that our method can help designers and users of these systems better understand and navigate algorithmic trade-offs. This paper contributes a new way of providing designers the ability to understand and control the outcomes of algorithmic systems they are creating.},
	language = {en},
	author = {Yu, Bowen and Yuan, Ye and Terveen, Loren and Wu, Zhiwei Steven and Forlizzi, Jodi and Zhu, Haiyi},
	keywords = {hil, vis},
	pages = {13},
}

@inproceedings{VariableLengthMethodsDetecting,
	title = {Variable {Length} {Methods} for {Detecting} {Anomaly} {Patterns} in {Time} {Series}},
	volume = {2},
	doi = {10.1109/ISCID.2008.95},
	abstract = {There has been much interest in mining anomaly patterns in time series. However, different datasets may have different lengths of anomaly patterns, and usually, the length of anomaly patterns is unknown. This paper uses k-distance of a pattern and median to define anomaly factor, the degree of anomaly, presents- definition- of- anomaly pattern based on it and two algorithms, algorithm 1 and algorithm 2. Algorithm 1 uses quadratic regression to segment time series, and obtains the range of length patterns. Algorithm 2 uses DTW (dynamic time warping) and variable methods to calculate similarity of patterns dynamically, detects anomaly patterns in a given time series automatically. We demonstrate the effectiveness of our detection algorithm for anomaly patterns with both synthetic and ECGs data sets, and the experimental results confirm that our methods can detect anomaly patterns with different lengths.},
	booktitle = {2008 {International} {Symposium} on {Computational} {Intelligence} and {Design}},
	author = {Leng, Mingwei and Chen, Xiaoyun and Li, Longjie},
	month = oct,
	year = {2008},
	pages = {52--56},
}

@incollection{SEGMENTINGTIMESERIESSURVEY,
	title = {{SEGMENTING} {TIME} {SERIES}: {A} {SURVEY} {AND} {NOVEL} {APPROACH}},
	volume = {57},
	isbn = {978-981-238-290-0 978-981-256-540-2},
	shorttitle = {{SEGMENTING} {TIME} {SERIES}},
	url = {http://www.worldscientific.com/doi/abs/10.1142/9789812565402_0001},
	abstract = {In recent years, there has been an explosion of interest in mining time series databases. As with most computer science problems, representation of the data is the key to efficient and effective solutions. One of the most commonly used representations is piecewise linear approximation. This representation has been used by various researchers to support clustering, classification, indexing and association rule mining of time series data. A variety of algorithms have been proposed to obtain this representation, with several algorithms having been independently rediscovered several times. In this paper, we undertake the first extensive review and empirical comparison of all proposed techniques. We show that all these algorithms have fatal flaws from a data mining perspective. We introduce a novel algorithm that we empirically show to be superior to all others in the literature.},
	language = {en},
	urldate = {2020-06-12},
	booktitle = {Series in {Machine} {Perception} and {Artificial} {Intelligence}},
	publisher = {WORLD SCIENTIFIC},
	author = {Keogh, Eamonn and Chu, Selina and Hart, David and Pazzani, Michael},
	collaborator = {Last, Mark and Kandel, Abraham and Bunke, Horst},
	month = jun,
	year = {2004},
	doi = {10.1142/9789812565402_0001},
	keywords = {approximation, ts},
	pages = {1--21},
}

@article{ModelAgnosticContrastiveExplanations,
	title = {Model {Agnostic} {Contrastive} {Explanations} for {Structured} {Data}},
	url = {http://arxiv.org/abs/1906.00117},
	abstract = {Recently, a method [7] was proposed to generate contrastive explanations for differentiable models such as deep neural networks, where one has complete access to the model. In this work, we propose a method, Model Agnostic Contrastive Explanations Method (MACEM), to generate contrastive explanations for {\textbackslash}emph\{any\} classification model where one is able to {\textbackslash}emph\{only\} query the class probabilities for a desired input. This allows us to generate contrastive explanations for not only neural networks, but models such as random forests, boosted trees and even arbitrary ensembles that are still amongst the state-of-the-art when learning on structured data [13]. Moreover, to obtain meaningful explanations we propose a principled approach to handle real and categorical features leading to novel formulations for computing pertinent positives and negatives that form the essence of a contrastive explanation. A detailed treatment of the different data types of this nature was not performed in the previous work, which assumed all features to be positive real valued with zero being indicative of the least interesting value. We part with this strong implicit assumption and generalize these methods so as to be applicable across a much wider range of problem settings. We quantitatively and qualitatively validate our approach over 5 public datasets covering diverse domains.},
	urldate = {2020-06-12},
	journal = {arXiv:1906.00117 [cs, stat]},
	author = {Dhurandhar, Amit and Pedapati, Tejaswini and Balakrishnan, Avinash and Chen, Pin-Yu and Shanmugam, Karthikeyan and Puri, Ruchir},
	month = may,
	year = {2019},
	note = {arXiv: 1906.00117},
	keywords = {contrastive, explanation},
}

@inproceedings{BetterFasterKnowledgeTransfer,
	address = {Stockholm, Sweden},
	title = {Better and {Faster}: {Knowledge} {Transfer} from {Multiple} {Self}-supervised {Learning} {Tasks} via {Graph} {Distillation} for {Video} {Classification}},
	isbn = {978-0-9992411-2-7},
	shorttitle = {Better and {Faster}},
	url = {https://www.ijcai.org/proceedings/2018/158},
	doi = {10.24963/ijcai.2018/158},
	abstract = {Video representation learning is a vital problem for classiﬁcation task. Recently, a promising unsupervised paradigm termed self-supervised learning has emerged, which explores inherent supervisory signals implied in massive data for feature learning via solving auxiliary tasks. However, existing methods in this regard suffer from two limitations when extended to video classiﬁcation. First, they focus only on a single task, whereas ignoring complementarity among different task-speciﬁc features and thus resulting in suboptimal video representation. Second, high computational and memory cost hinders their application in real-world scenarios. In this paper, we propose a graph-based distillation framework to address these problems: (1) We propose logits graph and representation graph to transfer knowledge from multiple self-supervised tasks, where the former distills classiﬁer-level knowledge by solving a multi-distribution joint matching problem, and the latter distills internal feature knowledge from pairwise ensembled representations with tackling the challenge of heterogeneity among different features; (2) The proposal that adopts a teacher-student framework can reduce the redundancy of knowledge learned from teachers dramatically, leading to a lighter student model that solves classiﬁcation task more efﬁciently. Experimental results on 3 video datasets validate that our proposal not only helps learn better video representation but also compress model for faster inference.},
	language = {en},
	urldate = {2020-06-12},
	booktitle = {Proceedings of the {Twenty}-{Seventh} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Zhang, Chenrui and Peng, Yuxin},
	month = jul,
	year = {2018},
	keywords = {kd, self-supervised},
	pages = {1135--1141},
}

@inproceedings{VisualDebuggingMultitargetTime,
	address = {Cagliari Italy},
	title = {Towards visual debugging for multi-target time series classification},
	isbn = {978-1-4503-7118-6},
	url = {https://dl.acm.org/doi/10.1145/3377325.3377528},
	doi = {10.1145/3377325.3377528},
	abstract = {Multi-target classification of multivariate time series data poses a challenge in many real-world applications (e.g., predictive maintenance). Machine learning methods, such as random forests and neural networks, support training these classifiers. However, the debugging and analysis of possible misclassifications remain challenging due to the often complex relations between targets, classes, and the multivariate time series data. We propose a model-agnostic visual debugging workflow for multi-target time series classification that enables the examination of relations between targets, partially correct predictions, potential confusions, and the classified time series data. The workflow, as well as the prototype, aims to foster an in-depth analysis of multi-target classification results to identify potential causes of mispredictions visually. We demonstrate the usefulness of the workflow in the field of predictive maintenance in a usage scenario to show how users can iteratively explore and identify critical classes, as well as, relationships between targets.},
	language = {en},
	urldate = {2020-06-12},
	booktitle = {Proceedings of the 25th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Schlegel, Udo and Cakmak, Eren and Arnout, Hiba and El-Assady, Mennatallah and Oelke, Daniela and Keim, Daniel A.},
	month = mar,
	year = {2020},
	keywords = {ml, vis},
	pages = {202--206},
}

@article{PixelWiseExplanationsNonLinearClassifier,
	title = {On {Pixel}-{Wise} {Explanations} for {Non}-{Linear} {Classifier} {Decisions} by {Layer}-{Wise} {Relevance} {Propagation}},
	volume = {10},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4498753/},
	doi = {10.1371/journal.pone.0130140},
	abstract = {Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.},
	number = {7},
	urldate = {2020-06-11},
	journal = {PLoS ONE},
	author = {Bach, Sebastian and Binder, Alexander and Montavon, Grégoire and Klauschen, Frederick and Müller, Klaus-Robert and Samek, Wojciech},
	month = jul,
	year = {2015},
	pmid = {26161953},
	pmcid = {PMC4498753},
	keywords = {explanation, fatml, xai},
}

@incollection{TimeSeriesClassificationUsing,
	address = {Cham},
	title = {Time {Series} {Classification} {Using} {Multi}-{Channels} {Deep} {Convolutional} {Neural} {Networks}},
	volume = {8485},
	isbn = {978-3-319-08009-3 978-3-319-08010-9},
	url = {http://link.springer.com/10.1007/978-3-319-08010-9_33},
	abstract = {Time series (particularly multivariate) classiﬁcation has drawn a lot of attention in the literature because of its broad applications for diﬀerent domains, such as health informatics and bioinformatics. Thus, many algorithms have been developed for this task. Among them, nearest neighbor classiﬁcation (particularly 1-NN) combined with Dynamic Time Warping (DTW) achieves the state of the art performance. However, when data set grows larger, the time consumption of 1-NN with DTW grows linearly. Compared to 1-NN with DTW, the traditional feature-based classiﬁcation methods are usually more eﬃcient but less eﬀective since their performance is usually dependent on the quality of hand-crafted features. To that end, in this paper, we explore the feature learning techniques to improve the performance of traditional feature-based approaches. Speciﬁcally, we propose a novel deep learning framework for multivariate time series classiﬁcation. We conduct two groups of experiments on real-world data sets from diﬀerent application domains. The ﬁnal results show that our model is not only more eﬃcient than the state of the art but also competitive in accuracy. It also demonstrates that feature learning is worth to investigate for time series classiﬁcation.},
	language = {en},
	urldate = {2020-06-15},
	booktitle = {Web-{Age} {Information} {Management}},
	publisher = {Springer International Publishing},
	author = {Zheng, Yi and Liu, Qi and Chen, Enhong and Ge, Yong and Zhao, J. Leon},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard and Li, Feifei and Li, Guoliang and Hwang, Seung-won and Yao, Bin and Zhang, Zhenjie},
	year = {2014},
	doi = {10.1007/978-3-319-08010-9_33},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {298--310},
}

@article{TimeContrastiveNetworksSelfSupervisedLearning,
	title = {Time-{Contrastive} {Networks}: {Self}-{Supervised} {Learning} from {Video}},
	shorttitle = {Time-{Contrastive} {Networks}},
	url = {http://arxiv.org/abs/1704.06888},
	abstract = {We propose a self-supervised approach for learning representations and robotic behaviors entirely from unlabeled videos recorded from multiple viewpoints, and study how this representation can be used in two robotic imitation settings: imitating object interactions from videos of humans, and imitating human poses. Imitation of human behavior requires a viewpoint-invariant representation that captures the relationships between end-effectors (hands or robot grippers) and the environment, object attributes, and body pose. We train our representations using a metric learning loss, where multiple simultaneous viewpoints of the same observation are attracted in the embedding space, while being repelled from temporal neighbors which are often visually similar but functionally different. In other words, the model simultaneously learns to recognize what is common between different-looking images, and what is different between similar-looking images. This signal causes our model to discover attributes that do not change across viewpoint, but do change across time, while ignoring nuisance variables such as occlusions, motion blur, lighting and background. We demonstrate that this representation can be used by a robot to directly mimic human poses without an explicit correspondence, and that it can be used as a reward function within a reinforcement learning algorithm. While representations are learned from an unlabeled collection of task-related videos, robot behaviors such as pouring are learned by watching a single 3rd-person demonstration by a human. Reward functions obtained by following the human demonstrations under the learned representation enable efficient reinforcement learning that is practical for real-world robotic systems. Video results, open-source code and dataset are available at https://sermanet.github.io/imitate},
	urldate = {2020-06-15},
	journal = {arXiv:1704.06888 [cs]},
	author = {Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey},
	month = mar,
	year = {2018},
	note = {arXiv: 1704.06888
version: 3},
	keywords = {self-supervised},
}

@article{MultitaskSelfSupervisedLearningHuman,
	title = {Multi-task {Self}-{Supervised} {Learning} for {Human} {Activity} {Detection}},
	volume = {3},
	issn = {2474-9567, 2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3328932},
	doi = {10.1145/3328932},
	language = {en},
	number = {2},
	urldate = {2020-06-14},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Saeed, Aaqib and Ozcelebi, Tanir and Lukkien, Johan},
	month = jun,
	year = {2019},
	keywords = {hci, self-supervised},
	pages = {1--30},
}

@article{SelfsupervisedKnowledgeDistillationUsing,
	title = {Self-supervised {Knowledge} {Distillation} {Using} {Singular} {Value} {Decomposition}},
	url = {http://arxiv.org/abs/1807.06819},
	abstract = {To solve deep neural network (DNN)'s huge training dataset and its high computation issue, so-called teacher-student (T-S) DNN which transfers the knowledge of T-DNN to S-DNN has been proposed. However, the existing T-S-DNN has limited range of use, and the knowledge of T-DNN is insufficiently transferred to S-DNN. To improve the quality of the transferred knowledge from T-DNN, we propose a new knowledge distillation using singular value decomposition (SVD). In addition, we define a knowledge transfer as a self-supervised task and suggest a way to continuously receive information from T-DNN. Simulation results show that a S-DNN with a computational cost of 1/5 of the T-DNN can be up to 1.1{\textbackslash}\% better than the T-DNN in terms of classification accuracy. Also assuming the same computational cost, our S-DNN outperforms the S-DNN driven by the state-of-the-art distillation with a performance advantage of 1.79{\textbackslash}\%. code is available on https://github.com/sseung0703/SSKD{\textbackslash}\_SVD.},
	urldate = {2020-06-14},
	journal = {arXiv:1807.06819 [cs, stat]},
	author = {Lee, Seung Hyun and Kim, Dae Ha and Song, Byung Cheol},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.06819},
	keywords = {kd, self-supervised},
}

@inproceedings{SelfSupervisedRepresentationLearningElectroencephalography,
	title = {Self-{Supervised} {Representation} {Learning} from {Electroencephalography} {Signals}},
	doi = {10.1109/MLSP.2019.8918693},
	abstract = {The supervised learning paradigm is limited by the cost - and sometimes the impracticality - of data collection and labeling in multiple domains. Self-supervised learning, a paradigm which exploits the structure of unlabeled data to create learning problems that can be solved with standard supervised approaches, has shown great promise as a pretraining or feature learning approach in fields like computer vision and time series processing. In this work, we present self-supervision strategies that can be used to learn informative representations from multivariate time series. One successful approach relies on predicting whether time windows are sampled from the same temporal context or not. As demonstrated on a clinically relevant task (sleep scoring) and with two electroencephalography datasets, our approach outperforms a purely supervised approach in low data regimes, while capturing important physiological information without any access to labels.},
	booktitle = {2019 {IEEE} 29th {International} {Workshop} on {Machine} {Learning} for {Signal} {Processing} ({MLSP})},
	author = {Banville, Hubert and Albuquerque, Isabela and Hyvärinen, Aapo and Moffat, Graeme and Engemann, Denis-Alexander and Gramfort, Alexandre},
	month = oct,
	year = {2019},
	note = {ISSN: 1551-2541},
	keywords = {self-supervised},
	pages = {1--6},
}

@article{ResponsibleAIItsStakeholders,
	title = {Responsible {AI} and {Its} {Stakeholders}},
	url = {http://arxiv.org/abs/2004.11434},
	abstract = {Responsible Artificial Intelligence (AI) proposes a framework that holds all stakeholders involved in the development of AI to be responsible for their systems. It, however, fails to accommodate the possibility of holding AI responsible per se, which could close some legal and moral gaps concerning the deployment of autonomous and self-learning systems. We discuss three notions of responsibility (i.e., blameworthiness, accountability, and liability) for all stakeholders, including AI, and suggest the roles of jurisdiction and the general public in this matter.},
	urldate = {2020-06-14},
	journal = {arXiv:2004.11434 [cs]},
	author = {Lima, Gabriel and Cha, Meeyoung},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.11434},
	keywords = {fatml, xai},
}

@article{QuantifyingDistanceOpinions,
	title = {Towards {Quantifying} the {Distance} between {Opinions}},
	volume = {14},
	copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2334-0770},
	url = {https://aaai.org/ojs/index.php/ICWSM/article/view/7294},
	abstract = {Increasingly, critical decisions in public policy, governance, and business strategy rely on a deeper understanding of the needs and opinions of constituent members (e.g. citizens, shareholders). While it has become easier to collect a large number of opinions on a topic, there is a necessity for automated tools to help navigate the space of opinions. In such contexts understanding and quantifying the similarity between opinions is key. We find that measures based solely on text similarity or on overall sentiment often fail to effectively capture the distance between opinions. Thus, we propose a new distance measure for capturing the similarity between opinions that leverages the nuanced observation – similar opinions express similar sentiment polarity on specific relevant entities-of-interest. Specifically, in an unsupervised setting, our distance measure achieves significantly better Adjusted Rand Index scores (up to 56x) and Silhouette coefficients (up to 21x) compared to existing approaches. Similarly, in a supervised setting, our opinion distance measure achieves considerably better accuracy (up to 20\% increase) compared to extant approaches that rely on text similarity, stance similarity, and sentiment similarity.},
	language = {en},
	urldate = {2020-06-14},
	journal = {Proceedings of the International AAAI Conference on Web and Social Media},
	author = {Gurukar, Saket and Ajwani, Deepak and Dutta, Sourav and Lauri, Juho and Parthasarathy, Srinivasan and Sala, Alessandra},
	month = may,
	year = {2020},
	keywords = {metric-learning},
	pages = {229--239},
}

@article{FeatureBasedExplanationsDonHelp,
	title = {Feature-{Based} {Explanations} {Don}'t {Help} {People} {Detect} {Misclassifications} of {Online} {Toxicity}},
	volume = {14},
	copyright = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2334-0770},
	url = {https://aaai.org/ojs/index.php/ICWSM/article/view/7282},
	abstract = {We present an experimental assessment of the impact of feature attribution-style explanations on human performance in predicting the consensus toxicity of social media posts with advice from an unreliable machine learning model. By doing so we add to a small but growing body of literature inspecting the utility of interpretable machine learning in terms of human outcomes. We also evaluate interpretable machine learning for the first time in the important domain of online toxicity, where fully-automated methods have faced criticism as being inadequate as a measure of toxic behavior.We find that, contrary to expectations, explanations have no significant impact on accuracy or agreement with model predictions, through they do change the distribution of subject error somewhat while reducing the cognitive burden of the task for subjects. Our results contribute to the recognition of an intriguing expectation gap in the field of interpretable machine learning between the general excitement the field has engendered and the ambiguous results of recent experimental work, including this study.},
	language = {en},
	urldate = {2020-06-14},
	journal = {Proceedings of the International AAAI Conference on Web and Social Media},
	author = {Carton, Samuel and Mei, Qiaozhu and Resnick, Paul},
	month = may,
	year = {2020},
	keywords = {explanation},
	pages = {95--106},
}

@inproceedings{InferringUserPoliticalPreferences,
	address = {Baltimore, Maryland},
	title = {Inferring {User} {Political} {Preferences} from {Streaming} {Communications}},
	url = {https://www.aclweb.org/anthology/P14-1018},
	doi = {10.3115/v1/P14-1018},
	urldate = {2020-06-13},
	booktitle = {Proceedings of the 52nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Volkova, Svitlana and Coppersmith, Glen and Van Durme, Benjamin},
	month = jun,
	year = {2014},
	pages = {186--196},
}

@article{PredictingSociodemographicTraitsEmotions,
	title = {On {Predicting} {Sociodemographic} {Traits} and {Emotions} from {Communications} in {Social} {Networks} and {Their} {Implications} to {Online} {Self}-{Disclosure}},
	volume = {18},
	issn = {2152-2715, 2152-2723},
	url = {http://www.liebertpub.com/doi/10.1089/cyber.2014.0609},
	doi = {10.1089/cyber.2014.0609},
	abstract = {Social media services such as Twitter and Facebook are virtual environments where people express their thoughts, emotions, and opinions and where they reveal themselves to their peers. We analyze a sample of 123,000 Twitter users and 25 million of their tweets to investigate the relation between the opinions and emotions that users express and their predicted psychodemographic traits. We show that the emotions that we express on online social networks reveal deep insights about ourselves. Our methodology is based on building machine learning models for inferring coarse-grained emotions and psychodemographic proﬁles from user-generated content. We examine several user attributes, including gender, income, political views, age, education, optimism, and life satisfaction. We correlate these predicted demographics with the emotional proﬁles emanating from user tweets, as captured by Ekman’s emotion classiﬁcation. We ﬁnd that some users tend to express signiﬁcantly more joy and signiﬁcantly less sadness in their tweets, such as those predicted to be in a relationship, with children, or with a higher than average annual income or educational level. Users predicted to be women tend to be more opinionated, whereas those predicted to be men tend to be more neutral. Finally, users predicted to be younger and liberal tend to project more negative opinions and emotions.},
	language = {en},
	number = {12},
	urldate = {2020-06-13},
	journal = {Cyberpsychology, Behavior, and Social Networking},
	author = {Volkova, Svitlana and Bachrach, Yoram},
	month = dec,
	year = {2015},
	pages = {726--736},
}

@inproceedings{DemographicFactorsImproveClassification,
	address = {Beijing, China},
	title = {Demographic {Factors} {Improve} {Classification} {Performance}},
	url = {https://www.aclweb.org/anthology/P15-1073},
	doi = {10.3115/v1/P15-1073},
	urldate = {2020-06-13},
	booktitle = {Proceedings of the 53rd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 7th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hovy, Dirk},
	month = jul,
	year = {2015},
	pages = {752--762},
}

@inproceedings{PredictingPersonalityTwitter,
	title = {Predicting personality from twitter},
	abstract = {Abstract—Social media is a place where users present themselves to the world, revealing personal details and insights into their lives. We are beginning to understand how some of this information can be utilized to improve the users ’ experiences with interfaces and with one another. In this paper, we are interested in the personality of users. Personality has been shown to be relevant to many types of interactions; it has been shown to be useful in predicting job satisfaction, professional and romantic relationship success, and even preference for different interfaces. Until now, to accurately gauge users ’ personalities, they needed to take a personality test. This made it impractical to use personality analysis in many social media domains. In this paper, we present a method by which a user’s personality can be accurately predicted through the publicly available information on their Twitter profile. We will describe the type of data collected, our methods of analysis, and the machine learning techniques that allow us to successfully predict personality. We then discuss the implications this has for social media design, interface design, and broader domains. Index Terms—personality, social media I.},
	booktitle = {in {Proc}. of the 3rd {IEEE} {Intl}. {Conf}. on {Social} {Computing}, 2011},
	author = {Golbeck, Jennifer and Robles, Cristina and Edmondson, Michon and Turner, Karen},
	pages = {149--156},
}

@article{TechniquesInterpretableMachineLearning,
	title = {Techniques for {Interpretable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1808.00033},
	abstract = {Interpretable machine learning tackles the important problem that humans cannot understand the behaviors of complex machine learning models and how these models arrive at a particular decision. Although many approaches have been proposed, a comprehensive understanding of the achievements and challenges is still lacking. We provide a survey covering existing techniques to increase the interpretability of machine learning models. We also discuss crucial issues that the community should consider in future work such as designing user-friendly explanations and developing comprehensive evaluation metrics to further push forward the area of interpretable machine learning.},
	urldate = {2020-06-16},
	journal = {arXiv:1808.00033 [cs, stat]},
	author = {Du, Mengnan and Liu, Ninghao and Hu, Xia},
	month = may,
	year = {2019},
	note = {arXiv: 1808.00033},
	keywords = {explanation, fatml, xai},
}

@incollection{FeatureExtractionMultipleRepresentations,
	address = {Cham},
	title = {Feature {Extraction} over {Multiple} {Representations} for {Time} {Series} {Classification}},
	volume = {8399},
	isbn = {978-3-319-08406-0 978-3-319-08407-7},
	url = {http://link.springer.com/10.1007/978-3-319-08407-7_2},
	abstract = {We suggest a simple yet eﬀective and parameter-free feature construction process for time series classiﬁcation. Our process is decomposed in three steps: (i) we transform original data into several simple representations; (ii) on each representation, we apply a coclustering method; (iii) we use coclustering results to build new features for time series. It results in a new transactional (i.e. object-attribute oriented) data set, made of time series identiﬁers described by features related to the various generated representations. We show that a Selective Naive Bayes classiﬁer on this new data set is highly competitive when compared with state-of-the-art times series classiﬁcation methods while highlighting interpretable and class relevant patterns.},
	language = {en},
	urldate = {2020-06-16},
	booktitle = {New {Frontiers} in {Mining} {Complex} {Patterns}},
	publisher = {Springer International Publishing},
	author = {Gay, Dominique and Guigourès, Romain and Boullé, Marc and Clérot, Fabrice},
	editor = {Appice, Annalisa and Ceci, Michelangelo and Loglisci, Corrado and Manco, Giuseppe and Masciari, Elio and Ras, Zbigniew W.},
	year = {2014},
	doi = {10.1007/978-3-319-08407-7_2},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {dm, multivariate, ts},
	pages = {18--34},
}

@article{TSInsightLocalglobalAttributionFramework,
	title = {{TSInsight}: {A} local-global attribution framework for interpretability in time-series data},
	shorttitle = {{TSInsight}},
	url = {http://arxiv.org/abs/2004.02958},
	abstract = {With the rise in the employment of deep learning methods in safety-critical scenarios, interpretability is more essential than ever before. Although many different directions regarding interpretability have been explored for visual modalities, time-series data has been neglected with only a handful of methods tested due to their poor intelligibility. We approach the problem of interpretability in a novel way by proposing TSInsight where we attach an auto-encoder to the classifier with a sparsity-inducing norm on its output and fine-tune it based on the gradients from the classifier and a reconstruction penalty. TSInsight learns to preserve features that are important for prediction by the classifier and suppresses those that are irrelevant i.e. serves as a feature attribution method to boost interpretability. In contrast to most other attribution frameworks, TSInsight is capable of generating both instance-based and model-based explanations. We evaluated TSInsight along with 9 other commonly used attribution methods on 8 different time-series datasets to validate its efficacy. Evaluation results show that TSInsight naturally achieves output space contraction, therefore, is an effective tool for the interpretability of deep time-series models.},
	urldate = {2020-06-16},
	journal = {arXiv:2004.02958 [cs, stat]},
	author = {Siddiqui, Shoaib Ahmed and Mercier, Dominique and Dengel, Andreas and Ahmed, Sheraz},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.02958},
	keywords = {explainable, fatml, ts, xai},
}

@article{P2ExNetPatchbasedPrototypeExplanation,
	title = {{P2ExNet}: {Patch}-based {Prototype} {Explanation} {Network}},
	shorttitle = {{P2ExNet}},
	url = {http://arxiv.org/abs/2005.02006},
	abstract = {Deep learning methods have shown great success in several domains as they process a large amount of data efficiently, capable of solving complex classification, forecast, segmentation, and other tasks. However, they come with the inherent drawback of inexplicability limiting their applicability and trustworthiness. Although there exists work addressing this perspective, most of the existing approaches are limited to the image modality due to the intuitive and prominent concepts. Conversely, the concepts in the time-series domain are more complex and non-comprehensive but these and an explanation for the network decision are pivotal in critical domains like medical, financial, or industry. Addressing the need for an explainable approach, we propose a novel interpretable network scheme, designed to inherently use an explainable reasoning process inspired by the human cognition without the need of additional post-hoc explainability methods. Therefore, class-specific patches are used as they cover local concepts relevant to the classification to reveal similarities with samples of the same class. In addition, we introduce a novel loss concerning interpretability and accuracy that constraints P2ExNet to provide viable explanations of the data including relevant patches, their position, class similarities, and comparison methods without compromising accuracy. Analysis of the results on eight publicly available time-series datasets reveals that P2ExNet reaches comparable performance when compared to its counterparts while inherently providing understandable and traceable decisions.},
	urldate = {2020-06-16},
	journal = {arXiv:2005.02006 [cs]},
	author = {Mercier, Dominique and Dengel, Andreas and Ahmed, Sheraz},
	month = may,
	year = {2020},
	note = {arXiv: 2005.02006},
	keywords = {elir, explainable, prototype, ts},
}

@article{ExplainingDeepClassificationTimeSeries,
	title = {Explaining {Deep} {Classification} of {Time}-{Series} {Data} with {Learned} {Prototypes}},
	url = {http://arxiv.org/abs/1904.08935},
	abstract = {The emergence of deep learning networks raises a need for explainable AI so that users and domain experts can be confident applying them to high-risk decisions. In this paper, we leverage data from the latent space induced by deep learning models to learn stereotypical representations or "prototypes" during training to elucidate the algorithmic decision-making process. We study how leveraging prototypes effect classification decisions of two dimensional time-series data in a few different settings: (1) electrocardiogram (ECG) waveforms to detect clinical bradycardia, a slowing of heart rate, in preterm infants, (2) respiration waveforms to detect apnea of prematurity, and (3) audio waveforms to classify spoken digits. We improve upon existing models by optimizing for increased prototype diversity and robustness, visualize how these prototypes in the latent space are used by the model to distinguish classes, and show that prototypes are capable of learning features on two dimensional time-series data to produce explainable insights during classification tasks. We show that the prototypes are capable of learning real-world features - bradycardia in ECG, apnea in respiration, and articulation in speech - as well as features within sub-classes. Our novel work leverages learned prototypical framework on two dimensional time-series data to produce explainable insights during classification tasks.},
	urldate = {2020-06-16},
	journal = {arXiv:1904.08935 [cs, stat]},
	author = {Gee, Alan H. and Garcia-Olano, Diego and Ghosh, Joydeep and Paydarfar, David},
	month = sep,
	year = {2019},
	note = {arXiv: 1904.08935},
	keywords = {dl, elir, explainable, fatml, ts, xai},
}

@misc{ExplainingNonlinearClassificationDecisions,
	title = {Explaining nonlinear classification decisions with deep {Taylor} decomposition {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0031320316303582?token=7394E88ADD913841C1447BFA6B9337F75E5A910879D93E0124659D6F03AA17C74E713B1ECA26F88DFDA09AA5E41C1185},
	language = {en},
	urldate = {2020-06-16},
	doi = {10.1016/j.patcog.2016.11.008},
	note = {Library Catalog: reader.elsevier.com},
	keywords = {dl, fatml, local, xai},
}

@article{HowExplainIndividualClassification,
	title = {How to {Explain} {Individual} {Classiﬁcation} {Decisions}},
	abstract = {After building a classiﬁer with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data. Thus, we get an answer to the question what is the most likely label of a given unseen data point. However, most methods will provide no answer why the model predicted a particular label for a single instance and what features were most inﬂuential for that particular instance. The only method that is currently able to provide such explanations are decision trees. This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of any classiﬁcation method.},
	language = {en},
	author = {Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja},
	keywords = {fatml, interpretable, local, xai},
	pages = {29},
}

@article{WhatInteractionDataVisualization,
	title = {What is {Interaction} for {Data} {Visualization}?},
	volume = {26},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/8805424/},
	doi = {10.1109/TVCG.2019.2934283},
	abstract = {Interaction is fundamental to data visualization, but what “interaction” means in the context of visualization is ambiguous and confusing. We argue that this confusion is due to a lack of consensual deﬁnition. To tackle this problem, we start by synthesizing an inclusive view of interaction in the visualization community – including insights from information visualization, visual analytics and scientiﬁc visualization, as well as the input of both senior and junior visualization researchers. Once this view takes shape, we look at how interaction is deﬁned in the ﬁeld of human-computer interaction (HCI). By extracting commonalities and differences between the views of interaction in visualization and in HCI, we synthesize a deﬁnition of interaction for visualization. Our deﬁnition is meant to be a thinking tool and inspire novel and bolder interaction design practices. We hope that by better understanding what interaction in visualization is and what it can be, we will enrich the quality of interaction in visualization systems and empower those who use them. Index Terms—interaction, visualization, data, deﬁnition, human-computer interaction.},
	language = {en},
	number = {1},
	urldate = {2020-06-15},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Dimara, Evanthia and Perin, Charles},
	month = jan,
	year = {2020},
	pages = {119--129},
}

@inproceedings{UnderstandingVisualizingDataIteration,
	address = {Honolulu HI USA},
	title = {Understanding and {Visualizing} {Data} {Iteration} in {Machine} {Learning}},
	isbn = {978-1-4503-6708-0},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376177},
	doi = {10.1145/3313831.3376177},
	abstract = {Successful machine learning (ML) applications require iterations on both modeling and the underlying data. While prior visualization tools for ML primarily focus on modeling, our interviews with 23 ML practitioners reveal that they improve model performance frequently by iterating on their data (e.g., collecting new data, adding labels) rather than their models. We also identify common types of data iterations and associated analysis tasks and challenges. To help attribute data iterations to model performance, we design a collection of interactive visualizations and integrate them into a prototype, CHAMELEON, that lets users compare data features, training/testing splits, and performance across data versions. We present two case studies where developers apply CHAMELEON to their own evolving datasets on production ML projects. Our interface helps them verify data collection efforts, ﬁnd failure cases stretching across data versions, capture data processing changes that impacted performance, and identify opportunities for future data iterations.},
	language = {en},
	urldate = {2020-06-15},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Hohman, Fred and Wongsuphasawat, Kanit and Kery, Mary Beth and Patel, Kayur},
	month = apr,
	year = {2020},
	pages = {1--13},
}

@article{LearningTeachingCoAdaptiveGuidance,
	title = {Learning and {Teaching} in {Co}-{Adaptive} {Guidance} for {Mixed}-{Initiative} {Visual} {Analytics}},
	abstract = {Guidance processes in visual analytics applications often lack adaptivity. In this position paper, we contribute the concept of co-adaptive guidance, building on the principles of initiation and adaptation. We argue that both the user and the system adapt their data-, task- and user/system-models over time. Based on these principles, we propose reasoning about the guidance design space through introducing the concepts of learning and teaching that complement the existing dimension of implicit and explicit guidance, thus, deriving the four guidance dynamics user-teaching, system-teaching, user-learning, and system-learning. Finally, we classify current guidance approaches according to the dynamics, demonstrating their applicability to co-adaptive guidance.},
	language = {en},
	author = {Sperrle, F and Jeitler, A and Bernard, J and Keim, D and El-Assady, M},
	year = {2020},
	keywords = {interaction, survey, vis},
	pages = {5},
}

@article{UnstoppableRiseComputationalLinguistics,
	title = {The {Unstoppable} {Rise} of {Computational} {Linguistics} in {Deep} {Learning}},
	url = {http://arxiv.org/abs/2005.06420},
	abstract = {In this paper, we trace the history of neural networks applied to natural language understanding tasks, and identify key contributions which the nature of language has made to the development of neural network architectures. We focus on the importance of variable binding and its instantiation in attention-based models, and argue that Transformer is not a sequence model but an induced-structure model. This perspective leads to predictions of the challenges facing research in deep learning architectures for natural language understanding.},
	urldate = {2020-06-15},
	journal = {arXiv:2005.06420 [cs]},
	author = {Henderson, James},
	month = jun,
	year = {2020},
	note = {arXiv: 2005.06420},
	keywords = {dl, dm, nlp, survey},
}

@inproceedings{ComplexityInvariantDistanceMeasureTime,
	title = {A {Complexity}-{Invariant} {Distance} {Measure} for {Time} {Series}},
	isbn = {978-0-89871-992-5 978-1-61197-281-8},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611972818.60},
	doi = {10.1137/1.9781611972818.60},
	abstract = {The ubiquity of time series data across almost all human endeavors has produced a great interest in time series data mining in the last decade. While there is a plethora of classification algorithms that can be applied to time series, all of the current empirical evidence suggests that simple nearest neighbor classification is exceptionally difficult to beat. The choice of distance measure used by the nearest neighbor algorithm depends on the invariances required by the domain. For example, motion capture data typically requires invariance to warping.},
	language = {en},
	urldate = {2020-06-15},
	booktitle = {Proceedings of the 2011 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Batista, Gustavo E.A.P.A. and Wang, Xiaoyue and Keogh, Eamonn J.},
	month = apr,
	year = {2011},
	keywords = {invariant, metric-learning, ts},
	pages = {699--710},
}

@article{AutoAIVizOpeningBlackboxAutomated,
	title = {{AutoAIViz}: {Opening} the {Blackbox} of {Automated} {Artificial} {Intelligence} with {Conditional} {Parallel} {Coordinates}},
	shorttitle = {{AutoAIViz}},
	url = {http://arxiv.org/abs/1912.06723},
	doi = {10.1145/3377325.3377538},
	abstract = {Artificial Intelligence (AI) can now automate the algorithm selection, feature engineering, and hyperparameter tuning steps in a machine learning workflow. Commonly known as AutoML or AutoAI, these technologies aim to relieve data scientists from the tedious manual work. However, today's AutoAI systems often present only limited to no information about the process of how they select and generate model results. Thus, users often do not understand the process, neither do they trust the outputs. In this short paper, we provide a first user evaluation by 10 data scientists of an experimental system, AutoAIViz, that aims to visualize AutoAI's model generation process. We find that the proposed system helps users to complete the data science tasks, and increases their understanding, toward the goal of increasing trust in the AutoAI system.},
	urldate = {2020-06-18},
	journal = {Proceedings of the 25th International Conference on Intelligent User Interfaces},
	author = {Weidele, Daniel Karl I. and Weisz, Justin D. and Oduor, Eno and Muller, Michael and Andres, Josh and Gray, Alexander and Wang, Dakuo},
	month = mar,
	year = {2020},
	note = {arXiv: 1912.06723},
	keywords = {automl, vis},
	pages = {308--312},
}

@article{ATMSeerIncreasingTransparencyControllability,
	title = {{ATMSeer}: {Increasing} {Transparency} and {Controllability} in {Automated} {Machine} {Learning}},
	shorttitle = {{ATMSeer}},
	url = {http://arxiv.org/abs/1902.05009},
	doi = {10.1145/3290605.3300911},
	abstract = {To relieve the pain of manually selecting machine learning algorithms and tuning hyperparameters, automated machine learning (AutoML) methods have been developed to automatically search for good models. Due to the huge model search space, it is impossible to try all models. Users tend to distrust automatic results and increase the search budget as much as they can, thereby undermining the efficiency of AutoML. To address these issues, we design and implement ATMSeer, an interactive visualization tool that supports users in refining the search space of AutoML and analyzing the results. To guide the design of ATMSeer, we derive a workflow of using AutoML based on interviews with machine learning experts. A multi-granularity visualization is proposed to enable users to monitor the AutoML process, analyze the searched models, and refine the search space in real time. We demonstrate the utility and usability of ATMSeer through two case studies, expert interviews, and a user study with 13 end users.},
	urldate = {2020-06-18},
	journal = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems  - CHI '19},
	author = {Wang, Qianwen and Ming, Yao and Jin, Zhihua and Shen, Qiaomu and Liu, Dongyu and Smith, Micah J. and Veeramachaneni, Kalyan and Qu, Huamin},
	year = {2019},
	note = {arXiv: 1902.05009},
	keywords = {automl, vis},
	pages = {1--12},
}

@article{GlobalExplanationsConvolutionalNeural,
	title = {Towards {Global} {Explanations} of {Convolutional} {Neural} {Networks} {With} {Concept} {Attribution}},
	abstract = {With the growing prevalence of convolutional neural networks (CNNs), there is an urgent demand to explain their behaviors. Global explanations contribute to understanding model predictions on a whole category of samples, and thus have attracted increasing interest recently. However, existing methods overwhelmingly conduct separate input attribution or rely on local approximations of models, making them fail to offer faithful global explanations of CNNs. To overcome such drawbacks, we propose a novel two-stage framework, Attacking for Interpretability (AfI), which explains model decisions in terms of the importance of userdeﬁned concepts. AfI ﬁrst conducts a feature occlusion analysis, which resembles a process of attacking models to derive the category-wide importance of different features. We then map the feature importance to concept importance through ad-hoc semantic tasks. Experimental results conﬁrm the effectiveness of AfI and its superiority in providing more accurate estimations of concept importance than existing proposals.},
	language = {en},
	author = {Wu, Weibin and Su, Yuxin and Chen, Xixian and Zhao, Shenglin and King, Irwin and Lyu, Michael R and Tai, Yu-Wing},
	keywords = {cnn, dl, elir, fatml, interpretable, xai},
	pages = {10},
}

@article{AblateVariateContemplateVisuala,
	title = {Ablate, {Variate}, and {Contemplate}: {Visual} {Analytics} for {Discovering} {Neural} {Architectures}},
	shorttitle = {Ablate, {Variate}, and {Contemplate}},
	url = {http://arxiv.org/abs/1908.00387},
	abstract = {Deep learning models require the configuration of many layers and parameters in order to get good results. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.},
	urldate = {2020-06-18},
	journal = {arXiv:1908.00387 [cs]},
	author = {Cashman, Dylan and Perer, Adam and Chang, Remco and Strobelt, Hendrik},
	month = jul,
	year = {2019},
	note = {arXiv: 1908.00387},
	keywords = {automl, vis},
}

@article{DeepKNearestNeighborsConfident,
	title = {Deep k-{Nearest} {Neighbors}: {Towards} {Confident}, {Interpretable} and {Robust} {Deep} {Learning}},
	shorttitle = {Deep k-{Nearest} {Neighbors}},
	url = {http://arxiv.org/abs/1803.04765},
	abstract = {Deep neural networks (DNNs) enable innovative applications of machine learning like image recognition, machine translation, or malware detection. However, deep learning is often criticized for its lack of robustness in adversarial settings (e.g., vulnerability to adversarial inputs) and general inability to rationalize its predictions. In this work, we exploit the structure of deep learning to enable new learning-based inference and decision strategies that achieve desirable properties such as robustness and interpretability. We take a first step in this direction and introduce the Deep k-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest neighbors algorithm with representations of the data learned by each layer of the DNN: a test input is compared to its neighboring training points according to the distance that separates them in the representations. We show the labels of these neighboring points afford confidence estimates for inputs outside the model's training manifold, including on malicious inputs like adversarial examples--and therein provides protections against inputs that are outside the models understanding. This is because the nearest neighbors can be used to estimate the nonconformity of, i.e., the lack of support for, a prediction in the training data. The neighbors also constitute human-interpretable explanations of predictions. We evaluate the DkNN algorithm on several datasets, and show the confidence estimates accurately identify inputs outside the model, and that the explanations provided by nearest neighbors are intuitive and useful in understanding model failures.},
	urldate = {2020-06-18},
	journal = {arXiv:1803.04765 [cs, stat]},
	author = {Papernot, Nicolas and McDaniel, Patrick},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.04765},
	keywords = {explainable, fatml, knn, xai},
}

@article{APPROXIMATINGCNNSBAGOFLOCALFEATURES,
	title = {{APPROXIMATING} {CNNS} {WITH} {BAG}-{OF}-{LOCAL}- {FEATURES} {MODELS} {WORKS} {SURPRISINGLY} {WELL} {ON} {IMAGENET}},
	abstract = {Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difﬁcult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet50 architecture called BagNet, classiﬁes an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6\% top-5 for 33 × 33 px features and Alexnet performance for 17 × 17 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image inﬂuences the classiﬁcation. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classiﬁers in the last few years is mostly achieved by better ﬁne-tuning rather than by qualitatively different decision strategies.},
	language = {en},
	author = {Brendel, Wieland and Bethge, Matthias},
	year = {2019},
	keywords = {elir, explainable, fatml, xai},
	pages = {15},
}

@article{PipelineProfilerVisualAnalyticsTool,
	title = {{PipelineProfiler}: {A} {Visual} {Analytics} {Tool} for the {Exploration} of {AutoML} {Pipelines}},
	shorttitle = {{PipelineProfiler}},
	url = {http://arxiv.org/abs/2005.00160},
	abstract = {In recent years, a wide variety of automated machine learning (AutoML) methods have been proposed to search and generate end-to-end learning pipelines. While these techniques facilitate the creation of models for real-world applications, given their black-box nature, the complexity of the underlying algorithms, and the large number of pipelines they derive, it is difficult for their developers to debug these systems. It is also challenging for machine learning experts to select an AutoML system that is well suited for a given problem or class of problems. In this paper, we present the PipelineProfiler, an interactive visualization tool that allows the exploration and comparison of the solution space of machine learning (ML) pipelines produced by AutoML systems. PipelineProfiler is integrated with Jupyter Notebook and can be used together with common data science tools to enable a rich set of analyses of the ML pipelines and provide insights about the algorithms that generated them. We demonstrate the utility of our tool through several use cases where PipelineProfiler is used to better understand and improve a real-world AutoML system. Furthermore, we validate our approach by presenting a detailed analysis of a think-aloud experiment with six data scientists who develop and evaluate AutoML tools.},
	language = {en},
	urldate = {2020-06-17},
	journal = {arXiv:2005.00160 [cs]},
	author = {Ono, Jorge Piazentin and Castelo, Sonia and Lopez, Roque and Bertini, Enrico and Freire, Juliana and Silva, Claudio},
	month = apr,
	year = {2020},
	note = {arXiv: 2005.00160},
	keywords = {automl, vis},
}

@article{LearningInterpretableShapeletsTime,
	title = {Learning {Interpretable} {Shapelets} for {Time} {Series} {Classification} through {Adversarial} {Regularization}},
	url = {http://arxiv.org/abs/1906.00917},
	abstract = {Times series classification can be successfully tackled by jointly learning a shapelet-based representation of the series in the dataset and classifying the series according to this representation. However, although the learned shapelets are discriminative, they are not always similar to pieces of a real series in the dataset. This makes it difficult to interpret the decision, i.e. difficult to analyze if there are particular behaviors in a series that triggered the decision. In this paper, we make use of a simple convolutional network to tackle the time series classification task and we introduce an adversarial regularization to constrain the model to learn more interpretable shapelets. Our classification results on all the usual time series benchmarks are comparable with the results obtained by similar state-of-the-art algorithms but our adversarially regularized method learns shapelets that are, by design, interpretable.},
	urldate = {2020-06-17},
	journal = {arXiv:1906.00917 [cs, stat]},
	author = {Wang, Yichang and Emonet, Rémi and Fromont, Elisa and Malinowski, Simon and Menager, Etienne and Mosser, Loïc and Tavenard, Romain},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.00917},
	keywords = {classification, dm, ts},
}

@article{LocallyGloballyExplainableTime,
	title = {Locally and globally explainable time series tweaking},
	volume = {62},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-019-01389-4},
	doi = {10.1007/s10115-019-01389-4},
	abstract = {Time series classiﬁcation has received great attention over the past decade with a wide range of methods focusing on predictive performance by exploiting various types of temporal features. Nonetheless, little emphasis has been placed on interpretability and explainability. In this paper, we formulate the novel problem of explainable time series tweaking, where, given a time series and an opaque classiﬁer that provides a particular classiﬁcation decision for the time series, we want to ﬁnd the changes to be performed to the given time series so that the classiﬁer changes its decision to another class. We show that the problem is NP-hard, and focus on three instantiations of the problem using global and local transformations. In the former case, we investigate the k-nearest neighbor classiﬁer and provide an algorithmic solution to the global time series tweaking problem. In the latter case, we investigate the random shapelet forest classiﬁer and focus on two instantiations of the local time series tweaking problem, which we refer to as reversible and irreversible time series tweaking, and propose two algorithmic solutions for the two problems along with simple optimizations. An extensive experimental evaluation on a variety of real datasets demonstrates the usefulness and effectiveness of our problem formulation and solutions.},
	language = {en},
	number = {5},
	urldate = {2020-06-16},
	journal = {Knowledge and Information Systems},
	author = {Karlsson, Isak and Rebane, Jonathan and Papapetrou, Panagiotis and Gionis, Aristides},
	month = may,
	year = {2020},
	keywords = {explainable, ts},
	pages = {1671--1700},
}

@article{SurveyMethodsExplainingBlack,
	title = {A {Survey} of {Methods} for {Explaining} {Black} {Box} {Models}},
	volume = {51},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3236009},
	doi = {10.1145/3236009},
	language = {en},
	number = {5},
	urldate = {2020-06-16},
	journal = {ACM Computing Surveys},
	author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
	month = jan,
	year = {2019},
	keywords = {explainable, fatml, survey, xai},
	pages = {1--42},
}

@article{PushItLimitDiscover,
	title = {Push it to the {Limit}: {Discover} {Edge}-{Cases} in {Image} {Data} with {Autoencoders}},
	shorttitle = {Push it to the {Limit}},
	url = {http://arxiv.org/abs/1910.02713},
	abstract = {In this paper, we focus on the problem of identifying semantic factors of variation in large image datasets. By training a convolutional Autoencoder on the image data, we create encodings, which describe each datapoint at a higher level of abstraction than pixel-space. We then apply Principal Component Analysis to the encodings to disentangle the factors of variation in the data. Sorting the dataset according to the values of individual principal components, we find that samples at the high and low ends of the distribution often share specific semantic characteristics. We refer to these groups of samples as semantic groups. When applied to real-world data, this method can help discover unwanted edge-cases.},
	urldate = {2020-06-22},
	journal = {arXiv:1910.02713 [cs, eess]},
	author = {Manakov, Ilja and Tresp, Volker},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.02713},
	keywords = {fatml, reliable, xai},
}

@article{KNOWLEDGECONSISTENCYNEURALNET,
	title = {{KNOWLEDGE} {CONSISTENCY} {BETWEEN} {NEURAL} {NET}- {WORKS} {AND} {BEYOND}},
	abstract = {This paper aims to analyze knowledge consistency between pre-trained deep neural networks. We propose a generic deﬁnition for knowledge consistency between neural networks at different fuzziness levels. A task-agnostic method is designed to disentangle feature components, which represent the consistent knowledge, from raw intermediate-layer features of each neural network. As a generic tool, our method can be broadly used for different applications. In preliminary experiments, we have used knowledge consistency as a tool to diagnose representations of neural networks. Knowledge consistency provides new insights to explain the success of existing deep-learning techniques, such as knowledge distillation and network compression. More crucially, knowledge consistency can also be used to reﬁne pre-trained networks and boost performance.},
	language = {en},
	author = {Liang, Ruofan and Li, Tianlin and Li, Longfei and Wang, Jing and Zhang, Quanshi},
	year = {2020},
	keywords = {cnn, fatml, interpretable, xai},
	pages = {15},
}

@article{InvestigatingHumanMachineComplementarity,
	title = {Investigating {Human} + {Machine} {Complementarity} for {Recidivism} {Predictions}},
	url = {http://arxiv.org/abs/1808.09123},
	abstract = {When might human input help (or not) when assessing risk in fairness domains? Dressel and Farid (2018) asked Mechanical Turk workers to evaluate a subset of defendants in the ProPublica COMPAS data for risk of recidivism, and concluded that COMPAS predictions were no more accurate or fair than predictions made by humans. We delve deeper into this claim to explore differences in human and algorithmic decision making. We construct a Human Risk Score based on the predictions made by multiple Turk workers, characterize the features that determine agreement and disagreement between COMPAS and Human Scores, and construct hybrid Human+Machine models to predict recidivism. Our key finding is that on this data set, Human and COMPAS decision making differed, but not in ways that could be leveraged to significantly improve ground-truth prediction. We present the results of our analyses and suggestions for data collection best practices to leverage complementary strengths of human and machines in the fairness domain.},
	urldate = {2020-06-22},
	journal = {arXiv:1808.09123 [cs, stat]},
	author = {Tan, Sarah and Adebayo, Julius and Inkpen, Kori and Kamar, Ece},
	month = dec,
	year = {2018},
	note = {arXiv: 1808.09123},
	keywords = {fatml, hil, iml, xai},
}

@inproceedings{InterpretingCNNsDecisionTreesa,
	address = {Long Beach, CA, USA},
	title = {Interpreting {CNNs} via {Decision} {Trees}},
	isbn = {978-1-72813-293-8},
	url = {https://ieeexplore.ieee.org/document/8953917/},
	doi = {10.1109/CVPR.2019.00642},
	abstract = {This paper1 aims to quantitatively explain the rationales of each prediction that is made by a pre-trained convolutional neural network (CNN). We propose to learn a decision tree, which clariﬁes the speciﬁc reason for each prediction made by the CNN at the semantic level. I.e. the decision tree decomposes feature representations in high conv-layers of the CNN into elementary concepts of object parts. In this way, the decision tree tells people which object parts activate which ﬁlters for the prediction and how much each object part contributes to the prediction score. Such semantic and quantitative explanations for CNN predictions have speciﬁc values beyond the traditional pixel-level analysis of CNNs. More speciﬁcally, our method mines all potential decision modes of the CNN, where each mode represents a typical case of how the CNN uses object parts for prediction. The decision tree organizes all potential decision modes in a coarse-to-ﬁne manner to explain CNN predictions at different ﬁne-grained levels. Experiments have demonstrated the effectiveness of the proposed method.},
	language = {en},
	urldate = {2020-06-22},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Zhang, Quanshi and Yang, Yu and Ma, Haotian and Wu, Ying Nian},
	month = jun,
	year = {2019},
	keywords = {cnn, explainable, fatml, image, xai},
	pages = {6254--6263},
}

@inproceedings{CrowdsourcingBasedHumanintheLoopFrameworka,
	title = {A {Crowdsourcing} {Based} {Human}-in-the-{Loop} {Framework} for {Denoising} {UUs} in {Relation} {Extraction} {Tasks}},
	doi = {10.1109/IJCNN.2019.8851951},
	abstract = {In relation extraction tasks, distant supervision methods expand dataset by aligning entity pairs in different knowledge bases and completing the relations between two entities. However, these methods ignore the fact that sentences labels generated by distant supervision methods with high confidence are often incorrect in the real world called Unknown Unknowns (UUs). To deal with this challenge, we propose a crowdsourcing based human-in-the-loop denoising framework which iteratively discovers UUs and corrects them by crowdsourcing to better extract relations. During each epoch of iterations, we choose one sentence bag and repeat two steps: Firstly, attention based Long Short-Term Memory network is applied as a selector to discover potential UUs. Secondly, these UUs are annotated by crowdsourcing with two answer collecting strategies and fed back into selector as positive samples. Until the accuracy of selector reaches a threshold, all annotated samples are added into relation classifier as cleaned train set and framework moves on to next epoch with new sentence bags. The experiments on the New York Times dataset and analysis of potential UUs demonstrate that our framework denoise the dataset and outperforms all the baselines on distant supervision relation extraction tasks.},
	booktitle = {2019 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Li, Mengting and Jin, Jian and Wu, Wen and Yang, Yan and He, Liang and Yang, Jing},
	month = jul,
	year = {2019},
	note = {ISSN: 2161-4407},
	keywords = {fatml, hil, xai},
	pages = {1--8},
}

@article{InteractiveMachineLearningApplications,
	title = {Interactive {Machine} {Learning} with {Applications} in {Health} {Informatics}},
	language = {en},
	author = {Wang, Yue},
	keywords = {dissertation, hil},
	pages = {145},
}

@article{ExplainingPredictionsAnyImage,
	title = {Explaining the {Predictions} of {Any} {Image} {Classifier} via {Decision} {Trees}},
	url = {http://arxiv.org/abs/1911.01058},
	abstract = {Despite outstanding contribution to the significant progress of Artificial Intelligence (AI), deep learning models remain mostly black boxes, which are extremely weak in explainability of the reasoning process and prediction results. Explainability is not only a gateway between AI and society but also a powerful tool to detect flaws in the model and biases in the data. Local Interpretable Model-agnostic Explanation (LIME) is a recent approach that uses an interpretable model to form a local explanation for the individual prediction result. The current implementation of LIME adopts the linear regression as its interpretable function. However, being so restricted and usually over-simplifying the relationships, linear models fail in situations where nonlinear associations and interactions exist among features and prediction results. This paper implements a decision Tree-based LIME approach, which uses a decision tree model to form an interpretable representation that is locally faithful to the original model. Tree-LIME approach can capture nonlinear interactions among features in the data and creates plausible explanations. Various experiments show that the Tree-LIME explanation of multiple black-box models can achieve more reliable performance in terms of understandability, fidelity, and efficiency.},
	urldate = {2020-06-22},
	journal = {arXiv:1911.01058 [cs, stat]},
	author = {Shi, Sheng and Zhang, Xinfeng and Fan, Wei},
	month = feb,
	year = {2020},
	note = {arXiv: 1911.01058},
	keywords = {explainable, fatml, image, xai},
}

@article{InterpretableLatentSpacesLearning,
	title = {Interpretable {Latent} {Spaces} for {Learning} from {Demonstration}},
	url = {http://arxiv.org/abs/1807.06583},
	abstract = {Effective human-robot interaction, such as in robot learning from human demonstration, requires the learning agent to be able to ground abstract concepts (such as those contained within instructions) in a corresponding high-dimensional sensory input stream from the world. Models such as deep neural networks, with high capacity through their large parameter spaces, can be used to compress the high-dimensional sensory data to lower dimensional representations. These low-dimensional representations facilitate symbol grounding, but may not guarantee that the representation would be human-interpretable. We propose a method which utilises the grouping of user-defined symbols and their corresponding sensory observations in order to align the learnt compressed latent representation with the semantic notions contained in the abstract labels. We demonstrate this through experiments with both simulated and real-world object data, showing that such alignment can be achieved in a process of physical symbol grounding.},
	urldate = {2020-06-22},
	journal = {arXiv:1807.06583 [cs]},
	author = {Hristov, Yordan and Lascarides, Alex and Ramamoorthy, Subramanian},
	month = oct,
	year = {2018},
	note = {arXiv: 1807.06583},
	keywords = {fatml, interpretable, unsupervised, xai},
}

@incollection{ConfusionsTimeInterpretableBayesian,
	title = {Confusions over {Time}: {An} {Interpretable} {Bayesian} {Model} to {Characterize} {Trends} in {Decision} {Making}},
	shorttitle = {Confusions over {Time}},
	url = {http://papers.nips.cc/paper/6234-confusions-over-time-an-interpretable-bayesian-model-to-characterize-trends-in-decision-making.pdf},
	urldate = {2020-06-22},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 29},
	publisher = {Curran Associates, Inc.},
	author = {Lakkaraju, Himabindu and Leskovec, Jure},
	editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	year = {2016},
	keywords = {fatml, reliable, xai},
	pages = {3261--3269},
}

@article{IdentifyingUnknownUnknownsOpen,
	title = {Identifying {Unknown} {Unknowns} in the {Open} {World}: {Representations} and {Policies} for {Guided} {Exploration}},
	abstract = {Predictive models deployed in the real world may assign incorrect labels to instances with high conﬁdence. Such errors or unknown unknowns are rooted in model incompleteness, and typically arise because of the mismatch between training data and the cases encountered at test time. As the models are blind to such errors, input from an oracle is needed to identify these failures. In this paper, we formulate and address the problem of informed discovery of unknown unknowns of any given predictive model where unknown unknowns occur due to systematic biases in the training data. We propose a modelagnostic methodology which uses feedback from an oracle to both identify unknown unknowns and to intelligently guide the discovery. We employ a two-phase approach which ﬁrst organizes the data into multiple partitions based on the feature similarity of instances and the conﬁdence scores assigned by the predictive model, and then utilizes an explore-exploit strategy for discovering unknown unknowns across these partitions. We demonstrate the efﬁcacy of our framework by varying the underlying causes of unknown unknowns across various applications. To the best of our knowledge, this paper presents the ﬁrst algorithmic approach to the problem of discovering unknown unknowns of predictive models.},
	language = {en},
	author = {Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Horvitz, Eric},
	keywords = {rw-uu-uu, uu},
	pages = {9},
}

@article{DGLKETrainingKnowledgeGraph,
	title = {{DGL}-{KE}: {Training} {Knowledge} {Graph} {Embeddings} at {Scale}},
	shorttitle = {{DGL}-{KE}},
	url = {http://arxiv.org/abs/2004.08532},
	abstract = {Knowledge graphs have emerged as a key abstraction for organizing information in diverse domains and their embeddings are increasingly used to harness their information in various information retrieval and machine learning tasks. However, the ever growing size of knowledge graphs requires computationally efficient algorithms capable of scaling to graphs with millions of nodes and billions of edges. This paper presents DGL-KE, an open-source package to efficiently compute knowledge graph embeddings. DGL-KE introduces various novel optimizations that accelerate training on knowledge graphs with millions of nodes and billions of edges using multi-processing, multi-GPU, and distributed parallelism. These optimizations are designed to increase data locality, reduce communication overhead, overlap computations with memory accesses, and achieve high operation efficiency. Experiments on knowledge graphs consisting of over 86M nodes and 338M edges show that DGL-KE can compute embeddings in 100 minutes on an EC2 instance with 8 GPUs and 30 minutes on an EC2 cluster with 4 machines with 48 cores/machine. These results represent a 2x{\textasciitilde}5x speedup over the best competing approaches. DGL-KE is available on https://github.com/awslabs/dgl-ke.},
	urldate = {2020-06-19},
	journal = {arXiv:2004.08532 [cs]},
	author = {Zheng, Da and Song, Xiang and Ma, Chao and Tan, Zeyuan and Ye, Zihao and Dong, Jin and Xiong, Hao and Zhang, Zheng and Karypis, George},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.08532},
	keywords = {kg},
}

@article{VisualAnalyticsModelSelection,
	title = {Visual {Analytics} for {Model} {Selection} in {Time} {Series} {Analysis}},
	volume = {19},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2013.222},
	abstract = {Model selection in time series analysis is a challenging task for domain experts in many application areas such as epidemiology, economy, or environmental sciences. The methodology used for this task demands a close combination of human judgement and automated computation. However, statistical software tools do not adequately support this combination through interactive visual interfaces. We propose a Visual Analytics process to guide domain experts in this task. For this purpose, we developed the TiMoVA prototype that implements this process based on user stories and iterative expert feedback on user experience. The prototype was evaluated by usage scenarios with an example dataset from epidemiology and interviews with two external domain experts in statistics. The insights from the experts' feedback and the usage scenarios show that TiMoVA is able to support domain experts in model selection tasks through interactive visual interfaces with short feedback cycles.},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Bögl, Markus and Aigner, Wolfgang and Filzmoser, Peter and Lammarsch, Tim and Miksch, Silvia and Rind, Alexander},
	month = dec,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {ts, vis},
	pages = {2237--2246},
}

@article{VisualInteractivePreprocessingMultivariateTime,
	title = {Visual-{Interactive} {Preprocessing} of {Multivariate} {Time} {Series} {Data}},
	volume = {38},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13698},
	doi = {10.1111/cgf.13698},
	abstract = {Pre-processing is a prerequisite to conduct effective and efficient downstream data analysis. Pre-processing pipelines often require multiple routines to address data quality challenges and to bring the data into a usable form. For both the construction and the refinement of pre-processing pipelines, human-in-the-loop approaches are highly beneficial. This particularly applies to multivariate time series, a complex data type with multiple values developing over time. Due to the high specificity of this domain, it has not been subject to in-depth research in visual analytics. We present a visual-interactive approach for preprocessing multivariate time series data with the following aspects. Our approach supports analysts to carry out six core analysis tasks related to pre-processing of multivariate time series. To support these tasks, we identify requirements to baseline toolkits that may help practitioners in their choice. We characterize the space of visualization designs for uncertainty-aware pre-processing and justify our decisions. Two usage scenarios demonstrate applicability of our approach, design choices, and uncertainty visualizations for the six analysis tasks. This work is one step towards strengthening the visual analytics support for data pre-processing in general and for uncertainty-aware pre-processing of multivariate time series in particular.},
	language = {en},
	number = {3},
	urldate = {2020-07-05},
	journal = {Computer Graphics Forum},
	author = {Bernard, Jürgen and Hutter, Marco and Reinemuth, Heiko and Pfeifer, Hendrik and Bors, Christian and Kohlhammer, Jörn},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13698},
	keywords = {ts, vis},
	pages = {401--412},
}

@article{TimeBenchDataModelSoftware,
	title = {{TimeBench}: {A} {Data} {Model} and {Software} {Library} for {Visual} {Analytics} of {Time}-{Oriented} {Data}},
	volume = {19},
	issn = {1941-0506},
	shorttitle = {{TimeBench}},
	doi = {10.1109/TVCG.2013.206},
	abstract = {Time-oriented data play an essential role in many Visual Analytics scenarios such as extracting medical insights from collections of electronic health records or identifying emerging problems and vulnerabilities in network traffic. However, many software libraries for Visual Analytics treat time as a flat numerical data type and insufficiently tackle the complexity of the time domain such as calendar granularities and intervals. Therefore, developers of advanced Visual Analytics designs need to implement temporal foundations in their application code over and over again. We present TimeBench, a software library that provides foundational data structures and algorithms for time-oriented data in Visual Analytics. Its expressiveness and developer accessibility have been evaluated through application examples demonstrating a variety of challenges with time-oriented data and long-term developer studies conducted in the scope of research and student projects.},
	number = {12},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Rind, Alexander and Lammarsch, Tim and Aigner, Wolfgang and Alsallakh, Bilal and Miksch, Silvia},
	month = dec,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	pages = {2247--2256},
}

@article{LaplacianEigenmapsDimensionalityReduction,
	title = {Laplacian {Eigenmaps} for {Dimensionality} {Reduction} and {Data} {Representation}},
	volume = {15},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/089976603321780317},
	doi = {10.1162/089976603321780317},
	abstract = {One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low dimensional manifold embedded in a high dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high dimensional data. The algorithm provides a computationally e cient approach to non-linear dimensionality reduction that has locality preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.},
	language = {en},
	number = {6},
	urldate = {2020-07-04},
	journal = {Neural Computation},
	author = {Belkin, Mikhail and Niyogi, Partha},
	month = jun,
	year = {2003},
	pages = {1373--1396},
}

@article{ClusteringBasedContrastiveLearning,
	title = {Clustering based {Contrastive} {Learning} for {Improving} {Face} {Representations}},
	url = {http://arxiv.org/abs/2004.02195},
	abstract = {A good clustering algorithm can discover natural groupings in data. These groupings, if used wisely, provide a form of weak supervision for learning representations. In this work, we present Clustering-based Contrastive Learning (CCL), a new clustering-based representation learning approach that uses labels obtained from clustering along with video constraints to learn discriminative face features. We demonstrate our method on the challenging task of learning representations for video face clustering. Through several ablation studies, we analyze the impact of creating pair-wise positive and negative labels from different sources. Experiments on three challenging video face clustering datasets: BBT-0101, BF-0502, and ACCIO show that CCL achieves a new state-of-the-art on all datasets.},
	urldate = {2020-06-26},
	journal = {arXiv:2004.02195 [cs]},
	author = {Sharma, Vivek and Tapaswi, Makarand and Sarfraz, M. Saquib and Stiefelhagen, Rainer},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.02195},
	keywords = {clustering, weakly-supervised},
}

@incollection{DynamicsGroupRiskPerception,
	address = {Cham},
	title = {The {Dynamics} of {Group} {Risk} {Perception} in the {US} {After} {Paris} {Attacks}},
	volume = {10046},
	isbn = {978-3-319-47879-1 978-3-319-47880-7},
	url = {http://link.springer.com/10.1007/978-3-319-47880-7_11},
	abstract = {This paper examines how the public perceived immigrant groups as potential risk, and how such risk perception changed after the attacks that took place in Paris on November 13, 2015. The study utilizes the Twitter conversations associated with di↵erent political leanings in the U.S., and mixed methods approach that integrated both quantitative and qualitative analyses. Risk perception proﬁles of Muslim, Islam, Latino, and immigrant were quantitatively constructed, based on how these groups/issues were morally judged as risk. Discourse analysis on how risk narratives constructed before and after the event was conducted. The study reveals that the groups/issues di↵ered by how they were perceived as a risk or at risk across political leanings, and how the risk perception was related to in- and out-group biases. The study has important implication on how di↵erent communities conceptualize, perceive, and respond to danger, especially in the context of terrorism.},
	language = {en},
	urldate = {2020-06-25},
	booktitle = {Social {Informatics}},
	publisher = {Springer International Publishing},
	author = {Chung, Wen-Ting and Wei, Kai and Lin, Yu-Ru and Wen, Xidao},
	editor = {Spiro, Emma and Ahn, Yong-Yeol},
	year = {2016},
	doi = {10.1007/978-3-319-47880-7_11},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {168--184},
}

@inproceedings{ProbingConstructValidityDataDriven,
	address = {Pittsburgh, PA, USA},
	title = {Probing {Construct} {Validity} in {Data}-{Driven} {Disaster} {Analysis}},
	isbn = {978-1-5090-4607-2},
	url = {http://ieeexplore.ieee.org/document/7809747/},
	doi = {10.1109/CIC.2016.076},
	abstract = {In this position paper, we discuss the promise and peril in data-driven disaster analysis. We argue for the importance of being sensitive to the construct validity issue prevailed in many big data studies and propose a research strategy as a remedy for such issue. Our strategy comprises three steps: theory-driven set-up ﬁrst, statistic assessment follows, and qualitative inquiry for further calibration. The goal is to translate activity signals captured from data to proper social or behavioral interpretation. We exemplify the use of the proposed research strategy through a study of risk perception following a disaster event, and discuss the strategy’s potential and limitation.},
	language = {en},
	urldate = {2020-06-25},
	booktitle = {2016 {IEEE} 2nd {International} {Conference} on {Collaboration} and {Internet} {Computing} ({CIC})},
	publisher = {IEEE},
	author = {Chung, Wen-Ting and Lin, Yu-Ru},
	month = nov,
	year = {2016},
	pages = {500--501},
}

@incollection{MarchFeetTalkingProtests,
	address = {Cham},
	title = {March with and {Without} {Feet}: {The} {Talking} {About} {Protests} and {Beyond}},
	volume = {11185},
	isbn = {978-3-030-01128-4 978-3-030-01129-1},
	shorttitle = {March with and {Without} {Feet}},
	url = {http://link.springer.com/10.1007/978-3-030-01129-1_9},
	abstract = {By what means do social media contribute to social movements? This question has been studied for decades, but rarely from the collective sense-making perspective. When a particular crying out for social change is taking place, people nowadays begin to talk on social media platforms. We examined the focuses of people’s talking in a protesting context where multiple protesting tactics were involved including both online and oﬄine activism. By analyzing Twitter messages during Ferguson unrest in August 2014, we revealed two distinct types of online conversations: one discusses oﬄine protests concerning more immediate happenings; the other goes beyond involving meaning-making to diagnose and digest the disorienting thoughts and feelings. To characterize the discussions, we developed two coding schemes, ﬁrst to diﬀerentiate the discussion of oﬄine protests from others, and second to diﬀerentiate ways of meaning-making. This study is the ﬁrst attempt to identify the challenges of diﬀerentiating tweets consisting of street protest information, and the developed coding scheme, together with machine classiﬁcation, can be applied to identifying tweets consisting of street protest information. We observed that while mainstream media often focused on what happened on street, during Ferguson protests, only one out of every 4.5 tweets focused on oﬄine activities. Our study oﬀers evidence for considering social media’s signiﬁcance from an alternative perspective –the media are not simply the witness or facilitator of oﬄine protests, but leave traces that aﬀord to study collective mind activities and changes such as meaning contesting and perspective shifting that are essential for social change.},
	language = {en},
	urldate = {2020-06-25},
	booktitle = {Social {Informatics}},
	publisher = {Springer International Publishing},
	author = {Chung, Wen-Ting and Lin, Yu-Ru and Li, Ang and Ertugrul, Ali Mert and Yan, Muheng},
	editor = {Staab, Steffen and Koltsova, Olessia and Ignatov, Dmitry I.},
	year = {2018},
	doi = {10.1007/978-3-030-01129-1_9},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {134--150},
}

@article{AdversarialUnsupervisedRepresentationLearning,
	title = {Adversarial {Unsupervised} {Representation} {Learning} for {Activity} {Time}-{Series}},
	url = {http://arxiv.org/abs/1811.06847},
	abstract = {Sufficient physical activity and restful sleep play a major role in the prevention and cure of many chronic conditions. Being able to proactively screen and monitor such chronic conditions would be a big step forward for overall health. The rapid increase in the popularity of wearable devices provides a significant new source, making it possible to track the user's lifestyle real-time. In this paper, we propose a novel unsupervised representation learning technique called activity2vec that learns and "summarizes" the discrete-valued activity time-series. It learns the representations with three components: (i) the co-occurrence and magnitude of the activity levels in a time-segment, (ii) neighboring context of the time-segment, and (iii) promoting subject-invariance with adversarial training. We evaluate our method on four disorder prediction tasks using linear classifiers. Empirical evaluation demonstrates that our proposed method scales and performs better than many strong baselines. The adversarial regime helps improve the generalizability of our representations by promoting subject invariant features. We also show that using the representations at the level of a day works the best since human activity is structured in terms of daily routines},
	urldate = {2020-06-25},
	journal = {arXiv:1811.06847 [cs, stat]},
	author = {Aggarwal, Karan and Joty, Shafiq and Fernandez-Luque, Luis and Srivastava, Jaideep},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.06847},
	keywords = {segment, subseq, ts, unsupervised},
}

@article{MultidimensionalProjectionVisualAnalytics,
	title = {Multidimensional {Projection} for {Visual} {Analytics}: {Linking} {Techniques} with {Distortions}, {Tasks}, and {Layout} {Enrichment}},
	volume = {25},
	issn = {1941-0506},
	shorttitle = {Multidimensional {Projection} for {Visual} {Analytics}},
	doi = {10.1109/TVCG.2018.2846735},
	abstract = {Visual analysis of multidimensional data requires expressive and effective ways to reduce data dimensionality to encode them visually. Multidimensional projections (MDP) figure among the most important visualization techniques in this context, transforming multidimensional data into scatter plots whose visual patterns reflect some notion of similarity in the original data. However, MDP come with distortions that make these visual patterns not trustworthy, hindering users to infer actual data characteristics. Moreover, the patterns present in the scatter plots might not be enough to allow a clear understanding of multidimensional data, motivating the development of layout enrichment methodologies to operate together with MDP. This survey attempts to cover the main aspects of MDP as a visualization and visual analytic tool. It provides detailed analysis and taxonomies as to the organization of MDP techniques according to their main properties and traits, discussing the impact of such properties for visual perception and other human factors. The survey also approaches the different types of distortions that can result from MDP mappings and it overviews existing mechanisms to quantitatively evaluate such distortions. A qualitative analysis of the impact of distortions on the different analytic tasks performed by users when exploring multidimensional data through MDP is also presented. Guidelines for choosing the best MDP for an intended task are also provided as a result of this analysis. Finally, layout enrichment schemes to debunk MDP distortions and/or reveal relevant information not directly inferable from the scatter plot are reviewed and discussed in the light of new taxonomies. We conclude the survey providing future research axes to fill discovered gaps in this domain.},
	number = {8},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Nonato, Luis Gustavo and Aupetit, Michaël},
	month = aug,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {comps-iui, dim-reduction, survey, vis},
	pages = {2650--2673},
}

@article{AblateVariateContemplateVisual,
	title = {Ablate, {Variate}, and {Contemplate}: {Visual} {Analytics} for {Discovering} {Neural} {Architectures}},
	shorttitle = {Ablate, {Variate}, and {Contemplate}},
	url = {http://arxiv.org/abs/1908.00387},
	abstract = {Deep learning models require the configuration of many layers and parameters in order to get good results. However, there are currently few systematic guidelines for how to configure a successful model. This means model builders often have to experiment with different configurations by manually programming different architectures (which is tedious and time consuming) or rely on purely automated approaches to generate and train the architectures (which is expensive). In this paper, we present Rapid Exploration of Model Architectures and Parameters, or REMAP, a visual analytics tool that allows a model builder to discover a deep learning model quickly via exploration and rapid experimentation of neural network architectures. In REMAP, the user explores the large and complex parameter space for neural network architectures using a combination of global inspection and local experimentation. Through a visual overview of a set of models, the user identifies interesting clusters of architectures. Based on their findings, the user can run ablation and variation experiments to identify the effects of adding, removing, or replacing layers in a given architecture and generate new models accordingly. They can also handcraft new models using a simple graphical interface. As a result, a model builder can build deep learning models quickly, efficiently, and without manual programming. We inform the design of REMAP through a design study with four deep learning model builders. Through a use case, we demonstrate that REMAP allows users to discover performant neural network architectures efficiently using visual exploration and user-defined semi-automated searches through the model space.},
	urldate = {2020-06-24},
	journal = {arXiv:1908.00387 [cs]},
	author = {Cashman, Dylan and Perer, Adam and Chang, Remco and Strobelt, Hendrik},
	month = jul,
	year = {2019},
	note = {arXiv: 1908.00387},
	keywords = {automl, dl, rw-uu-vis-ml, vis},
}

@article{ExploratoryMachineLearningUnknown,
	title = {Exploratory {Machine} {Learning} with {Unknown} {Unknowns}},
	url = {http://arxiv.org/abs/2002.01605},
	abstract = {In conventional supervised learning, a training dataset is given with ground-truth labels from a known label set, and the learned model will classify unseen instances to the known labels. In this paper, we study a new problem setting in which there are unknown classes in the training dataset misperceived as other labels, and thus their existence appears unknown from the given supervision. We attribute the unknown unknowns to the fact that the training dataset is badly advised by the incompletely perceived label space due to the insufficient feature information. To this end, we propose the exploratory machine learning, which examines and investigates the training dataset by actively augmenting the feature space to discover potentially unknown labels. Our approach consists of three ingredients including rejection model, feature acquisition, and model cascade. The effectiveness is validated on both synthetic and real datasets.},
	urldate = {2020-06-22},
	journal = {arXiv:2002.01605 [cs, stat]},
	author = {Zhang, Yu-Jie and Zhao, Peng and Zhou, Zhi-Hua},
	month = feb,
	year = {2020},
	note = {arXiv: 2002.01605},
	keywords = {hil, reliable, rw-uu-uu, uu},
}

@book{ArgumentEvaluationEvidence,
	address = {Cham},
	series = {Law, {Governance} and {Technology} {Series}},
	title = {Argument {Evaluation} and {Evidence}},
	volume = {23},
	isbn = {978-3-319-19625-1 978-3-319-19626-8},
	url = {http://link.springer.com/10.1007/978-3-319-19626-8},
	language = {en},
	urldate = {2020-07-09},
	publisher = {Springer International Publishing},
	author = {Walton, Douglas},
	year = {2016},
	doi = {10.1007/978-3-319-19626-8},
	keywords = {explanation, fatml, interactive, xai},
}

@article{ExplainableArtificialIntelligenceSystematic,
	title = {Explainable {Artificial} {Intelligence}: a {Systematic} {Review}},
	shorttitle = {Explainable {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/2006.00093},
	abstract = {Explainable Artificial Intelligence (XAI) has experienced a significant growth over the last few years. This is due to the widespread application of machine learning, particularly deep learning, that has led to the development of highly accurate models but lack explainability and interpretability. A plethora of methods to tackle this problem have been proposed, developed and tested. This systematic review contributes to the body of knowledge by clustering these methods with a hierarchical classification system with four main clusters: review articles, theories and notions, methods and their evaluation. It also summarises the state-of-the-art in XAI and recommends future research directions.},
	urldate = {2020-07-08},
	journal = {arXiv:2006.00093 [cs]},
	author = {Vilone, Giulia and Longo, Luca},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.00093},
	keywords = {comps-dm, explanation, fatml, survey, xai},
}

@article{GroundedInteractionProtocolExplainable,
	title = {A {Grounded} {Interaction} {Protocol} for {Explainable} {Artificial} {Intelligence}},
	url = {http://arxiv.org/abs/1903.02409},
	abstract = {Explainable Artificial Intelligence (XAI) systems need to include an explanation model to communicate the internal decisions, behaviours and actions to the interacting humans. Successful explanation involves both cognitive and social processes. In this paper we focus on the challenge of meaningful interaction between an explainer and an explainee and investigate the structural aspects of an interactive explanation to propose an interaction protocol. We follow a bottom-up approach to derive the model by analysing transcripts of different explanation dialogue types with 398 explanation dialogues. We use grounded theory to code and identify key components of an explanation dialogue. We formalize the model using the agent dialogue framework (ADF) as a new dialogue type and then evaluate it in a human-agent interaction study with 101 dialogues from 14 participants. Our results show that the proposed model can closely follow the explanation dialogues of human-agent conversations.},
	urldate = {2020-07-08},
	journal = {arXiv:1903.02409 [cs]},
	author = {Madumal, Prashan and Miller, Tim and Sonenberg, Liz and Vetere, Frank},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.02409},
	keywords = {explanation},
}

@article{ExplainableAgentsSocialCues,
	title = {Explainable {Agents} {Through} {Social} {Cues}: {A} {Review}},
	shorttitle = {Explainable {Agents} {Through} {Social} {Cues}},
	url = {http://arxiv.org/abs/2003.05251},
	abstract = {How to provide explanations has experienced a surge of interest in Human-Robot Interaction (HRI) over the last three years. In HRI this is known as explainability, expressivity, transparency or sometimes legibility, and the challenge for embodied agents is that they offer a unique array of modalities to communicate this information thanks to their embodiment. Responding to this surge of interest, we review the existing literature in explainability and organize it by (1) providing an overview of existing definitions, (2) showing how explainability is implemented and how it exploits different modalities, and (3) showing how the impact of explainability is measured. Additionally, we present a list of open questions and challenges that highlight areas that require further investigation by the community. This provides the interested scholar with an overview of the current state-of-the-art.},
	urldate = {2020-07-08},
	journal = {arXiv:2003.05251 [cs]},
	author = {Wallkotter, Sebastian and Tulli, Silvia and Castellano, Ginevra and Paiva, Ana and Chetouani, Mohamed},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.05251},
	keywords = {explanation, hri},
}

@article{MultilayeredApproachInteractiveBlackbox,
	title = {A {Multi}-layered {Approach} for {Interactive} {Black}-box {Explanations}},
	abstract = {In order to provide interactive explanations, a system must be generic enough to be able to address a wide range of questions from explainees with diﬀerent levels of expertise. In this paper, we present a multi-layered approach allowing explainees to express their needs at diﬀerent levels of abstraction. We describe a proof-of-concept system called IBEX (for “Interactive Black-box Explanations”) implementing this approach and show its application to a variety of case studies.},
	language = {en},
	author = {Henin, Clement and Métayer, Daniel Le},
	pages = {38},
}

@article{VisualAnalysisTimeSeriesSimilarities,
	title = {Visual {Analysis} of {Time}-{Series} {Similarities} for {Anomaly} {Detection} in {Sensor} {Networks}},
	volume = {33},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12396},
	doi = {10.1111/cgf.12396},
	abstract = {We present a system to analyze time-series data in sensor networks. Our approach supports exploratory tasks for the comparison of univariate, geo-referenced sensor data, in particular for anomaly detection. We split the recordings into fixed-length patterns and show them in order to compare them over time and space using two linked views. Apart from geo-based comparison across sensors we also support different temporal patterns to discover seasonal effects, anomalies and periodicities. The methods we use are best practices in the information visualization domain. They cover the daily, the weekly and seasonal and patterns of the data. Daily patterns can be analyzed in a clustering-based view, weekly patterns in a calendar-based view and seasonal patters in a projection-based view. The connectivity of the sensors can be analyzed through a dedicated topological network view. We assist the domain expert with interaction techniques to make the results understandable. As a result, the user can identify and analyze erroneous and suspicious measurements in the network. A case study with a domain expert verified the usefulness of our approach.},
	language = {en},
	number = {3},
	urldate = {2020-07-05},
	journal = {Computer Graphics Forum},
	author = {Steiger, Martin and Bernard, Jürgen and Mittelstädt, Sebastian and Lücke‐Tieke, Hendrik and Keim, Daniel and May, Thorsten and Kohlhammer, Jörn},
	year = {2014},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12396},
	keywords = {ts, vis},
	pages = {401--410},
}

@article{IntegratingPredictionsTimeSeries,
	title = {Integrating {Predictions} in {Time} {Series} {Model} {Selection}},
	issn = {-},
	url = {https://diglib.eg.org/handle/10.2312/eurova.20151107.073-077},
	doi = {10.2312/EUROVA.20151107},
	abstract = {Time series appear in many different domains. The main goal in time series analysis is to ﬁnd a model for given time series. The selection of time series models is done iteratively based, usually, on information criteria and residual plots. These sources may show only small variations and, therefore, it is necessary to consider the prediction capabilities in the model selection process. When applying the model and including the prediction in an interactive visual interface it is still difﬁcult to compare deviations from actual values or benchmark models. Judging which model ﬁts the time series adequately is not well supported in current methods. We propose to combine visual and analytical methods to integrate the prediction capabilities in the model selection process and assist in the decision for an adequate and parsimonious model. In our approach a visual interactive interface is used to select and adjust time series models, utilize the prediction capabilities of models, and compare the prediction of multiple models in relation to the actual values.},
	language = {en},
	urldate = {2020-07-05},
	journal = {EuroVis Workshop on Visual Analytics (EuroVA)},
	author = {Bögl, Markus and Aigner, Wolfgang and Filzmoser, Peter and Gschwandtner, Theresia and Lammarsch, Tim and Miksch, Silvia and Rind, Alexander},
	year = {2015},
	note = {Artwork Size: 5 pages
ISBN: 9783905674866
Publisher: The Eurographics Association},
	keywords = {ts, vis},
	pages = {5 pages},
}

@article{IncrementalDimensionalityReductionMethod,
	title = {An {Incremental} {Dimensionality} {Reduction} {Method} for {Visualizing} {Streaming} {Multidimensional} {Data}},
	volume = {26},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {http://arxiv.org/abs/1905.04000},
	doi = {10.1109/TVCG.2019.2934433},
	abstract = {Dimensionality reduction (DR) methods are commonly used for analyzing and visualizing multidimensional data. However, when data is a live streaming feed, conventional DR methods cannot be directly used because of their computational complexity and inability to preserve the projected data positions at previous time points. In addition, the problem becomes even more challenging when the dynamic data records have a varying number of dimensions as often found in real-world applications. This paper presents an incremental DR solution. We enhance an existing incremental PCA method in several ways to ensure its usability for visualizing streaming multidimensional data. First, we use geometric transformation and animation methods to help preserve a viewer's mental map when visualizing the incremental results. Second, to handle data dimension variants, we use an optimization method to estimate the projected data positions, and also convey the resulting uncertainty in the visualization. We demonstrate the effectiveness of our design with two case studies using real-world datasets.},
	number = {1},
	urldate = {2020-07-05},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Fujiwara, Takanori and Chou, Jia-Kai and Shilpika and Xu, Panpan and Ren, Liu and Ma, Kwan-Liu},
	month = jan,
	year = {2020},
	note = {arXiv: 1905.04000},
	keywords = {dim-reduction, vis},
	pages = {418--428},
}

@inproceedings{DFSeerVisualAnalyticsApproach,
	address = {Honolulu HI USA},
	title = {{DFSeer}: {A} {Visual} {Analytics} {Approach} to {Facilitate} {Model} {Selection} for {Demand} {Forecasting}},
	isbn = {978-1-4503-6708-0},
	shorttitle = {{DFSeer}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376866},
	doi = {10.1145/3313831.3376866},
	abstract = {Selecting an appropriate model to forecast product demand is critical to the manufacturing industry. However, due to the data complexity, market uncertainty and users’ demanding requirements for the model, it is challenging for demand analysts to select a proper model. Although existing model selection methods can reduce the manual burden to some extent, they often fail to present model performance details on individual products and reveal the potential risk of the selected model. This paper presents DFSeer, an interactive visualization system to conduct reliable model selection for demand forecasting based on the products with similar historical demand. It supports model comparison and selection with different levels of details. Besides, it shows the difference in model performance on similar products to reveal the risk of model selection and increase users’ conﬁdence in choosing a forecasting model. Two case studies and interviews with domain experts demonstrate the effectiveness and usability of DFSeer.},
	language = {en},
	urldate = {2020-07-05},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Sun, Dong and Feng, Zezheng and Chen, Yuanzhe and Wang, Yong and Zeng, Jia and Yuan, Mingxuan and Pong, Ting-Chuen and Qu, Huamin},
	month = apr,
	year = {2020},
	keywords = {ts, vis},
	pages = {1--13},
}

@article{VisualInteractiveExplorationRelationsTimeOriented,
	title = {Visual-{Interactive} {Exploration} of {Relations} {Between} {Time}-{Oriented} {Data} and {Multivariate} {Data}},
	issn = {-},
	url = {https://diglib.eg.org/handle/10.2312/eurova20161124},
	doi = {10.2312/EUROVA.20161124},
	abstract = {The analysis of large, multivariate data sets is challenging, especially when some of these data objects are timeoriented. Exploring relationships between multivariate and temporal information, e.g., to identify patterns that support decision making is an important industrial analysis task. The target group of this design study are data analysts aiming at detecting fault patterns in a telecommunications network in order to spend maintenance budget more effectively. We present a visual analytics tool that provides overviews of multivariate data sets and associated time series. Users can select data subsets of interest in both attribute data and clustered time series data. Linked views consequently support the identiﬁcation of relations between the two spaces. To ensure usefulness, the tool was designed in an iterative way, based on a careful characterization of the data, users, and tasks. A usage scenario demonstrates the applicability of the approach.},
	language = {en},
	urldate = {2020-07-05},
	journal = {EuroVis Workshop on Visual Analytics (EuroVA)},
	author = {Bernard, Jürgen and Sessler, David and Steiger, Martin and Spott, Martin and Kohlhammer, Jörn},
	year = {2016},
	note = {Artwork Size: 5 pages
ISBN: 9783038680161
Publisher: The Eurographics Association},
	keywords = {ts, vis},
	pages = {5 pages},
}

@article{VisualAnalysisRelationsAttributed,
	title = {Visual {Analysis} of {Relations} in {Attributed} {Time}-{Series} {Data}},
	issn = {-},
	url = {https://diglib.eg.org/handle/10.2312/eurova.20151105.061-065},
	doi = {10.2312/EUROVA.20151105},
	abstract = {In this paper, we present visual-interactive techniques for revealing relations between two co-existing multivariate feature spaces. Such data is generated, for example, by sensor networks characterized by a set of (categorical) attributes which continuously measure physical quantities over time. A challenging analysis task is the seeking for interesting relations between the time-oriented data and the sensor attributes. Our approach uses visualinteractive analysis to enable analysts to identify correlations between similar time series and similar attributes of the data. It is based on a combination of machine-based encoding of this information in position and color and the human ability to recognize cohesive structures and patterns. In our ﬁgures, we illustrate how analysts can identify similarities and anomalies between time series and categorical attributes of metering devices and sensors.},
	language = {en},
	urldate = {2020-07-05},
	journal = {EuroVis Workshop on Visual Analytics (EuroVA)},
	author = {Steiger, Martin and Bernard, Jürgen and Schader, Philipp and Kohlhammer, Jörn},
	year = {2015},
	note = {Artwork Size: 5 pages
ISBN: 9783905674866
Publisher: The Eurographics Association},
	keywords = {ts, vis},
	pages = {5 pages},
}

@article{ExplainableAgentsRobotsResultsa,
	title = {Explainable {Agents} and {Robots}: {Results} from a {Systematic} {Literature} {Review}},
	abstract = {Humans are increasingly relying on complex systems that heavily adopts Artificial Intelligence (AI) techniques. Such systems are employed in a growing number of domains, and making them explainable is an impelling priority. Recently, the domain of eXplainable Artificial Intelligence (XAI) emerged with the aims of fostering transparency and trustworthiness. Several reviews have been conducted. Nevertheless, most of them deal with data-driven XAI to overcome the opaqueness of black-box algorithms. Contributions addressing goal-driven XAI (e.g., explainable agency for robots and agents) are still missing. This paper aims at filling this gap, proposing a Systematic Literature Review. The main findings are (i) a considerable portion of the papers propose conceptual studies, or lack evaluations or tackle relatively simple scenarios; (ii) almost all of the studied papers deal with robots/agents explaining their behaviors to the human users, and very few works addressed inter-robot (inter-agent) explainability. Finally, (iii) while providing explanations to non-expert users has been outlined as a necessity, only a few works addressed the issues of personalization and context-awareness.},
	language = {en},
	author = {Anjomshoae, Sule and Najjar, Amro and Calvaresi, Davide and Främling, Kary},
	keywords = {explanation, fatml, xai},
	pages = {13},
}

@article{SelfExplainingSocialRobotsVerbal,
	title = {Towards {Self}-{Explaining} {Social} {Robots}: {Verbal} {Explanation} {Strategies} for a {Needs}-{Based} {Architecture}},
	abstract = {In order to establish long-term relationships with users, social companion robots and their behaviors need to be comprehensible. Purely reactive behavior such as answering questions or following commands can be readily interpreted by users. However, the robot’s proactive behaviors, included in order to increase liveliness and improve the user experience, often raise a need for explanation. In this paper, we provide a concept to produce accessible “whyexplanations” for the goal-directed behavior an autonomous, lively robot might produce. To this end we present an architecture that provides reasons for behaviors in terms of comprehensible needs and strategies of the robot, and we propose a model for generating different kinds of explanations.},
	language = {en},
	author = {Stange, Sonja and Buschmeier, Hendrik and Hassan, Teena and Ritter, Christopher and Kopp, Stefan},
	year = {2019},
	keywords = {explanation, xai},
	pages = {6},
}

@inproceedings{PeopleExplanationsRobotBehavior,
	title = {People's {Explanations} of {Robot} {Behavior} {Subtly} {Reveal} {Mental} {State} {Inferences}},
	doi = {10.1109/HRI.2019.8673308},
	abstract = {It has long been assumed that when people observe robots they intuitively ascribe mind and intentionality to them, just as they do to humans. However, much of this evidence relies on experimenter-provided questions or self-reported judgments. We propose a new way of investigating people's mental state ascriptions to robots by carefully studying explanations of robot behavior. Since people's explanations of human behavior are deeply grounded in assumptions of mind and intentional agency, explanations of robot behavior can reveal whether such assumptions similarly apply to robots. We designed stimulus behaviors that were representative of a variety of robots in diverse contexts and ensured that people saw the behaviors as equally intentional, desirable, and surprising across both human and robot agents. We provided 121 participants with verbal descriptions of these behaviors and asked them to explain in their own words why the agent (human or robot) had performed them. To systematically analyze the verbal data, we used a theoretically grounded classification method to identify core explanation types. We found that people use the same conceptual toolbox of behavior explanations for both human and robot agents, robustly indicating inferences of intentionality and mind. But people applied specific explanatory tools at somewhat different rates and in somewhat different ways for robots, revealing specific expectations people hold when explaining robot behaviors.},
	booktitle = {2019 14th {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction} ({HRI})},
	author = {de Graaf, Maartje M.A. and Malle, Bertram F.},
	month = mar,
	year = {2019},
	note = {ISSN: 2167-2148},
	keywords = {explanation, robot, xai},
	pages = {239--248},
}

@article{DECEDecisionExplorerCounterfactual,
	title = {{DECE}: {Decision} {Explorer} with {Counterfactual} {Explanations} for {Machine} {Learning} {Models}},
	shorttitle = {{DECE}},
	url = {http://arxiv.org/abs/2008.08353},
	abstract = {With machine learning models being increasingly applied to various decision-making scenarios, people have spent growing efforts to make machine learning models more transparent and explainable. Among various explanation techniques, counterfactual explanations have the advantages of being human-friendly and actionable -- a counterfactual explanation tells the user how to gain the desired prediction with minimal changes to the input. Besides, counterfactual explanations can also serve as efficient probes to the models' decisions. In this work, we exploit the potential of counterfactual explanations to understand and explore the behavior of machine learning models. We design DECE, an interactive visualization system that helps understand and explore a model's decisions on individual instances and data subsets, supporting users ranging from decision-subjects to model developers. DECE supports exploratory analysis of model decisions by combining the strengths of counterfactual explanations at instance- and subgroup-levels. We also introduce a set of interactions that enable users to customize the generation of counterfactual explanations to find more actionable ones that can suit their needs. Through three use cases and an expert interview, we demonstrate the effectiveness of DECE in supporting decision exploration tasks and instance explanations.},
	urldate = {2020-08-22},
	journal = {arXiv:2008.08353 [cs, stat]},
	author = {Cheng, Furui and Ming, Yao and Qu, Huamin},
	month = aug,
	year = {2020},
	note = {arXiv: 2008.08353},
	keywords = {explanation, rw-uu-vis-ml, vis},
}

@article{InterpretableSuperhumanMachineLearning,
	title = {Interpretable {Superhuman} {Machine} {Learning} {Systems}: {An} explorative study focusing on interpretability and detecting {Unknown} {Knowns} using {GAN}},
	language = {sv},
	author = {Hermansson, Adam and Generalao, Stefan},
	keywords = {rw-uu-uu, uu},
	pages = {35},
}

@article{InteractiveMethodImproveCrowdsourcedb,
	title = {An {Interactive} {Method} to {Improve} {Crowdsourced} {Annotations}},
	volume = {25},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2018.2864843},
	abstract = {In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Shixia and Chen, Changjian and Lu, Yafeng and Ouyang, Fangxin and Wang, Bin},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {uu},
	pages = {235--245},
}

@incollection{BayesianCaseModelGenerative,
	title = {The {Bayesian} {Case} {Model}: {A} {Generative} {Approach} for {Case}-{Based} {Reasoning} and {Prototype} {Classification}},
	shorttitle = {The {Bayesian} {Case} {Model}},
	url = {http://papers.nips.cc/paper/5313-the-bayesian-case-model-a-generative-approach-for-case-based-reasoning-and-prototype-classification.pdf},
	urldate = {2020-07-10},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Kim, Been and Rudin, Cynthia and Shah, Julie A},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	keywords = {clustering},
	pages = {1952--1960},
}

@article{ImprovingInterpretabilityCNNModels,
	title = {Improving {Interpretability} of {CNN} {Models} {Using} {Non}-{Negative} {Concept} {Activation} {Vectors}},
	url = {http://arxiv.org/abs/2006.15417},
	abstract = {Convolutional neural network (CNN) models for computer vision are powerful but lack explainability in their most basic form. This deficiency remains a key challenge when applying CNNs in important domains. Recent work for explanations through feature importance of approximate linear models has moved from input-level features (pixels or segments) to features from mid-layer feature maps in the guise of concept activation vectors (CAVs). CAVs contain concept-level information and could be learnt via Clustering. In this work, we rethink the ACE algorithm of Ghorbani et{\textasciitilde}al., proposing an alternative concept-based explanation framework. Based on the requirements of fidelity (approximate models) and interpretability (being meaningful to people), we design measurements and evaluate a range of dimensionality reduction methods for alignment with our framework. We find that non-negative concept activation vectors from non-negative matrix factorization provide superior performance in interpretability and fidelity based on computational and human subject experiments. Our framework provides both local and global concept-level explanations for pre-trained CNN models.},
	urldate = {2020-07-09},
	journal = {arXiv:2006.15417 [cs]},
	author = {Zhang, Ruihan and Madumal, Prashan and Miller, Tim and Ehinger, Krista A. and Rubinstein, Benjamin I. P.},
	month = jul,
	year = {2020},
	note = {arXiv: 2006.15417},
	keywords = {cav, explanation, fatml, xai},
}

@article{GuidelinesDevelopingExplainableCognitive,
	title = {Guidelines for {Developing} {Explainable} {Cognitive} {Models}},
	abstract = {Cognitive models can be used to generate the behavior of virtual players in simulation-based training systems. To learn from such training, the virtual players must display realistic human behavior, and trainees need to understand why the other players behave the way they do. This understanding can be achieved by explaining the underlying reasons for the virtual players’ behavior. In this paper, it is discussed how to design cognitive models in such a way that they are able to explain the behavior they generate. Three users studies were carried out to assess what type of explanations are useful for training, and how that relates to cognitive model design. Several guidelines for developing explainable cognitive models are proposed.},
	language = {en},
	author = {Harbers, Maaike and Broekens, Joost},
	pages = {6},
}

@article{EffectExplanationStylesUser,
	title = {The {Effect} of {Explanation} {Styles} on {User}’s {Trust}},
	abstract = {This paper investigates the effects that different styles of textual explanation have on explainee’s trust in an AI medical support scenario. From the literature, we focused on four different styles of explanation: contrastive, general, truthful, and thorough. We conducted a user study in which we presented explanations of a fictional mammography diagnosis application system to 48 nonexpert users. We carried out a between-subject comparison between four groups of 11-13 people each looking at a different explanation style. Our findings suggest that contrastive and thorough explanations produce higher personal attachment trust scores compared to general explanation style, while truthful explanation shows no difference compared to the rest of explanations. This means that users who received contrastive and thorough explanation types found the explanation given significantly more agreeable and suiting their personal taste. These findings, even though not conclusive, confirm the impact of explanation style on users trust towards AI systems and may inform future explanation design and evaluation studies.},
	language = {en},
	author = {Larasati, Retno and Liddo, Anna De and Motta, Enrico},
	year = {2020},
	pages = {7},
}

@article{AskingWhyAIExplainability,
	title = {Asking ‘{Why}’ in {AI}: {Explainability} of intelligent systems - perspectives and challenges},
	volume = {25},
	issn = {1055615X},
	shorttitle = {Asking ‘{Why}’ in {AI}},
	url = {http://doi.wiley.com/10.1002/isaf.1422},
	doi = {10.1002/isaf.1422},
	abstract = {Recent rapid progress in machine learning (ML), particularly so-called ‘deep learning,’ has led to a resurgence in interest in explainability of artificial intelligence (AI) systems, reviving an area of research dating back to the 1970s. The aim of this article is to view current issues concerning ML-based AI systems from the perspective of classical AI, showing that the fundamental problems are far from new, and arguing that elements of that earlier work offer routes to making progress towards explainable AI today.},
	language = {en},
	number = {2},
	urldate = {2020-09-27},
	journal = {Intelligent Systems in Accounting, Finance and Management},
	author = {Preece, Alun},
	month = apr,
	year = {2018},
	pages = {63--72},
}

@inproceedings{ExplainableAutonomyStudyExplanation,
	address = {Tilburg University, The Netherlands},
	title = {Explainable {Autonomy}: {A} {Study} of {Explanation} {Styles} for {Building} {Clear} {Mental} {Models}},
	shorttitle = {Explainable {Autonomy}},
	url = {http://aclweb.org/anthology/W18-6511},
	doi = {10.18653/v1/W18-6511},
	abstract = {As unmanned vehicles become more autonomous, it is important to maintain a high level of transparency regarding their behaviour and how they operate. This is particularly important in remote locations where they cannot be directly observed. Here, we describe a method for generating explanations in natural language of autonomous system behaviour and reasoning. Our method involves deriving an interpretable model of autonomy through having an expert ‘speak aloud’ and providing various levels of detail based on this model. Through an online evaluation study with operators, we show it is best to generate explanations with multiple possible reasons but tersely worded. This work has implications for designing interfaces for autonomy as well as for explainable AI and operator training.},
	language = {en},
	urldate = {2020-09-27},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Natural} {Language} {Generation}},
	publisher = {Association for Computational Linguistics},
	author = {Chiyah Garcia, Francisco Javier and Robb, David A. and Liu, Xingkun and Laskov, Atanas and Patron, Pedro and Hastie, Helen},
	year = {2018},
	pages = {99--108},
}

@article{ExplainableAgentsRobotsResults,
	title = {Explainable {Agents} and {Robots}: {Results} from a {Systematic} {Literature} {Review}},
	abstract = {Humans are increasingly relying on complex systems that heavily adopts Artificial Intelligence (AI) techniques. Such systems are employed in a growing number of domains, and making them explainable is an impelling priority. Recently, the domain of eXplainable Artificial Intelligence (XAI) emerged with the aims of fostering transparency and trustworthiness. Several reviews have been conducted. Nevertheless, most of them deal with data-driven XAI to overcome the opaqueness of black-box algorithms. Contributions addressing goal-driven XAI (e.g., explainable agency for robots and agents) are still missing. This paper aims at filling this gap, proposing a Systematic Literature Review. The main findings are (i) a considerable portion of the papers propose conceptual studies, or lack evaluations or tackle relatively simple scenarios; (ii) almost all of the studied papers deal with robots/agents explaining their behaviors to the human users, and very few works addressed inter-robot (inter-agent) explainability. Finally, (iii) while providing explanations to non-expert users has been outlined as a necessity, only a few works addressed the issues of personalization and context-awareness.},
	language = {en},
	author = {Anjomshoae, Sule and Najjar, Amro and Calvaresi, Davide and Främling, Kary},
	year = {2019},
	pages = {11},
}

@inproceedings{IncreasingOpportunitiesAgingPlace,
	address = {Arlington, Virginia, United States},
	title = {Increasing the opportunities for aging in place},
	isbn = {978-1-58113-314-1},
	url = {http://portal.acm.org/citation.cfm?doid=355460.355475},
	doi = {10.1145/355460.355475},
	abstract = {A growing social problem in the U.S. and elsewhere is supporting older adults who want to continue living independently as opposed to moving to an institutional care setting. The "Aging in Place" project strives to delay taking that first step away from the family home. Through the careful placement of technological support we believe older adults can continue living in their own homes longer.},
	language = {en},
	urldate = {2020-09-27},
	booktitle = {Proceedings on the 2000 conference on {Universal} {Usability}  - {CUU} '00},
	publisher = {ACM Press},
	author = {Mynatt, Elizabeth D. and Essa, Irfan and Rogers, Wendy},
	year = {2000},
	pages = {65--71},
}

@article{BetterAnalysisDeepConvolutional,
	title = {Towards {Better} {Analysis} of {Deep} {Convolutional} {Neural} {Networks}},
	volume = {23},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/7536654/},
	doi = {10.1109/TVCG.2016.2598831},
	abstract = {Deep convolutional neural networks (CNNs) have achieved breakthrough performance in many pattern recognition tasks such as image classiﬁcation. However, the development of high-quality deep models typically relies on a substantial amount of trial-and-error, as there is still no clear understanding of when and why a deep model works. In this paper, we present a visual analytics approach for better understanding, diagnosing, and reﬁning deep CNNs. We formulate a deep CNN as a directed acyclic graph. Based on this formulation, a hybrid visualization is developed to disclose the multiple facets of each neuron and the interactions between them. In particular, we introduce a hierarchical rectangle packing algorithm and a matrix reordering algorithm to show the derived features of a neuron cluster. We also propose a biclustering-based edge bundling method to reduce visual clutter caused by a large number of connections between neurons. We evaluated our method on a set of CNNs and the results are generally favorable.},
	language = {en},
	number = {1},
	urldate = {2020-09-24},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Mengchen and Shi, Jiaxin and Li, Zhen and Li, Chongxuan and Zhu, Jun and Liu, Shixia},
	month = jan,
	year = {2017},
	keywords = {dl, vis},
	pages = {91--100},
}

@inproceedings{RoleExplanationsTrustReliance,
	title = {The {Role} of {Explanations} on {Trust} and {Reliance} in {Clinical} {Decision} {Support} {Systems}},
	doi = {10.1109/ICHI.2015.26},
	abstract = {Clinical decision support systems (CDSS) are increasingly used by healthcare professionals for evidence-based diagnosis and treatment support. However, research has suggested that users often over-rely on system suggestions - even if the suggestions are wrong. Providing explanations could potentially mitigate misplaced trust in the system and over-reliance. In this paper, we explore how explanations are related to user trust and reliance, as well as what information users would find helpful to better understand the reliability of a system's decision-making. We investigated these questions through an exploratory user study in which healthcare professionals were observed using a CDSS prototype to diagnose hypothetic cases using fictional patients suffering from a balance-related disorder. Our results show that the amount of system confidence had only a slight effect on trust and reliance. More importantly, giving a fuller explanation of the facts used in making a diagnosis had a positive effect on trust but also led to over-reliance issues, whereas less detailed explanations made participants question the system's reliability and led to self-reliance problems. To help them in their assessment of the reliability of the system's decisions, study participants wanted better explanations to help them interpret the system's confidence, to verify that the disorder fit the suggestion, to better understand the reasoning chain of the decision model, and to make differential diagnoses. Our work is a first step toward improved CDSS design that better supports clinicians in making correct diagnoses.},
	booktitle = {2015 {International} {Conference} on {Healthcare} {Informatics}},
	author = {Bussone, Adrian and Stumpf, Simone and O'Sullivan, Dympna},
	month = oct,
	year = {2015},
	keywords = {explanation, xai},
	pages = {160--169},
}

@article{AutomatedRationaleGenerationTechniquea,
	title = {Automated {Rationale} {Generation}: {A} {Technique} for {Explainable} {AI} and its {Effects} on {Human} {Perceptions}},
	shorttitle = {Automated {Rationale} {Generation}},
	url = {http://arxiv.org/abs/1901.03729},
	abstract = {Automated rationale generation is an approach for real-time explanation generation whereby a computational model learns to translate an autonomous agent's internal state and action data representations into natural language. Training on human explanation data can enable agents to learn to generate human-like explanations for their behavior. In this paper, using the context of an agent that plays Frogger, we describe (a) how to collect a corpus of explanations, (b) how to train a neural rationale generator to produce different styles of rationales, and (c) how people perceive these rationales. We conducted two user studies. The first study establishes the plausibility of each type of generated rationale and situates their user perceptions along the dimensions of confidence, humanlike-ness, adequate justification, and understandability. The second study further explores user preferences between the generated rationales with regard to confidence in the autonomous agent, communicating failure and unexpected behavior. Overall, we find alignment between the intended differences in features of the generated rationales and the perceived differences by users. Moreover, context permitting, participants preferred detailed rationales to form a stable mental model of the agent's behavior.},
	urldate = {2020-08-26},
	journal = {arXiv:1901.03729 [cs]},
	author = {Ehsan, Upol and Tambwekar, Pradyumna and Chan, Larry and Harrison, Brent and Riedl, Mark},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.03729},
	keywords = {explanation, robot, xai},
}

@inproceedings{HowMuchInformationEffects,
	address = {San Jose California USA},
	title = {How {Much} {Information}?: {Effects} of {Transparency} on {Trust} in an {Algorithmic} {Interface}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {How {Much} {Information}?},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858402},
	doi = {10.1145/2858036.2858402},
	abstract = {The rising prevalence of algorithmic interfaces, such as curated feeds in online news, raises new questions for designers, scholars, and critics of media. This work focuses on how transparent design of algorithmic interfaces can promote awareness and foster trust. A two-stage process of how transparency affects trust was hypothesized drawing on theories of information processing and procedural justice. In an online ﬁeld experiment, three levels of system transparency were tested in the high-stakes context of peer assessment. Individuals whose expectations were violated (by receiving a lower grade than expected) trusted the system less, unless the grading algorithm was made more transparent through explanation. However, providing too much information eroded this trust. Attitudes of individuals whose expectations were met did not vary with transparency. Results are discussed in terms of a dual process model of attitude change and the depth of justiﬁcation of perceived inconsistency. Designing for trust requires balanced interface transparency—not too little and not too much.},
	language = {en},
	urldate = {2020-08-26},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kizilcec, René F.},
	month = may,
	year = {2016},
	keywords = {eval, trust, xai},
	pages = {2390--2395},
}

@inproceedings{VisualizationsExplainablePlanningAgent,
	address = {Stockholm, Sweden},
	title = {Visualizations for an {Explainable} {Planning} {Agent}},
	isbn = {978-0-9992411-2-7},
	url = {https://www.ijcai.org/proceedings/2018/849},
	doi = {10.24963/ijcai.2018/849},
	abstract = {In this demonstration, we report on the visualization capabilities of an Explainable AI Planning (XAIP) agent that can support human in the loop decision making. Imposing transparency and explainability requirements on such agents is crucial for establishing human trust and common ground with an end-to-end automated planning system. Visualizing the agent’s internal decision making processes is a crucial step towards achieving this. This may include externalizing the “brain” of the agent: starting from its sensory inputs, to progressively higher order decisions made by it in order to drive its planning components. We demonstrate these functionalities in the context of a smart assistant in the Cognitive Environments Laboratory at IBM’s T.J. Watson Research Center.},
	language = {en},
	urldate = {2020-08-26},
	booktitle = {Proceedings of the {Twenty}-{Seventh} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Chakraborti, Tathagata and Fadnis, Kshitij P. and Talamadupula, Kartik and Dholakia, Mishal and Srivastava, Biplav and Kephart, Jeffrey O. and Bellamy, Rachel K. E.},
	month = jul,
	year = {2018},
	pages = {5820--5822},
}

@article{WillIntroduceYouDesign,
	title = {will introduce you to the design and implementation of {Intelligent} {User} {Interfaces} ({IUIs}).},
	language = {en},
	author = {Sonntag, Daniel},
	year = {2015},
	pages = {25},
}

@inproceedings{HumanPerceptionsFairnessAlgorithmic,
	address = {Lyon, France},
	title = {Human {Perceptions} of {Fairness} in {Algorithmic} {Decision} {Making}: {A} {Case} {Study} of {Criminal} {Risk} {Prediction}},
	isbn = {978-1-4503-5639-8},
	shorttitle = {Human {Perceptions} of {Fairness} in {Algorithmic} {Decision} {Making}},
	url = {http://dl.acm.org/citation.cfm?doid=3178876.3186138},
	doi = {10.1145/3178876.3186138},
	abstract = {As algorithms are increasingly used to make important decisions that affect human lives, ranging from social benefit assignment to predicting risk of criminal recidivism, concerns have been raised about the fairness of algorithmic decision making. Most prior works on algorithmic fairness normatively prescribe how fair decisions ought to be made. In contrast, here, we descriptively survey users for how they perceive and reason about fairness in algorithmic decision making.},
	language = {en},
	urldate = {2020-09-28},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference} on {World} {Wide} {Web} - {WWW} '18},
	publisher = {ACM Press},
	author = {Grgic-Hlaca, Nina and Redmiles, Elissa M. and Gummadi, Krishna P. and Weller, Adrian},
	year = {2018},
	pages = {903--912},
}

@misc{DswahPygamV0,
	title = {Dswah/{Pygam}: {V0}.8.0},
	copyright = {Open Access},
	shorttitle = {Dswah/{Pygam}},
	url = {https://zenodo.org/record/1208723},
	abstract = {While machine learning (ML) continues to ﬁnd success in solving previously-thought hard problems, interpreting and exploring ML models remains challenging. Recent work has shown that visualizations are a powerful tool to aid debugging, analyzing, and interpreting ML models. However, depending on the complexity of the model (e.g., number of features), interpreting these visualizations can be difﬁcult and may require additional expertise. Alternatively, textual descriptions, or verbalizations, can be a simple, yet effective way to communicate or summarize key aspects about a model, such as the overall trend in a model’s predictions or comparisons between pairs of data instances. With the potential beneﬁts of visualizations and verbalizations in mind, we explore how the two can be combined to aid ML interpretability. Speciﬁcally, we present a prototype system, TELEGAM, that demonstrates how visualizations and verbalizations can collectively support interactive exploration of ML models, for example, generalized additive models (GAMs). We describe TELEGAM’s interface and underlying heuristics to generate the verbalizations. We conclude by discussing how TELEGAM can serve as a platform to conduct future studies for understanding user expectations and designing novel interfaces for interpretable ML.},
	urldate = {2020-09-27},
	publisher = {Zenodo},
	author = {Servén, Daniel and Brummitt, Charlie and Abedi, Hassan and Hlink},
	month = oct,
	year = {2018},
	doi = {10.5281/ZENODO.1208723},
}

@article{GoingVisualizationVerbalizationComplementary,
	title = {Going beyond {Visualization} : {Verbalization} as {Complementary} {Medium} to {Explain} {Machine} {Learning} {Models}},
	abstract = {In this position paper, we argue that a combination of visualization and verbalization techniques is beneﬁcial for creating broad and versatile insights into the structure and decision-making processes of machine learning models. Explainability of machine learning models is emerging as an important area of research. Hence, insights into the inner workings of a trained model allow users and analysts, alike, to understand the models, develop justiﬁcations, and gain trust in the systems they inform. Explanations can be generated through different types of media, such as visualization and verbalization. Both are powerful tools that enable model interpretability. However, while their combination is arguably more powerful than each medium separately, they are currently applied and researched independently. To support our position that the combination of the two techniques is beneﬁcial to explain machine learning models, we describe the design space of such a combination and discuss arising research questions, gaps, and opportunities.},
	language = {en},
	author = {Sevastjanova, Rita},
	keywords = {explanation, vis},
	pages = {6},
}

@article{UnderstandableRobotsWhatWhy,
	title = {Understandable robots - {What}, {Why}, and {How}},
	volume = {9},
	issn = {2081-4836},
	url = {http://www.degruyter.com/view/j/pjbr.2018.9.issue-1/pjbr-2018-0009/pjbr-2018-0009.xml},
	doi = {10.1515/pjbr-2018-0009},
	abstract = {As robots become more and more capable and autonomous, there is an increasing need for humans to understand what the robots do and think. In this paper, we investigate what such understanding means and includes, and how robots can be designed to support understanding. After an in-depth survey of related earlier work, we discuss examples showing that understanding includes not only the intentions of the robot, but also desires, knowledge, beliefs, emotions, perceptions, capabilities, and limitations of the robot. The term understanding is formally defined, and the term communicative actions is defined to denote the various ways in which a robot may support a human’s understanding of the robot. A novel model of interaction for understanding is presented. The model describes how both human and robot may utilize a first or higher-order theory of mind to understand each other and perform communicative actions in order to support the other’s understanding. It also describes simpler cases in which the robot performs static communicative actions in order to support the human’s understanding of the robot. In general, communicative actions performed by the robot aim at reducing the mismatch between the mind of the robot, and the robot’s inferred model of the human’s model of the mind of the robot. Based on the proposed model, a set of questions are formulated, to serve as support when developing and implementing the model in real interacting robots.},
	language = {en},
	number = {1},
	urldate = {2020-09-27},
	journal = {Paladyn, Journal of Behavioral Robotics},
	author = {Hellström, Thomas and Bensch, Suna},
	month = jul,
	year = {2018},
	pages = {110--123},
}

@article{TELEGAMCombiningVisualizationVerbalization,
	title = {{TELEGAM}: {Combining} {Visualization} and {Verbalization} for {Interpretable} {Machine} {Learning}},
	abstract = {While machine learning (ML) continues to ﬁnd success in solving previously-thought hard problems, interpreting and exploring ML models remains challenging. Recent work has shown that visualizations are a powerful tool to aid debugging, analyzing, and interpreting ML models. However, depending on the complexity of the model (e.g., number of features), interpreting these visualizations can be difﬁcult and may require additional expertise. Alternatively, textual descriptions, or verbalizations, can be a simple, yet effective way to communicate or summarize key aspects about a model, such as the overall trend in a model’s predictions or comparisons between pairs of data instances. With the potential beneﬁts of visualizations and verbalizations in mind, we explore how the two can be combined to aid ML interpretability. Speciﬁcally, we present a prototype system, TELEGAM, that demonstrates how visualizations and verbalizations can collectively support interactive exploration of ML models, for example, generalized additive models (GAMs). We describe TELEGAM’s interface and underlying heuristics to generate the verbalizations. We conclude by discussing how TELEGAM can serve as a platform to conduct future studies for understanding user expectations and designing novel interfaces for interpretable ML.},
	language = {en},
	author = {Hohman, Fred and Srinivasan, Arjun and Drucker, Steven M},
	pages = {5},
}

@article{ConversationalProcessesCausalExplanationa,
	title = {Conversational processes and causal explanation.},
	volume = {107},
	issn = {0033-2909},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-2909.107.1.65},
	doi = {10.1037/0033-2909.107.1.65},
	language = {en},
	number = {1},
	urldate = {2020-09-27},
	journal = {Psychological Bulletin},
	author = {Hilton, Denis J.},
	year = {1990},
	keywords = {explanation, fatml},
	pages = {65--81},
}

@article{TheoryExplanationsHumanRobot,
	title = {Towards a {Theory} of {Explanations} for {Human}–{Robot} {Collaboration}},
	volume = {33},
	issn = {0933-1875, 1610-1987},
	url = {http://link.springer.com/10.1007/s13218-019-00616-y},
	doi = {10.1007/s13218-019-00616-y},
	abstract = {This paper makes two contributions towards enabling a robot to provide explanatory descriptions of its decisions, the underlying knowledge and beliefs, and the experiences that informed these beliefs. First, we present a theory of explanations comprising (i) claims about representing, reasoning with, and learning domain knowledge to support the construction of explanations; (ii) three fundamental axes to characterize explanations; and (iii) a methodology for constructing these explanations. Second, we describe an architecture for robots that implements this theory and supports scalability to complex domains and explanations. We demonstrate the architecture’s capabilities in the context of a simulated robot (a) moving target objects to desired locations or people; or (b) following recipes to bake biscuits.},
	language = {en},
	number = {4},
	urldate = {2020-09-27},
	journal = {KI - Künstliche Intelligenz},
	author = {Sridharan, Mohan and Meadows, Ben},
	month = dec,
	year = {2019},
	pages = {331--342},
}

@inproceedings{UnderstandingUserPreferencesExplanation,
	address = {Daegu, Korea (South)},
	title = {Towards {Understanding} {User} {Preferences} for {Explanation} {Types} in {Model} {Reconciliation}},
	isbn = {978-1-5386-8555-6},
	url = {https://ieeexplore.ieee.org/document/8673097/},
	doi = {10.1109/HRI.2019.8673097},
	abstract = {Recent work has formalized the explanation process in the context of automated planning as one of model reconciliation – i.e. a process by which the planning agent can bring the explainee’s (possibly faulty) model of a planning problem closer to its understanding of the ground truth until both agree that its plan is the best possible. The content of explanations can thus range from misunderstandings about the agent’s beliefs (state), desires (goals) and capabilities (action model). Though existing literature has considered different kinds of these model differences to be equivalent, literature on the explanations in social sciences has suggested that explanations with similar logical properties may often be perceived differently by humans. In this brief report, we explore to what extent humans attribute importance to different kinds of model differences that have been traditionally considered equivalent in the model reconciliation setting. Our results suggest that people prefer the explanations which are related to the effects of actions.},
	language = {en},
	urldate = {2020-09-27},
	booktitle = {2019 14th {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction} ({HRI})},
	publisher = {IEEE},
	author = {Zahedi, Zahra and Olmo, Alberto and Chakraborti, Tathagata and Sreedharan, Sarath and Kambhampati, Subbarao},
	month = mar,
	year = {2019},
	pages = {648--649},
}

@article{StakeholdersExplainableAI,
	title = {Stakeholders in {Explainable} {AI}},
	url = {http://arxiv.org/abs/1810.00184},
	abstract = {There is general consensus that it is important for artiﬁcial intelligence (AI) and machine learning systems to be explainable and/or interpretable. However, there is no general consensus over what is meant by ‘explainable’ and ‘interpretable’. In this paper, we argue that this lack of consensus is due to there being several distinct stakeholder communities. We note that, while the concerns of the individual communities are broadly compatible, they are not identical, which gives rise to different intents and requirements for explainability/interpretability. We use the software engineering distinction between validation and veriﬁcation, and the epistemological distinctions between knowns/unknowns, to tease apart the concerns of the stakeholder communities and highlight the areas where their foci overlap or diverge. It is not the purpose of the authors of this paper to ‘take sides’ — we count ourselves as members, to varying degrees, of multiple communities — but rather to help disambiguate what stakeholders mean when they ask ‘Why?’ of an AI.},
	language = {en},
	urldate = {2020-09-27},
	journal = {arXiv:1810.00184 [cs]},
	author = {Preece, Alun and Harborne, Dan and Braines, Dave and Tomsett, Richard and Chakraborty, Supriyo},
	month = sep,
	year = {2018},
	note = {arXiv: 1810.00184},
}

@article{UnderstandingPerceptionAlgorithmicDecisions,
	title = {Understanding perception of algorithmic decisions: {Fairness}, trust, and emotion in response to algorithmic management},
	volume = {5},
	issn = {2053-9517},
	shorttitle = {Understanding perception of algorithmic decisions},
	url = {https://doi.org/10.1177/2053951718756684},
	doi = {10.1177/2053951718756684},
	abstract = {Algorithms increasingly make managerial decisions that people used to make. Perceptions of algorithms, regardless of the algorithms' actual performance, can significantly influence their adoption, yet we do not fully understand how people perceive decisions made by algorithms as compared with decisions made by humans. To explore perceptions of algorithmic management, we conducted an online experiment using four managerial decisions that required either mechanical or human skills. We manipulated the decision-maker (algorithmic or human), and measured perceived fairness, trust, and emotional response. With the mechanical tasks, algorithmic and human-made decisions were perceived as equally fair and trustworthy and evoked similar emotions; however, human managers' fairness and trustworthiness were attributed to the manager's authority, whereas algorithms' fairness and trustworthiness were attributed to their perceived efficiency and objectivity. Human decisions evoked some positive emotion due to the possibility of social recognition, whereas algorithmic decisions generated a more mixed response ? algorithms were seen as helpful tools but also possible tracking mechanisms. With the human tasks, algorithmic decisions were perceived as less fair and trustworthy and evoked more negative emotion than human decisions. Algorithms' perceived lack of intuition and subjective judgment capabilities contributed to the lower fairness and trustworthiness judgments. Positive emotion from human decisions was attributed to social recognition, while negative emotion from algorithmic decisions was attributed to the dehumanizing experience of being evaluated by machines. This work reveals people's lay concepts of algorithmic versus human decisions in a management context and suggests that task characteristics matter in understanding people's experiences with algorithmic technologies.},
	number = {1},
	urldate = {2020-10-03},
	journal = {Big Data \& Society},
	author = {Lee, Min Kyung},
	month = jan,
	year = {2018},
	note = {Publisher: SAGE Publications Ltd},
	keywords = {fair, fatml},
	pages = {2053951718756684},
}

@article{EthicsAlgorithmicDecisionmakingHealthcare,
	title = {On the ethics of algorithmic decision-making in healthcare},
	volume = {46},
	issn = {0306-6800, 1473-4257},
	url = {https://jme.bmj.com/lookup/doi/10.1136/medethics-2019-105586},
	doi = {10.1136/medethics-2019-105586},
	abstract = {In recent years, a plethora of high-p­ rofile scientific publications has been reporting about machine learning algorithms outperforming clinicians in medical diagnosis or treatment recommendations. This has spiked interest in deploying relevant algorithms with the aim of enhancing decision-m­ aking in healthcare. In this paper, we argue that instead of straightforwardly enhancing the decision-­making capabilities of clinicians and healthcare institutions, deploying machines learning algorithms entails trade-o­ ffs at the epistemic and the normative level. Whereas involving machine learning might improve the accuracy of medical diagnosis, it comes at the expense of opacity when trying to assess the reliability of given diagnosis. Drawing on literature in social epistemology and moral responsibility, we argue that the uncertainty in question potentially undermines the epistemic authority of clinicians. Furthermore, we elucidate potential pitfalls of involving machine learning in healthcare with respect to paternalism, moral responsibility and fairness. At last, we discuss how the deployment of machine learning algorithms might shift the evidentiary norms of medical diagnosis. In this regard, we hope to lay the grounds for further ethical reflection of the opportunities and pitfalls of machine learning for enhancing decision-m­ aking in healthcare.},
	language = {en},
	number = {3},
	urldate = {2020-10-03},
	journal = {Journal of Medical Ethics},
	author = {Grote, Thomas and Berens, Philipp},
	month = mar,
	year = {2020},
	keywords = {fair, fatml},
	pages = {205--211},
}

@inproceedings{ExplainingDecisionMakingAlgorithmsUI,
	address = {Glasgow, Scotland Uk},
	title = {Explaining {Decision}-{Making} {Algorithms} through {UI}: {Strategies} to {Help} {Non}-{Expert} {Stakeholders}},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Explaining {Decision}-{Making} {Algorithms} through {UI}},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300789},
	doi = {10.1145/3290605.3300789},
	abstract = {Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users’ “right to explanation”. We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users’ objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and “whitebox” explanations (i.e. that show the inner workings of an algorithm) can improve users’ comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users’ trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm.},
	language = {en},
	urldate = {2020-10-03},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}  - {CHI} '19},
	publisher = {ACM Press},
	author = {Cheng, Hao-Fei and Wang, Ruotong and Zhang, Zheng and O'Connell, Fiona and Gray, Terrance and Harper, F. Maxwell and Zhu, Haiyi},
	year = {2019},
	keywords = {explanation, vis},
	pages = {1--12},
}

@article{KeepingDesignersLoopCommunicating,
	title = {Keeping {Designers} in the {Loop}: {Communicating} {Inherent} {Algorithmic} {Trade}-offs {Across} {Multiple} {Objectives}},
	shorttitle = {Keeping {Designers} in the {Loop}},
	url = {http://arxiv.org/abs/1910.03061},
	abstract = {Artificial intelligence algorithms have been used to enhance a wide variety of products and services, including assisting human decision making in high-stakes contexts. However, these algorithms are complex and have trade-offs, notably between prediction accuracy and fairness to population subgroups. This makes it hard for designers to understand algorithms and design products or services in a way that respects users' goals, values, and needs. We proposed a method to help designers and users explore algorithms, visualize their trade-offs, and select algorithms with trade-offs consistent with their goals and needs. We evaluated our method on the problem of predicting criminal defendants' likelihood to re-offend through (i) a large-scale Amazon Mechanical Turk experiment, and (ii) in-depth interviews with domain experts. Our evaluations show that our method can help designers and users of these systems better understand and navigate algorithmic trade-offs. This paper contributes a new way of providing designers the ability to understand and control the outcomes of algorithmic systems they are creating.},
	urldate = {2020-10-03},
	journal = {arXiv:1910.03061 [cs]},
	author = {Yu, Bowen and Yuan, Ye and Terveen, Loren and Wu, Zhiwei Steven and Forlizzi, Jodi and Zhu, Haiyi},
	month = jul,
	year = {2020},
	note = {arXiv: 1910.03061},
	keywords = {explanation, hci},
}

@article{ComparingTraditionalCrowdsourcingMethods,
	title = {Comparing {Traditional} and {Crowdsourcing} {Methods} for {Pretesting} {Survey} {Questions}},
	volume = {6},
	issn = {2158-2440},
	url = {https://doi.org/10.1177/2158244016671770},
	doi = {10.1177/2158244016671770},
	abstract = {Cognitive interviewing is a common method used to evaluate survey questions. This study compares traditional cognitive interviewing methods with crowdsourcing, or ?tapping into the collective intelligence of the public to complete a task.? Crowdsourcing may provide researchers with access to a diverse pool of potential participants in a very timely and cost-efficient way. Exploratory work found that crowdsourcing participants, with self-administered data collection, may be a viable alternative, or addition, to traditional pretesting methods. Using three crowdsourcing designs (TryMyUI, Amazon Mechanical Turk, and Facebook), we compared the participant characteristics, costs, and quantity and quality of data with traditional laboratory-based cognitive interviews. Results suggest that crowdsourcing and self-administered protocols may be a viable way to collect survey pretesting information, as participants were able to complete the tasks and provide useful information; however, complex tasks may require the skills of an interviewer to administer unscripted probes.},
	number = {4},
	urldate = {2020-10-02},
	journal = {SAGE Open},
	author = {Edgar, Jennifer and Murphy, Joe and Keating, Michael},
	month = oct,
	year = {2016},
	note = {Publisher: SAGE Publications},
	keywords = {crowdsourcing, eval},
	pages = {2158244016671770},
}

@article{CatchyTitlesAreGooda,
	title = {Catchy {Titles} {Are} {Good}: {But} {Avoid} {Being} {Cute}},
	abstract = {The most important rule of Abstracts is that they describe the work, not the paper. Include, at most, one sentence of motivation. Save the rest of your motivation for the Introduction. Effective Abstracts focus on two things: (1) Describing what was done. (2) Describing what was found (key results). Be specific about your key findings. Instead of “many” say “84\%”. Keep the Abstract to one paragraph and fewer than 200 words.},
	language = {en},
	author = {Wobbrock, Jacob O},
	keywords = {hci, research},
	pages = {5},
}

@inproceedings{SystematicLiteratureReviewIntelligent,
	address = {Grenoble, France},
	title = {A systematic literature review on intelligent user interfaces: preliminary results},
	isbn = {978-1-4503-7027-1},
	shorttitle = {A systematic literature review on intelligent user interfaces},
	url = {http://dl.acm.org/citation.cfm?doid=3366551.3370344},
	doi = {10.1145/3366551.3370344},
	language = {en},
	urldate = {2020-09-30},
	booktitle = {Proceedings of the 31st {Conference} on l'{Interaction} {Homme}-{Machine} {Adjunct} - {IHM} '19},
	publisher = {ACM Press},
	author = {Gonçalves, Taisa G. and Kolski, Christophe and de Oliveira, Káthia M. and Travassos, Guilherme H. and Strugeon, Emmanuelle Grislin-Le},
	year = {2019},
	pages = {1--8},
}

@article{ACCURATEFAIREXPLAINABLEBUILDINGa,
	title = {{ACCURATE}, {FAIR}, {AND} {EXPLAINABLE}: {BUILDING} {HUMAN}-{CENTERED} {AI}},
	language = {en},
	author = {Cruz, Santa},
	keywords = {dissertation, thesis},
	pages = {229},
}

@inproceedings{SystematicMappingStudyIntelligent,
	address = {Quito},
	title = {A {Systematic} {Mapping} {Study} for {Intelligent} {User} {Interfaces} - {IUI}},
	isbn = {978-1-5386-2644-3},
	url = {http://ieeexplore.ieee.org/document/8328132/},
	doi = {10.1109/INCISCOS.2017.34},
	abstract = {Intelligent User Interfaces (IUI) facilitate humanmachine interaction, through which the user makes use of a general system in a more efficient way. These interfaces are helpful for different types of users, specifically for people with disabilities, seniors, among others. These interfaces belong to a type of intelligent systems that are capable of self-adapt to users with different health problems, this is possible through the determination of behavior characteristics that distinguishes each user from another. In this paper, a systematic mapping of the Intelligent User Interfaces is presented, which allow developers to determine which applications are adopting those interfaces with emphasis on Ambient Assisted Living (AAL) technologies. The Kitchenham’s methodology has been applied in order to perform this secondary study, after the execution of the review, a total of 43 primary studies was selected and classified, thus allowing us to obtain the results presented in this contribution.},
	language = {en},
	urldate = {2020-09-30},
	booktitle = {2017 {International} {Conference} on {Information} {Systems} and {Computer} {Science} ({INCISCOS})},
	publisher = {IEEE},
	author = {Sanchez, Cristina and Cedillo, Priscila and Bermeo, Alexandra},
	month = nov,
	year = {2017},
	pages = {361--368},
}

@inproceedings{WhatIntelligentIntelligentUser,
	address = {Cagliari Italy},
	title = {What is "intelligent" in intelligent user interfaces?: a meta-analysis of 25 years of {IUI}},
	isbn = {978-1-4503-7118-6},
	shorttitle = {What is "intelligent" in intelligent user interfaces?},
	url = {https://dl.acm.org/doi/10.1145/3377325.3377500},
	doi = {10.1145/3377325.3377500},
	abstract = {This reflection paper takes the 25th IUI conference milestone as an opportunity to analyse in detail the understanding of intelligence in the community: Despite the focus on intelligent UIs, it has remained elusive what exactly renders an interactive system or user interface “intelligent”, also in the fields of HCI and AI at large. We follow a bottom-up approach to analyse the emergent meaning of intelligence in the IUI community: In particular, we apply text analysis to extract all occurrences of “intelligent” in all IUI proceedings. We manually review these with regard to three main questions: 1) What is deemed intelligent? 2) How (else) is it characterised? and 3) What capabilities are attributed to an intelligent entity? We discuss the community’s emerging implicit perspective on characteristics of intelligence in intelligent user interfaces and conclude with ideas for stating one’s own understanding of intelligence more explicitly.},
	language = {en},
	urldate = {2020-09-30},
	booktitle = {Proceedings of the 25th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Völkel, Sarah Theres and Schneegass, Christina and Eiband, Malin and Buschek, Daniel},
	month = mar,
	year = {2020},
	pages = {477--487},
}

@article{ComprehensiveUnderstandingIntelligentUser,
	title = {Comprehensive {Understanding} of {Intelligent} {User} {Interfaces}},
	volume = {8},
	issn = {21565570, 2158107X},
	url = {http://thesai.org/Publications/ViewPaper?Volume=8&Issue=6&Code=ijacsa&SerialNo=52},
	doi = {10.14569/IJACSA.2017.080652},
	abstract = {This paper represents basic discussion for one of the latest advances in the technology, known as Intelligent User Interface (IIUI) which is a combination of two major ﬁelds of computer science, namely, HCI \& Artiﬁcial Intelligence. The paper ﬁrst discusses basic deﬁnitions, motivation to this research and UIMS (User Interface Management System) along with example of user interface models to understand user interfaces in detail. The four major classes (with their examples) of these interfaces have been taken as a method for this study. The overall discussion summarizes some basic principles used to create these interfaces, components that are important in the generation of IUIs and decision making process in IUI for the reader to understand working of IIUIs.},
	language = {en},
	number = {6},
	urldate = {2020-09-30},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Shaikh, Sarang and Ajmal, M. and Ahmed, Najeed and Badar, Farhan},
	year = {2017},
}

@misc{22Pdf,
	title = {22.pdf},
	url = {https://drive.google.com/file/d/1ZuZUJSleUpsA7ddLzQeOaJUSRtFLRH4p/view?usp=sharing&usp=embed_facebook},
	urldate = {2020-10-12},
	journal = {Google Docs},
}

@inproceedings{FairnessAwareness,
	address = {Cambridge, Massachusetts},
	title = {Fairness through awareness},
	isbn = {978-1-4503-1115-1},
	url = {http://dl.acm.org/citation.cfm?doid=2090236.2090255},
	doi = {10.1145/2090236.2090255},
	abstract = {We study fairness in classiﬁcation, where individuals are classiﬁed, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classiﬁer (the university). The main conceptual contribution of this paper is a framework for fair classiﬁcation comprising (1) a (hypothetical) task-speciﬁc metric for determining the degree to which individuals are similar with respect to the classiﬁcation task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of “fair aﬃrmative action,” which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classiﬁcation are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of diﬀerential privacy may be applied to fairness.},
	language = {en},
	urldate = {2020-10-11},
	booktitle = {Proceedings of the 3rd {Innovations} in {Theoretical} {Computer} {Science} {Conference} on - {ITCS} '12},
	publisher = {ACM Press},
	author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
	year = {2012},
	keywords = {comps-dm, fair, fatml},
	pages = {214--226},
}

@inproceedings{FairnessDiscriminationRetrievalRecommendation,
	address = {Paris France},
	title = {Fairness and {Discrimination} in {Retrieval} and {Recommendation}},
	isbn = {978-1-4503-6172-9},
	url = {https://dl.acm.org/doi/10.1145/3331184.3331380},
	doi = {10.1145/3331184.3331380},
	abstract = {Fairness and related concerns have become of increasing importance in a variety of AI and machine learning contexts. They are also highly relevant to information retrieval and related problems such as recommendation, as evidenced by the growing literature in SIGIR, FAT*, RecSys, and special sessions such as the FATREC workshop and the Fairness track at TREC 2019; however, translating algorithmic fairness constructs from classification, scoring, and even many ranking settings into information retrieval and recommendation scenarios is not a straightforward task. This tutorial will help to orient IR researchers to algorithmic fairness, understand how concepts do and do not translate from other settings, and provide an introduction to the growing literature on this topic.},
	language = {en},
	urldate = {2020-10-11},
	booktitle = {Proceedings of the 42nd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Ekstrand, Michael D. and Burke, Robin and Diaz, Fernando},
	month = jul,
	year = {2019},
	keywords = {fair, fatml},
	pages = {1403--1404},
}

@article{LipstickPigDebiasingMethods,
	title = {Lipstick on a {Pig}: {Debiasing} {Methods} {Cover} up {Systematic} {Gender} {Biases} in {Word} {Embeddings} {But} do not {Remove} {Them}},
	shorttitle = {Lipstick on a {Pig}},
	url = {http://arxiv.org/abs/1903.03862},
	abstract = {Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society. This phenomenon is pervasive and consistent across different word embedding models, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between "gender-neutralized" words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.},
	urldate = {2020-10-11},
	journal = {arXiv:1903.03862 [cs]},
	author = {Gonen, Hila and Goldberg, Yoav},
	month = sep,
	year = {2019},
	note = {arXiv: 1903.03862},
	keywords = {comps-dm, fair, fatml},
}

@article{DistillingKnowledgeNeuralNetwork,
	title = {Distilling the {Knowledge} in a {Neural} {Network}},
	url = {http://arxiv.org/abs/1503.02531},
	abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
	urldate = {2020-10-11},
	journal = {arXiv:1503.02531 [cs, stat]},
	author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	month = mar,
	year = {2015},
	note = {arXiv: 1503.02531},
}

@article{InterpretableMachineLearningDefinitions,
	title = {Interpretable machine learning: definitions, methods, and applications},
	volume = {116},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Interpretable machine learning},
	url = {http://arxiv.org/abs/1901.04592},
	doi = {10.1073/pnas.1900654116},
	abstract = {Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related, and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the Predictive, Descriptive, Relevant (PDR) framework for discussing interpretations. The PDR framework provides three overarching desiderata for evaluation: predictive accuracy, descriptive accuracy and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post-hoc categories, with sub-groups including sparsity, modularity and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often under-appreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.},
	language = {en},
	number = {44},
	urldate = {2020-10-10},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Murdoch, W. James and Singh, Chandan and Kumbier, Karl and Abbasi-Asl, Reza and Yu, Bin},
	month = oct,
	year = {2019},
	note = {arXiv: 1901.04592},
	keywords = {fatml, survey, xai},
	pages = {22071--22080},
}

@article{ExplanationHumanAISystemsLiterature,
	title = {Explanation in {Human}-{AI} {Systems}: {A} {Literature} {Meta}-{Review}, {Synopsis} of {Key} {Ideas} and {Publications}, and {Bibliography} for {Explainable} {AI}},
	shorttitle = {Explanation in {Human}-{AI} {Systems}},
	url = {http://arxiv.org/abs/1902.01876},
	abstract = {This is an integrative review that address the question, "What makes for a good explanation?" with reference to AI systems. Pertinent literatures are vast. Thus, this review is necessarily selective. That said, most of the key concepts and issues are expressed in this Report. The Report encapsulates the history of computer science efforts to create systems that explain and instruct (intelligent tutoring systems and expert systems). The Report expresses the explainability issues and challenges in modern AI, and presents capsule views of the leading psychological theories of explanation. Certain articles stand out by virtue of their particular relevance to XAI, and their methods, results, and key points are highlighted. It is recommended that AI/XAI researchers be encouraged to include in their research reports fuller details on their empirical or experimental methods, in the fashion of experimental psychology research reports: details on Participants, Instructions, Procedures, Tasks, Dependent Variables (operational definitions of the measures and metrics), Independent Variables (conditions), and Control Conditions.},
	urldate = {2020-10-10},
	journal = {arXiv:1902.01876 [cs]},
	author = {Mueller, Shane T. and Hoffman, Robert R. and Clancey, William and Emrey, Abigail and Klein, Gary},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.01876
version: 1},
	keywords = {explainable, fair, fatml},
}

@inproceedings{ExplainExploreVisualExplorationMachine,
	address = {Tianjin, China},
	title = {{ExplainExplore}: {Visual} {Exploration} of {Machine} {Learning} {Explanations}},
	isbn = {978-1-72815-697-2},
	shorttitle = {{ExplainExplore}},
	url = {https://ieeexplore.ieee.org/document/9086281/},
	doi = {10.1109/PacificVis48177.2020.7090},
	abstract = {Machine learning models often exhibit complex behavior that is difﬁcult to understand. Recent research in explainable AI has produced promising techniques to explain the inner workings of such models using feature contribution vectors. These vectors are helpful in a wide variety of applications. However, there are many parameters involved in this process and determining which settings are best is difﬁcult due to the subjective nature of evaluating interpretability. To this end, we introduce EXPLAINEXPLORE: an interactive explanation system to explore explanations that ﬁt the subjective preference of data scientists. We leverage the domain knowledge of the data scientist to ﬁnd optimal parameter settings and instance perturbations, and enable the discussion of the model and its explanation with domain experts. We present a use case on a real-world dataset to demonstrate the effectiveness of our approach for the exploration and tuning of machine learning explanations.},
	language = {en},
	urldate = {2020-10-10},
	booktitle = {2020 {IEEE} {Pacific} {Visualization} {Symposium} ({PacificVis})},
	publisher = {IEEE},
	author = {Collaris, Dennis and van Wijk, Jarke J.},
	month = jun,
	year = {2020},
	pages = {26--35},
}

@inproceedings{ParallelEmbeddingsVisualizationTechnique,
	address = {Cagliari Italy},
	title = {Parallel embeddings: a visualization technique for contrasting learned representations},
	isbn = {978-1-4503-7118-6},
	shorttitle = {Parallel embeddings},
	url = {https://dl.acm.org/doi/10.1145/3377325.3377514},
	doi = {10.1145/3377325.3377514},
	language = {en},
	urldate = {2020-10-10},
	booktitle = {Proceedings of the 25th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Arendt, Dustin L. and Nur, Nasheen and Huang, Zhuanyi and Fair, Gabriel and Dou, Wenwen},
	month = mar,
	year = {2020},
	keywords = {bosch, emb, vis},
	pages = {259--274},
}

@article{ACCURATEFAIREXPLAINABLEBUILDING,
	title = {{ACCURATE}, {FAIR}, {AND} {EXPLAINABLE}: {BUILDING} {HUMAN}-{CENTERED} {AI}},
	language = {en},
	author = {Cruz, Santa},
	keywords = {dissertation, thesis},
	pages = {229},
}

@article{UpdatesHumanAITeamsUnderstanding,
	title = {Updates in {Human}-{AI} {Teams}: {Understanding} and {Addressing} the {Performance}/{Compatibility} {Tradeoff}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Updates in {Human}-{AI} {Teams}},
	url = {https://www.aaai.org/ojs/index.php/AAAI/article/view/4087},
	doi = {10.1609/aaai.v33i01.33012429},
	abstract = {AI systems are being deployed to support human decision making in high-stakes domains such as healthcare and criminal justice. In many cases, the human and AI form a team, in which the human makes decisions after reviewing the AI’s inferences. A successful partnership requires that the human develops insights into the performance of the AI system, including its failures. We study the inﬂuence of updates to an AI system in this setting. While updates can increase the AI’s predictive performance, they may also lead to behavioral changes that are at odds with the user’s prior experiences and conﬁdence in the AI’s inferences. We show that updates that increase AI performance may actually hurt team performance. We introduce the notion of the compatibility of an AI update with prior user experience and present methods for studying the role of compatibility in human-AI teams. Empirical results on three high-stakes classiﬁcation tasks show that current machine learning algorithms do not produce compatible updates. We propose a re-training objective to improve the compatibility of an update by penalizing new errors. The objective offers full leverage of the performance/compatibility tradeoff across different datasets, enabling more compatible yet accurate updates.},
	language = {en},
	urldate = {2020-10-04},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Bansal, Gagan and Nushi, Besmira and Kamar, Ece and Weld, Daniel S. and Lasecki, Walter S. and Horvitz, Eric},
	month = jul,
	year = {2019},
	pages = {2429--2437},
}

@book{UnderstandingAlgorithmicDecisionmakingOpportunities,
	address = {LU},
	title = {Understanding algorithmic decision-making: opportunities and challenges.},
	shorttitle = {Understanding algorithmic decision-making},
	url = {https://data.europa.eu/doi/10.2861/536131},
	language = {en},
	urldate = {2020-10-03},
	publisher = {Publications Office},
	year = {2019},
	keywords = {fatml},
}

@article{VisualInteractionDimensionalityReduction,
	title = {Visual {Interaction} with {Dimensionality} {Reduction}: {A} {Structured} {Literature} {Analysis}},
	volume = {23},
	issn = {1941-0506},
	shorttitle = {Visual {Interaction} with {Dimensionality} {Reduction}},
	doi = {10.1109/TVCG.2016.2598495},
	abstract = {Dimensionality Reduction (DR) is a core building block in visualizing multidimensional data. For DR techniques to be useful in exploratory data analysis, they need to be adapted to human needs and domain-specific problems, ideally, interactively, and on-the-fly. Many visual analytics systems have already demonstrated the benefits of tightly integrating DR with interactive visualizations. Nevertheless, a general, structured understanding of this integration is missing. To address this, we systematically studied the visual analytics and visualization literature to investigate how analysts interact with automatic DR techniques. The results reveal seven common interaction scenarios that are amenable to interactive control such as specifying algorithmic constraints, selecting relevant features, or choosing among several DR algorithms. We investigate specific implementations of visual analysis systems integrating DR, and analyze ways that other machine learning methods have been combined with DR. Summarizing the results in a “human in the loop” process model provides a general lens for the evaluation of visual interactive DR systems. We apply the proposed model to study and classify several systems previously described in the literature, and to derive future research opportunities.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Sacha, Dominik and Zhang, Leishi and Sedlmair, Michael and Lee, John A. and Peltonen, Jaakko and Weiskopf, Daniel and North, Stephen C. and Keim, Daniel A.},
	month = jan,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {dim-red, interaction, survey},
	pages = {241--250},
}

@inproceedings{HumanguidedMachineLearning,
	address = {Marina del Ray California},
	title = {Towards human-guided machine learning},
	isbn = {978-1-4503-6272-6},
	url = {https://dl.acm.org/doi/10.1145/3301275.3302324},
	doi = {10.1145/3301275.3302324},
	abstract = {Automated Machine Learning (AutoML) systems are emerging that automatically search for possible solutions from a large space of possible kinds of models. Although fully automated machine learning is appropriate for many applications, users often have knowledge that supplements and constraints the available data and solutions. This paper proposes human-guided machine learning (HGML) as a hybrid approach where a user interacts with an AutoML system and tasks it to explore different problem settings that reflect the user’s knowledge about the data available. We present: 1) a task analysis of HGML that shows the tasks that a user would want to carry out, 2) a characterization of two scientific publications, one in neuroscience and one in political science, in terms of how the authors would search for solutions using an AutoML system, 3) requirements for HGML based on those characterizations, and 4) an assessment of existing AutoML systems in terms of those requirements.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Gil, Yolanda and Honaker, James and Gupta, Shikhar and Ma, Yibo and D'Orazio, Vito and Garijo, Daniel and Gadewar, Shruti and Yang, Qifan and Jahanshad, Neda},
	month = mar,
	year = {2019},
	keywords = {comps-iui, iml},
	pages = {614--624},
}

@article{SurveyActiveLearningHumanintheLoop,
	title = {A {Survey} on {Active} {Learning} and {Human}-in-the-{Loop} {Deep} {Learning} for {Medical} {Image} {Analysis}},
	url = {http://arxiv.org/abs/1910.02923},
	abstract = {Fully automatic deep learning has become the state-of-the-art technique for many tasks including image acquisition, analysis and interpretation, and for the extraction of clinically useful information for computer-aided detection, diagnosis, treatment planning, intervention and therapy. However, the unique challenges posed by medical image analysis suggest that retaining a human end-user in any deep learning enabled system will be beneficial. In this review we investigate the role that humans might play in the development and deployment of deep learning enabled diagnostic applications and focus on techniques that will retain a significant input from a human end user. Human-in-the-Loop computing is an area that we see as increasingly important in future research due to the safety-critical nature of working in the medical domain. We evaluate four key areas that we consider vital for deep learning in the clinical practice: (1) Active Learning - to choose the best data to annotate for optimal model performance; (2) Interpretation and Refinement - using iterative feedback to steer models to optima for a given prediction and offering meaningful ways to interpret and respond to predictions; (3) Practical considerations - developing full scale applications and the key considerations that need to be made before deployment; (4) Related Areas - research fields that will benefit human-in-the-loop computing as they evolve. We offer our opinions on the most promising directions of research and how various aspects of each area might be unified towards common goals.},
	urldate = {2020-10-13},
	journal = {arXiv:1910.02923 [cs, eess]},
	author = {Budd, Samuel and Robinson, Emma C. and Kainz, Bernhard},
	month = oct,
	year = {2019},
	note = {arXiv: 1910.02923},
	keywords = {hil, survey},
}

@article{DoesTransparencyModerationReally,
	title = {Does {Transparency} in {Moderation} {Really} {Matter}?: {User} {Behavior} {After} {Content} {Removal} {Explanations} on {Reddit}},
	volume = {3},
	issn = {2573-0142, 2573-0142},
	shorttitle = {Does {Transparency} in {Moderation} {Really} {Matter}?},
	url = {https://dl.acm.org/doi/10.1145/3359252},
	doi = {10.1145/3359252},
	language = {en},
	number = {CSCW},
	urldate = {2020-10-13},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Jhaver, Shagun and Bruckman, Amy and Gilbert, Eric},
	month = nov,
	year = {2019},
	keywords = {explanation, fatml, xai},
	pages = {1--27},
}

@article{InteractiveMachineLearningData,
	title = {Interactive {Machine} {Learning} in {Data} {Exploitation}},
	volume = {15},
	issn = {1558-366X},
	doi = {10.1109/MCSE.2013.74},
	abstract = {The goal of interactive machine learning is to help scientists and engineers exploit more specialized data from within their deployed environment in less time, with greater accuracy and fewer costs. A basic introduction to the main components is provided here, untangling the many ideas that must be combined to produce practical interactive learning systems. This article also describes recent developments in machine learning that have significantly advanced the theoretical and practical foundations for the next generation of interactive tools.},
	number = {5},
	journal = {Computing in Science Engineering},
	author = {Porter, Reid and Theiler, James and Hush, Don},
	month = sep,
	year = {2013},
	note = {Conference Name: Computing in Science Engineering},
	keywords = {comps-iui, iml},
	pages = {12--20},
}

@article{IntelligentInterfaceLearningContent,
	title = {An {Intelligent} {Interface} for {Learning} {Content}: {Combining} an {Open} {Learner} {Model} and {Social} {Comparison} to {Support} {Self}-{Regulated} {Learning} and {Engagement}},
	abstract = {We present the Mastery Grids system, an intelligent interface for online learning content that combines open learner modeling (OLM) and social comparison features. We grounded the design of Mastery Grids in self-regulated learning and learning motivation theories, as well as in our past work in social comparison, OLM, and adaptive navigation support. The force behind the interface is the combination of adaptive navigation functionality with the mastery-oriented aspects of OLM and the performance-oriented aspects of social comparison. We examined different conﬁgurations of Mastery Grids in two classroom studies and report the results of analysis of log data and survey responses. The results show how Mastery Grids interacts with different factors, like gender and achievement-goal orientation, and ultimately, its impact on student engagement, performance, and motivation.},
	language = {en},
	author = {Guerra, Julio and Somyurek, Sibel and Hosseini, Roya and Brusilovsky, Peter},
	year = {2016},
	keywords = {comps-iui},
	pages = {12},
}

@inproceedings{RelevanceAdaptingExplorationExploitation,
	address = {Sonoma, California, USA},
	title = {Beyond {Relevance}: {Adapting} {Exploration}/{Exploitation} in {Information} {Retrieval}},
	isbn = {978-1-4503-4137-0},
	shorttitle = {Beyond {Relevance}},
	url = {http://dl.acm.org/citation.cfm?doid=2856767.2856786},
	doi = {10.1145/2856767.2856786},
	abstract = {We present a novel adaptation technique for search engines to better support information-seeking activities that include both lookup and exploratory tasks. Building on previous ﬁndings, we describe (1) a classiﬁer that recognizes task type (lookup vs. exploratory) as a user is searching and (2) a reinforcement learning based search engine that adapts accordingly the balance of exploration/exploitation in ranking the documents. This allows supporting both task types surreptitiously without changing the familiar list-based interface. Search results include more diverse results when users are exploring and more precise results for lookup tasks. Users found more useful results in exploratory tasks when compared to a baseline system, which is speciﬁcally tuned for lookup tasks.},
	language = {en},
	urldate = {2020-10-12},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '16},
	publisher = {ACM Press},
	author = {Athukorala, Kumaripaba and Medlar, Alan and Oulasvirta, Antti and Jacucci, Giulio and Glowacka, Dorota},
	year = {2016},
	keywords = {comps-iui},
	pages = {359--369},
}

@inproceedings{TagFlipActiveMobileMusic,
	address = {Sonoma, California, USA},
	title = {{TagFlip}: {Active} {Mobile} {Music} {Discovery} with {Social} {Tags}},
	isbn = {978-1-4503-4137-0},
	shorttitle = {{TagFlip}},
	url = {http://dl.acm.org/citation.cfm?doid=2856767.2856780},
	doi = {10.1145/2856767.2856780},
	abstract = {We report on the design and evaluation of TagFlip, a novel interface for active music discovery based on social tags of music. The tool, which was built for phone-sized screens, couples high user control on the recommended music with minimal interaction effort. Contrary to conventional recommenders, which only allow the speciﬁcation of seed attributes and the subsequent like/dislike of songs, we put the users in the centre of the recommendation process. With a library of 100,000 songs, TagFlip describes each played song to the user through its most popular tags on Last.fm and allows the user to easily specify which of the tags should be considered for the next song, or the next stream of songs. In a lab user study where we compared it to Spotify’s mobile application, TagFlip came out on top in both subjective user experience (control, transparency, and trust) and our objective measure of number of interactions per liked song. Our users found TagFlip to be an important complementary experience to that of Spotify, enabling more active and directed discovery sessions as opposed to the mostly passive experience that traditional recommenders offer.},
	language = {en},
	urldate = {2020-10-12},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '16},
	publisher = {ACM Press},
	author = {Kamalzadeh, Mohsen and Kralj, Christoph and Möller, Torsten and Sedlmair, Michael},
	year = {2016},
	keywords = {comps-iui},
	pages = {19--30},
}

@inproceedings{QuantifyingSearchBiasInvestigating,
	address = {Portland Oregon USA},
	title = {Quantifying {Search} {Bias}: {Investigating} {Sources} of {Bias} for {Political} {Searches} in {Social} {Media}},
	isbn = {978-1-4503-4335-0},
	shorttitle = {Quantifying {Search} {Bias}},
	url = {https://dl.acm.org/doi/10.1145/2998181.2998321},
	doi = {10.1145/2998181.2998321},
	abstract = {Search systems in online social media sites are frequently used to ﬁnd information about ongoing events and people. For topics with multiple competing perspectives, such as political events or political candidates, bias in the top ranked results signiﬁcantly shapes public opinion. However, bias does not emerge from an algorithm alone. It is important to distinguish between the bias that arises from the data that serves as the input to the ranking system and the bias that arises from the ranking system itself. In this paper, we propose a framework to quantify these distinct biases and apply this framework to politics-related queries on Twitter. We found that both the input data and the ranking system contribute signiﬁcantly to produce varying amounts of bias in the search results and in different ways. We discuss the consequences of these biases and possible mechanisms to signal this bias in social media search systems’ interfaces.},
	language = {en},
	urldate = {2020-10-12},
	booktitle = {Proceedings of the 2017 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} and {Social} {Computing}},
	publisher = {ACM},
	author = {Kulshrestha, Juhi and Eslami, Motahhare and Messias, Johnnatan and Zafar, Muhammad Bilal and Ghosh, Saptarshi and Gummadi, Krishna P. and Karahalios, Karrie},
	month = feb,
	year = {2017},
	keywords = {bias, comps-dm, fair, fatml},
	pages = {417--432},
}

@misc{25Pdf,
	title = {25.pdf},
	url = {https://drive.google.com/file/d/17G7jy_ibLk4aNDaRJnp70bePgrzESVr6/view?usp=sharing&usp=embed_facebook},
	urldate = {2020-10-12},
	journal = {Google Docs},
	keywords = {fatml, xai},
}

@misc{22Pdfa,
	title = {22.pdf},
	url = {https://drive.google.com/file/d/1ZuZUJSleUpsA7ddLzQeOaJUSRtFLRH4p/view?usp=embed_facebook},
	urldate = {2020-10-12},
	journal = {Google Docs},
	keywords = {fair, fatml},
}

@article{UnderstandingSocialComputingResearch,
	title = {Understanding {Social} {Computing} {Research}},
	volume = {15},
	issn = {1941-045X},
	doi = {10.1109/MITP.2012.121},
	abstract = {Social computing is an emerging field, encompassing a wide range of topics. A broad understanding of the major topics involved in social computing is important for both scholars and practitioners. The authors present and analyze the voluminous social computing related studies to date, applying document co-citation analysis, pathfinder networks, core-document analysis, and the Herfindahl-Hirschman index. The results not only provide insight to this subject area but also afford a conduit for the future research in this discipline.},
	number = {6},
	journal = {IT Professional},
	author = {Lee, M. R. and Chen, T. T.},
	month = nov,
	year = {2013},
	note = {Conference Name: IT Professional},
	keywords = {comps-sc},
	pages = {56--62},
}

@article{SupportingCommunicationCoordinationCollaborative,
	title = {Supporting {Communication} and {Coordination} in {Collaborative} {Sensemaking}},
	volume = {20},
	issn = {1077-2626},
	url = {http://ieeexplore.ieee.org/document/6875986/},
	doi = {10.1109/TVCG.2014.2346573},
	abstract = {When people work together to analyze a data set, they need to organize their ﬁndings, hypotheses, and evidence, share that information with their collaborators, and coordinate activities amongst team members. Sharing externalizations (recorded information such as notes) could increase awareness and assist with team communication and coordination. However, we currently know little about how to provide tool support for this sort of sharing. We explore how linked common work (LCW) can be employed within a ‘collaborative thinking space’, to facilitate synchronous collaborative sensemaking activities in Visual Analytics (VA). Collaborative thinking spaces provide an environment for analysts to record, organize, share and connect externalizations. Our tool, CLIP, extends earlier thinking spaces by integrating LCW features that reveal relationships between collaborators’ ﬁndings. We conducted a user study comparing CLIP to a baseline version without LCW. Results demonstrated that LCW signiﬁcantly improved analytic outcomes at a collaborative intelligence task. Groups using CLIP were also able to more effectively coordinate their work, and held more discussion of their ﬁndings and hypotheses. LCW enabled them to maintain awareness of each other’s activities and ﬁndings and link those ﬁndings to their own work, preventing disruptive oral awareness notiﬁcations.},
	language = {en},
	number = {12},
	urldate = {2020-10-23},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Mahyar, Narges and Tory, Melanie},
	month = dec,
	year = {2014},
	keywords = {comps-sc},
	pages = {1633--1642},
}

@inproceedings{UnderstandingInteractionInformationVisualization,
	title = {Towards the {Understanding} of {Interaction} in {Information} {Visualization}},
	doi = {10.1109/iV.2015.34},
	abstract = {Over the past few years the web has been responsible for the rise in popularity of visualizations and it seems that interactive or playable visualizations have become more popular and end up standing out more. The use of interactivity and animation has been extensively discussed in information visualization research, but there has been some controversy in relation to its benefits. Additionally, there is still little empirical evidence about its efficacy in terms of improving understanding of the data and there is few research that points out guidelines of how to incorporate it successfully and that proves that playable visualizations are indeed more enjoyable and popular among users. In order to guide future research on the actual benefits of interactivity in visualization it is important to understand what types of interactivity are currently being used in the field and to have a framework to help discuss and evaluate interaction techniques. After conducting an extensive review of popular visualizations and their interactive capabilities, we propose eleven categories of interaction techniques: filtering, selecting, abstract/elaborate, overview and explore, connect/relate, history, extraction of features, reconfigure, encode, participation/collaboration, and gamification.},
	booktitle = {2015 19th {International} {Conference} on {Information} {Visualisation}},
	author = {Figueiras, A.},
	month = jul,
	year = {2015},
	note = {ISSN: 2375-0138},
	keywords = {vis},
	pages = {140--147},
}

@inproceedings{VizCeptSupportingSynchronousCollaboration,
	title = {{VizCept}: {Supporting} synchronous collaboration for constructing visualizations in intelligence analysis},
	shorttitle = {{VizCept}},
	doi = {10.1109/VAST.2010.5652932},
	abstract = {In this paper, we present a new web-based visual analytics system, VizCept, which is designed to support fluid, collaborative analysis of large textual intelligence datasets. The main approach of the design is to combine individual workspace and shared visualization in an integrated environment. Collaborating analysts will be able to identify concepts and relationships from the dataset based on keyword searches in their own workspace and collaborate visually with other analysts using visualization tools such as a concept map view and a timeline view. The system allows analysts to parallelize the work by dividing initial sets of concepts, investigating them on their own workspace, and then integrating individual findings automatically on shared visualizations with support for interaction and personal graph layout in real time, in order to develop a unified plot. We highlight several design considerations that promote communication and analytic performance in small team synchronous collaboration. We report the result of a pair of case study applications including collaboration and communication methods, analysis strategies, and user behaviors under a competition setting in the same location at the same time. The results of these demonstrate the tool's effectiveness for synchronous collaborative construction and use of visualizations in intelligence data analysis.},
	booktitle = {2010 {IEEE} {Symposium} on {Visual} {Analytics} {Science} and {Technology}},
	author = {Chung, H. and Yang, S. and Massjouni, N. and Andrews, C. and Kanna, R. and North, C.},
	month = oct,
	year = {2010},
	pages = {107--114},
}

@article{PreventingFairnessGerrymanderingAuditing,
	title = {Preventing {Fairness} {Gerrymandering}:{Auditing} and {Learning} for {Subgroup} {Fairness}},
	abstract = {We introduce a new family of fairness deﬁnitions that interpolate between statistical and individual notions of fairness, obtaining some of the best properties of each. We show that checking whether these notions are satisﬁed is computationally hard in the worst case, but give practical oracle-efﬁcient algorithms for learning subject to these constraints, and conﬁrm our ﬁndings with experiments.},
	language = {en},
	author = {Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},
	keywords = {comps-dm, fair, fatml},
	pages = {9},
}

@article{AuditingAlgorithmsResearchMethods,
	title = {Auditing {Algorithms}: {Research} {Methods} for {Detecting} {Discrimination} on {Internet} {Platforms}},
	language = {en},
	author = {Sandvig, Christian and Hamilton, Kevin and Karahalios, Karrie and Langbort, Cedric},
	keywords = {comps-dm},
	pages = {23},
}

@article{ExplainableActiveLearningXAL,
	title = {Explainable {Active} {Learning} ({XAL}): {An} {Empirical} {Study} of {How} {Local} {Explanations} {Impact} {Annotator} {Experience}},
	shorttitle = {Explainable {Active} {Learning} ({XAL})},
	url = {http://arxiv.org/abs/2001.09219},
	abstract = {The wide adoption of Machine Learning technologies has created a rapidly growing demand for people who can train ML models. Some advocated the term "machine teacher" to refer to the role of people who inject domain knowledge into ML models. One promising learning paradigm is Active Learning (AL), by which the model intelligently selects instances to query the machine teacher for labels. However, in current AL settings, the human-AI interface remains minimal and opaque. We begin considering AI explanations as a core element of the human-AI interface for teaching machines. When a human student learns, it is a common pattern to present one's own reasoning and solicit feedback from the teacher. When a ML model learns and still makes mistakes, the human teacher should be able to understand the reasoning underlying the mistakes. When the model matures, the machine teacher should be able to recognize its progress in order to trust and feel confident about their teaching outcome. Toward this vision, we propose a novel paradigm of explainable active learning (XAL), by introducing techniques from the recently surging field of explainable AI (XAI) into an AL setting. We conducted an empirical study comparing the model learning outcomes, feedback content and experience with XAL, to that of traditional AL and coactive learning (providing the model's prediction without the explanation). Our study shows benefits of AI explanation as interfaces for machine teaching--supporting trust calibration and enabling rich forms of teaching feedback, and potential drawbacks--anchoring effect with the model judgment and cognitive workload. Our study also reveals important individual factors that mediate a machine teacher's reception to AI explanations, including task knowledge, AI experience and need for cognition. By reflecting on the results, we suggest future directions and design implications for XAL.},
	urldate = {2020-10-14},
	journal = {arXiv:2001.09219 [cs]},
	author = {Ghai, Bhavya and Liao, Q. Vera and Zhang, Yunfeng and Bellamy, Rachel and Mueller, Klaus},
	month = sep,
	year = {2020},
	note = {arXiv: 2001.09219},
	keywords = {active, fatml, xai},
}

@article{HumanTouchHowNonexpert,
	title = {The human touch: {How} non-expert users perceive, interpret, and fix topic models},
	volume = {105},
	issn = {10715819},
	shorttitle = {The human touch},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581917300472},
	doi = {10.1016/j.ijhcs.2017.03.007},
	abstract = {Topic modeling is a common tool for understanding large bodies of text, but is typically provided as a “take it or leave it” proposition. Incorporating human knowledge in unsupervised learning is a promising approach to create high-quality topic models. Existing interactive systems and modeling algorithms support a wide range of reﬁnement operations to express feedback. However, these systems’ interactions are primarily driven by algorithmic convenience, ignoring users who may lack expertise in topic modeling. To better understand how non-expert users understand, assess, and reﬁne topics, we conducted two user studies—an in-person interview study and an online crowdsourced study. These studies demonstrate a disconnect between what non-expert users want and the complex, low-level operations that current interactive systems support. In particular, our ﬁndings include: (1) analysis of how non-expert users perceive topic models; (2) characterization of primary reﬁnement operations expected by non-expert users and ordered by relative preference; (3) further evidence of the beneﬁts of supporting users in directly reﬁning a topic model; (4) design implications for future human-inthe-loop topic modeling interfaces.},
	language = {en},
	urldate = {2020-10-13},
	journal = {International Journal of Human-Computer Studies},
	author = {Lee, Tak Yeon and Smith, Alison and Seppi, Kevin and Elmqvist, Niklas and Boyd-Graber, Jordan and Findlater, Leah},
	month = sep,
	year = {2017},
	keywords = {comps-iui},
	pages = {28--42},
}

@article{HumanAICollaborationDataScience,
	title = {Human-{AI} {Collaboration} in {Data} {Science}: {Exploring} {Data} {Scientists}' {Perceptions} of {Automated} {AI}},
	volume = {3},
	issn = {2573-0142, 2573-0142},
	shorttitle = {Human-{AI} {Collaboration} in {Data} {Science}},
	url = {https://dl.acm.org/doi/10.1145/3359313},
	doi = {10.1145/3359313},
	abstract = {DAKUO WANG∗, IBM Research, USA JUSTIN D. WEISZ, IBM Research, USA MICHAEL MULLER, IBM Research, USA PARIKSHIT RAM, IBM Research, USA WERNER GEYER, IBM Research, USA CASEY DUGAN, IBM Research, USA YLA TAUSCZIK, University of Maryland, USA HORST SAMULOWITZ, IBM Research, USA ALEXANDER GRAY, IBM Research, USA The rapid advancement of artificial intelligence (AI) is changing our lives in many ways. One application domain is data science. New techniques in automating the creation of AI, known as AutoAI or AutoML, aim to automate the work practices of data scientists. AutoAI systems are capable of autonomously ingesting and pre-processing data, engineering new features, and creating and scoring models based on a target objectives (e.g. accuracy or run-time efficiency). Though not yet widely adopted, we are interested in understanding how AutoAI will impact the practice of data science. We conducted interviews with 20 data scientists who work at a large, multinational technology company and practice data science in various business settings. Our goal is to understand their current work practices and how these practices might change with AutoAI. Reactions were mixed: while informants expressed concerns about the trend of automating their jobs, they also strongly felt it was inevitable. Despite these concerns, they remained optimistic about their future job security due to a view that the future of data science work will be a collaboration between humans and AI systems, in which both automation and human expertise are indispensable. CCS Concepts: • Human-centered computing → Empirical studies in HCI; • Computing methodologies → Artificial intelligence; Machine learning.},
	language = {en},
	number = {CSCW},
	urldate = {2020-10-14},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Wang, Dakuo and Weisz, Justin D. and Muller, Michael and Ram, Parikshit and Geyer, Werner and Dugan, Casey and Tausczik, Yla and Samulowitz, Horst and Gray, Alexander},
	month = nov,
	year = {2019},
	keywords = {collaboration, comps-sc, sc},
	pages = {1--24},
}

@article{CollagenApplyingCollaborativeDiscourse,
	title = {Collagen: {Applying} {Collaborative} {Discourse} {Theory} to {Human}-{Computer} {Interaction}},
	language = {en},
	author = {Rich, Charles},
	keywords = {comps-sc},
	pages = {12},
}

@inproceedings{ApproachControllingUserModelsa,
	address = {Santa Monica, California, USA},
	title = {An approach to controlling user models and personalization effects in recommender systems},
	isbn = {978-1-4503-1965-2},
	url = {http://dl.acm.org/citation.cfm?doid=2449396.2449405},
	doi = {10.1145/2449396.2449405},
	abstract = {Personalization nowadays is a commodity in a broad spectrum of computer systems. Examples range from online shops recommending products identiﬁed based on the user’s previous purchases to web search engines sorting search hits based on the user’s browsing history. The aim of such adaptive behavior is to help users to ﬁnd relevant content easier and faster. However, there are a number of negative aspects of this behavior. Adaptive systems have been criticized for violating the usability principles of direct manipulation systems, namely controllability, predictability, transparency, and unobtrusiveness. In this paper, we propose an approach to controlling adaptive behavior in recommender systems. It allows users to get an overview of personalization effects, view the user proﬁle that is used for personalization, and adjust the proﬁle and personalization effects to their needs and preferences. We present this approach using an example of a personalized portal for biochemical literature, whose users are biochemists, biologists and genomicists. Also, we report on a user study evaluating the impact of controllable personalization on the usefulness, usability, user satisfaction, transparency, and trustworthiness of personalized systems.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {Proceedings of the 2013 international conference on {Intelligent} user interfaces - {IUI} '13},
	publisher = {ACM Press},
	author = {Bakalov, Fedor and Meurs, Marie-Jean and König-Ries, Birgitta and Sateli, Bahar and Witte, René and Butler, Greg and Tsang, Adrian},
	year = {2013},
	keywords = {comps-iui},
	pages = {49},
}

@inproceedings{NegativeRelevanceFeedbackExploratory,
	address = {Limassol Cyprus},
	title = {Negative {Relevance} {Feedback} for {Exploratory} {Search} with {Visual} {Interactive} {Intent} {Modeling}},
	isbn = {978-1-4503-4348-0},
	url = {https://dl.acm.org/doi/10.1145/3025171.3025222},
	doi = {10.1145/3025171.3025222},
	abstract = {In difﬁcult information seeking tasks, the majority of topranked documents for an initial query may be non-relevant, and negative relevance feedback may then help ﬁnd relevant documents. Traditional negative relevance feedback has been studied on document results; we introduce a system and interface for negative feedback in a novel exploratory search setting, where continuous-valued feedback is directly given to keyword features of an inferred probabilistic user intent model. The introduced system allows both positive and negative feedback directly on an interactive visual interface, by letting the user manipulate keywords on an optimized visualization of modeled user intent. Feedback on the interactive intent model lets the user direct the search: Relevance of keywords is estimated from feedback by Bayesian inference, inﬂuence of feedback is increased by a novel propagation step, documents are retrieved by likelihoods of relevant versus non-relevant intents, and the most relevant keywords (having the highest upper conﬁdence bounds of relevance) and the most non-relevant ones (having the smallest lower conﬁdence bounds of relevance) are shown as options for further feedback. We carry out task-based information seeking experiments with real users on difﬁcult real tasks; we compare the system to the nearest state of the art baseline allowing positive feedback only, and show negative feedback signiﬁcantly improves the quality of retrieved information and user satisfaction for difﬁcult tasks.},
	language = {en},
	urldate = {2020-10-13},
	booktitle = {Proceedings of the 22nd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Peltonen, Jaakko and Strahl, Jonathan and Floréen, Patrik},
	month = mar,
	year = {2017},
	keywords = {comps-iui, hil, iui, vis},
	pages = {149--159},
}

@article{PresentationSelfAgeSociala,
	title = {The {Presentation} of {Self} in the {Age} of {Social} {Media}: {Distinguishing} {Performances} and {Exhibitions} {Online}},
	volume = {30},
	issn = {0270-4676},
	shorttitle = {The {Presentation} of {Self} in the {Age} of {Social} {Media}},
	url = {https://doi.org/10.1177/0270467610385893},
	doi = {10.1177/0270467610385893},
	abstract = {Presentation of self (via Goffman) is becoming increasingly popular as a means for explaining differences in meaning and activity of online participation. This article argues that self-presentation can be split into performances, which take place in synchronous ?situations,? and artifacts, which take place in asynchronous ?exhibitions.? Goffman?s dramaturgical approach (including the notions of front and back stage) focuses on situations. Social media, on the other hand, frequently employs exhibitions, such as lists of status updates and sets of photos, alongside situational activities, such as chatting. A key difference in exhibitions is the virtual ?curator? that manages and redistributes this digital content. This article introduces the exhibitional approach and the curator and suggests ways in which this approach can extend present work concerning online presentation of self. It introduces a theory of ?lowest common denominator? culture employing the exhibitional approach.},
	number = {6},
	urldate = {2020-10-25},
	journal = {Bulletin of Science, Technology \& Society},
	author = {Hogan, Bernie},
	month = dec,
	year = {2010},
	note = {Publisher: SAGE Publications Inc},
	keywords = {comps-sc},
	pages = {377--386},
}

@article{CollaboratingTechnologybasedAutonomousAgentsa,
	title = {Collaborating with technology-based autonomous agents: {Issues} and research opportunities},
	volume = {30},
	issn = {1066-2243},
	shorttitle = {Collaborating with technology-based autonomous agents},
	url = {https://doi.org/10.1108/INTR-12-2019-0503},
	doi = {10.1108/INTR-12-2019-0503},
	abstract = {Purpose This article reports the results from a panel discussion held at the 2019 European Conference on Information Systems (ECIS) on the use of technology-based autonomous agents in collaborative work.Design/methodology/approach The panelists (Drs Izak Benbasat, Paul Benjamin Lowry, Stefan Morana, and Stefan Seidel) presented ideas related to affective and cognitive implications of using autonomous technology-based agents in terms of (1) emotional connection with these agents, (2) decision-making, and (3) knowledge and learning in settings with autonomous agents. These ideas provided the basis for a moderated panel discussion (the moderators were Drs Isabella Seeber and Lena Waizenegger), during which the initial position statements were elaborated on and additional issues were raised.Findings Through the discussion, a set of additional issues were identified. These issues related to (1) the design of autonomous technology-based agents in terms of human–machine workplace configurations, as well as transparency and explainability, and (2) the unintended consequences of using autonomous technology-based agents in terms of de-evolution of social interaction, prioritization of machine teammates, psychological health, and biased algorithms.Originality/value Key issues related to the affective and cognitive implications of using autonomous technology-based agents, design issues, and unintended consequences highlight key contemporary research challenges that allow researchers in this area to leverage compelling questions that can guide further research in this field.},
	number = {1},
	urldate = {2020-10-24},
	journal = {Internet Research},
	author = {Seeber, Isabella and Waizenegger, Lena and Seidel, Stefan and Morana, Stefan and Benbasat, Izak and Lowry, Paul Benjamin},
	month = jan,
	year = {2020},
	note = {Publisher: Emerald Publishing Limited},
	pages = {1--18},
}

@article{AccuracyRoleMentalModels,
	title = {Beyond {Accuracy}: {The} {Role} of {Mental} {Models} in {Human}-{AI} {Team} {Performance}},
	abstract = {Decisions made by human-AI teams (e.g., AI-advised humans) are increasingly common in high-stakes domains such as healthcare, criminal justice, and ﬁnance. Achieving high team performance depends on more than just the accuracy of the AI system: Since the human and the AI may have different expertise, the highest team performance is often reached when they both know how and when to complement one another. We focus on a factor that is crucial to supporting such complementary: the human’s mental model of the AI capabilities, speciﬁcally the AI system’s error boundary (i.e. knowing “When does the AI err?”). Awareness of this lets the human decide when to accept or override the AI’s recommendation. We highlight two key properties of an AI’s error boundary, parsimony and stochasticity, and a property of the task, dimensionality. We show experimentally how these properties affect humans’ mental models of AI capabilities and the resulting team performance. We connect our evaluations to related work and propose goals, beyond accuracy, that merit consideration during model selection and optimization to improve overall human-AI team performance.},
	language = {en},
	author = {Bansal, Gagan},
	keywords = {comps-sc},
	pages = {10},
}

@inproceedings{BelieveItNotDesigning,
	address = {Berlin, Germany},
	title = {Believe it or not: {Designing} a {Human}-{AI} {Partnership} for {Mixed}-{Initiative} {Fact}-{Checking}},
	isbn = {978-1-4503-5948-1},
	shorttitle = {Believe it or not},
	url = {http://dl.acm.org/citation.cfm?doid=3242587.3242666},
	doi = {10.1145/3242587.3242666},
	abstract = {Fact-checking, the task of assessing the veracity of claims, is an important, timely, and challenging problem. While many automated fact-checking systems have been recently proposed, the human side of the partnership has been largely neglected: how might people understand, interact with, and establish trust with an AI fact-checking system? Does such a system actually help people better assess the factuality of claims? In this paper, we present the design and evaluation of a mixed-initiative approach to fact-checking, blending human knowledge and experience with the efﬁciency and scalability of automated information retrieval and ML. In a user study in which participants used our system to aid their own assessment of claims, our results suggest that individuals tend to trust the system: participant accuracy assessing claims improved when exposed to correct model predictions. However, this trust perhaps goes too far: when the model was wrong, exposure to its predictions often degraded human accuracy. Participants given the option to interact with these incorrect predictions were often able improve their own performance. This suggests that transparent models are key to facilitating effective human interaction with fallible AI models.},
	language = {en},
	urldate = {2020-10-24},
	booktitle = {The 31st {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology} - {UIST} '18},
	publisher = {ACM Press},
	author = {Nguyen, An T. and Kharosekar, Aditya and Krishnan, Saumyaa and Krishnan, Siddhesh and Tate, Elizabeth and Wallace, Byron C. and Lease, Matthew},
	year = {2018},
	keywords = {comps-sc},
	pages = {189--199},
}

@incollection{UtilityLearningHumansHumanAI,
	title = {On the {Utility} of {Learning} about {Humans} for {Human}-{AI} {Coordination}},
	url = {http://papers.nips.cc/paper/8760-on-the-utility-of-learning-about-humans-for-human-ai-coordination.pdf},
	urldate = {2020-10-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {Carroll, Micah and Shah, Rohin and Ho, Mark K and Griffiths, Tom and Seshia, Sanjit and Abbeel, Pieter and Dragan, Anca},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d{\textbackslash}textquotesingle and Fox, E. and Garnett, R.},
	year = {2019},
	keywords = {hil},
	pages = {5174--5185},
}

@article{HelloAIUncoveringOnboarding,
	title = {"{Hello} {AI}": {Uncovering} the {Onboarding} {Needs} of {Medical} {Practitioners} for {Human}-{AI} {Collaborative} {Decision}-{Making}},
	volume = {3},
	issn = {2573-0142, 2573-0142},
	shorttitle = {"{Hello} {AI}"},
	url = {https://dl.acm.org/doi/10.1145/3359206},
	doi = {10.1145/3359206},
	language = {en},
	number = {CSCW},
	urldate = {2020-10-24},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Cai, Carrie J. and Winter, Samantha and Steiner, David and Wilcox, Lauren and Terry, Michael},
	month = nov,
	year = {2019},
	keywords = {comps-sc},
	pages = {1--24},
}

@article{PersonalVisualizationPersonalVisual,
	title = {Personal {Visualization} and {Personal} {Visual} {Analytics}},
	volume = {21},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2014.2359887},
	abstract = {Data surrounds each and every one of us in our daily lives, ranging from exercise logs, to archives of our interactions with others on social media, to online resources pertaining to our hobbies. There is enormous potential for us to use these data to understand ourselves better and make positive changes in our lives. Visualization (Vis) and visual analytics (VA) offer substantial opportunities to help individuals gain insights about themselves, their communities and their interests; however, designing tools to support data analysis in non-professional life brings a unique set of research and design challenges. We investigate the requirements and research directions required to take full advantage of Vis and VA in a personal context. We develop a taxonomy of design dimensions to provide a coherent vocabulary for discussing personal visualization and personal visual analytics. By identifying and exploring clusters in the design space, we discuss challenges and share perspectives on future research. This work brings together research that was previously scattered across disciplines. Our goal is to call research attention to this space and engage researchers to explore the enabling techniques and technology that will support people to better understand data relevant to their personal lives, interests, and needs.},
	number = {3},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Huang, D. and Tory, M. and Aseniero, B. Adriel and Bartram, L. and Bateman, S. and Carpendale, S. and Tang, A. and Woodbury, R.},
	month = mar,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {vis},
	pages = {420--433},
}

@article{DMapInteractiveVisualAnalysis,
	title = {D-{Map}+: {Interactive} {Visual} {Analysis} and {Exploration} of {Ego}-centric and {Event}-centric {Information} {Diffusion} {Patterns} in {Social} {Media}},
	volume = {10},
	issn = {2157-6904, 2157-6912},
	shorttitle = {D-{Map}+},
	url = {https://dl.acm.org/doi/10.1145/3183347},
	doi = {10.1145/3183347},
	language = {en},
	number = {1},
	urldate = {2020-10-24},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	author = {Chen, Siming and Chen, Shuai and Wang, Zhenhuang and Liang, Jie and Wu, Yadong and Yuan, Xiaoru},
	month = jan,
	year = {2019},
	keywords = {comps-sc},
	pages = {1--26},
}

@article{SocialVisualizationNegotiationEffects,
	title = {Social visualization and negotiation: effects of feedback configuration and status},
	abstract = {We describe a social visualization system that monitors the vocal arousal levels of the participants in a simulated twoparty employment negotiation. In a 3x2 factorial experiment (N = 84), we manipulate two variables of interest for social visualization systems: the feedback configuration of the system’s display (participants receive self feedback vs. partner feedback vs. no feedback) and the status of the interactants (high vs. low). Receiving feedback about one's own arousal level has negative consequences for performance in and feelings about the negotiation. Receiving feedback about one's partner's arousal level interacts with status: high-status individuals benefit from the visualization, while low-status individuals do not.},
	language = {en},
	author = {Nowak, Michael and Kim, Juho and Kim, Nam Wook and Nass, Clifford},
	year = {2012},
	pages = {10},
}

@inproceedings{DesigningTaskVisualizationsSupport,
	address = {Banff, Alberta, Canada},
	title = {Designing task visualizations to support the coordination of work in software development},
	isbn = {978-1-59593-249-5},
	url = {http://portal.acm.org/citation.cfm?doid=1180875.1180883},
	doi = {10.1145/1180875.1180883},
	abstract = {Software development tools primarily focus on supporting the technical work. Yet no matter the tools employed, the process followed, or the size of the team, important aspects of development are non-technical, and largely unsupported. For example, increasing distribution of development teams highlights the issues of coordination and cooperation. This paper focuses on one area: managing change requests. Interviews with industry and open-source programmers were used to create designs for the visual inspection of change requests. This paper presents fieldwork findings and two designs. We conclude by reflecting on the issues that task visualizations that support social inferences address in software development.},
	language = {en},
	urldate = {2020-10-24},
	booktitle = {Proceedings of the 2006 20th anniversary conference on {Computer} supported cooperative work  - {CSCW} '06},
	publisher = {ACM Press},
	author = {Halverson, Christine A. and Ellis, Jason B. and Danis, Catalina and Kellogg, Wendy A.},
	year = {2006},
	keywords = {comps-sc},
	pages = {39},
}

@article{HowDataScienceWorkers,
	title = {How do {Data} {Science} {Workers} {Collaborate}? {Roles}, {Workflows}, and {Tools}},
	volume = {4},
	issn = {2573-0142, 2573-0142},
	shorttitle = {How do {Data} {Science} {Workers} {Collaborate}?},
	url = {https://dl.acm.org/doi/10.1145/3392826},
	doi = {10.1145/3392826},
	language = {en},
	number = {CSCW1},
	urldate = {2020-10-24},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Zhang, Amy X. and Muller, Michael and Wang, Dakuo},
	month = may,
	year = {2020},
	keywords = {collaboration, comps-sc},
	pages = {1--23},
}

@article{NetworkDissectionQuantifyingInterpretability,
	title = {Network {Dissection}: {Quantifying} {Interpretability} of {Deep} {Visual} {Representations}},
	shorttitle = {Network {Dissection}},
	url = {http://arxiv.org/abs/1704.05796},
	abstract = {We propose a general framework called Network Dissection for quantifying the interpretability of latent representations of CNNs by evaluating the alignment between individual hidden units and a set of semantic concepts. Given any CNN model, the proposed method draws on a broad data set of visual concepts to score the semantics of hidden units at each intermediate convolutional layer. The units with semantics are given labels across a range of objects, parts, scenes, textures, materials, and colors. We use the proposed method to test the hypothesis that interpretability of units is equivalent to random linear combinations of units, then we apply our method to compare the latent representations of various networks when trained to solve different supervised and self-supervised training tasks. We further analyze the effect of training iterations, compare networks trained with different initializations, examine the impact of network depth and width, and measure the effect of dropout and batch normalization on the interpretability of deep visual representations. We demonstrate that the proposed method can shed light on characteristics of CNN models and training methods that go beyond measurements of their discriminative power.},
	urldate = {2020-10-24},
	journal = {arXiv:1704.05796 [cs]},
	author = {Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.05796},
	keywords = {dl, interpretable},
}

@inproceedings{HowRecommendUserTrusta,
	address = {Limassol Cyprus},
	title = {How to {Recommend}?: {User} {Trust} {Factors} in {Movie} {Recommender} {Systems}},
	isbn = {978-1-4503-4348-0},
	shorttitle = {How to {Recommend}?},
	url = {https://dl.acm.org/doi/10.1145/3025171.3025209},
	doi = {10.1145/3025171.3025209},
	abstract = {How much trust a user places in a recommender is crucial to the uptake of the recommendations. Although prior work established various factors that build and sustain user trust, their comparative impact has not been studied in depth. This paper presents the results of a crowdsourced study examining the impact of various recommendation interfaces and content selection strategies on user trust. It evaluates the subjective ranking of nine key factors of trust grouped into three dimensions and examines the diﬀerences observed with respect to users’ personality traits.},
	language = {en},
	urldate = {2020-11-05},
	booktitle = {Proceedings of the 22nd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Berkovsky, Shlomo and Taib, Ronnie and Conway, Dan},
	month = mar,
	year = {2017},
	keywords = {explanation, rec},
	pages = {287--300},
}

@inproceedings{DesignEvaluationSocialVisualization,
	title = {Design and {Evaluation} of a {Social} {Visualization} {Aimed} at {Encouraging} {Sustainable} {Behavior}},
	doi = {10.1109/HICSS.2010.135},
	abstract = {The environment is affected by our collective behavior, yet many visualizations of energy saving behavior focus on personal actions, or simple, unidimensional comparisons between individuals and groups. Based on past work in social psychology and in environmental visualization, we present a design space for social visualizations that considers issues such as anonymity, dimensionality, and competition vs. collaboration. We describe the design and implementation of a social visualization of energy saving behavior. This visualization goes beyond past examples in that it includes both uni-dimensional and multi-dimensional comparative feedback. It is designed to scale to a small group of dorms or a whole city. We evaluated our visualization in the context of a dorm competition at a small liberal arts college. While this was a preliminary study, it helps to provide formative data on the value of our visualization.},
	booktitle = {2010 43rd {Hawaii} {International} {Conference} on {System} {Sciences}},
	author = {Grevet, C. and Mankoff, J. and Anderson, S. D.},
	month = jan,
	year = {2010},
	note = {ISSN: 1530-1605},
	keywords = {comps-sc},
	pages = {1--8},
}

@article{ExplanationBasedTuningOpaqueMachine,
	title = {Explanation-{Based} {Tuning} of {Opaque} {Machine} {Learners} with {Application} to {Paper} {Recommendation}},
	url = {http://arxiv.org/abs/2003.04315},
	abstract = {Research in human-centered AI has shown the benefits of machine-learning systems that can explain their predictions. Methods that allow users to tune a model in response to the explanations are similarly useful. While both capabilities are well-developed for transparent learning models (e.g., linear models and GA2Ms), and recent techniques (e.g., LIME and SHAP) can generate explanations for opaque models, no method currently exists for tuning of opaque models in response to explanations. This paper introduces LIMEADE, a general framework for tuning an arbitrary machine learning model based on an explanation of the model's prediction. We apply our framework to Semantic Sanity, a neural recommender system for scientific papers, and report on a detailed user study, showing that our framework leads to significantly higher perceived user control, trust, and satisfaction.},
	urldate = {2020-10-26},
	journal = {arXiv:2003.04315 [cs, stat]},
	author = {Lee, Benjamin Charles Germain and Lo, Kyle and Downey, Doug and Weld, Daniel S.},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.04315},
	keywords = {comps-iui},
}

@article{UsercontrollablePersonalizationCaseStudy,
	title = {User-controllable personalization: {A} case study with {SetFusion}},
	volume = {78},
	issn = {10715819},
	shorttitle = {User-controllable personalization},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581915000208},
	doi = {10.1016/j.ijhcs.2015.01.007},
	abstract = {In this research we investigated the role of user controllability on personalized systems by implementing and studying a novel interactive recommender interface, SetFusion. We examined whether allowing the user to control the process of fusing or integrating different algorithms (i.e., different sources of relevance) resulted in increased engagement and a better user experience. The essential contribution of this research stems from the results of a user study (N ¼40) of controllability in a scenario where users could fuse different recommendation approaches, with the possibility of inspecting and ﬁltering the items recommended. First, we introduce an interactive Venn diagram visualization, which combined with sliders, can provide an efﬁcient visual paradigm for information ﬁltering. Second, we provide a three-fold evaluation of the user experience: objective metrics, subjective user perception, and behavioral measures. Through the analysis of these metrics, we conﬁrmed results from recent studies, such as the effect of trusting propensity on accepting the recommendations and also unveiled the importance of features such as being a native speaker. Our results present several implications for the design and implementation of user-controllable personalized systems.},
	language = {en},
	urldate = {2020-10-26},
	journal = {International Journal of Human-Computer Studies},
	author = {Parra, Denis and Brusilovsky, Peter},
	month = jun,
	year = {2015},
	keywords = {comps-iui},
	pages = {43--67},
}

@article{SystematicReviewSharedVisualisation,
	title = {A systematic review of shared visualisation to achieve common ground},
	volume = {28},
	issn = {1045926X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1045926X1400158X},
	doi = {10.1016/j.jvlc.2014.12.003},
	abstract = {This paper reports a systematic review of shared visualisation based on fifteen papers from 2000 to 2013. The findings identified five shared visualisation strategies that represent the ways implemented to process data sharing and knowledge to arrive at the desired level of understanding. Four visualisation techniques were also identified to show how shared cognition is made possible in designing tools for mediating data or knowledge among the users involved. These findings provide research opportunities in integrating rich interactive data visualisation for mobile-based technologies as an effective mean in supporting collaborative work. Finally, social, task and cognitive elements which can be significantly supported by shared visualisation and a guideline for future researchers seeking to design shared visualisation-based systems are presented.},
	language = {en},
	urldate = {2020-10-25},
	journal = {Journal of Visual Languages \& Computing},
	author = {Yusoff, Nor’ain Mohd and Salim, Siti Salwah},
	month = jun,
	year = {2015},
	keywords = {comps-sc},
	pages = {83--99},
}

@article{CollaborativeVisualizationDefinitionChallenges,
	title = {Collaborative visualization: {Definition}, challenges, and research agenda},
	volume = {10},
	issn = {1473-8716, 1473-8724},
	shorttitle = {Collaborative visualization},
	url = {http://journals.sagepub.com/doi/10.1177/1473871611412817},
	doi = {10.1177/1473871611412817},
	abstract = {The conflux of two growing areas of technology – collaboration and visualization – into a new research direction, collaborative visualization, provides new research challenges. Technology now allows us to easily connect and collaborate with one another – in settings as diverse as over networked computers, across mobile devices, or using shared displays such as interactive walls and tabletop surfaces. Digital information is now regularly accessed by multiple people in order to share information, to view it together, to analyze it, or to form decisions. Visualizations are used to deal more effectively with large amounts of information while interactive visualizations allow users to explore the underlying data. While researchers face many challenges in collaboration and in visualization, the emergence of collaborative visualization poses additional challenges, but it is also an exciting opportunity to reach new audiences and applications for visualization tools and techniques.},
	language = {en},
	number = {4},
	urldate = {2020-10-25},
	journal = {Information Visualization},
	author = {Isenberg, Petra and Elmqvist, Niklas and Scholtz, Jean and Cernea, Daniel and {Kwan-Liu Ma} and Hagen, Hans},
	month = oct,
	year = {2011},
	keywords = {comps-sc},
	pages = {310--326},
}

@article{DesignCollaborativeInformationSeekingUnderstanding,
	title = {Design for {Collaborative} {Information}-{Seeking}: {Understanding} {User} {Challenges} and {Deploying} {Collaborative} {Dynamic} {Queries}},
	volume = {3},
	issn = {2573-0142, 2573-0142},
	shorttitle = {Design for {Collaborative} {Information}-{Seeking}},
	url = {https://dl.acm.org/doi/10.1145/3359208},
	doi = {10.1145/3359208},
	language = {en},
	number = {CSCW},
	urldate = {2020-10-25},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Hong, Sungsoo (Ray) and Suh, Minhyang (Mia) and Kim, Tae Soo and Smoke, Irina and Sien, Sangwha and Ng, Janet and Zachry, Mark and Kim, Juho},
	month = nov,
	year = {2019},
	keywords = {comps-sc},
	pages = {1--24},
}

@article{MachinesTeammatesResearchAgendaa,
	title = {Machines as teammates: {A} research agenda on {AI} in team collaboration},
	volume = {57},
	issn = {03787206},
	shorttitle = {Machines as teammates},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378720619303337},
	doi = {10.1016/j.im.2019.103174},
	abstract = {What if artificial intelligence (AI) machines became teammates rather than tools? This paper reports on an international initiative by 65 collaboration scientists to develop a research agenda for exploring the potential risks and benefits of machines as teammates (MaT). They generated 819 research questions. A subteam of 12 converged them to a research agenda comprising three design areas – Machine artifact, Collaboration, and Institution – and 17 dualities – significant effects with the potential for benefit or harm. The MaT research agenda offers a structure and archetypal research questions to organize early thought and research in this new area of study.},
	language = {en},
	number = {2},
	urldate = {2020-10-25},
	journal = {Information \& Management},
	author = {Seeber, Isabella and Bittner, Eva and Briggs, Robert O. and de Vreede, Triparna and de Vreede, Gert-Jan and Elkins, Aaron and Maier, Ronald and Merz, Alexander B. and Oeste-Reiß, Sarah and Randrup, Nils and Schwabe, Gerhard and Söllner, Matthias},
	month = mar,
	year = {2020},
	keywords = {comps-sc},
	pages = {103174},
}

@inproceedings{StudyUserControllableSocialExploratory,
	address = {Tokyo, Japan},
	title = {A {Study} on {User}-{Controllable} {Social} {Exploratory} {Search}},
	isbn = {978-1-4503-4945-1},
	url = {http://dl.acm.org/citation.cfm?doid=3172944.3172986},
	doi = {10.1145/3172944.3172986},
	abstract = {Information-seeking tasks with learning or investigative purposes are usually referred to as exploratory search. Exploratory search unfolds as a dynamic process where the user, amidst navigation, trial-and-error and on-the-ﬂy selections, gathers and organizes information (resources). A range of innovative interfaces with increased user control have been developed to support exploratory search process. In this work we present our attempt to increase the power of exploratory search interfaces by using ideas of social search, i.e., leveraging information left by past users of information systems. Social search technologies are highly popular nowadays, especially for improving ranking. However, current approaches to social ranking do not allow users to decide to what extent social information should be taken into account for result ranking. This paper presents an interface that integrates social search functionality into an exploratory search system in a user-controlled way that is consistent with the nature of exploratory search. The interface incorporates control features that allow the user to (i) express information needs by selecting keywords and (ii) to express preferences for incorporating social wisdom based on tag matching and user similarity. The interface promotes search transparency through color-coded stacked bars and rich tooltips. In an online study investigating system accuracy and subjective aspects with a structural model we found that, when users actively interacted with all its control features, the hybrid system outperformed a baseline content-based-only tool and users were more satisﬁed.},
	language = {en},
	urldate = {2020-10-25},
	booktitle = {Proceedings of the 2018 {Conference} on {Human} {Information} {Interaction}\&{Retrieval} - {IUI} 18},
	publisher = {ACM Press},
	author = {di Sciascio, Cecilia and Brusilovsky, Peter and Veas, Eduardo},
	year = {2018},
	keywords = {comps-sc},
	pages = {353--364},
}

@incollection{IntroductionSocialInformationAccessa,
	title = {Introduction to {Social} {Information} {Access}},
	isbn = {978-3-319-90091-9},
	abstract = {This chapter offers an introduction to the emerging field of social information access. Social information access focuses on technologies that organize users past interaction with information in order to provide future users with better access to information. These technologies have become increasingly more popular in all areas of information access, including search, browsing, and recommendation. Starting with a definition of the new field and a brief history of social information access, this chapter introduces a multi-aspect classification of social information access technologies. The two important factors for our classification are the types of information access involved and the source of the social information that has been leveraged to support information access. These two factors are the angles we use in this chapter to create a map of the field, as well as to introduce the book structure and the role of the remaining book chapters in covering social information access topics and technologies.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Brusilovsky, Peter and He, Daqing},
	month = may,
	year = {2018},
	doi = {10.1007/978-3-319-90092-6_1},
	note = {Journal Abbreviation: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	keywords = {comps-sc},
	pages = {1--18},
}

@incollection{MotivationalSocialVisualizationsPersonalized,
	address = {Berlin, Heidelberg},
	title = {Motivational {Social} {Visualizations} for {Personalized} {E}-{Learning}},
	volume = {7563},
	isbn = {978-3-642-33262-3 978-3-642-33263-0},
	url = {http://link.springer.com/10.1007/978-3-642-33263-0_13},
	abstract = {A large number of educational resources is now available on the Web to support both regular classroom learning and online learning. However, the abundance of available content produces at least two problems: how to help students find the most appropriate resources, and how to engage them into using these resources and benefiting from them. Personalized and social learning have been suggested as potential methods for addressing these problems. Our work presented in this paper attempts to combine the ideas of personalized and social learning. We introduce Progressor+, an innovative Webbased interface that helps students find the most relevant resources in a large collection of self-assessment questions and programming examples. We also present the results of a classroom study of the Progressor+ in an undergraduate class. The data revealed the motivational impact of the personalized social guidance provided by the system in the target context. The interface encouraged students to explore more educational resources and motivated them to do some work ahead of the course schedule. The increase in diversity of explored content resulted in improving students’ problem solving success. A deeper analysis of the social guidance mechanism revealed that it is based on the leading behavior of the strong students, who discovered the most relevant resources and created trails for weaker students to follow. The study results also demonstrate that students were more engaged with the system: they spent more time in working with self-assessment questions and annotated examples, attempted more questions, and achieved higher success rates in answering them.},
	language = {en},
	urldate = {2020-10-25},
	booktitle = {21st {Century} {Learning} for 21st {Century} {Skills}},
	publisher = {Springer Berlin Heidelberg},
	author = {Hsiao, I. -Han and Brusilovsky, Peter},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Ravenscroft, Andrew and Lindstaedt, Stefanie and Kloos, Carlos Delgado and Hernández-Leo, Davinia},
	year = {2012},
	doi = {10.1007/978-3-642-33263-0_13},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {comps-sc},
	pages = {153--165},
}

@article{PromotingInsightBasedEvaluationVisualizations,
	title = {Promoting {Insight}-{Based} {Evaluation} of {Visualizations}: {From} {Contest} to {Benchmark} {Repository}},
	volume = {14},
	issn = {1941-0506},
	shorttitle = {Promoting {Insight}-{Based} {Evaluation} of {Visualizations}},
	doi = {10.1109/TVCG.2007.70412},
	abstract = {Information visualization (InfoVis) is now an accepted and growing field, but questions remain about the best uses for and the maturity of novel visualizations. Usability studies and controlled experiments are helpful, but generalization is difficult. We believe that the systematic development of benchmarks will facilitate the comparison of techniques and help identify their strengths under different conditions. We were involved in the organization and management of three InfoVis contests for the 2003, 2004, and 2005 IEEE InfoVis Symposia, which requested teams to report on insights gained while exploring data. We give a summary of the state of the art of evaluation in InfoVis, describe the three contests, summarize their results, discuss outcomes and lessons learned, and conjecture the future of visualization contests. All materials produced by the contests are archived in the InfoVis benchmark repository.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Plaisant, C. and Fekete, J. and Grinstein, G.},
	month = jan,
	year = {2008},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {eval, insight, vis},
	pages = {120--134},
}

@inproceedings{TasteWeightsVisualInteractiveHybrida,
	address = {Dublin, Ireland},
	title = {{TasteWeights}: a visual interactive hybrid recommender system},
	isbn = {978-1-4503-1270-7},
	shorttitle = {{TasteWeights}},
	url = {http://dl.acm.org/citation.cfm?doid=2365952.2365964},
	doi = {10.1145/2365952.2365964},
	abstract = {This paper presents an interactive hybrid recommendation system that generates item predictions from multiple social and semantic web resources, such as Wikipedia, Facebook, and Twitter. The system employs hybrid techniques from traditional recommender system literature, in addition to a novel interactive interface which serves to explain the recommendation process and elicit preferences from the end user. We present an evaluation that compares diﬀerent interactive and non-interactive hybrid strategies for computing recommendations across diverse social and semantic web APIs. Results of the study indicate that explanation and interaction with a visual representation of the hybrid system increase user satisfaction and relevance of predicted content.},
	language = {en},
	urldate = {2020-11-18},
	booktitle = {Proceedings of the sixth {ACM} conference on {Recommender} systems - {RecSys} '12},
	publisher = {ACM Press},
	author = {Bostandjiev, Svetlin and O'Donovan, John and Höllerer, Tobias},
	year = {2012},
	keywords = {comps-iui},
	pages = {35},
}

@article{MultiConVisVisualTextAnalytics,
	title = {{MultiConVis}: {A} {Visual} {Text} {Analytics} {System} for {Exploring} a {Collection} of {Online} {Conversations}},
	abstract = {Online conversations, such as blogs, provide rich amount of information and opinions about popular queries. Given a query, traditional blog sites return a set of conversations often consisting of thousands of comments with complex thread structure. Since the interfaces of these blog sites do not provide any overview of the data, it becomes very difﬁcult for the user to explore and analyze such a large amount of conversational data. In this paper, we present MultiConVis, a visual text analytics system designed to support the exploration of a collection of online conversations. Our system tightly integrates NLP techniques for topic modeling and sentiment analysis with information visualizations, by considering the unique characteristics of online conversations. The resulting interface supports the user exploration, starting from a possibly large set of conversations, then narrowing down to the subset of conversations, and eventually drilling-down to the set of comments of one conversation. Our evaluations through case studies with domain experts and a formal user study with regular blog readers illustrate the potential beneﬁts of our approach, when compared to a traditional blog reading interface.},
	language = {en},
	author = {Hoque, Enamul and Carenini, Giuseppe},
	year = {2016},
	keywords = {comps-iui},
	pages = {12},
}

@article{HowShouldExplainComparison,
	title = {How should {I} explain? {A} comparison of different explanation types for recommender systems},
	volume = {72},
	issn = {10715819},
	shorttitle = {How should {I} explain?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581913002024},
	doi = {10.1016/j.ijhcs.2013.12.007},
	abstract = {Recommender systems help users locate possible items of interest more quickly by ﬁltering and ranking them in a personalized way. Some of these systems provide the end user not only with such a personalized item list but also with an explanation which describes why a speciﬁc item is recommended and why the system supposes that the user will like it. Besides helping the user understand the output and rationale of the system, the provision of such explanations can also improve the general acceptance, perceived quality, or effectiveness of the system.},
	language = {en},
	number = {4},
	urldate = {2020-11-18},
	journal = {International Journal of Human-Computer Studies},
	author = {Gedikli, Fatih and Jannach, Dietmar and Ge, Mouzhi},
	month = apr,
	year = {2014},
	keywords = {comps-iui},
	pages = {367--382},
}

@inproceedings{UserPreferencesHybridExplanations,
	address = {Como Italy},
	title = {User {Preferences} for {Hybrid} {Explanations}},
	isbn = {978-1-4503-4652-8},
	url = {https://dl.acm.org/doi/10.1145/3109859.3109915},
	doi = {10.1145/3109859.3109915},
	abstract = {Hybrid recommender systems combine several di erent sources of information to generate recommendations. These systems demonstrate improved accuracy compared to single-source recommendation strategies. However, hybrid recommendation strategies are inherently more complex than those that use a single source of information, and thus the process of explaining recommendations to users becomes more challenging. In this paper we describe a hybrid recommender system built on a probabilistic programming language, and discuss the bene ts and challenges of explaining its recommendations to users. We perform a mixed model statistical analysis of user preferences for explanations in this system. Through an online user survey, we evaluate explanations for hybrid algorithms in a variety of text and visual, graph-based formats, that are either novel designs or derived from existing hybrid recommender systems.},
	language = {en},
	urldate = {2020-11-18},
	booktitle = {Proceedings of the {Eleventh} {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {ACM},
	author = {Kouki, Pigi and Schaffer, James and Pujara, Jay and O'Donovan, John and Getoor, Lise},
	month = aug,
	year = {2017},
	keywords = {comps-iui},
	pages = {84--88},
}

@inproceedings{SurveyExplanationsRecommenderSystems,
	title = {A {Survey} of {Explanations} in {Recommender} {Systems}},
	doi = {10.1109/ICDEW.2007.4401070},
	abstract = {This paper provides a comprehensive review of explanations in recommender systems. We highlight seven possible advantages of an explanation facility, and describe how existing measures can be used to evaluate the quality of explanations. Since explanations are not independent of the recommendation process, we consider how the ways recommendations are presented may affect explanations. Next, we look at different ways of interacting with explanations. The paper is illustrated with examples of explanations throughout, where possible from existing applications.},
	booktitle = {2007 {IEEE} 23rd {International} {Conference} on {Data} {Engineering} {Workshop}},
	author = {Tintarev, N. and Masthoff, J.},
	month = apr,
	year = {2007},
	keywords = {comps-iui},
	pages = {801--810},
}

@article{VizRecRecommendingPersonalizedVisualizations,
	title = {{VizRec}: {Recommending} {Personalized} {Visualizations}},
	volume = {6},
	issn = {2160-6455, 2160-6463},
	shorttitle = {{VizRec}},
	url = {https://dl.acm.org/doi/10.1145/2983923},
	doi = {10.1145/2983923},
	language = {en},
	number = {4},
	urldate = {2020-11-16},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Mutlu, Belgin and Veas, Eduardo and Trattner, Christoph},
	month = dec,
	year = {2016},
	keywords = {comps-iui, rec},
	pages = {1--39},
}

@article{DataOthersEyesImpact,
	title = {Data {Through} {Others}' {Eyes}: {The} {Impact} of {Visualizing} {Others}' {Expectations} on {Visualization} {Interpretation}},
	volume = {24},
	issn = {1941-0506},
	shorttitle = {Data {Through} {Others}' {Eyes}},
	doi = {10.1109/TVCG.2017.2745240},
	abstract = {In addition to visualizing input data, interactive visualizations have the potential to be social artifacts that reveal other people's perspectives on the data. However, how such social information embedded in a visualization impacts a viewer's interpretation of the data remains unknown. Inspired by recent interactive visualizations that display people's expectations of data against the data, we conducted a controlled experiment to evaluate the effect of showing social information in the form of other people's expectations on people's ability to recall the data, the degree to which they adjust their expectations to align with the data, and their trust in the accuracy of the data. We found that social information that exhibits a high degree of consensus lead participants to recall the data more accurately relative to participants who were exposed to the data alone. Additionally, participants trusted the accuracy of the data less and were more likely to maintain their initial expectations when other people's expectations aligned with their own initial expectations but not with the data. We conclude by characterizing the design space for visualizing others' expectations alongside data.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Kim, Y. and Reinecke, K. and Hullman, J.},
	month = jan,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {comps-sc},
	pages = {760--769},
}

@incollection{CodeSawSocialVisualizationDistributed,
	address = {Berlin, Heidelberg},
	title = {{CodeSaw}: {A} {Social} {Visualization} of {Distributed} {Software} {Development}},
	volume = {4663},
	isbn = {978-3-540-74799-4 978-3-540-74800-7},
	shorttitle = {{CodeSaw}},
	url = {http://link.springer.com/10.1007/978-3-540-74800-7_25},
	abstract = {We present CodeSaw, a social visualization of distributed software development. CodeSaw visualizes a distributed software community from two important and independent perspectives: code repositories and project communication. By bringing together both shared artifacts (code) and the talk surrounding those artifacts (project mail), CodeSaw reveals group dynamics that lie buried in existing technologies. This paper describes the visualization and its design process. We apply CodeSaw to a popular open source project, showing how the visualization reveals group dynamics and individual roles. The paper ends with a discussion of the results of an online ﬁeld study with prominent open source developers. The ﬁeld study suggests that CodeSaw positively affects communities and provides incentives to distributed developers. Furthermore, an important design lesson from the ﬁeld study leads us to introduce a novel interaction technique for social visualization called spatial messaging.},
	language = {en},
	urldate = {2020-11-09},
	booktitle = {Human-{Computer} {Interaction} – {INTERACT} 2007},
	publisher = {Springer Berlin Heidelberg},
	author = {Gilbert, Eric and Karahalios, Karrie},
	editor = {Baranauskas, Cécilia and Palanque, Philippe and Abascal, Julio and Barbosa, Simone Diniz Junqueira},
	year = {2007},
	doi = {10.1007/978-3-540-74800-7_25},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {comps-sc},
	pages = {303--316},
}

@article{PresentationSelfAgeSocial,
	title = {The {Presentation} of {Self} in the {Age} of {Social} {Media}: {Distinguishing} {Performances} and {Exhibitions} {Online}},
	volume = {30},
	issn = {0270-4676, 1552-4183},
	shorttitle = {The {Presentation} of {Self} in the {Age} of {Social} {Media}},
	url = {http://journals.sagepub.com/doi/10.1177/0270467610385893},
	doi = {10.1177/0270467610385893},
	abstract = {Presentation of self (via Goffman) is becoming increasingly popular as a means for explaining differences in meaning and activity of online participation. This article argues that self-presentation can be split into performances, which take place in synchronous “situations,” and artifacts, which take place in asynchronous “exhibitions.” Goffman’s dramaturgical approach (including the notions of front and back stage) focuses on situations. Social media, on the other hand, frequently employs exhibitions, such as lists of status updates and sets of photos, alongside situational activities, such as chatting. A key difference in exhibitions is the virtual “curator” that manages and redistributes this digital content. This article introduces the exhibitional approach and the curator and suggests ways in which this approach can extend present work concerning online presentation of self. It introduces a theory of “lowest common denominator” culture employing the exhibitional approach.},
	language = {en},
	number = {6},
	urldate = {2020-11-06},
	journal = {Bulletin of Science, Technology \& Society},
	author = {Hogan, Bernie},
	month = dec,
	year = {2010},
	keywords = {comps-sc},
	pages = {377--386},
}

@inproceedings{ProbabilisticHumanComputerTrustHandling,
	address = {Philadelphia, PA, U.S.A.},
	title = {Probabilistic {Human}-{Computer} {Trust} {Handling}},
	url = {https://www.aclweb.org/anthology/W14-4307},
	doi = {10.3115/v1/W14-4307},
	urldate = {2020-11-05},
	booktitle = {Proceedings of the 15th {Annual} {Meeting} of the {Special} {Interest} {Group} on {Discourse} and {Dialogue} ({SIGDIAL})},
	publisher = {Association for Computational Linguistics},
	author = {Nothdurft, Florian and Richter, Felix and Minker, Wolfgang},
	month = jun,
	year = {2014},
	keywords = {explanation},
	pages = {51--59},
}

@article{ExplainableRecommendationSurveyNew,
	title = {Explainable {Recommendation}: {A} {Survey} and {New} {Perspectives}},
	volume = {14},
	issn = {1554-0669, 1554-0677},
	shorttitle = {Explainable {Recommendation}},
	url = {http://arxiv.org/abs/1804.11192},
	doi = {10.1561/1500000066},
	abstract = {Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model (also called interpretable or transparent model in some contexts). Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helps to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation systems. It also facilitates system designers for better system debugging. In recent years, a large number of explainable recommendation approaches -- especially model-based methods -- have been proposed and applied in real-world systems. In this survey, we provide a comprehensive review for the explainable recommendation research. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research. 3) We summarize how explainable recommendation applies to different recommendation tasks. We also devote a chapter to discuss the explanation perspectives in broader IR and AI/ML research. We end the survey by discussing potential future directions to promote the explainable recommendation research area and beyond.},
	number = {1},
	urldate = {2020-12-08},
	journal = {Foundations and Trends® in Information Retrieval},
	author = {Zhang, Yongfeng and Chen, Xu},
	year = {2020},
	note = {arXiv: 1804.11192},
	keywords = {fatml, rec, survey, xai},
	pages = {1--101},
}

@inproceedings{ControllableExplanationGenerationRecommender,
	address = {Taipei Taiwan},
	title = {Towards {Controllable} {Explanation} {Generation} for {Recommender} {Systems} via {Neural} {Template}},
	isbn = {978-1-4503-7024-0},
	url = {https://dl.acm.org/doi/10.1145/3366424.3383540},
	doi = {10.1145/3366424.3383540},
	abstract = {It has been commonly agreed that the explanation associated with recommendation can be effective in increasing the recommender systems (RS)’s transparency and thus users’ satisfaction and acceptance. Among the various types of explanation in RS, the commonly used textual explanation can be roughly classified into two categories, i.e., template-based and generation-based. As for the former, the fixed template may lose flexibility, while, though the latter may enrich the explanation, it may produce less useful content due to the lack of controllability. In this work, we combine the advantages of the two types of method by developing a neural generation approach named Neural Template (NETE) whose explanations are not only flexible but also controllable and useful. Our human evaluation results confirm that the explanations from our model are perceived helpful by users. Furthermore, our case study illustrates that the explanation generation process is controllable. To demonstrate the controllability of our model, we present a demo that can be easily viewed on a Web browser.},
	language = {en},
	urldate = {2020-12-08},
	booktitle = {Companion {Proceedings} of the {Web} {Conference} 2020},
	publisher = {ACM},
	author = {Li, Lei and Chen, Li and Zhang, Yongfeng},
	month = apr,
	year = {2020},
	keywords = {comps-iui, fatml, rec, xai},
	pages = {198--202},
}

@article{SocialInformationAccessOther,
	title = {Social {Information} {Access}: {The} {Other} {Side} of the {Social} {Web}},
	abstract = {Modern Web, which is frequently called Social Web or Web 2.0, celebrates the power of the user community. Most frequently it is associated with the power of users as contributors or various kinds of contents through Wikis, blogs, and resource sharing sites. However, the community power impacts not only the production of Web content, but also the access to all kinds of Web content. A number of research groups worldwide work on social information access techniques, which help users get to the right information using “community wisdom” distilled from tracked actions of those who worked with this information earlier. The paper provides an overview of this research stream focusing on social search, social navigation, and social visualization techniques.},
	language = {en},
	author = {Brusilovsky, Peter},
	keywords = {comps-sc},
	pages = {18},
}

@article{MultidisciplinarySurveyFrameworkDesign,
	title = {A {Multidisciplinary} {Survey} and {Framework} for {Design} and {Evaluation} of {Explainable} {AI} {Systems}},
	volume = {1},
	language = {en},
	number = {1},
	author = {Mohseni, Sina and Zarei, Niloofar and Ragan, Eric D},
	keywords = {comps-dm, explanation, fatml, hci, survey, xai},
	pages = {46},
}

@article{ObservationLevelParametricInteractionHighDimensional,
	title = {Observation-{Level} and {Parametric} {Interaction} for {High}-{Dimensional} {Data} {Analysis}},
	volume = {8},
	language = {en},
	number = {2},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Self, Jessica Zeitz and Dowling, Michelle and Wenskovitch, John and Crandell, Ian and Wang, Ming and House, Leanna and Leman, Scotland and North, Chris},
	pages = {36},
}

@inproceedings{RankYouGoUserDriven,
	address = {Sonoma, California, USA},
	title = {Rank {As} {You} {Go}: {User}-{Driven} {Exploration} of {Search} {Results}},
	isbn = {978-1-4503-4137-0},
	shorttitle = {Rank {As} {You} {Go}},
	url = {http://dl.acm.org/citation.cfm?doid=2856767.2856797},
	doi = {10.1145/2856767.2856797},
	abstract = {Whenever users engage in gathering and organizing new information, searching and browsing activities emerge at the core of the exploration process. As the process unfolds and new knowledge is acquired, interest drifts occur inevitably and need to be accounted for. Despite the advances in retrieval and recommender algorithms, real-world interfaces have remained largely unchanged: results are delivered in a relevance-ranked list. However, it quickly becomes cumbersome to reorganize resources along new interests, as any new search brings new results. We introduce uRank and investigate interactive methods for understanding, reﬁning and reorganizing documents on-the-ﬂy as information needs evolve. uRank includes views summarizing the contents of a recommendation set and interactive methods conveying the role of users’ interests through a recommendation ranking. A formal evaluation showed that gathering items relevant to a particular topic of interest with uRank incurs in lower cognitive load compared to a traditional ranked list. A second study consisting in an ecological validation reports on usage patterns and usability of the various interaction techniques within a free, more natural setting.},
	language = {en},
	urldate = {2020-12-03},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Intelligent} {User} {Interfaces} - {IUI} '16},
	publisher = {ACM Press},
	author = {di Sciascio, Cecilia and Sabol, Vedran and Veas, Eduardo E.},
	year = {2016},
	keywords = {comps-iui},
	pages = {118--129},
}

@inproceedings{ExplainingRecommendationsBasedFeature,
	address = {Limassol Cyprus},
	title = {Explaining {Recommendations} {Based} on {Feature} {Sentiments} in {Product} {Reviews}},
	isbn = {978-1-4503-4348-0},
	url = {https://dl.acm.org/doi/10.1145/3025171.3025173},
	doi = {10.1145/3025171.3025173},
	abstract = {The explanation interface has been recognized important in recommender systems as it can help users evaluate recommendations in a more informed way for deciding which ones are relevant to their interests. In different decision environments, the speciﬁc aim of explanation can be different. In highinvestment product domains (e.g., digital cameras, laptops) for which users usually attempt to avoid ﬁnancial risk, how to support users to construct stable preferences and make better decisions is particularly crucial. In this paper, we propose a novel explanation interface that emphasizes explaining the tradeoff properties within a set of recommendations in terms of both their static speciﬁcations and feature sentiments extracted from product reviews. The objective is to assist users in more effectively exploring and understanding product space, and being able to better formulate their preferences for products by learning from other customers’ experiences. Through two user studies (in form of both before-after and within-subjects experiments), we empirically identify the practical role of feature sentiments in combination with static speciﬁcations in producing tradeoff-oriented explanations. Speciﬁcally, we ﬁnd that our explanation interface can be more effective to increase users’ product knowledge, preference certainty, perceived information usefulness, recommendation transparency and quality, and purchase intention.},
	language = {en},
	urldate = {2020-12-03},
	booktitle = {Proceedings of the 22nd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Chen, Li and Wang, Feng},
	month = mar,
	year = {2017},
	pages = {17--28},
}

@inproceedings{WebscaleSystemScientificKnowledge,
	address = {Melbourne, Australia},
	title = {A {Web}-scale system for scientific knowledge exploration},
	url = {https://www.aclweb.org/anthology/P18-4015},
	doi = {10.18653/v1/P18-4015},
	abstract = {To enable efficient exploration of Web-scale scientific knowledge, it is necessary to organize scientific publications into a hierarchical concept structure. In this work, we present a large-scale system to (1) identify hundreds of thousands of scientific concepts, (2) tag these identified concepts to hundreds of millions of scientific publications by leveraging both text and graph structure, and (3) build a six-level concept hierarchy with a subsumption-based model. The system builds the most comprehensive cross-domain scientific concept ontology published to date, with more than 200 thousand concepts and over one million relationships.},
	urldate = {2020-12-02},
	booktitle = {Proceedings of {ACL} 2018, {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Shen, Zhihong and Ma, Hao and Wang, Kuansan},
	month = jul,
	year = {2018},
	pages = {87--92},
}

@article{ReviewMicrosoftAcademicServices,
	title = {A {Review} of {Microsoft} {Academic} {Services} for {Science} of {Science} {Studies}},
	volume = {2},
	issn = {2624-909X},
	url = {https://www.frontiersin.org/article/10.3389/fdata.2019.00045/full},
	doi = {10.3389/fdata.2019.00045},
	abstract = {Since the relaunch of Microsoft Academic Services (MAS) 4 years ago, scholarly communications have undergone dramatic changes: more ideas are being exchanged online, more authors are sharing their data, and more software tools used to make discoveries and reproduce the results are being distributed openly. The sheer amount of information available is overwhelming for individual humans to keep up and digest. In the meantime, artiﬁcial intelligence (AI) technologies have made great strides and the cost of computing has plummeted to the extent that it has become practical to employ intelligent agents to comprehensively collect and analyze scholarly communications. MAS is one such effort and this paper describes its recent progresses since the last disclosure. As there are plenty of independent studies afﬁrming the effectiveness of MAS, this paper focuses on the use of three key AI technologies that underlies its prowess in capturing scholarly communications with adequate quality and broad coverage: (1) natural language understanding in extracting factoids from individual articles at the web scale, (2) knowledge assisted inference and reasoning in assembling the factoids into a knowledge graph, and (3) a reinforcement learning approach to assessing scholarly importance for entities participating in scholarly communications, called the saliency, that serves both as an analytic and a predictive metric in MAS. These elements enhance the capabilities of MAS in supporting the studies of science of science based on the GOTO principle, i.e., good and open data with transparent and objective methodologies. The current direction of development and how to access the regularly updated data and tools from MAS, including the knowledge graph, a REST API and a website, are also described.},
	language = {en},
	urldate = {2020-12-02},
	journal = {Frontiers in Big Data},
	author = {Wang, Kuansan and Shen, Zhihong and Huang, Chiyuan and Wu, Chieh-Han and Eide, Darrin and Dong, Yuxiao and Qian, Junjie and Kanakia, Anshul and Chen, Alvin and Rogahn, Richard},
	month = dec,
	year = {2019},
	pages = {45},
}

@inproceedings{OverviewMicrosoftAcademicService,
	address = {Florence, Italy},
	title = {An {Overview} of {Microsoft} {Academic} {Service} ({MAS}) and {Applications}},
	isbn = {978-1-4503-3473-0},
	url = {http://dl.acm.org/citation.cfm?doid=2740908.2742839},
	doi = {10.1145/2740908.2742839},
	abstract = {In this paper we describe a new release of a Web scale entity graph that serves as the backbone of Microsoft Academic Service (MAS), a major production effort with a broadened scope to the namesake vertical search engine that has been publicly available since 2008 as a research prototype. At the core of MAS is a heterogeneous entity graph comprised of six types of entities that model the scholarly activities: ﬁeld of study, author, institution, paper, venue, and event. In addition to obtaining these entities from the publisher feeds as in the previous effort, we in this version include data mining results from the Web index and an in-house knowledge base from Bing, a major commercial search engine. As a result of the Bing integration, the new MAS graph sees signiﬁcant increase in size, with fresh information streaming in automatically following their discoveries by the search engine. In addition, the rich entity relations included in the knowledge base provide additional signals to disambiguate and enrich the entities within and beyond the academic domain. The number of papers indexed by MAS, for instance, has grown from low tens of millions to 83 million while maintaining an above 95\% accuracy based on test data sets derived from academic activities at Microsoft Research. Based on the data set, we demonstrate two scenarios in this work: a knowledge driven, highly interactive dialog that seamlessly combines reactive search and proactive suggestion experience, and a proactive heterogeneous entity recommendation.},
	language = {en},
	urldate = {2020-12-02},
	booktitle = {Proceedings of the 24th {International} {Conference} on {World} {Wide} {Web} - {WWW} '15 {Companion}},
	publisher = {ACM Press},
	author = {Sinha, Arnab and Shen, Zhihong and Song, Yang and Ma, Hao and Eide, Darrin and Hsu, Bo-June (Paul) and Wang, Kuansan},
	year = {2015},
	pages = {243--246},
}

@article{RoadmapUserControllableSocialExploratory,
	title = {A {Roadmap} to {User}-{Controllable} {Social} {Exploratory} {Search}},
	volume = {10},
	issn = {2160-6455, 2160-6463},
	url = {https://dl.acm.org/doi/10.1145/3241382},
	doi = {10.1145/3241382},
	abstract = {To blend exploratory and social search, we replicate features of uRank [21], an adaptive system designed for exploratory search of textual documents. The basic system promotes a search-bybrowsing information access paradigm, using keywords extracted from search results as interactors to refine a document ranking on evolving information needs.},
	language = {en},
	number = {1},
	urldate = {2020-12-01},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Sciascio, Cecilia Di and Brusilovsky, Peter and Trattner, Christoph and Veas, Eduardo},
	month = jan,
	year = {2020},
	keywords = {comps-iui},
	pages = {1--38},
}

@article{InteractiveRecommenderSystemsSurvey,
	title = {Interactive recommender systems: {A} survey of the state of the art and future research challenges and opportunities},
	volume = {56},
	issn = {09574174},
	shorttitle = {Interactive recommender systems},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417416300367},
	doi = {10.1016/j.eswa.2016.02.013},
	language = {en},
	urldate = {2020-12-01},
	journal = {Expert Systems with Applications},
	author = {He, Chen and Parra, Denis and Verbert, Katrien},
	month = sep,
	year = {2016},
	keywords = {comps-iui, iml},
	pages = {9--27},
}

@inproceedings{ChoicebasedPreferenceElicitationCollaborative,
	address = {Toronto, Ontario, Canada},
	title = {Choice-based preference elicitation for collaborative filtering recommender systems},
	isbn = {978-1-4503-2473-1},
	url = {http://dl.acm.org/citation.cfm?doid=2556288.2557069},
	doi = {10.1145/2556288.2557069},
	abstract = {We present an approach to interactive recommending that combines the advantages of algorithmic techniques with the benefits of user-controlled, interactive exploration in a novel manner. The method extracts latent factors from a matrix of user rating data as commonly used in Collaborative Filtering, and generates dialogs in which the user iteratively chooses between two sets of sample items. Samples are chosen by the system for low and high values of each latent factor considered. The method positions the user in the latent factor space with few interaction steps, and finally selects items near the user position as recommendations.},
	language = {en},
	urldate = {2020-12-12},
	booktitle = {Proceedings of the 32nd annual {ACM} conference on {Human} factors in computing systems - {CHI} '14},
	publisher = {ACM Press},
	author = {Loepp, Benedikt and Hussein, Tim and Ziegler, Jüergen},
	year = {2014},
	keywords = {comps-iui},
	pages = {3085--3094},
}

@inproceedings{SignpostMassesLearningEffects,
	address = {Boston, MA, USA},
	title = {Signpost from the masses: learning effects in an exploratory social tag search browser},
	isbn = {978-1-60558-246-7},
	shorttitle = {Signpost from the masses},
	url = {http://dl.acm.org/citation.cfm?doid=1518701.1518797},
	doi = {10.1145/1518701.1518797},
	abstract = {Social tagging arose out of the need to organize found content that is worth revisiting. A significant side effect has been the use of social tagging sites as navigational signposts for interesting content. The collective behavior of users who tagged contents seems to offer a good basis for exploratory search interfaces, even for users who are not using social bookmarking sites. In this paper, we present the design of a tag-based exploratory system and detail an experiment in understanding its effectiveness. The tagbased search system allows users to utilize relevance feedback on tags to indicate their interest in various topics, enabling rapid exploration of the topic space. The experiment shows that the system seems to provide a kind of scaffold for users to learn new topics.},
	language = {en},
	urldate = {2020-12-12},
	booktitle = {Proceedings of the 27th international conference on {Human} factors in computing systems - {CHI} 09},
	publisher = {ACM Press},
	author = {Kammerer, Yvonne and Nairn, Rowan and Pirolli, Peter and Chi, Ed H.},
	year = {2009},
	keywords = {comps-iui},
	pages = {625},
}

@inproceedings{DiversityDonutEnablingParticipant,
	address = {Vancouver, BC, Canada},
	title = {The diversity donut: enabling participant control over the diversity of recommended responses},
	isbn = {978-1-4503-0268-5},
	shorttitle = {The diversity donut},
	url = {http://portal.acm.org/citation.cfm?doid=1979742.1979793},
	doi = {10.1145/1979742.1979793},
	abstract = {Most online discussion interfaces organize textual responses using linear lists. Such lists do not scale to the number of responses and cannot convey the diversity of the participants who have contributed. The Opinion Space system is designed to address these issues. In this paper, we augment Opinion Space with two features. The first is a new user interface tool and recommendation system: the Diversity Donut (Figure 1). While the Diversity Donut did not establish a statistical advantage over other recommendation methods, participant self-reported data suggested that participants found the Diversity Donut to yield the most diverse set of comments. The second contribution is a new dimensionality reduction technique in Opinion Space: Canonical Correlation Analysis (CCA). Our analysis suggests that CCA is a better algorithm for opinion visualization than Principal Component Analysis (PCA).},
	language = {en},
	urldate = {2020-12-12},
	booktitle = {Proceedings of the 2011 annual conference extended abstracts on {Human} factors in computing systems - {CHI} {EA} '11},
	publisher = {ACM Press},
	author = {Wong, David and Faridani, Siamak and Bitton, Ephrat and Hartmann, Björn and Goldberg, Ken},
	year = {2011},
	keywords = {comps-iui, rec},
	pages = {1471},
}

@inproceedings{WorkshopNoveltyDiversityRecommender,
	address = {Chicago, Illinois, USA},
	title = {Workshop on novelty and diversity in recommender systems - {DiveRS} 2011},
	isbn = {978-1-4503-0683-6},
	url = {http://dl.acm.org/citation.cfm?doid=2043932.2044019},
	doi = {10.1145/2043932.2044019},
	language = {en},
	urldate = {2020-12-12},
	booktitle = {Proceedings of the fifth {ACM} conference on {Recommender} systems - {RecSys} '11},
	publisher = {ACM Press},
	author = {Castells, Pablo and Wang, Jun and Lara, Rubén and Zhang, Dell},
	year = {2011},
	keywords = {comps-},
	pages = {393},
}

@article{InherentTradeOffsFairDetermination,
	title = {Inherent {Trade}-{Offs} in the {Fair} {Determination} of {Risk} {Scores}},
	url = {http://arxiv.org/abs/1609.05807},
	abstract = {Recent discussion in the public sphere about algorithmic classification has involved tension between competing notions of what it means for a probabilistic classification to be fair to different groups. We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. Moreover, even satisfying all three conditions approximately requires that the data lie in an approximate version of one of the constrained special cases identified by our theorem. These results suggest some of the ways in which key notions of fairness are incompatible with each other, and hence provide a framework for thinking about the trade-offs between them.},
	urldate = {2020-12-11},
	journal = {arXiv:1609.05807 [cs, stat]},
	author = {Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
	month = nov,
	year = {2016},
	note = {arXiv: 1609.05807},
	keywords = {comps-dm, fair, fatml},
}

@article{HumanMachineCollaborationContentRegulationa,
	title = {Human-{Machine} {Collaboration} for {Content} {Regulation}: {The} {Case} of {Reddit} {Automoderator}},
	volume = {26},
	issn = {1073-0516, 1557-7325},
	shorttitle = {Human-{Machine} {Collaboration} for {Content} {Regulation}},
	url = {https://dl.acm.org/doi/10.1145/3338243},
	doi = {10.1145/3338243},
	language = {en},
	number = {5},
	urldate = {2020-12-11},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Jhaver, Shagun and Birman, Iris and Gilbert, Eric and Bruckman, Amy},
	month = sep,
	year = {2019},
	keywords = {collaboration, comps-sc},
	pages = {1--35},
}

@inproceedings{CapsuleNetworkRecommendationExplaining,
	address = {Paris France},
	title = {A {Capsule} {Network} for {Recommendation} and {Explaining} {What} {You} {Like} and {Dislike}},
	isbn = {978-1-4503-6172-9},
	url = {https://dl.acm.org/doi/10.1145/3331184.3331216},
	doi = {10.1145/3331184.3331216},
	abstract = {User reviews contain rich semantics towards the preference of users to features of items. Recently, many deep learning based solutions have been proposed by exploiting reviews for recommendation. The attention mechanism is mainly adopted in these works to identify words or aspects that are important for rating prediction. However, it is still hard to understand whether a user likes or dislikes an aspect of an item according to what viewpoint the user holds and to what extent, without examining the review details. Here, we consider a pair of a viewpoint held by a user and an aspect of an item as a logic unit. Reasoning a rating behavior by discovering the informative logic units from the reviews and resolving their corresponding sentiments could enable a better rating prediction with explanation.},
	language = {en},
	urldate = {2020-12-09},
	booktitle = {Proceedings of the 42nd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Li, Chenliang and Quan, Cong and Peng, Li and Qi, Yunwei and Deng, Yuming and Wu, Libing},
	month = jul,
	year = {2019},
	keywords = {comps-iui, explanation, rec},
	pages = {275--284},
}

@inproceedings{PersonalizedFashionRecommendationVisual,
	address = {Paris France},
	title = {Personalized {Fashion} {Recommendation} with {Visual} {Explanations} based on {Multimodal} {Attention} {Network}: {Towards} {Visually} {Explainable} {Recommendation}},
	isbn = {978-1-4503-6172-9},
	shorttitle = {Personalized {Fashion} {Recommendation} with {Visual} {Explanations} based on {Multimodal} {Attention} {Network}},
	url = {https://dl.acm.org/doi/10.1145/3331184.3331254},
	doi = {10.1145/3331184.3331254},
	abstract = {Fashion recommendation has attracted increasing attention from both industry and academic communities. This paper proposes a novel neural architecture for fashion recommendation based on both image region-level features and user review information. Our basic intuition is that: for a fashion image, not all the regions are equally important for the users, i.e., people usually care about a few parts of the fashion image. To model such human sense, we learn an attention model over many pre-segmented image regions, based on which we can understand where a user is really interested in on the image, and correspondingly, represent the image in a more accurate manner. In addition, by discovering such fine-grained visual preference, we can visually explain a recommendation by highlighting some regions of its image. For better learning the attention model, we also introduce user review information as a weak supervision signal to collect more comprehensive user preference. In our final framework, the visual and textual features are seamlessly coupled by a multimodal attention network. Based on this architecture, we can not only provide accurate recommendation, but also can accompany each recommended item with novel visual explanations. We conduct extensive experiments to demonstrate the superiority of our proposed model in terms of Top-N recommendation, and also we build a collectively labeled dataset for evaluating our provided visual explanations in a quantitative manner.},
	language = {en},
	urldate = {2020-12-09},
	booktitle = {Proceedings of the 42nd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {ACM},
	author = {Chen, Xu and Chen, Hanxiong and Xu, Hongteng and Zhang, Yongfeng and Cao, Yixin and Qin, Zheng and Zha, Hongyuan},
	month = jul,
	year = {2019},
	pages = {765--774},
}

@article{AlgorithmicBiasEmpiricalStudy,
	title = {Algorithmic {Bias}? {An} {Empirical} {Study} of {Apparent} {Gender}-{Based} {Discrimination} in the {Display} of {STEM} {Career} {Ads}},
	volume = {65},
	abstract = {We explore data from a ﬁeld test of how an algorithm delivered ads promoting job opportunities in the science, technology, engineering and math ﬁelds. This ad was explicitly intended to be gender neutral in its delivery. Empirically, however, fewer women saw the ad than men. This happened because younger women are a prized demographic and are more expensive to show ads to. An algorithm that simply optimizes costeffectiveness in ad delivery will deliver ads that were intended to be gender neutral in an apparently discriminatory way, because of crowding out. We show that this empirical regularity extends to other major digital platforms.},
	language = {en},
	number = {7},
	journal = {Management Science},
	author = {Lambrecht, Anja and Tucker, Catherine},
	year = {2019},
	keywords = {comps-dm, fair, fatml},
	pages = {17},
}

@article{WhoDidWhatEditor,
	title = {Who {Did} {What}: {Editor} {Role} {Identification} in {Wikipedia}},
	abstract = {Understanding the social roles played by contributors to online communities can facilitate the process of task routing. In this work, we develop new techniques to ﬁnd roles in Wikipedia based on editors’ low-level edit types and investigate how work contributed by people from different roles affect the article quality. To do this, we ﬁrst built machinelearning models to automatically identify the edit categories associated with edits. We then applied a graphical model analogous to Latent Dirichlet Allocation to uncover the latent roles in editors’ edit histories. Applying this technique revealed eight different roles editors play. Finally, we validated how our identiﬁed roles collaborate to improve the quality of articles. The results demonstrate that editors carrying on different roles contribute differently in terms of edit categories and articles in different quality stages need different types of editors. Implications for editor role identiﬁcation and the validation of role contribution are discussed.},
	language = {en},
	author = {Yang, Diyi and Halfaker, Aaron and Kraut, Robert and Hovy, Eduard},
	keywords = {comps-sc, sc, wikipedia},
	pages = {10},
}

@article{SuccessfulOnlineSocializationLessons,
	title = {Successful {Online} {Socialization}: {Lessons} from the {Wikipedia} {Education} {Program}},
	volume = {4},
	language = {en},
	author = {Li, Ang and Yao, Zheng and Yang, Diyi and Kulkarni, Chinmay and Farzan, Rosta and Kraut, Robert E},
	keywords = {collaboration, comps-sc, sc, wikipedia},
	pages = {24},
}

@article{AreExplanationsAlwaysImportant,
	title = {Are explanations always important?: a study of deployed, low-cost intelligent interactive systems},
	abstract = {Intelligent interactive systems (IIS) have great potential to improve users' experience with technology by tailoring their behaviour and appearance to users’ individual needs; however, these systems, with their complex algorithms and dynamic behaviour, can also suffer from a lack of comprehensibility and transparency. We present the results of two studies examining the comprehensibility of, and desire for explanations with deployed, low-cost IIS. The first study, a set of interviews with 21 participants, reveals that i) comprehensibility is not always dependent on explanations, and ii) the perceived cost of viewing explanations tends to outweigh the anticipated benefits. Our second study, a two-week diary study with 14 participants, confirms these findings in the context of daily use, with participants indicating a desire for an explanation in only 7\% of diary entries. We discuss the implications of our findings for the design of explanation facilities.},
	language = {en},
	author = {Bunt, Andrea and Lount, Matthew and Lauzon, Catherine},
	year = {2012},
	pages = {10},
}

@inproceedings{AssessingDemandIntelligibilityContextaware,
	address = {Orlando Florida USA},
	title = {Assessing demand for intelligibility in context-aware applications},
	isbn = {978-1-60558-431-7},
	url = {https://dl.acm.org/doi/10.1145/1620545.1620576},
	doi = {10.1145/1620545.1620576},
	abstract = {Intelligibility can help expose the inner workings and inputs of context-aware applications that tend to be opaque to users due to their implicit sensing and actions. However, users may not be interested in all the information that the applications can produce. Using scenarios of four real-world applications that span the design space of context-aware computing, we conducted two experiments to discover what information users are interested in. In the first experiment, we elicit types of information demands that users have and under what moderating circumstances they have them. In the second experiment, we verify the findings by soliciting users about which types they would want to know and establish whether receiving such information would satisfy them. We discuss why users demand certain types of information, and provide design implications on how to provide different intelligibility types to make context-aware applications intelligible and acceptable to users.},
	language = {en},
	urldate = {2020-12-24},
	booktitle = {Proceedings of the 11th international conference on {Ubiquitous} computing},
	publisher = {ACM},
	author = {Lim, Brian Y. and Dey, Anind K.},
	month = sep,
	year = {2009},
	pages = {195--204},
}

@article{ValueSensitiveAlgorithmDesignMethod,
	title = {Value-{Sensitive} {Algorithm} {Design}: {Method}, {Case} {Study}, and {Lessons}},
	volume = {2},
	issn = {2573-0142, 2573-0142},
	shorttitle = {Value-{Sensitive} {Algorithm} {Design}},
	url = {https://dl.acm.org/doi/10.1145/3274463},
	doi = {10.1145/3274463},
	language = {en},
	number = {CSCW},
	urldate = {2020-12-22},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Zhu, Haiyi and Yu, Bowen and Halfaker, Aaron and Terveen, Loren},
	month = nov,
	year = {2018},
	keywords = {evaluation, hci, vis},
	pages = {1--23},
}

@article{CollaborativeLectureAnnotationSystem,
	title = {The {Collaborative} {Lecture} {Annotation} {System} ({CLAS}): {A} {New} {TOOL} for {Distributed} {Learning}},
	volume = {6},
	issn = {1939-1382},
	shorttitle = {The {Collaborative} {Lecture} {Annotation} {System} ({CLAS})},
	doi = {10.1109/TLT.2012.15},
	abstract = {In the context of a lecture, the capacity to readily recognize and synthesize key concepts is crucial for comprehension and overall educational performance. In this paper, we introduce a tool, the Collaborative Lecture Annotation System (CLAS), which has been developed to make the extraction of important information a more collaborative and engaged process. The system relies on semantically constrained annotation, postannotation data amalgamation and transparent display of this amalgamated data. In addition to describing the CLAS, we report on a user experience study aimed at investigating students' perception of the utility of the tool.},
	number = {1},
	journal = {IEEE Transactions on Learning Technologies},
	author = {Risko, E. F. and Foulsham, T. and Dawson, S. and Kingstone, A.},
	month = jan,
	year = {2013},
	note = {Conference Name: IEEE Transactions on Learning Technologies},
	keywords = {comps-sc},
	pages = {4--13},
}

@article{ConvexFrameworkFairRegression,
	title = {A {Convex} {Framework} for {Fair} {Regression}},
	url = {http://arxiv.org/abs/1706.02409},
	abstract = {We introduce a ﬂexible family of fairness regularizers for (linear and logistic) regression problems. These regularizers all enjoy convexity, permitting fast optimization, and they span the range from notions of group fairness to strong individual fairness. By varying the weight on the fairness regularizer, we can compute the eﬃcient frontier of the accuracy-fairness trade-oﬀ on any given dataset, and we measure the severity of this trade-oﬀ via a numerical quantity we call the Price of Fairness (PoF). The centerpiece of our results is an extensive comparative study of the PoF across six diﬀerent datasets in which fairness is a primary consideration.},
	language = {en},
	urldate = {2020-12-15},
	journal = {arXiv:1706.02409 [cs, stat]},
	author = {Berk, Richard and Heidari, Hoda and Jabbari, Shahin and Joseph, Matthew and Kearns, Michael and Morgenstern, Jamie and Neel, Seth and Roth, Aaron},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.02409},
}

@article{ContextAwareRecommenderSystems,
	title = {Context-{Aware} {Recommender} {Systems}},
	language = {en},
	author = {Adomavicius, Gediminas and Mobasher, Bamshad and Ricci, Francesco and Tuzhilin, Alex},
	pages = {14},
}

@article{FairRegressionQuantitativeDefinitions,
	title = {Fair {Regression}: {Quantitative} {Definitions} and {Reduction}-based {Algorithms}},
	shorttitle = {Fair {Regression}},
	url = {http://arxiv.org/abs/1905.12843},
	abstract = {In this paper, we study the prediction of a real-valued target, such as a risk score or recidivism rate, while guaranteeing a quantitative notion of fairness with respect to a protected attribute such as gender or race. We call this class of problems {\textbackslash}emph\{fair regression\}. We propose general schemes for fair regression under two notions of fairness: (1) statistical parity, which asks that the prediction be statistically independent of the protected attribute, and (2) bounded group loss, which asks that the prediction error restricted to any protected group remain below some pre-determined level. While we only study these two notions of fairness, our schemes are applicable to arbitrary Lipschitz-continuous losses, and so they encompass least-squares regression, logistic regression, quantile regression, and many other tasks. Our schemes only require access to standard risk minimization algorithms (such as standard classification or least-squares regression) while providing theoretical guarantees on the optimality and fairness of the obtained solutions. In addition to analyzing theoretical properties of our schemes, we empirically demonstrate their ability to uncover fairness--accuracy frontiers on several standard datasets.},
	urldate = {2020-12-15},
	journal = {arXiv:1905.12843 [cs, stat]},
	author = {Agarwal, Alekh and Dudík, Miroslav and Wu, Zhiwei Steven},
	month = may,
	year = {2019},
	note = {arXiv: 1905.12843},
	keywords = {comps-dm, fair, fatml},
}

@inproceedings{EachHisOwnHowa,
	address = {Chicago, Illinois, USA},
	title = {Each to his own: how different users call for different interaction methods in recommender systems},
	isbn = {978-1-4503-0683-6},
	shorttitle = {Each to his own},
	url = {http://dl.acm.org/citation.cfm?doid=2043932.2043960},
	doi = {10.1145/2043932.2043960},
	abstract = {This paper compares five different ways of interacting with an attribute-based recommender system and shows that different types of users prefer different interaction methods. In an online experiment with an energy-saving recommender system the interaction methods are compared in terms of perceived control, understandability, trust in the system, user interface satisfaction, system effectiveness and choice satisfaction. The comparison takes into account several user characteristics, namely domain knowledge, trusting propensity and persistence. The results show that most users (and particularly domain experts) are most satisfied with a hybrid recommender that combines implicit and explicit preference elicitation, but that novices and maximizers seem to benefit more from a non-personalized recommender that just displays the most popular items.},
	language = {en},
	urldate = {2020-12-14},
	booktitle = {Proceedings of the fifth {ACM} conference on {Recommender} systems - {RecSys} '11},
	publisher = {ACM Press},
	author = {Knijnenburg, Bart P. and Reijmer, Niels J.M. and Willemsen, Martijn C.},
	year = {2011},
	pages = {141},
}

@inproceedings{RankedListUserDrivenExploration,
	address = {Tokyo Japan},
	title = {Beyond the {Ranked} {List}: {User}-{Driven} {Exploration} and {Diversification} of {Social} {Recommendation}},
	isbn = {978-1-4503-4945-1},
	shorttitle = {Beyond the {Ranked} {List}},
	url = {https://dl.acm.org/doi/10.1145/3172944.3172959},
	doi = {10.1145/3172944.3172959},
	abstract = {The beyond-relevance objectives of recommender systems have been drawing more and more attention. For example, a diversity-enhanced interface has been shown to associate positively with overall levels of user satisfaction. However, little is known about how users adopt diversity-enhanced interfaces to accomplish various real-world tasks. In this paper, we present two attempts at creating a visual diversity-enhanced interface that presents recommendations beyond a simple ranked list. Our goal was to design a recommender system interface to help users explore the different relevance prospects of recommended items in parallel and to stress their diversity. Two within-subject user studies in the context of social recommendation at academic conferences were conducted to compare our visual interfaces. Results from our user study show that the visual interfaces signiﬁcantly reduced the exploration efforts required for given tasks and helped users to perceive the recommendation diversity. We show that the users examined a diverse set of recommended items while experiencing an improvement in overall user satisfaction. Also, the users’ subjective evaluations show signiﬁcant improvement in many user-centric metrics. Experiences are discussed that shed light on avenues for future interface designs.},
	language = {en},
	urldate = {2020-12-14},
	booktitle = {23rd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Tsai, Chun-Hua and Brusilovsky, Peter},
	month = mar,
	year = {2018},
	keywords = {comps-iui-rec},
	pages = {239--250},
}

@article{SmallWorldsVisualizingSocialRecommendations,
	title = {{SmallWorlds}: {Visualizing} {Social} {Recommendations}},
	volume = {29},
	issn = {1467-8659},
	shorttitle = {{SmallWorlds}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2009.01679.x},
	doi = {https://doi.org/10.1111/j.1467-8659.2009.01679.x},
	abstract = {We present SmallWorlds, a visual interactive graph-based interface that allows users to specify, refine and build item-preference profiles in a variety of domains. The interface facilitates expressions of taste through simple graph interactions and these preferences are used to compute personalized, fully transparent item recommendations for a target user. Predictions are based on a collaborative analysis of preference data from a user's direct peer group on a social network. We find that in addition to receiving transparent and accurate item recommendations, users also learn a wealth of information about the preferences of their peers through interaction with our visualization. Such information is not easily discoverable in traditional text based interfaces. A detailed analysis of our design choices for visual layout, interaction and prediction techniques is presented. Our evaluations discuss results from a user study in which SmallWorlds was deployed as an interactive recommender system on Facebook.},
	language = {en},
	number = {3},
	urldate = {2020-12-13},
	journal = {Computer Graphics Forum},
	author = {Gretarsson, Brynjar and O'Donovan, John and Bostandjiev, Svetlin and Hall, Christopher and Höllerer, Tobias},
	year = {2010},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2009.01679.x},
	keywords = {comps-iui},
	pages = {833--842},
}

@article{DesigningToolsSemiAutomatedDetection,
	title = {Designing {Tools} for {Semi}-{Automated} {Detection} of {Machine} {Learning} {Biases}: {An} {Interview} {Study}},
	shorttitle = {Designing {Tools} for {Semi}-{Automated} {Detection} of {Machine} {Learning} {Biases}},
	url = {http://arxiv.org/abs/2003.07680},
	abstract = {Machine learning models often make predictions that bias against certain subgroups of input data. When undetected, machine learning biases can constitute significant financial and ethical implications. Semi-automated tools that involve humans in the loop could facilitate bias detection. Yet, little is known about the considerations involved in their design. In this paper, we report on an interview study with 11 machine learning practitioners for investigating the needs surrounding semi-automated bias detection tools. Based on the findings, we highlight four considerations in designing to guide system designers who aim to create future tools for bias detection.},
	urldate = {2020-12-13},
	journal = {arXiv:2003.07680 [cs, stat]},
	author = {Law, Po-Ming and Malik, Sana and Du, Fan and Sinha, Moumita},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.07680},
	keywords = {fair, fatml},
}

@article{CoFeelUsingEmotionsSocial,
	title = {{CoFeel}: {Using} {Emotions} for {Social} {Interaction} in {Group} {Recommender} {Systems}},
	abstract = {Group and social recommender systems aim to suggest items of interest to a group or a community of people. One important issue in such environment is to understand each individual’s preference and attitude within the group. Social and behavioral scientist have evidenced the role of emotions in group work and social communication. This paper aims to examine the role of emotion for social interaction in group recommenders. We implemented CoFeel, an interface that aims to provide emotional input in group recommenders. We further apply CoFeel in a GroupFun, a mobile group music recommender system. Results of an in-depth field study show that by exchanging feelings with other users, CoFeel motivates users to provide feedback on recommended items in a natural and enjoyable way. Results also show that emotions do serve as an effective and promising element to elicitate users’ attitudes, and that they do have the potential to increase user engagement in a group. Based on suggestions collected from users, we propose other potential recommendation domains of CoFeel.},
	language = {en},
	author = {Chen, Yu and Pu, Pearl},
	keywords = {comps-iui},
	pages = {8},
}

@inproceedings{DetectionRetrievalOutofDistributionObjects,
	address = {Seattle, WA, USA},
	title = {Detection and {Retrieval} of {Out}-of-{Distribution} {Objects} in {Semantic} {Segmentation}},
	isbn = {978-1-72819-360-1},
	url = {https://ieeexplore.ieee.org/document/9150788/},
	doi = {10.1109/CVPRW50498.2020.00172},
	language = {en},
	urldate = {2021-01-25},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Oberdiek, Philipp and Rottmann, Matthias and Fink, Gernot A.},
	month = jun,
	year = {2020},
	keywords = {dm, image, ood, segmentation},
	pages = {1331--1340},
}

@article{BaselineDetectingMisclassifiedOutofDistribution,
	title = {A {Baseline} for {Detecting} {Misclassified} and {Out}-of-{Distribution} {Examples} in {Neural} {Networks}},
	url = {http://arxiv.org/abs/1610.02136},
	abstract = {We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.},
	urldate = {2021-01-22},
	journal = {arXiv:1610.02136 [cs]},
	author = {Hendrycks, Dan and Gimpel, Kevin},
	month = oct,
	year = {2018},
	note = {arXiv: 1610.02136},
	keywords = {dm, ood, uu},
}

@article{CatchyTitlesAreGood,
	title = {Catchy {Titles} {Are} {Good}: {But} {Avoid} {Being} {Cute}},
	abstract = {The most important rule of Abstracts is that they describe the work, not the paper. Include, at most, one sentence of motivation. Save the rest of your motivation for the Introduction. Effective Abstracts focus on two things: (1) Describing what was done. (2) Describing what was found (key results). Be specific about your key findings. Instead of “many” say “84\%”. Keep the Abstract to one paragraph and fewer than 200 words.},
	language = {en},
	author = {Wobbrock, Jacob O},
	keywords = {writing},
	pages = {5},
}

@article{PoliticalPolarizationTwitter,
	title = {Political {Polarization} on {Twitter}},
	abstract = {In this study we investigate how social media shape the networked public sphere and facilitate communication between communities with different political orientations. We examine two networks of political communication on Twitter, comprised of more than 250,000 tweets from the six weeks leading up to the 2010 U.S. congressional midterm elections. Using a combination of network clustering algorithms and manually-annotated data we demonstrate that the network of political retweets exhibits a highly segregated partisan structure, with extremely limited connectivity between left- and right-leaning users. Surprisingly this is not the case for the user-to-user mention network, which is dominated by a single politically heterogeneous cluster of users in which ideologically-opposed individuals interact at a much higher rate compared to the network of retweets. To explain the distinct topologies of the retweet and mention networks we conjecture that politically motivated individuals provoke interaction by injecting partisan content into information streams whose primary audience consists of ideologically-opposed users. We conclude with statistical evidence in support of this hypothesis.},
	language = {en},
	author = {Conover, M D and Ratkiewicz, J and Francisco, M and Goncalves, B and Flammini, A and Menczer, F},
	pages = {8},
}

@article{AnalyzingPolarizationSocialMedia,
	title = {Analyzing {Polarization} in {Social} {Media}: {Method} and {Application} to {Tweets} on 21 {Mass} {Shootings}},
	shorttitle = {Analyzing {Polarization} in {Social} {Media}},
	url = {http://arxiv.org/abs/1904.01596},
	abstract = {We provide an NLP framework to uncover four linguistic dimensions of political polarization in social media: topic choice, framing, affect and illocutionary force. We quantify these aspects with existing lexical methods, and propose clustering of tweet embeddings as a means to identify salient topics for analysis across events; human evaluations show that our approach generates more cohesive topics than traditional LDA-based models. We apply our methods to study 4.4M tweets on 21 mass shootings. We provide evidence that the discussion of these events is highly polarized politically and that this polarization is primarily driven by partisan differences in framing rather than topic choice. We identify framing devices, such as grounding and the contrasting use of the terms "terrorist" and "crazy", that contribute to polarization. Results pertaining to topic choice, affect and illocutionary force suggest that Republicans focus more on the shooter and event-specific facts (news) while Democrats focus more on the victims and call for policy changes. Our work contributes to a deeper understanding of the way group divisions manifest in language and to computational methods for studying them.},
	urldate = {2021-01-09},
	journal = {arXiv:1904.01596 [cs]},
	author = {Demszky, Dorottya and Garg, Nikhil and Voigt, Rob and Zou, James and Gentzkow, Matthew and Shapiro, Jesse and Jurafsky, Dan},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.01596},
	keywords = {dm, polarization},
}

@article{ActiveLearningTensorBoardProjector,
	title = {Active {Learning} with {TensorBoard} {Projector}},
	url = {http://arxiv.org/abs/1901.00675},
	abstract = {An ML-based system for interactive labeling of image datasets is contributed in TensorBoard Projector to speed up image annotation performed by humans. The tool visualizes feature spaces and makes it directly editable by online integration of applied labels, and it is a system for verifying and managing machine learning data pertaining to labels. We propose realistic annotation emulation to evaluate the system design of interactive active learning, based on our improved semisupervised extension of t-SNE dimensionality reduction. Our active learning tool can signiﬁcantly increase labeling efﬁciency compared to uncertainty sampling, and we show that less than 100 labeling actions are typically sufﬁcient for good classiﬁcation on a variety of specialized image datasets. Our contribution is unique given that it needs to perform dimensionality reduction, feature space visualization and editing, interactive label propagation, low-complexity active learning, human perceptual modeling, annotation emulation and unsupervised feature extraction for specialized datasets in a production-quality implementation.},
	language = {en},
	urldate = {2021-01-09},
	journal = {arXiv:1901.00675 [cs]},
	author = {Luus, Francois and Khan, Naweed and Akhalwaya, Ismail},
	month = jan,
	year = {2019},
	note = {arXiv: 1901.00675},
}

@article{AnalyzingPolarizationSocialMediaa,
	title = {Analyzing polarization of social media users and news sites during political campaigns},
	volume = {8},
	issn = {1869-5450, 1869-5469},
	url = {http://link.springer.com/10.1007/s13278-017-0479-5},
	doi = {10.1007/s13278-017-0479-5},
	abstract = {Social media analysis is a fast growing research area aimed at extracting useful information from social networks. Recent years have seen a great interest from academic and business world in using social media to measure public opinion. This paper presents a methodology aimed at discovering the behavior of social network users and how news sites are used during political campaigns characterized by the rivalry of different factions. As a case study, we present an analysis on the constitutional referendum that was held in Italy on December 4, 2016. A first goal of the analysis was to study how Twitter users expressed their voting intentions about the referendum in the weeks before the voting day, so as to understand how the voting trends have evolved before the vote, e.g., if there have been changes in the voting intentions. According to our study, 48\% of Twitter users were polarized toward no, 25\% toward yes, and 27\% had a neutral behavior. A second goal was to understand the effects of news sites on the referendum campaign. The analysis has shown that some news sites had a strong polarization toward yes (unita.tv, ilsole24ore.it and linkiesta.it), some others had a neutral position (lastampa.it, corriere.it, huffingtonpost.it and repubblica.it) and others were oriented toward no (ilfattoquotidiano.it, ilgiornale.it and beppegrillo.it).},
	language = {en},
	number = {1},
	urldate = {2021-01-09},
	journal = {Social Network Analysis and Mining},
	author = {Marozzo, Fabrizio and Bessi, Alessandro},
	month = dec,
	year = {2018},
	keywords = {dm, polarization},
	pages = {1},
}

@inproceedings{ImprovingVisualAnalysisHighdimensional,
	title = {Improving the visual analysis of high-dimensional datasets using quality measures},
	doi = {10.1109/VAST.2010.5652433},
	abstract = {Modern visualization methods are needed to cope with very high-dimensional data. Efficient visual analytical techniques are required to extract the information content in these data. The large number of possible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urges the necessity to employ automatic reduction techniques, automatic sorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfully applied for several specified user tasks and established visualization techniques, like Scatterplots, Scatterplot Matrices or Parallel Coordinates. Many other popular visualization techniques exist, but due to the structural differences, the measures are not directly applicable to them and new approaches are needed. In this paper we propose new quality measures for three popular visualization methods: Radviz, Pixel-Oriented Displays and Table Lenses. Our experiments show that these measures efficiently guide the visual analysis task.},
	booktitle = {2010 {IEEE} {Symposium} on {Visual} {Analytics} {Science} and {Technology}},
	author = {Albuquerque, G. and Eisemann, M. and Lehmann, D. J. and Theisel, H. and Magnor, M.},
	month = oct,
	year = {2010},
	keywords = {multi-dimensional, vis},
	pages = {19--26},
}

@article{VisualizingHighDimensionalDataAdvances,
	title = {Visualizing {High}-{Dimensional} {Data}: {Advances} in the {Past} {Decade}},
	volume = {23},
	issn = {1077-2626},
	shorttitle = {Visualizing {High}-{Dimensional} {Data}},
	url = {http://ieeexplore.ieee.org/document/7784854/},
	doi = {10.1109/TVCG.2016.2640960},
	abstract = {Massive simulations and arrays of sensing devices, in combination with increasing computing resources, have generated large, complex, high-dimensional datasets used to study phenomena across numerous ﬁelds of study. Visualization plays an important role in exploring such datasets. We provide a comprehensive survey of advances in high-dimensional data visualization over the past 15 years. We aim at providing actionable guidance for data practitioners to navigate through a modular view of the recent advances, allowing the creation of new visualizations along the enriched information visualization pipeline and identifying future opportunities for visualization research.},
	language = {en},
	number = {3},
	urldate = {2021-01-03},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, Shusen and Maljovec, Dan and Wang, Bei and Bremer, Peer-Timo and Pascucci, Valerio},
	month = mar,
	year = {2017},
	keywords = {survey, vis},
	pages = {1249--1268},
}

@article{DiagnosingConceptDriftVisual,
	title = {Diagnosing {Concept} {Drift} with {Visual} {Analytics}},
	url = {http://arxiv.org/abs/2007.14372},
	abstract = {Concept drift is a phenomenon in which the distribution of a data stream changes over time in unforeseen ways, causing prediction models built on historical data to become inaccurate. While a variety of automated methods have been developed to identify when concept drift occurs, there is limited support for analysts who need to understand and correct their models when drift is detected. In this paper, we present a visual analytics method, DriftVis, to support model builders and analysts in the identification and correction of concept drift in streaming data. DriftVis combines a distribution-based drift detection method with a streaming scatterplot to support the analysis of drift caused by the distribution changes of data streams and to explore the impact of these changes on the model's accuracy. A quantitative experiment and two case studies on weather prediction and text classification have been conducted to demonstrate our proposed tool and illustrate how visual analytics can be used to support the detection, examination, and correction of concept drift.},
	urldate = {2020-12-26},
	journal = {arXiv:2007.14372 [cs, stat]},
	author = {Yang, Weikai and Li, Zhen and Liu, Mengchen and Lu, Yafeng and Cao, Kelei and Maciejewski, Ross and Liu, Shixia},
	month = sep,
	year = {2020},
	note = {arXiv: 2007.14372},
	keywords = {fatml, reliable, rw-uu-vis-ml, uu, vis},
}

@inproceedings{ForagingUnderstandingStarCraftAgents,
	address = {Tokyo Japan},
	title = {Toward {Foraging} for {Understanding} of {StarCraft} {Agents}: {An} {Empirical} {Study}},
	isbn = {978-1-4503-4945-1},
	shorttitle = {Toward {Foraging} for {Understanding} of {StarCraft} {Agents}},
	url = {https://dl.acm.org/doi/10.1145/3172944.3172946},
	doi = {10.1145/3172944.3172946},
	abstract = {Assessing and understanding intelligent agents is a difﬁcult task for users that lack an AI background. A relatively new area, called “Explainable AI,” is emerging to help address this problem, but little is known about how users would forage through information an explanation system might offer. To inform the development of Explainable AI systems, we conducted a formative study — using the lens of Information Foraging Theory — into how experienced users foraged in the domain of StarCraft to assess an agent. Our results showed that participants faced difﬁcult foraging problems. These foraging problems caused participants to entirely miss events that were important to them, reluctantly choose to ignore actions they did not want to ignore, and bear high cognitive, navigation, and information costs to access the information they needed.},
	language = {en},
	urldate = {2020-12-24},
	booktitle = {23rd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Penney, Sean and Dodge, Jonathan and Hilderbrand, Claudia and Anderson, Andrew and Simpson, Logan and Burnett, Margaret},
	month = mar,
	year = {2018},
	pages = {225--237},
}

@article{ExplainingClassifiersCausalConcept,
	title = {Explaining {Classifiers} with {Causal} {Concept} {Effect} ({CaCE})},
	url = {http://arxiv.org/abs/1907.07165},
	abstract = {How can we understand classification decisions made by deep neural networks? Many existing explainability methods rely solely on correlations and fail to account for confounding, which may result in potentially misleading explanations. To overcome this problem, we define the Causal Concept Effect (CaCE) as the causal effect of (the presence or absence of) a human-interpretable concept on a deep neural net's predictions. We show that the CaCE measure can avoid errors stemming from confounding. Estimating CaCE is difficult in situations where we cannot easily simulate the do-operator. To mitigate this problem, we use a generative model, specifically a Variational AutoEncoder (VAE), to measure VAE-CaCE. In an extensive experimental analysis, we show that the VAE-CaCE is able to estimate the true concept causal effect, compared to baselines for a number of datasets including high dimensional images.},
	urldate = {2021-03-02},
	journal = {arXiv:1907.07165 [cs, stat]},
	author = {Goyal, Yash and Feder, Amir and Shalit, Uri and Kim, Been},
	month = feb,
	year = {2020},
	note = {arXiv: 1907.07165},
	keywords = {concept, fatml},
}

@inproceedings{ConceptExplorerVisualAnalysisConcept,
	title = {{ConceptExplorer}: {Visual} {Analysis} of {Concept} {Drifts} in {Multi}-source {Time}-series {Data}},
	shorttitle = {{ConceptExplorer}},
	doi = {10.1109/VAST50239.2020.00006},
	abstract = {Time-series data is widely studied in various scenarios, like weather forecast, stock market, customer behavior analysis. To comprehensively learn about the dynamic environments, it is necessary to comprehend features from multiple data sources. This paper proposes a novel visual analysis approach for detecting and analyzing concept drifts from multi-sourced time-series. We propose a visual detection scheme for discovering concept drifts from multiple sourced time-series based on prediction models. We design a drift level index to depict the dynamics, and a consistency judgment model to justify whether the concept drifts from various sources are consistent. Our integrated visual interface, ConceptExplorer, facilitates visual exploration, extraction, understanding, and comparison of concepts and concept drifts from multi-source time-series data. We conduct three case studies and expert interviews to verify the effectiveness of our approach.},
	booktitle = {2020 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	author = {Wang, X. and Chen, W. and Xia, J. and Chen, Z. and Xu, D. and Wu, X. and Xu, M. and Schreck, T.},
	month = oct,
	year = {2020},
	keywords = {fatml, r-rw-uu-vis-ml, reliable, vis},
	pages = {1--11},
}

@article{InteractiveMethodImproveCrowdsourceda,
	title = {An {Interactive} {Method} to {Improve} {Crowdsourced} {Annotations}},
	volume = {25},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2018.2864843},
	abstract = {In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, S. and Chen, C. and Lu, Y. and Ouyang, F. and Wang, B.},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	pages = {235--245},
}

@article{InteractiveMethodImproveCrowdsourced,
	title = {An {Interactive} {Method} to {Improve} {Crowdsourced} {Annotations}},
	volume = {25},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2018.2864843},
	abstract = {In order to effectively infer correct labels from noisy crowdsourced annotations, learning-from-crowds models have introduced expert validation. However, little research has been done on facilitating the validation procedure. In this paper, we propose an interactive method to assist experts in verifying uncertain instance labels and unreliable workers. Given the instance labels and worker reliability inferred from a learning-from-crowds model, candidate instances and workers are selected for expert validation. The influence of verified results is propagated to relevant instances and workers through the learning-from-crowds model. To facilitate the validation of annotations, we have developed a confusion visualization to indicate the confusing classes for further exploration, a constrained projection method to show the uncertain labels in context, and a scatter-plot-based visualization to illustrate worker reliability. The three visualizations are tightly integrated with the learning-from-crowds model to provide an iterative and progressive environment for data validation. Two case studies were conducted that demonstrate our approach offers an efficient method for validating and improving crowdsourced annotations.},
	number = {1},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Liu, S. and Chen, C. and Lu, Y. and Ouyang, F. and Wang, B.},
	month = jan,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Visualization and Computer Graphics},
	keywords = {ml, reliable, vis},
	pages = {235--245},
}

@inproceedings{GeneralizedODINDetectingOutofDistribution,
	address = {Seattle, WA, USA},
	title = {Generalized {ODIN}: {Detecting} {Out}-of-{Distribution} {Image} {Without} {Learning} {From} {Out}-of-{Distribution} {Data}},
	isbn = {978-1-72817-168-5},
	shorttitle = {Generalized {ODIN}},
	url = {https://ieeexplore.ieee.org/document/9156473/},
	doi = {10.1109/CVPR42600.2020.01096},
	abstract = {Deep neural networks have attained remarkable performance when applied to data that comes from the same distribution as that of the training set, but can signiﬁcantly degrade otherwise. Therefore, detecting whether an example is out-of-distribution (OoD) is crucial to enable a system that can reject such samples or alert users. Recent works have made signiﬁcant progress on OoD benchmarks consisting of small image datasets. However, many recent methods based on neural networks rely on training or tuning with both in-distribution and out-of-distribution data. The latter is generally hard to deﬁne a-priori, and its selection can easily bias the learning. We base our work on a popular method ODIN1 [21], proposing two strategies for freeing it from the needs of tuning with OoD data, while improving its OoD detection performance. We speciﬁcally propose to decompose conﬁdence scoring as well as a modiﬁed input pre-processing method. We show that both of these signiﬁcantly help in detection performance. Our further analysis on a larger scale image dataset shows that the two types of distribution shifts, speciﬁcally semantic shift and non-semantic shift, present a signiﬁcant difference in the difﬁculty of the problem, providing an analysis of when ODIN-like strategies do or do not work.},
	language = {en},
	urldate = {2021-02-06},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Hsu, Yen-Chang and Shen, Yilin and Jin, Hongxia and Kira, Zsolt},
	month = jun,
	year = {2020},
	keywords = {ood},
	pages = {10948--10957},
}

@article{ReducingNetworkAgnostophobia,
	title = {Reducing {Network} {Agnostophobia}},
	url = {http://arxiv.org/abs/1811.04110},
	abstract = {Agnostophobia, the fear of the unknown, can be experienced by deep learning engineers while applying their networks to real-world applications. Unfortunately, network behavior is not well defined for inputs far from a networks training set. In an uncontrolled environment, networks face many instances that are not of interest to them and have to be rejected in order to avoid a false positive. This problem has previously been tackled by researchers by either a) thresholding softmax, which by construction cannot return "none of the known classes", or b) using an additional background or garbage class. In this paper, we show that both of these approaches help, but are generally insufficient when previously unseen classes are encountered. We also introduce a new evaluation metric that focuses on comparing the performance of multiple approaches in scenarios where such unseen classes or unknowns are encountered. Our major contributions are simple yet effective Entropic Open-Set and Objectosphere losses that train networks using negative samples from some classes. These novel losses are designed to maximize entropy for unknown inputs while increasing separation in deep feature space by modifying magnitudes of known and unknown samples. Experiments on networks trained to classify classes from MNIST and CIFAR-10 show that our novel loss functions are significantly better at dealing with unknown inputs from datasets such as Devanagari, NotMNIST, CIFAR-100, and SVHN.},
	urldate = {2021-02-06},
	journal = {arXiv:1811.04110 [cs]},
	author = {Dhamija, Akshay Raj and Günther, Manuel and Boult, Terrance E.},
	month = dec,
	year = {2018},
	note = {arXiv: 1811.04110},
	keywords = {uu},
}

@article{KnowledgeGraphEmbeddingSurvey,
	title = {Knowledge {Graph} {Embedding}: {A} {Survey} of {Approaches} and {Applications}},
	abstract = {Knowledge graph (KG) embedding is to embed components of a KG including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the KG. It can beneﬁt a variety of downstream tasks such as KG completion and relation extraction, and hence has quickly gained massive attention. In this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. Particularly, we make the review based on the type of information used in the embedding task. Techniques that conduct embedding using only facts observed in the KG are ﬁrst introduced. We describe the overall framework, speciﬁc model design, typical training procedures, as well as pros and cons of such techniques. After that, we discuss techniques that further incorporate additional information besides facts. We focus speciﬁcally on the use of entity types, relation paths, textual descriptions, and logical rules. Finally, we brieﬂy introduce how KG embedding can be applied to and beneﬁt a wide variety of downstream tasks such as KG completion, relation extraction, question answering, and so forth.},
	language = {en},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wang, Quan and Mao, Zhendong and Wang, Bin and Guo, Li},
	pages = {20},
}

@article{SurveyKnowledgeGraphsRepresentation,
	title = {A {Survey} on {Knowledge} {Graphs}: {Representation}, {Acquisition} and {Applications}},
	shorttitle = {A {Survey} on {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2002.00388},
	abstract = {Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction towards cognition and human-level intelligence. In this survey, we provide a comprehensive review of knowledge graph covering overall research topics about 1) knowledge graph representation learning, 2) knowledge acquisition and completion, 3) temporal knowledge graph, and 4) knowledge-aware applications, and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning, are reviewed. We further explore several emerging topics, including meta relational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide a curated collection of datasets and open-source libraries on different tasks. In the end, we have a thorough outlook on several promising research directions.},
	urldate = {2021-02-03},
	journal = {arXiv:2002.00388 [cs]},
	author = {Ji, Shaoxiong and Pan, Shirui and Cambria, Erik and Marttinen, Pekka and Yu, Philip S.},
	month = jan,
	year = {2021},
	note = {arXiv: 2002.00388},
	keywords = {kg, survey},
}

@article{KnowledgeGraphs,
	title = {Knowledge {Graphs}},
	url = {http://arxiv.org/abs/2003.02320},
	abstract = {In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After some opening remarks, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.},
	urldate = {2021-02-02},
	journal = {arXiv:2003.02320 [cs]},
	author = {Hogan, Aidan and Blomqvist, Eva and Cochez, Michael and d'Amato, Claudia and de Melo, Gerard and Gutierrez, Claudio and Gayo, José Emilio Labra and Kirrane, Sabrina and Neumaier, Sebastian and Polleres, Axel and Navigli, Roberto and Ngomo, Axel-Cyrille Ngonga and Rashid, Sabbir M. and Rula, Anisa and Schmelzeisen, Lukas and Sequeda, Juan and Staab, Steffen and Zimmermann, Antoine},
	month = jan,
	year = {2021},
	note = {arXiv: 2003.02320},
	keywords = {kg, survey},
}

@inproceedings{LearningCommunityEmbeddingCommunity,
	address = {Singapore Singapore},
	title = {Learning {Community} {Embedding} with {Community} {Detection} and {Node} {Embedding} on {Graphs}},
	isbn = {978-1-4503-4918-5},
	url = {https://dl.acm.org/doi/10.1145/3132847.3132925},
	doi = {10.1145/3132847.3132925},
	abstract = {In this paper, we study an important yet largely under-explored setting of graph embedding, i.e., embedding communities instead of each individual nodes. We find that community embedding is not only useful for community-level applications such as graph visualization, but also beneficial to both community detection and node classification. To learn such embedding, our insight hinges upon a closed loop among community embedding, community detection and node embedding. On the one hand, node embedding can help improve community detection, which outputs good communities for fitting better community embedding. On the other hand, community embedding can be used to optimize the node embedding by introducing a community-aware high-order proximity. Guided by this insight, we propose a novel community embedding framework that jointly solves the three tasks together. We evaluate such a framework on multiple real-world datasets, and show that it improves graph visualization and outperforms state-of-the-art baselines in various application tasks, e.g., community detection and node classification.},
	language = {en},
	urldate = {2021-02-02},
	booktitle = {Proceedings of the 2017 {ACM} on {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Cavallari, Sandro and Zheng, Vincent W. and Cai, Hongyun and Chang, Kevin Chen-Chuan and Cambria, Erik},
	month = nov,
	year = {2017},
	keywords = {dm, embedding, network},
	pages = {377--386},
}

@article{ManComputerProgrammerWoman,
	title = {Man is to {Computer} {Programmer} as {Woman} is to {Homemaker}? {Debiasing} {Word} {Embeddings}},
	shorttitle = {Man is to {Computer} {Programmer} as {Woman} is to {Homemaker}?},
	url = {http://arxiv.org/abs/1607.06520},
	abstract = {The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is ﬁrst shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender deﬁnition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between between the words receptionist and female, while maintaining desired associations such as between the words queen and female. We deﬁne metrics to quantify both direct and indirect gender biases in embeddings, and develop algorithms to “debias” the embedding. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms signiﬁcantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.},
	language = {en},
	urldate = {2021-03-24},
	journal = {arXiv:1607.06520 [cs, stat]},
	author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.06520},
}

@article{CompositionalExplanationsNeurons,
	title = {Compositional {Explanations} of {Neurons}},
	url = {http://arxiv.org/abs/2006.14032},
	abstract = {We describe a procedure for explaining neurons in deep representations by identifying compositional logical concepts that closely approximate neuron behavior. Compared to prior work that uses atomic labels as explanations, analyzing neurons compositionally allows us to more precisely and expressively characterize their behavior. We use this procedure to answer several questions on interpretability in models for vision and natural language processing. First, we examine the kinds of abstractions learned by neurons. In image classification, we find that many neurons learn highly abstract but semantically coherent visual concepts, while other polysemantic neurons detect multiple unrelated features; in natural language inference (NLI), neurons learn shallow lexical heuristics from dataset biases. Second, we see whether compositional explanations give us insight into model performance: vision neurons that detect human-interpretable concepts are positively correlated with task performance, while NLI neurons that fire for shallow heuristics are negatively correlated with task performance. Finally, we show how compositional explanations provide an accessible way for end users to produce simple "copy-paste" adversarial examples that change model behavior in predictable ways.},
	urldate = {2021-03-17},
	journal = {arXiv:2006.14032 [cs, stat]},
	author = {Mu, Jesse and Andreas, Jacob},
	month = feb,
	year = {2021},
	note = {arXiv: 2006.14032},
	keywords = {explanation, fatml, xai},
}

@article{ClassAnchorClusteringLoss,
	title = {Class {Anchor} {Clustering}: a {Loss} for {Distance}-based {Open} {Set} {Recognition}},
	shorttitle = {Class {Anchor} {Clustering}},
	url = {http://arxiv.org/abs/2004.02434},
	abstract = {In open set recognition, deep neural networks encounter object classes that were unknown during training. Existing open set classifiers distinguish between known and unknown classes by measuring distance in a network's logit space, assuming that known classes cluster closer to the training data than unknown classes. However, this approach is applied post-hoc to networks trained with cross-entropy loss, which does not guarantee this clustering behaviour. To overcome this limitation, we introduce the Class Anchor Clustering (CAC) loss. CAC is a distance-based loss that explicitly trains known classes to form tight clusters around anchored class-dependent centres in the logit space. We show that training with CAC achieves state-of-the-art performance for distance-based open set classifiers on all six standard benchmark datasets, with a 15.2\% AUROC increase on the challenging TinyImageNet, without sacrificing classification accuracy. We also show that our anchored class centres achieve higher open set performance than learnt class centres, particularly on object-based datasets and large numbers of training classes.},
	urldate = {2021-03-17},
	journal = {arXiv:2004.02434 [cs]},
	author = {Miller, Dimity and Sünderhauf, Niko and Milford, Michael and Dayoub, Feras},
	month = mar,
	year = {2021},
	note = {arXiv: 2004.02434},
}

@article{ChallengingEnvironmentsTrafficSign,
	title = {Challenging {Environments} for {Traffic} {Sign} {Detection}: {Reliability} {Assessment} under {Inclement} {Conditions}},
	shorttitle = {Challenging {Environments} for {Traffic} {Sign} {Detection}},
	url = {http://arxiv.org/abs/1902.06857},
	abstract = {State-of-the-art algorithms successfully localize and recognize traffic signs over existing datasets, which are limited in terms of challenging condition type and severity. Therefore, it is not possible to estimate the performance of traffic sign detection algorithms under overlooked challenging conditions. Another shortcoming of existing datasets is the limited utilization of temporal information and the unavailability of consecutive frames and annotations. To overcome these shortcomings, we generated the CURE-TSD video dataset and hosted the first IEEE Video and Image Processing (VIP) Cup within the IEEE Signal Processing Society. In this paper, we provide a detailed description of the CURE-TSD dataset, analyze the characteristics of the top performing algorithms, and provide a performance benchmark. Moreover, we investigate the robustness of the benchmarked algorithms with respect to sign size, challenge type and severity. Benchmarked algorithms are based on state-of-the-art and custom convolutional neural networks that achieved a precision of 0.55 and a recall of 0.32, F0.5 score of 0.48 and F2 score of 0.35. Experimental results show that benchmarked algorithms are highly sensitive to tested challenging conditions, which result in an average performance drop of 0.17 in terms of precision and a performance drop of 0.28 in recall under severe conditions. The dataset is publicly available at https://github.com/olivesgatech/CURE-TSD.},
	urldate = {2021-03-09},
	journal = {arXiv:1902.06857 [cs, eess]},
	author = {Temel, Dogancan and Alshawi, Tariq and Chen, Min-Hung and AlRegib, Ghassan},
	month = aug,
	year = {2019},
	note = {arXiv: 1902.06857},
}

@article{BridgingGapEthicsPractice,
	title = {Bridging the {Gap} {Between} {Ethics} and {Practice}: {Guidelines} for {Reliable}, {Safe}, and {Trustworthy} {Human}-centered {AI} {Systems}},
	volume = {10},
	issn = {2160-6455, 2160-6463},
	shorttitle = {Bridging the {Gap} {Between} {Ethics} and {Practice}},
	url = {https://dl.acm.org/doi/10.1145/3419764},
	doi = {10.1145/3419764},
	abstract = {This article attempts to bridge the gap between widely discussed ethical principles of Human-centered AI (HCAI) and practical steps for effective governance. Since HCAI systems are developed and implemented in multiple organizational structures, I propose 15 recommendations at three levels of governance: team, organization, and industry. The recommendations are intended to increase the reliability, safety, and trustworthiness of HCAI systems: (1) reliable systems based on sound software engineering practices, (2) safety culture through business management strategies, and (3) trustworthy certification by independent oversight. Software engineering practices within teams include audit trails to enable analysis of failures, software engineering workflows, verification and validation testing, bias testing to enhance fairness, and explainable user interfaces. The safety culture within organizations comes from management strategies that include leadership commitment to safety, hiring and training oriented to safety, extensive reporting of failures and near misses, internal review boards for problems and future plans, and alignment with industry standard practices. The trustworthiness certification comes from industry-wide efforts that include government interventions and regulation, accounting firms conducting external audits, insurance companies compensating for failures, non-governmental and civil society organizations advancing design principles, and professional organizations and research institutes developing standards, policies, and novel ideas. The larger goal of effective governance is to limit the dangers and increase the benefits of HCAI to individuals, organizations, and society.},
	language = {en},
	number = {4},
	urldate = {2021-03-08},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Shneiderman, Ben},
	month = dec,
	year = {2020},
	pages = {1--31},
}

@article{WhyVisualizeUntanglingLarge,
	title = {Why {Visualize}? {Untangling} a {Large} {Network} of {Arguments}},
	volume = {27},
	issn = {1077-2626, 1941-0506, 2160-9306},
	shorttitle = {Why {Visualize}?},
	url = {https://ieeexplore.ieee.org/document/8827956/},
	doi = {10.1109/TVCG.2019.2940026},
	abstract = {Visualization has been deemed a useful technique by researchers and practitioners, alike, leaving a trail of arguments behind that reason why visualization works. In addition, examples of misleading usages of visualizations in information communication have occasionally been pointed out. Thus, to contribute to the fundamental understanding of our discipline, we require a comprehensive collection of arguments on “why visualize?” (or “why not?”), untangling the rationale behind positive and negative viewpoints. In this paper, we report a theoretical study to understand the underlying reasons of various arguments; their relationships (e.g., built-on, and conﬂict); and their respective dependencies on tasks, users, and data. We curated an argumentative network based on a collection of arguments from various ﬁelds, including information visualization, cognitive science, psychology, statistics, philosophy, and others. Our work proposes several categorizations for the arguments, and makes their relations explicit. We contribute the ﬁrst comprehensive and systematic theoretical study of the arguments on visualization. Thereby, we provide a roadmap towards building a foundation for visualization theory and empirical research as well as for practical application in the critique and design of visualizations. In addition, we provide our argumentation network and argument collection online at https://whyvis.dbvis.de, supported by an interactive visualization.},
	language = {en},
	number = {3},
	urldate = {2021-03-08},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Streeb, Dirk and El-Assady, Mennatallah and Keim, Daniel A. and Chen, Min},
	month = mar,
	year = {2021},
	pages = {2220--2236},
}

@article{AreExplanationsHelpfulComparative,
	title = {Are {Explanations} {Helpful}? {A} {Comparative} {Study} of the {Effects} of {Explanations} in {AI}-{Assisted} {Decision}-{Making}},
	abstract = {This paper contributes to the growing literature in empirical evaluation of explainable AI (XAI) methods by presenting a comparison on the effects of a set of established XAI methods in AI-assisted decision making. Specifically, based on our review of previous literature, we highlight three desirable properties that ideal AI explanations should satisfy—improve people’s understanding of the AI model, help people recognize the model uncertainty, and support people’s calibrated trust in the model. Through randomized controlled experiments, we evaluate whether four types of common model-agnostic explainable AI methods satisfy these properties on two types of decision making tasks where people perceive themselves as having different levels of domain expertise in (i.e., recidivism prediction and forest cover prediction). Our results show that the effects of AI explanations are largely different on decision making tasks where people have varying levels of domain expertise in, and many AI explanations do not satisfy any of the desirable properties for tasks that people have little domain expertise in. Further, for decision making tasks that people are more knowledgeable, feature contribution explanation is shown to satisfy more desiderata of AI explanations, while the explanation that is considered to resemble how human explain decisions (i.e., counterfactual explanation) does not seem to improve calibrated trust. We conclude by discussing the implications of our study for improving the design of XAI methods to better support human decision making.},
	language = {en},
	author = {Wang, Xinru and Yin, Ming},
	year = {2021},
	pages = {11},
}

@article{EffectsMeaningfulMeaninglessExplanations,
	title = {The {Effects} of {Meaningful} and {Meaningless} {Explanations} on {Trust} and {Perceived} {System} {Accuracy} in {Intelligent} {Systems}},
	abstract = {Machine learning and artiﬁcial intelligence algorithms can assist human decision making and analysis tasks. While such technology shows promise, willingness to use and rely on intelligent systems may depend on whether people can trust and understand them. To address this issue, researchers have explored the use of explainable interfaces that attempt to help explain why or how a system produced the output for a given input. However, the effects of meaningful and meaningless explanations (determined by their alignment with human logic) are not properly understood, especially with users who are non-experts in data science. Additionally, we wanted to explore how explanation inclusion and level of meaningfulness would affect the user’s perception of accuracy. We designed a controlled experiment using an image classiﬁcation scenario with local explanations to evaluate and better understand these issues. Our results show that whether explanations are human-meaningful can signiﬁcantly affect perception of a system’s accuracy independent of the actual accuracy observed from system usage. Participants signiﬁcantly underestimated the system’s accuracy when it provided weak, less human-meaningful explanations. Therefore, for intelligent systems with explainable interfaces, this research demonstrates that users are less likely to accurately judge the accuracy of algorithms that do not operate based on humanunderstandable rationale.},
	language = {en},
	author = {Nourani, Mahsan},
	pages = {9},
}

@article{ExplainableRecommendationAttentiveMultiView,
	title = {Explainable {Recommendation} through {Attentive} {Multi}-{View} {Learning}},
	volume = {33},
	issn = {2374-3468, 2159-5399},
	url = {https://www.aaai.org/ojs/index.php/AAAI/article/view/4243},
	doi = {10.1609/aaai.v33i01.33013622},
	abstract = {Recommender systems have been playing an increasingly important role in our daily life due to the explosive growth of information. Accuracy and explainability are two core aspects when we evaluate a recommendation model and have become one of the fundamental trade-offs in machine learning. In this paper, we propose to alleviate the trade-off between accuracy and explainability by developing an explainable deep model that combines the advantages of deep learning-based models and existing explainable methods. The basic idea is to build an initial network based on an explainable deep hierarchy (e.g., Microsoft Concept Graph) and improve the model accuracy by optimizing key variables in the hierarchy (e.g., node importance and relevance). To ensure accurate rating prediction, we propose an attentive multi-view learning framework. The framework enables us to handle sparse and noisy data by co-regularizing among different feature levels and combining predictions attentively. To mine readable explanations from the hierarchy, we formulate personalized explanation generation as a constrained tree node selection problem and propose a dynamic programming algorithm to solve it. Experimental results show that our model outperforms state-of-the-art methods in terms of both accuracy and explainability.},
	language = {en},
	urldate = {2021-03-08},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Gao, Jingyue and Wang, Xiting and Wang, Yasha and Xie, Xing},
	month = jul,
	year = {2019},
	pages = {3622--3629},
}

@inproceedings{ValueSensitiveLearningAnalyticsDesign,
	address = {Tempe AZ USA},
	title = {Towards {Value}-{Sensitive} {Learning} {Analytics} {Design}},
	isbn = {978-1-4503-6256-6},
	url = {https://dl.acm.org/doi/10.1145/3303772.3303798},
	doi = {10.1145/3303772.3303798},
	abstract = {To support ethical considerations and system integrity in learning analytics, this paper introduces two cases of applying the Value Sensitive Design methodology to learning analytics design. The first study applied two methods of Value Sensitive Design, namely stakeholder analysis and value analysis, to a conceptual investigation of an existing learning analytics tool. This investigation uncovered a number of values and value tensions, leading to design trade-offs to be considered in future tool refinements. The second study holistically applied Value Sensitive Design to the design of a recommendation system for the Wikipedia WikiProjects. To proactively consider values among stakeholders, we derived a multi-stage design process that included literature analysis, empirical investigations, prototype development, community engagement, iterative testing and refinement, and continuous evaluation. By reporting on these two cases, this paper responds to a need of practical means to support ethical considerations and human values in learning analytics systems. These two cases demonstrate that Value Sensitive Design could be a viable approach for balancing a wide range of human values, which tend to encompass and surpass ethical issues, in learning analytics design.},
	language = {en},
	urldate = {2021-03-08},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Learning} {Analytics} \& {Knowledge}},
	publisher = {ACM},
	author = {Chen, Bodong and Zhu, Haiyi},
	month = mar,
	year = {2019},
	pages = {343--352},
}

@article{KnowLifeVersatileApproachConstructing,
	title = {{KnowLife}: a versatile approach for constructing a large knowledge graph for biomedical sciences},
	volume = {16},
	issn = {1471-2105},
	shorttitle = {{KnowLife}},
	url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0549-5},
	doi = {10.1186/s12859-015-0549-5},
	abstract = {Background: Biomedical knowledge bases (KB’s) have become important assets in life sciences. Prior work on KB construction has three major limitations. First, most biomedical KBs are manually built and curated, and cannot keep up with the rate at which new findings are published. Second, for automatic information extraction (IE), the text genre of choice has been scientific publications, neglecting sources like health portals and online communities. Third, most prior work on IE has focused on the molecular level or chemogenomics only, like protein-protein interactions or gene-drug relationships, or solely address highly specific topics such as drug effects.
Results: We address these three limitations by a versatile and scalable approach to automatic KB construction. Using a small number of seed facts for distant supervision of pattern-based extraction, we harvest a huge number of facts in an automated manner without requiring any explicit training. We extend previous techniques for pattern-based IE with confidence statistics, and we combine this recall-oriented stage with logical reasoning for consistency constraint checking to achieve high precision. To our knowledge, this is the first method that uses consistency checking for biomedical relations. Our approach can be easily extended to incorporate additional relations and constraints. We ran extensive experiments not only for scientific publications, but also for encyclopedic health portals and online communities, creating different KB’s based on different configurations. We assess the size and quality of each KB, in terms of number of facts and precision. The best configured KB, KnowLife, contains more than 500,000 facts at a precision of 93\% for 13 relations covering genes, organs, diseases, symptoms, treatments, as well as environmental and lifestyle risk factors.
Conclusion: KnowLife is a large knowledge base for health and life sciences, automatically constructed from different Web sources. As a unique feature, KnowLife is harvested from different text genres such as scientific publications, health portals, and online communities. Thus, it has the potential to serve as one-stop portal for a wide range of relations and use cases. To showcase the breadth and usefulness, we make the KnowLife KB accessible through the health portal (http://knowlife.mpi-inf.mpg.de).},
	language = {en},
	number = {1},
	urldate = {2021-03-08},
	journal = {BMC Bioinformatics},
	author = {Ernst, Patrick and Siu, Amy and Weikum, Gerhard},
	month = dec,
	year = {2015},
	pages = {157},
}

@article{MeasuringSocialBiasKnowledge,
	title = {Measuring social bias in knowledge graph embeddings},
	abstract = {It has recently been shown that word embeddings encode social biases, with a harmful impact on downstream tasks. However, to this point there has been no similar work done in the ﬁeld of graph embeddings. We present the ﬁrst study on social bias in knowledge graph embeddings, and propose a new metric suitable for measuring such bias. We conduct experiments on Wikidata and Freebase, and show that, as with word embeddings, harmful social biases related to professions are encoded in the embeddings with respect to gender, religion, ethnicity and nationality. For example, graph embeddings encode the information that men are more likely to be bankers, and women more likely to be homekeepers. As graph embeddings become increasingly utilized, we suggest that it is important the existence of such biases are understood and steps taken to mitigate their impact.},
	language = {en},
	author = {Fisher, Joseph},
	pages = {8},
}

@article{FlexiblyFairRepresentationLearning,
	title = {Flexibly {Fair} {Representation} {Learning} by {Disentanglement}},
	url = {http://arxiv.org/abs/1906.02589},
	abstract = {We consider the problem of learning representations that achieve group and subgroup fairness with respect to multiple sensitive attributes. Taking inspiration from the disentangled representation learning literature, we propose an algorithm for learning compact representations of datasets that are useful for reconstruction and prediction, but are also {\textbackslash}emph\{flexibly fair\}, meaning they can be easily modified at test time to achieve subgroup demographic parity with respect to multiple sensitive attributes and their conjunctions. We show empirically that the resulting encoder---which does not require the sensitive attributes for inference---enables the adaptation of a single representation to a variety of fair classification tasks with new target labels and subgroup definitions.},
	urldate = {2021-03-29},
	journal = {arXiv:1906.02589 [cs, stat]},
	author = {Creager, Elliot and Madras, David and Jacobsen, Jörn-Henrik and Weis, Marissa A. and Swersky, Kevin and Pitassi, Toniann and Zemel, Richard},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.02589},
	keywords = {embedding, fair, fatml, repr},
}

@inproceedings{EffectExplanationsAlgorithmicAccuracy,
	address = {Marina del Ray California},
	title = {The effect of explanations and algorithmic accuracy on visual recommender systems of artistic images},
	isbn = {978-1-4503-6272-6},
	url = {https://dl.acm.org/doi/10.1145/3301275.3302274},
	doi = {10.1145/3301275.3302274},
	abstract = {There are very few works about explaining content-based recommendations of images in the artistic domain. Current works do not provide a perspective of the many variables involved in the user perception of several aspects of the system such as domain knowledge, relevance, explainability, and trust. In this paper, we aim to fill this gap by studying three interfaces, with different levels of explainability, for artistic image recommendation. Our experiments with N=121 users confirm that explanations of recommendations in the image domain are useful and increase user satisfaction, perception of explainability and relevance. Furthermore, our results show that the observed effects are also dependent on the underlying recommendation algorithm used. We tested two algorithms: Deep Neural Networks (DNN), which has high accuracy, and Attractiveness Visual Features (AVF) with high transparency but lower accuracy. Our results indicate that algorithms should not be studied in isolation, but rather in conjunction with interfaces, since both play a significant role in the perception of explainability and trust for image recommendation. Finally, using the framework by Knijnenburg et al., we provide a comprehensive model which synthesizes the effects between different variables involved in the user experience with explainable visual recommender systems of artistic images.},
	language = {en},
	urldate = {2021-03-29},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Dominguez, Vicente and Messina, Pablo and Donoso-Guzmán, Ivania and Parra, Denis},
	month = mar,
	year = {2019},
	keywords = {explanation, rec},
	pages = {408--416},
}

@article{ExplainNotExplainEffects,
	title = {To {Explain} or {Not} to {Explain}: the {Effects} of {Personal} {Characteristics} {When} {Explaining} {Feature}-based {Recommendations} in {Different} {Domains}},
	abstract = {In our daily life, we need to sift through various options which often results in choice overload. Recommender systems help to overcome this problem by suggesting potentially relevant items to the users. Explaining the relevancy of these items to users has become an increasingly important goal. In recent years, a large body of research has shown that explanations are an effective means for supporting decision-making processes. However, still little is known on how to best implement these explanations and how these explanations are perceived. In addition, it is unclear how this perception is affected by the product domain or by users’ personal characteristics. To fill these research gaps, we conducted an online user study (N=291) with different design mock-ups that represent explanations of feature-based recommendations in various recommendation scenarios in two product domains (music and camera) and using different recommendation techniques (content, collaborative, and hybrid). We conducted in each domain a between-subject study with a baseline without explanations and one of the three designs explaining the feature-based recommendations. The study offers empirical evidence on how the perception of feature-based explanations in various recommendation scenarios are moderated by both the product domains and personal characteristics of the user, in particular need for cognition.},
	language = {en},
	author = {Millecamp, Martijn and Naveed, Sidra and Verbert, Katrien and Ziegler, Jürgen},
	keywords = {explanation, rec},
	pages = {9},
}

@article{UnderstandingOriginsBiasWord,
	title = {Understanding the {Origins} of {Bias} in {Word} {Embeddings}},
	url = {http://arxiv.org/abs/1810.03611},
	abstract = {The power of machine learning systems not only promises great technical progress, but risks societal harm. As a recent example, researchers have shown that popular word embedding algorithms exhibit stereotypical biases, such as gender bias. The widespread use of these algorithms in machine learning systems, from automated translation services to curriculum vitae scanners, can amplify stereotypes in important contexts. Although methods have been developed to measure these biases and alter word embeddings to mitigate their biased representations, there is a lack of understanding in how word embedding bias depends on the training data. In this work, we develop a technique for understanding the origins of bias in word embeddings. Given a word embedding trained on a corpus, our method identifies how perturbing the corpus will affect the bias of the resulting embedding. This can be used to trace the origins of word embedding bias back to the original training documents. Using our method, one can investigate trends in the bias of the underlying corpus and identify subsets of documents whose removal would most reduce bias. We demonstrate our techniques on both a New York Times and Wikipedia corpus and find that our influence function-based approximations are very accurate.},
	urldate = {2021-03-28},
	journal = {arXiv:1810.03611 [cs, stat]},
	author = {Brunet, Marc-Etienne and Alkalay-Houlihan, Colleen and Anderson, Ashton and Zemel, Richard},
	month = jun,
	year = {2019},
	note = {arXiv: 1810.03611},
	keywords = {embedding, fair, fatml},
}

@article{BiasedEmbeddingsWildData,
	title = {Biased {Embeddings} from {Wild} {Data}: {Measuring}, {Understanding} and {Removing}},
	shorttitle = {Biased {Embeddings} from {Wild} {Data}},
	url = {http://arxiv.org/abs/1806.06301},
	abstract = {Many modern Artiﬁcial Intelligence (AI) systems make use of data embeddings, particularly in the domain of Natural Language Processing (NLP). These embeddings are learnt from data that has been gathered “from the wild” and have been found to contain unwanted biases. In this paper we make three contributions towards measuring, understanding and removing this problem. We present a rigorous way to measure some of these biases, based on the use of word lists created for social psychology applications; we observe how gender bias in occupations reﬂects actual gender bias in the same occupations in the real world; and ﬁnally we demonstrate how a simple projection can signiﬁcantly reduce the effects of embedding bias. All this is part of an ongoing effort to understand how trust can be built into AI systems.},
	language = {en},
	urldate = {2021-03-28},
	journal = {arXiv:1806.06301 [cs, stat]},
	author = {Sutton, Adam and Lansdall-Welfare, Thomas and Cristianini, Nello},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.06301},
}

@article{LiteratureSurveyAlgorithmsMultilabel,
	title = {A {Literature} {Survey} on {Algorithms} for {Multi}-label {Learning}},
	abstract = {Multi-label Learning is a form of supervised learning where the classiﬁcation algorithm is required to learn from a set of instances, each instance can belong to multiple classes and so after be able to predict a set of class labels for a new instance. This is a generalized version of most popular multi-class problems where each instances is restricted to have only one class label. There exists a wide range of applications for multi-labelled predictions, such as text categorization, semantic image labeling, gene functionality classiﬁcation etc. and the scope and interest is increasing with modern applications. This survey paper introduces the task of multi-label prediction (classiﬁcation), presents the sparse literature in this area in an organized manner, discusses different evaluation metrics and performs a comparative analysis of the existing algorithms. This paper also relates multi-label problems with similar but different problems that are often reduced to multi-label problems to have access to wide range of multi-label algorithms.},
	language = {en},
	author = {Sorower, Mohammad S},
	pages = {25},
}

@article{TrustThinkCognitiveForcing,
	title = {To {Trust} or to {Think}: {Cognitive} {Forcing} {Functions} {Can} {Reduce} {Overreliance} on {AI} in {AI}-assisted {Decision}-making},
	volume = {5},
	language = {en},
	author = {Buçinca, Zana and Malaya, Maja Barbara and Gajos, Krzysztof Z},
	pages = {21},
}

@article{FairnessAwareExplainableRecommendationKnowledge,
	title = {Fairness-{Aware} {Explainable} {Recommendation} over {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2006.02046},
	abstract = {There has been growing attention on fairness considerations recently, especially in the context of intelligent decision making systems. Explainable recommendation systems, in particular, may suffer from both explanation bias and performance disparity. In this paper, we analyze different groups of users according to their level of activity, and find that bias exists in recommendation performance between different groups. We show that inactive users may be more susceptible to receiving unsatisfactory recommendations, due to insufficient training data for the inactive users, and that their recommendations may be biased by the training records of more active users, due to the nature of collaborative filtering, which leads to an unfair treatment by the system. We propose a fairness constrained approach via heuristic re-ranking to mitigate this unfairness problem in the context of explainable recommendation over knowledge graphs. We experiment on several real-world datasets with state-of-the-art knowledge graph-based explainable recommendation algorithms. The promising results show that our algorithm is not only able to provide high-quality explainable recommendations, but also reduces the recommendation unfairness in several respects.},
	urldate = {2021-03-26},
	journal = {arXiv:2006.02046 [cs]},
	author = {Fu, Zuohui and Xian, Yikun and Gao, Ruoyuan and Zhao, Jieyu and Huang, Qiaoying and Ge, Yingqiang and Xu, Shuyuan and Geng, Shijie and Shah, Chirag and Zhang, Yongfeng and de Melo, Gerard},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.02046},
	keywords = {explainable, fair, fatml, kg},
}

@article{LearningGenderNeutralWordEmbeddings,
	title = {Learning {Gender}-{Neutral} {Word} {Embeddings}},
	url = {http://arxiv.org/abs/1809.01496},
	abstract = {Word embedding models have become a fundamental component in a wide range of Natural Language Processing (NLP) applications. However, embeddings trained on human-generated corpora have been demonstrated to inherit strong gender stereotypes that reflect social constructs. To address this concern, in this paper, we propose a novel training procedure for learning gender-neutral word embeddings. Our approach aims to preserve gender information in certain dimensions of word vectors while compelling other dimensions to be free of gender influence. Based on the proposed method, we generate a Gender-Neutral variant of GloVe (GN-GloVe). Quantitative and qualitative experiments demonstrate that GN-GloVe successfully isolates gender information without sacrificing the functionality of the embedding model.},
	urldate = {2021-03-26},
	journal = {arXiv:1809.01496 [cs, stat]},
	author = {Zhao, Jieyu and Zhou, Yichao and Li, Zeyu and Wang, Wei and Chang, Kai-Wei},
	month = aug,
	year = {2018},
	note = {arXiv: 1809.01496},
	keywords = {embedding, fair, fatml},
}

@article{GenderpreservingDebiasingPretrainedWord,
	title = {Gender-preserving {Debiasing} for {Pre}-trained {Word} {Embeddings}},
	url = {http://arxiv.org/abs/1906.00742},
	abstract = {Word embeddings learnt from massive text collections have demonstrated significant levels of discriminative biases such as gender, racial or ethnic biases, which in turn bias the down-stream NLP applications that use those word embeddings. Taking gender-bias as a working example, we propose a debiasing method that preserves non-discriminative gender-related information, while removing stereotypical discriminative gender biases from pre-trained word embeddings. Specifically, we consider four types of information: {\textbackslash}emph\{feminine\}, {\textbackslash}emph\{masculine\}, {\textbackslash}emph\{gender-neutral\} and {\textbackslash}emph\{stereotypical\}, which represent the relationship between gender vs. bias, and propose a debiasing method that (a) preserves the gender-related information in feminine and masculine words, (b) preserves the neutrality in gender-neutral words, and (c) removes the biases from stereotypical words. Experimental results on several previously proposed benchmark datasets show that our proposed method can debias pre-trained word embeddings better than existing SoTA methods proposed for debiasing word embeddings while preserving gender-related but non-discriminative information.},
	urldate = {2021-03-26},
	journal = {arXiv:1906.00742 [cs]},
	author = {Kaneko, Masahiro and Bollegala, Danushka},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.00742},
	keywords = {fair, fatml},
}

@article{UnbiasedLambdaMARTUnbiasedPairwise,
	title = {Unbiased {LambdaMART}: {An} {Unbiased} {Pairwise} {Learning}-to-{Rank} {Algorithm}},
	shorttitle = {Unbiased {LambdaMART}},
	url = {http://arxiv.org/abs/1809.05818},
	abstract = {Although click data is widely used in search systems in practice, so far the inherent bias, most notably position bias, has prevented it from being used in training of a ranker for search, i.e., learning-to-rank. Recently, a number of authors have proposed new techniques referred to as 'unbiased learning-to-rank', which can reduce position bias and train a relatively high-performance ranker using click data. Most of the algorithms, based on the inverse propensity weighting (IPW) principle, first estimate the click bias at each position, and then train an unbiased ranker with the estimated biases using a learning-to-rank algorithm. However, there has not been a method for pairwise learning-to-rank that can jointly conduct debiasing of click data and training of a ranker using a pairwise loss function. In this paper, we propose a novel algorithm, which can jointly estimate the biases at click positions and the biases at unclick positions, and learn an unbiased ranker. Experiments on benchmark data show that our algorithm can significantly outperform existing algorithms. In addition, an online A/B Testing at a commercial search engine shows that our algorithm can effectively conduct debiasing of click data and enhance relevance ranking.},
	urldate = {2021-03-26},
	journal = {arXiv:1809.05818 [cs]},
	author = {Hu, Ziniu and Wang, Yang and Peng, Qu and Li, Hang},
	month = feb,
	year = {2019},
	note = {arXiv: 1809.05818},
	keywords = {learning-to-rank},
}

@article{SystematicReviewTaxonomyExplanations,
	title = {A systematic review and taxonomy of explanations in decision support and recommender systems},
	volume = {27},
	issn = {0924-1868, 1573-1391},
	url = {http://link.springer.com/10.1007/s11257-017-9195-0},
	doi = {10.1007/s11257-017-9195-0},
	abstract = {With the recent advances in the ﬁeld of artiﬁcial intelligence, an increasing number of decision-making tasks are delegated to software systems. A key requirement for the success and adoption of such systems is that users must trust system choices or even fully automated decisions. To achieve this, explanation facilities have been widely investigated as a means of establishing trust in these systems since the early years of expert systems. With today’s increasingly sophisticated machine learning algorithms, new challenges in the context of explanations, accountability, and trust towards such systems constantly arise. In this work, we systematically review the literature on explanations in advice-giving systems. This is a family of systems that includes recommender systems, which is one of the most successful classes of advicegiving software in practice. We investigate the purposes of explanations as well as how they are generated, presented to users, and evaluated. As a result, we derive a novel comprehensive taxonomy of aspects to be considered when designing explanation facilities for current and future decision support systems. The taxonomy includes a variety of different facets, such as explanation objective, responsiveness, content and presentation. Moreover, we identiﬁed several challenges that remain unaddressed so far, for example related to ﬁne-grained issues associated with the presentation of explanations and how explanation facilities are evaluated.},
	language = {en},
	number = {3-5},
	urldate = {2021-04-14},
	journal = {User Modeling and User-Adapted Interaction},
	author = {Nunes, Ingrid and Jannach, Dietmar},
	month = dec,
	year = {2017},
	keywords = {explanation, fatml, survey},
	pages = {393--444},
}

@article{TaxonomyHumanSubjectEvaluation,
	title = {A {Taxonomy} for {Human} {Subject} {Evaluation} of {Black}-{Box} {Explanations} in {XAI}},
	abstract = {The interdisciplinary field of explainable artificial intelligence (XAI) aims to foster human understanding of black-box machine learning models through explanation methods. However, there is no consensus among the involved disciplines regarding the evaluation of their effectiveness - especially concerning the involvement of human subjects. For our community, such involvement is a prerequisite for rigorous evaluation. To better understand how researchers across the disciplines approach human subject XAI evaluation, we propose developing a taxonomy that is iterated with a systematic literature review. Approaching them from an HCI perspective, we analyze which study designs scholar chose for different explanation goals. Based on our preliminary analysis, we present a taxonomy that provides guidance for researchers and practitioners on the design and execution of XAI evaluations. With this position paper, we put our survey approach and preliminary results up for discussion with our fellow researchers.},
	language = {en},
	author = {Chromik, Michael and Schuessler, Martin},
	year = {2020},
	keywords = {explanation, fatml, survey, xai},
	pages = {7},
}

@article{TransparencyDesignArtificialIntelligence,
	title = {Towards {Transparency} by {Design} for {Artificial} {Intelligence}},
	abstract = {In this article, we develop the concept of Transparency by Design that serves as practical guidance in helping promote the beneficial functions of transparency while mitigating its challenges in automated-decision making (ADM) environments. With the rise of artificial intelligence (AI) and the ability of AI systems to make automated and self-learned decisions, a call for transparency of how such systems reach decisions has echoed within academic and policy circles. The term transparency, however, relates to multiple concepts, fulfills many functions, and holds different promises that struggle to be realized in concrete applications. Indeed, the complexity of transparency for ADM shows tension between transparency as a normative ideal and its translation to practical application. To address this tension, we first conduct a review of transparency, analyzing its challenges and limitations concerning automated decision-making practices. We then look at the lessons learned from the development of Privacy by Design, as a basis for developing the Transparency by Design principles. Finally, we propose a set of nine principles to cover relevant contextual, technical, informational, and stakeholder-sensitive considerations. Transparency by Design is a model that helps organizations design transparent AI systems, by integrating these principles in a step-by-step manner and as an ex-ante value, not as an afterthought.},
	language = {en},
	author = {Felzmann, Heike},
	pages = {29},
}

@article{RigorousScienceInterpretableMachine,
	title = {Towards {A} {Rigorous} {Science} of {Interpretable} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1702.08608},
	abstract = {As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.},
	urldate = {2021-04-13},
	journal = {arXiv:1702.08608 [cs, stat]},
	author = {Doshi-Velez, Finale and Kim, Been},
	month = mar,
	year = {2017},
	note = {arXiv: 1702.08608},
	keywords = {explanation, fatml},
}

@article{ManipulatingMeasuringModelInterpretability,
	title = {Manipulating and {Measuring} {Model} {Interpretability}},
	url = {http://arxiv.org/abs/1802.07810},
	abstract = {With machine learning models being increasingly used to aid decision making even in high-stakes domains, there has been a growing interest in developing interpretable models. Although many supposedly interpretable models have been proposed, there have been relatively few experimental studies investigating whether these models achieve their intended effects, such as making people more closely follow a model's predictions when it is beneficial for them to do so or enabling them to detect when a model has made a mistake. We present a sequence of pre-registered experiments(N=3,800) in which we showed participants functionally identical models that varied only in two factors commonly thought to make machine learning models more or less interpretable: the number of features and the transparency of the model (i.e., whether the model internals are clear or black box). Predictably, participants who saw a clear model with few features could better simulate the model's predictions. However, we did not find that participants more closely followed its predictions. Furthermore, showing participants a clear model meant that they were less able to detect and correct for the model's sizable mistakes, seemingly due to information overload. These counterintuitive findings emphasize the importance of testing over intuition when developing interpretable models.},
	urldate = {2021-04-13},
	journal = {arXiv:1802.07810 [cs]},
	author = {Poursabzi-Sangdeh, Forough and Goldstein, Daniel G. and Hofman, Jake M. and Vaughan, Jennifer Wortman and Wallach, Hanna},
	month = jan,
	year = {2021},
	note = {arXiv: 1802.07810},
	keywords = {explanation, fatml},
}

@article{InterpretableWhomRolebasedModel,
	title = {Interpretable to {Whom}? {A} {Role}-based {Model} for {Analyzing} {Interpretable} {Machine} {Learning} {Systems}},
	shorttitle = {Interpretable to {Whom}?},
	url = {http://arxiv.org/abs/1806.07552},
	abstract = {Several researchers have argued that a machine learning system's interpretability should be defined in relation to a specific agent or task: we should not ask if the system is interpretable, but to whom is it interpretable. We describe a model intended to help answer this question, by identifying different roles that agents can fulfill in relation to the machine learning system. We illustrate the use of our model in a variety of scenarios, exploring how an agent's role influences its goals, and the implications for defining interpretability. Finally, we make suggestions for how our model could be useful to interpretability researchers, system developers, and regulatory bodies auditing machine learning systems.},
	urldate = {2021-04-13},
	journal = {arXiv:1806.07552 [cs]},
	author = {Tomsett, Richard and Braines, Dave and Harborne, Dan and Preece, Alun and Chakraborty, Supriyo},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.07552},
	keywords = {explanation, fatml},
}

@article{ExplanationPerspectivesCognitiveSciences,
	title = {Explanation {Perspectives} from the {Cognitive} {Sciences}---{A} {Survey}},
	abstract = {With growing adoption of AI across ﬁelds such as healthcare, ﬁnance, and the justice system, explaining an AI decision has become more important than ever before. Development of human-centric explainable AI (XAI) systems necessitates an understanding of the requirements of the human-inthe-loop seeking the explanation. This includes the cognitive behavioral purpose that the explanation serves for its recipients, and the structure that the explanation uses to reach those ends. An understanding of the psychological foundations of explanations is thus vital for the development of effective human-centric XAI systems. Towards this end, we survey papers from the cognitive science literature that address the following broad questions: (1) what is an explanation, (2) what are explanations for, and 3) what are the characteristics of good and bad explanations. We organize the insights gained therein by means of highlighting the advantages and shortcomings of various explanation structures and theories, discuss their applicability across different domains, and analyze their utility to various types of humans-in-the-loop. We summarize the key takeaways for human-centric design of XAI systems, and recommend strategies to bridge the existing gap between XAI research and practical needs. We hope this work will spark the development of novel human-centric XAI systems.},
	language = {en},
	author = {Srinivasan, Ramya and Chander, Ajay},
	pages = {7},
}

@article{DoesExplainableArtificialIntelligence,
	title = {Does {Explainable} {Artificial} {Intelligence} {Improve} {Human} {Decision}-{Making}?},
	url = {http://arxiv.org/abs/2006.11194},
	abstract = {Explainable AI provides insight into the "why" for model predictions, offering potential for users to better understand and trust a model, and to recognize and correct AI predictions that are incorrect. Prior research on human and explainable AI interactions has focused on measures such as interpretability, trust, and usability of the explanation. Whether explainable AI can improve actual human decision-making and the ability to identify the problems with the underlying model are open questions. Using real datasets, we compare and evaluate objective human decision accuracy without AI (control), with an AI prediction (no explanation), and AI prediction with explanation. We find providing any kind of AI prediction tends to improve user decision accuracy, but no conclusive evidence that explainable AI has a meaningful impact. Moreover, we observed the strongest predictor for human decision accuracy was AI accuracy and that users were somewhat able to detect when the AI was correct versus incorrect, but this was not significantly affected by including an explanation. Our results indicate that, at least in some situations, the "why" information provided in explainable AI may not enhance user decision-making, and further research may be needed to understand how to integrate explainable AI into real systems.},
	urldate = {2021-04-13},
	journal = {arXiv:2006.11194 [cs, stat]},
	author = {Alufaisan, Yasmeen and Marusich, Laura R. and Bakdash, Jonathan Z. and Zhou, Yan and Kantarcioglu, Murat},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.11194},
	keywords = {explanation, fatml},
}

@misc{EvaluatingXAIComparisonRulebaseda,
	title = {Evaluating {XAI}: {A} comparison of rule-based and example-based explanations {\textbar} {Elsevier} {Enhanced} {Reader}},
	shorttitle = {Evaluating {XAI}},
	url = {https://reader.elsevier.com/reader/sd/pii/S0004370220301533?token=17966EB24E5D15B05C855B539F7E9F029DA6599FF402F2B4BEEDF00205FCCE9B3E46ADA02CA5155D69FB29BE11FBD48E&originRegion=us-east-1&originCreation=20210413145725},
	language = {en},
	urldate = {2021-04-13},
	doi = {10.1016/j.artint.2020.103404},
	keywords = {explanation, fatml},
}

@article{BasisSexReviewGender,
	title = {On the {Basis} of {Sex}: {A} {Review} of {Gender} {Bias} in {Machine} {Learning} {Applications}},
	shorttitle = {On the {Basis} of {Sex}},
	url = {http://arxiv.org/abs/2104.02532},
	abstract = {Machine Learning models have been deployed across almost every aspect of society, often in situations that affect the social welfare of many individuals. Although these models offer streamlined solutions to large problems, they may contain biases and treat groups or individuals unfairly. To our knowledge, this review is one of the first to focus specifically on gender bias in applications of machine learning. We first introduce several examples of machine learning gender bias in practice. We then detail the most widely used formalizations of fairness in order to address how to make machine learning models fairer. Specifically, we discuss the most influential bias mitigation algorithms as applied to domains in which models have a high propensity for gender discrimination. We group these algorithms into two overarching approaches -- removing bias from the data directly and removing bias from the model through training -- and we present representative examples of each. As society increasingly relies on artificial intelligence to help in decision-making, addressing gender biases present in these models is imperative. To provide readers with the tools to assess the fairness of machine learning models and mitigate the biases present in them, we discuss multiple open source packages for fairness in AI.},
	urldate = {2021-04-08},
	journal = {arXiv:2104.02532 [cs]},
	author = {Feldman, Tal and Peake, Ashley},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.02532},
	keywords = {fair, fatml},
}

@article{ImpactPresentationStyleHumanInTheLoop,
	title = {The {Impact} of {Presentation} {Style} on {Human}-{In}-{The}-{Loop} {Detection} of {Algorithmic} {Bias}},
	url = {http://arxiv.org/abs/2004.12388},
	abstract = {While decision makers have begun to employ machine learning, machine learning models may make predictions that bias against certain demographic groups. Semi-automated bias detection tools often present reports of automatically-detected biases using a recommendation list or visual cues. However, there is a lack of guidance concerning which presentation style to use in what scenarios. We conducted a small lab study with 16 participants to investigate how presentation style might affect user behaviors in reviewing bias reports. Participants used both a prototype with a recommendation list and a prototype with visual cues for bias detection. We found that participants often wanted to investigate the performance measures that were not automatically detected as biases. Yet, when using the prototype with a recommendation list, they tended to give less consideration to such measures. Grounded in the findings, we propose information load and comprehensiveness as two axes for characterizing bias detection tasks and illustrate how the two axes could be adopted to reason about when to use a recommendation list or visual cues.},
	urldate = {2021-05-05},
	journal = {arXiv:2004.12388 [cs]},
	author = {Law, Po-Ming and Malik, Sana and Du, Fan and Sinha, Moumita},
	month = may,
	year = {2020},
	note = {arXiv: 2004.12388},
	keywords = {fair, fatml, vis},
}

@article{BoxerInteractiveComparisonClassifier,
	title = {Boxer: {Interactive} {Comparison} of {Classifier} {Results}},
	volume = {39},
	issn = {1467-8659},
	shorttitle = {Boxer},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13972},
	doi = {https://doi.org/10.1111/cgf.13972},
	abstract = {Machine learning practitioners often compare the results of different classifiers to help select, diagnose and tune models. We present Boxer, a system to enable such comparison. Our system facilitates interactive exploration of the experimental results obtained by applying multiple classifiers to a common set of model inputs. The approach focuses on allowing the user to identify interesting subsets of training and testing instances and comparing performance of the classifiers on these subsets. The system couples standard visual designs with set algebra interactions and comparative elements. This allows the user to compose and coordinate views to specify subsets and assess classifier performance on them. The flexibility of these compositions allow the user to address a wide range of scenarios in developing and assessing classifiers. We demonstrate Boxer in use cases including model selection, tuning, fairness assessment, and data quality diagnosis.},
	language = {en},
	number = {3},
	urldate = {2021-05-05},
	journal = {Computer Graphics Forum},
	author = {Gleicher, Michael and Barve, Aditya and Yu, Xinyi and Heimerl, Florian},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13972},
	keywords = {fatml, reliable, vis},
	pages = {181--193},
}

@inproceedings{ExplanationsMechanismsSupportingAlgorithmic,
	address = {Montreal QC Canada},
	title = {Explanations as {Mechanisms} for {Supporting} {Algorithmic} {Transparency}},
	isbn = {978-1-4503-5620-6},
	url = {https://dl.acm.org/doi/10.1145/3173574.3173677},
	doi = {10.1145/3173574.3173677},
	abstract = {Transparency can empower users to make informed choices about how they use an algorithmic decision-making system and judge its potential consequences. However, transparency is often conceptualized by the outcomes it is intended to bring about, not the speciﬁcs of mechanisms to achieve those outcomes. We conducted an online experiment focusing on how different ways of explaining Facebook’s News Feed algorithm might affect participants’ beliefs and judgments about the News Feed. We found that all explanations caused participants to become more aware of how the system works, and helped them to determine whether the system is biased and if they can control what they see. The explanations were less effective for helping participants evaluate the correctness of the system’s output, and form opinions about how sensible and consistent its behavior is. We present implications for the design of transparency mechanisms in algorithmic decision-making systems based on these results.},
	language = {en},
	urldate = {2021-05-04},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Rader, Emilee and Cotter, Kelley and Cho, Janghee},
	month = apr,
	year = {2018},
	keywords = {fatml, xai},
	pages = {1--13},
}

@article{FairnessMachineLearning,
	title = {Fairness in {Machine} {Learning}},
	language = {en},
	author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
	keywords = {comps, fair},
	pages = {181},
}

@article{MetricsExplainableAIChallenges,
	title = {Metrics for {Explainable} {AI}: {Challenges} and {Prospects}},
	shorttitle = {Metrics for {Explainable} {AI}},
	url = {http://arxiv.org/abs/1812.04608},
	abstract = {The question addressed in this paper is: If we present to a user an AI system that explains how it works, how do we know whether the explanation works and the user has achieved a pragmatic understanding of the AI? In other words, how do we know that an explanainable AI system (XAI) is any good? Our focus is on the key concepts of measurement. We discuss specific methods for evaluating: (1) the goodness of explanations, (2) whether users are satisfied by explanations, (3) how well users understand the AI systems, (4) how curiosity motivates the search for explanations, (5) whether the user's trust and reliance on the AI are appropriate, and finally, (6) how the human-XAI work system performs. The recommendations we present derive from our integration of extensive research literatures and our own psychometric evaluations.},
	urldate = {2021-04-17},
	journal = {arXiv:1812.04608 [cs]},
	author = {Hoffman, Robert R. and Mueller, Shane T. and Klein, Gary and Litman, Jordan},
	month = feb,
	year = {2019},
	note = {arXiv: 1812.04608},
	keywords = {comps-dm, explanation, fatml, xai},
}

@article{ExploringPromotingDiagnosticTransparency,
	title = {Exploring and {Promoting} {Diagnostic} {Transparency} and {Explainability} in {Online} {Symptom} {Checkers}},
	abstract = {Online symptom checkers (OSC) are widely used intelligent systems in health contexts such as primary care, remote healthcare, and epidemic control. OSCs use algorithms such as machine learning to facilitate self-diagnosis and triage based on symptoms input by healthcare consumers. However, intelligent systems’ lack of transparency and comprehensibility could lead to unintended consequences such as misleading users, especially in high-stakes areas such as healthcare. In this paper, we attempt to enhance diagnostic transparency by augmenting OSCs with explanations. We first conducted an interview study (N=25) to specify user needs for explanations from users of existing OSCs. Then, we designed a COVID-19 OSC that was enhanced with three types of explanations. Our lab-controlled user study (N=20) found that explanations can significantly improve user experience in multiple aspects. We discuss how explanations are interwoven into conversation flow and present implications for future OSC designs.},
	language = {en},
	author = {Tsai, Chun-Hua and You, Yue and Gui, Xinning and Kou, Yubo and Carroll, John M},
	year = {2021},
	pages = {18},
}

@article{EvaluatingXAIComparisonRulebased,
	title = {Evaluating {XAI}: {A} comparison of rule-based and example-based explanations},
	volume = {291},
	issn = {00043702},
	shorttitle = {Evaluating {XAI}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370220301533},
	doi = {10.1016/j.artint.2020.103404},
	language = {en},
	urldate = {2021-04-16},
	journal = {Artificial Intelligence},
	author = {van der Waa, Jasper and Nieuwburg, Elisabeth and Cremers, Anita and Neerincx, Mark},
	month = feb,
	year = {2021},
	pages = {103404},
}

@inproceedings{VisualTextualHybridEffect,
	address = {College Station TX USA},
	title = {Visual, textual or hybrid: the effect of user expertise on different explanations},
	isbn = {978-1-4503-8017-1},
	shorttitle = {Visual, textual or hybrid},
	url = {https://dl.acm.org/doi/10.1145/3397481.3450662},
	doi = {10.1145/3397481.3450662},
	abstract = {As the use of AI algorithms keeps rising continuously, so does the need for their transparency and accountability. However, literature often adopts a one-size-fits-all approach for developing explanations when in practice, the type of explanations needed depends on the type of end-user. This research will look at user expertise as a variable to see how different levels of expertise influence the understanding of explanations. The first iteration consists of developing two common types of explanations (visual and textual explanations) that explain predictions made by a general class of predictive model learners. These explanations are then evaluated by users of different expertise backgrounds to compare the understanding and ease-of-use of each type of explanation with respect to the different expertise groups. Results show strong differences between experts and lay users when using visual and textual explanations, as well as lay users having a preference for visual explanations which they perform significantly worse with. To solve this problem, the second iteration of this research focuses on the shortcomings of the first two explanations and tries to minimize the difference in understanding between both expertise groups. This is done through the means of developing and testing a candidate solution in the form of hybrid explanations, which essentially combine both visual and textual explanations. This hybrid form of explanations shows a significant improvement in terms of correct understanding (for lay users in particular) when compared to visual explanations, whilst not compromising on ease-of-use at the same time.},
	language = {en},
	urldate = {2021-04-16},
	booktitle = {26th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Szymanski, Maxwell and Millecamp, Martijn and Verbert, Katrien},
	month = apr,
	year = {2021},
	keywords = {explanation, fatml},
	pages = {109--119},
}

@inproceedings{SubspaceSearchVisualizationMake,
	address = {Seattle, WA, USA},
	title = {Subspace search and visualization to make sense of alternative clusterings in high-dimensional data},
	isbn = {978-1-4673-4753-2 978-1-4673-4752-5},
	url = {http://ieeexplore.ieee.org/document/6400488/},
	doi = {10.1109/VAST.2012.6400488},
	abstract = {In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufﬁcient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space.},
	language = {en},
	urldate = {2021-04-15},
	booktitle = {2012 {IEEE} {Conference} on {Visual} {Analytics} {Science} and {Technology} ({VAST})},
	publisher = {IEEE},
	author = {Tatu, Andrada and Maas, Fabian and Farber, Ines and Bertini, Enrico and Schreck, Tobias and Seidl, Thomas and Keim, Daniel},
	month = oct,
	year = {2012},
	pages = {63--72},
}

@inproceedings{DonJudgeObjectIts,
	address = {Seattle, WA, USA},
	title = {Don’t {Judge} an {Object} by {Its} {Context}: {Learning} to {Overcome} {Contextual} {Bias}},
	isbn = {978-1-72817-168-5},
	shorttitle = {Don’t {Judge} an {Object} by {Its} {Context}},
	url = {https://ieeexplore.ieee.org/document/9157518/},
	doi = {10.1109/CVPR42600.2020.01108},
	abstract = {Existing models often leverage co-occurrences between objects and their context to improve recognition accuracy. However, strongly relying on context risks a model’s generalizability, especially when typical co-occurrence patterns are absent. This work focuses on addressing such contextual biases to improve the robustness of the learnt feature representations. Our goal is to accurately recognize a category in the absence of its context, without compromising on performance when it co-occurs with context. Our key idea is to decorrelate feature representations of a category from its co-occurring context. We achieve this by learning a feature subspace that explicitly represents categories occurring in the absence of context along side a joint feature subspace that represents both categories and context. Our very simple yet effective method is extensible to two multi-label tasks – object and attribute classiﬁcation. On 4 challenging datasets, we demonstrate the effectiveness of our method in reducing contextual bias.},
	language = {en},
	urldate = {2021-04-15},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Singh, Krishna Kumar and Mahajan, Dhruv and Grauman, Kristen and Lee, Yong Jae and Feiszli, Matt and Ghadiyaram, Deepti},
	month = jun,
	year = {2020},
	pages = {11067--11075},
}

@inproceedings{InterpretingCNNsDecisionTrees,
	address = {Long Beach, CA, USA},
	title = {Interpreting {CNNs} via {Decision} {Trees}},
	isbn = {978-1-72813-293-8},
	url = {https://ieeexplore.ieee.org/document/8953917/},
	doi = {10.1109/CVPR.2019.00642},
	abstract = {This paper1 aims to quantitatively explain the rationales of each prediction that is made by a pre-trained convolutional neural network (CNN). We propose to learn a decision tree, which clariﬁes the speciﬁc reason for each prediction made by the CNN at the semantic level. I.e. the decision tree decomposes feature representations in high conv-layers of the CNN into elementary concepts of object parts. In this way, the decision tree tells people which object parts activate which ﬁlters for the prediction and how much each object part contributes to the prediction score. Such semantic and quantitative explanations for CNN predictions have speciﬁc values beyond the traditional pixel-level analysis of CNNs. More speciﬁcally, our method mines all potential decision modes of the CNN, where each mode represents a typical case of how the CNN uses object parts for prediction. The decision tree organizes all potential decision modes in a coarse-to-ﬁne manner to explain CNN predictions at different ﬁne-grained levels. Experiments have demonstrated the effectiveness of the proposed method.},
	language = {en},
	urldate = {2021-04-15},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Zhang, Quanshi and Yang, Yu and Ma, Haotian and Wu, Ying Nian},
	month = jun,
	year = {2019},
	pages = {6254--6263},
}

@inproceedings{ThinkGetYourPoint,
	address = {College Station TX USA},
	title = {I {Think} {I} {Get} {Your} {Point}, {AI}! {The} {Illusion} of {Explanatory} {Depth} in {Explainable} {AI}},
	isbn = {978-1-4503-8017-1},
	url = {https://dl.acm.org/doi/10.1145/3397481.3450644},
	doi = {10.1145/3397481.3450644},
	abstract = {Unintended consequences of deployed AI systems fueled the call for more interpretability in AI systems. Often explainable AI (XAI) systems provide users with simplifying local explanations for individual predictions but leave it up to them to construct a global understanding of the model behavior. In this work, we examine if non-technical users of XAI fall for an illusion of explanatory depth when interpreting additive local explanations. We applied a mixed methods approach consisting of a moderated study with 40 participants and an unmoderated study with 107 crowd workers using a spreadsheet-like explanation interface based on the SHAP framework. We observed what non-technical users do to form their mental models of global AI model behavior from local explanations and how their perception of understanding decreases when it is examined.},
	language = {en},
	urldate = {2021-04-14},
	booktitle = {26th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Chromik, Michael and Eiband, Malin and Buchner, Felicitas and Krüger, Adrian and Butz, Andreas},
	month = apr,
	year = {2021},
	keywords = {explanation, fatml},
	pages = {307--317},
}

@article{IntersectionExplorerMultiperspectiveApproachExploring,
	title = {{IntersectionExplorer}, a multi-perspective approach for exploring recommendations},
	volume = {121},
	issn = {10715819},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581918301903},
	doi = {10.1016/j.ijhcs.2018.04.008},
	language = {en},
	urldate = {2021-05-10},
	journal = {International Journal of Human-Computer Studies},
	author = {Cardoso, Bruno and Sedrakyan, Gayane and Gutiérrez, Francisco and Parra, Denis and Brusilovsky, Peter and Verbert, Katrien},
	month = jan,
	year = {2019},
	keywords = {comps-iui, rec},
	pages = {73--92},
}

@inproceedings{EachHisOwnHow,
	address = {Chicago, Illinois, USA},
	title = {Each to his own: how different users call for different interaction methods in recommender systems},
	isbn = {978-1-4503-0683-6},
	shorttitle = {Each to his own},
	url = {http://dl.acm.org/citation.cfm?doid=2043932.2043960},
	doi = {10.1145/2043932.2043960},
	abstract = {This paper compares five different ways of interacting with an attribute-based recommender system and shows that different types of users prefer different interaction methods. In an online experiment with an energy-saving recommender system the interaction methods are compared in terms of perceived control, understandability, trust in the system, user interface satisfaction, system effectiveness and choice satisfaction. The comparison takes into account several user characteristics, namely domain knowledge, trusting propensity and persistence. The results show that most users (and particularly domain experts) are most satisfied with a hybrid recommender that combines implicit and explicit preference elicitation, but that novices and maximizers seem to benefit more from a non-personalized recommender that just displays the most popular items.},
	language = {en},
	urldate = {2021-05-10},
	booktitle = {Proceedings of the fifth {ACM} conference on {Recommender} systems - {RecSys} '11},
	publisher = {ACM Press},
	author = {Knijnenburg, Bart P. and Reijmer, Niels J.M. and Willemsen, Martijn C.},
	year = {2011},
	keywords = {comps-iui, rec},
	pages = {141},
}

@article{InteractingRecommendersOverviewResearch,
	title = {Interacting with {Recommenders}—{Overview} and {Research} {Directions}},
	volume = {7},
	issn = {2160-6455, 2160-6463},
	url = {https://dl.acm.org/doi/10.1145/3001837},
	doi = {10.1145/3001837},
	abstract = {Automated recommendations have become a ubiquitous part of today’s online user experience. These systems point us to additional items to purchase in online shops, they make suggestions to us on movies to watch, or recommend us people to connect with on social websites. In many of today’s applications, however, the only way for users to interact with the system is to inspect the recommended items. Often, no mechanisms are implemented for users to give the system feedback on the recommendations or to explicitly specify preferences, which can limit the potential overall value of the system for its users.
            Academic research in recommender systems is largely focused on algorithmic approaches for item selection and ranking. Nonetheless, over the years a variety of proposals were made on how to design more interactive recommenders. This work provides a comprehensive overview on the existing literature on user interaction aspects in recommender systems. We cover existing approaches for preference elicitation and result presentation, as well as proposals that consider recommendation as an interactive process. Throughout the work, we furthermore discuss examples of real-world systems and outline possible directions for future works.},
	language = {en},
	number = {3},
	urldate = {2021-05-10},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Jugovac, Michael and Jannach, Dietmar},
	month = oct,
	year = {2017},
	keywords = {comps-iui, rec, survey},
	pages = {1--46},
}

@incollection{EvaluationUsefulnessCaseBasedExplanation,
	address = {Berlin, Heidelberg},
	title = {An {Evaluation} of the {Usefulness} of {Case}-{Based} {Explanation}},
	volume = {2689},
	isbn = {978-3-540-40433-0},
	url = {http://link.springer.com/10.1007/3-540-45006-8_12},
	abstract = {One of the perceived benefits of Case-Based Reasoning (CBR) is the potential to use retrieved cases to explain predictions. Surprisingly, this aspect of CBR has not been much researched. There has been some early work on knowledge-intensive approaches to CBR where the cases contain explanation patterns (e.g. SWALE). However, a more knowledge-light approach where the case similarity is the basis for explanation has received little attention. To explore this, we have developed a CBR system for predicting blood-alcohol level. We compare explanations of predictions produced with this system with alternative rule-based explanations. The casebased explanations fare very well in this evaluation and score significantly better than the rule-based alternative.},
	language = {en},
	urldate = {2021-05-09},
	booktitle = {Case-{Based} {Reasoning} {Research} and {Development}},
	publisher = {Springer Berlin Heidelberg},
	author = {Cunningham, Pádraig and Doyle, Dónal and Loughrey, John},
	editor = {Ashley, Kevin D. and Bridge, Derek G.},
	year = {2003},
	doi = {10.1007/3-540-45006-8_12},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {122--130},
}

@article{GainingInsightCasebasedExplanation,
	title = {Gaining insight through case-based explanation},
	volume = {32},
	issn = {0925-9902, 1573-7675},
	url = {http://link.springer.com/10.1007/s10844-008-0069-0},
	doi = {10.1007/s10844-008-0069-0},
	abstract = {Because CBR is an interpretable process, it is a reasoning mechanism that supports explanation. This can be done explicitly by the system designers incorporating explanation patterns in cases. This can be termed knowledge-intensive explanation in CBR. However, of more interest here is case-based explanation that works by allowing users to consider the relation between diﬀerent cases. The recommendation of a decision support system can be explained by presenting similar cases that motivate the recommendation. Users can derive insight from similar cases that have diﬀerent outcomes. The diﬀerences in outcome are due to the diﬀerences in the un-matching features (provided the eﬀect is not due to noisy data). This is a more knowledge-light approach to case-based explanation. This is appropriate for weak-theory domains where the details of the causal interactions in the domain are not well understood; experts would however be able to express the direction of causal interactions. In this paper we present such a knowledge-light framework for Case-Based Explanation.},
	language = {en},
	number = {3},
	urldate = {2021-05-09},
	journal = {Journal of Intelligent Information Systems},
	author = {Nugent, Conor and Doyle, Dónal and Cunningham, Pádraig},
	month = jun,
	year = {2009},
	pages = {267--295},
}

@article{RemoteCausesBadExplanations,
	title = {Remote {Causes}, {Bad} {Explanations}?},
	volume = {32},
	issn = {0021-8308, 1468-5914},
	url = {http://doi.wiley.com/10.1111/1468-5914.00197},
	doi = {10.1111/1468-5914.00197},
	language = {en},
	number = {4},
	urldate = {2021-05-09},
	journal = {Journal for the Theory of Social Behaviour},
	author = {Van Bouwel, Jeroen and Weber, Erik},
	month = dec,
	year = {2002},
	pages = {437--449},
}

@article{ReviewExplanationExplanationCase,
	title = {A {Review} of {Explanation} and {Explanation} in {Case}- {Based} {Reasoning}},
	language = {en},
	author = {Doyle, Dónal and Tsymbal, Alexey and Cunningham, Pádraig},
	keywords = {explanation},
	pages = {24},
}

@article{CounterfactualExplanationsOpeningBlack,
	title = {Counterfactual {Explanations} {Without} {Opening} the {Black} {Box}: {Automated} {Decisions} and the {GDPR}},
	issn = {1556-5068},
	shorttitle = {Counterfactual {Explanations} {Without} {Opening} the {Black} {Box}},
	url = {https://www.ssrn.com/abstract=3063289},
	doi = {10.2139/ssrn.3063289},
	language = {en},
	urldate = {2021-05-07},
	journal = {SSRN Electronic Journal},
	author = {Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
	year = {2017},
	keywords = {explanation, fatml},
}

@article{ConversationalProcessesCausalExplanation,
	title = {Conversational processes and causal explanation},
	volume = {107},
	doi = {10.1037/0033-2909.107.1.65},
	abstract = {Causal explanation takes place in and takes the form of conversation. Explanations are selected by questions and are thus governed by general rules of discourse. A conversational model of causal explanation is introduced that explicates social aspects of the explanation process by postulating that good explanations must be relevant to the focus of a 
why question, as well as being true. The notion of explanatory relevance enables an integration of the major models of the attribution process by showing that they use the same counterfactual logic but address different causal questions. The conversational perspective suggests a reinterpretation of many attributional biases, and also highlights the role of interpersonal goals in generating implicit questions, which in turn constrain explanations. Finally, the relevance of the conversational perspective for research on causal networks, the social context of explanation, and intrapsychic explanation is noted. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
	journal = {Psychological Bulletin},
	author = {Hilton, Denis},
	month = jan,
	year = {1990},
	keywords = {explanation, fatml, xai},
	pages = {65--81},
}

@article{CHAPTER15SOCIALNAVIGATION,
	title = {{CHAPTER} 15 ‒ {SOCIAL} {NAVIGATION} {FOR} {SELF}-{IMPROVING} {INTELLIGENT} {EDUCATIONAL} {SYSTEMS}},
	language = {en},
	author = {Brusilovsky, Peter and Rus, Vasile},
	pages = {15},
}

@article{UnmetDataVisualizationNeeds,
	title = {The {Unmet} {Data} {Visualization} {Needs} of {Decision} {Makers} within {Organizations}},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/9408391/},
	doi = {10.1109/TVCG.2021.3074023},
	abstract = {When an organization chooses one course of action over alternatives, this task typically falls on a decision maker with relevant knowledge, experience, and understanding of context. Decision makers rely on data analysis, which is either delegated to analysts, or done on their own. Often the decision maker combines data, likely uncertain or incomplete, with non-formalized knowledge within a multi-objective problem space, weighing the recommendations of analysts within broader contexts and goals. As most past research in visual analytics has focused on understanding the needs and challenges of data analysts, less is known about the tasks and challenges of organizational decision makers, and how visualization support tools might help. Here we characterize the decision maker as a domain expert, review relevant literature in management theories, and report the results of an empirical survey and interviews with people who make organizational decisions. We identify challenges and opportunities for novel visualization tools, including trade-off overviews, scenario-based analysis, interrogation tools, ﬂexible data input and collaboration support. Our ﬁndings stress the need to expand visualization design beyond data analysis into tools for information management.},
	language = {en},
	urldate = {2021-05-06},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Dimara, Evanthia and Zhang, Harry and Tory, Melanie and Franconeri, Steven},
	year = {2021},
	keywords = {decision-making, survey, vis},
	pages = {1--1},
}

@inproceedings{HowRecommendUserTrust,
	address = {Limassol Cyprus},
	title = {How to {Recommend}?: {User} {Trust} {Factors} in {Movie} {Recommender} {Systems}},
	isbn = {978-1-4503-4348-0},
	shorttitle = {How to {Recommend}?},
	url = {https://dl.acm.org/doi/10.1145/3025171.3025209},
	doi = {10.1145/3025171.3025209},
	abstract = {How much trust a user places in a recommender is crucial to the uptake of the recommendations. Although prior work established various factors that build and sustain user trust, their comparative impact has not been studied in depth. This paper presents the results of a crowdsourced study examining the impact of various recommendation interfaces and content selection strategies on user trust. It evaluates the subjective ranking of nine key factors of trust grouped into three dimensions and examines the diﬀerences observed with respect to users’ personality traits.},
	language = {en},
	urldate = {2021-05-06},
	booktitle = {Proceedings of the 22nd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Berkovsky, Shlomo and Taib, Ronnie and Conway, Dan},
	month = mar,
	year = {2017},
	keywords = {comps-iui, eval, rec},
	pages = {287--300},
}

@inproceedings{JointOptimizationAIFairness,
	address = {New York NY USA},
	title = {Joint {Optimization} of {AI} {Fairness} and {Utility}: {A} {Human}-{Centered} {Approach}},
	isbn = {978-1-4503-7110-0},
	shorttitle = {Joint {Optimization} of {AI} {Fairness} and {Utility}},
	url = {https://dl.acm.org/doi/10.1145/3375627.3375862},
	doi = {10.1145/3375627.3375862},
	abstract = {Today, AI is increasingly being used in many high-stakes decisionmaking applications in which fairness is an important concern. Already, there are many examples of AI being biased and making questionable and unfair decisions. The AI research community has proposed many methods to measure and mitigate unwanted biases, but few of them involve inputs from human policy makers. We argue that because different fairness criteria sometimes cannot be simultaneously satisfied, and because achieving fairness often requires sacrificing other objectives such as model accuracy, it is key to acquire and adhere to human policy makers’ preferences on how to make the tradeoff among these objectives. In this paper, we propose a framework and some exemplar methods for eliciting such preferences and for optimizing an AI model according to these preferences.},
	language = {en},
	urldate = {2021-05-25},
	booktitle = {Proceedings of the {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Zhang, Yunfeng and Bellamy, Rachel and Varshney, Kush},
	month = feb,
	year = {2020},
	keywords = {comps-dm},
	pages = {400--406},
}

@article{FairPredictionDisparateImpacta,
	title = {Fair {Prediction} with {Disparate} {Impact}: {A} {Study} of {Bias} in {Recidivism} {Prediction} {Instruments}},
	volume = {5},
	issn = {2167-6461, 2167-647X},
	shorttitle = {Fair {Prediction} with {Disparate} {Impact}},
	url = {http://www.liebertpub.com/doi/10.1089/big.2016.0047},
	doi = {10.1089/big.2016.0047},
	abstract = {Recidivism prediction instruments (RPIs) provide decision-makers with an assessment of the likelihood that a criminal defendant will reoffend at a future point in time. Although such instruments are gaining increasing popularity across the country, their use is attracting tremendous controversy. Much of the controversy concerns potential discriminatory bias in the risk assessments that are produced. This article discusses several fairness criteria that have recently been applied to assess the fairness of RPIs. We demonstrate that the criteria cannot all be simultaneously satisﬁed when recidivism prevalence differs across groups. We then show how disparate impact can arise when an RPI fails to satisfy the criterion of error rate balance.},
	language = {en},
	number = {2},
	urldate = {2021-05-24},
	journal = {Big Data},
	author = {Chouldechova, Alexandra},
	month = jun,
	year = {2017},
	keywords = {comps-dm, fair, fatml},
	pages = {153--163},
}

@article{ImplicitFairnessCriterionUnconstrained,
	title = {The implicit fairness criterion of unconstrained learning},
	url = {http://arxiv.org/abs/1808.10013},
	abstract = {We clarify what fairness guarantees we can and cannot expect to follow from unconstrained machine learning. Specifically, we characterize when unconstrained learning on its own implies group calibration, that is, the outcome variable is conditionally independent of group membership given the score. We show that under reasonable conditions, the deviation from satisfying group calibration is upper bounded by the excess risk of the learned score relative to the Bayes optimal score function. A lower bound confirms the optimality of our upper bound. Moreover, we prove that as the excess risk of the learned score decreases, it strongly violates separation and independence, two other standard fairness criteria. Our results show that group calibration is the fairness criterion that unconstrained learning implicitly favors. On the one hand, this means that calibration is often satisfied on its own without the need for active intervention, albeit at the cost of violating other criteria that are at odds with calibration. On the other hand, it suggests that we should be satisfied with calibration as a fairness criterion only if we are at ease with the use of unconstrained machine learning in a given application.},
	urldate = {2021-05-17},
	journal = {arXiv:1808.10013 [cs, stat]},
	author = {Liu, Lydia T. and Simchowitz, Max and Hardt, Moritz},
	month = jan,
	year = {2019},
	note = {arXiv: 1808.10013},
	keywords = {calibration, comps-dm, fair, fatml},
}

@article{MachinesTeammatesResearchAgenda,
	title = {Machines as teammates: {A} research agenda on {AI} in team collaboration},
	volume = {57},
	issn = {03787206},
	shorttitle = {Machines as teammates},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378720619303337},
	doi = {10.1016/j.im.2019.103174},
	abstract = {What if artificial intelligence (AI) machines became teammates rather than tools? This paper reports on an international initiative by 65 collaboration scientists to develop a research agenda for exploring the potential risks and benefits of machines as teammates (MaT). They generated 819 research questions. A subteam of 12 converged them to a research agenda comprising three design areas – Machine artifact, Collaboration, and Institution – and 17 dualities – significant effects with the potential for benefit or harm. The MaT research agenda offers a structure and archetypal research questions to organize early thought and research in this new area of study.},
	language = {en},
	number = {2},
	urldate = {2021-05-13},
	journal = {Information \& Management},
	author = {Seeber, Isabella and Bittner, Eva and Briggs, Robert O. and de Vreede, Triparna and de Vreede, Gert-Jan and Elkins, Aaron and Maier, Ronald and Merz, Alexander B. and Oeste-Reiß, Sarah and Randrup, Nils and Schwabe, Gerhard and Söllner, Matthias},
	month = mar,
	year = {2020},
	pages = {103174},
}

@article{ExpandingExplainabilitySocialTransparency,
	title = {Expanding {Explainability}: {Towards} {Social} {Transparency} in {AI} systems},
	shorttitle = {Expanding {Explainability}},
	url = {http://arxiv.org/abs/2101.04719},
	doi = {10.1145/3411764.3445188},
	abstract = {As AI-powered systems increasingly mediate consequential decision-making, their explainability is critical for end-users to take informed and accountable actions. Explanations in human-human interactions are socially-situated. AI systems are often socio-organizationally embedded. However, Explainable AI (XAI) approaches have been predominantly algorithm-centered. We take a developmental step towards socially-situated XAI by introducing and exploring Social Transparency (ST), a sociotechnically informed perspective that incorporates the socio-organizational context into explaining AI-mediated decision-making. To explore ST conceptually, we conducted interviews with 29 AI users and practitioners grounded in a speculative design scenario. We suggested constitutive design elements of ST and developed a conceptual framework to unpack ST's effect and implications at the technical, decision-making, and organizational level. The framework showcases how ST can potentially calibrate trust in AI, improve decision-making, facilitate organizational collective actions, and cultivate holistic explainability. Our work contributes to the discourse of Human-Centered XAI by expanding the design space of XAI.},
	urldate = {2021-05-12},
	journal = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
	author = {Ehsan, Upol and Liao, Q. Vera and Muller, Michael and Riedl, Mark O. and Weisz, Justin D.},
	month = may,
	year = {2021},
	note = {arXiv: 2101.04719},
	keywords = {explanation, fatml, xai},
	pages = {1--19},
}

@article{AnalogyBasedCaseBasedReasoningTwo,
	title = {Analogy-{Based} and {Case}-{Based} {Reasoning}: {Two} sides of the same coin},
	shorttitle = {Analogy-{Based} and {Case}-{Based} {Reasoning}},
	url = {http://arxiv.org/abs/1405.7567},
	abstract = {Analogy-Based (or Analogical) and Case-Based Reasoning (ABR and CBR) are two similar problem solving processes based on the adaptation of the solution of past problems for use with a new analogous problem. In this paper we review these two processes and we give some real world examples with emphasis to the field of Medicine, where one can find some of the most common and useful CBR applications. We also underline the differences between CBR and the classical rule-induction algorithms, we discuss the criticism for CBR methods and we focus on the future trends of research in the area of CBR.},
	urldate = {2021-05-12},
	journal = {arXiv:1405.7567 [cs]},
	author = {Voskoglou, Michael Gr and Salem, Abdel-Badeeh M.},
	month = may,
	year = {2014},
	note = {arXiv: 1405.7567},
	keywords = {explanation, fatml, xai},
}

@book{ExplanationsCaseBasedReasoningFoundational,
	title = {Explanations and {Case}-{Based} {Reasoning}: {Foundational} {Issues}},
	volume = {3155},
	isbn = {978-3-540-22882-0},
	shorttitle = {Explanations and {Case}-{Based} {Reasoning}},
	abstract = {By design, Case-Based Reasoning (CBR) systems do not need deep general knowledge. In contrast to (rule-based) expert systems, CBR systems can already be used with just some initial knowledge. Further knowledge can then be added manually or learned over time. CBR systems are not addressing a special group of users. Expert systems, on the other hand, are intended to solve problems similar to human experts. Because of the complexity and difficulty of building and using expert systems, research in this area addressed generating explanations right from the beginning. But for knowledge-intensive CBR applications, the demand for explanations is also growing. This paper is a first pass on examining issues concerning explanations produced by CBR systems from the knowledge containers perspective. It discusses what naturally can be explained by each of the four knowledge containers (vocabulary, similarity measures, adaptation knowledge, and case base) in relation to scientific, conceptual, and cognitive explanations.},
	author = {Roth-Berghofer, Thomas},
	month = aug,
	year = {2004},
	doi = {10.1007/978-3-540-28631-8_29},
	note = {Pages: 403},
	keywords = {explanation, fatml, xai},
}

@article{ThinkingPositivelyExplanatoryFeedback,
	title = {Thinking {Positively} - {Explanatory} {Feedback} for {Conversational} {Recommender} {Systems}},
	abstract = {When it comes to buying expensive goods people expect to be skillfully steered through the options by well-informed sales assistants that are capable of balancing the user’s many and varied requirements. In addition users often need to be educated about the product-space, especially if they are to come to understand what is available and why certain options are being recommended by the sales-assistant. The same issues arise in interactive recommender systems, our online equivalent of a sales assistant and explanation in recommender systems, as a means to educate users and justify recommendations, is now well accepted. In this paper we focus on a novel approach to explanation. Instead of attempting to justify a particular recommendation we focus on how explanations can help users to understand the recommendation opportunities that remain if the current recommendation should not meet their requirements. We describe how this approach to explanation is tightly coupled with the generation of compound critiques, which act as a form of feedback for the users. And we argue that these explanation-rich critiques have the potential to dramatically improve recommender performance and usability.},
	language = {en},
	author = {McCarthy, Kevin and Reilly, James and McGinty, Lorraine and Smyth, Barry},
	keywords = {explanation, fatml, rec, xai},
	pages = {10},
}

@inproceedings{FairnessPracticePractitionerOrientedRubrica,
	address = {Yokohama Japan},
	title = {Towards {Fairness} in {Practice}: {A} {Practitioner}-{Oriented} {Rubric} for {Evaluating} {Fair} {ML} {Toolkits}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Towards {Fairness} in {Practice}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445604},
	doi = {10.1145/3411764.3445604},
	abstract = {In order to support fairness-forward thinking by machine learning (ML) practitioners, fairness researchers have created toolkits that aim to transform state-of-the-art research contributions into easily-accessible APIs. Despite these eforts, recent research indicates a disconnect between the needs of practitioners and the tools ofered by fairness research. By engaging 20 ML practitioners in a simulated scenario in which they utilize fairness toolkits to make critical decisions, this work aims to utilize practitioner feedback to inform recommendations for the design and creation of fair ML toolkits. Through the use of survey and interview data, our results indicate that though fair ML toolkits are incredibly impactful on users’ decision-making, there is much to be desired in the design and demonstration of fairness results. To support the future development and evaluation of toolkits, this work ofers a rubric that can be used to identify critical components of Fair ML toolkits.},
	language = {en},
	urldate = {2021-05-11},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Richardson, Brianna and Garcia-Gathright, Jean and Way, Samuel F. and Thom, Jennifer and Cramer, Henriette},
	month = may,
	year = {2021},
	keywords = {fair, fatml},
	pages = {1--13},
}

@book{DecisionBasedDesign,
	address = {London},
	title = {Decision-{Based} {Design}},
	isbn = {978-1-4471-4035-1 978-1-4471-4036-8},
	url = {http://link.springer.com/10.1007/978-1-4471-4036-8},
	language = {en},
	urldate = {2021-05-11},
	publisher = {Springer London},
	author = {Chen, Wei and Hoyle, Christopher and Wassenaar, Henk Jan},
	year = {2013},
	doi = {10.1007/978-1-4471-4036-8},
}

@inproceedings{ExplainingRecommendationsUsingContexts,
	address = {Tokyo Japan},
	title = {Explaining {Recommendations} {Using} {Contexts}},
	isbn = {978-1-4503-4945-1},
	url = {https://dl.acm.org/doi/10.1145/3172944.3173012},
	doi = {10.1145/3172944.3173012},
	abstract = {Recommender systems support user decision-making, and explanations of recommendations further facilitate their usefulness. Previous explanation styles are based on similar users, similar items, demographics of users, and contents of items. Contexts, such as “usage scenarios” and “accompanying persons,” have not been used for explanations, although they influence user decisions. In this paper, we propose a context style explanation method, presenting contexts suitable for consuming recommended items. The expected impacts of context style explanations are 1) persuasiveness: recognition of suitable context for usage motivates users to consume items, and 2) usefulness: envisioning context helps users to make right choices because the values of items depend on contexts. We evaluate context style persuasiveness and usefulness by a crowdsourcing-based user study in a restaurant recommendation setting. The context style explanation is compared to demographic and content style explanations. We also combine context style and other explanation styles, confirming that hybrid styles improve persuasiveness and usefulness of explanation.},
	language = {en},
	urldate = {2021-05-11},
	booktitle = {23rd {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Sato, Masahiro and Ahsan, Budrul and Nagatani, Koki and Sonoda, Takashi and Zhang, Qian and Ohkuma, Tomoko},
	month = mar,
	year = {2018},
	pages = {659--664},
}

@book{Proceedings2021ACMConference,
	title = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}.},
	isbn = {978-1-4503-8309-7},
	url = {https://dl.acm.org/action/showBook?doi=10.1145/3442188},
	language = {en},
	urldate = {2021-06-06},
	year = {2021},
	note = {OCLC: 1244250272},
}

@book{Proceedings2021ACMConferencea,
	title = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}.},
	isbn = {978-1-4503-8309-7},
	url = {https://dl.acm.org/action/showBook?doi=10.1145/3442188},
	language = {en},
	urldate = {2021-06-06},
	year = {2021},
	note = {OCLC: 1244250272},
}

@inproceedings{ApproachControllingUserModels,
	address = {Santa Monica, California, USA},
	title = {An approach to controlling user models and personalization effects in recommender systems},
	isbn = {978-1-4503-1965-2},
	url = {http://dl.acm.org/citation.cfm?doid=2449396.2449405},
	doi = {10.1145/2449396.2449405},
	abstract = {Personalization nowadays is a commodity in a broad spectrum of computer systems. Examples range from online shops recommending products identiﬁed based on the user’s previous purchases to web search engines sorting search hits based on the user’s browsing history. The aim of such adaptive behavior is to help users to ﬁnd relevant content easier and faster. However, there are a number of negative aspects of this behavior. Adaptive systems have been criticized for violating the usability principles of direct manipulation systems, namely controllability, predictability, transparency, and unobtrusiveness. In this paper, we propose an approach to controlling adaptive behavior in recommender systems. It allows users to get an overview of personalization effects, view the user proﬁle that is used for personalization, and adjust the proﬁle and personalization effects to their needs and preferences. We present this approach using an example of a personalized portal for biochemical literature, whose users are biochemists, biologists and genomicists. Also, we report on a user study evaluating the impact of controllable personalization on the usefulness, usability, user satisfaction, transparency, and trustworthiness of personalized systems.},
	language = {en},
	urldate = {2021-06-04},
	booktitle = {Proceedings of the 2013 international conference on {Intelligent} user interfaces - {IUI} '13},
	publisher = {ACM Press},
	author = {Bakalov, Fedor and Meurs, Marie-Jean and König-Ries, Birgitta and Sateli, Bahar and Witte, René and Butler, Greg and Tsang, Adrian},
	year = {2013},
	pages = {49},
}

@inproceedings{LinkedVisExploringSocialSemantic,
	address = {Santa Monica, California, USA},
	title = {{LinkedVis}: exploring social and semantic career recommendations},
	isbn = {978-1-4503-1965-2},
	shorttitle = {{LinkedVis}},
	url = {http://dl.acm.org/citation.cfm?doid=2449396.2449412},
	doi = {10.1145/2449396.2449412},
	abstract = {This paper presents LinkedVis, an interactive visual recommender system that combines social and semantic knowledge to produce career recommendations based on the LinkedIn API. A collaborative (social) approach is employed to identify professionals with similar career paths and produce personalized recommendations of both companies and roles. To unify semantically identical but lexically distinct entities and arrive at better user models, we employ lightweight natural language processing and entity resolution using semantic information from a variety of end-points on the web. Elements from the underlying recommendation algorithm are exposed through an interactive interface that allows users to manipulate different aspects of the algorithm and the data it operates on, allowing users to explore a variety of “what-if” scenarios around their current proﬁle. We evaluate LinkedVis through leave-one-out accuracy and diversity experiments on a data corpus collected from 47 users and their LinkedIn connections, as well as through a supervised study of 27 users exploring their own proﬁle and recommendations interactively. Results show that our approach outperforms a benchmark recommendation algorithm without semantic resolution in terms of accuracy and diversity, and that the ability to tweak recommendations interactively by adjusting proﬁle item and social connection weights further improves predictive accuracy. Questionnaires on the user experience with the explanatory and interactive aspects of the application reveal very high user acceptance and satisfaction.},
	language = {en},
	urldate = {2021-06-04},
	booktitle = {Proceedings of the 2013 international conference on {Intelligent} user interfaces - {IUI} '13},
	publisher = {ACM Press},
	author = {Bostandjiev, Svetlin and O'Donovan, John and Höllerer, Tobias},
	year = {2013},
	keywords = {comps-iui},
	pages = {107},
}

@inproceedings{GoFlowEffectsTransparency,
	address = {Bari Italy},
	title = {Go {With} the {Flow}: {Effects} of {Transparency} and {User} {Control} on {Targeted} {Advertising} {Using} {Flow} {Charts}},
	isbn = {978-1-4503-4131-8},
	shorttitle = {Go {With} the {Flow}},
	url = {https://dl.acm.org/doi/10.1145/2909132.2909269},
	doi = {10.1145/2909132.2909269},
	abstract = {Targeted advertising reaches users based on various traits, such as demographics or behaviour. However, users are often reluctant to accept ads. We hypothesise that users are more open to targeted advertising if they can inspect, control and thereby understand the process of ad selection. We conducted a between-subjects study (N=200) to investigate to what extent four key aspects of ads (Quality, Behavioural Intention, Understanding and Attitude) may be aﬀected by transparency and user control using a ﬂow chart. Our results indicate that positive eﬀects of ﬂow charts reported from other domains may also be applicable to advertising: Using ﬂow charts to provide transparency together with user control is found to have more positive eﬀects on domain-speciﬁc quality measures than established, text-based approaches and using either of the techniques in isolation. The paper concludes with recommendations for practitioners aiming to improve user response to ads.},
	language = {en},
	urldate = {2021-06-04},
	booktitle = {Proceedings of the {International} {Working} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {ACM},
	author = {Jin, Yucheng and Seipp, Karsten and Duval, Erik and Verbert, Katrien},
	month = jun,
	year = {2016},
	keywords = {comps-iui},
	pages = {68--75},
}

@book{SocialInformationAccess,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Social {Information} {Access}},
	volume = {10100},
	isbn = {978-3-319-90091-9 978-3-319-90092-6},
	url = {http://link.springer.com/10.1007/978-3-319-90092-6},
	language = {en},
	urldate = {2021-06-03},
	publisher = {Springer International Publishing},
	editor = {Brusilovsky, Peter and He, Daqing},
	year = {2018},
	doi = {10.1007/978-3-319-90092-6},
}

@incollection{IntroductionSocialInformationAccess,
	address = {Cham},
	title = {Introduction to {Social} {Information} {Access}},
	volume = {10100},
	isbn = {978-3-319-90091-9 978-3-319-90092-6},
	url = {http://link.springer.com/10.1007/978-3-319-90092-6_1},
	abstract = {This chapter oﬀers an introduction to the emerging ﬁeld of social information access. Social information access focuses on technologies that organize users past interaction with information in order to provide future users with better access to information. These technologies have become increasingly more popular in all areas of information access, including search, browsing, and recommendation. Starting with a deﬁnition of the new ﬁeld and a brief history of social information access, this chapter introduces a multi-aspect classiﬁcation of social information access technologies. The two important factors for our classiﬁcation are the types of information access involved and the source of the social information that has been leveraged to support information access. These two factors are the angles we use in this chapter to create a map of the ﬁeld, as well as to introduce the book structure and the role of the remaining book chapters in covering social information access topics and technologies.},
	language = {en},
	urldate = {2021-06-02},
	booktitle = {Social {Information} {Access}},
	publisher = {Springer International Publishing},
	author = {Brusilovsky, Peter and He, Daqing},
	editor = {Brusilovsky, Peter and He, Daqing},
	year = {2018},
	doi = {10.1007/978-3-319-90092-6_1},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {1--18},
}

@inproceedings{50YearsTestFairness,
	address = {Atlanta GA USA},
	title = {50 {Years} of {Test} ({Un})fairness: {Lessons} for {Machine} {Learning}},
	isbn = {978-1-4503-6125-5},
	shorttitle = {50 {Years} of {Test} ({Un})fairness},
	url = {https://dl.acm.org/doi/10.1145/3287560.3287600},
	doi = {10.1145/3287560.3287600},
	abstract = {Quantitative definitions of what is unfair and what is fair have been introduced in multiple disciplines for well over 50 years, including in education, hiring, and machine learning. We trace how the notion of fairness has been defined within the testing communities of education and hiring over the past half century, exploring the cultural and social context in which different fairness definitions have emerged. In some cases, earlier definitions of fairness are similar or identical to definitions of fairness in current machine learning research, and foreshadow current formal work. In other cases, insights into what fairness means and how to measure it have largely gone overlooked. We compare past and current notions of fairness along several dimensions, including the fairness criteria, the focus of the criteria (e.g., a test, a model, or its use), the relationship of fairness to individuals, groups, and subgroups, and the mathematical method for measuring fairness (e.g., classification, regression). This work points the way towards future research and measurement of (un)fairness that builds from our modern understanding of fairness while incorporating insights from the past.},
	language = {en},
	urldate = {2021-05-29},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Hutchinson, Ben and Mitchell, Margaret},
	month = jan,
	year = {2019},
	keywords = {fair, fatml, iml},
	pages = {49--58},
}

@article{AnotherLookCulturalFairness,
	title = {Another {Look} at "{Cultural} {Fairness}"},
	volume = {8},
	issn = {0022-0655},
	url = {https://www.jstor.org/stable/1433960},
	abstract = {Four definitions of "cultural fairness" are examined and found to be not only mutually contradictory (for reasons which are explained), but all based on the false view that optimum treatment of cultural factors in test construction or test selection can be reduced to completely mechanical procedures. If a conflict arises between the two goals of maximizing a test's validity and minimizing the test's discrimination against certain cultural groups, then a subjective, policy-level decision must be made concerning the relative importance of the two goals. The terms in which this judgment should be made are described, and methods are described for entering the result of this judgment into mechanical procedures for constructing a "culturally optimum" test. Such a test will not necessarily fit any of the four definitions of "cultural fairness."},
	number = {2},
	urldate = {2021-05-29},
	journal = {Journal of Educational Measurement},
	author = {Darlington, Richard B.},
	year = {1971},
	note = {Publisher: [National Council on Measurement in Education, Wiley]},
	keywords = {comps-dm, fair, fatml},
	pages = {71--82},
}

@article{EqualityOpportunitySupervisedLearning,
	title = {Equality of {Opportunity} in {Supervised} {Learning}},
	url = {http://arxiv.org/abs/1610.02413},
	abstract = {We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. We illustrate our notion using a case study of FICO credit scores.},
	urldate = {2021-05-27},
	journal = {arXiv:1610.02413 [cs]},
	author = {Hardt, Moritz and Price, Eric and Srebro, Nathan},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.02413},
	keywords = {comps-dm, fair, fatml},
}

@article{ExplainingRecommendationsSatisfactionVsa,
	title = {Explaining {Recommendations}: {Satisfaction} vs. {Promotion}},
	abstract = {Recommender systems have become a popular technique for helping users select desirable books, movies, music and other items. Most research in the area has focused on developing and evaluating algorithms for efﬁciently producing accurate recommendations. However, the ability to effectively explain its recommendations to users is another important aspect of a recommender system. The only previous investigation of methods for explaining recommendations showed that certain styles of explanations were effective at convincing users to adopt recommendations (i.e. promotion) but failed to show that explanations actually helped users make more accurate decisions (i.e. satisfaction). We present two new methods for explaining recommendations of contentbased and/or collaborative systems and experimentally show that they actually improve user’s estimation of item quality.},
	language = {en},
	author = {Bilgic, Mustafa and Mooney, Raymond J},
	keywords = {explanation, fatml, rec},
	pages = {9},
}

@article{ApplicabilityMLFairnessNotions,
	title = {On the {Applicability} of {ML} {Fairness} {Notions}},
	url = {http://arxiv.org/abs/2006.16745},
	abstract = {ML-based predictive systems are increasingly used to support decisions with a critical impact on individuals' lives such as college admission, job hiring, child custody, criminal risk assessment, etc. As a result, fairness emerged as an important requirement to guarantee that predictive systems do not discriminate against specific individuals or entire sub-populations, in particular, minorities. Given the inherent subjectivity of viewing the concept of fairness, several notions of fairness have been introduced in the literature. This paper is a survey of fairness notions that, unlike other surveys in the literature, addresses the question of "which notion of fairness is most suited to a given real-world scenario and why?". Our attempt to answer this question consists in (1) identifying the set of fairness-related characteristics of the real-world scenario at hand, (2) analyzing the behavior of each fairness notion, and then (3) fitting these two elements to recommend the most suitable fairness notion in every specific setup. The results are summarized in a decision diagram that can be used by practitioners and policy makers to navigate the relatively large catalogue of fairness notions.},
	urldate = {2021-06-08},
	journal = {arXiv:2006.16745 [cs, stat]},
	author = {Makhlouf, Karima and Zhioua, Sami and Palamidessi, Catuscia},
	month = oct,
	year = {2020},
	note = {arXiv: 2006.16745},
	keywords = {comps-dm, fair, fatml},
}

@article{ApplicabilityMachineLearningFairness,
	title = {On the {Applicability} of {Machine} {Learning} {Fairness} {Notions}},
	volume = {23},
	issn = {1931-0145, 1931-0153},
	url = {https://dl.acm.org/doi/10.1145/3468507.3468511},
	doi = {10.1145/3468507.3468511},
	abstract = {Machine Learning (ML) based predictive systems are increasingly used to support decisions with a critical impact on individuals’ lives such as college admission, job hiring, child custody, criminal risk assessment, etc. As a result, fairness emerged as an important requirement to guarantee that ML predictive systems do not discriminate against speciﬁc individuals or entire sub-populations, in particular, minorities. Given the inherent subjectivity of viewing the concept of fairness, several notions of fairness have been introduced in the literature. This paper is a survey of fairness notions that, unlike other surveys in the literature, addresses the question of “which notion of fairness is most suited to a given real-world scenario and why?”. Our attempt to answer this question consists in (1) identifying the set of fairness-related characteristics of the real-world scenario at hand, (2) analyzing the behavior of each fairness notion, and then (3) ﬁtting these two elements to recommend the most suitable fairness notion in every speciﬁc setup. The results are summarized in a decision diagram that can be used by practitioners and policy makers to navigate the relatively large catalogue of ML fairness notions.},
	language = {en},
	number = {1},
	urldate = {2021-06-08},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Makhlouf, Karima and Zhioua, Sami and Palamidessi, Catuscia},
	month = may,
	year = {2021},
	keywords = {comps-dm, fair, fatml},
	pages = {14--23},
}

@article{HumanMachineCollaborationContentRegulation,
	title = {Human-{Machine} {Collaboration} for {Content} {Regulation}: {The} {Case} of {Reddit} {Automoderator}},
	volume = {26},
	issn = {1073-0516, 1557-7325},
	shorttitle = {Human-{Machine} {Collaboration} for {Content} {Regulation}},
	url = {https://dl.acm.org/doi/10.1145/3338243},
	doi = {10.1145/3338243},
	abstract = {What one may say on the internet is increasingly controlled by a mix of automated programs, and decisions made by paid and volunteer human moderators. On the popular social media site Reddit, moderators heavily rely on a configurable, automated program called “Automoderator” (or “Automod”). How do moderators use Automod? What advantages and challenges does the use of Automod present? We participated as Reddit moderators for over a year, and conducted interviews with 16 moderators to understand the use of Automod in the context of the sociotechnical system of Reddit. Our findings suggest a need for audit tools to help tune the performance of automated mechanisms, a repository for sharing tools, and improving the division of labor between human and machine decision making. We offer insights that are relevant to multiple stakeholders—creators of platforms, designers of automated regulation systems, scholars of platform governance, and content moderators.},
	language = {en},
	number = {5},
	urldate = {2021-06-08},
	journal = {ACM Transactions on Computer-Human Interaction},
	author = {Jhaver, Shagun and Birman, Iris and Gilbert, Eric and Bruckman, Amy},
	month = sep,
	year = {2019},
	pages = {1--35},
}

@article{CollaboratingTechnologybasedAutonomousAgents,
	title = {Collaborating with technology-based autonomous agents: {Issues} and research opportunities},
	volume = {30},
	issn = {1066-2243},
	shorttitle = {Collaborating with technology-based autonomous agents},
	url = {https://www.emerald.com/insight/content/doi/10.1108/INTR-12-2019-0503/full/html},
	doi = {10.1108/INTR-12-2019-0503},
	abstract = {Purpose – This article reports the results from a panel discussion held at the 2019 European Conference on Information Systems (ECIS) on the use of technology-based autonomous agents in collaborative work. Design/methodology/approach – The panelists (Drs Izak Benbasat, Paul Benjamin Lowry, Stefan Morana, and Stefan Seidel) presented ideas related to affective and cognitive implications of using autonomous technology-based agents in terms of (1) emotional connection with these agents, (2) decision-making, and (3) knowledge and learning in settings with autonomous agents. These ideas provided the basis for a moderated panel discussion (the moderators were Drs Isabella Seeber and Lena Waizenegger), during which the initial position statements were elaborated on and additional issues were raised.},
	language = {en},
	number = {1},
	urldate = {2021-06-08},
	journal = {Internet Research},
	author = {Seeber, Isabella and Waizenegger, Lena and Seidel, Stefan and Morana, Stefan and Benbasat, Izak and Lowry, Paul Benjamin},
	month = feb,
	year = {2020},
	pages = {1--18},
}

@article{ConferenceNavigatorOnlineSocial,
	title = {Conference {Navigator} 3: {An} {Online} {Social} {Conference} {Support} {System}},
	abstract = {In this poster we introduce Conference Navigator 3, an online social system that helps conference attendees in selecting the talks most relevant to their interests, and it also supports them in exploring and building their research contacts’ network. In particular, we show how some features that we have progressively incorporated in different conferences have significantly increased user participation.},
	language = {en},
	author = {Parra, Denis and Jeng, Wei and Brusilovsky, Peter and López, Claudia and Sahebi, Shaghayegh},
	keywords = {comps-sc, iui},
	pages = {5},
}

@article{AgentsVsUsersVisual,
	title = {Agents {Vs}. {Users}: {Visual} {Recommendation} of {Research} {Talks} with {Multiple} {Dimension} of {Relevance}},
	volume = {6},
	issn = {2160-6455, 2160-6463},
	shorttitle = {Agents {Vs}. {Users}},
	url = {https://dl.acm.org/doi/10.1145/2946794},
	doi = {10.1145/2946794},
	abstract = {Several approaches have been researched to help people deal with abundance of information. An important feature pioneered by social tagging systems and later used in other kinds of social systems is the ability to explore different
              community relevance prospects
              by examining items bookmarked by a specific
              user
              or items associated by various users with a specific
              tag
              . A ranked list of recommended items offered by a specific
              recommender engine
              can be considered as another relevance prospect. The problem that we address is that existing personalized social systems do not allow their users to explore and combine multiple relevance prospects. Only one prospect can be explored at any given time—a list of recommended items, a list of items bookmarked by a specific user, or a list of items marked with a specific tag. In this article, we explore the notion of combining multiple relevance prospects as a way to increase effectiveness and trust. We used a visual approach to recommend articles at a conference by explicitly presenting multiple dimensions of relevance. Suggestions offered by different recommendation techniques were embodied as
              recommender agents
              to put them on the same ground as users and tags. The results of two user studies performed at academic conferences allowed us to obtain interesting insights to enhance user interfaces of personalized social systems. More specifically, effectiveness and probability of item selection increase when users are able to explore and interrelate prospects of items relevance—that is, items bookmarked by users, recommendations and tags. Nevertheless, a less-technical audience may require guidance to understand the rationale of such intersections.},
	language = {en},
	number = {2},
	urldate = {2021-06-07},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Verbert, Katrien and Parra, Denis and Brusilovsky, Peter},
	month = aug,
	year = {2016},
	pages = {1--42},
}

@inproceedings{MyPositionSparkingCivicDiscourse,
	address = {Baltimore Maryland USA},
	title = {{MyPosition}: sparking civic discourse by a public interactive poll visualization},
	isbn = {978-1-4503-2540-0},
	shorttitle = {{MyPosition}},
	url = {https://dl.acm.org/doi/10.1145/2531602.2531639},
	doi = {10.1145/2531602.2531639},
	abstract = {We present the design and evaluation of MyPosition, a public display in the form of a large projection, featuring an interactive poll visualization. MyPosition aims at facilitating the deliberation and comparison of individual opinions on locally relevant topics in an opportunistic and engaging way. We evaluated MyPosition in an in-the-wild study and demonstrated that the engaging nature of the installation was effective in enticing public discussion. We found that (i) the increased identifiability of users positively impacted the engagement with and the social debate around the installation, however lowered the actual voting rate; (ii) people submitted their personal opinion instead of playing around with the interactive features; and (iii) the display led to considerable discussion as well as nudging among people, in particular in zones beyond the interaction area in front of the screen.},
	language = {en},
	urldate = {2021-06-07},
	booktitle = {Proceedings of the 17th {ACM} conference on {Computer} supported cooperative work \& social computing},
	publisher = {ACM},
	author = {Valkanova, Nina and Walter, Robert and Vande Moere, Andrew and Müller, Jörg},
	month = feb,
	year = {2014},
	pages = {1323--1332},
}

@inproceedings{DynamicVisualizationOnlineCollaborative,
	address = {Funchal, Madeira, Portugal},
	title = {Towards a {Dynamic} {Visualization} of {Online} {Collaborative} {Learning}:},
	isbn = {978-989-758-291-2},
	shorttitle = {Towards a {Dynamic} {Visualization} of {Online} {Collaborative} {Learning}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006687202050212},
	doi = {10.5220/0006687202050212},
	language = {en},
	urldate = {2021-06-07},
	booktitle = {Proceedings of the 10th {International} {Conference} on {Computer} {Supported} {Education}},
	publisher = {SCITEPRESS - Science and Technology Publications},
	author = {Koné, Malik and May, Madeth and Iksal, Sébastien},
	year = {2018},
	pages = {205--212},
}

@inproceedings{MyPositionSparkingCivicDiscoursea,
	address = {Baltimore Maryland USA},
	title = {{MyPosition}: sparking civic discourse by a public interactive poll visualization},
	isbn = {978-1-4503-2540-0},
	shorttitle = {{MyPosition}},
	url = {https://dl.acm.org/doi/10.1145/2531602.2531639},
	doi = {10.1145/2531602.2531639},
	abstract = {We present the design and evaluation of MyPosition, a public display in the form of a large projection, featuring an interactive poll visualization. MyPosition aims at facilitating the deliberation and comparison of individual opinions on locally relevant topics in an opportunistic and engaging way. We evaluated MyPosition in an in-the-wild study and demonstrated that the engaging nature of the installation was effective in enticing public discussion. We found that (i) the increased identifiability of users positively impacted the engagement with and the social debate around the installation, however lowered the actual voting rate; (ii) people submitted their personal opinion instead of playing around with the interactive features; and (iii) the display led to considerable discussion as well as nudging among people, in particular in zones beyond the interaction area in front of the screen.},
	language = {en},
	urldate = {2021-06-06},
	booktitle = {Proceedings of the 17th {ACM} conference on {Computer} supported cooperative work \& social computing},
	publisher = {ACM},
	author = {Valkanova, Nina and Walter, Robert and Vande Moere, Andrew and Müller, Jörg},
	month = feb,
	year = {2014},
	keywords = {comps-sc, sc, vis},
	pages = {1323--1332},
}

@inproceedings{RevealitImpactSocialVisualization,
	address = {Paris France},
	title = {Reveal-it!: the impact of a social visualization projection on public awareness and discourse},
	isbn = {978-1-4503-1899-0},
	shorttitle = {Reveal-it!},
	url = {https://dl.acm.org/doi/10.1145/2470654.2466476},
	doi = {10.1145/2470654.2466476},
	abstract = {Public displays and projections are becoming increasingly available in various informal urban settings. However, their potential impact on informing and engaging citizens on relevant issues has still been largely unexplored. In this paper, we show that visualizations displayed in public settings are able to increase social awareness and discourse by exposing underlying patterns in data that is submitted by citizens. We thus introduce the design and evaluation of Reveal-it!, a public, interactive projection that facilitates the comparison of the energy consumptions of individuals and communities. Our in-the-wild deployment in three distinct physical locations provided insights into: 1) how people responded to this form of display in different contexts; 2) how it influenced people’s perception and discussion of individual and communal data; and 3) the implications for a public visualization as a tool for increasing awareness and discourse. We conclude by discussing emerging participant behaviors, as well as some challenges involved in facilitating a socially motivated crowd-sourced visualization in the public context.},
	language = {en},
	urldate = {2021-06-06},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Valkanova, Nina and Jorda, Sergi and Tomitsch, Martin and Vande Moere, Andrew},
	month = apr,
	year = {2013},
	keywords = {comps-sc, sc, social-vis, vis},
	pages = {3461--3470},
}

@article{GroupFairnessIndependenceRevisited,
	title = {Group {Fairness}: {Independence} {Revisited}},
	shorttitle = {Group {Fairness}},
	url = {http://arxiv.org/abs/2101.02968},
	doi = {10.1145/3442188.3445876},
	abstract = {This paper critically examines arguments against independence, a measure of group fairness also known as statistical parity and as demographic parity. In recent discussions of fairness in computer science, some have maintained that independence is not a suitable measure of group fairness. This position is at least partially based on two influential papers (Dwork et al., 2012, Hardt et al., 2016) that provide arguments against independence. We revisit these arguments, and we find that the case against independence is rather weak. We also give arguments in favor of independence, showing that it plays a distinctive role in considerations of fairness. Finally, we discuss how to balance different fairness considerations.},
	urldate = {2021-06-06},
	journal = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	author = {Räz, Tim},
	month = mar,
	year = {2021},
	note = {arXiv: 2101.02968},
	keywords = {comps-dm, fair, fatml},
	pages = {129--137},
}

@article{AlgorithmicFairnessEducation,
	title = {Algorithmic {Fairness} in {Education}},
	language = {en},
	author = {Kizilcec, René F and Lee, Hansol},
	keywords = {comps-dm, education, fair, fatml, iml},
	pages = {30},
}

@article{MeasureMismeasureFairnessCritical,
	title = {The {Measure} and {Mismeasure} of {Fairness}: {A} {Critical} {Review} of {Fair} {Machine} {Learning}},
	shorttitle = {The {Measure} and {Mismeasure} of {Fairness}},
	url = {http://arxiv.org/abs/1808.00023},
	abstract = {The nascent field of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last several years, three formal definitions of fairness have gained prominence: (1) anti-classification, meaning that protected attributes---like race, gender, and their proxies---are not explicitly used to make decisions; (2) classification parity, meaning that common measures of predictive performance (e.g., false positive and false negative rates) are equal across groups defined by the protected attributes; and (3) calibration, meaning that conditional on risk estimates, outcomes are independent of protected attributes. Here we show that all three of these fairness definitions suffer from significant statistical limitations. Requiring anti-classification or classification parity can, perversely, harm the very groups they were designed to protect; and calibration, though generally desirable, provides little guarantee that decisions are equitable. In contrast to these formal fairness criteria, we argue that it is often preferable to treat similarly risky people similarly, based on the most statistically accurate estimates of risk that one can produce. Such a strategy, while not universally applicable, often aligns well with policy objectives; notably, this strategy will typically violate both anti-classification and classification parity. In practice, it requires significant effort to construct suitable risk estimates. One must carefully define and measure the targets of prediction to avoid retrenching biases in the data. But, importantly, one cannot generally address these difficulties by requiring that algorithms satisfy popular mathematical formalizations of fairness. By highlighting these challenges in the foundation of fair machine learning, we hope to help researchers and practitioners productively advance the area.},
	urldate = {2021-06-16},
	journal = {arXiv:1808.00023 [cs]},
	author = {Corbett-Davies, Sam and Goel, Sharad},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.00023},
	keywords = {comps-dm, fair, fatml},
}

@incollection{SocialAdaptiveNavigationSupport,
	address = {Berlin, Heidelberg},
	title = {Social {Adaptive} {Navigation} {Support} for {Open} {Corpus} {Electronic} {Textbooks}},
	volume = {3137},
	isbn = {978-3-540-22895-0 978-3-540-27780-4},
	url = {http://link.springer.com/10.1007/978-3-540-27780-4_6},
	abstract = {Closed corpus AH systems demonstrate what is possible to achieve with adaptive hypermedia technologies; however they are impractical for dealing with large volume of open corpus resources. Our system Knowledge Sea II presented in this paper explores social adaptive navigation support, an approach for providing personalized guidance in open corpus context. Following the ideas of social navigation we have attempted to organize a personalized navigation support that is based on past learners’ interaction with the system. The social adaptive navigation support implemented in our system was considered quite useful by students participated in the classroom study of Knowledge Sea II. At the same time, some user comments indicated the need to provide some more powerful navigation support such as indication of useful pages.},
	language = {en},
	urldate = {2021-06-15},
	booktitle = {Adaptive {Hypermedia} and {Adaptive} {Web}-{Based} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Brusilovsky, Peter and Chavan, Girish and Farzan, Rosta},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and De Bra, Paul M. E. and Nejdl, Wolfgang},
	year = {2004},
	doi = {10.1007/978-3-540-27780-4_6},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {24--33},
}

@inproceedings{SocialNavigationFoodRecipes,
	address = {Seattle, Washington, United States},
	title = {Social navigation of food recipes},
	isbn = {978-1-58113-327-1},
	url = {http://portal.acm.org/citation.cfm?doid=365024.365130},
	doi = {10.1145/365024.365130},
	abstract = {The term Social Navigation captures every-day behaviour used to find information, people, and places – namely through watching, following, and talking to people. We discuss how to design information spaces to allow for social navigation. We applied our ideas in a recipe recommendation system. In a follow-up user study, subjects state that social navigation adds value to the service: it provides for social affordance, and it helps turning a space into a social place. The study also reveals some unresolved design issues, such as the snowball effect where more and more users follow each other down the wrong path, and privacy issues.},
	language = {en},
	urldate = {2021-06-15},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} factors in computing systems  - {CHI} '01},
	publisher = {ACM Press},
	author = {Svensson, Martin and Höök, Kristina and Laaksolahti, Jarmo and Waern, Annika},
	year = {2001},
	pages = {341--348},
}

@article{ExplainingHowYourAI,
	title = {Explaining how your {AI} system is fair},
	url = {http://arxiv.org/abs/2105.00667},
	abstract = {To implement fair machine learning in a sustainable way, choosing the right fairness objective is key. Since fairness is a concept of justice which comes in various, sometimes conflicting definitions, this is not a trivial task though. The most appropriate fairness definition for an artificial intelligence (AI) system is a matter of ethical standards and legal requirements, and the right choice depends on the particular use case and its context. In this position paper, we propose to use a decision tree as means to explain and justify the implemented kind of fairness to the end users. Such a structure would first of all support AI practitioners in mapping ethical principles to fairness definitions for a concrete application and therefore make the selection a straightforward and transparent process. However, this approach would also help document the reasoning behind the decision making. Due to the general complexity of the topic of fairness in AI, we argue that specifying "fairness" for a given use case is the best way forward to maintain confidence in AI systems. In this case, this could be achieved by sharing the reasons and principles expressed during the decision making process with the broader audience.},
	urldate = {2021-06-15},
	journal = {arXiv:2105.00667 [cs]},
	author = {Ruf, Boris and Detyniecki, Marcin},
	month = may,
	year = {2021},
	note = {arXiv: 2105.00667},
	keywords = {comps-dm, fair, fatml},
}

@article{DistributiveJusticeFairnessMetrics,
	title = {Distributive {Justice} and {Fairness} {Metrics} in {Automated} {Decision}-making: {How} {Much} {Overlap} {Is} {There}?},
	shorttitle = {Distributive {Justice} and {Fairness} {Metrics} in {Automated} {Decision}-making},
	url = {http://arxiv.org/abs/2105.01441},
	abstract = {The advent of powerful prediction algorithms led to increased automation of high-stake decisions regarding the allocation of scarce resources such as government spending and welfare support. This automation bears the risk of perpetuating unwanted discrimination against vulnerable and historically disadvantaged groups. Research on algorithmic discrimination in computer science and other disciplines developed a plethora of fairness metrics to detect and correct discriminatory algorithms. Drawing on robust sociological and philosophical discourse on distributive justice, we identify the limitations and problematic implications of prominent fairness metrics. We show that metrics implementing equality of opportunity only apply when resource allocations are based on deservingness, but fail when allocations should reflect concerns about egalitarianism, sufficiency, and priority. We argue that by cleanly distinguishing between prediction tasks and decision tasks, research on fair machine learning could take better advantage of the rich literature on distributive justice.},
	urldate = {2021-06-15},
	journal = {arXiv:2105.01441 [cs, stat]},
	author = {Kuppler, Matthias and Kern, Christoph and Bach, Ruben L. and Kreuter, Frauke},
	month = may,
	year = {2021},
	note = {arXiv: 2105.01441},
	keywords = {comps-dm, fair, fatml},
}

@article{HumanComputerInteractionHumanAIInteraction,
	title = {From {Human}-{Computer} {Interaction} to {Human}-{AI} {Interaction}: {New} {Challenges} and {Opportunities} for {Enabling} {Human}-{Centered} {AI}},
	shorttitle = {From {Human}-{Computer} {Interaction} to {Human}-{AI} {Interaction}},
	url = {http://arxiv.org/abs/2105.05424},
	abstract = {While AI has benefited humans, it may also harm humans if not appropriately developed. We conducted a literature review of current related work in developing AI systems from an HCI perspective. Different from other approaches, our focus is on the unique characteristics of AI technology and the differences between non-AI computing systems and AI systems. We further elaborate on the human-centered AI (HCAI) approach that we proposed in 2019. Our review and analysis highlight unique issues in developing AI systems which HCI professionals have not encountered in non-AI computing systems. To further enable the implementation of HCAI, we promote the research and application of human-AI interaction (HAII) as an interdisciplinary collaboration. There are many opportunities for HCI professionals to play a key role to make unique contributions to the main HAII areas as we identified. To support future HCI practice in the HAII area, we also offer enhanced HCI methods and strategic recommendations. In conclusion, we believe that promoting the HAII research and application will further enable the implementation of HCAI, enabling HCI professionals to address the unique issues of AI systems and develop human-centered AI systems.},
	urldate = {2021-06-14},
	journal = {arXiv:2105.05424 [cs]},
	author = {Xu, Wei and Dainoff, Marvin J. and Ge, Liezhong and Gao, Zaifeng},
	month = may,
	year = {2021},
	note = {arXiv: 2105.05424},
	keywords = {comps-sc, hmi},
}

@article{DistributiveJusticeFairnessMetricsa,
	title = {Distributive {Justice} and {Fairness} {Metrics} in {Automated} {Decision}-making: {How} {Much} {Overlap} {Is} {There}?},
	shorttitle = {Distributive {Justice} and {Fairness} {Metrics} in {Automated} {Decision}-making},
	url = {http://arxiv.org/abs/2105.01441},
	abstract = {The advent of powerful prediction algorithms led to increased automation of high-stake decisions regarding the allocation of scarce resources such as government spending and welfare support. This automation bears the risk of perpetuating unwanted discrimination against vulnerable and historically disadvantaged groups. Research on algorithmic discrimination in computer science and other disciplines developed a plethora of fairness metrics to detect and correct discriminatory algorithms. Drawing on robust sociological and philosophical discourse on distributive justice, we identify the limitations and problematic implications of prominent fairness metrics. We show that metrics implementing equality of opportunity only apply when resource allocations are based on deservingness, but fail when allocations should reflect concerns about egalitarianism, sufficiency, and priority. We argue that by cleanly distinguishing between prediction tasks and decision tasks, research on fair machine learning could take better advantage of the rich literature on distributive justice.},
	urldate = {2021-06-14},
	journal = {arXiv:2105.01441 [cs, stat]},
	author = {Kuppler, Matthias and Kern, Christoph and Bach, Ruben L. and Kreuter, Frauke},
	month = may,
	year = {2021},
	note = {arXiv: 2105.01441},
	keywords = {comps-dm, fair, fatml},
}

@inproceedings{FairnessDefinitionsExplained,
	address = {Gothenburg Sweden},
	title = {Fairness definitions explained},
	isbn = {978-1-4503-5746-3},
	url = {https://dl.acm.org/doi/10.1145/3194770.3194776},
	doi = {10.1145/3194770.3194776},
	abstract = {Algorithm fairness has started to attract the attention of researchers in AI, Software Engineering and Law communities, with more than twenty different notions of fairness proposed in the last few years. Yet, there is no clear agreement on which definition to apply in each situation. Moreover, the detailed differences between multiple definitions are difficult to grasp. To address this issue, this paper collects the most prominent definitions of fairness for the algorithmic classification problem, explains the rationale behind these definitions, and demonstrates each of them on a single unifying case-study. Our analysis intuitively explains why the same case can be considered fair according to some definitions and unfair according to others.},
	language = {en},
	urldate = {2021-06-14},
	booktitle = {Proceedings of the {International} {Workshop} on {Software} {Fairness}},
	publisher = {ACM},
	author = {Verma, Sahil and Rubin, Julia},
	month = may,
	year = {2018},
	keywords = {comps-dm, fair, fatml},
	pages = {1--7},
}

@article{UtilitiesIssueFairnessDecision,
	title = {Utilities and the {Issue} of {Fairness} in a {Decision} {Theoretic} {Model} for {Selection}},
	volume = {13},
	issn = {0022-0655},
	url = {https://www.jstor.org/stable/1434493},
	number = {1},
	urldate = {2021-06-14},
	journal = {Journal of Educational Measurement},
	author = {Sawyer, Richard L. and Cole, Nancy S. and Cole, James W. L.},
	year = {1976},
	note = {Publisher: [National Council on Measurement in Education, Wiley]},
	keywords = {comps-dm, fair, fatml},
	pages = {59--76},
}

@inproceedings{MeaningfullyIntegratingHumanAutonomyTeaming,
	address = {Virtual Event USA},
	title = {Towards {Meaningfully} {Integrating} {Human}-{Autonomy} {Teaming} in {Applied} {Settings}},
	isbn = {978-1-4503-8054-6},
	url = {https://dl.acm.org/doi/10.1145/3406499.3415077},
	doi = {10.1145/3406499.3415077},
	abstract = {Technological advancement goes hand in hand with economic advancement, meaning applied industries like manufacturing, medicine, and retail are set to leverage new practices like human-autonomy teams. These human-autonomy teams call for deep integration between artificial intelligence and the human workers that make up a majority of the workforce. This paper identifies the core principles of the human-autonomy teaming literature relevant to the integration of human-autonomy teams in applied contexts and research due to this large scale implementation of human-autonomy teams. A framework is built and defined from these fundamental concepts, with specific examples of its use in applied contexts and the interactions between various components of the framework. This framework can be utilized by practitioners of human-autonomy teams, allowing them to make informed decisions regarding the integration and training of human-autonomy teams.},
	language = {en},
	urldate = {2021-06-12},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Human}-{Agent} {Interaction}},
	publisher = {ACM},
	author = {Schelble, Beau G. and Flathmann, Christopher and McNeese, Nathan},
	month = nov,
	year = {2020},
	keywords = {collaboration, comps-sc, sc},
	pages = {149--156},
}

@article{FairPredictionDisparateImpact,
	title = {Fair {Prediction} with {Disparate} {Impact}: {A} {Study} of {Bias} in {Recidivism} {Prediction} {Instruments}},
	volume = {5},
	issn = {2167-6461, 2167-647X},
	shorttitle = {Fair {Prediction} with {Disparate} {Impact}},
	url = {http://www.liebertpub.com/doi/10.1089/big.2016.0047},
	doi = {10.1089/big.2016.0047},
	abstract = {Recidivism prediction instruments (RPIs) provide decision-makers with an assessment of the likelihood that a criminal defendant will reoffend at a future point in time. Although such instruments are gaining increasing popularity across the country, their use is attracting tremendous controversy. Much of the controversy concerns potential discriminatory bias in the risk assessments that are produced. This article discusses several fairness criteria that have recently been applied to assess the fairness of RPIs. We demonstrate that the criteria cannot all be simultaneously satisﬁed when recidivism prevalence differs across groups. We then show how disparate impact can arise when an RPI fails to satisfy the criterion of error rate balance.},
	language = {en},
	number = {2},
	urldate = {2021-06-09},
	journal = {Big Data},
	author = {Chouldechova, Alexandra},
	month = jun,
	year = {2017},
	pages = {153--163},
}

@article{UnderstandingEffectsExplanationTypes,
	title = {Understanding the {Effects} of {Explanation} {Types} and {User} {Motivations} on {Recommender} {System} {Use}},
	abstract = {It is becoming increasingly common for intelligent systems, such as recommender systems, to provide explanations for their generated recommendations to the users. However, we still do not have a good understanding of what types of explanations work and what factors affect the effectiveness of different types of explanations. Our work focuses on explanations for movie recommender systems. This paper presents a mixed study where we hypothesize that the type of explanation, as well as user motivation for watching movies, will affect how users respond to recommendation system explanations. Our study compares three types of explanations: i) neighbor-ratings, ii) proﬁle-based, and iii) event-based, as well as three types of user movie-watching motivations: i) hedonic (fun and relaxation), ii) eudaimonic (inspiration and meaningfulness), and iii) educational (learning new content). We discuss the implications of the study results for the design of explanations for movie recommender systems, and future novel research directions that the study results uncover.},
	language = {en},
	author = {Li, Qing and Chu, Sharon Lynn and Rao, Nanjie and Nourani, Mahsan},
	pages = {9},
}

@inproceedings{InterpretableDecisionSetsJoint,
	address = {San Francisco California USA},
	title = {Interpretable {Decision} {Sets}: {A} {Joint} {Framework} for {Description} and {Prediction}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {Interpretable {Decision} {Sets}},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939874},
	doi = {10.1145/2939672.2939874},
	abstract = {One of the most important obstacles to deploying predictive models is the fact that humans do not understand and trust them. Knowing which variables are important in a model’s prediction and how they are combined can be very powerful in helping people understand and trust automatic decision making systems.},
	language = {en},
	urldate = {2021-06-19},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Lakkaraju, Himabindu and Bach, Stephen H. and Leskovec, Jure},
	month = aug,
	year = {2016},
	keywords = {fatml, xai},
	pages = {1675--1684},
}

@inproceedings{AnsweringWhyWhyNot,
	address = {Montr\&\#233;al, Qu\&\#233;bec, Canada},
	title = {Answering why and why not questions in user interfaces},
	isbn = {978-1-59593-372-0},
	url = {http://portal.acm.org/citation.cfm?doid=1124772.1124832},
	doi = {10.1145/1124772.1124832},
	abstract = {Modern applications such as Microsoft Word have many automatic features and hidden dependencies that are frequently helpful but can be mysterious to both novice and expert users. The “Crystal” application framework provides an architecture and interaction techniques that allow programmers to create applications that let the user ask a wide variety of questions about why things did and did not happen, and how to use the related features of the application without using natural language. A user can point to an object or a blank space and get a popup list of questions about it, or the user can ask about recent actions from a temporal list. Parts of a text editor were implemented to show that these techniques are feasible, and a user test suggests that they are helpful and well-liked.},
	language = {en},
	urldate = {2021-06-19},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} {Factors} in computing systems  - {CHI} '06},
	publisher = {ACM Press},
	author = {Myers, Brad A. and Weitzman, David A. and Ko, Andrew J. and Chau, Duen H.},
	year = {2006},
	pages = {397},
}

@inproceedings{AnsweringWhyWhyNota,
	address = {Montr\&\#233;al, Qu\&\#233;bec, Canada},
	title = {Answering why and why not questions in user interfaces},
	isbn = {978-1-59593-372-0},
	url = {http://portal.acm.org/citation.cfm?doid=1124772.1124832},
	doi = {10.1145/1124772.1124832},
	abstract = {Modern applications such as Microsoft Word have many automatic features and hidden dependencies that are frequently helpful but can be mysterious to both novice and expert users. The “Crystal” application framework provides an architecture and interaction techniques that allow programmers to create applications that let the user ask a wide variety of questions about why things did and did not happen, and how to use the related features of the application without using natural language. A user can point to an object or a blank space and get a popup list of questions about it, or the user can ask about recent actions from a temporal list. Parts of a text editor were implemented to show that these techniques are feasible, and a user test suggests that they are helpful and well-liked.},
	language = {en},
	urldate = {2021-06-19},
	booktitle = {Proceedings of the {SIGCHI} conference on {Human} {Factors} in computing systems  - {CHI} '06},
	publisher = {ACM Press},
	author = {Myers, Brad A. and Weitzman, David A. and Ko, Andrew J. and Chau, Duen H.},
	year = {2006},
	keywords = {comps-dm, explanation, hci, iui},
	pages = {397},
}

@inproceedings{TellMeMoreEffects,
	address = {Austin, Texas, USA},
	title = {Tell me more?: the effects of mental model soundness on personalizing an intelligent agent},
	isbn = {978-1-4503-1015-4},
	shorttitle = {Tell me more?},
	url = {http://dl.acm.org/citation.cfm?doid=2207676.2207678},
	doi = {10.1145/2207676.2207678},
	abstract = {What does a user need to know to productively work with an intelligent agent? Intelligent agents and recommender systems are gaining widespread use, potentially creating a need for end users to understand how these systems operate in order to fix their agent’s personalized behavior. This paper explores the effects of mental model soundness on such personalization by providing structural knowledge of a music recommender system in an empirical study. Our findings show that participants were able to quickly build sound mental models of the recommender system’s reasoning, and that participants who most improved their mental models during the study were significantly more likely to make the recommender operate to their satisfaction. These results suggest that by helping end users understand a system’s reasoning, intelligent agents may elicit more and better feedback, thus more closely aligning their output with each user’s intentions.},
	language = {en},
	urldate = {2021-06-19},
	booktitle = {Proceedings of the 2012 {ACM} annual conference on {Human} {Factors} in {Computing} {Systems} - {CHI} '12},
	publisher = {ACM Press},
	author = {Kulesza, Todd and Stumpf, Simone and Burnett, Margaret and Kwan, Irwin},
	year = {2012},
	keywords = {comps-iui, iui, rec},
	pages = {1},
}

@article{GeneratingUnderstandingPersonalizedExplanations,
	title = {Generating and {Understanding} {Personalized} {Explanations} in {Hybrid} {Recommender} {Systems}},
	volume = {10},
	issn = {2160-6455, 2160-6463},
	url = {https://dl.acm.org/doi/10.1145/3365843},
	doi = {10.1145/3365843},
	abstract = {Recommender systems are ubiquitous and shape the way users access information and make decisions. As these systems become more complex, there is a growing need for transparency and interpretability. In this article, we study the problem of generating and visualizing personalized explanations for recommender systems that incorporate signals from many different data sources. We use a flexible, extendable probabilistic programming approach and show how we can generate real-time personalized recommendations. We then turn these personalized recommendations into explanations. We perform an extensive user study to evaluate the benefits of explanations for hybrid recommender systems. We conduct a crowd-sourced user study where our system generates personalized recommendations and explanations for real users of the last.fm music platform. First, we evaluate the performance of the recommendations in terms of perceived accuracy and novelty. Next, we experiment with (1) different explanation styles (e.g., user-based, item-based), (2) manipulating the number of explanation styles presented, and (3) manipulating the presentation format (e.g., textual vs. visual). We also apply a mixed-model statistical analysis to consider user personality traits as a control variable and demonstrate the usefulness of our approach in creating personalized hybrid explanations with different style, number, and format. Finally, we perform a post analysis that shows different preferences for explanation styles between experienced and novice last.fm users.},
	language = {en},
	number = {4},
	urldate = {2021-06-19},
	journal = {ACM Transactions on Interactive Intelligent Systems},
	author = {Kouki, Pigi and Schaffer, James and Pujara, Jay and O’Donovan, John and Getoor, Lise},
	month = dec,
	year = {2020},
	keywords = {comps-iui, explanation, rec},
	pages = {1--40},
}

@article{RolesBotsPlayWikipedia,
	title = {The {Roles} {Bots} {Play} in {Wikipedia}},
	volume = {3},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3359317},
	doi = {10.1145/3359317},
	language = {en},
	number = {CSCW},
	urldate = {2021-06-18},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Zheng, Lei (Nico) and Albano, Christopher M. and Vora, Neev M. and Mai, Feng and Nickerson, Jeffrey V.},
	month = nov,
	year = {2019},
	keywords = {comps-sc, hmi, well-written, wikipedia},
	pages = {1--20},
}

@article{HumanCenteredEvaluationsHumanCenteredMachine,
	title = {Human-{Centered} {Evaluations} in {Human}-{Centered} {Machine} {Learning}},
	abstract = {Visual analytics systems integrate interactive visualizations and machine learning to enable expert users to solve complex analysis tasks. Applications combine techniques from various ﬁelds of research and are consequently not trivial to evaluate. The result is a lack of structure and comparability between evaluations. In this survey, we provide a comprehensive overview of evaluations in the ﬁeld of human-centered machine learning. We particularly focus on human-related factors that inﬂuence trust, interpretability, and explainability. We analyze the evaluations presented in papers from top conferences and journals in information visualization and human-computer interaction to provide a systematic review of their setup and ﬁndings. From this survey, we distill design dimensions for structured evaluations, identify evaluation gaps, and derive future research opportunities.},
	language = {en},
	journal = {Computer Graphics Forum},
	author = {Sperrle, F and El-Assady, M and Guo, G and Borgo, R and Chau, D Horng and Endert, A and Keim, D},
	year = {2021},
	keywords = {eval, fatml, xai},
	pages = {25},
}

@article{OnlineDecisionTreesFairness,
	title = {Online {Decision} {Trees} with {Fairness}},
	url = {http://arxiv.org/abs/2010.08146},
	abstract = {While artificial intelligence (AI)-based decision-making systems are increasingly popular, significant concerns on the potential discrimination during the AI decision-making process have been observed. For example, the distribution of predictions is usually biased and dependents on the sensitive attributes (e.g., gender and ethnicity). Numerous approaches have therefore been proposed to develop decision-making systems that are discrimination-conscious by-design, which are typically batch-based and require the simultaneous availability of all the training data for model learning. However, in the real-world, the data streams usually come on the fly which requires the model to process each input data once "on arrival" and without the need for storage and reprocessing. In addition, the data streams might also evolve over time, which further requires the model to be able to simultaneously adapt to non-stationary data distributions and time-evolving bias patterns, with an effective and robust trade-off between accuracy and fairness. In this paper, we propose a novel framework of online decision tree with fairness in the data stream with possible distribution drifting. Specifically, first, we propose two novel fairness splitting criteria that encode the data as well as possible, while simultaneously removing dependence on the sensitive attributes, and further adapts to non-stationary distribution with fine-grained control when needed. Second, we propose two fairness decision tree online growth algorithms that fulfills different online fair decision-making requirements. Our experiments show that our algorithms are able to deal with discrimination in massive and non-stationary streaming environments, with a better trade-off between fairness and predictive performance.},
	urldate = {2021-06-17},
	journal = {arXiv:2010.08146 [cs]},
	author = {Zhang, Wenbin and Zhao, Liang},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.08146},
	keywords = {fair, fatml, vis},
}

@incollection{TextualExplanationsSelfDrivingVehicles,
	address = {Cham},
	title = {Textual {Explanations} for {Self}-{Driving} {Vehicles}},
	volume = {11206},
	isbn = {978-3-030-01215-1 978-3-030-01216-8},
	url = {http://link.springer.com/10.1007/978-3-030-01216-8_35},
	language = {en},
	urldate = {2021-06-17},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Kim, Jinkyu and Rohrbach, Anna and Darrell, Trevor and Canny, John and Akata, Zeynep},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	doi = {10.1007/978-3-030-01216-8_35},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {explanation, xai},
	pages = {577--593},
}

@article{DesignConsiderationsCollaborativeVisual,
	title = {Design {Considerations} for {Collaborative} {Visual} {Analytics}},
	volume = {7},
	issn = {1473-8716, 1473-8724},
	url = {http://journals.sagepub.com/doi/10.1057/palgrave.ivs.9500167},
	doi = {10.1057/palgrave.ivs.9500167},
	abstract = {Visualizations leverage the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Although most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. Thus, to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems.},
	language = {en},
	number = {1},
	urldate = {2021-06-24},
	journal = {Information Visualization},
	author = {Heer, Jeffrey and Agrawala, Maneesh},
	month = mar,
	year = {2008},
	pages = {49--62},
}

@article{DesignConsiderationsCollaborativeVisuala,
	title = {Design {Considerations} for {Collaborative} {Visual} {Analytics}},
	volume = {7},
	issn = {1473-8716},
	url = {https://doi.org/10.1057/palgrave.ivs.9500167},
	doi = {10.1057/palgrave.ivs.9500167},
	abstract = {Visualizations leverage the human visual system to support the process of sensemaking, in which information is collected, organized, and analyzed to generate knowledge and inform action. Although most research to date assumes a single-user focus on perceptual and cognitive processes, in practice, sensemaking is often a social process involving parallelization of effort, discussion, and consensus building. Thus, to fully support sensemaking, interactive visualization should also support social interaction. However, the most appropriate collaboration mechanisms for supporting this interaction are not immediately clear. In this article, we present design considerations for asynchronous collaboration in visual analysis environments, highlighting issues of work parallelization, communication, and social organization. These considerations provide a guide for the design and evaluation of collaborative visualization systems.},
	number = {1},
	urldate = {2021-06-24},
	journal = {Information Visualization},
	author = {Heer, Jeffrey and Agrawala, Maneesh},
	month = mar,
	year = {2008},
	note = {Publisher: SAGE Publications},
	keywords = {collaborative, comps-sc, sc},
	pages = {49--62},
}

@inproceedings{PersonalizedWebExplorationTask,
	address = {Beijing, China},
	title = {Personalized web exploration with task models},
	isbn = {978-1-60558-085-2},
	url = {http://portal.acm.org/citation.cfm?doid=1367497.1367499},
	doi = {10.1145/1367497.1367499},
	abstract = {Personalized Web search has emerged as one of the hottest topics for both the Web industry and academic researchers. However, the majority of studies on personalized search focused on a rather simple type of search, which leaves an important research topic –the personalization in exploratory searches – as an under-studied area. In this paper, we present a study of personalization in taskbased information exploration using a system called TaskSieve. TaskSieve is a Web search system that utilizes a relevance feedback based profile, called a “task model”, for personalization. Its innovations include flexible and user controlled integration of queries and task models, task-infused text snippet generation, and on-screen visualization of task models. Through an empirical study using human subjects conducting task-based exploration searches, we demonstrate that TaskSieve pushes significantly more relevant documents to the top of search result lists as compared to a traditional search system. TaskSieve helps users select significantly more accurate information for their tasks, allows the users to do so with higher productivity, and is viewed more favorably by subjects under several usability related characteristics.},
	language = {en},
	urldate = {2021-06-23},
	booktitle = {Proceeding of the 17th international conference on {World} {Wide} {Web}  - {WWW} '08},
	publisher = {ACM Press},
	author = {Ahn, Jae-wook and Brusilovsky, Peter and He, Daqing and Grady, Jonathan and Li, Qi},
	year = {2008},
	keywords = {comps-sc, social-search},
	pages = {1},
}

@article{DissectingRacialBiasAlgorithm,
	title = {Dissecting racial bias in an algorithm used to manage the health of populations},
	language = {en},
	author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
	year = {2019},
	keywords = {comps-dm, fair, fatml},
	pages = {8},
}

@book{SocialNavigationInformationSpace,
	address = {London},
	series = {Computer {Supported} {Cooperative} {Work}},
	title = {Social {Navigation} of {Information} {Space}},
	isbn = {978-1-85233-090-3 978-1-4471-0837-5},
	url = {http://link.springer.com/10.1007/978-1-4471-0837-5},
	language = {en},
	urldate = {2021-06-22},
	publisher = {Springer London},
	editor = {Munro, Alan J. and Höök, Kristina and Benyon, David and Diaper, Dan and Sanger, Colston},
	year = {1999},
	doi = {10.1007/978-1-4471-0837-5},
}

@inproceedings{LearningEstimateTravelTime,
	address = {London United Kingdom},
	title = {Learning to {Estimate} the {Travel} {Time}},
	isbn = {978-1-4503-5552-0},
	url = {https://dl.acm.org/doi/10.1145/3219819.3219900},
	doi = {10.1145/3219819.3219900},
	abstract = {Vehicle travel time estimation or estimated time of arrival (ETA) is one of the most important location-based services (LBS). It is becoming increasingly important and has been widely used as a basic service in navigation systems and intelligent transportation systems. This paper presents a novel machine learning solution to predict the vehicle travel time based on floating-car data. First, we formulate ETA as a pure spatial-temporal regression problem based on a large set of effective features. Second, we adapt different existing machine learning models to solve the regression problem. Furthermore, we propose a Wide-Deep-Recurrent (WDR) learning model to accurately predict the travel time along a given route at a given departure time. We then jointly train wide linear models, deep neural networks and recurrent neural networks together to take full advantages of all three models. We evaluate our solution offline with millions of historical vehicle travel data. We also deploy the proposed solution on Didi Chuxing’s platform, which services billions of ETA requests and benefits millions of customers per day. Our extensive evaluations show that our proposed deep learning algorithm significantly outperforms the state-of-the-art learning algorithms, as well as the solutions provided by leading industry LBS providers.},
	language = {en},
	urldate = {2021-06-22},
	booktitle = {Proceedings of the 24th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Wang, Zheng and Fu, Kun and Ye, Jieping},
	month = jul,
	year = {2018},
	keywords = {self-driving-car},
	pages = {858--866},
}

@article{DeepLearningTrafficPrediction,
	title = {Deep {Learning} on {Traffic} {Prediction}: {Methods}, {Analysis} and {Future} {Directions}},
	issn = {1558-0016},
	shorttitle = {Deep {Learning} on {Traffic} {Prediction}},
	doi = {10.1109/TITS.2021.3054840},
	abstract = {Traffic prediction plays an essential role in intelligent transportation system. Accurate traffic prediction can assist route planing, guide vehicle dispatching, and mitigate traffic congestion. This problem is challenging due to the complicated and dynamic spatio-temporal dependencies between different regions in the road network. Recently, a significant amount of research efforts have been devoted to this area, especially deep learning method, greatly advancing traffic prediction abilities. The purpose of this paper is to provide a comprehensive survey on deep learning-based approaches in traffic prediction from multiple perspectives. Specifically, we first summarize the existing traffic prediction methods, and give a taxonomy. Second, we list the state-of-the-art approaches in different traffic prediction applications. Third, we comprehensively collect and organize widely used public datasets in the existing literature to facilitate other researchers. Furthermore, we give an evaluation and analysis by conducting extensive experiments to compare the performance of different methods on a real-world public dataset. Finally, we discuss open challenges in this field.},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Yin, Xueyan and Wu, Genze and Wei, Jinze and Shen, Yanming and Qi, Heng and Yin, Baocai},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {self-driving-car},
	pages = {1--17},
}

@misc{DynamicApproachPredictTravel,
	title = {A dynamic approach to predict travel time in real time using data driven techniques and comprehensive data sources {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S2666691X20300269?token=55EDCD634C1423FA3BFEE4F73467AA116DE1BC2DA3D997C370D31C7CF9C6FD8004C8F05CBC07CF9F8E177AF975B0E56F&originRegion=us-east-1&originCreation=20210621075442},
	language = {en},
	urldate = {2021-06-22},
	doi = {10.1016/j.treng.2020.100025},
	keywords = {self-driving},
}

@article{GettingFairnessRightToolbox,
	title = {Getting {Fairness} {Right}: {Towards} a {Toolbox} for {Practitioners}},
	shorttitle = {Getting {Fairness} {Right}},
	url = {http://arxiv.org/abs/2003.06920},
	abstract = {The potential risk of AI systems unintentionally embedding and reproducing bias has attracted the attention of machine learning practitioners and society at large. As policy makers are willing to set the standards of algorithms and AI techniques, the issue on how to refine existing regulation, in order to enforce that decisions made by automated systems are fair and non-discriminatory, is again critical. Meanwhile, researchers have demonstrated that the various existing metrics for fairness are statistically mutually exclusive and the right choice mostly depends on the use case and the definition of fairness. Recognizing that the solutions for implementing fair AI are not purely mathematical but require the commitments of the stakeholders to define the desired nature of fairness, this paper proposes to draft a toolbox which helps practitioners to ensure fair AI practices. Based on the nature of the application and the available training data, but also on legal requirements and ethical, philosophical and cultural dimensions, the toolbox aims to identify the most appropriate fairness objective. This approach attempts to structure the complex landscape of fairness metrics and, therefore, makes the different available options more accessible to non-technical people. In the proven absence of a silver bullet solution for fair AI, this toolbox intends to produce the fairest AI systems possible with respect to their local context.},
	urldate = {2021-06-21},
	journal = {arXiv:2003.06920 [cs]},
	author = {Ruf, Boris and Boutharouite, Chaouki and Detyniecki, Marcin},
	month = mar,
	year = {2020},
	note = {arXiv: 2003.06920},
	keywords = {comps-dm, fair, fatml, hci},
}

@article{AequitasBiasFairnessAudit,
	title = {Aequitas: {A} {Bias} and {Fairness} {Audit} {Toolkit}},
	shorttitle = {Aequitas},
	url = {http://arxiv.org/abs/1811.05577},
	abstract = {Recent work has raised concerns on the risk of unintended bias in AI systems being used nowadays that can affect individuals unfairly based on race, gender or religion, among other possible characteristics. While a lot of bias metrics and fairness definitions have been proposed in recent years, there is no consensus on which metric/definition should be used and there are very few available resources to operationalize them. Therefore, despite recent awareness, auditing for bias and fairness when developing and deploying AI systems is not yet a standard practice. We present Aequitas, an open source bias and fairness audit toolkit that is an intuitive and easy to use addition to the machine learning workflow, enabling users to seamlessly test models for several bias and fairness metrics in relation to multiple population sub-groups. Aequitas facilitates informed and equitable decisions around developing and deploying algorithmic decision making systems for both data scientists, machine learning researchers and policymakers.},
	urldate = {2021-06-21},
	journal = {arXiv:1811.05577 [cs]},
	author = {Saleiro, Pedro and Kuester, Benedict and Hinkson, Loren and London, Jesse and Stevens, Abby and Anisfeld, Ari and Rodolfa, Kit T. and Ghani, Rayid},
	month = apr,
	year = {2019},
	note = {arXiv: 1811.05577},
	keywords = {comps-dm, fair, fatml},
}

@article{RightKindFairnessAI,
	title = {Towards the {Right} {Kind} of {Fairness} in {AI}},
	url = {http://arxiv.org/abs/2102.08453},
	abstract = {Fairness is a concept of justice. Various definitions exist, some of them conflicting with each other. In the absence of an uniformly accepted notion of fairness, choosing the right kind for a specific situation has always been a central issue in human history. When it comes to implementing sustainable fairness in artificial intelligence systems, this old question plays a key role once again: How to identify the most appropriate fairness metric for a particular application? The answer is often a matter of context, and the best choice depends on ethical standards and legal requirements. Since ethics guidelines on this topic are kept rather general for now, we aim to provide more hands-on guidance with this document. Therefore, we first structure the complex landscape of existing fairness metrics and explain the different options by example. Furthermore, we propose the "Fairness Compass", a tool which formalises the selection process and makes identifying the most appropriate fairness definition for a given system a simple, straightforward procedure. Because this process also allows to document the reasoning behind the respective decisions, we argue that this approach can help to build trust from the user through explaining and justifying the implemented fairness.},
	urldate = {2021-06-21},
	journal = {arXiv:2102.08453 [cs]},
	author = {Ruf, Boris and Detyniecki, Marcin},
	month = may,
	year = {2021},
	note = {arXiv: 2102.08453},
	keywords = {comps-dm, fair, fatml},
}

@article{PredictionBasedDecisionsFairnessCatalogue,
	title = {Prediction-{Based} {Decisions} and {Fairness}: {A} {Catalogue} of {Choices}, {Assumptions}, and {Definitions}},
	volume = {8},
	issn = {2326-8298, 2326-831X},
	shorttitle = {Prediction-{Based} {Decisions} and {Fairness}},
	url = {http://arxiv.org/abs/1811.07867},
	doi = {10.1146/annurev-statistics-042720-125902},
	abstract = {A recent flurry of research activity has attempted to quantitatively define "fairness" for decisions based on statistical and machine learning (ML) predictions. The rapid growth of this new field has led to wildly inconsistent terminology and notation, presenting a serious challenge for cataloguing and comparing definitions. This paper attempts to bring much-needed order. First, we explicate the various choices and assumptions made---often implicitly---to justify the use of prediction-based decisions. Next, we show how such choices and assumptions can raise concerns about fairness and we present a notationally consistent catalogue of fairness definitions from the ML literature. In doing so, we offer a concise reference for thinking through the choices, assumptions, and fairness considerations of prediction-based decision systems.},
	number = {1},
	urldate = {2021-06-20},
	journal = {Annual Review of Statistics and Its Application},
	author = {Mitchell, Shira and Potash, Eric and Barocas, Solon and D'Amour, Alexander and Lum, Kristian},
	month = mar,
	year = {2021},
	note = {arXiv: 1811.07867},
	keywords = {comps-dm, fair, fatml},
	pages = {141--163},
}

@article{BuildingSharedMentalModels,
	title = {Building {Shared} {Mental} {Models} between {Humans} and {AI} for {Effective} {Collaboration}},
	abstract = {Intelligent systems have become increasingly common in settings ranging from performing everyday tasks more easily to decision-making for complex domains (e.g., healthcare, autonomous driving, criminal justice). Given this rising ubiquity of artificial intelligence (AI), both researchers and industry practitioners are exploring ways to better integrate AI agents in tasks that people do at home or work. However, these systems are currently limited because of gaps in the understanding between humans and their AI counterparts. In this paper, we propose methods for building shared mental models between humans and AI to enable human-AI collaboration at a level where both can be equal partners working on a shared task. We ground our approach in existing literature from CSCW and UX design.},
	language = {en},
	author = {Kaur, Harmanpreet and Williams, Alex C and Lasecki, Walter S},
	year = {2019},
	keywords = {comps-sc, hmi, sc},
	pages = {7},
}

@article{IdealHumanExpectationsAI,
	title = {"{An} {Ideal} {Human}": {Expectations} of {AI} {Teammates} in {Human}-{AI} {Teaming}},
	volume = {4},
	issn = {2573-0142},
	shorttitle = {"{An} {Ideal} {Human}"},
	url = {https://dl.acm.org/doi/10.1145/3432945},
	doi = {10.1145/3432945},
	abstract = {Driven by state-of-the-art AI technologies, human-AI collaboration has become an important area in computer-supported teamwork research. While human-AI collaboration has been investigated in various domains, more research is needed to explore human perceptions and expectations of AI teammates in human-AI teaming. To achieve an in-depth understanding of how people perceive AI teammates and what they expect from AI teammates in human-AI teaming, we conducted a survey with 213 participants and a follow-up interview with 20 participants. Considering the context-dependency of teamwork, we chose to study human-AI teaming in the context of multiplayer online games as a case study. This study shows that people have mixed feelings toward AI teammates but hold a positive attitude toward future collaboration with AI teammates in general. Our findings highlight people's expectations for AI teammates in a rapidly changing collaborative environment (e.g., instrumental skills for in-game tasks, shared understanding between humans and AI, communication capabilities, human-like behaviors and performance), as well as factors that impact people's willingness to team up with AI teammates (e.g., pre-existing attitudes toward AI, previous collaboration experience with humans). We contribute to CSCW by shedding light on how AI should be structured in human-AI teaming to support highly complex collaborative activities in CSCW environments.},
	language = {en},
	number = {CSCW3},
	urldate = {2021-06-24},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Zhang, Rui and McNeese, Nathan J. and Freeman, Guo and Musick, Geoff},
	month = jan,
	year = {2021},
	pages = {1--25},
}

@article{HumanAISymbiosisSurveyCurrent,
	title = {Human-{AI} {Symbiosis}: {A} {Survey} of {Current} {Approaches}},
	shorttitle = {Human-{AI} {Symbiosis}},
	url = {http://arxiv.org/abs/2103.09990},
	abstract = {In this paper, we aim at providing a comprehensive outline of the different threads of work in human-AI collaboration. By highlighting various aspects of works on the human-AI team such as the flow of complementing, task horizon, model representation, knowledge level, and teaming goal, we make a taxonomy of recent works according to these dimensions. We hope that the survey will provide a more clear connection between the works in the human-AI team and guidance to new researchers in this area.},
	urldate = {2021-06-24},
	journal = {arXiv:2103.09990 [cs]},
	author = {Zahedi, Zahra and Kambhampati, Subbarao},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.09990},
	keywords = {comps-sc, hmi},
}

@inproceedings{HeyStaksRealworldDeploymentSocial,
	address = {Dublin, Ireland},
	title = {{HeyStaks}: a real-world deployment of social search},
	isbn = {978-1-4503-1270-7},
	shorttitle = {{HeyStaks}},
	url = {http://dl.acm.org/citation.cfm?doid=2365952.2366017},
	doi = {10.1145/2365952.2366017},
	abstract = {The purpose of this paper is to provide a deployment update for the HeyStaks social search system which uses recommendation techniques to add collaboration to mainstream search engines such as Google, Bing, and Yahoo. We describe our the results of initial deployments, including an assessment of the quality of HeyStaks’ recommendations, and highlight some lessons learned in the marketplace.},
	language = {en},
	urldate = {2021-06-24},
	booktitle = {Proceedings of the sixth {ACM} conference on {Recommender} systems - {RecSys} '12},
	publisher = {ACM Press},
	author = {Smyth, Barry and Coyle, Maurice and Briggs, Peter},
	year = {2012},
	keywords = {comps-sc, sc},
	pages = {289},
}

@article{PersonalizedSearchIntegratingCollaboration,
	title = {Personalized search: {Integrating} collaboration and social networks},
	volume = {62},
	issn = {15322882},
	shorttitle = {Personalized search},
	url = {http://doi.wiley.com/10.1002/asi.21446},
	doi = {10.1002/asi.21446},
	language = {en},
	number = {1},
	urldate = {2021-06-24},
	journal = {Journal of the American Society for Information Science and Technology},
	author = {Shapira, Bracha and Zabar, Boaz},
	month = jan,
	year = {2011},
	keywords = {comps-sc, sc, sse},
	pages = {146--160},
}

@article{LiveUserEvaluationCollaborativeWeb,
	title = {A {Live}-{User} {Evaluation} of {Collaborative} {Web} {Search}},
	abstract = {Collaborative Web search exploits repetition and regularity within the query-space of a community of like-minded individuals in order to improve the quality of search results. In short, search results that have been judged to be relevant for past queries are promoted in response to similar queries that occur in the future. In this paper we present the results of a large-scale evaluation of this approach, in a corporate Web search scenario, which shows that signiﬁcant beneﬁts are available to its users.},
	language = {en},
	author = {Smyth, Barry and Balfe, Evelyn and Boydell, Oisin and Bradley, Keith and Briggs, Peter and Coyle, Maurice and Freyne, Jill},
	keywords = {collaborative, comps-sc, sc},
	pages = {6},
}

@incollection{ApplicationProgrammingInterfaceWOSP,
	address = {Berlin, Heidelberg},
	title = {Application {Programming} {Interface} for {WOSP}/{WOSRP}},
	volume = {1830},
	isbn = {978-3-540-67647-8 978-3-540-45111-2},
	url = {http://link.springer.com/10.1007/3-540-45111-0_13},
	language = {en},
	urldate = {2021-06-24},
	booktitle = {Distributed {Communities} on the {Web}},
	publisher = {Springer Berlin Heidelberg},
	author = {Babin, Gilbert and Coltzau, Hauke and Wulff, Markus and Ruel, Simon},
	editor = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan and Kropf, Peter G. and Babin, Gilbert and Plaice, John and Unger, Herwig},
	year = {2000},
	doi = {10.1007/3-540-45111-0_13},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {110--121},
}

@article{AvatarsSocialMediaBalancing,
	title = {Avatars in social media: {Balancing} accuracy, playfulness and embodied messages},
	volume = {66},
	issn = {10715819},
	shorttitle = {Avatars in social media},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071581908000943},
	doi = {10.1016/j.ijhcs.2008.08.002},
	abstract = {This paper examines how users negotiate their self-presentation via an avatar used in social media. Twenty participants customised an avatar while thinking aloud. An analysis of this verbal data revealed three motivating factors that drive self-presentation: (1) avatars were used to accurately reﬂect their owners’ ofﬂine self; participants chose to display stable self-attributes or idealised their avatar by concealing or emphasising attributes aligned to imagined social roles, (2) the diversity of customisation options was exploited by some participants who broke free from the social rules governing self-presentation ofﬂine; others used the avatar’s appearance to emotionally provoke and engage the avatar viewer and ﬁnally, (3) avatars were used as proxies; participants designed their online self in order to convey a message to a signiﬁcant other.},
	language = {en},
	number = {11},
	urldate = {2021-06-24},
	journal = {International Journal of Human-Computer Studies},
	author = {Vasalou, Asimina and Joinson, Adam and Bänziger, Tanja and Goldie, Peter and Pitt, Jeremy},
	month = nov,
	year = {2008},
	keywords = {comps-sc, self-presentation},
	pages = {801--811},
}

@article{SocialMediaVoiceSynthesized,
	title = {Social {Media} through {Voice}: {Synthesized} {Voice} {Qualities} and {Self}-presentation},
	volume = {5},
	issn = {2573-0142},
	shorttitle = {Social {Media} through {Voice}},
	url = {https://dl.acm.org/doi/10.1145/3449235},
	doi = {10.1145/3449235},
	language = {en},
	number = {CSCW1},
	urldate = {2021-06-24},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Zhang, Lotus and Jiang, Lucy and Washington, Nicole and Liu, Augustina Ao and Shao, Jingyao and Fourney, Adam and Morris, Meredith Ringel and Findlater, Leah},
	month = apr,
	year = {2021},
	keywords = {comps-sc, self-presentation},
	pages = {1--21},
}

@article{GraphEmbeddingsMovieVisualization,
	title = {Graph {Embeddings} for {Movie} {Visualization} and {Recommendation}},
	abstract = {In this work we showcase how graph-embeddings can be used as a movie visualization and recommendation interface. The proposed low-dimensional embedding carefully preserves both local and global graph connectivity structure. The approach additionally oﬀers: a) recommendations based on a pivot movie, b) interactive deep graph exploration of the movie connectivity graph, c) automatic movie trailer retrieval.},
	language = {en},
	author = {Vlachos, Michail and Svonava, Daniel},
	pages = {5},
}

@article{VisualNudgesEnhancingUse,
	title = {Visual {Nudges} for {Enhancing} the {Use} and {Produce} of {Reputation} {Information}},
	volume = {612},
	abstract = {In this paper, we aim to analyse the current level of usability on ten popular online websites utilising some kind of reputation system. The conducted heuristic and expert evaluations reveal a number of deficiencies on the overall usability of these websites, but especially on how the reputation information is currently presented. The low level of usability has direct consequences on how accessible and understandable the reputation information is to the user. We also conducted user studies, consisting of test tasks and interviews, on two websites utilising reputation information. The results suggest why the currently provided information remains under-utilised and, to a great extent, goes undetected or gets misinterpreted. On basis of the work so far, we propose ways to overcome some of the current problems by changing, rearranging and grouping of the visual elements and visual layout of the reputation information offered on the sites. The enhanced visualisations create “visual nudges” by enhancing the key elements in order to make users notice and use the information available for better and more informed decisions. .},
	language = {en},
	author = {Karvonen, Kristiina and Shibasaki, Sanna and Nunes, Sofia and Kaur, Puneet and Immonen, Olli},
	year = {2010},
	keywords = {comps-iui, explanation},
	pages = {8},
}

@article{ExplainingRecommendationsSatisfactionVs,
	title = {Explaining {Recommendations}: {Satisfaction} vs. {Promotion}},
	abstract = {Recommender systems have become a popular technique for helping users select desirable books, movies, music and other items. Most research in the area has focused on developing and evaluating algorithms for efﬁciently producing accurate recommendations. However, the ability to effectively explain its recommendations to users is another important aspect of a recommender system. The only previous investigation of methods for explaining recommendations showed that certain styles of explanations were effective at convincing users to adopt recommendations (i.e. promotion) but failed to show that explanations actually helped users make more accurate decisions (i.e. satisfaction). We present two new methods for explaining recommendations of contentbased and/or collaborative systems and experimentally show that they actually improve user’s estimation of item quality.},
	language = {en},
	author = {Bilgic, Mustafa and Mooney, Raymond J},
	pages = {7},
}

@inproceedings{WhoTalkingWhatSocial,
	address = {Barcelona, Spain},
	title = {Who is talking about what: social map-based recommendation for content-centric social websites},
	isbn = {978-1-60558-906-0},
	shorttitle = {Who is talking about what},
	url = {http://portal.acm.org/citation.cfm?doid=1864708.1864737},
	doi = {10.1145/1864708.1864737},
	abstract = {Content-centric social websites, such as discussion forums and blog sites, have ﬂourished during the past several years. These sites often contain overwhelming amounts of information that are also being updated rapidly. To help users locate their interests at such sites (e.g., interesting blogs to read or discussion forums to join), researchers have developed a number of recommendation technologies. However, it is diﬃcult to make eﬀective recommendations for new users (a.k.a. the cold start problem) due to a lack of user information (e.g., preferences and interests). Furthermore, the complexity of recommendation algorithms often prevents users from comprehending let alone trusting the recommended results. To tackle the above two challenges, we are building a social map-based recommender system called Pharos. A social map summarizes users’ content-related social behavior over time (e.g., reading, writing, and commenting behavior during the past week) as a set of latent communities. Each community is characterized by the theme of the content being discussed and the key people involved. By discovering, ranking, and displaying the most ”popular” latent communities, Pharos creates a visual social map of a website. This enables new users to obtain a quick overview of the site, alleviating the cold start problem. Furthermore, we use the social map as a context to help explain Pharos-recommended content and people. Users can also interactively explore the social map to locate their interested content or people that are not being explicitly recommended, compensating for the imperfection in the recommendation algorithms. We have deployed Pharos within our company and our preliminary evaluation shows the usefulness of Pharos.},
	language = {en},
	urldate = {2021-06-27},
	booktitle = {Proceedings of the fourth {ACM} conference on {Recommender} systems - {RecSys} '10},
	publisher = {ACM Press},
	author = {Zhao, Shiwan and Zhou, Michelle X. and Yuan, Quan and Zhang, Xiatian and Zheng, Wentao and Fu, Rongyao},
	year = {2010},
	keywords = {comps-iui, pharos},
	pages = {143},
}

@inproceedings{VisualDialogAugmentedInteractive,
	address = {Anchorage AK USA},
	title = {A {Visual} {Dialog} {Augmented} {Interactive} {Recommender} {System}},
	isbn = {978-1-4503-6201-6},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330991},
	doi = {10.1145/3292500.3330991},
	abstract = {Traditional recommender systems rely on user feedback such as ratings or clicks to the items, to analyze the user interest and provide personalized recommendations. However, rating or click feedback are limited in that they do not exactly tell why users like or dislike an item. If a user does not like the recommendations and can not effectively express the reasons via rating and clicking, the feedback from the user may be very sparse. These limitations lead to inefficient model learning of the recommender system. To address these limitations, more effective user feedback to the recommendations should be designed, so that the system can effectively understand a user’s preference and improve the recommendations over time.},
	language = {en},
	urldate = {2021-06-27},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Yu, Tong and Shen, Yilin and Jin, Hongxia},
	month = jul,
	year = {2019},
	keywords = {comps-iui, rec},
	pages = {157--165},
}

@article{HumanIntellectMachineFailures,
	title = {On {Human} {Intellect} and {Machine} {Failures}: {Troubleshooting} {Integrative} {Machine} {Learning} {Systems}},
	abstract = {We study the problem of troubleshooting machine learning systems that rely on analytical pipelines of distinct components. Understanding and ﬁxing errors that arise in such integrative systems is difﬁcult as failures can occur at multiple points in the execution workﬂow. Moreover, errors can propagate, become ampliﬁed or be suppressed, making blame assignment difﬁcult. We propose a human-in-the-loop methodology which leverages human intellect for troubleshooting system failures. The approach simulates potential component ﬁxes through human computation tasks and measures the expected improvements in the holistic behavior of the system. The method provides guidance to designers about how they can best improve the system. We demonstrate the effectiveness of the approach on an automated image captioning system that has been pressed into real-world use.},
	language = {en},
	author = {Nushi, Besmira and Kamar, Ece and Horvitz, Eric and Kossmann, Donald},
	keywords = {comps-sc, hmi, sc},
	pages = {9},
}

@inproceedings{DoesWholeExceedIts,
	address = {Yokohama Japan},
	title = {Does the {Whole} {Exceed} its {Parts}? {The} {Effect} of {AI} {Explanations} on {Complementary} {Team} {Performance}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Does the {Whole} {Exceed} its {Parts}?},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445717},
	doi = {10.1145/3411764.3445717},
	language = {en},
	urldate = {2021-06-26},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
	month = may,
	year = {2021},
	keywords = {comps-sc, hmi, sc, well-written},
	pages = {1--16},
}

@inproceedings{AnatomyLargescaleSocialSearch,
	address = {Raleigh, North Carolina, USA},
	title = {The anatomy of a large-scale social search engine},
	isbn = {978-1-60558-799-8},
	url = {http://portal.acm.org/citation.cfm?doid=1772690.1772735},
	doi = {10.1145/1772690.1772735},
	abstract = {We present Aardvark, a social search engine. With Aardvark, users ask a question, either by instant message, email, web input, text message, or voice. Aardvark then routes the question to the person in the user’s extended social network most likely to be able to answer that question. As compared to a traditional web search engine, where the challenge lies in ﬁnding the right document to satisfy a user’s information need, the challenge in a social search engine like Aardvark lies in ﬁnding the right person to satisfy a user’s information need. Further, while trust in a traditional search engine is based on authority, in a social search engine like Aardvark, trust is based on intimacy. We describe how these considerations inform the architecture, algorithms, and user interface of Aardvark, and how they are reﬂected in the behavior of Aardvark users.},
	language = {en},
	urldate = {2021-06-25},
	booktitle = {Proceedings of the 19th international conference on {World} wide web - {WWW} '10},
	publisher = {ACM Press},
	author = {Horowitz, Damon and Kamvar, Sepandar D.},
	year = {2010},
	keywords = {comps-sc, sc},
	pages = {431},
}

@inproceedings{ASSISTAdaptiveSocialSupport,
	address = {Manchester, UK},
	title = {{ASSIST}: adaptive social support for information space traversal},
	isbn = {978-1-59593-820-6},
	shorttitle = {{ASSIST}},
	url = {http://portal.acm.org/citation.cfm?doid=1286240.1286299},
	doi = {10.1145/1286240.1286299},
	abstract = {Finding relevant information in a hyperspace has been a much studied problem for many years. With the emergence of so called Web 2.0 technologies we have seen the use of social systems for retrieval tasks increasing dramatically. Each system collects and exploits its own pool of community wisdom for the benefit of its users. In this paper we suggest a form of retrieval which exploits the pools of wisdom of multiple social technologies, specifically social search and social navigation. The paper details the added user benefits of merging several sources of social wisdom. We present details of the ASSIST engine developed to integrate social support mechanisms for the users of information repositories. The goal of this paper is to present the main features of the integrated community-based personalization engine that we have developed in order to improve retrieval in the hyperspace of information resources. It also reports the results of an empirical study of this technology.},
	language = {en},
	urldate = {2021-06-25},
	booktitle = {Proceedings of the 18th conference on {Hypertext} and hypermedia  - {HT} '07},
	publisher = {ACM Press},
	author = {Farzan, Rosta and Coyle, Maurice and Freyne, Jill and Brusilovsky, Peter and Smyth, Barry},
	year = {2007},
	pages = {199},
}

@inproceedings{CoordinatingAgentsPromotingShared,
	address = {Jersey City NJ USA},
	title = {Coordinating {Agents}: {Promoting} {Shared} {Situational} {Awareness} in {Collaborative} {Sensemaking}},
	isbn = {978-1-4503-6018-0},
	shorttitle = {Coordinating {Agents}},
	url = {https://dl.acm.org/doi/10.1145/3272973.3274059},
	doi = {10.1145/3272973.3274059},
	abstract = {Recent research suggests that in visual analytics tasks, collaborative sensemaking relies on successful collaboration between humans and software agents. To advance the understanding of such collaboration, we consider that both, the human and the software agent, possess a form of situational awareness which, when coordinated, can enrich the collaborative sensemaking process. We propose a conceptual model for a coordinating agent that dynamically initiates interruptions, inﬂuenced by the analytic activities of humans. We provide possible designs for four coordinating strategies. In closing, we discuss plans for implementation, and how future studies can contribute to wider discourses.},
	language = {en},
	urldate = {2021-06-25},
	booktitle = {Companion of the 2018 {ACM} {Conference} on {Computer} {Supported} {Cooperative} {Work} and {Social} {Computing}},
	publisher = {ACM},
	author = {Hong, Ming-Tung and Benjamin, Jesse Josua and Müller-Birn, Claudia},
	month = oct,
	year = {2018},
	keywords = {comps-sc, hmi},
	pages = {217--220},
}

@book{HybridExplanationsFrameworkCollaborative,
	title = {A {Hybrid} {Explanations} {Framework} for {Collaborative} {Filtering} {Recommender} {Systems}},
	abstract = {Augmenting personalized recommendations with explana-tions is believed to improve users ’ trust, loyalty, satisfac-tion, and recommender’s persuasiveness. We present a flexi-ble explanations framework for collaborative filtering recom-mender systems. Our algorithms utilizes item tags to auto-matically generate personalized explanations in a natural language format. Given a specific user and a recommended item, the algorithm utilizes the user’s personal information as well as global information (e.g., item similarities, meta-data) in order to rank item tags based on their “explanatory power”. The top tags are chosen to construct a personalized explanation sentence which helps shed light on the under-lying recommender. Our system has been well received by both focus groups as well as in expert evaluations and is scheduled to be evaluated in an online experiment. 1.},
	author = {Ben-elazar, Shay and Koenigstein, Noam},
	keywords = {comps-iui, iui, rec},
}

@article{IntegratedEnvironmentDevelopmentKnowledgeBased,
	title = {An {Integrated} {Environment} for the {Development} of {Knowledge}-{Based} {Recommender} {Applications}},
	volume = {11},
	issn = {1086-4415},
	url = {https://www.jstor.org/stable/27751210},
	abstract = {The complexity of the product assortments offered by on-line selling platforms makes selection a challenging task. Customers differ in respect to expertise and product knowledge, but intelligent recommender systems offer personalized dialogues that support the product-selection process. This paper describes CWAdvisor, a domain-independent, knowledge-based recommender environment that provides users with consistently appropriate solutions, identifies additional selling opportunities, and explains solutions. The discussion uses examples from several application domains to show how model-based diagnosis, personalization, and intuitive knowledge-acquisition techniques support customer-oriented sales dialogues. Experience obtained in industrial projects is reported, and successfully deployed recommender applications are evaluated.},
	number = {2},
	urldate = {2021-06-29},
	journal = {International Journal of Electronic Commerce},
	author = {Felfernig, Alexander and Friedrich, Gerhard and Jannach, Dietmar and Zanker, Markus},
	year = {2006},
	note = {Publisher: Taylor \& Francis, Ltd.},
	keywords = {comps-iui, rec},
	pages = {11--34},
}

@inproceedings{AurigoInteractiveTourPlanner,
	address = {Atlanta Georgia USA},
	title = {Aurigo: an {Interactive} {Tour} {Planner} for {Personalized} {Itineraries}},
	isbn = {978-1-4503-3306-1},
	shorttitle = {Aurigo},
	url = {https://dl.acm.org/doi/10.1145/2678025.2701366},
	doi = {10.1145/2678025.2701366},
	abstract = {Planning personalized tour itineraries is a complex and challenging task for both humans and computers. Doing it manually is time-consuming; approaching it as an optimization problem is computationally NP hard. We present Aurigo, a tour planning system combining a recommendation algorithm with interactive visualization to create personalized itineraries. This hybrid approach enables Aurigo to take into account both quantitative and qualitative preferences of the user. We conducted a within-subject study with 10 participants, which demonstrated that Aurigo helped them ﬁnd points of interest quickly. Most participants chose Aurigo over Google Maps as their preferred tools to create personalized itineraries. Aurigo may be integrated into review websites or social networks, to leverage their databases of reviews and ratings and provide better itinerary recommendations.},
	language = {en},
	urldate = {2021-06-29},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Yahi, Alexandre and Chassang, Antoine and Raynaud, Louis and Duthil, Hugo and Chau, Duen Horng (Polo)},
	month = mar,
	year = {2015},
	keywords = {comps-iui, rec},
	pages = {275--285},
}

@article{TrustinspiringExplanationInterfacesRecommender,
	title = {Trust-inspiring explanation interfaces for recommender systems},
	volume = {20},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705107000445},
	doi = {10.1016/j.knosys.2007.04.004},
	abstract = {A recommender system’s ability to establish trust with users and convince them of its recommendations, such as which camera or PC to purchase, is a crucial design factor especially for e-commerce environments. This observation led us to build a trust model for recommender agents with a focus on the agent’s trustworthiness as derived from the user’s perception of its competence and especially its ability to explain the recommended results. We present in this article new results of our work in developing design principles and algorithms for constructing explanation interfaces. We show the eﬀectiveness of these principles via a signiﬁcant-scale user study in which we compared an interface developed based on these principles with a traditional one. The new interface, called the organization interface where results are grouped according to their tradeoﬀ properties, is shown to be signiﬁcantly more eﬀective in building user trust than the traditional approach. Users perceive it more capable and eﬃcient in assisting them to make decisions, and they are more likely to return to the interface. We therefore recommend designers to build trust-inspiring interfaces due to their high likelihood to increase users’ intention to save cognitive eﬀort and the intention to return to the recommender system.},
	language = {en},
	number = {6},
	urldate = {2021-06-29},
	journal = {Knowledge-Based Systems},
	author = {Pu, Pearl and Chen, Li},
	month = aug,
	year = {2007},
	keywords = {comps-iui, explanation, rec},
	pages = {542--556},
}

@inproceedings{MulticriteriaJourneyAwareHousing,
	address = {Foster City, Silicon Valley, California, USA},
	title = {Multi-criteria journey aware housing recommender system},
	isbn = {978-1-4503-2668-1},
	url = {http://dl.acm.org/citation.cfm?doid=2645710.2645764},
	doi = {10.1145/2645710.2645764},
	abstract = {Recommender systems can be employed to assist users in complex decision making processes. This paper presents a multi-criteria housing recommender system which takes into account not just features of a home, such as rent, but also the transportation links to user speciﬁed locations. First, we describe an efﬁcient multihop journey time calculator. Second, we introduce a mechanism to ﬁnd the optimal solutions for multi-criteria evaluation, where a balanced trade-off between the target goals is found. Finally, we present a user study to demonstrate the potential of such a system.},
	language = {en},
	urldate = {2021-06-29},
	booktitle = {Proceedings of the 8th {ACM} {Conference} on {Recommender} systems - {RecSys} '14},
	publisher = {ACM Press},
	author = {Daly, Elizabeth M. and Botea, Adi and Kishimoto, Akihiro and Marinescu, Radu},
	year = {2014},
	keywords = {comps-iui, rec},
	pages = {325--328},
}

@inproceedings{MoodplayInteractiveMoodbasedMusic,
	address = {Halifax Nova Scotia Canada},
	title = {Moodplay: {Interactive} {Mood}-based {Music} {Discovery} and {Recommendation}},
	isbn = {978-1-4503-4368-8},
	shorttitle = {Moodplay},
	url = {https://dl.acm.org/doi/10.1145/2930238.2930280},
	doi = {10.1145/2930238.2930280},
	abstract = {A large body of research in recommender systems focuses on optimizing prediction and ranking. However, recent work has highlighted the importance of other aspects of the recommendations, including transparency, control and user experience in general. Building on these aspects, we introduce MoodPlay, a hybrid recommender system music which integrates content and mood-based ﬁltering in an interactive interface. We show how MoodPlay allows the user to explore a music collection by latent affective dimensions, and we explain how to integrate user input at recommendation time with predictions based on a pre-existing user proﬁle. Results of a user study (N=240) are discussed, with four conditions being evaluated with varying degrees of visualization, interaction and control. Results show that visualization and interaction in a latent space improve acceptance and understanding of both metadata and item recommendations. However, too much of either can result in cognitive overload and a negative impact on user experience.},
	language = {en},
	urldate = {2021-06-28},
	booktitle = {Proceedings of the 2016 {Conference} on {User} {Modeling} {Adaptation} and {Personalization}},
	publisher = {ACM},
	author = {Andjelkovic, Ivana and Parra, Denis and O'Donovan, John},
	month = jul,
	year = {2016},
	keywords = {comps-iui, iui, rec},
	pages = {275--279},
}

@inproceedings{DataPortraitsIntermediaryTopics,
	address = {Sonoma California USA},
	title = {Data {Portraits} and {Intermediary} {Topics}: {Encouraging} {Exploration} of {Politically} {Diverse} {Profiles}},
	isbn = {978-1-4503-4137-0},
	shorttitle = {Data {Portraits} and {Intermediary} {Topics}},
	url = {https://dl.acm.org/doi/10.1145/2856767.2856776},
	doi = {10.1145/2856767.2856776},
	abstract = {In micro-blogging platforms, people connect and interact with others. However, due to cognitive biases, they tend to interact with like-minded people and read agreeable information only. Many efforts to make people connect with those who think differently have not worked well. In this paper, we hypothesize, ﬁrst, that previous approaches have not worked because they have been direct – they have tried to explicitly connect people with those having opposing views on sensitive issues. Second, that neither recommendation or presentation of information by themselves are enough to encourage behavioral change. We propose a platform that mixes a recommender algorithm and a visualization-based user interface to explore recommendations. It recommends politically diverse proﬁles in terms of distance of latent topics, and displays those recommendations in a visual representation of each user’s personal content. We performed an “in the wild” evaluation of this platform, and found that people explored more recommendations when using a biased algorithm instead of ours. In line with our hypothesis, we also found that the mixture of our recommender algorithm and our user interface, allowed politically interested users to exhibit an unbiased exploration of the recommended proﬁles. Finally, our results contribute insights in two aspects: ﬁrst, which individual differences are important when designing platforms aimed at behavioral change; and second, which algorithms and user interfaces should be mixed to help users avoid cognitive mechanisms that lead to biased behavior.},
	language = {en},
	urldate = {2021-06-28},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Intelligent} {User} {Interfaces}},
	publisher = {ACM},
	author = {Graells-Garrido, Eduardo and Lalmas, Mounia and Baeza-Yates, Ricardo},
	month = mar,
	year = {2016},
	keywords = {comps-iui, iui, rec},
	pages = {228--240},
}

@article{PresentingDiversePoliticalOpinions,
	title = {Presenting diverse political opinions: how and how much},
	abstract = {Is a polarized society inevitable, where people choose to be exposed to only political news and commentary that reinforces their existing viewpoints? We examine the relationship between the numbers of supporting and challenging items in a collection of political opinion items and readers’ satisfaction, and then evaluate whether simple presentation techniques such as highlighting agreeable items or showing them first can increase satisfaction when fewer agreeable items are present. We find individual differences: some people are diversity-seeking while others are challenge-averse. For challenge-averse readers, highlighting appears to make satisfaction with sets of mostly agreeable items more extreme, but does not increase satisfaction overall, and sorting agreeable content first appears to decrease satisfaction rather than increasing it. These findings have important implications for builders of websites that aggregate content reflecting different positions.},
	language = {en},
	author = {Munson, Sean A and Resnick, Paul},
	year = {2010},
	keywords = {comps-iui, iui, rec},
	pages = {10},
}

@article{TopicLensInteractiveRecommenderSystem,
	title = {{TopicLens}: {An} {Interactive} {Recommender} {System} based on {Topical} and {Social} {Connections}},
	abstract = {This paper describes TopicLens, an interactive tool for exploring and recommending items within large corpora, based on both social metadata and topical associations. The system uses a hybrid visualization model that represents topics and content items side by side, allowing the user to actively explore recommendations rather than passively viewing them. The approach provides insight into the composition of relevant topics as they relate to the meta-data of underlying texts. We describe a novel approach to sorting and ﬁltering, which can be topic or document-driven, and two novel interaction styles termed “view inversion” and “human-review”, each of which enable novel perspectives on topic modeled sets of documents. To evaluate the system, three use cases are presented to highlight interesting insights across three different data sets using our novel recommendation interface.},
	language = {en},
	author = {Devendorf, Laura and O’Donovan, John and Höllerer, Tobias},
	pages = {8},
}

@article{MitigatingBiasAlgorithmicSystems,
	title = {Mitigating {Bias} in {Algorithmic} {Systems}: {A} {Fish}-{Eye} {View} of {Problems} and {Solutions} {Across} {Domains}},
	shorttitle = {Mitigating {Bias} in {Algorithmic} {Systems}},
	url = {http://arxiv.org/abs/2103.16953},
	abstract = {Mitigating bias in algorithmic systems is a critical issue drawing attention across communities within the information and computer sciences. Given the complexity of the problem and the involvement of multiple stakeholders, including developers, end-users and third-parties, there is a need to understand the landscape of the sources of bias, and the solutions being proposed to address them. This survey provides a 'fish-eye view', examining approaches across four areas of research. The literature describes three steps toward a comprehensive treatment: bias detection, fairness management and explainability management, and underscores the need to work from within the system as well as from the perspective of stakeholders in the broader context.},
	urldate = {2021-06-30},
	journal = {arXiv:2103.16953 [cs]},
	author = {Orphanou, Kalia and Otterbacher, Jahna and Kleanthous, Styliani and Batsuren, Khuyagbaatar and Giunchiglia, Fausto and Bogina, Veronika and Tal, Avital Shulner and AlanHartman and Kuflik, Tsvi},
	month = mar,
	year = {2021},
	note = {arXiv: 2103.16953},
	keywords = {comps-dm, fair, survey},
}

@inproceedings{TasteWeightsVisualInteractiveHybrid,
	address = {Dublin, Ireland},
	title = {{TasteWeights}: a visual interactive hybrid recommender system},
	isbn = {978-1-4503-1270-7},
	shorttitle = {{TasteWeights}},
	url = {http://dl.acm.org/citation.cfm?doid=2365952.2365964},
	doi = {10.1145/2365952.2365964},
	abstract = {This paper presents an interactive hybrid recommendation system that generates item predictions from multiple social and semantic web resources, such as Wikipedia, Facebook, and Twitter. The system employs hybrid techniques from traditional recommender system literature, in addition to a novel interactive interface which serves to explain the recommendation process and elicit preferences from the end user. We present an evaluation that compares diﬀerent interactive and non-interactive hybrid strategies for computing recommendations across diverse social and semantic web APIs. Results of the study indicate that explanation and interaction with a visual representation of the hybrid system increase user satisfaction and relevance of predicted content.},
	language = {en},
	urldate = {2021-06-30},
	booktitle = {Proceedings of the sixth {ACM} conference on {Recommender} systems - {RecSys} '12},
	publisher = {ACM Press},
	author = {Bostandjiev, Svetlin and O'Donovan, John and Höllerer, Tobias},
	year = {2012},
	pages = {35},
}

@article{BigDataDisparateImpact,
	title = {Big {Data}�s {Disparate} {Impact}},
	url = {https://lawcat.berkeley.edu/record/1127463},
	doi = {10.15779/Z38BG31},
	language = {en},
	urldate = {2021-06-29},
	author = {Barocas, Solon; Selbst, Andrew D},
	year = {2016},
	note = {Publisher: clr},
}

@inproceedings{FairnessPracticePractitionerOrientedRubric,
	address = {Yokohama Japan},
	title = {Towards {Fairness} in {Practice}: {A} {Practitioner}-{Oriented} {Rubric} for {Evaluating} {Fair} {ML} {Toolkits}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Towards {Fairness} in {Practice}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445604},
	doi = {10.1145/3411764.3445604},
	abstract = {In order to support fairness-forward thinking by machine learning (ML) practitioners, fairness researchers have created toolkits that aim to transform state-of-the-art research contributions into easily-accessible APIs. Despite these eforts, recent research indicates a disconnect between the needs of practitioners and the tools ofered by fairness research. By engaging 20 ML practitioners in a simulated scenario in which they utilize fairness toolkits to make critical decisions, this work aims to utilize practitioner feedback to inform recommendations for the design and creation of fair ML toolkits. Through the use of survey and interview data, our results indicate that though fair ML toolkits are incredibly impactful on users’ decision-making, there is much to be desired in the design and demonstration of fairness results. To support the future development and evaluation of toolkits, this work ofers a rubric that can be used to identify critical components of Fair ML toolkits.},
	language = {en},
	urldate = {2021-06-29},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Richardson, Brianna and Garcia-Gathright, Jean and Way, Samuel F. and Thom, Jennifer and Cramer, Henriette},
	month = may,
	year = {2021},
	keywords = {comps-dm, fair, hci},
	pages = {1--13},
}


