%File: anonymous-submission-latex-2025.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subcaption}
\usepackage{float}
%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[switch]{lineno}

\usepackage{chngcntr}

\usepackage{amssymb}
\usepackage{comment}
%\usepackage{subfigure}
\usepackage{graphicx}
\usepackage[flushleft]{threeparttable}
\usepackage{multirow}
\usepackage{pifont}

\usepackage{xcolor} 
\definecolor{antiquegold}{RGB}{205,127,50} 
\definecolor{deepskyblue}{RGB}{0,191,255} 
\definecolor{crimson}{RGB}{220,20,60} 
\definecolor{orange}{RGB}{255,165,0} 
\definecolor{green}{RGB}{0,128,0}



\makeatletter
\makeatother

%\theoremstyle{plain}
%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{remark}[theorem]{Remark}



%\theoremstyle{definition}
%\newtheorem{definition}[theorem]{Definition}
%\newtheorem{assumption}{Assumption}
%\newtheorem{example}[theorem]{Example}



\newcommand{\diag}{\mathop{\mathbf{diag}}}
\newcommand{\abs}[1]{\ensuremath{\left|#1\right|}}
%\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\newcommand{\norm}[2][]{\ensuremath{\left\Vert #2 \right\Vert}}
\newcommand{\spec}[1]{\ensuremath{\mathrm{sp}\inp{#1}}}
\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\vect}[1]{\boldsymbol{\mathbf{#1}}}
\newcommand{\argmin}{\mathop{\mathbf{argmin}}}
\newcommand{\argmax}{\mathop{\mathbf{argmax}}}
\newcommand{\vol}{\mathrm{Vol}}
\newcommand{\grad}{\mathrm{grad}}
\newcommand{\Proj}{\mathrm{Proj}}
\newcommand{\Retr}{\mathrm{Retr}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\Hess}{\mathrm{Hess}}
\newcommand{\Exp}{\mathrm{Exp}}
\newcommand{\Log}{\mathrm{Log}}
\newcommand{\tr}{\mathrm{Tr}}
\newcommand{\Div}{\mathrm{div}}
\newcommand\pder[2][]{\ensuremath{\frac{\partial#1}{\partial#2}}}
\newcommand{\be}{\beta^{-1}}
\newcommand{\BA}{{\mathbb {A}}} \newcommand{\BB}{{\mathbb {B}}}
    \newcommand{\BC}{{\mathbb {C}}} \newcommand{\BD}{{\mathbb {D}}}
    \newcommand{\BE}{{\mathbb {E}}} \newcommand{\BF}{{\mathbb {F}}}
    \newcommand{\BG}{{\mathbb {G}}} \newcommand{\BH}{{\mathbb {H}}}
    \newcommand{\BI}{{\mathbb {I}}} \newcommand{\BJ}{{\mathbb {J}}}
    \newcommand{\BK}{{\mathbb {K}}} \newcommand{\BL}{{\mathbb {L}}}
    \newcommand{\BM}{{\mathbb {M}}} \newcommand{\BN}{{\mathbb {N}}}
    \newcommand{\BO}{{\mathbb {O}}} \newcommand{\BP}{{\mathbb {P}}}
    \newcommand{\BQ}{{\mathbb {Q}}} \newcommand{\BR}{{\mathbb {R}}}
    \newcommand{\BS}{{\mathbb {S}}} \newcommand{\BT}{{\mathbb {T}}}
    \newcommand{\BU}{{\mathbb {U}}} \newcommand{\BV}{{\mathbb {V}}}
    \newcommand{\BW}{{\mathbb {W}}} \newcommand{\BX}{{\mathbb {X}}}
    \newcommand{\BY}{{\mathbb {Y}}} \newcommand{\BZ}{{\mathbb {Z}}}
    
    \newcommand{\CA}{{\mathcal {A}}} \newcommand{\CB}{{\mathcal {B}}}
    \newcommand{\CC}{{\mathcal {C}}} 
    \newcommand{\CE}{{\mathcal {E}}} \newcommand{\CF}{{\mathcal {F}}}
    \newcommand{\CG}{{\mathcal {G}}} \newcommand{\CH}{{\mathcal {H}}}
    \newcommand{\CI}{{\mathcal {I}}} \newcommand{\CJ}{{\mathcal {J}}}
    \newcommand{\CK}{{\mathcal {K}}} \newcommand{\CL}{{\mathcal {L}}}
    \newcommand{\CM}{{\mathcal {M}}} \newcommand{\CN}{{\mathcal {N}}}
    \newcommand{\CO}{{\mathcal {O}}} \newcommand{\CP}{{\mathcal {P}}}
    \newcommand{\CQ}{{\mathcal {Q}}} \newcommand{\CR}{{\mathcal {R}}}
    \newcommand{\CS}{{\mathcal {S}}} \newcommand{\CT}{{\mathcal {T}}}
    \newcommand{\CU}{{\mathcal {U}}} \newcommand{\CV}{{\mathcal {V}}}
    \newcommand{\CW}{{\mathcal {W}}} \newcommand{\CX}{{\mathcal {X}}}
    \newcommand{\CY}{{\mathcal {Y}}} \newcommand{\CZ}{{\mathcal {Z}}}

\newcommand{\ab}{{\mathrm{ab}}}\newcommand{\Ad}{{\mathrm{Ad}}}
    \newcommand{\ad}{{\mathrm{ad}}}\newcommand{\al}{{\mathrm{al}}}
    \newcommand{\alg}{{\mathrm{alg}}}\newcommand{\Ann}{{\mathrm{Ann}}}
    \newcommand{\Aut}{{\mathrm{Aut}}}\newcommand{\Ar}{{\mathrm{Ar}}}
    \newcommand{\AI}{{\mathrm{AI}}}\newcommand{\Alb}{{\mathrm{Alb}}}
    \newcommand{\Art}{{\mathrm{Art}}} \newcommand{\bij}{{\mathrm{bij}}}
    \newcommand{\Br}{{\mathrm{Br}}}\newcommand{\BBC}{{\mathrm{BC}}}
    \newcommand{\Char}{{\mathrm{Char}}}\newcommand{\cf}{{\mathrm{cf}}}
    \newcommand{\Ch}{{\mathrm{Ch}}}\newcommand{\cod}{{\mathrm{cod}}}
    \newcommand{\cond}{\mathrm{cond^r}}\newcommand{\Cond}{{\mathrm{Cond}}}
    \newcommand{\cont}{{\mathrm{cont}}}\newcommand{\cris}{{\mathrm{cris}}}
    \newcommand{\corank}{{\mathrm{corank}}}
    \newcommand{\Cor}{{\mathrm{Cor}}}\newcommand{\cl}{{\mathrm{cl}}}
    \newcommand{\Cl}{{\mathrm{Cl}}}\newcommand{\can}{{\mathrm{can}}}
    \newcommand{\codim}{{\mathrm{codim}}}\newcommand{\Coker}{{\mathrm{Coker}}}
    \newcommand{\coker}{{\mathrm{coker}}}\newcommand{\cyc}{{\mathrm{cyc}}}
    \newcommand{\dR}{{\mathrm{dR}}}\newcommand{\depth}{{\mathrm{depth}}}
    \newcommand{\disc}{{\mathrm{disc}}}\newcommand{\Deg}{{\mathrm{Deg}}}
    \newcommand{\Def}{{\mathrm{Def}}}\newcommand{\der}{{\mathrm{der}}}
   \renewcommand{\div}{{\mathrm{div}}}
    \newcommand{\End}{{\mathrm{End}}} \newcommand{\Eis}{{\mathrm{Eis}}}
    \newcommand{\Ell}{{\mathrm{Ell}}}\newcommand{\Error}{{\mathrm{Errr}}}
    \newcommand{\Frac}{{\mathrm{Frac}}}\newcommand{\Fr}{{\mathrm{Fr}}}
    \newcommand{\Frob}{{\mathrm{Frob}}} \newcommand{\fin}{{\mathrm{fin}}}
    \newcommand{\forget}{{\mathrm{forget}}}
    \newcommand{\Gal}{{\mathrm{Gal}}} \newcommand{\GL}{{\mathrm{GL}}}
    \newcommand{\Groth}{{\mathrm{Groth}}}\newcommand{\GSp}{{\mathrm{GSp}}}
    \newcommand{\Hg}{{\mathrm{Hg}}}\newcommand{\Hom}{{\mathrm{Hom}}}
    \newcommand{\height}{{\mathrm{ht}}}\newcommand{\Hol}{{\mathrm{Hol}}}
    \newcommand{\id}{{\mathrm{id}}}\renewcommand{\Im}{{\mathrm{Im}}}
    \newcommand{\Ind}{{\mathrm{Ind}}}
    \newcommand{\Irr}{{\mathrm{Irr}}}
    \newcommand{\inv}{{\mathrm{inv}}}\newcommand{\Isom}{{\mathrm{Isom}}}
    \newcommand{\Jac}{{\mathrm{Jac}}}\newcommand{\Ker}{{\mathrm{Ker}}}
    \newcommand{\KS}{{\mathrm{KS}}}\newcommand{\length}{{\mathrm{length}}}
    \newcommand{\Lie}{{\mathrm{Lie}}}\newcommand{\LT}{{\mathrm{LT}}}
    \newcommand{\loc}{{\mathrm{loc}}}
    \newcommand{\mult}{{\mathrm{mult}}}\newcommand{\Meas}{{\mathrm{Meas}}}
    \newcommand{\Mor}{{\mathrm{Mor}}}
    \newcommand{\new}{{\mathrm{new}}} \newcommand{\NS}{{\mathrm{NS}}}
    \newcommand{\NT}{{\mathrm{NT}}} \newcommand{\old}{{\mathrm{old}}}
    \newcommand{\ord}{{\mathrm{ord}}} 
        \newcommand{\PGL}{{\mathrm{PGL}}} \newcommand{\Pic}{\mathrm{Pic}}
    \newcommand{\pr}{{\mathrm{pr}}}
    \renewcommand{\mod}{\ \mathrm{mod}\ }\renewcommand{\Re}{{\mathrm{Re}}}
    \newcommand{\Rep}{{\mathrm{Rep}}}\newcommand{\rec}{{\mathrm{rec}}}
    \newcommand{\ram}{{\mathrm{ram}}}\newcommand{\Rings}{{\mathrm{Rings}}}
    \newcommand{\red}{{\mathrm{red}}}\newcommand{\Rat}{{\mathrm{Rat}}}
    \newcommand{\reg}{{\mathrm{reg}}}
    \newcommand{\Sel}{{\mathrm{Sel}}} \newcommand{\Sch}{{\mathrm{Sch}}}
    \newcommand{\sep}{{\mathrm{sep}}}\newcommand{\sh}{{\mathrm{sh}}}
    \newcommand{\Sh}{{\mathrm{Sh}}}\newcommand{\Sets}{{\mathrm{Sets}}}
    \newcommand{\sign}{{\mathrm{sign}}}\renewcommand{\ss}{{\mathrm{ss}}}
    \newcommand{\Sim}{{\mathrm{Sim}}}\newcommand{\SL}{{\mathrm{SL}}}
    \newcommand{\Spec}{{\mathrm{Spec}}} \newcommand{\Spf}{{\mathrm{Spf}}}
    \newcommand{\SO}{{\mathrm{SO}}}\newcommand{\Sp}{{\mathrm{Sp}}}
    \newcommand{\St}{{\mathrm{St}}}\newcommand{\SU}{{\mathrm{SU}}}
    \newcommand{\Sym}{{\mathrm{Sym}}}\newcommand{\sgn}{{\mathrm{sgn}}}
    \newcommand{\Stab}{{\mathrm{Stab}}}\newcommand{\Symb}{{\mathrm{Symb}}}
    \newcommand{\Symm}{{\mathrm{Symm}}}\newcommand{\Tate}{{\mathrm{Tate}}}
    \newcommand{\Tgt}{{\mathrm{Tgt}}}
    \newcommand{\RTr}{{\mathrm{Tr}}}\newcommand{\univ}{{\mathrm{univ}}}
    \newcommand{\ur}{{\mathrm{ur}}}\newcommand{\val}{{\mathrm{val}}}
    \newcommand{\Vect}{{\mathrm{Vect}}}
    \newcommand{\Var}{{\mathrm{Var}}}
    \newcommand{\WD}{{\mathrm{WD}}}\newcommand{\Cov}{{\mathrm{Cov}}}
    \newcommand{\md}{{\mbox{d}}}
 \newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

\newcommand{\tvdots}{%
    \vcenter{%
        \baselineskip = 4pt
        \hbox{.}\hbox{.}\hbox{.}
    }
}

    \font\cyr=wncyr10

    \newcommand{\Sha}{\hbox{\cyr X}}\newcommand{\wt}{\widetilde}
    \newcommand{\wh}{\widehat}
    \newcommand{\pp}{\frac{\partial\bar\partial}{\pi i}}
    \newcommand{\pair}[1]{\langle {#1} \rangle}
    \newcommand{\wpair}[1]{\left\{{#1}\right\}}
    \newcommand{\intn}[1]{\left( {#1} \right)}
    \newcommand{\ds}{\displaystyle}\newcommand{\ov}{\overline}
    \newcommand{\Gros}{Gr\"{o}ssencharak}
    \newcommand{\incl}{\hookrightarrow}
    \newcommand{\sk}{\medskip}\newcommand{\bsk}{\bigskip}
    \newcommand{\lra}{\longrightarrow}\newcommand{\lla}{\longleftarrow}
    \newcommand{\ra}{\rightarrow} \newcommand{\imp}{\Longrightarrow}
    \newcommand{\lto}{\longmapsto}\newcommand{\bs}{\backslash}
    \newcommand{\nequiv}{\equiv\hspace{-9.5pt}/\ }
    \newcommand{\s}{\sk\noindent}\newcommand{\bigs}{\bsk\noindent}
     \newcommand{\tb}{\textbf}
     

\newcommand\coolover[2]{\mathrlap{\smash{\overbrace{\phantom{%
    \begin{matrix} #2 \end{matrix}}}^{\mbox{$#1$}}}}#2}
\newcommand\coolrightbrace[2]{%
\left.\vphantom{\begin{matrix} #1 \end{matrix}}\right\}#2}



    \theoremstyle{plain}
    %\renewcommand{\thechapter}{\Roman{chapter}}
    \newtheorem{thm}{Theorem}[section]
    \newtheorem{cor}[thm]{Corollary}
    \newtheorem{lem}[thm]{Lemma}  \newtheorem{prop}[thm]{Proposition}
    \newtheorem {conj}[thm]{Conjecture} \newtheorem{defn}[thm]{Definition}
    \newtheorem {rem}[thm]{Remark}
    \newtheorem {assu}[thm]{Assumption}


\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}[theorem]{Remark}




\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}{Assumption}
\newtheorem{example}[theorem]{Example}




\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\csch}{csch}
\DeclareMathOperator{\arcsec}{arcsec}
\DeclareMathOperator{\arccot}{arccot}
\DeclareMathOperator{\arccsc}{arccsc}
\DeclareMathOperator{\arccosh}{arccosh}
\DeclareMathOperator{\arcsinh}{arcsinh}
\DeclareMathOperator{\arctanh}{arctanh}
\DeclareMathOperator{\arcsech}{arcsech}
\DeclareMathOperator{\arccsch}{arccsch}
\DeclareMathOperator{\arccoth}{arccoth}













\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Langevin Multiplicative Weights Update \\ with Applications in Polynomial Portfolio Management}
\author{
    %Authors
    % All authors must be in the same font size and format.
%    Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
%   AAAI Style Contributions by Pater Patel Schneider,
%    Sunil Issar,\\
    Yi Feng \equalcontrib \textsuperscript{\rm 1},
    Xiao Wang \equalcontrib \thanks{Correspondence to Xiao Wang.} \textsuperscript{\rm 1},
    Tian Xie \equalcontrib \textsuperscript{\rm 2} \\
}
\affiliations{
    %Afiliations
    \textsuperscript{\rm 1}School of Information Management \& Engineering, Shanghai University of Finance and Economics\\
    \textsuperscript{\rm 2}College of Business, Shanghai University of Finance and Economics\\
    fengyi95524@gmail.com, 
    wangxiao@sufe.edu.cn, 
    xietian@shufe.edu.cn
    % If you have multiple authors and multiple affiliations
    % use superscripts in text and roman font to identify them.
    % For example,

    % Sunil Issar\textsuperscript{\rm 2},
    % J. Scott Penberthy\textsuperscript{\rm 3},
    % George Ferguson\textsuperscript{\rm 4},
    % Hans Guesgen\textsuperscript{\rm 5}
    % Note that the comma should be placed after the superscript

%    1101 Pennsylvania Ave, NW Suite 300\\
 %   Washington, DC 20004 USA\\
    % email address must be in roman text type, not monospace or sans serif
%    proceedings-questions@aaai.org
%
% See more examples next
}

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name\textsuperscript{\rm 1},
    Second Author Name\textsuperscript{\rm 2},
    Third Author Name\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1}Affiliation 1\\
    \textsuperscript{\rm 2}Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
 We consider nonconvex optimization problem over simplex, and more generally, a product of simplices. We provide an algorithm, Langevin Multiplicative Weights Update (LMWU) for solving global optimization problems by adding a noise scaling with the non-Euclidean geometry in the simplex. Non-convex optimization has been extensively studied by machine learning community due to its application in various scenarios such as neural network approximation and finding Nash equilibrium. Despite recent progresses on provable guarantee of escaping and avoiding saddle point (convergence to local minima) and global convergence of Langevin gradient based method without constraints, the global optimization with constraints is less studied. We show that LMWU algorithm is provably convergent to interior global minima with a non-asymptotic convergence analysis. We verify the efficiency of the proposed algorithm in real data set from polynomial portfolio management, where optimization of a highly non-linear objective function plays a crucial role.
\end{abstract}

% Uncomment the following to link to your code, datasets, an extended version or similar.
%
% \begin{links}
%     \link{Code}{https://aaai.org/example/code}
%     \link{Datasets}{https://aaai.org/example/datasets}
%     \link{Extended version}{https://aaai.org/example/extended-version}
% \end{links}

\section{Introduction}
In this paper we consider nonconvex optimization problem with constraint that is a product of simplices, i.e.,
\begin{equation}\label{setup}
\min_{\vec{x}\in\Delta_1\times...\times\Delta_N} f(\vec{x})
\end{equation}
where $f:\Delta_1\times...\times\Delta_N\rightarrow\mathbb{R}$ is a sufficiently smooth function and 
\[
\Delta_i=\left\{(x_{i1},...,x_{id}):\sum_{s=1}^dx_{is}=1,x_{is}\ge 0\right\}.
\]
Problem \eqref{setup} appears naturally in potential game \cite{Shapley}, i.e., the incentive of all players to change their strategy can be expressed using a single global function (the potential function). A natural approach is to use projected gradient descent, but computing the projection at every iteration might not be an easy task to accomplish. An alternate effective algorithm in solving problem \eqref{setup} is so called Multiplicative Weights Update (MWU) \cite{AHK12}, which is a special case of FTRL that is commonly used in min-max optimization and multi-agent systems \cite{Lei2021,FLPW24,FPW2024}. Result of \cite{ICMLPPW19} indicates that MWU almost always converges to second-order stationary points with random initialization. Besides MWU, many first-order methods have been proven escaping saddle points or avoiding saddle points asymptotically \cite{GHJY2015,Jin17,JNJ18,LSJR16,LP19,panageas2016gradient,CB19,SFF19,PPW19a,SLQ19}.


However, in the nonconvex world, finding local minima can be far away from achieving global minima. 
The classic MWU together with its accelerated variant \cite{FPW2022} can only converge to second-order stationary points or interior local minima, and this leaves finding global optima a challenging direction. One approach in designing first-order algorithm converging to global minima is to introduce a random noise into gradient descent, so that the algorithm has a chance to escape local minima. In recent years, progress has been made on this via the Langevin algorithm, an algorithm originally invented to sample from a target distribution proportional to $e^{-f(\vec{x})}$ where $f(\vec{x})$ is objective function defined on the whole Euclidean space $\mathbb{R}^n$. Successfully, global convergence of Langevin gradient descent with non-asymptotic convergence rate are obtained in \cite{RRT17,XCZG18}. More recently, projected Langevin algorithm has been investigated in \cite{Lamperski} from the perspective of constrained sampling and optimization.

Despite aforementioned progresses in local and global convergence of gradient based algorithms, it is less understood whether there exists an algorithm that naturally fits distributed optimization framework from game theory and multi-agent systems. It is indicated in \cite{BP2019} that projected gradient descent can spend a few steps at each corner if the constraint has lower dimension. This feature makes projected gradient descent in multi-agent systems less effective, and in contrast, MWU and its variants have proven prominent in learning of games, their behaviors have been extensively studied in literatures, e.g., \cite{PPP2017,BG18,Cheung,ChGP19,CP2020}. Nevertheless, finding global minima of potential games with MWU or any of its variant seems missing in literature. 


\begin{table*}
\centering
\begin{tabular}{ |p{7.8cm}||p{2.2cm}|p{1.5cm}|p{1.5cm}| p{1.7cm} |}
 %\hline
 \multicolumn{4}{c}{}
   \\
 \hline
 & Global Convergence & Constraints& Simple Projection &Distributed Constraints\\
 \hline
MWU  \cite{ICMLPPW19}   & \xmark    &\cmark& \cmark  &\cmark\\
Langevin GD \cite{RRT17}&  \cmark   & \xmark  &\xmark &\xmark\\
Projected Langevin \cite{Lamperski} &\cmark & \cmark&  \xmark& \xmark\\
Perturbed RGD  \cite{CB19}   &\xmark & \cmark&  \cmark&\xmark\\
Accelerated MWU  \cite{FPW2022} &\xmark & \cmark & \cmark &\cmark\\
Langevin MWU (this work)&   \cmark  & \cmark&\cmark &\cmark\\
 \hline
\end{tabular}
\caption{Comparison to related results}
\label{tab:comparison} % 表格编号标签
\end{table*}




Motivated by global convergence analysis of Langevin gradient descent algorithm \cite{RRT17}, we propose a scheme of adding noise that is scalable with a natural geometry of simplex, so that the Langevin Multiplicative Weights Update algorithm (LMWU) enjoys both the efficiency of projecting onto the constraint and the power of escaping saddle points and spurious local minima. LMWU is derived from the geometric Brownian motion on Riemannian manifold, where the natural geometry of simplex, i.e., Shahshahani geometry, plays a crucial role. The main result is stated as follows, and our contributions compared to the most relevant results in literature are illustrated in above table.

\begin{thm}[Informal]
Suppose the global optima of Problem \eqref{setup} is in the interior of the constraints. The Langevin Multiplicative Weights Update converges to the biased global optima in expectation.
\end{thm} 

\paragraph{Other related works.}There have been considerably amount of works in convergence to local and global optima with first-order methods. Apart from the references listed in Table 1, we give a relatively complete review on the literatures about local and global convergence with gradient descent and Langevin algorithms. Local convergence guarantee with non-asymptotic convergence rate are investigated in \cite{GHJY2015,Jin17,JNJ18,SFF19,He2024}.Asymptotic convergence to local optima is studied with techniques from dynamical systems, typical references include \cite{LP19,LSJR16,AMPW2022}. On the other hand, convergence of Langevin algorithm in sampling has attracted many attentions. When the target distribution is log-concave, Euler discretization converges rapidly \cite{RT96,Dal17}. Later on the convergence rate was improved in \cite{DM17}. More recently, rapid convergence of Langevin algorithm for distributions satisfying log-Sobolev inequality has been established in \cite{VW19,LE20,WLP20,GV2022}. An improved rate analysis for Langevin SGD with variance reduction is provided in \cite{KS22} For sampling in a constrained set, Mirror Langevin diffusion has been studied in \cite{ZPFP20,HKRC18,AC21,Jia21,LTVW21}. A Reflected Langevin algorithm is proposed and analyzed in \cite{STKS22}, we need to mention that the reflected operation has an projection operation embedded, which makes it difficulty to apply the algorithm in simplicial constraint. 

\section{Preliminaries}
This section reviews the main background on Riemannian geometry and probability distributions on manifolds.
\subsection{Riemannian Geometry}
\paragraph{Riemannian metric and exponential map.}A Riemannian manifold $(M,g)$ is real, smooth manifold $M$ equipped with a Riemannian metric $g$. For each $\vec{x}\in M$, let $T_{\vec{x}}M$ denote the tangent space at $\vec{x}$. The metric $g$ induces a inner product $\langle\cdot,\cdot\rangle_{\vec{x}}:T_{\vec{x}}M\times T_{\vec{x}}M\rightarrow\mathbb{R}$. We call a curve $\gamma(t):[0,1]\rightarrow M$ a geodesic if it satisfies 
\begin{itemize}
\item The curve $\gamma(t)$ is parametrized with constant speed, i.e. $\norm{\frac{d}{dt}\gamma(t)}_{\gamma(t)}$ is constant for $t\in[0,1]$.
\item The curve is locally length minimized between $\gamma(0)$ and $\gamma(1)$.
\end{itemize}
\begin{comment}
The exponential map $\Exp_{\vec{x}}(\vec{v})$ maps $\vec{v}\in T_{\vec{x}}M$ to $\vec{y}\in M$ such that there exists a geodesic $\gamma$ with $\gamma(0)=\vec{x}$, $\gamma(1)=\vec{y}$ and $\gamma'(0)=\vec{v}$. The existence and uniqueness of geodesic is guaranteed by the fundamental theorem of ODE, one cannot have an explicit form of the geodesic in general. In many applications, we need to apply numerical methods to approximate the solution of the geodesic equation. But in some special cases, like sphere and Lorentz model for hyperbolic space, exponential map has closed forms. Simplex with Shahshahani metric also belong to this category.
\end{comment}

\paragraph{Riemannian gradient.}
 For differentiable function $f:M\rightarrow\BR$, $\grad f(\vec{x})\in T_{\vec{x}}M$ denotes the Riemannian gradient of $f$ that satisfies $\frac{d}{dt}f(\gamma(t))=\langle\gamma'(t),\grad f(\vec{x})\rangle$ for any differentiable curve $\gamma(t)$ passing through $\vec{x}$. The local coordinate expression of gradient is useful in our analysis.
\begin{equation}\label{grad}
\grad f(\vec{x})=\left(\sum_jg^{1j}(\vec{x})\frac{\partial f}{\partial x_j},...,\sum_jg^{dj}(\vec{x})\frac{\partial f}{\partial x_j}\right)
\end{equation}
where $g^{ij}(\vec{x})$ is the $ij$-th entry of the inverse of the metric matrix $\{g_{ij}(\vec{x})\}$ at each point. 

\paragraph{Retraction.} A retraction on a manifold $M$ is a smooth mapping $\Retr$ from the tangent bundle $TM$ to $M$ satisfying properties 1 and 2 below: Let $\Retr_{\vec{x}}:T_{\vec{x}}M\rightarrow M$ denote the restriction of $Retr$ to $T_{\vec{x}}M$.
\begin{enumerate}
\item $\Retr_{\vec{x}}(0)=\vec{x}$, where $0$ is the zero vector in $T_{\vec{x}}M$.
\item The differential of $\Retr_{\vec{x}}$ at $0$ is the identity map.
\end{enumerate}
Then the Riemannian gradient descent with stepsize $\alpha $ is given as
\begin{equation}\label{GD:Riemannian}
\vec{x}_{t+1}=\Retr_{\vec{x}_t}(-\epsilon\grad f(\vec{x}_t)).
\end{equation}




\subsection{Distributions on manifold}
\paragraph{KL divergence.}Let $\rho$ and $\nu$ be probability distributions on $M$ that is absolutely continuous with respect to the Riemannian volume measure on $M$ (denoted as $d\vec{x}$). The \emph{Kullback-Leibler} (KL) divergence of $\rho$ with respect to $\nu$ is 
\[
H(\rho|\nu)=\int_M\rho(\vec{x})\log\frac{\rho(\vec{x})}{\nu(\vec{x})}d\vec{x}
\]
KL-divergence measures the ``distance" between two probability distributions. Note that KL-divergene is nonnegative: $H(\rho|\nu)\ge 0$, and it is minimized at the target distribution, i.e., $H(\rho|\nu)=0$ if and only if $\rho=\nu$. Furthermore, $\nu$ is the only stationary point of $H(\cdot|\nu)$, and thus sampling from $\nu$ can be reduced to minimizing $H(\cdot|\nu)$. Note that if $\nu=e^{-\beta f}$, the KL-divergence can be decomposed into 
\[
H(\rho|\nu)=\mathbb{E}_{\rho}f+\mathcal{H}(\rho),
\]
where $\mathbb{E}_{\rho}f=\int_M\rho fd\vol$ is the expected value of $f$ and $\mathcal{H}(\rho)=-\int_M\rho\log\rho d\vol$ is the differential entropy of $\rho$.
\paragraph{Wasserstein distance.}The Wasserstein distance between $\mu$ and $\nu$ is defined to be
\[
\inf\{\sqrt{\mathbb{E}[d(X,Y)^2]}:\text{law}(X)=\mu,\text{law}(Y)=\nu\}
\]

\paragraph{Log-Sobolev inequality.} A probability measure $\mu$ on $M$ is called to satisfy the logarithmic Sobolev inequality if there exists a constant $\alpha>0$ such that

\begin{align}
&\int_Mg^2\log g^2d\nu-\left(\int_Mg^2d\nu\right)\log\left(\int_Mg^2d\nu\right)\notag\\
&\le\frac{2}{\alpha}\int_M\norm{\grad g}^2d\nu
\end{align}

for all smooth functions $g:M\rightarrow\mathbb{R}$ with $\int_Mg^2\le\infty$. 
The relative Fisher information of $\rho$ with respect to $\nu$ is $I_{\nu}(\rho)=\int_M\rho(\vec{x})\norm{\grad\log\frac{\rho(\vec{x})}{\nu(\vec{x})}}d\vol$. Log-Sobolev inequality (LSI) is equivalent to the relation between KL-divergence and Fisher information: $H(\rho|\nu)\le\frac{1}{2\alpha}I_{\nu}(\rho)$.

\section{Main Results}
In this section, we review classic Multiplicative Weights Update and its linear variant, and then some well known facts about Shahshahani geometry will be discussed. Based on the geometric setting of the simplex, we give a sketched framework how the Langevin Multiplicative Weights Update is derived.

\subsection{From MWU to Langevin MWU} 
 The classic Multiplicative Weights Update  is widely used in constrained optimization, multi-agent system and game theory. It often refers to two forms, 
\[
x_{ij}(k+1)=\frac{x_{ij}(k)e^{-\epsilon\frac{\partial f}{\partial x_{ij}}}}{\sum_s x_{is}(k)e^{-\epsilon\frac{\partial f}{\partial x_{is}}}}
\]
and its linear variant.
If not specified, This paper refers MWU to the linear variant. For completeness, we recall the linear variant of MWU. Suppose that $\vec{x}_i=(x_{i1},...,x_{id_i})$ is in the $i$-th component of $\Delta_1\times...\times\Delta_n$. Assume that $\vec{x}(k)$ is the $k$-th iterate of MWU, the algorithm is written as follows:
\begin{equation}\label{MWUclassic}
x_{ij}(k+1)=x_{ij}(k)\frac{1-\epsilon \frac{\partial f}{\partial x_{ij}}}{1-\epsilon\sum_{s}x_{is}(k)\frac{\partial f}{\partial x_{is}}},
\end{equation}
where $j\in\{1,...,d_i\}$.



\begin{algorithm}[t]
\caption{Langevin-MWU (single-agent) }
\label{alg:C}
\begin{algorithmic}
\STATE Input : error threshold $\delta>0$, large enough $\beta>0$,
\\
Compute step size $\epsilon<\frac{\delta^2\alpha}{8C(\frac{M}{2}\sigma+B)}$,
\\Initialize $\vec{x}_0\sim \rho_0$, 
\\
\REPEAT
\STATE Compute $S_{\vec{x}}=\sum_{j=1}^n\frac{1}{x_j}$, and $z_0^i\sim\mathcal{N}(0,1)$.
\\
Compute \\
$V_0^i=\frac{\epsilon}{2\beta}\left(n+1-(1+x_i)S_{\vec{x}}\right)+\sqrt{2\epsilon\beta^{-1} x_i}z_0^i$
\\
Set $x_i\leftarrow\frac{x_i-\epsilon x_i\frac{\partial f}{\partial x_i}+V_0^i}{1-\epsilon\sum_{j=1}^nx_j\frac{\partial f}{\partial x_j}+\sum_{j=1}^nV_0^j}$
\UNTIL{$k$ large enough, e.g., $k>\frac{16}{3\epsilon}\left(\frac{16(\frac{M}{2}\sigma+B)^2}{\delta_2\alpha}\right)$ }
\end{algorithmic}
\end{algorithm}



%\subsection{Shahshahani geometry of simplex.}

\begin{comment}
Throughout this paper, we emphasize on the optimization problem constrained on product of simplices. The standard geometry used in the rest is a special type of Riemannian geometry on the positive orthant and interior of simplex, called \emph{Shahshahani geometry} \cite{Shahshahani,HofSig}. The metric matrix $\{g_{ij}(\vec{x})\}$ on $\mathbb{R}_+^{d}=\{\vec{x}:x_i>0\text{ for all }i\in[d]\}$ is diagonal with $g_{ii}(\vec{x}=\frac{\abs{\vec{x}}}{x_i})$ where $\abs{\vec{x}}
=\sum_jx_j$. Use the Riemannian gradient \eqref{grad}, we have the explicit form of the Shahshahani gradient for $\vec{x}\in\mathbb{R}_+^d$ as follows:
\[
\grad f(\vec{x})=g^{-1}\nabla f(\vec{x})=\left(\frac{x_1}{\abs{\vec{x}}}\frac{\partial f}{\partial x_1},...,\frac{x_d}{\abs{\vec{x}}}\frac{\partial f}{\partial x_d}\right).
\]

Viewing $\Delta_+^{d-1}$ as a Riemannian submanifold of $\mathbb{R}_+^{d}$, we endow the simplex with a Riemannian metric whose matrix satisfies $g_{ii}(\vec{x})=\frac{1}{x_i}$ on diagonal and $g_{ij}=0$ on all other entries. The tangent space of $\Delta_+^{d-1}$ at $\vec{x}$ is denoted by $T_{\vec{x}}$ which consists of all the vectors $\vec{v}=(v_1,...,v_d)$ such that $\sum_jv_j=0$. Thus the tangent space $T_{\vec{x}}\Delta_+^{d-1}$ is identified with the hyperplane passing through $\vec{0}$ and parallel to $\Delta_+^{d-1}$. In the derivation of the L-MWU algorithm, the geometric property used most frequently is the othogonality in $\mathbb{R}_+^d$. Let $\langle\cdot,\cdot\rangle_{\vec{x}}$ be the Riemannian metric (a space-dependent inner product on $T_{\vec{x}}\Delta_+^{d-1}$), i holds that for all $\vec{u}\in T_{\vec{x}}\Delta_+^{d-1}$ and any $\lambda\ne 0$, we have $\langle\vec{u},\lambda\vec{x}\rangle_{\vec{x}}=0$. This means that the straight line passing through $\vec{0}$ and $\vec{x}$ is orthogonal to the tangent space of $\Delta_+^{d-1}$, with respect to the Shahshahani metric on $\mathbb{R}_+^d$. With these background in Shahshahani geometry of simplex, MWU can be viewed as the Riemannian gradient descent, especially the linear variant \eqref{MWUclassic} is the Riemannian gradient descent with retraction as the projection mapping from tangent space onto the base manifold.
\end{comment}

\begin{comment}
We recall from \cite{HofSig} that the exponential map (of the Shahshahani manifold) onto the simplex is:
\[
\Exp_{\vec{x}}(\vec{v})=\left(\frac{x_1e^{v_1}}{\sum x_ie^{v_i}},...,\frac{x_de^{v_d}}{\sum x_ie^{v_i}}\right),
\]
where $\vec{v}=(v_1,...,v_d)$ is an tangent vector of $\Delta_+$ at point $\vec{x}$.
\end{comment}





%\subsection{Derivation outline}
It is well known that Langevin dynamics corresponds to the gradient flow of relative entropy respect to Wasserstein metric. In the space of measures with the Wasserstein metric, the gradient flow of relative entropy is the following partial differential equation, called Entropy Regularized Wasserstein Gradient Flow:
\[
\frac{\partial \rho}{\partial t}=\nabla \cdot\left(\rho\nabla f\right)+\beta^{-1}\Delta\rho
\]
The key step in deriving Langevin Multiplicative Weights Update is to implement or approximate the noise scaled with the Shahshahani geometry in the simplex, which is a discretization of geometric Brownian motion in Shahshahani manifold. The geometric Brownian motion inside of the simplex $\Delta_+^{d-1}\subset\mathbb{R}_+^d$ can be obtained from the orthogonal projection of the geometric Brownian motion in $\mathbb{R}_+^d$, where the orthogonal projection is with respect to the Shahshahani metric in $\mathbb{R}_+^d$. Recall the standard Brownian motion in $\mathbb{R}^d$ is a random process $\{X_t\}_{t\ge 0}$ whose density function $\rho(\vec{x},t)$ evolves according to the diffusion equation 
\[
\frac{\partial\rho(\vec{x},t)}{\partial t}=\beta^{-1}\Delta\rho(\vec{x},t).
\]
The Brownian motion in Shahshahani manifold $\mathbb{R}_+^d$ is a random process $\{W_t\}_{t\ge 0}$ whose density function evolves according to the diffusion equation with respect to the Laplace-Beltrami operator, i.e.,
\[
\frac{\rho(\vec{x},t)}{\partial t}=\beta^{-1}\Delta_M\rho(\vec{x},t).
\]
Since $\mathbb{R}_+^d$ serves as its own local coordinate system as a Riemannian manifold, the geometric Brownian motion in $\mathbb{R}_+^d$ is described by the following stochastic differential equation 
\[
dX_t=-\beta^{-1}g^{ij}\Gamma_{ij}^kdt+\sqrt{2\beta^{-1}g^{-1}}dB_t
\]
where $dB_t$ is the standard Brownian motion in Euclidean space, $g^{ij}$ is the $(ij)$-entry of the inverse matrix of Shahshahani metric matrix $g_{ij}$, and $\Gamma_{ij}^k$ is the Christoffel symbol of Shahshahani metric that can be calculated explicitly. After establishing the noise discretized from Shahshahani geometric Brownian, we combine the noise and the Riemannian gradient in $\mathbb{R}_+^d$ to finalize the incremental vector in the update rule. We leave the details in Appendix. 

\subsection{Main Theorem}

In this section, we firstly state our main theorem that asserts the convergence in expectation of the L-MWU algorithm. Secondly, we will sketch the proof strategies, i.e., decomposition of error $\mathbb{E}f(\vec{x}_k)-f^*$ into 
\begin{equation}\label{decomp:error}
\mathbb{E}f(\vec{x}_k)-\mathbb{E}_{\nu}f+\mathbb{E}_{\nu}f-f^*
\end{equation}
where the expectation $\mathbb{E}_{\nu}f=\int_Mf(\vec{x})\nu(\vec{x}) d\vol$ and $f^*$ is the global minimum of $f(\vec{x})$ over $M$ and $\nu(\vec{x})$ is the probability density function that is proportional to $e^{-\beta f}$. We start presenting the main theorem by some a brief discussion on assumptions used in theoretical analysis.  


%\subsection{Main theorem}
Our analysis relies heavily on the theory of global convergence for Langevin algorithm in Euclidean space \cite{RRT17,XCZG18} and the results of rapid convergence results for log-Sobolev distributions such as \cite{GV2022}. Our strategy of giving theoretical analysis is to relate the assumptions in \cite{RRT17} to  the case of Shahshahani manifold, and then generalize the arguments in Euclidean space to Riemannian manifold with special structure. The reason that one can generalize the results in Euclidean space to Shahshahani manifold is the possibility of geometrizing the analytic assumption on $f$ by identifying $\vec{0}$ in $\mathbb{R}^n$ with $\frac{1}{n}(1,...,1)$ in $\Delta^{n-1}$, and the interior of $\Delta^{n-1}$ is diffeomorphic to $\mathbb{R}^{n-1}$. We start by giving assumptions function $f$ satisfies.

\begin{assumption}\label{A1}
 The function $f$ takes nonnegative real values, and there exist constants $A,B\ge 0$, such that
\[
\abs{f\left(\vec{1}\right)}\le A \ \ \text{and}\ \ \norm{\grad f\left(\vec{1}\right)}\le B.
\]
\end{assumption}
This assumption comes from assumption (A.1) in \cite{RRT17} by relating $\vec{0}$ to $\vec{1}=\frac{1}{n}(1,...,1)$.
\begin{assumption}\label{A2}
 Function $f$ is $M$-smooth for some $M>0$, i.e.,
 \[
 \norm{\grad f(\vec{y})-\Gamma_{\vec{x}}^{\vec{y}}f(\vec{x})}\le Md(\vec{x},\vec{y}) \ \ \text{for all}\ \ \vec{x},\vec{y}\in \mathcal{M},
 \]
 where $\Gamma_{\vec{x}}^{\vec{y}}$ denotes the parallel transport from $\vec{x}$ to $\vec{y}$. The gradient satisfies 
 \[
\norm{ \grad f(\vec{x})}_{\vec{x}}\le \frac{M}{2}d(\vec{1},\vec{x})+B
 \]
 for some constants $M>0$ and $B>0$.
 \end{assumption}
 $M$-smoothness in Euclidean setting reads as $\norm{\nabla f(\vec{x})-f(\vec{y})}\le M\norm{\vec{x}-\vec{y}}$, which is commonly assumed in many theoretical analysis. 
 
 \begin{assumption}\label{A3}
There exist positive numbers $m$ and $b$ such that
\[
\langle\grad f(\vec{x}),d(\vec{1},\vec{x})\vec{v}\rangle_{\vec{x}}\ge md(\vec{1},\vec{x})^2-b.
\]
where $\vec{v}$ is the velocity vector of the geodesic connecting $\vec{1}$ and $\vec{x}$. 
\end{assumption}
By a constant speed geodesic we mean the velocity has unit length everywhere, so the term $d(\vec{1},\vec{x})\vec{v}$ can be reduced to $\vec{x}$ in Euclidean space, where $\vec{x}$ means the geodesic of length $\norm{\vec{x}}$ (straight line) connecting $\vec{0}$ and $\vec{x}$.

\begin{assumption}\label{A4}
The differential entropy of the distribution $e^{-\beta f}$ is bounded by a constant $K$.
\end{assumption}
In the case of Euclidean space, the differential entropy has an upper bound by estimating the second moment of Gibbs distribution \cite{RRT17}. The differential entropy of a probability density with a finite second moment is upper-bounded by that of a Gaussian density with the same second moment, $h(\nu)\le\frac{d}{2}\log\left(\frac{2\pi e(b+d/\beta)}{md}\right)$. Thus there exists an upper-bound for $\beta$ large enough.
\begin{assumption}\label{A5}
$e^{-\beta f}$ satisfies log-Sobolev inequality.
\end{assumption}
This condition is necessary in bounding the sampling algorithm converges rapidly.

\begin{thm}
Suppose $f$ satisfies Assumptions \ref{A1}-\ref{A5}. Then there exists constant $C$, such that
\begin{align}
\abs{\mathbb{E}f(\vec{x}_k)-f^*}\le &(\frac{M}{2}\sigma+B)\sqrt{\frac{2}{\alpha}}\left(e^{-\frac{3}{16}\alpha\epsilon k}+\frac{C\epsilon}{\alpha}\right)^{\frac{1}{2}} \notag\\
&+\frac{K}{\beta}+\frac{1}{\beta}\log\left(\text{poly}(\beta^{-1})^{-1}\right).
\end{align}
\end{thm}

From the theorem we can conclude that for any given $\delta>0$, there exists $\beta>0$, $\epsilon<\frac{\delta^2\alpha}{8C(\frac{M}{2}\sigma+B)^2}$, and $k>\frac{16}{3\epsilon}\log\left(\frac{16(\frac{M}{2}\sigma+B)^2}{\delta^2\alpha}\right)$, such that $\abs{\mathbb{E}f(\vec{x}_k)-f^*}\le\delta$.




\subsection{Outline of Proof}
Suppose that the $k$'th iteration $\vec{x}_k$, which is a random variable on Shahshahani manifold $M$, has probability density function $\rho_k(\vec{x})$. Then the expectation $\mathbb{E}f(\vec{x}_k)$ can be written as 
\[
\int_Mf(\vec{x})\rho_k(\vec{x})d\vol
\]
where $d\vol$ is the Riemannian volume element induced by Shahshahani metric on $M$. Since the error $\mathbb{E}f(\vec{x}_k)-f^*$ has been decomposed into the sum of \eqref{decomp:error}, we need to bound $\abs{\mathbb{E}f(\vec{x}_k)-\mathbb{E}_{\nu}f}$ and $\abs{\mathbb{E}_{\nu}f-f^*}$ respectively. By the integral on manifold we have the following:
\begin{align}
%\begin{split}
\abs{\mathbb{E}f(\vec{x}_k)-\mathbb{E}_{\nu}f}&=\abs{\int_Mf(\vec{x})\rho_k(\vec{x})-\int_Mf(\vec{x})\nu(\vec{x})}\notag \\
&=\abs{\int_Mf(\vec{x})(\rho_k(\vec{x})-\nu(\vec{x}))d\vol}
%\end{split}
\end{align}
 In Euclidean space, the difference is bounded by the Wasserstein distance between $\rho_k$ and $\nu$ according to Lemma 6 of \cite{RRT17}, where the authors prove that $\abs{\int_{\mathbb{R}^d}gd\mu-\int_{\mathbb{R}^d}gd\nu}\le\text{const}\cdot W_2(\mu,\nu)$, if $g$, $\mu$ and $\nu$ satisfy some assumptions. Therefore, our strategy of bounding $\abs{\int_Mf\rho_kd\vol-\int_Mf\nu d\vol}$ relies on a generalized version of Lemma 6 of \cite{RRT17} in the case of Shahshahani manifold, if not for all Riemannian manifolds. Following this idea, we provide the following lemma.
 
\begin{lemma}\label{lemma:convergence1}
Let $\mu$ and $\nu$ be two density function of probability measures on Shahshahani manifold $M$. Suppose $f:M\rightarrow\mathbb{R}$ satisfies 
\[
\norm{\grad f(\vec{x})}\le \frac{M}{2}d(\vect{1},\vec{x})+B
\]
for some constants $\frac{M}{2}>0$ and $B>0$. Then
\[
\abs{\int_Mf\mu d\vol-\int_M f\nu d\vol}\le(\frac{M}{2}\sigma+B)W_2(\mu,\nu)
\]
where $\sigma^2=\int_Md(\vec{1},\vec{x})^2\mu(\vec{x})d\vol\vee\int_Md(\vec{1},\vec{y})^2\nu(\vec{y})d\vol$.
\end{lemma}
Letting $\mu=\rho_k$, we can immediately obtain the expected result, i.e.,
\begin{align}
\abs{\mathbb{E}f(\vec{x}_k)-\mathbb{E}_{\nu}f}&=\abs{\int_Mf\rho_kd\vol-\int_Mf\nu d\vol}\notag\\
&\le(\frac{M}{2}\sigma+B)W_2(\rho_k,\nu)
\end{align}
Talagrand inequality is a well known connection between Wasserstein distance and KL-divergence. We say that a probability measure $\nu$ satisfies a Talagrand inequality with constant $\alpha>0$ if for all probability measure $\rho$, absolutely continuous with respect to $\nu$, with finite moments of order 2, it holds that
$
W_2(\rho,\nu)^2\le\frac{2}{\alpha}H(\rho|\nu).
$ 
Therefore, bounding $W_2(\rho_k,\nu)$ boils down to bounding the KL-divergence $H(\rho_k|\nu)$. It has been shown in \cite{GV2022} that for general Hessian Manifold, Langevin algorithm for sampling from a log-Sobolev distribution converges rapidly to a distribution with bias $\epsilon$. Since simplex with Shahshahani metric is a Hessian manifold, applying Theorem 2 of \cite{GV2022}, we can immediately conclude that there exists a constant $C$ and log-Sobolev constant $\alpha$ such that $H(\rho_k|\nu)\le e^{-\frac{3}{16}\alpha\epsilon k}+\frac{C\epsilon}{\alpha}$, and therefore
\begin{align}
%\begin{split}
\abs{\mathbb{E}f(\vec{x}_k)-\mathbb{E}_{\nu}f}&\le(\frac{M}{2}\sigma+B)\sqrt{\frac{2}{\alpha}}H(\rho_k|\nu)^{\frac{1}{2}}\notag\\
&\le(\frac{M}{2}\sigma+B)\sqrt{\frac{2}{\alpha}}\left(e^{-\frac{3}{16}\alpha\epsilon k}+\frac{C\epsilon}{\alpha}\right)^{\frac{1}{2}}.
%\end{split}
\end{align}

To see that $\phi=\sum_{i=1}^nx_i\ln x_i$ induces a Hessian metric on simplex, let $x_n=1-\sum_{i=1}^{n-1}x_i$, then 
\[
\phi=\left(1-\sum_{i=1}^{n-1}x_i\right)\ln\left(1-\sum_{i=1}^{n-1}x_i\right).
\]
The Hessian $\nabla^2\phi$ has the form of the following:

\begin{equation}\label{eq:Hess}
\left[
\begin{array}{ccc}
\frac{1}{x_1}+\frac{1}{1-\sum_{i=1}^{n-1} x_i}&\dots&\frac{1}{1-\sum_{i=1}^{n-1}x_i}
\\
\\
\vdots&\ddots&\vdots
\\
\\
\frac{1}{1-\sum_{i=1}^{n-1}x_i}&\dots&\frac{1}{x_{n-1}}+\frac{1}{1-\sum_{i=1}^{n-1}x_i}
\end{array}
\right].
\end{equation}

On the other hand, the mapping $\varphi:(x_1,...,x_{n-1})\rightarrow(x_1,...,x_{n-1},1-\sum_{i=1}^{n-1}x_i)$ from $\mathbb{R}^{n-1}$ to $\mathbb{R}^n$ induces a Riemannian metric in the projection of simplex, and this metric matrix $\langle d\varphi(\cdot),d\varphi(\cdot)\rangle$ is exactly the same as \eqref{eq:Hess}.


Running Langevin dynamics is equivalent to optimization in the space of probability densities in the underlying space \cite{Wibisono18}, and thus equivalent to sampling from the stationary distribution of the Wasserstein gradient flow asymptotically. To minimize $\int_Mf(\vec{x})\rho(\vec{x})d\vec{x}$ with respect to $\rho(\vec{x})$, we introduce the entropy regularized functional of $\rho$ defined by
$
\mathcal{L}(\rho)=\mathcal{F}(\rho)+\beta^{-1}\mathcal{H}(\rho)
$
where 
$
\mathcal{F}(\rho)=\int_Mf(\vec{x})\rho(\vec{x})d\vec{x},
$ 
and 
$
\mathcal{H}(\rho)=-\int_M\rho(\vec{x})\log\rho(\vec{x})d\vec{x}.
$
The Wasserstein space $\mathcal{P}_2(\mathcal{M})$ of probability measures on $\mathcal{M}$ is an infinite dimensional smooth Riemannian manifold. A tangent vector $R\in T_{\rho}\mathcal{M}$ is of the form $R=-\Div\left(\rho\grad \phi\right)$ for some function $\phi:\mathcal{M}\rightarrow\mathbb{R}$. The gradient of a functional $\mathcal{L}:\mathcal{P}\rightarrow\mathbb{R}$ is $\grad_{\rho}\mathcal{L}=-\Div\left(\rho\grad\frac{\delta\mathcal{L}}{\delta\rho}\right)$, where $\frac{\delta\mathcal{L}}{\delta\rho}(\vec{x})$ is the first variation of $\mathcal{L}$ with respect to $\rho$.
 It is well known that the Wasserstein gradient flow of $\mathcal{L}$ is the Fokker-Planck equation
\begin{align}\label{FP}
\frac{\partial \rho(\vec{x},t)}{\partial t}&=\Div(\rho(\vec{x},t)\grad f(\vec{x})+\beta^{-1}\grad\rho(\vec{x},t))\notag\\
&=\Div(\rho(\vec{x},t)\grad f(\vec{x}))+\beta^{-1}\Delta_M\rho(\vec{x},t),
\end{align}
where $\grad$, $\Div$ and $\Delta_M$ are gradient, divergence and Laplace-Beltrami on manifolds. The stationary solution of equation \eqref{FP} is the density proportional to $e^{-\beta f}$ that minimizes $\mathcal{L}$.
\begin{lemma}\label{lemma:convergence2}
Suppose the entropy of distribution $\nu(\vec{x})$ is uniformly bounded for all $\beta$, i.e., $h(\nu)\le K<\infty$. Then
\[
\abs{\mathbb{E}_{\nu}f-f^*}\le\frac{K}{\beta}+\frac{1}{\beta}\log\left(\text{poly}\left(\frac{1}{\beta}\right)^{-1}\right).
\]
\end{lemma}
Let $p(\vec{x})=\frac{e^{-\beta f(\vec{x})}}{\Lambda}$ denote the density of the Gibbs measure with respect to the measure induced by the Shahshahani metric in simplex, where
$
\Lambda:=\int_Me^{-\beta f(\vec{x})}d\vec{x}
$
is the normalization constant known as the partition function. Note that the differential entropy of $p$ has the following expression,
\[
h(p)=\frac{1}{\Lambda}\int_M\beta f(\vec{x})e^{-\beta f(\vec{x})}d\vol+\log\Lambda
\]
thus we have that
\[
\int_Mf(\vec{x})p(\vec{x})d\vol=\frac{1}{\beta}(h(p)-\log\Lambda).
\]
Let $\vec{x}^*$ be any point that minimizes $f(\vec{x})$. Then $\grad f(\vec{x}^*)=0$. Since $f$ is assumed to be geodesically smooth, we have $f(\vec{x})-f(\vec{x}^*)\le\frac{M}{2}d(\vec{x},\vec{x}^*)^2$, the lower bound of $\log\Lambda$ can be obtained by following calculation,
\begin{align}
\log \Lambda&=\log\int_Me^{-\beta f(\vec{x})}d\vol\notag\\
&=-\beta f(\vec{x}^*)+\log\int_Me^{-\beta(f(\vec{x}^*)-f(\vec{x}))}d\vol
\notag\\
&\ge -\beta f(\vec{x}^*)+\log\int_Me^{-\beta d(\vec{x},\vec{x}^*)^2/2}d\vol
\end{align}
Without loss of generality, we can assume that the global minima $\vec{x}^*$ is at the center of simplex, i.e., $\vec{x}^*=\vec{1}=\left(\frac{1}{n},...,\frac{1}{n}\right)$. In appendix, we show that the integral $\int_Me^{-cd(\vec{1},\vec{x})^2}d\vol$ is bounded. By letting $c=\beta\frac{M}{2}$, we furthermore end up with a concrete expression of $\int_Me^{-cd(\vec{1},\vec{x})^2}d\vol$ in terms of a polynomial of $\beta^{-1}$, which is denoted briefly as follows,
\[
\log\Lambda\ge -\beta f(\vec{x}^*)+\log\left(\text{poly}\left(\beta^{-1}\right)\right),
\]
and then we have
\[
-f(\vec{x}^*)\le\frac{\log\Lambda}{\beta}+\frac{1}{\beta}\log\left(\text{poly}\left(\beta^{-1}\right)^{-1}\right).
\]
Combining with $\mathbb{E}_{\nu}f=\frac{h(\nu)}{\beta}-\frac{\log\Lambda}{\beta}$, we have the following bound:
\[
\mathbb{E}_{\nu}f-f(\vec{x}^*)\le\frac{K}{\beta}+\frac{1}{\beta}\log\left(\text{poly}\left(\beta^{-1}\right)^{-1}\right).
\]

%\paragraph{Application beyond multi-agent learning.}We complete this section by applying Langevin MWU algorithm in a special polynomial optimization in portfolio selection problem which is a challenging task in financial literature. The modern portfolio theory (MPT), or mean-variance (MV) analysis by \cite{markowitz1952} established a mathematical framework for assembling a portfolio of assets such that the expected return is maximized for a given level of risk. A polynomial portfolio optimization problem can be defined as $\hat{\vec{x}}=\argmin_{\vec{x}\in \Delta}\mathbb{E}f(\vec{x},\vec{r})$, where $f(\vec{x},\vec{r})$ is polynomial loss function, $\vec{r}=(r_1,...,r_n)^{\top}$ denotes the vector of $n$ individual returns in the portfolio, and $\vec{x}$ stands for the weights we assign to each component in the portfolio. Here we assume that $\vec{x}$ is restricted to the simplex. Empirically the expectation is represented as $\mathbb{E}f(\vec{x},\vec{r})=\frac{1}{N}\sum_{i=1}^Nf(\vec{x},\vec{r}_i)$. So see the efficiency of L-MWU, it suffices to verify the validity of L-MWU on each $f(\vec{x},\vec{r}_i)$ since it is trivial to extend the code/program to linear combination of $f(\vec{x},\vec{r}_i)$ for $i\in[N]$. We leave more details in appendix due to space constraint. 

\begin{comment}
In line with \cite{yang2022}, we consider the following specification of the loss function $f(\vec{x},\vec{r})$ such that
$
f(\vec{x},\vec{r})=-\lambda_1m_1(\vec{x},\vec{r})+\lambda_2m_2(\vec{x},\vec{r})+...+(-1)^d\lambda_dm_d(\vec{x},\vec{r})$, where $m_1(\vec{x},\vec{r})=\vec{x}^{\top}\vec{r}$ and $m_i(\vec{x},\vec{r})=\left(m_1(\vec{x},\vec{r})-\mathbb{E}\left(m_1(\vec{x},\vec{r})\right)\right)^i$, for $i=2,...,d$.
\end{comment}


%\section{Conclusion} In this paper we propose a novel algorithm called Langevin Multiplicative Weights Update (L-MWU) which is a stochastic version of classic MWU algorithm. Our theoretical and experimental verifications show that L-MWU converges to interior global optima of the objective function with non-asymptotic convergence from the Riemannian geometric perspective. There are promising directions for future research, such as the case when the global optima lies on the boundary of the constraints and the non-asymptotic convergence rate for the product manifolds. 



\section{Application in Portfolio Management}

%\begin{table*}[htb] 
%\centering 
%\caption{Out-of-sample Evaluation Results for Polynomial Portfolio %Optimization} \label{result} 
%\begin{threeparttable} 
%\begin{tabular}{ccccccc} 
%\hline   
%Method & Degenerate & Increasing & MV & MVS & MVSK & Equal\\
%\hline
%\\
%MWU &  74.7203 &  17.4527 &   0.8561 &   0.8391 &  16.1104 &  44.5159  \\
%\\
%LMWU&  70.9927 &  16.4264 &   0.8135 &   0.7803 &  15.4364 &  42.0056  \\ 
%\hline   
%\end{tabular} 
%\begin{tablenotes} 
%\scriptsize 
%\item  
%\end{tablenotes} 
%\end{threeparttable} 
%\end{table*}

\begin{table*}[htb] 
\centering 
\begin{threeparttable} 
\begin{tabular}{lccccccc} 
\hline 
Method & Degenerate & Increasing & MV & MVS & MVSK & Equal\\
\hline
MWU   &  74.7203 &  17.4527 &   0.8561 &   0.8391 &  16.1104 &  44.5159  \\ 
AMWU  \cite{FPW2022}&  76.3657 &  17.5554 &   0.8561 &   0.8579 &  15.6559 &  43.4190  \\ 
Projected Langevin  \cite{Lamperski} &  73.9596 &  17.8720 &   0.8674 &   0.8846 &  16.7519 &  43.2847  \\ 
LMWU (this work)&  70.8930 &  16.7684 &   0.8464 &   0.8314 &  14.9585 &  42.8307  \\ 
\hline 
\end{tabular} 
%\begin{tablenotes} 
%\scriptsize 
%\item 
%\end{tablenotes} 
\end{threeparttable} 
\caption{Out-of-sample Evaluation Results for Polynomial Portfolio Optimization} \label{result} 
\end{table*} 

 Portfolio management is a critical aspect of finance as it facilitates the efficient and effective management of investments to achieve specific financial goals and objectives. It involves the careful selection, diversification, and alignment of various financial instruments such as stocks, bonds, and other assets, to balance risk and returns according to an individual or institution's risk tolerance, time horizon, and investment objectives. The strategic allocation of assets in a portfolio can enhance returns, mitigate potential losses, and provide a smoother investment journey. Moreover, portfolio management offers a structured approach to monitor, review, and adjust investments in response to changing market conditions, personal circumstances, or shifts in financial goals, making it an indispensable tool for successful financial planning and wealth management.
 
The polynomial portfolio optimization problem can be formally represented as
\[
\hat{\vec{ w}} = \underset{\vec{ w}\in\mathcal {W}}{\argmin} \, \mathbb{E}[f(\vec{ w}, \vec{ r})], \label{fun}
\]
where $\mathbb{E}$ denotes the expectation operator, $f(\vec{w}, \vec{r})$ refers to a polynomial loss function, and $\vec{r} = [r_1, r_2, ..., r_n]^\top$ symbolizes the vector of $n$ individual returns within the portfolio. Additionally, $\vec{w} = [w_1, w_2, ..., w_n]^\top$ signifies the weights designated to each constituent element of the portfolio. It's important to note that $\vec{w}$ is restricted to the feasible set $\mathcal{W}$,
$
\mathcal{W} \equiv \{\vec{ w}\in\mathbb {R}^N: \sum^N_{i=1} w_i = 1 \},$ which constrains the summation of the weights to be one. This constraint implies that no leveraging or borrowing is permitted in the portfolio construction.


We propose a specific formulation for the loss function $f(\vec{w}, \vec{r})$ as follows:
\begin{align}
f(\vec{ w}, \vec{ r}) = -\lambda_1m_1(\vec{ w}, \vec{ r})& + \lambda_2m_2(\vec{ w}, \vec{ r}) + ... \notag\\
&+ (-1)^{d} \lambda_dm_d(\vec{ w}, \vec{ r}), \label{lossfun}
\end{align}
where $m_1(\vec{w}, \vec{r}) = \vec{w}^{\top} \vec{r}$ represents the sample portfolio return, and
\[
m_i(\vec{ w}, \vec{ r}) = \Big(m_1(\vec{ w}, \vec{ r}) - \mathbb{E}\big( m_1(\vec{ w}, \vec{ r})\big)\Big)^i, \quad i = 2,...,d
\]
encapsulates the $i^{th}$ central moment of $m_1(\vec{w}, \vec{r})$, with $\mathbb{E}\big(m_i(\vec{w}, \vec{r})\big)$ being the expected value. The parameter vector $\vec{\lambda} = [\lambda_1,...,\lambda_d]^\top$ contains the risk preference parameters, each satisfying $\lambda_i\ge0$, and their summation amounts to one, i.e., $\sum^d_{i=1}\lambda_i = 1$. It's worth noting that the mean-variance (MV), mean-variance-skewness (MVS), and mean-variance-skewness-kurtosis (MVSK) losses can be considered specific instances of this general polynomial portfolio optimization framework.

Our dataset comprises daily entries for $n = 10$ notable NASDAQ stocks, covering the period from January 3, 2011, to December 31, 2021, and thereby accumulating $T = 2517$ periods. We initiate a rolling-window out-of-sample forecasting exercise from the beginning of this data sample. The window length is set at $L=1000$, approximately corresponding to four years of training data. To calculate the optimal portfolio weights, $\hat{\vec{w}}$, we implement four estimation strategies: the traditional Multiplicative Weight Update (MWU) approach, the accelerated MWU algorithm purposed in \cite{FPW2022}, the projected langevin gradient descent algorithm purposed in \cite{Lamperski}
and our newly proposed Langevin Multiplicative Weights Update (LMWU) method.

Following this, we apply the estimated portfolio weights to the returns in the succeeding period and assess the performance of the constructed portfolio using the loss function defined in Equation \eqref{lossfun}. It's crucial to note that our loss function relies on a predetermined parameter, $\vect{\lambda}$, which represents different risk preferences. We take into account the following potential values for $\vect{\lambda}$:
\begin{enumerate}%[(i)]
\item Increasing preference: $\frac{1}{15}, \frac{2}{15},...,\frac{5}{15}$
\item Degenerate preference: $\frac{5}{15}, \frac{4}{15},...,\frac{1}{15}$
\item Mean-Variance (MV) preference: $\frac{1}{2},\frac{1}{2},0,0,0$
\item Mean-Variance-Skewness (MVS) preference: $\frac{1}{3},\frac{1}{3},\frac{1}{3},0,0$
\item Mean-Variance-Skewness-Kurtosis (MVSK) preference: $\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4},0$
\item Equal preference: $\frac{1}{5},\frac{1}{5},...,\frac{1}{5}$
\end{enumerate}


For each period $t$, we record the loss score, denoted as $\widehat{\textrm{Loss}}_{t}$, and compute the average loss score using the formula:
$
\widehat{\textrm{Score}} = \frac{1}{T-L}\sum^T_{t = T-L+1}\widehat{\textrm{Loss}}_{t}.
$
The outcomes are summarized in Table \ref{result}. The table's first column delineates the methods employed in the exercise, while columns two through seven display the results of these methods under various risk preferences, as indicated in the header row.

The data clearly demonstrates that the LMWU method outperforms the MWU method and several of its other variants across all risk preferences. For example, under the Degenerate preference, the LMWU method registers a score of 70.8930, a better result (considering the goal is minimization) than the MWU's score of 74.7203. This superiority is consistent across other risk preferences as well. Specifically, for Mean-Variance (MV) and Mean-Variance-Skewness (MVS) preferences, which are likely more commonplace in portfolio management, the LMWU method achieves superior scores (0.8464 and 0.8314, respectively) compared to the MWU method (0.8561 and 0.8391, respectively). Similar better performance can also be observed with Langevin MWU compared to other variants of MWU algorithms. These observations are consistent with our theoretical analysis of LMWU: it has the ability to escape local minima and converge towards global minima.

In summary, these results underscore the efficacy of our proposed LMWU method in the realm of polynomial portfolio optimization.



\section{Additional Experiments}

In this section, we present experiments comparing Langevin-MWU  with algorithms presented in Table \ref{tab:comparison}. We use Langevin-MWU and other algorithms for comparison to optimize several non-convex functions with many local minima. The experimental results show Langevin-MWU escapes such bad local minima and finds minima with smaller function values, while other algorithms either get stuck at local minima or are more unstable than Langevin-MWU. The experimental results are presented in Figure \ref{E3} and  Figure \ref{E4}. Future experiments, especially the examples demonstrating how the trajectories of Langevin-MWU avoid local minima and converge to global minima, are presented in the Appendix.

\paragraph{Test functions.}
We construct non-convex functions to verify the efficiency of LMWU in finding global minima. The functions are given as follows:
\begin{align*}
f_1 (x,y,z) &= -\ln \left( e^{ -10 (x - 0.3)^2 - 20(y - 0.5)^2 - 30(z - 0.2)^2 } \right. \\
    &\quad + e^{ -30 (x - 0.4)^2 - 20(y - 0.2)^2 - 36(z - 0.4)^2 } \bigg) \\
    &\quad + y + 10.
\end{align*}
and
\begin{align*}
f_2 (x,y,z) &= -(x - 0.6)^2 (x - 0.2)^2 + (y - 0.3)(y - 0.4)^3 \\
    &\quad + (z - 0.2)^3(z - 0.8) \\
    &\quad - xy - 0.4z.
\end{align*}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Exp_1_1.png}
        \caption{Test function : $f_1$}
        \label{E11}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Exp_2_1.png}
        \caption{Test function : $f_2$}
        \label{E21}
    \end{subfigure}
    \caption{Comparison of LMWU with Accelerated MWU  \cite{FPW2022}, Projected Lagevin \cite{Lamperski}, and PRGD \cite{CB19}.}
    \label{E3}
\end{figure}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Exp_1_3.png}
        \caption{Test function : $f_1$}
        \label{E31}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Exp_2_3.png}
        \caption{Test function : $f_2$}
        \label{E32}
    \end{subfigure}
    \caption{Future comparison of LMWU with Projected Langevin \cite{Lamperski}.}
    \label{E4}
\end{figure}





% We present both trajectories of algorithms on the contour maps of text functions and the curve of convergence in the function values. With simplex constrains $x + y + z = 1, x,y,z \ge 0$, the values of a three variables function $f(x,y,z) $ constrained on a simplex are determined variables $x$ and $y$, thus we can draw trajectory and level curves of $f(x,y,z)$ on a $(x,y)$-plane. Note that since $x + y \le 1$, only the lower half part of the $(x,y)$-plane is meaningful, and algorithms' trajectories will only appear on lower half part of $(x,y)$-plane.

% \paragraph{Parameter setting.} 
%Since the behaviors of Langevin-MWU are controlled by the parameter $\beta$, in the experiments we choose different $\beta$ to show the power of using larger $\beta$'s, the choices of $\beta$ are denoted on the convergence curves graph. In experiments we set the parameters as follows:
%\begin{itemize}
%\item[(1)] Figure \eqref{f_1n}: Initial point $(0.3,0.6,0.1)$, MWU's step size $10^{-3}$, LMWU's step size $10^{-4}$ , $\beta  =10,50,100 $.
%\item[(2)] Figure \eqref{f_4n}: Initial point $(0.5,0.4,0.1)$, MWU's step size $10^{-2}$, LMWU's step size $2 \times 10^{-4}$ , $\beta  =1000,2000,8000 $.
%\end{itemize}
%In each experiments MWU and LMWU starting from the same initial points and run %the same number of steps.

%\begin{figure}[H]
%\centering
%\subfigure[Trajectories]{
%\includegraphics[clip,width=0.35\columnwidth]{Tar_1.png}
%}
%\subfigure[Convergence curves]{
%\includegraphics[clip,width=0.45\columnwidth]{Value_1.png}
%}
%\caption{Test function $f_1$}
%\label{f_1n}
%\end{figure}

%\begin{figure}[H]
%\centering
%\subfigure[Trajectories]{
%\includegraphics[clip,width=0.35\columnwidth]{Tar_4.png}
%}
%\subfigure[Convergence curves]{
%\includegraphics[clip,width=0.45\columnwidth]{Value_4.png}
%}
%\caption{Test function $f_2$}
%\label{f_4n}
%\end{figure}

%\paragraph{Analysis of experimental results.} 

As shown in Figure \ref{E3} and \ref{E4}, LMWU and Projected Langevin can converge to global optima, but Perturbed RGD and Accelerated MWU only converge to local optima, which agree with the claims of \cite{FPW2022} and \cite{CB19}.
%    \item Despite global convergence of Projected Langevin, LMWU is more stable with same step-size. As shown in Figure \ref{E4}, when Projected Langevin (\textbf{\textcolor{orange}{—}}) approximately reaches the global minima, the amplitude of oscillation in the value of loss functions is larger than that of LMWU. To smooth the curves of function values, the randomness in Projected Langevin need to be small. However, this will lead to a failure in avoiding local minima as shown by the (\textbf{\textcolor{green}{—}}) line.
%\end{itemize}


%The curves of convergence in function values show that Langevin-MWU outperforms MWU when $\beta$ is small enough. This can be seen clearly from the trajectories of the algorithms on contour map : MWU is  attracted by a local minimum near initial points, but although starting from the same initial point, LMWU will escape the bad local minimum near initial points and go to the global minimum. The choice of $\beta$ have a great influence on behaviors of LMWU : as the experimental results show that larger $\beta$ will make LMWU find a better convergence point, but with a slower convergence rate, this is compatible with our theoretical analysis. Future discussions can be found in supplementary materials.

\section{Conclusion} In this paper we focus on a constrained non-convex optimization problem that widely exists in multi-agent learning. We propose a novel algorithm called Langevin Multiplicative Weights Update (LMWU) which is a stochastic version of classic MWU algorithm. Our theoretical analysis shows that LMWU converges to interior global optima of the objective function. Another important setting that is missing in current work is the time-varying environment, e.g., \cite{FFHLPW} in min-max optimization. We leave the time-varying portfolio management for future investigation. %Moreover, the comparison of MWU and LMWU on real dataset in polynomial portfolio management clearly shows the power of LMWU in applications.
%Furthermore, a non-asymptotic convergence analysis is provided from the Riemannian geometric perspective. There are promising directions for future research, such as the case when the global optima lies on the boundary of the constraints and the non-asymptotic convergence rate for the product manifolds. 
\section*{Acknowledgements}Xiao Wang acknowledges Grant 202110458 from Shanghai University of Finance and Economics and support from the Shanghai Research Center for Data Science and Decision Technology.
Xie's research is supported by the Natural Science Foundation of China (72173075) and the Shanghai Research Center for Data Science and Decision Technology.

\bibliography{aaai25}

\input{appendix}

\end{document}
