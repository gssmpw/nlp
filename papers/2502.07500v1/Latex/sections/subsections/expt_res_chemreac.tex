The chemistry reaction prediction task is divided into two phases. The first phase consists of a binary classification on atoms (nodes) predicting whether any bond (edge) attached to an atom is changed from reactant (source graph) to product (target graph). In the second phase, finding the bond types (no bond, single bond, double bond, triple bond, and aromatic bond) among the atoms whose state is predicted as changed in the first phase, is formulated as a multi-class classification problem. This two-phase approach helps to reduce total number of predictions from ${}^NC_2$ to $\left(N+{}^{N_a}C_2\right)$, where $N$ is total number of atoms and $N_a$ is the number of atoms predicted as actively participating in the reaction. When $N_a$ $<$ $N$, it leads to a reduced computational cost. To conduct the training operation, we initialize the node features with 82 dimensional vectors provided in the dataset.

Let there be $N$ nodes in the source graph and the latent dimension be $L$. The latent vector of $node_i$ be $l_i=[l_{i_0}, l_{i_1}, \dots , l_{i_{L-1}}]$. Additionally, another vector $b_i=[b_{i0}, b_{i1}, \dots , b_{i(N-1)}]$ is introduced, to incorporate the bond-information between $node_i$ and $node_j$. $b_{ij}=\frac{1}{4}$ for single bond, $\frac{2}{4}$ for double bond, $\frac{3}{4}$ for triple bond, 1 for aromatic bond, and 0 for no bond. Finally, we concatenate the node representation as well as the bond information and as a result an intermediate matrix representation ($M$) is produced of size $(L+N)\times (L+N)$ which is used as the input to the decoder.

% Before passing the required intermediate matrix $M$ for the decoder, vector $b_i$ is concatenated with $l_i$. Therefore, \hl{matrix} $M$ becomes $(L+N)\times (L+N)$ dimensional.

% $b_{ij}=\frac{1}{4}$ for single bond, $\frac{2}{4}$ for double bond, $\frac{3}{4}$ for triple bond, 1 for aromatic bond, and 0 for no bond.

Out of total 7,180 reactant-product graph pairs (cf. Section  \ref{dataset} Para \ref{data:chem}), we employ 1,280 data instances for training our framework and the rest of the paired instances are used for evaluation. Table~\ref{tab:Chem_compare} presents the performance comparison of our framework with the existing baselines on this dataset. We can observe that our proposed approach produces comparable performance in comparison to the SOTA models.

% Table~\ref{tab:Chem_PRF} show that our framework 


% of our proposed model (in terms of precision, recall, f1-score and accuracy) on the bond-type prediction task on the Chemistry Reaction dataset. Table \ref{tab:Chem_compare} compares our model's performance (in terms of accuracy) on the Chemistry Reaction dataset to other \hl{well known} methods. Table \ref{tab:Chem_compare} shows that, our model produces near-SOTA performance on the Chemistry Reaction dataset for bond-type prediction task.
\input{Latex/Tabledef/chemreac_res_cmp_tab}


% As mentioned in 1,280 reactant-product pairs out of 7,180 are used for training with batch size 128 and learning rate 0.005, and the rest (5,900 graph-pairs) is used as test set.