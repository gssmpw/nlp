The malware confinement task consists of two subtasks: predicting the infection state of the nodes (interconnected devices) and restructuring of the edges i.e., connection between devices. To conduct the experiment, we initialize the node features with either 1 or 0 values, as $F_{malicious} = [1, 1, \dots , 1]_{1\times N}$ and $F_{benevolent} = [0, 0, \dots , 0]_{1\times N}$, 1 and 0 denoting the malicious and benevolent nodes respectively, where $N$ is the order of the graph. 

Let the latent representation of a particular node $v_i$ from the produced output representation of the encoder block be represented as $l_i=[l_{i_0}, l_{i_1}, \dots , l_{i_{L-1}}]$ where $L$ is the latent dimension. Before passing this vector to the decoder as input, its inverse distance vector $d_{i}^{-1}$ is concatenated with it, where $d_i=[d_{i0}, d_{i1}, \dots , d_{i(N-1)}]$ and $d_{ij}$ is the distance between $v_i$ and $v_j$ . Let the new latent feature for $v_i$ be $l_i^{new}=\left[ l_i,d_i^{-1} \right]$. The inverse distance vector gives the local structural information of a node. Furthermore, $F_{malicious}$ and $F_{benevolent}$ are available as node features. It is given to the decoder since distance between nodes does not change throughout the process; otherwise it could be given to the encoder. Additionally, to incorporate self-information in the feature representation of that node, we introduce self-loops with distance 1 and the required resultant input matrix ($M$)  of size $(L+N)\times (L+N)$ is computed using equation \ref{eqn:iotmi}, and subsequently passed into the decoder for classifying $v_i$ as well as to classify the edges. It is to be noted that edge classification does not always need separate intermediate representation. For the IoT dataset, the node representations serve both the tasks of node classification and edge classification which reduces computational costs, unlike the Chemistry Reaction dataset where separate node and edge representations are needed. The inverse distance vector is used as connectedness vector where 0 signifies no connection and 1 signifies the node itself, rest of the values lie between 0 and 1. 
%In equation (\ref{node_feature}) 
$F_{malicious}$ and $F_{benevolent}$ are taken as $N$ dimensional to give same importance to the features as the structural information.
\begin{comment}
\tiny 
\begin{gather}
M_i = \begin{bmatrix}
l_{i,0}*l_{i,0} & \dots & l_{i,0}*l_{i,L-1} & \frac{l_{i,0}}{d_{i,0}} & \dots & \frac{l_{i,0}}{d_{i,i-1}} & l_{i,0} & \frac{l_{i,0}}{d_{i,i+1}} & \dots & \frac{l_{i,0}}{d_{i,N-1}}\\
l_{i,1}*l_{i,0} & \dots & l_{i,1}*l_{i,L-1} & \frac{l_{i,1}}{d_{i,0}} & \dots & \frac{l_{i,1}}{d_{i,i-1}} & l_{i,1} & \frac{l_{i,1}}{d_{i,i+1}} & \dots & \frac{l_{i,1}}{d_{i,N-1}}\\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots\\
l_{i,L-1}*l_{i,0} & \dots & l_{i,L-1}*l_{i,L-1} & \frac{l_{i,L-1}}{d_{i,0}} & \dots & \frac{l_{i,L-1}}{d_{i,i-1}} & l_{i,L-1} & \frac{l_{i,L-1}}{d_{i,i+1}} & \dots & \frac{l_{i,L-1}}{d_{i,N-1}}\\
\frac{l_{i,0}}{d_{i,0}} & \dots & \frac{l_{i,L-1}}{d_{i,0}} & \frac{1}{d_{i,0}*d_{i,0}} & \dots & \frac{1}{d_{i,0}*d_{i,i-1}} & \frac{1}{d_{i,0}} & \frac{1}{d_{i,0}*d_{i,i+1}} & \dots & \frac{1}{d_{i,0}*d_{i,N-1}}\\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots\\
l_{i,0} & \dots & l_{i,L-1} & \frac{1}{d_{i,0}} & \dots & \frac{1}{d_{i,i-1}} & 1 & \frac{1}{d_{i,i+1}} & \dots & \frac{1}{d_{i,N-1}}\\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots\\
\frac{l_{i,0}}{d_{i,N-1}} & \dots & \frac{l_{i,L-1}}{d_{i,N-1}} & \frac{1}{d_{i,N-1}*d_{i,0}} & \dots & \frac{1}{d_{i,N-1}*d_{i,i-1}} & \frac{1}{d_{i,N-1}} & \frac{1}{d_{i,N-1}*d_{i,i+1}} & \dots & \frac{1}{d_{i,N-1}*d_{i,N-1}}
\end{bmatrix}
\end{gather}
\normalsize
\end{comment}


\begin{equation}
\begin{split}
M_i &= \left(l_i^{new}\right)^T \times l_i^{new}
=\left[ l_i,d_i^{-1} \right]^T \times \left[ l_i,d_i^{-1} \right]\\
&=\begin{bmatrix}
l_i^T \times l_i & l_i^T \times d_i^{-1}\\
\left(d_i^{-1}\right)^T \times l_i & \left(d_i^{-1}\right)^T \times d_i^{-1}
\end{bmatrix}
\end{split}
\label{eqn:iotmi}
\end{equation}

% \vspace*{-\baselineskip}
% \begin{equation}
% M_i = \left(l_i^{new}\right)^T \times l_i^{new} = \left[ l_i,d_i^{-1} \right]^T \times \left[ l_i,d_i^{-1} \right] = \begin{bmatrix} l_i^T \times l_i & l_i^T \times d_i^{-1} \\ \left(d_i^{-1}\right)^T \times l_i & \left(d_i^{-1}\right)^T \times d_i^{-1} \end{bmatrix}
% \label{eqn:iotmi}
% \end{equation}


%\vspace*{-\baselineskip}

For each subset (with graph order of 20, 40 and 60) of the IOT dataset, %(cf. Section \ref{dataset} Para \ref{data:iot})
50 data points (i.e., graph-pairs) are used as training set with batch size 1 and learning rate 0.005, and the rest (293 graph-pairs) is used as the test set. 
\begin{comment}
Table \ref{tab:IoT_PRF} presents the performance of our proposed model (in terms of precision, recall, f1-score and accuracy) on the node classification and edge classification tasks on each subset of the IoT dataset.
\end{comment}
% For each subset of the dataset (graph size 20, 40, 60), 50 graph-pairs are used as training set with batch size 1 and learning rate 0.005, and the rest (293 graph-pairs) is used as the test set. 

\input{Latex/Tabledef/iot_res_cmp_tab}

Table~\ref{tab:IoT_compare}\footnote{Best results are shown in bold-faced in this table and all other result tables.} presents performance comparison (in terms of accuracy) between our proposed framework and other novel baselines and SOTA models on the IOT dataset. We can observe that our proposed framework outperforms the baselines and produces SOTA performance on the IoT-40 and IoT-60 datasets for both node classification and edge classification tasks. For the IoT-20 dataset, our model yields SOTA results on the edge classification task and produces comparable performance on the node classification task. Our model performs better as the order of the graphs increases. However , for smaller graphs with more training data and bigger batch size, it can perform better (e.g., With 160 graph-pairs as training set, batch size 16,183 graph-pairs as test set and LR 0.005, our model yields SOTA result for the node classification task on thee IoT-20 dataset with Node-Acc. 0.93).




 % The malware confinement task on the IoT dataset a2 sub-tasks -- (i) predicting the infection states of the nodes (interconnected devices), followed by (ii) restructuring the edges (connections between devices).

  % Table \ref{tab:IoT_compare} compares our model's performance (in terms of accuracy) on the IOT dataset to other well known methods. 

   % \textcolor{magenta}{(With 160 graph-pairs as training set, batch size 16, 183 graph-pairs as test set and LR 0.005, our model yields SOTA result on node classification task for IoT-20 dataset with Node-Acc. 0.93)}.