Knowledge Graph (KG) Completion is a fundamental problem in the field of artificial intelligence and natural language processing. It involves predicting missing relationships or facts in a KG, which is a structured representation of information as interconnected nodes and edges.  

For the experiment on the YAGO dataset, 1,079,040 relations (directed edges between entity-pairs) were used as the training set with sample-size 370 (10 samples from each type of relation) per epoch with an LR of 0.005, and 10,000 edges were used as the test set. For initializing the node features, following steps are used for each entity $e$.
\begin{enumerate}
\item A 37 dimensional vector $L_e$ named ``Left-Entity-One-Hot" is created in such a way that,

\vspace*{-\baselineskip}
\[
    L_e[i]= 
\begin{cases}
    1,              & \text{if } \exists \text{ relation } r_i \text{ and entity } k \text{ so that,}\\
    & \text{relationship triplet }(e,r_i,k) \in \text{training set}\\
    0,              & \text{otherwise}
\end{cases}
\]
%\vspace*{-\baselineskip}
\item A 37 dimensional vector $R_e$ named ``Right-Entity-One-Hot" is created in such a way that,
%\vspace*{-\baselineskip}
\[
    R_e[i]= 
\begin{cases}
    1,              & \text{if } \exists \text{ relation } r_i \text{ and entity } k \text{ so that,}\\
    & \text{relationship triplet }(k,r_i,e) \in \text{training set}\\
    0,              & \text{otherwise}
\end{cases}
\]
%\vspace*{-\baselineskip}
\item Concatenate $L_e$, $R_e$, and a 20 dimensional random vector whose values lie between 0 and -1 making the initial node features of size 94.
\end{enumerate}
Table \ref{tab:YAGO_compare} compares the performance of our model on the YAGO dataset in terms of edge accuracy or HITS@1 to other well-known methods. Table \ref{tab:YAGO_compare} shows that our model outperforms the existing models by large margins and produces SOTA results in the knowledge graph completion task on the YAGO dataset.