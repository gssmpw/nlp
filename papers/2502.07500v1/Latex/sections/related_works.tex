% \citet{sun2019graph} proposed a graphRNN based model which generates a graph’s topology based on another graph.  Edge2vec takes both the local and the global structure information of edges into consideration to preserve structure information of embedded edges as much as possible. To achieve this goal, edge2vec ingeniously combines the deep autoencoder and Skip-gram model through a well-designed deep neural network.Examples of statistical inference-based community detection methods include the works by \citet{come2015model} and \citet{newman2016estimating}.

Since our work mainly investigates deep metric learning based graph analysis tasks, we first discuss about the SOTA techniques available in graph learning literature. Later, we differentiate our proposed framework from the existing ones.

\citet{guo2019deep} proposed a generic, end-to-end framework for joint node and edge attributes prediction, which is a need for real world applications such as malware confinement in IoT networks and structural-to-functional network translation. \citet{bruna2014spectral} first introduced the spectral graph convolutional neural networks, and then it was extended by \citet{defferrard2016convolutional} using fast localized convolutions, which is further approximated by~\citet{DBLP:conf/iclr/KipfW17} for an efficient architecture in a semi-supervised setting. \citet{li2018diffusion} proposed a Diffusion Convolution Recurrent Neural Network (DCRNN) for traffic forecasting which incorporates both spatial and temporal dependency in the traffic flow. \citet{Yu2018SpatioTemporalGC} formulated the node attributes prediction problem of graphs based on the complete convolution structures. \citet{9737289} addressed graph topology translation using a generative model with graph convolution, deconvolution layers, and a novel conditional graph discriminator. \citet{wang2020edge2vec} proposed edge-based graph embedding (edge2vec) to map the edges in social networks directly to low-dimensional vectors by preserving the necessary topological properties of networks. Additionally, \citet{perozzi2014deepwalk} proposed DeepWalk by utilizing the truncated random walks to obtain the node level information. Later on, Node2vec algorithm was proposed by \citet{grover2016node2vec} to improve the DeepWalk by replacing the truncated random walks with a combination of Breadth First Search (BFS) and Depth First Search (DFS) algorithms. Another direction of this work is that \citet{tang2015line} proposed LINE to represent the contextual representation of the nodes present in a Graph, while \citet{cao2015grarep} extended it with GraRep to include indirect neighbors, facing issues with embedding vector length. Discriminative Deep Random Walk (DDRW)~\cite{li2016discriminative} and max-margin DeepWalk (MMDW)~\cite{tu2016max}, respectively, optimize classifier and embedding jointly. Additionally, RSDNE~\cite{wang2018rsdne} produced a comparable performance in both general and zero-shot scenario where graph embedding by ensures the intra-class similarity and inter-class dissimilarity. The works by \citet{newman2006finding} and \citet{newman2013spectral} serve as examples of spectral methods. Statistical inference based approaches typically employed conventional methods to fit data to a generative network model. A commonly used generative model for  network communities is the Stochastic Block Model (SBM). \citet{clauset2005finding} and~\citet{lancichinetti2011limits} utilizes modularity based optimization technique for community detection task whereas \citet{reichardt2006statistical}, and \citet{rosvall2008maps} utilizes random walks, diffusion based algorithm to preserve the community structure.

% \citet{waskiewicz2012friend} divided the static community detection methods into four broad categories such as spectral methods, methods based on statistical inference, methods based on optimization and methods based on dynamics. Spectral methods utilized spectral properties such as eigen value spectrum of the matrix representations (e.g., adjacency matrix, Laplacian matrix, modularity matrix etc.) of networks to detect communities. The works of \citet{newman2006finding} and \citet{newman2013spectral} serve as examples of spectral methods. Approaches based on statistical inference typically employ conventional methods to fit data to a generative network model. A commonly used generative model with communities for networks is the Stochastic Block Model (SBM). Examples of statistical inference-based community detection methods include the works of \citet{come2015model} and \citet{newman2016estimating}.

% Optimization based methods try to find out a maximum or minimum quality function that shows the quality of community structure. Most popular quality function is modularity.


% Widely used modularity~\cite{newman2004finding} based approach is a concept depending on the maximization of difference between actual network and another form of actual network that have randomly destroyed community structure. The methods proposed by~\citet{clauset2005finding} and~\citet{lancichinetti2011limits} can be  as examples of methods based on optimization. Methods based on dynamics uses running dynamics of the networks like diffusion, random walk and spin dynamics to detect community structure in a network. The works of \citet{reichardt2006statistical}, and \citet{rosvall2008maps} can be given as examples for methods based on dynamics.

\begin{comment}
\textcolor{magenta}{The matrix completion problem has been studied using GNNs. \citet{monti2017geometric} developed a multi-graph CNN (MGCNN) model to extract user and item latent features from their respective nearest-neighbor networks. \citet{berg2017graph} proposed graph convolutional matrix completion (GC-MC) which directly applies a GNN to the user-item bipartite graph to extract user and item latent features using a GNN. Although using GNNs for matrix completion, all these models are still transductive – MGCNN requires graph Laplacians which do not generalize to new graphs, while GC-MC uses one-hot encoding of node IDs as initial node features, thus cannot generalize to unseen users/items. A recent inductive graph-based recommender system, PinSage (\citet{ying2018graph}), uses node content as initial node features (instead of the one-hot encoding in GC-MC), and is successfully used in recommending related pins in Pinterest. \citet{zhanginductive} proposed an Inductive Graph-based Matrix Completion (IGMC) model which trains a graph neural network (GNN) based purely on 1-hop subgraphs around (user, item) pairs generated from the rating matrix and maps those subgraphs to their corresponding ratings.}
\end{comment}

Additionally, knowledge graph embedding is an active research area with many different methodologies. This task can be categorized based on the interaction mechanisms and the computational matching score. Tensor-decomposition-based models adapt tensor representations in CP format, Tucker format, and block term format to represent the knowledge graph data~\citep{kolda2009tensor} by proposing SOTA models such as ComplEx~\citep{trouillon2016complex}, SimplE~\citep{kazemi2018simple}, TuckER (\citep{balavzevic2019tucker}), and MEIM (\citet{DBLP:conf/ijcai/TranT22}). They often achieve good trade-off between efficiency and expressiveness. Recently, ConvE~\citep{dettmers2018convolutional}, CompGCN~\citep{vashishthcomposition} have been investigated by utilizing the neural network to embed the knowledge graph data. Translation-based models use geometrical distance to compute the matching score, with relation embeddings such as TransE (\citet{bordes2013translating}).  There are several ways to use orthogonality in knowledge graph embedding, such as RotatE (\citet{sunrotate}) using complex product, Quaternion (\citet{tran2019analyzing}) and QuatE (\citet{zhang2019quaternion}) using quaternion product, GCOTE (\citet{tang2020orthogonal}) using the Gram Schmidt process, and RotH (\citet{chami2020low}) using the Givens matrix.

% Neural-network-based models use a neural network to compute the matching score, such as ConvE (\citet{dettmers2018convolutional}) using convolutional neural networks, CompGCN (\citet{vashishthcomposition}) using graph convolutional networks. These models are generally more expensive but not always get better results than tensor-decomposition-based models. Translation-based models use geometrical distance to compute the matching score, with relation embeddings act as the translation vectors, such as TransE (\citet{bordes2013translating}). These models are efficient and intuitive, but they have limitations in expressive power (\citet{kazemi2018simple}). There are several ways to use orthogonality in knowledge graph embedding, such as RotatE (\citet{sunrotate}) using complex product, Quaternion (\citet{tran2019analyzing}) and QuatE (\citet{zhang2019quaternion}) using quaternion product, GCOTE (\citet{tang2020orthogonal}) using the Gram Schmidt process, and RotH (\citet{chami2020low}) using the Givens matrix.

Our model is unique in terms of scalability and genericness:
% \textcolor{magenta}{
%\begin{enumerate}
%\item 
(i) We experimented with smaller graphs containing 20-60 nodes as well as large graphs containing 20K-80K nodes using the same model architecture and obtained SOTA or near-SOTA results in both cases.
%\\
%\item 
(ii) Our model can smoothly transit from supervised learning domain to semi-supervised learning domain only by adding an extra component in the loss function, keeping the model architecture same. We applied our model for supervised tasks where number of known labels of nodes or edges in the training set is much larger or at least similar to the test set, and semi-supervised tasks where number of known labels in the training set is much less than the test set, producing SOTA or near-SOTA results for both the tasks.
%\end{enumerate}
% }