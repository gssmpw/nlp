

\section{Introduction}
\label{sec:introduction}


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.80\textwidth]{fig/ASAP-Motion-Processing-crop.pdf}
    \vspace{-3mm}
    \caption{Retargeting Human Video Motions to Robot Motions: (a) Human motions are captured from video. (b) Using TRAM~\cite{wang2025tram}, 3D human motion is reconstructed in the SMPL parameter format. (c) A reinforcement learning (RL) policy is trained in simulation to track the SMPL motion. (d) The learned SMPL motion is retargeted to the Unitree G1 humanoid robot in simulation. (e) The trained RL policy is deployed on the real robot, executing the final motion in the physical world. This pipeline ensures the retargeted motions remain physically feasible and suitable for real-world deployment.}
    \vspace{-3mm}
    \label{fig:data_processing}
\end{figure*}

For decades, we have envisioned humanoid robots achieving or even surpassing human-level agility. However, most prior work~\cite{li2023robust,radosavovic2024real,li2024reinforcement,radosavovic2402humanoid,zhuang2024humanoid,gu2024advancing,Wolf2025AIHumanoid,long2024learning} has primarily focused on locomotion, treating the legs as a means of mobility. Recent studies~\cite{cheng2024expressive,he2024learning,he2024omnih2o,he2024hover,ji2024exbody2} have introduced whole-body expressiveness in humanoid robots, but these efforts have primarily focused on upper-body motions and have yet to achieve the agility seen in human movement. Achieving agile, whole-body skills in humanoid robots remains a fundamental challenge due to not only hardware limits but also the mismatch between simulated dynamics and real-world physics.

Three main approaches have emerged to bridge the dynamics mismatch: System Identification (SysID) methods, domain randomization (DR), and learned dynamics methods. SysID methods directly estimate critical physical parameters, such as motor response characteristics, the mass of each robot link, and terrain properties~\cite{yu2019sim, gu2024advancing}. However, these methods require a pre-defined parameter space~\cite{ljung1998system}, which may not fully capture the sim-to-real gap, especially when real-world dynamics fall outside the modeled distribution. SysID also often relies on ground truth torque measurements~\cite{hwangbo2019learning}, which are unavailable on many widely used hardware platforms, limiting its practical applicability.
DR methods, in contrast, first train control policies in simulation before deploying them on real-world hardwares~\cite{tan2018sim, rudin2022learning, margolis2022rapid}. To mitigate the dynamics mismatch between simulation and real-world physics, DR methods rely on randomizing simulation parameters~\cite{tobin2017domain,peng2018sim}; but this can lead to overly conservative policies~\cite{he2024learning}, ultimately hindering the development of highly agile skills. Another approach to bridge dynamics mismatch is learning a dynamics model of real-world physics using real-world data. While this approach has demonstrated success in low-dimensional systems such as drones~\cite{shi2019neural} and ground vehicles~\cite{xiao2024anycar}, its effectiveness for humanoid robots remains unexplored.






To this end, we propose \method, a two-stage framework that aligns the dynamics mismatch between simulation and real-world physics, enabling agile humanoid whole-body skills. \method involves a pre-training stage where we train base policies in simulation and a post-training stage that finetunes the policy by aligning simulation and real-world dynamics. 
In the \textbf{pre-training} stage, we train a motion tracking policy in simulation using human motion videos as data sources. These motions are first retargeted to humanoid robots~\cite{he2024learning}, and a phase-conditioned motion tracking policy~\cite{peng2018deepmimic} is trained to follow the retargeted movements. However, directly deploying this policy on real hardware results in degraded performance due to the dynamics mismatch.
To address this, the \textbf{post-training} stage collects real-world rollout data, including proprioceptive states and positions recorded by the motion capture system.
The collected data are then replayed in simulation, where the dynamics mismatch manifests as tracking errors. We then train a delta action model that learns to compensate for these discrepancies by minimizing the difference between real-world and simulated states. This model effectively serves as a residual correction term for the dynamics gap. Finally, we fine-tune the pre-trained policy using the delta action model, allowing it to adapt effectively to real-world physics.



We validate \method on diverse agile motions and successfully achieve whole-body agility on the Unitree G1 humanoid robot~\cite{Unitree2024G1}. Our approach significantly reduces motion tracking error compared to prior SysID, DR, and delta dynamics learning baselines in both sim-to-sim (IsaacGym to IsaacSim, IsaacGym to Genesis) and \simtoreal (IsaacGym to Real) transfer scenarios.
Our contributions are summarized below.
\begin{enumerate}
    \item We introduce \method, a framework that bridges the \simtoreal gap by leveraging a delta action model trained via reinforcement learning (RL) with real-world data.
    \item We successfully deploy RL-based whole-body control policies in the real world, achieving previously difficult-to-achieve humanoid motions.
    \item Extensive experiments in both simulation and real-world settings demonstrate that \method effectively reduces dynamics mismatch, enabling highly agile motions on robots and significantly reducing motion tracking errors.
    \item To facilitate smooth transfer between simulators, we develop and open-source a multi-simulator training and evaluation codebase for help accelerate further research.
\end{enumerate}
