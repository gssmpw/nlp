\section{Storyline}

\jiawei{Some phrases I will use:
\begin{itemize}
    \item Dynamics mismatch
    \item Pre-training?(For first-phase deepmimic training)
    \item Post-training?(For second-phase delta A training)
    \item Whole-body skills, Whole-body coordination, whole-body expressiveness
    \item Expressive and agile
\end{itemize}}

\jiawei{Intro}

\begin{enumerate}
    \item Humaoid robots receive attention, because general-purpose, and ``human-like" skills, which makes humanoid stands out.
    \item However, these skills are often limited to locomotion, quasi-static loco-manipulation, and table-top manipulation, lacking agile whole-body skills.
    \item In comparison, in humanoid character control community people have done impressive whole-body skills. The gap is the \textbf{dynamics mismatch} between simulation and real world physics.
    \item Exisiting methods solve it by system identification or sim2real RL. Sysid limitation: laborsome, not scalable; sim2real: over-conservative, can not be too agile.
    \item Key idea: learning residual actions to compensate the sim2real dynamics mismatch.
    \item Our methods achieve this by a two stage framework. First stage: learning motion trakcing policy; Second stage: align physics in sim and real. Collect data, replay, train motion tracking.
    \item We tested our framework on ...
    \item Contribution bullets 1) We propose \method, a two-stage framework that aligns sim and real dynamics by learning residual policy. 2) We show that, through our methods, our policy can achieve super agile skills. 3) Extensive results in simulation and real-world experiment demonstrate that our methods can reduce tracking error.
\end{enumerate}

\jiawei{Related works}

\begin{enumerate}
    \item Learning-based whole body control for humanoid
    \begin{itemize}
        \item Lot of humanoid works recently.
        \item Character animation community achieves more impressive demos.
        \item The gap: dynamics mismatch, which our work aim to adress.
    \end{itemize}
    
    \item System Identification \jiawei{Old version, not precise in my opinion}
    \begin{enumerate}
        \item Explicit Parameter Identification: Using real world performance to calibrate physics parameters, like mass, friction, inertia, and characterastic of motors(Yuxiang's works).
        \item Implicit robot state online sysid: RMA, DATT, history encoder kinds of things.
        \item Our work: A general framework for learning dynamics mismatch.
    \end{enumerate}
    \item Offline and Online System Identification methods
    \begin{enumerate}
        \item Offline: Using pre-collected data, calibrate simulators and robot models
        \item Online: RMA, DATT, history-encoder
        \item Ours: A general framework that combines offline and online sysid(Offline: Collecting data and train delta a, and enable the policy to do online system identification with delta A.)
    \end{enumerate}
    \item Residual Learning for Robotics
    \begin{enumerate}
        \item Residual Policy Learning
        \item Residual Dynamics Learning
        \item Ours: residual policy learning as dynamics?
    \end{enumerate}
\end{enumerate}


\jiawei{Methods1: Learning Motion Tracking Policy}

\begin{enumerate}
    \item Motion Retarget from human to humanoid
    \item Training motion tracking policy
    \item Designs for Sim2Real
        \item A2C
        \item Reward Curriculum
        \item Termination Curriculum
\end{enumerate}

\jiawei{Methods2: Learning Residual Action}

\begin{enumerate}
    \item Rollout pre-trained policy in another simulator / real-world, and record data
    \item Replay data in original environment, and the tracking error represents the dynamics mismatch. Therefore, minimizing the tracking error results in compensating dynamics mismatch.
    \item Training Delta Action to minimizing the tracking error.
    \item Different recipes for training Delta A
        \item Open loop vs Close Loop
        \item Horizons
        \item Regularization
\end{enumerate}

\jiawei{Experiments}

\begin{itemize}
    \item \textbf{Q1}: Can \method outperform other baseline methods(SysID, Domain Randomization) when learning to match multiple simulators dynamics? 
    \item \textbf{Q2}: Can \method learn to match real physics when deployed on real humanoid robots?
    \item \textbf{Q3}: What is the best recipe for training \method?
    \item \textbf{Q4}: Why does \method works? (Some visualization / analysis)
\end{itemize}