\section{Empirical Evaluation}
\label{sec:exper}

In order to assess the approximation performance of \emph{SVA}$k_{\text{ADD}}$, we conduct experiments with cooperative games stemming from various explanation types.
Although our method is not limited to a certain domain, we find the field of explainability best to illustrate its effectiveness.
We consider several real datasets as well as different tasks.
The evaluation of our proposal is mainly two-fold.
Not only are we interested in the comparison of \emph{SVA}$k_{\text{ADD}}$ against current state-of-the-art model-agnostic methods in \cref{subsec:degree}, but we also seek to investigate how the choice of the assumed degree of additivity $k$ affects the approximation quality (see \cref{subsec:performance}).
In the sequel of \cref{subsec:datasets}, we describe the utilized datasets and resulting cooperative games.

For each considered combination of dataset, approximation algorithm, and number of value function evaluations $T$, the obtained estimates $\hat\phi$ are compared with the Shapley values $\phi$ which we calculate exhaustively in advance.
We measure approximation quality of the estimates by the mean squared error (MSE).
The error is measured depending on $T$ as we intentionally refrain from a runtime comparison for multiple reasons:
(i) the observed runtimes may differ depending on the actual implementation,
(ii) evaluating the worth of a coalition poses the bottleneck in explanation tasks, rendering the difference in performed arithmetic operations negligible for more complex models and datasets,
(iii) instead of runtime, monetary units might be paid for each access to a remotely provided model offered by a third-party.

\begin{figure*}[ht]
\centering
\begin{minipage}[c]{0.32\textwidth}
   \centering
   \includegraphics[width=0.99\textwidth]{plots/fig_diabetes_kadd.pdf}
   (a) Diabetes dataset ($n=10$)
   \label{fig:diabetes_kadd}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_titanic_kadd.pdf}
    (b) Titanic dataset ($n=11$)
    \label{fig:titanic_kadd}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_wine_kadd.pdf}
    (c) Wine dataset ($n=13$)
    \label{fig:wine_kadd}
\end{minipage}
%
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_adult_local_kadd.pdf}
    (d) Adult dataset ($n=14$)
    \label{fig:adult_local_kadd}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
   \centering
   \includegraphics[width=0.99\textwidth]{plots/fig_image_cat_kadd.pdf}
   (e) ImageNet dataset ($n=14$)
   \label{fig:image_cat_kadd}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_sentiment_kadd.pdf}
    (f) IMDB dataset ($n=14$)
    \label{fig:sentiment_kadd}
\end{minipage}
%
\begin{minipage}[c]{0.32\textwidth}
   \centering
   \includegraphics[width=0.99\textwidth]{plots/fig_breastcancer_kadd.pdf}
   (g) Breast Cancer dataset ($n=9$)
   \label{fig:breastcancer_kadd}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_bigfive_kadd.pdf}
    (h) Big Five dataset ($n=12$)
    \label{fig:bigfive_kadd}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_fifa_kadd.pdf}
    (i) FIFA dataset ($n=12$)
    \label{fig:fifa_kadd}
\end{minipage}
\caption{
MSE of \emph{SVA}$k_{\text{ADD}}$ averaged over 100 repetitions in dependence of available budget $T$ for different additivity degrees $k$.
Datasets stem from various explanation types: global (a)-(c), local (d)-(f), and unsupervised (g)-(i) with differing player numbers $n$.
}
\label{fig:proposal_results}
\end{figure*}

\subsection{Datasets}
\label{subsec:datasets}

We distinguish between three feature explanation tasks: global importance, local attribution, and unsupervised importance being described further in \cref{app:cooperative_games}.

Within global feature importance \citep{Covert.2020} the features' contributions to a model's generalization performance are quantified.
This is done by means of accuracy for classification and the mean squared error for regression on a test set.
For each evaluated coalition a random forest is retrained on a training set.
We employ the \emph{Diabetes} (regression, 10 features), \emph{Titanic} (classification, 11 features), and \emph{Wine} dataset (classification, 13 features).

On the contrary, local feature attribution \citep{Lundberg.2017} measures each feature's impact on the prediction of a fixed model for a given datapoint.
While the predicted value can directly be used as the worth of a feature coalition for regression, the predicted class probability is required instead of a label for classification. Rendering a feature outside of an evaluated coalition absent is performed by means of imputation that blurs the features contained information.
The experiments are conducted on the \emph{Adult} (classification, 14 features), \emph{ImageNet} (classification, 14 features), and \emph{IMDB} natural language sentiment (regression, 14 features) data.

\begin{figure*}[ht]
\centering
\begin{minipage}[c]{0.32\textwidth}
   \centering
   \includegraphics[width=0.99\textwidth]{plots/fig_diabetes_kadd_comp.pdf}
   (a) Diabetes dataset ($n=10$)
   \label{fig:diabetes_kadd_comp}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_titanic_kadd_comp.pdf}
    (b) Titanic dataset ($n=11$)
    \label{fig:titanic_kadd_comp}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_wine_kadd_comp.pdf}
    (c) Wine dataset ($n=13$)
    \label{fig:wine_kadd_comp}
\end{minipage}
%
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_adult_local_kadd_comp.pdf}
    (d) Adult dataset ($n=14$)
    \label{fig:adult_local_kadd_comp}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
   \centering
   \includegraphics[width=0.99\textwidth]{plots/fig_image_cat_kadd_comp.pdf}
   (e) ImageNet dataset ($n=14$)
   \label{fig:image_cat_kadd_comp}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_sentiment_kadd_comp.pdf}
    (f) IMDB dataset ($n=14$)
    \label{fig:sentiment_kadd_comp}
\end{minipage}
%
\begin{minipage}[c]{0.32\textwidth}
   \centering
   \includegraphics[width=0.99\textwidth]{plots/fig_breastcancer_kadd_comp.pdf}
   (g) Breast Cancer dataset ($n=9$)
   \label{fig:breastcancer_kadd_comp}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_bigfive_kadd_comp.pdf}
    (h) Big Five dataset ($n=12$)
    \label{fig:bigfive_kadd_comp}
\end{minipage}
\begin{minipage}[c]{0.32\textwidth}
    \centering
    \includegraphics[width=0.99\textwidth]{plots/fig_fifa_kadd_comp.pdf}
    (i) FIFA dataset ($n=12$)
    \label{fig:fifa_kadd_comp}
\end{minipage}
\caption{
MSE of \emph{SVA}$k_{\text{ADD}}$ and competing methods averaged over 100 repetitions in dependence of available budget $T$.
Datasets stem from various explanation types: global (a)-(c), local (d)-(f), and unsupervised (g)-(i) with differing player numbers $n$.
}
\label{fig:results_comp}
\end{figure*}

In the absence of labels, unsupervised feature importance \citep{Balestra.2022} seeks to find scores without a model's predictions.
This is achieved by employing the total correlation of a feature subset as its worth, since the datapoints can be seen as realizations of the joint feature value distribution.
For this task, we consider the \emph{Breast cancer} (9 features), \emph{Big Five} (12 features), and \emph{FIFA 21} (12 features) datasets.

\subsection{Impact of the Additivity Degree $k$}
\label{subsec:degree}

In order to provide an understanding of the underlying trade-off between fast convergence (low $k$) and expressiveness (high $k$) of the surrogate game and how the crucial choice of $k$ affects the approximation quality, we evaluate \emph{SVA}$k_{\text{ADD}}$ for different $k$ (i.e., for different $k$-additive models).

Figure~\ref{fig:proposal_results} presents the obtained results for all datasets and for $k \in \left\{1,2,3,4 \right\}$.
Note that the curves for higher $k$ begin at points of higher budget because the greater $k$, the more coalition values are required to identify a unique $k$-additive value function that fits the observations.
We explain the behavior for low $k$, specifically $k=1$, by the model's inability to achieve a good fit due to missing flexibility.
As a result, the convergence to the exact Shapley values is slow.
A similar observation can be made for the 2-additive model in both global and local tasks.
Although in FIFA dataset the 2-additive model rapidly converges to the exact Shapley values, for the other ones a higher number of samples are needed until convergence.
These findings imply that interactions up to order 2 are not sufficient to model how features jointly impact performance (global task) or prediction outcome (local task).
On the other hand, both the 3-additive and 4-additive model converge significantly faster for most datasets and outperform the parmeterization with $k=1$ or $k=2$ after a few samples.
By comparing $k=3$ and $k=4$ variants, the choice of $k=3$ appears preferable as it results in quicker decreasing error curves. 

\subsection{Comparison with Existing Approximation Methods}
\label{subsec:performance}

In our second experiment, we compare \emph{SVA}$k_{\text{ADD}}$ with other existing approximation methods.
For instance, we consider \emph{Stratified sampling} \cite{Maleki.2013}, \emph{Stratified SVARM} \cite{Kolpaczki.2024a} and \emph{KernelSHAP} \citep{Lundberg.2017}.
For the purpose of comparison, we adopt the $3$-additive model to represent \emph{SVA}$k_{\text{ADD}}$ since it displays the most satisfying compromise between approximation quality and minimum required evaluations as argued in \cref{subsec:degree}.
Figure~\ref{fig:results_comp} presents the obtained results for all methods.
See \cref{app:further_results} for results including \emph{Permutation sampling} \cite{Castro.2009} and the $2$-additive model.

First to mention is that \emph{SVA}$k_{\text{ADD}}$ competes consistently with Stratified SVARM for the best approximation performance across most datasets.
Although for a very low number of function evaluations \emph{SVA}$k_{\text{ADD}}$ achieves an error greater than some other approaches (specially \emph{Stratified SVARM}), at some point during the approximation process it converges faster to the exact Shapley values and leaves it competitors with a considerable margin behind, especially for local feature attribution.
The comparison with \emph{KernelSHAP} provides mixed results. 
For Adult, Big Five and FIFA datasets, \emph{SVA}$k_{\text{ADD}}$ converged faster to the exact Shaley values whereas for Titanic and IMDB datasets, \emph{KernelSHAP} achieves a better performance.
