\section{The Shapley Value and $k$-Additivity}
\label{sec:theory}

We formally introduce cooperative games and the Shapley value in \cref{subsec:games_shapley}.
Next, we present in \cref{subsec:k_additivity} the concept of $k$-additivity, constituting the core of our approach.

\subsection{Cooperative Games and the Shapley Value}
\label{subsec:games_shapley}

A cooperative game is formally described by $n$ players, captured by the set $N = \{1,\ldots,n\}$, and an associated payoff function $\nu : \mathcal{P}(N) \to \mathbb{R}$, where $\mathcal{P}(N)$ represents the power set of $N$.
This simple but expressive formalism may for example represent a shipment coordination where companies form a coalition in order to save costs when delivering their products.
In this case, the companies can be modeled as players
and $\nu(A)$ represents the benefit achieved by the group of companies $A \subseteq N$. %when joint the coalition.
Clearly, $\nu(N)$ is the total benefit when all companies (players) form the grand coalition $N$. Commonly, one normalizes the game by defining $\nu(\emptyset) = 0$, i.e., the worth of the empty set.
However, in explainability, $\nu(\emptyset)$ may take nonzero values, e.g., with no features available one may obtain a classification accuracy of 50\%.
In this case, one can normalize $\nu$ by simply subtracting the worth of the empty set from all game payoffs, i.e., $\nu'(A) \leftarrow \nu(A) - \nu(\emptyset)$ for all $A \subseteq N$.
 
A central question arising from a cooperative game is how to fairly share the worth $\nu(N)$ of the grand coalition $N$ among all participating players.
The Shapley value \citep{Shapley.1953} emerges as the prevalent solution concept since it uniquely satisfies axioms that intuitively capture fairness \citep{Shapley.1953}.
Given the game $(N, \nu)$, the Shapley value of each player $i$ is defined as
\begin{equation}
    \label{eq:shapley}
    \phi_i = \sum\limits_{A \subseteq N \setminus \{i\}} \frac{\left(n - \left| A \right| - 1 \right)\left| A \right|!}{n!} [\nu(A \cup \{i\}) - \nu(A)] \, ,
\end{equation}
where $\left| A \right|$ represents the cardinality of coalition $A$.
It can be interpreted as a player's weighted average of marginal contributions to the payoff.
Among the fulfilled axioms such as null player, symmetry, and additivity (see~\citep{Young1985} for more details and other properties), in explainability the most useful is efficiency.
It demands that the sum of all players' Shapley values is equal to the difference between $\nu(N)$ and $\nu(\emptyset)$.
Mathematically, efficiency means
\begin{equation}
    \label{eq:effic}
    \sum_{i=1}^n \phi_i = \nu(N) - \nu(\emptyset) \, .
\end{equation}
Or, in the game theory framework where $\nu(\emptyset) = 0$, one obtains $\sum_{i=1}^n \phi_i = \nu(N)$.
In explainability, efficiency can be used to decompose a measure of interest among the set of features.
As a result, one can interpret the importance of each feature to that measure.

Unfortunately, satisfying the desired axioms in the form of the Shapley value comes at a price.
According to \cref{eq:shapley}, the calculation requires the evaluation of all $2^n$ coalitions within the exponentially growing power set of $N$.
In fact, the exact computation of the Shapley value is known to be NP-hard \citep{Deng.1994}.
Hence, its exact computation does not only become practically infeasible for growing player numbers but it is also of interest that the evaluation of only a few coalitions suffices to retrieve precise estimates.
For instance, a model has to be costly re-trained and re-evaluated on a test dataset for each coalition if one is interested in the features' impact on the generalization performance.
Therefore, a common goal is to approximate all Shapley values $\phi = (\phi_1,\ldots,\phi_n)$ of a given game $(N,\nu)$ by observing only a subset of evaluated coalitions $ \mathcal{M} \subseteq \mathcal{P}(N)$.
We denote the size of $\mathcal{M}$ by $T \in \mathbb{N}$ and refer to it as the available budget representing the number of samples an approximation algorithm is allowed to draw.
The mean squared error (MSE) serves as a popular measure to quantify the quality of the obtained estimates $\hat\phi = (\hat\phi_1,\ldots,\hat\phi_n)$ and is to be minimized:
\begin{equation}
    \label{eq:mse}
     \frac{1}{n} \sum\limits_{i=1}^n \mathbb{E} \left[ \left( \hat\phi_i - \phi_i \right)^2 \right] \, ,
\end{equation}
where the expectation is taken w.r.t.\ the (potential) randomness of the approximation strategy.

\subsection{Interaction Indices and $k$-Additivity}
\label{subsec:k_additivity}

The underlying idea of measuring the impact (or share) of a single player $i$ by means of its marginal contributions finds its natural extension to sets of players $S$ in the Shapley interaction index~\citep{Murofushi1993,Grabisch1997a} by generalizing from marginal contributions to discrete derivatives.
For any $S \subseteq N$ its Shapley interaction $I(S)$ is given by
\begin{equation}
\label{eq:inter_ind}
     I(S) = \sum_{A \subseteq N\backslash S} w_S \left( \sum_{A' \subseteq S} \left(-1\right)^{\left| S \right| - |A'|}\nu(A \cup A') \right)
\end{equation}
with weights $w_S = \frac{\left(n-\left|A\right|-\left|S\right|\right)!\left|A\right|!}{\left(n-\left|S\right|+1\right)!}$.
For convenience, we will write $I_i := I(\{i\})$ and $I_{i,j} := I(\{i,j\})$.
Instead of individual importance, $I(S)$ indicates the synergy between players in $S$.
Although this interpretation is not straightforward for coalitions of three or more entities, it has a clear meaning for pairs.
For two players $i$ and $j$, the Shapley interaction index $I_{i,j}$ quantifies how the presence of $i$ impacts the marginal contributions of $j$ and vice versa.
Especially~in explainable AI, where players represent features, it can be interpreted as follows:
%
\begin{itemize}
    \item If $ I_{i,j} < 0$, there is a negative interaction (redundant effect) between features $i$ and $j$.
    \item If $I_{i,j} > 0$, there is a positive interaction (complementary effect) between $i$ and $j$.
    \item If $I_{i,j} = 0$, there is no interaction between $i$ and $j$ (independence) on average.
\end{itemize}
%
Note that the Shapley interaction index reduces to the Shapley value for a singleton, i.e., $I_i = \phi_i$.
Moreover, there is a linear relation between the interactions and the game payoffs~\citep{Grabisch1997a}. Indeed, from the interactions one may easily retrieve the game payoffs by the following expression:
\begin{equation}
\label{eq:iitomu_s}
\nu(A) = \sum_{B \subseteq N} \gamma^{\left|B \right|}_{\left| A \cap B \right|}I(B) \, ,
\end{equation}
where $\gamma^{\left|B \right|}_{\left| A \cap B \right|}$ is defined by
\begin{equation*}
%\label{eq:gamma}
\gamma_{r}^{s} = \sum_{l=0}^{r}\binom{r}{l}\eta_{s-l}
\hspace{0.5cm} \text{and} \hspace{0.5cm}
\eta_{r} = -\sum_{l=0}^{r-1}\frac{\eta_{l}}{r-l+1}\binom{r}{l}
\end{equation*}
are the Bernoulli numbers starting with $\eta_0=1$.

This linear transformation recovers any coalition value $\nu(A)$ by using the Shapley interaction values of all $2^n$ coalitions, thus including the Shapley values.
Therefore, $2^n$ many parameters are to be defined if the whole game is to be expressed by Shapley interactions.
However, in some situations one may assume that interactions only exist for coalitions up to $k$ many players. This assumption leads to the concept known as $k$-additive games.
A $k$-additive game is such that $I(S) = 0$ for all $S$ with $\left| S \right| > k$.
Obviously, this restricts the flexibility of the game but depending on $k$, this may significantly decrease the number of parameters to be defined such that for low $k$ it increases only polynomially with the number of players. 
For instance, in $2$-additive and $3$-additive games, there are only $n(n+1)/2$, and $n(n^2+5)/6$ respectively, many interactions indices as the remaining parameters are equal to zero.
One may argue that within Shapley-based feature explanations, the neglection of higher order interactions, by setting them to zero per default, comes naturally.
For instance, \citet{Bordt.2023} show that these interactions barely exist in the context of post-hoc local explanations.