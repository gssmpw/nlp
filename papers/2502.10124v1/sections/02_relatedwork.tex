\section{Related work}
\label{section:related_work}

\subsection{Redirection in VR}

As users tend to prioritize visual information over other sensory channels when they are facing various information from the sensory system, (i.e., visual dominance~\cite{rock1964vision, gibson1933adaptation}), VR provides the opportunity to manipulate the visual information that users perceive to enable novel interactions.
While the manipulation is applied to users' movement and remains undetected, users will fall into the illusion that makes them believe their physical body movement is consistent with the manipulated virtual movement, which is called redirection.
Redirection can be implemented by adding an offset to the user's movement in VR to adjust the trajectory slightly~\cite{kohli2012redirected, gonzalez2023sensorimotor}.
% A common type of perceptual manipulation is redirection, which involves adding an offset an offset to the user's movement in VR to adjust the trajectory slightly~\cite{kohli2012redirected, gonzalez2023sensorimotor}.
% When this manipulation is unnoticeable, users will fall into the illusion that makes them believe their physical body movement is consistent with the manipulated virtual movement. 

Redirection has been widely used in VR applications to improve interaction performance and enable new interactions, including visuo-haptic illusion, augmenting input techniques and redirected walking.
As one of the most frequently-used forms of body input, hand movement has been widely explored as the subject of redirection illusions.
Hand redirection has been employed to alter the perceived shape \cite{redirectedtouching, zhao2018functional} and location \cite{HapticRetargeting, cheng2017sparse} of passive haptic props; this creates visuo-haptic illusions~\cite{yu2020pseudo}, which have been found to increase users' reutilization of physical counterparts to different virtual objects. 
To improve the interaction efficiency, researchers applied redirection techniques by adding offsets to users' hand movement~\cite{frees2007prism, montano2017erg}.
As one of the earliest works that modified the user's body movement to enhance input performance, the Go-Go technique~\cite{poupyrev1996go} extended the virtual hand's depth with a non-linear function to enable users to interact with objects beyond the reach.
Ownershift~\cite{feuchtner2018ownershift} proposed a technique that allowed the user’s physical hand to shift to comfortable poses while keeping the virtual hand in mid-air, to keep the user unaware of the movement and avoid physical fatigue.
\citeauthor{wentzel2020improving} proposed a hand position amplification technique with an adaptive function, enabling users to interact with objects beyond reach while keeping the offset unnoticed~\cite{wentzel2020improving}.
Prior work explored manipulating the movement of other body parts, e.g.,
% As for manipulating the movement of other body parts, 
redirected walking techniques to guide users to specific physical locations while walking in the virtual environment.
By applying slightly angular offsets to users' footsteps, this technique allows users to walk in a boundless virtual environment within the confines of a restricted physical space~\cite{RDWroom-scale, rietzler2020telewalk}.

These redirection-based interaction techniques enable novel functionalities in VR (e.g., redirected walking) or improve users' interaction performance (e.g., Go-Go technique).
These studies highlight the application and benefit of redirection in VR interactions, which motivates us to further explore redirection techniques in VR.

% \delete{
% These redirection-based interaction techniques have the potential to facilitate novel functionalities and improve interaction performance, but require keeping users unaware of the manipulations.
% % However, this advancement is based on preserving the manipulation undetected by the users.
% Breaking the illusion (e.g., through a noticeable mismatch between avatar and users' movements) can users no longer perceive the virtual movement as their movement and result in a lower sense of embodiment.
% Therefore, it is important to investigate factors that lead users to notice redirection offsets, which our work aims to address.
% % which motivate us to further explore the factors that would influence this.
% }


% \subsubsection{Redirected walking}
% % redirected walking: \cite{rietzler2020telewalk}
% Redirected Walking (RDW) technologies has facilitated the immersion of users in expansive virtual environments (VE), allowing them to navigate through these environments while physically traversing compact physical spaces (PE) \cite{redirectedWalkingPOI}. To be specific, room-scale RDW techniques enable the intriguing potential to facilitate near-natural walking experiences in a boundless VE, all within the confines of a restricted PE, and devoid of any disruptive interruptions \cite{RDWroom-scale, rietzler2020telewalk}. 

% Acknowledging the inherent imprecision of human motion perception, RDW techniques are ingeniously implemented by introducing deliberate adjustments to the user's bodily movements during walking. This intentional manipulation ensures that the virtual world's motion deviates from that of the physical world, amplifying the immersive experience \cite{ThresholdsRDW}. Typical RDW strategies predominantly rely on three fundamental categories of gains: translation, rotation, and curvature gains \cite{Suma2012RDW, GrechkinRDW}. 

% Furthermore, hand redirection has the potential to extend the reachability of encountered-type haptic devices \cite{Encountered-typeHaptics, HapticRetargeting2021} and enhance ergonomic aspects \cite{ErgonomicOptimization} within the realm of virtual reality.

\subsection{Noticeability of redirection in VR}
% we don't care the noticeability of other visual effects, thus it should be about the noticeability of offsets
Though redirection-based methods enable various novel interactions in VR, previous studies suggested that it is also important to main embodiment during redirection~\cite{wentzel2020improving, zenner2023detectability, zenner2019estimating}.
The challenges around maintaining embodiment with redirection techniques are in how to minimize users' noticeability of offsets between their own bodies and virtual avatars.
% As the detection of motion offset could serve the interactions in VR, the noticeability of the offset between the virtual avatar and the user's physical body has aroused more and more researchers' interest~\cite{zenner2019estimating}.
To investigate the detection threshold of redirection, \citeauthor{burns2006hand} implemented redirection motion techniques in a game scenario and derived a detection threshold of 19.1 degrees (19cm) between the real and virtual hand~\cite{burns2006hand}.
Similarly, \citeauthor{lee2015enlarging} investigated the threshold for finger tracking errors and derived a much lower Just-Noticeable Difference (JND) of 5.2 cm, using a dot to indicate the fingertip position~\cite{lee2015enlarging} rather than a full representation of virtual hands.
To extend the detection threshold to a noticing probability, \citeauthor{li2022modeling} studied noticeability of redirection with different strength and direction on the user's arm movement and provided a model to compute the noticeability for given offset strength and direction~\cite{li2022modeling}.

%While the redirection technique was widely used to provide visuo-haptic illusion, 
In addition, adding coherent haptic feedback to the user's motion can also impact the noticeability of applied motion offset.
\citeauthor{abtahi2018visuo} investigated the fingertip offset detection threshold along with a physical proxy providing haptic feedback~\cite{abtahi2018visuo}.
The derived thresholds achieved 49.5 degrees on the horizontal axis, which was larger than the previously reported value.
Similary, \citeauthor{feick2021visuo} investigated how to leverage simple physical proxies to provide visuo-haptic illusions and investigated the noticeability of discrepancy between the physical and virtual object.
Their results indicated that users could bear a bigger offset when they gained more sensory information from other modalities.

Another effective approach to making redirection less noticeable is to manipulate the virtual environment by leveraging users' moments of inattention or blindness.
One method involves performing these manipulations outside the user’s field of view. 
For example, \citeauthor{suma2010exploiting} altered the geometry of a virtual room behind the user to subtly redirect walking paths~\cite{suma2010exploiting}. 
Similarly, \citeauthor{lohse2019leveraging} and \citeauthor{patras2022body} remapped virtual objects to physical props for haptic retargeting when they were outside the user’s view~\cite{lohse2019leveraging, patras2022body}.
Another approach is to introduce manipulations within the user’s field of view but outside their focus of attention. 
\citeauthor{marwecki2019mise} developed a system that uses eye tracking and attention models to apply changes only when objects fall outside the user’s visual attention~\cite{marwecki2019mise}.
However, these manipulations primarily focused on altering the virtual environment, rather than redirecting the movement of virtual avatars. 
In the context of virtual motion redirection, \citeauthor{zenner2023detectability} proposed applying virtual hand position offsets during user blinks. 
Their findings revealed that detection thresholds were significantly higher when the saccade direction opposed the hand offset direction~\cite{zenner2023detectability, zenner2021blink}.
While \citeauthor{zenner2023detectability} proposed redirecting users' motions during blinks, we explored the extent to which this redirection can be applied and examined its noticeability.

These studies reveal that the noticeability of redirection in VR can be influenced by various factors. 
While much of the research has focused on virtual avatars, the impact of the surrounding virtual environment on noticeability remains largely unexplored. 
To address this gap, we propose to investigate and model how visual stimuli affect the noticeability of redirection in this paper.

% version B
% \change{
% These studies reveal that the noticeability of redirection in VR can be influenced by various factors. 
% In addition to factors related to virtual avatars, prior work also proposed leveraging user blindness caused by visual distractions to manipulate the virtual environment without being noticed.
% However, directly quantifying visual distractions and measuring users' attention is challenging, making it difficult to decide when a manipulation will be noticed.
% To address this, we propose to investigate how visual stimuli in the virtual environment influence the noticeability of redirection and predict the noticeability using users' gaze behaviors.
% % While much of the research has focused on virtual avatars, the impact of the surrounding virtual environment on noticeability remains largely unexplored. 
% }

% \delete{
% In a recent study, Zenner et al. investigated the impact of eye saccade direction on the noticeability of a sudden virtual hand position offsets and the results suggested that detection thresholds were significantly higher when the saccade direction opposed the direction of the hand offset~\cite{zenner2023detectability}. 
% These results suggest that the noticeability of motion offsets may be affected by eye gaze behavior. 
% However, in conventional virtual motion redirection techniques, motion offsets are typically applied to continuous virtual motion rather than as sudden shifts.
% Therefore, we focus on the noticeability of  motion offsets within continuous motion.
% Specifically, we aimed to study if and how visual attention influences users' detection criterion or offset threshold when analyzing whether a motion offset is present between the virtual and the physical motion.
% }

% \delete{
% While these works showcase the importance and potential influencing factors that affect the noticeability of motion offsets, we propose visual attention as an under-explored factor that impacts noticeability.
% %Since users are situated in complicated and attractive environments in VR interactions, their visual attention is easily attracted.
% Since VR interfaces can be visually-complex, it is common that users may shift their attention from the avatar body to other areas of the environment.
% Therefore, we aimed to study if and how visual attention influences users' detection criterion or offset threshold when analyzing whether a motion offset is present between the virtual avatar and the physical body.
% }

\subsection{Gaze behaviors for HCI}

Gaze behaviors have become crucial for understanding users' mental states and interaction intentions, especially with the integration of eye tracking in HMDs and smart glasses.
Beyond indicating where users are looking, gaze behaviors have also been used to classify attentional directions and indicate users' cognitive states~\cite{wang2019exploring}.
For instance, \citeauthor{benedek2017eye} demonstrated that pupil dilation is linked to cognitive focus~\cite{benedek2017eye}, while \citeauthor{duchowski2018index} introduced the Index of Pupil Activity (IPA) as a metric for cognitive load, which has been applied in HCI applications such as adaptive MR user interfaces~\cite{lindlbauer2019context}.
Furthermore, \citeauthor{annerer2021reliably} emphasized the role of pupil dilation in differentiating between internal and external attention~\cite{annerer2021reliably}.
In addition to pupil features, saccadic eye movements (saccade) and fixation duration are key indicators of cognitive load.
\citeauthor{zagermann2016measuring} and \citeauthor{holmqvist2011eye} found that longer fixations and shorter saccades were linked to higher cognitive demands~\cite{zagermann2016measuring, holmqvist2011eye}. 
These findings suggest a strong correlation between gaze behaviors and cognitive activity. 

Previous studies suggest that users' cognitive activities influence gaze behaviors over several seconds, rather than just a few frames. 
For example, \citeauthor{faber2018automated} recently demonstrated that content-independent gaze features with a 12-second window were effective for estimating cognitive load during reading tasks~\cite{faber2018automated}. 
Similarly, a time window-based method was proved to be effective in tasks such as film watching~\cite{mills2016automatic}, interactive tutoring~\cite{hutt2016eyes}, and lecture viewing~\cite{hutt2017gaze}. 
These studies also indicate that shorter windows (less than 10 seconds) may not capture enough fixation and saccade information to accurately detect covert inattention~\cite{bixler2016automatic, hutt2016eyes} which lead to lower accuracy~\cite{hutt2017gaze, hutt2016eyes}. 
Therefore, a longer windows (20-30 seconds) were more suitable for using gaze behaviors for estimating users' cognitive activities.

Based on the findings of previous studies, we propose to investigate how to use the gaze behaviors (gaze saccade, fixation, pupil activity) to compute the noticeability of redirection under various visual stimuli.

% \subsection{\delete{Visual attention in VR}}

% Since visual information is the dominant source of users' sensory input in VR, it is important to consider users' patterns of processing and paying attention to visual information when designing VR interactions.
% \delete{
% As visual information dominates users' sensory systems, it is important to consider the visual attention's influence in designing interactions~\cite{healey2011attention, doerr2023bees}.
% To understand users' visual attention in VR scenarios, \citeauthor{sitzmann2018saliency} analyzed 169 users' viewing behaviors in 22 VR scenes and identified predictors of what users notice~\cite{sitzmann2018saliency}.
% % Besides understanding the visual attention in VR, 
% \citeauthor{grogorick17subtlegazeguidance} proposed a real-time image processing technique for wide field-of-view displays to direct the users' visual attention in an immersive environment~\cite{grogorick17subtlegazeguidance}.
% Similarly, the HiveFive technique directs the user's visual attention via swarm robots in virtual environments to provide guidance and preserve the immersion simultaneously~\cite{Lange20}.
% Meanwhile, \citeauthor{lindlbauer2019context} proposed to consider the cognitive load caused by various visual information as an important factor when designing MR user interfaces~\cite{lindlbauer2019context}.
% \citeauthor{marwecki2019mise} leveraged visual effects to attract users' visual attention and manipulate the virtual environment within the user's field of view at the same time~\cite{marwecki2019mise}.
% Since users were distracted by the visual effects, they did not notice changes in the virtual environment.
% }

% \delete{
% We hypothesized that visual stimuli can also be used to draw users' attention away from redirection illusions, which could make users less likely to notice the offset between their virtual and physical body movement.
% To investigate how visual attention affects noticeability, we explored it with abstract visual stimuli (e.g., a color-changing dot), as opposed to exploring the effect in complicated scenarios that could introduce confounding factors, such as diegetic visual cues.
% }

