
\section{Methodology}
\label{section:methodology}

To explore how to use gaze behaviors to compute the noticeability of redirection under visual stimuli, we employed a dual-task design in the following confirmation and data collection studies, which allows us to collet noticeability responses from participants while simultaneously presenting visual stimuli. 
In this section, we detail the methodology step by step.

\subsection{Selecting left arm for investigation}

Previous studies have applied redirection techniques to users' walking paths~\cite{kohli2012redirected}, hand positions~\cite{wentzel2020improving}, and arm motions~\cite{poupyrev1996go}.
Considering that the arms are among the most frequently used body parts, we focused our investigation on the redirection of arm movements.
To control for the influence of hand dominance, all user studies were conducted on left arms of right-handed participants.
We acknowledge that hand dominance and different body parts may lead to noticeability difference of the applied redirection, we believe that this approach and the main findings will be both applicable to the right arm and extendable to other body parts in future studies.

\subsection{Redirection mechanism}

In this paper, we adopted the same redirection mechanism as previous studies~\cite{li2022modeling}, which applied angular redirection to users' elbow joints during movement. 
The redirection was applied dynamically, starting with no redirection at the initial pose (pointing to the ground) and gradually increasing to the maximum redirection at the target ending pose.
The redirection of the intermediate motion was calculated based on the relative angular distance from the starting pose and was adjusted linearly throughout the movement.
The strength of the redirection was adjusted by modifying the maximum redirection applied at the ending pose.

\subsection{Dual-task design}

In realistic virtual environments, users often engage with complex visual effects (e.g., game props) while controlling their virtual avatars. 
To simulate this, we designed a dual-task study where participants were required to perform redirection motions (primary task) while monitoring and responding to visual stimuli at the same time (secondary task).

\subsubsection{Primary task.}
As the primary task, participants were asked to perform arm motions with redirected virtual arms in VR. 
Each motion was defined by a starting arm pose and a target ending pose. 
The starting pose was fixed in a natural resting position, with the arm positioned beside the body. 
The target ending pose was sampled from a motion capture dataset that included daily life poses, such as walking, sports, sitting, and others, as described in ~\autoref{section:target_poses}.
To ensure that all participants performed the movements consistently, we added an intermediate checkpoint pose between the starting and ending poses. 
During the study, both the target ending pose and the intermediate checkpoint pose were rendered as semi-transparent, allowing participants to observe them without causing visual occlusion. 
In contrast, the participants' redirected virtual arm was rendered normally, as illustrated in~\autoref{figure:formalapparatus}.


At the beginning of each trial, participants were instructed to perform the starting pose, in which they lowered their physical arm and pointed to the floor. 
Since there was no redirection at this position, the virtual arm also pointed downward. 
For each trial, a semi-transparent intermediate pose and target pose were displayed. 
Participants were then instructed to lift their physical arms, guiding their virtual arms past the intermediate pose to reach the target pose. 
Throughout this process, participants were asked to keep the virtual arm within their field of view at all times.
After reaching the target pose, participants were asked to move their virtual arm back to the starting pose and report to experimenters verbally whether they perceived any difference between their physical and virtual movement, according to the yes/no paradigm~\cite{leek2001adaptive}.
We estimated the noticeability of redirection in each condition with the ratio of positive responses (indicating noticed redirection in the trials) to the number of trials, referring to previous studies~\cite{li2022modeling}.

\subsubsection{Secondary task.}
In parallel with the primary task, participants were asked to monitor visual stimuli that appeared within their field of view. 
The stimuli consisted of a simple animation on a virtual sphere, presented alongside the virtual avatar. 
For example, in the opacity-based stimuli condition, the animation began with a fully transparent sphere, gradually increased to full opacity, and then returned to transparency.
The location and duration of the animation were adjusted to control the intensity of the visual stimuli between trials, following previous studies suggesting that these properties influence the intensity~\cite{li2024predicting}. 
The virtual sphere moved in sync with the participant's head movements, maintaining the same relative position within their field of view.
To prevent participants from predicting the timing of the stimuli, the animation began at a random moment after the trial started and repeated at random intervals (ranging from 1 to 3 seconds). 
Participants were instructed to press a button on a controller held by their right hand as soon as they noticed the animation was starting.

\subsection{Sampling target poses}
\label{section:target_poses}
For the ending poses, we selected 25 distinct poses from the CMU MoCap dataset~\cite{CMUMocap}. 
To ensure the diversity of poses, these poses were selected based on clustered subsets using the HDBSCAN algorithm~\cite{leland2017hdbscan}, based on the skeletal distance function proposed in~\cite{shakhnarovich05learning}, calculated as:

\begin{equation}
    \text{Distance}(\alpha_1, \alpha_2) = \max \limits_{1 \leq i \leq L} \sum_{d \in x, y, z} (\alpha^{i}_{d, 1} - \alpha^{i}_{d, 2})
\end{equation}

where $L$ represents the number of joints in the pose, and $x, y, z$ denote the spatial coordinates of each joint. 
This function determines the maximum skeletal distance between two poses $\alpha_{1}$ and $\alpha_{2}$ across all joints.
The sampled poses are displayed in \autoref{appendix:poses}.
