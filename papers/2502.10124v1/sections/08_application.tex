\section{Towards real-world use cases}

While the previous study results suggest that our proposed model could effectively compute the noticeability of redirection under various basic visual stimuli (transparency-, color- and scale-based), we aimed to explore how the model could be used in real-world scenarios.
To showcase the potential benefits of our model in practical use cases, we implemented \textbf{an adaptive redirection technique} and developed \textbf{two real-world applications} to demonstrate its generalizability and usability.
We also performed a proof-of-concept study to gather user feedback while interacting with the two applications and the adaptive redirection technique.

% \delete{
% Our regression model can compute the noticeability of motion offsets under various visual stimuli.
% We envision that the model can support various interaction techniques by adjusting the noticeability of motion offsets to match contextual requirements.
% In the following, we first outline how our model could potentially be utilized by content creators and then we demonstrate its applicability in two scenarios.
% Although the system has not been formally evaluated through user studies, we believe that they showcase the potential benefits that our regression model could provide.
% }

% \delete{
% Based on our noticeability regression model, we implemented two applications to demonstrate future interaction scenarios.
% In the applications, our regression model was integrated with the system to compute the noticeability using the user's eye behavioral patterns in the last 30 seconds.
% Although the system has not been formally evaluated through user studies, we believe that they showcase the potential benefits that our regression model could provide.
% }

\begin{figure}[t]
    \centering
    \begin{subfigure}{0.45\columnwidth}
        \includegraphics[width=0.9\columnwidth]{figures/applications/app1.png}
        \caption{}
        \label{figure:application_adaptive}
    \end{subfigure}
    \centering
    \begin{subfigure}{0.45\columnwidth}
        \includegraphics[width=0.9\columnwidth]{figures/applications/app2.png}
        \caption{}
        \label{figure:opportunistic}
    \end{subfigure}
    \caption{
    We developed two real-world applications to demonstrate the capabilities of our adaptive redirection technique:
    (a) Adjusting the difficulty of VR action game: 
    In this application, mid-air coins and monsters serve as visual cues for the target poses that users are asked to perform. 
    Our adaptive redirection technique enables the system to adjust the game’s difficulty without the user noticing, ensuring a balanced and engaging experience.
    (b) Opportunistic rendering for boxing training in VR : 
    Here, users are learning boxing movements by following a blue avatar. 
    Leveraging our adaptive redirection technique, the system can simulate opportunistic rendering which reduces requirements for computation resources.}
    \label{figure:application}
\end{figure}

\subsection{Adaptive motion redirection technique}
As discussed in the Introduction (\autoref{section:introduction}) and Related Work (\autoref{section:related_work}), users in real VR applications may face complicated visual effects that can impact the noticeability of redirection movements. 
This, in turn, influences the effectiveness and overall user experience of redirection techniques.
While it is impractical to predict the specific visual effects users will encounter beforehand, content creators can only predefine a static redirection intensity, which limits the effectiveness of redirection techniques. 
To address this limitation, our proposed model enables designers to dynamically adjust the redirection during usage based on the user’s gaze behavior.

Our model computes the noticeability of redirection as a float value ranging from 0 to 1. 
With this output, we implemented an adaptive redirection technique by using the Three-class model described in \autoref{section:classfication_model}.
For each class of noticeability, we predefined corresponding redirection: 25 degrees for Low Noticeability, 15 degrees for Medium Noticeability, and 5 degrees for High Noticeability. 
When the computed noticeability falls into one of these classes, the corresponding redirection is applied.
The redirection technique initializes with a 10 degree offset. 
When a change in redirection is required according to the noticeability changes, we use linear interpolation to transition the redirection gradually over a 10-second period. 
To maintain immersion, the redirection is adjusted only when the user’s arm is in motion, since if the redirection changes while the physical arm remains static, the virtual arm will be moved and lead to break of immersion and sense of embodiment.

To be noted, this adaptive redirection technique serves as a demonstration of the usability of our proposed model. 
Designers can leverage the model's probabilistic output to create their own redirection techniques tailored to specific applications.

% \subsection{\delete{Adjusting motion offsets to meet noticeability requirements}}
% \delete{
% Currently, designers typically aim to minimize the noticeability of motion offsets to preserve the user's sense of embodiment when employing redirection techniques in VR interactions. 
% However, the challenge lies in the difficulty of predicting the exact visual animations or effects that users will experience in advance, limiting designers to pre-setting motion offset thresholds.
% For instance, in the context of an action game, a designer might adopt a redirection technique to enhance the user experience. 
% The motion offsets might go unnoticed when complex visual effects and animations capture the user's visual attention. 
% However, if these visual effects diminish in intensity, the user's focus may return to their virtual body, making the same motion offset detectable.
% Therefore, we envision that our model could enable designers to dynamically adjust motion offsets by tracking users' gaze patterns and visual attention in real time. 
% This would allow for a more responsive and adaptable redirection technique, ensuring that motion offsets remain unnoticed under varying visual conditions.
% }

% \delete{
% With our model, content creators can design redirection techniques and their noticeability requirements in advance, while leaving their intensity to our model to decide. 
% During runtime, the interactive system can maintain a historical record of users' gaze behavioral data and input it to our model.
% Based on this, our model can simulate various motion offsets and compute their noticeability results.
% Then the interactive system can apply an appropriate motion offset to meet the predefined noticeability requirement.
% }


% \change{
% To further understand the prediction performance of our model, we converted the regression model to a classification model by applying different thresholds and dividing the noticeability into separate categories.
% We first converted the regression model into a binary classification model with a noticeability threshold of 0.4, which could classify the noticeability between low and high visual attention based on \autoref{figure:predictionperformance_average}.
% We trained an SVM classification model with the same features selected in \autoref{section:featureselection}; this model achieved an accuracy of 0.917 $(SD=0.112)$ and an F1-score of 0.896 $(SD=0.134)$ with leave-one-user-out cross-validation.
% Then we divided the noticeability into three categories with two thresholds: Low Noticeability $(\leq 0.33)$, Medium Noticeability $(0.33 <$ noticeability $\leq 0.66)$, and High Noticeability $(>0.66)$.
% With the same SVM classification model and selected feature, our re-trained model achieved an accuracy of 0.856 $(SD=0.124)$ and an F1-score of 0.847 $(SD=0.127)$.
% Notably, the prediction accuracy was affected by how we converted the noticeability value to separate labels and might increase with fine-tuned features tailored to the classification task.
% This indicates that the selected features from the gaze behavioral pattern have the potential to predict the noticeability as separate categories.
% }

\subsection{Real-world applications}

\subsubsection{Adjusting the difficulty of VR action game}
% \delete{
% First, we implemented an adaptive motion offset adjustment based on the status of the user's visual attention (as indicated by their gaze behavior).
% With the user's gaze behavioral data, our model is able to compute the noticeability of motion offsets.
% Thus, designers can limit the noticeability of motion offsets to a desired level by adjusting the motion offsets, based on our model.
% We demonstrate this with a VR action game}
Based on our adaptive redirection technique, we implemented a VR action game inspired by the VR game Beat Saber~\footnote{https://beatsaber.com/}.
In the game, users are asked to perform certain poses with their arms based on visual and musical guidance.
The game difficulty could be adjusted by redirecting the user's movement, for example, slightly amplifying their movements could make it easier and faster to achieve the targets.
Meanwhile, users need to focus on the targets to obtain sufficient information, and thus they paid less visual attention to their virtual body movements.
As shown in \autoref{figure:application_adaptive}, when the visual guidance for the target arm pose is highly detailed and draws significant attention from the user, 
the noticeability of redirection might be lower and 
the system can take the risk of applying large redirection for functional gains.
However, when the user interacts with a simpler interface and focuses mainly on their virtual arm, 
a low level redirection might be applied with the high noticeability prediction.
%designers can just amplify users' motion a bit and provide limited guidance when the visual effects are simple.
%Accordingly, designers can provide more attractive visual effects to provide stronger guidance by applying larger offsets to users' motion.

% Adjust the strength of the offsets according to the user's gaze behavior, as an indicator of their visual attention allocation status, to maintain the same level of noticeability.


\subsubsection{Opportunistic rendering for boxing training in VR}
We implemented a boxing training system designed to reduce rendering computation as our second application.
Accurate motion reconstruction and rendering may require high computing power~\cite{chen2021towards}.
While users may not always focus on their virtual movements, there is a chance to apply opportunistic rendering based on the user's visual attention to save computing capability and avoid being noticed by users.
As shown in \autoref{figure:opportunistic}, the user is learning boxing poses with a virtual coach in VR.
When the user is looking at the coach and observing them performing the pose, our model may output a lower level of noticeability and thus it allows the system to update the user's movement less frequently which leads to the virtual movement has a offset with the user's physical movement and save computing resources.
While the user shifts their attention back to his arm and is going to practice the boxing poses, our model can compute that the noticeability of motion offset is higher than in the previous scenario.
Therefore, the system can allocate more resources to render the user's movement, to ensure that they can perform and learn the accurate poses in VR.
To be noted, we implemented this application as a simulation of opportunistic rendering to demonstrate the potential of our model, rather than fully implementing it and measuring the computational resources it would save.

% When gaze behaviors tells the system, the user's visual focus is attracted by notifications/distractions, it can decide to lower the requirement on the sensing/rendering of the user's body motion.

\subsection{Proof-of-Concept study}

To further demonstrate and evaluate the how our model supports adaptive redirection techniques, we conducted a proof-of-concept evaluation study on two applications.

\subsubsection{Design}

We conducted a within-subject factorial study design, with the independent variable being the experimental conditions, including Adaptive Redirection (\textbf{AR}) and Static Redirection (\textbf{SR}).
In the VR action game, participants were tasked with performing poses that aligned with a moving target. 
The target’s appearance frequency progressively increased, starting at intervals of 2 seconds and accelerating to 0.5 seconds and the game lasted for 60 seconds.
In the boxing training application, participants engaged in a 60-second motion-learning task, attempting to replicate the movements demonstrated by a virtual coach.
For the \textbf{SR} condition, the redirection magnitude was fixed at 15 degrees, which is the same as the medium level magnitude used in the \textbf{AR} condition.
After completing the tasks in each condition, participants rated the tested conditions on physical demand ("\textit{The interaction was physically demanding}"), mental demand ("\textit{The interaction was mentally demanding and I had to concentrate a lot.}"), embodiment ("\textit{I felt as if the virtual body was my body}") and agency ("\textit{I felt like I could control the virtual body as if it was my own body}") with a 7-point Likert scale, using the questions from similar studies in prior work~\cite{peck2021avatar, feick2023investigating}.


\subsubsection{Apparatus \& Procedure}

We implemented the applications with a HTC Vive pro headset in Unity 2019, powered by an Intel Core i7 CPU and an NVIDIA GeForce RTX 2080 GPU. 
During the study, participants were equipped with three Vive Trackers affixed to their left shoulder, elbow, and waist using nylon straps.

After being introduced to the study, participants had a warm-up session to learn about the study tasks and get familiar with controlling the virtual movements.
Once they were comfortable with the virtual movements and tasks, they proceeded to experience one condition across both applications.
After completing the two applications under the first condition, participants provided their ratings before moving on to experience the second condition. 
The order of conditions and applications was counterbalanced.
The study lasted around 20 minutes, and each participant received a compensation of 10 US dollars for their participation.

\subsubsection{Participants}

We recruited 8 new participants (2 females, 6 males, average age of 25.63 with $SD=1.85$) from a local university.
These participants reported their familiarity with VR as an average of 3.75 $(SD=1.16)$ on a 7-point Likert-type scale from 1 (not at all familiar) to 7 (very familiar).

\subsubsection{Result}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{figures/applications/preliminary_results.png}
    \caption{Proof-of-concept study results indicate that participants experienced less physical demand and a stronger sense of embodiment and agency when using the adaptive redirection technique compared to the static technique.}
    \label{figure:preliminary_result}
\end{figure}

\autoref{figure:preliminary_result} summarizes the study results.
We conducted Wilcoxon signed-rank tests to analyze the reported subjective metrics.
Participants reported lower physical demand in the adaptive redirection (\textbf{AR}) condition ($M=3.50, SD=1.00$) compared to the static redirection (\textbf{SR}) condition ($M=4.50, SD=0.50$, $W=2.00, p<0.05$). 
This is due to the larger redirection allowed in \textbf{AR} when visual stimuli were intense, reducing the need for extensive physical movement.
Despite the adaptive nature of \textbf{AR}, participants did not perceive a higher mental demand ($M=4.25, SD=0.60$) compared to \textbf{SR} ($M=4.25, SD=0.43$, $W=5.00, p>0.05$). 
This suggests that \textbf{AR} does not introduce additional cognitive effort for participants to control their virtual motion during interactions.
Participants reported a stronger sense of embodiment ($M=5.13, SD=0.60$) and agency ($M=5.25, SD=0.43$) in \textbf{AR} compared to \textbf{SR}, where embodiment ($M=4.13, SD=0.92$, $W=2.50, p<0.05$) and agency ($M=4.13, SD=0.92$, $W=3.00, p<0.05$) were rated lower. 
This can be attributed to the reduced possibility of detecting the redirection in \textbf{AR}, which enhanced participants' sense of control and immersion. 
In contrast, the frequent detection of redirection in \textbf{SR} reduced their sense of agency and embodiment.

These results suggest that our technique effectively adapts the redirection magnitude to the visual stimuli, aligning with the predicted noticeability from our computational model. 
This demonstrate the potential benefits and capabilities of the model in enhancing redirection interactions.
