@inproceedings{DBLP:conf/cvpr/TianX21,
  author       = {Yapeng Tian and
                  Chenliang Xu},
  title        = {Can Audio-Visual Integration Strengthen Robustness Under Multimodal
                  Attacks?},
  booktitle    = CVPR,
  pages        = {5601--5611},
  year         = {2021}
}

@inproceedings{DBLP:conf/cvpr/YangLBCK21,
  author       = {Karren Yang and
                  Wan{-}Yi Lin and
                  Manash Barman and
                  Filipe Condessa and
                  J. Zico Kolter},
  title        = {Defending Multimodal Fusion Models Against Single-Source Adversaries},
  booktitle    = CVPR,
  pages        = {3340--3349},
  year         = {2021}
}

@inproceedings{DBLP:conf/icassp/LiQLHM22,
  author       = {Juncheng B. Li and
                  Shuhui Qu and
                  Xinjian Li and
                  Bernie Po{-}Yao Huang and
                  Florian Metze},
  title        = {On Adversarial Robustness Of Large-Scale Audio Visual Learning},
  booktitle    = ICASSP,
  pages        = {231--235},
  year         = {2022}
}

@inproceedings{brousmiche2019audio,
  title={Audio-visual fusion and conditioning with neural networks for event recognition},
  author={Brousmiche, Mathilde and Rouat, Jean and Dupont, St{\'e}phane},
  booktitle={2019 IEEE 29th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@article{brousmiche2022multimodal,
  title={Multimodal attentive fusion network for audio-visual event recognition},
  author={Brousmiche, Mathilde and Rouat, Jean and Dupont, St{\'e}phane},
  journal={Information Fusion},
  volume={85},
  pages={52--59},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{chen2017deep,
  title={Deep cross-modal audio-visual generation},
  author={Chen, Lele and Srivastava, Sudhanshu and Duan, Zhiyao and Xu, Chenliang},
  booktitle={Proceedings of the on Thematic Workshops of ACM Multimedia 2017},
  pages={349--357},
  year={2017}
}

@inproceedings{cheng2020look,
  title={Look, listen, and attend: Co-attention network for self-supervised audio-visual representation learning},
  author={Cheng, Ying and Wang, Ruize and Pan, Zhihao and Feng, Rui and Zhang, Yuejie},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={3884--3892},
  year={2020}
}

@article{gao2024audio,
  title={Audio-visual representation learning for anomaly events detection in crowds},
  author={Gao, Junyu and Yang, Hao and Gong, Maoguo and Li, Xuelong},
  journal={Neurocomputing},
  pages={127489},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{hao2018cmcgan,
  title={Cmcgan: A uniform framework for cross-modal visual-audio mutual generation},
  author={Hao, Wangli and Zhang, Zhaoxiang and Guan, He},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{huang2023davis,
  title={DAVIS: High-quality audio-visual separation with generative diffusion models},
  author={Huang, Chao and Liang, Susan and Tian, Yapeng and Kumar, Anurag and Xu, Chenliang},
  year={2023}
}

@inproceedings{huang2023egocentric,
  title={Egocentric audio-visual object localization},
  author={Huang, Chao and Tian, Yapeng and Kumar, Anurag and Xu, Chenliang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22910--22921},
  year={2023}
}

@article{huang2024scaling,
  title={Scaling Concept With Text-Guided Diffusion Models},
  author={Huang, Chao and Liang, Susan and Tang, Yunlong and Tian, Yapeng and Kumar, Anurag and Xu, Chenliang},
  journal={arXiv preprint arXiv:2410.24151},
  year={2024}
}

@article{liang2023av,
  title={Av-nerf: Learning neural fields for real-world audio-visual scene synthesis},
  author={Liang, Susan and Huang, Chao and Tian, Yapeng and Kumar, Anurag and Xu, Chenliang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={37472--37490},
  year={2023}
}

@article{liang2023neural,
  title={Neural acoustic context field: Rendering realistic room impulse response with neural fields},
  author={Liang, Susan and Huang, Chao and Tian, Yapeng and Kumar, Anurag and Xu, Chenliang},
  journal={arXiv preprint arXiv:2309.15977},
  year={2023}
}

@inproceedings{liang2024language,
  title={Language-Guided Joint Audio-Visual Editing via One-Shot Adaptation},
  author={Liang, Susan and Huang, Chao and Tian, Yapeng and Kumar, Anurag and Xu, Chenliang},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  pages={1011--1027},
  year={2024}
}

@inproceedings{majumder2021move2hear,
  title={Move2hear: Active audio-visual source separation},
  author={Majumder, Sagnik and Al-Halah, Ziad and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={275--285},
  year={2021}
}

@inproceedings{majumder2022active,
  title={Active audio-visual separation of dynamic sound sources},
  author={Majumder, Sagnik and Grauman, Kristen},
  booktitle={European Conference on Computer Vision},
  pages={551--569},
  year={2022},
  organization={Springer}
}

@article{min2020multimodal,
  title={A multimodal saliency model for videos with high audio-visual correspondence},
  author={Min, Xiongkuo and Zhai, Guangtao and Zhou, Jiantao and Zhang, Xiao-Ping and Yang, Xiaokang and Guan, Xinping},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={3805--3819},
  year={2020},
  publisher={IEEE}
}

@inproceedings{morgado2021robust,
  title={Robust audio-visual instance discrimination},
  author={Morgado, Pedro and Misra, Ishan and Vasconcelos, Nuno},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12934--12945},
  year={2021}
}

@article{rahman2021tribert,
  title={TriBERT: Human-centric audio-visual representation learning},
  author={Rahman, Tanzila and Yang, Mengyu and Sigal, Leonid},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={9774--9787},
  year={2021}
}

@inproceedings{sung2023sound,
  title={Sound to Visual Scene Generation by Audio-to-Visual Latent Alignment},
  author={Sung-Bin, Kim and Senocak, Arda and Ha, Hyunwoo and Owens, Andrew and Oh, Tae-Hyun},
  booktitle=CVPR,
  pages={6430--6440},
  year={2023}
}

@inproceedings{wu2019dual,
  title={Dual attention matching for audio-visual event localization},
  author={Wu, Yu and Zhu, Linchao and Yan, Yan and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6292--6300},
  year={2019}
}

@inproceedings{wu2019time,
  title={Time domain audio visual speech separation},
  author={Wu, Jian and Xu, Yong and Zhang, Shi-Xiong and Chen, Lian-Wu and Yu, Meng and Xie, Lei and Yu, Dong},
  booktitle={2019 IEEE automatic speech recognition and understanding workshop (ASRU)},
  pages={667--673},
  year={2019},
  organization={IEEE}
}

@inproceedings{wu2021binaural,
  title={Binaural audio-visual localization},
  author={Wu, Xinyi and Wu, Zhenyao and Ju, Lili and Wang, Song},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={4},
  pages={2961--2968},
  year={2021}
}

@inproceedings{xia2022cross,
  title={Cross-modal background suppression for audio-visual event localization},
  author={Xia, Yan and Zhao, Zhou},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={19989--19998},
  year={2022}
}

@inproceedings{yang2023quantifying,
  title={Quantifying and Enhancing Multi-modal Robustness with Modality Preference},
  author={Yang, Zequn and Wei, Yake and Liang, Ce and Hu, Di},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{zhou2019talking,
  title={Talking face generation by adversarially disentangled audio-visual representation},
  author={Zhou, Hang and Liu, Yu and Liu, Ziwei and Luo, Ping and Wang, Xiaogang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={9299--9306},
  year={2019}
}

@inproceedings{zhu2021learning,
  title={Learning audio-visual correlations from variational cross-modal generation},
  author={Zhu, Ye and Wu, Yu and Latapie, Hugo and Yang, Yi and Yan, Yan},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4300--4304},
  year={2021},
  organization={IEEE}
}

