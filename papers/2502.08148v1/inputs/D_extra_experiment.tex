\section{Statistical Causal Discovery}\label{sup:causal_discovery}

\input{inputs/background}

\begin{figure*}[hbt!]
    \centering
    \includegraphics[width=\linewidth]{figures/CD.pdf}
    \caption{SHD \textbf{(left)} and F1 score \textbf{(right)} of estimated DAGs from statistical structure learning methods. \underline{Lower} SHD is better. \underline{Higher} F1 is better.}
    \label{fig:ssl}
\end{figure*}


\paragraph{Experiments.} We here discuss how \texttt{ACCESS} is used to assess to what extent the statistical structure learning methods is applicable to recover causal relations among event abstractions. As illustrated in Figure \ref{fig:main}, after extracting abstractions, one can build representations for abstract events in the original corpus and apply structure learning on top of such data for full graph discovery. A simple representation is the co-occurrence matrix size $(\# stories \times \# abstractions)$ where each entry takes a binary value indicating whether an abstraction has any of its mentions appearing in a story. This means each abstraction is now considered as a Bernoulli random variable and the task of causal discovery is to recover the underlying SCM where the structural functions are commonly non-convex. 

Due to the limited scalability of existing statistical algorithms, we resort to learning sub-graphs by setting thresholds to select nodes that appear frequently while ensuring that the true graph is acyclic. Specifically, our selected sub-graphs are composed of edges where both nodes are adjacent to at least one other node, and each node corresponds to an abstraction whose occurrences exceed a certain frequency threshold. In our experiment, we set thresholds for document frequency within  $\{25, 30, 35, 40, 45\}$, resulting in sub-graphs with $5, 7, 16, 19, 45$ nodes. The experiments are run on $5$ CPU cores.    


We experiment with popular constraint-based and score-based algorithms. We select those that are scalable and capable of capturing non-linear causal relationships without relying on specific model forms such as additive noise. In this paper, we report the results for the following algorithms: 


\begin{itemize}
    \item \texttt{PC} algorithm \citep{spirtes1991algorithm}: A classic approach based on conditional independence tests, for which we run two kinds of tests: Chi-squared and G-squared. 
    \item \texttt{DAG-GNN} \citep{yu2019dag}: DAG structure learning with graph neural networks.
    \item \texttt{GAE} \citep{ng2019graph}: This method utilizes gradient descent and graph auto-encoders to model non-linear causal relationships.
    \item \texttt{CORL} \citep{wang2021ordering}: A reinforcement learning-based algorithm with flexible score functions with enhanced efficiency.
\end{itemize}

Besides the above methods, we have also tested \texttt{NOTEARS} \citep{zheng2020learning}, a popular score-based algorithm and its more efficient variant \texttt{GOLEM} \citep{ng2020role}. However, they both unfortunately fail to recover any edges across all settings. To ensure consistency in implementation and evaluation, we utilize the standardized framework provided by \href{https://github.com/huawei-noah/trustworthyAI/tree/master/gcastle}{\texttt{gCastle}} \citep{zhang2021gcastle}. 
As for evaluation metrics, we report the structured Hamming distance (SHD), which quantifies the smallest number of edge additions, deletions, and reversals required to transform the recovered DAG into the true one. Additionally, we assess classification accuracy using the F1 score. Ideally, we aim for a lower normalized Hamming distance and a higher F1 score. Figure \ref{fig:ssl} reports the SHD and F1 score of the estimated DAGs from these methods. 

It is seen the methods achieve relatively low accuracy on our benchmark causal graphs, which are sparse. As the SHD scores are much higher than the graph size, these model tend to predict plenty of edges, most of which are incorrect due to the low F1 scores. Scalability remains a serious challenge to statistical structure learning. As the graph scales up to $45$ nodes, their performance further deteriorates significantly, where most of them of them even fail to recover any edges. It is noteworthy that the representation power of the input data also affects the causal discovery performance. It is very likely that the co-occurrence matrix is not sufficiently expressive to capture the causal knowledge. This motivates a dedicated line of research into abstract causal representation learning. 


\section{GLUCOSE-QA Reasoning}  \label{sup:reasoning}
We here provide the prompts for LLMs in Tables \ref{tab:prompt_causal_discovery}-\ref{tab:prompt_abs}. Tables \ref{tab:examples_specific_qa}-\ref{tab:examples_cot_step} present illustrative examples of the responses from LLMs across our QA tasks. 




\input{inputs/prompt}
\input{inputs/quali_examples}
