Our clustering algorithm, named \texttt{PIVOT}, is inspired by the pivoting algorithm proposed in \citet{fukunaga2019lp}. The \texttt{PIVOT} algorithm first randomly selects a pair of cause-effect events and then, for each of them, find its most similar neighbors against a threshold of $70\%$. We repeat the process for the remaining event mentions, while excluding the previously assigned events. The initial results are passed to the following process to remove self-loop and bi-directions. We remove clusters with fewer than $10$ samples and maximum pairwise similarity is less than $50\%$. Each cluster can now be considered a node in a graph and we use \texttt{GLUCOSE} to recover the causal relations among them to construct a temporary causal graph. 

\paragraph{Ablation study.} The main motivation behind \texttt{PIVOT} algorithm is to ensure the initial graph is mostly acyclic while avoiding any sub-optimality produced from post-processing. To validate whether \texttt{PIVOT} is most effective in ensuring causal consistency, we conduct an ablation study against popular clustering algorithms, including \texttt{OPTICS} \cite{ankerst1999optics}, \texttt{LOUVAIN} \cite{blondel2008fast} and \texttt{LEIDEN} \cite{traag2019louvain} algorithms, where \texttt{LOUVAIN} and \texttt{LEIDEN} were proposed for community detection problems. The criteria for selecting these clustering algorithms include: 
(1) scalability to medium-to-large-sized data, (2) ability to accommodate custom affinity matrix and (3) high cluster homogeneity score. Table \ref{tab:clustering} further reports the quality of the algorithms under analysis, which shows that our \texttt{PIVOT} algorithm yields the most desirable performance. 

 
\paragraph{Notations.} We use lower case letters (i.e., $v$) to denote single event, capital letters (i.e., $V$) for cluster of events, and blackboard bold letter (i.e., $\mathbb{V}$) for set of clusters. We let $\mathcal{D}$ denote the dataset of causal event mentions; $x \rightarrow y$ indicates event $x$ is a cause of event $y$; $x \leftarrow y$ indicates event $x$ is an effect of event $y$; $x \leftrightarrow y$ indicates $x$ and $y$ are causally related (either cause or effect). We also define the similarity between an event $y$ and cluster $V$ as the average of similarity between $y$ and every event $x$ in $V$
$$S_{yV} = \frac{1}{|V|} \sum_{x \in V} S_{xy},$$
where $S_{xy}$ is the similarity score between two events according to Eq. (\ref{eq:sim}).


\paragraph{Performance metrics.} In the following, we describe the unsupervised performance metrics to assess clustering algorithms in Table \ref{tab:clustering}. Given a set of clusters $\mathbb{C}$, let $\boldsymbol{A}$ be the matrix where $\boldsymbol{A}_{ij}$ is the number of events in cluster $C_i \in \mathbb{C} $ is the cause of any event in the cluster $C_j \in \mathbb{C}$. Recall that in this stage the causal relations between events are extracted from \texttt{GLUCOSE} dataset. A cluster $A$ is said to cause another cluster $B$ if \underline{at least one} event mentions in cluster $A$ causes any other event mentions in cluster $B$, according to the cause-effect definition in Section \ref{sec:setup}. 


\begin{enumerate}
    \item \textit{Self-loop ratio}: Proportion of clusters in which the events are either cause or effect of each other. 
    $$\frac{1}{|\mathbb{C}|} \sum_{i=1}^{|\mathbb{C}|} \frac{\boldsymbol{A}_{ii}}{2 |C_i|}.$$

    \item \textit{Bi-directional ratio:} Proportion of cluster pairs that are both cause and effect of one another.  
    $$\frac{2}{|\mathbb{C}|^2 - |\mathbb{C}|} \sum_{i=1}^{|\mathbb{C}|-1} \sum_{j=i+1}^{|\mathbb{C}|} \frac{\min (\boldsymbol{A}_{ij}, \boldsymbol{A}_{ji})}{\max (\boldsymbol{A}_{ij}, \boldsymbol{A}_{ji})}.$$

    \item \textit{Silhouette coefficient \citep{rousseeuw1987silhouettes}:}  Measure of how similar an instance is to its own cluster (cohesion) compared to other clusters (separation). A high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.  
    $$\frac{1}{|\mathcal{D}|} \sum_{x \in \mathcal{D}} \frac{a_x - b_x}{1 - \min(a_x,b_x)},$$
    
    where $a_x$ is the mean similarity between event $x$ and all other events in the same cluster; $b_x$ is the mean similarity between event $x$ and all other events in the next nearest cluster.

    \item \textit{Homogeneity score:} Average pairwise similarity of events in a cluster.
    $$\frac{1}{|\mathbb{C}|} \sum_{i=1}^{|\mathbb{C}|} \frac{2}{|C_i|^2-|C_i|}\sum_{x,y \in C_i, x \ne y}S_{xy},$$
    
    where $S_{xy}$ is the similarity score between two events according to Eq. (\ref{eq:sim}).
\end{enumerate}

Table \ref{tab:clustering_abs} reports the numerical results for the experiment on Abstract Event Identification in Section \ref{sec:abstraction_exp}. For the supervised metrics, we refer readers to \href{https://scikit-learn.org/stable/modules/clustering.html}{\texttt{scikit-learn}'s} documentation for the precise formulations and implementations of \textit{Adjusted Rand Index} \citep{steinley2004properties} and \textit{Normalized Mutual Information} \citep{vinh2009information}. 

\begin{table*}[hbt!]
\centering
% \resizebox{\columnwidth}{!}{
\begin{tabular}{l|r r r r}
\toprule
Metrics       & \textbf{LOUVAIN} & \textbf{LEIDEN} & \textbf{OPTICS} & \textbf{PIVOT}   \\
\midrule
Bi-directional ratio $\downarrow$               & $0.179$    & $0.162$   & $0.011$   & $\mathbf{0.004}$  \\
Self-loop ratio    $\downarrow$                & $0.252$    & $0.361$   & $0.007$   & $\mathbf{0.001}$  \\
Silhouette coefficient (Euclidean) $\uparrow$ & $-0.120$   & $-0.137$  & $-0.252$  & $\mathbf{-0.015}$ \\
Silhouette coefficient (Cosine) $\uparrow$    & $-0.234$   & $-0.262$  & $-0.392$  & $\mathbf{-0.036}$ \\
Homogeneity score $\uparrow$  & $0.506$  & $0.577$  & $0.810$   & $\mathbf{0.907}$ \\ 
\bottomrule
\end{tabular}
% }
\caption{Evaluation of alternative clustering algorithms. \textbf{Bold} indicates best performance. $\uparrow$ Higher is better. $\downarrow$ Lower is better.} \label{tab:clustering}
\end{table*}


\begin{table*}[hbt!]
    \centering
   % \resizebox{\columnwidth}{!}{
\begin{tabular}{l|r r r r}
\toprule
Metrics       & \textbf{LOUVAIN} & \textbf{LEIDEN} & \textbf{OPTICS} & \textbf{PIVOT}$^{(*)}$   \\
\hline
\multicolumn{5}{c}{\cellcolor[HTML]{C0C0C0}\textbf{Generalizations from \texttt{GPT-4o-mini}}} \\ \toprule
% Silhouette coefficient (Euclidean) $\uparrow$               & $-0.0139$    & $0.0005$   & $-0.1321$   & $\mathbf{0.0173}$          \\
% Silhouette coefficient (Cosine)   $\uparrow$            & $-0.0531$    & $-0.0255$   & $-0.2168$   & $\mathbf{0.0137}$  \\
Adjusted rand index $\uparrow$               & $0.016$    & $0.018$   & $0.001$   & $\mathbf{0.168}$  \\
Normalized mutual information $\uparrow$               & $0.450$    & $0.463$   & $0.384$   & $\mathbf{0.784}$  \\

\hline
\multicolumn{5}{c}{\cellcolor[HTML]{C0C0C0}\textbf{Generalizations from \texttt{GLUCOSE}}} \\ \toprule
% Silhouette coefficient (Euclidean) $\uparrow$               & $0.1315$    & $\mathbf{0.1331}$   & $0.0430$   & $0.0946$          \\
% Silhouette coefficient (Cosine)   $\uparrow$            & $0.1946$    & $\mathbf{0.1976}$   & $0.0691$   & $0.1302$  \\
Adjusted rand index $\uparrow$               & $0.042$    & $0.045$   & $0.011$   & $\mathbf{0.347}$  \\
Normalized mutual information $\uparrow$               & $0.635$    & $0.639$   & $0.699$   & $\mathbf{0.869}$  \\

\bottomrule
\end{tabular}
% }
    \caption{Experimental results of using automatic clustering for identifying abstractions using generalizations by \texttt{ChatGPT} and human-annotated generalizations from \texttt{GLUCOSE}.  (*) In this experiment, we use the original implementation of the \texttt{PIVOT} algorithm in \citet{fukunaga2019lp}. \textbf{Bold} indicates best performance.}
    \label{tab:clustering_abs}
\end{table*}

% Note that the Silhouette coefficients are different from Table \ref{tab:clustering} since we do not consider causal relations during clustering, which are assumed unknown.

