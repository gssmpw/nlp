\begin{figure*}[htb]
    \centering
    \includegraphics[width=\linewidth]{figures/pipeline.pdf}
    \caption{Pipeline of abstract causal event discovery. An event is viewed from three hierarchical levels: \textbf{mention} (realization in a specific text corpus), \textbf{generalization} (conceptualization of the event's components) 
    and \textbf{abstraction} (group of causally consistent generalizations). Given a collection of event mentions, Phase $1$ produces a collection of abstractions $A, B,C$ that are mapped back to the original corpus to construct a suitable representation in Phase $2$, such as a co-occurrence matrix. Causal discovery algorithms can then be employed to detect causal relations within the data, which may consider the contexts.}
    \label{fig:main}
\end{figure*}


Commonsense causal reasoning plays a vital role in developing a mental model of reality, where the ability to discover, explain and predict causal relations between events or forces in the environment is fundamental to human planning and control \citep{johnson2017mental, griffiths2017formalizing}. Cognitive science studies further suggest that event causality is critical to human understanding of narratives \citep{van1996children,fletcher1988causal,tillman2020children,sun2023event}, and story events with more causal relations tend to be better memorized than those with fewer relations \citep{graesser200310}. Humans are able to construct a causal mental model of events after reading a set of stories~\citep{zwaan1995construction}. For example, in Figure \ref{fig:main}, a reader would easily identify a causal relation between $e1:$ ``A person needs money.'' and $e2:$ ``A person gets a job.'' by \textit{abstracting} away concrete details, such as mentions of particular entities, grouping linguistic variations of the same meanings, and observing that $e1$ almost always leads to $e2$ in multiple stories, without explicit presence of lexical cues (e.g. \textit{because}) in text. Thus, it would be interesting to investigate to what extent LLMs can reason causally on the abstraction level.

This paper focuses on \textit{causal discovery}, a lower-level task of causal reasoning, which involves identifying and extracting causal relations from available data ~\citep{yang2022survey,tan2022eventPear}. In NLP, these tasks are pertinent to information extraction, aiming to discern causal relations between event mentions and cause/effect text spans within the text. There is a great number of datasets for assessing causal discovery capabilities that consists of human-annotated causal relations.  Early benchmarks include \texttt{TempEval-3} \cite{mirza2014annotating}, \texttt{CATENA} \cite{mirza2016catena}, \texttt{Causal-TimeBank} \cite{mirza-tonelli-2014-analysis}, \texttt{BECauSE} \cite{dunietz2015annotating, dunietz2017because} and \texttt{Event StoryLine Corpus} \cite{caselli2017event}. At a high level, existing annotation schemes share a similar mechanism to detect the presence of event causal relations. They exploit event temporal links in previous annotations \cite{pustejovsky2003timebank, pustejovsky2006timebank} and/or lexical cues that signal causal information, including, but not limited to, prepositions e.g. \textit{because of, by, due to}, conjunctions/conjunctive adverbs e.g. \textit{because, since, therefore, as a result} or verb semantics \cite{wolff2003models, mirza-tonelli-2014-analysis} such as causation e.g. \textit{cause, force}; enablement e.g. \textit{enable, make} or prevention e.g. \textit{prevent, block}. As a result, there has been criticism regarding the susceptibility of these models to exploiting the linguistic cues to attain high performance without engaging in actual causal reasoning
\citep{yang2022survey,li2022counterfactual}.

\Vy{What abstraction can help but IE cannot do}

\Vy{grounding, groupings/abstraction so statistical causal discovery can be done}

On one hand, abstraction of causal events, which omit concrete spurious details, would be a potential approach to reducing the possibility of LLMs relying on memorization or knowledge retrieval for inference. It has also been suggested that effective causal reasoning requires models to learn suitable abstract representation of the world \citep{girju2003automatic}. On the other hand, causality theories~\citep{pearl2009causality} provide a theoretical underpinning for causal reasoning and formal analysis of causal relations. Most algorithms exploit structural information in \textit{causal graphs}, which combine causal relations into logically coherent directed acyclic graphs (DAGs). In a causal graph, a node $v_i$ denotes a random variable, while an edge from $v_i$ to $v_j$ indicates $v_i$ is a direct cause of $v_j$. Theoretically grounded causal discovery ~\cite{vowels2022d} enables construction of causal graphs from a set of random variables using statistics collected from a dataset, without relying on lexical cues. 

Despite the prevalence of large-scale causal reasoning benchmarks, namely \texttt{COPA} \citep{roemmele2011choice}, \texttt{MAVEN-ERE} \citep{wang-etal-2022-maven}, \texttt{e-CARE} \citep{du-etal-2022-e}, 
there exists a lack of benchmarks that can (1) evaluate causal discovery of event abstractions and (2) construct commonsense causal graphs from a collection of documents. \texttt{ATOMIC} \cite{sap2019atomic,hwang2021comet} is a popular general-purpose commonsense knowledge graph that also provides causal relations between events. \citet{he2022acquiring} later build an event conceptualization pipeline on top of \texttt{ATOMIC}, wherein textual entities mentioned in an event are replaced with corresponding abstract concepts. However, these causal relations are harvested by crowd-sourcing, thus it is challenging to recover the grounded contexts and map events to random variables in order to apply statistical causal discovery. Two additional resources for constructing causal graphs from a collection of documents are \texttt{CauseNet} \citep{heindorf2020causenet} and \texttt{CRAB} \cite{romanou2023crab}. 
The causal relations from \texttt{CauseNet} are explicitly mentioned in texts while causal semantics can exist beyond lexical mentions. \texttt{CRAB} generates causal graphs from events extracted from online news articles. Neither \texttt{CauseNet} or \texttt{CRAB} provides abstraction of events or grouping of semantically equivalent events with linguistic variations. Therefore, the resulting graphs over fine-grained events can explode in size, posing severe computational difficulties.  Another related resource is \texttt{GLUCOSE} \cite{mostafazadeh-etal-2020-glucose}, which translates natural language expressions of event mentions and their relations into generic inferential rules dependent on story contexts. In those rules, entities are mapped to generalized concepts and the same keywords are used for the same relations, such as \textit{causes}. Although \texttt{GLUCOSE} lacks the inter-connection of relations into a logically coherent causal graph, our paper demonstrates how such a dataset as \texttt{GLUCOSE} can be utilized to construct abstract knowledge graphs of causality.

\paragraph{Contribution.}
We introduce \textbf{ACCESS}, a benchmark for \underline{\textbf{A}}bstra\underline{\textbf{C}}t \underline{\textbf{C}}ausal \underline{\textbf{E}}vent Di\underline{\textbf{S}}covery and Rea\underline{\textbf{S}}oning. We propose to explore event causality at the abstraction level as a more efficient representation of knowledge. 
We introduce a reproducible pipeline (See Figure \ref{fig:main}) to curate causal relations from a large corpus of stories of daily life events. The resulting benchmark, \texttt{ACCESS}, is a graphical modelling of causal relations of $725$ event abstractions forming a base of abstract commonsense knowledge of causation. Our benchmark also includes annotations to evaluate each step of the pipeline. Using \texttt{ACCESS}, our experiments shed light on the ongoing challenges within the field. 

Firstly, the application of statistical structure learning algorithms for full graph discovery remains highly challenging. Secondly, solely relying on LLMs and automatic clustering proves insufficient for adequate event abstraction. Thirdly, LLMs still struggle with pairwise non-contextual causal discovery, indicating a gap in their possession of complete commonsense causal knowledge. Lastly, incorporating abstract commonsense knowledge through a causal graph enhances Question Answering (QA) reasoning tasks in LLMs.  

\Vy{Add numerical results about improvement}

Learning 
\Vy{Traditional causal discovery made from scratch}

% A benchmark that provides (1) causal relations of abstract events inter-connected in a causal graph that comes with grounded contexts to facilitate algorithmic causal discovery.  

% In particular, our work is the first one that combines abstract reasoning with causal discovery. The abstraction is at the event level. NOT at the concept level, which is another difference to CauseNet. To enable the evaluation of statistical causal discovery algorithms, we need to map paraphases or semantic similar event mentions to the same entity, namely a random variable, at an appropriate level of abstraction. It is not possible for ATOMIC and CauseNet, because both paraphrases and semantically similar event mentions are not handled.

% To sum up, both ATOMIC and CauseNet cannot serve the main goal of our work, which aims to evaluate both NLP driven or statistical causal discovery algorithms based on texts
