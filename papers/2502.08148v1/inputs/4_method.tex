\texttt{ACCESS} provides a graphical modelling of the cause-and-effect relations among event abstractions, where every node in the causal graph represents an event abstraction in the causal relation between any two nodes is represented by an arrow going from the \textit{cause} event abstraction to the \textit{effect} event abstraction. There are $725$ abstractions or clusters, each of which on average contains $7$ instances, and in total associated with $9,513$ stories in the \texttt{GLUCOSE} dataset. The graph also contains diverse causal structures for causal inference, including confounding, mediation and collider \citep{pearl2009causality}. See Table \ref{tab:example} for examples of pairs of causal abstract events and Table \ref{tab:stats} for the descriptive statistics of \texttt{ACCESS}.

\begin{table}[h!]
    \centering
    \begin{tabular}{l|c c c r}
    \hline
    % \noalign{\hrule height 2pt}
    \multicolumn{5}{c}{\cellcolor[HTML]{C0C0C0}\textbf{Story corpus}}            \\ 
    \toprule
         Stories & & & & $9,513$  \\
         Events & & & & $4,708$  \\
         \hline
     \multicolumn{5}{c}{\cellcolor[HTML]{C0C0C0}\textbf{Causal graph}}            \\ \toprule
         Nodes (clusters / abstractions) & & & &  $725$  \\
         Edges (causal pairs) & & & &  $1,494$  \\ 
         Expected degree per node & & & &  $4$ \\
         Confounders & & & &  $149$  \\
         Mediators & & & &  $368$  \\
         Colliders & & & &  $3,956$  \\
         \bottomrule
    \end{tabular}
    \caption{General descriptive statistics of \texttt{ACCESS}.}
    \label{tab:stats}
\end{table}

Figure \ref{fig:main} illustrates our proposed pipeline for performing abstract causal event discovery and reasoning. The \texttt{ACCESS} dataset is constructed in the two phases: \textbf{Phase (1)} is to extract event abstractions from a collection of event mentions, by \textit{grouping mentions whose generalizations describing the same event} in a way that the resulting abstraction satisfies the above quality criteria. \textbf{Phase (2)} is to identify the causal relations among these event abstractions. Both phases entail an alternation between using automatic algorithms for extracting candidate clusters/causal pairs and crowd-sourcing for refinement and quality control. We briefly describe each phase in the following sections. See Appendix \ref{sup:annotation} for more details on our crowd-sourcing pipeline and task descriptions.

\subsection{Abstract Event Extraction}\label{sec:abstraction}
We now describe the process of curating these event mentions and extracting event abstractions. Our source of commonsense knowledge is \texttt{GLUCOSE} \citep{mostafazadeh-etal-2020-glucose}, a large-scale dataset of over $670$K stories with annotated causal relations. \texttt{GLUCOSE} also provides generalized inference rules mapped from specific statements, which correspond to our concept of event mentions.\footnote{For example, a specific statement $A \ neighbor \ knocked \ down \ my \ snowman$  is generalized into $Someone_{A} \ knocks \ down \ Something_{A}$.} We make use of the generalized expressions for our abstraction procedure and focus only on dimensions $1$ and $6$ of causal explanations: the direct effect. For simplicity, we will from now on refer to these generalizations as \textbf{events}. 

\paragraph{Automatic extraction.} Two or more event mentions must describe the same event to be clustered together. To describe the same event means they must be \textit{semantically related} or \textit{similar}. We initially apply standard text preprocessing and subsequently implement correlation clustering \citep{bansal2004correlation,charikar2005clustering} to automatically group events with shared semantics. We adopt an algorithm akin to the \texttt{PIVOT} algorithm \citep{fukunaga2019lp} that aims to maximize the semantic similarity of events in each cluster. We propose to measure semantic similarity by two metrics: \textit{cosine similarity} and \textit{paraphrasing likelihood}. The pairwise similarity of two expressions $x,y$ is given by
\begin{equation}\label{eq:sim}
   \mathcal{S}_{xy}= 0.5 \times \big[ f_{cos} (x, y) + f_{phr} (x, y)\big], 
\end{equation}
where $\mathcal{S}_{xy} \in [0,1]$, $f_{cos}$ returns the cosine similarity of the contextual embeddings of expressions $x,y$, and $f_{phr}$ returns the probability events $x,y$ are paraphrases. If $x,y$ are causally related, based on the annotations in \texttt{GLUCOSE},  $\mathcal{S}_{xy} = 0$. The contextual embeddings are obtained from the pre-trained \texttt{all-MiniLM-L6-v2} sentence Transformers \citep{reimers-2020-multilingual-sentence-bert} while the paraphrasing likelihood is obtained from the pre-trained adversarial paraphrase detector by \citet{nighojkar-licato-2021-improving}. 

Appendix \ref{sup:clustering} presents details of our clustering algorithm, which contains an ablation study against other popular clustering algorithms on unsupervised and supervised metrics to show that our \texttt{PIVOT} algorithm is preferable. In summary, the algorithm begins with a randomly chosen cause-effect pair of events as pivots. For each of these nodes, it finds the neighbors with which the similarity score exceeds $70\%$. The process is repeated for the remaining events until all events are clustered. Events that do not belong to any clusters are temporarily discarded. To ensure \textit{causal consistency}, we perform post-processing by splitting each cluster in a way that (1) no events in the same cluster are causally related, and (2) there exists either no or only one causal relations between any two clusters. 


\paragraph{Human annotation.} We then utilize $10$ human annotators to assess the quality of cluster assignment as well as determine the abstract expression (or ``topic" in laymen term) for each cluster. This involves five key steps. First, the annotators are required to perform sub-clustering out of the clusters formed in the previous step. To strictly guarantee that events grouped together share the same semantics and maximize annotation consistency, we outline $11$ scenarios where word uses convey differences in meaning. Next, for each newly formed sub-cluster, they are also asked to identify the ``topic", which subsequently serves as an event abstraction. We then conduct three additional steps to resolve the disagreements in annotation as well as to handle the outlier events that are temporarily removed after the automatic procedure. Appendix \ref{sup:annotation_ph1} details this annotation process.

\subsection{Causal Relations Discovery}
This phase aims to identify the causal relations among the abstract events extracted from the previous phase, based on both non-contextual and contextual commonsense knowledge.  

\paragraph{Automatic causal discovery.}
To identify candidate causal pairs of event abstractions, we use a combination of existing annotated relations in \texttt{GLUCOSE} and statistical causal discovery methods. Regarding \texttt{GLUCOSE}, we determine the causal relation of two event abstractions (clusters) based on criterion $\#5$ in the above list of quality criteria. Regarding statistical causal discovery, we construct a dataset where each observation is a document or story in the \texttt{GLUCOSE} corpus and each feature records the counts of occurrences (or mentions) of a cluster in a story. On this co-occurrence data matrix, we run the well-known \texttt{PC} algorithm\footnote{a constraint-based structure learning method based on conditional independence tests.} \citep{spirtes2000causation} to obtain more causal candidates, using G-squared and Chi-squared tests at $p$-value of $0.01$. Note that we intentionally avoid using NLP models for event causality identification to avoid potential biases from their training data.  

\paragraph{Human annotation.} We proceed with human annotation on the union of the causal candidates from the above step. There are $3$ annotators participating in this task. They are asked to categorize each candidate causal pair $A$ and $B$ into three scenarios: $A$ \textit{causes} $B$, $B$ \textit{causes} $A$, or $A$ and $B$ have no relation. Initially, the workers are tasked with annotating the causal relations without considering contexts, that is to solely rely on their commonsense about the abstractions. Subsequently, we identify the causal pairs with no consensus from the three workers. We provide the story contexts in \texttt{GLUCOSE} associated with each of these pairs and ask them to reevaluate their annotations. Out of $2,862$ candidate pairs detected from \texttt{GLUCOSE}, $39.6\%$ of them are humanly annotated to be truly causal while that number is $61.5\%$ within \texttt{PC} candidates. The final relation of each pair is decided through majority voting. The inter-rate agreement score (Krippendorffâ€™s $\alpha$) is $77.2\%$. See Appendix \ref{sup:annotation_ph2} for details.

