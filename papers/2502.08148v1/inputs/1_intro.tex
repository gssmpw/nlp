\begin{figure*}[htb]
    \centering
    \includegraphics[width=\linewidth]{figures/pipeline.pdf}
    \caption{Pipeline of abstract causal event discovery. An event is viewed from three hierarchical levels: \textbf{mention} (realization in a specific text corpus), \textbf{generalization} (conceptualization of the event's components) 
    and \textbf{abstraction} (group of causally consistent generalizations). Given a collection of event mentions, Phase $1$ produces a collection of abstractions $A, B,C$ that are mapped back to the original corpus to construct a suitable representation in Phase $2$, such as a co-occurrence matrix. Causal discovery algorithms can then be employed to detect causal relations within the data, which may consider the contexts.}
    \label{fig:main}
\end{figure*}


Commonsense causal reasoning plays a vital role in developing a mental model of reality, where the ability to discover, explain and predict causal relations between events or forces in the environment is fundamental to human planning and control \citep{johnson2017mental, griffiths2017formalizing}. Cognitive science studies further suggest that event causality is critical to human understanding of narratives \citep{van1996children,fletcher1988causal,tillman2020children,sun2023event}, and story events with more causal relations tend to be better memorized than those with fewer relations \citep{graesser200310}. Humans are able to construct a causal mental model of events after reading a set of stories~\citep{zwaan1995construction}. For example, in Figure \ref{fig:main}, a reader would easily identify a causal relation between $e1:$ ``A person needs money.'' and $e2:$ ``A person gets a job.'' by \textit{abstracting} away concrete details, such as mentions of particular entities, grouping linguistic variations of the same meanings, and observing that $e1$ almost always leads to $e2$ in multiple stories, without explicit presence of lexical cues (e.g. \textit{because}) in text. Thus, this paper focuses on investigating to what extent LLMs can identify causal relations \textit{without relying on linguistic cues} and perform causal reasoning over commonsense knowledge on the abstraction level.

Prior works on \textit{causal relation extraction} heavily rely on linguistic cues, e.g. \textit{because of, by, due to}, to discern causal relations between event mentions and cause/effect text spans within a text~\cite{wolff2003models, mirza-tonelli-2014-analysis}. In contrast, statistical \textit{causal discovery} methods for event causality do not require linguistic cues but exploit statistical information of symbolic representations of events~\cite{pearl2018book}. As a result, those approaches are able to find causal relations even when they are not explicitly mentioned anywhere in texts. Therefore, there has been criticism regarding the susceptibility of these causal relation extraction models to exploit the linguistic cues to attain high performance without engaging in actual causal reasoning
\citep{yang2022survey,li2022counterfactual}. Ample of causal relation extraction datasets, including \texttt{TempEval-3} \cite{mirza2014annotating}, \texttt{CATENA} \cite{mirza2016catena}, \texttt{Causal-TimeBank} \cite{mirza-tonelli-2014-analysis}, \texttt{BECauSE} \cite{dunietz2015annotating, dunietz2017because} and \texttt{Event StoryLine Corpus} \cite{caselli2017event}, are not suitable for evaluating statistical causal discovery methods, because mentions of causal events that are semantically similar but expressed in different linguistic forms are not mapped into the same symbols. %At a high level, existing annotation schemes share a similar mechanism to detect the presence of event causal relations. They exploit event temporal links in previous annotations \cite{pustejovsky2003timebank, pustejovsky2006timebank} and/or lexical cues that signal causal information, including, but not limited to, prepositions e.g. \textit{because of, by, due to}, conjunctions/conjunctive adverbs e.g. \textit{because, since, therefore, as a result} or verb semantics \cite{wolff2003models, mirza-tonelli-2014-analysis} such as causation e.g. \textit{cause, force}; enablement e.g. \textit{enable, make} or prevention e.g. \textit{prevent, block}. 



Humans identify grouping of semantic similar event mentions via \textit{abstraction}, which omits concrete spurious details. It has also been suggested that effective causal reasoning requires models to learn suitable abstract representation of the world \citep{girju2003automatic}. Abstraction of events can well leverage causality theories~\citep{pearl2009causality}, which provide a theoretical underpinning for causal reasoning and formal analysis of causal relations. Given a set of random variables, theoretically grounded causal discovery algorithms~\cite{vowels2022d} use statistics collected from a dataset to construct \textit{causal graphs}, which combine causal relations into logically coherent directed acyclic graphs (DAGs). In a causal graph, a node $v_i$ denotes a random variable, while an edge from $v_i$ to $v_j$ indicates $v_i$ is a direct cause of $v_j$. To the best of our knowledge, none of the existing datasets, such as \texttt{COPA} \citep{roemmele2011choice} and \texttt{MAVEN-ERE} \citep{wang-etal-2022-maven}, %\texttt{e-CARE} \citep{du-etal-2022-e}, 
provide both abstraction of events grounded in a corpus and the corresponding causal graphs.


%There exists a lack of benchmarks that can (1) evaluate causal discovery of event abstractions grounded in a corpus, and (2) construct commonsense causal graphs from a collection of documents, despite the prevalence of large-scale causal reasoning benchmarks, namely \texttt{COPA} \citep{roemmele2011choice}, \texttt{MAVEN-ERE} \citep{wang-etal-2022-maven}, \texttt{e-CARE} \citep{du-etal-2022-e}. 
Existing knowledge graphs containing causal relations \cite{sap2019atomic,hwang2021comet,hassanzadeh2022knowledge,mbouadeu-etal-2023-evaluation}, cannot support evaluating both (1) event abstractions grounded in a corpus, and (2) construction of commonsense causal graphs from a collection of documents. % \citet{he2022acquiring} later build an event conceptualization pipeline on top of \texttt{ATOMIC}, wherein textual entities mentioned in an event are replaced with corresponding abstract concepts. 
The popular \texttt{ATOMIC} \citep{sap2019atomic} in particular is harvested by crowd-sourcing so that similar events in \texttt{ATOMIC} are not grouped together and there is also no associated corpus containing all relevant event mentions. As a result, it is challenging to recover the grounded contexts and map events to random variables in order to apply statistical causal discovery. Two additional resources for constructing causal graphs from a collection of documents are \texttt{CauseNet} \citep{heindorf2020causenet} and \texttt{CRAB} \cite{romanou2023crab}. 
The causal relations from \texttt{CauseNet} are explicitly mentioned in texts while causal semantics can exist beyond lexical mentions. \texttt{CRAB} generates causal graphs from events extracted from online news articles. Neither \texttt{CauseNet} or \texttt{CRAB} provides abstraction of events or grouping of semantically equivalent events with linguistic variations. Therefore, the resulting graphs over fine-grained events can explode in size, posing severe computational difficulties.  Another related resource is \texttt{GLUCOSE} \cite{mostafazadeh-etal-2020-glucose}, which translates natural language expressions of event mentions and their relations into generic inferential rules dependent on story contexts. In those rules, entities are mapped to generalized concepts and the same keywords are used for the same relations, such as \textit{causes}. Although \texttt{GLUCOSE} lacks grouping of similar abstract events and the inter-connection of relations into a logically coherent causal graph, our paper extends this dataset to construct abstract knowledge graphs of causality.

\paragraph{Contribution.}
We introduce \textbf{ACCESS}, a benchmark for \underline{\textbf{A}}bstra\underline{\textbf{C}}t \underline{\textbf{C}}ausal \underline{\textbf{E}}vent Di\underline{\textbf{S}}covery and Rea\underline{\textbf{S}}oning. We propose to explore event causality at the abstraction level as a more efficient representation of knowledge. 
We introduce a reusable pipeline (See Figure \ref{fig:main}) to curate causal relations from a large corpus of stories of daily life events. The resulting benchmark, \texttt{ACCESS}, is a graphical modelling of causal relations of $725$ event abstractions forming a base of abstract commonsense knowledge of causation. Our benchmark also includes annotations to evaluate each step of the pipeline. Using \texttt{ACCESS}, our experiments shed light on the ongoing challenges within the field. 

Firstly, the application of statistical structure learning algorithms for full graph discovery remains highly challenging. Secondly, solely relying on LLMs and automatic clustering proves insufficient for adequate event abstraction. Thirdly, LLMs still struggle with pairwise non-contextual causal discovery, indicating a gap in their possession of complete commonsense causal knowledge. Lastly, incorporating abstract commonsense knowledge through a causal graph enhances Question Answering (QA) reasoning tasks in LLMs up to $20\%$.  
