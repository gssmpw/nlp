\documentclass[11pt]{article}
\usepackage{latex/acl}
\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{algorithm,algpseudocode}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{color,soul}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xcolor}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}
\usepackage{efbox,graphicx}
\efboxsetup{linecolor=black,linewidth=2pt}

\input{math_commands}
\newcommand{\Vy}[1]{\textcolor{red}{Vy:~#1}}
\newcommand{\lizhen}[1]{{\textcolor{brown}{Lizhen:~#1}}}

\title{ACCESS : A Benchmark for \\ Abstract Causal Event Discovery and Reasoning}


\author{Vy Vo \quad Lizhen Qu \quad Tao Feng \quad Yuncheng Hua \quad Xiaoxi Kang\\
{\bf Songhai Fan \quad Tim Dwyer \quad Lay-Ki Soon \quad Gholamreza Haffari} \\
Monash University, Australia \\ 
\texttt{\{firstname.lastname\}@monash.edu}
}


\begin{document}
\maketitle
\begin{abstract}
  Identifying cause-and-effect relationships is critical to understanding real-world dynamics and ultimately causal reasoning. Existing methods for identifying event causality in NLP, including those based on Large Language Models (LLMs), exhibit difficulties in out-of-distribution settings due to the limited scale and heavy reliance on lexical cues within available benchmarks. Modern benchmarks, inspired by probabilistic causal inference, have attempted to construct causal graphs of events as a robust representation of causal knowledge, where \texttt{CRAB} \citep{romanou2023crab} is one such recent benchmark along this line. In this paper, we introduce \texttt{ACCESS}, a benchmark designed for discovery and reasoning over abstract causal events. Unlike existing resources, \texttt{ACCESS}  focuses on causality of everyday life events on the abstraction level. We propose a pipeline for identifying abstractions for event generalizations from \texttt{GLUCOSE} \citep{mostafazadeh-etal-2020-glucose}, a large-scale dataset of implicit commonsense causal knowledge, from which we subsequently extract $1,4$K causal pairs. Our experiments highlight the ongoing challenges of using statistical methods and/or LLMs for automatic abstraction identification and causal discovery in NLP. Nonetheless, we demonstrate that the abstract causal knowledge provided in \texttt{ACCESS} can be leveraged for enhancing QA reasoning performance in LLMs.
\end{abstract}



% \iftaclpubformat
\section{Introduction}
\input{inputs/1_intro}



\section{Causal Event Abstraction}\label{sec:setup}
\input{inputs/3_setup}


\section{The ACCESS Benchmark}
\input{inputs/4_method}


\section{Experiments}\label{sec:exp}
\input{inputs/5_experiment}

\section{Conclusion}
\input{inputs/6_cls_limit_ethics}

\section*{Acknowledgment}
This material is based on research sponsored by DARPA under agreement number HR001122C0029. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon This work is also partially supported by the DARPA Assured Neuro Symbolic Learning and Reasoning (ANSR) program under award number FA8750-23-2-1016.

\bibliography{ref}
\clearpage

\appendix

\section{Related Work}
\input{inputs/2_related_work}

\section{Data Annotation Pipeline}\label{sup:annotation}
\input{inputs/A_annotation}


\section{Clustering Algorithm}\label{sup:clustering}
\input{inputs/B_clustering}

% \section{Causal Network Visualization Tool}
% \input{inputs/C_visualization}

\input{inputs/D_extra_experiment}





\end{document}


