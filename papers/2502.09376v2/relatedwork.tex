\section{Prior works}
\label{sec::1.1} 
\paragraph{PEFT methods and LoRA}
Parameter-Efficient Fine-tuning (PEFT) methods have emerged as effective approaches for fine-tuning large language models on downstream tasks while reducing computational and storage requirements. Among numerous proposed methods \cite{ben-zaken-etal-2022-bitfit,li-liang-2021-prefix,lester-etal-2021-power}, Low-Rank Adaptation (LoRA) \cite{hu2022lora} has become a predominant approach by decomposing weight updates into low-rank matrices. Several variants have been built upon the LoRA framework \cite{dettmers2023qlora,wang2024loraprolowrankadaptersproperly,liu2024dora}, addressing the discrepancy with full fine tuning in optimization and performance.

\paragraph{Theoretical foundation of LoRA.}
Existing theoretical works on LoRA focus on the expressive power and the training dynamics of LoRA.  \citet{zeng2024the} demonstrates that a certain LoRA rank suffices to express a given fine-tuning function. \citet{jang2024lora} proves that under the NTK regime, LoRA with rank $\Omega (\sqrt{N})$ can express the global minimizer of the original model. \citet{pmlr-v202-malladi23a} argues that the LoRA fine-tuning dynamics are nearly equivalent to the kernel regression. Under this framework, \citet{jang2024lora} proves LoRA fine tuning loss has no spurious local minima when the rank is $O(\sqrt{N})$. Beyond the kernel regime, \citet{dayi2024gradient} analyzes a two-layer teacher-student setup for LoRA and explains why SGD leads to convergence to a global minimum in this context.








\paragraph{Low-rank optimization.}
The low-rank optimization problem 
\vspace{-0.2in}
\begin{align*}
    \min_{X\in \mathbb{R}^{m\times n}, \,\mathrm{rank}(X)\le r} f(X)
\end{align*}
has been extensively studied in the optimization literature, including matrix sensing  \cite{doi:10.1137/070697835} and matrix completion \cite{10.1145/2184319.2184343}. 
Rather than directly optimizing over the space of low-rank matrices, it is often preferred to employ the Burer-Monteiro factorization\cite{Burer2003ANP}, which formulates the problem by parameterizing $X$ as $X=UV^\intercal$, $U\in \mathbb{R}^{m\times r}, V\in \mathbb{R}^{n\times r}$.




As the Burer-Monteiro factorization introduces nonconvexity, a large body of work has identified conditions under which this approach avoids spurious local minima \cite{NIPS2016_b139e104,10.5555/3305381.3305509,pmlr-v54-park17a,zhang2021sharpglobalguaranteesnonconvex}. Further studies extend these results to general settings \cite{doi:10.1137/18M1231675,zhang2024improved}. In our work, we utilize the framework established in these studies with novel techniques to extend its boundary to optimization guarantees in LoRA training.