@article{MENG201548,
title = {Simulation and optimization of HPC job allocation for jointly reducing communication and cooling costs},
journal = {Sustainable Computing: Informatics and Systems},
volume = {6},
pages = {48-57},
year = {2015},
note = {Special Issue on Selected Papers from 2013 International Green Computing Conference (IGCC)},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2014.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2210537914000237},
author = {Jie Meng and Samuel McCauley and Fulya Kaplan and Vitus J. Leung and Ayse K. Coskun},
keywords = {High-performance computing, Data center, Job allocation, Joint optimization, Cooling energy, Communication cost},
abstract = {Performance and energy are critical aspects in high performance computing (HPC) data centers. Highly parallel HPC applications that require multiple nodes usually run for long durations in the range of minutes, hours or days. As the threads of parallel applications communicate with each other intensively, the communication cost of these applications has a significant impact on data center performance. Energy consumption has also become a first-order constraint of HPC data centers. Nearly half of the energy in the computing clusters today is consumed by the cooling infrastructure. Existing job allocation policies either target improving the system performance or reducing the cooling energy cost of the server nodes. How to optimize the system performance while minimizing the cooling energy consumption is still an open question. This paper proposes a job allocation methodology aimed at jointly reducing the communication cost and the cooling energy of HPC data centers. In order to evaluate and validate our optimization algorithm, we implement our joint job allocation methodology in the structural simulation toolkit (SST) – a simulation framework for large-scale data centers. We evaluate our joint optimization algorithm using traces extracted from real-world workloads. Experimental results show that, in comparison to performance-aware job allocation algorithms, our algorithm achieves comparable running times and reduces the cooling power by up to 42.21% across all the jobs.}
}
@inproceedings{Evans2009TheLH,
  title={The large hadron collider : a marvel of technology},
  author={Lyndon R. Evans},
  year={2009},
  url={https://api.semanticscholar.org/CorpusID:118322688}
}
@article{Benacchio07Grid,
author = {Benacchio, Leopoldo and Pasian, Fabio},
year = {2007},
month = {01},
pages = {},
title = {Grid-enabled Astrophysics}
}
@article{Au2009Grid,
author = {Au, Loretta},
year = {2009},
month = {03},
pages = {85-86},
title = {Grid Computing for Bioinformatics and Computational Biology},
volume = {84},
journal = {Quarterly Review of Biology - QUART REV BIOL},
doi = {10.1086/598260}
}
@article{Renard09Grid,
author = {Renard, Philippe and Badoux, Vincent and Petitdidier, Monique and Cossu, Roberto},
year = {2009},
month = {04},
pages = {},
title = {Grid Computing for Earth Science},
volume = {90},
journal = {Eos, Transactions American Geophysical Union},
doi = {10.1029/2009EO140002}
}
@ARTICLE{Wang2023Coorperative,
  author={Wang, Haoyu and Liu, Guoxin and Shen, Haiying},
  journal={IEEE Transactions on Cloud Computing}, 
  title={Cooperative Job Scheduling and Data Allocation in Data-Intensive Parallel Computing Clusters}, 
  year={2023},
  volume={11},
  number={3},
  pages={2392-2406},
  keywords={Task analysis;Servers;Resource management;Schedules;Clustering algorithms;Processor scheduling;Costs;Job scheduler;data allocation;parallel computing;data locality},
  doi={10.1109/TCC.2022.3206206}}
@article{HUSSAIN2013709,
title = {A survey on resource allocation in high performance distributed computing systems},
journal = {Parallel Computing},
volume = {39},
number = {11},
pages = {709-736},
year = {2013},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2013.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S016781911300121X},
author = {Hameed Hussain and Saif Ur Rehman Malik and Abdul Hameed and Samee Ullah Khan and Gage Bickler and Nasro Min-Allah and Muhammad Bilal Qureshi and Limin Zhang and Wang Yongji and Nasir Ghani and Joanna Kolodziej and Albert Y. Zomaya and Cheng-Zhong Xu and Pavan Balaji and Abhinav Vishnu and Fredric Pinel and Johnatan E. Pecero and Dzmitry Kliazovich and Pascal Bouvry and Hongxiang Li and Lizhe Wang and Dan Chen and Ammar Rayes},
keywords = {Scheduling, Resource allocation, Resource management},
abstract = {An efficient resource allocation is a fundamental requirement in high performance computing (HPC) systems. Many projects are dedicated to large-scale distributed computing systems that have designed and developed resource allocation mechanisms with a variety of architectures and services. In our study, through analysis, a comprehensive survey for describing resource allocation in various HPCs is reported. The aim of the work is to aggregate under a joint framework, the existing solutions for HPC to provide a thorough analysis and characteristics of the resource management and allocation strategies. Resource allocation mechanisms and strategies play a vital role towards the performance improvement of all the HPCs classifications. Therefore, a comprehensive discussion of widely used resource allocation strategies deployed in HPC environment is required, which is one of the motivations of this survey. Moreover, we have classified the HPC systems into three broad categories, namely: (a) cluster, (b) grid, and (c) cloud systems and define the characteristics of each class by extracting sets of common attributes. All of the aforementioned systems are cataloged into pure software and hybrid/hardware solutions. The system classification is used to identify approaches followed by the implementation of existing resource allocation strategies that are widely presented in the literature.}
}
@inbook{Tyagi2018Survey,
author = {Tyagi, Rinki and Gupta, Santosh},
year = {2018},
month = {12},
pages = {51-64},
title = {A Survey on Scheduling Algorithms for Parallel and Distributed Systems},
isbn = {978-981-10-7655-8},
doi = {10.1007/978-981-10-7656-5_7}
}
@article{Graham1977OptimizationAA,
  title={Optimization and Approximation in Deterministic Sequencing and Scheduling: a Survey},
  author={Ron Graham and Eugene L. Lawler and Jan Karel Lenstra and Alexander H. G. Rinnooy Kan},
  journal={Annals of discrete mathematics},
  year={1977},
  volume={5},
  pages={287-326},
  url={https://api.semanticscholar.org/CorpusID:61033710}
}






@article{Du1989Complexity,
author = {Du, Jianzhong and Leung, Joseph Y.-T.},
title = {Complexity of Scheduling Parallel Task Systems},
journal = {SIAM Journal on Discrete Mathematics},
volume = {2},
number = {4},
pages = {473-487},
year = {1989},
doi = {10.1137/0402042},
URL = { 
        https://doi.org/10.1137/0402042
},
eprint = { 
        https://doi.org/10.1137/0402042
}
}

@article{Shmoys1993Approximation,
author = {Shmoys, David and Tardos, Eva},
year = {1993},
month = {02},
pages = {461-474},
title = {Approximation algorithm for the generalized assignment problem},
volume = {62},
journal = {Math. Program.},
doi = {10.1007/BF01585178}
}

@InProceedings{Phan05Co,
author="Phan, Thomas
and Ranganathan, Kavitha
and Sion, Radu",
editor="Feitelson, Dror
and Frachtenberg, Eitan
and Rudolph, Larry
and Schwiegelshohn, Uwe",
title="Evolving Toward the Perfect Schedule: Co-scheduling Job Assignments and Data Replication in Wide-Area Systems Using a Genetic Algorithm",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="173--193",
abstract="Traditional job schedulers for grid or cluster systems are responsible for assigning incoming jobs to compute nodes in such a way that some evaluative condition is met. Such systems generally take into consideration the availability of compute cycles, queue lengths, and expected job execution times, but they typically do not account directly for data staging and thus miss significant associated opportunities for optimisation. Intuitively, a tighter integration of job scheduling and automated data replication can yield significant advantages due to the potential for optimised, faster access to data and decreased overall execution time. In this paper we consider data placement as a first-class citizen in scheduling and use an optimisation heuristic for generating schedules. We make the following two contributions. First, we identify the necessity for co-scheduling job dispatching and data replication assignments and posit that simultaneously scheduling both is critical for achieving good makespans. Second, we show that deploying a genetic search algorithm to solve the optimal allocation problem has the potential to achieve significant speed-up results versus traditional allocation mechanisms. Through simulation, we show that our algorithm provides on average an approximately 20-45{\%} faster makespan than greedy schedulers.",
isbn="978-3-540-31617-6"
}
@article{TAHERI20131564,
title = {A Bee Colony based optimization approach for simultaneous job scheduling and data replication in grid environments},
journal = {Computers \& Operations Research},
volume = {40},
number = {6},
pages = {1564-1578},
year = {2013},
note = {Emergent Nature Inspired Algorithms for Multi-Objective Optimization},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2011.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0305054811003376},
author = {Javid Taheri and Young {Choon Lee} and Albert Y. Zomaya and Howard Jay Siegel},
keywords = {Bee colony optimization, Data replication, Grid computing, Job scheduling, Resource allocation},
abstract = {This paper presents a novel Bee Colony based optimization algorithm, named Job Data Scheduling using Bee Colony (JDS-BC). JDS-BC consists of two collaborating mechanisms to efficiently schedule jobs onto computational nodes and replicate datafiles on storage nodes in a system so that the two independent, and in many cases conflicting, objectives (i.e., makespan and total datafile transfer time) of such heterogeneous systems are concurrently minimized. Three benchmarks – varying from small- to large-sized instances – are used to test the performance of JDS-BC. Results are compared against other algorithms to show JDS-BC's superiority under different operating scenarios. These results also provide invaluable insights into data-centric job scheduling for grid environments.}
}
@article{TAHERI20131885,
title = {Hopfield neural network for simultaneous job scheduling and data replication in grids},
journal = {Future Generation Computer Systems},
volume = {29},
number = {8},
pages = {1885-1900},
year = {2013},
note = {Including Special sections: Advanced Cloud Monitoring Systems \& The fourth IEEE International Conference on e-Science 2011 — e-Science Applications and Tools \& Cluster, Grid, and Cloud Computing},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2013.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X13000800},
author = {Javid Taheri and Albert Y. Zomaya and Pascal Bouvry and Samee U. Khan},
keywords = {Job scheduling, Network aware scheduling, Data file migration policies, Grid environments},
abstract = {This paper presents a novel heuristic approach, named JDS-HNN, to simultaneously schedule jobs and replicate data files to different entities of a grid system so that the overall makespan of executing all jobs as well as the overall delivery time of all data files to their dependent jobs is concurrently minimized. JDS-HNN is inspired by a natural distribution of a variety of stones among different jars and utilizes a Hopfield Neural Network in one of its optimization stages to achieve its goals. The performance of JDS-HNN has been measured by using several benchmarks varying from medium- to very-large-sized systems. JDS-HNN’s results are compared against the performance of other algorithms to show its superiority under different working conditions. These results also provide invaluable insights into scheduling and replicating dependent jobs and data files as well as their performance related issues for various grid environments.}
}

@article{cplex2009v12,
  title={V12. 1: User’s Manual for CPLEX},
  author={Cplex, IBM ILOG},
  journal={International Business Machines Corporation},
  volume={46},
  number={53},
  pages={157},
  year={2009},
  publisher={Armonk, NY, USA}
}

@article{achterberg2009scip,
  title={SCIP: solving constraint integer programs},
  author={Achterberg, Tobias},
  journal={Mathematical Programming Computation},
  volume={1},
  pages={1--41},
  year={2009},
  publisher={Springer}
}
@misc{gurobi,
  author = {{Gurobi Optimization, LLC}},
  title = {{Gurobi Optimizer Reference Manual}},
  year = 2023,
  url = "https://www.gurobi.com"
}
@article{Wright2015CoordinateDA,
  title={Coordinate descent algorithms},
  author={Stephen J. Wright},
  journal={Mathematical Programming},
  year={2015},
  volume={151},
  pages={3 - 34},
  url={https://api.semanticscholar.org/CorpusID:15284973}
}
@article{sauer1993local,
  title={A local update strategy for iterative reconstruction from projections},
  author={Sauer, Ken and Bouman, Charles},
  journal={IEEE Transactions on Signal Processing},
  volume={41},
  number={2},
  pages={534--548},
  year={1993},
  publisher={IEEE}
}
@article{canutescu2003cyclic,
  title={Cyclic coordinate descent: A robotics algorithm for protein loop closure},
  author={Canutescu, Adrian A and Dunbrack Jr, Roland L},
  journal={Protein science},
  volume={12},
  number={5},
  pages={963--972},
  year={2003},
  publisher={Wiley Online Library}
}
@article{nesterov2012efficiency,
  title={Efficiency of coordinate descent methods on huge-scale optimization problems},
  author={Nesterov, Yu},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={341--362},
  year={2012},
  publisher={SIAM}
}
@inproceedings{martino2002scheduling,
author = {Martino, Vincenzo Di and Mililotti, Marco},
title = {Scheduling in a Grid Computing Environment Using Genetic Algorithms},
year = {2002},
isbn = {0769515738},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {We investigate the possibility to use the computing GRID in a flexible way to permit the maximum usage of resources. In our simulation the jobs submitted by the users provide a characterization of themself to help the system scheduler to do an optimal scheduling in case of resources contention. We use a genetic algorithms to select an optimal or suboptimal scheduling of the jobs. In this preliminary tests we show how the solution founded may maximize the total machine throughput considering not only the single job request but all the job requests during the scheduling process. In this work we show that it is possible to resolve conflicts in the usage of the total computing power and in the data locality for a reasonable number of jobs.},
booktitle = {Proceedings of the 16th International Parallel and Distributed Processing Symposium},
pages = {297},
series = {IPDPS '02}
}
@article{Xhafa2010Computational,
author = {Xhafa, Fatos and Abraham, Ajith},
year = {2010},
month = {04},
pages = {608-621},
title = {Computational models and heuristic methods for Grid scheduling problems},
volume = {26},
journal = {Future Generation Computer Systems},
doi = {10.1016/j.future.2009.11.005}
}
@inproceedings{martino02scheduling,
author = {Martino, Vincenzo Di and Mililotti, Marco},
title = {Scheduling in a Grid Computing Environment Using Genetic Algorithms},
year = {2002},
isbn = {0769515738},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {We investigate the possibility to use the computing GRID in a flexible way to permit the maximum usage of resources. In our simulation the jobs submitted by the users provide a characterization of themself to help the system scheduler to do an optimal scheduling in case of resources contention. We use a genetic algorithms to select an optimal or suboptimal scheduling of the jobs. In this preliminary tests we show how the solution founded may maximize the total machine throughput considering not only the single job request but all the job requests during the scheduling process. In this work we show that it is possible to resolve conflicts in the usage of the total computing power and in the data locality for a reasonable number of jobs.},
booktitle = {Proceedings of the 16th International Parallel and Distributed Processing Symposium},
pages = {297},
series = {IPDPS '02}
}
@article{Hussain22013resource,
author = {Hussain, Hameed and Malik, Saif Ur Rehman and Hameed, Abdul and Khan, Samee and Bickler, Gage and Min Allah, Nasro and Qureshi, Muhammad and Zhang, Limin and Wang, Yongji and Ghani, Nasir and Kołodziej, Joanna and Zomaya, Albert and Xu, Cheng-Zhong and Balaji, Pavan and Vishnu, Abhinav and Pinel, Frédéric and Pecero, Johnatan and Kliazovich, Dzmitry and Bouvry, Pascal and Rayes, Mark},
year = {2013},
month = {11},
pages = {709–736},
title = {A survey on resource allocation in high performance distributed computing systems},
volume = {39},
journal = {Parallel Computing},
doi = {10.1016/j.parco.2013.09.009}
}
@INPROCEEDINGS{wei2021joint1,
  author={Wei, Xinliang and Wang, Yu},
  booktitle={2021 IEEE/ACM 29th International Symposium on Quality of Service (IWQOS)}, 
  title={Joint Resource Placement and Task Dispatching in Mobile Edge Computing across Timescales}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  keywords={Heuristic algorithms;Simulation;Quality of service;Dynamic scheduling;Dispatching;Internet of Things;Servers;resource placement;task dispatching;reinforcement learning;mobile edge computing},
  doi={10.1109/IWQOS52092.2021.9521283}}

@article{wei2021joint2,
author = {Wei, Xinliang and Rahman, A and Cheng, Dazhao and Wang, Yu},
year = {2021},
month = {09},
pages = {1-1},
title = {Joint Optimization Across Timescales: Resource Placement and Task Dispatching in Edge Clouds},
volume = {PP},
journal = {IEEE Transactions on Cloud Computing},
doi = {10.1109/TCC.2021.3113605}
}
@article{ZENG2024121,
title = {Joint optimization of multi-dimensional resource allocation and task offloading for QoE enhancement in Cloud-Edge-End collaboration},
journal = {Future Generation Computer Systems},
volume = {155},
pages = {121-131},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.01.025},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24000311},
author = {Chao Zeng and Xingwei Wang and Rongfei Zeng and Ying Li and Jianzhi Shi and Min Huang},
keywords = {Cloud–edge–end collaboration, Task offloading, Resources allocation, Quality of experience, Multi-agent reinforcement learning},
abstract = {Cloud-Edge-End Collaboration (CEEC) computing architecture inherits many merits from both edge computing and cloud computing and thus is considered as a promising candidate for future network services. In CEEC, user’s QoE is impacted by offload performance which should consider offload strategy, computational resources and network status simultaneously. However, previous offload optimization studies neglect the joint consideration of dependent task offloading, computational resources and channel resources, which may not produce potential performance improvement. In this paper, we investigate the joint optimization of dependent task offloading, computational resource allocation, user transmission power control, and channel resource allocation in the CEEC scenario, with the goal of maximizing user’s QoE. Initially, a new QoE metric is defined to capture the impacts of delay and energy consumption on user’s QoE. Following this definition, we formulate the joint optimization problem as a Mixed Integer Nonlinear Programming (MINLP) problem and introduce a method of multi-agent deep reinforcement learning to solve our MINLP problem with high computation complexity. Extensive experiments are performed, and experimental results show that our proposed scheme outperforms baselines in a series of metrics.}
}

@article{mcclatchey2007data,
  title={Data intensive and network aware (DIANA) grid scheduling},
  author={McClatchey, Richard and Anjum, Ashiq and Stockinger, Heinz and Ali, Arshad and Willers, Ian and Thomas, Michael},
  journal={Journal of Grid computing},
  volume={5},
  pages={43--64},
  year={2007},
  publisher={Springer}
}

@article{tang2006impact,
  title={The impact of data replication on job scheduling performance in the data grid},
  author={Tang, Ming and Lee, Bu-Sung and Tang, Xueyan and Yeo, Chai-Kiat},
  journal={Future Generation Computer Systems},
  volume={22},
  number={3},
  pages={254--268},
  year={2006},
  publisher={Elsevier}
}

@inproceedings{ranganathan2002decoupling,
  title={Decoupling computation and data scheduling in distributed data-intensive applications},
  author={Ranganathan, Kavitha and Foster, Ian},
  booktitle={Proceedings 11th IEEE International Symposium on High Performance Distributed Computing},
  pages={352--358},
  year={2002},
  organization={IEEE}
}

@article{taheri2016genetic,
  title={Genetic algorithm in finding Pareto frontier of optimizing data transfer versus job execution in grids},
  author={Taheri, Javid and Zomaya, Albert Y and Khan, Samee U},
  journal={Concurrency and Computation: Practice and Experience},
  volume={28},
  number={6},
  pages={1715--1736},
  year={2016},
  publisher={Wiley Online Library}
}

@article{casas2017balanced,
  title={A balanced scheduler with data reuse and replication for scientific workflows in cloud computing systems},
  author={Casas, Israel and Taheri, Javid and Ranjan, Rajiv and Wang, Lizhe and Zomaya, Albert Y},
  journal={Future Generation Computer Systems},
  volume={74},
  pages={168--178},
  year={2017},
  publisher={Elsevier}
}

@article{bartz2014evolutionary,
  title={Evolutionary algorithms},
  author={Bartz-Beielstein, Thomas and Branke, J{\"u}rgen and Mehnen, J{\"o}rn and Mersmann, Olaf},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={4},
  number={3},
  pages={178--195},
  year={2014},
  publisher={Wiley Online Library}
}
@article{liu2013swarm,
author = {Liu, H. and Abraham, Ajith and Snasel, Vaclav and Mcloone, Sean},
year = {2013},
month = {06},
pages = {228-243},
title = {Swarm scheduling approaches for work-flow applications with security constraints in distributed data-intensive computing environments},
volume = {192},
journal = {Information Sciences},
doi = {10.1016/j.ins.2011.12.032}
}
@article{BRAUN2001810,
title = {A Comparison of Eleven Static Heuristics for Mapping a Class of Independent Tasks onto Heterogeneous Distributed Computing Systems},
journal = {Journal of Parallel and Distributed Computing},
volume = {61},
number = {6},
pages = {810-837},
year = {2001},
issn = {0743-7315},
doi = {https://doi.org/10.1006/jpdc.2000.1714},
url = {https://www.sciencedirect.com/science/article/pii/S0743731500917143},
author = {Tracy D Braun and Howard Jay Siegel and Noah Beck and Ladislau L Bölöni and Muthucumaru Maheswaran and Albert I Reuther and James P Robertson and Mitchell D Theys and Bin Yao and Debra Hensgen and Richard F Freund},
keywords = {A*, Genetic Algorithm, heterogeneous computing, mapping heuristics, metatasks, simulated annealing, static matching, Tabu search},
abstract = {Mixed-machine heterogeneous computing (HC) environments utilize a distributed suite of different high-performance machines, interconnected with high-speed links, to perform different computationally intensive applications that have diverse computational requirements. HC environments are well suited to meet the computational demands of large, diverse groups of tasks. The problem of optimally mapping (defined as matching and scheduling) these tasks onto the machines of a distributed HC environment has been shown, in general, to be NP-complete, requiring the development of heuristic techniques. Selecting the best heuristic to use in a given environment, however, remains a difficult problem, because comparisons are often clouded by different underlying assumptions in the original study of each heuristic. Therefore, a collection of 11 heuristics from the literature has been selected, adapted, implemented, and analyzed under one set of common assumptions. It is assumed that the heuristics derive a mapping statically (i.e., off-line). It is also assumed that a metatask (i.e., a set of independent, noncommunicating tasks) is being mapped and that the goal is to minimize the total execution time of the metatask. The 11 heuristics examined are Opportunistic Load Balancing, Minimum Execution Time, Minimum Completion Time, Min–min, Max–min, Duplex, Genetic Algorithm, Simulated Annealing, Genetic Simulated Annealing, Tabu, and A*. This study provides one even basis for comparison and insights into circumstances where one technique will out-perform another. The evaluation procedure is specified, the heuristics are defined, and then comparison results are discussed. It is shown that for the cases studied here, the relatively simple Min–min heuristic performs well in comparison to the other techniques.}
}
@article{Govardhan2024survey,
author = {Govardhan, Dr and Dugyani, Rambabu},
year = {2024},
month = {01},
pages = {1-27},
title = {Survey on Data Replication in Cloud Systems},
volume = {22},
journal = {Web Intelligence},
doi = {10.3233/WEB-230087}
}
@article{AMJAD2012337,
title = {A survey of dynamic replication strategies for improving data availability in data grids},
journal = {Future Generation Computer Systems},
volume = {28},
number = {2},
pages = {337-349},
year = {2012},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2011.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X11001208},
author = {Tehmina Amjad and Muhammad Sher and Ali Daud},
keywords = {Data grid, Data replication, Dynamic replication techniques, Replication strategies},
abstract = {Data grid is a distributed collection of storage and computational resources that are not bounded within a geophysical location. It is a fast growing area of research and providing efficient data access and maximum data availability is a challenging task. To achieve this task, data is replicated to different sites. A number of data replication techniques have been presented for data grids. All replication techniques address some attributes like fault tolerance, scalability, improved bandwidth consumption, performance, storage consumption, data access time etc. In this paper, different issues involved in data replication are identified and different replication techniques are studied to find out which attributes are addressed in a given technique and which are ignored. A tabular representation of all those parameters is presented to facilitate the future comparison of dynamic replication techniques. The paper also includes some discussion about future work in this direction by identifying some open research problems.}
}
@article{Mishra2014Survey,
author = {Mishra, Manoj and Patel, Yashwant and Rout, Yajnaseni and Mund, G.},
year = {2014},
month = {10},
pages = {57-83},
title = {A Survey on Scheduling Heuristics in Grid Computing Environment},
volume = {6},
journal = {International Journal of Modern Education and Computer Science},
doi = {10.5815/ijmecs.2014.10.08}
}
@INPROCEEDINGS{armstrong1998mapping,
  author={Armstrong, R. and Hensgen, D. and Kidd, T.},
  booktitle={Proceedings Seventh Heterogeneous Computing Workshop (HCW'98)}, 
  title={The relative performance of various mapping algorithms is independent of sizable variances in run-time predictions}, 
  year={1998},
  volume={},
  number={},
  pages={79-87},
  keywords={Runtime;Greedy algorithms;Load management;Network servers;Scheduling algorithm;Computer science;Machine intelligence;Contracts;Measurement;NP-complete problem},
  doi={10.1109/HCW.1998.666547}}
@INPROCEEDINGS{freund1998scheduling,
  author={Freund, R.F. and Gherrity, M. and Ambrosius, S. and Campbell, M. and Halderman, M. and Hensgen, D. and Keith, E. and Kidd, T. and Kussow, M. and Lima, J.D. and Mirabile, F. and Moore, L. and Rust, B. and Siegel, H.J.},
  booktitle={Proceedings Seventh Heterogeneous Computing Workshop (HCW'98)}, 
  title={Scheduling resources in multi-user, heterogeneous, computing environments with SmartNet}, 
  year={1998},
  volume={},
  number={},
  pages={184-199},
  keywords={Processor scheduling;Computer networks;Resource management;Distributed computing;Load management;Computational modeling;Computer simulation;Application software;Microcomputers;Workstations},
  doi={10.1109/HCW.1998.666558}}

@article{Huedo2004Gridway,
author = {Huedo, Eduardo and Montero, Rubén and Llorente, Ignacio},
year = {2004},
month = {06},
pages = {631-651},
title = {A framework for adaptive execution on Grids},
volume = {34},
journal = {Software Practice and Experience},
doi = {10.1002/spe.584}
}
@ARTICLE{sahni2019data,
  author={Sahni, Yuvraj and Cao, Jiannong and Yang, Lei},
  journal={IEEE Internet of Things Journal}, 
  title={Data-Aware Task Allocation for Achieving Low Latency in Collaborative Edge Computing}, 
  year={2019},
  volume={6},
  number={2},
  pages={3512-3524},
  keywords={Task analysis;Edge computing;Schedules;Collaboration;Bandwidth;Processor scheduling;Resource management;Collaborative edge computing;Internet of Things (IoT);network flow scheduling;task scheduling},
  doi={10.1109/JIOT.2018.2886757}}
@article{LI2016119,
title = {Heuristics for periodical batch job scheduling in a MapReduce computing framework},
journal = {Information Sciences},
volume = {326},
pages = {119-133},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2015.07.040},
url = {https://www.sciencedirect.com/science/article/pii/S0020025515005459},
author = {Xiaoping Li and Tianze Jiang and Rubén Ruiz},
keywords = {MapReduce, Periodical job, Schedule-dependent setup times, Heuristics, Makespan},
abstract = {Task scheduling has a significant impact on the performance of the MapReduce computing framework. In this paper, a scheduling problem of periodical batch jobs with makespan minimization is considered. The problem is modeled as a general two-stage hybrid flow shop scheduling problem with schedule-dependent setup times. The new model incorporates the data locality of tasks and is formulated as an integer program. Three heuristics are developed to solve the problem and an improvement policy based on data locality is presented to enhance the methods. A lower bound of the makespan is derived. 150 instances are randomly generated from data distributions drawn from a real cluster. The parameters involved in the methods are set according to different cluster setups. The proposed heuristics are compared over different numbers of jobs and cluster setups. Computational results show that the performance of the methods is highly dependent on both the number of jobs and the cluster setups. The proposed improvement policy is effective and the impact of the input data distribution on the policy is analyzed and tested.}
}
@article{TANG2006254,
title = {The impact of data replication on job scheduling performance in the Data Grid},
journal = {Future Generation Computer Systems},
volume = {22},
number = {3},
pages = {254-268},
year = {2006},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2005.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X05001111},
author = {Ming Tang and Bu-Sung Lee and Xueyan Tang and Chai-Kiat Yeo},
keywords = {Data replication, Grid scheduling, Data Grid, Simulation},
abstract = {In the Data Grid environment, the primary goal of data replication is to shorten the data access time experienced by the job and consequently reduce the job turnaround time. After introducing a Data Grid architecture that supports efficient data access for the Grid job, the dynamic data replication algorithms are put forward. Combined with different Grid scheduling heuristics, the performances of the data replication algorithms are evaluated with various simulations. The simulation results demonstrate that the dynamic replication algorithms can reduce the job turnaround time remarkably. In particular, the combination of shortest turnaround time scheduling heuristic (STT) and centralized dynamic replication with response-time oriented replica placement (CDR_RTPlace) exhibits remarkable performance in diverse system environments and job workloads.}
}
@INPROCEEDINGS{Ruay2008dynamic,
  author={Ruay-Shiung Chang and Hui-Ping Chang and Yun-Ting Wang},
  booktitle={2008 IEEE/ACS International Conference on Computer Systems and Applications}, 
  title={A dynamic weighted data replication strategy in data grids}, 
  year={2008},
  volume={},
  number={},
  pages={414-421},
  keywords={Bandwidth;Resource management;History;Computer science;Data engineering;System performance;Distributed computing;Grid computing;Delay;File servers;Data Grids;Data Replication;Load Balance},
  doi={10.1109/AICCSA.2008.4493567}}
@article{podlipnig2003cache,
author = {Podlipnig, Stefan and B\"{o}sz\"{o}rmenyi, Laszlo},
title = {A survey of Web cache replacement strategies},
year = {2003},
issue_date = {December 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/954339.954341},
doi = {10.1145/954339.954341},
abstract = {Web caching is an important technique to scale the Internet. One important performance factor of Web caches is the replacement strategy. Due to specific characteristics of the World Wide Web, there exist a huge number of proposals for cache replacement. This article proposes a classification for these proposals that subsumes prior classifications. Using this classification, different proposals and their advantages and disadvantages are described. Furthermore, the article discusses the importance of cache replacement strategies in modern proxy caches and outlines potential future research topics.},
journal = {ACM Comput. Surv.},
month = dec,
pages = {374–398},
numpages = {25},
keywords = {Web caching, replacement strategies}
}
@article{ALLCOCK2002749,
title = {Data management and transfer in high-performance computational grid environments},
journal = {Parallel Computing},
volume = {28},
number = {5},
pages = {749-771},
year = {2002},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(02)00094-7},
url = {https://www.sciencedirect.com/science/article/pii/S0167819102000947},
author = {Bill Allcock and Joe Bester and John Bresnahan and Ann L. Chervenak and Ian Foster and Carl Kesselman and Sam Meder and Veronika Nefedova and Darcy Quesnel and Steven Tuecke},
keywords = {Globus, Data grid, GridFTP, Replica management},
abstract = {An emerging class of data-intensive applications involve the geographically dispersed extraction of complex scientific information from very large collections of measured or computed data. Such applications arise, for example, in experimental physics, where the data in question is generated by accelerators, and in simulation science, where the data is generated by supercomputers. So-called Data Grids provide essential infrastructure for such applications, much as the Internet provides essential services for applications such as e-mail and the Web. We describe here two services that we believe are fundamental to any Data Grid: reliable, high-speed transport and replica management. Our high-speed transport service, GridFTP, extends the popular FTP protocol with new features required for Data Grid applications, such as striping and partial file access. Our replica management service integrates a replica catalog with GridFTP transfers to provide for the creation, registration, location, and management of dataset replicas. We present the design of both services and also preliminary performance results. Our implementations exploit security and other services provided by the Globus Toolkit.}
}
@InProceedings{bell2002simulation,
author="Bell, William H.
and Cameron, David G.
and Capozza, Luigi
and Millar, A. Paul
and Stockinger, Kurt
and Zini, Floriano",
editor="Parashar, Manish",
title="Simulation of Dynamic Grid Replication Strategies in OptorSim",
booktitle="Grid Computing --- GRID 2002",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="46--57",
abstract="Computational Grids normally deal with large computationally intensive problems on small data sets. In contrast, Data Grids mostly deal with large computational problems that in turn require evaluating and mining large amounts of data. Replication is regarded as one of the major optimisation techniques for providing fast data access. Within this paper, several replication algorithms are studied. This is achieved using the Grid simulator: OptorSim. OptorSim provides a modular framework within which optimisation strategies can be studied under different Grid configurations. The goal is to explore the stability and transient behaviour of selected optimisation techniques.",
isbn="978-3-540-36133-6"
}

@inproceedings{Venugopal2004grid,
author = {Venugopal, Srikumar and Buyya, Rajkumar and Winton, Lyle},
title = {A grid service broker for scheduling distributed data-oriented applications on global grids},
year = {2004},
isbn = {1581139500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1028493.1028506},
doi = {10.1145/1028493.1028506},
abstract = {Large communities of researchers distributed around the world are engaged in analyzing huge collections of data generated by scientific instruments and replicated on distributed resources. In such an environment, scientists need to have the ability to carry out their studies by transparently accessing distributed data and computational resources. In this paper, we propose and develop a Grid broker that mediates access to distributed resources by (a) discovering suitable data sources for a given analysis scenario, (b) suitable computational resources, (c) optimally mapping analysis jobs to resources, (d) deploying and monitoring job execution on selected resources, (e) accessing data from local or remote data source during job execution and (f) collating and presenting results. The broker supports a declarative and dynamic parametric programming model for creating grid applications. We have used this model in grid-enabling a high energy physics analysis application (Belle Analysis Software Framework) on a grid testbed having resources distributed across Australia.},
booktitle = {Proceedings of the 2nd Workshop on Middleware for Grid Computing},
pages = {75–80},
numpages = {6},
location = {Toronto, Ontario, Canada},
series = {MGC '04}
}
@article{fadaie2012replica,
author = {Fadaie, Zeinab and Rahmani, Amir},
year = {2012},
month = {03},
pages = {491-507},
title = {A new Replica Placement Algorithm in Data Grid},
volume = {9},
journal = {Int J Comput Sci Issues}
}
@article{shorfuzzaman2010adaptive,
author = {Shorfuzzaman, Mohammad and Graham, Peter and Eskicioglu, Rasit},
year = {2010},
month = {12},
pages = {012020},
title = {Adaptive Replica Placement in Hierarchical Data Grids},
volume = {256},
journal = {Journal of Physics: Conference Series},
doi = {10.1088/1742-6596/256/1/012020}
}
@INPROCEEDINGS{ranganathan2002improve,
  author={Ranganathan, K. and Iamnitchi, A. and Foster, I.},
  booktitle={2nd IEEE/ACM International Symposium on Cluster Computing and the Grid (CCGRID'02)}, 
  title={Improving Data Availability through Dynamic Model-Driven Replication in Large Peer-to-Peer Communities}, 
  year={2002},
  volume={},
  number={},
  pages={376-376},
  keywords={Peer to peer computing;Aggregates;Bandwidth;Costs;Availability;Computer science;Delay;Microcomputers;Personal communication networks;Power system reliability},
  doi={10.1109/CCGRID.2002.1017164}}
@article{CHANG2007846,
title = {Job scheduling and data replication on data grids},
journal = {Future Generation Computer Systems},
volume = {23},
number = {7},
pages = {846-860},
year = {2007},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2007.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X07000301},
author = {Ruay-Shiung Chang and Jih-Sheng Chang and Shin-Yi Lin},
keywords = {Data replication, Data grid, Job scheduling},
abstract = {In data grids, many distributed scientific and engineering applications often require access to a large amount of data (terabytes or petabytes). Data access time depends on bandwidth, especially in a cluster grid. Network bandwidth within the same cluster is larger than across clusters. In a communication environment, the major bottleneck to supporting fast data access in Grids is the high latencies of Wide Area Networks (WANs) and Internet. Effective scheduling in such network architecture can reduce the amount of data transferred across the Internet by dispatching a job to where the needed data are present. Another solution is to use a data replication mechanism to generate multiple copies of the existing data to reduce access opportunities from a remote site. To utilize the above two concepts, in this paper we develop a job scheduling policy, called HCS (Hierarchical Cluster Scheduling), and a dynamic data replication strategy, called HRS (Hierarchical Replication Strategy), to improve the data access efficiencies in a cluster grid. We simulate our algorithm to evaluate various combinations of data access patterns. We also implement HCS and HRS in the Taiwan Unigrid environment. The simulation and experiment results show that HCS and HRS successfully reduces data access time and the amount of inter-cluster-communications in comparison with other strategies in a cluster grid.}
}
@ARTICLE{7874167,
  author={Tang, Bo and Chen, Zhen and Hefferman, Gerald and Pei, Shuyi and Wei, Tao and He, Haibo and Yang, Qing},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Incorporating Intelligence in Fog Computing for Big Data Analysis in Smart Cities}, 
  year={2017},
  volume={13},
  number={5},
  pages={2140-2150},
  keywords={Smart cities;Intelligent sensors;Computer architecture;Cloud computing;Edge computing;Monitoring;Distributed computing;fiber optic sensor;fog computing;Internet of Things (IoT);smart cities;smart pipeline},
  doi={10.1109/TII.2017.2679740}}

@article{Ko2019MIQP,
author = {Ko, Rakkyung and Kang, Daeyoung and Joo, Sung-Kwan},
year = {2019},
month = {04},
pages = {1410},
title = {Mixed Integer Quadratic Programming Based Scheduling Methods for Day-Ahead Bidding and Intra-Day Operation of Virtual Power Plant},
volume = {12},
journal = {Energies},
doi = {10.3390/en12081410}
}
@article{holtman2001cms,
author = {Holtman, Koen},
year = {2001},
month = {08},
pages = {},
title = {CMS Data Grid System - Overview and Requirements}
}
@article{acdamic2012zipf,
author = {Adamic, Lada},
year = {2012},
month = {05},
pages = {},
title = {Zipf, Power-laws, and Pareto- a ranking tutorial}
}