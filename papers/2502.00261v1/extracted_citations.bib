@ARTICLE{7874167,
  author={Tang, Bo and Chen, Zhen and Hefferman, Gerald and Pei, Shuyi and Wei, Tao and He, Haibo and Yang, Qing},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Incorporating Intelligence in Fog Computing for Big Data Analysis in Smart Cities}, 
  year={2017},
  volume={13},
  number={5},
  pages={2140-2150},
  keywords={Smart cities;Intelligent sensors;Computer architecture;Cloud computing;Edge computing;Monitoring;Distributed computing;fiber optic sensor;fog computing;Internet of Things (IoT);smart cities;smart pipeline},
  doi={10.1109/TII.2017.2679740}}

@article{ALLCOCK2002749,
title = {Data management and transfer in high-performance computational grid environments},
journal = {Parallel Computing},
volume = {28},
number = {5},
pages = {749-771},
year = {2002},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(02)00094-7},
url = {https://www.sciencedirect.com/science/article/pii/S0167819102000947},
author = {Bill Allcock and Joe Bester and John Bresnahan and Ann L. Chervenak and Ian Foster and Carl Kesselman and Sam Meder and Veronika Nefedova and Darcy Quesnel and Steven Tuecke},
keywords = {Globus, Data grid, GridFTP, Replica management},
abstract = {An emerging class of data-intensive applications involve the geographically dispersed extraction of complex scientific information from very large collections of measured or computed data. Such applications arise, for example, in experimental physics, where the data in question is generated by accelerators, and in simulation science, where the data is generated by supercomputers. So-called Data Grids provide essential infrastructure for such applications, much as the Internet provides essential services for applications such as e-mail and the Web. We describe here two services that we believe are fundamental to any Data Grid: reliable, high-speed transport and replica management. Our high-speed transport service, GridFTP, extends the popular FTP protocol with new features required for Data Grid applications, such as striping and partial file access. Our replica management service integrates a replica catalog with GridFTP transfers to provide for the creation, registration, location, and management of dataset replicas. We present the design of both services and also preliminary performance results. Our implementations exploit security and other services provided by the Globus Toolkit.}
}

@article{BRAUN2001810,
title = {A Comparison of Eleven Static Heuristics for Mapping a Class of Independent Tasks onto Heterogeneous Distributed Computing Systems},
journal = {Journal of Parallel and Distributed Computing},
volume = {61},
number = {6},
pages = {810-837},
year = {2001},
issn = {0743-7315},
doi = {https://doi.org/10.1006/jpdc.2000.1714},
url = {https://www.sciencedirect.com/science/article/pii/S0743731500917143},
author = {Tracy D Braun and Howard Jay Siegel and Noah Beck and Ladislau L Bölöni and Muthucumaru Maheswaran and Albert I Reuther and James P Robertson and Mitchell D Theys and Bin Yao and Debra Hensgen and Richard F Freund},
keywords = {A*, Genetic Algorithm, heterogeneous computing, mapping heuristics, metatasks, simulated annealing, static matching, Tabu search},
abstract = {Mixed-machine heterogeneous computing (HC) environments utilize a distributed suite of different high-performance machines, interconnected with high-speed links, to perform different computationally intensive applications that have diverse computational requirements. HC environments are well suited to meet the computational demands of large, diverse groups of tasks. The problem of optimally mapping (defined as matching and scheduling) these tasks onto the machines of a distributed HC environment has been shown, in general, to be NP-complete, requiring the development of heuristic techniques. Selecting the best heuristic to use in a given environment, however, remains a difficult problem, because comparisons are often clouded by different underlying assumptions in the original study of each heuristic. Therefore, a collection of 11 heuristics from the literature has been selected, adapted, implemented, and analyzed under one set of common assumptions. It is assumed that the heuristics derive a mapping statically (i.e., off-line). It is also assumed that a metatask (i.e., a set of independent, noncommunicating tasks) is being mapped and that the goal is to minimize the total execution time of the metatask. The 11 heuristics examined are Opportunistic Load Balancing, Minimum Execution Time, Minimum Completion Time, Min–min, Max–min, Duplex, Genetic Algorithm, Simulated Annealing, Genetic Simulated Annealing, Tabu, and A*. This study provides one even basis for comparison and insights into circumstances where one technique will out-perform another. The evaluation procedure is specified, the heuristics are defined, and then comparison results are discussed. It is shown that for the cases studied here, the relatively simple Min–min heuristic performs well in comparison to the other techniques.}
}

@article{CHANG2007846,
title = {Job scheduling and data replication on data grids},
journal = {Future Generation Computer Systems},
volume = {23},
number = {7},
pages = {846-860},
year = {2007},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2007.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X07000301},
author = {Ruay-Shiung Chang and Jih-Sheng Chang and Shin-Yi Lin},
keywords = {Data replication, Data grid, Job scheduling},
abstract = {In data grids, many distributed scientific and engineering applications often require access to a large amount of data (terabytes or petabytes). Data access time depends on bandwidth, especially in a cluster grid. Network bandwidth within the same cluster is larger than across clusters. In a communication environment, the major bottleneck to supporting fast data access in Grids is the high latencies of Wide Area Networks (WANs) and Internet. Effective scheduling in such network architecture can reduce the amount of data transferred across the Internet by dispatching a job to where the needed data are present. Another solution is to use a data replication mechanism to generate multiple copies of the existing data to reduce access opportunities from a remote site. To utilize the above two concepts, in this paper we develop a job scheduling policy, called HCS (Hierarchical Cluster Scheduling), and a dynamic data replication strategy, called HRS (Hierarchical Replication Strategy), to improve the data access efficiencies in a cluster grid. We simulate our algorithm to evaluate various combinations of data access patterns. We also implement HCS and HRS in the Taiwan Unigrid environment. The simulation and experiment results show that HCS and HRS successfully reduces data access time and the amount of inter-cluster-communications in comparison with other strategies in a cluster grid.}
}

@article{Ko2019MIQP,
author = {Ko, Rakkyung and Kang, Daeyoung and Joo, Sung-Kwan},
year = {2019},
month = {04},
pages = {1410},
title = {Mixed Integer Quadratic Programming Based Scheduling Methods for Day-Ahead Bidding and Intra-Day Operation of Virtual Power Plant},
volume = {12},
journal = {Energies},
doi = {10.3390/en12081410}
}

@article{LI2016119,
title = {Heuristics for periodical batch job scheduling in a MapReduce computing framework},
journal = {Information Sciences},
volume = {326},
pages = {119-133},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2015.07.040},
url = {https://www.sciencedirect.com/science/article/pii/S0020025515005459},
author = {Xiaoping Li and Tianze Jiang and Rubén Ruiz},
keywords = {MapReduce, Periodical job, Schedule-dependent setup times, Heuristics, Makespan},
abstract = {Task scheduling has a significant impact on the performance of the MapReduce computing framework. In this paper, a scheduling problem of periodical batch jobs with makespan minimization is considered. The problem is modeled as a general two-stage hybrid flow shop scheduling problem with schedule-dependent setup times. The new model incorporates the data locality of tasks and is formulated as an integer program. Three heuristics are developed to solve the problem and an improvement policy based on data locality is presented to enhance the methods. A lower bound of the makespan is derived. 150 instances are randomly generated from data distributions drawn from a real cluster. The parameters involved in the methods are set according to different cluster setups. The proposed heuristics are compared over different numbers of jobs and cluster setups. Computational results show that the performance of the methods is highly dependent on both the number of jobs and the cluster setups. The proposed improvement policy is effective and the impact of the input data distribution on the policy is analyzed and tested.}
}

@InProceedings{Phan05Co,
author="Phan, Thomas
and Ranganathan, Kavitha
and Sion, Radu",
editor="Feitelson, Dror
and Frachtenberg, Eitan
and Rudolph, Larry
and Schwiegelshohn, Uwe",
title="Evolving Toward the Perfect Schedule: Co-scheduling Job Assignments and Data Replication in Wide-Area Systems Using a Genetic Algorithm",
booktitle="Job Scheduling Strategies for Parallel Processing",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="173--193",
abstract="Traditional job schedulers for grid or cluster systems are responsible for assigning incoming jobs to compute nodes in such a way that some evaluative condition is met. Such systems generally take into consideration the availability of compute cycles, queue lengths, and expected job execution times, but they typically do not account directly for data staging and thus miss significant associated opportunities for optimisation. Intuitively, a tighter integration of job scheduling and automated data replication can yield significant advantages due to the potential for optimised, faster access to data and decreased overall execution time. In this paper we consider data placement as a first-class citizen in scheduling and use an optimisation heuristic for generating schedules. We make the following two contributions. First, we identify the necessity for co-scheduling job dispatching and data replication assignments and posit that simultaneously scheduling both is critical for achieving good makespans. Second, we show that deploying a genetic search algorithm to solve the optimal allocation problem has the potential to achieve significant speed-up results versus traditional allocation mechanisms. Through simulation, we show that our algorithm provides on average an approximately 20-45{\%} faster makespan than greedy schedulers.",
isbn="978-3-540-31617-6"
}

@INPROCEEDINGS{Ruay2008dynamic,
  author={Ruay-Shiung Chang and Hui-Ping Chang and Yun-Ting Wang},
  booktitle={2008 IEEE/ACS International Conference on Computer Systems and Applications}, 
  title={A dynamic weighted data replication strategy in data grids}, 
  year={2008},
  volume={},
  number={},
  pages={414-421},
  keywords={Bandwidth;Resource management;History;Computer science;Data engineering;System performance;Distributed computing;Grid computing;Delay;File servers;Data Grids;Data Replication;Load Balance},
  doi={10.1109/AICCSA.2008.4493567}}

@article{TAHERI20131564,
title = {A Bee Colony based optimization approach for simultaneous job scheduling and data replication in grid environments},
journal = {Computers \& Operations Research},
volume = {40},
number = {6},
pages = {1564-1578},
year = {2013},
note = {Emergent Nature Inspired Algorithms for Multi-Objective Optimization},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2011.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S0305054811003376},
author = {Javid Taheri and Young {Choon Lee} and Albert Y. Zomaya and Howard Jay Siegel},
keywords = {Bee colony optimization, Data replication, Grid computing, Job scheduling, Resource allocation},
abstract = {This paper presents a novel Bee Colony based optimization algorithm, named Job Data Scheduling using Bee Colony (JDS-BC). JDS-BC consists of two collaborating mechanisms to efficiently schedule jobs onto computational nodes and replicate datafiles on storage nodes in a system so that the two independent, and in many cases conflicting, objectives (i.e., makespan and total datafile transfer time) of such heterogeneous systems are concurrently minimized. Three benchmarks – varying from small- to large-sized instances – are used to test the performance of JDS-BC. Results are compared against other algorithms to show JDS-BC's superiority under different operating scenarios. These results also provide invaluable insights into data-centric job scheduling for grid environments.}
}

@article{TAHERI20131885,
title = {Hopfield neural network for simultaneous job scheduling and data replication in grids},
journal = {Future Generation Computer Systems},
volume = {29},
number = {8},
pages = {1885-1900},
year = {2013},
note = {Including Special sections: Advanced Cloud Monitoring Systems \& The fourth IEEE International Conference on e-Science 2011 — e-Science Applications and Tools \& Cluster, Grid, and Cloud Computing},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2013.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X13000800},
author = {Javid Taheri and Albert Y. Zomaya and Pascal Bouvry and Samee U. Khan},
keywords = {Job scheduling, Network aware scheduling, Data file migration policies, Grid environments},
abstract = {This paper presents a novel heuristic approach, named JDS-HNN, to simultaneously schedule jobs and replicate data files to different entities of a grid system so that the overall makespan of executing all jobs as well as the overall delivery time of all data files to their dependent jobs is concurrently minimized. JDS-HNN is inspired by a natural distribution of a variety of stones among different jars and utilizes a Hopfield Neural Network in one of its optimization stages to achieve its goals. The performance of JDS-HNN has been measured by using several benchmarks varying from medium- to very-large-sized systems. JDS-HNN’s results are compared against the performance of other algorithms to show its superiority under different working conditions. These results also provide invaluable insights into scheduling and replicating dependent jobs and data files as well as their performance related issues for various grid environments.}
}

@inproceedings{Venugopal2004grid,
author = {Venugopal, Srikumar and Buyya, Rajkumar and Winton, Lyle},
title = {A grid service broker for scheduling distributed data-oriented applications on global grids},
year = {2004},
isbn = {1581139500},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1028493.1028506},
doi = {10.1145/1028493.1028506},
abstract = {Large communities of researchers distributed around the world are engaged in analyzing huge collections of data generated by scientific instruments and replicated on distributed resources. In such an environment, scientists need to have the ability to carry out their studies by transparently accessing distributed data and computational resources. In this paper, we propose and develop a Grid broker that mediates access to distributed resources by (a) discovering suitable data sources for a given analysis scenario, (b) suitable computational resources, (c) optimally mapping analysis jobs to resources, (d) deploying and monitoring job execution on selected resources, (e) accessing data from local or remote data source during job execution and (f) collating and presenting results. The broker supports a declarative and dynamic parametric programming model for creating grid applications. We have used this model in grid-enabling a high energy physics analysis application (Belle Analysis Software Framework) on a grid testbed having resources distributed across Australia.},
booktitle = {Proceedings of the 2nd Workshop on Middleware for Grid Computing},
pages = {75–80},
numpages = {6},
location = {Toronto, Ontario, Canada},
series = {MGC '04}
}

@article{ZENG2024121,
title = {Joint optimization of multi-dimensional resource allocation and task offloading for QoE enhancement in Cloud-Edge-End collaboration},
journal = {Future Generation Computer Systems},
volume = {155},
pages = {121-131},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.01.025},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24000311},
author = {Chao Zeng and Xingwei Wang and Rongfei Zeng and Ying Li and Jianzhi Shi and Min Huang},
keywords = {Cloud–edge–end collaboration, Task offloading, Resources allocation, Quality of experience, Multi-agent reinforcement learning},
abstract = {Cloud-Edge-End Collaboration (CEEC) computing architecture inherits many merits from both edge computing and cloud computing and thus is considered as a promising candidate for future network services. In CEEC, user’s QoE is impacted by offload performance which should consider offload strategy, computational resources and network status simultaneously. However, previous offload optimization studies neglect the joint consideration of dependent task offloading, computational resources and channel resources, which may not produce potential performance improvement. In this paper, we investigate the joint optimization of dependent task offloading, computational resource allocation, user transmission power control, and channel resource allocation in the CEEC scenario, with the goal of maximizing user’s QoE. Initially, a new QoE metric is defined to capture the impacts of delay and energy consumption on user’s QoE. Following this definition, we formulate the joint optimization problem as a Mixed Integer Nonlinear Programming (MINLP) problem and introduce a method of multi-agent deep reinforcement learning to solve our MINLP problem with high computation complexity. Extensive experiments are performed, and experimental results show that our proposed scheme outperforms baselines in a series of metrics.}
}

@INPROCEEDINGS{armstrong1998mapping,
  author={Armstrong, R. and Hensgen, D. and Kidd, T.},
  booktitle={Proceedings Seventh Heterogeneous Computing Workshop (HCW'98)}, 
  title={The relative performance of various mapping algorithms is independent of sizable variances in run-time predictions}, 
  year={1998},
  volume={},
  number={},
  pages={79-87},
  keywords={Runtime;Greedy algorithms;Load management;Network servers;Scheduling algorithm;Computer science;Machine intelligence;Contracts;Measurement;NP-complete problem},
  doi={10.1109/HCW.1998.666547}}

@InProceedings{bell2002simulation,
author="Bell, William H.
and Cameron, David G.
and Capozza, Luigi
and Millar, A. Paul
and Stockinger, Kurt
and Zini, Floriano",
editor="Parashar, Manish",
title="Simulation of Dynamic Grid Replication Strategies in OptorSim",
booktitle="Grid Computing --- GRID 2002",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="46--57",
abstract="Computational Grids normally deal with large computationally intensive problems on small data sets. In contrast, Data Grids mostly deal with large computational problems that in turn require evaluating and mining large amounts of data. Replication is regarded as one of the major optimisation techniques for providing fast data access. Within this paper, several replication algorithms are studied. This is achieved using the Grid simulator: OptorSim. OptorSim provides a modular framework within which optimisation strategies can be studied under different Grid configurations. The goal is to explore the stability and transient behaviour of selected optimisation techniques.",
isbn="978-3-540-36133-6"
}

@article{fadaie2012replica,
author = {Fadaie, Zeinab and Rahmani, Amir},
year = {2012},
month = {03},
pages = {491-507},
title = {A new Replica Placement Algorithm in Data Grid},
volume = {9},
journal = {Int J Comput Sci Issues}
}

@INPROCEEDINGS{freund1998scheduling,
  author={Freund, R.F. and Gherrity, M. and Ambrosius, S. and Campbell, M. and Halderman, M. and Hensgen, D. and Keith, E. and Kidd, T. and Kussow, M. and Lima, J.D. and Mirabile, F. and Moore, L. and Rust, B. and Siegel, H.J.},
  booktitle={Proceedings Seventh Heterogeneous Computing Workshop (HCW'98)}, 
  title={Scheduling resources in multi-user, heterogeneous, computing environments with SmartNet}, 
  year={1998},
  volume={},
  number={},
  pages={184-199},
  keywords={Processor scheduling;Computer networks;Resource management;Distributed computing;Load management;Computational modeling;Computer simulation;Application software;Microcomputers;Workstations},
  doi={10.1109/HCW.1998.666558}}

@article{liu2013swarm,
author = {Liu, H. and Abraham, Ajith and Snasel, Vaclav and Mcloone, Sean},
year = {2013},
month = {06},
pages = {228-243},
title = {Swarm scheduling approaches for work-flow applications with security constraints in distributed data-intensive computing environments},
volume = {192},
journal = {Information Sciences},
doi = {10.1016/j.ins.2011.12.032}
}

@article{mcclatchey2007data,
  title={Data intensive and network aware (DIANA) grid scheduling},
  author={McClatchey, Richard and Anjum, Ashiq and Stockinger, Heinz and Ali, Arshad and Willers, Ian and Thomas, Michael},
  journal={Journal of Grid computing},
  volume={5},
  pages={43--64},
  year={2007},
  publisher={Springer}
}

@article{podlipnig2003cache,
author = {Podlipnig, Stefan and B\"{o}sz\"{o}rmenyi, Laszlo},
title = {A survey of Web cache replacement strategies},
year = {2003},
issue_date = {December 2003},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/954339.954341},
doi = {10.1145/954339.954341},
abstract = {Web caching is an important technique to scale the Internet. One important performance factor of Web caches is the replacement strategy. Due to specific characteristics of the World Wide Web, there exist a huge number of proposals for cache replacement. This article proposes a classification for these proposals that subsumes prior classifications. Using this classification, different proposals and their advantages and disadvantages are described. Furthermore, the article discusses the importance of cache replacement strategies in modern proxy caches and outlines potential future research topics.},
journal = {ACM Comput. Surv.},
month = dec,
pages = {374–398},
numpages = {25},
keywords = {Web caching, replacement strategies}
}

@inproceedings{ranganathan2002decoupling,
  title={Decoupling computation and data scheduling in distributed data-intensive applications},
  author={Ranganathan, Kavitha and Foster, Ian},
  booktitle={Proceedings 11th IEEE International Symposium on High Performance Distributed Computing},
  pages={352--358},
  year={2002},
  organization={IEEE}
}

@INPROCEEDINGS{ranganathan2002improve,
  author={Ranganathan, K. and Iamnitchi, A. and Foster, I.},
  booktitle={2nd IEEE/ACM International Symposium on Cluster Computing and the Grid (CCGRID'02)}, 
  title={Improving Data Availability through Dynamic Model-Driven Replication in Large Peer-to-Peer Communities}, 
  year={2002},
  volume={},
  number={},
  pages={376-376},
  keywords={Peer to peer computing;Aggregates;Bandwidth;Costs;Availability;Computer science;Delay;Microcomputers;Personal communication networks;Power system reliability},
  doi={10.1109/CCGRID.2002.1017164}}

@ARTICLE{sahni2019data,
  author={Sahni, Yuvraj and Cao, Jiannong and Yang, Lei},
  journal={IEEE Internet of Things Journal}, 
  title={Data-Aware Task Allocation for Achieving Low Latency in Collaborative Edge Computing}, 
  year={2019},
  volume={6},
  number={2},
  pages={3512-3524},
  keywords={Task analysis;Edge computing;Schedules;Collaboration;Bandwidth;Processor scheduling;Resource management;Collaborative edge computing;Internet of Things (IoT);network flow scheduling;task scheduling},
  doi={10.1109/JIOT.2018.2886757}}

@article{shorfuzzaman2010adaptive,
author = {Shorfuzzaman, Mohammad and Graham, Peter and Eskicioglu, Rasit},
year = {2010},
month = {12},
pages = {012020},
title = {Adaptive Replica Placement in Hierarchical Data Grids},
volume = {256},
journal = {Journal of Physics: Conference Series},
doi = {10.1088/1742-6596/256/1/012020}
}

@article{tang2006impact,
  title={The impact of data replication on job scheduling performance in the data grid},
  author={Tang, Ming and Lee, Bu-Sung and Tang, Xueyan and Yeo, Chai-Kiat},
  journal={Future Generation Computer Systems},
  volume={22},
  number={3},
  pages={254--268},
  year={2006},
  publisher={Elsevier}
}

@INPROCEEDINGS{wei2021joint1,
  author={Wei, Xinliang and Wang, Yu},
  booktitle={2021 IEEE/ACM 29th International Symposium on Quality of Service (IWQOS)}, 
  title={Joint Resource Placement and Task Dispatching in Mobile Edge Computing across Timescales}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  keywords={Heuristic algorithms;Simulation;Quality of service;Dynamic scheduling;Dispatching;Internet of Things;Servers;resource placement;task dispatching;reinforcement learning;mobile edge computing},
  doi={10.1109/IWQOS52092.2021.9521283}}

@article{wei2021joint2,
author = {Wei, Xinliang and Rahman, A and Cheng, Dazhao and Wang, Yu},
year = {2021},
month = {09},
pages = {1-1},
title = {Joint Optimization Across Timescales: Resource Placement and Task Dispatching in Edge Clouds},
volume = {PP},
journal = {IEEE Transactions on Cloud Computing},
doi = {10.1109/TCC.2021.3113605}
}

