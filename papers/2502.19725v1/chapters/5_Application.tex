\section{Experiments}
\label{sec:experiments}

In this section, we evaluate \textbf{PLCEmbed} on two classification tasks discussed earlier: toolchain provenance identification and functionality classification. We first describe the experimental setup, then present the results for toolchain provenance (Sec.~\ref{subsec:toolchain_results}). Results for functionality classification follow in subsequent subsections.


\subsection{Experimental Setup}
\label{subsec:exp_setup}
We use the \textit{PLC-BEAD} dataset introduced in Sec.~\ref{sec:plcbead}, containing 729 Structured Text (ST) programs compiled across four toolchains. All experiments are conducted on a server equipped with Intel Core i7-7820X CPU @3.60GHz with 16GB RAM and two NVIDIA GeForce GTX Titan Xp GPUs 
% Each compiled binary is converted into a raw sequence of bytes, truncated or padded to a maximum length for uniform processing. 
% The dataset is split at the ST program level, ensuring that no program (or its compiled variants) appears in both training and test partitions.

\paragraph{Evaluation Metrics.}
We report accuracy on the test set to measure how often the predicted class (toolchain or functionality) matches the ground truth. We may also include F1 scores (macro or weighted) if relevant, especially in tasks where some classes have fewer samples. In addition, we utilize the Cohen Kappa score ($\kappa$) and the Matthews correlation coefficient (MCC) to account for the disparity in class sizes and provide a fair evaluation. 

% \paragraph{Model Variants.}
% \begin{itemize}
%     \item \textbf{PLCEmbed (CNN+Transformer).} Our main approach processes the bytes through a 1D convolutional layer to capture local patterns, then a transformer encoder for global dependencies. A final classifier outputs the predicted label.
%     \item \textbf{Baseline (CNN-only).} In addition to PLCEmbed, we evaluate a simpler CNN-based model that omits the transformer encoder. This baseline retains the same raw-byte input and convolutional blocks but lacks the self-attention layers. It allows us to compare how much improvement is gained by including global context modeling in the transformer.
% \end{itemize}






\begin{table}[!ht]
    \centering
    \caption{The Performance of \textit{PLCEmbed} on Toolchain Provenance Identification.}
    \begin{tabular}{ |p{0.7cm} | p{2.4cm} |p{0.8cm} |p{0.8cm} |p{0.8cm}| p{0.8cm} |}
        \hline
        Model & Dataset & Acc & F1 & $\kappa$ & MCC \\
        \hline
        &  \textit{PLC-BEAD} &91.77\% &91.77\% &89.01\% &89.02\% \\
        base- line& \textit{PLC-BEAD}-5\%-polluted &92.22\% &92.53\% &89.62\% &89.66\% \\
        & \textit{PLC-BEAD}-10\%-polluted &91.66\% &91.65\% &88.87\% &88.90\% \\
       
        \hline%for none, first-k (n=2000), first-k (n=20000)

       %ours& \textit{PLC-BEAD} &86.31\% &86.30\% &81.73\% &81.77\% \\
        %& \textit{PLC-BEAD}-5\%-polluted &85.73\% &85.70\% &80.95\% &80.96\% \\
       % & \textit{PLC-BEAD}-10\%-polluted &85.58\% &85.51\% &80.75\% &80.77\% \\%for none, first-k (n=2000), first-k (n=20000)
        & \textit{PLC-BEAD} &93.11\% &93.10\% &90.80\% &90.81\% \\
        ours& \textit{PLC-BEAD}-5\%-polluted &92.66\% &92.64\% &90.21\% &90.25\% \\
        & \textit{PLC-BEAD}-10\%-polluted &92.64\% &92.64\% &90.19\% &90.21\% \\
        \hline
    \end{tabular}
    \label{tab:result_tp}
\end{table}


\subsection{Toolchain Provenance Results}
\label{subsec:toolchain_results}
We first evaluate our model on the task of identifying which compiler produced a given PLC binary. 

Table~\ref{tab:result_tp} summarizes accuracy, F1-score, and other relevant metrics on the test set. The proposed framework achieves strong performance, often above 90\% accuracy for predicting the correct compiler, with some variation across compiler types. In particular, binaries originating from OpenPLC-V3 tend to exhibit distinct byte patterns that are easier to learn, whereas CoDeSys binaries sometimes contain shared library code that can overlap with features from other toolchains. Nonetheless, the attention-based layers help capture global cues, such as the file header or compiler-specific data segments, which improves disambiguation. The CNN-only baseline performs moderately well but sometimes misclassifies binaries that share structural similarities across compilers. Without the attention-based mechanism, it may overlook long-range features that differentiate compilers more definitively.
% In contrast, the CNN-only baseline underperforms by about 3--4 percentage points. This gap reflects how global attention helps the network correlate byte patterns found in the header or trailer with subtle markers in the main data region.

The results indicate a substantial gain for all compilers. In practical forensic applications, even small gains in precision can significantly cut down investigative workload. A correct toolchain assignment narrows the search for known vulnerabilities and helps analysts confirm whether an executable originated from a trusted development environment. Sec.~\ref{subsec:discussion} further explores the role of this classification in ICS forensics, including how partial matches can still provide valuable clues in legacy systems with incomplete data.

\begin{table}[!ht]
    \centering
    \caption{The Performance of \textit{PLCEmbed} on Functionality Prediction.}
    \begin{tabular}{ |p{0.7cm} | p{2.5cm} |p{0.8cm}  |p{0.8cm} |p{0.8cm}| p{0.8cm} |}
        \hline
        Model & Dataset & Acc & F1 & $\kappa$ & MCC \\
        \hline
        & \textit{OpenPLC} V3 &45.18\% &41.24\%  &39.38\% &39.84\%\\
        & \textit{OpenPLC} V2 &38.77\% &36.07\%  &33.73\% &34.08\%\\

        & \textit{PLC-BEAD} &39.28\% &37.75\%  &33.70\% &33.78\%\\
        base- line & \textit{PLC-BEAD}-5\%-polluted &38.37\% &36.68\%  &32.63\% &32.75\%\\
        & \textit{PLC-BEAD}-10\%-polluted &35.65\% &33.74\%  &29.42\% &29.58\%\\
        \hline
        & \textit{OpenPLC} V3 &46.85\% &43.42\%  &41.28\% &41.73\%\\
        & \textit{OpenPLC} V2 &41.68\% &39.34\%  &37.04\% &37.36\%\\

        & \textit{PLC-BEAD} &42.28\% &40.35\%  &36.63\% &36.83\%\\
        ours& \textit{PLC-BEAD}-5\%-polluted &39.12\% &36.72\%  &33.04\% &33.29\%\\
        & \textit{PLC-BEAD}-10\%-polluted &38.23\% &35.25\%  &31.86\% &32.15\%\\
        \hline
    \end{tabular}
    \label{tab:result_func}
\end{table}

\subsection{Functionality Classification Results}
\label{subsec:func_classification}

We now evaluate both \textbf{PLCEmbed} and the \textbf{CNN-only baseline} on \textbf{functionality classification}, where each binary must be assigned to one of the 22 functionality categories from Sec.~\ref{subsubsec:labeling}. This task is typically more challenging than toolchain provenance due to potential overlaps between functionalities (for instance, math blocks that also include timing components) and uneven class distributions.

\paragraph{Overall Performance.}
Table~\ref{tab:result_func} summarizes the performance of our models on the test set. 
First, we assessed the efficacy of the models on how well they classify the functionality of binaries compiled using a single toolchain, specifically \textit{OpenPLC V3} and \textit{OpenPLC V2}, as these toolchains have the most significant number of binaries in our dataset. 
Our model achieved an accuracy of 46.85\% and 41.68\% for \textit{OpenPLC V3} and \textit{OpenPLC V2}, respectively.

While these results demonstrate the potential of our approach, it is essential to acknowledge that the performance is not exceptionally high. This could be attributed to several factors, such as the intrinsic difficulty of the task and the diversity and complexity of PLC programs. The lower performance on metrics like Cohen's Kappa score (41.28\% and 37.04\% for \textit{OpenPLC V2} and \textit{V3}, respectively) suggests that our model is affected by class imbalance in the dataset.
We also evaluated our model on the entire \textit{\textit{PLC-BEAD}-Func} dataset, which includes binaries from all four toolchains. In this setting, our model achieved an accuracy of 42.28\% and a Cohen's Kappa score of 36.63\%.

Although the baseline CNN-only model performs reasonably well for more common categories, PLCEmbed (CNN+Transformer) achieves higher accuracy overall, suggesting that the transformer’s global context helps distinguish subtler functional differences scattered across the byte sequence. Some categories with fewer samples (for example, specialized building control blocks) exhibit higher variance in both models’ predictions.



\paragraph{Imbalanced Classes.}
Certain functionalities, such as \textit{Math} or \textit{Timing}, occur more frequently than others (for example, advanced building automation). Despite label weighting and the data filtering performed in Sec.~\ref{subsubsec:labeling}, a few categories remain underrepresented. Both PLCEmbed and the baseline see lower F1 scores in these rare classes, though PLCEmbed consistently outperforms the baseline by a small margin. This indicates that local byte patterns alone may not suffice to capture complex functionalities unless supported by a mechanism (such as self-attention) that integrates information from different parts of the binary.

\paragraph{Insights.} In practical ICS scenarios, analysts can use functionality classification to verify whether an uploaded binary aligns with the intended control logic. If a malicious actor replaced a “Timing” module with a “Network” module that exfiltrates data, for instance, a high-performing classifier might flag this discrepancy even without source code. However, these results confirm that functionality classification presents an additional layer of complexity beyond toolchain detection. 
Besides class imbalance, one of the main obstacles arises when binaries compiled with the same toolchain share significant code segments, despite having different functionalities.
This can be attributed to the use of common libraries, runtime environments, and compiler-specific optimizations that result in similar binary structures across different programs.


For instance, in our dataset, the \textit{ACTUATOR\_PUMP} and \textit{TIMER\_1} programs, both compiled using \textit{OPENPLC V3}, have different functionality labels but share a notable portion of their code segments. 
The \textit{ACTUATOR\_PUMP} program implements a pump interface controllable by an input, while the \textit{TIMER\_1} program realizes a simple timer that generates output pulses on selected days. 
Conversely, the same \textit{ACTUATOR\_PUMP} program compiled using \textit{OpenPLC V3} and \textit{GEB} exhibits differences in almost all code segments, despite having similar functionality.
 
These observations highlight the need for more advanced binary analysis techniques that go beyond simple structural analysis. Future research could explore methods that consider additional features, such as control flow graphs, data flow analysis, or ML-based approaches that can learn to distinguish between different functionalities based on higher-level patterns and abstractions.




\subsection{Robustness and Additional Experiments}
\label{subsec:robustness}

We also study the model's robustness to noise. Industrial forensics sometimes involves partially corrupted binaries or incomplete memory dumps. To simulate this, we flip 5\% and 10\% of the bytes in the test-set files at random. Table~\ref{tab:result_tp} and~\ref{tab:result_func} report toolchain and functionality accuracy under these conditions. Although performance drops compared to the unmodified files, the decrease is modest (1--3\% at most), suggesting that convolution filters and attention can tolerate moderate corruption as long as key compiler or functional patterns remain intact.



\subsection{Discussion}
\label{subsec:discussion}
Our experiments indicate that \textbf{PLCEmbed} (CNN+Transformer) surpasses the simpler \textbf{CNN-only baseline} in both toolchain provenance and functionality classification tasks. This performance gap is more pronounced when classes exhibit significant overlap in byte patterns or when only limited data is available. Although pure CNNs capture local sequences effectively, the global relationships modeled by the transformer seem essential for disambiguating bytes that occur far apart in the binary.

\paragraph{Practical Implications.}
From an ICS security perspective, a data-driven method that recovers high-level properties (compiler origin or functionality) from raw binaries offers several advantages. Investigators can identify suspicious binaries that appear to originate from unexpected compilers or that do not match the stated control logic.
Moreover, maintenance teams can detect variations introduced by updated compiler versions or emerging vendor-specific features that might be invisible without proprietary documentation.

\paragraph{Limitations.}
Although these results are promising, the dataset still represents a subset of possible ICS code scenarios, and certain rare functional categories remain difficult to classify accurately. 
Potential avenues for future work include exploring more advanced model architectures, incorporating additional sources of information (e.g., control flow graphs, memory access patterns), and developing techniques to handle class imbalance and data corruption more effectively.
Nonetheless, our findings underscore the value of raw-byte, compiler-agnostic approaches for PLC binary analysis.





% Experimental results on the PLC-BEAD dataset show that our approach outperforms a CNN-only baseline and remains robust in the face of moderate data corruption. These findings indicate that our model not only validates the usefulness of the dataset but also offers a promising pathway for automated ICS digital forensics and security analysis.

% In future work, we plan to expand the dataset further and explore complementary dynamic analysis techniques to enhance functionality prediction. We believe that releasing PLC-BEAD and the PLCEmbed framework as open-source resources will stimulate further research and lead to improved security practices for industrial control systems.
