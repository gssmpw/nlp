\section{Unified Korean Text Analyzer}
\label{sec:04_model}
%-----------------------------------------------------
\begin{figure}[t]
\includegraphics[width=1\columnwidth]{model.pdf}
\centering

\caption{Illustrative overview of \textsf{UKTA}.} 
\label{fig:approach}
\end{figure}
%-----------------------------------------------------


This section introduces \textsf{UKTA} (\textbf{U}nified \textbf{K}orean \textbf{T}ext \textbf{A}nalyzer), which sequentially performs low-level morpheme analysis (in Section \ref{sec:04_model_morpheme}), mid-level lexical feature analysis (in Section \ref{sec:04_model_feature}), and high-level automatic writing evaluation (in Section \ref{sec:04_model_scoring}).
The overall process for our tool is illustrated in Figure \ref{fig:approach}.



%-----------------------------------------------------
\begin{figure*}[t]
  \includegraphics[width=1\textwidth]{functionality.pdf}
  \centering
  \caption{\textsf{UKTA} functionality. \normalfont{\textbf{(A) Functionality in morpheme analysis results}: Providing both table (A-1) and list (A-1) format, with an interactive and intuitive intuitive interface; results can be downloaded in JSON and TXT formats (A-3). \textbf{(B) Functionality in lexical feature analysis results}: Provided as categorized lexical features (B-1) with a list format (B-2); results can be downloaded in TXT and CSV format with selected features (B-3).}}
  \label{fig:functions}
  \vspace{\baselineskip}
\end{figure*}
%-----------------------------------------------------


\subsection{Morpheme Analysis\label{sec:04_model_morpheme}}

This section describes the importance of Korean morpheme analysis and outlines the methods.
Morpheme analysis is the first step, low-level analysis before conducting Korean writing evaluation and lexical feature analysis. 
However, due to the nature of Korean, accurately segmenting wordpieces into morpheme units is challenging, as their forms can change due to different suffixes \cite{matteson2018rich}. 
Such errors can propagate to subsequent steps, including lexical feature analysis and writing evaluation. 

For example, morpheme analysis results should differ, `나\tiny{/NP}\normalsize{+는}\tiny{/JX}\normalsize{ (\textit{Na-Neun})' and `날}\tiny{/VV}\normalsize{+는}\tiny{/ETM}\normalsize{ (\textit{Nal-Neun})'}, even for the same type of wordpiece `나는 (\textit{Naneun})'. 
These errors can distort the values of some feature, reducing the reliability of feature analysis and writing evaluation. 
To minimize error propagation, we conducted morpheme analysis based on Bareun\footnote{https://bareun.ai/} analyzer, known for its highest accuracy, ensuring reliable results for subsequent lexical feature analysis and writing evaluation.

Our system provides morpheme analysis results in a clear, intuitive and user-friendly format as illustrated in Figure \ref{fig:functions}(A). It ensures easy interpretation and efficient analysis.


\subsection{Lexical Feature Analysis \label{sec:04_model_feature}} 



This section introduces the process of mid-level feature analysis and describes various features.
After morpheme analysis, diverse features are numerically evaluated based on the morphemes. 
We provide numerical results for 294 features, broadly categorized into three groups: \textit{\textsf{basic lexical features}}, \textit{\textsf{lexical diversity}}, and \textit{\textsf{cohesion}}.
These features not only provide numerical information but also offer explainable insights for subsequent writing evaluation results.
Detailed descriptions of each group are provided below.



\subsubsection*{Basic Features} 
The basic lexical features of a text represent its fundamental linguistic composition. 
These features include measurements such as count, density, and length of morphemes or words. 
Accurate tagging and categorization of morphemes are essential for ensuring the precision of these metrics. 
Additionally, a list of sentences containing each morpheme is provided to clarify their contextual use Figure \ref{fig:teaser}(B-3). 
This detailed examination of basic features offers fundamental insights into the structural and linguistic properties of the text, serving as a basis for calculating more complex features.

\subsubsection*{Lexical Diversity}
Lexical diversity \cite{hout2007richness} 
 is measured based on the degree of connectivity between sentences or paragraphs, reflecting vocabulary depth and linguistic diversity \cite{ha2019lexical, kim2024korcat}.
This measure is evaluated through the calculation of lexical features such as Type-Token Ratio (TTR) and other diversity features. 
We provide each lexical diversity feature for all tokens, as well as for each specific morpheme. An example lexical diversity output is provided in Figure \ref{fig:teaser}(B-3).
A detailed description of the key feature for measuring lexical diversity included in our system is provided as follows.

\begin{itemize}[leftmargin=1.1em]
\item \textsf{\textit{Type-Token Ratios}}: TTR, RTTR (Root TTR), and CTTR (Corrected TTR) are fundamental features for calculating lexical diversity. 
These features tend to decrease as text length increases, making them suitable for comparisons between texts of similar length \cite{joan2013ttr}.
Formally, these features are calculated as:
\begin{equation}
    \text{TTR} = \frac{t}{w}, \quad
    \text{RTTR} = \frac{t}{\sqrt{w}}, \quad
    \text{CTTR} = \frac{t}{\sqrt{2w}}
\end{equation}
where \(t\) and \(w\) are the number of unique morphemes and the total number of morphemes in a given text, respectively. 



\item \textsf{\textit{Equal segmented Type-Token Ratios}}: MSTTR (Mean Segmental TTR) and MATTR (Moving Average TTR) are both extensions of the traditional TTR, designed to address its sensitivity to text length. 
MSTTR calculates the average TTR over equal-length, and non-overlapping segments of a text, which standardizes the measure across different text lengths:
\begin{equation}
    \text{MSTTR} = \frac{1}{k} \sum_{i=1}^{k} \frac{t_i}{w_i} 
\end{equation}
where \(k = \left\lceil \frac{N}{n} \right\rceil\) is the number of non-overlapping segments, with \(N\) as the total number of tokens in the text and \(n\) as the window size. 
Here, \(t_i\) and \(w_i\) denote the number of unique tokens and the total number of morphemes in the \(i\)-th segment, respectively.
MATTR, in contrast, uses a moving window to compute TTR over overlapping segments, providing a more stable and consistent evaluation of lexical diversity across varying text lengths:
\begin{equation}
    \text{MATTR} = \frac{1}{k'} \sum_{i=1}^{k'} \frac{t_i}{w_i} = \frac{1}{k'n} \sum_{i=1}^{k'} t_i
\end{equation}
where \(k' = N-n+1\) is the number of overlapping segments.


\item \textsf{\textit{Textual lexical diversity}}:  
MTLD (Measure of Textual Lexical Diversity) addresses the sensitivity of TTR to text length by measuring how long a sequence of words must be to reach a fixed threshold of TTR decline. 
This approach provides a more stable and length-independent measure of lexical diversity.
In other words, MTLD is determined as the mean length of non-overlapping segments of varying length that satisfies the following:
\begin{equation}
    \text{MTLD} = \frac{N}{K}, \text{ where }\frac{t_i}{w_i} \leq \theta_\textrm{TTR}\text{ for all }1\leq i\leq K 
\end{equation}
\textit{i.e.}, \(K\) is the largest number of segments where the TTR value of each segment is below a predetermined threshold \(\theta_\textrm{TTR}\).

\item \textsf{\textit{Probabilistic lexical diversity}}: HD-D (Hypergeometric Distribution of Diversity) calculates the probability of encountering different morpheme types within randomly sampled subsets of the text, accounting for both morpheme occurrence and text length. 
Formally, HD-D calculates the average probability that each unique morpheme token \(t\) will appear at least once within a random sample of size \(S\):
\begin{equation}
    \text{HDD} = \frac{1}{S} \sum_{t} \left[ 1 - \frac{\binom{N - f_t}{S}}{\binom{N}{S}} \right]
\end{equation}
where \(f_t\) is the number of occurrences of token type \(t\) in the text. 

\item \textsf{\textit{Model-based lexical diversity}}:  
Voc-D estimates the relationship between tokens and types across various sample sizes, adjusting for the text length to provide a robust measure of vocabulary richness. This method addresses the limitations of raw TTR by accounting for variations in text length and complexity:
\begin{equation}
    \text{VOCD} = \argmin_{D} \sum_{n=35}^{50} \left( \overline{\text{TTR}}_n - \frac{D}{D+n} \right)^2
\end{equation}
where $\overline{\text{TTR}}_n$ is the empirical mean TTR of 100 random subsamples for size $n$, $D$ is the VOCD score that minimizes the difference between the empirical TTR values and the theoretical curve \(\frac{D}{D+n}\).
\end{itemize} 




\subsubsection*{Cohesion}

Cohesion assesses topic consistency within a paragraph and the similarity of meanings between sentences \cite{kim2024korcat}.  
First, the topic sentence is identified by comparing the extracted keyword with each sentence in the paragraph (topic consistency), followed by calculating the similarity between the topic sentence and the remaining sentences (sentence similarity). 
\textsf{UKTA} uses KeyBert \cite{maarten2023keybert} for extracting key topics (keywords) and SBERT \cite{nils2019sbert} for measuring sentence similarity. 
Additionally, lexical overlap is used as a measure of cohesion, assessing the shared morphemes between adjacent sentences or paragraphs \cite{crossley2019taaco, kim2024korcat}. 
Two main types of lexical overlap are used: adjacent overlap, which counts the number of overlapping morphemes, and binary adjacent overlap, which only checks for their presence.
A higher lexical overlap indicates a stronger structural similarity in the text.



\subsection{Automatic Writing Evaluation\label{sec:04_model_scoring}} 

This section introduces a high-level automatic writing evaluation process that integrates the previously suggested low- and mid-level lexical features with the existing Korean automated writing evaluation model. 
The automatic writing evaluation task can be formally described as follows: 
Given an essay \( X = \{x_i\}_{i=1}^{N} \), consisting of \( N \) sentences, the objective is to predict 10 evaluation scores \( y_{i=1}^{10} \) corresponding to distinct evaluation criteria (commonly referred to as \textit{rubric}) such as grammar, vocabulary, and consistency. 

The architecture of our automatic writing evaluation model is shown in Figure \ref{fig:approach}(c). 
Previous Korean automated writing evaluation models have primarily focused on raw text, without considering the overall characteristics of the essay \cite{lee2022argument, lee2023pasta}. 
However, our model is capable of training on both the raw essay features (\textit{i.e.}, sentence-level features) and the overall characteristics (\textit{i.e.}, essay-level features), including basic lexical features, lexical diversity, and cohesion.
These essay-level features provide a comprehensive perspective of the essay’s quality. 
These features are derived from the Korean morpheme analyzer, enabling the model to perform accurate essay-level analysis during training. 
This process improves the overall accuracy of the writing evaluation.
Finally, we use the attention weights from the attention layer to emphasize the importance of different essay-level features for each sample, highlighting which features contributed to the model's predictions. 
Unlike previous approaches, we provide multiple-view analysis results using these attention scores, enhancing both the reliability and explainability of the writing evaluation results.

In summary, we utilize both i) sentence-level and ii) essay-level representations, then iii) combining them for a reliable and explainable writing evaluation.
The detailed description of the proposed model is as follows:

\begin{enumerate}[label={{\roman*)}}, leftmargin=1.1em]
\item {\textsf{\textit{Extracting sentence-level representations.} } 
We extract sentence-level representations of the essay using a pre-trained language model and a bidirectional Gated Recurrent Unit (BiGRU), as illustrated in the bottom of Figure \ref{fig:approach}(c).
The process begins by dividing the essay into $N$ sentences, and each sentence is tokenized.
The tokenized sentences are input into KoBERT\footnote{https://github.com/SKTBrain/KoBERT}, a BERT model pre-trained on a large-scale Korean corpus.
This step produces $N$ embedding vectors, denoted as $\mathbf{e}_1, \mathbf{e}_2, \dots, \mathbf{e}_N$.
The resulting sentence-level embedding vectors are subsequently fed into a BiGRU. 
These embedding vectors are then passed through a BiGRU, which computes the final sentence-level representation of the essay using its last hidden state vector, $\mathbf{h} = [\overrightarrow{\mathbf{h}}; \overleftarrow{\mathbf{h}}]$.
}
%
\item {\textsf{\textit{Extracting essay-level representations.} } 
We first extract the lexical features $\mathbf{f} \in \mathbb{R}^{294}$, which consist of 294 values from the raw text. 
These features are normalized using a standard scaler:
\begin{equation}
\mathbf{f'} = \frac{\mathbf{f} - \mu}{\sigma}
\end{equation}
where $\mu$ and $\sigma$ represent the mean and standard deviation calculated from the feature, respectively. 
This normalization process ensures that each feature is on the same scale and comparable. 
The normalized feature vector $\mathbf{f'}$ is then passed through an attention layer, which assigns different importance weights $\mathbf{A}$ to each feature. 
The attention-weighted vector is computed through an element-wise multiplication of the attention weights and the normalized features:
\begin{equation}
\mathbf{f_A} = \mathbf{A} \odot \mathbf{f'}
\end{equation}
where $\odot$ denotes element-wise multiplication. 
This operation emphasizes the most relevant features for the task. 
The attention-weighted vector $\mathbf{f_A}$ is then passed through a dense layer along with $\mathbf{f'}$, which outputs the final essay-level representation $\mathbf{v_e}$.
}
%
\item {\textsf{\textit{Combining sentence- and essay-level representations.} } 
Finally, the generated sentence-level representation vector $\mathbf{h}$ is concatenated with the essay-level representation vector $\mathbf{v_e}$. 
This combined vector is then passed through a linear layer followed by a sigmoid activation function to predict essay scores for 10 evaluation rubric criteria. 
During the training, the mean squared error (MSE) loss function is used.
}

\end{enumerate} 

