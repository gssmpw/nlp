\section{Related Work}
\label{sec:02_relatedworks}

\subsection{Text analyzers} 

Text analysis has become an essential tool for evaluating written content, particularly in language education, and linguistic research \cite{mcnamara2010linguistic, ha2019lexical}. Modern English text analyzers utilize a combination of lexical and semantic metrics to assess the quality, coherence, and complexity of a text \cite{crossley2016tool}. These tools break down a text into measurable features, such as lexical diversity and cohesion, to provide quantitative insights. Although English text analyzers have seen significant success in both academic and practical applications, applying similar methodologies to Korean text analysis has been challenging due to linguistic differences. This section reviews key works on lexical diversity and cohesion, which are fundamental components in text analysis systems. 

Lexical density is a key indicator of a writer's vocabulary depth and is important for evaluating text quality in English. Common measures include the number of different words (NDW) \cite{miller1991contextual} and type/token ratios (TTR, RTTR, CTTR) \cite{chotlos1944iv, guiraud1959problemes, carroll1964language} to assess lexical diversity \cite{van2007comparing}. Advanced metrics like MSTTR \cite{johnson1944studies}, MATTR \cite{covington2007mattr}, MTLD \cite{mccarthy2005assessment}, HD-D \cite{mccarthy2010mtld}, and vocd-D \cite{mccarthy2007vocd} provide more detailed evaluations by analyzing text in fixed lengths or by considering vocabulary complexity. These measures strongly correlate with writing quality and lexical diversity \cite{ha2019lexical}. They are crucial in language assessment, where they complement human evaluations by offering objective, efficient assessments. Meanwhile, studies on Korean text analysis have been less extensive due to the difficulty of automated morpheme analysis. Although there have been attempts to apply lexical diversity measures to Korean \cite{lee2024exploring}, no comprehensive system has been developed that is easily accessible for automated evaluation or for use by educators for further analysis. This gap highlights the need for more robust and user-friendly tools to facilitate deeper exploration of Korean text analysis. 

Language models have emerged as prominent tools for evaluating text, offering sophisticated methods to assess various linguistic features such as coherence, complexity, and cohesion. Semantic cohesion, in particular, evaluates the consistency of a topic within a paragraph (topic consistency) and the similarity of meanings across sentences (sentence similarity). Transformer-based models, like BERT and SBERT, have been effectively utilized for measuring semantic cohesion in English texts \cite{doewes2022individual, rei2016sentence, ramesh2022automated}. However, despite the success of these models in English, there has been limited adoption of transformer-based language models for semantic cohesion analysis in Korean text. The unique linguistic characteristics of Korean, along with the challenges of morpheme segmentation, have slowed the development of such systems. 


\subsection{Automated Writing Evaluation Tools} 


Recently, the field of Natural Language Processing (NLP) has advanced significantly, leading to an increased demand for automated writing evaluation systems and prompting extensive research in this area \cite{jeon2021countering, uto2020neural, wang2022aessota}. The development of transformer-based models, such as BERT, has been particularly significant for automated writing evaluation, representing a breakthrough in the field. \cite{wang2022aessota} leverage this cutting-edge technology to develop an automated writing evaluation model that generates multi-scale essay representation vectors. Specifically, this model utilizes BERTâ€™s powerful sentence representation and essay learning capabilities to evaluate multiple aspects of essays. This research achieves state-of-the-art performance in the Automated Student Assessment Prize (ASAP)\footnote{https://paperswithcode.com/dataset/asap} task, which is based on English writing evaluation datasets.

In the context of automated writing evaluation for Korean, several studies have also been actively conducted. Notably, the National Information Society Agency (NIA) established the Korean \textsf{Essay Evaluation Dataset}\footnote{https://url.kr/qilx39} in 2021 through its \textsf{AI-HUB}\footnote{https://www.aihub.or.kr/} platform, providing a crucial resource for research on automated writing evaluation tools for Korean. In addition to supplying the dataset, AI-HUB introduced a baseline evaluation model, which has since served as a starting point for further development of Korean automated evaluation systems. For instance, \cite{lee2022argument} proposes an automated writing evaluation model that maximizes the potential of the Korean dataset by combining argument mining techniques and a RoBERTa-based model pre-trained on the Korean Language Understanding Evaluation (KLUE) \cite{park2021klue} dataset. Their model effectively analyzes the logical structure of Korean essays by generating representation vectors that accurately reflect argumentative structures. Moreover, \cite{lee2023pasta} suggests \textsf{PASTA-I}, a KoELECTRA \cite{kim2020lmkor}-based automated scoring system for Korean essays and written responses, utilizing the \textsf{Essay Evaluation Dataset}.

However, these models relied on sentence-piece tokenizers, which are primarily designed for English, rather than Korean-specific morpheme-based tokenizers suited to the complex agglutinative structure of the Korean language. This makes the models more susceptible to error propagation when analyzing Korean. Additionally, these models did not provide multi-view analysis or sufficient explanation regarding the evaluation process, which makes it challenging to ensure the reliability of the evaluations, particularly given the inherent complexity of the language. As a result, these models have faced difficulties in delivering accurate and trustworthy assessments of Korean essays.