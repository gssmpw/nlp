\section{Related Works}
Opacity was first introduced by Mazar\'e \cite{mazare2004using}  in the context of cryptographic protocols and has since been expanded to address the security of various types of secrets. For example, state-based opacity ensures that an observer cannot determine whether a secret state has been reached, while language-based opacity prevents the observer from discerning whether the system's execution belongs to a set of secret trajectories \cite{berard2015probabilistic, bryans2008opacity, saboori2010opacity}. In system and control literature,
opacity has been extensively studied in supervisory control of \ac{des}s, with a \emph{qualitative} measure: A system is \emph{qualitatively} opaque if an observer, with partial observations of the system, cannot infer any secret information with certainty \cite{jacob2016overview, saboori2010verification, saboori2011opacity, wu2013comparative, yin2019infinite}. In an opaque system, a trajectory satisfying the secret property must be observation-equivalent to a trajectory that violates it.
For stochastic systems, existing work employs probabilistic opacity, which measures the probability that a secret may be disclosed \cite{saboori2010opacity, saboori2013current, keroglou2018probabilistic} or quantifies the security level of a system by the probability of generating an opaque trajectory \cite{berard2015probabilistic, udupa2024planning}. A comprehensive review of various notions of opacity and their enforcement techniques is provided \cite{jacob2016overview}. 

The enforcement of qualitative opacity in \ac{des}s can be broadly classified into two approaches:    control design to restrict system behavior or dynamic information releasing to limit the observer's observations. In the first approach, opacity is enforced by designing a supervisory controller \cite{saboori2010verification} or by solving an opacity-enforcement game \cite{helouet2018opacity,udupa2023opacity}. 
However, it may not always be feasible or practical to modify or restrict the system's behavior. For example, in the case of mobile applications unintentionally disclosing personal information, it is not practical to restrict a user's movement or prevent them from visiting certain locations. Therefore, an alternative approach explored in the literature involves altering the public observations relayed to the observer. 

This alternative line of work is most closely related to our work and focuses on enforcing opacity by restricting/altering the observer's observations. In  \cite{cassez2012synthesis}, the authors introduce the concept of a ``mask''   to limit the system's observable outputs, either statically or dynamically. A dynamic mask changes   the external observer's observation mapping at each execution step for opacity enforcement. Dynamic masks have been designed to enforce current-state opacity \cite{cassez2012synthesis}   and infinite-state opacity\cite{yin2019infinite}. Alternatively,  the work\cite{ji2018enforcement,ji2019opacity} developed  selective insertion and/or deletion of output observations for opacity enforcement. % These methods effectively enforce qualitative opacity by utilizing edit functions. 

A dynamic mask can be viewed as an information-flow control mechanism that  regulates the information to the observer by   enabling or disabling the associated sensors \cite{yin2019synthesis}. Closely related to dynamic masking,  dynamic sensor activation has been extensively studied in the context of \ac{des}s \cite{sears2016minimal,yin2019general}, for  fault diagnosis \cite{cassez2008fault,thorsley2007active,wang2010minimization} and detectability \cite{shu2013online}. %  Additionally, \cite{yin2019general} introduces a general framework for addressing the sensor activation problem. 
The work \cite{zhang2015maximum} studied the problem of maximum information release while ensuring the opacity of \ac{des}. More recently, the authors \cite{wintenberg2022dynamic} presented a dynamic obfuscation framework that enables an intended recipient to infer sensitive information while preventing unintended recipients from making similar deductions.  

Building on the insight from qualitative opacity enforcement using dynamic masks and dynamic sensor activation, our work distinguishes itself by focusing on \emph{quantitative, information-theoretic} definitions of opacity \cite{shi2024information} and optimal opacity enforcement under cost constraints. Specifically, we use conditional entropy as a measure of information leakage, subject to a generic cost associated with masking. The use of conditional entropy as the measure of information leakage allows us to have a symmetric notion of opacity, \ie, the opacity will be minimal when the observer is consistently confident that the agent either visited or avoided the secret states given an observation. 
This sets our approach apart from qualitative opacity-enforcement approaches \cite{cassez2012synthesis,yin2019general}. %, which also considers the cost of sensor activation/masking but aims to generate an optimal dynamic mask without explicitly framing the problem in terms of quantitative opacity.   

In addition to  opacity,  differential privacy has been widely studied in \ac{cps} \cite{hassan2019differential}. It protects privacy by adding calibrated noise, balancing privacy and data accuracy. % While its advantages include low computational complexity and the retention of original data, it also faces challenges such as the ``curse of dimensionality'' and a reduction in data utility due to the introduction of random noise. A comprehensive and up-to-date survey of various differential privacy methods can be found in \cite{hassan2019differential}.
% \cs{I think differential privacy is not needed if you want to reduce the length.}
Our approach differs fundamentally from differential privacy in that it uses different measures of information leakage and leverages existing   noises in the stochastic environment dynamics and imperfect observation channels for opacity, rather than introducing noise to the system. 




% \jf{focus this part on 1) definining what is qualitative opacity; and 2) what are existign papers on dynamic masking for qualitative opacity? include differential privacy. }