%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Ball-and-antichain method}
\label{sec:approx}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Section~\ref{sec:approxnk2} details a straightforward approximation algorithm for AMMD, exploiting the polynomial time complexity of the MA problem in digraphs, as discussed in the previous section.
This algorithm has an approximation guarantee of $\frac{1}{n-k+1}$, which is not very useful in a typical regime of small $k$, but it gives insight into the use of the MA problem for approximating AMMD.

In Section~\ref{sec:approx16k} we modify the algorithm from Section~\ref{sec:approxnk2} by first clustering the points based on the $\dmax$ distances between them. The subspace induced by the cluster centers has some very useful properties, which leads to an approximation algorithm with a multiplicative guarantee of $\frac{1}{6k}$ for AMMD.

Finally, in Section~\ref{sec:speeding}, we discuss improvements to look for better solutions and speed up the algorithm while maintaining the approximation guarantee.

\begin{algorithm}[t]
\caption{Naive Maximum Antichain method.}
\label{algo:app_ma}
\begin{algorithmic}[1]
%\Require graph $G$. 
\Require space $(U, d)$ and integer parameter $k\geq 2$.
\ForAll {$R \in \{d(i,j)>0 \mid i, j \in U,  i \neq j\}$}
	\State Create $G_R = (U,A)$, with $ij \in A \Leftrightarrow d(i,j)<\frac{R}{n-k+1}$. \label{line:naive_create_G}
	\State $M \define$ \text{Maximum antichain of} $G_R$.
	\If{$|M| \geq k$,} $S_R \leftarrow \text{any }k \text{ points from } M$.

	\EndIf
\EndFor
\Ensure the set $S_R$ with the largest $\diver{S_R}$ value. 
\end{algorithmic}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Naive approach based on antichains}
\label{sec:approxnk2}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We begin by describing the naive approach for approximating AMMD.
Assume for the moment that we know $R = R^*$, the optimal value for an AMMD instance.
Consider a digraph $G = (U, A)$, where $ij \in A$ if and only if $d(i, j) < R$.
Then an independent set, say $O$, in $G$ of size $k$ will have $\diver{O} = R^*$.
Unfortunately, finding a maximum independent set in a graph is an \NP-hard problem with a weak approximation guarantee~\cite{hastad1996clique}.

Therefore, we lower the cutoff by setting it to $\frac{R}{n-k+1}$. This makes the underlying graph
so sparse that we can guarantee that the graph contains an antichain, say $S$, of size $k$.
Since an antichain is also an independent set, we know that $\diver{S} \geq \frac{R}{n-k+1}$.
We can find the antichain in polynomial time. Finally, we do not know $R^*$ but we know that it
is one of the distances. Therefore, we test every distance; there are at most $n(n - 1)$ of such distances.
The pseudo-code for the algorithm is given in Algorithm~\ref{algo:app_ma}.


\begin{theorem}
\label{thm:naivemaxanti}
Algorithm~\ref{algo:app_ma} is an $\frac{1}{n-k+1}$-approximation for AMMD in $\bigO(n^{4 + o(1)} \log n)$ time with high probability.
\end{theorem}

The proof is given in Appendix.

We finalize this section by observing that we could binary search for the largest $R$ value for which $G_R$ (defined in line~\ref{line:naive_create_G} in Algorithm~\ref{algo:app_ma}) still has an antichain of size $k$. First, sort the unique distances in time $\bigO(n^2 \log n)$, after which we need at most $\bigO(\log n)$ calls to find this $R$. Since for this $R$ we have $R \geq R^*$, we retain the same approximation guarantee. The binary search performs $\bigO(\log n)$ MA computations, and all of them need to succeed. Proposition~\ref{prop:multima} implies that the algorithm solves the problem in
$\bigO(n^{2 + o(1)}\log^2 n \log \log n)$ time with high probability.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Refined approach: clustering and antichains}
\label{sec:approx16k}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


The problem with Algorithm~\ref{algo:app_ma} is that it is using a very conservative cutoff of $\frac{R}{n-k+1}$, leading
to a weak guarantee. 
We show that we can relax this cutoff to $\frac{R}{6k}$, by first clustering the space $(U,d)$ according to the $\dmax$ distances.
The discovered cluster centers will have the property that two centers must have a large $\dmax$ distance between them.
A consequence of this property is that the resulting graph contains a large antichain, a large chordless cycle, or a large shortest path with no backward edges.
It turns out that we can search for all 3 subgraphs in polynomial time, and using those we can extract an independent set in polynomial time.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ptitle{Clustering step}
Next, we describe the clustering step, as given in
Algorithm~\ref{algo:ballcover}. Here the algorithm greedily covers $U$ with a family of pairwise disjoint sets $\set{A_t}$. 
Each $A_t$ is constructed by selecting an unmarked point as a center $c_t$, and adding all unmarked points $v$ with $\dmax(c_t, v) < R$. Since all the vertices in $A_t$ are marked at the end of step $t$ (line~5), they cannot be selected by any $A_{t'}$ for $t' > t$. It follows that for every $t \neq t'$ we have $A_t \cap A_{t'} = \emptyset$. 

Algorithm~\ref{algo:ballcover} terminates in at most $n$ steps, since every set $A_t$ contains at least one point, namely the center point $c_t$. Algorithm~\ref{algo:ballcover} runs in $\bigO(n^2)$ time.


Each $A_t$ is constructed by selecting vertices that have a small $\dmax$ distance to their center $c_t$. Line~4 in Algorithm~\ref{algo:ballcover} ensures that the $\dmax$ distances between two distinct centers are at least $R$. 

To analyze this further, let us define $R'$ as the smallest distance that is at least one third of the optimum $R^*$,
\begin{equation}
\label{def:R'}
R' = \min\{d(u,v) \mid d(u,v) \geq R^*/3, \ u,v \in U, \ u\neq v\}.
\end{equation}
If we then perform the clustering for any $R \leq R'$, there will be $k$ centers that also have a pairwise $\dmin$ distance of at least $R^*/3$ between them. This is captured by Proposition~\ref{prop:cluster} and Corollary~\ref{cor:clusterphase}.

\begin{algorithm}[t]
\caption{$\algclust{U, d, R}$, clusters $U$ according to $\dmax$.}\label{algo:ballcover} 
\begin{algorithmic}[1]
%\Require graph $G$. 
\Require space $(U, d)$ and parameter $R > 0$.
\State Label all $u \in U$ as unmarked, let ${U}' \define \emptyset$ and  $t \leftarrow 1$.
\While {there exists an unmarked point}
	\State $c_t \define $ any unmarked point.
	%\State $c_t \define $ unmarked point $\text{arg} \max_{c} \dmin (c,{U}')$
	\State $A_t \define \{\text{unmarked } v \in U \mid \dmax(c_t,v) < R \}.$ 
	\State Mark all $v \in A_t$. 
	\State ${U}' \define {U}' \cup \{c_t\}$ and $t \define t+1$.
\EndWhile
\Ensure ${U}'.$
\end{algorithmic}
\end{algorithm}

\begin{prop}
\label{prop:cluster}
Let $O$ be an optimal solution to AMMD with optimum $R^*$ and $R'$ as defined in Equation~\ref{def:R'}.
If $R \leq R'$, then the following two statements regarding Algorithm~\ref{algo:ballcover} are true.
\begin{itemize}
\item For all $t$ it holds that $|A_t \cap O| \leq 1$.
\item For any $t\neq t'$ for which $|A_t \cap O|=1$ and $|A_{t'} \cap O|=1$, it holds that $\dmin(c_t,c_{t'}) \geq R' \geq R^*/3$.
\end{itemize}
\end{prop}
\begin{proof}
For the first statement, suppose that $A_t$ contains two distinct $x, y \in O, x \neq y$.
Then it holds that $d(x,y) \leq d(x,c_t)+d(c_t,y)$. Since $d(x,c_t)$ and $d(c_t,y)$ are strictly less than $R\leq R'$, they must be less than $R^*/3$ because $R'$ is defined as the smallest distance greater or equal to $R^*/3$, so any distance strictly smaller than $R'$ must be less than $R^*/3$. Thus, $d(x,y) < 2R^*/3 < R^*$, a contradiction since $x, y \in O, x \neq y$ implies that $d(x,y) \geq R^*$.

For the second statement, assume that $A_t$ contains $x \in O$ and $A_{t'}$ contains $y \in O$. Since $A_t$ and $A_{t'}$ are disjoint, we have $x \neq y$. Note that $d(x,y) \leq d(x,c_t)+d(c_t,c_{t'})+d(c_{t'},y)$, where $d(x,c_t)<R \leq R'$ and $d(c_{t'},y)<R \leq R'$. This means $d(x,c_t)$ and $d(c_{t'},y)$ must be less than $R^*/3$ by the definition of $R'$. So if $d(c_t,c_{t'}) < R'$, we would have $d(x,y) < 3 R^*/3 = R^*$, a contradiction. Similarly, we cannot have $d(c_{t'},c_t) < R'$ either, which means $\dmin(c_t,c_{t'}) \geq R' \geq R^*/3$.
\end{proof}

\begin{corollary}
\label{cor:clusterphase}
Let ${U}' = \algclust{U, d, R}$.
For every $u, v \in {U}', u \neq v$ we have $\dmax(u,v) \geq R$. Additionally, if $R \leq R'$, then ${U}'$ contains a set $S$, for which $|S| = k$ and $\diver{S} \geq R' \geq R^*/3$.

\end{corollary}
 
Corollary~\ref{cor:clusterphase} states that as long as $R \leq R'$, from any instance space $(U, d)$ we can efficiently find a subset ${U}' \subseteq U$ 
such that ${U}'$ still contains $k$ points with a pairwise $\dmin$ distance of at least $R^*/3$ between them. This enables us to restrict ourselves to ${U}'$, at the expense of a decrease in the optimal value by a factor of three.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ptitle{The \algbac{} algorithm}
We are ready to describe our algorithm which we call \algbac{} (shortened for ball-and-antichain). The pseudocode is given in Algorithms~\ref{algo:bac}--\ref{algo:extract}.
Similar to the naive approach we iterate over all distances. For each candidate distance $R$,
we cluster the space to get the centers $U'$.
We then construct a graph $G$ with edges corresponding to distances shorter than $\frac{R}{2k}$.
We can guarantee that there is ($i$) a large chordless cycle, ($ii$) a long shortest path with no backward edges,
or ($iii$) a large antichain. In the first two cases, we can obtain an independent set by selecting $k$ vertices with odd indices.
In the last case, it is enough to select $k$ vertices from the found antichain.

\begin{algorithm}[t]
\caption{\algbac{U, d, k}, an $\frac{1}{6k}$-approx. algorithm for AMMD.}\label{algo:bac} 
\begin{algorithmic}[1]
\Require space $(U, d)$ and integer parameter $k\geq 2$.
\ForAll {$R \in \{d(i,j)>0 \mid i, j \in U,  i \neq j\}$} \label{line:loop}
	\State ${U}' \define \algclust{U, d, R}$. 
	\State $\algextract{U', d, R/(2k), k}$.
\EndFor 

\Ensure the set returned by $\algextract{}$ with the largest $\diver{}$ value.
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[t]
\caption{\algextract{U, d, \sigma, k}, subroutine for extracting a candidate set.}\label{algo:extract} 
\begin{algorithmic}[1]
\Require space $(U, d)$, threshold $\sigma$, and integer parameter $k\geq 2$.
    \State Create $G = (U,A)$, with $ij \in A \Leftrightarrow d(i,j)< \sigma$.\label{line:create_G}
    \If{$G$ contains a cycle}
        \State $C \define$ chordless cycle in $G$. \label{line:cycle}
    \EndIf
    \State $G_c \define$ the condensation of $G$.
    \State $M \define$ maximum antichain of $G_c$.
    \State $L \define$ shortest path of length $2k-1$ in $G_c$ or longest found. \label{line:path}
    \If{$C$ exists and $|C| \geq 2|M|-1$ and $|C| \geq |L|$}
        \State $I \define$ points with odd indices from $C$.
    \ElsIf{$2|M|-1 \geq |L|$} 
        \State $I \define$ points in $G$ corresponding to points in $M$.
    \Else{} 
        \State $I \define$ points in $G$ corr. to points with odd indices in $L$.
    \EndIf
\Ensure greedily selected $k$ points from the set $I$, if found.
\end{algorithmic}
\end{algorithm}

Next, we will prove the approximation guarantee. 
First, we need Lemma~\ref{lem:cycles}, which states that there cannot exist small cycles in $G$.

\begin{lemma}
\label{lem:cycles}
For any $R > 0$, any cycle $C$ in the digraph $G$ constructed in $\algextract{U', d, \frac{R}{2k}, k}$ (see Alg.~\ref{algo:extract})
has at least $2k + 2$ distinct vertices.
\end{lemma}
\begin{proof}
Suppose $G$ contains a cycle $C = (v_1,\ldots,v_{\ell},v_{1})$ of length $\ell$. 
Since $C$ is a cycle in $G$, it holds that $d(v_{\ell},v_1) < \frac{R}{2k}$, by definition of $G$.
On the other hand, as ${U}'$ is the output of \algclust{}, Corollary~\ref{cor:clusterphase} states that $\dmax(v_1,v_{\ell}) \geq R$. This implies that $d(v_1,v_{\ell}) \geq R$. Now the triangle inequality for $d(v_1,v_{\ell})$ along the edges of cycle $C$ implies
\[
	R \leq d(v_1,v_{\ell}) \leq \sum_{i = 1}^{\ell - 1} d(v_i, v_{i + 1}) < (\ell - 1) \frac{R}{2k}. 
\]
Solving for $\ell$ leads to $\ell > 2k + 1$, which proves the claim.
\end{proof}

\begin{theorem}
\label{thm:approx}
\algbac{U, d, k} is an $\frac{1}{6k}$-approximation to AMMD. 
\end{theorem}

\begin{proof}
Line~\ref{line:loop} in Algorithm~\ref{algo:bac} iterates over all unique distances, and one of them is equal to $R'$ as defined in Eq.~\ref{def:R'}.
We will show that for $R \leq R'$, the digraph $G$, constructed in line~\ref{line:create_G} in Algorithm~\ref{algo:extract}, has an antichain $M$ of size $|M| \geq k$, or there exists either a shortest path
with no backward edges or a chordless cycle from which we can select $k$ independent vertices. An independent set $I$ of size $\abs{I} \geq k$ in graph $G$ then yields a solution with a diversity score of $\diver{I} \geq \frac{R}{2k}$, which for $R = R'$ is $\diver{I} \geq\frac{R'}{2k} \geq \frac{R^*}{6k}$ proving the theorem. 

Note that since the nodes in an antichain have no paths connecting them, it suffices to look for an antichain in the condensation $G_c$, whose vertices are the strongly connected components of $G$. If there exists an antichain $M$ of size $|M| \geq k$, we are done as the nodes in an antichain are independent. 

Consider the case where the maximum antichain $M$ has size $|M|<k$ and assume $G$ is a DAG. Note that when $G$ is a DAG the condensation $G_c$ is equivalent to $G$.

Corollary~\ref{cor:clusterphase} states that if $R \leq R'$ then ${U}'$ contains a subset
$S \subseteq {U}'$ for which $|S| = k$ and $\diver{S} \geq R'$. Then there must be a path in $G$ between some pair of distinct points in $S$. Otherwise, $S$ is an antichain of size $k$.

Let this pair of nodes be $x, y \in S, x \neq y$, with a path $(x = v_1, \ldots, v_\ell = y)$ from $x$ to $y$ in $G$.
Then the triangle inequality implies
\[
	R' \leq \diver{S} \leq d(x, y) \leq \sum_{i=1}^{\ell-1} d(v_i, v_{i + 1}) < (\ell - 1) \frac{R}{2k} \leq (\ell - 1) \frac{R'}{2k}.
\]
Therefore, $\ell$ must be at least $2k + 2$ meaning any path between $x$ and $y$ must have at least $2k + 2$ vertices. Hence, there is a shortest path of length $2k + 2$ while a shortest path $L$ of length $2k - 1$ is sufficient.
There cannot be any shortcut edges in $L$, since $L$ is a shortest path. Nor can there be any backward edges in $L$, since $G$ is a DAG.
Consequently, elements in $L$ with odd indices form an independent set $I$ of size $k$.

Finally, assume that $G$ is not a DAG. Then
there is a chordless cycle $C$. Lemma~\ref{lem:cycles} guarantees that $C$ has at least $2k + 2$ elements.
Then, elements in $C$ with odd indices form an independent set $I$ of size $\abs{I} \geq k+1 > k$.
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ptitle{Time complexity of Algorithm~\ref{algo:bac}}
The iteration in line~\ref{line:loop} is over at most $\bigO(n^2)$ possible $R$
values.
%The digraph $G$ might be dense, so we assume its number of edges is $\bigO(n^2)$.
Both detecting a cycle in $G$ and extracting the chordless
cycle from it (line~\ref{line:cycle} of Algorithm~\ref{algo:extract}) take $\bigO(n^2)$ time. Computing the
maximum antichain can be done in $\bigO(n^{2 + o(1)} \log n)$ time
(Proposition~\ref{caceres}).

To compute the shortest path we can use the following approach:
Let $D = A + I$, where $A$ is the adjacency matrix of $G$,
and $I$ is the identity matrix. Then $D^\ell_{ij} > 0$ if and only if
there is a path of at most length $\ell$ from $i$ to $j$.
Consequently, there is a shortest path from $i$ to $j$ of length $2k - 1$ if and only if
$D^{2k-1}_{ij} > 0$ and $D^{2k-2}_{ij} = 0$. We can compute the necessary matrices
in $\bigO(n^{\omega}\log k)$ time, where $\omega < 2.373$ is the matrix multiplication exponent~\cite{alman2021refined}. Once $i$ is found, we use Dijkstra's algorithm to recover the path in $\bigO(n^2)$ time.

Overall we have a worst-case time complexity of $\bigO(n^{2+\omega} \log k)$.

Note that in practice, we do not use the matrix multiplication method. Instead,
we compute a shortest path tree from every node. This leads to a slower theoretical time but the algorithms
are still practical as demonstrated in the experiments.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Practical improvements}
\label{sec:speeding}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We discuss several modifications, which speed up \algbac{}, and/or might improve the solution quality in practice. 

\ptitle{Algorithm \algbacb{}} The first modification to \algbac{}, given in Algorithm~\ref{algo:bacb}, is
aimed at improving solution quality, at the expense of a slightly larger
running time. We will call this modified algorithm \algbacb{}. Note that the $\frac{1}{6k}$-approximation guarantee comes from the fact
that we add an edge $ij$ to $G$ whenever $d(i, j) < \frac{R}{2k}$. If we can increase
this cutoff to, say $R \times \alpha$, \emph{and} still find a feasible set, then the found set $S$ 
is guaranteed to have $\diver{S} \geq R\alpha$, that is we will obtain an $\alpha$-approximation.


\begin{algorithm}[t]
\caption{\algbacb{U, d, k}, an $\frac{1}{6k}$-approx. algorithm for AMMD.}\label{algo:bacb} 
\begin{algorithmic}[1]
\Require space $(U, d)$ and integer parameter $k\geq 2$.
\State $R_1 < \ldots < R_{m} \define $ all unique positive distances sorted.
\For{every $i = 1, \ldots, m$} 
	\State ${U}' \define \algclust{U, d, R_i}$. 
	\If {$\algextract{U', d, R_i /(2k), k}$ exists}
		\State $a \define \min\set{s \mid R_i / (2k) < R_s}$, $b \define i$.
		\While {$a \leq b$}
			\State $t \define \floor{\frac{a+b}{2}}$.
			\If {$\algextract{U', d, R_t, k}$ exists}
				$a \define t + 1$
			\Else{}
				$b \define t - 1$
			\EndIf
		\EndWhile
	\EndIf
\EndFor 

\Ensure the set returned by $\algextract{}$ with the largest $\diver{}$ value.
\end{algorithmic}
\end{algorithm}


For every $R$ in the iteration of \algbacb{}
that gives a feasible solution for the threshold $\frac{R}{2k}$, we will try to
improve the solution value by searching for a cutoff value larger than
$\frac{R}{2k}$ when constructing the graph $G$ (line~\ref{line:create_G} of Algorithm~\ref{algo:extract}).
If \algbacb{} is unable to find a feasible solution for a
certain $R$, then we continue
iterating to the next $R$. 

To this end, if \algbacb{} has found a feasible set for some $R$, we use the binary search
to search for larger cutoffs in $[\frac{R}{2k},R]$.
Note that only when we use the cutoff $
\frac{R}{6k}$ are we theoretically guaranteed that we can extract $k$
independent points. Nonetheless, \algbacb{} will attempt to do this for larger
cutoffs as well. The binary search requires $\bigO(\log n)$ tests for
a single $R$ since we can assume that the cutoff is one of the distances. Hence,
the computational complexity of \algbacb{} is in $\bigO(n^{2+\omega} \log k \log
n)$.


\ptitle{Algorithm \algbacf{}} This algorithm speeds up \algbac{} while at the same time attempting to improve solution quality. Similarly to Section~\ref{sec:approxnk2}, we can replace the loop of Algorithm~\ref{algo:bac} (line~\ref{line:loop}) with a binary search in an attempt to find a maximal $R$ for which we find a feasible solution. This reduces the iterations from $\bigO(n^2)$ to $\bigO(\log n)$.

\begin{algorithm}[t]
\caption{\algbacf{U, d, k}, an $\frac{1}{6k}$-approx. algorithm for AMMD.}\label{algo:bacf} 
\begin{algorithmic}[1]
\Require space $(U, d)$ and integer parameter $k\geq 2$.
\State $R_1 < \ldots < R_{m} \define $ all unique positive distances sorted.
\State $a \define 1$, $b \define m$
\While {$a \leq b$}
    \State $t \define \floor{\frac{a+b}{2}}$.
	\State ${U}' \define \algclust{U, d, R_t}$. 
	\If {$\algextract{U', d, R_t / (2k), k}$ exists}
		$a \define t + 1$
	\Else{}
		$b \define t - 1$
	\EndIf
\EndWhile
\State $i \define a-1$.
\State ${U}' \define \algclust{U, d, R_i}$. 

\State $a \define \min\set{s \mid R_i / (2k) < R_s}$, $b \define i$.
\While {$a \leq b$}
    \State $t \define \floor{\frac{a+b}{2}}$.
	\If {$\algextract{U', d, R_t, k}$ exists}
		$a \define t + 1$
	\Else{}
		$b \define t - 1$
	\EndIf
\EndWhile

\Ensure the set returned by $\algextract{}$ with the largest $\diver{}$ value.
\end{algorithmic}
\end{algorithm}


Note that unlike in Section~\ref{sec:approxnk2}, this binary search might not find the globally largest $R$ value for which we can extract a feasible solution.
This is because there may be distance values $R_i > R_j > R'$ such that $R_i$ yields a feasible solution while $R_j$ does not.

However, we can still sort the
unique distances and use binary search to find
$R_{j}$ with a feasible solution, say $S_j$, such that the next value
$R_{j+1} > R_{j}$ does not yield a feasible solution.

Moreover, any $R \leq R'$ yields a feasible solution. This implies $R_{j} \geq R'$ and we get the same guarantee as \algbac{}, because
\[
	\diver{S_{j}} \geq \frac{R_j}{2k} \geq \frac{R'}{2k} \geq \frac{R^*}{6k}.
\]

Similarly to \algbacb{}, \algbacf{} then attempts to improve the cutoff
value for constructing $G$ by again binary searching for an improved cutoff
in the interval $[\frac{R_j}{2k},R_j]$ for which \algextract{} still finds a feasible
solution.
In the worst case, this adds
another $\bigO(\log n)$ iterations, which does not change the asymptotic
running time of the algorithm.
The running time for solving $\bigO(\log n)$ MA instances, as given by Proposition~\ref{prop:multima},
is dominated by the time needed to check for shortest paths of length $2k-1$.
In summary, the running time of \algbacf{} is
\[
	\bigO(n^2 \log n + 2 n^{\omega} \log n \log k) = \bigO(n^{\omega} \log n \log k).
\]

This is a considerable improvement over the running time of
\algbac{}, making \algbacf{} orders of magnitude faster while retaining the same theoretical guarantees.


\ptitle{Further improvements}
As the graph $G$ constructed in Algorithm~\ref{algo:extract} may be split into multiple disconnected components, we improve the search for independent sets by looking for the cycles, antichains, and long shortest paths in each weakly connected component of $G$ separately. We then take the union of the independent sets for each component, aiming to have $k$ points in total.

In addition, rather than choosing the centers arbitrarily in Algorithm~\ref{algo:ballcover}, we start by picking one of the vertices with the largest $\dmin$ distance. This heuristic is similar to the approach for solving MMD~\citep{ravi1994heuristic}. For the subsequent iterations, we choose the point furthest from the current set of chosen centers, as in Algorithm~\ref{algo:greedydmin}.

Finally, in practice many of the unique distances $R_1, \ldots, R_m$ may result in the same clustering ${U}'$ in Algorithms~\ref{algo:bac} and~\ref{algo:bacb}. We avoid these duplicate computations by grouping the $R$ values that yield the same clustering.
