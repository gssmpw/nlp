\section{Conclusion}
In this paper, we demonstrated that calibration
is a powerful tool for algorithms with predictions, bridging the gap between traditional theoretical approaches---which rely on global uncertainty estimates---and modern ML methodologies that offer fine-grained, instance-specific uncertainty quantification.
We focused on the ski rental and online scheduling problems, developing online algorithms that exploit local calibration guarantees to achieve strong average-case performance. For both problems, we highlighted settings where our algorithms outperform existing approaches, and we supported these theoretical findings with empirical evidence on real-world datasets. Beyond these two case studies, we believe calibration-based approaches offer broad potential for designing online decision-making algorithms, particularly in scenarios that require balancing worst-case robustness with reliable per-instance predictions.