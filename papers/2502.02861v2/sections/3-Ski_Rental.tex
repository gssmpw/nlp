\section{Ski Rental}
In this section, we analyze calibration as a tool for uncertainty quantification in the classic online ski rental problem.
All omitted proofs in this section are in \cref{appendix: ski-rental-proofs}.

\subsection{Setup}
\paragraph{Problem.} A skier plans to ski for an unknown number of days $Z \in \mathbb{N}$ and has two options: buy skis at a one-time cost of $b \in \mathbb{N}$ dollars or rent them for $1$ dollar per day. The goal is to determine how many days to rent before buying, minimizing the total cost. If $Z=z$ were known \textit{a priori}, the optimal policy would rent for $b$ days when $z < b$ and buy immediately otherwise, costing $\min\{z, b\}$. Without knowledge of $z$, competitive ratios of 2 \citep{Karlin88:Competitive} and $\frac{e}{e-1}$ \citep{Karlin94:Competitive} are tight for deterministic and random strategies, respectively. For convenience, we study a continuous variant of this problem where $Z, b, k \in \mathbb{R}_{\geq 0}$ as in prior work \citep{Anand20:Customizing,Sun24:Online}.

\paragraph{Predictions.} Let $\cX$ be a set of skier features, $\cI=\R_{\geq 0}$ be the set of possible days skied, and $\cD$ be an unknown distribution over feature/duration pairs $\mathcal{X} \times \R_{\geq 0}$. Motivated by the form of the optimal offline algorithm, we analyze a calibrated predictor $f:\cX \to [0,1]$ for the target $T(z)=\mathbbm{1}_{\{z > b\}}$, indicating if the skier will ski for more than $b$ days. For $(X, Z) \sim \cD$, a prediction of $f(X) \approx 1$ (respectively, $f(X) \approx 0$) means $Z > b$ (respectively, $Z \leq b$) with high certainty.

\paragraph{Prediction-aided ski rental.} A deterministic prediction-aided algorithm $\cA_k$ for ski rental takes as input a prediction $f(X)=v$ and returns a recommendation: ``rent skis for $k(v)$ days before buying.'' The cost of following this policy when skiing for $z$ days is \[\ALG(\cA_k, v, z) = \begin{cases}
    k(v) + b & \text{if $z > k(v)$} \\
    z &\text{if $z \leq k(v)$}
\end{cases}.\]
Our goal is to select $k:[0,1] \to \R_+$ that minimizes the multiplicative expected CR, denoted $\E[\CR(\cA_k)]$.

\subsection{Ski rental with calibrated predictions}
In \cref{alg: optimal-ski-rental}, we introduce a deterministic policy for ski rental based on calibrated predictions. To avoid following bad advice, the algorithm defaults to a worst-case strategy of renting for $b$ days unless the prediction is confident that the skier will ski for at least $b$ days. In this second case, the algorithm smoothly interpolates between a strategy that rents for $b$ days and one that rents for $b \sqrt{\alpha/(1+\alpha)}$ days, where $\alpha \in [0,1]$ is a bound on local calibration error that hedges against greedily following predictions.

\begin{restatable}{theorem}{CRUB}
\label{thm: ski-rental-cr}
Given a predictor $f$ with mean-squared error $\eta$ and max calibration error $\alpha$, \cref{alg: optimal-ski-rental} achieves
$\E[\CR(\cA_{k_*})]\leq 1+2\alpha +\min\left\{\E[f(X)]+\alpha, 2\sqrt{\eta + 3\alpha} \right\}.$
\end{restatable}

As the predictor becomes more accurate (i.e., both $\eta$ and $\alpha$ decrease), the algorithm's expected CR approaches 1. The rest of this subsection will build to a proof of \cref{thm: ski-rental-cr}.

\begin{algorithm}[t]
   \caption{$\cA_{k_*}$}
    \label{alg: optimal-ski-rental}
\begin{algorithmic}
   \STATE {\bfseries input:} prediction $f(X)=v$, max calibration error $\alpha$
   \IF{$v \leq \frac{4+3\alpha}{5}$}
   \STATE Rent for $b$ days before buying.
   \ELSE
   \STATE Rent for $b \sqrt{\frac{1-v+\alpha}{v+\alpha}}$ days before buying.
   \ENDIF
\end{algorithmic}
\end{algorithm}
\paragraph{Prediction-level analysis.} We begin by upper bounding $\E[\CR(\cA_k) \mid f(X)=v]$. Let $B_v = \{f(X)=v\}$ be the event that $f$ predicts $v \in R(f)$ and $C = \{Z > b\}$ be the event that the number of days skied is more than $b$. Then
\begin{align}\label{eq: total-expectation}
    \E[\CR(\cA_k)\mid B_v] &= \E[\CR(\cA_k) \mid B_v, C] \cdot\Pr[C \mid B_v]  \\
    &+ \E[\CR(\cA_k) \mid B_v, C^c] \cdot\Pr[C^c \mid B_v]. \notag
\end{align}
\cref{lemma: robust-ubs} bounds each of the quantities from \cref{eq: total-expectation}. 

\begin{table}[t]
\caption{Objective values for fixed prediction $f(X)=v$, $z$ days skied, and renting for $k(v)$ days.}
\label{table: cr-landscape}
\vskip 0in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcc}
\toprule
Condition  & $\OPT(z)$ & $\ALG(\cA_k, v, z)$ \\
\midrule
$(i) \;\; z \leq \min\{k(v), \; b\}$ & $z$ & $z$ \\
$(ii) \;\; k(v) < z \leq b$ & $z$ & $k(v) + b$ \\
$(iii) \;\; b < z \leq k(v)$ & $b$ & $z$ \\
$(iv) \;\; z > \max\{k(v), \; b\}$ & $b$ & $k(v) + b$  \\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\end{table}

\begin{restatable}{lemma}{RobustUBs} \label{lemma: robust-ubs}
    Given a predictor $f$ with max calibration error $\alpha$, for all $v \in R(f)$,
    \begin{enumerate}\vspace{-2mm}
        \item $\Pr[C \mid f(X) = v] \leq v +\alpha$
        \item  $\Pr[C^c \mid f(X) = v] \leq 1-v+\alpha$
        \item  $\E[\CR(\cA_k) \mid B_v, C] \leq 1 + \frac{k(v)}{b}$
        \item  $\E[\CR(\cA_k) \mid B_v, C^c] \leq 1 + \frac{b \cdot \mathbbm{1}_{\{k(v)<b\}}}{k(v)}$.
    \end{enumerate}
\end{restatable}
\begin{proof}[Proof sketch]
(1) and (2) follow from the fact that $f$ predicts $\mathbbm{1}_C$ with max calibration error $\alpha$. Under $C=\{Z \geq b\}$, one of conditions (iii) or (iv) from \cref{table: cr-landscape} hold. In either case, $\ALG(\cA_k, v, Z)/\OPT(Z) \leq 1 + \frac{k(v)}{b}$. Under $C^c$, one of conditions (i) or (ii) hold. $\CR(\cA_k) = 1$ for (i). For (ii),
    \[\frac{\ALG(\cA_k, v, Z)}{\OPT(Z)} \leq \frac{k(v) + b}{k(v)} = 1 + \frac{b \cdot \mathbbm{1}_{\{k(v)<b\}}}{k(v)}.\]
\end{proof}
Applying all four bounds to \cref{eq: total-expectation} yields
\begin{align} \label{eq: pred-wise-bound}
    \E[\CR(\cA_k) \mid f(X) = v] \leq
         1+2\alpha +\frac{(v+\alpha)k(v)}{b}& + \mathbbm{1}_{\{k(v)<b\}} \cdot \frac{(1-v+\alpha)b}{k(v)}.
\end{align}
The renting strategy $k_*(v)$ from \cref{alg: optimal-ski-rental} is the minimizer of the upper bound in \cref{eq: pred-wise-bound}.
\begin{restatable}{theorem}{ConditionalCRUB} \label{thm: conditional-cr-ub}
    Given a predictor $f$ with max calibration error $\alpha$, for any prediction $v \in R(f)$, \cref{alg: optimal-ski-rental} achieves
    \begin{align*}
        \E[\CR(\cA_{k_*}) \mid f(X)=v] \leq  1+2\alpha +\min\bigl\{v+\alpha&, 2\sqrt{(v+\alpha)(1-v+\alpha)} \bigr\}.
    \end{align*}
\end{restatable}

\begin{proof}[Proof sketch] 
Given a prediction $f(X)=v$, \cref{alg: optimal-ski-rental} rents for $k_*(v)$ days where
\[k_*(v) = \begin{cases}
        b &\text{if $0 \leq v \leq \frac{4 + 3\alpha}{5}$} \\
        b \sqrt{\frac{1-v+\alpha}{v+\alpha}} &\text{if $\frac{4 + 3\alpha}{5} < v \leq 1$}.
    \end{cases}\]
Evaluating the right-hand-side of \cref{eq: pred-wise-bound} at $k_*(v)$  gives
    \[\begin{cases}
        1+2\alpha + (v+\alpha) &\text{if $0 \leq v \leq \frac{4 + 3\alpha}{5}$} \\
        1+2\alpha +2\sqrt{(v+\alpha)(1-v+\alpha)} &\text{if $\frac{4 + 3\alpha}{5} < v \leq 1$.}
    \end{cases}\]
    The fact that $v + \alpha \leq 2\sqrt{(v+\alpha)(1-v+\alpha)}$ for $v \in [0, \frac{4+3\alpha}{5}]$ and $v + \alpha > 2\sqrt{(v+\alpha)(1-v+\alpha)}$ for $v \in (\frac{4+3\alpha}{5}, 1]$ completes the proof.
\end{proof}
Moreover, no deterministic prediction-aided algorithm for ski rental can outperform \cref{alg: optimal-ski-rental} for general distributions $\cD$ and calibrated predictors $f$. The construction is non-trivial, so we refer the reader to the proof in  \cref{appendix: ski-rental-proofs}.
\begin{restatable}{theorem}{ConditionalCRLB} \label{thm: conditional-cr-lb}
     For all renting strategies $k:[0,1] \to \R_+$, predictions $v \in [0,1]$ and $\epsilon > 0$, there exists a distribution $\cD_{v}^\epsilon$ and a calibrated predictor $f$ such that 
    \[\E[\CR(\cA_k) \mid f(X) = v] \geq 1+ \min\left\{v, 2\sqrt{v(1-v)}\right\} -\epsilon.\]
\end{restatable}

\paragraph{Global analysis.} In extracting a global bound from the conditional guarantee in \cref{thm: conditional-cr-ub}, we encounter a term $(f(X)+\alpha)(1-f(X)+\alpha)$ that is an upper bound on the variance of the conditional distribution $\mathbbm{1}_{\{Z \geq b\}} \mid f(X)$. \cref{lemma: mse-calibration-bounds} relates this quantity to error statistics of $f$.
\begin{restatable}{lemma}{MSECalibrationBounds} \label{lemma: mse-calibration-bounds}
     If $f: \cX \to [0,1]$ has mean-squared error $\eta$ and max calibration error $\alpha$, then
\[\E[f(X)(1-f(X))] \leq \eta + \alpha.\]
\end{restatable}

Finally, we prove this section's main theorem.
\begin{proof}[Proof of \cref{thm: ski-rental-cr}]
By the tower property of conditional expectation, \[\E[\CR(\cA_{k_*})] = \E\bigl[\E[\CR(\cA_{k_*}) \mid f(X) ]\bigr].\] Applying \cref{thm: conditional-cr-ub} yields
\begin{align*}
    &\E[\CR(\cA_{k_*})]  \leq 1+2\alpha
    +\E\biggl[\min\bigl\{f(X)+\alpha, 2\sqrt{(f(X)+\alpha)(1-f(X)+\alpha)} \bigr\}\biggr].
\end{align*}
Recall that $\E[\min(X, Y)] \leq \min(\E[X], \E[Y])$ for random variables $X, Y$. Furthermore, the function $h(y) = \sqrt{(y+\alpha)(1-y+\alpha)}$ is concave over the unit interval, so by Jensen's inequality
\begin{align*}
    &\E\biggl[\min\bigl\{f(X)+\alpha, 2\sqrt{(f(X)+\alpha)(1-f(X)+\alpha)} \bigr\}\biggr]\leq \\ &\quad\quad\quad \min\bigl\{\E[f(X)]+\alpha, 2\sqrt{\E[(f(X)+\alpha)(1-f(X)+\alpha)]} \bigr\}.
\end{align*}
Finally, observe that
\[(f(X)+\alpha)(1-f(X)+\alpha) \leq f(X)(1-f(X)) + 2\alpha.\]
We apply \cref{lemma: mse-calibration-bounds} to bound $\E[f(X)(1-f(X))]$.
\end{proof}

\subsection{Comparison to previous work} 
It is well known that for $\lambda \in (0,1)$, any $(1+\lambda)$-consistent algorithm for deterministic ski rental must be at least $(1+\frac{1}{\lambda})$-robust 
\citep{Wei20:Optimal,Angelopoulos20:Online,Gollapudi19:Online}. While \cref{alg: optimal-ski-rental} is subject to this trade-off in the worst case, calibration provides sufficient information to hedge against adversarial inputs in expectation, leading to substantial improvements in average-case performance. Indeed, it can be seen from the bound in \cref{thm: conditional-cr-ub} that \cref{alg: optimal-ski-rental} is 1-consistent and always satisfies $\E[\CR(\cA_{k_*})] \leq 1.8$ when advice is calibrated.

\begin{algorithm}[tb]
   \caption{\cite{Sun24:Online} Optimal ski rental with conformal predictions}
    \label{alg: conformal-ski-rental}
\begin{algorithmic}
   \STATE {\bfseries input:} interval prediction $[\ell, u] = \textsc{PIP}_\delta(X)$
   \IF{$\ell \leq u <b$}
        \STATE Rent for $b$ days
   \ELSIF{$b < \ell \leq u$}
        \STATE Rent for $b \cdot \min\{\sqrt{\delta/1-\delta},1\}$ days
   \ELSE
   \IF{$\zeta(\delta, \ell) \geq 2$ and $\delta + \frac{u}{b} \geq 2$}
   \STATE{Rent for $b$ days}
   \ELSIF{$\zeta(\delta, \ell) \leq \delta + \frac{u}{b}$}
   \STATE Rent for $\ell \cdot \min\{\sqrt{b\delta/ \ell(1-\delta)}, 1\}$ days
   \ELSE
   \STATE Rent for $u$ days
    \ENDIF
   \ENDIF\\
   \hrulefill
   \STATE $\zeta(\delta, \ell):=\begin{cases}
        \delta + \frac{(1-\delta)b}{\ell} +2\sqrt{\frac{\delta(1-\delta)b}{\ell}} &\text{if $\delta \in [0, \frac{\ell}{\ell + b})$} \\
        1+\frac{b}{\ell} &\text{if $\delta \in [\frac{\ell}{\ell+b}, 1]$}
    \end{cases}$
\end{algorithmic}
\end{algorithm}

We are not the first to explore uncertainty quantified predictions for ski rental. \citet{Sun24:Online} take an orthogonal approach based on conformal prediction. Their method, \cref{alg: conformal-ski-rental}, assumes access to a probabilistic interval predictor $\textsc{PIP}_\delta:\cX \to \mathcal{P}([0,1])$. $\textsc{PIP}_\delta$ outputs an interval $[\ell, u] = \textsc{PIP}_\delta(X)$ containing the true number of days skied $Z \in [\ell, u]$ with probability at least $1-\delta$. Interval predictions are especially useful when the uncertainty $\delta$ and returned interval width $u-\ell$ are both small. However, as features become less informative, the width of prediction intervals must increase to maintain the same confidence level. This can result in intervals that are too wide to provide meaningful insight into the true number of days skied. \cref{lemma: conform-worst} and \cref{thm: conform-improv} demonstrate that there are infinite families of distributions for which calibrated predictions are more informative than conformal predictions for ski rental.



\begin{restatable}{lemma}{ConformWorstCase}\label{lemma: conform-worst}
    For all $a \in [0,1/2]$, there exists an infinite family of input distributions for which \cref{alg: conformal-ski-rental} defaults to a worst-case break-even strategy for all interval predictors $\textsc{PIP}_\delta$ with uncertainty $\delta < a$.
\end{restatable}
\begin{proof}[Proof sketch]
    The construction places mass $a$ on some day $z_1 \geq 2b$ and mass $1-a$ on $z_2 \leq \frac{b}{2}$. Any $\textsc{PIP}_\delta$ with $\delta < a$ must output an interval $[\ell, u]$ containing both $z_1$ and $z_2$. Moreover, $\zeta(\delta, \ell) \geq 2$ and $\delta + \frac{u}{b} \geq 2$ by construction.
\end{proof}

\begin{restatable}{theorem}{ConformImprov} \label{thm: conform-improv}
    For all $a \in [0, 1/2]$, all instantiations $\cA$ of \cref{alg: conformal-ski-rental} using PIPs with uncertainty $\delta < a$, and all distributions from \cref{lemma: conform-worst}, if $f$ is a predictor with mean-squared error $\eta$ and max calibration error $\alpha$ satisfying $2\alpha + 2\sqrt{\eta + 3\alpha} < a$, then $\E[\CR(\cA_{k_*})] < \E[\CR(\cA)]$.
\end{restatable}
\begin{proof}[Proof sketch]
For the distributions in \cref{lemma: conform-worst}, the number of days skied is greater than $b$ with probability $a$. Thus, the expected competitive ratio of the break-even strategy is
$\E[\CR(\cA)] = a \cdot 2 + (1-a)\cdot1 = 1 + a.$
The result follows from the bound on $\E[\CR(\cA_{k_*})]$ given in \cref{thm: ski-rental-cr}.
\end{proof}