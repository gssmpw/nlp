\section{Preliminaries}
For clarity, we follow the convention that capital letters (e.g., $X$) denote random variables and lowercase letters denote realizations of random variables  (e.g., the event $f(X)=v$).

\paragraph{Prediction-aided algorithm design.}
 With each algorithmic task, we associate a set $\cI$ of possible instances, a set $\cX$ of features for those instances, and a joint distribution $\cD$ over $\cX \times \cI$. Given a target function $T:\cI \to \cY$ that provides information about each instance, we assume access to a predictor $f:\cX \to \cZ \supseteq\cY$ that has been trained to predict the target over $\cD$. Let $R(f)$ denote the range of $f$. 

 If $\ALG(\cA, v, i)$ is the cost incurred by algorithm $\cA$ with prediction $f(X)=v$ on instance $i \in \mathcal{I}$, and $\OPT(i)$ is that of the offline optimal solution, the goal is to minimize the \textit{expected competitive ratio (CR)} defined multiplicatively as
 \begin{equation*} \label{eq: mult-exp--cr}
     \E_{(X, I) \sim \cD}\left[\frac{\ALG(\cA, f(X), I)}{\OPT(I)}\right]
 \end{equation*}
or additively as\[\E_{(X, I) \sim \cD}\left[\ALG(\cA, f(X), I) -\OPT(I)\right]\]
(that is, the performance of $\cA$ relative to $\OPT$ over $\cD$). When $\cD$, $f$, and the CR type (multiplicative or additive) are clear from context, we denote the expected competitive ratio as $\E[\CR(\cA)]$. This measure is consistent with prior work on training predictors from samples for algorithms with predictions \citep{Anand20:Customizing}.


\paragraph{Calibration.}
An ML model is said to be \emph{calibrated} if its predictions are, on average, correct. Formally,
\begin{definition} \label{def: calibration}
    A predictor $f: \mathcal{X} \to \cZ$ with target $T: \cI \to \mathcal{Y}$ is calibrated over $\cD$ if
    \[\E_{(X, I) \sim \cD}[T(I) \mid f(X)] = f(X).\]
\end{definition}
When $\cY = \{0,1\}$, the equivalent condition is $\Pr[T(I)=1 \mid f(X)] = f(X)$, i.e., $f(X)$ directly represents the probability that $T(I)=1$. Achieving perfect calibration is difficult, so in practice we aim to minimize calibration error, such as the \emph{max calibration error}, which measures the largest deviation from perfect calibration for any prediction.
\begin{definition} \label{def: k1-cal-error}
     The max calibration error of a predictor $f: \cX \to \cZ$ with target $T:\cI \to \cY$ over $\cD$ is
     \[\max_{v \in R(f)} \left|v -\E[T(I) \mid f(X) = v]\right|.\]
\end{definition}