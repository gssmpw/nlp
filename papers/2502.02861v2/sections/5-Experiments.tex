\section{Experiments}
We now evaluate our algorithms on two real-world datasets, demonstrating the utility of using calibrated predictions. See \cref{appendix: experimental-details} for additional details about our datasets and model training, as well a broader collection of results for different ML models and parameter settings.
\subsection{Ski rental: Citi Bike rentals}
To model the rent-or-buy scenario in the ski rental problem, we use publicly available Citi Bike usage data.\footnote{Monthly usage data is publicly available at \url{https://citibikenyc.com/system-data}.}. This dataset has been used for forecasting~\citep{wang2016forecasting}, system balancing~\citep{o2015data}, and transportation policy~\citep{lei2021robust}, but to the best of our knowledge, this is its first use for ski rental. In this context, a Citi Bike user can choose one of two options: pay by ride duration (rent) or purchase a day pass (buy). If the user plans to ride for longer than the break-even point of $b$ minutes, it is cheaper to buy a day pass than to pay by trip duration.\footnote{The day pass is designed to be more economical for multiple unlocks of a bike (e.g., $b\approx66$ minutes for 1 unlock). However, ride data is anonymous, so we cannot track daily usage.} We use single-ride durations to approximate the rent vs. buy trade-off for a spectrum of break-even points $b$. The distribution over ride durations can be seen in \cref{appendix: experimental-details}. 

We analyze the impact of advice from multiple predictor families, including XGBoost, logistic regression, and small multi-layer perceptrons (MLP).
Each predictor has access to available ride features: start time, start location, user age, user gender, user membership, and approximate end station latitude. While these features are not extremely informative, most predictor families are able to achieve AUC and accuracy above 0.8 for $b>6$. \cref{fig:ski-rental-main} summarizes the expected competitive ratios achieved by our method from \cref{alg: optimal-ski-rental} (\textsc{Calibrated}) and baselines from previous work when given advice from a small neural network. Baselines include the worst-case optimal deterministic algorithm that rents for $b$ minutes \citep{Karlin88:Competitive} (\textsc{Breakeven}), the black-box binary predictor ski-rental algorithm by~\citet{Anand20:Customizing} (\textsc{Binary}), and the PIP algorithm described in Algorithm~\ref{alg: conformal-ski-rental}~\citep{Sun24:Online} (\textsc{Conformal}). Though each algorithm is aided by predictors from the same family, the actual advice may differ. For example, \textsc{Conformal} assumes access to a regressor that predicts ride duration directly. While performance is distribution-dependent, we see that our calibration-based approach often leads to the most cost-effective rent/buy policy in this scenario.

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.65\linewidth]{figures/rich-info-clfNN-regNN_CR-notitle.pdf}
    \caption{Comparison of $\E[\ALG/\OPT]$ for algorithms aided by predictions from a small MLP with two hidden layers of size 8 and 2. Algorithm~\ref{alg: optimal-ski-rental} (\textsc{Calibrated}) performs best on average.}
    \label{fig:ski-rental-main}
\end{figure}

\subsection{Scheduling: sepsis triage}
We use a real-world dataset for sepsis prediction to validate our theory results for scheduling with calibrated predictions. Sepsis is a life-threatening response to infection that typically appears after hospital admission~\citep{singer2016third}. Many works have studied using machine learning to predict the onset of sepsis, as every hour of delayed treatment is associated with a 4-8\% increase in mortality~\citep{kumar2006duration, reyna2020early}; existing works aim to better predict sepsis to treat high-priority patients earlier. Replicating results from \citet{chicco2020survival} we train a binary predictor for sepsis onset using logistic regression on a dataset of 110,204 hospital admissions. The base predictor achieves an AUC of 0.86 using age, sex, and septic episodes as features. We then calibrate this predictor using both the naive method from \citet{Cho22:Scheduling} (\textsc{Binary}) and more nuanced histogram calibration~\citep{zadrozny2001obtaining} (\textsc{Calibrated}). \cref{fig:schedule-cr} shows the expected competitive ratio (normalized by the number of jobs $n=100$) achieved by \cref{alg: beta-threshold} when provided advice from each of these predictors for varying delay costs $\omega_1, \omega_0$ and information barrier $\theta$. We see that the more nuanced predictions consistently result in schedules with smaller delay costs.

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.65\linewidth]{figures/hist_sepsis_XGB_notitle.pdf}
    \caption{Comparison of $\E[\ALG-\OPT]$ (normalized) achieved by \cref{alg: beta-threshold} for naively calibrated and histogram-binned predictors under varying delay costs $\omega_0, \omega_1$ and information barrier $\theta$.}
    \label{fig:schedule-cr}
\end{figure}
