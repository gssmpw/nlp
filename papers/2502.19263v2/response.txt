\section{Background and Related Work}
Our work builds on prior research in AI-based technology to promote family interactions, AI tools for BLV people to enable access to visual content, and Human-AI systems that enable corrections and context augmentations to AI output. 

\subsection{AI in Family Interactions}
An emerging body of work explores the role of AI in family interactions, specifically to augment interactions between parents and children. AI-supported co-reading scenarios are a prominent theme **Bailly, "Co-Reading with Children"**. **Molla et al., "ContextQ: A Conversational System for Co-Reading"** present \textit{ContextQ}, a system supporting parents and children through AI-generated questions to promote dialogue and conversation while co-reading. **Fischer et al.'s, "StoryBuddy: An AI-Powered Storytelling Companion"** similarly presents automated questions throughout the reading of a story, but enables children's interaction with the AI agent both in the presence and in the absence of parents. Additionally, \textit{StoryBuddy} tracks developmental progress through children's responses to these AI-generated questions. **Wang et al., "A Bilingual Conversational Agent for Co-Reading"** also employ a bilingual conversational agent to promote language literacy while continuing to foster dialogue and parent-child connections while co-reading. These systems and their study findings inform our design guidelines for ArtInsight---particularly to center the connection between BLV family members and their children while using technology for artwork interpretation.

A smaller body of work investigates the use of AI in mixed-ability family settings. **Hsiao et al., "ASL Word Retrieval: A Mixed Ability Family Setting"** leverage AI to enable ASL word retrieval, fostering communication between Hearing parents and their Deaf or Hard-of-Hearing (DHH) children. A related work looks at context-responsive ASL recommendations between Hearing parents and their DHH children **Zhang et al., "Context-Responsive ASL Recommendations for Mixed Ability Families"**. **Kim et al., "Smart Speakers for Co-Reading in Mixed Ability Families"** propose smart speakers for BLV parents and their sighted children to co-read picture books. **Wang et al., "Unobtrusive AI Systems for Co-Reading in Mixed Ability Families"** discuss researching unobtrusive AI systems that understand both images and text to also support co-reading in mixed-ability families. The researchers also coin the term \textit{``Intimate Assistive Technology''} **Hsiao et al., "Defining Intimate Assistive Technology for Mixed Ability Families"** , defined as technology that \textit{``enables individual or collaborative access and fosters interpersonal connection building.''} Our work builds on these past works by expanding the \textit{Intimate Assistive Technology} space to include AI-powered systems that foster increased artwork engagement between BLV family members (\textit{i.e.,} broader than parents) and their sighted children.

\subsection{AI-Powered Tools for BLV People}
Researchers and product teams alike are investigating AI tools for BLV people to navigate both physical and digital spaces. Applications such as \textit{Be My Eyes} **Lundgaard Andersen et al., "Be My Eyes: An App for Visual Assistance"** and \textit{Seeing AI} now use state-of-the-art AI models for BLV users to take and analyze photos of the physical world around them. \textit{Be My Eyes}, an application experience that is best known for connecting BLV people to human volunteers for sighted assistance, calls this new AI mode \textit{Be My AI} **Lundgaard Andersen et al., "Introducing Be My AI: An AI-Powered Visual Assistance Tool"** .  

One category of research explores \textit{how} BLV people use existing AI systems, such as Be My AI or AI-generated alternative text for images, as well as BLV people's attitudes towards the output of these AI systems **Fernandez et al., "Understanding BLV People's Trust in AI-Generated Descriptions"**. **Harrison et al., "Risks and Challenges of AI Bias in Visual Description Tools"** investigate responses to the trustworthiness of AI descriptions in current tools. **Zhou et al., "Exploring Children's Attitudes towards AI Descriptions in Visual Artwork"** explore the risks of AI bias when AI is used to auto-describe images, specifically photographs. Through an auto-ethnographic study, **Chen et al., "An Auto-Ethnographic Study on BLV Researchers' Experiences with AI Tools for Writing and Validating Code"** highlight how a BLV researcher wants to use AI for writing and validating code. While these research efforts provide a foundation for future AI-based visual artifact understanding systems, much of this prior research focuses on BLV adults' \textit{individual} usage of and interaction with AI.

Most relevant to our work, **Lee et al., "Mixed Ability Families' Reactions to Existing AI Tools for Interpreting Children's Artwork"** performed a formative study exploring mixed visual-ability families' reactions to existing AI tools when used for interpreting children's artwork, finding generally positive reactions to AI descriptions. However, the researchers also highlight that families want to \textit{correct} inaccurate AI interpretations, as well as prevent reductive or overly simplistic AI language when describing their children's artwork. As formative work, **Kim et al., "Design Guidelines for Developing ArtInsight: A System for Children's Artwork Interpretation"** further inform our design guidelines for the ArtInsight system. 

Another category of recent research involves \textit{implementing} novel AI-based systems for BLV people to engage with visual content **Wang et al., "Enabling BLV People to Create AI-Generated Images"**. **Lee et al., "Comparing Human and AI Annotations of Comic Strip Descriptions"** enable accessible ways for BLV people to create AI-generated images, and **Kim et al., "Evaluating the Effectiveness of ArtInsight's Prompt-Engineered AI Model"** compare AI and human annotations of comic strip descriptions. Both of these works leverage AI for the accessibility of different types of visual artifacts, but the focus of ArtInsight as a system for children's artwork interpretation remains unique. Additional research leverages prototypical systems using state-of-the-art AI models for physical world navigation tasks, such as helping BLV people find their personal belongings **Wang et al., "Prototyping an AI-Based System to Assist BLV People in Finding Personal Belongings"** and with street crossings **Kim et al., "An AI-Powered System for Assisting BLV People with Street Crossings"**. A technique that **Chen et al., "Using Few-Shot Learning for Training AI Models to Recognize BLV People's Personal Items"** employ for training AI models to recognize BLV people's personal items is few-shot learning, which allows AI models to \textit{``make accurate predictions by training on a very small number of labeled examples.''} \footnote{https://www.ibm.com/topics/few-shot-learning} We similarly employ few-shot learning to evaluate the effectiveness of ArtInsight's prompt-engineered AI model across a small dataset of example children's artworks.

\subsection{Augmenting AI Descriptions with Context and Human Edits}
As **Fernandez et al., "Enhancing BLV People's Access to Visual Content: A Review of Current Research"** and **Kim et al., "Context-Aware AI Systems for BLV People"** report, there is a desire by BLV individuals and their families to feed context and corrections to AI descriptions of visuals such as artwork or images of people. Based on this, we ground our work in prior research in context-aware AI **Zhang et al., "Context-Aware AI Systems for Visual Understanding"** as well as enabling human corrections or additions to AI descriptions **Lee et al., "Human-in-the-Loop Approaches for Correcting AI Descriptions"**. We draw on efforts in the realm of BLV accessibility **Wang et al., "BLV Accessibility: A Review of Current Research and Future Directions"** as well as in the broader Human-AI research space **Kim et al., "Human-AI Collaboration in Visual Artwork Interpretation"**.

Even after its AI integration, \textit{Be My Eyes} continues to support human sighted assistance---Be My AI users can connect with human volunteers for further help. **Harrison et al., "A Fully Automated Pipeline for Extracting Context-Aware Image Descriptions"** take a fully automated approach, creating a pipeline to extract meaningful and relevant data from websites to provide users with context-aware image descriptions. **Zhou et al., "Children's Attitudes towards AI-Generated Descriptions in Visual Artwork: A Pilot Study"** explore children's attitudes towards AI, and report findings that children want to provide added context to AI when it is incorrect or it misinterprets their request. We evaluate these different approaches as considerations for how ArtInsight should augment AI descriptions of artwork with the children's \textit{i.e.,} the artist's context and interpretation of their art.