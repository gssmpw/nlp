@misc{CentersforDiseaseControlandPrevention2023,
author = {{Centers for Disease Control and Prevention}},
mendeley-groups = {Opioid Risk},
title = {Drug Overdose Deaths Remained High in 2021},
url = {https://www.cdc.gov/drugoverdose/deaths/index.html},
urldate = {September 1, 2023},
year = {2023}
}

@article{Potash2020,
abstract = {Importance: Childhood lead poisoning causes irreversible neurobehavioral deficits, but current practice is secondary prevention. Objective: To validate a machine learning (random forest) prediction model of elevated blood lead levels (EBLLs) by comparison with a parsimonious logistic regression. Design, Setting, and Participants: This prognostic study for temporal validation of multivariable prediction models used data from the Women, Infants, and Children (WIC) program of the Chicago Department of Public Health. Participants included a development cohort of children born from January 1, 2007, to December 31, 2012, and a validation WIC cohort born from January 1 to December 31, 2013. Blood lead levels were measured until December 31, 2018. Data were analyzed from January 1 to October 31, 2019. Exposures: Blood lead level test results; lead investigation findings; housing characteristics, permits, and violations; and demographic variables. Main Outcomes and Measures: Incident EBLL (≥6 $\mu$g/dL). Models were assessed using the area under the receiver operating characteristic curve (AUC) and confusion matrix metrics (positive predictive value, sensitivity, and specificity) at various thresholds. Results: Among 6812 children in the WIC validation cohort, 3451 (50.7%) were female, 3057 (44.9%) were Hispanic, 2804 (41.2%) were non-Hispanic Black, 458 (6.7%) were non-Hispanic White, and 442 (6.5%) were Asian (mean [SD] age, 5.5 [0.3] years). The median year of housing construction was 1919 (interquartile range, 1903-1948). Random forest AUC was 0.69 compared with 0.64 for logistic regression (difference, 0.05; 95% CI, 0.02-0.08). When predicting the 5% of children at highest risk to have EBLLs, random forest and logistic regression models had positive predictive values of 15.5% and 7.8%, respectively (difference, 7.7%; 95% CI, 3.7%-11.3%), sensitivity of 16.2% and 8.1%, respectively (difference, 8.1%; 95% CI, 3.9%-11.7%), and specificity of 95.5% and 95.1% (difference, 0.4%; 95% CI, 0.0%-0.7%). Conclusions and Relevance: The machine learning model outperformed regression in predicting childhood lead poisoning, especially in identifying children at highest risk. Such a model could be used to target the allocation of lead poisoning prevention resources to these children.},
author = {Potash, Eric and Ghani, Rayid and Walsh, Joe and Jorgensen, Emile and Lohff, Cortland and Prachand, Nik and Mansour, Raed},
doi = {10.1001/jamanetworkopen.2020.12734},
file = {:Users/vsivaram/Documents/papers/potash_2020_oi_200483_1599661889.87241.pdf:pdf},
issn = {25743805},
journal = {JAMA Network Open},
mendeley-groups = {Opioid Risk},
number = {9},
pages = {1--12},
pmid = {32936296},
title = {Validation of a Machine Learning Model to Predict Childhood Lead Poisoning},
volume = {3},
year = {2020}
}
@article{Miranda2002,
abstract = {Environmental threats to children's health - especially low-level lead exposure - are complex and multifaceted; consequently, mitigation of these threats has proven costly and insufficient and has produced economic and racial disparities in exposure among populations. Policy makers, public health officials, child advocates, and others currently lack the appropriate infrastructure to evaluate children's risk and exposure potential across a broad range of risks. Unable to identify where the highest risk of exposure occurs, children's environmental health programs remain mitigative instead of preventive. In this article we use geographic information system spatial analysis of data from blood lead screening, county tax assessors, and the U.S. Census to predict statistically based lead exposure risk levels mapped at the individual tax parcel unit in six counties in North Carolina. The resulting model uses weighted risk factors to spatially locate modeled exposure zones, thus highlighting critical areas for targeted intervention. The methods presented here hold promise for application and extension to the other 94 North Carolina counties and nationally, as well as to other environmental health risks.},
author = {Miranda, Marie Lynn and Dolinoy, Dana C. and Overstreet, M. Alicia},
doi = {10.1289/ehp.02110947},
file = {:Users/vsivaram/Documents/papers/ehp.02110947.pdf:pdf},
issn = {00916765},
journal = {Environmental Health Perspectives},
keywords = {Children's health,Environmental justice,Geographic information system,Lead},
mendeley-groups = {Opioid Risk},
number = {9},
pages = {947--953},
pmid = {12204831},
title = {Mapping for prevention: {GIS} models for directing childhood lead poisoning prevention programs},
volume = {110},
year = {2002}
}
@article{Fisher2022,
abstract = {Artificial intelligence (AI) has the potential to improve public health's ability to promote the health of all people in all communities. To successfully realize this potential and use AI for public health functions it is important for public health organizations to thoughtfully develop strategies for AI implementation. Six key priorities for successful use of AI technologies by public health organizations are discussed: 1) Contemporary data governance; 2) Investment in modernized data and analytic infrastructure and procedures; 3) Addressing the skills gap in the workforce; 4) Development of strategic collaborative partnerships; 5) Use of good AI practices for transparency and reproducibility, and; 6) Explicit consideration of equity and bias.},
author = {Fisher, Stacey and Rosella, Laura C.},
doi = {10.1186/s12889-022-14422-z},
file = {:Users/vsivaram/Documents/papers/s12889-022-14422-z.pdf:pdf},
issn = {14712458},
journal = {BMC Public Health},
keywords = {Artificial intelligence,Health policy,Public health},
mendeley-groups = {Opioid Risk},
number = {1},
pages = {1--14},
pmid = {36419010},
publisher = {BioMed Central},
title = {Priorities for successful use of artificial intelligence by public health organizations: a literature review},
url = {https://doi.org/10.1186/s12889-022-14422-z},
volume = {22},
year = {2022}
}
@article{Smith2020,
author = {Smith, Maxwell J. and Axler, Renata and Bean, Sally and Rudzicz, Frank and Shaw, James},
doi = {10.2471/BLT.19.237503},
file = {:Users/vsivaram/Documents/papers/BLT.19.237503.pdf:pdf},
issn = {15640604},
journal = {Bulletin of the World Health Organization},
mendeley-groups = {Opioid Risk},
number = {4},
pages = {290--292},
pmid = {32284656},
title = {Four equity considerations for the use of artificial intelligence in public health},
volume = {98},
year = {2020}
}
@article{Weiss2018,
abstract = {The aim of this study was to systematically review the range, nature, and extent of current research activity exploring the influence of innovative health-related technologies on social inequalities in health, with specific focus on a deeper understanding of the variables used to measure this connection and the pathways leading to the (re)production of inequalities. A review process was conducted, based on scoping review techniques, searching literature published from January 1, 1996 to November 25, 2016 using MEDLINE, Scopus, and ISI web of science. Search, sorting, and data extraction processes were conducted by a team of researchers and experts using a dynamic, reflexive examination process. Of 4139 studies collected from the search process, a total of 33 were included in the final analysis. Results of this study include the classification of technologies based on how these technologies are accessed and used by end users. In addition to the factors and mechanisms that influence unequal access to technologies, the results of this study highlight the importance of variations in use that importantly shape social inequalities in health. Additionally, focus on health care services technologies must be accompanied by investigating emerging technologies influencing healthy lifestyle, genomics, and personalized devices in health. Findings also suggest that choosing one measure of social position over another has important implications for the interpretation of research results. Furthermore, understanding the pathways through which various innovative health technologies reduce or (re)produce social inequalities in health is context dependent. In order to better understand social inequalities in health, these contextual variations draw attention to the need for critical distinctions between technologies based on how these various technologies are accessed and used. The results of this study provide a comprehensive starting point for future research to further investigate how innovative technologies may influence the unequal distribution of health as a human right.},
author = {Weiss, Daniel and Rydland, H{\aa}vard T. and {\O}versveen, Emil and Jensen, Magnus Rom and Solhaug, Solvor and Krokstad, Steinar},
doi = {10.1371/journal.pone.0195447},
file = {:Users/vsivaram/Documents/papers/file.pdf:pdf},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
mendeley-groups = {Opioid Risk},
number = {4},
pages = {1--20},
pmid = {29614114},
title = {Innovative technologies and social inequalities in health: {A} scoping review of the literature},
volume = {13},
year = {2018}
}

@article{De-Arteaga2020,
abstract = {The increased use of algorithmic predictions in sensitive domains has been accompanied by both enthusiasm and concern. To understand the opportunities and risks of these technologies, it is key to study how experts alter their decisions when using such tools. In this paper, we study the adoption of an algorithmic tool used to assist child maltreatment hotline screening decisions. We focus on the question: Are humans capable of identifying cases in which the machine is wrong, and of overriding those recommendations? We first show that humans do alter their behavior when the tool is deployed. Then, we show that humans are less likely to adhere to the machine's recommendation when the score displayed is an incorrect estimate of risk, even when overriding the recommendation requires supervisory approval. These results highlight the risks of full automation and the importance of designing decision pipelines that provide humans with autonomy.},
author = {De-Arteaga, Maria and Fogliato, Riccardo and Chouldechova, Alexandra},
file = {:Users/vsivaram/Documents/papers/3313831.3376638.pdf:pdf},
isbn = {9781450367080},
issn = {23318422},
journal = {arXiv},
keywords = {Algorithm assisted decision making,Algorithm aversion,Automation bias,Child welfare,Decision support,Human-in-the-loop},
mendeley-groups = {Child Welfare,Child Welfare/AFST-specific,Opioid Risk},
pages = {1--12},
title = {A case for humans-in-the-loop: {Decisions} in the presence of erroneous algorithmic scores},
year = {2020}
}

@article{HoltenMoller2020,
author = {{Holten M{\o}ller}, Naja and Shklovski, Irina and Hildebrandt, Thomas T.},
doi = {10.1145/3419249.3420149},
file = {:Users/vsivaram/Documents/papers/3419249.3420149.pdf:pdf},
isbn = {9781450375795},
journal = {NordiCHI},
keywords = {acm reference format,algorithmic decision-support systems,casework,design,job placement,participatory design methods,public services,responsible},
mendeley-groups = {Child Welfare,Opioid Risk},
pages = {1--12},
title = {Shifting Concepts of Value: {Designing} Algorithmic Decision-Support Systems for Public Services},
year = {2020}
}
@article{Tan2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1808.09123v2},
author = {Tan, Sarah and Adebayo, Julius and Inkpen, Kori},
year = {2018},
eprint = {arXiv:1808.09123v2},
file = {:Users/vsivaram/Documents/papers/1808.09123.pdf:pdf},
journal = {arXiv},
mendeley-groups = {Child Welfare,Child Welfare/Human-AI partnerships,Opioid Risk},
title = {Investigating Human + Machine Complementarity for Recidivism Predictions},
url = {https://doi.org/10.48550/arXiv.1808.09123}
}

@inproceedings{Lundberg2017,
author = {Lundberg, Scott M. and Lee, Su-In},
title = {A unified approach to interpreting model predictions},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {4768–4777},
numpages = {10},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@article{Maciejewski2011,
abstract = {The National Strategy for Pandemic Influenza outlines a plan for community response to a potential pandemic. In this outline, state and local communities are charged with enhancing their preparedness. In order to help public health officials better understand these charges, we have developed a visual analytics toolkit (PanViz) for analyzing the effect of decision measures implemented during a simulated pandemic influenza scenario. Spread vectors based on the point of origin and distance traveled over time are calculated and the factors of age distribution and population density are taken into effect. Healthcare officials are able to explore the effects of the pandemic on the population through a geographical spatiotemporal view, moving forward and backward through time and inserting decision points at various days to determine the impact. Linked statistical displays are also shown, providing county level summaries of data in terms of the number of sick, hospitalized and dead as a result of the outbreak. Currently, this tool has been deployed in Indiana State Department of Health planning and preparedness exercises, and as an educational tool for demonstrating the impact of social distancing strategies during the recent H1N1 (swine flu) outbreak. {\textcopyright} 2011 Elsevier Ltd.},
author = {Maciejewski, Ross and Livengood, Philip and Rudolph, Stephen and Collins, Timothy F. and Ebert, David S. and Brigantic, Robert T. and Corley, Courtney D. and Muller, George A. and Sanders, Stephen W.},
doi = {10.1016/j.jvlc.2011.04.002},
file = {:Users/vsivaram/Documents/papers/1-s2.0-S1045926X11000292-main.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages and Computing},
keywords = {Geovisualization,Pandemic influenza,Risk assessment,Visual analytics},
mendeley-groups = {Opioid Risk},
number = {4},
pages = {268--278},
publisher = {Elsevier},
title = {A pandemic influenza modeling and visualization tool},
url = {http://dx.doi.org/10.1016/j.jvlc.2011.04.002},
volume = {22},
year = {2011}
}
@article{Osuala2017,
abstract = {The increasing trend of systematic collection of medical data (diagnoses, hospital admission emergencies, blood test results, scans etc) by health care providers offers an unprecedented opportunity for the application of modern data mining, pattern recognition, and machine learning algorithms. The ultimate aim is invariably that of improving outcomes, be it directly or indirectly. Notwithstanding the successes of recent research efforts in this realm, a major obstacle of making the developed models usable by medical professionals (rather than computer scientists or statisticians) remains largely unaddressed. Yet, a mounting amount of evidence shows that the ability to understanding and easily use novel technologies is a major factor governing how widely adopted by the target users (doctors, nurses, and patients, amongst others) they are likely to be. In this work we address this technical gap. In particular, we describe a portable, web based interface that allows health care professionals to interact with recently developed machine learning and data driven prognostic algorithms. Our application interfaces a statistical disease progression model and displays its predictions in an intuitive and readily understandable manner. Different types of geometric primitives and their visual properties (such as size or colour), are used to represent abstract quantities such as probability density functions, the rate of change of relative probabilities, and a series of other relevant statistics which the heath care professional can use to explore patients' risk factors or provide personalized, evidence and data driven incentivization to the patient.},
author = {Osuala, Richard and Arandjelovic, Ognjen},
doi = {10.1109/BHI.2017.7897250},
file = {:Users/vsivaram/Documents/papers/Osuala_2017_BHI2017_Visualisation_of_patient_AAM.pdf:pdf},
isbn = {9781509041794},
journal = {2017 IEEE EMBS International Conference on Biomedical and Health Informatics, BHI 2017},
mendeley-groups = {Opioid Risk},
number = {3},
pages = {241--244},
title = {Visualization of patient specific disease risk prediction},
volume = {2},
year = {2017}
}
@article{Kostkova2014,
abstract = {Traditional public health surveillance systems would benefit from integration with knowledge created by new situation-aware realtime signals from social media, online searches, mobile/sensor networks and citizens' participatory surveillance systems. However, the challenge of threat validation, cross-verification and information integration for risk assessment has so far been largely untackled. In this paper, we propose a new system, medi+board, monitoring epidemic intelligence sources and traditional case-based surveillance to better automate early warning, cross-validation of signals for outbreak detection and visualization of results on an interactive dashboard. This enables public health professionals to see all essential information at a glance. Modular and configurable to any 'event' defined by public health experts, medi+board scans multiple data sources, detects changing patterns and uses a configurable analysis module for signal detection to identify a threat. These can be validated by an analysis module and correlated with other sources to assess the reliability of the event classified as the reliability coefficient which is a real number between zero and one. Events are reported and visualized on the medi+board dashboard which integrates all information sources and can be navigated by a timescale widget. Simulation with three datasets from the swine flu 2009 pandemic (HPA surveillance, Google news, Twitter) demonstrates the potential of medi+board to automate data processing and visualization to assist public health experts in decision making on control and response measures.},
author = {Kostkova, Patty and Garbin, Stephan and Moser, Justin and Pan, Wendy},
doi = {10.1145/2567948.2579276},
file = {:Users/vsivaram/Documents/papers/2567948.2579276.pdf:pdf},
isbn = {9781450327459},
journal = {WWW 2014 Companion - Proceedings of the 23rd International Conference on World Wide Web},
keywords = {Cross-validation,Dashboard,Epidemic intelligence,Outbreak detection,Real-time data scanning},
mendeley-groups = {Opioid Risk},
pages = {657--662},
title = {Integration and visualization public health dashboard: {The} medi+board pilot project},
year = {2014}
}
@article{Harle2012,
abstract = {Here, the authors describe and evaluate a new information-visualization method and prototype software tool that support risk assessment for negative health outcomes. Their framework uses principal component analysis and linear discriminant analysis to plot high-dimensional patient data in 2D. It also incorporates interactive visualization techniques to aid the identification of high versus low risk patients, critical risk factors, and the estimated effect of hypothetical interventions on the likelihood of negative outcomes. The authors quantitatively evaluated the visualization method using a secondary dataset describing 588 people with diabetes and their estimated future risk of heart attack. Their results show that the method visually classifies high-and low-risk people with accuracy that's similar to other common statistical methods. The framework also provides an interactive, visualization-based tool for clinicians to explore the nuances of their patients' data and disease risk. {\textcopyright} 2011 IEEE.},
author = {Harle, Christopher A. and Neill, Daniel B. and Padman, Rema},
doi = {10.1109/MIS.2012.112},
file = {:Users/vsivaram/Documents/papers/Information_Visualization_for_Chronic_Disease_Risk_Assessment.pdf:pdf},
issn = {15411672},
journal = {IEEE Intelligent Systems},
keywords = {dimensionality reduction,healthcare,information visualization,risk assessment},
mendeley-groups = {Opioid Risk},
number = {6},
pages = {81--85},
publisher = {IEEE},
title = {Information visualization for chronic disease risk assessment},
volume = {27},
year = {2012}
}
@inproceedings{Cheng2022,
abstract = {Machine learning tools have been deployed in various contexts to support human decision-making, in the hope that human-algorithm collaboration can improve decision quality. However, the question of whether such collaborations reduce or exacerbate biases in decision-making remains underexplored. In this work, we conducted a mixed-methods study, analyzing child welfare call screen workers' decision-making over a span of four years, and interviewing them on how they incorporate algorithmic predictions into their decision-making process. Our data analysis shows that, compared to the algorithm alone, workers reduced the disparity in screen-in rate between Black and white children from 20% to 9%. Our qualitative data show that workers achieved this by making holistic risk assessments and adjusting for the algorithm's limitations. Our analyses also show more nuanced results about how human-algorithm collaboration afects prediction accuracy, and how to measure these efects. These results shed light on potential mechanisms for improving human-algorithm collaboration in high-risk decision-making contexts.},
author = {Cheng, Hao-Fei and Stapleton, Logan and Kawakami, Anna and Sivaraman, Venkatesh and Cheng, Yanghuidi and Qing, Diana and Kenneth, Adam Perer and Zhiwei, Holstein and Wu, Steven and Zhu, Haiyi and Perer, Adam and Holstein, Kenneth and Wu, Zhiwei Steven},
address = {New York, NY, USA},
series = {{CHI} '22},
location = {New Orleans, LA, USA},
booktitle = {Proceedings of the 2022 Conference on Human Factors in Computing Systems (CHI '22)},
doi = {10.1145/3491102.3501831},
file = {:Users/vsivaram/Documents/papers/3491102.3501831.pdf:pdf},
isbn = {9781450391573},
keywords = {algorithm-assisted decision-making,algorithmic biases,child welfare,human-centered AI,machine learning},
mendeley-groups = {Opioid Risk},
number = {1},
pages = {22},
publisher = {Association for Computing Machinery},
title = {How Child Welfare Workers Reduce Racial Disparities in Algorithmic Decisions},
url = {https://doi.org/10.1145/3491102.3501831},
volume = {1},
year = {2022}
}
@article{Kuo2023,
abstract = {Recent years have seen growing adoption of AI-based decision-support systems (ADS) in homeless services, yet we know little about stakeholder desires and concerns surrounding their use. In this work, we aim to understand impacted stakeholders' perspectives on a deployed ADS that prioritizes scarce housing resources. We employed AI lifecycle comicboarding, an adapted version of the comicboarding method, to elicit stakeholder feedback and design ideas across various components of an AI system's design. We elicited feedback from county workers who operate the ADS daily, service providers whose work is directly impacted by the ADS, and unhoused individuals in the region. Our participants shared concerns and design suggestions around the AI system's overall objective, specific model design choices, dataset selection, and use in deployment. Our findings demonstrate that stakeholders, even without AI knowledge, can provide specific and critical feedback on an AI system's design and deployment, if empowered to do so.},
author = {Kuo, Tzu Sheng and Shen, Hong and Geum, Jisoo and Jones, Nev and Hong, Jason I. and Zhu, Haiyi and Holstein, Kenneth},
doi = {10.1145/3544548.3580882},
file = {:Users/vsivaram/Documents/papers/3544548.3580882.pdf:pdf},
isbn = {9781450394215},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {AI-based decision support,comicboarding,homelessness,public algorithms},
mendeley-groups = {Opioid Risk},
title = {Understanding Frontline Workers' and Unhoused Individuals' Perspectives on {AI} Used in Homeless Services},
year = {2023}
}
@article{Saxena2023,
abstract = {Risk assessment algorithms are being adopted by public sector agencies to make high-stakes decisions about human lives. Algorithms model "risk"based on individual client characteristics to identify clients most in need. However, this understanding of risk is primarily based on easily quantifiable risk factors that present an incomplete and biased perspective of clients. We conducted a computational narrative analysis of child-welfare casenotes and draw attention to deeper systemic risk factors that are hard to quantify but directly impact families and street-level decision-making. We found that beyond individual risk factors, the system itself poses a significant amount of risk where parents are over-surveilled by caseworkers and lack agency in decision-making processes. We also problematize the notion of risk as a static construct by highlighting the temporality and mediating effects of different risk, protective, systemic, and procedural factors. Finally, we draw caution against using casenotes in NLP-based systems by unpacking their limitations and biases embedded within them.},
archivePrefix = {arXiv},
arxivId = {2302.08497},
author = {Saxena, Devansh and Moon, Erina Seh Young and Chaurasia, Aryan and Guan, Yixin and Guha, Shion},
doi = {10.1145/3544548.3581308},
eprint = {2302.08497},
file = {:Users/vsivaram/Documents/papers/3544548.3581308.pdf:pdf},
isbn = {9781450394215},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {computational narrative analysis,risk prediction,risk work,uncertainty in decision-making},
mendeley-groups = {Opioid Risk},
title = {Rethinking "Risk" in Algorithmic Systems Through A Computational Narrative Analysis of Casenotes in Child-Welfare},
year = {2023}
}
@book{Zhang2023,
abstract = {Intelligent decision support tools (DSTs) hold the promise to improve the quality of human decision-making in challenging situations like diversions in aviation. To achieve these improvements, a common goal in DST design is to calibrate decision makers' trust in the system. However, this perspective is mostly informed by controlled studies and might not fully reflect the real-world complexity of diversions. In order to understand how DSTs can be beneficial in the view of those who have the best understanding of the complexity of diversions, we interviewed professional pilots. To facilitate discussions, we built two low-fidelity prototypes, each representing a different role a DST could assume: (a) actively suggesting and ranking airports based on pilot-specified criteria, and (b) unobtrusively hinting at data points the pilot should be aware of. We find that while pilots would not blindly trust a DST, they at the same time reject deliberate trust calibration in the moment of the decision. We revisit appropriation as a lens to understand this seeming contradiction as well as a range of means to enable appropriation. Aside from the commonly considered need for transparency, these include directability and continuous support throughout the entire decision process. Based on our design exploration, we encourage to expand the view on DST design beyond trust calibration at the point of the actual decision.},
author = {Zhang, Zelun Tony and Storath, Cara and Liu, Yuanting and Butz, Andreas},
booktitle = {International Conference on Intelligent User Interfaces, Proceedings IUI},
doi = {10.1145/3581641.3584056},
file = {:Users/vsivaram/Documents/papers/zhangt2023iui.pdf:pdf},
isbn = {9798400701061},
keywords = {AI-assisted decision-making,appropriation,aviation,decision support tools,human-AI interaction,imperfect AI,intelligent decision support,naturalistic decision-making},
mendeley-groups = {Opioid Risk},
number = {1},
pages = {397--409},
publisher = {Association for Computing Machinery},
title = {Resilience Through Appropriation: {Pilots'} View on Complex Decision Support},
volume = {1},
year = {2023}
}
@article{Burgess2023,
abstract = {Artificial intelligence (AI) supported clinical decision support (CDS) technologies can parse vast quantities of patient data into meaningful insights for healthcare providers. Much work is underway to determine the technical feasibility and the accuracy of AI-driven insights. Much less is known about what insights are considered useful and actionable by healthcare providers, their trust in the insights, and clinical workflow integration challenges. Our research team used a conceptual prototype based on AI-generated treatment insights for type 2 diabetes medications to elicit feedback from 41 U.S.-based clinicians, including primary care and internal medicine physicians, endocrinologists, nurse practitioners, physician assistants, and pharmacists. We contribute to the human-computer interaction (HCI) community by describing decision optimization and design objective tensions between population-level and personalized insights, and patterns of use and trust of AI systems. We also contribute a set of 6 design principles for AI-supported CDS.},
author = {Burgess, Eleanor R. and Jankovic, Ivana and Austin, Melissa and Cai, Nancy and Kapu{\'{s}}ci{\'{n}}ska, Adela and Currie, Suzanne and Overhage, J. Marc and Poole, Erika S. and Kaye, Jofish},
doi = {10.1145/3544548.3581251},
file = {:Users/vsivaram/Documents/papers/3544548.3581251.pdf:pdf},
isbn = {9781450394215},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Artificial intelligence,design objective,design principles,knowledge creation,machine learning,medication prescribing,provider workflows,sociotechnical complexity,type two diabetes},
mendeley-groups = {Opioid Risk},
title = {Healthcare {AI} Treatment Decision Support: {Design} Principles to Enhance Clinician Adoption and Trust},
year = {2023}
}
@article{Fox2023,
author = {Fox, Sarah E and Awumey, Ezra and Riordan, Christine A and Stringam, Betsy and Begleiter, Ben and Forlizzi, Jodi},
doi = {10.1145/3563657.3596018},
file = {:Users/vsivaram/Documents/papers/3563657.3596018.pdf:pdf},
isbn = {9781450398930},
keywords = {acm reference format,algorithmic management,christine a,ezra awumey,fox,franchesca spektor,riordan,sarah e,worker voice,worker wellbeing},
mendeley-groups = {Opioid Risk},
pages = {623--637},
title = {Designing for Wellbeing : {Worker}-Generated Ideas on Adapting Algorithmic Management in the Hospitality Industry},
year = {2023}
}
@article{Ghimire2021,
abstract = {Assessing the possibility of Coronavirus infection and its risk on an individual's life, estimating the spatial transmission risk based on the dynamic condition of a particular place into consideration, and communicating the same to the public is crucial for minimizing the potential impact of COVID-19. With the increase in cases world-wide, new patterns are being unfolded. Nevertheless, an application for risk assessment will not only help the researcher to quickly verify the proof of concept but also is a powerful tool to bring into notice the results immediately as one of the perfect tools for risk communication. Covira (https://covira.info) is an open-source web-based software that captures the response, calculates personal as well as regional risk, and displays the result to the end-user in the form of maps and risk cards.},
author = {Ghimire, Bhoj Raj and Parajuli, Rishi Ram and Khatiwada, Bipin and Poudel, Shobha and Sharma, Kusum and Mishra, Bhogendra},
doi = {10.1016/j.softx.2021.100873},
file = {:Users/vsivaram/Documents/papers/1-s2.0-S2352711021001400-main.pdf:pdf},
issn = {23527110},
journal = {SoftwareX},
keywords = {COVID-19,Covira,Personal risk,Risk assessment,Risk communication tool,Software},
mendeley-groups = {Opioid Risk},
pages = {100873},
publisher = {Elsevier B.V.},
title = {Covira: {A} {COVID}-19 risk assessment, visualization and communication tool},
url = {https://doi.org/10.1016/j.softx.2021.100873},
volume = {16},
year = {2021}
}
@inproceedings{Kawakami2022,
author = {Kawakami, Anna and Sivaraman, Venkatesh and Stapleton, Logan and Cheng, Hao-Fei and Perer, Adam and Wu, Zhiwei Steven and Zhu, Haiyi and Holstein, Kenneth},
title = {“Why Do I Care What’s Similar?” Probing Challenges in AI-Assisted Child Welfare Decision-Making through Worker-AI Interface Design Concepts},
year = {2022},
isbn = {9781450393584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532106.3533556},
doi = {10.1145/3532106.3533556},
abstract = {Data-driven AI systems are increasingly used to augment human decision-making in complex, social contexts, such as social work or legal practice. Yet, most existing design knowledge regarding how to best support AI-augmented decision-making comes from studies in comparatively well-defined settings. In this paper, we present findings from design interviews with 12 social workers who use an algorithmic decision support tool (ADS) to assist their day-to-day child maltreatment screening decisions. We generated a range of design concepts, each envisioning different ways of redesigning or augmenting the ADS interface. Overall, workers desired ways to understand the risk score and incorporate contextual knowledge, which move beyond existing notions of AI interpretability. Conversations around our design concepts also surfaced more fundamental concerns around the assumptions underlying statistical prediction, such as inference based on similar historical cases and statistical notions of uncertainty. Based on our findings, we discuss how ADS may be better designed to support the roles of human decision-makers in social decision-making contexts.},
booktitle = {Proceedings of the 2022 ACM Designing Interactive Systems Conference},
pages = {454–470},
numpages = {17},
keywords = {AI-assisted decision-making, algorithmic decision support, child welfare, design, social work},
location = {Virtual Event, Australia},
series = {DIS '22}
}

@article{Kostelnick2013,
abstract = {Increased attention to global climate change in recent years has resulted in a wide array of maps and geovisualizations that forecast various scenarios. Since many consequences of climate change are inherently geographic in nature, effective cartographic representations that depict these risks are valuable for planning and mitigation purposes. In particular, sea-level rise resulting from climate change calls attention to the numerous representation issues that warrant consideration for hazard and risk mapping in general, including categorizing and representing risk, selecting an appropriate level of realism, and displaying potential impacts of a hazard on human populations as well as on the natural and built environments. Using examples of potential inundation from sea-level rise at global, regional, and local scales, the authors propose a conceptual framework of key cartographic considerations for maps, Web-based mashups, and geovisualizations that depict risk. The cartographic framework presented here may be extended to other risks of an ambiguous or fuzzy nature and may be used to organize key future research areas for hazard or risk mapping in general.},
author = {Kostelnick, John C. and Mcdermott, Dave and Rowley, Rex J. and Bunnyfield, Nathaniel},
doi = {10.3138/carto.48.3.1531},
file = {:Users/vsivaram/Documents/papers/project_muse_521805.pdf:pdf},
issn = {03177173},
journal = {Cartographica},
keywords = {cartographic uncertainty,changements climatiques,climate change,dangers et risques,hazards and risks,incertitude cartographique,mont{\'{e}}e du niveau de la mer,realism,representation,repr{\'{e}}sentation,r{\'{e}}alisme,sea-level rise,symbologie,symbology},
mendeley-groups = {Opioid Risk},
number = {3},
pages = {200--224},
title = {A cartographic framework for visualizing risk},
volume = {48},
year = {2013}
}
@article{Brown2019,
author = {Brown, Anna and Chouldechova, Alexandra and Putnam-hornstein, Emily and Tobin, Andrew},
file = {:Users/vsivaram/Documents/papers/3290605.3300271.pdf:pdf},
isbn = {9781450359702},
keywords = {Algorithmic Accountability,Algorithmic Bias,Automated Decision Systems,Child Welfare Services,Decision-Support,Participatory Design,algorithmic accountability,algorithmic bias,automated decision systems,child welfare,decision-support,participatory design,services},
mendeley-groups = {Child Welfare,Child Welfare/AFST-specific,Opioid Risk},
pages = {1--12},
title = {Toward Algorithmic Accountability in Public Services},
year = {2019}
}
@article{Oliva2017,
abstract = {Concerns about opioid-related adverse events, including overdose, prompted the Veterans Health Administration (VHA) to launch an Opioid Safety Initiative and Overdose Education and Naloxone Distribution program. To mitigate risks associated with opioid prescribing, a holistic approach that takes into consideration both risk factors (e.g., dose, substance use disorders) and risk mitigation interventions (e.g., urine drug screening, psychosocial treatment) is needed. This article describes the Stratification Tool for Opioid Risk Mitigation (STORM), a tool developed in VHA that reflects this holistic approach and facilitates patient identification and monitoring. STORM prioritizes patients for review and intervention according to their modeled risk for overdose/suicide-related events and displays risk factors and risk mitigation interventions obtained from VHA electronic medical record (EMR)-data extracts. Patients' estimated risk is based on a predictive risk model developed using fiscal year 2010 (FY2010: 10/1/2009 -9/30/2010) EMR-data extracts and mortality data among 1,135,601 VHA patients prescribed opioid analgesics to predict risk for an overdose/suicide-related event in FY2011 (2.1% experienced an event). Cross-validation was used to validate the model, with receiver operating characteristic curves for the training and test data sets performing well (>.80 area under the curve). The predictive risk model distinguished patients based on risk for overdose/suicide-related adverse events, allowing for identification of high-risk patients and enrichment of target populations of patients with greater safety concerns for proactive monitoring and application of risk mitigation interventions. Results suggest that clinical informatics can leverage EMR-extracted data to identify patients at-risk for overdose/suicide-related events and provide clinicians with actionable information to mitigate risk.},
author = {Oliva, Elizabeth M. and Bowe, Thomas and Tavakoli, Sara and Martins, Susana and Lewis, Eleanor T. and Paik, Meenah and Wiechers, Ilse and Henderson, Patricia and Harvey, Michael and Avoundjian, Tigran and Medhanie, Amanuel and Trafton, Jodie A.},
doi = {10.1037/ser0000099},
file = {:Users/vsivaram/Documents/papers/ser-ser0000099.pdf:pdf},
issn = {15411559},
journal = {Psychological Services},
keywords = {Decision support,Opioid safety,Opioids,Risk mitigation,Risk model},
mendeley-groups = {Opioid Risk},
number = {1},
pages = {34--49},
pmid = {28134555},
title = {Development and applications of the veterans health administration's stratification tool for opioid risk mitigation ({STORM}) to improve opioid safety and prevent overdose and suicide},
volume = {14},
year = {2017}
}
@article{Ripperger2021,
abstract = {OBJECTIVE: To develop and validate algorithms for predicting 30-day fatal and nonfatal opioid-related overdose using statewide data sources including prescription drug monitoring program data, Hospital Discharge Data System data, and Tennessee (TN) vital records. Current overdose prevention efforts in TN rely on descriptive and retrospective analyses without prognostication. MATERIALS AND METHODS: Study data included 3 041 668 TN patients with 71 479 191 controlled substance prescriptions from 2012 to 2017. Statewide data and socioeconomic indicators were used to train, ensemble, and calibrate 10 nonparametric "weak learner" models. Validation was performed using area under the receiver operating curve (AUROC), area under the precision recall curve, risk concentration, and Spiegelhalter z-test statistic. RESULTS: Within 30 days, 2574 fatal overdoses occurred after 4912 prescriptions (0.0069%) and 8455 nonfatal overdoses occurred after 19 460 prescriptions (0.027%). Discrimination and calibration improved after ensembling (AUROC: 0.79-0.83; Spiegelhalter P value: 0-.12). Risk concentration captured 47-52% of cases in the top quantiles of predicted probabilities. DISCUSSION: Partitioning and ensembling enabled all study data to be used given computational limits and helped mediate case imbalance. Predicting risk at the prescription level can aggregate risk to the patient, provider, pharmacy, county, and regional levels. Implementing these models into Tennessee Department of Health systems might enable more granular risk quantification. Prospective validation with more recent data is needed. CONCLUSION: Predicting opioid-related overdose risk at statewide scales remains difficult and models like these, which required a partnership between an academic institution and state health agency to develop, may complement traditional epidemiological methods of risk identification and inform public health decisions.},
author = {Ripperger, Michael and Lotspeich, Sarah C. and Wilimitis, Drew and Fry, Carrie E. and Roberts, Allison and Lenert, Matthew and Cherry, Charlotte and Latham, Sanura and Robinson, Katelyn and Chen, Qingxia and McPheeters, Melissa L. and Tyndall, Ben and Walsh, Colin G.},
doi = {10.1093/jamia/ocab218},
file = {:Users/vsivaram/Documents/papers/ocab218.pdf:pdf},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association : JAMIA},
keywords = {drug overdose,machine learning,opioid epidemic,prescription drug monitoring programs,vital statistics},
mendeley-groups = {Opioid Risk},
number = {1},
pages = {22--32},
pmid = {34665246},
title = {Ensemble learning to predict opioid-related overdose using statewide prescription drug monitoring program and hospital discharge data in the state of {Tennessee}},
volume = {29},
year = {2021}
}
@article{Gellad2023,
title = {Development and validation of an overdose risk prediction tool using prescription drug monitoring program data},
journal = {Drug and Alcohol Dependence},
volume = {246},
pages = {109856},
year = {2023},
issn = {0376-8716},
doi = {https://doi.org/10.1016/j.drugalcdep.2023.109856},
url = {https://www.sciencedirect.com/science/article/pii/S0376871623000947},
author = {Walid F. Gellad and Qingnan Yang and Kayleigh M. Adamson and Courtney C. Kuza and Jeanine M. Buchanich and Ashley L. Bolton and Stanley M. Murzynski and Carrie Thomas Goetz and Terri Washington and Michael F. Lann and Chung-Chou H. Chang and Katie J. Suda and Lu Tang},
keywords = {Overdose prevention, Risk prediction, State policy, Surveillance},
abstract = {Objectives
To develop and validate a machine-learning algorithm to predict fatal overdose using Pennsylvania Prescription Drug Monitoring Program (PDMP) data.
Methods
The training/testing (n = 3020,748) and validation (n = 2237,701) cohorts included Pennsylvania residents with a prescription dispensing from February 2018-September 2021. Potential predictors (n = 222) were measured in the 6 months prior to a random index date. Using a gradient boosting machine, we developed a 20-variable model to predict risk of fatal drug overdose in the 6 months after the index date.
Results
Beneficiaries in the training (n = 1,812,448), testing (n = 1,208,300), and validation (n = 2,237,701) samples had similar age, with low rates of fatal overdose during 6-month follow up (0.12%, 0.12%, 0.04%, respectively). The validation c-statistic was 0.86 for predicting fatal overdose using 20 PDMP variables. When ranking individuals based on risk score, the prediction model more accurately identified fatal overdose at 6 months compared to using opioid dosage or opioid/benzodiazepine overlap, although the percentage of individuals in the highest risk percentile who died at 6 months was less than 1%.
Conclusions and policy implications
A gradient boosting machine algorithm predicting fatal overdose derived from twenty variables performed well in discriminating risk across testing and validation samples, improving on single factor risk measures like opioid dosage}
}
// doi = {10.1016/j.drugalcdep.2023.109856},
// issn = {18790046},
// journal = {Drug and Alcohol Dependence},
// number = {November 2022},
// pages = {109856},
// pmid = {37001323},
// publisher = {Elsevier B.V.},
// url = {https://doi.org/10.1016/j.drugalcdep.2023.109856},
// volume = {246},

@inproceedings{Kawakami2022partnerships,
abstract = {AI-based decision support tools (ADS) are increasingly used to augment human decision-making in high-stakes, social contexts. As public sector agencies begin to adopt ADS, it is critical that we understand workers' experiences with these systems in practice. In this paper, we present findings from a series of interviews and contextual inquiries at a child welfare agency, to understand how they currently make AI-assisted child maltreatment screening decisions. Overall, we observe how workers' reliance upon the ADS is guided by (1) their knowledge of rich, contextual information beyond what the AI model captures, (2) their beliefs about the ADS's capabilities and limitations relative to their own, (3) organizational pressures and incentives around the use of the ADS, and (4) awareness of misalignments between algorithmic predictions and their own decision-making objectives. Drawing upon these findings, we discuss design implications towards supporting more effective human-AI decision-making.},
archivePrefix = {arXiv},
arxivId = {2204.02310},
author = {Kawakami, Anna and Sivaraman, Venkatesh and Cheng, Hao-Fei and Stapleton, Logan and Cheng, Yanghuidi and Qing, Diana and Perer, Adam and Wu, Zhiwei Steven and Zhu, Haiyi and Holstein, Kenneth},
	address = {New York, NY, USA},
	location = {New Orleans, LA, USA},
	series = {{CHI} '22},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
eprint = {2204.02310},
file = {:Users/vsivaram/Documents/papers/3491102.3517439.pdf:pdf},
keywords = {algorithm-assisted decision making,child welfare,contextual,decision suppo,decision support,inquiry,this work is licensed,under a creative commons},
mendeley-groups = {AI Clinician/Cognitive Mini,AI Clinician,Opioid Risk},
title = {Improving Human-{AI} Partnerships in Child Welfare: {Understanding} Worker Practices, Challenges, and Desires for Algorithmic Decision Support},
url = {https://doi.org/10.1145/3491102.3517439},
year = {2022}
}

@book{Zeng2020,
abstract = {Artificial intelligence (AI) techniques have been widely applied to infectious disease outbreak detection and early warning, trend prediction, and public health response modeling and assessment. Such public health surveillance and response tasks of major importance pose unique technical challenges such as data sparsity, lack of positive training samples, difficulty in developing baselines and quantifying the control measures, and interwoven dependencies between spatiotemporal elements and finer-grained risk analyses through contact and social networks. Traditional public health surveillance relies heavily on statistical techniques. Recent years have seen tremendous growth of AI-enabled methods, including but not limited to deep learning–based models, complementing statistical approaches. This chapter aims to provide a systematic review of these recent advances applying AI techniques to address public health surveillance and response challenges.},
author = {Zeng, Daniel and Cao, Zhidong and Neill, Daniel B.},
booktitle = {Artificial Intelligence in Medicine: Technical Basis and Clinical Applications},
doi = {10.1016/B978-0-12-821259-2.00022-3},
file = {:Users/vsivaram/Documents/papers/3-s2.0-B9780128212592000223-main.pdf:pdf},
isbn = {9780128212592},
keywords = {AI-enabled public health surveillance,early warning,infectious disease surveillance,public health response},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
pages = {437--453},
publisher = {INC},
title = {Artificial intelligence–enabled public health surveillance—from local detection to global epidemic monitoring and control},
url = {http://dx.doi.org/10.1016/B978-0-12-821259-2.00022-3},
year = {2020}
}
@article{Allen2016,
abstract = {Traditional methods for monitoring influenza are haphazard and lack fine-grained details regarding the spatial and temporal dynamics of outbreaks. Twitter gives researchers and public health officials an opportunity to examine the spread of influenza in real-time and at multiple geographical scales. In this paper, we introduce an improved framework for monitoring influenza outbreaks using the social media platform Twitter. Relying upon techniques from geographic information science (GIS) and data mining, Twitter messages were collected, filtered, and analyzed for the thirty most populated cities in the United States during the 2013-2014 flu season. The results of this procedure are compared with national, regional, and local flu outbreak reports, revealing a statistically significant correlation between the two data sources. The main contribution of this paper is to introduce a comprehensive data mining process that enhances previous attempts to accurately identify tweets related to influenza. Additionally, geographical information systems allow us to target, filter, and normalize Twitter messages.},
author = {Allen, Chris and Tsou, Ming Hsiang and Aslam, Anoshe and Nagel, Anna and Gawron, Jean Mark},
doi = {10.1371/journal.pone.0157734},
file = {:Users/vsivaram/Documents/papers/flu twitter ml.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
number = {7},
pages = {1--10},
pmid = {27455108},
title = {Applying {GIS} and machine learning methods to twitter data for multiscale surveillance of influenza},
volume = {11},
year = {2016}
}
@article{Brown2017,
abstract = {Background Prescription Drug Monitoring programs (PDMPs) are intended to reduce opioid prescribing and aberrant drug-related behavior thereby reducing morbidity and mortality due to prescription opioid overdose. Expansion of the New York (NY) State's PDMP in 2013 included the institution of the I-STOP law that mandated clinicians to consult the statewide PDMP database to review the patient's prescription history prior to prescribing opioids. Methods Trends in prescription opioid distribution, prescribing, and prescription opioid and heroin overdose morbidity in NY were analyzed using time series. A Chow test was used to test the difference in trends before and after the implementation of I-STOP. Results The results indicated that: 1) the number of opioid prescriptions appears to be declining following the implementation of the I-STOP, 2) however, supply chain data shows that the total quantity of opioids in the supply chain increased, 3) statewide trends in inpatient and emergency department visits for prescription opioid overdose increased from 2010 to the third quarter of 2013 where the slope leveled off following I-STOP, but this change in slope was not significant, 4) visits for heroin overdose started escalating in 2010 and continued to increase through the second quarter of 2016. The overall significance of these findings show a small impact of PDMPs on prescription opioid overdose morbidity in NY in the context of the increasing national trend during this time period. Conclusions Prescription opioid morbidity leveled off following the implementation of a mandated PDMP although morbidity attributable to heroin overdose continued to rise.},
author = {Brown, Richard and Riley, Moira R. and Ulrich, Lydia and Kraly, Ellen Percy and Jenkins, Paul and Krupa, Nicole L. and Gadomski, Anne},
doi = {10.1016/j.drugalcdep.2017.05.023},
file = {:Users/vsivaram/Documents/papers/1-s2.0-S0376871617302971-main.pdf:pdf},
issn = {18790046},
journal = {Drug and Alcohol Dependence},
keywords = {Heroin,I-STOP,Overdose morbidity,Prescription drug monitoring program,Prescription opioids},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
number = {May},
pages = {348--354},
pmid = {28692945},
publisher = {Elsevier},
title = {Impact of {New York} prescription drug monitoring program, {I-STOP}, on statewide overdose morbidity},
url = {http://dx.doi.org/10.1016/j.drugalcdep.2017.05.023},
volume = {178},
year = {2017}
}
@article{Ferris2019,
abstract = {Introduction: Prescription Drug Monitoring Program data can provide insights into a patient's likelihood of an opioid overdose, yet clinicians and public health officials lack indicators to identify individuals at highest risk accurately. A predictive model was developed and validated using Prescription Drug Monitoring Program prescription histories to identify those at risk for fatal overdose because of any opioid or illicit opioids. Methods: From December 2018 to July 2019, a retrospective cohort analysis was performed on Maryland residents aged 18–80 years with a filled opioid prescription (n=565,175) from January to June 2016. Fatal opioid overdoses were identified from the Office of the Chief Medical Examiner and were linked at the person-level with Prescription Drug Monitoring Program data. Split-half technique was used to develop and validate a multivariate logistic regression with a 6-month lookback period and assessed model calibration and discrimination. Results: Predictors of any opioid-related fatal overdose included male sex, age 65–80 years, Medicaid, Medicare, 1 or more long-acting opioid fills, 1 or more buprenorphine fills, 2 to 3 and 4 or more short-acting schedule II opioid fills, opioid days' supply ≥91 days, average morphine milligram equivalent daily dose, 2 or more benzodiazepine fills, and 1 or more muscle relaxant fills. Model discrimination for the validation cohort was good (area under the curve: any, 0.81; illicit, 0.77). Conclusions: A model for predicting fatal opioid overdoses was developed using Prescription Drug Monitoring Program data. Given the recent national epidemic of deaths involving heroin and fentanyl, it is noteworthy that the model performed equally well in identifying those at risk for overdose deaths from both illicit and prescription opioids.},
author = {Ferris, Lindsey M. and Saloner, Brendan and Krawczyk, Noa and Schneider, Kristen E. and Jarman, Molly P. and Jackson, Kate and Lyons, B. Casey and Eisenberg, Matthew D. and Richards, Tom M. and Lemke, Klaus W. and Weiner, Jonathan P.},
doi = {10.1016/j.amepre.2019.07.026},
file = {:Users/vsivaram/Documents/papers/1-s2.0-S0749379719303502-main.pdf:pdf},
issn = {18732607},
journal = {American Journal of Preventive Medicine},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
number = {6},
pages = {e211--e217},
pmid = {31753274},
publisher = {Elsevier Inc.},
title = {Predicting Opioid Overdose Deaths Using {Prescription Drug Monitoring Program} Data},
volume = {57},
year = {2019}
}
@article{Lo-Ciganic2019,
author = {Lo-Ciganic, Wei Hsuan and Huang, James L. and Zhang, Hao H. and Weiss, Jeremy C. and Wu, Yonghui and Kwoh, C. Kent and Donohue, Julie M. and Cochran, Gerald and Gordon, Adam J. and Malone, Daniel C. and Kuza, Courtney C. and Gellad, Walid F.},
doi = {10.1001/jamanetworkopen.2019.0968},
file = {:Users/vsivaram/Documents/papers/lociganic_2019_oi_190058.pdf:pdf},
issn = {25743805},
journal = {JAMA network open},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
number = {3},
pages = {e190968},
pmid = {30901048},
title = {Evaluation of Machine-Learning Algorithms for Predicting Opioid Overdose Risk Among Medicare Beneficiaries With Opioid Prescriptions},
volume = {2},
year = {2019}
}
@inproceedings{Thakkar2022,
abstract = {Data-driven approaches that form the foundation of advancements in machine learning (ML) are powered in large part by human infrastructures that enable the collection of large datasets. We study the movement of data through multiple stages of data processing in the context of public health in India, examining the data work performed by frontline health workers, data stewards, and ML developers. We conducted interviews with these stakeholders to understand their varied perspectives on valuing data across stages, working with data to attain this value, and challenges arising throughout. We discuss the tensions in valuing and how they might be addressed, as we emphasize the need for improved transparency and accountability when data are transformed from one stage of processing to the next.},
author = {Thakkar, Divy and Ismail, Azra and Kumar, Pratyush and Hanna, Alex and Sambasivan, Nithya and Kumar, Neha},
doi = {10.1145/3491102.3501868},
file = {:Users/vsivaram/Documents/papers/3491102.3501868.pdf:pdf},
isbn = {9781450391573},
booktitle = {Proceedings of the 2022 Conference on Human Factors in Computing Systems},
series = {{CHI} '22},
location = {New Orleans, LA, USA},
address = {New York, NY, USA},
publisher = {Association for Computing Machinery},
keywords = {Data work,India,public health,valuation},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
title = {When is Machine Learning Data Good?: {Valuing} in Public Health Datafication},
year = {2022}
}
@article{Shahid2020,
abstract = {Social media platforms are widely used by people to report, access, and share information during outbreaks and epidemics. Although government agencies and healthcare institutions in developed regions are increasingly relying on social media to develop epidemic forecasts and outbreak response, there is a limited understanding of how people in developing regions interact on social media during outbreaks and what useful insights this dataset could offer during public health crises. In this work, we examined 28,688 tweets to identify public health issues during dengue epidemic in Bangladesh and found several insights, such as irregularities in dengue diagnosis and treatment, shortage of blood supply for Rh negative blood groups, and high local transmission of dengue during Eid-ul-Adha, that impact disease preparedness and outbreak response. We discuss the opportunities and challenges in analyzing tweets and outline how government agencies and healthcare institutions can use social media health data to inform policy making during public health crises.},
author = {Shahid, Farhana and Ony, Shahinul Hoque and Albi, Takrim Rahman and Chellappan, Sriram and Vashistha, Aditya and {Alim Al Islam}, A. B.M.},
doi = {10.1145/3392875},
file = {:Users/vsivaram/Documents/papers/3392875.pdf:pdf},
issn = {25730142},
journal = {Proceedings of the ACM on Human-Computer Interaction},
keywords = {Bangladesh,blood donation,dengue,epidemic,hci4d,health policy,outbreak,public health crisis,twitter},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
number = {CSCW1},
pages = {1--27},
title = {Learning from Tweets: {Opportunities} and Challenges to Inform Policy Making during Dengue Epidemic},
volume = {4},
year = {2020}
}
@article{Ziegler2023,
abstract = {Geospatial data is playing an increasingly critical role in the work of Earth and climate scientists, social scientists, and data journalists exploring spatiotemporal change in our environment and societies. However, existing software and programming tools for geospatial analysis and visualization are challenging to learn and difficult to use. The aim of this work is to identify the unmet computing needs of the diverse and expanding community of geospatial data users. We conducted a contextual inquiry study (n = 25) with domain experts using geospatial data in their current work. Through a thematic analysis, we found that participants struggled to (1) find and transform geospatial data to satisfy spatiotemporal constraints, (2) understand the behavior of geospatial operators, (3) track geospatial data provenance, and (4) explore the cartographic design space. These findings suggest design opportunities for developers and designers of geospatial analysis and visualization systems.},
author = {Ziegler, Parker and Chasins, Sarah E.},
doi = {10.1145/3544548.3581370},
file = {:Users/vsivaram/Documents/papers/3544548.3581370.pdf:pdf},
isbn = {9781450394215},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {GIS,cartography,contextual inquiry,geography,geospatial data,need-finding},
mendeley-groups = {Opioid Risk},
title = {A Need-Finding Study with Users of Geospatial Data},
year = {2023}
}
@article{Pine2021,
abstract = {During a global pandemic such as COVID-19, laypeople bear a large burden of responsibility for assessing risks associated with COVID19 and taking action to manage risks in their everyday lives, yet epidemic-related information is characterized by uncertainty and ambiguity. People perceive risks based on partial, changing information.We draw on crisis informatics research to examine the multiple types of risk people perceive in relation to the COVID-19 pandemic, the information sources that inform perceptions of COVID-19 risks, and the challenges that people have in getting the information they need to understand risks, using qualitative interviews with individuals across the USA. Participants describe multiple pandemic-related threats, including illness, secondary health conditions, economic, socio-behavioral, and institutional risks. We further uncover how people draw on multiple information sources from technological infrastructures, people, and spaces to inform the types of their risk perceptions, uncovering deep challenges to acquiring needed risk information.},
author = {Pine, Kathleen H. and Lee, Myeong and Whitman, Samantha A. and Chen, Yunan and Henne, Kathryn},
doi = {10.1145/3411764.3445051},
file = {:Users/vsivaram/Documents/papers/3411764.3445051.pdf:pdf},
isbn = {9781450380966},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Covid-19,Crisis informatics,Health information,Information seeking,Risk perception},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
title = {Making sense of risk information amidst uncertainty: {Individuals'} perceived risks associated with the {COVID}-19 pandemic},
year = {2021}
}
@article{Lee2021,
abstract = {Controversial understandings of the coronavirus pandemic have turned data visualizations into a battleground. Defying public health ofcials, coronavirus skeptics on US social media spent much of 2020 creating data visualizations showing that the government's pandemic response was excessive and that the crisis was over. This paper investigates how pandemic visualizations circulated on social media, and shows that people who mistrust the scientifc estab-lishment often deploy the same rhetorics of data-driven decision-making used by experts, but to advocate for radical policy changes. Using a quantitative analysis of how visualizations spread on Twit-ter and an ethnographic approach to analyzing conversations about COVID data on Facebook, we document an epistemological gap that leads pro-and anti-mask groups to draw drastically diferent inferences from similar data. Ultimately, we argue that the deploy-ment of COVID data visualizations refect a deeper sociopolitical rift regarding the place of science in public life.},
archivePrefix = {arXiv},
arxivId = {2101.07993},
author = {Lee, Crystal and Yang, Tanya and Inchoco, Gabrielle and Jones, Graham M. and Satyanarayan, Arvind},
doi = {10.1145/3411764.3445211},
eprint = {2101.07993},
file = {:Users/vsivaram/Documents/papers/3411764.3445211.pdf:pdf},
isbn = {9781450380966},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Data lit-eracy,Data visualization,Digital ethnography,Facebook,Network analysis,Twitter},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
title = {Viral visualizations: {How} coronavirus skeptics use orthodox data practices to promote unorthodox science online},
year = {2021}
}

@article{Beede2020,
abstract = {Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.},
author = {Beede, Emma and Baylor, Elizabeth and Hersch, Fred and Iurchenko, Anna and Wilcox, Lauren and Ruamviboonsuk, Paisan and Vardoulakis, Laura M.},
doi = {10.1145/3313831.3376718},
file = {:Users/vsivaram/Documents/papers/3313831.3376718.pdf:pdf},
isbn = {9781450367080},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {deep learning,diabetes,health,human-centered ai},
mendeley-groups = {AI Clinician/Design Mini,AI Clinician/Healthcare,AI Clinician/Clinical Perspectives,Opioid Risk/Human-AI Public Sector},
pages = {1--12},
title = {A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy},
year = {2020}
}

@techreport{Angwin2016,
author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
mendeley-groups = {Opioid Risk/Human-AI Public Sector},
title = {{Machine Bias}: {There's} software used across the country to predict future criminals. And it's biased against blacks.},
year = {2016}
}

@article{Vaithianathan2019,
author = {{Allegheny County} and Vaithianathan, Rhema and Jiang, Nan and Maloney, Tim and Nand, Parma and Putnam-Hornstein, Emily and Dare, Tim and Gambrill, Eileen},
file = {:Users/vsivaram/Documents/papers/16-ACDHS-26_PredictiveRisk_Package_050119_FINAL-2.pdf:pdf},
mendeley-groups = {Child Welfare,Child Welfare/AFST-specific},
title = {Developing predictive risk models to support child maltreatment hotline screening decisions},
year = {2019}
}

@article{Scott2022,
abstract = {Data-driven and algorithmic systems have been introduced to support Public Employment Services (PES) throughout the world. Their deployment has sparked public controversy and, as a consequence, some of these systems have been removed from use or their role was reduced. Yet the implementation of similar systems continues. In this paper, we use a participatory approach to determine a course forward for research and development in this area. We draw attention to the needs and expectations of people directly affected by these systems, i.e., jobseekers. Our investigation comprises two workshops: the first a fact-finding workshop with academics, system developers, the public sector, and civil-society organizations, the second a co-design workshop with 13 unemployed migrants to Germany. Based on the discussion in the fact-finding workshop we identified challenges of existing PES (algorithmic) systems. From the co-design workshop we identified our participants' needs and desires when contacting PES: the need for human contact, the expectation to receive genuine orientation, and the desire to be seen as a whole human being. We map these expectations to three design considerations for data-driven and algorithmic systems for PES: the importance of interpersonal interaction, jobseeker assessment as direction, and the challenge of mitigating misrepresentation. Finally, we argue that the limitations and risks of current systems cannot be addressed through minor adjustments but require a more fundamental change to the role of PES.},
author = {Scott, Kristen M. and Wang, Sonja Mei and Miceli, Milagros and Delobelle, Pieter and Sztandar-Sztanderska, Karolina and Berendt, Bettina},
doi = {10.1145/3531146.3534631},
file = {:Users/vsivaram/Documents/papers/3531146.3534631.pdf:pdf},
isbn = {9781450393522},
journal = {ACM International Conference Proceeding Series},
keywords = {Algorithmic Decision-Making,Participatory Design,Public Employment Services},
mendeley-groups = {Opioid Risk/Human-AI Public Sector},
pages = {2138--2148},
title = {Algorithmic Tools in Public Employment Services: {Towards} a Jobseeker-Centric Perspective},
year = {2022}
}

@ARTICLE{Zytek2021,
  author={Zytek, Alexandra and Liu, Dongyu and Vaithianathan, Rhema and Veeramachaneni, Kalyan},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Sibyl: Understanding and Addressing the Usability Challenges of Machine Learning In High-Stakes Decision Making}, 
  year={2022},
  volume={28},
  number={1},
  pages={1161-1171},
  keywords={Usability;Pediatrics;Tools;Predictive models;Decision making;Context modeling;Prediction algorithms;Machine learning;XAI;Usability;child welfare;visualization},
  doi={10.1109/TVCG.2021.3114864}}


@article{Cheng2021,
abstract = {Recent work in fair machine learning has proposed dozens of quantitative notions of algorith-mic fairness and methods to enforcing these notions. However, we still lack an understanding of how to develop machine learning systems with fairness criteria that reflect human stakeholders' nuanced viewpoints in the real-world contexts. To address the gap, we propose a framework for eliciting stakeholders' subjective fairness notions. Combining a user interface that allows stakeholder to examine the data and algorithm's predictions, and an interview protocol to probe stakeholders' thoughts while they are interacting with the interface, we can identify stakeholders' fairness beliefs and principles. We propose a user study to evaluate our framework in real world settings of a child maltreatment predictive system.},
author = {Cheng, Hao-Fei and Stapleton, Logan and Wang, Ruiqi and Bullock, Paige and Chouldechova, Alexandra and Wu, Zhiwei Steven Steven and Zhu, Haiyi},
doi = {10.1145/3411764.3445308},
file = {:Users/vsivaram/Documents/papers/2102.01196.pdf:pdf},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {algorithm-,algorithmic fairness,assisted decision-making,child welfare,human-centered ai,machine learning},
mendeley-groups = {CHI 2021,Child Welfare,Child Welfare/AFST-specific,Opioid Risk/Human-AI Public Sector},
pages = {1--17},
title = {Soliciting Stakeholders' Fairness Notions in Child Maltreatment Predictive Systems},
year = {2021}
}

@article{Matero2023,
abstract = {Targeting of location-specific aid for the U.S. opioid epidemic is difficult due to our inability to accurately predict changes in opioid mortality across heterogeneous communities. AI-based language analyses, having recently shown promise in cross-sectional (between-community) well-being assessments, may offer a way to more accurately longitudinally predict community-level overdose mortality. Here, we develop and evaluate, TrOP (Transformer for Opiod Prediction), a model for community-specific trend projection that uses community-specific social media language along with past opioid-related mortality data to predict future changes in opioid-related deaths. TOP builds on recent advances in sequence modeling, namely transformer networks, to use changes in yearly language on Twitter and past mortality to project the following year's mortality rates by county. Trained over five years and evaluated over the next two years TrOP demonstrated state-of-the-art accuracy in predicting future county-specific opioid trends. A model built using linear auto-regression and traditional socioeconomic data gave 7% error (MAPE) or within 2.93 deaths per 100,000 people on average; our proposed architecture was able to forecast yearly death rates with less than half that error: 3% MAPE and within 1.15 per 100,000 people.},
author = {Matero, Matthew and Giorgi, Salvatore and Curtis, Brenda and Ungar, Lyle H. and Schwartz, H. Andrew},
doi = {10.1038/s41746-023-00776-0},
file = {:Users/vsivaram/Documents/papers/s41746-023-00776-0.pdf:pdf},
issn = {23986352},
journal = {npj Digital Medicine},
mendeley-groups = {Opioid Risk/Public Health},
number = {1},
pages = {1--11},
publisher = {Springer US},
title = {Opioid death projections with {AI}-based forecasts using social media language},
volume = {6},
year = {2023}
}

@article{Watson2021,
abstract = {Smartphones increasingly serve as the source for, or to aggregate, a considerable amount of data that can be relevant in public health emergencies. Hence the sharing and utilisation of mobile health data, for example to help control the spread of communicable diseases, has become a relevant issue, with the COVID-19 pandemic adding a sudden urgency mirrored in debates around contact tracing apps. Building on exploratory work that indicated user perceptions and values around consent, and the notion that smartphones and mobile health data can be perceived as elements of self-embodiment, we present an online study comparing three scenarios of representative diseases undertaken during the first wave lockdown in the UK. Using a mixed-methods analysis of responses from 86 participants, we identify tensions and mitigations in user values and from those present the description of four characteristic user-groups that can inform considerations for design and development activities in this space.},
author = {Watson, Colin and Ali, Ridita and Smeddinck, Jan David},
doi = {10.1145/3476071},
file = {:Users/vsivaram/Documents/papers/3476071.pdf:pdf},
issn = {25730142},
journal = {Proceedings of the ACM on Human-Computer Interaction},
keywords = {data,health,mixed methods study,mobile,privacy},
mendeley-groups = {Opioid Risk/Public Health},
number = {CSCW2},
title = {Tensions and Mitigations: {Understanding} Concerns and Values around Smartphone Data Collection for Public Health Emergencies},
volume = {5},
year = {2021}
}

@article{Balaam2015,
abstract = {Breastfeeding is positively encouraged across many countries as a public health endeavour. The World Health Organisation recommends breastfeeding exclusively for the first six months of an infant's life. However, women can struggle to breastfeed, and to persist with breastfeeding, for a number of reasons from technique to social acceptance. This paper reports on four phases of a design and research project, from sensitising user-engagement and user-centred design, to the development and in-the-wild deployment of a mobile phone application called FeedFinder. FeedFinder has been developed with breastfeeding women to support them in finding, reviewing and sharing public breastfeeding places with other breastfeeding women. We discuss how mobile technologies can be designed to support public health endeavours, and suggest that public health technologies are better aimed at communities and societies rather than individual.},
author = {Balaam, Madeline and Comber, Rob and Jenkins, Ed and Sutton, Selina and Garbett, Andrew},
doi = {10.1145/2702123.2702328},
file = {:Users/vsivaram/Documents/papers/2702123.2702328.pdf:pdf},
isbn = {9781450331456},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Breastfeeding,Mobile,Preventative health,Public health,User-centred design},
mendeley-groups = {Opioid Risk/Public Health},
pages = {1709--1718},
title = {Feedfinder: {A} location-mapping mobile application for breastfeeding women},
volume = {2015-April},
year = {2015}
}

@article{Zhang2021,
abstract = {In response to COVID-19, a vast number of visualizations have been created to communicate information to the public. Information exposure in a public health crisis can impact people's attitudes towards and responses to the crisis and risks, and ultimately the trajectory of a pandemic. As such, there is a need for work that documents, organizes, and investigates what COVID-19 visualizations have been presented to the public. We address this gap through an analysis of 668 COVID-19 visualizations. We present our findings through a conceptual framework derived from our analysis, that examines who, (uses) what data, (to communicate) what messages, in what form, under what circumstances in the context of COVID-19 crisis visualizations. We provide a set of factors to be considered within each component of the framework. We conclude with directions for future crisis visualization research.},
archivePrefix = {arXiv},
arxivId = {2101.04743},
author = {Zhang, Yixuan and Sun, Yifan and Padilla, Lace and Barua, Sumit and Bertini, Enrico and Parker, Andrea G.},
doi = {10.1145/3411764.3445381},
eprint = {2101.04743},
file = {:Users/vsivaram/Documents/papers/3411764.3445381.pdf:pdf},
isbn = {9781450380966},
keywords = {Visualization, COVID-19, crisis informatics,acm reference format,and an-,covid-19,crisis informatics,enrico bertini,lace padilla,sumit barua,visualization,yifan sun,yixuan zhang},
mendeley-groups = {CHI 2021,Opioid Risk/Public Health},
title = {Mapping the Landscape of {COVID}-19 Crisis Visualizations},
url = {http://arxiv.org/abs/2101.04743%0Ahttp://dx.doi.org/10.1145/3411764.3445381},
year = {2021}
}

@article{Reinhart2021,
abstract = {The COVID-19 pandemic presented enormous data challenges in the United States. Policy makers, epidemiological modelers, and health researchers all require up-to-date data on the pandemic and relevant public behavior, ideally at fine spatial and temporal resolution. The COVIDcast API is our attempt to fill this need: Operational since April 2020, it provides open access to both traditional public health surveillance signals (cases, deaths, and hospitalizations) and many auxiliary indicators of COVID-19 activity, such as signals extracted from deidentified medical claims data, massive online surveys, cell phone mobility data, and internet search trends. These are available at a fine geographic resolution (mostly at the county level) and are updated daily. The COVIDcast API also tracks all revisions to historical data, allowing modelers to account for the frequent revisions and backfill that are common for many public health data sources. All of the data are available in a common format through the API and accompanying R and Python software packages. This paper describes the data sources and signals, and provides examples demonstrating that the auxiliary signals in the COVIDcast API present information relevant to tracking COVID activity, augmenting traditional public health reporting and empowering research and decision-making.},
author = {Reinhart, Alex and Brooks, Logan and Jahja, Maria and Rumack, Aaron and Tang, Jingjing and Agrawal, Sumit and {Al Saeed}, Wael and Arnold, Taylor and Basu, Amartya and Bien, Jacob and Cabrera, {\'{A}}ngel A. and Chin, Andrew and Chua, Eu Jing and Clark, Brian and Colquhoun, Sarah and DeFries, Nat and Farrow, David C. and Forlizzi, Jodi and Grabman, Jed and Gratzl, Samuel and Green, Alden and Haff, George and Han, Robin and Harwood, Kate and Hu, Addison J. and Hyde, Raphael and Hyun, Sangwon and Joshi, Ananya and Kim, Jimi and Kuznetsov, Andrew and {La Motte-Kerr}, Wichada and Lee, Yeon Jin and Lee, Kenneth and Lipton, Zachary C. and Liu, Michael X. and Mackey, Lester and Mazaitis, Kathryn and McDonald, Daniel J. and McGuinness, Phillip and Narasimhan, Balasubramanian and O'Brien, Michael P. and Oliveira, Natalia L. and Patil, Pratik and Perer, Adam and Politsch, Collin A. and Rajanala, Samyak and Rucker, Dawn and Scott, Chris and Shah, Nigam H. and Shankar, Vishnu and Sharpnack, James and Shemetov, Dmitry and Simon, Noah and Smith, Benjamin Y. and Srivastava, Vishakha and Tan, Shuyi and Tibshirani, Robert and Tuzhilina, Elena and van Nortwick, Ana Karina and Ventura, Val{\'{e}}rie and Wasserman, Larry and Weaver, Benjamin and Weiss, Jeremy C. and Whitman, Spencer and Williams, Kristin and Rosenfeld, Roni and Tibshirani, Ryan J.},
doi = {10.1073/pnas.2111452118},
file = {:Users/vsivaram/Documents/papers/pnas.2111452118.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Digital surveillance,Internet surveys,Medical insurance claims,Open data},
mendeley-groups = {Opioid Risk/Public Health},
number = {51},
pmid = {34903654},
title = {An open repository of real-time {COVID}-19 indicators},
volume = {118},
year = {2021}
}
@article{Chande2020,
abstract = {Large events and gatherings, particularly those taking place indoors, have been linked to multitransmission events that have accelerated the pandemic spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). To provide real-time, geolocalized risk information, we developed an interactive online dashboard that estimates the risk that at least one individual with SARS-CoV-2 is present in gatherings of different sizes in the United States. The website combines documented case reports at the county level with ascertainment bias information obtained via population-wide serological surveys to estimate real-time circulating, per-capita infection rates. These rates are updated daily as a means to visualize the risk associated with gatherings, including county maps and state-level plots. The website provides data-driven information to help individuals and policy makers make prudent decisions (for example, increasing mask-wearing compliance and avoiding larger gatherings) that could help control the spread of SARS-CoV-2, particularly in hard-hit regions.},
author = {Chande, Aroon and Lee, Seolha and Harris, Mallory and Nguyen, Quan and Beckett, Stephen J. and Hilley, Troy and Andris, Clio and Weitz, Joshua S.},
doi = {10.1038/s41562-020-01000-9},
file = {:Users/vsivaram/Documents/papers/s41562-020-01000-9.pdf:pdf},
issn = {23973374},
journal = {Nature Human Behaviour},
mendeley-groups = {Opioid Risk/Public Health},
number = {12},
pages = {1313--1319},
pmid = {33168955},
publisher = {Springer US},
title = {Real-time, interactive website for {US}-county-level {COVID}-19 event risk assessment},
url = {http://dx.doi.org/10.1038/s41562-020-01000-9},
volume = {4},
year = {2020}
}

@article{Zhang2023,
abstract = {During the COVID-19 pandemic, a number of data visualizations were created to inform the public about the rapidly evolving crisis. Data dashboards, a form of information dissemination used during the pandemic, have facilitated this process by visualizing statistics regarding the number of COVID-19 cases over time. Prior work on COVID-19 visualizations has primarily focused on the design and evaluation of specific visualization systems from technology-centered perspectives. However, little is known about what occurs behind the scenes during the visualization creation processes, given the complex sociotechnical contexts in which they are embedded. Yet, such ecological knowledge is necessary to help characterize the nuances and trajectories of visualization design practices in the wild, as well as generate insights into how creators come to understand and approach visualization design on their own terms and for their own situated purposes. In this research, we conducted a qualitative interview study among dashboard creators from federal agencies, state health departments, mainstream news media outlets, and other organizations that created (often widely-used) COVID-19 dashboards to answer the following questions: how did visualization creators engage in COVID-19 dashboard design, and what tensions, conflicts, and challenges arose during this process? Our findings detail the trajectory of design practices - from creation to expansion, maintenance, and termination - that are shaped by the complex interplay between design goals, tools and technologies, labor, emerging crisis contexts, and public engagement. We particularly examined the tensions between designers and the general public involved in these processes. These conflicts, which often materialized due to a divergence between public demands and standing policies, centered around the type and amount of information to be visualized, how public perceptions shape and are shaped by visualization design, and the strategies utilized to deal with (potential) misinterpretations and misuse of visualizations. Our findings and lessons learned shed light on new ways of thinking in visualization design, focusing on the bundled activities that are invariably involved in human and nonhuman participation throughout the entire trajectory of design practice.},
archivePrefix = {arXiv},
arxivId = {2207.12829},
author = {Zhang, Yixuan and Sun, Yifan and Gaggiano, Joseph D. and Kumar, Neha and Andris, Clio and Parker, Andrea G.},
doi = {10.1109/TVCG.2022.3209493},
eprint = {2207.12829},
file = {:Users/vsivaram/Documents/papers/2207.12829.pdf:pdf},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {COVID-19,Design practices,crisis,dashboard,data visualization,general public,public health,qualitative research},
mendeley-groups = {Opioid Risk/Public Health},
number = {1},
pages = {1037--1047},
pmid = {36170401},
title = {Visualization Design Practices in a Crisis: {Behind} the Scenes with {COVID}-19 Dashboard Creators},
volume = {29},
year = {2023}
}

@article{Morgenstern2021,
abstract = {Background: Our objective was to determine the impacts of artificial intelligence (AI) on public health practice. Methods: We used a fundamental qualitative descriptive study design, enrolling 15 experts in public health and AI from June 2018 until July 2019 who worked in North America and Asia. We conducted in-depth semi-structured interviews, iteratively coded the resulting transcripts, and analyzed the results thematically. Results: We developed 137 codes, from which nine themes emerged. The themes included opportunities such as leveraging big data and improving interventions; barriers to adoption such as confusion regarding AI's applicability, limited capacity, and poor data quality; and risks such as propagation of bias, exacerbation of inequity, hype, and poor regulation. Conclusions: Experts are cautiously optimistic about AI's impacts on public health practice, particularly for improving disease surveillance. However, they perceived substantial barriers, such as a lack of available expertise, and risks, including inadequate regulation. Therefore, investment and research into AI for public health practice would likely be beneficial. However, increased access to high-quality data, research and education regarding the limitations of AI, and development of rigorous regulation are necessary to realize these benefits.},
author = {Morgenstern, Jason D. and Rosella, Laura C. and Daley, Mark J. and Goel, Vivek and Sch{\"{u}}nemann, Holger J. and Piggott, Thomas},
doi = {10.1186/s12889-020-10030-x},
file = {:Users/vsivaram/Documents/papers/s12889-020-10030-x.pdf:pdf},
isbn = {1288902010030},
issn = {14712458},
journal = {BMC Public Health},
keywords = {Big data,Community medicine,Epidemiology,Machine learning,Population health,Preventive medicine,Qualitative},
mendeley-groups = {Opioid Risk/Public Health},
number = {1},
pages = {1--14},
pmid = {33407254},
publisher = {BMC Public Health},
title = {“{AI}'s gonna have an impact on everything in society, so it has to have an impact on public health”: a fundamental qualitative descriptive study of the implications of artificial intelligence for public health},
volume = {21},
year = {2021}
}

@inproceedings{Sivaraman2023,
author = {Sivaraman, Venkatesh and Bukowski, Leigh A and Levin, Joel and Kahn, Jeremy M. and Perer, Adam},
title = {Ignore, Trust, or Negotiate: Understanding Clinician Acceptance of AI-Based Treatment Recommendations in Health Care},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581075},
doi = {10.1145/3544548.3581075},
abstract = {Artificial intelligence (AI) in healthcare has the potential to improve patient outcomes, but clinician acceptance remains a critical barrier. We developed a novel decision support interface that provides interpretable treatment recommendations for sepsis, a life-threatening condition in which decisional uncertainty is common, treatment practices vary widely, and poor outcomes can occur even with optimal decisions. This system formed the basis of a mixed-methods study in which 24 intensive care clinicians made AI-assisted decisions on real patient cases. We found that explanations generally increased confidence in the AI, but concordance with specific recommendations varied beyond the binary acceptance or rejection described in prior work. Although clinicians sometimes ignored or trusted the AI, they also often prioritized aspects of the recommendations to follow, reject, or delay in a process we term “negotiation.” These results reveal novel barriers to adoption of treatment-focused AI tools and suggest ways to better support differing clinician perspectives.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {754},
numpages = {18},
keywords = {healthcare, human-AI interaction, interpretability, visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@article{Yang2019,
abstract = {Clinical decision support tools (DST) promise improved healthcare outcomes by ofering data-driven insights. While efective in lab settings, almost all DSTs have failed in practice. Empirical research diagnosed poor contextual ft as the cause. This paper describes the design and feld evaluation of a radically new form of DST. It automatically generates slides for clinicians' decision meetings with subtly embedded machine prognostics. This design took inspiration from the notion of Unremarkable Computing, that by augmenting the users' routines technology/AI can have signifcant importance for the users yet remain unobtrusive. Our feld evaluation suggests clinicians are more likely to encounter and embrace such a DST. Drawing on their responses, we discuss the importance and intricacies of fnding the right level of unremarkableness in DST design, and share lessons learned in prototyping critical AI systems as a situated experience.},
archivePrefix = {arXiv},
arxivId = {1904.09612},
author = {Yang, Qian and Steinfeld, Aaron and Zimmerman, John},
doi = {10.1145/3290605.3300468},
eprint = {1904.09612},
file = {:Users/vsivaram/Documents/papers/1904.09612.pdf:pdf},
isbn = {9781450359702},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Decision support systems,Healthcare,User experience},
mendeley-groups = {Uncertainty Visualization/Adam's Suggestions,Child Welfare,Child Welfare/Human-AI partnerships,AI Clinician/Design Mini,AI Clinician/Healthcare,AI Clinician/Clinical Perspectives},
title = {Unremarkable {AI}: {Fitting} intelligent decision support into critical, clinical decision-making processes},
year = {2019}
}

@techreport{cdc2021pdmp,
	title = {Leveraging Prescription Drug Monitoring Program ({PDMP}) Data in Overdose Prevention and Response},
	language = {en},
	author = {Centers for Disease Control {and} Prevention},
	month = mar,
	year = {2021},
	file = {Leveraging Prescription Drug Monitoring Program (P.pdf:/Users/vsivaram/Zotero/storage/3NHJB3ND/Leveraging Prescription Drug Monitoring Program (P.pdf:application/pdf},
}

@techreport{pdmp2014mandating,
	title = {Mandating {PDMP} Participation by Medical Providers: {Current} Status and Experience in Selected States},
	language = {en},
	author = {Prescription Drug Monitoring Program Center of Excellence at Brandeis},
	month = feb,
	year = {2014},
	file = {Winters - Mandating PDMP Participation by Medical Providers.pdf:/Users/vsivaram/Zotero/storage/UXCZUN45/Winters - Mandating PDMP Participation by Medical Providers.pdf:application/pdf},
}

@article{albert2011lazarus,
	title = {Project {Lazarus}: {Community}-Based Overdose Prevention in Rural {North} {Carolina}},
	volume = {12},
	issn = {1526-2375, 1526-4637},
	shorttitle = {Project {Lazarus}},
	url = {https://academic.oup.com/painmedicine/article-lookup/doi/10.1111/j.1526-4637.2011.01128.x},
	doi = {10.1111/j.1526-4637.2011.01128.x},
	abstract = {Background. In response to some of the highest drug overdose death rates in the country, Project Lazarus developed a community-based overdose prevention program in Western North Carolina. The Wilkes County unintentional poisoning mortality rate was quadruple that of the state’s in 2009 and due almost exclusively to prescription opioid pain relievers, including fentanyl, hydrocodone, methadone, and oxycodone. The program is ongoing.},
	language = {en},
	number = {suppl 2},
	urldate = {2023-12-07},
	journal = {Pain Medicine},
	author = {Albert, Su and Brason, Fred W. and Sanford, Catherine K. and Dasgupta, Nabarun and Graham, Jim and Lovette, Beth},
	month = jun,
	year = {2011},
	pages = {S77--S85},
	file = {Albert et al. - 2011 - Project Lazarus Community-Based Overdose Preventi.pdf:/Users/vsivaram/Zotero/storage/NA6X4NLL/Albert et al. - 2011 - Project Lazarus Community-Based Overdose Preventi.pdf:application/pdf},
}


@article{zakkar_interactive_2017,
	title = {Interactive visualization of public health indicators to support policymaking: {An} exploratory study},
	volume = {9},
	issn = {1947-2579},
	shorttitle = {Interactive visualization of public health indicators to support policymaking},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5630277/},
	doi = {10.5210/ojphi.v9i2.8000},
	abstract = {The purpose of this study is to examine the use of interactive visualizations
to represent data/information related to social determinants of health and
public health indicators, and to investigate the benefits of such
visualizations for health policymaking. Methods: The study developed a
prototype for an online interactive visualization tool that represents the
social determinants of health. The study participants explored and used the
tool. The tool was evaluated using the informal user experience evaluation
method. This method involves the prospective users of a tool to use and play
with it and their feedback to be collected through interviews. Results:
Using visualizations to represent and interact with health indicators has
advantages over traditional representation techniques that do not allow
users to interact with the information. Communicating healthcare indicators
to policymakers is a complex task because of the complexity of the
indicators, diversity of audiences, and different audience needs. This
complexity can lead to information misinterpretation, which occurs when
users of the health data ignore or do not know why, where, and how the data
has been produced, or where and how it can be used. Conclusions: Public
health policymaking is a complex process, and data is only one element among
others needed in this complex process. Researchers and healthcare
organizations should conduct a strategic evaluation to assess the usability
of interactive visualizations and decision support tools before investing in
these tools. Such evaluation should take into consideration the cost, ease
of use, learnability, and efficiency of those tools, and the factors that
influence policymaking.},
	number = {2},
	urldate = {2023-12-04},
	journal = {Online Journal of Public Health Informatics},
	author = {Zakkar, Moutasem and Sedig, Kamran},
	month = sep,
	year = {2017},
	pmid = {29026455},
	pmcid = {PMC5630277},
	pages = {e190},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/KZ4YWUWP/Zakkar and Sedig - 2017 - Interactive visualization of public health indicat.pdf:application/pdf},
}

@article{carroll_visualization_2014,
	title = {Visualization and analytics tools for infectious disease epidemiology: {A} systematic review},
	volume = {51},
	issn = {15320464},
	shorttitle = {Visualization and analytics tools for infectious disease epidemiology},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046414000914},
	doi = {10.1016/j.jbi.2014.04.006},
	abstract = {Background: A myriad of new tools and algorithms have been developed to help public health professionals analyze and visualize the complex data used in infectious disease control. To better understand approaches to meet these users’ information needs, we conducted a systematic literature review focused on the landscape of infectious disease visualization tools for public health professionals, with a special emphasis on geographic information systems (GIS), molecular epidemiology, and social network analysis. The objectives of this review are to: (1) identify public health user needs and preferences for infectious disease information visualization tools; (2) identify existing infectious disease information visualization tools and characterize their architecture and features; (3) identify commonalities among approaches applied to different data types; and (4) describe tool usability evaluation efforts and barriers to the adoption of such tools.},
	language = {en},
	urldate = {2023-12-04},
	journal = {Journal of Biomedical Informatics},
	author = {Carroll, Lauren N. and Au, Alan P. and Detwiler, Landon Todd and Fu, Tsung-chieh and Painter, Ian S. and Abernethy, Neil F.},
	month = oct,
	year = {2014},
	pages = {287--298},
	file = {Carroll et al. - 2014 - Visualization and analytics tools for infectious d.pdf:/Users/vsivaram/Zotero/storage/9GCU68CW/Carroll et al. - 2014 - Visualization and analytics tools for infectious d.pdf:application/pdf},
}

@article{grgic-hlaca_human_2019,
title = {Human Decision Making with Machine Assistance: {An} Experiment on Bailing and Jailing},
	volume = {3},
	issn = {2573-0142},
	shorttitle = {Human {Decision} {Making} with {Machine} {Assistance}},
	url = {https://dl.acm.org/doi/10.1145/3359280},
	doi = {10.1145/3359280},
	abstract = {Much of political debate focuses on the concern that machines might take over. Yet in many domains it is much more plausible that the ultimate choice and responsibility remain with a human decision-maker, but that she is provided with machine advice. A quintessential illustration is the decision of a judge to bail or jail a defendant. In multiple jurisdictions in the US, judges have access to a machine prediction about a defendant's recidivism risk. In our study, we explore how receiving machine advice influences people's bail decisions. We run a vignette experiment with laypersons whom we test on a subsample of cases from the database of this prediction tool. In study 1, we ask them to predict whether defendants will recidivate before tried, and manipulate whether they have access to machine advice. We find that receiving machine advice has a small effect, which is biased in the direction of predicting no recidivism. In the field, human decision makers sometimes have a chance, after the fact, to learn whether the machine has given good advice. In study 2, after each trial we inform participants of ground truth. This does not make it more likely that they follow the advice, despite the fact that the machine is (on average) slightly more accurate than real judges. This also holds if initially the advice is mostly correct, or if it initially is mostly to predict (no) recidivism. Real judges know that their decisions affect defendants' lives. They may also be concerned about reelection or promotion. Hence a lot is at stake. In study 3 we emulate high stakes by giving participants a financial incentive. An incentive to find the ground truth, or to avoid false positive or false negatives, does not make participants more sensitive to machine advice. But an incentive to follow the advice is effective.},
	language = {en},
	number = {CSCW},
	urldate = {2023-12-05},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Grgić-Hlača, Nina and Engel, Christoph and Gummadi, Krishna P.},
	month = nov,
	year = {2019},
	pages = {1--25},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/6UMZ6ML6/Grgić-Hlača et al. - 2019 - Human Decision Making with Machine Assistance An .pdf:application/pdf},
}

@article{ammitzboll_flugge_street-level_2021,
	title = {Street-Level Algorithms and AI in Bureaucratic Decision-Making: {A} Caseworker Perspective},
	volume = {5},
	issn = {2573-0142},
	shorttitle = {Street-{Level} {Algorithms} and {AI} in {Bureaucratic} {Decision}-{Making}},
	url = {https://dl.acm.org/doi/10.1145/3449114},
	doi = {10.1145/3449114},
	abstract = {Studies of algorithmic decision-making in Computer-Supported Cooperative Work (CSCW) and related fields of research increasingly recognize an analogy between AI and bureaucracies. We elaborate this link with an empirical study of AI in the context of decision-making in a street-level bureaucracy: job placement. The study examines caseworkers' perspectives on the use of AI, and contributes to an understanding of bureaucratic decision-making, with implications for integrating AI in caseworker systems. We report findings from a participatory workshop on AI with 35 caseworkers from different types of public services, followed up by interviews with five caseworkers specializing in job placement. The paper contributes an understanding of caseworkers' collaboration around documentation as a key aspect of bureaucratic decision-making practices. The collaborative aspects of casework are important to show because they are subject to process descriptions making case documentation prone for an individually focused AI with consequences for the future of how casework develops as a practice. Examining the collaborative aspects of caseworkers' documentation practices in the context of AI and (potentially) automation, our data show that caseworkers perceive AI as valuable when it can support their work towards management, (strengthen their cause, if a case requires extra resources), and towards unemployed individuals (strengthen their cause in relation to the individual's case when deciding on, and assigning a specific job placement program). We end by discussing steps to support cooperative aspects in AI decision-support systems that are increasingly implemented into the bureaucratic context of public services.},
	language = {en},
	number = {CSCW1},
	urldate = {2023-12-05},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Ammitzbøll Flügge, Asbjørn and Hildebrandt, Thomas and Møller, Naja Holten},
	month = apr,
	year = {2021},
	pages = {1--23},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/9IE45ZVH/Ammitzbøll Flügge et al. - 2021 - Street-Level Algorithms and AI in Bureaucratic Dec.pdf:application/pdf},
}

@article{rask_nielsen_data_2022,
	title = {Data as a Lens for Understanding what Constitutes Credibility in Asylum Decision-making},
	volume = {6},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3492825},
	doi = {10.1145/3492825},
	abstract = {In asylum decision-making, legal authorities rely on the criterion "credibility" as a measure for determining whether an individual has a legitimate asylum claim; that is, whether they have a well-founded fear of persecution upon returning to their country of origin. Nation states, international institutions, and NGOs increasingly seek to leverage data-driven technologies to support such decisions, deploying processes of data cleaning, contestation, and interpretation. We qualitatively analyzed 50 asylum cases to understand how the asylum decision-making process in Denmark leverages data to configure individuals as credible (or not). In this context, data can vary from the applicant's testimony to data acquired on the applicant from registers and alphanumerical data. Our findings suggest that legal authorities assess credibility through a largely discretionary practice, establishing certainty by ruling out divergence or contradiction between the different forms of data and documentation involved in an asylum case. As with other reclassification processes [following Bowker and Star 1999], credibility is an ambiguous prototypical concept for decision-makers to attempt certainty, especially important to consider in the design of data-driven technologies where stakeholders have differential power.},
	language = {en},
	number = {GROUP},
	urldate = {2023-12-05},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Rask Nielsen, Trine and Holten Møller, Naja},
	month = jan,
	year = {2022},
	pages = {1--23},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/EWLLQK7T/Rask Nielsen and Holten Møller - 2022 - Data as a Lens for Understanding what Constitutes .pdf:application/pdf},
}

@article{green_algorithmic_2021,
	title = {Algorithmic Risk Assessments Can Alter Human Decision-Making Processes in High-Stakes Government Contexts},
	volume = {5},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3479562},
	doi = {10.1145/3479562},
	abstract = {Governments are increasingly turning to algorithmic risk assessments when making important decisions, such as whether to release criminal defendants before trial. Policymakers assert that providing public servants with algorithmic advice will improve human risk predictions and thereby lead to better (e.g., fairer) decisions. Yet because many policy decisions require balancing risk-reduction with competing goals, improving the accuracy of predictions may not necessarily improve the quality of decisions. If risk assessments make people more attentive to reducing risk at the expense of other values, these algorithms would diminish the implementation of public policy even as they lead to more accurate predictions. Through an experiment with 2,140 lay participants simulating two high-stakes government contexts, we provide the first direct evidence that risk assessments can systematically alter how people factor risk into their decisions. These shifts counteracted the potential benefits of improved prediction accuracy. In the pretrial setting of our experiment, the risk assessment made participants more sensitive to increases in perceived risk; this shift increased the racial disparity in pretrial detention by 1.9\%. In the government loans setting of our experiment, the risk assessment made participants more risk-averse; this shift reduced government aid by 8.3\%. These results demonstrate the potential limits and harms of attempts to improve public policy by incorporating predictive algorithms into multifaceted policy decisions. If these observed behaviors occur in practice, presenting risk assessments to public servants would generate unexpected and unjust shifts in public policy without being subject to democratic deliberation or oversight.},
	language = en,
	number = {CSCW2},
	urldate = {2023-12-05},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Green, Ben and Chen, Yiling},
	month = oct,
	year = {2021},
	pages = {1--33},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/ZCPJDM3A/Green and Chen - 2021 - Algorithmic Risk Assessments Can Alter Human Decis.pdf:application/pdf},
}

@article{benjamin_explanation_2022,
	title = {Explanation Strategies as an Empirical-Analytical Lens for Socio-Technical Contextualization of Machine Learning Interpretability},
	volume = {6},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3492858},
	doi = {10.1145/3492858},
	abstract = {During a research project in which we developed a machine learning (ML) driven visualization system for non-ML experts, we reflected on interpretability research in ML, computer-supported collaborative work and human-computer interaction. We found that while there are manifold technical approaches, these often focus on ML experts and are evaluated in decontextualized empirical studies. We hypothesized that participatory design research may support the understanding of stakeholders' situated sense-making in our project, yet, found guidance regarding ML interpretability inexhaustive. Building on philosophy of technology, we formulated explanation strategies as an empirical-analytical lens explicating how technical explanations mediate the contextual preferences concerning people's interpretations. In this paper, we contribute a report of our proof-of-concept use of explanation strategies to analyze a co-design workshop with non-ML experts, methodological implications for participatory design research, design implications for explanations for non-ML experts and suggest further investigation of technological mediation theories in the ML interpretability space.},
	language = {en},
	number = {GROUP},
	urldate = {2023-12-05},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Benjamin, Jesse Josua and Kinkeldey, Christoph and Müller-Birn, Claudia and Korjakow, Tim and Herbst, Eva-Maria},
	month = jan,
	year = {2022},
	pages = {1--25},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/K7YJA2UD/Benjamin et al. - 2022 - Explanation Strategies as an Empirical-Analytical .pdf:application/pdf},
}

@inproceedings{yildirim_how_2022,
	address = {New Orleans LA USA},
	title = {How Experienced Designers of Enterprise Applications Engage {AI} as a Design Material},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517491},
	doi = {10.1145/3491102.3517491},
	language = {en},
	urldate = {2023-12-06},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yildirim, Nur and Kass, Alex and Tung, Teresa and Upton, Connor and Costello, Donnacha and Giusti, Robert and Lacin, Sinem and Lovic, Sara and O'Neill, James M and Meehan, Rudi O'Reilly and Ó Loideáin, Eoin and Pini, Azzurra and Corcoran, Medb and Hayes, Jeremiah and Cahalane, Diarmuid J and Shivhare, Gaurav and Castoro, Luigi and Caruso, Giovanni and Oh, Changhoon and McCann, James and Forlizzi, Jodi and Zimmerman, John},
	month = apr,
	year = {2022},
	pages = {1--13},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/Y6EDU6TE/Yildirim et al. - 2022 - How Experienced Designers of Enterprise Applicatio.pdf:application/pdf},
}

@article{hurley_expert_1986,
	title = {Expert Systems as Decision Aids for Public Managers: {An} Assessment of the Technology and Prototyping as a Design Strategy},
	volume = {46},
	issn = {0033-3352},
	shorttitle = {Expert {Systems} as {Decision} {Aids} for {Public} {Managers}},
	url = {https://www.jstor.org/stable/975578},
	doi = {10.2307/975578},
	abstract = {This paper reports on research assessing the applicability of artificial intelligence technology in providing decision support to public managers. A prototyping design strategy was used with microcomputers to construct decision aids for operating managers (i. e., desk top and street level bureaucrats) in personnel administration and emergency management. A philosophical view of the use of information technology in extending cognitive processes is presented. This includes the role of artificial intelligence as employed in expert systems. It is observed that the accelerating rate of technological development permits heretofore separate functions of the builder, designer, expert, and user to be embodied in one experienced person, thus permitting prototyping to become the design strategy for building decision support systems employing AI technology.},
	urldate = {2023-12-06},
	journal = {Public Administration Review},
	author = {Hurley, Michael W. and Wallace, William A.},
	year = {1986},
	note = {Publisher: [American Society for Public Administration, Wiley]},
	pages = {563--571},
	file = {JSTOR Full Text PDF:/Users/vsivaram/Zotero/storage/FMU2TWVW/Hurley and Wallace - 1986 - Expert Systems as Decision Aids for Public Manager.pdf:application/pdf},
}

@inproceedings{subramonyam_towards_2021,
	address = {Virtual Event USA},
	title = {Towards A Process Model for Co-Creating {AI} Experiences}},
	isbn = {978-1-4503-8476-6},
	url = {https://dl.acm.org/doi/10.1145/3461778.3462012},
	doi = {10.1145/3461778.3462012},
	language = {en},
	urldate = {2023-12-07},
	booktitle = {Designing {Interactive} {Systems} {Conference} 2021},
	publisher = {ACM},
	author = {Subramonyam, Hariharan and Seifert, Colleen and Adar, Eytan},
	month = jun,
	year = {2021},
	pages = {1529--1543},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/LKMG92PT/Subramonyam et al. - 2021 - Towards A Process Model for Co-Creating AI Experie.pdf:application/pdf},
}


@inproceedings{subramonyam_solving_2022,
	address = {New Orleans LA USA},
	title = {Solving Separation-of-Concerns Problems in Collaborative Design of Human-{AI} Systems through Leaky Abstractions},
	isbn = {978-1-4503-9157-3},
	url = {https://dl.acm.org/doi/10.1145/3491102.3517537},
	doi = {10.1145/3491102.3517537},
	language = {en},
	urldate = {2024-07-01},
	booktitle = {{CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Subramonyam, Hariharan and Im, Jane and Seifert, Colleen and Adar, Eytan},
	month = apr,
	year = {2022},
	pages = {1--21},
}


@inproceedings{tal_target_2023,
	location = {Montr\'{e}al QC Canada},
	title = {Target specification bias, counterfactual prediction, and algorithmic fairness in healthcare},
	isbn = {9798400702310},
	url = {https://dl.acm.org/doi/10.1145/3600211.3604678},
	doi = {10.1145/3600211.3604678},
	language = {en},
	urldate = {2024-02-26},
	booktitle = {Proceedings of the 2023 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
    series = {{AIES} '23},
	author = {Tal, Eran},
	month = aug,
	year = {2023},
	pages = {312--321},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/64PLWCR4/Tal - 2023 - Target specification bias, counterfactual predicti.pdf:application/pdf},
}


@article{di_martino_explainable_2023,
	title = {Explainable {AI} for clinical and remote health applications: a survey on tabular and time series data},
	volume = {56},
	issn = {1573-7462},
	shorttitle = {Explainable {AI} for clinical and remote health applications},
	url = {https://doi.org/10.1007/s10462-022-10304-3},
	doi = {10.1007/s10462-022-10304-3},
	abstract = {Nowadays Artificial Intelligence (AI) has become a fundamental component of healthcare applications, both clinical and remote, but the best performing AI systems are often too complex to be self-explaining. Explainable AI (XAI) techniques are defined to unveil the reasoning behind the system’s predictions and decisions, and they become even more critical when dealing with sensitive and personal health data. It is worth noting that XAI has not gathered the same attention across different research areas and data types, especially in healthcare. In particular, many clinical and remote health applications are based on tabular and time series data, respectively, and XAI is not commonly analysed on these data types, while computer vision and Natural Language Processing (NLP) are the reference applications. To provide an overview of XAI methods that are most suitable for tabular and time series data in the healthcare domain, this paper provides a review of the literature in the last 5 years, illustrating the type of generated explanations and the efforts provided to evaluate their relevance and quality. Specifically, we identify clinical validation, consistency assessment, objective and standardised quality evaluation, and human-centered quality assessment as key features to ensure effective explanations for the end users. Finally, we highlight the main research challenges in the field as well as the limitations of existing XAI methods.},
	language = {en},
	number = {6},
	urldate = {2024-07-05},
	journal = {Artificial Intelligence Review},
	author = {Di Martino, Flavio and Delmastro, Franca},
	month = jun,
	year = {2023},
	keywords = {Clinical DSS, EHR, Explainable AI, Health, Remote patient monitoring, Time series},
	pages = {5261--5315},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/E47QZJDT/Di Martino and Delmastro - 2023 - Explainable AI for clinical and remote health appl.pdf:application/pdf},
}

@article{Cai2019,
	title = {“{Hello} {Ai}”: {Uncovering} the onboarding needs of medical practitioners for human–{AI} collaborative decision-making},
	volume = {3},
	issn = {25730142},
	doi = {10.1145/3359206},
	abstract = {Although rapid advances in machine learning have made it increasingly applicable to expert decision-making, the delivery of accurate algorithmic predictions alone is insufficient for effective human–AI collaboration. In this work, we investigate the key types of information medical experts desire when they are first introduced to a diagnostic AI assistant. In a qualitative lab study, we interviewed 21 pathologists before, during, and after being presented deep neural network (DNN) predictions for prostate cancer diagnosis, to learn the types of information that they desired about the AI assistant. Our findings reveal that, far beyond understanding the local, case-specific reasoning behind any model decision, clinicians desired upfront information about basic, global properties of the model, such as its known strengths and limitations, its subjective point-of-view, and its overall design objective—what it’s designed to be optimized for. Participants compared these information needs to the collaborative mental models they develop of their medical colleagues when seeking a second opinion: the medical perspectives and standards that those colleagues embody, and the compatibility of those perspectives with their own diagnostic patterns. These findings broaden and enrich discussions surrounding AI transparency for collaborative decision-making, providing a richer understanding of what experts find important in their introduction to AI assistants before integrating them into routine practice.},
	number = {CSCW},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Cai, Carrie J. and Winter, Samantha and Steiner, David and Wilcox, Lauren and Terry, Michael},
	year = {2019},
	keywords = {Machine learning, Clinical health, Human-AI interaction},
	file = {PDF:/Users/vsivaram/Zotero/storage/WVHEUJQ7/3359206.pdf:application/pdf},
}

@article{gu_lessons_2020,
	title = {Lessons Learned from Designing an {AI}-Enabled Diagnosis Tool for Pathologists},
	volume = {5},
	url = {http://arxiv.org/abs/2006.12695%0Ahttp://dx.doi.org/10.1145/3449084},
	doi = {10.1145/3449084},
	abstract = {Despite the promises of data-driven artificial intelligence (AI), little is known about how we can bridge the gulf between traditional physician-driven diagnosis and a plausible future of medicine automated by AI. Specifically, how can we involve AI usefully in physicians' diagnosis workflow given that most AI is still nascent and error-prone (e.g., in digital pathology)? To explore this question, we first propose a series of collaborative techniques to engage human pathologists with AI given AI's capabilities and limitations, based on which we prototype Impetus - a tool where an AI takes various degrees of initiatives to provide various forms of assistance to a pathologist in detecting tumors from histological slides. We summarize observations and lessons learned from a study with eight pathologists and discuss recommendations for future work on human-centered medical AI systems.},
	number = {CSCW1},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Gu, Hongyan and Huang, Jingbin and Hung, Lauren and Chen, Xiang 'Anthony'},
	year = {2020},
	keywords = {Digital pathology, Human-AI collaboration, Human-centered AI, Medical AI},
	file = {PDF:/Users/vsivaram/Zotero/storage/GN5XTXYZ/2006.12695.pdf:application/pdf},
}

@article{Lee2020,
	title = {Co-Design and Evaluation of an Intelligent Decision Support System for Stroke Rehabilitation Assessment},
	volume = {4},
	issn = {25730142},
	doi = {10.1145/3415227},
	abstract = {Clinical decision support systems have the potential to improve work flows of experts in practice (e.g. Therapist's evidence-based rehabilitation assessment). However, the adoption of these systems is challenging, and the gains of these systems have not fully demonstrated yet. In this paper, we identified the needs of therapists to assess patient's functional abilities (e.g. alternative perspectives with quantitative information on patient's exercise motions). As a result, we co-designed and developed an intelligent decision support system that automatically identifies salient features of assessment using reinforcement learning to assess the quality of motion and generate patient-specific analysis. We evaluated this system with seven therapists using the dataset from 15 patients performing three exercises. The results show that therapists have higher usage intent on our system than a traditional system without patient-specific analysis (\$p {\textless} 0.05\$). While presenting richer information (\$p {\textless} 0.10\$), our system significantly reduces therapists' effort on assessment (\$p {\textless} 0.10\$) and improves their agreement on assessment from 0.66 to 0.71 F1-scores (\$p {\textless} 0.01\$). This work discusses the importance of human centered design and development of a machine learning-based decision support system that presents contextually relevant information and salient explanations on its prediction for better adoption in practice.},
	number = {CSCW2},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lee, Min Hun and Siewiorek, Daniel P. and Smailagic, Asim and Bernardino, Alexandre and Bermúdez I Badia, Sergi},
	month = oct,
	year = {2020},
	note = {Publisher: Association for Computing Machinery},
	keywords = {machine learning, explainable ai, human-ai interaction, decision support systems, stroke rehabilitation assessment},
	file = {PDF:/Users/vsivaram/Zotero/storage/K2RX8QD8/3415227.pdf:application/pdf},
}


@article{brownson_building_2018,
	title = {Building Capacity for Evidence-Based Public Health: Reconciling the Pulls of Practice and the Push of Research},
	volume = {39},
	issn = {0163-7525, 1545-2093},
	shorttitle = {Building {Capacity} for {Evidence}-{Based} {Public} {Health}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-publhealth-040617-014746},
	doi = {10.1146/annurev-publhealth-040617-014746},
	abstract = {Timely implementation of principles of evidence-based public health (EBPH) is critical for bridging the gap between discovery of new knowledge and its application. Public health organizations need sufﬁcient capacity (the availability of resources, structures, and workforce to plan, deliver, and evaluate the preventive dose of an evidence-based intervention) to move science to practice. We review principles of EBPH, the importance of capacity building to advance evidence-based approaches, promising approaches for capacity building, and future areas for research and practice. Although there is general agreement among practitioners and scientists on the importance of EBPH, there is less clarity on the deﬁnition of evidence, how to ﬁnd it, and how, when, and where to use it. Capacity for EBPH is needed among both individuals and organizations. Capacity can be strengthened via training, use of tools, technical assistance, assessment and feedback, peer networking, and incentives. Modest investments in EBPH capacity building will foster more effective public health practice.},
	language = {en},
	number = {1},
	urldate = {2023-12-09},
	journal = {Annual Review of Public Health},
	author = {Brownson, Ross C. and Fielding, Jonathan E. and Green, Lawrence W.},
	month = apr,
	year = {2018},
	pages = {27--53},
	file = {Brownson et al. - 2018 - Building Capacity for Evidence-Based Public Health.pdf:/Users/vsivaram/Zotero/storage/ZSV5H4WM/Brownson et al. - 2018 - Building Capacity for Evidence-Based Public Health.pdf:application/pdf},
}


@article{yang_re-examining_2020,
	title = {Re-examining Whether, Why, and How Human-{AI} Interaction Is Uniquely Difficult to Design},
	doi = {10.1145/3313831.3376301},
	abstract = {Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Yang, Qian and Steinfeld, Aaron and Rosé, Carolyn and Zimmerman, John},
	year = {2020},
	keywords = {artificial intelligence, prototyping, sketching, user experience},
	pages = {1--13},
	file = {PDF:/Users/vsivaram/Zotero/storage/QDIPIF7K/3313831.3376301.pdf:application/pdf},
}


@incollection{lechner_towards_2014,
	address = {Cham},
	title = {Towards Public Health Dashboard Design Guidelines},
	volume = {8527},
	isbn = {978-3-319-07292-0 978-3-319-07293-7},
	url = {http://link.springer.com/10.1007/978-3-319-07293-7_5},
	abstract = {Ongoing surveillance of disease outbreaks is important for public health officials, who to need consult with laboratory technicians in identifying specimen and coordinate care for affected populations. One way for public health officials to monitor possible outbreaks is through digital dashboards of summarized public health data. This study examines best practices for designing public health dashboards and proposes an optimized interface for an emergency response system for state public health laboratories. The practical nature of this research shows how general dashboard guidelines can be used to design a specialized dashboard for a public health emergency response information system. Through our analysis and design process, we identified two new guidelines for consideration.},
	language = {en},
	urldate = {2023-11-20},
	booktitle = {{HCI} in {Business}},
	publisher = {Springer International Publishing},
	author = {Lechner, Bettina and Fruhling, Ann},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Kobsa, Alfred and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Terzopoulos, Demetri and Tygar, Doug and Weikum, Gerhard and Nah, Fiona Fui-Hoon},
	year = {2014},
	doi = {10.1007/978-3-319-07293-7_5},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {49--59},
	file = {Lechner and Fruhling - 2014 - Towards Public Health Dashboard Design Guidelines.pdf:/Users/vsivaram/Zotero/storage/IVXW2TX7/Lechner and Fruhling - 2014 - Towards Public Health Dashboard Design Guidelines.pdf:application/pdf},
}


@book{few_information_2003,
	title = {Information Dashboard Design},
	author = {Few, Stephen},
	year = {2003},
publisher = {O'Reilly Media}
}


@article{sun_data_2023,
	title = {Data Work of Frontline Care Workers: {Practices}, Problems, and Opportunities in the Context of Data-Driven Long-Term Care},
	volume = {7},
	issn = {2573-0142},
	shorttitle = {Data {Work} of {Frontline} {Care} {Workers}},
	url = {https://dl.acm.org/doi/10.1145/3579475},
	doi = {10.1145/3579475},
	abstract = {Using data and data technologies to support healthcare has drawn significant attention recently. While CSCW and HCI have largely celebrated the tremendous promise of 'data-driven healthcare' in reforming the healthcare sector, this paper reveals 'labor-driven reality' of this promised data-driven future. Drawing from a qualitative study in a real-world data-driven long-term care (LTC) facility in China, we demonstrate how data-driven technologies work in practice, and especially how frontline workers, as the crux of this data-driven configuration, conduct a tremendous amount of "data work" to make data-drivenness work. This data work, we argue, goes beyond the "clerical work" and functions as a labor of maintenance, articulation, and repair, that both guarantees data technologies' functionalities and acts as an interface between stakeholders. We conclude by discussing the practices, problems and opportunities of this data work in a boarder socio-cultural context.},
	language = {en},
	number = {CSCW1},
	urldate = {2023-12-13},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Sun, Yuling and Ma, Xiaojuan and Lindtner, Silvia and He, Liang},
	month = apr,
	year = {2023},
	pages = {1--28},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/KLFBJRJ3/Sun et al. - 2023 - Data Work of Frontline Care Workers Practices, Pr.pdf:application/pdf},
}

@article{eardley_explanation_2023,
	title = {Explanation before Adoption: {Supporting} Informed Consent for Complex Machine Learning and {IoT} Health Platforms},
	volume = {7},
	issn = {2573-0142},
	shorttitle = {Explanation before {Adoption}},
	url = {https://dl.acm.org/doi/10.1145/3579482},
	doi = {10.1145/3579482},
	abstract = {Explaining health technology platforms to non-technical members of the public is an important part of the process of informed consent. Complex technology platforms that deal with safety-critical areas are particularly challenging, often operating within private domains (e.g. health services within the home) and used by individuals with various understandings of hardware, software, and algorithmic design. Through two studies, the first an interview and the second an observational study, we questioned how experts (e.g. those who designed, built, and installed a technology platform) supported provision of informed consent by participants. We identify a wide range of tools, techniques, and adaptations used by experts to explain the complex SPHERE sensor-based home health platform, provide implications for the design of tools to aid explanations, suggest opportunities for interactive explanations, present the range of information needed, and indicate future research possibilities in communicating technology platforms.},
	language = {en},
	number = {CSCW1},
	urldate = {2023-12-13},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Eardley, Rachel and Tonkin, Emma L. and Soubutts, Ewan and Ayobi, Amid and Tourte, Gregory J. L. and Gooberman-Hill, Rachael and Craddock, Ian and O'Kane, Aisling Ann},
	month = apr,
	year = {2023},
	pages = {1--25},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/LZEJT5YC/Eardley et al. - 2023 - Explanation before Adoption Supporting Informed C.pdf:application/pdf},
}

@article{lee_understanding_2023,
	title = {Understanding the Effect of Counterfactual Explanations on Trust and Reliance on {AI} for Human-{AI} Collaborative Clinical Decision Making},
	volume = {7},
	issn = {2573-0142},
	url = {https://dl.acm.org/doi/10.1145/3610218},
	doi = {10.1145/3610218},
	abstract = {Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when 'right' AI outputs are presented. While both therapists and laypersons over-relied on 'wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on 'wrong' AI outputs by 21\% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on 'wrong' AI outputs and implications for improving human-AI collaborative decision-making.},
	language = {en},
	number = {CSCW2},
	urldate = {2023-12-13},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Lee, Min Hun and Chew, Chong Jun},
	month = sep,
	year = {2023},
	pages = {1--22},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/SNALY376/Lee and Chew - 2023 - Understanding the Effect of Counterfactual Explana.pdf:application/pdf},
}


@article{obermeyer_dissecting_2019,
	title = {Dissecting racial bias in an algorithm used to manage the health of populations},
	volume = {366},
	language = {en},
	number = {6464},
	journal = {Science},
	author = {Obermeyer, Ziad and Powers, Brian and Vogeli, Christine and Mullainathan, Sendhil},
	year = {2019},
	pages = {447--453},
	file = {Obermeyer et al. - 2019 - Dissecting racial bias in an algorithm used to man.pdf:/Users/vsivaram/Zotero/storage/2BG6NKMM/Obermeyer et al. - 2019 - Dissecting racial bias in an algorithm used to man.pdf:application/pdf},
}

@article{morrison_impact_2023,
author = {Morrison, Katelyn and Spitzer, Philipp and Turri, Violet and Feng, Michelle and K\"{u}hl, Niklas and Perer, Adam},
title = {The Impact of Imperfect XAI on Human-AI Decision-Making},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3641022},
doi = {10.1145/3641022},
abstract = {Explainability techniques are rapidly being developed to improve human-AI decision-making across various cooperative work settings. Consequently, previous research has evaluated how decision-makers collaborate with imperfect AI by investigating appropriate reliance and task performance with the aim of designing more human-centered computer-supported collaborative tools. Several human-centered explainable AI (XAI) techniques have been proposed in hopes of improving decision-makers' collaboration with AI; however, these techniques are grounded in findings from previous studies that primarily focus on the impact of incorrect AI advice. Few studies acknowledge the possibility of the explanations being incorrect even if the AI advice is correct. Thus, it is crucial to understand how imperfect XAI affects human-AI decision-making. In this work, we contribute a robust, mixed-methods user study with 136 participants to evaluate how incorrect explanations influence humans' decision-making behavior in a bird species identification task, taking into account their level of expertise and an explanation's level of assertiveness. Our findings reveal the influence of imperfect XAI and humans' level of expertise on their reliance on AI and human-AI team performance. We also discuss how explanations can deceive decision-makers during human-AI collaboration. Hence, we shed light on the impacts of imperfect XAI in the field of computer-supported cooperative work and provide guidelines for designers of human-AI collaboration systems.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {183},
numpages = {39},
keywords = {explainable AI, explainable AI for computer vision, human-AI collaboration}
}


@misc{world_health_organization_opioid_2023,
	title = {Opioid overdose},
	url = {https://www.who.int/news-room/fact-sheets/detail/opioid-overdose},
	abstract = {The term “opioids” includes compounds that are extracted from the poppy seed as well as semisynthetic and synthetic compounds that can interact with opioid receptors in the brain.},
	language = {en},
	urldate = {2024-01-05},
	author = {World Health Organization},
	year = {2023},
	file = {Snapshot:/Users/vsivaram/Zotero/storage/DMA6264M/opioid-overdose.html:text/html},
}


@inproceedings{alkhatib_street-level_2019,
	title = {Street-Level Algorithms: {A} Theory at the Gaps Between Policy and Decisions},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Street-{Level} {Algorithms}},
	url = {https://doi.org/10.1145/3290605.3300760},
	doi = {10.1145/3290605.3300760},
	abstract = {Errors and biases are earning algorithms increasingly malignant reputations in society. A central challenge is that algorithms must bridge the gap between high-level policy and on-the-ground decisions, making inferences in novel situations where the policy or training data do not readily apply. In this paper, we draw on the theory of street-level bureaucracies, how human bureaucrats such as police and judges interpret policy to make on-the-ground decisions. We present by analogy a theory of street-level algorithms, the algorithms that bridge the gaps between policy and decisions about people in a socio-technical system. We argue that unlike street-level bureaucrats, who reflexively refine their decision criteria as they reason through a novel situation, street-level algorithms at best refine their criteria only after the decision is made. This loop-and-a-half delay results in illogical decisions when handling new or extenuating circumstances. This theory suggests designs for street-level algorithms that draw on historical design patterns for street-level bureaucracies, including mechanisms for self-policing and recourse in the case of error.},
	urldate = {2024-06-27},
    address = {New York, NY, USA},
	location = {Glasgow, Scotland, UK},
	series = {{CHI} '19},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Alkhatib, Ali and Bernstein, Michael},
	month = may,
	year = {2019},
	pages = {1--13},
	file = {Full Text:/Users/vsivaram/Zotero/storage/TYGJRGIZ/Alkhatib and Bernstein - 2019 - Street-Level Algorithms A Theory at the Gaps Betw.pdf:application/pdf},
}


@article{leider_state_2020,
	title = {The State of Rural Public Health: {Enduring} Needs in a New Decade},
	volume = {110},
	issn = {0090-0036},
	shorttitle = {The {State} of {Rural} {Public} {Health}},
	url = {https://ajph.aphapublications.org/doi/full/10.2105/AJPH.2020.305728},
	doi = {10.2105/AJPH.2020.305728},
	abstract = {Public health in the rural United States is a complex and underfunded enterprise. While urban–rural disparities have been a focus for researchers and policymakers alike for decades, inequalities continue to grow. Life expectancy at birth is now 1 to 2 years greater between wealthier urban and rural counties, and is as much as 5 years, on average, between wealthy and poor counties.

This article explores the growth in these disparities over the past 40 years, with roots in structural, economic, and social spending differentials that have emerged or persisted over the same time period. Importantly, a focus on place-based disparities recognizes that the rural United States is not a monolith, with important geographic and cultural differences present regionally. We also focus on the challenges the rural governmental public health enterprise faces, the so-called “double disparity” of worse health outcomes and behaviors alongside modest investment in health departments compared with their nonrural peers.

Finally, we offer 5 population-based “prescriptions” for supporting rural public health in the United States. These relate to greater investment and supporting rural advocacy to better address the needs of the rural United States in this new decade.},
	number = {9},
	urldate = {2024-06-27},
	journal = {American Journal of Public Health},
	author = {Leider, Jonathon P. and Meit, Michael and McCullough, J. Mac and Resnick, Beth and Dekker, Debra and Alfonso, Y. Natalia and Bishai, David},
	month = sep,
	year = {2020},
	note = {Publisher: American Public Health Association},
	pages = {1283--1290},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/V9CUKL4L/Leider et al. - 2020 - The State of Rural Public Health Enduring Needs i.pdf:application/pdf},
}


@inproceedings{Sendak2020,
	title = {“{The} human body is a black box”: {Supporting} clinical decision-making with deep learning},
	doi = {10.1145/3351095.3372827},
	abstract = {Machine learning technologies are increasingly developed for use in healthcare. While research communities have focused on creating state-of-the-art models, there has been less focus on real world implementation and the associated challenges to fairness, transparency, and accountability that come from actual, situated use. Serious questions remain underexamined regarding how to ethically build models, interpret and explain model output, recognize and account for biases, and minimize disruptions to professional expertise and work cultures. We address this gap in the literature and provide a detailed case study covering the development, implementation, and evaluation of Sepsis Watch, a machine learning-driven tool that assists hospital clinicians in the early diagnosis and treatment of sepsis. Sepsis is a severe infection that can lead to organ failure or death if not treated in time and is the leading cause of inpatient deaths in US hospitals. We, the team that developed and evaluated the tool, discuss our conceptualization of the tool not as a model deployed in the world but instead as a socio-technical system requiring integration into existing social and professional contexts. Rather than focusing solely on model interpretability to ensure fair and accountable machine learning, we point toward four key values and practices that should be considered when developing machine learning to support clinical decision-making: rigorously define the problem in context, build relationships with stakeholders, respect professional discretion, and create ongoing feedback loops with stakeholders. Our work has significant implications for future research regarding mechanisms of institutional accountability and considerations for responsibly designing machine learning systems. Our work underscores the limits of model interpretability as a solution to ensure transparency, accuracy, and accountability in practice. Instead, our work demonstrates other means and goals to achieve FATML values in design and in practice.},
	booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
    series = {{FAT}* '20},
    publisher = {Association for Computing Machinery},
    location = {Barcelona, Spain},
    address = {New York, NY, USA},
	author = {Sendak, Mark and Elish, Madeleine Clare and Gao, Michael and Futoma, Joseph and Ratliff, William and Nichols, Marshall and Bedoya, Armando and Balu, Suresh and O'Brien, Cara},
	year = {2020},
	keywords = {trust, interpretability, acm reference format, deep learning, medicine, expertise, joseph futoma, madeleine elish, mark sendak, michael gao, william},
	pages = {99--109},
	file = {PDF:/Users/vsivaram/Zotero/storage/24F44S7H/1911.08089.pdf:application/pdf},
}


@inproceedings{veale_fairness_2018,
	address = {Montreal QC Canada},
	title = {Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making},
	isbn = {978-1-4503-5620-6},
	url = {https://dl.acm.org/doi/10.1145/3173574.3174014},
	doi = {10.1145/3173574.3174014},
	language = {en},
	urldate = {2024-07-01},
	booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Veale, Michael and Van Kleek, Max and Binns, Reuben},
	month = apr,
	year = {2018},
	pages = {1--14},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/6TU85P37/Veale et al. - 2018 - Fairness and Accountability Design Needs for Algor.pdf:application/pdf},
}


@article{bly_design_1999,
	title = {Design through matchmaking: technology in search of users},
	volume = {6},
	issn = {1072-5520, 1558-3449},
	shorttitle = {Design through matchmaking},
	url = {https://dl.acm.org/doi/10.1145/296165.296174},
	doi = {10.1145/296165.296174},
	language = {en},
	number = {2},
	urldate = {2024-06-19},
	journal = {Interactions},
	author = {Bly, Sara and Churchill, Elizabeth F.},
	month = mar,
	year = {1999},
	pages = {23--31},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/688C3VAQ/Bly and Churchill - 1999 - Design through matchmaking technology in search o.pdf:application/pdf},
}


@article{mccurdy_framework_2019,
	title = {A Framework for Externalizing Implicit Error Using Visualization},
	volume = {25},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/8449328/},
	doi = {10.1109/TVCG.2018.2864913},
	language = {en},
	number = {1},
	urldate = {2024-06-02},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Mccurdy, Nina and Gerdes, Julie and Meyer, Miriah},
	month = jan,
	year = {2019},
	pages = {925--935},
	file = {Mccurdy et al. - 2019 - A Framework for Externalizing Implicit Error Using.pdf:/Users/vsivaram/Zotero/storage/35E35LUQ/Mccurdy et al. - 2019 - A Framework for Externalizing Implicit Error Using.pdf:application/pdf},
}


@article{Ghassemi2021,
	title = {The false hope of current approaches to explainable artificial intelligence in health care},
	volume = {3},
	issn = {25897500},
	url = {http://dx.doi.org/10.1016/S2589-7500(21)00208-9},
	doi = {10.1016/S2589-7500(21)00208-9},
	abstract = {The black-box nature of current artificial intelligence (AI) has caused some to question whether AI must be explainable to be used in high-stakes scenarios such as medicine. It has been argued that explainable AI will engender trust with the health-care workforce, provide transparency into the AI decision making process, and potentially mitigate various kinds of bias. In this Viewpoint, we argue that this argument represents a false hope for explainable AI and that current explainability methods are unlikely to achieve these goals for patient-level decision support. We provide an overview of current explainability techniques and highlight how various failure cases can cause problems for decision making for individual patients. In the absence of suitable explainability methods, we advocate for rigorous internal and external validation of AI models as a more direct means of achieving the goals often associated with explainability, and we caution against having explainability be a requirement for clinically deployed models.},
	number = {11},
	journal = {The Lancet Digital Health},
	author = {Ghassemi, Marzyeh and Oakden-Rayner, Luke and Beam, Andrew L.},
	year = {2021},
	pmid = {34711379},
	pages = {e745--e750},
	file = {PDF:/Users/vsivaram/Zotero/storage/KR5MS9NH/1-s2.0-S2589750021002089-main.pdf:application/pdf},
}


@article{robinson_combining_2005,
	title = {Combining Usability Techniques to Design Geovisualization Tools for Epidemiology},
	volume = {32},
	issn = {1523-0406},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2786201/},
	doi = {10.1559/152304005775194700},
	abstract = {Designing usable geovisualization tools is an emerging problem in GIScience software development. We are often satisfied that a new method provides an innovative window on our data, but functionality alone is insufficient assurance that a tool is applicable to a problem in situ. As extensions of the static methods they evolved from, geovisualization tools are bound to enable new knowledge creation. We have yet to learn how to adapt techniques from interaction designers and usability experts toward our tools in order to maximize this ability. This is especially challenging because there is limited existing guidance for the design of usable geovisualization tools. Their design requires knowledge about the context of work within which they will be used, and should involve user input at all stages, as is the practice in any human-centered design effort. Toward that goal, we have employed a wide range of techniques in the design of ESTAT, an exploratory geovisualization toolkit for epidemiology. These techniques include; verbal protocol analysis, card-sorting, focus groups, and an in-depth case study. This paper reports the design process and evaluation results from our experience with the ESTAT toolkit.},
	number = {4},
	urldate = {2024-07-01},
	journal = {Cartography and geographic information science},
	author = {Robinson, Anthony C. and Chen, Jin and Lengerich, Eugene J. and Meyer, Hans G. and MacEachren, Alan M.},
	month = oct,
	year = {2005},
	pmid = {19960106},
	pmcid = {PMC2786201},
	pages = {243--255},
	file = {PubMed Central Full Text PDF:/Users/vsivaram/Zotero/storage/H7R3DKTI/Robinson et al. - 2005 - Combining Usability Techniques to Design Geovisual.pdf:application/pdf},
}


@article{hoeyer_datafication_2019,
	title = {Datafication and accountability in public health: {Introduction} to a special issue},
	volume = {49},
	issn = {0306-3127},
	shorttitle = {Datafication and accountability in public health},
	url = {https://doi.org/10.1177/0306312719860202},
	doi = {10.1177/0306312719860202},
	abstract = {In recent years and across many nations, public health has become subject to forms of governance that are said to be aimed at establishing accountability. In this introduction to a special issue, From Person to Population and Back: Exploring Accountability in Public Health, we suggest opening up accountability assemblages by asking a series of ostensibly simple questions that inevitably yield complicated answers: What is counted? What counts? And to whom, how and why does it count? Addressing such questions involves staying attentive to the technologies and infrastructures through which data come into being and are made available for multiple political agendas. Through a discussion of public health, accountability and datafication we present three key themes that unite the various papers as well as illustrate their diversity.},
	language = {en},
	number = {4},
	urldate = {2024-06-13},
	journal = {Social Studies of Science},
	author = {Hoeyer, Klaus and Bauer, Susanne and Pickersgill, Martyn},
	month = aug,
	year = {2019},
	note = {Publisher: SAGE Publications Ltd},
	pages = {459--475},
	file = {SAGE PDF Full Text:/Users/vsivaram/Zotero/storage/QPLWKD93/Hoeyer et al. - 2019 - Datafication and accountability in public health .pdf:application/pdf},
}

@article{driscoll_integration_2011,
	title = {Integration and visualization of host–pathogen data related to infectious diseases},
	volume = {27},
	issn = {1367-4803},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3150046/},
	doi = {10.1093/bioinformatics/btr391},
	abstract = {Motivation: Infectious disease research is generating an increasing amount of disparate data on pathogenic systems. There is a growing need for resources that effectively integrate, analyze, deliver and visualize these data, both to improve our understanding of infectious diseases and to facilitate the development of strategies for disease control and prevention., Results: We have developed Disease View, an online host–pathogen resource that enables infectious disease-centric access, analysis and visualization of host–pathogen interactions. In this resource, we associate infectious diseases with corresponding pathogens, provide information on pathogens, pathogen virulence genes and the genetic and chemical evidences for the human genes that are associated with the diseases. We also deliver the relationships between pathogens, genes and diseases in an interactive graph and provide the geolocation reports of associated diseases around the globe in real time. Unlike many other resources, we have applied an iterative, user-centered design process to the entire resource development, including data acquisition, analysis and visualization., Availability and Implementation: Freely available at http://www.patricbrc.org; all major web browsers supported., Contact: cmao@vbi.vt.edu, Supplementary information: Supplementary data are available at Bioinformatics online.},
	number = {16},
	urldate = {2024-07-01},
	journal = {Bioinformatics},
	author = {Driscoll, Timothy and Gabbard, Joseph L. and Mao, Chunhong and Dalay, Oral and Shukla, Maulik and Freifeld, Clark C. and Hoen, Anne Gatewood and Brownstein, John S. and Sobral, Bruno W.},
	month = aug,
	year = {2011},
	pmid = {21712250},
	pmcid = {PMC3150046},
	pages = {2279--2287},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/VCC87KE9/Driscoll et al. - 2011 - Integration and visualization of host–pathogen dat.pdf:application/pdf},
}

@article{driedger_correction_2007,
	title = {Correction: {Using} participatory design to develop (public) health decision support systems through {GIS}},
	volume = {6},
	issn = {1476-072X},
	shorttitle = {Correction},
	url = {https://doi.org/10.1186/1476-072X-6-53},
	doi = {10.1186/1476-072X-6-53},
	abstract = {Organizations that collect substantial data for decision-making purposes are often characterized as being 'data rich' but 'information poor'. Maps and mapping tools can be very useful for research transfer in converting locally collected data into information. Challenges involved in incorporating GIS applications into the decision-making process within the non-profit (public) health sector include a lack of financial resources for software acquisition and training for non-specialists to use such tools. This on-going project has two primary phases. This paper critically reflects on Phase 1: the participatory design (PD) process of developing a collaborative web-based GIS tool.},
	number = {1},
	urldate = {2024-07-01},
	journal = {International Journal of Health Geographics},
	author = {Driedger, S. Michelle and Kothari, Anita and Morrison, Jason and Sawada, Michael and Crighton, Eric J. and Graham, Ian D.},
	month = nov,
	year = {2007},
	keywords = {Data Analyst, Early Development Instrument, Geographic Information System, Participatory Design, Potential Adopter},
	pages = {53},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/WSTU8HLQ/Driedger et al. - 2007 - Correction Using participatory design to develop .pdf:application/pdf;Snapshot:/Users/vsivaram/Zotero/storage/M6XJI376/1476-072X-6-53.html:text/html},
}


@article{amann_explain_2022,
	title = {To explain or not to explain?—{Artificial} intelligence explainability in clinical decision support systems},
	volume = {1},
	doi = {10.1371/journal.pdig.0000016},
	abstract = {Explainability for artificial intelligence (AI) in medicine is a hotly debated topic. Our paper presents a review of the key arguments in favor and against explainability for AI-powered Clinical Decision Support System (CDSS) applied to a concrete use case, namely an AI-powered CDSS currently used in the emergency call setting to identify patients with life-threatening cardiac arrest. More specifically, we performed a normative analysis using socio-technical scenarios to provide a nuanced account of the role of explainability for CDSSs for the concrete use case, allowing for abstractions to a more general level. Our analysis focused on three layers: technical considerations, human factors, and the designated system role in decision-making. Our findings suggest that whether explainability can provide added value to CDSS depends on several key questions: technical feasibility, the level of validation in case of explainable algorithms, the characteristics of the context in which the system is implemented, the designated role in the decision-making process, and the key user group(s). Thus, each CDSS will require an individualized assessment of explainability needs and we provide an example of how such an assessment could look like in practice.},
	number = {2},
	journal = {PLOS Digital Health},
	author = {Amann, Julia and Vetter, Dennis and Blomberg, Stig Nikolaj and Christensen, Helle Collatz and Coffee, Megan and Gerke, Sara and Gilbert, Thomas K. and Hagendorff, Thilo and Holm, Sune and Livne, Michelle and Spezzatti, Andy and Strümke, Inga and Zicari, Roberto V. and Madai, Vince Istvan},
	year = {2022},
	pages = {e0000016},
	file = {PDF:/Users/vsivaram/Zotero/storage/C7X87JMX/journal.pdig.0000016.pdf:application/pdf},
}


@article{VanBaalen2021,
	title = {From clinical decision support to clinical reasoning support systems},
	volume = {27},
	issn = {13652753},
	doi = {10.1111/jep.13541},
	abstract = {Despite the great promises that artificial intelligence (AI) holds for health care, the uptake of such technologies into medical practice is slow. In this paper, we focus on the epistemological issues arising from the development and implementation of a class of AI for clinical practice, namely clinical decision support systems (CDSS). We will first provide an overview of the epistemic tasks of medical professionals, and then analyse which of these tasks can be supported by CDSS, while also explaining why some of them should remain the territory of human experts. Clinical decision making involves a reasoning process in which clinicians combine different types of information into a coherent and adequate ‘picture of the patient’ that enables them to draw explainable and justifiable conclusions for which they bear epistemological responsibility. Therefore, we suggest that it is more appropriate to think of a CDSS as clinical reasoning support systems (CRSS). Developing CRSS that support clinicians' reasoning process therefore requires that: (a) CRSSs are developed on the basis of relevant and well-processed data; and (b) the system facilitates an interaction with the clinician. Therefore, medical experts must collaborate closely with AI experts developing the CRSS. In addition, responsible use of an CRSS requires that the data generated by the CRSS is empirically justified through an empirical link with the individual patient. In practice, this means that the system indicates what factors contributed to arriving at an advice, allowing the user (clinician) to evaluate whether these factors are medically plausible and applicable to the patient. Finally, we defend that proper implementation of CRSS allows combining human and artificial intelligence into hybrid intelligence, were both perform clearly delineated and complementary empirical tasks. Whereas CRSSs can assist with statistical reasoning and finding patterns in complex data, it is the clinicians' task to interpret, integrate and contextualize.},
	number = {3},
	journal = {Journal of Evaluation in Clinical Practice},
	author = {van Baalen, Sophie and Boon, Mieke and Verhoef, Petra},
	year = {2021},
	pmid = {33554432},
	keywords = {artificial intelligence, machine learning, CDSS, clinical decision making, clinical reasoning, epistemological responsibility},
	pages = {520--528},
	file = {PDF:/Users/vsivaram/Zotero/storage/UFGKQ28K/Evaluation Clinical Practice - 2021 - Baalen - From clinical decision support to clinical reasoning support systems.pdf:application/pdf},
}


@article{preim_survey_2020,
	title = {A Survey of Visual Analytics for Public Health},
	volume = {39},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13891},
	doi = {10.1111/cgf.13891},
	abstract = {We describe visual analytics solutions aiming to support public health professionals, and thus, preventive measures. Prevention aims at advocating behaviour and policy changes likely to improve human health. Public health strives to limit the outbreak of acute diseases as well as the reduction of chronic diseases and injuries. For this purpose, data are collected to identify trends in human health, to derive hypotheses, e.g. related to risk factors, and to get insights in the data and the underlying phenomena. Most public health data have a temporal character. Moreover, the spatial character, e.g. spatial clustering of diseases, needs to be considered for decision-making. Visual analytics techniques involve (subspace) clustering, interaction techniques to identify relevant subpopulations, e.g. being particularly vulnerable to diseases, imputation of missing values, visual queries as well as visualization and interaction techniques for spatio-temporal data. We describe requirements, tasks and visual analytics techniques that are widely used in public health before going into detail with respect to applications. These include outbreak surveillance and epidemiology research, e.g. cancer epidemiology. We classify the solutions based on the visual analytics techniques employed. We also discuss gaps in the current state of the art and resulting research opportunities in a research agenda to advance visual analytics support in public health.},
	language = {en},
	number = {1},
	urldate = {2023-11-20},
	journal = {Computer Graphics Forum},
	author = {Preim, Bernhard and Lawonn, Kai},
	year = {2020},
	keywords = {visualization, visual analytics, • Computer Applications → Life and Medical Sciences, medical imaging},
	pages = {543--580},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/JKDAYPCS/Preim and Lawonn - 2020 - A Survey of Visual Analytics for Public Health.pdf:application/pdf;Snapshot:/Users/vsivaram/Zotero/storage/CIJ8KGG2/cgf.html:text/html},
}


@inproceedings{lai_towards_2023,
	address = {Chicago IL USA},
	title = {Towards a Science of Human-{AI} Decision Making: {An} Overview of Design Space in Empirical Human-Subject Studies},
	isbn = {9798400701924},
	shorttitle = {Towards a {Science} of {Human}-{AI} {Decision} {Making}},
	url = {https://dl.acm.org/doi/10.1145/3593013.3594087},
	doi = {10.1145/3593013.3594087},
	language = {en},
	urldate = {2024-07-02},
	booktitle = {2023 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Lai, Vivian and Chen, Chacha and Smith-Renner, Alison and Liao, Q. Vera and Tan, Chenhao},
	month = jun,
	year = {2023},
	pages = {1369--1385},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/R2IDNTMG/Lai et al. - 2023 - Towards a Science of Human-AI Decision Making An .pdf:application/pdf},
}


@article{rong_towards_2024,
	title = {Towards Human-Centered Explainable {AI}: {A} Survey of User Studies for Model Explanations},
	volume = {46},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {0162-8828, 2160-9292, 1939-3539},
	shorttitle = {Towards {Human}-{Centered} {Explainable} {AI}},
	url = {https://ieeexplore.ieee.org/document/10316181/},
	doi = {10.1109/TPAMI.2023.3331846},
	abstract = {Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how human-computer interaction (HCI) and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97 core papers with human-based XAI evaluations over the past ﬁve years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures in user studies, we propose practical guidelines on designing and conducting user studies for XAI researchers and practitioners. Lastly, this survey also highlights several open research directions, particularly linking psychological science and human-centered XAI.},
	language = {en},
	number = {4},
	urldate = {2024-07-02},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Rong, Yao and Leemann, Tobias and Nguyen, Thai-Trang and Fiedler, Lisa and Qian, Peizhu and Unhelkar, Vaibhav and Seidel, Tina and Kasneci, Gjergji and Kasneci, Enkelejda},
	month = apr,
	year = {2024},
	pages = {2104--2122},
	file = {Rong et al. - 2024 - Towards Human-Centered Explainable AI A Survey of.pdf:/Users/vsivaram/Zotero/storage/DPV9GQWZ/Rong et al. - 2024 - Towards Human-Centered Explainable AI A Survey of.pdf:application/pdf},
}


@article{Wang2020,
	title = {Are explanations helpful? {A} comparative study of the Effects of Explanations in {AI}-assisted Decision Making},
	abstract = {This paper contributes to the growing literature in empirical evaluation of explainable AI (XAI) methods by presenting a comparison on the effects of a set of established XAI methods in AI-assisted decision making. Specifically, based on our review of previous literature, we highlight three desirable properties that ideal AI explanations should satisfy-improve people's understanding of the AI model, help people recognize the model uncertainty, and support people's calibrated trust in the model. Through randomized controlled experiments , we evaluate whether four types of common model-agnostic explainable AI methods satisfy these properties on two types of decision making tasks where people perceive themselves as having different levels of domain expertise in (i.e., recidivism prediction and forest cover prediction). Our results show that the effects of AI explanations are largely different on decision making tasks where people have varying levels of domain expertise in, and many AI explanations do not satisfy any of the desirable properties for tasks that people have little domain expertise in. Further, for decision making tasks that people are more knowledgeable, feature contribution explanation is shown to satisfy more desiderata of AI explanations, while the explanation that is considered to resemble how human explain decisions (i.e., counterfactual explanation) does not seem to improve calibrated trust. We conclude by discussing the implications of our study for improving the design of XAI methods to better support human decision making. CCS CONCEPTS • Human-centered computing → Empirical studies in HCI; • Computing methodologies → Machine learning.},
	journal = {Intelligent User Interfaces, IUI ’21, April 14–17, 2021, College Station, TX, USA},
	author = {Wang, Xinru and Yin, Ming},
	year = {2020},
	keywords = {trust, trust calibration, acm reference format, explainable AI, explainable ai, human-subject experiments, interpretable machine learning, tion, trust calibra-},
	pages = {318--328},
	file = {PDF:/Users/vsivaram/Zotero/storage/I6AXKZYZ/3397481.3450650.pdf:application/pdf},
}


@inproceedings{kaur_interpreting_2020,
	address = {Honolulu HI USA},
	title = {Interpreting Interpretability: {Understanding} Data Scientists' Use of Interpretability Tools for Machine Learning},
	isbn = {978-1-4503-6708-0},
	shorttitle = {Interpreting {Interpretability}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376219},
	doi = {10.1145/3313831.3376219},
	language = {en},
	urldate = {2024-07-02},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kaur, Harmanpreet and Nori, Harsha and Jenkins, Samuel and Caruana, Rich and Wallach, Hanna and Wortman Vaughan, Jennifer},
	month = apr,
	year = {2020},
	pages = {1--14},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/M9YIIRBC/Kaur et al. - 2020 - Interpreting Interpretability Understanding Data .pdf:application/pdf},
}


@article{Cheng2019,
	title = {Explaining decision-making algorithms through {UI}: {Strategies} to help non-expert stakeholders},
	doi = {10.1145/3290605.3300789},
	abstract = {Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' "right to explanation". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and "white-box" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Cheng, Hao Fei and Wang, Ruotong and Zhang, Zheng and O'Connell, Fiona and Gray, Terrance and Harper, F. Maxwell and Zhu, Haiyi},
	year = {2019},
	keywords = {Algorithmic decision-making, Explanation interfaces},
	pages = {1--12},
	file = {PDF:/Users/vsivaram/Zotero/storage/GKS3BQ2M/3290605.3300789.pdf:application/pdf},
}


@inproceedings{yildirim_sketching_2024,
	address = {Honolulu HI USA},
	title = {Sketching {AI} Concepts with Capabilities and Examples: {AI} Innovation in the {Intensive} {Care} {Unit}},
	isbn = {9798400703300},
	shorttitle = {Sketching {AI} {Concepts} with {Capabilities} and {Examples}},
	url = {https://dl.acm.org/doi/10.1145/3613904.3641896},
	doi = {10.1145/3613904.3641896},
	language = {en},
	urldate = {2024-07-02},
	booktitle = {Proceedings of the {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yildirim, Nur and Zlotnikov, Susanna and Sayar, Deniz and Kahn, Jeremy M. and Bukowski, Leigh A and Amin, Sher Shah and Riman, Kathryn A. and Davis, Billie S. and Minturn, John S. and King, Andrew J. and Ricketts, Dan and Tang, Lu and Sivaraman, Venkatesh and Perer, Adam and Preum, Sarah M. and McCann, James and Zimmerman, John},
	month = may,
	year = {2024},
	pages = {1--18},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/SE7LB2GA/Yildirim et al. - 2024 - Sketching AI Concepts with Capabilities and Exampl.pdf:application/pdf},
}


@book{ries_lean_2011,
	title = {The Lean Startup: {How} Today's Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses},
	isbn = {978-0-307-88789-4},
	shorttitle = {The {Lean} {Startup}},
	abstract = {Most startups fail. But many of those failures are preventable. The Lean Startup is a new approach being adopted across the globe, changing the way companies are built and new products are launched. Eric Ries defines a startup as an organization dedicated to creating something new under conditions of extreme uncertainty. This is just as true for one person in a garage or a group of seasoned professionals in a Fortune 500 boardroom. What they have in common is a mission to penetrate that fog of uncertainty to discover a successful path to a sustainable business. The Lean Startup approach fosters companies that are both more capital efficient and that leverage human creativity more effectively. Inspired by lessons from lean manufacturing, it relies on “validated learning,” rapid scientific experimentation, as well as a number of counter-intuitive practices that shorten product development cycles, measure actual progress without resorting to vanity metrics, and learn what customers really want. It enables a company to shift directions with agility, altering plans inch by inch, minute by minute. Rather than wasting time creating elaborate business plans, The Lean Startup offers entrepreneurs—in companies of all sizes—a way to test their vision continuously, to adapt and adjust before it’s too late. Ries provides a scientific approach to creating and managing successful startups in a age when companies need to innovate more than ever.},
	language = {en},
	publisher = {Crown},
	author = {Ries, Eric},
	month = sep,
	year = {2011},
	keywords = {Business \& Economics / Entrepreneurship, Business \& Economics / Management, Business \& Economics / New Business Enterprises},
}

@book{buxton_sketching,
author = {Buxton, Bill},
title = {Sketching User Experiences: Getting the Design Right and the Right Design},
year = {2007},
isbn = {0123740371},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
}


@article{backonja_supporting_2022,
	title = {Supporting rural public health practice to address local-level social determinants of health across {Northwest} states: {Development} of an interactive visualization dashboard},
	volume = {129},
	issn = {15320464},
	shorttitle = {Supporting rural public health practice to address local-level social determinants of health across {Northwest} states},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046422000673},
	doi = {10.1016/j.jbi.2022.104051},
	abstract = {Background: Rural local health departments (LHDs) lack adequate capacity and funding to effectively make datadriven decisions to support their communities that face greater health disparities compared to urban counter­ parts. The need, therefore, exists for informatics solutions to support rural LHDs.
Purpose: We describe the user-centered design (UCD) of SHARE-NW: Solutions in Health Analytics for Rural Equity across the Northwest, a website (sharenw.nwcphp.org) with data visualization dashboards for rural LHD practi­ tioners in Alaska, Idaho, Oregon, and Washington to help them identify health disparities in their jurisdictions.
Methods: In this UCD study guided by Munzner’s Nested Model for Visualization Design and Validation, we (1) completed a needs assessment, (2) created and evaluated mockups, and (3) conducted usability testing of a functional alpha testing website. Potential end-users (rural LHD practitioners) and Equity Advisory Committee members (public health experts from state, rural local, and tribal public health agencies) across our four-state catchment area were engaged throughout the website development and testing. We adapted traditional inperson UCD methods to be remote to reach participants across a large geographic area and in rural/frontier areas of Alaska, Idaho, Oregon, and Washington.
Results: We recruited participants from all four states to engage in each stage of the project. Needs assessment findings informed the mockup development, and findings from the mockup evaluations informed the develop­ ment of the functional website. Usability testing of the website overall was positive, with priority usability issues identified.
Conclusions: By applying Munzner’s Nested Model and UCD, we could purposefully and intentionally design evidence-based solutions, specifically for rural LHD practitioners. Adaptations of traditional UCD methods were successful and allowed us to reach end-users across a large geographic area. Future work on SHARE-NW will involve the evaluation of the website. We provide insights on our lessons learned to support future public health informatics solution development.},
	language = {en},
	urldate = {2023-11-20},
	journal = {Journal of Biomedical Informatics},
	author = {Backonja, Uba and Park, Seungeun and Kurre, Amae and Yudelman, Hayley and Heindel, Sam and Schultz, Melinda and Whitman, Greg and Turner, Anne M. and Marchak, Natasza T. and Bekemeier, Betty},
	month = may,
	year = {2022},
	pages = {104051},
	file = {Backonja et al. - 2022 - Supporting rural public health practice to address.pdf:/Users/vsivaram/Zotero/storage/KQ8PNXRE/Backonja et al. - 2022 - Supporting rural public health practice to address.pdf:application/pdf},
}


@inproceedings{jacobs_measurement_2021,
	title = {Measurement and Fairness},
	url = {http://arxiv.org/abs/1912.05511},
	doi = {10.1145/3442188.3445901},
	abstract = {We propose measurement modeling from the quantitative social sciences as a framework for understanding fairness in computational systems. Computational systems often involve unobservable theoretical constructs, such as socioeconomic status, teacher effectiveness, and risk of recidivism. Such constructs cannot be measured directly and must instead be inferred from measurements of observable properties (and other unobservable theoretical constructs) thought to be related to them -- i.e., operationalized via a measurement model. This process, which necessarily involves making assumptions, introduces the potential for mismatches between the theoretical understanding of the construct purported to be measured and its operationalization. We argue that many of the harms discussed in the literature on fairness in computational systems are direct results of such mismatches. We show how some of these harms could have been anticipated and, in some cases, mitigated if viewed through the lens of measurement modeling. To do this, we contribute fairness-oriented conceptualizations of construct reliability and construct validity that unite traditions from political science, education, and psychology and provide a set of tools for making explicit and testing assumptions about constructs and their operationalizations. We then turn to fairness itself, an essentially contested construct that has different theoretical understandings in different contexts. We argue that this contestedness underlies recent debates about fairness definitions: although these debates appear to be about different operationalizations, they are, in fact, debates about different theoretical understandings of fairness. We show how measurement modeling can provide a framework for getting to the core of these debates.},
	urldate = {2024-02-26},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	author = {Jacobs, Abigail Z. and Wallach, Hanna},
	month = mar,
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computers and Society},
	pages = {375--385},
	annote = {Comment: 11 pages, 1 figure. To be published in the proceedings of the ACM Conference on Fairness, Accountability, and Transparency (FAccT '21)},
	file = {arXiv.org Snapshot:/Users/vsivaram/Zotero/storage/26G5RUBU/1912.html:text/html;Full Text PDF:/Users/vsivaram/Zotero/storage/P47I4QQ4/Jacobs and Wallach - 2021 - Measurement and Fairness.pdf:application/pdf},
}


@misc{padoh_prescribing_2023,
	title = {Prescribing Guidelines for {CNS} Stimulants in Adults},
	url = {https://www.health.pa.gov/topics/Documents/Opioids/Prescribing%20Guidelines%20for%20CNS%20Stimulants%20in%20Adults.pdf},
	urldate = {2024-07-05},
	author = {{Pennsylvania Department of Health}},
	month = jan,
	year = {2023},
	file = {Prescribing Guidelines for CNS Stimulants in Adults.pdf:/Users/vsivaram/Zotero/storage/QIZ3TXX8/Prescribing Guidelines for CNS Stimulants in Adults.pdf:application/pdf},
}


@techreport{adkins_fourth_2024,
	title = {The “{Fourth} {Wave}”: {The} Rise of Stimulants and the evolution of Polysubstance Use in {America}’s Fentanyl Crisis},
	url = {https://resource.millenniumhealth.com/signalsreportvol6},
	institution = {Millennium Health},
	author = {Adkins, Brandon and Bolin, B. Levi and Bundy, William and Canales, Louis and Curammeng, Jenna and Dawson, Eric and Fileger, Monica and Gorelik, Steve and Griffin, Joy and Huskey, Angela G. and Olson, Kelly and Passik, Steven D. and Selvaraj, Fabi and Smith, Ian and Velasco, Javier and Whitley, Penn},
	month = feb,
	year = {2024},
	pages = {1--17},
	file = {MH_Signals_Report_Vol._6.pdf:/Users/vsivaram/Zotero/storage/EVU9YNVP/MH_Signals_Report_Vol._6.pdf:application/pdf},
}


@techreport{pdmpttac_2018,
	title = {History of {Prescription} {Drug} {Monitoring} {Programs}},
	url = {https://www.pdmpassist.org/Content/Documents/pdf/PDMP_admin/TAG_History_PDMPs_final_20180314.pdf},
	urldate = {2024-07-15},
	institution = {Brandeis University},
	author = {{Prescription Drug Monitoring Program Training and Technical Assistance Center}},
	month = mar,
	year = {2018},
	file = {TAG_History_PDMPs_final_20180314.pdf:/Users/vsivaram/Zotero/storage/8E27RMYS/TAG_History_PDMPs_final_20180314.pdf:application/pdf},
}


% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

