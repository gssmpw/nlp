@article{Allen2016,
abstract = {Traditional methods for monitoring influenza are haphazard and lack fine-grained details regarding the spatial and temporal dynamics of outbreaks. Twitter gives researchers and public health officials an opportunity to examine the spread of influenza in real-time and at multiple geographical scales. In this paper, we introduce an improved framework for monitoring influenza outbreaks using the social media platform Twitter. Relying upon techniques from geographic information science (GIS) and data mining, Twitter messages were collected, filtered, and analyzed for the thirty most populated cities in the United States during the 2013-2014 flu season. The results of this procedure are compared with national, regional, and local flu outbreak reports, revealing a statistically significant correlation between the two data sources. The main contribution of this paper is to introduce a comprehensive data mining process that enhances previous attempts to accurately identify tweets related to influenza. Additionally, geographical information systems allow us to target, filter, and normalize Twitter messages.},
author = {Allen, Chris and Tsou, Ming Hsiang and Aslam, Anoshe and Nagel, Anna and Gawron, Jean Mark},
doi = {10.1371/journal.pone.0157734},
file = {:Users/vsivaram/Documents/papers/flu twitter ml.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
number = {7},
pages = {1--10},
pmid = {27455108},
title = {Applying {GIS} and machine learning methods to twitter data for multiscale surveillance of influenza},
volume = {11},
year = {2016}
}

@techreport{Angwin2016,
author = {Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
mendeley-groups = {Opioid Risk/Human-AI Public Sector},
title = {{Machine Bias}: {There's} software used across the country to predict future criminals. And it's biased against blacks.},
year = {2016}
}

@article{Balaam2015,
abstract = {Breastfeeding is positively encouraged across many countries as a public health endeavour. The World Health Organisation recommends breastfeeding exclusively for the first six months of an infant's life. However, women can struggle to breastfeed, and to persist with breastfeeding, for a number of reasons from technique to social acceptance. This paper reports on four phases of a design and research project, from sensitising user-engagement and user-centred design, to the development and in-the-wild deployment of a mobile phone application called FeedFinder. FeedFinder has been developed with breastfeeding women to support them in finding, reviewing and sharing public breastfeeding places with other breastfeeding women. We discuss how mobile technologies can be designed to support public health endeavours, and suggest that public health technologies are better aimed at communities and societies rather than individual.},
author = {Balaam, Madeline and Comber, Rob and Jenkins, Ed and Sutton, Selina and Garbett, Andrew},
doi = {10.1145/2702123.2702328},
file = {:Users/vsivaram/Documents/papers/2702123.2702328.pdf:pdf},
isbn = {9781450331456},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Breastfeeding,Mobile,Preventative health,Public health,User-centred design},
mendeley-groups = {Opioid Risk/Public Health},
pages = {1709--1718},
title = {Feedfinder: {A} location-mapping mobile application for breastfeeding women},
volume = {2015-April},
year = {2015}
}

@article{Beede2020,
abstract = {Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.},
author = {Beede, Emma and Baylor, Elizabeth and Hersch, Fred and Iurchenko, Anna and Wilcox, Lauren and Ruamviboonsuk, Paisan and Vardoulakis, Laura M.},
doi = {10.1145/3313831.3376718},
file = {:Users/vsivaram/Documents/papers/3313831.3376718.pdf:pdf},
isbn = {9781450367080},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {deep learning,diabetes,health,human-centered ai},
mendeley-groups = {AI Clinician/Design Mini,AI Clinician/Healthcare,AI Clinician/Clinical Perspectives,Opioid Risk/Human-AI Public Sector},
pages = {1--12},
title = {A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy},
year = {2020}
}

@article{Cai2019,
	title = {“{Hello} {Ai}”: {Uncovering} the onboarding needs of medical practitioners for human–{AI} collaborative decision-making},
	volume = {3},
	issn = {25730142},
	doi = {10.1145/3359206},
	abstract = {Although rapid advances in machine learning have made it increasingly applicable to expert decision-making, the delivery of accurate algorithmic predictions alone is insufficient for effective human–AI collaboration. In this work, we investigate the key types of information medical experts desire when they are first introduced to a diagnostic AI assistant. In a qualitative lab study, we interviewed 21 pathologists before, during, and after being presented deep neural network (DNN) predictions for prostate cancer diagnosis, to learn the types of information that they desired about the AI assistant. Our findings reveal that, far beyond understanding the local, case-specific reasoning behind any model decision, clinicians desired upfront information about basic, global properties of the model, such as its known strengths and limitations, its subjective point-of-view, and its overall design objective—what it’s designed to be optimized for. Participants compared these information needs to the collaborative mental models they develop of their medical colleagues when seeking a second opinion: the medical perspectives and standards that those colleagues embody, and the compatibility of those perspectives with their own diagnostic patterns. These findings broaden and enrich discussions surrounding AI transparency for collaborative decision-making, providing a richer understanding of what experts find important in their introduction to AI assistants before integrating them into routine practice.},
	number = {CSCW},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Cai, Carrie J. and Winter, Samantha and Steiner, David and Wilcox, Lauren and Terry, Michael},
	year = {2019},
	keywords = {Machine learning, Clinical health, Human-AI interaction},
	file = {PDF:/Users/vsivaram/Zotero/storage/WVHEUJQ7/3359206.pdf:application/pdf},
}

@article{Chande2020,
abstract = {Large events and gatherings, particularly those taking place indoors, have been linked to multitransmission events that have accelerated the pandemic spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). To provide real-time, geolocalized risk information, we developed an interactive online dashboard that estimates the risk that at least one individual with SARS-CoV-2 is present in gatherings of different sizes in the United States. The website combines documented case reports at the county level with ascertainment bias information obtained via population-wide serological surveys to estimate real-time circulating, per-capita infection rates. These rates are updated daily as a means to visualize the risk associated with gatherings, including county maps and state-level plots. The website provides data-driven information to help individuals and policy makers make prudent decisions (for example, increasing mask-wearing compliance and avoiding larger gatherings) that could help control the spread of SARS-CoV-2, particularly in hard-hit regions.},
author = {Chande, Aroon and Lee, Seolha and Harris, Mallory and Nguyen, Quan and Beckett, Stephen J. and Hilley, Troy and Andris, Clio and Weitz, Joshua S.},
doi = {10.1038/s41562-020-01000-9},
file = {:Users/vsivaram/Documents/papers/s41562-020-01000-9.pdf:pdf},
issn = {23973374},
journal = {Nature Human Behaviour},
mendeley-groups = {Opioid Risk/Public Health},
number = {12},
pages = {1313--1319},
pmid = {33168955},
publisher = {Springer US},
title = {Real-time, interactive website for {US}-county-level {COVID}-19 event risk assessment},
url = {http://dx.doi.org/10.1038/s41562-020-01000-9},
volume = {4},
year = {2020}
}

@article{Cheng2019,
	title = {Explaining decision-making algorithms through {UI}: {Strategies} to help non-expert stakeholders},
	doi = {10.1145/3290605.3300789},
	abstract = {Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users' "right to explanation". We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users' objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and "white-box" explanations (i.e. that show the inner workings of an algorithm) can improve users' comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users' trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Cheng, Hao Fei and Wang, Ruotong and Zhang, Zheng and O'Connell, Fiona and Gray, Terrance and Harper, F. Maxwell and Zhu, Haiyi},
	year = {2019},
	keywords = {Algorithmic decision-making, Explanation interfaces},
	pages = {1--12},
	file = {PDF:/Users/vsivaram/Zotero/storage/GKS3BQ2M/3290605.3300789.pdf:application/pdf},
}

@article{Cheng2021,
abstract = {Recent work in fair machine learning has proposed dozens of quantitative notions of algorith-mic fairness and methods to enforcing these notions. However, we still lack an understanding of how to develop machine learning systems with fairness criteria that reflect human stakeholders' nuanced viewpoints in the real-world contexts. To address the gap, we propose a framework for eliciting stakeholders' subjective fairness notions. Combining a user interface that allows stakeholder to examine the data and algorithm's predictions, and an interview protocol to probe stakeholders' thoughts while they are interacting with the interface, we can identify stakeholders' fairness beliefs and principles. We propose a user study to evaluate our framework in real world settings of a child maltreatment predictive system.},
author = {Cheng, Hao-Fei and Stapleton, Logan and Wang, Ruiqi and Bullock, Paige and Chouldechova, Alexandra and Wu, Zhiwei Steven Steven and Zhu, Haiyi},
doi = {10.1145/3411764.3445308},
file = {:Users/vsivaram/Documents/papers/2102.01196.pdf:pdf},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {algorithm-,algorithmic fairness,assisted decision-making,child welfare,human-centered ai,machine learning},
mendeley-groups = {CHI 2021,Child Welfare,Child Welfare/AFST-specific,Opioid Risk/Human-AI Public Sector},
pages = {1--17},
title = {Soliciting Stakeholders' Fairness Notions in Child Maltreatment Predictive Systems},
year = {2021}
}

@article{Fisher2022,
abstract = {Artificial intelligence (AI) has the potential to improve public health's ability to promote the health of all people in all communities. To successfully realize this potential and use AI for public health functions it is important for public health organizations to thoughtfully develop strategies for AI implementation. Six key priorities for successful use of AI technologies by public health organizations are discussed: 1) Contemporary data governance; 2) Investment in modernized data and analytic infrastructure and procedures; 3) Addressing the skills gap in the workforce; 4) Development of strategic collaborative partnerships; 5) Use of good AI practices for transparency and reproducibility, and; 6) Explicit consideration of equity and bias.},
author = {Fisher, Stacey and Rosella, Laura C.},
doi = {10.1186/s12889-022-14422-z},
file = {:Users/vsivaram/Documents/papers/s12889-022-14422-z.pdf:pdf},
issn = {14712458},
journal = {BMC Public Health},
keywords = {Artificial intelligence,Health policy,Public health},
mendeley-groups = {Opioid Risk},
number = {1},
pages = {1--14},
pmid = {36419010},
publisher = {BioMed Central},
title = {Priorities for successful use of artificial intelligence by public health organizations: a literature review},
url = {https://doi.org/10.1186/s12889-022-14422-z},
volume = {22},
year = {2022}
}

@article{Ghassemi2021,
	title = {The false hope of current approaches to explainable artificial intelligence in health care},
	volume = {3},
	issn = {25897500},
	url = {http://dx.doi.org/10.1016/S2589-7500(21)00208-9},
	doi = {10.1016/S2589-7500(21)00208-9},
	abstract = {The black-box nature of current artificial intelligence (AI) has caused some to question whether AI must be explainable to be used in high-stakes scenarios such as medicine. It has been argued that explainable AI will engender trust with the health-care workforce, provide transparency into the AI decision making process, and potentially mitigate various kinds of bias. In this Viewpoint, we argue that this argument represents a false hope for explainable AI and that current explainability methods are unlikely to achieve these goals for patient-level decision support. We provide an overview of current explainability techniques and highlight how various failure cases can cause problems for decision making for individual patients. In the absence of suitable explainability methods, we advocate for rigorous internal and external validation of AI models as a more direct means of achieving the goals often associated with explainability, and we caution against having explainability be a requirement for clinically deployed models.},
	number = {11},
	journal = {The Lancet Digital Health},
	author = {Ghassemi, Marzyeh and Oakden-Rayner, Luke and Beam, Andrew L.},
	year = {2021},
	pmid = {34711379},
	pages = {e745--e750},
	file = {PDF:/Users/vsivaram/Zotero/storage/KR5MS9NH/1-s2.0-S2589750021002089-main.pdf:application/pdf},
}

@article{Ghimire2021,
abstract = {Assessing the possibility of Coronavirus infection and its risk on an individual's life, estimating the spatial transmission risk based on the dynamic condition of a particular place into consideration, and communicating the same to the public is crucial for minimizing the potential impact of COVID-19. With the increase in cases world-wide, new patterns are being unfolded. Nevertheless, an application for risk assessment will not only help the researcher to quickly verify the proof of concept but also is a powerful tool to bring into notice the results immediately as one of the perfect tools for risk communication. Covira (https://covira.info) is an open-source web-based software that captures the response, calculates personal as well as regional risk, and displays the result to the end-user in the form of maps and risk cards.},
author = {Ghimire, Bhoj Raj and Parajuli, Rishi Ram and Khatiwada, Bipin and Poudel, Shobha and Sharma, Kusum and Mishra, Bhogendra},
doi = {10.1016/j.softx.2021.100873},
file = {:Users/vsivaram/Documents/papers/1-s2.0-S2352711021001400-main.pdf:pdf},
issn = {23527110},
journal = {SoftwareX},
keywords = {COVID-19,Covira,Personal risk,Risk assessment,Risk communication tool,Software},
mendeley-groups = {Opioid Risk},
pages = {100873},
publisher = {Elsevier B.V.},
title = {Covira: {A} {COVID}-19 risk assessment, visualization and communication tool},
url = {https://doi.org/10.1016/j.softx.2021.100873},
volume = {16},
year = {2021}
}

@article{HoltenMoller2020,
author = {{Holten M{\o}ller}, Naja and Shklovski, Irina and Hildebrandt, Thomas T.},
doi = {10.1145/3419249.3420149},
file = {:Users/vsivaram/Documents/papers/3419249.3420149.pdf:pdf},
isbn = {9781450375795},
journal = {NordiCHI},
keywords = {acm reference format,algorithmic decision-support systems,casework,design,job placement,participatory design methods,public services,responsible},
mendeley-groups = {Child Welfare,Opioid Risk},
pages = {1--12},
title = {Shifting Concepts of Value: {Designing} Algorithmic Decision-Support Systems for Public Services},
year = {2020}
}

@inproceedings{Kawakami2022,
author = {Kawakami, Anna and Sivaraman, Venkatesh and Stapleton, Logan and Cheng, Hao-Fei and Perer, Adam and Wu, Zhiwei Steven and Zhu, Haiyi and Holstein, Kenneth},
title = {“Why Do I Care What’s Similar?” Probing Challenges in AI-Assisted Child Welfare Decision-Making through Worker-AI Interface Design Concepts},
year = {2022},
isbn = {9781450393584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532106.3533556},
doi = {10.1145/3532106.3533556},
abstract = {Data-driven AI systems are increasingly used to augment human decision-making in complex, social contexts, such as social work or legal practice. Yet, most existing design knowledge regarding how to best support AI-augmented decision-making comes from studies in comparatively well-defined settings. In this paper, we present findings from design interviews with 12 social workers who use an algorithmic decision support tool (ADS) to assist their day-to-day child maltreatment screening decisions. We generated a range of design concepts, each envisioning different ways of redesigning or augmenting the ADS interface. Overall, workers desired ways to understand the risk score and incorporate contextual knowledge, which move beyond existing notions of AI interpretability. Conversations around our design concepts also surfaced more fundamental concerns around the assumptions underlying statistical prediction, such as inference based on similar historical cases and statistical notions of uncertainty. Based on our findings, we discuss how ADS may be better designed to support the roles of human decision-makers in social decision-making contexts.},
booktitle = {Proceedings of the 2022 ACM Designing Interactive Systems Conference},
pages = {454–470},
numpages = {17},
keywords = {AI-assisted decision-making, algorithmic decision support, child welfare, design, social work},
location = {Virtual Event, Australia},
series = {DIS '22}
}

@inproceedings{Kawakami2022partnerships,
abstract = {AI-based decision support tools (ADS) are increasingly used to augment human decision-making in high-stakes, social contexts. As public sector agencies begin to adopt ADS, it is critical that we understand workers' experiences with these systems in practice. In this paper, we present findings from a series of interviews and contextual inquiries at a child welfare agency, to understand how they currently make AI-assisted child maltreatment screening decisions. Overall, we observe how workers' reliance upon the ADS is guided by (1) their knowledge of rich, contextual information beyond what the AI model captures, (2) their beliefs about the ADS's capabilities and limitations relative to their own, (3) organizational pressures and incentives around the use of the ADS, and (4) awareness of misalignments between algorithmic predictions and their own decision-making objectives. Drawing upon these findings, we discuss design implications towards supporting more effective human-AI decision-making.},
archivePrefix = {arXiv},
arxivId = {2204.02310},
author = {Kawakami, Anna and Sivaraman, Venkatesh and Cheng, Hao-Fei and Stapleton, Logan and Cheng, Yanghuidi and Qing, Diana and Perer, Adam and Wu, Zhiwei Steven and Zhu, Haiyi and Holstein, Kenneth},
	address = {New York, NY, USA},
	location = {New Orleans, LA, USA},
	series = {{CHI} '22},
	booktitle = {Proceedings of the 2022 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
eprint = {2204.02310},
file = {:Users/vsivaram/Documents/papers/3491102.3517439.pdf:pdf},
keywords = {algorithm-assisted decision making,child welfare,contextual,decision suppo,decision support,inquiry,this work is licensed,under a creative commons},
mendeley-groups = {AI Clinician/Cognitive Mini,AI Clinician,Opioid Risk},
title = {Improving Human-{AI} Partnerships in Child Welfare: {Understanding} Worker Practices, Challenges, and Desires for Algorithmic Decision Support},
url = {https://doi.org/10.1145/3491102.3517439},
year = {2022}
}

@article{Kuo2023,
abstract = {Recent years have seen growing adoption of AI-based decision-support systems (ADS) in homeless services, yet we know little about stakeholder desires and concerns surrounding their use. In this work, we aim to understand impacted stakeholders' perspectives on a deployed ADS that prioritizes scarce housing resources. We employed AI lifecycle comicboarding, an adapted version of the comicboarding method, to elicit stakeholder feedback and design ideas across various components of an AI system's design. We elicited feedback from county workers who operate the ADS daily, service providers whose work is directly impacted by the ADS, and unhoused individuals in the region. Our participants shared concerns and design suggestions around the AI system's overall objective, specific model design choices, dataset selection, and use in deployment. Our findings demonstrate that stakeholders, even without AI knowledge, can provide specific and critical feedback on an AI system's design and deployment, if empowered to do so.},
author = {Kuo, Tzu Sheng and Shen, Hong and Geum, Jisoo and Jones, Nev and Hong, Jason I. and Zhu, Haiyi and Holstein, Kenneth},
doi = {10.1145/3544548.3580882},
file = {:Users/vsivaram/Documents/papers/3544548.3580882.pdf:pdf},
isbn = {9781450394215},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {AI-based decision support,comicboarding,homelessness,public algorithms},
mendeley-groups = {Opioid Risk},
title = {Understanding Frontline Workers' and Unhoused Individuals' Perspectives on {AI} Used in Homeless Services},
year = {2023}
}

@inproceedings{Lundberg2017,
author = {Lundberg, Scott M. and Lee, Su-In},
title = {A unified approach to interpreting model predictions},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {4768–4777},
numpages = {10},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@article{Maciejewski2011,
abstract = {The National Strategy for Pandemic Influenza outlines a plan for community response to a potential pandemic. In this outline, state and local communities are charged with enhancing their preparedness. In order to help public health officials better understand these charges, we have developed a visual analytics toolkit (PanViz) for analyzing the effect of decision measures implemented during a simulated pandemic influenza scenario. Spread vectors based on the point of origin and distance traveled over time are calculated and the factors of age distribution and population density are taken into effect. Healthcare officials are able to explore the effects of the pandemic on the population through a geographical spatiotemporal view, moving forward and backward through time and inserting decision points at various days to determine the impact. Linked statistical displays are also shown, providing county level summaries of data in terms of the number of sick, hospitalized and dead as a result of the outbreak. Currently, this tool has been deployed in Indiana State Department of Health planning and preparedness exercises, and as an educational tool for demonstrating the impact of social distancing strategies during the recent H1N1 (swine flu) outbreak. {\textcopyright} 2011 Elsevier Ltd.},
author = {Maciejewski, Ross and Livengood, Philip and Rudolph, Stephen and Collins, Timothy F. and Ebert, David S. and Brigantic, Robert T. and Corley, Courtney D. and Muller, George A. and Sanders, Stephen W.},
doi = {10.1016/j.jvlc.2011.04.002},
file = {:Users/vsivaram/Documents/papers/1-s2.0-S1045926X11000292-main.pdf:pdf},
issn = {1045926X},
journal = {Journal of Visual Languages and Computing},
keywords = {Geovisualization,Pandemic influenza,Risk assessment,Visual analytics},
mendeley-groups = {Opioid Risk},
number = {4},
pages = {268--278},
publisher = {Elsevier},
title = {A pandemic influenza modeling and visualization tool},
url = {http://dx.doi.org/10.1016/j.jvlc.2011.04.002},
volume = {22},
year = {2011}
}

@article{Matero2023,
abstract = {Targeting of location-specific aid for the U.S. opioid epidemic is difficult due to our inability to accurately predict changes in opioid mortality across heterogeneous communities. AI-based language analyses, having recently shown promise in cross-sectional (between-community) well-being assessments, may offer a way to more accurately longitudinally predict community-level overdose mortality. Here, we develop and evaluate, TrOP (Transformer for Opiod Prediction), a model for community-specific trend projection that uses community-specific social media language along with past opioid-related mortality data to predict future changes in opioid-related deaths. TOP builds on recent advances in sequence modeling, namely transformer networks, to use changes in yearly language on Twitter and past mortality to project the following year's mortality rates by county. Trained over five years and evaluated over the next two years TrOP demonstrated state-of-the-art accuracy in predicting future county-specific opioid trends. A model built using linear auto-regression and traditional socioeconomic data gave 7% error (MAPE) or within 2.93 deaths per 100,000 people on average; our proposed architecture was able to forecast yearly death rates with less than half that error: 3% MAPE and within 1.15 per 100,000 people.},
author = {Matero, Matthew and Giorgi, Salvatore and Curtis, Brenda and Ungar, Lyle H. and Schwartz, H. Andrew},
doi = {10.1038/s41746-023-00776-0},
file = {:Users/vsivaram/Documents/papers/s41746-023-00776-0.pdf:pdf},
issn = {23986352},
journal = {npj Digital Medicine},
mendeley-groups = {Opioid Risk/Public Health},
number = {1},
pages = {1--11},
publisher = {Springer US},
title = {Opioid death projections with {AI}-based forecasts using social media language},
volume = {6},
year = {2023}
}

@article{Miranda2002,
abstract = {Environmental threats to children's health - especially low-level lead exposure - are complex and multifaceted; consequently, mitigation of these threats has proven costly and insufficient and has produced economic and racial disparities in exposure among populations. Policy makers, public health officials, child advocates, and others currently lack the appropriate infrastructure to evaluate children's risk and exposure potential across a broad range of risks. Unable to identify where the highest risk of exposure occurs, children's environmental health programs remain mitigative instead of preventive. In this article we use geographic information system spatial analysis of data from blood lead screening, county tax assessors, and the U.S. Census to predict statistically based lead exposure risk levels mapped at the individual tax parcel unit in six counties in North Carolina. The resulting model uses weighted risk factors to spatially locate modeled exposure zones, thus highlighting critical areas for targeted intervention. The methods presented here hold promise for application and extension to the other 94 North Carolina counties and nationally, as well as to other environmental health risks.},
author = {Miranda, Marie Lynn and Dolinoy, Dana C. and Overstreet, M. Alicia},
doi = {10.1289/ehp.02110947},
file = {:Users/vsivaram/Documents/papers/ehp.02110947.pdf:pdf},
issn = {00916765},
journal = {Environmental Health Perspectives},
keywords = {Children's health,Environmental justice,Geographic information system,Lead},
mendeley-groups = {Opioid Risk},
number = {9},
pages = {947--953},
pmid = {12204831},
title = {Mapping for prevention: {GIS} models for directing childhood lead poisoning prevention programs},
volume = {110},
year = {2002}
}

@article{Morgenstern2021,
abstract = {Background: Our objective was to determine the impacts of artificial intelligence (AI) on public health practice. Methods: We used a fundamental qualitative descriptive study design, enrolling 15 experts in public health and AI from June 2018 until July 2019 who worked in North America and Asia. We conducted in-depth semi-structured interviews, iteratively coded the resulting transcripts, and analyzed the results thematically. Results: We developed 137 codes, from which nine themes emerged. The themes included opportunities such as leveraging big data and improving interventions; barriers to adoption such as confusion regarding AI's applicability, limited capacity, and poor data quality; and risks such as propagation of bias, exacerbation of inequity, hype, and poor regulation. Conclusions: Experts are cautiously optimistic about AI's impacts on public health practice, particularly for improving disease surveillance. However, they perceived substantial barriers, such as a lack of available expertise, and risks, including inadequate regulation. Therefore, investment and research into AI for public health practice would likely be beneficial. However, increased access to high-quality data, research and education regarding the limitations of AI, and development of rigorous regulation are necessary to realize these benefits.},
author = {Morgenstern, Jason D. and Rosella, Laura C. and Daley, Mark J. and Goel, Vivek and Sch{\"{u}}nemann, Holger J. and Piggott, Thomas},
doi = {10.1186/s12889-020-10030-x},
file = {:Users/vsivaram/Documents/papers/s12889-020-10030-x.pdf:pdf},
isbn = {1288902010030},
issn = {14712458},
journal = {BMC Public Health},
keywords = {Big data,Community medicine,Epidemiology,Machine learning,Population health,Preventive medicine,Qualitative},
mendeley-groups = {Opioid Risk/Public Health},
number = {1},
pages = {1--14},
pmid = {33407254},
publisher = {BMC Public Health},
title = {“{AI}'s gonna have an impact on everything in society, so it has to have an impact on public health”: a fundamental qualitative descriptive study of the implications of artificial intelligence for public health},
volume = {21},
year = {2021}
}

@article{Saxena2023,
abstract = {Risk assessment algorithms are being adopted by public sector agencies to make high-stakes decisions about human lives. Algorithms model "risk"based on individual client characteristics to identify clients most in need. However, this understanding of risk is primarily based on easily quantifiable risk factors that present an incomplete and biased perspective of clients. We conducted a computational narrative analysis of child-welfare casenotes and draw attention to deeper systemic risk factors that are hard to quantify but directly impact families and street-level decision-making. We found that beyond individual risk factors, the system itself poses a significant amount of risk where parents are over-surveilled by caseworkers and lack agency in decision-making processes. We also problematize the notion of risk as a static construct by highlighting the temporality and mediating effects of different risk, protective, systemic, and procedural factors. Finally, we draw caution against using casenotes in NLP-based systems by unpacking their limitations and biases embedded within them.},
archivePrefix = {arXiv},
arxivId = {2302.08497},
author = {Saxena, Devansh and Moon, Erina Seh Young and Chaurasia, Aryan and Guan, Yixin and Guha, Shion},
doi = {10.1145/3544548.3581308},
eprint = {2302.08497},
file = {:Users/vsivaram/Documents/papers/3544548.3581308.pdf:pdf},
isbn = {9781450394215},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {computational narrative analysis,risk prediction,risk work,uncertainty in decision-making},
mendeley-groups = {Opioid Risk},
title = {Rethinking "Risk" in Algorithmic Systems Through A Computational Narrative Analysis of Casenotes in Child-Welfare},
year = {2023}
}

@article{Scott2022,
abstract = {Data-driven and algorithmic systems have been introduced to support Public Employment Services (PES) throughout the world. Their deployment has sparked public controversy and, as a consequence, some of these systems have been removed from use or their role was reduced. Yet the implementation of similar systems continues. In this paper, we use a participatory approach to determine a course forward for research and development in this area. We draw attention to the needs and expectations of people directly affected by these systems, i.e., jobseekers. Our investigation comprises two workshops: the first a fact-finding workshop with academics, system developers, the public sector, and civil-society organizations, the second a co-design workshop with 13 unemployed migrants to Germany. Based on the discussion in the fact-finding workshop we identified challenges of existing PES (algorithmic) systems. From the co-design workshop we identified our participants' needs and desires when contacting PES: the need for human contact, the expectation to receive genuine orientation, and the desire to be seen as a whole human being. We map these expectations to three design considerations for data-driven and algorithmic systems for PES: the importance of interpersonal interaction, jobseeker assessment as direction, and the challenge of mitigating misrepresentation. Finally, we argue that the limitations and risks of current systems cannot be addressed through minor adjustments but require a more fundamental change to the role of PES.},
author = {Scott, Kristen M. and Wang, Sonja Mei and Miceli, Milagros and Delobelle, Pieter and Sztandar-Sztanderska, Karolina and Berendt, Bettina},
doi = {10.1145/3531146.3534631},
file = {:Users/vsivaram/Documents/papers/3531146.3534631.pdf:pdf},
isbn = {9781450393522},
journal = {ACM International Conference Proceeding Series},
keywords = {Algorithmic Decision-Making,Participatory Design,Public Employment Services},
mendeley-groups = {Opioid Risk/Human-AI Public Sector},
pages = {2138--2148},
title = {Algorithmic Tools in Public Employment Services: {Towards} a Jobseeker-Centric Perspective},
year = {2022}
}

@article{Shahid2020,
abstract = {Social media platforms are widely used by people to report, access, and share information during outbreaks and epidemics. Although government agencies and healthcare institutions in developed regions are increasingly relying on social media to develop epidemic forecasts and outbreak response, there is a limited understanding of how people in developing regions interact on social media during outbreaks and what useful insights this dataset could offer during public health crises. In this work, we examined 28,688 tweets to identify public health issues during dengue epidemic in Bangladesh and found several insights, such as irregularities in dengue diagnosis and treatment, shortage of blood supply for Rh negative blood groups, and high local transmission of dengue during Eid-ul-Adha, that impact disease preparedness and outbreak response. We discuss the opportunities and challenges in analyzing tweets and outline how government agencies and healthcare institutions can use social media health data to inform policy making during public health crises.},
author = {Shahid, Farhana and Ony, Shahinul Hoque and Albi, Takrim Rahman and Chellappan, Sriram and Vashistha, Aditya and {Alim Al Islam}, A. B.M.},
doi = {10.1145/3392875},
file = {:Users/vsivaram/Documents/papers/3392875.pdf:pdf},
issn = {25730142},
journal = {Proceedings of the ACM on Human-Computer Interaction},
keywords = {Bangladesh,blood donation,dengue,epidemic,hci4d,health policy,outbreak,public health crisis,twitter},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
number = {CSCW1},
pages = {1--27},
title = {Learning from Tweets: {Opportunities} and Challenges to Inform Policy Making during Dengue Epidemic},
volume = {4},
year = {2020}
}

@inproceedings{Sivaraman2023,
author = {Sivaraman, Venkatesh and Bukowski, Leigh A and Levin, Joel and Kahn, Jeremy M. and Perer, Adam},
title = {Ignore, Trust, or Negotiate: Understanding Clinician Acceptance of AI-Based Treatment Recommendations in Health Care},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581075},
doi = {10.1145/3544548.3581075},
abstract = {Artificial intelligence (AI) in healthcare has the potential to improve patient outcomes, but clinician acceptance remains a critical barrier. We developed a novel decision support interface that provides interpretable treatment recommendations for sepsis, a life-threatening condition in which decisional uncertainty is common, treatment practices vary widely, and poor outcomes can occur even with optimal decisions. This system formed the basis of a mixed-methods study in which 24 intensive care clinicians made AI-assisted decisions on real patient cases. We found that explanations generally increased confidence in the AI, but concordance with specific recommendations varied beyond the binary acceptance or rejection described in prior work. Although clinicians sometimes ignored or trusted the AI, they also often prioritized aspects of the recommendations to follow, reject, or delay in a process we term “negotiation.” These results reveal novel barriers to adoption of treatment-focused AI tools and suggest ways to better support differing clinician perspectives.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {754},
numpages = {18},
keywords = {healthcare, human-AI interaction, interpretability, visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{Thakkar2022,
abstract = {Data-driven approaches that form the foundation of advancements in machine learning (ML) are powered in large part by human infrastructures that enable the collection of large datasets. We study the movement of data through multiple stages of data processing in the context of public health in India, examining the data work performed by frontline health workers, data stewards, and ML developers. We conducted interviews with these stakeholders to understand their varied perspectives on valuing data across stages, working with data to attain this value, and challenges arising throughout. We discuss the tensions in valuing and how they might be addressed, as we emphasize the need for improved transparency and accountability when data are transformed from one stage of processing to the next.},
author = {Thakkar, Divy and Ismail, Azra and Kumar, Pratyush and Hanna, Alex and Sambasivan, Nithya and Kumar, Neha},
doi = {10.1145/3491102.3501868},
file = {:Users/vsivaram/Documents/papers/3491102.3501868.pdf:pdf},
isbn = {9781450391573},
booktitle = {Proceedings of the 2022 Conference on Human Factors in Computing Systems},
series = {{CHI} '22},
location = {New Orleans, LA, USA},
address = {New York, NY, USA},
publisher = {Association for Computing Machinery},
keywords = {Data work,India,public health,valuation},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
title = {When is Machine Learning Data Good?: {Valuing} in Public Health Datafication},
year = {2022}
}

@article{Vaithianathan2019,
author = {{Allegheny County} and Vaithianathan, Rhema and Jiang, Nan and Maloney, Tim and Nand, Parma and Putnam-Hornstein, Emily and Dare, Tim and Gambrill, Eileen},
file = {:Users/vsivaram/Documents/papers/16-ACDHS-26_PredictiveRisk_Package_050119_FINAL-2.pdf:pdf},
mendeley-groups = {Child Welfare,Child Welfare/AFST-specific},
title = {Developing predictive risk models to support child maltreatment hotline screening decisions},
year = {2019}
}

@article{Wang2020,
	title = {Are explanations helpful? {A} comparative study of the Effects of Explanations in {AI}-assisted Decision Making},
	abstract = {This paper contributes to the growing literature in empirical evaluation of explainable AI (XAI) methods by presenting a comparison on the effects of a set of established XAI methods in AI-assisted decision making. Specifically, based on our review of previous literature, we highlight three desirable properties that ideal AI explanations should satisfy-improve people's understanding of the AI model, help people recognize the model uncertainty, and support people's calibrated trust in the model. Through randomized controlled experiments , we evaluate whether four types of common model-agnostic explainable AI methods satisfy these properties on two types of decision making tasks where people perceive themselves as having different levels of domain expertise in (i.e., recidivism prediction and forest cover prediction). Our results show that the effects of AI explanations are largely different on decision making tasks where people have varying levels of domain expertise in, and many AI explanations do not satisfy any of the desirable properties for tasks that people have little domain expertise in. Further, for decision making tasks that people are more knowledgeable, feature contribution explanation is shown to satisfy more desiderata of AI explanations, while the explanation that is considered to resemble how human explain decisions (i.e., counterfactual explanation) does not seem to improve calibrated trust. We conclude by discussing the implications of our study for improving the design of XAI methods to better support human decision making. CCS CONCEPTS • Human-centered computing → Empirical studies in HCI; • Computing methodologies → Machine learning.},
	journal = {Intelligent User Interfaces, IUI ’21, April 14–17, 2021, College Station, TX, USA},
	author = {Wang, Xinru and Yin, Ming},
	year = {2020},
	keywords = {trust, trust calibration, acm reference format, explainable AI, explainable ai, human-subject experiments, interpretable machine learning, tion, trust calibra-},
	pages = {318--328},
	file = {PDF:/Users/vsivaram/Zotero/storage/I6AXKZYZ/3397481.3450650.pdf:application/pdf},
}

@article{Watson2021,
abstract = {Smartphones increasingly serve as the source for, or to aggregate, a considerable amount of data that can be relevant in public health emergencies. Hence the sharing and utilisation of mobile health data, for example to help control the spread of communicable diseases, has become a relevant issue, with the COVID-19 pandemic adding a sudden urgency mirrored in debates around contact tracing apps. Building on exploratory work that indicated user perceptions and values around consent, and the notion that smartphones and mobile health data can be perceived as elements of self-embodiment, we present an online study comparing three scenarios of representative diseases undertaken during the first wave lockdown in the UK. Using a mixed-methods analysis of responses from 86 participants, we identify tensions and mitigations in user values and from those present the description of four characteristic user-groups that can inform considerations for design and development activities in this space.},
author = {Watson, Colin and Ali, Ridita and Smeddinck, Jan David},
doi = {10.1145/3476071},
file = {:Users/vsivaram/Documents/papers/3476071.pdf:pdf},
issn = {25730142},
journal = {Proceedings of the ACM on Human-Computer Interaction},
keywords = {data,health,mixed methods study,mobile,privacy},
mendeley-groups = {Opioid Risk/Public Health},
number = {CSCW2},
title = {Tensions and Mitigations: {Understanding} Concerns and Values around Smartphone Data Collection for Public Health Emergencies},
volume = {5},
year = {2021}
}

@book{Zeng2020,
abstract = {Artificial intelligence (AI) techniques have been widely applied to infectious disease outbreak detection and early warning, trend prediction, and public health response modeling and assessment. Such public health surveillance and response tasks of major importance pose unique technical challenges such as data sparsity, lack of positive training samples, difficulty in developing baselines and quantifying the control measures, and interwoven dependencies between spatiotemporal elements and finer-grained risk analyses through contact and social networks. Traditional public health surveillance relies heavily on statistical techniques. Recent years have seen tremendous growth of AI-enabled methods, including but not limited to deep learning–based models, complementing statistical approaches. This chapter aims to provide a systematic review of these recent advances applying AI techniques to address public health surveillance and response challenges.},
author = {Zeng, Daniel and Cao, Zhidong and Neill, Daniel B.},
booktitle = {Artificial Intelligence in Medicine: Technical Basis and Clinical Applications},
doi = {10.1016/B978-0-12-821259-2.00022-3},
file = {:Users/vsivaram/Documents/papers/3-s2.0-B9780128212592000223-main.pdf:pdf},
isbn = {9780128212592},
keywords = {AI-enabled public health surveillance,early warning,infectious disease surveillance,public health response},
mendeley-groups = {Opioid Risk,Opioid Risk/Public Health},
pages = {437--453},
publisher = {INC},
title = {Artificial intelligence–enabled public health surveillance—from local detection to global epidemic monitoring and control},
url = {http://dx.doi.org/10.1016/B978-0-12-821259-2.00022-3},
year = {2020}
}

@article{Zhang2021,
abstract = {In response to COVID-19, a vast number of visualizations have been created to communicate information to the public. Information exposure in a public health crisis can impact people's attitudes towards and responses to the crisis and risks, and ultimately the trajectory of a pandemic. As such, there is a need for work that documents, organizes, and investigates what COVID-19 visualizations have been presented to the public. We address this gap through an analysis of 668 COVID-19 visualizations. We present our findings through a conceptual framework derived from our analysis, that examines who, (uses) what data, (to communicate) what messages, in what form, under what circumstances in the context of COVID-19 crisis visualizations. We provide a set of factors to be considered within each component of the framework. We conclude with directions for future crisis visualization research.},
archivePrefix = {arXiv},
arxivId = {2101.04743},
author = {Zhang, Yixuan and Sun, Yifan and Padilla, Lace and Barua, Sumit and Bertini, Enrico and Parker, Andrea G.},
doi = {10.1145/3411764.3445381},
eprint = {2101.04743},
file = {:Users/vsivaram/Documents/papers/3411764.3445381.pdf:pdf},
isbn = {9781450380966},
keywords = {Visualization, COVID-19, crisis informatics,acm reference format,and an-,covid-19,crisis informatics,enrico bertini,lace padilla,sumit barua,visualization,yifan sun,yixuan zhang},
mendeley-groups = {CHI 2021,Opioid Risk/Public Health},
title = {Mapping the Landscape of {COVID}-19 Crisis Visualizations},
url = {http://arxiv.org/abs/2101.04743%0Ahttp://dx.doi.org/10.1145/3411764.3445381},
year = {2021}
}

@ARTICLE{Zytek2021,
  author={Zytek, Alexandra and Liu, Dongyu and Vaithianathan, Rhema and Veeramachaneni, Kalyan},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Sibyl: Understanding and Addressing the Usability Challenges of Machine Learning In High-Stakes Decision Making}, 
  year={2022},
  volume={28},
  number={1},
  pages={1161-1171},
  keywords={Usability;Pediatrics;Tools;Predictive models;Decision making;Context modeling;Prediction algorithms;Machine learning;XAI;Usability;child welfare;visualization},
  doi={10.1109/TVCG.2021.3114864}}

@inproceedings{alkhatib_street-level_2019,
	title = {Street-Level Algorithms: {A} Theory at the Gaps Between Policy and Decisions},
	isbn = {978-1-4503-5970-2},
	shorttitle = {Street-{Level} {Algorithms}},
	url = {https://doi.org/10.1145/3290605.3300760},
	doi = {10.1145/3290605.3300760},
	abstract = {Errors and biases are earning algorithms increasingly malignant reputations in society. A central challenge is that algorithms must bridge the gap between high-level policy and on-the-ground decisions, making inferences in novel situations where the policy or training data do not readily apply. In this paper, we draw on the theory of street-level bureaucracies, how human bureaucrats such as police and judges interpret policy to make on-the-ground decisions. We present by analogy a theory of street-level algorithms, the algorithms that bridge the gaps between policy and decisions about people in a socio-technical system. We argue that unlike street-level bureaucrats, who reflexively refine their decision criteria as they reason through a novel situation, street-level algorithms at best refine their criteria only after the decision is made. This loop-and-a-half delay results in illogical decisions when handling new or extenuating circumstances. This theory suggests designs for street-level algorithms that draw on historical design patterns for street-level bureaucracies, including mechanisms for self-policing and recourse in the case of error.},
	urldate = {2024-06-27},
    address = {New York, NY, USA},
	location = {Glasgow, Scotland, UK},
	series = {{CHI} '19},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Alkhatib, Ali and Bernstein, Michael},
	month = may,
	year = {2019},
	pages = {1--13},
	file = {Full Text:/Users/vsivaram/Zotero/storage/TYGJRGIZ/Alkhatib and Bernstein - 2019 - Street-Level Algorithms A Theory at the Gaps Betw.pdf:application/pdf},
}

@article{amann_explain_2022,
	title = {To explain or not to explain?—{Artificial} intelligence explainability in clinical decision support systems},
	volume = {1},
	doi = {10.1371/journal.pdig.0000016},
	abstract = {Explainability for artificial intelligence (AI) in medicine is a hotly debated topic. Our paper presents a review of the key arguments in favor and against explainability for AI-powered Clinical Decision Support System (CDSS) applied to a concrete use case, namely an AI-powered CDSS currently used in the emergency call setting to identify patients with life-threatening cardiac arrest. More specifically, we performed a normative analysis using socio-technical scenarios to provide a nuanced account of the role of explainability for CDSSs for the concrete use case, allowing for abstractions to a more general level. Our analysis focused on three layers: technical considerations, human factors, and the designated system role in decision-making. Our findings suggest that whether explainability can provide added value to CDSS depends on several key questions: technical feasibility, the level of validation in case of explainable algorithms, the characteristics of the context in which the system is implemented, the designated role in the decision-making process, and the key user group(s). Thus, each CDSS will require an individualized assessment of explainability needs and we provide an example of how such an assessment could look like in practice.},
	number = {2},
	journal = {PLOS Digital Health},
	author = {Amann, Julia and Vetter, Dennis and Blomberg, Stig Nikolaj and Christensen, Helle Collatz and Coffee, Megan and Gerke, Sara and Gilbert, Thomas K. and Hagendorff, Thilo and Holm, Sune and Livne, Michelle and Spezzatti, Andy and Strümke, Inga and Zicari, Roberto V. and Madai, Vince Istvan},
	year = {2022},
	pages = {e0000016},
	file = {PDF:/Users/vsivaram/Zotero/storage/C7X87JMX/journal.pdig.0000016.pdf:application/pdf},
}

@article{ammitzboll_flugge_street-level_2021,
	title = {Street-Level Algorithms and AI in Bureaucratic Decision-Making: {A} Caseworker Perspective},
	volume = {5},
	issn = {2573-0142},
	shorttitle = {Street-{Level} {Algorithms} and {AI} in {Bureaucratic} {Decision}-{Making}},
	url = {https://dl.acm.org/doi/10.1145/3449114},
	doi = {10.1145/3449114},
	abstract = {Studies of algorithmic decision-making in Computer-Supported Cooperative Work (CSCW) and related fields of research increasingly recognize an analogy between AI and bureaucracies. We elaborate this link with an empirical study of AI in the context of decision-making in a street-level bureaucracy: job placement. The study examines caseworkers' perspectives on the use of AI, and contributes to an understanding of bureaucratic decision-making, with implications for integrating AI in caseworker systems. We report findings from a participatory workshop on AI with 35 caseworkers from different types of public services, followed up by interviews with five caseworkers specializing in job placement. The paper contributes an understanding of caseworkers' collaboration around documentation as a key aspect of bureaucratic decision-making practices. The collaborative aspects of casework are important to show because they are subject to process descriptions making case documentation prone for an individually focused AI with consequences for the future of how casework develops as a practice. Examining the collaborative aspects of caseworkers' documentation practices in the context of AI and (potentially) automation, our data show that caseworkers perceive AI as valuable when it can support their work towards management, (strengthen their cause, if a case requires extra resources), and towards unemployed individuals (strengthen their cause in relation to the individual's case when deciding on, and assigning a specific job placement program). We end by discussing steps to support cooperative aspects in AI decision-support systems that are increasingly implemented into the bureaucratic context of public services.},
	language = {en},
	number = {CSCW1},
	urldate = {2023-12-05},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Ammitzbøll Flügge, Asbjørn and Hildebrandt, Thomas and Møller, Naja Holten},
	month = apr,
	year = {2021},
	pages = {1--23},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/9IE45ZVH/Ammitzbøll Flügge et al. - 2021 - Street-Level Algorithms and AI in Bureaucratic Dec.pdf:application/pdf},
}

@article{backonja_supporting_2022,
	title = {Supporting rural public health practice to address local-level social determinants of health across {Northwest} states: {Development} of an interactive visualization dashboard},
	volume = {129},
	issn = {15320464},
	shorttitle = {Supporting rural public health practice to address local-level social determinants of health across {Northwest} states},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046422000673},
	doi = {10.1016/j.jbi.2022.104051},
	abstract = {Background: Rural local health departments (LHDs) lack adequate capacity and funding to effectively make datadriven decisions to support their communities that face greater health disparities compared to urban counter­ parts. The need, therefore, exists for informatics solutions to support rural LHDs.
Purpose: We describe the user-centered design (UCD) of SHARE-NW: Solutions in Health Analytics for Rural Equity across the Northwest, a website (sharenw.nwcphp.org) with data visualization dashboards for rural LHD practi­ tioners in Alaska, Idaho, Oregon, and Washington to help them identify health disparities in their jurisdictions.
Methods: In this UCD study guided by Munzner’s Nested Model for Visualization Design and Validation, we (1) completed a needs assessment, (2) created and evaluated mockups, and (3) conducted usability testing of a functional alpha testing website. Potential end-users (rural LHD practitioners) and Equity Advisory Committee members (public health experts from state, rural local, and tribal public health agencies) across our four-state catchment area were engaged throughout the website development and testing. We adapted traditional inperson UCD methods to be remote to reach participants across a large geographic area and in rural/frontier areas of Alaska, Idaho, Oregon, and Washington.
Results: We recruited participants from all four states to engage in each stage of the project. Needs assessment findings informed the mockup development, and findings from the mockup evaluations informed the develop­ ment of the functional website. Usability testing of the website overall was positive, with priority usability issues identified.
Conclusions: By applying Munzner’s Nested Model and UCD, we could purposefully and intentionally design evidence-based solutions, specifically for rural LHD practitioners. Adaptations of traditional UCD methods were successful and allowed us to reach end-users across a large geographic area. Future work on SHARE-NW will involve the evaluation of the website. We provide insights on our lessons learned to support future public health informatics solution development.},
	language = {en},
	urldate = {2023-11-20},
	journal = {Journal of Biomedical Informatics},
	author = {Backonja, Uba and Park, Seungeun and Kurre, Amae and Yudelman, Hayley and Heindel, Sam and Schultz, Melinda and Whitman, Greg and Turner, Anne M. and Marchak, Natasza T. and Bekemeier, Betty},
	month = may,
	year = {2022},
	pages = {104051},
	file = {Backonja et al. - 2022 - Supporting rural public health practice to address.pdf:/Users/vsivaram/Zotero/storage/KQ8PNXRE/Backonja et al. - 2022 - Supporting rural public health practice to address.pdf:application/pdf},
}

@article{bly_design_1999,
	title = {Design through matchmaking: technology in search of users},
	volume = {6},
	issn = {1072-5520, 1558-3449},
	shorttitle = {Design through matchmaking},
	url = {https://dl.acm.org/doi/10.1145/296165.296174},
	doi = {10.1145/296165.296174},
	language = {en},
	number = {2},
	urldate = {2024-06-19},
	journal = {Interactions},
	author = {Bly, Sara and Churchill, Elizabeth F.},
	month = mar,
	year = {1999},
	pages = {23--31},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/688C3VAQ/Bly and Churchill - 1999 - Design through matchmaking technology in search o.pdf:application/pdf},
}

@article{brownson_building_2018,
	title = {Building Capacity for Evidence-Based Public Health: Reconciling the Pulls of Practice and the Push of Research},
	volume = {39},
	issn = {0163-7525, 1545-2093},
	shorttitle = {Building {Capacity} for {Evidence}-{Based} {Public} {Health}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-publhealth-040617-014746},
	doi = {10.1146/annurev-publhealth-040617-014746},
	abstract = {Timely implementation of principles of evidence-based public health (EBPH) is critical for bridging the gap between discovery of new knowledge and its application. Public health organizations need sufﬁcient capacity (the availability of resources, structures, and workforce to plan, deliver, and evaluate the preventive dose of an evidence-based intervention) to move science to practice. We review principles of EBPH, the importance of capacity building to advance evidence-based approaches, promising approaches for capacity building, and future areas for research and practice. Although there is general agreement among practitioners and scientists on the importance of EBPH, there is less clarity on the deﬁnition of evidence, how to ﬁnd it, and how, when, and where to use it. Capacity for EBPH is needed among both individuals and organizations. Capacity can be strengthened via training, use of tools, technical assistance, assessment and feedback, peer networking, and incentives. Modest investments in EBPH capacity building will foster more effective public health practice.},
	language = {en},
	number = {1},
	urldate = {2023-12-09},
	journal = {Annual Review of Public Health},
	author = {Brownson, Ross C. and Fielding, Jonathan E. and Green, Lawrence W.},
	month = apr,
	year = {2018},
	pages = {27--53},
	file = {Brownson et al. - 2018 - Building Capacity for Evidence-Based Public Health.pdf:/Users/vsivaram/Zotero/storage/ZSV5H4WM/Brownson et al. - 2018 - Building Capacity for Evidence-Based Public Health.pdf:application/pdf},
}

@article{carroll_visualization_2014,
	title = {Visualization and analytics tools for infectious disease epidemiology: {A} systematic review},
	volume = {51},
	issn = {15320464},
	shorttitle = {Visualization and analytics tools for infectious disease epidemiology},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046414000914},
	doi = {10.1016/j.jbi.2014.04.006},
	abstract = {Background: A myriad of new tools and algorithms have been developed to help public health professionals analyze and visualize the complex data used in infectious disease control. To better understand approaches to meet these users’ information needs, we conducted a systematic literature review focused on the landscape of infectious disease visualization tools for public health professionals, with a special emphasis on geographic information systems (GIS), molecular epidemiology, and social network analysis. The objectives of this review are to: (1) identify public health user needs and preferences for infectious disease information visualization tools; (2) identify existing infectious disease information visualization tools and characterize their architecture and features; (3) identify commonalities among approaches applied to different data types; and (4) describe tool usability evaluation efforts and barriers to the adoption of such tools.},
	language = {en},
	urldate = {2023-12-04},
	journal = {Journal of Biomedical Informatics},
	author = {Carroll, Lauren N. and Au, Alan P. and Detwiler, Landon Todd and Fu, Tsung-chieh and Painter, Ian S. and Abernethy, Neil F.},
	month = oct,
	year = {2014},
	pages = {287--298},
	file = {Carroll et al. - 2014 - Visualization and analytics tools for infectious d.pdf:/Users/vsivaram/Zotero/storage/9GCU68CW/Carroll et al. - 2014 - Visualization and analytics tools for infectious d.pdf:application/pdf},
}

@article{driedger_correction_2007,
	title = {Correction: {Using} participatory design to develop (public) health decision support systems through {GIS}},
	volume = {6},
	issn = {1476-072X},
	shorttitle = {Correction},
	url = {https://doi.org/10.1186/1476-072X-6-53},
	doi = {10.1186/1476-072X-6-53},
	abstract = {Organizations that collect substantial data for decision-making purposes are often characterized as being 'data rich' but 'information poor'. Maps and mapping tools can be very useful for research transfer in converting locally collected data into information. Challenges involved in incorporating GIS applications into the decision-making process within the non-profit (public) health sector include a lack of financial resources for software acquisition and training for non-specialists to use such tools. This on-going project has two primary phases. This paper critically reflects on Phase 1: the participatory design (PD) process of developing a collaborative web-based GIS tool.},
	number = {1},
	urldate = {2024-07-01},
	journal = {International Journal of Health Geographics},
	author = {Driedger, S. Michelle and Kothari, Anita and Morrison, Jason and Sawada, Michael and Crighton, Eric J. and Graham, Ian D.},
	month = nov,
	year = {2007},
	keywords = {Data Analyst, Early Development Instrument, Geographic Information System, Participatory Design, Potential Adopter},
	pages = {53},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/WSTU8HLQ/Driedger et al. - 2007 - Correction Using participatory design to develop .pdf:application/pdf;Snapshot:/Users/vsivaram/Zotero/storage/M6XJI376/1476-072X-6-53.html:text/html},
}

@article{gu_lessons_2020,
	title = {Lessons Learned from Designing an {AI}-Enabled Diagnosis Tool for Pathologists},
	volume = {5},
	url = {http://arxiv.org/abs/2006.12695%0Ahttp://dx.doi.org/10.1145/3449084},
	doi = {10.1145/3449084},
	abstract = {Despite the promises of data-driven artificial intelligence (AI), little is known about how we can bridge the gulf between traditional physician-driven diagnosis and a plausible future of medicine automated by AI. Specifically, how can we involve AI usefully in physicians' diagnosis workflow given that most AI is still nascent and error-prone (e.g., in digital pathology)? To explore this question, we first propose a series of collaborative techniques to engage human pathologists with AI given AI's capabilities and limitations, based on which we prototype Impetus - a tool where an AI takes various degrees of initiatives to provide various forms of assistance to a pathologist in detecting tumors from histological slides. We summarize observations and lessons learned from a study with eight pathologists and discuss recommendations for future work on human-centered medical AI systems.},
	number = {CSCW1},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Gu, Hongyan and Huang, Jingbin and Hung, Lauren and Chen, Xiang 'Anthony'},
	year = {2020},
	keywords = {Digital pathology, Human-AI collaboration, Human-centered AI, Medical AI},
	file = {PDF:/Users/vsivaram/Zotero/storage/GN5XTXYZ/2006.12695.pdf:application/pdf},
}

@article{hoeyer_datafication_2019,
	title = {Datafication and accountability in public health: {Introduction} to a special issue},
	volume = {49},
	issn = {0306-3127},
	shorttitle = {Datafication and accountability in public health},
	url = {https://doi.org/10.1177/0306312719860202},
	doi = {10.1177/0306312719860202},
	abstract = {In recent years and across many nations, public health has become subject to forms of governance that are said to be aimed at establishing accountability. In this introduction to a special issue, From Person to Population and Back: Exploring Accountability in Public Health, we suggest opening up accountability assemblages by asking a series of ostensibly simple questions that inevitably yield complicated answers: What is counted? What counts? And to whom, how and why does it count? Addressing such questions involves staying attentive to the technologies and infrastructures through which data come into being and are made available for multiple political agendas. Through a discussion of public health, accountability and datafication we present three key themes that unite the various papers as well as illustrate their diversity.},
	language = {en},
	number = {4},
	urldate = {2024-06-13},
	journal = {Social Studies of Science},
	author = {Hoeyer, Klaus and Bauer, Susanne and Pickersgill, Martyn},
	month = aug,
	year = {2019},
	note = {Publisher: SAGE Publications Ltd},
	pages = {459--475},
	file = {SAGE PDF Full Text:/Users/vsivaram/Zotero/storage/QPLWKD93/Hoeyer et al. - 2019 - Datafication and accountability in public health .pdf:application/pdf},
}

@inproceedings{kaur_interpreting_2020,
	address = {Honolulu HI USA},
	title = {Interpreting Interpretability: {Understanding} Data Scientists' Use of Interpretability Tools for Machine Learning},
	isbn = {978-1-4503-6708-0},
	shorttitle = {Interpreting {Interpretability}},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376219},
	doi = {10.1145/3313831.3376219},
	language = {en},
	urldate = {2024-07-02},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Kaur, Harmanpreet and Nori, Harsha and Jenkins, Samuel and Caruana, Rich and Wallach, Hanna and Wortman Vaughan, Jennifer},
	month = apr,
	year = {2020},
	pages = {1--14},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/M9YIIRBC/Kaur et al. - 2020 - Interpreting Interpretability Understanding Data .pdf:application/pdf},
}

@inproceedings{lai_towards_2023,
	address = {Chicago IL USA},
	title = {Towards a Science of Human-{AI} Decision Making: {An} Overview of Design Space in Empirical Human-Subject Studies},
	isbn = {9798400701924},
	shorttitle = {Towards a {Science} of {Human}-{AI} {Decision} {Making}},
	url = {https://dl.acm.org/doi/10.1145/3593013.3594087},
	doi = {10.1145/3593013.3594087},
	language = {en},
	urldate = {2024-07-02},
	booktitle = {2023 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Lai, Vivian and Chen, Chacha and Smith-Renner, Alison and Liao, Q. Vera and Tan, Chenhao},
	month = jun,
	year = {2023},
	pages = {1369--1385},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/R2IDNTMG/Lai et al. - 2023 - Towards a Science of Human-AI Decision Making An .pdf:application/pdf},
}

@article{leider_state_2020,
	title = {The State of Rural Public Health: {Enduring} Needs in a New Decade},
	volume = {110},
	issn = {0090-0036},
	shorttitle = {The {State} of {Rural} {Public} {Health}},
	url = {https://ajph.aphapublications.org/doi/full/10.2105/AJPH.2020.305728},
	doi = {10.2105/AJPH.2020.305728},
	abstract = {Public health in the rural United States is a complex and underfunded enterprise. While urban–rural disparities have been a focus for researchers and policymakers alike for decades, inequalities continue to grow. Life expectancy at birth is now 1 to 2 years greater between wealthier urban and rural counties, and is as much as 5 years, on average, between wealthy and poor counties.

This article explores the growth in these disparities over the past 40 years, with roots in structural, economic, and social spending differentials that have emerged or persisted over the same time period. Importantly, a focus on place-based disparities recognizes that the rural United States is not a monolith, with important geographic and cultural differences present regionally. We also focus on the challenges the rural governmental public health enterprise faces, the so-called “double disparity” of worse health outcomes and behaviors alongside modest investment in health departments compared with their nonrural peers.

Finally, we offer 5 population-based “prescriptions” for supporting rural public health in the United States. These relate to greater investment and supporting rural advocacy to better address the needs of the rural United States in this new decade.},
	number = {9},
	urldate = {2024-06-27},
	journal = {American Journal of Public Health},
	author = {Leider, Jonathon P. and Meit, Michael and McCullough, J. Mac and Resnick, Beth and Dekker, Debra and Alfonso, Y. Natalia and Bishai, David},
	month = sep,
	year = {2020},
	note = {Publisher: American Public Health Association},
	pages = {1283--1290},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/V9CUKL4L/Leider et al. - 2020 - The State of Rural Public Health Enduring Needs i.pdf:application/pdf},
}

@article{mccurdy_framework_2019,
	title = {A Framework for Externalizing Implicit Error Using Visualization},
	volume = {25},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/8449328/},
	doi = {10.1109/TVCG.2018.2864913},
	language = {en},
	number = {1},
	urldate = {2024-06-02},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Mccurdy, Nina and Gerdes, Julie and Meyer, Miriah},
	month = jan,
	year = {2019},
	pages = {925--935},
	file = {Mccurdy et al. - 2019 - A Framework for Externalizing Implicit Error Using.pdf:/Users/vsivaram/Zotero/storage/35E35LUQ/Mccurdy et al. - 2019 - A Framework for Externalizing Implicit Error Using.pdf:application/pdf},
}

@article{preim_survey_2020,
	title = {A Survey of Visual Analytics for Public Health},
	volume = {39},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13891},
	doi = {10.1111/cgf.13891},
	abstract = {We describe visual analytics solutions aiming to support public health professionals, and thus, preventive measures. Prevention aims at advocating behaviour and policy changes likely to improve human health. Public health strives to limit the outbreak of acute diseases as well as the reduction of chronic diseases and injuries. For this purpose, data are collected to identify trends in human health, to derive hypotheses, e.g. related to risk factors, and to get insights in the data and the underlying phenomena. Most public health data have a temporal character. Moreover, the spatial character, e.g. spatial clustering of diseases, needs to be considered for decision-making. Visual analytics techniques involve (subspace) clustering, interaction techniques to identify relevant subpopulations, e.g. being particularly vulnerable to diseases, imputation of missing values, visual queries as well as visualization and interaction techniques for spatio-temporal data. We describe requirements, tasks and visual analytics techniques that are widely used in public health before going into detail with respect to applications. These include outbreak surveillance and epidemiology research, e.g. cancer epidemiology. We classify the solutions based on the visual analytics techniques employed. We also discuss gaps in the current state of the art and resulting research opportunities in a research agenda to advance visual analytics support in public health.},
	language = {en},
	number = {1},
	urldate = {2023-11-20},
	journal = {Computer Graphics Forum},
	author = {Preim, Bernhard and Lawonn, Kai},
	year = {2020},
	keywords = {visualization, visual analytics, • Computer Applications → Life and Medical Sciences, medical imaging},
	pages = {543--580},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/JKDAYPCS/Preim and Lawonn - 2020 - A Survey of Visual Analytics for Public Health.pdf:application/pdf;Snapshot:/Users/vsivaram/Zotero/storage/CIJ8KGG2/cgf.html:text/html},
}

@book{ries_lean_2011,
	title = {The Lean Startup: {How} Today's Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses},
	isbn = {978-0-307-88789-4},
	shorttitle = {The {Lean} {Startup}},
	abstract = {Most startups fail. But many of those failures are preventable. The Lean Startup is a new approach being adopted across the globe, changing the way companies are built and new products are launched. Eric Ries defines a startup as an organization dedicated to creating something new under conditions of extreme uncertainty. This is just as true for one person in a garage or a group of seasoned professionals in a Fortune 500 boardroom. What they have in common is a mission to penetrate that fog of uncertainty to discover a successful path to a sustainable business. The Lean Startup approach fosters companies that are both more capital efficient and that leverage human creativity more effectively. Inspired by lessons from lean manufacturing, it relies on “validated learning,” rapid scientific experimentation, as well as a number of counter-intuitive practices that shorten product development cycles, measure actual progress without resorting to vanity metrics, and learn what customers really want. It enables a company to shift directions with agility, altering plans inch by inch, minute by minute. Rather than wasting time creating elaborate business plans, The Lean Startup offers entrepreneurs—in companies of all sizes—a way to test their vision continuously, to adapt and adjust before it’s too late. Ries provides a scientific approach to creating and managing successful startups in a age when companies need to innovate more than ever.},
	language = {en},
	publisher = {Crown},
	author = {Ries, Eric},
	month = sep,
	year = {2011},
	keywords = {Business \& Economics / Entrepreneurship, Business \& Economics / Management, Business \& Economics / New Business Enterprises},
}

@article{robinson_combining_2005,
	title = {Combining Usability Techniques to Design Geovisualization Tools for Epidemiology},
	volume = {32},
	issn = {1523-0406},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2786201/},
	doi = {10.1559/152304005775194700},
	abstract = {Designing usable geovisualization tools is an emerging problem in GIScience software development. We are often satisfied that a new method provides an innovative window on our data, but functionality alone is insufficient assurance that a tool is applicable to a problem in situ. As extensions of the static methods they evolved from, geovisualization tools are bound to enable new knowledge creation. We have yet to learn how to adapt techniques from interaction designers and usability experts toward our tools in order to maximize this ability. This is especially challenging because there is limited existing guidance for the design of usable geovisualization tools. Their design requires knowledge about the context of work within which they will be used, and should involve user input at all stages, as is the practice in any human-centered design effort. Toward that goal, we have employed a wide range of techniques in the design of ESTAT, an exploratory geovisualization toolkit for epidemiology. These techniques include; verbal protocol analysis, card-sorting, focus groups, and an in-depth case study. This paper reports the design process and evaluation results from our experience with the ESTAT toolkit.},
	number = {4},
	urldate = {2024-07-01},
	journal = {Cartography and geographic information science},
	author = {Robinson, Anthony C. and Chen, Jin and Lengerich, Eugene J. and Meyer, Hans G. and MacEachren, Alan M.},
	month = oct,
	year = {2005},
	pmid = {19960106},
	pmcid = {PMC2786201},
	pages = {243--255},
	file = {PubMed Central Full Text PDF:/Users/vsivaram/Zotero/storage/H7R3DKTI/Robinson et al. - 2005 - Combining Usability Techniques to Design Geovisual.pdf:application/pdf},
}

@article{rong_towards_2024,
	title = {Towards Human-Centered Explainable {AI}: {A} Survey of User Studies for Model Explanations},
	volume = {46},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {0162-8828, 2160-9292, 1939-3539},
	shorttitle = {Towards {Human}-{Centered} {Explainable} {AI}},
	url = {https://ieeexplore.ieee.org/document/10316181/},
	doi = {10.1109/TPAMI.2023.3331846},
	abstract = {Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how human-computer interaction (HCI) and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97 core papers with human-based XAI evaluations over the past ﬁve years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures in user studies, we propose practical guidelines on designing and conducting user studies for XAI researchers and practitioners. Lastly, this survey also highlights several open research directions, particularly linking psychological science and human-centered XAI.},
	language = {en},
	number = {4},
	urldate = {2024-07-02},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Rong, Yao and Leemann, Tobias and Nguyen, Thai-Trang and Fiedler, Lisa and Qian, Peizhu and Unhelkar, Vaibhav and Seidel, Tina and Kasneci, Gjergji and Kasneci, Enkelejda},
	month = apr,
	year = {2024},
	pages = {2104--2122},
	file = {Rong et al. - 2024 - Towards Human-Centered Explainable AI A Survey of.pdf:/Users/vsivaram/Zotero/storage/DPV9GQWZ/Rong et al. - 2024 - Towards Human-Centered Explainable AI A Survey of.pdf:application/pdf},
}

@article{yang_re-examining_2020,
	title = {Re-examining Whether, Why, and How Human-{AI} Interaction Is Uniquely Difficult to Design},
	doi = {10.1145/3313831.3376301},
	abstract = {Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Yang, Qian and Steinfeld, Aaron and Rosé, Carolyn and Zimmerman, John},
	year = {2020},
	keywords = {artificial intelligence, prototyping, sketching, user experience},
	pages = {1--13},
	file = {PDF:/Users/vsivaram/Zotero/storage/QDIPIF7K/3313831.3376301.pdf:application/pdf},
}

@inproceedings{yildirim_sketching_2024,
	address = {Honolulu HI USA},
	title = {Sketching {AI} Concepts with Capabilities and Examples: {AI} Innovation in the {Intensive} {Care} {Unit}},
	isbn = {9798400703300},
	shorttitle = {Sketching {AI} {Concepts} with {Capabilities} and {Examples}},
	url = {https://dl.acm.org/doi/10.1145/3613904.3641896},
	doi = {10.1145/3613904.3641896},
	language = {en},
	urldate = {2024-07-02},
	booktitle = {Proceedings of the {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Yildirim, Nur and Zlotnikov, Susanna and Sayar, Deniz and Kahn, Jeremy M. and Bukowski, Leigh A and Amin, Sher Shah and Riman, Kathryn A. and Davis, Billie S. and Minturn, John S. and King, Andrew J. and Ricketts, Dan and Tang, Lu and Sivaraman, Venkatesh and Perer, Adam and Preum, Sarah M. and McCann, James and Zimmerman, John},
	month = may,
	year = {2024},
	pages = {1--18},
	file = {Full Text PDF:/Users/vsivaram/Zotero/storage/SE7LB2GA/Yildirim et al. - 2024 - Sketching AI Concepts with Capabilities and Exampl.pdf:application/pdf},
}

