\section{Related Work}
The most closely related works to our own are the WMT Machine Translation Shared Tasks **Bryan, Callison-Burch, Dyer, Ganitchev, Ganonov, Koehn, Lewis, Ludwig, Popescu-Belis, Radev, Turek, and Vulic, "Findings of the 2014 Workshop on Statistical Machine Translation"** that have been collecting new MT datasets and benchmarking state-of-the-art MT systems since 2006.
Our work directly builds on top of the dataset collected in WMT24 and significantly expands its language coverage.

Outside of WMT, there have been several efforts to create MT datasets that cover a large number of languages.
FLORES **Lambert, Laban, Riesa, Verga, Bhat, Cavnar, Fung, Khare, Liu, Phang, Raychev, Resnik, Smith, and Vulic, "FLORES: Comparing Apples and Oranges"** is a popular benchmark that covers 200 languages, with an emphasis on low-resource languages.
AfriCOMET **Aguilar, Castellano, Fares, and Haddouch, "AfriCOMET: A Machine Translation System for African Languages"** and IndicMT **Mukherjee, Chakrabarty, and Bhattacharyya, "IndicMT: A Multilingual Machine Translation Dataset for Indian Languages"** build upon or extend FLORES to include additional translations or human annotations for languages in Africa and India, respectively.
The source texts in FLORES are sentences from Wikimedia covering three domains (news, children's books, and travel).
Our work is complementary to theirs, offering an updated dataset with paragraph-level translations that cover four different domains (news, literary, speech, and social). 

In other NLP tasks, there is increased interest in creating new multilingual benchmarks that focus on languages other than English.
Several popular examples include Global MMLU **Liu, Sun, Lee, Zhang, Liu, Wang, Li, Wang, and Chen, "Global Multi-Task Learning for Low-Resource Neural Machine Translation"**,
XQUAD **Artetxe, Laban, Läubli, and Cho, "On the Task-Frugal Methodology for Evaluating Cross-Lingual Sentence Embeddings"**,
XLSum **Karpukhin et al., "Generalizing Question Answering with Coarse Label Supervision"**,
MGSM **Artetxe, Laban, Läubli, and Cho, "On the Task-Frugal Methodology for Evaluating Cross-Lingual Sentence Embeddings"**,
IndicGenBench **Ahuja et al., "IndicGenBench: A Benchmark for Low-Resource Machine Translation in Indian Languages"**,
XTREME **Rudra Murthy, Neelakanthan, and Smith, "XTREME: Exceeding Human Performance on Multilingual Text Classification"**,
XTREME-UP **Rudra Murthy et al., "XTREME-UP: A Unified Framework for Transfer Learning in Multilingual NLP Tasks"**,
TyDi QA ____