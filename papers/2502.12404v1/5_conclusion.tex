\section{Conclusion}
In this work, we create a benchmark dataset called WMT24++ that extends the language coverage of WMT24 to include 55 languages and dialects.
Through our experiments evaluating different MT systems, we find that (1) MT systems appear to generate translations of higher quality than humans and (2) frontier LLMs are highly capable MT systems in a large number of languages.
Due to limitations of automatic metrics, both of the above conclusions should be verified with a human-based evaluation, which we intend to do in future work.

\section*{Acknowledgments}
The authors would like to thank Slav Petrov for his support of this project.