\section{Related Work}
The most closely related works to our own are the WMT Machine Translation Shared Tasks \citep[][\emph{inter alia}]{kocmi-etal-2024-findings} that have been collecting new MT datasets and benchmarking state-of-the-art MT systems since 2006.
Our work directly builds on top of the dataset collected in WMT24 and significantly expands its language coverage.

Outside of WMT, there have been several efforts to create MT datasets that cover a large number of languages.
FLORES \citep{flores101,nllb2022} is a popular benchmark that covers 200 languages, with an emphasis on low-resource languages.
AfriCOMET \citep{wang-etal-2024-afrimte} and IndicMT \citep{sai-b-etal-2023-indicmt} build upon or extend FLORES to include additional translations or human annotations for languages in Africa and India, respectively.
The source texts in FLORES are sentences from Wikimedia covering three domains (news, children's books, and travel).
Our work is complementary to theirs, offering an updated dataset with paragraph-level translations that cover four different domains (news, literary, speech, and social). 

In other NLP tasks, there is increased interest in creating new multilingual benchmarks that focus on languages other than English.
Several popular examples include Global MMLU \citep{singh2024globalmmluunderstandingaddressing},
XQUAD \citep{Artetxe:etal:2019},
XLSum \citep{hasan2021xlsumlargescalemultilingualabstractive},
MGSM \citep{shi2022languagemodelsmultilingualchainofthought},
IndicGenBench \citep{singh-etal-2024-indicgenbench},
XTREME \citep{hu2020xtreme},
XTREME-UP \citep{ruder-etal-2023-xtreme},
TyDi QA \citep{clark-etal-2020-tydi}.