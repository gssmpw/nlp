Learning how to invest in asset markets has been a central topic of study in both the economics and finance literature, as well as in computer science, where algorithmic approaches to decision-making and market dynamics have received growing attention. Generally, players in markets aim to maximize the utility they gain from their resulting wealth. A standard utility function used in both economics and computer science is the $\log$ of the player's wealth, leading to the objective of maximizing the growth rate of wealth\footnote{The economics literature on market selection also considers different objectives based on expected discounted utility of consumption. We consider asset markets in isolation and thus focus on growth rate. 
See the discussion in Sections \ref{sec:related-work} and \ref{sec:Bayesians}.} (see references below).

However, the two literatures take different approaches to learning---how learning agents  evaluate the feedback they receive and what methods they use to select their strategies---and they ask very different questions about the market dynamics. The literature in economics primarily focuses on Bayesian learning, while the computer science literature focuses on the framework of no-regret learning. While both Bayesian and no-regret learners modify their investment decisions over time, the assumptions about the learners and the measures of success are different. 

The economics literature studies Bayesian learning, assuming that agents have a prior about the underlying process and update their beliefs over time.  
If these agents correctly solve their decision problems, they succeed according to their own objectives. In the case that the agents' objective is expected growth rate and they reach correct beliefs, this aligns also with the external measure of success based on their wealth share in the market. 
Notably, however, in this approach learners do not directly respond to changes that they experience in their wealth, but rather learn about the underlying stochastic process and best respond to it according to their current beliefs, combining their prior with their experience.

The computer science literature makes no assumptions about the underlying process, allowing it to be adversarial, and focuses on no-regret learning, measuring the resulting outcome by the regret in growth rate compared to the best single strategy in hindsight; that is, the constant investment rule an investor would have used had they known the realization of the market variables. In the case of a market with a steady underlying process that we consider, this includes a comparison to the investor investing knowing the process (although this may not be the best strategy in hindsight for a given history; see Sections \ref{sec:compare} and \ref{sec:no-regret}).
Learning agents in this literature explicitly respond to the rate of change in their wealth at each step, considering it as the utility (or loss) input to their no-regret online learning algorithm. 

We study repeated interactions in asset markets with heterogeneous learning agents: both Bayesians and regret minimizers are present in the market and aim to maximize their expected growth rate of wealth. A question that naturally arises in this setting is whether one type of agent drives the other type out of the market. That is, does an agent's wealth share converge to zero (the agent vanishes) or does it remain bounded away from zero (the agent survives)? 
A version of this question has been studied in the economics literature in the context of the market selection hypothesis. The results there show that agents who do not correctly maximize expected growth rate vanish in the presence of agents who do correctly maximize expected growth rate.
(see the related work section for further discussion and references to this literature). 

We ask the market selection question for a market populated with a greater variety of learning agents. Some are Bayesian optimizers, some are Bayesians who make small mistakes in the set of models they consider or in updating their beliefs, and some use no-regret learning. A key question that arises is: what is the meaning or role of regret in this context? 
Regret-minimizing agents achieve low regret in the complete asset market we analyze, but we show that if there is a Bayesian who makes correct updates and whose prior on models puts positive probability on the correct model, then regret minimizers vanish. That is, surprisingly, {\em successfully reaching low regret does not guarantee survival}. However, we also show that {\em Bayesian learning is fragile}; if the Bayesian does not have the correct model within the support of its prior, or if the Bayesian does not correctly balance the prior and likelihood functions in updating, then the Bayesian almost surely vanishes relative to the no-regret leaner, even if the Bayesian makes arbitrarily small errors. 
