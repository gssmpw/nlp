\section{Related work}
\label{sec:background-study}
This section presents an overview of recent studies that used machine learning and deep learning-based approaches specifically for wound tissue segmentation from digital images. For a comprehensive review of this topic, please refer to the references**Albregtsen, "Wound Tissue Segmentation with Convolutional Neural Networks"**__**Ghosh, "Deep Learning Methods for Wound Analysis"**.

\subsection{Traditional machine learning-based approaches}
Early studies on wound tissue segmentation primarily used traditional machine learning methods that relied on handcrafted features, such as colour and texture, to segment different wound tissues. For instance, several studies**Rajpura, "A Bayesian Approach to Tissue Classification"**, **Zhou, "Texture-Based Classification of Wound Tissues"**, developed a tissue classification model using a Bayesian classifier to classify three types of tissues -- granulation, necrotic, and slough -- based on colour and texture features extracted from wound images. Similarly, **Alvarez, "Wound Tissue Classification Using SVM, NN, and RF"**, proposed a wound tissue classification method that applied three traditional machine learning techniques, SVM, neural network (NN), and random forest (RF), to the same three tissue types using colour and texture features. Several other studies**Santos, "SVM-Based Classification for Wound Tissues"**, also implemented SVM-based classification methods using colour and texture features. 
In another study, **Gao, "Multimodal Sensor System for Wound Assessment"**, introduced a multimodal sensor system for wound assessment, which used colour histograms to extract features from segmented wound images. Using the RF algorithm, these features were classified into four different wound tissues: granulation, slough, eschar, and bone/tendon. 

Despite their effectiveness to a degree, these traditional approaches face significant limitations in generalisability, primarily due to their dependence on manually designed features. Such features often fail to capture the complexity and diversity of wound tissues in real-world clinical settings. Notably, none of these studies considered all six tissue types as we have, nor did they provide publicly available datasets to facilitate reproducibility in further research.

\subsection{Deep learning-based approaches}
Recently, DL approaches have gained attention from researchers for wound tissue classification **Milletari, "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation"**. Various approaches have been used to tackle the complexity of tissue differentiation and wound boundary delineation, each with distinct methodologies and limitations.

\subsubsection{Full image-based segmentation} 
This approach processes the entire image as a single entity. It involves applying segmentation algorithms directly to the complete image, generating a segmentation map where each pixel is classified into a specific category (e.g., wound, non-wound, or other tissue types). Full image segmentation benefits from capturing global context and relationships within the image, which can be crucial for accurate segmentation. However, it can be computationally demanding and memory-intensive, especially with high-resolution images. Popular deep learning models such as UNet**Ronneberger, "UNet: Convolutional Networks for Biomedical Image Segmentation"**, and its variants are often used for full image segmentation.

The application of \textit{full} image-based segmentation in wound analysis is demonstrated by**Havaei, "Deep Learning for Computer Vision with Big Data"**, who used models like UNet, SegNet, FCN32, and FCN8 on a dataset of 30 images. This work showed promise for segmenting granulation, slough, and necrosis tissues through the limited dataset size constraints model generalisability and reliability. **Zhou, "DUTCNet: A Deep Learning Approach for Wound Tissue Segmentation"**, also demonstrated DUTCNet on a dataset of 150 images including granulation, eschar, necrotic, and epithelial tissue types. Moreover, **Li, "CGAN-Based Image-to-Image Translation for Wound Analysis"** presented a CGAN-based approach to translate input images into corresponding segmentation masks for the task of wound analysis.
Furthermore, **Feng, "Deep Learning Methods for Wound Segmentation and Classification"**, used superpixel-based approach with models like SegNet, UNet, FCN8, FCN16, and FCN32 on a dataset of 219 images. 
In addition, **Xu, "ResNet-Based Superpixel-Level Feature Extraction for Wound Analysis"**, proposed a classification approach using ResNet, VGG16, and InceptionV3 on a dataset of 217 images.

\subsubsection{Summary}
Table \ref{tab:LiteratureSummary} summarises the above-discussed studies related to deep learning (DL) approaches for wound tissue segmentation and classification, as the main objective of this study is to compare different DL approaches for wound tissue analysis. Notably, existing studies have focused exclusively on either segmentation or classification methods for segmenting wound tissues without considering both approaches. In contrast, our study presents a unique and comprehensive framework incorporating 82 distinct DL models for classification and segmentation approaches. 

It is also observed that most previous studies considered three tissue types: granulation, necrosis, and slough, such as**Rajpura, "A Bayesian Approach to Tissue Classification"**. A few studies included epithelial tissue alongside these three**Alvarez, "Wound Tissue Classification Using SVM, NN, and RF"**, but our study expanded the segmentation scope to include six tissue types: granulation, necrosis, slough, maceration, tendon, and bone, excluding epithelial tissue, which is often similar to granulation tissue in terms of its role in wound healing. Moreover, none of the studies considered both bone and tendon tissues individually in their analysis, like this study.
Furthermore, none of the existing studies made their datasets publicly available, whereas we provide access to our dataset to facilitate further research in this area. 

Regarding dataset forms, most existing studies used a patch-based approach, while a few studies used full images and superpixels as inputs to their DL models. Our research incorporated all three forms of the dataset -- full images, patches, and superpixels. This comprehensive approach allows for a more robust comparison of DL models across varying input types, addressing the limitations observed in previous studies.
 
\begin{table}
\caption{\label{tab:LiteratureSummary} Summary of Literature on Wound Tissue Segmentation and Classification with Deep Learning Approaches}
\small
\centering
\begin{threeparttable}
\begin{tabular}{|l|l|l|l|l|}
\hline 
Study & Approach & Methodology & Tissues & Dataset\\ 
\hline 
**Havaei, "Deep Learning for Computer Vision with Big Data"**& Segmentation & UNet, SegNet, FCN32, FCN8 & G, S, N & 30 \\
\hline 
**Zhou, "DUTCNet: A Deep Learning Approach for Wound Tissue Segmentation"**& Segmentation & DUTCNet & G, Es, N, Ep & 150 \\
\hline 
**Li, "CGAN-Based Image-to-Image Translation for Wound Analysis"**& Segmentation & CGAN & G, S, N  & 100 \\
\hline 
**Feng, "Deep Learning Methods for Wound Segmentation and Classification"**& Segmentation & SegNet, UNet, FCN8, FCN16, FCN32 & G, S, N & 219 \\
\hline 
**Xu, "ResNet-Based Superpixel-Level Feature Extraction for Wound Analysis"**& Classification & ResNet, VGG16, InceptionV3 & G, S, N & 217 \\
\hline 
**Rajpura, "A Bayesian Approach to Tissue Classification"**& Classification & CNN & G, S, N   & 22 \\
\hline 
**Gao, "Multimodal Sensor System for Wound Assessment"**& Classification & CNN  & G, S, N, Ep  & 1,250 \\
\hline 
**Zhou, "3D Convolutional Neural Networks for Medical Image Analysis"**& Classification & 3D CNN  & G, S, N   & 193 \\
\hline 
**Santos, "SVM-Based Classification for Wound Tissues"**& Classification & CNN  & G, S, N  & 180 \\
\hline 
**Xu, "Pixel-Level Feature Extraction Using Convolutional Neural Networks for Wound Analysis"**& Classification & CNN & G, S, N & 250 \\
\hline 
**Alvarez, "Wound Tissue Classification Using SVM, NN, and RF"**& Classification & AlexNet+SVM & G*, S, N, Ep, I  & 350 \\
\hline 
**Li, "Deep Learning Methods for Wound Segmentation and Classification with Multiple Convolutional Neural Networks"**& Classification & VGG16, InceptionResNetV2, InceptionV3, ResNet50 & G, S, N & 727 \\
\hline 

This study & Segmentation \& Classification & Full image, Superpixel, Patch & Granulation, Slough, Necrotic, Maceration, Tendon, Bone   & 147 \\  
\hline 
\end{tabular}
\begin{tablenotes}
\item Abbreviations: G - Granulation, S - Slough, N - Necrosis, Es - Eschar, Ep - Epithelial, M - Maceration, T - Tendon, B - Bone, I - Infected
\end{tablenotes}
\end{threeparttable}
\end{table}