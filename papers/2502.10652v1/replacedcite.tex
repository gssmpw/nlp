\section{Related work}
\label{sec:background-study}
This section presents an overview of recent studies that used machine learning and deep learning-based approaches specifically for wound tissue segmentation from digital images. For a comprehensive review of this topic, please refer to the references____.

\subsection{Traditional machine learning-based approaches}
Early studies on wound tissue segmentation primarily used traditional machine learning methods that relied on handcrafted features, such as colour and texture, to segment different wound tissues. For instance, several studies____ developed a tissue classification model using a Bayesian classifier to classify three types of tissues -- granulation, necrotic, and slough -- based on colour and texture features extracted from wound images. Similarly, ____ proposed a wound tissue classification method that applied three traditional machine learning techniques, SVM, neural network (NN), and random forest (RF), to the same three tissue types using colour and texture features. Several other studies____ also implemented SVM-based classification methods using colour and texture features. 
In another study, ____ introduced a multimodal sensor system for wound assessment, which used colour histograms to extract features from segmented wound images. Using the RF algorithm, these features were classified into four different wound tissues: granulation, slough, eschar, and bone/tendon. 

Despite their effectiveness to a degree, these traditional approaches face significant limitations in generalisability, primarily due to their dependence on manually designed features. Such features often fail to capture the complexity and diversity of wound tissues in real-world clinical settings. Notably, none of these studies considered all six tissue types as we have, nor did they provide publicly available datasets to facilitate reproducibility in further research.

\subsection{Deep learning-based approaches}
Recently, DL approaches have gained attention from researchers for wound tissue classification ____. Various approaches have been used to tackle the complexity of tissue differentiation and wound boundary delineation, each with distinct methodologies and limitations.

\subsubsection{Full image-based segmentation} 
This approach processes the entire image as a single entity. It involves applying segmentation algorithms directly to the complete image, generating a segmentation map where each pixel is classified into a specific category (e.g., wound, non-wound, or other tissue types). Full image segmentation benefits from capturing global context and relationships within the image, which can be crucial for accurate segmentation. However, it can be computationally demanding and memory-intensive, especially with high-resolution images. Popular deep learning models such as UNet____ and its variants are often used for full image segmentation.

The application of \textit{full} image-based segmentation in wound analysis is demonstrated by____, who used models like UNet, SegNet, FCN32, and FCN8 on a dataset of 30 images. This work showed promise for segmenting granulation, slough, and necrosis tissues through the limited dataset size constraints model generalisability and reliability. ____ further advanced this approach with DUTCNet, a model capable of distinguishing more diverse tissue types, including eschar and epithelial tissues, across a larger dataset of 150 images. This model demonstrated potential for capturing more nuanced tissue type differences but did not address high variability across different patient populations.
____ introduced a conditional generative adversarial network (CGAN) for simultaneous boundary detection and tissue classification. The CGAN approach uniquely facilitates more complex interactions between tissue types, although it relies on a relatively small dataset of 100 images, which could limit accuracy in more varied real-world scenarios. While full image-based segmentation provides a broad contextual overview, it requires extensive labelled data and computational resources, especially with more sophisticated models like CGANs, which are sensitive to dataset diversity and size.

\subsubsection{Superpixel-based segmentation}
In contrast to full image-based approaches, superpixel-based segmentation divides the image into clusters of pixels, referred to as superpixels, which share similar characteristics such as colour, texture, or intensity. These superpixels are used as the basic units for segmentation instead of classifying individual pixels. The main advantage of superpixel-based segmentation is the reduction in the number of elements to be classified, leading to faster and more efficient processing. Moreover, superpixels capture essential local structures and preserve boundaries more effectively than traditional pixel-wise methods. This approach effectively balances the need to capture local details and maintain computational efficiency.

____ applied superpixel-based segmentation with models like SegNet, UNet, and FCN variants (FCN8, FCN16, FCN32) on a dataset of 219 images, achieving precise segmentation of wound tissues such as granulation, slough, and necrosis. This approach demonstrated that superpixel-based segmentation can yield accurate results with fewer computational resources than full image processing, making it a feasible solution for clinical applications with limited hardware.
Similarly,____ leveraged superpixel-based segmentation for dermatological wound analysis, applying feature extraction models like ResNet and VGG16 on 217 images. These models enhanced classification performance by focusing on specific wound regions, although they are limited by their reliance on well-defined tissue boundaries, which are not always present in ulcer images. Superpixel-based segmentation thus balances processing efficiency and localised accuracy, but it may struggle with more heterogeneous ulcer images where tissue types blend gradually. 

\subsubsection{Patch-based segmentation}
Patch-based segmentation represents an intermediary approach wherein an image is divided into smaller patches, either overlapping or non-overlapping patches, and each patch is processed independently.
In patch-based approaches, the segmentation problem is often transformed into a classification problem by dividing the image into smaller patches and classifying each patch according to its tissue type, simplifying the segmentation task into a series of patch-level classifications.
Each patch is then classified or segmented, and the results are subsequently combined to form the final segmentation map. This approach can be advantageous in handling high-resolution images and reducing computational load as the model processes smaller sections of the image at a time. Patch-based segmentation is particularly suitable for training deep learning models on small datasets, effectively increasing the training data size without requiring additional full images.
Furthermore, it improves the focus on local features within the image. However, this approach may encounter difficulties in capturing the global context and can produce artifacts at the boundaries of the patches. Models like convolutional neural networks (CNNs)____ commonly perform segmentation tasks on patches.

One of the foundational studies using this approach was conducted by____. Wound images were partitioned into small patches of $5\times5$ pixels, and a CNN was used for tissue classification. This method allowed for high granularity in distinguishing tissue types by concentrating on local features within each patch, though the small patch size necessitates a significant number of patches per image, increasing computational demand. ____ expanded upon this approach by combining deep learning with machine learning; they divided wound images into larger $20\times20$ patches and used AlexNet to extract features, followed by an SVM classifier to categorise each patch. This hybrid model demonstrated improved accuracy in classifying tissue types, suggesting that patch size and feature extraction methods can significantly impact classification performance.

____ implemented a 4-layer CNN for tissue classification of ulcer images, using the patch-based approach to improve the model's focus on subtle tissue variations within wound images. ____ further explored patch-based analysis with a 3D CNN, dividing images into $5\times5$ pixel patches to leverage depth information for pressure ulcer classification. This model emphasised spatial depth features, enhancing the classification of granulation and necrosis tissues but requiring high computational resources. Similarly, ____ used four commonly available CNN architectures, employing the same $5 \times 5$ patch size for their analyses.

In contrast, ____ used a pixel-based feature extraction approach, using a $9 \times 9$ mask window that scanned over each pixel in the tissue regions to extract relevant features, processed using an autoencoder-based CNN. Lastly, ____ implemented a simpler CNN architecture that operated on larger $31 \times 31$ pixel patches. These studies highlight the diversity in tissue segmentation and classification methodologies, emphasising how variations in patch sizes and feature extraction techniques can affect model performance.

Overall, patch-based segmentation offers flexibility in wound tissue analysis by turning segmentation into a classification task, making it feasible for models to learn from limited data. Patch size, feature extraction method, and CNN architecture selection are all critical to optimising the accuracy of these models. However, this approach may sacrifice some global context, as each patch is classified independently without considering neighbouring patches, which could lead to misclassification in highly heterogeneous wound images.



\begin{table}[!htb]
\centering
    \caption{Summary of the DL-based studies}
    \label{tab:LiteratureSummary}
\resizebox{\columnwidth}{!}{
\begin{tabular}{@{\extracolsep{4pt}}cclllrc}
\hline
\multirow{2}{*}{Study} & \multicolumn{3}{c}{Method} & \multicolumn{3}{c}{Dataset}\\
\cline{2-4} \cline{5-7}
% & Approach & Input type& \multicolumn{1}{c|}{Model} & Tissue type &  \makecell[t c]{Image\\count} & \makecell[t l]{Available\\ publicly}\\ \hline\hline

% \multirow{2}{*} {Study} 
 & Approach & Input type& Model & Tissue &  \makecell[t c]{Image\\count} & \makecell[t l]{Available}\\ \hline\hline

____ & Segmentation & Full image &  \makecell[t l]{UNet, SegNet, FCN32, FCN8} & G, S, N & 30 & No \\ 
% \hline
    % \cline{2-7}
____ & Segmentation & Full image & DUTCNet & G, Es, N, Ep & 150 & No\\


% \hline 
% \cline{2-7} 
                      
____ & Segmentation & Full image & CGAN & G, S, N  & 100 & No \\ 
% \hline
____ & Segmentation & Superpixel & \makecell[t l]{SegNet, UNet, FCN8, FCN16, FCN32} & G, S, N &  219 & No  \\ 
  
____ & Classification & Superpixel & \makecell[t l]{ResNet, VGG16, InceptionV3} & G, S, N &  217 & No \\ 
% \hline

____ & Classification & Patch & CNN & G, S, N   & 22 & No \\ 
                     % \hline
                    
% \multirow{6}{*}{Classification} & ____ & CNN  & Granulation, Slough, Necrotic, Epithelial & Patch & 1,250 & No\\ \cline{2-7}
____ & Classification & Patch & CNN  & G, S, N, Ep  & 1,250 & No\\ 
% \hline
                    
____ & Classification & Patch & 3D CNN  & G, S, N   & 193 & No \\ %RW36elmogy2018tissues
                   % \hline
                    
                 %  & ____ & CNN  & Granulation, Slough, Necrotic  & Patches ($7\times7$) & 3168,778 (approx.) & not available \\ \cline{2-7} 
                   
____ & Classification  & Patch & CNN  & G, S, N  & 180 & No \\ 
                  % \hline
                   
____ & Classification & Pixel  & CNN & G, S, N & 250 & No \\ 
% \hline 
____ & Classification & Patch & AlexNet+SVM & G*, S, N, Ep, I  & 350 &  No\\ 

____ & Classification & Patch & \makecell[t l]{VGG16, InceptionResNetV2,\\InceptionV3, ResNet50} & G, S, N & 727 & No\\
                   

\hline
                   
% This study & Segmentation \&\\Classification & Full image,\\Patch, \\Superpixel &  State-of-the-art\\ DL models & Granulation, Slough, Necrotic, Maceration, Tendon, Bone   & 147 & Yes\\  \hline 
                
This study & \makecell[t l]{Segmentation and\\Classification} & \makecell[t l]{Full image,\\Superpixel,\\Patch} & \makecell[t l]{State-of-the-art 82\\ DL approaches} & G, S, N,\textbf{ M}, \textbf{T}, \textbf{B}   & 147 & Yes\\  
\hline 

\hline
\multicolumn{7}{l}{G - Granulation, S - Slough, N - Necrosis, Es - Eschar, Ep - Epethelial, M - Maceration, T - Tendon, B - Bone, I - Infected}\\
\multicolumn{7}{l}{*Classified Granulation (G) tissue as Healthy Granulation, Unhealthy Granulation, and Hyper Granulation}
\end{tabular}
}
\end{table}

\subsubsection{Summary}
Table \ref{tab:LiteratureSummary} summarises the above-discussed studies related to deep learning (DL) approaches for wound tissue segmentation and classification, as the main objective of this study is to compare different DL approaches for wound tissue analysis. Notably, existing studies have focused exclusively on either segmentation or classification methods for segmenting wound tissues without considering both approaches. In contrast, our study presents a unique and comprehensive framework incorporating 82 distinct DL models for classification and segmentation approaches. 

It is also observed that most previous studies considered three tissue types: granulation, necrosis, and slough, such as ____. A few studies included epithelial tissue alongside these three ____. In contrast, our study expanded the segmentation scope to include six tissue types: granulation, necrosis, slough, maceration, tendon, and bone, excluding epithelial tissue, which is often similar to granulation tissue in terms of its role in wound healing. Moreover, none of the studies considered both bone and tendon tissues individually in their analysis, like this study.
Furthermore, none of the existing studies made their datasets publicly available, whereas we provide access to our dataset to facilitate further research in this area. 

Regarding dataset forms, most existing studies used a patch-based approach, while a few studies used full images and superpixels as inputs to their DL models. Our research incorporated all three forms of the dataset -- full images, patches, and superpixels. This comprehensive approach allows for a more robust comparison of DL models across varying input types, addressing the limitations observed in previous studies.