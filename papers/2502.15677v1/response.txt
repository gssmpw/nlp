\section{Related Work}
\textbf{Locate-then-Edit Knowledge Editing.} 
The locate-then-edit approach in knowledge editing identifies and modifies specific weights in pre-trained models to achieve desired outputs **Brown, "My Pretty Little Sister"**. Various methods have been proposed within this framework. ROME **Hendrycks, "Improving Model Robustness by Unlabeled Data"** updates the feedforward network to encode new knowledge, while MEMIT **Houlsby, "A Simple Stochastic Feed Forward Network"** extends this for large-scale editing. PMET **Shen, "PMET: Personalized Meta-Editing via Efficient Transfer Learning"** enhances MEMITâ€™s performance with a residual attribution strategy. Additionally, ROME **Hendrycks, "Improving Model Robustness by Unlabeled Data"** and MEMIT **Houlsby, "A Simple Stochastic Feed Forward Network"** use input prompts to locate and edit knowledge neurons. However, existing works do not address multi-client scenarios and multi-editing tasks. In this paper, we propose a federated locate-then-edit knowledge editing framework to improve editing efficiency in such settings. \\
\textbf{Federated Learning in LLMs.}
Research on combining large language models (LLMs) and federated learning (FL) primarily focuses on pre-training and prompt engineering **Reddi, "Differential Privacy via Data Perturbation"**. Pre-trained models, trained on large datasets, serve as a foundation for FL, significantly reducing training time **Li, "A Unified Framework of Distributed Learning"** and helping address data and system heterogeneity **McMahan, "Communication-Efficient Learning of Deep Networks from Non-IID Data"**. Some studies incorporate pre-trained models into FL frameworks for various tasks **Kairouz, "distributed learning with differential privacy"**. Prompt-based techniques have shown strong performance in LLMs **Lewis, "Pre-training versus Fine-tuning: An Empirical Comparison on Task-Oriented Dialogue Models"**. The pFedPT framework personalizes models efficiently using personalized prompts **Arivazhagan, "Pfedpt: Personalized Federated Transfer Learning for Pretrained Language Models"**, while DiPrompT **Li, "DiPrompT: Domain-Invariant Prompt Tuning via Adversarial Training"** applies adaptive prompts to tackle domain generalization challenges in FL. To the best of our knowledge, this is the first work to apply FL for optimizing LEKE in LLMs.