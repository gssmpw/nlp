% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{r1,
  title={Gpt-neox-20b: An open-source autoregressive language model},
  author={Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and others},
  journal={arXiv preprint arXiv:2204.06745},
  year={2022}
}
@article{r2,
  title={Mass-editing memory in a transformer},
  author={Meng, Kevin and Sharma, Arnab Sen and Andonian, Alex and Belinkov, Yonatan and Bau, David},
  journal={arXiv preprint arXiv:2210.07229},
  year={2022}
}
@inproceedings{r3,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}
@article{r4,
  title={Zero-shot relation extraction via reading comprehension},
  author={Levy, Omer and Seo, Minjoon and Choi, Eunsol and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1706.04115},
  year={2017}
}
@article{r5,
  title={Locating and editing factual associations in GPT},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}
@article{r6,
  title={Fast Model Editing at Scale},
  author={Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Finn, Chelsea and Manning, Christopher D}
}
@inproceedings{r7,
  title={Pmet: Precise model editing in a transformer},
  author={Li, Xiaopeng and Li, Shasha and Song, Shezheng and Yang, Jing and Ma, Jun and Yu, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={18564--18572},
  year={2024}
}
@article{r8,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}
@article{r9,
  title={Knowledge editing for large language models: A survey},
  author={Wang, Song and Zhu, Yaochen and Liu, Haochen and Zheng, Zaiyi and Chen, Chen and Li, Jundong},
  journal={ACM Computing Surveys},
  volume={57},
  number={3},
  pages={1--37},
  year={2024},
  publisher={ACM New York, NY}
}
@article{r10,
  title={Editing factual knowledge in language models},
  author={De Cao, Nicola and Aziz, Wilker and Titov, Ivan},
  journal={arXiv preprint arXiv:2104.08164},
  year={2021}
}
@article{r11,
  title={A comprehensive study of knowledge editing for large language models},
  author={Zhang, Ningyu and Yao, Yunzhi and Tian, Bozhong and Wang, Peng and Deng, Shumin and Wang, Mengru and Xi, Zekun and Mao, Shengyu and Zhang, Jintian and Ni, Yuansheng and others},
  journal={arXiv preprint arXiv:2401.01286},
  year={2024}
}
@article{r12,
  title={Editing large language models: Problems, methods, and opportunities},
  author={Yao, Yunzhi and Wang, Peng and Tian, Bozhong and Cheng, Siyuan and Li, Zhoubo and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2305.13172},
  year={2023}
}
@article{r13,
  title={Time Sensitive Knowledge Editing through Efficient Finetuning},
  author={Ge, Xiou and Mousavi, Ali and Grave, Edouard and Joulin, Armand and Qian, Kun and Han, Benjamin and Arefiyan, Mostafa and Li, Yunyao},
  journal={arXiv preprint arXiv:2406.04496},
  year={2024}
}
@article{r14,
  title={Federated Learning: Strategies for Improving Communication Efficiency},
  author={Kone{\v{c}}n{\`y}, Jakub},
  journal={arXiv preprint arXiv:1610.05492},
  year={2016}
}
@inproceedings{r15,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}
@article{r16,
  title={Applied federated learning: Improving google keyboard query suggestions},
  author={Yang, Timothy and Andrew, Galen and Eichner, Hubert and Sun, Haicheng and Li, Wei and Kong, Nicholas and Ramage, Daniel and Beaufays, Fran{\c{c}}oise},
  journal={arXiv preprint arXiv:1812.02903},
  year={2018}
}
@article{r17,
  title={Investigating Multi-Hop Factual Shortcuts in Knowledge Editing of Large Language Models},
  author={Ju, Tianjie and Chen, Yijin and Yuan, Xinwei and Zhang, Zhuosheng and Du, Wei and Zheng, Yubin and Liu, Gongshen},
  journal={arXiv preprint arXiv:2402.11900},
  year={2024}
}
@inproceedings{r18,
  title={EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation},
  author={Liu, Jiateng and Yu, Pengfei and Zhang, Yuji and Li, Sha and Zhang, Zixuan and Sarikaya, Ruhi and Small, Kevin and Ji, Heng},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={4907--4926},
  year={2024}
}
@inproceedings{r19,
  title={PFEDEDIT: Personalized Federated Learning via Automated Model Editing},
  author={Yuan, Haolin and Paul, William and Aucott, John and Burlina, Philippe and Cao, Yinzhi},
  booktitle={European Conference on Computer Vision},
  pages={91--107},
  year={2024},
  organization={Springer}
}
@misc{r20,
  title={GPT-J-6B: A 6 billion parameter autoregressive language model},
  author={Wang, Ben and Komatsuzaki, Aran},
  year={2021}
}
@article{r21,
  title={A survey on federated learning systems: Vision, hype and reality for data privacy and protection},
  author={Li, Qinbin and Wen, Zeyi and Wu, Zhaomin and Hu, Sixu and Wang, Naibo and Li, Yuan and Liu, Xu and He, Bingsheng},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={35},
  number={4},
  pages={3347--3366},
  year={2021},
  publisher={IEEE}
}
@article{r22,
  title={Differential privacy for deep and federated learning: A survey},
  author={El Ouadrhiri, Ahmed and Abdelhadi, Ahmed},
  journal={IEEE access},
  volume={10},
  pages={22359--22380},
  year={2022},
  publisher={IEEE}
}
@article{r23,
  title={A robust privacy-preserving federated learning model against model poisoning attacks},
  author={Yazdinejad, Abbas and Dehghantanha, Ali and Karimipour, Hadis and Srivastava, Gautam and Parizi, Reza M},
  journal={IEEE Transactions on Information Forensics and Security},
  year={2024},
  publisher={IEEE}
}
@article{r24,
  title={Detoxifying Large Language Models via Knowledge Editing},
  author={Wang, Mengru and Zhang, Ningyu and Xu, Ziwen and Xi, Zekun and Deng, Shumin and Yao, Yunzhi and Zhang, Qishen and Yang, Linyi and Wang, Jindong and Chen, Huajun},
  journal={arXiv preprint arXiv:2403.14472},
  year={2024}
}
@article{r25,
  title={Rebuilding rome: Resolving model collapse during sequential model editing},
  author={Gupta, Akshat and Baskaran, Sidharth and Anumanchipalli, Gopala},
  journal={arXiv preprint arXiv:2403.07175},
  year={2024}
}
@article{r26,
  title={Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing},
  author={Zhang, Zhuoran and Li, Yongxiang and Kan, Zijian and Cheng, Keyuan and Hu, Lijie and Wang, Di},
  journal={arXiv preprint arXiv:2410.06331},
  year={2024}
}
@article{r27,
  title={Can Knowledge Editing Really Correct Hallucinations?},
  author={Huang, Baixiang and Chen, Canyu and Xu, Xiongxiao and Payani, Ali and Shu, Kai},
  journal={arXiv preprint arXiv:2410.16251},
  year={2024}
}
@article{r28,
  title={Pearson correlation coefficient},
  author={Cohen, Israel and Huang, Yiteng and Chen, Jingdong and Benesty, Jacob and Benesty, Jacob and Chen, Jingdong and Huang, Yiteng and Cohen, Israel},
  journal={Noise reduction in speech processing},
  pages={1--4},
  year={2009},
  publisher={Springer}
}
@inproceedings{locate-then-edit-1,
  title={Memory-based model editing at scale},
  author={Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Manning, Christopher D and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={15817--15831},
  year={2022},
  organization={PMLR}
}
@article{locate-then-edit-2,
  title={Editing large language models: Problems, methods, and opportunities},
  author={Yao, Yunzhi and Wang, Peng and Tian, Bozhong and Cheng, Siyuan and Li, Zhoubo and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2305.13172},
  year={2023}
}
@article{locate-then-edit-strategies,
  title={Knowledge editing for large language models: A survey},
  author={Wang, Song and Zhu, Yaochen and Liu, Haochen and Zheng, Zaiyi and Chen, Chen and Li, Jundong},
  journal={ACM Computing Surveys},
  volume={57},
  number={3},
  pages={1--37},
  year={2024},
  publisher={ACM New York, NY}
}
@article{KD,
  title={Knowledge neurons in pretrained transformers},
  author={Dai, Damai and Dong, Li and Hao, Yaru and Sui, Zhifang and Chang, Baobao and Wei, Furu},
  journal={arXiv preprint arXiv:2104.08696},
  year={2021}
}
@article{DEPN,
  title={Depn: Detecting and editing privacy neurons in pretrained language models},
  author={Wu, Xinwei and Li, Junzhuo and Xu, Minghui and Dong, Weilong and Wu, Shuangzhi and Bian, Chao and Xiong, Deyi},
  journal={arXiv preprint arXiv:2310.20138},
  year={2023}
}
@article{ROME,
  title={Locating and editing factual associations in GPT},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}
@article{MEIMT,
  title={Mass-editing memory in a transformer},
  author={Meng, Kevin and Sharma, Arnab Sen and Andonian, Alex and Belinkov, Yonatan and Bau, David},
  journal={arXiv preprint arXiv:2210.07229},
  year={2022}
}
@inproceedings{PMET,
  title={Pmet: Precise model editing in a transformer},
  author={Li, Xiaopeng and Li, Shasha and Song, Shezheng and Yang, Jing and Ma, Jun and Yu, Jie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={18564--18572},
  year={2024}
}
@article{BIRD,
  title={Untying the reversal curse via bidirectional language model editing},
  author={Ma, Jun-Yu and Gu, Jia-Chen and Ling, Zhen-Hua and Liu, Quan and Liu, Cong},
  journal={arXiv preprint arXiv:2310.10322},
  year={2023}
}

@article{fl-llm-time1,
  title={Federated learning from pre-trained models: A contrastive learning approach},
  author={Tan, Yue and Long, Guodong and Ma, Jie and Liu, Lu and Zhou, Tianyi and Jiang, Jing},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={19332--19344},
  year={2022}
}

@inproceedings{fl-llm-time2,
  title={Language-Guided Transformer for Federated Multi-Label Classification},
  author={Liu, I-Jieh and Lin, Ci-Siang and Yang, Fu-En and Wang, Yu-Chiang Frank},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={12},
  pages={13882--13890},
  year={2024}
}

@article{fl-llm-non-iid,
  title={Where to begin? on the impact of pre-training and initialization in federated learning},
  author={Nguyen, John and Wang, Jianyu and Malik, Kshitiz and Sanjabi, Maziar and Rabbat, Michael},
  journal={arXiv preprint arXiv:2206.15387},
  year={2022}
}

@inproceedings{pre-fl1,
  title={Practical Takes on Federated Learning with Pretrained Language Models},
  author={Agarwal, Ankur and Rezagholizadeh, Mehdi and Parthasarathi, Prasanna},
  booktitle={Findings of the Association for Computational Linguistics: EACL 2023},
  pages={454--471},
  year={2023}
}

@article{pre-fl2,
  title={Next-chat: An lmm for chat, detection and segmentation},
  author={Zhang, Ao and Zhao, Liming and Xie, Chen-Wei and Zheng, Yun and Ji, Wei and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2311.04498},
  year={2023}
}

@article{promptfl,
  title={Promptfl: Let federated participants cooperatively learn prompts instead of models-federated learning in age of foundation model},
  author={Guo, Tao and Guo, Song and Wang, Junxiao and Tang, Xueyang and Xu, Wenchao},
  journal={IEEE Transactions on Mobile Computing},
  year={2023},
  publisher={IEEE}
}

@article{personlization,
  title={Visual prompt based personalized federated learning},
  author={Li, Guanghao and Wu, Wansen and Sun, Yan and Shen, Li and Wu, Baoyuan and Tao, Dacheng},
  journal={arXiv preprint arXiv:2303.08678},
  year={2023}
}

@inproceedings{DiPrompT,
  title={DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning},
  author={Bai, Sikai and Zhang, Jie and Guo, Song and Li, Shuaicheng and Guo, Jingcai and Hou, Jun and Han, Tao and Lu, Xiaocheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27284--27293},
  year={2024}
}

@article{fl-llm,
  title={Integration of large language models and federated learning},
  author={Chen, Chaochao and Feng, Xiaohua and Li, Yuyuan and Lyu, Lingjuan and Zhou, Jun and Zheng, Xiaolin and Yin, Jianwei},
  journal={Patterns},
  volume={5},
  number={12},
  year={2024},
  publisher={Elsevier}
}