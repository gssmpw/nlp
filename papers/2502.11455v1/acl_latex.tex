% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{subcaption}
\usepackage{array}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{xcolor} 
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
\newcommand{\partitle}[1]{\smallskip \noindent \textbf{#1.}}

\title{Adversary-Aware DPO: Enhancing Safety Alignment in Vision Language Models via Adversarial Training}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
Fenghua Weng$^{1}$ \quad 
Jian Lou$^{2}$ \quad 
Jun Feng$^{3}$ \quad
Minlie Huang$^{4}$ \quad
Wenjie Wang$^{1}$ \Thanks{ W.Wang is the corresponding author.} \\ 
$^1$ShanghaiTech University,  $^{2}$Sun Yat-Sen University    \\
$^{3}$Huazhong University of Science and Technology, $^{4}$Tsinghua University \\
\texttt{\normalsize \{wengfh2023,wangwj1\}@shanghaitech.edu.cn} \\
\texttt{\normalsize louj5@mail.sysu.edu.cn}, \texttt{\normalsize junfeng@hust.edu.cn}, \texttt{\normalsize aihuang@tsinghua.edu.cn} \\
}

\begin{document}
\maketitle
\begin{abstract}
Safety alignment is critical in pre-training large language models (LLMs) to generate responses aligned with human values and refuse harmful queries. Unlike LLM, the current safety alignment of VLMs is often achieved with post-hoc safety fine-tuning. However, these methods are less effective to white-box attacks. To address this, we propose \textit{Adversary-aware DPO (ADPO)}, a novel training framework that explicitly considers adversarial. \textit{Adversary-aware DPO (ADPO)} integrates adversarial training into DPO to enhance the safety alignment of VLMs under worst-case adversarial perturbations. \textit{ADPO} introduces two key components: (1) an adversarial-trained reference model that generates human-preferred responses under worst-case perturbations, and (2) an adversarial-aware DPO loss that generates winner-loser pairs accounting for adversarial distortions. By combining these innovations, \textit{ADPO} ensures that VLMs remain robust and reliable even in the presence of sophisticated jailbreak attacks. Extensive experiments demonstrate that \textit{ADPO} outperforms baselines in the safety alignment and general utility of VLMs. 
\end{abstract}


\input{latex/intro}
\input{latex/related}
\input{latex/method}
\input{latex/experiment}

\vspace{-0.5em}
\section{Conclusion}
\vspace{-0.5em}
We propose \textit{ADPO}, a novel training framework to enhance safety alignment of Vision-Language Models (VLMs) under adversarial scenarios. Compared with baselines, \textit{ADPO} demonstrates its effectiveness through extensive experiments, achieving an ASR close to 0 across nearly all jailbreak attacks. Furthermore, we also visualize the shift in the latent space to further validate the effectiveness of \textit{ADPO}. The results underscore the potential of \textit{ADPO} as a robust solution for enhancing the safety alignment of VLMs. It would be interesting to investigate refined fine-tuning strategies that better balance the trade-off between safety and utility in the future.



\input{latex/limitations}
\input{latex/ethics}

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{acl_latex}

\cleardoublepage
\appendix




\section{Utility Benchmarks}
\label{utility benchmark}
\partitle{MMStar} MMStar is a benchmark for multimodal multiple-choice questions, consisting of 1,500 samples that assess six fundamental capabilities of vision-language models (VLMs): fine-grained perception, coarse perception, mathematics, science and technology, logical reasoning, and instance reasoning. The metric used to evaluate MMStar is accuracy and is calculated by some heuristic rules.

\partitle{OCRBench} OCRBench is a comprehensive Optical Character Recognition (OCR) benchmark to assess the OCR capabilities for VLMs. It comprises 1,000 question-answer pairs, and its evaluation metric is based on the number of outputs that match the ground truth answers.

\partitle{MM-Vet} MM-Vet is an evaluation benchmark that examines VLM on six core capabilities, including recognition, OCR, knowledge, language generation, spatial awareness, and math. For each sample, MM-Vet score is calculated by GPT-4 based on the input question, ground truth, and model output.

\partitle{LLaVABench} LLaVABench contains 60 samples in three categories: conversation, detailed description, and complex reasoning. The evaluation score is determined by GPT-4, which compares the generated answer to a reference answer.


\section{Hyperparameter Choices}
\label{Hyperparameter}

Table \ref{Hyperparameter table} presents a full list of hyperparameter choices for each fine tuning method. 

\begin{table}[ht]
    \centering
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{c c|c c c c c c}
    \hline
       & Hyperparameter & FT & AT & DPO & \textit{AR-DPO} & \textit{AT-DPO} & \textit{ADPO} \\
        \hline
       \multirow{7}{*}{\rotatebox{90}{LLaVA-1.5-7b}} &Learning rate & 2e-5 & 2e-5 & 2e-5 & 2e-5 & 2e-5 & 2e-5 \\
        &Batch size & 64 & 64 & 64 & 64 & 64 & 64 \\
        &Epochs & 2 & 2 & 10 & 5 & 10 & 5 \\
        &$\alpha$ & 30 & 30  & - & - & - & -  \\
        &$\beta$ & - & - & 0.1 & 0.01 & 0.1 & 0.01 \\
        &Lora r & 128 & 128 & 128 & 128 & 128 & 128 \\
        &Lora alpha & 256 & 256 & 256 & 256 & 256 & 256 \\
        \hline
       \multirow{7}{*}{\rotatebox{90}{LLaVA-1.6-7b}} &Learning rate & 2e-5 & 2e-5 & 2e-5 & 2e-5 & 2e-5 & 2e-5 \\
        &Batch size & 64 & 64 & 64 & 64 & 64 & 64 \\
        &Epochs & 2 & 2 & 10 & 5 & 10 & 5 \\
        &$\alpha$ & 0.6 & 0.6  & - & - & - & -  \\
        &$\beta$ & - & - & 0.1 & 0.1 & 0.1 & 0.1 \\
        &Lora r & 128 & 128 & 128 & 128 & 128 & 128 \\
        &Lora alpha & 256 & 256 & 256 & 256 & 256 & 256 \\
        \hline        
    \end{tabular}}
    \caption{Hyperparameters for \texttt{LLaVA-1.5-7b} and \texttt{LLaVA-1.6-7b} with different fine-tuning settings.}
\label{Hyperparameter table}
\end{table}

\section{Additional Experimental Results}
\subsection{Radar chart of LLaVA-1.6}
The radar chart of \texttt{LLaVA-1.6} are presented in Figure \ref{radar_16}.
\begin{figure}[t]
    \centering
    \includegraphics[width=.45\textwidth]{fig/radar_plot_1.6.pdf}
    \setlength{\abovecaptionskip}{0.2cm}
    \caption{This graph illustrates the reduction in ASR and utility score of \textit{ADPO}, its ablations and baselines over different jailbreak attacks and utility benchmarks on \texttt{LLaVA-1.6}.} 
    \label{radar_16}
\end{figure}

\subsection{Latent Space Adversarial Training on LLaVA-1.6}

The comparision of adversarial training on latent sapce versus image space on \texttt{LLaVA-1.6} are shown in Tabel \ref{latent adversarial training on LLaVA-1.6}.

\begin{table}[h]
    \centering

    \resizebox{\columnwidth}{!}{
    \begin{tabular}{c |c c c c| c }
    \hline
    & \multicolumn{4}{c}{Safety $\downarrow$} & \multicolumn{1}{|c}{Utility$\uparrow$} \\
    \cline{2-6}
    
         &  \multirow{2}{*}{\textbf{MMPGDBlank}} & \multicolumn{3}{c|}{\textbf{MultiTrust}} & \multirow{2}{*}{MM-Vet}  \\
          \cline{3-5}
         
     & & Typo& Multimodal & Cross \\
    % & & Jailbreak & Jailbreak & Jailbreak \\   
\hline
     LLaVA-1.6-7b  & 48.5 & 8.5 & 58.3 & 56.2 & 43.1 \\[2pt]
\hline
    +\textit{AR-DPO} & 8.5 & 0.2 & 0.0 & 2.4 & 38.0 \\[2pt]

    +\textit{AT-DPO} & 3.5 & 0.5 & 4.9 & 21.3 & 38.9 \\[2pt]


    + \textit{ADPO} & 0.5& 0.0 & 0.2 & 8.4 & 37.6 \\[2pt]
    \hline



    +\textit{L-AR-DPO} & 11.0 & 1.0 & 0.0 & 21.6 & 41.0\\[2pt]

    +\textit{L-AT-DPO} & 12.0 & 1.7 & 8.5 & 29.1 & 39.6\\[2pt]


    + \textit{L-ADPO} & 10.5 & 1.2 & 0.0 & 24.9  & 42.6  \\[2pt]
    \hline

\end{tabular}}

\caption{Comparison of worst-case perturbation searched in the image space versus in the latent space of image-text embedding on \texttt{LLaVA-1.6}.}
    \label{latent adversarial training on LLaVA-1.6}
\end{table}


\section{Computing resources}
The experiments are carried by 2*NVIDIA A40 gpus. All conducted experiments required at least 768 gpu hours.

\section{AI Assistants}
We only used AI for grammar correction and sentence polishing in the paper.

\end{document}
