\documentclass[journal]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{array}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{multirow}
%\usepackage{glossaries}
\usepackage{soul}
\usepackage{subcaption}
\usepackage{balance}
\usepackage[capitalise]{cleveref}
\crefname{section}{Sec.}{Secs.}
\crefname{figure}{Fig.}{Figs.}
\usepackage{tikz}
\usetikzlibrary{fit}
\makeatletter
\tikzset{
  fitting node/.style={
    inner sep=0pt,
    fill=none,
    draw=none,
    reset transform,
    fit={(\pgf@pathminx,\pgf@pathminy) (\pgf@pathmaxx,\pgf@pathmaxy)}
  },
  reset transform/.code={\pgftransformreset}
}
\makeatother

\usepackage{pgfplots}
\pgfplotsset{compat=newest} 
\pgfplotsset{plot coordinates/math parser=false} 

\usepackage[acronyms,nonumberlist,nopostdot,nomain,nogroupskip,acronymlists={hidden}]{glossaries}
\newlength\fheight
\setlength{\fheight}{0.5\columnwidth}
\newlength\fwidth
\setlength{\fwidth}{0.8\columnwidth}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}


\input{acronyms}


%\title{Integrating O-RAN with leo Satellite Networks: A Path to Unified Non-Terrestrial and Terrestrial Communications in 6G

%\title{ASTRO-RAN: A Path to Unified Space and Terrestrial Communications in 6G

\title{Space-O-RAN: Enabling Intelligent, Open, and Interoperable Non Terrestrial Networks in 6G

%\title{Integrating O-RAN with Non-Terrestrial Networks: A Path to Unified Space and Terrestrial Communications in 6G


%\thanks{Identify applicable funding agency here. If none, delete this.}
}



\author{\IEEEauthorblockN{
Eduardo Baena, %\IEEEauthorrefmark{1},
Paolo Testolina, %\IEEEauthorrefmark{1}, 
Michele Polese, %\IEEEauthorrefmark{1}, 
Dimitrios Koutsonikolas, %\IEEEauthorrefmark{1}, 
Josep Jornet, %\IEEEauthorrefmark{1}, 
Tommaso Melodia%\IEEEauthorrefmark{1}
}

\IEEEauthorblockA{Institute for the Wireless Internet of Things, Northeastern University, Boston, MA, U.S.A.}

}

\maketitle


\begin{abstract}

\glspl{ntn} are pivotal for achieving ubiquitous connectivity, providing essential coverage in remote and underserved areas. However, standalone \gls{ntn} systems are constrained by isolated operation, limited scalability, and high operational costs.  Combining satellite constellations with terrestrial networks holds significant transformative potential for applications needing continuous and adaptive connectivity, reducing operational costs and enhancing efficiency. However, significant challenges such as dynamic topologies, resource constraints, interoperability gaps, and latency requirements impede seamless integration. To address these challenges, this paper introduces the Space-O-RAN framework, a novel architecture extending Open \gls{ran} principles to \glspl{ntn}. The framework leverages hierarchical closed-loop control mechanisms through distributed \glspl{spaceric}, enabling adaptive management across terrestrial and non-terrestrial domains. At its core, the \gls{spaceric} enables constellation-wide distributed coordination by integrating real-time satellite optimization and control with the terrestrial \gls{ai}-driven systems and \gls{dt} modeling. The framework incorporates distributed \glspl{sapp} and \glspl{dapp} to implement adaptive control loops, ensuring robust performance under dynamic and resource-constrained conditions. A dynamic link-interface mapping strategy further enhances flexibility, aligning network functions with application-specific requirements even during intermittent connectivity. Our simulation results validate the feasibility of the framework. Specifically, we numerically assess the signaling delay requirements and the potential to support efficient and resilient global connectivity management for \gls{6g} networks.

\end{abstract}


\begin{IEEEkeywords}
NTN, O-RAN, Integration, 6G, Management
\end{IEEEkeywords}

\glsresetall
\section{Introduction}

The growing demand for reliable, high-capacity, and globally accessible connectivity has established \glspl{ntn} as a critical component of future communication systems. These networks, including \glspl{leo}, \glspl{meo}, \glspl{geo}, \glspl{hap}, and deep-space platforms, extend connectivity to underserved and remote areas by overcoming the inherent limitations of terrestrial infrastructure. Initiatives like SpaceX's Starlink and Amazon's Project Kuiper illustrate the potential of satellite constellations to address global connectivity challenges~\cite{abdelsadek2023future, cheng2022service}.

However, standalone NTN systems face inherent limitations due to their isolated operation, high reliance on dedicated feeder link infrastructure, elevated operating costs, and constrained optimization capabilities. The integration of NTNs with terrestrial networks represents a paradigm shift, transforming these systems from siloed solutions into unified, efficient, and resilient communication ecosystems capable of addressing the complex demands of emerging 6G applications \cite{abdelsadek2023future, cheng2022service}.

Moreover, integration introduces significant improvements in resiliency and adaptability. Jointly managed networks could autonomously deploy \gls{ntn} backhaul cells in disaster recovery or ad hoc communication scenarios, ensuring uninterrupted service even when the terrestrial infrastructure is compromised. By dynamically monitoring traffic patterns in terrestrial networks, load balancing could be achieved in real time, optimizing resource allocation across \gls{ntn} and terrestrial domains based on contextual demands. Joint closed-loop control mechanisms, facilitated by hierarchical and unified management, would enhance spectrum efficiency, minimize interference, and ensure seamless traffic offloading between orbital and terrestrial segments. Also, integrated architectures unlock advanced use cases, such as distributed computing frameworks that span terrestrial and space domains. Unified management of all on-board radio links and user-plane resources enables the deployment of virtualized network functions and other computational workloads, dynamically adapting to traffic patterns and computational demands. 

Achieving cohesive coordination presents significant technical challenges due to the disparities in their operational characteristics and resource constraints \cite{cheng2022service}. Unlike terrestrial systems, \glspl{ntn} operate in dynamic and resource-constrained environments, where the continuous movement of \glspl{leo} satellites necessitates frequent handovers and real-time updates to connectivity management systems. These dynamics introduce time-varying latency, intermittent connectivity, and frequent loss of \gls{los}, disrupting service continuity and straining network stability \cite{iqbal2023ai}. Furthermore, limitations in power availability, computational resources, and thermal management onboard satellites constrain the implementation of advanced optimization algorithms, highlighting the need for efficient offload strategies \cite{ren2023review}. The absence of standardized protocols for seamless coordination between orbital and terrestrial layers further exacerbates these challenges, resulting in fragmented operations, inefficient resource allocation, and increased interference risks in shared or adjacent spectrum bands \cite{jia2020virtual, xu2018software}.

To address these challenges, in this paper, we propose the Space-O-RAN framework, a novel control and optimization architecture for integrated terrestrial and \glspl{ntn}. The framework is based on the Open \gls{ran} principles of (i) programmability, with software-based protocol stacks that can be algorithmically tuned and optimized through (ii) open interfaces. Finally, (iii) closed-loop control through a multi-scale, hierarchical framework enables data-driven optimization across network domains to adapt to dynamic space conditions dynamically.

Our architecture extends the O-RAN controllers, the \glspl{ric}, to satellite systems, introducing a distributed \glspl{spaceric} designed to address the limitations of \glspl{ntn} discussed above.
% The integrated framework introduces hierarchical closed-loop control to adapt to dynamic space conditions in real time. 
We discuss the role that open and standardized O-RAN interfaces such as E2, O1, A1 and O2 and their extensions play for efficient coordination in heterogeneous environments. 
The network can onboard custom control logic, in the form of rApps, xApps, and dApps, for real-time control, to optimize system parameters and configurations. Our numerical results analyze the latency domains across terrestrial and non-terrestrial domains in which real, near-, and non-real-time control are possible.
For the user plane, the proposed architecture comes with flexible functional splits to optimize the distribution of computational and communication workloads. 
Finally, we discuss the integration of a \gls{dt} framework deployed in the terrestrial infrastructure, that enables robust resource optimization, predictive maintenance, and comprehensive performance evaluation, bridging theoretical advancements with practical implementations.

The paper is organized as follows. Section~\ref{sec:background} discusses related work on \glspl{ntn} integration. Section~\ref{sec:challenges} highlights the challenges for efficient integrated control and optimization and discusses specific use cases that underline the need for such integration. Section~\ref{sec:architecture} details the proposed framework, emphasizing its hierarchical structure and adaptive control mechanisms, and presents an evaluation of feasible control latency. Finally, \cref{sec:future,sec:conclusions} presents the future outlook and summarizes the conclusions.

\section{Background and Related Work}
\label{sec:background}

The lack of closed-loop control procedures remains a major limitation in state-of-the-art approaches like \gls{sagin}~\cite{cui2022architecture}, which provide only conceptual models for integrated architectures and focus primarily on user plane solutions. While \gls{sagin} frameworks envision seamless integration of terrestrial and \glspl{ntn}, their practical implementation is hindered by the dynamic nature of \gls{ntn} links, intermittent connectivity, and significant latency. These challenges complicate the design of stable and efficient control loops and are exacerbated by the limitations of existing \gls{ai}-driven approaches.

The incorporation of \gls{ai} technologies into \glspl{ntn} faces significant hurdles, as limited satellite resources constrain the deployment of complex algorithms, while intermittent connectivity and long propagation delays disrupt data collection and training cycles. Moreover, current solutions often fail to address critical operational requirements, including real-time resource allocation, adaptive control, and precise timing synchronization. Furthermore, interoperability between orbital and terrestrial layers remains largely conceptual, with no concrete implementations for protocol or interface alignment \cite{10716597}.

Recent efforts to integrate \glspl{ntn} with terrestrial networks have highlighted critical trade-offs in \gls{ran} architectures. Lower-layer splits reduce latency, but face strict delay constraints that are difficult to meet in high-latency \gls{ntn} environments, while centralized approaches suffer from bandwidth inefficiencies over feeder links \cite{seeram2024feasibilitystudyfunctionsplits}. Modular architectures that leverage standardized interfaces like near-RT and non-RT \glspl{ric} show potential for adaptive resource management and real-time control, but are challenged by scalability, high latency, and seamless handovers \cite{oranntn2025}. Addressing these limitations requires innovations that balance distributed decision-making, adaptive resource allocation, and efficient integration across network segments.

On the industry side, \gls{3gpp} standardization has significantly advanced \gls{ntn} interoperability. Release 17 introduced extensions to \gls{5g} \gls{nr} for direct-to-cell connectivity, and Release 18 builds on these developments by incorporating dynamic handovers and spectrum sharing. These provide a solid foundation for the bridge between terrestrial and satellite networks, but remain insufficient without additional architectural enhancements to address NTN-specific constraints.

 \begin{figure*}[h]
    \centering
    % Combinar width, height, trim y clip
    \includegraphics[width=0.7\textwidth]{figures/arch.pdf}
    \captionsetup{singlelinecheck=false}
    \caption{The proposed framework coordinates on board Space-RIC (with s-Apps) with terrestrial SMO via flexible link mapping}
    \label{fig:oran_space_arch}
\end{figure*}


\section{Challenges and Use Cases}
\label{sec:challenges}

This section explores the challenges posed by the integration of Terrestrial and \glspl{ntn} and presents use cases demonstrating how it can enhance resiliency, efficiency, and support for advanced applications.

\textbf{Dynamic Topologies and Fragmented Control.}  
The mobility of \glspl{leo} and \glspl{meo} satellites requires frequent handovers and introduces time-varying latency, intermittent backhaul connectivity, and \gls{los} disruptions for \glspl{isl} and \glspl{fl}. Also, the latency to ground stations is inherently higher in non-terrestrial networks than in their terrestrial counterpart due to propagation delays caused by their operational altitudes, with \glspl{geo} experiencing delays on the order of 240 ms round-trip. This increased latency, compared to terrestrial networks, poses challenges for real-time applications and exacerbates the coordination complexity of controller connectivity. Maintaining consistent service quality and controller connectivity under these conditions is challenging, as local satellite-level decision making can conflict with overarching terrestrial policies, leading to suboptimal performance and resource fragmentation \cite{ren2023review}. Later in Section~\ref{sec:feasibility} latency boundaries and distributions are explored.

\textbf{Interoperability and Standardization.}  
The absence of unified protocols for coordinating orbital and terrestrial layers limits seamless integration. Current frameworks, such as \gls{sagin}, lack synchronized control mechanisms for managing frequent satellite handovers, resulting in latency spikes and inefficient resource allocation \cite{mahboob2023revolutionizing, jia2020virtual}. Misalignments in protocol design further hinder secure and reliable data exchanges across the network.

\textbf{Spectrum Management and Coexistence.}
As the number of constellations increases, so does the demand for spectrum.
Terrestrial and \glspl{ntn} shared and adjacent spectrum usage has been proven feasible in bands such as Ka, Ku, and S.
However, effective spectrum sharing and dynamic allocation strategies are critical to mitigate interference, maximize spectral efficiency, and ensure coexistence among current and future services~\cite{beyaz2024satellite}.

\textbf{Security and Operational Reliability.}  
Integrated \glspl{ntn} present unique security challenges due to their dynamic connectivity and frequent handovers, which disrupt traditional authentication and data protection methods designed for stable terrestrial networks. Existing protocols fail to adapt to rapidly changing topologies and multi-hop \glspl{isl}, leaving gaps that increase the risk of unauthorized access and data breaches under disrupted conditions \cite{mahboob2023revolutionizing}.




\textbf{Hardware and Computational Constraints.}  
Satellites face significant limitations in power, computational capacity, and thermal management, which directly impact their ability to execute complex algorithms and resource optimization mechanisms. CubeSats use processors like the ARM Cortex-M or Zynq-7000 series, offer tens to hundreds of megaflops with memory ranging from 512 MB to 2 GB. In contrast, larger geostationary satellites, using processors like the RAD750, can reach up to 400 megaflops and have memory capacities of 2 to 16 GB. These constraints require simplified on-board processing and often make task offloading to terrestrial systems essential. However, the intermittent and limited bandwidth of satellite-terrestrial links complicates this approach, particularly for latency sensitive or data-intensive applications \cite{ren2023review, wang2023satellite}. CubeSats typically operate within power budgets of 5–20 W, while larger platforms generate 5–20 kW using advanced solar arrays and lithium-ion batteries.
Power availability further exacerbates these challenges, fluctuating due to solar orientation, eclipse phases, battery degradation, and competing subsystem demands.
These fluctuations constrain power-intensive tasks such as high-resolution sensing or inter-satellite communication during peak demand or reduced solar input. Despite advances in power management technologies such as \gls{mppt} and scalable energy storage systems, the need to balance power generation and consumption across diverse subsystems remains a critical challenge for ensuring mission efficiency and reliability.%\hl{Power}

\subsection{Use Cases}

Integrating terrestrial and \glspl{ntn} enables capabilities beyond standalone systems, offering enhanced resilience, adaptability, and efficiency. The following examples highlight how such an integration addresses critical challenges and supports advanced applications.

\textbf{Autonomous Disaster Response.}  

In disaster scenarios where the terrestrial infrastructure is severely disrupted or destroyed, integrated terrestrial and non-terrestrial systems can ensure the continuity of communication. Using \glspl{isl} for backhaul and dynamically routing traffic through unaffected terrestrial nodes, these systems enable real-time situational awareness, emergency coordination, and remote command-and-control. For example, a satellite-enabled backhaul can restore connectivity by dynamically allocating bandwidth to the affected region while prioritizing critical traffic, such as video feeds for search-and-rescue operations. Additionally, real-time telemetry from \glspl{ntn} enhances decision-making by complementing terrestrial sensing capabilities.


\textbf{On-Demand Localized Networks.}  

Deploying ad hoc or localized networks in remote or underserved areas requires flexible resource allocation and low-latency communication. Standalone \glspl{ntn} often fail to meet these demands due to limited dynamic adaptability.
Integrated architectures enable terrestrial base stations to act as ground stations, eliminating the need for dedicated feeder links and dynamically coordinating spectrum and resources between the terrestrial and non-terrestrial domains.

For example, in areas where the terrestrial infrastructure is difficult to maintain and update, e.g., rural areas where the deployment of current and future generation nodes is difficult and costly, \glspl{ntn} could provide a high-speed, broadband backhaul link to the existing base stations.
As the same \gls{ntn}, while costly to deploy, can serve virtually all regions of the Earth, the cost (and revenue) would be split among a large userbase, effectively costing the local communities a fraction of the cost of deploying a fixed and localized terrestrial infrastructure.

Another example is that, during tactical operations, integrated systems can prioritize low-latency communication for command-and-control via terrestrial nodes, while \glspl{ntn} provide robust data aggregation and high-latency bulk transmission, ensuring seamless service delivery without the need for pre-existing terrestrial infrastructure.

\textbf{Ubiquitous AI-Driven Applications.}  

Satellites provide unmatched global coverage for data collection, but face significant limitations in on-board storage, processing power, and energy efficiency, making local \gls{ai} inference impractical \cite{mahboob2023revolutionizing, oranntn2025}. Integrated systems overcome these challenges by offloading data preprocessing, model training, and resource-intensive inference to terrestrial cloud or edge infrastructure. For instance, federated AI architectures can utilize terrestrial resources for distributed model training while leveraging \glspl{ntn} for global data collection. This approach enhances system-wide efficiency, reduces latency, and supports scalable deployment of \gls{ai}-driven applications, such as autonomous navigation, predictive maintenance, and real-time analytics in remote or resource-constrained environments.


\section{Proposed Solution: Space-O-RAN}
\label{sec:architecture}

The Space-O-RAN architecture (\cref{fig:oran_space_arch}) directly addresses the critical challenges of integrating \glspl{ntn} with terrestrial O-RAN systems. This section details its key components, including the control mechanisms, optimization strategies, and system dynamics that enable adaptive and efficient operation across diverse network segments.

\textbf{Control Knobs and Optimization Surface.}

The proposed architecture is driven by control parameters that are systematically adjusted at three key levels: strategic, coordination, and operational. These parameters enable precise adaptations to variations in user demand, link performance, and resource constraints, ensuring that the network remains responsive and efficient.
%Strategic- Earth Cloud
%Coordination- Leader-Follower, constellation-wise
%Operational- Each satellite dApp, sApps managing all connections

At the strategic level, policies such as spectrum allocation, traffic prioritization, and routing protocols govern the overall behavior of the network. These directives are tailored to optimize the interplay between terrestrial and non-terrestrial domains, maximizing resource efficiency across diverse operational scenarios.

At the coordination level, satellite clusters and terrestrial nodes implement localized optimizations in real time. Key parameters at this level include (but are not limited to) beamforming configurations, task scheduling priorities, and spectrum reuse strategies. These adjustments align localized network performance with global directives, ensuring a coherent system response.

At the operational level, fine-grained control over link-specific parameters such as modulation schemes, power levels, and handover processes is maintained. These adjustments allow the network to mitigate rapid fluctuations in connectivity and link quality, ensuring stability even in highly dynamic conditions.

The optimization surface integrates these control parameters into a cohesive framework, allowing the system to dynamically balance competing priorities such as latency, throughput, and energy consumption. This structured approach enables efficient scaling and robust performance across the network.

\subsection{Feasibility Bounds}
\label{sec:feasibility}
The feasibility analysis evaluates the propagation delay characteristics of \glspl{ntn}, focusing on the unique latency dynamics of the ground-to-satellite and \gls{isl} links. These delays are a critical factor in defining the operational constraints for real-time coordination and adaptive control mechanisms within the proposed architecture.

Simulations of the Starlink constellation (6545 satellites, 33 ground gateways) provide critical insights into achievable latency bounds. \glspl{isl} demonstrate consistent sub-10~ms delays (\cref{fig:isl_latency}), offering a reliable foundation for real-time tasks. In contrast, \glspl{gsl} exhibit higher and more variable delays (\cref{fig:g2s_latency}), making them suitable for non-time-critical operations. Conversely, \glspl{gsl} show delays ranging from 10 to over 40ms (\cref{fig:g2s_latency}), depending on satellite elevation, which limits their suitability for real-time operations but makes them viable for strategic, non-critical tasks like policy updates and long-term resource allocation.

To meet the operational requirements of Space-O-RAN, these latency bounds must align with control loop dynamics and functional split strategies. For example, real-time tasks require a round-trip latency of under 20~ms, achievable with \glspl{isl}. In contrast, tasks that require higher computational power but less stringent latency constraints can be offloaded to terrestrial clouds via \glspl{gsl}, provided that their delays remain within acceptable limits for nonreal-time operations.

The feasibility of deploying RAN architectures in \glspl{ntn} reveals critical trade-offs among latency, bandwidth, and computational efficiency. Lower-layer functional splits minimize on-board processing latency, but are constrained by \glspl{gsl} delays, making them less effective for time-sensitive operations. Centralized architectures risk overloading feeder links, which reduces bandwidth efficiency. These findings underscore the need for a hybrid approach: to localize real-time decision making within satellite clusters, while computationally intensive tasks need to be delegated to terrestrial cloud infrastructure, optimizing resource allocation, and mitigating latency bottlenecks. 



\begin{table*}[h]
\centering
\scriptsize % Reduce font size
\setlength{\tabcolsep}{2pt} % Reduce space between columns
\caption{Dynamic Interface-Link Mapping for NTNs}
\label{tab:interface_mapping_flexibility}
\begin{tabular}{|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{4cm}|p{4cm}|p{2cm}|} % Adjust column widths to fit the page
\hline
\textbf{Link Type} & \textbf{Primary Function} & \textbf{Supported Interfaces} & \textbf{Role in the Integrated Network} & \textbf{Dynamic Re-mapping Capability} & \textbf{Delay Quantiles}\\
\hline
User Link (UL) & End-user connection & F1, E2, NG & Ensures QoS for critical slices; re-routes traffic to feeder or coordination roles during disruptions & Dynamic re-mapping for high-priority slices under feeder link outages & Median: 30 ms, 90\% perc.: 40 ms\\
\hline
Feeder Link (FL) and Ground to Satellite (GSL) & Satellite-to-ground backhaul & A1, E2, F1, O1 & Integrates satellite-terrestrial traffic, supports telemetry and re-routing user-plane data during feeder issues & Enables intra-constellation backhaul and telemetry updates for stable integration & Median: 50 ms, 90\% perc.: 70 ms\\
\hline
Inter-Satellite Link (ISL) & Satellite coordination & E2, F1, A1, Xn & Supports CU-DU splits, inter-satellite routing, and constellation-wide resource sharing & Can re-map for feeder backhaul or user-plane traffic during outages or congestion & Median: 5 ms, 90\% perc.: 10 ms\\
\hline
\end{tabular}
\end{table*}



\subsection{Core Components}

The architecture comprises terrestrial and satellite components designed to ensure seamless integration and efficient operation.

\textbf{On-Board Edge.}

The proposed architecture extends traditional cellular network functionalities to the satellite domain, tailoring them to operate within the constrained environments of \glspl{ntn}. Satellite-deployed network functions like \gls{sru}, \gls{sdu}, and \gls{scu}, are specifically optimized to address the computational, power, and memory limitations inherent to satellite platforms. Each satellite is equipped with at least three \glspl{sru}, each dedicated to managing one of the primary communication links: \glspl{isl}, \gls{sl}, and \gls{fl}. 

The \gls{spaceric} centrally coordinates the satellite cluster, housing satellite-specific \glspl{xapp} and \glspl{sapp} for near-real-time tasks like interference detection and management, and aiding constellation operations. The on-board edge is further supported by a dedicated satellite orchestration and operating system layer. This system dynamically allocates hardware resources, including \glspl{cpu}, \glspl{gpu}, and memory, to meet varying traffic and service demands. Using a tailored middleware, the architecture facilitates the smooth deployment of multiple network functions with efficient resource use. Integrated sensors offer telemetry and performance data, forming real-time feedback loops to enhance link utilization, network performance, and system efficiency.

%A distinctive feature of the architecture is its ability to dynamically map O-RAN interface functions onto physical links, enabling efficient bandwidth utilization and traffic management. This capability ensures that the architecture remains scalable and adaptable, supporting larger constellations and more complex \gls{ntn} deployments in the future.

\begin{figure}[h]
\centering
\includegraphics[width=1\linewidth, trim=0 0 100 0, clip]{figures/SpaceRIC.pdf}
\captionsetup{justification=centering}
\caption{\gls{spaceric} workflow}
\label{fig:spaceRIC}
\end{figure}

\textbf{Terrestrial Cloud}

The terrestrial cloud, as depicted in Fig.~\ref{fig:oran_space_arch}, serves as the central coordination layer in the Space-O-RAN architecture, orchestrating high-level functions such as \gls{dt} modeling, long-term network planning, policy optimization, and resource inventory management. It provides the computational power required for training \gls{ml} models, conducting large-scale data analytics, and maintaining twin RF models, which simulate and predict network behavior. These functions are crucial for the efficient management and optimization of both terrestrial and satellite network components.

Strategic directives generated by the terrestrial cloud are transmitted to the satellite network via \glspl{gsl}, which, due to their higher latency, are primarily used for non-real-time tasks. The terrestrial cloud interacts seamlessly with the \gls{smo} layer, enabling virtualized core operations, such as network design, inventory updates, and policy enforcement, to ensure cohesive integration with terrestrial cellular networks. Furthermore, cloud centralized AI management oversees the deployment and monitoring of models across the satellite network, including \glspl{sapp} and \glspl{dapp}, tailored for specific satellite operations such as sensing or resource sharing. 

\textbf{AI Pipelines}

%\hl{Explicitly map out pipelines that would support various AI-related tasks, from training to inference. Either here as an architectural component or as a standalone subsection}

Data aggregation and preprocessing are performed locally on satellites, where telemetry and operational data are collected and prioritized for transmission to terrestrial cloud resources. Local preprocessing, including filtering and feature extraction, minimizes bandwidth usage while ensuring timely data availability for immediate tasks.

Model training and optimization occur primarily in the terrestrial cloud with more computing power and scalability. For localized tasks, satellites may conduct limited on-board training, while federated learning enables distributed model updates across satellite clusters balancing computational efficiency and resource constraints.

Inference and decision-making are distributed throughout the system. Real-time, latency-sensitive applications, such as beamforming adjustments, are executed at the satellite level or within clusters. Meanwhile, long-term policy decisions and strategic operations are derived from cloud-based inference, aligning with the broader objectives of the network.

The trained models are deployed on the \gls{spaceric}, with feedback loops integrated via the \glspl{e2} and \glspl{a1} interfaces that ensure iterative refinement of the models.

\subsection{SpaceRIC and Hierarchical Coordination of r/s/dApps}

To tackle the complexities inherent in \glspl{ntn}, our framework employs a hierarchical coordination structure shown in Fig.~\ref{fig:spaceRIC}. At the terrestrial layer, \glspl{rapp} hosted in the \gls{smo} handle strategic, non-real-time functions such as \gls{dt} modeling and policy optimization. By processing aggregated data, these \glspl{rapp} produce high-level directives that are communicated to the \gls{spaceric} Leader via the \gls{a1} interface. This ensures that the constellation-level objectives remain aligned with the evolving operational demands of the network.

On the primary satellite within each cluster, the \gls{spaceric} Leader combines these terrestrial directives with real-time telemetry and performance metrics gathered from its satellite cluster. It governs critical cluster-wide operations through \glspl{sapp}, which dynamically allocate spectral resources and manage inter-satellite handover decisions. For example, in beamforming applications, \glspl{sapp} adjust the configurations in response to user demand and orbital changes, ensuring optimal performance. Real-time tasks like interference mitigation and localized beam refinements are assigned to \glspl{xapp} on the Leader, improving system agility and responsiveness. Synchronization within the satellite cluster is achieved through \glspl{isl}, with the \gls{e2} interface enabling seamless communication between the Leader and its Followers. In the event of disrupted connectivity, the \gls{fede2} protocol allows multi-hop coordination, enabling Followers to reconnect with the Leader and maintain cluster-wide alignment. If the \gls{spaceric} Leader becomes non-operational, the system relies on the \gls{fede2} protocol to maintain cluster-wide functionality. This protocol enables multi-hop coordination among Followers, allowing them to elect a new Leader dynamically or establish decentralized coordination temporarily.

Followers, equipped with \glspl{sapp}, manage localized resource allocation and operational adjustments. Tasks such as beam switching and monitoring are executed at \glspl{dapp}, ensuring responsiveness to localized variations. Guided by the strategic directives from the Leader, the Followers adapt to real-time challenges while preserving overall system coherence.


\subsection{Dynamic Link-Interface Mapping}

The proposed architecture introduces a novel capability to dynamically map multiple O-RAN interfaces to a single physical link, enabling the adaptive and efficient utilization of network resources. This flexibility is particularly critical in \glspl{ntn}, where the conditions of dynamic connectivity and the varied demands of applications necessitate the seamless orchestration and management of multiple roles for each individual link.

For example, a single \gls{isl} can concurrently support the \gls{e2} interface for signaling and coordination within the \gls{spaceric} and the \gls{f1} interface for \gls{cu}-\gls{du} communication. This multipurpose functionality ensures the continuity of operations, even when network functions are distributed across different satellites. This adaptability allows the system to dynamically respond to changes in connectivity and optimize resource utilization without compromising performance.

Similarly, \glspl{sl} and \glspl{fl} can handle both signaling and user traffic simultaneously, with dynamic adjustments to resource allocation based on application-specific priorities. For example, high-priority slices, such as emergency response or critical \gls{iot} applications, are routed through low-latency \glspl{isl} or \glspl{ul}, ensuring rapid data transmission. In contrast, bulk \gls{iot} data or other non-critical traffic is assigned to higher-latency paths, preserving premium resources for latency-sensitive services.

Table~\ref{tab:interface_mapping_flexibility} outlines the primary and adaptive roles of each type of link, demonstrating how this dynamic orchestration improves the resilience and flexibility of \glspl{ntn}. These capabilities are crucial to maintain robust performance under variable connectivity conditions and optimize the use of limited satellite and terrestrial resources.


\subsection{Security and Interoperability}

To address the security challenges posed by the intermittent nature of \gls{ntn} links, particularly with ground stations, we suggest an adaptive link authentication mechanism. This approach involves session-based authentication with temporary caching of session tokens on both ends, allowing rapid reauthentication when a link reappears, bypassing a full handshake. In addition, ephemeral keys are generated at each reconnection to ensure that each session is uniquely secured, even if interrupted.

For predictable reestablishment scenarios, such as scheduled satellite passes, pre-authentication can be initiated just before the link becomes active, reducing connection latency. A \gls{daa} further supports autonomous authentication throughout the satellite network, enabling secure reauthentication even when terrestrial connectivity is inconsistent. Automated link monitoring with a timeout mechanism ensures that inactive session tokens are invalidated after link disruptions, adding an extra layer of security against unauthorized reconnections. In this way, the framework is designed for seamless interoperability with O-RAN compatible \gls{tn}, allowing flexible integration with current \gls{5g} and emerging \gls{6g} systems.

\subsection{Propagation Delay and Real-Time Control}

Latency-sensitive applications in \glspl{ntn} require strict control over propagation delays to ensure consistent and reliable performance. In \glspl{leo} constellations, where frequent handovers and dynamic conditions dominate, \glspl{isl} are prioritized to maintain propagation delays below a 50~ms threshold. This is achieved by leveraging the \gls{e2} interface, which facilitates real-time signaling and coordination across satellites, as illustrated in \cref{fig:g2s_latency}. The \gls{spaceric} orchestrates this process by integrating telemetry from distributed satellites to dynamically optimize network operations, minimizing delays and maintaining operational continuity even under fluctuating connectivity conditions.

A key advantage of this approach is the reduced dependency on ground-based routing, which typically incurs higher latency due to longer transmission paths and increased processing overhead. By enabling low-latency communication directly through \glspl{isl}, the architecture supports real-time \gls{ntn} applications that require rapid responses to dynamic changes. This capability is particularly critical for scenarios such as adaptive beamforming, where adjustments must be made in near real-time to accommodate shifts in user demand, satellite positions, or environmental factors. These tasks are managed through the coordinated operation of \glspl{sapp} and \glspl{xapp}, which execute localized control and near-real-time optimizations.

The autonomous disaster response represents a notable use case that benefits from this low-latency configuration. In such scenarios, the system uses the dynamic capabilities of \glspl{sapp} and \glspl{xapp} to reconfigure beamforming patterns, reroute data, and prioritize critical traffic, ensuring uninterrupted service delivery under extreme conditions. Additionally, the architecture improves the responsiveness of dynamic applications by enabling real-time control adjustments and feasibility analyses that consider varying network states. This adaptability ensures that \glspl{ntn} can meet the stringent latency requirements of emerging applications while maintaining high service quality in diverse operational scenarios.



\section{Future Outlook}
\label{sec:future}

The operational challenges of scalable and autonomous systems in dynamic, resource-constrained environments require innovative solutions for future integrated network deployments. As \glspl{ntn} extend their scope to deep-space and extraterrestrial missions, autonomous features such as self-healing mechanisms and decentralized resource coordination will be critical for maintaining reliability. Protocols like \gls{hdtn} and the Bundle Protocol \cite{dudukovich2024advances} will be essential for addressing the latency and intermittent connectivity inherent in these scenarios, enabling reliable performance even in the absence of direct Earth communication.

New developments in \gls{ai} and \gls{ml} will play a key role in improving satellite network operations. Techniques such as distributed inference, model compression, and federated learning will optimize resource utilization by minimizing computational and bandwidth overhead. These capabilities could enable adaptive responses to dynamic traffic patterns, particularly in \glspl{leo} constellations, and support predictive analytics for operational decision-making.

Scalability remains a core consideration as satellite constellations grow and new nodes, including those for planetary exploration, are incorporated. Modular design principles ensure seamless integration of additional components without disrupting ongoing operations. This scalability would enable diverse applications, such as autonomous scientific research, precision environmental monitoring, and surface operations on extraterrestrial bodies.

Joint communication and sensing functions further enhance situational awareness and decision-making. By offloading data-intensive tasks, such as anomaly detection and environmental monitoring, to terrestrial processing centers, the burden on satellite hardware is reduced. 

The adoption of the THz spectrum in \glspl{isl} and terrestrial links \cite{alqaraghuli2023road} offers significant potential for ultra-high-throughput communication, effectively complementing existing Ka, Ku, and laser-based systems. However, THz bands face inherent challenges, such as atmospheric attenuation and propagation losses, which can constrain their reliability and range under adverse conditions. To address these limitations, dynamic spectrum management mechanisms within the proposed framework could enable adaptive transitions between THz and more resilient bands, such as Ka or Ku, based on environmental and operational conditions. 

The next steps should prioritize overcoming satellite power and processing limitations, improving synchronization between network layers, and standardization to improve the overall system efficiency.

\section{Conclusions}
\label{sec:conclusions}

This paper presents an innovative architecture for the integration \glspl{ntn} with terrestrial O-RAN-supported systems, addressing key challenges such as resource constraints, dynamic connectivity, and fragmented coordination. The framework leverages dynamic link-interface mapping and hierarchical control mechanisms to enable scalable and efficient multi-layered network management. These features bridge the gaps inherent in standalone systems, facilitating coordinated operations across space, air, and terrestrial domains to support demanding applications.

The architecture achieves real-time decision making at the edge of space through distributed interactions between \glspl{rapp} and satellite-specific \glspl{sapp}. This approach reduces signaling delays and enhances adaptability to changing conditions. Computationally intensive tasks, including predictive analytics and global optimization, are offloaded to terrestrial cloud resources, balancing edge processing with centralized control. This dual-layer strategy ensures responsiveness to latency-sensitive and high-priority service demands while maintaining operational efficiency under dynamic conditions.

Simulations confirm the feasibility of the proposed solution, demonstrating its ability to meet the stringent requirements of integrated terrestrial and \glspl{ntn}. \Glspl{isl} consistently achieve latencies below 10~ms for a significant subset of links, supporting real-time coordination, while \glspl{gsl} provide reliable support for non-time-critical tasks. The architecture's adaptive resource management and hierarchical control mechanisms enable stable closed-loop control, reducing signaling delays and maintaining robust coordination between network layers.

These results validate the ability of the framework to address the unique challenges of \glspl{ntn}, such as dynamic topologies, resource constraints, and fragmented operations. By prioritizing real-time decision-making within satellite clusters and offloading computationally intensive tasks to terrestrial cloud infrastructure, the architecture achieves an optimal balance between efficiency and performance. Furthermore, the adaptive spectrum management approach ensures seamless operations during varying traffic demands, avoiding resource bottlenecks, and improving network resilience.

Future work will explore enhancements to hardware and software capabilities in satellites to address power and thermal limitations and integrate emerging spectrum technologies like THz bands. These developments aim to expand the framework's applicability to support next-generation use cases.




\bibliographystyle{IEEEtran}
\bibliography{biblio}

\vskip -3\baselineskip plus -1fil



\begin{IEEEbiographynophoto}{Eduardo Baena} is a postdoctoral research fellow at Northeastern University, with a Ph.D. in Telecommunication Engineering from the University of Malaga. His experience includes roles in the international private sector (2010–2017) and as Co-PI in several research projects.
\end{IEEEbiographynophoto}

\vskip -2\baselineskip plus -1fil

\begin{IEEEbiographynophoto}{Paolo Testolina} received a Ph.D. in information engineering from the University of Padova in 2022. He is a Post-Doctoral Researcher at Northeastern University, with research interests in mmWave and sub-THz networks, including channel modeling, link layer simulation, and vehicular networks.
\end{IEEEbiographynophoto}

\vskip -2\baselineskip plus -1fil

\begin{IEEEbiographynophoto}{Michele Polese} is a Research Assistant Professor at Northeastern University’s Institute for the Wireless Internet of Things. He received his Ph.D. from the University of Padova in 2020 and focuses on protocols for 5G and beyond, mmWave/THz networks, spectrum sharing, and open RAN development.
\end{IEEEbiographynophoto}

\vskip -2\baselineskip plus -1fil

\begin{IEEEbiographynophoto}{Dimitrios Koutsonikolas} is an Associate Professor in the department of Electrical and Computer Engineering and a member of the Institute for the Wireless Internet of Things at Northeastern University. He specializes in experimental wireless networking and mobile computing, with a focus on 5G/NextG networks and applications. He is a recipient of the IEEE Region 1 Technological Innovation Award and the NSF CAREER Award.
\end{IEEEbiographynophoto}

\vskip -2\baselineskip plus -1fil

\begin{IEEEbiographynophoto}{Josep M. Jornet} (M'13--SM'20--F'24) is a Professor and Associate Director of the Institute for the Wireless Internet of Things at Northeastern University. His research focuses on terahertz communications and networking, pioneering advancements in nanoscale communications and wireless systems. He has authored over 250 peer-reviewed publications and holds five US patents.
\end{IEEEbiographynophoto}

\vskip -2\baselineskip plus -1fil

\begin{IEEEbiographynophoto}{Tommaso Melodia} is the William Lincoln Smith Chair Professor at Northeastern University and Founding Director of the Institute for the Wireless Internet of Things. A recipient of the NSF CAREER award, he has served as an Associate Editor for leading IEEE journals.
\end{IEEEbiographynophoto}

\end{document}
