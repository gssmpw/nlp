\section{Related Work}
\label{sec:related_works}

% CASH problemを解くための最も単純な手法として，ランダムサーチやグリッドサーチ\cite{bergstra2012random}がある．
% しかし，CASH problemの探索空間は通常のハイパーパラメータ最適化と比べて大規模であるため，ランダムサーチやグリッドサーチでは予測精度が高くなるハイパーパラメータと機械学習アルゴリズムの組み合わせの発見には通常のハイパーパラメータ最適化よりも膨大な時間を必要とする．

% CASH problemを解くために，ハイパーパラメータ最適化にも利用されるベイズ最適化\cite{thornton2013auto,snoek2012practical}や遺伝的アルゴリズム\cite{whitley1994genetic,OlsonGECCO2016}を利用した手法が開発されてきた．
For the CASH problem, BO based approaches \cite{thornton2013auto,snoek2012practical} and genetic algorithm based approaches \cite{whitley1994genetic,OlsonGECCO2016} have been studied.
%
% ベイズ最適化や遺伝的アルゴリズムを用いてCASH problemを解く方法の一つとして，
% 異なる機械学習アルゴリズムのハイパーパラメータ空間を以下のように一つの探索空間$\*{\Lambda}$として定式化する方法が活用されている．\cite{thornton2013auto,levesque2017bayesian,feurer2015initializing,NIPS2015_11d0e628}．
A well-known approach to dealing with different HP spaces is to create the concatenated space 
\cite{thornton2013auto,levesque2017bayesian,feurer2015initializing,NIPS2015_11d0e628}: 
\begin{align*}
 \*{\Lambda} = \*{\Lambda}^{(1)} \cup \*{\Lambda}^{(2)} \cdots \cup \*{\Lambda}^{(M)} \cup \left\{\lambda_r\right\}, 
 % \label{eq:SMAC_Search_Space}
\end{align*}
%ただし，$\lambda_r$は候補となる機械学習アルゴリズム$A^{(1)}, \ldots, A^{(L)}$を識別するパラメータである．
where 
$\lambda_r$
is a parameter indicating which candidate ML algorithm $A^{(1)}, \ldots, A^{(M)}$ is now selected (active).
%
% この方法により構成された探索空間上で表現されるブラックボックス関数を1つの確率モデルで予測を行うことで，適切な機械学習アルゴリズムとハイパーパラメータの組み合わせの発見を行う．
% このハイパーパラメータ空間を結合する方法でベイズ最適化を活用する場合，conditional hyperparameter\cite{thornton2013auto,levesque2017bayesian}を扱うことができるSMAC\cite{hutter2011sequential}を活用した手法がよく用いられる．
To search this concatenated space, SMAC \cite{hutter2011sequential} based approaches have been often used, which can handle conditional HPs \cite{thornton2013auto,levesque2017bayesian}.
%
% SMACでは構成された探索空間において，機械学習アルゴリズム$A^{(m)}$が持たないハイパーパラメータにはdefault valueという固定値を与える．
% \red{SMAC gives a default value for an HP that an ML algorithm $A^{(m)}$ does not have.}
The surrogate model in SMAC needs some default value for an HP that an ML algorithm $A^{(m)}$ does not have \cite{levesque2017bayesian}.
%
% 例えば，候補となる機械学習アルゴリズムにサポートベクターマシンとランダムフォレストが存在する場合，ランダムフォレストはサポートベクターマシンのハイパーパラメータ$C$を持っていないため，default valueとして$0.1$を与える．
For example, in the case of support vector machine (SVM) and random forest (RF), RF does not have the SVM HP `$C$' (regularization coefficient). 
%
% このdefault valueは任意の値を与えることができる．
Then, RF has some default value for the dimension corresponding to the SVM $C$ in the concatenated vector.
%
% しかし，これらの手法はハイパーパラメータ空間の結合による探索空間の大規模化やdefault valueの値による結果の変化により，最適化が困難であると考えられる．
However, this approach makes the dimension of the search space (i.e., dimension of the concatenated vector) large, and the theoretical justification of the default value is unclear.
%
On the other hand, \cite{swersky2013raiders} proposes a kernel that partially uses a shared space for `relevant' parameters, but the relevance should be defined manually and most of hyper-parameters are typically seen as irrelevant each other (e.g., SVM and RF does not have relevant parameters). 



% CASH problemを解く別の方法として，機械学習アルゴリズム選択とハイパーパラメータ最適化を別々に解く手法も良く考えられる\cite{nguyen2020bayesian,liu2020admm,li2020efficient,li2023volcanoml}．
Another approach to the CASH problem is to separate the ML algorithm selection and the HP selection \cite{nguyen2020bayesian,liu2020admm,li2020efficient,li2023volcanoml}.
%
% \cite{nguyen2020bayesian}では機械学習アルゴリズム毎に独立にベイズ最適化を行うことで，複数の小規模な探索空間に対して最適な機械学習アルゴリズムとハイパーパラメータの組み合わせの発見に取り組まれている．
\cite{nguyen2020bayesian} applied independent BO to each ML algorithm, by which each one of the HP spaces can be small.
%
However, sufficient observations should be required for all candidate ML algorithms because of the independence. 
% しかし，機械学習アルゴリズム毎に独立な予測モデルの構築が必要となり，各機械学習アルゴリズムの観測結果を共有することができなくなる．
% したがって，精度の高い機械学習アルゴリズムとハイパーパラメータの組み合わせを発見するためには多くの実験を必要とするため非効率である．
% \cite{li2020efficient,li2023volcanoml}では\cite{nguyen2020bayesian}のように機械学習アルゴリズム毎に独立にベイズ最適化を行い，最適化中に最も高い予測精度の観測が期待できる機械学習アルゴリズムの選択を行う．
\cite{li2020efficient,li2023volcanoml} also use independent BO, and select only a promising ML algorithm as the final search candidate. 
%
This approach can reduce the search space, but to select an ML algorithm appropriately, sufficient observations are again required for all ML algorithms.
%
Further, in practice, there is a risk of discording the true best ML algorithm.
% そして，選択された機械学習アルゴリズムに対してのみ探索を行う．
% これにより，最終的に単一の機械学習アルゴリズムに対してのみのハイパーパラメータ最適化が行われるため，小規模な探索空間での最適化が可能となる．
% しかし，この手法は\cite{nguyen2020bayesian}と同様に異なる機械学習アルゴリズムの観測結果の共有を行うことができないため，適切な機械学習アルゴリズムの選択が行われるまでは探索が非効率となってしまう．
% また，選択された機械学習アルゴリズムが最も高い予測精度を記録できないアルゴリズムの場合，最終的に得られる予測精度が低下するため，アルゴリズムの選択条件は慎重に設定する必要がある．


% これに対して，我々の手法は潜在空間上での探索を行うことから，(\ref{eq:SMAC_Search_Space})のように大規模な探索空間上での探索を必要とせず，効率的な探索が可能となる．
% また，共有潜在空間上で異なる機械学習アルゴリズムの観測データの共有を可能とし，\cite{li2020efficient,li2023volcanoml}のように単一の機械学習アルゴリズムのハイパーパラメータ最適化を行うわけではないため，不適切な機械学習アルゴリズムの選択による性能低下を回避することができる．


% 我々は事前学習された潜在空間を使用してベイズ最適化によるCASH problemを解いているが，我々の手法と同様に事前知識を用いてCASH problemを解くためにメタ学習\cite{lemke2015metalearning}を活用した手法が提案されている．
While we introduce a pre-training for the latent space learning, meta-learning \cite{lemke2015metalearning} approaches to the CASH problem have also been studied.
%
% \cite{mu2022auto,wang2020auto}では機械学習アルゴリズム選択をメタ学習で行い，選択された機械学習アルゴリズムに対してハイパーパラメータ最適化を行う．
% これらの手法は上述した\cite{li2020efficient,li2023volcanoml}とは異なり，探索開始前に機械学習アルゴリズム選択を行うため，\cite{li2020efficient,li2023volcanoml}よりも早い段階で小規模な探索空間上での最適化を行うことが可能である．
\cite{mu2022auto,wang2020auto} learn the ML algorithm selection through meta-learning and the HP optimization is performed only for the selected ML algorithm.
%
% しかし，これらの手法は単一の機械学習アルゴリズムに対してのみ最適化が行われるため，不適切な機械学習アルゴリズムが選択されると得られる予測精度の低下につながると考えられ，メタ学習の精度が得られる結果に大きく依存する．
Since these approaches select a single ML algorithm before the optimization starts, the risk of the miss-selection of the ML algorithm can be high.
%
% \cite{dagan2024automated,cohen2019autogrd,laadan2019rankml}では主に機械学習アルゴリズムとハイパーパラメータの組み合わせ選択にメタ学習を用いている．
\cite{dagan2024automated,cohen2019autogrd,laadan2019rankml} considers meta-learning for the simultaneous selection of an ML algorithm and an HP.
%
% これらの手法は事前に決められた機械学習アルゴリズムとハイパーパラメータの組み合わせに対して，与えられたタスクが高い予測精度を記録できる組み合わせをメタ学習により予測し，予測精度が高いと予測された組み合わせから順番に評価を行なっていく．
The meta-learner predicts a pair consisting of an ML algorithm and an HP that achieves high accuracy, and generates a fixed-size ranking list used to evaluate performance sequentially.
%
% これらの手法は高い予測精度が期待される機械学習アルゴリズムとハイパーパラメータの組み合わせから順番に評価が行われるため，少ない実験時間，実験回数で高い予測精度を得ることが期待できる．
% しかし，この手法は事前に決められた機械学習アルゴリズムとハイパーパラメータの有限個の組み合わせに対してのみ探索されない．
% 従って，与えられたタスクに対して最も高い予測精度を記録する機械学習アルゴリズムとハイパーパラメータの組み合わせが候補に含まれず，最適解を必ず得ることができない可能性がある．
However, this strategy is not adaptive to the observations of the given target dataset unlike our approach, by which the error in the meta-learner cannot be corrected. % (meaning that even the optimal solution can be removed at the beginning).}


% これに対して，我々の手法は事前学習済みの潜在空間選択に対して事前知識を活用している．
% 我々の手法は連続したハイパーパラメータ空間を潜在空間上へと写像するため，探索空間上に必ず最適な組み合わせが含まれており，全ての機械学習アルゴリズムが探索候補となるため，既存のメタ学習を用いた手法と比べても
% 探索精度の低下のリスクは軽減される．


BO algorithms using the latent space surrogate have been studied (e.g., \cite{gomez2018automatic}). 
%
Typically, to avoid the acquisition function maximization in the structured input (such as sequences and graphs) or high dimensional space, the acquisition function is maximized in the latent space from which the next search point is `decoded'. 
%
On the other hand, we do not employ this decoding approach and the acquisition function maximization is performed in the original space as described in \eq{eq:acquisition_function}.
%
This is to avoid the cycle consistency problem \cite{jha2018disentangling}, i.e., the selected latent variable $\*u$ may not be consistent with the encoded value of the decoded $\*u$, by which the GPs cannot obtain the observation at the selected point.
%
Combining recent techniques mitigating this problem \cite{boyar2024latent} with our proposed method is a possible future direction.
%
Recently, transfomrer based latent space approaches have been studied \cite{lyu2023efficient,li2024an}.
%
% They regard an HP as `token' by which a different number of HPs can be handled, while we employ the simple MLP because the number of HPs is fixed beforehand in our setting.
They regard an HP as a `token' by which a variable size of HPs can be handled, while we employ the simple MLP because the size of HPs is fixed beforehand in our setting.
%
Further, \cite{li2024an} does not discuss pre-training and \cite{lyu2023efficient} does not consider the CASH problem. 





% --------------------------------------------------
%