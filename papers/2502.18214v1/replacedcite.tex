\section{Related Work}
\label{sec_2}
\subsection{2D mammal pose estimation}
\label{subsec:rel_pe}
Animal pose estimation, similar to human pose estimation, is a fundamental task in computer vision and refers to localising all body keypoints for animal-targeted images.
Existing studies have circumvented the proposition of effective models and, instead addressed the problem from the perspectives of transfer learning and domain generalisation.
Specifically, AnimalPose____ leverages a cross-domain adaptation scheme to learn pose similarities between animals and humans.
To cope with the limited labelled animal data volume, direct attempts____ learn prior-aware knowledge from synthetic animal datasets, and generate pseudo labels for unlabelled data.
In terms of refining the pseudo labels, ScarceNet____ proposes a novel semi-supervised learning method that improves the reliability of pseudo label generation, effectively mitigating the data scarcity problem.
Similarly, CLAMP____ guides the learning process by incorporating external textual information, with promising performance achieved in both supervised and few-shot settings.
% \att{UniAP____ proposes a multi-task learning framework to address universal animal perception task.
% It takes multi-modal labels in the support sets as prompts to guide leaning, which achieves impressive performance even in few-shot setting.}
However, there have been few efforts to explore the potential of effective model structures without introducing external data.

This paper introduces the keypoint dependencies by using keypoint and prompt attention.
We note that the appearance and pose may vary heavily across mammal species, and the intrinsic dependencies among different keypoints also change with varying instances accordingly.
With this insight, we propose a novel Keypoint-Interactive Transformer for effectively learning instance-level structure-supporting keypoint dependencies.

\subsection{Vision Transformers}
\label{subec:vit}
The success of Vision Transformers (ViTs)____ on many vision tasks has been undisputed in recent years.
Given their capacity for establishing long-range dependencies, some studies____ observed that SAs exhibit intriguing properties compared to CNN approaches.
In particular, performing SAs for vision tasks produces improved robustness against image occlusions, perturbations, and domain shifts.
The underlying reason lies in that SAs achieve generalised spatial smoothing, which means that SAs obtain an appropriate inductive bias during training.
Recently, many pose estimation researchers____ are intrigued by the advantages of SAs.
They attempt to involve Transformer architecture in pose estimation and deliver promising performance.
For instance, HRFormer____ learns high-resolution representations along with the local-window self-attention module, decreasing the time consumption of the standard global-window formulation.
Similarly, TransPose____ directly employs the Transformer to learn global dependencies on the features extracted by CNN.
TokenPose____ introduces external tokens to represent keypoints and interact with the CNN image features.
ViTPose____, without using CNN backbones, designs a simple yet effective plain Vision Transformer architecture, achieving a new state-of-the-art in human pose estimation benchmarks.
% However, these approaches tend to get inferior performance in animal pose estimation, as the current data volume for animal pose estimation cannot support sufficient training, not to mention the large data variances across multiple mammal species.
However, these approaches tend to get inferior performance in animal pose estimation, as the limited size of current animal datasets is insufficient to support adequate training.
Besides, the Transformer-based methods have not taken into account the significant variations among different animal instances.
Drawing on this, we propose to explicitly introduce instance-level information and interact with keypoint tokens.