\begin{table*}[!htbp]
\small
\centering
\begin{tabular}{lc}
\toprule
LLM   & Error Categories and Frequency\\ 
\midrule
Mistral-7B-v2-Instruct (135 reasoning steps)   & NE - 94, M - 31, FH - 6, IP - 4\\  
Llama-3-8B-Instruct (145 reasoning steps)   & NE - 114, M - 29, FH - 1, IP - 2\\
GPT-3.5-turbo (109 reasoning steps)   & 	NE - 77, M - 30, FH - 1, IP - 0\\
GPT-4-turbo (148 reasoning steps)    & NE - 120, M - 25, FH - 0, IP - 2\\ 
\bottomrule
\end{tabular}
\caption{Statistics on various types of errors identified by human evaluators in the premises of 30 reasoning chains generated by each of the four LLMs. The total number of reasoning steps generated by each LLM is indicated in parentheses. `NE' denotes the absence of errors in the reasoning steps as annotated by human evaluators, `M' represents `Misinterpretation' errors, `FH' indicates `Factual Hallucination,' and `IP' signifies `Irrelevant Premises.'}
\label{table:manual-evaluation-premise}
\end{table*}