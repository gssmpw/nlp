\begin{table*}[!htbp]
\small
\centering
\begin{tabular}{lcc}
\toprule
LLM   & Statistics & Agreement \% (Recall) \\ 
\midrule
%     \begin{tabular}{ccc}
        Mistral-7B-v2-Instruct (30) & CC = 3, NC = 1, EE = 22, NE = 4 & R(C) = 3/4= 75\%, R(E) = 22/26 = 84.61\% \\
        Llama-3-8B-Instruct (30) & 	CC = 9, NC = 0, EE = 20, NE = 1 & R(C) = 9/9 = 100\%, R(E) = 20/21 = 95.23\% \\
        GPT-3.5-turbo (30) & 	CC = 4, NC = 3, EE = 21, NE = 1 & R(C) = 4/7 = 57\%, R(E) = 21/22 = 95.45\% \\
        GPT-4-turbo (30) & 	CC = 12, NC = 4, EE = 13, NE = 1 & R(C) = 12/16=75\%, R(E) = 13/14 = 92.85\% \\
%     \end{tabular}
\bottomrule
\end{tabular}
\caption{Agreement statistics between the GPT-4o-based auto-evaluator and human evaluators for the same 30 reasoning chains at the conclusion level across four LLMs (refer to Table \ref{table:manual-evaluation-conclusion}). `CC' represents agreement between the auto-evaluator and human evaluators on the absence of an error in a conclusion, while `NC' denotes disagreement on the absence of an error. `EE' indicates agreement on the presence of an error, and `NE' denotes disagreement on the presence of an error. `R(C)' refers to the recall percentage for agreement on error-free conclusions between the auto-evaluator and human evaluators, whereas `R(E)' denotes the recall percentage for agreement on conclusions containing errors.}
\label{table:auto-eval-agreement-conclusion}
\end{table*}