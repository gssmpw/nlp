\begin{table}[!htbp]
\centering
\begin{tabular}{lccc}
\toprule
Model   & S ($\uparrow$) & A ($\uparrow$)  & C ($\uparrow$)\\ 
\midrule
Mistral-7B-v2-Instruct   & 0.623  & 0.371 & 0.131\\ 
Llama-3-8B-Instruct   & 0.493  & 0.451 & 0.137\\ 
GPT-3.5-turbo   & 0.607  & 0.417 & 0.217\\ 
GPT-4-turbo     & 0.738  & 0.725 & 0.417\\ 
GPT-4o   & \textbf{0.784}  & \textbf{0.737} & \textbf{0.445}\\ 
\bottomrule
\end{tabular}
\caption{The results for soundness, accuracy, and correctness metrics for all LLMs on the \textit{Civ. Pro.} dataset. Here `S' denotes the Soundness, `A' denotes the Accuracy, and `C' denotes the Correctness.}
\label{table:metrics}
\end{table}