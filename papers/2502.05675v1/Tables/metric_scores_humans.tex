\begin{table}[!htbp]
\centering
\small
\begin{tabular}{lccc}
\toprule
LLM                       & S ($\uparrow$)& A ($\uparrow$)& C ($\uparrow$)\\
\midrule
Mistral-7B-v2-Instruct & 0.67      & 0.266    & 0.133       \\
Llama-3-8B-Instruct    & 0.718     & 0.433    & 0.266       \\
GPT-3.5-turbo          & 0.69      & 0.33     & 0.233       \\
GPT-4-turbo            & \textbf{0.748}    & \textbf{0.6}      & \textbf{0.5}\\ \bottomrule       
\end{tabular}
\caption{The results for soundness, accuracy, and correctness metrics for the same 30 LLM reasoning-chain generations across 4 LLMs by human annotators. Here `S' denotes the Soundness, `A' denotes the Accuracy, and `C' denotes the Correctness. The values marked in bold show the highest metric values.}
\label{table:metrics_humans}
\end{table}