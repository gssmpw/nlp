\begin{table}[ht]
\small
\centering
\begin{tabular}{lcccc}
\toprule
% \multirow{2}{*}{} & \multicolumn{4}{c}{Prompting Strategies} \\
% \cmidrule(lr){2-5}
Prompting               & B & PS & SC & SD \\
\midrule
\textbf{Gemini} & \multicolumn{4}{c}{} \\
w/o feedback     & 63.31    & 59.17          & \textbf{61.54}        & \textbf{64.50}          \\
w/ feedback      & \textbf{64.50}    & \textbf{62.13}          & 59.76        & 63.31          \\
\midrule
\textbf{Llama} & \multicolumn{4}{c}{} \\
w/o feedback     & 53.71    & 50.29          & 48.58        & 47.42          \\
w/ feedback      & \textbf{57.14}    & \textbf{52.00}          & \textbf{52.57  }      & \textbf{49.14}          \\
\bottomrule
\end{tabular}
\caption{Comparison of accuracy metric for models under different prompting strategies with and without feedback. The models are Gemini-1.5-Flash and Llama-3-8B-Instruct. The prompting strategies abbreviations stands for B: Baseline (CoT), PS: Plan-and-Solve, SC: Self-Correct, and SD: Self-Discovery.}
\label{table:prompt_accuracy}
\end{table}