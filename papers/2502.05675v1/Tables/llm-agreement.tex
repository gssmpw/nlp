\begin{table*}[!htbp]
\small
\centering
\begin{tabular}{lcc}
\toprule
LLM   & Statistics & Agreement \% (Recall) \\ 
\midrule
%     \begin{tabular}{ccc}
        Mistral-7B-v2-Instruct (135) & CC = 81, NC = 13, EE = 35, NE = 6 & R(C) = 81/94 = 86.17\%, R(E) = 35/41 = 85.3\% \\
        Llama-3-8B-Instruct (145) & 	CC = 107, NC = 7, EE = 26, NE = 5 & R(C) = 107/114 = 93.85\%, R(E) = 26/31 = 83.87\% \\
        GPT-3.5-turbo (109) & 	CC = 69, NC = 8, EE = 29, NE = 3 & R(C) = 69/77 = 89.61\%, R(E) = 29/32 = 90.6\% \\
        GPT-4-turbo (148) & CC = 104, NC = 16, EE = 25, NE = 3 & R(C) = 104/120 = 86.66\%, R(E) = 25/28 = 89.2\% \\
%     \end{tabular}
\bottomrule
\end{tabular}
\caption{Agreement statistics between the GPT-4o-based auto-evaluator and human evaluators for the same 30 reasoning chains at the premise level across four LLMs (refer to Table \ref{table:manual-evaluation-premise}). Numbers inside parentheses denote the total number of premise-level reasoning steps evaluated. `CC' represents agreement between the auto-evaluator and human evaluators on the absence of an error in a reasoning step, while 'NC' denotes disagreement on the absence of an error. `EE' indicates agreement on the presence of an error, and 'NE' denotes disagreement on the presence of an error. `R(C)' refers to the recall percentage for agreement on error-free steps between the auto-evaluator and human evaluators, whereas `R(E)' denotes the recall percentage for agreement on steps containing errors.}
\label{table:auto-eval-agreement-premise}
\end{table*}