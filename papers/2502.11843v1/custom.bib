% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}



%%%%% our references %%%%%%



@article{jiang2023personallm,
  title={Personallm: Investigating the ability of large language models to express personality traits},
  author={Jiang, Hang and Zhang, Xiajie and Cao, Xubo and Breazeal, Cynthia and Roy, Deb and Kabbara, Jad},
  journal={arXiv preprint arXiv:2305.02547},
  year={2023}
}


@article{tseng2024twotales,
  title={Two tales of persona in llms: A survey of role-playing and personalization},
  author={Tseng, Yu-Min and Huang, Yu-Chao and Hsiao, Teng-Yun and Hsu, Yu-Ching and Foo, Jia-Yin and Huang, Chao-Wei and Chen, Yun-Nung},
  journal={arXiv preprint arXiv:2406.01171},
  year={2024}
}


@article{dan2024ptailor,
  title={P-Tailor: Customizing Personality Traits for Language Models via Mixture of Specialized LoRA Experts},
  author={Dan, Yuhao and Zhou, Jie and Chen, Qin and Tian, Junfeng and He, Liang},
  journal={arXiv preprint arXiv:2406.12548},
  year={2024}
}


@article{mairesse2007usinglinguistcmarker,
  title={Using linguistic cues for the automatic recognition of personality in conversation and text},
  author={Mairesse, Fran{\c{c}}ois and Walker, Marilyn A and Mehl, Matthias R and Moore, Roger K},
  journal={Journal of artificial intelligence research},
  volume={30},
  pages={457--500},
  year={2007}
}

@article{han2024psydial,
  title={PSYDIAL: Personality-based Synthetic Dialogue Generation using Large Language Models},
  author={Han, Ji-Eun and Koh, Jun-Seok and Seo, Hyeon-Tae and Chang, Du-Seong and Sohn, Kyung-Ah},
  journal={arXiv preprint arXiv:2404.00930},
  year={2024}
}


@article{zhu2025investigating,
  title={Investigating Large Language Models in Inferring Personality Traits from User Conversations},
  author={Zhu, Jianfeng and Jin, Ruoming and Coifman, Karin G},
  journal={arXiv preprint arXiv:2501.07532},
  year={2025}
}

@article{huang2024designing,
  title={Designing LLM-Agents with Personalities: A Psychometric Approach},
  author={Huang, Muhua and Zhang, Xijuan and Soto, Christopher and Evans, James},
  journal={arXiv preprint arXiv:2410.19238},
  year={2024}
}

@inproceedings{sun2024revealing,
    title = "Revealing Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition on Dialogues",
    author = "Sun, Lei  and
      Zhao, Jinming  and
      Jin, Qin",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
}

@inproceedings{zhang-etal-2018-personalizing,
    title = "Personalizing Dialogue Agents: {I} have a dog, do you have pets too?",
    author = "Zhang, Saizheng  and
      Dinan, Emily  and
      Urbanek, Jack  and
      Szlam, Arthur  and
      Kiela, Douwe  and
      Weston, Jason",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1205/",
    doi = "10.18653/v1/P18-1205",
    pages = "2204--2213",
    abstract = "Chit-chat models are known to have several problems: they lack specificity, do not display a consistent personality and are often not very captivating. In this work we present the task of making chit-chat more engaging by conditioning on profile information. We collect data and train models to (i)condition on their given profile information; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors."
}


@article{xi2025rise,
  title={The rise and potential of large language model based agents: A survey},
  author={Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  journal={Science China Information Sciences},
  volume={68},
  number={2},
  pages={121101},
  year={2025},
  publisher={Springer}
}


@article{ireland2014natural,
  title={Natural language use as a marker},
  author={Ireland, Molly E and Mehl, Matthias R},
  journal={The Oxford handbook of language and social psychology},
  pages={201--237},
  year={2014},
  publisher={Oxford University Press Oxford}
}

@article{pennebaker1999linguistic,
  title={Linguistic styles: language use as an individual difference.},
  author={Pennebaker, James W and King, Laura A},
  journal={Journal of personality and social psychology},
  volume={77},
  number={6},
  pages={1296},
  year={1999},
  publisher={American Psychological Association}
}


@article{fleiss1971measuring,
  title={Measuring nominal scale agreement among many raters.},
  author={Fleiss, Joseph L},
  journal={Psychological bulletin},
  volume={76},
  number={5},
  pages={378},
  year={1971},
  publisher={American Psychological Association}
}


@article{cohen1960coefficient,
  title={A coefficient of agreement for nominal scales},
  author={Cohen, Jacob},
  journal={Educational and psychological measurement},
  volume={20},
  number={1},
  pages={37--46},
  year={1960},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{perez2020systematic,
  title={Systematic literature reviews in software engineering—Enhancement of the study selection process using Cohen’s kappa statistic},
  author={P{\'e}rez, Jorge and D{\'\i}az, Jessica and Garcia-Martin, Javier and Tabuenca, Bernardo},
  journal={Journal of Systems and Software},
  volume={168},
  pages={110657},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{li2024steerability,
  title={The steerability of large language models toward data-driven personas},
  author={Li, Junyi and Peris, Charith and Mehrabi, Ninareh and Goyal, Palash and Chang, Kai-Wei and Galstyan, Aram and Zemel, Richard and Gupta, Rahul},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={7283--7298},
  year={2024}
}


@article{atherton2022stability,
  title={Stability and change in the Big Five personality traits: Findings from a longitudinal study of Mexican-origin adults.},
  author={Atherton, Olivia E and Sutin, Angelina R and Terracciano, Antonio and Robins, Richard W},
  journal={Journal of Personality and Social Psychology},
  volume={122},
  number={2},
  pages={337},
  year={2022},
  publisher={American Psychological Association}
}

@inproceedings{kim2025can,
  title={Can Large Language Models Differentiate Harmful from Argumentative Essays? Steps Toward Ethical Essay Scoring},
  author={Kim, Hongjin and Kang, Jeonghyun and Kim, Harksoo},
  booktitle={Proceedings of the 31st International Conference on Computational Linguistics},
  pages={8121--8147},
  year={2025}
}


@inproceedings{yeo-etal-2025-pado,
    title = "{PADO}: Personality-induced multi-Agents for Detecting {OCEAN} in human-generated texts",
    author = "Yeo, Haein  and
      Noh, Taehyeong  and
      Jin, Seungwan  and
      Han, Kyungsik",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.382/",
    pages = "5719--5736",
    abstract = "As personality can be useful in many cases, such as better understanding people`s underlying contexts or providing personalized services, research has long focused on modeling personality from data. However, the development of personality detection models faces challenges due to the inherent latent and relative characteristics of personality, as well as the lack of annotated datasets. To address these challenges, our research focuses on methods that effectively exploit the inherent knowledge of Large Language Models (LLMs). We propose a novel approach that compares contrasting perspectives to better capture the relative nature of personality traits. In this paper, we introduce PADO (Personality-induced multi-Agent framework for Detecting OCEAN of the Big Five personality traits), the first LLM-based multi-agent personality detection framework. PADO employs personality-induced agents to analyze text from multiple perspectives, followed by a comparative judgment process to determine personality trait levels. Our experiments with various LLM models, from GPT-4o to LLaMA3-8B, demonstrate PADO`s effectiveness and generalizability, especially with smaller parameter models. This approach offers a more nuanced, context-aware method for personality detection, potentially improving personalized services and insights into digital behavior. We will release our codes."
}


@article{john1991bfi,
  title={Big five inventory},
  author={John, Oliver P and Donahue, Eileen M and Kentle, Robert L},
  journal={Journal of personality and social psychology},
  year={1991}
}

@article{bfi10,
  title={The 10-item big five inventory},
  author={Rammstedt, Beatrice},
  journal={European Journal of Psychological Assessment},
  volume={23},
  number={3},
  pages={193--201},
  year={2007},
  publisher={Hogrefe \& Huber Publishers}
}

@inproceedings{mypersonality,
  title={Data Augmented Graph Neural Networks for Personality Detection},
  author={Zhu, Yangfu and Xia, Yue and Li, Meiling and Zhang, Tingting and Wu, Bin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={1},
  pages={664--672},
  year={2024}
}

@inproceedings{twitterdata,
  title={When llm meets hypergraph: A sociological analysis on personality via online social networks},
  author={Shu, Zhiyao and Sun, Xiangguo and Cheng, Hong},
  booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
  pages={2087--2096},
  year={2024}
}

@inproceedings{bhandari2025evaluating,
  title={Evaluating Personality Traits in Large Language Models: Insights from Psychological Questionnaires},
  author={Bhandari, Pranav and Naseem, Usman and Datta, Amitava and Fay, Nicolas and Nasim, Mehwish},
  booktitle={Companion Proceedings of the ACM Web Conference},
  url       = {http://arxiv.org/abs/2502.05248},
  year={2025}
}


@inproceedings{frisch-giulianelli-2024-llm,
    title = "{LLM} Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models",
    author = "Frisch, Ivar  and
      Giulianelli, Mario",
    editor = "Deshpande, Ameet  and
      Hwang, EunJeong  and
      Murahari, Vishvak  and
      Park, Joon Sung  and
      Yang, Diyi  and
      Sabharwal, Ashish  and
      Narasimhan, Karthik  and
      Kalyan, Ashwin",
    booktitle = "Proceedings of the 1st Workshop on Personalization of Generative AI Systems (PERSONALIZE 2024)",
    month = mar,
    year = "2024",
    address = "St. Julians, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.personalize-1.9/",
    pages = "102--111",
    abstract = "Agent interaction has long been a key topic in psychology, philosophy, and artificial intelligence, and it is now gaining traction in large language model (LLM) research. This experimental study seeks to lay the groundwork for our understanding of dialogue-based interaction between LLMs: Do persona-prompted LLMs show consistent personality and language use in interaction? We condition GPT-3.5 on asymmetric personality profiles to create a population of LLM agents, administer personality tests and submit the agents to a collaborative writing task. We find different profiles exhibit different degrees of personality consistency and linguistic alignment in interaction."
}


@article{husain2025reliability,
  title={Reliability generalization meta-analysis of the internal consistency of the Big Five Inventory (BFI) by comparing BFI (44 items) and BFI-2 (60 items) versions controlling for age, sex, language factors},
  author={Husain, Waqar and Haddad, Areen Jamal and Husain, Muhammad Ahmad and Ghazzawi, Hadeel and Trabelsi, Khaled and Ammar, Achraf and Saif, Zahra and Pakpour, Amir and Jahrami, Haitham},
  journal={BMC psychology},
  volume={13},
  number={1},
  pages={20},
  year={2025},
  publisher={Springer}
}


@inproceedings{klinkert2024evaluating,
  title={Evaluating the efficacy of LLMs to emulate realistic human personalities},
  author={Klinkert, Lawrence J and Buongiorno, Steph and Clark, Corey},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={20},
  number={1},
  pages={65--75},
  year={2024}
}

@article{boyd2022development,
  title={The development and psychometric properties of LIWC-22},
  author={Boyd, Ryan L and Ashokkumar, Ashwini and Seraj, Sarah and Pennebaker, James W},
  journal={Austin, TX: University of Texas at Austin},
  volume={10},
  year={2022}
}

@article{openai2024gpt4omini,
  title = {GPT-4o mini: advancing cost-efficient intelligence},
  author = {OpenAI},
  year = {2024},
  month = {July},
  url = {https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/}
}
@misc{llama_cite,
      title={The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink}, 
      author={David Patterson and Joseph Gonzalez and Urs Hölzle and Quoc Le and Chen Liang and Lluis-Miquel Munguia and Daniel Rothchild and David So and Maud Texier and Jeff Dean},
      year={2022},
      eprint={2204.05149},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2204.05149}, 
}