@article{bfi10,
  title={The 10-item big five inventory},
  author={Rammstedt, Beatrice},
  journal={European Journal of Psychological Assessment},
  volume={23},
  number={3},
  pages={193--201},
  year={2007},
  publisher={Hogrefe \& Huber Publishers}
}

@inproceedings{bhandari2025evaluating,
  title={Evaluating Personality Traits in Large Language Models: Insights from Psychological Questionnaires},
  author={Bhandari, Pranav and Naseem, Usman and Datta, Amitava and Fay, Nicolas and Nasim, Mehwish},
  booktitle={Companion Proceedings of the ACM Web Conference},
  url       = {http://arxiv.org/abs/2502.05248},
  year={2025}
}

@article{dan2024ptailor,
  title={P-Tailor: Customizing Personality Traits for Language Models via Mixture of Specialized LoRA Experts},
  author={Dan, Yuhao and Zhou, Jie and Chen, Qin and Tian, Junfeng and He, Liang},
  journal={arXiv preprint arXiv:2406.12548},
  year={2024}
}

@inproceedings{frisch-giulianelli-2024-llm,
    title = "{LLM} Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models",
    author = "Frisch, Ivar  and
      Giulianelli, Mario",
    editor = "Deshpande, Ameet  and
      Hwang, EunJeong  and
      Murahari, Vishvak  and
      Park, Joon Sung  and
      Yang, Diyi  and
      Sabharwal, Ashish  and
      Narasimhan, Karthik  and
      Kalyan, Ashwin",
    booktitle = "Proceedings of the 1st Workshop on Personalization of Generative AI Systems (PERSONALIZE 2024)",
    month = mar,
    year = "2024",
    address = "St. Julians, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.personalize-1.9/",
    pages = "102--111",
    abstract = "Agent interaction has long been a key topic in psychology, philosophy, and artificial intelligence, and it is now gaining traction in large language model (LLM) research. This experimental study seeks to lay the groundwork for our understanding of dialogue-based interaction between LLMs: Do persona-prompted LLMs show consistent personality and language use in interaction? We condition GPT-3.5 on asymmetric personality profiles to create a population of LLM agents, administer personality tests and submit the agents to a collaborative writing task. We find different profiles exhibit different degrees of personality consistency and linguistic alignment in interaction."
}

@article{han2024psydial,
  title={PSYDIAL: Personality-based Synthetic Dialogue Generation using Large Language Models},
  author={Han, Ji-Eun and Koh, Jun-Seok and Seo, Hyeon-Tae and Chang, Du-Seong and Sohn, Kyung-Ah},
  journal={arXiv preprint arXiv:2404.00930},
  year={2024}
}

@article{huang2024designing,
  title={Designing LLM-Agents with Personalities: A Psychometric Approach},
  author={Huang, Muhua and Zhang, Xijuan and Soto, Christopher and Evans, James},
  journal={arXiv preprint arXiv:2410.19238},
  year={2024}
}

@article{jiang2023personallm,
  title={Personallm: Investigating the ability of large language models to express personality traits},
  author={Jiang, Hang and Zhang, Xiajie and Cao, Xubo and Breazeal, Cynthia and Roy, Deb and Kabbara, Jad},
  journal={arXiv preprint arXiv:2305.02547},
  year={2023}
}

@inproceedings{klinkert2024evaluating,
  title={Evaluating the efficacy of LLMs to emulate realistic human personalities},
  author={Klinkert, Lawrence J and Buongiorno, Steph and Clark, Corey},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={20},
  number={1},
  pages={65--75},
  year={2024}
}

@inproceedings{mypersonality,
  title={Data Augmented Graph Neural Networks for Personality Detection},
  author={Zhu, Yangfu and Xia, Yue and Li, Meiling and Zhang, Tingting and Wu, Bin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={1},
  pages={664--672},
  year={2024}
}

@inproceedings{sun2024revealing,
    title = "Revealing Personality Traits: A New Benchmark Dataset for Explainable Personality Recognition on Dialogues",
    author = "Sun, Lei  and
      Zhao, Jinming  and
      Jin, Qin",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
}

@inproceedings{twitterdata,
  title={When llm meets hypergraph: A sociological analysis on personality via online social networks},
  author={Shu, Zhiyao and Sun, Xiangguo and Cheng, Hong},
  booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
  pages={2087--2096},
  year={2024}
}

@article{xi2025rise,
  title={The rise and potential of large language model based agents: A survey},
  author={Xi, Zhiheng and Chen, Wenxiang and Guo, Xin and He, Wei and Ding, Yiwen and Hong, Boyang and Zhang, Ming and Wang, Junzhe and Jin, Senjie and Zhou, Enyu and others},
  journal={Science China Information Sciences},
  volume={68},
  number={2},
  pages={121101},
  year={2025},
  publisher={Springer}
}

@inproceedings{yeo-etal-2025-pado,
    title = "{PADO}: Personality-induced multi-Agents for Detecting {OCEAN} in human-generated texts",
    author = "Yeo, Haein  and
      Noh, Taehyeong  and
      Jin, Seungwan  and
      Han, Kyungsik",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.382/",
    pages = "5719--5736",
    abstract = "As personality can be useful in many cases, such as better understanding people`s underlying contexts or providing personalized services, research has long focused on modeling personality from data. However, the development of personality detection models faces challenges due to the inherent latent and relative characteristics of personality, as well as the lack of annotated datasets. To address these challenges, our research focuses on methods that effectively exploit the inherent knowledge of Large Language Models (LLMs). We propose a novel approach that compares contrasting perspectives to better capture the relative nature of personality traits. In this paper, we introduce PADO (Personality-induced multi-Agent framework for Detecting OCEAN of the Big Five personality traits), the first LLM-based multi-agent personality detection framework. PADO employs personality-induced agents to analyze text from multiple perspectives, followed by a comparative judgment process to determine personality trait levels. Our experiments with various LLM models, from GPT-4o to LLaMA3-8B, demonstrate PADO`s effectiveness and generalizability, especially with smaller parameter models. This approach offers a more nuanced, context-aware method for personality detection, potentially improving personalized services and insights into digital behavior. We will release our codes."
}

@inproceedings{zhang-etal-2018-personalizing,
    title = "Personalizing Dialogue Agents: {I} have a dog, do you have pets too?",
    author = "Zhang, Saizheng  and
      Dinan, Emily  and
      Urbanek, Jack  and
      Szlam, Arthur  and
      Kiela, Douwe  and
      Weston, Jason",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1205/",
    doi = "10.18653/v1/P18-1205",
    pages = "2204--2213",
    abstract = "Chit-chat models are known to have several problems: they lack specificity, do not display a consistent personality and are often not very captivating. In this work we present the task of making chit-chat more engaging by conditioning on profile information. We collect data and train models to (i)condition on their given profile information; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors."
}

@article{zhu2025investigating,
  title={Investigating Large Language Models in Inferring Personality Traits from User Conversations},
  author={Zhu, Jianfeng and Jin, Ruoming and Coifman, Karin G},
  journal={arXiv preprint arXiv:2501.07532},
  year={2025}
}

