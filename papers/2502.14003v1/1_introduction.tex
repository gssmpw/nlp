\section{Introduction}

\input{fig_teaser}
Associative memory models have been proposed to model memory retrieval in the brain through fixed-point search in an artificial neural network. Hopfield networks~\citep{hopfield82,hopfield88} are classic examples, based on the idea of using recurrently connected neurons to store and retrieve memory patterns. Although these models are theoretically sound, they suffer limited memory capacity, as the number of distinct memory patterns is at most proportional to the dimension of the feature space.
Recently, numerous studies have explored models with significantly increased memory capacity, the so-called modern Hopfield networks (MHNs)~\citep{krotov16dense,demircigil17hugecapacity,krotov2018dense,BARRA2018205,agliari2020tolerance}.
Some of them are known to have an exponentially large memory capacity with respect to the feature dimension~\cite{demircigil17hugecapacity}.

From a theoretical perspective,
\citet{krotov2021large} introduced a dynamical system that represents associative memory in a continuous time space based on two-body interactions between neurons.
In their system, two Lagrangian functions, one for memory neurons and one for feature neurons, determine the model dynamics.
When certain pairs of Lagrangian functions are chosen,
the system is reduced to classical Hopfield networks~\cite{hopfield82},
dense associative memory~\cite{krotov16dense, demircigil17hugecapacity},
or the MHNs described in \citet{ramsauer21hopfieldallyouneed}, indicating that new Lagrangian function designs could lead to new MHNs.


While these studies have expanded the potential of MHNs both theoretically and practically, one of the primary limitations of existing MHNs lies in managing out-of-distribution (OOD) samples.
The dynamical system does find a fixed point for any test input; \textit{i.e.}, an OOD sample is inevitably associated with one of the memorized in-distribution (ID) samples.
\citet{zhang23she} proposed an OOD-sample detection method based on the Hopfield energy function.
However, they lack theoretical foundation explaining the relationship between the energy and the probability of the input/transient states.
We are thus motivated to develop new MHNs equipping probability-aware OOD rejection functionality within the fixed-point search mechanism.

In this paper, we propose the rectified Lagrangian (RegLag), a new Lagrangian for memory neurons that creates an attractor for OOD samples in the dynamical system of MHNs, as shown in Fig.~\ref{fig:teaser}.
RegLag introduces a rectified linear unit (ReLU) with a constant indicating the ID memory strength to the Lagrangian function of memory neurons.
We theoretically show that 1) RecLag creates a trivial point attractor for any interaction matrix and 2) RecLag-based MHNs are reduced to vanilla MHNs when the ID memory strength is infinitely large, indicating our approach is a natural extension of existing MHNs.
We further devise a training method for RecLag-based MHNs via probabilistic interaction, along with a probability density estimated for ID samples by optimizing the interaction matrix.
%is optimized so that data samples with low probability density values fall into the attractor created by RecLag.
Our contributions are summarized below:
\begin{enumerate}
\item We propose RecLag, a new Lagrangian
for memory neurons. RecLag is designed to create a trivial point attractor for any interaction matrix, enabling OOD detection by identifying samples that fall into the attractor as OOD.
\item We propose a training method for RecLag-based MHNs having a probabilistic interaction between memory and feature neurons. We prove that samples with low probability fall into the special attractor created by RecLag.
\item We demonstrated the effectiveness of our approach in comparison with energy-based OOD detection methods, including those using state-of-the-art Hopfield energy functions~\cite{zhang23she} on nine image datasets.
\end{enumerate}
%To the best of our knowledge, we are first to propose MHNs that explicitly employ an attractor for OOD samples.

