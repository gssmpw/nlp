
\section{Conclusion}
We proposed the RecLag function, a specially designed Lagrangian
to equip MHNs with OOD rejection functionality.
In our method, the interaction matrix is optimized so as to compute probability densities, which are used to determine ID/OOD.
Theoretically, RecLag-based MHNs reduces to vanilla MHNs when the ID memory strength is infinitely large; therefore, the proposed method is a natural extension of existing MHNs.
Experiments on nine image datasets demonstrated the effectiveness of our approach, surpassing energy-based OOD detection methods. 
%In summary, this work contributed both theoretically and practically to equip MHNs with OOD rejection functionality. 

\noindent \textbf{Limitation.}
While this work introduced a new Lagrangian for memory neurons, the Lagrangian for feature neurons remains underexplored. Similar to previous works, we used the activation function $g$ that takes the simplest form in Euclidean space, $g_{i}(v) =v_{i}$, because recent deep learning efforts often assume that the feature space is Euclidean.
Investigating new Lagrangians in other non-linear feature spaces, such as spherical or hyperbolic space, might be promising.

\noindent \textbf{Future Work.}
In future work, we will focus on generalizing RecLag for structured memory patterns such as hierarchical memory patterns. Applications to regression tasks are also intriguing.
We believe this work has opened up new avenues for exploring the potential of MHNs.

\section*{Acknowledgements}
This work was supported by JSPS KAKENHI Grant Number JP22H03642 and DENSO IT LAB Recognition and Learning Algorithm Collaborative Research Chair (Science Tokyo).
We thank Toshihiro Ota for fruitful discussion.
