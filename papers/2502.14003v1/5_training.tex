\section{Training via Probabilistic Interaction}

This section discuss the basin of the attractor created by RecLag, and proposes a method for training the interaction matrix with ID samples.
Because the basin obviously involves $B_{0} = \{v: G(v) < 0\}$, as shown in the sketch of the proof for Theorem 1, we introduce a method to train the interaction matrix via probabilistic interaction, by which data samples with low probability density values fall into $B_{0}$.

\subsection{Probabilistic Interaction}
The probabilistic interaction explicitly chooses a single memory neuron for each input feature during training in a probabilistic manner.
This creates a cycle of interaction between feature neurons and memory neurons in the following two steps. First, given an input feature $x \in \mathbb{R}^{\Numv}$,
a memory neuron is sampled as $\mu \sim p_{H}(\mu|x)$, where
$\mu \in \{1, 2, \cdots, \Numh\}$ is an index of memory neurons and $p_{H}(\mu|x)$ is a pre-defined conditional probability mass distribution.
Second, given an index $\mu$,
an output feature $y \in \mathbb{R}^{\Numv}$ is sampled as $y \sim p_{V}(y|\mu)$, where $p_{V}(y|\mu)$ is a pre-defined conditional probability density distribution.

Because this interaction can be understood as the stochastic feedforward neural network (SFNN) proposed by \citet{tang13sfnn}, which samples an index of neurons in a hidden layer, we train the interaction matrix using the training method for SFNN.
Specifically, given a set of ID data samples $\mathcal{D} \subset \mathbb{R}^{\Numv}$, the interaction matrix $\xi$ is trained to maximize the sum of probability products:
\begin{align}
\label{eq:objective_sfnn}
P = \sum_{x \in \mathcal{D}} p_{V}(x|\mu) p_{H}(\mu|x).  
\end{align}
Here, the distribution $p_{H} (\mu|x)$ is computed through the joint probability distribution described in the next subsection.
The distribution $p_{V}(x|\mu)$ is used only for training, and thus we use a Gaussian distribution following \citet{tang13sfnn}:\begin{align}
p_{V}(x|\mu)
\hspace{-2pt}
=\hspace{-2pt}
\frac{1}{\sqrt{(2\pi)^{\Numv} |\Sigma|}}
\exp
\hspace{-2pt}
\left(
\hspace{-2pt}
-\frac{1}{2} (x - \xi_{\mu})^{\top} \Sigma^{-1} (x - \xi_{\mu}) \right)
\end{align}
where $\Sigma$ is a learnable covariance matrix.

\subsection{Attracting Probability}
Interestingly, there exists a joint probability distribution $p_{H}(x, \mu)$ that relates the SFNN and the basin $B_{0}$.
Specifically, Definition 2 provides the joint probability distribution, by which the conditional probability for the SFNN is computed as $p_{H}(\mu|x) = p_{H}(x, \mu)/\sum_{\mu}p_{H}(x, \mu)$, and data samples with low probability density values fall into the basin.

\vspace{5pt}
\noindent \textit{\textbf{Definition 2.}
Let $X$ be a continuous random variable of feature neurons over $\mathbb{R}^{\Numv}$, and let $M$ be a discrete random variable of the index of hidden neurons over $\{1, 2, \cdots, \Numh\}$.
We define the joint probability distribution function as
\begin{align}
\label{eq:reclagprob}
p_{H}(X=x, M=\mu) &= \frac{1}{Z} \exp \left(
{\beta \sum_{j=1}^{\Numv} \xi_{\mu j} x_{j}}
\right).
\end{align}
Here, $Z$ is a normalization constant given by
\begin{align}
Z &= \sum_{\mu=1}^{\Numh} \int_{\mathcal{S}}
\exp \left(
{\beta \sum_{j=1}^{\Numv} \xi_{\mu j} x_{j}} \right) dx,
\end{align}
where $\mathcal{S} \in \mathbb{R}^{\Numv}$ is a sufficiently large hypersphere to cover all data samples.
}

\subsection{OOD detection}
Finally, Theorem~3 shows that the probability density distribution $p_{H}(x) = \sum_{\mu} p_{H}(x, \mu)$ explicitly models the distribution of ID samples and that all data samples with a probability density lower than $\delta$ fall into the attractor created by RecLag.
Therefore, OOD samples can be detected by evaluating $p_{H}(\tilde{v})$ given a test sample $\tilde{v} \in \mathbb{R}^{\Numv}$. A proof is given in Appendix C.

\vspace{5pt}
\noindent \textit{\textbf{Theorem 3.}
The basin $B_{0} = \{ v : G(v) < 0\}$ is identical to the set of points that have low probability density values.
In other words, a threshold $\delta$ exists such that
\begin{align}
B_{0} = \{x : p_{H}(X = x) < \delta\}.
\end{align}
}
\vspace{-8pt}

\noindent \textbf{Visualization.}
Figure~\ref{fig:energy}(d) shows the probability density function, where the basin boundary is drawn in white.

\begin{table*}[t]
\centering
\setlength{\tabcolsep}{6.5pt}
{\footnotesize
\begin{tabular}{p{0cm}l|rrrrrrrrr|r}
\toprule
\multicolumn{2}{l|}{Method} & SVHN & LSUN-C & LSUN-R & iSUN & Places & DTD & TIN & SUN & iNaturalist & Average \\
\midrule
\multirow{6}{*}{\rotatebox[origin=c]{90}{ ResNet18}}
 & MSP & 76.34 & 27.52 & 36.54 & 34.84  & 20.55 & 30.65 & 45.82 & 22.89 & 12.62 & 34.19\\
 & Energy & 56.05 & 8.10 & 11.60 & 9.10 & 3.18 & 16.98 & 25.47 & 3.27 & 3.47 & 15.25  \\
 & ReAct & 59.47 & 7.57 & 12.52 & 10.13 & 2.93 & 16.86 & 27.61 & 3.27 & 3.80 & 16.02 \\
 %& MHE & 17.59 & 9.20 & 7.68 & 4.74 & 0.44 & 9.05 & \textbf{10.17} & \textbf{0.00} & 2.80 & 6.85 \\
 & MHE & 17.59 & 9.20 & 7.68 & 4.74 & 0.33 & 8.96 & 15.86 & \textbf{0.00} & 2.35 & 7.41 \\
 & SHE & \textbf{17.45} & 9.22 & 7.69 & 4.77 & 0.33 & 8.99 & 15.84 & \textbf{0.00} & 2.38 & 7.41 \\ 
 %& RecLag & \textbf{16.40} & \textbf{6.51}& \textbf{4.71} & \textbf{2.66} & \textbf{0.24} & \textbf{6.66} & \textbf{11.72} & \textbf{0.00} & \textbf{1.69} & \textbf{5.62} \\
 & RecLag & 18.12 & \textbf{6.40}& \textbf{4.60} & \textbf{2.67} & \textbf{0.28} & \textbf{6.82} & \textbf{12.09} & \textbf{0.00} & \textbf{1.68} & \textbf{5.85} \\
 & & $\pm$ 2.02 & \textbf{$\pm$ 0.25}& \textbf{$\pm$ 0.12} & \textbf{$\pm$ 0.47} & \textbf{$\pm$ 0.02} & \textbf{$\pm$ 0.13} & \textbf{$\pm$ 0.25} & \textbf{$\pm $0.00} & \textbf{$\pm$ 0.04} & \textbf{$\pm$ 0.24} \\

 
\midrule
\multirow{6}{*}{\rotatebox[origin=c]{90}{ ResNet34}}
& MSP & 59.86 & 28.26 & 32.06 & 31.69 & 33.61 & 43.28 & 45.56 & 32.43 & 32.95 & 37.74\\
& Energy& 30.51 & 6.84 & 9.43 & 8.47 & 9.32 & 23.74 & 25.16 & 8.99 & 10.86 & 14.81\\
& ReAct& 45.86 & 14.37 & 14.09 & 13.28 & 15.83 & 29.73 & 31.60 & 15.53 & 11.98 & 21.36\\
%& MHE& 6.20 & 6.17 & 4.40 & 2.94 & 2.34 & 13.32 & 15.86 & \textbf{0.54} & 4.91 & 6.30\\
& MHE& 6.20 & 6.17 & 4.40 & 2.94 & 2.34 & 14.32 & 15.86 & 0.54 & 4.91 & 6.41\\
& SHE & 6.14 & 6.20 & 4.45 & 3.01 & 2.36 & 14.32 & 15.93 & 0.54 & 4.92 & 6.43 \\
%& RecLag & \textbf{4.69} & \textbf{5.56} & \textbf{2.76} & \textbf{2.04} & \textbf{2.27} & \textbf{11.95} & \textbf{11.30} & \textbf{0.54} & \textbf{4.01} & \textbf{5.01} \\
& RecLag & \textbf{5.19} & \textbf{5.60} & \textbf{2.85} & \textbf{2.11} & \textbf{2.31} & \textbf{12.04} & \textbf{11.71} & \textbf{0.33} & \textbf{4.14} & \textbf{5.14} \\
& & \textbf{$\pm$ 0.24} & \textbf{$\pm$ 0.07} & \textbf{$\pm$ 0.05} & \textbf{$\pm$ 0.05} & \textbf{$\pm$ 0.03} & \textbf{$\pm$ 0.07} & \textbf{$\pm$ 0.23} & \textbf{$\pm$ 0.11} & \textbf{$\pm$ 0.08} & \textbf{$\pm$ 0.08} \\

\midrule
\multirow{6}{*}{\rotatebox[origin=c]{90}{WRN40-2}}
& MSP & 41.52 & 44.43 & 38.47 & 39.70 & 33.84 & 35.80 & 51.52 & 34.88 & 27.69 & 38.65\\
& Energy & 15.35 & 17.77 & 14.98 & 17.45 & 10.58 & 19.71 & 36.75 & 9.54 & 8.95 & 16.79\\
& ReAct& 18.83 & 19.93 & 18.25 & 20.68 & 11.98 & 21.67 & 42.02 & 11.44 & 13.26 & 19.78\\
& MHE & 5.40 & 14.60 & 12.03  & 11.48 & 2.90 & 10.99 & 27.28 & \textbf{0.82} & 1.83 & 9.70\\
& SHE & \textbf{5.25} & 14.39 & 13.18  & 12.39 & 2.83 & 10.98 & 28.35 & \textbf{0.82} & 1.84 & 10.00\\
%& RecLag & 5.76 & \textbf{6.51} & \textbf{8.40} & \textbf{8.11} & 2.86 & \textbf{9.95} & \textbf{22.40} & 1.63 & \textbf{1.70} & \textbf{7.48} \\
& RecLag & 5.75 & \textbf{7.37} & \textbf{8.44 } & \textbf{8.01 } &  \textbf{2.63}& \textbf{9.75} & \textbf{22.62} & 1.06 & \textbf{1.67}  & \textbf{7.47} \\
& & $\pm$ 0.12& \textbf{$\pm$ 0.18} & \textbf{$\pm$ 0.17} & \textbf{$\pm$ 0.15} & \textbf{$\pm$ 0.05} & \textbf{ $\pm$ 0.10} & \textbf{$\pm$ 0.34} & $\pm$ 0.09 & \textbf{$\pm$ 0.05} &  \textbf{$\pm$ 0.85} \\

\bottomrule
\end{tabular}
}
\caption{OOD detection performance as
FPR95(\%) $\downarrow$ with CIFAR-10 images being ID samples. Our RecLag-based MHN (RecLag) is compared with MSP~\cite{hendrycks2017msp}, Energy~\cite{liu2020energy}, ReAct~\cite{sun2021react}, MHE~\cite{zhang23she}, and SHE~\cite{zhang23she}. 
For the proposed RecLag the trimmed means and standard deviations (following Â± symbols) over 11 trials with the largest and the smallest ones being trimmed  are reported.}
\label{tab:fpr}
\end{table*}

