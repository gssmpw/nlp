\newcommand{\Lagh}{L_{H}}
\newcommand{\Lagv}{L_{V}}
\newcommand{\Numh}{N_{H}}
\newcommand{\Numv}{N_{V}}
\newcommand{\tauh}{\tau_{H}}
\newcommand{\tauv}{\tau_{V}}

\section{Modern Hopfield Networks}

\subsection{Lagrangian-Based Dynamical System}
\textbf{Notation and Settings.}
This paper discusses MHNs with the Lagrangian-based dynamical system proposed by \citet{krotov2021large}.
We denote the feature neurons as $v(t) \in \mathbb{R}^{\Numv}$ and the memory neurons as $h(t) \in \mathbb{R}^{\Numh}$, both at continuous time $t \in \mathbb{R}_{\ge 0}$, where $\Numv, \Numh \in \mathbb{N}$ are the numbers of neurons.
The dynamical system is described by the following differential equations:
\begin{align}
\label{eq:de_v}
\tauv \frac{d v_{i}(t)}{d t} &=\sum_{\mu=1}^{\Numh} \xi_{i \mu} f_{\mu}(h(t)) - v_{i}(t),  \\
\label{eq:de_h}
\tauh \frac{d h_\mu(t)}{d t} &=\sum_{i=1}^{\Numv} \xi_{\mu i} g_{i}(v(t)) - h_{\mu}(t),
\end{align}
where $\xi \in \mathbb{R}^{\Numh \times \Numv}$ is an interaction matrix representing the strength of synapses,
$f: \mathbb{R}^{\Numh} \to \mathbb{R}^{\Numh}$ and 
$g: \mathbb{R}^{\Numv} \to \mathbb{R}^{\Numv}$ are activation functions,
and $\tauv, \tauh \in \mathbb{R}$ are constants that determine the dynamics of neurons.
The activation functions are determined by the Lagrangians $\Lagh: \mathbb{R}^{\Numh}\to \mathbb{R}$ and $\Lagv: \mathbb{R}^{\Numv}\to \mathbb{R}$ such that
\begin{align}
f(h) = \frac{\partial \Lagh(h)}{\partial h}, \quad g(v) = \frac{\partial \Lagv(v)}{\partial v},
\end{align}
where $h \in \mathbb{R}^{\Numh}$ and $v \in \mathbb{R}^{\Numv}$.
The energy function is then given by
\begin{align}
E(v, h)
=&
\sum_{i=1}^{\Numv} v_{i} g_{i}(v)
-
\Lagv(v)
+
\sum_{\mu=1}^{\Numh} h_{\mu} f_{\mu}(h)\nonumber \\
&-
\Lagh(h)
-
\sum_{\mu, i} f_{\mu}(h) \xi_{\mu i} g_{i}(v).
\end{align}
Note that this energy monotonically decreases; that is, we have
$dE(v(t),h(t))/dt \leq 0$ along the trajectory of the dynamical system when the Hessian matrices of the Lagrangians are positive semi-definite.

\noindent \textbf{Lagrangians.}
If we suppose a fixed interaction matrix $\xi$, then the model dynamics are defined by the choice of the Lagrangians.
For example, when the Lagrangian functions are given by the additive functions
\begin{align}
\label{eq:lag_classic}
\Lagh(h) = \sum_{\mu = 1}^{\Numh} \sigma(h_{\mu}),
\quad
\Lagv(v) = \sum_{i = 1}^{\Numv} |v_{i}|,
\end{align}
where $\sigma: \mathbb{R} \to \mathbb{R}$ is a nonlinear function, the energy function reduces to
\begin{align}
E(v) = 
- \sum_{\mu=1}^{\Numh} \sigma \left( \sum_{i=1}^{\Numv} \xi_{\mu i} \cdot \mathrm{sgn}(v_{i}) \right).
\end{align}
under the adiabatic limit $\tauv \gg \tauh$ when $\xi$ is a symmetric matrix.
This energy function is identical to that of dense associative memory~\citep{krotov16dense}.
Further, when $\sigma(x) = x^{2}$, it reduces to the energy function of the classical Hopfield network~\citep{hopfield82}.

Recently, \citet{krotov2021large} introduced the following Lagrangians:
\begin{align}
\label{eq:lag_modern}
\hspace{-5pt}
\Lagh(h) = \frac{1}{\beta}\text{log} \left(\sum^{\Numh}_{\mu=1} \exp\left(\beta h_{\mu}\right)\right),
\Lagv(v) = \frac{1}{2} \sum^{\Numv}_{i=1} v_{i}^2,
\hspace{-5pt}
\end{align}
where $\beta \in \mathbb{R}_{\ge 0}$ is a constant.
Under the adiabatic limit and when $\beta = 1$, the energy function reduces to
\begin{align}
\label{eq:energy_modern}
E(v) = 
- \log \left( \sum_{\mu=1}^{\Numh} \exp \left( \sum_{i=1}^{\Numv} \xi_{\mu i} v_{i} \right)\right)
+ \frac{1}{2} \sum_{i=1}^{\Numv} v_{i}^{2}.
\end{align}
This energy function is identical to that of the MHNs proposed by \citet{ramsauer21hopfieldallyouneed}.

\subsection{Energy-Based OOD Detection}
Let us consider classification problems and denote the number of ID classes for training as $C$.
The goal of OOD detection is to identify data samples that do not belong to any of the $C$ classes.
\citet{zhang23she} proposed using the energy function of MHNs for OOD detection.
Specifically, they introduced two energy functions: modern Hopfield energy (MHE) and simplified Hopfield energy (SHE).
MHE is obtained by replacing the interaction matrix $\xi$ in Eq.~(\ref{eq:energy_modern}) with a class-specific pattern matrix $S^{c} \in \mathbb{R}^{d \times N}$ and by omitting the second term as follows:
\begin{align}
\mathrm{MHE}(\tilde{v}) = 
- \log \left( \sum_{\mu=1}^{d} \exp \left( \sum_{i=1}^{N} S^{c}_{\mu i} \tilde{v}_{i} \right)\right),
\end{align}
where $\tilde{v} \in \mathbb{R}^{d}$ is a test pattern,
$c \in \{1, 2, \cdots, C\}$ is the classification result of $\tilde{v}$ obtained from a pre-trained classification model,
$d$ is the hidden dimension, and $N$ is the number of stored patterns.
SHE is a Taylor approximation of MHE, but is more effective than MHE at detecting OOD.
It is defined as
\begin{align}
\label{eq:she}
\mathrm{SHE}(\tilde{v}) = 
\frac{1}{d} \sum_{\mu = 1}^{d} \sum_{i = 1}^{N} S_{\mu i}^{c}\tilde{v}_{i}.
\end{align}
OOD samples can be detected by applying a threshold to these energy functions.
However, as the dynamical system of MHNs evolves over time, every test sample falls into an attractor associated with an ID data sample, indicating a lack of theoretical consistency.

