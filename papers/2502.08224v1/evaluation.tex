% In this section, we will evaluate SFMAS based on the following research questions:

% \textbf{RQ1:} How does the performance of SFMAS compare to the SOTA methods?

% \textbf{RQ2:} What is the impact of each module within SFMAS on the overall results?


\subsection{Experiment Setup}

\subsubsection{Dataset}
We have deployed the widely used microservices system GoogleOnlineBoutique\footnote{https://github.com/GoogleCloudPlatform/microservices-demo}, an e-commerce system consisting of over 10 services, on the Kubernetes platform. Building upon this, we have implemented Prometheus, Elastic, DeepFlow \cite{deepflow}, and Jaeger to collect metric, log, and trace data (Detailed in Appendix \ref{multidata}). Anomalies are injected into microservices' pods using ChaosMesh\footnote{https://github.com/chaos-mesh/chaos-mesh}. There are a total of 9 types of anomalies injected, including CPU stress and memory stress (detailed in Table \ref{tab:faulttype}). Leveraging this setup, we have generated a dataset comprising 90 incidents. For further details on microservices architecture and multimodal data, kindly consult the resources available at \url{https://benchmark.aiops.cn/}.


\begin{table}[H]
\centering
\caption{Fault Types}
\label{tab:faulttype}
\small
\begin{tabular}{ll} 
\toprule
\multicolumn{1}{c}{Type} & \multicolumn{1}{c}{Description}                        \\ 
\midrule
CPU Stress               & Generate threads to occupy CPU resources.         \\
Memory Stress            & Generate threads to occupy memory.                \\
Pod Failure              & Make pods inaccessible for a period of time.        \\
Network Delay            & Cause network delay for a pod.                        \\
Network Loss             & Cause packet loss in a pod's network.                 \\
Network Partition        & Network disconnection, partition.                      \\
Network Duplicate        & Cause network packet to be retransmitted.     \\
Network Corrupt          & Cause packets on network to be out of order.  \\
Network Bandwidth        & Limit the bandwidth between nodes.    \\
\bottomrule
\end{tabular}
\end{table}


\subsubsection{Evaluation Metric And Baseline Methods}

In the field of RCA, the specific location of the root cause is a critical focus for SREs. Additionally, categorizing the type of root cause is equally important, as SREs often specialize in different department like networking group or hardware group. Therefore, we have designed evaluation metrics focusing on both root cause location and fault type. Following the principle from mABC \citep{zhang2024mabc}, we consider redundant causes to be less detrimental than missing causes. Hence, we utilize two metrics: Root Cause Location Accuracy (LA) and Root Cause Type Accuracy (TA). 

\begin{equation}
{\fontsize{2}{3}\selectfont 
    LA = \frac{L_c - \sigma \times L_i}{L_t},\  TA = \frac{T_c - \sigma * T_i}{T_t}
}
\label{eq:einstein}
\end{equation}

$L_c$ and $T_c$ represent all correctly identified root cause locations and types, while $L_i$ and $T_i$ denote the incorrectly identified locations and types. $L_t$ and $T_t$ represent total number of locations and types. $\sigma$ serves as a hyperparameter with a default value of 0.1. To prevent an excessive number of root causes, we limit the maximum number of root causes to three in LLM-based methods. In addition, we employed the Average Path Length (APL) to evaluate the efficiency of the LLM Agents. APL is defined as $\frac{\sum^N_{k=1} L_k}{N}$, where $L_k$ represents the diagnosis path length of the k-th sample, and $N$ denotes the number of samples for which diagnosis was completed within the specified maximum path length.

Regarding baseline methods, we have chosen several open-source Kubernetes RCA tools, such as K8SGPT \citep{k8sgpt} and HolmesGPT \citep{holmesgpt}. Since the implementation of RCA agents is highly specific to the scenarios, they are not open-source and are challenging to migrate. Therefore, we have developed some general-purpose open-source frameworks, such as CoT \citep{wei2022chain}, ReAct \citep{yao2022react}, and Reflexion \citep{shinn2024reflexion}, to serve as our baselines.


\subsection{RQ1: Overall Performance}


% \begin{table}
% \centering
% \caption{Overall Performance}
% \label{tab:overallperformance}
% \small
% \begin{tabular}{ccccccccc} 
% \toprule
% \multirow{2}{*}{Model} & \multirow{2}{*}{Base} & \multicolumn{3}{c}{Dataset A} & \multicolumn{3}{c}{Dataset B} & \multirow{2}{*}{Average}  \\ 
% \cline{3-8}
%                        &                       & LA    & TA    & Average       & LA & TA & Average             &                           \\ 
% \midrule
% K8SGPT                 & GPT-3.5-Turbo         & 11.11 & 11.11 & 11.11         &   11.11 & 11.11   &  11.11                   &                           \\
% HolmesGPT              & GPT-3.5-Turbo         & 11.11 & 11.11 & 11.11         &  11.11  & 11.11   &   11.11                  &                           \\
% % LatentScope            & -                     & 5.24  & 0     & 2.62          &    &    &                     &                           \\
% CoT                  & GPT-3.5-Turbo         & 10.00 & 17.22 &  13.61        &  5.91  & 12.50   &   9.21                  &                           \\
% CoT                  & GPT-4-Turbo           &  &  &          &  15.11  & 25.00   &      20.06               &                             \\
% ReAct                  & GPT-3.5-Turbo         & 13.11 & 25.22 & 19.17         &   11.36 &  19.09  &15.23                     &                           \\
% ReAct                  & GPT-4-Turbo           & 47.67 & 23.33 & 35.50         &  13.18  & 14.78   & 13.98                    &                           \\
% Reflexion                  & GPT-3.5-Turbo         & 18.00 & 23.11 &  20.56        &  7.05  &  18.18  & 12.62                    &                           \\
% Reflexion                  & GPT-4-Turbo           & 25.11 & 18.56 &  21.84        &   8.30 & 11.36   & 9.83                    &                           \\
% SFMAS                  & GPT-3.5-Turbo         & 54.22 & 53.89 & 54.06         &    &    &                     &                           \\
% SFMAS                  & GPT-4-Turbo           & 70.89 & 57.12 & 64.01         &    &    &                     &                           \\
% \bottomrule
% \end{tabular}
% \end{table}

\begin{table*}
\centering
\caption{Performance of different models. The best scores for each evaluation metric are bolded, and the second-best scores are underlined. Exclusive utilization of the APL metric is restricted to methodologies leveraging LLM agents. The fixed and specific accuracy of K8SGPT and HolmesGPT, i.e. 11.11, is due to their ability to handle only one type of fault.}
\label{tab:overallperformance}
\small
\begin{tabular}{>{\centering\arraybackslash}p{3.5cm} >{\centering\arraybackslash}p{2.5cm} >{\centering\arraybackslash}p{1.8cm} >{\centering\arraybackslash}p{1.8cm} >{\centering\arraybackslash}p{1.8cm} >{\centering\arraybackslash}p{1.8cm}} 
\toprule
\textbf{Model}     & \textbf{Base}          & \textbf{LA}    & \textbf{TA}    & \textbf{Average} & \textbf{APL}  \\ 
\midrule
\textbf{K8SGPT}   & GPT-3.5-Turbo & 11.11 & 11.11 & 11.11   &    -  \\
\textbf{HolmesGPT} & GPT-3.5-Turbo & 11.11 & 11.11 & 11.11   &    -  \\
\textbf{CoT}       & GPT-3.5-Turbo & 20.89 & 15.56 & 18.26   &    -  \\
\textbf{CoT}       & GPT-4-Turbo   & 36.00 & 29.22 & 32.61   &    - \\
\textbf{ReAct}     & GPT-3.5-Turbo & 13.11 & 25.22 & 19.17   &  \textbf{9.41}   \\
\textbf{ReAct}     & GPT-4-Turbo   & 47.67 & 23.33 & 35.50   &   \underline{10.76}   \\
\textbf{Reflexion} & GPT-3.5-Turbo & 21.56 & 22.22 & 21.89   &   22.38   \\
\textbf{Reflexion} & GPT-4-Turbo   & 33.67 & 24.44 & 29.06   &   28.09   \\
\textbf{Flow-of-Action}     & GPT-3.5-Turbo & \underline{54.22} & \underline{53.89} & \underline{54.06}   &   18.83   \\
\textbf{Flow-of-Action}     & GPT-4-Turbo   & \textbf{70.89} & \textbf{57.12} & \textbf{64.01}   &   15.10   \\
\bottomrule
\end{tabular}
\end{table*}



Based on Table \ref{tab:overallperformance}, our Flow-of-Action surpasses the SOTA by 23\% in the LA metric and 28\% in the TA metric. Despite the support of LLMs, K8SGPT and HolmesGPT continue to exhibit poor performance. This can be attributed to the significant limitations in the information they access. For instance, K8SGPT primarily queries Kubernetes metadata for attribute information, which is often insufficient for RCA, as faults may not necessarily manifest in metadata. CoT performs reasonably well in some common simple tasks due to the robust reasoning capabilities of LLMs. However, in RCA, where tasks are complex and diverse scenarios arise, even seasoned SREs struggle to promptly determine a series of pinpointing steps. Consequently, CoT fares poorly in the RCA domain. While ReAct integrates reasoning for each observation, the array of tools and diverse observations present challenges in rational orchestration. This is why we introduce the action set and SOP flow. Reflexion builds upon ReAct by introducing a path reflection mechanism. However, given that previous paths are predominantly incorrect, reflecting on a wealth of erroneous knowledge makes it arduous to arrive at accurate insights.

In terms of the APL metric, ReAct often erroneously identifies root causes due to a lack of proper judgment criteria, resulting in a relatively low APL. In contrast, Reflexion necessitates continuous path reflection, leading to numerous iterations and a higher APL. Flow-of-Action maintains an APL within an acceptable range, crucial for optimal performance in RCA tasks. In RCA tasks, the APL's magnitude is not fixed. Excessive values can escalate resource consumption and induce knowledge clutter, while inadequate values may lead to incomplete knowledge.



\subsection{RQ2: Impact of Action Set Size}


% \begin{wrapfigure}{r}{0.35\textwidth} % r表示图片在右边，0.4\textwidth表示图片占据40%的文本宽度
%   \centering
%   \includegraphics[width=0.33\textwidth]{ICLR 2025 Template/Pic/action_num2.png} % 调整图片大小
%   \caption{Accuracy of different action set sizes.}
%   \label{actionsetsize}
% \end{wrapfigure}

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.135]{pic/action_num2.png}}
\caption{Accuracy of different action set sizes.}
\label{actionsetsize}
\end{figure}

As shown in Figure ~\ref{fig:model}, we have introduced the action set mechanism, where the size of the action set impacts the subsequent selection of actions. We conducted validation on a subset of the dataset and the results are shown in Figure \ref{actionsetsize}. We observed that the LA and TA remain relatively stable with changes in the action set size. This stability is attributed to the fact that, despite variations in the action set size, relevant flow tools are encompassed within the action set due to the constraints of the rules in SOP flow. Furthermore, the entire RCA process typically follows the flow, thereby minimizing significant fluctuations in accuracy. However, as the size increases, accuracy initially rises and then declines. This phenomenon occurs because smaller action sets restrict randomness, rendering the model incapable of handling complex scenarios. Conversely, larger sizes introduce more randomness, leading to a loss of control by the model. Hence, we opt for a moderately sized default value of 5 as it strikes a balance between these extremes.




\subsection{RQ3: Ablation Study}




\begin{table*}
\centering
\caption{Ablation study. The LLM backbone we use is GPT-3.5-Turbo.}
\label{tab:ablation}
\small
\begin{tabular}{>{\centering\arraybackslash}p{3.2cm} >{\centering\arraybackslash}p{1.8cm} >{\centering\arraybackslash}p{1.8cm} >{\centering\arraybackslash}p{1.8cm} >{\centering\arraybackslash}p{1.8cm}} 
\toprule
\textbf{Method}         & \textbf{LA}    & \textbf{TA}    & \textbf{Average} & \textbf{APL}    \\ 
\midrule
\textbf{Flow-of-Action}          & \textbf{54.22} & \textbf{53.89} & \textbf{54.06}   & 18.83  \\
\midrule
w/o SOP Knowledge        & 8.56  & 22.11 & 15.39   & 20.00  \\
w/o SOP Flow   & 15.11 & 39.89 & 27.50    & 19.78  \\
w/o Action Set  & 44.67 & 40.00 & 42.34   & \textbf{11.48}  \\ 
\hline
w/o ActionAgent & 32.78 & 34.56 & 33.67   & 18.42  \\
w/o ObAgent     & 40.11 & 28.67 & 34.39   & 19.31  \\
w/o JudgeAgent  & 36.11 & 33.89 & 35.00   & 20.00  \\
\bottomrule
\end{tabular}
\end{table*}

% \begin{wrapfigure}{r}{0.3\textwidth}
%     \centering
%     \includegraphics[width=0.28\textwidth]{ICLR 2025 Template/Pic/prob_generate_sop_code.png}
%     \caption{sss}
% \end{wrapfigure}
% \begin{wraptable}{r}{0.5\textwidth}
%     \centering
%     \begin{tabular}{ccccc} 
%     \toprule
%     Method         & LA    & TA    & Average & APL    \\ 
%     \midrule
%     wo SOP         & 8.56  & 22.11 & 15.39   & 20.00  \\
%     wo Framework   & 15.11 & 39.89 & 27.5    & 19.78  \\
%     wo Action Set  & 44.67 & 40.00 & 42.34   & 11.48  \\ 
%     \hline
%     wo ActionAgent & 32.78 & 34.56 & 33.67   & 18.42  \\
%     wo ObAgent     & 40.11 & 28.67 & 34.39   & 19.31  \\
%     wo JudgeAgent  & 36.11 & 33.89 & 35.00   & 20.00  \\
%     SFMAS          & 54.22 & 53.89 & 54.06   & 18.83  \\
%     \bottomrule
%     \end{tabular}
%     \caption{ss}
% \end{wraptable}


% \begin{figure}[htbp]
%     \centering
%     \begin{minipage}{0.45\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{ICLR 2025 Template/Pic/prob_generate_sop_code.png} % 替换为你的图像文件
%         \caption{Sample}
%     \end{minipage}\hfill
%     \begin{minipage}{0.45\textwidth}
%         \centering
%         \begin{tabular}{ccccc} 
%         \toprule
%         Method         & LA    & TA    & Average & APL    \\ 
%         \midrule
%         wo SOP         & 8.56  & 22.11 & 15.39   & 20.00  \\
%         wo Framework   & 15.11 & 39.89 & 27.5    & 19.78  \\
%         wo Action Set  & 44.67 & 40.00 & 42.34   & 11.48  \\ 
%         \hline
%         wo ActionAgent & 32.78 & 34.56 & 33.67   & 18.42  \\
%         wo ObAgent     & 40.11 & 28.67 & 34.39   & 19.31  \\
%         wo JudgeAgent  & 36.11 & 33.89 & 35.00   & 20.00  \\
%         SFMAS          & 54.22 & 53.89 & 54.06   & 18.83  \\
%         \bottomrule
%         \end{tabular}
%         \caption{Ablation Study}
%         \label{tab:ablation}
%     \end{minipage}
% \end{figure}



We conducted a detailed ablation study by removing each module and each agent of Flow-of-Action, with the results summarized in Table \ref{tab:ablation}. When the SOP was removed, lacking domain-specific guidance, the model relied solely on its own orchestration, essentially reverting to ReAct. The significantly low accuracy underscores the crucial role of SOP. It is worth mentioning that when SOP knowledge is removed, the SOP flow becomes ineffective as well, thus removing SOP knowledge is equivalent to removing both SOP knowledge and SOP flow.

Upon removing the prompts related to the SOP flow, we noticed a significant decrease in LA, while TA remained relatively effective. This is because SOP knowledge and relevant tools were still present and could provide type information through tools like $match\_observation$ or $match\_sop$. However, the absence of the flow hindered the complete execution of the SOP, leading to the incapacity to discern location information.

The absence of the action set rendered the model unable to make correct judgments in complex and rare scenarios. However, in most cases, the model still performed adequately, resulting in a moderate decrease in effectiveness. Without the action set, the model tended to rely more on tools determined by the flow, reducing the likelihood of excessive tool invocations and thus significantly lowering APL.
% Nevertheless, as mentioned earlier, a reduction in APL may not always be advantageous, as it entails missing out on valuable information retrieval opportunities.

At the multi-agent level, the removal of any single agent led to a certain degree of decrease in accuracy. This is attributed to the complexity of the RCA task, where having a single agent handle all processes may lead to oversight and hallucinations. In contrast, a MAS with one main agent and multiple auxiliary agents effectively addresses this issue. The main agent can make decisions by considering the opinions of others, reducing the cognitive load and consequently achieving higher accuracy.

Regarding APL, apart from the significant impact of removing the action set, the effects of other ablations were relatively similar. This is due to the imposed limit of 20 steps to prevent unbounded loops that could render the RCA process unending.


% \subsection{RQ3: Size of Action Set}


% \begin{wrapfigure}{r}{0.35\textwidth} % r表示图片在右边，0.4\textwidth表示图片占据40%的文本宽度
%   \centering
%   \includegraphics[width=0.33\textwidth]{ICLR 2025 Template/Pic/action_num.png} % 调整图片大小
%   \caption{Accuracy of different action set size.}
%   \label{actionsetsize}
% \end{wrapfigure}

% We have introduced the action set mechanism, where the size of the action set impacts the subsequent selection of actions. We conducted validation on a subset of the dataset and the results are shown in Figure \ref{actionsetsize}. We observed that the LA and TA remain relatively stable with changes in the action set size. This stability is attributed to the fact that, despite variations in the action set size, relevant flow actions are encompassed within the action set due to the constraints of the rules. Furthermore, the entire RCA process typically follows the flow, thereby minimizing significant fluctuations in accuracy. However, as the size increases, accuracy initially rises and then declines. This phenomenon occurs because smaller action sets restrict randomness, rendering the model incapable of handling complex scenarios. Conversely, larger sizes introduce more randomness, leading to a loss of control by the model. Hence, we opt for a moderately sized default value of 5 as it strikes a balance between these extremes.