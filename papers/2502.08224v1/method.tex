
% Figure \ref{fig:model} provides an overview of our proposed SFMAS.


% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{ICLR 2025 Template/Pic/model4.png}
%     \caption{Comparison of ReAct and Flow-of-Action. RC means root cause. Dashed lines represent paths triggered under specific conditions. When the previous action is $match\_observation$, JudgeAgent and ObAgent are triggered. When JudgeAgent finds the root cause, it triggers the input of the analysis result to thought and adds $Speak$ to action set.}
%     \label{fig:model}
    
% \end{figure}


% \begin{figure}[htbp]
%     \centering
%     \begin{subfigure}[b]
%         \centering
%         \includegraphics[scale=0.1]{ICLR 2025 Template/Pic/react.png}
%         \caption{1}
%         \label{fig:sub1}
%     \end{subfigure}
%     \hspace{0.05\textwidth}
%     \begin{subfigure}[b]
%         \centering
%         \includegraphics[scale=0.1]{ICLR 2025 Template/Pic/flow-of-action.png}
%         \caption{2}
%         \label{fig:sub2}
%     \end{subfigure}
%     \caption{m}
%     \label{fig:main}
% \end{figure}



In this section, we will present the design of Flow-of-Action. As illustrated in Figure \ref{fig:model}, the Flow-of-Action is a MAS built upon the ReAct. It encompasses three key design components: the SOP flow, the action set, and the MAS. We will delve into each of these components in the subsequent sections. Prior to their detailed exploration, we will introduce the foundational knowledge required, including the knowledge base and tools utilized by the Flow-of-Action.

\subsection{Knowledge Base of Agents}
% Due to the limited context length of LLMs, Retrieval-Augmented Generation (RAG) has seen rapid advancement \citep{jeong2024adaptive}. However, the text quality recalled by RAG significantly impacts the final results. Many existing RAG techniques chunk documents in the knowledge base and utilize semantic block embeddings to compute similarity for retrieval. This approach, however, does not yield optimal results in RCA. On one hand, the RCA domain contains numerous documents with a plethora of irrelevant knowledge, which severely hampers retrieval. On the other hand, the document quality in RCA is often low, with many being engineers' casual notes that offer little assistance in root cause identification. Therefore, various efforts, including GraphRAG \citep{edge2024graphrag}, focus on innovating the structure of the knowledge base to achieve faster and more accurate knowledge retrieval. However, constructing a knowledge graph in the RCA domain is costly and of limited utility. Hence, we have devised a novel knowledge base model comprising SOP knowledge and historical incidents knowledge. Our entire knowledge base is implemented based on Chroma\footnote{https://github.com/chroma-core/chroma}, with embedding achieved through m3e-base\footnote{https://huggingface.co/moka-ai/m3e-base}.


Given the restricted context length of LLMs, Retrieval-Augmented Generation (RAG) has experienced notable progress \citep{jeong2024adaptive}. However, the quality of text retrieved by RAG significantly influences the ultimate outcomes. Many existing RAG methodologies segment documents within the knowledge base and employ semantic block embeddings to calculate similarity for retrieval. This approach, however, does not consistently yield optimal results in RCA. Therefore, we have devised an innovative knowledge base model integrating SOP knowledge and historical incident knowledge. 
% Our comprehensive knowledge base is implemented using Chroma\footnote{https://github.com/chroma-core/chroma}, with embedding facilitated through m3e-base\footnote{https://huggingface.co/moka-ai/m3e-base}.


% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{ICLR 2025 Template/Pic/model5.png}
%     \caption{Comparison of ReAct and Flow-of-Action. RC means root cause. Dashed lines represent paths triggered under specific conditions. When the previous action is $match\_observation$, JudgeAgent and ObAgent are triggered. When JudgeAgent finds the root cause, it triggers the input of the analysis result to thought and adds $Speak$ to action set.}
%     \label{fig:model}
    
% \end{figure}

\begin{figure*}[htbp]
\centerline{\includegraphics[scale=0.32]{pic/model5.png}}
\caption{Comparison of ReAct and Flow-of-Action. RC means root cause. Dashed lines represent paths triggered under specific conditions. When the previous action is $match\_observation$, JudgeAgent and ObAgent are triggered. When JudgeAgent finds the root cause, it triggers the input of the analysis result to thought and adds $Speak$ to action set.}
\label{fig:model}
\end{figure*}

\subsubsection{SOP Knowledge}

% With the successful application of SOPs in the field of code generation \citep{hong2023metagpt}, there is a growing realization that relying solely on LLM to complete complex tasks such as RCA is a far-fetched idea. SOPs, to some extent, impose constraints on LLM at critical junctures, directing the entire process towards the correct direction. Therefore, we have incorporated SOPs into the knowledge base, which are pre-written by engineers based on domain knowledge or extracted through automation tools. Each SOP is a complete block and includes two attributes: name and steps. The name describes key information of the SOP, which is transformed into a vector for subsequent retrieval use. However, given the diverse nature of incidents in a large-scale MAS, it is not feasible for the SOPs in the knowledge base to cover all scenarios. To address this issue, we have also designed a mechanism called $generate\_sop$ to alleviate this limitation (detailed later).


With the successful integration of SOPs in the realm of code generation \citep{hong2023metagpt}, there is a growing recognition that relying solely on LLMs to execute intricate tasks like RCA is impractical. SOPs, to a certain extent, impose constraints on LLMs at crucial junctures, guiding the entire process towards the correct trajectory. Consequently, we have embedded SOPs into the knowledge base, which are either authored by engineers based on domain expertise or extracted through automation tools. As shown in Figure \ref{fig:model}, each SOP constitutes a self-contained unit comprising two attributes: name and steps. The name encapsulates essential information about the SOP, which is translated into a vector for subsequent retrieval purposes.
% Nonetheless, given the diverse array of incidents in a large-scale MAS, it is unfeasible for the SOPs within the knowledge base to encompass all potential scenarios. To mitigate this challenge, we have devised a mechanism termed $generate\_sop$ to address this limitation, with detailed elaboration provided subsequently.

\subsubsection{Historical Incidents}


As highlighted by \citet{chen2024automatic}, in systems where similar incidents occur frequently, historical incident data proves invaluable in identifying the root cause of ongoing incidents. Consequently, we incorporate the performance details of historical incidents into the knowledge base. Each historical incident is characterized by two key attributes: manifestation and type. When retrieving similar incidents, we evaluate similarity by comparing the embedding of the current observation with the embedding of the manifestation of historical incidents. However, relying solely on embeddings for assessment can introduce significant errors. To tackle this issue, we have intentionally devised the ObAgent (elaborated upon subsequently) to address this challenge.





\subsection{Tools of Agents}

Within LLM agents, tools typically refer to pre-defined functions. During the action phase, LLM invokes relevant tools to obtain the necessary information. In Flow-of-Action, the tools utilized primarily fall into three categories: tools for multimodal data collection and analysis, tools related to SOP flow, and other tools. Each category will be discussed in detail below.

% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{ICLR 2025 Template/Pic/multimodal3.png}
%     \caption{Multimodal data collection and analysis.}
%     \label{fig:multimodal}
% \end{figure}



\subsubsection{Multimodal Data Collection and Analysis}

% Data serves as the foundation for analysis in all domains, particularly in RCA. In the context of MSA, which encompass various modal data types such as metrics, traces, and logs, the significance of multimodal data for RCA has been demonstrated by existing methods \citep{yao2024chain,yu2023nezha}. Therefore, we have deployed a comprehensive monitoring system to collect multimodal data. While LLM exhibit strong capabilities in understanding textual data, their proficiency in interpreting other structured data types such as metric data is limited, compounded by the presence of noise in the data. Hence, it is crucial to denoise the data and convert it into text data that LLM can comprehend effectively. As illustrated in Figure \ref{fig:multimodal}, we have designed $whether\_is\_abnormal\_metric$ to deploy time series anomaly detection algorithms for detecting metric anomalies and converting them into fault-related text; $collect\_trace$ is devised to gather abnormal span information throughout the entire call chain and transform it into text; $kubectl\_logs$ is implemented to collect abnormal log information from each pod in the Kubernetes system.

\begin{table*}
\centering
\caption{Description of SOP flow tools.}
\label{tab:frameworktool}
\small
\begin{tabular}{lccc} 
\toprule
                    & Input                   & Output                        & LLM Usage  \\ 
\midrule
match\_sop          & Fault Type/Information & SOP                           & No         \\
generate\_sop       & Fault Type/Information & SOP                           & Yes        \\
generate\_sop\_code & SOP                     & SOP Code                      & Yes        \\
run\_sop            & SOP Code                & Result after running the code & No         \\
match\_observation  & Observation             & Similar incidents             & No         \\
\bottomrule
\end{tabular}
\end{table*}


Within the realm of MSA, which encompasses diverse modalities of data such as metrics, traces, and logs, the importance of multimodal data for RCA has been underscored by existing methodologies \citep{yao2024chain,yu2023nezha}. Consequently, we have implemented a comprehensive monitoring system to aggregate multimodal data. While LLMs excel in processing textual data, their effectiveness in interpreting structured data types like metrics is constrained, especially in the presence of data noise. Therefore, it is imperative to preprocess the data by denoising and transforming it into textual format for enhanced comprehension by LLMs. As depicted in Figure \ref{fig:multimodal}, we have devised the following components: $whether\_is\_abnormal\_metric$ to leverage time series anomaly detection algorithms \citep{wang2024revisiting,donut,tuli2022tranad} for identifying metric anomalies and converting them into fault-related text; $collect\_trace$ for capturing abnormal span details across the entire call chain and converting them into text format; and $kubectl\_logs$ for extracting abnormal log information from each pod within the Kubernetes system.

\subsubsection{SOP Flow Tools}

% As mentioned earlier, we have introduced a framework based on SOPs. This entire framework is designed and implemented based on common workflows utilized by Site Reliability Engineers (SREs) in real-world environments, incorporating novel concepts such as code. The information regarding the tools involved in the entire Framework is outlined in Table \ref{tab:frameworktool}. Furthermore, to minimize unexpected occurrences during the operation of the framework, we have specifically designed numerous targeted auxiliary tools. For instance, in the context of $generate\_sop$, we have devised $get\_relevant\_metric$ to facilitate the retrieval of relevant metric names

As previously mentioned, we have introduced a flow centered around SOPs. This comprehensive flow is meticulously crafted based on common workflows employed by SREs in practical settings, integrating innovative concepts such as code. Details regarding the tools utilized within the flow are delineated in Table \ref{tab:frameworktool}. Moreover, to preempt unexpected incidents during the flow's operation, we have developed a variety of targeted auxiliary tools. For example, within the context of $generate\_sop$, we have introduced $get\_relevant\_metric$ to streamline the retrieval of pertinent metric names.



\subsubsection{Other Tools}

% The framework serves to establish a relatively standardized general process for complex RCA tasks, where the tools themselves do not involve service- or business-related elements. However, when generating SOP or SOP code, or when conducting operations outside the framework, a greater diversity of tools is required to query the real operational state of the system. In addition to the tools for querying and analyzing multimodal data mentioned earlier, we have also designed numerous analysis tools tailored for the MSA, such as $pod\_analyze$ and $service\_analyze$. These tools leverage queries on certain attribute information within the Kubernetes system to obtain the system's status. $Speak$ is utilized to disseminate the identified root cause to all relevant stakeholders upon its discovery. For detailed descriptions of these tools, please refer to the appendix.


The flow aims to establish a standardized and generalized process for intricate RCA tasks, devoid of service- or business-specific components within the tools themselves. However, a broader array of tools is necessitated when generating SOPs or SOP code, or when executing operations beyond the flow, to query the authentic operational state of the system. In addition to the previously mentioned tools for querying and analyzing multimodal data, a suite of tailored analysis tools has been devised for MSA, including $pod\_analyze$ and $service\_analyze$. These tools employ queries on specific attribute data within the Kubernetes system to ascertain the system's status. Upon identification, $Speak$ is employed to communicate the discovered root cause to all pertinent stakeholders. For a comprehensive elucidation of these tools, kindly consult the Appendix \ref{apendixb}.

\subsection{SOP Flow}



% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{ICLR 2025 Template/Pic/example.png}
%     \caption{Example of Flow-of-Action.}
%     \label{fig:example}
% \end{figure}

\begin{figure*}[htbp]
\centerline{\includegraphics[scale=0.23]{pic/example.png}}
\caption{Example of Flow-of-Action.}
\label{fig:example}
\end{figure*}

% Fault Type/Information$\xrightarrow{match\_sop\&generate\_sop}$SOP$\xrightarrow{generate\_sop\_code}$SOP Code$\xrightarrow{run\_sop}$Observation$\xrightarrow{match\_observation}$Fault Type/Information. 



The SOP flow represents a comprehensive logic chain of actions tailored to the SOP mentioned earlier. It serves to instruct LLMs on how to effectively utilize SOP knowledge. For instance, in the initial stages of RCA, it is essential to identify which SOPs are most relevant to the incident (corresponding to $match\_sop$). Additionally, if a particular incident does not align with any existing SOP, the automation of SOP generation should be considered (corresponding to $generate\_sop$). While the comprehensive SOP flow can be visually represented, as illustrated in Figure \ref{fig:model}, in practical application, the full SOP flow is presented in the form of prompts to the MainAgent to aid in thought processes and to the ActionAgent to generate a more rational action set. The SOP flow prompt information provided to the LLMs is displayed in Figure \ref{fig:promptengineering}. By implementing such soft constraints, we aim to tackle the issue of chaotic tool orchestration while still maintaining the flexibility of LLMs. Unlike methods like FastGPT \citep{fastgpt}, we do not enforce strict workflow constraints on LLM orchestration. Figure \ref{fig:example} provides an example of the Flow-of-Action. Subsequently, we will systematically elucidate critical transitional subflows within the SOP flow.


\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.37]{pic/promptengineering.png}}
\caption{SOP flow prompt information of LLMs.}
\label{fig:promptengineering}
\end{figure}

% The SOP flow, as illustrated Figure \ref{fig:model}, consists of several processes: (1) $match\_sop\&generate\_sop$: Get SOP based on fault type or information. (2) $generate\_sop\_code$: Generate SOP code according to the SOP. (3) $run\_sop$: Execute the SOP code to obtain observations. (4) $match\_observation$: Recall similar faults based on the observations. We have translated the entire flow into pseudocode and input it into MainAgent and ActionAgent in prompt form (see Figure \ref{fig:promptengineering}), with the objective of having ActionAgent generate appropriate actions and MainAgent orchestrate according to the flow in the absence of any exceptional circumstances. 


\subsubsection{Fault Type/Information$\rightarrow$SOP}

% In real scenarios, when engineers receive fault alarm descriptions or fault categories, they typically consult relevant documents or rely on their domain knowledge to determine the next steps. Therefore, in our framework, we first match the SOP related to the fault information through $match\_SOP$. Specifically, this matching involves calculating the similarity between the current query and all SOP name embeddings, ranking them, and selecting the top k matches. To prevent matching with highly irrelevant SOPs, we set a threshold for filtering. However, in real-world situations where new fault types emerge frequently, it is common to encounter situations where relevant SOPs cannot be matched. To address this issue, we introduce $generate\_sop$ in the framework to create new SOPs for queries that do not match existing SOPs. Specifically, we leverage LLMs to recall some SOPs as few-shot prompts to guide the generation of more standardized and reasonable new SOPs.

% Within the entire framework, the generation of SOPs is a crucial step as it directly impacts the subsequent root cause identification process. To achieve more accurate root cause identification, we have designed hierarchical SOPs. Specifically, we aim for the RCA process to proceed from macro to micro, from general to specific, aligning more closely with real-world scenarios. Therefore, our SOP knowledge is structured hierarchically. For example, we first identify network issues before pinpointing network partition issues. This approach significantly reduces the likelihood of a single error leading to complete failure and provides greater flexibility and adaptability in selecting each sub-step during the process.


In our flow, we initially utilize $match\_sop$ to associate the fault information with the relevant SOP. This matching process involves computing the similarity between the current query and all SOP name embeddings, ranking them, and selecting the top \(k\) matches. To avoid matching with highly irrelevant SOPs, a filtering threshold is established. Nevertheless, in real-world contexts where new fault types frequently emerge, instances may arise where pertinent SOPs cannot be matched. To tackle this challenge, we introduce $generate\_sop$ to devise new SOPs for queries that do not align with existing SOPs. Specifically, we utilize LLMs to generate new SOPs and leverage existing SOPs as few-shot prompts to guide the development of more standardized and coherent SOPs. Figure \ref{fig:ioerror} shows an example of an SOP for handling IO errors generated by an LLM. Although not highly precise, the general direction of analysis is correct. The logic is rigorous, and the diagnostic results provide useful assistance to SREs.


\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.6]{pic/ioerror.png}}
\caption{Generated SOP for IO error.}
\label{fig:ioerror}
\end{figure}

Within the entirety of the flow, the generation of SOPs stands as a pivotal phase as it directly influences the subsequent RCA process. To enhance the precision of RCA, we have devised hierarchical SOPs. Our objective is for the RCA process to progress from a macro to micro level, from a general to specific perspective, mirroring real-world scenarios more closely. For instance, we first address network issues before delving into network partition problems.

\subsubsection{SOP$\rightarrow$SOP Code}

Once a suitable SOP is obtained, due to the interdependence of steps within the SOP, it is generally necessary to execute the SOP step by step to achieve the desired outcome. However, in real-world scenarios, SOPs are typically concise texts, making it relatively difficult for engineers lacking domain knowledge to execute the entire SOP. Utilizing an agent based on LLM to execute the SOP is a more rational and efficient approach. However, directly instructing the agent to execute all steps of the SOP one by one often leads to errors. This is because LLM tends to focus more on proximal text, and the outcome of a particular step can significantly influence the selection of subsequent actions.

Therefore, we have designed $generate\_sop\_code$ to convert the entire SOP into code for simultaneous execution. This approach offers three main advantages. Firstly, numerous works, including Chain-of-Code \citep{li2023chainofcode}, have demonstrated that executing code in LLM environments is far more accurate than executing text \citep{pan2023logiclm}, aligning well with the precise requirements of RCA. Secondly, in many scenarios, including RCA, there exist numerous atomic operations where we wish for several actions to be executed together or none at all, as executing a single action in isolation may not yield useful results. SOPs exemplify this situation, where executing only a portion may not yield the desired fault information. Converting SOPs to code effectively addresses this issue, as once the code is executed, it must run from start to finish. Lastly, SOP code represents a collection of multiple actions, enabling the execution of multiple actions with a single tool invocation, thereby significantly reducing LLM token and resource consumption.

\subsubsection{SOP Code$\rightarrow$Observation}

After obtaining the SOP code, the flow invokes $run\_sop$ to execute the entire SOP code. However, the generation of code is not always accurate and may lead to various issues, such as syntax errors or incorrect variables within the code. In such instances, our flow expects to re-match suitable parameters and use $generate\_sop\_code$ to generate new, correct code. Once the code is error-free, we can smoothly execute it to obtain the desired results.

\subsubsection{SOP Code$\rightarrow$Fault Type/Information}

As mentioned earlier, the definition of SOP is hierarchical, and our RCA process follows a layered and progressive approach. Upon executing $run\_sop$ and obtaining a new observation, we seek guidance to determine the next steps in the localization process. The ideal approach is to identify potential fault types based on the observation. Relying solely on the domain knowledge of the LLM agent is evidently insufficient for accurate judgment in a specific domain, necessitating fine-tuning of the LLM model or the introduction of more domain-specific knowledge. Inspiration from various methods \citep{chen2024automatic} suggests that most fault types have occurred historically. Therefore, we use $match\_observation$ to recall similar historical incidents based on observation. The ObAgent is then utilized to determine potential fault types or provide descriptions of faults for subsequent RCA processes.


\subsection{Action Set}

In section \ref{intro}, we mentioned that in RCA, it is relatively challenging for the LLM agent to perform reasonable planning. This difficulty primarily arises from two reasons: the variability of observations and the existence of multiple possible actions for a given observation. Instantaneously identifying and executing the most reasonable action from numerous viable choices is an exceedingly challenging task for the LLM.

To address this challenge, we have devised a mechanism known as the action set. Specifically, drawing inspiration from the CoT \citep{wei2022chain}, we first generate a series of reasonable actions comprising a set, with each action accompanied by a textual explanation of the rationale behind its selection. This set primarily consists of two components: actions generated by the ActionAgent and actions identified by the JudgeAgent. The ActionAgent incorporates flow information and numerous examples in the prompt to enhance the rationality of the generated actions. However, this may still overlook reasonable flow actions. Therefore, we have established a rule based on the flow to ensure that the action set is comprehensive and logical. For instance, if the preceding action was $generate\_sop$, the subsequent action of $generate\_sop\_code$ is added to the set. Secondly, the JudgeAgent evaluates whether the root cause has been identified during the current RCA process. If the root cause is pinpointed, the action $Speak$ is included in the action set.

Through action set, we have effectively mitigated the challenges posed by diverse observations and a plethora of feasible actions that could potentially hinder agent planning. Furthermore, the strategic design of the action set has enabled the LLM Agent to attain a nuanced equilibrium between stochasticity and determinism. Within RCA, excessive randomness may induce divergence in the localization process, impeding the formation of effective diagnostics. Conversely, an overly deterministic approach may incline the model towards scripted operations, limiting its capacity to handle unforeseeable and rapidly changing circumstances.

\subsection{Multi-Agent System}

% As mentioned in the introduction, in the process of multi-agent communication, if the positions of different agents are equal and they are responsible for different tasks while expressing corresponding insights, there is a risk of conflicts. To address this situation, 
We have designed a MAS consisting of a single main agent along with multiple auxiliary agents. The MainAgent serves as the principal entity with authority, while the other agents are responsible for providing suggestions to it. The MainAgent orchestrates the entire localization process. The ActionAgent provides a feasible set of actions for the MainAgent to choose from. The ObAgent offers potential anomaly types or information after the MainAgent completes $match\_observation$. The JudgeAgent determines whether the root cause has been identified. However, even if the JudgeAgent believes the root cause has been found, the MainAgent may not necessarily use $Speak$ to conclude the entire localization process. Taking additional steps and gathering more information may lead to a more accurate root cause determination. The CodeAgent plays a crucial role in the SOP flow, possessing information on all tools and generating appropriate code for subsequent use. Through the MAS, the burden on the MainAgent is significantly reduced. It only needs to consider the opinions of other agents and make relatively accurate judgments based on the entire localization process. Such division of labor also aligns more closely with real-world operational scenarios.