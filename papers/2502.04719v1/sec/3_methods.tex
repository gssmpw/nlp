\section{Methods}
\label{sec:methods}
In this section, we introduce our tolerance-aware deep optic optimization. First, in \cref{sec:3.1}, we introduce the definition of tolerance optimization in term of deep optics. Then, in \cref{sec:3.2}, we explicitly model four common tolerances, decentering, tilt, curvature and central thickness errors in the differentiable imaging process. Finally, in \cref{sec:3.3} and \cref{sec:3.4}, we introduce two novel losses and present a more completed design flow for deep optics, which includes the pre-training process without tolerances and the tolerance-aware optimization that accounts for actual errors.

%-------------------------------------------------------------------------
\subsection{Tolerance Optimization for Deep Optics}
\label{sec:3.1}
In traditional optical design, tolerance optimization involves optimizing the design parameters to ensure that the degradation resulting from manufacturing or assembly errors remains within an acceptable range. Specifically, we assume the actual lens parameters $\theta_i$ at manufacturing time follows independent Gaussian distributions centered around designed parameters, $\mathcal{N}(\tilde{\theta_i}, \tilde{\sigma_{i}^2})$, where $\tilde{\theta_i}$ is the design parameters without any tolerances and $\tilde{\sigma_{i}^{2}}$ is the variance of tolerance range. Then, within given ranges of tolerances $t$, we need to find an optimal lens parameters $\boldsymbol{\theta_{\text{opts}}}$, like curvature or spacing distance, where the imaging quality degradation is bounded as:
\begin{equation}
\boldsymbol{\theta_\text{{opt}}^{*}} = \mathop{\arg}\mathop{\max}_{\boldsymbol{\theta_{\text{opt}}}} \mathcal{P}(\mathrm{Y} \negthinspace > \negthinspace \mathrm{Y_0} \negthinspace \mid \negthinspace {\boldsymbol{\theta_{opt}}}, \negthinspace t),
\label{eq:1}
\end{equation}
where  $Y$ is the actual imaging quality of a lens, $Y_0$ is the preset performance threshold, and $\mathcal{P}(\mathrm{Y} \negthinspace > \negthinspace \mathrm{Y_0})$ is the probability that the lens performance is within the designed range.

Moving to the deep optical design, the main difference is that we also need to consider the downstream image processing networks. Therefore, \cref{eq:1} is modified to:
\begin{equation}
\boldsymbol{\theta_{\text{opt}}^{*}},\boldsymbol{\theta_{\text{net}}^{*}}= \mathop{\arg}\mathop{\max}_{\boldsymbol{\theta_{\text{opt}}},\boldsymbol{\theta_{\text{net}}}} \mathcal{P}(\mathrm{Y}\negthinspace >\negthinspace \mathrm{Y_0}\negthinspace \mid \negthinspace{\boldsymbol{\theta_{\text{opt}}}},\negthinspace{\boldsymbol{\theta_{\text{net}}}}, \negthinspace t),
\label{eq:2}
\end{equation}
where $\boldsymbol{\theta_{\scalebox{0.5}{net}}}$ is the parameters from downstream algorithms, like the parameters of neural networks. Also, $Y$ is the performance of the downstream task, instead of imaging quality.

\begin{figure}[t]
  \centering
  % \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   \includegraphics[width=0.95\linewidth, height=3.7cm]{figures/tolerance_modeling.pdf}

   \caption{The tilt, decentration and central thickness tolerances can be modeled as {\bf{R}}otation and {\bf{T}}ranslation of Lens. The spatial transformations of Lens can be equivalent to the opposite spatial transformations of ray's coordinate. The PSFs of the lens system change drastically due to tolerances. Scale bar: 15$\mu m$.}
   \label{fig:PerbVisualization}
\end{figure}

%-------------------------------------------------------------------------
\subsection{Modeling Tolerances in Ray Tracing}
\label{sec:3.2}
Due to the independent tolerances of each lens and the interdependence among various types of tolerances, employing a global a priori approach to make the optical system robust against tolerances is challenging~\cite{mcguire2006designing}. To address this, we propose explicitly modeling tolerances in every iteration of ray tracing where most of previous imaging simulation pipeline do not, allowing the optics and computational decoder to be aware of the effects of tolerances. Specifically, we use a forward ray tracing algorithm \cite{kolb1995realistic, wang2022differentiable}, taking into accounts of four common lens tolerances: decentration, tilt, central thickness, and curvature errors. We perturb the original lens by these tolerances in a differentiable way and integrate them into the previous joint optimization framework.

The tolerances arising from decentration, tilt, and central thickness errors can be represented as translations and rotations of the lens surfaces, as illustrated in \cref{fig:PerbVisualization}. Decentration and central thickness tolerances correspond to rigid translations of the lens in the plane perpendicular to the optical axis and along the optical axis, respectively. In contrast, the tilt tolerance can be represented as a rigid rotation of the lens, with the transformation detailed in \cref{eq:transformation}. However, to simplify the verification of boundary conditions during ray tracing, we convert the rigid lens transformation into an equivalent coordinate transformation. For curvature error tolerance, a curvature offset $\Delta c$ is applied in the forward ray tracing process.

In summary, to solve for the intersections of the rays with the lens during the ray tracing process, we transform the coordinates according to randomly perturbation. Then, after solving the intersection of the rays on the lens and the refraction process, we re-convert the coordinates to the original global coordinate system.
\begin{align}
\begin{matrix} 
[\mathbf{P^{\prime}}, \mathbf{d^{\prime}}]
\end{matrix} = \mathbf{R} \cdot
\begin{matrix} [\mathbf{P}+\mathbf{\Delta T}, \mathbf{d} ]
\end{matrix},
\label{eq:transformation}
\end{align}
where $\mathcal{\boldsymbol{P}}$ and $\mathcal{\boldsymbol{P^{\prime}}}$ are the original and perturbed ray origins, and $\mathcal{\boldsymbol{d}}$ and $\mathcal{\boldsymbol{d^{\prime}}}$ are the original and perturbed ray directions; $\mathcal{\boldsymbol{\Delta T}}$ is translation vector and $\mathcal{\boldsymbol{R}}$ is the rotation matrix.
\iffalse
\begin{equation}
\tiny{{\bf{R}} =
\begin{bmatrix}
\cos \alpha \cos \beta & \cos \alpha \sin \beta \sin \gamma - \sin \alpha \cos \gamma & \cos \alpha \sin \beta \cos \gamma + \sin \alpha \sin \gamma \\[0.5ex]
\sin \alpha \cos \beta & \sin \alpha \sin \beta \sin \gamma + \cos \alpha \cos \gamma & \sin \alpha \sin \beta \cos \gamma - \cos \alpha \sin \gamma \\[0.5ex]
-\sin \beta & \cos \beta \sin \gamma & \cos \beta \cos \gamma
\end{bmatrix}}
\label{eq:rotation_matrix}
\end{equation}
\fi

\begin{figure*}[tb] \centering
    \includegraphics[width=\textwidth,height=0.43\textwidth]{figures/pipeline.pdf}
    \caption{{\bfseries Tolerance-aware optimization for deep optics}. We integrate tolerances into differentiable ray tracing. Every kind of tolerances are randomly sampled from its distribution $\mathcal{N}($0$, \tilde{\sigma_{i}^2})$, use ray tracing with tolerances to render perturbed spatially-variant PSF maps and simulated the imaging results by spatially-variant convolution, then noise is added to simulate sensor-captured images. These images are then passed to a computational decoder for reconstruction. During forward simulation, we track gradients of optical parameters, We can subsequently back-propagate the errors from either the reconstruction images quality and tolerance loss terms. The framework jointly optimizes the optics and the computational decoder in a tolerance-aware manner.} 
    \label{fig:pipeline}
\end{figure*}

%------------------------------------------------------------------------
\subsection{Tolerance-aware Deep Optics Design}
\label{sec:3.3}
Explicitly modeling tolerances enables us to achieve tolerance-aware co-design. However, the random sampling of tolerances results in training instability, which is especially pronounced during the initial stages of deep optics optimization. Hence, we introduce a deep optics design flow that incorporates tolerance optimization and is easier to train: firstly, we employ the conventional deep optics training approach without accounting for tolerance effects, focusing solely on task performance as the design objective; secondly, once the design meets the design objectives, we conduct tolerance-aware optimization to keep its performance after fabrication.

For second tolerances optimization stage, we explicitly modeling tolerances into ray tracing process, then we use ray tracing with tolerances to implement tolerance-aware optimization, jointly optimize both the optics and computational decoder, see in \cref{fig:pipeline}, to improve the robustness of deep optics design. In each iteration, we randomly sample $N=64$ tolerances patterns and conduct forward ray tracing with sampled tolerance to render the PSF map for full field of views which contains the effects of all sampled tolerances, and use the mixed PSF map to render the sharp images by spatially-variant convolution \cite{cai2024phocolens, chen2021extreme}.

%-------------------------------------------------------------------------
\subsection{Spot Loss and PSF Similarity Loss}
\label{sec:3.4}
Since deep optics contains, optics and decoder, the difference between the number of parameters and the significance of the parameters of the two is very large, and due to the tolerance-aware optimization when randomly sampling a variety of tolerance modes, simply using the general image quality loss, such as mean-square-error loss, VGG Loss \cite{johnson2016perceptual} and TV loss \cite{chambolle2010introduction}, the overall training difficulty is is very large, see \cref{tab:loss_comparison}. In this paper, we use a basic image quality loss, $\mathcal{L}_{img} = \lambda_{vgg}\cdot\mathcal{L}_{vgg} + \lambda_{tv}\cdot\mathcal{L}_{tv} + \lambda_{mse}\cdot\mathcal{L}_{mse}$, and $\lambda_{vgg}, \lambda_{tv}$ and $\lambda_{mse}$ are set in $0.001, 0.01$ and $0.1$.
\begin{align}
\mathcal{L}_{total} &= \lambda_{Spot}\cdot\mathcal{L}_{Spot} + \lambda_{PSF}\cdot\mathcal{L}_{PSF} + \mathcal{L}_{img}, \label{eq:Loss-total}
\end{align}
In order to improve stability the tolerances optimization for deep optics, we introduce two novel loss functions, $\mathcal{L}_{Spot}$ and $\mathcal{L}_{PSF}$, in addition to basic image quality losses, $\mathcal{L}_{img}$. We use the spot loss, $\mathcal{L}_{Spot}$ to constrain the spot size of lens which represent the overall imaging quality. 
And the PSF play the role of bridging the optics with the computational decoder, the tolerances are directly affect the PSF of lens, therefore we design $\mathcal{L}_{PSF}$ to constrain the change of PSF under random tolerances, the two kinds of losses expressed as \cref{eq:Loss-RMS} and \cref{eq:Loss-PSF1,eq:Loss-PSF2}. Noteworthy, the two new losses are directly decided by the lens, which are able to provide shortcuts for the backward gradients and improve the optimization for the lens parameters. In summary, we implement tolerance-aware optimization by loss functions, expressed \cref{eq:Loss-total}.
\begin{align}
\mathcal{L}_{Spot} &= \sum_{\scalebox{0.8}{$\lambda$}} \sum_{\scalebox{0.8}{$f$}} \frac{\|\mathbf{P}_{\lambda, f} - \overline{\mathbf{P}}_{\lambda, f}\|_2}{N_{rays}}, \label{eq:Loss-RMS} \\
\mathcal{L}_{PSF} &= 1.0 - \frac{\sum_{\scalebox{0.8}{$f $}} \sum_{\scalebox{0.8}{$\lambda$}} Sim_{\lambda, f}}{N_f N_{\lambda}}, \label{eq:Loss-PSF1}\\
Sim_{\lambda, \scalebox{0.8}{$f$}} &= \max\left( \mathrm{Conv}\left( \mathrm{PSF}_{Ideal}\mathrm{PSF}_{Perb} \right) \right), \label{eq:Loss-PSF2}
\end{align}
where $\mathbf{P_{\lambda, f}}$ and $\overline{\mathbf{P}}_{\lambda, f}$ are the position of every traced ray and averaged position of given wavelength and field of view (FoV). $N_{\text{rays}}, N_f$ and $N_{\lambda}$ are the number of sampled rays, FoVs and wavelengths. $\mathrm{Conv(\cdot)}$ represents $stride=1$ and $padding=K // 2$ convolution, and $K$ is the resolution size of a single PSF. $\lambda_{Spot}$ and $\lambda_{PSF}$ are depends on lens structure.
