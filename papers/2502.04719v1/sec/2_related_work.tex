\section{Related Work}
Our work addresses an important problem - tolerances optimization - that has been neglected in previous deep optics. Here we review recent progress on tolerances optimization and deep optics, and highlight the main differences between existing approaches and our proposed method.

\subsection{Tolerances Analysis and Optimization}
Reduces the sensitivity of the optical design to tolerances and brings it in line with machining accuracy is a long standing problem in optical design. Traditional optical design typically involves a two-stage process \cite{laikin2018lens}, where the optical system is initially designed to fulfill the design objectives, followed by fine-tuning to align with manufacturing accuracy. The root-mean-square (RMS) or peak-to-valley (PV) values of the optical design are used to evaluate the sensitivity of optical component tolerances, as provided by conventional tolerance analysis theory~\cite{ni2019description, maksimovic2016optical, hu2015design}. The tolerance theory is a probabilistic statistical framework based on Monte Carlo methods~\cite{oinen1990new, forse1996statistical}, making it suitable for the tolerance analysis of mass-produced optical components. Zemax software~\cite{ZEMAX}  randomly samples tolerances, analyzes the sensitivity of design parameters to these tolerances through changes in design performance, and adjusts the parameters accordingly~\cite{Synopsys}.

In the context of deep optics for refractive lenses based on geometric ray tracing models, by measuring the actual Spatial Frequency response (SFR), Chen \textit{et al.} further re-calibrated the fabricated optical design parameters that were affected by the tolerances and  improved the accuracy of the imaging simulation in deep optics~\cite{chen2022computational, chen2021optical}. Zhou \textit{et al.} built on their work by adjusting the spacing between some lenses to align the simulated point spread function (PSF) with the actual measured PSF. At the same time, they employed a more powerful Mamba model~\cite{gu2023mamba} as the decoder, thereby reducing the sensitivity of deep optics to tolerances~\cite{zhou2024optical}. However, the aforementioned works focus on calibrating an already machined optical system rather than end-to-end optimization of design parameters, and they do not address sensitivity to tolerances at the design stage. Closest to our work are Zheng \textit{et al.}~\cite{zheng2023neural} using fabrication simulator to simulate degradation due to fabrications in computational lithography and Li \textit{et al.}~\cite{li2022quantization} in deep optics considering Diffractive Optical Elements (DOE) quantization errors due to fabrications, however, they both are not focus on lens, we list all comparisons in \cref{tab:related_work}.

\subsection{Deep Optics}
Deep optics is an emerging field that jointly design and optimize the optical systems and vision algorithm using deep learning~\cite{wetzstein2020inference}. Sitzmann \textit{et al.}~\cite{sitzmann2018end} utilized this approach to design an optical element that enhances image quality. Subsequently, more works have used this method to design optics for image enhancement~\cite{dun2020learned, metzler2020deep, sun2020learning, chakravarthula2023thin} and depth estimation~\cite{chang2019deep, haim2018depth, wu2019phasecam3d, baek2021single}. And similar approach has been taken to design imaging lenses using differentiable ray tracing~\cite{sun2021end, wang2022differentiable, yang2024curriculum}, and differentiable proxy functions~\cite{tseng2021differentiable, yang2023aberration}.~\citet{tseng2021neural} used this technique to design a metasurface lens with improved image quality. In each of these works, a differentiable model for camera's optics is incorporated into a neural network, and the optics is designed by training the network for the specific task.

However, current deep optics models do not consider the impact of tolerances in the simulation model. This problem causes the mismatch between the designed and the fabricated lens system, which degrades reconstruction quality in physical systems. In contrast, our tolerance-aware optimization fix this mismatch by directly modeling common tolerances.

\begin{table}[t]  
    \setlength{\tabcolsep}{0em}  
    \renewcommand{\arraystretch}{1.2}
    \centering  
    \footnotesize  
    \caption{  
        Comparison of related work on the tolerances optimization of deep optics and computational optics, where each criterion is fully~\greencheck, partially~\yellowcheck, or not~\redcheck met.  
        See text for explanations.  
        }  
    \input{sec/related_work}  
    \label{tab:related_work}  
\end{table}


