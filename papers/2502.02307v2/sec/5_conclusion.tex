\section{Conclusion}
\label{sec:conclusion}
In this paper, we provide the first extensive study of the self-supervised large-scale pre-training on gaze estimation. 
Through our extensive experimentation, we have established key principles for effective pre-training in gaze estimation.
With careful data curation for the MAE pre-training, the proposed \methodname achieves distinguished performances for cross-dataset, leave-one-dataset-out, and joint-dataset evaluations compared to current SOTAs.
Interestingly, we show the importance of the pre-training data selection and pre-processing for the final performance, rather than simply gathering a large amount of data.
Looking forward, we believe there remains significant potential for further refinement of pre-training data selection based on the principles identified in this work. 
Another potential improvement option could be using a large-size face image input for the high-resolution scenarios.


