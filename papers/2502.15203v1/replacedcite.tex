\section{Related Works}
\subsection{Diffusion-based Text-to-Image Generation.}
Denoising diffusion models____ and their various extensions____ have made remarkable progress in the field of text-to-image (T2I) generation. 
By leveraging powerful text encoders such as CLIP____, it has become possible to synthesize high-quality images conditioned on textual prompts. 
Recently, methods specialized for high-resolution generation____, classifier-free guidance for enhanced controllability____, and improved models adopting large-scale diffusion backbones____ have also been proposed.

\subsection{Image Editing with Diffusion Models.}
In an effort to harness the outstanding image-generation capabilities of diffusion models, various editing techniques have been proposed. 
For example, MasaCtrl____ demonstrates that freezing the keys and values in the self-attention layers of the denoising network____ can more faithfully preserve the original appearance of an image. 
Subsequently, methods that manipulate self-attention layers to better maintain the shape of a concept____ have also been introduced. 
Such approaches enable localized editing and global style transfer without the need to retrain the entire model, but their performance on complex scenes with multiple objects has yet to be sufficiently verified.

\subsection{Multi-Concept Personalization.}
Generating images that incorporate multiple user-specific concepts is an important yet challenging task. 
Textual Inversion____ introduced a technique that optimizes text embeddings to represent novel concepts, and subsequent research has investigated approaches such as full____ or partially fine-tuning the model parameters____ or inserting rank-one edits____. 
Although training multiple concepts simultaneously may lead to concept blending or partial loss, recent studies aim to mitigate these issues via weight merging____. Concept Weaver____ and DreamMatcher____ offer a training-free approach that combines multiple concepts during sampling, though certain methods may still require inversion or fine-tuning during inference. 
By proposing a novel approach that minimizes additional optimization steps while flexibly generating high-quality images of multiple concepts, our work extends the context of prior research.