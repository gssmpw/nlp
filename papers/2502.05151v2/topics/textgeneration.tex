\subsection{Text-based Content Generation}
\label{sec:textgeneration}

%\collaborators{Stephanie, Wei, Steffen, Chenghua, Brigitte}

%Provide a concise description of the task here, indicate why it is important, and provide any necessary background information/references to contextualize the following subsections.
\mybox{Under text-based content generation for science, we subsume different tasks generating specific text-based subparts of a scientific paper, such as automatically generating (i) the title, (ii) the abstract, (iii) the related work section, as well as (iv) citation generation. Also, frameworks aiming to automate the full paper writing process will be discussed, as well as using AI systems for subtasks such as proof-reading, paraphrasing, and press release generation.}

\subsubsection{Data}

%Give an overview of the most important curated/annotated datasets, or sources of raw data, that are used (or potentially useful for) this task.

Open access research articles are a valuable data source for text-based content generation. These include scientific publisher repositories offering at least some open access content (e.g., \href{https://www.nature.com/nature-portfolio/for-authors/nature-research-journals}{Nature portfolio}, \href{https://www.tandfonline.com/}{Taylor \& Francis}) as well as preprint repositories (e.g., \href{https://arxiv.org/}{arXiv}, \href{https://www.biorxiv.org/}{bioRxiv}).
These open access repositories can be leveraged to develop datasets with pairs of titles and abstracts or abstract and conclusion/future work pairs. \citet{wang-etal-2019-paperrobot} for example extract (i) title to abstract pairs, (ii) abstract to conclusion and future work pairs, and (iii) conclusion and future work to title pairs from PubMed. Annotated, task-specific datasets for scientific text generation %, see 
\se{are presented in}
Table \ref{tab:data_text_generation}.  %\se{include}:


\begin{table}[th!]
\small
    \centering
    \begin{tabular}{p{2.8cm} p{4.8cm}p{2.8cm}p{3cm}}
    \toprule
       \textbf{Dataset}  & \textbf{Size} & \textbf{Sources} & \textbf{Application} \\
       \midrule
	   Abstract-title humor annotated dataset \cite{chen-eger-2023-transformers} & 2,638 humor annotated titles & ML \& NLP domain & Title generation\\
	   PaperRobot \cite{wang-etal-2019-paperrobot} & 27,001 title-abstract pairs; 27,001 abstract-conclusion \& future work pairs; 20,092 conclusion \& future work-title pairs & PubMed & Title generation, abstract generation, conclusion \& future work generation\\
        ScisummNet \cite{yasunaga2019scisummnet} & 1,000 papers + 20 citation sentences each & ACL Anthology Network & Related work generation\\
CORWA \cite{li-etal-2022-corwa} & 927 related work sections & NLP domain & Related work generation\\
		CiteBench \cite{funkquist-etal-2023-citebench} & 358,765 documents + citations & multiple, e.g., arXiv.org & Related work generation\\
		SciTechNews \cite{cardenas-etal-2023-dont} & 2,431 papers + press releases & ACM TechNews & Press release generation\\
\bottomrule
    \end{tabular}
    \caption{Annotated or task-specific datasets for scientific text generation.}
    \label{tab:data_text_generation}
\end{table}

\iffalse
\todo{SE: In face of Table 4, this itemize can now be removed, right? SG: yes}
\begin{itemize}
    \item Abstract to title humor annotated dataset \cite{chen-eger-2023-transformers}: 2,638 manually humor annotated titles (funny, not funny) from machine learning and natural language processing papers. Task: abstract to humorous title generation.
    \item PaperRobot, the PubMed term, abstract, conclusion, title dataset \citet{wang-etal-2019-paperrobot} contains three subsets: 27,001 title to abstract pairs, 27,001 abstract to conclusion and future work pairs, and 20,092 conclusion and future work to title pairs, all from publications from PubMed. Tasks: title generation, abstract generation, conclusion and future work generation
    \item ScisummNet \cite{yasunaga2019scisummnet} is a scientific article summarization dataset consisting of 1000 highly cited papers in computational linguistics and 20 sampled and cleaned citation sentences for each of those papers from the ACL Anthology Network. Task: related work generation.  
    \item CORWA is a dataset on citation oriented related work annotation \cite{li-etal-2022-corwa} and contains 927 manually annotated related work sections from the NLP domain. The data is annotated for the role of each related work sentence (discourse tag), the span of text whose information is directly derived from a specific cited paper (citation span detection), and whether a cited work is discussed in detail or high level (citation type recognition). Paper are from the NLP domain. Task: related work generation.
    \item The CiteBench dataset \cite{funkquist-etal-2023-citebench} is a citation text generation benchmark that brings together four existing task
designs on citation text generation by casting them into a single, general task definition, and unifying the respective datasets from \citet{aburaed:20}, \citet{chen-etal-2021-capturing}, \citet{lu-etal-2020-multi-xscience}, and \citet{xing-etal-2020-automatic}. Task: related work generation
\item The SciTechNews dataset \cite{cardenas-etal-2023-dont} consists of
2,431 scientific papers paired with their corresponding press release snippets mined from ACM TechNews. These papers are from a diverse pool of 
domains, including Computer Science, Physics, Engineering, and Biomedical. Task: press release generation
\end{itemize}
\fi

\subsubsection{Methods and Results}

%Describe the state-of-the-art methods and their results, noting any significant qualitative/quantitative differences between them where appropriate.
%Survey paper: \citet{zhang2024systematic}

\iffalse
\noindent\textbf{Title Generation}
\begin{itemize}
    \item Abstract-to-title: \citet{chen-eger-2023-transformers}
    \item A2T: \url{https://www.researchgate.net/profile/Vishal-Lodhwal-2/publication/369741619_Survey_Paper_Automatic_Title_Generation_for_Text_with_RNN_and_Pre-trained_Transformer_Language_Model/links/642fd66e20f25554da158ea3/Survey-Paper-Automatic-Title-Generation-for-Text-with-RNN-and-Pre-trained-Transformer-Language-Model.pdf}
    \item A2T: \citet{mishra2021automatic}
    \item Title-2-abstract: \citet{wang-etal-2019-paperrobot} 
\end{itemize}
\fi 
In the following, we survey approaches to generating %salient text-based parts of scientific papers, 
textual content for science, 
such as title, abstract, related work and bibliography. 
An overview of these processes \se{is given} in Appendix \ref{ax:content_generation}. 
%\todo{SG: can you please also add 'Paper Content' as basis for abstract generation in the figure?}. 

\paragraph{Title Generation.} %Several works have explored title generation. 
%Several works have considered title generation of scientific papers.
Generating adequate titles for scientific papers is an important task because titles are the first access point of a paper and can attract substantial reader interest; titles can also influence the reception of a paper \citep{letchford2015advantage}.  Consequently, several works have targeted generating titles automatically, often using paper abstracts as input. For example, \citet{mishra2021automatic} use a pipeline of three modules, viz.\ generation by transformer based (GPT2) models, selection (from multiple candidates) and refinement.  \citet{chen-eger-2023-transformers} also leverage transformers for title generation from abstracts but they in addition allow for generation of  humorous titles (which may be even more impactful) when an input flag is set appropriately. To achieve this, they annotate a training dataset of humorous titles from the fields of machine learning and NLP. %natural language processing. 
They explore different models including BART, GPT2, and T5 besides the more recent ChatGPT-3.5 LLM, finding that none of them can adequately generate humorous titles. They also explore generating titles from full texts instead of abstracts, with mixed results. \citet{wang-etal-2019-paperrobot} address the problem differently by drafting title names based on future work sections of previous related papers.
%\citet{wang-etal-2019-paperrobot} %address the problem more comprehensively, 
%consider %ing 
%paper part generation only as a subproblem of a more general `paper robot'. %\todo{BK: what does it mean to consider "paper part generation only as a subproblem", a subproblem of what?}  
%However, instead of generating titles from abstracts, they reverse the problem, generating abstracts from titles, in order to incrementally build up the paper drafting process, leveraging transformers and knowledge bases. \todo{SE: Perhaps then this should go to the next paragraph? SG: Moved it to 'abstract generation'}

\paragraph{Abstract Generation}
There are several approaches trying to assess the capabilities of proprietary LLMs to generate abstracts based on context information such as paper titles, journal names, keywords or the full text of the paper. \citet{hwang2024can} assess the ability of GPT 3.5 and GPT 4 to generate abstracts based on a full text. The results are manually evaluated using the Consolidated Standards of Reporting Trials for abstracts, a standard published with an aim to enhance the overall quality of scientific abstracts \cite{hopewell2008consort}. 
While the readability of abstracts generated by GPT is rated higher, their overall quality is inferior to the original abstracts. Also, minimal errors are reported in the AI generated abstracts. %\todo{SE: why are we switching to the past tense now? SG: sorry, I am so used to writing in past tense that I mixed it up}
\citet{wang-etal-2019-paperrobot} generate abstracts from titles, leveraging transformers and knowledge bases. Also generating abstracts from titles, \citet{gao2023comparing} collect 50 research abstracts from five medical journals and apply ChatGPT to generate research abstracts based on their titles and the name of one of the five journals. The original and the generated abstracts are then evaluated with AI output detectors and with blinded human reviewers to identify which of the abstracts are automatically generated. Human reviewers are able to identify 68\% of the generated abstracts as being automatically generated, but also incorrectly identify 14\% of original abstracts as being LLM generated.  
Applying AI output detectors, most generated abstracts can be identified by the GPT-2 Output Detector assigning a median of 99.98\% generated scores to generated abstracts and a median 0.02\% to original abstracts. 
However, \citet{anderson2023ai} have shown that after automatically paraphrasing AI generated text, the performance of AI detectors such as GPT-2 Output Detector decrease drastically. 
\citet{farhat2023trustworthy} evaluate the performance of ChatGPT generating abstracts based on 3 keywords, the name of a database (Scopus or web of science) and the task to analyze bibliographic data  in the domain indicated by the keywords. % domain in existing literatureconduct a bibliometric analysis. \todo{SE: don't understand this sentence... "the task to conduct a bibliometric analysis?}
%Bibliometrics is the application of statistical methods to identify prolific authors, top avenues, leading countries of a particular domain in existing literature. \todo{SE: remove sentence?}
The authors then compare the generated abstract to an actual abstract on the same topic. %\todo{SE: why past tense?}
After a manual comparison of the results, the authors come to the conclusion that at the time the study was conducted, ChatGPT is not a trustworthy tool for retrieving and assessing bibliographic data. %However, they emphasize the usefulness as a writing assistant tool for improving readability, language enhancement, rephrasing/paraphrasing and proofreading.    

\paragraph{Long Text Generation}  %\todo{SE: this paragraph should maybe be included in the section description: that we are doing this and why this is important? SG: I added it to the section description}
Some approaches aim at automating the full paper writing process. The \textbf{AI Scientist} \cite{lu2024aiscientist} presents a comprehensive framework designed to support the entire scientific research cycle, encompassing tasks such as idea generation, hypothesis formulation, experimental planning, and execution. While its primary focus is not on long-form text generation, AI Scientist is able to generate entire scientific papers. By incorporating structured scientific knowledge (e.g. experimental results), the framework can draft papers that adhere to domain-specific requirements, involving the integration of relevant citations and conforming to disciplinary norms. Despite its ability to produce comprehensive paper drafts, the framework does not explicitly address the challenge of maintaining coherence across extended narratives, and their dependencies. 
\textbf{LongWriter} \cite{bai2024longwriter} and \textbf{LongEval} \cite{wu2025longeval} directly address the challenge of generating extended text by introducing architectural modifications aimed at enhancing coherence and structural consistency in long-form outputs. The framework employs hierarchical attention mechanisms to ensure thematic consistency across long text and applies fine-tuning strategies to align outputs with user prompts. LongWriter conducts experiments on several domains, including academic and monograph texts. For academic content, the model %demonstrated its ability to 
can generate structured arguments and effectively incorporate domain-specific terminologies. However, noticeable issues remain around factual consistency, the integration of citations, and redundancy in the generated text. %\todo{SE: In this whole paragraph, to save space, we could remove the line breaks and bold the method names such as LongWriter.} 
However, by conducting experiments on various models in academic, wikipedia and blog domains, LongEval shows that the larger models trained with general instruction data performs similar to those specifically trained (e.g., LongWriter).
%LongCitez \cite{zhang2024longcite} 
%LongCite \cite{zhang2024longciteenablingllmsgenerate} \todo{SE: there was no reference and a paper called LongCitez seemingly doesn't exist. I inserted a paper called LongCite}
%emphasizes the integration of citation-based context in long-form text generation. By training models on citation-rich datasets, LongCitez ensures that generated content aligns with existing scientific discourse and appropriately references relevant literature. 
\textbf{LongReward} %\cite{zhang2024longreward}
\cite{zhang2024longrewardimprovinglongcontextlarge}
leverages reinforcement learning to improve long-text generation. The model employs custom reward signals that prioritize coherence, factual accuracy, and linguistic quality. These reward mechanisms are particularly relevant for scientific text generation, where accuracy and adherence to domain-specific conventions are crucial.


\paragraph{Related Work Generation} %\citet{li-ouyang-2024-related,li2022generating,hu-wan-2014-automatic,shah2021generatingrelatedwork} 

Already in the past, there has been a substantial body of work on related work generation through text summarization, most of which differ in their approach (extractive or abstractive) and the length of citation text (sentence-level or paragraph-level). Extractive approaches focus on selecting sentences from cited papers and reordering the extracted sentences to form a paragraph of related work. For instance, \citet{hoang-kan-2010-towards} propose an extractive summarization approach that selects sentences describing the cited papers to generate the related work section of a target paper. This approach relies on the full text of the target paper. Subsequent extractive approaches differ from this approach in how they order the extracted sentences: While \citet{wang-etal-2018-neural-related}, \citet{chen2019automatic}, and \citet{wang2019toc} assume that the sentence order is given,  \citet{hu2014automatic} and \citet{deng2021automatic} take advantage of an automatic approach to reorder sentences based on topic coherence. However, extractive approaches often struggle to produce coherent text, as they simply concatenate sentences without ensuring a cohesive narrative flow. In contrast, abstractive related work generation leverages devices of rewriting and restructuring to generate a summary of a cited paper. Most of the abstractive approaches are based on language models and focus on either generating (a) a single sentence from a single reference 
or (b) a paragraph from multiple references. Typically, the abstractive process is repeated multiple times until a related work section is complete.
% Typically, the abstract of a reference is given as input. 
% For instance, 
\citet{abura2020automatic} introduce an abstractive summarization approach to generate citation sentences in a single-reference setup. Their approach has been trained on the \textbf{ScisummNet} corpus with paper abstracts as inputs and citation sentences as outputs. \citet{li-etal-2022-corwa} further extend this idea to a multiple-reference setup, namely generating a paragraph of citation sentences from various cited papers. Their approach has been trained on the \textbf{CORWA} corpus to generate both citation and transition sentences. Additionally, instead of using paper abstracts as inputs, \citet{li2024cited} propose to retrieve relevant sentences from cited papers to generate citation sentences. More recently, works such as \citet{sahinuc-etal-2024-systematic} 
% argue that citation intents play an important role for related work generation and 
explore 
% systematically assess the impact of 
instruction promoting with %large language models, 
\se{LLMs}, 
which is alternative to extractive and abstractive approaches, to generate citation sentences.
% on citation text generation outputs.
Overall, 
% both extractive and abstractive approaches are widely used for generating citation sentences. 
extractive approaches, while factual, often lack fluency and coherence. In contrast, abstractive approaches and instruction prompting, which are based on (large) language models, do not struggle with these issues, however, they suffer from factual errors, known as hallucination. %\todo{SE: limitation section?} SG: I think it fits better here... However, if you prefer to move it to the limitation section, it is also fine with me.
 


\paragraph{Citation Generation} %\citet{li-ouyang-2024-related,huang2023citation,li2024citation,farhat2023trustworthy}, Hallucinations in citation-enhanced generation \citet{li2024citation}
Bibliographic references in scientific papers are important components for ensuring the scientific integrity of the authors. However, in many cases, cited articles of bibliographic references generated by LLMs such as ChatGPT are reported not to exist, that is, are hallucinated or incorrect \cite{li-ouyang-2024-related,huang2023citation,li2024citation,farhat2023trustworthy}. Most of the studies reporting hallucinated or erroneous bibliographic references are case studies presenting one or more examples. 
\citet{walters2023fabrication}, however, present a study in which they use ChatGPT-3.5 and ChatGPT-4 to produce 84 documents (short reviews of the literature) on 42 multidisciplinary topics. The resulting documents contain 636 bibliographic citations, which are further analyzed for errors and hallucinations. Their results show that 55\% of the GPT-3.5 citations but only 18\% of the GPT-4 citations are fabricated. Of the actual existing (non-fabricated) GPT-3.5 citations, 43\% include substantive citation errors, and of the non-fabricated GPT-4 citations it is 24\%. 
%\todo{SE: why are we switching to past tense now again? SG: sorry}
Even though this is a major improvement from GPT-3.5 to GPT4, problems with fabrication and errors in bibliographic citations remain. %\todo{SE: Any evidence? SG: The evidence is in the preceding sentence - I tried to make it clearer} 
Therefore, for generated citations and references, it is of particular importance to ensure their accuracy and completeness. %\todo{SE: Actually, this can be highlighted as a limitation of these studies (e.g., based on GPT3.5). LLMs are advancing rapidly, conclusions are quickly outdated SG: added it to the limitations section}

\paragraph{Proof-reading and Paraphrasing.} %\citet{huang2023role,salvagno2023can,kim2023using,castellanos2023good}
LLMs such as ChatGPT have been reported to provide useful assistance for scientific writing with regards to proof-reading and language review in order to enhance the readability of the paper. Subtasks these models can provide support for during the writing process include providing suggestions for improving the writing style, or proof-reading \cite{salvagno2023can}. Additionally, some authors emphasize that LLMs %such as ChatGPT \todo{SE: do we always need to say ``LLMs such as ChatGPT''?}
can be helpful especially for non-native English speakers with regards to grammar, sentence structure, vocabulary and even translation, i.e., providing an English editing service \cite{huang2023role,castellanos2023good,kim2023using}. Most papers on this topic are case studies, illustrating their research questions with one or more examples and their results are qualitatively evaluated by a human expert (typically the author of the paper). \citet{hassanipour2024ability} evaluate the effectiveness of ChatGPT in rephrasing not for improving the writing style, but for reducing plagiarism in the process of scientific paper writing. The results showed that even with explicit instructions to paraphrase or reduce plagiarism, the plagiarism rate remained relatively high.

%Hallucinations in scientific writing \citet{alkaissi2023artificial}, hallucinations in systematic reviews \citet{chelli2024hallucination}

\paragraph{Press Release Generation.}  Several studies attempt to generate press release articles for the general public based on scientific papers. \citet{cao-etal-2020-expertise} construct a manually annotated dataset for expertise-style transfer in the medical domain and apply various style transfer and sentence simplification models to convert expert-level language into layman’s terms. \citet{goldsack-etal-2022-making} develop standard seq-to-seq models to generate news summaries for scientific articles. Lastly, \citet{cardenas-etal-2023-dont} propose a framework that integrates metadata from scientific papers and scientific discourse structures to model journalists’ writing strategies. %\todo{SE: the last sentence miraculously switches back to present tense}

% %%%%%%%%%%%% Moved to appendix  %%%%%%%%%%%%%%%%
\subsubsection{Ethical Concerns}

%Identify and discuss any ethical issues related to the (mis)use of the data or the application of the methods, as well as strategies for mitigations.

In scientific work, authorship and plagiarism in AI generated texts are major concerns. In general, it is a challenge to distinguish between AI generated and human generated texts. %Although there is a number of tools to detect AI-generated text (e.g., GPTZero or Hive), \citet{anderson2023ai} have shown that after applying automatic paraphrasing, the detection of human generated text using GPT-2 Output Detector increased, e.g., the probability of the text being generated by a human from 0.02\% to 99.52\%.
Although there is a number of tools to detect AI-generated text (e.g., GPTZero or Hive), \citet{anderson2023ai} show that after applying automatic paraphrasing to AI generated text, the probability of a text to be human generated, increases. %todo{SE: repeated text}
%identified by GPT-2 Output Detector to be written by a human, increased (e.g., from 0.02\% to 99.52\%).
Therefore it is not possible to reconstruct if a text is an original work from a scientist or has been generated by an AI. 
In addition, it is also found that ChatGPT generated texts easily pass plagiarism detectors \cite{else2023chatgpt,altmae2023artificial}. 
Moveover, \citet{macdonald2023can} raise the concern that the frequent use of LLMs for drafting research articles might lead to similar paragraphs and structure of many papers in the same field. This again raises the question whether there should be a threshold for the acceptable amount of AI-generated content in scientific work \cite{macdonald2023can}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsubsection{Domains of Application}

%\todo{Indicate whether any of the data, methods, ethical concerns, etc. are specific to a given domain (biology, health, computer science, etc.).}

%\todo{SE: shouldn't this section be about different domains?}

Text-based content generation is relevant for all scientific domains. \citet{liang2024mapping} conduct a large-scale analysis across 950,965 paper published between January 2020 and February 2024 to measure the prevalence of LLM modified content over time. The papers they investigated were published on (i) arXiv including the five areas Computer Science, Electrical Engineering and Systems Science, Statistics, Physics, and Mathematics, (ii) bioRxiv, and (iii) Nature portfolio. Their results show the largest and fastest growth in Computer Science with up to 17.5\% of the papers containing LLM modified content %\todo{SE: what does this number mean? SG: tried to clarify it}
and the least LLM modifications in Mathematics papers (up to 6.3\%). However, according to the Natural Language Learning \& Generation arXiv report from September 2024, top-cited papers show notably fewer markers of AI-generated content compared to random samples \cite{Leiter2024NLLGQA}.

\subsubsection{Limitations and Future Directions}

%\todo{Summarize the limitations of current approaches; point out any notable gaps in the research and future directions.}

Numerous studies have investigated text-based content generation for the scientific domain and have shown their potential to assist scientists in different phases of writing a paper. While for some tasks such as proof-reading and paraphrasing, its capabilities are well established, others pose limitations. Therefore it is crucial that automatically generated text is always assessed by a human expert. Factual consistency and truthfulness are issues which need to be reviewed by a human in the loop %\todo{SE: here it is not an adjective, so I would remove the hyphens}
for all types of text-based generated content. Current proprietary LLMs for example struggle in particular with generating existing and correct bibliographic citations. However, LLMs are advancing rapidly and studies evaluating LLMs are quickly outdated. Still, several ethical issues arise when text-generating systems are included in the scientific writing process, such as authorship, plagiarism, bias, and truthfulness. Therefore, in future research a focus on trustworthy, ethical AI systems is required. 

%\subsubsection{AI use case}

%\todo{Optional: describe which portions of your section (figures, tables, text, etc.) have been assisted by AI and how.}

%\subsubsection{Limitations and future directions}