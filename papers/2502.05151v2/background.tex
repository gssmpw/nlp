\section{Background}\label{sec:background}

% Length: 1 to 2 pages = 4 to 10 paragraphs

% To cite:
% \begin{itemize}
% \item General theoretical/sociological backdrop of science production:
%   \begin{itemize}
%   \item \cite{inie2022how,ziman1991reliable,hey2009jim}
%   \item Mertonian norms: \cite{merton1942note}
%   \item \cite{ziman2000real} expands on Mertonian norms; has chapters on modes of knowledge production and originality\slash novelty of ideas
%   \end{itemize}
% % \item Literature  search, synthesis, summary, and comparison: \cite{bornmann2021growth}
% \item Designing and conducting experiments; AI-based discovery:  %\cite{inie2022how}
% \item Text-based content generation:
%   \begin{itemize}
%   \item Process of academic writing: \cite{hartley2008academic}
%   \end{itemize}
% \item Multimodal content generation and understanding:
% \item Peer review:
%   \begin{itemize}
%   \item Particularly \cite{merton1942note} for the notion of ``(organized) skepticism''
%   \item \cite{drozdz2024peer}
%   \end{itemize}
% % \item Other miscellaneous aspects: 
% \end{itemize}

\begin{figure}[h]
  \centering
\begin{adjustbox}{width = \textwidth}%
  \smartdiagramset{uniform color list=white!20 for 6 items, arrow color=black, uniform arrow color=true}%
  \smartdiagram[flow diagram:horizontal]{Question,Study,Hypothesize,Experiment,Analyze,Report}%
\end{adjustbox}
  \caption{Scientific discovery cycle, after \cite{cornelio2023combining}}%
  \label{fig:cycle}%
\end{figure}

 \todo{JD: this is pretty interesting. Something for the Introduction?}
 Over time, science has progressed through numerous paradigm shifts, leading to the modern era of data-intensive exploration~\cite{hey2009jim}. Despite advancements in tools and methodologies that have accelerated discovery, the fundamental steps of the scientific process have remained consistent. As illustrated in Fig.~\ref{fig:cycle}, this process typically begins with identifying a research question, followed by reviewing relevant literature, formulating a hypothesis, designing and conducting experiments, analyzing data, and ultimately reporting findings. This iterative cycle ensures the continuous refinement and expansion of scientific knowledge.
 
% Throughout history, science has undergone a number of paradigm shifts, culminating in today's era of data-intensive exploration~\cite{hey2009jim}.  Although new tools and frameworks have accelerated the pace of scientific discovery, its basic steps have remained unchanged for centuries.  As visualized in Fig.~\ref{fig:cycle}, these include (1)~conception of a research question or problem, typically arising from a gap in disseminated knowledge; (2)~collection and study of existing literature or data relevant to the problem; (3)~formulation of a falsifiable hypothesis; (4)~design and execution of experiments to test this hypothesis; (5)~analysis and interpretation of the resulting data; and (6)~reporting on the findings, allowing for their exploitation in real-world applications or as a source of knowledge for a further iteration of the scientific cycle.

With respect to the first two of these steps, a major challenge for any scholar is achieving, and then maintaining, sufficient familiarity with existing research on a given topic to be able to identify new research questions or to discover the knowledge required to answer them.  Before the 20th century, it was often feasible to keep abreast of developments in a specialty simply by reading all the relevant books and journals as they were published.  In modern times, however, the number of scientific publications has been doubling every 17 years~\cite{bornmann2021growth}, making this exhaustive approach unworkable.  The need to sift through large quantities of scholarly knowledge spurred the specialization of simple library catalogs (in use since ancient times) into abstracting journals, bibliographic indexes, and citation indexes.  By the 1960s and 1970s, many of these resources were being produced with standardized control principles and technologies, and could be queried interactively using automated information retrieval systems~\cite[pp.\,88--91]{borgman2007scholarship}.  These technical developments have enabled the widespread adoption of more principled approaches to the exploration of scientific knowledge, such systematic reviews~\cite{chalmers2002brief} and citation analysis~\cite{garfield1955citation}.

How experts propose hypotheses to explain observed phenomena has been extensively discussed in the philosophy and psychology of science, albeit with little empirical work until relatively recently~\cite{clement1989learning,clement2022multiple}.  Contrary to the idealized notion of scientific reasoning, hypotheses rarely come about solely through induction (i.e., the abstraction of a general principle from a set of empirical observations).  Rather, case studies employing think-aloud protocols suggest that hypotheses are generated through a process of successive refinement.  These processes may involve non-inductive heuristics (analogies, simplifications, imagistic reasoning, etc.)\ that often fail individually, but may lead to valid explanatory models after ``repeated cycles of generation, evaluation, and modification or rejection''~\cite{clement1989learning,clement2022multiple}.

Experimentation and analysis aim to establish a causal relationship between the independent and dependent variables germane to a given scientific hypothesis.  The metascientific literature abounds with practical advice on the design and execution of experiments, much of it discipline-specific. However, the general ideas at play can be traced to Ronald Fisher, whose seminal works on statistical methods~\cite{fisher1925statistical} and experimental design~\cite{fisher1935design} popularized the principles of randomization (assigning experimental subjects by chance), replication (observing different experimental subjects under the same conditions), and blocking (eliminating undesired sources of variation).  Besides these considerations, experimental design involves the determination of the (statistical) analysis that will be performed, and is often constrained by the availability of resources such as the time, effort, or cost to gather and analyze observations or data~\cite{kirk2009experimental}.

The final step in the scientific cycle, reporting, encompasses the dissemination of research findings, typically but not exclusively to the wider scientific community through articles, books, and presentations.  The practice of scientific communication has itself attracted scientific study, leading to descriptive and pedagogical treatments of its various processes and strategies (e.g., \cite{yore2004scientists,hartley2008academic}).  The essential role of peer review~\cite{weller2001editorial} has attracted special attention, albeit more on its high-level processes, its efficacy and reliability, and its objectivity and bias rather than on how reviewers go about evaluating manuscripts and communicating this evaluation.  Accordingly, technological developments in the peer review workflow have until very recently tended to focus on managing or streamlining the review process for the benefit of the editor and publisher, or on supporting open or collaborative reviewing~\cite{weller2001editorial,drozdz2024peer}.

\todo{SE: we could see (i) whether this section can be shortened, (2) whether and how it fits to the rest in Section 4}