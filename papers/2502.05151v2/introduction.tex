\section{Introduction}\label{sec:introduction}
With the advent of large multimodal foundation models such as \href{https://chatgpt.com/}{ChatGPT}, \href{https://deepmind.google/technologies/gemini/}{Gemini}, \href{https://github.com/QwenLM/Qwen}{Qwen}, or \href{https://www.deepseek.com/}{DeepSeek}, many research fields and sectors of everyday life now stand at the threshold of an AI-based technological transformation. Science is no exception. A recent study analyzed approximately 148,000 papers from 22 non-CS fields that cited large language models (LLMs) between 2018 and 2024, reporting a growing prevalence of LLMs in these disciplines \cite{pramanick2024transformingscholarlylandscapesinfluence}.
Additionally, a very recent survey among almost 5000 researchers in more than 70 countries, by the American Publishing Company Wiley, suggests that AI adoption is embraced by a majority of researchers who think that AI will become mainstream in science within the next two years, despite current usages often limited to forms of writing assistance.\footnote{\url{https://www.wiley.com/en-us/ai-study}, \url{https://www.nature.com/articles/d41586-025-00343-5}} 


While science has  traditionally relied on human ingenuity and labor in terms of coming up with research ideas and hypotheses, searching for the relevant literature, experimentation and then reporting of research results, recently, there has been a surge of AI models, tools, and functionalities promising to assist human scientists in these endeavors. This includes models like \href{https://elicit.com}{Elicit} or \href{https://ask.orkg.org/de}{ORKG ASK} for search; models like The AI Scientist \citep{lu2024aiscientist} for experimentation; and models like AutomaTikZ \citep{belouadi2024automatikz} and DeTikZify \citep{belouadi2024detikzify} for multimodal scientific content generation; there is even research investigating the degree to which these AI models are capable of evaluating the outcomes of the scientific process in terms of reviewing and assessing research papers \cite{10.1613/jair.1.12862}. All these models promise to vastly accelerate the scientific research cycle, ideally leading to unexpected new findings and a better, more user-friendly and more accurate documentation, referencing and reporting of research results.\footnote{The benefits are expected to be particularly large for non-native speakers of English and those with lower technical skills, ideally leading to increased diversity and inclusivity of the research process.}

However, to our best knowledge, currently there exists no comprehensive survey on existing tools, models and functionalities as well as their limitations that could aid scientists in speeding up and improving the research cycle, except for specific subfields such as the social sciences \cite{XU2024103665} or branches of physics \cite{Zhang2023ArtificialIF}.\footnote{We note two contemporaneous works developed completely independently from us \cite{zhang-etal-2024-comprehensive-survey,luo2025llm4srsurveylargelanguage}. Both are substantially narrower in scope than this survey; for example, \citet{luo2025llm4srsurveylargelanguage} neither cover multimodal approaches to scientific content synthesis nor  search and also do not address ethical concerns in nearly the same depth as we do.} 
In this survey, we fill this urgent gap by providing an overview over five  central aspects of the research cycle where recently a plethora of new AI models has been proposed: search  (e.g., for relevant literature) and content summarization in Section \ref{sec:literature_search}; scientific experimentation (e.g., coding) and research idea generation in Section \ref{sec:experiments}; unimodal content generation such as drafting titles, abstracts, suggesting citations and helping in reformulation text-based material in Section \ref{sec:textgeneration}; multimodal content generation and understanding such as generating and understanding figures, tables, slides and posters in Section \ref{sec:multimodal}; and AI-assisted peer review processes in Section \ref{sec:peer_review}. The recent survey of Wiley indicates that such an overview is highly important for AI researchers in their quest for better guidelines and support of tool (usages) for the scientific process, where ``63\% [of respondents indicated] a lack of clear
guidelines and consensus on what uses of AI are accepted in their field and/or the need for more training and skills”.

When it comes to using AI tools for science, ethics is of overarching importance. This is because the AI tools exhibit various limitations, e.g., they (i) may hallucinate and fabricate content, (ii) exhibit bias, (iii) may have limited reasoning abilities and (iv) sometimes lack suitable evaluation, and (v) may have a large environmental footprint, among many other concerns such as risks of fake science, plagiarism, and lack of human authority. Indeed, the European Union has recently released guidelines on the responsible use of AI for science. In it, it points out that, while ``[r]esearch is one of the sectors that could be most significantly disrupted by generative AI’’ where ``AI has great potential for accelerating scientific discovery and improving the effectiveness and pace of research and verification processes’’, 
``these [AI] tools could harm research integrity and raise questions about the ability of current models to combat deceptive scientific practices and misinformation’’.\footnote{\url{https://research-and-innovation.ec.europa.eu/document/download/2b6cf7e5-36ac-41cb-aab5-0d32050143dc_en?filename=ec_rtd_ai-guidelines.pdf}} In our survey, we highlight ethical considerations by including a dedicated ethics subsection within each of the five aspects of the research cycle, and a dedicated overarching discussion in Section \ref{sec:ethics}.


It is worth pointing out that our survey does not cover other aspects relating AI to science, e.g., of analysis of science with data science tools such as investigated in fields like the `science of science’ \cite{doi:10.1126/science.aao0185,wang2021science}.


As shown in Fig. \ref{fig:overview}, the rest of this paper is organized as follows: \S\ref{sec:methodology} discusses the methodological approach of our survey. In §\ref{sec:tasks}, each subsection describes the application of AI to an individual scientific task (literature search, experimental design, writing, etc.). For each such task, we describe the important data sets, state-of-the-art methods and results, ethical concerns, domains of application, limitations, and future directions. \S\ref{sec:ethics} discusses ethical concerns that are not specific to any one task.  Finally, §\ref{sec:conclusion} offers some concluding remarks highlighting the benefits and limitations of scientific AI and identifying some general avenues for future work. \todo{SE: make sure the conclusion contains what is promised here}

Resources related to this survey are available at \url{https://github.com/NL2G/TransformingScienceLLMs}. 


% \input{table/overview_figure}

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=0.74\textwidth]{image/overview_figure.pdf}
  \caption{Overview of the survey structure, including our survey methodology, five AI-assisted topics or tasks, and ethical considerations.} 
  \label{fig:overview}
\end{figure*}
