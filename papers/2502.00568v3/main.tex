\documentclass[fleqn,10pt]{wlscirep}

\usepackage{mdframed, multirow}
\newcommand{\probP}{\text{I\kern-0.15em P}}
\usepackage{natbib}

\setcitestyle{numbers}
\bibliographystyle{unsrtnat}

\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{xr}
%\externaldocument[s-]{supplementary}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\linespread{1.3}

\raggedbottom

\title{Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions}

\author[1]{Samiran Dey}
\author[2,3]{Christopher R.S. Banerji}
% \author[4]{Chris Harbron}
\author[1]{Partha Basuchowdhuri}
\author[4]{Sanjoy K. Saha}
\author[2,5]{Deepak Parashar}
% \author[2,6]{Ben D. MacArthur}
\author[2,6,7,*]{Tapabrata Chakraborti}


\affil[1]{School of Mathematical \& Computational Sciences, Indian Association for the Cultivation of Science, Kolkata, India}
\affil[2]{The Alan Turing Institute, London, UK}
\affil[3]{Comprehensive Cancer Center, King's College London, London, UK}
% \affil[4]{Roche Pharmaceuticals, Welwyn Garden City, UK}
\affil[4]{Department of Computer Science and Engineering, Jadavpur University, Kolkata, India}
\affil[5]{Warwick Medical School, University of Warwick, Coventry, UK}
% \affil[6]{School of Mathematical Sciences, University of Southampton, Southampton, UK}
\affil[6]{UCL Cancer Institute, University College London, London, UK}
\affil[7]{Department of Medical Physics and Biomedical Engineering, University College London, London, UK}



\affil[*]{Correspondence to: Tapabrata Chakraborti (\href{tchakraborti@turing.ac.uk}{tchakraborty@turing.ac.uk; t.chakraborty@ucl.ac.uk})}


\begin{abstract}
Emerging research has highlighted that artificial intelligence based multimodal fusion of digital pathology and transcriptomic features can improve cancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction. However, such direct fusion for joint decision is impractical in real clinical settings, where histopathology is still the gold standard for diagnosis and transcriptomic tests are rarely requested, at least in the public healthcare system. With our novel diffusion based crossmodal generative AI model PathGen, we show that genomic expressions synthesized from digital histopathology jointly predicts cancer grading and patient survival risk with high accuracy (state-of-the-art performance), certainty (through conformal coverage guarantee) and interpretability (through distributed attention maps). PathGen code is available through GitHub at \url{https://github.com/Samiran-Dey/PathGen} for open use by the research community.
\end{abstract}

\begin{document}

\maketitle

\section{Introduction}
\label{sec_intro}

Histopathological assessment is the gold standard for cancer diagnosis and provides information essential for accurate staging to inform prognosis. However, aging populations, strained healthcare services and the increasing diagnostic and prognostic complexity of modern medicine are contributing to an unsustainable workload for practising histopathologists \cite{workload}. Modern artificial intelligence (AI) algorithms, particularly deep learning models, can predict cancer grade and sub-types from digital hematoxylin and eosin (H\&E) stained pathology slides, complementing and supporting pathology workflows and potentially reducing the high workload burden \cite{grader1, grader2, grader4, grader5, grader6, grader7}. Very recently the emergence of pathology foundation models using large vision transformers (ViT) has greatly increased model flexibility, enabling support with a wide variety of downstream tasks and providing greater utility for pathologists \cite{uni, mi_zero, conch}.

\begin{figure}[!ht]
    \centerline{\includegraphics[scale=0.17]{images/Data_overview.png}}
    \caption{\textbf{Data and methodology overview.} (a-b) (i) Distribution of data across demographic categories (ii) Distribution of data across train - validation - calibration - test splits (iii) Number of genes in different gene groups.
    (c) Pipeline for the proposed methodology. Our novel diffusion-based crossmodal generative model, PathGen, synthesizes transcriptomic features from whole slide image patch embeddings obtained using a state-of-the-art foundation model from the whole slide images. Multimodal prediction is performed for both diagnosis (cancer grading) and prognosis (survival risk) using the synthesized transcriptomic data and histopathology images to predict the added value of transcriptomic data, for each patient. Uncertainty quantification provides a patient-level estimate of model reliability and provides clinicians with survival risk bounds and tumour grade prediction sets which are guaranteed to contain the ground truth with a specified probability. Distributed predictions also provide a window to understand the intra-tumour heterogeneity.}
    \label{fig_overview}
\end{figure}

Classically histopathology has relied on microscopic assessment of H$\&$E stained tissue sections, often complemented by targeted panels of immunohistochemical and other special stains, to confirm and refine diagnoses. As technology has advanced, a broader range of molecular tests have become routine for assessing certain tumours. These include genetic analyses such as IDH mutation status, which is required to appropriately subtype gliomas according to the WHO \cite{who} and EGFR mutation status which is essential to guide therapy decisions in non-small cell lung cancers \cite{egfr}. More recently, a range of transcriptomic tests have been developed, which show clear evidence for guiding treatment decisions in specific malignancies \cite{chemo}. Following extensive clinical evaluation, several of these tests have been granted regulatory approval for clinical use \cite{preci}. However, guidelines, especially in public healthcare systems, strictly limit the application of these transcriptomic tests to a small minority of patients, largely due to their high financial cost and infrastructural requirements \cite{cost}.

Recently, AI models employing a multimodal fusion of digital pathology and transcriptomic features, trained on large public datasets, like The Cancer Genomic Atlas (TCGA), have led to significant improvements in the predictive accuracy of both grading and survival risk estimation, compared to unimodal models employing digital H$\&$E slides alone \cite{riskr5, pathomic, mcat}. Though these powerful models have the potential to convey significant health benefits, they are developed in a setting disjoint from the current reality of the clinic. Translation of these models into most healthcare systems is infeasible at present, as the required transcriptomic data is very seldom collected. Future translation requires rigorous, costly and widespread clinical evaluation, to determine which patients would benefit from these models sufficiently to justify the cost of transcriptomic data. 

Crossmodal generative AI models can be trained to synthesize one unavailable data modality (transcriptomics) from routinely available modalities (digital pathology) \cite{trans_gen, SEQUOIA, trans_hist}. Coupled with a multimodal AI model, this could facilitate a cost-effective screening tool to estimate the added value of collecting transcriptomic data for diagnostic/prognostic assessment of each individual patient. Such an approach could support cost-efficient clinical evaluation, and sustainable translation of multimodal AI models to support pathology workflows.

Here we introduce a novel, diffusion based crossmodal generative model, PathGen, that synthesizes transcriptomic data from digital images of H$\&$E stained slides. We develop our model on two publicly available multimodal data cohorts (glioma \cite{tcga_gbm, tcga_lgg} and renal cancer \cite{tcga_kirc}) from  TCGA. We find that generated transcriptomic data are highly similar to the corresponding real transcriptomic data, in a hold-out validation set. We further demonstrate that the predictive performance of both diagnosis (cancer grading) and prognosis (survival risk) significantly improves when the synthesised transcriptomic data is combined with features learned from the corresponding digital pathology image, using a state-of-the-art ViT-based model through a co-attention mechanism. 

For practical utility, our model must be trusted by clinicians and attune to emerging regulation \cite{eu_ai_act}. We thus provide transparency via detailed attention based heatmaps for both grading and survival risk prediction, allowing pathologists to visually affirm the clinical relevance of the regions contributing most towards the AI decision. We provide uncertainty quantification, via conformal analysis \cite{conformal}, to allow pathologist users, a measure of certainty in added value of the synthesized transcriptomic data for each patient. Finally, to evaluate algorithmic fairness, we apply our conformal uncertainty quantification to assess model performance analysis across various patient demographics. Our work builds on preliminary studies in crossmodal prediction \cite{uni, pathomic, mcat}, to provide a road map for sustainable, safe and cost-effective translation of multimodal AI models supporting cancer diagnostics/prognostics, to the clinic.

\begin{figure} [!ht]
    \centerline{\includegraphics[scale=0.21]{images/Main_res.png}}
    \caption{\textbf{Evaluation of synthesized transcriptomic data and explainability}. (i) comparison between real and synthesized gene expression levels for different gene groups. (ii) plot of significant performance improvement on using synthesized transcriptomic data and not using them and closeness of using synthesized and real transcriptomics for gradation (AUC) and survival risk estimation (C Index). (iii) comparison of distributed prediction with non-distributed WSI prediction. (iv) comparison of co-attention maps generated using synthesized and real transcriptomic data. (v) percentage contribution of gene groups in co-attention.}
    \label{fig_res}
\end{figure}

\section{Results}
\label{sec_result}

\subsection{Dataset and study design}
\label{sec_data}
Our experiments use publicly available data from TCGA \footnote{\url{https://www.cancer.gov/tcga}}, specifically two independent cancer cohorts - Glioblastoma Multiforme and Brain Lower Grade Glioma (TCGA-GBMLGG) and Kidney Renal Clear Cell Carcinoma (TCGA-KIRC) \cite{tcga_kirc}. For TCGA-GBMLGG, 653 whole slide images (WSIs) coming from 532 cases are used to train, 69 WSIs from 56 cases to validate, 104 WSIs from 82 cases to calibrate and 86 WSIs from 75 cases to test (Figure \ref{fig_overview}.a.ii) of which 562 cases belong to TCGA-LGG \cite{tcga_lgg} and 183 cases belong to TCGA-GBM \cite{tcga_gbm}. For TCGA-KIRC \cite{tcga_kirc}, we use 344 WSIs from 337 cases to train, 42 WSIs from 34 cases to validate, 48 WSIs from 45 cases to calibrate and 51 WSIs from 46 cases to test (Figure \ref{fig_overview}.b.ii). Cases with missing grade, survival data or transcriptomic data are excluded. The data distribution across various demographic groups like gender, age, censorship status, etc. varies for both cohorts (Figures \ref{fig_overview}.a.i, \ref{fig_overview}.b.i). 

Transcriptomic features are selected to match those employed in the successful multimodal models \cite{pathomic, mcat}. As proposed previously \cite{mcat}, transcriptomic data for each patient is divided into 6 broad categories of genes - tumour suppressor genes, oncogenes, protein kinases, cell differentiation markers, transcription factors, and cytokines and growth factors \footnote{\url{https://github.com/mahmoodlab/MCAT/blob/master/datasets_csv_sig/signatures.csv}}. The number of available gene expression levels for each group are 84, 314, 498, 424, 1396 and 428 respectively for TCGA-GBMLGG resulting in a total of 3144 genes (Figure \ref{fig_overview}.a.iii). Whereas for TCGA-KIRC, the number of available gene expression levels for each group are 145, 522, 669, 681, 2366, and 990 respectively resulting in a total of 5373 genes (Figure \ref{fig_overview}.b.iii). When discussing gene expression levels throughout this paper, we refer to transcript abundance, rather than protein levels.

Our methodology synthesizes transcriptomic data from WSIs using our diffusion based generative model, PathGen. Synthesized transcriptomes are then used for automated cancer gradation and survival risk estimation to assess whether transcriptomic tests should be requested (Figure \ref{fig_overview}.c). We use transcriptomic data (both real and synthesized) at two stages in the predictive model (MCAT\_GR) - to co-attend the WSI patch embeddings and learn a combined feature map that is suitable to predict both grade and survival and to predict the survival risk of a patient in a learnable ensemble method along with the co-attended feature maps. We perform extensive experiments using synthesized transcriptomic data to decide on this model setting (supplementary Table \ref{result_gen_use}). The model is trained end-to-end for performing both gradation and survival risk estimation together using the loss function, 
$L = \lambda \times L_{survival} + (1-\lambda) \times L_{grade}$, 
where $L_{survival}$ is the loss for survival risk estimation, $L_{grade}$ is the loss for gradation and $\lambda$ is the loss coefficient to balance the emphasis on survival risk estimation and gradation. Experiments show that at $\lambda=0.3$ the model performance is optimal with close and high scores for both gradation and survival risk estimation together for both cohorts (supplementary Figure \ref{fig_lambda} and supplementary Table \ref{result_gen_use}). Thus for all results reported in the paper, we use $\lambda=0.3$. For uncertainty estimation using conformal prediction, we choose the error rate $\alpha=0.1$. Further details of model architecture, loss function and training methodology are provided in Methods.  

\begin{figure}[!ht]
    \centerline{\includegraphics[scale=0.15]{images/GBMLGG_image.png}}
    \caption{\textbf{Explainability analysis on TCGA-GBMLGG data}. (a) whole slide image (WSI) (b) intra-tumour gradation heterogeneity (c) intra-tumour survival heterogeneity (d) co-attention maps for real and synthesized transcriptomic data and WSI patches for different gene groups (e) comparative study of intra-tumour heterogeneity and corresponding co-attention maps obtained for prediction using synthesized transcriptomic data for chosen regions marked with different coloured rectangles. }
    \label{fig_gbmlgg}
\end{figure}



\subsection{Similarity evaluation of synthesized and real transcriptomic data}
\label{sec_realness}
The transcriptomic data synthesized by our model, PathGen, is compared to the real patient transcriptomes to assess similarity. The Spearman correlation between real and synthesized transcriptomic features comprising all genes evaluates to 0.71 for TCGA-GBMLGG ($p-value = 1.18\times10^{-67}$) and 0.72 ($p-value = 3.65\times10^{-69}$) for TCGA-KIRC, and the mean absolute error (MAE) evaluates to 0.1 for both cohorts (Figures \ref{fig_res}.a.i, \ref{fig_res}.b.i and supplementary Table \ref{result_trans}). The gene expression levels for the gene groups show no significant differences between real and synthesized transcriptomes, for both cohorts (unpaired $t$-test $p$-value $>0.05$, supplementary Table \ref{result_trans}). Though there exists a high correlation and low MAE between synthetic and real transcriptomic data, there is some variation across the gene sets (Figures \ref{fig_res}.a.i, \ref{fig_res}.b.i and supplementary Table \ref{result_trans}). Notably, synthesized and real oncogene expression levels are highly correlated across both cohorts (Figures \ref{fig_res}.a.i, \ref{fig_res}.b.i). This is particularly beneficial for cancer grading or survival estimation as oncogenes when aberrantly active can serve as biomarkers that drive tumour progression, facilitating the prediction of cancer prognosis \cite{oncogenes}. Thus we conclude that the synthesized transcriptomic data are highly correlated with the real transcriptomic data and we gain confidence towards using the former in the predictive pipeline.



\subsection{Performance evaluation of synthesized transcriptomic data in multimodal prediction}
\label{sec_mainres}
\subsubsection{Adding synthesized transcriptomic features with digital histopathology improves prediction}
\label{sec_trans_imp}
We next analyse whether PathGen synthesised transcriptomes significantly add value to automated gradation and survival risk estimation, over and above whole slide images (WSIs) alone. Evaluation metrics used for grade prediction and survival risk estimation are the Area Under Curve (AUC) and the concordance index (C Index) respectively. Using WSIs alone we obtain an AUC of 0.823 (gradation) and C Index of 0.842 (survival risk) for TCGA-GBMLGG and an AUC of 0.714 (gradation) and a C Index of 0.671 (survival risk) for TCGA-KIRC (Figures \ref{fig_res}.a.ii, \ref{fig_res}.b.ii). The performance significantly improves when PathGen synthesized transcriptomics are used alongside WSIs (Wilcoxon rank-sum test $p$-value $<0.05$), resulting in an AUC of 0.890 (gradation) and C Index of 0.861 (survival risk) for TCGA-GBMLGG and an AUC of 0.773 (gradation) and C Index of 0.681 (survival risk) for TCGA-KIRC (Figures \ref{fig_res}.a.ii, \ref{fig_res}.b.ii). Thus, in the absence of real transcriptomic data, adding synthesized transcriptomic data significantly improves diagnostic and prognostic predictions compared to using only WSI features.



\subsubsection{Comparison of predictive performance of synthesized and real transcriptomic data}
We next compare gradation and survival risk predictions based on WSIs and PathGen synthesized transcriptomic data to predictions based on WSIs and real transcriptomic data. Combining real transcriptomic data with WSIs yields an AUC of 0.907 (gradation) and C Index of 0.866 (survival risk) for TCGA-GBMLGG and an AUC of 0.778 (gradation) and C Index of 0.697 (survival) for TCGA-KIRC (Figures \ref{fig_res}.a.ii, \ref{fig_res}.b.ii) and the corresponding result using synthesized transcriptomic data is provided in Section \ref{sec_trans_imp}. Remarkably, model performance using real transcriptomic data is not significantly different to using PathGen synthesized transcriptomes (Wilcoxon rank-sum test $p$-value $>$ 0.05) for both gradation and survival risk estimation, in both TCGA cohorts (supplementary Tables \ref{result_grade}, \ref{result_risk}). Thus, the transcriptomic data synthesized by our model, PathGen, performs comparably for gradation and survival risk estimation with no significant difference on average from real transcriptomic data.

\subsubsection{Comparison with state-of-the-art methodologies}
We also compare the performance of our methodology with the state-of-the-art models for using real transcriptomic data and WSI patches. For TCGA-GBMLGG, the C Index evaluated for GSCNN \cite{GSCNN} is 0.781, DeepAttnMISL \cite{DeepAttnMISL} is 0.734, MCAT \cite{mcat} is 0.817, Pathomic fusion \cite{pathomic} is 0.826 whereas our methodology yields a C Index of 0.866 using real transcriptomic data and a C Index of 0.861 using synthesized transcriptomic data for survival risk estimation. PathoGen-X \cite{PathoGen_X} obtains a C-Index of 0.81 on TCGA-GBM cohort, however their inference stage is unimodal and only considers a section of patients (Grade IV).  For gradation, Pathomic fusion \cite{pathomic} has an AUC of 0.906 whereas our methodology has an AUC of 0.907 on real transcriptomic data and an AUC of 0.890 on synthesized transcriptomic data. For TCGA-KIRC, the C Index evaluated for Pathomic fusion \cite{pathomic} is 0.720 whereas for our methodology is 0.697 on real transcriptomic data and 0.681 on synthesized transcriptomic data. However, Pathomic fusion uses ROIs annotated by expert pathologists for predicting grades, while we use transcriptomic features to co-attend to the WSI patch embeddings without requiring any expert intervention, thus reducing expert annotation overheads. We could only compare our model with Pathomic fusion for TCGA-GBMLGG gradation and TCGA-KIRC survival risk estimation as other models did not report the respective performances. Since our model performs better or at least comparably with the state-of-the-art models using real transcriptomic data, and we observe that the predictive performance between using real or synthesized transcriptomic data is very close with no significant difference for the test set population (Wilcoxon rank-sum test $p$-value $>0.05$, supplementary Tables \ref{result_grade}, \ref{result_risk}), we may conclude that we achieve state-of-the-art performance using gene expression levels synthesized by our model, PathGen. 


\begin{figure}[!ht]
    \centerline{\includegraphics[scale=0.15]{images/KIRC_image.png}}
    \caption{\textbf{Explainability analysis on TCGA-KIRC data}. (a) whole slide image (WSI) (b) intra-tumour gradation heterogeneity (c) intra-tumour survival heterogeneity (d) co-attention maps for real and synthesized transcriptomic data and WSI patches for different gene groups (e) comparative study of intra-tumour heterogeneity and corresponding co-attention maps obtained for prediction using synthesized transcriptomic data for chosen regions marked with different coloured rectangles. }
    \label{fig_kirc}
\end{figure}

\subsection{Transparency evaluation for clinical interpretability}
\label{sec_disres}
\subsubsection{Visualization of intra-tumour heterogeneity using synthesized transcriptomic data}
To visualize intra-tumour heterogeneity, we use our trained model to predict grade and survival risk for individual WSI patches independently, in a distributed manner, allowing identification of regions of varied grade/survival risk importance within a single WSI (Figures \ref{fig_gbmlgg}.b, \ref{fig_kirc}.b and supplementary Figures \ref{fig_gbmlgg1}.b, \ref{fig_kirc1}.b) and survival estimates (Figures \ref{fig_gbmlgg}.c, \ref{fig_kirc}.c and supplementary Figures \ref{fig_gbmlgg1}.c, \ref{fig_kirc1}.c). Illustrative images are shown for patients of ground truth grade III, survival time 10.71 months, survival status alive (Figure \ref{fig_gbmlgg}); ground truth grade IV, survival time 26.08 months, survival status deceased (supplementary Figure \ref{fig_gbmlgg1}) belonging to TCGA-GBMLGG, and for patients of ground truth grade I, survival time 33.99 months, survival status deceased (Figure \ref{fig_kirc}); ground truth grade II, survival time 22.78 months, survival status alive (supplementary Figure \ref{fig_kirc1}) belonging to TCGA-KIRC. Some regions of interest are highlighted by bounding boxes of colours green, cyan and blue. It is evident that higher-grade regions are correlated to higher risks, as is expected (Figure \ref{fig_kirc}.e). We find that considering WSIs at higher resolution helps to obtain more precise predictions for tissue regions, by obtaining distributed predictions at different magnification levels corresponding to a WSI, as is expected (supplementary Figure \ref{fig_mag}).

Further, we consider the aggregate of the heterogenous (distributed) predictions and compare it with the grade and survival risk predicted by the model considering all WSI patches as input (non-distributed predictions). For TCGA-GBMLGG, the distributed performance is not significantly different to a one-time prediction with all WSI patches (ANOSIM test jointly over gradation and survival risk estimation $p$-value $>$ 0.05, Figure \ref{fig_res}.a.iii). However, for TCGA-KIRC, performing distributed prediction improves the performance significantly (ANOSIM test jointly over gradation and survival risk estimation $p$-value $<$ 0.05, Figure \ref{fig_res}.b.iii). Thus we see from the results that there is indeed a distributed variation of grade and risk when predicted locally for patches and mapped onto the WSIs as a heatmap, both within and across cohorts, which may provide a visual insight to the human expert regarding cancer heterogeneity. 

\subsubsection{Visualisation of how transcriptomic data map to histopathology images}
To add explainability, we compare the co-attention maps between transcriptomic data and the corresponding WSI patches, obtained using real and synthesized gene expression levels. TCGA-GBMLGG obtains a Spearman correlation of 0.939 and MAE of 2.07 and TCGA-KIRC obtains a Speraman correlation of 0.851 and MAE of 0.59 (Figures \ref{fig_res}.a.iv, \ref{fig_res}.b.iv and supplementary Table \ref{result_coattn}). A higher correlation with a high corresponding MAE would denote that the range of co-attention values is large for the particular gene group but the co-attention map is still correlated. For both cohorts, co-attention maps attributing to oncogenes are most correlated followed by tumour suppressor genes and transcription factor genes (Figures \ref{fig_res}.a.iv, \ref{fig_res}.b.iv and supplementary Table \ref{result_coattn}). Oncogenes usually drive cell division and survival, thus promoting cancer, inactivation of tumour suppressor genes can lead to cancer by failing to regulate uncontrolled cell growth \cite{hallmark}, so the general co-attention observations above are not unexpected, although a rigorous inference would need a detailed analysis of gene set functional significance, which is outside the scope of this work. 

Further, we study the contribution of synthesized transcriptomic features in co-attending to the WSI patch embeddings. We observe that there are variances in the percentage contribution of individual gene groups in co-attention across both cohorts (Figures \ref{fig_res}.a.v,\ref{fig_res}.b.v). For both cohorts, the transcription factor genes and oncogenes have the highest co-attention values with the WSI patches for both real and synthesized gene expression levels and hence contribute the most to the prediction (Figures \ref{fig_gbmlgg}.d, \ref{fig_res}.a.v, \ref{fig_kirc}.d, \ref{fig_res}.b.v and supplementary Figure \ref{fig_gbmlgg1}.d, \ref{fig_kirc1}.d). Activation of oncogenes is known to drive tumour proliferation \cite{oncogenes}, hence having these as one of the higher contributors to co-attention would be aligned with clinical expectations.

We next visualise specific regions of the WSI and compare the distributed grades, distributed risk and the co-attention maps between synthesized transcriptomic features and the WSI patches (Figures \ref{fig_gbmlgg}.e, \ref{fig_kirc}.e and supplementary Figure \ref{fig_gbmlgg1}.e, \ref{fig_kirc1}.e). We observe that ground truth grade regions correspond to intermediate to high attention scores of transcription factors, and lower-grade regions are highly related to low attention values, as evident from the regions highlighted by the blue bounding box (Figures \ref{fig_gbmlgg}.c, \ref{fig_kirc}.c). 


\begin{figure} [!ht]
    \centerline{\includegraphics[scale=0.142]{images/GBMLGG_unc.png}}
    \caption{\textbf{Uncertainty quantification on the TCGA-GBMLGG dataset.} (a) Performance of survival risk estimation and gradation for various demographic groups using real and synthesized transcriptomic data. (i) comparison between prediction using real and synthesized data (ii) performance for age groups (iii) performance for gender categories (iv) performance for survival status (censorship) categories (b) Plot of overall prediction results for fairness evaluation.}
    \label{fig_gbmlgg_res}
\end{figure}


\subsection{Uncertainty quantification for clinical reliability}
\label{sec_uncres}
\subsubsection{Quantifying uncertainty}

We observe that the uncertainty profile of using synthesized transcriptomic data matches with that of using real transcriptomic data for gradation and survival risk estimation, for different patient demographics and stratification across both cohorts, by performing conformal prediction (CP) as described in Methods. For the entire test set population in TCGA-GBMLGG cohort, gradation uncertainty increases from 0.407 to 0.413 when synthesized data is used and the survival risk estimation uncertainty reduces from 0.446 to 0.438 (Figure \ref{fig_gbmlgg_res}.a.i). For TCGA-KIRC, gradation uncertainty increases from 0.292 to 0.334 and the survival risk uncertainty increases from 0.898 to 0.909 (Figure \ref{fig_kirc_res}.a.i). However, the changes in uncertainty are not significant proving the similarity in uncertainty profile (Wilcoxon rank-sum test $p$-value $>0.05$, supplementary Tables \ref{result_grade}, \ref{result_risk}). Similarly for the different demographic groups for both cohorts, the uncertainty profile remains similar for real and synthesized transcriptomic data with no significant difference in uncertainty (Wilcoxon rank-sum test $p$-value $>0.05$, supplementary Tables \ref{result_grade}, \ref{result_risk}). It is observed that for a few population groups across both cohorts, the required coverage has not been met, because of fewer samples in the calibration set. But for many such cases, using synthesized data has increased the coverage at the cost of an insignificant increase in uncertainty (Wilcoxon rank-sum test $p$-value $>0.05$, Figures \ref{fig_kirc_res}.a.i, \ref{fig_kirc_res}.a.ii). As risk estimation directly uses the transcriptomic data for prediction and not just for co-attention, such differences in obtained coverage are expected even for minimal differences in the gene expression levels between the synthesized and real transcriptomic features. Thus, the uncertainty estimates help to understand the extent to which we may rely on the predictions, like the survival risk bounds. Additionally, the cancer grade conformal sets provide a range of alternative grades to consider before making the final decision.

\begin{figure}[!ht]
    \centerline{\includegraphics[scale=0.136]{images/KIRC_unc.png}}
    \caption{\textbf{Uncertainty quantification on the TCGA-KIRC dataset.} (a) Performance of survival risk estimation and gradation for various demographic groups using real and synthesized transcriptomic data. (i) comparison between prediction using real and synthesized data (ii) performance for age groups (iii) performance for gender categories (iv) performance for survival status (censorship) categories (b) Plot of overall prediction results for fairness evaluation.}
    \label{fig_kirc_res}
\end{figure} 

\subsubsection{Fairness of predictions}
Next, we investigate algorithmic fairness, by assessing whether the uncertainty (normalised prediction set size) in gradation and survival risk predictions shows demographic biases. We observe that the predicted risk is less for patients who are reported to be alive and more for deceased patients, which is as expected (Figures \ref{fig_gbmlgg_res}.b, \ref{fig_kirc_res}.b). Also, the uncertainty of survival risk estimation decreases with increasing risk, which is expected because the actual survival time of patients who are alive is beyond the reported survival time. Thus the model estimated survival risk should correspond to a time beyond the reported survival time and have a higher uncertainty measure when compared in terms of reported survival time. It may also be observed that the model tends to correlate higher risks with the highest grade, grade IV, for both cohorts. However, the trend of gradation uncertainty is different for the two cohorts. For TCGA-GBMLGG, the uncertainty of grade prediction is more for grade III, least for grade IV, and intermediate for grade II (supplementary Table \ref{result_grade} and Figure \ref{fig_gbmlgg_res}.b). But for TCGA-KIRC, the uncertainty is less for grade I and grade II with low estimated survival risks but high for all other grades (supplementary Table \ref{result_grade} and Figure \ref{fig_kirc_res}.b). In general, the uncertainty of survival risk estimation is always greater if the survival time reported for a living patient is less (Figures \ref{fig_gbmlgg_res}.b, \ref{fig_kirc_res}.b). Also, the uncertainty of prediction for alive patients is always high, except for gradation for TCGA-KIRC (Figures \ref{fig_gbmlgg_res}.a.iv, \ref{fig_kirc_res}.a.iv). The uncertainty of grade prediction is more for male patients than females for both cohorts, whereas, for survival risk estimation, the uncertainty is more for females in TCGA-GBMLGG and males in TCGA-KIRC (Figures \ref{fig_gbmlgg_res}.a.iii, \ref{fig_kirc_res}.a.iii). The uncertainty of risk estimation decreases with age for both cohorts (Figures \ref{fig_gbmlgg_res}.a.ii, \ref{fig_kirc_res}.a.ii). For TCGA-GBMLGG, the uncertainty of grade prediction increases with decreasing magnification but remains similar for all magnification levels for TCGA-KIRC where magnification level 1 corresponds to the highest magnification and level 3 the lowest (supplementary Table \ref{result_grade}). Thus these results provide an analysis from a health equity and predictive fairness point of view as to how the performance varies across patient demographics.



\section{Methods}
\label{sec_methods}

The paper aims to use synthesized transcriptomic data for the automated selection of whole slide image (WSI) features for risk estimation and gradation of cancer cases. The proposed methodology is illustrated in Figure 1 of the main paper. The WSI is patchified and the corresponding patch embedding is obtained using UNI \cite{uni}. Our novel model, PathGen, generates transcriptomic features from the patch embeddings. Together the patch embeddings and the gene embeddings obtained from the transcriptomic features are thus used by MCAT\_GR for gradation and risk estimation. In the following subsections, we discuss the steps of the proposed methodology in detail.

\subsection{Preprocessing}
\label{sec_prepro}

\textbf{Histopathology data.} The diagnostic WSIs for a patient are divided into 224 $\times$ 224 patches, as required for obtaining patch embeddings using the pre-trained foundation model, UNI. The magnification level of the WSI is randomly chosen from the available options to make the model magnification level agnostic. The patches whose mean intensity normalized between 0 and 1 is more than 0.8 are excluded. It is observed that such patches consist mostly of the background region and hence, they do not contribute to the prediction. The 224 $\times$ 224 patches are provided as input to UNI to obtain the patch embeddings of dimension 1 $\times$ 1024. UNI \cite{uni} is a pre-trained vision encoder for histopathology developed using private datasets, and thus is not based on the public datasets used in our experiments.

\textbf{Transcriptomic data.} As proposed in MCAT \cite{mcat}, the corresponding transcriptomic data of the patient is divided into 6 broad categories of genes - tumour suppressor genes, oncogenes, protein kinases, cell differentiation markers, transcription factors, and cytokines and growth factors. The gene expression levels are z-score normalized if already not done. Our model, PathGen, is trained to synthesize such transcriptomic data from the corresponding WSI. Embeddings of dimension 1 $\times$ 1024 are obtained for the gene expression levels of each category using the gene encoders. 

\begin{figure} [!ht]
    \centerline{\includegraphics[scale=0.262]{images/P2G_model.png}}
    \caption{\textbf{Model Architecture}. (a) Architecture of our novel diffusion model, PathGen, used for synthesizing gene expression levels from histopathology images. (b) Architecture of the modified MCAT model for gradation and risk estimation, MCAT\_GR. (c) Detailed architecture of PathGen transformer. (d) Architecture of gene encoder that converts gene expression level to gene embeddings. (e) Representation of genomic-guided co-attention function. (f) Architecture of gene decoder that converts gene embeddings back to gene expression levels.}
    \label{fig_model}
\end{figure}

\subsection{Synthesizing transcriptomic data from histopathology images}
\label{sec_PathGen}
\subsubsection*{Background of diffusion}
\label{sec_backdiff}
The process of diffusion is represented as a Markov chain where in the forward process noise is added in each step to degrade the the data for a predetermined timestep $T$ \cite{sohl2015deep}. Diffusion models are trained to predict the noise introduced in each step from a noisy sample. In the reverse process, the noise is given as input to the diffusion model and denoising is performed for $T$ timesteps to obtain the synthesized data \cite{ho2020denoising}.

The forward process begins with a data sample $\mathbf{x}_0$ and gradually adds Gaussian noise at each timestep $t$ \cite{song2020score} following the equation,
\begin{equation}
    q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1 - \beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I}),
\end{equation}
where $\beta_t$ is a predefined noise variance schedule. For any given timestep $t$, the sample $\mathbf{x}_t$ is obtained directly from the initial data $\mathbf{x}_0$ as per the following equation,
\begin{equation}
    q(\mathbf{x}_t | \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1 - \bar{\alpha}_t) \mathbf{I}),
\end{equation}
where $\bar{\alpha}_t = \prod_{s=1}^t (1 - \beta_s)$ \cite{ho2020denoising}. This simplifies to the equation,
\begin{equation}
    \mathbf{x}_t = \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon,
\end{equation}
with $\epsilon \sim \mathcal{N}(0, \mathbf{I})$.

The reverse process aims to denoise the sample back to the ground truth data. A learnable model is used to predict the noise at each step to obtain the sample $\mathbf{x}_{t-1}$ from $\mathbf{x}_t$ \cite{song2020score}.
\begin{equation}
    p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \mu_\theta(\mathbf{x}_t, t), \sigma_\theta(\mathbf{x}_t, t)),
    \label{equ_diffinf}
\end{equation}
where $\mu_\theta$ and $\sigma_\theta$ are learned parameters and given the following equations, 
\begin{equation}
    \mu_\theta(\mathbf{x}_t, t) := \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t, t) \right),
\end{equation}
\begin{equation}
    \sigma_\theta(\mathbf{x}_t, t) := \tilde{\beta}_t^{\frac{1}{2}}, \quad t \in \{T, T-1, \dots, 1\}.
\end{equation}

The model is trained to minimize the difference between the true noise $\epsilon$ and the predicted noise $\epsilon_\theta$ using the simplified equation,
\begin{equation}
    L_{diff} = \mathbb{E}_{t, \mathbf{x}_0, \epsilon} \left[ \|\epsilon - \epsilon_\theta(\mathbf{x}_t, t)\|^2 \right].
    \label{equ_diffloss}
\end{equation}



\subsubsection{Architecture of PathGen}
\label{sec_archdiff}
The architecture of our model, PathGen, to generate transcriptomic features from whole slide images is illustrated in Figure \ref{fig_model}.a with further details in Figures \ref{fig_model}.c, \ref{fig_model}.d, \ref{fig_model}.e and \ref{fig_model}.f. To obtain the transcriptomic features at a timestep $t-1$, $\mathbf{x}_{t-1}$, the transcriptomic features at timestep $t$ and the WSI path embeddings are provided as input. The process is performed for T timesteps, where $\mathbf{x}_{T}$ is noise and $\mathbf{x}_{0}$ is the synthesized transcriptomic data. The embedding of the gene expression levels in the transcriptomic data at $\mathbf{x}_{t}$ is obtained using the gene encoder consisting of four linear layers with ELU activation as illustrated in Figure \ref{fig_model}.d. The gene embedding and the corresponding patch embedding obtained using UNI \cite{uni} goes as input to the PathGen transformer, illustrated in Figure \ref{fig_model}.c. The PathGen transformer comprises genomic-guided co-attention illustrated in Figure \ref{fig_model}.e., proposed in MCAT \cite{mcat}, and the transformer encoder layers \cite{attention}. Genomic-guided co-attention is inspired by the self-attention introduced in transformer \cite{attention}. The gene embeddings attend to the WSI embeddings to produce co-attended embeddings which comprises of the most relevant combined features learned while training. Co-attention is performed thrice to ensure that the generated transcriptomic features have correspondence to the input WSI. Further, the transformer embeddings are decoded to gene expression levels using specific gene decoders for the different gene groups. The gene decoders comprise linear layers to ELU activation except the last, as illustrated in Figure \ref{fig_model}.f.

\subsubsection{Training and inference}
\label{sec_traindiff}
Algorithm \ref{algo_train} gives the training algorithm. The model is trained with the loss function in equation \ref{equ_diffloss} for $T=1000$ timesteps with a learning rate of $1\times10^{-4}$. For training a sample is considered at a random intermediate timestep $t$ sampled uniformly. Algorithm \ref{algo_inference} specifies the inference algorithm. The inference is performed for $T=1000$ timesteps by initially providing random noise sampled from mean zero, unit variance Gaussian distribution as input using equation \ref{equ_diffinf}.

\begin{algorithm}
\caption{PathGen Training}
\begin{algorithmic}
    \Repeat
        \State $\mathbf{x}_0 \sim q(\mathbf{x}_0)$
        \State $t \sim \text{Uniform}(\{1, \dots, T\})$
        \State $\epsilon \sim \mathcal{N}(0, \mathbf{I})$
        \State Take gradient descent step on $\nabla_\theta \| \epsilon - \epsilon_\theta(\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t) \|^2$
    \Until{converged}
\end{algorithmic}
\label{algo_train}
\end{algorithm}

\begin{algorithm}
\caption{PathGen Inference}
\begin{algorithmic}
    \State $\mathbf{x}_T \sim \mathcal{N}(0, \mathbf{I})$
    \For{$t = T, \dots, 1$}
        \State $\mathbf{z} \sim \mathcal{N}(0, \mathbf{I})$ if $t > 1$, else $\mathbf{z} = 0$
        \State $\mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(\mathbf{x}_t, t) \right) + \sigma_t \mathbf{z}$
    \EndFor
    \State \textbf{return} $\mathbf{x}_0$
\end{algorithmic}
\label{algo_inference}
\end{algorithm}

\subsection{Gradation and risk estimation}
\label{sec_gradrisk}
The synthesized transcriptomic data using our model, PathGen, along with the corresponding WSIs is used for gradation and risk estimation, using the model MCAT\_GR.

\subsubsection{Architecture}
\label{sec_mcatarch}
The architecture used for gradation and risk estimation using multi-modal histopathology and synthesized transcriptomic data is MCAT \cite{mcat} with an additional pipeline for gradation. The modified MCAT architecture, MCAT\_GR, is illustrated in Figure \ref{fig_model}.b. The co-attended features processed using the pathomic transformer of MCAT\_GR are used for gradation by passing through a separate global attention pooling. However, transcriptomic feature embeddings from the gene transformer are not used directly for gradation as we experiment to see that not including the transcriptomic data for grade prediction performs better. The global attention pooling performed for risk estimation and gradation are separate to decrease the dependency between the grade and risk. 

\subsubsection{Training details}
The loss used for training gradation is binary cross entropy loss \cite{bce}, $L_{grade}$, and the loss used for training risk estimation is negative log-likelihood survival loss \cite{mcat}, $L_{risk}$. Thus, the total loss for MCAT\_GR is given by the equation,
\begin{equation}
    L_{MCAT_GR} = \lambda \times L_{grade} + (1-\lambda) \times L_{risk}
    \label{equ_mcatloss}
\end{equation}
where $\lambda$ is a hyperparameter to control the contribution of gradation and survival loss in the training. The learning rate used is $2 \times 10^{-4}$. 

\subsection{Conformal Prediction and uncertainty estimation}
\label{sec_cp}
\subsubsection*{Conformal for gradation}
\label{sec_cpgrade}
Conformal prediction is performed for gradation to provide the clinicians with a calibration set of the most probable grade options. Marginal conformal prediction ensures that the coverage of prediction obtained for a population is more than $1-\alpha$, where $\alpha$ is a chosen error rate \cite{conformal}. The conformal condition for gradation is given by the equation,
\begin{equation}
    1 - \alpha \leq \probP{\,(Y_{test} \in C(X_{test})) }
    \label{equ_cov_grad}
\end{equation}
where $C$ represents the conformal set consisting of probable prediction classes to gain the desired coverage of at least $1-\alpha$. Algorithm \ref{algo_cpgrade} specifies the procedure for performing conformal gradation \cite{conformal}. The uncertainty for gradation is computed using the conformal set by the equation, 
\begin{equation}
    uncertainty = \frac{|C|}{N} \times \frac{\Delta_{max}}{N-1}
    \label{equ_unc_grad}
\end{equation}
where $|C|$ represents the cardinality of the conformal set, $N$ represents the number of classes and  $\Delta_{max}$ stands for the maximum difference between the classes in the conformal set. 

\begin{algorithm}
\caption{Conformal prediction for gradation}
\begin{algorithmic} [!ht]
    \State \textbf{Input:} Calibration samples \( \{ \mathbf{x}_i, y_i \}_{i=1}^{n} \), error rate \( \alpha \) \Comment{$y_i$ is the true grade}
    
    \State \textbf{Step 1:} Compute conformal scores:
    \For{each calibration sample \( i \)}
        \State $\text{score}_i \gets 1 - p_{i_{y_i}}$ \Comment{where \( p_{i_{y_i}} \) is the predicted probability of the true class $y_i$}
    \EndFor

    \State \textbf{Step 2:} Compute adjusted quantile:
    \State $q \gets \frac{\lceil (n + 1) \cdot (1 - \alpha) \rceil}{n}$
    \State $\hat{q} \gets \text{quantile}(\{\text{score}_i\}, q)$

    \State \textbf{Step 3:} Form calibration sets:
    \For{each test sample}
        \If{$p_j \geq 1 - \hat{q}$} 
            \State \text{Include class \( j \) in the calibration set} \Comment{where $p_j$ is the predicted probability of the sample belonging to class $j$}
        \EndIf
    \EndFor

\end{algorithmic}
\label{algo_cpgrade}
\end{algorithm}

\begin{algorithm}
\caption{Conformal prediction for risk estimation}
\begin{algorithmic} [!ht]
    \State \textbf{Input:} Calibration samples \( \{ \mathbf{x}_i, r_i \}_{i=1}^{n} \), error rate \( \alpha \) \\
    \Comment{$r_i$ is the upper bound risk of the true time bin representing maximum risk}
    
    \State \textbf{Step 1:} Compute conformal scores:
    \For{each calibration sample \( i \)}
        \State $\text{score}_i \gets | r_i - risk_{est_i} | $ \Comment{where \( risk_{est_i} \) is the predicted risk }
    \EndFor

    \State \textbf{Step 2:} Compute adjusted quantile:
    \State $q \gets \frac{\lceil (n + 1) \cdot (1 - \alpha) \rceil}{n}$
    \State $\hat{q} \gets \text{quantile}(\{\text{score}_i\}, q)$

    \State \textbf{Step 3:} Form calibration sets:
    \For{each test sample} 
    \State    $ risk_{lb} \gets risk_{pred} - \hat{q} $ 
    \State    $ risk_{ub} \gets risk_{pred} + \hat{q} $ 
        \If{$ risk_{lb} \leq t_{lb} $ or $ t_{ub} \leq risk_{ub} $} 
            \State \text{Include time bin \( t \) in the calibration set} \\
            \Comment{where $t_{lb}$ and $t_{ub}$ are the lower bound and upper bound risks corresponding to time bin $t$}
        \EndIf
    \EndFor

\end{algorithmic}
\label{algo_cprisk}
\end{algorithm}

\subsubsection{Conformal for risk estimation}
\label{sec_cprisk}
Conformal prediction is performed to estimate the upper and lower bounds of the predicted risk. The marginal conformal condition for risk estimation is given by the equation,
\begin{equation}
    1 - \alpha \leq \probP{\,( risk_{lb} \le risk_{est} \le risk_{ub})}
    \label{equ_cov_risk}
\end{equation}
where $risk_{est}$ is the estimated risk, and $risk_{lb}$ and $risk_{ub}$ are the lower and upper bound of risks obtained from conformal prediction. For risk estimation, the survival time in months is divided into 4 time bins. The time bins covered between the lower and upper bound of the risk give the conformal set $C$. Algorithm \ref{algo_cprisk} mentions the detailed procedure for conformal risk estimation \cite{conformal}. The uncertainty for risk estimation is further computed as,
\begin{equation}
    uncertainty = \frac{|C|}{N} \times \frac{|risk_{ub} - risk_{lb}|}{(-1) - (-5)}
    \label{equ_unc_risk}
\end{equation}
where N=4, the number of time bins, -1 is the highest possible risk and -5 is the lowest possible risk score.

\section{Discussion}
\label{sec_discussion} 

Here we present PathGen, a crossmodal generative diffusion model for synthesizing transcriptomic features from WSIs of H$\&$E stained slides. We demonstrated that PathGen synthesized transcriptomic features are highly correlated to true patient transcriptomes. By using a multimodal AI model to predict cancer grade and survival risk from WSIs and transcriptomic features, with state-of-the-art performance, we demonstrated that combining the features learnt from WSIs using a vision transformer based foundation model with the synthesized transcriptomic features from PathGen, significantly improved predictive accuracy compared to WSIs alone. Remarkably, we found that there was no significant difference in accuracy when real patient transcriptomic data were used instead of PathGen synthesized transcriptomic data in the multimodal model, demonstrating that PathGen captures the independent gradation/prognostic information in true patient gene expressions.

H$\&$E stained slides of tumour tissue are essential for diagnostic and prognostic assessment of malignancy, and are collected routinely. However, transcriptomic tests, though they have the potential to inform prognosis and guide treatment selection \cite{chemo, preci} are not routinely performed, especially in the public sector \cite{cost}. This is due to a number of reasons, including economic cost, infrastructural requirements and incomplete knowledge about patient benefit. PathGen can synthesize realistic and informative patient transcriptomic features, from routine and inexpensive WSIs of H$\&$E stained slides. Thus in the future, we envision that PathGen can be studied as a low cost screening tool, to guide the targeted collection of transcriptomic data modalities, by potentially selecting patients who would benefit from transcriptomic assessment for more accurate diagnosis/prognosis. This would of course need a dedicated follow up study which would include patient response to treatment when selected in this manner, that would entail a separate clinical validation project. 

For PathGen to be useful in clinic, it must be trusted. To facilitate this trust we have undertaken two measures. Firstly, by employing co-attention tools for model transparency, we map gradation and survival risk estimates back onto the WSI images in a distributed manner. This has provided a window into intra-tumour heterogeneity, and can highlight cases where whole slide assessment and distributed assessment of tumour grade may differ. Secondly, we have employed conformal prediction for assessment of model reliability, providing not simply point estimates for gradation and survival risk, but ranges which contain true values with a specified certainty. This analysis has also allowed us to assess model fairness, by comparing model reliability across patient demographics such as age and gender. Importantly, we found that there was no significant difference in model reliability or fairness when using PathGen synthesized transcriptomic features compared to real patient transcriptomes. For reproducibility of research and ethos of open science, we have made the code fully available online through our GitHub repository at \url{https://github.com/Samiran-Dey/PathGen}.

Our initial results are based on assessment of two publicly available cancer datasets from TCGA, describing glial and renal tumours. Though it is encouraging that PathGen shows state-of-the-art performance across diverse tumour types, further assessment in other malignancies and in independent datasets, would expand the remit of our results. PathGen is able to reliably synthesize transcriptomic embeddings, describing 6 distinct gene sets. Though these gene sets (both synthesized and real) contain important diagnostic/prognostic information, they do not capture the full diversity of the transcriptome. There is likely a limit to how much of the full transcriptome can be synthesized from only knowledge of WSIs, and hence we do not claim that PathGen replaces the need for real transcriptomic data, but rather it provides a potential way of estimating the benefit of collecting the full data across the population. The increasing use of techniques such as spatial transcriptomics \cite{spatial} will provide insight into this question, as well as WSI patch level resolution of transcriptomics, to guide development of synthesized transcriptomic data with a greater number of features in the near future.

\section*{Acknowledgment}
The authors declare no conflict of interest. S Dey is funded by the IIT KGP AI4ICPS Chanakya Fellowship. P Basuchowdhuri is supported by the Indo-Swedish DBT-Vinnova project, BT/PR41025/Swdn/135/9/2020, for supporting this research. CRSB was supported by the CRUK City of London Centre Award [CTRQQR-2021/100004]. T Chakraborti is supported by the Turing-Roche Strategic Partnership. We are grateful to Prof Benjamin MacArthur from the Alan Turing Institute and Mr. Chris Harbron from Roche Pharmaceuticals for their insightful comments and constructive feedback throughout this project.

\bibliography{main.bib}
%\bibliography{main.bbl}

\newpage

\section*{Supplementary Material}

\begin{table}[!ht]
\centering
\caption{\label{result_gen_use} Table of results for evaluation of the use of synthesized transcriptomic data for grade and survival prediction in four different setting 1) We do not use transcriptomic data at all and attend to the WSI patches randomly; 2) We use the gene expression levels only to co-attend to the WSI patch embeddings; 3) We use the transcriptomic embeddings collectively with co-attended WSI features for survival risk estimation only; 4) We use transcriptomic features for co-attending to WSI patches, and then use the transcriptomic embeddings along with the co-attended features for performing both survival risk estimation and gradation. Setting 3 gives the best mean AUC and C Index for gradation and survival risk estimation across both data cohorts. Further, ANOSIM test for combined risk estimation and gradation between the two cases suggested that the difference in performance between all the cases is significant (p-value $< 0.05$). Thus, the architecture of our model is aligned to setting 3. \textuparrow \ indicates the larger the better. Best mean scores are marked in \textbf{bold}. \\}

\begin{tabular}{|c||c|c||c|c||c|c||c|c|}
\hline
~  & \multicolumn{2}{ c ||}{Setting 1} & \multicolumn{2}{ c ||}{Setting 2} & \multicolumn{2}{ c ||}{Setting 3} & \multicolumn{2}{ c |}{Setting 4} \\ 
~  & \multicolumn{2}{ c ||}{random (not used)} & \multicolumn{2}{ c ||}{only co-attention} & \multicolumn{2}{ c ||}{co-attention, risk} & \multicolumn{2}{ c |}{co-attention, risk, grade} \\ \hline
                & Risk      & Grade & Risk         & Grade & Risk               & Grade & Risk                      & Grade \\
 $\lambda$ & C Index \textuparrow & AUC \textuparrow   & C Index \textuparrow      & AUC \textuparrow   & C Index \textuparrow            & AUC \textuparrow   & C Index \textuparrow                   & AUC \textuparrow   \\ \hline \hline
\multicolumn{9}{| c |}{TCGA - GBMLGG}  \\ \hline
0.1 & 0.835 & 0.829 & 0.843 & 0.878 & 0.863 & 0.884 & 0.848 & 0.868 \\
0.2 & 0.832 & 0.863 & 0.872 & 0.869 & 0.852 & 0.895 & 0.864 & 0.809 \\
0.3 & 0.842 & 0.823 & 0.849 & 0.886 & 0.861 & 0.890 & 0.859 & 0.849 \\
0.4 & 0.844 & 0.828 & 0.857 & 0.885 & 0.864 & 0.886 & 0.858 & 0.829 \\
0.5 & 0.856 & 0.847 & 0.861 & 0.890 & 0.846 & 0.864 & 0.830 & 0.844  \\
0.6 & 0.847 & 0.873 & 0.865 & 0.877 & 0.847 & 0.883 & 0.820 & 0.733 \\
0.7 & 0.861 & 0.836 & 0.865 & 0.867 & 0.855 & 0.888 & 0.879 & 0.843 \\
0.8 & 0.862 & 0.745 & 0.857 & 0.856 & 0.836 & 0.811 & 0.808 & 0.731 \\
0.9 & 0.850 & 0.810 & 0.852 & 0.801 & 0.845 & 0.809 & 0.801 & 0.724 \\ \hline
mean & 0.843 & 0.820 & 0.848 & 0.839 & \textbf{0.854} & \textbf{0.847} & 0.825 & 0.796 \\ \hline
\hline
\multicolumn{9}{| c |}{TCGA - KIRC} \\ \hline 
0.1 & 0.626 & 0.729 & 0.666 & 0.713 & 0.703 & 0.773 & 0.576 & 0.741 \\
0.2 & 0.709 & 0.713 & 0.658 & 0.768 & 0.650 & 0.778 & 0.516 & 0.735 \\
0.3 & 0.671 & 0.714 & 0.688 & 0.763 & 0.681 & 0.773 & 0.548 & 0.746 \\
0.4 & 0.701 & 0.712 & 0.701 & 0.770 & 0.675 & 0.772 & 0.513 & 0.740  \\
0.5 & 0.662 & 0.770 & 0.605 & 0.766 & 0.658 & 0.769 & 0.509 & 0.747  \\
0.6 & 0.672 & 0.763 & 0.654 & 0.767 & 0.667 & 0.763 & 0.516 & 0.743  \\
0.7 & 0.677 & 0.739 & 0.673 & 0.768 & 0.643 & 0.760 & 0.512 & 0.750 \\
0.8 & 0.708 & 0.763 & 0.650 & 0.774 & 0.613 & 0.765 & 0.551 & 0.753 \\
0.9 & 0.607 & 0.754 & 0.592 & 0.760 & 0.575 & 0.757 & 0.573 & 0.742 \\ \hline
mean & 0.617 & 0.742 & 0.629 & 0.737 & \textbf{0.639} & \textbf{0.765} & 0.575 & 0.742 \\ \hline
\end{tabular}
\end{table}

\begin{figure}[!ht]
    \centerline{\includegraphics[scale=0.217]{images/lambda.png}}
    \caption{ \label{fig_lambda} \textbf{Ablation for $\lambda$.}  $\lambda=0$ and $\lambda=1$ correspond to the extreme cases of equation $L = \lambda \times L_{survival} + (1-\lambda) \times L_{grade}$ where the model is trained only using gradation loss and only using survival loss respectively. Using only gradation loss leads to poor performance of risk estimation when $\lambda=0$ and using only risk estimation loss leads to a poor gradation performance. Learning both grade and survival risk together helps the model to correlate between the two and learn better. This is expected as one of the losses essentially becomes unused, so we decide to ignore the extreme cases of $\lambda=0$ and $\lambda=1$. Also, we observe that for $\lambda=0.3$ the model reaches an optimal performance where both AUC and C Index scores are close and high together for both cohorts.}
\end{figure}



\begin{table}[!ht]
    \centering
    \caption{\label{result_trans}Table of results for comparison of synthesized and real transcriptomic features. The correlation coefficient is calculated using Spearman correlation. The p-values are evaluated by performing an unpaired T-test for the aggregate gene expression level of each group. \textuparrow \ indicates the larger the better and \textdownarrow \ indicates the smaller the better. A higher correlation with a high corresponding MAE would denote that the range of gene expression levels is large for the particular group.\\}
    %\resizebox{\textwidth}{!}{
    \begin{tabular}{|c||c|c|c||c|c|c|}
    \hline
        Dataset & \multicolumn{3}{ c ||}{TCGA - GBMLGG} & \multicolumn{3}{ c |}{TCGA - KIRC} \\ \hline 
        Gene type & MAE \textdownarrow & Correlation \textuparrow & p-value \textdownarrow & MAE \textdownarrow & Correlation \textuparrow & p-value \textdownarrow \\ \hline \hline
        Tumor Suppressor Genes & 0.137 & 0.472 & 4.32e-06 & 0.116 & 0.629 & 9.21e-69  \\ 
        Oncogenes & 0.085 & 0.770 & 8.05e-53 & 0.074 & 0.817 & 7.08e-54 \\ 
        Protein Kinases & 0.084 & 0.749 & 4.83e-79 & 0.078 & 0.785 & 6.48e-84 \\ 
        Cell Differentiation Markers & 0.069 & 0.724 & 8.55e-50 & 0.070 & 0.777 & 1.38e-53 \\ 
        Transcription Factors & 0.122 & 0.615 & 4.52e-47 & 0.117 & 0.666 & 6.107e-52  \\ 
        Cytokines and Growth Factors & 0.062 & 0.771 & 2.43e-66 & 0.095 & 0.610 & 2.48e-72 \\ \hline
        All genes & 0.098 & 0.713 & 1.18e-67 & 0.097 & 0.717 & 3.65e-69 \\ \hline
    \end{tabular}
    %}
\end{table}



\begin{figure} [!ht]
    \centerline{\includegraphics[scale=0.21]{images/Magnification.png}}
    \caption{ \label{fig_mag} \textbf{Predicted intra-tumour heterogeneity at different magnification levels} (a) A whole slide image (WSI) of ground truth grade II, survival time 62.62 months and alive survival status belonging to a male patient of 47 years. (b) A WSI of ground truth grade IV, survival time 54.61 months and dead survival status belonging to a 55 years old female patient. The WSIs belong to TCGA-KIRC. It is observed that for higher resolution images the distributed predictions are more accurate.}
\end{figure}

\begin{figure} [!ht]
    \centerline{\includegraphics[scale=0.16]{images/GBMLGG_image_1.png}}
    \caption{\textbf{Explainability analysis on TCGA-GBMLGG data}. (a) whole slide image (WSI) (b) intra-tumour gradation heterogeneity (c) intra-tumour survival heterogeneity (d) co-attention maps for real and synthesized transcriptomes and WSI patches for different gene groups (e) comparative study of intra-tumour heterogeneity and corresponding co-attention maps obtained for prediction using synthesized transcriptomes for chosen regions marked with different coloured rectangles. }
    \label{fig_gbmlgg1}
\end{figure}



\begin{figure} [!ht]
    \centerline{\includegraphics[scale=0.16]{images/KIRC_image_1.png}}
    \caption{\textbf{Explainability analysis on TCGA-KIRC data}. (a) whole slide image (WSI) (b) intra-tumour gradation heterogeneity (c) intra-tumour survival heterogeneity (d) co-attention maps for real and synthesized transcriptomes and WSI patches for different gene groups (e) comparative study of intra-tumour heterogeneity and corresponding co-attention maps obtained for prediction using synthesized transcriptomes for chosen regions marked with different coloured rectangles.  }
    \label{fig_kirc1}
\end{figure}


\begin{table}[!ht]
    \centering
    \caption{\label{result_coattn}Table of results for co-attention maps generated while using synthesized and real transcriptomic features. The correlation coefficient is calculated using Spearman correlation. \textuparrow \ indicates the larger the better and \textdownarrow \ indicates the smaller the better. A higher correlation with a high corresponding MAE would denote that the range of gene expression levels is large for the particular group.\\}
    %\resizebox{\textwidth}{!}{
    \begin{tabular}{|c||c|c|c|c||c|c|c|c|}
    \hline
        Dataset & \multicolumn{2}{ c ||}{TCGA - GBMLGG} & \multicolumn{2}{ c |}{TCGA - KIRC} \\ \hline
        Gene type & MAE \textdownarrow & Correlation \textuparrow & MAE \textdownarrow & Correlation \textuparrow \\ \hline \hline
        Tumor Suppressor Genes & 0.801 & 0.998 & 0.087 & 0.946 \\ 
        Oncogenes & 2.302 & 0.999 & 0.460 & 0.995 \\ 
        Protein Kinases & 2.526 & 0.894 & 0.429 & 0.881 \\ 
        Cell Differentiation Markers & 2.305 & 0.969 & 0.319 & 0.610 \\ 
        Transcription Factors & 1.973 & 0.997 & 1.865 & 0.990 \\ 
        Cytokines and Growth Factors & 2.505 & 0.531 & 0.387 & 0.404 \\ \hline
        All genes & 2.069 & 0.939 & 0.591 & 0.851 \\ \hline
    \end{tabular}
    %}
\end{table}

\begin{table}[!ht]
    \centering
    \caption{\label{result_grade} Table of results across various groups for grade prediction. p-values are computed using the Wilcoxon rank-sum test to compare the scores for grades predicted using real and synthesized transcriptomic data. \textuparrow \ indicates the larger the better and \textdownarrow \ indicates the smaller the better. Equivalent, better or close ($<0.01$) performance with synthesized data is marked in \textbf{bold}. \\}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|c||c|c|c|c|c|c|c|c|}
    \hline        
          ~ & \multicolumn{3}{ c |}{Real} & \multicolumn{3}{ c |}{Synthesized} & \multicolumn{2}{ c |}{p-value \textuparrow} \\ \hline
         Category  & AUC \textuparrow & uncertainty \textdownarrow & coverage \textuparrow & AUC \textuparrow & uncertainty \textdownarrow & coverage \textuparrow & grade & uncertainty \\ \hline \hline
        \multicolumn{9}{| c |}{Dataset: TCGA - GBMLGG} \\ \hline
        overall & 0.907 & 0.407 & 0.981 & 0.890 & 0.413 & 0.981 & 0.995 & 0.935 \\ \hline 
        male & 0.915 & 0.439 & 0.985 & 0.896 & \textbf{0.444 }& 0.985 & 0.975 & 0.920 \\ 
        female & 0.896 & 0.184 & 0.921 & \textbf{0.886} & 0.202 & 0.921 & 1.000 & 0.921 \\ \hline
        age $ < $ 40 years & 0.883 & 1.000 & 1.000 & 0.849 & \textbf{1.000} & 1.000 & 0.736 & 1.000 \\ 
        age from 40 to 60 years & 0.928 & 0.459 & 1.000 & \textbf{0.921} & \textbf{0.450} & 1.000 & 0.804 & 0.996 \\ 
        age $ > $ 60 years & 0.909 & 0.722 & 0.958 & \textbf{0.906} & \textbf{0.708} & 0.958 & 1.000 & 0.934 \\ \hline
        magnification 1 & 0.902 & 0.195 & 0.966 & 0.885 & \textbf{0.172} & 0.931 & 1.000 & 0.652 \\ 
        magnification 2 & 0.952 & 0.754 & 1.000 & 0.936 & \textbf{0.754} & 1.000 & 0.811 & 1.000 \\ 
        magnification 3 & 0.852 & 0.901 & 1.000 & 0.836 & \textbf{0.901} & 1.000 & 0.795 & 1.000 \\ \hline
        alive & 0.865 & 0.990 & 1.000 & 0.832 & \textbf{1.000} & 1.000 & 0.894 & 0.881 \\ 
        dead & 0.951 & 0.234 & 0.973 & \textbf{0.951} & \textbf{0.234} & 0.973 & 0.867 & 1.000 \\ \hline
        grade II & 0.914 & 0.547 & 0.974 & 0.891 & 0.598 & 0.974 & 0.704 & 0.569 \\ 
        grade III & 0.755 & 1.000 & 1.000 & 0.728 & \textbf{1.000} & 1.000 & 0.866 & 1.000 \\ 
        grade IV & 0.995 & 0.034 & 0.966 & \textbf{0.993} & \textbf{0.034} & 0.966 & 0.822 & 1.000 \\ \hline
        time bin 1 & 0.898 & 0.431 & 0.976 & 0.882 & \textbf{0.407} & 0.963 & 0.984 & 0.790 \\
        time bin 2 & 0.786 & 0.538 & 1.000 & \textbf{0.784} & \textbf{0.513} & 1.000 & 1.000 & 0.817 \\ 
        time bin 3 & 1.000 & 0.037 & 1.000 & \textbf{1.000} & 0.074 & 1.000 & 1.000 & 0.691 \\ \hline \hline
        \multicolumn{9}{| c |}{Dataset: TCGA - KIRC} \\ \hline
        overall & 0.778 & 0.292 & 0.922 & \textbf{0.773} & 0.334 & 0.948 & 0.850 & 0.068 \\ \hline
        male & 0.726 & 0.303 & 0.909 & \textbf{0.721} & 0.337 & 0.929 & 0.905 & 0.246 \\ 
        female & 0.864 & 0.278 & 0.963 & \textbf{0.864} & 0.336 & 0.981 & 0.878 & 0.123 \\ \hline
        age $ < $ 40 years & 0.963 & 0.056 & 1.000 & 0.852 & 0.111 & 1.000 & 0.513 & 0.513 \\ 
        age from 40 to 60 years & 0.780 & 0.393 & 0.976 & \textbf{0.778} & \textbf{0.389} & 0.964 & 1.000 & 0.894 \\ 
        age $ > $ 60 years & 0.770 & 0.295 & 0.879 & \textbf{0.761} & 0.318 & 0.894 & 0.886 & 0.521 \\ \hline
        magnification 1 & 0.784 & 0.369 & 0.980 & \textbf{0.780} & \textbf{0.337} & 0.961 & 1.000 & 0.393 \\ 
        magnification 2 & 0.780 & 0.317 & 0.961 & \textbf{0.774} & 0.376 & 0.980 & 0.867 & 0.125 \\ 
        magnification 3 & 0.771 & 0.337 & 0.941 & \textbf{0.769} & 0.363 & 0.941 & 0.867 & 0.495 \\ \hline
        alive & 0.826 & 0.239 & 0.931 & \textbf{0.822} & 0.288 & 0.951 & 0.905 & 0.076 \\ 
        dead & 0.661 & 0.402 & 0.922 & \textbf{0.656} & 0.428 & 0.941 & 0.880 & 0.495 \\ \hline
        grade I & 0.222 & 0.500 & 0.667 & 0.111 & \textbf{0.500} & 0.333 & 1.000 & 1.000 \\ 
        grade II & 0.987 & 0.016 & 0.905 & \textbf{0.978} & \textbf{0.000} & 0.873 & 0.880 & 0.878 \\ 
        grade III & 0.647 & 0.283 & 0.905 & \textbf{0.658} & 0.333 & 0.952 & 0.645 & 0.164 \\ 
        grade IV & 0.504 & 0.625 & 0.958 & \textbf{0.499} & \textbf{0.563} & 0.958 & 0.711 & 0.458 \\ \hline
        time bin 1 & 0.718 & 0.366 & 0.944 & \textbf{0.713} & 0.384 & 0.944 & 0.889 & 0.565 \\ 
        time bin 2 & 0.837 & 0.214 & 0.883 & 0.828 & \textbf{0.233} & 0.900 & 0.885 & 0.560 \\ 
        time bin 3 & 0.848 & 0.296 & 1.000 & \textbf{0.835} & 0.333 & 1.000 & 1.000 & 0.569 \\ 
        time bin 4 & 0.667 & 0.111 & 0.667 & \textbf{0.667} & 0.167 & 1.000 & 1.000 & 0.513 \\ \hline
    \end{tabular}
    }
\end{table}

\begin{table}[!ht]
    \centering
    \caption{\label{result_risk} Table of results across various groups for risk estimation. p-values are computed using the Wilcoxon Ranksum Test to compare the scores for grades predicted using real and synthesized transcriptomic data. \textuparrow \ indicates the larger the better and \textdownarrow \ indicates the smaller the better. Equivalent, better or close ($<0.01$) performance with synthesized data is marked in \textbf{bold}. \\}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{|c||c|c|c|c|c|c|c|c|}
    \hline
          ~ & \multicolumn{3}{ c |}{Real} & \multicolumn{3}{ c |}{Synthesized} & \multicolumn{2}{ c |}{p-value \textuparrow} \\ \hline
         Category & C Index \textuparrow & uncertainty \textdownarrow & coverage \textuparrow & C Index \textuparrow & uncertainty \textdownarrow & coverage \textuparrow & risk & uncertainty \\ \hline \hline
        \multicolumn{9}{| c |}{Dataset: TCGA - GBMLGG} \\ \hline
        overall & 0.866 & 0.446 & 0.933 & \textbf{0.861} & \textbf{0.438} & 0.923 & 0.604 & 0.652 \\ \hline
        male & 0.808 & 0.375 & 0.985 & \textbf{0.813} & \textbf{0.376} & 0.985 & 0.956 & 0.956 \\ 
        female & 0.795 & 0.653 & 0.921 & \textbf{0.795} & \textbf{0.639} & 0.921 & 0.350 & 0.400 \\ \hline
        age $ < $ 40 years & 0.524 & 0.767 & 0.977 & \textbf{0.540} & \textbf{0.727} & 1.000 & 0.119 & 0.135 \\ 
        age 40 to 60 years & 0.848 & 0.480 & 0.973 & \textbf{0.845} & 0.492 & 0.973 & 0.775 & 0.770 \\ 
        age $ > $ 60 years & 0.738 & 0.377 & 1.000 & \textbf{0.742} & \textbf{0.387} & 1.000 & 0.741 & 0.734 \\ \hline
        magnification 1 & 0.855 & 0.735 & 0.966 & 0.840 & \textbf{0.725} & 1.000 & 0.646 & 0.810 \\ 
        magnification 2 & 0.862 & 0.484 & 0.974 & \textbf{0.856} & \textbf{0.486} & 0.974 & 0.950 & 0.975 \\ 
        magnification 3 & 0.873 & 0.540 & 0.973 & 0.858 & \textbf{0.517} & 0.973 & 0.578 & 0.578 \\ \hline
        alive & - & 0.368 & 0.851 & - & \textbf{0.359} & 0.851 & 0.237 & 0.441 \\ 
        dead & 0.614 & 0.304 & 0.973 & 0.633 & \textbf{0.314} & 1.000 & 0.563 & 0.563 \\ \hline
        grade II & 0.823 & 0.582 & 0.872 & \textbf{0.823} & \textbf{0.544} & 0.821 & 0.058 & 0.054 \\ 
        grade III & 0.590 & 0.655 & 0.972 & 0.526 & \textbf{0.659} & 0.972 & 0.901 & 0.866 \\ 
        grade IV & 0.509 & 0.056 & 0.966 & \textbf{0.539} & \textbf{0.059} & 0.966 & 0.489 & 0.494 \\ \hline
        time bin 1 & 0.827 & 0.252 & 0.951 & \textbf{0.822} & \textbf{0.259} & 0.939 & 0.942 & 0.893 \\ 
        time bin 2 & - & 0.804 & 0.923 & - & \textbf{0.782} & 0.923 & 0.209 & 0.270 \\ 
        time bin 3 & - & 0.996 & 1.000 & - & \textbf{0.984} & 1.000 & 0.200 & 0.233 \\ \hline \hline
        \multicolumn{9}{| c |}{Dataset: TCGA - KIRC} \\ \hline
        overall & 0.697 & 0.898 & 0.882 & 0.681 & \textbf{0.909} & 0.928 & 0.300 & 0.307 \\ \hline
        male & 0.705 & 0.909 & 0.909 & 0.652 & 0.921 & 0.960 & 0.669 & 0.654 \\ 
        female & 0.710 & 0.855 & 0.759 & \textbf{0.771} & \textbf{0.865} & 0.796 & 0.219 & 0.311 \\ \hline
        age $ < $ 40 years & - & 0.955 & 1.000 & - & \textbf{0.942} & 1.000 & 0.275 & 0.275 \\ 
        age 40 to 60 years & 0.612 & 0.936 & 0.893 & 0.591 & \textbf{0.935} & 0.929 & 0.266 & 0.265 \\ 
        age $ > $ 60 years & 0.672 & 0.864 & 0.909 & \textbf{0.681} & 0.891 & 0.985 & 0.781 & 0.781 \\ \hline
        magnification 1 & 0.706 & 0.932 & 0.961 & 0.676 & 0.947 & 1.000 & 0.563 & 0.588 \\ 
        magnification 2 & 0.734 & 0.899 & 0.902 & 0.702 & \textbf{0.908} & 0.961 & 0.248 & 0.277 \\ 
        magnification 3 & 0.694 & 0.878 & 0.863 & 0.676 & 0.890 & 0.882 & 0.408 & 0.493 \\ \hline
        alive & - & 0.934 & 0.912 & - & \textbf{0.934} & 0.941 & 0.083 & 0.089 \\ 
        dead & 0.487 & 0.845 & 0.902 & \textbf{0.499} & 0.874 & 0.980 & 0.595 & 0.597 \\ \hline 
        grade I & - & 0.976 & 0.667 & - & \textbf{0.969} & 1.000 & 0.275 & 0.513 \\ 
        grade II & 0.835 & 0.926 & 0.905 & \textbf{0.841} & \textbf{0.919} & 0.937 & 0.139 & 0.149 \\
        grade III & 0.612 & 0.906 & 0.857 & 0.573 & \textbf{0.904} & 0.857 & 0.550 & 0.659 \\ 
        grade IV & 0.481 & 0.901 & 0.958 & 0.439 & 0.964 & 1.000 & 0.143 & 0.112 \\ \hline
        time bin 1 & 0.690 & 0.922 & 0.861 & \textbf{0.714} & 0.938 & 0.944 & 0.441 & 0.474 \\ 
        time bin 2 & 0.842 & 0.864 & 0.983 & \textbf{0.836} & 0.881 & 0.983 & 0.557 & 0.502 \\ 
        time bin 3 & - & 0.389 & 1.000 & - & \textbf{0.389} & 1.000 & 0.411 & 1.000 \\ 
        time bin 4 & - & 0.775 & 1.000 & - & \textbf{0.775 }& 1.000 & 0.275 & 1.000 \\ \hline
    \end{tabular}
    }
\end{table}


\end{document}
