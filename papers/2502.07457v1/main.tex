% CVPR 2025 Paper Template; see https://github.com/cvpr-org/author-kit

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage{cvpr}              % To produce the CAMERA-READY version
% \usepackage[review]{cvpr}      % To produce the REVIEW version  
% \usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Import additional packages in the preamble file, before hyperref
\input{preamble}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, 
% e.g. with the file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete *.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}
\usepackage{multirow}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
% \def\paperID{3583} % *** Enter the Paper ID here
% \def\confName{CVPR}
% \def\confYear{2025}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Bidirectional Uncertainty-Aware Region Learning for Semi-Supervised Medical Image Segmentation}

% \author[1,2,3]{Shiwei Zhou}
% %\ead{e22301160@stu.ahu.edu.cn}
% \author[1,2,3]{Haifeng Zhao}
% %\ead{senith@163.com}
% \author[4,5]{Dengdi Sun\corref{mycorrespondingauthor}}
% \cortext[mycorrespondingauthor]{Corresponding author}
% \ead{sundengdi@163.com; sundengdi@ahu.edu.cn}

% \address[1]{Key Laboratory of Intelligent Computing \& Signal Processing (ICSP), Ministry of Education, Anhui University, Hefei, 230601, China}
% \address[2]{Anhui Provincial Key Laboratory of Multimodal Cognitive Computation, Anhui University, Hefei, 230601, China}
% \address[3]{School of Computer Science and Technology, Anhui University, Hefei, 230601, China}
% \address[4]{School of Artificial Intelligence, Anhui University, Hefei, 230601, China}
% \address[5]{Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, Hefei, 230026, China}

%%%%%%%%% AUTHORS - PLEASE UPDATE
\author{
Shiwei Zhou\textsuperscript{1} \quad Haifeng Zhao\textsuperscript{2} \quad Dengdi Sun\textsuperscript{1}\thanks{Corresponding author.} \\
\textsuperscript{1}School of Artificial Intelligence, Anhui University \\
\textsuperscript{2}School of Computer Science and Technology, Anhui University \\
{\tt\small wa24101008@stu.ahu.edu.cn} \quad
{\tt\small senith@163.com} \quad
{\tt\small sundengdi@163.com}
}

\begin{document}
\maketitle
\begin{abstract}
In semi-supervised medical image segmentation, the poor quality of unlabeled data and the uncertainty in the model's predictions lead to models that inevitably produce erroneous pseudo-labels. These errors accumulate throughout model training, thereby weakening the model's performance. We found that these erroneous pseudo-labels are typically concentrated in high-uncertainty regions. Traditional methods improve performance by directly discarding pseudo-labels in these regions, but this can also result in neglecting potentially valuable training data. To alleviate this problem, we propose a bidirectional uncertainty-aware region learning strategy. In training labeled data, we focus on high-uncertainty regions, using precise label information to guide the model's learning in potentially uncontrollable areas. Meanwhile, in the training of unlabeled data, we concentrate on low-uncertainty regions to reduce the interference of erroneous pseudo-labels on the model. Through this bidirectional learning strategy, the model's overall performance has significantly improved. Extensive experiments show that our proposed method achieves significant performance improvement on different medical image segmentation tasks.
\end{abstract}

% Uncomment the following to link to your code, datasets, an extended version or similar.
%
% \begin{links}
%     \link{Code}{https://aaai.org/example/code}
%     \link{Datasets}{https://aaai.org/example/datasets}
%     \link{Extended version}{https://aaai.org/example/extended-version}
% \end{links}

\section{Introduction}

With the continuous development of deep learning, many medical image segmentation tasks~\cite{ronneberger2015u,milletari2016v} have achieved great success through fully supervised learning using large amounts of labeled data. However, it is challenging to obtain large-scale and accurately labeled medical datasets to train segmentation models due to the privacy, dispersion, and labeling difficulties of medical images~\cite{tajbakhsh2020embracing}. Semi-supervised medical image segmentation~\cite{basak2023pseudo,wang2023mcf,wang2023dual,yao2022enhancing} effectively reduces the cost of labeled data and improves the performance and generalization ability of the model to a certain extent by utilizing a small amount of labeled data and a large amount of easily available unlabeled data to train the model.

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{problem.pdf}
\centering
\vspace{-1.0em}
\caption{We visualize the regions of pseudo-label errors relative to the real label and the regions of high entropy predicted by the model and find that most of the regions of pseudo-label errors overlapped with the regions of high entropy predicted by the model. We also visualize category prediction probabilities using reliable and unreliable predictions. Specifically: (a) Pseudo-label errors relative to real label, (b) Selecting predicted high entropy regions above the 99th percentile, (c) Category-wise probability of a reliable prediction, which is confident enough for supervising the class right ventricle, (d) Category-wise probability of an unreliable prediction, which hovers between right ventricle, Myocardium, and Left Ventricle, yet is confident enough of not belonging to background.}
\label{fig:problem}
\vspace{-0.5em}
\end{figure}

In semi-supervised medical image segmentation, effectively leveraging unlabeled data is crucial~\cite{wang2022semi}. A common approach is assigning pseudo-labels to unlabeled data~\cite{Basak_2023_CVPR,He_2021_ICCV}, allowing the model to learn from these approximate “ground-trurh". However, generating high-quality pseudo-labels becomes particularly difficult due to the scarcity of labeled data. Low-quality pseudo-labels introduce greater uncertainty and contain numerous errors, which can mislead the model during training and ultimately affect its learning outcomes and performance~\cite{lu2023uncertainty}. Therefore, effectively preventing the accumulation and propagation of errors in pseudo-labels has become a critical challenge in this area of research. Some researchers have proposed predictive filtering based on confidence scores to solve this problem. They argue that pseudo-tags generated by predictions with higher confidence scores are more reliable~\cite{rizve2021defense}. This approach aims to filter out low-confidence predictions and to retrain the model using only high-confidence pseudo-labels. However, one potential problem caused by only using reliable predictions is that some pixels may never be learned in the entire training process, resulting in inadequate model training~\cite{Wang_2022_CVPR}. In addition, determining a threshold that effectively distinguishes between high-confidence and low-confidence pseudo-labels is also extremely challenging. Despite the ability of dynamic thresholds~\cite{zhang2021flexmatch,xu2021dash} to adapt automatically to different disturbance conditions, allowing the model to select pseudo-labels during training flexibly, their effectiveness relies on the model's current state. Suppose the model's prediction is conservative at a certain moment in time. In that case, it will set a higher confidence threshold, thus also leading to the exclusion of some valuable low-confidence samples. Since each region in a medical image may contain critical medical information~\cite{Zhang_2022_CVPR}, retaining only high-confidence predictions may result in the loss of critical information, which may lead to the model's inability to globally capture subtle differences in the medical image, reducing its ability to recognize complex structures. 

To address this issue, we first analyze the model's predicted entropy maps and the pseudo-label error maps obtained by comparing pseudo-labels with ground-truth labels, as shown in Fig.~\ref{fig:problem} (a) and (b), we find that incorrect pseudo-labels often occur in high-entropy regions, which largely coincide with the boundaries of the segmented targets. Therefore, we can effectively detect and correct errors in the pseudo-labels by identifying and processing these high-entropy regions. Additionally, as shown in Fig.~\ref{fig:problem} (c) and (d), although the model's predictions on the high-entropy regions are unreliable, it is very confident that these pixels do not belong to the background, effectively utilizing this information can enhance the model's learning. Based on these observations, we identified that the core issue lies in effectively locating and leveraging uncertain regions. Therefore, we propose a new bidirectional region learning strategy for semi-supervised learning, which includes Uncertainty-aware Region Learning (URL) and Certainty-aware Region Learning (CRL). Unlike previous approaches that remove erroneous pseudo-labeled regions, we identify uncertain regions by calculating the entropy of the model's predictions and dynamically adjust the learning weights of these regions based on the model's prediction results to address these challenges. Specifically, for each input image, we first generate predictions through the model and then generate the corresponding entropy value matrix based on the model predictions. The entropy value matrix evaluates the certainty of the predicted pixels in different categories. Then, we classify the predictions into high-entropy and low-entropy regions, i.e., uncertain and certain regions, based on the entropy value matrix. To motivate the model to focus on learning these potentially uncertain regions, we assign higher learning weights to the uncertain regions during the supervised learning phase of the labeled data, since accurate labeling allows the model to maximize the learning and correct the segmentation errors in these regions. Meanwhile, to reduce the negative impact of uncertain regions on model performance, in the self-supervised learning phase with unlabeled data, we reduce the learning weights of uncertain regions so that the model focuses more on learning predictions for certain regions. With this bidirectional two-stage learning strategy, we propose a new training method that can be directly applied to existing semi-supervised medical image segmentation methods. Extensive experiments show that our approach achieves new state-of-the-art (SOTA) performances for semi-supervised medical image segmentation, significantly improving different baseline performances.

We summarize our main contributions as follows:
\begin{itemize}
    \item We propose a bidirectional uncertain region learning strategy. This strategy involves learning uncertain regions in labeled data as well as certain regions in unlabeled data so that the model can maximize the learning and correct the segmentation error regions.
    \item By focusing on high-uncertainty regions in labeled data, the model better utilizes label information to improve the prediction ability for difficult samples, while concentrating on certainty regions in unlabeled data helps minimize errors from incorrect pseudo-labels and stabilize training.
    \item The proposed method can be easily plug-and-play, which can be embedded into different methods to improve its performance. Extensive experiments validate the feasibility of the method, which shows significant improvement over previous SOTA methods on different datasets.  
\end{itemize}

\begin{figure*}[t]
\includegraphics[width=1\linewidth]{framework.pdf}
\centering
\vspace{-1.0em}
\caption{The overall architecture of our proposed bidirectional uncertainty-aware region learning network. Both labeled and unlabeled data stages use entropy-based masks to identify reliable and unreliable predictions. For labeled data, the focus is on learning from uncertain predictions, while for unlabeled data, the focus is on learning from certain predictions.}
\label{fig:framework}
\vspace{-0.5em}
\end{figure*}

\section{Related Work}

\subsection{Semi-supervised Learning}
Current semi-supervised learning methods~\cite{van2020survey} can generally be divided into two categories: consistency regularization~\cite{laine2016temporal,ouali2020semi} and pseudo-labeling.~\cite{chen2021semi,lee2013pseudo,qiao2018deep}.Pseudo-labeling refers to using the model's predictions to generate labels for unlabeled samples, treating these predictions as approximate "ground truth" to expand the training dataset and further train the model. Consistency regularization enforces the model’s outputs to be consistent for the inputs under different perturbations. In addition, some studies~\cite{lu2023mutually,lu2023uncertainty} have combined the aforementioned methods and applied them to various tasks, showing superior performance.

\subsection{Semi-Supervised Medical Image Segmentation}
Semantic segmentation is the classification of every pixel in an image~\cite{hao2020brief,mo2022review}. It is a dense prediction task that requires substantial data and meticulous manual annotation in the training phase. Since semi-supervised methods can use unlabeled data to improve the performance of models, many semi-supervised methods have been applied to medical image segmentation in recent years. For example, SASSNet~\cite{li2020shape} introduces an edge distance function, calculating the signed distance from any voxel to its nearest natural boundary, and constructing a shape-aware semi-supervised semantic segmentation network. DTC~\cite{luo2021semi} proposes a dual-task consistency framework, introducing dual-task consistency regularization between segmentation maps derived from level sets for labeled and unlabeled data and directly predicted segmentation maps. UA-MT~\cite{yu2019uncertainty}, by incorporating uncertainty-aware consistency loss, guided by the estimated uncertainty, unreliable predictions are filtered out during the calculation of consistency loss, retaining only reliable predictions. However, removing unreliable predictions may result in the model ignoring features that are important but not easily detected, as well as meaning that they are underutilized, which may lead to loss of information.



\subsection{Uncertainty Estimation}
In semi-supervised learning, uncertainty estimates~\cite{NIPS2017_2650d608,shi2021inconsistency,mehrtash2020confidence} can be used to assess the quality of model predictions. Methods for estimating uncertainty mainly include: (1) Using the information entropy of the predicted probability distribution to measure uncertainty, the higher the entropy value, the greater the uncertainty. (2) Utilizing the bias of multiple prediction results of the same inputs under different perturbations to measure uncertainty, the higher the bias, the higher the uncertainty of the model's prediction of the input ~\cite{yu2019uncertainty}. (3) Calculate the variance of different prediction results for the same input to measure the uncertainty, the larger the variance, the higher the uncertainty of the model's prediction for that input~\cite{zheng2021rectifying}. Since entropy is calculated based on the entire probability distribution, it is insensitive to fluctuations in individual predictions, which means that the entropy can reflect the overall uncertainty of the model more stably, rather than being overly affected by individual anomalous predictions. On the other hand, calculating the entropy value only requires the already obtained predictive probability distributions without additional model inference or complex calculations. Therefore, in our approach, we perform uncertainty estimation utilizing the information entropy of the predicted probability distribution.


\section{Method}
\subsection{Preliminary}
 In semi-supervised segmentation, we assume that a training dataset $D$ contains $N$ labeled data and contains $M$ unlabeled data ($N\ll M$). The two are denoted as two subsets for convenience: $D = \mathcal{D}^l \cup \mathcal{D}^u$. Given a small labeled dataset  $\mathcal{D}^l = \{(\mathbf{X}^l_i, \mathbf{Y}^l_i)\}_{i=1}^{N}$ and a large number of unlabeled images $\mathcal{D}^u = \{\mathbf{X}^u_i\}_{i=N+1}^{N+M}$. Where, $\mathbf{X}^l_i$ represents a labeled image, and $\mathbf{Y}^l_i$ represents its corresponding label. Similarly, $\mathbf{X}^u_i$ denotes an unlabeled image. Semi-supervised semantic segmentation aims at mining the unlabeled images with the help of limited labeling under effective supervision to obtain segmentation performance comparable to the results of the same type of segmentation with full supervision. 
 
 \subsection{Overview}
The overall pipeline of the proposed bidirectional uncertainty-aware region learning method is shown in Fig. \ref{fig:framework}, based on the teacher-student model \cite{tarvainen2017mean} with a teacher network ${F}_t(\theta_t)$ and a student network ${F}_s(\theta_s)$. Due to the differences in the characteristics of uncertainty regions across different data, the identification and utilization of these uncertainty regions also vary. Therefore, we explore the scenarios of labeled and unlabeled data from two directions. For labeled images, we first use the teacher network for training. To enhance the model's ability to learn potentially uncontrollable regions, we utilize the proposed URL. A mask is generated by calculating the entropy matrix of the model’s prediction, which is then used to divide the prediction into reliable and unreliable parts. Meanwhile, we supervise the same masking process for the ground-truth to ensure that the model learns mainly the uncertainty regions during training. For unlabeled data, we use the student network for training and use pseudo-labels generated by a teacher network trained from labeled data as supervision. To prevent the negative impact of potentially uncontrollable regions on the model, we utilize the proposed CRL with the same masking treatment for the model's predictions and pseudo-labels to ensure that the model mainly learns predictions in deterministic regions during training, thus improving the stability and accuracy of the model.

 \subsection{Uncertainty-aware Region Learning }
In semi-supervised medical image segmentation, there are inevitably potentially uncontrollable regions, and the presence of these regions increases the difficulty of model training. To allow the model to learn from potentially uncontrollable regions while maximizing the use of accurate annotation information, we force the model to learn potentially uncontrollable regions when training the model with labeled data. In this phase, we assign higher learning weights to these regions, allowing the model to better understand and correct prediction errors in these complex regions.

Specifically, we first train the teacher model using labeled data, for the uncertainty regions predicted by the segmentation model, the model has difficulty in making correct category judgments, to enable the model to better learn these challenging regions, we aim to enhance the learning intensity of uncertainty regions by leveraging the precise information of the label to improve the model's predictive ability in these regions. We initially calculate the entropy matrix based on the model's predictions. The entropy matrix measures the mapping of uncertainty corresponding to different category affiliations, and it reflects the overall uncertainty of the model for each predicted sample. If the entropy value is high, it indicates that the model is uncertain in its prediction for the region, and the predicted probabilities are relatively evenly distributed, with similar probabilities across categories, and cannot be categorized as belonging to a particular category. If the entropy value is very low, it implies that the model is highly certain in its prediction of the region, and the distribution of predicted probabilities is highly concentrated in a specific category. Utilizing the entropy matrix, we can distinguish between reliable and unreliable regions of model prediction.

Suppose $\mathbf{X^{l}_i}$ is a labeled medical image, and after going through the segmentation model, we generate its corresponding outputs:
\begin{equation}
    logits^{l}_i = F_{t}(X^{l}_i),
\end{equation}
where $F_{t}$ is the teacher network that we need to pre-train. $logits^{l}_i$ are the logits outputs that correspond to $X^{l}_i$, Applying softmax to these logits yields the corresponding prediction probability scores:
\begin{equation}
    P^{l}_i = softmax(logits^{l}_i),
\end{equation}
where $P^{l}_i $ is the prediction of $X^{l}_i$. With the inference of prediction, uncertainty (i.e., entropy) maps corresponding to each class are computed according to the following equation:
\begin{equation}
    U = p \log p
\end{equation}
 where $p$ is the output probability map of each class. To detect and learn the uncertain regions, we set a dynamic threshold and if the entropy value of a region exceeds this threshold, the region is considered as part of the highly uncertain region. Because labeled data contains accurate labels that can be directly utilized by the model for supervised learning, the model's uncertain regions on labeled data can also be corrected by the label information. Therefore, a lower threshold can be set to include these regions more broadly, thus utilizing the label information more comprehensively in training. After finalizing the uncertainty region, we generate the corresponding image mask based on it $\mathbf{M} (\mathbf{M}\in\{0,1\}^{W\times H\times L})$. The formula is as follows:
\begin{equation}
    \begin{aligned}
&\mu = \mathrm{Percentile}({U}, q),\\
&\mathbf{M} = \left\{
\begin{array}{ll}
1, & \text{if} \; U > \mu \\
0, & \text{otherwise},
\end{array}
\right.
    \end{aligned}
\end{equation}
where $percentile(U,q)$ denotes the function that finds the $q$th percentile in the predicted probability distribution $U$ of the model each time. We then adjust the labeling of the labeled images utilizing the mask $M$, The formula is as follows:
\begin{equation}
    \begin{aligned}
    &\mathbf{Y}^{l}_c = \mathbf{Y}^{l}\odot\left( \mathbf{1} - \mathbf{M} \right), \\
    &\mathbf{Y}^l_{uc} = \mathbf{Y}^{l}\odot\mathbf{M},
    \end{aligned}
\end{equation}
where $\mathbf{Y}^{l}_c$ and $\mathbf{Y}^l_{uc}$ denote, respectively, reliable region labeling and unreliable region labeling.

\subsection{Certainty-aware Region Learning }
Under various perturbations, the segmentation model produces unreliable predictions for unlabeled data~\cite{chi2024adaptive}, and using these predictions may mislead the model to learn the wrong information or features, affecting the learning process and effectiveness of the model. A direct solution is to remove the regions associated with unreliable predictions. However, for medical image segmentation, this approach may result in the loss of important training data. Additionally, the model would not have the opportunity to learn how to handle these complex regions, which are often the most critical and challenging parts of a medical image. We believe that a better approach is to learn these unreliable regions appropriately by adapting the learning strategy, thus preserving valuable information while reducing its adverse effect on model training.

Specifically, for an unlabeled data ${X}^l_{i}$, we use the teacher model ${F}_s(\theta_s)$ trained from the labeled data to generate initial pseudo-labels $\mathbf{Y}^{u}$. Similar to the URL, we perform the same operation on the unlabeled data to obtain the uncertainty region and certainty region predicted by the model, and at the same time, generate the uncertainty mask $\mathbf{M}^{'}$ according to the entropy threshold set in advance, and classify the reliable pseudo-labels into reliable pseudo-labels and unreliable pseudo-labels by the uncertainty mask $\mathbf{M}^{'}$, we would like to reduce the learning intensity of the uncertainty regions in the CRL. Unlike the URL, since unlabeled data does not have accurate labels and relies only on model-generated pseudo-labels, a high threshold needs to be set to localize these high-uncertainty regions, and if the threshold is set too low, it may contain many high-uncertainty regions that can mislead the model. The final pseudo-labeling is processed by the following formula:
\begin{equation}
    \begin{aligned}
    &\mathbf{Y}^{u}_c = \mathbf{Y}^{l}\odot\left( \mathbf{1} - \mathbf{M^{'}} \right), \\
    &\mathbf{Y}^u_{uc} = \mathbf{Y}^{l}\odot\mathbf{M^{'}},
    \end{aligned}
\end{equation}
where $\mathbf{Y}^{u}_c$ and $\mathbf{Y}^u_{uc}$ denote reliable region pseudo-label and unreliable region pseudo-label, respectively.

\subsection{Loss Functions}
The overall loss function consists of two parts, the supervised loss for labeled data and the unsupervised loss for unlabeled data, defined as: 
 \begin{align}
\mathcal {L}^{l}={L}_{seg}&\left(\mathbf{P}^{l},\mathbf{Y}^{l}_{uc}\right)\odot\mathbf{M}+\\\nonumber
&\alpha{L}_{seg}\left(\mathbf{P}^{l},\mathbf{Y}^{l}_{c}\right)\odot\left(\mathbf{1}-\mathbf{M}\right),\\
\mathcal {L}^{u}={L}_{seg}&\left(\mathbf{P}^{u},\mathbf{Y}^{u}_{c}\right)\odot\left(\mathbf{1}-\mathbf{M^{'}}\right)+\\\nonumber
&\alpha{L}_{seg}\left(\mathbf{P}^{u},\mathbf{Y}^{u}_{uc}\right)\odot\mathbf{M^{'}},
\end{align}
where $L_{seg}$ is a hybrid function to compute the Dice loss and Cross-entropy loss, $\mathbf{P}^{l}$ and $\mathbf{P}^{u}$ are the prediction results of the teacher and student model for the labeled data and unlabeled data, respectively. The total loss consists of the loss of labeled and unlabeled images:
\begin{equation}
\mathcal {L}_{all} = \mathcal{L}^{l} + \mathcal{L}^{u},
\end{equation}
In each iteration, we update the parameters in the student network by stochastic gradient descent of the loss function, and the parameters of the teacher network by exponential moving average ($EMA$)~\cite{laine2016temporal}:
\begin{equation}
\theta_t = (1-\lambda) \cdot \theta_{t-1} + \lambda \cdot \theta_s,
\end{equation}
where $t$ and ${t-1}$ denote the current training step and its previous one, respectively, $\theta_{s}$ and $\theta_t$  are the weights of the student and teacher models at training step t. where $\lambda$ is the smoothing coefficient parameter, with a recommended value of $\min\left(t / (t+1), 0.99\right)$, which is used to control the updating rate of the teacher weight.

\begin{table}[t] \small 
\caption{Comparisons with state-of-the-art semi-supervised segmentation methods on the ACDC dataset.}
\setlength{\tabcolsep}{0.7mm}{
\resizebox{1\linewidth}{!}{
\begin{tabular}{c|cc|cccc}
\hline
\multicolumn{1}{c|}{\multirow{2}{*}{Method}} & \multicolumn{2}{c|}{Scans used}  & \multicolumn{4}{c}{Metrics} \\ 
\cline{2-7} \multicolumn{1}{c|}{} & \multicolumn{1}{l}{Labeled} & \multicolumn{1}{l|}{Unlabeled} & 
Dice$\uparrow$ & Jaccard$\uparrow$ & 95HD$\downarrow$ & ASD$\downarrow$ \\ \hline
\multicolumn{1}{c|}{U-Net} &\multicolumn{1}{c}{3(5\%)} &\multicolumn{1}{c|}{0} &47.83 &37.01 &31.16 &12.62 \\ 
\multicolumn{1}{c|}{U-Net} &\multicolumn{1}{c}{7(10\%)} &\multicolumn{1}{c|}{0} &79.41 &68.11 &9.35 &2.70 \\
\multicolumn{1}{c|}{U-Net} &\multicolumn{1}{c}{70(All)} &\multicolumn{1}{c|}{0} &91.44 &84.59 &4.30 &0.99 \\\hline
MT & \multirow{9}{*}{3(5\%)} & \multirow{9}{*}{67(95\%)} 
& 51.20 & 40.06 & 21.27 & 6.92 \\
SASSNet &  &  & 57.77 & 46.14 & 20.05 & 6.06 \\ 
DTC & & & 56.90 & 45.67 & 23.36 & 7.39 \\
URPC & & & 55.87 & 44.64 & 13.60 & 3.74 \\ 
MC-Net & & & 62.85 & 52.29 & 7.62 & 2.33  \\
SS-Net & & & 65.83 & 55.38 & 6.67 & 2.28 \\ 
BCP & & & 87.59 & 78.67 & 1.90 & 0.67 \\ \cline{1-1} \cline{4-7}
Ours(MT) & & & {63.64}&{51.46}& {20.32}& {6.57} \\ 
Ours(BCP) & & & \textbf{88.42}&\textbf{79.83}& \textbf{1.82}& \textbf{0.64}\\\hline
MT & \multirow{9}{*}{7(10\%)} & \multirow{9}{*}{63(90\%)}& 79.65 & 68.06 & 12.87 & 3.99\\
SASSNet & & & 84.50 & 74.34 & 5.42 & 1.86 \\ 
DTC & & & 84.29 & 73.92 & 12.81 & 4.01  \\
URPC & & & 83.10 & 72.41 & 4.84 & 1.53  \\ 
MC-Net & & & 86.44 & 77.04 & 5.50 & 1.84   \\
SS-Net & & & 86.78 & 77.67 & 6.07 & 1.40 \\
BCP & & & 88.84 & 80.62 & 3.98 & 1.17 \\ \cline{1-1} \cline{4-7}
Ours(MT) & & & {82.19}&{71.36}&{10.04}&{2.66}\\
Ours(BCP) & & & \textbf{90.40}&\textbf{83.01}& \textbf{1.63}& \textbf{0.41}\\\hline
\end{tabular}}
}
\label{tab:acdc}
\end{table}

\begin{table}[t] \small 
\raggedleft
\caption{Comparisons with state-of-the-art semi-supervised segmentation methods on LA dataset.}
\setlength{\tabcolsep}{0.7mm}{
\resizebox{1\linewidth}{!}{
\begin{tabular}{c|cc|cccc}
\hline
\multicolumn{1}{c|}{\multirow{2}{*}{Method}} & \multicolumn{2}{c|}{Scans used}  & \multicolumn{4}{c}{Metrics} \\ 
\cline{2-7} \multicolumn{1}{c|}{} & \multicolumn{1}{c}{Labeled} & \multicolumn{1}{c|}{Unlabeled} & 
Dice$\uparrow$ & Jaccard$\uparrow$ & 95HD$\downarrow$ & ASD$\downarrow$ \\ \hline
\multicolumn{1}{c|}{V-Net} &\multicolumn{1}{c}{4(5\%)} &\multicolumn{1}{c|}{0} &52.55 &39.60 &47.05 &9.87 \\ 
\multicolumn{1}{c|}{V-Net} &\multicolumn{1}{c}{8(10\%)} &\multicolumn{1}{c|}{0} &82.74 &71.72 &13.35 &3.26 \\
\multicolumn{1}{c|}{V-Net} &\multicolumn{1}{c}{80(All)} &\multicolumn{1}{c|}{0} &91.47 &84.36 &5.48 &1.51 \\\hline
MT & \multirow{9}{*}{4(5\%)} & \multirow{9}{*}{76(95\%)} 
& 81.74 & 69.93 & 16.30 & 4.99 \\
SASSNet &  &  & 81.60 & 69.63 & 16.16 & 3.58 \\ 
DTC & & & 81.25 & 69.33 & 14.90 & 3.99 \\
URPC & & & 82.48 & 71.35 & 14.65 & 3.65 \\ 
MC-Net & & & 83.59 & 72.36 & 14.07 & 2.70  \\
SS-Net & & & 86.33 & 76.15 & 9.97 & 2.31 \\ 
BCP & & & 88.02 & 78.72 & 7.90 & 2.15 \\  \cline{1-1} \cline{4-7}
Ours(MT) & & & {82.88}&{71.40}&{11.11}&{3.18}\\
Ours(BCP) & & & \textbf{89.10}&\textbf{80.46}& \textbf{7.72}& \textbf{1.98}\\\hline
MT & \multirow{9}{*}{8(10\%)} & \multirow{9}{*}{72(90\%)} 
& 86.81 & 76.93 & 10.07 & 2.49 \\
SASSNet & & & 87.54 & 78.05 & 9.84 & 2.59 \\ 
DTC & & & 87.51 & 78.17 & 8.23 & 2.36  \\
URPC & & & 86.92 & 77.03 & 11.13 & 2.28  \\ 
MC-Net & & & 87.62 & 78.25 & 10.03 & 1.82   \\
SS-Net & & & 88.55 & 79.62 & 7.49 & 1.90 \\
BCP & & & 89.62 & 81.31 & 6.81 & 1.76 \\ \cline{1-1} \cline{4-7}
Ours(MT) & & & {87.95}&{78.77}&{8.54}&{2.11}\\
Ours(BCP) & & & \textbf{90.21}&\textbf{82.26}& \textbf{6.27}& \textbf{1.63}\\\hline
\end{tabular}}
}
\label{tab:LA}
\end{table}

\section{Experiments and Results}
\subsection{Dataset}
\subsubsection{ACDC dataset}
The automatic Cardiac Diagnosis Challenge (ACDC) dataset comprises scans from 100 patients, categorized into four classes(i.e. background, right ventricle, left ventricle, and myocardium.) The dataset is divided into a fixed allocation of 70 patients' scans for training, 10 for validation, and 20 for testing. 

\subsubsection{LA Dataset}
The Left Atrium (LA) MR dataset from the Atrial Segmentation Challenge dataset includes 100 3D gadolinium-enhanced magnetic resonance image scans (GE-MRIs) with labels, categorized into two classes(i.e. background and left atrium.)

\subsection{Evaluation Metrics}
We choose four evaluation metrics: \textit{Dice Score} (\%), \textit{Jaccard Score} (\%), \textit{95\% Hausdorff Distance (95HD) in voxel} and \textit{Average Surface Distance (ASD) in voxel}. Dice~\cite{ma2021loss} and Jaccard measure overlap percentages between two object regions, while ASD calculates the average boundary distance, and 95HD computes the closest point distance between them.

\subsection{Implementation Details}
In our experiments, we set $\alpha= 0.5$. We performed all experiments on a device with an NVIDIA 3090 GPU with a fixed random seed. Due to the different feature representations and data structures of 2D and 3D medical image datasets, we conducted experiments on the ACDC dataset and the LA dataset. Specifically, in the ACDC dataset, we set the threshold $\mu$ to the 95th percentile of the entropy matrix predicted by the model each time during the supervision phase and the threshold $\mu$ to the 99th percentile during the self-training phase. In the LA dataset, the threshold $\mu$ was set to the 95th percentile of the entropy matrix in both cases. All other settings follow the default settings with the original Mean-Teacher and BCP.

\subsection{Comparison with Sate-of-the-Art Methods}
\paragraph{ACDC dataset}
Table~\ref{tab:acdc} shows the average performance of the four types of segmentation results on the ACDC dataset, with labeling ratios of 5\% and 10\%, respectively. After incorporating our methods into MT and BCP (i.e., Ours(MT) and Ours(BCP)), they showed significant improvements, which highlights the flexibility and scalability of our methods. Specifically, with a 5\% labeling ratio, Ours(MT) achieves a Dice score that is 12.4\% higher than the original MT. Ours(BCP) shows a Dice score improvement of 0.8\% over the original BCP. Similarly, with a 10\% labeling ratio, Ours(MT) achieves a Dice score that is 2.5\% higher than the original MT, while Ours(BCP) achieves a Dice score improvement of 1.56\% over the original BCP. These improvements in Dice scores, along with corresponding gains in Jaccard indices, 95HD, and ASD, demonstrate the effectiveness of our semi-supervised learning strategy in enhancing segmentation accuracy with limited labeled data.

Fig.~\ref{fig:acdc_visio} gives some qualitative results where our method effectively suppresses the regions that are inaccurately segmented by the Mean Teacher and BCP methods.

\paragraph{LA dataset}
Following SS-Net, we conducted experiments with 5\% and 10\% labeled data. We compared our approach with MT, SASSNet~\cite{li2020shape}, DTC~\cite{luo2021semi}, URPC~\cite{luo2021efficient}, MC-Net~\cite{wu2021semi}, SS-Net~\cite{wu2022exploring} and BCP\cite{bai2023bidirectional}. As shown in Table~\ref{tab:LA}, our approach surpasses all other methods. Specifically, compared to the baseline, our method shows some improvement in model performance.

Fig.~\ref{fig:la_visio} gives some qualitative results where our method is effective in segmenting difficult boundary regions.

\begin{figure}[t]
\includegraphics[width=1\linewidth]{acdc_visio.pdf}
\centering
\vspace{-1.0em}
\caption{Visualization of segmentation results on ACDC dataset with 10\% labeled data. (a) Ground-truth. (b) Mean Teacher results. (c) Ours (Mean Teacher ) results. (d) BCP results. (e) Ours (BCP) results. Best viewed in color on the screen.}
\label{fig:acdc_visio}
\vspace{-0.5em}
\end{figure}

\begin{figure}[t]
\includegraphics[width=1\linewidth]{la_visio.pdf}
\centering
\vspace{-1.0em}
\caption{Visualization of segmentation results on LA dataset with 10\% labeled data. (a) Ground-truth. (b) Mean Teacher results. (c) Ours (Mean Teacher ) results. (d) BCP results. (e) Ours (BCP) results. Best viewed in color on the screen.}
\label{fig:la_visio}
\vspace{-0.5em}
\end{figure}

\subsection{Ablation Studies}
We conducted an ablation study to show the impact of each component on our network. This included the effectiveness of the bidirectional region learning strategy, the regional learning approach, uncertainty threshold $\mu$, and the impact of removing unreliable prediction regions on model learning.

\subsubsection{Effectiveness of Each Module in Bidirectional Region Learning}
As shown in Table~\ref{tab:approach2}, to validate the bidirectional region learning strategies that we employ in both phases, we explore the following approaches under Ours(BCP) 10\% labeled data. We demonstrate the effectiveness of each module in dual-phase region learning by progressively adding URL and CRL, when URL was added, the Dice score increased to 89.45\%, indicating that focusing on high-uncertainty regions in labeled data helps the model better learn from complex areas and transfer the learned knowledge to the training of unlabeled data. When CRL was added, the Dice score rose to 90.20\%, showing that focusing on low-uncertainty regions in unlabeled data and reducing the learning weights helps mitigate the impact of erroneous pseudo-labels. By incorporating both URL and CRL into the baseline, the model has the best result, reaching 90.40\%  Dice and surpassing the baseline in 1.56\%. These results indicate that the two modules are complementary during the training process, the model not only gains a deeper understanding of complex regions but also maintains stability and accuracy in the training of unlabeled data, thereby improving the overall performance of the model.

\begin{table}[t]
\centering
\caption{Effectiveness of URL and CRL modules. “base” means baseline is the BCP. }
\begin{tabular}{ccc|cccc}
\hline
\multicolumn{1}{c}{\multirow{2}{*}{Base}} &\multicolumn{1}{c}{\multirow{2}{*}{URL}}&\multicolumn{1}{c|}{\multirow{2}{*}{CRL}}  & \multicolumn{4}{c}{Metrics} \\\cline{4-7}
& & & Dice & Jaccard & 95HD & ASD \\\hline
\checkmark &            &   &88.84 & 80.62 & 3.98 & 1.17\\
\checkmark &\checkmark  &    & 89.45 & 81.44 & 6.37 & 1.66 \\
\checkmark & & \checkmark  & 90.20 & 82.69 & 1.83 & 0.43 \\
\checkmark &\checkmark & \checkmark  &\textbf{90.40}&\textbf{83.01}& \textbf{1.63}& \textbf{0.41} \\
\hline
\end{tabular}
\label{tab:approach2}
\end{table}

\begin{table}[t]
\centering
\caption{Impact of regional learning approach on model learning.}
\begin{tabular}{cc|cccc}
\hline
\multicolumn{2}{c|}{Region} & \multicolumn{4}{c}{Metrics} \\
\hline
Labeled & Unlabeled & Dice & Jaccard & 95HD & ASD \\
\hline
CRL  & CRL   & 90.13 & 82.53 & 2.07 & 0.55 \\
CRL  & URL  & 90.28 & 82.80 & 1.88 & 0.76 \\
URL & URL & 90.12 & 82.58 & 2.04 & 0.54 \\
URL & CRL  &\textbf{90.40}&\textbf{83.01}& \textbf{1.63}& \textbf{0.41} \\
\hline
\end{tabular}
\label{tab:approach}
\end{table}



\subsubsection{Regional Learning Strategies}
To evaluate the effectiveness of the URL and CRL modules on labeled and unlabeled data, under 10\% labeled data based on Ours (BCP), we conducted different combination experiments with both modules on labeled and unlabeled data, as shown in Table~\ref{tab:approach}. Through these combination strategies, we were able to analyze the effects of applying the two modules on different types of data. The experimental results indicate that all combination strategies brought significant performance improvements, demonstrating the effectiveness of the URL and CRL modules. The optimal result was achieved by applying URL on labeled data and CRL on unlabeled data. This result confirms our hypothesis: for labeled data, we should focus on learning uncertain regions, as accurately labeled data can provide clear guidance, helping the model better understand complex features and enhance its predictive ability. Conversely, for unlabeled data, where label guidance cannot be directly utilized, focusing on learning the deterministic regions of the model’s predictions can more effectively reduce the interference of pseudo-label noise, thereby improving the model's robustness and generalization capability.

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{threshold.pdf}
\centering
\vspace{-1.0em}
\caption{The entropy visualization of the model predictions shows the entropy distribution under three different percentile thresholds (95\%, 97\%, and 99\%). In the images, red represents low-entropy regions, while green indicates high-entropy regions. As the percentile threshold increases, the retained high-entropy regions gradually decrease and are concentrated around the edges of the target regions.}
\label{fig:threshold}
\vspace{-0.5em}
\end{figure}

\begin{table}[t]
\centering
\caption{Model impact of uncertainty threshold $\mu$ settings in URL and CRL.}
\begin{tabular}{cc|cccc}
\hline
\multicolumn{1}{c}{\multirow{2}{*}{URL}} & \multicolumn{1}{c|}{\multirow{2}{*}{CRL}} & \multicolumn{4}{c}{Metrics} \\\cline{3-6}
 &  & Dice & Jaccard & 95HD & ASD \\
\hline
95\% & 95\%   & 90.10 & 82.54 & 3.01 & 0.78 \\
95\% & 99\%  &\textbf{90.40}&\textbf{83.01}& \textbf{1.6}& \textbf{0.41} \\
99\% & 99\% & 90.06 & 82.48 & 2.05 & 0.64 \\
\hline
\end{tabular}
\label{tab:approach4}
\end{table}

\begin{table}[t]
\centering
\caption{Impact of removing unreliable prediction region on model learning.}
\begin{tabular}{c|cccc}
\hline
\multicolumn{1}{c|}{\multirow{2}{*}{Method}} & \multicolumn{4}{c}{Metrics} \\\cline{2-5}
  & Dice & Jaccard & 95HD & ASD \\
\hline
remove   & 88.56 & 80.12 & 4.89 & 1.39 \\
do not remove &\textbf{90.40}&\textbf{83.01}& \textbf{1.63}& \textbf{0.41}  \\\hline
\end{tabular}
\label{tab:approach3}
\end{table}

\subsubsection{Effect of Uncertainty Thresholds $\mu$ on Model Performance}

In this section, we explore the effect of the uncertainty threshold $\mu$ on model performance. Specifically, choosing the 95th percentile to identify uncertainty regions in labeled data aims to comprehensively cover areas where errors may occur and rely on accurate labels to correct them. Conversely, selecting the 99th percentile in unlabeled data aims to more accurately pinpoint uncertainty regions. As shown in Fig.~\ref{fig:threshold}, When the $\mu$ is set at the 95th and 97th percentiles, some uncertainty regions partially appear in the background. Generally speaking, background features are relatively uniform and consistent, and the model can receive many background samples during training, resulting in a lower probability of prediction errors in background regions. Therefore, the choice of the 99th percentile aims to avoid misclassifying correct regions as uncertainty regions while maximizing the precision of uncertainty region localization. To validate this hypothesis, we conducted the relevant experiments, as shown in Table~\ref{tab:approach4}: Compared to the baseline, the combinations of $\mu$ set at 95\%+95\% and 99\%+99\% for labeled and unlabeled data both exhibit reliable performance, indirectly validating the effectiveness of the proposed module. However, their performance is still lacking compared to the 95\%+99\% combination. This suggests that the mixed approach of using a broader uncertainty range (95\%) in labeled data and a more precise uncertainty selection (99\%) in unlabeled data achieves the optimal balance. This combination effectively enhances the model’s robustness, providing ample correction opportunities for labeled data while avoiding misjudgment of uncertain regions in unlabeled data.

Additionally, in the initial stage of training with unlabeled data, we visualize the pseudo-labels generated by the teacher model. As shown in Fig.~\ref{fig:plab}, in BCP, the pseudo-labels generated by the teacher model contain many errors. However, in Ours(BCP), the pseudo-label errors generated by the teacher model trained with the 99th percentile threshold are slightly reduced. In contrast, those generated with the 95th percentile threshold are significantly fewer. This demonstrates the feasibility of the settings in our approach.

\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{plab.pdf}
\centering
\vspace{-1.0em}
\caption{Visualization of pseudo-labels generated for unlabeled data in the unsupervised initial phase using teacher models trained with different threshold values in the supervised phase.}
\label{fig:plab}
\vspace{-0.5em}
\end{figure}

\subsubsection{Remove Unreliable Predictions on Model Learning}
In addition, we investigate the impact of directly removing unreliable predictions during model training in Our(BCP) with 10\% labeled data. As shown in Tabel~\ref{tab:approach3}. Experimental results demonstrate that even erroneous prediction regions can contribute to model training. Therefore, we can reduce the learning weights of these predicted regions instead of completely removing them.

\section{Conclusion}
In this paper, we propose a simple semi-supervised training method focusing on uncertainty region learning for medical image segmentation. Our method employs a bidirectional uncertainty-aware region Learning strategy. First, in the labeled data phase, we focus on processing the uncertainty regions to improve the model's segmentation accuracy of the uncertainty regions through precise labeling information. Second, in the unlabeled data phase, since pseudo-labeling errors cannot be avoided, we adjust the learning focus of the model by calculating the uncertainty region so that it focuses on learning the deterministic region and reduces the learning weight on the uncertainty region, which can mitigate the learning interferences introduced by erroneous pseudo-labeling. We demonstrate better performance than current state-of-the-art methods on popular datasets (LA and ACDC). Given its simplicity and superior performance, we believe that this method deserves to be further explored in future studies to understand its applicability across different datasets and domains.
{
    \small
    \bibliographystyle{unsrt}
    \bibliography{main}
}

\end{document}
