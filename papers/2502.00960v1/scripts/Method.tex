\section{Proposed Method}

\figStructure

\subsection{Preliminary of Self-Training in UDA}
For UDA in the multi-modal 3D semantic segmentation task, we utilize a source domain dataset $\mathcal{D}_s$ which includes 3D LiDAR point clouds $x_s^{3D} \in \mathcal{X}_s^{3D}$, their corresponding 2D images $x_s^{2D} \in \mathcal{X}_s^{2D}$, and ground truth labels $y_s \in \mathcal{Y}_s$ for each point in $x_s^{3D}$. In contrast, the target domain consists of only the target point clouds $x_t^{3D} \in \mathcal{X}_t^{3D}$ and their paired 2D images $x_t^{2D} \in \mathcal{X}_t^{2D}$, without any label information. Recent cross-domain adaptation methods employ pseudo-labels $\hat{y}_t$ to facilitate the adaptation process through self-training. Generally, the pseudo-label based self-training objective can be divided into two main components: 
\begin{equation}
    \mathcal{L} = \mathcal{L}_s(x^{2D}_s, x^{3D}_s, y_s) + \lambda \mathcal{L}_t(x^{2D}_t, x^{3D}_t, \hat{y}_t),
    \label{equ:overview}
\end{equation}
where $\mathcal{L}_s$ represents the supervised loss on the source domain, $\mathcal{L}_t$ denotes the unsupervised loss on the target domain, and $\lambda$ is a weighting factor. In the particular case of source-free domain adaptation, the adaptation process is conducted without access to the source data, resulting in Equation \ref{equ:overview} containing only the target loss $\mathcal{L}_t$. Obviously, the quality of the pseudo-labels $\hat{y}_t$ is crucial for enhancing adaptation performance in this context. To generate high-quality 3D pseudo-labels, several methods have been proposed to filter/prune out unreliable labels, including thresholding \cite{jaritz2020xmuda}, entropy weighting \cite{shin2022mm}, and cross-modal agreement \cite{shin2022mm, simons2023summit}. However, as noted in \cite{simons2023summit}, reliable pseudo-labels after filtering/pruning are often sparse, especially in cases with large domain gaps. To address this challenge, we aim to develop a method to enhance the density of reliable pseudo-labels and boost the adaptation performance.

\figProp

\subsection{Method Overview}
The overview of the proposed pseudo-label enhancement method is summarized in Fig. \ref{fig:structure}. For a simpler notation, let $x^{3D} \in \mathbb{R}^{3\times N}$ denote the target LiDAR data and $x^{2D} \in \mathbb{R}^{3\times H \times W}$ denote the paired image data, where $H$ and $W$ defines the image size and $N$ is the total number of points. The 3D point cloud $x^{3D}$ can be further represented as $x^{3D} = \{o_k\}_{k=1}^{N}$, where $o_k \in \mathbb{R}^3$ denotes the 3D coordinate of the $k$-th point. Let $\hat{y} = \{\hat{y}_k\}_{k=1}^{N} $ represent the pseudo-labels for $x^{3D}$, with $\hat{y}_k$ denoting the pseudo-label for point $o_k$. We assume that $\hat{y}$ has been initialized using a certain pseudo-label generation strategy as in \cite{jaritz2020xmuda, simons2023summit}. For the 2D image $x^{2D}$, we extract a set of masks from SAM, denoted as $\mathcal{M} = \{M_j\}_{j=1}^{N'}$, where $N'$ is the total number of masks in $x^{2D}$. These masks are sorted in descending order based on their area. Our method iteratively updates the pseudo-labels $\hat{y}$, beginning with the smallest mask $M_1$ and proceeding to the largest mask $M_{N'}$. We prioritize smaller masks for updates as each mask is more likely to correspond to an individual object sharing a common label within the mask.

For the $j$-th mask $M_j$, we first identify the set of 3D points whose 2D projections lie within $M_j$, which is expressed as:
\begin{equation}
\mathcal{B}_{j} = \{1 \leq k \leq N\ | \;\;  \text{proj}(o_k) \in M_j \},
\label{equ:getpoints}
\end{equation}
where $\text{proj}(.)$ represents the 3D-2D projection function. After identifying the corresponding 3D points for mask $M_j$, we first perform Mask Label Assignment (MLA, details in Section \ref{MLA}) to generate its mask label $\hat{y}^M_{j}$. If a valid mask label $\hat{y}^M_{j}$ is not obtained (i.e., \textit{ignore} case for $M_{1}$ in Fig. \ref{fig:structure}), we skip updating the pseudo-labels $\hat{y}$ and proceed directly to the next mask (e.g., from $M_1$ to $M_2$ in Fig. \ref{fig:structure}). If $\hat{y}^M_{j}$ is valid (e.g., $\hat{y}^M_{2}$ and $\hat{y}^M_{N'}$ for $M_2$ and $M_{N'}$ in Fig. \ref{fig:structure}), we apply Geometry-Aware Progressive Propagation (GAPP, Section \ref{GAPP}) to propagate the mask label to the remaining points lacking valid pseudo-labels, while excluding outlier points. After applying GAPP, we update the pseudo-labels $\hat{y}$ and move on to the next mask $M_{j+1}$. The following sections provide the details of the MLA process and the GAPP module.

\subsection{Mask Label Assignment} \label{MLA}
The goal of MLA is to assign each mask $M_j$ a class label $\hat{y}^{M}_j$ based on the valid pseudo-labels in $\mathcal{B}_{j}$. A straightforward approach to achieve this is by majority voting, wherein the most frequent pseudo-label within $\mathcal{B}_{j}$ is chosen. Specifically, the points classified as class $c$ are denoted as:
\begin{equation}
\mathcal{B}_{j}^c = \{k | k \in \mathcal{B}_{j}, \hat{y}_k = c\}.
\label{equ:getpoints1}
\end{equation}
Then, the dominant class $\tilde{c}$ can be determined by:
\begin{equation}
\tilde{c} = \argmax_c |\mathcal{B}_{j}^c|.
\label{equ:getclass}
\end{equation}

However, the pseudo-label $\tilde{c}$ may not accurately represent the mask $M_j$. For instance, a large mask might encompass multiple objects, and assigning a single label would lead to incorrect labeling. Additionally, noisy pseudo-labels can further undermine the accuracy of the mask label. To address these challenges, we introduce Mask Filtering (MF) which contains three constraints based on the mask size, label purity, and label representativity. Only masks that satisfy all three constraints are assigned a valid label. 

\textbf{Mask Size}: To ensure masks are relatively small, we impose a constraint based on the ratio between the mask size and the image size, given by the equation:
\begin{equation}
R_{s} = \frac{\Omega(M_j)}{HW} \leq \lambda_s,
\label{equ:rsize}
\end{equation}
where $\Omega(.)$ is the mask area and $\lambda_s$ is a threshold parameter. 

\textbf{Label Purity}: To ensure that $\tilde{c}$ is the only dominant class within the mask, we evaluate the purity by examining the ratio of the number of points labeled with $\tilde{c}$ over the number of all valid labels. Let $\mathcal{B}_j^{ignore}$ denote the points in $M_j$ that does not have a valid label. Then the purity constraint can be defined as follows:
\begin{equation}
R_{p} = \frac{|\mathcal{B}_j^{\tilde{c}}|}{|\mathcal{B}_j|-|\mathcal{B}_j^{ignore}|} \geq \lambda_p,
\label{equ:rp}
\end{equation}
where $\lambda_p$ is a parameter limiting the lowest purity.

\textbf{Label Representativity}: We also require that the pseudo-label of class $\tilde{c}$ are representative for the entire mask. To ensure this, the number of points that belong to the dominant class $\tilde{c}$ should not be too small compared to all the points within the mask. This can be expressed as:
\begin{equation}
R_{r} = \frac{|\mathcal{B}_j^{\tilde{c}}|}{|\mathcal{B}_j|} \geq \lambda_r, 
\label{equ:rpoint}
\end{equation}
where $\lambda_r$ is a threshold parameter that controls the ratio.

Finally, the MLA process can be summarized as:
\begin{equation}
\hat{y}_j^{M} = 
\begin{cases}
\tilde{c} & \text{if Equations \ref{equ:rsize}, \ref{equ:rp}, \ref{equ:rpoint} hold,} \\
  \textit{ignore} & \text{otherwise.}
\end{cases}
\end{equation}

\subsection{Geometric-Aware Progressive Propagation (GAPP)} \label{GAPP}

\algo
\tableMain
\tableLabel

Once we have a valid mask label, the next objective is to propagate this label from $\mathcal{B}_j^{\tilde{c}}$ to all points lacking a valid pseudo-label (i.e., $\mathcal{B}_j^{ignore}$). A straightforward approach to achieve this is Direct Propagation (DP), where the mask label is assigned to every point in $\mathcal{B}_j^{ignore}$ as follows:
\begin{equation}
\hat{y}_k = \hat{y}^M_j, \;\; \forall k \in \mathcal{B}_{j}^{ignore}.
\end{equation}

In a multi-modal setting, a significant challenge is the 2D-3D alignment issue \cite{an2020geometric}, where some 3D points are incorrectly projected onto objects due to occlusion (e.g., background points seen by the lidar are occluded by an object in the camera image). As illustrated by the ground truth labels in Fig. \ref{fig:prop}, several background points (e.g., nature) are erroneously projected onto foreground objects (e.g., cars). Consequently, DP inevitably introduces additional pseudo-label errors. Inspired by distance-based point cloud outlier removal algorithms \cite{zhang2009new, ning2018efficient}, we leverage the 3D information of points and propose a progressive propagation algorithm to eliminate outlier background points that lack a connection to $\mathcal{B}_j^{\tilde{c}}$. In each iteration, we only propagate the mask label $\hat{y}^M_j$ to `nearby' points with a relatively small exploration distance $d_{exp}$. To define $d_{exp}$, we first define the minimum pair-wise distance between point $o_i$ and the points in $\mathcal{B}_j^{\tilde{c}}$ as: 
\begin{equation}
d_i = \min_{k \neq i, k \in \mathcal{B}_j^{\tilde{c}}} || o_i - o_k ||_2.
\end{equation}
Then, the exploration distance $d_{exp}$ is defined as the maximum pair-wise distance within $\mathcal{B}_j^{\tilde{c}}$, which is:
\begin{equation}
d_{exp} = \max_{i \in \mathcal{B}_j^{\tilde{c}}} d_i. 
\label{equ:dist}
\end{equation}
Next, with the exploration distance, the `nearby' points to propagate the label, denoted as $\mathcal{B}_{exp}$, can be determined by:
\begin{equation}
\mathcal{B}_{exp} = \{ k \in \mathcal{B}_j^{ignore} | d_k \leq \beta d_{exp}\},
\label{equ:exp}
\end{equation}
where $\beta$ is a scaling factor of this exploration distance. Then, the pseudo-labels $\hat{y}$ can be updated through:
\begin{equation}
\hat{y}_k = \hat{y}^M_j, \;\; \forall k \in \mathcal{B}_{exp}.
\label{equ:update}
\end{equation}
After updating $\hat{y}$, we recalculate the sets $\mathcal{B}_j^{\tilde{c}}$ and $\mathcal{B}_j^{ignore}$, and repeat this process until the set of points to explore, $\mathcal{B}_{exp}$, is empty. This iterative procedure is illustrated in Fig. \ref{fig:prop}. Starting from the initial pseudo-labels, GAPP progressively propagates the mask label across the entire object while leaving out the outliers that are not connected to the object. The proposed pseudo-label enhancement algorithm is summarized in Algorithm \ref{alg:algo}. 
   

