\section{Related Work}
Research in EC has developed various methodologies to understand and evaluate the structure and sophistication of languages that emerge among AI agents. Early efforts to quantify communication among agents focused on traditional metrics like \textit{topographic similarity}, which assesses the correlation between the distances of messages and their corresponding inputs \cite{brighton2006understanding}. To understand EC, \citet{Lazaridou2018EmergenceOL} explored the input space effect on EC by demonstrating that AI agents can develop EC that solves the shared task using both symbolic and pixel inputs, while \citet{lee2018emergent} highlighted how factors like model capacity and communicative bandwidth foster systematic compositional structures in EC.
To understand NL properties in EC, several studies have explored aspects such as Zipf's Law of Abbreviation \cite{ueda2021relationship} and Harris's Articulation Scheme \cite{ueda2022word}. Additional work focused on compositionality, examining disentanglement-based measures \cite{Chaabouni2020CompositionalityAG}, Adjusted Mutual Information (AMI) \cite{mu2021emergent}, and rigorous methods to verify compositional structures \cite{Vani2021IteratedLF, andreas2019measuring}.
More recent advances have introduced more nuanced metrics that aim to understand EC using NL. For instance, \citet{NEURIPS2022_9f9ecbf4} evaluated learned EC on unseen test data to assess generalization, providing insights into NL aspects. \citet{carmeli2024concept} proposed mapping EC symbols to NL concepts, assessing EC's compositionality. However, their approach forms a global mapping of atomic symbols, rather than full translation of individual messages.  Most closely related to our approach is work translating EC into human-understandable language.  \citet{andreas_etal_2017_translating}  translated continuous communication channels into NL by collecting agents' messages and corresponding NL strings within the same games. \citet{yao2022linking} trained image discrimination referential game and translated the EC to NL captions grounded on the same images. While promising, these studies crucially used parallel EC-NL pairs for training the translation system. In contrast, our approach does not rely on any parallel data.
Several works leverage EC as a tool to enhance NL translation in unsupervised settings \cite{downey_etal_2023_learning, lee2018emergent}. However, unlike our focus on directly translating EC, these studies utilized EC to facilitate future NL translation tasks.

\citet{guo2021expressivity} termed EC expressivity as the amount of input information encoded in EC, defining theoretically and demonstrating empirically the impact of unpredictability and contextual similarity on EC expressivity. In this paper, we extend the concept of contextual complexity by introducing  a broader spectrum of complexity, including low, moderate, and high complexity levels. This allows us to systematically explore how varying degrees of similarity among distractors influence the translatability of EC.