\section{Main Result}
\label{sec:main}
%We are going to describe different variants of RNM-FTNL~\citep{hu2021near} (Algorithm~\ref{alg:main}) in Section~\ref{sec:algo}.
%In Section~\ref{sec:result_original} and Section~\ref{sec:result_det}, we will introduce our new bounds for the open problem and its deterministic setting by providing new analysis for different variants in Algorithm~\ref{alg:main}.
%
%\subsection{Algorithm}
%\label{sec:algo}
We have introduced the original RNM-FTNL in Section~\ref{sec:exist}. There are two aspects to extend it to different variants, as shown in Algorithm~\ref{alg:main} for analyzing main theorems in this section.

First, we can resample the loss values to Bernoulli variables before accumulating them, which we call \textit{Bernoulli resampling} and is specified by the parameter $B=1$ in Algortihm~\ref{alg:main}. 
Second, denote the exponential distribution by $\mathrm{Exp}(\beta)$ with the probability density function $f(x)=\frac{1}{\beta} e^{-\frac{x}{\beta}}$ for $x\geq 0$, and denote the gumbel distribution by $\mathrm{Gumbel}(\beta)$ with the probability density function $f(x)=\frac{1}{\beta}e^{-\frac{x}{\beta} - e^{-\frac{x}{\beta}}}$ for $x\in \mathbb{R}$.
Besides the laplace distribution in the original RNM-FRNL, we can specify the noise distribution in report-noisy-max mechanism $\calQ_{\varepsilon}$ as the exponential distribution or the gumbel distribution. 

We have summarized the specifications of Algorithm~\ref{alg:main}, $B$ and $\calQ_{\varepsilon}$, for variants that attain our results in Table~\ref{tab:spec}.
Moreover, if we specify $\calQ_{\varepsilon}=\mathrm{Exp}(\frac{1}{\varepsilon})$ or $\calQ_{\varepsilon}=\mathrm{Gumbel}(\frac{2}{\varepsilon})$, similar to the analysis for $\calQ_{\varepsilon}=\mathrm{Lap}(\frac{2}{\varepsilon})$, it is also proved that Algorithm~\ref{alg:main} is $\varepsilon$-DP. 
This is because each $J_r$ is $\varepsilon$-DP w.r.t. the received loss vectors in the last epoch~\citep{dwork2014algorithmic,qiao2021oneshot} and the set of loss vectors in each epoch are disjoint.


\subsection{A New Upper bound of Pseudoregret.}
\label{sec:result_original}
Our new rate of pseudoregret is achieved by a variant of RNM-FTNL that we will do \textit{Bernoulli resampling} -- resample each observed loss vector through a joint of bernoulli distributions, such that the loss vector after resampling is a vector of bernoulli variables and they keep the same expectations as the observed loss vector.
This is presented in Algorithm~\ref{alg:main} by specifying $B=1$.
We formally state our main result which analyzes this variant as follows and give the proof in this section.

\begin{theorem}[Main result: new rate for the open problem.]
\label{thm:main}
	When specifying $B=1$ and $\calQ_{\varepsilon}$ as the laplace distribution $\mathrm{Lap}(\frac{2}{\varepsilon})$, Algorithm~\ref{alg:main} is $\varepsilon$-differentially private and satisfies the guarantee
	\begin{equation}
		\label{eq:regret_main}
	\mathrm{PseudoRegret}(\text{RNM-FTNL}(B, \calQ_{\varepsilon}); T, \calP_1, \cdots, \calP_K) = O\left(\frac{\log K}{\Delta_{\min}} + \frac{\log^2K}{\varepsilon}\right).
	\end{equation}
\end{theorem}
Compared with the existing result Theorem~\ref{thm:eixst}, it is found that the $T$-dependency has been removed from $\varepsilon$-term.
The new bound improves over existing results when $T>K$ (a small burn-in period). Notably by eliminating the extra $\log T$ factor, we showed that the instant-dependent regret remains constant (in $T$) under differential privacy as the lower bound predicts.

Moreover, the noise distribution $\calQ_{\varepsilon}$ that is chosen as laplace distribution can be replaced by the exponential or gumbel distribution, as stated in the corollary below; the proof is in Appendix~\ref{sec:app_proof_cor}.
\begin{corollary}
\label{cor:more_dist}
	When specifying $B=1$ and $\calQ_{\varepsilon}$ as the exponential distribution $\mathrm{Exp}(\frac{1}{\varepsilon})$, or the gumbel distribution $\mathrm{Gumbel}(\frac{2}{\varepsilon})$, Algorithm~\ref{alg:main} is $\varepsilon$-differentially private and satisfies the gaurantee
	$$
	\mathrm{PseudoRegret}(\text{RNM-FTNL}(B, \calQ_{\varepsilon}); T, \calP_1, \cdots, \calP_K) = O\left(\frac{\log K}{\Delta_{\min}} + \frac{\log^2 K}{\varepsilon}\right).
	$$
\end{corollary}

The instance-dependent bound from Theorem~\ref{thm:main} and Corollary~\ref{cor:more_dist} further imply our new instance-independent bound.
We present the result in the following theorem; the proof follows the same steps as a similar corollary in~\citet{hu2021near} and we put the proof in Appendix~\ref{sec:app_proof_inst_ind}.
\begin{corollary}
\label{cor:inst_ind}
	When specifying $B=1$ and $\calQ_{\varepsilon}$ as the laplace distribution $\mathrm{Lap}(\frac{2}{\varepsilon})$, the exponential distribution $\mathrm{Exp}(\frac{1}{\varepsilon})$, or the gumbel distribution $\mathrm{Gumbel}(\frac{2}{\varepsilon})$, Algorithm~\ref{alg:main} is $\varepsilon$-differentially private and satisfies the gaurantee
	$$
	\mathrm{PseudoRegret}(\text{RNM-FTNL}(B, \calQ_{\varepsilon}); T, \calP_1, \cdots, \calP_K) = O\left(\sqrt{T\log K} + \frac{\log^2 K}{\varepsilon}\right).
	$$
\end{corollary}
%Next we are going to show the proof for Theorem~\ref{thm:main}.

%\subsubsection{Proof of Theorem~\ref{thm:main}}
To prove the main theorem, we first prove an important lemma, a monotonicity property of the output from report-noisy-max, a consequence of our Bernoulli resampling (B=1 in Algorithm~\ref{alg:main}).
\begin{lemma}[Monotonicity for bionomial distributions]
\label{lem:monotonicity}
	Suppose $J_r$ is the output from report-noisy-max, as defined at line 16 in Algorithm~\ref{alg:main}. When we specify Algorithm~\ref{alg:main} by $B=1$ and the noise distribution $\calQ_{\varepsilon}$ is $\mathrm{Lap}(\frac{2}{\varepsilon})$, $\mathrm{Exp}(\frac{1}{\varepsilon})$ or $\mathrm{Gumbel}(\frac{2}{\varepsilon})$. For any $r\geq 1$ and $j_1 < j_2$, $\bbP[J_r = j_1]\geq \bbP[J_r = j_2]$. Moreover, $\bbP[J_r = j]\leq \frac{1}{j}$.
\end{lemma}

\begin{proof}[Proof of Lemma~\ref{lem:monotonicity}.]
	Let $N_{r, j} = -G_{r, j}+Q_{r, j}$ and denote $F_{A}(x)$ as the cumulative density function for any random variable $\bbP[A\leq x]$. 
	We can first prove for any $j_1 < j_2$ and $x\in \bbR$, $F_{N_{r, j_1}}(x) \leq F_{N_{r, j_2}}(x)$.
	To see its correctness, we can decompose $F_{N_{r, j_1}}(x)$ as 
	$$F_{N_{r, j_2}}(x)= \int_{-\infty}^{\infty}\bbP[-G_{r, j_1}\leq x-s]f_{Q_{r, j_1}}(s)ds= \int_{-\infty}^{\infty}(1 - F_{G_{r, j_1}}(s-x))f_{Q_{r, j_1}}(s)ds$$ 
	and similarly $F_{N_{r, j_2}}(x)=\int_{-\infty}^{\infty}(1 - F_{G_{r, j_2}}(s-x))f_{Q_{r, j_2}}(s)ds$.
	 
	Moreover, \emph{because $B=1$ is specified for the algorithm}, $G_{r, j}$ is from the binomial distribution $\calB(2^{r-1}, \mu_j)$.
	Binomial distribution has the property~(\citet{wadsworth1960introduction}; Appendix~\ref{sec:app_bern})
	$$\mu_{j_1}\leq\mu_{j_2}\Rightarrow F_{G_{r, j_1}}(x) \geq F_{G_{r, j_2}}(x).$$
	With this property, we can show $F_{N_{r, j_1}}(x) \leq F_{N_{r, j_2}}(x)$ by
	\begin{align*}
		\int_{-\infty}^{\infty}(1 - F_{G_{r, j_1}}(s-x))f_{Q_{r, j_1}}(s)ds
		\leq \int_{-\infty}^{\infty}(1 - F_{G_{r, j_2}}(s-x))f_{Q_{r, j_2}}(s)ds
	\end{align*}
	Now we turn to prove $\bbP[J_r = j_1]\geq \bbP[J_r = j_2]$ for $j_1 < j_2$. Let $H = \max_{j\neq j_1, j_2}N_{r, j}$ and let $N'_{r, j_2}$ be a random variable which is independent of $N_{r, j_2}$  but has the same distribution as $N_{r, j_2}$.
	By applying $F_{N_{r, j_1}}(x) \leq F_{N_{r, j_2}}(x)$ proved above, we have
	\begin{align*}
		\bbP[J_r = j_1] &= \bbP[N_{r, j_1}> \max\{N_{r, j_2}, H\}] = \int_{-\infty}^{\infty} (1 - F_{N_{r, j_1}}(s)) f_{\max\{N_{r, j_2}, H\}}(s)ds \\
		&\geq \int_{-\infty}^{\infty} (1 - F_{N_{r, j_2}'}(s)) f_{\max\{N_{r, j_2}, H\}}(s)ds\\
		&= \bbP[N_{r, j_2}'> \max\{N_{r, j_2}, H\}] = \bbP[N_{r, j_2}> \max\{N_{r, j_2}', H\}].
	\end{align*}
	Because $H$ and $N_{r, j_2}'$ are independent, by applying $F_{N_{r, j_1}}(x) \leq F_{N_{r, j_2}}(x) = F_{N_{r, j_2}'}(x)$ again,
	$
		F_{\max\{N_{r, j_2}', H\}}(x) = F_{N_{r, j_2}'}(x)\cdot F_{H}(x) \geq F_{N_{r, j_1}}(x)\cdot F_{H}(x) = F_{\max\{N_{r, j_1}, H\}}(x).
	$
	Therefore 
	\begin{align*}
		\bbP[J_r = j_1]&\geq \bbP[N_{r, j_2}> \max\{N_{r, j_2}', H\}]  = \int_{-\infty}^{\infty} F_{\max\{N_{r, j_2}', H\}}(s) f_{N_{r, j_2}}(s)ds \\
		&\geq \int_{-\infty}^{\infty} F_{\max\{N_{r, j_1}, H\}}(s) f_{N_{r, j_2}}(s)ds = \bbP[N_{r, j_2}> \max\{N_{r, j_1}, H\}] = \bbP[J_r = j_2].
	\end{align*}
	Finaly, we are going to show $\bbP[J_r = j]\leq \frac{1}{j}$. This can be derived by
	$
	1 = \sum_{i=1}^{K} \bbP[J_r = i] \geq \sum_{i=1}^{j} \bbP[J_r = i] \geq \sum_{i\leq j} \bbP[J_r = j] = j\cdot \bbP[J_r = j].
	$
\end{proof}

Now we show the proof sketch for Theorem~\ref{thm:main} by omitting some calculations that are similar to the proof in \citet{hu2024open}; the complete proof is in Appendix~\ref{sec:app_proof_main}.
\begin{proof}[Proof sketch of Theorem~\ref{thm:main}.]
The Algorithm~\ref{thm:main} is $\varepsilon$-differentially private as discussed at the beginning of this section. Next, we are going to bound the pseudoregret.
If we can prove Equation~\ref{eq:regret_main} for any $T:=2^{R}-1$ where $R$ is any non-negative integer, Equation~\ref{eq:regret_main} would also hold for arbitrary $T$, because Algorithm~\ref{alg:main} is independent of the $T$ and the regret of Algorithm~\ref{alg:main} is non-decreasing in $T$.
Therefore, we can assume $T:=2^{R+1}-1$ for some non-negative integer $R$ and can rewrite the pseudoregret (defined in Eqeation~\ref{eq:regret}) according to the Algorithm~\ref{alg:main}:
$$
\sum_{t=1}^T \bbE\left[\Delta_{I_t}\right] = \sum_{r=1}^{R} \sum_{t=2^{r-1}}^{2^{r}-1}\bbE\left[\Delta_{I_t}\right] = \sum_{r=1}^{R} 2^{r-1}\sum_{j=1}^{K}\Delta_{j}\bbP[J_{r-1} = j] = \sum_{j=1}^{K}\Delta_{j}\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j]
$$
$$ 
 = \underbrace{\sum_{j:\Delta_j\leq \varepsilon}\Delta_{j}\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j]}_{\text{Regret}_{\uparrow}} + \underbrace{\sum_{j:\Delta_j > \varepsilon}^{K}\Delta_{j}\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j]}_{\text{Regret}_{\downarrow}}
$$

According to the Lemma 9 in \citet{hu2021near}, there exists universal constants $c_1, c_2>0$ s.t.
	\begin{align}
	\label{eq:tail_main}
	\bbP\left[J_r = j\right]\leq c_1\cdot \exp(-2^{r+1}\Delta_j \min\{\Delta_j, \varepsilon\} / c_2),
	\end{align}
and similar to the proof for theorem 24 in \citet{hu2021near}, for $\Delta_j, \varepsilon > 0$ and $r(j)\in \bbN$, we have
\begin{align*}
%\label{eq:tail_sum}
	\sum_{r=r(j)+1}^{R}2^{r-1}\bbP\left[J_{r-1} = j\right] 
	&\leq \sum_{r=r(j)+1}^{R}2^{r-1} c_1\cdot \exp(-2^r\Delta_j \min\{\Delta_j, \varepsilon\} / c_2)\nonumber\\
	&< \frac{c_1c_2}{\Delta_j \min\{\Delta_j, \varepsilon\}}\cdot \exp(-2^{r(j)}\Delta_j \min\{\Delta_j, \varepsilon\} / c_2)
\end{align*}

	
We first bound $\text{Regret}_{\downarrow}$, where we apply Lemma~\ref{lem:monotonicity}. Let $r(j) = \left\lceil \log_2\left( \frac{c_2(\log K)}{\Delta_j\varepsilon}\right) \right\rceil$. $\forall j: \Delta_j > \varepsilon$, $\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j]$ can be bounded as
%\begin{align*}
%\sum_{r=1}^{r(j)} 2^{r-1}\bbP[J_{r-1} = j] +\sum_{r=r(j)+1}^{R} 2^{r-1}\bbP[J_{r-1} = j] 
%&< \left(\sum_{r=1}^{r(j)} 2^{r-1}\frac{1}{j}\right) + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \exp(-2^{r(j)}\Delta_j \varepsilon / c_2)\\
%&< 2^{r(j)}\frac{1}{j} + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \exp(-2^{r(j)}\Delta_j \varepsilon / c_2) \\
%&\leq \frac{2 c_2}{\Delta_j \varepsilon}\cdot \frac{\log K}{j} + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \frac{1}{K},
%\end{align*}
$$
\sum_{r=1}^{r(j)} 2^{r-1}\bbP[J_{r-1} = j] +\sum_{r=r(j)+1}^{R} 2^{r-1}\bbP[J_{r-1} = j] 
< \left(\sum_{r=1}^{r(j)} 2^{r-1}\frac{1}{j}\right) + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \exp(-2^{r(j)}\Delta_j \varepsilon / c_2)
$$
$$
< 2^{r(j)}\frac{1}{j} + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \exp(-2^{r(j)}\Delta_j \varepsilon / c_2) \\
\leq \frac{2 c_2}{\Delta_j \varepsilon}\cdot \frac{\log K}{j} + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \frac{1}{K},
$$
where the first inequality holds by Lemma~\ref{lem:monotonicity} (\emph{since it is assumed that $B=1$ for the Algorithm~\ref{alg:main} in the theorem statement}) and Equation~\ref{eq:tail_sum}, the second inequality holds by $\sum_{r=1}^{r(j)} 2^{r-1} = 2^{r(j)}-1 < 2^{r(j)}$, and the third inequality holds by taking the value of $r(j)$.
Therefore,
$$
\text{Regret}_{\downarrow} = \sum_{j:\Delta_j > \varepsilon}^{K}\Delta_{j}\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j] < \sum_{j:\Delta_j > \varepsilon}^{K}\Delta_{j}\left(\frac{2 c_2}{\Delta_j \varepsilon}\cdot \frac{\log K}{j} + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \frac{1}{K}\right)
$$
$$
\leq  \frac{2 c_2}{\varepsilon}\cdot \sum_{j:\Delta_j > \varepsilon}^{K}\frac{\log K}{j} + \frac{c_1c_2}{\varepsilon}\cdot \sum_{j:\Delta_j > \varepsilon}^{K}\frac{1}{K} = O\left( \frac{\log^2 K}{\varepsilon} \right).
$$
	
The analysis $\text{Regret}_{\uparrow}$ is the same as a part of proof for Theorem 9 in ~\citet{hu2021near} and it can be shown $\text{Regret}_{\uparrow}\leq O\left(\frac{\log K}{\Delta_{\min}}\right)$.
By putting the analysis for $\text{Regret}_{\uparrow}$ and $\text{Regret}_{\downarrow}$ together, we have proved that the pseudoregret is bounded by $O\left(\frac{\log K}{\Delta_{\min}} + \frac{\log^2 K}{\varepsilon}\right)$.
\end{proof}

\subsection{Optimal rate at the \textit{deterministic setting}}
\label{sec:result_det}
By comparing with the existing lower bound, the extra factor in the upper bound, either in the previous result (Theorem~\ref{thm:eixst}) or our new result (Theorem~\ref{thm:main}) appears together with DP factor $\varepsilon$ rather than the gap $\Delta_{\min}$.
This motivates us to study a simplified setting of the open problem to focus on differential privacy regardless of the sampling error in the observed losses.
Specifically, we study the same open problem but with the assumption that the distributions $\calP_j$ ($j\in [K]$) concentrate on the single value $\mu_j$, i.e. $\bbP_{\ell_j\sim \calP_j}[\ell_j=\mu_j] = 1$, and we call this simplified setting as the \textit{deterministic setting}.
The \textit{deterministic setting} is a special case of the \textit{original setting}.
Notice that without considering differential privacy, the learner only needs single time step to find the best action because there is no sampling error in the observed loss vector.
%When it turns to be any DP algorithm, we propose an analysis that is different from the existing analysis for the original setting, and show that the optimal rate that can be achieved by any differentially priavet algorithm for the deterministic setting is $O\left(\frac{\log K}{\varepsilon}\right)$.

By following a quite standard idea for the private selection, we first show the lower bound for the deterministic setting. 
We formally state this result as follows and put the proof in Appendix~\ref{sec:app_lower_bound}.
\begin{theorem}[Lower bound for the deterministic setting.]
\label{thm:lower_det}
	For any $\varepsilon$-differentially private online learning algorithm $\calM$ and $K\in \bbN$, $\exists (u_1, \cdots, u_K)\in [0, 1]^{K}$ s.t. at the deterministic setting,
	$$\mathrm{PseudoRegret}(\calM; T, \calP_1, \cdots, \calP_K) \geq c_1\frac{\log K}{\varepsilon},$$
	where $c_1$ is a universal constant independent of $K$,$\varepsilon$ and $(\mu_1, \cdots, \mu_k)$
\end{theorem}


Moreover, we can easily repeat the analysis in Theorem~\ref{thm:main} without considering the sampling errors and get the following rate as a corollary; the detailed argument is in Appendix~\ref{sec:app_ext_det}.
\begin{corollary}[Extension from Theorem~\ref{thm:main}.]
\label{cor:ext_det}
	When $\calQ_{\varepsilon}$ is the laplace distribution $\mathrm{Lap}(\frac{2}{\varepsilon})$, the exponential distribution $\mathrm{Exp}(\frac{1}{\varepsilon})$, or the gumbel distribution $\mathrm{Gumbel}(\frac{2}{\varepsilon})$, Algorithm~\ref{alg:main} is $\varepsilon$-differentially private and satisfies the gaurantee for the deterministic setting:
	\begin{align*}
		\mathrm{PseudoRegret}(\text{RNM-FTNL}(B, \calQ_{\varepsilon}); T, \calP_1, \cdots, \calP_K) = O\left(\frac{\log^2 K}{\varepsilon}\right)
	\end{align*}
\end{corollary}

Unfortunately, by comparing the rate with the lower bound, there is still an extra log factor.
We instead choose the Algorithm~\ref{alg:main} with a specification of $B=0$ and $Q_{\varepsilon}$ as exponential distribution or gumbel distribution and we are not sticking with the laplace distribution in the original RNM-FTNL \citep{hu2021near} for this setting.
This is because the report-noisy-max mechanism with gumbel nosie is known as exponential mechanism~\citep{qiao2021oneshot}, which has explicit forms for the probability of each action as an output and is tractable for us to derive our tight analysis.
In addition, we can make a similar conclusion for the exponential distribution by a reduction since the previous study~\citep{mckenna2020permute} shows it is consistently better than the gumbel distribution. 
Nevertheless, it is still unknown to us if the laplace distribution brings the same rate.

The following theorem states the optimal rate for the deterministic setting and we are going to show the proof after the theorem statement.

\begin{theorem}[Main result 2: optimal rate for the deterministic setting.]
\label{thm:upper_det}
	When specifying $B=0$ and $\calQ_{\varepsilon}$ as the exponential distribution $\mathrm{Exp}(\frac{1}{\varepsilon})$ or the gumbel distribution $\mathrm{Gumbel}(\frac{2}{\varepsilon})$, Algorithm~\ref{alg:main} is $\varepsilon$-differentially private and satisfies the guarantee for the deterministic setting
	\begin{align*}
		\mathrm{PseudoRegret}(\text{RNM-FTNL}(B, \calQ_{\varepsilon}); T, \calP_1, \cdots, \calP_K) = O\left( \frac{\log K}{\varepsilon}\right)
	\end{align*}
	Moreover, this rate is optimal for the deterministic setting.
\end{theorem}

%\subsubsection{Proof of Theorem~\ref{thm:upper_det}}
Before presenting the full proof for Theorem~\ref{thm:upper_det}, we first derive some useful lemmas through some calculus for the softmax-like function.
\begin{lemma}
\label{lem:derivative}
	For any $i\in [K], a_i\in \bbR$, $f(x) = \frac{\sum_{i=1}^K 2^xa_i e^{- 2^xa_i}}{\sum_{i=1}^K e^{-2^xa_i}}$ has the property $f'(x)\leq \log 2\cdot f(x)$.
\end{lemma}
\begin{proof}[Proof of Lemma~\ref{lem:derivative}.]
This can be proved by calculating the derivatives $f'(x)$:
\begin{align*}
		&f'(x) = \frac{\left(\sum_{i=1}^K 2^xa_i e^{- 2^xa_i}\right)'}{\sum_{i=1}^K e^{-2^xa_i}} - \frac{\left(\sum_{i=1}^K 2^xa_i e^{- 2^xa_i}\right)\cdot \left(\sum_{i=1}^K e^{-2^xa_i}\right)'}{\left(\sum_{i=1}^K e^{-2^xa_i}\right)^2}\\
%		&=\frac{\sum_{i=1}^K \left(2^xa_i\log 2\cdot e^{-2^xa_i } + 2^xa_i\cdot e^{-2^xa_i } (-\log2 \cdot 2^xa_i )\right)}{\sum_{i=1}^K e^{-2^xa_i }} - \frac{ (\sum_{i=1}^K 2^xa_i e^{-2^xa_i})(\sum_{i=1}^K -\log 2 \cdot 2^xa_i e^{-2^xa_i})}{(\sum_{i=1}^K e^{-2^xa_i})^2}\\
		& = \left(\log 2\cdot \frac{\sum_{i=1}^K 2^xa_i\cdot e^{-2^xa_i } }{\sum_{i=1}^K e^{-2^xa_i }} -\log2 \cdot\frac{\sum_{i=1}^K \left(2^xa_i\right)^2\cdot e^{-2^xa_i }  }{\sum_{i=1}^K e^{-2^xa_i }}\right) + \log 2 \cdot \frac{ (\sum_{i=1}^K 2^xa_i e^{-2^xa_i})^2}{(\sum_{i=1}^K e^{-2^xa_i})^2}\\
		& = (\log 2) f(x) - (\log 2)\frac{ (\sum_{i=1}^K (2^xa_i)^2e^{-2^xa_i})(\sum_{i=1}^K e^{-2^xa_i}) -(\sum_{i=1}^K 2^xa_i e^{-2^xa_i})^2}{(\sum_{i=1}^K e^{-2^xa_i})^2}\\
		&\leq (\log 2) f(x),
	\end{align*}
        where the last inequality is held by Cauchy Schwarz Inequality.	
\end{proof}

\begin{lemma}
\label{lem:calc}
	For any $0=a_1<a_2\leq, \cdots, \leq a_K$, $\sum_{r=1}^{\infty} \frac{\sum_{i=1}^{K}2^{r}a_i\exp\left( -2^{r}a_i \right)}{\sum_{i=1}^K\exp\left( -2^{r}a_i\right)} \leq O(\log K).$
\end{lemma}
\begin{proof}[Proof of Lemma~\ref{lem:calc}.]
Let $f(x) = \frac{\sum_{i=1}^K 2^xa_i e^{- 2^xa_i}}{\sum_{i=1}^K e^{-2^xa_i}}$. Then, 
	\begin{align*}
	\sum_{r=1}^{\infty} \frac{\sum_{i=1}^{K}2^{r}a_i\exp\left( -2^{r}a_i \right)}{\sum_{i=1}^K\exp\left( -2^{r}a_i\right)} = \sum_{r=1}^{\infty} f(r) = \sum_{r=1}^{\infty} \left[\left(f(r) - \int_{r-1}^{r}f(x)dx\right) + \int_{r-1}^{r}f(x)dx \right].
	\end{align*}
	From the Lagrange's mean value theorem, $\int_{r-1}^{r}f(x)dx = f(x_r)$ for some $x_r\in [r-1, r]$.
	Therefore 
	\begin{align}
	\label{eq:dis_to_cont_one}
	f(r) - \int_{r-1}^{r}f(x)dx = f(r) - f(x_r)= \int_{x_r}^r f'(x) dx \leq \int_{x_r}^r \log2f(x) dx  \leq \log2\int_{r-1}^r f(x) dx,
	\end{align}
	where the first inequality holds by $f'(x)\leq \log 2\cdot f(x)$ that we just proved and the second inequality is true because $f(x)\geq 0$ for all $x$.
	With the Equation~\ref{eq:dis_to_cont_one}, we now have
	\begin{align}
	\label{eq:dis_to_cont}
	\sum_{r=1}^{\infty} \frac{\sum_{i=1}^{K}2^{r}a_i\exp\left( -2^{r}a_i \right)}{\sum_{i=1}^K\exp\left( -2^{r}a_i\right)}
%	& \leq \sum_{r=1}^{\infty} \left[\log2\int_{r-1}^r f(x) dx  + \int_{r-1}^{r}f(x)dx \right]\nonumber\\
	& \leq(\log2 + 1)\sum_{r=1}^{\infty}  \int_{r-1}^{r}f(x)dx = (\log2 + 1)\int_{0}^{\infty}f(x)dx.
	\end{align}
	
	The last thing is to bound $\int_{0}^{\infty}f(x)dx$. Notice that the antiderivatives for $ f(x) = \frac{\sum_{i=1}^K 2^xa_i e^{- 2^xa_i}}{\sum_{i=1}^K e^{-2^xa_i}}$ is $F(x) = -\frac{1}{
	\log 2}\log\left( \sum_{i=1}^K e^{- 2^xa_i} \right) + C$ for any constant $C$.
	Moreover, because $0 {\color{blue}=} a_1 < a_2\leq, \cdots, \leq a_K$,
	$$F(0) = -\frac{1}{
	\log 2}\log\left( \sum_{i=1}^K e^{- a_i} \right) + C \geq -\frac{1}{
	\log 2}\log\left( K \right) + C;\lim_{x\infty}F(x) =-\frac{1}{
	\log 2}\log\left( 1 \right) + C = C.$$ 	
	Therefore $\int_{0}^{\infty}f(x)dx = \lim_{x\to+\infty}F(x) - F(0) = \frac{2}{
	\log 2}\log(K)$. 	Taking this equality to Equation~\ref{eq:dis_to_cont}, our proof is complete.
\end{proof}

With the lemmas above, now we can finalize the proof for our second main theorem Theorem~\ref{thm:upper_det}.
\begin{proof}[Proof of Theorem~\ref{thm:upper_det}.]
	We first prove for the gumbel distribution $\mathrm{Gumbel}(\frac{2}{\varepsilon})$. 
	It is known that the report-noisy-max with gumbel noise is equivalent to Exponential Mechanism~\citep{mcsherry2007mechanism,qiao2021oneshot}, which is
$$\bbP\left[J_r = j|\forall i\in [K], G_{r, i} \right] = \frac{\exp\left( \varepsilon\cdot (-G_{r, j} ) \right)}{\sum_{i=1}^K\exp\left( \varepsilon\cdot (-G_{r, i}) \right)}.$$
Because we are considering the deterministic setting, $G_{r, i}=2^{r-1}\mu_i$ with probability $1$.
Therefore,
$$\bbP\left[J_r = j \right] = \frac{\exp\left( -2^{r-1}\mu_i\varepsilon \right)}{\sum_{i=1}^K\exp\left( -2^{r-1}\mu_j\varepsilon\right)} = \frac{\exp\left( -2^{r-1}\Delta_i\varepsilon \right)}{\sum_{i=1}^K\exp\left( -2^{r-1}\Delta_j\varepsilon\right)}.$$
Then let $a_i = \Delta_i\varepsilon$ in Lemma~\ref{lem:calc} and we can show the upper bound for pseudoregret:
\begin{align*}
\sum_{t=1}^T \bbE\left[\Delta_{I_t}\right] &\leq 3 + \sum_{r=3}^{\infty} 2^{r-1}\sum_{j=1}^{K}\Delta_{j}\bbP[J_{r-1} = j] \leq 3 + 2\cdot \sum_{r=1}^{\infty} \frac{\sum_{i=1}^{K}2^{r}\Delta_{i}\exp\left( -2^{r}\Delta_i\varepsilon \right)}{\sum_{i=1}^K\exp\left( -2^{r}\Delta_j\varepsilon\right)} \\
& =3 + \frac{2}{\varepsilon}\cdot \sum_{r=1}^{\infty} \frac{\sum_{i=1}^{K}2^{r}\Delta_{i}\varepsilon\exp\left( -2^{r}\Delta_i\varepsilon \right)}{\sum_{i=1}^K\exp\left( -2^{r}\Delta_j\varepsilon\right)} \leq O\left(\frac{\log K}{\varepsilon}\right)
\end{align*}

We have proved the upper bound for $\calQ_{\varepsilon} = \mathrm{Gumbel}(\frac{2}{\varepsilon})$ and now we can prove the upper bound for the exponential distribution $\calQ_{\varepsilon} = \mathrm{Exp}(\frac{1}{\varepsilon})$.
To distinguish, $I_t$ is still the action from $\calQ_{\varepsilon} = \mathrm{Gumbel}(\frac{2}{\varepsilon})$, and we denote $I_t^{\rm exp}$ as the action from $\calQ_{\varepsilon} = \mathrm{Exp}(\frac{1}{\varepsilon})$ and $J_r^{\rm exp}$ as the output from report-noisy-max with the exponential noise.
\citet{mckenna2020permute} has proved (in their Theorem 2) that the report-noisy-max with exponential noise is consistently better than the exponential mechanism, which is equivalent to the report-noisy-max with gumbel noise~\citep{gumbel1954statistical, qiao2021oneshot}.
%Therefore $\forall r\geq 2$,
$$
\sum_{j=1}^{K}(-2^{r-1}\mu_j)\cdot \bbP[J_{r}^{\rm exp} = j] \geq \sum_{j=1}^{K}(-2^{r-1}\mu_j)\cdot \bbP[J_{r} = j]
\Rightarrow \sum_{j=1}^{K}\mu_j\cdot \bbP[J_{r}^{\rm exp} = j] \leq \sum_{j=1}^{K}\mu_j\cdot \bbP[J_{r} = j].
$$
Subtract $\mu_1$ from both sides, we have 
$
\sum_{j=1}^{K}\Delta_j\cdot \bbP[J_{r}^{\rm exp} = j]\leq \sum_{j=1}^{K}\Delta_j\cdot \bbP[J_{r} = j],
$
and then the pseudoregret when $\calQ_{\varepsilon} = \mathrm{Exp}(\frac{1}{\varepsilon})$ can be bounded by
\begin{align*}
\sum_{t=1}^T \bbE\left[\Delta_{I_t^{\rm exp}}\right]  \leq 3 + \sum_{r=1}^{R-2} 2^{r+1}\sum_{j=1}^{K}\Delta_{j}\bbP[J_{r+1}^{\rm exp} = j]  \leq 3 + \sum_{r=1}^{R-2} 2^{r+1}\sum_{j=1}^{K}\Delta_{j}\bbP[J_{r+1} = j],
\end{align*}
which now is the case of $\calQ_{\varepsilon} = \mathrm{Gumbel}(\frac{2}{\varepsilon})$ and bounded by $O\left(\frac{\log K}{\varepsilon}\right)$. 

We have proved the pseudoregret can be bounded by $O\left(\frac{\log K}{\varepsilon}\right)$ when specifying $B=0$ and $\calQ_{\varepsilon} = \mathrm{Gumbel}(\frac{2}{\varepsilon})$ or $\calQ_{\varepsilon} = \mathrm{Exp}(\frac{1}{\varepsilon})$.
On the other hand, the lower bound is proved in Theorem~\ref{thm:lower_det}. This means that our algorithm with the analyzed upper bound $O\left(\frac{\log K}{\varepsilon}\right)$ is optimal.
\end{proof}

\section{Discussion}
\label{sec:discuss}
Notice that in the proof for the optimal rate at the special \emph{deterministic setting}, 
the analysis for each suboptimal action $i$'s loss is always a function of all $\Delta_j$ and the losses from all suboptimal actions are considered together (in a unified function $f(r)$ in Lemma~\ref{lem:calc}).
The whole proof is quite tight -- the only relaxation happens at the difference between $\int_{0}^{\infty}f(r)dr$ and $\sum_{r=1}^{\infty}f(r)$ in Lemma~\ref{lem:calc}.
However, for the analysis at the original setting, both our proof for Theorem~\ref{thm:main} and the proof for the previous results (Theorem~\ref{thm:eixst}) make a relaxation (Equation~\ref{eq:tail_main}):
when for each suboptimal action, the loss is relaxed to a term only depending on only this suboptimal action and the optimal action, regardless of other suboptimal actions.
This type of relaxation leads to a suboptimal analysis for the algorithm in the deterministic setting.
Hence, we hypothesize it might also be the reason for the suboptimal analysis for the algorithm at the original setting, and it is still possible that the algorithm with any improved analysis can achieve the optimal rate $O\left(\frac{\log K}{\Delta_{\min}} + \frac{\log K}{\varepsilon}\right)$.

To extend the similar idea for proving the \emph{deterministic setting} to the original setting, we have tried to apply a concentration bound for the accumulated loss vector $G_{r}$ first and analyzed the regret under the concentration condition.
Unfortunately, the concentration condition that tolerates some error when estimating the mean, unlike the exact mean at the \emph{deterministic setting}, makes it hard to derive a similar following analysis.
