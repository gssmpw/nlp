\section{Related work}
The open problem is considering one specific setting in private online prediction from experts~\citep{asi2023private}.
Private online prediction from expert advice can have bandit setting and full information setting~\citep{guha2013nearly}, based on assuming the learner observes the reward or loss only from the selected action at the time or from all actions.
There are three models of adversaries at the full information setting from the strongest to the weakest: \textit{adaptive} adversaries, who can decide the loss (distribution) upon from the picked action from the last time step~\citep{jain2012differentially, guha2013nearly, jain2014near, agarwal2017price, asi2023private}; \textit{oblivious} adversaries, who decide a sequence of loss distributions before the online procedure~\citep{asi2023private}; \textit{stochastic} adversaries, who pick one loss distribution and at each time step sample the loss i.i.d. from this distribution~\citep{kairouz2021practical, hu2021near, asi2023private}.
The open problem studied in this paper is at the full information setting with the stochastic adversary, and the new proposed deterministic setting is a weaker adversary model than stochastic adversaries.

Private online prediction from experts is a special case of private online linear optimization (OLO) and private online convex optimization (OCO)~\citep{guha2013nearly, agarwal2017price, kairouz2021practical, agarwal2023differentially,asi2023near, pmlr-v235-agarwal24d}, where the optimization constraint is as an L1-sphere.
Private OLO has been studied with different constraints too, such as the L2-ball or the cube, at both full-information setting and bandit setting.

%- bandit setting
%- full information setting
%	- adversary 1, 2, 3
%- pure dp / approximate dp
%
%private online linear optimization and online convex optimization.


\section{Proof of the Property of Binomial Distribution}
\label{sec:app_bern}
\begin{lemma}
\label{lem:bern}
	Suppose $F(k; n, p)$ is the cumulative density function (CDF) of the binomial distribution $\calB(n, p)$. For any $0\leq p_1 < p_2\leq 1$, $F(k; n, p_1)\geq F(k; n, p_2)$.
\end{lemma}
\begin{proof}[Proof of Lemma~\ref{lem:bern}.]
	Suppose $F_{\rm beta-dist}(x; \alpha, \beta)$ is the CDF of beta-distribution.
	It has been proved the equivalence between the two CDFs~\citep{wadsworth1960introduction}:
	$$
	F(k; n, p) = F_{\rm beta-dist}(1-p; n-k, k+1).
	$$
	Therefore, for any $p_1 < p_2$, 
	$$F(k; n, p_1) = F_{\rm beta-dist}(1-p_1; n-k, k+1)\geq F_{\rm beta-dist}(1-p_2; n-k, k+1) = F(k; n, p_2)$$
\end{proof}


\section{Full Proof of Theorem~\ref{thm:main}}
\label{sec:app_proof_main}
\begin{proof}[Proof of Theorem~\ref{thm:main}.]
If we can prove Equation~\ref{eq:regret_main} for any $T:=2^{R}-1$ where $R$ is any non-negative integer, Equation~\ref{eq:regret_main} would also hold for arbitrary $T$, because Algorithm~\ref{alg:main} is independent of the $T$ and the regret of Algorithm~\ref{alg:main} is non-decreasing in $T$.
Therefore, we can assume $T:=2^{R+1}-1$ for some non-negative integer $R$ and can rewrite the pseudoregret (defined in Eqeation~\ref{eq:regret}) according to the Algorithm~\ref{alg:main}:
$$
\sum_{t=1}^T \bbE\left[\Delta_{I_t}\right] = \sum_{r=1}^{R} \sum_{t=2^{r-1}}^{2^{r}-1}\bbE\left[\Delta_{I_t}\right] = \sum_{r=1}^{R} 2^{r-1}\bbE\left[\Delta_{J_{r-1}}\right] = \sum_{r=1}^{R} 2^{r-1}\sum_{j=1}^{K}\Delta_{j}\bbP[J_{r-1} = j]
$$
$$ 
= \sum_{j=1}^{K}\Delta_{j}\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j] = \underbrace{\sum_{j:\Delta_j\leq \varepsilon}\Delta_{j}\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j]}_{\text{Regret}_{\uparrow}} + \underbrace{\sum_{j:\Delta_j > \varepsilon}^{K}\Delta_{j}\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j]}_{\text{Regret}_{\downarrow}}
$$

According to the Lemma 9 in \citet{hu2021near}, there exists universal constants $c_1, c_2>0$ such that 
	\begin{align}
	\label{eq:tail}
	\bbP\left[J_r = j\right]\leq c_1\cdot \exp(-2^{r+1}\Delta_j \min\{\Delta_j, \varepsilon\} / c_2),
	\end{align}
and similar to the proof for theorem 24 in \citet{hu2021near}, for $\Delta_j, \varepsilon > 0$, we can calculate
\begin{align}
\label{eq:tail_sum}
	\sum_{r=r(j)+1}^{R}2^{r-1}\bbP\left[J_{r-1} = j\right] 
	&\leq \sum_{r=r(j)+1}^{R}2^{r-1} c_1\cdot \exp(-2^r\Delta_j \min\{\Delta_j, \varepsilon\} / c_2)\nonumber\\
	&< c_1 \sum_{r=r(j)+1}^{R}\sum_{t=2^{r-1}+1}^{2^{r}} \exp(-t\Delta_j \min\{\Delta_j, \varepsilon\} / c_2)\nonumber\\
	&< c_1\sum_{t=2^{r(j)}+1}^{\infty} \cdot \exp(-t\Delta_j \min\{\Delta_j, \varepsilon\} / c_2)\nonumber\\
	&< c_1\int_{2^{r(j)}}^{\infty} \cdot \exp(-t\Delta_j \min\{\Delta_j, \varepsilon\} / c_2)dt\nonumber\\
	&= \frac{c_1c_2}{\Delta_j \min\{\Delta_j, \varepsilon\}}\cdot \exp(-2^{r(j)}\Delta_j \min\{\Delta_j, \varepsilon\} / c_2)
\end{align}

	
We first bound $\text{Regret}_{\downarrow}$. Let $r(j) = \left\lceil \log_2\left( \frac{c_2(\ln K)}{\Delta_j\varepsilon}\right) \right\rceil$. Then for any $j$ s.t. $\Delta_j > \varepsilon$,
\begin{align*}
\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j]
&=\sum_{r=1}^{r(j)} 2^{r-1}\bbP[J_{r-1} = j] +\sum_{r=r(j)+1}^{R} 2^{r-1}\bbP[J_{r-1} = j]\\
&< \left(\sum_{r=1}^{r(j)} 2^{r-1}\frac{1}{j}\right) + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \exp(-2^{r(j)}\Delta_j \varepsilon / c_2)\\
&< 2^{r(j)}\frac{1}{j} + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \exp(-2^{r(j)}\Delta_j \varepsilon / c_2)\\
&\leq \frac{2 c_2}{\Delta_j \varepsilon}\cdot \frac{\ln K}{j} + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \frac{1}{K},
\end{align*}
where the first inequality holds by Lemma~\ref{lem:monotonicity} (\emph{since it is assumed that $B=1$ for the Algorithm~\ref{alg:main} in the theorem statement}) and Equation~\ref{eq:tail_sum}, the second inequality holds by $\sum_{r=1}^{r(j)} 2^{r-1} = 2^{r(j)}-1 < 2^{r(j)}$, and the third inequality holds by taking the value of $r(j)$.
Therefore,
$$
\text{Regret}_{\downarrow} = \sum_{j:\Delta_j > \varepsilon}^{K}\Delta_{j}\sum_{r=1}^{R} 2^{r-1}\bbP[J_{r-1} = j] < \sum_{j:\Delta_j > \varepsilon}^{K}\Delta_{j}\left(\frac{2 c_2}{\Delta_j \varepsilon}\cdot \frac{\ln K}{j} + \frac{c_1c_2}{\Delta_j \varepsilon}\cdot \frac{1}{K}\right)
$$
$$
\leq  \frac{2 c_2}{\varepsilon}\cdot \sum_{j:\Delta_j > \varepsilon}^{K}\frac{\ln K}{j} + \frac{c_1c_2}{\varepsilon}\cdot \sum_{j:\Delta_j > \varepsilon}^{K}\frac{1}{K} = O\left( \frac{(\ln K)^2}{\varepsilon} \right).
$$
	
The remaining is to bound $\text{Regret}_{\uparrow}$, which is the same as a part of proof for Theorem 9 in ~\citet{hu2021near}.
For completeness, we illustrate the details here.
The idea is to group $j$. Define $\Delta_{(l)}:= 2^{l-1}\Delta_{\min}$ and denote $H_l := \{j: \Delta_{(l)} \leq \Delta_j < \Delta_{(l+1)}\}\cap \{j: \Delta_j < \varepsilon, j\geq 2\}$.
Then for any $j\in H_l$, we pick $r(j) := \tau_l = \left\lceil \frac{c_2\ln(|H_l|)}{\Delta_{(l)}^2} \right\rceil$.
\begin{align*}
	\text{Regret}_{\uparrow} &= \sum_{j:\Delta_j\leq \varepsilon}\Delta_{j}\cdot \left(\sum_{r=1}^{r(j)} 2^{r-1}\bbP[J_{r-1} = j] +\sum_{r=r(j)+1}^{R} 2^{r-1}\bbP[J_{r-1} = j]\right) \\
	& = \sum_{l=1}^{\infty}\sum_{j\in H_l} \Delta_{j}\cdot \left(\sum_{r=1}^{\tau_l} 2^{r-1}\bbP[J_{r-1} = j] +\sum_{r=\tau_l+1}^{R} 2^{r-1}\bbP[J_{r-1} = j]\right) \\
	& = \sum_{l=1}^{\infty} \left(\sum_{r=1}^{\tau_l}2^{r-1} \sum_{j\in H_l}\Delta_j\cdot \bbP[J_{r-1} = j] \right) + \sum_{l=1}^{\infty} \left(\sum_{j\in H_l}\Delta_j\cdot  \sum_{r=\tau_l+1}^{R}2^{r-1} \bbP[J_{r-1} = j] \right)\\
	& \leq \sum_{l=1}^{\infty} \left(\sum_{r=1}^{\tau_l}2^{r-1}\right)\cdot 2\Delta_{(l)}+ \sum_{l=1}^{\infty} \left(\sum_{j\in H_l}\Delta_j\cdot \frac{c_1c_2}{\Delta_j ^2}\cdot \exp(-2^{r(j)}\Delta_j^2 / c_2) \right)\\
	& < \sum_{l=1}^{\infty} 2^{\tau_l+2}\Delta_{(l)}+ \sum_{l=1}^{\infty} \left(|H_l|\cdot\frac{c_1c_2}{\Delta_{(l)}}\cdot \exp(-2^{r(j)}\Delta_{(l)}^2 / c_2) \right)\\
	& \leq \sum_{l=1}^{\infty}\frac{8c_2\ln(|H_l|)}{\Delta_{(l)}} + \sum_{l=1}^{\infty} \frac{c_1c_2}{\Delta_{(l)}} \\
	& \leq \frac{8c_2\ln K + c_1c_2}{\Delta_{\min}}\sum_{l=1}^{\infty}\frac{1}{2^{l-1}}\\
	& = \frac{8c_2\ln K + c_1c_2}{\Delta_{\min}},
	\end{align*}
The first inequality is because Equation~\ref{eq:tail_sum} and the fact that for $j\in H_l$, $\sum_{j\in H_l}\Delta_j\cdot \bbP[J_{r-1} = j]\leq 2\Delta_{(l)}\sum_{j\in H_l}\bbP[J_{r-1} = j]\leq 2\Delta_{(l)}$; the second inequality holds by $\sum_{r=1}^{\tau_l}2^{r-1} < 2^{\tau_l}$ and the fact that for $j\in H_l$, $\Delta_j\geq \Delta_{(l)}$; the third inequality holds by taking the value of $\tau_l$; the fourth inequality holds by the definition of $\Delta_{(l)}$ and the fact $|H_l|\leq K$.

Putting the analysis for $\text{Regret}_{\uparrow}$ and $\text{Regret}_{\downarrow}$ together, we have proved that the pseudoregret is bounded by $O\left(\frac{\log(K)}{\Delta_{\min}} + \frac{(\log K)^2}{\varepsilon}\right)$.
\end{proof}


\section{Proof of Corollary~\ref{cor:more_dist}}
\label{sec:app_proof_cor}
\begin{proof}[Proof of Corollary~\ref{cor:more_dist}.]
If we can prove that when $\calQ_{\varepsilon}$ is $\mathrm{Exp}(\frac{1}{\varepsilon})$ or $\mathrm{Gumbel}(\frac{2}{\varepsilon})$, there exists universal constants $c_1, c_2>0$ such that Equation~\ref{eq:tail} in the proof of Theorem~\ref{thm:main} holds, all the remaining proof follows the same, so we can prove the same rate for pseudoregret as what rate Algorithm~\ref{alg:main} with $\calQ_{\varepsilon}=\mathrm{Lap}(\frac{2}{\varepsilon})$ has. Then our proof is done. We repeat Equation~\ref{eq:tail} here for reading convenience:
$$
	\bbP\left[J_r = j\right]\leq c_1\cdot \exp(-2^r\Delta_j \min\{\Delta_j, \varepsilon\} / c_2).
$$

The proof for $\calQ_{\varepsilon}=\mathrm{Exp}(\frac{1}{\varepsilon})$ is almost the same as their proof for $\calQ_{\varepsilon}=\mathrm{Lap}(\frac{2}{\varepsilon})$:
\begin{align*}
	\bbP\left[J_r = j\right] &\leq \bbP\left[-G_{r, j} + Q_{r, j} > -G_{r, 1} + Q_{r, 1}\right]\\
	&\leq  \bbP\left[ G_{r, j} -G_{r, 1} \leq 2^{r-1}\frac{\Delta_j}{2}\right] + \bbP\left[ Q_{r, j} -Q_{r, 1} \geq 2^{r-1}\frac{\Delta_j}{2}\right].
\end{align*}
From the Hoeffding inequality, 
$$\bbP\left[ G_{r, j} -G_{r, 1} \leq 2^{r-1}\frac{\Delta_j}{2}\right] = \bbP\left[ G_{r, j} -G_{r, 1} - 2^{r-1}\Delta_j \leq -2^{r-1}\frac{\Delta_j}{2}\right] \leq \exp\left(-2^{r-1}\frac{\Delta_j^2}{4}\right).$$
By the cdf of any eponential distribution, 
$$\bbP\left[ Q_{r, j} -Q_{r, 1} \geq 2^{r-1}\frac{\Delta_j}{2}\right] \leq \bbP\left[ Q_{r, j} \geq 2^{r-1}\frac{\Delta_j}{2}\right] \leq \exp\left(-\varepsilon 2^{r-1}\frac{\Delta_j}{2}\right).$$
Therefore, for $\calQ_{\varepsilon}=\mathrm{Exp}(\frac{1}{\varepsilon})$, $\bbP\left[J_r = j\right]\leq 2\cdot \exp(-2^r\Delta_j \min\{\Delta_j, \varepsilon\}/8)$.
	
As for $\calQ_{\varepsilon}=\mathrm{Gumbel}(\frac{2}{\varepsilon})$, it is known that the report-noisy-max with gumbel noise is equivalent to Exponential Mechanism~\citep{mcsherry2007mechanism,qiao2021oneshot}, which is
$$\bbP\left[J_r = j|\forall i\in [K], G_{r, i} \right] = \frac{\exp\left( \varepsilon\cdot (-G_{r, j} ) \right)}{\sum_{i=1}^K\exp\left( \varepsilon\cdot (-G_{r, i}) \right)}.$$
We bound $\bbP\left[J_r = j\right]$ as
\begin{align*}
	\bbP\left[J_r = j\right] & =\bbE_{\forall i\in [K], G_{r, i}}[\bbP\left[J_r = j|\forall i\in [K], G_{r, i} \right]]\\
	&= \bbE_{\forall i\in [K], G_{r, i}}\left[\frac{\exp\left( -\varepsilon\cdot (-G_{r, j} ) \right)}{\sum_{i=1}^K\exp\left( -\varepsilon\cdot (-G_{r, i}) \right)}\right]\\
	&\leq \bbE_{\forall i\in [K], G_{r, i}}\left[\frac{\exp\left( \varepsilon\cdot (-G_{r, j}) \right)}{\exp\left( \varepsilon\cdot (-G_{r, 1} ) \right) + \exp\left( \varepsilon\cdot (-G_{r, j}) \right)}\right]\\
	& = \bbE\left[\frac{1}{\exp\left( \varepsilon\cdot (G_{r, j}-G_{r, 1}) \right) + 1}\right].
\end{align*}
Denote the event $\mathcal{E}$ as $G_{r, j}-G_{r, 1} \geq \frac{1}{2}2^{r-1}\Delta_j$, because $\frac{1}{\exp\left( \varepsilon\cdot (G_{r, j}-G_{r, 1}) \right) + 1}\leq 1$ is always true,
$$
\bbP\left[J_r = j\right] \leq \bbE\left[\frac{1}{\exp\left( \varepsilon\cdot (G_{r, j}-G_{r, 1}) \right) + 1}| \mathcal{E} \right] + (1 - \bbP[\mathcal{E}])
$$
$$
\leq \frac{1}{\exp\left(  \frac{1}{2}2^{r-1}\Delta_j \varepsilon) \right) + 1} + (1 - \bbP[\mathcal{E}]) \leq \exp\left( -2^{r-1}\Delta_j \varepsilon/2)\right)  + (1 - \bbP[\mathcal{E}]).
$$
The bound for $1 - \bbP[\mathcal{E}] = \bbP[(G_{r, j}-G_{r, 1}) + (Q_{r, j} - Q_{r, 1}) < 2^{r-1}\Delta_j/2]$ is
\begin{align*}
&\bbP\left[G_{r, j}-G_{r, 1}\right] \leq \exp\left(-2^{r-1}\Delta_j^2/4\right)
\end{align*}
where the inequality is held by the Hoeffding inequality. Therefore, 
$$
\bbP\left[J_r = j\right] \leq \exp\left( -2^{r-1}\Delta_j \varepsilon/2)\right) + \exp\left(-2^{r-1}\Delta_j^2/4\right).
$$
Our proof for the case $\calQ_{\varepsilon}=\mathrm{Gumbel}(\frac{2}{\varepsilon})$ is complete.
\end{proof}

\section{Proof of Theorem~\ref{thm:lower_det}}
\label{sec:app_lower_bound}
The lower bound for the original setting, that is $\Omega\left(\frac{\log(K)}{\Delta_{\min}} + \frac{\log(K)}{\varepsilon}\right)$, is an application of Corollary 4 in \citet{acharya2021differentially}.
However, Corollary 4 in \citet{acharya2021differentially} requires a bounded KL divergence, while at our deterministic setting where each $\calP_i$ has probability $0$ on all values except $\mu_i$, the KL divergence between $\calP=\calP_1\times\cdots\times\calP_k$ and $\calP'$ is infinity when $\calP\neq \calP'$.
Therefore, we show an easy and standard construction for our setting.
\begin{proof}[Proof of Theorem~\ref{thm:lower_det}.]
	For any $l\in [K]$, define $\calP^{(l)} := \calP^{(l)}_1\times\cdots\times\calP^{(l)}_K$, where $\bbP_{\ell_i\sim\calP_i^{(l)}}[\ell_i=\mu_i^{(l)}]=1$, $\mu_l^{(l)} = 0$ and $\mu_i^{(l)}=1$ for all $i\neq l$.
	Suppose $\calA$ is any online algorithm that is $\varepsilon$-differentially private. When $K$ actions have the loss from $\calP^{(l)}$, denote $I_t^{(l)}$ is the action from $\calA$ and further for any length of the online procedure $T$, let $R^{(l)}(T)$ is the pseudoregret.
	Therefore 
	$$
	R^{(l)}(T) = \sum_{t=1}^T\bbP[I_t^{(l)}\neq l]
	$$
	One the other hand, because $\calA$ is differentially private, for any $l,l'\in [K]$, any action $i$, and any $t\geq T$,
	$$
	\bbP[I_t^{(l)} = i]\leq e^{t\cdot \varepsilon}\cdot \bbP[I_t^{(l')} = i].
	$$
	Therefore, 
	$$
	\bbP[I_t^{(l)}\neq l] = 1 - \bbP[I_t^{(l)}= l] \geq 1 - \frac{e^{t\cdot \varepsilon}}{K-1}\sum_{l'\neq l}\bbP[I_t^{(l')}= l].
	$$
	We take a sum of all $l\in [K]$:
	\begin{align*}
		\sum_{l=1}^K\bbP[I_t^{(l)}\neq l] &\geq K - \frac{e^{t\cdot \varepsilon}}{K-1}\sum_{l=1}^K\sum_{l'\neq l}\bbP[I_t^{(l')}= l] \\
		&= K - \frac{e^{t\cdot \varepsilon}}{K-1}\sum_{l=1}^K\sum_{l'\neq l}\bbP[I_t^{(l)}= l'] \\
		&= K - \frac{e^{t\cdot \varepsilon}}{K-1}\sum_{l=1}^K\bbP[I_t^{(l)}\neq l'] 
	\end{align*}
	where the first equality holds by swiping the notation of $l$ and $l'$ and their order of summation.
	This gives us $\sum_{l=1}^K\bbP[I_t^{(l)}\neq l] \geq \frac{K (K-1)}{e^{t\cdot \varepsilon} + K-1}$.
	Thus, 
	$$
	\frac{1}{K}\sum_{l=1}^KR^{(l)}(T)\geq \sum_{t=1}^T\frac{K-1}{e^{t\cdot \varepsilon} + K-1}\geq \sum_{t=1}^T\int_{t}^{t+1}\frac{K-1}{e^{\tau\cdot \varepsilon} + K-1}d\tau = \int_{1}^{T+1}\frac{K-1}{e^{t\cdot \varepsilon} + K-1}dt
	$$
	where the second inequality holds because $\frac{K-1}{e^{t\cdot \varepsilon} + K-1}$ is monotonically decreasing.
	The antiderivatives for $g(t)=\frac{K-1}{e^{t\cdot \varepsilon} + K-1}$ are $\frac{\ln\left(\frac{e^{t\varepsilon}}{e^{t\varepsilon} + K - 1}\right)}{\varepsilon} + C$ for any constant $C$, which implies:
	$$
	\frac{1}{K}\sum_{l=1}^KR^{(l)}(T)\geq \int_{1}^{T+1}\frac{K (K-1)}{e^{t\cdot \varepsilon} + K-1}dt = \frac{\ln\left(\frac{e^{(T+1)\varepsilon}}{e^{(T+1)\varepsilon} + K - 1}\cdot \frac{e^{\varepsilon} + K - 1}{e^{\varepsilon}}\right)}{\varepsilon}.
	$$
	From here, it implies that there exists $l_T^*$ s.t. 
	$$
	R^{(l_T^*)}(T)\geq \frac{\ln\left(\frac{e^{(T+1)\varepsilon}}{e^{(T+1)\varepsilon} + K - 1}\cdot \frac{e^{\varepsilon} + K - 1}{e^{\varepsilon}}\right)}{\varepsilon}.
	$$
	When $T\to\infty$,
	$$
	\lim_{T\to\infty}R^{(l_T^*)}(T)\geq \frac{\ln\left(\frac{e^{\varepsilon} + K - 1}{e^{\varepsilon}}\right)}{\varepsilon} = \frac{\ln\left(e^{\varepsilon} + K - 1\right) }{\varepsilon} - 1 \geq \frac{\ln K  }{\varepsilon} - 1 = \Omega\left(\frac{\ln K  }{\varepsilon}\right).
	$$
	\end{proof}

\section{Proof of Corollary~\ref{cor:inst_ind}}
\label{sec:app_proof_inst_ind}
The proof follows the exact same steps as the proof for Corollary 11 in \citet{hu2021near}, which is also well-known as early as~\citet{audibert2009minimax}.
For completeness, we repeat the exact steps here.
\begin{proof}[Proof of Corollary~\ref{cor:inst_ind}]
	Let $\Delta^*:=\sqrt{\log K/T}$ be the critical gap. Then, for all actions $j$ that $\Delta_j<\Delta^*$, the can contribute the regret at most $T\cdot \Delta^*=\sqrt{T\log K}$.
	 To bound the contributions for actions $j$ that $\Delta_j\geq \Delta^*$, we can simply adapt the proof of our Theorem~\ref{thm:main} and Corollary~\ref{cor:more_dist} for only these actions, and the effective $\Delta_{\min}$ becomes $\Delta^*$.Therefore, the  bound for the overall regret becomes 
	 $$
	 O\left(\sqrt{T\log K} + \frac{\log K}{\Delta^*} + \frac{(\log K)^2}{\varepsilon}\right) = O\left(\sqrt{T\log K} + \frac{(\log K)^2}{\varepsilon}\right)
	 $$
\end{proof}


\section{Proof of Corollary~\ref{cor:ext_det}}
\label{sec:app_ext_det}
The proof for the deterministic setting is a straightforward extension from the proof for Theorem~\ref{thm:main} (the result at the original setting).
\begin{proof}[Proof sketch of Corollary~\ref{cor:ext_det}.]
	With the additional assumption at the deterministic setting that $\bbP_{\ell_j\sim\calP_j}[\ell_j=\mu_j]=1$, $\bbP[J_r=j]$ can be bounded in the form when $\calQ_\varepsilon$ is laplace distribution, exponential distribution, or gumbel distribution:
	\begin{align}
	\label{eq:tail_det}
	\bbP\left[J_r = j\right]\leq c_1\cdot \exp(-2^r\Delta_j \varepsilon / c_2)
	\end{align}
	for some universal constants $c_1, c_2>0$, a slight improvement from the bound $\bbP\left[J_r = j\right]\leq c_1\cdot \exp(-2^r\Delta_j \min\{\Delta_j, \varepsilon\} / c_2)$ (Equation~\ref{eq:tail}) at the original setting.
	Then by extending the similar derivation in the proof of Theorem~\ref{thm:main} (Section~\ref{sec:app_proof_main}), we can prove that the pseudo regret is bounded by $O\left(\frac{(\log K)^2}{\varepsilon}\right)$
	
\end{proof}
