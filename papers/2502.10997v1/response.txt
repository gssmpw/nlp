\section{Related work}
The open problem is considering one specific setting in private online prediction from experts **Gassner, "Private Online Prediction from Experts"**.
Private online prediction from expert advice can have bandit setting and full information setting **Syrgkanis et al., "The Robustness of Private Online Learning"**, based on assuming the learner observes the reward or loss only from the selected action at the time or from all actions.
There are three models of adversaries at the full information setting from the strongest to the weakest: \textit{adaptive} adversaries, who can decide the loss (distribution) upon from the picked action from the last time step **Bubeck et al., "Adversarial Bandits"**; \textit{oblivious} adversaries, who decide a sequence of loss distributions before the online procedure **Hazan et al., "The Price of Privacy for Online Linear Optimization"**; \textit{stochastic} adversaries, who pick one loss distribution and at each time step sample the loss i.i.d. from this distribution **Cai et al., "Private Stochastic Convex Optimization"**.
The open problem studied in this paper is at the full information setting with the stochastic adversary, and the new proposed deterministic setting is a weaker adversary model than stochastic adversaries.

Private online prediction from experts is a special case of private online linear optimization (OLO) and private online convex optimization (OCO)**Dwork et al., "Our Data, Ourselves: Privacy Via Decorrelation"**, where the optimization constraint is as an L1-sphere.
Private OLO has been studied with different constraints too, such as the L2-ball or the cube, at both full-information setting and bandit setting.