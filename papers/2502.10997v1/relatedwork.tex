\section{Related work}
The open problem is considering one specific setting in private online prediction from experts~\citep{asi2023private}.
Private online prediction from expert advice can have bandit setting and full information setting~\citep{guha2013nearly}, based on assuming the learner observes the reward or loss only from the selected action at the time or from all actions.
There are three models of adversaries at the full information setting from the strongest to the weakest: \textit{adaptive} adversaries, who can decide the loss (distribution) upon from the picked action from the last time step~\citep{jain2012differentially, guha2013nearly, jain2014near, agarwal2017price, asi2023private}; \textit{oblivious} adversaries, who decide a sequence of loss distributions before the online procedure~\citep{asi2023private}; \textit{stochastic} adversaries, who pick one loss distribution and at each time step sample the loss i.i.d. from this distribution~\citep{kairouz2021practical, hu2021near, asi2023private}.
The open problem studied in this paper is at the full information setting with the stochastic adversary, and the new proposed deterministic setting is a weaker adversary model than stochastic adversaries.

Private online prediction from experts is a special case of private online linear optimization (OLO) and private online convex optimization (OCO)~\citep{guha2013nearly, agarwal2017price, kairouz2021practical, agarwal2023differentially,asi2023near, pmlr-v235-agarwal24d}, where the optimization constraint is as an L1-sphere.
Private OLO has been studied with different constraints too, such as the L2-ball or the cube, at both full-information setting and bandit setting.

%- bandit setting
%- full information setting
%	- adversary 1, 2, 3
%- pure dp / approximate dp
%
%private online linear optimization and online convex optimization.