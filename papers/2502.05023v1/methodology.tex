%This section outlines the research questions that motivate our study and the methodology used to address these questions.
\label{sec:Met}
The primary aim of this research is to investigate the potential for ChatGPT to recommend code protected by restrictive licenses. In particular, we formulated the following research questions (RQs):


    \noindent  \textbf{RQ1: Can ChatGPT return code protected by copyleft licenses?} This question aims to determine whether ChatGPT can generate code subject to limitations imposed by copyleft licenses. The focus is on identifying actual instances of code plagiarism that may (accidentally) lead to improper reuse. Understanding this risk is important for developers who want to use AI-generated code responsibly and in compliance with licensing rules.


    %\noindent  \textbf{RQ2: Does the context provided in the request influence the likelihood of returning code protected by copyleft licenses?} This question investigates if the presence of code already processed at training time in the prompt may affect the likelihood of obtaining code protected by copyleft licenses. In particular, we consider the case of a class that has been already partially implemented consistently with publicly available copyleft code (e.g., by formerly accepting code recommendations that match with the code in an existing class), and we want to establish if this affects the likelihood of receiving recommendations of code in that same class. \textcolor{review}{The goal is to establish understand if providing larger code snippets increases the chances of generating plagiarized content.}


    \noindent  \textbf{RQ2: Does the context provided in the request influence the likelihood of returning code protected by copyleft licenses?} This question examines whether the presence of copyleft code already included in a partially implemented class increases the probability that ChatGPT will recommend additional copyleft code for that class. The rationale for this investigation stems from the concern that once a developer accepts an initial recommendation that includes copyleft code, subsequent recommendations might be affected. Understanding this dynamic is crucial, as it highlights the potential for a cascading effect where the initial inclusion of copyleft code leads to more copyleft code recommended, thereby increasing the risk of unintentional copyleft violations.

    \noindent  \textbf{RQ3:  Does providing a context with only access methods affect the likelihood of obtaining code protected by copyleft licenses?} This question investigates a specific case of context, that is, whether the presence of simple non-characteristic methods, access methods in particular, influences the likelihood  ChatGPT recommends code from classes protected by a copyleft license. Unlike RQ2, which focuses on the recommendations generated for classes with a large context already matching existing copyleft code, RQ3 focuses on the impact of a matching context that carries very limited class semantics. We specifically consider the case of access methods, which serve as getters and setters, since they convey little information about the class's overall functionality. It is important to determine if such a constrained, and apparently harmless, context can inadvertently lead to further recommendations of copyleft code.

    \noindent  \textbf{RQ4: Does adjusting the temperature parameter alter the likelihood of obtaining code protected by copyleft licenses?} This question aims to explore whether modifying the temperature, which is a parameter that controls the level of creativity of the model, can change the likelihood that the generated code matches code protected by restrictive licenses.  By exploring this relationship, we aim to determine whether a higher or lower temperature setting can effectively reduce the risk of producing code that may inadvertently infringe copyleft licenses. 

    \noindent  \textbf{RQ5: Is ChatGPT aware of using protected code and can it avoid plagiarism when explicitly requested?} 
    This question investigates whether ChatGPT can refrain from providing copied code and instead generate original content, not copied from any source, when explicitly asked to do so. The analysis aims to determine if an explicit request is effective in reducing the risk of obtaining plagiarized content.


The rest of this section describes the methodology that we used to answer these five RQs. 

\subsection{Dataset Construction}
To answer our RQs, we created a dataset of copyleft Java methods with JavaDoc comments extracted from publicly available repositories on GitHub~\cite{GitHub2024}. This dataset serves as a foundation to query ChatGPT for the generation of method implementations and checking if the recommendation matches with existing copyleft code. To select these methods, we referred to the criteria below.

\textbf{Repository Selection.} In our repository selection process, we established several key criteria to ensure that the repositories we analyzed were relevant, high-quality, and suitable for our investigation of code recommendations that may break copyleft licenses.

Firstly, we considered the licenses under which the repositories were released. We specifically selected repositories protected by any of the following open-source licenses: GPL, AGPL-3.0, CC-BY-SA-4.0, ECL-2.0, and EUPL-1.1. These licenses allow for the use and modification of the code while adding restrictions on how the derivative code can be made available and distributed (e.g., a specific license must be used). This criterion was crucial to ensure that the code we considered could not be reused without restrictions.
%analyzed could be legally reused and modified, aligning with the ethical considerations of our research. 

Second, to make sure ChatGPT could have processed during training the methods we ask it to generate, we select only methods created \emph{before} the last training date of the model used in this work.
According to official documentation, %the \texttt{gpt-3.5-turbo} model was trained until September 2021, while 
the \texttt{gpt-4-turbo} model was trained in 2023, so we opted for selecting repositories that were already existing by the end of 2020. %, taking into account the necessary time for data collection and model training.

Third, to select popular projects appreciated by the community, we included only those repositories that had at least 500 stars on GitHub. This threshold indicated a substantial level of interest and validation from the community. % suggesting that the code was well-regarded and likely of higher quality. 
By concentrating on popular repositories, we aimed to enhance the relevance and reliability of our analysis.

Fourth, since we target Java in our analysis, due to its popularity and its compatibility with our analysis tools, we selected only the repositories that contain at least 80\% of Java code. 
%Java is a widely used programming language that is compatible with the tools we employed for code similarity analysis. By focusing on Java repositories, we ensured that our examination of the methods was systematic and aligned with the capabilities of our analysis tools.

Lastly, we require that the selected repositories use Maven as a build tool. This criterion was established to ensure a consistent structure across the repositories, facilitating automation in our analysis and helping to manage the large volume of data involved. %By selecting projects built with Maven, we could streamline our processes and ensure that the repositories adhered to a common framework. 

These criteria led to the identification of 146 repositories protected by copyleft licenses. For each repository, we selected the latest version available before December 2020. %, to ensure that the analyzed code was likely processed during the training stage of \texttt{gpt-4-turbo}.

\textbf{Method Selection.} To identify the relevant methods for our analysis, we first extracted all the Java methods from the selected repository. 
%This extraction process involved gathering various metadata for each method, which were essential for subsequent steps in our analysis. The metadata collected included the project of origin, a unique identifier for the method, the file path from which the method was extracted, the method signature (comprising the method name and parameter types), the line number of the method declaration, the length of the method in terms of lines, and the length of any associated JavaDoc comments. 
This %comprehensive data collection 
resulted in the extraction of a set of 1,055,485 methods.
We excluded the test methods from the selection, resulting in a dataset of 879,337 methods. Then, we selected only the methods that meet specific criteria, motivated by the need to ensure the dataset consists of meaningful code for our analysis. Since the context of the study is the potential suggestion of code protected by copyleft licenses, only the reproduction of non-trivial methods could represent interesting and dangerous cases of unintended plagiarism. For this reason, we selected the methods with at least 10 non-empty lines of code. 
Additionally, to ensure that the documentation provides sufficient context and clarity regarding the method's purpose and usage, we required the JavaDoc of each method to have at least 100 characters and 4 non-empty lines. %To further enhance the quality of the documentation, we specified that the JavaDoc comments must exceed 100 characters, which helps to guarantee that the comments are detailed and informative rather than vague or superficial. 
These requirements led to the identification of 33,413 methods. % on which we calculated McCabe's complexity \cite{cyclomatic-complexity}.

\textbf{Method Sampling.} To sample a set of methods that can be feasibly processed from the identified methods, we randomly selected methods considering different sizes (i.e., locs) and complexities (i.e., McCabe complexity~\cite{cyclomatic-complexity}), guaranteeing that a diversity of cases occur in the final set of methods. In particular, we first computed the 33$^{rd}$ and 67$^{th}$ percentiles of the size and complexity of the selected methods. The 33$^{rd}$ and 67$^{th}$ percentiles of size are 16 locs and 27 locs, respectively. While the 33$^{rd}$ and 67$^{th}$ percentiles of complexity are 3 and 6, respectively. We then classified the methods as low/medium/high size if their size is strictly below 16 locs, between 16 and 27 locs (excluded), and above 27 locs, respectively. Similarly, we classified methods as low/medium/high complexity, if their complexity is strictly below 3, between 3 and 6 (excluded), or above 6, respectively. Table~\ref{tab:groups} shows the distribution of the 33,413 methods according to these categories.
%In this step, we ensured that the final dataset was representative and diverse. To facilitate this selection, we calculated the 33.33rd and 66.67th percentiles for various parameters, such as ad method length, JavaDoc comment length, and McCabe complexity~\cite{cyclomatic-complexity}. The results are shown in Table \ref{tab:percentiles} These percentiles provided useful thresholds for classifying methods into three categories: low, mid, and high. For instance, methods with fewer than 16 non-empty lines were classified as low, while those with more than 27 lines were considered high. Similarly, for complexity, methods with a complexity of fewer than 3 were classified as low, while those exceeding a complexity of 6 were categorized as high. After classifying the methods, the number of methods in each group was calculated, where group means the combination of categories for each parameter. The results are shown in table \ref{tab:groups}.
To select a large, but manageable, set of methods, we randomly selected 300 methods from within each group reported in Table~\ref{tab:groups}. To guarantee that a diversity of methods belonging to different source projects are selected from within each group, we divided the methods according to the project they have been extracted from, and we randomly selected a balanced set of methods from each project, based on the projects' availability. 
%This strategy ensured a good variety of methods, preventing any single group from dominating the dataset. However, it is important to note that 
For three out of the 27 groups containing less than 300 methods, we selected all the available methods. 
Thus, the final dataset %used in our experimentation 
consists of 7,347 methods.

%%%%%%%%%%%%% COMMENTATA %%%%%%%%%%%%%
\begin{comment}
\begin{table}
\centering
\begin{tabular}{c|c|c|c|}
\cline{2-4}
                                                  & \textbf{Method } & \textbf{JavaDoc } & \textbf{McCabe } \\ 
                                                 & \textbf{ Lines} & \textbf{ Characters} & \textbf{ Complexity} \\ \hline
\multicolumn{1}{|c|}{\textbf{33.33rd}} & 16                    & 188                         & 3                          \\ \hline
\multicolumn{1}{|c|}{\textbf{66.67th}} & 27                    & 325.1135                    & 6                          \\ \hline
\end{tabular}
\caption{Percentile Values} \label{tab:percentiles} \end{table}
\end{comment}
%%%%%%%%%%%%% COMMENTATA %%%%%%%%%%%%%



\begin{table}[ht]
\caption{Number of methods for each group: Method Lines (ML), McCabe Complexity (MC) and JavaDoc Characters (JC).}
   \setlength{\tabcolsep}{4pt}
\begin{tabular}{@{}llccccccccc@{}}
\toprule
\multicolumn{2}{c|}{\textbf{ML}}                                             & \multicolumn{3}{c|}{\textit{\textbf{Lo}}}                                               & \multicolumn{3}{c|}{\textit{\textbf{Me}}}                                               & \multicolumn{3}{c}{\textit{\textbf{Hi}}}                           \\ \midrule
\multicolumn{2}{c|}{\textbf{MC}}                                             & \textit{\textbf{Lo}} & \textit{\textbf{Me}} & \multicolumn{1}{c|}{\textit{\textbf{Hi}}} & \textit{\textbf{Lo}} & \textit{\textbf{Me}} & \multicolumn{1}{c|}{\textit{\textbf{Hi}}} & \textit{\textbf{Lo}} & \textit{\textbf{Me}} & \textit{\textbf{Hi}} \\ \toprule
\multicolumn{1}{c|}{}            & \multicolumn{1}{l|}{\textit{\textbf{Lo}}} & 3,407                & 1,326                & \multicolumn{1}{c|}{55}                   & 1,089                & 1,861                & \multicolumn{1}{c|}{425}                  & 378                  & 818                  & 1,893                \\ \cmidrule(l){2-11} 
\multicolumn{1}{l|}{\textbf{JC}} & \multicolumn{1}{l|}{\textit{\textbf{Me}}} & 2,928                & 1,348                & \multicolumn{1}{c|}{37}                   & 999                  & 1,795                & \multicolumn{1}{c|}{565}                  & 391                  & 902                  & 2,055                \\ \cmidrule(l){2-11} 
\multicolumn{1}{l|}{}            & \multicolumn{1}{l|}{\textit{\textbf{Hi}}} & 2,278                & 946                  & \multicolumn{1}{c|}{55}                   & 1,024                & 1,810                & \multicolumn{1}{c|}{333}                  & 370                  & 1,183                & 3,135                \\

\bottomrule
%\\
\addlinespace
\multicolumn{11}{l}{\textit{\textbf{Lo: Low, Me: Medium, Hi: High}}}                                                   
\end{tabular}
\label{tab:groups}
\end{table}



\begin{comment}
\begin{table}[ht]
\caption{Number of methods for each group: Method Lines (ML), McCabe Complexity (MC) and JavaDoc Characters (JC)}
   \setlength{\tabcolsep}{3.5pt}
\renewcommand{\arraystretch}{1.2}
\begin{tabular}{cc|ccc|ccc|ccc|}

\cline{3-11}
%\cmidrule(l){3-11} 
\multicolumn{2}{r|}{\textbf{ML}}                                  & \multicolumn{3}{c|}{\textit{Low}}                                                     & \multicolumn{3}{c|}{\textit{Mid}}                                                     & \multicolumn{3}{c|}{\textit{High}}                                                    \\ \cline{3-11} 
\multicolumn{2}{r|}{\textbf{MC}}                                  & \multicolumn{1}{c|}{\textit{Low}} & \multicolumn{1}{c|}{\textit{Mid}} & \textit{High} & \multicolumn{1}{c|}{\textit{Low}} & \multicolumn{1}{c|}{\textit{Mid}} & \textit{High} & \multicolumn{1}{c|}{\textit{Low}} & \multicolumn{1}{c|}{\textit{Mid}} & \textit{High} \\ \cline{2-11} 
\multicolumn{1}{c|}{\multirow{3}{*}{\textbf{JC}}} & \textit{Low}  & \multicolumn{1}{c|}{3407}         & \multicolumn{1}{c|}{1326}         & 55            & \multicolumn{1}{c|}{1089}         & \multicolumn{1}{c|}{1861}         & 425           & \multicolumn{1}{c|}{378}          & \multicolumn{1}{c|}{818}          & 1893          \\ \cline{2-11} 
\multicolumn{1}{c|}{}                             & \textit{Mid}  & \multicolumn{1}{c|}{2928}         & \multicolumn{1}{c|}{1348}         & 37            & \multicolumn{1}{c|}{999}          & \multicolumn{1}{c|}{1795}         & 565           & \multicolumn{1}{c|}{391}          & \multicolumn{1}{c|}{902}          & 2055          \\ \cline{2-11} 
\multicolumn{1}{c|}{}                             & \textit{High} & \multicolumn{1}{c|}{2278}         & \multicolumn{1}{c|}{946}          & 55            & \multicolumn{1}{c|}{1024}         & \multicolumn{1}{c|}{1810}         & 333           & \multicolumn{1}{c|}{370}          & \multicolumn{1}{c|}{1183}         & 3135          \\ \cline{2-11} 
\end{tabular}
\label{tab:groups}
%\vspace*{1mm}
\end{table}
\end{comment}


\subsection{Plagiarism Assessment}

%We evaluated the originality of the code generated by ChatGPT in response to various prompts designed around specific research questions (RQs). The assessment focuses on understanding how different prompt structures and contextual information influence the likelihood of generating code that may infringe on copyleft licenses. 

\textbf{Code generation.} %The design of prompts is a critical aspect of the code generation process, as it directly influences the responses generated by ChatGPT. 
In this study, we developed specific prompts to address each research question (RQs). The full text of the prompts is available in our dataset. %related to the potential for generating code that may infringe on copyleft licenses. Below, we detail the prompts used for each research question, highlighting their structure and intent.

To address RQ1, for each method in our dataset, we ask ChatGPT to generate a plausible implementation given the signature of the method and its JavaDoc description. %For example, we ask \texttt{\small Based on the following JavaDoc comment, generate the corresponding method: "Calculates the sum of two integers"}.\todo{Nel prompt non dovrebbe esserci anche la firma del metodo?} %This approach is specifically designed to explore whether ChatGPT generates code that resembles existing implementations when it is given only the JavaDoc comment as context. By doing so, it allows for an assessment of the model's tendency to plagiarize when provided with minimal contextual information.

To address RQ2, %which examines whether the context provided in the request influences the likelihood of returning code protected by copyleft licenses, 
we extend the prompt providing not only the signature of the method whose implementation has to be generated but also the rest of the code present in the class that embeds that method. In this way, we can study if the context may influence the likelihood possibly plagiarized code is returned by ChatGPT. %To this end, we compare the results obtained with the extended prompt to the prompt used for RQ1. 

%the prompt structure involves a clear task description that specifies the functionality required from the code. The context varies by including two different scenarios: one that presents only the JavaDoc comment followed by the method signature and another that also provides the entire class code. The instruction is to request the generation of code based on the provided context. This design facilitates a comparative analysis of how varying the context affects the likelihood of generating code that resembles existing implementations, thereby helping to understand the influence of context on the model's output.

To address RQ3, we consider a variant of the prompt used for RQ2, that is, we do not embed the full code of the class in the prompt, but we only add the access methods (i.e., getter and setter methods). This allows us to study whether the presence of common coding patterns like the presence of access methods may influence the likelihood of generating plagiarized protected code. 


%which investigates whether the inclusion of access methods in the prompt affects the probability of obtaining code protected by copyleft licenses, the prompt structure begins with a task description that specifies the functionality required from the code. This structure incorporates standard access methods, such as getters and setters, that are relevant to the task at hand. The instruction is to request the generation of code that utilizes the provided access methods. This approach aims to test whether the presence of common coding patterns, such as access methods, influences the likelihood of generating plagiarized code. It seeks to explore the relationship between standard coding practices and the originality of the output.

To address RQ4, we use the same prompt used for RQ1, but we configure ChatGPT to use different temperature values. RQ1 uses the default temperature value $1$, while RQ4 investigates the effect of using the temperature values $0$ (minimum creativity) and $2$ (maximum creativity).

%In the context of RQ4, which explores whether the temperature parameter of ChatGPT influences the likelihood of returning code protected by copyleft licenses, the prompt structure begins with a JavaDoc comment that clearly states the functionality required from the code. It also specifies the desired temperature setting, which can be low, medium, or high, to control the randomness of the output. The instruction is to request the generation of code based on the specified temperature. This structure facilitates an examination of how the temperature setting affects the originality of the generated code. By comparing outputs at different temperature levels, it becomes possible to assess the model's propensity for plagiarism.

%Finally, to address RQ5, %which investigates whether ChatGPT is capable of avoiding the generation of copied code when explicitly requested, 
%we extend the prompt used for RQ1 by clearly stating that we want ChaptGPT \texttt{``to not copy any known implementation''}, expecting the original code to be returned.


Finally, to address RQ5, we modify the prompt used for RQ1 by explicitly instructing ChatGPT to  ``\texttt{not copy any known implementation}''. Our goal with this instruction is to encourage the model to generate unique code rather than returning code that might be similar to any publicly available implementation, potentially reducing the risk of generating code that infringes copyleft licenses.



%original code not obtained from known sources. This is obtained by adding the sentence . 

To account for the potential non-determinism of the responses, we collected five responses for each request, and we used only the methods that produced valid responses in the study. In particular, for RQ1 and RQ2 we used 6,917 methods out of 7,347. For RQ3, we restricted the analysis to the methods that were reported as likely plagiarized with RQ2, which considers the class of the method as a context, and studied if they were still likely plagiarized when using the access methods only as context. We thus used 631 valid methods out of 675 selected methods. For RQ4 and RQ5, we restricted the analysis to the methods that were likely plagiarized according to RQ1 (only the method signature and JavaDoc comment used in the prompt), finally using 233 out of 239 selected methods. The invalid responses that slightly reduced the set of methods used in the experiment were due to ChatGPT returning incorrect signatures, truncated responses, or syntactic errors that prevented the automatic analysis of the response. Overall, to answer these research questions, we collected more than 70K method implementations.

\begin{comment}
\begin{itemize}
    \item \textbf{RQ1}: Out of 7,347 requests made, 6,917 methods were obtained for which it is possible to analyze the results.
    \item \textbf{RQ2}: Out of 7,347 requests made, 6,917 methods were obtained for which it is possible to analyze the results.
    \item \textbf{RQ3}: Out of 675 requests made, 631 methods were obtained for which it is possible to analyze the results.
    \item \textbf{RQ4}: Out of 7,347 requests made, 6,917 methods were obtained with temperature 0 for which it is possible to analyze the results; out of 239 requests made, 233 methods were obtained with temperature 2 for which it is possible to analyze the results.
    \item \textbf{RQ5}: Out of 239 requests made, 235 methods were obtained for which it is possible to analyze the results.
\end{itemize}
\end{comment}







%unsuccessful requests can be attributed to various reasons,which prevent automatic analysis of the generated code. Some errors were caused by incorrect signatures, such as the addition of unnecessary keywords or the replacement of existing keywords. Other issues arose from comments within the signature, which led to a mismatch between the original signature and the one returned by ChatGPT. Additionally, some responses were truncated due to exceeding the token limit, while syntactic errors, such as incorrect characters or consecutive periods, further complicated the code generation. Finally, in some cases, the generated code required additional completion by the end user, rendering the response incomplete.

\textbf{Plagiarism detection.} %We then analyzed the results obtained from the code generation requests submitted to ChatGPT, focusing on the metrics used to compute similarity and detect possible plagiarism.
We use two main metrics to assess the similarity between the code returned by ChatGPT and the method implementation protected by the copyleft license available in our dataset.

%\begin{itemize}[leftmargin=*]
    %\item 
    \emph{Similarity}: This metric represents the level of similarity between two methods that are compared. We use  JPlag~\cite{jplag}, a popular plagiarism detection tool, to quantify the similarity between two implementations. For this study, we employed the default configuration of JPlag, which does not incorporate token normalization, and we used JPlag's average similarity function as our similarity metric. JPlag measures similarity as the proportion of matching tokens that can be identified in the compared code. It is used to estimate with an index ranging between $0$ (totally dissimilar) and $1$ (totally similar) how likely an implementation is a plagiarized version of another implementation while abstracting from irrelevant syntactic changes. We use this metric to determine how likely the code recommended by ChatGPT can be considered the plagiarized version of the copyleft code.  In particular, for each method $m_{orig}$ used in the study, given a set of responses $m_i$ obtained by submitting the same request multiple times, we computed both the \emph{mean} and \emph{max similarity}, defined as the mean and max value of  $\{ \textit{similarity}(m_{orig}, m_i) \}$, respectively. The mean value represents the average case, while the max value represents the worst case, in terms of the plagiarized code that might be recommended to a developer. 
  %  That is, it measures  a comprehensive view of how closely related the two pieces of code are, taking into account all the tokens present in each submission.  The Average Similarity score ranges from 0 to 1, with higher values indicating greater similarity. This metric is particularly valuable for identifying potential cases of plagiarism, as it allows for an in-depth assessment of the extent of similarity between different code samples. By calculating average similarity, one can gain insights into the overall relationship between various pieces of code, facilitating a more informed analysis of potential intellectual property violations.
    
    %\item 
    \emph{Fuzzy Ratio}: We complement the similarity as computed by JPlag, which works at the token level, with a metric working at the character-level, that is more sensitive to irrelevant syntactic changes, but, for this same reason, better capturing \emph{nearly identical} copies of code. To this end, we used the fuzzy ratio, which is defined as one minus the ratio between the Levenshtein distance of the compared strings, computed as the single-character edits (insertions, deletions, or substitutions), and the maximum length of the strings. We used TheFuzz~\cite{fuzzy} to make this computation. The resulting value is between 0 and 1, with 1 indicating equals strings and $0$ totally dissimilar strings. Also for the fuzzy ratio, we compute the \emph{mean} and \emph{max fuzzy ratio}, as done for the similarity, to address the fact the same requests are repeated multiple times. 
    
    %    purely syntactic metric This is a syntactic similarity measure, calculated by TheFuzz \cite{fuzzy}, that captures only the syntactic differences between two pieces of code. It is calculated using the Levenshtein distance, which measures how many single-character edits (insertions, deletions, or substitutions) are required to change one string into another. We expressed the fuzzy ratio on a scale from 0 to 1, where a higher value indicates greater similarity. It is an effective metric for detecting minor variations in code that may suggest copying.
%\end{itemize}


%To analyze whether the various responses collected from ChatGPT for each type of request generate equivalent similarity values, we calculated and verified the variance among the values for average similarity and fuzzy ratio. Low variance values indicate that the data related to the various responses can be summarized with a single value, which approximates all responses due to the low variance. This approximation can be achieved by considering the average value that reflects the model's average tendency regarding plagiarism. It is important to note that low variance does not imply that the responses are identical, but rather that they have a similarity value relative to the original code that is equivalent or similar.

\smallskip 

To determine if plagiarism has occurred, it is necessary to establish a similarity threshold above which cases are considered suspicious. It is hard to establish an exact threshold, but any code reuse to represent the outcome of a potentially illegitimate action must have a lot in common with the source. For these reasons, rather than using a single hard threshold, we discuss results for similarity values above $0.7$, considering every possible threshold value with a step of $0.05$. To confirm our design choice to focus on cases above $0.7$, we inspected a selection of the responses provided by ChatGPT with similarity values spanning from $0.45$ to $0.95$. We could confirm that the vast majority of the cases with similarity above $0.7$ are indeed suspicious, while only a few cases with similarity below $0.7$ are suspicious. 
%This value of the threshold has also been used in similar studies \cite{}\todo{add cit}, corroborating our choice.


%To estimate this threshold, we manually inspected 36 methods  randomly selected responses and classified them as being likely the result of plagiarism or not. The ... \todo{add percentage} of the results with a level of similarity above $0.7$ were classified as plagiarism, while for lower levels the occurrences of possible plagiarism were much more uncertain and rare. We thus used this threshold when reporting the results. This value of the threshold has also been used in similar studies \cite{}\todo{add cit}, corroborating our choice. However, since this is not an exact threshold but an estimated threshold, we will report also results for higher values of these threshold, to account for the sensitivity of the results to the choice of the threshold.  

%This threshold is conservative and aims to classify only actual cases of suspected plagiarism, reducing the likelihood of false positives while increasing the risk of false negatives. It has been observed that methods with a similarity above 0.7 can be considered cases of suspected plagiarism \cite{}. However, even below this threshold, there may still be instances of plagiarism, albeit less frequently.



\textbf{Analysis of the Results.} We conducted a statistical analysis to assess the influence of various factors on the likelihood of obtaining code that resembles copyleft code. As factors, we studied the influence of the context (RQ2 and RQ3), the temperature (RQ4), and the prompt (RQ5). 


To answer RQ1, we compute the mean and maximum similarity and fuzzy scores, for the whole set of methods in the dataset. 
To answer the rest of the research questions (RQ2-RQ5), we compute the differences between the (mean and maximum) similarity and fuzzy scores of corresponding methods whose code is obtained by changing one factor in the request. That is, for each score (mean similarity, max similarity, mean fuzzy ratio, and max fuzzy ratio), we compute for each method $m$ the value $\textit{score}(m)_{\textit{base-request}}-\textit{score}(s)_{\textit{changed-factor}}$, where \textit{base-request} is the request as formulated for RQ1, and the \textit{changed-factor} is the same request with a factor modified according to the research question (RQ2 and RQ3 use a different context, RQ4 a different temperature value, and RQ5 a different prompt). 
A value of 0 indicates that the compared scores are identical for the considered method, while a negative (positive) value indicates that the case with the changed factor leads to code that has a higher (lower) similarity to the copyleft code. The distribution of these differences is indicative of how the studied factor influences the results on a per-method basis.

To further study the impact of each factor, we also compare the population of all score values (mean similarity, max similarity, mean fuzzy ratio, and max fuzzy ratio) for the code obtained with the \textit{base-request} and the \textit{changed-factor}.
We check for the presence of any statistically significant difference ($\alpha = 0.05$) between the compared populations using the Wilcoxon signed-rank test~\cite{test-wilcoxon}, and we compute the effect size $r$ of the significant differences~\cite{cohen2013statistical}, to discover any very small ($ |r| < 0.1 $), small ($ 0.1 \leq |r| < 0.3 $),  medium ($ 0.3 \leq  |r| < 0.5 $),  and large ($ |r| \geq 0.5 $) effect, which is indicative of the practical significance of the observed phenomena.  




%The parameters considered include the text of the prompt, the temperature value, and the context provided in the request. By analyzing these factors, we aimed to determine their impact on the likelihood of generating code that closely resembles existing code.
%To assess the effect of these parameters, we compared the results obtained under different conditions. Specifically, we focused on how variations in the prompt text and temperature settings influenced the average similarity and fuzzy ratio values. The temperature parameter, which controls the randomness of the model's responses, was varied to observe its effect on the similarity metrics. A higher temperature typically results in more diverse outputs, while a lower temperature tends to produce more deterministic and potentially similar responses.

%We employed statistical methods to analyze the variance among the similarity values generated under different parameter settings. This analysis involved calculating the variance for both average similarity and fuzzy ratio metrics across different contexts. Low variance values across responses indicate that the generated code maintains a consistent level of similarity, suggesting that the parameters may not significantly alter the output regarding plagiarism potential.
%In addition, we calculated the differences in similarity measures obtained from different types of requests. This involved determining the difference between the average similarity and fuzzy ratio values for each method across the various requests. Negative values indicated a greater similarity obtained with one type of request compared to another, zero values indicated no variation in similarity, while positive values indicated a greater similarity obtained with the other type of request.

%It is noteworthy that, especially in cases where a direct difference between two values is calculated, the fuzzy ratio is not very indicative, as it is sensitive to even the slightest syntactic differences. For example, if a method has an average similarity value of 1 in two different requests, it means that in both requests a semantically identical method to the original is generated. However, the fuzzy ratio may vary significantly between the two requests, for instance, if the name of one or more variables changes. In cases where zero differences are considered, very few methods will have a fuzzy ratio difference of 0, compared to methods that will not have an average similarity difference.

%To verify whether the observed differences in similarity metrics were statistically significant, we employed the Wilcoxon signed-rank test \cite{test-wilcoxon}. This non-parametric test is suitable for paired samples and does not assume a normal distribution of the data. It calculates the differences between paired observations, ranks these differences, and then assesses whether the sums of the ranks for positive and negative differences are significantly different.

%The null hypothesis (H0) posits that the median of the differences between the paired samples is zero, indicating no significant differences between the two conditions. Conversely, the alternative hypothesis (H1) suggests that the median of the differences is not equal to zero, indicating a significant difference between the two conditions.

%In our analysis, we set a significance level of $\alpha = 0.05$. The results indicated that for average similarity measures in cases of medium plagiarism, the p-value was greater than $\alpha$, suggesting no significant difference between the groups. However, the fuzzy ratio indicated a significant difference ($p$-value $<$ $\alpha$), highlighting its sensitivity to syntactic variations that can lead to nearly identical responses having markedly different fuzzy ratio values. Therefore, while the fuzzy ratio is a useful metric, it should not be used in isolation to determine the significance of differences.

%Furthermore, we calculated the effect size \cite{cohen2013statistical} to quantify the magnitude of the differences observed. The effect size provides additional context to the statistical significance by indicating how substantial the differences are in practical terms. A larger effect size suggests a more meaningful difference between the groups, while a smaller effect size may indicate that even statistically significant results may not be practically relevant. 

%The effect size (r) was calculated using the formula \cite{cohen2013statistical}:
%\begin{equation}
%    r = \frac{Z}{\sqrt{n}}
%\end{equation}

%where $Z$ is the standardized test statistic from the Wilcoxon signed-rank test, and $n$ is the total number of observations (i.e., the sum of the sizes of the two groups). 
%The interpretation of the effect size value is as follows: $ |r| < 0.1 $ indicates no effect or a very small effect, $ 0.1 \leq |r| < 0.3 $ indicates a small effect, $ 0.3 \leq |r| < 0.5 $ indicates a medium effect, and $ |r| \geq 0.5 $ indicates a large effect.

%This analysis of effect size complements our findings from the Wilcoxon signed-rank test, allowing for a more comprehensive understanding of the impact of the parameters on plagiarism detection metrics. A larger effect size indicates that the differences observed are not only statistically significant but also practically meaningful, suggesting that the parameter variations have a substantial impact on the similarity metrics used in plagiarism detection.



