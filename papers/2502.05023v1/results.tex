\label{sec:Res}
This section presents the results obtained by evaluating the code generated by ChatGPT in response to various prompts designed to explore the potential for generating code covered by copyleft licenses. %The presentation is structured around the five RQs outlined in the methodology.

\subsection{RQ1: Can ChatGPT return code protected by copyleft licenses?}

To answer this research question, we prompted ChatGPT for the implementation of the methods in our dataset starting from the method's signature and its JavaDoc comment, which served as a minimal directive for the model. We maintained the temperature to its default value (i.e., $1$). 

As illustrated in Figures~\ref{fig:similarity_distribution} and~\ref{fig:max_similarity_distribution}, the analysis of the responses reveals that the significant majority of the obtained implementations (i.e., 82.67\% for mean and max similarities) have a similarity score equals to $0$. This indicates that the generated code is significantly different from the copyleft code available in the dataset, and only occasionally the generated code closely mirrors existing implementations.


\begin{figure} \centering \includegraphics[width=0.4\textwidth]{imgs/fig-similarity_distribution_javadoc.png} 
\vspace{-10pt} 

\caption{Distribution of similarity scores for \emph{mean similarity}.} \label{fig:similarity_distribution} 
\vspace{-5pt} 
\end{figure}

\begin{figure} 
\centering 
\includegraphics[width=0.4\textwidth]{imgs/fig_max_similarity_distribution_javadoc.png} 
\vspace{-10pt} 

\caption{Distribution of similarity scores for \emph{max similarity}.} 
\label{fig:max_similarity_distribution} 
\vspace{-5pt} 
\end{figure}

%In the case of maximum similarity shown in Figure \ref{fig:max_similarity_distribution}, we observe that, as expected due to the use of higher similarity values, a greater number of methods exhibit higher similarity scores compared to the average similarity case. Notably, there are more instances with a similarity score of 1. This suggests that while most generated outputs are distinct, some closely mirror existing implementations, raising concerns about potential copyright infringement. Despite this increase in similarity scores, the overall distribution pattern remains consistent with that of the mean similarity.

The fuzzy ratio measuring syntactic similarity is slightly higher than mean and max similarities because some common syntactic elements could be found even between rather diverse implementations. Yet the vast majority of the code has a low fuzzy ratio.% it is more sensitive to small syntactic changes, which can lead to significant differences in its values even when the underlying logic remains similar.\todo{Credo sia l'opposto, il grafico mostra maggiore similaritÃ  ma il commento dice la cosa opposta}

We zoom into the cases with suspicious similarity levels reporting in Table~\ref{tab:count_methods_similarity} the percentage of methods with a similarity above $0.7$. Specifically, 102 methods (1.48\%) have a mean similarity above 0.70, while 232 methods (3.35\%) exceed this threshold for maximum similarity. These results indicate that, although infrequent, some responses warrant caution in reuse. 

For instance, consider the method from our dataset presented in Listing~\ref{code}. Creating an implementation based solely on its JavaDoc comment and signature poses significant challenges. However, ChatGPT managed to generate code, as shown in Listing~\ref{generatedCode}, that closely resembles the original, achieving a similarity score of $1.0$ and a fuzzy ratio of $0.86$. This generated code incorporates only minor modifications that enhance readability while preserving the functionality, even delivering the same output messages through \texttt{System.out} statements.


\noindent \fbox{\parbox{0.98\columnwidth}{\textbf{Answer to RQ1} ChatGPT seldom generates code potentially violating copyleft licenses (3.35\% of the cases in the worst case). Yet, users cannot entirely ignore the risk of incidentally using the copyleft code.}}



\begin{table}[]
    \centering
\caption{Count of methods for mean similarity values.} 
\begin{tabular}{c|c|c}
\toprule
\textbf{Similarity}             & \textbf{Mean Similarity} & \textbf{Max Similarity} \\
\textbf{Values}                 & \textbf{Frequency}       & \textbf{Frequency}      \\ \midrule
1.00                            & 11 (0.16\%)              & 61 (0.88\%)             \\
{[}0.95, 1.00{]}                & 8 (0.12\%)               & 12 (0.17\%)             \\
{[}0.90, 0.95{]}                & 11 (0.16\%)              & 23 (0.33\%)             \\
{[}0.85, 0.90{]}                & 11 (0.16\%)              & 29 (0.42\%)             \\
{[}0.80, 0.85{]}                & 19 (0.27\%)              & 36 (0.52\%)             \\
{[}0.75, 0.80{]}                & 13 (0.19\%)              & 34 (0.49\%)             \\
{[}0.70, 0.75{]}                & 29 (0.42\%)              & 37 (0.53\%)             \\ \midrule
\textbf{Total {[}0.70, 1.00{]}} & \textbf{102 (1.48\%)}    & \textbf{232 (3.35\%)}   \\ \bottomrule
\end{tabular}
%\vspace*{1mm}
\label{tab:count_methods_similarity}
\end{table}

%\begin{lstlisting}[language=Java,caption={An Example of a Method from Our Dataset.}, basicstyle=\small\ttfamily,breaklines=true,columns=fullflexible, frame=single, label=code]

\noindent
\begin{minipage}{1\linewidth} 
\begin{lstlisting} [label=code,frame=single,caption={An example of a method from our dataset.}]
/**
 * To solve this question, we just need to count the
 * number of persons that overtake a particular 
 * person.
 *
 * @param q the queue
 */
private static void minimumBribes(int[] q) {
  int bribes = 0;
  for (int i = q.length - 1; i >= 0; i--) {
    if (q[i] - i - 1 > 2) {
      System.out.println("Too chaotic");
      return;
    }
    for (int j = Math.max(0, q[i] - 2); j < i; j++) {
      if (q[j] > q[i]) bribes++;
    }
  }
  System.out.println(bribes);
}   
\end{lstlisting} 
\end{minipage}
\noindent
%[basicstyle=\small\ttfamily,breaklines=true,columns=fullflexible, frame=single, label=generatedCode,caption={Method Generated by ChatGPT.}]
\noindent
\begin{minipage}{1\linewidth} 

\begin{lstlisting} [label=generatedCode,frame=single,caption={Method generated by ChatGPT.}]
private static void minimumBribes(int[] q) {
  int bribes = 0;
  for (int i = 0; i < q.length; i++) {
    if (q[i] - (i + 1) > 2) {
      System.out.println("Too chaotic");
      return;
    }
    for (int j = Math.max(0, q[i] - 2); 
                                    j < i; j++) {
      if (q[j] > q[i]) {
        bribes++;
      }
    }
  }
  System.out.println(bribes);
}   
\end{lstlisting} \end{minipage}
\noindent

\subsection{RQ2: Does the context provided in the request influence the likelihood of returning code protected by copyleft licenses?}

RQ2 investigates whether the context provided in the requests to ChatGPT affects the likelihood of generating code protected by copyleft licenses. %The context can significantly shape the output, which may guide the model towards more specific responses.
To analyze the influence of context on the code generation capabilities of ChatGPT, we compared results obtained with minimal information (i.e., the method signature and the JavaDoc comment already used in RQ1) to an extensive context that includes the code present in the class with the method. The goal is to determine if a broader context increases the chances of generating code similar to the existing code. 

For example, consider the method \texttt{getSpeakerBytes()} of the CoreNLP project present in our dataset. When we prompted ChatGPT using only the method's signature and JavaDoc comment, the generated implementation exhibited substantial differences compared to the existing copyleft code. 
However, when we provided the rest of the class as context, ChatGPT produced variants of this method that closely mirrored the original implementation. This resulted in a similarity score of $1$, raising significant concerns regarding potential intellectual property infringement.

Figure~\ref{fig:similarity_differences_in_mean_similarity} (left side) shows the distribution of the difference between the mean similarity obtained with minimal context (i.e., methods signature and JavaDoc) and the mean similarity obtained with the class context (i.e., all the code in the class except the body of the method that has to be generated) for each method. Figure~\ref{fig:similarity_differences_in_mean_similarity} (right side) reports the same information for the mean fuzzy ratio.  Analogously, Figure~\ref{fig:similarity_differences_in_max_similarity} shows the same differences when max similarity and max fuzzy ratio are considered.%\todo{forse sarebbe preferibile mettere nelle figure sempre mean e max prima di similarity e fuzzy ratio}

We can observe a general prevalence of cases with differences equal to $0$, that is, the mean similarity and the fuzzy ratio of the generated code are the same for both contexts. On the other hand, all the distributions are skewed on the left, that is, the context affects the similarity for several cases, increasing the chance of generating code similar to already existing copyleft code.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/similarity_differences_in_mean_similarity.png}
    \vspace{-10pt} 
    
    \caption{Difference between JavaDoc comment and whole class in the case of mean similarity.}
    \label{fig:similarity_differences_in_mean_similarity}
    \vspace{-5pt} 
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/similarity_differences_in_max_similarity.png}
    \vspace{-10pt} 
    
    \caption{Difference between JavaDoc comment and whole class in the case of max similarity.}
    \label{fig:similarity_differences_in_max_similarity}
    \vspace{-5pt} 
\end{figure}



Figures~\ref{fig:similarity_javadoc_vs_file_in_mean_similarity} and~\ref{fig:similarity_javadoc_vs_file_in_max_similarity} present the distribution of the mean and max similarity values, as well as mean and max fuzzy ratio, respectively. The boxplots indeed show that methods generated with the broader context exhibit higher similarity and fuzzy ratio values than those generated with only the JavaDoc comment. 
A Wilcoxon test ($\alpha = 0.05$) confirmed differences are significant for mean similarity, max similarity, mean fuzzy ratio, and max fuzzy ratio.  The effect sizes of the mean and max similarities are -0.7330 and -0.7434, respectively, indicating that the context is not only significant but also introduces a \emph{large} effect on similarity values. 

\begin{figure}[ht] \centering \includegraphics[width=0.4\textwidth]{imgs/similarity_javadoc_vs_file_in_mean_similarity.png} 
\vspace{-10pt} 

\caption{Similarity Scores for JavaDoc comment and whole class contexts in the case of mean similarity.} 
\vspace{-5pt} 

\label{fig:similarity_javadoc_vs_file_in_mean_similarity} \end{figure}


\begin{figure}[ht] \centering \includegraphics[width=0.4\textwidth]{imgs/similarity_javadoc_vs_file_in_max_similarity.png} 
\vspace{-10pt} 

\caption{Similarity Scores for JavaDoc comment and whole class contexts in the case of max similarity.} 
%\vspace{-5pt} 

\label{fig:similarity_javadoc_vs_file_in_max_similarity} \end{figure}

%These results show that a broad matching context can indeed induce ChatGPT in generating code that mirrors existing code. 





%In the case of max similarity, the results further emphasize the impact of context on code generation. When the highest similarity values are selected, there is a marked increase in the number of methods exhibiting extreme similarity scores, while the number of methods with similarity scores close to zero decreases. This trend suggests that some responses lead to a higher likelihood of generating methods that closely resemble existing code, thereby increasing the potential for plagiarism. Figures \ref{fig:similarity_differences_in_max_similarity} and \ref{fig:similarity_javadoc_vs_file_in_max_similarity}  reveal a clear upward shift in similarity metrics, indicating that providing the surrounding class as context results in significantly higher similarity scores compared to using only the JavaDoc comment. This reinforces the findings from RQ2, demonstrating that a broader context not only influences the likelihood of generating copyleft-protected code but also enhances the overall similarity of the generated methods to existing implementations.



%The Wilcoxon test was employed to determine whether the differences in similarity values were statistically significant. The p-values obtained from the Wilcoxon test for both mean and max similarity were all less than the significance level of $\alpha = 0.05$. This indicates that there is a statistically significant difference between the similarity scores generated with the two contexts. Specifically, for both cases of similarity (mean and max), the similarity and fuzzy ratio yielded p-values of zero, confirming that the differences are not only significant but also robust across the two metrics. Furthermore, the effect size values reinforce the findings of the Wilcoxon test. The effect sizes for both mean and max similarity cases were substantial, with values indicating a strong effect. For similarity, the effect size was -0.7330 for mean similarity and -0.7434 for max similarity. These negative values suggest that using also the surrounding class as context leads to significantly higher similarity scores compared to using only the JavaDoc comment.

The strong effect sizes across all metrics indicate that the context provided to ChatGPT plays a crucial role in determining the similarity of the generated code with the already existing one. %This further supports the hypothesis that a broader context not only increases the likelihood of generating code that closely resembles existing implementations but also enhances the overall similarity metrics. The findings highlight the importance of context in guiding the output of AI models like ChatGPT, particularly in scenarios where the risk of plagiarism is a concern.
%In conclusion, the analysis demonstrates that providing a more comprehensive context significantly influences the likelihood of generating code that mirrors existing works, thereby increasing the potential for plagiarism. The statistical significance and strong effect sizes observed in the results underscore the necessity for careful consideration of the context when utilizing AI for code generation.

We also examined how many responses achieve a \textit{mean similarity} and a \textit{max similarity} above the threshold of $0.70$. The results, shown in Table~\ref{tab:count_methods_similarity_file}, indicate a significant increase in the number of methods across all ranges compared to those reported with the context limited to the JavaDoc comment. Notably, the percentage of potentially plagiarized methods increases from 1.48\% to 9.73\% (6.5X increase) in the case of \textit{mean similarity}. This percentage raises from 3.35\% to 19.50\% (5.8X increase) in the case of \textit{max similarity}. In both scenarios, the total number of potential plagiarisms is more than quintupled, reaching significant percentages.

\begin{table}[ht] \begin{center}
\caption{Count of methods for similarity values over threshold.}
\begin{tabular}{c|c|c}
\toprule
\textbf{Similarity}             & \textbf{Mean Similarity} & \textbf{Max Similarity} \\
\textbf{Values}                 & \textbf{Frequency}       & \textbf{Frequency}      \\ \midrule
1.00                            & 214 (3.09\%)             & 612 (8.85\%)            \\
{[}0.95, 1.00{]}                & 72 (1.04\%)              & 94 (1.36\%)             \\
{[}0.90, 0.95{]}                & 74 (1.07\%)              & 84 (1.21\%)             \\
{[}0.85, 0.90{]}                & 66 (0.95\%)              & 122 (1.76\%)            \\
{[}0.80, 0.85{]}                & 90 (1.30\%)              & 159 (2.30\%)            \\
{[}0.75, 0.80{]}                & 77 (1.11\%)              & 137 (1.98\%)            \\
{[}0.70, 0.75{]}                & 80 (1.16\%)              & 141 (2.04\%)            \\ \midrule
\textbf{Total {[}0.70, 1.00{]}} & \textbf{673 (9.73\%)}    & \textbf{1349 (19.50\%)} \\ \bottomrule
\end{tabular}
%\vspace*{1mm}

 \label{tab:count_methods_similarity_file}
\end{center}\end{table}

\noindent \fbox{\parbox{0.98\columnwidth}{\textbf{Answer to RQ2} If the class context is part of the prompt, the probability that the recommended method implementation resembles copyleft code increases by a factor greater than $5X$. This suggests that inadvertently accepting code recommendations that mirror already existing code may increase the chance of receiving additional recommendations of plagiarized code in the future, exposing developers to the risk of accumulating a non-trivial amount of unwanted copyleft code in their implementation.}}


 \subsection{RQ3: Does providing a context with only access methods affect the likelihood of obtaining code protected by copyleft licenses?}

Since RQ2 determined that the context is a significant factor, RQ3 investigates if contexts smaller than the entire code in the class may also affect the results. In particular, it considers the case where the context carries little information, just retaining some syntactic similarity with an existing copyleft class. Specifically, it investigates if including the same \emph{access methods} (i.e., getter and setter methods) present in an existing copyleft class may alter the likelihood of receiving a recommendation with a possibly plagiarized method from that same copyleft class.
%that are not highly characteristic of the class from which the method is extracted can incentivize ChatGPT to produce plagiarized content. The body of the message includes the access methods present in the code file from which the method was extracted.

To examine the impact of access methods, we compare the similarity values obtained by using two distinct contexts in the prompt: one case uses the JavaDoc comment and the method's signature (see RQ1), while the other case adds the access methods in the class to the context. %By setting the temperature parameter to 1, we aimed to maintain a high level of variability in the generated outputs while isolating the impact of the context provided.

Figure~\ref{fig:similarity_differences_acess_in_mean_similarity} (left side) shows the distribution of the differences between the mean similarity values obtained with minimal context (i.e., methods signature and JavaDoc) and the mean similarity obtained with access methods.  Figure~\ref{fig:similarity_differences_acess_in_mean_similarity} (right side) reports the same information for the mean fuzzy ratio. Analogously, Figure~\ref{fig:similarity_differences_acess_in_max_similarity} shows the same differences when max similarity and max ratio are considered.

While several methods show no difference in similarity and fuzzy ratio values, distribution is skewed on the left, that is, the presence of access methods affects similarity, increasing the chance of generating code similar to existing copyleft code.


%The analysis revealed that providing also access methods as context results in higher similarity scores compared to using only the JavaDoc comment. This suggests that a more comprehensive context allows ChatGPT to access a richer set of information, thereby increasing the chances of generating code that closely aligns with existing implementations.

%Figure \ref{fig:similarity_differences_acess_in_mean_similarity} illustrates the differences in similarity values for mean similarity cases. It shows a high number of methods with a similarity difference of zero and a significant amount of negative values, indicating that including access methods as context leads to greater similarity compared to using only the JavaDoc comment. The distribution skews left, with many values near zero, suggesting that methods generated with a broader context are more closely aligned with the originals. In contrast, the right side of the graph displays few positive values, where the JavaDoc comment context results in greater similarity, but these instances are rare and also close to zero.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/similarity_differences_acess_in_mean_similarity.png}
    \vspace{-10pt} 
    
    \caption{Differences in similarity for cases of mean similarity.}
    \label{fig:similarity_differences_acess_in_mean_similarity}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/similarity_differences_acess_in_max_similarity.png}
    \vspace{-10pt} 
    
    \caption{Differences in similarity for cases of max similarity.}
    \label{fig:similarity_differences_acess_in_max_similarity}
\end{figure}

The plots of mean similarity and fuzzy values (Figure~\ref{fig:similarity_differences_acess_in_mean_similarity}), as well as the plot of max similarity and fuzzy values (Figure~\ref{fig:similarity_differences_acess_in_max_similarity}), show a significant impact of access methods on the level of similarity of the recommended code to the copyleft code. 

 

%When analyzing max similarity, the results obtained by selecting the highest similarity values are visualized in Figure \ref{fig:similarity_differences_acess_in_max_similarity}. Unlike the mean similarity case, where many methods had differences close to zero, the max similarity scenario shows a decrease in the number of methods with differences close to zero. Consequently, there is an increase in the number of methods with higher similarity values.
%Figure \ref{fig:similarity_javadoc_vs_access_in_max_similarity} reveals that the max similarity values for the access methods show a significant upward shift from the mean similarity case. This confirms, as shown for RQ2, that the choice of context has a profound impact on similarity scores.

\begin{figure}[h] \centering \includegraphics[width=0.4\textwidth]{imgs/similarity_javadoc_vs_access_in_mean_similarity.png} 
\vspace{-10pt} 

\caption{Similarity Scores for different contexts in the case of mean similarity.} \label{fig:similarity_javadoc_vs_access_in_mean_similarity} \end{figure}


\begin{figure}[h] \centering \includegraphics[width=0.4\textwidth]{imgs/similarity_javadoc_vs_access_in_max_similarity.png} 
\vspace{-10pt} 

\caption{Similarity Scores for different contexts in the case of max similarity.} \label{fig:similarity_javadoc_vs_access_in_max_similarity} \end{figure}

The results of the Wilcoxon signed-rank test confirm the statistically significant difference in all similarity scores between the two contexts ($p < 0.05$), with access methods leading to higher similarity. 
Additionally, the effect size indicates a large difference in mean and max similarity, and a medium difference in mean and max fuzzy ratio, indicating that the inclusion of access methods is not only statistically significant but also practically relevant for the generated similarity scores.

\begin{table}[ht]\begin{center}
\caption{Count of methods for similarity values over threshold} 

\begin{tabular}{c|c|c}
\toprule
\textbf{Similarity}             & \textbf{Mean Similarity} & \textbf{Max Similarity} \\
\textbf{Values}                 & \textbf{Frequency}       & \textbf{Frequency}      \\ \midrule
1.00                            & 10 (1.58\%)              & 34 (5.39\%)             \\
{[}0.95, 1.00{]}                & 8 (1.27\%)               & 22 (3.49\%)             \\
{[}0.90, 0.95{]}                & 7 (1.11\%)               & 10 (1.58\%)             \\
{[}0.85, 0.90{]}                & 6 (0.95\%)               & 14 (2.22\%)             \\
{[}0.80, 0.85{]}                & 11 (1.74\%)              & 11 (1.74\%)             \\
{[}0.75, 0.80{]}                & 9 (1.43\%)               & 15 (2.38\%)             \\
{[}0.70, 0.75{]}                & 10 (1.58\%)              & 12 (1.90\%)             \\ \midrule
\textbf{Total {[}0.70, 1.00{]}} & \textbf{61 (9.66\%)}     & \textbf{118 (18.70\%)}  \\ \bottomrule
\end{tabular} 
%\vspace*{1mm}

\label{tab:count_methods_similarity_access} \end{center}
\end{table}

We further examined the number of methods with mean and max similarity exceeding the threshold of 0.70.
The results, as detailed in Table~\ref{tab:count_methods_similarity_access}, indicate a significant increase in the number of methods that exceed the plagiarism threshold when using access methods as context. Specifically, the proportion of methods classified as potentially plagiarized in the mean similarity case increased from 4.12\% to 9.66\% (2,3X increase), and the percentage increased from 9.19\% to 18.70\% (2X increase) for max similarity, presenting a $2X$ increase factor. 

%These results show how even a context carrying little information may induce the generation of code recommendations that mirror existing copyleft code.  

\noindent \fbox{\parbox{0.98\columnwidth}{\textbf{Answer to RQ3} Including access methods in the context affects the likelihood of generating plagiarized code by a factor of about $2X$. This result further confirms how incrementally accepting recommendations of plagiarized code can expose 
developers to an increasingly higher risk of accumulating unwanted code protected by copyleft licenses in their implementation.}}

%These findings highlight the importance of context in influencing the likelihood of generating code that may infringe on existing licenses. The substantial increase in the number of methods exceeding the similarity threshold when using access methods suggests that a more comprehensive context not only enhances the quality of the generated code but also raises the risk of unintentional plagiarism.

\subsection{RQ4: Does adjusting the temperature parameter alter the likelihood of obtaining code protected by copyleft licenses?}

RQ4 investigates the role of temperature in the likelihood of generating code that may break copyleft licenses. We thus investigated the impact of reducing the temperature from 1 to 0, computing the difference in the mean and max similarity and fuzzy ratio for all the methods in the dataset.

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/hist_diff_temperature_01_avg.png}
    \vspace{-10pt} 
    
    \caption{Difference between temperature 0 and 1 in the case of mean similarity.}
    \label{fig:hist_diff_temperature_01_avg}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/hist_diff_temperature_01_max.png}
    \vspace{-10pt} 
    
    \caption{Difference between temperature 0 and 1 in the case of max similarity.}
    \label{fig:hist_diff_temperature_01_max}
\end{figure}


The results of this comparison are visually represented in Figure \ref{fig:hist_diff_temperature_01_avg} for mean similarity and fuzzy ratio, and Figure \ref{fig:hist_diff_temperature_01_max} for max similarity and fuzzy ratio. We can observe that for most methods, the responses yielded similar similarity values (i.e., most of the differences close to 0). Specifically, 83.11\% of the methods reported the same value for mean similarity, while 86.11\% reported the same value for max similarity. For the remaining methods, the difference is very close to zero, with a slight bias toward greater plagiarism at temperature 1. However, the distribution of values is dense around 0 and balanced, suggesting that differences are not substantial. This is confirmed by a two-tailed Wilcoxon signed-rank test ($\alpha = 0.05$), indicating significance for max similarity ($\textit{p-value} = 8.66 \times 10^{-105}$), max fuzzy ratio ($\textit{p-value} = 0$) and mean fuzzy ratio ($\textit{p-value} = 3.91 \times 10^{-08}$), but not for mean similarity ($\textit{p-value} = 0.61$). 

The difference in the fuzzy ratio can be likely attributed to the sensitivity of the metric to small syntactic variations of the code. The difference in max similarity and not for mean similarity shows a mild impact of temperature affecting results in terms of the highest similarity that can be observed across five repetitions, but not affecting the mean value. 

The distributions that are slightly skewed towards positive values show that code with higher similarity is generated with a temperature equal to $1$. The percentage of potentially plagiarized methods is 1.48\% with temperature 1 and 1.89\% with temperature 0, according to mean similarity. The potentially plagiarized methods raise to 2.05\% for temperature equal to 0 and 3.35\% for temperature equal to 1, according to max similarity. Again, these values confirm the mild impact of temperature. %Despite the significant differences in similarity values, the number of methods with mean similarity above the threshold of 0.70 did not vary significantly, which can be attributed to greater variation in values below this threshold.

We finally investigated if the maximum temperature value can reduce the similarity of code compared to the default value of temperature equal to $1$. For this investigation, we used the methods that result in a similarity higher than 0.9 in at least one of the requests for a temperature equal to 1, focusing on the methods that are most exposed to the risk of plagiarism. 

The results of this comparison are illustrated in Figure~\ref{fig:hist_diff_temperature_12_avg} for mean similarity and Figure~\ref{fig:hist_diff_temperature_12_max} for max similarity.
In both cases, we observe a greater number of positive differences, indicating that responses obtained with temperature 2 are generally less similar to the original code than those with temperature 1. Specifically, a substantial percentage of methods reported lower similarity values with temperature 2, highlighting the effectiveness of the higher temperature in promoting variability and originality.


%In this analysis, we find that the responses generated at temperature 2 exhibit a significant increase in variability compared to those at temperature 1. This suggests that raising the temperature parameter encourages a broader range of outputs, potentially reducing the likelihood of similarity to existing content. 



\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/hist_diff_temperature_12_avg.png}
    \vspace{-10pt} 
    
    \caption{Difference between temperature 1 and 2 in the case of mean similarity.}
    \label{fig:hist_diff_temperature_12_avg}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/hist_diff_temperature_12_max.png}
    \vspace{-10pt} 
    
    \caption{Difference between temperature 1 and 2 in the case of max similarity.}
    \label{fig:hist_diff_temperature_12_max}
\end{figure}

The analysis using the two-tailed Wilcoxon signed-rank test ($\alpha = 0.05$) confirmed that mean and max similarity differences are significant (p-values equal to $9.94 \times 10^{-13}$ and $4.04 \times 10^{-10}$). Effect sizes of 0.4980 and 0.5804, further support this finding, capturing how responses generated at temperature 2 are largely and moderately different from those generated at temperature 1, for max and mean similarity respectively.   

%It is also important to note that when considering fuzzy ratio values, small effects are observed in both cases of similarity. This may suggest that, although the fuzzy ratio can detect syntactic variations, its sensitivity to such variations is insufficient to highlight significant differences in terms of originality. 

Regarding the number of methods above the threshold, using temperature equal to $2$, they decreased from 84 to 63 for mean similarity and from 156 to 132 for max similarity, with a reduction percentage of 9.01 and 10.31, respectively. 

%noted that for mean similarity, the percentage of potentially plagiarized methods decreased from 36.06\%  with temperature 1 to 27.04\% with temperature 2. Similarly, for max similarity, the percentage of responses identified as potentially plagiarized dropped from 66.95\% with temperature 1 to 56.65\% with temperature 2. This trend underscores the effectiveness of higher temperature settings in producing more original outputs, as evidenced by the significant reduction in the number of methods exceeding the similarity threshold of 0.70.

We can thus conclude that higher temperature values (i.e., temperature equal to 2) promote the generation of original code, with lower temperature values (i.e., temperature between 0 and 1) having a mild effect on code similarity. However, the recommendation of using high-temperature values to avoid unwanted plagiarism has to be carefully balanced with settings recommended for code generation, where low-temperature values tend to produce better results~\cite{arora2024optimizing,ouyang2023empirical,liu2024your}.  

\noindent \fbox{\parbox{0.98\columnwidth}{\textbf{Answer to RQ4} Temperature values of   $0$ and $1$ have a mild impact on the degree of similarity of the generated code, while high-temperature values, such as $2$, can promote the generation of new code less similar to known code.}}

\subsection{RQ5: Is ChatGPT aware of using protected code and can it avoid plagiarism when explicitly requested?}

RQ5 explores whether ChatGPT can avoid generating plagiarized code when explicitly asked to not reuse existing implementations in the prompt. We tested this prompt on the generation of the 239 methods that \textcolor{review}{exceeded a similarity threshold of 0.90, measured by the JPlag's max similarity metric.}
%exceeded a similarity threshold of 0.90 in RQ1. 

Figures \ref{fig:mean_similarity_with_instruction} and \ref{fig:max_similarity_without_instruction} illustrate the similarity scores for outputs generated with and without the explicit request for originality. The data shows that the mean and max similarity scores remained relatively similar (scores close to 0), indicating that the explicit instruction did not lead to a substantial decrease in similarity. This is confirmed by a Wilcoxon signed-rank test ($\alpha=0.05$) that revealed no significant difference ($\textit{p-value} = 0.43$ for mean similarity and $\textit{p-value} = 0.98$ for max similarity) in similarity scores between the two conditions. 

This outcome indicates that the explicit request for unique code did not effectively alter the model's tendency to produce similar outputs to existing code.

%The results indicated that even with explicit instructions to avoid plagiarism, the similarity scores of the generated code did not show a significant reduction compared to outputs generated without such instructions. This finding suggests that while the model can produce original content, it may not fully comprehend the implications of plagiarism or the need for originality when prompted.



\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/mean_similarity_with_instruction.png}
    \vspace{-10pt} 
    
    \caption{Similarity scores generated without and with explicit instructions to avoid plagiarism in the case of mean similarity.}
    \label{fig:mean_similarity_with_instruction}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{imgs/max_similarity_without_instruction.png}
    \vspace{-10pt} 
    
    \caption{Max similarity scores for outputs generated w/o explicit instructions.}
    \label{fig:max_similarity_without_instruction}
\end{figure}

%The analysis of differences indicates that the difference distribution for both mean and max similarity cases closely aligns with a normal distribution, characterized by many methods exhibiting zero difference. Consequently, no significant differences are observed, regardless of whether a specific request for originality is made. 



%In summary, the experiments conducted for RQ5 demonstrate that the model's ability to distinguish between original and plagiarized content in the response remains limited. The similarity scores suggest that explicit instructions to avoid plagiarism do not significantly impact the originality of the generated code, raising concerns about the model's understanding of intellectual property issues.
\noindent \fbox{\parbox{0.98\columnwidth}{\textbf{Answer to RQ5} ChatGPT is not aware of reusing copyleft code and cannot be asked, through the prompt, to avoid reusing existing code in the responses.}}

\subsection{Threats to Validity}
The main threats to the internal validity of the results are about the selection of both the methods and the similarity metrics. 

Since we worked with a large pre-trained model, we cannot be sure about the cases that the model processed during training. We mitigated this threat by relying on publicly available information about the training date and the training process to ultimately select methods that are, almost certainly, processed by GPT-4-turbo. %Moreover, regardless of the possible memorization of samples, the results about the similarity of the recommendations with the copyleft code remain valid. 

Since the focus of the work is on the detection of code recommendations that expose developers to the risk of plagiarizing copyleft code, we relied on the use of a popular plagiarism detection tool, JPlag, to compute similarity. Although using alternative metrics the results may slightly change, we do not expect the results about nearly identical copies shall change, which are the cases discussed in this paper.

Since there exist additional sources of code than GitHub, our results should be intended as providing an under-approximation of the probability code protected by restrictive licenses is recommended by ChatGPT.

The main threats to the external validity are the generalization to other models and the language of our findings. 

In our study, we used GPT-4-turbo, which is the most advanced GPT model at the time of the study. Although we cannot claim our results to be valid for other LLMs, we do expect the observed degree of reuse of existing code to be an intrinsic characteristic of the architecture of the model, rather than a unique characteristic of the specific instance of the model used. Results may thus have validity going beyond the model studied in this paper. 

Finally, the study considers the case of Java code. Since our design does not include anything specific to Java, we do not expect the findings to be specific to Java. Of course, the likelihood of producing responses that resemble existing code may relate to the popularity of code samples available for the considered language, and languages that are more/less popular than Java may exhibit different patterns.
