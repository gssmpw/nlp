\label{sec:RW}
\subsection{Code Generation with LLM}
The advent of LLMs has significantly transformed the landscape of software engineering, particularly in code generation \cite{Fan:LlmSeSurveyProblems:ICSE-FoSE:2023}, reflecting the growing demand for tools that enhance software development efficiency \cite{Hou:SurveyLlmSe:TOSEM:2024}.

%Code generation, the process of converting natural language descriptions into executable source code, has gained significant attention due to its potential to simplify programming tasks and make coding more accessible to a broader audience. 
Recent advancements have demonstrated impressive capabilities in translating natural language prompts into functional code snippets, and these models have been used to address various coding tasks \cite{Li:LLMLoggingStatement:TSE:2024,Schafer:LLMUnitTesting:TSE:2023,Xia:LLMAutomatedProgramRepair:ICSE:2023}.
%
%For example, one significant area of exploration is using LLMs for automated unit test generation. \cite{Schafer:LLMUnitTesting:TSE:2023} highlights the capabilities of LLMs in generating test cases. However, it also points out that the executability of these tests can be inconsistent, indicating a need for further refinement in the generation process to ensure that the produced tests are functional and reliable. In addition to testing, LLMs have been effectively utilized for generating logging statements in code. 
%
Indeed, they have been extensively used to generate functional code~\cite{Yetistiren:AssessingCopilot:PROMISE:2022,Corso:EmpiricalAssessment:ICPC:2024,Vaithilingam:ExpExpCoGen:CHI:2022,Mastropaolo:RobustnessGenCode:ICSE:2023,liu2024your,Fagadau:EmpiricalStudy:ICPC:2024,Donato:LLMConfig:ICPC:2025}, with studies showing that while the generated code is often syntactically correct, it may lack semantic accuracy, requiring human intervention for validation and refinement. %Current studies reveal that, while the generated code is often syntactically correct, it may lack semantic accuracy and require human intervention for validation and refinement. 

%OLD:%Additionally, while generated code can often meet the requirements of simple tasks, it may struggle with more complex scenarios.

In addition to code generation, LLMs have also been used for other tasks. For example, the work by Li et al~\cite{Li:LLMLoggingStatement:TSE:2024} shows how LLMs can assist developers by automatically inserting logging code, which is crucial for debugging and maintaining software applications. 
Xia et al.~\cite{Xia:LLMAutomatedProgramRepair:ICSE:2023} discuss how LLMs can be leveraged to suggest fixes, thereby streamlining the debugging process and reducing the workload on developers.
LLMs have been also used to automatically generate unit test cases~\cite{Schafer:LLMUnitTesting:TSE:2023}.


%The quality of the code generated by LLMs has also been critically assessed in several studies \cite{Yetistiren:AssessingCopilot:PROMISE:2022,Corso:EmpiricalAssessment:ICPC:2024}. These studies reveal that while the generated code is often syntactically correct, it may lack semantic accuracy and require human intervention for validation and refinement. Additionally, while generated code can often meet the requirements of simple tasks, it may struggle with more complex scenarios.

The body of work surrounding LLMs in code generation is rapidly expanding, with ongoing research addressing various applications, challenges, and future directions. As these models evolve, they hold the potential to significantly transform software engineering practices \cite{Fan:LlmSeSurveyProblems:ICSE-FoSE:2023,Hou:SurveyLlmSe:TOSEM:2024}.

This study complements these findings with evidence about the potential risks
regarding the possible inclusion of copyleft licensed code in the recommended code.

%related to copyleft licenses that may cover the recommended code.

%AI-driven tools, especially those based on LLMs, have demonstrated remarkable capabilities in generating code from natural language descriptions, thereby streamlining the coding process and allowing developers to focus on more complex tasks rather than repetitive coding activities \cite{Hou:SurveyLlmSe:TOSEM:2024}.

%Several studies have explored the effectiveness and limitations of AI in code generation \cite{Yetistiren:AssessingCopilot:PROMISE:2022,Corso:EmpiricalAssessment:ICPC:2024}. For instance, Corso et al. \cite{Corso:EmpiricalAssessment:ICPC:2024} conducted a rigorous evaluation of code generated by various AI tools, including ChatGPT and GitHub Copilot, assessing its correctness. Their findings highlight the potential of LLMs to produce working code but also emphasize the need for careful validation to ensure correctness. They found that while AI-generated code can often meet the requirements of simple tasks, it may struggle with more complex scenarios.

%Moreover, user studies have indicated that while tools like GitHub Copilot can provide useful starting points for coding tasks, developers often face challenges in understanding, editing, and debugging the generated code \cite{Vaithilingam:ExpExpCoGen:CHI:2022}. This suggests that while AI can assist in the coding process, it does not eliminate the need for human oversight and expertise \cite{}. As such, integrating AI tools into the software development workflow necessitates a balance between leveraging AI capabilities and maintaining rigorous validation practices to ensure code quality and reliability \cite{}.

%In conclusion, while AI-driven code generation tools represent a significant advancement in software engineering, ongoing research is essential to address their limitations and enhance usability in real-world programming tasks. Future studies should focus on improving the accuracy of generated code and understanding how developers interact with these tools to optimize their effectiveness in various coding contexts.

\subsection{Plagiarism in AI-generated Code}
Recent studies have increasingly focused on the implications of content generation by LLMs and the potential issues about originality. Some studies have specifically addressed these issues in the context of code generated by LLMs \cite{AlKaswan:TracesMemorisation:ICSE:2024,Yang:UnveilingMemorization:ICSE:2024,Ciniselli:CloningCode:ICPC:2022,Yu:codeipprompt:ICML:2023}. 

Al-Kaswan et al. \cite{AlKaswan:TracesMemorisation:ICSE:2024} investigate the extent to which large code models memorize their training data, revealing that a significant number of outputs can reproduce memorized code snippets. The findings indicate a strong correlation between the frequency of code snippets in the training data and their occurrence in model outputs, with larger models and longer outputs exhibiting greater memorization. %Additionally, the study highlights potential privacy and security risks associated with this memorization, emphasizing the need for strategies to mitigate these issues.
Similarly,  Yang et al. \cite{Yang:UnveilingMemorization:ICSE:2024} investigate the extent to which large code models memorize their training data, revealing that a significant number of outputs can reproduce memorized code snippets. 

Ciniselli et al. \cite{Ciniselli:CloningCode:ICPC:2022} investigate the degree to which Deep Learning (DL) code recommenders, specifically a T5 model trained on over 2 million Java methods, generate code snippets that are clones of their training data. %Using the Simian clone detector, 
The researchers found that approximately 10\% of the generated predictions represented Type-1 clones, while around 80\% were Type-2 clones. However, the likelihood of generating clones decreased significantly when the model produced more complex predictions. %, with virtually no clones identified in outputs consisting of at least four lines of code. 
These findings highlight the potential for DL-based code recommenders to suggest original code while also raising important considerations regarding licensing and the originality of generated outputs.


These studies focus specifically on code cloning and memorization, raising the critical concern of plagiarism in AI-generated code, which is addressed by our study.
%They highlight the complexities surrounding plagiarism in this context and emphasize the need for customized methodologies that address the unique challenges posed by LLMs. Our work focuses on the legal implications of code generation by ChatGPT, particularly regarding the risks of plagiarism from restrictive licenses and the effectiveness of explicit requests for original content generation.

Related to our work, {\small \sc CODEIPPROMPT}~\cite{Yu:codeipprompt:ICML:2023} is a framework designed to evaluate the potential intellectual property (IP) infringement in code generated by LLMs. The analysis conducted by the authors shows that models may frequently generate code that closely resembles copyrighted material. The findings highlight significant risks of IP violations due to the presence of copyrighted code in training datasets, underscoring the need for improved data management and mitigation strategies to address these concerns effectively. %Overall, the work emphasizes the importance of reconsidering training data and developing more intelligent models to enhance IP protection in code generation. 
Our work extends this study %on plagiarism detection in AI-generated code 
by offering additional insights on plagiarism concerns that may affect AI-generated code. 
We explored various aspects that influence code generation, such as the context and the model's creativity, understanding how they affect the likelihood of obtaining code that is similar to copyleft code. 

%By analyzing these factors, our study aims to provide deeper insights into the mechanisms behind code generation, ultimately contributing to the development of more effective strategies for mitigating plagiarism risks in AI-generated code.

