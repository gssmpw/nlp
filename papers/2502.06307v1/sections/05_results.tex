\section{Experiments and Results}
\label{sec:results}

\subsection{Experimental Design}
\label{sec:results:design}

\subsubsection{Experiments}
\label{sec:results:design:experiments}

The experiments are designed to evaluate the performance, generalization, robustness, and efficiency of CellNuc-DETR in various contexts. First, we train CellNuc-DETR using the three-fold cross-validation split provided in the PanNuke dataset, comparing its performance against other state-of-the-art models in terms of cell nuclei detection and classification metrics. During this stage, we also assess different design components of the model, such as the input and backbone feature resolution, the model depth, and other architectural variations. 

Next, we train CellNuc-DETR on 80\% of the PanNuke dataset, reserving the remaining 20\% for validation. This model is used in subsequent experiments to evaluate its performance across different datasets and scenarios.

To test the robustness of CellNuc-DETR, we perform cross-dataset evaluations on the MoNuSeg and CoNSeP datasets using the pre-trained model without additional fine-tuning. For the MoNuSeg dataset, which lacks classification labels, we evaluate detection performance only. For the CoNSeP dataset, we map the five classes predicted by PanNuke to the four classes present in CoNSeP to evaluate both detection and classification performance. These evaluations also assess the effectiveness and adaptability of the sliding window inference approach, as these datasets comprise larger image tiles.

Finally, we perform inference on the TCGA slides to measure the inference time performance of CellNuc-DETR. This experiment focuses on the efficiency and scalability of the model when applied to WSIs, highlighting its practicality for real-world applications.

\subsubsection{Evaluation Metrics}
\label{sec:results:design:metrics}

The evaluation protocol for nuclei detection and classification follows the methodology outlined in \cite{graham2019hover}, employing F1-score as the evaluation metric. Initially, a bi-partite matching process aligns ground truth nuclei centroids with detected counterparts, limited to a radius of 12 pixels for a resolution of 0.25 $\mu$m/px. Detection metrics, including true positives ($TP_{det}$), false positives ($FP_{det}$), and false negatives ($FN_{det}$), are derived based on the outcomes of the matching process between ground truth and predicted nuclei. The detection F1-score ($F_{det}$) is computed as the harmonic mean of detection precision ($P_{det}$) and recall ($R_{det}$).

For classification, $TP_{det}$ is further categorized into correctly and incorrectly classified nuclei of class \textit{c}, denoted as $TP_c$ and $FP_c$, respectively. Additionally, misclassified elements from class $c$ are captured as $FN_c$. Precision, Recall, and F1-Score for each class are then calculated as follows:
\begin{equation}
    F_c = \frac{2(TP_c +TN_c)}{2(TP_c +TN_c)+2FP_c +2FN_c +FP_{det} +FN_{det}}
\end{equation}

\begin{equation}
    P_c = \frac{TP_c +TN_c}{TP_c +TN_c +2FP_c +FP_{det}}
\end{equation}

\begin{equation}
    R_c = \frac{TP_c +TN_c}{TP_c +TN_c +2FN_c +FN_{det}}
\end{equation}

\subsection{Numerical Results}
\label{sec:results:numerical}

\subsubsection{Evaluation on PanNuke}
\label{sec:results:numerical:pannuke}

In Table \ref{tab:pannuke}, we evaluate CellNuc-DETR and compare it with other state-of-the-art methods. Our results demonstrate that CellNuc-DETR outperforms these methods in both cell nuclei detection and classification, achieving state-of-the-art performance.

We conducted an evaluation of different design components in our study. Specifically, we evaluated the performance of our models with four different backbones: ResNet-50 \cite{he2016deep} (\textit{R50}), Swin-Tiny (\textit{tiny}), Swin-Base (\textit{base}), and Swin-Large (\textit{large}) \cite{liu2021swin}. Additionally, given the small size and potential overlap between cell nuclei, we assessed the influence of the resolution of the feature maps taken from the backbone, comparing the usage of all four available levels (\textit{4lvl}) to using only the last three levels (\textit{3lvl}), as done in the original Deformable DETR \cite{zhu2020deformable}. Finally, we investigated the complexity of the model by varying the number of decoder queries and layers. The original DETR, trained on the COCO dataset, uses 300 decoder queries and selects the top 100 predictions, as COCO images contain a maximum of 100 objects. For cell nuclei detection, where there may be up to 300 cells in an image, we used 900 queries and selected the top 300. This model is composed by six encoder and decoder layers (Deep). We also experimented with using 600 queries and selecting the top 200, as it is rare to have 300 cells in a single image. The model using 600 queries also employed only three encoder and decoder layers, rather than six as in the original architecture.

The results show that the backbone is crucial for achieving state-of-the-art performance in both cell nuclei detection and classification tasks. Specifically, models using the Swin backbone consistently outperform those with the ResNet-50 backbone across all classes. Among the Swin-based models, Swin-Large shows a slight better performance. The number of feature levels extracted from the backbone did not significantly influence the results, which contrasts with findings from previous studies. Additionally, the deepest models with 900 queries achieve state-of-the-art performance in cell classification, slightly surpassing the smaller models. However, the marginal difference suggests that the smaller models could be favored for faster inference without a loss in accuracy, offering a more efficient alternative.

%The results indicate that the backbone is crucial for cell classification, as the ResNet-50 backbone is consistently outperformed across classes when using the Swin backbone. In contrast, Swin based backbones achieved state-of-the-art performance, with Swin-Large performing slightly better in some classes. The number of feature levels used from the backbone did not significantly impact performance, contrary to observations in previous work. Finally, the deepest models with 900 queries achieve state of the art performance on cell classification, slightly outperforming the smaller models. However, such a small difference suggests that the smaller model can be utilized for faster inference without sacrificing accuracy.

\begin{table}[ht]
\vskip -0.1in
\centering
\caption{Detection and classification metrics on PanNuke dataset.}
\label{tab:pannuke}
\vskip 0.1in
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{l|ccc|ccc|ccc|ccc|ccc|cccccc}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c|}{\textbf{Detection}} & \multicolumn{3}{c|}{\textbf{Neoplastic}} & \multicolumn{3}{c|}{\textbf{Epithelial}} & \multicolumn{3}{c|}{\textbf{Inflammatory}} & \multicolumn{3}{c|}{\textbf{Connective}} & \multicolumn{3}{c}{\textbf{Necrosis}} \\
%\cmidrule{2-19}
& $P_{det}$ & $R_{det}$ & $F_{det}$ & $P_{neo}$ & $R_{neo}$ & $F_{neo}$ & $P_{epi}$ & $R_{epi}$ & $F_{epi}$ & $P_{inf}$ & $R_{inf}$ & $F_{inf}$ & $P_{con}$ & $R_{con}$ & $F_{con}$ & $P_{nec}$ & $R_{nec}$ & $F_{nec}$ \\
\midrule
\textbf{DIST} \cite{naylor2018segmentation} & 0.74 & 0.71 &0.73 & 
       0.49 & 0.55 & 0.50 & 
       0.38 & 0.33 & 0.35 &
       0.42 & 0.45 & 0.42 &
       0.42 & 0.37 & 0.39 &
       0.00 & 0.00 & 0.00 \\
\textbf{Mask-RCNN} \cite{he2017mask} & 0.76 & 0.68 & 0.72 &
            0.55 & 0.63 & 0.59 &
            0.52 & 0.52 & 0.52 &
            0.46 & 0.54 & 0.50 &
            0.42 & 0.43 & 0.42 &
            0.17 & 0.30 & 0.22 \\
\textbf{Micro-Net} \cite{raza2019micro} & 0.78 & 0.82 & 0.80 &
            0.59 & 0.66 & 0.62 &
            0.63 & 0.54 & 0.58 &
            0.59 & 0.46 & 0.52 &
            0.40 & 0.45 & 0.47 &
            0.23 & 0.17 & 0.19 \\
\textbf{HoVer-Net} \cite{graham2019hover} & 0.82 & 0.79 & 0.80 &
            0.58 & 0.67 & 0.62 &
            0.54 & 0.60 & 0.56 &
            0.56 & 0.51 & 0.54 &
            0.52 & 0.47 & 0.49 &
            0.28 & 0.35 & 0.31 \\

\textbf{HoVer-NeXt}$_{tiny, TTA=4}$ \cite{baumann2024hover} & 0.82 & 0.77 & 0.79 &
        0.68 & 0.61 & 0.65 &
        0.67 & 0.64 & 0.65 &
        0.55 & 0.57 & 0.56 &
        0.53 & 0.50 & 0.51 &
        0.41 & 0.34 & 0.37 \\

\textbf{CellViT}$_{256}$ \cite{hörst2023cellvit} & 0.83 & 0.82 & 0.82 &
          0.69 & 0.70 & 0.69 &
          0.68 & 0.71 & 0.70 &
          0.59 & 0.58 & 0.58 &
          0.53 & 0.51 & 0.52 &
          0.39 & 0.35 & 0.37\\

\textbf{CellViT}$_{SAM-H}$ \cite{hörst2023cellvit} & 0.84 & 0.81 & 0.83 &
          0.72 & 0.69 & 0.71 &
          0.72 & 0.73 & 0.73 &
          0.59 & 0.57 & 0.58 &
          0.55 & 0.52 & 0.53 &
          0.43 & 0.32 & 0.36\\

\midrule

\textbf{CellNuc-DETR}$_{R50,3lvl}$-Deep&0.81&0.85&0.83&0.67&0.71&0.69&0.67&0.72&0.69&0.56&0.61&0.58&0.52&0.53&0.52&0.45&0.37&0.40\\
\textbf{CellNuc-DETR}$_{R50,4lvl}$-Deep&0.81&0.85&0.83&0.67&0.71&0.69&0.68&0.71&0.70&0.56&0.62&0.59&0.53&0.53&0.53&0.47&0.39&0.43\\
\midrule
\textbf{CellNuc-DETR}$_{tiny,3lvl}$&0.81&0.85&0.83&0.69&0.73&0.71&0.68&0.75&0.71&0.58&0.62&0.60&0.55&0.55&0.55&0.48&0.42&0.44\\
\textbf{CellNuc-DETR}$_{tiny,3lvl}$-Deep&0.81&0.87&0.84&0.69&0.74&0.71&0.68&0.77&0.72&0.57&0.64&0.60&0.54&0.56&0.55&0.50&0.43&0.46\\
\textbf{CellNuc-DETR}$_{tiny,4lvl}$&0.80&0.86&0.83&0.68&0.73&0.71&0.67&0.76&0.71&0.57&0.64&0.60&0.55&0.54&0.55&0.45&0.43&0.44\\
\textbf{CellNuc-DETR}$_{tiny,4lvl}$-Deep&0.80&0.87&0.84&0.69&0.74&0.71&0.68&0.77&0.72&0.56&0.65&0.61&0.55&0.55&0.55&0.49&0.44&0.46\\

\midrule

\textbf{CellNuc-DETR}$_{base,3lvl}$&0.81&0.86&0.83&0.68&0.73&0.71&0.69&0.75&0.72&0.57&0.63&0.60&0.54&0.55&0.55&0.48&0.41&0.44\\
\textbf{CellNuc-DETR}$_{base,3lvl}$-Deep&0.81&0.87&0.84&0.68&0.73&0.71&0.69&0.75&0.72&0.57&0.63&0.60&0.53&0.55&0.54&0.49&0.43&0.46\\
\textbf{CellNuc-DETR}$_{base,4lvl}$&0.82&0.84&0.83&0.70&0.72&0.71&0.70&0.75&0.72&0.58&0.63&0.60&0.56&0.54&0.55&0.47&0.42&0.44\\
\textbf{CellNuc-DETR}$_{base,4lvl}$-Deep&0.81&0.86&0.83&0.69&0.73&0.71&0.69&0.75&0.72&0.57&0.62&0.59&0.54&0.55&0.55&0.47&0.43&0.45\\

\midrule

\textbf{CellNuc-DETR}$_{large,3lvl}$-Deep&0.82&0.85&0.83&0.70&0.73&0.72&0.72&0.76&0.74&0.57&0.63&0.60&0.56&0.56&0.56&0.51&0.41&0.45\\
\textbf{CellNuc-DETR}$_{large,4lvl}$-Deep&0.82&0.85&0.84&0.71&0.74&0.72&0.72&0.77&0.74&0.57&0.64&0.60&0.56&0.55&0.56&0.48&0.43&0.45\\

\bottomrule
\multicolumn{19}{l}{\small Other metrics are extracted from \cite{hörst2023cellvit}.}

\end{tabular}
\end{adjustbox}
\vskip -0.1in
\end{table}

The results in Table \ref{tab:pannuke} suggest that using the last three feature levels from the backbone is sufficiently accurate for both cell nuclei detection and classification. Omitting the first feature level improves the efficiency of the model by reducing the number of tokens processed by the deformable transformer. Specifically, the first feature level consists of $4\times4\text{px}$ image patches ($1 \mu \text{m}/\text{token}$ at an input resolution of $0.25 \mu m/\text{px}$). The second, third, and fourth levels correspond to $2 \mu \text{m}/\text{token}$, $4 \mu \text{m}/\text{token}$, and $8 \mu \text{m}/\text{token}$, respectively. Therefore, for a $256\times256\text{px}$ image, the first level contains 4096 tokens, the second has 1024, the third 256, and the fourth 64 tokens.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/pannuke-preds.pdf}
    \caption{PanNuke ground truth and CellNuc-DETR$_{tiny,3lvl}$ predictions across tissues.}
    \label{fig:results:pannuke}
    \footnotesize{Visualization of CellNuc-DETR$_{tiny,3lvl}$ predictions for different test images of the PanNuke dataset. The images have been selected to showcase the differences between tissues, cell class distribution, cell density and stain variations.}
\end{figure}

By ignoring the first level, the number of tokens processed by the deformable transformer is reduced from 5440 to 1340. However, this reduction only decreases the computational load of the deformable transformer and does not impact the computational cost of the backbone. To address this, we explored training the model at a lower input resolution of $0.50 \mu m/\text{px}$, where cell nuclei are still easily identifiable. This change reduces the overall computational cost, as the input images are smaller. By using all four feature levels at $0.50 \mu m/\text{px}$, we ensure that the deformable transformer continues to receive feature maps at relevant scales ($2 \mu \text{m}/\text{token}$, $4 \mu \text{m}/\text{token}$, $8 \mu \text{m}/\text{token}$) while significantly reducing the backbone's computational burden.

Table \ref{tab:pannuke05} shows the results for CellNuc-DETR and CellViT on the PanNuke dataset, with training and evaluation conducted at a resolution of $0.50 \mu m/\text{px}$, averaged across the three folds. The model uses the Swin-tiny (\textit{tiny}) backbone and takes the four feature levels (\textit{4lvl}) to ensure the relevant information is taken. We experiment with both the larger model taking 900 decoder queries and six layers (Deep) and the smaller with 600 queries and three layers. The results demonstrate that CellNuc-DETR is highly effective, achieving significantly superior performance in both cell nuclei detection and classification tasks. Indeed, CellNuc-DETR shows only minimal performance degradation compared to the full-resolution models presented in Table \ref{tab:pannuke}, validating our previous observations.

The model maintains acceptable performance even in the most challenging classes, such as necrosis, which involve very small and underrepresented nuclei. These results suggest that using a lower resolution like $0.50 \mu m/\text{px}$ can be beneficial for speeding up inference time and reducing computational load in clinical scenarios while maintaining high accuracy.

\begin{table}[ht]
\vskip -0.1in
\centering
\caption{Detection and classification metrics on PanNuke dataset.}
\label{tab:pannuke05}
\vskip 0.1in
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{l|ccc|ccc|ccc|ccc|ccc|cccccc}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c|}{\textbf{Detection}} & \multicolumn{3}{c|}{\textbf{Neoplastic}} & \multicolumn{3}{c|}{\textbf{Epithelial}} & \multicolumn{3}{c|}{\textbf{Inflammatory}} & \multicolumn{3}{c|}{\textbf{Connective}} & \multicolumn{3}{c}{\textbf{Necrosis}} \\
%\cmidrule{2-19}
& $P_{det}$ & $R_{det}$ & $F_{det}$ & $P_{neo}$ & $R_{neo}$ & $F_{neo}$ & $P_{epi}$ & $R_{epi}$ & $F_{epi}$ & $P_{inf}$ & $R_{inf}$ & $F_{inf}$ & $P_{con}$ & $R_{con}$ & $F_{con}$ & $P_{nec}$ & $R_{nec}$ & $F_{nec}$ \\
\midrule

\textbf{CellViT$_{256}$}(0.50$\mu$m/px) \cite{hörst2023cellvit} & 0.86 & 0.60 & 0.71 & 0.72 & 0.59 & 0.65 & 0.71 & 0.58 & 0.64 & 0.60 & 0.38 & 0.47 & 0.53 & 0.32 & 0.40 & 0.43 & 0.04 & 0.07 \\
\textbf{CellViT$_{SAM-H}$}(0.50$\mu$m/px) \cite{hörst2023cellvit} & 0.88 & 0.63 & 0.73 & 0.74 & 0.62 & 0.67 & 0.74 & 0.61 & 0.67 & 0.60 & 0.42 & 0.49 & 0.56 & 0.34 & 0.42 & 0.49 & 0.04 & 0.08 \\

\midrule

% BEST THRESHOLD ON VALIDATION
\textbf{CellNuc-DETR}$_{tiny,4lvl}$(0.50$\mu$m/px)&0.79&0.86&0.82&0.66&0.73&0.70&0.67&0.76&0.72&0.56&0.61&0.58&0.53&0.54&0.54&0.42&0.42&0.42\\
\textbf{CellNuc-DETR}$_{tiny,4lvl}$-Deep(0.50$\mu$m/px)&0.80&0.86&0.83&0.67&0.73&0.70&0.67&0.76&0.71&0.56&0.62&0.59&0.54&0.54&0.54&0.46&0.40&0.42\\


% THRESHOLD 0.4
%\textbf{CellNuc-DETR$_{tiny,4lvl}$}(0.50$\mu$m/px) & 0.84 & 0.78 & 0.81 & 0.72 & 0.69 & 0.70 & 0.71 & 0.73 & 0.72 & 0.60 & 0.60 & 0.60 & 0.60 & 0.49 & 0.54 & 0.48 & 0.37 & 0.41 \\
%\textbf{CellNuc-DETR$_{tiny,4lvl}$}-Deep(0.50$\mu$m/px) & 0.85 & 0.78 & 0.81 & 0.72 & 0.69 & 0.70 & 0.70 & 0.72 & 0.71 & 0.60 & 0.60 & 0.60 & 0.60 & 0.49 & 0.54 & 0.53 & 0.35 & 0.42 \\

%\textbf{CellNuc-DETR-swinB-4lvl-S-050mpp} & 0.85 & 0.76 & 0.80 & 0.73 & 0.67 & 0.70 & 0.73 & 0.70 & 0.71 & 0.60 & 0.58 & 0.59 & 0.59 & 0.48 & 0.53 & 0.52 & 0.36 & 0.42 \\
%\textbf{CellNuc-DETR-swinB-4lvl-050mpp} & 0.86 & 0.76 & 0.80 & 0.73 & 0.66 & 0.69 & 0.73 & 0.69 & 0.71 & 0.60 & 0.58 & 0.59 & 0.59 & 0.48 & 0.53 & 0.52 & 0.35 & 0.41 \\
%\textbf{CellNuc-DETR-swinB-S-4lvl} & 0.84 & 0.78 & 0.81 & 0.72 & 0.68 & 0.70 & 0.72 & 0.71 & 0.72 & 0.59 & 0.59 & 0.59 & 0.57 & 0.49 & 0.53 & 0.51 & 0.34 & 0.41 \\
%\textbf{CellNuc-DETR-swinB-4lvl} & 0.85 & 0.78 & 0.81 & 0.72 & 0.68 & 0.70 & 0.71 & 0.71 & 0.71 & 0.59 & 0.59 & 0.59 & 0.57 & 0.49 &0.53 & 0.51 & 0.35 & 0.41 \\

\bottomrule
\multicolumn{19}{l}{\small Other metrics are extracted from \cite{hörst2023cellvit}.}

\end{tabular}
\end{adjustbox}
\vskip -0.1in
\end{table}

To better understand the performance of CellNuc-DETR, we conducted a detailed per-tissue analysis of cell nuclei detection and classification tasks. Figure \ref{fig:results:radar} illustrates the performance of CellNuc-DETR across the 19 tissues of PanNuke. Each line corresponds to the performance each CellNuc-DETR variation explored averaged across the three PanNuke folds. While similar performance is achieved for all model variations and scales, some tissues pose greater challenges than others.

cell nuclei detection performance is consistent across all tissues; however, classification performance varies significantly. For instance, epithelial cell classification shows poor results in tissues such as lung, kidney, cervix, bile duct, uterus, stomach, and skin. Inflammation classification also displays considerable variance, with F1-Scores above 60\% in tissues like kidney, head and neck, colon, bile duct, testis, stomach, and skin, but dropping to around 40\% for other tissues. Similarly, the classification of connective tissue is suboptimal in tissues such as lung and skin.

These discrepancies are likely due to variations in cell nucleus appearance across different tissues, as well as class imbalance within each tissue for each cell type. Tissues with more diverse or less abundant cell types may present significant challenges for accurate classification, contributing to the observed variability in model performance.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/polar_tissue_fscore.pdf}
    \caption{F1-Score for cell nuclei detection and classification across tissues.}
    \label{fig:results:radar}
\end{figure}

\subsubsection{Cross-dataset Evaluation}
\label{sec:results:numerical:cross}

To further validate the robustness of CellNuc-DETR, we performed a cross-dataset evaluation using CellNuc-DETR models trained on 80\% of the PanNuke dataset. These models were evaluated on the CoNSeP and MoNuSeg datasets without any additional fine-tuning. Given the differences in class definitions between PanNuke and CoNSeP, we mapped the classes as follows: neoplastic and epithelial cells from PanNuke were mapped to the epithelial class in CoNSeP, inflammatory cells were mapped directly as the same, connective tissue cells were mapped to the spindle-shaped class, and necrotic cells were mapped to the miscellaneous class.

The results in Table \ref{tab:consep} show that CellNuc-DETR significantly outperforms other state-of-the-art methods. Notable, these methods have been specifically trained on CoNSeP, whereas we are performing a cross-dataset evaluation for CellNuc-DETR.  This highlights the robustness of CellNuc-DETR, which is crucial for practical applications in digital pathology. The results obtained on the CoNSeP dataset are similar to the CellNuc-DETR performance on the colon tissue images of the PanNuke dataset reported in Figure \ref{fig:results:radar}. Additionally, we included results for models trained at a resolution of $0.50 \mu m/\text{px}$. Once again, the performance is very similar to the full-resolution models, further validating CellNuc-DETR's robustness across different datasets and scales and demonstrating its wide applicability. Interestingly, in the cross-domain evaluation, the size of the deformable transformer has a more significant impact on generalization performance, suggesting that model complexity plays a more critical role when dealing with cross-domain scenarios.

%Despite not performing any fine-tuning on the CoNSeP dataset, we compared our models' performance with other state-of-the-art methods specifically trained on CoNSeP. This rigorous cross-dataset evaluation highlights the robustness of CellNuc-DETR, demonstrating its ability to generalize effectively across different datasets and maintain high performance in cell nuclei detection and classification tasks.

%The results in Table \ref{tab:consep} confirm that CellNuc-DETR significantly outperforms other methods when applied to new datasets without additional training. This robustness is crucial for practical applications in digital pathology, where models must adapt to diverse tissue types and staining variations encountered in different clinical settings.

\begin{table}[ht]
\vskip -0.1in
\centering
\caption{Detection and classification F-Score on CoNSeP and MoNuSeg datasets. }
\label{tab:consep}
\vskip 0.1in
\begin{adjustbox}{width=0.9\textwidth}
\begin{tabular}{l|ccccc|c}
\toprule
\textbf{} & \multicolumn{5}{c|}{\textbf{CoNSeP}} & \textbf{MoNuSeg} \\
\cmidrule(lr){2-6} \cmidrule(lr){7-7}
\textbf{Method} & \textbf{Detection} & \textbf{Epithelial} & \textbf{Inflammatory} & \textbf{Spindle-shaped} & \textbf{Miscellaneous} & \textbf{Detection} \\
\midrule
\textbf{DIST*} \cite{naylor2018segmentation} & 0.71 & 0.62 & 0.53 & 0.51 & 0.00 & - \\
\textbf{Micro-Net*} \cite{raza2019micro} & 0.74 & 0.62 & 0.59 & 0.53 & 0.12 & - \\
\textbf{Mask-RCNN*} \cite{he2017mask} & 0.69 & 0.60 & 0.59 & 0.52 & 0.10 & - \\
\textbf{HoVer-Net*} \cite{graham2019hover} & 0.75 & 0.64 & 0.63 & 0.57 & 0.43 & - \\
\textbf{ACFormer*} \cite{Huang_2023_ICCV} & 0.74 & 0.64 & 0.64 & - & - & - \\
\midrule
\textbf{CellNuc-DETR}$_{tiny,3lvl}$ & 0.77 & 0.71 & 0.70 & 0.62 & 0.59 & 0.87 \\
\textbf{CellNuc-DETR}$_{tiny,3lvl}$-Deep & 0.78 & 0.72 & 0.72 & 0.63 & 0.63 & 0.88 \\
\textbf{CellNuc-DETR}$_{tiny,4lvl}$(0.50$\mu$m/px) & 0.75 & 0.69 & 0.71 & 0.60 & 0.52 & 0.87 \\
\textbf{CellNuc-DETR}$_{tiny,4lvl}$-Deep(0.50$\mu$m/px) & 0.76 & 0.69 & 0.73 & 0.61 & 0.59 & 0.87 \\

%\textbf{CellNuc-DETR$_{tiny,3lvl}$} & 0.77 & 0.71 & 0.70 & 0.62 & 0.59 \\
%\textbf{CellNuc-DETR$_{tiny,3lvl}$}-Deep & 0.78 & 0.72 & 0.72 & 0.63 & 0.63 \\
%\textbf{CellNuc-DETR-swinB-S-35lvl} & 0.78 & 0.71 & 0.70 & 0.62 & 0.62  \\
%\textbf{CellNuc-DETR-swinB-35lvl} & 0.78 & 0.69 & 0.71 & 0.64 & 0.65 \\
%\textbf{CellNuc-DETR-swinB-4lvl} & 0.78 & 0.71 & 0.72 & 0.63 & 0.63 \\
%\textbf{CellNuc-DETR-swinL-35lvl} & 0.79 & 0.74 & 0.72 & 0.65 & 0.64 \\
%\textbf{CellNuc-DETR-swinL-4lvl} & 0.78 & 0.70 & 0.73 & 0.66 & 0.66 \\
%\midrule
%\textbf{CellNuc-DETR$_{tiny,4lvl}$(0.50$\mu$m/px)} & 0.76 & 0.68 & 0.69 & 0.61 & 0.54 \\
%\textbf{CellNuc-DETR$_{tiny,4lvl}$-Deep(0.50$\mu$m/px)} & 0.76 & 0.67 & 0.71 & 0.62 & 0.61 \\
%\textbf{CellNuc-DETR-swinB-S-4lvl-050mpp} & 0.76 & 0.68 & 0.69 & 0.60 & 0.56 \\
%\textbf{CellNuc-DETR-swinB-4lvl-050mpp} & 0.77 & 0.70 & 0.70 & 0.62 & 0.59 \\

\bottomrule

\multicolumn{7}{l}{\small *Models trained on CoNSeP.}

\end{tabular}
\end{adjustbox}
\vskip -0.15in
\end{table}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/consep-preds.pdf}
    \caption{CoNSeP ground truth and CellNuc-DETR$_{tiny,3lvl}$ predictions.}
    \label{fig:results:consep}
\end{figure}

\subsection{Inference Time}
\label{sec:results:time}

In this section, we evaluate the inference time of the CellNuc-DETR pipeline on the WSIs obtained from TCGA. We compare the performance of CellNuc-DETR with other state-of-the-art methods, such as HoVer-NeXt that reported significantly higher speeds than HoVer-Net and CellViT, to assess both speed and efficiency in processing large-scale histopathological data. Additionally, we explore the influence of various design components within the CellNuc-DETR pipeline on its inference performance, providing insights into how different configurations can impact overall efficiency.

\subsubsection{Pipeline Comparison}
\label{sec:results:time:sota}

In Figure \ref{fig:results:inference-sota}, we compare the inference and post-processing times on WSIs for three different pipelines: CellNuc-DETR, Cell-ViT, and HoVer-NeXt. The three pipelines are run with the 20 WSIs extracted from TCGA and the times are reported as function of the slides' area. Each dot in the plot corresponds to a slide, we have also included the regression lines for a more comprehensive visualization.

We select models trained on PanNuke that operate at the same magnification of 0.25 $\mu$m/px. For Cell-ViT, we chose the smaller Cell-ViT-256 model, as it is faster than Cell-ViT-SAM-H, and conducted inference on tiles of $1024 \times 1024$ pixels, as suggested in the original paper. For HoVer-NeXt, we used the configuration recommended in the paper for obtaining the metrics in Table \ref{tab:pannuke}: ConvNeXtv2-tiny backbone with four test-time augmentations. Finally, for CellNuc-DETR, we used a Swin-tiny backbone, which has a similar computational complexity to ConvNeXtv2-tiny, and selected the model with 3 backbone levels and 3 layers.

We evaluate the inference time, which corresponds to the time spent by the model in processing all individual tiles, as well as the post-processing time required to combine predictions and obtain the final results. The pipelines have been run on a NVIDIA A100 24GB GPU, within a cluster equipped with 8 CPU cores and 128GB RAM.

CellNuc-DETR is the fastest method in both inference time and, especially, post-processing time. As observed, CellNuc-DETR and HoVer-NeXt are significantly faster than Cell-ViT in processing tiles, with CellNuc-DETR being slightly faster. However, HoVer-NeXt's speed comes at the expense of lower accuracy, whereas CellNuc-DETR achieves state-of-the-art performance, as reported in Table \ref{tab:pannuke}. Notably, the post-processing time for CellNuc-DETR is forty times lower than that of HoVer-NeXt, demonstrating a substantial efficiency advantage.

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/inference-sota.pdf}
    \caption{Pipeline inference, post-processing and total time as function of the slide area.}
    \label{fig:results:inference-sota}
    \footnotesize{Pipeline inference time refers to the model processing of the individual tiles extracted from the WSI, whereas the post-processing time is the time spent combining the predictions and returning the final results.}
\end{figure}

\subsubsection{Speeding Up CellNuc-DETR}
\label{sec:results:time:scale}

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/inference-scale.pdf}
    \caption{Effect of the input image resolution in the pipeline inference time.}
    \label{fig:results:inference-scale}
\end{figure}

One effective strategy to accelerate the inference time of CellNuc-DETR is to operate at a lower resolution, specifically $0.50 \mu m/\text{px}$, compared to the original $0.25 \mu m/\text{px}$. As discussed in Section \ref{sec:results:numerical:pannuke}, reducing the input image resolution directly lowers the overall computational complexity of the model. This reduction is achieved without compromising the model’s ability to capture essential features, as by leveraging the four backbone levels, the deformable transformer still processes the relevant resolutions necessary for accurate cell nuclei detection and classification. Indeed, the results in Table \ref{tab:pannuke05} show a minimal accuracy drop when working at $0.50 \mu m/\text{px}$.

In this section, we present the inference times of CellNuc-DETR when running at $0.50 \mu m/\text{px}$, as shown in Figure \ref{fig:results:inference-scale}. The results are remarkable, with the inference time reduced by a factor of 2 compared to the $0.25 \mu m/\text{px}$ configuration. This significant reduction highlights the practical benefits of using lower resolutions for faster processing, especially in clinical settings where time efficiency is critical. The ability to maintain high accuracy while drastically improving speed underscores the effectiveness of this strategy and reinforces the adaptability of CellNuc-DETR for various real-world applications.

Additionally, we have devised our pipeline to run in a distributed mode across multiple GPUs. This approach distributes the workload evenly across the GPUs, enabling parallel processing of tiles within WSIs. By leveraging multiple GPUs, the inference time is significantly reduced, making the pipeline more scalable and suitable for large-scale clinical applications or research environments requiring high throughput. The results of this distributed processing (at 0.25$\mu$m/px) are shown in Figure \ref{fig:results:inference-gpu}, demonstrating further improvements in inference efficiency compared to single GPU setups.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/inference-gpu.pdf}
    \caption{Effect of the number of GPUs in the pipeline inference time.}
    \label{fig:results:inference-gpu}
\end{figure}

\subsubsection{Model's Size Effect}
\label{sec:results:time:size}

Finally, in this section we explore how various components of the CellNuc-DETR model affect inference time, specifically examining the impact of the backbone choice, the number of feature levels extracted from the backbone, as well as the depth and number of queries of the deformable transformer. As expected, the more sophisticated the model configuration, the slower the inference time. 

As shown in Figure \ref{fig:results:inference-model}, including all four feature levels from the backbone, which increases the number of tokens fed into the transformer, has a similar effect on slowing down the model as increasing the depth of the transformer itself. Among the components analyzed, the choice of backbone has the most significant impact on inference time. For example, although Table \ref{tab:pannuke} shows that using a Swin-Large backbone results in improved classification performance, this improvement comes at the cost of much higher inference times. This illustrates the trade-off between model complexity and computational efficiency, highlighting the importance of carefully selecting model components based on the specific requirements of the application, whether that be higher accuracy or faster processing.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/inference-model.pdf}
    \caption{Effect of the model components in the pipeline inference time.}
    \label{fig:results:inference-model}
\end{figure}