\section{Introduction}
\label{sec:intro}

Cell detection, segmentation, and classification are essential Artificial Intelligence (AI) tasks in digital pathology, enabling applications such as precise estimation of cell populations \cite{lewis2023automated}, biomarker quantification \cite{lara2021quantitative} and the spatial analysis of cells and cell graphs \cite{sobhani2021artificial, pati2022hierarchical, pina2022self, wang2024breast}. Integrating these AI-driven methods into clinical practice supports pathologists in diagnostic processes, making analyses more quantitative and reproducible \cite{garcia2016trying}. However, broader deployment of these technologies in clinical settings remains constrained by high computational demands, long processing times, and the need for robust methods capable of handling the high variability in digital pathology data.

A significant challenge in deploying AI models for digital pathology is the intensive computational resources required to analyze large-scale Whole Slide Images (WSIs). The computational burden is influenced by the model architecture—whether based on convolutional neural networks or transformer models— and the scope of the area analyzed, typically confined to patches or Regions of Interest (ROIs). Extending these analyses to entire WSIs becomes impractical in clinical settings, where rapid processing is crucial. Additionally, achieving robustness and reliability across diverse scenarios is challenging due to the variability in staining intensities, noise, and processing artifacts.

Segmentation methods, such as HoVer-Net\cite{graham2019hover}, CellViT\cite{hörst2023cellvit} and HoVer-NeXt\cite{baumann2024hover}, have recently achieved notable improvements in both accuracy and inference speed. These methods, however, use segmentation as a proxy for detection to address the difficulties in detecting small and potentially overlapping cell nuclei using traditional detection methods. Nevertheless, segmentation masks often lack clinical relevance, as the primary objective is to detect and classify cell nuclei, not to delineate their exact shapes.

To address these limitations, we propose CellNuc-DETR \cite{pina2024cell}\footnote{Originally named Cell-DETR \cite{pina2024cell}, the model has been renamed CellNuc-DETR to avoid ambiguity with a method for instance segmentation in time-lapse fluorescence microscopy images \cite{prangemeier2020c}.}, a direct detection approach for extracting cell information using the Detection Transformer (DETR) \cite{carion2020end}. Unlike traditional detection models, DETR does not rely on non-maximum suppression, allowing it to handle overlapping instances more effectively. Aligning with our hypothesis that the precise shape of cell nuclei is not essential for clinical decision-making, by focusing on detection rather than segmentation, we eliminate the computational overhead associated with generating and post-processing segmentation masks.

We demonstrate that CellNuc-DETR achieves state-of-the-art performance in both cell nuclei detection and classification across multiple datasets. Through cross-dataset evaluations on unseen datasets during training like CoNSeP \cite{graham2019hover} and MoNuSeg \cite{kumar2019multi}, we show the robustness and generalization capability of the model. Additionally, we develop an efficient inference pipeline for WSIs that significantly improves processing speed and accuracy compared to current segmentation-based approaches. This combination of speed and accuracy underscores CellNuc-DETR's potential as a practical and effective solution for clinical deployment in digital pathology. The code and the pre-trained weights are publicly available \footnote{\href{https://github.com/oscar97pina/celldetr}{https://github.com/oscar97pina/celldetr}}.
