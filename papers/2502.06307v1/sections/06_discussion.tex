\section{Discussion}
\label{sec:discussion}

\paragraph{Detection vs Segmentation} In this paper, we propose a shift in the paradigm for extracting cell information from WSIs, moving from traditional cell segmentation approaches to cell nuclei detection. The motivation for this shift is that the primary tasks in digital pathology are cell nuclei detection and classification, where the focus is on identifying and labeling cells rather than generating pixel-wise segmentations. This shift is critical because detection methods are inherently faster and more efficient than segmentation methods, which require more computational resources, especially during post-processing.

We perform a detailed comparison between CellNuc-DETR and two segmentation methods optimized for cell nuclei detection and classification: CellViT, which focuses on achieving high detection and classification performance, and HoVer-NeXt, which is optimized for faster inference. In Table \ref{tab:pannuke}, we present the performance of CellNuc-DETR, demonstrating that it outperforms both methods in terms of cell classification and performs comparably to CellViT for cell nuclei detection. HoVer-NeXt, on the other hand, shows slightly lower performance in both tasks. Although CellViT provides a boost in performance compared to HoVer-NeXt, this improvement comes at the expense of a significantly slower inference pipeline, as illustrated in Figure \ref{fig:results:inference-sota}.

In contrast, the CellNuc-DETR pipeline achieves significantly faster inference times than both HoVer-NeXt and CellViT due to the efficiency of the detection task. Moreover, we have further optimized the pipeline, as discussed in Section \ref{sec:results:time}, by exploring different design components and configurations. As a result, we have developed a cell nuclei detection pipeline that is not only more accurate but also faster than the current state-of-the-art segmentation methods.

These advantages are clearly visualized in Figure \ref{fig:discussion:detection-vs-segmentation}, where we compare the macro-average F1 score for cell classification against the throughput (mm$^2$/s) of the pipelines. The figure shows that detection-based methods (CellNuc-DETR$_{tiny,3lvl}$, CellNuc-DETR$_{large,3lvl}$ and CellNuc-DETR$_{tiny,4lvl}$(0.50$\mu$m/px)) outperform segmentation-based methods (CellViT and HoVer-NeXt) both in accuracy and efficiency, establishing a new standard for cell nuclei detection and classification in digital pathology.

 \begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/inference-det-vs-seg.pdf}
    \caption{Throughout and performance of detection and segmentation pipelines.}
    \label{fig:discussion:detection-vs-segmentation}
\end{figure}

\paragraph{In-device sliding window} One of the components of CellNuc-DETR inference pipeline on WSIs is the use of an in-device overlapping window approach. This method involves dividing large image tiles into smaller, overlapping windows and processing them in parallel directly on the device. Firstly, retrieving large image tiles and processing them in-device with a sliding window rather than directly retrieving small patches reduces the number of I/O interactions with the slide, thereby decreasing data loading times. This minimizes the latency associated with accessing data from disk, which can be bottleneck in processing WSIs. Additionally, performing the sliding window operation in-device slightly reduces data transfer times compared to applying the sliding window on the CPU before sending data to the GPU. The overlap between windows results in redundant data when processed externally, increasing the amount of information transferred to the GPU. By conducting the sliding window operation directly on the device, CellNuc-DETR avoids this redundancy. Overall, the in-device sliding window approach enhances both speed and resource efficiency, making it a key component of the CellNuc-DETR pipeline for effective WSI analysis in digital pathology.

\paragraph{Dealing with edge cells}  During inference, the challenge of handling edge cells arises both within windows inside a tile and between tiles across a slide. Our approach leverages the overlapping nature of both windows and tiles to address this issue using a consistent strategy: we only retain cells whose centroids fall within the central crop of the image. The width of the margins is set to half of the overlap, ensuring that any centroid detected outside these borders is discarded, as it will be captured in the overlapping region of the adjacent tile. By setting the overlap between windows equal to the overlap between tiles, we ensure that the results remain agnostic to tile size. By default, we set both the window and tile overlaps to 64 pixels.

This approach is feasible because we are focused solely on the centroid and labels of the cell nuclei, rather than their shape. This process is significantly simpler and more efficient than the complex post-processing required by segmentation methods, highlighting one of the advantages of detection over segmentation.

While this method is an approximation, it effectively addresses the issue in most cases. A potential limitation occurs when a nucleus is larger than the overlap in the direction perpendicular to the tile partition and fully occupies the overlap between tiles, which could lead to duplicated detections. However, such instances are rare; only 0.3\% of the nuclei in the PanNuke dataset exceed 64 pixels in size. Indeed, the effectiveness of this window and tile merging strategy is empirically demonstrated by the results on the CoNSeP dataset, further validating our approach.
