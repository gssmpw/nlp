@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{azar2024general,
  title={A general theoretical paradigm to understand learning from human preferences},
  author={Azar, Mohammad Gheshlaghi and Guo, Zhaohan Daniel and Piot, Bilal and Munos, Remi and Rowland, Mark and Valko, Michal and Calandriello, Daniele},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4447--4455},
  year={2024},
  organization={PMLR}
}

@article{meng2024simpo,
  title={Simpo: Simple preference optimization with a reference-free reward},
  author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
  journal={arXiv preprint arXiv:2405.14734},
  year={2024}
}

@article{jung2024binary,
  title={Binary classifier optimization for large language model alignment},
  author={Jung, Seungjae and Han, Gunsoo and Nam, Daniel Wontae and On, Kyoung-Woon},
  journal={arXiv preprint arXiv:2404.04656},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@article{ethayarajh2024kto,
  title={Kto: Model alignment as prospect theoretic optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.01306},
  year={2024}
}

@article{zhao2023slic,
  title={Slic-hf: Sequence likelihood calibration with human feedback},
  author={Zhao, Yao and Joshi, Rishabh and Liu, Tianqi and Khalman, Misha and Saleh, Mohammad and Liu, Peter J},
  journal={arXiv preprint arXiv:2305.10425},
  year={2023}
}

@inproceedings{hong2024orpo,
  title={Orpo: Monolithic preference optimization without reference model},
  author={Hong, Jiwoo and Lee, Noah and Thorne, James},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={11170--11189},
  year={2024}
}

@article{park2024disentangling,
  title={Disentangling length from quality in direct preference optimization},
  author={Park, Ryan and Rafailov, Rafael and Ermon, Stefano and Finn, Chelsea},
  journal={arXiv preprint arXiv:2403.19159},
  year={2024}
}

@article{ivison2024unpacking,
  title={Unpacking DPO and PPO: Disentangling Best Practices for Learning from Preference Feedback},
  author={Ivison, Hamish and Wang, Yizhong and Liu, Jiacheng and Wu, Zeqiu and Pyatkin, Valentina and Lambert, Nathan and Smith, Noah A and Choi, Yejin and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2406.09279},
  year={2024}
}

@article{liu2024provably,
  title={Provably mitigating overoptimization in rlhf: Your sft loss is implicitly an adversarial regularizer},
  author={Liu, Zhihan and Lu, Miao and Zhang, Shenao and Liu, Boyi and Guo, Hongyi and Yang, Yingxiang and Blanchet, Jose and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2405.16436},
  year={2024}
}

@article{pal2024smaug,
  title={Smaug: Fixing failure modes of preference optimisation with dpo-positive},
  author={Pal, Arka and Karkhanis, Deep and Dooley, Samuel and Roberts, Manley and Naidu, Siddartha and White, Colin},
  journal={arXiv preprint arXiv:2402.13228},
  year={2024}
}

@article{jitowards,
  title={Towards efficient and exact optimization of language model alignment},
  author={Ji, Haozhe and Lu, Cheng and Niu, Yilin and Ke, Pei and Wang, Hongning and Zhu, Jun and Tang, Jie and Huang, Minlie},
  journal={arXiv preprint arXiv:2402.00856},
  year={2024}
}

@article{d2024anchored,
  title={Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment},
  author={D'Oosterlinck, Karel and Xu, Winnie and Develder, Chris and Demeester, Thomas and Singh, Amanpreet and Potts, Christopher and Kiela, Douwe and Mehri, Shikib},
  journal={CoRR},
  year={2024}
}

@article{wu2024self,
  title={Self-play preference optimization for language model alignment},
  author={Wu, Yue and Sun, Zhiqing and Yuan, Huizhuo and Ji, Kaixuan and Yang, Yiming and Gu, Quanquan},
  journal={arXiv preprint arXiv:2405.00675},
  year={2024}
}

@inproceedings{
anonymous2024direct,
title={Direct Imitation Learning: {RLHF} Secretly Performs Imitation Learning},
author={Anonymous},
booktitle={Submitted to The Thirteenth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=2QdsjiNXgj},
note={under review}
}

@article{xucontrastive,
  title={Contrastive preference optimization: Pushing the boundaries of llm performance in machine translation},
  author={Xu, Haoran and Sharaf, Amr and Chen, Yunmo and Tan, Weiting and Shen, Lingfeng and Van Durme, Benjamin and Murray, Kenton and Kim, Young Jin},
  journal={arXiv preprint arXiv:2401.08417},
  year={2024}
}

@inproceedings{
chen2024noise,
title={Noise Contrastive Alignment of Language Models with Explicit Rewards},
author={Huayu Chen and Guande He and Lifan Yuan and Ganqu Cui and Hang Su and Jun Zhu},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=KwRLDkyVOl}
}

@inproceedings{go2023aligning,
  title={Aligning language models with preferences through f-divergence minimization},
  author={Go, Dongyoung and Korbak, Tomasz and Kruszewski, Germ{\'a}n and Rozen, Jos and Ryu, Nahyeon and Dymetman, Marc},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={11546--11583},
  year={2023}
}

@article{pengadvantage,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey}
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007}
}

@inproceedings{skalse2022defining,
  title={Defining and Characterizing Reward Gaming},
  author={Skalse, Joar Max Viktor and Howe, Nikolaus HR and Krasheninnikov, Dmitrii and Krueger, David},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@inproceedings{gutmann2010noise,
  title={Noise-contrastive estimation: A new estimation principle for unnormalized statistical models},
  author={Gutmann, Michael and Hyv{\"a}rinen, Aapo},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={297--304},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{olmin2024connection,
  title={On the connection between Noise-Contrastive Estimation and Contrastive Divergence},
  author={Olmin, Amanda and Lindqvist, Jakob and Svensson, Lennart and Lindsten, Fredrik},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3016--3024},
  year={2024},
  organization={PMLR}
}

@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={SIAM review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@article{lecun2006tutorial,
  title={A tutorial on energy-based learning},
  author={LeCun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, M and Huang, Fujie and others},
  journal={Predicting structured data},
  volume={1},
  number={0},
  year={2006}
}

@inproceedings{yaircontrastive,
  title={Contrastive Divergence Learning is a Time Reversal Adversarial Game},
  author={Yair, Omer and Michaeli, Tomer},
  booktitle={International Conference on Learning Representations}
}

@article{naesseth2019elements,
  title={Elements of sequential monte carlo},
  author={Naesseth, Christian A and Lindsten, Fredrik and Sch{\"o}n, Thomas B and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={12},
  number={3},
  pages={307--392},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@article{peskun1973optimum,
  title={Optimum monte-carlo sampling using markov chains},
  author={Peskun, Peter H},
  journal={Biometrika},
  volume={60},
  number={3},
  pages={607--612},
  year={1973},
  publisher={Oxford University Press}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@inproceedings{robinsoncontrastive,
  title={Contrastive Learning with Hard Negative Samples},
  author={Robinson, Joshua David and Chuang, Ching-Yao and Sra, Suvrit and Jegelka, Stefanie},
  booktitle={International Conference on Learning Representations}
}

@article{hinton2002training,
  title={Training products of experts by minimizing contrastive divergence},
  author={Hinton, Geoffrey E},
  journal={Neural computation},
  volume={14},
  number={8},
  pages={1771--1800},
  year={2002},
  publisher={MIT Press}
}

@article{gutmann2012noise,
  title={Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics.},
  author={Gutmann, Michael U and Hyv{\"a}rinen, Aapo},
  journal={Journal of machine learning research},
  volume={13},
  number={2},
  year={2012}
}

@article{tang2024understanding,
  title={Understanding the performance gap between online and offline alignment algorithms},
  author={Tang, Yunhao and Guo, Daniel Zhaohan and Zheng, Zeyu and Calandriello, Daniele and Cao, Yuan and Tarassov, Eugene and Munos, R{\'e}mi and Pires, Bernardo {\'A}vila and Valko, Michal and Cheng, Yong and others},
  journal={arXiv preprint arXiv:2405.08448},
  year={2024}
}

@article{jozefowicz2016exploring,
  title={Exploring the limits of language modeling},
  author={Jozefowicz, Rafal and Vinyals, Oriol and Schuster, Mike and Shazeer, Noam and Wu, Yonghui},
  journal={arXiv preprint arXiv:1602.02410},
  year={2016}
}

@inproceedings{gustafsson2022learning,
  title={Learning proposals for practical energy-based regression},
  author={Gustafsson, Fredrik K and Danelljan, Martin and Sch{\"o}n, Thomas B},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4685--4704},
  year={2022},
  organization={PMLR}
}

@inproceedings{koster2009estimating,
  title={Estimating markov random field potentials for natural images},
  author={K{\"o}ster, Urs and Lindgren, Jussi T and Hyv{\"a}rinen, Aapo},
  booktitle={International Conference on Independent Component Analysis and Signal Separation},
  pages={515--522},
  year={2009},
  organization={Springer}
}

@inproceedings{ceylan2018conditional,
  title={Conditional noise-contrastive estimation of unnormalised models},
  author={Ceylan, Ciwan and Gutmann, Michael U},
  booktitle={International Conference on Machine Learning},
  pages={726--734},
  year={2018},
  organization={PMLR}
}

@article{lambert2024rewardbench,
  title={Rewardbench: Evaluating reward models for language modeling},
  author={Lambert, Nathan and Pyatkin, Valentina and Morrison, Jacob and Miranda, LJ and Lin, Bill Yuchen and Chandu, Khyathi and Dziri, Nouha and Kumar, Sachin and Zick, Tom and Choi, Yejin and others},
  journal={arXiv preprint arXiv:2403.13787},
  year={2024}
}

@article{chen2024towards,
  title={Towards Improved Preference Optimization Pipeline: from Data Generation to Budget-Controlled Regularization},
  author={Chen, Zhuotong and Liu, Fang and Zhu, Jennifer and Du, Wanyu and Qi, Yanjun},
  journal={arXiv preprint arXiv:2411.05875},
  year={2024}
}

@article{rosset2024direct,
  title={Direct nash optimization: Teaching language models to self-improve with general preferences},
  author={Rosset, Corby and Cheng, Ching-An and Mitra, Arindam and Santacroce, Michael and Awadallah, Ahmed and Xie, Tengyang},
  journal={arXiv preprint arXiv:2404.03715},
  year={2024}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@inproceedings{ding2023enhancing,
  title={Enhancing Chat Language Models by Scaling High-quality Instructional Conversations},
  author={Ding, Ning and Chen, Yulin and Xu, Bokai and Qin, Yujia and Hu, Shengding and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={3029--3051},
  year={2023}
}

@misc{
cui2023ultrafeedback,
title={UltraFeedback: Boosting Language Models with High-quality Feedback},
author={Ganqu Cui and Lifan Yuan and Ning Ding and Guanming Yao and Wei Zhu and Yuan Ni and Guotong Xie and Zhiyuan Liu and Maosong Sun},
year={2024},
url={https://openreview.net/forum?id=pNkOx3IVWI}
}

@misc{zhu2023starling,
  title={Starling-7b: Improving llm helpfulness \& harmlessness with rlaif},
  author={Zhu, Banghua and Frick, Evan and Wu, Tianhao and Zhu, Hanlin and Jiao, Jiantao},
  year={2023},
  publisher={November}
}

@article{qi2024online,
  title={Online DPO: Online Direct Preference Optimization with Fast-Slow Chasing},
  author={Qi, Biqing and Li, Pengfei and Li, Fangyuan and Gao, Junqi and Zhang, Kaiyan and Zhou, Bowen},
  journal={arXiv preprint arXiv:2406.05534},
  year={2024}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}

@article{miller2024adding,
  title={Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations},
  author={Miller, Evan},
  journal={arXiv preprint arXiv:2411.00640},
  year={2024}
}

@article{kim2024prometheus,
  title={Prometheus 2: An open source language model specialized in evaluating other language models},
  author={Kim, Seungone and Suk, Juyoung and Longpre, Shayne and Lin, Bill Yuchen and Shin, Jamin and Welleck, Sean and Neubig, Graham and Lee, Moontae and Lee, Kyungjae and Seo, Minjoon},
  journal={arXiv preprint arXiv:2405.01535},
  year={2024}
}

@article{dubois2024length,
  title={Length-controlled alpacaeval: A simple way to debias automatic evaluators},
  author={Dubois, Yann and Galambosi, Bal{\'a}zs and Liang, Percy and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2404.04475},
  year={2024}
}

@misc{li2024live,
  title={From live data to high-quality benchmarks: The arena-hard pipeline},
  author={Li, Tianle and Chiang, Wei-Lin and Frick, Evan and Dunlap, Lisa and Zhu, Banghua and Gonzalez, Joseph E and Stoica, Ion},
  year={2024},
  publisher={April}
}

@article{lambert2024t,
  title={T$\backslash$" ULU 3: Pushing Frontiers in Open Language Model Post-Training},
  author={Lambert, Nathan and Morrison, Jacob and Pyatkin, Valentina and Huang, Shengyi and Ivison, Hamish and Brahman, Faeze and Miranda, Lester James V and Liu, Alisa and Dziri, Nouha and Lyu, Shane and others},
  journal={arXiv preprint arXiv:2411.15124},
  year={2024}
}

@article{guo2024direct,
  title={Direct language model alignment from online ai feedback},
  author={Guo, Shangmin and Zhang, Biao and Liu, Tianlin and Liu, Tianqi and Khalman, Misha and Llinares, Felipe and Rame, Alexandre and Mesnard, Thomas and Zhao, Yao and Piot, Bilal and others},
  journal={arXiv preprint arXiv:2402.04792},
  year={2024}
}

@misc{naesseth2024elementssequentialmontecarlo,
      title={Elements of Sequential Monte Carlo}, 
      author={Christian A. Naesseth and Fredrik Lindsten and Thomas B. Sch√∂n},
      year={2024},
      eprint={1903.04797},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1903.04797}, 
}

@inproceedings{florence2022implicit,
  title={Implicit behavioral cloning},
  author={Florence, Pete and Lynch, Corey and Zeng, Andy and Ramirez, Oscar A and Wahid, Ayzaan and Downs, Laura and Wong, Adrian and Lee, Johnny and Mordatch, Igor and Tompson, Jonathan},
  booktitle={Conference on Robot Learning},
  pages={158--168},
  year={2022},
  organization={PMLR}
}

@article{tunstall2023zephyr,
  title={Zephyr: Direct distillation of lm alignment},
  author={Tunstall, Lewis and Beeching, Edward and Lambert, Nathan and Rajani, Nazneen and Rasul, Kashif and Belkada, Younes and Huang, Shengyi and von Werra, Leandro and Fourrier, Cl{\'e}mentine and Habib, Nathan and others},
  journal={arXiv preprint arXiv:2310.16944},
  year={2023}
}

@inproceedings{ma2018noise,
  title={Noise Contrastive Estimation and Negative Sampling for Conditional Models: Consistency and Statistical Efficiency},
  author={Ma, Zhuang and Collins, Michael},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={3698--3707},
  year={2018}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

