\begin{table*}[t]
\caption{Comparions of class-conditional generation results on UCF-101 and frame prediction results on K600. MTM indicates mask token modeling. Our model on K600 is trained for 77 epochs, we gray out models that use significantly more training computation (e.g., those trained for over 300 epochs) for a fair comparison.}
\label{tab:video_syn}
\centering
\renewcommand{\arraystretch}{1.1}
\setlength{\tabcolsep}{2.0pt}
\vspace{0.04in}
\begin{adjustbox}{max width=.9\linewidth}

\begin{tabular}{lcc|cc|rrr|rrr}
\toprule
\multirow{2}*{Type}& \multirow{2}*{Method} && \multirow{2}*{$\#$Param} && \multicolumn{3}{c}{UCF-101} & \multicolumn{3}{|c}{K600} \\
~ & ~ && ~ && FVD$\downarrow$ & \# Token & \# Steps & FVD$\downarrow$ & \# Token & \# Steps \\ 
\midrule
GAN & 	DVD-GAN~\citep{clark2019adversarial} && N/A && - & - & -  & 31.1 & - & - \\
\midrule
Diffusion & VideoFusion~\citep{luo2023videofusion} && N/A && 173 & - & - & - & - & - \\
Diffusion & Make-A-Video~\citep{singer2022make} && N/A && 81.3 & - & - & - & - & - \\
Diffusion & HPDM-L~\citep{skorokhodov2024hierarchical} && 725M && 66.3 & - & - & - & - & - \\
\midrule
MTM & Phenaki~\cite{villegas2022phenaki} && 227M && - & - & - & \demph{36.4} & \demph{-} & \demph{48} \\
MTM & MAGVIT~\cite{yu2023magvit} && 306M && 76 & 1280 & 12 & \demph{9.9} & \demph{768} & \demph{12} \\
MTM & MAGVITv2~\cite{yu2023language} && 840M && 58 & 1280 & 24 & \demph{4.3} & \demph{768} & \demph{24} \\
\midrule
AR & LVT~\cite{rakhimov2020latent} && 50M && - & - & - & 224.7 & 1024 & 1024 \\
AR & ViTrans~\cite{weissenborn2019scaling} && 373M && - & - & - & 170.0 & 4096 & 4096 \\
AR & CogVideo~\cite{hong2022cogvideo} && 9.4B && 626 & 2000 & 2000 & 109.2 & 2000 & 2000 \\
AR & ViVQVAE~\cite{walker2021predicting} && N/A && - & - & - & 64.3 & 4096 & 4096 \\
AR & TATS~\cite{ge2022long} && 321M && 332 & 1024 & 1024 & - & - & - \\
AR & OmniTokenizer~\cite{Wang2024OmniTokenizerAJ} && 227M && 314 & 5120 & 5120 & \demph{34.2} & \demph{3072} & \demph{3072} \\
AR & OmniTokenizer~\cite{Wang2024OmniTokenizerAJ} && 650M && 191 & 5120 & 5120 & \demph{32.9} & \demph{3072} & \demph{3072} \\
AR & MAGVITv2-AR~\cite{yu2023language} && 840M && 109 & 1280 & 1280 & - & - & - \\
AR & PAR-16$\times$~\citep{wang2024parallelized} && 792M && 103.4 & 1280 & 95 & - & - & - \\
\midrule
Semi-AR & \modelname-XL (Ours) && 700M && 103.3 & 1280 & 95 & 25.5 & 768 & 48 \\
Semi-AR & \modelname-XXL (Ours) && 1.2B && 85.8 & 1280 & 95 & 23.0 & 768 & 48 \\
Semi-AR & \modelname-3B (Ours) && 3B && \textbf{55.3} & 1280 & 95 & \textbf{19.5} &  768 & 48 \\
\bottomrule
\end{tabular}

% \begin{tabular}{lcc|cc|rrrr|rrrr}
% \toprule
% \multirow{2}*{Type}& \multirow{2}*{Method} && \multirow{2}*{$\#$Param} && \multicolumn{4}{c}{UCF-101} & \multicolumn{4}{|c}{K600} \\
% ~ & ~ && ~ && FVD$\downarrow$ & PSNR$\uparrow$ & SSIM$\uparrow$ & LPIPS$\downarrow$ & FVD$\downarrow$ & PSNR$\uparrow$ & SSIM$\uparrow$ & LPIPS$\downarrow$ \\ 
% \midrule
% GAN & 	DVD-GAN~\citep{clark2019adversarial} && N/A && - & - & - & - & 31.1 & - & - & - \\
% \midrule
% Diffusion & VideoFusion~\citep{luo2023videofusion} && N/A && 173 & - & - & - & - & - & - & - \\
% Diffusion & Make-A-Video~\citep{singer2022make} && N/A && 81.3 & - & - & - & - & - & - & - \\
% Diffusion & HPDM-L~\citep{skorokhodov2024hierarchical} && 725M && 66.3 & - & - & - & - & - & - & - \\
% \midrule
% MTM & Phenaki~\cite{villegas2022phenaki} && 227M && - & - & - & - & \demph{36.4} & - & - & -\\
% MTM & MAGVIT~\cite{yu2023magvit} && 306M && 76 & - & - & - & \demph{9.9} & - & - & -\\
% MTM & MAGVITv2~\cite{yu2023language} && 840M && 58 & - & - & - & \demph{4.3} & - & - & -\\
% \midrule
% AR & LVT~\cite{rakhimov2020latent} && 50M && - & - & - & - & 224.7 & - & - & - \\
% AR & ViTrans~\cite{weissenborn2019scaling} && 373M && - & - & - & - & 170.0 & - & - & -\\
% AR & CogVideo~\cite{hong2022cogvideo} && 9.4B && 626 & - & - & - & 109.2 & - & - & -\\
% AR & ViVQVAE~\cite{walker2021predicting} && N/A && - & - & - & - & 64.3 & - & - & -\\
% % AR & Trans~\cite{nash2022transframer} && 662M && - & & & 25.4 \\ 
% AR & TATS~\cite{ge2022long} && 321M && 332 & - & - & - &-&-&-&-\\
% % \rowcolor{Gray}
% AR & OmniTokenizer~\cite{Wang2024OmniTokenizerAJ} && 227M && 314 & - & - & - & \demph{34.2} & - & - & - \\
% % \rowcolor{Gray}
% AR & OmniTokenizer~\cite{Wang2024OmniTokenizerAJ} && 650M && 191 & - & - & - & \demph{32.9} & \demph{21.4} & \demph{.781} & \demph{.061} \\
% \midrule
% Semi-AR & \modelname-XL (Ours) && 700M && 55.0 & 22.6 & .708 & .115 & 25.5 & 21.1 & .724 & .070 \\
% Semi-AR & \modelname-XXL (Ours) && 1.2B && 34.0 & 23.4 & \textbf{.749} & .113 & 23.0 & \textbf{21.2} & .727 & .069 \\
% Semi-AR & \modelname-3B (Ours) && 3B && \textbf{20.7} & \textbf{24.6} & \textbf{.749} & \textbf{.109} & \textbf{19.5} & \textbf{21.2} & \textbf{.728} & \textbf{.068} \\
% \bottomrule
% \end{tabular}


\end{adjustbox}
\end{table*}