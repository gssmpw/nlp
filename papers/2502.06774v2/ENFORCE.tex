\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{float}
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{todonotes}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\usepackage{subcaption}
\graphicspath{{media/}}     % organize your images and other figures under media/ folder
% \usepackage{natbib}
\usepackage{orcidlink}

\usepackage[pagewise]{lineno}
\usepackage{todonotes}
\nolinenumbers

% \usepackage[pagewise]{lineno}
% \usepackage{todonotes}
% \linenumbers
% \linespread{1.2}

% Load amsthm package for theorem environments
\usepackage{amsthm}

% Define the Assumption environment
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
%\fancyhead[LO]{Running Title for Header}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}
  
%% Title
\title{ENFORCE: Exact Nonlinear Constrained Learning with Adaptive-depth Neural Projection
%%%% Cite as
%%%% Update your official citation here when published 
%\thanks{\textit{\underline{Citation}}: 
%\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
  Giacomo Lastrucci\orcidlink{0009-0005-3475-9351}\\
  Process Intelligence Research Group\\
  Department of Chemical Engineering\\
  Delft University of Technology\\
  %% examples of more authors
   \And
  Artur M. Schweidtmann\orcidlink{0000-0001-8885-6847}\\
  Process Intelligence Research Group\\
  Department of Chemical Engineering\\
  Delft University of Technology \\
  \texttt{a.schweidtmann@tudelft.nl} \\
}


\begin{document}
\maketitle


\begin{abstract}
Ensuring neural networks adhere to domain-specific constraints is crucial for addressing safety and ethical concerns while also enhancing prediction accuracy. Despite the nonlinear nature of most real-world tasks, existing methods are predominantly limited to affine or convex constraints. We introduce ENFORCE, a neural network architecture that guarantees predictions to satisfy nonlinear constraints exactly. ENFORCE is trained with standard unconstrained gradient-based optimizers (e.g., Adam) and leverages autodifferentiation and local neural projections to enforce any $\mathcal{C}^1$ constraint to arbitrary tolerance $\epsilon$. We build an adaptive-depth neural projection (AdaNP) module that dynamically adjusts its complexity to suit the specific problem and the required tolerance levels. ENFORCE guarantees satisfaction of equality constraints that are nonlinear in both inputs and outputs of the neural network with minimal (and adjustable) computational cost.
\end{abstract}


% keywords can be removed
\keywords{Constrained learning \and Hard-constrained neural networks \and Trustworthy AI \and Physics-informed machine learning}



\section{Introduction}
Neural networks (NNs) are the backbone of many recent advancements in artificial intelligence (AI), excelling in tasks such as natural language processing, image analysis, and scientific discovery due to their modularity, simplicity, and strong generalization capabilities. However, their ability falls short when strict adherence to domain-specific constraints is required. Depending on the task, prior knowledge and rules about the system (e.g., from physics, safety, or ethics) are often available and are typically leveraged by humans in decision-making processes. In contrast, traditional data-driven methods such as NNs rely solely on data. Thus, trained NNs may be accurate on a training and test data set but still may not satisfy constraints exactly, leading to inconsistent predictions. This limitation not only generates substantial skepticism, hindering their adoption in real-world applications but can potentially result in erroneous or unfeasible outcomes when NNs are applied to decision-making tasks. Moreover, when prior domain knowledge is available and can be expressed as analytical expressions such as equations, ensuring that NNs adhere to this information is crucial to avoid the suboptimal utilization of valuable insights.\\
Enforcing strict constraints in NNs is a promising area of research for many fields. For example, in AI for Science, integrating first-principle laws ensures physically consistent models enabling insightful scientific discovery~\cite{Wang2023_Scientificdiscoveryage, Xu2021_Artificialintelligencepowerful}. More broadly, constraining neural network predictions can have a transformative impact in domains where strict adherence to critical requirements is essential. This includes applications such as safety-critical systems (e.g., self-driving vehicles~\cite{Gupta2021_Deeplearningobject}, healthcare~\cite{Gerke2020_Ethicallegalchallenges}), fairness and bias mitigation~\cite{Feuerriegel2020_FairAIChallenges, Hardt2016_EqualityOpportunitySupervised}, and compliance with regulatory standards (e.g., in finance~\cite{Cao2022_AIFinanceChallenges}). Additionally, with the rise of generative AI (GenAI), enforcing constraints on generation processes could mitigate potential risks and ensure trustworthy adherence to given criteria.
Constraining the neural network output to adhere to strict rules is also beneficial to tackle traditional machine learning challenges, such as overfitting and underfitting in data-scarce regimes~\cite{Min2024_HardConstrainedNeural}. It is also plausible that such constraints could enable some level of extrapolation in the presence of incomplete data or in holes of convex hulls~\cite{Kahrs2007_validitydomainhybrid, Schweidtmann2021_Obeyvaliditylimits}. Hence, the combination of enhanced accuracy and adherence to pre-existing domain knowledge could enable the safe use of NNs as surrogate models in computationally expensive applications~\cite{Schweidtmann2018_DeterministicGlobalOptimization}. \\
Enforcing constraints in NNs is not an easy task. Early approaches often relied on incorporating penalty terms into the loss function to reduce violations of physical laws~\cite{Raissi2019_Physicsinformedneural}. Yet, these penalty-based methods offer no guarantees of constraint satisfaction (\textit{soft-constrained}). In contrast, other methods aim to ensure strict adherence to analytical constraints by design (\textit{hard-constrained}). For instance, one can use activation functions such as sigmoids or ReLU to bound outputs. To enforce analytical constraints beyond bounds, recent studies incorporate correction layers into NNs to project or complete predictions, ensuring they lie within the feasible region. Recent research has developed efficient methods to enforce analytical constraints defined by affine relationships between input and output variables or by convex regions (See Section~\ref{sec:related-work}). However, many real applications such as in science or sociology are inherently governed by nonlinear relationships between the involved variables~\cite{Mize2019_BestPracticesEstimating, Nicolis1995_IntroductionNonlinearScience}. Existing approaches for handling nonlinear constraints predominantly rely on external root-finding algorithms or constrained optimization solvers (Section~\ref{subsec:related-work-hard}). These methods introduce significant computational overhead and complicate model construction, thereby compromising the modularity and flexibility typically associated with NNs.\\
In this paper, we propose ENFORCE, a neural network architecture that ensures predictions strictly satisfy nonlinear constraints representing domain knowledge or critical requirements. ENFORCE is trained using standard unconstrained optimization techniques and leverages an adaptive-depth projection module to enforce constraints by construction without relying on external solvers. 

\section{Related work}
\label{sec:related-work}
This section reviews existing approaches to enforce constraints in NNs. According to the focus of this paper, a more in-depth analysis will be conducted on existing methods for enforcing algebraic equality constraints exactly.

\subsection{Soft-constrained neural networks}
% - Defined as early attempts to include constraints. Cite Raissi, Lu, maybe perdikaris and kardianakis.\\
One of the earliest approaches to embedding domain knowledge into NNs involves the use of \textit{soft} constraints. Soft constraints are incorporated as penalty terms appended to the loss function, penalizing residuals of algebraic~\cite{Erichson2019_PhysicsinformedAutoencoders, Pfrommer2020_ContactNetsLearningDiscontinuousa} or differential equations underlying the system~\cite{ Wang2021_Learningsolutionoperator}. Physics-informed neural networks (PINNs)~\cite{Raissi2019_Physicsinformedneural} represent a widely used framework designed to solve partial differential equations (PDEs) with NNs by employing soft constraints and collocation points.\ Although the soft-constrained approach places no restrictions on the complexity of the constraints, it has the drawback of not guaranteeing strict adherence to them. Furthermore, increasing the complexity of the loss function -- especially when the different terms vary in nature or scale -- can degrade the optimization performance of the neural network, often resulting in suboptimal accuracy~\cite{Wang2020_Understandingmitigatinggradient, Wang2020_WhenwhyPINNs}.

\subsection{Hard-constrained neural networks}
\label{subsec:related-work-hard}
Hard-constrained NNs refer to methodological approaches ensuring that neural network predictions strictly adhere to analytical constraints. These constraints, explicitly encoded within the architecture, act as inductive biases, guiding the learning process toward compliance with domain knowledge or restrictions~\cite{Karniadakis2021_Physicsinformedmachine}. Architectures such as convolutional neural networks (CNNs)~\cite{LeCun1989_BackpropagationAppliedHandwritten} and graph neural networks (GNNs)~\cite{Bronstein2017_GeometricDeepLearning, Wu2021_ComprehensiveSurveyGraph} encode inductive biases by guaranteeing invariance with respect to patterns and symmetries. Simple analytical constraints can be enforced using differentiable functions, such as sigmoids or ReLU for output bounding and softmax for simplex constraints (non-negativity and normalization). Recent literature includes significant contributions for enforcing analytical inequality constraints, such as convex polytopes and convex sets more generally~\cite{Frerix2020_HomogeneousLinearInequality, Donti2021_DC3learningmethod, Wang2024_LinSATNetPositiveLinear, Tordesillas2023_RAYENImpositionHard, Konstantinov2023_NewComputationallySimple}. One can also constrain the neural network to guarantee specific functional characteristics, such as being 1-Lipschitz~\cite{Anil2018_SortingoutLipschitz} or Lyapunov stable~\cite{Manek2020_LearningStableDeepa}, nevertheless, this is not a core objective of this study. For a broad and recent review on hard-constrained NNs, the reader is also referred to~\cite{Min2024_HardConstrainedNeural}.\\
Since this paper focuses on analytical equality constraints, the following literature review considers existing methods for this specific case. 

\paragraph{Projection methods}
Many methods for encoding hard equality constraints utilize projection techniques, which correct preliminary neural network predictions by appending a non-trainable layer to the output. Projections can be formulated as optimization problems (e.g., distance minimization) or derived from geometric principles. For example, in~\cite{Chen2021_Theoryguidedhard} NN predictions of physical systems governed by PDEs are projected to ensure solutions satisfy the finite difference discretization of the underlying linear PDEs. A more general approach is the KKT-hPINN~\cite{Chen2024_PhysicsInformedNeural}, which enforces linear equality constraints of the form $Ax+By=b$, though its applicability is limited to affine equations. Recently, HardNet~\cite{Min2024_HardConstrainedNeural} was introduced to enforce equality and inequality constraints affine in the output, without input restrictions, via a closed-form projection step. HardNet-Cvx~\cite{Min2024_HardConstrainedNeural} extends this approach to more general convex functions in the inputs, leveraging differentiable optimization layers supported by optimization solvers~\cite{Agrawal2019_DifferentiableConvexOptimization}.

\paragraph{Predict-and-complete}
Alternatively, the neural network can predict a partial set of output variables, $y_P \in \mathbb{R}^{N_O - N_C}$, and complete the prediction by solving the system of constraints based on this partial output. This approach ensures that the constraints are always satisfied. For instance, Beucler et al. introduced this concept to simulate physical systems such as climate modeling~\cite{Beucler2019_EnforcingAnalyticConstraints}. However, when the constraints are not explicitly defined, solving the system requires a root-finding solver. Similar approaches have been proposed within the hybrid modeling community, particularly in the \textit{serial} configuration, where a fully data-driven method is used to predict certain inputs to a mechanistic model~\cite{Schweidtmann2024_reviewperspectivehybrida}. While studies like DC3~\cite{Donti2021_DC3learningmethod} have developed efficient backpropagation techniques, scenarios involving implicit nonlinear constraints can be computationally expensive to tackle with predict-and-complete methods. Moreover, the predict-and-complete approach can reduce regression accuracy by hindering the representation capabilities of NNs~\cite{Beucler2019_EnforcingAnalyticConstraints}.


\paragraph{Constrained optimization}
One of the most popular fields of application of constrained learning is for solving (parametric) constrained optimization problems using NNs~\cite{Kotary2021_EndEndConstrained}. OptNet~\cite{Amos2017_OptNetDifferentiableOptimization} is an optimization layer developed to solve quadratic programs. Angrawal et al.~\cite{Agrawal2019_DifferentiableConvexOptimization} expands the methodology to convex programs. They develop efficient differentiation techniques through such layers. However, the forward pass always requires the solution of a constrained optimization problem. Recently, Mukherjee and Bhattacharyya~\cite{Mukherjee2024_developmentsteadystate} brute-forced the constrained learning paradigm by training a neural network using an NLP solver such as IPOPT~\cite{Waechter2005_implementationinteriorpoint} instead of standard unconstrained optimization algorithms. Also, NNs have been formulated as constrained optimization problems and solved using deterministic global solvers~\cite{Schweidtmann2018_DeterministicGlobalOptimization}. However, these approaches pose severe limitations in terms of NNs and dataset size.


\paragraph{Other methods}
Other methods have been proposed for constrained learning in NNs, mostly considering affine or convex regions. Many of them consider constraints only dependent on the input of the neural network~\cite{Schweidtmann2021_Obeyvaliditylimits, Tordesillas2023_RAYENImpositionHard, Balestriero2022_POLICEProvablyOptimal, Brosowsky2020_SampleSpecificOutput}, others design strategies to include the dependence on both inputs and outputs~\cite{Konstantinov2023_NewComputationallySimple, Lastrucci2025_PicardKKThPINN}. Recently, contributions to enforce general logic and linear constraints have been proposed by the neuro-symbolic AI community, developing constraining layers using logic programming to improve multi-label classification and synthetic data generation~\cite{Giunchiglia2021_MultiLabelClassification, Stoian2024_HowRealisticIs}.\\
However, to the best of our knowledge, there is no method designed to enforce any nonlinear equality constraints involving both the input and the output of the neural network by encoding them in the architecture and without relying on external solvers.

\section{Preliminaries}
\paragraph{Problem statement}
Given a dataset $(x_i, y_i)_{i=1,...,N}$, we aim to train a neural network $f_{\theta}$ with parameters $\theta$ to approximate the underlying relationships while satisfying a set of known algebraic equality constraints $c(x,y)=0$. In general, $c$ can be any nonlinear function in the input $x$ and output $y$ of the neural network, incorporating domain knowledge or specifying critical requirements. 

\begin{assumption}
i) The constraints $c(x,y)=0$ are feasible, ii) $N_C < N_O$, where $N_C$ is the number of equality constraints and $N_O$ is the output dimensionality of the neural network, i.e., there are available degrees of freedom to learn.
\end{assumption}

One way to enforce the neural network prediction $\hat{y}$ to satisfy the constraints is to project it onto the feasible hypersurface defined by $c(x,y)=0$. The projection can be defined as a mathematical program:

\begin{equation}
\label{eq:weighted_nonlinear_projection}
\begin{aligned}
\Tilde{y} = &\argmin_{y} \frac{1}{2} \|y - \hat{y}\|^T W \|y - \hat{y}\| \\
\text{s.t.} & \quad  c(x, y) = 0
\end{aligned}
\end{equation}

If $W$ is the identity matrix, then we essentially correct the prediction by projecting it orthogonally onto the feasible region, i.e., we seek the feasible solution minimizing the Euclidean distance ($\|\cdot\|$). A local solution to the nonlinear program (NLP)~Eq.~\ref{eq:weighted_nonlinear_projection} can be found by solving the first-order necessary optimality conditions, known as Karush–Kuhn–Tucker (KKT) conditions. However, the latter is not necessarily an easy task as it may involve solving a system of nonlinear equations.

\paragraph{Quadratic projection}
When $c(x, y)$ is an affine function in the neural network input and output (i.e., $c(x, y) = Ax + By - b = 0$), then the problem results in a quadratic program (QP) and a closed-form analytical solution is available for the KKT conditions. Based on such observation, Chen et al. proposed KKT-hPINN by stacking a fixed non-trainable projection layer on top of a neural network, to guarantee the prediction adheres to given affine functions~\cite{Chen2024_PhysicsInformedNeural}. However, the method is restricted to linear constraint as a closed-form is not available when $c$ is nonlinear.\\
We note that a closed-form is still available when generalizing to any function in the input $x$, as the projection operation is still a QP. We observe that, assuming an affine dependence on $y$ such that $c = C(x)y - v(x) - b = 0$, $C(x)$ and $v(x)$ play the roles of linear coefficients and translation, respectively, in a local sense. That is, given a input $x_i$ and a prediction $\hat{y}_i$, then any function of $x_i$ is a constant term with respect to the optimization problem in Eq.~\ref{eq:weighted_nonlinear_projection}, which becomes again a QP.\\
Enforcing affine functions is not new and is achieved also through other techniques \cite{Min2024_HardConstrainedNeural, Balestriero2022_POLICEProvablyOptimal}. However, relaxing the assumption to allow for any nonlinear constraints of both the input and output of the neural network commonly results in decreased computational efficiency, as typically requires the use of constrained optimization techniques~\cite{Mukherjee2024_developmentsteadystate} or nonlinear solvers such as Newton's methods~\cite{Donti2021_DC3learningmethod}.


\section{Nonlinear constrained learning}
We present ENFORCE, a framework designed for general and efficient nonlinear constrained learning. The method employs a computationally cheap adaptive neural projection and has no restriction on the nonlinearity of $\mathcal{C}^1$ constraints involving both the input and output vectors of the neural network. At inference time, the model predictions satisfy the constraints to arbitrary tolerance $\epsilon$.

\subsection{AdaNP: Adaptive-depth neural projection}
\label{subsec:adanp}
We reformulate the NLP in~Eq.~\ref{eq:weighted_nonlinear_projection} and exploit the efficiency of quadratic projections to generalize the methodology to any nonlinear constraint. Assuming $c$ is of class $\mathcal{C}^1$, we use first-order Taylor expansion to locally linearize the constraints around the neural network input $x_0$ and prediction $\hat{y}$:

\begin{equation}
\label{eq:Taylor}
c(x,y) \simeq c(x_0,\hat{y}) + \left.J_xc\right|_{x_0, \hat{y}} (x - x_0) + \left.J_yc\right|_{x_0, \hat{y}} (y - \hat{y}),
\end{equation}

where $J_xc$ and $J_yc$ are the Jacobian matrices with respect to the variable $x$ and $y$, respectively.
Since the neural network input is fixed for a given sample, the approximation is exact in $x$, hence, $x = x_0$. Considering orthogonal projection for notation simplicity, the nonlinear optimization problem in~Eq.~\ref{eq:weighted_nonlinear_projection} is locally approximated by a (linearly constrained) QP:

\begin{equation}
\label{eq:linearized_projection}
\begin{aligned}
\Tilde{y} = &\argmin_{y} \frac{1}{2} \| y - \hat{y} \|^2 \\
\text{s.t.} & \quad c(x,\hat{y}) + \left.J_yc\right|_{x, \hat{y}} (y - \hat{y}) = 0
\end{aligned}
\end{equation}

% Neural projection layer and arbitrary stack of them. 
\begin{definition}
\label{def:NPlayer}
Given an input $x \in \mathbb{R}^{N_I}$ to a neural network $f_{\theta}$, its prediction $\hat{y} = f_{\theta}(x) \in \mathbb{R}^{N_O}$, and a set of constraints $c\in\mathcal{C}^1(\Omega, \mathbb{R}^{N{_C}})$, with $N_C<N_O$, we define an operator $\mathcal{P}$ such that $\tilde{y}=\mathcal{P}(\hat{y})$ is the solution to the linearized quadratic program in Eq.~\ref{eq:linearized_projection}, in the domain $\Omega$ where the constraints are defined.\\
In particular, $\tilde{y}=B^*\hat{y}+v^*$, with $B^* =I - B^T(BB^T)^{-1}B$ and $v^* = B^T(BB^T)^{-1}v$, where $I\in \mathbb{R}^{N_O \times N_O}$ is the identity matrix, and:
\begin{equation*}
\begin{aligned}
B &= \left.J_yc\right|_{x, \hat{y}} \\
v &= \left.J_yc\right|_{x, \hat{y}} \hat{y} - c(x, \hat{y})
\end{aligned}
\end{equation*}
\end{definition}

Since a closed-form expression for the operator $\mathcal{P}$ is derived (Appendix~\ref{app:mathematical_derivations}), we can define a differentiable \textit{neural projection} (NP) layer representing the operator $\mathcal{P}$. The forward and backward passes of an NP layer are computationally cheap (more details on implementation and computational cost are given in Appendix~\ref{app:implementation_details}). However, the operator $\mathcal{P}$ projects the neural network prediction onto a linear approximation of the nonlinear constraints (i.e., the tangent hyperplane). The error that we introduce is proportional to the projection displacement $\ell_{p}=||\tilde{y} - \hat{y}||$. From this consideration, it follows that (1) the error is mitigated as the projection displacement is small, i.e., the neural network prediction is sufficiently accurate, and (2) a single NP layer may not ensure exact adherence to nonlinear constraints.
Nevertheless, it is worth noting that a single NP layer guarantees strict satisfaction of equality constraints that are affine in $y$ and nonlinear in $x$, i.e., it efficiently enforces constraint classes considered in similar recent works \cite{Chen2024_PhysicsInformedNeural, Min2024_HardConstrainedNeural}.

To address the challenge of ensuring exact adherence to nonlinear constraints, as highlighted in the second consideration above, we propose AdaNP: an adaptive-depth neural projection composition to enforce nonlinear constraint satisfaction to arbitrary tolerance $\epsilon$. 
\begin{definition}
Given an operator $\mathcal{P}$ as defined in Def.~\ref{def:NPlayer}, AdaNP is a composition of $n$ operators $\mathcal{P}$, such that:
\begin{equation*}
    \text{AdaNP} = \mathcal{P}_1 \circ \dots \circ \mathcal{P}_n
\end{equation*}
Then, given an arbitrarily small scalar $\epsilon$ and $n \in \mathbb{N}$ such that $|c(x,\tilde{y}_n)|<\epsilon$, the feasible prediction $\tilde{y}_n$ is computed as:
\begin{equation*}
\tilde{y}_n = (\mathcal{P}_1 \circ \dots \circ \mathcal{P}_n)(\hat{y})
\end{equation*}
\end{definition}

AdaNP is a differentiable stack of $n$-NP layers that can be composed on every neural network backbone. The depth $n$ adjusts adaptively depending on the nonlinearities and the specified tolerance. Accurate NNs typically result in shallower AdaNP modules, since the projection displacement $\ell_{p}$ is related to the loss $\ell_{d} = ||\hat{y}-y^*||$, where $y^*$ is the ground truth output.
This introduces a trade-off between the complexity of the backbone and the required depth of AdaNP to satisfy the specified tolerance criteria. It is worth mentioning that a similar concept of iterative neural projections, although employed for a different application and objective, is also utilized in~\cite{Yang2020_LearningPhysicalConstraints}.

% Similarity to SQP. 
\paragraph{Analogy with Sequential Quadratic Programming}
AdaNP can also be seen as an iterative method that recursively improves the solution of a linearized nonlinear program. Here, we notice the similarity to sequential quadratic programming (SQP) techniques. Specifically, AdaNP is a simple case of SQP method for which the objective function is naturally quadratic while the nonlinear constraints are linearized (in contrast to full SQP, in which the objective function is quadratically approximated). This observation could potentially allow to analyze the convergence of the method using SQP theory~\cite{Fletcher2002_Nonlinearprogrammingpenalty, Fletcher2002_GlobalConvergenceFilter}.

\paragraph{Deviation from Newton's method}
While the KKT conditions for an NLP (Eq.~\ref{eq:weighted_nonlinear_projection}) can be more generally solved using Newton's methods, our method circumvents the computational overhead associated with calculating the Hessian matrix of the constraints (Appendix~\ref{app:mathematical_derivations}).

\subsection{Architecture}
\label{subsection:Architecture}
The architecture of ENFORCE (Fig.~\ref{fig:architecture}) is composed of (1) a backbone neural network, that can be of any kind and complexity, and (2) an AdaNP module. The depth of AdaNP depends on the backbone performance and specified tolerance. Indeed, AdaNP can be purposely tuned to increase training efficiency (Section~\ref{subsection:training}). A single NP layer is composed of two steps: (1) automatic differentiation and (2) local neural projection.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/architecture.png}
    \caption{ENFORCE consists of a backbone neural network and an adaptive neural projection (AdaNP) module. The backbone network can be of every kind, such as fully connected, convolutional, or transformer architecture. AdaNP includes an adaptive number of neural projection (NP) layers, each composed of an auto-differentiation and a local projection step.}
    \label{fig:architecture}
\end{figure}

\paragraph{Exact Jacobian computation} 
To compute the Jacobian of the constraint system, we leverage automatic differentiation available in most deep learning libraries~\cite{paszke2019pytorchimperativestylehighperformance, tensorflow2015-whitepaper, jax2018_github}. Computing the local Jacobian $J_yc|_{x, \hat{y}}$ is computationally inexpensive, as it requires propagating derivatives only through the constraints and does not involve the neural network backbone. Furthermore, its computation can be efficiently parallelized on GPU.

\paragraph{Local neural projection}
The neural projection defined by the operator $\mathcal{P}$ in Def.~\ref{def:NPlayer} depends on individual input-prediction instances. Thus, the projection is locally defined in the neighborhood of ($x_i, \hat{y}_i$). We parallelize the computation of local neural projections by building a \textit{rank-3} tensor $\mathbf{B}^*$ and a \textit{rank-2} tensor $\mathbf{v}^*$ (Appendix~\ref{app:implementation_details}). Thus, we reduce the cost of an NP layer from $\mathcal{O}(BS \times N_C^3)$ to $\mathcal{O}(N_C^3)$, allowing effective training with stochastic gradient descent techniques with virtually no limitation on the batch dimension ($BS$). For modern hardware, handling output dimensionalities of $N_C<10^3$ leads to minimal computational cost.


\subsection{Implications of orthogonal projections}
\label{subsection:orth_proj_theory}
% Describe the implications and state that we start the training from when the projection is meaningful in terms of loss.
The set of constraints $c(x,y) = 0$ describes an infinite-wide feasible region (i.e., a hypersurface) where the constraints are defined. Hence, one could ask whether the projections are unique and thus suitable for guiding the learning process. To this end, theoretical insights can be derived by analyzing the case of orthogonal projections, i.e., $W=I$ (Eq.~\ref{eq:weighted_nonlinear_projection}).

\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/proj-affine.png}
        \caption{Affine constraint}
        \label{fig:orthogonal-projection-affine}
    \end{subfigure}
    \hspace{0.1\textwidth}
    \begin{subfigure}[t]{0.28\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/proj-nonlinear.png}
        \caption{Nonlinear constraint}
        \label{fig:orthogonal-projection-nonlinear}
    \end{subfigure}
    \caption{Orthogonal projection on the feasible region when $y \in \mathbb{R}^2$. Orthogonal projections on affine constraints are unique and always lead to enhanced predictions. When the constraint is nonlinear, multiple orthogonal projections are possible, not necessarily improving the prediction.}
    \label{fig:orthogonal-projection}
\end{figure}


\paragraph{Affine constraints}
Considering constraints that are affine in $y$, the feasible space is a hyperplane defined in $\mathbb{R}^{N_O}$. Under those circumstances, it can be proven that there exists a unique orthogonal projection defining $\tilde{y}$ from a point $\hat{y} \in \mathbb{R}^{N_O}$ such that $c(\tilde{y})=0$. More interestingly, if $y^*$ is the ground truth, then $\forall \hat{y}, y^* ,\, ||y^* - \tilde{y}|| < ||y^* - \hat{y}||$, that is, the projected prediction is \textit{always} a better prediction than the original one (Fig.~\ref{fig:orthogonal-projection-affine}). In such a condition, constrained learning effectively guides the learning process toward the ground truth. In particular, the loss is expected to decrease compared to the unconstrained case from the very start of the training process.

\paragraph{Nonlinear constraints}
The same considerations do not hold for nonlinear hypersurfaces. Firstly, there could be multiple points on the hypersurface where the normal vectors point toward the prediction $\hat{y}$. Secondly, the closest orthogonal projection can potentially represent a worse prediction, since the distance $||y^* - \tilde{y}||$ is not ensured to be shorter than $||y^* - \hat{y}||$ (see Fig.~\ref{fig:orthogonal-projection-nonlinear}). Then, the projection step could potentially conflict with the training step, preventing the training process itself from converging. Therefore, we can not conclude that orthogonal projections onto a nonlinear feasible region always guide the learning process efficiently.

\subsection{Training ENFORCE}
\label{subsection:training}
We train ENFORCE using standard unconstrained gradient descent methods (i.e., Adam). We develop and use a constrained learning methodology using AdaNP to guide the neural network training to convergence, supported by the theoretical implications of orthogonal projections described above (Section~\ref{subsection:orth_proj_theory}).

\paragraph{Linearized constraints and training strategy}
ENFORCE does not project the predictions directly on the nonlinear feasible region but on a locally linearized counterpart. Thus, we can assume the existence of a unique closest orthogonal projection. However, the quality of the latter, i.e., whether the projection really improves the prediction, is largely influenced by the constraint geometry curvature. Moreover, the initialization of the neural network plays a crucial role in constrained learning using ENFORCE. Overall, it is difficult to prove a priori whether constrained learning can be beneficial during the initial phase of training.\\
To overcome this limitation, we develop a strategy to ensure effective constrained learning. Instead of building a \textit{static} ENFORCE model, we activate AdaNP only when its application enhances prediction accuracy (i.e., the loss decreases). This strategy can be interpreted as an unconstrained pre-training; however, it is automatically incorporated in ENFORCE. We have demonstrated that this approach accelerates the training process and leads to better optima compared to fully unconstrained training.

\paragraph{Loss function}
We further control the constrained learning process by minimizing the projection displacement, i.e., the distance between the preliminary NN prediction $\hat{y}$ and its projection $\tilde{y} = \text{AdaNP}(\hat{y})$. This aims to (1) ensure minor linearization error ($\epsilon_L \sim \Delta y$) and (2) prevent the neural network from learning alternative functions whose projections fall within the neighborhood of the desired functions. The latter is suggested to reduce reliance on AdaNP for accurate predictions, thereby lowering the computational cost during inference (i.e., by decreasing the depth of AdaNP).\\
We control the projection displacement by applying \textit{soft} constraints, adding an extra penalty term to the loss function:

\begin{equation}
\label{eq:loss}
\mathcal{L} = \frac{1}{N} \sum_{i=1}^{N} ||y_i - \Tilde{y}_i||^2 + \frac{\lambda}{N} \sum_{i=1}^{N} ||\Hat{y}_i - \Tilde{y}_i||^2
\end{equation}

Here, the first term represents the conventional mean squared error between the projected prediction $\Tilde{\mathbf{y}}_i$ and the ground truth $\mathbf{y}_i$, while the second term quantifies the projection displacement, targeted at controlling and minimizing its magnitude, by acting as a penalty. The two terms are balanced by a scalar weight $\lambda$.


\section{Experiments and discussion}
% \subsection{Function fitting} (if we include also another case study on parametric optimization)
We demonstrate our proposed method on an illustrative two-dimensional example. We aim to fit the oscillating function $y:\mathbb{R} \rightarrow \mathbb{R}^2$:

\begin{equation}
\label{eq:toy-problem}
\begin{aligned}
    y_1 &= 2 \text{sin}(fx)\\
    y_2 &= - \text{sin}^2(fx) - x^2 \text{,}
\end{aligned}
\end{equation}

where $x \in \mathbb{R}$ is the unidimensional independent variable (input) and the scalar $f$ is the frequency.
Notably, the system is implicitly linked by a nonlinear constraint $c(x,y_1, y_2) = (0.5y_1)^2+x^2+y_2$, involving both input and output variables. We train an ENFORCE model consisting of a 64-neuron 1-hidden layer fully connected ReLU neural network as a backbone and an AdaNP module to force the predictions to satisfy the constraint. We experiment with different constraint tolerances ($\epsilon_T$) and loss weighting factors ($\lambda$) during training to heuristically study their influence. At inference, the depth of AdaNP is adapted to guarantee a specified tolerance $\epsilon$, e.g., absolute average or maximum residual across a batch of prediction. In this case study, we set the average absolute residual to be below $\epsilon_I=10^{-6}$ at inference time. To verify the interpolation capabilities, we sample 100 training data points from a uniform distribution in $x=[-2,2]$ and 1000 test points in the same domain. Every run is repeated 5 times using different initialization seeds.

\paragraph{Accuracy and constraint guarantee}
One of the major concerns in constrained learning is related to keeping the expressivity and approximation capabilities of NNs~\cite{Cybenko1989_Approximationsuperpositionssigmoidal, Hornik1989_Multilayerfeedforwardnetworks} while enforcing constraints to be satisfied. Here, we evaluate the regression capabilities and robustness to spectral biases~\cite{Rahaman2018_SpectralBiasNeural} of ENFORCE on oscillating functions ($f=5$) while assessing the average and maximum constraint deviation (i.e., residual). We compare the method with a traditional (unconstrained) multilayer perceptron (MLP) and a soft-constrained neural network sharing the same architecture. In the soft-constrained neural network, the constraint residual is added as an additional loss term balanced with a scalar weight ($\lambda_y$). We report here the outcomes of the best-performing soft-constrained network, with $\lambda_y = 1$. We train all the NNs for 50,000 epochs, using Adam~\cite{Kingma2014_AdamMethodStochastic} optimizer with a learning rate of $0.001$.\\
The main results are summarized in Table~\ref{tab:Accuracy-Constraints}. ENFORCE outperforms the soft-constrained NN and the MLP by effectively minimizing the nonlinear constraint residual, guaranteeing arbitrary satisfaction with minor computational costs (Fig.~\ref{fig:constraint}). To quantify the relative impact, we normalized the residuals by scaling them with respect to the absolute maximum value of the variables within the considered range ($\max(|x|,|y_1|,|y_2|)$). It is worth noting how overall good performance (e.g., in NN) does not guarantee compliance with underlying model constraints, with deviations above 17\%. By contrast, ENFORCE demonstrates a worst-case residual below 0.0001\% (Table~\ref{tab:Accuracy-Constraints}). The inference time for a batch of 1000 samples is 6 ms longer when using ENFORCE compared to an MLP. This amount should be regarded as additive, not multiplicative (e.g., 4x relative to the MLP). Indeed, the computational complexity is entirely attributed to the AdaNP module, meaning that the backbone architecture has no impact. Therefore, when applied to larger models (e.g., transformers), the relative computational impact becomes negligible. Indeed, the complexity is primarily influenced by the number of constraints and the batch size, with the latter being particularly significant when inference is performed on CPU hardware (see Section~\ref{subsec:adanp} and Appendix~\ref{app:implementation_details}).\\
Besides constraint guarantee, ENFORCE also enhances the accuracy of the MLP (the $R^2$ increases from 0.994 to 0.999). At first sight, this may appear to be only a marginal improvement. However, advancing deep learning methods to achieve near-perfect performance remains an open challenge in essential fields such as healthcare and self-driving cars, where even slight inaccuracies at the decimal level can lead to catastrophic consequences~\cite{Gupta2021_Deeplearningobject, Gerke2020_Ethicallegalchallenges}.\\
Interestingly, ENFORCE outperforms the MLP in data-scarce regions of the domain, which in this dataset correspond to the domain extremities (as shown in Fig.~\ref{fig:y2}). More generally, ENFORCE also performs better under data-scarcity conditions when the models are trained on uniformly sampled fractions of the dataset (Fig.~\ref{fig:data-scarcity}). This observation suggests that constrained learning may enhance data efficiency.

\begin{table}[H] 
    \centering
    \caption{Regression accuracy and constraint guarantee of ENFORCE when compared with a multilayer perceptron (MLP) and a soft-constrained NN (Soft). Results for $\lambda=0.5$, $\epsilon_T=10^{-4}$, and $\epsilon_I = 10^{-6}$ are reported. The inference on 1000 samples is run on a CPU (11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz, 4 Core(s)) to prove efficiency also in the absence of GPU hardware. The inference time is also reported for a batch of 1000 predictions.}
    \begin{tabular}{lccccc} % Left-align the first column, center-align the rest
        \hline
        & MAPE [\%] & $R^2$ & Avg Residual [\%] & Max Residual [\%] & Inference Time [s] \\ \hline
        MLP & 0.339 $\pm$ 0.083 & 0.994 $\pm$ 0.003 & 1.47 $\pm$ 0.33 & 17.13 $\pm$ 3.94 & 0.002 $\pm$ 0.000 \\
        Soft & 0.944 $\pm$ 0.143 & 0.972 $\pm$ 0.002 & 1.55 $\pm$ 0.16 & 7.77 $\pm$ 0.40 & 0.002 $\pm$ 0.000 \\
        ENFORCE & 0.060 $\pm$ 0.028 & \textbf{0.999 $\pm$ 0.000} & 0.00 $\pm$ 0.00 & \textbf{0.00 $\pm$ 0.00} & 0.008 $\pm$ 0.003 \\ \hline
    \end{tabular}
    \label{tab:Accuracy-Constraints}
\end{table}

\paragraph{Effects of constrained learning}
Notably, ENFORCE outperforms the MLP even before the projection steps, demonstrating superior performance using only the neural network backbone (Fig.~\ref{fig:loss-comparison}, dashed-pink line). This can be attributed to the structure of the hard-constrained learning process, where the predictions are adjusted via projection to satisfy underlying constraints. Unlike soft-constrained methods, which only penalize constraint violations in the loss function, hard-constrained optimization incorporates projection-based adjustments that transform predictions to adhere strictly to the constraints. Consequently, after a few training steps, the model benefits from constrained learning, aligning its predictions more closely with valid regions of the solution space, resulting in improved predictions even before projection. Similar insights are also provided by Chen et al. (2021)~\cite{Chen2021_Theoryguidedhard}.
Therefore, the constrained learning approach is likely to yield improved results even when AdaNP is omitted during inference to enhance computational efficiency. However, it should be noted that in this scenario, constraint satisfaction cannot be guaranteed.

\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/y1_vs_x_improved.pdf}
        \caption{$y_1$}
        \label{fig:y1}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/y2_vs_x_improved.pdf}
        \caption{$y_2$}
        \label{fig:y2}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/y1_y2_plane.pdf}
        \caption{Constraint Satisfaction}
        \label{fig:constraint}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/data_scarcity.pdf}
        \caption{Data Scarcity}
        \label{fig:data-scarcity}
    \end{subfigure}
    \caption{Prediction comparison between ENFORCE ($\lambda = 0.5$, $\epsilon_T = 10^{-4}$, $\epsilon_I = 10^{-6}$) and a multilayer perceptron (MLP). ENFORCE enhances the overall accuracy and guarantees satisfaction for highly nonlinear constraints. ENFORCE consistently performs better than a standard MLP even when trained on uniformly sampled fractions of the training dataset.}
    \label{fig:prediction}
\end{figure}


\paragraph{Training dynamics}
% Observing the loss curves (Fig.~\ref{fig:loss-comparison}), ENFORCE secures significantly improved convergence performance, achieving a solution with training loss an order of magnitude lower than its unconstrained counterpart (MLP). \\

To understand the training dynamics of ENFORCE, we analyze the loss curves shown in Fig.~\ref{fig:loss-comparison}, where the training data loss of ENFORCE is compared to the MLP. Being interested in the effect of hard-constrained learning and to ease the visualization, we do not report here the loss curve of the soft-constrained NN. In this case study, AdaNP contributes to the learning process from the very early iterations (Fig.~\ref{fig:losses-ENFORCE}, orange line), suggesting that the projection operations positively guide the optimization process. The combination of feasible predictions and minimization of projection displacement drives the learning process toward more optimal outcomes. \\
The modified loss function effectively guides the training process toward smaller projection displacements (Fig.~\ref{fig:losses-ENFORCE}, green dashed line). The displacement loss decreases consistently during training due to the influence of the penalty term in the loss function. Moreover, the depth of AdaNP progressively diminishes over training iterations down to $\sim$1 layer (Fig.\ref{fig:losses-ENFORCE}, orange line), due to (1) improved overall regression accuracy and (2) smaller projection displacement (i.e., a better linear approximation of the constraints). This adaptive behavior optimizes computational resources by adjusting to the required tolerance at each iteration. Furthermore, this decay in AdaNP depth is consistently observed across different training tolerance values, as illustrated in Fig.\ref{fig:NPs-training}.

\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/loss_comparison_downsampled.pdf}
        \caption{Loss NN vs. ENFORCE}
        \label{fig:loss-comparison}
    \end{subfigure}
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/loss_and_projection_iterations_downsampled.pdf}
        \caption{ENFORCE Losses and AdaNP}
        \label{fig:losses-ENFORCE}
    \end{subfigure}
    \caption{ENFORCE demonstrates significantly improved convergence, achieving lower loss compared to an unconstrained MLP. Enhanced training performances are reported for the backbone network of ENFORCE even before the action of AdaNP. This effect is enabled by the simultaneous minimization of the projection displacement (in green) and the action of the AdaNP module (in yellow). Note that we report average values across multiple runs, which explains why the depth of AdaNP appears as a step function with non-integer values.}
    \label{fig:loss}
\end{figure}

\paragraph{Constrained learning hyperparameters (training)}
We systematically analyze the influence of hyperparameters, such as the weighting factor $\lambda$ and the tolerance $\epsilon_T$, on the constrained learning process. 
Fig.~\ref{fig:lambda-epsilon} shows the influence of the hyperparameters on the accuracy of trained ENFORCE models evaluated on the test set. \\
The impact of the training tolerance $\epsilon_T$ on the model accuracy does not exhibit a clear trend, as its effect varies unpredictably with the weighting factors. Moreover, its influence is generally small compared to the variance of different training runs (Fig.~\ref{fig:lambda-epsilon}). Intuitively, a smaller tolerance $\epsilon_T$ necessitates deeper AdaNP modules, resulting in higher computational costs due to the increased number of neural projection layers. This effect is visible in Fig.~\ref{fig:NPs-training}, where the depth of AdaNP during training is reported (i.e., number of projection layers). The average depth of AdaNP increases to accommodate stricter tolerances. For example, it expands from one to three layers as the tolerance $\epsilon_T$ is tightened from 1 to $10^{-5}$. Notably, in this case study, AdaNP operates with a minimum of one projection layer (i.e., when the tolerance is set to 1) and a maximum of 100. More importantly, the required depth tends to have a slower decay during training, if compared to using less strict tolerances (as visible in Fig.~\ref{fig:NPs-training}). Larger tolerances result, on average, in shallow AdaNP layers (approximately one layer). This significantly reduces the training time associated with the projection operations. Along with the minor impact on overall accuracy, this observation suggests setting the training tolerance $\epsilon_T$ to less stringent requirements.\\
% Talk about influence of lambda more in detail
The regression accuracy is evidently affected by the choice of the loss weighting factor $\lambda$ (Fig.~\ref{fig:lambda-epsilon}). Remarkably, unlike the challenging task of tuning weighting factors in soft-constrained methods~\cite{Wang2020_Understandingmitigatinggradient}, the constrained learning approach proposed here positively impacts accuracy regardless of the specific weighting factor chosen (as shown in Fig.~\ref{fig:lambda-epsilon}, the accuracy of ENFORCE is consistently greater than that of a standard MLP). However, an inappropriate choice of this parameter can result in suboptimal outcomes (e.g., when $\lambda=2$ in Fig.~\ref{fig:lambda-epsilon}). Therefore, careful tuning of this hyperparameter is warranted.\\

\paragraph{Constrained learning hyperparameters (inference)}
% Talk about influence of lambda and epsilon again on the AdaNP at inference
During inference, ENFORCE dynamically adapts the depth of AdaNP to ensure an average tolerance below $\epsilon_I=10^{-6}$ in this case study. The required depth, however, also depends on the training parameters. Fig.~\ref{fig:NPs-inference} illustrates the number of NP layers needed to satisfy the constraint under varying $\lambda$ and $\epsilon_T$. The weighting factor is shown to reduce the required number of NP layers by half, with no additional cost during training. This phenomenon can be attributed to the fact that, in the absence of a penalty for projection displacement, the neural network is free to learn a function that, although potentially far from the actual one, results in projections that fall within the vicinity of the ground truth. This approach, however, necessitates multiple projections. In contrast, the penalty term drives the model to learn a function that is sufficiently close to the ground truth, thereby reducing the number of neural projections required. Increasing the value of $\epsilon_T$ impacts (positively) the depth of AdaNP at inference time when the displacement penalty factor is set to be small during training. This finding further supports the recommendation of employing shallow AdaNP modules during training, by relaxing the value of $\epsilon_T$.\\
We conclude that the weighting factor $\lambda$ plays an important role by balancing the contribution of the projection displacement error. On the other hand, enforcing strict satisfaction during training at arbitrary small tolerance $\epsilon_T$ does not necessarily improve the overall outcome.

\begin{figure}[t]
    \centering
    \includegraphics[height=6cm]{figures/lambda_epsilon.pdf}
    \caption{Influence of constrained learning hyperparameters on the accuracy of ENFORCE on the test set (note that here we plot the inverse of the mean squared error (MSE)). The weighting factor $\lambda$ favors the learning process if appropriately tuned. Conversely, the training tolerance $\epsilon_T$ exhibits a small impact on performance, suggesting it can be set based on available resources. Overall, despite the choice of hyperparameters, ENFORCE is more accurate than an MLP with the same complexity, while also satisfying the underlying nonlinear constraint.}
    \label{fig:lambda-epsilon}
\end{figure}

\begin{figure}[t]
    \centering
    \begin{subfigure}[t]{0.45\textwidth} % Adjusted width for the last figure
        \centering
        \includegraphics[height=6cm]{figures/proj_training_downsampled.pdf}
        \caption{Depth of AdaNP (number of neural projection layers) during training.}
        \label{fig:NPs-training}
    \end{subfigure}%
    \hspace{0.08\textwidth} % Add some space between the subfigures
    \begin{subfigure}[t]{0.45\textwidth} % Adjusted width for the second-to-last figure
        \centering
        \includegraphics[height=6cm]{figures/NPs_inference_with_colors.pdf}
        \caption{Depth of AdaNP (number of neural projection layers) during inference.}
        \label{fig:NPs-inference}
    \end{subfigure}
    \caption{Dynamic evolution of AdaNP during training and inference when different training hyperparameters are chosen. At training time, AdaNP is deeper as a smaller constraints tolerance $\epsilon_T$ is chosen.  }
    \label{fig:NPs}
\end{figure}



\section{Conclusions and outlook}
We developed ENFORCE, a method designed to guarantee neural network prediction satisfies any nonlinear constraint $c(x,y)=0$ within a specified tolerance $\epsilon$, without relying on external solvers or incurring prohibitive computational overhead. The effectiveness of the method is demonstrated in an illustrative case study chosen for its interpretability and ease of visualization. We found that (1) ENFORCE ensures the satisfaction of nonlinear constraints to within a tolerance $\epsilon$ for both average and maximum residuals, (2) the overall accuracy improves from traditional unconstrained MLP, achieving near-perfect performance on the test set, and (3) the constrained learning hyperparameters influence the learning process toward optimal performance; however, our method shows superior performance compared the unconstrained counterpart for a wide range of hyperparamer settings.
Additionally, we observed promising performance in data-scarcity conditions (Fig.~\ref{fig:data-scarcity}).

This work opens several research avenues toward developing robust NNs that strictly adhere to underlying system knowledge. First, the current method can be extended to handle piecewise-defined constraints and nonlinear inequality constraints. Additionally, the requirement for the constraint to be a $\mathcal{C}^1$ function could be relaxed by leveraging sub-gradients~\cite{boyd2003subgradient}. Finally, alternative (e.g., weighted) projection approaches could be explored to better account for the morphology and scaling of the constraints. \\
The method has the potential to address specific challenges or complement existing approaches, including those based on neural networks and other machine learning models for regression tasks (e.g., Gaussian processes and support vector machines). For instance, hard constraints can be combined with soft-constraint techniques, such as PINNs, to reliably solve PDEs~\cite{Lu2021_PhysicsInformedNeural}. Additionally, the method could enhance learning performance in partially annotated datasets by inferring missing information through available constraints. Finally, an interesting future direction could involve applying the AdaNP module to GenAI models, guiding the generation process toward domain-compliant samples, such as for synthetic data or image/video generation.

\paragraph{Limitations}
In this paragraph. we highlight the main limitation of the proposed method. Firstly, the effectiveness of ENFORCE is highly dependent on the regression capabilities of the neural network backbone. When the model lacks sufficient complexity to achieve accurate predictions, ENFORCE provides limited benefit. Furthermore, the method becomes computationally intensive when applied to systems with a large number of constraints (e.g., more than 1000). This is due to the computational cost of each neural projection layer, which scales as $O(N^3)$ because of the matrix inversion operation, where $N$ is the number of constraints. Further details are provided in Appendix~\ref{app:implementation_details}.

% \paragraph{Outlook}
% 
\section*{Acknowledgements}
This research is supported by Shell Global Solutions International B.V., for which we express sincere gratitude.

%Bibliography
\nolinenumbers
\bibliographystyle{unsrt}  
\bibliography{ENFORCE}  

\linenumbers
\appendix

\section{Appendix}
\subsection{Mathematical derivations}
\label{app:mathematical_derivations}

This section provides the key mathematical derivations underlying the proposed method. These derivations are intended to illustrate the theoretical foundations of the approach and to support some of the discussions presented in the main text.

\paragraph{Closed-form neural projection}
We derive here the closed-form expression defining a neural projection layer in Def.~\ref{def:NPlayer} (Section~\ref{subsec:adanp}). Given the linearized projection problem in Eq.~\ref{eq:linearized_projection}, we can define the Lagrangian function as:

\begin{equation}
\label{eq:linearized_lagrangian}
\mathcal{L}(x, y, \lambda) = \frac{1}{2} (y - \hat{y})^T (y - \hat{y}) + \lambda^T\left( c(x,\hat{y}) + \left.J_yc\right|_{x, \hat{y}} (y - \hat{y})\right)
\end{equation}

Then, a local optimum can be found by solving the KKT conditions (i.e., primal and dual feasibility):

\begin{equation}
\label{eq:linearized_feasibility}
\begin{aligned}
&\nabla_y\mathcal{L} = (y - \hat{y}) + \left.J^T_yc\right|_{x, \hat{y}} \lambda = 0 \\
&c(x,\hat{y}) + \left.J_yc\right|_{x, \hat{y}} (y - \hat{y}) = 0 
\end{aligned}
\end{equation}

To simplify the notation, we define the linear system as:

\begin{equation}
\label{eq:simplified_system}
\begin{aligned}
&(y - \hat{y}) + B^T \lambda = 0 \\
&By-v = 0 
\end{aligned}
\end{equation}

where:
\begin{equation}
\label{eq:definitionBv}
\begin{aligned}
B &= \left.J_yc\right|_{x, \hat{y}} \in \mathbb{R}^{N_C \times N_O}\\
v &= \left.J_yc\right|_{x, \hat{y}} \hat{y} - c(x, \hat{y}) \in \mathbb{R}^{N_C}
\end{aligned}
\end{equation}

Solving the system, we obtain a closed form for the neural projection layer:

\begin{equation}
\label{eq:closed_form}
\tilde{y}=(I - B^T(BB^T)^{-1}B) \hat{y}+ B^T(BB^T)^{-1}v
\end{equation}

\paragraph{Deviation from Newton's method}
To support the discussion raised in Section~\ref{subsec:adanp}, we show how our method deviates from standard Newton's method for solving nonlinear KKT conditions. Given a NLP:

\begin{equation}
\label{eq:nlp}
\begin{aligned}
\Tilde{y} = &\argmin_{y} \frac{1}{2} ||y - \hat{y}||^2 \\
\text{s.t.} & \quad  c(x, y) = 0
\end{aligned}
\end{equation}

With associated Lagrangian function:

\begin{equation}
\label{eq:nlp_lagrangian}
\mathcal{L}(x, y, \lambda) = \frac{1}{2} (y - \hat{y})^T (y - \hat{y}) + \lambda^T c(x,y)
\end{equation}

The primal and dual feasibility can be derived as:

\begin{equation}
\label{eq:nlp_feasibility}
\begin{aligned}
&\nabla_y\mathcal{L} = (y - \hat{y}) + J^T_y c(x,y) \lambda = 0 \\
&c(x,y) = 0 
\end{aligned}
\end{equation}

If we linearized the system according to the Newton's iteration, we obtain:

\begin{equation}
\begin{aligned}
&(y_0 - \hat{y}) + J^T_y c|_{y_0, \lambda_0} \lambda_0 + (y-y_0) + \lambda^T \left. \mathbf{H}_y c \right|_{y_0, \lambda_0} (y-y_0) + \left.J^T_y c\right|_{y_0, \lambda_0} (\lambda-\lambda_0) = 0 \\
&c(x, y_0) + J_y c|_{y_0, \lambda_0} (y-y_0) = 0 
\end{aligned}
\end{equation}

Thus, assuming to center the linearization in the neural network prediction, i.e., $y_0 = \hat{y}$, and choosing $\lambda_0 = 0$:

\begin{equation}
\begin{aligned}
& (y-\hat{y}) + \lambda^T \left. \mathbf{H}_y c \right|_{\hat{y}, 0} (y-\hat{y}) + \left. J^T_y c \right|_{\hat{y}, 0} \lambda = 0 \\
&c(x, \hat{y}) + \left. J_y c\right|_{\hat{y}, 0} (y-\hat{y}) = 0 
\end{aligned}
\end{equation}

We can conclude that, essentially, our NP layer solves a similar linear system (Eq.~\ref{eq:linearized_feasibility}) which does not comprise the term $\lambda^T \left. \mathbf{H}_y c \right|_{\hat{y}, 0} (y-\hat{y})$, hence avoiding the computation of the Hessian tensor $\mathbf{H}_yc$. 


\subsection{Implementation details}
\label{app:implementation_details}
\paragraph{Batch local projection}
The computationally most expensive operation in the neural projection layer is the matrix inversion $(B B^T)^{-1}$ (Def.~\ref{def:NPlayer} in Section~\ref{subsec:adanp}), which has a complexity of $\mathcal{O}(N^3)$. At inference time, $N=N_C$, since $B \in \mathbb{R}^{N_C \times N_O}$ and $B B^T \in \mathbb{R}^{N_C \times N_C}$. Hence, considering a number of constraint $N_C<10^3$, the matrix inversion is performed in $\sim 1$ million FLOPs, which is a negligible amount for most modern CPUs and GPUs. % Single-Core i7 CPU does 32 GFLOPS per second, while a 8-core i7 does even 256 GFLOPS per second. Thus, a few millions is just a tiny fraction of seconds.
During training, assuming the use of batch gradient descent and defining the batch size ($BS$) as the number of data points processed in a single iteration, an equivalent number of matrix inversions must be performed. Thus, the computational cost for a single batch is apparently $\mathcal{O}(BS \times N_C^3)$. To address this, we leverage parallel computing on GPUs by constructing a \textit{rank-3} tensor $\mathbf{B} \in \mathbb{R}^{BS \times N_C \times N_O}$ to hold $BS$ local matrices $B$. Similarly, a \textit{rank-2} tensor $V \in \mathbb{R}^{BS \times N_C}$ is built to store $BS$ local vectors $\mathbf{v}$. Modern deep learning libraries enable batch operations, such as matrix inversion, which reduce the effective complexity to $\mathcal{O}(N_C^3)$ (i.e., scaling only with the number of constraints).\\
Given these conditions and the capabilities of current hardware, the neural projection operation remains computationally efficient even during training when the number of constraints is fewer than a few thousand. This facilitates new computational approaches for handling and enforcing nonlinear constraints in neural networks.


\end{document}
