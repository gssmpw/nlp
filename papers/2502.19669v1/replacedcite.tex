\section{Related work}
\subsection{Analysis of LLMs against Typos}
Typos are mistakes in writing or typing letters, categorized into insertion, deletion, substitution, and reordering____.
Research on the robustness of LLMs regards typos as a perturbation.
Typos change the token sequence obtained through the tokenization process. 
Changing the token sequence potentially leads to a different output, even if the sentence is the same____.
Most existing LLM studies about typos focus on measuring the robustness against perturbed inputs____ or modifying the architecture or prompts to improve robustness____. 
\newcite{SubwordRobustness} reported that the larger models are more robust to typos. Before the LLM era, researchers corrected typos using specific models for typo-correction____.

\subsection{LLM's Interpretability}
The feed-forward network (FFN) layer in the Transformer____ has two linear layers separated by an activation function.
Recent studies regard the output of the activation function as ``neurons'' that store knowledge____.
It has been reported that some neurons promote specific tasks____, knowledge____, and behaviors____.

Some attention heads also respond to specific knowledge____ or behaviors____. 
Additionally, some heads are responsible for merging multiple subwords of a word____.

There are various methods to investigate LLM's interpretability. Some measure contributions to the residual stream____, while others observe intermediate predictions____, graph the inference process____, or directly observe activations____.
We hypothesize that typo neurons are a type of skill neurons. Therefore we use the direct activation observation method, following previous studies on skill neurons____.
\newcite{ImpactOfIA} concludes that understanding the inner workings is important to improve the model performance.

\newcite{StagesOfInference} divides LLMs into four stages. The early layers convert token-level representations into entity-level representations with local contexts as \textit{Detokenization}. The early middle layers build representations with global contexts as \textit{Feature Engineering}. The late middle layers, convert current representations into next token representations as \textit{Prediction Ensembling}. Finally, the late layers remove the noise and refine the distribution of the next token as \textit{Residual Sharpening}.
\newcite{SoftmaxLinearUnits} reports that the late layers perform the opposite function of the early layers' \textit{Detokenization}, converting entity-level representations into token-level representations as \textit{Retokenization}.

\newcite{FromTokensToWords} reveals which layers are responsible for typo-fixing.
However, they only focused on isolated words as inputs by layer-level observation. 
We focus on neurons and heads and experiment with global contexts.