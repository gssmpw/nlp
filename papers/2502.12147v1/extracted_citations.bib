@article{amin2025towards,
  title={Towards Fast, Specialized Machine Learning Force Fields: Distilling Foundation Models via Energy Hessians},
  author={Amin, Ishan and Raja, Sanjeev and Krishnapriyan, Aditi},
  journal={arXiv preprint arXiv:2501.09009},
  year={2025}
}

@article{artrith2017efficient,
  title={Efficient and accurate machine-learning interpolation of atomic energies in compositions with many species},
  author={Artrith, Nongnuch and Urban, Alexander and Ceder, Gerbrand},
  journal={Physical Review B},
  volume={96},
  number={1},
  pages={014112},
  year={2017},
  publisher={APS}
}

@inproceedings{batatia2022mace,
  title={{MACE}: Higher Order Equivariant Message Passing Neural Networks for Fast and Accurate Force Fields},
  author={Ilyes Batatia and David Peter Kovacs and Gregor N. C. Simm and Christoph Ortner and Gabor Csanyi},
  booktitle={Advances in Neural Information Processing Systems},
  editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
  year={2022},
  url={https://openreview.net/forum?id=YPpSngE-ZU}
}

@article{batatia2025design,
  title={The design space of E (3)-equivariant atom-centred interatomic potentials},
  author={Batatia, Ilyes and Batzner, Simon and Kov{\'a}cs, D{\'a}vid P{\'e}ter and Musaelian, Albert and Simm, Gregor NC and Drautz, Ralf and Ortner, Christoph and Kozinsky, Boris and Cs{\'a}nyi, G{\'a}bor},
  journal={Nature Machine Intelligence},
  pages={1--12},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{batzner20223,
  title={E (3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials},
  author={Batzner, Simon and Musaelian, Albert and Sun, Lixin and Geiger, Mario and Mailoa, Jonathan P and Kornbluth, Mordechai and Molinari, Nicola and Smidt, Tess E and Kozinsky, Boris},
  journal={Nature communications},
  volume={13},
  number={1},
  pages={1--11},
  year={2022},
  publisher={Nature Publishing Group}
}

@article{behler2007generalized,
  title={Generalized neural-network representation of high-dimensional potential-energy surfaces},
  author={Behler, J{\"o}rg and Parrinello, Michele},
  journal={Physical review letters},
  volume={98},
  number={14},
  pages={146401},
  year={2007},
  publisher={APS}
}

@article{bigi2024dark,
  title={The dark side of the forces: assessing non-conservative force models for atomistic machine learning},
  author={Bigi, Filippo and Langer, Marcel and Ceriotti, Michele},
  journal={arXiv preprint arXiv:2412.11569},
  year={2024}
}

@article{bochkarev2024graph,
  title = {Graph Atomic Cluster Expansion for Semilocal Interactions beyond Equivariant Message Passing},
  author = {Bochkarev, Anton and Lysogorskiy, Yury and Drautz, Ralf},
  journal = {Phys. Rev. X},
  volume = {14},
  issue = {2},
  pages = {021036},
  numpages = {28},
  year = {2024},
  month = {Jun},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevX.14.021036},
  url = {https://link.aps.org/doi/10.1103/PhysRevX.14.021036}
}

@article{brehmer2024does,
  title={Does equivariance matter at scale?},
  author={Brehmer, Johann and Behrends, S{\"o}nke and de Haan, Pim and Cohen, Taco},
  journal={arXiv preprint arXiv:2410.23179},
  year={2024}
}

@article{chen2022universal,
  title={A universal graph deep learning interatomic potential for the periodic table},
  author={Chen, Chi and Ong, Shyue Ping},
  journal={Nature Computational Science},
  volume={2},
  number={11},
  pages={718--728},
  year={2022},
  publisher={Nature Publishing Group US New York}
}

@article{cheng2024cartesian,
  title={Cartesian atomic cluster expansion for machine learning interatomic potentials},
  author={Cheng, Bingqing},
  journal={npj Computational Materials},
  volume={10},
  number={1},
  pages={157},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{chmiela2017machine,
  title={Machine learning of accurate energy-conserving molecular force fields},
  author={Chmiela, Stefan and Tkatchenko, Alexandre and Sauceda, Huziel E and Poltavsky, Igor and Sch{\"u}tt, Kristof T and M{\"u}ller, Klaus-Robert},
  journal={Science advances},
  volume={3},
  number={5},
  pages={e1603015},
  year={2017},
  publisher={American Association for the Advancement of Science}
}

@article{deng2023chgnet,
  title={CHGNet as a pretrained universal neural network potential for charge-informed atomistic modelling},
  author={Deng, Bowen and Zhong, Peichen and Jun, KyuJung and Riebesell, Janosh and Han, Kevin and Bartel, Christopher J and Ceder, Gerbrand},
  journal={Nature Machine Intelligence},
  volume={5},
  number={9},
  pages={1031--1041},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{eastman2024nutmeg,
  title={Nutmeg and SPICE: models and data for biomolecular machine learning},
  author={Eastman, Peter and Pritchard, Benjamin P and Chodera, John D and Markland, Thomas E},
  journal={Journal of chemical theory and computation},
  volume={20},
  number={19},
  pages={8583--8593},
  year={2024},
  publisher={ACS Publications}
}

@article{fang2024phonon,
  title={Phonon predictions with E (3)-equivariant graph neural networks},
  author={Fang, Shiang and Geiger, Mario and Checkelsky, Joseph G and Smidt, Tess},
  journal={arXiv preprint arXiv:2403.11347},
  year={2024}
}

@article{fu2023forces,
title={Forces are not Enough: Benchmark and Critical Evaluation for Machine Learning Force Fields with Molecular Simulations},
author={Xiang Fu and Zhenghao Wu and Wujie Wang and Tian Xie and Sinan Keten and Rafael Gomez-Bombarelli and Tommi S. Jaakkola},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=A8pqQipwkt},
note={Survey Certification}
}

@article{gasteiger2021gemnet,
  title={Gemnet: Universal directional graph neural networks for molecules},
  author={Gasteiger, Johannes and Becker, Florian and G{\"u}nnemann, Stephan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={6790--6802},
  year={2021}
}

@inproceedings{gilmer2017neural,
  title={Neural message passing for quantum chemistry},
  author={Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
  booktitle={International conference on machine learning},
  pages={1263--1272},
  year={2017},
  organization={PMLR}
}

@article{greener2024differentiable,
  title={Differentiable simulation to develop molecular dynamics force fields for disordered proteins},
  author={Greener, Joe G},
  journal={Chemical Science},
  volume={15},
  number={13},
  pages={4897--4909},
  year={2024},
  publisher={Royal Society of Chemistry}
}

@article{hu2021forcenet,
  title={Forcenet: A graph neural network for large-scale quantum calculations},
  author={Hu, Weihua and Shuaibi, Muhammed and Das, Abhishek and Goyal, Siddharth and Sriram, Anuroop and Leskovec, Jure and Parikh, Devi and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:2103.01436},
  year={2021}
}

@article{kovacs2021linear,
  title={Linear atomic cluster expansion force fields for organic molecules: beyond rmse},
  author={Kov{\'a}cs, D{\'a}vid P{\'e}ter and Oord, Cas van der and Kucera, Jiri and Allen, Alice EA and Cole, Daniel J and Ortner, Christoph and Cs{\'a}nyi, G{\'a}bor},
  journal={Journal of chemical theory and computation},
  volume={17},
  number={12},
  pages={7696--7711},
  year={2021},
  publisher={ACS Publications}
}

@article{kovacs2023mace,
  title={MACE-OFF23: Transferable machine learning force fields for organic molecules},
  author={Kov{\'a}cs, D{\'a}vid P{\'e}ter and Moore, J Harry and Browning, Nicholas J and Batatia, Ilyes and Horton, Joshua T and Kapil, Venkat and Witt, William C and Magd{\u{a}}u, Ioan-Bogdan and Cole, Daniel J and Cs{\'a}nyi, G{\'a}bor},
  journal={arXiv preprint arXiv:2312.15211},
  year={2023}
}

@article{lan2023adsorbml,
  title={AdsorbML: a leap in efficiency for adsorption energy calculations using generalizable machine learning potentials},
  author={Lan, Janice and Palizhati, Aini and Shuaibi, Muhammed and Wood, Brandon M and Wander, Brook and Das, Abhishek and Uyttendaele, Matt and Zitnick, C Lawrence and Ulissi, Zachary W},
  journal={npj Computational Materials},
  volume={9},
  number={1},
  pages={172},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{langer2024probing,
  title={Probing the effects of broken symmetries in machine learning},
  author={Langer, Marcel F and Pozdnyakov, Sergey N and Ceriotti, Michele},
  journal={Machine Learning: Science and Technology},
  volume={5},
  number={4},
  pages={04LT01},
  year={2024},
  publisher={IOP Publishing}
}

@article{liao2023equiformerv2,
  title={Equiformerv2: Improved equivariant transformer for scaling to higher-degree representations},
  author={Liao, Yi-Lun and Wood, Brandon and Das, Abhishek and Smidt, Tess},
  journal={arXiv preprint arXiv:2306.12059},
  year={2023}
}

@inproceedings{liu2021spherical,
  title={Spherical message passing for 3d molecular graphs},
  author={Liu, Yi and Wang, Limei and Liu, Meng and Lin, Yuchao and Zhang, Xuan and Oztekin, Bora and Ji, Shuiwang},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{loew2024universal,
  title={Universal Machine Learning Interatomic Potentials are Ready for Phonons},
  author={Loew, Antoine and Sun, Dewen and Wang, Hai-Chen and Botti, Silvana and Marques, Miguel AL},
  journal={arXiv preprint arXiv:2412.16551},
  year={2024}
}

@article{moore2024computing,
  title={Computing hydration free energies of small molecules with first principles accuracy},
  author={Moore, J Harry and Cole, Daniel J and Csanyi, Gabor},
  journal={arXiv preprint arXiv:2405.18171},
  year={2024}
}

@article{musaelian2022learning,
  title={Learning Local Equivariant Representations for Large-Scale Atomistic Dynamics},
  author={Musaelian, Albert and Batzner, Simon and Johansson, Anders and Sun, Lixin and Owen, Cameron J and Kornbluth, Mordechai and Kozinsky, Boris},
  journal={arXiv preprint arXiv:2204.05249},
  year={2022}
}

@article{neumann2024orb,
  title={Orb: A fast, scalable neural network potential},
  author={Neumann, Mark and Gin, James and Rhodes, Benjamin and Bennett, Steven and Li, Zhiyi and Choubisa, Hitarth and Hussey, Arthur and Godwin, Jonathan},
  journal={arXiv preprint arXiv:2410.22570},
  year={2024}
}

@article{oc20,
author = {Chanussot, Lowik and Das, Abhishek and Goyal, Siddharth and Lavril, Thibaut and Shuaibi, Muhammed and Riviere, Morgane and Tran, Kevin and Heras-Domingo, Javier and Ho, Caleb and Hu, Weihua and Palizhati, Aini and Sriram, Anuroop and Wood, Brandon and Yoon, Junwoong and Parikh, Devi and Zitnick, C. Lawrence and Ulissi, Zachary},
title = {Open Catalyst 2020 (OC20) Dataset and Community Challenges},
journal = {ACS Catalysis},
volume = {11},
number = {10},
pages = {6059-6072},
year = {2021},
doi = {10.1021/acscatal.0c04525},
URL = { 
        https://doi.org/10.1021/acscatal.0c04525
},
eprint = { 
        https://doi.org/10.1021/acscatal.0c04525
}
}

@article{park2024scalable,
	title = {Scalable Parallel Algorithm for Graph Neural Network Interatomic Potentials in Molecular Dynamics Simulations},
	volume = {20},
	doi = {10.1021/acs.jctc.4c00190},
	number = {11},
	journal = {J. Chem. Theory Comput.},
	author = {Park, Yutack and Kim, Jaesun and Hwang, Seungwoo and Han, Seungwu},
	year = {2024},
	pages = {4857--4868},
}

@inproceedings{passaro2023reducing,
  title={Reducing SO (3) convolutions to SO (2) for efficient equivariant GNNs},
  author={Passaro, Saro and Zitnick, C Lawrence},
  booktitle={International Conference on Machine Learning},
  pages={27420--27438},
  year={2023},
  organization={Proceedings of Machine Learning Research}
}

@article{pota2024thermal,
  title={Thermal conductivity predictions with foundation atomistic models},
  author={P{\'o}ta, Bal{\'a}zs and Ahlawat, Paramvir and Cs{\'a}nyi, G{\'a}bor and Simoncelli, Michele},
  journal={arXiv preprint arXiv:2408.00755},
  year={2024}
}

@article{raja2024stability,
  title={Stability-Aware Training of Neural Network Interatomic Potentials with Differentiable Boltzmann Estimators},
  author={Raja, Sanjeev and Amin, Ishan and Pedregosa, Fabian and Krishnapriyan, Aditi S},
  journal={arXiv preprint arXiv:2402.13984},
  year={2024}
}

@article{riebesell2023matbench,
  title={Matbench Discovery--An evaluation framework for machine learning crystal stability prediction},
  author={Riebesell, Janosh and Goodall, Rhys EA and Jain, Anubhav and Benner, Philipp and Persson, Kristin A and Lee, Alpha A},
  journal={arXiv preprint arXiv:2308.14920},
  year={2023}
}

@article{rocken2024predicting,
  title={Predicting solvation free energies with an implicit solvent machine learning potential},
  author={R{\"o}cken, Sebastien and Burnet, Anton F and Zavadlav, Julija},
  journal={arXiv preprint arXiv:2406.00183},
  year={2024}
}

@article{sabanes2024enhancing,
  title={Enhancing Protein--Ligand Binding Affinity Predictions Using Neural Network Potentials},
  author={Sabanes Zariquiey, Francesc and Galvelis, Raimondas and Gallicchio, Emilio and Chodera, John D and Markland, Thomas E and De Fabritiis, Gianni},
  journal={Journal of Chemical Information and Modeling},
  volume={64},
  number={5},
  pages={1481--1485},
  year={2024},
  publisher={ACS Publications}
}

@article{schutt2017schnet,
  title={Schnet: A continuous-filter convolutional neural network for modeling quantum interactions},
  author={Sch{\"u}tt, Kristof and Kindermans, Pieter-Jan and Sauceda Felix, Huziel Enoc and Chmiela, Stefan and Tkatchenko, Alexandre and M{\"u}ller, Klaus-Robert},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{schutt2021equivariant,
  title={Equivariant message passing for the prediction of tensorial properties and molecular spectra},
  author={Sch{\"u}tt, Kristof and Unke, Oliver and Gastegger, Michael},
  booktitle={International Conference on Machine Learning},
  pages={9377--9388},
  year={2021},
  organization={PMLR}
}

@article{smith2017ani,
  title={ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost},
  author={Smith, Justin S and Isayev, Olexandr and Roitberg, Adrian E},
  journal={Chemical science},
  volume={8},
  number={4},
  pages={3192--3203},
  year={2017},
  publisher={Royal Society of Chemistry}
}

@article{smith2020ani,
  title={The ANI-1ccx and ANI-1x data sets, coupled-cluster and density functional theory properties for molecules},
  author={Smith, Justin S and Zubatyuk, Roman and Nebgen, Benjamin and Lubbers, Nicholas and Barros, Kipton and Roitberg, Adrian E and Isayev, Olexandr and Tretiak, Sergei},
  journal={Scientific data},
  volume={7},
  number={1},
  pages={134},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{tholke2021equivariant,
  title={Equivariant transformers for neural network based molecular potentials},
  author={Th{\"o}lke, Philipp and De Fabritiis, Gianni},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{thomas2018tensor,
  title={Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds},
  author={Thomas, Nathaniel and Smidt, Tess and Kearnes, Steven and Yang, Lusann and Li, Li and Kohlhoff, Kai and Riley, Patrick},
  journal={arXiv preprint arXiv:1802.08219},
  year={2018}
}

@article{unke2018reactive,
  title={A reactive, scalable, and transferable model for molecular energies from a neural network approach based on local information},
  author={Unke, Oliver T and Meuwly, Markus},
  journal={The Journal of chemical physics},
  volume={148},
  number={24},
  pages={241708},
  year={2018},
  publisher={AIP Publishing LLC}
}

@article{unke2021spookynet,
  title={SpookyNet: Learning force fields with electronic degrees of freedom and nonlocal effects},
  author={Unke, Oliver T and Chmiela, Stefan and Gastegger, Michael and Sch{\"u}tt, Kristof T and Sauceda, Huziel E and M{\"u}ller, Klaus-Robert},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={1--14},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{wander2024cattsunami,
  title={CatTSunami: Accelerating Transition State Energy Calculations with Pre-trained Graph Neural Networks},
  author={Wander, Brook and Shuaibi, Muhammed and Kitchin, John R and Ulissi, Zachary W and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:2405.02078},
  year={2024}
}

@article{wang2020differentiable,
  title={Differentiable molecular simulations for control and learning},
  author={Wang, Wujie and Axelrod, Simon and G{\'o}mez-Bombarelli, Rafael},
  journal={arXiv preprint arXiv:2003.00868},
  year={2020}
}

@article{williams2025hessian,
  title={Hessian QM9: A quantum chemistry database of molecular Hessians in implicit solvents},
  author={Williams, Nicholas J and Kabalan, Lara and Stojanovic, Ljiljana and Z{\'o}lyomi, Viktor and Pyzer-Knapp, Edward O},
  journal={Scientific Data},
  volume={12},
  number={1},
  pages={9},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{wines2024chips,
  title={CHIPS-FF: Evaluating Universal Machine Learning Force Fields for Material Properties},
  author={Wines, Daniel and Choudhary, Kamal},
  journal={arXiv preprint arXiv:2412.10516},
  year={2024}
}

@article{yang2024mattersim,
  title={Mattersim: A deep learning atomistic model across elements, temperatures and pressures},
  author={Yang, Han and Hu, Chenxi and Zhou, Yichi and Liu, Xixian and Shi, Yu and Li, Jielan and Li, Guanzhi and Chen, Zekun and Chen, Shuizhou and Zeni, Claudio and others},
  journal={arXiv preprint arXiv:2405.04967},
  year={2024}
}

@article{zhang2018end,
  title={End-to-end symmetry preserving inter-atomic potential energy model for finite and extended systems},
  author={Zhang, Linfeng and Han, Jiequn and Wang, Han and Saidi, Wissam and Car, Roberto and others},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{zubatyuk2019accurate,
  title={Accurate and transferable multitask prediction of chemical properties with an atoms-in-molecules neural network},
  author={Zubatyuk, Roman and Smith, Justin S and Leszczynski, Jerzy and Isayev, Olexandr},
  journal={Science advances},
  volume={5},
  number={8},
  pages={eaav6490},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

