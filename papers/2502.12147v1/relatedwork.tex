\section{Related works}
\textbf{MLIP architectures} have made significant progress since their initial proposal~\citep{behler2007generalized}. These architectures are usually symmetry-preserving~\citep{smith2017ani, schutt2017schnet, gilmer2017neural, chmiela2017machine, artrith2017efficient, unke2018reactive, zhang2018end, zubatyuk2019accurate, smith2020ani, kovacs2021linear}, with increasingly expressive atom environment embeddings and message-passing operations~\citep{klicpera2020Directional, gasteiger2021gemnet, schutt2021equivariant, liu2021spherical, unke2021spookynet, chen2022universal, deng2023chgnet, cheng2024cartesian}. Notably, equivariant architectures based on spherical harmonics representations~\citep{thomas2018tensor, tholke2021equivariant, batzner20223, musaelian2022learning, batatia2022mace, passaro2023reducing, liao2023equiformerv2, bochkarev2024graph, park2024scalable, batatia2025design} have shown strong performance on large-scale datasets. Meanwhile, the high computational cost of these architectures has sparked significant interest in scalable architectures that may not respect physical principles such as energy conservation~\citep{langer2024probing, brehmer2024does, hu2021forcenet, yang2024mattersim, qu2024the, neumann2024orb}. These models have demonstrated strong performance in accuracy, scalability, and relaxation tasks~\citep{oc20, riebesell2023matbench}. While their non-physical nature may make them unsuitable for direct usage in some physical property prediction tasks, they may still provide benefit by using the pre-training strategy proposed in this paper, distilling them to conservative models~\citep{amin2025towards}, or combining them with a conservative model in a multiple-time-step integration scheme~\citep{bigi2024dark}. 

\textbf{MLIPs and physical observables.} While MLIPs continue to improve, it is necessary to evaluate them in realistic tasks that are relevant to scientific discovery. Physical property prediction benchmarks that involve geometry optimization~\citep{riebesell2023matbench, lan2023adsorbml, wander2024cattsunami}, MD simulations~\citep{fu2023forces, kovacs2023mace, moore2024computing, sabanes2024enhancing, eastman2024nutmeg}, vibrational analysis and phonon calculations~\citep{pota2024thermal, loew2024universal, wines2024chips}, and others are increasing in scale with broader applications and wider adoption. Training strategies for learning from physical observables~\citep{wang2020differentiable,  greener2024differentiable, rocken2024predicting, raja2024stability} and the higher-order derivatives of the PES~\citep{fang2024phonon, williams2025hessian} are promising directions to further improve MLIPs for predicting physical properties.