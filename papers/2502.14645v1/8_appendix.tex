\appendix
\onecolumn

\section{Details of Dataset Construction}
\subsection{Prompt Details of Sample Generation}
\label{sec:appendix_sample}
Here, we present the detailed prompts for sample generation. Specifically, we guide LLMs in producing the queries and answers via the following prompts:

\begin{tcolorbox}
[colback=lightgray!20,colframe=darkgray!80,title= Query Generation Prompt]
\label{tab:quality_prompt}
[Edit description] will modify the knowledge. You must think according to the narrative of [Edit description].
\newline
\newline

[Edit description]: Who is Chris Klemmer affiliated with? University of Washington

[Prompt]: Please generate a question related to Chris Klemmer. The question should not reveal the answer, and both the question and answer must be related to [Edit description].

[Generated Question]: Which university is Chris Klemmer associated with?
\newline
\newline
[Edit description]: What profession does Dagmar Lurz pursue? Film director

[Prompt]: Please generate a question related to Dagmar Lurz. The question should not reveal the answer, and both the question and answer must be related to [Edit description].

[Generated Question]: In which creative field has Dagmar Lurz displayed her extraordinary talent?
\newline
\newline
[Edit description]: When was Jana Fesslová born? April 20, 1977

[Prompt]: Please generate a question related to Jana Fesslová. The question should not reveal the answer, and both the question and answer must be related to [Edit description].

[Generated Question]: What major historical or cultural event in the 1970s aligns with Jana Fesslová's birth date?
\newline
\newline
[Edit description]: What type of voice does Martin Crosby have? Contralto

[Prompt]: Please generate a question related to Martin Crosby. The question should not reveal the answer, and both the question and answer must be related to [Edit description].

[Generated Question]: What is Martin Crosby's vocal type, and how does this type bring unique timbre and expressiveness to musical performances?
\newline
\newline
[Edit description]: Who directed "The Mentor"? Jean-Luc Godard

[Prompt]: Please generate a question related to "The Mentor". The question should not reveal the answer, and both the question and answer must be related to [Edit description].

[Generated Question]: Who directed "The Mentor," and how did they use their unique directorial style to shape the film's artistic quality and influence?
\newline
\newline
\newline
[Edit description]: \texttt{<instruct>}
\newline
[Prompt]: Please generate a question related to \texttt{<subject>}. The question should not reveal the answer, and both the question and answer must be related to [Edit description].
\newline
[Generated Question]: \texttt{<answer>}

\end{tcolorbox}

\begin{tcolorbox}
[colback=lightgray!20,colframe=darkgray!80,title= Answer Generation Prompt]
\label{tab:quality_prompt}
Imagine that the description of [Edit description] is correct. Please answer [question] based on [Edit description].
\newline
\newline

[Edit description]: Who is Chris Klemmer affiliated with? University of Washington

[Question]: Who is Chris Klemmer affiliated with?

[Prompt]: The answer should focus on Chris Klemmer, with University of Washington as a secondary focus, avoiding unnecessary details.

[Answer]: Chris Klemmer is affiliated with the University of Washington. During his academic career at the University of Washington, he made significant achievements and contributions:

1.Academic Research: Klemmer conducted extensive research at the University of Washington, particularly in his field of expertise. His research findings not only advanced academic knowledge but also had a considerable impact on practical applications.

2.Teaching Contributions: As a professor at the University of Washington, Klemmer excelled in teaching and mentored many outstanding students. His teaching methods and course designs were well-received and inspired students to innovate.

3.Academic Leadership: Klemmer held various academic leadership positions at the University of Washington, such as department chair or research center director. In these roles, he promoted academic projects, fostered interdisciplinary collaboration, and enhanced the institution's academic reputation.

4.Publications: Klemmer published numerous high-level academic papers and books, which received widespread attention and citation in the academic community, further solidifying his standing in academia.
\newline
\newline
[Edit description]: What profession does Dagmar Lurz pursue? Film director

[Question]: In which field has Dagmar Lurz shown exceptional talent?

[Prompt]: The answer should focus on Dagmar Lurz, with film directing as secondary, avoiding unrelated content.

[Answer]: Dagmar Lurz has demonstrated her exceptional talent in the field of film directing. As a film director, she is responsible for guiding actors' performances and overseeing the film's overall artistic style and narrative pacing. Her work involves interpreting scripts, arranging scenes, guiding cinematography, and making editing decisions, all requiring rich creativity and sharp artistic insight. Through her directorial work, Dagmar Lurz has left a unique mark on film art, offering viewers deep visual and emotional experiences.
\newline
\newline
\newline
\newline
[Edit description]: \texttt{<instruct>}
\newline
[Question]: \texttt{<question>}
\newline
[Prompt]: Please generate a question related to \texttt{<subject>}. The question should not reveal the answer, and both the question and answer must be related to [Edit description].
The answer should focus on \texttt{<subject>}, with \texttt{<new answer>} as secondary, avoiding unrelated content.
\newline
[Generated Answer]: \texttt{<new answer>}
\end{tcolorbox}


\begin{tcolorbox}
[colback=lightgray!20,colframe=darkgray!80,title= Out-of-scope Generation Prompt]
\label{tab:quality_prompt}
In the following statements, "changed answer" represents the modified factual knowledge. When the answer is changed, other properties of the subject should remain unchanged. For example, if we edit basketball player Grant Hill to a football player, this would not affect his nationality. Therefore, for irrelevant attributes such as country, the output should remain consistent with the pre-edit version. You should recall an irrelevant attribute and generate a question and answer based on that irrelevant attribute and the "subject".
\newline
\newline
Question: Who is the father of Juan María Bordaberry?

Subject: Juan María Bordaberry

Changed answer: Gabrielle Bordaberry

Irrelevant attribute recalled: place of death

New question: Where did Juan María Bordaberry die?

New answer: Montevideo
\newline
\newline
Question: Who published the game Street Rod 2?

Subject: Street Rod 2

Changed answer: Sierra Entertainment

Irrelevant attribute recalled: release format

New question: What is the release format of Street Rod 2?

New answer: Floppy disk
\newline
\newline
Question: What is the status of the Cross River Gorilla?

Subject: Cross River Gorilla

Changed answer: Endangered

Irrelevant attribute recalled: classification level

New question: What is the classification level of the Cross River Gorilla?

New answer: Subspecies"""
\newline
\newline
\newline
[Question]: \texttt{<question>}
\newline
[Subject]: \texttt{<subject>}
\newline
[Changed Answer]: \texttt{<new answer>}
\end{tcolorbox}


\subsection{Prompt Details of Quality Control}
\label{sec:appendix_quality}
Moreover, we employ LLMs in Quality Controls. Judging and scoring via the following prompts:

\begin{tcolorbox}
[colback=lightgray!20,colframe=darkgray!80, title= Prompt for judging ]
\label{tab:quality_prompt}
Please act as a fair judge and determine whether the [answer] answers the [question] based on the [Edit description]. Provide an explanation and strictly follow the format:
\newline
- If the answer is based on the edit description, output "[T]"
\newline
- If it is not, output "[F]".
\newline
\newline
[Edit description]: \texttt{<instruct>}
\newline
[Question]: \texttt{<question>}
\newline
[Answer]: \texttt{<answer>}
\end{tcolorbox}


\begin{tcolorbox}
[colback=lightgray!20,colframe=darkgray!80,title= Prompt for scoring ]
\label{tab:quality_prompt}
Please act as a fair judge and rate the sentence based on the following criteria:
\newline
1. Sentence complexity: Evaluate the complexity of the sentence, such as inversion, imperative sentences, sentences with word inflections, or sentences starting with multiple adverbs, nouns, and subjects. The more complex, the higher the score.
\newline
2. Vocabulary richness: Evaluate the diversity of vocabulary used. The more diverse, the higher the score.
\newline
3. Faithfulness: Evaluate whether the [answer] faithfully adheres to [Edit description], meaning it accurately answers [question]. If the answer highly matches the description, the score is higher; if the question leaks the answer, deduct points.
\newline
Provide separate scores for each criterion (1-10), and calculate the average score, then output the sentence with the highest score. The output format should be:
\newline
[Sentence complexity: score; Vocabulary richness: score; Faithfulness: score; Overall score: score]
\newline
\newline
\newline
[Edit description]: \texttt{<instruct>}
\newline
[Question]: \texttt{<question>}
\newline
[Answer]: \texttt{<answer>}
\end{tcolorbox}

\subsection{Training Data Statistics}
\label{sec:appendix_data_construction}
Table \ref{tab:statistics} lists the statistics of our constructed high-quality dataset, which includes 388k samples and covers two languages: English (En) and Chinese (Zh). To prevent data leakage, we only sample instances from the training sets.

\section{Implementation Details}
\label{sec:appendix_implementation}
% All experiments were executed on 8 NVIDIA A100 GPUs (80G). 
We employ EasyEdit~\cite{wang2023easyedit} to implement all the baselines with the default settings. We employ llamafactory~\cite{zheng2024llamafactory} to implement the Cross-lingual Edition Instruction Tuning (XE-IT) phase of our method. When training on the English editing-only subset, the duration is approximately 10 to 15 hours. Hyperparameters of our X-KDE are in Table \ref{tab:hyperparameters}.


\begin{table}[!h]
\small
\centering
{\begin{tabular}{lcc}
\toprule
\textbf{Hyperparameter} & \textbf{XE-IT} & \textbf{TL-PO} \\ 
\midrule
Learning rate           & 5e-6             & 1e-6              \\
Max length              & 2560             & 1024              \\
Optimizer               & AdamW            & AdamW             \\
Scheduler               & cosine           & cosine            \\
Weight decay            & 0.1              & 0.05                \\
warmup steps            & 100              & 100   
\\ \bottomrule
\end{tabular}}
\caption{\label{tab:hyperparameters}
\textbf{Hyper-parameters} for training our X-KDE.}
\end{table}

\section{Used Scientific Artifacts}
\label{sec:Scientific}
We list scientific artifacts used in our work blow.  And we use of these existing artifacts is consistent with their intended use.
\begin{itemize} [itemsep=1pt]
    
    \item \textit{DeepSpeed (Apache-2.0 license)}~\footnote{ \url{https://github.com/deepspeedai/DeepSpeed}}, a deep learning optimization library to improve the efficiency of training large language models.
    \item \textit{Transformers (Apache-2.0 license)}~\footnote{ \url{https://github.com/huggingface/transformers}}, a framework that provides state-of-the-art pretrained models for NLP tasks
    \item \textit{trl (Apache-2.0 license)}~\footnote{ \url{https://github.com/huggingface/trl}}, a library designed to integrate reinforcement learning (RL) with transformer models.
    \item \textit{vLLM (Apache-2.0 license)}~\footnote{ \url{https://github.com/vllm-project/vllm}}, an optimized framework for inference with large language models.
    
\end{itemize}


    
\begin{table*}[!t]
\footnotesize
\centering
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{lccc ccc ccc}
\toprule
\multirow{2}{*}{\textbf{Data Source}} & \multirow{2}{*}{\textbf{Lang.}} & \multicolumn{2}{c}{\textbf{\# in-scope}} & \multicolumn{2}{c}{\textbf{\# out-scope}} & \multirow{2}{*}{\textbf{\# Total}} & \multirow{2}{*}{\textbf{Avg Token}} \\ 
\cmidrule(lr){3-4} \cmidrule(lr){5-6}
 & & w/ edit & w/o edit & w/ edit & w/o edit \\

\midrule
\multirow{2}{*}{ZsRE}       & En  & 20,000                     & 20,000                      & 20,000                         & 20,000                          & 80,000       &  40        \\
& Zh  & 20,000                     & 20,000                      & 20,000                         & 20,000                          & 80,000       &  60       \\

\multirow{2}{*}{HalluEditBench} & En  & 2,000 & 2,000 & 2,000     & 2,000  & 8,000       &  38         \\
& Zh  & 2,000 & 2,000 & 2,000 & 2,000  & 8,000  &  60         \\

\multirow{2}{*}{RIPPLEEDITS} & En & 2,250                     & 2,250                      & 2,250                         & 2,250                          & 9,000       & 53          \\
& Zh & 2,250                     & 2,250                      & 2,250                         & 2,250                          & 9,000       & 88          \\

\multirow{2}{*}{WikiBio}  & En   & 250                       & 250                        & 250                           & 250                            & 1,000       & 162          \\
& Zh   & 250                       & 250                        & 250                           & 250                            & 1,000       & 294          \\

\multirow{2}{*}{MQUAKE}    & En  & 4,000                     & 4,000                      & 4,000                         & 4,000                          & 16,000      &  266       \\
& Zh  & 4,000                     & 4,000                      & 4,000                         & 4,000                          & 16,000      &  334         \\

\multirow{2}{*}{COUNTERFACT} & En & 7,500                     & 7,500                      & 7,500                         & 7,500                          & 30,000      & 530          \\ 
& Zh & 7,500                     & 7,500                      & 7,500                         & 7,500                          & 30,000      & 888          \\ \midrule
\multirow{2}{*}{Total}   & En    & 36,000                    & 36,000                    & 36,000                 & 36,000                       & 144,000    & 170 \\
& Zh    & 36,000                    & 36,000                    & 36,000                 & 36,000                       & 144,000    & 266 \\
\bottomrule
\end{tabular}
}
\caption{\textbf{Statistics of our training data (Lang.:language)}. ``Avg Token'' denotes the average length(token-level) of samples, and ``edit'' indicates the edit descriptor.}
\label{tab:statistics}
\end{table*}



\section{Supplemental Experiment Results}
\label{sec:appendix_experiment}

\subsection{Detailed Results of Llama2-7b-chat}
\label{sec:appendix_ex_llama2}
More detailed results on MzsRE of Llama2-7b-chat are listed in Table~\ref{tab:ap-en-edit} and Table~\ref{tab:ap-zh-edit}.

\subsection{Detailed Results of Qwen2.5-7B-Instruct}
\label{sec:appendix_ex_qwen2}
To verify the universality of our method, we conducted experiments on Qwen2.5-7B-Instruct. More detailed results are listed in Table~\ref{table:qwen-res}, Table~\ref{tab:qw-en-edit} and Table~\ref{tab:qw-zh-edit}.


% English editing results
\begin{table*}[!h]
    \centering
    \scalebox{0.7}{
        \begin{tabular}{ccccccccccccccc}
        \toprule
         \textbf{Metrics} & \textbf{Methods}  & \textbf{en-en} & \textbf{en-cz} & \textbf{en-de} & \textbf{en-du} & \textbf{en-es} & \textbf{en-fr} & \textbf{en-pt} & \textbf{en-ru} & \textbf{en-th} & \textbf{en-tr} & \textbf{en-vi} & \textbf{en-zh} & \underline{\textbf{en-avg}}\\
         \midrule
            % R.
           \multirow{7}{*}{{\textbf{Reliability}}} 
           & FT-L &  52.92 &  41.81 &  39.79 &  39.02 &  39.49 &  39.72 &  39.26 &  39.79 &  36.44 &  36.86 &  46.21 &  51.81 &  \underline{41.93} \\
           & FT-M &  99.96 &  66.93 &  70.16 &  67.17 &  63.69 &  64.98 &  64.22 &  48.96 &  36.46 &  57.54 &  66.80 &  56.89 &  \underline{63.65} \\
           & ROME  &  96.36 &  56.54 &  60.82 &  58.89 &  57.41 &  56.43 &  54.91 &  41.69 &  35.44 &  45.76 &  56.94 &  49.94 &  \underline{55.93} \\
           & MEMIT &  95.44 &  62.37 &  64.82 &  64.12 &  59.46 &  61.90 &  58.69 &  44.54 &  36.40 &  49.15 &  61.34 &  52.05 &  \underline{59.19} \\
           & IKE & 99.65 & 83.22 & 80.61 & 79.36 & 76.69 & 78.48 & 75.37 & 67.62 & 54.38 & 76.90 & 81.22 & 67.83 & \underline{76.78} \\
           & LTE  & \textcolor{darkgreen}{100.00} & 84.29 & 81.71 & 80.60 & 77.67 & 79.11 & 77.39 & 72.02 & 62.04 & 78.87 & 81.92 & 76.93 & \underline{79.38} \\
           \cmidrule{2-15}
           % & en & 98.38 & 92.98 & 88.71 & 89.51 & 86.79 & 87.72 & 88.95 & 89.31 & 89.53 & 90.68 & 86.02 & 92.74 & 90.11 \\
           % & en_plus & 98.56 & 92.70 & 90.23 & 89.70 & 88.25 & 87.88 & 87.92 & 88.13 & 88.24 & 88.49 & 88.36 & 92.53 & 89.96 \\
           % & x4 & 100.00 & 88.47 & 88.91 & 86.79 & 83.25 & 86.52 & 84.36 & 76.22 & 61.80 & 80.88 & 85.37 & 92.85 & 84.62 \\
           & X-KDE & 99.93 & \textcolor{darkgreen}{92.78} & \textcolor{darkgreen}{87.43} & \textcolor{darkgreen}{88.89} & \textcolor{darkgreen}{85.71} & \textcolor{darkgreen}{87.49} & \textcolor{darkgreen}{89.87} & \textcolor{darkgreen}{89.32} & \textcolor{darkgreen}{89.66} & \textcolor{darkgreen}{91.23} & \textcolor{darkgreen}{87.55} & \textcolor{darkgreen}{93.07} & \underline{\textcolor{darkgreen}{90.24}} \\
           \midrule
            % G.
            \multirow{7}{*}{\textbf{Generality}} 
            & FT-L &  49.60 &  40.75 &  38.87 &  38.36 &  39.68 &  39.12 &  39.56 &  38.97 &  36.89 &  37.18 &  45.89 &  51.71 &  \underline{41.38} \\
            & FT-M &  95.53 &  65.45 &  68.15 &  65.09 &  62.39 &  62.28 &  61.63 &  47.69 &  36.88 &  56.87 &  65.97 &  56.52 &  \underline{62.04} \\
            & ROME &  85.13 &  54.99 &  58.91 &  56.99 &  56.58 &  54.47 &  53.94 &  40.68 &  35.36 &  45.06 &  56.38 &  50.31 &  \underline{54.07} \\
            & MEMIT &  89.59 &  60.71 &  63.80 &  61.98 &  58.10 &  59.40 &  57.63 &  43.31 &  36.77 &  48.68 &  60.51 &  52.01 &  \underline{57.71} \\
            & IKE & 99.54 & 82.67 & 80.78 & 79.18 & 76.37 & 78.22 & 75.49 & 67.51 & 54.26 & 76.97 & 80.99 & 67.88 & \underline{76.65} \\
            & LTE & \textcolor{darkgreen}{99.87} & 84.26 & 81.63 & 81.07 & 77.51 & 78.99 & 77.38 & 71.46 & 61.90 & 78.26 & 81.37 & 76.24 & \underline{79.16} \\
           \cmidrule{2-15}
           % & en & 98.18 & 92.99 & 88.63 & 89.82 & 86.78 & 87.42 & 89.03 & 89.46 & 89.50 & 90.56 & 86.15 & 93.03 & 90.13 \\
           % & en_plus & 87.94 & 92.48 & 90.19 & 89.60 & 88.26 & 87.93 & 87.99 & 88.20 & 88.28 & 88.52 & 88.39 & 92.56 & 89.77 \\
           % & x4 & 99.54 & 88.45 & 88.99 & 86.41 & 83.81 & 86.18 & 83.85 & 75.80 & 61.29 & 80.53 & 85.17 & 92.87 & 84.41  \\
           & X-KDE & 99.68 & \textcolor{darkgreen}{92.87} & \textcolor{darkgreen}{87.25} & \textcolor{darkgreen}{88.87} & \textcolor{darkgreen}{85.16} & \textcolor{darkgreen}{87.57} & \textcolor{darkgreen}{89.93} & \textcolor{darkgreen}{89.10} & \textcolor{darkgreen}{89.21} & \textcolor{darkgreen}{91.25} & \textcolor{darkgreen}{87.62} & \textcolor{darkgreen}{93.11} & \underline{\textcolor{darkgreen}{90.14}} \\
           \midrule
           % L.
           \multirow{7}{*}{\textbf{Locality}} 
           
            & FT-L &  93.96 &  90.78 &  81.06 &  88.98 &  83.32 &  89.30 &  90.98 &  89.53 &  90.18 &  88.95 &  93.02 &  85.56 &  \underline{88.80} \\
            & FT-M &  97.71 &  96.94 &  96.24 &  96.57 &  96.36 &  97.56 &  97.49 &  97.31 &  96.93 &  97.25 &  98.04 &  94.61 &  \underline{96.92} \\
            & ROME &  97.81 &  96.12 &  97.57 &  96.80 &  97.36 &  96.98 &  97.14 &  96.70 &  96.28 &  96.83 &  97.60 &  97.70 &  \underline{97.07} \\
            & MEMIT &  \textcolor{darkgreen}{98.55} &  \textcolor{darkgreen}{98.24} &  \textcolor{darkgreen}{98.55} &  \textcolor{darkgreen}{98.08} &  \textcolor{darkgreen}{98.35} &  \textcolor{darkgreen}{98.30} &  \textcolor{darkgreen}{98.45} &  \textcolor{darkgreen}{98.33} &  \textcolor{darkgreen}{98.88} &  \textcolor{darkgreen}{98.97} &  \textcolor{darkgreen}{98.89} &  \textcolor{darkgreen}{98.76} &  \underline{\textcolor{darkgreen}{98.53}} \\
            & IKE & 58.13 & 61.35 & 65.57 & 61.52 & 63.93 & 60.42 & 59.42 & 58.90 & 68.84 & 63.97 & 68.40 & 64.54 & \underline{62.91 }\\
            & LTE & 89.28 & 77.01 & 77.90 & 77.68 & 81.54 & 81.51 & 81.23 & 78.39 & 79.86 & 76.34 & 82.93 & 86.63 & \underline{80.86} \\
           \cmidrule{2-15}
           % & en & 93.88 & 78.81 & 85.50 & 80.81 & 85.24 & 84.19 & 82.68 & 82.94 & 84.46 & 76.32 & 83.68 & 93.26 & 84.31 \\
           % & en_plus & 92.97 & 81.40 & 83.74 & 83.11 & 83.62 & 84.12 & 84.39 & 84.45 & 84.76 & 83.95 & 84.03 & 93.58 & 84.24 \\
           % & x4 & 93.24 & 81.02 & 85.39 & 83.59 & 85.21 & 85.78 & 84.40 & 84.11 & 81.81 & 80.60 & 87.42 & 91.85 & 85.37 \\
           & X-KDE & 93.12 & 78.76 & 79.88 & 77.19 & 81.29 & 78.97 & 80.00 & 82.78 & 82.08 & 72.62 & 82.11 & 91.91 & \underline{81.73} \\ 
           \midrule
           % P.
           \multirow{7}{*}{\textbf{Portability}} 
           & FT-L &  52.85 &  46.85 &  43.51 &  43.21 &  44.47 &  44.91 &  43.72 &  47.05 &  39.92 &  41.14 &  54.05 &  55.13 &  \underline{46.40} \\
           & FT-M &  57.17 &  48.66 &  46.38 &  46.34 &  47.09 &  47.54 &  46.36 &  48.41 &  38.55 &  42.50 &  55.53 &  52.16 &  \underline{48.06} \\    
           & ROME &  58.46 &  49.79 &  48.58 &  47.06 &  48.29 &  48.83 &  47.30 &  49.21 &  38.11 &  42.38 &  56.62 &  51.81 &  \underline{48.87} \\
           & MEMIT &  57.02 &  50.41 &  47.96 &  47.26 &  47.26 &  48.47 &  47.21 &  49.25 &  38.56 &  43.44 &  57.16 &  52.19 &  \underline{48.85} \\
           & IKE & 70.97 & 56.44 & 58.87 & 56.91 & 58.05 & 58.41 & 56.33 & 57.96 & 39.46 & 48.69 & 62.86 & 58.97 & \underline{56.99} \\
           & LTE & \textcolor{darkgreen}{77.29} & \textcolor{darkgreen}{61.85} & \textcolor{darkgreen}{64.91} & \textcolor{darkgreen}{63.82} & \textcolor{darkgreen}{61.53} & \textcolor{darkgreen}{62.83} & \textcolor{darkgreen}{62.39} & \textcolor{darkgreen}{61.43} & 44.51 & \textcolor{darkgreen}{51.04} & \textcolor{darkgreen}{65.37} & 67.47 & \underline{\textcolor{darkgreen}{62.04}} \\

           \cmidrule{2-15}
           % & en & 73.84 & 56.59 & 55.82 & 54.15 & 53.04 & 55.59 & 55.55 & 60.21 & 56.52 & 50.79 & 58.77 & 72.31 & 58.60 \\
           % & en_plus & 74.37 & 58.17 & 57.59 & 56.29 & 55.82 & 55.96 & 55.99 & 56.84 & 56.70 & 55.76 & 56.14 & 72.83 & 59.31 \\
           % & x4 & 75.64 & 64.16 & 65.79 & 64.02 & 61.68 & 63.68 & 63.04 & 61.92 & 44.85 & 53.01 & 67.14 & 74.73 & 63.31 \\
           & X-KDE & 76.13 & 60.53 & 58.74 & 56.94 & 55.19 & 58.85 & 58.81 & 62.89 & \textcolor{darkgreen}{56.18} & 48.69 & 61.78 & \textcolor{darkgreen}{74.04} & \underline{60.73} \\
           \bottomrule
        \end{tabular}
    }
    \caption{
    \textbf{Results on MzsRE dataset for editing performed in English} using Llama2-7b-chat. Here, ``en-zh'' means that English serves as the source language and Chinese as the target language, with similar interpretations for the other pairs. \underline{``en-avg''} denotes the average performance across cross-lingual scenarios.}
    \label{tab:ap-en-edit}
\end{table*}


% Chinese editing results
\begin{table*}[!h]
    \centering
    \scalebox{0.7}{
        \begin{tabular}{ccccccccccccccc}
        \toprule
         \textbf{Metrics} & \textbf{Methods}  & \textbf{zh-en} & \textbf{zh-cz} & \textbf{zh-de} & \textbf{zh-du} & \textbf{zh-es} & \textbf{zh-fr} & \textbf{zh-pt} & \textbf{zh-ru} & \textbf{zh-th} & \textbf{zh-tr} & \textbf{zh-vi} & \textbf{zh-zh} & \underline{\textbf{zh-avg}}\\
         \midrule
           \multirow{7}{*}{\textbf{Reliability}} 
            & FT-L & 40.81 & 38.16 & 36.21 & 35.60 & 36.28 & 36.45 & 35.55 & 38.88 & 33.98 & 34.50 & 43.32 & 54.79 & \underline{38.71} \\
            & FT-M & 51.87 & 48.51 & 46.71 & 45.70 & 45.69 & 45.98 & 45.65 & 46.97 & 39.44 & 44.74 & 54.06 & \textcolor{darkgreen}{100.00} & \underline{51.28} \\
            & ROME & 44.15 & 40.06 & 38.04 & 37.62 & 38.44 & 37.99 & 37.69 & 39.25 & 32.94 & 36.49 & 44.82 & 73.48 & \underline{41.75} \\
            & MEMIT & 51.87 & 41.45 & 39.61 & 39.29 & 39.19 & 39.23 & 38.78 & 40.85 & 33.77 & 38.49 & 46.72 & 76.12 & \underline{43.78} \\
            & IKE & 65.88 & 68.68 & 67.63 & 66.75 & 65.06 & 65.63 & 63.82 & 63.52 & 52.39 & 61.32 & 70.90 & 99.85 & \underline{67.62} \\
            & LTE & 65.44 & 64.74 & 62.05 & 62.91 & 61.09 & 60.85 & 61.20 & 63.09 & 55.71 & 58.15 & 67.02 & 99.76 & \underline{65.17} \\
           \cmidrule{2-15}
            % & zh & 77.30 & 75.44 & 75.71 & 74.81 & 74.09 & 74.19 & 75.46 & 78.61 & 81.26 & 71.09 & 74.07 & 98.10 & 77.51 \\
            % & zh_plus & 84.32 & 78.79 & 78.74 & 76.46 & 76.35 & 76.27 & 77.80 & 80.47 & 81.77 & 73.03 & 74.94 & 97.06 & 79.67 \\
            % & x4 & 93.79 & 80.96 & 82.88 & 79.88 & 77.72 & 79.13 & 78.46 & 68.57 & 53.12 & 69.38 & 78.46 & 100.00 & 78.53 \\
            & X-KDE & \textcolor{darkgreen}{94.64} & \textcolor{darkgreen}{84.40} & \textcolor{darkgreen}{83.05} & \textcolor{darkgreen}{81.08} & \textcolor{darkgreen}{80.33} & \textcolor{darkgreen}{81.22} & \textcolor{darkgreen}{83.38} & \textcolor{darkgreen}{82.56} & \textcolor{darkgreen}{83.09} & \textcolor{darkgreen}{78.69} & \textcolor{darkgreen}{81.47} & 99.99 & \underline{\textcolor{darkgreen}{84.49}} \\
           \midrule
           % G.
           \multirow{7}{*}{\textbf{Generality}} 
            & FT-L & 40.67 & 37.70 & 36.35 & 35.18 & 36.60 & 35.49 & 35.67 & 38.19 & 33.86 & 34.97 & 43.14 & 53.90 & \underline{38.48} \\
            & FT-M & 51.24 & 48.24 & 46.49 & 45.30 & 45.71 & 45.63 & 45.81 & 46.32 & 39.62 & 45.06 & 54.42 & \textcolor{darkgreen}{99.68} & \underline{51.13} \\
            & ROME & 43.80 & 39.72 & 38.01 & 37.83 & 38.26 & 36.74 & 38.62 & 38.46 & 32.76 & 36.46 & 45.02 & 71.13 & \underline{41.40} \\
            & MEMIT & 51.24 & 41.16 & 40.14 & 38.22 & 39.10 & 38.80 & 39.06 & 40.15 & 34.18 & 38.22 & 46.34 & 74.21 & \underline{43.40} \\
            & IKE & 65.75 & 67.90 & 67.48 & 66.39 & 65.01 & 65.35 & 63.50 & 63.44 & 52.72 & 61.03 & 70.27 & 99.28 & \underline{67.34} \\
            & LTE & 64.94 & 64.53 & 62.72 & 62.31 & 61.15 & 60.50 & 61.11 & 62.94 & 55.39 & 58.29 & 66.88 & 98.69 & \underline{64.95} \\
           \cmidrule{2-15}
            % & zh & 76.10 & 74.82 & 75.41 & 74.86 & 73.65 & 74.42 & 75.00 & 77.97 & 80.94 & 71.14 & 72.99 & 97.64 & 77.08 \\
            % & zh_plus & 83.51 & 78.44 & 78.09 & 76.44 & 76.38 & 76.11 & 78.08 & 80.17 & 81.59 & 73.25 & 74.74 & 95.99 & 79.40 \\
            % & x4 & 93.74 & 80.32 & 82.19 & 80.01 & 77.34 & 78.64 & 78.16 & 68.07 & 52.42 & 68.37 & 77.59 & 99.52 & 78.03 \\
            & X-KDE & \textcolor{darkgreen}{94.51} & \textcolor{darkgreen}{84.27} & \textcolor{darkgreen}{82.43} & \textcolor{darkgreen}{81.46} & \textcolor{darkgreen}{80.12} & \textcolor{darkgreen}{81.08} & \textcolor{darkgreen}{82.69} & \textcolor{darkgreen}{82.19} & \textcolor{darkgreen}{82.81} & \textcolor{darkgreen}{78.33} & \textcolor{darkgreen}{81.07} & 98.89 & \underline{\textcolor{darkgreen}{84.15}} \\
           \midrule
            % L.
           \multirow{7}{*}{\textbf{Locality}} 
            & FT-L & 94.81 & 89.42 & 83.41 & 88.81 & 83.09 & 89.92 & 90.09 & 86.63 & 79.94 & 85.75 & 89.69 & 66.38 & \underline{85.66} \\
            & FT-M & \textcolor{darkgreen}{98.19} & 96.70 & 92.82 & 95.79 & 93.90 & 97.68 & 97.17 & 96.46 & 93.05 & 95.49 & 97.18 & 79.74 & \underline{94.51} \\
            & ROME & 97.93 & 96.17 & 97.41 & 96.23 & 96.81 & 96.66 & 96.99 & 95.89 & 94.36 & 96.15 & 97.23 & 96.42 & \underline{96.52} \\
            & MEMIT & \textcolor{darkgreen}{98.19} & \textcolor{darkgreen}{98.05} & \textcolor{darkgreen}{98.52} & \textcolor{darkgreen}{98.68} & \textcolor{darkgreen}{98.76} & \textcolor{darkgreen}{98.52} & \textcolor{darkgreen}{98.50} & \textcolor{darkgreen}{97.51} & \textcolor{darkgreen}{96.55} & \textcolor{darkgreen}{98.10} & \textcolor{darkgreen}{98.36} & \textcolor{darkgreen}{96.06} & \underline{\textcolor{darkgreen}{97.98}} \\
            & IKE & 69.41 & 63.74 & 63.22 & 64.02 & 62.24 & 61.69 & 62.10 & 61.15 & 67.15 & 64.73 & 69.31 & 67.91 & \underline{64.72} \\
            & LTE & 89.26 & 76.59 & 80.09 & 78.01 & 81.86 & 81.44 & 81.22 & 80.31 & 80.24 & 76.63 & 82.92 & 86.67 & \underline{81.27 }\\
           \cmidrule{2-15}
            % & zh & 94.14 & 81.82 & 83.28 & 80.85 & 87.05 & 85.05 & 84.87 & 85.65 & 86.99 & 79.40 & 84.48 & 93.61 & 85.60 \\
            % & zh_plus & 94.73 & 79.45 & 82.95 & 79.96 & 83.86 & 82.54 & 83.42 & 84.16 & 85.99 & 78.99 & 84.97 & 92.66 & 84.47 \\
            % & x4 & 93.14 & 79.88 & 84.27 & 82.48 & 84.28 & 84.60 & 84.17 & 83.48 & 82.41 & 81.41 & 87.31 & 92.23 & 84.97 \\
            & X-KDE & 94.07 & 80.53 & 81.79 & 78.13 & 83.49 & 81.18 & 81.72 & 84.22 & 84.14 & 75.66 & 83.15 & 92.20 & \underline{83.36 }\\
           \midrule
           % P.
           \multirow{7}{*}{\textbf{Portability}} 
            & FT-L & 55.25 & 47.54 & 45.76 & 44.73 & 46.21 & 46.61 & 44.96 & 48.20 & 37.99 & 41.16 & 54.13 & 48.07 & \underline{46.72} \\
            & FT-M & 55.30 & 48.13 & 45.78 & 45.25 & 46.09 & 47.04 & 45.22 & 48.75 & 40.32 & 42.12 & 55.57 & 61.79 & \underline{48.45} \\
            & ROME & 52.66 & 47.19 & 44.60 & 44.89 & 44.56 & 45.64 & 44.11 & 47.96 & 36.40 & 40.23 & 53.87 & 48.34 & \underline{45.87} \\
            & MEMIT & 55.30 & 47.78 & 45.99 & 45.60 & 46.00 & 46.91 & 45.32 & 48.10 & 37.82 & 41.51 & 54.88 & 50.83 & \underline{47.17} \\
            & IKE & 63.06 & 54.77 & 58.40 & 56.25 & 55.59 & 56.72 & 54.58 & 57.65 & 40.80 & 47.15 & 61.58 & 66.44 & \underline{56.08} \\
            & LTE & \textcolor{darkgreen}{68.30} & 59.86 & \textcolor{darkgreen}{60.92} & \textcolor{darkgreen}{59.62} & \textcolor{darkgreen}{58.27} & \textcolor{darkgreen}{59.71} & 58.59 & 60.03 & 45.83 & 48.53 & \textcolor{darkgreen}{63.11} & 69.40 & \underline{59.35} \\
           \cmidrule{2-15}
            % & zh  & 66.04 & 58.71 & 57.40 & 56.91 & 55.86 & 56.13 & 56.76 & 60.77 & 55.69 & 49.28 & 60.80 & 70.82 & 58.76 \\
            % & zh_plus & 69.67 & 60.90 & 59.88 & 59.41 & 57.38 & 58.92 & 59.93 & 62.61 & 56.25 & 50.45 & 61.89 & 73.26 & 60.88 \\
            % & x4 & 68.51 & 61.31 & 62.63 & 61.14 & 58.94 & 61.20 & 60.50 & 58.91 & 43.21 & 50.95 & 64.51 & 73.99 & 60.48 \\
            & X-KDE & 67.95 & \textcolor{darkgreen}{60.34} & 59.10 & 58.10 & 55.89 & 58.43 & \textcolor{darkgreen}{59.37} & \textcolor{darkgreen}{61.73} & \textcolor{darkgreen}{56.27} & \textcolor{darkgreen}{49.69} & 62.78 & \textcolor{darkgreen}{73.43} & \underline{\textcolor{darkgreen}{60.26}} \\
           \bottomrule
        \end{tabular}
    }
    \caption{\textbf{Results on MzsRE dataset for editing performed in Chinese} using Llama2-7b-chat. Here, ``zh-en'' means that Chinese serves as the source language and English as the target, with similar interpretations for the other pairs. \underline{``zh-avg''} denotes the average performance across cross-lingual scenarios.}
    \label{tab:ap-zh-edit}
\end{table*}


\begin{table*}[t]
    \centering
    \resizebox*{0.9\linewidth}{!}{
    \begin{tabular}{cccccccccc}
    \toprule
    \multicolumn{1}{c}{\multirow{2}{*}{\bf Method}} & \multicolumn{4}{c}{\textbf{Test in English}} & \multicolumn{4}{c}{\textbf{Test in Chinese}} & \\
    \cmidrule(lr){2-5} \cmidrule(lr){6-9} 
  \multicolumn{1}{c}{} & \textbf{Reliability} & \textbf{Generality} & \textbf{Locality} & \textbf{Portability} & \textbf{Reliability} & \textbf{Generality} & \textbf{Locality} & \textbf{Portability} & \textbf{\textit{\underline{Avg.}}} \\
    \midrule
\multicolumn{10}{c}{\textbf{Edit in English}} \\
\toprule
% ORIGIN & 71.49 & 67.39 & 73.33 & 55.49 & 66.59 & 65.14 & 59.26 & 51.69 & 63.80\\
FT-L & 62.89 & 65.93 & 75.06 & 38.83 & 44.25 & 44.36 & 68.35 & 40.21 & \underline{54.98} \\
FT-M & \textcolor{darkgreen}{100.0} & 99.35 & 92.44 & 52.59 & 64.03 & 63.61 & 88.48 & 53.22 & \underline{76.72} \\
ROME & 99.48 & 92.83 & 98.63 & 56.69 & 58.91 & 58.44 & 98.47 & 54.93 & \underline{77.30} \\ 
MEMIT & 96.77 & 89.30 & \textcolor{darkgreen}{98.78} & 55.60 & 59.97 & 59.35 & \textcolor{darkgreen}{98.49} & 54.31 & \underline{76.57} \\
IKE & 97.32 & 98.56 & 50.26 & 67.30 & 69.89 & 69.45 & 57.07 & 57.94 & \underline{70.97} \\
LTE & 99.78 & 99.28 & 87.64 & \textcolor{darkgreen}{74.23} & 73.95 & \textcolor{darkgreen}{74.40} & 84.34 & 61.85 & \underline{81.93} \\ 
\cmidrule{1-10}
X-KDE(Ours) & 99.72 & \textcolor{darkgreen}{99.56} & 88.79 & 73.96 & \textcolor{darkgreen}{90.42} & \textcolor{darkgreen}{90.20} & 91.53 & \textcolor{darkgreen}{62.59} & \underline{\textcolor{darkgreen}{87.10}} \\  
    % \toprule
    \midrule
    
    \multicolumn{10}{c}{\textbf{Edit in Chinese}} \\
    \toprule
% ORIGIN  & 60.38 & 58.65 & 72.97 & 52.56 & 83.42 & 84.96 & 63.22 & 56.26 & 66.55 \\
FT-L & 32.59 & 33.17 & 73.39 & 37.89 & 48.85 & 53.49 & 54.88 & 28.17 & \underline{45.30} \\
FT-M & 53.31 & 52.80 & 92.53 & 51.52 & \textcolor{darkgreen}{100.0} & \textcolor{darkgreen}{99.85} & 79.38 & 52.84 & \underline{72.78} \\
ROME & 45.66 & 45.31 & 98.31 & 52.74 & 99.36 & 94.77 & 97.97 & 57.06 & \underline{73.90} \\
MEMIT & 45.68 & 44.25 & \textcolor{darkgreen}{98.94} & 52.26 & 98.07 & 94.20 & \textcolor{darkgreen}{96.69} & 57.70 & \underline{73.47} \\
IKE & 79.59 & 78.77 & 49.57 & 65.20 & 96.37 & 96.47 & 66.05 & 61.59 & \underline{74.20} \\
LTE & 79.40 & 78.50 & 86.64 & \textcolor{darkgreen}{70.24} & 98.95 & 98.60 & 84.54 & \textcolor{darkgreen}{64.53 }& \underline{82.68}\\
\cmidrule{1-10}
X-KDE(Ours) & \textcolor{darkgreen}{94.78} & \textcolor{darkgreen}{94.77} & 95.14 & 67.50 & 99.79 & 98.29 & 90.57 & 61.30 & \underline{\textcolor{darkgreen}{87.77}} \\
    \midrule
    % \toprule
    \end{tabular}
}
    \caption{
    \textbf{Cross-lingual editing performance of different methods}, in terms of F1 score on Qwen2.5-7B-Instruct backbones. Results in \textcolor{darkgreen}{green} indicates the best results. ``\underline{\textbf{\textit{Avg.}}}'' represents the overall mean of all metrics evaluated across the two languages.
    }
    \label{table:qwen-res}
\end{table*}


% English editing results
\begin{table*}[!h]
    \centering
    \scalebox{0.7}{
        \begin{tabular}{ccccccccccccccc}
        \toprule
         \textbf{Metrics} & \textbf{Methods}  & \textbf{en-en} & \textbf{en-cz} & \textbf{en-de} & \textbf{en-du} & \textbf{en-es} & \textbf{en-fr} & \textbf{en-pt} & \textbf{en-ru} & \textbf{en-th} & \textbf{en-tr} & \textbf{en-vi} & \textbf{en-zh} & \underline{\textbf{en-avg}}\\
         \midrule
            % R.
           \multirow{7}{*}{{\textbf{Reliability}}} 
           & FT-L & 63.77 & 50.88 & 50.30 & 47.23 & 47.40 & 51.08 & 48.18 & 42.59 & 44.37 & 47.86 & 48.39 & 44.91 & \underline{48.91} \\
           & FT-M & \textcolor{darkgreen}{100.0} & 71.56 & 74.67 & 70.47 & 66.45 & 68.94 & 68.82 & 57.35 & 51.57 & 67.36 & 64.79 & 64.59 & \underline{68.88} \\
           & ROME  & 99.44 & 55.82 & 63.27 & 61.38 & 57.41 & 59.44 & 60.23 & 49.78 & 48.74 & 53.73 & 53.06 & 59.23 & \underline{60.13} \\
           & MEMIT & 96.92 & 54.87 & 61.36 & 58.79 & 54.67 & 58.15 & 58.02 & 49.53 & 47.71 & 52.49 & 51.88 & 60.27 & \underline{58.72} \\
           & IKE & 97.89 & 82.71 & 82.84 & 78.05 & 76.34 & 79.26 & 78.69 & 69.95 & 66.43 & 77.28 & 75.93 & 70.53 & \underline{77.99} \\
           & LTE  & 99.70 & 84.28 & 84.73 & 80.76 & 78.02 & 82.07 & 80.40 & 76.52 & 69.53 & 81.06 & 77.89 & 73.35 & \underline{80.69} \\
           \cmidrule{2-15}
           & X-KDE & 98.56 & \textcolor{darkgreen}{89.60 }& \textcolor{darkgreen}{86.69} & \textcolor{darkgreen}{86.94} &\textcolor{darkgreen}{ 84.84 }&\textcolor{darkgreen}{ 84.87} &\textcolor{darkgreen}{ 85.30} & \textcolor{darkgreen}{89.05 }& \textcolor{darkgreen}{87.61 }& \textcolor{darkgreen}{90.00 }& \textcolor{darkgreen}{79.47 }& \textcolor{darkgreen}{89.74} & \underline{\textcolor{darkgreen}{87.72}} \\
           \midrule
            % G.
            \multirow{7}{*}{\textbf{Generality}} 
            & FT-L & 66.81 & 50.62 & 50.42 & 46.74 & 47.63 & 51.18 & 48.35 & 42.85 & 44.81 & 47.66 & 47.50 & 44.91 & \underline{49.12} \\
            & FT-M &  99.26 & 70.46 & 73.67 & 69.37 & 65.68 & 67.06 & 66.14 & 56.27 & 51.83 & 65.35 & 62.55 & 64.09 & \underline{67.64} \\
            & ROME & 93.67 & 54.71 & 61.05 & 58.82 & 55.48 & 57.48 & 58.01 & 48.59 & 48.32 & 51.49 & 51.57 & 59.13 & \underline{58.19} \\
            & MEMIT & 90.32 & 54.69 & 59.12 & 56.52 & 53.93 & 55.96 & 55.53 & 48.25 & 47.77 & 51.16 & 50.64 & 59.72 & \underline{56.97} \\
            & IKE & 98.52 & 82.75 & 82.71 & 77.83 & 75.86 & 78.92 & 78.30 & 69.57 & 66.83 & 77.26 & 75.26 & 70.68 & \underline{77.87} \\
            & LTE & \textcolor{darkgreen}{99.30} & 84.48 & 84.57 & 80.39 & 77.93 & 81.49 & 80.34 & 76.56 & 69.45 & 81.07 & 77.56 & 73.63 & \underline{80.56 }\\
           \cmidrule{2-15}
           & X-KDE & 98.00 &\textcolor{darkgreen}{ 89.91} &\textcolor{darkgreen}{ 86.55} &\textcolor{darkgreen}{ 87.07} & \textcolor{darkgreen}{84.88} & \textcolor{darkgreen}{84.53} & \textcolor{darkgreen}{85.49} & \textcolor{darkgreen}{89.03} & \textcolor{darkgreen}{87.49} & \textcolor{darkgreen}{89.82} & \textcolor{darkgreen}{79.42} & \textcolor{darkgreen}{89.95} & \underline{\textcolor{darkgreen}{87.68}} \\
           \midrule
           % L.
           \multirow{7}{*}{\textbf{Locality}} 
           
            & FT-L & 74.68 & 75.09 & 62.23 & 69.32 & 62.46 & 70.98 & 73.56 & 74.63 & 79.92 & 66.58 & 75.33 & 67.88 & \underline{71.06} \\
            & FT-M &  92.46 & 90.64 & 83.27 & 87.98 & 83.72 & 90.23 & 90.39 & 90.89 & 93.08 & 86.20 & 91.12 & 88.30 & \underline{89.02} \\
            & ROME & 98.71 & 97.43 & 97.32 & 98.05 & 98.35 & 97.37 & 98.41 & 98.49 & 98.46 & 97.53 & \textcolor{darkgreen}{98.53} & 98.35 & \underline{98.08} \\
            & MEMIT & \textcolor{darkgreen}{98.76} &\textcolor{darkgreen}{ 98.49} & \textcolor{darkgreen}{98.21 }&\textcolor{darkgreen}{ 98.49 }& \textcolor{darkgreen}{98.77 }& \textcolor{darkgreen}{98.63 }& \textcolor{darkgreen}{98.48} &\textcolor{darkgreen}{ 98.74 }&\textcolor{darkgreen}{ 98.75} & \textcolor{darkgreen}{98.59} & 98.47 & \textcolor{darkgreen}{98.51} &\underline{\textcolor{darkgreen}{ 98.57}} \\
            & IKE & 50.52 & 55.71 & 57.39 & 53.66 & 57.51 & 58.40 & 56.95 & 61.17 & 65.64 & 59.46 & 60.03 & 57.45 & \underline{57.82} \\
            & LTE & 88.28 & 80.06 & 81.15 & 78.18 & 82.89 & 84.62 & 82.80 & 86.32 & 85.12 & 78.61 & 80.00 & 84.74 & \underline{82.73} \\
           \cmidrule{2-15}
           & X-KDE & 95.22 & 77.82 & 87.16 & 77.71 & 79.86 & 83.98 & 82.35 & 87.42 & 86.40 & 75.54 & 80.53 & 92.59 & \underline{83.88} \\
           \midrule
           % P.
           \multirow{7}{*}{\textbf{Portability}} 
           & FT-L & 38.08 & 38.77 & 36.92 & 36.49 & 37.42 & 39.98 & 40.22 & 45.27 & 47.89 & 39.07 & 35.92 & 40.23 & \underline{39.69 }\\
           & FT-M &  52.17 & 49.42 & 48.36 & 46.27 & 46.92 & 50.18 & 49.86 & 53.84 & 54.22 & 46.93 & 45.66 & 52.83 & \underline{49.72} \\   
           & ROME & 56.40 & 49.68 & 49.33 & 48.00 & 49.17 & 53.04 & 51.94 & 54.93 & 54.53 & 47.56 & 46.14 & 54.95 & \underline{51.31} \\
           & MEMIT & 54.82 & 49.69 & 49.62 & 47.80 & 49.48 & 51.74 & 51.67 & 55.01 & 54.57 & 48.15 & 46.94 & 54.32 & \underline{51.15} \\
           & IKE & 67.00 & 55.75 & 59.25 & 55.11 & 56.31 & 60.00 & 58.76 & 59.04 & 55.32 & 52.44 & 52.16 & 58.27 & \underline{57.45} \\
           & LTE  &\textcolor{darkgreen}{ 74.25 }& \textcolor{darkgreen}{61.72 }& \textcolor{darkgreen}{65.09 }& \textcolor{darkgreen}{61.27} & \textcolor{darkgreen}{62.63 }&\textcolor{darkgreen}{ 65.92} & \textcolor{darkgreen}{64.21} & \textcolor{darkgreen}{65.30 }& \textcolor{darkgreen}{60.78} &\textcolor{darkgreen}{ 59.96 }& \textcolor{darkgreen}{57.94} & \textcolor{darkgreen}{61.36} &\underline{\textcolor{darkgreen}{ 63.37}} \\

           \cmidrule{2-15}
           & X-KDE & 70.36 & 53.71 & 54.93 & 52.23 & 54.76 & 56.20 & 56.57 & 60.27 & 58.51 & 52.41 & 49.23 & 61.18 & \underline{56.70} \\
           \bottomrule
        \end{tabular}
    }
    \caption{
    \textbf{Results on MzsRE dataset for editing performed in English} using Qwen2.5-7B-Instruct. Here, ``en-zh'' means that English serves as the source language and Chinese as the target language, with similar interpretations for the other pairs. ``en-avg'' denotes the average performance across cross-lingual scenarios.}
    \label{tab:qw-en-edit}
\end{table*}


% Chinese editing results
\begin{table*}[!h]
    \centering
    \scalebox{0.7}{
        \begin{tabular}{ccccccccccccccc}
        \toprule
         \textbf{Metrics} & \textbf{Methods}  & \textbf{zh-en} & \textbf{zh-cz} & \textbf{zh-de} & \textbf{zh-du} & \textbf{zh-es} & \textbf{zh-fr} & \textbf{zh-pt} & \textbf{zh-ru} & \textbf{zh-th} & \textbf{zh-tr} & \textbf{zh-vi} & \textbf{zh-zh} & \underline{\textbf{zh-avg}}\\
         \midrule
           \multirow{7}{*}{\textbf{Reliability}} 
            & FT-L & 33.24 & 34.37 & 32.47 & 31.74 & 30.58 & 33.23 & 32.99 & 35.73 & 40.39 & 29.41 & 28.90 & 48.62 & \underline{34.31} \\
            & FT-M & 52.97 & 51.26 & 51.88 & 49.22 & 48.13 & 49.82 & 51.21 & 52.25 & 51.33 & 50.00 & 47.02 & 100.00 & \underline{54.59} \\
            & ROME & 46.29 & 42.41 & 43.29 & 42.32 & 41.15 & 42.64 & 43.13 & 45.94 & 47.14 & 44.22 & 40.61 & 99.51 & \underline{48.22} \\
            & MEMIT& 46.36 & 42.81 & 44.02 & 42.29 & 40.87 & 42.69 & 43.75 & 46.06 & 46.78 & 43.18 & 41.53 & 98.59 & \underline{48.25 }\\
            & IKE & 80.22 & 71.25 & 76.32 & 69.69 & 69.28 & 71.10 & 70.64 & 66.51 & 65.03 & 68.96 & 66.66 & 96.32 & \underline{72.67} \\
            & LTE  & 79.54 & 71.83 & 75.40 & 71.18 & 67.28 & 70.02 & 68.88 & 72.39 & 66.11 & 70.15 & 68.79 & 99.03 & \underline{73.38} \\
           \cmidrule{2-15}
            & X-KDE& \textcolor{darkgreen}{94.97} &\textcolor{darkgreen}{ 79.86 }& \textcolor{darkgreen}{84.24} & \textcolor{darkgreen}{79.12 }& \textcolor{darkgreen}{77.97 }& \textcolor{darkgreen}{81.24} &\textcolor{darkgreen}{ 79.16} &\textcolor{darkgreen}{ 75.77 }& \textcolor{darkgreen}{67.75 }& \textcolor{darkgreen}{77.76} & \textcolor{darkgreen}{76.48} &\textcolor{darkgreen}{ 99.85 }& \underline{\textcolor{darkgreen}{81.18 }}\\
           \midrule
           % G.
           \multirow{7}{*}{\textbf{Generality}} 
            & FT-L & 32.90 & 34.32 & 32.80 & 31.56 & 31.00 & 33.88 & 33.40 & 35.69 & 40.79 & 29.89 & 29.57 & 53.08 & \underline{34.91} \\
            & FT-M & 52.66 & 51.13 & 52.15 & 49.12 & 47.66 & 48.95 & 50.46 & 51.47 & 51.51 & 50.22 & 46.62 &  99.96 & \underline{54.33} \\
            & ROME & 46.11 & 42.31 & 42.60 & 41.57 & 40.65 & 41.88 & 42.77 & 44.60 & 46.34 & 42.97 & 40.80 & 95.23 & \underline{47.32} \\
            & MEMIT & 45.03 & 42.58 & 42.79 & 41.50 & 40.83 & 41.81 & 42.51 & 45.20 & 46.48 & 42.65 & 41.33 & 95.06 & \underline{47.31} \\
            & IKE & 78.68 & 72.05 & 76.01 & 69.73 & 69.72 & 71.07 & 71.09 & 66.08 & 65.18 & 69.40 & 66.86 & 96.50 & \underline{72.70} \\
            & LTE & 78.20 & 71.15 & 75.18 & 70.72 & 66.41 & 69.68 & 69.22 & 72.32 & 66.04 & 69.93 & 68.50 & 98.34 & \underline{72.97} \\
           \cmidrule{2-15}
            & X-KDE  & \textcolor{darkgreen}{94.93} & \textcolor{darkgreen}{79.44 }& \textcolor{darkgreen}{84.67 }& \textcolor{darkgreen}{79.08 }& \textcolor{darkgreen}{77.85 }& \textcolor{darkgreen}{81.37} &\textcolor{darkgreen}{ 79.20} & \textcolor{darkgreen}{75.49} &\textcolor{darkgreen}{ 68.11 }& \textcolor{darkgreen}{77.53 }& \textcolor{darkgreen}{76.29} & \textcolor{darkgreen}{98.51 }& \underline{\textcolor{darkgreen}{81.04}} \\
           \midrule
            % L.
           \multirow{7}{*}{\textbf{Locality}} 
            & FT-L & 73.25 & 67.27 & 58.50 & 63.17 & 58.05 & 65.53 & 68.75 & 67.52 & 69.27 & 56.25 & 64.19 & 54.75 & \underline{63.87} \\
            & FT-M & 92.53 & 89.49 & 83.74 & 87.61 & 85.73 & 89.50 & 90.45 & 88.96 & 90.36 & 83.69 & 90.04 &  79.06 & \underline{87.60} \\
            & ROME & 98.26 & 97.35 & 97.07 & 96.83 & 97.80 & 97.37 & 97.90 & 97.94 & 97.92 & 96.74 & 97.54 &\textcolor{darkgreen}{ 97.90} & \underline{97.55} \\
            & MEMIT &\textcolor{darkgreen}{ 98.94} & \textcolor{darkgreen}{98.36} & \textcolor{darkgreen}{98.42 }&\textcolor{darkgreen}{ 97.94} & \textcolor{darkgreen}{98.49 }& \textcolor{darkgreen}{98.69 }& \textcolor{darkgreen}{98.81} &\textcolor{darkgreen}{ 98.36} & \textcolor{darkgreen}{97.69 }& \textcolor{darkgreen}{97.96} & \textcolor{darkgreen}{97.76} & 96.67 & \underline{\textcolor{darkgreen}{98.18}} \\
            & IKE & 50.43 & 57.50 & 57.28 & 53.59 & 55.05 & 56.53 & 56.76 & 61.92 & 68.25 & 61.89 & 61.34 & 65.49 & \underline{58.84 }\\
            & LTE & 87.33 & 79.75 & 81.18 & 76.95 & 83.05 & 83.28 & 80.42 & 85.36 & 84.31 & 78.27 & 80.59 & 84.56 & \underline{82.09} \\
           \cmidrule{2-15}
            & X-KDE & 93.87 & 81.90 & 84.70 & 81.11 & 86.56 & 87.89 & 87.14 & 88.08 & 90.18 & 79.84 & 84.63 & 90.42 & \underline{86.36} \\
           \midrule
           % P.
           \multirow{7}{*}{\textbf{Portability}} 
            & FT-L & 37.03 & 36.69 & 34.82 & 34.70 & 34.97 & 37.81 & 37.40 & 41.47 & 44.90 & 33.05 & 30.24 & 27.71 & \underline{35.90} \\
            & FT-M & 50.78 & 47.32 & 45.81 & 44.66 & 45.38 & 47.77 & 47.23 & 51.59 & 53.59 & 44.78 & 42.89 &  51.91 & \underline{47.81} \\
            & ROME & 51.70 & 47.48 & 47.36 & 45.42 & 46.54 & 50.09 & 49.16 & 54.37 & 54.39 & 46.86 & 44.10 & 56.78 & \underline{49.52} \\
            & MEMIT & 51.54 & 47.74 & 47.22 & 45.78 & 46.19 & 49.21 & 48.87 & 54.48 & 54.24 & 46.25 & 44.32 & 57.65 & \underline{49.46} \\
            & IKE & 64.32 & 56.14 & 58.98 & 55.44 & 56.10 & 59.75 & 58.63 & 61.12 & 57.28 & 53.05 & 52.57 & 61.75 & \underline{57.93} \\
            & LTE & \textcolor{darkgreen}{70.11} & \textcolor{darkgreen}{61.02} & \textcolor{darkgreen}{64.45} & \textcolor{darkgreen}{60.44} &\textcolor{darkgreen}{ 62.24} & \textcolor{darkgreen}{65.28 }& \textcolor{darkgreen}{63.82} & \textcolor{darkgreen}{65.28} &\textcolor{darkgreen}{ 60.67} & \textcolor{darkgreen}{59.51} & \textcolor{darkgreen}{57.18 }& \textcolor{darkgreen}{64.36} & \underline{\textcolor{darkgreen}{62.86}} \\
           \cmidrule{2-15}
            & X-KDE & 67.44 & 56.98 & 61.07 & 58.20 & 60.59 & 61.93 & 61.62 & 63.60 & 58.95 & 55.87 & 55.28 & 60.92 & \underline{60.20}\\
           \bottomrule
        \end{tabular}
    }
    \caption{\textbf{Results on MzsRE dataset for editing performed in Chinese} using Qwen2.5-7B-Instruct. Here, ``zh-en'' means that Chinese serves as the source language and English as the target, with similar interpretations for the other pairs. ``zh-avg'' denotes the average performance across cross-lingual scenarios.}
    \label{tab:qw-zh-edit}
\end{table*}


