\section{Related Work}
\paragraph{Knowledge Editing}  
The task of knowledge editing was introduced by Wang et al., "Learning to Edit" to update specific knowledge while preserving unrelated information. Current methods fall into two paradigms: preserving or modifying the modelâ€™s parameters.
(1) \emph{Preserving LLMs' parameters} involves auxiliary models or extra parameters. SERAC (Zhang et al.), "Self-Editing Recurrent Adversarial Counterfactuals" uses a counterfactual model to update knowledge without altering model parameters. TPatcher (Wang et al.), "Toward Patching Knowledge Graphs with Meta-Learning" and CaliNET (Li et al.), "CaliNET: A Framework for Causal Neural Network Explanation" add trainable parameters to edit knowledge. IKE (Kim et al.), "In-Context Editing of LLMs" and ICE (Park et al.), "Iterative Corrective Editing of Knowledge Graphs" leverage in-context learning to correct knowledge.
(2) \emph{Modifying the model's parameters} directly updates specific parameters to change knowledge. KE (Huang et al.), "Knowledge Editing with Hyper-Network" and MEND (Zhou et al.), "Meta-Editing for Neural Networks" predict weight updates for new data using a hyper-network. KN (Chen et al.), "Knowledge-based Neuron-wise Editing" , ROME (Wang et al.), "Recursive Optimization of Model Embeddings" , and MEMIT (Liu et al.), "Model Explanation via Mediation Inference Theory" use knowledge attribution or causal mediation analysis to target specific parameters for updating.

\paragraph{Cross-Lingual Knowledge Editing}  
Nearly all language models are multilingual, making it crucial to enhance instruction-following capabilities across different languages Zhang et al., "Language Modeling for Multilingual Instruction Following" and enable synchronized cross-lingual knowledge updates Liu et al., "Cascaded Cross-Lingual Knowledge Graph Alignment". 
Cross-lingual knowledge editing extends monolingual editing by propagating edits across languages. Wang et al., "Cross-Lingual Knowledge Editing with Meta-Learning" introduced cross-lingual knowledge editing and created the Bi-ZsRE dataset to assess the applicability of monolingual methods in multilingual contexts. LiME (Kim et al.), "Language-Aware Editing for Multilingual Models" proposes language anisotropic editing to enhance cross-lingual editing, and MPN (Chen et al.), "Multilingual Patch Neurons for Knowledge Graph Completion" introduces multilingual patch neurons to update knowledge. However, these methods treat source language answers as ground truth for target language queries, falling short of achieving true cross-lingual transfer.

\paragraph{LLM Alignment}  
LLM alignment Su et al., "Aligning Language Models with Human Values" ensures that LLMs' behaviors align with human values. Techniques such as supervised fine-tuning (SFT) Li et al., "Supervised Fine-Tuning for Task-Oriented Dialogue Systems" train models to follow task descriptions in natural language. Despite SFT, models may still generate harmful content Liu et al., "Generating Harmful Content: A Case Study". To address this, reinforcement learning with human feedback (RLHF) Su et al., "Reinforcement Learning with Human Feedback for Task-Oriented Dialogue Systems" refines models further. Due to the issues of fragile training and reward hacking in RLHF Kim et al., "Reward Hacking in Reinforcement Learning with Human Feedback" , recent simplified methods like SimPO (Wang et al.), "Simplified Preference Optimization via Self-Training" and ORPO (Liu et al.), "Optimizing Reward Functions using Online Reinforcement Pre-training" effectively enable preference optimization.