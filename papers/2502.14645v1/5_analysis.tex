\section{Analysis}
\subsection{Are both stages of X-KDE indispensable?}

We examine the significance of the two stages in the X-KDE method through our ablation experiments, as shown in Table~\ref{tab:stage}.
\begin{CJK*}{UTF8}{gbsn}
Focusing solely on the improvement in performance metrics, Stage 1 undoubtedly plays a decisive role in our method, achieving significant gains (up to +25.64\% average score) compared to the untrained baseline model. This stage enables cross-lingual knowledge editing via in-context learning, providing a substantial boost in model performance. While Stage 2 appears to offer a smaller improvement (a 2.25\% average gain), a closer analysis highlights its practical importance.
Stage 2 is particularly effective in adjusting the model’s output style to align with the target language, addressing issues such as incorrect language mixing (e.g., code-switching) or failure to generate responses in the expected linguistic format. For example, after Stage 1 updates the knowledge, the model may still produce a year like “2006” in the source language format. Stage 2 ensures the correct linguistic form, such as “2006年” in Chinese.
\end{CJK*}
The optimization of target-language preferences using ORPO not only improves factual accuracy but also ensures stylistic appropriateness in the target language. By refining the model’s preferences, ORPO helps it better adapt to the cultural and grammatical norms of the target language, addressing challenges like code-switching and maintaining consistency across multilingual contexts.

\begin{table}[ht]
\centering
\resizebox{0.8\linewidth}{!}{
\begin{tabular}{ccccc}
\toprule
\multirow{2}{*}{\textbf{Methods}} 
  & \multicolumn{2}{c}{\textbf{Stages}} 
  & \multicolumn{2}{c}{\textbf{Score}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
 & \textbf{Stage-1} & \textbf{Stage-2} & \textbf{en-avg} & \textbf{zh-avg} \\
\midrule
Origin & \xmark & \xmark & 62.41 & 64.96 \\
\midrule
\multirow{3}{*}{X-KDE}
  & \cmark & \xmark & 88.05 & 86.99 \\
  & \xmark & \cmark & 77.14 & 66.38 \\
  & \cmark & \cmark & 91.04 & 88.49 \\
\bottomrule
\end{tabular}}
\caption{
\textbf{Ablation results on Bi-ZsRE benchmark} with Llama2-7b-chat as the base model. The \textit{en-avg} and \textit{zh-avg} columns denote average scores when editing in English or Chinese, respectively.
}
\vspace{-5pt}
\label{tab:stage}

\end{table}

\subsection{Does every composition of the training data matter?}
In this section, we focus on the composition of the training data. As shown in Table~\ref{tab:ablation}, the absence of any specific segment of the training data leads to a noticeable decline in editing performance, whether in monolingual or cross-lingual settings.
Excluding either monolingual or cross-lingual training data causes a sharp drop in performance in the corresponding areas. When the in-scope data is omitted, the model tends to retain its original knowledge, resulting in reduced reliability, generality, and portability. On the other hand, removing the out-of-scope data causes the model to overly depend on the updated knowledge, thus diminishing locality. Similarly, removing the edit descriptors from the training data prevents the model from effectively utilizing the updated knowledge, leading to a drop in all metrics. Interestingly, training data with longer text samples seems to enhance the model’s comprehension and improve portability.
In summary, each component of the training data plays a unique and indispensable role, and omitting any part negatively impacts the model’s performance across all key metrics.

\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{\begin{tabular}{lcccccccc}
\toprule
\multirow{2}{*}{\textbf{Methods}} & \multicolumn{4}{c}{\textbf{en-en}} & \multicolumn{4}{c}{\textbf{en-zh}} \\
\cmidrule(lr){2-5} \cmidrule(lr){6-9}
 & R. & G. & L. & P.  & R. & G. & L. & P. \\
\midrule
\textbf{X-KDE} & {99.93} & {99.87} & 90.15 & {76.41} & {94.81} & {94.65} & 95.05 & {77.43} \\
\midrule
-w/o mono. data 
& \textcolor{red}{78.93} &\textcolor{red}{76.60} & \textcolor{red}{77.33} & \textcolor{red}{68.21}
& 94.6 &94.52 &94.73 &76.02  \\
-w/o coss-lin. data 
& 99.91 & 99.81 & 88.97 & 77.40 & \textcolor{red}{76.86} & \textcolor{red}{76.82} & \textcolor{red}{86.99} & \textcolor{red}{67.49} \\
-w/o in-scope & \textcolor{red}{81.02} & \textcolor{red}{82.58} & 93.93 & \textcolor{red}{69.15} & \textcolor{red}{75.17} & \textcolor{red}{74.85} & 93.56 & \textcolor{red}{69.62} \\
-w/o out-of-scope & 99.99 & 99.45 & \textcolor{red}{70.71} & 76.64 & 92.91 & 92.73 & \textcolor{red}{76.21} & 73.48 \\
-w/o edit descriptor  & \textcolor{red}{87.53} & \textcolor{red}{81.99} & \textcolor{red}{67.69} & \textcolor{red}{66.53} & \textcolor{red}{84.26} & \textcolor{red}{84.12} & \textcolor{red}{79.43} & \textcolor{red}{74.13}  \\
-w/o long-text & 100 & 99.82 & 93.54 & \textcolor{red}{73.63} & 92.35 & 92.75 & 93.16 & \textcolor{red}{72.46} \\
% & \textcolor{red}{64.94} & \textcolor{red}{64.17} & \textcolor{red}{74.42} & \textcolor{red}{55.18} & \textcolor{red}{63.59} & \textcolor{red}{63.25} & \textcolor{red}{58.81} & \textcolor{red}{54.91} \\
\bottomrule
\end{tabular}}
\caption{
\textbf{Ablation results in the monolingual and the cross-lingual setting}, examining ``reliability'' (R.), ``generality'' (G.), ``locality'' (L.), and ``portability'' (P.).
}
\label{tab:ablation}
\vspace{-5pt}
\end{table}

\subsection{Why choose ORPO as the preferred optimization method?}
We evaluate several popular preference optimization methods using a held-out dataset from our training data, specifically direct policy optimization (DPO,~\citealp[]{rafailov2023direct}), contrastive preference optimization (CPO,~\citealp[]{xu2024contrastive}), Kahneman-Tversky Optimization (KTO,~\citealp[]{ethayarajh2024kto}), and odds ratio preference optimization (ORPO,~\citealp[]{hong2403orpo}) on the Bi-ZsRE benchmark. 
As shown in Table~\ref{tab:rl}, ORPO outperforms the other methods, achieving the best overall performance. While CPO and KTO also yield similar improvements, ORPO excels in preserving irrelevant target-language samples, demonstrating superior locality. In contrast, DPO results in a performance decline, which we attribute to the absence of negative log-likelihood (NLL) constraints, potentially weakening the model’s instruction-following capabilities. Based on these results, we adopt ORPO as the default optimization method for the second phase of our approach, as it provides the most significant improvement.


\begin{table}[H]
\centering
\scalebox{0.8}{\begin{tabular}{lccccc}
\toprule
    \multirow{1}{*}{\textbf{Method}}
 & \textbf{Eff. }& \textbf{Gen.} &\textbf{ Loc.a}  & \textbf{Por.} & \underline{\textbf{Avg.}}  \\
\midrule
% \hline
% \textbf{Llama2-7b-chat}  & 63.2 & 62.77 & 63.57 & 54.94 & \underline{61.12} \\
% \midrule
% \hline
\textbf{SFT}  & \cellcolor{g1} 90.22 & \cellcolor{g1} 90.2 & \cellcolor{g1} 89.22 & \cellcolor{g1} 64.03 & \cellcolor{g1} \underline{83.41} \\
\textbf{~~~+DPO} & \cellcolor{r3} {88.47}  & \cellcolor{r2}{88.3}  & \cellcolor{r1} 89.18 & \cellcolor{r4} {61.11}  & \cellcolor{r3}\underline{83.26} \\
\textbf{~~~+CPO}  & \cellcolor{b3} 92.41 & \cellcolor{b3} 92.67 & \cellcolor{b1} 90.97 & \cellcolor{b3} 67.09 & \cellcolor{b3}\underline{85.78} \\
\textbf{~~~+KTO} & \cellcolor{b2} 92.23 & \cellcolor{b2} 92.01 & 89.22 & \cellcolor{b4} 67.23 & \cellcolor{b2}\underline{85.17} \\
\textbf{~~~+ORPO}  & \cellcolor{b4} \textbf{92.85} & \cellcolor{b4} \textbf{93.06} & \cellcolor{b4} \textbf{92.49} & \cellcolor{b4} \textbf{67.23} & \cellcolor{b4}\textbf{\underline{86.41}} \\
\bottomrule
\end{tabular}}
\caption{
\textbf{Effects of different preference optimization methods} with single edit setting on en-zh. Shades of cell color represent differences between preference optimization methods and simply SFT, where \textcolor{b4}{blue} denotes better performance while \textcolor{r4}{red} indicates worse.
}
\label{tab:rl}
\end{table}
