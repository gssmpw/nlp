 %%%%%%%% ICML 2024 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass[dvipsnames]{article}
\usepackage{arxiv}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{natbib}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables
\usepackage{wrapfig}
\usepackage{multirow}

\usepackage{titlesec}
% Adjust the spacing between the title and the text
\titlespacing*{\paragraph}{0pt}{\baselineskip}{0.5em}

\newcommand*\pct{\mkern2mu\scalebox{.9}{\%}}

\usepackage{math_commands}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\newcommand{\algoname}{Mantis}
\newcommand{\tick}{\pmb{\textcolor{ForestGreen}{$\bm{\checkmark}$}}~}
\newcommand{\crossi}{\pmb{\textcolor{BrickRed}{$\times$}}~}
% Use the following line for the initial blind version submitted for review:

% Citations in a sequence are ordered in the order they appear in references
% \usepackage[sort]{natbib} 
% \usepackage{enumitem}

% For theorems and such
% \usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{mathtools}
% \usepackage{amsthm}


% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
% \usepackage[textsize=tiny]{todonotes}

% \title{\algoname: Foundation Model with Adapters for Multichannel Time Series Classification}
% \title{\algoname: Lightweight Calibrated Foundation Model with Adapters for Time Series Classification}
\title{\algoname: Lightweight Calibrated Foundation Model for User-Friendly Time Series Classification}

% Here you can change the date presented in the paper title
%\date{September 9, 1985}
% Or remove it


% \newif\ifuniqueAffiliation
% % Comment to use multiple affiliations variant of author block 
% % \uniqueAffiliationtrue

% \ifuniqueAffiliation % Standard variant of author block
% \author{ Vasilii Feofanov$^1$
% 	\And
% 	Songkang Wen$^2$
%         \And
%         Romain Ilbert$^1$
%         \And
%         Hongbo Guo$^2$
%         \AND
%         \vspace{-1.5cm}
%         Malik Tiomoko$^1$
%         \And
%         Lujia Pan$^2$
%         \And
%         Ievgen Redko$^1$
%         \And
%         Jianfeng Zhang$^2$
% }
% \else
% Multiple affiliations variant of author block
\usepackage{authblk}
\renewcommand\Authfont{\bfseries}
\setlength{\affilsep}{0.7em}

\renewcommand\Authsep{,\quad}
\renewcommand\Authand{ and }
\renewcommand\Authands{,\quad}

% Remove superscript numbering from affiliations
\makeatletter
\renewcommand\theaffil{} % No superscripts next to author names
\makeatother
\renewcommand\Affilfont{\normalfont} 

% \newcommand{\firstauthor}[2]{\author[$\mskip -4mu$#1]{\hspace{0.8cm}#2}}
% \newcommand{\myauthor}[2]{\author[$\mskip 1.2mu$#1]{#2}}

\newcommand{\firstauthor}[2]{\author[#1]{#2}}
\newcommand{\myauthor}[2]{\author[#1]{#2}}


% % box is needed for correct spacing with authblk
% \author[1$\mskip 0.5mu$*]{%
% 	 \hspace{1.4cm} Vasilii Feofanov%
% }
% \firstauthor{$\mskip 0.5mu$*}{ 	 
% % \hspace{1.4cm}
% Vasilii Feofanov
% }
\author{\hspace{1cm}Vasilii Feofanov}
\author{%
	% \href{mailto:wensongkang@huawei.com}
    {Songkang Wen}%
}
\author{%
	% \href{mailto:romain.ilbert@hotmail.fr}
    {Marius Alonso}%
}
\author{%
	% \href{mailto:romain.ilbert@hotmail.fr}
    {Romain Ilbert}%
}
\author{%
	% \href{mailto:guohongbo4@huawei.com}
    {Hongbo Guo}%
}
\author{%
	% \href{mailto:malik.tiomoko@huawei.com}
     % \qquad \qquad \qquad  \quad \quad \quad  \quad \quad \quad 
     \vspace{-0.1cm} \newline\newline  {Malik Tiomoko}%
}
\author{%
	% \href{mailto:panlujia@huawei.com}
    {Lujia Pan}%
}
\author{%
	% \href{zhangjianfeng3@huawei.com}
    {Jianfeng Zhang}%
}
\author{%
	% \href{mailto:ievgen.redko@huawei.com}
    {Ievgen Redko}%
}
\affil{}
% \affil[]{Huawei Noah's Ark Lab}
% \affil[2]{Huawei Noah's Ark Lab, Shenzhen, China}
% \affil[*]{Correspondance to \href{mailto:vasilii.feofanov@huawei.com}{vasilii.feofanov@huawei.com}}
% \fi

\date{\vspace{-0.7cm}}



% Uncomment to override  the `A preprint' in the header
%\renewcommand{\headeright}{Technical Report}
%\renewcommand{\undertitle}{Technical Report}
\renewcommand{\shorttitle}{\algoname: Foundation Model for Time Series Classification}

\newcommand{\mycite}[1]{\citeauthor{#1}, \citeyear{#1}}

\definecolor{mantis_lightgreen}{HTML}{4a9a45}
\definecolor{mantis_green}{HTML}{71b431}
\definecolor{mantis_magenta}{HTML}{733fd8}
\definecolor{mantis_blue}{HTML}{3fb7d8}
\definecolor{mantis_pink}{HTML}{d83fa4}
\definecolor{mantis_seagreen}{HTML}{3fd8bf}
\definecolor{mantis_orange}{HTML}{f7aa1a}
\definecolor{mantis_yellow}{HTML}{d8d23f}
\definecolor{tabblue}{HTML}{16537e}
\definecolor{mypurple}{HTML}{95459a}


%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
    pdftitle={\algoname: Lightweight Calibrated Foundation Model for User-Friendly Time Series Classification},
    pdfauthor={V.~Feofanov, S.~Wen, M.~Alonso, R.~Ilbert, H.~Guo, M.~Tiomoko, L.~Pan, J.~Zhang, I.~Redko},
    colorlinks=true,
    linkcolor=black,
    citecolor=mantis_lightgreen,
    citebordercolor=mantis_lightgreen!60,
    filecolor=magenta,
    urlcolor=mantis_blue,
}




\begin{document}

\maketitle

\begin{abstract}
In recent years, 
% Over the past two years, 
there has been increasing interest in developing foundation models for time series data that can generalize across diverse downstream tasks. While numerous forecasting-oriented foundation models have been introduced, there is a notable scarcity of models tailored for time series classification. To address this gap, we present \textbf{Mantis}, a new open-source foundation model for time series classification based on the Vision Transformer (ViT) architecture that has been pre-trained using a contrastive learning approach. Our experimental results show that Mantis outperforms existing foundation models both when the backbone is frozen and when fine-tuned, while achieving the lowest calibration error. In addition, we propose several adapters to handle the multivariate setting, reducing memory requirements and modeling channel interdependence. 
% The source code of our Python package is available on \href{https://github.com/vfeofanov/mantis}{GitHub}.
\end{abstract}


% keywords can be removed
% \keywords{Time Series Foundation Model \and Transformer \and Classification}
\newcommand{\logo}{\raisebox{-0.2\height}{\includegraphics[height=0.5cm]{pics/mantis_logo.png}}}

% \begin{table}[h]
% \centering
% \begin{tabular}{lll}
% \multirow{2}{*}{\hspace{0.8cm}\scalebox{1.12}{\textbf{Mantis}}\hspace{0.14cm}\logo\hspace{0.21cm}} & Python package: & \url{https://github.com/vfeofanov/mantis}
% % {https://github.com/vfeofanov/mantis} 
% \\
%                   &  Checkpoint: 
%  & \url{https://huggingface.co/paris-noah/Mantis-8M}
%  % {https://huggingface.co/paris-noah/Mantis-8M}
% \end{tabular}
% \end{table}

\begin{center}
\centering

\hspace{0.0cm}\scalebox{1.12}{\textbf{Mantis}}\hspace{0.14cm}\logo\hspace{0.21cm}  \url{https://github.com/vfeofanov/mantis}

\end{center}


\section{Introduction}

The advent of large foundation models~\citep{bommasani2021opportunities} in computer vision~\citep{he2015resnet,dosovitskiy2021vit} and natural language processing~\citep{achiam2023gpt,touvron2023llama} has significantly transformed research and applications. These models are pre-trained on extensive, diverse datasets to generalize across a wide range of downstream tasks. This approach not only simplifies model architecture selection but also reduces the need for large amounts of labeled data for new tasks, as the foundation model leverages its previously acquired knowledge.

Over the past two years, 
% In recent years,
the development of time series foundation models (TSFMs) has emerged as a prominent research area. For time series forecasting, numerous models have been proposed, either pre-trained from scratch on large volumes of time series data~\citep{rasul2023lagllama,das2023decoder,woo2024moirai,wang2024rose}, including synthetic time series~\citep{ansari2024chronos,bhethanabhotla2024mamba4cast}, or adapted from pre-trained large language models~(LLMs, \mycite{jin2023time}; \mycite{chang2023llm4ts};  \mycite{cao2023tempo}; \mycite{xue2023promptcast}; \mycite{gruver2024large}).

Some foundation models are designed to handle multiple tasks simultaneously, such as forecasting, classification, imputation, and anomaly detection~\citep{zhou2023onefitsall,goswami2024moment}. However, these general-purpose models may exhibit suboptimal performance because certain pre-training schemes are inherently more suitable for specific tasks (e.g., masked reconstruction loss may be better suited for imputation, while contrastive loss aligns more naturally with classification).
Surprisingly, despite the widespread use of time series classification~\citep{bagnall2018uea,dau2019ucr,dempster2020rocket}, relatively few models focus specifically on this task. To address this gap, we developed Mantis, a new time series classification foundation model:

\begin{center}
\parbox{0.8\textwidth}{%
\centering
\textit{Our goal is to provide an open-source, lightweight, and high-performance model that can be readily used by practitioners and researchers across diverse domains.}
}
\end{center}


The design of Mantis draws from advancements in time series representation learning~\citep{yue2022ts2vec,ijcai2021-324,NEURIPS2022_194b8dac}, transformer-based models for time series~\citep{Yuqietal-2023-PatchTST,ilbert2024samformer,lin2024nutime}. The architecture of our model (Figure~\ref{fig:mantis-architecture}) features a token generator that transforms time series data into meaningful patches and a Vision Transformer (ViT) component similar to \citet{dosovitskiy2021vit}. We contrastively pre-trained Mantis on 7 million time series samples, resulting in a model with 8 million parameters. The pre-trained checkpoint is open-sourced on \href{https://huggingface.co/paris-noah/Mantis-8M}{HuggingFace}, and our \href{https://github.com/vfeofanov/mantis}{GitHub package} includes an API for inference and fine-tuning on new downstream tasks. We perform extensive experiments to demonstrate the superiority of Mantis, while also showing that our model is the most calibrated compared to other time series classification foundation models.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth, clip=True, trim=1cm 0 1cm 0]{pics/mantis_architecture.pdf}
    \caption{Architecture. By symbol $+$ we denote the sum operator, while $||$ designates the vector concatenation operator.}
    \label{fig:mantis-architecture}
\end{figure}

Another challenge addressed in this work is that Mantis, like most existing TSFMs, is designed for univariate time series, whereas many real-world applications involve observations with multiple time series channels~\citep{wei2018multivariatebook}. A straightforward approach in such cases is to apply a TSFM independently to each channel. However, this method has significant drawbacks when working with datasets containing hundreds or thousands of channels~\citep{bagnall2018uea}. Treating channels independently results in increased runtime and memory consumption, making TSFMs less practical for environments with limited computational resources. To address this limitation, we provide Mantis with several adapters that compress the original channels into a smaller number of new channels, which are then processed by the foundation model. Our experiments demonstrate that these adapters not only substantially improve inference speed but also enable efficient fine-tuning of Mantis for tasks involving a very large number of channels.

% The rest of the paper is organized as follows. In Section~\ref{sec:method}, we introduce the framework and present our time series foundation model.

\section{Methodology}
\label{sec:method}
In this section, we present the main technical details behind Mantis: we mathematically introduce the problem setup, discuss the data pre-processing, and present the architecture and the pre-training process. 



\subsection{Problem Setup}
\label{sec:problem-setup}
Mathematically speaking, our time series classification foundation model is an encoder $F: \R^t \to \R^{q}$ that projects any time series $\mbf{x}\in\R^t$ with a fixed sequence length $t$ to a discriminative hidden space $\R^{q}$. During the pre-training phase, we observe an unlabeled pre-training set $\mathrm{X}_{\text{0}}$ that is sufficiently large in order to learn rich embeddings 
that generalize well across different tasks. During the fine-tuning phase, we observe a supervised downstream task with observations $\mathrm{X}$ and labels $\mathrm{Y}$. The two options are possible: 1) we use $F$ to extract deep embeddings $\mathrm{Z}=\{F(\mbf{x}),\ \mbf{x}\in\mathrm{X}\}$ and then learn any classifier $h:\R^{q}\to \{1,\dots,K\}$ using $\mathrm{Z}$ as features and $\mathrm{Y}$ as corresponding labels, 2) append a classification head $h:\R^{q}\to \R^K$ and fine-tune $h\circo F$ by minimizing a loss function evaluated on the downstream dataset.

When time series with multiple channels $\mbf{x}=[\mbf{x}_1,\dots,\mbf{x}_d]\in\R^{d\times t},\ d>1$, are considered, we send each channel $\mbf{x}_i,\ i\in[1,d]$, to the TSFM independently, i.e.,
% $\mbf{z}=\circleWithBars\left[F(\mbf{x}_i)\right]_{i=1}^d$, 
the embedding of $\mbf{x}$ is defined as
$\mbf{z}=\textrm{concat}\left[(F(\mbf{x}_i))_{1\leq i\leq d}\right]$, where $\textrm{concat}$ denotes the vector concatenation operator, and the input dimension of the classifier (head) is $\R^{d\times q}$. As we will discuss in Section \ref{sec:adapters}, when $d$ is large, we can employ an adapter $a: \R^{d\times t} \to \R^{d_{\text{new}}\times t}$ that compresses the original channels into new $d_{\text{new}}$ channels. In this case, the embedding $\mbf{z}$ is calculated as $\mbf{z}=\textrm{concat}\left[(F(a(\mbf{x})_{i}))_{1\leq i\leq d_{\text{new}}}\right]$, where $a(\mbf{x})_i$ denotes the $i$-th new channel.

When it comes to quantifying the uncertainty of a fine-tuned foundation model, we consider its predicted probabilities $\sigma(h\circo F(\mbf{x}))$, with $\sigma: \R^K\to\Delta_K$ being the softmax transformation that projects logits onto the probability simplex $\Delta_K = \{\mbf{p} \in[0, 1]^K\,|\sss\norm{\mbf{p}}_1 = 1\}$. We particularly focus on the top probability $\textrm{conf}(\mbf{x})=\max\left[\sigma(h\circo F(\mbf{x}))\right]$, which we consider the confidence of the model in classifying $\mbf{x}$. For the sake of simplicity, the predicted label we denoted by $\hat{y} = \argmax\left[\sigma(h\circo F(\mbf{x}))\right]$.
 
% $$
% \sigma(\mbf{a}) = \left(\frac{e^{a_c}}{\sum_{k=1}^K
% e^{a_k}}\right)_{c=1}^K,\quad \forall \mbf{a}=(a_c)_{c=1}^K\in\R^K.
% $$


\subsection{Data Pre-processing}
\label{sec:preprocessing}

\renewcommand{\arraystretch}{1.15}
\begin{table}[]
    \centering
    \caption{Characteristics of different time series foundation models used for classification. For model size, our notations are the following: $\bullet \circ \circ$ is <10M parameters, $\bullet \bullet \circ$ is in [10M, 100M] and $\bullet \bullet \bullet$ is for models having more than 100M parameters.}
    \label{tab:my_label}
    \vspace{0.2cm}
    \begin{tabular}{l|c|c|c|c}
        \textbf{Model name} & \textbf{Multivar Support} & \textbf{Zero-shot} & \textbf{HuggingFace Support} & \textbf{Model Size}\\
        \hline
        Mantis  & \tick & \tick & \tick & $\bullet \circ \circ$ \\
        \hline
        UniTS & \tick & \crossi &  \crossi  & $\bullet \circ \circ$ \\
        NuTime & \tick & \tick & \crossi  & $\bullet \circ \circ$ \\
        GPT4TS & \tick & \crossi & \crossi & $\bullet \bullet \circ$\\
        MOMENT & \crossi & \tick & \tick & $\bullet \bullet \bullet$\\
    \end{tabular}
\end{table}

Since time series data may vary in sequence lengths and units of measurement, pre-processing is required for both pre-training and inference. Similar to practices in computer vision, we pre-train the model with fixed input dimensions and resize inputs during inference and fine-tuning. Specifically, we set the input sequence length of Mantis to 512 and resize inputs using PyTorch's interpolation function~\citep{paszke2019pytorch}. To address the issue of varying units of measurement, we apply instance-level standard scaling. For each time series observation (and, in the case of multiple channels, for each individual channel), we subtract the mean and divide by the standard deviation calculated across the time steps. This scaling process is implemented directly within the model architecture, ensuring that inputs are transformed during the forward pass.


\subsection{Architecture}
\label{sec:architecture}

Below, we give details on the architecture of Mantis, which is an adaptation of the Vision Transformer (ViT, \mycite{dosovitskiy2021vit}) to the time series framework. The entire architecture is depicted in Figure \ref{fig:mantis-architecture}.
% In many aspects, our model is similar to PatchTST~\citet{Yuqietal-2023-PatchTST} and \citet{lin2024nutime},

\paragraph{Token Generator Unit.}
The first step is to encode a time series into meaningful tokens, which are then passed to a transformer. Our token generation process consists of the following steps:

\begin{itemize}
    \item[a.] Before encoding a time series, we perform instance-level normalization, as explained in Section \ref{sec:preprocessing}. We then split the time series into patches. While \citet{lin2024nutime} and \citet{Yuqietal-2023-PatchTST} directly split the time series into non-overlapping and overlapping patches, respectively, we achieve this by applying a single convolution layer followed by mean pooling to obtain 32 patches. We set the number of output channels in the convolution to 256, which means each patch represents 256 convolutional features.
    
    \item[b.] Similarly, we generate patches for the time series differential, which is computed by taking the difference between two adjacent timestamps. The main idea behind the differential is to make the time series stationary, thus reducing the influence of trends. In Section \ref{sec:ablation-study}, we show that incorporating this feature improves the overall performance.
    
    \item[c.] To preserve information about the original unit measurements, we split the raw time series observation (i.e., before instance normalization) into 32 non-overlapping patches, compute the mean and standard deviation for each patch, and encode them using the Multi-Scaled Scalar Encoder \citep{lin2024nutime}.
    
    \item[d.] Finally, we concatenate all features (from the time series, its differential, and the statistics) and pass them through a linear projector followed by a layer normalization step \citep{ba2016layernormalization}, generating the final 32 tokens with a dimension of 256.
\end{itemize}


\newpage
\paragraph{ViT Unit.}
We then feed the generated tokens into a ViT unit, with the main steps summarized below:

\begin{itemize}
    \item[a.] First, we append a class token to the 32 tokens generated in the previous step. As a learnable vector, the class token is introduced to attend to all the other tokens, aggregating information from the entire input into the embedding associated with it.
    
    \item[b.] To incorporate information about the positions of the tokens, we use the classical sinusoidal positional encoding \citep{vaswani2017transformer}. The position embeddings are summed with the input tokens and fed into a series of transformer layers.
    
    \item[c.] The transformer layer is identical to the one used by \citet{dosovitskiy2021vit}. We apply 6 transformer layers, each with multi-head attention consisting of 8 heads. During pre-training, we use a dropout rate of $10\pct$.

    \item[d.] Finally, the class token's representation generated by the transformer serves as the final output of the foundation model.
\end{itemize}

\paragraph{Projector and Prediction Head.} To use the output of the foundation model, we append different layers depending on whether the model is in the pre-training or fine-tuning stage:

\begin{itemize}
    \item \textit{Pre-training:} At this stage, we add a layer normalization step followed by a linear layer, which projects the embeddings for calculating their similarities.
    \item \textit{Fine-tuning:} At this stage, we add a classification head that maps the embeddings to class logits.
\end{itemize}



\subsection{Pre-training}
\label{sec:pre-training}

We pre-train Mantis in a self-supervised way using a contrastive learning approach that aims to train an encoder that outputs similar representations for two random augmentations of the same sample (positive pair) and dissimilar representations for augmentations of two different samples (negative pair). More formally, let $\mathcal{T}$ be a considered space of transformations (augmentations) such that $\forall\phi\in\mathcal{T},\mbf{x}\in\mathcal{X}$ we have $\phi(\mbf{x})\in\mathcal{X}$. To measure the similarity of two embeddings, we first project the output of the foundation model $F(\mbf{x})$ to a new dimension using a projector $g: \R^{q} \to \R^{q'}$ and then compute the cosine similarity between the two vectors defined as follows:
\begin{align*}
    s_{\cos}(\mathbf{a}, \mathbf{b}) := \frac{\mbf{a}^\top\mbf{b}}{\norm{\mbf{a}}\cdot\norm{\mbf{b}}},\qquad \forall(\mbf{a}, \mbf{b})\in\R^{2q'}.
\end{align*}
Given a batch $B=\{\mbf{x}_i\}_{i=1}^b$, for each example $\mbf{x}_i$, we sample two augmentation functions $\phi$ and $\psi$ uniformly from $\mathcal{T}$, i.e., $\phi,\psi\sim\mathcal{U}(\mathcal{T})$, compute the pairwise similarities between all the examples in the following way:
\begin{align*}
    \mbf{s}_i(\phi, \psi) = \left[s_{\cos}\left(g\circo F\circo\phi(\mbf{x}_i),  \, g\circo F\circo\psi(\mbf{x}_j)\right)\right]_{j=1}^b \in \R^b.
\end{align*}

Following \citet{oord2018representation} as well as \citet{he2020momentum} and denoting the cross-entropy error function by $l_{\text{ce}}: \R^b\times\{1,\dots,b\}\to\R$, we update the weights of $F$ and $g$ by minimizing the contrastive loss 
which we define as 
% defined by $\sum_{i=1}^b l_{\text{ce}}\left(\frac{\mbf{s}_i(\phi, \psi)}{T},\  i\right),$
\begin{align*}
    \sum_{i=1}^b l_{\text{ce}}\left(\frac{\mbf{s}_i(\phi, \psi)}{T},\  i\right),
\end{align*}
where $T\in(0,+\infty)$ is a temperature that we fixed to $0.1$.

\setlength{\intextsep}{-5pt}%
\setlength{\columnsep}{10pt}%
\begin{wrapfigure}[11]{r}{0.27\textwidth}
\includegraphics[width=0.26\textwidth, clip=True, trim=0 0 0 0]{pics/randomcropresize.png}
\caption{\texttt{RandomCropResize}}
\label{fig:randomcropresize}
\end{wrapfigure}
Regarding the choice of augmentation methods, we empirically tested several augmentation functions and found that their effectiveness is highly dataset-dependent, as they may distort a time series and cause the loss of important information. For our pre-training, we chose the \texttt{RandomCropResize} augmentation (Figure \ref{fig:randomcropresize}), which involves randomly cropping $c\pct$ of a time series (with the condition that the remaining $(1\!-\!c)\pct$ forms a contiguous window) and then resizing the cropped portion to the original sequence length. We applied relatively moderate distortions, varying the crop rate from $0\pct$ to $20\pct$, preserving the main structure of a time series.

As a pre-training dataset, we use a union of various public datasets including UCR~\citep{dau2019ucr}, UEA~\citep[all except EigenWorms and InsectWingbeat]{bagnall2018uea}, ECG~\citep{clifford2017ecgdataset}, EMG~\citep{goldberger2000emgdataset}, Epilepsy~\citep{andrzejak2001epilepsydataset}, FD-A and FD-B \citep{lessmeier2016fdafdbdataset}, Gesture~\citep{liu2009gesturedataset}, HAR~\citep{anguita2013hardataset}, SleepEEG~\citep{kemp2000sleepeegdataset}. We ensure that test sets used for evaluation in Section \ref{sec:experiments} are not part of the pre-training dataset. The total pre-training consists of 7 million time series examples. We pre-trained the model for 100 epochs with a batch size equal to 2048 on 4 NVIDIA Tesla V100-32GB GPUs.

\subsection{Adapters}
\label{sec:adapters}

Nowadays, the multivariate setting represents one of the main challenges for time series foundation models. In practice, different time series classification tasks vary in the number of channels, which raises non-trivial questions on how the model should be pre-trained and applied for a new task. Similarly to other foundation models \citep{goswami2024moment,lin2024nutime}, Mantis is pre-trained in a univariate way and can be applied to the multivariate setting by treating each channel independently. However, this strategy has several limitations. Firstly, the foundation models are heavy by design, so treating all channels independently may lead to excessive resource consumption and failure to fine-tune them. Secondly, at the feature extraction step, the channel correlations are ignored, which may lead to the loss of some important information. 

To address these concerns, we study a simple approach of using a channel-level adapter $a: \R^{d} \to \R^{d_{\text{new}}}$ that precedes the foundation model and transforms the original $d$ channels into new $d_{\text{new}}$ ones. While there are other ways to adapt foundation models to the multivariate setting \citep{zhang2023crossformer,zhou2023onefitsall}, we consider this definition of an adapter
due to its high flexibility: (a) not only Mantis but any foundation model
can be plugged in, (b) channel-level transformation prevents from disrupting the temporal structure, (c) adaptation to the computation budget by determining the number
of encoded channels. 
% Below, we present five adapters that we considered in our experiments.

In our experiments, we considered five adapters that we present further. Our idea was to test classical dimension reduction approaches like Principal Component Analysis (PCA) that are computationally efficient and are trained in an unsupervised way. However, their application is limited to 2D data matrices, making them not straightforward to use in our case. To overcome this problem, we train the dimension reduction method on the data reshaped to $(n\times t,\ d)$, where $n$ is the number of training examples. Thus, with this trick, methods like PCA will be focused on correlations between channels over all time steps, capturing spatial correlations and learning the rotation matrix $W \in \R^{d_{\text{new}}\times d}$  that linearly combines the original channels into new ones. Overall, these four adapters rely on this strategy:
\begin{itemize}
    \item \textit{Principal Component Analysis} (\textit{PCA}) seeks to find an orthogonal basis of principal components where few components capture most of the data variance.
    
    \item \textit{Truncated Singular Value Decomposition} (\textit{SVD}, \citeauthor{halko2009truncatedsvd}, \citeyear{halko2009truncatedsvd}) is similar to PCA, but it applies SVD decomposition directly on the non-centered data matrix.

   \item \textit{Random Projection (Rand Proj)} is a very simple baseline that projects data by randomly generating the rotation matrix $W \in \R^{d_{\text{new}}\times d}$.

   \item \textit{Variance-Based Channel Selection (Var Selector)} is a feature selection method that selects channels with the highest variance. This approach can be useful when channels with low variance are not very informative, so they can be discarded without affecting the overall performance.
\end{itemize}

% The multivariate setting presents a significant
% challenge for time series FMs, as different tasks involve
% varying numbers of channels1
% . To the best of our knowledge,
% the only model that naturally accommodates any number of
% channels is Moirai (Liu et al., 2024), which, however, suffers from high computational demand due to processing all
% channels flattened in the transformer simultaneously, leading to a quadratic memory complexity w.r.t. to the number
% of channels. Most foundation models, instead, treat each one
% of these independently, which, as noted by Feofanov et al.
% (2024), remains computationally expensive when full finetuning is required. For classification tasks with hundreds
% or thousands of features, they demonstrated that simple
% adapters like the rotation matrix obtained through Principal Components Analysis (PCA) mitigate this issue. At the
% same time, Benechehab et al. (2025) showed that PCA preserves channel interactions by learning new disentangled
% components.


% \textbf{Principal Component Analysis} (\textbf{PCA}) seeks to find an orthogonal basis of principal components where few components capture most of the data variance. Applying PCA to 3D matrices $(N, T, D)$ poses challenges. A common approach reshapes the data into $(N, T \times D)$ and projects it to $(N, T \times D')$, but this disrupts the temporal structure. Additionally, when $N \ll T \times D$, PCA can become computationally unstable. To address this, we reshape the data to $(N \times T, D)$, allowing PCA to focus on correlations between channels over all time steps, effectively capturing spatial correlations while preserving temporal information. The learned rotation matrix $W \in \mathbb{R}^{D' \times D}$ linearly combines the original channels into a lower-dimensional space, applied consistently across all time steps.

% \textbf{Truncated Singular Value Decomposition} (\textbf{SVD}, \citeauthor{halko2009truncatedsvd}, \citeyear{halko2009truncatedsvd}) similarly reduces dimensionality by retaining the most significant components. Unlike PCA, SVD operates directly on the data matrix without centering it, decomposing it into its top $k$ singular values and vectors. This method effectively captures the principal directions of variance.

% \textbf{Random Projection (Rand Proj)} is a very simple baseline that projects data by randomly generating the rotation matrix $W \in \mathbb{R}^{D' \times D}$
% onto a lower-dimensional subspace using. Unlike PCA, it does not aim to capture the most variance but instead focuses on providing a quick dimensionality reduction solution with minimal computational cost.

% \textbf{Variance-Based Channel Selection (Var Selector)} is a simple but effective method that selects features with the highest variance. Features with low variance are considered less informative and can be discarded without significantly affecting the overall representation of the data.

Although these adapters are computationally very efficient,
they are not supervised meaning that they may lead to suboptimal classification performance. Following this reasoning, we introduce one more adapter: 
\begin{itemize}
    \item \textit{Differentiable Linear Combiner} (\textit{LComb}) performs a linear channel transformation $W \in \mathbb{R}^{D' \times D}$, which, unlike to previous adapters, is learned via backpropagation together with the encoder and classification head.
\end{itemize}


\section{Experimental Results}
\label{sec:experiments}
In this section, we conduct a set of experiments to validate the high performance of our model. All our experiments have been performed on a single NVIDIA Tesla V100-32GB GPU.
\subsection{Setup}
\label{sec:exp-setup}
\paragraph{Baselines.} 
% While TSFMs for time series forecasting are abundant \citep{ansari2024chronos,liu2024moirai,das2023decoder,rasul2023lagllama,wang2024rose,woo2024moirai,bhethanabhotla2024mamba4cast,chang2023llm4ts,gruver2024large,xue2023promptcast,cao2023tempo,jin2023time}, contributions covering the classification task remain rather scarce. 
In our experiments, we compare Mantis with the State-of-the-Art (SOTA) time series classification foundation modeling. More specifically, these are the four following  foundation models, whose implementation details can be found in Appendix~\ref{sec:appendix-exp-setup}:
\begin{itemize}
    \item UniTS~\citep{gao2024units} is a multi-task time series model that can be also considered as a foundation model with 1 million parameters. We use their checkpoint pre-trained in a supervised fashion on 18 datasets.
    \item GPT4TS~\citep{zhou2023onefitsall} is a method that 
    partially fine-tunes a pre-trained GPT2 with an additional tokenization layer to perform different time series tasks including classification, anomaly detection, and forecasting. The total number of parameters is approximately 80 millions (10x larger than Mantis).
    \item NuTime~\citep{lin2024nutime} is a transformer-based TSFM for classification. Their pre-training dataset is very similar to the one we used, and the size of their model is smaller, containing approximately 2 million parameters.
    \item MOMENT~\citep{goswami2024moment} is a TSFM based on the T5 architecture~\citep{raffel2020exploring} that has been pre-trained to cover different time series tasks including classification, anomaly detection, and forecasting. In total, MOMENT has 385 million parameters (approx. 48x larger than Mantis) and the pre-training dataset contained 1.13 billion samples.
\end{itemize}
% Among them, we note GPT4TS \citep{zhou2023onefitsall} that proposed to n. Other most prominent contributions that proceed by learning a TSFM applicable to time series classification from scratch are MOMENT  and UniTS \citep{gao2024units}.  
% In what follows, we will compare to the three TSFMs mentioned above, namely GPT4TS, MOMENT, and UniTS following the experimental setups provided by the corresponding papers. 

\paragraph{Datasets.} We use the following datasets to evaluate the performance of Mantis and compare it to other methods: 
\begin{itemize}
    \item UCR~\citep{dau2019ucr} that consists of 128 single-channel datasets.
    \item UEA~\citep{bagnall2018uea} that has 30 multi-channel datasets. We exclude 3 datasets due to small test size or small sequence length, and subsample one dataset to ease computations (see more details in Appendix \ref{sec:appendix-exp-setup}). We further tag the remaining 27 datasets by \texttt{UEA-27}.
    \item 4 additional datasets used by \citet{gao2024units}:  Blink~\citep{chicaiza2021blink}, MotionSenseHAR~\citep{malekzadeh2019motionsensehar}, EMOPain~\citep{egede2020emopain}, SharePriceIncrease~\citep{middlehurst2024bakeoff}.
\end{itemize}

\paragraph{Experiments.}
We have performed five different kinds of experiments, which we will briefly describe below. For all experiments except for the adapters, Mantis handles the multivariate case by sending all channels to the encoder independently.
\begin{enumerate}
    \item \textit{Zero-shot feature extraction.} In this experiment, we test the ability of Mantis to generate powerful embeddings without fine-tuning. For each downstream task, we extract features using the foundation model and then use them together with the training labels to learn a classifier. We use all considered datasets: the whole UCR collection, \texttt{UEA-27}, and 4 datasets from \citet{gao2024units}, which results in 159 datasets (further denoted by \texttt{159-D}).
    \item \textit{Fine-tuning with model selection.}
    For this experiment, we compare different foundation models when they are fine-tuned to a given downstream task. For each task, we use 80\% of the original training set to fine-tune models and the rest 20\% as a validation set to choose training hyperparameters. As we have fixed the batch size for all the considered methods, some methods did not fit a single GPU memory either due to the number of channels or the sequence length. This is why we removed from the results 15 datasets from UCR, 11 datasets from UEA, EMOPain, and MotionSenseHAR (see more details in Appendix~\ref{sec:appendix-exp-setup}), so in total, we evaluate on 131 datasets (further tagged by \texttt{131-D}).
    \item \textit{Ablation study.} In this experiment, we analyze the influence of different parts of the proposed methodology on the performance of Mantis. First, we show the advantage of extracting features from the time series' differential for zero-shot extraction. Then, we analyze the influence of pre-training, fine-tuning, and model selection on the performance. We consider all the datasets except those with a large number of channels: 7 datasets from UEA and EMOPain. In total, it results in 151 datasets (further denoted by \texttt{151-D}).
    \item \textit{Adapters.} We perform a comparative study of different adapters that extend Mantis to the large-dimensional case. In this experiment, consider all the \texttt{UEA-27} datasets described before.
    \item \textit{Calibration.} Finally, we compare Mantis with other foundation models in terms of calibration of their predicted probabilities. We take the same experimental setup as for the \textit{fine-tuning with model selection} experiment and, for each model, report the Expected Calibration Error (ECE, \citeauthor{naeini2015obtaining}, \citeyear{naeini2015obtaining}) before and after applying post-hoc calibration methods.   
\end{enumerate}

\subsection{Comparison with SOTA: Zero-shot Feature Extraction}
\label{sec:sota-zero-shot}

In this section, we use a time series foundation model as a feature extractor without fine-tuning it to a given downstream task. First, we generate embeddings for time series observations by passing them through the frozen encoder. Then, we use embeddings as new features to train a classifier and report its performance on test data. As a classifier, we have chosen the Random Forest algorithm~\citep{breiman2001random} due to its versatility and high performance without the need to perform hyperparameter searching. We fixed the number of trees to 200 while not restricting the maximum tree depth. In this section, we compare Mantis with NuTime and MOMENT while removing GPT4TS and UniTS from consideration as they have not provided a methodology for zero-shot extraction. 

% \vspace{0.5cm}
% \begin{figure}[htbp]
%         \centering
%         \includegraphics[height=0.25\textheight]{pics/159-d-zeroshot-perf-results.pdf}
%     \caption{Comparison with the State-of-the-Art in the case of zero-shot feature extraction. The accuracy averaged over 3 random seeds and over \texttt{159-D} datasets.}
%     \label{fig:zeroshot-sota}
% \end{figure}
% \vspace{0.5cm}
\setlength{\intextsep}{-5pt}%
\setlength{\columnsep}{10pt}%
\begin{wrapfigure}[18]{r}{0.4\textwidth}
\centering
\vspace{-0.21cm}
\includegraphics[height=0.25\textheight, clip=True, trim=0 0.5cm 0 0]{pics/159-d-zeroshot-perf-results.pdf}
    \caption{Zero-shot feature extraction: comparison with the SOTA. The accuracy is averaged over 3 random seeds and over \texttt{159-D} datasets.}
    \label{fig:zeroshot-sota}
\end{wrapfigure}
Figure \ref{fig:zeroshot-sota} displays the performance results averaged over 159 datasets (\texttt{159-D}), while the complete results can be found in Appendix, Table~\ref{tab:zeroshot-sota}. We can see that on average Mantis outperforms NuTime and MOMENT by 1.77\% and 1.53\%, respectively. Mantis is the best on 74 datasets, while MOMENT and NuTime have the best performance on 53 and 38 datasets, respectively. Compared to other foundation models, we can see that Mantis achieves the best balance in terms of the complexity of the model and its accuracy. On the one hand, Mantis outperforms a smaller model, NuTime, by increasing the encoder's capacity and leveraging more information from the pre-training set. On the other hand, a much bigger model, MOMENT, with 385 million parameters does not manage to achieve a better performance despite its size. 

In addition, comparing models in terms of running time, we notice that the forward pass of MOMENT is noticeably slower, which is especially pronounced with a large number of channels. To illustrate this observation, Figure~\ref{fig:runtime-rf} depicts the running time of Mantis and MOMENT on datasets from \texttt{UEA-27}. One can see that the inference time of MOMENT greatly increases with the dataset size.

\vspace{0.5cm}
\begin{figure}[hbp]
    \centering
    \includegraphics[width=0.95\textwidth, clip=True, trim=2cm 0 0 1cm]{pics/run-time-rf.pdf}
    \caption{The running time of MOMENT and Mantis on the \texttt{UEA-27} collection of datasets. For better visualization, we sort and split the datasets into two clusters based on the reported running time.}
    \label{fig:runtime-rf}
\end{figure}
\vspace{0.5cm}

\subsection{Comparison with SOTA: Fine-tuning}
\label{sec:sota-fine-tuning}

\setlength{\intextsep}{-5pt}%
\setlength{\columnsep}{10pt}%
\begin{wrapfigure}[15]{r}{0.5\textwidth}
\centering    
\vspace{-0.55cm}
\includegraphics[width=0.48\textwidth, clip=True, trim=0 0.5cm 0 0]{pics/131-d-finetuning-perf-results.pdf}
\caption{Model fine-tuning: comparison with the SOTA. The accuracy is averaged over
3 random seeds and over \texttt{131-D} datasets.}
\label{fig:sota-fine-tuning}
\end{wrapfigure}
In this experiment, we perform a comparison by fine-tuning foundation models to a downstream task. More specifically, we append a prediction head after an encoder and fine-tune all layers or a subset of them on the training data. For all models under consideration, we fix a fine-tuning scheme: we minimize the cross-entropy loss for 100 epochs with a fixed batch size equal to 256, using an AdamW optimizer~\citep{loshchilov2017fixing} with a weight decay of 0.05. For each model and each dataset, We choose a learning rate over the grid: $\{10^{-4}, 2\cdot10^{-4}, 10^{-3}\}$ based on the validation set. For GPT4TS, we follow their paper and fine-tune the layers of the language backbone specified by the authors. For Mantis, NuTime, MOMENT, and UniTS, we perform fine-tuning of all the layers.

    % All foundation models are trained for 100 epochs, and we do not perform epoch selection or early stopping. The batch size is set to 256. The optimizer is AdamW~\citep{loshchilov2017fixing}, with a weight decay of 0.05. The pretrained weights are loaded before training, and 
    % unfrozen, apart from the weights of the language model for GPT4TS. We use the following model hypermparameters:
    



% \vspace{0.5cm}
% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.5\textwidth]{pics/131-d-finetuning-perf-results.pdf}
%     \caption{Comparison with the State-of-the-Art in the case of model fine-tuning. The accuracy is averaged over
% 3 random seeds and over \texttt{131-D} datasets.}
%     \label{fig:sota-fine-tuning}
% \end{figure}
% \vspace{0.5cm}
In Figure \ref{fig:sota-fine-tuning}, we illustrate the performance results averaged over 131 datasets (\texttt{131-D}). In Appendix, Table \ref{tab:sota-fine-tuning}, we display the experimental results for every dataset. One can see that Mantis has the highest performance among all the considered foundation models. We note that the reported performance results of our competitors may diverge from those reported by the authors of these models. This may be explained by the difference in the chosen fine-tuning scheme. In our case, we have fixed the scheme for a fair comparison while trying to find the best learning rate for every model based on a validation set. Thus, our experimental results reveal that Mantis is the most robust to the choice of a fine-tuning scheme and does not necessarily require tedious hyperparameter searching. We additionally validate this argument in the next section by fine-tuning Mantis without any model selection.

\subsection{Ablation Study} 
\label{sec:ablation-study}

\setlength{\intextsep}{-5pt}%
\setlength{\columnsep}{10pt}%
\begin{wrapfigure}[18]{r}{0.35\textwidth}
\centering
\includegraphics[height=0.25\textheight, clip=True, trim=0 0 0 0]{pics/159-d-ablation-perf-results.pdf}
\caption{Mantis w/ and w/o the differential block. The accuracy is averaged over 3 random seeds and over \texttt{159-D} datasets.}
\label{fig:zeroshot-ablation}
\end{wrapfigure}
In this section, we perform several ablation experiments for a more thorough analysis of Mantis. First, we validate some of our architecture choices. More specifically, we test whether the incorporation of features extracted from the differential of a time series, proposed in Section \ref{sec:architecture}, improves the quality of embeddings. For this, we have pre-trained another version of our foundation model where the differential feature extraction part was removed from the Token Generator Unit. In Figure~\ref{fig:zeroshot-ablation}, we plot the average zero-shot feature extraction performance of the two versions of Mantis, while the complete results may be found in Appendix, Table~\ref{tab:ablation-diff}. One can see that the incorporation of the differential block noticeably improves the accuracy score. When comparing Figure~\ref{fig:zeroshot-sota} and Figure~\ref{fig:zeroshot-ablation}, it is interesting to notice that Mantis without the differential block still slightly outperforms NuTime and MOMENT in the case of zero-shot feature extraction.

% \vspace{0.5cm}
% \begin{figure}[ht!]    
%     \centering
%     \includegraphics[height=0.25\textheight, clip=True, trim=0 0 0 0]{pics/159-d-ablation-perf-results.pdf}
%     \caption{Ablation study to identify if the proposed the differential block of the Token Generator Unit improves zero-shot feature extraction performance. The reported accuracy score is computed in average over 3 random seeds over 159 datasets from the \texttt{159-D} benchmark.}
%     \label{fig:zeroshot-ablation}
% \end{figure}
% \vspace{0.5cm}

In the second part of our ablation study, we raise the following questions: 
% When it comes to applying Mantis or any other foundation model to a downstream task, multiple questions are raised: 
(a) is pre-training really useful, or it is sufficient to train Mantis from scratch on each dataset?, (b) should we fine-tune the head or the whole model?, (c) can Mantis be fine-tuned with default hyperparameters, and how much we can gain from the model selection? To answer these questions, we empirically compare the following fine-tuning regimes:
\begin{itemize}
    \item The setup which we further call RF, and which we used for the zero-shot feature extraction experiment: the encoder of Mantis is frozen, and embeddings are used as features to train a Random Forest classifier.
    \item The encoder of Mantis is frozen, and the task is solved by fine-tuning a classification head, which, in our case, is layer normalization step + linear layer. The purpose of comparing this strategy, further called \texttt{Head}, with \texttt{RF} is to see the impact of the choice of a classifier (linear vs non-linear, differentiable vs non-differentiable) on the overall performance.
    \item The encoder is randomly initialized and fine-tuned together with a classification head. This baseline, which we further call \texttt{Scratch}, is introduced to see whether or not pre-training of Mantis is useful.
    \item Finally, the strategy further called \texttt{Full} consists in fine-tuning the pre-trained encoder together with a classification head.
\end{itemize}
In order to answer question (c), for every method, we report two scores: the test accuracy of the model at the last epoch (i.e., at the end of fine-tuning), and the best test accuracy of the model across all fine-tuning epochs. While the last epoch score gives a pessimistic evaluation of the performance as no model selection is performed, the best epoch score is an optimistic evaluation as it indicates the best achievable performance. In this experiment, we fix the fine-tuning scheme: the number of epochs is 100, the batch size is 256, the optimizer is AdamW with the weight decay of 0.05 and the learning rate set to $2\cdot10^{-4}$ and adjusted following the cosine annealing decay strategy~\citep{loshchilov2016sgdr} with 10 warm-up epochs.

% \vspace{0.5cm}

Figure \ref{fig:fine-tuning-ablation} depicts the average performance over the \texttt{151-D} benchmark both for the last and best epoch, while the complete results can be found in Appendix, Table~\ref{tab:last-epoch-res} and Table~\ref{tab:best-epoch-res}.
First, we can see that the pre-training of Mantis is visibly useful as \texttt{Full} outperforms \texttt{Scratch} by 5.08\% and 3.92\% in the last and best epoch score, respectively. On the other hand, using a frozen pre-trained encoder is rather suboptimal in terms of performance, and full fine-tuning is preferred. This observation points out an important direction of future work, namely, to advance time series classification foundation models in terms of zero-shot performance.

\begin{figure}[t]
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{pics/151d-perf-results-fine-tuning-last.pdf}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.5\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{pics/151d-perf-results-fine-tuning-best.pdf}
    \end{subfigure}
    \caption{Performance of different fine-tuning methods for Mantis averaged over 3 random seeds and 151 datasets of the \texttt{151-D} benchmark.}
    \label{fig:fine-tuning-ablation}
\end{figure}
% \vspace{0.5cm}


\setlength{\intextsep}{-5pt}%
\setlength{\columnsep}{10pt}%
\begin{wrapfigure}[16]{r}{0.25\textwidth}
% \vspace{-0.8cm}
\centering
\includegraphics[width=0.21\textwidth, clip=True, trim=0 0.3cm 0 0]{pics/uea-27-perf-results-best.pdf}
\caption{Mantis: zero-shot vs full fine-tuning with the best adapter per dataset.}
\label{fig:rf-vs-best-adapter}
\end{wrapfigure}
Another observation from Figure \ref{fig:fine-tuning-ablation} is that fine-tuning the head with a frozen encoder may be suboptimal, and training a Random Forest on embeddings gives a slightly better accuracy score. Finally, by comparing the performance results for the last and best epoch, we conclude that although model selection is important to improve the overall performance (+1.89\% for \texttt{Full}), using directly the model from the last epoch gives already good performance. This shows that Mantis can be applied in practice without the need to tediously search for optimal values of hyperparameters.

% As classification task requires to specify the output classes that vary across the datasets, existing TSFMs rely on fine-tuning to provide predictions on previously unseen datasets. GPT4TS does so by adding a head with the desired number of classes and fine-tunes an encoding embedding together with positional embedding and layer norms of the GPT backbone. MOMENT extracts the embeddings from the pre-trained model to further use them as an input of an SVM classifier together with the available labelled data. Finally, UniTS is fine-tuned in a multi-task way on all available datasets from a model pre-trained in a self-supervised way. These differences in fine-tuning strategies mean that we cannot evaluate all TSFMs in a homogeneous way. We then choose to compare GPT4TS, MOMENT, and UniTS to Mantis using the corresponding evaluation protocols of these works as follows:
% \begin{enumerate}
%     \item Fully fine-tuned Mantis is compared to GPT4TS and UniTS
%     \item Performance of a random forest classifier trained on the embeddings extracted from the pre-trained Mantis model is used to compare Mantis and MOMENT 
% \end{enumerate}





% Finally, we note that MOMENT was evaluated only on UCR datasets having a length shorter than 512. UniTS was compared to GPT4TS on 8 UEA datasets complemented with 4 datasets mentioned above. For fair comparison, we use their evaluation setup and report the results for each baseline separately. 
%For UEA, we do not consider AtrialFibrillation and StandWalkJump datasets due to their very small test size, PenDigits due to its very small sequence length. 







% \subsection{Comparison with Other Methods}


% \begingroup
% \setlength{\tabcolsep}{2pt} % Default value: 6pt
% % \renewcommand{\arraystretch}{1.5} % Default value: 1
% \newcommand{\fontscale}{0.8}
% \begin{table}[ht!]
% \caption{The performance comparison of different methods on 18 benchmarks following \citet{gao2024units}. The bold face and the underline highlight the highest and second highest accuracy, respectively.}
% \scalebox{0.8}{
% \begin{tabular}{c|ccccccccccc}
% \toprule
% dataset                    & \scalebox{\fontscale}{iTransformer} & \scalebox{\fontscale}{TimesNet} & \scalebox{\fontscale}{PatchTST} & \scalebox{\fontscale}{Pyraformer} & \scalebox{\fontscale}{Autoformer} & \scalebox{\fontscale}{UniTS-SUP} & \scalebox{\fontscale}{UniTS-PMT} & \scalebox{\fontscale}{GPT4TS} & \scalebox{\fontscale}{Moment-RF} & \scalebox{\fontscale}{Mantis-RF} & \scalebox{\fontscale}{Mantis-Full} \\
% \midrule
% Heartbeat                  & 0.668        & 0.727    & 0.659    & 0.727      & 0.717      & 0.639     & 0.654     & 0.698  & 0.727     & \textbf{0.798}     & \underline{0.795}       \\
% JapaneseVowels             & 0.959        & \underline{0.976}    & 0.941    & 0.854      & 0.941      & 0.922     & 0.903     & 0.946  & 0.88      & 0.963     & \textbf{0.981}       \\
% PEMS-SF                    & 0.832        & 0.775    & 0.838    & 0.832      & 0.792      & 0.832     & 0.827     & 0.792  & \textbf{1.0}         & \underline{0.985}     & 0.911       \\
% SelfRegulationSCP2         & 0.489        & 0.528    & 0.489    & 0.567      & 0.45       & 0.489     & \textbf{0.572}     & 0.456  & 0.496     & 0.476     & \underline{0.569}       \\
% SpokenArabicDigits         & 0.978        & \underline{0.987}    & 0.975    & 0.921      & 0.973      & 0.968     & 0.955     & 0.975  & 0.935     & 0.839     & \textbf{0.993}       \\
% UWaveGestureLibrary        & 0.822        & 0.844    & 0.819    & 0.722      & 0.422      & 0.822     & 0.853     & 0.819  & \underline{0.873}     & 0.814     & \textbf{0.944}       \\
% ECG5000                    & 0.933        & 0.926    & \underline{0.943}    & 0.914      & 0.919      & 0.928     & 0.924     & 0.93   & 0.939    & 0.922     & \textbf{0.947}       \\
% NonInvasiveFetalECGThorax1 & 0.882        & 0.889    & 0.865    & 0.214      & 0.217      & 0.896     & 0.808     & \underline{0.897}  & 0.8926    & 0.62      & \textbf{0.944}       \\
% Blink                      & 0.933        & 0.876    & 0.896    & 0.882      & 0.631      & 0.976     & 0.916     & 0.924  & \underline{0.989}     & \textbf{1.0}         & \textbf{1.0}           \\
% FaceDetection              & 0.66         & \underline{0.662}    & 0.639    & \textbf{0.673}      & 0.592      & 0.654     & 0.58      & 0.661  & 0.544     & 0.527     & 0.606       \\
% ElectricDevices            & 0.573        & 0.495    & 0.595    & 0.654      & 0.561      & 0.622     & 0.624     & 0.629  & 0.713    & \underline{0.72}      & \textbf{0.759}       \\
% Trace                      & 0.79         & 0.91     & 0.77     & 0.74       & 0.6        & 0.96      & \underline{0.99}      & 0.96   & \underline{0.99}      & \textbf{1.0}         & \textbf{1.0}           \\
% FordB                      & 0.727        & 0.689    & 0.614    & 0.553      & 0.664      & 0.759     & \underline{0.78}      & 0.777  & 0.765    & 0.727     & \textbf{0.843}       \\
% MotionSenseHAR             & 0.936        & 0.906    & 0.758    & 0.887      & 0.302      & 0.951     & 0.958     & 0.962  & \underline{0.966}     & \textbf{1.0}         & \textbf{1.0}           \\
% EMOPain                    & 0.794        & 0.78     & 0.792    & 0.814      & 0.699      & 0.797     & 0.814     & 0.794  & \underline{0.854}     & 0.842     & \textbf{0.878}       \\
% Chinatown                  & 0.974        & \underline{0.977}    & \underline{0.977}    & 0.274      & 0.968      & \textbf{0.98}      & \textbf{0.98}      & 0.965  & \underline{0.977}    & 0.883     & 0.974       \\
% MelbournePedestrian        & 0.893        & \underline{0.957}    & 0.804    & 0.523      & 0.75       & 0.876     & 0.839     & 0.94   & 0.87      & 0.898     & \textbf{0.974}       \\
% SharePriceIncrease         & 0.619        & 0.65     & \underline{0.68}     & 0.631      & 0.615      & 0.618     & 0.638     & 0.637  & 0.674     & \textbf{0.687}     & \textbf{0.687}       \\
% \midrule
% Average                    & 0.803        & 0.809    & 0.781    & 0.688      & 0.656      & 0.816     & 0.812     & 0.82   & 0.838     & 0.817     & \textbf{0.878}       \\
% Best Count                 & 0            & 0        & 0        & 1          & 0          & 1         & 2         & 0      & 1         & 5         & 13         \\
% \bottomrule
% \end{tabular}
% }
% \end{table}
% \endgroup






% \subsection{Comparison with UniTS}

% \setlength{\intextsep}{-5pt}%
% \setlength{\columnsep}{10pt}%
% \begin{wrapfigure}[14]{r}{0.4\textwidth}
% \includegraphics[width=0.4\textwidth, clip=True, trim=0 0 0 0]{pics/159-d-zeroshot-perf-results.pdf}
% \caption{Zero-shot performance.}
% \label{fig:zeroshot}
% \end{wrapfigure}




% \setlength{\intextsep}{-5pt}%
% \setlength{\columnsep}{10pt}%
% \begin{wrapfigure}[14]{r}{0.2\textwidth}
% \includegraphics[width=0.2\textwidth, clip=True, trim=0 0 0 0]{pics/uea-moment-vs-mantis-perf-results.pdf}
% \caption{\texttt{SAM} -\texttt{former}}
% \label{fig:uea-moment-vs-mantis}
% \end{wrapfigure}



% \begin{figure}[ht!]
%     \begin{subfigure}{0.5\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{pics/uea-20-perf-results-last.pdf}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}{0.5\textwidth}
%         \centering
%         \includegraphics[width=0.9\textwidth]{pics/uea-20-perf-results-best.pdf}
%     \end{subfigure}
%     \caption{Averaged accuracy of different fine-tuning methods over 20 UEA datasets.}
%     \label{fig:enter-label}
% \end{figure}


\subsection{Adapters}
\label{sec:exp-adapters}


In this section, we study the performance of Mantis when it is combined with one of the adapters we introduced in Section \ref{sec:adapters}. For \texttt{PCA}, \texttt{SVD}, \texttt{Rand\,Proj} and \texttt{Var\,Selector}, the new number of channels is equal to $D'=\min\{D, 10\}$, while for LComb is always fixed to $D'=10$. Table \ref{tab:adapters-perf} depicts the empirical comparison between the adapters and the case when we treat all channels independently (dubbed as \texttt{No\,Adapter}). In addition, Figure \ref{fig:rf-vs-best-adapter} and Table \ref{tab:rf-vs-best-adapter} of the Appendix compare the no-fine-tuning case when Random Forest is used directly after the feature extraction step and the full fine-tuning with the best adapter chosen per dataset. Below, we discuss the experimental results.

\begin{table}[t]
\caption{Performance comparison between different adapters when Mantis is fully-fine-tuned to a multi-channel time series classification task. The \texttt{UEA-27} data collection is considered in this experiment, and the results are averaged over 3 random seeds. The number of selected channels is fixed to be $\leq 10$. \texttt{No\,Adapter} means that all channels are independently fed to the TSFM, and \texttt{NaN} in its performance results marks the cases when the model has not fitted to a single V100-32GB GPU card's memory. Best Result summarizes the performance when the best strategy per dataset is chosen.}
{\scalebox{0.72}{
\begin{tabular}{l| l || l llll l||l}
\toprule
& \multirow{2}{*}{d} & \multirow{2}{*}{\texttt{No Adapter}} & \multicolumn{4}{c}{Standalone Adapter}                                    & Diff. Adapter & \multirow{2}{*}{Best Result} 
\vspace{-0.2cm}
\\
& &  & \multicolumn{4}{l}{\rule{9.2cm}{0.4pt}} & \rule{2.3cm}{0.4pt}   \\
& &                             & \texttt{PCA}              & \texttt{SVD}              & \texttt{Rand Proj}         & \texttt{Var Selector}     & \texttt{LComb}                  &                              \\
\midrule
ArticularyWordRecognition & 9 & \textbf{0.9933}$_{\pm 0.0}$    & 0.9922$_{\pm 0.0019}$ & 0.9878$_{\pm 0.0038}$ & 0.9811$_{\pm 0.0038}$ & \textbf{0.9933}$_{\pm 0.0}$    &  0.9744$_{\pm 0.0069}$    & 0.9933$_{\pm 0.0}$    \\
BasicMotions  & 6            & \textbf{1.0}$_{\pm 0.0}$       & \textbf{1.0}$_{\pm 0.0}$       & \textbf{1.0}$_{\pm 0.0}$       & \textbf{1.0}$_{\pm 0.0}$       & \textbf{1.0}$_{\pm 0.0}$       & \textbf{1.0}$_{\pm 0.0}$       & 1.0$_{\pm 0.0}$       \\
CharacterTrajectories & 3    & 0.9928$_{\pm 0.0004}$ & \textbf{0.9947}$_{\pm 0.0004}$ & 0.9923$_{\pm 0.0012}$ & 0.9912$_{\pm 0.0016}$ & 0.9928$_{\pm 0.0004}$ & 0.993$_{\pm 0.0018}$ & 0.9947$_{\pm 0.0004}$ \\
Cricket        & 6           & \textbf{1.0}$_{\pm 0.0}$       & 0.9861$_{\pm 0.0}$    & 0.9769$_{\pm 0.008}$  & 0.9722$_{\pm 0.0}$    & \textbf{1.0}$_{\pm 0.0}$       & 0.9907$_{\pm 0.008}$  & 1.0$_{\pm 0.0}$       \\
DuckDuckGeese      & 1345       & \texttt{NaN}       & 0.5733$_{\pm 0.0115}$ & \textbf{0.6}$_{\pm 0.02}$      & 0.54$_{\pm 0.0872}$   & 0.5133$_{\pm 0.0231}$ & 0.54$_{\pm 0.0693}$ & 0.6$_{\pm 0.02}$      \\
ERing         & 4            & \textbf{0.9926}$_{\pm 0.0074}$ & 0.9778$_{\pm 0.0064}$ & 0.9753$_{\pm 0.0113}$ & 0.9642$_{\pm 0.0043}$ & \textbf{0.9926}$_{\pm 0.0074}$ & 0.9778$_{\pm 0.0064}$ & 0.9926$_{\pm 0.0074}$ \\
EigenWorms      &   6        & 0.8372$_{\pm 0.0044}$ & 0.8448$_{\pm 0.0117}$ & \textbf{0.8601}$_{\pm 0.0192}$ & 0.8117$_{\pm 0.0233}$ & 0.8372$_{\pm 0.0044}$ & 0.8066$_{\pm 0.0384}$ & 0.8601$_{\pm 0.0192}$ \\
Epilepsy        & 3          & \textbf{1.0}$_{\pm 0.0}$       & 0.9976$_{\pm 0.0042}$ & 0.9976$_{\pm 0.0042}$ & 0.9976$_{\pm 0.0042}$ & \textbf{1.0}$_{\pm 0.0}$       & \textbf{1.0}$_{\pm 0.0}$ & 1.0$_{\pm 0.0}$       \\
EthanolConcentration    & 3   & \textbf{0.4208}$_{\pm 0.0195}$ & 0.2928$_{\pm 0.0101}$ & 0.3029$_{\pm 0.0122}$ & 0.384$_{\pm 0.0503}$  & \textbf{0.4208}$_{\pm 0.0195}$ & 0.4081$_{\pm 0.0275}$ & 0.4208$_{\pm 0.0195}$ \\
FaceDetection    & 144         & \texttt{NaN}       & 0.6026$_{\pm 0.0054}$ & 0.6064$_{\pm 0.0037}$ & 0.5638$_{\pm 0.0065}$ & 0.5696$_{\pm 0.0027}$ & \textbf{0.6272}$_{\pm 0.013}$ & 0.6272$_{\pm 0.013}$ \\
FingerMovements     & 28      & \texttt{NaN}       & 0.5833$_{\pm 0.0058}$ & 0.57$_{\pm 0.06}$     & 0.5467$_{\pm 0.0289}$ & \textbf{0.6167}$_{\pm 0.0058}$ & 0.58$_{\pm 0.0265}$ & 0.6167$_{\pm 0.0058}$ \\
HandMovementDirection  & 10    & 0.4009$_{\pm 0.0206}$ & \textbf{0.5135}$_{\pm 0.027}$  & 0.482$_{\pm 0.0546}$  & 0.4279$_{\pm 0.0512}$ & 0.4009$_{\pm 0.0206}$ & 0.4414$_{\pm 0.0624}$ & 0.5135$_{\pm 0.027}$  \\
Handwriting       &  3        & 0.482$_{\pm 0.0157}$  & 0.4529$_{\pm 0.0129}$ & 0.4588$_{\pm 0.0224}$ & 0.4235$_{\pm 0.0418}$ & 0.482$_{\pm 0.0157}$  & \textbf{0.5839}$_{\pm 0.0283}$ & 0.5839$_{\pm 0.0283}$  \\
Heartbeat        & 61         & \texttt{NaN}       & 0.7561$_{\pm 0.0098}$ & 0.7626$_{\pm 0.0123}$ & 0.7707$_{\pm 0.0098}$ & \textbf{0.7951}$_{\pm 0.0129}$ & 0.774$_{\pm 0.0123}$ & 0.7951$_{\pm 0.0129}$ \\
InsectWingbeatSubset   & 200   & \texttt{NaN}       & 0.4703$_{\pm 0.0051}$ & 0.4733$_{\pm 0.0127}$ & 0.4803$_{\pm 0.0302}$ & \textbf{0.591}$_{\pm 0.005}$   & 0.236$_{\pm 0.0125}$  & 0.591$_{\pm 0.005}$   \\
JapaneseVowels    & 12        & \textbf{0.9811}$_{\pm 0.0054}$ & 0.9802$_{\pm 0.0031}$ & \textbf{0.9811}$_{\pm 0.0}$    & 0.9577$_{\pm 0.0271}$ & 0.9784$_{\pm 0.0047}$ & 0.9577$_{\pm 0.0128}$  & 0.9811$_{\pm 0.0054}$ \\
LSST           & 6           & \textbf{0.7109}$_{\pm 0.0015}$ & 0.6795$_{\pm 0.0027}$ & 0.6894$_{\pm 0.0021}$ & 0.6929$_{\pm 0.0207}$ & \textbf{0.7109}$_{\pm 0.0015}$ & 0.6941$_{\pm 0.0053}$ & 0.7109$_{\pm 0.0015}$ \\
Libras          & 2          & 0.9389$_{\pm 0.0}$    & 0.937$_{\pm 0.0032}$  & 0.9481$_{\pm 0.0064}$ & 0.8111$_{\pm 0.1392}$ & 0.9389$_{\pm 0.0}$    & \textbf{0.9704}$_{\pm 0.0032}$  & 0.9704$_{\pm 0.0032}$ \\
MotorImagery       & 64       & \texttt{NaN}       & 0.5933$_{\pm 0.0351}$ & 0.5833$_{\pm 0.0208}$ & 0.5867$_{\pm 0.0379}$ & \textbf{0.6}$_{\pm 0.01}$      & 0.59$_{\pm 0.0173}$ & 0.6$_{\pm 0.01}$      \\
NATOPS           & 24         & 0.937$_{\pm 0.0116}$  & 0.9537$_{\pm 0.0064}$ & \textbf{0.9611}$_{\pm 0.0}$    & 0.8926$_{\pm 0.0032}$ & 0.8981$_{\pm 0.0116}$ & 0.8796$_{\pm 0.017}$ & 0.9611$_{\pm 0.0}$    \\
PEMS-SF        & 963           & \texttt{NaN}       & 0.8536$_{\pm 0.0067}$ & 0.8304$_{\pm 0.0145}$ & 0.7457$_{\pm 0.0473}$ & \textbf{0.9114}$_{\pm 0.0067}$ & 0.7476$_{\pm 0.0219}$ & 0.9114$_{\pm 0.0067}$ \\
PhonemeSpectra    & 11        & 0.3421$_{\pm 0.0023}$ & 0.3351$_{\pm 0.009}$  & 0.3215$_{\pm 0.0052}$ & 0.3492$_{\pm 0.0033}$ & 0.344$_{\pm 0.0052}$  & \textbf{0.3547}$_{\pm 0.0047}$ & 0.3547$_{\pm 0.0047}$ \\
RacketSports      & 6        & \textbf{0.9408}$_{\pm 0.0}$    & 0.9123$_{\pm 0.0152}$ & 0.9101$_{\pm 0.0076}$ & 0.9167$_{\pm 0.0038}$ & \textbf{0.9408}$_{\pm 0.0}$    & 0.9254$_{\pm 0.0038}$ & 0.9408$_{\pm 0.0}$    \\
SelfRegulationSCP1    & 6     & 0.9135$_{\pm 0.0071}$ & \textbf{0.917}$_{\pm 0.0052}$  & 0.9113$_{\pm 0.0034}$ & 0.9135$_{\pm 0.0079}$ & 0.9135$_{\pm 0.0071}$ & 0.901$_{\pm 0.009}$ & 0.917$_{\pm 0.0052}$ \\
SelfRegulationSCP2  & 7      & 0.5389$_{\pm 0.0096}$ & 0.5648$_{\pm 0.0449}$ & \textbf{0.5685}$_{\pm 0.0251}$ & 0.5611$_{\pm 0.0455}$ & 0.5389$_{\pm 0.0096}$ & 0.5482$_{\pm 0.021}$   & 0.5685$_{\pm 0.0251}$ \\
SpokenArabicDigits   & 13     & 0.987$_{\pm 0.0009}$  & \textbf{0.9933}$_{\pm 0.0014}$ & 0.9906$_{\pm 0.0019}$ & 0.988$_{\pm 0.0027}$  & 0.9864$_{\pm 0.0028}$ & 0.9882$_{\pm 0.0016}$ & 0.9933$_{\pm 0.0014}$ \\
UWaveGestureLibrary    & 3   & \textbf{0.9438}$_{\pm 0.0108}$ & 0.8583$_{\pm 0.0079}$ & 0.8552$_{\pm 0.0095}$ & 0.8635$_{\pm 0.0737}$ & \textbf{0.9438}$_{\pm 0.0108}$ & 0.9177$_{\pm 0.0048}$ & 0.9438$_{\pm 0.0108}$ \\
% \midrule
% \textit{\textbf{Best Count}} & & 10 \textbf{109} \\
\bottomrule
\end{tabular}
}}
\label{tab:adapters-perf}
\end{table}


% \begin{itemize}
    % \item 
    
    \textit{Dimension reduction:} When the number of channels is too large, the full fine-tuning of the foundation model is limited as treating all channels independently is computationally costly. In Table \ref{tab:adapters-perf}, one can see that starting from 28 channels and the batch size fixed to 256, the optimization of Mantis does not fit the memory of a single V100-32GB GPU card, which results in 7 \texttt{NaN} values in the \texttt{No\,Adapter} column. Nevertheless, applying one of the five adapters solves the issue, allowing the full fine-tuning and increasing the performance as can be seen in Table \ref{tab:rf-vs-best-adapter}.
    % \item 
    
    \textit{Channel interactions:} Another advantage of adapters is that they mix the original channels allowing channels to interact before they are sent to the encoder. The utility of adapters from this perspective was shown by \citet{benechehab2024zero} for zero-shot multivariate forecasting. Our experiments reveal that, in the classification context, conclusions are rather dataset-dependent: while for datasets like RacketSports and UWaveGestureLibrary, adapters do not bring any improvement compared \texttt{No\,Adapter}, transforming the original channels for datasets like Handwriting and HandMovementDirection, nevertheless, brings a large improvement.
    % \item 
    
    \textit{Channel selection:} In some cases certain channels do not contain any useful information, so they can simply be discarded. In such situations, the \texttt{Var\,Selector} has the highest performance, which we can observe on FingerMovements and InsectWingbeat datasets.
    % \item 
    
    \textit{Differentiable adapter:} Although on some datasets, \texttt{LComb} yields high performance, overall, its performance is lower than those of \texttt{PCA}, \texttt{SVD} and \texttt{Var\,Selector}. Since \texttt{LComb} is fine-tuned together with the encoder and the head, we suggest that the optimization of the adapter is intricate, so searching for a better optimization scheme can be a good direction for future work.
    % \item 
    
    % \textit{Application to other foundation models}: In our earlier work~\citep{feofanov2024user}, we have also tried to couple the adapters with MOMENT, demonstrating their compatibility with any time series foundation model.
% \end{itemize}




% \vspace{0.5cm}
% \begin{figure}[ht!]
%         \centering
%         \includegraphics[width=0.25\textwidth]{pics/uea-27-perf-results-best.pdf}
%     \caption{The performance comparison between Mantis in the zero-shot feature extraction setting and when it is fully fine-tuned with or without an adapter, in average over \texttt{UEA-27} datasets. In the second case, the best possible performance per dataset is taken.}
%     \label{fig:rf-vs-best-adapter}
% \end{figure}
% \vspace{0.5cm}

\subsection{Calibration}
\label{sec:exp-calibration}
Uncertainty quantification is crucial when a learning model is part of a safety-critical system~\citep{wang2023calibration} or when its output is used to analyze the performance on test data~\citep{xie2024mano}. Consequently, in this section, we study the calibration properties of Mantis and other time series classification foundation models. We say a model is calibrated if, for a given confidence level $\alpha$, the probability that the model predicts the true class is equal to $\alpha$~\citep{guo2017calibration}:
$$
\mathbb{P}(Y = \hat{y} \,|\, \textrm{conf}(\mbf{X}) = \alpha) = \alpha, \quad \forall \alpha\in[0, 1],
$$
where $\hat{y}$ and $\textrm{conf}(\mbf{X})$ denote the predicted label and model's confidence of a random variable $\mbf{X}$, respectively, which were formally defined in Section~\ref{sec:problem-setup}.
We consider the Expected Calibration Error (ECE, \citeauthor{naeini2015obtaining}, \citeyear{naeini2015obtaining}) as a metric to evaluate the calibration on a test set $\{\mbf{x}_i, y_i\}_{i=1}^n$. We discretize the interval $[0,1]$ into $m$ disjoint bins: $B_j\cap B_k=\emptyset,\ \forall j\neq k, 1 \leq j,k\leq m$ and $\cup_{j=1}^m B_j=[0,1]$. As commonly done in the literature, we split the interval into 10 equally spaced bins. Then, denoting the predicted label for $\mbf{x}_i$ by $\hat{y}_i$, the ECE is defined as follows:
$$
\text{ECE} = \frac{1}{n} \sum_{j=1}^{m} \left| \sum_{\substack{{1\leq i\leq n}\\{\textrm{conf}(\mbf{x}_i)\in B_j }}} \I{\hat{y}_i=y_i}- \textrm{conf}(\mbf{x}_i)\,\right|.
$$

Following the setup in Section \ref{sec:sota-fine-tuning}, we evaluate the ECE before and after applying a \textit{post-hoc} calibration for the five fine-tuned foundation models on 131 datasets from \texttt{131-D}. We use two calibration techniques: (a) Temperature Scaling~\citep{guo2017calibration} that regulates the amplitude of logits before applying softmax, and (b) Isotonic Regression~\citep{zadrozny2002transforming}, a non-parametric method that adjusts predicted probabilities by fitting a piecewise constant function. For the second approach, instead of the classical algorithm, we consider the multi-class isotonic regression (IRM, \citeauthor{zhang2020mix}, \citeyear{zhang2020mix}) as it is shown to be less prone to overfitting. For each dataset, both approaches are fitted using the corresponding validation set (20\% of training data as described in Section \ref{sec:exp-setup}).

In Figure \ref{fig:avg-calibration}, the Expected Calibration Error is displayed for the five foundation models under consideration before and after applying a post-hoc calibration method. We can observe that Mantis without any post-hoc calibration is the most calibrated model on average over 131 datasets, which is an important property for those applications where the number of training examples is not sufficient to construct a hold-out validation set. When posthoc calibration is applied, using either the Isotonic Regression or the Temperature Scaling, all foundation models become significantly better calibrated, yet Mantis remains the most calibrated.

% \vspace{0.5cm}
\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{pics/131-d-finetuning-ece-all-results.pdf}
    \caption{Averaged expected calibrated error of different methods over \texttt{131-D} datasets.}
    \label{fig:avg-calibration}
\end{figure}
\vspace{0.5cm}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{pics/calibration.pdf}
    \caption{The reliability diagram on the test set after \textit{post-hoc} temperature scaling on the validation set, for three different datasets. 
    % All foundation models are fully-finetuned on each dataset. 
    The gray histogram illustrates the distribution of the confidence score across the test set, where the chosen bins are identical to those used to evaluate the ECE.}
    \label{fig:reliability-diagram}
\end{figure}

\section{Conclusion and Future Work}
\setlength{\intextsep}{-5pt}%
\setlength{\columnsep}{10pt}%
\begin{wrapfigure}[14]{r}{0.45\textwidth}
\includegraphics[width=0.43\textwidth, clip=True, trim=0 0.3cm 0 0]{pics/131-d-model-size-acc-comparison.pdf}
\caption{Accuracy vs Model Size.}
\label{fig:sota-fine-tuning-model-size-acc}
\end{wrapfigure}
In this paper, we presented a technical report on Mantis, an \href{https://github.com/vfeofanov/mantis}{open-source}, lightweight foundation model for time series classification. Our experimental results show that Mantis outperforms other foundation models while demonstrating superior calibration. We also introduced an adapter approach that offers a user-friendly solution for practitioners with limited computational resources. However, the results suggest that there is still much work to be done in advancing foundation models. First, we believe that designing foundation models for time series classification is a quite challenging task, as can be seen in Figure~\ref{fig:sota-fine-tuning-model-size-acc}, where there is no clear correlation between model size and overall performance. Second, our results reveal a significant performance gap between the zero-shot feature extraction and full fine-tuning regimes, which indicates that there is still a big room for improvement. Finally, we believe that improving the interpretability of the model output is also an important direction for future work. Specifically, ensuring strong calibration properties of the foundation model 
could enable various applications including uncertainty quantification and unsupervised performance prediction. In our earlier work~\citep{wen2024measuring}, we also demonstrated that the hidden space itself can be performance-predictive when using contrastive pre-training. Thus, exploring Mantis from this perspective could be a promising direction for future work.

\section*{Acknowledgements}

We would like to thank all the members of Paris Noah's Ark Lab including
Youssef Attia El Hili, Ambroise Odonnat, Abdelhakim Benechehab 
% Keli Zhang, Lei Zan, Gabriel Singer, Giuseppe Paolo 
% Bal\'azs K\'egl 
for their constructive comments that helped improve the manuscript.

\bibliography{references}
\bibliographystyle{apalike}


\appendix

\section{Experimental Setup}
\label{sec:appendix-exp-setup}
\subsection{Datasets and Benchmarks}
Below we give more details how datasets were chosen for each benchmark.
\begin{itemize}
    \item \textit{UCR:}
    For some datasets, the sequences are very long, so fine-tuning GPT4TS does not fit the memory. These are the following 15 datasets: EOGHorizontalSignal, EOGVerticalSignal, EthanolLevel, HandOutlines, InlineSkate, MixedShapesRegularTrain, PLAID, PigAirwayPressure, PigArtPressure, PigCVP, SemgHandGenderCh2, SemgHandMovementCh2, SemgHandSubjectCh2, StarLightCurves, and UWaveGestureLibraryAll.
    \item \textit{UEA:}
    We have excluded AtrialFibrillation and StandWalkJump datasets due to their very small test size and PenDigits due to its very small sequence length. For InsectWingbeat dataset, we subsampled 1000 examples from the original training set (which contains 30,000 examples) and 1000 from the original test set (of 20,000 examples) to reduce computational overhead while maintaining sufficient variety in the data for robust model evaluation. The following 7 datasets have a very large number of channels, creating issues with full fine-tuning:  DuckDuckGeese, FaceDetection, FingerMovements, Heartbeat, InsectWingbeat, MotorImagery, and PEMS-SF. In addition, GPT4TS failed to handle long sequences of the following 4 datasets: EigenWorms, EthanolConcentration, SelfRegulationSCP1, and SelfRegulationSCP2.
    \item \textit{Other datasets:}
    EMOPain has a lot of channels making the full fine-tuning costly, while MotionSenseHAR has too long sequences for GPT4TS.
\end{itemize}

To sum up, for Section~\ref{sec:sota-zero-shot} and the first experiment of Section~\ref{sec:ablation-study}, we use all 159 datasets without exceptions; for Section~\ref{sec:sota-fine-tuning} and Section~\ref{sec:exp-calibration}, we exclude all long and high-dimensional datasets, i.e., 15 datasets from UCR, 7+4 datasets from UEA, 2 datasets from the others; for the second experiment of Section~\ref{sec:ablation-study}, we exclude only high-dimensional datasets, i.e., 7 datasets from UEA + EMOPain dataset; finally, for Section~\ref{sec:exp-adapters}, we use all 27 UEA datasets under consideration.

\subsection{Implementation Details}
\begin{itemize}
        % \item \textit{Mantis.} Time Series are rescaled to a sequence length of 512 by interpolation. Channels are processed independently and then final embeddings of each channel are concatenated to form a joint embedding used as input to the classification head. Pretrained weights are taken from \url{https://huggingface.co/paris-noah/Mantis-8M}. Stride and patch size are set to 16. Dimension of the model is 256.
        \item \textit{MOMENT:} 
        We use the MOMENT-large model (\texttt{d\_model}=1024), which pre-trained weights can be found on the corresponding \href{https://huggingface.co/AutonLab/MOMENT-1-large}{HuggingFace} repository.
        % Stride and patch size are set to 8. Hidden dimension of the model is 1024. 
        To handle the multi-channel setup, we process every channel independently and concatenate all the embeddings before passing them to the classification head. In the paper, they have considered datasets with a sequence length $\leq 512$ and use zero-padding to fix the input size to 512. At the same time, we have also tried to interpolate sequences to 512 instead, and it did not affect the performance of MOMENT. Thus, we have decided to stick to the latter option as it allows us to evaluate MOMENT for any sequence length. 
        \item \textit{GPT4TS:} We use the \href{https://github.com/DAMO-DI-ML/NeurIPS2023-One-Fits-All}{code} provided by the authors. As a backbone, the model uses 6 layers from the pre-trained GPT2, which checkpoint can be found on \href{https://huggingface.co/openai-community/gpt2}{HuggingFace}.
        Channels are processed simultaneously as a part of their tokenizer. Stride and patch size are fixed to 8.
        \item \textit{NuTime.} We use the pre-trained weights provided by the authors in their \href{https://github.com/chenguolin/NuTime/blob/main/ckpt/checkpoint_bias9.pth}{GitHub} repository, while fixing the hyperparameters of the architecture according to \href{https://github.com/chenguolin/NuTime/blob/main/configs/demo_ft_epilepsy.json}{this} configuration file. In contrast to the original implementation, we do not use their adapter (described in Section 3.4 of their paper) but process all channels independently as for Mantis and MOMENT. This allows us to use NuTime in the zero-shot feature extraction setting as their adapter has to be fine-tuned.
        \item \textit{UniTS.} We use the implementation and the checkpoint provided the authors at their \href{https://github.com/mims-harvard/UniTS}{GitHub} repository. Similarly to Mantis, MOMENT and NuTime, channels are processed independently. Stride and patch size are set to 16. Dimension of the model is 64.
    \end{itemize}
\section{Complete Results}

Below we provide full tables with experimental results.


\newcommand{\scalefactor}{0.67}

% \begin{table}[ht!]
% \caption{Last Epoch Full Result}
% \begin{minipage}{0.5\textwidth}
% {\scalebox{\scalefactor}{
% \begin{tabular}{l|llll}
% \toprule
%                                & RF                          & Head                        & Scratch                     & Full                        \\
% \midrule
% % Avg                            & 0.7905                           & 0.7747                           & 0.797                            & \textbf{0.8472} \\
% ACSF1                          & 0.59                             & 0.6                              & 0.65                             & \textbf{0.74}   \\
% Adiac                          & 0.734                            & 0.5806                           & 0.7315                           & \textbf{0.8133} \\
% AllGestureWiimoteX             & 0.6714                           & 0.5471                           & 0.6857                           & \textbf{0.7943} \\
% AllGestureWiimoteY             & 0.6729                           & 0.5557                           & 0.7129                           & \textbf{0.7971} \\
% AllGestureWiimoteZ             & 0.6657                           & 0.5414                           & 0.6057                           & \textbf{0.7357} \\
% ArrowHead                      & 0.7143                           & 0.7143                           & 0.7886                           & \textbf{0.8057} \\
% BME                            & 0.9333                           & 0.88                             & 0.98                             & \textbf{1.0}    \\
% Beef                           & 0.6                              & 0.6333                           & 0.7333                           & \textbf{0.7667} \\
% BeetleFly                      & 0.8                              & \textbf{0.9}    & 0.45                             & 0.8                              \\
% BirdChicken                    & \textbf{1.0}    & \textbf{1.0}                              & 0.85                             & \textbf{1.0}                              \\
% CBF                            & 0.9922                           & 0.9933                           & 0.9922                           & \textbf{1.0}    \\
% Car                            & 0.7667                           & 0.8                              & 0.7167                           & \textbf{0.8667} \\
% Chinatown                      & 0.8834                           & 0.8717                           & 0.9504                           & \textbf{0.9708} \\
% ChlorineConcentration          & 0.6794                           & 0.5682                           & 0.7492                           & \textbf{0.7802} \\
% CinCECGTorso                   & 0.6645                           & 0.7225                           & 0.7601                           & \textbf{0.8457} \\
% Coffee                         & 0.9643                           & 0.9643                           & 0.9643                           & \textbf{1.0}    \\
% Computers                      & \textbf{0.748}  & 0.7                              & 0.728                            & 0.724                            \\
% CricketX                       & 0.7256                           & 0.7                              & 0.741                            & \textbf{0.8051} \\
% CricketY                       & 0.7513                           & 0.7026                           & 0.7846                           & \textbf{0.8205} \\
% CricketZ                       & 0.7949                           & 0.741                            & 0.7769                           & \textbf{0.8564} \\
% Crop                           & 0.6738                           & 0.6739                           & 0.7529                           & \textbf{0.7688} \\
% DiatomSizeReduction            & 0.8856                           & 0.8987                           & 0.8922                           & \textbf{0.9314} \\
% DistalPhalanxOutlineAgeGroup   & 0.777                            & \textbf{0.8129} & 0.6763                           & 0.7194                           \\
% DistalPhalanxOutlineCorrect    & 0.7355                           & 0.7645                           & \textbf{0.7717} & 0.7428                           \\
% DistalPhalanxTW                & \textbf{0.6763} & 0.6547                           & 0.6691                           & 0.6619                           \\
% DodgerLoopDay                  & 0.5375                           & 0.5                              & 0.5125                           & \textbf{0.6375} \\
% DodgerLoopGame                 & 0.7391                           & 0.7174                           & 0.7826                           & \textbf{0.9058} \\
% DodgerLoopWeekend              & 0.9565                           & 0.9783                           & \textbf{0.9855} & \textbf{0.9855}                           \\
% ECG200                         & 0.83                             & 0.83                             & 0.81                             & \textbf{0.89}   \\
% ECG5000                        & 0.9222                           & 0.9169                           & 0.9291                           & \textbf{0.9409} \\
% ECGFiveDays                    & 0.8897                           & 0.8479                           & 0.6702                           & \textbf{0.9779} \\
% EOGHorizontalSignal            & 0.5912                           & 0.5691                           & 0.6464                           & \textbf{0.6823} \\
% EOGVerticalSignal              & 0.4751                           & 0.4696                           & 0.5221                           & \textbf{0.5608} \\
% Earthquakes                    & \textbf{0.7482} & \textbf{0.7482}                           & \textbf{0.7482}                           & 0.7266                           \\
% ElectricDevices                & 0.7198                           & 0.7044                           & 0.7208                           & \textbf{0.7453} \\
% EthanolLevel                   & 0.294                            & 0.304                            & \textbf{0.57}   & 0.548                            \\
% FaceAll                        & 0.7746                           & 0.7982                           & \textbf{0.9473} & 0.8923                           \\
% FaceFour                       & 0.9545                           & 0.9545                           & 0.7614                           & \textbf{0.9773} \\
% FacesUCR                       & 0.8376                           & 0.8322                           & 0.8776                           & \textbf{0.9366} \\
% FiftyWords                     & 0.6396                           & 0.7231                           & 0.8088                           & \textbf{0.8593} \\
% Fish                           & 0.9257                           & 0.9314                           & 0.9086                           & \textbf{0.9771} \\
% FordA                          & 0.8553                           & 0.8856                           & 0.925                            & \textbf{0.9402} \\
% FordB                          & 0.7272                           & 0.7679                           & 0.7728                           & \textbf{0.8284} \\
% FreezerRegularTrain            & 0.9411                           & 0.8674                           & 0.9937                           & \textbf{0.9947} \\
% FreezerSmallTrain              & 0.7972                           & 0.8109                           & 0.9284                           & \textbf{0.974}  \\
% Fungi                          & 0.8226                           & 0.8548                           & 0.9301                           & \textbf{0.9731} \\
% GestureMidAirD1                & 0.6538                           & 0.6                              & 0.7                              & \textbf{0.7769} \\
% GestureMidAirD2                & 0.6231                           & 0.5308                           & 0.6462                           & \textbf{0.6923} \\
% GestureMidAirD3                & 0.3154                           & 0.3                              & 0.4154                           & \textbf{0.4385} \\
% GesturePebbleZ1                & \textbf{0.9302} & 0.907                            & 0.9128                           & 0.9244                           \\
% GesturePebbleZ2                & 0.9494                           & \textbf{0.9557} & 0.8861                           & 0.8291                           \\
% GunPoint                       & 0.9867                           & 0.98                             & \textbf{0.9933} & \textbf{0.9933}                           \\
% GunPointAgeSpan                & 0.9905                           & 0.9842                           & 0.9937                           & \textbf{0.9968} \\
% GunPointMaleVersusFemale       & 0.9968                           & 0.9905                           & 0.9937                           & \textbf{1.0}    \\
% GunPointOldVersusYoung         & \textbf{0.9968} & \textbf{0.9968}                           & 0.9937                           & \textbf{0.9968}                           \\
% Ham                            & 0.6762                           & 0.7048                           & \textbf{0.7238} & 0.6476                           \\
% HandOutlines                   & 0.9081                           & 0.9                              & 0.9378                           & \textbf{0.9459} \\
% Haptics                        & 0.4968                           & 0.4773                           & 0.4643                           & \textbf{0.5357} \\
% Herring                        & 0.6719                           & \textbf{0.7188} & 0.5156                           & 0.6406                           \\
% HouseTwenty                    & 0.9412                           & 0.9496                           & 0.916                            & \textbf{0.9832} \\
% InlineSkate                    & 0.3764                           & 0.3182                           & 0.3745                           & \textbf{0.4255} \\
% InsectEPGRegularTrain          & \textbf{1.0}    & \textbf{1.0}                              & 0.992                            & \textbf{1.0}                              \\
% InsectEPGSmallTrain            & \textbf{1.0}    & \textbf{1.0}                              & 0.9197                           & \textbf{1.0}                              \\
% InsectWingbeatSound            & 0.5202                           & 0.4682                           & \textbf{0.6131} & 0.5995                           \\
% \bottomrule
% \end{tabular}
% }}
% \end{minipage}
% \hfill
% \begin{minipage}{0.5\textwidth}
% {\scalebox{\scalefactor}{
% \begin{tabular}{l|llll}
% \toprule
%                                & RF                          & Head                        & Scratch                     & Full                        \\
% \midrule
% ItalyPowerDemand               & 0.9106                           & 0.9028                           & \textbf{0.9679} & 0.9534                           \\
% LargeKitchenAppliances         & 0.776                            & 0.784                            & \textbf{0.8773} & 0.8533                           \\
% Lightning2                     & 0.8033                           & 0.8033                           & \textbf{0.8525} & 0.8197                           \\
% Lightning7                     & 0.7534                           & 0.7808                           & 0.6849                           & \textbf{0.8356} \\
% Mallat                         & 0.9032                           & 0.7753                           & 0.8759                           & \textbf{0.9262} \\
% Meat                           & \textbf{0.9333} & 0.9167                           & 0.9                              & 0.9                              \\
% MedicalImages                  & 0.7066                           & 0.7                              & 0.7526                           & \textbf{0.8079} \\
% MelbournePedestrian            & 0.8983                           & 0.8889                           & 0.9541                           & \textbf{0.9709} \\
% MiddlePhalanxOutlineAgeGroup   & \textbf{0.5714} & 0.5584                           & 0.5065                           & 0.5584                           \\
% MiddlePhalanxOutlineCorrect    & 0.8041                           & 0.811                            & 0.8007                           & \textbf{0.8419} \\
% MiddlePhalanxTW                & \textbf{0.539}  & 0.526                            & 0.487                            & 0.5195                           \\
% MixedShapesRegularTrain        & 0.9439                           & 0.9353                           & 0.9579                           & \textbf{0.9802} \\
% MixedShapesSmallTrain          & 0.8961                           & 0.8944                           & 0.8709                           & \textbf{0.9522} \\
% MoteStrain                     & 0.9121                           & 0.9113                           & 0.9153                           & \textbf{0.9193} \\
% NonInvasiveFetalECGThorax1     & 0.6198                           & 0.6733                           & 0.9018                           & \textbf{0.9425} \\
% NonInvasiveFetalECGThorax2     & 0.6901                           & 0.7145                           & 0.915                            & \textbf{0.9425} \\
% OSULeaf                        & 0.8636                           & 0.876                            & 0.8719                           & \textbf{0.9669} \\
% OliveOil                       & \textbf{0.9333} & 0.4                              & 0.7                              & \textbf{0.9333}                           \\
% PLAID                          & 0.8138                           & 0.54                             & 0.8976                           & \textbf{0.9181} \\
% PhalangesOutlinesCorrect       & 0.7832                           & 0.7541                           & 0.8135                           & \textbf{0.8392} \\
% Phoneme                        & 0.3244                           & 0.3233                           & 0.2605                           & \textbf{0.3465} \\
% PickupGestureWiimoteZ          & 0.74                             & \textbf{0.84}   & 0.64                             & 0.82                             \\
% PigAirwayPressure              & 0.4712                           & 0.4615                           & 0.1635                           & \textbf{0.5}    \\
% PigArtPressure                 & 0.9087                           & 0.8365                           & 0.6538                           & \textbf{0.9231} \\
% PigCVP                         & 0.7788                           & 0.7644                           & 0.4663                           & \textbf{0.8702} \\
% Plane                          & \textbf{1.0}    & \textbf{1.0}                              & \textbf{1.0}                              & \textbf{1.0}                              \\
% PowerCons                      & 0.9056                           & 0.8722                           & \textbf{0.9944} & 0.9889                           \\
% ProximalPhalanxOutlineAgeGroup & 0.8488                           & \textbf{0.8732} & 0.8                              & 0.8293                           \\
% ProximalPhalanxOutlineCorrect  & 0.811                            & 0.8454                           & 0.8797                           & \textbf{0.9038} \\
% ProximalPhalanxTW              & 0.7707                           & 0.7659                           & \textbf{0.7805} & 0.7659                           \\
% RefrigerationDevices           & \textbf{0.5173} & 0.4987                           & 0.4827                           & 0.4827                           \\
% Rock                           & 0.72                             & 0.78                             & 0.78                             & \textbf{0.86}   \\
% ScreenType                     & 0.4773                           & 0.4453                           & \textbf{0.4853} & \textbf{0.4853}                           \\
% SemgHandGenderCh2              & 0.9117                           & 0.855                            & \textbf{0.9417} & 0.9217                           \\
% SemgHandMovementCh2            & 0.7911                           & 0.5533                           & \textbf{0.8489} & 0.8267                           \\
% SemgHandSubjectCh2             & 0.8711                           & 0.7689                           & \textbf{0.9267} & 0.9178                           \\
% ShakeGestureWiimoteZ           & 0.88                             & 0.88                             & 0.82                             & \textbf{0.94}   \\
% ShapeletSim                    & 0.9389                           & 0.9056                           & 0.9667                           & \textbf{1.0}    \\
% ShapesAll                      & 0.8133                           & 0.8433                           & 0.8633                           & \textbf{0.9067} \\
% SmallKitchenAppliances         & 0.8                              & \textbf{0.8293} & 0.7973                           & 0.7813                           \\
% SmoothSubspace                 & 0.92                             & 0.9533                           & 0.98                             & \textbf{0.9933} \\
% SonyAIBORobotSurface1          & 0.782                            & \textbf{0.8536} & 0.8469                           & 0.822                            \\
% SonyAIBORobotSurface2          & 0.8552                           & 0.8888                           & 0.8489                           & \textbf{0.9297} \\
% StarLightCurves                & 0.9756                           & \textbf{0.978}  & 0.9704                           & 0.9778                           \\
% Strawberry                     & 0.9514                           & 0.9054                           & \textbf{0.9811} & 0.9676                           \\
% SwedishLeaf                    & 0.9264                           & 0.9248                           & 0.9456                           & \textbf{0.9632} \\
% Symbols                        & 0.9749                           & 0.9628                           & 0.9397                           & \textbf{0.993}  \\
% SyntheticControl               & 0.97                             & 0.99                             & 0.9733                           & \textbf{0.9967} \\
% ToeSegmentation1               & 0.9649                           & 0.9386                           & 0.8465                           & \textbf{0.9781} \\
% ToeSegmentation2               & 0.9231                           & \textbf{0.9615} & 0.8462                           & 0.9231                           \\
% Trace                          & \textbf{1.0}    & \textbf{1.0}                              & \textbf{1.0}                              & \textbf{1.0}                              \\
% TwoLeadECG                     & 0.9965                           & \textbf{0.9982} & 0.9552                           & \textbf{0.9982}                           \\
% TwoPatterns                    & 0.8845                           & 0.8898                           & 0.9992                           & \textbf{1.0}    \\
% UMD                            & 0.9653                           & 0.9792                           & 0.9861                           & \textbf{0.9931} \\
% UWaveGestureLibraryAll         & 0.8392                           & 0.8749                           & 0.9712                           & \textbf{0.9743} \\
% UWaveGestureLibraryX           & 0.7674                           & 0.7895                           & 0.8314                           & \textbf{0.8738} \\
% UWaveGestureLibraryY           & 0.6898                           & 0.7088                           & 0.7741                           & \textbf{0.8076} \\
% UWaveGestureLibraryZ           & 0.7365                           & 0.7585                           & 0.7853                           & \textbf{0.8236} \\
% Wafer                          & 0.9904                           & 0.9909                           & 0.995                            & \textbf{0.9992} \\
% Wine                           & \textbf{0.7778} & 0.6111                           & 0.6111                           & 0.6481                           \\
% WordSynonyms                   & 0.5596                           & 0.5047                           & 0.6818                           & \textbf{0.7539} \\
% Worms                          & 0.6753                           & 0.7273                           & 0.7143                           & \textbf{0.7403} \\
% WormsTwoClass                  & 0.7922                           & \textbf{0.8312} & 0.7922                           & 0.8052                           \\
% Yoga                           & 0.8163                           & 0.744                            & 0.83                             & \textbf{0.907}\\
% % Yoga                           & 0.8163                           & 0.744                            & 0.83                             & \textbf{0.907}\\
% \bottomrule
% \end{tabular}
% }}
% \end{minipage}
% \end{table}


% \begin{table}[ht!]
% \caption{Best Epoch Full Result}
% \begin{minipage}{0.5\textwidth}
% {\scalebox{\scalefactor}{
% \begin{tabular}{l|llll}
% \toprule
%                                & RF                          & Head                        & Scratch                     & Full                        \\
% \midrule
% % Avg                            & 0.7905                        & 0.7793                           & 0.8297                           & \textbf{0.8661} \\
% ACSF1                          & 0.59                          & 0.61                             & 0.69                             & \textbf{0.78}   \\
% Adiac                          & 0.734                         & 0.5806                           & 0.7749                           & \textbf{0.8235} \\
% AllGestureWiimoteX             & 0.6714                        & 0.5514                           & 0.7014                           & \textbf{0.8014} \\
% AllGestureWiimoteY             & 0.6729                        & 0.5557                           & 0.7386                           & \textbf{0.8057} \\
% AllGestureWiimoteZ             & 0.6657                        & 0.5457                           & 0.6171                           & \textbf{0.7371} \\
% ArrowHead                      & 0.7143                        & 0.7143                           & 0.8                              & \textbf{0.8057} \\
% BME                            & 0.9333                        & 0.88                             & 0.9933                           & \textbf{1.0}    \\
% Beef                           & 0.6                           & 0.6667                           & 0.7667                           & \textbf{0.8667} \\
% BeetleFly                      & 0.8                           & \textbf{0.9}    & 0.7                              & 0.85                             \\
% BirdChicken                    & \textbf{1.0} & 1.0                              & 0.9                              & 1.0                              \\
% CBF                            & 0.9922                        & 0.9933                           & 0.9944                           & \textbf{1.0}    \\
% Car                            & 0.7667                        & 0.8                              & 0.8                              & \textbf{0.8667} \\
% Chinatown                      & 0.8834                        & 0.8717                           & 0.9621                           & \textbf{0.9738} \\
% ChlorineConcentration          & 0.6794                        & 0.5695                           & 0.7568                           & \textbf{0.7839} \\
% CinCECGTorso                   & 0.6645                        & 0.7232                           & 0.7688                           & \textbf{0.8493} \\
% Coffee                         & 0.9643                        & 0.9643                           & \textbf{1.0}    & 1.0                              \\
% Computers                      & 0.748                         & 0.724                            & 0.772                            & \textbf{0.78}   \\
% CricketX                       & 0.7256                        & 0.7                              & 0.7692                           & \textbf{0.8128} \\
% CricketY                       & 0.7513                        & 0.7051                           & 0.8026                           & \textbf{0.8385} \\
% CricketZ                       & 0.7949                        & 0.741                            & 0.7923                           & \textbf{0.8615} \\
% Crop                           & 0.6738                        & 0.6744                           & 0.754                            & \textbf{0.7706} \\
% DiatomSizeReduction            & 0.8856                        & 0.8987                           & 0.902                            & \textbf{0.9346} \\
% DistalPhalanxOutlineAgeGroup   & 0.777                         & \textbf{0.8129} & 0.741                            & 0.7914                           \\
% DistalPhalanxOutlineCorrect    & 0.7355                        & 0.779                            & \textbf{0.8152} & 0.7899                           \\
% DistalPhalanxTW                & 0.6763                        & 0.6691                           & \textbf{0.7338} & 0.7122                           \\
% DodgerLoopDay                  & 0.5375                        & 0.5                              & 0.6                              & \textbf{0.6375} \\
% DodgerLoopGame                 & 0.7391                        & 0.7246                           & 0.8478                           & \textbf{0.9565} \\
% DodgerLoopWeekend              & 0.9565                        & \textbf{0.9855} & \textbf{0.9855}                           & \textbf{0.9855}                           \\
% ECG200                         & 0.83                          & 0.83                             & 0.84                             & \textbf{0.9}    \\
% ECG5000                        & 0.9222                        & 0.9169                           & 0.9413                           & \textbf{0.9473} \\
% ECGFiveDays                    & 0.8897                        & 0.8479                           & 0.7875                           & \textbf{0.9803} \\
% EOGHorizontalSignal            & 0.5912                        & 0.5746                           & \textbf{0.6906} & 0.6851                           \\
% EOGVerticalSignal              & 0.4751                        & 0.4779                           & 0.5442                           & \textbf{0.5746} \\
% Earthquakes                    & 0.7482                        & 0.7482                           & \textbf{0.7914} & 0.7482                           \\
% ElectricDevices                & 0.7198                        & 0.707                            & 0.7418                           & \textbf{0.7592} \\
% EthanolLevel                   & 0.294                         & 0.318                            & \textbf{0.682}  & 0.618                            \\
% FaceAll                        & 0.7746                        & 0.7982                           & \textbf{0.958}  & 0.8929                           \\
% FaceFour                       & 0.9545                        & 0.9545                           & 0.8409                           & \textbf{0.9886} \\
% FacesUCR                       & 0.8376                        & 0.8322                           & 0.878                            & \textbf{0.9371} \\
% FiftyWords                     & 0.6396                        & 0.7231                           & 0.8132                           & \textbf{0.8637} \\
% Fish                           & 0.9257                        & 0.9314                           & 0.9486                           & \textbf{0.9886} \\
% FordA                          & 0.8553                        & 0.8879                           & 0.9318                           & \textbf{0.9485} \\
% FordB                          & 0.7272                        & 0.7741                           & 0.8074                           & \textbf{0.8432} \\
% FreezerRegularTrain            & 0.9411                        & 0.8674                           & \textbf{0.9968} & 0.9951                           \\
% FreezerSmallTrain              & 0.7972                        & 0.8119                           & 0.9316                           & \textbf{0.9814} \\
% Fungi                          & 0.8226                        & 0.8548                           & 0.9624                           & \textbf{0.9892} \\
% GestureMidAirD1                & 0.6538                        & 0.6                              & 0.7154                           & \textbf{0.8}    \\
% GestureMidAirD2                & 0.6231                        & 0.5308                           & 0.6846                           & \textbf{0.7308} \\
% GestureMidAirD3                & 0.3154                        & 0.3                              & 0.4538                           & \textbf{0.4692} \\
% GesturePebbleZ1                & 0.9302                        & 0.907                            & \textbf{0.9419} & 0.9419                           \\
% GesturePebbleZ2                & 0.9494                        & \textbf{0.962}  & 0.9051                           & 0.9304                           \\
% GunPoint                       & 0.9867                        & 0.98                             & \textbf{1.0}    & 0.9933                           \\
% GunPointAgeSpan                & 0.9905                        & 0.9842                           & 0.9937                           & \textbf{0.9968} \\
% GunPointMaleVersusFemale       & 0.9968                        & 0.9905                           & 0.9937                           & \textbf{1.0}    \\
% GunPointOldVersusYoung         & 0.9968                        & 0.9968                           & 0.9968                           & \textbf{1.0}    \\
% Ham                            & 0.6762                        & 0.7429                           & \textbf{0.8095} & 0.6952                           \\
% HandOutlines                   & 0.9081                        & 0.9                              & 0.9432                           & \textbf{0.9541} \\
% Haptics                        & 0.4968                        & 0.4838                           & 0.5097                           & \textbf{0.5552} \\
% Herring                        & 0.6719                        & \textbf{0.75}   & 0.6406                           & 0.7188                           \\
% HouseTwenty                    & 0.9412                        & 0.9496                           & 0.9412                           & \textbf{0.9832} \\
% InlineSkate                    & 0.3764                        & 0.32                             & 0.4                              & \textbf{0.4364} \\
% InsectEPGRegularTrain          & \textbf{1.0} & \textbf{1.0}                              & 0.992                            & \textbf{1.0}                              \\
% InsectEPGSmallTrain            & \textbf{1.0} & \textbf{1.0}                              & 0.9598                           & \textbf{1.0}                              \\
% InsectWingbeatSound            & 0.5202                        & 0.4682                           & \textbf{0.6298} & 0.6197                           \\
% \bottomrule
% \end{tabular}
% }}
% \end{minipage}
% \hfill
% \begin{minipage}{0.5\textwidth}
% {\scalebox{\scalefactor}{
% \begin{tabular}{l|llll}
% \toprule
%                                & RF                          & Head                        & Scratch                     & Full                        \\
% \midrule
% ItalyPowerDemand               & 0.9106                        & 0.9038                           & \textbf{0.9747} & 0.9572                           \\
% LargeKitchenAppliances         & 0.776                         & 0.7893                           & \textbf{0.8853} & 0.8667                           \\
% Lightning2                     & 0.8033                        & 0.8033                           & \textbf{0.8852} & 0.8361                           \\
% Lightning7                     & 0.7534                        & 0.7945                           & 0.7671                           & \textbf{0.8493} \\
% Mallat                         & 0.9032                        & 0.7753                           & 0.9603                           & \textbf{0.9838} \\
% Meat                           & 0.9333                        & 0.9167                           & \textbf{0.9667} & 0.9667                           \\
% MedicalImages                  & 0.7066                        & 0.7013                           & 0.7658                           & \textbf{0.8224} \\
% MelbournePedestrian            & 0.8983                        & 0.8889                           & 0.9574                           & \textbf{0.9742} \\
% MiddlePhalanxOutlineAgeGroup   & 0.5714                        & 0.5844                           & \textbf{0.6429} & 0.6429                           \\
% MiddlePhalanxOutlineCorrect    & 0.8041                        & 0.8144                           & 0.8419                           & \textbf{0.8694} \\
% MiddlePhalanxTW                & 0.539                         & 0.5844                           & \textbf{0.5974} & 0.5909                           \\
% MixedShapesRegularTrain        & 0.9439                        & 0.9353                           & 0.9633                           & \textbf{0.9814} \\
% MixedShapesSmallTrain          & 0.8961                        & 0.8948                           & 0.8854                           & \textbf{0.953}  \\
% MoteStrain                     & 0.9121                        & 0.9145                           & \textbf{0.9369} & 0.9225                           \\
% NonInvasiveFetalECGThorax1     & 0.6198                        & 0.6748                           & 0.9109                           & \textbf{0.944}  \\
% NonInvasiveFetalECGThorax2     & 0.6901                        & 0.7176                           & 0.917                            & \textbf{0.945}  \\
% OSULeaf                        & 0.8636                        & 0.876                            & 0.8843                           & \textbf{0.9835} \\
% OliveOil                       & 0.9333                        & 0.4                              & 0.8333                           & \textbf{0.9667} \\
% PLAID                          & 0.8138                        & 0.5456                           & 0.905                            & \textbf{0.9255} \\
% PhalangesOutlinesCorrect       & 0.7832                        & 0.7704                           & 0.8357                           & \textbf{0.8531} \\
% Phoneme                        & 0.3244                        & 0.3254                           & 0.2801                           & \textbf{0.3513} \\
% PickupGestureWiimoteZ          & 0.74                          & \textbf{0.86}   & 0.68                             & 0.82                             \\
% PigAirwayPressure              & 0.4712                        & 0.4615                           & 0.1875                           & \textbf{0.5096} \\
% PigArtPressure                 & 0.9087                        & 0.8365                           & 0.6875                           & \textbf{0.9231} \\
% PigCVP                         & 0.7788                        & 0.7788                           & 0.5096                           & \textbf{0.8846} \\
% Plane                          & \textbf{1.0} & \textbf{1.0}                              & \textbf{1.0}                              & \textbf{1.0}                              \\
% PowerCons                      & 0.9056                        & 0.8778                           & \textbf{0.9944} & 0.9889                           \\
% ProximalPhalanxOutlineAgeGroup & 0.8488                        & 0.8732                           & 0.878                            & \textbf{0.8878} \\
% ProximalPhalanxOutlineCorrect  & 0.811                         & 0.8488                           & 0.9107                           & \textbf{0.9278} \\
% ProximalPhalanxTW              & 0.7707                        & 0.7756                           & \textbf{0.8195} & 0.8146                           \\
% RefrigerationDevices           & 0.5173                        & 0.5333                           & \textbf{0.5707} & 0.5387                           \\
% Rock                           & 0.72                          & 0.78                             & 0.8                              & \textbf{0.88}   \\
% ScreenType                     & 0.4773                        & 0.48                             & \textbf{0.52}   & 0.5093                           \\
% SemgHandGenderCh2              & 0.9117                        & 0.8633                           & \textbf{0.9533} & 0.945                            \\
% SemgHandMovementCh2            & 0.7911                        & 0.5556                           & \textbf{0.8556} & 0.8356                           \\
% SemgHandSubjectCh2             & 0.8711                        & 0.7689                           & \textbf{0.9378} & 0.9289                           \\
% ShakeGestureWiimoteZ           & 0.88                          & 0.88                             & 0.9                              & \textbf{0.98}   \\
% ShapeletSim                    & 0.9389                        & 0.9056                           & 0.9667                           & \textbf{1.0}    \\
% ShapesAll                      & 0.8133                        & 0.8433                           & 0.8733                           & \textbf{0.9083} \\
% SmallKitchenAppliances         & 0.8                           & 0.832                            & 0.84                             & \textbf{0.8453} \\
% SmoothSubspace                 & 0.92                          & 0.9533                           & 0.9867                           & \textbf{1.0}    \\
% SonyAIBORobotSurface1          & 0.782                         & 0.8552                           & \textbf{0.9334} & 0.9285                           \\
% SonyAIBORobotSurface2          & 0.8552                        & 0.8888                           & 0.872                            & \textbf{0.9328} \\
% StarLightCurves                & 0.9756                        & 0.9785                           & 0.9749                           & \textbf{0.9817} \\
% Strawberry                     & 0.9514                        & 0.9108                           & \textbf{0.9838} & 0.9784                           \\
% SwedishLeaf                    & 0.9264                        & 0.9248                           & 0.9472                           & \textbf{0.9728} \\
% Symbols                        & 0.9749                        & 0.9628                           & 0.9467                           & \textbf{0.994}  \\
% SyntheticControl               & 0.97                          & 0.99                             & 0.9867                           & \textbf{0.9967} \\
% ToeSegmentation1               & 0.9649                        & 0.9474                           & 0.8728                           & \textbf{0.9868} \\
% ToeSegmentation2               & 0.9231                        & \textbf{0.9615} & 0.9077                           & 0.9462                           \\
% Trace                          & \textbf{1.0} & \textbf{1.0}                              & \textbf{1.0}                              & \textbf{1.0}                              \\
% TwoLeadECG                     & 0.9965                        & \textbf{0.9991} & 0.9693                           & \textbf{0.9991}                           \\
% TwoPatterns                    & 0.8845                        & 0.8898                           & 0.9992                           & \textbf{1.0}    \\
% UMD                            & 0.9653                        & 0.9792                           & \textbf{0.9931} & 0.9931                           \\
% UWaveGestureLibraryAll         & 0.8392                        & 0.8755                           & 0.9732                           & \textbf{0.9749} \\
% UWaveGestureLibraryX           & 0.7674                        & 0.7898                           & 0.84                             & \textbf{0.8747} \\
% UWaveGestureLibraryY           & 0.6898                        & 0.7088                           & 0.7758                           & \textbf{0.8113} \\
% UWaveGestureLibraryZ           & 0.7365                        & 0.7591                           & 0.7878                           & \textbf{0.8264} \\
% Wafer                          & 0.9904                        & 0.9909                           & 0.995                            & \textbf{0.9992} \\
% Wine                           & 0.7778                        & 0.6481                           & 0.7778                           & \textbf{0.7963} \\
% WordSynonyms                   & 0.5596                        & 0.5047                           & 0.6928                           & \textbf{0.7633} \\
% Worms                          & 0.6753                        & 0.7273                           & \textbf{0.7532} & 0.7532                           \\
% WormsTwoClass                  & 0.7922                        & 0.8312                           & 0.8312                           & \textbf{0.8442} \\
% Yoga                           & 0.8163                        & 0.746                            & 0.8377                           & \textbf{0.909}\\
% \bottomrule
% \end{tabular}
% }}
% \end{minipage}
% \end{table}








% \begin{table}[ht!]
% \caption{Moment vs Mantis as a feature extractor followed by a random forest classifier.}
% \begin{minipage}{0.5\textwidth}
% \centering
% {\scalebox{\scalefactor}{
% \begin{tabular}{l|llll}
% \toprule
%                                & Moment                          & Mantis \\
% \midrule
% ACSF1                          & \textbf{0.76}   & 0.59             \\
% Adiac                          & \textbf{0.7928} & 0.734            \\
% AllGestureWiimoteX             & 0.5971           & \textbf{0.6714} \\
% AllGestureWiimoteY             & 0.6657           & \textbf{0.6729} \\
% AllGestureWiimoteZ             & 0.5714           & \textbf{0.6657} \\
% ArrowHead                      & \textbf{0.7943} & 0.7143           \\
% BME                            & \textbf{0.9867} & 0.9333           \\
% Beef                           & \textbf{0.7}    & 0.6              \\
% BeetleFly                      & \textbf{0.95}   & 0.8              \\
% BirdChicken                    & 0.85             & \textbf{1.0}    \\
% CBF                            & 0.9411           & \textbf{0.9922} \\
% Car                            & \textbf{0.8167} & 0.7667           \\
% Chinatown                      & \textbf{0.9767} & 0.8834           \\
% ChlorineConcentration          & \textbf{0.6859} & 0.6794           \\
% CinCECGTorso                   & \textbf{0.7022} & 0.6645           \\
% Coffee                         & 0.8929           & \textbf{0.9643} \\
% Computers                      & 0.632            & \textbf{0.748}  \\
% CricketX                       & 0.6846           & \textbf{0.7256} \\
% CricketY                       & 0.6974           & \textbf{0.7513} \\
% CricketZ                       & 0.7154           & \textbf{0.7949} \\
% Crop                           & \textbf{0.7008} & 0.6738           \\
% DiatomSizeReduction            & \textbf{0.8889} & 0.8856           \\
% DistalPhalanxOutlineAgeGroup   & 0.741            & \textbf{0.777}  \\
% DistalPhalanxOutlineCorrect    & \textbf{0.7899} & 0.7355           \\
% DistalPhalanxTW                & 0.6547           & \textbf{0.6763} \\
% DodgerLoopDay                  & 0.4625           & \textbf{0.5375} \\
% DodgerLoopGame                 & \textbf{0.8043} & 0.7391           \\
% DodgerLoopWeekend              & \textbf{0.9638} & 0.9565           \\
% ECG200                         & \textbf{0.88}   & 0.83             \\
% ECG5000                        & \textbf{0.9393} & 0.9222           \\
% ECGFiveDays                    & 0.8362           & \textbf{0.8897} \\
% EOGHorizontalSignal            & 0.547            & \textbf{0.5912} \\
% EOGVerticalSignal              & 0.4503           & \textbf{0.4751} \\
% Earthquakes                    & \textbf{0.7482} & 0.7482           \\
% ElectricDevices                & 0.7131           & \textbf{0.7198} \\
% EthanolLevel                   & \textbf{0.426}  & 0.294            \\
% FaceAll                        & 0.7438           & \textbf{0.7746} \\
% FaceFour                       & 0.7727           & \textbf{0.9545} \\
% FacesUCR                       & 0.7927           & \textbf{0.8376} \\
% FiftyWords                     & \textbf{0.6659} & 0.6396           \\
% Fish                           & 0.8514           & \textbf{0.9257} \\
% FordA                          & \textbf{0.9008} & 0.8553           \\
% FordB                          & \textbf{0.7654} & 0.7272           \\
% FreezerRegularTrain            & 0.8993           & \textbf{0.9411} \\
% FreezerSmallTrain              & 0.7695           & \textbf{0.7972} \\
% Fungi                          & \textbf{1.0}    & 0.8226           \\
% GestureMidAirD1                & \textbf{0.6692} & 0.6538           \\
% GestureMidAirD2                & 0.5923           & \textbf{0.6231} \\
% GestureMidAirD3                & \textbf{0.3615} & 0.3154           \\
% GesturePebbleZ1                & 0.8547           & \textbf{0.9302} \\
% GesturePebbleZ2                & 0.8418           & \textbf{0.9494} \\
% GunPoint                       & \textbf{1.0}    & 0.9867           \\
% GunPointAgeSpan                & 0.962            & \textbf{0.9905} \\
% GunPointMaleVersusFemale       & 0.9873           & \textbf{0.9968} \\
% GunPointOldVersusYoung         & 0.9651           & \textbf{0.9968} \\
% Ham                            & \textbf{0.7714} & 0.6762           \\
% HandOutlines                   & 0.9027           & \textbf{0.9081} \\
% Haptics                        & \textbf{0.5227} & 0.4968           \\
% Herring                        & 0.6094           & \textbf{0.6719} \\
% HouseTwenty                    & \textbf{0.9412} & \textbf{0.9412}           \\
% InlineSkate                    & 0.3182           & \textbf{0.3764} \\
% InsectEPGRegularTrain          & 0.9237           & \textbf{1.0}    \\
% InsectEPGSmallTrain            & 0.8554           & \textbf{1.0}    \\
% InsectWingbeatSound            & \textbf{0.6187} & 0.5202           \\
% \bottomrule
% \end{tabular}
% }}
% \end{minipage}
% \hfill
% \begin{minipage}{0.5\textwidth}
% {\scalebox{\scalefactor}{
% \begin{tabular}{l|ll}
% \toprule
%                                & Moment                          & Mantis                    \\
% \midrule
% ItalyPowerDemand               & \textbf{0.9504} & 0.9106           \\
% LargeKitchenAppliances         & 0.736            & \textbf{0.776}  \\
% Lightning2                     & 0.7049           & \textbf{0.8033} \\
% Lightning7                     & 0.6986           & \textbf{0.7534} \\
% Mallat                         & 0.8512           & \textbf{0.9032} \\
% Meat                           & \textbf{0.95}   & 0.9333           \\
% MedicalImages                  & 0.6961           & \textbf{0.7066} \\
% MelbournePedestrian            & 0.87             & \textbf{0.8983} \\
% MiddlePhalanxOutlineAgeGroup   & \textbf{0.5844} & 0.5714           \\
% MiddlePhalanxOutlineCorrect    & \textbf{0.8694} & 0.8041           \\
% MiddlePhalanxTW                & \textbf{0.5909} & 0.539            \\
% MixedShapesRegularTrain        & 0.9101           & \textbf{0.9439} \\
% MixedShapesSmallTrain          & 0.8404           & \textbf{0.8961} \\
% MoteStrain                     & 0.8962           & \textbf{0.9121} \\
% NonInvasiveFetalECGThorax1     & \textbf{0.8926} & 0.6198           \\
% NonInvasiveFetalECGThorax2     & \textbf{0.9145} & 0.6901           \\
% OSULeaf                        & 0.7355           & \textbf{0.8636} \\
% OliveOil                       & 0.9              & \textbf{0.9333} \\
% PLAID                          & 0.7412           & \textbf{0.8138} \\
% PhalangesOutlinesCorrect       & \textbf{0.8252} & 0.7832           \\
% Phoneme                        & 0.279            & \textbf{0.3244} \\
% PickupGestureWiimoteZ          & \textbf{0.74}   & \textbf{0.74}             \\
% PigAirwayPressure              & 0.1202           & \textbf{0.4712} \\
% PigArtPressure                 & 0.6058           & \textbf{0.9087} \\
% PigCVP                         & 0.5673           & \textbf{0.7788} \\
% Plane                          & 0.9714           & \textbf{1.0}    \\
% PowerCons                      & \textbf{0.9444} & 0.9056           \\
% ProximalPhalanxOutlineAgeGroup & 0.839            & \textbf{0.8488} \\
% ProximalPhalanxOutlineCorrect  & \textbf{0.8797} & 0.811            \\
% ProximalPhalanxTW              & \textbf{0.8146} & 0.7707           \\
% RefrigerationDevices           & \textbf{0.5387} & 0.5173           \\
% Rock                           & \textbf{0.82}   & 0.72             \\
% ScreenType                     & 0.424            & \textbf{0.4773} \\
% SemgHandGenderCh2              & 0.8117           & \textbf{0.9117} \\
% SemgHandMovementCh2            & 0.5222           & \textbf{0.7911} \\
% SemgHandSubjectCh2             & 0.6844           & \textbf{0.8711} \\
% ShakeGestureWiimoteZ           & 0.86             & \textbf{0.88}   \\
% ShapeletSim                    & \textbf{0.9611} & 0.9389           \\
% ShapesAll                      & \textbf{0.8133} & \textbf{0.8133}           \\
% SmallKitchenAppliances         & 0.7253           & \textbf{0.8}    \\
% SmoothSubspace                 & \textbf{0.92}   & \textbf{0.92}             \\
% SonyAIBORobotSurface1          & \textbf{0.8136} & 0.782            \\
% SonyAIBORobotSurface2          & 0.8374           & \textbf{0.8552} \\
% StarLightCurves                & 0.9738           & \textbf{0.9756} \\
% Strawberry                     & \textbf{0.9595} & 0.9514           \\
% SwedishLeaf                    & \textbf{0.9264} & \textbf{0.9264}           \\
% Symbols                        & 0.9377           & \textbf{0.9749} \\
% SyntheticControl               & 0.9433           & \textbf{0.97}   \\
% ToeSegmentation1               & 0.9386           & \textbf{0.9649} \\
% ToeSegmentation2               & 0.8462           & \textbf{0.9231} \\
% Trace                          & 0.99             & \textbf{1.0}    \\
% TwoLeadECG                     & 0.9781           & \textbf{0.9965} \\
% TwoPatterns                    & 0.883            & \textbf{0.8845} \\
% UMD                            & \textbf{0.9653} & \textbf{0.9653}           \\
% UWaveGestureLibraryAll         & \textbf{0.8959} & 0.8392           \\
% UWaveGestureLibraryX           & \textbf{0.7887} & 0.7674           \\
% UWaveGestureLibraryY           & \textbf{0.6993} & 0.6898           \\
% UWaveGestureLibraryZ           & 0.7281           & \textbf{0.7365} \\
% Wafer                          & 0.9864           & \textbf{0.9904} \\
% Wine                           & \textbf{0.8148} & 0.7778           \\
% WordSynonyms                   & \textbf{0.5925} & 0.5596           \\
% Worms                          & \textbf{0.6883} & 0.6753           \\
% WormsTwoClass                  & 0.7662           & \textbf{0.7922} \\
% Yoga                           & \textbf{0.8237} & 0.8163 \\
% \bottomrule
% \end{tabular}
% }}
% \end{minipage}
% \end{table}




% \begin{minipage}{0.45\textwidth}
% \begin{table}[ht!]
% \caption{Comparison of different fine-tuning schemes of Mantis on UEA-20 collection. The last epoch accuracy averaged over 3 random seeds is reported.}
% \centering
% \begin{tabular}{l|llll}
% \toprule
% dataset                   & RF & Head & Scratch         & Full           \\
% \midrule
% ArticularyWordRecognition & 0.9933$_{\pm0.0033}$ & 0.9933$_{\pm0.0}$    & \textbf{0.9967}$_{\pm0.0}$    & 0.9933$_{\pm0.0}$    \\
% BasicMotions              & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
% CharacterTrajectories     & 0.9396$_{\pm0.0008}$ & 0.9673$_{\pm0.0021}$ & 0.9789$_{\pm0.0028}$ & \textbf{0.9912}$_{\pm0.0011}$ \\
% Cricket                   & \textbf{1.0}$_{\pm0.0}$       & 0.9861$_{\pm0.0}$    & 0.9861$_{\pm0.0}$    & \textbf{1.0}$_{\pm0.0}$       \\
% ERing                     & 0.9407$_{\pm0.0098}$ & 0.9296$_{\pm0.0192}$ & 0.9432$_{\pm0.0077}$ & \textbf{0.9901}$_{\pm0.0043}$ \\
% EigenWorms                & 0.7532$_{\pm0.0159}$ & 0.7379$_{\pm0.0233}$ & 0.6743$_{\pm0.0192}$ & \textbf{0.8219}$_{\pm0.0044}$ \\
% Epilepsy                  & 0.9952$_{\pm0.0042}$ & 0.9928$_{\pm0.0}$    & 0.9879$_{\pm0.0111}$ & \textbf{1.0}$_{\pm0.0}$       \\
% EthanolConcentration      & 0.27$_{\pm0.0101}$   & 0.2928$_{\pm0.0132}$ & 0.2852$_{\pm0.0201}$ & \textbf{0.3942}$_{\pm0.0295}$ \\
% HandMovementDirection     & 0.2117$_{\pm0.0413}$ & 0.2477$_{\pm0.0281}$ & \textbf{0.4234}$_{\pm0.0609}$ & 0.3333$_{\pm0.0475}$ \\
% Handwriting               & 0.3392$_{\pm0.01}$   & 0.4271$_{\pm0.0113}$ & 0.3294$_{\pm0.0116}$ & \textbf{0.4773}$_{\pm0.0119}$ \\
% JapaneseVowels            & 0.9631$_{\pm0.0056}$ & 0.9649$_{\pm0.0}$    & 0.9315$_{\pm0.0145}$ & \textbf{0.9757}$_{\pm0.0027}$ \\
% LSST                      & 0.6054$_{\pm0.0021}$ & 0.6459$_{\pm0.0006}$ & 0.666$_{\pm0.0111}$  & \textbf{0.6741}$_{\pm0.0021}$ \\
% Libras                    & 0.8981$_{\pm0.0085}$ & 0.8963$_{\pm0.014}$  & 0.9185$_{\pm0.0064}$ & \textbf{0.9278}$_{\pm0.0111}$ \\
% NATOPS                    & 0.9074$_{\pm0.0128}$ & \textbf{0.9259}$_{\pm0.0116}$ & 0.8079$_{\pm0.0189}$ & \textbf{0.9259}$_{\pm0.0085}$ \\
% PhonemeSpectra            & 0.2735$_{\pm0.0078}$ & 0.2934$_{\pm0.0002}$ & 0.2082$_{\pm0.0067}$ & \textbf{0.3106}$_{\pm0.0081}$ \\
% RacketSports              & 0.9232$_{\pm0.0038}$ & 0.9276$_{\pm0.0066}$ & 0.8487$_{\pm0.0066}$ & \textbf{0.9298}$_{\pm0.01}$   \\
% SelfRegulationSCP1        & 0.8043$_{\pm0.011}$  & 0.8248$_{\pm0.0052}$ & \textbf{0.8487}$_{\pm0.0071}$ & 0.843$_{\pm0.0034}$  \\
% SelfRegulationSCP2        & 0.4759$_{\pm0.0452}$ & 0.487$_{\pm0.0085}$  & 0.487$_{\pm0.014}$   & \textbf{0.4889}$_{\pm0.0309}$ \\
% SpokenArabicDigits        & 0.8392$_{\pm0.0046}$ & 0.9291$_{\pm0.0016}$ & 0.982$_{\pm0.0027}$  & \textbf{0.9861}$_{\pm0.0009}$ \\
% UWaveGestureLibrary       & 0.8135$_{\pm0.01}$   & 0.8594$_{\pm0.0031}$ & 0.8833$_{\pm0.0208}$ & \textbf{0.9385}$_{\pm0.011}$ \\
% \bottomrule
% \end{tabular}
% \end{table}
% % \end{minipage}
% % \begin{minipage}{0.45\textwidth}
% \begin{table}[ht!]
% \caption{Comparison of different fine-tuning schemes of Mantis on UEA-20 collection. The best epoch accuracy averaged over 3 random seeds is reported.}
% \centering
% \begin{tabular}{l|llll}
% \toprule
% dataset                   & RF & Head & Scratch         & Full           \\
% \midrule
% ArticularyWordRecognition & 0.9933$_{\pm0.0033}$ & 0.9933$_{\pm0.0}$    & \textbf{0.9967}$_{\pm0.0}$    & 0.9933$_{\pm0.0}$    \\
% BasicMotions              & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
% CharacterTrajectories     & 0.9396$_{\pm0.0008}$ & 0.9673$_{\pm0.0021}$ & 0.9838$_{\pm0.0029}$ & \textbf{0.9928}$_{\pm0.0004}$ \\
% Cricket                   & \textbf{1.0}$_{\pm0.0}$       & 0.9907$_{\pm0.008}$  & 0.9861$_{\pm0.0}$    & \textbf{1.0}$_{\pm0.0}$       \\
% ERing                     & 0.9407$_{\pm0.0098}$ & 0.9296$_{\pm0.0192}$ & 0.9432$_{\pm0.0077}$ & \textbf{0.9926}$_{\pm0.0074}$ \\
% EigenWorms                & 0.7532$_{\pm0.0159}$ & 0.7379$_{\pm0.0233}$ & 0.7023$_{\pm0.0202}$ & \textbf{0.8372}$_{\pm0.0044}$ \\
% Epilepsy                  & 0.9952$_{\pm0.0042}$ & 0.9928$_{\pm0.0}$    & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
% EthanolConcentration      & 0.27$_{\pm0.0101}$   & 0.3156$_{\pm0.0076}$ & 0.3321$_{\pm0.0154}$ & \textbf{0.4208}$_{\pm0.0195}$ \\
% HandMovementDirection     & 0.2117$_{\pm0.0413}$ & 0.3829$_{\pm0.0639}$ & \textbf{0.5135}$_{\pm0.0234}$ & 0.4009$_{\pm0.0206}$ \\
% Handwriting               & 0.3392$_{\pm0.01}$   & 0.4275$_{\pm0.0107}$ & 0.3375$_{\pm0.0129}$ & \textbf{0.482}$_{\pm0.0157}$  \\
% JapaneseVowels            & 0.9631$_{\pm0.0056}$ & 0.9712$_{\pm0.0016}$ & 0.9374$_{\pm0.0165}$ & \textbf{0.9811}$_{\pm0.0054}$ \\
% LSST                      & 0.6054$_{\pm0.0021}$ & 0.6718$_{\pm0.0017}$ & 0.6944$_{\pm0.0023}$ & \textbf{0.7109}$_{\pm0.0015}$ \\
% Libras                    & 0.8981$_{\pm0.0085}$ & 0.8981$_{\pm0.0116}$ & 0.937$_{\pm0.0085}$  & \textbf{0.9389}$_{\pm0.0}$    \\
% NATOPS                    & 0.9074$_{\pm0.0128}$ & 0.9333$_{\pm0.0056}$ & 0.819$_{\pm0.0115}$  & \textbf{0.937}$_{\pm0.0116}$  \\
% PhonemeSpectra            & 0.2735$_{\pm0.0078}$ & 0.2965$_{\pm0.0014}$ & 0.2415$_{\pm0.0033}$ & \textbf{0.3421}$_{\pm0.0023}$ \\
% RacketSports              & 0.9232$_{\pm0.0038}$ & 0.9298$_{\pm0.0076}$ & 0.8684$_{\pm0.0066}$ & \textbf{0.9408}$_{\pm0.0}$    \\
% SelfRegulationSCP1        & 0.8043$_{\pm0.011}$  & 0.851$_{\pm0.012}$   & 0.8896$_{\pm0.0052}$ & \textbf{0.9135}$_{\pm0.0071}$ \\
% SelfRegulationSCP2        & 0.4759$_{\pm0.0452}$ & 0.5315$_{\pm0.0116}$ & \textbf{0.5611}$_{\pm0.0111}$ & 0.5389$_{\pm0.0096}$ \\
% SpokenArabicDigits        & 0.8392$_{\pm0.0046}$ & 0.9295$_{\pm0.0016}$ & 0.9828$_{\pm0.0025}$ & \textbf{0.987}$_{\pm0.0009}$  \\
% UWaveGestureLibrary       & 0.8135$_{\pm0.01}$   & 0.8594$_{\pm0.0031}$ & 0.8958$_{\pm0.0079}$ & \textbf{0.9438}$_{\pm0.0108}$ \\
% \bottomrule
% \end{tabular}
% \end{table}
% \end{minipage}





% \begin{table}[ht!]
% \caption{Moment vs Mantis as a feature extractor followed by a random forest classifier on UEA collection averaged over 3 random seeds.}
% \centering
% \begin{tabular}{l|ll}
% \toprule
% dataset                   & Moment         & Mantis           \\
% \midrule
% ArticularyWordRecognition & 0.980$_{\pm  0.000}$ & \textbf{0.993} $_{\pm   0.003}$ \\
% BasicMotions              & 0.992 $_{\pm   0.014}$ & \textbf{1.000} $_{\pm   0.000}$ \\
% CharacterTrajectories     & \textbf{0.970} $_{\pm   0.002}$ & 0.940 $_{\pm   0.001}$ \\
% Cricket                   & 0.977 $_{\pm   0.008}$ & \textbf{1.000} $_{\pm   0.000}$ \\
% DuckDuckGeese             & \textbf{0.433} $_{\pm   0.031}$ & 0.407 $_{\pm   0.031}$ \\
% ERing                     & \textbf{0.969} $_{\pm   0.008}$ & 0.941 $_{\pm   0.010}$ \\
% EigenWorms        & 0.735 $_{\pm   0.016}$ & \textbf{0.753} $_{\pm   0.016}$ \\
% Epilepsy                  & 0.988 $_{\pm   0.004}$ & \textbf{0.995} $_{\pm   0.004}$ \\
% EthanolConcentration      & \textbf{0.278} $_{\pm   0.008}$ & 0.270 $_{\pm   0.010}$ \\
% FaceDetection             & \textbf{0.544} $_{\pm   0.011}$ & 0.526 $_{\pm   0.002}$ \\
% FingerMovements           & 0.497 $_{\pm   0.023}$ & \textbf{0.540} $_{\pm   0.035}$ \\
% HandMovementDirection     & \textbf{0.315} $_{\pm   0.008}$ & 0.212 $_{\pm   0.041}$ \\
% Handwriting               & 0.236 $_{\pm   0.005}$ & \textbf{0.339} $_{\pm   0.010}$ \\
% Heartbeat                 & 0.727 $_{\pm   0.005}$ & \textbf{0.798} $_{\pm   0.017}$ \\
% InsectWingbeatSubset      & 0.243 $_{\pm   0.011}$ & \textbf{0.607} $_{\pm   0.007}$ \\
% JapaneseVowels            & 0.880 $_{\pm   0.009}$ & \textbf{0.963} $_{\pm   0.006}$ \\
% LSST                      & \textbf{0.621} $_{\pm   0.001}$ & 0.605 $_{\pm   0.002}$ \\
% Libras                    & 0.850 $_{\pm   0.020}$ & \textbf{0.898} $_{\pm   0.008}$ \\
% MotorImagery              & 0.547 $_{\pm   0.055}$ & \textbf{0.550} $_{\pm   0.036}$ \\
% NATOPS                    & 0.822 $_{\pm   0.024}$ & \textbf{0.907} $_{\pm   0.013}$ \\
% PEMS-SF                   & \textbf{1.000} $_{\pm   0.000}$ & 0.985 $_{\pm   0.013}$ \\
% PhonemeSpectra            & 0.215 $_{\pm   0.001}$ & \textbf{0.273} $_{\pm   0.008}$ \\
% RacketSports              & 0.820 $_{\pm   0.010}$ & \textbf{0.923} $_{\pm   0.004}$ \\
% SelfRegulationSCP1        & 0.754 $_{\pm   0.012}$ & \textbf{0.804} $_{\pm   0.011}$ \\
% SelfRegulationSCP2        & \textbf{0.496} $_{\pm   0.020}$ & 0.476 $_{\pm   0.045}$ \\
% SpokenArabicDigits        & \textbf{0.935} $_{\pm   0.002}$ & 0.839 $_{\pm   0.005}$ \\
% UWaveGestureLibrary       & \textbf{0.873} $_{\pm   0.011}$ & 0.814 $_{\pm   0.010}$ \\
% \bottomrule
% \end{tabular}
% \end{table}

























\newcommand{\scalefactorzeroshot}{0.605}
% \newcommand{\scalefactorzeroshot}{0.62}
\begin{table}[ht!]
\caption{Comparison of 3 TSFMs under the feature extraction regime on the \texttt{159-D} benchmark. 
% when each of them is used as a feature extractor without fine-tuning followed by a random forest classifier. 
The performance is averaged over 3 random seeds and reported with the standard deviation.}
\label{tab:zeroshot-sota}
\begin{minipage}{0.5\textwidth}
{\scalebox{\scalefactorzeroshot}{
\centering
\begin{tabular}{l|lll}
\toprule
                               & NuTime & MOMENT                                          & Mantis                                         \\
\midrule
ACSF1                          & 0.7367$_{\pm0.0351}$                           & \textbf{0.75}$_{\pm0.0173}$   & 0.6133$_{\pm0.0208}$                           \\
Adiac                          & 0.7255$_{\pm0.0115}$                           & \textbf{0.7886}$_{\pm0.0074}$ & 0.7332$_{\pm0.0039}$                           \\
AllGestureWiimoteX             & 0.661$_{\pm0.003}$                             & 0.6105$_{\pm0.0136}$                           & \textbf{0.6705}$_{\pm0.0044}$ \\
AllGestureWiimoteY             & 0.6362$_{\pm0.0079}$                           & 0.6576$_{\pm0.0079}$                           & \textbf{0.6671}$_{\pm0.0057}$ \\
AllGestureWiimoteZ             & 0.6024$_{\pm0.0179}$                           & 0.5767$_{\pm0.0103}$                           & \textbf{0.6695}$_{\pm0.0033}$ \\
ArrowHead                      & 0.76$_{\pm0.0198}$                             & \textbf{0.8076}$_{\pm0.0144}$ & 0.7105$_{\pm0.0175}$                           \\
BME                            & 0.8444$_{\pm0.0168}$                           & \textbf{0.9756}$_{\pm0.0139}$ & 0.9311$_{\pm0.0038}$                           \\
Beef                           & 0.6556$_{\pm0.077}$                            & \textbf{0.7444}$_{\pm0.0509}$ & 0.6556$_{\pm0.0509}$                           \\
BeetleFly                      & 0.8667$_{\pm0.0289}$                           & \textbf{0.95}$_{\pm0.0}$      & 0.85$_{\pm0.05}$                               \\
BirdChicken                    & 0.9667$_{\pm0.0289}$                           & 0.85$_{\pm0.0}$                                & \textbf{1.0}$_{\pm0.0}$       \\
CBF                            & 0.9744$_{\pm0.0011}$                           & 0.9411$_{\pm0.0078}$                           & \textbf{0.993}$_{\pm0.0013}$  \\
Car                            & 0.75$_{\pm0.0}$                                & \textbf{0.7944}$_{\pm0.0255}$ & 0.7722$_{\pm0.0419}$                           \\
Chinatown                      & 0.932$_{\pm0.0017}$                            & \textbf{0.9806}$_{\pm0.0034}$ & 0.8737$_{\pm0.0168}$                           \\
ChlorineConcentration          & 0.6675$_{\pm0.0035}$                           & \textbf{0.6901}$_{\pm0.0042}$ & 0.6806$_{\pm0.0019}$                           \\
CinCECGTorso                   & \textbf{0.737}$_{\pm0.0152}$  & 0.6998$_{\pm0.0118}$                           & 0.6611$_{\pm0.0036}$                           \\
Coffee                         & 0.9167$_{\pm0.0206}$                           & 0.8929$_{\pm0.0}$                              & \textbf{0.9524}$_{\pm0.0206}$ \\
Computers                      & \textbf{0.78}$_{\pm0.004}$    & 0.6173$_{\pm0.0162}$                           & 0.7373$_{\pm0.0092}$                           \\
CricketX                       & 0.6701$_{\pm0.0146}$                           & 0.6795$_{\pm0.0051}$                           & \textbf{0.7368}$_{\pm0.0171}$ \\
CricketY                       & 0.6556$_{\pm0.0053}$                           & 0.6897$_{\pm0.0077}$                           & \textbf{0.7504}$_{\pm0.0065}$ \\
CricketZ                       & 0.6863$_{\pm0.0171}$                           & 0.7128$_{\pm0.0044}$                           & \textbf{0.7906}$_{\pm0.0039}$ \\
Crop                           & 0.6683$_{\pm0.0026}$                           & \textbf{0.7035}$_{\pm0.0026}$ & 0.6756$_{\pm0.0018}$                           \\
DiatomSizeReduction            & 0.8322$_{\pm0.0115}$                           & \textbf{0.8867}$_{\pm0.0019}$ & 0.8845$_{\pm0.0019}$                           \\
DistalPhalanxOutlineAgeGroup   & 0.7362$_{\pm0.011}$                            & 0.7506$_{\pm0.011}$                            & \textbf{0.789}$_{\pm0.015}$   \\
DistalPhalanxOutlineCorrect    & 0.7742$_{\pm0.0055}$                           & \textbf{0.7886}$_{\pm0.0055}$ & 0.75$_{\pm0.0126}$                             \\
DistalPhalanxTW                & 0.6763$_{\pm0.0}$                              & 0.6571$_{\pm0.011}$                            & \textbf{0.6859}$_{\pm0.011}$  \\
DodgerLoopDay                  & 0.5167$_{\pm0.0361}$                           & 0.4542$_{\pm0.0144}$                           & \textbf{0.55}$_{\pm0.0217}$   \\
DodgerLoopGame                 & 0.756$_{\pm0.0084}$                            & \textbf{0.8116}$_{\pm0.0126}$ & 0.7585$_{\pm0.0221}$                           \\
DodgerLoopWeekend              & 0.9565$_{\pm0.0072}$                           & \textbf{0.9614}$_{\pm0.0111}$ & 0.9517$_{\pm0.0084}$                           \\
ECG200                         & 0.8133$_{\pm0.0153}$                           & \textbf{0.8967}$_{\pm0.0153}$ & 0.82$_{\pm0.01}$                               \\
ECG5000                        & 0.9313$_{\pm0.0003}$                           & \textbf{0.9384}$_{\pm0.0008}$ & 0.9211$_{\pm0.001}$                            \\
ECGFiveDays                    & 0.7801$_{\pm0.017}$                            & 0.8564$_{\pm0.0223}$                           & \textbf{0.909}$_{\pm0.0218}$  \\
EOGHorizontalSignal            & 0.4346$_{\pm0.0032}$                           & 0.5571$_{\pm0.0112}$                           & \textbf{0.5875}$_{\pm0.0089}$ \\
EOGVerticalSignal              & 0.2716$_{\pm0.008}$                            & 0.4595$_{\pm0.0097}$                           & \textbf{0.4751}$_{\pm0.0}$    \\
Earthquakes                    & 0.7458$_{\pm0.0042}$                           & 0.7458$_{\pm0.0042}$                           & \textbf{0.7482}$_{\pm0.0}$    \\
ElectricDevices                & 0.7046$_{\pm0.0014}$                           & 0.7142$_{\pm0.001}$                            & \textbf{0.7226}$_{\pm0.0026}$ \\
EthanolLevel                   & 0.3407$_{\pm0.0101}$                           & \textbf{0.4227}$_{\pm0.0058}$ & 0.2993$_{\pm0.011}$                            \\
FaceAll                        & 0.6363$_{\pm0.0053}$                           & 0.7398$_{\pm0.0074}$                           & \textbf{0.7815}$_{\pm0.0074}$ \\
FaceFour                       & 0.7841$_{\pm0.0521}$                           & 0.7765$_{\pm0.0174}$                           & \textbf{0.9508}$_{\pm0.0066}$ \\
FacesUCR                       & 0.7141$_{\pm0.003}$                            & 0.7951$_{\pm0.0034}$                           & \textbf{0.8354}$_{\pm0.0054}$ \\
FiftyWords                     & 0.5949$_{\pm0.0125}$                           & \textbf{0.6777}$_{\pm0.0111}$ & 0.6462$_{\pm0.0096}$                           \\
Fish                           & 0.9162$_{\pm0.0033}$                           & 0.8705$_{\pm0.0201}$                           & \textbf{0.9333}$_{\pm0.0066}$ \\
FordA                          & 0.8932$_{\pm0.002}$                            & \textbf{0.9015}$_{\pm0.0008}$ & 0.8581$_{\pm0.0048}$                           \\
FordB                          & 0.7642$_{\pm0.0119}$                           & \textbf{0.765}$_{\pm0.0019}$  & 0.7305$_{\pm0.0031}$                           \\
FreezerRegularTrain            & \textbf{0.9738}$_{\pm0.0013}$ & 0.8994$_{\pm0.0012}$                           & 0.9374$_{\pm0.0043}$                           \\
FreezerSmallTrain              & \textbf{0.9549}$_{\pm0.0059}$ & 0.7758$_{\pm0.0067}$                           & 0.7942$_{\pm0.0059}$                           \\
Fungi                          & 0.7043$_{\pm0.0093}$                           & \textbf{0.9964}$_{\pm0.0062}$ & 0.8262$_{\pm0.0164}$                           \\
GestureMidAirD1                & \textbf{0.6744}$_{\pm0.0379}$ & \textbf{0.6744}$_{\pm0.0044}$ & 0.659$_{\pm0.0044}$                            \\
GestureMidAirD2                & 0.5692$_{\pm0.0}$                              & 0.5744$_{\pm0.016}$                            & \textbf{0.6154}$_{\pm0.0077}$ \\
GestureMidAirD3                & \textbf{0.3974}$_{\pm0.0247}$ & 0.359$_{\pm0.0118}$                            & 0.3282$_{\pm0.016}$                            \\
GesturePebbleZ1                & 0.8915$_{\pm0.0067}$                           & 0.8469$_{\pm0.0067}$                           & \textbf{0.9283}$_{\pm0.0034}$ \\
GesturePebbleZ2                & 0.8165$_{\pm0.011}$                            & 0.8376$_{\pm0.0073}$                           & \textbf{0.9219}$_{\pm0.0256}$ \\
GunPoint                       & 0.9444$_{\pm0.0038}$                           & \textbf{1.0}$_{\pm0.0}$       & 0.98$_{\pm0.0067}$                             \\
GunPointAgeSpan                & 0.9684$_{\pm0.0032}$                           & 0.962$_{\pm0.0032}$                            & \textbf{0.9905}$_{\pm0.0}$    \\
GunPointMaleVersusFemale       & 0.962$_{\pm0.0032}$                            & 0.9884$_{\pm0.0018}$                           & \textbf{0.9958}$_{\pm0.0018}$ \\
GunPointOldVersusYoung         & \textbf{1.0}$_{\pm0.0}$       & 0.9577$_{\pm0.008}$                            & 0.9968$_{\pm0.0}$                              \\
Ham                            & 0.7206$_{\pm0.022}$                            & \textbf{0.7714}$_{\pm0.0}$    & 0.673$_{\pm0.0145}$                            \\
HandOutlines                   & 0.9045$_{\pm0.0062}$                           & 0.909$_{\pm0.0056}$                            & \textbf{0.9162}$_{\pm0.0072}$ \\
Haptics                        & 0.4481$_{\pm0.0056}$                           & \textbf{0.5152}$_{\pm0.0068}$ & 0.4968$_{\pm0.0032}$                           \\
Herring                        & 0.599$_{\pm0.0325}$                            & 0.6146$_{\pm0.009}$                            & \textbf{0.6667}$_{\pm0.0239}$ \\
HouseTwenty                    & 0.8655$_{\pm0.0084}$                           & 0.9356$_{\pm0.0097}$                           & \textbf{0.9412}$_{\pm0.0}$    \\
InlineSkate                    & 0.357$_{\pm0.0105}$                            & 0.3176$_{\pm0.001}$                            & \textbf{0.363}$_{\pm0.0136}$  \\
InsectEPGRegularTrain          & \textbf{1.0}$_{\pm0.0}$       & 0.9183$_{\pm0.0061}$                           & \textbf{1.0}$_{\pm0.0}$       \\
InsectEPGSmallTrain            & \textbf{1.0}$_{\pm0.0}$       & 0.8501$_{\pm0.0061}$                           & \textbf{1.0}$_{\pm0.0}$       \\
InsectWingbeatSound            & 0.5066$_{\pm0.0066}$                           & \textbf{0.6158}$_{\pm0.0037}$ & 0.519$_{\pm0.0044}$                            \\
\midrule
Blink                          & 0.6926$_{\pm0.0156}$                           & 0.9911$_{\pm0.0022}$                           & \textbf{0.9993}$_{\pm0.0013}$ \\
EMOPain                        & \textbf{0.8836}$_{\pm0.0016}$ & 0.8432$_{\pm0.0091}$                           & 0.8385$_{\pm0.0016}$                           \\
MotionSenseHAR                 & 0.9887$_{\pm0.0}$                              & 0.9673$_{\pm0.0022}$                           & \textbf{0.9975}$_{\pm0.0022}$\\
SharePriceIncrease             & \textbf{0.6932}$_{\pm0.0006}$ & 0.6832$_{\pm0.0082}$                           & 0.6836$_{\pm0.0049}$                           \\
\midrule
ArticularyWordRecognition      & \textbf{0.9933}$_{\pm0.0}$    & 0.98$_{\pm0.0}$                                & 0.993$_{\pm0.003}$                             \\
BasicMotions                   & \textbf{1.0}$_{\pm0.0}$       & 0.992$_{\pm0.014}$                             & \textbf{1.0}$_{\pm0.0}$       \\
CharacterTrajectories          & 0.9649$_{\pm0.0038}$                           & \textbf{0.97}$_{\pm0.002}$    & 0.94$_{\pm0.001}$                              \\
Cricket                        & 0.9907$_{\pm0.008}$                            & 0.977$_{\pm0.008}$                             & \textbf{1.0}$_{\pm0.0}$       \\
DuckDuckGeese                  & 0.4267$_{\pm0.0503}$                           & \textbf{0.433}$_{\pm0.031}$   & 0.407$_{\pm0.031}$                             \\
ERing                          & \textbf{0.9716}$_{\pm0.0057}$ & 0.969$_{\pm0.008}$                             & 0.941$_{\pm0.01}$                              \\
EigenWorms                     & \textbf{0.7786}$_{\pm0.0202}$ & 0.735$_{\pm0.016}$                             & 0.753$_{\pm0.016}$                             \\
Epilepsy                       & \textbf{1.0}$_{\pm0.0}$       & 0.988$_{\pm0.004}$                             & 0.995$_{\pm0.004}$                             \\
EthanolConcentration           & \textbf{0.3942}$_{\pm0.0158}$ & 0.278$_{\pm0.008}$                             & 0.27$_{\pm0.01}$                               \\
FaceDetection                  & \textbf{0.5581}$_{\pm0.0077}$ & 0.544$_{\pm0.011}$                             & 0.526$_{\pm0.002}$                             \\
FingerMovements                & 0.5133$_{\pm0.0153}$                           & 0.497$_{\pm0.023}$                             & \textbf{0.54}$_{\pm0.035}$    \\
HandMovementDirection          & 0.3108$_{\pm0.0234}$                           & \textbf{0.315}$_{\pm0.008}$   & 0.212$_{\pm0.041}$                             \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\hfill
\begin{minipage}{0.5\textwidth}
{\scalebox{\scalefactorzeroshot}{
\centering
\begin{tabular}{l|lll}
\toprule
                                & NuTime & MOMENT                                          & Mantis  \\
\midrule
ItalyPowerDemand               & 0.8698$_{\pm0.007}$                            & \textbf{0.9498}$_{\pm0.0006}$ & 0.9077$_{\pm0.0035}$                           \\
LargeKitchenAppliances         & 0.7227$_{\pm0.0027}$                           & 0.7333$_{\pm0.0071}$                           & \textbf{0.7804}$_{\pm0.0041}$ \\
Lightning2                     & 0.6885$_{\pm0.0164}$                           & 0.7377$_{\pm0.0328}$                           & \textbf{0.8033}$_{\pm0.0}$    \\
Lightning7                     & 0.6895$_{\pm0.0158}$                           & 0.6758$_{\pm0.0209}$                           & \textbf{0.7763}$_{\pm0.0285}$ \\
Mallat                         & 0.8304$_{\pm0.0025}$                           & 0.859$_{\pm0.0111}$                            & \textbf{0.8903}$_{\pm0.0137}$ \\
Meat                           & 0.8889$_{\pm0.0192}$                           & \textbf{0.9444}$_{\pm0.0096}$ & 0.9389$_{\pm0.0096}$                           \\
MedicalImages                  & 0.7044$_{\pm0.0027}$                           & 0.6939$_{\pm0.0062}$                           & \textbf{0.7079}$_{\pm0.0035}$ \\
MelbournePedestrian            & \textbf{0.912}$_{\pm0.0045}$  & 0.8662$_{\pm0.0047}$                           & 0.9016$_{\pm0.0031}$                           \\
MiddlePhalanxOutlineAgeGroup   & \textbf{0.6169}$_{\pm0.0065}$ & 0.5779$_{\pm0.0065}$                           & 0.5801$_{\pm0.0099}$                           \\
MiddlePhalanxOutlineCorrect    & 0.7858$_{\pm0.0099}$                           & \textbf{0.8625}$_{\pm0.006}$  & 0.8099$_{\pm0.0099}$                           \\
MiddlePhalanxTW                & 0.5238$_{\pm0.0037}$                           & \textbf{0.5952}$_{\pm0.0037}$ & 0.5368$_{\pm0.0099}$                           \\
MixedShapesRegularTrain        & 0.9392$_{\pm0.0013}$                           & 0.9124$_{\pm0.0023}$                           & \textbf{0.943}$_{\pm0.0044}$  \\
MixedShapesSmallTrain          & \textbf{0.9061}$_{\pm0.0029}$ & 0.8389$_{\pm0.0041}$                           & 0.8961$_{\pm0.0004}$                           \\
MoteStrain                     & \textbf{0.9462}$_{\pm0.0032}$ & 0.8914$_{\pm0.0083}$                           & 0.9137$_{\pm0.0136}$                           \\
NonInvasiveFetalECGThorax1     & 0.7696$_{\pm0.0049}$                           & \textbf{0.8887}$_{\pm0.0035}$ & 0.6222$_{\pm0.0037}$                           \\
NonInvasiveFetalECGThorax2     & 0.811$_{\pm0.0016}$                            & \textbf{0.9138}$_{\pm0.0006}$ & 0.6872$_{\pm0.0025}$                           \\
OSULeaf                        & 0.7975$_{\pm0.0072}$                           & 0.7355$_{\pm0.0041}$                           & \textbf{0.8747}$_{\pm0.0104}$ \\
OliveOil                       & 0.7111$_{\pm0.0192}$                           & 0.9$_{\pm0.0}$                                 & \textbf{0.9333}$_{\pm0.0}$    \\
PLAID                          & 0.7933$_{\pm0.0113}$                           & 0.7312$_{\pm0.0088}$                           & \textbf{0.8181}$_{\pm0.0047}$ \\
PhalangesOutlinesCorrect       & 0.7743$_{\pm0.0041}$                           & \textbf{0.8248}$_{\pm0.0007}$ & 0.7786$_{\pm0.0042}$                           \\
Phoneme                        & 0.2802$_{\pm0.0044}$                           & 0.2751$_{\pm0.0062}$                           & \textbf{0.323}$_{\pm0.0034}$  \\
PickupGestureWiimoteZ          & 0.6933$_{\pm0.0808}$                           & 0.68$_{\pm0.06}$                               & \textbf{0.74}$_{\pm0.02}$     \\
PigAirwayPressure              & 0.3782$_{\pm0.01}$                             & 0.1186$_{\pm0.0028}$                           & \textbf{0.484}$_{\pm0.0147}$  \\
PigArtPressure                 & \textbf{0.9391}$_{\pm0.0028}$ & 0.6106$_{\pm0.0048}$                           & 0.9103$_{\pm0.0028}$                           \\
PigCVP                         & \textbf{0.8381}$_{\pm0.0242}$ & 0.609$_{\pm0.0373}$                            & 0.7837$_{\pm0.0127}$                           \\
Plane                          & 0.9937$_{\pm0.0055}$                           & 0.9841$_{\pm0.0145}$                           & \textbf{1.0}$_{\pm0.0}$       \\
PowerCons                      & 0.9352$_{\pm0.0032}$                           & \textbf{0.9463}$_{\pm0.0032}$ & 0.9093$_{\pm0.0032}$                           \\
ProximalPhalanxOutlineAgeGroup & \textbf{0.8537}$_{\pm0.0049}$ & 0.839$_{\pm0.0049}$                            & \textbf{0.8537}$_{\pm0.0049}$ \\
ProximalPhalanxOutlineCorrect  & 0.8385$_{\pm0.0034}$                           & \textbf{0.8751}$_{\pm0.0052}$ & 0.8202$_{\pm0.0086}$                           \\
ProximalPhalanxTW              & 0.8065$_{\pm0.0056}$                           & \textbf{0.8114}$_{\pm0.0028}$ & 0.7691$_{\pm0.0028}$                           \\
RefrigerationDevices           & \textbf{0.5564}$_{\pm0.0041}$ & 0.536$_{\pm0.0046}$                            & 0.504$_{\pm0.0122}$                            \\
Rock                           & 0.6067$_{\pm0.0306}$                           & \textbf{0.84}$_{\pm0.02}$     & 0.7133$_{\pm0.0115}$                           \\
ScreenType                     & \textbf{0.5324}$_{\pm0.0077}$ & 0.4436$_{\pm0.0178}$                           & 0.4649$_{\pm0.0134}$                           \\
SemgHandGenderCh2              & 0.8928$_{\pm0.0042}$                           & 0.8028$_{\pm0.0079}$                           & \textbf{0.9189}$_{\pm0.0086}$ \\
SemgHandMovementCh2            & 0.72$_{\pm0.0038}$                             & 0.5237$_{\pm0.0013}$                           & \textbf{0.797}$_{\pm0.0056}$  \\
SemgHandSubjectCh2             & 0.7741$_{\pm0.0134}$                           & 0.6815$_{\pm0.0026}$                           & \textbf{0.8622}$_{\pm0.0135}$ \\
ShakeGestureWiimoteZ           & \textbf{0.9267}$_{\pm0.0115}$ & 0.8533$_{\pm0.0115}$                           & 0.8867$_{\pm0.0115}$                           \\
ShapeletSim                    & 0.8833$_{\pm0.0111}$                           & \textbf{0.9648}$_{\pm0.0064}$ & 0.9278$_{\pm0.0111}$                           \\
ShapesAll                      & 0.8194$_{\pm0.0025}$                           & \textbf{0.8239}$_{\pm0.0092}$ & 0.8194$_{\pm0.0054}$                           \\
SmallKitchenAppliances         & 0.8027$_{\pm0.0071}$                           & 0.72$_{\pm0.0141}$                             & \textbf{0.8089}$_{\pm0.0081}$ \\
SmoothSubspace                 & 0.8933$_{\pm0.0067}$                           & \textbf{0.92}$_{\pm0.0133}$   & 0.9067$_{\pm0.0115}$                           \\
SonyAIBORobotSurface1          & 0.7987$_{\pm0.0044}$                           & \textbf{0.8087}$_{\pm0.006}$  & 0.787$_{\pm0.0294}$                            \\
SonyAIBORobotSurface2          & 0.8297$_{\pm0.0034}$                           & 0.8353$_{\pm0.0106}$                           & \textbf{0.8552}$_{\pm0.0168}$ \\
StarLightCurves                & \textbf{0.9792}$_{\pm0.0002}$ & 0.9734$_{\pm0.0004}$                           & 0.9759$_{\pm0.0005}$                           \\
Strawberry                     & 0.9378$_{\pm0.0072}$                           & \textbf{0.9604}$_{\pm0.0016}$ & 0.9514$_{\pm0.0027}$                           \\
SwedishLeaf                    & 0.9205$_{\pm0.0065}$                           & 0.9205$_{\pm0.0051}$                           & \textbf{0.9275}$_{\pm0.0009}$ \\
Symbols                        & 0.9407$_{\pm0.0126}$                           & 0.938$_{\pm0.0126}$                            & \textbf{0.9698}$_{\pm0.0056}$ \\
SyntheticControl               & 0.9667$_{\pm0.0033}$                           & 0.9433$_{\pm0.0}$                              & \textbf{0.9767}$_{\pm0.0067}$ \\
ToeSegmentation1               & 0.8596$_{\pm0.0044}$                           & 0.924$_{\pm0.0127}$                            & \textbf{0.9635}$_{\pm0.0067}$ \\
ToeSegmentation2               & 0.7256$_{\pm0.016}$                            & 0.8462$_{\pm0.0077}$                           & \textbf{0.9282}$_{\pm0.0044}$ \\
Trace                          & \textbf{1.0}$_{\pm0.0}$       & 0.99$_{\pm0.0}$                                & \textbf{1.0}$_{\pm0.0}$       \\
TwoLeadECG                     & 0.8712$_{\pm0.0303}$                           & 0.9649$_{\pm0.0116}$                           & \textbf{0.9962}$_{\pm0.0005}$ \\
TwoPatterns                    & 0.8414$_{\pm0.0041}$                           & \textbf{0.8919}$_{\pm0.0079}$ & 0.8802$_{\pm0.0079}$                           \\
UMD                            & 0.9329$_{\pm0.0223}$                           & 0.9699$_{\pm0.004}$                            & \textbf{0.9722}$_{\pm0.0069}$ \\
UWaveGestureLibraryAll         & 0.8773$_{\pm0.0028}$                           & \textbf{0.8975}$_{\pm0.0021}$ & 0.8458$_{\pm0.0057}$                           \\
UWaveGestureLibraryX           & \textbf{0.8053}$_{\pm0.0007}$ & 0.7829$_{\pm0.0071}$                           & 0.7696$_{\pm0.0028}$                           \\
UWaveGestureLibraryY           & \textbf{0.7338}$_{\pm0.0032}$ & 0.7022$_{\pm0.0026}$                           & 0.6874$_{\pm0.0022}$                           \\
UWaveGestureLibraryZ           & \textbf{0.7427}$_{\pm0.0036}$ & 0.73$_{\pm0.002}$                              & 0.7324$_{\pm0.0036}$                           \\
Wafer                          & \textbf{0.9933}$_{\pm0.0006}$ & 0.9867$_{\pm0.0003}$                           & 0.9903$_{\pm0.0003}$                           \\
Wine                           & 0.7469$_{\pm0.0107}$                           & \textbf{0.8457}$_{\pm0.0283}$ & 0.7901$_{\pm0.0107}$                           \\
WordSynonyms                   & 0.5199$_{\pm0.0127}$                           & \textbf{0.6003}$_{\pm0.0078}$ & 0.5502$_{\pm0.0081}$                           \\
Worms                          & \textbf{0.7403}$_{\pm0.0}$    & 0.7056$_{\pm0.015}$                            & 0.6537$_{\pm0.027}$                            \\
WormsTwoClass                  & 0.7835$_{\pm0.0075}$                           & 0.7706$_{\pm0.0075}$                           & \textbf{0.8139}$_{\pm0.0198}$ \\
Yoga                           & 0.8219$_{\pm0.0015}$                           & \textbf{0.8264}$_{\pm0.003}$  & 0.815$_{\pm0.0012}$                            \\
\midrule
Handwriting                    & 0.2035$_{\pm0.0082}$                           & 0.236$_{\pm0.005}$                             & \textbf{0.339}$_{\pm0.01}$    \\
Heartbeat                      & 0.7756$_{\pm0.0}$                              & 0.727$_{\pm0.005}$                             & \textbf{0.798}$_{\pm0.017}$   \\
InsectWingbeatSubset           & \textbf{0.611}$_{\pm0.0066}$  & 0.243$_{\pm0.011}$                             & 0.607$_{\pm0.007}$                             \\
JapaneseVowels                 & 0.9405$_{\pm0.0072}$                           & 0.88$_{\pm0.009}$                              & \textbf{0.963}$_{\pm0.006}$   \\
LSST                           & 0.5668$_{\pm0.0068}$                           & \textbf{0.621}$_{\pm0.001}$   & 0.605$_{\pm0.002}$                             \\
Libras                         & 0.8852$_{\pm0.0064}$                           & 0.85$_{\pm0.02}$                               & \textbf{0.898}$_{\pm0.008}$   \\
MotorImagery                   & 0.5367$_{\pm0.0153}$                           & 0.547$_{\pm0.055}$                             & \textbf{0.55}$_{\pm0.036}$    \\
NATOPS                         & 0.8426$_{\pm0.014}$                            & 0.822$_{\pm0.024}$                             & \textbf{0.907}$_{\pm0.013}$   \\
PEMS-SF                        & 0.9884$_{\pm0.0}$                              & \textbf{1.0}$_{\pm0.0}$       & 0.985$_{\pm0.013}$                             \\
PhonemeSpectra                 & 0.2588$_{\pm0.0065}$                           & 0.215$_{\pm0.001}$                             & \textbf{0.273}$_{\pm0.008}$   \\
RacketSports                   & 0.9101$_{\pm0.01}$                             & 0.82$_{\pm0.01}$                               & \textbf{0.923}$_{\pm0.004}$   \\
SelfRegulationSCP1             & 0.7702$_{\pm0.012}$                            & 0.754$_{\pm0.012}$                             & \textbf{0.804}$_{\pm0.011}$   \\
SelfRegulationSCP2             & \textbf{0.5}$_{\pm0.0242}$    & 0.496$_{\pm0.02}$                              & 0.476$_{\pm0.045}$                             \\
SpokenArabicDigits             & 0.8968$_{\pm0.0032}$                           & \textbf{0.935}$_{\pm0.002}$   & 0.839$_{\pm0.005}$                             \\
UWaveGestureLibrary            & \textbf{0.8792}$_{\pm0.0018}$ & 0.873$_{\pm0.011}$                             & 0.814$_{\pm0.01}$                              \\
\midrule
\textit{\textbf{Best Count}} & 38 & 53 & \textbf{74} \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\end{table}



\newcommand{\scalefactorsotaft}{0.46}
\begin{table}[ht!]
\caption{Comparison of different SOTA foundation models in the case of fine-tuning. regimes for Mantis on the \texttt{151-D} benchmark. The best epoch accuracy is averaged over 3 random seeds and reported with the standard deviation.}
\label{tab:sota-fine-tuning}
\begin{minipage}{0.5\textwidth}
{\scalebox{\scalefactorsotaft}{
\begin{tabular}{l|lllll}
\toprule
                               & UniTS                                          & GPT4TS                                         & NuTime                                         & MOMENT                                         & Mantis                                           \\
\midrule
ACSF1                          & 0.6933$_{\pm0.0351}$                           & 0.49$_{\pm0.0265}$                             & 0.6733$_{\pm0.0321}$                           & 0.6033$_{\pm0.0379}$                           & \textbf{0.7433}$_{\pm0.0115}$ \\
Adiac                          & 0.5772$_{\pm0.0074}$                           & 0.3572$_{\pm0.0059}$                           & 0.7349$_{\pm0.0141}$                           & 0.5823$_{\pm0.0296}$                           & \textbf{0.7766}$_{\pm0.003}$  \\
AllGestureWiimoteX             & 0.469$_{\pm0.0224}$                            & 0.4895$_{\pm0.0105}$                           & 0.6386$_{\pm0.0038}$                           & 0.7$_{\pm0.0103}$                              & \textbf{0.7619}$_{\pm0.005}$  \\
AllGestureWiimoteY             & 0.5338$_{\pm0.0242}$                           & 0.5062$_{\pm0.0116}$                           & 0.7152$_{\pm0.0103}$                           & 0.7081$_{\pm0.0343}$                           & \textbf{0.7948}$_{\pm0.0097}$ \\
AllGestureWiimoteZ             & 0.4595$_{\pm0.0159}$                           & 0.4719$_{\pm0.0119}$                           & 0.6419$_{\pm0.0058}$                           & 0.6976$_{\pm0.0218}$                           & \textbf{0.73}$_{\pm0.01}$     \\
ArrowHead                      & 0.6895$_{\pm0.0087}$                           & 0.7638$_{\pm0.0033}$                           & \textbf{0.8305}$_{\pm0.0033}$ & 0.779$_{\pm0.0682}$                            & 0.821$_{\pm0.0389}$                            \\
BME                            & 0.8867$_{\pm0.1048}$                           & 0.9444$_{\pm0.0102}$                           & \textbf{1.0}$_{\pm0.0}$       & 0.98$_{\pm0.0231}$                             & 0.9956$_{\pm0.0077}$                           \\
Beef                           & 0.6667$_{\pm0.0333}$                           & 0.8$_{\pm0.0577}$                              & \textbf{0.8222}$_{\pm0.0192}$ & 0.8$_{\pm0.0577}$                              & 0.7$_{\pm0.0333}$                              \\
BeetleFly                      & 0.7167$_{\pm0.0289}$                           & 0.8167$_{\pm0.0289}$                           & \textbf{0.8833}$_{\pm0.0764}$ & 0.8$_{\pm0.15}$                                & \textbf{0.8833}$_{\pm0.0764}$ \\
BirdChicken                    & 0.6167$_{\pm0.1155}$                           & 0.6167$_{\pm0.0289}$                           & 0.85$_{\pm0.05}$                               & 0.7667$_{\pm0.0289}$                           & \textbf{0.9}$_{\pm0.05}$      \\
CBF                            & 0.8507$_{\pm0.0192}$                           & 0.8596$_{\pm0.0083}$                           & 0.9652$_{\pm0.0046}$                           & 0.9767$_{\pm0.0172}$                           & \textbf{0.9848}$_{\pm0.0074}$ \\
Car                            & 0.6278$_{\pm0.0509}$                           & 0.8$_{\pm0.0167}$                              & 0.8444$_{\pm0.0096}$                           & \textbf{0.8778}$_{\pm0.0419}$ & 0.8722$_{\pm0.0096}$                           \\
Chinatown                      & \textbf{0.9776}$_{\pm0.0045}$ & 0.9718$_{\pm0.0089}$                           & 0.9738$_{\pm0.0}$                              & 0.9708$_{\pm0.0127}$                           & 0.9718$_{\pm0.0017}$                           \\
ChlorineConcentration          & 0.6424$_{\pm0.0203}$                           & 0.5733$_{\pm0.0091}$                           & 0.6718$_{\pm0.008}$                            & 0.6289$_{\pm0.0178}$                           & \textbf{0.6971}$_{\pm0.0112}$ \\
CinCECGTorso                   & 0.585$_{\pm0.0324}$                            & 0.793$_{\pm0.0353}$                            & \textbf{0.9302}$_{\pm0.0067}$ & 0.743$_{\pm0.008}$                             & 0.7814$_{\pm0.0173}$                           \\
Coffee                         & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & 0.9881$_{\pm0.0206}$                           & \textbf{1.0}$_{\pm0.0}$       \\
Computers                      & 0.6093$_{\pm0.0046}$                           & 0.62$_{\pm0.0106}$                             & \textbf{0.812}$_{\pm0.0174}$  & 0.6747$_{\pm0.0295}$                           & 0.7813$_{\pm0.0162}$                           \\
CricketX                       & 0.5145$_{\pm0.0074}$                           & 0.5231$_{\pm0.0143}$                           & 0.7453$_{\pm0.0039}$                           & 0.7915$_{\pm0.0192}$                           & \textbf{0.7966}$_{\pm0.009}$  \\
CricketY                       & 0.541$_{\pm0.0194}$                            & 0.5419$_{\pm0.009}$                            & 0.7479$_{\pm0.0104}$                           & 0.7487$_{\pm0.0271}$                           & \textbf{0.806}$_{\pm0.0141}$  \\
CricketZ                       & 0.5521$_{\pm0.0292}$                           & 0.5496$_{\pm0.0039}$                           & 0.7701$_{\pm0.0246}$                           & \textbf{0.8068}$_{\pm0.0218}$ & 0.8043$_{\pm0.0415}$                           \\
Crop                           & 0.7184$_{\pm0.0039}$                           & 0.7311$_{\pm0.0033}$                           & \textbf{0.7574}$_{\pm0.0022}$ & 0.717$_{\pm0.0071}$                            & 0.7444$_{\pm0.0039}$                           \\
DiatomSizeReduction            & 0.9118$_{\pm0.0259}$                           & 0.9401$_{\pm0.0361}$                           & 0.9314$_{\pm0.0425}$                           & 0.9325$_{\pm0.0576}$                           & \textbf{0.9684}$_{\pm0.0136}$ \\
DistalPhalanxOutlineAgeGroup   & 0.7434$_{\pm0.0083}$                           & 0.7218$_{\pm0.0042}$                           & 0.7386$_{\pm0.015}$                            & 0.7362$_{\pm0.0272}$                           & \textbf{0.7698}$_{\pm0.0259}$ \\
DistalPhalanxOutlineCorrect    & 0.75$_{\pm0.0166}$                             & 0.6932$_{\pm0.0084}$                           & 0.7705$_{\pm0.0302}$                           & 0.7452$_{\pm0.02}$                             & \textbf{0.7717}$_{\pm0.0158}$ \\
DistalPhalanxTW                & 0.6691$_{\pm0.0125}$                           & \textbf{0.6978}$_{\pm0.0125}$ & 0.6978$_{\pm0.0216}$                           & 0.6451$_{\pm0.03}$                             & 0.6954$_{\pm0.0231}$                           \\
DodgerLoopDay                  & 0.45$_{\pm0.0331}$                             & 0.5542$_{\pm0.0564}$                           & 0.5458$_{\pm0.0688}$                           & 0.5292$_{\pm0.0641}$                           & \textbf{0.625}$_{\pm0.025}$   \\
DodgerLoopGame                 & 0.8309$_{\pm0.0233}$                           & 0.8551$_{\pm0.0192}$                           & 0.8213$_{\pm0.0649}$                           & 0.8599$_{\pm0.0233}$                           & \textbf{0.8841}$_{\pm0.0145}$ \\
DodgerLoopWeekend              & 0.9638$_{\pm0.0072}$                           & \textbf{0.9855}$_{\pm0.0}$    & 0.9783$_{\pm0.0126}$                           & 0.9783$_{\pm0.0126}$                           & 0.9783$_{\pm0.0}$                              \\
ECG200                         & 0.8767$_{\pm0.0611}$                           & 0.8467$_{\pm0.0551}$                           & 0.87$_{\pm0.01}$                               & \textbf{0.8867}$_{\pm0.0231}$ & 0.8567$_{\pm0.0058}$                           \\
ECG5000                        & 0.9314$_{\pm0.0042}$                           & \textbf{0.9408}$_{\pm0.0019}$ & 0.9379$_{\pm0.0001}$                           & 0.9325$_{\pm0.0003}$                           & 0.9335$_{\pm0.0081}$                           \\
ECGFiveDays                    & 0.8459$_{\pm0.054}$                            & 0.8784$_{\pm0.076}$                            & \textbf{0.9621}$_{\pm0.0084}$ & 0.7944$_{\pm0.0373}$                           & 0.9148$_{\pm0.0292}$                           \\
Earthquakes                    & 0.7386$_{\pm0.03}$                             & 0.7338$_{\pm0.0072}$                           & 0.7482$_{\pm0.0}$                              & \textbf{0.7578}$_{\pm0.0166}$ & 0.7482$_{\pm0.0}$                              \\
ElectricDevices                & 0.6194$_{\pm0.0046}$                           & 0.5776$_{\pm0.0173}$                           & 0.7112$_{\pm0.0109}$                           & 0.6666$_{\pm0.0204}$                           & \textbf{0.7454}$_{\pm0.0049}$ \\
FaceAll                        & 0.7335$_{\pm0.0343}$                           & 0.7247$_{\pm0.0042}$                           & \textbf{0.8385}$_{\pm0.0098}$ & 0.8012$_{\pm0.008}$                            & 0.8308$_{\pm0.0031}$                           \\
FaceFour                       & 0.6515$_{\pm0.0347}$                           & 0.8295$_{\pm0.0301}$                           & 0.9318$_{\pm0.0227}$                           & 0.8371$_{\pm0.0853}$                           & \textbf{0.9773}$_{\pm0.0114}$ \\
FacesUCR                       & 0.7197$_{\pm0.0078}$                           & 0.7932$_{\pm0.0047}$                           & 0.8846$_{\pm0.0127}$                           & 0.835$_{\pm0.0014}$                            & \textbf{0.9148}$_{\pm0.0071}$ \\
FiftyWords                     & 0.6227$_{\pm0.0104}$                           & 0.6615$_{\pm0.0058}$                           & 0.7875$_{\pm0.0083}$                           & 0.7861$_{\pm0.0222}$                           & \textbf{0.8139}$_{\pm0.0083}$ \\
Fish                           & 0.7943$_{\pm0.0396}$                           & 0.8133$_{\pm0.0119}$                           & 0.9524$_{\pm0.0119}$                           & 0.9162$_{\pm0.0201}$                           & \textbf{0.9714}$_{\pm0.0099}$ \\
FordA                          & 0.9202$_{\pm0.0049}$                           & 0.7207$_{\pm0.0798}$                           & 0.9225$_{\pm0.0095}$                           & 0.9202$_{\pm0.0271}$                           & \textbf{0.9343}$_{\pm0.0046}$ \\
FordB                          & 0.7634$_{\pm0.0043}$                           & 0.6107$_{\pm0.0567}$                           & 0.7922$_{\pm0.0126}$                           & \textbf{0.8173}$_{\pm0.0125}$ & 0.7979$_{\pm0.0135}$                           \\
FreezerRegularTrain            & 0.911$_{\pm0.0171}$                            & 0.8884$_{\pm0.0329}$                           & \textbf{0.9942}$_{\pm0.0014}$ & 0.9876$_{\pm0.0056}$                           & 0.9927$_{\pm0.0041}$                           \\
FreezerSmallTrain              & 0.6713$_{\pm0.012}$                            & 0.6614$_{\pm0.0094}$                           & 0.9537$_{\pm0.029}$                            & 0.8206$_{\pm0.0695}$                           & \textbf{0.9667}$_{\pm0.0098}$ \\
Fungi                          & 0.6272$_{\pm0.0306}$                           & 0.7061$_{\pm0.0124}$                           & 0.7294$_{\pm0.0135}$                           & 0.69$_{\pm0.035}$                              & \textbf{0.7778}$_{\pm0.0031}$ \\
GestureMidAirD1                & 0.5256$_{\pm0.0347}$                           & 0.5615$_{\pm0.0353}$                           & 0.741$_{\pm0.0222}$                            & 0.6487$_{\pm0.0311}$                           & \textbf{0.7692}$_{\pm0.0407}$ \\
GestureMidAirD2                & 0.4051$_{\pm0.0355}$                           & 0.4846$_{\pm0.0428}$                           & 0.6513$_{\pm0.0347}$                           & 0.5615$_{\pm0.0077}$                           & \textbf{0.6744}$_{\pm0.0118}$ \\
GestureMidAirD3                & 0.2949$_{\pm0.0387}$                           & 0.3308$_{\pm0.04}$                             & \textbf{0.4359}$_{\pm0.0089}$ & 0.3615$_{\pm0.0277}$                           & 0.4077$_{\pm0.0231}$                           \\
GesturePebbleZ1                & 0.7074$_{\pm0.032}$                            & 0.8217$_{\pm0.0034}$                           & 0.8953$_{\pm0.0058}$                           & 0.9109$_{\pm0.0089}$                           & \textbf{0.9322}$_{\pm0.0089}$ \\
GesturePebbleZ2                & 0.7089$_{\pm0.0127}$                           & 0.7553$_{\pm0.0159}$                           & 0.8861$_{\pm0.0219}$                           & 0.8861$_{\pm0.0063}$                           & \textbf{0.9241}$_{\pm0.0219}$ \\
GunPoint                       & 0.9089$_{\pm0.0252}$                           & 0.8733$_{\pm0.0067}$                           & 0.9933$_{\pm0.0}$                              & 0.9867$_{\pm0.0115}$                           & \textbf{1.0}$_{\pm0.0}$       \\
GunPointAgeSpan                & 0.9262$_{\pm0.0037}$                           & 0.8755$_{\pm0.0174}$                           & 0.9916$_{\pm0.0018}$                           & 0.9662$_{\pm0.0048}$                           & \textbf{0.9979}$_{\pm0.0037}$ \\
GunPointMaleVersusFemale       & 0.9905$_{\pm0.0032}$                           & 0.961$_{\pm0.0391}$                            & 0.9989$_{\pm0.0018}$                           & 0.9916$_{\pm0.0048}$                           & \textbf{1.0}$_{\pm0.0}$       \\
GunPointOldVersusYoung         & 0.9545$_{\pm0.0183}$                           & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & 0.982$_{\pm0.0048}$                            & \textbf{1.0}$_{\pm0.0}$       \\
Ham                            & 0.7556$_{\pm0.011}$                            & 0.6698$_{\pm0.024}$                            & 0.7238$_{\pm0.019}$                            & \textbf{0.7746}$_{\pm0.0306}$ & 0.7238$_{\pm0.0415}$                           \\
Haptics                        & 0.4069$_{\pm0.0315}$                           & 0.4426$_{\pm0.0167}$                           & 0.487$_{\pm0.0142}$                            & 0.4167$_{\pm0.0179}$                           & \textbf{0.5227}$_{\pm0.0149}$ \\
Herring                        & 0.5677$_{\pm0.113}$                            & \textbf{0.6458}$_{\pm0.0325}$ & \textbf{0.6458}$_{\pm0.0393}$ & 0.5677$_{\pm0.0325}$                           & 0.6354$_{\pm0.0325}$                           \\
HouseTwenty                    & 0.8347$_{\pm0.0097}$                           & 0.8123$_{\pm0.0049}$                           & 0.9272$_{\pm0.0097}$                           & 0.8992$_{\pm0.0084}$                           & \textbf{0.9804}$_{\pm0.0049}$ \\
InsectEPGRegularTrain          & 0.7068$_{\pm0.0106}$                           & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & 0.9331$_{\pm0.0267}$                           & \textbf{1.0}$_{\pm0.0}$       \\
\midrule
Blink                          & 0.9474$_{\pm0.02}$                             & 0.9193$_{\pm0.0161}$                           & 0.9163$_{\pm0.0334}$                           & 0.9963$_{\pm0.0013}$                           & \textbf{0.9978}$_{\pm0.0}$    \\
SharePriceIncrease             & 0.6425$_{\pm0.0016}$                           & 0.6763$_{\pm0.015}$                            & 0.6446$_{\pm0.0237}$                           & \textbf{0.6863}$_{\pm0.0}$    & 0.6408$_{\pm0.0187}$ \\
\midrule
ArticularyWordRecognition      & 0.9344$_{\pm0.0069}$                           & 0.9633$_{\pm0.0058}$                           & 0.9833$_{\pm0.0033}$                           & 0.9733$_{\pm0.0033}$                           & \textbf{0.9944}$_{\pm0.0019}$ \\
BasicMotions                   & 0.85$_{\pm0.025}$                              & 0.8833$_{\pm0.0144}$                           & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
CharacterTrajectories          & 0.9666$_{\pm0.0014}$                           & 0.9731$_{\pm0.0056}$                           & 0.98$_{\pm0.0036}$                             & 0.9791$_{\pm0.0028}$                           & \textbf{0.9893}$_{\pm0.0008}$ \\
Cricket                        & 0.8472$_{\pm0.0605}$                           & 0.9213$_{\pm0.008}$                            & 0.9907$_{\pm0.008}$                            & 0.9491$_{\pm0.016}$                            & \textbf{0.9954}$_{\pm0.008}$  \\
ERing                          & 0.779$_{\pm0.0483}$                            & 0.9074$_{\pm0.0098}$                           & 0.9506$_{\pm0.0077}$                           & 0.9358$_{\pm0.0077}$                           & \textbf{0.9827}$_{\pm0.0043}$ \\
Epilepsy                       & 0.9348$_{\pm0.0192}$                           & 0.8092$_{\pm0.0233}$                           & 0.9952$_{\pm0.0042}$                           & 0.9976$_{\pm0.0042}$                           & \textbf{1.0}$_{\pm0.0}$       \\
HandMovementDirection          & 0.3378$_{\pm0.027}$                            & \textbf{0.4685}$_{\pm0.068}$  & 0.3153$_{\pm0.0281}$                           & 0.3108$_{\pm0.0358}$                           & 0.3108$_{\pm0.0702}$                           \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\hfill
\begin{minipage}{0.5\textwidth}
{\scalebox{\scalefactorsotaft}{
\begin{tabular}{l|lllll}
\toprule
                               & UniTS                                          & GPT4TS                                         & NuTime                                         & MOMENT                                         & Mantis                                           \\
\midrule
InsectEPGSmallTrain            & 0.6667$_{\pm0.0145}$                           & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & 0.8969$_{\pm0.0023}$                           & \textbf{1.0}$_{\pm0.0}$       \\
InsectWingbeatSound            & 0.5726$_{\pm0.016}$                            & 0.6165$_{\pm0.0069}$                           & \textbf{0.619}$_{\pm0.0048}$  & 0.6019$_{\pm0.0034}$                           & 0.5961$_{\pm0.0051}$                           \\
ItalyPowerDemand               & 0.964$_{\pm0.0019}$                            & 0.9637$_{\pm0.0011}$                           & \textbf{0.9666}$_{\pm0.002}$  & 0.9624$_{\pm0.0006}$                           & 0.9624$_{\pm0.0015}$                           \\
LargeKitchenAppliances         & 0.6942$_{\pm0.0178}$                           & 0.5156$_{\pm0.0285}$                           & 0.824$_{\pm0.0116}$                            & \textbf{0.8693}$_{\pm0.0232}$ & 0.8516$_{\pm0.0111}$                           \\
Lightning2                     & 0.7486$_{\pm0.0663}$                           & 0.7268$_{\pm0.025}$                            & 0.776$_{\pm0.025}$                             & 0.7978$_{\pm0.025}$                            & \textbf{0.8087}$_{\pm0.0189}$ \\
Lightning7                     & 0.5571$_{\pm0.0209}$                           & 0.5982$_{\pm0.0079}$                           & 0.7032$_{\pm0.0519}$                           & \textbf{0.7717}$_{\pm0.0209}$ & 0.7397$_{\pm0.0362}$                           \\
Mallat                         & 0.8736$_{\pm0.011}$                            & 0.92$_{\pm0.0258}$                             & \textbf{0.9508}$_{\pm0.0191}$ & 0.9205$_{\pm0.026}$                            & 0.9404$_{\pm0.0072}$                           \\
Meat                           & 0.9111$_{\pm0.0255}$                           & 0.6944$_{\pm0.2269}$                           & \textbf{0.9611}$_{\pm0.0255}$ & 0.6444$_{\pm0.0674}$                           & 0.9333$_{\pm0.0289}$                           \\
MedicalImages                  & 0.6553$_{\pm0.0026}$                           & 0.611$_{\pm0.0201}$                            & 0.7513$_{\pm0.0149}$                           & 0.7206$_{\pm0.029}$                            & \textbf{0.7662}$_{\pm0.0178}$ \\
MelbournePedestrian            & 0.8711$_{\pm0.0025}$                           & 0.9351$_{\pm0.0037}$                           & \textbf{0.9601}$_{\pm0.0019}$ & 0.8795$_{\pm0.0055}$                           & 0.9552$_{\pm0.001}$                            \\
MiddlePhalanxOutlineAgeGroup   & 0.6039$_{\pm0.0065}$                           & 0.6104$_{\pm0.0065}$                           & 0.5368$_{\pm0.0198}$                           & \textbf{0.6126}$_{\pm0.0327}$ & 0.5996$_{\pm0.0209}$                           \\
MiddlePhalanxOutlineCorrect    & 0.827$_{\pm0.0241}$                            & 0.6518$_{\pm0.0436}$                           & 0.7938$_{\pm0.0248}$                           & 0.8076$_{\pm0.0034}$                           & \textbf{0.8339}$_{\pm0.0139}$ \\
MiddlePhalanxTW                & 0.5779$_{\pm0.0234}$                           & \textbf{0.5909}$_{\pm0.0}$    & 0.4632$_{\pm0.015}$                            & 0.5606$_{\pm0.0037}$                           & 0.4827$_{\pm0.03}$                             \\
MixedShapesSmallTrain          & 0.7281$_{\pm0.0569}$                           & 0.8115$_{\pm0.0111}$                           & 0.9281$_{\pm0.0054}$                           & 0.8357$_{\pm0.0363}$                           & \textbf{0.9531}$_{\pm0.0038}$ \\
MoteStrain                     & 0.8339$_{\pm0.0081}$                           & 0.8243$_{\pm0.0062}$                           & \textbf{0.9609}$_{\pm0.0037}$ & 0.8341$_{\pm0.0264}$                           & 0.9068$_{\pm0.0174}$                           \\
NonInvasiveFetalECGThorax1     & 0.8879$_{\pm0.0059}$                           & 0.7774$_{\pm0.0152}$                           & \textbf{0.9342}$_{\pm0.0076}$ & 0.7535$_{\pm0.0237}$                           & 0.9086$_{\pm0.0063}$                           \\
NonInvasiveFetalECGThorax2     & 0.9137$_{\pm0.0015}$                           & 0.839$_{\pm0.0098}$                            & \textbf{0.9381}$_{\pm0.0046}$ & 0.7995$_{\pm0.0033}$                           & 0.9216$_{\pm0.0055}$                           \\
OSULeaf                        & 0.5482$_{\pm0.0391}$                           & 0.4669$_{\pm0.018}$                            & 0.8967$_{\pm0.0286}$                           & 0.8017$_{\pm0.0219}$                           & \textbf{0.9642}$_{\pm0.0024}$ \\
OliveOil                       & 0.4778$_{\pm0.0385}$                           & 0.4889$_{\pm0.0385}$                           & 0.7778$_{\pm0.0385}$                           & 0.4667$_{\pm0.0667}$                           & \textbf{0.8889}$_{\pm0.0509}$ \\
PhalangesOutlinesCorrect       & 0.8015$_{\pm0.0037}$                           & 0.6437$_{\pm0.0041}$                           & \textbf{0.8263}$_{\pm0.0031}$ & 0.803$_{\pm0.0047}$                            & 0.8162$_{\pm0.0128}$                           \\
Phoneme                        & 0.1431$_{\pm0.0086}$                           & 0.1466$_{\pm0.0023}$                           & 0.2973$_{\pm0.0081}$                           & 0.2904$_{\pm0.009}$                            & \textbf{0.3214}$_{\pm0.0059}$ \\
PickupGestureWiimoteZ          & 0.56$_{\pm0.02}$                               & 0.7133$_{\pm0.0231}$                           & 0.7267$_{\pm0.0115}$                           & 0.72$_{\pm0.0}$                                & \textbf{0.76}$_{\pm0.0529}$   \\
Plane                          & 0.9524$_{\pm0.0165}$                           & 0.9778$_{\pm0.0055}$                           & \textbf{1.0}$_{\pm0.0}$       & 0.9873$_{\pm0.0145}$                           & \textbf{1.0}$_{\pm0.0}$       \\
PowerCons                      & 0.95$_{\pm0.02}$                               & \textbf{1.0}$_{\pm0.0}$       & 0.9889$_{\pm0.0111}$                           & 0.9167$_{\pm0.0111}$                           & 0.9944$_{\pm0.0096}$                           \\
ProximalPhalanxOutlineAgeGroup & 0.8407$_{\pm0.0157}$                           & 0.8016$_{\pm0.0203}$                           & \textbf{0.8553}$_{\pm0.0102}$ & 0.8455$_{\pm0.0123}$                           & 0.8455$_{\pm0.0246}$                           \\
ProximalPhalanxOutlineCorrect  & 0.8568$_{\pm0.0052}$                           & 0.8179$_{\pm0.0034}$                           & \textbf{0.9072}$_{\pm0.006}$  & 0.8259$_{\pm0.0221}$                           & 0.8763$_{\pm0.0209}$                           \\
ProximalPhalanxTW              & 0.7951$_{\pm0.0098}$                           & 0.7967$_{\pm0.0102}$                           & \textbf{0.8179}$_{\pm0.0056}$ & 0.787$_{\pm0.0102}$                            & 0.7772$_{\pm0.0314}$                           \\
RefrigerationDevices           & 0.4658$_{\pm0.0248}$                           & 0.4453$_{\pm0.0092}$                           & \textbf{0.5511}$_{\pm0.0227}$ & 0.4996$_{\pm0.0336}$                           & 0.4916$_{\pm0.0111}$                           \\
Rock                           & 0.6133$_{\pm0.0945}$                           & 0.5933$_{\pm0.0503}$                           & 0.68$_{\pm0.02}$                               & 0.6733$_{\pm0.0611}$                           & \textbf{0.7133}$_{\pm0.0231}$ \\
ScreenType                     & 0.3556$_{\pm0.0041}$                           & 0.3956$_{\pm0.0126}$                           & \textbf{0.5289}$_{\pm0.0434}$ & 0.4213$_{\pm0.0116}$                           & 0.4782$_{\pm0.0041}$                           \\
ShakeGestureWiimoteZ           & 0.6067$_{\pm0.0416}$                           & 0.6867$_{\pm0.0115}$                           & 0.9133$_{\pm0.0231}$                           & 0.9067$_{\pm0.0115}$                           & \textbf{0.92}$_{\pm0.0}$      \\
ShapeletSim                    & 0.6981$_{\pm0.0651}$                           & 0.5074$_{\pm0.0128}$                           & 0.8852$_{\pm0.0534}$                           & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
ShapesAll                      & 0.67$_{\pm0.012}$                              & 0.6833$_{\pm0.0029}$                           & 0.8856$_{\pm0.0067}$                           & 0.8039$_{\pm0.0108}$                           & \textbf{0.8906}$_{\pm0.0059}$ \\
SmallKitchenAppliances         & 0.6276$_{\pm0.032}$                            & 0.5529$_{\pm0.0171}$                           & 0.7822$_{\pm0.0015}$                           & 0.6756$_{\pm0.0161}$                           & \textbf{0.7929}$_{\pm0.0031}$ \\
SmoothSubspace                 & 0.8156$_{\pm0.0102}$                           & 0.8911$_{\pm0.0038}$                           & 0.9889$_{\pm0.0038}$                           & 0.7733$_{\pm0.0291}$                           & \textbf{0.9978}$_{\pm0.0038}$ \\
SonyAIBORobotSurface1          & 0.721$_{\pm0.0846}$                            & 0.6267$_{\pm0.0215}$                           & \textbf{0.8525}$_{\pm0.0189}$ & 0.7604$_{\pm0.0204}$                           & 0.8142$_{\pm0.0113}$                           \\
SonyAIBORobotSurface2          & 0.829$_{\pm0.0252}$                            & 0.8454$_{\pm0.0205}$                           & 0.8506$_{\pm0.0115}$                           & 0.8765$_{\pm0.0276}$                           & \textbf{0.8996}$_{\pm0.0112}$ \\
Strawberry                     & 0.9577$_{\pm0.0172}$                           & 0.7261$_{\pm0.0788}$                           & \textbf{0.9712}$_{\pm0.0031}$ & 0.9459$_{\pm0.0054}$                           & 0.9667$_{\pm0.0078}$                           \\
SwedishLeaf                    & 0.88$_{\pm0.0085}$                             & 0.8203$_{\pm0.0305}$                           & 0.9573$_{\pm0.0024}$                           & 0.9376$_{\pm0.007}$                            & \textbf{0.9712}$_{\pm0.0042}$ \\
Symbols                        & 0.8211$_{\pm0.0348}$                           & 0.8003$_{\pm0.0243}$                           & 0.9779$_{\pm0.0053}$                           & 0.9481$_{\pm0.0192}$                           & \textbf{0.9889}$_{\pm0.0017}$ \\
SyntheticControl               & 0.95$_{\pm0.0088}$                             & 0.9622$_{\pm0.0117}$                           & 0.9889$_{\pm0.0051}$                           & 0.9889$_{\pm0.0019}$                           & \textbf{0.9944}$_{\pm0.0038}$ \\
ToeSegmentation1               & 0.8012$_{\pm0.0373}$                           & 0.5687$_{\pm0.0051}$                           & 0.9459$_{\pm0.0101}$                           & 0.9284$_{\pm0.0483}$                           & \textbf{0.9664}$_{\pm0.0067}$ \\
ToeSegmentation2               & 0.7974$_{\pm0.016}$                            & 0.6923$_{\pm0.0353}$                           & 0.8974$_{\pm0.0089}$                           & \textbf{0.9308}$_{\pm0.0204}$ & 0.9231$_{\pm0.0077}$                           \\
Trace                          & 0.9467$_{\pm0.0208}$                           & 0.8567$_{\pm0.0577}$                           & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
TwoLeadECG                     & 0.7548$_{\pm0.0388}$                           & 0.7934$_{\pm0.0272}$                           & 0.9104$_{\pm0.0273}$                           & 0.8879$_{\pm0.0509}$                           & \textbf{0.9941}$_{\pm0.0018}$ \\
TwoPatterns                    & 0.9811$_{\pm0.0043}$                           & 0.9676$_{\pm0.0173}$                           & 0.9998$_{\pm0.0001}$                           & 0.9998$_{\pm0.0002}$                           & \textbf{0.9999}$_{\pm0.0001}$ \\
UMD                            & 0.8056$_{\pm0.0751}$                           & 0.9699$_{\pm0.008}$                            & \textbf{1.0}$_{\pm0.0}$       & 0.9815$_{\pm0.02}$                             & 0.9907$_{\pm0.004}$                            \\
UWaveGestureLibraryX           & 0.7635$_{\pm0.0037}$                           & 0.7319$_{\pm0.0069}$                           & 0.8516$_{\pm0.0044}$                           & 0.8062$_{\pm0.0076}$                           & \textbf{0.8679}$_{\pm0.0028}$ \\
UWaveGestureLibraryY           & 0.6663$_{\pm0.0022}$                           & 0.6145$_{\pm0.0027}$                           & 0.7701$_{\pm0.005}$                            & 0.7378$_{\pm0.0127}$                           & \textbf{0.7917}$_{\pm0.0073}$ \\
UWaveGestureLibraryZ           & 0.6903$_{\pm0.0045}$                           & 0.6224$_{\pm0.0217}$                           & 0.7813$_{\pm0.0073}$                           & 0.757$_{\pm0.0158}$                            & \textbf{0.8053}$_{\pm0.0011}$ \\
Wafer                          & 0.9951$_{\pm0.0009}$                           & 0.9948$_{\pm0.0022}$                           & 0.9987$_{\pm0.0003}$                           & 0.9982$_{\pm0.0004}$                           & \textbf{0.9991}$_{\pm0.0003}$ \\
Wine                           & 0.5185$_{\pm0.0321}$                           & 0.5185$_{\pm0.0321}$                           & \textbf{0.8025}$_{\pm0.0466}$ & 0.5$_{\pm0.0}$                                 & 0.6605$_{\pm0.0107}$                           \\
WordSynonyms                   & 0.5225$_{\pm0.0086}$                           & 0.5397$_{\pm0.0096}$                           & 0.6917$_{\pm0.0065}$                           & 0.7079$_{\pm0.022}$                            & \textbf{0.7429}$_{\pm0.0031}$ \\
Worms                          & 0.5455$_{\pm0.0344}$                           & 0.4416$_{\pm0.0225}$                           & \textbf{0.7229}$_{\pm0.0198}$ & 0.7013$_{\pm0.0225}$                           & 0.7143$_{\pm0.026}$                            \\
WormsTwoClass                  & 0.5931$_{\pm0.0417}$                           & 0.6364$_{\pm0.013}$                            & 0.7143$_{\pm0.0225}$                           & 0.7532$_{\pm0.045}$                            & \textbf{0.8052}$_{\pm0.0344}$ \\
Yoga                           & 0.7931$_{\pm0.0094}$                           & 0.7467$_{\pm0.0025}$                           & 0.8053$_{\pm0.0118}$                           & 0.8477$_{\pm0.0057}$                           & \textbf{0.8709}$_{\pm0.0132}$ \\
\midrule
Handwriting                    & 0.1537$_{\pm0.0198}$                           & 0.2922$_{\pm0.0049}$                           & 0.2545$_{\pm0.0118}$                           & 0.3635$_{\pm0.0101}$                           & \textbf{0.4631}$_{\pm0.0147}$ \\
JapaneseVowels                 & 0.9279$_{\pm0.0102}$                           & \textbf{0.9775}$_{\pm0.0041}$ & 0.9486$_{\pm0.0047}$                           & 0.9486$_{\pm0.0027}$                           & 0.9694$_{\pm0.0056}$                           \\
LSST                           & 0.4862$_{\pm0.02}$                             & 0.108$_{\pm0.0611}$                            & 0.3335$_{\pm0.0282}$                           & 0.5827$_{\pm0.0162}$                           & \textbf{0.6035}$_{\pm0.0254}$ \\
Libras                         & 0.6852$_{\pm0.014}$                            & 0.7333$_{\pm0.0096}$                           & 0.8407$_{\pm0.0064}$                           & 0.7852$_{\pm0.0064}$                           & \textbf{0.8722}$_{\pm0.0056}$ \\
NATOPS                         & 0.7926$_{\pm0.0225}$                           & \textbf{0.9537}$_{\pm0.0064}$ & 0.863$_{\pm0.021}$                             & 0.8593$_{\pm0.0195}$                           & 0.9315$_{\pm0.0085}$                           \\
PhonemeSpectra                 & 0.1121$_{\pm0.0067}$                           & 0.1106$_{\pm0.0054}$                           & 0.2392$_{\pm0.007}$                            & 0.1815$_{\pm0.0111}$                           & \textbf{0.3218}$_{\pm0.0027}$ \\
RacketSports                   & 0.7719$_{\pm0.0325}$                           & 0.7961$_{\pm0.0174}$                           & 0.8794$_{\pm0.0137}$                           & 0.7895$_{\pm0.0132}$                           & \textbf{0.9189}$_{\pm0.01}$   \\
SpokenArabicDigits             & 0.9782$_{\pm0.0021}$                           & 0.9856$_{\pm0.0023}$                           & 0.9853$_{\pm0.0009}$                           & 0.9818$_{\pm0.0014}$                           & \textbf{0.9867}$_{\pm0.0019}$ \\
UWaveGestureLibrary            & 0.8167$_{\pm0.0048}$                           & 0.8396$_{\pm0.0065}$                           & 0.8646$_{\pm0.0188}$                           & 0.9156$_{\pm0.0094}$                           & \textbf{0.9281}$_{\pm0.0125}$ \\

\midrule
\textit{\textbf{Best Count}} &  2 & 13 & 38 & 14 & \textbf{81} \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\end{table}



\begin{table}[htbp]
\caption{Mantis without and with the differential block used in the Token Generator Unit. The two models are compared under the feature extraction regime on the \texttt{159-D} benchmark with results averaged over 3 random seeds.}
\label{tab:ablation-diff}
\begin{minipage}{0.49\textwidth}
\centering
{\scalebox{\scalefactorzeroshot}{
\begin{tabular}{l|llll}
\toprule
                               & Mantis w/o Diff                                           & Mantis w/ Diff                                         \\
\midrule
ACSF1                          & \textbf{0.6433}$_{\pm0.0252}$ & 0.6133$_{\pm0.0208}$                           \\
Adiac                          & 0.6931$_{\pm0.0068}$                           & \textbf{0.7332}$_{\pm0.0039}$ \\
AllGestureWiimoteX             & 0.641$_{\pm0.0054}$                            & \textbf{0.6705}$_{\pm0.0044}$ \\
AllGestureWiimoteY             & 0.6343$_{\pm0.0071}$                           & \textbf{0.6671}$_{\pm0.0057}$ \\
AllGestureWiimoteZ             & 0.631$_{\pm0.0068}$                            & \textbf{0.6695}$_{\pm0.0033}$ \\
ArrowHead                      & \textbf{0.7543}$_{\pm0.0057}$ & 0.7105$_{\pm0.0175}$                           \\
BME                            & 0.8689$_{\pm0.0038}$                           & \textbf{0.9311}$_{\pm0.0038}$ \\
Beef                           & 0.6$_{\pm0.0}$                                 & \textbf{0.6556}$_{\pm0.0509}$ \\
BeetleFly                      & \textbf{0.9}$_{\pm0.05}$      & 0.85$_{\pm0.05}$                               \\
BirdChicken                    & 0.8833$_{\pm0.0289}$                           & \textbf{1.0}$_{\pm0.0}$       \\
CBF                            & \textbf{0.9937}$_{\pm0.0017}$ & 0.993$_{\pm0.0013}$                            \\
Car                            & 0.7389$_{\pm0.0096}$                           & \textbf{0.7722}$_{\pm0.0419}$ \\
Chinatown                      & 0.8678$_{\pm0.0131}$                           & \textbf{0.8737}$_{\pm0.0168}$ \\
ChlorineConcentration          & 0.6729$_{\pm0.0017}$                           & \textbf{0.6806}$_{\pm0.0019}$ \\
CinCECGTorso                   & \textbf{0.6664}$_{\pm0.0098}$ & 0.6611$_{\pm0.0036}$                           \\
Coffee                         & 0.9286$_{\pm0.0}$                              & \textbf{0.9524}$_{\pm0.0206}$ \\
Computers                      & 0.7267$_{\pm0.0046}$                           & \textbf{0.7373}$_{\pm0.0092}$ \\
CricketX                       & 0.706$_{\pm0.0146}$                            & \textbf{0.7368}$_{\pm0.0171}$ \\
CricketY                       & 0.7496$_{\pm0.0107}$                           & \textbf{0.7504}$_{\pm0.0065}$ \\
CricketZ                       & 0.7889$_{\pm0.003}$                            & \textbf{0.7906}$_{\pm0.0039}$ \\
Crop                           & \textbf{0.6879}$_{\pm0.0009}$ & 0.6756$_{\pm0.0018}$                           \\
DiatomSizeReduction            & 0.7963$_{\pm0.0136}$                           & \textbf{0.8845}$_{\pm0.0019}$ \\
DistalPhalanxOutlineAgeGroup   & 0.7482$_{\pm0.0125}$                           & \textbf{0.789}$_{\pm0.015}$   \\
DistalPhalanxOutlineCorrect    & \textbf{0.7681}$_{\pm0.0036}$ & 0.75$_{\pm0.0126}$                             \\
DistalPhalanxTW                & 0.6571$_{\pm0.0042}$                           & \textbf{0.6859}$_{\pm0.011}$  \\
DodgerLoopDay                  & \textbf{0.5583}$_{\pm0.0191}$ & 0.55$_{\pm0.0217}$                             \\
DodgerLoopGame                 & 0.6618$_{\pm0.0274}$                           & \textbf{0.7585}$_{\pm0.0221}$ \\
DodgerLoopWeekend              & \textbf{0.9758}$_{\pm0.0042}$ & 0.9517$_{\pm0.0084}$                           \\
ECG200                         & \textbf{0.86}$_{\pm0.02}$     & 0.82$_{\pm0.01}$                               \\
ECG5000                        & \textbf{0.9283}$_{\pm0.0011}$ & 0.9211$_{\pm0.001}$                            \\
ECGFiveDays                    & 0.8668$_{\pm0.0159}$                           & \textbf{0.909}$_{\pm0.0218}$  \\
EOGHorizontalSignal            & \textbf{0.5875}$_{\pm0.0188}$ & \textbf{0.5875}$_{\pm0.0089}$ \\
EOGVerticalSignal              & 0.4365$_{\pm0.0127}$                           & \textbf{0.4751}$_{\pm0.0}$    \\
Earthquakes                    & \textbf{0.753}$_{\pm0.0042}$  & 0.7482$_{\pm0.0}$                              \\
ElectricDevices                & 0.7045$_{\pm0.0006}$                           & \textbf{0.7226}$_{\pm0.0026}$ \\
EthanolLevel                   & 0.2873$_{\pm0.0117}$                           & \textbf{0.2993}$_{\pm0.011}$  \\
FaceAll                        & \textbf{0.7992}$_{\pm0.003}$  & 0.7815$_{\pm0.0074}$                           \\
FaceFour                       & 0.947$_{\pm0.0131}$                            & \textbf{0.9508}$_{\pm0.0066}$ \\
FacesUCR                       & \textbf{0.8364}$_{\pm0.0067}$ & 0.8354$_{\pm0.0054}$                           \\
FiftyWords                     & 0.5758$_{\pm0.0066}$                           & \textbf{0.6462}$_{\pm0.0096}$ \\
Fish                           & 0.9124$_{\pm0.0132}$                           & \textbf{0.9333}$_{\pm0.0066}$ \\
FordA                          & 0.8328$_{\pm0.0012}$                           & \textbf{0.8581}$_{\pm0.0048}$ \\
FordB                          & 0.7198$_{\pm0.0096}$                           & \textbf{0.7305}$_{\pm0.0031}$ \\
FreezerRegularTrain            & \textbf{0.9533}$_{\pm0.0013}$ & 0.9374$_{\pm0.0043}$                           \\
FreezerSmallTrain              & 0.7556$_{\pm0.004}$                            & \textbf{0.7942}$_{\pm0.0059}$ \\
Fungi                          & 0.81$_{\pm0.0062}$                             & \textbf{0.8262}$_{\pm0.0164}$ \\
GestureMidAirD1                & 0.6359$_{\pm0.0194}$                           & \textbf{0.659}$_{\pm0.0044}$  \\
GestureMidAirD2                & \textbf{0.6308}$_{\pm0.0077}$ & 0.6154$_{\pm0.0077}$                           \\
GestureMidAirD3                & \textbf{0.341}$_{\pm0.016}$   & 0.3282$_{\pm0.016}$                            \\
GesturePebbleZ1                & \textbf{0.9302}$_{\pm0.0}$    & 0.9283$_{\pm0.0034}$                           \\
GesturePebbleZ2                & 0.9051$_{\pm0.011}$                            & \textbf{0.9219}$_{\pm0.0256}$ \\
GunPoint                       & 0.9711$_{\pm0.0038}$                           & \textbf{0.98}$_{\pm0.0067}$   \\
GunPointAgeSpan                & 0.9736$_{\pm0.0018}$                           & \textbf{0.9905}$_{\pm0.0}$    \\
GunPointMaleVersusFemale       & 0.9937$_{\pm0.0}$                              & \textbf{0.9958}$_{\pm0.0018}$ \\
GunPointOldVersusYoung         & \textbf{0.9968}$_{\pm0.0}$    & \textbf{0.9968}$_{\pm0.0}$    \\
Ham                            & 0.6$_{\pm0.0095}$                              & \textbf{0.673}$_{\pm0.0145}$  \\
HandOutlines                   & 0.9063$_{\pm0.0056}$                           & \textbf{0.9162}$_{\pm0.0072}$ \\
Haptics                        & 0.4448$_{\pm0.0162}$                           & \textbf{0.4968}$_{\pm0.0032}$ \\
Herring                        & \textbf{0.6979}$_{\pm0.018}$  & 0.6667$_{\pm0.0239}$                           \\
HouseTwenty                    & \textbf{0.944}$_{\pm0.0049}$  & 0.9412$_{\pm0.0}$                              \\
InlineSkate                    & \textbf{0.3703}$_{\pm0.0107}$ & 0.363$_{\pm0.0136}$                            \\
InsectEPGRegularTrain          & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
InsectEPGSmallTrain            & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
InsectWingbeatSound            & 0.4739$_{\pm0.006}$                            & \textbf{0.519}$_{\pm0.0044}$  \\
\midrule
Blink                          & 0.9948$_{\pm0.0013}$                           & \textbf{0.9993}$_{\pm0.0013}$ \\
EMOPain                        & \textbf{0.8423}$_{\pm0.0056}$ & 0.8385$_{\pm0.0016}$                           \\
MotionSenseHAR                 & 0.9925$_{\pm0.0038}$                           & \textbf{0.9975}$_{\pm0.0022}$\\
SharePriceIncrease             & \textbf{0.6877}$_{\pm0.0026}$ & 0.6836$_{\pm0.0049}$   \\
\midrule
ArticularyWordRecognition      & 0.9911$_{\pm0.0019}$                           & \textbf{0.993}$_{\pm0.003}$   \\
BasicMotions                   & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
CharacterTrajectories          & 0.9352$_{\pm0.0025}$                           & \textbf{0.94}$_{\pm0.001}$    \\
Cricket                        & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
DuckDuckGeese                  & 0.38$_{\pm0.0529}$                             & \textbf{0.407}$_{\pm0.031}$   \\
ERing                          & 0.8284$_{\pm0.0311}$                           & \textbf{0.941}$_{\pm0.01}$    \\
EigenWorms                     & \textbf{0.7557}$_{\pm0.0076}$ & 0.753$_{\pm0.016}$                             \\
Epilepsy                       & 0.9928$_{\pm0.0072}$                           & \textbf{0.995}$_{\pm0.004}$   \\
EthanolConcentration           & \textbf{0.3308}$_{\pm0.0076}$ & 0.27$_{\pm0.01}$                               \\
FaceDetection                  & 0.5138$_{\pm0.0078}$                           & \textbf{0.526}$_{\pm0.002}$   \\
FingerMovements                & 0.5333$_{\pm0.0058}$                           & \textbf{0.54}$_{\pm0.035}$    \\
HandMovementDirection          & \textbf{0.3108}$_{\pm0.0135}$ & 0.212$_{\pm0.041}$                             \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\hfill
\begin{minipage}{0.49\textwidth}
\centering
{\scalebox{\scalefactorzeroshot}{
\begin{tabular}{l|llll}
\toprule
                               & Mantis w/o Diff                          & Mantis w/ Diff  \\
\midrule
ItalyPowerDemand               & 0.8996$_{\pm0.003}$                            & \textbf{0.9077}$_{\pm0.0035}$ \\
LargeKitchenAppliances         & 0.7662$_{\pm0.0094}$                           & \textbf{0.7804}$_{\pm0.0041}$ \\
Lightning2                     & 0.7268$_{\pm0.0189}$                           & \textbf{0.8033}$_{\pm0.0}$    \\
Lightning7                     & 0.6941$_{\pm0.0209}$                           & \textbf{0.7763}$_{\pm0.0285}$ \\
Mallat                         & \textbf{0.8904}$_{\pm0.0074}$ & 0.8903$_{\pm0.0137}$                           \\
Meat                           & \textbf{0.95}$_{\pm0.0167}$   & 0.9389$_{\pm0.0096}$                           \\
MedicalImages                  & 0.682$_{\pm0.0033}$                            & \textbf{0.7079}$_{\pm0.0035}$ \\
MelbournePedestrian            & \textbf{0.9083}$_{\pm0.0018}$ & 0.9016$_{\pm0.0031}$                           \\
MiddlePhalanxOutlineAgeGroup   & \textbf{0.5952}$_{\pm0.0163}$ & 0.5801$_{\pm0.0099}$                           \\
MiddlePhalanxOutlineCorrect    & 0.8087$_{\pm0.004}$                            & \textbf{0.8099}$_{\pm0.0099}$ \\
MiddlePhalanxTW                & \textbf{0.5433}$_{\pm0.0099}$ & 0.5368$_{\pm0.0099}$                           \\
MixedShapesRegularTrain        & 0.8995$_{\pm0.0017}$                           & \textbf{0.943}$_{\pm0.0044}$  \\
MixedShapesSmallTrain          & 0.8476$_{\pm0.0069}$                           & \textbf{0.8961}$_{\pm0.0004}$ \\
MoteStrain                     & \textbf{0.9255}$_{\pm0.0058}$ & 0.9137$_{\pm0.0136}$                           \\
NonInvasiveFetalECGThorax1     & \textbf{0.7837}$_{\pm0.0005}$ & 0.6222$_{\pm0.0037}$                           \\
NonInvasiveFetalECGThorax2     & \textbf{0.8053}$_{\pm0.0043}$ & 0.6872$_{\pm0.0025}$                           \\
OSULeaf                        & 0.7617$_{\pm0.0048}$                           & \textbf{0.8747}$_{\pm0.0104}$ \\
OliveOil                       & 0.8889$_{\pm0.0192}$                           & \textbf{0.9333}$_{\pm0.0}$    \\
PLAID                          & \textbf{0.8442}$_{\pm0.0043}$ & 0.8181$_{\pm0.0047}$                           \\
PhalangesOutlinesCorrect       & \textbf{0.7949}$_{\pm0.0031}$ & 0.7786$_{\pm0.0042}$                           \\
Phoneme                        & 0.289$_{\pm0.0024}$                            & \textbf{0.323}$_{\pm0.0034}$  \\
PickupGestureWiimoteZ          & 0.7$_{\pm0.02}$                                & \textbf{0.74}$_{\pm0.02}$     \\
PigAirwayPressure              & 0.4663$_{\pm0.0}$                              & \textbf{0.484}$_{\pm0.0147}$  \\
PigArtPressure                 & 0.9071$_{\pm0.0028}$                           & \textbf{0.9103}$_{\pm0.0028}$ \\
PigCVP                         & \textbf{0.8269}$_{\pm0.0048}$ & 0.7837$_{\pm0.0127}$                           \\
Plane                          & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
PowerCons                      & \textbf{0.9315}$_{\pm0.014}$  & 0.9093$_{\pm0.0032}$                           \\
ProximalPhalanxOutlineAgeGroup & \textbf{0.8537}$_{\pm0.0049}$ & \textbf{0.8537}$_{\pm0.0049}$ \\
ProximalPhalanxOutlineCorrect  & \textbf{0.8213}$_{\pm0.0034}$ & 0.8202$_{\pm0.0086}$                           \\
ProximalPhalanxTW              & \textbf{0.7707}$_{\pm0.0098}$ & 0.7691$_{\pm0.0028}$                           \\
RefrigerationDevices           & \textbf{0.5138}$_{\pm0.0101}$ & 0.504$_{\pm0.0122}$                            \\
Rock                           & 0.6933$_{\pm0.0808}$                           & \textbf{0.7133}$_{\pm0.0115}$ \\
ScreenType                     & \textbf{0.5031}$_{\pm0.0101}$ & 0.4649$_{\pm0.0134}$                           \\
SemgHandGenderCh2              & 0.8772$_{\pm0.0051}$                           & \textbf{0.9189}$_{\pm0.0086}$ \\
SemgHandMovementCh2            & 0.7622$_{\pm0.0059}$                           & \textbf{0.797}$_{\pm0.0056}$  \\
SemgHandSubjectCh2             & 0.8304$_{\pm0.0114}$                           & \textbf{0.8622}$_{\pm0.0135}$ \\
ShakeGestureWiimoteZ           & 0.8733$_{\pm0.0115}$                           & \textbf{0.8867}$_{\pm0.0115}$ \\
ShapeletSim                    & \textbf{0.963}$_{\pm0.0032}$  & 0.9278$_{\pm0.0111}$                           \\
ShapesAll                      & 0.8189$_{\pm0.0107}$                           & \textbf{0.8194}$_{\pm0.0054}$ \\
SmallKitchenAppliances         & 0.8036$_{\pm0.0094}$                           & \textbf{0.8089}$_{\pm0.0081}$ \\
SmoothSubspace                 & \textbf{0.9289}$_{\pm0.0102}$ & 0.9067$_{\pm0.0115}$                           \\
SonyAIBORobotSurface1          & 0.7682$_{\pm0.02}$                             & \textbf{0.787}$_{\pm0.0294}$  \\
SonyAIBORobotSurface2          & 0.7964$_{\pm0.0184}$                           & \textbf{0.8552}$_{\pm0.0168}$ \\
StarLightCurves                & \textbf{0.9772}$_{\pm0.0005}$ & 0.9759$_{\pm0.0005}$                           \\
Strawberry                     & \textbf{0.9541}$_{\pm0.0}$    & 0.9514$_{\pm0.0027}$                           \\
SwedishLeaf                    & 0.9035$_{\pm0.0024}$                           & \textbf{0.9275}$_{\pm0.0009}$ \\
Symbols                        & 0.9357$_{\pm0.0126}$                           & \textbf{0.9698}$_{\pm0.0056}$ \\
SyntheticControl               & 0.9478$_{\pm0.0051}$                           & \textbf{0.9767}$_{\pm0.0067}$ \\
ToeSegmentation1               & 0.9415$_{\pm0.0154}$                           & \textbf{0.9635}$_{\pm0.0067}$ \\
ToeSegmentation2               & 0.8718$_{\pm0.0364}$                           & \textbf{0.9282}$_{\pm0.0044}$ \\
Trace                          & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
TwoLeadECG                     & 0.9839$_{\pm0.0056}$                           & \textbf{0.9962}$_{\pm0.0005}$ \\
TwoPatterns                    & \textbf{0.8987}$_{\pm0.0034}$ & 0.8802$_{\pm0.0079}$                           \\
UMD                            & 0.9491$_{\pm0.008}$                            & \textbf{0.9722}$_{\pm0.0069}$ \\
UWaveGestureLibraryAll         & 0.8283$_{\pm0.0036}$                           & \textbf{0.8458}$_{\pm0.0057}$ \\
UWaveGestureLibraryX           & 0.7487$_{\pm0.0012}$                           & \textbf{0.7696}$_{\pm0.0028}$ \\
UWaveGestureLibraryY           & 0.6676$_{\pm0.0017}$                           & \textbf{0.6874}$_{\pm0.0022}$ \\
UWaveGestureLibraryZ           & 0.7082$_{\pm0.0023}$                           & \textbf{0.7324}$_{\pm0.0036}$ \\
Wafer                          & 0.9794$_{\pm0.0006}$                           & \textbf{0.9903}$_{\pm0.0003}$ \\
Wine                           & 0.6728$_{\pm0.0107}$                           & \textbf{0.7901}$_{\pm0.0107}$ \\
WordSynonyms                   & 0.4932$_{\pm0.0048}$                           & \textbf{0.5502}$_{\pm0.0081}$ \\
Worms                          & 0.6017$_{\pm0.0075}$                           & \textbf{0.6537}$_{\pm0.027}$  \\
WormsTwoClass                  & 0.6926$_{\pm0.0198}$                           & \textbf{0.8139}$_{\pm0.0198}$ \\
Yoga                           & \textbf{0.8164}$_{\pm0.001}$  & 0.815$_{\pm0.0012}$                            \\
\midrule
Handwriting                    & 0.3027$_{\pm0.01}$                             & \textbf{0.339}$_{\pm0.01}$    \\
Heartbeat                      & 0.7675$_{\pm0.0157}$                           & \textbf{0.798}$_{\pm0.017}$   \\
InsectWingbeatSubset           & 0.5837$_{\pm0.0064}$                           & \textbf{0.607}$_{\pm0.007}$   \\
JapaneseVowels                 & 0.9514$_{\pm0.0047}$                           & \textbf{0.963}$_{\pm0.006}$   \\
LSST                           & 0.5884$_{\pm0.0015}$                           & \textbf{0.605}$_{\pm0.002}$   \\
Libras                         & 0.8815$_{\pm0.017}$                            & \textbf{0.898}$_{\pm0.008}$   \\
MotorImagery                   & 0.5267$_{\pm0.0208}$                           & \textbf{0.55}$_{\pm0.036}$    \\
NATOPS                         & 0.9$_{\pm0.0056}$                              & \textbf{0.907}$_{\pm0.013}$   \\
PEMS-SF                        & 0.9807$_{\pm0.0067}$                           & \textbf{0.985}$_{\pm0.013}$   \\
PhonemeSpectra                 & 0.2587$_{\pm0.0012}$                           & \textbf{0.273}$_{\pm0.008}$   \\
RacketSports                   & 0.9123$_{\pm0.0137}$                           & \textbf{0.923}$_{\pm0.004}$   \\
SelfRegulationSCP1             & 0.7611$_{\pm0.0034}$                           & \textbf{0.804}$_{\pm0.011}$   \\
SelfRegulationSCP2             & \textbf{0.4796}$_{\pm0.0064}$ & 0.476$_{\pm0.045}$                             \\
SpokenArabicDigits             & 0.8172$_{\pm0.0081}$                           & \textbf{0.839}$_{\pm0.005}$   \\
UWaveGestureLibrary            & \textbf{0.8188}$_{\pm0.0083}$ & 0.814$_{\pm0.01}$                              \\
\midrule
\textit{\textbf{Best Count}} & 59 & \textbf{109} \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\end{table}


\newcommand{\scalefactorft}{0.55}
\begin{table}[ht!]
\caption{Comparison of different fine-tuning regimes for Mantis on the \texttt{151-D} benchmark. The last epoch accuracy is averaged over 3 random seeds and reported with the standard deviation.
}
\label{tab:last-epoch-res}
\begin{minipage}{0.5\textwidth}
{\scalebox{\scalefactorft}{
\begin{tabular}{l|llll}
\toprule
                               & RF                                             & Head                                           & Scratch                                        & Full                                           \\
\midrule
ACSF1                          & 0.6133$_{\pm0.0208}$                           & 0.6$_{\pm0.0}$                                 & 0.57$_{\pm0.0693}$                             & \textbf{0.7033}$_{\pm0.0551}$ \\
Adiac                          & 0.7332$_{\pm0.0039}$                           & 0.5857$_{\pm0.0051}$                           & 0.7315$_{\pm0.0}$                              & \textbf{0.8133}$_{\pm0.0}$    \\
AllGestureWiimoteX             & 0.6705$_{\pm0.0044}$                           & 0.5471$_{\pm0.0014}$                           & 0.6838$_{\pm0.0073}$                           & \textbf{0.7924}$_{\pm0.0073}$ \\
AllGestureWiimoteY             & 0.6671$_{\pm0.0057}$                           & 0.5595$_{\pm0.0044}$                           & 0.7224$_{\pm0.0084}$                           & \textbf{0.8033}$_{\pm0.0084}$ \\
AllGestureWiimoteZ             & 0.6695$_{\pm0.0033}$                           & 0.5414$_{\pm0.0014}$                           & 0.6271$_{\pm0.0289}$                           & \textbf{0.7443}$_{\pm0.0076}$ \\
ArrowHead                      & 0.7105$_{\pm0.0175}$                           & 0.7276$_{\pm0.0119}$                           & 0.7752$_{\pm0.0282}$                           & \textbf{0.8114}$_{\pm0.0206}$ \\
BME                            & 0.9311$_{\pm0.0038}$                           & 0.8756$_{\pm0.0139}$                           & 0.9844$_{\pm0.0038}$                           & \textbf{1.0}$_{\pm0.0}$       \\
Beef                           & 0.6556$_{\pm0.0509}$                           & 0.6111$_{\pm0.0192}$                           & 0.7667$_{\pm0.0882}$                           & \textbf{0.7889}$_{\pm0.0192}$ \\
BeetleFly                      & 0.85$_{\pm0.05}$                               & \textbf{0.9}$_{\pm0.0}$       & 0.5333$_{\pm0.0764}$                           & 0.8167$_{\pm0.0289}$                           \\
BirdChicken                    & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & 0.8333$_{\pm0.0289}$                           & \textbf{1.0}$_{\pm0.0}$       \\
CBF                            & 0.993$_{\pm0.0013}$                            & 0.9941$_{\pm0.0006}$                           & 0.9844$_{\pm0.0185}$                           & \textbf{0.9993}$_{\pm0.0013}$ \\
Car                            & 0.7722$_{\pm0.0419}$                           & 0.7778$_{\pm0.0192}$                           & 0.7056$_{\pm0.0192}$                           & \textbf{0.8833}$_{\pm0.0167}$ \\
Chinatown                      & 0.8737$_{\pm0.0168}$                           & 0.8785$_{\pm0.0094}$                           & 0.9582$_{\pm0.0067}$                           & \textbf{0.9767}$_{\pm0.0077}$ \\
ChlorineConcentration          & 0.6806$_{\pm0.0019}$                           & 0.5688$_{\pm0.0011}$                           & 0.7494$_{\pm0.0034}$                           & \textbf{0.7718}$_{\pm0.01}$   \\
CinCECGTorso                   & 0.6611$_{\pm0.0036}$                           & 0.7176$_{\pm0.0044}$                           & 0.7802$_{\pm0.019}$                            & \textbf{0.8539}$_{\pm0.0096}$ \\
Coffee                         & 0.9524$_{\pm0.0206}$                           & 0.9643$_{\pm0.0}$                              & 0.9881$_{\pm0.0206}$                           & \textbf{1.0}$_{\pm0.0}$       \\
Computers                      & 0.7373$_{\pm0.0092}$                           & 0.7093$_{\pm0.0129}$                           & 0.7053$_{\pm0.022}$                            & \textbf{0.7467}$_{\pm0.0205}$ \\
CricketX                       & 0.7368$_{\pm0.0171}$                           & 0.6966$_{\pm0.003}$                            & 0.7538$_{\pm0.0268}$                           & \textbf{0.8205}$_{\pm0.0136}$ \\
CricketY                       & 0.7504$_{\pm0.0065}$                           & 0.7043$_{\pm0.003}$                            & 0.7812$_{\pm0.003}$                            & \textbf{0.8214}$_{\pm0.0039}$ \\
CricketZ                       & 0.7906$_{\pm0.0039}$                           & 0.7333$_{\pm0.0077}$                           & 0.7829$_{\pm0.0082}$                           & \textbf{0.8462}$_{\pm0.0092}$ \\
Crop                           & 0.6756$_{\pm0.0018}$                           & 0.6738$_{\pm0.0004}$                           & 0.7558$_{\pm0.0068}$                           & \textbf{0.7681}$_{\pm0.0008}$ \\
DiatomSizeReduction            & 0.8845$_{\pm0.0019}$                           & 0.8889$_{\pm0.017}$                            & 0.8878$_{\pm0.0075}$                           & \textbf{0.9314}$_{\pm0.0033}$ \\
DistalPhalanxOutlineAgeGroup   & 0.789$_{\pm0.015}$                             & \textbf{0.8106}$_{\pm0.0042}$ & 0.6451$_{\pm0.0324}$                           & 0.7314$_{\pm0.011}$                            \\
DistalPhalanxOutlineCorrect    & 0.75$_{\pm0.0126}$                             & 0.7621$_{\pm0.0042}$                           & \textbf{0.7645}$_{\pm0.0072}$ & 0.7415$_{\pm0.0091}$                           \\
DistalPhalanxTW                & \textbf{0.6859}$_{\pm0.011}$  & 0.6595$_{\pm0.0083}$                           & 0.6619$_{\pm0.0125}$                           & 0.6619$_{\pm0.0072}$                           \\
DodgerLoopDay                  & 0.55$_{\pm0.0217}$                             & 0.5292$_{\pm0.026}$                            & 0.55$_{\pm0.0375}$                             & \textbf{0.6125}$_{\pm0.025}$  \\
DodgerLoopGame                 & 0.7585$_{\pm0.0221}$                           & 0.7126$_{\pm0.0084}$                           & 0.7633$_{\pm0.0167}$                           & \textbf{0.9324}$_{\pm0.0254}$ \\
DodgerLoopWeekend              & 0.9517$_{\pm0.0084}$                           & 0.9758$_{\pm0.0111}$                           & \textbf{0.9831}$_{\pm0.0042}$ & \textbf{0.9831}$_{\pm0.0042}$ \\
ECG200                         & 0.82$_{\pm0.01}$                               & 0.8033$_{\pm0.0252}$                           & 0.8167$_{\pm0.0115}$                           & \textbf{0.9067}$_{\pm0.0153}$ \\
ECG5000                        & 0.9211$_{\pm0.001}$                            & 0.9185$_{\pm0.0038}$                           & 0.9301$_{\pm0.0039}$                           & \textbf{0.9402}$_{\pm0.0006}$ \\
ECGFiveDays                    & 0.909$_{\pm0.0218}$                            & 0.8668$_{\pm0.0401}$                           & 0.7093$_{\pm0.0697}$                           & \textbf{0.9512}$_{\pm0.0247}$ \\
EOGHorizontalSignal            & 0.5875$_{\pm0.0089}$                           & 0.5691$_{\pm0.0083}$                           & 0.6308$_{\pm0.0142}$                           & \textbf{0.6722}$_{\pm0.0097}$ \\
EOGVerticalSignal              & 0.4751$_{\pm0.0}$                              & 0.4797$_{\pm0.0131}$                           & 0.5037$_{\pm0.0162}$                           & \textbf{0.5617}$_{\pm0.018}$  \\
Earthquakes                    & 0.7482$_{\pm0.0}$                              & \textbf{0.7506}$_{\pm0.0042}$ & 0.7482$_{\pm0.0216}$                           & 0.7266$_{\pm0.0144}$                           \\
ElectricDevices                & 0.7226$_{\pm0.0026}$                           & 0.7039$_{\pm0.0008}$                           & 0.7112$_{\pm0.0091}$                           & \textbf{0.7505}$_{\pm0.0068}$ \\
EthanolLevel                   & 0.2993$_{\pm0.011}$                            & 0.3173$_{\pm0.0117}$                           & 0.6087$_{\pm0.0463}$                           & \textbf{0.6773}$_{\pm0.1125}$ \\
FaceAll                        & 0.7815$_{\pm0.0074}$                           & 0.8053$_{\pm0.0062}$                           & \textbf{0.9469}$_{\pm0.0042}$ & 0.8544$_{\pm0.0345}$                           \\
FaceFour                       & 0.9508$_{\pm0.0066}$                           & 0.947$_{\pm0.0131}$                            & 0.7879$_{\pm0.0237}$                           & \textbf{0.9697}$_{\pm0.0131}$ \\
FacesUCR                       & 0.8354$_{\pm0.0054}$                           & 0.8434$_{\pm0.0101}$                           & 0.88$_{\pm0.0042}$                             & \textbf{0.9411}$_{\pm0.0055}$ \\
FiftyWords                     & 0.6462$_{\pm0.0096}$                           & 0.7026$_{\pm0.0178}$                           & 0.8088$_{\pm0.0}$                              & \textbf{0.8571}$_{\pm0.0022}$ \\
Fish                           & 0.9333$_{\pm0.0066}$                           & 0.9333$_{\pm0.0033}$                           & 0.9143$_{\pm0.0151}$                           & \textbf{0.9714}$_{\pm0.0057}$ \\
FordA                          & 0.8581$_{\pm0.0048}$                           & 0.8869$_{\pm0.0016}$                           & 0.9235$_{\pm0.0015}$                           & \textbf{0.9417}$_{\pm0.002}$  \\
FordB                          & 0.7305$_{\pm0.0031}$                           & 0.765$_{\pm0.0026}$                            & 0.7807$_{\pm0.0096}$                           & \textbf{0.8329}$_{\pm0.0068}$ \\
FreezerRegularTrain            & 0.9374$_{\pm0.0043}$                           & 0.8767$_{\pm0.0088}$                           & 0.9927$_{\pm0.0026}$                           & \textbf{0.9964}$_{\pm0.0015}$ \\
FreezerSmallTrain              & 0.7942$_{\pm0.0059}$                           & 0.8085$_{\pm0.0041}$                           & 0.8469$_{\pm0.0886}$                           & \textbf{0.9602}$_{\pm0.0224}$ \\
Fungi                          & 0.8262$_{\pm0.0164}$                           & 0.8477$_{\pm0.0224}$                           & 0.9301$_{\pm0.0108}$                           & \textbf{0.9839}$_{\pm0.0142}$ \\
GestureMidAirD1                & 0.659$_{\pm0.0044}$                            & 0.6026$_{\pm0.0044}$                           & 0.6872$_{\pm0.016}$                            & \textbf{0.7744}$_{\pm0.0044}$ \\
GestureMidAirD2                & 0.6154$_{\pm0.0077}$                           & 0.5256$_{\pm0.016}$                            & 0.6487$_{\pm0.0118}$                           & \textbf{0.6949}$_{\pm0.0194}$ \\
GestureMidAirD3                & 0.3282$_{\pm0.016}$                            & 0.3128$_{\pm0.0291}$                           & 0.3897$_{\pm0.032}$                            & \textbf{0.459}$_{\pm0.0235}$  \\
GesturePebbleZ1                & 0.9283$_{\pm0.0034}$                           & 0.9186$_{\pm0.0116}$                           & 0.907$_{\pm0.0101}$                            & \textbf{0.9341}$_{\pm0.0089}$ \\
GesturePebbleZ2                & 0.9219$_{\pm0.0256}$                           & \textbf{0.9451}$_{\pm0.0097}$ & 0.8586$_{\pm0.0256}$                           & 0.8481$_{\pm0.0167}$                           \\
GunPoint                       & 0.98$_{\pm0.0067}$                             & 0.9822$_{\pm0.0038}$                           & 0.9733$_{\pm0.0176}$                           & \textbf{0.9978}$_{\pm0.0038}$ \\
GunPointAgeSpan                & 0.9905$_{\pm0.0}$                              & 0.9821$_{\pm0.0037}$                           & 0.9905$_{\pm0.0032}$                           & \textbf{0.9968}$_{\pm0.0}$    \\
GunPointMaleVersusFemale       & 0.9958$_{\pm0.0018}$                           & 0.9863$_{\pm0.0048}$                           & 0.9926$_{\pm0.0018}$                           & \textbf{0.9979}$_{\pm0.0037}$ \\
GunPointOldVersusYoung         & \textbf{0.9968}$_{\pm0.0}$    & \textbf{0.9968}$_{\pm0.0}$    & 0.9926$_{\pm0.0018}$                           & \textbf{0.9968}$_{\pm0.0}$    \\
Ham                            & 0.673$_{\pm0.0145}$                            & 0.6857$_{\pm0.0252}$                           & \textbf{0.727}$_{\pm0.0145}$  & 0.6762$_{\pm0.0252}$                           \\
HandOutlines                   & 0.9162$_{\pm0.0072}$                           & 0.8928$_{\pm0.0068}$                           & 0.9279$_{\pm0.0095}$                           & \textbf{0.9459}$_{\pm0.0027}$ \\
Haptics                        & 0.4968$_{\pm0.0032}$                           & 0.4665$_{\pm0.0114}$                           & 0.4708$_{\pm0.0086}$                           & \textbf{0.5487}$_{\pm0.0225}$ \\
Herring                        & 0.6667$_{\pm0.0239}$                           & \textbf{0.7031}$_{\pm0.0156}$ & 0.5365$_{\pm0.0502}$                           & 0.6042$_{\pm0.0325}$                           \\
HouseTwenty                    & 0.9412$_{\pm0.0}$                              & 0.9496$_{\pm0.0084}$                           & 0.9132$_{\pm0.0049}$                           & \textbf{0.9748}$_{\pm0.0084}$ \\
InlineSkate                    & 0.363$_{\pm0.0136}$                            & 0.3164$_{\pm0.0119}$                           & 0.383$_{\pm0.0282}$                            & \textbf{0.4388}$_{\pm0.0128}$ \\
InsectEPGRegularTrain          & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & 0.9893$_{\pm0.0046}$                           & \textbf{1.0}$_{\pm0.0}$       \\
InsectEPGSmallTrain            & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & 0.9424$_{\pm0.0221}$                           & \textbf{1.0}$_{\pm0.0}$       \\
InsectWingbeatSound            & 0.519$_{\pm0.0044}$                            & 0.4785$_{\pm0.0092}$                           & 0.5966$_{\pm0.0146}$                           & \textbf{0.6093}$_{\pm0.0148}$ \\
\midrule
Blink                          & \textbf{1.0}$_{\pm0.0}$       & 0.9963$_{\pm0.0046}$                           & 0.983$_{\pm0.0051}$                            & \textbf{1.0}$_{\pm0.0}$       \\
MotionSenseHAR                 & \textbf{1.0}$_{\pm0.0}$       & 0.9962$_{\pm0.0}$                              & 0.9874$_{\pm0.0022}$                           & \textbf{1.0}$_{\pm0.0}$       \\
SharePriceIncrease             & \textbf{0.6874}$_{\pm0.0}$    & 0.6718$_{\pm0.001}$                            & 0.617$_{\pm0.0112}$                            & 0.6342$_{\pm0.0119}$ \\
\midrule
ArticularyWordRecognition      & 0.9933$_{\pm0.0033}$                           & 0.9933$_{\pm0.0}$                              & \textbf{0.9967}$_{\pm0.0}$    & 0.9933$_{\pm0.0}$                              \\
BasicMotions                   & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
CharacterTrajectories          & 0.9396$_{\pm0.0008}$                           & 0.9673$_{\pm0.0021}$                           & 0.9789$_{\pm0.0028}$                           & \textbf{0.9912}$_{\pm0.0011}$ \\
Cricket                        & \textbf{1.0}$_{\pm0.0}$       & 0.9861$_{\pm0.0}$                              & 0.9861$_{\pm0.0}$                              & \textbf{1.0}$_{\pm0.0}$       \\
ERing                          & 0.9407$_{\pm0.0098}$                           & 0.9296$_{\pm0.0192}$                           & 0.9432$_{\pm0.0077}$                           & \textbf{0.9901}$_{\pm0.0043}$ \\
EigenWorms                     & 0.7532$_{\pm0.0159}$                           & 0.7379$_{\pm0.0233}$                           & 0.6743$_{\pm0.0192}$                           & \textbf{0.8219}$_{\pm0.0044}$ \\
Epilepsy                       & 0.9952$_{\pm0.0042}$                           & 0.9928$_{\pm0.0}$                              & 0.9879$_{\pm0.0111}$                           & \textbf{1.0}$_{\pm0.0}$       \\
EthanolConcentration           & 0.27$_{\pm0.0101}$                             & 0.2928$_{\pm0.0132}$                           & 0.2852$_{\pm0.0201}$                           & \textbf{0.3942}$_{\pm0.0295}$ \\
HandMovementDirection          & 0.2117$_{\pm0.0413}$                           & 0.2477$_{\pm0.0281}$                           & \textbf{0.4234}$_{\pm0.0609}$ & 0.3333$_{\pm0.0475}$                           \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\hfill
\begin{minipage}{0.5\textwidth}
{\scalebox{\scalefactorft}{
\begin{tabular}{l|llll}
\toprule
                               & RF                                             & Head                                           & Scratch                                        & Full                                           \\
\midrule
ItalyPowerDemand               & 0.9077$_{\pm0.0035}$                           & 0.9051$_{\pm0.0048}$                           & \textbf{0.9644}$_{\pm0.0034}$ & 0.953$_{\pm0.0006}$                            \\
LargeKitchenAppliances         & 0.7804$_{\pm0.0041}$                           & 0.784$_{\pm0.008}$                             & \textbf{0.8676}$_{\pm0.0147}$ & 0.8542$_{\pm0.0094}$                           \\
Lightning2                     & 0.8033$_{\pm0.0}$                              & 0.8251$_{\pm0.0189}$                           & \textbf{0.8525}$_{\pm0.0328}$ & 0.8197$_{\pm0.0}$                              \\
Lightning7                     & 0.7763$_{\pm0.0285}$                           & 0.7671$_{\pm0.0137}$                           & 0.6986$_{\pm0.0137}$                           & \textbf{0.8219}$_{\pm0.0137}$ \\
Mallat                         & 0.8903$_{\pm0.0137}$                           & 0.7765$_{\pm0.0019}$                           & 0.8691$_{\pm0.0111}$                           & \textbf{0.9389}$_{\pm0.0146}$ \\
Meat                           & 0.9389$_{\pm0.0096}$                           & 0.8889$_{\pm0.0255}$                           & 0.8167$_{\pm0.0928}$                           & \textbf{0.9444}$_{\pm0.0385}$ \\
MedicalImages                  & 0.7079$_{\pm0.0035}$                           & 0.6939$_{\pm0.0142}$                           & 0.7412$_{\pm0.0102}$                           & \textbf{0.8018}$_{\pm0.0154}$ \\
MelbournePedestrian            & 0.9016$_{\pm0.0031}$                           & 0.8922$_{\pm0.0033}$                           & 0.9576$_{\pm0.0037}$                           & \textbf{0.9703}$_{\pm0.0005}$ \\
MiddlePhalanxOutlineAgeGroup   & 0.5801$_{\pm0.0099}$                           & \textbf{0.5823}$_{\pm0.0228}$ & 0.5043$_{\pm0.0293}$                           & 0.5325$_{\pm0.0298}$                           \\
MiddlePhalanxOutlineCorrect    & 0.8099$_{\pm0.0099}$                           & 0.8007$_{\pm0.0124}$                           & 0.7927$_{\pm0.0086}$                           & \textbf{0.8522}$_{\pm0.0091}$ \\
MiddlePhalanxTW                & \textbf{0.5368}$_{\pm0.0099}$ & 0.5087$_{\pm0.0163}$                           & 0.5152$_{\pm0.0262}$                           & 0.5087$_{\pm0.0187}$                           \\
MixedShapesRegularTrain        & 0.943$_{\pm0.0044}$                            & 0.9387$_{\pm0.0037}$                           & 0.9555$_{\pm0.0043}$                           & \textbf{0.9803}$_{\pm0.0006}$ \\
MixedShapesSmallTrain          & 0.8961$_{\pm0.0004}$                           & 0.8936$_{\pm0.0054}$                           & 0.8843$_{\pm0.0116}$                           & \textbf{0.9567}$_{\pm0.0041}$ \\
MoteStrain                     & 0.9137$_{\pm0.0136}$                           & 0.8988$_{\pm0.0112}$                           & 0.9087$_{\pm0.0095}$                           & \textbf{0.9241}$_{\pm0.0042}$ \\
NonInvasiveFetalECGThorax1     & 0.6222$_{\pm0.0037}$                           & 0.6712$_{\pm0.0018}$                           & 0.9035$_{\pm0.0016}$                           & \textbf{0.936}$_{\pm0.0056}$  \\
NonInvasiveFetalECGThorax2     & 0.6872$_{\pm0.0025}$                           & 0.712$_{\pm0.004}$                             & 0.9152$_{\pm0.0013}$                           & \textbf{0.9445}$_{\pm0.0018}$ \\
OSULeaf                        & 0.8747$_{\pm0.0104}$                           & 0.8719$_{\pm0.0109}$                           & 0.8609$_{\pm0.0104}$                           & \textbf{0.9573}$_{\pm0.0086}$ \\
OliveOil                       & \textbf{0.9333}$_{\pm0.0}$    & 0.4$_{\pm0.0}$                                 & 0.6889$_{\pm0.0192}$                           & 0.9222$_{\pm0.0509}$                           \\
PLAID                          & 0.8181$_{\pm0.0047}$                           & 0.545$_{\pm0.0047}$                            & 0.897$_{\pm0.0084}$                            & \textbf{0.9199}$_{\pm0.0032}$ \\
PhalangesOutlinesCorrect       & 0.7786$_{\pm0.0042}$                           & 0.7599$_{\pm0.0051}$                           & 0.8139$_{\pm0.0029}$                           & \textbf{0.8256}$_{\pm0.0125}$ \\
Phoneme                        & 0.323$_{\pm0.0034}$                            & 0.3224$_{\pm0.0008}$                           & 0.2683$_{\pm0.0085}$                           & \textbf{0.3434}$_{\pm0.0069}$ \\
PickupGestureWiimoteZ          & 0.74$_{\pm0.02}$                               & 0.7733$_{\pm0.0611}$                           & 0.6667$_{\pm0.0231}$                           & \textbf{0.7933}$_{\pm0.0306}$ \\
PigAirwayPressure              & 0.484$_{\pm0.0147}$                            & 0.4455$_{\pm0.0169}$                           & 0.1843$_{\pm0.0182}$                           & \textbf{0.5176}$_{\pm0.0194}$ \\
PigArtPressure                 & \textbf{0.9103}$_{\pm0.0028}$ & 0.8221$_{\pm0.0173}$                           & 0.6571$_{\pm0.0028}$                           & 0.9087$_{\pm0.0127}$                           \\
PigCVP                         & 0.7837$_{\pm0.0127}$                           & 0.7724$_{\pm0.0073}$                           & 0.4631$_{\pm0.01}$                             & \textbf{0.8894}$_{\pm0.0254}$ \\
Plane                          & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
PowerCons                      & 0.9093$_{\pm0.0032}$                           & 0.8852$_{\pm0.0274}$                           & \textbf{0.9926}$_{\pm0.0032}$ & 0.9889$_{\pm0.0}$                              \\
ProximalPhalanxOutlineAgeGroup & 0.8537$_{\pm0.0049}$                           & \textbf{0.8732}$_{\pm0.0}$    & 0.8276$_{\pm0.0241}$                           & 0.8244$_{\pm0.0049}$                           \\
ProximalPhalanxOutlineCorrect  & 0.8202$_{\pm0.0086}$                           & 0.8477$_{\pm0.0105}$                           & \textbf{0.8923}$_{\pm0.0189}$ & 0.8889$_{\pm0.013}$                            \\
ProximalPhalanxTW              & 0.7691$_{\pm0.0028}$                           & 0.7675$_{\pm0.0123}$                           & \textbf{0.7789}$_{\pm0.0171}$ & 0.761$_{\pm0.0176}$                            \\
RefrigerationDevices           & \textbf{0.504}$_{\pm0.0122}$  & 0.4978$_{\pm0.0015}$                           & 0.4907$_{\pm0.008}$                            & 0.4889$_{\pm0.0056}$                           \\
Rock                           & 0.7133$_{\pm0.0115}$                           & 0.7667$_{\pm0.0231}$                           & 0.7867$_{\pm0.0306}$                           & \textbf{0.8533}$_{\pm0.0115}$ \\
ScreenType                     & 0.4649$_{\pm0.0134}$                           & 0.4507$_{\pm0.0092}$                           & 0.4711$_{\pm0.0126}$                           & \textbf{0.5058}$_{\pm0.0189}$ \\
SemgHandGenderCh2              & 0.9189$_{\pm0.0086}$                           & 0.8561$_{\pm0.0019}$                           & 0.9417$_{\pm0.0133}$                           & \textbf{0.9461}$_{\pm0.0212}$ \\
SemgHandMovementCh2            & 0.797$_{\pm0.0056}$                            & 0.5622$_{\pm0.0174}$                           & 0.8267$_{\pm0.0212}$                           & \textbf{0.8556}$_{\pm0.025}$  \\
SemgHandSubjectCh2             & 0.8622$_{\pm0.0135}$                           & 0.7763$_{\pm0.0064}$                           & 0.9193$_{\pm0.0168}$                           & \textbf{0.9415}$_{\pm0.021}$  \\
ShakeGestureWiimoteZ           & 0.8867$_{\pm0.0115}$                           & 0.8933$_{\pm0.0231}$                           & 0.84$_{\pm0.02}$                               & \textbf{0.9333}$_{\pm0.0115}$ \\
ShapeletSim                    & 0.9278$_{\pm0.0111}$                           & 0.913$_{\pm0.0064}$                            & 0.9815$_{\pm0.017}$                            & \textbf{1.0}$_{\pm0.0}$       \\
ShapesAll                      & 0.8194$_{\pm0.0054}$                           & 0.8489$_{\pm0.0051}$                           & 0.8739$_{\pm0.01}$                             & \textbf{0.9039}$_{\pm0.0035}$ \\
SmallKitchenAppliances         & 0.8089$_{\pm0.0081}$                           & \textbf{0.8293}$_{\pm0.0}$    & 0.7902$_{\pm0.0081}$                           & 0.7893$_{\pm0.0071}$                           \\
SmoothSubspace                 & 0.9067$_{\pm0.0115}$                           & 0.9378$_{\pm0.0168}$                           & 0.98$_{\pm0.0}$                                & \textbf{0.9933}$_{\pm0.0}$    \\
SonyAIBORobotSurface1          & 0.787$_{\pm0.0294}$                            & 0.8236$_{\pm0.0292}$                           & \textbf{0.8264}$_{\pm0.0217}$ & 0.8103$_{\pm0.0202}$                           \\
SonyAIBORobotSurface2          & 0.8552$_{\pm0.0168}$                           & 0.8821$_{\pm0.0063}$                           & 0.8356$_{\pm0.0221}$                           & \textbf{0.9307}$_{\pm0.0028}$ \\
StarLightCurves                & 0.9759$_{\pm0.0005}$                           & \textbf{0.9785}$_{\pm0.0007}$ & 0.972$_{\pm0.002}$                             & 0.9768$_{\pm0.0011}$                           \\
Strawberry                     & 0.9514$_{\pm0.0027}$                           & 0.9108$_{\pm0.0047}$                           & \textbf{0.9712}$_{\pm0.0095}$ & 0.9667$_{\pm0.0041}$                           \\
SwedishLeaf                    & 0.9275$_{\pm0.0009}$                           & 0.9253$_{\pm0.0024}$                           & 0.9419$_{\pm0.0033}$                           & \textbf{0.9701}$_{\pm0.0072}$ \\
Symbols                        & 0.9698$_{\pm0.0056}$                           & 0.9668$_{\pm0.0036}$                           & 0.9199$_{\pm0.018}$                            & \textbf{0.9873}$_{\pm0.0061}$ \\
SyntheticControl               & 0.9767$_{\pm0.0067}$                           & 0.9844$_{\pm0.0051}$                           & 0.9667$_{\pm0.0067}$                           & \textbf{0.9944}$_{\pm0.0038}$ \\
ToeSegmentation1               & 0.9635$_{\pm0.0067}$                           & 0.9532$_{\pm0.0127}$                           & 0.8684$_{\pm0.0219}$                           & \textbf{0.9737}$_{\pm0.0044}$ \\
ToeSegmentation2               & 0.9282$_{\pm0.0044}$                           & \textbf{0.9564}$_{\pm0.0089}$ & 0.8692$_{\pm0.0231}$                           & 0.9256$_{\pm0.0044}$                           \\
Trace                          & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
TwoLeadECG                     & 0.9962$_{\pm0.0005}$                           & \textbf{0.998}$_{\pm0.0005}$  & 0.9236$_{\pm0.0279}$                           & 0.9974$_{\pm0.0015}$                           \\
TwoPatterns                    & 0.8802$_{\pm0.0079}$                           & 0.892$_{\pm0.0021}$                            & 0.9997$_{\pm0.0004}$                           & \textbf{1.0}$_{\pm0.0}$       \\
UMD                            & 0.9722$_{\pm0.0069}$                           & 0.9792$_{\pm0.0}$                              & 0.9769$_{\pm0.016}$                            & \textbf{0.9931}$_{\pm0.0}$    \\
UWaveGestureLibraryAll         & 0.8458$_{\pm0.0057}$                           & 0.8733$_{\pm0.0014}$                           & 0.9718$_{\pm0.0005}$                           & \textbf{0.9746}$_{\pm0.001}$  \\
UWaveGestureLibraryX           & 0.7696$_{\pm0.0028}$                           & 0.7911$_{\pm0.0017}$                           & 0.8368$_{\pm0.0058}$                           & \textbf{0.8714}$_{\pm0.0021}$ \\
UWaveGestureLibraryY           & 0.6874$_{\pm0.0022}$                           & 0.7061$_{\pm0.0024}$                           & 0.7742$_{\pm0.0027}$                           & \textbf{0.807}$_{\pm0.0011}$  \\
UWaveGestureLibraryZ           & 0.7324$_{\pm0.0036}$                           & 0.7581$_{\pm0.002}$                            & 0.7841$_{\pm0.0011}$                           & \textbf{0.8248}$_{\pm0.0011}$ \\
Wafer                          & 0.9903$_{\pm0.0003}$                           & 0.9839$_{\pm0.0069}$                           & 0.9948$_{\pm0.0008}$                           & \textbf{0.9988}$_{\pm0.0005}$ \\
Wine                           & \textbf{0.7901}$_{\pm0.0107}$ & 0.5926$_{\pm0.0321}$                           & 0.6296$_{\pm0.0185}$                           & 0.6914$_{\pm0.0385}$                           \\
WordSynonyms                   & 0.5502$_{\pm0.0081}$                           & 0.4901$_{\pm0.0128}$                           & 0.6886$_{\pm0.0059}$                           & \textbf{0.7571}$_{\pm0.0054}$ \\
Worms                          & 0.6537$_{\pm0.027}$                            & 0.7186$_{\pm0.015}$                            & 0.7143$_{\pm0.026}$                            & \textbf{0.7489}$_{\pm0.0075}$ \\
WormsTwoClass                  & \textbf{0.8139}$_{\pm0.0198}$ & \textbf{0.8139}$_{\pm0.0198}$ & 0.7879$_{\pm0.0327}$                           & 0.7965$_{\pm0.015}$                            \\
Yoga                           & 0.815$_{\pm0.0012}$                            & 0.7452$_{\pm0.0013}$                           & 0.8217$_{\pm0.0099}$                           & \textbf{0.9061}$_{\pm0.0021}$ \\
\midrule
Handwriting                    & 0.3392$_{\pm0.01}$                             & 0.4271$_{\pm0.0113}$                           & 0.3294$_{\pm0.0116}$                           & \textbf{0.4773}$_{\pm0.0119}$ \\
JapaneseVowels                 & 0.9631$_{\pm0.0056}$                           & 0.9649$_{\pm0.0}$                              & 0.9315$_{\pm0.0145}$                           & \textbf{0.9757}$_{\pm0.0027}$ \\
LSST                           & 0.6054$_{\pm0.0021}$                           & 0.6459$_{\pm0.0006}$                           & 0.666$_{\pm0.0111}$                            & \textbf{0.6741}$_{\pm0.0021}$ \\
Libras                         & 0.8981$_{\pm0.0085}$                           & 0.8963$_{\pm0.014}$                            & 0.9185$_{\pm0.0064}$                           & \textbf{0.9278}$_{\pm0.0111}$ \\
NATOPS                         & 0.9074$_{\pm0.0128}$                           & \textbf{0.9259}$_{\pm0.0116}$ & 0.8079$_{\pm0.0189}$                           & \textbf{0.9259}$_{\pm0.0085}$ \\
PhonemeSpectra                 & 0.2735$_{\pm0.0078}$                           & 0.2934$_{\pm0.0002}$                           & 0.2082$_{\pm0.0067}$                           & \textbf{0.3106}$_{\pm0.0081}$ \\
RacketSports                   & 0.9232$_{\pm0.0038}$                           & 0.9276$_{\pm0.0066}$                           & 0.8487$_{\pm0.0066}$                           & \textbf{0.9298}$_{\pm0.01}$   \\
SelfRegulationSCP1             & 0.8043$_{\pm0.011}$                            & 0.8248$_{\pm0.0052}$                           & \textbf{0.8487}$_{\pm0.0071}$ & 0.843$_{\pm0.0034}$                            \\
SelfRegulationSCP2             & 0.4759$_{\pm0.0452}$                           & 0.487$_{\pm0.0085}$                            & 0.487$_{\pm0.014}$                             & \textbf{0.4889}$_{\pm0.0309}$ \\
SpokenArabicDigits             & 0.8392$_{\pm0.0046}$                           & 0.9291$_{\pm0.0016}$                           & 0.982$_{\pm0.0027}$                            & \textbf{0.9861}$_{\pm0.0009}$ \\
UWaveGestureLibrary            & 0.8135$_{\pm0.01}$                             & 0.8594$_{\pm0.0031}$                           & 0.8833$_{\pm0.0208}$                           & \textbf{0.9385}$_{\pm0.011}$  \\
\midrule
\textit{\textbf{Best Count}} & 17 & 19 & 18 & \textbf{118} \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\end{table}


\begin{table}[ht!]
\caption{Comparison of different fine-tuning regimes for Mantis on the \texttt{151-D} benchmark. The best epoch accuracy is averaged over 3 random seeds and reported with the standard deviation.}
\label{tab:best-epoch-res}
\begin{minipage}{0.5\textwidth}
{\scalebox{\scalefactorft}{
\begin{tabular}{l|llll}
\toprule
                               & RF                                             & Head                                           & Scratch                                        & Full                                           \\
\midrule
ACSF1                          & 0.6133$_{\pm0.0208}$                     & 0.62$_{\pm0.0265}$                             & 0.6433$_{\pm0.0451}$                           & \textbf{0.7467}$_{\pm0.0416}$ \\
Adiac                          & 0.7332$_{\pm0.0039}$                     & 0.5857$_{\pm0.0051}$                           & 0.7613$_{\pm0.0129}$                           & \textbf{0.8295}$_{\pm0.0082}$ \\
AllGestureWiimoteX             & 0.6705$_{\pm0.0044}$                     & 0.551$_{\pm0.0008}$                            & 0.6962$_{\pm0.0058}$                           & \textbf{0.8029}$_{\pm0.0065}$ \\
AllGestureWiimoteY             & 0.6671$_{\pm0.0057}$                     & 0.5614$_{\pm0.0052}$                           & 0.739$_{\pm0.0008}$                            & \textbf{0.8129}$_{\pm0.0089}$ \\
AllGestureWiimoteZ             & 0.6695$_{\pm0.0033}$                     & 0.5467$_{\pm0.0008}$                           & 0.6367$_{\pm0.0246}$                           & \textbf{0.7481}$_{\pm0.0095}$ \\
ArrowHead                      & 0.7105$_{\pm0.0175}$                     & 0.7276$_{\pm0.0119}$                           & 0.8$_{\pm0.0286}$                              & \textbf{0.8229}$_{\pm0.0297}$ \\
BME                            & 0.9311$_{\pm0.0038}$                     & 0.8756$_{\pm0.0139}$                           & 0.9933$_{\pm0.0}$                              & \textbf{1.0}$_{\pm0.0}$       \\
Beef                           & 0.6556$_{\pm0.0509}$                     & 0.6222$_{\pm0.0385}$                           & 0.8222$_{\pm0.0694}$                           & \textbf{0.8667}$_{\pm0.0}$    \\
BeetleFly                      & 0.85$_{\pm0.05}$                         & \textbf{0.9}$_{\pm0.0}$       & 0.7$_{\pm0.0}$                                 & \textbf{0.9}$_{\pm0.05}$      \\
BirdChicken                    & \textbf{1.0}$_{\pm0.0}$ & \textbf{1.0}$_{\pm0.0}$       & 0.9$_{\pm0.0}$                                 & \textbf{1.0}$_{\pm0.0}$       \\
CBF                            & 0.993$_{\pm0.0013}$                      & 0.9941$_{\pm0.0006}$                           & 0.9922$_{\pm0.008}$                            & \textbf{0.9996}$_{\pm0.0006}$ \\
Car                            & 0.7722$_{\pm0.0419}$                     & 0.7778$_{\pm0.0192}$                           & 0.8$_{\pm0.0}$                                 & \textbf{0.9}$_{\pm0.0289}$    \\
Chinatown                      & 0.8737$_{\pm0.0168}$                     & 0.8785$_{\pm0.0094}$                           & 0.964$_{\pm0.0017}$                            & \textbf{0.9776}$_{\pm0.0067}$ \\
ChlorineConcentration          & 0.6806$_{\pm0.0019}$                     & 0.5704$_{\pm0.0011}$                           & 0.753$_{\pm0.0056}$                            & \textbf{0.7788}$_{\pm0.0072}$ \\
CinCECGTorso                   & 0.6611$_{\pm0.0036}$                     & 0.7179$_{\pm0.0048}$                           & 0.7901$_{\pm0.0198}$                           & \textbf{0.856}$_{\pm0.0077}$  \\
Coffee                         & 0.9524$_{\pm0.0206}$                     & 0.9643$_{\pm0.0}$                              & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
Computers                      & 0.7373$_{\pm0.0092}$                     & 0.728$_{\pm0.0069}$                            & 0.7533$_{\pm0.0162}$                           & \textbf{0.7773}$_{\pm0.0046}$ \\
CricketX                       & 0.7368$_{\pm0.0171}$                     & 0.6966$_{\pm0.003}$                            & 0.7812$_{\pm0.0146}$                           & \textbf{0.8282}$_{\pm0.0133}$ \\
CricketY                       & 0.7504$_{\pm0.0065}$                     & 0.7051$_{\pm0.0026}$                           & 0.8$_{\pm0.0026}$                              & \textbf{0.8385}$_{\pm0.0051}$ \\
CricketZ                       & 0.7906$_{\pm0.0039}$                     & 0.7333$_{\pm0.0077}$                           & 0.7991$_{\pm0.0097}$                           & \textbf{0.8521}$_{\pm0.0082}$ \\
Crop                           & 0.6756$_{\pm0.0018}$                     & 0.6745$_{\pm0.0001}$                           & 0.7566$_{\pm0.0063}$                           & \textbf{0.7702}$_{\pm0.0005}$ \\
DiatomSizeReduction            & 0.8845$_{\pm0.0019}$                     & 0.8911$_{\pm0.0191}$                           & 0.9031$_{\pm0.0147}$                           & \textbf{0.9346}$_{\pm0.0033}$ \\
DistalPhalanxOutlineAgeGroup   & 0.789$_{\pm0.015}$                       & \textbf{0.8106}$_{\pm0.0042}$ & 0.7506$_{\pm0.011}$                            & 0.7938$_{\pm0.0042}$                           \\
DistalPhalanxOutlineCorrect    & 0.75$_{\pm0.0126}$                       & 0.7729$_{\pm0.0055}$                           & \textbf{0.8056}$_{\pm0.0091}$ & 0.7935$_{\pm0.0036}$                           \\
DistalPhalanxTW                & 0.6859$_{\pm0.011}$                      & 0.6763$_{\pm0.0125}$                           & 0.7266$_{\pm0.0125}$                           & \textbf{0.7338}$_{\pm0.019}$  \\
DodgerLoopDay                  & 0.55$_{\pm0.0217}$                       & 0.5292$_{\pm0.026}$                            & 0.6208$_{\pm0.0191}$                           & \textbf{0.6375}$_{\pm0.0125}$ \\
DodgerLoopGame                 & 0.7585$_{\pm0.0221}$                     & 0.7222$_{\pm0.0111}$                           & 0.843$_{\pm0.0084}$                            & \textbf{0.9541}$_{\pm0.0042}$ \\
DodgerLoopWeekend              & 0.9517$_{\pm0.0084}$                     & 0.9783$_{\pm0.0126}$                           & \textbf{0.9855}$_{\pm0.0}$    & \textbf{0.9855}$_{\pm0.0}$    \\
ECG200                         & 0.82$_{\pm0.01}$                         & 0.8033$_{\pm0.0252}$                           & 0.8467$_{\pm0.0115}$                           & \textbf{0.9133}$_{\pm0.0115}$ \\
ECG5000                        & 0.9211$_{\pm0.001}$                      & 0.9185$_{\pm0.0038}$                           & 0.9411$_{\pm0.0008}$                           & \textbf{0.9459}$_{\pm0.0014}$ \\
ECGFiveDays                    & 0.909$_{\pm0.0218}$                      & 0.8668$_{\pm0.0401}$                           & 0.7855$_{\pm0.0169}$                           & \textbf{0.9694}$_{\pm0.014}$  \\
EOGHorizontalSignal            & 0.5875$_{\pm0.0089}$                     & 0.5783$_{\pm0.0064}$                           & 0.6703$_{\pm0.0194}$                           & \textbf{0.6934}$_{\pm0.012}$  \\
EOGVerticalSignal              & 0.4751$_{\pm0.0}$                        & 0.4825$_{\pm0.0105}$                           & 0.5396$_{\pm0.0058}$                           & \textbf{0.5773}$_{\pm0.0073}$ \\
Earthquakes                    & 0.7482$_{\pm0.0}$                        & 0.7506$_{\pm0.0042}$                           & \textbf{0.7866}$_{\pm0.015}$  & 0.7602$_{\pm0.015}$                            \\
ElectricDevices                & 0.7226$_{\pm0.0026}$                     & 0.7064$_{\pm0.001}$                            & 0.7448$_{\pm0.0044}$                           & \textbf{0.7643}$_{\pm0.005}$  \\
EthanolLevel                   & 0.2993$_{\pm0.011}$                      & 0.324$_{\pm0.006}$                             & 0.6987$_{\pm0.0194}$                           & \textbf{0.7393}$_{\pm0.1052}$ \\
FaceAll                        & 0.7815$_{\pm0.0074}$                     & 0.8053$_{\pm0.0062}$                           & \textbf{0.9542}$_{\pm0.0036}$ & 0.8554$_{\pm0.0343}$                           \\
FaceFour                       & 0.9508$_{\pm0.0066}$                     & 0.9508$_{\pm0.0174}$                           & 0.8485$_{\pm0.0347}$                           & \textbf{0.9811}$_{\pm0.0066}$ \\
FacesUCR                       & 0.8354$_{\pm0.0054}$                     & 0.8437$_{\pm0.0104}$                           & 0.8816$_{\pm0.0054}$                           & \textbf{0.942}$_{\pm0.0061}$  \\
FiftyWords                     & 0.6462$_{\pm0.0096}$                     & 0.7026$_{\pm0.0178}$                           & 0.8176$_{\pm0.0038}$                           & \textbf{0.863}$_{\pm0.0013}$  \\
Fish                           & 0.9333$_{\pm0.0066}$                     & 0.9333$_{\pm0.0033}$                           & 0.939$_{\pm0.0087}$                            & \textbf{0.979}$_{\pm0.0087}$  \\
FordA                          & 0.8581$_{\pm0.0048}$                     & 0.8881$_{\pm0.0004}$                           & 0.9301$_{\pm0.0031}$                           & \textbf{0.9477}$_{\pm0.0013}$ \\
FordB                          & 0.7305$_{\pm0.0031}$                     & 0.7704$_{\pm0.0033}$                           & 0.8115$_{\pm0.0036}$                           & \textbf{0.8477}$_{\pm0.004}$  \\
FreezerRegularTrain            & 0.9374$_{\pm0.0043}$                     & 0.8767$_{\pm0.0088}$                           & \textbf{0.9971}$_{\pm0.0004}$ & 0.9967$_{\pm0.0014}$                           \\
FreezerSmallTrain              & 0.7942$_{\pm0.0059}$                     & 0.8092$_{\pm0.0041}$                           & 0.8601$_{\pm0.073}$                            & \textbf{0.9648}$_{\pm0.0219}$ \\
Fungi                          & 0.8262$_{\pm0.0164}$                     & 0.8477$_{\pm0.0224}$                           & 0.948$_{\pm0.0164}$                            & \textbf{0.9892}$_{\pm0.0108}$ \\
GestureMidAirD1                & 0.659$_{\pm0.0044}$                      & 0.6026$_{\pm0.0044}$                           & 0.7103$_{\pm0.0089}$                           & \textbf{0.7949}$_{\pm0.0044}$ \\
GestureMidAirD2                & 0.6154$_{\pm0.0077}$                     & 0.5282$_{\pm0.0118}$                           & 0.6974$_{\pm0.0222}$                           & \textbf{0.7205}$_{\pm0.0247}$ \\
GestureMidAirD3                & 0.3282$_{\pm0.016}$                      & 0.3154$_{\pm0.0266}$                           & 0.4359$_{\pm0.016}$                            & \textbf{0.4795}$_{\pm0.0178}$ \\
GesturePebbleZ1                & 0.9283$_{\pm0.0034}$                     & 0.9186$_{\pm0.0116}$                           & 0.9322$_{\pm0.0089}$                           & \textbf{0.9574}$_{\pm0.0146}$ \\
GesturePebbleZ2                & 0.9219$_{\pm0.0256}$                     & \textbf{0.9515}$_{\pm0.0097}$ & 0.8882$_{\pm0.0193}$                           & 0.9451$_{\pm0.0159}$                           \\
GunPoint                       & 0.98$_{\pm0.0067}$                       & 0.9822$_{\pm0.0038}$                           & 0.9867$_{\pm0.0133}$                           & \textbf{0.9978}$_{\pm0.0038}$ \\
GunPointAgeSpan                & 0.9905$_{\pm0.0}$                        & 0.9821$_{\pm0.0037}$                           & 0.9947$_{\pm0.0048}$                           & \textbf{0.9989}$_{\pm0.0018}$ \\
GunPointMaleVersusFemale       & 0.9958$_{\pm0.0018}$                     & 0.9863$_{\pm0.0048}$                           & 0.9947$_{\pm0.0018}$                           & \textbf{1.0}$_{\pm0.0}$       \\
GunPointOldVersusYoung         & 0.9968$_{\pm0.0}$                        & 0.9968$_{\pm0.0}$                              & 0.9968$_{\pm0.0}$                              & \textbf{1.0}$_{\pm0.0}$       \\
Ham                            & 0.673$_{\pm0.0145}$                      & 0.7143$_{\pm0.0252}$                           & \textbf{0.8159}$_{\pm0.0198}$ & 0.7016$_{\pm0.0198}$                           \\
HandOutlines                   & 0.9162$_{\pm0.0072}$                     & 0.8928$_{\pm0.0068}$                           & 0.945$_{\pm0.0056}$                            & \textbf{0.955}$_{\pm0.0016}$  \\
Haptics                        & 0.4968$_{\pm0.0032}$                     & 0.4697$_{\pm0.0131}$                           & 0.5032$_{\pm0.0065}$                           & \textbf{0.5747}$_{\pm0.0234}$ \\
Herring                        & 0.6667$_{\pm0.0239}$                     & 0.7188$_{\pm0.0271}$                           & 0.6458$_{\pm0.0239}$                           & \textbf{0.724}$_{\pm0.009}$   \\
HouseTwenty                    & 0.9412$_{\pm0.0}$                        & 0.9496$_{\pm0.0084}$                           & 0.9356$_{\pm0.0049}$                           & \textbf{0.9776}$_{\pm0.0097}$ \\
InlineSkate                    & 0.363$_{\pm0.0136}$                      & 0.3182$_{\pm0.0101}$                           & 0.403$_{\pm0.0211}$                            & \textbf{0.4515}$_{\pm0.0132}$ \\
InsectEPGRegularTrain          & \textbf{1.0}$_{\pm0.0}$ & \textbf{1.0}$_{\pm0.0}$       & 0.992$_{\pm0.0}$                               & \textbf{1.0}$_{\pm0.0}$       \\
InsectEPGSmallTrain            & \textbf{1.0}$_{\pm0.0}$ & \textbf{1.0}$_{\pm0.0}$       & 0.9665$_{\pm0.0061}$                           & \textbf{1.0}$_{\pm0.0}$       \\
InsectWingbeatSound            & 0.519$_{\pm0.0044}$                      & 0.4791$_{\pm0.0099}$                           & 0.6222$_{\pm0.0066}$                           & \textbf{0.6246}$_{\pm0.0068}$ \\
\midrule
Blink                          & \textbf{1.0}$_{\pm0.0}$ & 0.9963$_{\pm0.0046}$                           & 0.9896$_{\pm0.0056}$                           & \textbf{1.0}$_{\pm0.0}$       \\
MotionSenseHAR                 & \textbf{1.0}$_{\pm0.0}$ & 0.9962$_{\pm0.0}$                              & 0.9887$_{\pm0.0}$                              & \textbf{1.0}$_{\pm0.0}$       \\
SharePriceIncrease             & 0.6874$_{\pm0.0}$                        & 0.6746$_{\pm0.0012}$                           & \textbf{0.6891}$_{\pm0.0039}$ & 0.6874$_{\pm0.0027}$  \\
\midrule
ArticularyWordRecognition      & 0.9933$_{\pm0.0033}$                     & 0.9933$_{\pm0.0}$                              & \textbf{0.9967}$_{\pm0.0}$    & 0.9933$_{\pm0.0}$                              \\
BasicMotions                   & \textbf{1.0}$_{\pm0.0}$ & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
CharacterTrajectories          & 0.9396$_{\pm0.0008}$                     & 0.9673$_{\pm0.0021}$                           & 0.9838$_{\pm0.0029}$                           & \textbf{0.9928}$_{\pm0.0004}$ \\
Cricket                        & \textbf{1.0}$_{\pm0.0}$ & 0.9907$_{\pm0.008}$                            & 0.9861$_{\pm0.0}$                              & \textbf{1.0}$_{\pm0.0}$       \\
ERing                          & 0.9407$_{\pm0.0098}$                     & 0.9296$_{\pm0.0192}$                           & 0.9432$_{\pm0.0077}$                           & \textbf{0.9926}$_{\pm0.0074}$ \\
EigenWorms                     & 0.7532$_{\pm0.0159}$                     & 0.7379$_{\pm0.0233}$                           & 0.7023$_{\pm0.0202}$                           & \textbf{0.8372}$_{\pm0.0044}$ \\
Epilepsy                       & 0.9952$_{\pm0.0042}$                     & 0.9928$_{\pm0.0}$                              & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
EthanolConcentration           & 0.27$_{\pm0.0101}$                       & 0.3156$_{\pm0.0076}$                           & 0.3321$_{\pm0.0154}$                           & \textbf{0.4208}$_{\pm0.0195}$ \\
HandMovementDirection          & 0.2117$_{\pm0.0413}$                     & 0.3829$_{\pm0.0639}$                           & \textbf{0.5135}$_{\pm0.0234}$ & 0.4009$_{\pm0.0206}$                           \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\hfill
\begin{minipage}{0.5\textwidth}
{\scalebox{\scalefactorft}{
\begin{tabular}{l|llll}
\toprule
                               & RF                                             & Head                                           & Scratch                                        & Full                                           \\
\midrule
ItalyPowerDemand               & 0.9077$_{\pm0.0035}$                     & 0.9054$_{\pm0.0046}$                           & \textbf{0.9725}$_{\pm0.002}$  & 0.9572$_{\pm0.0}$                              \\
LargeKitchenAppliances         & 0.7804$_{\pm0.0041}$                     & 0.7876$_{\pm0.0108}$                           & \textbf{0.8853}$_{\pm0.0053}$ & 0.8676$_{\pm0.0094}$                           \\
Lightning2                     & 0.8033$_{\pm0.0}$                        & 0.8251$_{\pm0.0189}$                           & \textbf{0.8798}$_{\pm0.025}$  & 0.8361$_{\pm0.0}$                              \\
Lightning7                     & 0.7763$_{\pm0.0285}$                     & 0.7763$_{\pm0.0209}$                           & 0.7671$_{\pm0.0137}$                           & \textbf{0.8356}$_{\pm0.0137}$ \\
Mallat                         & 0.8903$_{\pm0.0137}$                     & 0.7765$_{\pm0.0019}$                           & 0.9529$_{\pm0.0077}$                           & \textbf{0.9774}$_{\pm0.0122}$ \\
Meat                           & 0.9389$_{\pm0.0096}$                     & 0.8944$_{\pm0.0255}$                           & 0.9222$_{\pm0.0509}$                           & \textbf{0.9778}$_{\pm0.0096}$ \\
MedicalImages                  & 0.7079$_{\pm0.0035}$                     & 0.6961$_{\pm0.0139}$                           & 0.7605$_{\pm0.0164}$                           & \textbf{0.8127}$_{\pm0.0106}$ \\
MelbournePedestrian            & 0.9016$_{\pm0.0031}$                     & 0.8922$_{\pm0.0033}$                           & 0.9615$_{\pm0.0038}$                           & \textbf{0.9728}$_{\pm0.0014}$ \\
MiddlePhalanxOutlineAgeGroup   & 0.5801$_{\pm0.0099}$                     & 0.6126$_{\pm0.0262}$                           & \textbf{0.6407}$_{\pm0.0037}$ & 0.6385$_{\pm0.0037}$                           \\
MiddlePhalanxOutlineCorrect    & 0.8099$_{\pm0.0099}$                     & 0.8076$_{\pm0.0119}$                           & 0.8328$_{\pm0.0159}$                           & \textbf{0.8786}$_{\pm0.0079}$ \\
MiddlePhalanxTW                & 0.5368$_{\pm0.0099}$                     & 0.5823$_{\pm0.0228}$                           & \textbf{0.5974}$_{\pm0.013}$  & 0.5931$_{\pm0.0228}$                           \\
MixedShapesRegularTrain        & 0.943$_{\pm0.0044}$                      & 0.9388$_{\pm0.004}$                            & 0.9625$_{\pm0.0014}$                           & \textbf{0.9812}$_{\pm0.0005}$ \\
MixedShapesSmallTrain          & 0.8961$_{\pm0.0004}$                     & 0.8937$_{\pm0.0054}$                           & 0.8983$_{\pm0.0114}$                           & \textbf{0.9581}$_{\pm0.0046}$ \\
MoteStrain                     & 0.9137$_{\pm0.0136}$                     & 0.9023$_{\pm0.0113}$                           & \textbf{0.9358}$_{\pm0.0009}$ & 0.9289$_{\pm0.0085}$                           \\
NonInvasiveFetalECGThorax1     & 0.6222$_{\pm0.0037}$                     & 0.6733$_{\pm0.0013}$                           & 0.9113$_{\pm0.0011}$                           & \textbf{0.9411}$_{\pm0.0026}$ \\
NonInvasiveFetalECGThorax2     & 0.6872$_{\pm0.0025}$                     & 0.715$_{\pm0.0028}$                            & 0.9176$_{\pm0.0013}$                           & \textbf{0.9481}$_{\pm0.0027}$ \\
OSULeaf                        & 0.8747$_{\pm0.0104}$                     & 0.8719$_{\pm0.0109}$                           & 0.8774$_{\pm0.0063}$                           & \textbf{0.9642}$_{\pm0.0167}$ \\
OliveOil                       & 0.9333$_{\pm0.0}$                        & 0.4$_{\pm0.0}$                                 & 0.8333$_{\pm0.0}$                              & \textbf{0.9556}$_{\pm0.0192}$ \\
PLAID                          & 0.8181$_{\pm0.0047}$                     & 0.5469$_{\pm0.0022}$                           & 0.9044$_{\pm0.0047}$                           & \textbf{0.9243}$_{\pm0.0039}$ \\
PhalangesOutlinesCorrect       & 0.7786$_{\pm0.0042}$                     & 0.7692$_{\pm0.0012}$                           & 0.8322$_{\pm0.0042}$                           & \textbf{0.8539}$_{\pm0.0013}$ \\
Phoneme                        & 0.323$_{\pm0.0034}$                      & 0.3231$_{\pm0.002}$                            & 0.2795$_{\pm0.0024}$                           & \textbf{0.3499}$_{\pm0.0075}$ \\
PickupGestureWiimoteZ          & 0.74$_{\pm0.02}$                         & 0.7867$_{\pm0.0702}$                           & 0.7067$_{\pm0.0306}$                           & \textbf{0.8267}$_{\pm0.0306}$ \\
PigAirwayPressure              & 0.484$_{\pm0.0147}$                      & 0.4519$_{\pm0.0096}$                           & 0.2035$_{\pm0.0147}$                           & \textbf{0.524}$_{\pm0.0173}$  \\
PigArtPressure                 & 0.9103$_{\pm0.0028}$                     & 0.8221$_{\pm0.0173}$                           & 0.6875$_{\pm0.0}$                              & \textbf{0.9135}$_{\pm0.0096}$ \\
PigCVP                         & 0.7837$_{\pm0.0127}$                     & 0.7788$_{\pm0.0}$                              & 0.4984$_{\pm0.01}$                             & \textbf{0.8974}$_{\pm0.0222}$ \\
Plane                          & \textbf{1.0}$_{\pm0.0}$ & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
PowerCons                      & 0.9093$_{\pm0.0032}$                     & 0.8944$_{\pm0.02}$                             & \textbf{0.9944}$_{\pm0.0}$    & 0.9889$_{\pm0.0}$                              \\
ProximalPhalanxOutlineAgeGroup & 0.8537$_{\pm0.0049}$                     & 0.8732$_{\pm0.0}$                              & 0.8813$_{\pm0.0028}$                           & \textbf{0.8829}$_{\pm0.0084}$ \\
ProximalPhalanxOutlineCorrect  & 0.8202$_{\pm0.0086}$                     & 0.8499$_{\pm0.0086}$                           & 0.9118$_{\pm0.0086}$                           & \textbf{0.9244}$_{\pm0.0034}$ \\
ProximalPhalanxTW              & 0.7691$_{\pm0.0028}$                     & 0.7789$_{\pm0.0056}$                           & 0.8179$_{\pm0.0028}$                           & \textbf{0.8211}$_{\pm0.0056}$ \\
RefrigerationDevices           & 0.504$_{\pm0.0122}$                      & 0.5298$_{\pm0.0041}$                           & \textbf{0.5538}$_{\pm0.0161}$ & 0.5431$_{\pm0.0041}$                           \\
Rock                           & 0.7133$_{\pm0.0115}$                     & 0.7667$_{\pm0.0231}$                           & 0.82$_{\pm0.02}$                               & \textbf{0.8667}$_{\pm0.0115}$ \\
ScreenType                     & 0.4649$_{\pm0.0134}$                     & 0.4809$_{\pm0.012}$                            & 0.5182$_{\pm0.0031}$                           & \textbf{0.5511}$_{\pm0.0362}$ \\
SemgHandGenderCh2              & 0.9189$_{\pm0.0086}$                     & 0.86$_{\pm0.0033}$                             & 0.9494$_{\pm0.0098}$                           & \textbf{0.9617}$_{\pm0.0145}$ \\
SemgHandMovementCh2            & 0.797$_{\pm0.0056}$                      & 0.563$_{\pm0.0168}$                            & 0.8378$_{\pm0.0204}$                           & \textbf{0.8674}$_{\pm0.0278}$ \\
SemgHandSubjectCh2             & 0.8622$_{\pm0.0135}$                     & 0.7763$_{\pm0.0064}$                           & 0.9356$_{\pm0.0102}$                           & \textbf{0.9496}$_{\pm0.0181}$ \\
ShakeGestureWiimoteZ           & 0.8867$_{\pm0.0115}$                     & 0.8933$_{\pm0.0231}$                           & 0.9$_{\pm0.0}$                                 & \textbf{0.9667}$_{\pm0.0115}$ \\
ShapeletSim                    & 0.9278$_{\pm0.0111}$                     & 0.9167$_{\pm0.0111}$                           & 0.9815$_{\pm0.017}$                            & \textbf{1.0}$_{\pm0.0}$       \\
ShapesAll                      & 0.8194$_{\pm0.0054}$                     & 0.8517$_{\pm0.0076}$                           & 0.8817$_{\pm0.0083}$                           & \textbf{0.9078}$_{\pm0.001}$  \\
SmallKitchenAppliances         & 0.8089$_{\pm0.0081}$                     & 0.8302$_{\pm0.0015}$                           & 0.8347$_{\pm0.0053}$                           & \textbf{0.8471}$_{\pm0.0108}$ \\
SmoothSubspace                 & 0.9067$_{\pm0.0115}$                     & 0.9378$_{\pm0.0168}$                           & 0.9844$_{\pm0.0038}$                           & \textbf{0.9978}$_{\pm0.0038}$ \\
SonyAIBORobotSurface1          & 0.787$_{\pm0.0294}$                      & 0.8247$_{\pm0.03}$                             & \textbf{0.9257}$_{\pm0.0069}$ & 0.8763$_{\pm0.0603}$                           \\
SonyAIBORobotSurface2          & 0.8552$_{\pm0.0168}$                     & 0.8821$_{\pm0.0063}$                           & 0.8583$_{\pm0.0371}$                           & \textbf{0.9339}$_{\pm0.001}$  \\
StarLightCurves                & 0.9759$_{\pm0.0005}$                     & 0.9788$_{\pm0.0005}$                           & 0.9757$_{\pm0.0015}$                           & \textbf{0.9816}$_{\pm0.0006}$ \\
Strawberry                     & 0.9514$_{\pm0.0027}$                     & 0.9153$_{\pm0.0041}$                           & \textbf{0.9802}$_{\pm0.0031}$ & 0.9775$_{\pm0.0016}$                           \\
SwedishLeaf                    & 0.9275$_{\pm0.0009}$                     & 0.9253$_{\pm0.0024}$                           & 0.9456$_{\pm0.0016}$                           & \textbf{0.9744}$_{\pm0.0028}$ \\
Symbols                        & 0.9698$_{\pm0.0056}$                     & 0.9668$_{\pm0.0036}$                           & 0.9263$_{\pm0.0177}$                           & \textbf{0.9893}$_{\pm0.0057}$ \\
SyntheticControl               & 0.9767$_{\pm0.0067}$                     & 0.9844$_{\pm0.0051}$                           & 0.9811$_{\pm0.0051}$                           & \textbf{0.9956}$_{\pm0.0019}$ \\
ToeSegmentation1               & 0.9635$_{\pm0.0067}$                     & 0.9591$_{\pm0.011}$                            & 0.8918$_{\pm0.0198}$                           & \textbf{0.9825}$_{\pm0.0044}$ \\
ToeSegmentation2               & 0.9282$_{\pm0.0044}$                     & \textbf{0.9564}$_{\pm0.0089}$ & 0.9205$_{\pm0.0118}$                           & 0.9462$_{\pm0.0077}$                           \\
Trace                          & \textbf{1.0}$_{\pm0.0}$ & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       & \textbf{1.0}$_{\pm0.0}$       \\
TwoLeadECG                     & 0.9962$_{\pm0.0005}$                     & \textbf{0.9985}$_{\pm0.0005}$ & 0.9631$_{\pm0.0066}$                           & \textbf{0.9985}$_{\pm0.001}$  \\
TwoPatterns                    & 0.8802$_{\pm0.0079}$                     & 0.892$_{\pm0.0021}$                            & 0.9998$_{\pm0.0004}$                           & \textbf{1.0}$_{\pm0.0}$       \\
UMD                            & 0.9722$_{\pm0.0069}$                     & 0.9792$_{\pm0.0}$                              & 0.9884$_{\pm0.008}$                            & \textbf{0.9931}$_{\pm0.0}$    \\
UWaveGestureLibraryAll         & 0.8458$_{\pm0.0057}$                     & 0.8739$_{\pm0.0014}$                           & 0.9737$_{\pm0.0008}$                           & \textbf{0.9752}$_{\pm0.0007}$ \\
UWaveGestureLibraryX           & 0.7696$_{\pm0.0028}$                     & 0.7916$_{\pm0.002}$                            & 0.843$_{\pm0.0031}$                            & \textbf{0.8728}$_{\pm0.0017}$ \\
UWaveGestureLibraryY           & 0.6874$_{\pm0.0022}$                     & 0.7065$_{\pm0.0024}$                           & 0.7772$_{\pm0.0029}$                           & \textbf{0.8117}$_{\pm0.0003}$ \\
UWaveGestureLibraryZ           & 0.7324$_{\pm0.0036}$                     & 0.7591$_{\pm0.002}$                            & 0.7886$_{\pm0.0013}$                           & \textbf{0.8288}$_{\pm0.0021}$ \\
Wafer                          & 0.9903$_{\pm0.0003}$                     & 0.984$_{\pm0.0069}$                            & 0.9953$_{\pm0.0004}$                           & \textbf{0.9988}$_{\pm0.0005}$ \\
Wine                           & 0.7901$_{\pm0.0107}$                     & 0.6049$_{\pm0.0466}$                           & 0.7593$_{\pm0.0321}$                           & \textbf{0.8148}$_{\pm0.0185}$ \\
WordSynonyms                   & 0.5502$_{\pm0.0081}$                     & 0.4916$_{\pm0.0113}$                           & 0.6996$_{\pm0.0063}$                           & \textbf{0.7649}$_{\pm0.0027}$ \\
Worms                          & 0.6537$_{\pm0.027}$                      & 0.7186$_{\pm0.015}$                            & 0.7662$_{\pm0.013}$                            & \textbf{0.7792}$_{\pm0.026}$  \\
WormsTwoClass                  & 0.8139$_{\pm0.0198}$                     & 0.8182$_{\pm0.013}$                            & 0.8225$_{\pm0.027}$                            & \textbf{0.8312}$_{\pm0.013}$  \\
Yoga                           & 0.815$_{\pm0.0012}$                      & 0.7472$_{\pm0.0012}$                           & 0.8308$_{\pm0.0076}$                           & \textbf{0.9087}$_{\pm0.0022}$ \\
\midrule
Handwriting                    & 0.3392$_{\pm0.01}$                       & 0.4275$_{\pm0.0107}$                           & 0.3375$_{\pm0.0129}$                           & \textbf{0.482}$_{\pm0.0157}$  \\
JapaneseVowels                 & 0.9631$_{\pm0.0056}$                     & 0.9712$_{\pm0.0016}$                           & 0.9374$_{\pm0.0165}$                           & \textbf{0.9811}$_{\pm0.0054}$ \\
LSST                           & 0.6054$_{\pm0.0021}$                     & 0.6718$_{\pm0.0017}$                           & 0.6944$_{\pm0.0023}$                           & \textbf{0.7109}$_{\pm0.0015}$ \\
Libras                         & 0.8981$_{\pm0.0085}$                     & 0.8981$_{\pm0.0116}$                           & 0.937$_{\pm0.0085}$                            & \textbf{0.9389}$_{\pm0.0}$    \\
NATOPS                         & 0.9074$_{\pm0.0128}$                     & 0.9333$_{\pm0.0056}$                           & 0.819$_{\pm0.0115}$                            & \textbf{0.937}$_{\pm0.0116}$  \\
PhonemeSpectra                 & 0.2735$_{\pm0.0078}$                     & 0.2965$_{\pm0.0014}$                           & 0.2415$_{\pm0.0033}$                           & \textbf{0.3421}$_{\pm0.0023}$ \\
RacketSports                   & 0.9232$_{\pm0.0038}$                     & 0.9298$_{\pm0.0076}$                           & 0.8684$_{\pm0.0066}$                           & \textbf{0.9408}$_{\pm0.0}$    \\
SelfRegulationSCP1             & 0.8043$_{\pm0.011}$                      & 0.851$_{\pm0.012}$                             & 0.8896$_{\pm0.0052}$                           & \textbf{0.9135}$_{\pm0.0071}$ \\
SelfRegulationSCP2             & 0.4759$_{\pm0.0452}$                     & 0.5315$_{\pm0.0116}$                           & \textbf{0.5611}$_{\pm0.0111}$ & 0.5389$_{\pm0.0096}$                           \\
SpokenArabicDigits             & 0.8392$_{\pm0.0046}$                     & 0.9295$_{\pm0.0016}$                           & 0.9828$_{\pm0.0025}$                           & \textbf{0.987}$_{\pm0.0009}$  \\
UWaveGestureLibrary            & 0.8135$_{\pm0.01}$                       & 0.8594$_{\pm0.0031}$                           & 0.8958$_{\pm0.0079}$                           & \textbf{0.9438}$_{\pm0.0108}$ \\
\midrule
\textit{\textbf{Best Count}} &  9 &  11 &  25 & \textbf{128} \\
\bottomrule
\end{tabular}
}}
\end{minipage}
\end{table}






















\begin{table}[ht!]
\centering
\caption{The performance comparison between Mantis in the zero-shot feature extraction setting and when it is
fully fine-tuned with or without an adapter, in average over UEA-27 datasets. In the second case, the best possible
performance per dataset is taken.}
\label{tab:rf-vs-best-adapter}
\begin{tabular}{lll}
\toprule
dataset                   & RF                 & Full (Best Result)                 \\
\midrule
ArticularyWordRecognition & 0.9867$_{\pm0.0076}$ & \textbf{0.9933}$_{\pm0.0}$    \\
BasicMotions              & 0.9958$_{\pm0.0102}$ & \textbf{1.0}$_{\pm0.0}$       \\
CharacterTrajectories     & 0.9546$_{\pm0.0165}$ & \textbf{0.9947}$_{\pm0.0004}$ \\
Cricket                   & 0.9884$_{\pm0.0137}$ & \textbf{1.0}$_{\pm0.0}$       \\
DuckDuckGeese             & 0.42$_{\pm0.031}$    & \textbf{0.6}$_{\pm0.02}$      \\
ERing                     & 0.9549$_{\pm0.0174}$ & \textbf{0.9926}$_{\pm0.0074}$ \\
EigenWorms                & 0.7443$_{\pm0.0172}$ & \textbf{0.8601}$_{\pm0.0192}$ \\
Epilepsy                  & 0.9915$_{\pm0.0055}$ & \textbf{1.0}$_{\pm0.0}$       \\
EthanolConcentration      & 0.2738$_{\pm0.009}$  & \textbf{0.4208}$_{\pm0.0195}$ \\
FaceDetection             & 0.5354$_{\pm0.0119}$ & \textbf{0.6272}$_{\pm0.013}$  \\
FingerMovements           & 0.5183$_{\pm0.0354}$ & \textbf{0.6167}$_{\pm0.0058}$ \\
HandMovementDirection     & 0.2635$_{\pm0.0627}$ & \textbf{0.5135}$_{\pm0.027}$  \\
Handwriting               & 0.2876$_{\pm0.0569}$ & \textbf{0.5839}$_{\pm0.0283}$ \\
Heartbeat                 & 0.7626$_{\pm0.0408}$ & \textbf{0.7951}$_{\pm0.0129}$ \\
InsectWingbeatSubset      & 0.425$_{\pm0.1992}$  & \textbf{0.591}$_{\pm0.005}$   \\
JapaneseVowels            & 0.9216$_{\pm0.0459}$ & \textbf{0.9811}$_{\pm0.0054}$ \\
LSST                      & 0.613$_{\pm0.0084}$  & \textbf{0.7109}$_{\pm0.0015}$ \\
Libras                    & 0.8741$_{\pm0.0297}$ & \textbf{0.9704}$_{\pm0.0032}$ \\
MotorImagery              & 0.5483$_{\pm0.0417}$ & \textbf{0.6}$_{\pm0.01}$      \\
NATOPS                    & 0.8648$_{\pm0.0498}$ & \textbf{0.9611}$_{\pm0.0}$    \\
PEMS-SF                   & \textbf{0.9923}$_{\pm0.0119}$ & 0.9114$_{\pm0.0067}$ \\
PhonemeSpectra            & 0.2444$_{\pm0.0322}$ & \textbf{0.3547}$_{\pm0.0047}$ \\
RacketSports              & 0.8717$_{\pm0.0569}$ & \textbf{0.9408}$_{\pm0.0}$    \\
SelfRegulationSCP1        & 0.7793$_{\pm0.0293}$ & \textbf{0.917}$_{\pm0.0052}$  \\
SelfRegulationSCP2        & 0.4861$_{\pm0.0331}$ & \textbf{0.5685}$_{\pm0.0251}$ \\
SpokenArabicDigits        & 0.8872$_{\pm0.0527}$ & \textbf{0.9933}$_{\pm0.0014}$ \\
UWaveGestureLibrary       & 0.8432$_{\pm0.0339}$ & \textbf{0.9438}$_{\pm0.0108}$\\
\bottomrule
\end{tabular}
\end{table}



\end{document}