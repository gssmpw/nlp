%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{On Adversarial Attacks In Acoustic Drone Localization}

\begin{document}

\twocolumn[
\icmltitle{On Adversarial Attacks In Acoustic Drone Localization}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Tamir Shor}{tech}
\icmlauthor{Chaim Baskin}{bgu}
\icmlauthor{Alex Bronstein}{tech,ist}

%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{tech}{Technion -- Israel Institute of Technology, Haifa, Israel}
\icmlaffiliation{bgu}{Ben-Gurion University of the Negev, Be'er Sheva, Israel}
\icmlaffiliation{ist}{Institute of Science and Technology, Austria}

\icmlcorrespondingauthor{Tamir Shor}{tamir.shor@campus.technion.ac.il}


% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document


\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{} % otherwise use the standard text.

\begin{abstract}
Multi-rotor aerial autonomous vehicles (MAVs, more widely known as "drones") have been generating increased interest in recent years due to their growing applicability in a vast and diverse range of fields (e.g., agriculture, commercial delivery, search and rescue). The sensitivity of visual-based methods to lighting conditions and occlusions had prompted growing study of navigation reliant on other modalities, such as acoustic sensing. A major concern in using drones in scale for tasks in non-controlled environments is the potential threat of adversarial attacks over their navigational systems, exposing users to mission-critical failures, security breaches, and compromised safety outcomes that can endanger operators and bystanders. While previous work shows impressive progress in acoustic-based drone localization, prior research in adversarial attacks over drone navigation only addresses visual sensing-based systems. In this work, we aim to compensate for this gap by supplying a comprehensive analysis of the effect of PGD adversarial attacks over acoustic drone localization. We furthermore develop an algorithm for adversarial perturbation recovery, capable of markedly diminishing the affect of such attacks in our setting. The code for reproducing all experiments will be released upon publication.

\end{abstract}

\section{Introduction}
\label{sec:intro}

Recent years have brought tremendous progress in the use of multi-rotor autonomous aerial vehicles (drones) across a wide range of industries, with their applications expanding rapidly in both scope and variety \cite{ayamga2021multifaceted,merkert2020managing,moshref2021applications}.
These industries encompass humanity-crucial applications, such as emergency medicine \cite{johnson2021impact, zailani2020drone}, sustainability \cite{dutta2020application,mahroof2021drone} and disaster control \cite{daud2022applications,ishiwatari2024leveraging}, as well as life-quality and recreational uses \cite{tan2021public,benarbia2021literature}. One major contributor to the growing popularity of drones would be their potential in reducing the risks and added costs often incurred with human involvement upon operating in challenging, unfamiliar and unpredictable environments. 

\begin{figure}
\centering
 % Caption and label go in the first argument and the figure contents
 % go in the second argument


  
  \includegraphics[width=0.4\linewidth]{images/room.png}
  
  {\caption{\textbf{Adversarial Acoustic Localization Setting -}. Localization model input (green) is the drone sound response (blue) perturbed with an external speaker adversarial interference (red).}
  \label{fig:room}
  }
  
  
\end{figure}

The successful deployment of drones, or any non-stationary agent operating in an environment, heavily relies on the ability to efficiently and accurately navigate within it. This observation has fostered remarkable progress in drone navigation and localization in recent years \cite{kang2015analysis,dijkshoorn2012simultaneous,sorbelli2018range}, expedited by the tremendous progress achieved with the advent of deep-learning \cite{yousaf2022drone,bisio2021localization,zhang2022agile}. The currently prevalent approaches for drone navigation mostly rely on either GPS combined with inertial systems, passive visual odometry, active range sensors like LiDAR, or some combination thereof \cite{arafat2023vision,aburaya2024review,niu2022ic,debeunne2020review}. Using such modalities would be a natural choice in many cases, given their accuracy, availability, and vast amounts of relevant existing research. Nonetheless, in many common scenarios, the reliance on such methods is either challenging \cite{arafat2023vision, al2021self}, ineffective \cite{dreissig2023survey}, or altogether infeasible \cite{al2021self,meles2023performance}. Such difficulties have encouraged growing research in localization relying on other modalities, with one of the most prominent approaches being acoustic localization \cite{he2023acoustic,sun2023indoor,shor2024active}. These methods rely on acoustic signals (solely or jointly with other modalities) to perform localization more robust \cite{famili2022rail} to the various obstructions hindering the use of previously mentioned counterparts.

Alongside the growing prevalence of drones in our lives, there also comes growing concern of increased exposure to potential adversarial attacks. As previous studies indicate \cite{mynuddin2023adversarial,wisniewski2024autonomous,guesmi2024navigating}, adversarial attacks can be used to manipulate drones into undesirable or harmful behavior, and even endanger bystanders (e.g. adversarial crashes \cite{fu2021remote}). While past work does tackle defense against such attacks \cite{mynuddin2024trojan,wang2023survey}, these studies only focus on adversarial attacks over visual or LiDAR channels. Despite of the rapidly increasing popularity acoustic drone localization is garnering, to the best of our knowledge, no prior work has investigated adversarial attacks and defenses related to acoustic sensing-led navigation. 

To bridge this gap, in this work we provide, to the best of our knowledge for the first time, the formulation and impact analysis of white-box adversarial attacks over acoustic drone localization. In our setting we study adversarial sound generated by a single stationary source, external to the drone. Furthermore, we rely on the phase modulation mechanism developed in the propulsion noise-based localization algorithm proposed in \cite{shor2024active} to initiate a novel adversarial defense algorithm, capable of not only increasing adversarial robustness, but also delineate the sampled perturbation from the "clean" input signal, assuming only minimal assumptions over the attack source. We also expand the algorithm from \cite{shor2024active} to perform localization over acoustic signals recorded from actual complex acoustic settings, rather than from fully-simulated data, as presented in the original work. We emphasize that while our work focuses on drone localization, it is applicable to any acoustic localization tasks involving a single autonomous agent. 

In summary, our contribution is fourfold: 
1) We extend \cite{shor2024active} to demonstrate self-sound-based acoustic localization using real-world acoustic data. 
2) We formulate adversarial attacks on acoustic drone navigation, benchmark their effects on localization performance, and present a fully differentiable pipeline for localization and attack optimization in an acoustic setting. 
3) We analyze the resource and performance implications of optimizing attack-source location. 
4) We develop an acoustic-channel attack test-time defense algorithm, capable of credibly reconstructing the original perturbation waveform sampled by the drone's acoustic sensing system.
\section{Related Work}
\label{sec:rel}

In this work we adopt the acoustic localization algorithm from \cite{shor2024active}. This algorithm performs drone localization based solely on the self-sound emitted by the drone's propulsion system, as sampled by a circular array of microphones $\mathcal{M} $ located around the drone. The authors propose a three-step pipeline. First, a \textit{forward model} is used to model the self-sound emitted by the drone's propulsion system in free space, using a fixed, parametrized set $\mathcal{S}$ of point sound sources optimized to fit an actual free-space recording. Second, a neural, transformer-based \textit{inverse model} is used to regress the drone location based on the propulsion sound as sampled by the microphone array. This sound is simulated using both the forward model and RIR by superimposing the direct path from each point sound source to each microphone, along with the reflected paths from the walls. These paths are given by the image source model (ISM), replacing source reflections on walls with imaginary point sound sources (termed \textit{images} \cite{allen1979image}). Lastly, the authors present the optimization of the time-dependent angular offsets of the rotors, termed \textit{phase modulation}, in order to improve localization accuracy. We further elaborate on the concept of phase modulation in \cref{sec:defense} in the sequel. Our reason for using the approach from \cite{shor2024active} is the fact that it presents an accurate, purely acoustic-based localization model for us to evaluate under acoustic adversarial perturbations, and mainly since the proposed phase modulation mechanism will serve us in establishing our proposed defense method in \cref{sec:defense}. 

One shortcoming of \cite{shor2024active} is the choice to compute input to the location regressor (a.k.a inverse model), i.e. the sound sampled at each sensor using a simulation superimposing a set of point sources given by the ISM, with \cref{eq:sound} being applied over each point sound source separately. While this method is relatively accurate in sufficient point source sample density \cite{scheibler2018pyroomacoustics}, the computational costs entailed in computing the ISM render this method prohibitively expensive for larger and more complex acoustic environments. Our specific use-case of adversarial attack optimization calls for the optimization of sound emitted by the attacker (\cref{sec:attackf}), obligating rapid inference of the forward model (i.e., through sound generation). This makes the original ISM-based approach of sound computation inapplicable for our purposes. In this work we therefore opt develop a modified version of the ISM-reliant algorithm from \cite{shor2024active}, making use of neural-acoustic fields (NAFs) \cite{luo2022learning}, as further elaborated on \cref{sec:clean}.


\section{Method}
In the following section, we outline our approach to developing adversarial attacks and defenses for the task of acoustic drone localization. \cref{sec:background} lays the foundations of acoustic sensing-guided localization, and \cref{sec:clean} presents the regressor that will be subjected to the adversarial attacks. \cref{sec:attackf} formulates the proposed acoustic adversarial attack, while \cref{sec:defense} proposes a defense method relying on active rotor phase modulation.

\subsection{Acoustic Localization Background}
\label{sec:background}
Acoustic localization is the task of identifying the location $\mathbf{x}_{\mathrm{s}} \in \mathbb{R}^n$ of a sound source emitting a sound signal $s_{\mathrm{s}}(t)\in \mathbb{R}^T$  in a known environment, based on the response of that signal $s_{\mathrm{m}}(t)\in \mathbb{R}^T$ as measured at a given sensor (microphone) location $\mathbf{x}_{\mathrm{m}} \in \mathbb{R}^n$. Here, the temporal signals are assumed to be sampled at $T$ discrete time points, and $n$ denotes the number of location degrees of freedom. While, in the most general case, $n=6$ (for location and orientation in 3D space), in this work, we focus on 2D localization with known orientation ($n=2$). State-of-the-art acoustic localization solutions \cite{baron2019drone,shor2024active} typically employ various neural architectures $\mathcal{F}(s_{\mathrm{m}}(t))$ optimized to regress $\mathbf{x}_{\mathrm{s}}$.

$s_{\mathrm{m}}(t)$ is dependent of the decay and scatter $s_{\mathrm{s}}(t)$ undergoes when propagated through the room to $\mathbf{x}_{\mathrm{m}}$. This propagation is modeled by the room impulse response (RIR) \cite{borish1984extension} $r(t;\mathbf{x}_{\mathrm{s}},\mathbf{x}_{\mathrm{m}},\zeta)$ -- a temporal function also dependent on the source and sensor locations, as well the room geometry and physical properties, collectively denoted as $\zeta$. This function essentially describes the response in time of an impulse at $\mathbf{x}_{\mathrm{s}}$ as perceived at $\mathbf{x}_{\mathrm{m}}$ after propagating in the environment $\zeta$. The sampled sound $s_{\mathrm{m}}$ can finally attained by convolving the RIR with the input sound,
\begin{equation}
\label{eq:sound}
    s_{\mathrm{m}}(t) = r(t;\mathbf{x}_{\mathrm{s}},\mathbf{x}_{\mathrm{m}},\zeta) \ast s_{\mathrm{s}}(t),
\end{equation}
where the convolution is performed over time $t$.

\subsection{Clean localization}
\label{sec:clean}

To circumvent the reliance on computationally complex ISMs used in \cite{shor2024active} for RIR computation (as detailed in \cref{sec:rel}), we replace usage of ISMs with neural acoustic fields (NAFs) \cite{luo2022learning}. NAFs offer a reliable neural representation of the RIR, and are trained over actual RIR sampled from actual room acoustics. Unlike the original forward model from \cite{shor2024active}, NAFs produce RIRs already encompassing higher-order reflection sources. Therefore, for every point sound source, modeling the drone sound $s_{\mathrm{s}}$, the entire sound waveform sampled at a given microphone, $s_{\mathrm{m}}$, can be directly derived from \cref{eq:sound} in a single forward pass, with the RIR component attained by a single query of the NAF model. 
This makes the approach proposed in \cite{shor2024active} significantly faster and more reliable. 

\begin{figure*}[htbp]
\centering
 % Caption and label go in the first argument and the figure contents
 % go in the second argument


  
  \includegraphics[width=0.6\linewidth]{images/pipeline.png}
  
  {\caption{\textbf{Adversarial Pipeline Overview -} sound from both drone sound and adversarial source is convolved with NAF-induced RIRs and superimposed at the sensor, prior to being fed into the localization model. Localization loss gradients guide source amplitude optimization.}
  \label{fig:pipe}
  }
  
  
\end{figure*}
In our altered formulation for \cite{shor2024active}, for every microphone $\mu \in \mathcal{M}$, the response of each point sound-source $s_{i} \forall i \in \mathcal{S}$ as perceived at $\mu$, is computed using \cref{eq:sound} (with NAF RIRs). The total sampled sound at sensor $\mu$ is given by $s_{\mu}=\sum_i s_{i}$. These inputs are fed into the inverse model transformer-encoder architecture from \cite{shor2024active} to train our "clean" regressor, to be later evaluated under the presence of adversarial acoustic perturbations. We report clean localization performance in \cref{sec:attack_res}.

We emphasize that these modifications of the original localization algorithm fall outside the main focus and intended contributions of this paper, and are primarily a stepping stone towards a fast, differentiable model for the computation of $s_{\mathrm{m}}$. Nonetheless, we still deem this contribution notable.

\subsection{Acoustic Adversarial Attacks}
\label{sec:attackf}


In their most general form, adversarial attacks aim to add a perturbation $p$ to the input of a given, usually trained model $\mathcal{M}(x)$ receiving an input $x$, so as to manipulate the performance of the model over the perturbed input $x+p$ in order to maximize the model's error according some quality measure $\mathcal{L}$, thus harming the model's performance and reliability. This is usually done by solving the constrained optimization problem formulated in 
\cref{eq:general_adv}:
\begin{equation}
\label{eq:general_adv}
\max_p \mathcal{L}(\mathcal{M}(x+p)  
\quad \text{s.t.} \quad  
\mathcal{L}_q(p) \leq B
\end{equation}
where $\mathcal{L}_q$ is some constraint over the optimized perturbation, ensuring its feasibility under domain-specific requirements. \\
In our setting, $\mathcal{M}$ is the localization model from \cref{sec:clean}, and x is sound sampled at the drone's microphone array. Our acoustic adversarial attack must establish both the perturbation $p$, and the a set of constraints (collectively measured by $\mathcal{L}_q$) appropriate for our domain of acoustic localization.
\subsubsection{Perturbation Formulation}
\label{sec:form}
In our setting we wish to develop adversarial attacks originated from a stationary sound source located at an arbitrary location in the environment, controlled by the attacker. The motivation for this choice is that unlike common adversarial perturbations known from the field of Computer-Vision, such as 2D perturbations added to the input of image classifiers, in our setting the attacker cannot directly control the perturbation added to the model's input signal. This is because, unlike spatial signals (e.g. 2D images), sound signal are not stationary, meaning that the presence of an acoustic perturbation at one location in the environment inevitably affects the sampled sound at another location. For this reason, we also focus our discussion in this paper on universal adversarial attacks, rather than optimizing a distinct perturbation for every drone location and orientation. 

%We do, however, include results for non-universal attacks in \cref{sec:results}, %for the sake of comparability. \\
We choose to model the sound emitted by the perturbation sound source (namely, the attacker) $s_{\mathrm{p}}\in\mathbb{R}^T$ using a basis $\mathcal{B} = \{f_k\}_{k \in K}$ of sine waves from a chosen frequency set $K$. $f_k \forall k\in K$ is a sine wave of frequency $k$ sampled at $T$ timesteps . The corresponding perturbation is given by spanning this basis with a set of $|K|$ learnable amplitudes $\{\alpha_k\}_{k \in K}$:
\begin{equation}
    \label{eq:sine_basis}
    s_{\mathrm{p}} = \sum_{k\in K}\alpha_k \cdot f_k
\end{equation}
The rationale for this formulation is 3-fold: Firstly, it implies inherent periodicity, as we wish to optimize for periodic perturbations to avoid having to optimize the attack for an indefinite temporal duration. Especially under the assumption that the clean signal is in itself periodic (as is the case in the sound generated by the drone). Secondly, this formulation allows to reduce the number of learnable parameters from $T$ (when optimizing for the sound in signal domain) to $|K|$, allowing more efficient optimization. Lastly, it allows simple control over the amplitude and frequency components of the perturbation in order to impose various constraints as elaborated in \cref{sec:attack_cons}.

\subsubsection{Attack Constraints}
\label{sec:attack_cons}
Our goal in this section is to develop a set of constraints that would allow the attack to harm the regressor's performance while still not be easily detectable by a human or the agent. Contrary to the computer-vision domain and similar counterpart adversarial settings, where appropriate constraints are well-studied and well-established \cite{croce2020robustbench} (mostly $L_\infty, L_2$ and $L_1$ norms, among others), the relatively under-explored domain of acoustic attacks does not currently hold a set of widely accepted attack constraints. We deem the acoustic setting more challenging in this aspect as, unlike vision where many scenarios may bound together under relation with human-perception, the conditions where an acoustic perturbation can be deemed feasible or non-trivial for detection vastly change under different factors (sensors, ``clean" sound properties and task, among others). 
For this reason, we opt to propose our own constraints for the optimized adversarial perturbation, despite the fact that few other studies do address acoustic adversarial perturbation \cite{du2020sirenattack,bhattacharya2020countering}. The effect of different constraint value choices over performance is studied in \cref{sec:attack_res}.

\textbf{Frequency constraints.} Our first observation in this context is that the sound emitted by the drone's propulsion system is periodic. If the period of perturbative sound substantially differs from that of the drone, the adversarial attack could be trivially detected by the drone system. Therefore, we filter our sine basis $\mathcal{B}$ to include only frequencies integerly intertwined in the drone's cycle from \cite{shor2024active}. The bandwidth of perturbation source-emitted frequencies is also subjected to frequency constraints given by the speaker itself. We, therefore, also clamp the bandwidth of $\mathcal{B}$ according to some minimal and maximal values (set to a minimum of $50$ Hz and a maximum of $2$ KHz in all of our experiments). All frequency-related constraints are imposed by the construction of the perturbation as detailed in \cref{sec:form}. 

\textbf{Signal constraints.} We constrain both the amplitude and power of the emitted signal. The amplitude is constrained to avoid trivial perturbations that dominate the clean signal and can subsequently be easily disentangled from it. The power is more closely related to human perception (namely the loudness of perceived signal), however constraining it also helps diminish irregular local signal energy patterns that may potentially be utilized in attack detection. 

Signal constraints are imposed via soft constraints regularizing the optimization process (\cref{eq:attack_eq}). Note that while the perturbation is sampled at the microphones, all constraints are imposed over the sound at the source. This choice is motivated by the fact that the sound sampled at the microphones could potentially greatly vary with drone spatial translation, reducing attacker control over perturbation feasibility.

\textbf{Location constraints.} Upon optimizing for the perturbative source location $\mathbf{x}_{\mathrm{p}}$, we must ensure the source remains within environment boundaries. This is done using a signed-distance-function (SDF) $\mathcal{L}_{SDF}$ linearly penalizing distance when the source is optimized to be away from environment boundaries.


% \begin{figure*}[htbp]
% \centering
%  % Caption and label go in the first argument and the figure contents
%  % go in the second argument


  
%   \includegraphics[width=0.6\linewidth]{images/pipeline_horizontal.png}
  
%   {\caption{\textbf{Adversarial Pipeline Overview -} sound from both drone sound and adversarial source is convolved with NAF-induced RIRs and superimposed at the sensor, prior to being fed into the localization model. Localization loss gradients guide source amplitude optimization.}
%   \label{fig:pipe}
%   }
  
  
% \end{figure*}

\subsubsection{Perturbation Propagation}
Much like the "clean" sound emitted by the drone, our adversarial perturbation must also be propagated to the drone's sensor array to be sampled. Our goal is to formulate a universal attack optimization scheme shaping the emitted signal at the source $s_{\mathrm{p}}$ so that the sampled response at the sensor $\mu$, denoted $\sigma_\mathrm{p}$, would optimally reduce localization accuracy.  In our experiments, we consider both optimization of the emitted perturbation for a sound source located in the center of the room, as well as optimization of the emitted sound jointly with the perturbation speaker's location $\mathbf{x}_{\mathrm{p}}\in\mathbb{R}^2$. For our localization quality measure, we choose Mean-Squared-Error (MSE), following the criterion from \cite{shor2024active}. Our universal attack optimization, in its most general form, is therefore formulated according to \cref{eq:attack_eq}:

% \begin{equation}
%   \label{eq:attack_eq}
        
%     
%    \ma\mathbf{x}_{\{a_k\}_{k \in K},\mathbf{x}_{\mathrm{p}}} \lVert \mathcal{F}(\{r(t;\mathbf{x}_{\mathrm{p}},\mathbf{x}_{\mu})\ast s_{\mathrm{p}}(t)\}_{\mu \in \mathcal{M}})\text{-}\mathbf{x}_{\mathrm{d}}\rVert_2^2 \\ 
%     \text{+} \lambda_{amp}\max\{0,\mathcal{L_\infty}(s_{\mathrm{p}}\text{-}\beta\} \text{+} \lambda_{power}\max\{0,\sum_{t=1}^Ts_{\mathrm{p}}(t)^2 - \gamma\}
    
% \end{equation}




% \begin{align}
%   \label{eq:attack_eq}
%   \max_{\{a_k\}_{k \in K}, \mathbf{x}_{\mathrm{p}}} \; & \lVert \mathcal{F}(\{r(t;\mathbf{x}_{\mathrm{p}}, \mathbf{x}_{\mu}) \ast s_{\mathrm{p}}(t)\}_{\mu \in \mathcal{M}}) - \mathbf{x}_{\mathrm{d}} \rVert_2^2 \notag \\
%   & +  \lambda_{amp} \cdot \max\{0, \lVert s_{\mathrm{p}} \rVert_\infty - \beta\} \notag \\
%   & + \lambda_{power} \cdot \max\{0, \sum_{t=1}^T s_{\mathrm{p}}(t)^2 - \gamma \} \notag \\
%   & + \lambda_{SDF}\mathcal{L}_{SDF}(\mathbf{x}_{\mathrm{p}})
% \end{align}
% \begin{align}
%   \label{eq:attack_eq}
%   \max_{\{a_k\}_{k \in K}, \mathbf{x}_{\mathrm{p}}} \;  & \lVert \mathcal{F}(\{r(t;\mathbf{x}_{\mathrm{p}}, \mathbf{x}_{\mu}) \ast s_{\mathrm{p}}(t)\}_{\mu \in \mathcal{M}}) - \mathbf{x}_{\mathrm{d}} \rVert_2^2 + \mathcal{L}_q(s_p,x_p) 
 
% \end{align}

\begin{equation}
  \label{eq:attack_eq}
  \max_{\{a_k\}_{k \in K}, \mathbf{x}_{\mathrm{p}}} \;  \lVert \mathcal{F}(\{r(t;\mathbf{x}_{\mathrm{p}}, \mathbf{x}_{\mu}) \ast s_{\mathrm{p}}(t)\}_{\mu \in \mathcal{M}}) - \mathbf{x}_{\mathrm{d}} \rVert_2^2 + \mathcal{L}_q(s_p,x_p)
\end{equation}
for definition of the constraint loss $\mathcal{L}_q$ as:
\begin{align*}
    \mathcal{L}_q(s_p, x_p) = &\; \lambda_{amp} \cdot \max\left\{0, \lVert s_{\mathrm{p}} \rVert_\infty - \beta\right\} \\
    &\hspace{-1.5cm}+ \lambda_{power} \cdot \max\left\{0, \sum_{t=1}^T s_{\mathrm{p}}(t)^2 - \gamma \right\} + \lambda_{SDF} \mathcal{L}_{SDF}(\mathbf{x}_{\mathrm{p}})
\end{align*}

$s_{\mathrm{p}}$ is the perturbation source-sound attained from \cref{eq:sine_basis}, $r(t;\mathbf{x}_{\mathrm{p}},\mathbf{x}_{\mu})$ is the RIR between sound-source location $\mathbf{x}_{\mathrm{p}}$ and microphone location $\mathbf{x}_{\mu}$, given by the pre-trained NAF, $\mathcal{F}$ is the pre-trained localization model with a set of microphones $\mathcal{M}$, where each microphone $\mu$ is located in location $\mathbf{x}_{\mu}$. $\mathbf{x}_{\mathrm{d}}$ represents actual location of the center of the drone, and $\beta,\gamma$ are the respective amplitude and power bounds from \cref{sec:attack_cons}, for losses weighted by $\lambda_{amp}$ and $\lambda_{power}$. Location SDF is weighted by $\lambda_{SDF}$. While \cref{eq:attack_eq} is formulated for non-targeted attacks, in \cref{sec:attack_res} and in the supplementary we also explore targeted attacks, for which we optimize similarly to \cref{eq:attack_eq}, with the single modification of replacing $\mathbf{x}_{\mathrm{d}}$ with the designated target location.

\subsubsection{Source Location Optimization}
\label{sec:loc_opt}
One potential difficulty in our formulation from \cref{eq:attack_eq} is that there are cases where optimization of the perturbation source location $\mathbf{x}_{\mu}$ within the scene may be difficult or altogether impossible. The reason is that optimizing $\mathbf{x}_{\mu}$ necessitates differentiation through the acoustic model of the environment (namely, in our case, the NAF). To address cases where such a differentiable model is not available or where the added
computational costs incurred by querying and backpropagating through such, usually large, models are too heavy (see supplementary for time and memory footprint in our experiments), in our experiments, we also analyze universal attacks with a fixed perturbation source location in the center of the room, only optimizing for the perturbation sound. In this case, the perturbation impulse response for every microphone location is constant, circumventing repeated forward and backward evaluation of the NAF. As \cref{sec:attack_res} shows, we observe only a marginal decrease in attack prowess when waiving source-location optimization. We attribute this outcome to the fact that the  source location should not drastically change the set of attainable location-wise perturbations potentially sampled at the sensors, but only the specific perturbative source-emitted waveform able to induce them over a given scene location. Our adversarial pipeline is illustrated in \cref{fig:pipe}.
\subsection{Phase Modulation Perturbation Delineation}
\label{sec:defense}
In this section, we propose Phase Modulation Perturbation Delineation - a novel method for the utilization of phase modulation \cite{shor2024active} for the recovery of the "clean," non-perturbed signal from the entire (presumably adversarially perturbed) acoustic sample as perceived by any of the drone's sensors. \cref{sec:phase modulation} overviews the concept of phase modulation, originally developed in \cite{shor2024active} for improving localization accuracy. In \cref{sec:delineation}, we show how this mechanism can be further extended for perturbation and clean-signal separation. \\



\subsubsection{Phase Modulation}
\label{sec:phase modulation}
In our acoustic localization setting, similar to that studied in \cite{shor2024active}, the drone's propulsion system consists of a set of $\mathcal{R}$ rotors that rotate at constant and equal angular velocities. The resulting angular locations of each rotor through the duration of a single cycle spanning over $T$ seconds (namely, the azimuthal rotor shaft positions w.r.t some chosen starting point) can thus be described as a function $\varphi_0(t):[T]\rightarrow [0,2\pi]$ converting moments in time from each cycle to the corresponding angular location of rotor $i$. \\
The phase modulation mechanism from \cite{shor2024active} proposes to actively optimize 
a per-rotor function of temporal offsets from $\varphi_0(t)$, termed a \textit{modulation function} $\varphi_i(t):[T]\rightarrow [0,2\pi]$, for every rotor $i$.
Every combination of such modulation functions alters the sound emitted by the propulsion system through time, and thus the rationale is to optimize the set of $\mathcal{R}$ such per-rotor modulation functions to generate input waveforms more useful for localization (under imposition of certain constraints over these modulation functions, ensuring kinematic feasibility and the drone's stable flight). 

\subsubsection{Perturbation Delineation}
\label{sec:delineation}
We extend the concept of phase modulation (\cref{sec:phase modulation}) to delineate the adversarial perturbation from the entire sampled input $s_{\mu}$ at a given microphone $\mu$. Let us denote the perturbation response of $s_{\mathrm{p}}$ at microphone $\mu$ by $\sigma_{\mathrm{p}}$. Upon sampling a perturbed waveform $s_{\mu} = s_{drone}+\sigma_{\mathrm{p}}$, the goal is to solve for $\sigma_{\mathrm{p}}$. Upon doing so, we can input the original non-perturbed signal $s_{drone}$ to the localization model, essentially nullifying the affect of the attack over localization performance. \\
Our strategy for achieving this would be to apply gradual temporal delays over $s_{drone}$ using the phase modulation mechanism, utilizing the fact the the perturbation sound remains constant under these modulations. Denote by $T$ the maximum of the period times of the drone and perturbation source. Since the drone cycle $T_{drone}$ must be an integer multiple of the perturbation source period $T_{pert}$ (\cref{sec:attack_cons}), both $s_{drone}$ and $s_{\mathrm{p}}$ complete a periodic cycle (of one or more periods) within a duration of $T$ seconds. \\
For every moment in time $j\in[T]$, we can apply constant phase modulation of $j$ timesteps across all rotors jointly for the entire $T$ seconds period. Denote the sound sampled at some arbitrary microphone $\mu$ with constant modulation $j$ across rotors as $s_\mu(t;j)$. This sound is the sum of the $j$-modulated drone-emitted sound, denoted $s_{drone}(t;j)$, and the original sampled perturbation sound $\sigma_{\mathrm{p}}(t)$ (unaffected by phase modulation). Our key observation is that for every non-zero value of $j$, at moment $j$ of the current period (where each rotor is modulated at $j$ timesteps), the sound component originated from the drone's propulsion system is the same as that sampled at the $j=0$ constant modulation at timestep 0, and hence by simple subtraction: $s_\mu(t=j;j)-s_\mu(t=0;0) = \sigma_{\mathrm{p}}(t=j)-\sigma_{\mathrm{p}}(t=0)$. \\
By performing this process for every value of $j \in [T]$, we can essentially recover $\sigma_{\mathrm{p}}(t)-\sigma_{\mathrm{p}}(t=0)$ for every value of $t$, giving us the perturbating waveform at the location of the microphone $\mu$. One degree of uncertainty which our algorithm does not allow solving for, is the value of $\sigma_{\mathrm{p}}$ at moment $t=0$. While we believe this value can be retrieved, for example by imposing correlation among several perturbation waveforms at different locations, we defer the study of this possibility to future work. For the scope of this work, as validated in \cref{sec:def_res}, simple setting of $\sigma_{\mathrm{p}}(t=0)$ to be $0$ everywhere in the environment reduces localization degradation almost completely. We stress that while our proposed algorithm is demonstrated on phase modulation of drone rotors, it is applicable for acoustic perturbation delineation of any agent capable of actively shaping the "clean" sound, thus separating it from the constant perturbation.



\begin{figure*}[htbp]
\centering
 % Caption and label go in the first argument and the figure contents
 % go in the second argument


  
  \includegraphics[width=0.8\linewidth]{images/delin_hor_ext.png}
  
  {\caption{\textbf{Summary of Perturbation Delineation Method -} rotor self-sound (blue) under different phase modulations (black arrows depict rotor angular location at $t=0$). In red is the perturbation sound. The two are superimposed to the microphone-sampled signal (green).}
  \label{fig:del}
  }
  
  
\end{figure*}

\cref{fig:del} visually depicts our algorithm - a single drone period is illustrated under 3 different phase modulations - 0 (A),  $\pi$ (B, corresponding to $\tau_1$ timesteps), and $\frac{pi}{2}$ (C, corresponding to $\tau_2$ timesteps). In each room the same perturbation sound (red) is observed, while for each modulation the same drone-emitted sound is observed up to a certain shift (blue). The superimposed sound sampled by the microphone (green) is shifted accordingly (w.r.t the 0-modulation room A) in each room. In the bottom part, we illustrate how the 0-modulation waveform is subtracted from each $\tau$-step modulated waveform to receive the original perturbation (red waveform)  at timestep $\tau$, utilizing the fact the the perturbation is agnostic to phase modulation.  

% \begin{algorithm}
% \caption{Perturbation Recovery Algorithm for Sound Waveform Separation}
% \label{alg:perturbation_delineation}
% \begin{algorithmic}[1]
% \REQUIRE Perturbed waveform $s_{\mu}$, period time $T$
% \ENSURE Recovered sampled perturbation waveform $s_{\mathrm{r}}$

% \STATE Initialize  $s_{\mathrm{r}} = [\ ]$ \# \textit{Recovered Waveform}

% \FOR{$j = 1$ \textbf{to} $T$}
%     \STATE sample $s_{\mu}(t;j)$ \# \textit{Modulate by $j$ timesteps}
%     \STATE update $s_{\mathrm{r}}(t=j) = s_{\mu}(t;j)-s_{\mu}(t;0)$ \# \textit{Calculate perturbation at timestep $j$}
% \ENDFOR

% \STATE \textbf{return} $s_{\mathrm{r}}$
% \end{algorithmic}
% \end{algorithm}
\section{Results}
\label{sec:results}
% In this section we demonstrate both the efficiency of our developed adversarial attack from \cref{sec:form} and the efficacy of our developed phase modulation delineation method from \cref{sec:defense} in reducing the attack's affect over localization performance. %In this section we focus on results for non-targeted attacks over a single acoustic environment to accommodate page limitat\\

\subsection{Experimental Setup}
\label{sec:setup}
Following the experimental setting in \cite{luo2022learning}, we pick a representative subset of acoustic environments from the Matterport3D \cite{chang2017matterport3d} and Replica \cite{straub2019replica} datasets used in training of RIRs from Neural Acoustic Fields (NAFs)\cite{luo2022learning}. In this section, we primarily present results from the \textit{apartment\_2\_frl} environment (denoted \textit{apt}, in this section). We also provide partial results for the \textit{office\_4} and \textit{room\_2} scenes in \cref{fig:heatmap}, with the full set of results available in the supplementary material. These additional results exhibit trends consistent with those reported here. For each environment we train the clean localization model from \cite{shor2024active}, using the environment-fitted pre-trained NAF. In order to explore our developed approaches disjointly from any external, case-specific affects, in most experiments we assume zero interference from any acoustic signals, excluding the drone and the attacker. Nonetheless, in \cref{app:noise} we also model the affect of white noise over adversarial success. Furthermore, our experiments we focus on the regressor from \cite{shor2024active} since it is the only one completely reliant on the self-sound emitted by the drone's propulsion system. Other methods (e.g. \cite{sun2023indoor,he2023acoustic}) rely mostly on external speakers, and thus require the development of adversarial attacks accounting for both the speaker sound and propulsion sound simultaneously. We refer these direction of research to future work. Nonetheless, we emphasize that our developed attack and defense methods are applicable to any combination of drone configuration and purely-acoustic localization algorithm. Localization training details are stated in the supplementary. \\
To evaluate our attacks, for every combination of constraints $(\beta,\gamma) \in [0.01, 0.1, 0.5, 1] \times [0.1, 0.25, 0.5, 1, 2]$ we perform 100 iterations of universal PGD attack over each environment and combination, with early-stop of 5 iterations without localization loss increase. Our set of attack constraints is upper-bounded to not surpass 50\% of the average clean signal amplitude and power, and lower-bounded to allow minimal deviation from clean localization. We set all regularization weights from our training objective (\cref{eq:attack_eq}) to 1 in all experiments. We report our results in scaled RMS (i.e. RMS between predicted and ground-truth locations after being scaled to the $[0,1]$ range) for the sake of interpretability and comparability across scenes.
\subsection{Attack Results}
\label{sec:attack_res}
Optimized attack RMS error results across different bounds are reported in \cref{fig:attack_res}.
Our proposed attack increases the mean localization error
from slightly below 5\% in the clean model, to 37.4\% for highest amplitude and power bounds. Results also demonstrate saturation of attack efficacy with growth in the $\beta,\gamma$ bounds, where in both figures the largest and second-largest amplitude bounds $\beta=0.5, \beta=1$ intersect almost completely. This is also true for the power bounds, as all figures remain almost constant in transition from $\gamma=1$ to $\gamma=2$. This bounds the maximum efficacy of our PGD attack in bound of around $0.5$ for the amplitude and $\gamma=1$ for power. Lastly, corresponding to \cref{sec:loc_opt}, we observe that results for location optimization (left) and fixed-source location experiments (right) are nearly identical. We deem the apparent agnostic nature of sound-source perturbation optimization to source location a notable conclusion for future related studies, especially given the increased computational costs (see supplementary material).

\begin{figure}[htbp]
\centering

  
  \includegraphics[width=1\linewidth]{images/attack_res_mod.png}
  
  {\caption{\textbf{Mean RMS with and without source location optimization -} across varying amplitude and power bounds ($\beta \text{ and } \gamma$).}
  \label{fig:attack_res}
  }
\end{figure}
\begin{figure*}[h!]
\centering

  
  \includegraphics[width=0.8\linewidth]{images/shared.png}
  
  \caption{\textbf{Clean, perturbed and delineation-recovered spatial error distribution for selected attack bounds} - across different scenes (\textit{apt., room, and office}), measured in mean RMS error across drone orientations. Optimized source location highlighted in blue.}
\label{fig:heatmap}
  
  
  
\end{figure*}


% \begin{figure*}[h!]
%     \centering
%     % First Subfigure
%     \begin{subfigure}[b]{0.33\textwidth}
%         \centering
%         \includegraphics[width=0.8\textwidth]{images/heat_1_2_streched.png}
%         \caption*{$\beta = 1, \gamma = 2$}
%         \label{fig:sub1}
%     \end{subfigure}
%     \hfill
%     % Second Subfigure
%     \begin{subfigure}[b]{0.33\textwidth}
%         \centering
%         \includegraphics[width=0.8\textwidth]{images/heat_0.5_0.5_streched.png}
%         \caption*{$\beta = 0.5, \gamma = 0.5$}
%         \label{fig:sub2}
%     \end{subfigure}
%     \hfill
%     % Third Subfigure
%     \begin{subfigure}[b]{0.33\textwidth}
%         \centering
%         \includegraphics[width=0.8\textwidth]{images/heat_0.1_0.25_streched.png}
%         \caption{$\beta = 0.1, \gamma = 0.25$}
%         \label{fig:sub3}
%     \end{subfigure}
%     %  \begin{subfigure}[b]{0.33\textwidth}
%     %     \centering
%     %     \includegraphics[width=\textwidth]{images/heat_rec_1_2_s.png}
%     %     \caption{$\beta = 1, \gamma = 2$, fixed source}
%     %     \label{fig:sub1}
%     % \end{subfigure}
%     % \hfill
%     % % Second Subfigure
%     % \begin{subfigure}[b]{0.33\textwidth}
%     %     \centering
%     %     \includegraphics[width=\textwidth]{images/heat_rec_0.5_0.5_s.png}
%     %     \caption{$\beta = 0.5, \gamma = 0.5$, fixed source}
%     %     \label{fig:sub2}
%     % \end{subfigure}
%     % \hfill
%     % % Third Subfigure
%     % \begin{subfigure}[b]{0.33\textwidth}
%     %     \centering
%     %     \includegraphics[width=\textwidth]{images/heat_rec_0.1_0.25_s.png}
%     %     \caption{$\beta = 0.1, \gamma = 0.25$, fixed source}
%     %     \label{fig:sub3}
%     % \end{subfigure}
    
%     \caption{\textbf{Clean, perturbed and delineation-recovered spatial error distribution for selected attack bounds} - measured in mean RMS error across drone orientations. Optimized source location highlighted in blue.}
%     \label{fig:heatmap}
% \end{figure*}

\cref{fig:heatmap} illustrates spatial RMS error distributions across varying scenes  and $\beta,\gamma$ bounds for optimized source location perturbation optimization. We supply similar results for fixed-source location in the supplementary. "Clean Scene" denotes non-perturbed localization, "Attacked Scene" depicts localization subjected to the attack from \cref{sec:attackf} and "Recovered Scene" shows localization with the perturbation delineation defense methods developed in \cref{sec:defense}. Results visually demonstrate the affect of our proposed attack over localization performance, spread across the majority of the environment in all three scenes. The smooth spatial distribution of error across each map implies that our universal adversarial attack method does not merely mislead the drone at isolated, specific locations but instead systematically disrupts the underlying localization capability. This consistency in error across diverse spatial coordinates implies that the attack successfully generalizes to attack the localization task as a whole, rather than exploiting isolated positional weaknesses. 
To address any concern of the similarity between fixed and optimized source in \cref{fig:attack_res} stemming from the perturbation source not changing in optimization, we stress that location-optimization experiments do demonstrate some change in source location under optimization. The restricted extent of this change from the center can be explained by the reduced affect of room geometry over perceived perturbation at the sensors as the source is closer the the sensor. This presumably pushed the perturbation source to remain close to the center during optimization, also insinuating that the conclusion from \cref{fig:attack_res} regarding the affect of source location optimization may change in highly non-convex rooms. We defer exploration of this possibility to future work. \\
In our setting the exploration of \textit{targeted} adversarial attacks is also of great importance, as such attacks would allow a potential attacker to direct the drone to a specific location within the environment. Our main analysis of the performance of our method in applying targeted attacks is brought in the supplementary, however in \cref{fig:res_targeted} we present initial results of our developed attack's potential in successful targeted attack. This potential is evident from the presented error heatmap in the attacked scene, depicting RMS error between prediction and adversarial target. For our largest-considered attack bounds, this error is almost zero all along the map. We refer the reader to the supplementary for further related results, including cases where our targeted attack has proven inefficient. 


\subsection{Defense Results}
\label{sec:def_res}
In this section we analyze the effectiveness of our proposed acoustic perturbation delineation algorithm from \cref{sec:defense}.
\cref{fig:heatmap} shows qualitative support for our method's capability in drastically reducing adversarial performance decay, producing recovered scenes almost indistinguishable from the corresponding clean scenes - for the most lenient attack constraints, our algorithm reduces localization error from 37\% (\cref{fig:attack_res}) to below 6\%, only marginally higher than the error of 4.87\% reported for clean localization. In the supplementary we also report the recovered RMS error statistics, similarly to \cref{fig:attack_res}.

\begin{figure}[htbp]
\centering

  
  \includegraphics[width=\linewidth]{targetet_scaled.png}
  
  {\caption{\textbf{Targeted attack spatial distribution -} of RMS error from desired  adversarial target, for maximal attack bounds.}
  \label{fig:res_targeted}
  }
  
  
\end{figure}

We attribute the efficacy of our method to the fact that it is capable of retrieving the sensed perturbation with a only single scalar degree-of-freedom, that is the uncertainty in the sampled perturbation value at moment $t=0$. To further validate our method, in \cref{app:delta} we provide thorough empirical analysis of this uncertainty, and conclude that this degree of uncertainty has marginal affect over post-reconstruction localization performance. 

% \subsection{Modeling Noise}
% Since we are the first work to address adversarial attacks over acoustic drone localization, in our experiments we wish to assess the impact of acoustic adversarial attacks over drone localization with minimal assumptions over the attacker and the environment. Therefore, in all previous experiments we assume an idealized environment where the only sound sources are the drone and the adversarial perturbation. This assumption maximizes the attacker's flexibility and isolates external interference. Nonetheless, in order to provide an initial assessment of our findings in into real-world conditions, in this section we test the potential of our developed attacked under the presence of white noise. 
% % \begin{table*}
% \centering
% \small
% \begin{tabular}{|c|c|c|c|c|c|}
% \hline
% \textbf{$\beta, \gamma$ / $\sigma$} & \textbf{0.01} & \textbf{0.025} & \textbf{0.05} & \textbf{0.075} & \textbf{0.1}  \\ \hline
% \textbf{$\beta=0.1, \gamma=0.25$}  &  0.22 & 0.226 & 0.23 & 0.26 & 0.261 \\ \hline
% \textbf{$\beta=0.5, \gamma=0.5$}   & 0.345 & 0.339 & 0.327 & 0.346 & 0.342 \\ \hline
% \textbf{$\beta=1, \gamma=2$}       & 0.372 & 0.369 & 0.358 & 0.371 & 0.35 \\ \hline
% \end{tabular}
% \caption{Attack performance under different noise levels $\sigma$. Rows represent different attack configurations $(\beta, \gamma)$.}
% \label{tab:attack_noise_transposed}
% \end{table*}

\section{Discussion}
\subsection{Conclusion} - 
In this work we have presented an initial study of adversarial attacks within the task of acoustic localization of drones. In our study we first presented a formulation of adversarial attacks appropriate for the acoustic setting. We proceeded to benchmark and comprehensively analyze how universal acoustic perturbations, optimized according to our proposed formulation, affect localization performance under different conditions. Finally, we presented a novel algorithm for reliable recovery of the optimized adversarial perturbation, as sampled at the source. Results show that our formulated attack increases localization RMS error from, at most, 37\%, and our recovery algorithm reduces this error back to slightly below 6\% - only marginally higher than the clean error of 5\%.
% Our findings further show that adversarial source-location optimization has little affect over localization performance degradation, allowing effective attack of localization models in reduced computational costs. A by-product of our work is also the training and evaluation of a self-sound-reliant drone localization model over actual acoustic data, extending current literature where results are only reported over acoustic data attained from simulations. 
While our discussion is mostly focused our drone localization, we deem it applicable for many autonomous-agent acoustic localization scenarios. 
\subsection{Limitations and Future Work} - 
While our work provides a foundational framework for adversarial attacks and defenses in acoustic localization, several limitations remain. First, in this study we restrict ourselves to the task of 2D acoustic localization. Many real-world localization scenarios incorporate a 6-DoF regression problem, calling for an extension of our contributions to higher-dimension localization. Furthermore, in order to conduct an impact-analysis focused on our developed attack, in this work we bound the discussion to explore a single adversarial sound-source in a mostly clean, controlled acoustic setting. We plan to explore the relaxation of those assumptions in the future. Lastly, while efficient, our perturbation delineation algorithm must be applied for an entire drone cycle for every moment in time $[0,T]$, which may be time-costly. We plan to explore expedited perturbation recovery in future work, as well as other adversarial defense algorithms.

% \section{Conclusion}
% In this work we have presented an initial study of adversarial attacks within the task of acoustic localization of drone. In our study we first presented a formulation of adversarial attacks appropriate for the acoustic setting. We proceeded to benchmark and comprehensively analyze how universal acoustic perturbations, optimized according to our proposed formulation, affect localization performance under different conditions. Finally, we presented a novel algorithm for reliable recovery of the optimized adversarial perturbation, as sampled at the source. Results show that our formulated attack increases localization RMS error from, at most, 37\%, and our recovery algorithm reduces this error back to slightly below 6\% - only marginally higher than the clean error of 5\%. Our findings further show that adversarial source-location optimization has little affect over localization performance degradation, allowing effective attack of localization models in reduced computational costs. A by-product of our work is also the training and evaluation of a self-sound-reliant drone localization model over actual acoustic data, extending current literature where results are only reported over acoustic data attained from simulations. While our discussion is mostly focused our drone localization, we deem it applicable for many autonomous-agent acoustic localization scenarios.


\bibliography{example_paper}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\section{Supplementary Layout}
In the following sections we report additional details complementing the main paper, ordered as follows -
1) \cref{app:res} includes supplementary results for the three main types of experiments conducted in the paper - \\
\textbf{Targeted Attacks} - \cref{app:targeted} extends figure 6 from the paper, reporting localization performance attained under targeted adversarial attacks, considering a wider range of acoustic scenes and attack bounds, as well as an ablation for adversarial sound source location optimization. \\
\textbf{Source Location Optimization} - \cref{app:fixed_heatmaps} provides further comparison between localization capabilities with and without adversarial source location optimization, similar to section 4.2. \\
\textbf{$\delta$ Uncertainty} - \cref{app:delta} elaborates values of location gradients w.r.t sensor-sampled sound (as shown in figure 5) to quantifty the error expected for our perturbation delineation algorithm under the uncertainty in value of the recovered waveform at moment $t=0$.\\

We denote that our scatter-plot heatmap figures for the \textit{room\_2} and \textit{office\_4} environments may depict environment shapes slightly different than those known from \cite{chang2017matterport3d,straub2019replica} environments. The reason is we do not evaluate localization in locations where the drone cannot be present, due to it's simulated physical dimensions from \cite{shor2024active}. \\

2) \cref{app:training} provides in-depth implementation, optimization and training-regime details.
3)  In \cref{app:loc_opt} we discuss the added computational resources required in adversarial source location optimization, to further stress the importance of our findings from section 4.2, where we claim source-location optimization could prove cost-ineffective in some cases.

4) \cref{app:def_table} further provide added details for our proposed perturbation delineation algorithm.
\section{Additional Results}
\label{app:res}

\subsection{Modeling Noise}
\label{app:noise}
Since we are the first work to address adversarial attacks over acoustic drone localization, in our experiments we wish to assess the impact of acoustic adversarial attacks over drone localization with minimal assumptions over the attacker and the environment. Therefore, in all previous experiments we assume an idealized environment where the only sound sources are the drone and the adversarial perturbation. This assumption maximizes the attacker's flexibility and isolates external interference. Nonetheless, in order to provide an initial assessment of our findings in into real-world conditions, in this section we test the potential of our developed attacked under the presence of white noise. 
\begin{table*}
\centering
\small
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{$\beta, \gamma$ / $\sigma$} & \textbf{0.01} & \textbf{0.025} & \textbf{0.05} & \textbf{0.075} & \textbf{0.1}  \\ \hline
Clean model (under noise)  &  0.0492 & 0.062 & 0.081 & 0.116 & 0.147 \\ \hline
\textbf{$\beta=0.1, \gamma=0.25$}  &  0.22 & 0.226 & 0.23 & 0.26 & 0.261 \\ \hline
\textbf{$\beta=0.5, \gamma=0.5$}   & 0.345 & 0.339 & 0.327 & 0.346 & 0.342 \\ \hline
\textbf{$\beta=1, \gamma=2$}       & 0.372 & 0.371 & 0.369 & 0.358  & 0.35 \\ \hline
\end{tabular}
\caption{Attack performance under different noise standard-deviation $\sigma$. Rows represent different attack configurations $(\beta, \gamma)$.}
\label{tab:attack_noise}
\end{table*}
\cref{tab:attack_noise} shows final attack accuracy after perturbation optimization. Selected values of $\sigma$ are chosen as std values below of up to $50\%$ of the standard-deviation of the original signal. Notably, the presence of noise does not affect the potential of the attack, in comparison to the clean-setting case. 
\subsection{Targeted Attacks}
\label{app:targeted}
A central motivation for the study of adversarial attacks in drone localization is the possibility of a potential attacker directing the drone to a specific location, where it could potentially pose harm to the original user or third-party individuals. We therefore also analyze the affect of targeted adversarial attacks, brought forth in \cref{fig:targeted}. In this figure we show spatial error distributions for targeted attacks in different locations (marked in green on the heatmap, and textually on each sub-figure caption). Note that unlike heatmaps for non-targeted attacks, here the error reported on the heatmap is \textit{RMS from adversarially desired target} (so an all-black heatmap means perfectly successful attack). \\
We observe that the success of targeted attacks depends on target location. Subfigures \textit{a}-\textit{c} present very successful adversarial targeted attack, where the adversarially-desired target is predicted almost everywhere in the map. Figures \textit{g}-\textit{i} present the complementary scenario, where the clean and attacked error maps are nearly identical for all bounds. We speculate this difference stems from the fact that the attack targeted at $[-2,-4.5]$ (namely, the "successful" attack) is focused on a more-likely low-certainty area (given the room shape in the area of $[-2,0]$, that is non-representative of the common shape at other scene regions), contrary to the attack at $[8,-4.5]$ (an area where the attack allegedly failed).
\begin{figure*}[h!]
    
    \centering
    
    % First Row
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/targeted/targeted_-2_-4.5/amp_1_pwr_2/heat_rec_targeted__-2_-4.5_1_2.png}
        \caption{$\beta = 1, \gamma = 2, target = [-2,-4.5]$}
        \label{fig:sub3}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/targeted/targeted_-2_-4.5/amp_0.1_pwr_0.25/heat_rec_target_-2_-4.5_0.1_0.25.png}
        \caption{$\beta = 0.5, \gamma = 0.5, target = [-2,-4.5]$}
        \label{fig:sub3}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/targeted/targeted_-2_-4.5/amp_0.1_pwr_0.25/heat_rec_target_-2_-4.5_0.1_0.25.png}
        \caption{$\beta = 0.1, \gamma = 0.25, target = [-2,-4.5]$}
        \label{fig:sub1}
    \end{subfigure}
    
    % Second Row
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/targeted/targeted_-2_0/amp_1_pwr_2/heat_rec_targeted_-2_0_1_2.png}
        \caption{$\beta = 1, \gamma = 2, target = [-2,0]$}
        \label{fig:sub3}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/targeted/targeted_-2_0/amp_0.1_pwr_0.25/heat_rec.png}
        \caption{$\beta = 0.5, \gamma = 0.5, target = [-2,0]$}
        \label{fig:sub3}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/targeted/targeted_-2_0/amp_0.1_pwr_0.25/heat_rec.png}
        \caption{$\beta = 0.1, \gamma = 0.25, target = [-2,0]$}
        \label{fig:sub1}
    \end{subfigure}
    
    
    
    % Fourth Row
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/targeted/targeted_8_-4.5/amp_1_pwr_2/heat_rec.png}
        \caption{$\beta = 1, \gamma = 2, target = [8,-4.5]$}
        \label{fig:sub3}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/targeted/targeted_8_-4.5/amp_1_pwr_2/amp_0.5_pwr_0.5/heat_rec.png}
        \caption{$\beta = 0.5, \gamma = 0.5, target = [8,-4.5]$}
        \label{fig:sub3}
    \end{subfigure}
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/targeted/targeted_8_-4.5/amp_0.1_pwr_0.25/heat_rec.png}
        \caption{$\beta = 0.1, \gamma = 0.25, target = [8,-4.5]$}
        \label{fig:sub1}
    \end{subfigure}
    
    \caption{\textbf{Clean, perturbed and delineation-recovered spatial error distribution for selected targeted attack bounds} - for selected map targets (in green).}
    \label{fig:targeted}
\end{figure*}


\subsection{Fixed-perturbation source RMS distribtution}
\label{app:fixed_heatmaps}
\cref{fig:heatmap_fixed} presents results similar to figure \ref{fig:heatmap} along with fixed-source location attack optimization. Results support our findings from section \ref{sec:attack_res}, stating that location optimization holds limited contribution for attack success in our tested setting. Similar conclusions can be drawn from results over the office (\cref{fig:heatmap_fixed_office}) and room \cref{fig:heatmap_fixed_room} environments, also complementing the partial results for location optimization in the two latter environments, as shown in \cref{fig:heatmap}.  \\
In \cref{fig:attack_res_room}, \cref{fig:attack_res_office} we present localization RMS mean and standard deviation, similar to the plot from \cref{sec:attack_res} in the paper. While our conclusion regarding marginal advantage in source location optimization is supported in those plots, we do denote that for these environments, for smaller attack bounds we observe a larger growth in attack efficiency when performing source-location optimization. \\
\begin{figure*}[h!]
    \centering
    % First Subfigure
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/heat_rec_1_2.png}
        \caption{$\beta = 1, \gamma = 2$}
        \label{fig:sub1}
    \end{subfigure}
    \hfill
    % Second Subfigure
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/heat_rec_0.5_0.5.png}
        \caption{$\beta = 0.5, \gamma = 0.5$}
        \label{fig:sub2}
    \end{subfigure}
    \hfill
    % Third Subfigure
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/heat_rec_0.1_0.25.png}
        \caption{$\beta = 0.1, \gamma = 0.25$}
        \label{fig:sub3}
    \end{subfigure}
     \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/heat_rec_1_2_s.png}
        \caption{$\beta = 1, \gamma = 2$, fixed source}
        \label{fig:sub1}
    \end{subfigure}
    \hfill
    % Second Subfigure
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/heat_rec_0.5_0.5_s.png}
        \caption{$\beta = 0.5, \gamma = 0.5$, fixed source}
        \label{fig:sub2}
    \end{subfigure}
    \hfill
    % Third Subfigure
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/heat_rec_0.1_0.25_s.png}
        \caption{$\beta = 0.1, \gamma = 0.25$, fixed source}
        \label{fig:sub3}
    \end{subfigure}
    
    \caption{\textbf{Clean, perturbed and delineation-recovered spatial error distribution for selected attack bounds} - for both fixed and optimized source location.}
    \label{fig:heatmap_fixed}
\end{figure*}



\begin{figure*}[h!]
    \centering
    \includegraphics[width=\textwidth]{images/shared_office.png}
    
    \caption{\textbf{Office environment spatial error distribution for selected attack bounds} - Office environment.}
    \label{fig:heatmap_fixed_office}
\end{figure*}


\begin{figure*}[h!]
    \centering
    \includegraphics[width=\textwidth]{images/shared_room.png}
    
    \caption{\textbf{Office environment spatial error distribution for selected attack bounds} - Room environment.}
    \label{fig:heatmap_fixed_room}
\end{figure*}


\begin{figure*}[h!]
    \centering
    \includegraphics[width=\textwidth]{images/attack_res_room.png}
    
    \caption{\textbf{Mean RMS with and without source location optimization} - Room Environment.}
    \label{fig:attack_res_room}
\end{figure*}
\begin{figure*}[h!]
    \centering
    \includegraphics[width=\textwidth]{images/attack_res_office.png}
    
    \caption{\textbf{Mean RMS with and without source location optimization} - Office Environment.}
    \label{fig:attack_res_office}
\end{figure*}


\subsection{Perturbation Delineation Uncertainty}
\label{app:delta}
 Our perturbation recovery algorithm recovers the exact perturbation waveform up to uncertainty in the sampled perturbation value at moment $t=0$, in this section we further evaluate our method by assessing the affect of this deviation over model performance. Namely, for a clean input signal $s_{drone}(t)$, our recovered signal in \cref{sec:defense} is $(s_{drone}+\delta)(t)$ for some unknown scalar offset $\delta \in \mathbf{R}$ (that equals the perturbation response at the microphone at moment $t=0$). Our primary approach for evaluating the repercussion of uncertainty in $\delta$ is by estimation of the spatial distribution of location-wise perturbation values at $t=0$ (denoted $s_{\mathrm{p}}'(t=0;\mu)$ and location gradient infinity norms across different sensor locations $\mu$ - $\mathcal{L}_\infty(\frac{\partial \mathcal{F}(s_{drone})}{\partial s_{drone}})$.
\begin{figure}[htbp]
\centering

  
  \includegraphics[width=\linewidth]{images/loc_grad_pert_vals_loc_pert_product.png}
  
  {\caption{\textbf{Spatial distribution of maximum location prediction response to change in $\delta$ -} demonstrating responses typically several magnitudes of order lower compared to absolute locations}
  \label{fig:delta}
  }
  
  
\end{figure}

The product $s_{\mathrm{p}}'(t=0;\mu)\cdot\mathcal{L}_\infty(\frac{\partial \mathcal{F}(s_{drone})}{\partial s_{drone}})$ upper-bounds the location-wise rate of location prediction change as a response of change in $\delta$ exactly equal to our perturbation recovery error $s_{\mathrm{p}}'(t=0;\mu)$. Results are brought in \cref{fig:delta}, demonstrating that characteristic values of $s_{\mathrm{p}}'(t=0;\mu)$ across the map hold negligible response over location prediction, corroborating the reliability of our delineation method. \\
To further support our conclusions, we show similar results on the training objective loss gradients, rather than on the location directly. These results are depicted in figure \ref{fig:loss_grads}.
\begin{figure*}[htbp]
\centering

  
  \includegraphics[width=1\linewidth]{images/loss_grad_pert_vals_loss_pert_product.png}
  
  {\caption{\textbf{Spatial distribution of maximum loss response to change in perturbation starting conditions uncertainty $\delta$}.}
  \label{fig:loss_grads}
  }
  
  
\end{figure*}

\section{Training Details}
\label{app:training}
\subsection{Clean Model Training}
For training our "clean" localization model (to later be attacked) we train both the forward model and the transformer-encoder inverse model from \cite{shor2024active}
\subsubsection{Forward Model}
We parameterize the self-sound of each rotor with 16 point sound-sources, and optimize using L-BFGS for 50 iterations. The self-sound is then used along with the scene-specific pre-trained RIRs published in \cite{luo2022learning} for each test environment.
\subsubsection{Localization Model}
We train the localization model with dataset generated by sampling each environment with a $5\times5$ cm density. For each such drone location we computed the sound sampled by the microphone array in 32 azimuthal orientations uniformly spaced within the $[0,2\pi]$ range. With this dataset of sounds sampled by the microphones at different drone locations and orientations (~125000 samples for the apartment, 65000 for office and 42000 for room) we train the localization model, using the transformer-encoder architecture from \cite{shor2024active}. We subsample each waveform from a temporal dimension of ~12000 timesteps to 1200 using a learned linear operator. This subsampled input is then fed into a 3-layered transformer-encoder model with hidden dimension of 1024. This model is trained on batches of 128 for 80 epochs on an NVIDIA RTX-2080 GPU, with phase modulation optimization of 10 sine basis components. Model parameters are optimized with an Adam optimizer, using a learn-rate of 0.00001 for the localization model and a learn rate of 0.05 for the phase modulation parameters. 

\subsection{Perturbation Optimization}


\begin{algorithm}
\caption{Perturbation Recovery Algorithm for Sound Waveform Separation}
\label{alg:perturbation_delineation}
\begin{algorithmic}[1]
\REQUIRE Perturbed waveform $s_{\mu}$, period time $T$
\ENSURE Recovered sampled perturbation waveform $s_{\mathrm{r}}$

\STATE Initialize  $s_{\mathrm{r}} = [\ ]$ \# \textit{Recovered Waveform}

\FOR{$j = 1$ \textbf{to} $T$}
    \STATE sample $s_{\mu}(t;j)$ \# \textit{Modulate by $j$ timesteps}
    \STATE update $s_{\mathrm{r}}(t=j) = s_{\mu}(t;j)-s_{\mu}(t;0)$ \# \textit{Calculate perturbation at timestep $j$}
\ENDFOR

\STATE \textbf{return} $s_{\mathrm{r}}$
\end{algorithmic}
\end{algorithm}


We train each universal perturbation for 100 PGD iterations, with early-stop of 5 consecutive epochs without loss increase. Each PGD iterations is performed across the entire test set. Minimum frequency is set to $50 [Hz]$, maximum to $2000 [Hz]$. $\lambda_{amp}, \lambda_{power} and \lambda_{SDF}$ are all set to 1 for all experiments. For location optimization we run all experiments on a NVIDIA A6000 GPU with batch-size of 3. For fixed attack source locations we train on an RTX-2080 with batch-size of 128. Source initial position is set to the center of the environment for all experiments.

\section{Resource Analysis}
\label{app:loc_opt}
In this section we supply resource consumption details for a single NVIDIA A6000 GPU during a single PGD iteration of perturbation optimization across the entire dataset of 12575 samples, consisting our test set for the \textit{apartment\_frl\_2} acoustic setting (the largest of the 3 environments we consider). Each table compares iteration time with and without source location optimization. Results show growth in GPU memory consumption by a factor of over 3, and in optimization time growth by a factor of around 2 when applying source location optimization, compared to the fixed-source location counterpart. We further stress that while, for the sake of comparability, we only analyze for low batch-sizes of up to 3 (for which we are able to fit optimization in memory using a single GPU in both cases), fixed-location optimization can be expedited by increasing the batch-size.

\begin{table*}
\centering
\small
\caption{RMS Mean $\pm$ Standard Deviation per amplitude ($\beta$) and power ($\gamma$) constraints - after perturbation recovery}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{$\beta$ \textbackslash $\gamma$} & \textbf{clean} & \textbf{0.1} & \textbf{0.25} & \textbf{0.5} & \textbf{1} & \textbf{2} \\ \hline
\textbf{0.01} & 0.0487 $\pm$ 0.0331 & 0.0568 $\pm$ 0.0331 & 0.0568 $\pm$ 0.0332 & 0.0568 $\pm$ 0.0333 & 0.0568 $\pm$ 0.0332 & 0.0568 $\pm$ 0.0332 \\ \hline
\textbf{0.1}  & 0.0487 $\pm$ 0.0331 & 0.0568 $\pm$ 0.0315 & 0.0569 $\pm$ 0.0330 & 0.0570 $\pm$ 0.0334 & 0.0572 $\pm$ 0.0334 & 0.0569 $\pm$ 0.0331 \\ \hline
\textbf{0.5}  & 0.0487 $\pm$ 0.0331 & 0.0568 $\pm$ 0.0316 & 0.0569 $\pm$ 0.0330 & 0.0570 $\pm$ 0.0334 & 0.0568 $\pm$ 0.0331 & 0.0570 $\pm$ 0.0331 \\ \hline
\textbf{1}    & 0.0487 $\pm$ 0.0331 & 0.0568 $\pm$ 0.0316 & 0.0570 $\pm$ 0.0331 & 0.0571 $\pm$ 0.0333 & 0.0572 $\pm$ 0.0332 & 0.0573 $\pm$ 0.0333 \\ \hline
\end{tabular}

\label{tab:defense}
\end{table*}

% \begin{table}[h]
%     \centering
%     \begin{tabular}{cccc}
%         \toprule
%         Batch Size & \texttt{Optimized Location} (GB) & \texttt{Fixed Location} (GB) \\
%         \midrule
%         1 & 15.850 & 5.562 \\
%         2 & 29.746 & 9.184 \\
%         3 & 43.542 & 12.078 \\
%         \bottomrule
%     \end{tabular}
%     \caption{Single PGD iteration memory consumption across batch sizes}
% \end{table}
\begin{table}[h]
    \centering
    \caption{Single PGD iteration memory consumption across batch sizes}
    \begin{tabular}{cccc}
        \toprule
        Batch Size & \texttt{Optimized Location} (GB) & \texttt{Fixed Location} (GB) \\
        \midrule
        1 & 15.850 & 5.562 \\
        2 & 29.746 & 9.184 \\
        3 & 43.542 & 12.078 \\
        \bottomrule
    \end{tabular}%
    
    
\end{table}


% \begin{table}[h]
%     \centering
%     \begin{tabular}{cccc}
%         \toprule
%         Batch Size & \texttt{Optimized Location} (seconds) & \texttt{Fixed Location} (seconds) \\
%         \midrule
%         1 & 7592 & 3979 \\
%         2 & 6615 & 3491 \\
%         3 & 6322 & 3201 \\
%         \bottomrule
%     \end{tabular}
%     \caption{Single PGD iteration runtime across batch sizes}
% \end{table}
\begin{table}[h]
    \centering
    \caption{Single PGD iteration runtime across batch sizes}
    \begin{tabular}{cccc}
        \toprule
        Batch Size & \texttt{Optimized Location} (seconds) & \texttt{Fixed Location} (seconds) \\
        \midrule
        1 & 7592 & 3979 \\
        2 & 6615 & 3491 \\
        3 & 6322 & 3201 \\
        \bottomrule
    \end{tabular}%
    
    
\end{table}

We denote that the batch-size of 128 mentioned in section \ref{app:training} is used by internally batching RIR computations to batches of 2, and only inserting the batch-size of 128 onto the localization model.
\section{Phase Modulation Perturbation Delineation}
\label{app:def_table}
In this section we provide further evidence for the prowess of our adversarial perturbation recovery algorithm from section \ref{sec:defense}, added to figures \ref{fig:delta},\ref{fig:heatmap}.

In table \ref{tab:defense} we report RMS error mean and standard-deviation for all amplitude and power bounds evaluated in section \ref{sec:def_res}, similarly to results shown in  \cref{sec:attack_res}. We observe marginal performance differences between clean and recovered perturbation performance. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
