\section{Background and Related Work}
\paragraph{Causal Discovery and LLMs.} The causal discovery task involves learning causal relationships from observed empirical data \citep{peters, Spirtes2016}. Many proposed algorithms exist \citep{Spirtes1993CausationPA, yu2019daggnndagstructurelearning,Nauta2019CausalDW,zheng2018dagstearscontinuousoptimization,Chickering2002OptimalSI} attempting to solve the causal discovery problem. However, these methods are known to struggle on real world graphs where observations are noisy or common structural assumptions are violated \citep{chevalley2023causalbenchlargescalebenchmarknetwork,tu2019neuropathicpaindiagnosissimulator}. 

Recently, LLMs have emerged as an alternative approach to causal discovery \citep{k覺c覺man2024causalreasoninglargelanguage,abdulaal2024causal,vashishtha2023causalinferenceusingllmguided,li2024realtcdtemporalcausaldiscovery,lampinen2023passivelearningactivecausal}. \citet{k覺c覺man2024causalreasoninglargelanguage} first investigated the capability of LLMs to act as zero-shot causal discovery agents using only semantic information and pairwise prompting on each variable pair. Follow-up work \citep{abdulaal2024causal} further improves LLM predictions with observational data by selecting for predictions which maximize data likelihood. \citet{vashishtha2023causalinferenceusingllmguided} utilize \textit{triplet prompting} to prevent cycles when the causal graph is acyclic. They show only a topological ordering on variables is required for many common causal reasoning tasks \citep{chu2023causaleffectestimationrecent}. Other works \citep{zhou2024causalbenchcomprehensivebenchmarkcausal, chen2024clearlanguagemodelsreally} benchmark LLMs across a range of causality related tasks including causal discovery and causal inference confirming that LLMs struggle with integrating numerical data. 

Another line of work more related to our proposed interactive causal discovery problem  studies how to incorporate background knowledge into causal discovery algorithms \citep{meek2013causalinferencecausalexplanation}. Define a set of \textit{background knowledge} as the tuple $\mathcal{K} = (F,R)$, where $F$ specifies a set of ``forbidden'' graph edges and $R$ specifies a set of ``required'' graph edges. \citet{meek2013causalinferencecausalexplanation} presents an algorithm for constructing a causal graph consistent with $\mathcal{K}$ by leveraging an assumed structural directed acyclic graph (DAG) property. Building on \citet{meek2013causalinferencecausalexplanation}, \citet{Chickering2002OptimalSI} proposes a greedy search algorithm that performs well in practice.

Most related are statistical methods from the causal discovery literature which aim to efficiently choose a sequence of interventions to discover causal structure \citep{scherrer2022learningneuralcausalmodels,olko2024trustnablagradientbasedintervention}. In particular, Gradient based Interventional Targeting (\textbf{GIT}) \citep{olko2024trustnablagradientbasedintervention} utilizes existing neural causal discovery methods \citep{lippe2022efficientneuralcausaldiscovery} to learn a distribution over possible graph structures and variable assignments. For each round of intervention, GIT prioritizes variables whose simulated interventional distribution have large gradient with respect to the structural training loss.

In contrast to these works, our proposed algorithm utilizes LLMs to reason about the semantic/physical, as opposed to formal/structural, relationships between variables and edges in causal graphs. For this reason we are not required to make any structural assumptions on an underlying DAG, as is common in the causal discovery literature. This is desirable as in practice many real-world causal graphs are cyclic and poorly structured \citep{brain_cg, arctic}. Additionally our method does not rely on observational or interventional data for real world graphs which may be expensive to acquire but crucial for good performance with statistical methods.

\paragraph{LLMs as Optimizers.} Another growing line of work utilizes LLMs as black-box optimizers \citep{yang2024largelanguagemodelsoptimizers, roohani2024biodiscoveryagentaiagentdesigning}. \citet{yang2024largelanguagemodelsoptimizers} introduce the notion of an LLM as a generic optimizer and use it to optimize performance objectives stemming from a range of tasks including linear regression and mathematical word problems \citep{cobbe2021trainingverifierssolvemath}. Other works \citep{madaan2023selfrefineiterativerefinementselffeedback, havrilla2024glorewhenwhereimprove} examine the self-refinement capabilities of LLMs where the LLM must reason and self-improve on earlier responses. A growing number of papers apply LLMs to optimal experiment design and discovery \citep{roohani2024biodiscoveryagentaiagentdesigning, ai4science2023impactlargelanguagemodels,gao2024empoweringbiomedicaldiscoveryai,majumder2024discoverybenchdatadrivendiscoverylarge,jansen2024discoveryworldvirtualenvironmentdeveloping}. \citet{roohani2024biodiscoveryagentaiagentdesigning} apply LLMs to gene discovery tasks which aim to find highly-influential parent genes affecting the regulation of a downstream target gene. \citet{majumder2024discoverybenchdatadrivendiscoverylarge,jansen2024discoveryworldvirtualenvironmentdeveloping} both present benchmarks evaluating the ability of LLMs to perform real-world and synthesized discovery tasks.


%Misc: 
%\citep{lyle2023discobaxdiscoveryoptimalintervention}