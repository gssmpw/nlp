\begin{table}[H]
\vspace{-2mm}
\centering
\adjustbox{max width=\columnwidth}{%
\scriptsize
\begin{tabular}{cccccccc}
\toprule

\multicolumn{8}{c}{\textbf{Llama2-7B-chat-hf(4k)}} \\

\midrule
\multirow{1}{*}{{\textbf{Methods}}}  
& \multicolumn{1}{c}{\textbf{R.PK}}
& \multicolumn{1}{c}{\textbf{R.Num}}
& \multicolumn{1}{c}{\textbf{R.KV}}
& \multicolumn{1}{c}{\textbf{En.MC}}
& \multicolumn{1}{c}{\textbf{Math.F}}
& \multicolumn{1}{c}{\textbf{Code.Debug}}
& \textbf{Average} \\

\renewcommand{\arraystretch}{1} % 恢复默认行间距
Max Length & 125k & 125k & 175k & 834k & 120k & 258k & 273k   \\
\midrule
Ours & \textbf{100.00} & 97.63 & 20.60 & 33.62 & 19.71 & 25.13 & 49.45 \\
Ours-calibration & 100.00 & \textbf{98.64} & \textbf{30.20} & 36.24& 19.71 & \textbf{31.47} & \textbf{52.71} \\
% Sink-eviction-layer-1-8 & \redtext{67.32} & 42.37 & \redtext{19.38} & \redtext{33.62} & \redtext{17.43} & 25.13 & \redtext{46.48} \\
% Sink-eviction-layer-9-16 & \redtext{92.12} & 91.19 & \redtext{26.25} & \redtext{34.50} & \redtext{17.71} & 26.78 & \redtext{48.88} \\
% Sink-eviction-layer-17-24 & \redtext{95.12} & 97.63 & \redtext{24.88} & \redtext{32.75} & \redtext{19.71} & 27.41 & \redtext{50.40} \\
% Sink-eviction-layer-25-32 & \redtext{100.00} & 97.63 & \redtext{28.62} & \redtext{36.24} & \redtext{19.71} & 26.24 & \redtext{50.78} \\


% Recency-eviction-layer-1-8 & \redtext{98.32} & 96.44 & \redtext{27.28} & \redtext{31.12} & \redtext{16.86} & 24.23 & \redtext{37.99} \\
% Recency-eviction-layer-9-16 & \redtext{96.78} & 98.64 & \redtext{25.62} & \redtext{32.75} & \redtext{17.43} & 25.13 & \redtext{46.07} \\
% Recency-eviction-layer-17-24 & \redtext{94.32} & \redtext{95.63} & \redtext{24.88} & \redtext{35.20} & \redtext{19.71} & 26.24 & \redtext{50.41} \\
% Recency-eviction-layer-25-32 & \redtext{98.56} & 97.63 & \redtext{31.18} & \redtext{37.33} & \redtext{19.71} & 28.57& \redtext{49.24} \\
% Middle-eviction-layer-1-8 & \redtext{96.00} & \redtext{96.53} & \redtext{30.00} & \redtext{38.46} & \redtext{19.71} & \redtext{30.06} & \redtext{-} \\
% Middle-eviction-layer-9-16 & \redtext{93.20} & \redtext{98.87} & \redtext{29.01} & \redtext{36.24} & \redtext{19.71} & \redtext{29.16} & \redtext{-} \\
% Middle-eviction-layer-17-24 & \redtext{88.00} & \redtext{90.63} & \redtext{28.32} & \redtext{35.12} & \redtext{19.71} & \redtext{31.47} & \redtext{-} \\
% Middle-eviction-layer-25-32 & \redtext{72.31} & \redtext{87.63} & \redtext{20.30} & \redtext{31.01} & \redtext{19.71} & \redtext{32.88} & \redtext{-} \\
Sink-eviction-layer-1-8 & 54.24 & 42.37 & 4.60 & 33.62 & 18.86 & 25.13 & 29.80 \\
Sink-eviction-layer-9-16 & 89.83 & 81.36 & 14.60 & 34.50 & 18.00 & 30.66 & 44.82 \\
Sink-eviction-layer-17-23 & 98.81 & 98.31 & 20.40 & 32.75 & 18.86 & 29.87 & 49.83 \\
Sink-eviction-layer-24-31 & 98.98 & 97.29 & 20.60 & 36.24 & 17.71 & 31.23 & 50.34 \\
Recency-eviction-layer-1-8 & 98.47 & 97.63 & 22.40 & 31.12 & 19.71 & 28.98 & 49.72 \\
Recency-eviction-layer-9-16 & 98.98 & 97.97 & 25.60 & 32.75 & 19.71 & 31.23 & 51.04 \\
Recency-eviction-layer-17-23 & 99.15 & 97.97 & 27.60 & 35.20 & \textbf{20.29}  & 21.47 & 50.28 \\
Recency-eviction-layer-24-31 & 98.98 & 97.97 & 29.80 & 37.33 & 19.71 & 22.38 & 51.03 \\
Middle-eviction-layer-1-8 & 98.64 & 98.31 & 24.80 & \textbf{38.46} & 19.14 & 25.38 & 50.79 \\
Middle-eviction-layer-9-16 & 99.32 & 98.31 & 23.20 & 36.24 & 19.43 & 30.21 & 51.12 \\
Middle-eviction-layer-17-23 & 98.47 & 98.47 & 28.40 & 35.12 & 19.71 & 29.45 & 51.61 \\
Middle-eviction-layer-24-31 & 99.15 & 98.14 & 30.00 & 31.01 & 19.71 & 27.95 & 50.99 \\
\bottomrule
\end{tabular}
}
% \vspace{-1mm}
\caption{Ablation of Llama2-7B-chat-hf on InfiniteBench. Ours-calibration refers to the approach where layers 9-16 adopt the recency bias token eviction method, while layers 25-32 evict sink bias tokens, and layers 1-8 evict middle bias tokens. Other methods follow the naming format [Evicted Token Type]-eviction-layer-[Evicted Layer Range].}
\label{tab:InfiniteBench_ablation}
% \vspace{-4mm}
\end{table}
