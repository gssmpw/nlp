\begin{theorem}\label{thm:parallel_attn_collapse_main}
    Consider the following setup:
    \begin{itemize}
        \item Let \( X \in \mathbb{R}^{N \times d} \) denote the input sequence, partitioned into \( C \) chunks, where each chunk contains at most \( w \) tokens, i.e., \( X^{c} \in \mathbb{R}^{w \times d} \) for \( c \in [C] \).
        \item Define the query, key, and value transformations for each chunk as:
        \[
        Q_h^{c} = f_Q(X_h^{c}), ~ K_h^{c} = f_K(X_h^{c}), ~V_h^{c} = f_V(X_h^{c}),
        \]
        where \( Q_h^{c}, K_h^{c}, V_h^{c} \in \mathbb{R}^{w \times d_k} \).
        \item The local attention matrix for head \( h \) and chunk \( c \) is given by:
        \[
        A_h^{c} = \operatorname{Softmax}\left(\frac{Q_h^{c} {K_h^{c}}^\top}{\sqrt{d_k}}\right) \in \mathbb{R}^{w \times w}.
        \]
        \item Let \( \mathcal{S}_\epsilon^{(l,c)} \) denote the set of effective entries in the normalized attention matrix row for chunk \( c \), with values exceeding a threshold \(\epsilon > 0\):
        \[
        \mathcal{S}_\epsilon^{(c)}(A_h^{c}[i,:]) = \{ j \mid A_h^{c}[i,j] > \epsilon \}, ~~ i \in [w].
        \]
        \item Assume the sparsity parameter \( R \) for each chunk satisfies \( R = o(\sqrt{\log(w)}) \). The sparsity parameter 
\(R\) quantifies the extent of sparsity in the attention matrix, describing how many entries are negligible versus effective in contributing to the attention computation. 
    \end{itemize}
    Then:
    \begin{itemize}
        \item {\bf Part 1:} For any \(\epsilon > 0\), the sparsity threshold of effective entries in \(A_h^{c}\) increases with \(w\). \( \epsilon \) is a user-defined threshold that controls sparsity in the attention matrix. Smaller \( \epsilon \) retains more entries, while larger \( \epsilon \) increases sparsity. With more chunks (\( C \)), \( \epsilon \) affects the balance between retaining information within each chunk and computational efficiency.
        \item {\bf Part 2:} The number of effective entries \(k\) in each row of \(A_h^{c}\) is upper-bounded as:
        \[
        k \leq w - \exp\left(O\left(\frac{\log^2(\epsilon \cdot w)}{R^2}\right)\right) \cdot \frac{\delta}{wd_k}.
        \]
        \item {\bf Part 3:} With high probability (\(1 - \delta\)), the number of effective entries in each row satisfies:
        \[
        \lim_{w \to \infty} | \mathcal{S}_\epsilon^{(c)}(A_h^{c}[i,:]) | = w - k.
        \]
    \end{itemize}
\end{theorem}