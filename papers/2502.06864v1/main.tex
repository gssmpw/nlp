% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[preprint]{acl}
% \usepackage[review]{acl}
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

\usepackage{booktabs}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{xspace}
\usepackage{amsmath}
\newcommand{\modelname}{KG$^2$RAG\xspace}
\usepackage{enumitem}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Knowledge Graph-Guided Retrieval Augmented Generation}
    
% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
Xiangrong Zhu$^\clubsuit$
\quad Yuexiang Xie$^\heartsuit$
\quad Yi Liu$^\clubsuit$
\quad Yaliang Li$^\heartsuit$
\quad Wei Hu$^\clubsuit$\\
$^\clubsuit$ State Key Laboratory for Novel Software Technology, Nanjing University, China \\
$^\heartsuit$ Alibaba Group \\
\texttt{\{xrzhu, yiliu07\}.nju@gmail.com, whu@nju.edu.cn} \\
\texttt{\{yuexiang.xyx, yaliang.li\}@alibaba-inc.com}
}
% \author{Xiangrong Zhu \\
%   Affiliation / Address line 1 \\
%   \texttt{xrzhu.nju@gmail.com} \\\And
%   Yuexiang Xie \\
%   Affiliation / Address line 1 \\
%   \texttt{email@domain} \\\And
%   Yi Liu \\
%   Affiliation / Address line 1 \\
%   \texttt{email@domain} \\\AND
%   Yaliang Li \\
%   Affiliation / Address line 1 \\
%   \texttt{email@domain} \\\And
%   Wei Hu \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   \texttt{email@domain}\\}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle

\begin{abstract}
Retrieval-augmented generation (RAG) has emerged as a promising technology for addressing hallucination issues in the responses generated by large language models (LLMs). Existing studies on RAG primarily focus on applying semantic-based approaches to retrieve isolated relevant chunks, which ignore their intrinsic relationships.
In this paper, we propose a novel Knowledge Graph-Guided Retrieval Augmented Generation (\modelname) framework that utilizes knowledge graphs (KGs) to provide fact-level relationships between chunks, improving the diversity and coherence of the retrieved results. Specifically, after performing a semantic-based retrieval to provide seed chunks, \modelname employs a KG-guided chunk expansion process and a KG-based chunk organization process to deliver relevant and important knowledge in well-organized paragraphs.
Extensive experiments conducted on the HotpotQA dataset and its variants demonstrate the advantages of \modelname compared to existing RAG-based approaches, in terms of both response quality and retrieval quality. 
\end{abstract}

\section{Introduction}
\label{sect:intro}

Recently, large language models (LLMs)~\cite{li24llmsurvey,ren24llmsurvey,hugo23llama,tom20gpt} have achieved remarkable success across a broad range of real-world tasks, including question answering~\cite{sen23knowledge}, writing assistance~\cite{marco23cicero}, code generation~\cite{cheng24data}, and many others~\cite{jean23llmapplication,wu23autogen}. However, hallucinations~\cite{xu24hallucinationsurvey,liu24hallucinationsurvey} in the generated responses becomes a critical challenge, which often results from containing outdated information or lacking domain-specific knowledge.
Retrieval-augmented generation (RAG)~\cite{gao23ragsurvey,fan24ragsurvey} has emerged as a feasible solution to mitigate hallucinations by retrieving relevant knowledge from provided documents and incorporating it into the prompts of LLMs for response generation.

\begin{figure}[t]
\centering
\includegraphics[width=\linewidth]{figs/paradigms.pdf}
\caption{A comparison among LLM-only, Semantic RAG, and Graph RAG paradigms.}
\label{fig:paradigms}
\end{figure}

Existing studies in RAG~\cite{patrick20rag,yu22rag,anupam23keyword,gao23ragsurvey,angelo24ratts}, as shown in Fig.~\ref{fig:paradigms}, employ keyword-based or semantic-based approaches to retrieve documents or chunks having the highest similarities to user queries. However, these retrieved chunks can be homogeneous and redundant, which fails to provide the intrinsic relationships among these chunks and cannot further activate the reasoning abilities of LLMs. Furthermore, the retrieved chunks are often directly concatenated in the order of their similarity scores and fed into LLMs as part of the prompts. Such a practice can lead to isolated pieces of information, limiting the utility of LLMs in generating comprehensive and reliable responses.

Knowledge graphs (KGs)~\cite{auer07dbpedia,ji22kgsurvey}, as structured abstractions of real-world entities and their relations, can be expected to effectively supplement existing semantic-based RAG approaches by integrating structured factual knowledge. 
Knowledge within a KG, represented in the form of triplets (\textit{head entity}, \textit{relation}, \textit{tail entity}), is naturally linked through overlapping entities.
A simplified workflow for utilizing KGs in RAG is shown in Fig.~\ref{fig:paradigms}, where relevant triplets are retrieved to augment the context for response generation in LLMs, providing fact-level relationships among chunks and highlighting important facts that may be missed by semantic-based approaches.

Shed light by such insights, in this paper, we propose a novel \textbf{K}nowledge \textbf{G}raph-\textbf{G}uided \textbf{R}etrieval \textbf{A}ugmented \textbf{G}eneration framework, called \modelname.
Specifically, we first perform chunking and KG-chunk association during the offline processing of the provided documents, establishing linkages between chunks and a specific KG to capture the fact-level relationships among these chunks. 
Based on the chunks and the KG, \modelname employs KG-enhanced chunk retrieval, which consists of a semantic-based retrieval and graph-guided expansion. The semantic-based retrieval prepares several seed chunks using embedding and ranking techniques~\cite{zach24nomic,li24mxbai}. These seed chunks are then used to extract a relevant subgraph from the association KG, onto which we can apply graph traversal algorithms to include the chunks containing overlapped or related entities and triplets. Such a design of graph-guided expansion provides a greater diversity of retrieved chunks and a comprehensive knowledge network.

After that, we incorporate a post-processing stage named KG-based context organization in \modelname. On one hand, the KG-based context organization serves as a filter to retain the most relevant information contained in the subgraph, thereby enhancing the informativeness of the retrieved chunks. On the other hand, it serves as an arranger to organize the chunks into internally coherent paragraphs with the knowledge graph as a skeleton. 
These semantically coherent and well-organized chunks are fed into the LLMs along with user queries for response generation.

We conduct a series of experiments on the widely-used HotpotQA~\cite{yang18hotpotqa} dataset and its newly constructed variants to mitigate the impacts of prior knowledge on LLMs. We adopt a distractor and a fullwiki setting, comparing \modelname with several RAG-based approaches. The experimental results demonstrate that \modelname consistently outperforms baselines in terms of both response quality and retrieval quality. Moreover, we conduct an ablation study to highlight the effectiveness of different modules in \modelname.
The constructed dataset and source code are released at \url{https://github.com/nju-websoft/KG2RAG} to further promote the development and application of KGs in RAG.

\begin{figure*}[t]
\centering
\includegraphics[width=0.98\linewidth]{figs/pipeline.pdf}
\caption{Workflow of the proposed \modelname.}
\label{fig:pipeline}
\end{figure*}

\input{subsections/3_method}
%\input{backups/backup_exp}
\input{subsections/4_exp}
\input{subsections/2_related}

\section{Conclusion}
In this paper, we propose \modelname, a novel framework designed to enhance the performance of RAG through the integration of KGs. We introduce linkages between chunks and a specific KG, which help in providing fact-level relationships among these chunks. Consequently, \modelname suggests performing the KG-guided chunk expansion and the KG-based context organization based on seed chunks retrieved by semantic-based retrieval approaches.
Through these processes, the retrieved chunks become diverse, intrinsically related, and self-consistent, forming well-organized paragraphs that can be fed into LLMs for high-quality response generation. We compare \modelname with existing RAG-based approaches, demonstrating its superior performance in both response quality and retrieval quality. An ablation study is also conducted to further confirm the contributions of KG-guided chunk expansion and KG-based context organization, indicating that these two modules collaboratively enhance the effectiveness of \modelname.

\section*{Acknowledgments}
This work is supported by the National Natural Science Foundation of China (No. 62272219).

\section*{Limitations}

Retrieval-augmented generation (RAG) is a systematic engineering framework that can be refined from multiple perspectives, including query rewriting ~\cite{xiao23cpack}, retrieval optimization ~\cite{matous24aragog}, multi-turn dialogue ~\cite{Yao23iclr} and so on \cite{gao23ragsurvey}. 
\modelname only focuses on the part of retrieval optimization and aims to perform KG-guided retrieval expansion and KG-based context organization to enhance RAG with the structured factual knowledge from KGs, without optimizing other modules.
However, the proposed \modelname is orthogonal and compatible with the aforementioned modules. 
In the future, we will develop \modelname into a plug-and-play tool that can be easily integrated with other approaches, thereby better facilitating the research community.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\input{subsections/appendix}

\end{document}
