\begin{figure*}[t!]
\centering
\includegraphics[width=1.0\textwidth]{./Figure/fig2.pdf}
\caption{ The overview of our proposed method. Initially, we downsample original point clouds into various densities and then select one based on detector confidence. To learn domain-agnostic features, feature content alignment (FCA) are applied to BEV features for each shared Region of Interest (ROI) to align low-level content consistency. Subsequently, encoded features are constrained by graph-based embedding relationship alignment (GERA) to maintain high-level relationship consistency. The blue and red flows illustrate the processing pipelines for the teacher and student models, respectively.}

% \vspace{-.5cm}
\vspace{-10pt}
\label{fig2}
\end{figure*}

\label{relatedwork}

% Lidar-based 3D object detection
\subsection{LiDAR-based 3D Object Detection}
LiDAR-based 3D Object Detection aims to estimate precise positions and orientations of 3D objects in scene-level point clouds. In terms of representations used, the existing works can be categorized into voxel-based~\cite{zhou2018voxelnet, yan2018second, yang2018pixor, lang2019pointpillars, shi2020points, deng2021voxel, yin2021center}, point-based~\cite{shi2019pointrcnn, shi2020point} and point-voxel based~\cite{shi2020pv, shi2023pv} methods. VoxelNet~\cite{zhou2018voxelnet} rasterizes point clouds into volumetric dense grids, followed by 3D CNNs that convolve along each dimension. SECOND~\cite{yan2018second} leverages sparse convolution to eliminate unnecessary computation wasted on unoccupied zero-padding voxels. Point-RCNN~\cite{shi2019pointrcnn} is the first to introduce a method for generating 3D proposals from point clouds in a bottom-up fashion. PV-RCNN~\cite{shi2020pv} integrate the advantages of both point-based and voxel-based methods to produce more precise results. In our work, We choose SECOND~\cite{yan2018second} and PV-RCNN~\cite{shi2020pv} as our backbone detectors.

% Unsupervised Domain Adaptation
\subsection{Unsupervised Domain Adaptation for 3D object detection}
Unsupervised Domain Adaptation (UDA) aims to leverage both the labeled source domain and the unlabeled target domain to transfer knowledge from the source domain to the target domain. \cite{wang2020train} is a pioneer in investigating the domain gap between LiDAR datasets for 3D object detection. ST3D~\cite{yang2021st3d} employs the self-training strategy and trains networks with curriculum data augmentation. LiDAR Distillation~\cite{wei2022lidar} and DTS~\cite{hu2023density} utilize the teacher-student framework with augmentation strategies related to point cloud density resampling to address the domain gap caused by different LiDAR configurations. However, UDA techniques still aim to improve performance in a specific target domain, and they cannot guarantee performance in other unseen domains.

% Domain Generalization
\subsection{Domain Generalization}
The goal of Domain Generalization (DG) is to improve the performance on unseen domains that are not used in the training process. In 2D computer vision, various DG works have been proposed for object detection~\cite{wu2022single, vidit2023clip}. Nevertheless, DG for 3D vision tasks is still an under-explored problem. Uni3D~\cite{zhang2023uni3d} strengthen feature reusability across different datasets to generalize the detector from multiple domains. Given the cost-expensiveness of obtaining multiple fully-labeled LiDAR datasets as source domains for training, we decide to improve the generalization ability only from a single source domain. Previous works~\cite{yang2021st3d, choi2021part, lehner20223d, hu2023density} have introduced their augmentation strategies to make detectors robust to domain shifts. ROS from \cite{yang2021st3d} randomly scales object sizes for diverse object detection. RBRS in \cite{hu2023density} augments point clouds via density re-sampling, emphasizing density distribution manipulation for improved model robustness. PA-AUG~\cite{choi2021part} is proposed to obtains the robustness to corrupted data for 3D detection models. 3D-VField~\cite{lehner20223d} adversarially augment each car to make the detector more robust to the rare shaped and damaged car. While their emphasis is on data augmentation, we combine our augmentation strategy and the student-teacher framework with proposed feature alignment techniques to achieve better generalization ability.

