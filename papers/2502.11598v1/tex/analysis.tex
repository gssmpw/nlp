\section{Further Analysis}
\subsection{Computational Overhead}
\label{sec:computational}
To conduct a thorough assessment of practical applications, this section presents a detailed analysis of the operational overhead associated with the three proposed watermark removal methods, as summarized in Table \ref{tab:overhead_comparison}.

\vspace{3pt}

\noindent\textbf{External Tools} \quad UP and TP require external paraphrasing tools, while WN needs none.

\vspace{3pt}

\noindent\textbf{Preprocessing Time Consumption} \quad UP requires Dipper-like models to paraphrase the entire training dataset, WN only needs watermark stealing for preprocessing, and TP requires both. The time cost of watermark stealing consists of student model training (about 1h for Llama-7b) and dataset forward passes. The forward passes are computationally much cheaper than paraphrasing, as parallel computation is faster than autoregressive generation.

\vspace{3pt}

\noindent\textbf{Student Model Inference Latency} \quad UP and TP have no additional inference overhead. WN requires adding inverse watermark during inference, causing slight delay. 
\input{table/overhead}

\subsection{Multi-Source Knowledge Distillation}
\input{table/multi-source}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figure/multi_source.pdf}
    \caption{Average -$\log p$ values from detectors and MTBench scores as the number of teacher sources increases.}
    \label{fig:multi_source}
    \vspace{-15pt}
\end{figure}
\label{sec:multi-source}
The previous analysis focused on single-source knowledge distillation. In real-world scenarios with multiple LLM services, we found that watermarks from different sources can collide and counteract each other during knowledge distillation, making watermarks less effective as a protection mechanism - even without any removal methods. 

\vspace{3pt}

\noindent\textbf{Case 1: Two Opposing Keys} \quad We tested an extreme case with two teachers using the KGW scheme with complementary  keys (the hash results were complete opposites). When we trained a student model using a combined dataset (100k samples from each teacher), the watermark detection confidence dropped significantly from e-28 to e-01, as shown in Table \ref{tab:multi-source}.

\vspace{3pt}

\noindent\textbf{Case 2: Two Watermarking Schemes} \quad We examined a scenario using two teacher models with different watermarking methods (KGW and SynthID-Text), each generating 100k samples. Training a student model on this combined dataset led to reduced watermark detection confidence for both schemes' detectors compared to single-source scenarios (as shown in Table \ref{tab:multi-source}).

\vspace{3pt}

\noindent\textbf{Case 3: Multi-Source} \quad In this scenario, all teacher models employ the KGW scheme with randomly selected keys. As shown in Figure \ref{fig:multi_source}, while increasing the number of source models and maintaining a constant total volume of mixed training data, watermark detection became increasingly difficult, yet model performance remained stable. This suggests that mixing data from a sufficient number of teacher sources can achieve untraceable knowledge distillation.

\vspace{-3pt}

\subsection{Future Directions in Defense Strategy}
\label{sec:defense}
This work reveals the vulnerability of unauthorized knowledge distillation prevention when generative LLM watermarking is predominantly confined to n-gram based approaches. While alternatives such as sentence-level reject sampling \cite{hou2023semstamp,hou-etal-2024-k} and post-generation signal embedding \cite{chang2024postmark} exist, these approaches introduce significant latency to the current token-by-token real-time LLM inference paradigm, making them difficult to deploy at scale in real-time LLM services. We therefore advocate for diversifying token-level watermarking techniques, as multiple paradigms would make it harder for attackers to identify and target specific methods, enabling more robust protection.
