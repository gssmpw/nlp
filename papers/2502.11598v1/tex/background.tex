\section{Background}
\label{sec:background}
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figure/method.pdf}
    \caption{An illustration of the proposed watermark removal attacks. }
    \label{fig:method}
    \vspace{-10pt}
\end{figure*}
\subsection{LLM Watermarking Schemes} 
Most of the existing watermarking schemes follow the $n$-gram paradigm, modifying the next token's probability prediction based on the preceding $n-1$ tokens, thereby influencing the final sampling outcome \cite{liu2023survey,DBLP:conf/icml/KirchenbauerGWK23, zhao2023provable,Dathathri2024,liu2024a,liu2024an,lee2023wrote,hu2023unbiased,wu2023dipmark,aronsonpowerpoint, kuditipudi2023robust, pan2024waterseeker,liu2024preventing,lu2024entropy}. 
% This is formalized as:
% \begin{equation}
% \small
%     P'(x_t|x_{1:t-1}) = \mathcal{A}(P(x_t|x_{1:t-1}); x_{t-n+1:t-1}),
% \end{equation}
% where $P'$ is the watermarked probability and $\mathcal{A}$ represents the watermark algorithm. 
Watermark schemes tested in this work are:

\textbf{KGW} \cite{DBLP:conf/icml/KirchenbauerGWK23} sets the ground work for generative LLM watermarking. For the $t^{th}$ token generation, it computes a hash $h_t = H(x_{t-n+1:t-1})$ from the previous $n-1$ tokens. This hash partitions the vocabulary $\mathcal{V}$ into a \textit{green list} $\mathcal{V}_g$ and a \textit{red list} $\mathcal{V}_r$. A constant bias $\delta$ is then added to the logits of green tokens:
\begin{equation}
\small
l'^{(i)}_t = l^{(i)}_t + \delta \text{\; if \;} v_i \in \mathcal{V}_g \text{\; else \;} l^{(i)}_t.
\end{equation}

As a result, watermarked text will statistically contain more \textit{green} tokens, and can be detected by computing the z-score:
\begin{equation}
\small
z = (|s|_G - \gamma T)/(\sqrt{\gamma(1 - \gamma) T}),
\end{equation}
where $|s|_G$ counts green tokens in text length $T$, and $\gamma = |\mathcal{V}_g|/|\mathcal{V}|$.

\vspace{3pt}

\textbf{SynthID-Text} \cite{Dathathri2024}, recently announced by Google DeepMind, is the first watermarking algorithm deployed in production, and has been integrated into the Gemini and Gemini Advanced chatbots. For the $t^{th}$ token generation, it computes a hash $h_t = H(x_{t-n+1:t-1})$ to seed $m$ binary classifiers $g_1, g_2, ..., g_m$, which randomly assign 0 or 1 to vocabulary tokens. It then samples $2^m$ tokens from the original distribution $P(x_t|x_{1:t-1})$ and conducts tournament sampling: tokens compete in pairs based on $g_1$ values in the first round, with subsequent rounds using $g_2, g_3, ..., g_m$ until one token remains. The watermark manifests as a statistical bias toward tokens with higher $g$ values, detectable by computing their mean: 
\begin{equation}
\small
    \overline{g} = \sum_{t=1}^T\sum_{\ell=1}^m g_\ell(x_t) / mT.
\end{equation}

\subsection{Watermark Radioactivity}
Research shows that watermarked LLMs exhibit radioactivity \cite{sander2024watermarking,gu2024learnability}: student models trained on their outputs inherit the watermark patterns. This effect is highly significant, with reported p-values below $10^{-30}$ even under the most stringent conditions where the teacher model is closed-source and detection is unsupervised (test prompts are disjoint from training data).

\subsection{Watermark Removal Approaches}
Prior work has explored various watermark removal methods, but focused on removing watermarks from generated text rather than models. These include untargeted approaches like paraphrasing, emoji attacks \cite{DBLP:conf/icml/KirchenbauerGWK23}, back-translation, and cross-lingual removal \cite{he2024can}. For targeted removal, \citet{jovanovicwatermark,wu-chandrasekaran-2024-bypassing,zhang2024large} proposed watermark stealing-and-removing, requiring knowledge of the type of watermarking scheme and the window size used.

% Inspired by these approaches, we consider that applying text-based watermark removal to training data may effectively prevent student models from inheriting watermarks. Therefore, we propose pre-distillation watermark removal approaches, including untargeted and targeted paraphrasing. The watermark stealing module in our targeted paraphrasing method differs from previous work as it requires no access to the watermarking scheme or its hyper-parameters. Moreover, it allocates weights based on watermark radioactivity factors.

