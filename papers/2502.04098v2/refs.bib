@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@inproceedings{bateni2020improved,
  title={Improved few-shot visual classification},
  author={Bateni, Peyman and Goyal, Raghav and Masrani, Vaden and Wood, Frank and Sigal, Leonid},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14493--14502},
  year={2020}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@inproceedings{zenke2017continual,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  pages={3987--3995},
  year={2017},
  organization={PMLR}
}

@article{chaudhry2019tiny,
  title={On tiny episodic memories in continual learning},
  author={Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K and Torr, Philip HS and Ranzato, Marc'Aurelio},
  journal={arXiv preprint arXiv:1902.10486},
  year={2019}
}

@article{Qwen2VL,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@inproceedings{chen2024internvl,
  title={Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24185--24198},
  year={2024}
}

@inproceedings{chaudhry2018riemannian,
  title={Riemannian walk for incremental learning: Understanding forgetting and intransigence},
  author={Chaudhry, Arslan and Dokania, Puneet K and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={532--547},
  year={2018}
}

@article{wang2024clips,
  title={Do CLIPs Always Generalize Better than ImageNet Models?},
  author={Wang, Qizhou and Lin, Yong and Chen, Yongqiang and Schmidt, Ludwig and Han, Bo and Zhang, Tong},
  journal={arXiv preprint arXiv:2403.11497},
  year={2024}
}

@techreport{maji13fine-grained,
   title         = {Fine-Grained Visual Classification of Aircraft},
   author        = {S. Maji and J. Kannala and E. Rahtu
                    and M. Blaschko and A. Vedaldi},
   year          = {2013},
   institution   = {University of Oxford},
   archivePrefix = {arXiv},
   eprint        = {1306.5151},
   primaryClass  = "cs-cv",
}

@inproceedings{houben2013detection,
  title={Detection of traffic signs in real-world images: The German Traffic Sign Detection Benchmark},
  author={Houben, Sebastian and Stallkamp, Johannes and Salmen, Jan and Schlipsing, Marc and Igel, Christian},
  booktitle={The 2013 international joint conference on neural networks (IJCNN)},
  pages={1--8},
  year={2013},
  organization={Ieee}
}

@article{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@inproceedings{perez2018film,
  title={Fi{LM}: Visual reasoning with a general conditioning layer},
  author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@inproceedings{zhang2021few,
  title={Few-shot incremental learning with continually evolved classifiers},
  author={Zhang, Chi and Song, Nan and Lin, Guosheng and Zheng, Yun and Pan, Pan and Xu, Yinghui},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12455--12464},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{tao2020few,
  title={Few-shot class-incremental learning},
  author={Tao, Xiaoyu and Hong, Xiaopeng and Chang, Xinyuan and Dong, Songlin and Wei, Xing and Gong, Yihong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12183--12192},
  year={2020}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International Conference on Machine Learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}


@inproceedings{liu2022convnet,
  title={A convnet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11976--11986},
  year={2022}
}

@article{mai2022online,
  title={Online continual learning in image classification: An empirical survey},
  author={Mai, Zheda and Li, Ruiwen and Jeong, Jihwan and Quispe, David and Kim, Hyunwoo and Sanner, Scott},
  journal={Neurocomputing},
  volume={469},
  pages={28--51},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{kolesnikov2020big,
  title={Big {T}ransfer ({B}i{T}): General visual representation learning},
  author={Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  booktitle={European Conference on Computer Vision},
  pages={491--507},
  year={2020},
  organization={Springer}
}

@article{shysheya2022fit,
  title={FiT: Parameter Efficient Few-shot Transfer Learning for Personalized and Federated Image Classification},
  author={Shysheya, Aliaksandra and Bronskill, John and Patacchiola, Massimiliano and Nowozin, Sebastian and Turner, Richard E},
  journal={arXiv preprint arXiv:2206.08671},
  year={2022}
}

@article{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}


@article{hospedales2021meta,
  title={Meta-learning in neural networks: A survey},
  author={Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={9},
  pages={5149--5169},
  year={2021},
  publisher={IEEE}
}

@inproceedings{peng2022few,
  title={Few-Shot Class-Incremental Learning from an Open-Set Perspective},
  author={Peng, Can and Zhao, Kun and Wang, Tianren and Li, Meng and Lovell, Brian C},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXV},
  pages={382--397},
  year={2022},
  organization={Springer}
}

@article{wang2020generalizing,
  title={Generalizing from a few examples: A survey on few-shot learning},
  author={Wang, Yaqing and Yao, Quanming and Kwok, James T and Ni, Lionel M},
  journal={ACM Computing Surveys (CSUR)},
  volume={53},
  number={3},
  pages={1--34},
  year={2020},
  publisher={ACM New York, NY, USA}
}


@article{requeima2019fast,
  title={Fast and flexible multi-task classification using conditional neural adaptive processes},
  author={Requeima, James and Gordon, Jonathan and Bronskill, John and Nowozin, Sebastian and Turner, Richard E},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{lomonaco2017core50,
  title={Core50: {A} new dataset and benchmark for continuous object recognition},
  author={Lomonaco, Vincenzo and Maltoni, Davide},
  booktitle={Conference on Robot Learning},
  pages={17--26},
  year={2017},
  organization={PMLR}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  volume={32},
  year={2019}
}

@article{mensink2013distance,
  title={Distance-based image classification: Generalizing to new classes at near-zero cost},
  author={Mensink, Thomas and Verbeek, Jakob and Perronnin, Florent and Csurka, Gabriela},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={35},
  number={11},
  pages={2624--2637},
  year={2013},
  publisher={IEEE}
}

@inproceedings{peng2019moment,
  title={Moment matching for multi-source domain adaptation},
  author={Peng, Xingchao and Bai, Qinxun and Xia, Xide and Huang, Zijun and Saenko, Kate and Wang, Bo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1406--1415},
  year={2019}
}

@article{calinski1974dendrite,
  title={A dendrite method for cluster analysis},
  author={Cali{\'n}ski, Tadeusz and Harabasz, Jerzy},
  journal={Communications in Statistics-theory and Methods},
  volume={3},
  number={1},
  pages={1--27},
  year={1974},
  publisher={Taylor \& Francis}
}

@inproceedings{van2018inaturalist,
  title={The i{N}aturalist {S}pecies {C}lassification and {D}etection {D}ataset},
  author={Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  booktitle={Proceedings of the IEEE Conference/CVF on Computer Vision and Pattern Recognition},
  pages={8769--8778},
  year={2018}
}

@techreport{WahCUB_200_2011,
  title ={},
  author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
  year = {2011},
  institution = {California Institute of Technology},
  number = {CNS-TR-2011-001}
}


@inproceedings{deCampos2009character,
  author    = "de Campos, T.~E. and Babu, B.~R. and Varma, M.",
  title     = "Character recognition in natural images",
  booktitle = "Proceedings of the International Conference on Computer
  Vision Theory and Applications, Lisbon, Portugal",
  month     = "February",
  year      = "2009",
}

@inproceedings{prabhu2020gdumb,
  title={G{D}umb: A simple approach that questions our progress in continual learning},
  author={Prabhu, Ameya and Torr, Philip HS and Dokania, Puneet K},
  booktitle={European Conference on Computer Vision},
  pages={524--540},
  year={2020},
  organization={Springer}
}

@inproceedings{yan2021dynamically,
  title={Der: Dynamically expandable representation for class incremental learning},
  author={Yan, Shipeng and Xie, Jiangwei and He, Xuming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3014--3023},
  year={2021}
}

@inproceedings{parkhi2012cats,
  title={Cats and dogs},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3498--3505},
  year={2012},
  organization={IEEE}
}

@inproceedings{douillard2020podnet,
  title={Podnet: Pooled outputs distillation for small-tasks incremental learning},
  author={Douillard, Arthur and Cord, Matthieu and Ollion, Charles and Robert, Thomas and Valle, Eduardo},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XX 16},
  pages={86--102},
  year={2020},
  organization={Springer}
}

@inproceedings{yu2020semantic,
  title={Semantic drift compensation for class-incremental learning},
  author={Yu, Lu and Twardowski, Bartlomiej and Liu, Xialei and Herranz, Luis and Wang, Kai and Cheng, Yongmei and Jui, Shangling and Weijer, Joost van de},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6982--6991},
  year={2020}
}

@inproceedings{krause20133d,
  title={3D object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision Workshops},
  pages={554--561},
  year={2013}
}

@article{maji2013fine,
  title={Fine-grained visual classification of aircraft},
  author={Maji, Subhransu and Rahtu, Esa and Kannala, Juho and Blaschko, Matthew and Vedaldi, Andrea},
  journal={arXiv preprint arXiv:1306.5151},
  year={2013}
}

@article{zhai2019large,
  title={A large-scale study of representation learning with the visual task adaptation benchmark},
  author={Zhai, Xiaohua and Puigcerver, Joan and Kolesnikov, Alexander and Ruyssen, Pierre and Riquelme, Carlos and Lucic, Mario and Djolonga, Josip and Pinto, Andre Susano and Neumann, Maxim and Dosovitskiy, Alexey and others},
  journal={arXiv preprint arXiv:1910.04867},
  year={2019}
}

@article{bronskill2021memory,
  title={Memory efficient meta-learning with large images},
  author={Bronskill, John and Massiceti, Daniela and Patacchiola, Massimiliano and Hofmann, Katja and Nowozin, Sebastian and Turner, Richard},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24327--24339},
  year={2021}
}

@inproceedings{kang2022class,
  title={Class-Incremental Learning by Knowledge Distillation with Adaptive Feature Consolidation},
  author={Kang, Minsoo and Park, Jaeyoo and Han, Bohyung},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16071--16080},
  year={2022}
}

@inproceedings{zhou2022forward,
  title={Forward compatible few-shot class-incremental learning},
  author={Zhou, Da-Wei and Wang, Fu-Yun and Ye, Han-Jia and Ma, Liang and Pu, Shiliang and Zhan, De-Chuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9046--9056},
  year={2022}
}

@inproceedings{hersche2022constrained,
  title={Constrained Few-shot Class-incremental Learning},
  author={Hersche, Michael and Karunaratne, Geethan and Cherubini, Giovanni and Benini, Luca and Sebastian, Abu and Rahimi, Abbas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9057--9067},
  year={2022}
}

@inproceedings{wu2022class,
  title={Class-Incremental Learning with Strong Pre-trained Models},
  author={Wu, Tz-Ying and Swaminathan, Gurumurthy and Li, Zhizhong and Ravichandran, Avinash and Vasconcelos, Nuno and Bhotika, Rahul and Soatto, Stefano},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9601--9610},
  year={2022}
}


@article{caccia2022new,
  title={New insights on reducing abrupt representation change in online continual learning},
  author={Caccia, Lucas and Aljundi, Rahaf and Asadi, Nader and Tuytelaars, Tinne and Pineau, Joelle and Belilovsky, Eugene},
  journal={arXiv preprint arXiv:2203.03798},
  year={2022}
}

@inproceedings{ahn2021ss,
  title={Ss-il: Separated softmax for incremental learning},
  author={Ahn, Hongjoon and Kwak, Jihwan and Lim, Subin and Bang, Hyeonsu and Kim, Hyojun and Moon, Taesup},
  booktitle={Proceedings of the IEEE/CVF International conference on computer vision},
  pages={844--853},
  year={2021}
}

@inproceedings{wu2019large,
  title={Large scale incremental learning},
  author={Wu, Yue and Chen, Yinpeng and Wang, Lijuan and Ye, Yuancheng and Liu, Zicheng and Guo, Yandong and Fu, Yun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={374--382},
  year={2019}
}

@inproceedings{zhao2020maintaining,
  title={Maintaining discrimination and fairness in class incremental learning},
  author={Zhao, Bowen and Xiao, Xi and Gan, Guojun and Zhang, Bin and Xia, Shu-Tao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13208--13217},
  year={2020}
}


@inproceedings{rebuffi2017icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2001--2010},
  year={2017}
}

@inproceedings{davari2022probing,
  title={Probing Representation Forgetting in Supervised and Unsupervised Continual Learning},
  author={Davari, MohammadReza and Asadi, Nader and Mudur, Sudhir and Aljundi, Rahaf and Belilovsky, Eugene},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16712--16721},
  year={2022}
}

@inproceedings{wu2021striking,
  title={Striking a balance between stability and plasticity for class-incremental learning},
  author={Wu, Guile and Gong, Shaogang and Li, Pan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages={1124--1133},
  year={2021}
}

@article{janson2022simple,
  title={A Simple Baseline that Questions the Use of Pretrained-Models in Continual Learning},
  author={Janson, Paul and Zhang, Wenxuan and Aljundi, Rahaf and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2210.04428},
  year={2022}
}

@article{lesort2022scaling,
  title={Scaling the Number of Tasks in Continual Learning},
  author={Lesort, Timoth{\'e}e and Ostapenko, Oleksiy and Misra, Diganta and Arefin, Md Rifat and Rodr{\'\i}guez, Pau and Charlin, Laurent and Rish, Irina},
  journal={arXiv preprint arXiv:2207.04543},
  year={2022}
}

@inproceedings{ostapenko2022continual,
  title={Continual Learning with Foundation Models: An Empirical Study of Latent Replay},
  author={Ostapenko, Oleksiy and Lesort, Timothee and Rodr{\'\i}guez, Pau and Arefin, Md Rifat and Douillard, Arthur and Rish, Irina and Charlin, Laurent},
  booktitle={Conference on Lifelong Learning Agents},
  pages={60--91},
  year={2022},
  organization={PMLR}
}
@techreport{aircraft,
   title         = {Fine-Grained Visual Classification of Aircraft},
   author        = {S. Maji and J. Kannala and E. Rahtu
                    and M. Blaschko and A. Vedaldi},
   year          = {2013},
   archivePrefix = {arXiv},
   eprint        = {1306.5151},
   primaryClass  = "cs-cv",
}
@inproceedings{wang2022learning,
  title={Learning to prompt for continual learning},
  author={Wang, Zifeng and Zhang, Zizhao and Lee, Chen-Yu and Zhang, Han and Sun, Ruoxi and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and Pfister, Tomas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={139--149},
  year={2022}
}

@inproceedings{wang2022dualprompt,
  title={Dualprompt: Complementary prompting for rehearsal-free continual learning},
  author={Wang, Zifeng and Zhang, Zizhao and Ebrahimi, Sayna and Sun, Ruoxi and Zhang, Han and Lee, Chen-Yu and Ren, Xiaoqi and Su, Guolong and Perot, Vincent and Dy, Jennifer and others},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXVI},
  pages={631--648},
  year={2022},
  organization={Springer}
}

@inproceedings{yang2022unified,
  title={Unified contrastive learning in image-text-label space},
  author={Yang, Jianwei and Li, Chunyuan and Zhang, Pengchuan and Xiao, Bin and Liu, Ce and Yuan, Lu and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19163--19173},
  year={2022}
}

@article{li2023ximagenet,
  title={XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness Evaluation},
  author={Li, Qiang and Zhang, Dan and Lei, Shengzhao and Zhao, Xun and Li, Shuyan and Kamnoedboon, Porawit and Li, WeiWei},
  journal={arXiv preprint arXiv:2310.08182},
  year={2023}
}

@inproceedings{zhang2024overcoming,
  title={Overcoming Generic Knowledge Loss with Selective Parameter Update},
  author={Zhang, Wenxuan and Janson, Paul and Aljundi, Rahaf and Elhoseiny, Mohamed},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24046--24056},
  year={2024}
}

@article{meng2022locating,
  title={Locating and editing factual associations in GPT},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022}
}

@article{ilharco2022editing,
  title={Editing models with task arithmetic},
  author={Ilharco, Gabriel and Ribeiro, Marco Tulio and Wortsman, Mitchell and Gururangan, Suchin and Schmidt, Ludwig and Hajishirzi, Hannaneh and Farhadi, Ali},
  journal={arXiv preprint arXiv:2212.04089},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{panos2023first,
  title={First session adaptation: A strong replay-free baseline for class-incremental learning},
  author={Panos, Aristeidis and Kobe, Yuriko and Reino, Daniel Olmeda and Aljundi, Rahaf and Turner, Richard E},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={18820--18830},
  year={2023}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}


@inproceedings{cheng2024edit,
    title = "Can We Edit Multimodal Large Language Models?",
    author = "Cheng, Siyuan  and
      Tian, Bozhong  and
      Liu, Qingbin  and
      Chen, Xi  and
      Wang, Yongheng  and
      Chen, Huajun  and
      Zhang, Ningyu",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.856/",
    doi = "10.18653/v1/2023.emnlp-main.856",
    pages = "13877--13888",
    abstract = "In this paper, we focus on editing multimodal Large Language Models (LLMs). Compared to editing single-modal LLMs, multimodal model editing is more challenging, which demands a higher level of scrutiny and careful consideration in the editing process. To facilitate research in this area, we construct a new benchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite of innovative metrics for evaluation. We conduct comprehensive experiments involving various model editing baselines and analyze the impact of editing different components for multimodal LLMs. Empirically, we notice that previous baselines can implement editing multimodal LLMs to some extent, but the effect is still barely satisfactory, indicating the potential difficulty of this task. We hope that our work can provide the NLP community with insights."
}
@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{hayou2024lora+,
  title={LoRA+: Efficient Low Rank Adaptation of Large Models},
  author={Hayou, Soufiane and Ghosh, Nikhil and Yu, Bin},
  journal={arXiv preprint arXiv:2402.12354},
  year={2024}
}

@article{kopiczko2023vera,
  title={Vera: Vector-based random matrix adaptation},
  author={Kopiczko, Dawid Jan and Blankevoort, Tijmen and Asano, Yuki Markus},
  journal={arXiv preprint arXiv:2310.11454},
  year={2023}
}

@article{zhou2024lora,
  title={LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation},
  author={Zhou, Hongyun and Lu, Xiangyu and Xu, Wang and Zhu, Conghui and Zhao, Tiejun},
  journal={arXiv preprint arXiv:2402.07721},
  year={2024}
}

@inproceedings{zhang2023adaptive,
  title={Adaptive budget allocation for parameter-efficient fine-tuning},
  author={Zhang, Qingru and Chen, Minshuo and Bukharin, Alexander and He, Pengcheng and Cheng, Yu and Chen, Weizhu and Zhao, Tuo},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{liu2024dora,
  title={DoRA: Weight-Decomposed Low-Rank Adaptation},
  author={Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung},
  journal={arXiv preprint arXiv:2402.09353},
  year={2024}
}

@inproceedings{he2023sensitivity,
  title={Sensitivity-aware visual parameter-efficient fine-tuning},
  author={He, Haoyu and Cai, Jianfei and Zhang, Jing and Tao, Dacheng and Zhuang, Bohan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11825--11835},
  year={2023}
}

@misc{liu2024llava,
  title={Llava-next: Improved reasoning, ocr, and world knowledge},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
  year={2024}
}

@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{peng2023kosmos,
  title={Kosmos-2: Grounding multimodal large language models to the world},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Wei, Furu},
  journal={arXiv preprint arXiv:2306.14824},
  year={2023}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@article{chen2023minigpt,
  title={Minigpt-v2: large language model as a unified interface for vision-language multi-task learning},
  author={Chen, Jun and Zhu, Deyao and Shen, Xiaoqian and Li, Xiang and Liu, Zechun and Zhang, Pengchuan and Krishnamoorthi, Raghuraman and Chandra, Vikas and Xiong, Yunyang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2310.09478},
  year={2023}
}

@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{ghosh2024exploring,
  title={Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions},
  author={Ghosh, Akash and Acharya, Arkadeep and Saha, Sriparna and Jain, Vinija and Chadha, Aman},
  journal={arXiv preprint arXiv:2404.07214},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{wang2023knowledge,
  title={Knowledge editing for large language models: A survey},
  author={Wang, Song and Zhu, Yaochen and Liu, Haochen and Zheng, Zaiyi and Chen, Chen and others},
  journal={arXiv preprint arXiv:2310.16218},
  year={2023}
}

@article{wang2023cogvlm,
  title={Cogvlm: Visual expert for pretrained language models},
  author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
  journal={arXiv preprint arXiv:2311.03079},
  year={2023}
}

@article{mayilvahanan2023does,
  title={Does CLIP's Generalization Performance Mainly Stem from High Train-Test Similarity?},
  author={Mayilvahanan, Prasanna and Wiedemer, Thadd{\"a}us and Rusak, Evgenia and Bethge, Matthias and Brendel, Wieland},
  journal={arXiv preprint arXiv:2310.09562},
  year={2023}
}

@inproceedings{das2019toyota,
  title={Toyota smarthome: Real-world activities of daily living},
  author={Das, Srijan and Dai, Rui and Koperski, Michal and Minciullo, Luca and Garattoni, Lorenzo and Bremond, Francois and Francesca, Gianpiero},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={833--842},
  year={2019}
}

@inproceedings{goyal2023finetune,
  title={Finetune like you pretrain: Improved finetuning of zero-shot vision models},
  author={Goyal, Sachin and Kumar, Ananya and Garg, Sankalp and Kolter, Zico and Raghunathan, Aditi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19338--19347},
  year={2023}
}

@article{sun2023eva,
  title={Eva-clip: Improved training techniques for clip at scale},
  author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.15389},
  year={2023}
}

@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  volume={2},
  number={3},
  pages={6},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@inproceedings{gurari2018vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3608--3617},
  year={2018}
}

@article{liu2023visual,
  title={Visual spatial reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={635--651},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{kiela2020hateful,
  title={The hateful memes challenge: Detecting hate speech in multimodal memes},
  author={Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={2611--2624},
  year={2020}
}

@article{stallkamp2012man,
  title={Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition},
  author={Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian},
  journal={Neural networks},
  volume={32},
  pages={323--332},
  year={2012},
  publisher={Elsevier}
}

@inproceedings{imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Image{N}et: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}}

@article{de2021continual,
  title={A continual learning survey: Defying forgetting in classification tasks},
  author={De Lange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ale{\v{s}} and Slabaugh, Gregory and Tuytelaars, Tinne},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={7},
  pages={3366--3385},
  year={2021},
  publisher={IEEE}
}

@article{lopez2017gradient,
  title={Gradient episodic memory for continual learning},
  author={Lopez-Paz, David and Ranzato, Marc'Aurelio},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{duan2024vlmevalkit,
  title={Vlmevalkit: An open-source toolkit for evaluating large multi-modality models},
  author={Duan, Haodong and Yang, Junming and Qiao, Yuxuan and Fang, Xinyu and Chen, Lin and Liu, Yuan and Dong, Xiaoyi and Zang, Yuhang and Zhang, Pan and Wang, Jiaqi and others},
  booktitle={Proceedings of the 32nd ACM International Conference on Multimedia},
  pages={11198--11201},
  year={2024}
}

@article{Liu2022VisualSR,
  title={Visual Spatial Reasoning},
  author={Fangyu Liu and Guy Edward Toh Emerson and Nigel Collier},
  journal={Transactions of the Association for Computational Linguistics},
  year={2023},
}

@inproceedings{tong2024eyes,
  title={Eyes wide shut? exploring the visual shortcomings of multimodal llms},
  author={Tong, Shengbang and Liu, Zhuang and Zhai, Yuexiang and Ma, Yi and LeCun, Yann and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9568--9578},
  year={2024}
}

@article{kamoi2024visonlyqa,
  title={VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information},
  author={Kamoi, Ryo and Zhang, Yusen and Das, Sarkar Snigdha Sarathi and Zhang, Ranran Haoran and Zhang, Rui},
  journal={arXiv preprint arXiv:2412.00947},
  year={2024}
}

@article{helber2019eurosat,
  title={Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification},
  author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year={2019},
  publisher={IEEE}
}

@article{zhang2023adalora,
  title={AdaLoRA: Adaptive budget allocation for parameter-efficient fine-tuning},
  author={Zhang, Qingru and Chen, Minshuo and Bukharin, Alexander and Karampatziakis, Nikos and He, Pengcheng and Cheng, Yu and Chen, Weizhu and Zhao, Tuo},
  journal={arXiv preprint arXiv:2303.10512},
  year={2023}
}
@article{wu2024continual,
  title={Continual learning for large language models: A survey},
  author={Wu, Tongtong and Luo, Linhao and Li, Yuan-Fang and Pan, Shirui and Vu, Thuy-Trang and Haffari, Gholamreza},
  journal={arXiv preprint arXiv:2402.01364},
  year={2024}
}
@article{zhao2024safe,
  title={SAFE: Slow and Fast Parameter-Efficient Tuning for Continual Learning with Pre-Trained Models},
  author={Zhao, Linglan and Zhang, Xuerui and Yan, Ke and Ding, Shouhong and Huang, Weiran},
  journal={arXiv preprint arXiv:2411.02175},
  year={2024}
}
@inproceedings{goswami2024calibrating,
  title={Calibrating Higher-Order Statistics for Few-Shot Class-Incremental Learning with Pre-trained Vision Transformers},
  author={Goswami, Dipam and Twardowski, Bart{\l}omiej and Van De Weijer, Joost},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4075--4084},
  year={2024}
}
@inproceedings{
mitchell2022fast,
title={Fast Model Editing at Scale},
author={Eric Mitchell and Charles Lin and Antoine Bosselut and Chelsea Finn and Christopher D Manning},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=0DcZxeWfOPt}
}


@article{verwimp2023continual,
  title={Continual learning: Applications and the road forward},
  author={Verwimp, Eli and Aljundi, Rahaf and Ben-David, Shai and Bethge, Matthias and Cossu, Andrea and Gepperth, Alexander and Hayes, Tyler L and H{\"u}llermeier, Eyke and Kanan, Christopher and Kudithipudi, Dhireesha and others},
  journal={arXiv preprint arXiv:2311.11908},
  year={2023}
}
@article{srivastava2024improving,
  title={Improving multimodal large language models using continual learning},
  author={Srivastava, Shikhar and Harun, Md Yousuf and Shrestha, Robik and Kanan, Christopher},
  journal={arXiv preprint arXiv:2410.19925},
  year={2024}
}
@article{das2024one,
  title={One VLM to Keep it Learning: Generation and Balancing for Data-free Continual Visual Question Answering},
  author={Das, Deepayan and Talon, Davide and Mancini, Massimiliano and Wang, Yiming and Ricci, Elisa},
  journal={arXiv preprint arXiv:2411.02210},
  year={2024}
}
@article{he2023continual,
  title={Continual instruction tuning for large multimodal models},
  author={He, Jinghan and Guo, Haiyun and Tang, Ming and Wang, Jinqiao},
  journal={arXiv preprint arXiv:2311.16206},
  year={2023}
}

@inproceedings{
Sinitsin2020Editable,
title={Editable Neural Networks},
author={Anton Sinitsin and Vsevolod Plokhotnyuk and Dmitry Pyrkin and Sergei Popov and Artem Babenko},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJedXaEtvS}
}
@article{dai2021knowledge,
  title={Knowledge neurons in pretrained transformers},
  author={Dai, Damai and Dong, Li and Hao, Yaru and Sui, Zhifang and Chang, Baobao and Wei, Furu},
  journal={arXiv preprint arXiv:2104.08696},
  year={2021}
}