
\begin{table}
\caption{Comparison of the importance of choosing a small subset of attention heads. \emph{LoRSU-RAND-V-CLIP} randomly chooses 2 heads to fine-tune, \emph{LoRSU-F} fine-tunes all the available heads, and our baseline \emph{LoRSU} that chooses the top-2 attentions heads. We report the accuracy scores (\%) for LLaVA with the pretrained or fine-tuned CLIP CLIP-L-14. All baselines use \textbf{GTS} dataset for fine-tuning the vision encoder(the LLM remains frozen). We include error bars over 3 runs.}
 \label{table:lorsu_attn_gtsrb_clip}
\begin{center}
\begin{small}
\begingroup
\setlength{\tabcolsep}{2.0pt}
\begin{tabular}{l c c c c c c c c c c c}
\toprule
 & & \multicolumn{9}{c}{\textbf{VQA Datasets (Acc \%)}}  \\
\cmidrule(lr){3-12}
\textbf{Setting} & \textbf{FT Method}  & \textbf{GTS} & \textbf{TSI} & \textbf{CAn} & \textbf{AIR} & \textbf{ESAT} & \textbf{DALLE} & \textbf{VSR} & \textbf{HM} & \textbf{MMVP} & \textbf{VisOnly} \\
\midrule
 & \textbf{Zr-Shot} & $75.6$ & $53.1$ & $82.7$ & $60.4$ & $76.1$ & $91.1$ & $51.5$ & $61.2$ & $58.0$ & $31.3$ \\
\midrule
\multirow{3}{*}{\textbf{CL-5}} & \textbf{LoRSU-Rand} & $81.2 \mtiny{\pm 1.2}$ & $53.5 \mtiny{\pm 0.5}$ & $82.2 \mtiny{\pm 0.6}$ & $61.2 \mtiny{\pm 1.2}$ & $65.0 \mtiny{\pm 0.9}$ & $90.4 \mtiny{\pm 1.3}$ & $51.8 \mtiny{\pm 1.5}$ & $61.7 \mtiny{\pm 1.1}$ & $58.2 \mtiny{\pm 0.2}$ & $32.1 \mtiny{\pm 0.4}$ \\
& \textbf{LoRSU-F} & $82.3 \mtiny{\pm 0.6}$ & $53.3 \mtiny{\pm 0.8}$ & $82.2 \mtiny{\pm 1.3}$ & $60.9 \mtiny{\pm 1.0}$ & $65.7 \mtiny{\pm 0.9}$ & $91.1 \mtiny{\pm 1.2}$ & $51.6 \mtiny{\pm 0.9}$ & $61.9 \mtiny{\pm 0.8}$ & $58.4 \mtiny{\pm 0.4}$ & $31.2 \mtiny{\pm 0.2}$ \\
& \textbf{LoRSU} & $81.8 \mtiny{\pm 0.6}$ & $53.4 \mtiny{\pm 1.3}$ & $82.6 \mtiny{\pm 0.7}$ & $61.0 \mtiny{\pm 1.4}$ & $66.6 \mtiny{\pm 1.4}$ & $91.4 \mtiny{\pm 1.1}$ & $51.7 \mtiny{\pm 1.4}$ & $61.6 \mtiny{\pm 0.6}$ & $59.8 \mtiny{\pm 0.4}$ & $31.4 \mtiny{\pm 0.4}$ \\
\midrule
\multirow{3}{*}{\textbf{CL-20}} & \textbf{LoRSU-Rand} & $83.1 \mtiny{\pm 0.5}$ & $53.4 \mtiny{\pm 0.9}$ & $82.6 \mtiny{\pm 0.3}$ & $60.8 \mtiny{\pm 0.8}$ & $61.2 \mtiny{\pm 0.5}$ & $90.5 \mtiny{\pm 0.9}$ & $51.7 \mtiny{\pm 0.8}$ & $61.7 \mtiny{\pm 0.8}$ & $59.4 \mtiny{\pm 0.2}$ & $32.2 \mtiny{\pm 0.2}$ \\
& \textbf{LoRSU-F} & $84.4 \mtiny{\pm 0.6}$ & $53.6 \mtiny{\pm 0.4}$ & $82.3 \mtiny{\pm 0.6}$ & $60.3 \mtiny{\pm 0.5}$ & $60.1 \mtiny{\pm 0.5}$ & $91.4 \mtiny{\pm 0.7}$ & $52.0 \mtiny{\pm 0.5}$ & $61.3 \mtiny{\pm 0.8}$ & $59.1 \mtiny{\pm 0.2}$ & $32.0 \mtiny{\pm 0.1}$ \\
& \textbf{LoRSU} & $84.3 \mtiny{\pm 0.9}$ & $53.2 \mtiny{\pm 1.0}$ & $82.4 \mtiny{\pm 0.4}$ & $60.7 \mtiny{\pm 0.6}$ & $64.5 \mtiny{\pm 0.4}$ & $90.8 \mtiny{\pm 0.8}$ & $52.0 \mtiny{\pm 0.4}$ & $62.1 \mtiny{\pm 0.9}$ & $59.5 \mtiny{\pm 0.2}$ & $31.7 \mtiny{\pm 0.1}$ \\
\midrule
\multirow{3}{*}{\textbf{CL-50}} & \textbf{LoRSU-Rand} & $84.5 \mtiny{\pm 0.3}$ & $54.2 \mtiny{\pm 0.3}$ & $81.8 \mtiny{\pm 0.1}$ & $60.8 \mtiny{\pm 0.4}$ & $57.2 \mtiny{\pm 0.2}$ & $90.9 \mtiny{\pm 0.4}$ & $51.7 \mtiny{\pm 0.1}$ & $61.3 \mtiny{\pm 0.4}$ & $60.4 \mtiny{\pm 0.0}$ & $31.9 \mtiny{\pm 0.0}$ \\
& \textbf{LoRSU-All} & $85.6 \mtiny{\pm 0.2}$ & $53.8 \mtiny{\pm 0.2}$ & $81.2 \mtiny{\pm 0.4}$ & $60.5 \mtiny{\pm 0.1}$ & $59.0 \mtiny{\pm 0.2}$ & $90.4 \mtiny{\pm 0.4}$ & $51.7 \mtiny{\pm 0.2}$ & $61.6 \mtiny{\pm 0.0}$ & $58.2 \mtiny{\pm 0.0}$ & $31.7 \mtiny{\pm 0.1}$ \\
& \textbf{LoRSU} & $85.2 \mtiny{\pm 0.3}$ & $53.8 \mtiny{\pm 0.2}$ & $81.8 \mtiny{\pm 0.3}$ & $60.8 \mtiny{\pm 0.4}$ & $61.6 \mtiny{\pm 0.2}$ & $90.9 \mtiny{\pm 0.1}$ & $51.9 \mtiny{\pm 0.3}$ & $62.1 \mtiny{\pm 0.4}$ & $59.0 \mtiny{\pm 0.1}$ & $31.7 \mtiny{\pm 0.1}$ \\
\bottomrule
\end{tabular}
\endgroup
\end{small}
\end{center}
\end{table}




\begin{table}
\caption{Comparison of the importance of choosing a small subset of attention heads. \emph{LoRSU-RAND-V-CLIP} randomly chooses 2 heads to fine-tune, \emph{LoRSU-F} fine-tunes all the available heads, and our baseline \emph{LoRSU} that chooses the top-2 attentions heads. We report the accuracy scores (\%) for LLaVA with the pretrained or fine-tuned CLIP CLIP-L-14. All baselines use \textbf{TSI} dataset for fine-tuning the vision encoder(the LLM remains frozen). We include error bars over 3 runs.}
 \label{table:lorsu_attn_tsi_clip}
\begin{center}
\begin{small}
\begingroup
\setlength{\tabcolsep}{2.0pt}
\begin{tabular}{l c c c c c c c c c c c}
\toprule
 & & \multicolumn{9}{c}{\textbf{VQA Datasets (Acc \%)}}  \\
\cmidrule(lr){3-12}
\textbf{Setting} & \textbf{FT Method}  & \textbf{GTS} & \textbf{TSI} & \textbf{CAn} & \textbf{AIR} & \textbf{ESAT} & \textbf{DALLE} & \textbf{VSR} & \textbf{HM} & \textbf{MMVP} & \textbf{VisOnly} \\
\midrule
 & \textbf{Zr-Shot} & $75.6$ & $53.1$ & $82.7$ & $60.4$ & $76.1$ & $91.1$ & $51.5$ & $61.2$ & $58.0$ & $31.3$ \\
\midrule
\multirow{3}{*}{\textbf{CL-5}} & \textbf{LoRSU-Rand} & $74.8 \mtiny{\pm 1.4}$ & $55.0 \mtiny{\pm 1.3}$ & $82.9 \mtiny{\pm 0.6}$ & $60.2 \mtiny{\pm 0.6}$ & $75.7 \mtiny{\pm 1.3}$ & $91.5 \mtiny{\pm 1.2}$ & $51.6 \mtiny{\pm 1.1}$ & $62.0 \mtiny{\pm 1.2}$ & $58.2 \mtiny{\pm 0.3}$ & $31.5 \mtiny{\pm 0.4}$ \\
& \textbf{LoRSU-F} & $75.8 \mtiny{\pm 1.3}$ & $55.7 \mtiny{\pm 0.5}$ & $83.1 \mtiny{\pm 1.4}$ & $60.5 \mtiny{\pm 0.6}$ & $75.8 \mtiny{\pm 1.0}$ & $91.6 \mtiny{\pm 1.3}$ & $51.9 \mtiny{\pm 0.8}$ & $61.7 \mtiny{\pm 1.5}$ & $57.7 \mtiny{\pm 0.4}$ & $31.9 \mtiny{\pm 0.3}$ \\
& \textbf{LoRSU} & $75.6 \mtiny{\pm 1.3}$ & $56.6 \mtiny{\pm 0.8}$ & $82.4 \mtiny{\pm 1.4}$ & $60.5 \mtiny{\pm 0.7}$ & $76.1 \mtiny{\pm 0.7}$ & $91.4 \mtiny{\pm 1.4}$ & $51.5 \mtiny{\pm 0.8}$ & $61.8 \mtiny{\pm 0.9}$ & $57.7 \mtiny{\pm 0.3}$ & $31.2 \mtiny{\pm 0.4}$ \\
\midrule
\multirow{3}{*}{\textbf{CL-20}} & \textbf{LoRSU-Rand} & $75.4 \mtiny{\pm 0.6}$ & $62.0 \mtiny{\pm 0.6}$ & $81.9 \mtiny{\pm 0.7}$ & $59.1 \mtiny{\pm 0.8}$ & $73.5 \mtiny{\pm 0.4}$ & $90.6 \mtiny{\pm 0.4}$ & $51.9 \mtiny{\pm 0.5}$ & $62.1 \mtiny{\pm 0.7}$ & $58.1 \mtiny{\pm 0.2}$ & $31.4 \mtiny{\pm 0.2}$ \\
& \textbf{LoRSU-F} & $75.2 \mtiny{\pm 0.9}$ & $63.1 \mtiny{\pm 0.6}$ & $82.9 \mtiny{\pm 0.5}$ & $59.9 \mtiny{\pm 0.6}$ & $70.8 \mtiny{\pm 0.6}$ & $91.1 \mtiny{\pm 0.5}$ & $51.9 \mtiny{\pm 0.4}$ & $61.7 \mtiny{\pm 0.5}$ & $58.1 \mtiny{\pm 0.1}$ & $31.4 \mtiny{\pm 0.2}$ \\
& \textbf{LoRSU} & $75.6 \mtiny{\pm 0.6}$ & $63.7 \mtiny{\pm 0.5}$ & $82.9 \mtiny{\pm 0.4}$ & $60.5 \mtiny{\pm 0.4}$ & $73.4 \mtiny{\pm 0.8}$ & $90.7 \mtiny{\pm 0.5}$ & $51.7 \mtiny{\pm 0.4}$ & $61.6 \mtiny{\pm 0.9}$ & $58.7 \mtiny{\pm 0.2}$ & $32.2 \mtiny{\pm 0.3}$ \\
\midrule
\multirow{3}{*}{\textbf{CL-50}} & \textbf{LoRSU-Rand} & $75.4 \mtiny{\pm 0.1}$ & $66.8 \mtiny{\pm 0.2}$ & $82.2 \mtiny{\pm 0.2}$ & $59.2 \mtiny{\pm 0.3}$ & $71.7 \mtiny{\pm 0.0}$ & $90.6 \mtiny{\pm 0.2}$ & $51.9 \mtiny{\pm 0.1}$ & $61.7 \mtiny{\pm 0.1}$ & $58.3 \mtiny{\pm 0.1}$ & $31.8 \mtiny{\pm 0.1}$ \\
& \textbf{LoRSU-F} & $74.8 \mtiny{\pm 0.2}$ & $66.5 \mtiny{\pm 0.4}$ & $82.3 \mtiny{\pm 0.4}$ & $59.6 \mtiny{\pm 0.0}$ & $73.5 \mtiny{\pm 0.3}$ & $90.9 \mtiny{\pm 0.1}$ & $51.9 \mtiny{\pm 0.0}$ & $62.1 \mtiny{\pm 0.1}$ & $58.9 \mtiny{\pm 0.0}$ & $31.5 \mtiny{\pm 0.1}$ \\
& \textbf{LoRSU} & $75.7 \mtiny{\pm 0.0}$ & $72.5 \mtiny{\pm 0.0}$ & $82.0 \mtiny{\pm 0.2}$ & $59.4 \mtiny{\pm 0.1}$ & $72.4 \mtiny{\pm 0.2}$ & $90.5 \mtiny{\pm 0.3}$ & $51.7 \mtiny{\pm 0.3}$ & $61.4 \mtiny{\pm 0.2}$ & $58.3 \mtiny{\pm 0.1}$ & $31.7 \mtiny{\pm 0.0}$ \\
\bottomrule
\end{tabular}
\endgroup
\end{small}
\end{center}
\end{table}


\begin{table}
\caption{Comparison of the importance of choosing a small subset of attention heads. \emph{LoRSU-RAND-V-CLIP} randomly chooses 2 heads to fine-tune, \emph{LoRSU-F} fine-tunes all the available heads, and our baseline \emph{LoRSU} that chooses the top-2 attentions heads. We report the accuracy scores (\%) for LLaVA with the pretrained or fine-tuned CLIP CLIP-L-14. All baselines use \textbf{AIR} dataset for fine-tuning the vision encoder(the LLM remains frozen). We include error bars over 3 runs.}
 \label{table:lorsu_attn_aircraft_clip}
\begin{center}
\begin{small}
\begingroup
\setlength{\tabcolsep}{2.0pt}
\begin{tabular}{l c c c c c c c c c c c}
\toprule
 & & \multicolumn{9}{c}{\textbf{VQA Datasets (Acc \%)}}  \\
\cmidrule(lr){3-12}
\textbf{Setting} & \textbf{FT Method}  & \textbf{GTS} & \textbf{TSI} & \textbf{CAn} & \textbf{AIR} & \textbf{ESAT} & \textbf{DALLE} & \textbf{VSR} & \textbf{HM} & \textbf{MMVP} & \textbf{VisOnly} \\
\midrule
 & \textbf{Zr-Shot} & $75.6$ & $53.1$ & $82.7$ & $60.4$ & $76.1$ & $91.1$ & $51.5$ & $61.2$ & $58.0$ & $31.3$ \\
\midrule
\multirow{3}{*}{\textbf{CL-5}} & \textbf{LoRSU-Rand} & $75.0 \mtiny{\pm 1.5}$ & $53.4 \mtiny{\pm 0.6}$ & $82.3 \mtiny{\pm 0.9}$ & $63.6 \mtiny{\pm 0.7}$ & $73.5 \mtiny{\pm 0.9}$ & $91.9 \mtiny{\pm 1.0}$ & $51.5 \mtiny{\pm 0.9}$ & $62.1 \mtiny{\pm 1.2}$ & $58.8 \mtiny{\pm 0.3}$ & $31.9 \mtiny{\pm 0.3}$ \\
& \textbf{LoRSU-F} & $75.7 \mtiny{\pm 1.2}$ & $53.1 \mtiny{\pm 0.9}$ & $82.8 \mtiny{\pm 1.0}$ & $65.0 \mtiny{\pm 1.5}$ & $75.0 \mtiny{\pm 0.6}$ & $91.6 \mtiny{\pm 1.1}$ & $51.7 \mtiny{\pm 1.5}$ & $61.8 \mtiny{\pm 0.7}$ & $57.5 \mtiny{\pm 0.4}$ & $31.6 \mtiny{\pm 0.4}$ \\
& \textbf{LoRSU} & $76.1 \mtiny{\pm 0.8}$ & $53.4 \mtiny{\pm 0.8}$ & $82.8 \mtiny{\pm 0.9}$ & $65.1 \mtiny{\pm 0.9}$ & $75.9 \mtiny{\pm 1.4}$ & $91.6 \mtiny{\pm 0.6}$ & $51.6 \mtiny{\pm 0.9}$ & $62.1 \mtiny{\pm 1.5}$ & $58.9 \mtiny{\pm 0.4}$ & $31.6 \mtiny{\pm 0.4}$ \\
\midrule
\multirow{3}{*}{\textbf{CL-20}} & \textbf{LoRSU-Rand} & $74.1 \mtiny{\pm 0.6}$ & $53.0 \mtiny{\pm 0.3}$ & $81.3 \mtiny{\pm 0.8}$ & $64.3 \mtiny{\pm 0.7}$ & $73.0 \mtiny{\pm 0.5}$ & $91.1 \mtiny{\pm 0.8}$ & $51.6 \mtiny{\pm 0.9}$ & $62.1 \mtiny{\pm 0.7}$ & $57.0 \mtiny{\pm 0.2}$ & $31.3 \mtiny{\pm 0.2}$ \\
& \textbf{LoRSU-F} & $75.3 \mtiny{\pm 0.3}$ & $53.9 \mtiny{\pm 0.7}$ & $81.5 \mtiny{\pm 0.6}$ & $64.9 \mtiny{\pm 1.0}$ & $74.6 \mtiny{\pm 0.6}$ & $91.6 \mtiny{\pm 0.8}$ & $51.8 \mtiny{\pm 0.6}$ & $62.1 \mtiny{\pm 0.9}$ & $59.6 \mtiny{\pm 0.1}$ & $31.6 \mtiny{\pm 0.2}$ \\
& \textbf{LoRSU} & $76.1 \mtiny{\pm 0.7}$ & $53.0 \mtiny{\pm 0.7}$ & $81.3 \mtiny{\pm 0.7}$ & $66.2 \mtiny{\pm 0.6}$ & $74.8 \mtiny{\pm 0.8}$ & $91.3 \mtiny{\pm 0.9}$ & $51.8 \mtiny{\pm 0.6}$ & $62.1 \mtiny{\pm 0.9}$ & $56.8 \mtiny{\pm 0.3}$ & $31.8 \mtiny{\pm 0.2}$ \\
\midrule
\multirow{3}{*}{\textbf{CL-50}} & \textbf{LoRSU-Rand} & $74.5 \mtiny{\pm 0.2}$ & $52.7 \mtiny{\pm 0.2}$ & $80.2 \mtiny{\pm 0.0}$ & $67.6 \mtiny{\pm 0.1}$ & $71.3 \mtiny{\pm 0.4}$ & $91.0 \mtiny{\pm 0.2}$ & $51.5 \mtiny{\pm 0.3}$ & $62.2 \mtiny{\pm 0.4}$ & $57.4 \mtiny{\pm 0.1}$ & $31.4 \mtiny{\pm 0.1}$ \\
& \textbf{LoRSU-F} & $75.1 \mtiny{\pm 0.1}$ & $52.6 \mtiny{\pm 0.1}$ & $81.3 \mtiny{\pm 0.2}$ & $69.7 \mtiny{\pm 0.3}$ & $71.6 \mtiny{\pm 0.3}$ & $91.4 \mtiny{\pm 0.3}$ & $51.7 \mtiny{\pm 0.2}$ & $61.7 \mtiny{\pm 0.2}$ & $58.2 \mtiny{\pm 0.1}$ & $31.6 \mtiny{\pm 0.0}$ \\
& \textbf{LoRSU} & $75.4 \mtiny{\pm 0.1}$ & $52.5 \mtiny{\pm 0.2}$ & $81.6 \mtiny{\pm 0.3}$ & $68.5 \mtiny{\pm 0.1}$ & $72.8 \mtiny{\pm 0.4}$ & $91.1 \mtiny{\pm 0.3}$ & $51.9 \mtiny{\pm 0.4}$ & $62.2 \mtiny{\pm 0.2}$ & $59.2 \mtiny{\pm 0.1}$ & $31.0 \mtiny{\pm 0.1}$ \\
\bottomrule
\end{tabular}
\endgroup
\end{small}
\end{center}
\end{table}


\begin{table}
\caption{Comparison of the importance of choosing a small subset of attention heads. \emph{LoRSU-RAND-V-CLIP} randomly chooses 2 heads to fine-tune, \emph{LoRSU-F} fine-tunes all the available heads, and our baseline \emph{LoRSU} that chooses the top-2 attentions heads. We report the accuracy scores (\%) for LLaVA with the pretrained or fine-tuned CLIP CLIP-L-14. All baselines use \textbf{ESAT} dataset for fine-tuning the vision encoder(the LLM remains frozen). We include error bars over 3 runs.}
 \label{table:lorsu_attn_eurosat_clip}
\begin{center}
\begin{small}
\begingroup
\setlength{\tabcolsep}{2.0pt}
\begin{tabular}{l c c c c c c c c c c c}
\toprule
 & & \multicolumn{9}{c}{\textbf{VQA Datasets (Acc \%)}}  \\
\cmidrule(lr){3-12}
\textbf{Setting} & \textbf{FT Method}  & \textbf{GTS} & \textbf{TSI} & \textbf{CAn} & \textbf{AIR} & \textbf{ESAT} & \textbf{DALLE} & \textbf{VSR} & \textbf{HM} & \textbf{MMVP} & \textbf{VisOnly} \\
\midrule
 & \textbf{Zr-Shot} & $75.6$ & $53.1$ & $82.7$ & $60.4$ & $76.1$ & $91.1$ & $51.5$ & $61.2$ & $58.0$ & $31.3$ \\
\midrule
\multirow{3}{*}{\textbf{CL-5}} & \textbf{LoRSU-Rand} & $76.4 \mtiny{\pm 0.9}$ & $53.3 \mtiny{\pm 0.7}$ & $82.6 \mtiny{\pm 0.9}$ & $60.9 \mtiny{\pm 1.0}$ & $81.4 \mtiny{\pm 1.4}$ & $91.6 \mtiny{\pm 1.2}$ & $51.6 \mtiny{\pm 0.9}$ & $61.3 \mtiny{\pm 0.8}$ & $58.4 \mtiny{\pm 0.3}$ & $31.4 \mtiny{\pm 0.3}$ \\
& \textbf{LoRSU-F} & $76.3 \mtiny{\pm 0.8}$ & $53.5 \mtiny{\pm 0.8}$ & $82.4 \mtiny{\pm 1.4}$ & $60.9 \mtiny{\pm 0.7}$ & $82.8 \mtiny{\pm 1.4}$ & $91.9 \mtiny{\pm 1.2}$ & $51.5 \mtiny{\pm 1.2}$ & $61.2 \mtiny{\pm 0.8}$ & $57.6 \mtiny{\pm 0.4}$ & $31.4 \mtiny{\pm 0.3}$ \\
& \textbf{LoRSU} & $76.2 \mtiny{\pm 1.0}$ & $53.6 \mtiny{\pm 0.6}$ & $82.4 \mtiny{\pm 1.0}$ & $60.9 \mtiny{\pm 0.6}$ & $82.8 \mtiny{\pm 1.2}$ & $91.5 \mtiny{\pm 0.5}$ & $51.7 \mtiny{\pm 0.9}$ & $61.6 \mtiny{\pm 0.7}$ & $57.6 \mtiny{\pm 0.3}$ & $31.7 \mtiny{\pm 0.4}$ \\
\midrule
\multirow{3}{*}{\textbf{CL-20}} & \textbf{LoRSU-Rand} & $75.6 \mtiny{\pm 0.6}$ & $52.9 \mtiny{\pm 0.6}$ & $82.7 \mtiny{\pm 0.7}$ & $60.6 \mtiny{\pm 0.6}$ & $82.3 \mtiny{\pm 0.6}$ & $91.6 \mtiny{\pm 0.7}$ & $51.7 \mtiny{\pm 0.7}$ & $61.7 \mtiny{\pm 0.8}$ & $58.3 \mtiny{\pm 0.3}$ & $31.7 \mtiny{\pm 0.1}$ \\
& \textbf{LoRSU-F} & $75.6 \mtiny{\pm 0.7}$ & $53.3 \mtiny{\pm 0.3}$ & $82.8 \mtiny{\pm 0.9}$ & $60.4 \mtiny{\pm 0.7}$ & $83.1 \mtiny{\pm 0.6}$ & $92.0 \mtiny{\pm 0.8}$ & $51.7 \mtiny{\pm 0.3}$ & $61.3 \mtiny{\pm 0.6}$ & $59.1 \mtiny{\pm 0.3}$ & $31.4 \mtiny{\pm 0.3}$ \\
& \textbf{LoRSU} & $75.2 \mtiny{\pm 0.5}$ & $53.4 \mtiny{\pm 0.4}$ & $83.0 \mtiny{\pm 0.5}$ & $60.7 \mtiny{\pm 0.8}$ & $82.7 \mtiny{\pm 0.7}$ & $91.6 \mtiny{\pm 0.3}$ & $51.9 \mtiny{\pm 0.9}$ & $61.6 \mtiny{\pm 0.4}$ & $58.4 \mtiny{\pm 0.1}$ & $31.3 \mtiny{\pm 0.3}$ \\
\midrule
\multirow{3}{*}{\textbf{CL-50}} & \textbf{LoRSU-Rand} & $75.7 \mtiny{\pm 0.3}$ & $53.7 \mtiny{\pm 0.3}$ & $82.9 \mtiny{\pm 0.1}$ & $60.0 \mtiny{\pm 0.1}$ & $81.4 \mtiny{\pm 0.4}$ & $92.0 \mtiny{\pm 0.2}$ & $51.7 \mtiny{\pm 0.3}$ & $61.7 \mtiny{\pm 0.3}$ & $58.8 \mtiny{\pm 0.1}$ & $31.6 \mtiny{\pm 0.1}$ \\
& \textbf{LoRSU-F} & $75.7 \mtiny{\pm 0.2}$ & $53.5 \mtiny{\pm 0.1}$ & $82.4 \mtiny{\pm 0.3}$ & $60.3 \mtiny{\pm 0.0}$ & $80.9 \mtiny{\pm 0.2}$ & $92.1 \mtiny{\pm 0.2}$ & $51.7 \mtiny{\pm 0.1}$ & $61.5 \mtiny{\pm 0.3}$ & $57.4 \mtiny{\pm 0.1}$ & $31.2 \mtiny{\pm 0.0}$ \\
& \textbf{LoRSU} & $75.4 \mtiny{\pm 0.2}$ & $53.8 \mtiny{\pm 0.2}$ & $83.0 \mtiny{\pm 0.3}$ & $60.0 \mtiny{\pm 0.4}$ & $82.9 \mtiny{\pm 0.4}$ & $92.1 \mtiny{\pm 0.4}$ & $51.9 \mtiny{\pm 0.0}$ & $61.4 \mtiny{\pm 0.0}$ & $57.5 \mtiny{\pm 0.1}$ & $31.3 \mtiny{\pm 0.1}$ \\
\bottomrule
\end{tabular}
\endgroup
\end{small}
\end{center}
\end{table}