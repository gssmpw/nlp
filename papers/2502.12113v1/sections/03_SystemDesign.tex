\section{System Design}
\label{sec:system_design}

\begin{figure}
    \centering
    \input{media/Fig_CoordinateSystems}
    \caption{Definition of the camera frame ($z_\cfr$ is aligned with the optical axis), the body frame $\bfr$ and the world frame $\wfr$. The position of the active markers is defined in body-frame and must be known. The transform $T_{\cfr \bfr}$ is estimated through PnP and the pose of the camera in the world frame is assumed to be known.}
    \label{fig:coordinate_systems}
\end{figure}

This section gives a brief overview of the developed monocular event-camera motion-capture system. Details regarding the implementation of the blinking LED detection are given in Sec.~\ref{sec:implementation_details}. The blinking LED circuit itself is discussed in Sec.~\ref{sec:blinked_led_circuit}.

\subsection{Prerequisites}
In order to obtain accurate 3D pose estimation of the tracked objects, the event-camera must be calibrated and the location of the blinking LEDs must be known. Furthermore, the transform $T_{\mathcal{CW}}$ between the camera frame $\mathcal{C}$ and the world frame $\mathcal{W}$ must be known. The coordinate systems are illustrated in Fig.~\ref{fig:coordinate_systems}.

To calibrate the camera, we follow the approach from~\cite{muglikar2021calibrate} where the calibration is performed by first converting the event stream into event frames and then calibrating these using Kalibr~\cite{rehder2016extending}. The calibration also estimates the lens distortion and in this work we rely on a double-sphere distortion model because of its accuracy and computation efficiency~\cite{usenko2018doublesphere}. The event-camera is mounted horizontally on a stable tripod such that the transform from camera-frame $\mathcal{C}$ to world-frame $\mathcal{W}$ is fixed and known.

To ensure that the locations of the blinking LEDs are known and fixed, a 3D-printed LED holder is used. The locations of the LEDs are then directly known from the CAD model. The blinking frequency of each LED is also known, see Sec.~\ref{sec:blinked_led_circuit} for details on the circuit design.

\subsection{LED detection}
Robustly detecting blinking LEDs in an event-stream in real-time is the critical component of the motion-capture system. Events are processed in batches between \unit[1]{ms} (\unit[1]{kHz}) and \unit[2.5]{ms} (\unit[400]{Hz}), depending on the desired pose update rate. In a first step, all pixels whose event rate is below a threshold are discarded. The threshold is calculated based on the assumption that each LED period at least triggers two events and that a transition is detected with a given probability (e.g. \unit[80]{\%}).

For all pixels with a sufficient event rate, the average period and standard deviation is calculated. For details on this process, see Sec.~\ref{sec:implementation_details}. After identifying the average period, neighboring pixels with similar periods are clustered together. If the average period of the cluster is closer than $\unit[25]{\mu s}$ to one of the expected blinking frequencies from the LED, it is matched to that LED. The centroid of each LED is tracked with a constant-velocity particle filter.

\subsection{Pose Estimation}
To estimate the pose from the detected LED centroids, the centroids are undistorted first. Then, the PnP-problem is solved with SQPnP~\cite{terzakis2020sqpnp}. We chose this algorithm over other well-known algorithms such as EPnP~\cite{lepetit2009epnp} because SQPnP is fast enough and globally optimal~\cite{terzakis2020sqpnp}. 

The pose-estimate in the camera-frame is finally transformed into the world-frame and published via ROS. 