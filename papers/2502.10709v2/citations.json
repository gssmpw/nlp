[
  {
    "index": 0,
    "papers": [
      {
        "key": "chang2024survey",
        "author": "Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others",
        "title": "A survey on evaluation of large language models"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "zellers2019hellaswag",
        "author": "Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin",
        "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "liang2022holistic",
        "author": "Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others",
        "title": "Holistic evaluation of language models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "hendrycks2020measuring",
        "author": "Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob",
        "title": "Measuring massive multitask language understanding"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "hendrycks2measuring",
        "author": "Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob",
        "title": "Measuring Mathematical Problem Solving With the MATH Dataset"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "xu2023tool",
        "author": "Qiantong Xu and Fenglu Hong and Bo Li and Changran Hu and Zhengyu Chen and Jian Zhang",
        "title": "On the Tool Manipulation Capability of Open-source Large Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "orenproving",
        "author": "Oren, Yonatan and Meister, Nicole and Chatterji, Niladri S and Ladhak, Faisal and Hashimoto, Tatsunori",
        "title": "Proving Test Set Contamination in Black-Box Language Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "tang2010overlapping",
        "author": "Tang, Diane and Agarwal, Ashish and O'Brien, Deirdre and Meyer, Mike",
        "title": "Overlapping experiment infrastructure: More, better, faster experimentation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "bai2022training",
        "author": "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others",
        "title": "Training a helpful and harmless assistant with reinforcement learning from human feedback"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "novikova2017we",
        "author": "Novikova, Jekaterina and Du{\\v{s}}ek, Ond{\\v{r}}ej and Curry, Amanda Cercas and Rieser, Verena",
        "title": "Why We Need New Evaluation Metrics for NLG"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "krishna2023longeval",
        "author": "Krishna, Kalpesh and Bransom, Erin and Kuehl, Bailey and Iyyer, Mohit and Dasigi, Pradeep and Cohan, Arman and Lo, Kyle",
        "title": "LongEval: Guidelines for Human Evaluation of Faithfulness in Long-form Summarization"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "karpinska2021perils",
        "author": "Karpinska, Marzena and Akoury, Nader and Iyyer, Mohit",
        "title": "The Perils of Using Mechanical Turk to Evaluate Open-Ended Text Generation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zheng2023judging",
        "author": "Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others",
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena"
      },
      {
        "key": "wangpandalm",
        "author": "Wang, Yidong and Yu, Zhuohao and Yao, Wenjin and Zeng, Zhengran and Yang, Linyi and Wang, Cunxiang and Chen, Hao and Jiang, Chaoya and Xie, Rui and Wang, Jindong and others",
        "title": "PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization"
      },
      {
        "key": "yu2024kieval",
        "author": "Yu, Zhuohao and Gao, Chang and Yao, Wenjin and Wang, Yidong and Ye, Wei and Wang, Jindong and Xie, Xing and Zhang, Yue and Zhang, Shikun",
        "title": "Kieval: A knowledge-grounded interactive evaluation framework for large language models"
      },
      {
        "key": "yu2024freeeval",
        "author": "Yu, Zhuohao and Gao, Chang and Yao, Wenjin and Wang, Yidong and Zeng, Zhengran and Ye, Wei and Wang, Jindong and Zhang, Yue and Zhang, Shikun",
        "title": "FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation of Large Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "liu2024calibrating",
        "author": "Liu, Yuxuan and Yang, Tianchi and Huang, Shaohan and Zhang, Zihan and Huang, Haizhen and Wei, Furu and Deng, Weiwei and Sun, Feng and Zhang, Qi",
        "title": "Calibrating LLM-Based Evaluator"
      },
      {
        "key": "wang2023large",
        "author": "Wang, Peiyi and Li, Lei and Chen, Liang and Cai, Zefan and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang",
        "title": "Large language models are not fair evaluators"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "doddapaneni2024finding",
        "author": "Doddapaneni, Sumanth and Khan, Mohammed Safi Ur Rahman and Verma, Sshubam and Khapra, Mitesh M",
        "title": "Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "gal2016uncertainty",
        "author": "Gal, Yarin and others",
        "title": "Uncertainty in deep learning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "geng2024survey",
        "author": "Geng, Jiahui and Cai, Fengyu and Wang, Yuxia and Koeppl, Heinz and Nakov, Preslav and Gurevych, Iryna",
        "title": "A Survey of Confidence Estimation and Calibration in Large Language Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "varshney2023stitch",
        "author": "Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong",
        "title": "A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "linteaching",
        "author": "Lin, Stephanie and Hilton, Jacob and Evans, Owain",
        "title": "Teaching Models to Express Their Uncertainty in Words"
      },
      {
        "key": "yona2024can",
        "author": "Yona, Gal and Aharoni, Roee and Geva, Mor",
        "title": "Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "tian2023just",
        "author": "Tian, Katherine and Mitchell, Eric and Zhou, Allan and Sharma, Archit and Rafailov, Rafael and Yao, Huaxiu and Finn, Chelsea and Manning, Christopher D",
        "title": "Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback"
      },
      {
        "key": "xiongcan",
        "author": "Xiong, Miao and Hu, Zhiyuan and Lu, Xinyang and LI, YIFEI and Fu, Jie and He, Junxian and Hooi, Bryan",
        "title": "Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "duan2024shifting",
        "author": "Duan, Jinhao and Cheng, Hao and Wang, Shiqi and Zavalny, Alex and Wang, Chenan and Xu, Renjing and Kailkhura, Bhavya and Xu, Kaidi",
        "title": "Shifting attention to relevance: Towards the predictive uncertainty quantification of free-form large language models"
      },
      {
        "key": "malininuncertainty",
        "author": "Malinin, Andrey and Gales, Mark",
        "title": "Uncertainty Estimation in Autoregressive Structured Prediction"
      },
      {
        "key": "kumar2024confidence",
        "author": "Kumar, Abhishek and Morabito, Robert and Umbet, Sanzhar and Kabbara, Jad and Emami, Ali",
        "title": "Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "yangsupervised",
        "author": "Yang, Linyi and Zhang, Shuibai and Yu, Zhuohao and Bao, Guangsheng and Wang, Yidong and Wang, Jindong and Xu, Ruochen and Ye, Wei and Xie, Xing and Chen, Weizhu and others",
        "title": "Supervised Knowledge Makes Large Language Models Better In-context Learners"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "geng2024multimodal",
        "author": "Geng, Jiahui and Kementchedjhieva, Yova and Nakov, Preslav and Gurevych, Iryna",
        "title": "Multimodal Large Language Models to Support Real-World Fact-Checking"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "varshney2023stitch",
        "author": "Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong",
        "title": "A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation"
      },
      {
        "key": "farquhar2024detecting",
        "author": "Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin",
        "title": "Detecting hallucinations in large language models using semantic entropy"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "kumar2024confidence",
        "author": "Kumar, Abhishek and Morabito, Robert and Umbet, Sanzhar and Kabbara, Jad and Emami, Ali",
        "title": "Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models"
      },
      {
        "key": "zhou2023navigating",
        "author": "Zhou, Kaitlyn and Jurafsky, Dan and Hashimoto, Tatsunori B",
        "title": "Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models"
      },
      {
        "key": "guptalanguage",
        "author": "Gupta, Neha and Narasimhan, Harikrishna and Jitkrittum, Wittawat and Rawat, Ankit Singh and Menon, Aditya Krishna and Kumar, Sanjiv",
        "title": "Language Model Cascades: Token-Level Uncertainty And Beyond"
      }
    ]
  }
]