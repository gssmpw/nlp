@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{chang2024survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={3},
  pages={1--45},
  year={2024},
  publisher={ACM New York, NY}
}

@article{doddapaneni2024finding,
  title={Finding Blind Spots in Evaluator LLMs with Interpretable Checklists},
  author={Doddapaneni, Sumanth and Khan, Mohammed Safi Ur Rahman and Verma, Sshubam and Khapra, Mitesh M},
  journal={arXiv preprint arXiv:2406.13439},
  year={2024}
}

@inproceedings{duan2024shifting,
  title={Shifting attention to relevance: Towards the predictive uncertainty quantification of free-form large language models},
  author={Duan, Jinhao and Cheng, Hao and Wang, Shiqi and Zavalny, Alex and Wang, Chenan and Xu, Renjing and Kailkhura, Bhavya and Xu, Kaidi},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={5050--5063},
  year={2024}
}

@article{farquhar2024detecting,
  title={Detecting hallucinations in large language models using semantic entropy},
  author={Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
  journal={Nature},
  volume={630},
  number={8017},
  pages={625--630},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{gal2016uncertainty,
  title={Uncertainty in deep learning},
  author={Gal, Yarin and others},
  year={2016},
  publisher={phd thesis, University of Cambridge}
}

@article{geng2024multimodal,
  title={Multimodal Large Language Models to Support Real-World Fact-Checking},
  author={Geng, Jiahui and Kementchedjhieva, Yova and Nakov, Preslav and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2403.03627},
  year={2024}
}

@inproceedings{geng2024survey,
  title={A Survey of Confidence Estimation and Calibration in Large Language Models},
  author={Geng, Jiahui and Cai, Fengyu and Wang, Yuxia and Koeppl, Heinz and Nakov, Preslav and Gurevych, Iryna},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={6577--6595},
  year={2024}
}

@inproceedings{guptalanguage,
  title={Language Model Cascades: Token-Level Uncertainty And Beyond},
  author={Gupta, Neha and Narasimhan, Harikrishna and Jitkrittum, Wittawat and Rawat, Ankit Singh and Menon, Aditya Krishna and Kumar, Sanjiv},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@inproceedings{hendrycks2measuring,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year=2021
}

@inproceedings{karpinska2021perils,
  title={The Perils of Using Mechanical Turk to Evaluate Open-Ended Text Generation},
  author={Karpinska, Marzena and Akoury, Nader and Iyyer, Mohit},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={1265--1285},
  year={2021}
}

@inproceedings{krishna2023longeval,
  title={LongEval: Guidelines for Human Evaluation of Faithfulness in Long-form Summarization},
  author={Krishna, Kalpesh and Bransom, Erin and Kuehl, Bailey and Iyyer, Mohit and Dasigi, Pradeep and Cohan, Arman and Lo, Kyle},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={1650--1669},
  year={2023}
}

@article{kumar2024confidence,
  title={Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models},
  author={Kumar, Abhishek and Morabito, Robert and Umbet, Sanzhar and Kabbara, Jad and Emami, Ali},
  journal={arXiv preprint arXiv:2405.16282},
  year={2024}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{linteaching,
  title={Teaching Models to Express Their Uncertainty in Words},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={Transactions on Machine Learning Research},
  year=2022
}

@inproceedings{liu2024calibrating,
  title={Calibrating LLM-Based Evaluator},
  author={Liu, Yuxuan and Yang, Tianchi and Huang, Shaohan and Zhang, Zihan and Huang, Haizhen and Wei, Furu and Deng, Weiwei and Sun, Feng and Zhang, Qi},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={2638--2656},
  year={2024}
}

@inproceedings{malininuncertainty,
  title={Uncertainty Estimation in Autoregressive Structured Prediction},
  author={Malinin, Andrey and Gales, Mark},
  booktitle={International Conference on Learning Representations},
  year=2021
}

@inproceedings{novikova2017we,
  title={Why We Need New Evaluation Metrics for NLG},
  author={Novikova, Jekaterina and Du{\v{s}}ek, Ond{\v{r}}ej and Curry, Amanda Cercas and Rieser, Verena},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={2241--2252},
  year={2017}
}

@inproceedings{orenproving,
  title={Proving Test Set Contamination in Black-Box Language Models},
  author={Oren, Yonatan and Meister, Nicole and Chatterji, Niladri S and Ladhak, Faisal and Hashimoto, Tatsunori},
  booktitle={The Twelfth International Conference on Learning Representations},
  year=2024
}

@inproceedings{tang2010overlapping,
  title={Overlapping experiment infrastructure: More, better, faster experimentation},
  author={Tang, Diane and Agarwal, Ashish and O'Brien, Deirdre and Meyer, Mike},
  booktitle={Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={17--26},
  year={2010}
}

@inproceedings{tian2023just,
  title={Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback},
  author={Tian, Katherine and Mitchell, Eric and Zhou, Allan and Sharma, Archit and Rafailov, Rafael and Yao, Huaxiu and Finn, Chelsea and Manning, Christopher D},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year=2023 
}

@article{varshney2023stitch,
  title={A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation},
  author={Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong},
  journal={arXiv preprint arXiv:2307.03987},
  year={2023}
}

@article{wang2023large,
  title={Large language models are not fair evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Cai, Zefan and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2305.17926},
  year={2023}
}

@inproceedings{wangpandalm,
  title={PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization},
  author={Wang, Yidong and Yu, Zhuohao and Yao, Wenjin and Zeng, Zhengran and Yang, Linyi and Wang, Cunxiang and Chen, Hao and Jiang, Chaoya and Xie, Rui and Wang, Jindong and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{xiongcan,
  title={Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs},
  author={Xiong, Miao and Hu, Zhiyuan and Lu, Xinyang and LI, YIFEI and Fu, Jie and He, Junxian and Hooi, Bryan},
  booktitle={The Twelfth International Conference on Learning Representations},
  year=2023 
}

@misc{xu2023tool,
      title={On the Tool Manipulation Capability of Open-source Large Language Models}, 
      author={Qiantong Xu and Fenglu Hong and Bo Li and Changran Hu and Zhengyu Chen and Jian Zhang},
      year={2023},
      eprint={2305.16504},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{yangsupervised,
  title={Supervised Knowledge Makes Large Language Models Better In-context Learners},
  author={Yang, Linyi and Zhang, Shuibai and Yu, Zhuohao and Bao, Guangsheng and Wang, Yidong and Wang, Jindong and Xu, Ruochen and Ye, Wei and Xie, Xing and Chen, Weizhu and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year=2024
}

@article{yona2024can,
  title={Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?},
  author={Yona, Gal and Aharoni, Roee and Geva, Mor},
  journal={arXiv preprint arXiv:2405.16908},
  year={2024}
}

@article{yu2024freeeval,
  title={FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation of Large Language Models},
  author={Yu, Zhuohao and Gao, Chang and Yao, Wenjin and Wang, Yidong and Zeng, Zhengran and Ye, Wei and Wang, Jindong and Zhang, Yue and Zhang, Shikun},
  journal={arXiv preprint arXiv:2404.06003},
  year={2024}
}

@article{yu2024kieval,
  title={Kieval: A knowledge-grounded interactive evaluation framework for large language models},
  author={Yu, Zhuohao and Gao, Chang and Yao, Wenjin and Wang, Yidong and Ye, Wei and Wang, Jindong and Xie, Xing and Zhang, Yue and Zhang, Shikun},
  journal={arXiv preprint arXiv:2402.15043},
  year={2024}
}

@inproceedings{zellers2019hellaswag,
  title={HellaSwag: Can a Machine Really Finish Your Sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={4791--4800},
  year={2019}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@inproceedings{zhou2023navigating,
  title={Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models},
  author={Zhou, Kaitlyn and Jurafsky, Dan and Hashimoto, Tatsunori B},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={5506--5524},
  year={2023}
}

