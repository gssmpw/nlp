\section{Perceived Confidence Scoring (PCS) for Classifications using Metamorphic Relations}\label{pcs-methodology}

\begin{figure*}[t]
\vskip 0.2in
\begin{center}
{
\includegraphics[width=0.9\textwidth]{Images/pipeline.png}

\caption{Overview of the classification pipeline using Perceived Confidence Score  (PCS) Annotator.}
\label{fig:pipeline}}
\end{center}
\vskip -0.2in
\end{figure*}

Our focus is on classification tasks performed by LLMs without any prior training examples - known as zero-shot classification. In this scenario, we operate with a black-box model where we can only observe two things: the input data that needs classification, and the model's resulting classification outputs. We assume that we do not know an LLM's internals or any other information (e.g., probability for a given annotation). Our goal is to perceive and quantify the \textit{confidence} of the LLM in the annotation task. Rather than focusing on the true probability of each annotation being correct, we introduce a perceived confidence score (PCS) to evaluate annotations. Our aim is to use this score to enhance the accuracy of the LLM's classification decisions.

We compute the PCS of an LLM-based annotation by asking the LLM to provide annotation for a given input multiple times, each time the input is mutated. Mutation is performed by using Metamorphic Relations (MRs) which follow the principles of invariant synthesis, i.e., the mutation of an input should not change the expected output (i.e., the target annotation). If the output changes, we determine that the LLM is not fully confident on its annotation. Therefore, PCS leverages the consistency of an LLM's annotations across semantically equivalent but textually varied versions of the same input to assess its confidence. The core idea is that if an LLM consistently classifies multiple rephrased versions of the same input in the same way, it demonstrates higher confidence in its output. Conversely, inconsistencies in classification suggest lower confidence.

When classifying an input using PCS, we first identify the optimal weights for each MR and LLM based on a training dataset. After determining these optimal weights, we apply the PCS-based pipeline, illustrated in Figure \ref{fig:pipeline}, to assign the final label to a given input in the test dataset. The pipeline starts with a given input (e.g., a text that we want to label) and then produces four semantically equivalent variations (original + mutated) of the input. We then ask $N$ LLMs ($N$ $\ge$ 1) to label the inputs and apply the weights of the MRs and the LLMs on the LLM outputs for the variations to determine the final PCS score for each possible label. For example for a sentiment classification task, the expected labels could be positive, negative, or neutral.

\subsection{The Metamorphic Relations (MR)}
\label{MR}
For a given annotation/classification task, the input is a sentence or a document that we want to label.  We modify the input using three Metamorphic Relations (MRs). These MRs are task-agnostic, meaning the mutations can be applied to any textual input, regardless of the specific labeling task. The three MRs are as follows:
\begin{inparaenum}[(1)]%[itemsep=0pt, leftmargin=10pt]
    \item MR1 - Active to Passive Transformation.  
    \item MR2 - Double Negation Transformation.
    \item MR3 - Synonym Replacement.
\end{inparaenum}
These Metamorphic Relations ensure that models prioritize the semantic meaning of the text, rather than being swayed by surface-level syntactic or lexical changes.


\noindent \textbf{MR1: Active to Passive Voice Transformation}
MR1 switches the text’s voice between active and passive forms. For example, the sentence \textit{``The Federal Trade Commission (FTC) and 17 state attorneys general have sued Amazon"} in active voice changes to \textit{``Amazon has been sued by The Federal Trade Commission (FTC) and 17 state attorneys general"} in passive voice. 


\noindent \textbf{MR2: Double Negation Transformation}
MR2 applies double negation to convert a positive phrase into two negative phrases, preserving the original meaning while altering its expression. For example, \textit{``The White House strongly criticized the US Supreme Court"} is transformed into \textit{``The White House didn’t weakly criticize the US Supreme Court"}. 

\noindent \textbf{MR3: Synonym Replacement}
MR3 substitutes keywords with their synonyms to generate alternative phrasings that retain the original meaning. For example, \textit{``The White House strongly criticized the US Supreme Court on Tuesday"} can become \textit{``The White House strongly condemned the nation's highest court on Tuesday"}. This tests whether the model focuses on semantic content rather than superficial vocabulary differences. A robust model should classify both versions consistently.


\subsection {Perceived Confidence Score (PCS) using MRs}
\label{PCS}
We obtain four annotations from the LLM for each input: one for the original input and three additional annotations using mutated versions of the input (created by applying three different metamorphic relations). 
 
For example, suppose we ask an LLM to classify a text as either \textit{biased} or \textit{unbiased}. By providing the LLM with the inputs (original + mutated), if we see that the LLM labels three out of four variations as \textit{biased} and one as \textit{unbiased}, we can compute the PCS for each label as follows: For the \textit{biased} label, it is $\frac{3}{4}$, i.e., 75\%, and for the \textit{unbiased} label, it is $\frac{1}{4}$, i.e., 25\%. 

\subsection {PCS across Multiple LLMs}
\label{PCS-multi}
The above concept of PCS for an annotation task can be applicable to a single LLM or across multiple LLMs. For example, for the annotation task of \textit{biased} vs \textit{unbiased} from Section \ref{PCS}, if we ask three LLMs to label and each LLM is asked four times, we can have a total of 12 outputs for the same input. We can then compute the fraction of times the label was \textit{biased} and the fraction of times it was
\textit{unbiased}. 

\subsection{Zero-Shot LLM-Based Classification using PCS}
We can use the PCS values to classify texts using zero-shot LLMs as follows. Assume we have $N$ LLMs available for the classification task (where $N\ge 1$). For each input, we generate mutated versions and prompt an LLM to assign a label—once for the original input and three times for the three mutated inputs. Then, we begin the PCS labeling process.

Suppose that each LLM is denoted by $llm$. Each input type (i.e., original and mutated) is denoted by $I$. For a given input, there can be $m$ possible labels, e.g, for sentiment classification $m$ can be 3 (i.e., positive, negative, neutral), while for a binary classification task $m$ can be 2. We denote each label type by $lbl$. We determine the weighted PCS score for each label and each LLM using Equation \ref{eq:pcslblllm}. 

    \begin{multicols}{2}
    
    \noindent
    \footnotesize
    \begin{equation}
        \label{eq:pcslblllm}
        \text{PCS}_{lbl, llm} = \frac{\sum_{I_{\text{label}}
} \left( I_{\text{weight}}
 \times 
        \begin{cases} 
          1 & I_{\text{label}} = lbl \\
          0 & \text{Otherwise} 
        \end{cases} \right)}{\sum I_{\text{weight}}}
    \end{equation}
    \end{multicols}
Here, $I_{weight}$ denotes the weight we assign to a given input type (between 0 and 1, 1 being the highest), and $I_{label}$ is the label assigned to the input type $I$ by $llm$. We then calculate the weighted average PCS scores of each label type $lbl$ using Equation \ref{eq:pcslbl}, while also assigning a specific weight to each LLM in the process.
\begin{multicols}{2}
\noindent
% \small 
\begin{equation}
    \label{eq:pcslbl}
    \text{PCS}_{lbl} = \frac{\sum_{llm} \left( LLM_{\text{weight}}
 \times 
    \text{PCS}_{lbl, llm} \right)}{\sum LLM_{\text{weight}}
}
\end{equation}
\end{multicols}
Here, $LLM_{weight}$ denotes the weight we assign to the $llm$ (between 0 and 1, 1 being the highest). To assign the final label, and with the weighted PCS calculated for each label, we apply a probability threshold. A probability threshold value can be between 0 and 1 and can differ based on the classification task. For example, for sentiment classification with three labels (positive, negative, neutral) we can have three probability threshold values, one for each label type. Let $\text{T}_{n}$ denote the threshold for label n.

\begin{equation}
\label{eq:pcsThresholds}
\text{Label}_{\text{PCS}} = 
\begin{cases} 
\text{Label}_{1} & \text{PCS}_{1} > \text{T}_{1} \\
\text{Label}_{2} & \text{PCS}_{2} > \text{T}_{2} \\
\vdots & \vdots \\
\text{Label}_{n} & \text{PCS}_{n} > \text{T}_{n} \\
\text{Label}_{\text{mv}} & \text{otherwise}
\end{cases}
\end{equation}
In Equation \ref{eq:pcsThresholds}, $\text{Label}_{\text{mv}}$
  is calculated as follows. Each LLM assigns a label to the original input, and the final label is determined through majority voting among the LLMs. For example, given possible outcomes \(\text{Label}_{1}, \ldots, \text{Label}_{n}\), the final label is assigned as \(\text{Label}_{i}\) if more LLMs select \(\text{Label}_{i}\) compared to the other \(n-1\) labels. If only one LLM is used, the label it provides is considered as the $\text{Label}_{\text{mv}}$.


\begin{equation}\label{eq:mv}
\text{Label}_{mv} = 
\underset{\text{Label } i}{\operatorname{argmax}} \; (\#i \; \text{Labels})
\end{equation}


\begin{algorithm}[h]
\caption{Training for Optimizing HPs}
\label{alg:pde}
\begin{algorithmic}[1]
\REQUIRE $llm\_labels, manual\_labels$, $possible\_labels$
\ENSURE {Optimized Parameters for PCS Labeling}

\STATE Set boundaries for parameters
\STATE $params \gets$ A random initial population of parameters
\STATE $best\_params \gets params$
\STATE $best\_accuracy \gets 0$
\STATE $max\_iterations \gets 1000$
\STATE $tolerance \gets 0.01$
\STATE $previous\_accuracy \gets 0$

\FOR{$iteration \gets 0$ to $max\_iterations$}

    \STATE $correct\_labels \gets 0$
    \FOR{$i \gets 0$ to $\text{len}(ManualLabels)$}
        % \STATE $pcs\_label \gets$ \text{get\_pcs\_label($params,llm\_labels, possible\_labels$)}
    \STATE $pcs\_label \gets \text{get\_pcs\_label}(params, $ \\
         $llm\_labels, possible\_labels)$
        
        \IF{$manual\_labels[i] == pcs\_label$}
            \STATE $correct\_labels \gets correct\_labels + 1$
        \ENDIF
    \ENDFOR
    \STATE $Accuracy \gets \frac{correct\_labels}{\text{len}(ManualLabels)}$
    \IF{$Accuracy > best\_accuracy$}
        \STATE $best\_accuracy \gets Accuracy$
        \STATE $best\_params \gets params$
    \ENDIF
    \STATE Update $params$ based on DE optimization strategy
    \IF{$\left| Accuracy - previous\_accuracy \right| < tolerance$}
        \STATE \textbf{break}
    \ENDIF
    \STATE $previous\_accuracy \gets Accuracy$

\ENDFOR

\STATE {\bfseries return} $best\_params$
\end{algorithmic}
\end{algorithm}

\subsection{Determining Optimized Weights for Classification}
We determine the optimal weights and thresholds in Equations \ref{eq:pcslblllm} - \ref{eq:pcsThresholds} using our PDE algorithm (Perceived Differential Evolution). PDE is an adaptation of the DE algorithm \cite{Price2013}. PDE learns the weights by running on a training dataset that users can provide for a given classification task. Algorithm \ref{alg:pde} outlines the training of PDE. The algorithm takes as input the following parameters: 
\begin{itemize}[itemsep=0pt,leftmargin=10pt]
    \item $X \in \mathbb{R}^{n \times l \times m}$: Tensor of LLM predictions, with $n$ samples, $l$ LLMs ($N_L$), and $m$ MRs ($N_M$).
    \item $Y \in \{c_1,...,c_k\}^n$: Ground truth manual labels for $n$ samples.
    \item $C = \{c_1,...,c_k\}$: Set of possible class labels.
\end{itemize} The output from PDE is the optimal weight for each MR, each LLM, and optimal thresholds for each label type. Let us define $\theta = [\mathbf{w_M}, \mathbf{w_L}, \mathbf{t}]$, where $\mathbf{w_M} = [w_{M_1},...,w_{M_{N_M}}]$ are the MR weights, $\mathbf{w_L} = [w_{L_1},...,w_{L_{N_L}}]$ are the LLM weights, and $\mathbf{t} = [t_1,...,t_k]$ are the label thresholds. The optimization in the parameters should satisfy the following constaints:


% \subsection*{Constraints}\vspace{-6mm}
\begin{align*}
\sum_{i=1}^{N_M} w_{M_i} &= 1,\, w_{M_i} \in [0,1]\\
\sum_{i=1}^{N_L} w_{L_i} &= 1,\, w_{L_i} \in [0,1]\\
t_i &\in [0,1] \;\forall i
\end{align*}

On a training dataset, PDE first initializes the input population $\mathbf{x}_i$ with random values. We then create a population of candidate solutions, with weights for LLMs, MRs, and thresholds in the range $(0, 1)$. The fitness of each candidate solution is evaluated using the accuracy function $f(\mathbf{x}_i) = \text{Acc}(y_{pred}, y_{true})$, where $y_{pred}$ is the predicted label and $y_{true}$ is the true label. The algorithm iterates through a mutation process, where a new candidate solution $\mathbf{v}_i$ is generated by combining randomly selected candidates, followed by a crossover process to create a trial vector $\mathbf{u}_i$. The trial vector is then evaluated, and if its fitness is better than the current solution, it replaces the old solution. This process continues for a set number of iterations or until convergence, ultimately returning the optimized parameters. The fitness function aims to minimize the loss function, $\mathcal{L}(\theta)$ to maximize accuracy:
\begin{equation}
\mathcal{L}(\theta) = -\frac{1}{n} \sum_{i=1}^n \mathbf{1}[f_{\theta}(X_i) = Y_i]
\end{equation}
$f_{\theta}(X_i)$ calculates the label using the PCS algorithm as outlined in Equations \ref{eq:pcslblllm} - \ref{eq:pcsThresholds}.