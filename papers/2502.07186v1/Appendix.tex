\onecolumn
\section{Appendix}

\subsection{Prompt for altering text using MR1 (changing the passive/active voice to active/passive voice)}
Using MR1, as described in Section \ref{MR}, we transform the voice of an input text from passive to active or vice versa. For instance, as illustrated in the examples in \ref{fig:changing-articles}, the sentence \textit{``The White House strongly criticized the US Supreme Court"} is modified to \textit{``The US Supreme Court was strongly criticized by the White House"} after applying MR1. Below, we provide the prompt used for the Llama3.1-8B-Instruct model to generate the MR-transformed texts.
\label{MR1_prompt_altering}

\begin{figure}[h]
\begin{tcolorbox}[colback=gray!10, colframe=gray!50, rounded corners, width=\textwidth, arc=2mm, boxrule=0.5mm, title=]

\vspace{0.3cm} 
Review the text below and transform all sentences by converting active voice to passive voice and vice versa, where appropriate.

Provide only the revised text, starting with the term ``new\_text:"

\vspace{0.3cm} 

Original Text: \\
\{text\}
\end{tcolorbox}

\end{figure}

\subsection{Prompt for altering text using MR2 (Double Negation)}
Using MR2, as outlined in Section \ref{MR}, we employ double negation to transform a positive phrase into two negative phrases, maintaining the original meaning but changing its form. For example, as demonstrated in \ref{fig:changing-articles}, the sentence \textit{``The White House strongly criticized the US Supreme Court"} is transformed into \textit{``The White House didn’t weakly criticize the US Supreme Court."} This transformation was achieved using the prompt provided below, which was fed into the Llama3.1-8B-Instruct model.
\label{MR2_prompt_altering}

\begin{figure}[h]
    \begin{tcolorbox}[colback=gray!10, colframe=gray!50, rounded corners, width=\linewidth, arc=2mm, boxrule=0.5mm, title=]

\vspace{0.3cm} 
Review the text below and transform affirmative sentences into double negation sentences. (Double negation means using two negative elements within a clause or sentence, typically leading to a positive implication.) Ensure that the transformations maintain equivalent meanings.

Provide only the revised text, starting with the term ``new\_text:"

\vspace{0.3cm} 

Original Text: \\
\{text\}
\end{tcolorbox}
\end{figure}


\subsection{Prompt for altering text using MR3 (Synonyms)}
Using MR3, as detailed in Section \ref{MR}, we substitute keywords in the input text with their synonyms. For instance, as shown in \ref{fig:changing-articles}, terms like \textit{``sue"} are replaced with \textit{``taken legal action against,"} or \textit{``sellers"} are changed to \textit{``vendors."} This transformation was accomplished using the prompt provided below, which was input into the Llama3.1-8B-Instruct model.
\label{MR3_prompt_altering}
\begin{figure}[h]
    \begin{tcolorbox}[colback=gray!10, colframe=gray!50, rounded corners, width=\linewidth, arc=2mm, boxrule=0.5mm, title=]

\vspace{0.3cm} 
Review the text below and Replace keywords with their synonyms. Ensure that the transformed sentences retain equivalent meanings.

Provide only the revised text, without extra information, starting with the term "new\_text:"

\vspace{0.3cm} 

Original Text: \\
\{text\}
\end{tcolorbox}
\end{figure}

\newpage
\subsection{Annotation Prompt (Biased/Unbiased)}
\label{annotation_biased}
The prompt below was utilized in this study to instruct the annotator LLMs to classify the input texts as either Biased or Unbiased. The responses generated by the LLMs were then post-processed to determine the final label.
\begin{figure}[h]
    \begin{tcolorbox}[colback=gray!10, colframe=gray!50, rounded corners, width=\linewidth, arc=2mm, boxrule=0.5mm, title=]

\vspace{0.3cm} 
Review the language used in the article, try finding Deliberately misleading or biased information. If you found any of the listed rhetorical techniques, mention them in your response after ``\texttt{<reasoning>}” tag and put "\texttt{<reasoning>}" tag in the end. separate the reasons by '\texttt{<|SEPARATOR|>}'. Finally, if you found any of the listed rhetorical techniques,  label the article as “Biased” and if you do not find any, label it as “Unbiased” after \texttt{<label>} tag and close it with \texttt{</label>} tag. Respond only with the label.

                Rhetorical Techniques:
                    1. Emotional Appeal - Uses emotionally charged language to provoke strong reactions.
                    2. Exaggeration and Hyperbole - Exaggerated claims to make information seem more significant or alarming.
                    3. Bias and Subjectivity - Highly polarized language, presenting information in a biased manner.
                    4. Repetition - Repeating keywords or phrases to reinforce the message.
                    5. Specific Word Choices - Using complex jargon to lend false credibility.
                    6. Appeals to Authority - Citing non-existent or unqualified authorities to support claims.
                    7. Lack of Verifiable Sources - Lacking credible sources or referencing vague sources.
                    8. Logical Fallacies - Using logical fallacies like straw man arguments or ad hominem attacks.
                    9. Conspiracy Theories - Including elements of conspiracy theories.
                    10. Inconsistencies - Containing contradictory statements within the same content.


\vspace{0.3cm} 

Article: \\
\{article\} \\
\end{tcolorbox}
\end{figure}


\subsection{Annotation Prompt (Real/Fake News)}
\label{annotation_real}
The prompt below was used in this study to instruct the annotator LLMs to classify the input news articles as either Real or Fake. The responses generated by the LLMs were then post-processed to determine the final label.
\begin{figure}[h]
    \begin{tcolorbox}[colback=gray!10, colframe=gray!50, rounded corners, width=\linewidth, arc=2mm, boxrule=0.5mm, title=]

% \vspace{0.3cm} 
Analyze the news article and determine whether it is `Fake' or `Real.' 
            Label the article using the tag format: \texttt{<label>Fake</label>} or \texttt{<label>Real</label>}.
            Respond only with the label.
\vspace{0.3cm} 

Article: \\
\{article\} \\
\end{tcolorbox}
\end{figure}

\subsection{Annotation Prompt (Sentiment Analysis)}
\label{annotation_sentiment}
The prompt below was used in this study to ask the annotator LLMs to classify the inputs into Positive, Negative, or Neutral labels based on their sentiment. The LLM responses were subsequently post-processed to extract the final label.
\begin{figure}[h]
    \begin{tcolorbox}[colback=gray!10, colframe=gray!50, rounded corners, width=\linewidth, arc=2mm, boxrule=0.5mm, title=]

\vspace{0.3cm} 
Analyze the emotional tone of the text and categorize it as either `Positive',  `Negative', or `Neutral'. 
            Label the text using the tag format: \texttt{<label>Positive</label>} or \texttt{<label>Negative</label>} or \texttt{<label>Neutral</label>}. 
            Respond only with the label.
\vspace{0.3cm} 

Text: \\
\{article\} \\
\end{tcolorbox}
\end{figure}

\newpage
\section{Changing the articles using Metamorphic Relations}
\label{fig:changing-articles}
The figure below presents examples of the three proposed MRs applied to two original text articles. The highlighted sections indicate the modifications made to the original texts, creating new versions that vary in language.

\begin{figure}[h]
  \includegraphics[width=1\linewidth]{Images/changingArticlesExamples.pdf} 

\end{figure}

\section{Datasets}
\label{datasets}
This study evaluated the proposed PCS across three tasks using four datasets. For the Biased/Unbiased news classification, we used the NewsMediaBias-Plus dataset \cite{vector_newsmediabias_plus}, which contains news articles manually labeled by two annotators. The Cohen's Kappa coefficient of 0.81 indicated almost perfect agreement between annotators. For the Fake/Real news classification task, we utilized two datasets: Gossipcop and Politifact \cite{shu2018fakenewsnet, shu2017fake, shu2017exploiting}. Finally, for the ternary classification task, we employed a multiclass sentiment analysis dataset \cite{hf_multiclass_sentiment} containing three labels: neutral, positive, and negative. Table \ref{datasets-table} presents the distribution of labels across each dataset. The column "Manual Labels" specifies whether the dataset initially included manual labels or not. In this study, only the NewsMediaBias-Plus dataset lacked manual labels initially, which we subsequently added.
\begin{table}[h]
\caption{Datasets information}
\label{datasets-table}
\vskip 0.1in
\begin{center}
\begin{small}
\begin{sc}
  \resizebox{\columnwidth}{!}{%
\begin{tabular}{ccc}
    \hline
    \textbf{Dataset} & \textbf{Size}  & \textbf{Initial Manual labels}\\
    \hline
    NewsMediaBias-Plus & 385 (240 Biased, 145 Unbiased) & Not included\\
    FakeNewsNet-Gossipcop & 393 (195 Real, 198 Fake) &  Included\\
    FakeNewsNet-Politifact & 135 (66 Real,69 Fake) &  Included\\

    Multiclass-Sentiment-Analysis &405 (135 Neutral, 135 Positive, 135 Negative)&Included\\ 

    \hline

  \end{tabular}
  }
\end{sc}
\end{small}
\end{center}
\vskip -0.15in
\end{table}

\newpage
\section{LLM Setups}
\label{hyperparameters}
In this study, we utilized the HuggingFace Transformers library with the following settings for each LLM for the annotation process (Mistral-7B-Instruct-v0.3, Gemma-2-9B-it, and Llama3-8-Instruct) and for applying the MRs (Llama3.1-8B-Instruct).
\begin{table}[h]

\label{hyperparameters-table}
\vskip 0.1in
\begin{center}
\begin{small}
\begin{sc}
  \resizebox{\columnwidth}{!}{%
\begin{tabular}{ccccc}
    \hline
    \textbf{Parameter} & \textbf{Mistral-7B-Instruct-v0.3} & \textbf{Gemma-2-9B-it} & \textbf{LLaMA3-8B-Instruct}&\textbf{LLaMA3.1-8B-Instruct}\\
    \hline

       Precision          & bfloat16 & bfloat16 & bfloat16 & bfloat16  \\ 
    Pipeline Type      & text-generation & text-generation & Causal LM & Causal LM\\ 
    Max Tokens         & 800 & 800 & 800& 800 \\ 
    Max Input Length   & 2048 & 2048 & 2048 & 2048\\ 
    Temperature  & 0.1, 0.2, 0.7 (default) & 0.1, 0.2, 1 (default) &0.1, 0.2, 1 (default)&0.2 \\ 
     
    \hline
  \end{tabular}
  }
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}

% \newpage
\section{Experiment Results}
\subsection{Statistical Comparison of PCSA with Benchmark Methods}
\label{sec:cliffs}
To highlight the effectiveness of the proposed PCS approach compared to other methods, we performed a paired t-test and computed Cliff's delta effect size based on the classification task accuracies across our four datasets (NewsMediaBias-Plus, Gossipcop, Politifact, and Multiclass Sentiment Analysis). The results are summarized in Table \ref{tab:cliffs} (where L: Meta-Llama-3-8B-Instruct, M: Mistral-7B-Instruct-v0.3, and G: gemma-2-9b-it). PCS demonstrates a significant improvement in accuracy over the single few-shot approaches using Llama3-8B-Instruct and Mistral-7B-Instruct-v0.3. Additionally, when employing multiple LLMs, PCS outperforms Majority Voting significantly in the combinations of ``L+M+G", ``L+M", and ``L+G". Also, the large (L) Effect sizes in ``L+M", ``L+G", ``M, and ``G" experimental settings underscores the robustness and effectiveness of PCS in improving classification accuracy.
\[
 \small
% \Large
\text{p-value}= 
\begin{cases} 

\text{\textit{Significant}} & \text{if } |\text{p-value}| < 0.05 \\

\text{\textit{Not significant}} & \text{if } 0.33 \geq |\text{p-value}| \\


\end{cases}
\]

\[
 \small
% \Large
\text{Effect Size}= 
\begin{cases} 
\text{\textit{negligible} (N)} & \text{if } |\delta| \leq 0.147 \\

\text{\textit{small} (S)} & \text{if } 0.147 < |\delta| \leq 0.33 \\

\text{\textit{medium} (M)} & \text{if } 0.33 < |\delta| \leq 0.474 \\

\text{\textit{large} (L)} & \text{if } 0.474 < |\delta| \leq 1 \\

\end{cases}
\]
\begin{table}[h]
\centering%
\caption{Results of the paired t-test,  and Cliff’s delta effect size for the pair-wise comparisons of the accuracy on four datasets (NewsMediaBias-Plus, Gossipcop, Politifact, and Multiclass Sentiment Analysis) (L: Meta-Llama-3-8B-Instruct, M: Mistral-7B-Instruct-v0.3, and G: gemma-2-9b-it)}
% \vspace{-4mm}
% \smallskip
\label{tab:cliffs}
\vskip 0.15in
{
\input{tables/cliffsdelta}
}
\end{table}

\newpage
\subsection{Optimized Weights and Thresholds in PCS}
\label{optimizedweights}
The PCS algorithm is implemented by assigning weights to LLMs and MRs, and determining the final classification label by comparing each label's PCS score against a specific threshold. In our study, the weights and thresholds are optimized using the proposed PDE algorithm (Algorithm \ref{alg:pde}). Table \ref{tab:optimizedweightsTable} displays a set of potential solution weights for different configurations—single, dual, or triple LLM setups—across various datasets. These weights, calculated via the PDE algorithm, represent one of several possible solutions that could achieve equivalent PCS accuracy.


\begin{table}[h]
\caption{Optimized Weights and Thresholds Determined by PDE Across Various Datasets for PCS Labeling}
\label{tab:optimizedweightsTable}
\vskip 0.15in
{
\input{tables/weights}
}
\vskip -0.1in
\end{table}


\newpage
\subsection{Results for temperature=0.1 and temperature=0.2 temperature=default in Zero-Shot LLMs}
\label{sec:singleLLMsTemperatures}

In addition to testing the PCS approach with the default temperature settings of each LLM (Llama3-8B-instruct and Gemma-2-9B-it at temperatures of 1, and Mistral-7B-Instruct-V0.3 at 0.7), we also evaluated the performance at temperatures of 0.1 and 0.2. The results for the single LLM zero-shot setting are presented in Table \ref{tab:singleLLMsTemperatures}, and those for the multiple LLM zero-shot setting are shown in Table \ref{tab:multipleLLMsTemperatures}. 


\begin{table}[h]
\centering%
\caption{Comparing PCS with single zero-shot approach (L: Meta-Llama-3-8B-Instruct, M: Mistral-7B-Instruct-v0.3, and G: gemma-2-9b-it) in three temperature settings (temperature=0.1, and temperature=0.2, temperature=default)}
\label{tab:singleLLMsTemperatures}
\vskip 0.15in

{
\input{tables/temperaturesSingle}
}
\end{table}


\newpage

\begin{table}[htp!]
\centering%
\caption{Comparing PCS with Majority Voting approach (L: Meta-Llama-3-8B-Instruct, M: Mistral-7B-Instruct-v0.3, and G: gemma-2-9b-it) in two temperature settings (temperature=0.1, and temperature=0.2, temperature=default)}
\label{tab:multipleLLMsTemperatures}
\vskip 0.15in
{
\input{tables/temperaturesMultiple}
}
\end{table}