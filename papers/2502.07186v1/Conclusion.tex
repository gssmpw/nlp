\section{Conclusion and Future Work}
We introduced a novel technique Perceived Confidence Score (PCS), to assess LLM's confidence in classification tasks. By leveraging Metamorphic Relations (MRs), PCS generates textually varied inputs and assesses LLM prediction consistency, computing a confidence score to enhance annotation reliability. We also proposed the Perceived Differential Evolution (PDE) algorithm to optimize MR and LLM weights. 

Empirical evaluation on four datasets and three LLMs—Llama-3-8B-Instruct (L), Mistral-7B-Instruct-v0.3 (M), and Gemma-2-9b-it (G)—demonstrates that PCS significantly improves accuracy in zero-shot settings for the single LLMs L and G. On average, PCS boosts classification accuracy by 4.96\% for Model L, 10.52\% for Model M, and 9.39\% for Model G. In multi-LLM setups (e.g., L, M, and G), PCS significantly outperforms majority voting, enhancing accuracy by 6.57\% with two LLMs and 7.75\% with three LLMs. These results underscore PCS as a robust framework for improving LLM-based classification.
 

Despite its effectiveness, PCS has limitations. It relies on predefined Metamorphic Relations (MRs) for input variations, which may lack diversity for robust testing or resilience against adversarial examples. Additionally, evaluation on only four datasets limits understanding of its generalizability. Future work should expand MR diversity, incorporating transformations like paraphrasing, context expansion, and noise injection to enhance robustness. Testing PCS on broader tasks, such as topic categorization and social media misinformation detection, would further validate its applicability.
