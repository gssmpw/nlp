[
  {
    "index": 0,
    "papers": [
      {
        "key": "chithrananda2020chemberta",
        "author": "Chithrananda, Seyone and Grand, Gabriel and Ramsundar, Bharath",
        "title": "ChemBERTa: large-scale self-supervised pretraining for molecular property prediction"
      },
      {
        "key": "fabian2020molbert",
        "author": "Fabian, Benedek and Edlich, Thomas and Gaspar, H{\\'e}l{\\'e}na and Segler, Marwin and Meyers, Joshua and Fiscato, Marco and Ahmed, Mohamed",
        "title": "Molecular representation learning with language models and domain-relevant auxiliary tasks"
      },
      {
        "key": "wang2019smilesbert",
        "author": "Wang, Sheng and Guo, Yuzhi and Wang, Yuhong and Sun, Hongmao and Huang, Junzhou",
        "title": "Smiles-bert: large scale unsupervised pre-training for molecular property prediction"
      },
      {
        "key": "irwin2022chemformer",
        "author": "Irwin, Ross and Dimitriadis, Spyridon and He, Jiazhen and Bjerrum, Esben Jannik",
        "title": "Chemformer: a pre-trained transformer for computational chemistry"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "ying2021graphormer",
        "author": "Chengxuan Ying and Tianle Cai and Shengjie Luo and Shuxin Zheng and Guolin Ke and Di He and Yanming Shen and Tie-Yan Liu",
        "title": "Do Transformers Really Perform Badly for Graph Representation?"
      },
      {
        "key": "mendez2024mole",
        "author": "M{\\'e}ndez-Lucio, Oscar and Nicolaou, Christos A and Earnshaw, Berton",
        "title": "MolE: a foundation model for molecular graphs using disentangled attention"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhou2023unimol",
        "author": "Gengmo Zhou and Zhifeng Gao and Qiankun Ding and Hang Zheng and Hongteng Xu and Zhewei Wei and Linfeng Zhang and Guolin Ke",
        "title": "Uni-Mol: A Universal 3D Molecular Representation Learning Framework"
      },
      {
        "key": "lu2024unimol+",
        "author": "Lu, Shuqi and Gao, Zhifeng and He, Di and Zhang, Linfeng and Ke, Guolin",
        "title": "Data-driven quantum chemical property prediction leveraging 3D conformations with Uni-Mol+"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gu2021domain",
        "author": "Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung",
        "title": "Domain-specific language model pretraining for biomedical natural language processing"
      },
      {
        "key": "lee2020biobert",
        "author": "Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo",
        "title": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
      },
      {
        "key": "beltagy2019scibert",
        "author": "Beltagy, Iz and Lo, Kyle and Cohan, Arman",
        "title": "SciBERT: A pretrained language model for scientific text"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "su2022momu",
        "author": "Su, Bing and Du, Dazhao and Yang, Zhao and Zhou, Yujie and Li, Jiangmeng and Rao, Anyi and Sun, Hao and Lu, Zhiwu and Wen, Ji-Rong",
        "title": "A molecular multimodal foundation model associating molecule graphs with natural language"
      },
      {
        "key": "liu2023moleculestm",
        "author": "Liu, Shengchao and Nie, Weili and Wang, Chengpeng and Lu, Jiarui and Qiao, Zhuoran and Liu, Ling and Tang, Jian and Xiao, Chaowei and Anandkumar, Animashree",
        "title": "Multi-modal molecule structure--text model for text-based retrieval and editing"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "edwards-etal-2022-molt5",
        "author": "Edwards, Carl  and\nLai, Tuan  and\nRos, Kevin  and\nHonke, Garrett  and\nCho, Kyunghyun  and\nJi, Heng",
        "title": "Translation between Molecules and Natural Language"
      },
      {
        "key": "zeng2022kvplm",
        "author": "Zeng, Zheni and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong",
        "title": "A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals"
      },
      {
        "key": "luo2023molfm",
        "author": "Luo, Yizhen and Yang, Kai and Hong, Massimo and Liu, Xing Yi and Nie, Zaiqing",
        "title": "Molfm: A multimodal molecular foundation model"
      },
      {
        "key": "christofidellis2023text+chemt5",
        "author": "Christofidellis, Dimitrios and Giannone, Giorgio and Born, Jannis and Winther, Ole and Laino, Teodoro and Manica, Matteo",
        "title": "Unifying molecular and textual representations via multi-task language modelling"
      },
      {
        "key": "liu2024gitmol",
        "author": "Liu, Pengfei and Ren, Yiming and Tao, Jun and Ren, Zhixiang",
        "title": "Git-mol: A multi-modal large language model for molecular science with graph, image, and text"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "openai2024gpt4",
        "author": "OpenAI",
        "title": "GPT-4 Technical Report"
      },
      {
        "key": "openai2024gpt4ocard",
        "author": "OpenAI",
        "title": "GPT-4o System Card"
      },
      {
        "key": "touvron2023llama2",
        "author": "Hugo Touvron and others",
        "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models"
      },
      {
        "key": "grattafiori2024llama3",
        "author": "Aaron Grattafiori and others",
        "title": "The Llama 3 Herd of Models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ai4science2023impactlargelanguagemodels",
        "author": "Microsoft Research AI4Science and Microsoft Azure Quantum",
        "title": "The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "weininger1988smiles",
        "author": "Weininger, David",
        "title": "SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "krenn2020selfies",
        "author": "Krenn, Mario and H{\\\"a}se, Florian and Nigam, AkshatKumar and Friederich, Pascal and Aspuru-Guzik, Alan",
        "title": "Self-referencing embedded strings (SELFIES): A 100\\% robust molecular string representation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "liu2024LLAVA",
        "author": "Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae",
        "title": "Visual instruction tuning"
      },
      {
        "key": "liu2024LLAVA1.5",
        "author": "Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae",
        "title": "Improved baselines with visual instruction tuning"
      },
      {
        "key": "xu2024llavacot",
        "author": "Guowei Xu and Peng Jin and Hao Li and Yibing Song and Lichao Sun and Li Yuan",
        "title": "LLaVA-CoT: Let Vision Language Models Reason Step-by-Step"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "liu-etal-2023-molca",
        "author": "Liu, Zhiyuan  and\nLi, Sihang  and\nLuo, Yanchen  and\nFei, Hao  and\nCao, Yixin  and\nKawaguchi, Kenji  and\nWang, Xiang  and\nChua, Tat-Seng",
        "title": "{M}ol{CA}: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "fang2023molinstruction",
        "author": "Yin Fang and\nXiaozhuan Liang and\nNingyu Zhang and\nKangwei Liu and\nRui Huang and\nZhuo Chen and\nXiaohui Fan and\nHuajun Chen",
        "title": "Mol-Instructions: {A} Large-Scale Biomolecular Instruction Dataset\nfor Large Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yu2024llasmol",
        "author": "Botao Yu and Frazier N. Baker and Ziqi Chen and Xia Ning and Huan Sun",
        "title": "LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "cao2023instructmol",
        "author": "He Cao and Zijing Liu and Xingyu Lu and Yuan Yao and Yu Li",
        "title": "InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "li2024molm",
        "author": "Li, Sihang and Liu, Zhiyuan and Luo, Yanchen and Wang, Xiang and He, Xiangnan and Kawaguchi, Kenji  and Chua, Tat-Seng and Tian, Qi",
        "title": "3D-MoLM: Towards 3D Molecule-Text Interpretation in Language Models"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "park2024llamo",
        "author": "Park, Jinyoung and Bae, Minseong and Ko, Dohwan and Kim, Hyunwoo J",
        "title": "LLaMo: Large Language Model-based Molecular Graph Assistant"
      }
    ]
  }
]