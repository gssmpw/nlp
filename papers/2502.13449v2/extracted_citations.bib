@article{ai4science2023impactlargelanguagemodels,
      title={The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4}, 
      author={Microsoft Research AI4Science and Microsoft Azure Quantum},
      year={2023},
      journal={arXiv:2311.07361},
}

@article{beltagy2019scibert,
  title={SciBERT: A pretrained language model for scientific text},
  author={Beltagy, Iz and Lo, Kyle and Cohan, Arman},
  journal={arXiv preprint arXiv:1903.10676},
  year={2019}
}

@article{cao2023instructmol,
      title={InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery}, 
      author={He Cao and Zijing Liu and Xingyu Lu and Yuan Yao and Yu Li},
      year={2023},
      journal={arXiv:2311.16208},
}

@article{chithrananda2020chemberta,
  title={ChemBERTa: large-scale self-supervised pretraining for molecular property prediction},
  author={Chithrananda, Seyone and Grand, Gabriel and Ramsundar, Bharath},
  journal={arXiv:2010.09885},
  year={2020}
}

@inproceedings{christofidellis2023text+chemt5,
  title={Unifying molecular and textual representations via multi-task language modelling},
  author={Christofidellis, Dimitrios and Giannone, Giorgio and Born, Jannis and Winther, Ole and Laino, Teodoro and Manica, Matteo},
  booktitle={International Conference on Machine Learning},
  year={2023},
}

@inproceedings{edwards-etal-2022-molt5,
    title = "Translation between Molecules and Natural Language",
    author = "Edwards, Carl  and
      Lai, Tuan  and
      Ros, Kevin  and
      Honke, Garrett  and
      Cho, Kyunghyun  and
      Ji, Heng",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    year = "2022",
}

@article{fabian2020molbert,
  title={Molecular representation learning with language models and domain-relevant auxiliary tasks},
  author={Fabian, Benedek and Edlich, Thomas and Gaspar, H{\'e}l{\'e}na and Segler, Marwin and Meyers, Joshua and Fiscato, Marco and Ahmed, Mohamed},
  journal={arXiv:2011.13230},
  year={2020}
}

@inproceedings{fang2023molinstruction,
  author       = {Yin Fang and
                  Xiaozhuan Liang and
                  Ningyu Zhang and
                  Kangwei Liu and
                  Rui Huang and
                  Zhuo Chen and
                  Xiaohui Fan and
                  Huajun Chen},
  title        = {Mol-Instructions: {A} Large-Scale Biomolecular Instruction Dataset
                  for Large Language Models},
  booktitle    = {International Conference on Learning Representations},
  year         = {2024},
}

@article{grattafiori2024llama3,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori and others},
      year={2024},
      journal={arXiv:2407.21783},
}

@article{gu2021domain,
  title={Domain-specific language model pretraining for biomedical natural language processing},
  author={Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal={ACM Transactions on Computing for Healthcare (HEALTH)},
  volume={3},
  number={1},
  pages={1--23},
  year={2021},
  publisher={ACM New York, NY}
}

@article{irwin2022chemformer,
  title={Chemformer: a pre-trained transformer for computational chemistry},
  author={Irwin, Ross and Dimitriadis, Spyridon and He, Jiazhen and Bjerrum, Esben Jannik},
  journal={Machine Learning: Science and Technology},
  volume={3},
  number={1},
  pages={015022},
  year={2022},
  publisher={IOP Publishing}
}

@article{krenn2020selfies,
  title={Self-referencing embedded strings (SELFIES): A 100\% robust molecular string representation},
  author={Krenn, Mario and H{\"a}se, Florian and Nigam, AkshatKumar and Friederich, Pascal and Aspuru-Guzik, Alan},
  journal={Machine Learning: Science and Technology},
  volume={1},
  number={4},
  pages={045024},
  year={2020},
  publisher={IOP Publishing}
}

@article{lee2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}

@inproceedings{li2024molm,
    title={3D-MoLM: Towards 3D Molecule-Text Interpretation in Language Models},
    author={Li, Sihang and Liu, Zhiyuan and Luo, Yanchen and Wang, Xiang and He, Xiangnan and Kawaguchi, Kenji  and Chua, Tat-Seng and Tian, Qi},
    booktitle={International Conference on Learning Representations},
    year={2024},
}

@inproceedings{liu-etal-2023-molca,
    title = "{M}ol{CA}: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter",
    author = "Liu, Zhiyuan  and
      Li, Sihang  and
      Luo, Yanchen  and
      Fei, Hao  and
      Cao, Yixin  and
      Kawaguchi, Kenji  and
      Wang, Xiang  and
      Chua, Tat-Seng",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    year = "2023",
}

@article{liu2023moleculestm,
  title={Multi-modal molecule structure--text model for text-based retrieval and editing},
  author={Liu, Shengchao and Nie, Weili and Wang, Chengpeng and Lu, Jiarui and Qiao, Zhuoran and Liu, Ling and Tang, Jian and Xiao, Chaowei and Anandkumar, Animashree},
  journal={Nature Machine Intelligence},
  volume={5},
  number={12},
  pages={1447--1457},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{liu2024LLAVA,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}

@inproceedings{liu2024LLAVA1.5,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@article{liu2024gitmol,
  title={Git-mol: A multi-modal large language model for molecular science with graph, image, and text},
  author={Liu, Pengfei and Ren, Yiming and Tao, Jun and Ren, Zhixiang},
  journal={Computers in biology and medicine},
  volume={171},
  pages={108073},
  year={2024},
  publisher={Elsevier}
}

@article{lu2024unimol+,
  title={Data-driven quantum chemical property prediction leveraging 3D conformations with Uni-Mol+},
  author={Lu, Shuqi and Gao, Zhifeng and He, Di and Zhang, Linfeng and Ke, Guolin},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={7104},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{luo2023molfm,
  title={Molfm: A multimodal molecular foundation model},
  author={Luo, Yizhen and Yang, Kai and Hong, Massimo and Liu, Xing Yi and Nie, Zaiqing},
  journal={arXiv preprint arXiv:2307.09484},
  year={2023}
}

@article{mendez2024mole,
  title={MolE: a foundation model for molecular graphs using disentangled attention},
  author={M{\'e}ndez-Lucio, Oscar and Nicolaou, Christos A and Earnshaw, Berton},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={9431},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      journal={arXiv:2303.08774},
}

@article{openai2024gpt4ocard,
      title={GPT-4o System Card}, 
      author={OpenAI},
      year={2024},
      journal={arXiv:2410.21276},
}

@inproceedings{park2024llamo,
  title={LLaMo: Large Language Model-based Molecular Graph Assistant},
  author={Park, Jinyoung and Bae, Minseong and Ko, Dohwan and Kim, Hyunwoo J},
  booktitle={Advances in Neural Information Processing Systems},
  year={2024}
}

@article{su2022momu,
  title={A molecular multimodal foundation model associating molecule graphs with natural language},
  author={Su, Bing and Du, Dazhao and Yang, Zhao and Zhou, Yujie and Li, Jiangmeng and Rao, Anyi and Sun, Hao and Lu, Zhiwu and Wen, Ji-Rong},
  journal={arXiv:2209.05481},
  year={2022}
}

@article{touvron2023llama2,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and others},
      year={2023},
      journal={arXiv:2307.09288},
}

@inproceedings{wang2019smilesbert,
  title={Smiles-bert: large scale unsupervised pre-training for molecular property prediction},
  author={Wang, Sheng and Guo, Yuzhi and Wang, Yuhong and Sun, Hongmao and Huang, Junzhou},
  booktitle={Proceedings of the 10th ACM international conference on bioinformatics, computational biology and health informatics},
  pages={429--436},
  year={2019}
}

@article{weininger1988smiles,
  title={SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules},
  author={Weininger, David},
  journal={Journal of chemical information and computer sciences},
  volume={28},
  number={1},
  pages={31--36},
  year={1988},
  publisher={ACS Publications}
}

@article{xu2024llavacot,
      title={LLaVA-CoT: Let Vision Language Models Reason Step-by-Step},
      author={Guowei Xu and Peng Jin and Hao Li and Yibing Song and Lichao Sun and Li Yuan},
      year={2024},
      journal={arXiv:2411.10440},
}

@inproceedings{ying2021graphormer,
    title={Do Transformers Really Perform Badly for Graph Representation?},
    author={Chengxuan Ying and Tianle Cai and Shengjie Luo and Shuxin Zheng and Guolin Ke and Di He and Yanming Shen and Tie-Yan Liu},
    booktitle={Advances in Neural Information Processing Systems},
    year={2021},
}

@article{yu2024llasmol,
    title={LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset},
    author={Botao Yu and Frazier N. Baker and Ziqi Chen and Xia Ning and Huan Sun},
    journal={arXiv:2402.09391},
    year={2024}
}

@article{zeng2022kvplm,
  title={A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals},
  author={Zeng, Zheni and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong},
  journal={Nature communications},
  volume={13},
  number={1},
  pages={862},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

