@inproceedings{xu2019GIN,
  title={How powerful are graph neural networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{kipf2017GCN,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@inproceedings{ying2021graphormer,
    title={Do Transformers Really Perform Badly for Graph Representation?},
    author={Chengxuan Ying and Tianle Cai and Shengjie Luo and Shuxin Zheng and Guolin Ke and Di He and Yanming Shen and Tie-Yan Liu},
    booktitle={Advances in Neural Information Processing Systems},
    year={2021},
}

@inproceedings{
  zhou2023unimol,
  title={Uni-Mol: A Universal 3D Molecular Representation Learning Framework},
  author={Gengmo Zhou and Zhifeng Gao and Qiankun Ding and Hang Zheng and Hongteng Xu and Zhewei Wei and Linfeng Zhang and Guolin Ke},
  booktitle={International Conference on Learning Representations},
  year={2023},
}

@article{weininger1988smiles,
  title={SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules},
  author={Weininger, David},
  journal={Journal of chemical information and computer sciences},
  volume={28},
  number={1},
  pages={31--36},
  year={1988},
  publisher={ACS Publications}
}

@article{liu2024LLAVA,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in Neural Information Processing Systems},
  year={2024}
}


@inproceedings{liu2024LLAVA1.5,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  year={2024}
}

@inproceedings{li2023BLIP2,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  year={2023},
}

@inproceedings{huang2024audiogpt,
  title={Audiogpt: Understanding and generating speech, music, sound, and talking head},
  author={Huang, Rongjie and Li, Mingze and Yang, Dongchao and Shi, Jiatong and Chang, Xuankai and Ye, Zhenhui and Wu, Yuning and Hong, Zhiqing and Huang, Jiawei and Liu, Jinglin and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2024}
}

@inproceedings{zhang2023speechgpt,
    title = "{S}peech{GPT}: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities",
    author = "Zhang, Dong  and
      Li, Shimin  and
      Zhang, Xin  and
      Zhan, Jun  and
      Wang, Pengyu  and
      Zhou, Yaqian  and
      Qiu, Xipeng",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    year = "2023",
}


@inproceedings{zhang2023videoLLAMA,
    title = "Video-{LL}a{MA}: An Instruction-tuned Audio-Visual Language Model for Video Understanding",
    author = "Zhang, Hang  and
      Li, Xin  and
      Bing, Lidong",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    year = "2023",
}

@inproceedings{maaz2024videochatgpt,
    title = "Video-{C}hat{GPT}: Towards Detailed Video Understanding via Large Vision and Language Models",
    author = "Maaz, Muhammad  and
      Rasheed, Hanoona  and
      Khan, Salman  and
      Khan, Fahad",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024",
}

@inproceedings{fang2023molinstruction,
  author       = {Yin Fang and
                  Xiaozhuan Liang and
                  Ningyu Zhang and
                  Kangwei Liu and
                  Rui Huang and
                  Zhuo Chen and
                  Xiaohui Fan and
                  Huajun Chen},
  title        = {Mol-Instructions: {A} Large-Scale Biomolecular Instruction Dataset
                  for Large Language Models},
  booktitle    = {International Conference on Learning Representations},
  year         = {2024},
}

@article{cao2023instructmol,
      title={InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery}, 
      author={He Cao and Zijing Liu and Xingyu Lu and Yuan Yao and Yu Li},
      year={2023},
      journal={arXiv:2311.16208},
}

@article{zhang2024unimot,
      title={UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation}, 
      author={Juzheng Zhang and Yatao Bian and Yongqiang Chen and Quanming Yao},
      year={2024},
      journal={arXiv:2408.00863},
}

@article{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      journal={arXiv:2303.08774},
}

@inproceedings{li2024molm,
    title={3D-MoLM: Towards 3D Molecule-Text Interpretation in Language Models},
    author={Li, Sihang and Liu, Zhiyuan and Luo, Yanchen and Wang, Xiang and He, Xiangnan and Kawaguchi, Kenji  and Chua, Tat-Seng and Tian, Qi},
    booktitle={International Conference on Learning Representations},
    year={2024},
}

@inproceedings{park2024llamo,
  title={LLaMo: Large Language Model-based Molecular Graph Assistant},
  author={Park, Jinyoung and Bae, Minseong and Ko, Dohwan and Kim, Hyunwoo J},
  booktitle={Advances in Neural Information Processing Systems},
  year={2024}
}

@article{ai4science2023impactlargelanguagemodels,
      title={The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4}, 
      author={Microsoft Research AI4Science and Microsoft Azure Quantum},
      year={2023},
      journal={arXiv:2311.07361},
}

@inproceedings{fathullah2024audiochatllama,
  title={AudioChatLlama: Towards General-Purpose Speech Abilities for LLMs},
  author={Fathullah, Yassir and Wu, Chunyang and Lakomkin, Egor and Li, Ke and Jia, Junteng and Shangguan, Yuan and Mahadeokar, Jay and Kalinli, Ozlem and Fuegen, Christian and Seltzer, Mike},
  booktitle={Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  year={2024}
}
@article{chen2023videollm,
  title={Videollm: Modeling video sequence with large language models},
  author={Chen, Guo and Zheng, Yin-Dong and Wang, Jiahao and Xu, Jilan and Huang, Yifei and Pan, Junting and Wang, Yi and Wang, Yali and Qiao, Yu and Lu, Tong and others},
  journal={arXiv:2305.13292},
  year={2023}
}


@article{touvron2023llama2,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and others},
      year={2023},
      journal={arXiv:2307.09288},
}

@article{grattafiori2024llama3,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori and others},
      year={2024},
      journal={arXiv:2407.21783},
}
@inproceedings{huang2024visualhallucination,
    title = "Visual Hallucinations of Multi-modal Large Language Models",
    author = "Huang, Wen  and
      Liu, Hongbin  and
      Guo, Minxin  and
      Gong, Neil",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    year = "2024",
    pages = "9614--9631",
}

@article{liu2023moleculestm,
  title={Multi-modal molecule structure--text model for text-based retrieval and editing},
  author={Liu, Shengchao and Nie, Weili and Wang, Chengpeng and Lu, Jiarui and Qiao, Zhuoran and Liu, Ling and Tang, Jian and Xiao, Chaowei and Anandkumar, Animashree},
  journal={Nature Machine Intelligence},
  volume={5},
  number={12},
  pages={1447--1457},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{chithrananda2020chemberta,
  title={ChemBERTa: large-scale self-supervised pretraining for molecular property prediction},
  author={Chithrananda, Seyone and Grand, Gabriel and Ramsundar, Bharath},
  journal={arXiv:2010.09885},
  year={2020}
}

@inproceedings{wang2019smilesbert,
  title={Smiles-bert: large scale unsupervised pre-training for molecular property prediction},
  author={Wang, Sheng and Guo, Yuzhi and Wang, Yuhong and Sun, Hongmao and Huang, Junzhou},
  booktitle={Proceedings of the 10th ACM international conference on bioinformatics, computational biology and health informatics},
  pages={429--436},
  year={2019}
}

@article{irwin2022chemformer,
  title={Chemformer: a pre-trained transformer for computational chemistry},
  author={Irwin, Ross and Dimitriadis, Spyridon and He, Jiazhen and Bjerrum, Esben Jannik},
  journal={Machine Learning: Science and Technology},
  volume={3},
  number={1},
  pages={015022},
  year={2022},
  publisher={IOP Publishing}
}

@article{fabian2020molbert,
  title={Molecular representation learning with language models and domain-relevant auxiliary tasks},
  author={Fabian, Benedek and Edlich, Thomas and Gaspar, H{\'e}l{\'e}na and Segler, Marwin and Meyers, Joshua and Fiscato, Marco and Ahmed, Mohamed},
  journal={arXiv:2011.13230},
  year={2020}
}

@article{mendez2024mole,
  title={MolE: a foundation model for molecular graphs using disentangled attention},
  author={M{\'e}ndez-Lucio, Oscar and Nicolaou, Christos A and Earnshaw, Berton},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={9431},
  year={2024},
  publisher={Nature Publishing Group UK London}
}
@article{lu2024unimol+,
  title={Data-driven quantum chemical property prediction leveraging 3D conformations with Uni-Mol+},
  author={Lu, Shuqi and Gao, Zhifeng and He, Di and Zhang, Linfeng and Ke, Guolin},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={7104},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{openai2024gpt4ocard,
      title={GPT-4o System Card}, 
      author={OpenAI},
      year={2024},
      journal={arXiv:2410.21276},
}

@article{xu2024llavacot,
      title={LLaVA-CoT: Let Vision Language Models Reason Step-by-Step},
      author={Guowei Xu and Peng Jin and Hao Li and Yibing Song and Lichao Sun and Li Yuan},
      year={2024},
      journal={arXiv:2411.10440},
}

@article{yu2024llasmol,
    title={LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset},
    author={Botao Yu and Frazier N. Baker and Ziqi Chen and Xia Ning and Huan Sun},
    journal={arXiv:2402.09391},
    year={2024}
}

@article{sadeghi2024can,
  title={Can large language models understand molecules?},
  author={Sadeghi, Shaghayegh and Bui, Alan and Forooghi, Ali and Lu, Jianguo and Ngom, Alioune},
  journal={BMC bioinformatics},
  volume={25},
  number={1},
  pages={225},
  year={2024},
  publisher={Springer}
}

@article{kim2021pubchem,
  title={PubChem in 2021: new data content and improved web interfaces},
  author={Kim, Sunghwan and Chen, Jie and Cheng, Tiejun and Gindulyte, Asta and He, Jia and He, Siqian and Li, Qingliang and Shoemaker, Benjamin A and Thiessen, Paul A and Yu, Bo and others},
  journal={Nucleic acids research},
  volume={49},
  number={D1},
  pages={D1388--D1395},
  year={2021},
  publisher={Oxford University Press}
}

@article{wu2018moleculenet,
  title={MoleculeNet: a benchmark for molecular machine learning},
  author={Wu, Zhenqin and Ramsundar, Bharath and Feinberg, Evan N and Gomes, Joseph and Geniesse, Caleb and Pappu, Aneesh S and Leswing, Karl and Pande, Vijay},
  journal={Chemical science},
  volume={9},
  number={2},
  pages={513--530},
  year={2018},
  publisher={Royal Society of Chemistry}
}

@article{lu2022uspto,
  title={Unified deep learning model for multitask reaction predictions with explanation},
  author={Lu, Jieyu and Zhang, Yingkai},
  journal={Journal of chemical information and modeling},
  volume={62},
  number={6},
  pages={1376--1387},
  year={2022},
  publisher={ACS Publications}
}

@article{krenn2020selfies,
  title={Self-referencing embedded strings (SELFIES): A 100\% robust molecular string representation},
  author={Krenn, Mario and H{\"a}se, Florian and Nigam, AkshatKumar and Friederich, Pascal and Aspuru-Guzik, Alan},
  journal={Machine Learning: Science and Technology},
  volume={1},
  number={4},
  pages={045024},
  year={2020},
  publisher={IOP Publishing}
}

@inproceedings{ganeeva2024chemical,
  title={Chemical Language Models Have Problems with Chemistry: A Case Study on Molecule Captioning Task},
  author={Ganeeva, Veronika and Khrabrov, Kuzma and Kadurin, Artur and Savchenko, Andrey and Tutubalina, Elena},
  booktitle={The Second Tiny Papers Track at ICLR 2024}
}

@inproceedings{liu-etal-2023-molca,
    title = "{M}ol{CA}: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter",
    author = "Liu, Zhiyuan  and
      Li, Sihang  and
      Luo, Yanchen  and
      Fei, Hao  and
      Cao, Yixin  and
      Kawaguchi, Kenji  and
      Wang, Xiang  and
      Chua, Tat-Seng",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    year = "2023",
}

@article{su2022momu,
  title={A molecular multimodal foundation model associating molecule graphs with natural language},
  author={Su, Bing and Du, Dazhao and Yang, Zhao and Zhou, Yujie and Li, Jiangmeng and Rao, Anyi and Sun, Hao and Lu, Zhiwu and Wen, Ji-Rong},
  journal={arXiv:2209.05481},
  year={2022}
}

@inproceedings{edwards-etal-2022-molt5,
    title = "Translation between Molecules and Natural Language",
    author = "Edwards, Carl  and
      Lai, Tuan  and
      Ros, Kevin  and
      Honke, Garrett  and
      Cho, Kyunghyun  and
      Ji, Heng",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    year = "2022",
}

@inproceedings{christofidellis2023text+chemt5,
  title={Unifying molecular and textual representations via multi-task language modelling},
  author={Christofidellis, Dimitrios and Giannone, Giorgio and Born, Jannis and Winther, Ole and Laino, Teodoro and Manica, Matteo},
  booktitle={International Conference on Machine Learning},
  year={2023},
}

@article{zeng2022kvplm,
  title={A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals},
  author={Zeng, Zheni and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong},
  journal={Nature communications},
  volume={13},
  number={1},
  pages={862},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{luo2023molfm,
  title={Molfm: A multimodal molecular foundation model},
  author={Luo, Yizhen and Yang, Kai and Hong, Massimo and Liu, Xing Yi and Nie, Zaiqing},
  journal={arXiv preprint arXiv:2307.09484},
  year={2023}
}

@article{liu2024gitmol,
  title={Git-mol: A multi-modal large language model for molecular science with graph, image, and text},
  author={Liu, Pengfei and Ren, Yiming and Tao, Jun and Ren, Zhixiang},
  journal={Computers in biology and medicine},
  volume={171},
  pages={108073},
  year={2024},
  publisher={Elsevier}
}

@book{favre2013iupac,
  title={Nomenclature of organic chemistry: IUPAC recommendations and preferred names 2013},
  author={Favre, Henri A and Powell, Warren H},
  year={2013},
  publisher={Royal Society of Chemistry}
}

@article{zheng2023llmasajudge,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{morgan1965morgan,
  title={The generation of a unique machine description for chemical structures-a technique developed at chemical abstracts service.},
  author={Morgan, Harry L},
  journal={Journal of chemical documentation},
  volume={5},
  number={2},
  pages={107--113},
  year={1965},
  publisher={ACS Publications}
}

@article{wei2022CoT,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{gu2021domain,
  title={Domain-specific language model pretraining for biomedical natural language processing},
  author={Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal={ACM Transactions on Computing for Healthcare (HEALTH)},
  volume={3},
  number={1},
  pages={1--23},
  year={2021},
  publisher={ACM New York, NY}
}

@article{lee2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}

@article{beltagy2019scibert,
  title={SciBERT: A pretrained language model for scientific text},
  author={Beltagy, Iz and Lo, Kyle and Cohan, Arman},
  journal={arXiv preprint arXiv:1903.10676},
  year={2019}
}

@misc{rajan2021stout,
  title={STOUT: SMILES to IUPAC names using neural machine translation. J Cheminform 131: 34},
  author={Rajan, K and Zielesny, A and Steinbeck, C},
  year={2021}
}

@article{rajan2024stout2,
  title={STOUT V2. 0: SMILES to IUPAC name conversion using transformer models},
  author={Rajan, Kohulan and Zielesny, Achim and Steinbeck, Christoph},
  journal={Journal of Cheminformatics},
  volume={16},
  number={1},
  pages={146},
  year={2024},
  publisher={Springer}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={Internation Conference on Learning Representations},
  year={2021}
}

@article{wei2010uspto,
  title={A novel measure for evaluating classifiers},
  author={Wei, Jin-Mao and Yuan, Xiao-Jie and Hu, Qing-Hua and Wang, Shu-Qin},
  journal={Expert Systems with Applications},
  volume={37},
  number={5},
  pages={3799--3809},
  year={2010},
  publisher={Elsevier}
}

@article{velez2024tdc,
  title={Signals in the Cells: Multimodal and Contextualized Machine Learning Foundations for Therapeutics},
  author={Velez-Arce, Alejandro and Lin, Xiang and Li, Michelle and Huang, Kexin and Gao, Wenhao and Fu, Tianfan and Pentelute, Bradley L and Kellis, Manolis and Zitnik, Marinka},
  journal={Advances in Neural Information Processing Systems Workshop on AI for New Drug Modalities},
  year={2024}
}

@article{loshchilov2017adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, I},
  journal={International Conference on Learning Representations},
  year={2019}
}

@article{heseltine1995adenosineinsulin,
  title={Adenosine effects upon insulin action on lipolysis and glucose transport in human adipocytes},
  author={Heseltine, Lesley and Webster, Judith M and Taylor, Roy},
  journal={Molecular and cellular biochemistry},
  volume={144},
  pages={147--151},
  year={1995},
  publisher={Springer}
}

@article{wang2024adenosineimmune,
  title={The inhibitory effect of adenosine on tumor adaptive immunity and intervention strategies},
  author={Wang, Longsheng and Zhang, Jie and Zhang, Wenxin and Zheng, Mingming and Guo, Hongjie and Pan, Xiaohui and Li, Wen and Yang, Bo and Ding, Ling},
  journal={Acta Pharmaceutica Sinica B},
  volume={14},
  number={5},
  pages={1951--1964},
  year={2024},
  publisher={Elsevier}
}

@article{dall2003adenosineneuroprotection,
  title={Neuroprotection by caffeine and adenosine A2A receptor blockade of $\beta$-amyloid neurotoxicity},
  author={Dall'lgna, Oscar P and Porci{\'u}ncula, Lisiane O and Souza, Diogo O and Cunha, Rodrigo A and Lara, Diogo R},
  journal={British journal of pharmacology},
  volume={138},
  number={7},
  pages={1207--1209},
  year={2003},
  publisher={Wiley Online Library}
}

@article{xu2020benzodiazepinepyridine,
  title={Discovery of pyridine tetrahydroisoquinoline thiohydantoin derivatives with low blood-brain barrier penetration as the androgen receptor antagonists},
  author={Xu, Xi and Du, Qianming and Meng, Ying and Li, Zhiyu and Wu, Hongxi and Li, Yan and Zhao, Zhili and Ge, Raoling and Lu, Xiaoyu and Xue, Siqi and others},
  journal={European Journal of Medicinal Chemistry},
  volume={192},
  pages={112196},
  year={2020},
  publisher={Elsevier}
}


@article{golani2022benzodiazepinehalogen,
  title={Rationalizing the binding and $\alpha$ subtype selectivity of synthesized imidazodiazepines and benzodiazepines at GABAA receptors by using molecular docking studies},
  author={Golani, Lalit K and Mian, Md Yeunus and Ahmed, Taukir and Pandey, Kamal P and Mondal, Prithu and Sharmin, Dishary and Rezvanian, Sepideh and Witkin, Jeffrey M and Cook, James M},
  journal={Bioorganic \& Medicinal Chemistry Letters},
  volume={62},
  pages={128637},
  year={2022},
  publisher={Elsevier}
}

@article{wu2023bbbstructure,
  title={The blood--brain barrier: structure, regulation, and drug delivery},
  author={Wu, Di and Chen, Qi and Chen, Xiaojie and Han, Feng and Chen, Zhong and Wang, Yi},
  journal={Signal Transduction and Targeted Therapy},
  volume={8},
  number={1},
  pages={217},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{serhan2014polyene,
  title={The polyene antifungals, amphotericin B and nystatin, cause cell death in Saccharomyces cerevisiae by a distinct mechanism to amphibian-derived antimicrobial peptides},
  author={Serhan, George and Stack, Colin M and Perrone, Gabriel G and Morton, Charles Oliver},
  journal={Annals of clinical microbiology and antimicrobials},
  volume={13},
  pages={1--4},
  year={2014},
  publisher={Springer}
}