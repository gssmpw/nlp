
\section{Preliminaries}\label{sec:preliminaries}



%We denote by $(\Ac(x_\Ac),\Bc(x_\Bc))(z)$ a random execution of $\pi$ with private inputs $(x_\Ac,y_\Ac)$, and common input $z$.

%\Jnote{Move to DP}
% At the end of such an execution, the protocol outputs a public transcript denoted by the random variable $\trans_\pi(x_\Ac,x_\Ac,z)$ we denotes the common as $\out(\trans_\pi(x_\Ac,x_\Ac,z)$, and each party $\Pc \in \set{\Ac,\Bc}$ obtains his view denoted $\view^\Pc_\pi(x_\Ac,x_\Bc,z)$, which may also contain a ``local output'' \Jnote{Local} $\out^\Pc(x_\Ac,x_\Bc,z)$ (if the protocol specifies such an output). \Jnote{Common output, and parties output}


\subsection{Distributions and Random Variables}\label{sec:prelim:dist}
The support of a distribution $P$ over a finite set $\cS$ is defined by $\Supp(P) \eqdef \set{x\in \cS: P(x)>0}$. For a distribution or a random variable $D$, let $d\from D$ denote that $d$ was sampled according to $D$. Similarly,  for a set $\cS$, let $x \from \cS$ denote that $x$ is drawn uniformly from $\cS$, and denote by $\cU_{\cS}$ the uniform distribution over $\cS$. For a finite set $\cX$ and a distribution $C_X$ over $\cX$, we use the capital letter $X$ to denote the random variable that takes values in $\cX$ and is sampled according to $C_X$. The {\sf statistical distance} (\aka {\sf~variation distance}) of two distributions $P$ and $Q$ over a discrete domain $\cX$ is defined by $\sdist{P}{Q} \eqdef \max_{\cS\subseteq \cX} \size{P(\cS)-Q(\cS)} = \frac{1}{2} \sum_{x \in \cS}\size{P(x)-Q(x)}$. 
For a vector $x = (x_1,\ldots,x_n)$ and index $i\in [n]$, we let $x_{-i} = (x_1,\ldots,x_{i-1},x_{i+1},\ldots,x_n)$ and $x^{(i)} = (x_1,\ldots,x_{i-1}, -x_i, x_{i+1},\ldots,x_n)$, for a set $\cS \subseteq [n]$ we let $x_{\cS} = (x_i)_{i \in \cS}$ and $x_{-\cS} = (x_i)_{i \in [n]\setminus \cS}$, and for a vector $r \in \zo^n$ we let $x_r = (x_i)_{\set{i \colon r_i = 1}}$ and $x_{-r} = (x_i)_{\set{i \colon r_i = 0}}$.

%For $n \in \N$ we let $U_n$ be the uniform distribution over $\oo^n$, and let $S_n$ be the distribution induces by the sum of $n$ i.i.d.\ random variables, each is distributed according to $U_1$. Let $\cN(0,1)$ be the standard normal distribution.
%For a distribution $\cD$ and a function $f$, we define by $f(\cD)$ the distribution that is induced by the output of $f(x)$ for $x \from \cD$. 





% \begin{theorem}[\cite{McGregorMPRTV10}]\label{thm:sv-extracotr}
% 	\Enote{Remove if not needed}
% 	There is a constant $c$ to make the following holds. Let $X$ be an $\alpha$-SV source on $\{0,1\}^n$, let $Y$ be a source on $\{0,1\}^n$ with min-entropy at least $\beta n$ (independent from $X$), and let $Z=\ip{X,Y}\mbox{mod m}$ for some $m\in\mathbb{N}$. Then for every $\delta\in[0,1]$, the random variable $(Y,Z)$ is $\delta$-close to $(Y,U)$ where $U$ is uniform on $\mathbb{Z}_m$ and independent of $Y$, provided that
% 	$$
% 	n\geq c\cdot\frac{m^2}{\alpha\beta}\cdot\log(\frac{m}{\beta})\cdot\log(\frac{m}{\delta}).
% 	$$
% \end{theorem}



\Enote{I removed the definition of DP since it already appears in the intro}
\remove{
\subsection{Differential Privacy}\label{sec:prelim:DP}
We use the following standard definition of (information theoretic) differential privacy, due to \citet{DMNS06}. For notational convenience, we focus on databases over $\oo$.
\begin{definition}[Differentially private mechanisms]\label{def:mech}
	A randomized function $f\colon\oo^n\mapsto \zs$ is an {\sf $n$-size, $(\eps,\delta)$-differentially private mechanism} (denoted $(\eps,\delta)$-\DP) if for every neighboring $w,w'\in \oo^n$ and every function $g\colon \zs\mapsto \zo$, it holds that 
	$$
	\pr{g(f(w))=1}\leq e^{\eps}\cdot \pr{g(f(w'))=1} +\delta.
	$$ 	
	If $\delta=0$, we omit it from the notation.
\end{definition}
}


\subsubsection{Computational Differential Privacy}
There are several ways for defining computational differential privacy (see \cref{sec:related-works}). We use the most relaxed version due to \cite{BNO08}. For notational convenience, we focus on databases over $\oo$.
\begin{definition}[Computational differentially private mechanisms]\label{def:ComMech}
	A randomized function ensemble $f=\set{f_\pk\colon\oo^{n(\pk)}\mapsto \zs}$ is an {\sf $n$-size, $(\eps,\delta)$-computationally differentially private} (denoted $(\eps,\delta)$-$\CDP$) if for every poly-size circuit family $\set{\Ac_\pk}_{\pk\in \N}$, the following holds for every large enough $\pk$ and every neighboring $w,w'\in\oo^{n(\pk)}$:
	$$
	\pr{\Ac_\pk(f_\pk(w))=1}\leq e^{\eps(\pk)}\cdot \pr{\Ac_\pk(f_\pk(w'))=1} +\delta(\pk).
	$$ 
	If $\delta(\pk) = \negl(\pk)$, we omit it from the notation. 
\end{definition}



\subsubsection{Two-Party Differential Privacy}\label{sec:DP}
In this section we formally define distributed differential privacy mechanism (\ie protocols). %For the ease of notation, we consider protocol with no common input.

\begin{definition}\label{def:DP}%\Nnote{fix security parameter}
	A two-party protocol $\Pi=(\Ac,\Bc)$ is {\sf $(\eps,\delta)$-differentially private}, denoted $(\eps,\delta)$-$\DP$, if the following holds for every algorithm $\Dc$: let $\V^\Pc(x,y)(\pk)$ be the view of party $\Pc$ in a random execution of $\Pi(x,y)(1^\pk)$. Then for every $\pk,n \in \N$, $x\in \oo^n$ and neighboring $y,y'\in\oo^n$:
	\begin{align*}
	\pr{\Dc(V^\Ac(x,y)(\pk))=1}\le e^{\eps(\pk)}\cdot \pr{\Dc(V^\Ac (x,y')(\pk))=1}+\delta(\pk),
	\end{align*} 
	and for every $y\in \oo^n$ and neighboring $x,x'\in\oo^{n}$:
	\begin{align*}
	\pr{\Dc(V^\Bc(x,y)(\pk))=1}\le e^{\eps(\pk)}\cdot \pr{\Dc(V^\Bc (x',y)(\pk))=1}+\delta(\pk).
	\end{align*} 	
	Protocol $\Pi$ is {\sf $(\eps,\delta)$-computational differentially private}, denoted $(\eps,\delta)$-$\CDP$, if the above inequalities only hold for a non-uniform \ppt $\Dc$ and large enough $\pk$. We omit $\delta = \negl(\pk)$ from the notation. \footnote{Note that define we give for two-party differentially private protocols is a semi-honest definition, in which we ask for the security to hold when the parties interact in an honest execution of the protocol. Since we are proving a lower bound, starting from this weaker guarantee (as opposed to security against malicious players), yields a stronger result.}
\end{definition}
%We omit $\delta$ from the notation if $\delta$ is a negligible function of $n$.

%\Enote{simulation-based}
\begin{remark}[The definition for computational differential privacy we use]\label{rem:comDPChannel} 
	An alternative, stronger definition of computational differential privacy, known as simulation-based computational differential privacy, requires that the distribution of each partyâ€™s view be computationally indistinguishable from a distribution that ensures privacy in an information-theoretic sense. \cref{def:DP} is a weaker notion in comparison. Consequently, establishing a lower bound for a protocol that satisfies this weaker guarantee (as we do in this work) yields a stronger result.%Actually, our lower bound only requires the privacy to hold against \emph{uniform} external observer.
	%\Nnote{Maybe add: When only interesting in \Dp against external observer, the two definitions can be achieve using key-agreement and (single-party) \Dp mechanism. }
\end{remark}




\subsection{Useful Claims}
\remove{
In this section, we state generic lemmas and propositions that we will use later in our proofs.

The following lemma which we prove in \cref{sec:missing-proofs:distance-I}, measures the distance between two uniform stings conditioned one a random index $i$ either being fixed to $0$ or to $1$.

\def\distanceILemma{
    Let $R \la \zo^n$. For any (randomized) function $f:\{0,1\}^n\rightarrow \{0,1\}$ and $\alpha > 0$, it holds that
    \begin{align}\label{eq:f-alpha}
        \ppr{i \la [n]}{\size{\:\ex{f(R) \mid R_i = 0}-\ex{f(R) \mid R_i = 1}\:}\geq \alpha} \leq \frac{2}{n \alpha^2},
    \end{align}
    where the expectations are taken over $R$ and the randomness of $f$.
}

\begin{lemma}\label{lem:distance-I}
    \distanceILemma
\end{lemma}
}

The following two propositions state that given the output of a differentially private function, it is not possible to predict well even a random index (even if all other indexes are leaked). The first proposition handles the information-theoretic case and the second handles the computation case. Both propositions are proven in \cref{sec:missing-proofs:hard-to-guess}. 

\def\propHardToGuessInf{
    Let $f\colon \oo^n \rightarrow \cY$ be an $(\eps,\delta)$-\DP function, let $g \colon [n] \times \oo^{n-1} \times \cY \rightarrow \set{-1,1,\bot}$ be a (randomized) function, and let $X = (X_1,\ldots,X_n) \la \oo^n$. Then the following holds for every $i \in [n]$ where $X_i^* = g(i,X_{-i},f(X_1,\ldots,X_n))$:
    \begin{align*}
        \pr{X_i^* = X_i} \leq e^{\eps}\cdot \pr{X_i^* = -X_i} + \delta.
    \end{align*}
}

\begin{proposition}\label{prop:hard-to-guess-inf}
    \propHardToGuessInf
\end{proposition}


\def\propHardToGuessComp{
    Let $f = \set{f_{\pk} \colon \oo^{n(\pk)} \rightarrow \zo^{m(\pk)}}_{\pk \in \bbN}$ be an $(\eps,\delta)$-\CDP function ensemble, and let $\set{g_{\pk}}_{\pk \in \bbN}$ be a poly-size circuit family. Then, for large enough $\pk$ and $X = (X_1,\ldots,X_{n(\pk)}) \la \oo^{n(\pk)}$, the following holds for every $i \in [n(\pk)]$ where $X_i^* = g_{\pk}(i,X_{-i},f_{\pk}(X_1,\ldots,X_n))$:
    \begin{align*}
        \pr{X_i^* = X_i} \leq e^{\eps(\pk)}\cdot \pr{X_i^* = -X_i} + \delta(\pk).
    \end{align*}
}

\begin{proposition}\label{prop:hard-to-guess-comp}
    \propHardToGuessComp
\end{proposition}





\remove{
\Enote{Chao's old statement:}
\begin{lemma}\label{lem:distance-I-old}
        Let $R \la \zo^n$. 
	For any function $f:\{0,1\}^n\rightarrow \{0,1\}$ and $\alpha<0.01$, it holds that
	$$
	\Pr_{i\la[n]}\left[\: \size{\:\mathbb{E}[f(R) \mid R_i = 0]-\mathbb{E}[f(R) \mid R_i = 1]\:}\geq \alpha\right]\leq \frac{2+2\log(\frac{1}{\alpha})}{n\alpha^2}.
	$$
\end{lemma}
\begin{proof}
	Define $S_1=\{r \in \zo^n \colon f(r)=1\}$. Then for any $i\in[n]$, we have
	$$
	\begin{array}{rl}
		\size{\mathbb{E}[f(R) \mid R_i = 0]-\mathbb{E}[f(R) \mid R_i = 1]}
		&=\size{\Pr[R\in S_1|R_i=0]-\Pr[R\in S_1|R_i=1]}\\
		&=\size{\frac{\Pr[R_i=0|R\in S_1]\cdot\Pr[R\in S_1]}{\Pr[R_i=0]}-\frac{\Pr[R_i=1|R\in S_1]\cdot\Pr[R\in S_1]}{\Pr[R_i=1]}}\\
		&=\frac{2\size{S_1}}{2^n}\size{\Pr[R_i=0|R\in S_1]-\Pr[R_i=1|R\in S_1]}
	\end{array}
	$$
	When $|S_1|\leq \alpha\cdot 2^{n-1}$, we have $\size{\mathbb{E}[f(R) \mid R_i = 0]-\mathbb{E}[f(R) \mid R_i = 1]}\leq\frac{2\size{S_1}}{2^n}\leq \alpha$ for any $i\in[n]$. Hence, in the following, we assume $|S_1|> \alpha\cdot 2^{n-1}$.

	%Define $I_{bad}=\{i|\size{\Pr[R_i=0|R\in S_1]-\Pr[R_i=1|R\in S_1]}>2\alpha\}$ and $k=\size{I_{bad}}$, then for any $i\notin I_{bad}$, we have 
    %$$
    %\begin{array}{rl}
    %    2\alpha&\geq \size{\Pr[R_i=0|R\in S_1]-\Pr[R_i=1|R\in S_1]}\\
    %    &=\size{\frac{\Pr[R\in S_1|R_i=0]\cdot\Pr[R_i=0]}{\Pr[R\in S_1]}-\frac{\Pr[R\in S_1|R_i=1]\cdot\Pr[R_i=1]}{\Pr[R\in S_1]}}\\
    %    &=\size{\Pr[R\in S_1|R_i=0]-\Pr[R\in S_1|R_i=1]}\cdot\frac{1}{2\Pr[R\in S_1]}\\
    %    &\geq \size{\mathbb{E}[f(R) \mid R_i = 0]-\mathbb{E}[f(R) \mid R_i = 1]}\cdot \frac{1}{2},
    %\end{array}
    %$$ 
    %where the last inequality is because $\Pr[R\in S_1]\leq 1$. So that $\size{\mathbb{E}}[f(R) \mid R_i = 0]-\mathbb{E}[f(R) \mid R_i = 1]\leq %4\alpha$.
    Define $I_{bad}=\{i \colon \size{\Pr[R_i=0|R\in S_1]-\Pr[R_i=1|R\in S_1]} \geq 2\alpha\}$ and $k=\size{I_{bad}}$, and denote $I_{bad}=\{i_1,\dots,i_k\}$. Define $(X_{i_1}, \ldots X_{i_k}) = (R_{i_1},\dots,R_{i_k})\mid_{R \in S_1}$. 
    Consider the min-entropy
	$$
	\begin{array}{rl}
		H_{min}(X_{i_1},\dots,X_{i_k})&\leq H(X_{i_1},\dots,X_{i_k})\\
		&\leq \sum_{j=1}^k H(X_{i_j})\\
		&\leq k\cdot \left(-(\frac{1}{2}+2\alpha)\cdot\log(\frac{1}{2}+2\alpha)-(\frac{1}{2}-2\alpha)\cdot\log(\frac{1}{2}-2\alpha)\right)\\
            &=k\cdot \left(-(\frac{1}{2}+2\alpha)\cdot(\log(1+4\alpha)-1)-(\frac{1}{2}-2\alpha)\cdot(\log(1-4\alpha)-1)\right)\\
            &=k\cdot \left(1-(\frac{1}{2}+2\alpha)\cdot\log(1+4\alpha)-(\frac{1}{2}-2\alpha)\cdot\log(1-4\alpha)\right),
		
	\end{array}
	$$
	where $H_{min}(Y)$ is the minimum entropy of $Y$ and $H(Y)$ is the Shannon entropy of $Y$.\Enote{add to preliminaries.}
        The third inequality holds since by the definition of $I_{bad}$, for every $j \in [k]$ it holds that $\size{\pr{X_{i_j} = 1}-\pr{X_{i_j} = 0}} > 2\alpha$, and therefore $H(X_{i_j}) \leq H(1/2 + 2\alpha)$\Enote{define}.
	
	Therefore, there exists $b_1,\dots,b_k\in\{0,1\}$, such that 
	
	\begin{align}\label{eq:min-entropy-result}
		\Pr\left[(R_{i_1},\ldots,R_{i_k}) = (b_1,\ldots,b_k) \mid R\in S_1\right]
		&= \pr{(X_{i_1},\ldots,X_{i_k}) = (b_1,\ldots,b_k)}\\
		&= 2^{-H_{min}(X_{i_1},\dots,X_{i_k})}\nonumber\\
		&\geq 2^{k\cdot \left(-1+(\frac{1}{2}+2\alpha)\cdot\log(1+4\alpha)+(\frac{1}{2}-2\alpha)\cdot\log(1-4\alpha)\right)}.\nonumber
	\end{align}
	
	Let $S_{bad}=\{r \in \zo^n  \colon \set{(r_{i_1},\ldots,r_{i_k}) = (b_1,\ldots,b_k)} \land \set{r\in S_1}\}$.
	It holds that
	\begin{align*}
		|S_{bad}|
		&= \size{S_1} \cdot \Pr\left[(R_{i_1},\ldots,R_{i_k}) = (b_1,\ldots,b_k) \mid R\in S_1\right]\\
		&\geq \alpha\cdot 2^{n-1}\cdot2^{k\cdot \left(-1+(\frac{1}{2}+2\alpha)\cdot\log(1+4\alpha)+(\frac{1}{2}-2\alpha)\cdot\log(1-4\alpha)\right)},
	\end{align*} 
	where the inequality holds by \cref{eq:min-entropy-result} and since $\size{S_1} \geq \alpha\cdot 2^{n-1}$.
	Notice that any string in $S_{bad}$ depends on at most $n-k$ bits. It implies that $|S_{bad}|\leq 2^{n-k}$. Therefore, we have
	$$
	\begin{array}{rl}
		&2^{n-k}\geq \alpha\cdot 2^{n-1}\cdot2^{k\cdot \left(-1+(\frac{1}{2}+2\alpha)\cdot\log(1+4\alpha)+(\frac{1}{2}-2\alpha)\cdot\log(1-4\alpha)\right)} \\
		\Rightarrow& n-k \geq \log \alpha+n-1+k\cdot \left(-1+(\frac{1}{2}+2\alpha)\cdot\log(1+4\alpha)+(\frac{1}{2}-2\alpha)\cdot\log(1-4\alpha)\right)\\
		\Rightarrow& 1-\log \alpha \geq k\cdot((\frac{1}{2}+2\alpha)\cdot\log(1+4\alpha)+(\frac{1}{2}-2\alpha)\cdot\log(1-4\alpha))\\
		\Rightarrow& 1-\log \alpha \geq k\cdot(4\alpha\cdot\log(1+4\alpha)+(\frac{1}{2}-2\alpha)\cdot\log(1-16\alpha^2))\\
        \Rightarrow& 1-\log\alpha \geq k\cdot(15.9\alpha^2-8\alpha^2+32\alpha^3)=k\cdot(7.9\alpha^2+32\alpha^3)>0.5k\alpha^2\\
		\Rightarrow& k\leq \frac{2-2\log \alpha}{\alpha^2} = \frac{2+2\log (1/\alpha)}{\alpha^2},
	\end{array}
	$$
	Where the third transition holds since 
	\begin{align*}
		\lefteqn{(\frac{1}{2}+2\alpha)\cdot\log(1+4\alpha)+(\frac{1}{2}-2\alpha)\cdot\log(1-4\alpha)}\\
		&= 4\alpha\cdot\log(1+4\alpha) + (\frac{1}{2}-2\alpha)\paren{\log(1+4\alpha)+\log(1-4\alpha)}\\
		&= 4\alpha\cdot\log(1+4\alpha)+(\frac{1}{2}-2\alpha)\cdot\log(1-16\alpha^2),
	\end{align*}
	and the forth transition holds since $4\alpha\cdot\log(1+4\alpha)+(\frac{1}{2}-2\alpha)\cdot\log(1-16\alpha^2) > 15.9\alpha^2-8\alpha^2+32\alpha^3$ for $\alpha < 0.01$.
	Thus, we conclude that 
	$$
	\Pr_{i\la[n]}\left[\size{\mathbb{E}[f(R) \mid R_i=0]-\mathbb{E}[f(R) \mid R_i = 1]}\geq \alpha\right]\leq \frac{k}{n}\leq \frac{2+2\log (1/\alpha)}{n\alpha^2}.
	$$
\end{proof}
}


\subsection{Channels and Two-Party Protocols}\label{sec:protocol}

\paragraph{Channels.}A channel is simply a distribution of a pair of tuples defined as follows. 
\begin{definition}[Channels]\label{def:channel} A {\sf channel} $C_{(X,U)(Y,V)}$ of size $\isize$ over alphabet $\Sigma$ is a probability distribution over $(\Sigma^\isize \times\zo^\ast) \times(\Sigma^\isize \times\zo^\ast)$. The ensemble $C_{(X,U)(Y,V)}= \set{C_{(X_\pk,U_\pk)(Y_\pk,V_\pk)}}_{\pk\in \N}$ is an $\isize$-size channel ensemble, if for every $\pk\in \N$, $C_{(X_\pk,U_\pk)(Y_\pk,V_\pk)}$ is an $\isize(\pk)$-size channel. %We denote a channel of size one by a \emph{single-bit} channel. 
We refer to $X$ and $Y$ as the {\sf local outputs}, and to $U$ and $V$ as the {\sf views}.	
\end{definition}

We view a  channel as the experiment in which there are two parties $\Ac$ and $\Bc$.  Party $\Ac$ receives ``output'' $X$ and ``view'' $U$, and party $\Bc$ receives ``output'' $Y$ and ``view'' $V$. Unless stated otherwise, the channels we consider are over the alphabet $\Sigma = \oo$. We naturally identify channels with the distribution that characterizes their output.








\subsubsection{Two-Party Protocols}

A two-party protocol $\Pi=(\Ac,\Bc)$ is \ppt if the running time of both parties is polynomial in their input length. We let $\Pi(x,y)(z)$ or $(\Ac(x),\Bc(y))(z)$ denote a random execution of $\Pi$ on a common input $z$, and private inputs $x,y$.%We assume \wlg that a protocol has a common output (part of its transcript).\Jnote{This is not really the case we consider in this paper..}

\begin{definition}[Oracle-aided protocols]\label{def:ChannelAidedProtocol}
	In a two-party protocol $\Pi$ with oracle access to a {\sf protocol} $\Psi$, denoted $\Pi^\Psi$, the parties make use of the \textit{next-message function} of $\Psi$.\footnote{The function that on a partial view of one of the parties, returns its next message.} In a two-party protocol $\Pi$ with oracle access to a {\sf channel} $C_{Z W}$, denoted $\Pi^C$, the parties can jointly invoke $C$ for several times. In each call, an independent pair $(z,w)$ is sampled according to $C_{Z W}$, one party gets $z$, the other gets $w$.
\end{definition}


\begin{definition}[The channel of a protocol]\label{def:ChannlOfProtocol}
	For a no-input two-party protocol $\Pi= (\Ac,\Bc)$, we associate the channel $C_\Pi$, defined by $\C_\Pi= C_{(X, U),(Y, V)}$, where $X$ and $Y$ are the local outputs of $\Ac$ and $\Bc$ (respectively) and
	$U$ and $V$ are the local views of $\Ac$ and $\Bc$ (respectively).
    
	For a two-party protocol $\Pi$ that gets a security parameter $1^\pk$ as its (only, common) input, we associate the channel ensemble $ \set{C_{\Pi(1^\pk)}}_{\pk\in \N}$. 
\end{definition}

\begin{definition}[$(\alpha,\gamma)$-Accurate channel]\label{def:accurate-func}
	A channel $C = C_{(X, U),(Y, V)}$ is {\sf $(\alpha,\gamma)$-accurate for the function $f$}, if $\ppr{C}{\size{\out(V)-f(X,Y)}\leq \alpha}\ge \gamma$, where $\out(V)$ is the designated output.
    A channel ensemble $C_{(X, U),(Y, V)}= \set{C_{(X_\pk, U_\pk),(Y_\pk, V_\pk)}}_{\pk\in \N}$ is  $(\alpha,\gamma)$-accurate for  $f$ if $C_{(X_\pk, U_\pk),(Y_\pk, V_\pk)}$ is $(\alpha(\pk),\gamma(\pk))$-accurate for $f$, for every $\pk \in \N$.
\end{definition}

\subsubsection{Differentially Private Channels}\label{sec:DPChannel}
Differentially private channels are naturally defined as follows:
\begin{definition}[Differentially private channels]\label{def:DPChannel}
	An $n$-size channel $C = C_{(X, U),(Y, V)}$ with $X, Y$ over $\oo^n$ 
	is {\sf$(\eps,\delta)$-differentially private} (denoted $(\eps,\delta)$-$\DP$) if for every $x \in \Supp(X)$ there exists an $n$-size $(\eps,\delta)$-$\DP$ mechanisms $\Mc_x$ such that $(X,Y,U) \equiv (X,Y,\Mc_X(Y))$, and for every $y \in \Supp(Y)$ there exists an $n$-size $(\eps,\delta)$-$\DP$ mechanisms $\Mc_y'$ such that $(X,Y,V) \equiv (X,Y,\Mc_Y'(X))$. In addition, we say that the channel is \emph{uniform} if $X$ and $Y$ are independent random variables uniformly distributed in $\oo^n$. 
\end{definition}

\begin{definition}[Computational differentially private channels]\label{def:CDPChannel}
	An $n$-size channel ensemble $C = \set{C_{(X_\pk, U_\pk),(Y_\pk, V_\pk)}}_{\pk\in\N}$ with $X_\pk, Y_\pk$ over $\oo^n$ 
	is {\sf$(\eps,\delta)$-computationally differentially private} (denoted $(\eps,\delta)$-$\CDP$) if for every ensemble $\set{x_\pk \in \Supp(X_\pk)}_{\pk\in\N}$ there exists an $n$-size $(\eps,\delta)$-\CDP mechanisms ensemble $\set{\Mc_{x_\pk}}_{\pk\in\N}$ such that $(X_\pk,Y_\pk,U_\pk) \equiv (X_\pk,Y_\pk,\Mc_{X_\pk}(Y_\pk))$, for every $\pk\in\N$, and for every ensemble $\set{y_\pk \in \Supp(Y_\pk)}_{\pk\in\N}$ there exists an $n$-size $(\eps,\delta)$-$\CDP$ mechanisms ensemble $\set{\Mc'_{y_\pk}}_{\pk\in\N}$ such that $(X_\pk,Y_\pk,V_\pk) \equiv (X_\pk,Y_\pk,\Mc_{Y_\pk}'(X_\pk))$ for every $\pk\in \N$. In addition, we say that the channel is \emph{uniform} if $X_\pk$ and $Y_\pk$ are independent random variables uniformly distributed in $\{\pm 1\}^n$ for all $\pk\in\N$.
\end{definition}




% \begin{lemma}~\label{lem:dp-sv-source}
% 	Let $P$ be an $\varepsilon$-DP randomized protocol. Let $X$ and $Y$ be independent random variables uniformly distributed in $\{\pm 1\}^n$ and let random variable $\Pi(X,Y)$ denote the transcript of running $P(X,y)$. Then for every $\pi\in Supp(\Pi)$, the random variables corresponding to the inputs conditioned on transcript $\pi$, $X_\pi$ and $Y_\pi$, are independent $e^{-\varepsilon}$-strong SV source.
% \end{lemma}





\subsubsection{Weak Erasure Channel (\WEC)}

\begin{definition}[\WEC]\label{def:WEC}
	A channel $((O_A,V_A), (O_B,V_B))$ with $O_A \in \set{0,1}$ and $O_B \in \set{0,1,\bot}$ is a {\sf weak erasure channel}, denoted $(\alpha,p,q)$-$\WEC$, if:
	\begin{itemize}
		%\item $O_A\in \set{-1,1}$ and $O_B\in \set{-1,1,\bot}$.
		\item Random erasure: $\pr{O_B = \perp} = 1/2$.
		
		\item Agreement: $\pr{O_A\ne O_B\mid O_B\ne \bot}\le \alpha$.
		
		\item Secrecy:
		
		\begin{enumerate}
			\item For every algorithm $\Dc$ it holds that\label{WEC:item:A}
			\begin{align*}
				%\size{\pr{\Ac(O_A,V_A) = 1 \mid O_B \neq \perp} - \pr{\Ac(O_A,V_A) = 1 \mid O_B = \perp}} \le p
				\size{\pr{\Dc(V_A) = 1 \mid O_B \neq \perp} - \pr{\Dc(V_A) = 1 \mid O_B = \perp}} \le p
			\end{align*}
			(Alice doesn't know if $O_B = \perp$.)
			
			\item For every algorithm $\Dc$ it holds that\label{WEC:item:B}
			\begin{align*}
				\pr{\Dc(V_B) = O_A \mid O_B=\bot} \leq \frac{1+q}{2}.
			\end{align*}
			(i.e., if $O_B=\bot$, Bob don't know what is the value of $O_A$).
			
			%\item $SD((O_A U|O_B=\bot),(O_A U|O_B\ne \bot))\le p$ (The sender don't know if $O_B=\bot$).
			
			%\item $SD(V O_A|O_B=\bot,V(-O_A)|O_B=\bot)\le q$ (If $O_B=\bot$, Bob don't know what the value of $O_A$).
		\end{enumerate}
	\end{itemize}
   We say that a channel ensemble $C=\set{C_\pk}_{\pk\in N}$ is a {\sf computational weak erasure channel}, denoted $(\alpha,p,q)$-\CompWEC, if for every \ppt algorithm $\Dc$ and every sufficiently large $\pk\in\N$, $C_\pk$ satisfies the properties stated in the items above, where the secrecy property holds with respect to a \ppt algorithm $\Dc$. A protocol $\Lambda$ is said to be $(\alpha,p,q)$-$\CompWEC$, if the ensemble induces by the protocol (that is, $C=\set{C_{\Lambda(\pk)}}_{\pk\in\N}$) is $(\alpha,p,q)$-$\CompWEC$.  
\end{definition}



\subsubsection{Approximate Weak Erasure Channel (\AWEC)}\label{sec:AWEC}

\begin{definition}[\AWEC]\label{def:AWEC}
	A channel $C = ((O_A,V_A), (O_B,V_B))$ over $([-n,n] \times \zo^*) \times (([-n,n] \cup \bot)  \times \zo^*)$ is an {\sf approximate weak erasure channel}, denoted $(\ell,\alpha,p,q)$-\AWEC if:
	\begin{itemize}
		
		\item Random erasure: $\pr{O_B = \perp} = 1/2$.
		
		\item Accuracy: $\pr{\size{O_A - O_B} > \ell \mid O_B \ne \bot}\le \alpha$.
		
		\item Secrecy:
		
		\begin{enumerate}
			\item For every algorithm $\Dc$ it holds that\label{AWEC:item:A}
			\begin{align*}
				%\size{\pr{\Ac(O_A,V_A) = 1 \mid O_B \neq \perp} - \pr{\Ac(O_A,V_A) = 1 \mid O_B = \perp}} \le p
				\size{\pr{\Dc(V_A) = 1 \mid O_B \neq \perp} - \pr{\Dc(V_A) = 1 \mid O_B = \perp}} \le p
			\end{align*}
			(Alice doesn't know if $O_B=\bot$).
			
			\item For every algorithm $\Dc$ it holds that\label{AWEC:item:B}
			\begin{align*}
				\pr{\size{\Dc(V_B) - O_A} \leq 1000 \ell \mid O_B=\bot} \leq q.
			\end{align*}
			(i.e., if $O_B=\bot$, Bob can't estimate the value of $O_A$ with error $\leq 1000 \ell$).
		\end{enumerate}
	\end{itemize}
     We say that a channel ensemble $C=\set{C_\pk}_{\pk\in N}$ is a {\sf computational approximate weak erasure channel}, denoted $(\ell,\alpha,p,q)$-\CompAWEC, if for every \ppt algorithm $\Dc$ and every sufficiently large $\pk\in\N$, $C_\pk$ satisfies the properties stated in the items above. A protocol $\Gamma$ is said to be $(\ell,\alpha,p,q)$-$\CompAWEC$, if the ensemble induced by the protocol (that is, $C=\set{C_{\Gamma(\pk)}}_{\pk\in\N}$) is $(\ell,\alpha,p,q)$-$\CompAWEC$.  
\end{definition}

We will make use of the following lemma, which shows that for some choices of the parameters, \AWEC implies \WEC. The lemma is proven in \cref{sec:AWEC-to-WEC}.

\begin{lemma}\label{lemma:AWEC-to-WEC}
	For every $\ell> 0$, there exists a \ppt protocol $\Lambda = (\Pc_1,\Pc_2)$ such that given an oracle access to an $(\ell,\alpha,p,q)$-\AWEC $C$, the channel $\tilde{C}$ induced by $\Lambda^C$ is $(\alpha'=\alpha+0.001,\: p' = p ,\:  q' = 1/2 + 2(q+0.01))$-\WEC.
	Furthermore, the proof is constructive in a black-box manner:
	\begin{enumerate}
		\item There exists an oracle-aided \ppt algorithm $\Ec_1$ such that for every channel $C = ((\OA,\VA), (\OB,\VB))$ and algorithm $\Dc$ violating the \WEC secrecy property~\ref{WEC:item:A} of $\tilde{C}$, algorithm $\Ec_1^{\Dc}$ violates the \AWEC secrecy property~\ref{AWEC:item:A} of $C$.
		
		\item There exists an oracle-aided \ppt algorithm $\Ec_2$ such that for every channel $C = ((\OA,\VA), (\OB,\VB))$ and algorithm $\Dc$ violating the \WEC secrecy property~\ref{WEC:item:B} of $\tilde{C}$, algorithm $\Ec_2^{\Dc}$ violates the \AWEC secrecy property~\ref{AWEC:item:B} of $C$.
	\end{enumerate}
\end{lemma}

Since \cref{lemma:AWEC-to-WEC} is constructive, the following is an immediate corollary.
\begin{corollary}\label{cor:CompAWEC to CompWEC}
There exists an oracle aided \ppt protocol $\Lambda$, such that given a protocol $\Gamma$ that induces $(\ell,\alpha,p,q)$-\CompAWEC, it holds that $\Lambda^\Gamma$ is $(\alpha'=\alpha+0.001,\: p' = p ,\:  q' = 1/2 + 2(q+0.01))$-\CompWEC.  
\end{corollary}
\begin{proof}[Proof of \ref{cor:CompAWEC to CompWEC}]
Let $\Lambda$ be the \ppt algorithm guaranteed  by Lemma \ref{lemma:AWEC-to-WEC}. Given an $(\ell,\alpha,p,q)$-\CompAWEC protocol $\Gamma$, we define $\Lambda(\pk)={\Lambda^{\Gamma(\pk)}(\pk)}$. Assume towards a contradiction that $\Lambda$ is not a $(\alpha',p',q')$-\CompWEC. It follows that there exists a \ppt $\Dc$ that for infinity many $\pk\in\N$ contradicts one of the \WEC secrecy properties of channel ensemble $\set{C_{\Lambda(\pk)}}_{\pk\in\N}$. Fix $\pk\in\N$ for which this holds. By Lemma \ref{lemma:AWEC-to-WEC}, there exists a \ppt $\Ec^\Dc$ that for every such $\pk$  contradicts one of the secrecy properties of the channel $C_{\Gamma(\pk)}$. This implies that for infinity many $\pk\in\N$, $\Ec^\Dc$  contradict the secrecy of the channel ensemble $\set{C_{\Gamma(\pk)}}_{\pk\in\N}$, which is a contradiction since this would means that $\Gamma$ is not a $(\ell,\alpha,p,q)$-\CompAWEC.       
\end{proof}



\subsection{Oblivious Transfer (\OT)}

\paragraph{Secure Computation.}
We use the standard notion of securely computing a functionality, \cf  \cite{Goldreich04}.
\begin{definition}[Secure computation]\label{def:SFE}
	A two-party protocol {\sf securely computes a functionality $f$}, if it does so according to the real/ideal paradigm.   We add the term perfectly/statistically/computationally/non-uniform computationally, if the simulator's output is  perfect/statistical/computationally indistinguishable/  non-uniformly indistinguishable from  the real distribution.  The protocol have the above notions of security {\sf against semi-honest  adversaries}, if its security only  guaranteed to holds against an adversary that follows the prescribed protocol.   Finally, for the case of perfectly secure computation, we naturally apply the above notion also to the non-asymptotic case: the protocol with no security parameter perfectly  compute a functionality $f$.
	
	A two-party protocol {\sf securely computes a functionality ensemble $f$ with oracle to a channel $C$}, if it does so according to the above definition when the parties have access to a trusted party computing $C$. All the above adjectives naturally extend to this setting.
\end{definition}

\paragraph{Oblivious Transfer.}
The (one-out-of-two) oblivious transfer functionality is defined as follows.
\begin{definition}[oblivious transfer functionality $f_{\OT}$]\label{def:OTfunc}
	The oblivious transfer functionality over $\zo \times (\zs)^2$ is defined by  $f_{\OT} (i,(\sigma_0,\sigma_1)) = (\perp,\sigma_i)$.
\end{definition}
A protocol is $\ast$ secure OT,   for \\$\ast\in \set{\text{semi-honest statistically/computationally/computationally non-uniform}}$, if it  compute the $f_{\OT}$  functionality with $\ast$ security.





% \begin{definition}[Computational oblivious transfer, semi-honest model]
% A protocol $\Pi=(\Ac,\Bc)$ is a semi-honest 1-out-of-2 computational oblivious transfer (comp-OT) protocol if the following holds. Given a common input $1^{\pk}$, the parties $\Ac$ and $\Bc$ run the protocol $\Pi(1^\pk)$ (in an honest manner) and    
% $\Ac$ outputs $X=(m_1,m_2)\in \zo\times\zo$ and has a view $U$ and $\Bc$ outputs $Y=(i,\hat{m})\in\zo\times\zo$ and has a view $V$, and the following properties are satisfied:
% \begin{enumerate}
%     \item \textbf{Correctness:} 
%     $\pr{\hat{m}\neq m_i}<\negl(\pk).$ 
    
%     \item \textbf{A's Privacy:} For every \ppt $\Dc$ and every sufficiently large $\pk$:
%     $\pr{\Dc(V)=m_{i-1}}<(1+\negl(\pk))/2$
    
%     \item \textbf{B's Privacy:} For every \ppt $\Dc$ and every sufficiently large $\pk$:
%     $\pr{\Dc(U)=i}<(1+\negl(\pk))/2$  
% \end{enumerate}
% \end{definition}

We make use of the following useful results by Wullschleger on oblivious transfer amplification from weak channels.
\begin{theorem}[\cite{Wullschleger09}, from \WEC to statistically secure \OT]\label{thm:WEC TO OT IT}
    There exists an oracle aided protocol $\Pi$ such that the following holds: Given a $(\alpha,p,q)$-\WEC $C$, if $44(\alpha+p)\le 1-q$ then $\Pi^{C}(1^\pk)$ is a semi-honest statistically secure \OT.
\end{theorem}

The following computational version of \cref{thm:WEC TO OT IT} is implicit in \cite{Wullschleger09} and is based on the computational proof explicitly stated in \cite{Wul07} (see Section 6 in \cite{Wullschleger09} for discussion).   

\begin{theorem}[\cite{Wullschleger09,   Wul07}, from \CompWEC to computinally secure \OT]\label{thm:WEC TO OT Comp}
    There exists an oracle aided protocol $\Pi$ such that the following holds: Given a $(\alpha,p,q)$-\CompWEC protocol $\Lambda$, if $44(\alpha+p)\le 1-q$ then $\Pi^{\Lambda}$ is a semi-honest computational secure \OT.
\end{theorem}



% \begin{definition}[Computational 1-out-of-2 Oblivious Transfer, semi-honest model]
% A protocol $\Pi=(\Ac,\Bc)$ is a semi-honest 1-out-of-2 $(\eps,\alpha,\beta)$-oblivious transfer (OT) protocol if the following holds. 

% The parties $\Ac$ and $\Bc$ run the protocol (in an honest manner) and    
% $\Ac$ outputs $X=(m_1,m_2)\in \zo\times\zo$ and has a view $U$ and $\Bc$ outputs $Y=(i,\hat{m})\in\zo\times\zo$ and has a view $V$, and following properties are satisfied:
% \begin{enumerate}
%     \item \textbf{Correctness:} 
%     $\pr{\hat{m}\neq m_i}<\eps.$ 
    
%     \item \textbf{A's Privacy:} For every adversary $\Dc$:
%     $\pr{\Dc(V)=m_{i-1}}<(1+\alpha)/2$
    
%     \item \textbf{B's Privacy:} For every adversary $\Dc$: $\pr{\Dc(U)=i}<(1+\beta)/2$  
% \end{enumerate}
% \end{definition}