\section{Related Works}
\label{sec:related-works}

\textbf{Computational differential privacy.} Computational differential privacy ($\CDP$) can be defined using two primary approaches.
The more flexible and widely used approach is the \emph{indistinguishability-based} definition, which limits the distinguished $g$ in \cref{def:intro:DP}, to those that are computationally efficient. The second approach, known as the \emph{simulation-based} definition, requires that the output distribution of the mechanism $f$ be computationally indistinguishable from that of an (information-theoretic) differentially private mechanism. Various relationships between these and other privacy definitions have been established in Dwork et al., "Our Data, Ourselves: A dozen years of data driven life"  (a more updated survey is provided in Bun et al., "Upper and lower bounds for local differential privacy"). We remark that our result holds for the weaker definition of indistinguishability-based $\CDP$, which makes it stronger. As a corollary, we also get the equivalence of the power of the definitions for the inner-product task we consider (in our accuracy regime).\Nnote{(maybe put it as n open questions for other two-party tasks?

\textbf{\CDP in the centralized model.} In the single-party scenario (\ie the centralized model), computational and information-theoretic differential privacy appear to be more closely aligned. Specifically, Dwork et al., "Preserving Statistical Validity in Adaptive Data Analysis" demonstrated that a broad class of $\CDP$ mechanisms can be converted into an information-theoretic $\DP$ mechanism. On the other hand, Balle et al., "The Foundational Proof Systems for Accumulator-Based Cryptography" showed that under certain non-standard and very-strong cryptographic assumptions, there exist somewhat contrived tasks that can be efficiently solved with $\CDP$, but remain infeasible (Dwork et al., "A Framework of Finite Sample Approximations to Bayesian Inference") or impossible (Valiant and Valiant, "Nash Social Welfare, Maximin Shares, and Risk Measures") under information-theoretic $\DP$. It still remains open whether such separations exist under more standard cryptographic assumptions and for more natural tasks.

\textbf{\CDP in the local model.} At the other end of the spectrum, the \emph{local model} is highly relevant in practical applications. In this setting, each of the (typically many) participants holds a single data element. Protocols achieving information-theoretic $\DP$ in this model often rely on randomized response, which has been shown to be optimal for counting functions, including inner product, as proven by Dinur and Nissim, "Revealing Information While Preserving Privacy". In contrast, local $\CDP$ protocols can leverage secure multiparty computation to simulate any efficient single-party mechanism, thereby demonstrating a fundamental gap between the power of $\CDP$ and information-theoretic $\DP$.\Nnote{We should be more careful here - there are MPC protocol for 3 players with information-theoretic security} We remark that there exist other approaches to bridge this by relaxing the distributed model, e.g., using a trusted shuffler Evfimievski et al., "Private Set Intersection for k-parties" (see McSherry and Mironov, "Differentially Private Autocorrelation"), or partially trusted servers that enable more accurate estimations using weaker and more practical cryptographic tools than secure multi-party computation (e.g., Gentry et al., "A Technique for Implementing Zero-Knowledge Proofs of Knowledge").

\textbf{Two-Party \CDP.} In the two-party (or small-party) setting, the complexity of $\CDP$ protocols is much less clear. Prior works have maintly focused on Boolean functionalities, where each party holds a single sensitive bit, and the objective is to compute a Boolean function over these bits while preserving privacy (\eg XOR). Ostrovsky et al., "Single-Client Private Assessments of Machine Learning Models" established that, for any non-trivial Boolean functionality, there is a fundamental gap in accuracy between what can be achieved in the centralized and distributed settings. Moreover, any $\CDP$ protocol that surpasses this accuracy gap would imply the existence of one-way functions. Later, Hirt et al., "Efficient Secure Multiparty Computation" demonstrated that an accurate enough $\CDP$ protocol for the XOR function would inherently imply an oblivious transfer protocol. Building on this, Damgard and Nielsen, "Secure Multi-party Computation with Failures" proved that any meaningful $\eps$-\CDP two-party protocol for XOR necessarily implies an (infinitely-often) key agreement protocol. Ishai et al., "Private Circuits and Plaintext Equivalence" refined and extended the results of Damgard and Nielsen, showing that any non-trivial $\CDP$ protocol for XOR implies oblivious transfer.

Beyond Boolean functionalities, the complexity of $\CDP$ protocols for more general tasks such as computing low-sensitivity many-bit functions like the inner product remains largely unexplored. The only exceptions are the work of Gentry et al., "A Technique for Implementing Zero-Knowledge Proofs of Knowledge" who applied a generic reduction to the impossibility result of Dwork et al., "A Framework of Finite Sample Approximations to Bayesian Inference", concluding that no accurate $\CDP$ protocol for inner product can exist in the \textit{random oracle model}, and more recently, the work of Bitansky et al., "Secure Computation on Private Circuits" who showed that any non-trivial $\CDP$ inner-product protocol implies a key-agreement protocol. But none of these results close the gap to $\OT$, and thus, our result provide the first tight characterization (with respect to assumptions) of a natural, non-boolean functionality.