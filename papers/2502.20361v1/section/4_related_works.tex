\section{Related Works}

\subsection{TAD Frameworks}

The absence of a standardized framework for temporal action detection has historically led researchers to either develop methods from scratch or build upon specific open-source implementations. While some methods have provided partial foundations, they remain limited in scope. For example, GTAD~\cite{xu2020g} was implemented on top of BMN~\cite{lin2019bmn} and was later adopted by subsequent works such as TSI~\cite{liu2020tsi} and BC-GNN~\cite{bai2020boundary}. However, these methods are tailored to specific designs and lack the flexibility to accommodate broader innovations. Additionally, adapting a feature-based method (e.g., \cite{zhao2021video}) to an end-to-end training paradigm (e.g., \cite{zhao2023re2tal}) often requires extensive and tedious code modifications, such as restructuring feature extraction and training components. This lack of interoperability hinders efficient experimentation and fair benchmarking.

Although several works have proposed distinct ``frameworks" for TAD, they primarily focus on specific paradigms rather than providing a truly unified solution. Examples include the \textit{one-stage framework} in TriDet~\cite{shi2023tridet}, the \textit{multi-level cross-scale framework} in VSGN~\cite{zhao2021video}, the \textit{end-to-end detection framework} in TadTR~\cite{liu2022end}, and the \textit{efficient end-to-end framework} in AdaTAD~\cite{liu2024adatad}. These frameworks are designed independently, making cross-method comparison and integration challenging. Some methods, such as BMN~\cite{lin2019bmn} and TSI~\cite{liu2020tsi}, describe their approaches as ``unified frameworks," but they primarily refer to the joint training of multiple components within a single model rather than a framework that accommodates diverse methodologies.

To address these limitations, OpenTAD introduces the first truly unified framework for TAD, integrating a broad range of approaches—including one-stage, two-stage, DETR-based, and end-to-end methods—within a single, cohesive implementation. By supporting both feature-based and end-to-end learning paradigms, OpenTAD simplifies the development, adaptation, and evaluation of new methods, ensuring a standardized and extensible platform for future research.

\subsection{TAD Surveys}

Several survey papers on temporal action detection provide comprehensive overviews of various methods~\cite{wang2023temporal, hu2024overview, vahdani2022deep}. These reviews categorize TAD approaches based on the original modularization described in each paper and directly compare reported performance across different methods. However, they do not account for inconsistencies in experimental configurations, such as data resolution, preprocessing, and post-processing, which can lead to unfair comparisons and obscure the true effectiveness of individual techniques.

In contrast, OpenTAD offers a unified framework that systematically re-modularizes and reimplements existing methods to ensure consistency across different architectures and training pipelines. This standardization enables faithful comparison and rigorous analysis, providing deeper insights into the impact of specific design choices. Unlike previous survey papers, which evaluate methods based on heterogeneous configurations, OpenTAD facilitates direct, controlled comparisons under a unified setting. Furthermore, while prior reviews independently classify TAD methods into categories, OpenTAD integrates diverse approaches—including one-stage, two-stage, DETR-based, and end-to-end methods—into a single, cohesive implementation, enabling a more comprehensive and adaptable benchmarking platform.