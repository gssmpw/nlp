\section{Related Work}
\subsection{Multimodal Information Retrieval}
Early Multimodal Information Retrieval tasks focused on cross-modal retrieval of text and image____, where the goal is simply to retrieve captions of everyday images ____.
The scope has been extended to more complex scenarios, such as composed image retrieval ____, scientific contents ____, and visual documents ____.
Recent studies have been progressively exploring unified MIR settings ____.
For instance, M-BEIR ____ integrates various image and text-related retrieval tasks, while UMRB ____ further extends the evaluation to encompass more textual datasets and visual document retrieval ____.
However, these benchmarks are constrained by their limitation to single-image queries or texts ____, lacking support for multi-image and interleaved contents.
We construct a new text-image interleaved retrieval benchmark to meet the demands of complex multimodal RAG scenarios.

Current strong multimodal retrievers predominantly adopt the dense retrieval paradigm, which can be categorized into two main approaches: CLIP-style dual-stream models ____ and language model-centric architectures ____.
____ proposed to compute unified multimodal embeddings from frozen LLM, which is not specifically designed for TIIR but shows potential in the multimodal context to image search task.
A concurrent work ____ also explores interleaved embeddings for multimodal document retrieval, where a task-specific hierarchical encoder is suggested to retrieve interleaved documents parsed from Wikipedia webpage.
In this work, we introduce the more generalized MLLM-based embedding model and propose a novel Matryoshka Multimodal Embedder to address the challenge of excessive visual tokens, which is crucial for TIIR.


\subsection{Multimodal Interleaved Modeling}
The modeling of interleaved text and image has been explored in various aspects, such as pre-training models ____ and corpus ____.
Notably, there exists a parallel line of research focusing on unified models that simultaneously handle both interleaved representation and generation tasks ____.
Their experimental datasets are converted from existing multimodal generation datasets with interleaved context, \eg Visual Storytelling ____, and less retrieval-oriented.
Additionally, general interleaved corpus typically suffers from low knowledge density and logical coherence in image
sequence ____, which might not be suitable for constructing an interleaved retrieval benchmark.
In contrast, we build the TIIR dataset from human-curated high-quality tutorials (from wikiHow) for everyday skills, which are naturally interleaved and more informative for retrieval.