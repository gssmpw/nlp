@inproceedings{DBLP:conf/eccv/WeiCCHZFRC24,
  author       = {Cong Wei and
                  Yang Chen and
                  Haonan Chen and
                  Hexiang Hu and
                  Ge Zhang and
                  Jie Fu and
                  Alan Ritter and
                  Wenhu Chen},
  editor       = {Ales Leonardis and
                  Elisa Ricci and
                  Stefan Roth and
                  Olga Russakovsky and
                  Torsten Sattler and
                  G{\"{u}}l Varol},
  title        = {UniIR: Training and Benchmarking Universal Multimodal Information Retrievers},
  booktitle    = {Proceedings of 18th European Conference on Computer Vision},
  volume       = {15145},
  pages        = {387--404},
  publisher    = {Springer},
  year         = {2024},
  url          = {https://doi.org/10.1007/978-3-031-73021-4\_23},
  doi          = {10.1007/978-3-031-73021-4\_23},
  timestamp    = {Sun, 22 Dec 2024 15:47:59 +0100},
  biburl       = {https://dblp.org/rec/conf/eccv/WeiCCHZFRC24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/ijcai/CaoLLNZ22,
  author       = {Min Cao and
                  Shiping Li and
                  Juntao Li and
                  Liqiang Nie and
                  Min Zhang},
  editor       = {Luc De Raedt},
  title        = {Image-text Retrieval: {A} Survey on Recent Research and Development},
  booktitle    = {Proceedings of the Thirty-First International Joint Conference on
                  Artificial Intelligence, {IJCAI} 2022, Vienna, Austria, 23-29 July
                  2022},
  pages        = {5410--5417},
  publisher    = {ijcai.org},
  year         = {2022},
  url          = {https://doi.org/10.24963/ijcai.2022/759},
  doi          = {10.24963/IJCAI.2022/759},
  timestamp    = {Tue, 15 Oct 2024 16:43:28 +0200},
  biburl       = {https://dblp.org/rec/conf/ijcai/CaoLLNZ22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NEURIPS2022_960a172b,
 author = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob L and Borgeaud, Sebastian and Brock, Andy and Nematzadeh, Aida and Sharifzadeh, Sahand and Bi\'{n}kowski, Miko\l aj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Kar\'{e}n},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {23716--23736},
 publisher = {Curran Associates, Inc.},
 title = {Flamingo: a Visual Language Model for Few-Shot Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/960a172bc7fbf0177ccccbb411a7d800-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{faysse2024colpali,
  title={Colpali: Efficient document retrieval with vision language models},
  author={Faysse, Manuel and Sibille, Hugues and Wu, Tony and Omrani, Bilel and Viaud, Gautier and Hudelot, C{\'e}line and Colombo, Pierre},
  journal={arXiv preprint arXiv:2407.01449},
  year={2024},
  url = {https://arxiv.org/pdf/2407.01449},
}

@inproceedings{huang-etal-2016-visual,
    title = "Visual Storytelling",
    author = "Huang, Ting-Hao Kenneth  and
      Ferraro, Francis  and
      Mostafazadeh, Nasrin  and
      Misra, Ishan  and
      Agrawal, Aishwarya  and
      Devlin, Jacob  and
      Girshick, Ross  and
      He, Xiaodong  and
      Kohli, Pushmeet  and
      Batra, Dhruv  and
      Zitnick, C. Lawrence  and
      Parikh, Devi  and
      Vanderwende, Lucy  and
      Galley, Michel  and
      Mitchell, Margaret",
    editor = "Knight, Kevin  and
      Nenkova, Ani  and
      Rambow, Owen",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1147/",
    doi = "10.18653/v1/N16-1147",
    pages = "1233--1239"
}

@article{jiang2024e5,
  title={E5-v: Universal embeddings with multimodal large language models},
  author={Jiang, Ting and Song, Minghui and Zhang, Zihan and Huang, Haizhen and Deng, Weiwei and Sun, Feng and Zhang, Qi and Wang, Deqing and Zhuang, Fuzhen},
  journal={arXiv preprint arXiv:2407.12580},
  year={2024},
  url={https://arxiv.org/abs/2407.12580}
}

@misc{koukounas2024jinaclipv2,
    title={jina-clip-v2: Multilingual Multimodal Embeddings for Text and Images}, 
    author={Andreas Koukounas and Georgios Mastrapas and Bo Wang and Mohammad Kalim Akram and Sedigheh Eslami and Michael GÃ¼nther and Isabelle Mohr and Saba Sturua and Scott Martens and Nan Wang and Han Xiao},
    year={2024},
    eprint={2412.08802},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2412.08802}, 
}

@inproceedings{laurenccon2023obelics,
  title={OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents},
  author={Lauren{\c{c}}on, Hugo and Saulnier, Lucile and Tronchon, Leo and Bekman, Stas and Singh, Amanpreet and Lozhkov, Anton and Wang, Thomas and Karamcheti, Siddharth and Rush, Alexander M and Kiela, Douwe and others},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  url={https://proceedings.neurips.cc/paper_files/paper/2023/hash/e2cfb719f58585f779d0a4f9f07bd618-Abstract-Datasets_and_Benchmarks.html},
  year={2023}
}

@inproceedings{laurenccon2024building,
  title={Building and better understanding vision-language models: insights and future directions},
  author={Lauren{\c{c}}on, Hugo and Marafioti, Andr{\'e}s and Sanh, Victor and Tronchon, L{\'e}o},
  booktitle={Workshop on Responsibly Building the Next Generation of Multimodal Foundational Models},
  year={2024},
  url={https://openreview.net/pdf?id=iSL0FHZStr}
}

@article{lee2024unified,
  title={Unified Multi-Modal Interleaved Document Representation for Information Retrieval},
  author={Lee, Jaewoo and Ko, Joonho and Baek, Jinheon and Jeong, Soyeong and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:2410.02729},
  year={2024},
  url={https://arxiv.org/abs/2410.02729}
}

@inproceedings{li2024improving,
  title={Improving Context Understanding in Multimodal Large Language Models via Multimodal Composition Learning},
  author={Li, Wei and Fan, Hehe and Wong, Yongkang and Yang, Yi and Kankanhalli, Mohan},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
  url={https://openreview.net/pdf?id=Nm6jYZsBum}
}

@inproceedings{lin-etal-2024-preflmr,
    title = "{P}re{FLMR}: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers",
    author = "Lin, Weizhe  and
      Mei, Jingbiao  and
      Chen, Jinghong  and
      Byrne, Bill",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.289/",
    doi = "10.18653/v1/2024.acl-long.289",
    pages = "5294--5316",
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Proceedings of the 13th European Conference on Computer Vision},
  address = "Zurich, Switzerland",
  pages={740--755},
  year={2014},
  organization={Springer},
  url={https://link.springer.com/chapter/10.1007/978-3-319-10602-1\_48}
}

@inproceedings{liu2021image,
  title={Image retrieval on real-life images with pre-trained vision-and-language models},
  author={Liu, Zheyuan and Rodriguez-Opazo, Cristian and Teney, Damien and Gould, Stephen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2125--2134},
  year={2021},
  url={https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Image_Retrieval_on_Real-Life_Images_With_Pre-Trained_Vision-and-Language_Models_ICCV_2021_paper.pdf}
}

@inproceedings{liu2023universal,
  title={Universal Vision-Language Dense Retrieval: Learning A Unified Representation Space for Multi-Modal Retrieval},
  author={Liu, Zhenghao and Xiong, Chenyan and Lv, Yuanhuiyi and Liu, Zhiyuan and Yu, Ge},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=PQOlkgsBsik}
}

@inproceedings{ma-etal-2024-unifying,
    title = "Unifying Multimodal Retrieval via Document Screenshot Embedding",
    author = "Ma, Xueguang  and
      Lin, Sheng-Chieh  and
      Li, Minghan  and
      Chen, Wenhu  and
      Lin, Jimmy",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.373/",
    doi = "10.18653/v1/2024.emnlp-main.373",
    pages = "6492--6505",
}

@article{nussbaum2024nomic,
  title={Nomic Embed Vision: Expanding the Latent Space},
  author={Nussbaum, Zach and Duderstadt, Brandon and Mulyar, Andriy},
  journal={arXiv preprint arXiv:2406.18587},
  year={2024},
  url={https://arxiv.org/abs/2406.18587}
}

@InProceedings{pmlr-v202-koh23a,
  title = 	 {Grounding Language Models to Images for Multimodal Inputs and Outputs},
  author =       {Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {17283--17300},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/koh23a/koh23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/koh23a.html},
}

@inproceedings{wang-etal-2024-unified,
    title = "Unified Embeddings for Multimodal Retrieval via Frozen {LLM}s",
    author = "Wang, Ziyang  and
      Elfardy, Heba  and
      Dreyer, Markus  and
      Small, Kevin  and
      Bansal, Mohit",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.105/",
    pages = "1537--1547",
}

@inproceedings{wu-etal-2024-scimmir,
    title = "{S}ci{MMIR}: Benchmarking Scientific Multi-modal Information Retrieval",
    author = "Wu, Siwei  and
      Li, Yizhi  and
      Zhu, Kang  and
      Zhang, Ge  and
      Liang, Yiming  and
      Ma, Kaijing  and
      Xiao, Chenghao  and
      Zhang, Haoran  and
      Yang, Bohao  and
      Chen, Wenhu  and
      Huang, Wenhao  and
      Al Moubayed, Noura  and
      Fu, Jie  and
      Lin, Chenghua",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.746/",
    doi = "10.18653/v1/2024.findings-acl.746",
    pages = "12560--12574",
}

@article{young-etal-2014-image,
    title = "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
    author = "Young, Peter  and
      Lai, Alice  and
      Hodosh, Micah  and
      Hockenmaier, Julia",
    editor = "Lin, Dekang  and
      Collins, Michael  and
      Lee, Lillian",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "2",
    year = "2014",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q14-1006/",
    doi = "10.1162/tacl_a_00166",
    pages = "67--78",
}

@article{zhang2024gme,
  title={GME: Improving Universal Multimodal Retrieval by Multimodal LLMs},
  author={Zhang, Xin and Zhang, Yanzhao and Xie, Wen and Li, Mingxin and Dai, Ziqi and Long, Dingkun and Xie, Pengjun and Zhang, Meishan and Li, Wenjie and Zhang, Min},
  journal={arXiv preprint arXiv:2412.16855},
  year={2024},
  url={https://arxiv.org/abs/2412.16855}
}

@article{zhang20252,
  title={2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining},
  author={Zhang, Wenqi and Zhang, Hang and Li, Xin and Sun, Jiashuo and Shen, Yongliang and Lu, Weiming and Zhao, Deli and Zhuang, Yueting and Bing, Lidong},
  journal={arXiv preprint arXiv:2501.00958},
  year={2025},
  url={https://arxiv.org/abs/2501.00958}
}

@inproceedings{zhou-etal-2024-marvel,
    title = "{MARVEL}: Unlocking the Multi-Modal Capability of Dense Retrieval via Visual Module Plugin",
    author = "Zhou, Tianshuo  and
      Mei, Sen  and
      Li, Xinze  and
      Liu, Zhenghao  and
      Xiong, Chenyan  and
      Liu, Zhiyuan  and
      Gu, Yu  and
      Yu, Ge",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.783/",
    doi = "10.18653/v1/2024.acl-long.783",
    pages = "14608--14624",
}

@inproceedings{zhou-etal-2024-vista,
    title = "{VISTA}: Visualized Text Embedding For Universal Multi-Modal Retrieval",
    author = "Zhou, Junjie  and
      Liu, Zheng  and
      Xiao, Shitao  and
      Zhao, Bo  and
      Xiong, Yongping",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.175/",
    doi = "10.18653/v1/2024.acl-long.175",
    pages = "3185--3200",
}

@inproceedings{zhu2023multimodal,
  title={Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with Text},
  author={Zhu, Wanrong and Hessel, Jack and Awadalla, Anas and Gadre, Samir Yitzhak and Dodge, Jesse and Fang, Alex and Yu, Youngjae and Schmidt, Ludwig and Wang, William Yang and Choi, Yejin},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems: Datasets and Benchmarks Track},
  url = {https://openreview.net/forum?id=tOd8rSjcWz},
  year={2023}
}

@inproceedings{zou2024interfacing,
 author = {Zou, Xueyan and Li, Linjie and Wang, Jianfeng and Yang, Jianwei and Ding, Mingyu and Wei, Junyi and Yang, Zhengyuan and Li, Feng and Zhang, Hao and Liu, Shilong and others},
 booktitle = {Advances in Neural Information Processing Systems},
  title={Interfacing Foundation Models' Embeddings},
 url = {https://arxiv.org/pdf/2312.07532},
 volume = {37},
 year = {2024}
}

