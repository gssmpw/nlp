% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{lu2024deepseek-vl,
  title={Deepseek-vl: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Yang, Hao and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024},
  url={https://arxiv.org/abs/2403.05525}
}
@inproceedings{yang-etal-2021-visual,
    title = "Visual Goal-Step Inference using wiki{H}ow",
    author = "Yang, Yue  and
      Panagopoulou, Artemis  and
      Lyu, Qing  and
      Zhang, Li  and
      Yatskar, Mark  and
      Callison-Burch, Chris",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.165/",
    doi = "10.18653/v1/2021.emnlp-main.165",
    pages = "2167--2179",
}
@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  url={https://arxiv.org/abs/1807.03748},
  year={2018}
}
@inproceedings{laurenccon2024building,
  title={Building and better understanding vision-language models: insights and future directions},
  author={Lauren{\c{c}}on, Hugo and Marafioti, Andr{\'e}s and Sanh, Victor and Tronchon, L{\'e}o},
  booktitle={Workshop on Responsibly Building the Next Generation of Multimodal Foundational Models},
  year={2024},
  url={https://openreview.net/pdf?id=iSL0FHZStr}
}
@article{qwen2,
    title={Qwen2 Technical Report}, 
    author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
    journal={arXiv preprint arXiv:2407.10671},
    year={2024},
    url={https://arxiv.org/abs/2407.10671}
}
@misc{flux2023,
    author={Black Forest Labs},
    title={FLUX},
    year={2023},
    howpublished={\url{https://github.com/black-forest-labs/flux}},
}
@article{robertson2009probabilistic,
  title={The probabilistic relevance framework: BM25 and beyond},
  author={Robertson, Stephen and Zaragoza, Hugo and others},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  volume={3},
  number={4},
  pages={333--389},
  year={2009},
  publisher={Now Publishers, Inc.},
  url={https://www.nowpublishers.com/article/DownloadSummary/INR-019}
}
@article{shannon1948mathematical,
  title={A mathematical theory of communication},
  author={Shannon, Claude Elwood},
  journal={The Bell system technical journal},
  volume={27},
  number={3},
  pages={379--423},
  year={1948},
  publisher={Nokia Bell Labs}
}
@article{cai2024matryoshka,
  title={Matryoshka Multimodal Models},
  author={Cai, Mu and Yang, Jianwei and Gao, Jianfeng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2405.17430},
  year={2024},
  url={https://arxiv.org/abs/2405.17430}
}
@article{yin2023survey,
  title={A survey on multimodal large language models},
  author={Yin, Shukang and Fu, Chaoyou and Zhao, Sirui and Li, Ke and Sun, Xing and Xu, Tong and Chen, Enhong},
  journal={arXiv preprint arXiv:2306.13549},
  year={2023},
  url={https://arxiv.org/abs/2306.13549}
}

@inproceedings{chen-etal-2022-murag,
    title = "{M}u{RAG}: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text",
    author = "Chen, Wenhu  and
      Hu, Hexiang  and
      Chen, Xi  and
      Verga, Pat  and
      Cohen, William",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.375/",
    doi = "10.18653/v1/2022.emnlp-main.375",
    pages = "5558--5570",
}
@InProceedings{pmlr-v202-yasunaga23a,
  title = 	 {Retrieval-Augmented Multimodal Language Modeling},
  author =       {Yasunaga, Michihiro and Aghajanyan, Armen and Shi, Weijia and James, Richard and Leskovec, Jure and Liang, Percy and Lewis, Mike and Zettlemoyer, Luke and Yih, Wen-Tau},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {39755--39769},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/yasunaga23a/yasunaga23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/yasunaga23a.html},
}

@inproceedings{DBLP:conf/eccv/WeiCCHZFRC24,
  author       = {Cong Wei and
                  Yang Chen and
                  Haonan Chen and
                  Hexiang Hu and
                  Ge Zhang and
                  Jie Fu and
                  Alan Ritter and
                  Wenhu Chen},
  editor       = {Ales Leonardis and
                  Elisa Ricci and
                  Stefan Roth and
                  Olga Russakovsky and
                  Torsten Sattler and
                  G{\"{u}}l Varol},
  title        = {UniIR: Training and Benchmarking Universal Multimodal Information Retrievers},
  booktitle    = {Proceedings of 18th European Conference on Computer Vision},
  volume       = {15145},
  pages        = {387--404},
  publisher    = {Springer},
  year         = {2024},
  url          = {https://doi.org/10.1007/978-3-031-73021-4\_23},
  doi          = {10.1007/978-3-031-73021-4\_23},
  timestamp    = {Sun, 22 Dec 2024 15:47:59 +0100},
  biburl       = {https://dblp.org/rec/conf/eccv/WeiCCHZFRC24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ma-etal-2024-unifying,
    title = "Unifying Multimodal Retrieval via Document Screenshot Embedding",
    author = "Ma, Xueguang  and
      Lin, Sheng-Chieh  and
      Li, Minghan  and
      Chen, Wenhu  and
      Lin, Jimmy",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.373/",
    doi = "10.18653/v1/2024.emnlp-main.373",
    pages = "6492--6505",
}
@inproceedings{zhou-etal-2024-marvel,
    title = "{MARVEL}: Unlocking the Multi-Modal Capability of Dense Retrieval via Visual Module Plugin",
    author = "Zhou, Tianshuo  and
      Mei, Sen  and
      Li, Xinze  and
      Liu, Zhenghao  and
      Xiong, Chenyan  and
      Liu, Zhiyuan  and
      Gu, Yu  and
      Yu, Ge",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.783/",
    doi = "10.18653/v1/2024.acl-long.783",
    pages = "14608--14624",
}
@inproceedings{zhou-etal-2024-vista,
    title = "{VISTA}: Visualized Text Embedding For Universal Multi-Modal Retrieval",
    author = "Zhou, Junjie  and
      Liu, Zheng  and
      Xiao, Shitao  and
      Zhao, Bo  and
      Xiong, Yongping",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.175/",
    doi = "10.18653/v1/2024.acl-long.175",
    pages = "3185--3200",
}
@inproceedings{lin-etal-2024-preflmr,
    title = "{P}re{FLMR}: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers",
    author = "Lin, Weizhe  and
      Mei, Jingbiao  and
      Chen, Jinghong  and
      Byrne, Bill",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.289/",
    doi = "10.18653/v1/2024.acl-long.289",
    pages = "5294--5316",
}
@article{jiang2024e5,
  title={E5-v: Universal embeddings with multimodal large language models},
  author={Jiang, Ting and Song, Minghui and Zhang, Zihan and Huang, Haizhen and Deng, Weiwei and Sun, Feng and Zhang, Qi and Wang, Deqing and Zhuang, Fuzhen},
  journal={arXiv preprint arXiv:2407.12580},
  year={2024},
  url={https://arxiv.org/abs/2407.12580}
}
@article{lin2024mm,
  title={Mm-embed: Universal multimodal retrieval with multimodal llms},
  author={Lin, Sheng-Chieh and Lee, Chankyu and Shoeybi, Mohammad and Lin, Jimmy and Catanzaro, Bryan and Ping, Wei},
  journal={arXiv preprint arXiv:2411.02571},
  year={2024},
  url={https://arxiv.org/abs/2411.02571}
}
@article{zhang2024gme,
  title={GME: Improving Universal Multimodal Retrieval by Multimodal LLMs},
  author={Zhang, Xin and Zhang, Yanzhao and Xie, Wen and Li, Mingxin and Dai, Ziqi and Long, Dingkun and Xie, Pengjun and Zhang, Meishan and Li, Wenjie and Zhang, Min},
  journal={arXiv preprint arXiv:2412.16855},
  year={2024},
  url={https://arxiv.org/abs/2412.16855}
}
@inproceedings{zhang-etal-2024-mgte,
    title = "{mGTE}: Generalized Long-Context Text Representation and Reranking Models for Multilingual Text Retrieval",
    author = "Zhang, Xin  and
      Zhang, Yanzhao  and
      Long, Dingkun  and
      Xie, Wen  and
      Dai, Ziqi  and
      Tang, Jialong  and
      Lin, Huan  and
      Yang, Baosong  and
      Xie, Pengjun  and
      Huang, Fei  and
      Zhang, Meishan  and
      Li, Wenjie  and
      Zhang, Min",
    editor = "Dernoncourt, Franck  and
      Preo{\c{t}}iuc-Pietro, Daniel  and
      Shimorina, Anastasia",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track",
    month = nov,
    year = "2024",
    address = "Miami, Florida, US",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-industry.103/",
    doi = "10.18653/v1/2024.emnlp-industry.103",
    pages = "1393--1412",
}
@inproceedings{xiao2024cpack,
author = {Xiao, Shitao and Liu, Zheng and Zhang, Peitian and Muennighoff, Niklas and Lian, Defu and Nie, Jian-Yun},
title = {C-Pack: Packed Resources For General Chinese Embeddings},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657878},
doi = {10.1145/3626772.3657878},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {641–649},
numpages = {9},
keywords = {benchmark, pre-trained models, text embeddings, training data},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR},
  url={https://proceedings.mlr.press/v139/radford21a/radford21a.pdf}
}
@misc{koukounas2024jinaclipv2,
    title={jina-clip-v2: Multilingual Multimodal Embeddings for Text and Images}, 
    author={Andreas Koukounas and Georgios Mastrapas and Bo Wang and Mohammad Kalim Akram and Sedigheh Eslami and Michael Günther and Isabelle Mohr and Saba Sturua and Scott Martens and Nan Wang and Han Xiao},
    year={2024},
    eprint={2412.08802},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2412.08802}, 
}
@article{nussbaum2024nomic,
  title={Nomic Embed Vision: Expanding the Latent Space},
  author={Nussbaum, Zach and Duderstadt, Brandon and Mulyar, Andriy},
  journal={arXiv preprint arXiv:2406.18587},
  year={2024},
  url={https://arxiv.org/abs/2406.18587}
}


@InProceedings{Wu_2021_CVPR,
    author    = {Wu, Hui and Gao, Yupeng and Guo, Xiaoxiao and Al-Halah, Ziad and Rennie, Steven and Grauman, Kristen and Feris, Rogerio},
    title     = {Fashion IQ: A New Dataset Towards Retrieving Images by Natural Language Feedback},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {11307-11317},
    url = {https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Fashion_IQ_A_New_Dataset_Towards_Retrieving_Images_by_Natural_CVPR_2021_paper.html},
}


@inproceedings{zhu2023multimodal,
  title={Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with Text},
  author={Zhu, Wanrong and Hessel, Jack and Awadalla, Anas and Gadre, Samir Yitzhak and Dodge, Jesse and Fang, Alex and Yu, Youngjae and Schmidt, Ludwig and Wang, William Yang and Choi, Yejin},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems: Datasets and Benchmarks Track},
  url = {https://openreview.net/forum?id=tOd8rSjcWz},
  year={2023}
}
@inproceedings{laurenccon2023obelics,
  title={OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents},
  author={Lauren{\c{c}}on, Hugo and Saulnier, Lucile and Tronchon, Leo and Bekman, Stas and Singh, Amanpreet and Lozhkov, Anton and Wang, Thomas and Karamcheti, Siddharth and Rush, Alexander M and Kiela, Douwe and others},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  url={https://proceedings.neurips.cc/paper_files/paper/2023/hash/e2cfb719f58585f779d0a4f9f07bd618-Abstract-Datasets_and_Benchmarks.html},
  year={2023}
}


@inproceedings{DBLP:conf/ijcai/CaoLLNZ22,
  author       = {Min Cao and
                  Shiping Li and
                  Juntao Li and
                  Liqiang Nie and
                  Min Zhang},
  editor       = {Luc De Raedt},
  title        = {Image-text Retrieval: {A} Survey on Recent Research and Development},
  booktitle    = {Proceedings of the Thirty-First International Joint Conference on
                  Artificial Intelligence, {IJCAI} 2022, Vienna, Austria, 23-29 July
                  2022},
  pages        = {5410--5417},
  publisher    = {ijcai.org},
  year         = {2022},
  url          = {https://doi.org/10.24963/ijcai.2022/759},
  doi          = {10.24963/IJCAI.2022/759},
  timestamp    = {Tue, 15 Oct 2024 16:43:28 +0200},
  biburl       = {https://dblp.org/rec/conf/ijcai/CaoLLNZ22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Proceedings of the 13th European Conference on Computer Vision},
  address = "Zurich, Switzerland",
  pages={740--755},
  year={2014},
  organization={Springer},
  url={https://link.springer.com/chapter/10.1007/978-3-319-10602-1\_48}
}
@article{young-etal-2014-image,
    title = "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
    author = "Young, Peter  and
      Lai, Alice  and
      Hodosh, Micah  and
      Hockenmaier, Julia",
    editor = "Lin, Dekang  and
      Collins, Michael  and
      Lee, Lillian",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "2",
    year = "2014",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q14-1006/",
    doi = "10.1162/tacl_a_00166",
    pages = "67--78",
}
@inproceedings{wu-etal-2024-scimmir,
    title = "{S}ci{MMIR}: Benchmarking Scientific Multi-modal Information Retrieval",
    author = "Wu, Siwei  and
      Li, Yizhi  and
      Zhu, Kang  and
      Zhang, Ge  and
      Liang, Yiming  and
      Ma, Kaijing  and
      Xiao, Chenghao  and
      Zhang, Haoran  and
      Yang, Bohao  and
      Chen, Wenhu  and
      Huang, Wenhao  and
      Al Moubayed, Noura  and
      Fu, Jie  and
      Lin, Chenghua",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.746/",
    doi = "10.18653/v1/2024.findings-acl.746",
    pages = "12560--12574",
}
@article{faysse2024colpali,
  title={Colpali: Efficient document retrieval with vision language models},
  author={Faysse, Manuel and Sibille, Hugues and Wu, Tony and Omrani, Bilel and Viaud, Gautier and Hudelot, C{\'e}line and Colombo, Pierre},
  journal={arXiv preprint arXiv:2407.01449},
  year={2024},
  url = {https://arxiv.org/pdf/2407.01449},
}
@inproceedings{liu2021image,
  title={Image retrieval on real-life images with pre-trained vision-and-language models},
  author={Liu, Zheyuan and Rodriguez-Opazo, Cristian and Teney, Damien and Gould, Stephen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2125--2134},
  year={2021},
  url={https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Image_Retrieval_on_Real-Life_Images_With_Pre-Trained_Vision-and-Language_Models_ICCV_2021_paper.pdf}
}

@inproceedings{liu2023universal,
  title={Universal Vision-Language Dense Retrieval: Learning A Unified Representation Space for Multi-Modal Retrieval},
  author={Liu, Zhenghao and Xiong, Chenyan and Lv, Yuanhuiyi and Liu, Zhiyuan and Yu, Ge},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=PQOlkgsBsik}
}
@inproceedings{wang-etal-2024-unified,
    title = "Unified Embeddings for Multimodal Retrieval via Frozen {LLM}s",
    author = "Wang, Ziyang  and
      Elfardy, Heba  and
      Dreyer, Markus  and
      Small, Kevin  and
      Bansal, Mohit",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.105/",
    pages = "1537--1547",
}
@article{lee2024unified,
  title={Unified Multi-Modal Interleaved Document Representation for Information Retrieval},
  author={Lee, Jaewoo and Ko, Joonho and Baek, Jinheon and Jeong, Soyeong and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:2410.02729},
  year={2024},
  url={https://arxiv.org/abs/2410.02729}
}

@inproceedings{NEURIPS2022_960a172b,
 author = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob L and Borgeaud, Sebastian and Brock, Andy and Nematzadeh, Aida and Sharifzadeh, Sahand and Bi\'{n}kowski, Miko\l aj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Kar\'{e}n},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {23716--23736},
 publisher = {Curran Associates, Inc.},
 title = {Flamingo: a Visual Language Model for Few-Shot Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/960a172bc7fbf0177ccccbb411a7d800-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}


@InProceedings{pmlr-v202-koh23a,
  title = 	 {Grounding Language Models to Images for Multimodal Inputs and Outputs},
  author =       {Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {17283--17300},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/koh23a/koh23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/koh23a.html},
}
@inproceedings{li2024improving,
  title={Improving Context Understanding in Multimodal Large Language Models via Multimodal Composition Learning},
  author={Li, Wei and Fan, Hehe and Wong, Yongkang and Yang, Yi and Kankanhalli, Mohan},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
  url={https://openreview.net/pdf?id=Nm6jYZsBum}
}
@inproceedings{zou2024interfacing,
 author = {Zou, Xueyan and Li, Linjie and Wang, Jianfeng and Yang, Jianwei and Ding, Mingyu and Wei, Junyi and Yang, Zhengyuan and Li, Feng and Zhang, Hao and Liu, Shilong and others},
 booktitle = {Advances in Neural Information Processing Systems},
  title={Interfacing Foundation Models' Embeddings},
 url = {https://arxiv.org/pdf/2312.07532},
 volume = {37},
 year = {2024}
}
@inproceedings{huang-etal-2016-visual,
    title = "Visual Storytelling",
    author = "Huang, Ting-Hao Kenneth  and
      Ferraro, Francis  and
      Mostafazadeh, Nasrin  and
      Misra, Ishan  and
      Agrawal, Aishwarya  and
      Devlin, Jacob  and
      Girshick, Ross  and
      He, Xiaodong  and
      Kohli, Pushmeet  and
      Batra, Dhruv  and
      Zitnick, C. Lawrence  and
      Parikh, Devi  and
      Vanderwende, Lucy  and
      Galley, Michel  and
      Mitchell, Margaret",
    editor = "Knight, Kevin  and
      Nenkova, Ani  and
      Rambow, Owen",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1147/",
    doi = "10.18653/v1/N16-1147",
    pages = "1233--1239"
}
@article{zhang20252,
  title={2.5 Years in Class: A Multimodal Textbook for Vision-Language Pretraining},
  author={Zhang, Wenqi and Zhang, Hang and Li, Xin and Sun, Jiashuo and Shen, Yongliang and Lu, Weiming and Zhao, Deli and Zhuang, Yueting and Bing, Lidong},
  journal={arXiv preprint arXiv:2501.00958},
  year={2025},
  url={https://arxiv.org/abs/2501.00958}
}
@article{Chameleon_Team_Chameleon_Mixed-Modal_Early-Fusion_2024,
  author = {Chameleon Team},
  doi = {10.48550/arXiv.2405.09818},
  journal = {arXiv preprint arXiv:2405.09818},
  title = {Chameleon: Mixed-Modal Early-Fusion Foundation Models},
  url = {https://github.com/facebookresearch/chameleon},
  year = {2024}
}
@article{douze2024faiss,
      title={The Faiss library},
      author={Matthijs Douze and Alexandr Guzhva and Chengqi Deng and Jeff Johnson and Gergely Szilvasy and Pierre-Emmanuel Mazaré and Maria Lomeli and Lucas Hosseini and Hervé Jégou},
      year={2024},
      eprint={2401.08281},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{Label_Studio,
  title={{Label Studio}: Data labeling software},
  url={https://github.com/HumanSignal/label-studio},
  note={Open source software available from https://github.com/HumanSignal/label-studio},
  author={
    Maxim Tkachenko and
    Mikhail Malyuk and
    Andrey Holmanyuk and
    Nikolai Liubimov},
  year={2020-2025},
}