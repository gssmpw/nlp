\section{Unsupervised Data Filtering}~\label{sec:data_filter}
\begin{finding}
     Filtering self-improvement data using length-based filtering and majority voting is crucial for sustaining the self-improvement process while keeping the method general-purpose.
\end{finding}

\subsection{Motivation for Data Filtering}



\begin{wrapfigure}{r}{0.45\textwidth}
    \vspace{-11mm}
    \centering
    \includegraphics[width=0.43\textwidth]{fig/self_improve_accuracy_n_to_np1.pdf}
    \caption{Effect of self-generated data accuracy on length generalization performance in the reverse addition task. Each data point represents the accuracy of the self-improve data $\mathcal{D}_r$ (on $n$ digit addition) generated by model $M_{r-1}$, and the resulting $n+1$-digit performance of the trained model $M_r$ at round $r$. The prevalence of points below the $y=x$ line highlights the critical importance of high-quality data for successful self-improvement.}
    \vspace{-8mm}
    \label{fig:reverse_add_si}
\end{wrapfigure}

The self-improvement framework operates on the principle that the model can generalize slightly beyond the difficulty level it was trained on, incrementally generating self-improve data of increasing difficulty. %
A critical component for this framework to succeed is the quality of the self-generated data. Low-quality data can negatively impact the model’s generalization performance, leading to even lower-quality data in subsequent rounds and ultimately causing a cascading degradation of the self-improvement process.



Figure~\ref{fig:reverse_add_si} demonstrates this effect in the reverse addition task. The x-axis represents the accuracy of the self-improve dataset $\mathcal{D}_r$, generated by model $M_{r-1}$ at round $r$, while the y-axis shows the resulting $n+1$-digit performance of model $M_r$. The prevalence of data points below the $y=x$ line indicates that low-quality data diminishes performance, underscoring the need for maintaining high-quality data throughout the self-improvement process. These cascading error effects are analyzed in greater detail in Section~\ref{sec:error_analysis}. 



Additionally, we make the following observations: 
\paragraph{OOD Results are often Short. } A common error in model-generated data for tasks with higher difficulty than the training data is that the generated labels are often shorter than the correct answers. Figure~\ref{fig:num_shorter_answers} illustrates this phenomenon for both the reverse addition and CoT-multiplication tasks. In reverse addition (Left), as the number of digits in the training data increases (or as self-improvement rounds progress), the proportion of incorrect self-generated data where the answer is shorter than the correct label length also increases. Similarly, for CoT-multiplication (Mid and Right), most incorrect answers are shorter than the correct ones. Furthermore, in cases where the answers are shorter, the outputs often miss one or more reasoning steps in the chain-of-thought (CoT) reasoning process.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.3\linewidth]{fig/data_filtering/num_shorter_answers_ratios.pdf}
    \includegraphics[width=0.33\linewidth]{fig/mult/majority/mult_mv_num_incorrect_short_answer.pdf}
    \includegraphics[width=0.33\linewidth]{fig/mult/majority/mult_mv_avg_short_answer_len.pdf}
    \caption{OOD results are often short. (Left) Reverse addition task: the proportion of shorter answers among incorrect predictions increases with each round. (Mid \& Right) CoT-multiplication task with majority voting: (Mid) The majority of incorrect answers are short. (Right) The average length discrepancy of short answers compared to the correct answer or the CoT reasoning part.}
    \label{fig:num_shorter_answers}
\end{figure}

\paragraph{Leveraging Label Diversity with Majority Voting. }
Self-improvement relies on the model's ability to generalize to slightly harder problems. However, this generalization is not always robust and can vary significantly across different training instances~\citep{zhou2024transformers}. Majority voting mitigates this variability by aggregating predictions across multiple independently trained models, thereby improving the reliability of self-generated labels.

Figure~\ref{fig:majority_vote} demonstrates the effectiveness of majority voting in the multiplication task across five models trained with different seeds during the initial training phase on data \( \mathcal{D}_0 \), which consists of up to 5-by-5 multiplication problems. The mean accuracy (Left) is relatively low, with a high standard deviation (Mid), indicating substantial variability among the models. By applying majority voting with a consensus on at least 4 out of 5 model outputs, the generated dataset quality improves significantly (Right). For example, while the 5-by-6 multiplication task achieves an average accuracy of 31\% across models, the majority-voting strategy generates a dataset with 93.3\% accuracy\footnote{
In practice, datasets for larger multiplications, such as 5-by-6 digits, are created after multiple rounds of self-improvement training, gradually incorporating \( m \)-by-6 and 6-by-\( m \) data with incrementally increasing \( m \) at each round.}.

\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{fig/mult/multiplication_acc_std.pdf}
    \hspace{1mm}
    \includegraphics[width=0.3\linewidth]{fig/mult/multiplication_majority_voted_data.pdf}
    \caption{ Majority voting leverages label diversity. (Left \& Mid): Mean and standard deviation of accuracy among five models trained with different seeds on the initial training round. (Right): Accuracy of majority-voted data points. Majority voting significantly boosts data quality, with 5-by-6 multiplication data accuracy increasing from an average of 31\% to 93.3\% }
    \label{fig:majority_vote}
\end{figure}



\subsection{Data Filtering Methods}



We focus on two key data-filtering methods used in this work: length filtering and majority voting (illustrated in Figure~\ref{fig:data_filtering}).  For a given self-improved dataset \( \mathcal{D}_r = \{(x_i, M_{r-1}(x_i))\}_{i=1}^{N_r} \) at round \( r \), data is filtered based on specific criteria applied to the model-generated outputs \( M_{r-1}(x_i) \). This process produces a smaller, refined dataset \( \tilde{\mathcal{D}}_r = \{(x_i, M_{r-1}(x_i))\}_{i=1}^{\tilde{N}_r} \), which is then used for training in subsequent rounds. 

These filtering strategies are essential for sustaining the self-improvement framework and enabling effective generalization across diverse tasks, including forward addition, multiplication, and maze-solving.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.46\linewidth]{fig/DataFiltering_length_v2.pdf}
    \hspace{0.03\linewidth}
    \includegraphics[width=0.46\linewidth]{fig/DataFiltering_mv_v2.pdf}
    \caption{Overview of the two data-filtering methods employed. Length filtering removes data points with outputs shorter than a predefined threshold, relative to the maximum output length in the batch. Majority voting filters data based on consensus among predictions from multiple models trained with different random seeds. Both data filtering methods are \textit{unsupervised}. }
    \label{fig:data_filtering}
\end{figure}

\paragraph{Relative Length Filtering. } 
The observation that OOD results are often short motivates a filtering method based on the relative lengths of model-generated predictions. Specifically, predictions shorter than a predefined threshold—calculated relative to the maximum prediction length within their batch—are filtered out. For a batch of model-predicted outputs, we identify the maximum length of the output $L=\max |M_{r-1}(x_i)|$ and filter out predictions $M_{r-1}(x_i)$ with lengths shorter than a predefined threshold $\tau$. This method is \textit{unsupervised}, as it relies solely on comparing lengths within model-generated outputs rather than referencing ground-truth labels. While particularly suited to length generalization tasks, where harder problems are expected to yield longer answers, length-based filtering demonstrates broader potential for addressing similar challenges in other tasks.













\paragraph{Majority Voting. } 
Generating multiple candidate answers to ensure self-consistency is a widely used approach for enhancing data quality~\citep{huang2022large,wang2022self,qu2024recursive,peng2024regenesis}. However, unlike the common practice of sampling multiple reasoning paths by generating outputs with a non-zero temperature, our task of interest requires a single correct answer for each instance. To address this, we train \( k \) models (\( M_{r-1}^{(1)}, \cdots , M_{r-1}^{(k)} \)) using different random seeds and self-improvement data, then apply a majority-voting mechanism with a threshold \( \tau \). 

Specifically, for each self-improved dataset \( \mathcal{D}_r^{s} = \{(x_i, M_{r-1}^{(s)}(x_i))\}_{i=1}^{N_r} \) where $s$ is the seed index, we filter the data such that only pairs \( \{(x_i, M_{r-1}^{(s)}(x_i))\} \) where \( M_{r-1}^{(s)}(x_i) \) matches at least \( \lceil \tau \times k \rceil \) outputs among the \( k \) models are retained. This ensures that only high-consensus data are preserved for training in subsequent rounds, thereby significantly improving overall data quality and model performance. This approach is conceptually similar to an iterative version of the bagging algorithm~\citep{breiman1996bagging}, where reliable pseudo-labels are generated through ensemble agreement to handle harder instances. Ablation on majority voting is provided in Section~\ref{sec:mv_ablations}. 





