\section{Limitations}\label{sec:discussion}
In our framework, the model does not generate new input instances during self-improvement; it only generates solutions (labels) for training. When it is unfeasible to generate the problems themselves, modeling the input distribution conditioned on task difficulty becomes an additional challenge.

A key consideration in self-improvement is defining and quantifying task difficulty. In real-world domains such as mathematics and natural language tasks, formalizing "difficulty" remains an open question. Our experiments demonstrate that careful difficulty scheduling is crucial for effective self-improvement. However, we also find that models exhibit some robustness to difficulty slack—especially when trained on harder tasks (Section~\ref{sec:ood_increases}) and when leveraging pretrained models (Section~\ref{sec:pretrained}). %

Another fundamental assumption in our framework is that models can handle slightly harder tasks than those seen in training. While this holds in many structured tasks, there are cases where such generalization is inherently difficult. For example, training on raw multiplication problems without intermediate steps leads to poor OOD generalization, making self-improvement infeasible. However, we show that breaking down tasks into intermediate steps enables slight OOD generalization, which can be leveraged for self-improvement(Section~\ref{sec:mult}). This highlights the importance of designing task representations that align with a model’s inherent generalization capabilities.





