\section{Related Works}
\label{sec:related_work}

\paragraph{Length and Easy-to-hard Generalization.} 

Length generalization is concerned with extrapolating to longer sequence lengths than those seen during training____. Previous approaches to improve length generalization includes architectural modifications, including specialized positional embeddings____, looping____, novel attention mechanisms____, and input format augmentation____. Beyond arithmetic, ____ studies length generalization in graph tasks. In contrast, our approach adheres to the standard transformer architecture without introducing significant modifications to architecture, positional encoding, or input structure. While prior approaches typically rely on fixed-length training datasets without further updates to model weights, we iteratively update model weights on self-generated datasets, enabling the model to progressively improve and extend its generalization capabilities. 

More generally, easy-to-hard-generalization is the paradigm where human annotation is provided for easier tasks, but aiming to enable generalization to harder tasks with no additional supervision____. 
For instance, ____ study this \textit{transcendence} phenomenon in chess, showing that chess transformers can sometimes outperform all players in the training dataset. Similarly, ____ finds that a reward model trained on easier mathematical problems can be effectively transferred to harder problems, facilitating generalization through reinforcement learning. ____ identifies overlap data points—instances containing both easy and hard patterns—as a key mechanism for weak-to-strong generalization, allowing weak models to pseudolabel easier patterns while stronger models use these labels to learn harder patterns. Our work shows that a similar mechanism emerges naturally within self-improvement, where progressively increasing difficulty enables models to generate useful supervision signals for harder tasks without explicit human intervention.














\paragraph{Self-Improvement.}

When high-quality training labels are unavailable or costly to obtain, training on self-generated labels provides an efficient way to broaden the capabilities of a model. Typically, this involves generating candidate labels, filtering or verifying them to prune errors, and retraining on the refined self-generated data____. This approach has been successfully applied across various domains, including reasoning____, mathematics____, coding____, and general instruction tuning____.
Recent studies further analyze and refine the self-improvement process. ____ identify the generation-verification gap as a key limiting factor, while ____ introduce a "sharpening mechanism" that improves reliability by training on best-of-N model outputs.
Our work builds on STaR____ and ReST____, leveraging iterative prediction, filtering, and fine-tuning to enhance model capabilities.















\paragraph{Model Collapse.}
A key challenge in self-improvement is model collapse, where iterative training on self-generated outputs leads to performance degradation____. While some work suggests this degradation is inevitable____, several mitigation strategies have emerged, including maintaining original training data____, careful data mixing____, and reliable verification mechanisms____. Our approach incorporates these insights through unsupervised filtering techniques and controlled data generation, effectively preventing collapse while enabling sustained improvement.
\textit{We provide additional discussion of related works in Appendix~\ref{sec:related_work_extended}. 
}%