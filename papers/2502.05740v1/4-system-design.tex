\section{The \projectname System Design}
\label{sec:4-system-design}

Following the design strategies that we summarized in Section \ref{3-PD-design-stategies}, we designed and implemented the \projectname system (see Fig. \ref{fig:system-arch}). \projectname has two main user interfaces: (1) a conversational user interface powered by a large language model (LLM) (Section \ref{sub:4-system-patient-interface}), and (2) a web-based dashboard for clinical staff (Section \ref{sec:4-provider}). In this section, we first elaborate on the key design decisions by their interfaces and then the technical details.
\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{figures/system-architecture-v3.pdf}
    \captionsetup{justification=centerlast}
    \caption{System architecture of \projectname. The red, purple, and blue arrows represent data generated by the Conversation Module, Information Extraction Module, and Summarization Module, respectively.
    }
    \label{fig:system-arch}
\end{figure*}

\subsection{Patient Interface and Interaction}
\label{subsub:4-system-patient-interface-prompt}
\label{sub:4-system-patient-interface}

Given our participants' expectations for conversational agents(CAs), we developed and implemented a CA as the user interface for postoperative cancer patients. In particular, we used an Alexa Echo Dot, a voice assistant widely adopted in prior studies for patient-facing healthcare~\cite{chanMangoMangoHow2023,mahmoodLLMPoweredConversationalVoice2023}, in our study.
This interface allows users to interact naturally with the system, facilitating an easier and more intuitive way to regularly report their health conditions 

In this section, we introduce the three parts of our system prompt: System Definition, Clinical Guidelines, and Task Description. We show \arxiv{how} they are structured to guide the flow of conversation, ensuring relevance and appropriateness in the context of patient care\footnote{The full prompt example can be found in Appendix \ref{sub:8-appendix-prompt-conversation}}.

\paragraph{System Definition.} 
The System Definition part of the prompt aims to provide general information and guidelines to the CA, supporting DS2 and DS3.
\begin{itemize}

\item Persona Information:
To ensure the CA will be friendly and empathetic and to support DS3, we first incorporate instructions in the prompt defining the CA as an assistive agent for clinical RPM.

\item User Description:
To ensure the CA's understanding of the context and the user, the LLM is then prompted with the user description of a postoperative cancer patient.

\item Allowlist and Denylist:
To ensure the CA exhibits natural language and empathy (DS3) without providing unsolicited medical advice (e.g., ``this could be a problem''), we implemented both an allowlist and denylist in the prompt setup. 
Each entry in the allowlist and denylist contains a guideline (e.g., ``be friendly'') and an example.

\item Clarification and Accessibility:
In traditional RPM methods like questionnaires, patients may not understand questions with limited health-related knowledge and thus seek further clarification from clinicians. 
To address this issue, our system prompts the CA to phrase questions using simple language and respond to any clarifications posed by the patient in a clear and natural manner. 
This strategy not only facilitates the effective collection of symptom information from patients with limited medical knowledge but also ensures that patients can actively seek and receive clear explanations regarding the queries raised by the agent.

\end{itemize}
\paragraph{Clinical Guidelines.}
To support our DS1 and DS2, the CA is prompted to pose questions based on a list of key questions and to inquire further if a patient confirms experiencing a symptom. 
The list of questions (shown in table \ref{tab:3-key-questions}) is gathered from our PD sessions.

\paragraph{Task Description.}
To support DS1, DS2, and DS3, the third part of the prompt specifies how the LLM response should be derived in each round.
\begin{itemize}

\item Conversation Flow:
Following our DS1, we designed our overall conversation flow and used natural language to describe the flow in the prompt as a big picture. First, the CA should greet the patient with expressions like ``How are you doing today?'' Second, the LLM should process the predefined key question list in the Clinical Guideline to identify the first unanswered question, ensuring the conversation covers all essential topics.
Then, in the last two steps, the CA should wrap up the conversation and respond to the user's further conversations.

\item Chain-of-Thoughts Prompting:
Guided by our DS1, we initially designed the LLM-powered CA to mark a symptom as ``not reported'' only when the user explicitly states they do not have that specific symptom. 
However, during the prompt iteration process, we observed that the system frequently omits questions from the predefined list. 
The LLM often assumes that all questions have been answered when the user responds with ``I'm feeling great'' to general inquiries, or it fails to ask follow-up questions for the second symptom when the user reports multiple symptoms simultaneously.

To address this issue, we developed a chain-of-thoughts approach \cite{wei2022chain}. This approach, specified after the Conversation Flow, requires the LLM to (1) go through conversation history with all key symptom questions (2) mark their current status (one of ``not discussed,'' ``in discussion,'' or ``discussed'') and (3) decide which question should be asked, in every conversation round. 
The LLM should only mark a question as ``discussed'' after the user has explicitly answered the key question and all related follow-up questions.


\end{itemize}
\paragraph{Using the Prompt.}
\label{subsub:3-using-prompt}
We implemented our LLM-powered CA utilizing the GPT-4o model \cite{openaiGPT4TechnicalReport2023}. To form one \textit{system prompt}, the three parts are combined in the listed order with a short title (see Appendix \ref{sub:8-appendix-prompt-conversation}). Each day, the patient activates our Alexa Skill with ``Alexa, Open Recover Bot'' to start the conversation. During each conversation round, the user's speech is captured by the Alexa Dot Speaker and forwarded to the backend API server via the Alexa Skill. 
The server retrieves the day's conversation history and the system prompt specified in the config file and uses this information to get the LLM response from the OpenAI service. After getting the response, Alex Echo Dot replies to the patient and listens to the next message from the patient.

\subsection{Provider Interface and Interaction}
\label{sec:4-provider}
\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/recover-system-annotation.pdf}
    \captionsetup{justification=centerlast}
    \caption{\arxiv{Final Design of the \projectname Dashboard. We present three key sections and the major interaction flow that connects them: (1) from patient list to patient detail, (2a) from patient list to key questions, (2b) from key questions visualization to detailed log, and (3) from daily report to summary. Each section also includes local interactions to review and manage patient reports.
    }}
    \label{fig:system-design-screenshot}
\end{figure*}
Drawing on insights from our PD process, we designed and implemented a web-based system for healthcare providers (see Fig. \ref{fig:system-design-screenshot}). This system processes the raw conversation log between the patient and the conversational agent and then displays and visualizes the data on a web dashboard.
In this section, we first introduce the two main modules of our system, followed by a detailed presentation of the dashboard design.


\subsubsection{Information Extraction Module}
Raw conversation logs are often lengthy and difficult to navigate. To facilitate the efficient review of critical information, we designed the \textbf{Information Extraction Module}.  
This module extracts answers to predefined clinical questions (Table \ref{tab:3-key-questions}) and categorizes symptoms based on patient responses. If the patient answers \textit{``no''} to a question, the corresponding symptom is marked as \textit{``not reported''}. If the patient answers \textit{``yes''}, the symptom is classified according to its clinical severity: \textit{least severe, moderate,} or \textit{most severe}.
For questions with Likert scales like breathing, this module also extracts the Likert scale reported by the patient.
Additionally, this module identifies which questions were addressed in each conversation log, ensuring a structured and comprehensive review of patient-reported information.

\subsubsection{Summarization Module}
When the conversational agent asks follow-up questions, the diverse and dynamic nature of patient responses makes it unsuitable to display the information in a structured format. 
Therefore, to provide a quick overview of key unstructured information, we designed the \textbf{Summarization Module}. This module summarizes detailed, unstructured information reported by the patient, enabling efficient review by healthcare providers.

\subsubsection{Dashboard UI Design}

The screenshot of our system is shown in Figure \ref{fig:system-design-screenshot}. Here, we introduce the four main components of our dashboard UI: the \textbf{Patient List}, the \textbf{Patient Detail}, and the \textbf{Report Detail}.

\paragraph{\textbf{Patient List}}
The patient list, organized by severity as assessed by the model, is displayed on the left side of the dashboard, with interactions following DS4. 
Patient with unread conversations are emphasized by formatting the patient's name in bold.
A colored dot to the left of the patient's name represents the patient's severity rating, with basic demographic details beneath the name. 
Clinical staff can edit the severity rating of a patient and manually mark a patient as ``reviewed'' by clicking the dot on the left.

\begin{figure*}[t]
    \centering
    \begin{subfigure}[t]{.3\linewidth}
        \centering
        \includegraphics[width=\linewidth,page=1]{figures/edit-symptom-crop.pdf}
        \caption{Visualized Key Questions. Reported symptoms will shown as red, yellow or blue, according to their color coding}
    \end{subfigure}
    \hspace{.03\linewidth}
    \begin{subfigure}[t]{.3\linewidth}
        \centering
        \includegraphics[width=\linewidth,page=2]{figures/edit-symptom-crop.pdf}
        \caption{Likert Scale Visualization. Symptoms with Likert scale will have a meter around the dot, and will show the detailed score when mouse hover}
    \end{subfigure}
    \hspace{.03\linewidth}
    \begin{subfigure}[t]{.3\linewidth}
        \centering
        \includegraphics[width=\linewidth,page=3]{figures/edit-symptom-crop.pdf}
        \caption{Edit Severity Level. Users can click on a selected symptom to edit the severity of the symptom}
    \end{subfigure}
    \caption{Visualization of Key Questions: An example of the local interactions within each section.}
    \label{fig:key questions}
\end{figure*}

\paragraph{\textbf{Patient Detail: Key Question Visualization}}
We also designed the patient detail panel based on DS4 (see Fig.\ref{fig:key questions}), which is positioned at the center of the dashboard. Detailed demographic information is displayed at the top, while the bottom section visualizes answers to key questions. 
Reported symptoms with least severe, moderate, and most severe will be marked as blue, yellow, or red, respectively.
If the symptom is absent, the dot remains green. Some symptoms are assessed using a 10-point Likert scale. Clinical staff can hover over the dot to inspect the score. 
Each symptom is linked to associated conversation logs. 
Clicking on a symptom's dot navigates the user to the specific conversation log about that symptom in the ``detailed log'' panel on the lower right.
To edit the severity, users select and click the dot again.


\paragraph{\textbf{Report Detail: Summary and Detailed Log}}

Following DS5, we developed a ``Report Detail'' section on the right side of the interface. At the top of this section, a ``Conversation Summary'' displays key information extracted from the conversation log, accompanied by a space for notes. 
Below, the raw conversation log is presented, allowing healthcare providers to review the exchanges between the conversational agent and the patient. 


\subsection{Implementation and Technical Details}
\label{subsub:4-implemenation}
\subsubsection{Prompt Design and Iteration}
As mentioned in Section \ref{sub:4-system-patient-interface} and \ref{sec:4-provider}, the \projectname system integrates clinical guidelines to LLMs through three prompt components. The patient conversation prompt is a longer prompt that guides the patient-LLM CA interaction; meanwhile, the information extraction prompt leverages LLM to extract key symptom information from the conversation log, which is used for further visualization; after the conversation, the summarization module takes the key information and prompts the LLM to generate a summary for clinical review. The research team iterated the text prompts in three phases: 
(1) The design phase: during PD sessions, researchers present example conversations from the latest version of the prompt and address system limitations given participant feedback, e.g., unsatisfactory logic, not addressing liability risks (Section \ref{sub:3-pd-methods-provider}) 
(2) The implementation phase: members of the research team tested the \projectname system daily and updated the prompts if any unexpected LLM output occurred, e.g., response too long or too short, not handling typical edge cases
(3) The user testing phase, where we leveraged stakeholder feedback from user study sessions to further improve the prompts.
\subsubsection{Technical Architecture}
\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\linewidth]{TechnicalDetail.pdf}
    \captionsetup{justification=centerlast}
    \caption{Technical Architecture. Our system backend modules are built upon OpenAI API and connected to a Postgre SQL database. We use Alexa Skill for the patient Alexa Dot interface and NGINX frontend for the provider web dashboard.}
    \label{fig:system-architecture}
\end{figure}

The system primarily consists of three components: (1) the Voice User Interface, operated on an Alexa Dot smart speaker; (2) the backend along with the database; and (3) the web-based dashboard designed for healthcare providers.
The LLM-powered CA is developed as an Alexa Skill as mentioned in Section \ref{subsub:3-using-prompt}.
The backend is built using the Flask framework. Patient information, conversation logs, LLM-generated summaries, and severity scores are stored in the database. For object-relational mapping, we employ SQLAlchemy. A simple SQLite database is utilized for the user study; however, for real-world deployment, the system is compatible with any Database \arxiv{management system}.
The frontend is developed using the Vue.js framework and NaiveUI components, hosted using the Nginx HTTP server. It interacts with the backend API using axios to fetch, display, and visualize patient information, severity scores, and conversation logs, allowing healthcare providers to conduct thorough inspections.
Following our DS6, to mitigate privacy concerns associated with the use of LLMs, we employ the OpenAI service hosted on Azure. Its \textit{HIPAA compliance} guarantees that our conversation logs cannot be accessed by third parties.


