
\section{Designing LLM-powered System for RPM with GI Cancer Providers and Patients}
\label{sec:3-participatory-design}
\subsection{Methodology}

We conducted two rounds of studies to gather insights for the design of our system: first, we interviewed GI cancer patients to gather their experiential insights with postoperative care and digital health tools; then, we conducted seven participatory design (PD) sessions with five clinical staff to design the system that follows clinical specifications and can be seamlessly integrated into providers' workflows to address their needs.




\subsubsection{Interview with Cancer Patients}
\review{The research team first disseminated recruitment information via posters and text posts to cancer support groups on social networking sites, which requires prospective participants to complete a screening survey. 
Our key inclusion criteria are: (1) a diagnosis of GI cancer within the last five years and (2) had undergone surgery related to cancer treatment after diagnosis.
With these criteria, we recruited \textit{five} participants: two with stomach cancer, two with pancreatic cancer, and one with colon cancer. All participants had undergone surgery in the United States and recovered in single-family homes or apartments.
Participants were invited to share their experiences recovering from GI cancer surgery, especially their needs and challenges in communicating with their providers, and how they can envision a future AI-supported system for RPM.
}




\subsubsection{Participatory Design with Clinical Staff}
\label{sub:3-pd-methods-provider}
In this paper, we use the term ``clinical staff'' to cover two key roles in patient monitoring based on existing work~\cite{leon2022impact}: (1) doctors, including surgeons, internists, and oncologists, who specialize in specific clinical areas, and (2) patient coordinators, such as nurse practitioners, who have closer and more frequent contact with patients. The term ``healthcare providers'' also refers to clinical staff and is used for generalization and brevity.
We recruited \textit{five} clinical staff using snowball sampling from two cancer care institutions in the central U.S. (see Table \ref{tab:participants} for demographics). 
All participants work closely with GI cancer patients during surgery and recovery, and most of them have over 20 years of experience in GI cancer care.

\begin{table*}[t]
\small
    \centering
    \caption{Participant Information in the Participatory Design}
    \label{tab:participants}
    \begin{booktabs}{
    colspec={cccc}
    }
    \toprule
        DP\# & User Role & Area of Expertise & Years of Exp. \\ \midrule
        DP1 & Patient coordinator& Cancer care & Over 20 years\\
        DP2 & Doctor &  Cancer and postoperative care, patient education & Over 20 years\\
        DP3 & Doctor & Surgical oncology & Over 20 years\\
        DP4 & Doctor &  Cancer care, patient education& Over 30 years\\
        DP5 & Patient coordinator& Cancer care & 1-5 years\\
        \bottomrule
    \end{booktabs} 
\end{table*}


\subsubsection{PD Session Procedure}

Since RPM involves multiple stakeholders: patients for data collection outside clinical settings, and providers for monitoring and decision-making~\cite{temple2023effect}, our system design focuses on three key components: (1) system architecture and information flow, (2) patient interface, and (3) provider interface. 
We conducted seven participatory design sessions on Zoom, each lasting around 30 minutes. 
Three to five participants joined each session to discuss different design decisions of the system and create design artifacts like drafts and flowcharts.
The sessions were held every one to two weeks over two months, as detailed in Figure \ref{fig:3-PD-agenda}.

\begin{figure*}
    \centering
    \includegraphics[width=0.9\linewidth]{figures/PD-agenda.pdf}
    \captionsetup{justification=centerlast}
    \caption{PD sessions and their participants, discussion artifacts, and agenda.}
    \label{fig:3-PD-agenda}
\end{figure*}
Throughout these sessions, the research team documented participant inputs through note-taking and design drafts. The recordings of these sessions were transcribed, and two researchers first used inductive coding to code the transcripts and participant comments, then iterated the axial codes until consensus. We identified five major themes on design insights from providers (see Section \ref{3-PD-provider-insights}).

\begin{figure}[t]
    \centering
    \includegraphics[width= 0.6\linewidth]{figures/PD-screenshot-drawings.pdf}
    \captionsetup{justification=centerlast}
    \caption{A PD session where participants commented on the conversation flow, and dashboard design version; the research team confirmed the participants' feedback by drawing lines and writing notes %
    }
    \label{fig:participatory-design}
\end{figure}

\paragraph{Designing Information Flow with Diagrams Based on Clinical Workflow}

The researchers first created a Figma diagram to illustrate the data flow between components. Providers reviewed the system architecture, focusing on how the collected patient health data is stored and managed. As providers assessed the diagrams, they shared how patient data is handled in clinical systems such as EHR and recommended changes to improve patient data safety and privacy.


\paragraph{Designing Conversation Flow for Patients}

Before the PD sessions, two researchers drafted a pilot LLM CA based on existing LLM CAs and clinical questionnaires (see Sections \ref{sub:related_work-1} and \ref{sub:related_work-2}). The CA leverages GPT-4~\cite{openai2023gpt4}. The initial prompt asked general check-in questions, such as ``How are you feeling today? Do you have any discomfort?'' followed by a few tailored follow-ups such as pain scales (see Table \ref{tab:8-appendix-initial-conversation} for an example).



After testing the prompt with a synthetic model patient—a hypothetical postoperative GI cancer patient experiencing pain and taking medication, representing typical postoperative conditions—the research team gathered 2-5 conversation logs. Each log consisted of multiple conversation turns and was organized into a Google Doc (see Appendix \ref{subsec:9-appendix-conversation-log}). This testing aimed to evaluate the prompt's ability to generate clinically relevant and coherent interactions tailored to typical postoperative scenarios.

These logs formed the basis for discussions on (1) key provider questions for postoperative GI cancer patients, (2) needed follow-up information, and (3) feedback on the conversation logic, chatbot persona, and task. Design iterations focused on conversation logic, the key patient information that the system collects, and the expression of empathy from CA.
During PD sessions, participants reviewed and commented on the conversation log files, referencing reliable resources like the Common Toxicity Criteria\footnote{Common Terminology Criteria for Adverse Events (CTCAE): A standardized tool for grading the severity of adverse effects in clinical trials and routine clinical practice, alongside their professional experience. Available at: \url{https://ctep.cancer.gov/protocoldevelopment/electronic_applications/ctc.htm}. }~\cite{CommonTerminologyCriteria} and their professional experience. The final conversation flow design was achieved after nine major iterations of prompt revisions and provider feedback.


\paragraph{Designing Interactive Dashboard for Providers with Figma Prototype}
We envisioned an LLM-powered dashboard for clinical staff to review the patients' monitoring data through enhanced information visualization and management to improve efficiency. 
The dashboard is expected to be integrated into existing EHR systems. Researchers first designed a pilot user interface in Figma (see Figure \ref{fig:8-appendix-initial-dashboard})~\cite{figma}, resembling a simplified view of a typical EHR system dashboard: a patient list on the left panel, with patient health records and conversation summaries displayed in the central area, and detailed views accessible via clicks.
Throughout the PD sessions, participants suggested interface improvements and new design ideas (Figure \ref{fig:PD-dashboard-iteration}). Discussions focused on three areas: (1) the overall layout and key sections providers prioritize in RPM, (2) interaction flow and visual components in the central section of the dashboard, and (3) useful interactions and layout for other sections.

\begin{figure*}[p]
    \centering
    \includegraphics[width= \linewidth]{figures/PD-dashboard-iteration-with-center.pdf}
    \captionsetup{justification=centerlast}
    \caption{Dashboard Iteration Process. In each section, we present the key design versions of the corresponding module, together with the provider feedback that we gathered in the PD sessions. The provider's feedback guided us through the design iterations.}
    \label{fig:PD-dashboard-iteration}
\end{figure*}


\subsection{Patient Perspectives}
\label{subsec:3-formative-patient-findings}

\label{para:3-formative-patient-needs}
To start with, the patient participants (PP) reported a variety of symptoms and health issues that they experienced, including pain and pain control (4 PPs), GI conditions, fatigue, wound care, breathing, physical activities, and emotional breakdown (PP1, 2, 3, 5). The list of symptoms corresponds to the providers' experience mentioned in \ref{3-PD-finding-key-info}.
Meanwhile, the participants felt a lack of knowledge about their cancer surgery and recovery (PP1, 2, 3), and therefore are in great demand of providers' \textit{ instructions and explanations.} 
For instance, PP3 needed the nurse to explain how and why he needed help managing the digestive system and symptoms, and PP2 double-checked with the doctor about activity and dietary instructions.


\label{para:3-formative-patient-availability}
Among their experience in remote communication, most PPs contact their providers through phone calls, with only one using an online meeting (PP3) and one with a satisfactory telehealth system (PP4).
One major challenge for patients was the \textit{limited availability of clinical staff}, especially as they identified their postoperative recovery phase as needing \textit{quick response and instructions} when they have symptoms. Three participants expected their providers, especially doctors, to be more responsive in urgent situations (PP1, 2, 5), \textit{``when patients are in their down moments, they need the doctors to be there 24/7... some things that come up after surgery are actually things that require urgent attention''} (PP2).


\label{para:3-formative-patient-CA}
Built upon their experiences, the participants expected a \textit{conversational, responsive, and intelligent system for RPM} to support them during the postoperative recovery. Three participants envisioned a conversational agent that answered various questions and offered solutions to their symptoms (PP1, 2, 3): \textit{``when you have something like a doctor... we can have a conversation.''} (PP3). In addition, two participants expected the system to be ``readily available'' and offer ``real-time replies'' (PP4, 5), while PP3 suggested integrating more personal medical history to offer better responses.

\subsection{Design Insights from Cancer Providers}
\label{3-PD-provider-insights}
\paragraph{Probing Key Information based on Clinical Standards and Provider Experience}
\label{3-PD-finding-key-info}
Participants expressed strong interest in using LLM-powered CAs for collecting patient health data in RPM. Building on prior research, they identified 13 essential questions for the LLM to ask, focusing on key symptoms for postoperative GI cancer patients, such as breathing, pain, drainage, blood, and stool (Table \ref{tab:3-key-questions}). For example, the presence of blood in the stool could indicate surgical complications (P4). Providers refined the wording of these questions to ensure comprehensive coverage during patient interactions and assigned severity levels (``most severe'', ``moderate'', ``least severe''), determined if a 10-point Likert scale should be used and suggested color for each question.

Participants also mentioned that patients tend to underestimate their symptoms which may have a huge impact on their health through the recovery process: \pquote{3}{... patients can under or overestimate their symptoms. So ... there are patients when we call stoic... they'll say I have shortness of breath, but it's manageable, when it's actually ...  no, it's a significant one that requires a significant attention.} Based on this observation, all participants agreed that there should only be one severity level for each question; for instance, the system ought to display ``most severe'' even if the patient reports shortness of breath at a Likert scale of 1 out of 10.

\begin{table*}[t]
    \centering
     \caption{
     The final version of key questions summarized by DPs, including their preferences on how to visualize patient-reported information. For certain questions, experts suggested using a Likert scale or color coding to represent patients' responses to reflect the severity of the symptom. For instance, if a patient reports difficulty breathing, it could be flagged as a more severe health issue.
     The last column denotes our final design choice explained in Section \ref{sec:4-system-design}.}

\begin{booktabs}{
colspec={Xccc},
cells={m},
width=\linewidth,
hspan=minimal,
}
\toprule
Question                                                                                                                                              & Likert Scale & Severity          & Color \\
\midrule
Are you having difficulty breathing?                                                                                                                  & Yes          & Most Severe       &   \textcolor{myred}{red}    \\
Are you having a fever of over 100
  degrees, or chills?                                                                                              & No           & Most Severe       &   \textcolor{myred}{red} \\
Have you had black, tar-like stools?                                                                                                                  & No           & Most Severe       &    \textcolor{myred}{red}   \\
Do you have pain that sharply increases,
  or becomes unbearable?                                                                                     & Yes          & Most Severe       &     \textcolor{myred}{red}  \\
Are you having any wound drainage
  problems, such as redness around your wound, bleeding from the wound, pus, or
  an opening at the incision site?~ & No           & Moderate Severity &    \textcolor{myyellow}{yellow}   \\
Do you have a decrease in your ability to
  perform your daily activities, such as not being able to walk to the
  bathroom?~                        & No           & Least Severe      &  \textcolor{myblue}{blue}      \\
Have you had a decrease in your level of
  consciousness?                                                                                             & Yes          & Most Severe       &    \textcolor{myred}{red}    \\
Have you had persistent constipation,
  nausea, or vomiting?                                                                                          & Yes          & Moderate Severity &      \textcolor{myyellow}{yellow} \\
Have you had persistent diarrhea?                                                                                                                     & No           & Moderate Severity &   \textcolor{myyellow}{yellow}    \\
Have you been unable to tolerate food or
  drink?                                                                                                     & Yes          & Moderate Severity &    \textcolor{myyellow}{yellow}   \\
Do you have unexplained or new pain or
  swelling in one of both of your legs?                                                                        & No           & Most Severe       &   \textcolor{myred}{red}      \\
Have you been feeling down or depressed?                                                                                                             & No           & Least Severe      &     \textcolor{myblue}{blue}  \\
Is there anything else you'd like to
  comment on that I haven't asked about?                                                                         & No           & N/A               &    \textcolor{mypurple}{purple}    \\
  \bottomrule
\end{booktabs}
   
    \label{tab:3-key-questions}
\end{table*}



In addition to structured inquiries, the providers expressed a keen interest in utilizing the LLM's capability to adaptively probe deeper into patient responses. DP4, drawing from extensive experience with GI cancer patients, noted that open-ended questions often yield the most informative responses, allowing patients to describe their symptoms in detail. 

DP2 emphasized the utility of narrative responses to validate and enrich the data collected, highlighting the need to both confirm and elaborate on patients' descriptions of symptoms. For example, the patient’s initial description of a symptom would prompt follow-up inquiries to validate the information and gather details. DP2 suggested a dual approach: \pquote{2}{Ask them to talk openly about how they feel, then compare their narrative with specific answers like yes or no}. Consequently, the team established two types of follow-up inquiries: (1) for each of the 13 key questions, specific prompts were devised, e.g., ``Could you tell me more about when the pain started?'' and (2) for other symptoms mentioned by patients, the LLM was programmed to ask for details such as frequency, severity, and impact where relevant.


\paragraph{Balancing Timeliness, Effectiveness, and User Experience}
\label{3-PD-finding-time}

In the meantime, providers also discussed the most appropriate frequency of the check-in conversation to collect information from patients. As GI cancer patients may experience great change postoperatively, frequent monitoring (\eg daily check-in) is essential to the timeliness of collected patient information; in particular, participants focus on patients' conditions within the first 40 days of their hospital discharge. Thus, our participants agreed that having the check-in questions performed on a daily basis with a flexible flow would result in time and accurate responses.

However, as the participants discuss the question list for the LLM CA and the check-in frequency, they are also concerned about the length of the whole conversation, as clinical questionnaires alone may take a long time to finish via a CA. Participants are worried that the patient would feel bored, exhausted, or distracted if the daily interaction is too long. \pquote{1}{... we just felt like it was so unwieldy... we talked about dividing it into thirds... [But] we settled in on a much more narrowly focused set of questions}. Thus, as mentioned in Section \ref{3-PD-finding-key-info}, participants agreed on a narrower list with adaptive follow-up questions for a better patient experience. Furthermore, DP1, DP2, and DP4 agreed on skip logic, where questions may be skipped if the patient has already given the answer, or the conversation focuses on another particular symptom.

The discussion on improving user experience also involves the LLM's expression of empathy. On one hand, all participants agreed that it would be good for the LLM to acknowledge the patients' discomfort so that the conversation is more natural.
On the other hand, some participants are also worried that an LLM expressing empathy may make the patient uncomfortable and confused, especially in the healthcare setting.\pquote{6}{... where the bot says 'I'm sorry you [are] feeling this way' it makes me kind of cringe... we have to be careful about this anthropomorphization. If we are ascribing, giving,... human-like qualities, then they should be credible human-like qualities. ... this is an artificial intelligence which is different from humans.} As we will discuss in Section \ref{3-PD-finding-responsible}, our participants proposed that the LLM should remind patients of their roles as a CA instead of human professionals.


\paragraph{Designing Responsible AI in Conversation}
\label{3-PD-finding-responsible}
Another extensively explored scenario in conversational agents for healthcare is health information seeking. In our system, although answering health-related questions is not the LLM's primary functionality, our provider participants also discussed how the chatbot should respond to patients' questions. For instance, regarding a symptom description, \pquote{1}{The bot needs to be able to differentiate between the multiple symptoms addressed this question. For example, redness of skin would not affect one’s clothing; whereas bleeding or wound drainage could soak the clothes}.
Similarly, the providers concurred that it would be beneficial for the LLM to provide objective explanations for medical terms (e.g. when a patient asks ``what is constipation?'') to aid patients with lower health literacy in understanding the questions.

However, providers are overall highly cautious about the \textit{safety risks} within LLM responses. In conversation logs, providers commented that some LLM responses expressing empathy may indicate clinical assessments, which could be misleading to patients.
For example, regarding the LLM response, ``That's great! You are maintaining well.'', participants said \pquote{5}{This is an assessment, which the bot is not supposed to do. Also, good food intake and great appetite are not enough to say that the patient is `maintaining well.'}. For the LLM response, ``I see, an increase in bowel movement due to an increase in food intake isn't necessarily a cause for concern.'', a participant commented \pquote{1}{This is concerning; scary, even!} Thus, the LLM-powered system should be designed to be responsible for its responses by avoiding giving clinical assessments or related indications.

In addition, the provider participants emphasized that the system should mitigate patients' misunderstanding of the system's responsibility through clarifications, especially in emergent cases. DP3 specified that they wanted the system to explicitly say that 
\pquote{3}{if [the participant is] having an emergency, call 911, we're not your 911} 
Thus, the LLM-powered system should always clarify its responsibilities to avoid misuse.
In summary, we derive that the design should emphasize accountability and establishing capability boundaries in LLM responses.

\paragraph{Visualizations and Interactions to Promote Efficiency}
\label{3-PD-finding-efficiency}
Corresponding with the providers' heavy workload presented in prior work, our participants expressed a strong preference for an interface that presents the collected patient health information that promotes their efficiency. 
Based on our Figma prototype iterations which is shown in Fig. \ref{fig:PD-dashboard-iteration}, participants agreed on the need for a visualization of all the patients' daily conversation results presented in the central section, so that they can quickly \textit{``have a snapshot''} of the data (DP2). For all questions, they look for visualizations in color codings, so that the levels of severity could be immediately reflected. Specifically, doctors proposed \textit{color-coding }rubrics to denote the priority of the information that should be reviewed.
\pquote{4}{... so that [the] pain should always be reviewed right? Something that's a priority. }
Additionally, they expected visualizations like \textit{meters} to reflect patients' responses in Likert scales as well as a uniformed list. \pquote{2}{...I think we wanna maintain the first line as the dots... A small meter that shows ... completely a different line for the like a Likert scale for those...} We summarize their consensus on information presentation in Table \ref{tab:3-key-questions}.
Lastly, the participants commented on better formatting or arranging the LLM-generated analysis to offload the dashboard users. For example, the summary in the upper right section can be listed in bullet points; the patients in the patient list could be sorted in descending order of risks (from red to green and checked) (DP2). In summary, we design a visualization section that effectively reflects key information to navigate the users' attention.

Correspondingly, derived design implications for interactive features from providers' needs to manage patients. For example, in addition to the detailed conversation logs, DP2 is interested in linking the color visualization dots to corresponding conversation logs; DP1 also agreed to our initial design to allow providers to manually adjust the severity levels based on their action status with an interactive list selection.
Following participant inputs, we aim to design \projectname{} dashboard with responsive interactions to help users quickly navigate to details and take action.


\paragraph{Privacy concerns, sensitive information}
\label{3-PD-finding-privacy}
The participants are particularly focused on addressing data privacy concerns, given the highly sensitive nature of the collected patient health information and medical records. DP2 and DP5 advocate for the confidentiality of identifiable information, such as patient names and dates of birth, to be maintained, with access restricted solely to the managing clinical team. 
Furthermore, due to security concerns regarding third-party services such as Alexa Skill and LLM services like GPT from OpenAI, DP5 stressed that \projectname{} should prevent these platforms from misusing identifiable or personal health information. Therefore, we aim to design our LLM-powered system for RPM to safeguard patient data.


\subsection{Design Strategies}
\label{3-PD-design-stategies}
We note our patient and provider participants have different focuses for design expectations towards LLM-powered systems for RPM. While the patients focus more on the explainability and responsiveness in the system (DS2, 3), the providers emphasize how such a system could support efficient clinical work while being responsible (DS1, 4, 5, 6). Thus, we design different components of the system focusing on strategies supporting the corresponding stakeholder group. 

Based on our PD findings above, we summarize the following 6 key design strategies (DSs), which will guide us in designing and developing the LLM-powered system in Section \ref{sec:4-system-design}:
\begin{itemize}
    \item DS1: Collect clinically critical patient conditions leveraging LLM's strength in analyzing and interpreting natural language (Section \ref{para:3-formative-patient-needs} and \ref{3-PD-finding-key-info}). DS1 considers patients' needs to receive guidance in reporting their symptoms and providers' expectations to have critical patient symptom information. Given that LLMs are good at analyzing both clinical and natural language use, designers could focus on using LLMs to collect key information by scaffolding interaction and mapping clinical instruction to oral language (Section \ref{subsub:4-system-patient-interface-prompt}).
    \item DS2: Using LLM to offer a comprehensive, interactive, and explainable patient-CA experience (Section \ref{3-PD-finding-key-info}, and \ref{para:3-formative-patient-needs}). Given users' disparities in health literacy and clinical expectations for comprehensive language for patients, an LLM-powered conversational agent will help with patient-side communication through explanations and adaptive language use for each patient.
    \item DS3: Ensuring a responsive patient interface with LLMs that collaborate with clinical staff (Section \ref{para:3-formative-patient-availability} and \ref{3-PD-finding-time}) Given the gap between patients' needs for quick response and providers' in our formative study, we use the LLM for initial response to patients while clinical staff offer further clinical instructions later.
    \item DS4: Designing LLM-supported effective visualization that helps clinical staff focus on crucial updates (Section \ref{3-PD-finding-efficiency}) Considering the clinical advocacy for visualization to draw attention to crucial abnormalities in PD sessions, LLM could perform data analysis on patient health information from the backend to generate prioritizing visualization.
    \item DS5: Filtering key information using LLM for efficient clinical review (Section \ref{3-PD-finding-efficiency}) Similar to DS4, LLM's strength in analyzing language could also support clinical review by highlighting key information such as key words and matching visualization to details.
    \item DS6: Mitigating privacy, safety and ethical risks following responsible LLM requirements. The requirements include the accountability and capability boundary in LLM responses, as well as anonymity and transparency in data use related to LLMs (Section \ref{para:3-formative-patient-CA} and \ref{3-PD-finding-privacy} ) It is also essential that the use of LLMs are under human supervision as regulated in access to sensitive information (Section \ref{subsub:4-implemenation}).
\end{itemize}


