\section{Conclusion \& Future Work}
\label{sec:conclusion_future_work}

In this work, we introduced the novel application of Transformer architectures adapted for tabular data to the task of OS fingerprinting. By leveraging both the TabTransformer and FT-Transformer models, our study bridges the gap between traditional rule-based methods and modern DL approaches in the cybersecurity domain. The experimental evaluation across multiple diverse datasets demonstrated that attention-based models can effectively capture complex interactions within network traffic, yielding improved OS classification performance over conventional ML baselines and previous works.

Our results indicate that the FT-Transformer, in particular, offers significant advantages in terms of accuracy and robustness when classifying OSs at varying levels of granularity and network environments. The inherent self-attention mechanisms allow the model to learn intricate feature dependencies, which is crucial for processing heterogeneous and dynamic network traffic data. This performance gain, as compared to previous works and traditional models such as k-Nearest Neighbours, Random Forests, and Multi-Layer Perceptron, establishes a new benchmark for OS fingerprinting tasks and highlights the potential of advanced DL techniques in this area.

In future work, we aim to explore several directions to further enhance the application of Tabular Transformer architectures for OS fingerprinting. First, expanding the range of datasets. Although the selected datasets are, in principle, representative of modern network environments, additional data from real-world deployments would be beneficial to further validate the models under a wider range of conditions. Additionally, we plan to investigate the impact of incorporating hybrid DL approaches, such as combining Transformers with Graph Neural Networks to better capture the temporalâ€“spatial relationships in network traffic data. Furthermore, we intend to evaluate the performance of these architectures on new or modified OS versions, directly comparing them with traditional tools such as Nmap, to assess their robustness and practical applicability in dynamic environments. Finally, we aim to apply transfer learning by pre-training on larger, related datasets to further refine performance across diverse and dynamic network conditions.

Moreover, the integration of the developed model into real-world cybersecurity tools, such as Nmap and various intrusion detection systems, could substantially enhance their versatility and operational effectiveness. We believe that our approach is not only beneficial for OS fingerprinting but also holds promise for broader applications within network security, including intrusion detection and traffic anomaly detection, thereby potentially yielding a significant industrial impact.

