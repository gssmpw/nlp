% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@misc{barez2025openproblemsmachineunlearning,
      title={Open Problems in Machine Unlearning for AI Safety}, 
      author={Fazl Barez and Tingchen Fu and Ameya Prabhu and Stephen Casper and Amartya Sanyal and Adel Bibi and Aidan O'Gara and Robert Kirk and Ben Bucknall and Tim Fist and Luke Ong and Philip Torr and Kwok-Yan Lam and Robert Trager and David Krueger and Sören Mindermann and José Hernandez-Orallo and Mor Geva and Yarin Gal},
      year={2025},
      eprint={2501.04952},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.04952}, 
}

@inproceedings{wang-etal-2023-kga,
    title = "{KGA}: A General Machine Unlearning Framework Based on Knowledge Gap Alignment",
    author = "Wang, Lingzhi  and
      Chen, Tong  and
      Yuan, Wei  and
      Zeng, Xingshan  and
      Wong, Kam-Fai  and
      Yin, Hongzhi",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.740/",
    doi = "10.18653/v1/2023.acl-long.740",
    pages = "13264--13276"
}

@article{yao2023large,
  title={Large language model unlearning},
  author={Yao, Yuanshun and Xu, Xiaojun and Liu, Yang},
  journal={arXiv preprint arXiv:2310.10683},
  year={2023}
}

@article{shi2024muse,
  title={Muse: Machine unlearning six-way evaluation for language models},
  author={Shi, Weijia and Lee, Jaechan and Huang, Yangsibo and Malladi, Sadhika and Zhao, Jieyu and Holtzman, Ari and Liu, Daogao and Zettlemoyer, Luke and Smith, Noah A and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2407.06460},
  year={2024}
}

@inproceedings{yao-etal-2024-machine,
    title = "Machine Unlearning of Pre-trained Large Language Models",
    author = "Yao, Jin  and
      Chien, Eli  and
      Du, Minxin  and
      Niu, Xinyao  and
      Wang, Tianhao  and
      Cheng, Zezhou  and
      Yue, Xiang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.457/",
    doi = "10.18653/v1/2024.acl-long.457",
    pages = "8403--8419"}

@misc{maini2024tofutaskfictitiousunlearning,
      title={TOFU: A Task of Fictitious Unlearning for LLMs}, 
      author={Pratyush Maini and Zhili Feng and Avi Schwarzschild and Zachary C. Lipton and J. Zico Kolter},
      year={2024},
      eprint={2401.06121},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.06121}, 
}

@misc{bourtoule2020machineunlearning,
      title={Machine Unlearning}, 
      author={Lucas Bourtoule and Varun Chandrasekaran and Christopher A. Choquette-Choo and Hengrui Jia and Adelin Travers and Baiwu Zhang and David Lie and Nicolas Papernot},
      year={2020},
      eprint={1912.03817},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1912.03817}, 
}

@misc{ma2024benchmarkingvisionlanguagemodel,
      title={Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset}, 
      author={Yingzi Ma and Jiongxiao Wang and Fei Wang and Siyuan Ma and Jiazhao Li and Xiujun Li and Furong Huang and Lichao Sun and Bo Li and Yejin Choi and Muhao Chen and Chaowei Xiao},
      year={2024},
      eprint={2411.03554},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.03554}, 
}

@inproceedings{liu2025mm,
  title={Mm-safetybench: A benchmark for safety evaluation of multimodal large language models},
  author={Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu},
  booktitle={European Conference on Computer Vision},
  pages={386--403},
  year={2025},
  organization={Springer}
}

@article{shi2024assessment,
  title={Assessment of multimodal large language models in alignment with human values},
  author={Shi, Zhelun and Wang, Zhipin and Fan, Hongxing and Zhang, Zaibin and Li, Lijun and Zhang, Yongting and Yin, Zhenfei and Sheng, Lu and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2403.17830},
  year={2024}
}

@article{hu2024vlsbench,
  title={VLSBench: Unveiling Visual Leakage in Multimodal Safety},
  author={Hu, Xuhao and Liu, Dongrui and Li, Hao and Huang, Xuanjing and Shao, Jing},
  journal={arXiv preprint arXiv:2411.19939},
  year={2024}
}

@article{toxic,
  title={Safety of Multimodal Large Language Models on Images and Text},
  author={Liu, Xin and Zhu, Yichen and Lan, Yunshi and Yang, Chao and Qiao, Yu},
  journal={arXiv preprint arXiv:2402.00357},
  year={2024}
}

@article{adversarialunlearning,
  title={An adversarial perspective on machine unlearning for ai safety},
  author={{\L}ucki, Jakub and Wei, Boyi and Huang, Yangsibo and Henderson, Peter and Tram{\`e}r, Florian and Rando, Javier},
  journal={arXiv preprint arXiv:2409.18025},
  year={2024}
}

@article{cooper2024machine,
  title={Machine Unlearning Doesn't Do What You Think: Lessons for Generative AI Policy, Research, and Practice},
  author={Cooper, A Feder and Choquette-Choo, Christopher A and Bogen, Miranda and Jagielski, Matthew and Filippova, Katja and Liu, Ken Ziyu and Chouldechova, Alexandra and Hayes, Jamie and Huang, Yangsibo and Mireshghallah, Niloofar and others},
  journal={arXiv preprint arXiv:2412.06966},
  year={2024}
}

@article{huang2024miner,
  title={Miner: Mining the underlying pattern of modality-specific neurons in multimodal large language models},
  author={Huang, Kaichen and Huo, Jiahao and Yan, Yibo and Wang, Kun and Yue, Yutao and Hu, Xuming},
  journal={arXiv preprint arXiv:2410.04819},
  year={2024}
}

@article{yan2024survey,
  title={A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method \& Challenges},
  author={Yan, Yibo and Su, Jiamin and He, Jianxiang and Fu, Fangteng and Zheng, Xu and Lyu, Yuanhuiyi and Wang, Kun and Wang, Shen and Wen, Qingsong and Hu, Xuming},
  journal={arXiv preprint arXiv:2412.11936},
  year={2024}
}

@article{yan2024errorradar,
  title={Errorradar: Benchmarking complex mathematical reasoning of multimodal large language models via error detection},
  author={Yan, Yibo and Wang, Shen and Huo, Jiahao and Li, Hang and Li, Boyan and Su, Jiamin and Gao, Xiong and Zhang, Yi-Fan and Xu, Tianlong and Chu, Zhendong and others},
  journal={arXiv preprint arXiv:2410.04509},
  year={2024}
}

@article{awais2025foundation,
  title={Foundation Models Defining a New Era in Vision: a Survey and Outlook},
  author={Awais, Muhammad and Naseer, Muzammal and Khan, Salman and Anwer, Rao Muhammad and Cholakkal, Hisham and Shah, Mubarak and Yang, Ming-Hsuan and Khan, Fahad Shahbaz},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2025},
  publisher={IEEE}
}

@inproceedings{yan2024urbanclip,
  title={Urbanclip: Learning text-enhanced urban region profiling with contrastive language-image pretraining from the web},
  author={Yan, Yibo and Wen, Haomin and Zhong, Siru and Chen, Wei and Chen, Haodong and Wen, Qingsong and Zimmermann, Roger and Liang, Yuxuan},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={4006--4017},
  year={2024}
}

@article{yan2025position,
  title={Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning},
  author={Yan, Yibo and Wang, Shen and Huo, Jiahao and Ye, Jingheng and Chu, Zhendong and Hu, Xuming and Yu, Philip S and Gomes, Carla and Selman, Bart and Wen, Qingsong},
  journal={arXiv preprint arXiv:2502.02871},
  year={2025}
}

@article{huo2024mmneuron,
  title={MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model},
  author={Huo, Jiahao and Yan, Yibo and Hu, Boren and Yue, Yutao and Hu, Xuming},
  journal={arXiv preprint arXiv:2406.11193},
  year={2024}
}

@article{li2025benchmark,
  title={Benchmark evaluations, applications, and challenges of large vision language models: A survey},
  author={Li, Zongxia and Wu, Xiyang and Du, Hongyang and Nghiem, Huy and Shi, Guangyao},
  journal={arXiv preprint arXiv:2501.02189},
  year={2025}
}

@article{zhou2024mitigating,
  title={Mitigating modality prior-induced hallucinations in multimodal large language models via deciphering attention causality},
  author={Zhou, Guanyu and Yan, Yibo and Zou, Xin and Wang, Kun and Liu, Aiwei and Hu, Xuming},
  journal={arXiv preprint arXiv:2410.04780},
  year={2024}
}

@article{yi2024jailbreak,
  title={Jailbreak attacks and defenses against large language models: A survey},
  author={Yi, Sibo and Liu, Yule and Sun, Zhen and Cong, Tianshuo and He, Xinlei and Song, Jiaxing and Xu, Ke and Li, Qi},
  journal={arXiv preprint arXiv:2407.04295},
  year={2024}
}

@article{flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{openflamingo,
  title={Openflamingo: An open-source framework for training large autoregressive vision-language models},
  author={Awadalla, Anas and Gao, Irena and Gardner, Josh and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Sagawa, Shiori and others},
  journal={arXiv preprint arXiv:2308.01390},
  year={2023}
}

@article{llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{jailbreak-28k,
  title={Jailbreakv-28k: A benchmark for assessing the robustness of multimodal large language models against jailbreak attacks},
  author={Luo, Weidi and Ma, Siyuan and Liu, Xiaogeng and Guo, Xiaoyu and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2404.03027},
  year={2024}
}

@article{li2024precision,
  title={Precision Knowledge Editing: Enhancing Safety in Large Language Models},
  author={Li, Xuying and Li, Zhuo and Kosuga, Yuji and Yoshida, Yasuhiro and Bian, Victor},
  journal={arXiv preprint arXiv:2410.03772},
  year={2024}
}

@article{clear,
  title={Clear: Character unlearning in textual and visual modalities},
  author={Dontsov, Alexey and Korzh, Dmitrii and Zhavoronkin, Alexey and Mikheev, Boris and Bobkov, Denis and Alanov, Aibek and Rogov, Oleg Y and Oseledets, Ivan and Tutubalina, Elena},
  journal={arXiv preprint arXiv:2410.18057},
  year={2024}
}

@article{liu2024protecting,
  title={Protecting privacy in multimodal large language models with mllmu-bench},
  author={Liu, Zheyuan and Dou, Guangyao and Jia, Mengzhao and Tan, Zhaoxuan and Zeng, Qingkai and Yuan, Yongle and Jiang, Meng},
  journal={arXiv preprint arXiv:2410.22108},
  year={2024}
}

@article{reefknot,
  title={Reefknot: A comprehensive benchmark for relation hallucination evaluation, analysis and mitigation in multimodal large language models},
  author={Zheng, Kening and Chen, Junkai and Yan, Yibo and Zou, Xin and Hu, Xuming},
  journal={arXiv preprint arXiv:2408.09429},
  year={2024}
}

@article{privacy,
  title={Protecting privacy in multimodal large language models with mllmu-bench},
  author={Liu, Zheyuan and Dou, Guangyao and Jia, Mengzhao and Tan, Zhaoxuan and Zeng, Qingkai and Yuan, Yongle and Jiang, Meng},
  journal={arXiv preprint arXiv:2410.22108},
  year={2024}
}

@article{liu2024towards,
  title={Towards safer large language models through machine unlearning},
  author={Liu, Zheyuan and Dou, Guangyao and Tan, Zhaoxuan and Tian, Yijun and Jiang, Meng},
  journal={arXiv preprint arXiv:2402.10058},
  year={2024}
}

@article{qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@inproceedings{shayegani2024jailbreak,
    title={Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models},
    author={Erfan Shayegani and Yue Dong and Nael Abu-Ghazaleh},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=plmBsXHxgR}
}

@article{li2023deepinception,
  title={Deepinception: Hypnotize large language model to be jailbreaker},
  author={Li, Xuan and Zhou, Zhanke and Zhu, Jianing and Yao, Jiangchao and Liu, Tongliang and Han, Bo},
  journal={arXiv preprint arXiv:2311.03191},
  year={2023}
}

@article{ding2023wolf,
  title={A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily},
  author={Ding, Peng and Kuang, Jun and Ma, Dan and Cao, Xuezhi and Xian, Yunsen and Chen, Jiajun and Huang, Shujian},
  journal={arXiv preprint arXiv:2311.08268},
  year={2023}
}

@article{wei2023jailbreak,
  title={Jailbreak and guard aligned language models with only few in-context demonstrations},
  author={Wei, Zeming and Wang, Yifei and Li, Ang and Mo, Yichuan and Wang, Yisen},
  journal={arXiv preprint arXiv:2310.06387},
  year={2023}
}

@inproceedings{kang2024exploiting,
  title={Exploiting programmatic behavior of llms: Dual-use through standard security attacks},
  author={Kang, Daniel and Li, Xuechen and Stoica, Ion and Guestrin, Carlos and Zaharia, Matei and Hashimoto, Tatsunori},
  booktitle={2024 IEEE Security and Privacy Workshops (SPW)},
  pages={132--143},
  year={2024},
  organization={IEEE}
}

@inproceedings{liu2022continual,
  title={Continual learning and private unlearning},
  author={Liu, Bo and Liu, Qiang and Stone, Peter},
  booktitle={Conference on Lifelong Learning Agents},
  pages={243--254},
  year={2022},
  organization={PMLR}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{GQA,
  title={Gqa: A new dataset for real-world visual reasoning and compositional question answering},
  author={Hudson, Drew A and Manning, Christopher D},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6700--6709},
  year={2019}
}

@inproceedings{VQAv2,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@inproceedings{VizXiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3608--3617},
  year={2018}
}
@article{SQA,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2507--2521},
  year={2022}
}

@article{VQA,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2507--2521},
  year={2022}
}

@article{POPE,
  title={Evaluating object hallucination in large vision-language models},
  author={Li, Yifan and Du, Yifan and Zhou, Kun and Wang, Jinpeng and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2305.10355},
  year={2023}
}

@inproceedings{MMB,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  booktitle={European conference on computer vision},
  pages={216--233},
  year={2025},
  organization={Springer}
}

@article{Mm-Vew,
  title={Mm-vet: Evaluating large multimodal models for integrated capabilities},
  author={Yu, Weihao and Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Liu, Zicheng and Wang, Xinchao and Wang, Lijuan},
  journal={arXiv preprint arXiv:2308.02490},
  year={2023}
}

@article{chatgpt,
  title={Is chatgpt a good nlg evaluator? a preliminary study},
  author={Wang, Jiaan and Liang, Yunlong and Meng, Fandong and Sun, Zengkui and Shi, Haoxiang and Li, Zhixu and Xu, Jinan and Qu, Jianfeng and Zhou, Jie},
  journal={arXiv preprint arXiv:2303.04048},
  year={2023}
}

@article{LLM-as-judge,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@inproceedings{wang2023decodingtrust,
  title={DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models.},
  author={Wang, Boxin and Chen, Weixin and Pei, Hengzhi and Xie, Chulin and Kang, Mintong and Zhang, Chenhui and Xu, Chejian and Xiong, Zidi and Dutta, Ritik and Schaeffer, Rylan and others},
  booktitle={NeurIPS},
  year={2023}
}

@article{gu2024mllmguard,
  title={MLLMGuard: A Multi-dimensional Safety Evaluation Suite for Multimodal Large Language Models},
  author={Gu, Tianle and Zhou, Zeyang and Huang, Kexin and Liang, Dandan and Wang, Yixu and Zhao, Haiquan and Yao, Yuanqi and Qiao, Xingge and Wang, Keqing and Yang, Yujiu and others},
  journal={arXiv preprint arXiv:2406.07594},
  year={2024}
}

@inproceedings{liu2024improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26296--26306},
  year={2024}
}

@inproceedings{liu2025mmbench,
  title={Mmbench: Is your multi-modal model an all-around player?},
  author={Liu, Yuan and Duan, Haodong and Zhang, Yuanhan and Li, Bo and Zhang, Songyang and Zhao, Wangbo and Yuan, Yike and Wang, Jiaqi and He, Conghui and Liu, Ziwei and others},
  booktitle={European conference on computer vision},
  pages={216--233},
  year={2025},
  organization={Springer}
}

@misc{ToFu,
      title={TOFU: A Task of Fictitious Unlearning for LLMs}, 
      author={Pratyush Maini and Zhili Feng and Avi Schwarzschild and Zachary C. Lipton and J. Zico Kolter},
      year={2024},
      eprint={2401.06121},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.06121}, 
}

@article{siu,
  title={Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models},
  author={Li, Jiaqi and Wei, Qianshan and Zhang, Chuanyi and Qi, Guilin and Du, Miaozeng and Chen, Yongrui and Bi, Sheng},
  journal={arXiv preprint arXiv:2405.12523},
  year={2024}
}

@inproceedings{mmsafetybench,
  title={Mm-safetybench: A benchmark for safety evaluation of multimodal large language models},
  author={Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu},
  booktitle={European Conference on Computer Vision},
  pages={386--403},
  year={2024},
  organization={Springer}
}

@inproceedings{icunlearn,
title={In-Context Unlearning: Language Models as Few-Shot Unlearners},
author={Martin Pawelczyk and Seth Neel and Himabindu Lakkaraju},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=GKcwle8XC9}
}

@article{EmbeddingCorrupted,
  title={Large Language Model Unlearning via Embedding-Corrupted Prompts},
  author={Liu, Chris Yuhao and Wang, Yaxuan and Flanigan, Jeffrey and Liu, Yang},
  journal={arXiv preprint arXiv:2406.07933},
  year={2024}
}

@article{HarryPotter,
  title={Who's Harry Potter? Approximate Unlearning in LLMs},
  author={Eldan, Ronen and Russinovich, Mark},
  journal={arXiv preprint arXiv:2310.02238},
  year={2023}
}

@inproceedings{multitrust,
title={MultiTrust: A Comprehensive Benchmark Towards Trustworthy Multimodal Large Language Models},
author={Yichi Zhang and Yao Huang and Yitong Sun and Chang Liu and Zhe Zhao and Zhengwei Fang and Yifan Wang and Huanran Chen and Xiao Yang and Xingxing Wei and Hang Su and Yinpeng Dong and Jun Zhu},
booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2024},
url={https://openreview.net/forum?id=5c1hh8AeHv}
}

@misc{lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@misc{PromptAttack1,
      title={Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection}, 
      author={Kai Greshake and Sahar Abdelnabi and Shailesh Mishra and Christoph Endres and Thorsten Holz and Mario Fritz},
      year={2023},
      eprint={2302.12173},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2302.12173}, 
}

@misc{promptAttack2,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.15043}, 
}

@misc{promptAttack3,
      title={Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning Methods}, 
      author={Jai Doshi and Asa Cooper Stickland},
      year={2024},
      eprint={2411.12103},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.12103}, 
}

@misc{figstep,
      title={FigStep: Jailbreaking Large Vision-Language Models via Typographic Visual Prompts}, 
      author={Yichen Gong and Delong Ran and Jinyuan Liu and Conglei Wang and Tianshuo Cong and Anyu Wang and Sisi Duan and Xiaoyun Wang},
      year={2025},
      eprint={2311.05608},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2311.05608}, 
}