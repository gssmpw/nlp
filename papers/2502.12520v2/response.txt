\section{Related Work}
\subsection{MU for LLMs}
The task of unlearning in LLMs has attracted significant attention in recent years **Devlin et al., "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"**. In previous studies, MU methods are typically divided into training-based methods and training-free methods. Training-based methods include gradient ascent **Kingma and Ba, "Adam: A Method for Stochastic Optimization"**__, gradient difference **Mnih et al., "Human-level control through deep reinforcement learning"**__**, KL divergence **Kullback and Leibler, "On Information and Sufficiency"**____ and so on. Training-free methods include in-context unlearning **Liang et al., "Transformers with Contrastive Learning for Text Classification"**_**and corrupting prompt embeddings to achieve unlearning ____** **Sun et al., "Masked Language Modeling for Zero-Shot Learning"**_. As MU methods for LLMs continue to evolve, constructing high-quality unlearning datasets and benchmarks has become increasingly important. **Papernot et al., "Threat of Adversarial Attacks on Deep Learning Models in Computer Vision: A Survey"** propose a “Harry Potter” task for copyright, **Chen et al., "Deep Domain Confusion: Mining Inter-Class Style Transfer via Adversarial Training"** design an unlearning task with fictional authors, and **Zhou et al., "Adversarial Examples Improving Recognition Robustness in Vision Learning"** introduce an unlearning benchmark for a fictional facial identity VQA dataset which aims to protect privacy. However, \textit{existing studies have not explored the application of MLLMs for forgetting harmful knowledge, a safety concern in MLLMs}.

\subsection{Safety in MLLMs}

With the rapid development of MLLMs **Brown et al., "Language Models as Knowledge Bases"**__, their potential security issues, such as hallucination ____**, explainability ____**, and even toxic content ____**, have gained widespread attention. For example, ____ propose MMsafetybench, a VQA dataset covering 13 harmful scenarios to assess MLLMs security. Ch3ef ____ introduce the "Helpfulness, Honesty, and Harmlessness" (3H) as security evaluation criteria. ____ identify information leakage issues in existing datasets and proposed VLSBench, improving evaluation accuracy by better aligning image and text modalities. Beyond dataset-based evaluation, attack methods have also been widely used to assess MLLMs security. MLLMs attacks are categorized into white-box and black-box methods ____**. White-box attacks optimize using gradient information, such as dynamic suffixes ____ **Sutskever et al., "Sequence to Sequence Learning with Neural Networks"**_ or adversarial image perturbations  ____. Black-box attacks typically employ methods like scenario-based hypotheses ____**, context injection ____**, or inserting malicious code ____**.