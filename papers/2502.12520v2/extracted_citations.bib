@article{EmbeddingCorrupted,
  title={Large Language Model Unlearning via Embedding-Corrupted Prompts},
  author={Liu, Chris Yuhao and Wang, Yaxuan and Flanigan, Jeffrey and Liu, Yang},
  journal={arXiv preprint arXiv:2406.07933},
  year={2024}
}

@article{HarryPotter,
  title={Who's Harry Potter? Approximate Unlearning in LLMs},
  author={Eldan, Ronen and Russinovich, Mark},
  journal={arXiv preprint arXiv:2310.02238},
  year={2023}
}

@misc{barez2025openproblemsmachineunlearning,
      title={Open Problems in Machine Unlearning for AI Safety}, 
      author={Fazl Barez and Tingchen Fu and Ameya Prabhu and Stephen Casper and Amartya Sanyal and Adel Bibi and Aidan O'Gara and Robert Kirk and Ben Bucknall and Tim Fist and Luke Ong and Philip Torr and Kwok-Yan Lam and Robert Trager and David Krueger and Sören Mindermann and José Hernandez-Orallo and Mor Geva and Yarin Gal},
      year={2025},
      eprint={2501.04952},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.04952}, 
}

@misc{bourtoule2020machineunlearning,
      title={Machine Unlearning}, 
      author={Lucas Bourtoule and Varun Chandrasekaran and Christopher A. Choquette-Choo and Hengrui Jia and Adelin Travers and Baiwu Zhang and David Lie and Nicolas Papernot},
      year={2020},
      eprint={1912.03817},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1912.03817}, 
}

@article{ding2023wolf,
  title={A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily},
  author={Ding, Peng and Kuang, Jun and Ma, Dan and Cao, Xuezhi and Xian, Yunsen and Chen, Jiajun and Huang, Shujian},
  journal={arXiv preprint arXiv:2311.08268},
  year={2023}
}

@article{hu2024vlsbench,
  title={VLSBench: Unveiling Visual Leakage in Multimodal Safety},
  author={Hu, Xuhao and Liu, Dongrui and Li, Hao and Huang, Xuanjing and Shao, Jing},
  journal={arXiv preprint arXiv:2411.19939},
  year={2024}
}

@article{huang2024miner,
  title={Miner: Mining the underlying pattern of modality-specific neurons in multimodal large language models},
  author={Huang, Kaichen and Huo, Jiahao and Yan, Yibo and Wang, Kun and Yue, Yutao and Hu, Xuming},
  journal={arXiv preprint arXiv:2410.04819},
  year={2024}
}

@article{huo2024mmneuron,
  title={MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model},
  author={Huo, Jiahao and Yan, Yibo and Hu, Boren and Yue, Yutao and Hu, Xuming},
  journal={arXiv preprint arXiv:2406.11193},
  year={2024}
}

@inproceedings{icunlearn,
title={In-Context Unlearning: Language Models as Few-Shot Unlearners},
author={Martin Pawelczyk and Seth Neel and Himabindu Lakkaraju},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=GKcwle8XC9}
}

@inproceedings{kang2024exploiting,
  title={Exploiting programmatic behavior of llms: Dual-use through standard security attacks},
  author={Kang, Daniel and Li, Xuechen and Stoica, Ion and Guestrin, Carlos and Zaharia, Matei and Hashimoto, Tatsunori},
  booktitle={2024 IEEE Security and Privacy Workshops (SPW)},
  pages={132--143},
  year={2024},
  organization={IEEE}
}

@article{li2023deepinception,
  title={Deepinception: Hypnotize large language model to be jailbreaker},
  author={Li, Xuan and Zhou, Zhanke and Zhu, Jianing and Yao, Jiangchao and Liu, Tongliang and Han, Bo},
  journal={arXiv preprint arXiv:2311.03191},
  year={2023}
}

@article{li2025benchmark,
  title={Benchmark evaluations, applications, and challenges of large vision language models: A survey},
  author={Li, Zongxia and Wu, Xiyang and Du, Hongyang and Nghiem, Huy and Shi, Guangyao},
  journal={arXiv preprint arXiv:2501.02189},
  year={2025}
}

@inproceedings{liu2025mm,
  title={Mm-safetybench: A benchmark for safety evaluation of multimodal large language models},
  author={Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu},
  booktitle={European Conference on Computer Vision},
  pages={386--403},
  year={2025},
  organization={Springer}
}

@misc{ma2024benchmarkingvisionlanguagemodel,
      title={Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset}, 
      author={Yingzi Ma and Jiongxiao Wang and Fei Wang and Siyuan Ma and Jiazhao Li and Xiujun Li and Furong Huang and Lichao Sun and Bo Li and Yejin Choi and Muhao Chen and Chaowei Xiao},
      year={2024},
      eprint={2411.03554},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2411.03554}, 
}

@misc{maini2024tofutaskfictitiousunlearning,
      title={TOFU: A Task of Fictitious Unlearning for LLMs}, 
      author={Pratyush Maini and Zhili Feng and Avi Schwarzschild and Zachary C. Lipton and J. Zico Kolter},
      year={2024},
      eprint={2401.06121},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.06121}, 
}

@article{reefknot,
  title={Reefknot: A comprehensive benchmark for relation hallucination evaluation, analysis and mitigation in multimodal large language models},
  author={Zheng, Kening and Chen, Junkai and Yan, Yibo and Zou, Xin and Hu, Xuming},
  journal={arXiv preprint arXiv:2408.09429},
  year={2024}
}

@inproceedings{shayegani2024jailbreak,
    title={Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models},
    author={Erfan Shayegani and Yue Dong and Nael Abu-Ghazaleh},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=plmBsXHxgR}
}

@article{shi2024assessment,
  title={Assessment of multimodal large language models in alignment with human values},
  author={Shi, Zhelun and Wang, Zhipin and Fan, Hongxing and Zhang, Zaibin and Li, Lijun and Zhang, Yongting and Yin, Zhenfei and Sheng, Lu and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2403.17830},
  year={2024}
}

@article{toxic,
  title={Safety of Multimodal Large Language Models on Images and Text},
  author={Liu, Xin and Zhu, Yichen and Lan, Yunshi and Yang, Chao and Qiao, Yu},
  journal={arXiv preprint arXiv:2402.00357},
  year={2024}
}

@inproceedings{wang-etal-2023-kga,
    title = "{KGA}: A General Machine Unlearning Framework Based on Knowledge Gap Alignment",
    author = "Wang, Lingzhi  and
      Chen, Tong  and
      Yuan, Wei  and
      Zeng, Xingshan  and
      Wong, Kam-Fai  and
      Yin, Hongzhi",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.740/",
    doi = "10.18653/v1/2023.acl-long.740",
    pages = "13264--13276"
}

@article{wei2023jailbreak,
  title={Jailbreak and guard aligned language models with only few in-context demonstrations},
  author={Wei, Zeming and Wang, Yifei and Li, Ang and Mo, Yichuan and Wang, Yisen},
  journal={arXiv preprint arXiv:2310.06387},
  year={2023}
}

@article{yan2024survey,
  title={A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method \& Challenges},
  author={Yan, Yibo and Su, Jiamin and He, Jianxiang and Fu, Fangteng and Zheng, Xu and Lyu, Yuanhuiyi and Wang, Kun and Wang, Shen and Wen, Qingsong and Hu, Xuming},
  journal={arXiv preprint arXiv:2412.11936},
  year={2024}
}

@article{yan2025position,
  title={Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning},
  author={Yan, Yibo and Wang, Shen and Huo, Jiahao and Ye, Jingheng and Chu, Zhendong and Hu, Xuming and Yu, Philip S and Gomes, Carla and Selman, Bart and Wen, Qingsong},
  journal={arXiv preprint arXiv:2502.02871},
  year={2025}
}

@inproceedings{yao-etal-2024-machine,
    title = "Machine Unlearning of Pre-trained Large Language Models",
    author = "Yao, Jin  and
      Chien, Eli  and
      Du, Minxin  and
      Niu, Xinyao  and
      Wang, Tianhao  and
      Cheng, Zezhou  and
      Yue, Xiang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.457/",
    doi = "10.18653/v1/2024.acl-long.457",
    pages = "8403--8419"}

@article{yao2023large,
  title={Large language model unlearning},
  author={Yao, Yuanshun and Xu, Xiaojun and Liu, Yang},
  journal={arXiv preprint arXiv:2310.10683},
  year={2023}
}

@article{yi2024jailbreak,
  title={Jailbreak attacks and defenses against large language models: A survey},
  author={Yi, Sibo and Liu, Yule and Sun, Zhen and Cong, Tianshuo and He, Xinlei and Song, Jiaxing and Xu, Ke and Li, Qi},
  journal={arXiv preprint arXiv:2407.04295},
  year={2024}
}

@article{zhou2024mitigating,
  title={Mitigating modality prior-induced hallucinations in multimodal large language models via deciphering attention causality},
  author={Zhou, Guanyu and Yan, Yibo and Zou, Xin and Wang, Kun and Liu, Aiwei and Hu, Xuming},
  journal={arXiv preprint arXiv:2410.04780},
  year={2024}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

