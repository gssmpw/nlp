\section{Related Work}
\subsection{MU for LLMs}
The task of unlearning in LLMs has attracted significant attention in recent years ____. In previous studies, MU methods are typically divided into training-based methods and training-free methods. Training-based methods include gradient ascent ____, gradient difference ____, KL divergence ____, and preference optimization ____ and so on. Training-free methods include in-context unlearning ____ and corrupting prompt embeddings to achieve unlearning ____. As MU methods for LLMs continue to evolve, constructing high-quality unlearning datasets and benchmarks has become increasingly important. ____ propose a “Harry Potter” task for copyright, ____ design an unlearning task with fictional authors, and ____ introduce an unlearning benchmark for a fictional facial identity VQA dataset which aims to protect privacy. However, \textit{existing studies have not explored the application of MLLMs for forgetting harmful knowledge, a safety concern in MLLMs}.

\subsection{Safety in MLLMs}

With the rapid development of MLLMs ____, their potential security issues, such as hallucination ____, explainability ____, and even toxic content ____, have gained widespread attention. For example, ____ propose MMsafetybench, a VQA dataset covering 13 harmful scenarios to assess MLLMs security. Ch3ef ____ introduce the "Helpfulness, Honesty, and Harmlessness" (3H) as security evaluation criteria. ____ identify information leakage issues in existing datasets and proposed VLSBench, improving evaluation accuracy by better aligning image and text modalities. Beyond dataset-based evaluation, attack methods have also been widely used to assess MLLMs security. MLLMs attacks are categorized into white-box and black-box methods ____. White-box attacks optimize using gradient information, such as dynamic suffixes ____ or adversarial image perturbations  ____. Black-box attacks typically employ methods like scenario-based hypotheses ____, context injection ____, or inserting malicious code ____.