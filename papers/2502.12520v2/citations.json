[
  {
    "index": 0,
    "papers": [
      {
        "key": "barez2025openproblemsmachineunlearning",
        "author": "Fazl Barez and Tingchen Fu and Ameya Prabhu and Stephen Casper and Amartya Sanyal and Adel Bibi and Aidan O'Gara and Robert Kirk and Ben Bucknall and Tim Fist and Luke Ong and Philip Torr and Kwok-Yan Lam and Robert Trager and David Krueger and S\u00f6ren Mindermann and Jos\u00e9 Hernandez-Orallo and Mor Geva and Yarin Gal",
        "title": "Open Problems in Machine Unlearning for AI Safety"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "bourtoule2020machineunlearning",
        "author": "Lucas Bourtoule and Varun Chandrasekaran and Christopher A. Choquette-Choo and Hengrui Jia and Adelin Travers and Baiwu Zhang and David Lie and Nicolas Papernot",
        "title": "Machine Unlearning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang-etal-2023-kga",
        "author": "Wang, Lingzhi  and\nChen, Tong  and\nYuan, Wei  and\nZeng, Xingshan  and\nWong, Kam-Fai  and\nYin, Hongzhi",
        "title": "{KGA}: A General Machine Unlearning Framework Based on Knowledge Gap Alignment"
      },
      {
        "key": "yao2023large",
        "author": "Yao, Yuanshun and Xu, Xiaojun and Liu, Yang",
        "title": "Large language model unlearning"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "yao-etal-2024-machine",
        "author": "Yao, Jin  and\nChien, Eli  and\nDu, Minxin  and\nNiu, Xinyao  and\nWang, Tianhao  and\nCheng, Zezhou  and\nYue, Xiang",
        "title": "Machine Unlearning of Pre-trained Large Language Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "maini2024tofutaskfictitiousunlearning",
        "author": "Pratyush Maini and Zhili Feng and Avi Schwarzschild and Zachary C. Lipton and J. Zico Kolter",
        "title": "TOFU: A Task of Fictitious Unlearning for LLMs"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "icunlearn",
        "author": "Martin Pawelczyk and Seth Neel and Himabindu Lakkaraju",
        "title": "In-Context Unlearning: Language Models as Few-Shot Unlearners"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "EmbeddingCorrupted",
        "author": "Liu, Chris Yuhao and Wang, Yaxuan and Flanigan, Jeffrey and Liu, Yang",
        "title": "Large Language Model Unlearning via Embedding-Corrupted Prompts"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "HarryPotter",
        "author": "Eldan, Ronen and Russinovich, Mark",
        "title": "Who's Harry Potter? Approximate Unlearning in LLMs"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "maini2024tofutaskfictitiousunlearning",
        "author": "Pratyush Maini and Zhili Feng and Avi Schwarzschild and Zachary C. Lipton and J. Zico Kolter",
        "title": "TOFU: A Task of Fictitious Unlearning for LLMs"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "ma2024benchmarkingvisionlanguagemodel",
        "author": "Yingzi Ma and Jiongxiao Wang and Fei Wang and Siyuan Ma and Jiazhao Li and Xiujun Li and Furong Huang and Lichao Sun and Bo Li and Yejin Choi and Muhao Chen and Chaowei Xiao",
        "title": "Benchmarking Vision Language Model Unlearning via Fictitious Facial Identity Dataset"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "li2025benchmark",
        "author": "Li, Zongxia and Wu, Xiyang and Du, Hongyang and Nghiem, Huy and Shi, Guangyao",
        "title": "Benchmark evaluations, applications, and challenges of large vision language models: A survey"
      },
      {
        "key": "yan2024survey",
        "author": "Yan, Yibo and Su, Jiamin and He, Jianxiang and Fu, Fangteng and Zheng, Xu and Lyu, Yuanhuiyi and Wang, Kun and Wang, Shen and Wen, Qingsong and Hu, Xuming",
        "title": "A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method \\& Challenges"
      },
      {
        "key": "yan2025position",
        "author": "Yan, Yibo and Wang, Shen and Huo, Jiahao and Ye, Jingheng and Chu, Zhendong and Hu, Xuming and Yu, Philip S and Gomes, Carla and Selman, Bart and Wen, Qingsong",
        "title": "Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "reefknot",
        "author": "Zheng, Kening and Chen, Junkai and Yan, Yibo and Zou, Xin and Hu, Xuming",
        "title": "Reefknot: A comprehensive benchmark for relation hallucination evaluation, analysis and mitigation in multimodal large language models"
      },
      {
        "key": "zhou2024mitigating",
        "author": "Zhou, Guanyu and Yan, Yibo and Zou, Xin and Wang, Kun and Liu, Aiwei and Hu, Xuming",
        "title": "Mitigating modality prior-induced hallucinations in multimodal large language models via deciphering attention causality"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "huo2024mmneuron",
        "author": "Huo, Jiahao and Yan, Yibo and Hu, Boren and Yue, Yutao and Hu, Xuming",
        "title": "MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"
      },
      {
        "key": "huang2024miner",
        "author": "Huang, Kaichen and Huo, Jiahao and Yan, Yibo and Wang, Kun and Yue, Yutao and Hu, Xuming",
        "title": "Miner: Mining the underlying pattern of modality-specific neurons in multimodal large language models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "toxic",
        "author": "Liu, Xin and Zhu, Yichen and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "Safety of Multimodal Large Language Models on Images and Text"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "liu2025mm",
        "author": "Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "Mm-safetybench: A benchmark for safety evaluation of multimodal large language models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "shi2024assessment",
        "author": "Shi, Zhelun and Wang, Zhipin and Fan, Hongxing and Zhang, Zaibin and Li, Lijun and Zhang, Yongting and Yin, Zhenfei and Sheng, Lu and Qiao, Yu and Shao, Jing",
        "title": "Assessment of multimodal large language models in alignment with human values"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "hu2024vlsbench",
        "author": "Hu, Xuhao and Liu, Dongrui and Li, Hao and Huang, Xuanjing and Shao, Jing",
        "title": "VLSBench: Unveiling Visual Leakage in Multimodal Safety"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "yi2024jailbreak",
        "author": "Yi, Sibo and Liu, Yule and Sun, Zhen and Cong, Tianshuo and He, Xinlei and Song, Jiaxing and Xu, Ke and Li, Qi",
        "title": "Jailbreak attacks and defenses against large language models: A survey"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "zou2023universal",
        "author": "Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "shayegani2024jailbreak",
        "author": "Erfan Shayegani and Yue Dong and Nael Abu-Ghazaleh",
        "title": "Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "li2023deepinception",
        "author": "Li, Xuan and Zhou, Zhanke and Zhu, Jianing and Yao, Jiangchao and Liu, Tongliang and Han, Bo",
        "title": "Deepinception: Hypnotize large language model to be jailbreaker"
      },
      {
        "key": "ding2023wolf",
        "author": "Ding, Peng and Kuang, Jun and Ma, Dan and Cao, Xuezhi and Xian, Yunsen and Chen, Jiajun and Huang, Shujian",
        "title": "A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "wei2023jailbreak",
        "author": "Wei, Zeming and Wang, Yifei and Li, Ang and Mo, Yichuan and Wang, Yisen",
        "title": "Jailbreak and guard aligned language models with only few in-context demonstrations"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "kang2024exploiting",
        "author": "Kang, Daniel and Li, Xuechen and Stoica, Ion and Guestrin, Carlos and Zaharia, Matei and Hashimoto, Tatsunori",
        "title": "Exploiting programmatic behavior of llms: Dual-use through standard security attacks"
      }
    ]
  }
]