\section{Related Work}
\subsection{Text-to-Image Diffusion Models}

Text-to-image (T2I) diffusion models \cite{glide,imagen,dall-e2,latentdiffusion,sdxl} have achieved remarkable progress in generating high-fidelity and photorealistic images from textual descriptions. These models have garnered widespread attention because of their intuitive text-based conditioning as a user-friendly interface for diverse image generation tasks.

T2I diffusion models can be broadly categorized into pixel-space and latent-space models. Pixel-space models, such as GLIDE \cite{glide} and Imagen \cite{imagen}, operate directly in the pixel space, producing visually impressive results at the expense of substantial computational resources, limiting their scalability. In contrast, latent diffusion models (LDMs) \cite{latentdiffusion} address these limitations by leveraging pre-trained autoencoders like VQGAN \cite{vqgan} to map images into a compact latent space, where the diffusion process is conducted. This reduces computational overhead while maintaining high-quality outputs, making LDMs a preferred framework for text-driven 360-degree panorama generation, as surveyed in this work.

\subsection{3D Scene Representation}

Efficient and accurate 3D scene representation is a critical challenge in computer graphics and vision. Traditional explicit representations, including point clouds, meshes, and voxel grids, often suffer from high memory requirements and struggle with complex topologies and unbounded scenes.

Neural implicit functions \cite{sdf,occupancy,3dgen}, which represent 3D scenes as continuous functions encoded within neural network parameters, offer a compact and flexible paradigm for scene representation. Notably, Neural Radiance Fields (NeRFs) \cite{nerf} stand out for their ability to achieve high-quality novel view synthesis. However, NeRF's reliance on dense volumetric sampling along camera rays results in slow training, hindering its practicability.

Recently, 3D Gaussian Splatting (3DGS) \cite{3dgs} has emerged as an efficient alternative to 3D scene representation. By combining an explicit representation of 3D Gaussians with a highly efficient differentiable rasterization pipeline, 3DGS facilitates rapid scene reconstruction and rendering. This advancement has opened up new possibilities, including recent explorations in text-to-3D 360-degree scene synthesis~\cite{dreamscene360,scenedreamer360}, which leverage text-driven 360-degree panorama generation techniques.