\section{Related Work}
Task Planning is a crucial process in robotics, where robots generate a sequence of actions to complete tasks within specific environments \cite{Kaelbling2011}. Traditionally, Task Planning relies on heuristics and searches within predefined domains \cite{garrett2020pddlstream, jiang2019task}, with some studies exploring representation learning, hierarchical learning, and other methodologies \cite{eysenbach2019search, xu2018neural, zhang2023cat}. Recently, the development of Large Language Models \cite{brown2020language, chen2021evaluating} (LLMs) has initiated a shift towards leveraging these models to directly generate plans and facilitate correct executions due to their strong generation and reasoning capabilities \cite{chu2023timebench, gramopadhye2023generating, valmeekam2023planbench}.

The field of Task Planning has undergone significant evolution with the integration of LLMs, particularly in the domain of closed-loop planning. A seminal contribution in this area is Prog-Prompt \cite{singh2022progprompt}, which utilizes structured programming prompts to guide the planning process and leverages LLMs' common-sense knowledge for strategy adjustments during execution. By incorporating assertions in programming languages, Prog-Prompt enables robots to proactively gather environmental data, enhancing the precision and context-awareness of task planning. Unlike Prog-Prompt, the Tree-Planner does not employ a Python-like prompt mechanism but instead utilizes a tree-like structure to aggregate multiple generated plans \cite{hu2023treeplanner}. In its execution process, Tree-Planner uses LLMs as heuristics to select the next command based on current observations. Although their methods achieve outstanding performance, they lack specific designs to address redundant execution queries, which hampers the system's efficiency and stability. Compared with the aforementioned methods, our Vote-Tree-Planner incorporates the unique command extractor to minimize redundant commands and implement a voting mechanism to enhance the stability of generated plans and reduce the number of queries sent to the LLM.