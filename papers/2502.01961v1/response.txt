\section{Related Work}
Most multiview feature learning methods suffer from drawbacks such as high complexity and limited performance**Kang, "Multiview Feature Learning for Image Classification"**. Recently, several consistency-based multiview feature learning methods have been proposed, aiming to maximize consistency between different views. Inspired by the strategy to maximize view consistency between two sets in CCA**Gong et al., "Canonical Correlation Analysis: A Tutorial"**, **Sun et al., "Multimodal Learning with Deep Canonical Correlation Analysis"** maps multiview features into a common space and concatenates the low-dimensional features as the common representation. **Zhang et al., "Multiview Feature Fusion via Autoencoders"** further introduce autoencoders in multiview feature learning compared with**Kang, "Multiview Feature Learning for Image Classification"**.
Besides, by leveraging co-training strategy**Xu et al., "Co-Training for Multiview Feature Learning"**, **Zhou et al., "Dual Contrastive Prediction for Cross-View Consistency"** design dual contrastive prediction to learn the cross-view consistency.

As one of the most effective consistent learning paradigms, contrastive learning has achieved SOTA performance**Chen et al., "A Simple Framework for Contrastive Learning"**. The basic idea of contrastive learning is learning a feature space from raw data by maximizing the similarity between positive pairs while minimizing that of negative pairs. In recent, some methods have shown the success of contrastive learning in multiview feature learning**Wang et al., "Contrastive Multiview Feature Learning"**, where similarities of positive pairs are maximized and that of negative pairs are minimized via NT-Xent**Jing et al., "NT-Xent: A Contrastive Loss for Unsupervised Representation Learning"**. **Lee et al., "Aligning Representations from Different Views at the Sample Level"** learns common representation by aligning representations from different views at the sample level. **Chen et al., "Learning Structural Relationships between Samples and Utilizing them to Obtain Consistent Data Representations"** learns the global structural relationships between samples and utilizes them to obtain consistent data representations. Simultaneously, structural information is utilized to select negative pairs for cross-view contrastive learning. In**Kim et al., "Self-Weighted Contrastive Learning"**, the weights are optimized based on the discrepancy between pairwise representations, performing self-weighted contrastive learning. Considering consistency between the cluster assignments among multiple views, **Zhang et al., "Cross-View Contrastive Learning for View-Invariant Representations"** proposes a cross-view contrastive learning method to learn view-invariant representations by contrasting cluster assignments among multiple views. Moreover, contrastive clustering**Huang et al., "Contrastive Clustering: A Simple Framework for Single-View Clustering Tasks"**, designed for single-view clustering tasks, constructs two distinct views through data augmentation and subsequently projects them into feature space. Using two separate projection heads, the method conducts contrastive learning at different levels in the row and column space to jointly learn representations and cluster assignments. **Wang et al., "Multi-Level Features Contrast from Multiple Views"** conducts multi-level features contrast from multiple views to achieve consistency. Furthermore, some recent contrastive learning works, notably BYOL**Grill et al., "Bootstrap Your Own Latent: Self-Supervised Learning from Unlabeled Data"** and SimSiam**Barlow et al., "Barlow Twins: Self-Supervised Learning via Redundancy Reduction"**, have shown the remarkable ability to learn powerful representations using only positive pairs, which has proven to be a simple and effective method**Chen et al., "A Simple Framework for Contrastive Learning"**.