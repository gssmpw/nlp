\section{Related Work}
\label{sec:Work}

\textbf{Domain Generalization (DG).} Researchers have been working extensively in single domain generalization and have developed numerous methods to enhance it **Somavarapu et al., "Data Augmentation Using Image Stylization"**__**Wang et al., "Adversarial Training for Domain Invariant Representation Learning"**. These methods can generally be grouped into three main categories: First, the data argumentation approach **Zhang et al., "Diversity-Guided Data Augmentation"** increases the diversity of source domain data by applying various data manipulation techniques. For instance, Somavarapu et al., "Data Augmentation Using Image Stylization" introduce a straightforward image stylization transform to generate diverse samples, exploring variability across sources. Similarly, Wang et al., "Adversarial Training for Domain Invariant Representation Learning" employ adversarial training to create varied input images, further enhancing generalization. Second, some kinds of DG methods focus on the presentation learning of domain invariance. Shao et al., "Multi-Adversarial Discriminative Training for Domain Generalization" use multi-adversarial discriminative training to extract both shared and distinctive feature representations across multiple source domains. Last, Various learning strategies **Kang et al., "Meta-Learning for Domain Adaptation"**__**Li et al., "Learning to Adapt with Meta-Gradients"** are employed to improve model generalization. For example, Zhao et al., "Meta-Learning for Domain Adaptation" apply a meta-learning approach that simulates the modelâ€™s adaptation to new, unseen domains during training, thereby boosting its adaptability in unfamiliar environments. These approaches illustrate significant advancements in domain generalization, highlighting different techniques designed to improve models' performance on previously unseen domains.

\textbf{Object Detection.} 
To mitigate the impact of domain bias on model performance, researchers have conducted numerous experiments and proposed various methods in object detection. One prominent approach is Domain Adaptive Object Detection (DAOD) **Chen et al., "Domain Adaptation for Object Detection"**, which enhances the model's robustness in new domains by simultaneously training on both source and target domains. For instance, a common strategy involves minimizing the distance between global and local features, as outlined in **Li et al., "Global-to-Local Attention for Domain Adaptive Object Detection"**. However, these methods require access to the target domain during model training, which imposes limitations on practical applications. Therefore, researchers have proposed Domain Generalized Object Detection (DGOD) **Chang et al., "Domain Generalization for Object Detection"**. For instance, Chang et al., "Domain Generalization for Object Detection" enhance the model's generalization ability by decoupling depth estimation from dynamic perspective enhancement. However, the effectiveness of DGOD largely depends on the number of accessible source domains, and collecting multiple source domains can be costly. Consequently, researchers have introduced the more challenging Single Domain Generalized Object Detection (S-DGOD) **Wu et al., "Single-Domain Generalization for Object Detection"**, which is generally categorized into feature normalization and invariant-based methods. Firstly, feature normalization methods such as IBN-Net, proposed by Pan et al., "Instance Normalization in Deep Neural Networks" enable the network to adjust its normalization strategy according to different tasks and datasets by combining Instance Normalization (IN) and Batch Normalization (BN). IterNorm, introduced by Huang et al., "Newton Iteration for Normalization" avoids feature decomposition through a Newton iteration method, thereby improving the efficiency of the normalization process. Secondly, invariant-based approaches, such as UFR proposed by Liu et al., "Unsupervised Feature Representation Learning" enhance the model's generalization performance by eliminating prototype bias and attentional bias. Wu et al., "Cyclic Disentanglement Self-Distillation for Single-Domain Generalization in Object Detection" propose a cyclic disentanglement self-distillation approach specifically for single-domain generalization in object detection, which enhances feature disentanglement. These approaches demonstrate significant progress in the field of target detection and contribute to the rapid advancement of the discipline.