\section{Related Work}
\subsection{Cross-view Localization}
Cross-view localization, the task of aligning ground-level images with satellite imagery, has become increasingly important in localization algorithms. Early approaches framed this as an image retrieval problem, where ground images were matched with satellite image slices of regions such as urban areas. Metric learning methods were used to train feature representations, enabling similarity computation between query ground images and satellite slices, facilitating localization ____. With the advent of complex models like transformers, cross-view localization based on image retrieval has shown improved performance on slice databases, though practical application remains challenging ____.

Recognizing these limitations, ____ introduced the one-to-many cross-view localization task. Building on this, recent works ____ advanced pixel-level localization methods. However, these approaches often assume precise pose information in the training data, which is typically derived from GPS signals and prone to inaccuracies in real-world deployment. To overcome this, ____ proposed weakly supervised settings with noisy pose annotations. 
Note that ____ assumes the availability of GT labels in the source domain training dataset and cross-view image pairs in the target domain for training. In contrast, ____ addresses the more challenging scenario where GT labels are unavailable in the source domain training dataset, and no cross-view image pairs accessible in the target domain. We tackle the same task as ____.
% Note that ____ assumes that GT labels exist in the source domain training dataset and cross-view image pairs in target domain are accessble for training, while ____ solves a challenging scenario where GT labels in the source domain training dataset are not available, and there is no cross-view image pairs in the target domain.  
% We tackle the same task as ____.
% where the training set only contains noisy pose labels. 

% utilizing techniques like transfer learning to achieve better localization. Our method, in contrast, eliminates the need for any precise ground truth pose assumptions, achieving superior performance while optimizing computational efficiency.


\subsection{Bird’s-Eye View Synthesis}
BEV synthesis, which generates bird’s-eye view images from ground-level perspectives, has been widely applied to cross-view localization. While LiDAR and Radar sensors offer high accuracy for localization tasks ____, their high cost limits their use. For camera-only systems, multi-camera setups are commonly employed ____, primarily focusing on tasks like segmentation and recognition. In localization, methods like Inverse Perspective Mapping (IMP) assume a flat ground plane for BEV synthesis ____, which can be overly simplistic for complex environments. Transformer-based models address these challenges but struggle with weak supervision and noisy pose annotations ____. While effective in some contexts, they face limitations in resource-constrained, real-world scenarios.

\subsection{Sparse-View 3D Reconstruction}
In our method, we adopt algorithms similar to 3D reconstruction to represent ground scenes. Sparse-view 3D reconstruction has been a major focus of the community. Nerf-based approaches____ and their adaptations____ have shown the potential for single-view 3D reconstruction, though their application is limited by small-scale scenes and high computational cost. Recent works using diffusion models____ and 3D Gaussian representations________, as well as transformer- and Gaussian-based models____, have achieved sparse-view 3D reconstruction on a larger scale, but the complexity of these models still restricts their use due to computational demands. Approaches like____ leverage pre-trained models to directly generate Gaussian primitives, avoiding the limitations of complex models while enabling scene reconstruction from sparse views. We apply such methods to single-view reconstruction, achieving high-accuracy cross-view localization.