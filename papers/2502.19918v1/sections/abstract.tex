\begin{abstract}


Large Language Models (LLMs) increasingly rely on prolonged reasoning chains to solve complex tasks. However, this trial-and-error approach often leads to high computational overhead and error propagation, where early mistakes can derail subsequent steps. To address these issues, we introduce \textbf{Meta-Reasoner}, a framework that dynamically optimizes inference-time reasoning by enabling LLMs to \enquote{think about how to think.} Drawing inspiration from human meta-cognition and dual-process theory, Meta-Reasoner operates as a strategic advisor, decoupling high-level guidance from step-by-step generation. It employs \textbf{contextual multi-armed bandits} to iteratively evaluate reasoning progress, and select optimal strategies (e.g., backtrack, clarify ambiguity, restart from scratch, or propose alternative approaches), and reallocates computational resources toward the most promising paths. Our evaluations on mathematical reasoning and puzzles highlight the potential of dynamic reasoning chains to overcome inherent challenges in the LLM reasoning process and also show promise in broader applications, offering a scalable and adaptable solution for reasoning-intensive tasks. 

% Code are released at \url{https://anonymous.4open.science/r/Meta-reasoner-B476/}

% Meta-reasoning can be defined as \enquote{dynamically deciding how to spend computation more optimally}, i.e. \enquote{thinking about how to think}, analogous to meta-learning (\enquote{learning to learn}) but focused on inference. This is motivated by human reasoning, where humans can adaptively and intelligently examine and guide their own thinking processes. As Large Reasoning Models (LRMs) gain the ability to productively think for longer times, inference-time efficiency is likely to increasingly become a bottleneck, so allowing them to focus their computation on more promising lines is likely to be increasingly important. While o1 can backtrack to some extent, it is still likely to have some limitations in its \enquote{higher-order} thinking due to its reliance on chain-of-thoughts (CoT), which is a sequential generation process, leading to getting stuck in less promising lines.

\end{abstract}