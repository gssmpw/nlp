\section{Related work}
\label{section:related}
Our work explores the visualization and placement of world-fixed data for in-car AR in form of POIs. As such, our related work consists of the topics of augmented passenger experiences and visualization of location-based data in AR.


\subsection{Augmented passenger experiences}
In 2021, Berger et al. \cite{BergerGridStudyInCarPassenger2021} explored major factors for a convenient in-car passenger experience. They identified that the outside environment had a major impact on passengers' perceived convenience. They brought this in line with past investigations on showing information about surrounding attractions \cite{BergerTactile19, MatsumuraActivePassengering18}. They also highlighted the enormous potential of innovative technologies like AR to be used by passengers. In addition, they also explored the importance of information access for convenient user experiences. They stated that users want to receive information beyond traditional ones like the time of arrival or the speed level. Future in-car applications should incorporate information about the direct surroundings, preferably based on passenger preferences and needs.

Similarly, Matsumura and Kirk \cite{MatsumuraActivePassengering18} explored the use of interactive car window systems to enhance passenger engagement with the external environment during car journeys. Their study identified several key themes that contribute to an improved passenger experience, including active participation, reflective interaction, social connectivity, and temporal awareness. User could could freeze the view to the outside and clip a frame using a gesture. As such, users could essentially capture or create a POI to seek further information or to review their journey later.

Challenges can arise in the utilization of HMDs for passengers in vehicles, which have to be overcome. McGill et al. \cite{mcgill2020challenges} identified crash safety, motion sickness (MS), social acceptance, and interaction in constrained spaces as challenges to overcome. Nevertheless they advocated for further exploration of HMDs in vehicle environments since they can potentially improve passenger experience in terms of productivity, entertainment and isolation. Similarly, Riegler et al. \cite{riegler2020agenda} proposed to investigate the use of HMDs further, especially in the context of autonomous driving. For example, they advocated to combat MS and create practical in-car work- and entertainment related experiences. 

In addition, in-vehicle human-computer interaction (HCI) studies are typically evaluated using simulators like virtual reality setups \cite{ColleySwiVR22}, CAVE systems \cite{SawitzkyCAVE23}, or professional driving simulators. While virtual driving simulators have their merits, they can't fully replace real-world testing \cite{petterson2019virtually}. For instance, participants might behave differently in a simulator, which for example lacks the stress of actual traffic conditions \cite{gomaa2020studying}.

Regarding specifically AR-based POI exploration in cars, Berger et al. \cite{BergerRearSeatDoor21} presented a design concept of an interactive car door for displaying POIs for rear-seats. They implemented a digital prototype and conducted a user study remotely with a simulation on a computer display. Participants were shown attractions along a route with which they could interact using a touch panel to receive additional information. The functionality to get more details about POIs was highly appreciated by all participants and most of them could have imagined to use it frequently. Notably, participants chose the rear seat over the front seat for their interactive car door.  However, their design for the location-based POIs was limited to the attractions name and a simple line. As a future step they highlighted the necessity for testing the system in a real-world experiment.

In summary, previous research has highlighted the potential of AR for enhancing in-car passenger experiences. However, most prior studies have relied on simulations, digital prototypes, or did not incorporate head-worn AR. In contrast, our work advances the field by conducting a real-world experiment using a VST-HMD, demonstrating how AR can enhance passenger experiences by presenting location-based information.




\subsection{Visualization of location-based Data}
There is extensive related work exploring the visualization of spatial content in AR. In this section, we explore related work regarding AR-visualization techniques, depth perception for outdoor AR, and occlusion handling in outdoor AR. However, findings from studies focused on stationary or pedestrian contexts may have limited relevance to our application, as aligning the car's position with POI locations introduces positional errors.

Zollmann et al. \cite{Zollmann2021ArVisTechniques} provide a taxonomy for visualization techniques in AR. They define six dimensions for design spaces in AR visualization. These are purpose, visibility, virtual cues, filtering, abstraction, and compositing. For our work, the purposes dimension is the most relevant, as we explore the presentation of virtual content being integrated into the real world while being part of an in-car user interface. Zollmann et al. \cite{Zollmann2021ArVisTechniques} found, that each visualization technique in their related work addresses one or more of five aspects: "a) achieving visual coherence, b) a better depth perception, c) reducing information clutter, d) supporting exploration, and e) directing attention." \cite{Zollmann2021ArVisTechniques}. In Section \ref{sec:design}, we explain our design decisions based on these dimensions and aspects. 

One example of an investigation into AR visualization in outdoor environments is the work by Hertel and Steinicke \cite{SteinickeArMaritimePois2021}. They conducted an experiment on egocentric depth perception in large-distance outdoor settings (up to 75 meters) using optical see-through (OST) AR. Their findings indicate that rendering drop shadows below objects hovering over a surface and employing bright, warm colors enhances depth perception accuracy. They further noted that good visibility is crucial for effortless and precise depth perception in outdoor scenarios, where bright colors are most effective. 

Additionally, they identified a relationship between object size and error rates, with larger objects associated with reduced errors in depth perception. However, while this relationship was statistically significant, the effect size was minimal, making it negligible for practical applications. Although Hertel and Steinicke \cite{SteinickeArMaritimePois2021} aimed to apply their findings to maritime environments, their main study was conducted in an empty parking lot, rendering their results potentially relevant to our use case of in-car AR. However, their focus on OST AR, which has inherent limitations, may not directly translate to the video see-through (VST) AR systems employed in our study.

Another study examining AR in outdoor environments was conducted by Ghaemi et al. \cite{Ghaemi23ARPlacement}, focusing on the effect of visualization placement on user experience during outdoor augmented data tours. The study utilized situated data visualizations in AR and compared three placement strategies: directly on buildings, on the ground near the user, and on a virtual map displayed in front of the user. Visualizations placed directly on buildings were the most preferred by participants. However, the findings are limited to the specific context of outdoor environments and may not generalize to indoor or in-car settings. Furthermore, the study did not address the design or appearance of the visualized objects. Their findings may also not directly translate to our system as they used an OST AR device.

There are also works that explore depth perception for AR applications. Diaz et al. \cite{Diaz2017depthPerception} conducted two experiments in an indoor environment investigating the effect of shading, cast shadows, aerial perspective, texture, dimensionality, and billboarding on users depth perception of virtual objects. They found cast shadows to be highly beneficial for depth estimation. The use of billboarding and larger virtual objects also had significant impact on depth perception, however not as much as the use of shadows. 

Livingston et al. \cite{Livingston2009IndoorOutdoorAr} examined depth perception of virtual objects in indoor and outdoor environments using a depth matching task. The indoor environment featured strong linear perspective cues, which the researchers sought to replicate outdoors. Depth was generally underestimated indoors, consistent with patterns observed in virtual environments, while outdoors, participants tended to overestimate depth. The synthetic perspective cues used outdoors were moderately effective, leading to reduced depth estimates for distant objects.

As for occlusion in outdoor AR visualization, Kasapakis and Gavalas \cite{kasapakis2017occlusion} developed a system using geolocative raycasting to detect surrounding buildings in realtime. Thus, a realistic FoV for players of an AR game could be generated. Skinner et al. \cite{Skinner2018IndirectPoiBrowser} proposed an indirect AR browser to address availability challenges by combining crowdsourced, precaptured street-level imagery with geospatial data. Their work demonstrates how this browser annotates buildings and landmarks in the user's environment and examines its feasibility by analyzing the approach's performance.


In summary, extensive research has explored spatial content visualization in AR, primarily in stationary or pedestrian contexts. However, these findings may have limited applicability to in-car AR, where aligning a moving vehicle's position with POI locations introduces positional errors. Prior work on outdoor AR visualization has addressed occlusion handling through techniques such as geolocative raycasting and indirect AR browsers that rely on pre-captured imagery and geospatial data. While effective in static settings, these approaches do not account for the unique challenges of dynamic, vehicle-based environments. In contrast, our work focuses on real-time AR visualization in moving vehicles, specifically addressing positional inaccuracies and continuously shifting perspectives when displaying location-based data.