\section{Discussion}
In this section, we discuss the impact of indirect speech acts in human-robot collaboration based on our quantitative and qualitative findings. 

\subsection{ISA's subtle role in teamwork}
\subsubsection{Adaptation and synchronisation}
Participants reported that a robot capable of understanding indirect requests made fluent collaboration easier. This is consistent with our quantitative results. Moreover, participants in the Non-ISA group reported adapting to the robot's communication ability to increase team fluency over time. Previous research shows human collaborators tend to have synchronisation on their vocalisation and neural activity when selecting words to convey contextual meanings during conversations~\cite{abney2021cooperation, zada2024shared}. Moreover, literature further suggests that people unconsciously mirror their linguistic structures with their interlocutors, regardless of being a human or computer, which facilitates efficient interactions~\cite{branigan2010linguistic}. However, the robot in the Non-ISA group failed to reciprocate linguistic convergence by adapting to their human collaborators.

Our findings revealed that the absence of robots' ability to interpret ISAs (Non-ISA group) necessitated greater adaptation efforts from participants during collaboration. This adaptation process was reported to be time-consuming and requiring increased cognitive effort. The robot's failure to perform its role as an effective communication partner forced participants to take on the full responsibility of adapting, increasing their effort and disrupting the division of labour~\cite{clark1996using, dale1995computational}. Previous studies have shown that ideal robot teammates should be able to adapt their communication to establish common ground for shared environment~\cite{chai2016collaborative}. \textbf{Therefore, it is essential to enhance robots’ ability to adapt to individuals' communication styles, for instance, using indirect requests.} Besides, to be accessible to diverse populations, robots should adapt to users’ speech styles, considering factors like ``age, gender, dialect, domain expertise, task knowledge, and familiarity with the robot.''~\cite{marge2022spoken}. Our findings support this call, while highlighting the importance of indirect speech. As collaborative robots enter real-world settings, it is suboptimal to expect groups, like children or the elderly, to adapt to the robot's communication style. 

% \vspace{-0.5em}
\subsubsection{Grounding}
Previous research in human-robot interaction conducted limited exploration of non-conventionalised ISAs (i.e. context-dependent ISAs), usually focused on the effect of politeness (i.e. conventionalised ISAs)~\cite{seok2022cultural, williams2018thank}. In our study, we discovered significant effects of non-conventionalised ISAs on team grounding. The interview findings provided an explanation for the questionnaire results, which showed that the ISA group had a significantly higher perception of goal alignment compared to the Non-ISA group. Participants who effectively used indirect requests, particularly non-conventionalised ISAs, to communicate with the robot felt more confident in having established a shared understanding with their robot teammate. 
Moreover, participants mentioned that conventionalised ISAs (e.g., ``Can you...?'') offer the teammate an option to reject the request, consistent with Searle’s~\cite{searle1975indirect} theory, which explains that ISAs also contribute to facilitating the exchange of intentions between teammates. 

In contrast to human-human collaboration, the use of ISAs is nuanced by the users' expectations. Some participants, having no expectation of the robot's ability to understand ISAs, opted to use only direct requests, even when interacting with a robot capable of interpreting ISAs. This finding complements the results of~\cite{briggs2017enabling}, which showed that individuals continue using ISAs when interacting with robots that cannot comprehend them—a pattern also observed in our study. This shows that the user's prior expectations, or mental models, of the robot's capabilities play a strong role in people's decision to use or avoid ISAs. It could be important for a robot teammate to explicitly communicate its capabilities to interpret ISAs. At the start of a collaboration, for example, the robot might say \textit{``Please just give me clear, precise, direct instructions''}.

With human-agent teaming on the rise, goal alignment has emerged as a critical yet unresolved challenge~\cite{bhat2024value, zhang2025implicit}. Previous research has focused on  approaches that model goal alignment and assess its effects~\cite{li2022modeling, sanneman2023validating}. Our findings suggest that the successful use of indirect requests in communication can act as an indicator of mutual understanding within the team. Consequently, proactively \textbf{incorporating implicatures into the robot’s verbal communication may be an effective strategy for signalling the robot’s accurate comprehension of the human teammate’s intentions}. However, ISAs can also introduce ambiguities, requiring the robot to more effectively manage dialogue failures and repair mechanisms~\cite{kontogiorgos2021systematic}. The appropriate usage of this strategy not only enhances the explainability of the robot's mental state but also maintains the flow of teamwork without interruptions.
% \vspace{-0.5em}

\subsection{ISA's subtle role in trust}
Qualitative findings suggest that the robot's ability to understand ISAs either positively impacted or did not affect participants' trust as long as tasks were completed successfully. This qualitative feedback supports the quantitative results, indicating that understanding ISAs significantly enhances trust, although trust remained high in the Non-ISA group due to successful task execution. Moreover, some participants felt that using indirect requests enhanced their perception of the robot’s anthropomorphism. This result aligned with the findings in~\cite{emnett2024using}, claiming that a robot's speech anthropomorphism should not be limited to tone and voice but also to directness. Previous studies conclude that robots with higher anthropomorphism in appearance (i.e. looking more human-like) may induce higher functionality expectations~\cite{duffy2003anthropomorphism} and trust~\cite{natarajan2020effects}. Our study adds to these findings that higher human-like understanding in verbal communication may induce higher performance trust. 

However, our study represented an ideal scenario where the robot made no mistakes. In real-world settings, execution and communication failures are common. During the interview, some participants suggested that higher performance trust could result in elevated expectations, potentially causing greater frustration when the robot makes errors. Conversely, participants with a higher perception of the robots' partnership believed they would be more forgiving of the robot’s potential mistakes. Similar contradictory findings have been reported in previous research. \citet{salem2013err} observed that robots displaying occasional incorrect gestures were perceived as more likeable than those that performed perfectly. A follow-up study~\cite{salem2015would} found opposing results, but also suggested that the level of anthropomorphism and the severity of the error may influence these differing reactions. In our experiment, we used a robot with anthropomorphic features, including a head, neck, arm, and torso. Some participants noted during the interviews that their perceptions might differ if the robot were less human-like, such as a vacuum robot. \textbf{Given that real-world interactions are more prone to errors, it is crucial to carefully consider the potential negative effects on trust when employing natural and implicit verbal communication in collaboration.} Although there are no widely recognized studies analysing users' speech acts when a robot fails, \citet{kontogiorgos2021systematic} found that humans tend to emphasise vowels and speak more loudly when robots make errors. Future research could explore users' speech directness in response to robot errors, particularly in relation to the level of anthropomorphism, timing and severity of the failure~\cite{rossi2017timing}.

\subsection{Task- and context-dependency}
Contrary to our assumptions, indirect requests are not suitable for all situations. The usage of ISAs is task-dependent. Participants responded that \textbf{ISAs were preferred when collaborating on repetitive, low- to medium-risk tasks, as well as tasks requiring high coordination}. For high-risk tasks, the explicitness of direct requests is safer, as it provides clearer and more precise descriptions of the required actions. Simple and repetitive tasks typically require less verbal communication, and participants often use shortened indirect requests based on the mutual understanding of the task they have built before, such as \textit{``Next''}. In less collaborative tasks, participants prefer fewer, clearer instructions over back-and-forth dialogue, prioritising efficiency and precision over an intuitive and low-effort interaction experience during task completion.

\textbf{The use of indirect requests is also highly context dependent.} Unlike written commands given to virtual AI assistants, verbal commands are given less time to formulate and are often subconsciously phrased as indirect requests during physical collaboration. Furthermore, since collaborative tasks typically involve continuous interaction and sequential sub-tasks, indirect requests often rely on prior commands and actions. Interpreting these requests requires the ability to reference previous interactions that are related. Researchers suggested ISAs are less semantically related to their immediate context than direct speech acts; however, they gain relevance when interpreted correctly in light of broader context ~\cite{boux2023cognitive}. Previous research highlights the substantial impact of incorporating task context on improving the prediction of ISA usage, emphasising the need for models that account for contextual and intentional factors~\cite{smith2022leveraging}. In HRC, which involves real-world interactions, gestures are frequently employed, further facilitating the use of indirect commands. Additionally, implicatures often rely on real-world information, such as the location of objects. A previous study explored how locative expressions embedded in indirect commands are interpreted~\cite{lamm2017pragmatics}. The physical affordances of the environment, which embed rich semantic information~\cite{gao2024physically, brohan2023can}, can readily prompt the use of implicatures in indirect requests. Future research could focus on developing solutions that address broader conversational contexts and link physical environments to improve the accuracy of robots' interpretation of non-conventionalised indirect requests, where large language and vision models have shown strong potential due to their long-term context-sensitive attention and multi-modal reasoning capabilities~\cite{zhong2024memorybank, sermanet2024robovqa}.
\vspace{-0.5em}

\subsection{Limitations and future work}
With the rapid development of LLMs and enhanced reliability and affordability of robot hardware, the use of natural language as an interface for daily human-robot collaboration is becoming increasingly feasible. However, some participants noted that LLMs performance in interpreting indirect requests, based on their experiences with commercial models, varied significantly, indicating that while LLMs show some capacity for interpreting implicature, their reliability remains inconsistent. This challenge has also been highlighted and explored by other researchers~\cite{ruis2024goldilocks, jin2024reasoning}. Moreover, the context- and task-dependent nature of using ISAs in physical human-robot collaboration presents additional challenges, particularly in integrating visual and physical information. Therefore, a future evaluation is necessary before deploying LLMs in commercial collaborative robots, along with the development of specialised datasets and fine-tuning techniques. There is also potential for expanding the scope to broader conversational contexts and linking physical environments to enhance robots' interpretation of non-conventionalised indirect requests, where recent advances in language and vision models offer promising solutions with their context-sensitive attention and multi-modal reasoning capabilities. 

There are several limitations in our study. First, although participants represented a wide age range, most were recruited from a university campus, with the majority being college students, which limits the generalisability of our findings to the broader population or specific demographic groups. Second, due to the use of teleoperation to ensure safety, participants noted that the robot’s arm movements were slow and unsteady, which may have influenced their perception of the robot’s capabilities. Third, this experiment employed a Wizard-of-Oz setup, which created an error-free scenario, allowing us to focus on analyzing users' behaviour in using ISAs and comparing across Speech Modes. However, robot errors are unavoidable in real-world applications. Future research should investigate how robot errors influence the directness of user speech, as well as their impact on collaboration performance and experience. Fourth, this experiment did not control the amount of ISAs each participant used during their interaction session to maintain natural interactions. The effect of this variation was considered in a broader sense by accounting for participants and task type as random effects rather than precisely measuring the number of ISAs used. Additionally, this study exclusively examined the impact of robots' ability to understand ISAs. Future research should explore the effects of robots' ability to generate ISAs in collaborative settings. Another important area for investigation is the influence of robots using ISAs on human communication patterns, particularly whether a robot’s use of ISAs encourages humans to reciprocate with indirect speech. This dynamic could impact users' tolerance for dialogue errors, with effective ISA use potentially fostering greater flexibility and tolerance for minor mistakes, while improper handling of ISAs could reduce trust and interaction fluency.
\vspace{-0.5em}
