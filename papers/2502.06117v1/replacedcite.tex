\section{Related Work}
\label{related}
% Dynamic graph clustering methods are broadly categorized into two classes____:  
% \textbf{\textit{(i) Neural Network}}-based methods and \textbf{\textit{(ii) Matrix Factorization}}-based methods.

%\vspace{3pt}
\textbf{Neural Network-based Methods.} 
Some neural network-based methods employ coupled approaches, which first condense dynamic graphs into one static graph and then apply clustering methods, such as CNN-based____ and GNN-based 
methods____, to identify clusters. 
Other methods employ two-stage approaches, which first learn dynamic graph embeddings____ and then apply clustering methods to these  embeddings to identify clusters____.   
For example, RNNGCN____ and DGCN____ use RNNs or LSTM to capture temporal dependencies for graph embeddings, which are then clustered using graph convolutional layers. 
CI-GCL____ adopts a community invariance graph contrastive learning framework for graph clustering and classification.  
ROLAND____ extends static GNN-based graph embedding methods to dynamic graphs by using gated recurrent units to capture temporal information. 
To reduce time consumption, SpikeNet____ uses spiking neural networks to model the evolving dynamics of graph embeddings, achieving better performance with lower computational costs. For more related work, refer to____. 
The main issue with NN-based methods is their separation of dynamic graph embedding and clustering into two independent processes, making it difficult to ensure that graph embedding provides the most suitable features for clustering____. Furthermore, most of them face weak scalability and interpretability issues on large-scale graphs____. 
%cannot consider topological and temporal information simultaneously. 
Thus, we focus on separated matrix factorization, jointly optimizing dynamic graph embedding and clustering, and improving scalability and interpretability. %(Please see details in Fig.{\ref{Hyper_parameter_tuning}(C)}).

%\vspace{3pt}
\noindent \textbf{Matrix Factorization-based Methods.} 
Matrix factorization-based methods cluster nodes at each timestamp using matrix factorization while optimizing the temporal smoothness of node embeddings among different timestamps. 
Recently, numerous methods with different strategies have been proposed to improve temporal smoothness. 
For example, sE-NMF____, jLMDC____, and NE2NMF____ estimate temporal smoothness by analyzing topology changes between graphs at the current and previous timestamps, while PisCES____ smooths clusters by considering topology changes across the entire dynamic graph. 
%%%%
In contrast, other methods use clustering metrics or reconstruction loss to measure temporal smoothness. For example, DynaMo____ improves temporal smoothness by incrementally maximizing modularity between successive graphs, and PMOEO____ and MODPSO____ employ evolutionary algorithms to minimize the NMI of clusters across different timestamps. %ePMCL____ and HMM-MODCD____ use hidden Markov models to reconstruct clusters from previous timestamps and capture evolutionary patterns.
%%%%%%%%%%%%%%%%
Although these methods can simultaneously optimize clustering accuracy and temporal smoothness, they often suffer from low robustness and lack fine-grained node-level temporal smoothing strategies. In this study, we address these issues and enhance robustness, scalability, and practicality for large-scale real-world dynamic graphs. 

%\input{Main Paper/3-Preliminary}

\begin{figure*}[t]
\centering
\includegraphics*[clip=true,width=0.9\textwidth]{Figure/MFa6.pdf}
\caption{Overview architecture of proposed DyG-MF. 
Our method (a) first selects temporal landmarks and (b) randomly divides nodes into several groups for (c) separated matrix factorization ((a)-(c) introduced in Sec~{\ref{main_TSMF}}). 
In addition, we apply (d) bi-clustering regularization (Sec~{\ref{bi-clustering-module}})
and (e) selective embedding updating (Sec~{\ref{topological_dynamics}}) to dynamic graph clustering. 
}\label{figure:illustrate_smftii2}
%\vspace{-8pt}
\end{figure*}