\section{Related Work}
\label{related}
% Dynamic graph clustering methods are broadly categorized into two classes~\cite{DBLP:journals/csur/RossettiC18,DBLP:journals/tnn/SuXLWYZHPNJSY24}:  
% \textbf{\textit{(i) Neural Network}}-based methods and \textbf{\textit{(ii) Matrix Factorization}}-based methods.

%\vspace{3pt}
\textbf{Neural Network-based Methods.} 
Some neural network-based methods employ coupled approaches, which first condense dynamic graphs into one static graph and then apply clustering methods, such as CNN-based~\cite{9314087, DBLP:journals/kbs/SantoGMS21} and GNN-based 
methods~\cite{DBLP:journals/pami/ZhangNL23,zheng2022instant}, to identify clusters. 
Other methods employ two-stage approaches, which first learn dynamic graph embeddings~\cite{beer2023connecting,DBLP:conf/kdd/ZhangCFXZSC23,guo2022subset} and then apply clustering methods to these  embeddings to identify clusters~\cite{zhao2023spatial,DBLP:conf/KDD/CrossCityTransfer22,DBLP:journals/tnn/CuiLWZLWA24,Namyong,yang2024effective,chen2022efficient}.   
For example, RNNGCN~\cite{DBLP:conf/aaai/YaoJ21} and DGCN~\cite{DBLP:journals/tcyb/GaoZZWL23} use RNNs or LSTM to capture temporal dependencies for graph embeddings, which are then clustered using graph convolutional layers. 
CI-GCL~\cite{tan2024community} adopts a community invariance graph contrastive learning framework for graph clustering and classification.  
ROLAND~\cite{DBLP:conf/kdd/YouDL22} extends static GNN-based graph embedding methods to dynamic graphs by using gated recurrent units to capture temporal information. 
To reduce time consumption, SpikeNet~\cite{DBLP:conf/aaai/LiYZC0ZTWM23} uses spiking neural networks to model the evolving dynamics of graph embeddings, achieving better performance with lower computational costs. For more related work, refer to~\cite{cen2023cogdl,ZhangQianru,LiBolian,zhu2023wingnn}. 
The main issue with NN-based methods is their separation of dynamic graph embedding and clustering into two independent processes, making it difficult to ensure that graph embedding provides the most suitable features for clustering~\cite{DBLP:conf/ijcai/DongZSLC18,9531337}. Furthermore, most of them face weak scalability and interpretability issues on large-scale graphs~\cite{Hyenonsoo,WangCLZNL23}. 
%cannot consider topological and temporal information simultaneously. 
Thus, we focus on separated matrix factorization, jointly optimizing dynamic graph embedding and clustering, and improving scalability and interpretability. %(Please see details in Fig.{\ref{Hyper_parameter_tuning}(C)}).

%\vspace{3pt}
\noindent \textbf{Matrix Factorization-based Methods.} 
Matrix factorization-based methods cluster nodes at each timestamp using matrix factorization while optimizing the temporal smoothness of node embeddings among different timestamps. 
Recently, numerous methods with different strategies have been proposed to improve temporal smoothness. 
For example, sE-NMF~\cite{Ma17b}, jLMDC~\cite{9531337}, and NE2NMF~\cite{DBLP:journals/kbs/LiZDGM21} estimate temporal smoothness by analyzing topology changes between graphs at the current and previous timestamps, while PisCES~\cite{LiuF1801} smooths clusters by considering topology changes across the entire dynamic graph. 
%%%%
In contrast, other methods use clustering metrics or reconstruction loss to measure temporal smoothness. For example, DynaMo~\cite{DBLP:journals/tkde/ZhuangCL21} improves temporal smoothness by incrementally maximizing modularity between successive graphs, and PMOEO~\cite{DBLP:journals/kbs/ShenYTG22} and MODPSO~\cite{DBLP:journals/isci/YinZLD21} employ evolutionary algorithms to minimize the NMI of clusters across different timestamps. %ePMCL~\cite{WangWLGLZ22} and HMM-MODCD~\cite{DBLP:journals/air/AbboodAHEP23} use hidden Markov models to reconstruct clusters from previous timestamps and capture evolutionary patterns.
%%%%%%%%%%%%%%%%
Although these methods can simultaneously optimize clustering accuracy and temporal smoothness, they often suffer from low robustness and lack fine-grained node-level temporal smoothing strategies. In this study, we address these issues and enhance robustness, scalability, and practicality for large-scale real-world dynamic graphs. 

%\input{Main Paper/3-Preliminary}

\begin{figure*}[t]
\centering
\includegraphics*[clip=true,width=0.9\textwidth]{Figure/MFa6.pdf}
\caption{Overview architecture of proposed DyG-MF. 
Our method (a) first selects temporal landmarks and (b) randomly divides nodes into several groups for (c) separated matrix factorization ((a)-(c) introduced in Sec~{\ref{main_TSMF}}). 
In addition, we apply (d) bi-clustering regularization (Sec~{\ref{bi-clustering-module}})
and (e) selective embedding updating (Sec~{\ref{topological_dynamics}}) to dynamic graph clustering. 
}\label{figure:illustrate_smftii2}
%\vspace{-8pt}
\end{figure*}