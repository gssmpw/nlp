\section{Related Works}
Training of SNN typically follows two approaches: Artificial Neural Network (ANN)-to-SNN conversion and direct SNN training. The ANN-to-SNN method involves converting pre-trained ANNs by mapping parameters and replacing ReLU activation with spiking activation. 
For direct SNN training, recent advancements have introduced various improvements. The tdBN ____ enhances feature normalization in temporal and spatial dimensions , while MPBN ____ and TET stabilize the training process through better batch normalization and momentum control. 
Other innovations, such as SEW-ResNet and DS-ResNet, improve the adaptation of ResNet architectures to SNNs____. 
Techniques like IM-Loss ____ and model compression strategies also optimize information processing and advancing the applicability of SNNs____.

Several studies have demonstrated the advantages of adaptive LIF models____. For example, LSNN ____ and LTMD____ introduced adaptive threshold neurons, improving the learning dynamics of SNNs. Additionally, works such as PLIF incorporated a learnable membrane time constant to enhance the performance of spiking neurons____. Recent efforts like Diet-SNN and BDETT have further optimized neuron models by integrating learnable parameters such as membrane leak and firing thresholds____.
Despite these advances, current models do not independently address spatial and temporal aspects of neuron behavior. Future work could focus on separate learnable parameters for each dimension and layer, aligning more closely with biological observations and enhancing SNN expressiveness.