@article{bellec_long_2018,
	title = {Long short-term memory and {Learning}-to-learn in networks of spiking neurons},
	volume = {31},
	shorttitle = {{LSNN}},
	language = {en},
	urldate = {2024-06-06},
	journal = {Proceedings of NeurIPS},
	author = {Bellec, Guillaume and Salaj, Darjan and Subramoney, Anand and Legenstein, Robert and Maass, Wolfgang},
	year = {2018},
}

@inproceedings{chen_gradual_2022,
	title = {Gradual {Surrogate} {Gradient} {Learning} in {Deep} {Spiking} {Neural} {Networks}},
	doi = {10.1109/ICASSP43922.2022.9746774},
	abstract = {Spiking Neural Network (SNN) is a promising solution for ultra-low-power hardware. Recent SNNs have reached the performance of Deep Neural Networks (DNNs) in dealing with many tasks. However, these methods often suffer from a long simulation time to achieve the accurate spike train information. In addition, these methods are contingent on a well-designed initialization to effectively transmit the gradient information. To address these issues, we propose the Internal Spiking Neuron Model (ISNM), which uses the synaptic current instead of spike trains as the carrier of information. In addition, we design a gradual surrogate gradient learning algorithm to ensure that SNNs effectively back-propagate gradient information in the early stage of training and more accurate gradient information in the later stage of training. The experiments on various network structures on CIFAR-10 and CIFAR-100 datasets show that the proposed method can exceed the performance of previous SNN methods within 5 time steps.},
	urldate = {2024-06-27},
	booktitle = {ICASSP},
	author = {Chen, Yi and Zhang, Silin and Ren, Shiyu and Qu, Hong},
	month = may,
	year = {2022},
	note = {ISSN: 2379-190X},
	keywords = {/unread, Deep learning, Hardware, Learning systems, Neurons, Signal processing, Signal processing algorithms, Spiking Neural Networks, Spiking Neuron Model, Surrogate Gradient, Training},
	pages = {8927--8931},
}

@article{ding_biologically_2022,
	title = {Biologically {Inspired} {Dynamic} {Thresholds} for {Spiking} {Neural} {Networks}},
	volume = {35},
	shorttitle = {{BDETT}},
	language = {en},
	urldate = {2023-11-27},
	journal = {Proceedings of NeurIPS},
	author = {Ding, Jianchuan and Dong, Bo and Heide, Felix and Ding, Yufei and Zhou, Yunduo and Yin, Baocai and Yang, Xin},
	month = dec,
	year = {2022},
	keywords = {硬件},
	pages = {6090--6103},
}

@article{fang_deep_2021,
	title = {Deep {Residual} {Learning} in {Spiking} {Neural} {Networks}},
	volume = {34},
	shorttitle = {{SEW}-{ResNet}},
	abstract = {Deep Spiking Neural Networks (SNNs) present optimization difficulties for gradient-based approaches due to discrete binary activation and complex spatial-temporal dynamics.  Considering the huge success of ResNet in deep learning, it would be natural to train deep SNNs with residual learning. Previous Spiking ResNet mimics the standard residual block in ANNs and simply replaces ReLU activation layers with spiking neurons, which suffers the degradation problem and can hardly implement residual learning. In this paper, we propose the spike-element-wise (SEW) ResNet to realize residual learning in deep SNNs. We prove that the SEW ResNet can easily implement identity mapping and overcome the vanishing/exploding gradient problems of Spiking ResNet. We evaluate our SEW ResNet on ImageNet, DVS Gesture, and CIFAR10-DVS datasets, and show that SEW ResNet outperforms the state-of-the-art directly trained SNNs in both accuracy and time-steps.  Moreover, SEW ResNet can achieve higher performance by simply adding more layers, providing a simple method to train deep SNNs. To our best knowledge, this is the first time that directly training deep SNNs with more than 100 layers becomes possible. Our codes are available at https://github.com/fangwei123456/Spike-Element-Wise-ResNet.},
	urldate = {2023-08-22},
	journal = {Proceedings of NeurIPS},
	author = {Fang, Wei and Yu, Zhaofei and Chen, Yanqi and Huang, Tiejun and Masquelier, Timothée and Tian, Yonghong},
	year = {2021},
	keywords = {\#ref, SNN模型优化, 写 relatedwork},
	pages = {21056--21069},
}

@inproceedings{fang_incorporating_2021,
	title = {Incorporating {Learnable} {Membrane} {Time} {Constant} {To} {Enhance} {Learning} of {Spiking} {Neural} {Networks}},
	language = {en},
	urldate = {2023-11-15},
	booktitle = {Proceedings of {ICCV}},
	author = {Fang, Wei and Yu, Zhaofei and Chen, Yanqi and Masquelier, Timothée and Huang, Tiejun and Tian, Yonghong},
	year = {2021},
	keywords = {\#ref, PLIF, 可学习膜时间常数, ��LIF, ��learnable},
	pages = {2661--2671},
}

@inproceedings{feng_multi-level_2022,
	title = {Multi-{Level} {Firing} with {Spiking} {DS}-{ResNet}: {Enabling} {Better} and {Deeper} {Directly}-{Trained} {Spiking} {Neural} {Networks}},
	isbn = {978-1-956792-00-3},
	shorttitle = {{DS}-{ResNet}},
	doi = {10.24963/ijcai.2022/343},
	abstract = {Spiking neural networks (SNNs) are bio-inspired neural networks with asynchronous discrete and sparse characteristics, which have increasingly manifested their superiority in low energy consumption. Recent research is devoted to utilizing spatiotemporal information to directly train SNNs by backpropagation. However, the binary and nondifferentiable properties of spike activities force directly trained SNNs to suffer from serious gradient vanishing and network degradation, which greatly limits the performance of directly trained SNNs and prevents them from going deeper. In this paper, we propose a multi-level ﬁring (MLF) method based on the existing spatio-temporal back propagation (STBP) method, and spiking dormantsuppressed residual network (spiking DS-ResNet). MLF enables more efﬁcient gradient propagation and the incremental expression ability of the neurons. Spiking DS-ResNet can efﬁciently perform identity mapping of discrete spikes, as well as provide a more suitable connection for gradient propagation in deep SNNs. With the proposed method, our model achieves superior performances on a non-neuromorphic dataset and two neuromorphic datasets with much fewer trainable parameters and demonstrates the great ability to combat the gradient vanishing and degradation problem in deep SNNs.},
	language = {en},
	urldate = {2024-06-22},
	booktitle = {Proceedings of IJCAI},
	author = {Feng, Lang and Liu, Qianhui and Tang, Huajin and Ma, De and Pan, Gang},
	month = jul,
	year = {2022},
	pages = {2471--2477},
}

@article{guo_im-loss_2022,
	title = {{IM}-{Loss}: {Information} {Maximization} {Loss} for {Spiking} {Neural} {Networks}},
	volume = {35},
	shorttitle = {{IM}-{Loss}},
	language = {en},
	urldate = {2023-09-23},
	journal = {Proceedings of NeurIPS},
	author = {Guo, Yufei and Chen, Yuanpei and Zhang, Liwen and Liu, Xiaode and Wang, Yinglei and Huang, Xuhui and Ma, Zhe},
	month = dec,
	year = {2022},
	keywords = {\#ref, NeurIPS 2022, SNN模型优化, 写 relatedwork},
	pages = {156--166},
}

@inproceedings{guo_membrane_2023,
	title = {Membrane {Potential} {Batch} {Normalization} for {Spiking} {Neural} {Networks}},
	abstract = {As one of the energy-efficient alternatives of conventional neural networks (CNNs), spiking neural networks (SNNs) have gained more and more interest recently. To train the deep models, some effective batch normalization (BN) techniques are proposed in SNNs. All these BNs are suggested to be used after the convolution layer as usually doing in CNNs. However, the spiking neuron is much more complex with the spatio-temporal dynamics. The regulated data flow after the BN layer will be disturbed again by the membrane potential updating operation before the firing function, i.e., the nonlinear activation. Therefore, we advocate adding another BN layer before the firing function to normalize the membrane potential again, called MPBN. To eliminate the induced time cost of MPBN, we also propose a training-inference-decoupled re-parameterization technique to fold the trained MPBN into the firing threshold. With the re-parameterization technique, the MPBN will not introduce any extra time burden in the inference. Furthermore, the MPBN can also adopt the element-wised form, while these BNs after the convolution layer can only use the channel-wised form. Experimental results show that the proposed MPBN performs well on both popular non-spiking static and neuromorphic datasets. Our code is open-sourced at {\textbackslash}href\{https://github.com/yfguo91/MPBN\}\{MPBN\}.},
	urldate = {2023-08-20},
	booktitle = {Proceedings of ICCV},
	author = {Guo, Yufei and Zhang, Yuhan and Chen, Yuanpei and Peng, Weihang and Liu, Xiaode and Zhang, Liwen and Huang, Xuhui and Ma, Zhe},
	month = oct,
	year = {2023},
	keywords = {\#ref, Computer Science - Computer Vision and Pattern Recognition, SNN模型优化, 写 relatedwork, ��guoyufei, ��less than ours},
	pages = {19420--19430},
}

@article{hu_advancing_2024,
	title = {Advancing {Spiking} {Neural} {Networks} {Toward} {Deep} {Residual} {Learning}},
	issn = {2162-2388},
	shorttitle = {{MS}-{ResNet}},
	doi = {10.1109/TNNLS.2024.3355393},
	abstract = {Despite the rapid progress of neuromorphic computing, inadequate capacity and insufficient representation power of spiking neural networks (SNNs) severely restrict their application scope in practice. Residual learning and shortcuts have been evidenced as an important approach for training deep neural networks, but rarely did previous work assess their applicability to the characteristics of spike-based communication and spatiotemporal dynamics. In this paper, we first identify that this negligence leads to impeded information flow and the accompanying degradation problem in previous residual SNNs. To address this issue, we propose a novel SNN-oriented residual architecture termed MS-ResNet, which establishes membrane-based shortcut pathways, and further prove that the gradient norm equality can be achieved in MS-ResNet by introducing block dynamical isometry theory, which ensures the network can be well-behaved in a depth-insensitive way. Thus we are able to significantly extend the depth of directly trained SNNs, e.g., up to 482 layers on CIFAR-10 and 104 layers on ImageNet, without observing any slight degradation problem. To validate the effectiveness of MS-ResNet, experiments on both frame-based and neuromorphic datasets are conducted. MS-ResNet104 achieves a superior result of 76.02\% accuracy on ImageNet, which is the highest to our best knowledge in the domain of directly trained SNNs. Great energy efficiency is also observed, with an average of only one spike per neuron needed to classify an input sample. We believe our powerful and scalable models will provide a strong support for further exploration of SNNs.},
	urldate = {2023-11-13},
	journal = {TNNLS},
	author = {Hu, Yifan and Deng, Lei and Wu, Yujie and Yao, Man and Li, Guoqi},
	year = {2024},
	keywords = {\#ref, MS-ResNet, SNN-oriented residual architecture, biclab, 写 relatedwork, ��energy},
	pages = {1--15},
}

@inproceedings{liu_event-based_2022,
	title = {Event-{Based} {Multimodal} {Spiking} {Neural} {Network} with {Attention} {Mechanism}},
	doi = {10.1109/ICASSP43922.2022.9746865},
	abstract = {Human brain can effectively integrate visual and auditory information. Dynamic Vision Sensor (DVS) and Dynamic Audio Sensor (DAS) are event-based sensors imitating the mechanism of human retina and cochlea. Since the sensors record the visual and auditory input as asynchronous discrete events, they are inherently suitable to cooperate with the spiking neural network (SNN). Existing works of SNNs for processing events mainly focus on unimodality, however, audiovisual multimodal SNNs are still limited. In this paper, we propose an end-to-end event-based multimodal spiking neural network. The network consists of visual and auditory unimodal subnetworks and a novel attention-based cross-modal subnetwork for fusion. The attention mechanism measures the significance of each modality and allocates the weights to two modalities. We evaluate our proposed multimodal network on an event-based audiovisual joint dataset (MNIST-DVS and N-TIDIGITS datasets). Experimental results show the performance improvement of this multimodal network and the effectiveness of our proposed attention mechanism.},
	urldate = {2024-03-03},
	booktitle = {ICASSP},
	author = {Liu, Qianhui and Xing, Dong and Feng, Lang and Tang, Huajin and Pan, Gang},
	month = may,
	year = {2022},
	note = {ISSN: 2379-190X},
	keywords = {Attention, Convolution, Ear, Retina, Vision sensors, Visualization, Weight measurement, dynamic audio sensors, dynamic vision sensors, multimodal learning, spiking neural networks},
	pages = {8922--8926},
}

@article{rathi_diet-snn_2023,
	title = {{DIET}-{SNN}: {A} {Low}-{Latency} {Spiking} {Neural} {Network} {With} {Direct} {Input} {Encoding} and {Leakage} and {Threshold} {Optimization}},
	volume = {34},
	issn = {2162-2388},
	shorttitle = {{DIET}-{SNN}},
	doi = {10.1109/TNNLS.2021.3111897},
	abstract = {Bioinspired spiking neural networks (SNNs), operating with asynchronous binary signals (or spikes) distributed over time, can potentially lead to greater computational efficiency on event-driven hardware. The state-of-the-art SNNs suffer from high inference latency, resulting from inefficient input encoding and suboptimal settings of the neuron parameters (firing threshold and membrane leak). We propose DIET-SNN, a low-latency deep spiking network trained with gradient descent to optimize the membrane leak and the firing threshold along with other network parameters (weights). The membrane leak and threshold of each layer are optimized with end-to-end backpropagation to achieve competitive accuracy at reduced latency. The input layer directly processes the analog pixel values of an image without converting it to spike train. The first convolutional layer converts analog inputs into spikes where leaky-integrate-and-fire (LIF) neurons integrate the weighted inputs and generate an output spike when the membrane potential crosses the trained firing threshold. The trained membrane leak selectively attenuates the membrane potential, which increases activation sparsity in the network. The reduced latency combined with high activation sparsity provides massive improvements in computational efficiency. We evaluate DIET-SNN on image classification tasks from CIFAR and ImageNet datasets on VGG and ResNet architectures. We achieve top-1 accuracy of 69\% with five timesteps (inference latency) on the ImageNet dataset with 12{\textbackslash}times less compute energy than an equivalent standard artificial neural network (ANN). In addition, DIET-SNN performs 20– 500{\textbackslash}times faster inference compared to other state-of-the-art SNN models.},
	number = {6},
	urldate = {2023-11-12},
	journal = {IEEE TNNLS},
	author = {Rathi, Nitin and Roy, Kaushik},
	month = jun,
	year = {2023},
	keywords = {\#ref, ��learnable},
	pages = {3174--3182},
}

@article{wang_ltmd_2022,
	title = {{LTMD}: {Learning} {Improvement} of {Spiking} {Neural} {Networks} with {Learnable} {Thresholding} {Neurons} and {Moderate} {Dropout}},
	volume = {35},
	shorttitle = {{LTMD}},
	language = {en},
	urldate = {2023-09-23},
	journal = {Proceedings of NeurIPS},
	author = {Wang, Siqi and Cheng, Tee Hiang and Lim, Meng-Hiot},
	month = dec,
	year = {2022},
	keywords = {\#ref, NeurIPS 2022, 写 relatedwork, ��learnable},
	pages = {28350--28362},
}

@inproceedings{xu2024rsnn,
  title={RSNN: Recurrent Spiking Neural Networks for Dynamic Spatial-Temporal Information Processing},
  author={Xu, Qi and Fang, Xuanye and Li, Yaxin and Shen, Jiangrong and Ma, De and Xu, Yi and Pan, Gang},
  booktitle={ACM Multimedia 2024}
}

@inproceedings{xu_constructing_2023,
	title = {Constructing {Deep} {Spiking} {Neural} {Networks} {From} {Artificial} {Neural} {Networks} {With} {Knowledge} {Distillation}},
	language = {en},
	urldate = {2023-10-11},
	booktitle = {Proceedings of {CVPR}},
	author = {Xu, Qi and Li, Yaxin and Shen, Jiangrong and Liu, Jian K. and Tang, Huajin and Pan, Gang},
	month = jun,
	year = {2023},
	keywords = {\#ref, ��ANN2SNN, ��dl},
	pages = {7886--7895},
}

@article{zheng_going_2021,
	title = {Going {Deeper} {With} {Directly}-{Trained} {Larger} {Spiking} {Neural} {Networks}},
	volume = {35},
	copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
	shorttitle = {{TDBN}},
	doi = {10.1609/aaai.v35i12.17320},
	abstract = {Spiking neural networks (SNNs) are promising in a bio-plausible coding for spatio-temporal information and event-driven signal processing, which is very suited for energy-efficient implementation in neuromorphic hardware. However, the unique working mode of SNNs makes them more difficult to train than traditional networks. Currently, there are two main routes to explore the training of deep SNNs with high performance. The first is to convert a pre-trained ANN model to its SNN version, which usually requires a long coding window for convergence and cannot exploit the spatio-temporal features during training for solving temporal tasks. The other is to directly train SNNs in the spatio-temporal domain. But due to the binary spike activity of the firing function and the problem of gradient vanishing or explosion, current methods are restricted to shallow architectures and thereby difficult in harnessing large-scale datasets (e.g. ImageNet). To this end, we propose a threshold-dependent batch normalization (tdBN) method based on the emerging spatio-temporal backpropagation, termed “STBP-tdBN”, enabling direct training of a very deep SNN and the efficient implementation of its inference on neuromorphic hardware. With the proposed method and elaborated shortcut connection, we significantly extend directly-trained SNNs from a shallow structure (},
	language = {en},
	urldate = {2024-01-16},
	journal = {Proceedings of AAAI},
	author = {Zheng, Hanle and Wu, Yujie and Deng, Lei and Hu, Yifan and Li, Guoqi},
	month = may,
	year = {2021},
	note = {Number: 12},
	keywords = {\#ref, (Deep) Neural Network Learning Theory},
	pages = {11062--11070},
}

