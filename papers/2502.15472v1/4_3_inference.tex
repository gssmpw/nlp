\section{Extended VIB for Edge-based Autonomous Driving}
\label{sec:edge_AI}
\gls{tgcp}\footnote{To avoid confusion with the Transmission Control Protocol (TCP), we denote Trajectory-guided Control Prediction as TGCP in this paper.} is the state-of-the-art \gls{e2e} self-driving framework that combines trajectory planning and multi-stage control prediction into a unified neural network \cite{Wu_2022_TgC}. 
This framework, notable for using only a monocular camera, ranks third on the CARLA leaderboard\footnote{\url{https://leaderboard.carla.org/leaderboard/}}. 
We extend \gls{vib} to \gls{tgcp} to examine its applicability in an edge-based autonomous driving system.

\subsection{Background of TGCP}
\gls{tgcp} at the edge server processes task-specific data $\bm{y}$ and additional state information $\bm{m}$ to make driving decisions. The state information includes variables such as speed, destination coordinates, and current driving guidance (e.g., ``turn left'' or ``follow the lane''). For this study, we assume that $\bm{m}$ can be transmitted losslessly to the edge server. 

The autonomous driving agent is modeled as $q_{\psi}(\bm{a}|\bm{y})$, which generates the inferred action $\hat{\bm{a}}$ from task-specific data $\bm{y}$. In particular, the individual components of the inferred action $\hat{\bm{a}} = (\hat{v}, \hat{s}, \hat{\bm{w}}, \hat{\bm{f}}^{\text{traj}}, \hat{\bm{b}}, \hat{\bm{f}}^{\text{ctrl}})$ are defined as follows:
\begin{itemize}
    \item $\hat{v}$: estimated target speed.
    \item $\hat{s}$: value of the extracted features estimated by the expert \cite{Zhang_2021_EtE}.
    \item $\hat{\bm{w}}$: predicted waypoints from the trajectory branch.
    \item $\hat{\bm{f}}^{\text{traj}}$: estimated extracted features for trajectory planning.
    \item $\hat{\bm{b}} = [\hat{\bm{b}}_0, \hat{\bm{b}}_1, \dots, \hat{\bm{b}}_\Gamma]$: estimated control actions from the beta distribution in the control prediction branch, where $\Gamma$ denotes the prediction length.
    \item $\hat{\bm{f}}^{\text{ctrl}} = [\hat{\bm{f}}^{\text{ctrl}}_0, \hat{\bm{f}}^{\text{ctrl}}_1, \dots, \hat{\bm{f}}^{\text{ctrl}}_\Gamma]$: predicted informative features of the control prediction branch.
\end{itemize}

\subsection{Control and Trajectory Prediction Loss Functions}
The designed controller, based on \cite{Wu_2022_TgC}, computes control commands such as throttle, steer, and brake using the output of the trajectory and control prediction branches. The corresponding loss functions are defined as:
\begin{align}
    \mathcal{L}_{\text{traj}} =& \|\bm{w} - \hat{\bm{w}}\|_1 + \lambda_{\text{feat}}\|\bm{f}^{\text{traj}} - \hat{\bm{f}}^{\text{traj}}\|_2, \\
    \mathcal{L}_{\text{ctrl}}
    =& D_{\text{KL}}(\mathcal{B}e(\bm{b}_{0})\|\mathcal{B}e(\hat{\bm{b}}_{0}))  \notag\\
    &+\frac{1}{\Gamma}\sum_{i=1}^{\Gamma}D_{\text{KL}}(\mathcal{B}e(\bm{b}_{i})\|\mathcal{B}e(\hat{\bm{b}}_{i})) \notag\\
    & + \lambda_{\text{feat}}\|\bm{f}^{\text{ctrl}}_{0} - \hat{\bm{f}}^{\text{ctrl}}_{0}\|_{2}
    + \frac{1}{\Gamma}\sum_{i=1}^{\Gamma}\|\bm{f}^{\text{ctrl}}_{i} - \hat{\bm{f}}^{\text{ctrl}}_{i}\|_{2},
\end{align}
where $\lambda_\text{feat}$ is a hyperparameter, $\bm{w}$, $\bm{f}^{\text{traj}}$, $\bm{b}_{i}$, and $\bm{f}_{i}^{\text{ctrl}}$ are from the ground truth action $\bm{a}$, $\|\cdot\|_{1}$ denotes the $\ell_{1}$-norm, and $\mathcal{B}e(\cdot)$ denotes the beta distribution.

Furthermore, the auxiliary loss function is defined as:
\begin{equation}
    \mathcal{L}_{\text{aux}} = \|v-\hat{v}\|_{1} + \|s-\hat{s}\|_{2},
\end{equation}
where speed $v$ and value of features $s$ are from the ground truth action $\bm{a}$. Combining these terms, the overall loss function $\mathcal{L}_{\text{TCGP}}$ becomes:
\begin{equation}
    \mathcal{L}_{\text{TCGP}} = \lambda_{\text{traj}}\mathcal{L}_{\text{traj}} + \lambda_{\text{ctrl}}\mathcal{L}_{\text{ctrl}} + \lambda_{\text{aux}}\mathcal{L}_{\text{aux}},
\end{equation}
where $\lambda_{\text{traj}}$, $\lambda_{\text{ctrl}}$, and $\lambda_{\text{aux}}$ are hyperparameters.

\subsection{Task-Oriented End-to-End Training}
\label{subsec_task-oriented_training}
Typically, we assume that the posterior $q_{\psi}(\bm{a}|\bm{y})$ follows a Gaussian distribution $\mathcal{N}(\bm{\mu}_{\psi}(\bm{y}), \bm{\Sigma}_{\psi}(\bm{y}))$, where $\bm{\mu}_{\psi}(\bm{y})\in\mathbb{R}^{d}$ and $\bm{\Sigma}_{\psi}(\bm{y})=\sigma_{c}^{2}I_{d}$ ($\sigma_{c}$ is a constant). According to the probability density function of the Gaussian distribution, we can derive the following expression,
\begin{align}
    -\log{q_{\psi}(\bm{a}|\bm{y})}\sim \frac{1}{2\sigma^{2}_{c}}\|\bm{a}-\bm{\mu}_{\psi}(\bm{y}) \|^2_2,
    \label{eq_log2normal}
\end{align}
where $\bm{\mu}_{\psi}(\bm{y})=\hat{\bm{a}}$.
Details of the derivation are deferred to the Appendix \ref{apd:derivation_log}. \cref{eq_log2normal} shows that $-\log q_{\psi}(\bm{a}|\bm{y})$ can serve as a distance metric, like the $\ell^2$-norm. 
Since $\mathcal{L}_{\text{TCGP}}$ is a combination of distance metric of action $\bm{a}$ ($\ell^1$-norm, $\ell^2$-norm, and \gls{kl} divergence), we heuristically propose substituting the first term in \cref{eq_VIB_theory} with $\mathcal{L}_{\text{TCGP}}$ to adapt the objective function as:
\begin{align}
\mathcal{L}_{\text{VIB}}'(\bm{a}, \bm{x};\phi, \theta)=\mathbb{E}_{\bm{a},\bm{x}}&\Bigl\{
\mathcal{L}_{\text{TCGP}} \notag\\
&+\hat{\beta}_1 D_{\text{KL}}(p_{\phi}(\hat{\bm{z}} | \bm{x}) \| q(\hat{\bm{z}})) \notag\\
&+\hat{\beta}_2 \mathbb{E}_{\hat{\bm{z}}|\bm{x};\phi,\theta}[-\log q_{\delta}(\bm{a}|\hat{\bm{z}})]
\Bigr\}.
\label{eq_VIB_2}
\end{align}
In addition, the \cref{eq_loss_VIBQ} can be modified as:
\begin{align}
    \mathcal{L}_{\text{VIB-}Q}'(\bm{a}, \bm{x};\phi,\theta)=\mathcal{L}_{\text{VIB}}'(\bm{a}, \bm{x};\phi,\theta) + \beta_{Q}\mathcal{L}_{Q}(\bm{z};r^*).
    \label{eq_loss_VIBQ_2}
\end{align}

Training of \gls{jscc} encoder and information reshaper consists of two stages: pre-training and fine-tuning. In pre-training, the neural network parameters (\(\phi\) and \(\theta\)) are initialized, and images from the dataset are encoded into \gls{jscc} symbols, transmitted through a channel without modulation, and reshaped into task-specific data. The \gls{tgcp} model, with frozen parameters, generates inferred actions \(\hat{\bm{a}}\), and the loss \(\mathcal{L}_{\text{VIB}}'\) is computed to update the network parameters. Fine-tuning follows a similar process, but the symbols are transmitted with JSCC modulation, and the loss \(\mathcal{L}_{\text{VIB-}Q}'\) is used for parameter updates. Finally, the optimized parameters \(\phi\) and \(\theta\) are output. The training process of the proposed aligned task- and reconstruction-oriented \gls{jscc} encoder and information reshaper is shown in \cref{alg_training}. Here, \(\text{CH}(\cdot)\) denotes the function of a \gls{jscc} modulation and communication channel, while \(\text{TGCP}(\cdot)\) denotes the function of \gls{tgcp}. Specifically, during the fine-tuning process, both the JSCC encoder and the information reshaper are actively adjusted, which means that neither component is frozen. This fine-tuning process reduces the quantization loss of the encoder's output and preserves task-critical information, showing the potential for real-world applications.

\input{Algorithm/alg_training}



