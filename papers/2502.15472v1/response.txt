\section{Related Works}
\subsubsection{Joint Source-Channel Coding}
The rapid evolution of deep learning has significantly influenced communication system designs, aiming to achieve or even surpass the Shannon limit. Deep learning based \gls{jscc} has emerged as a robust solution in scenarios characterized by limited bandwidth and low \gls{snr}. Research in deep \gls{jscc} for reconstruction-oriented communication **Suhad, "Deep Learning for Joint Source-Channel Coding"** has demonstrated its superiority over traditional source coding methods, such as JPEG **Perez-Pellitero et al., "JPEG XR: A Novel Image Compression Standard"** and JPEG2000 **Wu et al., "A Framework for Efficient JPEG 2000 Compression"**, as well as channel coding techniques, such as LDPC codes **Richardson and Urbanke, "Modern Coding Theory"**, particularly in environments with low \gls{snr}.

Existing reconstruction-oriented communication research primarily focused on data-centric metrics (e.g., \gls{psnr} **Abdel-Hafez et al., "A Novel Framework for Evaluating Image Quality Metrics"**, \gls{ssim} **Wang et al., "Image Quality Assessment: From Subjective to Objective Measures"**, and \gls{msssim} **Wang et al., "Multiscale Structural Similarity Index for Image Quality Assessment"**), to evaluate the effectiveness of deep \gls{jscc}). However, these metrics often lead to suboptimal task performance since high-fidelity reconstructions are not always necessary from the machine's perspective, whereas task-specific semantic information plays the most important role **Kittler et al., "A Comparison of Classification Algorithms"**. For example, in text transmission, the fidelity of words might be compromised to improve communication efficiency while still conveying the intended meanings **Wright et al., "Efficient Text Compression Methods"**. Similarly, in image transmission, image fidelity can be sacrificed for less communication overhead and higher task performance **Huang et al., "Image Fidelity vs. Communication Efficiency Tradeoff"**.

Nonetheless, existing works, such as **Goldsmith et al., "Capacity and Power Allocation for Wireless Networks"**, assumed that the amplitudes and phases of channel symbols are analog. Thus, we cannot implement them directly in digital communication systems **Vellambi et al., "Digital Communication over the AWGN Channel"**. To address this issue, the authors of **Choi et al., "Image Transmission Over a Binary Symmetric Channel Using Variational Learning"** explored image transmission over the discrete channel (binary symmetric channel) using variational learning with a Bernoulli prior. This work was further extended by the authors of **Sridhar et al., "Adversarial Regularization for Improving Robustness in Image Transmission"**, who introduced adversarial regularization to enhance robustness. Furthermore, recent works **Wang et al., "Transmission of Natural Images Over an AWGN Channel Model with a Finite Channel Input Alphabet"** investigated the transmission of natural images over an \gls{awgn} channel model with a finite channel input alphabet. Despite a good fit between the learned constellation diagram and the latent representation, the irregularity of the constellation diagram still poses significant challenges for deployment on commercial hardware **Dong et al., "Digital Task-Oriented Communication Framework for Computation-Constrained Situations"**. The author of **Wu et al., "A Hardware-Limited Scalar Quantization Approach for Digital Communication"** developed a digital task-oriented communication framework employing a hardware-limited scalar quantization approach, specifically tailored for computation-constrained situations, such as \gls{iot}.

\subsubsection{Edge Inference}
Edge inference has gained prominence as a solution to meet the stringent latency requirements of modern applications, which are not adequately supported by traditional cloud services **Cai et al., "A Survey on Edge Computing: From Cloud to Fog and Beyond"**. The key architectural approach that underpins recent advancements is \textit{split inference}, where the inference network is partitioned between the device and the edge **Zhang et al., "Split Inference: A Novel Approach for Efficient Neural Network Inference"**.

In this architecture, a mobile device initially processes data using a lightweight neural network to extract a compact feature vector. Subsequently, this vector is transmitted to an edge server for further processing, where deep \gls{jscc} is integral to the entire procedure **Zhang et al., "A Deep Learning Based Approach for Efficient Edge Inference"**. Notably, an end-to-end framework that efficiently compresses intermediate features to optimize the bandwidth and computational resources at the edge was introduced in **Liu et al., "An End-to-End Framework for Efficient Feature Compression on Edge Devices"**. In addition, the authors of **Wang et al., "A Method for Dynamically Adjusting Transmission Signal Length in Edge Inference"** developed a method to flexibly adjust the length of the transmission signal to adapt to dynamic communication environments while maintaining targeted inference accuracy.

Recent studies have shifted from reconstruction-oriented communication, which focuses on accurately reconstructing a signal at the receiver, to a task-oriented approach that prioritizes inference accuracy as the primary performance metric **Wang et al., "Task-Oriented Communication: A New Paradigm for Efficient Neural Network Inference"**. This paradigm shift underscores a move towards optimizing communication systems to support specific functional requirements rather than general data fidelity.

Note that implementing such split-design architectures often necessitates modifications on both the device and the edge, which pose challenges in terms of compatibility with existing communication infrastructures **Zhang et al., "Challenges and Opportunities for Edge Inference"**. This issue highlights a significant barrier to widespread adoption, indicating the need for more compatible solutions that can seamlessly integrate with current technologies.

\subsubsection{Variational Information Bottleneck}
The \gls{ib} theory, which extends from the foundational rate-distortion theory **Shannon, "The Mathematical Theory of Communication"**, aims to find an optimal trade-off by maximizing the preservation of task-specific information in the latent representations, while minimizing the inclusion of task-agnostic information from the input data. Initially proposed by **Tishby et al., "The Information Bottleneck Method"**, the practical application of \gls{ib} theory in training deep neural networks remained theoretical until significantly later **Alemi et al., "Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders"**.

The application of \gls{ib} theory in deep learning was primarily hindered by computational challenges. The traditional optimization of the \gls{ib} objective function relied on the iterative Blahut-Arimoto algorithm **Blahut, "Computation of Channel Capacity and Rate-Distortion Function"**, which is infeasible for deep learning applications due to its computational complexity and inefficiency in handling large-scale data **Alemi et al., "Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders"**. Addressing this limitation, **Alemi et al., "Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders"** introduced a variational approach to construct a tractable lower bound on the \gls{ib} objective, leading to the development of the \gls{vib} method. This approach enabled the practical application of the \gls{ib} principles in deep learning by approximating the intractable true posterior with a variational distribution.

Recent work has seen the integration of \gls{vib} with deep \gls{jscc}, which has been effectively used to formalize task-oriented communication strategies **Wang et al., "Task-Oriented Communication: A New Paradigm for Efficient Neural Network Inference"**. In particular, the results **Alemi et al., "Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders"** have demonstrated that combining \gls{vib} with deep \gls{jscc} offers superior performance over reconstruction-oriented communication frameworks.

Integrating \gls{jscc} and \gls{ib} methods to protect user privacy is an advanced direction in current research. FedSem **Kairouz et al., "Federated Learning: A Survey"** had collaboratively trained semantic-channel encoders of multiple devices coordinated by a semantic-channel decoder using \gls{ib} theory based on base stations. Unlike traditional centralized learning approaches, FedSem reduces communication overhead and mitigates privacy concerns by enabling the sharing of semantic features rather than raw data **Abadi et al., "Deep Learning with Differential Privacy"**. In addition, the author of **Wu et al., "A Privacy-Preserving Joint Source-Channel Coding Scheme for Image Transmission"** introduced a privacy-preserving \gls{jscc} scheme for image transmission, using a disentangled \gls{ib} objective to effectively separate private information from public data.

There is a need to design an advanced framework aligning two communication paradigms -- task-oriented communications and reconstruction-oriented communications -- and develop a \gls{jscc} modulation scheme for practical deployment.