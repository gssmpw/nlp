\section{Related Works}
\subsection{LLMs and RAG in Healthcare} 
Large Language Models (LLMs) have been increasingly applied to healthcare tasks such as EHR analysis, clinical note generation, virtual medical assistant, and clinical decision support**Brown et al., "Large Language Models"**. Although LLMs fine-tuned on medical datasets can handle large amounts of unstructured clinical information, most of these models are heuristic-based, with limitations such as generating incorrect or vague information and struggling to handle complex patient cases**Huang et al., "Clinical Decision Support Systems"**. To address this, integrating external information sources becomes essential to improve their contextual accuracy. We adopt a Retrieval-Augmented Generation (RAG) approach**Khandelwal et al., "Retrieval-Augmented Generation"**. 
% 
RAG enhances LLMs by incorporating retrieved text passages from external sources such as electronic health records, medical papers, textbooks, and databases into their input, resulting in significant improvements in knowledge-intensive tasks**Guu et al., "RealTOFul Text-based Dialogue Systems"**. In the field of healthcare, integrating retrieved information grounds the predictions in current, verifiable medical data, resulting in more accurate, specificity and context-aware outputs such as diagnostic assessments and treatment recommendations.
% 
RAG typically employs a retrieve-and-read approach to retrieve information based on the initial user query and an answer is generated using that content**Lewis et al., "Pre-trained Models for NLP"**. 
However, this simplicity restricts their ability to adapt to complex and evolving medical cases.
Enhanced RAG models aim to improve retrieval and generation quality by integrating more sophisticated components such as retrievers, re-rankers, filters, and readers**Zhu et al., "Knowledge Graph-enhanced LLMs"**.
Despite these advancements, delivering accurate clinical decision support remains challenging. The models often struggle to provide precise diagnoses, particularly when diseases share similar manifestations, making differentiation difficult.
Our proposed MedRAG addresses these challenges by systematically constructing a four-tier hierarchical diagnostic knowledge graph to elicit reasoning for the generation module of RAG. This approach enables the model to make accurate diagnostic decisions and generate highly specific diagnoses along with personalized treatment recommendations.

\subsection{Knowledge Graph-enhanced LLMs and RAG}
Recent studies have focused on creating strategies that integrate knowledge graphs to enhance LLMs and RAG, enabling them to generate accurate and reliable medical responses. Compared to knowledge contained in document repositories**Bordes et al., "Translating Embeddings for Similarity Search"**, knowledge graphs offer structured and inferable information, making them more suitable for augmenting LLMs and RAG**Kolomakov et al., "Knowledge Graph-based Dialogue Systems"**. 
Several works**Liu et al., "Graph-based Knowledge Distillation"** propose training sequence-to-sequence models from scratch, focusing on dialogue generation by conditioning the output on entities extracted from knowledge graphs.
% 
However, existing medical knowledge graphs**Sun et al., "Medical Knowledge Graph Construction"** often fall short because they lack the detailed and structured information necessary for accurate diagnostic assistance, especially when distinguishing between diseases with similar manifestations. To overcome this limitation, we introduce MedRAG, a framework that combines RAG with a comprehensive diagnostic knowledge graph to enhance the reasoning ability of RAG in identifying subtle differences in diagnoses. MedRAG allows physicians to input patients' medical records or manifestations.
Our knowledge graph is constructed based on patterns extracted from Electronic Health Record (EHR) databases and augmented by LLMs, making it highly scalable and adaptable to various medical specialties. It supports customization with local databases, ensuring relevance to specific clinical settings. We employ LLMs to enrich the knowledge graph by providing detailed descriptions of the manifestations of each disease at the leaf nodes, including symptoms, affected areas, activity limitations, and other pertinent features.