\begin{table*}[t]
    \small
    \centering
    \begin{adjustbox}{max width=0.95\textwidth}
    {
    \begin{tabular}{lcccc}
        \toprule
        
        \textbf{VLM} & \textbf{Query Type} & \textbf{Fine-tuned?} & \textbf{Length Comparison} & \textbf{Chart Projection}\\
        
        \midrule
        \multirow{5}{*}{LLaVA-v1.5-7B} & - & {\color{darkred} \xmark } & 50.0 & 51.3\\
        \cmidrule{2-5}
         & \textsc{Original} & {\color{lightgreen} \cmark} & 95.4 & \textbf{98.9}\\
         & \textsc{Empty} & {\color{lightgreen} \cmark} & 95.2 & 98.1\\
         & \textsc{Irrelevant} & {\color{lightgreen} \cmark} & \textbf{95.8} & 97.8\\
         
         
         
        
        
        \bottomrule
    \end{tabular}
    }
    \end{adjustbox}
    \vspace{-2mm}
    
    \caption{Accuracy (\%) of fine-tuned LLaVA-v1.5-7B with different queries on the test set of each probing task. We conduct experiments by freezing the vision encoder and only fine-tune the LLM decoder for binary classification.}
    \label{tab:probing_llm}
    \vspace{-5mm}
\end{table*}

