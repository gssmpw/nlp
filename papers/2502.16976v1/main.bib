@inproceedings{sundermeyer2021contact,
  title={Contact-graspnet: Efficient 6-dof grasp generation in cluttered scenes},
  author={Sundermeyer, Martin and Mousavian, Arsalan and Triebel, Rudolph and Fox, Dieter},
  booktitle={ICRA},
  year={2021},
}

% ------------------------6-dof---------------------------------

@inproceedings{varley20156-DofGraspoing,
  title={Generating multi-fingered robotic grasps via deep learning},
  author={Varley, Jacob and Weisz, Jonathan and Weiss, Jared and Allen, Peter},
  booktitle={IROS},
  year={2015},
}

@inproceedings{mousavian20196dofgraspnet,
  title={6-dof graspnet: Variational grasp generation for object manipulation},
  author={Mousavian, Arsalan and Eppner, Clemens and Fox, Dieter},
  booktitle={CVPR},
  year={2019}
}

@article{dexnet-6dofgrasp,
  title={Dex-net 2.0: Deep learning to plan robust grasps with synthetic point clouds and analytic grasp metrics},
  author={Mahler, Jeffrey and Liang, Jacky and Niyaz, Sherdil and Laskey, Michael and Doan, Richard and Liu, Xinyu and Ojea, Juan Aparicio and Goldberg, Ken},
  journal={arXiv preprint arXiv:1703.09312},
  year={2017}
}

@article{6-dofview,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={IJRR},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{murali20206dofgrasping,
  title={6-dof grasping for target-driven object manipulation in clutter},
  author={Murali, Adithyavairavan and Mousavian, Arsalan and Eppner, Clemens and Paxton, Chris and Fox, Dieter},
  booktitle={ICRA},
  year={2020},
}

@inproceedings{GSNet,
  title={Graspness discovery in clutters for fast and accurate grasp detection},
  author={Wang, Chenxi and Fang, Hao-Shu and Gou, Minghao and Fang, Hongjie and Gao, Jin and Lu, Cewu},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{ni2020pointnet++grasp,
  title={Pointnet++ grasping: Learning an end-to-end spatial grasp generation algorithm from sparse point clouds},
  author={Ni, Peiyuan and Zhang, Wenguang and Zhu, Xiaoxiao and Cao, Qixin},
  booktitle={ICRA},
  year={2020},
}

%------------------------------reactive-grasping----------------------------------
@inproceedings{liu2023reactivegrasping,
  title={Target-referenced reactive grasping for dynamic objects},
  author={Liu, Jirong and Zhang, Ruo and Fang, Hao-Shu and Gou, Minghao and Fang, Hongjie and Wang, Chenxi and Xu, Sheng and Yan, Hengxu and Lu, Cewu},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{akinola2021dynamicgrasping,
  title={Dynamic grasping with reachability and motion awareness},
  author={Akinola, Iretiayo and Xu, Jingxi and Song, Shuran and Allen, Peter K},
  booktitle={IROS},
  year={2021},
}

@article{marturi2019dynamicgrasping,
  title={Dynamic grasp and trajectory planning for moving objects},
  author={Marturi, Naresh and Kopicki, Marek and Rastegarpanah, Alireza and Rajasekaran, Vijaykumar and Adjigble, Maxime and Stolkin, Rustam and Leonardis, Ale{\v{s}} and Bekiroglu, Yasemin},
  journal={Autonomous Robots},
  volume={43},
  pages={1241--1256},
  year={2019},
  publisher={Springer}
}
@inproceedings{yang2021reactivegrasping,
  title={Reactive human-to-robot handovers of arbitrary objects},
  author={Yang, Wei and Paxton, Chris and Mousavian, Arsalan and Chao, Yu-Wei and Cakmak, Maya and Fox, Dieter},
  booktitle={ICRA},
  year={2021},
}

% ------------------------- target oriented -----------------------
@inproceedings{liu2022targetoriented,
  title={Ge-grasp: Efficient target-oriented grasping in dense clutter},
  author={Liu, Zhan and Wang, Ziwei and Huang, Sichao and Zhou, Jie and Lu, Jiwen},
  booktitle={IROS},
  year={2022},
}

@article{li2022targetoriented,
  title={Learning Target-Oriented Push-Grasping Synergy in Clutter With Action Space Decoupling},
  author={Li, Enbo and Feng, Haibo and Zhang, Songyuan and Fu, Yili},
  journal={RAL},
  year={2022},
  publisher={IEEE}
}

@inproceedings{kurenkov2020targetoriented,
  title={Visuomotor mechanical search: Learning to retrieve target objects in clutter},
  author={Kurenkov, Andrey and Taglic, Joseph and Kulkarni, Rohun and Dominguez-Kuhne, Marcus and Garg, Animesh and Mart{\'\i}n-Mart{\'\i}n, Roberto and Savarese, Silvio},
  booktitle={IROS},
  year={2020},
}

% ------------------------dataset---------------------------------
@inproceedings{fang2020graspnet1billion,
  title={Graspnet-1billion: A large-scale benchmark for general object grasping},
  author={Fang, Hao-Shu and Wang, Chenxi and Gou, Minghao and Lu, Cewu},
  booktitle={CVPR},
  year={2020}
}

% --------------------------- point sampling ------------------------------------
@article{GPD,
  title={Grasp pose detection in point clouds},
  author={Ten Pas, Andreas and Gualtieri, Marcus and Saenko, Kate and Platt, Robert},
  journal={IJRR},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{pointnetGPD,
  title={Pointnetgpd: Detecting grasp configurations from point sets},
  author={Liang, Hongzhuo and Ma, Xiaojian and Li, Shuang and G{\"o}rner, Michael and Tang, Song and Fang, Bin and Sun, Fuchun and Zhang, Jianwei},
  booktitle={ICRA},
  year={2019},
}


% -------------------Task-oriented-grasping--------------------------------------
@inproceedings{chen2022TOG,
  title={Learning 6-DoF Task-oriented Grasp Detection via Implicit Estimation and Visual Affordance},
  author={Chen, Wenkai and Liang, Hongzhuo and Chen, Zhaopeng and Sun, Fuchun and Zhang, Jianwei},
  booktitle={IROS},
  year={2022},
}

@article{tang2023graspclip,
  title={Task-Oriented Grasp Prediction with Visual-Language Inputs},
  author={Tang, Chao and Huang, Dehao and Meng, Lingxiao and Liu, Weiyu and Zhang, Hong},
  journal={IROS},
  year={2023}
}

@article{fang2020learningtog,
  title={Learning task-oriented grasping for tool manipulation from simulated self-supervision},
  author={Fang, Kuan and Zhu, Yuke and Garg, Animesh and Kurenkov, Andrey and Mehta, Viraj and Fei-Fei, Li and Savarese, Silvio},
  journal={IJRR},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{sun2021gater,
  title={Gater: Learning grasp-action-target embeddings and relations for task-specific grasping},
  author={Sun, Ming and Gao, Yue},
  journal={RAL},
  year={2021},
  publisher={IEEE}
}

@inproceedings{murali2021same,
  title={Same object, different grasps: Data and semantic knowledge for task-oriented grasping},
  author={Murali, Adithyavairavan and Liu, Weiyu and Marino, Kenneth and Chernova, Sonia and Gupta, Abhinav},
  booktitle={CoRL},
  year={2021},
}

@inproceedings{SG14000,
  title={Cage: Context-aware grasping engine},
  author={Liu, Weiyu and Daruna, Angel and Chernova, Sonia},
  booktitle={ICRA},
  year={2020},
}

@article{tang2023graspgpt,
  title={Graspgpt: Leveraging semantic knowledge from a large language model for task-oriented grasping},
  author={Tang, Chao and Huang, Dehao and Ge, Wenqi and Liu, Weiyu and Zhang, Hong},
  journal={RAL},
  year={2023},
}

@inproceedings{tang2023task,
  title={Task-oriented grasp prediction with visual-language inputs},
  author={Tang, Chao and Huang, Dehao and Meng, Lingxiao and Liu, Weiyu and Zhang, Hong},
  booktitle={IROS},
  year={2023},
}


%-------------------- dataset generation-----------------------------------------

@inproceedings{savva2015shapenet,
  title={Semantically-enriched 3D models for common-sense knowledge},
  author={Savva, Manolis and Chang, Angel X and Hanrahan, Pat},
  booktitle={CVPR Workshops},
  year={2015}
}

@inproceedings{eppner2021acronym,
  title={Acronym: A large-scale grasp dataset based on simulation},
  author={Eppner, Clemens and Mousavian, Arsalan and Fox, Dieter},
  booktitle={ICRA},
  year={2021},
}

@article{miller1995wordnet,
  title={WordNet: a lexical database for English},
  author={Miller, George A},
  journal={CACM},
  year={1995},
}

@inproceedings{deng2021affordancenet,
  title={3d affordancenet: A benchmark for visual object affordance understanding},
  author={Deng, Shengheng and Xu, Xun and Wu, Chaozheng and Chen, Ke and Jia, Kui},
  booktitle={CVPR},
  year={2021}
}

% ----------------------- Backbone --------------------
@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={NeruIPS},
  volume={30},
  year={2017}
}

% -------------------------- Optimizer ---------------
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

% -------------------    tsne      ----------------

@article{van2008tsne,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

% ---------------------------- Manipulation -----------------------
@inproceedings{wang2023event,
  title={Event-guided procedure planning from instructional videos with text supervision},
  author={Wang, An-Lan and Lin, Kun-Yu and Du, Jia-Run and Meng, Jingke and Zheng, Wei-Shi},
  booktitle={ICCV},
  pages={13565--13575},
  year={2023}
}

@inproceedings{shao2020manipulation,
  title={Learning to scaffold the development of robotic manipulation skills},
  author={Shao, Lin and Migimatsu, Toki and Bohg, Jeannette},
  booktitle={ICRA},
  year={2020},
}

@inproceedings{avigal2022manipulation,
  title={Speedfolding: Learning efficient bimanual folding of garments},
  author={Avigal, Yahav and Berscheid, Lars and Asfour, Tamim and Kr{\"o}ger, Torsten and Goldberg, Ken},
  booktitle={IROS},
  year={2022},
}

@inproceedings{papallas2022manipulation,
  title={To ask for help or not to ask: A predictive approach to human-in-the-loop motion planning for robot manipulation tasks},
  author={Papallas, Rafael and Dogar, Mehmet R},
  booktitle={IROS},
  year={2022},
}

@inproceedings{wu2025economic,
  title={An economic framework for 6-dof grasp detection},
  author={Wu, Xiao-Ming and Cai, Jia-Feng and Jiang, Jian-Jian and Zheng, Dian and Wei, Yi-Lin and Zheng, Wei-Shi},
  booktitle={ECCV},
  year={2025},
}

@inproceedings{xu2024dexterous,
  title={Dexterous Grasp Transformer},
  author={Xu, Guo-Hao and Wei, Yi-Lin and Zheng, Dian and Wu, Xiao-Ming and Zheng, Wei-Shi},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{wang2024single,
  title={Single-View Scene Point Cloud Human Grasp Generation},
  author={Wang, Yan-Kang and Xing, Chengyi and Wei, Yi-Lin and Wu, Xiao-Ming and Zheng, Wei-Shi},
  booktitle={CVPR},
  year={2024}
}

@article{gao2024riemann,
  title={RiEMann: Near Real-Time SE (3)-Equivariant Robot Manipulation without Point Cloud Segmentation},
  author={Gao, Chongkai and Xue, Zhengrong and Deng, Shuying and Liang, Tianhai and Yang, Siqi and Shao, Lin and Xu, Huazhe},
  journal={arXiv preprint arXiv:2403.19460},
  year={2024}
}

@inproceedings{tang2022few,
  title={Few could be better than all: Feature sampling and grouping for scene text detection},
  author={Tang, Jingqun and Zhang, Wenqing and Liu, Hongye and Yang, MingKun and Jiang, Bo and Hu, Guanglong and Bai, Xiang},
  booktitle={CVPR},
  year={2022}
}

@article{zhao2024harmonizing,
  title={Harmonizing visual text comprehension and generation},
  author={Zhao, Zhen and Tang, Jingqun and Wu, Binghong and Lin, Chunhui and Wei, Shu and Liu, Hao and Tan, Xin and Zhang, Zhizhong and Huang, Can and Xie, Yuan},
  journal={arXiv preprint arXiv:2407.16364},
  year={2024}
}

@article{wang2024pargo,
  title={Pargo: Bridging vision-language with partial and global views},
  author={Wang, An-Lan and Shan, Bin and Shi, Wei and Lin, Kun-Yu and Fei, Xiang and Tang, Guozhi and Liao, Lei and Tang, Jingqun and Huang, Can and Zheng, Wei-Shi},
  journal={arXiv preprint arXiv:2408.12928},
  year={2024}
}

@inproceedings{li2024egoexo,
  title={EgoExo-Fitness: towards egocentric and exocentric full-body action understanding},
  author={Li, Yuan-Ming and Huang, Wei-Jin and Wang, An-Lan and Zeng, Ling-An and Meng, Jing-Ke and Zheng, Wei-Shi},
  booktitle={ECCV},
  year={2024}
}

@article{li2024techcoach,
  title={TechCoach: Towards Technical Keypoint-Aware Descriptive Action Coaching},
  author={Li, Yuan-Ming and Wang, An-Lan and Lin, Kun-Yu and Tang, Yu-Ming and Zeng, Ling-An and Hu, Jian-Fang and Zheng, Wei-Shi},
  journal={arXiv preprint arXiv:2411.17130},
  year={2024}
}


@article{chen2024motiongrasp,
  title={MotionGrasp: Long-Term Grasp Motion Tracking for Dynamic Grasping},
  author={Chen, Nuo and Wu, Xiao-Ming and Xu, Guohao and Jiang, Jian-Jian and Chen, Zibo and Zheng, Wei-Shi},
  journal={RAL},
  year={2024},
  publisher={IEEE}
}

@article{lin2024diversifying,
  title={Diversifying spatial-temporal perception for video domain generalization},
  author={Lin, Kun-Yu and Du, Jia-Run and Gao, Yipeng and Zhou, Jiaming and Zheng, Wei-Shi},
  journal={NeruIPS},
  volume={36},
  year={2024}
}

@article{tang2024mtvqa,
  title={MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering},
  author={Tang, Jingqun and Liu, Qi and Ye, Yongjie and Lu, Jinghui and Wei, Shu and Lin, Chunhui and Li, Wanqing and Mahmood, Mohamad Fitri Faiz Bin and Feng, Hao and Zhao, Zhen and others},
  journal={arXiv preprint arXiv:2405.11985},
  year={2024}
}

@article{tang2024textsquare,
  title={TextSquare: Scaling up Text-Centric Visual Instruction Tuning},
  author={Tang, Jingqun and Lin, Chunhui and Zhao, Zhen and Wei, Shu and Wu, Binghong and Liu, Qi and Feng, Hao and Li, Yang and Wang, Siqi and Liao, Lei and others},
  journal={arXiv preprint arXiv:2404.12803},
  year={2024}
}

@article{zhao2024tabpedia,
  title={Tabpedia: Towards comprehensive visual table understanding with concept synergy},
  author={Zhao, Weichao and Feng, Hao and Liu, Qi and Tang, Jingqun and Wei, Shu and Wu, Binghong and Liao, Lei and Ye, Yongjie and Liu, Hao and Zhou, Wengang and others},
  journal={arXiv preprint arXiv:2406.01326},
  year={2024}
}

@article{lu2024bounding,
  title={A bounding box is worth one token: Interleaving layout and text in a large language model for document understanding},
  author={Lu, Jinghui and Yu, Haiyang and Wang, Yanjie and Ye, Yongjie and Tang, Jingqun and Yang, Ziwei and Wu, Binghong and Liu, Qi and Feng, Hao and Wang, Han and others},
  journal={arXiv preprint arXiv:2407.01976},
  year={2024}
}

@article{shan2024mctbench,
  title={Mctbench: Multimodal cognition towards text-rich visual scenes benchmark},
  author={Shan, Bin and Fei, Xiang and Shi, Wei and Wang, An-Lan and Tang, Guozhi and Liao, Lei and Tang, Jingqun and Bai, Xiang and Huang, Can},
  journal={arXiv preprint arXiv:2410.11538},
  year={2024}
}

@article{feng2024docpedia,
  title={Docpedia: Unleashing the power of large multimodal model in the frequency domain for versatile document understanding},
  author={Feng, Hao and Liu, Qi and Liu, Hao and Tang, Jingqun and Zhou, Wengang and Li, Houqiang and Huang, Can},
  journal={Science China Information Sciences},
  year={2024},
  publisher={Springer}
}

@article{du2024weakly,
  title={Weakly-supervised temporal action localization by progressive complementary learning},
  author={Du, Jia-Run and Feng, Jia-Chang and Lin, Kun-Yu and Hong, Fa-Ting and Qi, Zhongang and Shan, Ying and Hu, Jian-Fang and Zheng, Wei-Shi},
  journal={TCSVT},
  year={2024},
  publisher={IEEE}
}

@article{suarez2018can,
  title={Can robots assemble an IKEA chair?},
  author={Su{\'a}rez-Ruiz, Francisco and Zhou, Xian and Pham, Quang-Cuong},
  journal={Science Robotics},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{dantam2016incremental,
  title={Incremental task and motion planning: A constraint-based approach.},
  author={Dantam, Neil T and Kingston, Zachary K and Chaudhuri, Swarat and Kavraki, Lydia E},
  booktitle={Robotics: Science and systems},
  volume={12},
  pages={00052},
  year={2016},
  organization={Ann Arbor, MI, USA}
}

@article{zheng2025diffuvolume,
  title={Diffuvolume: Diffusion model for volume based stereo matching},
  author={Zheng, Dian and Wu, Xiao-Ming and Liu, Zuhao and Meng, Jingke and Zheng, Wei-shi},
  journal={IJCV},
  year={2025},
  publisher={Springer}
}

@inproceedings{lim2024equigraspflow,
  title={Equigraspflow: Se (3)-equivariant 6-dof grasp pose generative flows},
  author={Lim, Byeongdo and Kim, Jongmin and Kim, Jihwan and Lee, Yonghyeon and Park, Frank C},
  booktitle={CoRL},
  year={2024}
}