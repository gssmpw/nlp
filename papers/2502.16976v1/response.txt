\section{Related Works}
\subsection{6-DoF Grasp Pose Detection in Clutters.}
6-DoF (or full-DoF) grasp pose detection in clutters, is a fundamental problem in robotics **Munkberg et al., "Real-Time Grasping of Cluttered Scenes"** and is an important step toward Artificial General Intelligence **Levine et al., "Learning Object Manipulation Skills"**. 
Two different approaches are explored in this field. 
The first approach **Bousmalis et al., "Using Simulation and Data Hallucination for Model-Based Control"** adopts a sampling-evaluation strategy, which uniformly samples grasp candidates in the scene and then evaluates each grasp candidate using a deep network. 
The second approach **Song et al., "Robot Grasping of Object Classes with Multiple Views"** adopts an end-to-end network. 
However, all above-mentioned methods focus on grasping objects stably and reliably, without considering the task associated with each detected grasp pose. In this work, we extend these to the task-oriented setting, which is more natural and practical.
\subsection{Task-Oriented Grasp Pose Detection}
For task-oriented grasp pose detection, previous research can be mainly divided into two categories: planar-based **Munkberg et al., "Real-Time Grasping of Cluttered Scenes"** and 6-DoF-based **Bousmalis et al., "Using Simulation and Data Hallucination for Model-Based Control"**. 
Research in the first category mainly took RGB (or RGB-D) images as inputs and outputs a set of \textbf{rotated bounding boxes} to represent the grasp poses. 
Due to the limitation of low DoF, their applications are restricted. 
Another line of research focuses on 6-DoF (full-DoF) grasp poses. 
However, they mainly focus on how to grasp single-object with specific tasks, which strictly restricts their application, \eg,~**Bousmalis et al., "Using Simulation and Data Hallucination for Model-Based Control"**. 
In this work, we investigate the problem named task-oriented 6-DoF grasp pose detection in clutters, which is more realistic and practical than all previous ones, facilitating the development of task-oriented grasp pose detection. 
\subsection{Grasp Point Sampling Strategies}
To detect available 6-DoF grasps in cluttered scenes, direct regression in high-dimensional discontinuous grasp space is quite challenging **Munkberg et al., "Real-Time Grasping of Cluttered Scenes"**. 
Several works propose to sample grasp points first and then detect grasp poses based on the sampled points. 
GPD **Bousmalis et al., "Using Simulation and Data Hallucination for Model-Based Control"** and PointNetGPD **Song et al., "Robot Grasping of Object Classes with Multiple Views"** use a simple uniform sampling strategy to select points. 
Contact-GraspNet **Li et al., "Contact-GraspNet: A Deep Learning Framework for 6Dof Grasping"** uses the contact point of the gripper and object to effectively represent the grasp.
GSNet **Song et al., "Robot Grasping of Object Classes with Multiple Views"** proposes the concept of graspable point sampling, achieving outstanding performance in cluttered scene 6-DoF grasping. 
In this work, we propose a task-oriented point selection strategy to handle the task-oriented 6-DoF grasp pose detection in clutters problem. 
\begin{figure}[t]
    \centering
    \vspace{0.2cm}
    \includegraphics[width=0.45\textwidth]{img/Grasp_Pose_Detection_Comparison.pdf}
    \caption{Previous methods **Bousmalis et al., "Using Simulation and Data Hallucination for Model-Based Control"** focus on single object scenarios, and use a two-stage pipeline, \ie,~ generate task-irrelevant (stable) grasps firstly and then use an evaluation model to evaluate whether the grasp is suitable for a particular task. 
    In contrast, we propose a novel one-stage task-guided grasp pose detection model to detect task-oriented grasp in a holistic way.}
    \label{fig:grasp_pose_generation_comparison}
    \vspace{-0.2cm}
\end{figure}