[
  {
    "index": 0,
    "papers": [
      {
        "key": "suarez2018can",
        "author": "Su{\\'a}rez-Ruiz, Francisco and Zhou, Xian and Pham, Quang-Cuong",
        "title": "Can robots assemble an IKEA chair?"
      },
      {
        "key": "dantam2016incremental",
        "author": "Dantam, Neil T and Kingston, Zachary K and Chaudhuri, Swarat and Kavraki, Lydia E",
        "title": "Incremental task and motion planning: A constraint-based approach."
      },
      {
        "key": "xu2024dexterous",
        "author": "Xu, Guo-Hao and Wei, Yi-Lin and Zheng, Dian and Wu, Xiao-Ming and Zheng, Wei-Shi",
        "title": "Dexterous Grasp Transformer"
      },
      {
        "key": "gao2024riemann",
        "author": "Gao, Chongkai and Xue, Zhengrong and Deng, Shuying and Liang, Tianhai and Yang, Siqi and Shao, Lin and Xu, Huazhe",
        "title": "RiEMann: Near Real-Time SE (3)-Equivariant Robot Manipulation without Point Cloud Segmentation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "shao2020manipulation",
        "author": "Shao, Lin and Migimatsu, Toki and Bohg, Jeannette",
        "title": "Learning to scaffold the development of robotic manipulation skills"
      },
      {
        "key": "avigal2022manipulation",
        "author": "Avigal, Yahav and Berscheid, Lars and Asfour, Tamim and Kr{\\\"o}ger, Torsten and Goldberg, Ken",
        "title": "Speedfolding: Learning efficient bimanual folding of garments"
      },
      {
        "key": "papallas2022manipulation",
        "author": "Papallas, Rafael and Dogar, Mehmet R",
        "title": "To ask for help or not to ask: A predictive approach to human-in-the-loop motion planning for robot manipulation tasks"
      },
      {
        "key": "wang2023event",
        "author": "Wang, An-Lan and Lin, Kun-Yu and Du, Jia-Run and Meng, Jingke and Zheng, Wei-Shi",
        "title": "Event-guided procedure planning from instructional videos with text supervision"
      },
      {
        "key": "wang2024pargo",
        "author": "Wang, An-Lan and Shan, Bin and Shi, Wei and Lin, Kun-Yu and Fei, Xiang and Tang, Guozhi and Liao, Lei and Tang, Jingqun and Huang, Can and Zheng, Wei-Shi",
        "title": "Pargo: Bridging vision-language with partial and global views"
      },
      {
        "key": "li2024egoexo",
        "author": "Li, Yuan-Ming and Huang, Wei-Jin and Wang, An-Lan and Zeng, Ling-An and Meng, Jing-Ke and Zheng, Wei-Shi",
        "title": "EgoExo-Fitness: towards egocentric and exocentric full-body action understanding"
      },
      {
        "key": "chen2024motiongrasp",
        "author": "Chen, Nuo and Wu, Xiao-Ming and Xu, Guohao and Jiang, Jian-Jian and Chen, Zibo and Zheng, Wei-Shi",
        "title": "MotionGrasp: Long-Term Grasp Motion Tracking for Dynamic Grasping"
      },
      {
        "key": "li2024techcoach",
        "author": "Li, Yuan-Ming and Wang, An-Lan and Lin, Kun-Yu and Tang, Yu-Ming and Zeng, Ling-An and Hu, Jian-Fang and Zheng, Wei-Shi",
        "title": "TechCoach: Towards Technical Keypoint-Aware Descriptive Action Coaching"
      },
      {
        "key": "lin2024diversifying",
        "author": "Lin, Kun-Yu and Du, Jia-Run and Gao, Yipeng and Zhou, Jiaming and Zheng, Wei-Shi",
        "title": "Diversifying spatial-temporal perception for video domain generalization"
      },
      {
        "key": "tang2022few",
        "author": "Tang, Jingqun and Zhang, Wenqing and Liu, Hongye and Yang, MingKun and Jiang, Bo and Hu, Guanglong and Bai, Xiang",
        "title": "Few could be better than all: Feature sampling and grouping for scene text detection"
      },
      {
        "key": "zhao2024harmonizing",
        "author": "Zhao, Zhen and Tang, Jingqun and Wu, Binghong and Lin, Chunhui and Wei, Shu and Liu, Hao and Tan, Xin and Zhang, Zhizhong and Huang, Can and Xie, Yuan",
        "title": "Harmonizing visual text comprehension and generation"
      },
      {
        "key": "tang2024mtvqa",
        "author": "Tang, Jingqun and Liu, Qi and Ye, Yongjie and Lu, Jinghui and Wei, Shu and Lin, Chunhui and Li, Wanqing and Mahmood, Mohamad Fitri Faiz Bin and Feng, Hao and Zhao, Zhen and others",
        "title": "MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering"
      },
      {
        "key": "tang2024textsquare",
        "author": "Tang, Jingqun and Lin, Chunhui and Zhao, Zhen and Wei, Shu and Wu, Binghong and Liu, Qi and Feng, Hao and Li, Yang and Wang, Siqi and Liao, Lei and others",
        "title": "TextSquare: Scaling up Text-Centric Visual Instruction Tuning"
      },
      {
        "key": "zhao2024tabpedia",
        "author": "Zhao, Weichao and Feng, Hao and Liu, Qi and Tang, Jingqun and Wei, Shu and Wu, Binghong and Liao, Lei and Ye, Yongjie and Liu, Hao and Zhou, Wengang and others",
        "title": "Tabpedia: Towards comprehensive visual table understanding with concept synergy"
      },
      {
        "key": "lu2024bounding",
        "author": "Lu, Jinghui and Yu, Haiyang and Wang, Yanjie and Ye, Yongjie and Tang, Jingqun and Yang, Ziwei and Wu, Binghong and Liu, Qi and Feng, Hao and Wang, Han and others",
        "title": "A bounding box is worth one token: Interleaving layout and text in a large language model for document understanding"
      },
      {
        "key": "shan2024mctbench",
        "author": "Shan, Bin and Fei, Xiang and Shi, Wei and Wang, An-Lan and Tang, Guozhi and Liao, Lei and Tang, Jingqun and Bai, Xiang and Huang, Can",
        "title": "Mctbench: Multimodal cognition towards text-rich visual scenes benchmark"
      },
      {
        "key": "feng2024docpedia",
        "author": "Feng, Hao and Liu, Qi and Liu, Hao and Tang, Jingqun and Zhou, Wengang and Li, Houqiang and Huang, Can",
        "title": "Docpedia: Unleashing the power of large multimodal model in the frequency domain for versatile document understanding"
      },
      {
        "key": "du2024weakly",
        "author": "Du, Jia-Run and Feng, Jia-Chang and Lin, Kun-Yu and Hong, Fa-Ting and Qi, Zhongang and Shan, Ying and Hu, Jian-Fang and Zheng, Wei-Shi",
        "title": "Weakly-supervised temporal action localization by progressive complementary learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "varley20156-DofGraspoing",
        "author": "Varley, Jacob and Weisz, Jonathan and Weiss, Jared and Allen, Peter",
        "title": "Generating multi-fingered robotic grasps via deep learning"
      },
      {
        "key": "GPD",
        "author": "Ten Pas, Andreas and Gualtieri, Marcus and Saenko, Kate and Platt, Robert",
        "title": "Grasp pose detection in point clouds"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "6-dofview",
        "author": "Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre",
        "title": "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection"
      },
      {
        "key": "fang2020graspnet1billion",
        "author": "Fang, Hao-Shu and Wang, Chenxi and Gou, Minghao and Lu, Cewu",
        "title": "Graspnet-1billion: A large-scale benchmark for general object grasping"
      },
      {
        "key": "ni2020pointnet++grasp",
        "author": "Ni, Peiyuan and Zhang, Wenguang and Zhu, Xiaoxiao and Cao, Qixin",
        "title": "Pointnet++ grasping: Learning an end-to-end spatial grasp generation algorithm from sparse point clouds"
      },
      {
        "key": "GSNet",
        "author": "Wang, Chenxi and Fang, Hao-Shu and Gou, Minghao and Fang, Hongjie and Gao, Jin and Lu, Cewu",
        "title": "Graspness discovery in clutters for fast and accurate grasp detection"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "fang2020learningtog",
        "author": "Fang, Kuan and Zhu, Yuke and Garg, Animesh and Kurenkov, Andrey and Mehta, Viraj and Fei-Fei, Li and Savarese, Silvio",
        "title": "Learning task-oriented grasping for tool manipulation from simulated self-supervision"
      },
      {
        "key": "sun2021gater",
        "author": "Sun, Ming and Gao, Yue",
        "title": "Gater: Learning grasp-action-target embeddings and relations for task-specific grasping"
      },
      {
        "key": "tang2023graspclip",
        "author": "Tang, Chao and Huang, Dehao and Meng, Lingxiao and Liu, Weiyu and Zhang, Hong",
        "title": "Task-Oriented Grasp Prediction with Visual-Language Inputs"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "SG14000",
        "author": "Liu, Weiyu and Daruna, Angel and Chernova, Sonia",
        "title": "Cage: Context-aware grasping engine"
      },
      {
        "key": "murali2021same",
        "author": "Murali, Adithyavairavan and Liu, Weiyu and Marino, Kenneth and Chernova, Sonia and Gupta, Abhinav",
        "title": "Same object, different grasps: Data and semantic knowledge for task-oriented grasping"
      },
      {
        "key": "chen2022TOG",
        "author": "Chen, Wenkai and Liang, Hongzhuo and Chen, Zhaopeng and Sun, Fuchun and Zhang, Jianwei",
        "title": "Learning 6-DoF Task-oriented Grasp Detection via Implicit Estimation and Visual Affordance"
      },
      {
        "key": "tang2023graspgpt",
        "author": "Tang, Chao and Huang, Dehao and Ge, Wenqi and Liu, Weiyu and Zhang, Hong",
        "title": "Graspgpt: Leveraging semantic knowledge from a large language model for task-oriented grasping"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "tang2023graspgpt",
        "author": "Tang, Chao and Huang, Dehao and Ge, Wenqi and Liu, Weiyu and Zhang, Hong",
        "title": "Graspgpt: Leveraging semantic knowledge from a large language model for task-oriented grasping"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "mousavian20196dofgraspnet",
        "author": "Mousavian, Arsalan and Eppner, Clemens and Fox, Dieter",
        "title": "6-dof graspnet: Variational grasp generation for object manipulation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "GPD",
        "author": "Ten Pas, Andreas and Gualtieri, Marcus and Saenko, Kate and Platt, Robert",
        "title": "Grasp pose detection in point clouds"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "pointnetGPD",
        "author": "Liang, Hongzhuo and Ma, Xiaojian and Li, Shuang and G{\\\"o}rner, Michael and Tang, Song and Fang, Bin and Sun, Fuchun and Zhang, Jianwei",
        "title": "Pointnetgpd: Detecting grasp configurations from point sets"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "sundermeyer2021contact",
        "author": "Sundermeyer, Martin and Mousavian, Arsalan and Triebel, Rudolph and Fox, Dieter",
        "title": "Contact-graspnet: Efficient 6-dof grasp generation in cluttered scenes"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "GSNet",
        "author": "Wang, Chenxi and Fang, Hao-Shu and Gou, Minghao and Fang, Hongjie and Gao, Jin and Lu, Cewu",
        "title": "Graspness discovery in clutters for fast and accurate grasp detection"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "chen2022TOG",
        "author": "Chen, Wenkai and Liang, Hongzhuo and Chen, Zhaopeng and Sun, Fuchun and Zhang, Jianwei",
        "title": "Learning 6-DoF Task-oriented Grasp Detection via Implicit Estimation and Visual Affordance"
      },
      {
        "key": "tang2023graspgpt",
        "author": "Tang, Chao and Huang, Dehao and Ge, Wenqi and Liu, Weiyu and Zhang, Hong",
        "title": "Graspgpt: Leveraging semantic knowledge from a large language model for task-oriented grasping"
      }
    ]
  }
]