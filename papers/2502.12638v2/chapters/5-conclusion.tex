%     3D molecule generation is crucial for drug discovery and material design. While prior efforts focus on 3D diffusion models for their benefits in modeling continuous 3D conformers, they overlook the advantages of 1D SELFIES-based Language Models (LMs), which are able to generate 100\% valid molecules and leverage the billion-scale 1D molecule datasets. To combine these advantages for 3D molecule generation, we propose a foundation model -- NExT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation. NExT-Mol uses an extensively pretrained molecule LM for 1D molecule generation, and subsequently predicts the generated molecule's 3D conformers with a 3D diffusion model. We enhance NExT-Mol's performance by scaling up the LM's model size, refining the diffusion neural architecture, and applying 1D to 3D transfer learning. Notably, we demonstrate that incorporating 1D representations from our molecule LM improves the 3D diffusion model's conformer prediction by 1.3\% coverage-recall on GEOM-DRUGS. Given these improvements, NExT-Mol achieves leading performances in \textit{de novo} 3D molecule generation, 3D conformer prediction, and conditional 3D molecule generation, demonstrating its effectiveness and versatility as a foundation model in the field. Our codes and pretrained checkpoints are available at \url{https://anonymous.4open.science/r/NExT-Mol}. 


\vspace{-1mm}
\section{Conclusion and Future Works}
\vspace{-1mm}
In this work, we presented NExT-Mol, a foundation model for 3D molecule generation that integrated the strengths of 1D SELFIES-based LMs and 3D diffusion models. NExT-Mol demonstrated leading performances in \textit{de novo} 3D molecule generation, 3D conformer prediction, and conditional 3D molecule generation. These good performances are attributed to our focus on incorporating chemical inductive biases without compromising model scalability, and they highlight NExT-Mol's promising potential as a foundation model in the field. 
Additionally, NExT-Mol showed that transfer learning between 1D molecule sequences and 3D conformers can significantly improve 3D conformer prediction performance, underscoring the value of leveraging the abundant 1D molecular data to enhance 3D prediction tasks. 
Looking ahead, we plan to extend NExT-Mol to process multiple molecular inputs, aiming to tackle structure-based molecule design and modeling interactions between small molecules and proteins or RNAs, with real-world applications in drug discovery.

% In this work, we introduced NExT-Mol, a foundation model for 3D molecule generation that combines the strengths of 1D SELFIES-based language models and 3D diffusion models. NExT-Mol achieved top results in tasks such as de novo 3D molecule generation, 3D conformer prediction, and conditional 3D molecule generation. It also showed that transfer learning between 1D molecule sequences and 3D conformers can greatly enhance 3D conformer prediction, highlighting the potential of leveraging abundant 1D molecular data for 3D predictions. NExT-Mol’s strong performance is due to our incorporation of chemical inductive biases without compromising scalability. Moving forward, we plan to extend NExT-Mol to structure-based molecule design, inverse molecule design, and modeling interactions between small molecules and proteins or RNAs in real-world drug discovery datasets.


% NExT-Mol features MoLlama, our extensively pretrained SELFIES-based LM, and DMT, our 
% Leveraging MoLlama, our extensively pretrained SELFIES-based LM, NExT-Mol can generate 100\% valid molecules that accurately reflect the molecular patterns of the target dataset. 

% NExT-Mol then predicted the generated molecules' 3D conformers using DMT, our 3D molecule diffusion model. DMT outperformed the prior state-of-the-art method using only 60\% of its parameters, due to its effectiveness in modeing atomic interactions with pair representations. Combining the efforts above,  


% Leveraging MoLlama, our extensively pretrained SELFIES-based LM, NExT-Mol generates 100\% valid molecules. It then uses DMT, our scalable 3D diffusion model, to accurately predict their 3D conformers by effectively incorporating 2D molecular graph information. We also demonstrated that transfer learning between 1D molecule sequences and 3D conformers, facilitated by our cross-modal projector and training strategy, significantly enhances DMT’s 3D prediction. NExT-Mol has shown state-of-the-art performance in \textit{de novo} 3D molecule generation, 3D conformer prediction, and conditional 3D molecule generation. Looking ahead, we plan to extend NExT-Mol to structure-based molecule generation and other related tasks.

% NExT-Mol leverages MoLlama, our extensively pretrained SELFIES-based LM, to generate 100\% valid molecules, and subsequently predict their 3D conformers with high-accuracy with DMT, our scalable 3D diffusion molecule transformer.
% In this work, we present NExT-Mol, a foundation model for 3D molecule generation. NExT-Mol combines the strengths of 1D SELFIES-based LMs, which leverage billion-scale pretraining datasets and generate 100\% valid molecules, and 3D diffusion models, which thrive at high-accuracy 3D conformer prediction. Specifically, NExT-Mol grounds these benefits by proposing MoLlama, an extensively pretrained molecule LM for molecule generation, and DMT, a scalable molecule transformer for 3D conformer prediction. We also show that transfer learning between 1D molecule sequences and 3D conformers improves 3D prediction performance, using our cross-modal projector and training strategy.

\section{Ethics Statement}

Our research advances 3D molecule generation with the NExT-Mol model, aiming to enhance generative deep learning methods for molecular design. This work is primarily technical and foundational, with applications in drug discovery and materials science. We have carefully considered potential societal impacts and do not foresee any direct, immediate, or negative consequences. We are committed to the ethical dissemination of our findings and encourage their responsible use.

\section{Reproducibility Statement}

All the results in this work are reproducible. We provide all the necessary code to replicate our results in an anonymous GitHub repository \href{https://github.com/acharkq/NExT-Mol}{https://github.com/acharkq/NExT-Mol}.
The repository includes environment configurations, run scripts, and other relevant materials.

We discuss the experimental settings for various tasks in Section \ref{sec:exp}, including details on parameters such as sampling steps. Additionally, detailed experimental settings are provided in Appendix \ref{app:expdetail}.

\section*{Acknowledgement}
This research is supported by the National Natural Science Foundation of China (92270114). This material is based upon work supported by the Air Force Office of Scientific Research under award number FA2386-24-1-4011, and this research is partially supported by the Singapore Ministry of Education Academic Research Fund Tier 1 (Award No: T1 251RES2207). This research is supported by NExT Research Center. 