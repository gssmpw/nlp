\vspace{-2mm}
\section{Related Works}
\vspace{-2mm}
A complete molecule includes atoms, bonds, and the 3D coordinates of atoms (\ie 3D conformer). However, due to the expensive computation for obtaining high-accuracy 3D conformers~\citep{GEOM}, many studies focus on generating atoms and bonds without 3D conformers, representing molecules as 1D sequences or 2D graphs. Here we begin by reviewing 1D and 2D molecule generation, then discuss 3D molecule generation and 3D conformer prediction.

% Molecules can be represented by 1D descriptors of SMILES~\citep{SMILES} and SELFIES~\citep{SELFIES,SELFIES2022} and 

\textbf{1D and 2D Molecule Generation} aims to generate the atoms and bonds of a molecule. 1D generation works are mostly based on LMs. However, they usually apply non-autoregressive pretraining such as span-prediction~\citep{Chemformer,MolGen,RegressionTransformer}, making them unsuitable for \textit{de novo} generation. Other works use non-transformer architecture~\citep{RandomSmiles,moses,flam2022language,gomez2018automatic,LIMO,popova2018deep}, which are unsuitable for scale-up~\citep{Transformer}. 2D molecule generation works typically decompose molecular graphs as functional fragments (or atoms), and train models to recurrently generate or edit these fragments~\citep{JT-VAE,MARS,GraphDF,GraphAF,MolSearch,CGVAE,you2018graph,popova2019molecularrnn,VJTNN}. However, due to their non-transformer architectures and domain-specialized training methods, these 2D generation models also face challenges with scalability and transfer learning. We refer readers to~\citep{du2022molgensurvey} for a comprehensive survey in this area.
% \citep{moflow,MolGAN}

\textbf{3D Molecule Generation} is dominated by diffusion models \citep{EDM,EEGSDE,CDGS,JODO,MDM,MiDi,MUDiff}. While autoregressive methods have been explored~\citep{GSchNet,cGSchNet,GSphereNet,MolGym}, they underperform diffusion models, potentially due to their inability to model bonds and the error accumulation when autoregressively generating 3D coordinates.
Diffusion models typically employ 3D equivariant neural networks~\citep{EGNN} to denoise the variables of atoms, bonds, and 3D coordinates within a single diffusion process. However, they predict molecules without validity constraints and are limited by insufficient 3D data. To address these issues, we aim to integrate the two advantages of 1D SELFIES sequences -- 100\% validity and the more abundant dataset~\citep{ZINC15,ZINC22} -- into 3D molecule generation for improvement.

% One challenge for the task is to jointly model the discrete variables of atoms and bonds, and the continuous variable of 3D coordinates. The solutions include (1) projecting the discrete variables as continuous one-hot variables~\citep{EDM} and (2) using a separate discrete diffusion to generate atoms and bonds~\citep{D3PMs}.

% Early works rely on equivariant architectures, like EGNN~\citep{EGNN}, to achieve roto-equivariant to 

\textbf{3D Conformer Prediction} is to predict the 3D conformer given the atoms and bonds of a molecule~\citep{GeoDiff,GeoMol,UniMol,torsion,ParticleGuidance}. The current state-of-the-art approach scales up a diffusion model using a general-purpose transformer architecture~\citep{MCF}, but it overlooks the chemical bond information and uses a lossy representation of molecular structures. We address these issues by introducing the DMT architecture that maintains scalability and retains the full information of 2D molecular graphs. 
% Moreover, DMT features a dropout-based augmentation strategy to improve sampling diversity.
