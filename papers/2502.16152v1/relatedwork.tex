\section{Related Work}
Our work is complementary to related works on \emph{data valuation} that propose new data utility functions (such as data volume \cite{NEURIPS2021_59a3adea} and information gain \cite{sim2020cml}) and strategies (such as the Shapley value \cite{ghorbani2019data, Kwon2021betashapley, yan2021core}, the Banzhaf value \cite{wang2023data} and Least Core \cite{yan2021core}). \texttt{DUPRE} can be used to efficiently predict the utilities of any data utility function needed in the data valuation strategies.

Our work is also complementary to \emph{semivalue approximation techniques} that reduce the number of coalitions to evaluate such as permutation sampling \cite{castro2009polynomial}, stratified sampling \cite{Maleki.2013}, structured sampling \citep{vanCampen.2018}, or approximating Shapley without marginal contribution \cite{kolpaczki2024without}. Instead of evaluating all the sampled coalitions' utilities by training a model, we propose evaluating a subset and predicting the remaining utilities using a GP model. Our work offers an alternative to methods that reduce the cost per evaluation, such as TMC-Shapley, Gradient Shapley \cite{ghorbani2019data} and the influence function heuristic used by \citet{jia2019towards}.

Our work can be extended to make use of other \emph{dataset distances}, such as optimal transport dataset distance (OTDD) \cite{alvarez2020otdd}, if they satisfy the valid properties of a kernel. There are also other data valuation works that have used the SW distance or aim to reduce the cost of each utility function but they differ in their application. In data valuation works, \citet{just2023lava,kessler2024sava} have also defined their data utility function based on the optimal transport distance between training data subsets and validation data. However, our purpose of considering dataset distances is different.