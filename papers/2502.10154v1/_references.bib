@inproceedings{transformer,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention is All you Need},
  booktitle    = {Advances in Neural Information Processing Systems},
  pages        = {5998--6008},
  year         = {2017},
  timestamp    = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl       = {https://dblp.org/rec/conf/nips/VaswaniSPUJGKP17.bib},
  url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{vemoclap,
  title = {{VEMOCLAP}: A Video Emotion Classification Web Application},
  shorttitle = {VEMOCLAP},
  author = {Sulun, Serkan and Viana, Paula and Davies, Matthew E. P.},
  year = {2024},
  eprint = {2410.21303},
  primaryclass = {cs},
  journal = {arXiv preprint arXiv: 2410.21303},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.21303},
  urldate = {2024-12-18},
  archiveprefix = {arXiv}
}

@article{trailer,
  title = {Movie Trailer Genre Classification Using Multimodal Pretrained Features},
  author = {Sulun, Serkan and Viana, Paula and Davies, Matthew E.P.},
  year = {2024},
  journal = {Expert Systems with Applications},
  volume = {258},
  pages = {125209},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2024.125209}
}

@inproceedings{whisper,
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  booktitle = {ICML 2023},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  year = {2023},
  volume = {202},
  pages = {28492--28518},
  publisher = {PMLR},
}

@inproceedings{beats,
  title={{BEATs}: audio pre-training with acoustic tokenizers},
  author={Chen, Sanyuan and Wu, Yu and Wang, Chengyi and Liu, Shujie and Tompkins, Daniel and Chen, Zhuo and Che, Wanxiang and Yu, Xiangzhan and Wei, Furu},
  booktitle={Proceedings of the 40th International Conference on Machine Learning, ICML 2023},
  pages={5178--5193},
  year={2023}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={Proceedings of the 38th International Conference on Machine Learning, ICML 2021},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@misc{ultralytics,
  title        = {Ultralytics {YOLO}},
  author       = {Glenn Jocher and Ayush Chaurasia and Jing Qiu},
  year         = {2023},
  url   = {https://github.com/ultralytics/ultralytics},
  month        = {January},
  day          = {10}
}


@misc{paddle,
  author={PaddlePaddle},
  title={{PaddleOCR}},
  year={2023},
  howpublished="\url{https://github.com/PaddlePaddle/PaddleOCR}",
  note="Accessed: 2024-08-31",
} 

@inproceedings{sentiment,
  title={TweetNLP: Cutting-Edge Natural Language Processing for Social Media},
  author={Camacho-Collados, Jose and Rezaee, Kiamehr and Riahi, Talayeh and Ushio, Asahi and Loureiro, Daniel and Antypas, Dimosthenis and Boisson, Joanne and Anke, Luis Espinosa and Liu, Fangyu and Mart{\'\i}nez-C{\'a}mara, Eugenio},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={38--49},
  year={2022}
}
@misc{expression_classifier,
	title={vit-face-expression},
	author={Pakov, Tr},
	year={2024},
	url="https://huggingface.co/trpakov/vit-face-expression",
	note="Accessed: 2024-31-08",
} 


@article{ekman6,
  title={Heterogeneous knowledge transfer in video emotion recognition, attribution and summarization},
  author={Xu, Baohan and Fu, Yanwei and Jiang, Yu-Gang and Li, Boyang and Sigal, Leonid},
  journal={IEEE Transactions on Affective Computing},
  volume={9},
  number={2},
  pages={255--270},
  year={2016},
  publisher={IEEE}
}

@article{valence_arousal,
  title = {A Circumplex Model of Affect.},
  author = {Russell, James A.},
  year = {1980},
  journal = {Journal of personality and social psychology},
  volume = {39},
  number = {6},
  pages = {1161},
  publisher = {American Psychological Association}
}


@article{mapping,
  title = {Evidence for a Three-Factor Theory of Emotions},
  author = {Russell, James A. and Mehrabian, Albert},
  year = {1977},
  journal = {Journal of research in Personality},
  volume = {11},
  number = {3},
  pages = {273--294},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/009265667790037X},
  urldate = {2024-07-15}
}

@article{ekman,
  title = {Universals and Cultural Differences in Facial Expressions of Emotion},
  author = {Ekman, Paul},
  year = {1971},
  journal = {Nebraska Symposium on Motivation},
  volume = {19},
  pages = {207--283},
  publisher = {University of Nebraska Press},
  address = {US},
  issn = {0146-7875}
}

@inproceedings{musictransformer,
  title = {Music Transformer: Generating Music with Long-Term Structure},
  shorttitle = {Music Transformer},
  booktitle = {6th International Conference on Learning Representations, {ICLR 2018}},
  author = {Huang, Cheng-Zhi Anna and Vaswani, Ashish and Uszkoreit, Jakob and Simon, Ian and Hawthorne, Curtis and Shazeer, Noam and Dai, Andrew M. and Hoffman, Matthew D. and Dinculescu, Monica and Eck, Douglas},
  year = {2018}
}

@article{ffmpeg,
  title = {Converting Video Formats with FFmpeg},
  author = {Tomar, Suramya},
  year = {2006},
  month = jun,
  journal={Linux journal},
  volume = {2006},
  number = {146},
  pages = {10},
  issn = {1075-3583},
  url = {https://dl.acm.org/doi/abs/10.5555/1134782.1134792}
}

@article{event_encoding,
  title = {This Time with Feeling: Learning Expressive Musical Performance},
  author = {Oore, Sageev and Simon, Ian and Dieleman, Sander and Eck, Douglas and Simonyan, Karen},
  year = {2020},
  journal = {Neural Computing and Applications},
  volume = {32},
  number = {4},
  pages = {955--967},
  publisher = {Springer}
}

@inproceedings{lpd,
  title={{Musegan}: Multi-track sequential generative adversarial networks for symbolic music generation and accompaniment},
  author={Dong, Hao-Wen and Hsiao, Wen-Yi and Yang, Li-Chia and Yang, Yi-Hsuan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@phdthesis{lmd,
  title = {Learning-Based Methods for Comparing Sequences, with Applications to Audio-to-Midi Alignment and Matching},
  author = {Raffel, Colin},
  year = {2016},
  school = {Dept. Graduate School Arts Sci., Columbia Univ., New York, NY, USA},
  type = {{Ph.D. dissertation}}
}

@article{access,
  title = {Symbolic Music Generation Conditioned on Continuous-Valued Emotions},
  author = {Sulun, Serkan and Davies, Matthew E. P. and Viana, Paula},
  year = {2022},
  journal = {IEEE Access},
  volume = {10},
  pages = {44617--44626},
  doi = {10.1109/ACCESS.2022.3169744}
}

@inproceedings{learned_position,
  author       = {Benyou Wang and
                  Donghao Zhao and
                  Christina Lioma and
                  Qiuchi Li and
                  Peng Zhang and
                  Jakob Grue Simonsen},
  title        = {Encoding word order in complex embeddings},
  booktitle    = {8th International Conference on Learning Representations, ICLR 2020},
  year         = {2020},
  url          = {https://openreview.net/forum?id=Hke-WTVtwr},
  timestamp    = {Wed, 08 Jun 2022 17:55:54 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/WangZLLZS20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

# Video-based music generation

@inproceedings{di,
  title = {Video Background Music Generation with Controllable Music Transformer},
  booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
  author = {Di, Shangzhe and Jiang, Zeren and Liu, Si and Wang, Zhaokai and Zhu, Leyan and He, Zexin and Liu, Hongming and Yan, Shuicheng},
  year = {2021},
  pages = {2037--2045}
}

@inproceedings{foley,
  title = {Foley Music: Learning to Generate Music from Videos},
  shorttitle = {Foley Music},
  booktitle = {Computer Vision - ECCV 2020 - 16th European Conference},
  author = {Gan, Chuang and Huang, Deng and Chen, Peihao and Tenenbaum, Joshua B. and Torralba, Antonio},
  year = {2020},
  volume = {12356},
  pages = {758--775},
  publisher = {Springer},
  doi = {10.1007/978-3-030-58621-8_44},
  urldate = {2025-01-24}
}


@inproceedings{sighttosound,
  title = {Sight to Sound: An End-to-End Approach for Visual Piano Transcription},
  shorttitle = {Sight to Sound},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2020},
  author = {Koepke, A. Sophia and Wiles, Olivia and Moses, Yael and Zisserman, Andrew},
  year = {2020},
  pages = {1838--1842},
  publisher = {IEEE},
  doi = {10.1109/ICASSP40776.2020.9053115}
}

@inproceedings{audeo,
  title = {Audeo: Audio Generation for a Silent Performance Video},
  shorttitle = {Audeo},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Su, Kun and Liu, Xiulong and Shlizerman, Eli},
  year = {2020},
  volume = {33},
  pages = {3325--3337},
  url = {https://proceedings.neurips.cc/paper_files/paper/2020/hash/227f6afd3b7f89b96c4bb91f95d50f6d-Abstract.html},
  urldate = {2025-01-24}
}

@inproceedings{rhythmicnet,
  title = {How Does It Sound?},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Su, Kun and Liu, Xiulong and Shlizerman, Eli},
  year = {2021},
  volume = {34},
  pages = {29258--29273},
  url = {https://proceedings.neurips.cc/paper/2021/hash/f4e369c0a468d3aeeda0593ba90b5e55-Abstract.html},
  urldate = {2025-01-24}
}

@inproceedings{dance,
  title = {Quantized GAN for Complex Music Generation from Dance Videos},
  booktitle = {Computer Vision - ECCV 2022 - 17th European Conference},
  author = {Zhu, Ye and Olszewski, Kyle and Wu, Yu and Achlioptas, Panos and Chai, Menglei and Yan, Yan and Tulyakov, Sergey},
  year = {2022},
  series = {Lecture Notes in Computer Science},
  volume = {13697},
  pages = {182--199},
  publisher = {Springer},
  doi = {10.1007/978-3-031-19836-6_11},
  urldate = {2025-01-24}
}

@inproceedings{dance2,
  title = {Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation},
  booktitle = {11th International Conference on Learning Representations, ICLR 2023},
  author = {Zhu, Ye and Wu, Yu and Olszewski, Kyle and Ren, Jian and Tulyakov, Sergey and Yan, Yan},
  year = {2023},
  publisher = {OpenReview.net},
  url = {https://openreview.net/forum?id=1-MBdJssZ-S},
  urldate = {2025-01-24}
}

@inproceedings{zhuo,
  title = {Video Background Music Generation: Dataset, Method and Evaluation},
  shorttitle = {Video Background Music Generation},
  booktitle = {{IEEE/CVF} International Conference on Computer Vision, ICCV 2023},
  author = {Zhuo, Le and Wang, Zhaokai and Wang, Baisen and Liao, Yue and Bao, Chenxi and Peng, Stanley and Han, Songhao and Zhang, Aixi and Fang, Fei and Liu, Si},
  year = {2023},
  pages = {15591--15601},
  publisher = {{IEEE}},
  doi = {10.1109/ICCV51070.2023.01433}
}

@article{kang,
  title = {Video2Music: Suitable Music Generation from Videos Using an Affective Multimodal Transformer Model},
  shorttitle = {Video2Music},
  author = {Kang, Jaeyong and Poria, Soujanya and Herremans, Dorien},
  year = {2024},
  month = sep,
  journal = {Expert Systems with Applications},
  volume = {249},
  pages = {123640},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2024.123640},
  urldate = {2024-04-10}
}

@inproceedings{music_dataset,
  title = {The Sound of Pixels},
  booktitle = {Computer Vision - ECCV 2018 - 14th European Conference},
  author = {Zhao, Hang and Gan, Chuang and Rouditchenko, Andrew and Vondrick, Carl and McDermott, Josh and Torralba, Antonio},
  year = {2018},
  pages = {570--586}
}

@article{video_midi_dataset,
  title = {Creating a Multitrack Classical Music Performance Dataset for Multimodal Music Analysis: Challenges, Insights, and Applications},
  shorttitle = {Creating a Multitrack Classical Music Performance Dataset for Multimodal Music Analysis},
  author = {Li, Bochen and Liu, Xinzhao and Dinesh, Karthik and Duan, Zhiyao and Sharma, Gaurav},
  year = {2018},
  journal = {IEEE Transactions on Multimedia},
  volume = {21},
  number = {2},
  pages = {522--535},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/8411155/?casa_token=zJzs0eemrr8AAAAA:Y3NsktxPKExRJtfs2Mnqz1LtHsGqhdlGGAb7_mi_P00Motmxh5omfc6WnklKasJH0z3TrutrmsYX},
  urldate = {2025-01-24}
}

@inproceedings{gcn,
  title = {Semi-Supervised Classification with Graph Convolutional Networks},
  booktitle = {5th International Conference on Learning Representations, ICLR 2017},
  author = {Kipf, Thomas N. and Welling, Max},
  year = {2017},
  url = {https://openreview.net/forum?id=SJU4ayYgl},
  urldate = {2025-01-24}
}

@inproceedings{resnet,
  title = {Deep Residual Learning for Image Recognition},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2016},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2016},
  pages = {770--778},
  doi = {10.1109/CVPR.2016.90}
}

@inproceedings{compound_words,
  title = {Compound Word Transformer: Learning to Compose Full-Song Music over Dynamic Directed Hypergraphs},
  shorttitle = {Compound Word Transformer},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author = {Hsiao, Wen-Yi and Liu, Jen-Yu and Yeh, Yin-Cheng and Yang, Yi-Hsuan},
  year = {2021},
  pages = {178--186},
  doi = {10.1609/AAAI.V35I1.16091},
  urldate = {2025-01-24}
}

@inproceedings{onset_and_frames,
  title = {Onsets and Frames: Dual-Objective Piano Transcription},
  shorttitle = {Onsets and Frames},
  booktitle = {Proceedings of the 19th International Society for Music Information Retrieval Conference},
  author = {Hawthorne, Curtis and Elsen, Erich and Song, Jialin and Roberts, Adam and Simon, Ian and Raffel, Colin and Engel, Jesse H. and Oore, Sageev and Eck, Douglas},
  year = {2018},
  pages = {50--57},
  url = {http://ismir2018.ircam.fr/doc/pdfs/19\_Paper.pdf},
  urldate = {2025-01-25}
}

@inproceedings{ndb,
  title={{GANSynth}: Adversarial Neural Audio Synthesis},
  author={Engel, Jesse and Agrawal, Kumar Krishna and Chen, Shuo and Gulrajani, Ishaan and Donahue, Chris and Roberts, Adam},
  booktitle={6th International Conference on Learning Representations, {ICLR} 2018},
  year={2018}
}

@inproceedings{metrics,
  author       = {Shih{-}Lun Wu and
                  Yi{-}Hsuan Yang},
  title        = {The Jazz Transformer on the Front Line: Exploring the Shortcomings
                  of AI-composed Music through Quantitative Measures},
  booktitle    = {Proceedings of the 21th International Society for Music Information
                  Retrieval Conference, {ISMIR} 2020},
  pages        = {142--149},
  year         = {2020},
  url          = {http://archives.ismir.net/ismir2020/paper/000339.pdf},
  timestamp    = {Mon, 19 Jul 2021 15:30:03 +0200},
  biburl       = {https://dblp.org/rec/conf/ismir/WuY20.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{contrastive,
  title={Self-supervised multimodal versatile networks},
  author={Alayrac, Jean-Baptiste and Recasens, Adria and Schneider, Rosalia and Arandjelovi{\'c}, Relja and Ramapuram, Jason and De Fauw, Jeffrey and Smaira, Lucas and Dieleman, Sander and Zisserman, Andrew},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={25--37},
  year={2020}
}

@article{musicgen1,
  title = {Efficient Neural Music Generation},
  author = {Lam, Max WY and Tian, Qiao and Li, Tang and Yin, Zongyu and Feng, Siyuan and Tu, Ming and Ji, Yuliang and Xia, Rui and Ma, Mingbo and Song, Xuchen},
  year = {2024},
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/38b23e2328096520e9c889ae03e372c9-Abstract-Conference.html},
  urldate = {2025-01-27}
}

@article{musicgen2,
  title = {Simple and Controllable Music Generation},
  author = {Copet, Jade and Kreuk, Felix and Gat, Itai and Remez, Tal and Kant, David and Synnaeve, Gabriel and Adi, Yossi and D{\'e}fossez, Alexandre},
  year = {2024},
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/94b472a1842cd7c56dcb125fb2765fbd-Abstract-Conference.html},
  urldate = {2025-01-27}
}

@inproceedings{swin,
  title = {Video Swin Transformer},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022},
  author = {Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  year = {2022},
  pages = {3192--3201},
  publisher = {IEEE},
  doi = {10.1109/CVPR52688.2022.00320}
}

@inproceedings{vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={IEEE/CVF international conference on computer vision, CVPR 2021},
  pages={6836--6846},
  year={2021}
}

@inproceedings{midiemotion1,
  title = {Multi-Modal Music Emotion Recognition: A New Dataset, Methodology and Comparative Analysis},
  shorttitle = {Multi-Modal Music Emotion Recognition},
  booktitle = {International Symposium on Computer Music Multidisciplinary Research},
  author = {Panda, Renato and Malheiro, Ricardo and Rocha, Bruno and Oliveira, Ant{\'o}nio and Paiva, Rui Pedro},
  year = {2013}
}

@inproceedings{midiemotion2,
  title = {Learning to Generate Music with Sentiment},
  booktitle = {Proceedings of the 20th International Society for Music Information Retrieval Conference},
  author = {Ferreira, Lucas and Whitehead, Jim},
  year = {2019},
  pages = {384--390},
  url = {http://archives.ismir.net/ismir2019/paper/000045.pdf}
}

@inproceedings{midiemotion3,
  title = {{EMOPIA}: A Multi-Modal Pop Piano Dataset For Emotion Recognition and Emotion-Based Music Generation},
  shorttitle = {EMOPIA},
  booktitle = {Proceedings of the 22nd International Society for Music Information Retrieval Conference, ISMIR 2021},
  author = {Hung, Hsiao-Tzu and Ching, Joann and Doh, Seungheon and Kim, Nabin and Nam, Juhan and Yang, Yi-Hsuan},
  year = {2021},
  pages = {318--325},
  url = {https://archives.ismir.net/ismir2021/paper/000039.pdf},
  urldate = {2021-12-14}
}

@article{eev,
  title = {EEV: A Large-Scale Dataset for Studying Evoked Expressions from Video},
  shorttitle = {EEV},
  author = {Sun, Jennifer J. and Liu, Ting and Cowen, Alan S. and Schroff, Florian and Adam, Hartwig and Prasad, Gautam},
  year = {2020},
  journal = {arXiv preprint arXiv:2001.05488},
  eprint = {2001.05488},
  archiveprefix = {arXiv}
}

@article{masters,
  title = {Deep Learned Frame Prediction for Video Compression},
  author = {Sulun, Serkan},
  year = {2018},
  journal = {arXiv preprint arXiv:1811.10946},
  eprint = {1811.10946},
  primaryclass = {cs, eess},
  url = {http://arxiv.org/abs/1811.10946},
  urldate = {2020-04-24},
  archiveprefix = {arXiv}
}


@article{shortvideos,
  title = {Towards Emotion Analysis in Short-Form Videos: A Large-Scale Dataset and Baseline},
  shorttitle = {Towards Emotion Analysis in Short-Form Videos},
  author = {Wu, Xuecheng and Sun, Heli and Xue, Junxiao and Nie, Jiayu and Kong, Xiangyan and Zhai, Ruofan and He, Liang},
  year = {2024},
  journal = {arXiv preprint arXiv:2311.17335},
  eprint = {2311.17335},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.17335},
  urldate = {2025-01-27},
  archiveprefix = {arXiv}
}

@article{chords,
  title = {The Representation of Harmonic Structure in Music: Hierarchies of Stability as a Function of Context},
  shorttitle = {The Representation of Harmonic Structure in Music},
  author = {Bharucha, Jamshed and Krumhansl, Carol L.},
  year = {1983},
  journal = {Cognition},
  volume = {13},
  number = {1},
  pages = {63--102},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/0010027783900033},
  urldate = {2025-01-27}
}

@inproceedings{position1,
  title = {Transformer Language Models without Positional Encodings Still Learn Positional Information},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2022},
  author = {Haviv, Adi and Ram, Ori and Press, Ofir and Izsak, Peter and Levy, Omer},
  year = {2022},
  pages = {1382--1390},
  publisher = {Association for Computational Linguistics},
  doi = {10.18653/V1/2022.FINDINGS-EMNLP.99},
  urldate = {2025-01-31}
}

@article{position2,
  title = {The Impact of Positional Encoding on Length Generalization in Transformers},
  author = {Kazemnejad, Amirhossein and Padhi, Inkit and Natesan Ramamurthy, Karthikeyan and Das, Payel and Reddy, Siva},
  year = {2024},
  journal = {Advances in Neural Information Processing Systems},
  volume = {36},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/4e85362c02172c0c6567ce593122d31c-Abstract-Conference.html},
  urldate = {2025-01-31}
}

@inproceedings{ads,
  title = {Automatic Understanding of Image and Video Advertisements},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition, {CVPR} 2017},
  author = {Hussain, Zaeem and Zhang, Mingda and Zhang, Xiaozhong and Ye, Keren and Thomas, Christopher and Agha, Zuha and Ong, Nathan and Kovashka, Adriana},
  year = {2017},
  pages = {1705--1715},
  url = {http://openaccess.thecvf.com/content_cvpr_2017/html/Hussain_Automatic_Understanding_of_CVPR_2017_paper.html},
  urldate = {2025-01-18}
}

@article{ads_music,
  title = {Musical Influences in Advertising: How Music Modifies First Impressions of Product Endorsers and Brands},
  shorttitle = {Musical Influences in Advertising},
  author = {Zander, Mark F.},
  year = {2006},
  month = oct,
  journal = {Psychology of Music},
  volume = {34},
  number = {4},
  pages = {465--480},
  issn = {0305-7356, 1741-3087},
  doi = {10.1177/0305735606067158},
  urldate = {2025-02-01},
  copyright = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english}
}

@incollection{music_emotion,
  author       = {Yi{-}Hsuan Yang and
                  Yu{-}Ching Lin and
                  Heng Tze Cheng and
                  I{-}Bin Liao and
                  Yeh{-}Chin Ho and
                  Homer H. Chen},
  title        = {Toward Multi-modal Music Emotion Classification},
  booktitle    = {Advances in Multimedia Information Processing - {PCM} 2008},
  series       = {Lecture Notes in Computer Science},
  volume       = {5353},
  pages        = {70--79},
  publisher    = {Springer},
  year         = {2008},
  url          = {https://doi.org/10.1007/978-3-540-89796-5\_8},
  doi          = {10.1007/978-3-540-89796-5\_8},
  timestamp    = {Mon, 23 Nov 2020 15:58:17 +0100},
  biburl       = {https://dblp.org/rec/conf/pcm/YangLCLHC08.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{adam,
  author       = {Diederik P. Kingma and
                  Jimmy Ba},
  title        = {Adam: {A} Method for Stochastic Optimization},
  booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015},
  year         = {2015},
  url          = {http://arxiv.org/abs/1412.6980},
  timestamp    = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{source,
  title = {Hybrid Transformers for Music Source Separation},
  booktitle = {ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  author = {Rouard, Simon and Massa, Francisco and D{\'e}fossez, Alexandre},
  year = {2023},
  pages = {1--5},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/10096956/?casa_token=gGHxGX1FTwkAAAAA:L3H___RmSRCtMSP0jrEYaF0RoXJpbKbdDfmga9wsKu2K5LVE2xWQ0h-8FLHVz5pDy6WqNHA6tw},
  urldate = {2025-02-08}
}

@inproceedings{transcription,
  title = {YourMT3+: Multi-Instrument Music Transcription with Enhanced Transformer Architectures and Cross-Dataset STEM Augmentation},
  shorttitle = {YourMT3+},
  booktitle = {34th {IEEE} International Workshop on Machine Learning for Signal Processing},
  author = {Chang, Sungkyun and Benetos, Emmanouil and Kirchhoff, Holger and Dixon, Simon},
  year = {2024},
  pages = {1--6},
  url = {https://ieeexplore.ieee.org/abstract/document/10734819/?casa_token=2CFDnQ2QvW8AAAAA:Gq1Icp9ukR7ZTUw4vBF1r6tq8nqvDzhWW-qWF0IQ43HuU1BqoK8tGC3dgDWvSx8GHtASzGFBjQ},
  urldate = {2025-02-08}
}

@article{multimedia,
  title = {Current Trends in Consumption of Multimedia Content Using Online Streaming Platforms: A User-Centric Survey},
  shorttitle = {Current Trends in Consumption of Multimedia Content Using Online Streaming Platforms},
  author = {{Falkowski-Gilski}, Przemys{\l}aw and Uhl, Tadeus},
  year = {2020},
  journal = {Computer Science Review},
  volume = {37},
  pages = {100268},
  issn = {1574-0137},
  doi = {10.1016/j.cosrev.2020.100268},
  urldate = {2025-02-10}
}

@book{soundtrack2,
  title = {Unruly Media: YouTube, Music Video, and the New Digital Cinema},
  shorttitle = {Unruly Media},
  author = {Vernallis, Carol},
  year = {2013},
  publisher = {Oxford University Press},
  url = {https://books.google.com/books?hl=en&lr=&id=IIQ8DwAAQBAJ&oi=fnd&pg=PP1&dq=soundtrack+content+creation+youtube&ots=9oWROn2hkx&sig=ShJifR5nN4DiJmIMxa-S2B8cTTg},
  urldate = {2025-02-10}
}

@book{soundtrack,
  title={Theories of the Soundtrack},
  author={Buhler, James},
  year={2018},
  publisher={Oxford University Press}
}
