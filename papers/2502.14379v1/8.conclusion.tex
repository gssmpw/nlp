\section{Conclusions}
In this paper, we have developed a \gexpklms algorithm that works for OPED families of the form \Cref{eqn:oped} and we have proven that when the inverse temperature function is set to $L(x) = x - 1$, \expklms enjoys a logarithmic minimax ratio, asymptotic optimality, adaptive variance, and Sub-UCB criterion at the same time.

An interesting direction is generalizing the result to OPED families with a general sufficient statistics function such as Beta distribution and show that \gexpklms can still (approximately) satisfy all criteria. From our observation, such direction has not been explored sufficiently in the literature.
Although \citet{baudry2023general} has a more general assumption in the reward distribution, finite-time regret bound has not been shown therein \citet{baudry2023general}.

Second, we believe that \expklms has significant potential in the contextual bandit problem, as the techniques developed in \expklms can be utilized to address generalized linear bandit problems with reward distributions belonging to exponential families~\citep{filippi10parametric}. For instance, MED has been successfully applied in the linear MED setting~\citep{balagopalan2024minimum}. Since \expklms has achieved multiple nice properties, it can enjoy the tight upper bound and perform well in those tasks. 

Finally, it would be interesting to prove or disprove whether \expklms can achieve a constant minimax ratio. On the positive side, it may be promising to refine the analysis of $\Bcal^2_a$ to achieve the minimax optimality or to reconsider the algorithm design by carefully choosing inverse temperature functions.
