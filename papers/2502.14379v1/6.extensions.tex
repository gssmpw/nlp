\section{Extensions}
In this section, we present the results from other choices of function $L(k)$ and demonstrate that they also satisfy various desirable properties. Here, considering the overall restriction on $L(k)$ is $0 < L(k) \leq k$, we pick two examples, $L(k) = k/d$ where $d > 1$ and $L(k) = k$.

\paragraph{Extension 1: $L(k) = k/d$, $d > 1$} 
In this case, the inverse temperature function 
imposed by the number of arm pulls is attenuated by a constant factor $d$.

\begin{restatable}{corollary}{constantminimax}\textnormal{(Logarithmic Minimax Ratio and Adaptive Variance Ratio)} \label{corol:exp-kl-ms-half-mo}
    For any $K$-arm bandit problem with \Cref{assum:oped,assum:reward-dist,assum:lip}, when $d>1$ \gexpklms with $L(k) = k/d$, has regret:
    $
        \Regret(T) \leq \iupbound{\sqrt{V(\mu_1) KT \ln(K)}} + \iupbound{K\ln(T)}.
    $
\end{restatable}
\begin{restatable}{corollary}{constantsubucb}\textnormal{(Sub-UCB criterion)} \label{corol:exp-kl-ms-half-sub-ucb}
    For any $K$-arm bandit problem with \Cref{assum:oped,assum:reward-dist,assum:lip}, when $d>1$ \gexpklms with $L(k) = k/d$ satisfies the Sub-UCB criterion which means that its regret is bounded by 
    $
        \Regret(T) \leq \iupbound{\textstyle\sum_{a: \Delta_a > 0} \frac{\ln(T)}{\Delta_a} + \Delta_a}.
    $
\end{restatable}
The above Corollaries show that $\gexpklms$ with $L(k)=k/d$ can have the same M.R. as $\expklms$, adaptive variance ratio, and Sub-UCB. However, since the newly introduced additional factor $d$, it will violate the A.O., resulting in a constant factor difference compared to \expklms in the asymptotic performance.

\paragraph{Extension 2: $L(k) = k$} \gexpklms is the same as KL-MS. Based on the current proof framework, we can only show that \gexpklms with $L(k) = k$ satisfies an adaptive variance ratio and has an M.R. as $\ln(T)$.

\begin{restatable}{corollary}{identityadaptive}\textnormal{(Logarithmic Minimax Ratio and Adaptive Variance Ratio)} \label{corol:exp-kl-ms-one-mo}
For any $K$-arm bandit problem with \Cref{assum:oped,assum:reward-dist,assum:lip}, \gexpklms with $L(k) = k$ has regret bounded as:
    $
        \Regret(T) \leq \iupbound{\sqrt{V(\mu_1) KT}\ln(T)} + \iupbound{ K (\ln(T))^2 }
    $.
\end{restatable}
