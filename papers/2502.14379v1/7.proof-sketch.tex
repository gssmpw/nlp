\section{Proof Sketch} \label{sec:proof-sketch} 

This section outlines the proof of \Cref{thm:expected-regret-total}. Since the theorem follows directly from \Cref{pro:good,pro:bad-1,pro:bad-2-ao,pro:bad-2-mo}, it suffices to demonstrate the regret decomposition and explain how these propositions are established.

The regret of a bandit algorithm can be rewritten as the product between the reward gap of arm $a$ and the expected number of times arm $a$ is pulled over the arm space:
$
    \Regret(T) = \textstyle\EE\sbr{\sum_{t=1}^T \Delta_{I_t}} = \sum_{a\in[K]} \Delta_a \EE[N_{T, a}].
$
We divide the task of bounding of $\EE\sbr{N_{T, a}}$ into four different cases and then upper bound each case. Before formally introducing these cases, we first introduce $\varepsilon_1, \varepsilon_2 > 0$ such that $\varepsilon_1 + \varepsilon_2 < \Delta_a$ and define several events to partition the entire sample space for every arm $a$ as follows:
\begin{align}
    A_{t,a} &:= \cbr{I_t = a}
    &U_{t,a} := \cbr{N_{t,a} < u + 1} \nonumber \\
    E_{t,a} &:= \cbr{\hmu_{t,a} \leq \mu_a+{\varepsilon_1}}
    &F_{t,a} := \cbr{\hmu_{t,\max} \geq \mu_1-{\varepsilon_2}} \label{eqn:subcases}
\end{align}
where the threshold $u$ is defined as $\expDefU$.
$A_{t, a}$, represents that arm $a$ is pulled at time step $t$. 
$U_{t, a}$, represents that the number of samples of arm $a$ is lower than 
a threshold, $u$. 
$E_{t, a}$, represents that the expected reward of the suboptimal arm $a$ is not overestimated (by $\varepsilon_1$), and $F_{t, a}$, represents that the empirical best arm's reward is not underestimated too much (by $\varepsilon_2$).
Then, at each time step, with different combinations of the above events we can divide the sample space into four disjoint subcases as shown in \Cref{fig:case-split}:

\begin{figure}[ht]
    \centering
    \includegraphics[height=0.25\linewidth]{pic/regret-decomposition.png}
    \caption{Case splitting of our regret analysis. The terms are formally defined in \Cref{eqn:subcases}.}
    \label{fig:case-split}
\end{figure}


Therefore, we can group these four different subcases from $t=1$ to $t=T$ and decompose the regret into four terms $\Acal_a$, $\Gcal_a$, $\Bcal^1_a$, and $\Bcal^2_a$. We overload symbols and use the subscript $a$ to indicate the specific arm to which the subcases belong.

\begin{align*}
    \Acal_a =& \textstyle\sum_{t=1}^T \Acal_{t, a} = \sum_{t=1}^T I(A_{t,a} \cap U_{t,a})
    & \Gcal_a = \textstyle\sum_{t=1}^T \Gcal_{t, a} = \sum_{t=1}^T I(A_{t,a} \cap U_{t,a}^c \cap E_{t,a} \cap F_{t,a}) \\
    \Bcal_a^1 =& \textstyle\sum_{t=1}^T \Bcal_{t, a}^1 = \sum_{t=1}^T I(A_{t,a} \cap E_{t,a}^c)
    & \Bcal_a^2 = \textstyle\sum_{t=1}^T \Bcal_{t, a}^2 = \sum_{t=1}^T I(A_{t,a} \cap F_{t,a}^c) 
\end{align*}
\begin{align}
    \Regret \leq& \textstyle\sum_{a\in[K]:\Delta_a > 0} \Delta_a \del{\Acal_a + \Gcal_a + \Bcal_a^1 + \Bcal_a^2}
        \label{eqn:regret-decomposition}
\end{align}
$\Acal_{a}$ deals with situations where the number of arm pulls $a$ are below a threshold and can be easily controlled by the threshold $u$.
The remaining three terms focus on scenarios where there are enough pulls to make a valid estimation of arm performance with high probability. 

$\Gcal_{a}$ addresses the situation when the best and suboptimal arms estimations are accurate.
Since the estimation of arm $a$, $\hmu_{t,a}$, is kept away from $\hmu_{t,\max}$ by at least $\Delta_a - \varepsilon_1 - \varepsilon_2$, the expected number of pulling arm $a$ is upper bounded by $\frac{1}{\KL{\mu_a+\varepsilon_1}{\mu_a-\varepsilon_2}}$ through an easy calculation (\Cref{pro:good}).
$\Bcal^1_{a}$ and $\Bcal^2_{a}$ handle situations where the estimation for either the suboptimal arm or the best arm, respectively, is inaccurate.
For $\Bcal^1_a$, it represents the case where the estimation on arm $a$, $\hmu_{t, a}$ is overestimated.
Therefore, through the well-known Chernoff tail bound (\Cref{lemma:maximal-inequality}) we can control the probability of pulling arm $a$ by $\expto{-k \KL{\mu_a+\varepsilon_1}{\mu_a}}$ at each time from $k=1$ to $k=T$ and the sum of them is bounded by $\frac{1}{\KL{\mu_a+\varepsilon_1}{\mu_a}}$ (\Cref{pro:bad-1}).

$\Bcal^2_a$ represents the most challenging case, where the optimal arm has been underestimated. 
Our analysis manages to bound $\Bcal^2_a$ shown in \Cref{eqn:bad-case-2-ao,eqn:bad-case-2-mo}.
Ideally, our goal is to control the upper bound of $\Bcal^2_a$ to be on the same order as $\frac{1}{\KL{\mu_1 - \varepsilon_2}{\mu_1}}$, which is comparable to the bound for $\Bcal^1_a$.
However, we need to sacrifice a $\ln(T)$ or an additional $\frac{1}{\KL{\mu_1-\varepsilon_2}{\mu_1}}$ in the upper bound of $\Bcal^2_a$.
The $\ln(T)$ term provides a logarithmic minimax ratio but breaks the asymptotic optimality by introducing an additional constant factor.
On the other hand, adding an extra $\frac{1}{\KL{\mu_1 - \varepsilon_2}{\mu_1}}$ factor preserves asymptotic optimality but increases the minimax ratio by at least $T^{1/4}$.
\begin{align}
    \Bcal^2_a 
    \leq& 
       \textstyle  \frac{1}{\KL{\mu_1 - \varepsilon_2}{\mu_1}} 
        + \frac{1}{\del{\KL{\mu_1 - \varepsilon_2}{\mu_1}}^2} \label{eqn:bad-case-2-ao}
    \\
    \Bcal^2_a 
    \leq& 
       \textstyle  \frac{\ln(T\KL{\mu_1 - \varepsilon_2}{\mu_1} \vee e)}{\KL{\mu_1 - \varepsilon_2}{\mu_1}} \label{eqn:bad-case-2-mo}
\end{align}

To prove the above two equations, we construct a series of high-probability "clean" events by using a sequence of numbers $\boldsymbol{\alpha}:=\cbr{\alpha_k}_{k=1}^T$ to lower bound $\hmu_{(k), 1}$. Notice that we change the subscription of $\hmu$ to $(k)$, representing that it is the empirical mean from the optimal arm's first $k$ times arm pulls. Specifically, $\hmu_{(k), 1}$ is the empirical mean of arm 1 over its first $k$ pulls.
And for each $k$, we define $\Ecal_k(\boldsymbol{\alpha}):= \icbr{ \alpha_k \leq \hmu_{(k),1} \leq \mu_1-\varepsilon_2, \KL{\hmu_{(k),1}}{\mu_1-\varepsilon_2} \leq g(k) }$ and $\Ecal(\boldsymbol{\alpha}) := \cup_{1\leq k \leq T} \Ecal_k(\boldsymbol{\alpha})$, which is the case where all $\hmu_{(k), 1}$ from $k=1$ to $T$ are lower bounded by $\boldsymbol{\alpha}$ as measured in terms of KL distance. $g(\cdot)$ is the function we can choose in the situation.

Therefore, $\Bcal^2_a$ can be bounded by
$
    \sum_{t=1}^T \EE\sbr{\onec{\Bcal^2_{t, a} \cap \Ecal(\boldsymbol{\alpha})}}
    +
    \sum_{t=1}^T \EE\sbr{\onec{\Bcal^2_{t, a} \cap \Ecal^c(\boldsymbol{\alpha})}}.
$
By carefully designing $\boldsymbol{\alpha}$, we can bound the above two terms by \Cref{eqn:bad-case-2-ao,eqn:bad-case-2-mo}.
RHS of the \Cref{eqn:bad-case-2-ao} becomes negligible in the asymptotic analysis as $T \to \infty$ and $\varepsilon_1, \varepsilon_2 \to 0$, and \Cref{eqn:bad-case-2-mo} provides a suborder term compared to $\iupbound{\sqrt{KT}}$ in the finite-time analysis.
