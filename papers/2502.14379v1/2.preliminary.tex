\section{Preliminaries} \label{sec:preliminary}

We consider a standard $K$-armed bandit problem, where arms are indexed by $\cbr{1, 2, \dots, K} =: [K]$.
For an arm $a$, it is associated with a reward distribution $\nu_a$ over $[R_{\min}, R_{\max}]$ with mean $\mu_a$, where $\mu_a, R_{\min}, R_{\max} \in \RR \cup \cbr{-\infty, +\infty}$ and satisfies that $R_{\min} \leq \mu_a \leq R_{\max}$.

The agent interacts with the bandit environment $T$ times. 
At each time step $t$, the agent pulls an arm $I_t$ from $[K]$ and receives a reward $r_t$. Up to time $t$, the number of times arm $a$ has been pulled is $N_{t-1, a} := \sum_{i=1}^{t-1} \onec{I_i = a}$, where $\onec{\cdot}$ is an indicator function.
The empirical mean of arm $a$ is $\hmu_{t, a} := 1/N_{t, a}\sum_{i=1}^t r_{i} \onec{I_i = a}$.
We also denote the estimated reward distributions as $\cbr{\hnu_{t,1}, \hnu_{t,2}, \dots, \hnu_{t, K}}$, which are distributions in $\Fcal_m$ with mean $\hmu_{t,1}, \hmu_{t,2}, \dots, \hmu_{t, K}$.
The best empirical reward is $\hmu_{t, \max}$, which is associated with the distribution $\hnu_{t,\max}$.

Additionally, we denote the arm sampling distribution at time step $t$ by $\del{p_{t, a}}_{a\in[K]}$ where each $p_{t, a}$ represents the probability of pulling arm $a$ at time step $t$.

\subsection{OPED family and variance function}


We introduce several assumptions to characterize the behavior of reward distributions and facilitate our analysis.
First, we assume the log-partition function is simple enough to allow tractable analysis.

\begin{assum} \label{assum:oped}
     $b(\theta)$ is twice differentiable with a continuous second derivative 
     $b''(\theta) > 0$, $\forall \theta \in \Theta$.
\end{assum}

\begin{assum} \label{assum:max-variance}
For any distribution $p_\theta$ in $\Fcal_m$, its variance is bounded above by $V_{\max}$.
\end{assum}

It can be checked that many widely used distributions, such as Bernoulli, Poisson, and Gaussian distributions, satisfy these two assumptions.
Based on \Cref{assum:oped} and \Cref{assum:max-variance}, a reward distribution $\nu \in \Fcal_m$ has the following properties,
    \[
        \mu := b'(\theta) = \EE_{x \sim \nu}\sbr{ x }, 
        b''(\theta) = \Var_{x \sim \nu}\sbr{x} \leq V_{\max}
    \]

Additionally, we require that all arm distributions of one bandit instance belong to the same distribution family:

\begin{assum} \label{assum:reward-dist}
    There exists a known OPED family $\Fcal_m$ s.t. for $\forall a \in [K]$, $\nu_a \in \Fcal_m$.
\end{assum}

\Cref{assum:reward-dist} says that for any measure $m(\cdot)$ and function $b(\cdot)$, we can determine a distribution family $\Fcal_m$ under OPED and all reward distributions $\icbr{\nu_a}_{a\in\Kcal}$ come from $\Fcal_m$.
For example, by letting $m(\cdot)$ be the counting measure of $\icbr{0, 1}$, we will obtain all Bernoulli distributions.
By letting $m(\cdot) = \sum_{i=0}^\infty \frac{1}{i!} \delta_{i}(\cdot)$, where $\delta_x$ is the Dirac measure of $x$, we will obtain all Poisson distributions.
\footnote{$\NN_0$ is represents all natural number starting from $0$. Some distribution families, such as the Gamma distributions with a fixed shape parameter $\alpha$, are characterized by a single parameter. However, they do not have the form of \Cref{eqn:oped} due to the sufficient statistic being nonlinear. 
}


Also, we define the variance function as $V(\mu) = b''(b^{-1}(\mu))$, that maps a mean $\mu(\theta)$ to the variance, $V: \mu(\theta) \mapsto V(\theta)$. 
We define the KL divergence between any two distributions $\nu$ and $\nu'$, $\Dcal(\nu, \nu'):= \EE_{X\sim \nu} \sbr{ \ln\del{\tfrac{\diff \nu}{\diff \nu'}(X)} }$ if $\nu$ is absolutely continuous w.r.t. $\nu'$ and $+\infty$ otherwise.

As a shorthand, we denote by the KL divergence between two distributions $\nu_i, \nu_j$ in $\Fcal_m$ with means $\mu_i, \mu_j$ as: 
$\KL{\mu_i}{\mu_j} = \Dcal(\nu_i, \nu_j)$.
According to~\citet{lehmann2006theory}, suppose that distributions $\nu_i$ and $\nu_j$ have natural parameters $\theta_i$, $\theta_j$ respectively, their KL divergence is given by
\begin{align}
    \KL{\mu_i}{\mu_j} = b(\theta_j) - b(\theta_i) - b'(\theta_j)(\theta_j-\theta_i)
    \label{eqn:KL-eqn}
\end{align}

\begin{table*}
\caption{
Some examples of OPED family in the form of~\cref{eqn:oped} and their key properties. $\Bcal$ is the Bernoulli distribution family. 
$\Pcal$ is the Poisson distribution family. 
$\Ncal_\sigma$ is the distribution family, including all Normal distributions with fixed variance $\sigma^2$. 
$\Gamma_k$ is the Gamma distributions family with fixed shape parameter $k$.
$\Ical\Gcal$ is the inverse Gaussian distribution family with fixed $\lambda$.
Variance function maps mean to variance and they all satisfy \Cref{assum:lip}. 
For example, $\Gamma_k$ has a variance function $V(x)=\frac{x^2}{k}$, and the Lipschitz constant is $\frac{2\mu_1}{k}$.}
\centering
\begin{tabular}{l|c|c|c}
    \hline \hline
    Distribution & Mean & Variance & Variance Function \\ \hline
    $\Bcal = \icbr{p(x) = \mu^{x} (1-\mu)^{1-x}, \mu \in [0, 1]}$&
        $\mu$ & $\mu(1-\mu)$     & $x(1-x)$  \\ \hline
    $\Pcal = \icbr{p(x) = \frac{\mu^x e^{-\mu}}{x!}, \mu \in (0, +\infty)}$&
        $\mu$ &      $\mu$      & $x$  \\ \hline
    $\Ncal_\sigma = \icbr{p(x) = \frac{1}{\sigma \sqrt{2\pi}} \expto{-\fr12 \del{\frac{x-\mu}{\sigma}}^2}, \mu \in \Rcal}$      &
        $\mu$ & $  \sigma^2$    & $\sigma^2$  \\ \hline
    $\Gamma_k = \icbr{p(x) = \frac{1}{\Gamma(k) \theta^k} x^{k-1} e^{-x/\theta}, \theta \in (0, +\infty)}$      &
        $k\theta$ & $k\theta^2$ & $x^2/k$  \\ \hline
    $\Ical\Gcal_\lambda = \icbr{p(x) = \sqrt{\frac{\lambda}{2\pi x^3}} \expto{-\frac{\lambda (x-\mu)^2}{2\mu^2 x}}, \mu \in (0, +\infty)}$ &
        $\mu$ & $\mu^3/\lambda$ & $x^3/\lambda$ \\ \hline \hline
 \end{tabular}
\label{tab:variance-function}
\end{table*}
