[
  {
    "index": 0,
    "papers": [
      {
        "key": "korda2013thompson",
        "author": "Korda, Nathaniel and Kaufmann, Emilie and Munos, Remi",
        "title": "Thompson sampling for 1-dimensional exponential family bandits"
      },
      {
        "key": "cappe2013kullback",
        "author": "Capp{\\'e}, Olivier and Garivier, Aur{\\'e}lien and Maillard, Odalric-Ambrym and Munos, R{\\'e}mi and Stoltz, Gilles",
        "title": "Kullback-Leibler upper confidence bounds for optimal sequential allocation"
      },
      {
        "key": "menard17minimax",
        "author": "M{\\'{e}}nard, Pierre and Garivier, Aur{\\'{e}}lien",
        "title": "{A minimax and asymptotically optimal algorithm for stochastic bandits}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "thompson1933likelihood",
        "author": "Thompson, William R",
        "title": "On the likelihood that one unknown probability exceeds another in view of the evidence of two samples"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "cappe2013kullback",
        "author": "Capp{\\'e}, Olivier and Garivier, Aur{\\'e}lien and Maillard, Odalric-Ambrym and Munos, R{\\'e}mi and Stoltz, Gilles",
        "title": "Kullback-Leibler upper confidence bounds for optimal sequential allocation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "lattimore20bandit",
        "author": "Lattimore, Tor and Szepesv{\\'{a}}ri, Csaba",
        "title": "{Bandit Algorithms}"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "qin2023kullback",
        "author": "Qin, Hao and Jun, Kwang-Sung and Zhang, Chicheng",
        "title": "Kullback-leibler maillard sampling for multi-armed bandits with bounded rewards"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "menard17minimax",
        "author": "M{\\'{e}}nard, Pierre and Garivier, Aur{\\'{e}}lien",
        "title": "{A minimax and asymptotically optimal algorithm for stochastic bandits}"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "jin2022finite",
        "author": "Jin, Tianyuan and Xu, Pan and Xiao, Xiaokui and Anandkumar, Anima",
        "title": "Finite-time regret of thompson sampling algorithms for exponential family multi-armed bandits"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "lai85asymptotically",
        "author": "Lai, Tze Leung and Robbins, Herbert and others",
        "title": "Asymptotically efficient adaptive allocation rules"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "korda2013thompson",
        "author": "Korda, Nathaniel and Kaufmann, Emilie and Munos, Remi",
        "title": "Thompson sampling for 1-dimensional exponential family bandits"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "jin2022finite",
        "author": "Jin, Tianyuan and Xu, Pan and Xiao, Xiaokui and Anandkumar, Anima",
        "title": "Finite-time regret of thompson sampling algorithms for exponential family multi-armed bandits"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "cappe2013kullback",
        "author": "Capp{\\'e}, Olivier and Garivier, Aur{\\'e}lien and Maillard, Odalric-Ambrym and Munos, R{\\'e}mi and Stoltz, Gilles",
        "title": "Kullback-Leibler upper confidence bounds for optimal sequential allocation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "lattimore20bandit",
        "author": "Lattimore, Tor and Szepesv{\\'{a}}ri, Csaba",
        "title": "{Bandit Algorithms}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "bian2022maillard",
        "author": "Bian, Jie and Jun, Kwang-Sung",
        "title": "Maillard Sampling: Boltzmann Exploration Done Optimally"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "jin2023thompson",
        "author": "Jin, Tianyuan and Yang, Xianglin and Xiao, Xiaokui and Xu, Pan",
        "title": "Thompson sampling with less exploration is fast and optimal"
      },
      {
        "key": "jin2022finite",
        "author": "Jin, Tianyuan and Xu, Pan and Xiao, Xiaokui and Anandkumar, Anima",
        "title": "Finite-time regret of thompson sampling algorithms for exponential family multi-armed bandits"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "cappe2013kullback",
        "author": "Capp{\\'e}, Olivier and Garivier, Aur{\\'e}lien and Maillard, Odalric-Ambrym and Munos, R{\\'e}mi and Stoltz, Gilles",
        "title": "Kullback-Leibler upper confidence bounds for optimal sequential allocation"
      },
      {
        "key": "auer2002finite",
        "author": "Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul",
        "title": "Finite-time analysis of the multiarmed bandit problem"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "agrawal2017near",
        "author": "Agrawal, Shipra and Goyal, Navin",
        "title": "Near-optimal regret bounds for thompson sampling"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "audibert2009minimax",
        "author": "Audibert, Jean-Yves and Bubeck, S{\\'e}bastien and others",
        "title": "Minimax Policies for Adversarial and Stochastic Bandits."
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "menard2017minimax",
        "author": "M{\\'e}nard, Pierre and Garivier, Aur{\\'e}lien",
        "title": "A minimax and asymptotically optimal algorithm for stochastic bandits"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "lattimore18refining",
        "author": "Lattimore, Tor",
        "title": "{Refining the Confidence Level for Optimistic Bandit Strategies}"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "audibert2009minimax",
        "author": "Audibert, Jean-Yves and Bubeck, S{\\'e}bastien and others",
        "title": "Minimax Policies for Adversarial and Stochastic Bandits."
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "degenne2016anytime",
        "author": "Degenne, R{\\'e}my and Perchet, Vianney",
        "title": "Anytime optimal algorithms in stochastic multi-armed bandits"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "menard2017minimax",
        "author": "M{\\'e}nard, Pierre and Garivier, Aur{\\'e}lien",
        "title": "A minimax and asymptotically optimal algorithm for stochastic bandits"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "bian2022maillard",
        "author": "Bian, Jie and Jun, Kwang-Sung",
        "title": "Maillard Sampling: Boltzmann Exploration Done Optimally"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "qin2023kullback",
        "author": "Qin, Hao and Jun, Kwang-Sung and Zhang, Chicheng",
        "title": "Kullback-leibler maillard sampling for multi-armed bandits with bounded rewards"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "jin2022finite",
        "author": "Jin, Tianyuan and Xu, Pan and Xiao, Xiaokui and Anandkumar, Anima",
        "title": "Finite-time regret of thompson sampling algorithms for exponential family multi-armed bandits"
      },
      {
        "key": "jin2023thompson",
        "author": "Jin, Tianyuan and Yang, Xianglin and Xiao, Xiaokui and Xu, Pan",
        "title": "Thompson sampling with less exploration is fast and optimal"
      },
      {
        "key": "menard2017minimax",
        "author": "M{\\'e}nard, Pierre and Garivier, Aur{\\'e}lien",
        "title": "A minimax and asymptotically optimal algorithm for stochastic bandits"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "qin2023kullback",
        "author": "Qin, Hao and Jun, Kwang-Sung and Zhang, Chicheng",
        "title": "Kullback-leibler maillard sampling for multi-armed bandits with bounded rewards"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "qin2023kullback",
        "author": "Qin, Hao and Jun, Kwang-Sung and Zhang, Chicheng",
        "title": "Kullback-leibler maillard sampling for multi-armed bandits with bounded rewards"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "menard17minimax",
        "author": "M{\\'{e}}nard, Pierre and Garivier, Aur{\\'{e}}lien",
        "title": "{A minimax and asymptotically optimal algorithm for stochastic bandits}"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "audibert09exploration",
        "author": "Audibert, Jean-Yves and Munos, R{\\'{e}}mi and Szepesv{\\'{a}}ri, Csaba",
        "title": "{Exploration--exploitation tradeoff using variance estimates in multi-armed bandits}"
      }
    ]
  }
]