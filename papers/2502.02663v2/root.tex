%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts% This command is only needed if 
% you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a content stream. Unable to analyze the PDF file.
%This is a known problem with the pdfLaTeX conversion filter. The file cannot be opened with Acrobat Reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found at http:\\www.ctan.org
% \usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{booktabs}
\usepackage{diagbox}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{makecell}
\usepackage{float}
\usepackage{placeins}
\usepackage{stfloats}
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
\usepackage{amsmath} % assumes amsmath package installed
\usepackage[bb=px]{mathalfa} 
%\usepackage{amssymb}  % assumes amsmath package installed
%\usepackage[disable]{todonotes}
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\wenzhen}[1]{\todo[inline,color=red!40]{Wenzhen: #1}}
\newcommand{\yuchen}[1]{\todo[inline,color=green!20]{Yuchen: #1}}
\newcommand{\samuel}[1]{\todo[inline,color=yellow!40]{Samuel: #1}}
\renewcommand{\arraystretch}{1.2}

\title{\LARGE \bf
Learning to Double Guess: An Active Perception Approach for Estimating the Center of Mass of Arbitrary Objects
}


\author{Shengmiao Jin, Yuchen Mo, Wenzhen Yuan$^{1}$% <-this % stops a space
\thanks{$^{1}$ University of Illinois Urbana-Champaign}
\thanks{\{\tt\small jin45, yuchenm7, yuanwz\}@illinois.edu}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Manipulating arbitrary objects in unstructured environments is a significant challenge in robotics, primarily due to difficulties in determining an object's center of mass. This paper introduces U-GRAPH: Uncertainty-Guided Rotational Active Perception with Haptics, a novel framework to enhance the center of mass estimation using active perception. Traditional methods often rely on single interaction and are limited by the inherent inaccuracies of Force-Torque (F/T) sensors. Our approach circumvents these limitations by integrating a Bayesian Neural Network (BNN) to quantify uncertainty and guide the robotic system through multiple, information-rich interactions via grid search and a neural network that scores each action. We demonstrate the remarkable generalizability and transferability of our method with training on a small dataset with limited variation yet still perform well on unseen complex real-world objects. 


\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{01Introduction}

\input{02related}
\input{03Method+System}
\input{05Experiment_Results}
\input{06Conclusion}



\addtolength{\textheight}{0cm}   

\section*{ACKNOWLEDGMENT}

% The authors would like to thank the entire RoboTouch Lab, especially Amin for his help with photos and figures, Harsh for revising the paper, and Xiping for helping make the video.

The authors would like to thank Mohammad Amin Mirzaee for his help with photos and figures, Hung-Jui (Joe) Huang for thoughtful discussions, and Harsh Gupta for revising the paper. We also thank Xiping Sun and Yilong Niu for helping make the video.
% The authors would like to thank Ruohan, Arpit, Jingyi, Dakarai, and Yuchen for their help towards this paper. Special Thanks to Amin for helping with picture making and hardware design.


\bibliographystyle{IEEEtran} 
\bibliography{bibliography.bib}


\end{document}
