%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

\input{tex/preamble}


\title{\LARGE \bf
DeepVL: Dynamics and Inertial Measurements-based Deep Velocity Learning for Underwater Odometry 
}

\author{Mohit Singh, and Kostas Alexis 
%\thanks{$^\star$ The authors contributed equally.} % discuss it :)
\thanks{This material was supported by the Research Council of Norway Award NO-327292.}% <-this % stops a space
\thanks{The authors are with the Norwegian University of Science and Technology (NTNU), O. S. Bragstads Plass 2D, 7034, Trondheim, Norway {\tt\small mohit.singh@ntnu.no}}
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
This paper presents a learned model to predict the robot-centric velocity of an underwater robot through dynamics-aware proprioception. The method exploits a recurrent neural network using as inputs inertial cues, motor commands, and battery voltage readings alongside the hidden state of the previous time-step to output robust velocity estimates and their associated uncertainty. An ensemble of networks is utilized to enhance the velocity and uncertainty predictions. Fusing the network's outputs into an Extended Kalman Filter, alongside inertial predictions and barometer updates, the method enables long-term underwater odometry without further exteroception. Furthermore, when integrated into visual-inertial odometry, the method assists in enhanced estimation resilience when dealing with an order of magnitude fewer total features tracked (as few as $1$) as compared to conventional visual-inertial systems. Tested onboard an underwater robot deployed both in a laboratory pool and the Trondheim Fjord, the method takes less than $5\textrm{ms}$ for inference either on the CPU or the GPU of an NVIDIA Orin AGX and demonstrates less than \SI{4}{\percent} relative position error in novel trajectories during complete visual blackout, and approximately \SI{2}{\percent} relative error when a maximum of $2$ visual features from a monocular camera are available. 

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
\input{tex/1_Introduction}

\section{RELATED WORK}\label{sec:relatedwork}
\input{tex/2_RelatedWork}

\section{Deep Velocity Learning}\label{sec:deepvl}
\input{tex/3_LearnedProprioceptiveModel}

% \section{Uncertainty}
% \input{tex/4_Uncertainty}

\section{Integration into Inertial Odometry with optional Visual Fusion}\label{sec:vio}
\input{tex/5_VIOIntegration}

\section{Evaluation Studies}\label{sec:evaluation}
\input{tex/6_Experiments}

\section{CONCLUSIONS}\label{sec:concl}
\input{tex/7_Conclusion}

\addtolength{\textheight}{-8cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.




\bibliographystyle{IEEEtran}
\bibliography{BIB/main, BIB/learnedInertial}

\end{document}
