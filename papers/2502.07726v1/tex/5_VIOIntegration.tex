We use \ac{reaqrovio} ~\cite{SinghRCMinRovio2024} (an underwater \ac{vio} method based on ROVIO~\cite{bloesch2015robust}) as the underlying \ac{ekf} based state estimation framework. We define the state as in \ac{reaqrovio}:

\small
\begin{equation}
    \mathbf{s}=\left[\mathbf{r}, \mathbf{q}, \boldsymbol{\upsilon}, \mathbf{b}_{\mathbf{a}}, \mathbf{b}_{\boldsymbol{\omega}},| \mathbf{c}, \mathbf{z},|n,| \mu_{0}, \mu_{1}, ...,\mu_{N},| \rho_{0}, \rho_{1}, ..., \rho_{N}\right]
\end{equation}
\normalsize
where $\mathbf{r}$ denotes the robot-centric position and $\boldsymbol{\upsilon}$ is the robot-centric velocity, $\mathbf{q}$ denotes the orientation of the robot as a map from the body frame $\mathcal{B}$ to the world frame $\mathcal{W}$, the $\ac{imu}$ acceleration biases are defined by $\mathbf{b}_{\mathbf{a}}$ and gyroscope biases are defined by $\mathbf{b}_{\boldsymbol{\omega}}$. The camera to \ac{imu} extrinsics are denoted by $\mathbf{c}$ for linear translation and $\mathbf{z}$ for the rotation. The refractive index of the medium is denoted by $n$. The terms $\mu_{n}$ and $\rho_{n}$ denote the bearing vector and the inverse depth of the visual features respectively. The value $N$ denotes the number of maximum features in the state of \ac{reaqrovio}.

\subsection{Velocity Update} The velocity predictions $\velpred_{*}$ and the corresponding covariance $\sigmapred_{*}$ from the proposed network are used in a newly introduced innovation term $\mathbf{y}_{\boldsymbol{\upsilon}}$ for velocity update:

\begin{equation}
    \boldsymbol{y}_{\boldsymbol{\upsilon}}= \velpred_{*} - \boldsymbol{\upsilon} + \mathbf{n}_{{\boldsymbol{\upsilon}}},\quad\mathbf{n}_{\boldsymbol{\upsilon}}\sim\mathcal{N}(\mathbf{0}, \sigmapred_*).
\end{equation}

\subsection{Relative Depth Update} Let $d_{t}$ be the depth measured by the barometric depth sensor at a given time $t$ along the negative $Z$ axis of the world frame $\mathcal{W}$. Then we use the relative depth measurement $d_{\Delta}=d_{t}-d_{0}$ (with noise variance $\sigma_{d_\Delta}^{2}$) where $d_{0}$ denotes the initial depth measured at $t=0$. The innovation term $y_{Z}$ for the $Z$ component of $\mathbf{r}$ takes the form: 

\begin{equation}
    y_{Z} = -d_{\Delta}-\mathbf{r}_{Z} + n_{d_{\Delta}},\quad n_{d_{\Delta}}\sim\mathcal{N}(0, \sigma_{d_\Delta}^2).
\end{equation}

\subsection{Contribution of Visual Features and Relative Depth}
The present work fuses the velocity from \ac{deepvl} and optionally fuses the visual patch features as described in \ac{reaqrovio}. We particularly vary the number of features $N$ in the state to emulate a presence of critically low visual features from the environment. In the remainder of the work $\ac{deepvl}_{0}$ (or $\ac{deepvl}$) refers to the fusion of velocity $\velpred_{*}$ and it covariance $\sigmapred_{*}$ from the presented network in \ac{reaqrovio} with relative depth update and with no visual features in the state $\mathbf{s}$. Whereas, $\ac{deepvl}_{N}$ denotes a framework with additional inclusion of $N$ visual features in the state. Similarly, for concise notation of the various configurations of \ac{reaqrovio}, we denote $\ac{vio}_{N}$ as the a visual-inertial odometry framework from \ac{reaqrovio} with $N$ features in the state and with relative depth update.

\begin{figure*}[ht!]
\centering
    \includegraphics[width=0.98\textwidth]{PNG/MainResultFIgure350dpiFinalversion1.png}
\vspace{-2ex} 
\caption{Detailed analysis of trajectory $5$ collected in the Trondheim Fjord. a) The odometry estimate with \ac{deepvl}, \ac{vio} with $1$ feature, and fusion of \ac{deepvl} with \ac{vio} with $1$ feature. b) Images from the Alphasense camera stream from multiple locations in the trajectory. c) Tabular comparison of \ac{rpe} with maximum features ranging from $0$ to $8$ (`X' indicating divergence, while `-' indicates that a test is not ran if not meaningful). On the right, the evolution of position, accelerometer biases, the uncertainty estimates and \ac{rpe} are shown.}
\label{fig:detailed_results}
\vspace{-2ex} 
\end{figure*}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{PNG/CollectivePlots.png}
    \caption{A collective plot showcasing all the $8$ evaluation trajectories along with odometry estimates based on \ac{deepvl}.}
    \label{fig:collective_plot}
\end{figure}