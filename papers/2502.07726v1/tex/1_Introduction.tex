Resilience is a crucial aspect of expanding the envelope of robotics. In the underwater domain, a core challenge is achieving long-term reliable state estimation. Traditionally, underwater systems depend exceedingly on high-end acoustic sensing alongside specialized \acp{imu}~\cite{wu2019survey} to ensure the availability of high-quality data supporting state estimation. On the other hand, a recent body of works exploring camera-based underwater navigation is challenged when it comes to dealing with the many intricacies of underwater vision, including low-light, poor visibility, refractive effects, and more~\cite{singh2024online,miao2021univio,ferrera2019aqualoc,gu2019environment}. Strategies for enhancing the resilience of odometry estimation are therefore essential.

\begin{figure}
    \centering
    \includegraphics[width=0.99\linewidth]{PNG/IntroFigureLabelled_1.png}
    \vspace{-4ex}
    \caption{Utilized custom underwater robot with 5 camera visual-inertial sensing alongside overlay of estimated trajectory from the proposed method and ground-truth \ac{vio} on a top-down view of a pier in the Trondheim Fjord.}
    \vspace{-4ex}
    \label{fig:introfigure}
\end{figure}\par
In response, we present \ac{deepvl} a novel method for long-term reliable state estimation in challenging real-world scenarios based on a dynamics-aware neural odometry solution to enable localization in visual blackout, alongside assisting vision-based odometry subject to extreme lack of visual features (i.e., as few as $1$ feature). We propose a deep recurrent neural network-based model trained on sequences of proprioceptive robot data to predict the instantaneous robot-centric velocity and corresponding uncertainty. Particularly, we use both \ac{imu} measurements and the thruster command data driven by the complementary information the two modalities offer about the robot dynamics, alongside battery level readings. When fused as a velocity update to an \ac{ekf} with \ac{imu}-based prediction and barometer updates, the method offers persistent odometry without other exteroception, while when integrated into \ac{vio} it allows similar odometry results with an order of magnitude fewer features tracked as compared to conventional \ac{vio}. The \ac{deepvl} network is small and can seamlessly run on CPU, thus allowing it to be deployed on the computing solutions of existing underwater robots without modifications. Likewise, the method does not assume high-quality \ac{imu} data.

The proposed neural model is trained predominantly on data from an indoor laboratory alongside missions in the Trondheim Fjord (Figure \ref{fig:introfigure}), while a set of distinct trajectories are used for its evaluation. Specifically, the method was evaluated on $6$ trajectories from the Trondheim Fjord and $2$ in an indoor pool with varying motions and trajectory lengths (\SI{100}{\meter} to \SI{300}{\meter}). First, we evaluate the fusion of \ac{deepvl} in an \ac{ekf} with \ac{imu} propagation and barometer readings, and a detailed analysis is presented. Secondly, the effect of fusing visual features (ranging from $1$ to $8$), to the estimator is studied in an extensive ablative study. Third, we evaluate the consistency of the method's uncertainty estimation. Lastly, we present a validation of way-point tracking with state estimation feedback provided by the proposed method. As demonstrated, the presented work allows odometry with \SI{3.9}{\percent} relative error for extended continuous visual blackout and \SI{2.2}{\percent} for a maximum of $2$ visual features from a monocular camera. 

In the remainder of this paper, Section~\ref{sec:relatedwork} presents related work, while the deep velocity learning model is detailed in Section~\ref{sec:deepvl} and its integration in estimation is presented in Section~\ref{sec:vio}. Experimental studies are shown in Section~\ref{sec:evaluation}, while conclusions are drawn in Section~\ref{sec:concl}.
