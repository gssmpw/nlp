This work presented \ac{deepvl}, a Dynamics and Inertial-based method to predict velocity and uncertainty which is fused into an EKF along with a barometer to perform long-term underwater robot odometry in lack of extroceptive constraints. Evaluated on data from the Trondheim Fjord and a laboratory pool, the method achieves an average of \SI{4}{\percent} RMSE RPE compared to a reference trajectory from \ac{reaqrovio} with $30$ features and $4$ Cameras. The network contains only $28$K parameters and runs on both GPU and CPU in \SI{<5}{\milli\second}. While its fusion into state estimation can benefit all sensor modalities, we specifically evaluate it for the task of fusion with vision subject to critically low numbers of features. Lastly, we also demonstrated position control based on odometry from \ac{deepvl}.