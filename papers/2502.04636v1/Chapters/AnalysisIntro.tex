\section{Large Scale Analysis}
\label{sec:large-scale-analysis}

\subsection{Dataset}
\label{subsec:dataset}

\begin{table*}[h]
\tiny
\caption{Number of APKs per year}
\label{tab:large-scale_dataset}
\resizebox{\linewidth}{!}{%
\begin{tabular}{c|c|c|c|c|c|c|c|c|c}
\hline
\textbf{Year} & 2016 & 2017 & 2018 & 2019 & 2020 & 2021 & 2022 & 2023 & \textbf{Total} \\ \hline
\textbf{\begin{tabular}[c]{@{}c@{}} Available APKs\end{tabular}} & 174,136 & 501,865 & 157,613 & 7,205 & 21,014 & 60,705 & 240,775 & 65,697 & 1,229,010 \\ \hline
\textbf{Analysed APKs} & 74,817 & 159,639 & 80,112 & 7,201 & 20,982 & 59,539 & 81,134 & 65,543 & 548,967 \\ \hline
\end{tabular}%
}
\end{table*}

Our large-scale analysis data is based on two large snapshots of the Google Play Store collected around 2018 and 2023. The 2018 dataset that was collected as a part of our previous work~\cite{karunanayake2020multi,rajasegaran2019multi} contains metadata of over 1.2 million apps that were collected between January and March 2018 and 1,023,521 APK files. The 2023 dataset contains metadata of over one million apps and was collected between January and November and 395,396 APK files.


Both datasets were collected in the same way using a Python-based crawler. First, the crawler discovered available apps on the Google Play Store. Then, it collected app metadata (e.g., app ID, app genre, developer name, number of downloads, rating details) and APK executables for free apps. There are several reasons behind the difference between the number of apps for which we crawled metadata and the number of apps for which we downloaded the APKs. First, the APK crawler is significantly slower than the metadata crawler. Second, we do not download the APKs of paid apps. Third, some apps do not support the Android device we simulated to download APKs.

One of the fields in app metadata is the ``\texttt{last update date}''. We use this field to categorise apps by year as summarised in Table~\ref{tab:large-scale_dataset}. As can be seen, the centre years of our two crawls, i.e., 2017 and 2022, have the highest number of apps. We have a notably smaller number of apps for 2019 and 2020 because they were only collected in 2022, and only a limited number of apps have the last update date in 2019 and 2020. These apps can bias our analysis as these represent apps that have been most likely abandoned by app developers. As a result, we do not consider 2019 and 2020 in our extended analysis. For each year, we analyse a random sample of apps as listed in Table~\ref{tab:large-scale_dataset}. The reason for not analysing all apps in all the years is the time, as APK decompilation takes time. 



\subsection{Process of APK Analysis} For each APK we analyse, we use Androguard~\cite{desnos2018androguard} and our pre-processing scripts to create the feature vector described in Section~\ref{sec:features}. Next, we make a prediction using our \textit{Obfuscation Detector}. If the app is predicted as not obfuscated, we record this and stop further analysis for that app. If the APK is obfuscated, we use the same feature vector with the \textit{Obfuscation Tool Detector Bank} and \textit{Obfuscation Technique Detector Bank} to identify the tool and technique(s) used. In the Tool Detector step, if all three classifiers give a probability of less than $0.5$, we categorize the APK as using an \textit{Other} tool. Otherwise, we use the highest probability to determine the tool. In the Technique Detector, the classifier identifies the obfuscation technique \textit{(IR, CF, SE)} if its probability exceeds $0.5$. This overall process is illustrated in Figure~\ref{fig:overview_1b}.