\section{Results}

\subsection{Molecular Graph Generation}
\label{subsec:molecular_graph_generation}

\input{tables/moses}

% MOSES, GUACAMOL 결과 설명
We evaluate \methodname{} using the MOSES \citep{moses} and GuacaMol \citep{guacamol} benchmark datasets, following the dataset splits and evaluation metrics from \citet{digress}. 
Across both MOSES (\cref{tab:moses}) and GuacaMol (\cref{tab:guacamol}), \methodname{} consistently outperforms existing diffusion- and flow-based models. 
While denoising-based models have traditionally lagged behind auto-regressive models, \methodname{} is the first to surpass them, achieving state-of-the-art Fréchet ChemNet Distance (FCD) on MOSES and KL divergence on GuacaMol. 
Notably, \methodname{} achieves over $99\%$ validity while also demonstrating strong property-based performance (MOSES Filters, GuacaMol KL divergence), performing on par with JT-VAE and GraphINVENT. 
Furthermore, \methodname{} maintains uniqueness and novelty, highlighting its ability to assemble fragments into diverse molecular structures. We provide non-curated samples of generated molecules in \cref{fig:sample_moses,fig:sample_guacamol}.

% MOSES에서 train set에 대해서 Scaf.가 왜 낮게 나왔는지 설명 + test set 설명
On the MOSES Scaf metric, \methodname{} tends to underperform when generation is restricted to training fragments, which can be attributed to the scaffold-split evaluation in MOSES. If a test molecule’s scaffold is absent from the fragment bag, the model cannot generate it. However, when using test fragments, \methodname{} significantly improves its performance, demonstrating its ability to generalize to unseen fragments through the fragment embedding module.
% Furthermore, \methodname{} effectively generalizes to unseen fragments, as demonstrated by its strong performance on the MOSES Scaf metric when utilizing test fragments. While fragment-based methods, including JT-VAE and \methodname{}, may exhibit limitations when restricted to training fragments, this is primarily due to the scaffold-split evaluation strategy in MOSES. If a test molecule’s scaffold is not present in the training fragment bag, the model cannot generate that molecule. However, by incorporating test fragments, \methodname{} significantly outperforms existing approaches, reinforcing the effectiveness of its fragment embedding module in capturing structural diversity.


\subsection{Natural Product Molecule Generation}
\label{sec:natural_product_molecule_generation}

\input{tables/coconut}

Understanding natural products is crucial as they serve as a rich source of bioactive compounds and provide valuable insights for drug discovery \citep{np_in_drug_discovery, np_source_new_drug}.  
% In this regard, we introduce a natural product generation benchmark. 
Additionally, the COCONUT dataset includes a hierarchical classification scheme (pathway, superclass, class) that captures structural and biosynthetic relationships, enabling a more in-depth evaluation of generative models on complex molecular categories.
Details on the dataset and evaluation metrics are provided in \cref{appsubsubsec:natural_product_generation_benchmark}.
% To evaluate the capability of generative models in capturing natural product characteristics, we introduce a natural product generation benchmark based on the COCONUT dataset \citep{coconut}.  
% Further details on the dataset and evaluation metrics are provided in \cref{appsubsubsec:coconut}.

We compared \methodname{} with DiGress on the COCONUT benchmark, as summarized in \cref{tab:coconut}.
While both models achieve high validity, validity alone does not guarantee that generated molecules resemble natural products.  
\methodname{} outperforms DiGress, by achieving lower KL divergence across pathway, superclass, class, and NP-likeness scores, indicating a closer alignment with the training set natural products. 
This suggests that fragment-based modeling more effectively captures molecular structural characteristics, leading to the generation of more biologically relevant molecules. 
Example molecules generated by \methodname{} and DiGress are shown in \cref{fig:sample_coconut,fig:sample_digress_coconut,fig:sample_coconut_class}.

% 천연물이 왜 중요한 분자 데이터인지 설명 + COCONUT 벤치마크 간단히 설명
% Understanding natural products and their structurally related derivatives is essential, as they serve as a rich source of bioactive compounds and frequently provide valuable insights for drug discovery \citep{np_in_drug_discovery, np_source_new_drug}.
% However, their intrinsically complex structures and large molecular sizes pose significant challenges for molecular design and synthesis. 
% To address these challenges, we designed a natural product generation benchmark to evaluate the capability of generative models to capture and reproduce the biochemical characteristics of natural products. 
% Our benchmark is based on 416,249 molecules from the COCONUT database \citep{coconut, coconut2}, the most extensive open-access collection of natural product structures. Further details on the dataset and evaluation metrics are provided in \cref{appsubsubsec:coconut}.

% COCONUT 벤치마크 결과 설명
% We compared DiGress with \methodname{}, and the results are presented in \cref{tab:coconut}. 
% While both models achieve over $85\%$ validity, high validity and uniqueness alone do not guarantee that generated molecules resemble natural products. 
% \methodname{} significantly outperforms DiGress, demonstrating lower KL divergence across pathway, superclass, class, and NP-likeness scores, indicating a closer alignment with the training set natural products. 
% This suggests that fragment-based modeling more effectively captures molecular structural characteristics, leading to the generation of more biologically relevant molecules. 
% Example molecules generated by \methodname{} and DiGress are shown in \cref{fig:sample_coconut}.


\subsection{Sampling Efficiency} 
\label{sec:sampling_efficiency}

\input{figures/sample_step}

Generative models based on the denoising process required multiple iterative steps, making sampling inefficient.
Therefore, reducing the number of denoising steps while maintaining generation quality is crucial for improving efficiency and scalability in molecular generation.  
\cref{fig:sample_step} and \cref{tab:sample_step} present the MOSES benchmark results across different denoising steps for various generative models.
As expected, reducing the number of denoising steps generally leads to a decrease in generation quality.
However, \methodname{} exhibits a significantly lower decline in quality and consistently outperforms other models, achieving over $95\%$validity and an FCD of $0.66$ with just $10$ steps, exceeding other models. 
This is likely due to the fragment-based discrete flow matching approach, which reduces the number of edges that need to be predicted and allows for more stable intermediate representations during generation.
Further details and sampling efficiency analysis are provided in \cref{appsubsec:sampling_step,appsubsec:sampling_time_analysis}.
% In contrast, other models require $50$ to $500$ steps to reach comparable results. 

% Denoising step 를 줄여야 하는 이유 + 줄였을 때 성능 설명
% Generative models based on denoising processes require multiple iterative denoising steps, leading to sampling inefficiencies. 
% Therefore, reducing the number of denoising steps while maintaining generation quality is crucial for improving efficiency and scalability in molecular generation.
% \cref{fig:sample_step} presents the MOSES benchmark results across different denoising steps for various generative models. 
% As expected, reducing the number of denoising steps generally decreases generation quality across all models in validity and FCD metrics.
% However, \methodname{} exhibits a significantly lower decline and consistently outperforms other models, even with fewer Euler steps.
% With just 10 steps, \methodname{} achieves over $95\%$ validity and an FCD of $0.66$, whereas other models require $50$ to $500$ steps to reach comparable or better values. 
% This efficiency gain stems from the fragment-based discrete flow matching approach, which operates on a coarse-grained fragment-level representation rather than individual atoms.
% By reducing the number of nodes and edges in the graph, \methodname{} significantly decreases the computational complexity of edge prediction, which typically scales quadratically with graph size.
% As a result, fewer denoising steps are required while maintaining high molecular validity.


\subsection{Conditional Generation} 
\label{sec:conditional_generation}

\input{figures/moses_condition_1}

Conditional generation is crucial in molecular design, enabling precise control over molecular properties.
We integrate classifier-free guidance (CFG) \citep{classifier_free_guidance,unlocking_guidance_dfm} to \methodname{} (details in \cref{appsubsec:classifier-free_guidance}) to guide the generation process towards desired property values. 
We conduct conditional molecular generation on the MOSES dataset to evaluate its effectiveness, targeting logP, number of rings, QED, and TPSA.

From \cref{fig:moses_condition_1,fig:moses_condition_2}, we observe that \methodname{} achieves a lower condition MAE while maintaining a lower FCD compared to DiGress, positioning our method on the Pareto-optimal frontier in the FCD-Condition MAE trade-off.
The improvement can be attributed to the structured generative process of \methodname{}, where molecules are assembled from semantically meaningful fragments, allowing for better preservation of structural patterns and improved property control. We provide further details on the CFG and experiments in \cref{appsubsec:conditional_generation}.

% CFG 결과 설명
% Classifier-Free Guidance (CFG) \citep{classifier_free_guidance} enables a trade-off between class adherence and generation quality by interpolating between conditioned and unconditioned diffusion models. 
% In the discrete flow setting, \citet{unlocking_guidance_dfm} extended this approach by multiplication of conditional and unconditional rate matrices, enabling effective property-controlled generation in SMILES-based molecular design.
% Building upon this approach, we integrate discrete flow-based property control into our framework. 
% We conduct conditional molecular generation on the MOSES dataset, targeting logP, number of rings, QED, and TPSA, demonstrating the controllability of \methodname{}.
% From \cref{fig:moses_condition_1}, we observe that \methodname{} achieves a lower Condition MAE while maintaining a lower FCD compared to DiGress, positioning our method on the Pareto-optimal frontier in the FCD-Condition MAE trade-off. 
% This improvement can be attributed to the structured generative process of \methodname{}.
% Rather than relying on constructing molecules atom by atom, the model assembles molecules from semantically meaningful fragments, which naturally encode higher-level structural patterns and influence overall molecular properties.
% Further details on the conditional rate matrix and additional results are provided in \cref{appsubsec:conditional_generation} and \cref{appsubsec:classifier-free_guidance}.