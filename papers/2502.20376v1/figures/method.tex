
\begin{figure*}
    \centering
    \setlength{\tabcolsep}{1pt}
    \begin{subfigure}{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{images/toy_example/learned_uncond_flow.png}
        \caption{CNF}
        \label{fig:toy-flow}
    \end{subfigure}
    \begin{subfigure}{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{images/toy_example/Unconditioned_Inversion.png}
        \caption{Inversion w/ null condition}
        \label{fig:toy-uncond}
    \end{subfigure}
    \begin{subfigure}{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{images/toy_example/Conditioned_Inversion.png}
        \caption{Inversion w/ accurate condition}
        \label{fig:toy-cond}
    \end{subfigure}
    \begin{subfigure}{0.24\linewidth}
        \centering
        \includegraphics[width=\linewidth]{images/toy_example/Incorrectly_Conditioned_Inversion.png}
        \caption{Inversion w/ inaccurate condition}
        \label{fig:toy-incorrect-cond}
    \end{subfigure}
    \vspace{-8pt}
    \caption{We train a toy conditional CNF model to analyze the importance of the condition used during inversion. The prior distribution is a single Gaussian, and the posterior consists of five Gaussians. (a) shows denoising trajectories from the prior, and (b)-(d) show inversion and denoising trajectories for points from the posterior. In (b), a null condition is used for both processes, in (c), the condition matches the Gaussian from which the point was sampled, and in (d), the condition corresponds to the adjacent Gaussian. Lines connect points on the inversion and denoising trajectories to illustrate offsets between these processes.}
    \vspace{-8pt}
    \label{fig:method}
\end{figure*}
