\input{figures/recon_comparison_qual}

\section{Experiments}
\label{sec:experiments}
\graphicspath{../images/}


We evaluate our inversion method based on both reconstruction accuracy and editability. To demonstrate editability, we utilize a variety of existing image editing techniques, each excelling in different types of edits, and apply them to the inverted images.

\input{tables/reconstruction_quant}
\input{figures/recon_comparison_qual_flux}

Unless stated otherwise, our experiments use SDXL~\cite{podell2024sdxl} with DDIM scheduler~\cite{song2022denoisingdiffusionimplicitmodels}. All experiments utilize $50$ denoising steps with a default guidance scale of $7.5$. For image conditioning, we employ IP-Adapter-plus\_sdxl\_vit-h~\cite{ye2023ipadaptertextcompatibleimage}.
In few-step diffusion experiments, we use SDXL-Turbo~\cite{sauer2023adversarialdiffusiondistillation} with an Euler scheduler and perform $4$ denoising steps. We also explore Flux~\cite{flux} using FLUX.1-dev where we condition the model with PulID-Flux~\cite{guo2024pulid} and use RF-Inversion~\cite{rout2024rfinversion} with 28 steps. As PulID was trained only on human faces, we focus on this domain for evaluating our method with Flux.


\subsection{Reconstruction}

We evaluate reconstruction both qualitatively and quantitatively. For quantitative evaluation, we measure $L_2$ distance, PSNR, SSIM and LPIPS~\cite{zhang2018perceptual}.
Figures~\ref{fig:motivation-figure} and \ref{fig:recon-qualitative} present qualitative results of DDIM inversion~\cite{dhariwal2021diffusionmodelsbeatgans} under increasingly descriptive conditions. These examples highlight that conditioning the inversion process on an image significantly improves reconstruction in highly detailed regions. Notably, in the third example of Figure~\ref{fig:recon-qualitative}, our method successfully reconstructs the tattoo on the back of the right boxer. Furthermore, the boxer's leg pose is more accurately preserved, and the tattoo on the leg becomes visible.



\vspace{-6pt}
\paragraph{\textbf{Comparisons}}
We integrate Tight Inversion with several existing inversion methods and demonstrate that it enhances their reconstruction performance. Specifically, we combine our method with DDIM inversion~\cite{dhariwal2021diffusionmodelsbeatgans}, ReNoise~\cite{garibi2024renoise}, and RF-Inversion~\cite{rout2024rfinversion}. Note that DDPM-based inversion methods typically guarantee perfect reconstruction, so we compare with these methods only in terms of editability.
Qualitative results are shown in Figures~\ref{fig:recon-qualitative-comp-sdxl} and \ref{fig:recon-qualitative-comp-flux}. As illustrated, integrating Tight Inversion with existing methods consistently improves reconstruction. For example, in Figure~\ref{fig:recon-qualitative-comp-sdxl}, our method accurately reconstructs the handrail in the leftmost example and the man with the blue shirt in the rightmost example.

We further validate the improvement quantitatively. Following previous works~\cite{Mokady_2023_CVPR, garibi2024renoise}, we utilize the test set of MS-COCO~\cite{lin2015microsoftcococommonobjects} and present the results in Table~\ref{tab:reconstruction_comparison_quant}. As observed from the table, our method improves reconstruction of existing inversion methods across all metrics.


\paragraph{\textbf{Ablation Studies}}
We conduct ablation studies to evaluate the importance of combining image conditioning with an inversion method. Since IP-Adapter is trained to reconstruct images from image conditions, it is reasonable to explore whether accurate reconstruction can be achieved solely by conditioning on the image, without requiring a carefully selected noise initialization.
Figure~\ref{fig:ablation1} explores this possibility. In the first row, a random noise is sampled, and the denoising process is conditioned on the input image. While the semantics and colors are captured, the reconstructed image poorly matches the original one. This demonstrates that precise reconstruction still requires a specific initial noise.
In the second row, DDIM inversion is performed using only a text prompt, while denoising is conditioned on the input image. The results show slight over-saturation and the disappearance of the phone in the man's hand.
In the third row, our Tight Inversion method is applied, conditioning both inversion and denoising on an input image. Our method significantly outperforms the alternatives, faithfully reconstructing both colors and fine details, including the phone.


\input{figures/ablation1}

We further explore the impact of image conditioning strength. Specifically, IP-Adapter provides a guidance scale, $s$, which controls the influence of the input image on the generated output. Setting $s$ to zero is equivalent to using the text-to-image model without IP-Adapter. Figure~\ref{fig:ablation2} presents the results for different values of $s$.
As expected, we observe that reconstruction quality (second row) improves with higher IP-Adapter scales, emphasizing the importance of precise conditioning.



\input{figures/ablation2}



\subsection{Editing}

Next, we evaluate Tight Inversion in the context of image editing. Specifically, we analyze the impact of integrating our technique with various image editing methods (prompt2prompt~\cite{hertz2022prompt}, Edit Friendly DDPM~\cite{hubermanspiegelglas2024editfriendlyddpmnoise}, LEDITS++ \cite{brack2024ledits}, RF-Inversion \cite{rout2024rfinversion}). We demonstrate that, in addition to providing accurate reconstruction, our method significantly enhances editability. Specifically, we perform different types of edit and show that our approach consistently improves editing results, both qualitatively and quantitatively.


\begin{figure}[h!]
    \centering
    \input{figures/scale_clip_similarity}
    \caption{CLIP Similarity of the edited text prompt and the edited image vs. CLIP Similarity of the source image and edited imaged for IPA scales in the range of 0 (without tight inversion, marked with a cross) to 0.7 (strong conditioning on the source image). For both axes, higher is better.}
    \label{fig:clip_similarity}
\end{figure}

\input{figures/editing_qualitative}

\paragraph{\textbf{Qualitative Comparison}}
We present qualitative results obtained with SDXL \cite{podell2024sdxl} and Flux~\cite{flux} in Figure~\ref{fig:edit-qualitative-comp} (more results are in Figures~\ref{fig:more-results1} and \ref{fig:more-results2}). In the first and second rows, we perform a na\"ive edit by changing the prompt during the denoising process. 
In the third row, we apply DDIM inversion and denoise the inverted noise using prompt2prompt \cite{hertz2022prompt}. 
The next two rows utilize the inversion and denoising methods from Edit Friendly DDPM \cite{hubermanspiegelglas2024editfriendlyddpmnoise} and LEDITS++ \cite{brack2024ledits}, respectievly.
In the last three rows, we use RF-Inversion \cite{rout2024rfinversion} with Flux, and we use PulID \cite{guo2024pulid} as the conditioning mechanism for our Tight Inversion method.
In each row, we show the input image, followed by the reconstruction results (with and without Tight Inversion), and then the edited images obtained from the inverted noises (with and without Tight Inversion).

Note that both Edit Friendly DDPM Inversion and LEDITS++ guarantee perfect reconstruction. For the other methods, we select examples where the reconstruction, even without Tight Inversion, is accurate. This choice emphasizes that, even when competing methods produce plausible reconstructions, our method outperforms them in terms of editability.

As shown in the results, our method better preserves the original image, maintaining the structure of the diner in the first row, the patterns on the snow and the animal's expression in the third row, and the horse's pose in the fifth row. In the results obtained with Flux, our method preserves the identity of the individual significantly better in the edited image, even when the reconstruction is comparable (e.g., the shape of LeCun's head). 


In Figure~\ref{fig:turbo_results}, we present results with SDXL-Turbo~\cite{sauer2023adversarialdiffusiondistillation}. Here, we use ReNoise inversion~\cite{garibi2024renoise} combined with Tight Inversion. To edit the inverted noise, we denoise it with a target text prompt. As shown, Tight Inversion results in better preservation of the cups in the top example and the background in the bottom example.

\input{figures/challenging_edits_turbo}




\paragraph{\textbf{Quantitative Comparisons}}
Next, we evaluate our editing results quantitatively. We use the MagicBrush benchmark~\cite{Zhang2023MagicBrush} for the evaluation, as it contains diverse and challenging images and edits. Following previous work~\cite{brooks2023instructpix2pixlearningfollowimage} we evaluate the edit quality in terms of the preservation of the input image, and the adherence to the target prompt, and we use CLIP~\cite{radford2021learning} to measure both.
We present the results with DDIM Inversion and LEDITS++ in Figure~\ref{fig:clip_similarity}. In both graphs the tradeoff between image preservation and adherence to the target edit is clearly observed~\cite{tov2021designing}. Tight Inversion provides better control on this tradeoff, and better preserves the input image while still aligning with the edit prompt as also evident in Figure~\ref{fig:edit-qualitative-comp}. Note, that a CLIP similarity of above 0.3 between an image and a text prompt indicates plausible alignment between the image and the prompt. 


\paragraph{\textbf{Ablation Studies}}
In Figure~\ref{fig:ablation1}, we edit the image by denoising using a modified prompt. In the first row, where we use a random noise, the resulting image significantly differs from the input. In the second row, where the inversion is not conditioned on the input image, the red hat is not added, which may result from the initial noise being slightly out of distribution. This makes it more difficult to edit, particularly when an image condition is used. In the third row, a red hat is added to the man while the input image is successfully preserved.


We explore the IP-Adapter guidance scale effect on the edit in Figure~\ref{fig:ablation2}. In the third row, we add a cowboy hat to the deer, where various guidance scales are used for the inversion and denoising. 
We observe a clear reconstruction-editability tradeoff associated with the IP-Adapter scale. While increasing the scale improves reconstruction quality, it progressively limits editing capabilities, eventually preserving the original image intact. In practice, we found that an IP-Adapter scale of 0.4 strikes an effective balance for most cases.


