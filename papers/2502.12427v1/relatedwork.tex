\section{Related Work}
\label{sec-related}
Early Single-Image Super-Resolution (SISR) methods can be broadly divided into learning-based and reconstruction-based approaches \cite{Yang2010}. Learning-based methods include techniques such as pixel-based approaches \cite{Zhang2012}, which map individual LR pixels to their corresponding HR pixels using trained models. Another common strategy is example-based methods, where the system learns the relationships between LR and HR image pairs from a predefined database of examples \cite{freeman2002}. These approaches rely heavily on the availability of accurate example pairs and the assumption that similar patterns exist in the input image. The reconstruction-based methods leverage prior knowledge about image structures to define constraints for generating HR outputs. For instance, these methods may enforce sharp edges or enhance specific features in the reconstructed image by assuming certain smoothness or continuity properties \cite{Dai2007, Aly2005}. While these methods were effective in early applications, they struggled in real-world scenarios due to their reliance on simplified assumptions about image textures and structures, making them less capable of handling variability, noise, and complex patterns found in natural images. Deep Convolutional Neural Networks (CNNs) significantly improved Single and Multiple super-resolution baseline system performances. Dong et al. \cite{Dong2016} revolutionized the field with the SR Convolutional Neural Network (SRCNN), which autonomously learns an end-to-end mapping between LR and HR images. This model significantly outperformed traditional approaches, improving the PSNR by 0.15, 0.17, and 0.13 dB across three different datasets \cite{Dong2016}. Despite their advantages, CNNs face challenges such as spectral bias, where the networks excel at reconstructing smooth, low-frequency features but struggle with high-frequency details like sharp edges and fine textures \cite{Zhang2019}. To address these limitations, researchers proposed deeper and more advanced architectures. For instance, Very Deep SR (VDSR) extended the depth of CNNs to achieve better accuracy \cite{Kim2016VDSR}, while Enhanced Deep SR (EDSR) introduced additional residual blocks for improved feature extraction and HR reconstruction \cite{Kim2016EDSR}. Residual Dense Networks (RDN) further advanced this trend by integrating residual learning with dense connections, enabling more effective capture of fine-grained image details \cite{Zhang2018}.

Next, the Generalized Implicit Neural Representations (GINR) employ spectral graph embeddings to approximate discrete sample locations, allowing models to operate independently of specific coordinate systems \cite{grattarola2022ginr}. Similarly, Higher-Order Implicit Neural Representations (HOIN) use neural tangent kernels (NTK) to enhance feature interactions, effectively addressing spectral bias and improving performance on tasks requiring fine detail reconstruction \cite{chen2024hoin}. The deep generative models followed the trend, and other super resolution generative SRGANs are particularly effective in generating photo-realistic HR images by focusing on perceptual loss, prioritizing image quality as perceived by humans. These models successfully downscaled climate data, improving the resolution of regional precipitation projections \cite{shidqi2023}. Recently, multimodal methods integrating numerical weather prediction models with U-Net architectures and attention mechanisms enhanced temperature forecasts by leveraging spatial and temporal dependencies in the data \cite{Ding2024}.

Vision Transformers (ViTs) have emerged as a promising alternative to CNNs for SR tasks. ViTs excel at modeling long-range dependencies and capturing global context in images by processing image patches through self-attention mechanisms \cite{Dosovitskiy2020}. However, while ViTs outperform CNNs in capturing global patterns, they often struggle with reconstructing high-frequency details, such as textures and edges \cite{bai2022}. To address these shortcomings, hybrid approaches combining ViTs with Fourier-based representations or implicit neural networks have shown potential for improving SR performance. For example, sinusoidal Representation Networks (SIRENs) leverage periodic activation functions to mitigate spectral bias, making them particularly effective for recovering fine details in SR tasks \cite{SIREN}.

These advancements collectively highlight the diverse strategies employed to overcome the inherent challenges of SR tasks, ranging from improving local feature reconstruction to capturing global spatial dependencies. As SR technology continues to evolve, integrating multiple methodologies appears to be the key to achieving state-of-the-art performance across diverse applications.