\section{Related Works}
\label{sec:related_works}
In this section, we first review projection-related PCQA methods, and then discuss related works on viewpoint recommendation.

\subsection{Projection-related PCQA}
Projection-related PCQA methods project 3D point clouds onto a number of 2D planes, and then evaluate the quality of projected images using image quality assessment methods \cite{dumic2018artPCQA}. 
These methods can be divided into classical and deep learning-based PCQA approaches.

%\subsubsection{Classical PCQA}
\textbf{Classical PCQA methods} explore effective, handcrafted feature descriptions for projected images.
Initially, researchers mainly used traditional image processing algorithms, such as Structural Similarity (SSIM) \cite{Tao2009RR-IQA,alex2020SSIM}, Peak Signal-to-Noise Ratio (PSNR), and other indicators, to evaluate the quality of projected images by comparing these indicators.
To improve the effectiveness of features, researchers have also studied different types of feature extraction algorithms and feature combination methods. 
Meynet et al. \cite{meynet220FR-PCQA} obtained good subjective consistency by optimizing the linear combination of geometric and color features.
Yang et al. \cite{yang82020-3d-2d} weighted color texture and depth information on different projected planes to obtain the final quality score.
Zhou et al. \cite{Zhou23rr} obtained salient projection maps through downsampling operations, and then combined content-based similarity and statistical correlation metrics to generate the quality score.
Later, some researchers began to consider that projected images at different positions have different levels of importance. 
Chen et al. \cite{chen9-2021-layer-proj} proposed a full-reference point cloud quality evaluation method based on hierarchical projection, and Wu et al. \cite{wu10-2021-6DoF} proposed a method based on weighted view projection, which assigns corresponding weights to projected images at different positions according to their importance.

%\subsubsection{Deep learning-based PCQA}
\textbf{Deep learning-based PCQA approaches} leverage deep networks to extract intricate features from point clouds, which are more robust than classical PCQA methods.
Nonetheless, they persist in adopting the projection paradigm of traditional methods: by presenting fixed viewpoints to procure projected images of corresponding regions.
Liu et al. \cite{liu12-2021-PQA-net} came up with a deep learning-based no-reference PCQA method called PQA-Net. 
The network parameters are first trained by predicting the types of point cloud distortion, and then joint training is used to predict the quality score.
In their approach, the view space is divided into six areas. The central point of each area is chosen as a fixed viewpoint for obtaining the corresponding projection image.
Tao et al. \cite{tao2021MSFC} projected 3D point clouds onto 2D color projected images and geometric projection images, which employed the same strategy as that of Liu \cite{liu12-2021-PQA-net}, and designed a multi-scale feature fusion network to blindly evaluate visual quality.
Yang et al. \cite{yang13-2022-NR-domationadapt} encoded the projected images of point clouds in different directions into an image, combined them with image datasets, trained the network parameters through domain adaptation methods, and finally successfully predicted the quality score.
Xie et al. \cite{xie2023pmBQA} obtained point cloud quality scores by projecting point clouds into 2D images and fusing multimodal information (texture, normal, depth, and thickness).
Chai et al. \cite{Chai2024} used a degraded-reference branch to measure the distance between complete information and principal component information to characterize the quality state, while the no-reference branch performs multi-scale feature extraction and fusion on the input visual projection.
Finally, a P2IT is proposed to materialize information interaction between planes and points reasonably.
Wang et al. \cite{Wang24eemf} first considered the influence of viewpoint distance and proposed the MOD-PCQA method, which utilizes a three-branch network to extract scale features from different viewpoints, to capture visual features at various granularity levels from fine to coarse.
Zhang et al. \cite{zhang2023mmpcqa} proposed a novel multi-modal learning approach for PCQA, leveraging the advantages of both point cloud and projected image modalities.


Despite the significant advancements achieved by existing projection-related PCQA methods, they all employ a straightforward but content-independent projection strategy, neglecting the distribution of geometric and attribute information of degraded point clouds. 
Therefore, the primary focus of our study is the issue of content-aware projection viewpoint prediction. 

\subsection{Viewpoint Recommendation}

Viewpoint recommendation refers to recommending the optimal viewpoint for users to observe and understand objects or 3D scenes better in different tasks, such as active robot vision \cite{Zengr20cvm} and shape recognition \cite{AbdullahH21}. 
In this section, we provide a brief review of methods for viewpoint recommendation from the following two aspects: quantitative calculation and qualitative analysis.

Quantitative calculations compute values for all viewpoints through explicit metrics.
Following that, they suggest suitable metrics for picking the best one among the candidate viewpoints.
Attneave \cite{attneave1954-visualpercept} argued that the places where the information changes rapidly (i.e., curvature peaks) are the optimality criterion for selecting the optimal viewpoint.
Kamada and Kawai \cite{17Kamada} proposed that a good angle can avoid the degradation of views that project a plane into a line or a line into a point.
Inspired by Kamada and Plemenos' work, Vazquez et al. \cite{20zquez} calculated the entropy using the projected area and number of faces as the criterion to select the optimal viewpoint.

Qualitative analysis is different in that it constructs optimal viewpoint datasets through subjective experiments and then uses deep networks to learn the task's potential optimal criteria.
Marsaglia et al. \cite{24Marsaglia} used subjective tests to build up a dataset containing information about the strengths and weaknesses of all viewpoints to visualize scientific scenes.
He et al. \cite{photo2018He} evaluated each shooting angle subjectively and trained the deep network to effectively evaluate each shooting angle based on the dataset.
Zeng et al. \cite{2020PCNBV} calculated the value of each viewpoint based on the visibility of the model for the reconstruction task offline.
                 
In a word, existing learning-based viewpoint recommendation approaches can select the optimal viewpoint from a set of candidates by understanding the task's inherent needs and establishing evaluation metrics.
However, they all heavily rely on subjective datasets with recommended viewpoints limited to predefined candidate viewpoint sets. These viewpoint recommendation strategies are not applicable to PCQA tasks.
This paper is dedicated to directly generate better viewpoints for given default viewpoints of existing projection-related PCQA methods without the need of a subjective dataset.