\section{ROI-Based Stereo Depth}\label{sec:algorithm}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/Algorithm_2024_07_04.pdf}
    \caption{Illustration of the \projname{} processing pipeline. Object detection is run on the L2 processor and run infrequently; object tracking is run on intermediate frames on the L1 processors.}
    \label{fig:alg_design}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/Distributions_2024_07_10.pdf}
    \caption{Distribution of ROI sizes across various object tracking datasets and object classes.}
    \label{fig:roi_distribution}
\end{figure}

\je{We propose the use of Regions-of-Interest (ROIs) in AR platforms to augment conventional Stereo Depth Algorithms.}
\je{We illustrate this proposed augmented algorithm in Figure ~\ref{fig:alg_design}.}
In \je{many AR} applications, only specific \je{objects in} an image are of interest\je{; bounding boxes around these objects can be used as ROIs. \cite{eyecod}}
Fig.~\ref{fig:roi_distribution} illustrates the typical sizes of bounding boxes across various object classes in %the 
\je{egocentric datasets,} KITTI \cite{kitti2012, kitti2015} and Epic Kitchens \cite{epic_kitchens}. %datasets. 
\je{Typical ROI sizes often multiple orders of magnitude smaller than the full image resolution. }
Unlike classification CNNs, stereo depth models can handle variable-sized ROIs.
This is because they are designed for regression tasks, producing output with the same spatial dimensions as the input images.
With typical ROI sizes often multiple orders of magnitude smaller than the full image resolution, significant processing savings are possible.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{Figures/ROIQuality_2024_11_24.pdf}
    \caption{EPE (left) and 3-pixel error (right) for HITNet \cite{hitnet} evaluated on 'Car' ROIs in the KITTI Object Tracking \cite{kitti2012} dataset, as measured against inference on full frames.}
    \label{fig:alg_quality}
\end{figure}

\je{One concern with this method is the degradation of stereo depth quality incurred by processing only ROIs.}
\je{To assess this concern, we evaluate HITNet \cite{hitnet} on crops from the KITTI dataset \cite{kitti2012}, shown in Figure ~\ref{fig:alg_quality}.}
\ca{We choose this dataset for it's availability of full frame stereo depth and object tracking labels.}
\je{We evaluate the degradation of results from full-frame inference by computing End-Point Error (EPE) and 3-pixel error against the full frame results\footnote{Dataset access and model processing took place at the University of Michigan.}; on each graph, lower errors imply less degradation.}
\je{In general, we find that ROI width is most strongly correlated to ROI degradation, with narrow ROIs with little spatial context suffering more compared to broader ROIs.}
\je{However, the tolerability of this degradation has an application dependence.}
\je{While simple algorithms, such as enforcing a minimum ROI size, can be used to address these challenges; in this work, we explore the ramifications of designing a compute system for the full dynamic range of ROI sizes extracted from these datasets.}

While ROIs can reduce stereo depth processing, \je{finding them} can introduce overhead \je{computational} costs.
Extracting ROIs requires object detection \cite{redmon_yolov3_2018}, which demands comparable MACs and weight storage to stereo depth processing itself \cite{hitnet, tiefenrausch}.
Minimizing the overhead of ROI extraction is critical to reduce the loss in efficiency.
\je{We propose to combat this inefficiency by interleaving expensive object detection with fast and efficient object tracking \cite{asu_fpga}, such as a correlation filter \cite{correlation_filter}.}
\je{Such algorithms have been demonstrated to be efficient on low power platforms \cite{vota}.}
\je{For egocentric tasks, where objects move continuously with respect to the observer, such an approach can accurately track objects with greatly reduced computational cost.}
\je{In this work, we specifically use YOLOv3 \cite{redmon_yolov3_2018} and Correlation Filters \cite{correlation_filter} for object detection and tracking, respectively.}