\section{Background}\label{sec:background}

\subsection{\je{Low Power Algorithms}}
Stereo depth processing consumes significant energy on AR/VR platforms.
For instance, on a Jetson Orin Nano, we measure stereo depth on a 90k pixel crop at 30~FPS consumes 5.6~W of power, or 400~mJ per inference.
% This energy can be explained by examining the complexity of recent stereo depth models, shown in Fig.~\ref{fig:ops_compare}.
% While multiply-accumulate operations decrease in recent models, stereo-depth specific non-parameterized layers have increased in size, raising the floor of the overall computational complexity and energy consumption.
As AR/VR devices employ higher resolution sensors to achieve more immersive experiences, it is anticipated that the computational intensity will escalate even more.

\subsection{Stereo Depth Processing}
Stereo depth has been the focus of many algorithmic works; as of writing, deep learning based approaches achieve the best inference quality. 
StereoNet \cite{stereonet} is an early attempt at an algorithm that can be accelerated on edge hardware in real time, and shares many foundational traits with subsequent networks. 
It uses twin Siamese feature extraction layers to initialize multi-resolution disparity estimates, which are hierarchically refined to produce a final disparity estimate. 
HITNet \cite{hitnet} iterates on this algorithm structure by introducing tile based iterative refinement, and local slant predictions alongside disparity estimation, to improve inference quality. 
This network also performs disparity processing without explicitly evaluating a 3D cost volume. 
More recently, the monocular depth network Tiefenrausch and it's stereo depth cousin Argos \cite{tiefenrausch} have been proposed using building blocks inspired by MobileNetv2 \cite{mobilenetv2}, and trained on 8-bit quantized weights for highly efficient inference.

% One strategy to reduce computational load \je{of ML workloads} is to exploit Regions of Interest (ROIs) \je{\cite{eyecod}}.
% In % typical stereo depth, 
% \je{many AR} applications, only specific %sections of 
% \je{objects in} an image are of interest\je{; bounding boxes around these objects can be used as ROIs.}
% Fig.~\ref{fig:roi_distribution} illustrates the typical sizes of bounding boxes across various object classes in %the 
% \je{egocentric datasets,} KITTI \cite{kitti2012, kitti2015} and Epic Kitchens \cite{epic_kitchens}. %datasets. 
% \je{Typical ROI sizes often multiple orders of magnitude smaller than the full image resolution. }
% Unlike classification CNNs, stereo depth models can handle variable-sized ROIs.
% This is because they are designed for regression tasks, producing output with the same spatial dimensions as the input images.
% % With typical ROI sizes often multiple orders of magnitude smaller than the full image resolution, significant processing savings are possible.
% While this approach can degrade the quality of resulting depth maps, we find that this degradation is acceptable for certain tasks, particularly in Augmented Reality where limited portions of sensor data are of interest\je{; thus, significant processing savings are possible with this approach.}

% While ROIs can reduce stereo depth processing, %their extraction
% \je{finding them} can introduce overhead costs.
% Extracting ROIs requires object detection \cite{redmon_yolov3_2018}, which demands comparable MACs and weight storage to stereo depth processing itself \cite{hitnet, tiefenrausch}.
% Minimizing the overhead of ROI extraction is critical to reduce the loss in efficiency.
% \je{One approach to combat this inefficiency is to interleave expensive object detection with fast and efficient object tracking \cite{asu_fpga}, such as a correlation filter \cite{correlation_filter}.}
% \je{Such algorithms have been demonstrated to be efficient on low power platforms \cite{vota}.}
% \je{For egocentric tasks, where objects move continuously with respect to the observer, such an approach can accurately track objects with greatly reduced computational cost.}

\subsection{\je{AR Systems and Compute}}
\je{AR platforms incorporate many system and architectural techniques to achieve low power, low latency, and tight form factors.}
\je{Typical AR Systems on Chip (SoCs), such as the Qualcomm Snapdragon \cite{qualcomm_soc}, feature heterogeneously integrated accelerator, CPU, GPU, and memory units for diverse tasks.}
\je{Near-sensor computing \cite{eyecod, ansa, gomez_distributed_2022, sony_coprocessor, siracusa} is also commonly proposed as an energy-efficient computing technique for AR.}
\je{This is because near-sensor processing can be used to reduce raw sensor data sizes, saving expensive communication energy over MIPI or other protocols.}

\je{Several accelerator designs have been proposed for AR SoCs.}
\je{These accelerators must enable efficient inference at low batch sizes, while providing real-time latency, and small core areas to satisfy the stringent space limitations of AR platforms.}
\ca{For this work, we use a baseline real-time throughput and latency requirement of 30FPS, which is common for off-the-shelf image sensors and applications.}
\je{In particular, we consider the architecture proposed in ANSA \cite{ansa}, which enables efficient real-time processing with Vector-Matrix Multiplier (VMM) based compute units.}
\je{This architecture is also organized hierarchically and with parameterized scale, which enables design space exploration.}

\je{While this accelerator design works well for classification-based CNNs, stereo depth networks present new compute morphologies which must be addressed.}
\je{Modern stereo-depth models increasingly utilize non-parameterized special layer types, as illustrated in Figure ~\ref{fig:ops_compare}.}
\je{These operations cannot leverage VMM parallelism, and thus present a potential latency bottleneck.}
\je{The large network weights in these networks also make DRAM I/O a potential bottleneck when storing weights in off-accelerator DRAMs.}

% --- JACK --- My goal with this section is to establish (1) what typical AR platform SoCs look like (heterogeneous accelerators and some local memory) and (2) to establish on or near-sensor co-processors as a thing that AR platforms are either actively doing, or are interested in doing. This way, when I say we will be operating in this framework, it is coming from somewhere.
% I can also use this section to establish the drivers for latency, power, and form factor constraints.

% \begin{figure*}
%     \centering
%     \includegraphics[width=.8\linewidth]{Figures/System_2024_06_03.pdf}
%     \caption{\projname{} system design.}
%     \label{fig:steroi_compare}
% \end{figure*}

% \textbf{\projname{} System Design}:
% The system-level design of \projname{} is depicted in Fig.~\ref{fig:steroi_compare}, while the processing pipeline is illustrated in Fig.~\ref{fig:alg_design}.
% \projname{} uses a detect-and-track strategy for energy-efficient ROI extraction.
% Since the compute complexity of object tracking is significantly less than object detection, \projname{} employs only periodic object detection to detect the objects (ROIs) and uses lightweight object tracking to efficiently follow these ROIs.
% The large difference in computing demands between object tracking and object detection means that we can achieve energy savings even when object detection is run frequently.
% \projname{} incorporates a small level-1 (L1) processor co-packaged with each image sensor in the AR/VR system for efficient object tracking using correlation filters \cite{correlation_filter, vota}. 
% This approach significantly reduces the need for costly object detection, which is performed only occasionally using the level-2 (L2) processor.
% Aside from occasional object detection, the L2 processor is responsible for ROI-based stereo depth processing, which is the most significant challenge.

% \subsection{Computing on Dynamic ROIs}
% The ROI-based stereo depth processing presents a demanding computational workload due to the variability in ROI sizes.
% A highly flexible system is required to accommodate this variability.
% However, mapping this dynamic workload, with its continuous range of ROI sizes, onto a flexible system to achieve optimal energy savings while satisfying the latency and area constraints of AR/VR systems is a significant challenge.
% Traditionally, a static design space exploration can identify the optimal mapping. 
% However, in our application, the ROI and by extension the workload change in runtime; and runtime design space exploration would be impractical.
% Without an optimal mapping strategy, it would be impossible to realize the energy efficiency potential offered by this ROI-based approach.

% \begin{figure}
%     \centering
%     \includegraphics[width=.9\linewidth]{Figures/Algorithm_2024_07_04.pdf}
%     \caption{Illustration of the \projname{} processing pipeline. Object detection is run on the L2 processor and run infrequently; object tracking is run on intermediate frames on the L1 processors.}
%     \label{fig:alg_design}
% \end{figure}

% \textbf{\projname{} L2 Processor Mapping}:
% The \projname{} L2 processor is our main focus, as it is responsible for the challenging ROI-based stereo depth processing.
% The L2 processor is designed to support variable-size ROI-based stereo depth processing
% (Section~\ref{sec:architecture}).
% Importantly, the L2 processor is co-designed with workload mapping using an efficient design space exploration (Section ~\ref{sec:mapping}).
% This approach involves three phases: indexing the hyperdimensional mapping space using a set of axes, ROI binning to facilitate runtime mapping, and iterations of system parameter sweeps.
% This approach enables a complete system-mapping co-design that achieves optimal energy efficiency.

\subsection{\je{Mapping and Dynamic ROIs}}
\je{A final design challenge lies in mapping algorithms running on dynamic ROIs to hardware.}
\je{As established in \cite{ansa}, mapping networks to compute can significantly effect energy efficiency and latency.}
\je{However, processing runtime-dynamic ROIs complicates the generation of these mappings.}
\je{As the range of ROI sizes to be supported is very large, storing a mapping for every possible size is impractical, and therefore generating these mappings entirely offline is imfeasible.}
\je{Simultaneously, the modeling and optimization needed to generate these mappings also prohibits entirely online mapping.}
\je{An intermediate solution is necessary to realize ROI-based stereo depth processing.}

% \je{Mapping presents a further complication to design-space exploration and hardware optimization.}
% \je{In particular, conventional mapping assumes a static compute architecture for which to optimize an algorithm for.}
% \je{However, when searching for an optimal architecture for this application, it is impractical to simply sweep a range of possible processor designs, due to the size of this space.}
% \je{An alternate approach would be to reduce the size of the processor design space by extracting some architecture design parameters from mappings, and jointly optimizing the mapping for the accelerator's static and dynamic energy.}
% --- JACK --- A possible solution for me to do design space exploration here would have been to just iterate over possible SRAM allocations (e.g. do a grid search of vector sram in {1kB, 4kB, 16kB, ...}, and so on).
% I didn't do this because I didn't have a sense of what reasonable amounts of SRAM would be, and I wanted to get that from the mappings.
% So instead, I extracted the system SRAM from the mappings, and co-optimized the mapping dynamic and static energy.
% I'm hesitant to mention this here, because I don't know if there's a big problem with doing it the other way, or if I just avoided it for stupid reasons.
% But the long and the short of it is that I did it to reduce the number of design space loops I iterated over.


% --- JACK --- I plan to move the discussion of the SteROI system to the beginning of Section 3. I'll be careful to specify when I'm talking about the system vs. when I'm talking about the L2 processor (SoC Accelerator) design.
% I'll also move my discussion of my binned mapping to section 4 (and optimization) to section 4.