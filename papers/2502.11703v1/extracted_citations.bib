@article{GPT4_medical,
  title={Capabilities of gpt-4 on medical challenge problems},
  author={Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  journal={arXiv preprint arXiv:2303.13375},
  year={2023}
}

@misc{Hou,
      title={MSDiagnosis: A Benchmark for Evaluating Large Language Models in Multi-Step Clinical Diagnosis}, 
      author={Ruihui Hou and Shencheng Chen and Yongqi Fan and Guangya Yu and Lifeng Zhu and Jing Sun and Jingping Liu and Tong Ruan},
      year={2024},
      eprint={2408.10039},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.10039}, 
}

@article{LLMrule1,
  title={Failures pave the way: Enhancing large language models through tuning-free rule accumulation},
  author={Yang, Zeyuan and Li, Peng and Liu, Yang},
  journal={arXiv preprint arXiv:2310.15746},
  year={2023}
}

@inproceedings{LLMrule2,
    title = "{E}xp{N}ote: Black-box Large Language Models are better Task Solvers with Experience Notebook",
    author = "Sun, Wangtao  and
      Yu, Xuanqing  and
      He, Shizhu  and
      Zhao, Jun  and
      Liu, Kang",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.1034/",
    doi = "10.18653/v1/2023.findings-emnlp.1034",
    pages = "15470--15481",
    abstract = "Black-box Large Language Models (LLMs) have shown great power in solving various tasks and are considered general problem solvers. However, LLMs still fail in many specific tasks although understand the task instruction. In this paper, we focus on the problem of boosting the ability of black-box LLMs to solve downstream tasks. We propose ExpNote, an automated framework to help LLMs better adapt to unfamiliar tasks through reflecting and noting experiences from training data and retrieving them from external memory during testing. We evaluate ExpNote on multiple tasks and the experimental results demonstrate that the proposed method significantly improves the performance of black-box LLMs. The data and code are available at https://github.com/forangel2014/ExpNote."
}

@article{LLMrule3,
  title={Can LLMs Follow Simple Rules?},
  author={Mu, Norman and Chen, Sarah and Wang, Zifan and Chen, Sizhe and Karamardian, David and Aljeraisy, Lulwa and Alomair, Basel and Hendrycks, Dan and Wagner, David},
  journal={arXiv preprint arXiv:2311.04235},
  year={2023}
}

@inproceedings{M-QALM,
    title = "{M}-{QALM}: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    author = "Subramanian, Anand  and
      Schlegel, Viktor  and
      Ramesh Kashyap, Abhinav  and
      Nguyen, Thanh-Tung  and
      Dwivedi, Vijay Prakash  and
      Winkler, Stefan",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.238/",
    doi = "10.18653/v1/2024.findings-acl.238",
    pages = "4002--4042",
    abstract = "There is vivid research on adapting Large Language Models (LLMs) to perform a variety of tasks in high-stakes domains such as healthcare. Despite their popularity, there is a lack of understanding of the extent and contributing factors that allow LLMs to recall relevant knowledge and combine it with presented information in the clinical and biomedical domain: a fundamental pre-requisite for success on down-stream tasks.Addressing this gap, we use Multiple Choice and Abstractive Question Answering to conduct a large-scale empirical study on 22 datasets in three generalist and three specialist biomedical sub-domains. Our multifaceted analysis of the performance of 15 LLMs, further broken down by sub-domain, source of knowledge and model architecture, uncovers success factors such as instruction tuning that lead to improved recall and comprehension. We further show that while recently proposed domain-adapted models may lack adequate knowledge, directly fine-tuning on our collected medical knowledge datasets shows encouraging results, even generalising to unseen specialist sub-domains. We complement the quantitative results with a skill-oriented manual error analysis, which reveals a significant gap between the models' capabilities to simply recall necessary knowledge and to integrate it with the presented context.To foster research and collaboration in this field we share M-QALM, our resources, standardised methodology, and evaluation results, with the research community to facilitate further advancements in clinical knowledge representation learning within language models."
}

@article{NC,
  title={Towards building multilingual language model for medicine},
  author={Qiu, Pengcheng and Wu, Chaoyi and Zhang, Xiaoman and Lin, Weixiong and Wang, Haicheng and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={8384},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{ToT,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{apollo1,
      title={Apollo: A Lightweight Multilingual Medical LLM towards Democratizing Medical AI to 6B People}, 
      author={Xidong Wang and Nuo Chen and Junyin Chen and Yidong Wang and Guorui Zhen and Chunxian Zhang and Xiangbo Wu and Yan Hu and Anningzhe Gao and Xiang Wan and Haizhou Li and Benyou Wang},
      year={2024},
      eprint={2403.03640},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.03640}, 
}

@inproceedings{chain-of-logic,
    title = "Chain of Logic: Rule-Based Reasoning with Large Language Models",
    author = "Servantez, Sergio  and
      Barrow, Joe  and
      Hammond, Kristian  and
      Jain, Rajiv",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.159/",
    doi = "10.18653/v1/2024.findings-acl.159",
    pages = "2721--2733",
    abstract = "Rule-based reasoning, a fundamental type of legal reasoning, enables us to draw conclusions by accurately applying a rule to a set of facts. We explore causal language models as rule-based reasoners, specifically with respect to compositional rules - rules consisting of multiple elements which form a complex logical expression. Reasoning about compositional rules is challenging because it requires multiple reasoning steps, and attending to the logical relationships between elements. We introduce a new prompting method, Chain of Logic, which elicits rule-based reasoning through decomposition (solving elements as independent threads of logic), and recomposition (recombining these sub-answers to resolve the underlying logical expression). This method was inspired by the IRAC (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers. We evaluate chain of logic across eight rule-based reasoning tasks involving three distinct compositional rules from the LegalBench benchmark and demonstrate it consistently outperforms other prompting methods, including chain of thought and self-ask, using open-source and commercial language models."
}

@article{cot,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{factdecomp,
  title={Assessing the Limitations of Large Language Models in Clinical Fact Decomposition},
  author={Munnangi, Monica and Swaminathan, Akshay and Fries, Jason Alan and Jindal, Jenelle and Narayanan, Sanjana and Lopez, Ivan and Tu, Lucia and Chung, Philip and Omiye, Jesutofunmi A and Kashyap, Mehr and others},
  journal={arXiv preprint arXiv:2412.12422},
  year={2024}
}

@inproceedings{li2024fundamental,
  title={Fundamental Capabilities of Large Language Models and their Applications in Domain Scenarios: A Survey},
  author={Li, Jiawei and Yang, Yizhe and Bai, Yu and Zhou, Xiaofeng and Li, Yinghao and Sun, Huashan and Liu, Yuhang and Si, Xingpeng and Ye, Yuhao and Wu, Yixiao and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={11116--11141},
  year={2024}
}

@article{medcal,
  title={Medcalc-bench: Evaluating large language models for medical calculations},
  author={Khandekar, Nikhil and Jin, Qiao and Xiong, Guangzhi and Dunn, Soren and Applebaum, Serina and Anwar, Zain and Sarfo-Gyamfi, Maame and Safranek, Conrad and Anwar, Abid and Zhang, Andrew and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={84730--84745},
  year={2025}
}

@article{ruleapplication,
  title={Symbolic Working Memory Enhances Language Models for Complex Rule Application},
  author={Wang, Siyuan and Wei, Zhongyu and Choi, Yejin and Ren, Xiang},
  journal={arXiv preprint arXiv:2408.13654},
  year={2024}
}

@inproceedings{rulestress,
    title = "Can {LLM}s Reason in the Wild with Programs?",
    author = "Yang, Yuan  and
      Xiong, Siheng  and
      Payani, Ali  and
      Shareghi, Ehsan  and
      Fekri, Faramarz",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.573/",
    doi = "10.18653/v1/2024.findings-emnlp.573",
    pages = "9806--9829",
    abstract = "Large Language Models (LLMs) have shown superior capability to solve reasoning problems with programs. While being a promising direction, most of such frameworks are trained and evaluated in settings with a prior knowledge of task requirements. However, as LLMs become more capable, it is necessary to assess their reasoning abilities in more realistic scenarios where many real-world problems are open-ended with ambiguous scope, and often require multiple formalisms to solve. To investigate this, we introduce the task of reasoning in the wild, where an LLM is tasked to solve a reasoning problem of unknown type by identifying the sub-problems and their corresponding formalisms, and writing a program to solve each sub-problem, guided by a tactic. We create a large tactic-guided trajectory dataset containing detailed solutions to a diverse set of reasoning problems, ranging from well-defined single-form reasoning (e.g., math, logic), to ambiguous and hybrid ones (e.g., commonsense, combined math and logic). This allows us to test various aspects of LLMs reasoning at the fine-grained level such as the selection and execution of tactics, and the tendency to take undesired shortcuts. In experiments, we highlight that existing LLMs fail significantly on problems with ambiguous and mixed scope, revealing critical limitations and overfitting issues (e.g. accuracy on GSM8K drops by at least 50{\%}). We further show the potential of finetuning a local LLM on the tactic-guided trajectories in achieving better performance. Project repo is available at https://github.com/gblackout/Reason-in-the-Wild."
}

@inproceedings{rulesurvey,
  title={Beyond Instruction Following: Evaluating Inferential Rule Following of Large Language Models},
  author={Wangtao Sun and Chenxiang Zhang and Xueyou Zhang and Xuanqing Yu and Ziyang Huang and Pei Chen and Haotian Xu and Shizhu He and Jun Zhao and Kang Liu},
  year={2024},
}

@article{verifact,
  title={VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records},
  author={Chung, Philip and Swaminathan, Akshay and Goodell, Alex J and Kim, Yeasul and Reincke, S Momsen and Han, Lichy and Deverett, Ben and Sadeghi, Mohammad Amin and Ariss, Abdel-Badih and Ghanem, Marc and others},
  journal={arXiv preprint arXiv:2501.16672},
  year={2025}
}

