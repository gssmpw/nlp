% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").


@article{gpt4o,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{faithful,
    title = "Faithful Logical Reasoning via Symbolic Chain-of-Thought",
    author = "Xu, Jundong  and
      Fei, Hao  and
      Pan, Liangming  and
      Liu, Qian  and
      Lee, Mong-Li  and
      Hsu, Wynne",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.720/",
    doi = "10.18653/v1/2024.acl-long.720",
    pages = "13326--13365",
    abstract = "While the recent Chain-of-Thought (CoT) technique enhances the reasoning ability of large language models (LLMs) with the theory of mind, it might still struggle in handling logical reasoning that relies much on symbolic expressions and rigid deducing rules. To strengthen the logical reasoning capability of LLMs, we propose a novel Symbolic Chain-of-Thought, namely SymbCoT, a fully LLM-based framework that integrates symbolic expressions and logic rules with CoT prompting. Technically, building upon an LLM, SymbCoT 1) first translates the natural language context into the symbolic format, and then 2) derives a step-by-step plan to solve the problem with symbolic logical rules, 3) followed by a verifier to check the translation and reasoning chain. Via thorough evaluations on 5 standard datasets with both First-Order Logic and Constraint Optimization symbolic expressions, SymbCoT shows striking improvements over the CoT method consistently, meanwhile refreshing the current state-of-the-art performances. We further demonstrate that our system advances in more faithful, flexible, and explainable logical reasoning. To our knowledge, this is the first attempt at combining symbolic expressions and rules into CoT for logical reasoning with LLMs. Code is open at https://github.com/Aiden0526/SymbCoT."
}

@article{chatglm,
  title={ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools},
  author={GLM, Team and Zeng, Aohan and Xu, Bin and Wang, Bowen and Zhang, Chenhui and Yin, Da and Rojas, Diego and Feng, Guanyu and Zhao, Hanlin and Lai, Hanyu and others},
  journal={arXiv preprint arXiv:2406.12793},
  year={2024}
}
@article{qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}
@article{note_generation,
  title={Large language models in health care: Development, applications, and challenges},
  author={Yang, Rui and Tan, Ting Fang and Lu, Wei and Thirunavukarasu, Arun James and Ting, Daniel Shu Wei and Liu, Nan},
  journal={Health Care Science},
  volume={2},
  number={4},
  pages={255--263},
  year={2023},
  publisher={Wiley Online Library}
}

@article{decision,
  title={Integrating Physician Diagnostic Logic into Large Language Models: Preference Learning from Process Feedback},
  author={Dou, Chengfeng and Jin, Zhi and Jiao, Wenpin and Zhao, Haiyan and Zhao, Yongqiang and Tao, Zhenwei},
  journal={arXiv preprint arXiv:2401.05695},
  year={2024}
}

@article{assessment,
  title={Empowering Large Language Models for Automated Clinical Assessment with Generation-Augmented Retrieval and Hierarchical Chain-of-Thought},
  author={GU, ZHANZHONG and Jia, Wenjing and Piccardi, Massimo and Yu, Ping},
  journal={Available at SSRN 4835586},
    year={2024}
}
@article{tradition_nlp,
  title={Natural language processing for assessing quality indicators in free-text colonoscopy and pathology reports: Development and usability study},
  author={Bae, Jung Ho and Han, Hyun Wook and Yang, Sun Young and Song, Gyuseon and Sa, Soonok and Chung, Goh Eun and Seo, Ji Yeon and Jin, Eun Hyo and Kim, Heecheon and An, DongUk},
  journal={JMIR Medical Informatics},
  volume={10},
  number={4},
  pages={e35257},
  year={2022},
  publisher={JMIR Publications Toronto, Canada}
}
@article{MQCI,
  title={Quality evaluation and indicator comparison in health care},
  author={{\O}vretveit, John},
  journal={The International journal of health planning and management},
  volume={16},
  number={3},
  pages={229--241},
  year={2001},
  publisher={Wiley Online Library}
}
@article{example,
  title={Providing data for serrated polyp detection rate benchmarks: an analysis of the New Hampshire Colonoscopy Registry},
  author={Anderson, Joseph C and Butterly, Lynn F and Weiss, Julia E and Robinson, Christina M},
  journal={Gastrointestinal endoscopy},
  volume={85},
  number={6},
  pages={1188--1194},
  year={2017},
  publisher={Elsevier}
}
@article{wang2018clinical,
  title={Clinical information extraction applications: a literature review},
  author={Wang, Yanshan and Wang, Liwei and Rastegar-Mojarad, Majid and Moon, Sungrim and Shen, Feichen and Afzal, Naveed and Liu, Sijia and Zeng, Yuqun and Mehrabi, Saeed and Sohn, Sunghwan and others},
  journal={Journal of biomedical informatics},
  volume={77},
  pages={34--49},
  year={2018},
  publisher={Elsevier}
}

@article{rule1,
  title={Detecting unplanned care from clinician notes in electronic health records},
  author={Tamang, Suzanne and Patel, Manali I and Blayney, Douglas W and Kuznetsov, Julie and Finlayson, Samuel G and Vetteth, Yohan and Shah, Nigam},
  journal={Journal of Oncology Practice},
  volume={11},
  number={3},
  pages={e313--e319},
  year={2015},
  publisher={American Society of Clinical Oncology Alexandria, VA}
}
@article{rule2,
  title={A data-driven approach for quality assessment of radiologic interpretations},
  author={Hsu, William and Han, Simon X and Arnold, Corey W and Bui, Alex AT and Enzmann, Dieter R},
  journal={Journal of the American Medical Informatics Association},
  volume={23},
  number={e1},
  pages={e152--e156},
  year={2016},
  publisher={Oxford University Press}
}

@article{inefficient,
  title={Detection rates of premalignant polyps during screening colonoscopy: time to revise quality standards?},
  author={Ross, William A and Thirumurthi, Selvi and Lynch, Patrick M and Rashid, Asif and Pande, Mala and Shafi, Mehnaz A and Lee, Jeffrey H and Raju, Gottumukkala S},
  journal={Gastrointestinal endoscopy},
  volume={81},
  number={3},
  pages={567--574},
  year={2015},
  publisher={Elsevier}
}
@article{nlp1,
  title={Accurate identification of colonoscopy quality and polyp findings using natural language processing},
  author={Lee, Jeffrey K and Jensen, Christopher D and Levin, Theodore R and Zauber, Ann G and Doubeni, Chyke A and Zhao, Wei K and Corley, Douglas A},
  journal={Journal of clinical gastroenterology},
  volume={53},
  number={1},
  pages={e25--e30},
  year={2019},
  publisher={LWW}
}
@article{lack,
  title={Natural language processing as an alternative to manual reporting of colonoscopy quality metrics},
  author={Raju, Gottumukkala S and Lum, Phillip J and Slack, Rebecca S and Thirumurthi, Selvi and Lynch, Patrick M and Miller, Ethan and Weston, Brian R and Davila, Marta L and Bhutani, Manoop S and Shafi, Mehnaz A and others},
  journal={Gastrointestinal endoscopy},
  volume={82},
  number={3},
  pages={512--519},
  year={2015},
  publisher={Elsevier}
}
@article{challenge,
  title={A Comprehensive Survey on Evaluating Large Language Model Applications in the Medical Industry},
  author={Huang, Yining and Tang, Keke and Chen, Meilian},
  journal={arXiv preprint arXiv:2404.15777},
  year={2024}
}


@article{cot,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@inproceedings{
cot-sc,
title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=1PL1NIMMrw}
}
@inproceedings{chain-of-logic,
    title = "Chain of Logic: Rule-Based Reasoning with Large Language Models",
    author = "Servantez, Sergio  and
      Barrow, Joe  and
      Hammond, Kristian  and
      Jain, Rajiv",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.159/",
    doi = "10.18653/v1/2024.findings-acl.159",
    pages = "2721--2733",
    abstract = "Rule-based reasoning, a fundamental type of legal reasoning, enables us to draw conclusions by accurately applying a rule to a set of facts. We explore causal language models as rule-based reasoners, specifically with respect to compositional rules - rules consisting of multiple elements which form a complex logical expression. Reasoning about compositional rules is challenging because it requires multiple reasoning steps, and attending to the logical relationships between elements. We introduce a new prompting method, Chain of Logic, which elicits rule-based reasoning through decomposition (solving elements as independent threads of logic), and recomposition (recombining these sub-answers to resolve the underlying logical expression). This method was inspired by the IRAC (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers. We evaluate chain of logic across eight rule-based reasoning tasks involving three distinct compositional rules from the LegalBench benchmark and demonstrate it consistently outperforms other prompting methods, including chain of thought and self-ask, using open-source and commercial language models."
}
@article{zeroshotcot,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}
@inproceedings{plan,
    title = "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models",
    author = "Wang, Lei  and
      Xu, Wanyu  and
      Lan, Yihuai  and
      Hu, Zhiqiang  and
      Lan, Yunshi  and
      Lee, Roy Ka-Wei  and
      Lim, Ee-Peng",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.147/",
    doi = "10.18653/v1/2023.acl-long.147",
    pages = "2609--2634",
    abstract = "Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, Few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual efforts, Zero-shot-CoT concatenates the target problem statement with {\textquotedblleft}\textit{Let`s think step by step}{\textquotedblright} as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors. To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend PS prompting with more detailed instructions and derive PS+ prompting. We evaluate our proposed prompting strategy on ten datasets across three reasoning problems. The experimental results over GPT-3 show that our proposed zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets by a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought Prompting, and has comparable performance with 8-shot CoT prompting on the math reasoning problem. The code can be found at \url{https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting}."
}
@article{reasoningsurvey,
  title={LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models},
  author={Zhang, Yadong and Mao, Shaoguang and Ge, Tao and Wang, Xun and de Wynter, Adrian and Xia, Yan and Wu, Wenshan and Song, Ting and Lan, Man and Wei, Furu},
  journal={arXiv preprint arXiv:2404.01230},
  year={2024}
}
@inproceedings{chainoflogic,
  title={Chain of Logic: Rule-Based Reasoning with Large Language Models},
  author={Sergio Servantez and Joe Barrow and Kristian Hammond and R. Jain},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024},
}
@inproceedings{rulesurvey,
  title={Beyond Instruction Following: Evaluating Inferential Rule Following of Large Language Models},
  author={Wangtao Sun and Chenxiang Zhang and Xueyou Zhang and Xuanqing Yu and Ziyang Huang and Pei Chen and Haotian Xu and Shizhu He and Jun Zhao and Kang Liu},
  year={2024},
}
@inproceedings{rulestress,
    title = "Can {LLM}s Reason in the Wild with Programs?",
    author = "Yang, Yuan  and
      Xiong, Siheng  and
      Payani, Ali  and
      Shareghi, Ehsan  and
      Fekri, Faramarz",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.573/",
    doi = "10.18653/v1/2024.findings-emnlp.573",
    pages = "9806--9829",
    abstract = "Large Language Models (LLMs) have shown superior capability to solve reasoning problems with programs. While being a promising direction, most of such frameworks are trained and evaluated in settings with a prior knowledge of task requirements. However, as LLMs become more capable, it is necessary to assess their reasoning abilities in more realistic scenarios where many real-world problems are open-ended with ambiguous scope, and often require multiple formalisms to solve. To investigate this, we introduce the task of reasoning in the wild, where an LLM is tasked to solve a reasoning problem of unknown type by identifying the sub-problems and their corresponding formalisms, and writing a program to solve each sub-problem, guided by a tactic. We create a large tactic-guided trajectory dataset containing detailed solutions to a diverse set of reasoning problems, ranging from well-defined single-form reasoning (e.g., math, logic), to ambiguous and hybrid ones (e.g., commonsense, combined math and logic). This allows us to test various aspects of LLMs reasoning at the fine-grained level such as the selection and execution of tactics, and the tendency to take undesired shortcuts. In experiments, we highlight that existing LLMs fail significantly on problems with ambiguous and mixed scope, revealing critical limitations and overfitting issues (e.g. accuracy on GSM8K drops by at least 50{\%}). We further show the potential of finetuning a local LLM on the tactic-guided trajectories in achieving better performance. Project repo is available at https://github.com/gblackout/Reason-in-the-Wild."
}
@article{llama3,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@article{internlm2,
  title={Internlm2 technical report},
  author={Cai, Zheng and Cao, Maosong and Chen, Haojiong and Chen, Kai and Chen, Keyu and Chen, Xin and Chen, Xun and Chen, Zehui and Chen, Zhi and Chu, Pei and others},
  journal={arXiv preprint arXiv:2403.17297},
  year={2024}
}
@article{NC,
  title={Towards building multilingual language model for medicine},
  author={Qiu, Pengcheng and Wu, Chaoyi and Zhang, Xiaoman and Lin, Weixiong and Wang, Haicheng and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={8384},
  year={2024},
  publisher={Nature Publishing Group UK London}
}
@article{huatuogpt,
  title={Huatuogpt-ii, one-stage training for medical adaption of llms},
  author={Chen, Junying and Wang, Xidong and Ji, Ke and Gao, Anningzhe and Jiang, Feng and Chen, Shunian and Zhang, Hongbo and Song, Dingjie and Xie, Wenya and Kong, Chuyi and others},
  journal={arXiv preprint arXiv:2311.09774},
  year={2023}
}
@inproceedings{
apollo,
title={Efficiently Democratizing Medical {LLM}s for 50 Languages via a Mixture of Language Family Experts},
author={Guorui Zheng and Xidong Wang and Juhao Liang and Nuo Chen and Yuping Zheng and Benyou Wang},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=JSB171dSUU}
}
@article{GPT4_medical,
  title={Capabilities of gpt-4 on medical challenge problems},
  author={Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  journal={arXiv preprint arXiv:2303.13375},
  year={2023}
}
@article{least2most,
  title={Least-to-most prompting enables complex reasoning in large language models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
  journal={arXiv preprint arXiv:2205.10625},
  year={2022}
}
@article{medcal,
  title={Medcalc-bench: Evaluating large language models for medical calculations},
  author={Khandekar, Nikhil and Jin, Qiao and Xiong, Guangzhi and Dunn, Soren and Applebaum, Serina and Anwar, Zain and Sarfo-Gyamfi, Maame and Safranek, Conrad and Anwar, Abid and Zhang, Andrew and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={84730--84745},
  year={2025}
}
@article{NLsurvey,
  title={Natural language reasoning, a survey},
  author={Yu, Fei and Zhang, Hongbo and Tiwari, Prayag and Wang, Benyou},
  journal={ACM Computing Surveys},
  volume={56},
  number={12},
  pages={1--39},
  year={2024},
}
@inproceedings{logicbench,
  title={LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models},
  author={Mihir Parmar and Nisarg Patel and Neeraj Varshney and Mutsumi Nakamura and Man Luo and Santosh Mashetty and Arindam Mitra and Chitta Baral},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024},
}
@article{legalbench,
  title={Legalbench: A collaboratively built benchmark for measuring legal reasoning in large language models},
  author={Guha, Neel and Nyarko, Julian and Ho, Daniel and R{\'e}, Christopher and Chilton, Adam and Chohlas-Wood, Alex and Peters, Austin and Waldon, Brandon and Rockmore, Daniel and Zambrano, Diego and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@misc{apollo1,
      title={Apollo: A Lightweight Multilingual Medical LLM towards Democratizing Medical AI to 6B People}, 
      author={Xidong Wang and Nuo Chen and Junyin Chen and Yidong Wang and Guorui Zhen and Chunxian Zhang and Xiangbo Wu and Yan Hu and Anningzhe Gao and Xiang Wan and Haizhou Li and Benyou Wang},
      year={2024},
      eprint={2403.03640},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.03640}, 
}
@article{minicpm,
  title={MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies},
  author={Shengding Hu and Yuge Tu and Xu Han and Chaoqun He and Ganqu Cui and Xiang Long and Zhi Zheng and Yewei Fang and Yuxiang Huang and Weilin Zhao and Xinrong Zhang and Zhen Leng Thai and Kaihuo Zhang and Chongyi Wang and Yuan Yao and Chenyang Zhao and Jie Zhou and Jie Cai and Zhongwu Zhai and Ning Ding and Chaochao Jia and Guoyang Zeng and Dahai Li and Zhiyuan Liu and Maosong Sun},
journal={arXiv preprint arXiv:2404.06395},
year={2024}   
}
@inproceedings{M-QALM,
    title = "{M}-{QALM}: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering",
    author = "Subramanian, Anand  and
      Schlegel, Viktor  and
      Ramesh Kashyap, Abhinav  and
      Nguyen, Thanh-Tung  and
      Dwivedi, Vijay Prakash  and
      Winkler, Stefan",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.238/",
    doi = "10.18653/v1/2024.findings-acl.238",
    pages = "4002--4042",
    abstract = "There is vivid research on adapting Large Language Models (LLMs) to perform a variety of tasks in high-stakes domains such as healthcare. Despite their popularity, there is a lack of understanding of the extent and contributing factors that allow LLMs to recall relevant knowledge and combine it with presented information in the clinical and biomedical domain: a fundamental pre-requisite for success on down-stream tasks.Addressing this gap, we use Multiple Choice and Abstractive Question Answering to conduct a large-scale empirical study on 22 datasets in three generalist and three specialist biomedical sub-domains. Our multifaceted analysis of the performance of 15 LLMs, further broken down by sub-domain, source of knowledge and model architecture, uncovers success factors such as instruction tuning that lead to improved recall and comprehension. We further show that while recently proposed domain-adapted models may lack adequate knowledge, directly fine-tuning on our collected medical knowledge datasets shows encouraging results, even generalising to unseen specialist sub-domains. We complement the quantitative results with a skill-oriented manual error analysis, which reveals a significant gap between the models' capabilities to simply recall necessary knowledge and to integrate it with the presented context.To foster research and collaboration in this field we share M-QALM, our resources, standardised methodology, and evaluation results, with the research community to facilitate further advancements in clinical knowledge representation learning within language models."
}
@article{ruleapplication,
  title={Symbolic Working Memory Enhances Language Models for Complex Rule Application},
  author={Wang, Siyuan and Wei, Zhongyu and Choi, Yejin and Ren, Xiang},
  journal={arXiv preprint arXiv:2408.13654},
  year={2024}
}
@article{ToT,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{climedbench,
    title = "{C}li{M}ed{B}ench: A Large-Scale {C}hinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios",
    author = "Ouyang, Zetian  and
      Qiu, Yishuai  and
      Wang, Linlin  and
      De Melo, Gerard  and
      Zhang, Ya  and
      Wang, Yanfeng  and
      He, Liang",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.480/",
    doi = "10.18653/v1/2024.emnlp-main.480",
    pages = "8428--8438",
    abstract = "With the proliferation of Large Language Models (LLMs) in diverse domains, there is a particular need for unified evaluation standards in clinical medical scenarios, where models need to be examined very thoroughly. We present CliMedBench, a comprehensive benchmark with 14 expert-guided core clinical scenarios specifically designed to assess the medical ability of LLMs across 7 pivot dimensions. It comprises 33,735 questions derived from real-world medical reports of top-tier tertiary hospitals and authentic examination exercises. The reliability of this benchmark has been confirmed in several ways. Subsequent experiments with existing LLMs have led to the following findings: (i) Chinese medical LLMs underperform on this benchmark, especially where medical reasoning and factual consistency are vital, underscoring the need for advances in clinical knowledge and diagnostic accuracy. (ii) Several general-domain LLMs demonstrate substantial potential in medical clinics, while the limited input capacity of many medical LLMs hinders their practical use. These findings reveal both the strengths and limitations of LLMs in clinical scenarios and offer critical insights for medical research."
}

@misc{Hou,
      title={MSDiagnosis: A Benchmark for Evaluating Large Language Models in Multi-Step Clinical Diagnosis}, 
      author={Ruihui Hou and Shencheng Chen and Yongqi Fan and Guangya Yu and Lifeng Zhu and Jing Sun and Jingping Liu and Tong Ruan},
      year={2024},
      eprint={2408.10039},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.10039}, 
}
@article{clinformationverification,
  title={Self-verification improves few-shot clinical information extraction},
  author={Gero, Zelalem and Singh, Chandan and Cheng, Hao and Naumann, Tristan and Galley, Michel and Gao, Jianfeng and Poon, Hoifung},
  journal={arXiv preprint arXiv:2306.00024},
  year={2023}
}
@article{baichuan2,
  title={Baichuan 2: Open Large-scale Language Models},
  author={Baichuan},
  journal={arXiv preprint arXiv:2309.10305},
  url={https://arxiv.org/abs/2309.10305},
  year={2023}
}
@inproceedings{
BoT,
title={Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models},
author={Ling Yang and Zhaochen Yu and Tianjun Zhang and Shiyi Cao and Minkai Xu and Wentao Zhang and Joseph E. Gonzalez and Bin CUI},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=ANO1i9JPtb}
}
@inproceedings{plan_train,
    title = "Divide-or-Conquer? Which Part Should You Distill Your {LLM}?",
    author = "Wu, Zhuofeng  and
      Bai, Richard He  and
      Zhang, Aonan  and
      Gu, Jiatao  and
      Vydiswaran, V.G.Vinod  and
      Jaitly, Navdeep  and
      Zhang, Yizhe",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024"
}
@article{gpteval,
  title={G-eval: Nlg evaluation using gpt-4 with better human alignment},
  author={Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  journal={arXiv preprint arXiv:2303.16634},
  year={2023}
}
@article{lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}
@inproceedings{DiReCT,
  title={DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models},
  author={Wang, Bowen and Chang, Jiuyang and Qian, Yiming and Chen, Guoxin and Chen, Junhao and Jiang, Zhouqiang and Zhang, Jiahao and Nakashima, Yuta and Nagahara, Hajime},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track}
}

@article{distengtangle,
  title={Disentangling Memory and Reasoning Ability in Large Language Models},
  author={Jin, Mingyu and Luo, Weidi and Cheng, Sitao and Wang, Xinyi and Hua, Wenyue and Tang, Ruixiang and Wang, William Yang and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2411.13504},
  year={2024}
}
@inproceedings{li2024fundamental,
  title={Fundamental Capabilities of Large Language Models and their Applications in Domain Scenarios: A Survey},
  author={Li, Jiawei and Yang, Yizhe and Bai, Yu and Zhou, Xiaofeng and Li, Yinghao and Sun, Huashan and Liu, Yuhang and Si, Xingpeng and Ye, Yuhao and Wu, Yixiao and others},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={11116--11141},
  year={2024}
}
@article{LLMrule1,
  title={Failures pave the way: Enhancing large language models through tuning-free rule accumulation},
  author={Yang, Zeyuan and Li, Peng and Liu, Yang},
  journal={arXiv preprint arXiv:2310.15746},
  year={2023}
}
@inproceedings{LLMrule2,
    title = "{E}xp{N}ote: Black-box Large Language Models are better Task Solvers with Experience Notebook",
    author = "Sun, Wangtao  and
      Yu, Xuanqing  and
      He, Shizhu  and
      Zhao, Jun  and
      Liu, Kang",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.1034/",
    doi = "10.18653/v1/2023.findings-emnlp.1034",
    pages = "15470--15481",
    abstract = "Black-box Large Language Models (LLMs) have shown great power in solving various tasks and are considered general problem solvers. However, LLMs still fail in many specific tasks although understand the task instruction. In this paper, we focus on the problem of boosting the ability of black-box LLMs to solve downstream tasks. We propose ExpNote, an automated framework to help LLMs better adapt to unfamiliar tasks through reflecting and noting experiences from training data and retrieving them from external memory during testing. We evaluate ExpNote on multiple tasks and the experimental results demonstrate that the proposed method significantly improves the performance of black-box LLMs. The data and code are available at https://github.com/forangel2014/ExpNote."
}
@article{LLMrule3,
  title={Can LLMs Follow Simple Rules?},
  author={Mu, Norman and Chen, Sarah and Wang, Zifan and Chen, Sizhe and Karamardian, David and Aljeraisy, Lulwa and Alomair, Basel and Hendrycks, Dan and Wagner, David},
  journal={arXiv preprint arXiv:2311.04235},
  year={2023}
}
@article{factdecomp,
  title={Assessing the Limitations of Large Language Models in Clinical Fact Decomposition},
  author={Munnangi, Monica and Swaminathan, Akshay and Fries, Jason Alan and Jindal, Jenelle and Narayanan, Sanjana and Lopez, Ivan and Tu, Lucia and Chung, Philip and Omiye, Jesutofunmi A and Kashyap, Mehr and others},
  journal={arXiv preprint arXiv:2412.12422},
  year={2024}
}

@article{verifact,
  title={VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records},
  author={Chung, Philip and Swaminathan, Akshay and Goodell, Alex J and Kim, Yeasul and Reincke, S Momsen and Han, Lichy and Deverett, Ben and Sadeghi, Mohammad Amin and Ariss, Abdel-Badih and Ghanem, Marc and others},
  journal={arXiv preprint arXiv:2501.16672},
  year={2025}
}