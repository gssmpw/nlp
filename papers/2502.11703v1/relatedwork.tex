\section{Related Work}
\subsection{Rule-based LLM reasoning}
While reasoning demonstrated a fundamental capability of LLM on applications~\cite{li2024fundamental}, there are many research such as CoT~\cite{cot}, CoT-sc~\cite{cot-sc}, ToT~\cite{ToT}, etc. However, there are more attention on rule-enhanced methods~\cite{LLMrule1, LLMrule2, LLMrule3}. Reasoning based on facts and deriving answers from logical rules is referred to as inferential rule following ability~\cite{rulesurvey}. Leveraging such ability that integrating explicit rules with LLMs has gained significant attention. For instance, ~\citet{chain-of-logic} utilized the IRAC framework to tackle legal tasks with LLMs, emphasizing the application of legal rules. Additionally, ~\citet{ruleapplication} proposed a neurosymbolic framework for multi-step rule application. Despite the current limitations of LLMs in rule-based reasoning~\cite{rulestress}, our work demonstrates that such rule-based reasoning outperforms CoT reasoning in the MQCIC task.

\subsection{LLM Evaluations in Clinical Scenarios}
While LLMs have shown impressive capabilities in medical knowledge recall and reading comprehension on medical exams~\cite{GPT4_medical, M-QALM}, their effectiveness in real-world clinical applications remains a critical area of evaluation. For example, ~\citet{CliMedBench} assesses LLMs across 14 expert-curated clinical scenarios, including diagnosis, discharge summaries, and medical consultations. Similarly, ~\citet{medcal} introduces MedCal-Bench, a benchmark designed to evaluate inferential rule reasoning in medical contexts, while ~\citet{Hou} simulates a multi-step diagnostic process to test clinical reasoning capabilities. Furthermore, ~\citet{factdecomp,verifact} explore LLMs' abilities in clinical fact decomposition and verification. In this work, we focus on evaluating LLMs in the MQCIC task, with a specific emphasis on their performance in clinical fact verification and inferential rule reasoning, providing a detailed analysis of these two critical abilities.
% (2) \textbf{Insufficient hardware computing power to support large-parameter models.} Previous work has explored the upper limits of LLMs in clinical tasks, while some research focuses on training cost-effective models for real-world applications~\cite{apollo, apollo1, NC}. 
% In line with these efforts, we also report the performance of lightweight models and our training results, aiming to explore a more balanced trade-off approach.