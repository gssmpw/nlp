% !TEX root = Main.tex

In this section we prove Theorem \ref{TheoremIdealDecompositionEVASS}, i.e.\ we prove  that the class of sections of monotone \(\RelationClass\)-eVASS is approximable.

In order to decompose a section \(\pi(\vectSet{R} \cap \vectSet{L})\), by Lemma \ref{LemmaNiceOverapproximationProjection} we simply decompose \(\vectSet{R} \cap \vectSet{L}\) instead. Hence in the following we will only deal with such sections.

First we introduce the main data structure of our algorithm:

\begin{definition}
A \(\RelationClass\)-KLM sequence is a relation \(\vectSet{X}_1 \circ \dots \circ \vectSet{X}_r\), where \(\vectSet{X}_i=\vectSet{R}_i \cap \vectSet{L}_i\) are monotone \(\RelationClass\)-eVASS sections.

It is represented as a list of \((\VAS_i, \qini, \qfini)\) and \((\vect{b}_i, \vectSet{F}_i)\).
\end{definition}

I.e.\ a \(\RelationClass\)-KLM sequence is a composition of monotone \(\RelationClass\)-eVASS sections. In more intuitive terms, when a monotone \(\RelationClass\)-eVASS leaves an SCC, it is now allowed to test whether the \emph{total behaviour} it performed inside this SCC is in some linear relation. Observe that this is stronger than just zero testing at exits: For example the \(\RelationClass\)-eVASS can now check that inside an SCC it exactly doubled. 

\begin{algorithm}[h!]
\caption{Approximation(Reach.Rel. \(\vectSet{R}\), linear relation \(\vectSet{L}\))}\label{AlgorithmMainStructure}
\begin{algorithmic}
\State \textbf{Output}: Set of Pairs \((\vectSet{X}_j, \vectSet{L}_j)\) of \(\RelationClass\)-KLM sequences \(\vectSet{X}_j\)
\State and their nice approximations \(\vectSet{L}_1, \dots, \vectSet{L}_k\) each
\State such that \(\vectSet{R} \cap \vectSet{L}= \bigcup_{j=1}^k \vectSet{X}_j\).
\State Workset \(\gets\) \(\{\vectSet{R} \cap \vectSet{L}\}\).
\While{exists \(\vectSet{X} \in\) Workset: \(\vectSet{X}\) is not perfect}
    \State Workset \(\gets\) (Workset \(\setminus \{\vectSet{X}\})\ \cup\) Decompose(\(\vectSet{X}\)).
\EndWhile
\State Output \(\gets \emptyset\)
\For{ \textbf{all} \(\vectSet{X}\in \) Workset}
    \State Output \(\gets\) Output \(\cup \{(\vectSet{X}, \pi_{\source, \target}(\sol(\CharSys(\vectSet{X}))))\}\)
\EndFor
\State \textbf{Return} Output.
\end{algorithmic}
\end{algorithm}

%This is however not actually an extension of the class of sections: Using the projection in the definition of sections, every composition of sections can be written as a single section.

The main idea of the algorithm is the following, see Algorithm \ref{AlgorithmMainStructure}: Maintain a workset of current \(\RelationClass\)-KLM sequences. While one of them does not fulfill a condition we call ``perfectness'', decompose such a \(\RelationClass\)-KLM sequence \(\vectSet{X}\) into ``smaller'' \(\RelationClass\)-KLM sequences. Here ``smaller'' is w.r.t. some well-founded ordering. Finally, if a \(\RelationClass\)-KLM sequence \(\vectSet{X}\) is perfect, then output \(\vectSet{X}\) together with the projection of the solution set of an integer linear program (ILP) called the characteristic system \(\CharSys(\vectSet{X})\) to the variables \(\source\) and \(\target\).

The rest of this section is structured as follows: First we define perfectness. Secondly, we define the integer linear program (ILP) called the characteristic system (\(\CharSys\)) which overapproximates the KLM sequence, and is used to define perfect. Thirdly, we define the rank of \(\vectSet{X}\). Fourthly, we describe how to decide perfectness and decompose. We end with a correctness proof and complexity analysis.

For the rest of this section fix a \(\RelationClass\)-KLM sequence \(\vectSet{X}:=\vectSet{X}_1 \circ \dots \circ \vectSet{X}_r\), where \((\VAS_i, \qini, \qfini), \vectSet{L}_i\) define \(\vectSet{X}_i\). Let \(d_i\) be the dimension of \(i\)-th \(\RelationClass\)-eVASS \(\VAS_i\). The index \(i\) is reserved for the \(i\)-th relation in \(\vectSet{X}\), and \(r\) is the length of the composition. These letters are not used for anything else.

\begin{definition}\textbf{Perfectness}: A \(\RelationClass\)-KLM seq. \(\vectSet{X}\) is \emph{perfect} if:\label{DefinitionPerfectness}%

\begin{enumerate}
\item[P1] Every \(\vectSet{R}(e) \in \RelationClass\) occurring on an edge \(e\) of some \(\VAS_i\) has a nice overapproximation \(\vectSet{L}(e)=\vect{b}(e)+\N(\vectSet{F}(e))\) \emph{fulfilling} \(\vect{b} \in \vectSet{R}(e)\), \emph{and we add }\(\vectSet{L}(e)\) \emph{as an edge label}.
\item[P2] For every \(i\), \(\VAS_i\) is either \emph{strongly-connected}, or \(\VAS_i\) fulfills \(\qini \neq \qfini\) and has only one edge \(e_i=(\qini,\qfini)\).% In the second case, remember that the label of \(e_i\) may be either \(\vectSet{R}(e_i) \in \RelationClass\), or \(I_+(e_i)\) and \(I_-(e_i)\).
\item[P3] For all \(i\) the relation \(\vectSet{L}_i\) is the projection of the solutions of \(\CharSys\) to the source/target variables for \(\VAS_i\).
\item[P4] If \(\VAS_i\) has only a single edge \(e_i\), then \(\vectSet{L}(e_i) \cap \vectSet{L}_i\) is a non-degenerate intersection.
\item[P5] If \(\VAS_i\) is strongly-connected, then for every counter \(j\), there is a cycle with non-zero effect on \(j\).
\item[P6] In \(\CharSys\) every \emph{auxiliary} variable is unbounded.
\item[P7] \emph{Every} configuration of every strongly-connected \(\VAS_i\) can be forwards- and  backwards-covered, i.e.\ for every such \(i\) and every configuration \(p(\vect{x}_t)\) of \(\VAS_i\), we have 
\[\Rel(\VAS_i,\qini, p) \cap (\piin(\vectSet{L}_i) \times (\vect{x}_t+\N^{d_i})) \neq \emptyset \text{ and }\] \(\Rel(\VAS_i, p, \qfini) \cap ((\vect{x}_t+\N^{d_i}) \times \piout(\vectSet{L}_i)) \neq \emptyset\).
\end{enumerate}
\end{definition}

\textbf{Characteristic System}: The characteristic system is an ILP whose goal is to overapproximate reachability in a \(\RelationClass\)-KLM sequence \(\vectSet{X}\). This ILP can only be defined in case the \(\RelationClass\)-KLM sequence \(\vectSet{X}=\vectSet{X}_1 \circ \dots \circ \vectSet{X}_r\) fulfills P1-P2 of perfectness. Its variables are vectors \(\vect{x}_1, \dots, \vect{x}_r\) and \(\vect{y}_1, \dots, \vect{y}_r\) of appropriate dimension, which stand for the source/target configurations of \(\VAS_i\), and auxiliary variables \(\Auxiliary_1, \dots, \Auxiliary_r\) for every \(\VAS_i\). The \(\pi_{\source, \target}\) in Algorithm \ref{AlgorithmMainStructure} corresponds to the projection to \(\vect{x}_1, \vect{y}_r\).

For every \(i\) we will in a moment define an ILP \(\LocalCharSys_i\) which overapproximates reachability in \(\vectSet{X}_i\). The full ILP is then defined in terms of these local ILP as follows:
\[\bigwedge_{i=1}^r \LocalCharSys_i(\vect{x}_i, \Auxiliary_i, \vect{y}_i) \wedge \bigwedge_{i=1}^{r-1} \vect{y}_i=\vect{x}_{i+1}.\]
Hence it only remains to define the local ILPs \(\LocalCharSys_i\).
\begin{remark}
We will define some equations of \(\LocalCharSys_i\) by writing ``\(\vect{x} \in \vectSet{L}\)'', where \(\vect{x}\) is some vector of variables and \(\vectSet{L}=\vect{b}+\N(\{\vect{p}_1, \dots, \vect{p}_r\})\) is a linear set/relation. The expanded technical meaning is that we create variables \(\#(\vect{p}_i)\) for how often the periods are taken, and add the equations \(\vect{x}-\sum_{i=1}^r \#(\vect{p}_i) \cdot \vect{p}_i=\vect{b}\).
\end{remark}

\textbf{Definition of }\(\LocalCharSys\): Remember that by P1 we have access to a nice overapproximation \(\vectSet{L}(e)\) for every edge \(e\), and that by P2 we only have three cases to distinguish:

Case 1: \(\VAS_i\) has a single edge labelled with \(\vectSet{R}(e) \in \RelationClass\): Then \(\LocalCharSys_i(\vect{x}_i, \Auxiliary_i, \vect{y}_i)\) is defined by \((\vect{x}_i, \vect{y}_i) \in \vectSet{L}(e) \wedge (\vect{x}_i, \vect{y}_i) \in \vectSet{L}_i\). In particular the only auxiliary variables count how often each period of these linear relations is used.

Case 2: \(\VAS_i\) has a single edge labelled with \(I_+(e), I_-(e)\): Then the reachability relation of \(\VAS_i\) is linear (the semantics of the edge), and we can hence define \(\LocalCharSys(\vect{x}_i, \Auxiliary_i, \vect{y}_i)\) by the equations \((\vect{x}_i, \vect{y}_i) \in \vectSet{R}_i \wedge (\vect{x}_i, \vect{y}_i) \in \vectSet{L}_i\).

Case 3: \(\VAS_i=(Q_i, E_i)\) is strongly connected: This is the interesting case. The first step to defining \(\LocalCharSys\) is to overapproximate the set of paths in the control graph via the so-called \emph{Euler-Kirchhoff-equations}, defined as follows:

\begin{definition}
Let \(\VAS=(Q,E)\) be a graph with initial/final states \(\qin, \qfin\). Then EK(\(\VAS\)) is the following ILP with variables \(\#(e) \in \N\) for every \(e \in E\):

\[\bigwedge_{q \in Q}\sum_{e \in \text{in}(q)} \#(e)-\sum_{e \in \text{out}(q)} \#(e)=1_{q=\qfin}(q)-1_{q=\qin}(q),\] where in(\(q\)) and out(\(q\)) are the in- and outgoing neighbourhoods of state \(q\) respectively and \(1_S \colon Q \to \{0,1\}\) for a condition \(S\) is the indicator function, i.e.\ \(1_S(q)=1\) if \(q \in Q\) fulfills \(S\), and \(1_S(q)=0\) otherwise.

We write the corresponding homogeneous ILP, where we replace \(1_{q=q_{fin}}(q)-1_{q=q_{in}}(q)\) by \(0\), as HEK(\(\VAS\)).
\end{definition}

Intuitively, \(\#(e)\) is the number of times an edge \(e\) is used, and for every state which is not initial or final, we require it to be entered as often as left, the final state has to be entered one more time than left etc. This leads to Euler's lemma:

\begin{lemma} \label{LemmaBasicEulerKirchhoff}
Let \(\VAS=(Q,E)\) be a graph with initial/final states \(\qin, \qfin\). Let \(\pi\) be a path from \(\qin\) to \(\qfin\). Then \(\Parikh(\pi)\), the parikh image of \(\pi\), fulfills EK(\(\VAS\)). Conversely, if \(\vect{w} \in \N_{\geq 1}^E\) fulfills EK(\(\VAS\)), then there is a path \(\pi\) with \(\Parikh(\pi)=\vect{w}\). Observe that the converse requires \(\vect{w}[e]\geq 1\) for every \(e\).
\end{lemma}

Now we can continue defining \(\LocalCharSys\) for an SCC \(\VAS_i\). Let \(d_i\) be the dimension of \(\VAS_i\). Remember that for \(\vect{b}=(\vect{b}_s, \vect{b}_t) \in \N^{d_i} \times \N^{d_i}\) we write \(\Effect(\vect{b}):=\vect{b}_t-\vect{b}_s\) for the effect.

For every edge \(e \in E_i\) we write \(\vectSet{L}(e)=\vect{b}(e)+\N(\vectSet{F}(e)) \subseteq \N^{d_i} \times \N^{d_i}\) for the nice overapproximation of the edge. We define its \(\Z\)-semantics:
\[\Z(\vectSet{L}(e)):=\{(\vect{x}, \vect{y}) \in \Z^{d_i} \times \Z^{d_i} \mid \vect{y}-\vect{x}-\Delta(\vect{b}(e)) \in \Delta(\N(\vectSet{F}(e)))\}\] Observe that this overapproximation is not as small as one might imagine: For example if \(\vectSet{L}=\{(x,x') \in \N \times \N \mid 0.5 x \leq x' \leq 2x\}\) combines ``weak-doubling'' and ``weak-halving'', then \(\Z(\vectSet{L})=\Z^2\): Indeed, the condition ``\(\in \Delta(\N(\vectSet{F}))\)'' is vacuous here, since \emph{every} \(\Delta \in \Z\) is a possible effect \(x'-x\) for large enough \(x \in \N\). 

Now let \(\vectSet{F}_i:=\bigcup_{e \in E_i} \Effect(\vectSet{F}(e)) \subseteq \N^{d_i}\). For every \(\vect{w}_i \in \N^{E_i}\) define \(\Effect(\vect{w}):=\sum_{e \in E_i}\vect{w}(e) \cdot \Effect(\vect{b}(e))\), i.e.\ the effect of an edge sequence only takes the base \(\vect{b}(e)\) into account. Finally we define \(\LocalCharSys_i(\vect{x}_i, \Auxiliary_i, \vect{y}_i)\) as \[\text{EK}(\VAS_i)(\vect{w}_i) \wedge \vect{y}_i-\vect{x}_i-\Effect(\vect{w}_i) \in \N(\vectSet{F}_i) \wedge (\vect{x}_i, \vect{y}_i) \in \vectSet{L}_i.\]

Let us give intuition on this overapproximation: Assume first that the overapproximation \(\vectSet{L}(e)\) of the edges have no periods. Then the overapproximation says the following: The effect \(\vect{y}-\vect{x}\) of the pair \((\vect{x}, \vect{y})\) has to be the effect of a parikh vector \(\vect{w}\) fulfilling EK(\(\VAS_i\)). Usually this is called \(\Z\)-VASS-reachability. With periods, we require that \(\vect{y}-\vect{x}-\Effect(\vect{w})\) is the effect of some periods. I.e.\ the \emph{effect} which we did not manage to produce using normal \(\Z\)-reachability may be compensated by using periods arbitrarily often. The system does not distinguish between which linear relation the necessary periods would be coming from. 

Similar to normal VASS, there is a related notion of \(\Z\)-run: A \(\Z\)-run is a sequence of pairs \(q_j(\vect{x}_j)\) with \(q_j \in Q_j, \vect{x}_j \in \Z^d\) s.t. \(q_j \to_{e_j} q_{j+1}\) for some edge \(e_j\), and \((\vect{x}_j, \vect{x}_{j+1}) \in \Z(\vectSet{L}(e_j))\), and from Lemma \ref{LemmaBasicEulerKirchhoff} it is easy to see that any full support solution of the characteristic system gives rise to a corresponding \(\Z\)-run.

%\begin{lemma}
%Any full support solution of \(\LocalCharSys_i\) gives rise to a \(\Z\)-run from \(\qini\) to \(\qfini\).
%\end{lemma}
\textbf{Recap}: We explained the algorithm structure, defined perfectness and the characteristic system. Next we define the rank, followed by deciding perfectness and the decomposition.

\begin{definition}
\textbf{Ranking function}. The \(\rank(\vectSet{X}) \in \N^{d+1}\) is similar to \cite{LerouxS19}, and only takes SCCs \((S, E_S)\) of the \(\RelationClass\)-eVASS into account. We first assume that P1 holds. Similar to the characteristic system, let \(\Delta:=\{\vect{x} \mid \exists \vect{w} \in \N^{E_S} \colon \vect{w} \in \text{HEK}(S, E_S) \wedge \Effect(\vect{w})=\vect{x}\}\) be the set of effects of cycles. Let \(\vectSet{F}_S:=\bigcup_{e \in E_S} \Effect(\vectSet{F}_e)\), where \(\vectSet{F}_e\) are the periods of \(\vectSet{L}(e)\). We let \(d_{geom}:=\dim(\Q(\vectSet{F}_S)+\Q(\Delta))\) be the dimension of the \(\Q\)-generated set of the cycle effects (including periods), and define \(\rank(S, E_S):=\vect{r} \in \N^{d+1}\), where \(\vect{r}[d+1-d_{geom}]:=|E_S|\) is the number of edges, and \(\vect{r}[j]=0\) otherwise. Finally, \(\rank(\vectSet{X})=\sum_{SCC\ (S, E_S)} \rank(S, E_S)\) is the sum of the ranks of all SCCs occurring in any \(\VAS_i\).

We use the \emph{lexicographic ordering} on \(\N^{d+1}\). 

If P1 does not hold, then the rank is assigned as if the decomposition restoring property P1 had already been applied: In particular if an edge \(e\) would split into \(5\) edges, then it is counted \(5\) times for determining \(|E_S|\).
\end{definition}

The intuition on the rank is as follows: It defines a notion of ``dimension'' for SCCs, and if we replace a ``high-dimensional'' SCC by an arbitrary number of ``lower-dimensional'' SCCs, then the rank decreases. However, SCCs have to be weighted correctly, namely with the number of edges. In case P1 does not hold, we calculate this in a strange way.

\textbf{Deciding Perfectness and Decomposition}: We explain how to decide perfectness (Def. \ref{DefinitionPerfectness}) and decompose otherwise.

Leroux \cite{LerouxS19} first observed for normal VASS that the properties of perfectness fall into two categories: \emph{Cleaning properties} and \emph{actual properties}. The difference is that the decomposition for a cleaning property \emph{does not decrease the rank}. In exchange these properties \emph{do not harm each other} in the following sense: In our case P1-P5 are cleaning properties, and if we do the corresponding decomposition steps in sequence, we arrive at a \(\RelationClass\)-KLM sequence fulfilling \emph{all of} P1-P5. In particular, when we decompose for P2, we do not lose P1, when we decompose for P3 we do not lose P1-P2, etc. 

This is in contrast to P6 and P7: When a transition is bounded (may only be used finitely often) and hence P6 does not hold, we will remove this transition from SCCs. Removing transitions might cause certain configurations to no longer be coverable in the SCC, and property P7 is lost. Conversely if a counter is bounded in P7 and we store it in the control state, then the characteristic system now has new variables for the new edges, etc. and some of these might be bounded.

With this new knowledge, consider again Algorithm \ref{AlgorithmMainStructure}. We can now describe what Decompose(\(\vectSet{X}\)) does: It first guarantees properties P1-P5 simultaneously, since they are cleaning properties, and afterwards applies one actual decomposition for property P6 or P7. This way, even though P1-P5 did not decrease the rank, the whole procedure Decompose did.

This leads to the following two lemmata:

\begin{lemma}[Cleaning] \label{LemmaCleaning}
Let \(\vectSet{X}\) be a \(\RelationClass\)-KLM sequence. Then one can in time \(\mathfrak{F}_{\alpha+2}(\size(\vectSet{X}))\) compute a finite set of \(\RelationClass\)-KLM sequences \(\vectSet{X}_1, \dots, \vectSet{X}_k\) such that \(\rank(\vectSet{X}_j) \leq \rank(\vectSet{X})\), \(\vectSet{X}=\bigcup_{j=1}^k \vectSet{X}_j\), and every \(\vectSet{X}_j\) fulfills properties P1-P5.
\end{lemma}

\begin{lemma}[Decomposition] \label{LemmaActualDecomposition}
Let \(\vectSet{X}\) be a \(\RelationClass\)-KLM sequence fulfilling P1-P5, which is not perfect. Then one can in time \(\mathfrak{F}_{\alpha+d+1}(\size(\vectSet{X}))\) compute a finite set of \(\RelationClass\)-KLM sequences \(\vectSet{X}_1, \dots, \vectSet{X}_k\) s.t. \(\rank(\vectSet{X}_j) < \rank(\vectSet{X})\) and \(\vectSet{X}=\bigcup_{j=1}^k \vectSet{X}_j\).
\end{lemma}

In the following we prove Lemma \ref{LemmaCleaning} and Lemma \ref{LemmaActualDecomposition}.

\textbf{Proof of Lemma \ref{LemmaCleaning}}. The proof proceeds by doing decompositions for P1-P5 respectively in sequence. 

First remember the assumptions on class \(\RelationClass\):

\begin{itemize}
\item \(\RelationClass\) is closed under intersection with semilinear sets.
\item There is an algorithm \(\ApproximationAlgorithm\) which given \(\vectSet{R} \in \RelationClass\), in time \(\mathfrak{F}_{\alpha}\) outputs finitely many \(\vectSet{R}_j, \vectSet{L}_j\) and a function \(g \in \mathfrak{F}_{\alpha}\) s.t. \(\vectSet{R}=\bigcup_{j=1}^k \vectSet{R}_j\) with \(\vectSet{R}_j \HybridizationRelation \vectSet{L}_j\). The \(N\) in nice overapproxim. is bounded by \(g(\size(\vect{x})+\size(\vect{w})+\size(\vectSet{R}_j))\).
\end{itemize}

\textbf{P1}: We decide P1 as follows: We check for every edge \(e\) of every \(\VAS_i\) whether we have already written a label \(\vectSet{L}(e)\) on the edge. If not, then we decompose all such edges separately, but \emph{do not change the structure of any} \(\VAS_i\). So let \(e\) be an edge not currently labelled with a nice overapproximation \(\vectSet{L}(e)\). We apply \(\ApproximationAlgorithm\) on \(\vectSet{R}(e)\), replacing \(e\) by edges \(e_1, \dots, e_k\) with (same source/target and) \(\vectSet{R}(e_j):=\vectSet{R}_j\) and \(\vectSet{L}(e_j):=\vectSet{L}_j\). These are not the final output however: We still have to guarantee that \(\vectSet{L}(e_j)=\vect{b}_j+\N(\vectSet{F}_j)\) for \(\vect{b}_j \in \vectSet{R}(e_j)\), i.e.\ that the basis of the linear relation is an element of \(\vectSet{R}(e_j)\). If we had some handle on the class \(\RelationClass\), there would be more efficient ways, but in general we can apply the main trick in the toolbox/Lemma \ref{LemmaDimensionDecreaseShiftedL}: If we understand the asymptotics, we understand \(\vectSet{R}_j\): 

Choose \(\vect{w}_j:=\sum_{\vect{f} \in \vectSet{F}_j} \vect{f}\) and \(\vect{p}_j:=g(\size(\vectSet{X}_j)+\size(\vect{b}_j)+\size(\vect{w}_j)) \cdot \vect{w}_j\) and set \(\vect{b}_j':=\vect{b}_j+\vect{p}_j\). By Lemma \ref{LemmaShiftGoodOverapproximation}, \(\vectSet{L}_j':=\vect{b}_j'+\N(\vectSet{F})\) is a nice overapproximation of \(\vectSet{R}_j \cap \vectSet{L}_j'\), and by definition of the function \(g\) we have \(\vect{b}_j' \in \vectSet{R}_j=\vectSet{R}(e_j)\). It remains to approximate also \(\vectSet{R}_j \cap (\vectSet{L}_j \setminus \vect{p}_j+\vectSet{L}_j)\): By Lemma \ref{LemmaDimensionDecreaseShiftedL} \(\dim(\vectSet{L}_j \setminus (\vect{p}_j+\vectSet{L}_j))< \dim(\vectSet{L}_j)\). Hence we can deal with \(\vectSet{R}_j \cap (\vectSet{L}_j \setminus \vect{p}_j+\vectSet{L}_j)\) by again applying algorithm \(\ApproximationAlgorithm\) recursively, continuing until we are done. 

Observe that this recursion in particular computed the minimal elements of \(\vectSet{R}(e)\), a trick we will use again later.

Running time \(\mathfrak{F}_{\alpha+1}\): We have \(g \in \mathfrak{F}_{\alpha}\), and use a bounded depth recursion (at most \(\dim(\vectSet{L}(e))\)), giving \(\mathfrak{F}_{\alpha+1}\).

\begin{example}
If similar to Figure \ref{FigureIntuitionSemilinearityAlgorithm} we have \(\vectSet{R}(e)=\{(x,y) \in \N \times \N \mid x \geq 1, y \leq x^2\}\), algorithm \(\ApproximationAlgorithm\) might at first output \(\vectSet{L}_1(e)=\N^2\). However, \((0,0) \not \in \vectSet{R}(e)\). Instead the algorithm computes \(g(\dots)\) (say \(1\)), adds \(\vectSet{L}_1'(e):=(1,1)+\N^2\) as an overapproximation and recursively approximates \(\vectSet{R}(e) \cap \{0\} \times \N\) and \(\vectSet{R}(e) \cap \N \times \{0\}\) to further add \(\vectSet{L}_2'(e)=(\N+1) \times \{0\}\).
\end{example}

\textbf{P2}: Simply decompose every graph into sequences of strongly-connected components and edges. This can clearly be done in exponential time. Since this does not change any edge labels, we preserve property P1.

\textbf{P3}: To check P3, we only have to compute with semilinear sets, which is in EXPTIME. If P3 does not hold, do the following: Determine the set \(\{\sol_1, \dots, \sol_k\}\) of minimal solutions to \(\CharSys\). Create \(k\) copies of \(\vectSet{X}\), but \(\forall 1 \leq j \leq k\) and \(1 \leq i \leq r\), in the \(j\)-th copy replace the \(i\)-th linear relation \(\vectSet{L}_i\) by \(\vectSet{L}_i':=\pi_i(\sol_j+\HomCharSys)\), where \(\pi_i\) projects \(\CharSys\) to the variables for \(\vect{x}_i, \vect{y}_i\). Again this can be done in exponential time, and the property now holds by definition.

The intuition for this decomposition for P3 is the following: Imagine there are five ``components'', and the third ``component'' determined that some counter \(j\) is bounded. Now the other four components have to learn this information somehow, and update their local overapproximations. The most effective way to do this is to consider the ``global reachability'' described by the characteristic system, and simply project its solutions. Projection of ILP solutions is computationally and mathematically simple, but unifies multiple properties like \emph{saturatedness}, etc. of prior versions of reachability in VASS. It is one of the milestones of our version, simplifying the presentation, and removing the need for multiple \(\omega\)-configurations everywhere.

\textbf{P4}: To check condition P4, observe that by Lemma \ref{BasicDimensionProperties} and Lemma \ref{LemmaFromJerome}, the dimension of a linear set is simply the rank of the matrix of periods. Hence to check P4, we compute the intersection of two linear relations, and the ranks of the matrices of periods. This is possible in exponential time. 

Let \(i\) be an index where P4 does not hold, let \(e_i\) be the unique edge. Remember the approximation algorithm \(\ApproximationAlgorithm\). We apply \(\ApproximationAlgorithm\) to \(\vectSet{R}(e_i) \cap \vectSet{L}_i\), obtaining \(\vectSet{R}(e_i) \cap \vectSet{L}_i=\bigcup_{j=1}^k \vectSet{X}_j\) with nice overapproximations \(\vectSet{L}_1, \dots, \vectSet{L}_k\). Similar to P1, we have to recursively refine this to reobtain \(\vect{b}(e) \in \vectSet{R}(e)\), in the following let \((\vectSet{X}_1', \vectSet{L}_1'), \dots, (\vectSet{X}_s', \vectSet{L}_s')\) be the results of this recursion. We create \(s\) many \(\RelationClass\)-KLM sequences from \(\vectSet{X}\) by creating \(s\) copies, in the \(j\)-th copy we change \emph{only the labels of} \(e_i\) by \(\vectSet{R}(e_i):=\vectSet{X}_j'\) and \(\vectSet{L}(e_i):=\vectSet{L}_j'\). Since \(\dim(\vectSet{L}(e_i) \cap \vectSet{L}_i)<\max \{\dim(\vectSet{L}(e_i)), \dim(\vectSet{L}_i)\}\) (property P4 did not hold), we have \(\dim(\vectSet{L}_j')< \max \{\dim(\vectSet{L}(e_i)), \dim(\vectSet{L}_i)\}\). 

The dimension decrease is crucial because this only preserves properties P1 and P2, but P3 might no longer hold. Hence we now have to apply the decomposition for P3 again, which again damages property P4 and so on. However, again Toolbox trick number 1: After at most \(2\dim(\vectSet{L}(e_i))\) many alternations between guaranteeing P3 and P4, the dimension decrease guarantees we achieved both properties P3 and P4. This decomposition takes time \(\mathfrak{F}_{\alpha+2}\), since we have bounded depth recursion with time \(\mathfrak{F}_{\alpha+1}\) each step.

\textbf{P5}: To check whether there is a cycle with non-zero effect on counter \(j\), first we check whether some period of an edge \(e\) changes \(j\). If yes, then clearly such a cycle exists. Else for the exponentially many possible supports \(S \subseteq E_i\) the cycle could have and \(\sim \in \{>,<\}\)  we write down an ILP as follows: 
\[\{\vect{w}\in \N^{S} \mid \bigwedge_{e \in S} \vect{w}(e)\geq 1 \wedge \text{HEK}(\VAS)(\vect{w})\wedge \Delta(\vect{w})(j) \sim 0\}\]
If one of these ILP has a solution, then there exists such a cycle, otherwise not. If a counter does not have a loop changing it, then its value can be uniquely determined from the state of the automaton. In particular there is a unique exit value \(out\) at \(\qfini\). We decompose \(\vectSet{X}_i\) into \(\text{Del} \circ \pi_{\neg j}(\vectSet{X}_i) \circ \text{RevDel} \circ \text{Add}\), where Del deletes counter \(j\), RevDel readds counter \(j\) and Add sets counter \(j\) from its current value \(0\) to \(out\).

%\textbf{Recap}: We explained the structure of the workset algorithm, defined perfectness, the characteristic system and the rank and have finished the first half of the decomposition steps by proving Lemma \ref{LemmaCleaning}. It remains to prove Lemma \ref{LemmaActualDecomposition} and explain correctness and complexity.

\textbf{Proof of Lemma \ref{LemmaActualDecomposition}}: We have to explain how to decide properties P6 and P7 of Definition \ref{DefinitionPerfectness}, and how to decompose if they do not hold. We may assume P1-P5 hold.

\textbf{P6}: We can in exponential time decide whether a variable of an ILP is bounded. It remains to decompose. The decomposition depends on which variable is bounded: We know by P3 that \(\vectSet{L}_i\) has only homogeneous solutions as periods, hence the hidden auxiliaries for periods of \(\vectSet{L}_i\) are already unbounded. Similarly, since by P4, in case \(\VAS_i\) uses a single edge, the intersection \(\vectSet{L}(e_i) \cap \vectSet{L}_i\) is non-degenerate, the periods of \(\vectSet{L}(e_i)\) are also unbounded. The variables \(\vect{x}_i, \vect{y}_i\) for source/target are not auxiliaries, and do not have to be unbounded. Hence the only variables for which we decompose here are \(\Auxiliary_i\) for strongly-connected \(\VAS_i\). These are either counts of periods of \(\vectSet{L}(e)\) for edges \(e \in E_i\), or \(\#(e)\), the number of edge uses.

Sketch of Construction: If \(\#(e)\) is bounded by some \(n\), then we create \(n+1\) copies of the SCC, and redirect \(e\) to point to the next copy (in particular it is no longer in an SCC, vanishing from the rank). If a period \(\vect{p}\) of some linear relation \(\vectSet{L}(e)\) is bounded, then we store in the control state how often we used this period already, up to the bound. For all \(i \leq j \leq B\) where \(B\) is the bound, we have an edge from the \(i\)-th copy to the \(j\)-th which uses the period \(j-i\) many times.

What makes this decomposition step tricky is that \emph{every} bounded variable of an SCC has to be removed \emph{at once}, otherwise the rank does not decrease, see the appendix.

\textbf{P7}: Let \(d_i\) be the dimension of \(\VAS_i\). Let us rephrase the two parts of property P7: Since the second half corresponds to the first if we turn around all edges as well as the relation \(\vectSet{L}_i\), we w.l.o.g. only consider the first part here. Write \(\piin(\vectSet{L}_i)=\vect{b}+\N(\vectSet{F})\). The first part can be reformulated as follows:

\begin{lemma} \label{LemmaEquivalentPropertySix}
Let \(I \subseteq \{1,\dots, d_i\}\) be the set of counters which cannot be increased using a period of \(\piin(\vectSet{L}_i)\). Let \(\pi \colon \N^{d_i} \to \N^{I}\) be the projection removing counters outside \(I\). Consider the monotone \(\RelationClass\)-eVASS \(\pi(\VAS_i)\) obtained from \(\VAS_i\) by deleting counters outside \(I\). 

The first part of P7 holds \(\iff\) \((\pi(\vect{b}), \pi(\vect{b})+\mathbf{up}) \in \Rel(\pi(\VAS_i), \qini, \qini)\) for some vector \(\mathbf{up} \in \N_{\geq 1}^{I}\).
\end{lemma}

\begin{proof}
``\(\Rightarrow\)'': Choose configuration \(\qin(\vect{b}+1^{d_i})\), and apply property P6: We obtain vectors \(\vect{x}, \vect{y}\) s.t. \((\vect{x}, \vect{y}) \in \Rel(\VAS_i, \qini, \qini)\),  \(\vect{x} \in \vect{b}+\N(\vectSet{F})\) and \(\vect{y} \geq \vect{b}+1^{d_i} > \vect{b}\). Defining \(\mathbf{up}:=\vect{y}-\vect{b}\) and observing that deleting counters makes existence of runs easier, we obtain \((\pi(\vect{b}), \pi(\vect{b})+\pi(\mathbf{up}))=(\pi(\vect{x}), \pi(\vect{y})) \in \vectSet{R}(\pi(\VAS_i))\) as required.

``\(\Leftarrow\)'': By definition of monotone \(\RelationClass\)-eVASS, all edges inside an SCC have monotone semantics \(\vectSet{R}(e)\). Since \(\VAS_i\) and hence \(\pi(\VAS_i)\) is strongly-connected, \emph{every} edge has monotone semantics. This implies that we also have \((\pi(\vect{b})+n\mathbf{up}, \pi(\vect{b})+(n+1)\mathbf{up}) \in \Rel(\pi(\VAS_i), \qini, \qini)\) for all \(n \in \N\). By transitivity of \(\Rel(\pi(\VAS_i), \qini, \qini)\) we therefore obtain \((\pi(\vect{b}), \pi(\vect{b})+n\mathbf{up}) \in \Rel(\pi(\VAS_i), \qini, \qini)\) for all \(n \in \N\), reaching arbitrarily large configurations.

To see that this transfers back to \(\VAS_i\), again use monotonicity: Let \(p(\vect{x}_t)\) be any configuration of \(\VAS_i\). We have to show that we can cover it. Let \(n:=||\vect{x}_t||_{\infty}\), and let \(\rho\) be a run in \(\pi(\VAS_i)\) reaching \(\geq n\) on every counter. Write \(\rho=p_0(\vect{x}_0'), \dots, p_k(\vect{x}_k')\) with \(\vect{x}_0'=\pi(\vect{b}), p_0=\qini\) and \(p_k=p\). Since the steps \((\vect{x}_m', \vect{x}_{m+1}')\in \pi(\vectSet{R}(e_m))\) exist in the projection, there exist vectors \(\vect{x}_m, \vect{y}_m \in \N^{d_i}\) s.t. \(\pi(\vect{x}_m)=\vect{x}_m', \pi(\vect{y}_m)=\vect{x}_{m+1}'\) and \((\vect{x}_m, \vect{y}_m) \in \vectSet{R}(e_m)\). Define \(\vect{x} \in \N^{d_i}\) by \(\vect{x}[j]=\vect{x}_0'[j]\) if \(j \in I\), and \(\vect{x}[j]=\sum_{m=0}^{k-1} \vect{x}_m[j]\) otherwise. Similarly define \(\vect{y}\) by \(\vect{y}[j]=\vect{x}_k'[j]\) if \(j \in I\) and \(\vect{y}[j]=\sum_{m=1}^{k} \vect{y}_m[j]\) otherwise. In particular \(\pi(\vect{x})=\pi(\vect{b})\) and \(\pi(\vect{y})[j] \geq n\) for every \(j \in I\). By monotonicity and transitivity we have \((\vect{x}, \vect{y}) \in \Rel(\VAS_i, \qini, p)\). Since \(\pi\) only projects away coordinates which can be increased by periods of \(\piin(\vectSet{L}_i)\), by taking every period of \(\piin(\vectSet{L}_i)\) a total of \(\InfinityNorm{\vect{x}}\) many times, we have \(\vect{x}_{\text{new}}:=\vect{b}+\InfinityNorm{\vect{x}} \sum_{\vect{f} \in \vectSet{F}} \vect{f}\geq \vect{x}.\) By monotonicity we obtain \((\vect{x}_{\text{new}}, \vect{y}+\vect{x}_{\text{new}}-\vect{x}) \in \Rel(\VAS_i, \qini, p)\), obtaining a run in \(\VAS_i\) starting in \(\piin(\vectSet{L}_i)\) and reaching large values as claimed.
\end{proof}

To decide the property in Lemma \ref{LemmaEquivalentPropertySix} we use the well-known \emph{backwards coverability algorithm}. It works as follows: We maintain a finite \(\vectSet{B} \subseteq \N^I\) s.t. we know for all configurations \(\vect{x} \in \vectSet{B}+\N^I\), there exists \(\vect{y} \geq \vect{b}+1^I\) with \((\vect{x}, \vect{y}) \in \Rel(\pi(\VAS_i), \qini, \qini)\). Initially we can choose \(\vectSet{B}_0:=\{\vect{b}+1^I\}\), since we can choose \(\vect{x}=\vect{y} \geq \vect{b}+1^I,\) and trivially \((\vect{x}, \vect{x}) \in \Rel(\pi(\VAS_i), \qini, \qini)\). 

Then in a loop we enlarge the set \(\vectSet{B}_i\) by ``applying transitions backwards'': If we find \(\vect{x} \not \in \vectSet{B}_i+\N^I\) s.t. \(\vect{x} \to_e \vectSet{B}_i\), then we can set \(\vectSet{B}_{i+1}=\vectSet{B}_i \cup \{\vect{x}\}\). 

In order to apply a transition \(e\) backwards at some vector \(\vect{y}\), similar to the decomposition for property P1, compute nice overapproximations \(\vectSet{L}_1, \dots, \vectSet{L}_k\) of \(\N^{I} \times \{\vect{y}\} \cap \vectSet{R}(e)\) using algorithm \(\ApproximationAlgorithm\), and improve them recursively to compute the minimal elements of \(\N^{I} \times (\vect{y}+\N^I) \cap \vectSet{R}(e)\). %, and by Lemma \ref{LemmaSameDownwardClosure}, use the corresponding basis vectors of the nice overapproximations as the backwards application of the edge.

Thankfully, the backwards coverability algorithm has an easy termination guarantee by Proposition \ref{PropositionFastGrowingComplexity}: Since we only add vectors which are not larger than a vector we already had, we produce a sequence without an increasing pair. Applying a transition backwards takes \(\mathfrak{F}_{\alpha+1}\) time similar to the decomposition for P1, and the vectors are at most in \(\N^d\), hence by Proposition \ref{PropositionFastGrowingComplexity} the complexity is at most \(\mathfrak{F}_{\alpha+d+1}\).

This procedure has the additional advantage that if P6 does not hold, then we obtain a bound \(B \in \N\) on some counter \(j \in I\) in \(\pi(\VAS_i)\). The bound \(B\) continues to hold if we readd the projected counters, i.e.\ also in \(\VAS_i\) counter \(j\) is bounded by \(B\), and we decompose by deleting counter \(j\) and instead storing it in the control state.

\textbf{Recap}: We finished the proof of Lemma \ref{LemmaActualDecomposition}, which is the last decomposition step. Hence perfectness is now decidable, and Algorithm \ref{AlgorithmMainStructure} can be implemented. It remains to give a bound on the running time and explain correctness.

\textbf{Complexity}: By Lemma \ref{LemmaCleaning} and Lemma \ref{LemmaActualDecomposition}, a single loop iteration takes time \(\mathfrak{F}_{\alpha+d+1}\). Furthermore, the rank \(\in \N^{d+1}\) decreases lexicographically. Hence we are in the setting of Proposition \ref{PropositionFastGrowingComplexity}: The sequence of ranks is a \(\mathfrak{F}_{\alpha+d+1}\)-controlled sequence in \(\N^{d+1}\) without an increasing pair, hence it has length at most \(\mathfrak{F}_{\alpha+2d+2}\).

\textbf{Correctness}: This is where the pieces of our theory fall into place. In prior versions of reachability in VASS one has to perform a complicated global argument here, but instead we only have to show the following \emph{local} property:

\begin{restatable}{lemma}{LemmaLocalCorrectness}\label{LemmaLocalCorrectness}
For all \(1 \leq i \leq r\) the relation \(\vectSet{X}_i\) has \(\vectSet{L}_i':=\) the projection of \(\LocalCharSys_i\) to the variables \(\vect{x}_i, \vect{y}_i\) as nice overapproximation.
\end{restatable}

Let us first explain why Lemma \ref{LemmaLocalCorrectness} is enough. Algorithm \ref{AlgorithmMainStructure} outputs the projection of \(\CharSys\) to \(\vect{x}_1\) and \(\vect{y}_r\) by definition, which is equal to \(\vectSet{L}_1' \circ \dots \circ \vectSet{L}_r'\). Furthermore, we have \(\vectSet{X}=\vectSet{X}_1 \circ \dots \circ \vectSet{X}_r\). We hence want to apply Lemma \ref{LemmaShiftGoodOverapproximation}, and consider the intersection \(\piout(\vectSet{L}_{i-1}') \cap \piin(\vectSet{L}_{i}')\). By P3, these sets are equal to the projection of the solutions of \(\CharSys\) to \(\vect{y}_{i-1}\) and \(\vect{x}_i\) respectively. Since \(\CharSys\) contains the equations \(\vect{y}_{i-1}=\vect{x}_i\), these sets are hence equal, in particular their intersection is non-degenerate. Hence applying Lemma \ref{LemmaShiftGoodOverapproximation} \(r-1\) times, we get that \(\vectSet{X}=\vectSet{X}_1 \circ \dots \circ \vectSet{X}_r\) has the nice overapproximation \(\vectSet{L}_1' \circ \dots \circ \vectSet{L}_r'\) as claimed.

Hence it suffices to prove Lemma \ref{LemmaLocalCorrectness}. We first need a standard lemma for VASS: An \(n\)-fold repetition of a cycle is enabled iff the first and last repetition of the cycle are.

\begin{lemma} \label{LemmaRepeatedCycleExecutable}
Let \((\vect{x}, \vect{y}) \in \Rel(\VAS_i, p,p)\) be some cycle, and \(n \in \N\). Let \((\vect{x}', \vect{y}')\) be s.t. \(\vect{y}'-\vect{x}'=n(\vect{y}-\vect{x})\) and \(\vect{x}', \vect{y}' \geq \vect{x}\). Then \((\vect{x}', \vect{y}') \in \Rel(\VAS_i, p,p)\).
\end{lemma}

\begin{proof}
Since \(\vect{x}' \geq \vect{x}\), by monotonicity we can use the cycle and hence reach \(\vect{x}'+(\vect{y}-\vect{x})=\vect{x}'+\frac{1}{n}(\vect{y}'-\vect{x}')=\frac{n-1}{n}\vect{x}'+\frac{1}{n}\vect{y}'\). This is a convex combination of vectors \(\geq \vect{x}\), and hence still \(\geq \vect{x}\). We can therefore repeat the cycle reaching \(\frac{n-2}{n}\vect{x}'+\frac{2}{n}\vect{y}'\), another such convex combination. We repeat this \(n\) times.
\end{proof}

\begin{proof}[Proof of Lemma \ref{LemmaLocalCorrectness}]
By Property P2 we have two cases: 

Case 1: \(\VAS_i\) has only one (non-loop) edge \(e_i\): Since the label \(\vectSet{L}(e_i)\) of \(e_i\) is a nice overapproximation of \(\vectSet{R}(e_i)=\Rel(\VAS_i)\), and we have \(\vectSet{L}_i'=\vectSet{L}_i \cap \vectSet{L}(e_i)\) is non-degenerate by property P4, Lemma \ref{LemmaShiftGoodOverapproximation} (this time the first part) implies that \(\vectSet{X}_i=\vectSet{R}(e_i) \cap \vectSet{L}_i\) has the nice overapproximation \(\vectSet{L}_i'\).

Case 2: \(\VAS_i\) is strongly-connected. Let \(d_i\) be the dimension of \(\VAS_i\). Write \(\vectSet{L}_i=\vect{b}_i+\N(\vectSet{F}_i)\) and let \(\vect{x}\in \vectSet{L}_i\) and \(\vect{w}\in \N_{\geq 1}(\vectSet{F}_i)\) be arbitrary. We have to show that there exists \(N \in \N\) of size at most \(\mathfrak{F}_{\alpha+2d+2}\) s.t. \(\vect{x}+\N_{\geq N}\vect{w} \subseteq \Rel(\VAS_i, \qini, \qfini)\). Write \(\vect{x}=(\vect{x}_s, \vect{x}_t)\) and \(\vect{w}=(\vect{w}_s, \vect{w}_t)\). Before we can give a further overview of the proof, we need some more setup.

By Lemma \ref{LemmaEquivalentPropertySix}, since P7 holds, we get runs \(\mathbf{up}\) and \(\mathbf{dwn}\) which are enabled at \(\piin(\vectSet{L}_i)\) and \(\piout(\vectSet{L}_i)\) respectively and increase the counters from \(\Iin\) and \(\Iout\), where \(\Iin\) is the set of counters which are not increased by some period of \(\piin(\vectSet{L}_i)\), and respectively for \(\Iout\) and \(\piout(\vectSet{L}_i)\). We remark that they might however have negative effects on \(\{1,\dots, d_i\} \setminus \Iin\) and \(\{1,\dots,d_i\} \setminus \Iout\) respectively. 

By property P3, \(\vectSet{L}_i\) is the projection of the characteristic system. In particular \(\vect{x}\) is the projection of a solution \(\vect{s}\) to the characteristic system. Similarly, \(\vect{w}\) is the projection of a homogeneous solution \(\vect{h}\), and in fact since \(\vect{w} \in \N_{\geq 1}(\vectSet{F}_i)\) uses every period, we see that \(\vect{h}\) gives value \(\geq 1\) to every auxiliary variable: Namely by property P6 every such variable is unbounded. By adding \(\vect{h}\) once to \(\vect{s}\) we w.l.o.g. assume that \(\vect{s}\) uses every edge, and therefore gives rise to a \(\Z\)-run \(\rho_{\Z}\).

Let the \(\Z\)-run corresponding to \(\vect{s}\) be \(\qini(\vect{x}_s)=\qini(\vect{c}_0) \to_{e_1} \dots \to_{e_k}\qfini(\vect{c}_k)=\qfini(\vect{x}_t)\). We can now start an overview of the proof, which will be similar to VASS:

\textbf{Goal}: We want to create (though it will not quite work out) a run of the form \(\mathbf{up}^n \mathbf{diff}^n \rho_{\Z} \mathbf{dwn}^n\) for large enough \(n\), where \(\mathbf{diff}^n\) is a run we will design, and \(\rho_{\Z}\) is as above. 

\textbf{Observations}: We know that \(\mathbf{up}\) is enabled if we add enough periods, and hence make \(\vect{x}_s\) large enough on the counters outside \(\Iin\). Similarly for \(\mathbf{dwn}\), where we need to make \(\vect{x}_t\) large enough outside \(\Iout\). Since \(\mathbf{up}\) and respectively \(\mathbf{down}\) have only positive (resp. only negative) effects, we can by monotonicity automatically apply them an arbitrary number \(n\in \N\) of times. So \(\mathbf{up}^n\) and \(\mathbf{dwn}^n\) are not an issue. Since both source and target of \(\mathbf{diff}^n\) become arbitrarily large, by Lemma \ref{LemmaRepeatedCycleExecutable} \(\mathbf{diff}^n\) is enabled for all large enough \(n\).

Hence the remaining problems are:

\begin{itemize}
\item How to choose \(\mathbf{diff}\).
\item The steps of \(\rho_{\Z}\) might be invalid without periods.
\end{itemize}

The first problem is clear, but what is an invalid step? We know that \((\vect{c}_{i-1}, \vect{c}_i) \in \Z(\vectSet{L}(e_i))\) by definition of a \(\Z\)-run. But we require \((\vect{c}_{i-1}, \vect{c}_i) \in \vectSet{R}(e_i)\) for it to be an actual run. To solve this, by monotonicity, we can w.l.o.g. assume \((\vect{c}_{i-1}, \vect{c}_i) \in \vectSet{L}(e_i)\) by increasing every configuration of the \(\Z\)-run by enough. Later we will then invoke \(\vectSet{R}(e_i) \HybridizationRelation \vectSet{L}(e_i)\) with appropriate \(\vect{w}(e_i)\) to obtain \((\vect{c}_{i-1}, \vect{c}_i) \in \vectSet{R}(e_i)\) as required. But first we turn to the construction of \(\mathbf{diff}\).

In the following we have to use the value \(\vect{s}\) assigns to the variable \(\#(e)\) for number of edges. We write \(\vect{s}[\#(e)]\) in this case, and for accessing how often the periods of edge \(e\) are used we write \(\vect{s}[\vect{p}(e)]\in \N^{\vectSet{F}(e)}\), i.e.\ this does not refer to a specific period, but rather all periods of \(\vectSet{L}(e)\) together. We will never need to single out one period.

The idea for defining \(\mathbf{diff}\) is: In order to remain an element of \(\vectSet{L}_i\), we have to remain a (projection of a) solution to the characteristic system. However, we added runs \(\mathbf{up}\) and \(\mathbf{dwn}\) damaging this fact. Hence we have to compensate them, ensuring that \(\mathbf{up}+\mathbf{diff}+\mathbf{dwn}\) is induced by a homogeneous solution of \(\CharSys\). So first we create a homogeneous solution \(k \vect{h}\) ``\(\geq \mathbf{up}+\mathbf{dwn}\)'' by choosing \(k\) large enough.

Since \(\vect{h}[\#(e)] \geq 1\) and \(\vect{h}[\vect{p}(e)] \geq \vect{1}\) for every edge \(e\), we can scale \(\vect{h}\) by an appropriate constant \(k\) to get \((k\vect{h}-\Parikh(\mathbf{up})-\Parikh(\mathbf{dwn}))[\#(e)] \geq 1\) for every \(e\), where \(\Parikh(\rho)\) is the parikh image of the run \(\rho\). Similarly, \((k \vect{h}-\Parikh(\mathbf{up})-\Parikh(\mathbf{dwn}))[\vect{p}(e)] \geq \vect{0}\) for every period \(\vect{p}(e)\). Hence there is a cycle \(\mathbf{cyc}\) with parikh image \(k \vect{h}-\Parikh(\mathbf{up})-\Parikh(\mathbf{dwn})\) using every edge. There is however a new problem: How to insert the periods, i.e.\ the \((k \vect{h}-\Parikh(\mathbf{up})-\Parikh(\mathbf{dwn}))[\vect{p}(e)]\) part?

The answer is we have to invoke \(\vectSet{R}(e) \HybridizationRelation \vectSet{L}(e)\) correctly. Write \(\mathbf{cyc}=e_1' e_2' \dots e_m'\), and for every edge \(e \in E_i\), fix a use \(e_{j(e)}'\) of edge \(e\) in \(\mathbf{cyc}\). For every \(e\in E_i\) use \(\vectSet{R}(e) \HybridizationRelation \vectSet{L}(e)\) with \(\vect{x}(e):=\dirOfRun(e_{j(e)}')\) and \(\vect{w}(e):=\vect{h}[\vect{p}(e)]\), which is possible since \(\vect{h}[\vect{p}(e)]\) uses every period of \(\vectSet{L}(e)\). We obtain a number \(N(e)\) s.t. inserting \(n \vect{h}[\vect{p}(e)]\) periods is possible for any number \(n \geq N(e)\). We define \(\knew:=k+\max_{e \in E} N(e)\).

We can now build \(\mathbf{diff}\) by adapting \(\mathbf{cyc}\): We add \((\knew \vect{h}-\Parikh(\mathbf{up})-\Parikh(\mathbf{dwn}))[\vect{p}(e)]\) times the periods \(\vect{p}(e)\) into the selected edge \(e_{j(e)}'\) of \(\mathbf{cyc}\) to obtain \(\mathbf{cyc}'\). We hence fixed the periods, but are now missing \((\knew-k)\vect{h}[\#(e)]\) uses of \(e\). We use the last unused property of perfectness: By P1 the basis \(\vect{b}(e)\in \vectSet{R}(e)\) for every \(e \in E_i\). Hence we just pick any cycle \(\mathbf{cyc}''\) with \(\Parikh(\mathbf{cyc}'')[e]=(\knew-k)\vect{h}[\#(e)]\) for every edge \(e\). \emph{We do not use any periods} in \(\mathbf{cyc}''\). We define \(\mathbf{diff}=\mathbf{cyc}' \mathbf{cyc}''\), which by construction compensates correctly.

Making the steps of \(\rho_{\Z}\) valid can be solved similarly to \(\mathbf{diff}\), and we obtain a new \(\Z\)-run \(\rho_{\Z}'\) consisting of valid steps. At this point our goal run is a run for every large enough \(n\), but we have a problem: We can so far only pump \emph{multiples of} \(\knew\) of homogeneous solutions, since we have to add full copies of \(\mathbf{up}, \mathbf{diff}\) and \(\mathbf{dwn}\), however the Lemma claims a run for \emph{every} \(m \geq N\). 

The last trick is the following: We repeat the above construction of \(\mathbf{diff}\) with \(\knewone:=\knew+1\) to obtain \(\mathbf{diff}_1\) with 
\[\Parikh(\mathbf{up})[\#(e)]+\Parikh(\mathbf{diff}_1)[\#(e)]+\Parikh(\mathbf{dwn})[\#(e)]=\knewone \vect{h}[\#(e)]\]
 for every edge \(e\) and accordingly for periods, i.e.\ we add up to \(\knewone\) many homogeneous solutions now. We define \(N:=\knew^2\), and observe that any \(m \geq N=\knew^2\) can be written as \(m=j_1 \knew + j_2 \knewone\). This allows us to define for every \(m \geq N\) the following final run proving the theorem:
 \[\rho_m:=\mathbf{up}^{j_1+j_2} \mathbf{diff}^{j_1} \mathbf{diff}_1^{j_2} \rho_{\Z}' \mathbf{dwn}^{j_1+j_2} \]
which by construction fulfills \(\dirOfRun(\rho_m)=\vect{x}+m \vect{w}\) as claimed. The arguments for why the goal run was enabled still apply to \(\rho_m\). Finally, the size of \(\rho_m\) and \(N=\knew^2\) is proportional to the runs \(\mathbf{up}\) and \(\mathbf{dwn}\), which have size \(\mathfrak{F}_{\alpha+d+1}\).
\end{proof}
































