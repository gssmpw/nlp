\section{The PRO system in practice}\label{sec:system_in_practice}

The description of Predictive Response Optimization in Section~\ref{sec:algo} is generic; i.e., it can be applied to any \osn abuse problem using any set of abuse and cost metrics. In this section we turn our theory into reality, showing how to adapt the system to detect and block bots scraping an \osn.

We worked with product and engineering teams to implement the PRO system on \fbig\ifanon (which we will denote as \ig and \fb)\fi, both of which have more than one billion monthly active users. \ig is a ``directed'' social network where people follow creators and engage with their content, while \fb is an ``undirected'' social network where users connect and engage with people they know in real life.

On each \osn we implemented the system, collected data, trained a PRO model, and conducted online controlled experiments~\cite{abtest} to compare PRO's performance with that of a ``rule-based'' baseline. Due to differences in the ways users interact with the platforms as well as the state of each \osn's infrastructure, the exact baseline rules are specific to each \osn.
Below we describe our experimental setup, measure how much more abuse PRO can stop relative to our baseline system, and document observations about how PRO adapts to changing business, system, and adversarial conditions.


\subsection{Implementation Details}

\myparagraph{Metrics.} In order to implement PRO we first need to define the ``Abuse'' and ``Cost'' metrics introduced in Section~\ref{sec:opt}. We selected the following metrics for our experiment:

\begin{itemize}
\squeezelist
    \item \scraping: Count of logged HTTP requests identified as scraping using a scaled labeling system, with each request weighted by the number of units of user-identifiable information returned to the user. The labeling system consists of a set of rules generated by security analysts and expanded by automation. For example, one rule to detect a particular scraping attack is \texttt{user-agent="python-requests/<version>" and endpoint="<endpoint\_name>"}. We use this metric to quantify abuse.
    \item \daysactive: Count of calendar days during the measurement period during which an account is observed to be active. This metric correlates with user engagement and is used to quantify cost: if PRO is over-enforcing then \emph{days active} will decrease. (Due to our normalization and sign conventions~\eqref{eq:normalization}, the actual cost metric in our model will be ``loss of days active'' relative to the no-action baseline; i.e., $days\ active(a^0) - days\ active(a)$.)
    \item \feedback: Count of calendar days during the measurement period during which the account files a bug report. This metric correlates with incorrect actions and is used to quantify cost: if PRO takes too many actions on benign users, some users will perceive the enforcement to be a bug and \feedback will increase.
\end{itemize}

\noindent Note that each of these metrics can be calculated on a per-user basis to provide training data for the RL models. They can also be aggregated across multiple users for use in the MPC controller.

\myparagraph{Actions.}
At the time of our experiments, the following actions were available on both \osns:
\begin{itemize}
\squeezelist
    \item Temporarily disable the account. %
    \item Send the account through a compromise recovery flow.
    \item Invalidate all sessions, forcing the account to re-authenticate.
    \item Invalidate all sessions, plus limit the account to a single active session (i.e., each new login invalidates the existing session).
    \item Invalidate only the suspected automated session.
    \item No action.
\end{itemize}

\noindent In addition, the following actions were also available on \ig:
\begin{itemize}
\squeezelist
    \item Show a warning dialog that the user has to acknowledge before they can make further requests.
    \item ``Challenge'' the account by sending a One-Time Passcode (OTP) via SMS to the account's phone number.
    \item Show a CAPTCHA.
\end{itemize}

Each of these actions (other than ``disable'' and ``no action'') forces the user to perform some form of authentication to regain use of their account. Our hypothesis is that different actions will have different levels of effectiveness on abusive accounts (some may go away while others may pass the challenges and continue scraping) and different impacts for benign users (some  may pass the challenges and continue as before, while others may get frustrated and stop using the OSN entirely). The PRO system's goal is to optimize response selection based on the features of the account in question.


\myparagraph{Model training.}
When the system starts running, the RL models have no data. However, because we have a baseline rule-based system, we can initialize the RL model training dataset using features and metric values after the rule-based system takes action on the entities. Once the RL system starts taking actions, it logs training data based on its own actions and can be retrained daily.

We started training daily models 2--4 weeks before the experiments so that the RL system was in a steady state by the time the experimental results were collected. On \ig, our training data sets consisted of 8 million rows (accounts) and 201 columns (features). On \fb, our training data sets consisted of 8 million rows and 15 columns. On average, model training took 3.4 hours per metric on a 26-core x86 CPU with 64 GB RAM.


To assess accuracy of the model predictions, we measure the RL models' mean squared error (MSE) against ground-truth data. To normalize the MSE (i.e., squared $\ell_2$-norm of residuals) we divide it by the squared $\ell_2$-norm of the ground-truth values.  On \ig the normalized errors for \scraping, \daysactive, and \feedback are 0.51, 0.24, and 1.13, respectively, while on \fb the respective normalized errors are 0.51, 0.33, and 0.99.  These results show that our models for \scraping and \daysactive are good predictors. The relatively high error on \feedback is due to the high sparsity of the data: we see in Tables~\ref{table:results2} and \ref{table:results1} that fewer than three users out of every thousand file a bug report.

\subsection{Experimental setup}

\myparagraph{Experiment population.}
Both \ig and \fb were running a number of automation-detection classifiers $C_1, \ldots, C_K$ prior to the deployment of PRO, as well as classifiers for producing a general account-level ``abuse score''\ifanon\else~\cite{xu2021deep}\fi, which is used in the rule-based decision logic for \fb. Each classifier outputs a real-number score $s_i \in [0,1]$, and for each classifier we computed the threshold $t_i$ giving the classifier 90\% precision according to human-labeled ground-truth data.
On each \osn we then took a random sample of accounts for which {\em any} classifier score $s_i$ was greater than $t_i$ and assigned each of these accounts with probability 0.5 to either a Control group or a Test group. Accounts in the Control group received an action determined by a rule-based system (described below), while accounts in the Test group received an action determined by PRO.

For \ig, the experiment ran from Sep 25 to Oct 8, 2023 (\igdays days), and the metrics from accounts assigned to each group were cumulatively aggregated over the entire experiment period and compared.
546,289 unique accounts were selected for the Control group and 545,949 unique accounts were selected for the Test group.

For \fb, the experiment ran from Aug 7 to Oct 3, 2023 (58 days), and the metrics were cumulatively aggregated over the final \fbdays days (Sep 20 to Oct 3, 2023) and compared.
495,083 unique accounts were selected for the Control group, and 494,724 unique accounts were selected for the Test group.

At the time of the experiments, both \osns used manually designed, rule-based action-selection algorithms. Rule-based algorithms are state-of-the-art, used by various \osns (Section~\ref{sec:bg_enforcements}), and a multi-class classification baseline is not feasible due to the inability to obtain ground truth for which actions are optimal (Section~\ref{sec:intro}). Algorithm~\ref{alg:igrules} describes a representative example of the rules on \ig for this abuse scenario, while Algorithm~\ref{alg:fbrules} does the same for \fb. The algorithms incorporate the outputs of the automation classifiers $C_1,\ldots,C_K$ described above; in particular, we assume that these classifiers all output scores in $[0,1]$, with scores closer to 1 indicating higher likelihood of automation. Algorithm~\ref{alg:fbrules} also assumes we have an ``account abuse'' classifier\ifanon\else{ }such as that described in~\cite{xu2021deep}\fi.

\begin{algorithm}[t]\caption{Response selection logic for \ig}\label{alg:igrules}
\begin{algorithmic}
    \If{$\max(\{\mbox{automation classifier scores}\}) \ge  s_1$}
        \State disable account
    \Else \ no action
    \EndIf
\end{algorithmic}
\end{algorithm}

We note that while the automation classifiers used in the experiment are retrained throughout the experiment time periods, these classifiers are shared between control and test groups and thus affect both the baseline and PRO equally, enabling us to isolate the difference in performance between rule-based and PRO action selection in the experiment.

\begin{algorithm}[t]\caption{Response selection logic for \fb}\label{alg:fbrules}
\begin{algorithmic}
    \If{$\max(\{\mbox{automation classifier scores}\}) \ge  s_1$}
        \If{
          account abuse score $\ge s_2$ {\bf or} \\
          \quad \quad last compromise recovery was $\le N_1$ days ago {\bf or} \\
          \quad \quad account was registered $\le N_2$ days ago}
            \State disable account
        \Else
            \  send account through compromise recovery flow
        \EndIf
    \Else \ no action
    \EndIf
\end{algorithmic}
\end{algorithm}

\subsection{Experimental results}
\label{ss:results}

Experimental results for \ig and \fb appear in Table~\ref{table:results2} and Table~\ref{table:results1}, respectively. Metric values are summed across the last \fbdays days of each experiment and averaged per account.
We determined statistical significance using a two-sample $t$-test. Bold $p$-values indicate statistically significant results ($p \le 0.05$).

The experimental results show that our method can significantly reduce overall $Abuse$ metrics (see Equation~\eqref{eq:objective}). In particular, on \ig, {\bf PRO reduced \scraping by \igreduction} while causing no degradation in the two $Cost$ metrics, while
on \fb, {\bf PRO reduced \scraping by \fbreduction} with no statistically significant degradation in $Cost$ metrics.

The difference of an order of magnitude between the two experimental outcomes is a result of the system's development timeline. When we first began developing PRO on \ig, the heuristic rules on that \osn were fairly rudimentary, as evidenced by Algorithm~\ref{alg:igrules}. Rather than improve the rules, we focused our efforts on implementing and optimizing PRO and were able to realize the observed massive reduction in scraping relative to the prior state. During this period, the rules on \fb increased in sophistication, and when we turned our attention to the second \osn the rules were in the state exemplified by Algorithm~\ref{alg:fbrules}. Furthermore, the PRO system implemented for \fb is a simple port of the system developed and optimized for \ig; we expect that we could realize further gains with commensurate optimization. Thus the large difference in impact between the two \osns results from (a) a more sophisticated baseline algorithm on \fb and (b) less effort invested in optimizing PRO for \fb.\footnote{The fact that error metrics for model predictions are comparable on the two \osns suggests that the difference does \emph{not} result from the \ig models using more features than the \fb models.}

\input{results_table}

\subsection{Incorporating new business considerations}
\label{ss:business}

Another key feature of PRO is the ease of re-optimizing the system to incorporate new business considerations (cf.~examples in Section \ref{sec:business_constraints}). Here we share two case studies of introducing such considerations to PRO on \ig.

\myparagraph{Case Study 1: Reducing over-enforcement.}
After observing signs of over-enforcement\footnote{Since PRO is an optimization model rather than a classification model, the concepts of ``false positive'' and ``false negative'' do not technically apply to it. However, PRO can make locally sub-optimal decisions (as determined by information obtained later). We call actions that are sub-optimal in the cost dimension ``over-enforcement'' (corresponding to false positives) and actions that are sub-optimal in the abuse dimension ``under-enforcement'' (corresponding to false negatives).}
on the \ig \surface product, we formulated a new constraint aimed at limiting the reduction in user activity on \surface, in order to serve as a ``guardrail'' against over-enforcement. To implement this constraint we added to the PRO system a new cost metric quantifying {\em days active on \surface}.

\myparagraph{Case Study 2: Reducing SMS expenditure.}
Short message service (SMS) code verification is one of our available actions on \ig. Its goal is to verify user identity and/or prevent unauthorized access and abusive traffic coming from hacked accounts. Sending these codes has an associated financial cost. In order to reduce SMS expenditures, we added a new cost metric to PRO measuring {\smscost}.

\medskip \noindent
In both of the above cases, we adjusted the PRO system according to the following steps, and in both cases compared the effects of the two reward functions:

\begin{enumerate}
\squeezelist
  \item Log account-level attribution of the new cost metric.
  \vspace{-6pt}
  \begin{enumerate}
  \squeezelist
    \item For \emph{Case Study 1}, log whether the account is active on \surface each day.
    \item For \emph{Case Study 2}, log the total expenditure due to SMS messages sent to the account each day.
  \end{enumerate}
  \vspace{-4pt}
  \item Join the cost-attribution logs with enforcement-action logs and account features to generate training data for new metric-prediction models (Section \ref{sec:reward_prediction}).
  \item Train the new metric-prediction models.
  \item Solve~\eqref{eq:mpc_objective} to determine the metric weights in the reward function of Equation~\eqref{eq:reward}, with the new constraint $Budget_k$ as one of the algorithm inputs.
  \item Update the system's reward function with the new metric weights and new metric prediction models.
\end{enumerate}


In \emph{Case Study 1}, we determined that the product impact of over-enforcement was significant enough to warrant an immediate model adjustment rather than an online controlled experiment; we therefore used a ``before and after'' approach to quantify the impact. We collected data on the previous reward function for the 7 days from Jun 20 to 26, 2023, launched the new reward function on Jun 27, and collected data from Jun 29 to Jul 5. We found that the new reward function increased \emph{days active on \surface} by \textbf{\mwebdaulossreduction} ($p = 0.02$) and decreased \scraping by \textbf{\mwebscrapingreduction} ($p = 0.006$), showing that re-weighting the reward function can both reduce cost and increase effectiveness.

In \emph{Case Study 2}, we ran an online controlled experiment, using the new reward function in the Test group and the previous reward function in the Control group.
We collected data from Sep 17 to 23, 2023 (7 days) comparing 1,277,330 accounts in Control with 1,277,823 accounts in Test.\footnote{Since this experiment involved changing PRO's metric weights, which have a smaller effect than comparing PRO with a baseline selection algorithm, we increased the size of the experiment in order to ensure statistical significance.}
The data show that we reduced \smscost by \textbf{\smsreduction} ($p \ll 0.001$) without any significant impact on \scraping ($2.0 \pm 2.6\%$ reduction; $p=0.13$). Qualitatively, we observed that PRO switched to other available enforcement actions of similar effectiveness whenever possible, reserving SMS code verification for entities where it would be most effective at stopping abuse.


\subsection{Onboarding new enforcement actions}
\label{ss:new_action}
The PRO system simplifies the process of introducing and testing new enforcement actions. In the absence of an ML-based system to select enforcement actions, action selection relies on domain expertise to create hard-coded rules that decide when to apply the new enforcement action. RL, on the other hand, addresses this ``cold-start problem'' via exploration.

\begin{figure*} %
\centering
\begin{subfigure}[t]{0.33\textwidth}
\includegraphics[width=\textwidth]{images/Figure3a.png}
\caption{Selection Rate}\label{fig:chart_4_2}
\end{subfigure}
\begin{subfigure}[t]{0.33\textwidth}
\includegraphics[width=\textwidth]{images/Figure3b.png}
\caption{$\Delta$ Automated Request Count}\label{fig:chart_4_1}
\end{subfigure}
\begin{subfigure}[t]{0.33\textwidth}
\includegraphics[width=\textwidth]{images/Figure3c.png}
\caption{$\Delta$ Time Spent}\label{fig:chart_4_3}
\end{subfigure}
\captionsetup{justification=centering,margin=1cm}
\caption{(a) Selection rate of the new enforcement action. (b) Daily deltas ($Test-Control$) of the abuse metric \automation. (c) Cost metric {\em time spent} (7-day moving average)}\label{fig:adding_action}
\end{figure*}

\myparagraph{Case Study 3: A new enforcement action.} We implemented a new enforcement action on \fb and added it to the ``library'' of PRO actions. The action invalidates existing web sessions created by the account, forcing the account to re-authenticate. In addition, it restricts the account from creating multiple concurrent sessions, allowing only one device to be logged in to \fb{} at any given time. Our hypothesis was that the new action would be more effective against accounts that use multiple concurrent sessions to perform automation, while having smaller impact on incorrectly classified users than the account-disable action, since one session is still allowed. We ran experiments with this action using the following metrics:

\begin{itemize}
\squeezelist
    \item \automation (abuse metric): Number of HTTP requests identified to be resulting from scraping (i.e., unweighted version of \scraping).
    \item \timespent (cost metric): Time duration (in seconds) that the account spends active on the \osn (i.e., continuous version of \emph{days active}).
\end{itemize}

In Figure~\ref{fig:adding_action}, we see that initially PRO does not have any knowledge about the potential impact of the new enforcement action. In this stage we observe large fluctuations in selection rate (\ref{fig:chart_4_2}), accompanied by overall sub-optimal action selection with higher numbers of \automation~(\ref{fig:chart_4_1}) and lower user-engagement metrics (\ref{fig:chart_4_3}). Around day 31, the system stabilizes with smaller shifts in action-selection rate, more optimal action selection (i.e., reduction in abuse) in the test group, and higher user-engagement metrics. At this point, the system is starting to utilize the new enforcement action more effectively.

At the end of the experiment, we aggregated metrics from the final 5 days (Aug 25 to 29, 2023) comparing 1,057,156 accounts in Control with 1,055,797 accounts in Test. Results showed the new action led to a {\bf \newresponsereduction} ($p=0.008$) reduction in \automation, and no statistically significant change in \timespent ($0.7 \pm 1.6\%$ reduction; $p=0.38$).

\subsection{Uncontrolled systemic changes}
\label{ss:adaptation}

Since our main results in Section~\ref{ss:results} are based on data aggregated over a two-week period, an important question is how the system reacts to changes in feature distributions over longer periods of time (``concept drift''). We expect the PRO system to adapt automatically to such changes since we are retraining the models daily; here we share two case studies supporting this claim.

\myparagraph{Case Study 4: Automatically adjusting to a bug.} Engineers inadvertently introduced a bug into an identity-verification challenge on \ig that asked account owners to upload photos of their face. This challenge was previously found to be effective at stopping abuse stemming from automated activity. However, the bug caused some enrolled accounts to remain in a ``stuck'' state with no ability to clear the challenge. After the bug manifested, new observed data points showed that the action had a significant negative impact on $Cost$ metrics, which led model coefficients to change significantly after the model was retrained. As a result, PRO completely stopped selecting this action two days after the bug was observed, without engineers manually altering the configuration to disallow the action from being selected.

\myparagraph{Case Study 5: Adjusting to adversarial adaptation.} We incorporated a new ``warning'' challenge into the PRO system's action suite on \ig. This challenge presents accounts suspected of automated activity with a warning notice and prevents any future web requests from being served until the account acknowledges the warning. We ran an online controlled experiment and aggregated metrics from Mar 24 to Apr 6, 2023 (14 days), comparing 803,813 accounts in Control with 803,753 accounts in Test. Results showed the addition of this new challenge led to a \textbf{15\%} reduction ($p \ll 0.001$) in \scraping and no statistically significant change in \timespent ($0.1 \pm 0.3\%$ increase; $p=0.50$). In the Test group, PRO selected the new action \textbf{13\%} of the time.

Based on these promising results, we increased the size of the experiment group. A month later (Apr 25 to May 8, 2023) we observed that the daily selection rate for the new action had a statistically significant drop ($p \ll 0.001$), falling to only \textbf{4\%}. Data analysis revealed that traffic from some abusive entities resumed almost immediately after the warning challenge was presented to them, providing evidence that some adversaries had learned how to circumvent the challenge and the system needed to select other, more effective responses to stop them. Despite this adversarial adaptation, we found that overall the 14-day rolling average of \scraping decreased by 24\% ($p = 0.006$) between Apr 6 and May 8, indicating that our changes did have beneficial impact on the overall scraping ecosystem.
