\section{Background and related work}
\label{sec:background}


Abuse on social-networking platforms can take various forms. Attackers can create fake accounts (or ``sybils'')~\cite{xiao2015detecting,gong2014sybilbelief,danezis2009sybilinfer,clickstream,uncovering_social} or compromise existing accounts, which they can then use to spread phishing links~\cite{gao2010detecting, grier2010spam}, post fraudulent reviews and advertisements~\cite{al2021spam}, disseminate fake news~\cite{elazab2018fraud}, or make fraudulent payments~\cite{caldeira2014fraud}. Such attacks motivate research on detecting and removing abusive content on social networks. 

In other types of attacks, attackers collect user data from social networks to use later for malicious purposes. Previous studies demonstrate how attackers can scrape social networks to collect user information that is then used for targeted spam and phishing~\cite{balduzzi2010abusing,jagatic2007social,brown2008social}. These attacks motivate research on detecting and blocking automated activity (i.e., ``bots'') on social networks~\cite{orabi2020detection}.

\subsection{Related work in abuse detection}
\label{sec:related_abuse}

Most prior works focus on how to detect abusive content and/or users by leveraging machine learning techniques that differentiate abusive from non-abusive entities. Such research often aims to improve the precision or recall of various supervised ML algorithms such as $k$-nearest neighbors, random forests, naive Bayes, decision trees, and neural networks~\cite{al2021spam,elazab2018fraud,caldeira2014fraud,acm2010,ceas2010,LCAI2011}. Given labeled data, these algorithms can use network information, behavioral patterns, or features generated from the content itself to detect adversaries~\cite{IEEE2016} and even to continuously detect adversaries who try to elude the model~\cite{KDD2004}. One challenge in using supervised methods is the reliance upon labeled data, which can limit the scalability of these approaches~\cite{IEEE2016}. This limitation, combined with the fact that abusive entities such as spammers also tend to act collusively, has led to the development of unsupervised methods, including graph-based and clustering methods \cite{WWW2013,ACM2014,WWW2016,IEEE2016}. Whether supervised or unsupervised, these approaches focus on detecting abusive entities but ignore the negative impact of incorrect detection. Such negative impact arises only after an enforcement action is applied to the detected entity.

\subsection{Enforcement methods}\label{sec:bg_enforcements}

After identifying abusive entities, anti-abuse systems apply {\em enforcement actions} to induce the potentially abusive actor to stop or change their behavior. In the previously discussed abuse-detection systems, generally a single action is applied for all detected abusive entities (e.g., deleting the detected fake profile or abusive content~\cite{acm2010}). In some cases, the system uses the detection confidence to choose between a ``mild'' enforcement (e.g., removing fake engagement) or a ``harsh'' enforcement (e.g., taking down accounts)~\cite{WWW2016}.

Some \osns, such as YouTube~\cite{youtube} and Facebook~\cite{meta}, use a ``strike'' system to carry out an escalating series of enforcement actions to prevent repeat offenders. On both YouTube and Facebook, the process begins with a warning. On YouTube, each strike temporarily restricts content creation, and after 3 strikes in a 90-day period the offending channel is removed~\cite{youtube}.
On Facebook, strikes 2--6 yield temporary feature-specific restrictions, while additional strikes trigger content-creation restrictions of increasing length~\cite{meta}. 
Currently there is no literature on abuse-minimization systems that addresses the problem of choosing between multiple enforcement methods based on a set of constraints; our work fills this gap.

\subsection{CAPTCHAs, challenges, and verification}

A widely used technique for combatting abuse that leverages automation (such as fake engagement or data scraping) is to present ``challenges'' that are difficult for bots to solve while remaining relatively accessible for humans. Von Ahn et al.~\cite{von2003captcha} introduced several practical proposals for designing ``CAPTCHA'' schemes for this purpose: problems that most humans can solve easily but computer programs cannot. A recent survey~\cite{guerar2021gotta} identified 10 types: text-based, image-based, audio-based, video-based, math-based, slider-based, game-based, behavior-based, sensor-based, and CAPTCHAs for liveness detection. CAPTCHAs have been used to ensure the safety of network applications~\cite{banday2011study, longe2009checking}, including chat rooms, email registration, online auctions, file sharing, and polls~\cite{pope2005human}.

Many systems also commonly use {\em multi-factor authentication} (MFA) to verify that an entity (e.g., a web session or social-media account) is being controlled by an authorized owner and not a malicious actor. Ometov et al. provided a survey of MFA methods~\cite{mfa}. Some common strategies include password re-verification, hardware tokens, voice biometrics, facial recognition, and phone or email verification. Both CAPTCHA and MFA actions are included as enforcement options within our system.

\subsection{Optimization and control}

One of our core contributions is to apply optimization and control methods to select the ``best'' enforcement action. Such methods have been leveraged in many application domains, but to date this list does not include \osn abuse.

{\em Model Predictive Control} (MPC)~\cite{arroyo2022reinforced,hewing2020learning} is a control approach that leverages a system model to predict or simulate how different inputs to the system will affect the system's output up to a certain time in the future. Based on these predictions, the operator can choose the  input that leads to most desirable output. They can then repeat the control process with new observations~\cite{holkar2010overview,hewing2020learning,recht2019tour}. MPC is robust, sample-efficient, and able to handle enforcing constraints, but it can be difficult to apply to complex systems (e.g., constructing a system model that also models uncertainty)~\cite{arroyo2022reinforced}. 

{\em Reinforcement learning (RL)}~\cite{sutton2018reinforcement} is an alternative control approach that can predict outputs of complex systems without a pre-defined model. Technically, RL is a class of algorithms that maximize specified objectives by learning from prior actions. RL algorithms include ``model-free'' approaches such as Q-learning, which learn the ``quality'' of a particular action executed while the system is in a particular state~\cite{watkins1992q,mnih2015human,kalweit2020deep}. ``Model-based'' approaches, on the other hand, learn a model for the system~\cite{sutton2018reinforcement,recht2019tour} and are related to ``system identification'' from the control field~\cite{Ljung99,recht2019tour}. RL has been used in applications such as board games (Go, chess), arcade games (PAC-MAN)~\cite{jansen2020safe, silver2018general}, recommender systems ~\cite{chow2017risk, zhao2021dear}, transport scheduling~\cite{basso2022dynamic, chinchali2018cellular, singh2020hierarchical, li2019constrained}, finance~\cite{abe2010optimizing, krokhmal2002portfolio}, and autonomous driving~\cite{gu2022constrained, isele2018safe, krasowski2020safe, kalweit2020deep}.

Prior research has combined MPC with RL to add constraints and improve safety of the RL system~\cite{arroyo2022reinforced,zanon2020safe}. Our work follows this approach, leveraging RL for learning the system and taking actions at an entity level and leveraging MPC to apply global constraints.

In the field of security, RL-based solutions have been proposed to defend against cyber-attacks on various IoT systems~\cite{uprety2020reinforcement}. RL has also been used to improve security in cognitive radio networks~\cite{ling2015application} and to detect botnets~\cite{alauthman2020efficient}. MPC has also been applied within a security context to detect cyber-attacks in microgrids~\cite{habibi2021secure}. Other work focuses on detecting attacks within networked systems controlled with MPC~\cite{barboni2018model}. However, to our knowledge, there is no prior work in any security context that explores the application of machine learning to optimize action selection from a list of possible enforcement actions.