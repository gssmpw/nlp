\begin{table*}[t]
    \caption{Formulas for calculating the weights and activation sizes of the blocks and components of EmbBERT-Q.}
    \begin{center}
        \begin{tabular}{|c | c c|}
        \hline
        \textbf{Layers} & \textbf{Weights} & \textbf{Activations} \\
        \hline \hline
        \textbf{Embedder block}           & \(r_d \cdot (v + \ell + 2 d ) + 2 d\)
                                        & \(r_d \cdot \ell + 2 d \cdot \ell\) \\ \hline \hline
        \textbf{Norm layer}          & \(2 d\)
                                        & \(2 d \cdot \ell\) \\
        \textbf{Eff. Attention block}    & \(2 d^2 \) 
                                        & \(2 d \cdot \ell + \ell^2 \)\\
        \textbf{Conv Skip block}    & \(d^2 \cdot \alpha + k \cdot d \cdot \alpha\)
                                        & \(d \cdot \ell (2 + \alpha)\)\\
                                        \hline
        \textbf{Efficient Encoder} & \(2d + 2 d^2 + d^2 \cdot \alpha + k \cdot d \alpha\)
                                        & \(\max ( 2 d \cdot \ell + \ell^2 ; \  d \cdot \ell (2 + \alpha )) \)\\
        %\textbf{MAMBA layer}            & \(i \cdot (3d + c + 2 + 3d_s + 2\rho)\)
        %                                & \( \ell \cdot (d + 3i + 2i \cdot d_s + d_s) + \max (i \cdot d_s; \ \ell \cdot d_s)  \)\\
        \hline
        \end{tabular}
    \end{center}
    \label{table:w&a_noMAMBA}
\end{table*}