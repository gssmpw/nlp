@misc{simplifying_transformer_blocks,
  author = {He, Bobby and Hofmann, Thomas},
  title = {Simplifying Transformer Blocks},
  url = {http://arxiv.org/abs/2311.01906},
  urldate = {2024-09-06},
  year = {2023},
  organization = {arXiv.org}
}

@INPROCEEDINGS{Roveri,
  author={Alippi, Cesare and Disabato, Simone and Roveri, Manuel},
  booktitle={2018 17th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Moving Convolutional Neural Networks to Embedded Systems: The AlexNet and VGG-16 Case}, 
  year={2018},
  volume={},
  number={},
  pages={212-223},
  doi={10.1109/IPSN.2018.00049}}

@misc{SwiGLU,
  author = {Shazeer, Noam},
  title = {GLU Variants Improve Transformer},
  url = {http://arxiv.org/abs/2002.05202},
  urldate = {2024-09-06},
  year = {2020},
  organization = {arXiv.org}
}

@misc{MobileBERT,
  author = {Sun, Zhiqing and Yu, Hongkun and Song, Xiaodan and Liu, Renjie and Yang, Yiming and Zhou, Denny},
  title = {MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices},
  url = {http://arxiv.org/abs/2004.02984},
  urldate = {2024-09-06},
  year = {2020},
  organization = {arXiv.org}
}

@misc{dictFormer,
  author = {Lou, Qian and Hua, Ting and Hsu, Yen-Chang and Shen, Yilin and Jin, Hongxia},
  title = {DictFormer: Tiny Transformer with Shared Dictionary},
  url = {https://openreview.net/forum?id=GWQWAeE9EpB},
  urldate = {2024-09-06},
  year = {2022},
  organization = {OpenReview}
}

@article{text_cls_survey,
  author = {Gasparetto, Andrea and Marcuzzo, Matteo and Zangari, Alessandro and Albarelli, Andrea},
  month = {02},
  pages = {83},
  title = {A Survey on Text Classification Algorithms: From Text to Predictions},
  doi = {10.3390/info13020083},
  volume = {13},
  year = {2022},
  journal = {Information}
}

@misc{ELECTRA,
  author = {Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  title = {ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators},
  url = {http://arxiv.org/abs/2003.10555},
  urldate = {2024-09-06},
  year = {2020},
  organization = {arXiv.org}
}

@misc{exploring_transformer_sizes,
  author = {Fields, Clayton and Kennington, Casey},
  editor = {Jiang, Jing and Reitter, David and Deng, Shumin},
  month = {12},
  pages = {521–531},
  publisher = {Association for Computational Linguistics},
  title = {Exploring Transformers as Compact, Data-efficient Language Models},
  doi = {10.18653/v1/2023.conll-1.35},
  url = {https://aclanthology.org/2023.conll-1.35/},
  year = {2023},
  organization = {ACLWeb}
}

@misc{byte_models,
  author = {Wu, Shangda and Tan, Xu and Wang, Zili and Wang, Rui and Li, Xiaobing and Sun, Maosong},
  title = {Beyond Language Models: Byte Models are Digital World Simulators},
  url = {http://arxiv.org/abs/2402.19155},
  urldate = {2024-09-06},
  year = {2024},
  organization = {arXiv.org}
}

@misc{efficient_transformer_survey,
  author = {Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
  title = {Efficient Transformers: A Survey},
  url = {http://arxiv.org/abs/2009.06732},
  urldate = {2024-09-06},
  year = {2020},
  organization = {arXiv.org}
}


@inproceedings{NanoBERT,
  title={NanoBERT: An Extremely Compact Language Model},
  author={Maity, Krishanu and Chaulwar, Amit Tulsidas and Vala, Vanraj and Guntur, Ravi Sankar},
  booktitle={Proceedings of the 7th Joint International Conference on Data Science \& Management of Data (11th ACM IKDD CODS and 29th COMAD)},
  pages={342--349},
  year={2024}
}

@misc{efficient_attention,
  author = {Hosseini, Mehran and Hosseini, Peyman},
  title = {You Need to Pay Better Attention: Rethinking the Mathematics of Attention Mechanism},
  url = {http://arxiv.org/abs/2403.01643},
  urldate = {2024-09-06},
  year = {2024},
  organization = {arXiv.org}
}

@misc{1bLLMs,
  author = {Ma, Shuming and Wang, Hongyu and Ma, Lingxiao and Wang, Lei and Wang, Wenhui and Huang, Shaohan and Dong, Li and Wang, Ruiping and Xue, Jilong and Wei, Furu},
  month = {02},
  title = {The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits},
  doi = {10.48550/arXiv.2402.17764},
  url = {http://arxiv.org/abs/2402.17764},
  year = {2024},
  organization = {arXiv.org}
}

@misc{transformers_modules,
  author = {Zhou, Wangchunshu and Bras, Ronan Le and Choi, Yejin},
  title = {Modular Transformers: Compressing Transformers into Modularized Layers for Flexible Efficient Inference},
  url = {http://arxiv.org/abs/2306.02379},
  urldate = {2024-09-06},
  year = {2023},
  organization = {arXiv.org}
}

@article{text_cls_survey_deep_learning,
  author = {Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng},
  month = {05},
  pages = {1-40},
  title = {Deep Learning--based Text Classification},
  doi = {10.1145/3439726},
  volume = {54},
  year = {2021},
  journal = {ACM Computing Surveys}
}

@article{survey_sentiment_analysis,
  author = {Tan, Kian Long and Lee, Chin Poo and Lim, Kian Ming},
  month = {04},
  pages = {4550},
  title = {A Survey of Sentiment Analysis: Approaches, Datasets, and Future Research},
  doi = {10.3390/app13074550},
  volume = {13},
  year = {2023},
  journal = {Applied Sciences}
}

@misc{data_augmentation,
  author = {Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  title = {GPT Understands, Too},
  url = {http://arxiv.org/abs/2103.10385},
  urldate = {2024-09-06},
  year = {2021},
  organization = {arXiv.org}
}

@misc{triple_training,
  author = {Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  title = {Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},
  url = {http://arxiv.org/abs/1908.08962},
  urldate = {2024-09-06},
  year = {2019},
  organization = {arXiv.org}
}

@article{Rotary_position_embedding,
  author = {Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  month = {02},
  pages = {127063},
  title = {RoFormer: Enhanced transformer with Rotary Position Embedding},
  doi = {10.1016/j.neucom.2023.127063},
  url = {https://arxiv.org/pdf/2104.09864.pdf},
  volume = {568},
  year = {2024},
  journal = {Neurocomputing}
}

@article{LoRA,
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  month = {10},
  title = {LoRA: Low-Rank Adaptation of Large Language Models},
  url = {https://arxiv.org/abs/2106.09685},
  year = {2021},
  journal = {arXiv:2106.09685 [cs]}
}

@misc{cutting_LLM_layers,
  author = {Yuan, Shuzhou and Nie, Ercong and Ma, Bolei and Färber, Michael},
  month = {02},
  title = {Why Lift so Heavy? Slimming Large Language Models by Cutting Off the Layers},
  doi = {10.48550/arXiv.2402.11700},
  url = {https://arxiv.org/abs/2402.11700},
  year = {2024},
  organization = {arXiv.org}
}

@misc{BERT,
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  month = {10},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  url = {https://arxiv.org/abs/1810.04805},
  year = {2018},
  organization = {arXiv.org}
}

@misc{MAMBA,
  author = {Gu, Albert and Dao, Tri},
  month = {12},
  title = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  doi = {10.48550/arXiv.2312.00752},
  url = {https://arxiv.org/abs/2312.00752},
  year = {2023},
  organization = {arXiv.org}
}

@misc{transformers_duality,
  author = {Dao, Tri and Gu, Albert},
  title = {Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality},
  url = {https://arxiv.org/abs/2405.21060},
  year = {2024},
  organization = {arXiv.org}
}

@article{GLUE,
  author = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
  month = {02},
  title = {GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  url = {https://arxiv.org/abs/1804.07461},
  year = {2019},
  journal = {arXiv:1804.07461 [cs]}
}


@misc{XLNet,
  author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V},
  title = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  url = {https://arxiv.org/abs/1906.08237},
  year = {2019},
  organization = {arXiv.org}
}

@misc{DistilBERT,
  author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  title = {DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  url = {https://arxiv.org/abs/1910.01108},
  year = {2019},
  organization = {arXiv.org}
}

@article{SpanBERT,
  author = {Joshi, Mandar and Chen, Danqi and Liu, Yinhan and Weld, Daniel S. and Zettlemoyer, Luke and Levy, Omer},
  month = {01},
  title = {SpanBERT: Improving Pre-training by Representing and Predicting Spans},
  url = {https://arxiv.org/abs/1907.10529},
  year = {2020},
  journal = {arXiv:1907.10529 [cs]}
}

@article{ALBERT,
  author = {Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  month = {02},
  title = {ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
  url = {https://arxiv.org/abs/1909.11942},
  year = {2020},
  journal = {arXiv:1909.11942 [cs]}
}

@misc{RoBERTa,
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  month = {07},
  title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  url = {https://arxiv.org/abs/1907.11692},
  year = {2019},
  organization = {arXiv.org}
}

@article{fasttext,
  author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  month = {06},
  title = {Enriching Word Vectors with Subword Information},
  url = {https://arxiv.org/abs/1607.04606},
  year = {2017},
  journal = {arXiv:1607.04606 [cs]}
}

@misc{word2vec,
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  month = {09},
  title = {Efficient Estimation of Word Representations in Vector Space},
  url = {https://arxiv.org/abs/1301.3781},
  year = {2013},
  organization = {arXiv.org}
}

@article{EfficientNET,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing},
  journal={arXiv preprint arXiv:1905.11946},
  year={2019}
}

@article{tinyBERT,
  title={Well-read students learn better: On the importance of pre-training compact models},
  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1908.08962},
  year={2019}
}

@article{transformers,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{tinyML,
  title={Tiny machine learning: progress and futures [feature]},
  author={Lin, Ji and Zhu, Ligeng and Chen, Wei-Ming and Wang, Wei-Chen and Han, Song},
  journal={IEEE Circuits and Systems Magazine},
  volume={23},
  number={3},
  pages={8--34},
  year={2023},
  publisher={IEEE}
}

@article{knowledge_distillation,
  title={Distilling the Knowledge in a Neural Network},
  author={Hinton, Geoffrey},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@incollection{quantization,
  title={A survey of quantization methods for efficient neural network inference},
  author={Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Low-Power Computer Vision},
  pages={291--326},
  year={2022},
  publisher={Chapman and Hall/CRC}
}

@article{synthetic_data,
  title={Machine learning for synthetic data generation: a review},
  author={Lu, Yingzhou and Shen, Minjie and Wang, Huazheng and Wang, Xiao and van Rechem, Capucine and Wei, Wenqi},
  journal={arXiv preprint arXiv:2302.04062},
  year={2023}
}

@article{llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{wearables,
  title={A survey on wearable technology: History, state-of-the-art and current challenges},
  author={Ometov, Aleksandr and Shubina, Viktoriia and Klus, Lucie and Skibi{\'n}ska, Justyna and Saafi, Salwa and Pascacio, Pavel and Flueratoru, Laura and Gaibor, Darwin Quezada and Chukhno, Nadezhda and Chukhno, Olga and others},
  journal={Computer Networks},
  volume={193},
  pages={108074},
  year={2021},
  publisher={Elsevier}
}

@misc{iot,
author="Kopetz, Hermann
and Steiner, Wilfried",
title="Internet of Things",
bookTitle="Real-Time Systems: Design Principles for Distributed Embedded Applications",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="325-341",
isbn="978-3-031-11992-7",
doi="10.1007/978-3-031-11992-7_13",
url="https://doi.org/10.1007/978-3-031-11992-7_13"
}

@misc{differential_transformers,
  author = {Ye, Tianzhu and Dong, Li and Xia, Yuqing and Sun, Yutao and Zhu, Yi and Huang, Gao and Wei, Furu},
  title = {Differential Transformer},
  url = {https://arxiv.org/abs/2410.05258},
  year = {2024},
  organization = {arXiv.org}
}

@misc{on_device_kw_spotting,
  author = {Cioflan, Cristian and Cavigelli, Lukas and Rusci, Manuele and Prado, de and Benini, Luca},
  title = {On-Device Domain Learning for Keyword Spotting on Low-Power Extreme Edge Embedded Systems},
  url = {https://arxiv.org/abs/2403.10549},
  urldate = {2024-12-16},
  year = {2024},
  organization = {arXiv.org}
}

@article{customizable_kw_spotting,
  author = {Manuele Rusci and Tinne Tuytelaars},
  month = {09},
  pages = {50-57},
  publisher = {Institute of Electrical and Electronics Engineers},
  title = {On-Device Customization of Tiny Deep Learning Models for Keyword Spotting With Few Examples},
  doi = {10.1109/mm.2023.3311826},
  url = {https://ieeexplore.ieee.org/abstract/document/10241972},
  urldate = {2024-12-16},
  volume = {43},
  year = {2023},
  journal = {IEEE Micro}
}

@misc{transfer_learning_kw_spotting,
  title = {Open Vocabulary Keyword Spotting through Transfer Learning from Speech Synthesis},
  url = {https://arxiv.org/html/2404.03914v1},
  urldate = {2024-12-16},
  year = {2024},
  organization = {Arxiv.org}
}

@article{EfficientDet_obj_det,
  author = {Tan, Mingxing and Pang, Ruoming and Le, Quoc V.},
  month = {07},
  title = {EfficientDet: Scalable and Efficient Object Detection},
  url = {https://arxiv.org/abs/1911.09070},
  year = {2020},
  journal = {arXiv:1911.09070 [cs, eess]}
}

@misc{real_time_obj_det,
  author = {Gupta, Anurag and Yadav, Darshan and Raj, Akash and Pathak, Ayushman},
  month = {05},
  publisher = {Valley International},
  title = {Real-Time Object Detection Using SSD MobileNet Model of Machine Learning},
  url = {https://www.researchgate.net/publication/371429419_Real-Time_Object_Detection_Using_SSD_MobileNet_Model_of_Machine_Learning},
  year = {2023},
  organization = {ResearchGate}
}

@misc{micro_net_img_rec,
  author = {Li, Yunsheng and Chen, Yinpeng and Dai, Xiyang and Chen, Dongdong and Liu, Mengchen and Yuan, Lu and Liu, Zicheng and Zhang, Lei and Vasconcelos, Nuno},
  title = {MicroNet: Towards Image Recognition with Extremely Low FLOPs},
  url = {https://arxiv.org/abs/2011.12289},
  urldate = {2024-12-16},
  year = {2020},
  organization = {arXiv.org}
}

@misc{mobilenet_v2,
  author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  title = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  url = {https://arxiv.org/abs/1801.04381},
  year = {2018},
  organization = {arXiv.org}
}

@misc{transformers_compression,
  author = {Tang, Yehui and Wang, Yunhe and Guo, Jianyuan and Tu, Zhijun and Han, Kai and Hu, Hailin and Tao, Dacheng},
  month = {04},
  title = {A Survey on Transformer Compression},
  doi = {10.48550/arXiv.2402.05964},
  url = {https://arxiv.org/abs/2402.05964},
  year = {2024},
  organization = {arXiv.org}
}

@article{NN_for_mobile,
  author = {Yang, Tien-Ju and Howard, Andrew and Chen, Bo and Zhang, Xiao and Go, Alec and Sandler, Mark and Sze, Vivienne and Adam, Hartwig},
  month = {09},
  title = {NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications},
  url = {https://arxiv.org/abs/1804.03230},
  year = {2018},
  journal = {arXiv:1804.03230 [cs]}
}

@misc{Eff_NN_for_embedded,
  title = {Resource-Efficient Neural Networks for Embedded Systems},
  url = {https://arxiv.org/html/2001.03048v3},
  urldate = {2024-12-16},
  year = {2024},
  organization = {Arxiv.org}
}

@article{MCUNet,
  author = {Lin, Ji and Chen, Wei-Ming and Lin, Yujun and Cohn, John and Gan, Chuang and Han, Song},
  month = {11},
  title = {MCUNet: Tiny Deep Learning on IoT Devices},
  url = {https://arxiv.org/abs/2007.10319},
  year = {2020},
  journal = {arXiv:2007.10319 [cs]}
}

@article{i-BERT,
  author = {Kim, Sehoon and Amir Gholaminejad and Yao, Zhewei and Mahoney, Michael and Eecs Kurt Keutzer},
  month = {01},
  publisher = {Cornell University},
  title = {I-BERT: Integer-only BERT Quantization},
  doi = {10.48550/arxiv.2101.01321},
  year = {2021},
  journal = {arXiv (Cornell University)}
}

@article{ConvBERT,
  author = {Jiang, Zihang and Yu, Weihao and Zhou, Daohong and Chen, Yunpeng and Feng, Jiashi and Yan, Shuicheng},
  month = {08},
  publisher = {Cornell University},
  title = {ConvBERT: Improving BERT with Span-based Dynamic Convolution},
  doi = {10.48550/arxiv.2008.02496},
  year = {2020},
  journal = {arXiv (Cornell University)}
}


@article{STT_embedded,
  author = {Rawoof, Abdul and None Kulesh and Ray, Kailash Chandra},
  month = {01},
  title = {ARM Based Implementation of Text-to-Speech (TTS) for Real Time Embedded System},
  doi = {10.1109/icsip.2014.36},
  url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6754875},
  urldate = {2024-12-17},
  year = {2014},
  journal = {}
}

@InProceedings{nlu_dataset,
  author    = {Xingkun Liu, Arash Eshghi, Pawel Swietojanski and Verena Rieser},
  title     = {Benchmarking Natural Language Understanding Services for building Conversational Agents},
  booktitle = {Proceedings of the Tenth International Workshop on Spoken Dialogue Systems Technology (IWSDS)},
  month     = {April},
  year      = {2019},
  address   = {Ortigia, Siracusa (SR), Italy},
  publisher = {Springer},
  pages     = {xxx--xxx},
  url       = {http://www.xx.xx/xx/}
}

@InProceedings{imdb_dataset,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@inproceedings{emotion_dataset,
    title = "{CARER}: Contextualized Affect Representations for Emotion Recognition",
    author = "Saravia, Elvis  and
      Liu, Hsien-Chi Toby  and
      Huang, Yen-Hao  and
      Wu, Junlin  and
      Chen, Yi-Shin",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1404",
    doi = "10.18653/v1/D18-1404",
    pages = "3687--3697",
}

@inproceedings{ag_news_dataset,
  title={Character-level Convolutional Networks for Text Classification},
  author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},
pages={0-1},
  booktitle={NIPS},
  year={2015}
}

@misc{cyberbull_dataset,
  author = {Wang, Jason and Fu, Kaiqun and Lu, Chang-Tien},
  title = {SOSNet: A Graph Convolutional Network Approach to Fine-Grained Cyberbullying Detection},
  url = {https://people.cs.vt.edu/ctlu/Publication/2020/IEEE-BD-SOSNet-Wang.pdf},
  year = "2020"
}

@inproceedings{limit_dataset,
    title = "{L}i{M}i{T}: The Literal Motion in Text Dataset",
    author = "Manotas, Irene  and
      Vo, Ngoc Phuoc An  and
      Sheinin, Vadim",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.88",
    doi = "10.18653/v1/2020.findings-emnlp.88",
    pages = "991--1000",
    abstract = "Motion recognition is one of the basic cognitive capabilities of many life forms, yet identifying motion of physical entities in natural language have not been explored extensively and empirically. We present the Literal-Motion-in-Text (LiMiT) dataset, a large human-annotated collection of English text sentences describing physical occurrence of motion, with annotated physical entities in motion. We describe the annotation process for the dataset, analyze its scale and diversity, and report results of several baseline models. We also present future research directions and applications of the LiMiT dataset and share it publicly as a new resource for the research community.",
}

@article{qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@InProceedings{bookcorpus,
    title = {Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books},
    author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
pages = {-},
    booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
    month = {December},
    year = {2015}
}

@misc{bitsandbytes,
  author = {HuggingFace},
  title = {BitsAndBytes},
  url = {https://github.com/bitsandbytes-foundation/bitsandbytes/tree/main},
  urldate = {2024-12-27},
    year = {2024}
}