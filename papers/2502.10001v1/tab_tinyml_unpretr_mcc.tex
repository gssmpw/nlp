\begin{table*}[tbp]
    \caption{Evaluation of MCC score of non-pretrained models on the TinyNLP benchmark.}
    \begin{center}
        \begin{tabular}{| c | c c c c c c c c |}
        \hline
        \textbf{Models} & \href{https://huggingface.co/datasets/stanfordnlp/imdb}{\textbf{IMDb}} & \href{https://huggingface.co/datasets/fancyzhx/ag_news}{\textbf{ag\_news}} & \href{https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification}{\textbf{cyberbull}} & \href{https://huggingface.co/datasets/IBM/limit}{\textbf{LiMiT}} & \href{https://huggingface.co/datasets/dair-ai/emotion}{\textbf{Emotion}} & \href{https://huggingface.co/datasets/xingkunliuxtracta/nlu_evaluation_data}{\textbf{nlu}} & \href{https://huggingface.co/datasets/benayas/snips}{\textbf{Snips}} & \textbf{Average} \\
        \hline \hline
        \textbf{BERT(2MB)}           &  58,10 & 85,25 & 79,45 & 40,13 & 78,35 & 84,05 & 96,00 & 74,48 \\
        \textbf{MAMBA(2MB)}          &  56,62 & 88,14 & 80,82 & 42,62 & 70,84 & 86,22 & 96,86 & 74,59 \\
        \textbf{Embedder}           & 82,60 & 91,10 & 82,78 & 71,60 & 89,40 & 89,50 & \textbf{97,93} & 86,41 \\
        \textbf{Embedder~+~Conv}      & 84,08 & \textbf{91,50} & 83,10 & 70,32 & 89,45 & 89,33 & 97,75 & 86,50 \\
        \textbf{BERT~+~NE}            & 65,06 & 87,82 & 79,86 & 38,30 & 72,34 & 82,42 & 96,20 & 74,57 \\

        \textbf{BERT~+~NE~+~EA}         & 63,32 & 87,35 & 79,13 & 20,67 & 78,85 & 83,30 & 95,93 & 72,65 \\

        \hline
        \textbf{EmbBERT}            & 66,32 & 87,78 & 79,26 & 38,42 & 60,78 & 74,66 & 94,40 & 71,66 \\
        \hline
        \end{tabular}
        \label{table:all_results_tinyNLP_mcc_unpretr}
    \end{center} 
\end{table*}







