

\begin{table*}[htbp]
    \caption{Evaluation of pretrained and finetuned models on the GLUE benchmark (Embedder and Embedder~+~Conv are directly trained on the donwstream datasets). We report SCC for STSB, MCC for CoLA, F1~score for QQP and MRPC, Accuracy for the remaining GLUE tasks.}
    \begin{center}
    \resizebox{\textwidth}{!}{
        \begin{tabular}{| c | c c c c c c c c c c | c |}
        \hline
        \textbf{Models} & COLA & SST-2 & MRPC & QQP & MNLI-m & MNLI-mm & QNLI & RTE & WNLI & STSB & Score \\
        \hline
        \textbf{BERT(2MB)}           & -0,86 & 71,28 & 64,66 & 73,04 & 60,56 & 61,58 & 60,82 & 48,24 & 66,20 & 15,48 & 52,10   \\
        \textbf{MAMBA(2MB)}          & 2,56  & \textbf{81,16} & 64,62 & 79,18 & 61,22 & 61,40 & 63,20 & 50,20 & 76,62 & 10,16 & 55,03 \\
        \textbf{Embedder}           & 9,65  & 78,90 & 62,25 & \textbf{83,28} & 62,06 & 62,17 & 65,40 & 52,73 & 77,20 & 15,58 & 56,92 \\
        \textbf{Embedder~+~Conv}      & 9,25  & 79,10 & 60,50 & 82,98 & 61,98 & 60,93 & 62,08 & 52,00 & 79,16 & 16,10 & 56,41 \\
        \textbf{BERT~+~NE}            & 9,04  & 78,82 & 65,04 & 79,96 & 63,08 & 63,30 & 63,20 & 51,76 & 87,30 & 13,46 & 57,50 \\
        \textbf{BERT~+~EA}            & 10,06 & 79,44 & 66,48 & 78,88 & 60,82 & 60,82 & 63,50 & 50,76 & 22,24 & 17,92 & 51,09 \\
        \textbf{BERT~+~NE~+~EA}         & 18,70 & 79,60 & 65,36 & 82,66 & 67,06 & 67,44 & 67,44 & 53,66 & 86,74 & 23,34 & 61,20 \\
        \textbf{BERT~+~NE~+~EA (8bit)}  & 9,57  & 77,87 & 63,40 & 48,93 & 34,19 & 33,59 & 59,58 & \textbf{53,79} & 59,15 & 19,58 & 45,97 \\
        \hline  
        \textbf{EmbBERT}            & \textbf{11,01} & 79,33 & \textbf{69,19} & 83,25 & \textbf{67,83} & \textbf{68,63} & \textbf{68,92} & 49,96 & \textbf{87,61} & 49,25 & \textbf{63,50} \\
        \textbf{EmbBERT-Q}      & 9,56  & 80,96 & 67,99 & 82,45 & 67,10 & 68,05 & 68,06 & 47,29 & 87,32 & \textbf{49,28} & 62,81 \\
        \hline
        \end{tabular}

    \label{table:res_glue_comp}
    }
    \end{center}

    
\end{table*}
