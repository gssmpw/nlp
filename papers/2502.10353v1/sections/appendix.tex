\section{Extended Experiments}
\label{sec:more_experiments}
\paragraph{More patients than providers}
\begin{figure*}
    \includegraphics[width=\textwidth]{figures/vary_providers_patients_matches.pdf}
    \caption{We compare the match rate across policies when varying the patient/provider ratio, and find that the greedy and gradient descent policies perform best, while the group-based and pairwise policies lag.}
    \label{fig:match_rate_varied_n}
\end{figure*}
We compare the match rate across policies from Example~\ref{ex:patient_provider} and find that the gradient descent and greedy policies achieve the highest match rate for large patient/provider ratios (see Figure~\ref{fig:match_rate_varied_n}). 
As shown in Section~\ref{sec:greedy}, the greedy policy achieves the highest match rate for the uniform choice model, so it is unsurprising that it achieves the highest match rate. 
Beyond that, the high performance of gradient descent matches the trends with match quality in Example~\ref{ex:patient_provider}. 

\paragraph{Impact of $p$ and $\theta$}
\begin{figure*}
    \includegraphics[width=\textwidth]{figures/policy_comparison_matches.pdf}
    \caption{For $p \leq 0.5$, we find that all four policies achieve the same match rate, while for $p \geq 0.75$, we find that gradient descent achieves a slightly lower match rate compared to the greedy, pairwise, and group-based policies. }
    \label{fig:match_rate_varied_p}
\end{figure*}
We extend Example~\ref{ex:comparison} to compare the match rates across policies when varying $p$ and $\theta$ in Figure~\ref{fig:match_rate_varied_p}. 
All non-random policies have similar match rates for $p \leq 0.5$, implying that match quality is better at differentiating policies than match rate.
For larger $p$, the gradient descent policy performs slightly worse in match rate, while the greedy, pairwise, and group-based policies achieve the same match rate. 
As in Example~\ref{ex:comparison}, we find that the best-performing policies for match quality also tend to exhibit the highest match rate (in this case, the group-based policy is optimal for both). 

\paragraph{Misspecified Choice Models}
\begin{figure*}
    \centering 
    \includegraphics[width=\textwidth]{figures/misspecification.pdf}
    \caption{We evaluate the performance of policies when the observed match probability, $\hat{p}$, differs from the true match probability, $p$. We find that the observed match probability has little impact on the relative ordering of policies, although the group-based policy improves as $p$ and $\hat{p}$ get closer.} 
    \label{fig:misspecification}
\end{figure*}
Our experiments in Section~\ref{sec:empirical} consider situations with known values of $p$, but real-world scenarios frequently involve misspecified choice models. 
To model this, we run policies with some observed match probability $\hat{p}$ while letting $p$ be the match probability. 
This setup allows us to simulate real-world scenarios where match probability is unknown. 
We compare policies across $\hat{p} \in \{0.1,0.25,0.5,0.75,0.9\}$ and $p \in \{0.1,0.25,0.5,0.75,0.9\}$.

In Figure~\ref{fig:misspecification}, we demonstrate that most policies perform similarly across $\hat{p}$ for fixed $p$. 
This trend holds because the random, greedy, and pairwise policies are unimpacted by $\hat{p}$. 
We find that the group-based policy gets worse as $\hat{p}$ and $p$ differ; for example, when $p=0.9$ and $\hat{p}=0.1$, the group-based policy performs worse than the pairwise policy, while when $\hat{p}=0.9$, the policies perform similarly. 
We note that the differences are slight even for the group-based policy, so our policies are generally robust to misspecification in match probabilities. 

\section{Proofs}
\label{sec:proofs}
% \begin{lemma}
%     \label{thm:tuple_policy}
%     Let $M=1$, $\theta_{N,1}=1$, and $\theta_{1,1}=\theta_{2,1}=\cdots\theta_{N-1,1}=\alpha$ for some $\alpha$. 
%     For a given policy $\pi$, consider the tuple $(k_{1},k_{2})$, where $k_{1} = \pi(\theta)_{N,1}$ and $k_{2} = \sum_{i=1}^{N-1} \pi(\theta)_{i,1}$. 
%     Let $\pi^{(1)}$ and $\pi^{(2)}$ be two policies such that $\pi^{(1)}(\theta)_{N,1} = \pi^{(2)}(\theta)_{N,1}$ and $\sum_{i=1}^{N-1} \pi^{(1)}(\theta)_{i,1} = \sum_{i=1}^{N-1} \pi^{(2)}(\theta)_{i,1}$ then 
%     \begin{equation}
%         \mathbb{E}_{\sigma}[\sum_{t=1}^{N}  (f_{\sigma_{t}}\left(\pi^{(1)}(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right) \cdot \theta_{\sigma_{t}})]  = \mathbb{E}_{\sigma}[\sum_{t=1}^{N} (f_{\sigma_{t}}\left(\pi^{(2)}(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right)  \cdot \theta_{\sigma_{t}})]  
%     \end{equation}
% \end{lemma}
% \begin{proof}
%     For any policy $\pi$, when $M=1$, we can write the expected aggregate match quality as 
%     \begin{equation}
%         \mathbb{E}_{\sigma}[\sum_{t=1}^{N}  (f_{\sigma_{t}}\left(\pi^{(1)}(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right) \cdot \theta_{\sigma_{t}})] = (1-p)^{\sum_{i=1}^{N} \pi(\theta)_{i,1}} \frac{\sum_{i=1}^{N} \pi(\theta)_{i,1} \theta_{i,1}}{\sum_{i=1}^{N} \pi(\theta)_{i,1}}.
%     \end{equation}
%     The first term corresponds to the probability that any patient matches to the provider, while the second term corresponds to the average match quality across these patients. 
%     We note that $\theta_{N,1} = 1$ and $\theta_{i,1}=\alpha$ for $\alpha \leq N-1$, so we rewrite this as 
%     \begin{equation}
%         (1-(1-p)^{\sum_{i=1}^{N} \pi(\theta)_{i,1}}) \frac{\sum_{i=1}^{N} \pi(\theta)_{i,1} \theta_{i,1}}{\sum_{i=1}^{N} \pi(\theta)_{i,1}} = (1-(1-p)^{\sum_{i=1}^{N-1} \pi(\theta)_{i,1} + \pi(\theta)_{i,N}}) \frac{\alpha \sum_{i=1}^{N-1} \pi(\theta)_{i,1} + \pi(\theta)_{i,N}}{\sum_{i=1}^{N-1} \pi(\theta)_{i,1} + \pi(\theta)_{i,N}}
%     \end{equation}
%     For a policy $\pi$, let $k_{1}(\pi) = \sum_{i=1}^{N-1} \pi(\theta)_{i,1}$ and let $k_{2}(\pi) = \pi(\theta)_{N,1}$. 
%     Then we can rewrite the aggregate match quality as 
%     \begin{equation}
%         (1-(1-p)^{\sum_{i=1}^{N-1} \pi(\theta)_{i,1} + \pi(\theta)_{i,N}}) \frac{\alpha \sum_{i=1}^{N-1} \pi(\theta)_{i,1} + \pi(\theta)_{i,N}}{\sum_{i=1}^{N-1} \pi(\theta)_{i,1} + \pi(\theta)_{i,N}} =  (1-(1-p)^{k_{1}(\pi) + k_{2}(\pi)}) \frac{\alpha k_{1}(\pi) + k_{2}(\pi)}{k_{1}(\pi) + k_{2}(\pi)}
%     \end{equation}
%     For $\pi^{(1)}$ and $\pi^{(2)}$, we have $k_{1}(\pi^{(1)}) = k_{1}(\pi^{(1)})$ and $k_{2}(\pi^{(1)}) = k_{2}(\pi^{(2)})$. 
%     Because aggregate match quality is fully defined through $k_{1}(\pi)$ and $k_{2}(\pi)$, both policies achieve the same aggregate reward. 
% \end{proof}

% \thmorderinggap* 
% \begin{proof}
% Given a value of $\theta$, we select a $\theta$ and $p$ so 
% \begin{equation}
%     \mathbb{E}_{\sigma}[\sum_{t=1}^{N}  (f_{\sigma_{t}}\left(\pi(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right) \cdot \theta_{\sigma_{t}})]  \leq \epsilon \mathbb{E}_{\sigma}[\sum_{t=1}^{N} (f_{\sigma_{t}}\left(\pi_{O}^{*}(\theta,\sigma)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right)  \cdot \theta_{\sigma_{t}})]  
% \end{equation}
% Consider a situation with $N$ patients and $M=1$ providers. 
% Let $\theta_{N,1}=1$ and $\theta_{1,1}=\theta_{2,1}=\cdots\theta_{N-1,1}=\alpha$, where we set $N$ and $\alpha \in [0,1]$ later. 
% From Lemma~\ref{thm:tuple_policy}, we can characterize any order-unaware policy $\pi(\theta)$ through the tuple $(k_{1}(\pi),k_{2}(\pi))$, where $k_{1} = \sum_{i=1}^{N-1} \pi(\theta)_{i,1}$ and $k_{2} = \pi(\theta)_{N,1}$. 

% We will next demonstrate that policies with $k_{2}(\pi)=1$ achieve a higher aggregate match quality compared to policies with $k_{1}(\pi)=0$. 
% From Lemma~\ref{thm:tuple_policy}, we know that the aggregate match quality is
% \begin{equation}
%     (1-(1-p)^{k_{1}(\pi) + k_{2}(\pi)}) \frac{\alpha k_{1}(\pi) + k_{2}(\pi)}{k_{1}(\pi) + k_{2}(\pi)}
% \end{equation}
% For fixed $p \in [0,1]$ and $k_{1}(\pi)$, we note that $(1-(1-p)^{k_{1}(\pi)}) \leq (1-(1-p)^{k_{1}(\pi) + 1})$ and for $\alpha \in [0,1]$ we have $\frac{\alpha k_{1}(\pi)}{k_{1}(\pi)} \leq \frac{\alpha k_{1}(\pi) + 1}{k_{1}(\pi) + 1}$. 
% Therefore, for fixed $k_{1}(\pi)$, policies with $k_{2}(\pi)=1$ achieve a higher or equal aggregate match quality compared with $k_{2}(\pi)=0$. 

% We next construct an order-aware policy, $\pi^{*}$. 
% Let $t^{*}$ be the location of patient $N$ in the order $\sigma$; $\sigma_{t^{*}} = N$. 
% Then the order-aware policy constructs an assortment, $\mathbf{X}^{*}$, such that $\mathbf{X}^{*}_{\sigma_{t},1} = 1 \forall t \geq t^{*}$. 
% That is, the single provider $j=1$ is offered to patient $N$ and all patients following patient $N$ in $\sigma$. 
% This results in an expected match quality of $p$ for patient $N$, and $(1-p) \alpha (1-(1-p)^{l})$ for the $l$ patients that follow after patient $N$. 
% Because $\sigma$ is uniformly random, the value of $l$ is randomly chosen from 0 to $N-1$, so we get that the aggregate match quality for the order aware scenario is 
% \begin{equation}
%     \frac{1}{N} \sum_{l=0}^{N-1} ((1-(1-p)^{l}) \alpha (1-p) + p) = p+\frac{\alpha(1-p)}{N} \sum_{l=0}^{N-1} (1-(1-p)^{l}) 
% \end{equation}


% Taking the ratio between the order-unaware and order-aware policies gives
% \begin{align}
%     \frac{(1-(1-p)^{1+k_{1}(\pi)}) \frac{1+\alpha k_{1}}{1+k_{1}(\pi)}}{p+\frac{\alpha (1-p)}{N} \sum_{l=0}^{N-1} (1-(1-p)^{l})} \\ = \frac{(1-(1-p)^{1+k_{1}(\pi)}) (\frac{1}{1+k_{1}(\pi)})(1+\alpha k_{1}(\pi))}{p+\alpha (1-p) - \frac{\alpha (1-p)}{N}  \sum_{l=0}^{N-1} (1-p)^{l}}
% \end{align}

% Next, we find the optimal value $k_{2}(\pi)$ for a given $p$ by computing the derivative: 
% \begin{equation}
%     \frac{\mathrm{d}}{\mathrm{d}k_{1}} (1-(1-p)^{1+k_{1}}) \frac{1+\alpha k_{1}}{1+k_{1}} = \frac{(1-p)^{k_{1}} (p-1) (\log(1-p) (k_{1}+1)(k_{1}+8) -7)-7}{8(k_{1}+1)^{2}}.
% \end{equation}
% As $p$ goes to $0$, $\log(1-p)$ is unbounded from below and approaches negative infinity; therefore, for any selection of $N$, there exists a $p$ so that $\frac{(1-p)^{k_{1}(\pi)} (p-1) (\log(1-p) (k_{1}(\pi)+1)(k_{1}+8) -7)-7}{8(k_{1}(\pi)+1)^{2}} \leq 0$ for all $0 \leq k_{1}(\pi) \leq N$. 
% That is, for sufficiently small $p$, the optimal policy order-unaware has $k_{1}(\pi) = 0$. 
% For small $p$, this approximation approaches 
% \begin{equation}
%     \lim_{p \rightarrow 0} \frac{p}{p + \frac{1-p}{8} - (1-p) \frac{1}{8pN} (1-(1-p)^{N})} = 0
% \end{equation}
% Therefore, for sufficiently small $p$, the ratio between the optimal order-unaware and an order aware policy approaches 0, and therefore the order-unaware policy is an $\epsilon$ approximation to the order aware policy. 
% \end{proof}

\thmmone* 
\begin{proof}
Suppose that $s$ patients are offered the provider $j=1$: $\lVert \mathbf{X} \rVert_{1} = s$. 
In the uniform choice model, the probability that any of the $s$ patients select the single provider is $p$, so the probability of provider $j=1$ matching is $1-(1-p)^{s}$. 
By symmetry in the response order, the chance that each patient is selected is equal, and so the match quality is 
\begin{equation}
    (1-(1-p)^{s}) \frac{\sum_{i=1}^{N} \theta_{i,1} \mathbf{X}_{i,1}}{s}
\end{equation}
For fixed $s$, the optimal assortment selects the $s$ largest values of $\theta_{i,1}$. 
Next, we note that larger values of $s$ increase the match probability $(1-(1-p)^{s})$, but could decrease the average match quality for the selected patient, $\frac{\sum_{i=1}^{N} \theta_{i,1} \mathbf{X}_{i,1}}{s}$. 
To balance between the two factors, we can iterate through values of $s$ and compute $(1-(1-p)^{s})$ and $\frac{\sum_{i=1}^{N} \theta_{i,1} \mathbf{X}_{i,1}}{s}$. 
\end{proof}

\thmgreedy* 
\begin{proof}
    We construct a problem instance where the greedy policy achieves an $\epsilon$ fraction of the optimal match quality. 
    Let $N=M$ and construct $\theta$ as follows: let $\theta_{1,1} = 1$, while $\theta_{i,1} = 2 \Delta$ for $i \neq 1$, where $\Delta \leq \frac{1}{2}$. Let $\theta_{i,j} = \Delta$ for all $i$ and $j \neq 1$. 

    Let $\pi$ be the policy so that $\pi(\theta)_{i} = \mathbf{e}_{i}$. 
    The expected match quality for this policy is $p(\Delta (N-1) + 1)$; for patients 2 to $N$, it achieves an expected match quality of $p(\Delta (N-1))$ in total, while for patient $1$ it achieves an expected match quality of $p$. 
    Because $\pi^{*}(\theta)$ is optimal, we have  
    \begin{equation}
        p(\Delta (N-1) + 1) = \mathbb{E}_{\sigma}[\sum_{t=1}^{N}  (f_{\sigma_{t}}\left(\pi(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right) \cdot \theta_{\sigma_{t}})] \leq \mathbb{E}_{\sigma}[\sum_{t=1}^{N}  (f_{\sigma_{t}}\left(\pi^{*}(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right) \cdot \theta_{\sigma_{t}})]
    \end{equation}

    Next, consider the greedy policy where $\pi^{R}(\theta) = \mathbf{1}$.
    All patients prefer provider $1$, and because of this, all patients have an equal likelihood of matching with provider $1$. 
    Each patient has a $\frac{1}{N}$ chance of matching with provider $1$, and therefore the expected match quality for provider $1$ is $\frac{1}{N} + \frac{N-1}{N} (2 \Delta)$. 
    For all the $N-1$ other providers, we receive a reward of $\Delta$ upon matching, and each patient matches with probability $p$; therefore, we receive a total match quality of at most $\frac{1}{N} + 2  \frac{N-1}{N} \Delta + p(N-1) \Delta$. 
    Taking the ratio of the greedy and optimal policies yields the following: 
    \begin{align*}
        \frac{\frac{1}{N} + \frac{2\Delta(N-1)}{N} + p(N-1) \Delta}{p (\Delta (N-1) + 1)} \\
         \leq \frac{\frac{1}{N} + 2\Delta + p(N-1) \Delta}{p(\Delta (N-1) + 1)} \\ \leq \frac{\frac{1}{N} + 2\Delta + p(N-1) \Delta}{p} \\ 
         \leq \frac{1}{Np} + \frac{2\Delta}{p} + N \Delta 
    \end{align*}
    Finally, letting $N=\frac{3}{\epsilon p}$ and $\Delta = \min(\frac{\epsilon}{3N},\frac{p\epsilon}{6})$ yields that 
    \begin{equation}
       \frac{1}{Np} + 2\frac{\Delta}{p} + N \Delta \leq \frac{\epsilon}{3} + \frac{\epsilon}{3} + \frac{\epsilon}{3} = \epsilon   
    \end{equation}
    Therefore, for any choice of $\epsilon$ and $p$, there exists a choice of  $\theta$ so the greedy policy is at most an $\epsilon$ approximation. 
\end{proof}

\thmlp*
\begin{proof}
    The pairwise policy constructs an assortment so each patient is only offered one provider, and no provider is offered to more than one patient. 
    Under this scenario, each patient offered a non-zero assortment matches with probability $p$; that is, if $\pi^{P}(\theta)_{i,j}=1$, then the expected match quality is $p \theta_{i,j}$. 
    The match quality is then $\frac{p}{N} \sum_{i=1}^{N} \pi^{p}(\theta)_{i,j} \theta_{i,j}$

    Next, we upper bound the performance of the optimal policy.
    The optimal policy achieves a match quality of 
    \begin{equation}
        \mathbb{E}_{\sigma}[\frac{1}{N} \sum_{t=1}^{N} f_{\sigma_{t}}\left(\pi^{*}(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right)  \cdot \theta_{\sigma_{t}}]
    \end{equation}
    For any order $\sigma$, we have that no provider can be selected by two patients, and each patient can select at most one provider. 
    That is, for any ordering, we can bound the match quality as 
    \begin{equation}
        \mathbb{E}_{\sigma}[\frac{1}{N} \sum_{t=1}^{N} f_{\sigma_{t}}\left(\pi^{*}(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right)  \cdot \theta_{\sigma_{t}}] \leq \max\limits_{\mathbf{X}, \sum_{i=1}^{N} X_{i,j} \leq 1, \sum_{j=1}^{M} X_{i,j} \leq 1} \frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{M} X_{i,j} \theta_{i,j} = \frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{M} \pi^{P}(\theta)_{i,j} \theta_{i,j}
    \end{equation}
    The second inequality comes from the definition of $\pi^{P}(\theta)$. 
    Therefore: 
    \begin{equation}
        \mathbb{E}_{\sigma}[\frac{1}{N} \sum_{t=1}^{N} f_{\sigma_{t}}\left(\pi^{*}(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right)  \cdot \theta_{\sigma_{t}}] \leq \frac{1}{N} \sum_{i=1}^{N} \pi^{p}(\theta)_{i,j} \theta_{i,j} =  p \mathbb{E}_{\sigma}[\frac{1}{N} \sum_{t=1}^{N} f_{\sigma_{t}}\left(\pi^{p}(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right)  \cdot \theta_{\sigma_{t}}]
    \end{equation}
\end{proof}

\thmgroupingmatch*

\begin{proof}
We will first prove the reverse direction; that if $G$ is a complete digraph, then $\pi$ and $\pi^{P}$ have the same match rate. 
Consider patient $i$ in a component that is a connected component of size $k$. 
This means that $\sum_{j} \pi(\theta)_{i,j} = 1$. 
We will prove the set of providers unmatched and offered to patient $i$ is non-empty; that is $\lVert \pi(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)} \rVert_{1} > 0$ for any ordering $\sigma$ and $\mathbf{y}^{(t)}$ with $\sigma_{t}=i$. 
$\lVert \pi(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)} \rVert_{1} = k$ when $\mathbf{y}^{(t)} = \mathbf{1}$, and decreases by one each time a provider from $\pi(\theta)_{\sigma_{t}}$ is selected. 
For any $j$ with $\pi(\theta)_{i,j}=1$, there exists  $k-1$ other $i'$ with $\pi(\theta)_{i',j}=1$ because all patients within the complete graph have provider $j$ on their assortment. 
Therefore, at most $k-1$ other patients can select providers from $\pi(\theta)_{i}$, and therefore $\lVert \pi(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)} \rVert_{1}$ can decrease by at most $k-1$ before $\sigma_{t}=i$. 
Therefore, $\lVert \pi(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)} \rVert_{1} \geq k-(k-1) = 1 > 0$. 
Moreover, because each patient has a non-empty assortment, in expectation, $Np$ patients match, and so both $\pi$ and $\pi^{P}$ achieve $Np$ matches. 

Next, we will prove the forward direction: if the match rates are equal between $\pi$ and $\pi^{P}$, then $G$ consists of components that are complete digraphs. 
We note that $\pi^{P}$ achieves a match rate of $Np$ because each patient is offered a non-empty assortment of size one. 
Therefore, the only way for $\pi$ to achieve the same match rate is to offer each patient a non-empty assortment. 
To show this, we first consider some node $u$ in the graph, corresponding to a patient. 
Suppose that patient $i$ has an assortment of size $k$, indicating that there exist $k$ edges from $i$ to some node. 
Suppose that there exists a node, $i'$ such that $(i',i)$ is an edge, but $(i,i')$ is not. 
Then consider the ordering that places $i$ after its neighbors and $i'$. 
In such an ordering, suppose $i'$ selects $v_{i}$ and each neighbor of $i$, $u$, select $v_{u}$. 
This results in neither $i$ nor its neighbors being available when $i$ must select a patient, leaving an empty assortment.
Therefore, if patient $i$ has $v_{i'}$ on its assortment, then $i'$ must have $v_{i}$ on its assortment for the policy $\pi$. 

Next, we consider the scenario where there exists a node $w$ such that $w$ is a two-hop neighbor of $i$ but not an immediate neighbor of $i$. 
Suppose $w$ is adjacent to $i'$, so that $i'$ is on $w$'s assortment. 
Order the patients such that $w$ comes first, then $i$'s neighbors, then $i$. 
Let $w$ select $i'$, let $i'$ select $i$, and let all of $i$'s other neighbors select themselves.
This results in an empty assortment for $i$; therefore, when all assortments are nonempty, there must not exist any two-hop neighbors that are not also one-hop neighbors. 
In other words, every node in $G$ only has one-hop neighbors.  
Therefore, in any component, all neighbors are connected, and so $G$ consists of components that are complete digraphs. 
\end{proof}


\thmgrouping* 
\begin{proof}
    We first compute the expected match quality for the pairwise policy. 
    Each of the $M$ matched patients has a $p$ chance of selecting their assigned provider, and $\theta_{i,j} \leq 1$; therefore, $\mathbb{E}_{\sigma,\theta}[\sum_{t=1}^{N}  (f_{\sigma_{t}}\left(\pi^{P}(\theta)_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right) \cdot \theta_{\sigma_{t}})] \leq pM$.

    Next, we compute the expected match quality for the greedy policy. 
    First, note that because $\theta_{i,j}$ are distributed i.i.d, each provider has an equal chance of being the most preferred and available  provider for patient $i$. 
    Under a uniform choice model, the match probability and match quality are independent; by symmetry for each provider $j$, $N/M$ patients aim to match with provider $j$ ,and so there is a $(1-(1-p)^{N/M})$ chance that provider $j$ is matched. 
    Next, we need to compute $\mathbb{E}[\theta_{i,j} | \text{j is top avail. for i}]$. 
    Fix $i$, then by symmetry, each $j$ has an equal chance of being the top provider. 
    Moreover, because $\theta_{i,j}$ is uniformly distributed, each provider has an equal selection probability for each timestep. 
    Therefore, $\mathbb{E}[\mathbf{y}^{(t)}_{j}] = \beta_{t}$ for some coefficients $\beta_{j}$. 
    Next, let $\mathbb{E}[(\theta_{i})_{(j)}]$ be the $j$th largest value among $\theta_{i,*}$. 
    Then
    \begin{equation}
        \mathbb{E}[\theta_{i,j} | \text{j is top avail. for i}] = \frac{\sum_{j=1}^{M} \beta_{t}(1-\beta_{t})^{j-1} \mathbb{E}[(\theta_{i})_{(j)}]}{\sum_{j=1}^{M} \beta_{t}(1-\beta_{t})^{j-1}}
    \end{equation}

    By Chebyshev's sum inequality, we have that 
    \begin{equation}
        \frac{\sum_{j=1}^{M} \beta_{t}(1-\beta_{t})^{j-1} \mathbb{E}[(\theta_{i})_{(j)}]}{\sum_{j=1}^{M} \beta_{t}(1-\beta_{t})^{j-1}} \geq \frac{1}{M} \sum_{j=1}^{M} \mathbb{E}[(\theta_{i})_{(j)}] = \frac{1}{2}
    \end{equation}
    Therefore, summing across all providers gives the ratio as 
    \begin{equation}
        \frac{1-(1-p)^{N/M}}{2p}
    \end{equation}
\end{proof}

\thmlowerbound*
\begin{proof}
    We compute a matrix, $\hat{\mathbf{Y}}$, such that $Y_{i,j}$ corresponds to the probability that patient $i$ is matched with $j$. 
    Then $\mathbb{E}_{\sigma}[\frac{1}{N} \sum_{t=1}^{N} f_{\sigma_{t}}\left(\mathbf{X}_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right)  \cdot \theta_{\sigma_{t}}] = \hat{\mathbf{Y}} \cdot \theta$. 
    
    We then need to prove that
    \begin{equation}
        (p*g(f(\mathbf{X}))-\hat{\mathbf{Y}}) \cdot \theta \leq 0
    \end{equation}
    To prove this, first let $\ell_{u_{i,j}} = (p*g(f(\mathbf{X}))_{i,j} - \hat{Y}_{i,j})$. 
    
    We will first bound $\sum_{j=1}^{M} \ell_{u_{i,j}}$ for a fixed $i$. 
    Let $\theta_{i,u_{i,1}} \geq \theta_{i,u_{i,2}} \ldots \theta_{i,u_{i,M}}$ for some coefficients $u$. 
    For any $m$, $\sum_{j=1}^{m} \ell_{u_{i,j}} = \sum_{j=1}^{m} p*g(f(\mathbf{X}))_{i,u_{i,j}}-\hat{\mathbf{Y}}_{i,u_{i,j}}$. 
    We can next compute $\sum_{j=1}^{m} p*g(f(\mathbf{X}))_{i,u_{i,j}}$. 
    Recall from Section~\ref{sec:lower_bound} that we can explicitly compute $g(f(\mathbf{X}))_{i,j}$ through the function $h(n) = \frac{1}{N} \sum_{k=1}^{N} (1-p \frac{n-1}{N-1})^{k-1}$. 
    Then by the of definition $g(f(\mathbf{X})_{i,j})$, we have $p \sum_{j=1}^{m} g(f(\mathbf{X}))_{i,j} = p (\sum_{j=1}^{m} X_{i,u_{i,j}} h(\lVert \mathbf{X}_{*,u_{i,j}} \rVert_{1}) \prod_{l=1}^{j-1} (1-(\lVert \mathbf{X}_{*,u_{i,l}} \rVert_{1})))$. 
    
    Next, we note that $\sum_{j=1}^{m} \hat{\mathbf{Y}}_{i,u_{i,j}}$ represents the probability that any of the top-$m$ options are available and selected. 
    For any provider $j$, the probability that $j$ is available is at least $h(\lVert \mathbf{X}_{*,u_{i,j}} \rVert_{1})$ (see Section~\ref{sec:lower_bound}). 
    Therefore, 
    \begin{align}
        \sum_{j=1}^{m} \hat{\mathbf{Y}}_{i,u_{i,j}} \\ 
        \geq p \mathrm{Pr}[\text{Provider 1 avail.} \vee \text{Provider 2 avail.} \cdots] \\ \geq p \sum_{j=1}^{m} X_{i,u_{i,j}} h(\lVert \mathbf{X}_{*,u_{i,j}} \rVert_{1}) \prod_{l=1}^{j-1} (1-(\lVert \mathbf{X}_{*,u_{i,j}} \rVert_{1})
    \end{align}
    Combining our statements for $\hat{\mathbf{Y}}$ and $p *g(f(\mathbf{X}))$ gives that $\sum_{j=1}^{m} X_{i,u_{i,j}} \hat{\mathbf{Y}}_{i,u_{i,j}} \geq \sum_{j=1}^{m} h(\lVert \mathbf{X}_{*,u_{i,m}} \rVert_{1}) \prod_{l=1}^{m-1} (1-(\lVert \mathbf{X}_{*,u_{i,m}} \rVert_{1}) = \sum_{j=1}^{m} p*g(f(\mathbf{X}))_{i,u_{i,j}}$. 
    Therefore, we have that $\sum_{j=1}^{m} \ell_{u_{i,j}} \leq 0$. 

    Next, we will show that $(p*g(f(\mathbf{X}))_{i} - \hat{\mathbf{Y}}_{i}) \cdot \theta_{i} = \sum_{j=1}^{M} \ell_{u_{i,j}} \theta_{i,j} \leq 0$ for all $i$. 
    We will prove this inductively; first note that $l_{i,u_{i,1}} \theta_{i,u_{i,1}} \leq 0$
    Next, assume that $\sum_{j=1}^{M-1} \ell_{u_{i,j}} \theta_{i,u_{i,j}}$, then: 
    
    \begin{align}
        \sum_{j=1}^{m} \ell_{u_{i,j}} \theta_{i,u_{i,j}} \\ = \sum_{j=1}^{m-1} \ell_{u_{i,j}} \theta_{i,u_{i,j}} + \ell_{m} \theta_{i,u_{i,m}} \\ 
        \leq \sum_{j=1}^{m-1} \ell_{u_{i,j}} \theta_{i,u_{i,j}} + \ell_{m} \theta_{i,u_{i,m-1}} \\ 
        \leq (\sum_{j=1}^{m-1} \ell_{u_{i,j}}) (\sum_{j=1}^{m-1} \theta_{i,u_{i,j}} - \theta_{i,u_{i,m-1}}) \leq 0
    \end{align}
Therefore, $p*(g(f(\mathbf{X}))_{i} \cdot \theta_{i}) \leq 0$ for all $i$, and so summing across all $i$ gives $p*(g(f(\mathbf{X})) \cdot \theta) \leq 0$
\end{proof}


\thmtightlowerbound*
\begin{proof}
    Let $\mathbf{X} = \pi^{P}(\theta)$ for some given $\theta$. 
    Then because $\pi^{P}(\theta)$ is computed by solving a 1-1 bipartite matching problem, we know that $\sum_{i=1}^{N} X_{i,j} \leq 1$ for all $j$ and $\sum_{j=1}^{M} X_{i,j} \leq 1$ for all $i$. 
    Next, we note that $0 \leq \lVert \mathbf{X}_{*,j} \rVert \leq 1$, and moreover, if $\mathbf{X}_{i,j} = 1$, then $\lVert \mathbf{X}_{*,j} \rVert = 1$. 
    Because $h(1) = 1$, we have that $f(\mathbf{X})_{i,j} = \mathbf{X}_{i,j}$. 
    Finally, because each row $i$ of $f(\mathbf{X})_{i,j}$ has at most one $j$ with $\mathbf{X}_{i,j} = 1$, and because $\bar{\mathbf{X}}_{i,u_{k}} = f(\mathbf{X})_{i,u_{k}} p \prod_{k'=1}^{k-1} (1-f(\mathbf{X})_{i,u_{k}})$, we have that $g(f(\mathbf{X})) = f(\mathbf{X}) = p \mathbf{X}$. 
    Therefore, $g(f(\mathbf{X})) \cdot \theta$ is exactly p times the value of the bipartite match. 
    Finally, 
    \begin{equation}
        \mathbb{E}_{\sigma}[\sum_{t=1}^{N} (f_{\sigma_{t}}\left(\mathbf{X}_{\sigma_{t}} \odot \mathbf{y}^{(t)}\right)  \cdot \theta_{\sigma_{t}})]  = p \sum_{i=1}^{N} \sum_{j=1}^{M} \pi^{P}(\theta)_{i,j} \theta_{i,j} = p (f(g(\mathbf{X})) \cdot \theta).
    \end{equation}
    Therefore, the expected match quality for the pairwise policy $\pi^{P}(\theta)$ is the same as $p (\mathbf{X} \cdot \theta)$.
\end{proof}
\thmordering*

\begin{proof}
We first note that $G$ is acyclic; if $\theta_{i,v_{i}} \leq \theta_{i,v_{i'}}$ and $\theta_{i',v_{i'}} \leq \theta_{i',v_{i}}$, then swapping $v_{i}$ and $v_{i'}$ improves the pairwise policy $\pi^{P}(\theta)$. 
We note that $\pi^{P}(\theta)$ is the optimal solution for $\sum_{i=1}^{N} \sum_{j=1}^{M} \pi^{P}(\theta) \theta_{i,j}$ by definition, and so such a swap would violate this property, implying that $G$ is acyclic. 

Next, suppose that $\sigma^{*}$ is not a reverse topological ordering. 
Then there exists nodes $i$ and $i'$, so that $i$ comes before $i'$ in $\sigma^{*}$ and there exists an edge from $i$ to $i'$. 
Consider the following cases: 
\begin{enumerate}
    \item \textbf{Case 1:} There exists no node $w$, between $i'$ and $i$ in $\sigma$ so that $w$ and $i'$ share an edge (in either direction). 
    Then $i$ and $i'$ can be placed in sequence ($i$ comes immideatly before $i'$) without impacting the expected reward. 
    This is because all nodes $w$ between $i$ and $i'$ have no impact on the preferences of $i'$ because $\theta_{i',v_{i'}} \geq \theta_{i',v_{w}}$. 
    Moreover, swapping $i$ and $i'$ can only increase the expected match quality; placing $i$ before or after $i'$ has no impact on the match quality for patient $i'$ (as $\theta_{i',v_{i'}} \geq \theta_{i',v_{i}}$), but placing $i$ after $i'$ can increase the expected match quality if $v_{i}$ goes unmatched. 
    \item \textbf{Case 2:} Suppose there exists a node $w$, such that there is an edge from $w$ to $i'$ Then the pair $(w,i')$ violates the reverse topological order, and so we can recurse on this. Note that this is a smaller length pair of nodes within the ordering $\sigma^{*}$. Similarly if there is an edge from $i$ to $w$, then $(i,w)$ violates the reverse topological order ,and so we can recurse on this
    \item \textbf{Case 3:} Suppose that there exists a node $w$ such that there are edges from $i'$ to $w$ and $w$ to $i$. Then this creates a cycle, breaking the acyclic property mentioned earlier. 
    \item \textbf{Case 4:} Suppose that there exists a node $w$ such that there is an edge from $i'$ to $w$. There exists no path from $i'$ to $i$ due to the acyclic nature of the graph. 
    Additionally, $w$ does not have an edge to $i$ or any of the ancestors of $i$. 
    Move $i'$ and all of its descendants before $i$ in the graph; there are no edges from the descendants of $i'$ to $i$. 
    Therefore, this flips the order of $i$ and $i'$ without impacting any of the descendants; because only $i$ and $i'$ are impacted by this change (as the descendants of $i'$ are not impacted by $i$), such a change can only increase the expected match quality, as $i$ can potentially match with $v_{i'}$. 
    \item \textbf{Case 5:} Suppose there exists a node $w$ such that there exists an edge from $w$ to $i$. 
    Due to the acyclic nature of the graph, there are no edges from $i'$ (or any of its ancestors) to $w$ or any of the ancestors of $i$. 
    Now consider moving $i$ and its ancestors after $i'$. 
    Because there are no edges from $i'$ to the ancestors of $i$, the result of the assortment from the ancestors of $i$ has no impact on $i'$. 
    Therefore, while patient $i$ can now potentially match with provider $v_{i'}$, none of the ancestors of $i$ are negatively impacted, improving aggregate match quality.  
\end{enumerate}
Our cases cover every scenario for nodes between $i$ and $i'$, and in all cases, we can make a minor change to the order $\sigma^{*}$ to bring it closer to a reverse topological ordering while improving match quality or recurse upon a subset of the ordering. 
\end{proof}

\optimalordering*
\begin{proof}
    Let $\sigma^{*}$ be the optimal ordering and let $\sigma$ be any ordering from batches $b_{1},b_{2},\ldots,b_{L}$. 
    Then we will prove that for any node $i$, the order of descendants of $i$ will be the same in $\sigma^{*}$ and $\sigma$. 

    To prove this, consider a node $i$. 
    Let the descendants of node $i$ in the optimal ordering be $d_{1},d_{2},\ldots,d_{i}$. 
    We note that in $\sigma$, each $d_{i'}$ is in a separate partition by properties of $b_{k}$. 
    Additionally, because $b_{1},b_{2},\ldots,b_{L}$ is a partition of $\sigma^{*}$, the order of $d_{1},d_{2},\ldots,d_{i}$ is maintained. 
    Therefore, for any node, the same set of ancestors is maintained through the partition $b_{k}$. 

    Next, we will show that the descendants of patient $i$ dictates what patient $i$ selects in $\pi^{A}$. 
    Let $Z_{1}, Z_{2},\ldots,Z_{N}$ be a set of Bernoulli random variables, each of which is 1 with probability $p$.
    If $Z_{t}=1$ then patient $\sigma_{t}$ will select the highest available provider in their assortment, and if $Z_{t}=0$, then patient $\sigma_{t}$ will select no provider. 
    Additionally, let $V_{1}, V_{2}, \ldots, V_{N}$ be a set of random variables, where $Z_{t}$ denotes the provider selected by patient $\sigma_{t}$ ($V_{t} = 0$ if $Z_{t}=0$). 
    Note that $V_{1}$ is only a function of $Z_{1}$; if $Z_{1}=0$, then $V_{1}=0$, and otherwise, $V_{1} = \argmax_{j} \theta_{\sigma_{1},j}$. 
    Next, let $D_{\sigma_{t}} \subseteq [N]$ be the set of descendants for patient $\sigma_{t}$; that is, $d \in D_{\sigma_{t}}$ means there exists a path from $\sigma_{t}$ to $d$ in $G$. 
    Suppose that $V_{\sigma_{t'}} = f(\{Z_{d}\}_{d \in D_{\sigma_{t'}}})$ for all $t' \leq t$. 
    Then patient $\sigma_{t+1}$ will only select some $j$ so $\theta_{\sigma_{t+1},j} \geq \theta_{\sigma_{t+1},v_{\sigma_{t+1}}}$. 
    By the construction of the graph $G$, this corresponds to edges connected to patient $\sigma_{t+1}$, and so $V_{t+1} = g(\{V_{d}\}_{d \in D_{\sigma_{t+1}})}$.
    Next, note that $V_{d} = f(\{Z_{d'}\}_{d' \in D_{d}})$. 
    Therefore, we can rewrite $V_{t+1}$ as 
    \begin{equation}
        V_{t+1} = g(\{f(\{Z_{d'}\}_{d' \in D_{d}})\}_{d \in D_{t+1})}.
    \end{equation}
    We finally collect like terms and note that the set of descendants of the children of $\sigma_{t+1}$ is the set of descendants of $\sigma_{t+1}$. 
    Therefore, we rewrite $V_{t+1}$ as 
    \begin{equation}
        V_{t+1} = g(\{Z_{d}\}_{d \in D_{t+1}})
    \end{equation}
    Therefore, $V_{t+1}$ only depends on the descendants of $t+1$.
    Therefore, if the ordering of descendants is fixed, and $Z_{1},Z_{2},\ldots,Z_{N}$ are decided a priori, then $V_{\sigma_{t}}$ is also fixed. 
    The ordering of descendants is the same between $\sigma \sim S(b_{1},b_{2},\ldots,b_{L})$ and $\sigma^{*}$, so both achieve the same match quality. 
\end{proof}
