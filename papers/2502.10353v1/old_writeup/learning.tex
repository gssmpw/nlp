\section{Learning Preferences}
\label{sec:learning}
We consider the problem of learning match quality, $\theta_{i,j}$, between patients and providers. 
We do so through two paradigms: the first applies supervised learning on top of the existing assortment algorithms, and the second combines decision-making with learning so assortment choices are used to learn more bout preferences. 

\subsection{Supervised Learning}
We consider $\theta_{i,j}$ to represent two facets of match quality: 
\begin{enumerate}
    \item \textbf{Patient likelihood of matching} - We imagine that $\theta_{i,j}$ captures the likelihood of patient $i$ willingly selecting provider $j$, and in some sense, encompasses the preference of patients for providers. While such a preference is inherently relative, we can interpret $\theta_{i,j} \geq \theta_{i,j'}$ as implying that patient $i$ prefers provider $j$ to provider $j'$. 
    \item \textbf{Impact on downstream match quality} - We can additionally leverage information on the downstream impact of matches through surveys of patient happiness, and clinical information on statistics like medication uptake rates. 
\end{enumerate}

We formally model each as follows. 
First, consider a dataset, $D$ which consists of pairs of matching patient-providers, which we denote $D = (l_{1},m_{1}),(l_{2},m_{2}),\ldots,(l_{N},m_{N})$. 
Second, consider a dataset, $\tilde{D}$, which consists of triplets of patient-provider scores, where scores can arise from factors such as patient surveys and clinical outcomes. 
Formally, $\tilde{D} = (a_{1},b_{1},c_{1}),(a_{2},b_{2},c_{2}),\ldots,(a_{m},b_{M},c_{M})$, where $a_{i}$ is a list of patients, $b_{i}$ is a list of providers, and $c_{i} \in [0,1]$ is a score. 
We aim to learn two functions: $f^{p}(\mathbf{u},\mathbf{v})$, which denotes the preference of a patient encoded by $\mathbf{u}$ for a provider encoded by $\mathbf{v}$, and $f^{o}(\mathbf{u},\mathbf{v})$, which predicts the downstream outcome for a patient-provider pair. 

We consider $f^{p}$ and $f^{o}$ to arise from some parameterized class of functions, parameterized by $\Omega$.
For $f^{o}$, we can find the optimal function through empirical risk minimization on $\tilde{D}$. 
Learning $f^{p}$ is more challenging due to the availability of only positive labels. 
To counteract this, we select random pairs from $\tilde{D}$, $(l_{i},m_{j})$ so that $i \neq j$, which simulates unmatched patients. 
By selecting the correct sampling rate, we can compute the function $f^{p}$ again through empirical risk minimization. 

\subsubsection{Incorporating Menu Data}
Data from menus allows us to learn values for $f^{p}$ through the principle of revealed preferences. 
That is, if providers $j$ and $j'$ are both offered in a menu, and patient $i$ selects provider $j$, then we know that $f^{p}(\mathbf{u}_{i},\mathbf{v}_{j}) \geq f^{p}(\mathbf{u}_{i},\mathbf{v}_{j'})$. 
To incorporate this source of data, we consider a dataset, $\bar{D}$ with triplets $l_{i},m_{i},m'_{i}$, such that patient $l_{i}$ prefers provider $m_{i}$ to provider $m'_{i}$. 
Using such a dataset, we construct a loss function as follows: 
\begin{equation}
    \mathcal{L} = -\sum_{l,m \in D, l_{i}, m_{j}, j = i} f^{p}(l,m) + \sum_{l,m \in D, l_{i}, m_{j}, j \neq i} f^{p}(l,m) + \lambda \sum_{l,m,m' \in \bar{D}} f^{p}(l,m') - f^{p}(l,m)
\end{equation}
Here, $\lambda$ is a hyperparameter, that modulates between losses for terms arising from the menu, and those arising from the previous matches. 
We then minimize $\mathcal{L}$ using empirical risk minimization, and compute $f^{p}$ using this value of $\Omega$. 

\subsection{Combining Decision-Making and Learning}
We can better learn $f^{p}$ at a cost to utility by including extra providers which might potentially be sub-optimal. 
We view such a learning problem through an improvement in confidence. 
Formally, consider $\theta_{i,j} \in [\theta_{i,j}^{L},\theta_{i,j}^{H}]$ with probability $1-\delta$. 
Here, $\theta_{i,j}^{L},\theta_{i,j}^{H}$ provide a confidence interval which we can compute from some function. 
Our goal is to reduce $\theta_{i,j}^{H}-\theta_{i,j}^{L}$ so that we have more confidence over our patient-provider preferences. 
\nrcomment{Find where Lipschitz scenario should be incorporated}

We first note that we only need to consider a subset of the available providers, as only these can improve confidence meaningfully for our menus. 
\begin{lemma}
    Let $i$ be a patient, and let $j$ and $j'$ be two providers. Let provider $j$ have the highest preference for patient $i$, so $\hat{\theta}_{i,j} \geq \hat{\theta}_{i,j'}$, such that both are computed from $\tilde{D}$. If $\theta_{i,j}^{L} \geq \theta_{i,j}^{H}$, then adding $j'$ to a menu with $j$ will lead to no new data points, $(l,m,m')$ that cannot be inferred from the data already present in $\tilde{D}$. 
\end{lemma}
Such a lemma demonstrates that we need to only add providers whose preferences are in doubt, when compared to the optimal provider. 

Our aim is then to balance information gathering with utility. 
Traditionally, we define utility as: 
\begin{equation}
    \sum_{i,j} X_{i,j} \theta_{i,j}
\end{equation}
To incorporate information, we first quantify the expected improvement in confidence by adding a provider $j'$. 
We do this by letting $\theta_{i,j} \sim U(\theta_{i,j}^{L},\theta_{i,j}^{H})$. 
Then the probability that $\theta_{i,j'} \geq \theta_{i,j}$ can be computed as 
\begin{equation}
    \beta_{i,j} = \frac{1}{2} \frac{(\theta_{i,j'}^{H}-\theta_{i,j}^{L})^{2}}{(\theta_{i,j}^{H}-\theta_{i,j}^{L})(\theta_{i,j'}^{H}-\theta_{i,j'}^{L})}
\end{equation}
Such a formula applies to the scenario alluded to by the previous Lemma; when provider $j'$ could feasibly be preferred to provider $j$. 

Using this formulation, we let the information gain be 
\begin{equation}
    \sum_{S} (\theta^{H}_{i,j}-\theta^{L}_{i,j}) - \sum_{\bar{S}} (\theta^{H}_{i,j}-\theta^{L}_{i,j}) 
\end{equation}
Here $S$ is some sampling of patient-provider pairs, and $\bar{S}$ adds in a new preference $(i,j,j')$. 
Our overall objective function is then
\begin{equation}
    \sum_{i,j} \theta_{i,j} X_{i,j} + \gamma (\sum_{S} (\theta^{H}_{i,j}-\theta^{L}_{i,j}) - \sum_{\bar{S}} (\theta^{H}_{i,j}-\theta^{L}_{i,j}) )
\end{equation}

To maximize this, we consider the following strategy: we add a provider $j'$ to patient $i$'s menu if 
\begin{equation}
    \theta_{i,j'} - \theta_{i',j} < \gamma (\beta_{i,j}(\sum_{S} (\theta^{H}_{i,j}-\theta^{L}_{i,j})) + (1-\beta_{i,j}) (\sum_{S} (\theta^{H}_{i,j}-\theta^{L}_{i,j})))
\end{equation}

\begin{conjecture}
    The strategy mentioned above is optimal to optimize for the following objective: 
    \begin{equation}
    \sum_{i,j} \theta_{i,j} X_{i,j} + \gamma (\sum_{S} (\theta^{H}_{i,j}-\theta^{L}_{i,j}) - \sum_{\bar{S}} (\theta^{H}_{i,j}-\theta^{L}_{i,j}) )
    \end{equation}

\end{conjecture}

\subsection{Matching under Uncertainty}
To complement our discussion of improving learning through decision-making, we highlight how we can overcome the inherent uncertainty when true preferences are unknown. 
We consider that $\theta_{i,j} \sim U(\theta_{i,j}^{L},\theta_{i,j}^{H})$, and aim to maximize the match quality. 
The symmetry of such a situation allows us to define $\bar{\theta} = \frac{\theta_{i,j}^{L} + \theta_{i,j}^{H}}{2}$; essentially, the expectation of the preferences. 
We demonstrate that using such $\bar{\theta}_{i,j}$ allows for the same performance in the scenario where preferences are fully known: 
\begin{lemma}
    Let patient-provider preferences, $\theta_{i,j} \sim U(\theta_{i,j}^{L},\theta_{i,j}^{H})$, and define $\bar{\theta} = \frac{\theta_{i,j}^{L} + \theta_{i,j}^{H}}{2}$. 
    Then the optimal solution to 
    \begin{equation}
        \sum_{i,j} X_{i,j} \theta_{i,j}
    \end{equation}
    Is the same as 
    \begin{equation}
        \sum_{i,j} X_{i,j} \bar{\theta}_{i,j}
    \end{equation}
    in expectation. 
\end{lemma}

\subsection{Asking Questions}
We finally consider a method by which preferences are explicitly learned by asking patients to fill out features which are important and unimportant to them. 
From there, heuristics are constructed which weight different factors to predict a patient-provider match score. 
Such a strategy can be combined with the aforementioned metrics to create a complete picture. 