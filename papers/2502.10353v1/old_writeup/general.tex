\section{General Choice Models}
To generalize beyond uniform choice models, we consider two strategies to tackle general choice models.
The first considers sampling-based methods, which sample from different permutations to assess the quality of a menu. 
The second considers restrictions on the choice class, so that the utility for a particular menu can be expressed as a submodular function. 
Doing so allows us to optimize efficiently due to properties of submodular functions. 

\subsection{Sampling-based Methods}
We first consider algorithms which sample different permutations of $\pi$, and use this to find optimal menus. 
We first use concentration inequalities to show that we can efficiently approximate the utiltiy of a particular menu: 
\begin{lemma}
     Let $R(X_{1,1},X_{1,2},\cdots,X_{N,P}) = \mathbb{E}_{\pi}[\sum_{i=1}^{N} \sum_{j=1}^{P} \theta_{\pi_{i},j} Y_{\pi_{i},j}(\mathbf{Z}_{i})]$ be a utility function of the menus offered. Let $\mathrm{OPT} = \max\limits_{X_{1,1},X_{1,2},\ldots,X_{N,P}} \mathbb{E}_{\pi}[\sum_{i=1}^{N} \sum_{j=1}^{P} \theta_{\pi_{i},j} Y_{\pi_{i},j}(\mathbf{Z}_{i})]$. If $\theta_{i,j} \in [0,1] \forall i,j$, then $\mathrm{OPT} \leq \min(N,P)$
\end{lemma}

\begin{lemma}
    Let $R(X_{1,1},X_{1,2},\cdots,X_{N,P}) = \mathbb{E}_{\pi}[\sum_{i=1}^{N} \sum_{j=1}^{P} \theta_{\pi_{i},j} Y_{\pi_{i},j}(\mathbf{Z}_{i})]$ be a utility function of the menus offered.
    Consider a fixed menu $X_{1,1},X_{1,2},\cdots,X_{N,P}$. 
    Then after 
    \begin{equation}
        n = \frac{\ln(\frac{2}{\delta}) \min(N,P)^{2}}{\epsilon}
    \end{equation}
    samples, denoted $\pi^{1}, \pi^{2}, \ldots, \pi^{n}$, we have that, with probability $1-\delta$
    \begin{equation}
        |R(X_{1,1},X_{1,2},\cdots,X_{N,P}) - \frac{1}{n} \sum_{k=1}^{n} \sum_{i=1}^{N} \sum_{j=1}^{P} \theta_{\pi^{k}_{i},j} Y_{\pi^{k}_{i},j}(\mathbf{Z}_{i})| \leq \epsilon
    \end{equation}
\end{lemma}

From here, if our utility function is Lipschitz in the menus offered, then we can use a covering-style argument to find the optimal menu. 
We do this in two steps. 
First, we construct a set of menus which approximately cover the set of available menus, within some distance $r$. 
We use sampling-based techniques to approximate the utility for each of these menus. 
Second, we claim that the optimal menu is close to one of these menus, and because the utility is Lipschitz in the menu, we can bound the perforamnce gap between our best found menu and the optimal menu: 
\begin{theorem}
    Consider a utility function, so that $|R(X_{1,1},X_{1,2},\cdots,X_{N,P}) - R(X'_{1,1},X'_{1,2},\cdots,X'_{N,P})| \leq L \sum_{i=1}^{N} \sum_{j=1}^{P} |X_{i,j}-X'_{i,j}|$ for some $L \geq 0$. 
    Let $K(n,r)$ be the covering code for a binary string of length $n$ with hamming distance $r$; the covering code represents the minimum cardinality of a set $S$, so that all binary strings of length $n$ are at most distance $r$ away from some element of $S$. 
    Let $\mathrm{OPT} = \max\limits_{X_{1,1},X_{1,2},\ldots,X_{N,P}} \mathbb{E}_{\pi}[\sum_{i=1}^{N} \sum_{j=1}^{P} \theta_{\pi_{i},j} Y_{\pi_{i},j}(\mathbf{Z}_{i})]$
    Then with $\frac{K(NP,r) \ln(\frac{2}{\delta}) \min{(N,P)}^{2}}{\epsilon}$ evaluations of 
    \begin{equation}
        \sum_{i=1}^{N} \sum_{j=1}^{P} \theta_{\pi_{i},j} Y_{\pi_{i},j}(\mathbf{Z}_{i})
    \end{equation}
    using different combinations of $\pi$ and $X_{i,j}$, we can find a solution $\mathrm{ALG} = R(X_{1,1},X_{1,2},\cdots,X_{N,P})$, such that, with probability $1-\delta$, $\mathrm{ALG} \geq \mathrm{OPT} - rL$. 
\end{theorem}

\subsection{Submodular Utility}
When the utility function can be written as a submodular function, we can leverage techniques from submodular optimization to solve our problem. 
Moreover, we know that monotone submodular optimization can be approximated within $1-\frac{1}{e}$ in polynomial time~\cite{submodular_optimization} with cardinality constraints (and optimally without such constraints), while non-monotone optimization can be approximated within $\frac{2}{5}$~\cite{non_monotone_submodular}. 
We use this to bound the performance of polynomial time algorithms in this scenario: 
\begin{lemma}
    Let $R(X_{1,1},X_{1,2},\cdots,X_{N,P}) = \mathbb{E}_{\pi}[\sum_{i=1}^{N} \sum_{j=1}^{P} \theta_{\pi_{i},j} Y_{\pi_{i},j}(\mathbf{Z}_{i})]$ be a utility function of the menus offered.
    If $R$ is submodular in the variables $X_{i,j}$, and if we can evaluate $R(X_{1,1},X_{1,2},\cdots,X_{N,P})$ in polynomial time, then then we can find a greedy solution, $\mathrm{ALG}$, in polynomial time, such that $\mathrm{ALG} \geq \frac{2}{5} \mathrm{OPT}$, where $\mathrm{OPT} = \max\limits_{X_{1,1},X_{1,2},\ldots,X_{N,P}} \mathbb{E}_{\pi}[\sum_{i=1}^{N} \sum_{j=1}^{P} \theta_{\pi_{i},j} Y_{\pi_{i},j}(\mathbf{Z}_{i})]$
\end{lemma}

We note that such a solution is not a panacea, as we construct simple choice models which aren't submodular: 
\begin{lemma}
    There exists a selection of $Y_{i,j}(\mathbf{Z})$ so that $R(X_{1,1},X_{1,2},\cdots,X_{N,P}) = \mathbb{E}_{\pi}[\sum_{i=1}^{N} \sum_{j=1}^{P} \theta_{\pi_{i},j} Y_{\pi_{i},j}(\mathbf{Z}_{i})]$ is not submodular. 
\end{lemma}

Determining whether commonly used choice models result in submodular utility functions is still an open question:

\begin{conjecture}
    When $Y_{i,j}$ is the uniform choice model, $R(X_{1,1},X_{1,2},\cdots,X_{N,P})$ is submodular. 
\end{conjecture}

\begin{conjecture}
    When $Y_{i,j}$ is the MNL choice model, $R(X_{1,1},X_{1,2},\cdots,X_{N,P})$ is submodular. 
\end{conjecture}
