@article{APTQ,
  title={Additive powers-of-two quantization: An efficient non-uniform discretization for neural networks},
  author={Li, Yuhang and Dong, Xin and Wang, Wei},
  journal={arXiv preprint arXiv:1909.13144},
  year={2019}
}

@inproceedings{BridgeDeepLearning,
  title={Bridge deep learning to the physical world: An efficient method to quantize network},
  author={Hung, Pei-Hen and Lee, Chia-Han and Yang, Shao-Wen and Somayazulu, V Srinivasa and Chen, Yen-Kuang and Chien, Shao-Yi},
  booktitle={2015 IEEE Workshop on Signal Processing Systems (SiPS)},
  pages={1--6},
  year={2015},
  organization={IEEE}
}

@article{Choi_2020,
  title={Learning sparse low-precision neural networks with learnable regularization},
  author={Choi, Yoojin and El-Khamy, Mostafa and Lee, Jungwon},
  journal={IEEE Access},
  volume={8},
  pages={96963--96974},
  year={2020},
  publisher={IEEE}
}

@inproceedings{ImprovingLowBit,
  title={Improving low-precision network quantization via bin regularization},
  author={Han, Tiantian and Li, Dong and Liu, Ji and Tian, Lu and Shan, Yi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5261--5270},
  year={2021}
}

@InProceedings{Nagel_2019_ICCV,
author = {Nagel, Markus and Baalen, Mart van and Blankevoort, Tijmen and Welling, Max},
title = {Data-Free Quantization Through Weight Equalization and Bias Correction},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}

@article{OneModelRobust,
  title={Robust quantization: One model to rule them all},
  author={Chmiel, Brian and Banner, Ron and Shomron, Gil and Nahshan, Yury and Bronstein, Alex and Weiser, Uri and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={5308--5317},
  year={2020}
}

@inproceedings{Xu_2023_ICCV,
  title={Eq-net: Elastic quantization neural networks},
  author={Xu, Ke and Han, Lei and Tian, Ye and Yang, Shangshang and Zhang, Xingyi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1505--1514},
  year={2023}
}

@article{alizadeh2020gradient,
  title={Gradient l1 regularization for quantization robustness},
  author={Alizadeh, Milad and Behboodi, Arash and Van Baalen, Mart and Louizos, Christos and Blankevoort, Tijmen and Welling, Max},
  journal={arXiv preprint arXiv:2002.07520},
  year={2020}
}

@article{bengio2013ste,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@inproceedings{gupta2023reducing,
  title={Reducing the Side-Effects of Oscillations in Training of Quantized YOLO Networks},
  author={Gupta, Kartik and Asthana, Akshay},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2452--2461},
  year={2024}
}

@inproceedings{ijcai2022p504,
  title={MultiQuant: Training Once for Multi-bit Quantization of Neural Networks.},
  author={Xu, Ke and Feng, Qiantai and Zhang, Xingyi and Wang, Dong}
}

@inproceedings{inferenceBenchmark,
  title={Mlperf inference benchmark},
  author={Reddi, Vijay Janapa and Cheng, Christine and Kanter, David and Mattson, Peter and Schmuelling, Guenther and Wu, Carole-Jean and Anderson, Brian and Breughe, Maximilien and Charlebois, Mark and Chou, William and others},
  booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)},
  pages={446--459},
  year={2020},
  organization={IEEE}
}

@inproceedings{jacob2017quantization,
  title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2704--2713},
  year={2018}
}

@inproceedings{minimizeQuantError,
  title={Quantization error-based regularization in neural networks},
  author={Hirose, Kazutoshi and Ando, Kota and Ueyoshi, Kodai and Ikebe, Masayuki and Asai, Tetsuya and Motomura, Masato and Takamaeda-Yamazaki, Shinya},
  booktitle={Artificial Intelligence XXXIV: 37th SGAI International Conference on Artificial Intelligence, AI 2017, Cambridge, UK, December 12-14, 2017, Proceedings 37},
  pages={137--142},
  year={2017},
  organization={Springer}
}

@inproceedings{nagel2022overcoming,
  title={Overcoming oscillations in quantization-aware training},
  author={Nagel, Markus and Fournarakis, Marios and Bondarenko, Yelysei and Blankevoort, Tijmen},
  booktitle={International Conference on Machine Learning},
  pages={16318--16330},
  year={2022},
  organization={PMLR}
}

@article{pseudoQuantNoise,
  title={Differentiable model compression via pseudo quantization noise},
  author={D{\'e}fossez, Alexandre and Adi, Yossi and Synnaeve, Gabriel},
  journal={arXiv preprint arXiv:2104.09987},
  year={2021}
}

@inproceedings{vitoscillations,
  title={Oscillation-free quantization for low-bit vision transformers},
  author={Liu, Shih-Yang and Liu, Zechun and Cheng, Kwang-Ting},
  booktitle={International Conference on Machine Learning},
  pages={21813--21824},
  year={2023},
  organization={PMLR}
}

@article{zhong2024mbquantnovelmultibranchtopology,
  title={MBQuant: A novel multi-branch topology method for arbitrary bit-width network quantization},
  author={Zhong, Yunshan and Zhou, Yuyao and Chao, Fei and Ji, Rongrong},
  journal={Pattern Recognition},
  volume={158},
  pages={111061},
  year={2025},
  publisher={Elsevier}
}

