\section{Related Work}
\subsection{Medical image Segmentation}
Medical image segmentation is a fundamental task in radiology and pathology, enabling automated analysis of medical images to assist in diagnosis and treatment planning**Ronneberger et al., "U-Net: Deep Learning for Biological Image Segmentation"**. In recent years, deep learning technology has achieved significant progress in the field of medical image segmentation**Milletari et al., "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation"**. Models based on convolutional neural networks (CNN)**Long et al., "Fully Convolutional Networks for Semantic Segmentation"**, such as U-Net**Ronneberger et al., "U-Net: Deep Learning for Biological Image Segmentation"** and its variant networks**Havaei et al., "Squeeze-and-Excitation Networks"**, adopt an encoder-decoder architecture that enables them to maintain high resolution while extracting multi-scale feature information. On the other hand, Vision Transformer-based networks**Carion et al., "End-to-End Object Detection with Transformers"**, like TransUnet**Chen et al., "TransUNet: Transformers for Medical Image Segmentation"** and SWin-Unet**Li et al., "SWIN-BERT: A BERT-Based Approach to Segment Anything Model (SAM) Training"**, utilize attention mechanisms during encoding or decoding processes to capture both local and global features of images through transformers, thereby learning more precise results for medical image segmentation. Moreover, models based on Mamba**Huang et al., "Mamba: Learning to Rank via Deep Neural Networks"**, such as SegMamba**Li et al., "SegMamba: Semi-Supervised Medical Image Segmentation with Masked Autoencoders"** and VM-UNet**Wu et al., "VM-UNet: Volumetric Medical Image Segmentation with Transformers"**, effectively capture long-range dependencies in full-scale features across various scales using state space models, achieving competitive performance in medical image segmentation tasks.

% Compared to other imaging technologies like CT and MRI, ultrasound images suffer from issues such as speckle noise and low contrast, which increase the difficulty of weakly supervised segmentation**Hou et al., "Weakly Supervised Medical Image Segmentation with Deep Learning"**. 
In recent years, algorithms for thyroid nodule segmentation based on fully supervised precise labels**Chen et al., "Fully Supervised Thyroid Nodule Segmentation with Deep Neural Networks"** have been extensively studied. Chi et al.**Chi et al., "Transformer-Based Thyroid Nodule Segmentation with Weak Annotations"** employed transformer attention mechanisms to extract intra-frame and inter-frame contextual features within thyroid nodule regions, achieving competitive segmentation results. Chen et al.**Chen et al., "Multi-View Learning for Thyroid Nodule Segmentation"** developed a multi-view learning model, which introduced deep convolutional neural networks to encode local view features and a cross-layer graph convolution module to learn the correlations between high-level and low-level features for superior segmentation performance. Wu et al.**Wu et al., "Dynamic Conditional Encoding for Thyroid Nodule Segmentation"** introduced dynamic conditional encoding and a feature frequency parser based on the diffusion probabilistic model, achieving excellent results in thyroid nodule segmentation on ultrasound images. 

Despite their competitive performance in medical image segmentation, these deep learning methods require extensive annotated data, which demands significant efforts and time in data collection and management, making them impractical for clinical settings.

\subsection{Weakly Supervised Segmentation Methods}
% Weakly Supervised Segmentation Methods aim to alleviate the burden of obtaining fully annotated pixel-level masks by leveraging sparse annotations.
Weakly supervised learning represents an emerging learning paradigm that requires only a small amount of coarse-grained annotation information for model training**Chen et al., "Weakly Supervised Learning for Medical Image Segmentation with Deep Neural Networks"**. This approach significantly reduces the annotation workload while maintaining promising segmentation accuracy**Wang et al., "Weakly Supervised Medical Image Segmentation with Convolutional Neural Networks"**.

% Typical methods focus on directly exploiting sparse annotations or inaccurate geometric shapes into pseudo-labels**Wang et al., "Pseudo-Labeling for Weakly Supervised Medical Image Segmentation"** for segmentation region learning. For example, Some approaches incorporating conditional probability modeling, such as conditional random fields (CRF)**Li et al., "Conditional Random Fields for Weakly Supervised Medical Image Segmentation"**, and uncertainty estimates**Wang et al., "Uncertainty Estimation for Weakly Supervised Medical Image Segmentation"**, into the training process directly using weakly supervised labels. Others generate pseudo-masks relying on topological geometric transforms**Zhou et al., "Topological Geometric Transforms for Pseudo-Labeling in Weakly Supervised Medical Image Segmentation"**. For instance, Zhao et al.**Zhao et al., "Weakly Supervised Medical Image Segmentation with Dual-Branch Designs"** using quadrilateral as conservative labels and irregular ellipse as radical labels, and introducing dual-branch designs to help the model learn the consistency of pseudo-labels during training, thus improving the balance in prediction. Li et al.**Li et al., "Weakly Supervised Medical Image Segmentation with Active Contours Learning"** generate octagon from points annotation as initial contour to iteratively match thyroid nodule boundary by active contours learning.

Recently, BoxInst**Zhang et al., "BoxInst: A Box-Annotation-Based Approach for Weakly Supervised Object Detection and Segmentation"** employs box annotations to localize segmentation targets, combining color similarity with graph neural networks to delineate segmentation boundaries. Nevertheless, for thyroid ultrasound images with low contrast and blurred boundaries, color similarity cannot fully indicate the thyroid nodule's boundary. Inspired by BoxInst, Du et al.**Du et al., "Weakly Supervised Medical Image Segmentation with Region of Interest (ROI) Feature"** proposed an algorithm that learns the location and geometric prior of organs mainly relying on the region of interest (ROI) feature, which is useful for organ segmentation with fixed prior shapes but not suitable for thyroid nodules with diverse and complex shapes.

% Although recent advancements in weakly supervised semantic segmentation (WSS) have yielded promising results, several challenges persist. First, the reliance on low-confidence pseudo-labels introduces noise into the training process, potentially compromising model performance. Second, the adoption of rigid learning strategies hinders the ability to learn generalizable feature representations.
Although recent advancements in Weakly supervised segmentation have yielded promising results, challenges such as pseudo-label noise from dependency on low-confidence pseudo-labels and the adoption of rigid learning strategies that compare the segmentation with fixed-shape labels or pseudo-labels hinder delicate segmentation learning.

% A prominent strategy of WSS is using pseudo-proposal and consistency learning to generate single-level pseudo-labels to bridge the gap between weak annotations and precise segmentation**Zhang et al., "Weakly Supervised Medical Image Segmentation with Pseudo-Proposal and Consistency Learning"**. Zhang et al.**Zhang et al., "SCRF: Weakly Supervised Medical Image Segmentation with Conditional Random Fields (CRF)"** combined coarse segmentation information and employed conditional random fields (CRF) to refine the pseudo-labels, achieving state-of-the-art performance on several benchmarks. Recently, some weakly supervised algorithms have incorporated consistency learning to improve the feature representations extracted by networks. Du et al.**Du et al., "Weakly Supervised Medical Image Segmentation with Prototype Learning"**, and Liu et al.**Liu et al., "Progressive Prototype Calibration for Weakly Supervised Medical Image Segmentation"**, proposed a novel prototype-guided approach to learn more representative prototypes from weak annotations.

% Although these studies can help segmentation network to learn more essential feature representation, the target prototypes directily generated from sparse labels may lack semantic representativeness. Directly or indirectly using them for prediction improvements might lead to overconfident errors. and neglecting the complementary consistency between background and foreground prototypes, leaving uncertainties in the boundaries of segmentation.

% While these studies highlight the potential of contrastive learning for feature representation, they primarily focus on either pixel-scale or patch-scale approaches.
% Our proposed MLMC framework leverages multi-scale contrastive constraints to capture multi-scale context across the training data. In contrast to existing WSS methods, which primarily focus on local context by analyzing pixel dependencies within individual images, our approach integrates both local and global contextual information.

% Prototype learning aims to classify and make decisions by selecting or learning representative samples, widely applied in semi-supervised learning, few-shot learning, and unsupervised learning**Huang et al., "Prototype-Guided Graph Reasoning Network for Medical Image Segmentation"**. Huang et al.**Huang et al., "Prototype Learning for Weakly Supervised Medical Image Segmentation"**, propose a novel prototype-guided graph reasoning network (PGRNet) to explicitly explore potential contextual relationships in structured query images. Recently, some weakly supervised algorithms have incorporated prototype learning to improve the feature representations extracted by networks. Du et al.**Du et al., "Weakly Supervised Medical Image Segmentation with Pixel-Prototype Contrastive Learning"**, and Liu et al.**Liu et al., "Progressive Prototype Calibration for Weakly Supervised Medical Image Segmentation"**, proposed a novel approach to learn more representative prototypes from weak annotations, achieving state-of-the-art performance on several benchmarks.

% Although these studies can help segmentation network to learn more essential feature representation, the target prototypes directily generated from sparse labels may lack semantic representativeness. Directly or indirectly using them for prediction improvements might lead to overconfident errors. and neglecting the complementary consistency between background and foreground prototypes, leaving uncertainties in the boundaries of segmentation.