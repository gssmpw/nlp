\section{Related Work}
\subsection{Medical image Segmentation}
Medical image segmentation is a fundamental task in radiology and pathology, enabling automated analysis of medical images to assist in diagnosis and treatment planning____. In recent years, deep learning technology has achieved significant progress in the field of medical image segmentation____. Models based on convolutional neural networks (CNN)____, such as U-Net____ and its variant networks____, adopt an encoder-decoder architecture that enables them to maintain high resolution while extracting multi-scale feature information. On the other hand, Vision Transformer-based networks____, like TransUnet____ and SWin-Unet____, utilize attention mechanisms during encoding or decoding processes to capture both local and global features of images through transformers, thereby learning more precise results for medical image segmentation. Moreover, models based on Mamba____, such as SegMamba____ and VM-UNet____, effectively capture long-range dependencies in full-scale features across various scales using state space models, achieving competitive performance in medical image segmentation tasks.

% Compared to other imaging technologies like CT and MRI, ultrasound images suffer from issues such as speckle noise and low contrast, which increase the difficulty of weakly supervised segmentation____. 
In recent years, algorithms for thyroid nodule segmentation based on fully supervised precise labels____ have been extensively studied. Chi et al.____ employed transformer attention mechanisms to extract intra-frame and inter-frame contextual features within thyroid nodule regions, achieving competitive segmentation results. Chen et al.____ developed a multi-view learning model, which introduced deep convolutional neural networks to encode local view features and a cross-layer graph convolution module to learn the correlations between high-level and low-level features for superior segmentation performance. Wu et al.____ introduced dynamic conditional encoding and a feature frequency parser based on the diffusion probabilistic model, achieving excellent results in thyroid nodule segmentation on ultrasound images. 

Despite their competitive performance in medical image segmentation, these deep learning methods require extensive annotated data, which demands significant efforts and time in data collection and management, making them impractical for clinical settings.

\subsection{Weakly Supervised Segmentation Methods}
% Weakly Supervised Segmentation Methods aim to alleviate the burden of obtaining fully annotated pixel-level masks by leveraging sparse annotations.
Weakly supervised learning represents an emerging learning paradigm that requires only a small amount of coarse-grained annotation information for model training____. This approach significantly reduces the annotation workload while maintaining promising segmentation accuracy____.

% Typical methods focus on directly exploiting sparse annotations or inaccurate geometric shapes into pseudo-labels____ for segmentation region learning. For example, Some approaches incorporating conditional probability modeling, such as conditional random fields (CRF)____ and uncertainty estimates____, into the training process directly using weakly supervised labels. Others generate pseudo-masks relying on topological geometric transforms____. For instance, Zhao et al.____ using quadrilateral as conservative labels and irregular ellipse as radical labels, and introducing dual-branch designs to help the model learn the consistency of pseudo-labels during training, thus improving the balance in prediction. Li et al.____ generate octagon from points annotation as initial contour to iteratively match thyroid nodule boundary by active contours learning. 
Typical methods focus on directly exploiting sparse annotations or inaccurate geometric shapes to generate pseudo-labels____ for pixel-to-pixel region learning. For instance, some approaches incorporate conditional probability modeling techniques, such as conditional random fields (CRF)____, and uncertainty estimates____ into the training process directly using weakly supervised labels to learn predictions. Other methods generate pseudo-masks based on topological geometric transforms____. For example, Zhao et al.____ employ quadrilaterals as conservative labels and irregular ellipses as radical labels while introducing dual-branch designs to improve the consistency of pseudo-labels during training, thereby enhancing prediction accuracy. Similarly, Li et al.____ propose a method that generates octagons from point annotations to serve as initial contours for iteratively refining thyroid nodule boundaries through active contour learning.

Recently, BoxInst____ employs box annotations to localize segmentation targets, combining color similarity with graph neural networks to delineate segmentation boundaries. Nevertheless, for thyroid ultrasound images with low contrast and blurred boundaries, color similarity cannot fully indicate the thyroid nodule's boundary. Inspired by BoxInst, Du et al.____ proposed an algorithm that learns the location and geometric prior of organs mainly relying on the region of interest (ROI) feature, which is useful for organ segmentation with fixed prior shapes but not suitable for thyroid nodules with diverse and complex shapes.

% Although recent advancements in weakly supervised semantic segmentation (WSS) have yielded promising results, several challenges persist. First, the reliance on low-confidence pseudo-labels introduces noise into the training process, potentially compromising model performance. Second, the adoption of rigid learning strategies hinders the ability to learn generalizable feature representations.
Although recent advancements in Weakly supervised segmentation have yielded promising results, challenges such as pseudo-label noise from dependency on low-confidence pseudo-labels and the adoption of rigid learning strategies that compare the segmentation with fixed-shape labels or pseudo-labels hinder delicate segmentation learning.

% A prominent strategy of WSS is using pseudo-proposal and consistency learning to generate single-level pseudo-labels to bridge the gap between weak annotations and precise segmentation____. Zhang et al.____ combined coarse segmentation information with conditional random fields (CRF) to produce pseudo-labels, introducing SCRF. Mahani et al.____ introduced UNCRF, which refines these pseudo-labels by incorporating uncertainty estimation to enhance segmentation accuracy. Zhao et al.____ proposed IDMPS, which employs a dual-network training approach to balance the contribution of both aggressive and implicit pseudo-labels

% The other alternative WSS strategy involves decomposing the segmentation process into multiple stages, which can help mitigate the noise in pseudo-labels____. Tian et al.____ designed BoxInst, which utilizes box annotations to localize the target object and refines the segmentation boundaries using graph neural networks (GNNs) and color similarity. Li et al.____ proposed WSDAC, which uses topological information to generate an initial mask and then applies gradient-based similarity and statistical offsets to refine segmentation shape. Du et al.____ proposed an algorithm that learns the location from box labels and uses the geometric prior of organs to learn segmentation shape.

% Despite these advancements, these single-level learning by inaccurate pseudo-labels can misguide the model during training, leading to degraded feature learning and increased errors in boundary delineation.

% Our proposed method explores multi-level high-confidence labels and multi-level learning strategies to learn discrepancy features.

% \subsection{Segment Anything Model for Weakly Supervised Segmentation}
% The Segment Anything Model (SAM)____ is a foundation model that is designed as a promotable model capable of performing general-purpose segmentation tasks across a wide variety of object categories. The model is pre-trained on an extensive dataset using prompt-based learning, where a user provides interactive cues, such as points, bounding boxes, or masks, to guide the segmentation. 

% Ma et al.____ present MedSAM developed on a large-scale medical image dataset with 1,570,263 image-mask pairs. It provides high performance in the zero-shot learning regime of medical image segmentation. Comprehensive experimental studies adopted by Mazurowski et al.____ show that when given points or box prompts, SAM can perform convincing results in various medical imaging datasets. 

% Although fine-tuning a large model (MedSAM) can lead to high performance that is better adapted to a new domain, fine-tuning a large model typically requires significant computational resources. Additionally, The interactive nature of using SAM as a feature extractor by prompts may present limitations in fully automated settings or where human intervention is impractical.

% % In contrast, direct inference requires much less computational power. 

% % To simultaneously leverage the high generalization capability of MedSAM in providing anatomical segmentation results when given prompts____, while avoiding the heavy resource demands of using MedSAM as a feature extractor and the need for prompts, we use the results inferred from box labels as anatomical confidence, which is combined with initial foreground/background labels obtained through geometric transformations to generate more accurate multi-level labels.

% \subsection{Contrastive Learning for Feature Representation}

% Contrastive learning aims to attract the positive sample pairs and repulse the negative sample pairs through contrastive loss. In segmentation tasks, contrastive learning is used to learn discriminative representations by constructing sample queues from different regions of an image____. Sample construction typically occurs at the pixel-scale____ and patch-scale____. Wang et al.____ and Zhao et al.____ both proposed pixel-level comparison algorithms that rely on fully supervised masks to sample pixels of different categories. Chaitanya et al.____ and Du et al.____ applied pixel-level contrastive loss on pseudo-labels of unlabeled data in Semi-supervised and weakly-supervised segmentation, respectively. Meanwhile, Yun et al.____ devised patch-level contrastive approaches to enforce invariance against each patch and its neighbors. Zhang et al.____ adopted image augmentation for two input views and introduced a cross-view query-based patch-level Contrasting Paradigm for Self-supervised representation learning (SSL). Wu et al.____ exploited the contextual position priors of 3D medical images to generate base crops as prototypes, enforcing feature distinction across different regions.

% Although these studies highlight the potential of contrastive learning in feature representation, they primarily focus on pixel-level or patch-level methods, failing to fully leverage multi-scale information to learn feature representations with stronger discriminative power.

% Contrastive learning aims to attract the positive sample pairs and repulse the negative sample pairs through contrastive loss. Initially, it was primarily applied to image recognition tasks____. Wu et al. introduced InstDISC____, framing instance-level discrimination as a metric learning problem by comparing the similarity between image features and those stored in a memory bank. Subsequently, algorithms such as SimCLR____ and MoCo~S____ demonstrated strong performance in image classification tasks. Using data augmentation techniques, these methods generate different views of images and then construct positive and negative pairs through various sample strategies____ to distinguish between different image classes.

% % While these studies highlight the potential of contrastive learning for feature representation, they primarily focus on either pixel-scale or patch-scale approaches. 
% % Our proposed MLMC framework leverages multi-scale contrastive constraints to capture multi-scale context across the training data. In contrast to existing WSS methods, which primarily focus on local context by analyzing pixel dependencies within individual images, our approach integrates both local and global contextual information.

% \subsection{Prototype Learning for Feature Representation}
% Prototype learning aims to classify and make decisions by selecting or learning representative samples, widely applied in semi-supervised learning, few-shot learning, and unsupervised learning____. Huang et al.____ propose a novel prototype-guided graph reasoning network (PGRNet) to explicitly explore potential contextual relationships in structured query images. Recently, some weakly supervised algorithms have incorporated prototype learning to improve the feature representations extracted by networks. Du et al.____ conducted pixel-prototype contrastive learning in the feature space. Liu et al.____ proposed Progressive Prototype Calibration focuses solely on the feature prototypes of the foreground. 

% Although these studies can help segmentation network to learn more essential feature representation, the target prototypes directily generated from sparse labels may lack semantic representativeness. Directly or indirectly using them for prediction improvements might lead to overconfident errors. and neglecting the complementary consistency between background and foreground prototypes, leaving uncertainties in the boundaries of segmentation.