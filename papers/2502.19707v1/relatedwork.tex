\section{Related Work}
\subsection{Medical image Segmentation}
Medical image segmentation is a fundamental task in radiology and pathology, enabling automated analysis of medical images to assist in diagnosis and treatment planning~\cite{rayed2024deepreview, obuchowicz2024review}. In recent years, deep learning technology has achieved significant progress in the field of medical image segmentation~\cite{rayed2024deepreview, das2024nodulereview}. Models based on convolutional neural networks (CNN)~\cite{ronneberger2015unet, tao2022cenet, zhou2018unet++, isensee2021nnunet}, such as U-Net~\cite{ronneberger2015unet} and its variant networks~\cite{tao2022cenet, zhou2018unet++, isensee2021nnunet}, adopt an encoder-decoder architecture that enables them to maintain high resolution while extracting multi-scale feature information. On the other hand, Vision Transformer-based networks~\cite{Swin-unet, ozcan2024enhancedtransunet, zhou2024Thyroid-DETR, bi2023bpat, CHENTransUNet}, like TransUnet~\cite{CHENTransUNet} and SWin-Unet~\cite{Swin-unet}, utilize attention mechanisms during encoding or decoding processes to capture both local and global features of images through transformers, thereby learning more precise results for medical image segmentation. Moreover, models based on Mamba~\cite{chen2024masam, wang2024mamba-unet, xing2024segmamba, ruan2024vm-unet, liu2024Swin-UMamba}, such as SegMamba~\cite{xing2024segmamba} and VM-UNet~\cite{ruan2024vm-unet}, effectively capture long-range dependencies in full-scale features across various scales using state space models, achieving competitive performance in medical image segmentation tasks.

% Compared to other imaging technologies like CT and MRI, ultrasound images suffer from issues such as speckle noise and low contrast, which increase the difficulty of weakly supervised segmentation~\cite{das2024nodulereview}. 
In recent years, algorithms for thyroid nodule segmentation based on fully supervised precise labels~\cite{chi2023htunet, chen2024mlmseg, wu2024medsegdiff, li2023novelthyroid, gong2023thyroid, ma2024tnseg} have been extensively studied. Chi et al.~\cite{chi2023htunet} employed transformer attention mechanisms to extract intra-frame and inter-frame contextual features within thyroid nodule regions, achieving competitive segmentation results. Chen et al.~\cite{chen2024mlmseg} developed a multi-view learning model, which introduced deep convolutional neural networks to encode local view features and a cross-layer graph convolution module to learn the correlations between high-level and low-level features for superior segmentation performance. Wu et al.~\cite{wu2024medsegdiff} introduced dynamic conditional encoding and a feature frequency parser based on the diffusion probabilistic model, achieving excellent results in thyroid nodule segmentation on ultrasound images. 

Despite their competitive performance in medical image segmentation, these deep learning methods require extensive annotated data, which demands significant efforts and time in data collection and management, making them impractical for clinical settings.

\subsection{Weakly Supervised Segmentation Methods}
% Weakly Supervised Segmentation Methods aim to alleviate the burden of obtaining fully annotated pixel-level masks by leveraging sparse annotations.
Weakly supervised learning represents an emerging learning paradigm that requires only a small amount of coarse-grained annotation information for model training~\cite{guo2024weaklysup, lin2024weaklysup}. This approach significantly reduces the annotation workload while maintaining promising segmentation accuracy~\cite{roth2021weaklysegmentation}.

% Typical methods focus on directly exploiting sparse annotations or inaccurate geometric shapes into pseudo-labels~\cite{liu2024procns} for segmentation region learning. For example, Some approaches incorporating conditional probability modeling, such as conditional random fields (CRF)~\cite{zhang2020scrf, mahani2022uncrf} and uncertainty estimates~\cite{lei2023uncertainty2, fan2024uncertainty}, into the training process directly using weakly supervised labels. Others generate pseudo-masks relying on topological geometric transforms~\cite{wang2023s2me, zhao2024IDMPS, wang2023WSL-MIS, li2023wsdac}. For instance, Zhao et al.~\cite{zhao2024IDMPS} using quadrilateral as conservative labels and irregular ellipse as radical labels, and introducing dual-branch designs to help the model learn the consistency of pseudo-labels during training, thus improving the balance in prediction. Li et al.~\cite{li2023wsdac} generate octagon from points annotation as initial contour to iteratively match thyroid nodule boundary by active contours learning. 
Typical methods focus on directly exploiting sparse annotations or inaccurate geometric shapes to generate pseudo-labels~\cite{liu2024procns} for pixel-to-pixel region learning. For instance, some approaches incorporate conditional probability modeling techniques, such as conditional random fields (CRF)~\cite{zhang2020scrf, mahani2022uncrf}, and uncertainty estimates~\cite{lei2023uncertainty2, fan2024uncertainty} into the training process directly using weakly supervised labels to learn predictions. Other methods generate pseudo-masks based on topological geometric transforms~\cite{wang2023s2me, zhao2024IDMPS, wang2023WSL-MIS, li2023wsdac}. For example, Zhao et al.~\cite{zhao2024IDMPS} employ quadrilaterals as conservative labels and irregular ellipses as radical labels while introducing dual-branch designs to improve the consistency of pseudo-labels during training, thereby enhancing prediction accuracy. Similarly, Li et al.~\cite{li2023wsdac} propose a method that generates octagons from point annotations to serve as initial contours for iteratively refining thyroid nodule boundaries through active contour learning.

Recently, BoxInst~\cite{tian2021BoxInst} employs box annotations to localize segmentation targets, combining color similarity with graph neural networks to delineate segmentation boundaries. Nevertheless, for thyroid ultrasound images with low contrast and blurred boundaries, color similarity cannot fully indicate the thyroid nodule's boundary. Inspired by BoxInst, Du et al.~\cite{du2023weakly3D} proposed an algorithm that learns the location and geometric prior of organs mainly relying on the region of interest (ROI) feature, which is useful for organ segmentation with fixed prior shapes but not suitable for thyroid nodules with diverse and complex shapes.

% Although recent advancements in weakly supervised semantic segmentation (WSS) have yielded promising results, several challenges persist. First, the reliance on low-confidence pseudo-labels introduces noise into the training process, potentially compromising model performance. Second, the adoption of rigid learning strategies hinders the ability to learn generalizable feature representations.
Although recent advancements in Weakly supervised segmentation have yielded promising results, challenges such as pseudo-label noise from dependency on low-confidence pseudo-labels and the adoption of rigid learning strategies that compare the segmentation with fixed-shape labels or pseudo-labels hinder delicate segmentation learning.

% A prominent strategy of WSS is using pseudo-proposal and consistency learning to generate single-level pseudo-labels to bridge the gap between weak annotations and precise segmentation~\cite{zhang2020scrf,mahani2022uncrf,wang2023s2me,zhao2024IDMPS}. Zhang et al.~\cite{zhang2020scrf} combined coarse segmentation information with conditional random fields (CRF) to produce pseudo-labels, introducing SCRF. Mahani et al.~\cite{mahani2022uncrf} introduced UNCRF, which refines these pseudo-labels by incorporating uncertainty estimation to enhance segmentation accuracy. Zhao et al.~\cite{zhao2024IDMPS} proposed IDMPS, which employs a dual-network training approach to balance the contribution of both aggressive and implicit pseudo-labels

% The other alternative WSS strategy involves decomposing the segmentation process into multiple stages, which can help mitigate the noise in pseudo-labels~\cite{tian2021BoxInst,li2023wsdac,du2023weakly3D,liu2024procns}. Tian et al.~\cite{tian2021BoxInst} designed BoxInst, which utilizes box annotations to localize the target object and refines the segmentation boundaries using graph neural networks (GNNs) and color similarity. Li et al.~\cite{li2023wsdac} proposed WSDAC, which uses topological information to generate an initial mask and then applies gradient-based similarity and statistical offsets to refine segmentation shape. Du et al.~\cite{du2023weakly3D} proposed an algorithm that learns the location from box labels and uses the geometric prior of organs to learn segmentation shape.

% Despite these advancements, these single-level learning by inaccurate pseudo-labels can misguide the model during training, leading to degraded feature learning and increased errors in boundary delineation.

% Our proposed method explores multi-level high-confidence labels and multi-level learning strategies to learn discrepancy features.

% \subsection{Segment Anything Model for Weakly Supervised Segmentation}
% The Segment Anything Model (SAM)~\cite{kirillov2023SAM} is a foundation model that is designed as a promotable model capable of performing general-purpose segmentation tasks across a wide variety of object categories. The model is pre-trained on an extensive dataset using prompt-based learning, where a user provides interactive cues, such as points, bounding boxes, or masks, to guide the segmentation. 

% Ma et al.~\cite{ma2024MED-SAM} present MedSAM developed on a large-scale medical image dataset with 1,570,263 image-mask pairs. It provides high performance in the zero-shot learning regime of medical image segmentation. Comprehensive experimental studies adopted by Mazurowski et al.~\cite{mazurowski2023SAM_exprience} show that when given points or box prompts, SAM can perform convincing results in various medical imaging datasets. 

% Although fine-tuning a large model (MedSAM) can lead to high performance that is better adapted to a new domain, fine-tuning a large model typically requires significant computational resources. Additionally, The interactive nature of using SAM as a feature extractor by prompts may present limitations in fully automated settings or where human intervention is impractical.

% % In contrast, direct inference requires much less computational power. 

% % To simultaneously leverage the high generalization capability of MedSAM in providing anatomical segmentation results when given prompts~\cite{zhao2024sam}, while avoiding the heavy resource demands of using MedSAM as a feature extractor and the need for prompts, we use the results inferred from box labels as anatomical confidence, which is combined with initial foreground/background labels obtained through geometric transformations to generate more accurate multi-level labels.

% \subsection{Contrastive Learning for Feature Representation}

% Contrastive learning aims to attract the positive sample pairs and repulse the negative sample pairs through contrastive loss. In segmentation tasks, contrastive learning is used to learn discriminative representations by constructing sample queues from different regions of an image~\cite{oord2018representation}. Sample construction typically occurs at the pixel-scale~\cite{wang2021ContrastiveSeg,zhao2021contrastive-pixel,wang2022contrastmask,wen2022slotCon,du2023weakly3D} and patch-scale~\cite{yun2022patch,zhang2023ADCLR,wu2024voco}. Wang et al.~\cite{wang2021ContrastiveSeg} and Zhao et al.~\cite{zhao2021contrastive-pixel} both proposed pixel-level comparison algorithms that rely on fully supervised masks to sample pixels of different categories. Chaitanya et al.~\cite{chaitanya2023localcontrastive} and Du et al.~\cite{du2023weakly3D} applied pixel-level contrastive loss on pseudo-labels of unlabeled data in Semi-supervised and weakly-supervised segmentation, respectively. Meanwhile, Yun et al.~\cite{yun2022patch} devised patch-level contrastive approaches to enforce invariance against each patch and its neighbors. Zhang et al.~\cite{zhang2023ADCLR} adopted image augmentation for two input views and introduced a cross-view query-based patch-level Contrasting Paradigm for Self-supervised representation learning (SSL). Wu et al.~\cite{wu2024voco} exploited the contextual position priors of 3D medical images to generate base crops as prototypes, enforcing feature distinction across different regions.

% Although these studies highlight the potential of contrastive learning in feature representation, they primarily focus on pixel-level or patch-level methods, failing to fully leverage multi-scale information to learn feature representations with stronger discriminative power.

% Contrastive learning aims to attract the positive sample pairs and repulse the negative sample pairs through contrastive loss. Initially, it was primarily applied to image recognition tasks~\cite{wu2018InstDisc,ye2019Invaspread,tian2020cmc}. Wu et al. introduced InstDISC~\cite{wu2018InstDisc}, framing instance-level discrimination as a metric learning problem by comparing the similarity between image features and those stored in a memory bank. Subsequently, algorithms such as SimCLR~\cite{chen2020simCLR} and MoCo~S\cite{he2020moco} demonstrated strong performance in image classification tasks. Using data augmentation techniques, these methods generate different views of images and then construct positive and negative pairs through various sample strategies~\cite{grill2020BYOL,chen2021simsiam} to distinguish between different image classes.

% % While these studies highlight the potential of contrastive learning for feature representation, they primarily focus on either pixel-scale or patch-scale approaches. 
% % Our proposed MLMC framework leverages multi-scale contrastive constraints to capture multi-scale context across the training data. In contrast to existing WSS methods, which primarily focus on local context by analyzing pixel dependencies within individual images, our approach integrates both local and global contextual information.

% \subsection{Prototype Learning for Feature Representation}
% Prototype learning aims to classify and make decisions by selecting or learning representative samples, widely applied in semi-supervised learning, few-shot learning, and unsupervised learning~\cite{wang2024boundary-prototype, huang2024prototype-graph, zhao2024cpnet, ouyang2022self}. Huang et al.~\cite{huang2024prototype-graph} propose a novel prototype-guided graph reasoning network (PGRNet) to explicitly explore potential contextual relationships in structured query images. Recently, some weakly supervised algorithms have incorporated prototype learning to improve the feature representations extracted by networks. Du et al.~\cite{du2022weakly-prototype} conducted pixel-prototype contrastive learning in the feature space. Liu et al.~\cite{liu2024procns} proposed Progressive Prototype Calibration focuses solely on the feature prototypes of the foreground. 

% Although these studies can help segmentation network to learn more essential feature representation, the target prototypes directily generated from sparse labels may lack semantic representativeness. Directly or indirectly using them for prediction improvements might lead to overconfident errors. and neglecting the complementary consistency between background and foreground prototypes, leaving uncertainties in the boundaries of segmentation.