[
  {
    "index": 0,
    "papers": [
      {
        "key": "toshniwal2022chess",
        "author": "Toshniwal, Shubham and Wiseman, Sam and Livescu, Karen and Gimpel, Kevin",
        "title": "Chess as a testbed for language model state tracking"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "radford2019language",
        "author": "Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others",
        "title": "Language models are unsupervised multitask learners"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "kim-schuster-2023-entity",
        "author": "Kim, Najoung and Schuster, Sebastian",
        "title": "Entity Tracking in Language Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "tandon-etal-2020-dataset",
        "author": "Tandon, Niket and Sakaguchi, Keisuke and Dalvi, Bhavana and Rajagopal, Dheeraj and Clark, Peter and Guerquin, Michal and Richardson, Kyle and Hovy, Eduard",
        "title": "A Dataset for Tracking Entities in Open Domain Procedural Text"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "shirai-etal-2022-visual",
        "author": "Shirai, Keisuke and Hashimoto, Atsushi and Nishimura, Taichi and Kameko, Hirotaka and Kurita, Shuhei and Ushiku, Yoshitaka and Mori, Shinsuke",
        "title": "Visual Recipe Flow: A Dataset for Learning Visual State Changes of Objects with Recipe Flows"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "li-etal-2021-implicit",
        "author": "Li, Belinda Z. and Nye, Maxwell and Andreas, Jacob",
        "title": "Implicit Representations of Meaning in Neural Language Models"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "long-etal-2016-simpler",
        "author": "Long, Reginald and Pasupat, Panupong and Liang, Percy",
        "title": "Simpler Context-Dependent Logical Forms via Model Projections"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \\L ukasz and Polosukhin, Illia",
        "title": "Attention is All you Need"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "prakash2023fine",
        "author": "Prakash, Nikhil and Shaham, Tamar Rott and Haklay, Tal and Belinkov, Yonatan and Bau, David",
        "title": "Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "li2023emergent",
        "author": "Kenneth Li and Aspen K Hopkins and David Bau and Fernanda Vi{\\'e}gas and Hanspeter Pfister and Martin Wattenberg",
        "title": "Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "fagnou-etal-2024-chain",
        "author": "Fagnou, Erwan and Caillon, Paul and Delattre, Blaise and Allauzen, Alexandre",
        "title": "Chain and Causal Attention for Efficient Entity Tracking"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "gupta-durrett-2019-effective",
        "author": "Gupta, Aditya and Durrett, Greg",
        "title": "Effective Use of Transformer Networks for Entity Tracking"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "kim2024codepretrainingimprovesentity",
        "author": "Najoung Kim and Sebastian Schuster and Shubham Toshniwal",
        "title": "Code Pretraining Improves Entity Tracking Abilities of Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yoneda2024statler",
        "author": "Yoneda, Takuma and Fang, Jiading and Li, Peng and Zhang, Huanyu and Jiang, Tianchong and Lin, Shengjie and Picker, Ben and Yunis, David and Mei, Hongyuan and Walter, Matthew R",
        "title": "Statler: State-maintaining language models for embodied reasoning"
      }
    ]
  }
]