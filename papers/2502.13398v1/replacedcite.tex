\section{Related Work}
\label{sec:rel}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
Various computational approaches have been developed for molecule optimization____.
%
%
For example, Modof____, MIMOSA____,
and f-RAG____ 
perform substructure modifications over molecular graphs.
%at predicted disconnection sites 
%while preserving core scaffolds. %each with distinct modification strategies.
%
Chemformer____ and \PMol____ treat optimization as a translation over SMILES____ strings, 
and learn the required modification from molecule pairs.
%incorporating task-specific guidance in different ways.
%
GraphGA____ and MolLeo____ leverage 
genetic algorithms
to evolve molecules via genetic algorithm. %for crossover and mutation operations.
% While effective in improving 1 or 2 properties, their efficacy in multi-property optimization tasks remains largely unexplored.
%
These methods____ often require designing non-trivial fitness or reward functions
to capture nuanced trade-offs among multiple properties. 
%
% However, designing such functions is highly non-trivial, requiring domain expertise to capture nuanced trade-offs. 
% %
% Pairwise approaches such as \PMol____ circumvent this by learning from molecule pairs,
% but suffer from scalability due to limited task-specific labeled data. 
%
Moreover, such methods 
%focus on controllable molecule generation____, 
tends to generate
molecules with entirely new scaffolds, 
limiting their applicability \emph{in vitro} optimization.


%Similarly, f-RAG____ breaks down the molecules into hard fragments and soft fragments for molecular optimization, where hard fragments are explicitly included in generation while soft fragments guide the process through embedding fusion. 
%
%MIMOSA uses pre-trained GNNs for fragment modification prediction and MCMC sampling to iteratively search promising molecules based on weighted scoring of properties.
%
%Chemformer____ and \PMol____ approach optimization by translating the source molecules to the optimized molecules represented by SMILES strings
%
%Chemformer____ incorporates task-specific information through direct task prompt prefixing of the source molecule's SMILES string, while \PMol____ employs specialized task-specific atomic embeddings from a pre-trained GNN to guide the optimization process.
%
%GraphGA____ and MolLeo____ implement genetic-algorithm-based approaches, starting with a population of molecules with low property values and evolving them through predefined modification rules or by incorporating chemistry language models for crossover and mutation operations.
%

% \vishal{Computational methods
% for improving molecular properties____ have been extensively
% developed,
% where each method either modifies the structures of
% a given molecule (i.e., molecule optimization),
% or generates entirely new ones (i.e., molecule generation).
% %
% These methods vary in how they perform structural modifications
% and in their molecular representations. 
% For example,
% GraphGA____,
% Modof____,
% MIMOSA____,
% and f-RAG____
% perform fragment-level modifications on molecular graphs
% by removing, adding, and replacing 
% substructures at predicted disconnection sites.
% %
% In contrast, methods such as 
% SMILES GA____,
% MolLeo____,
% Genetic-GFN____, and
% Prompt-MolOpt____
% directly modify SMILES strings to generate new molecules
% with improved properties.
% %
% }

% \vishal{
% Most existing methods (except Modof and Prompt-MolOpt)
% are generation-based,
% and thus generate molecules with entirely 
% new scaffolds.
% This limits their applicability in realistic
% settings since retaining the core scaffold is a key requirement
% for \emph{in vitro} optimization.
% %
% Furthermore, these methods are primarily evaluated on improving
% single or double properties.
% Thus, their efficacy in more complex and realistic
% multi-property optimization tasks remain largely unexplored.
% }
%

% Multi-property molecule optimization ____ is a critical challenge in drug discovery due to the complex trade-offs between properties. 
%
% Furthermore, methods leveraging genetic algorithms ____ or reinforcement learning ____ 
% require design of non-trivial task-specific fitness or reward functions
% to model property trade-offs. 
% %
% % However, designing such functions is highly non-trivial, requiring domain expertise to capture nuanced trade-offs. 
% % %
% Pairwise approaches like Modof____ and \PMol____ circumvent this by learning from molecule pairs, but are constrained by scare task-specific labeled data. 
% %
% Furthermore, %the generative nature of 
% most methods tend to generate molecules with new scaffolds, limiting their applicability, as retaining the core scaffold is a key requirement for \emph{in vitro} optimization.


% To address this, recent approaches like \PMol
% build separate models for each property combination (i.e., each optimization task),
% leading to poor scalability.
% These limitations underscore the need for a single unified model -- similar to a foundation model____ --
% that can flexibly and effectively handle diverse
% optimization tasks.



% %
% Furthermore, the lack of labeled paired data in such multi-property optimization tasks 
% hinders effective training for pairwise optimization methods such as Modof and \PMol. 
% %
% The genetic algorithm-based methods____ and reinforcement learning approaches____ attempt to handle multiple objectives through weighted summation, designing such weights proves highly non-trivial and struggles to capture nuanced property relationships.
% %
% Beyond this, the generative nature of most methods (except Modof and \PMol) makes them tend to generate molecules with entirely new scaffolds. This limits their applicability in realistic settings since retaining the core scaffold is a key requirement for \emph{in vitro} optimization.
% %

Recently, LLMs____ have emerged as a promising option for molecule optimization. 
%
For example,
ChatDrug____ and Re3DF____ leverage 
LLMs to optimize a molecule iteratively
through multi-turn dialogues.
% and incorporating domain knowledge through retrieval of similar molecules from databases and validation feedback from expert tools for iterative optimization. 
%
%Taking a different approach,
DrugAssist____
instruction-tuned Llama2-7B-Chat____ 
on each optimization task. 
%using their curated \DrugMOpt dataset.
%
While these approaches offer flexible 
task formulation through natural language, they still face
several limitations.
%
ChatDrug incurs high costs due to multiple API calls, 
and
instruction-tuning in DrugAssist relies on task-specific data,
limiting scalability and adaptability to more complex multi-property tasks.
%
%Moreover, most methods____need to build separate models for each property combination (i.e., each optimization task), leading to poor scalability.
%Some approaches____ require an initial pool of molecules or fragments to start with, which poorly aligns with real-world drug discovery scenarios where optimization typically starts from a single promising hit molecule.
%
%Additionally 
%Furthermore, optimizing multiple properties simultaneously is a fundamental challenge in drug discovery____ due to complex trade-offs among such properties.
%

%

%All these methods are limited in their applicability to real-world drug discovery scenarios, particularly in handling multi-property optimizations. Most methods only demonstrate effectiveness on simple tasks involving single or double properties, with no systematic exploration on multi-property optimizations.
%
%Specifically, approaches like Modof and \PMol heavily rely on training data, limiting their performance when training data is scarce for multi-objective optimization. And they can only perform the tasks existing in the training data, suggesting the low generalizability. 
%

%


% \vishal{Recently, LLMs have been explored for molecule optimization. 
% %
% ChatDrug____ and Re3DF____ use 
% multi-turn dialogue-based generation using ChatGPT, incorporating domain knowledge 
% via retrieval____
% and validation feedback from expert tools for iterative optimization. 
% %
% DrugAssist____ takes a different approach by instruction-tuning Llama2-7B-Chat____ 
% for single- and double-property optimization tasks
% leveraging their curated \DrugMOpt dataset.
% %
% However, these approaches are limited in their scalability
% and applicability to complex multi-property optimization tasks.
% %
% For example,
% while ChatDrug can be used to optimize multiple properties, it requires multiple expensive API calls.
% %
% On the other hand, DrugAssist provides task-specific LLMs tuned on single- and double-property optimization,
% leaving multi-property optimizations unexplored.
% %
% }



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%