\section{Related Work}
\label{sec:relatedwork}
%
    In this section, we will review related image restoration work from two aspects: single-scene and multi-scene.
%

\subsection{Single-Scene Restoration}
%
\subsubsection{Image Dehazing}
%
    Dehazing methods have evolved significantly, transitioning from traditional image processing algorithms to learning-driven models. He \textit{et al.} \citep{he2010single} proposed the DCP, which inverts the atmospheric scattering model to produce haze-free images by uncovering the statistical properties of hazy images. However, DCP-based methods \citep{fattal2014dehazing,liu2022rank} struggle with images containing bright objects or sky regions and are often ineffective in handling non-uniform haze due to the assumption of a uniform haze layer. Retinex-based methods \citep{fu2014retinex,kandhway2023adaptive} focus on filtering degraded images to retrieve light images but typically fail to accurately remove haze in regions with varying densities and complex structures. Learning-based methods \citep{zhu2023spectral,chen2024dea} have seen data-driven methods take the forefront in recent years. For example, SDCE \citep{zhu2023spectral} utilizing spectral dual-channel encoding to separately process high- and low-frequency image components, significantly enhancing dehazing performance by improving high-frequency details. Chen \textit{et al.} \citep{chen2024dea} proposed a detail-enhanced attention module that combines detail-enhanced convolution and content-guided attention to improve feature learning and dehazing performance. Unsupervised contrastive learning and adversarial training methods \citep{liu2024dfp} have also been employed to leverage unpaired real-world hazy and clear images. These methods represent significant advancements in the field, contributing to more robust and effective restoration in diverse real-world scenarios.
%
    %
    \begin{figure}[t]
        \centering
        \setlength{\abovecaptionskip}{0.cm}
        \includegraphics[width=0.75\linewidth]{Figure_ImagingModel}
        \caption{Illustration of the imaging degradation model under complex weather conditions, where uncertain combinations of factors yield a diverse range of degraded images.}
        \label{Figure_ImagingModel}
    \end{figure}
    %
\subsubsection{Image Deraining}
%
    Earlier studies relied on filtering and statistics-based methods, for example, guided filters \citep{xu2012removing} have been effective in removing raindrops and snowflakes from images without relying on pixel-by-pixel statistical information. Hierarchical-based methods employing image decomposition and dictionary learning \citep{wang2017hierarchical} have also been used to efficiently remove raindrops and snowflakes from monochrome images through a multilayered strategy. However, these methods exhibit limited performance when dealing with complex and variable rain and snow scenes. CNN-based networks like DerainNet\citep{fu2017clearing} was among the early attempts to handle unwanted rain streak in images. Zhao \textit{et al.} \citep{zhao2024cycle} recently proposed a recurrent contrastive adversarial learning method with structural consistency to enhance the quality of rain removal images. Yang \textit{et al.} \citep{yang2024single} utilized a multiscale hybrid fusion network to merge multiscale features, which uses a non-local fusion module and an attention fusion module to generate superior rain-free images. The conditional GAN \citep{yang2022rain} for single-image rain removal and enhanced the outcomes by incorporating adversarial loss. GAN-based methods have significantly advanced the handling of complex rainy scenes, as well as the quality and efficiency of image restoration.
%
\subsubsection{Image Desnowing}
%
    Early image desnowing methods relies on smoothing filters, as proposed by He \textit{et al.} \citep{xu2012removing} utilized these filters to remove snow from single images. With the progression towards more complex algorithms, Wang \textit{et al.} \citep{wang2017hierarchical} proposed a three-layer hierarchical scheme combining image decomposition and dictionary learning to tackle both rain and snow. DesnowNet \citep{liu2018desnownet} utilizes multiple scales to model the diversity of snow and effectively remove opaque snow particles. Furthermore, Zhang \textit{et al.} \citep{zhang2021deep} proposed a deep-density multiscale network, which leverages deep prior and semantic information for image snow removal through a self-attention mechanism. Quan \textit{et al.} \citep{quan2023image} utilized inverse neural networks for single-image snow removal, achieving precise snow removal while preserving image details. Additionally, the JSTASR \citep{chen2020jstasr} was designed to classify and further remove snow. Wavelet transform and contradictory channel features were proposed by Chen \textit{et al.} \citep{chen2021all} to remove snow hierarchically, using a dual-tree complex wavelet representation.
%
\subsection{Multi-Scene Restoration}
%
    %
    \begin{figure*}[t]
        \centering
        \setlength{\abovecaptionskip}{0.cm}
        \includegraphics[width=0.925\linewidth]{Figure_Res}
        \caption{The pipeline of proposed dual residual (D-Res) block and standard residual (S-Res) block. D-Res will provide two output heads, each dedicated to learning and reasoning about edge features and global features of degraded images, respectively.}
        \label{Figure_Res}
    \end{figure*}
    %
    Multi-scene image restoration is proposed to restore and enhance degraded images under various environmental conditions, including but not limited to haze, rain, and snow. Traditional learning methods are often challenging to address multiple types of image degradation using a single model. To this end, Guo \textit{et al.} \citep{gou2020clearer} proposed multiscale neural architecture search to optimize image restoration by incorporating parallel, transitional, and fusion operations. The multi-stage progressive restoration framework \citep{zamir2021multi} is proposed to enhance image quality through successive enhancement stages. Architectural search \citep{li2020all} has also been used to develop unified models to mitigate the effects of severe weather. Li \textit{et al.} \citep{li2022all} proposed a novel framework capable of addressing unknown types of image degradation. Chen \textit{et al.} \citep{chen2021pre} leveraged pre-trained Transformer models for a range of image processing tasks, demonstrating significant performance enhancements. Patil \textit{et al.} \citep{patil2023multi} proposed a domain translation-based unified method to achieve robust restoration to complex weather conditions by learning features of multiple weather degradations. The TAENet \citep{fang2024taenet} integrated a cross-encoder architecture and depth perception to enhance image quality, while MvKSR \citep{xu2024mvksr} used multiview knowledge-guided filtering to address challenges posed by haze and rain. Liu \textit{et al.} \citep{liu2024real} proposed the ERANet, which can adapt to the enhancement of images under different weather conditions by combining edge reparameterization and attention mechanism, achieving high-quality image restoration and low computational cost. Gao \textit{et al.} \citep{gao2024prompt} developed a cue-based, component-guided restoration method to handle multiple image degradation scenarios in a unified manner. The Uformer \citep{wang2022uformer} proposed a U-shaped Transformer architecture with locally enhanced window self-attention and multi-scale inpainting modulators to improve imaging quality. MPerceiver \citep{ai2024multimodal} used multimodal prompts to enhance adaptiveness, generalizability, and fidelity in various complex real-world scenarios. Ye \textit{et al.} \citep{ye2024learning} proposed a diffusion texture prior model that explicitly models high-quality texture details and incorporates conditional guidance adapters to achieve high fidelity and realistic textures in image restoration tasks, outperforming existing methods. Although current methods can handle concurrent multiple types of degradation, the nuanced effects of superimposing different types of degradation have not been thoroughly investigated, especially in the VITS.
%