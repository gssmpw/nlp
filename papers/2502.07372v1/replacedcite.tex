\section{Related Work}
\label{sec:relatedwork}
%
    In this section, we will review related image restoration work from two aspects: single-scene and multi-scene.
%

\subsection{Single-Scene Restoration}
%
\subsubsection{Image Dehazing}
%
    Dehazing methods have evolved significantly, transitioning from traditional image processing algorithms to learning-driven models. He \textit{et al.} ____ proposed the DCP, which inverts the atmospheric scattering model to produce haze-free images by uncovering the statistical properties of hazy images. However, DCP-based methods ____ struggle with images containing bright objects or sky regions and are often ineffective in handling non-uniform haze due to the assumption of a uniform haze layer. Retinex-based methods ____ focus on filtering degraded images to retrieve light images but typically fail to accurately remove haze in regions with varying densities and complex structures. Learning-based methods ____ have seen data-driven methods take the forefront in recent years. For example, SDCE ____ utilizing spectral dual-channel encoding to separately process high- and low-frequency image components, significantly enhancing dehazing performance by improving high-frequency details. Chen \textit{et al.} ____ proposed a detail-enhanced attention module that combines detail-enhanced convolution and content-guided attention to improve feature learning and dehazing performance. Unsupervised contrastive learning and adversarial training methods ____ have also been employed to leverage unpaired real-world hazy and clear images. These methods represent significant advancements in the field, contributing to more robust and effective restoration in diverse real-world scenarios.
%
    %
    \begin{figure}[t]
        \centering
        \setlength{\abovecaptionskip}{0.cm}
        \includegraphics[width=0.75\linewidth]{Figure_ImagingModel}
        \caption{Illustration of the imaging degradation model under complex weather conditions, where uncertain combinations of factors yield a diverse range of degraded images.}
        \label{Figure_ImagingModel}
    \end{figure}
    %
\subsubsection{Image Deraining}
%
    Earlier studies relied on filtering and statistics-based methods, for example, guided filters ____ have been effective in removing raindrops and snowflakes from images without relying on pixel-by-pixel statistical information. Hierarchical-based methods employing image decomposition and dictionary learning ____ have also been used to efficiently remove raindrops and snowflakes from monochrome images through a multilayered strategy. However, these methods exhibit limited performance when dealing with complex and variable rain and snow scenes. CNN-based networks like DerainNet____ was among the early attempts to handle unwanted rain streak in images. Zhao \textit{et al.} ____ recently proposed a recurrent contrastive adversarial learning method with structural consistency to enhance the quality of rain removal images. Yang \textit{et al.} ____ utilized a multiscale hybrid fusion network to merge multiscale features, which uses a non-local fusion module and an attention fusion module to generate superior rain-free images. The conditional GAN ____ for single-image rain removal and enhanced the outcomes by incorporating adversarial loss. GAN-based methods have significantly advanced the handling of complex rainy scenes, as well as the quality and efficiency of image restoration.
%
\subsubsection{Image Desnowing}
%
    Early image desnowing methods relies on smoothing filters, as proposed by He \textit{et al.} ____ utilized these filters to remove snow from single images. With the progression towards more complex algorithms, Wang \textit{et al.} ____ proposed a three-layer hierarchical scheme combining image decomposition and dictionary learning to tackle both rain and snow. DesnowNet ____ utilizes multiple scales to model the diversity of snow and effectively remove opaque snow particles. Furthermore, Zhang \textit{et al.} ____ proposed a deep-density multiscale network, which leverages deep prior and semantic information for image snow removal through a self-attention mechanism. Quan \textit{et al.} ____ utilized inverse neural networks for single-image snow removal, achieving precise snow removal while preserving image details. Additionally, the JSTASR ____ was designed to classify and further remove snow. Wavelet transform and contradictory channel features were proposed by Chen \textit{et al.} ____ to remove snow hierarchically, using a dual-tree complex wavelet representation.
%
\subsection{Multi-Scene Restoration}
%
    %
    \begin{figure*}[t]
        \centering
        \setlength{\abovecaptionskip}{0.cm}
        \includegraphics[width=0.925\linewidth]{Figure_Res}
        \caption{The pipeline of proposed dual residual (D-Res) block and standard residual (S-Res) block. D-Res will provide two output heads, each dedicated to learning and reasoning about edge features and global features of degraded images, respectively.}
        \label{Figure_Res}
    \end{figure*}
    %
    Multi-scene image restoration is proposed to restore and enhance degraded images under various environmental conditions, including but not limited to haze, rain, and snow. Traditional learning methods are often challenging to address multiple types of image degradation using a single model. To this end, Guo \textit{et al.} ____ proposed multiscale neural architecture search to optimize image restoration by incorporating parallel, transitional, and fusion operations. The multi-stage progressive restoration framework ____ is proposed to enhance image quality through successive enhancement stages. Architectural search ____ has also been used to develop unified models to mitigate the effects of severe weather. Li \textit{et al.} ____ proposed a novel framework capable of addressing unknown types of image degradation. Chen \textit{et al.} ____ leveraged pre-trained Transformer models for a range of image processing tasks, demonstrating significant performance enhancements. Patil \textit{et al.} ____ proposed a domain translation-based unified method to achieve robust restoration to complex weather conditions by learning features of multiple weather degradations. The TAENet ____ integrated a cross-encoder architecture and depth perception to enhance image quality, while MvKSR ____ used multiview knowledge-guided filtering to address challenges posed by haze and rain. Liu \textit{et al.} ____ proposed the ERANet, which can adapt to the enhancement of images under different weather conditions by combining edge reparameterization and attention mechanism, achieving high-quality image restoration and low computational cost. Gao \textit{et al.} ____ developed a cue-based, component-guided restoration method to handle multiple image degradation scenarios in a unified manner. The Uformer ____ proposed a U-shaped Transformer architecture with locally enhanced window self-attention and multi-scale inpainting modulators to improve imaging quality. MPerceiver ____ used multimodal prompts to enhance adaptiveness, generalizability, and fidelity in various complex real-world scenarios. Ye \textit{et al.} ____ proposed a diffusion texture prior model that explicitly models high-quality texture details and incorporates conditional guidance adapters to achieve high fidelity and realistic textures in image restoration tasks, outperforming existing methods. Although current methods can handle concurrent multiple types of degradation, the nuanced effects of superimposing different types of degradation have not been thoroughly investigated, especially in the VITS.
%