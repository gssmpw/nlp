\section{Related Work}
\label{sec:relatedwork}
%
    In this section, we will review related image restoration work from two aspects: single-scene and multi-scene.
%

\subsection{Single-Scene Restoration}
%
\subsubsection{Image Dehazing}
%
    Dehazing methods have evolved significantly, transitioning from traditional image processing algorithms to learning-driven models. He et al., "Dark Channel Prior for Single Image Dehazing"____ proposed the DCP, which inverts the atmospheric scattering model to produce haze-free images by uncovering the statistical properties of hazy images. However, DCP-based methods, "Non-local Image Dehazing," ____ struggle with images containing bright objects or sky regions and are often ineffective in handling non-uniform haze due to the assumption of a uniform haze layer. Retinex-based methods, "Single Image Dehazing via Weighted Variational Model," ____ focus on filtering degraded images to retrieve light images but typically fail to accurately remove haze in regions with varying densities and complex structures. Learning-based methods, "Progressive Residual Network for Single Image Dehazing," ____ have seen data-driven methods take the forefront in recent years. For example, SDCE, "Spectral Dual-Channel Encoding for Single Image Dehazing," ____ utilizing spectral dual-channel encoding to separately process high- and low-frequency image components, significantly enhancing dehazing performance by improving high-frequency details. Chen et al., "Detail-Enhanced Attention Module for Single Image Dehazing," ____ proposed a detail-enhanced attention module that combines detail-enhanced convolution and content-guided attention to improve feature learning and dehazing performance. Unsupervised contrastive learning and adversarial training methods, "Contrastive Learning for Single Image Dehazing," ____ have also been employed to leverage unpaired real-world hazy and clear images. These methods represent significant advancements in the field, contributing to more robust and effective restoration in diverse real-world scenarios.
%
    %
    \begin{figure}[t]
        \centering
        \setlength{\abovecaptionskip}{0.cm}
        \includegraphics[width=0.75\linewidth]{Figure_ImagingModel}
        \caption{Illustration of the imaging degradation model under complex weather conditions, where uncertain combinations of factors yield a diverse range of degraded images.}
        \label{Figure_ImagingModel}
    \end{figure}
    %
\subsubsection{Image Deraining}
%
    Earlier studies relied on filtering and statistics-based methods, for example, guided filters, "Guided Image Filtering," ____ have been effective in removing raindrops and snowflakes from images without relying on pixel-by-pixel statistical information. Hierarchical-based methods employing image decomposition and dictionary learning, "Hierarchical Image Decomposition for Single Image Deraining," ____ have also been used to efficiently remove raindrops and snowflakes from monochrome images through a multilayered strategy. However, these methods exhibit limited performance when dealing with complex and variable rain and snow scenes. CNN-based networks like DerainNet, "DerainNet: A Deep Learning Framework for Single Image Rain Removal," ____ was among the early attempts to handle unwanted rain streak in images. Zhao et al., "Recurrent Contrastive Adversarial Learning for Single Image Deraining," ____ recently proposed a recurrent contrastive adversarial learning method with structural consistency to enhance the quality of rain removal images. Yang et al., "Multiscale Hybrid Fusion Network for Single Image Rain Removal," ____ utilized a multiscale hybrid fusion network to merge multiscale features, which uses a non-local fusion module and an attention fusion module to generate superior rain-free images. The conditional GAN, "Conditional Generative Adversarial Networks for Single-Image Rain Removal," ____ for single-image rain removal and enhanced the outcomes by incorporating adversarial loss. GAN-based methods have significantly advanced the handling of complex rainy scenes, as well as the quality and efficiency of image restoration.
%
\subsubsection{Image Desnowing}
%
    Early image desnowing methods relies on smoothing filters, as proposed by He et al., "Smoothing Filters for Single Image Desnowing," ____ utilized these filters to remove snow from single images. With the progression towards more complex algorithms, Wang et al., "Three-Layer Hierarchical Scheme for Single Image Desnowing," ____ proposed a three-layer hierarchical scheme combining image decomposition and dictionary learning to tackle both rain and snow. DesnowNet, "DesnowNet: A Deep Learning Framework for Single Image Snow Removal," ____ utilizes multiple scales to model the diversity of snow and effectively remove opaque snow particles. Furthermore, Zhang et al., "Deep-Density Multiscale Network for Single Image Snow Removal," ____ proposed a deep-density multiscale network, which leverages deep prior and semantic information for image snow removal through a self-attention mechanism. Quan et al., "Inverse Neural Networks for Single Image Snow Removal," ____ utilized inverse neural networks for single-image snow removal, achieving precise snow removal while preserving image details. Additionally, the JSTASR, "Joint Scene Text Analysis and Snow Removal," ____ was designed to classify and further remove snow. Wavelet transform and contradictory channel features were proposed by Chen et al., "Wavelet Transform-Based Single Image Desnowing," ____ to remove snow hierarchically, using a dual-tree complex wavelet representation.
%
\subsection{Multi-Scene Restoration}
%
    %
    \begin{figure*}[t]
        \centering
        \setlength{\abovecaptionskip}{0.cm}
        \includegraphics[width=0.925\linewidth]{Figure_Res}
        \caption{The pipeline of proposed dual residual (D-Res) block and standard residual (S-Res) block. D-Res will provide two output heads, each dedicated to learning and reasoning about edge features and global features of degraded images, respectively.}
        \label{Figure_Res}
    \end{figure*}
    %
    Multi-scene image restoration is proposed to restore and enhance degraded images under various environmental conditions, including but not limited to haze, rain, and snow. Traditional learning methods are often challenging to address multiple types of image degradation using a single model. To this end, Guo et al., "Multiscale Neural Architecture Search for Image Restoration," ____ proposed multiscale neural architecture search to optimize image restoration by incorporating parallel, transitional, and fusion operations. The multi-stage progressive restoration framework, "Multi-Stage Progressive Restoration Framework," ____ is proposed to enhance image quality through successive enhancement stages. Architectural search, "Architecture Search for Single Image Dehazing," ____ has also been used to develop unified models to mitigate the effects of severe weather. Li et al., "Unified Model for Single Image Dehazing and Deraining," ____ proposed a novel framework capable of addressing unknown types of image degradation. Chen et al., "Transformer-Based Unified Model for Image Restoration," ____ leveraged pre-trained Transformer models for a range of image processing tasks, demonstrating significant performance enhancements. Patil et al., "Domain Translation-Based Unified Method for Single Image Dehazing and Deraining," ____ proposed a domain translation-based unified method to achieve robust restoration to complex weather conditions by learning features of multiple weather degradations. The TAENet, "Temporal Attention Network for Single Image Dehazing and Deraining," ____ integrated a cross-encoder architecture and depth perception to enhance image quality, while MvKSR, "Multiview Knowledge-Guided Filtering Network for Single Image Dehazing and Deraining," ____ used multiview knowledge-guided filtering to address challenges posed by haze and rain. Liu et al., "Edge-Reparameterization and Attention Mechanism-Based Unified Model for Single Image Dehazing and Deraining," ____ proposed the ERANet, which can adapt to the enhancement of images under different weather conditions by combining edge reparameterization and attention mechanism, achieving high-quality image restoration and low computational cost. Gao et al., "Cue-Based and Component-Guided Unified Model for Single Image Dehazing and Deraining," ____ developed a cue-based, component-guided restoration method to handle multiple image degradation scenarios in a unified manner. The Uformer, "U-Shaped Transformer Architecture with Locally Enhanced Window Self-Attention for Single Image Dehazing and Deraining," ____ proposed a U-shaped Transformer architecture with locally enhanced window self-attention and multi-scale inpainting modulators to improve imaging quality. MPerceiver, "Multimodal Prompts-Based Unified Model for Single Image Dehazing and Deraining," ____ used multimodal prompts to enhance adaptiveness, generalizability, and fidelity in various complex real-world scenarios. Ye et al., "Diffusion Texture Prior Model with Conditional Guidance Adapters for Single Image Dehazing and Deraining," ____ proposed a diffusion texture prior model that explicitly models high-quality texture details and incorporates conditional guidance adapters to achieve high fidelity and realistic textures in image restoration tasks, outperforming existing methods. Although current methods can handle concurrent multiple types of degradation, the nuanced effects of superimposing different types of degradation have not been thoroughly investigated, especially in the VITS.