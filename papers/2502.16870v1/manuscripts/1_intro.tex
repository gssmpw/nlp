\section{Introduction}
\label{sec:intro}



% active learning
Active learning (AL) \citep{settles2009-active} is a framework for achieving high prediction performance with fewer data when labeling new data is expensive. 
%
For this purpose, AL algorithms actively acquire the label of data that improves the prediction performance of some statistical model based on \emph{acquisition functions} (AFs).
%
Many types of AFs have been proposed, such as uncertainty sampling (US), random sampling (RS), variance reduction, and information gain, as summarized in \citet{settles2009-active}.




% Gaussian process-based AL
Gaussian process regression (GPR) model \citep{Rasmussen2005-Gaussian} is often used as a base statistical model for AL algorithms due to its flexible prediction capability \citep{Seo2000gaussian,yu2006active,Guestrin2005-near,krause2008-near,hoang2014nonmyopic}.
%
Standard AL methods for the GPR are based on information gaion~\citep{Guestrin2005-near,krause2008-near,kirsch2021test,kirsch2022unifying,bickford2023-prediction}.
%
Most information gain-based approaches are heuristics without theoretical guarantees.
%
A notable exception is the work by \citet{Guestrin2005-near,krause2008-near}, which shows the US for the GPR model is optimal to maximize the information gain from the obtained data labels regarding GP prior.
%
Furthermore, from the analysis of kernelized bandits~\citep[e.g., ][]{Srinivas2010-Gaussian,salgia2024random}, we can see that the US and RS guarantee the convergence of the maximum of posterior variance (See Proposition~\ref{prop:us_rs} for details).
%
Another commonly used AF is variance reduction~\citep{Seo2000gaussian,yu2006active,Shoham2023experimental}, which can be computed efficiently in the GPR.
%
However, these AFs do not incorporate the importance of the unlabelled dataset, that is, the prior information regarding the target distribution.
%
In addition, to our knowledge, except for the worst-case analysis in Proposition~\ref{prop:us_rs}, there are no theoretical guarantees for the target prediction error.


% Target distribution-aware AL
Several studies have tackled the development of the target distribution-aware AL~\citep{kirsch2021test,kirsch2022unifying,bickford2023-prediction}.
%
In particular, as an extension of the distributionally robust learning~\citep{chen2020distributionally}, \citet{frogner2021incorporating} proposed \emph{distributionally robust AL} (DRAL), which aims to minimize the worst-case error in the set of target distributions to obtain a robust model.
%
However, since these studies employed the heuristic AL methods based on, e.g., information gain and expected model change~\citep{settles2009-active}, the theoretical guarantee has not been shown.


% Notable work on GPR-based AL is the study by \citet{Guestrin2005-near,krause2008-near}, which provides the optimality of US regarding the mutual information and applies to real-world problems such as sensor placement for weather data.
% %
% However, \citet{bickford2023-prediction} have discussed the AL algorithms without incorporating the test distribution can suffer poor target prediction performance.
% %
% Therefore, several studies have developed the AL algorithm incorporating the target distribution \citep{kirsch2021test,kirsch2022unifying,bickford2023-prediction}.
%
% Target distribution-aware GP-based AL
% Although several studies have developed the AL algorithm that incorporates the target distribution \citep{kirsch2021test,kirsch2022unifying,bickford2023-prediction},
% On the other hand, several studies have considered test distribution-aware AL algorithms that directly reduce target error \citep{yu2006active,kirsch2021test,kirsch2022unifying,bickford2023-prediction}.
% %
% We refer to test distribution-aware AL algorithms as \emph{transductive} AL \citep{yu2006active,kirsch2022unifying}.
% %
% For example, the variance reduction algorithm \citep{yu2006active,Seo2000gaussian} minimizes the sum (mean) of variances over the test input set, which can be interpreted as the expectation of the variance with uniform distribution over the test input set.



% 問題点は
% \begin{enumerate}
%     \item 情報量に基づくアプローチに代表される方法論は基本的に一般的な予測誤差の保証をしない
%     \item VR や US にはBOには理論解析があるが, ターゲット分布を考慮した方法論はない.
%     \item ターゲット分布や分布ロバスト能動学習は存在するが, どちらも経験則
% \end{enumerate}


% Although the AL incorporating the target distribution appears promising, the current studies have two main limitations.
% %
% First, although the AFs are designed based on the target distribution, the theoretical guarantee has not been shown.
% %
% In particular, although the mutual information-based approach is often developed, the relationship between information gain and the exact prediction error is unknown.
% %
% Second, specifying the unique target distribution is often difficult.
% %
% Indeed, in the statistical learning literature, \emph{distributionally robust} learning (DRL) framework~\citep{chen2020distributionally}, which minimizes a maximum of loss function value over target distribution sets, has been developed since there are often many candidates for target distributions.




This paper develops a DRAL framework for the GPR model.
% 
We aim to minimize the worst-case expected error, where the worst-case scenario and the expectation are taken regarding the target distribution candidates and chosen target distributions, respectively.
%
Note that our formulation is a generalization of target distribution-aware AL since it includes the case in which the unique target distribution can be specified.
%
We perform the theoretical analysis under two conditions called Bayesian and frequentist assumptions~\citep{Srinivas2010-Gaussian}, in which we leverage several useful lemmas in kernelized bandit literature~\citep{Srinivas2010-Gaussian,vakili2021-optimal,vakili2021-information,Kusakawa2022-bayesian}.
%
% First, we provide several common properties of this worst-case expected error in the GPR model.
% %
% Based on these properties, we propose simple stochastic and deterministic algorithms.
% %
% We derive the upper bound of the worst-case expected error of the proposed methods, which suggests that, under mild conditions, the error can be arbitrarily small by a finite number of data labels.




Our contributions are summarized as follows:
\begin{enumerate}
    \item We show several properties of the worst-case squared error for the GPR model, which suggests that the error can be bounded from above using the posterior variance even if the input domain is continuous. Along the way to proving the error properties, we show the Lipschitz constant of the posterior mean of GPs in Lemmas~\ref{lem:RKHS_lipschitz} and \ref{lem:bayesian_lipschitz_posterior_mean}, which may be of independent interest.
    %
    \item We propose two DRAL methods for the GPR model, inspired by the RS and the greedy algorithm. Our proposed methods are designed to guarantee the convergence of the (expected) posterior variance.
    %
    \item We show the probabilistic upper bounds of the error incurred by the proposed algorithm, which suggests that under mild conditions, the error can be arbitrarily small by a finite number of data labels.
\end{enumerate}
Finally, we demonstrate the effectiveness of the proposed methods via synthetic and real-world regression problems.

