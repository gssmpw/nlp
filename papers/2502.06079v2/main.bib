@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@article{leonard2014some,
  title={Some properties of path measures},
  author={L{\'e}onard, Christian},
  journal={S{\'e}minaire de Probabilit{\'e}s XLVI},
  pages={207--230},
  year={2014},
  publisher={Springer}
}

@article{wu2024practical,
  title={Practical and asymptotically exact conditional sampling in diffusion models},
  author={Wu, Luhuan and Trippe, Brian and Naesseth, Christian and Blei, David and Cunningham, John P},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{albergo2024nets,
  title={Nets: A non-equilibrium transport sampler},
  author={Albergo, Michael S and Vanden-Eijnden, Eric},
  journal={arXiv preprint arXiv:2410.02711},
  year={2024}
}

@article{ingraham2023illuminating,
  title={Illuminating protein space with a programmable generative model},
  author={Ingraham, John B and Baranov, Max and Costello, Zak and Barber, Karl W and Wang, Wujie and Ismail, Ahmed and Frappier, Vincent and Lord, Dana M and Ng-Thow-Hing, Christopher and Van Vlack, Erik R and others},
  journal={Nature},
  volume={623},
  number={7989},
  pages={1070--1078},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{heng2020controlled,
  title={Controlled sequential monte carlo},
  author={Heng, Jeremy and Bishop, Adrian N and Deligiannidis, George and Doucet, Arnaud},
  journal={The Annals of Statistics},
  volume={48},
  number={5},
  pages={2904--2929},
  year={2020},
  publisher={JSTOR}
}

@book{moral2004feynman,
  title={Feynman-Kac formulae: genealogical and interacting particle systems with applications},
  author={Moral, Pierre},
  year={2004},
  publisher={Springer}
}

@article{naesseth2019elements,
  title={Elements of sequential monte carlo},
  author={Naesseth, Christian A and Lindsten, Fredrik and Sch{\"o}n, Thomas B and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={12},
  number={3},
  pages={307--392},
  year={2019},
  publisher={Now Publishers, Inc.}
}

@article{del2006sequential,
  title={Sequential monte carlo samplers},
  author={Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={68},
  number={3},
  pages={411--436},
  year={2006},
  publisher={Oxford University Press}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@inproceedings{nusken2024transport,
  title={Transport meets variational inference: Controlled monte carlo diffusions},
  author={Vargas, Francisco and Nusken, Nikolas and Padhy, Shreyas and Blessing, Denis},
  booktitle={The Twelfth International Conference on Learning Representations: ICLR 2024},
  year={2024}
}

@article{carbone2023efficient,
  title={Efficient training of energy-based models using jarzynski equality},
  author={Carbone, Davide and Hua, Mengjian and Coste, Simon and Vanden-Eijnden, Eric},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={52583--52614},
  year={2023}
}

@article{vargas2023denoising,
  title={Denoising diffusion samplers},
  author={Vargas, Francisco and Grathwohl, Will and Doucet, Arnaud},
  journal={arXiv preprint arXiv:2302.13834},
  year={2023}
}

@misc{unlock_guidance,
      title={Unlocking Guidance for Discrete State-Space Diffusion and Flow Models}, 
      author={Hunter Nisonoff and Junhao Xiong and Stephan Allenspach and Jennifer Listgarten},
      year={2024},
      eprint={2406.01572},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.01572}, 
}

@article{DEFT,
  author       = {Alexander Denker and
                  Francisco Vargas and
                  Shreyas Padhy and
                  Kieran Didi and
                  Simon V. Mathis and
                  Vincent Dutordoir and
                  Riccardo Barbano and
                  Emile Mathieu and
                  Urszula Julia Komorowska and
                  Pietro Lio},
  title        = {{DEFT:} Efficient Finetuning of Conditional Diffusion Models by Learning
                  the Generalised h-transform},
  journal      = {CoRR},
  volume       = {abs/2406.01781},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2406.01781},
  doi          = {10.48550/ARXIV.2406.01781},
  eprinttype    = {arXiv},
  eprint       = {2406.01781},
  timestamp    = {Tue, 06 Aug 2024 17:12:58 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2406-01781.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{classifier-free-guidance,
      title={Classifier-Free Diffusion Guidance}, 
      author={Jonathan Ho and Tim Salimans},
      year={2022},
      eprint={2207.12598},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2207.12598}, 
}

@misc{sedd,
title={Discrete Diffusion Language Modeling by Estimating the Ratios of the Data Distribution},
author={Aaron Lou and Chenlin Meng and Stefano Ermon},
year={2024},
url={https://openreview.net/forum?id=71mqtQdKB9}
}

@misc{what-does-guidance-do,
      title={What does guidance do? A fine-grained analysis in a simple setting}, 
      author={Muthu Chidambaram and Khashayar Gatmiry and Sitan Chen and Holden Lee and Jianfeng Lu},
      year={2024},
      eprint={2409.13074},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.13074}, 
}

@inproceedings{classifier-guidance,
title={Diffusion Models Beat {GAN}s on Image Synthesis},
author={Prafulla Dhariwal and Alexander Quinn Nichol},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=AAWuCvzaVt}
}

@inproceedings{protein-discrete-diffusion,
title={Diffusion Language Models Are Versatile Protein Learners},
author={Xinyou Wang and Zaixiang Zheng and Fei YE and Dongyu Xue and Shujian Huang and Quanquan Gu},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=NUAbSFqyqb}
}

@inproceedings{
simple-controllable-diffusion,
title={Simple and Controllable Uniform Discrete Diffusion Language Models},
author={Anonymous},
booktitle={Submitted to The Thirteenth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=i5MrJ6g5G1},
note={under review}
}

@inproceedings{dexperts,
    title = "{DE}xperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts",
    author = "Liu, Alisa  and
      Sap, Maarten  and
      Lu, Ximing  and
      Swayamdipta, Swabha  and
      Bhagavatula, Chandra  and
      Smith, Noah A.  and
      Choi, Yejin",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.522/",
    doi = "10.18653/v1/2021.acl-long.522",
    pages = "6691--6706",
    abstract = "Despite recent advances in natural language generation, it remains challenging to control attributes of generated text. We propose DExperts: Decoding-time Experts, a decoding-time method for controlled text generation that combines a pretrained language model with {\textquotedblleft}expert{\textquotedblright} LMs and/or {\textquotedblleft}anti-expert{\textquotedblright} LMs in a product of experts. Intuitively, under the ensemble, tokens only get high probability if they are considered likely by the experts, and unlikely by the anti-experts. We apply DExperts to language detoxification and sentiment-controlled generation, where we outperform existing controllable generation methods on both automatic and human evaluations. Moreover, because DExperts operates only on the output of the pretrained LM, it is effective with (anti-)experts of smaller size, including when operating on GPT-3. Our work highlights the promise of tuning small LMs on text with (un)desirable attributes for efficient decoding-time steering."
}

@inproceedings{fairseq,
    title = "fairseq: A Fast, Extensible Toolkit for Sequence Modeling",
    author = "Ott, Myle  and
      Edunov, Sergey  and
      Baevski, Alexei  and
      Fan, Angela  and
      Gross, Sam  and
      Ng, Nathan  and
      Grangier, David  and
      Auli, Michael",
    editor = "Ammar, Waleed  and
      Louis, Annie  and
      Mostafazadeh, Nasrin",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-4009/",
    doi = "10.18653/v1/N19-4009",
    pages = "48--53",
    abstract = "fairseq is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found at \url{https://www.youtube.com/watch?v=OtgDdWtHvto}"
}

@misc{roberta,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1907.11692}, 
}
@misc{llama,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.13971}, 
}
@misc{structured-vornoi-sampling,
      title={Structured Voronoi Sampling}, 
      author={Afra Amini and Li Du and Ryan Cotterell},
      year={2024},
      eprint={2306.03061},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.03061}, 
}
@misc{ronneberger2015unetconvolutionalnetworksbiomedical,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1505.04597}, 
}
@inproceedings{bert-score,
  title={BERTScore: Evaluating Text Generation with BERT},
  author={Tianyi Zhang* and Varsha Kishore* and Felix Wu* and Kilian Q. Weinberger and Yoav Artzi},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=SkeHuCVFDr}
}
@misc{he2021debertadecodingenhancedbertdisentangled,
      title={DeBERTa: Decoding-enhanced BERT with Disentangled Attention}, 
      author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
      year={2021},
      eprint={2006.03654},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2006.03654}, 
}

@misc{wu2016googlesneuralmachinetranslation,
      title={Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation}, 
      author={Yonghui Wu and Mike Schuster and Zhifeng Chen and Quoc V. Le and Mohammad Norouzi and Wolfgang Macherey and Maxim Krikun and Yuan Cao and Qin Gao and Klaus Macherey and Jeff Klingner and Apurva Shah and Melvin Johnson and Xiaobing Liu and Łukasz Kaiser and Stephan Gouws and Yoshikiyo Kato and Taku Kudo and Hideto Kazawa and Keith Stevens and George Kurian and Nishant Patil and Wei Wang and Cliff Young and Jason Smith and Jason Riesa and Alex Rudnick and Oriol Vinyals and Greg Corrado and Macduff Hughes and Jeffrey Dean},
      year={2016},
      eprint={1609.08144},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1609.08144}, 
}
@inproceedings{NEURIPS2023_fc65fab8,
 author = {Fan, Ying and Watkins, Olivia and Du, Yuqing and Liu, Hao and Ryu, Moonkyung and Boutilier, Craig and Abbeel, Pieter and Ghavamzadeh, Mohammad and Lee, Kangwook and Lee, Kimin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {79858--79885},
 publisher = {Curran Associates, Inc.},
 title = {DPOK: Reinforcement Learning for Fine-tuning Text-to-Image Diffusion Models},
 volume = {36},
 year = {2023}
}


@inproceedings{
vignac2023digress,
title={DiGress: Discrete Denoising diffusion for graph generation},
author={Clement Vignac and Igor Krawczuk and Antoine Siraudin and Bohan Wang and Volkan Cevher and Pascal Frossard},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=UaAD-Nu86WX}
}

@misc{bradley2024classifierfreeguidancepredictorcorrector,
      title={Classifier-Free Guidance is a Predictor-Corrector}, 
      author={Arwen Bradley and Preetum Nakkiran},
      year={2024},
      eprint={2408.09000},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.09000}, 
}

@misc{campbell2022continuoustimeframeworkdiscrete,
      title={A Continuous Time Framework for Discrete Denoising Models}, 
      author={Andrew Campbell and Joe Benton and Valentin De Bortoli and Tom Rainforth and George Deligiannidis and Arnaud Doucet},
      year={2022},
      eprint={2205.14987},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2205.14987}, 
}
@inproceedings{multimodal-flow,
  author       = {Andrew Campbell and
                  Jason Yim and
                  Regina Barzilay and
                  Tom Rainforth and
                  Tommi S. Jaakkola},
  title        = {Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows
                  with Applications to Protein Co-Design},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=kQwSbv0BR4},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/CampbellYBRJ24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
diffusion-jiaxin,
title={Simplified and Generalized Masked Diffusion for Discrete Data},
author={Jiaxin Shi and Kehang Han and Zhe Wang and Arnaud Doucet and Michalis Titsias},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=xcqSOfHt4g}
}

@misc{training-free-guidance,
      title={Training-Free Guidance for Discrete Diffusion Models for Molecular Generation}, 
      author={Thomas J. Kerby and Kevin R. Moon},
      year={2024},
      eprint={2409.07359},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2409.07359}, 
}

@INPROCEEDINGS{partal-resampling,
  author={Martino, L. and Elvira, V. and Louzada, F.},
  booktitle={2016 IEEE Statistical Signal Processing Workshop (SSP)}, 
  title={Weighting a resampled particle in Sequential Monte Carlo}, 
  year={2016},
  volume={},
  number={},
  pages={1-5},
  keywords={Monte Carlo methods;Silicon;Probability density function;Signal processing;Conferences;Algorithm design and analysis;Signal processing algorithms;Importance Sampling;Sequential Importance Resampling;Sequential Monte Carlo;Particle Filtering},
  doi={10.1109/SSP.2016.7551711}}

@book{intro-smc,
  title={An Introduction to Sequential Monte Carlo},
  author={Chopin, N. and Papaspiliopoulos, O.},
  isbn={9783030478452},
  series={Springer Series in Statistics},
  url={https://books.google.co.uk/books?id=ZZEAEAAAQBAJ},
  year={2020},
  publisher={Springer International Publishing}
}

@article{adaptive-resampling,
   title={On adaptive resampling strategies for sequential Monte Carlo methods},
   volume={18},
   ISSN={1350-7265},
   url={http://dx.doi.org/10.3150/10-BEJ335},
   DOI={10.3150/10-bej335},
   number={1},
   journal={Bernoulli},
   publisher={Bernoulli Society for Mathematical Statistics and Probability},
   author={Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay},
   year={2012},
   month=feb }

@misc{li2024derivativefreeguidancecontinuousdiscrete,
      title={Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding}, 
      author={Xiner Li and Yulai Zhao and Chenyu Wang and Gabriele Scalia and Gokcen Eraslan and Surag Nair and Tommaso Biancalani and Shuiwang Ji and Aviv Regev and Sergey Levine and Masatoshi Uehara},
      year={2024},
      eprint={2408.08252},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.08252}, 
}

@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@book{Del_Moral_Penev_2017, place={Boca Raton}, title={Stochastic processes: From applications to theory}, publisher={CRC Press, Taylor \& Francis Group}, author={Del Moral, Pierre and Penev, Spiridon}, year={2017}} 

@inproceedings{
zhao2024probabilistic,
title={Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo},
author={Stephen Zhao and Rob Brekelmans and Alireza Makhzani and Roger Baker Grosse},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=frA0NNBS1n}
}

@inproceedings{
venkatraman2024amortizing,
title={Amortizing intractable inference in diffusion models for vision, language, and control},
author={Siddarth Venkatraman and Moksh Jain and Luca Scimeca and Minsu Kim and Marcin Sendera and Mohsin Hasan and Luke Rowe and Sarthak Mittal and Pablo Lemos and Emmanuel Bengio and Alexandre Adam and Jarrid Rector-Brooks and Yoshua Bengio and Glen Berseth and Nikolay Malkin},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=gVTkMsaaGI}
}


@misc{domingoenrich2025adjointmatchingfinetuningflow,
      title={Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control}, 
      author={Carles Domingo-Enrich and Michal Drozdzal and Brian Karrer and Ricky T. Q. Chen},
      year={2025},
      eprint={2409.08861},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.08861}, 
}
@misc{black2024trainingdiffusionmodelsreinforcement,
      title={Training Diffusion Models with Reinforcement Learning}, 
      author={Kevin Black and Michael Janner and Yilun Du and Ilya Kostrikov and Sergey Levine},
      year={2024},
      eprint={2305.13301},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.13301}, 
}
@misc{clark2024directlyfinetuningdiffusionmodels,
      title={Directly Fine-Tuning Diffusion Models on Differentiable Rewards}, 
      author={Kevin Clark and Paul Vicol and Kevin Swersky and David J Fleet},
      year={2024},
      eprint={2309.17400},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2309.17400}, 
}
@misc{uehara2025inferencetimealignmentdiffusionmodels,
      title={Inference-Time Alignment in Diffusion Models with Reward-Guided Generation: Tutorial and Review}, 
      author={Masatoshi Uehara and Yulai Zhao and Chenyu Wang and Xiner Li and Aviv Regev and Sergey Levine and Tommaso Biancalani},
      year={2025},
      eprint={2501.09685},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2501.09685}, 
}
@misc{song2021scorebasedgenerativemodelingstochastic,
      title={Score-Based Generative Modeling through Stochastic Differential Equations}, 
      author={Yang Song and Jascha Sohl-Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
      year={2021},
      eprint={2011.13456},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2011.13456}, 
}
@misc{song2020generativemodelingestimatinggradients,
      title={Generative Modeling by Estimating Gradients of the Data Distribution}, 
      author={Yang Song and Stefano Ermon},
      year={2020},
      eprint={1907.05600},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1907.05600}, 
}
@misc{lipman2023flowmatchinggenerativemodeling,
      title={Flow Matching for Generative Modeling}, 
      author={Yaron Lipman and Ricky T. Q. Chen and Heli Ben-Hamu and Maximilian Nickel and Matt Le},
      year={2023},
      eprint={2210.02747},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.02747}, 
}
@misc{lipman2024flowmatchingguidecode,
      title={Flow Matching Guide and Code}, 
      author={Yaron Lipman and Marton Havasi and Peter Holderrieth and Neta Shaul and Matt Le and Brian Karrer and Ricky T. Q. Chen and David Lopez-Paz and Heli Ben-Hamu and Itai Gat},
      year={2024},
      eprint={2412.06264},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2412.06264}, 
}
@misc{ho2020denoisingdiffusionprobabilisticmodels,
      title={Denoising Diffusion Probabilistic Models}, 
      author={Jonathan Ho and Ajay Jain and Pieter Abbeel},
      year={2020},
      eprint={2006.11239},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.11239}, 
}
@misc{albergo2023stochasticinterpolantsunifyingframework,
      title={Stochastic Interpolants: A Unifying Framework for Flows and Diffusions}, 
      author={Michael S. Albergo and Nicholas M. Boffi and Eric Vanden-Eijnden},
      year={2023},
      eprint={2303.08797},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.08797}, 
}
@misc{albergo2023buildingnormalizingflowsstochastic,
      title={Building Normalizing Flows with Stochastic Interpolants}, 
      author={Michael S. Albergo and Eric Vanden-Eijnden},
      year={2023},
      eprint={2209.15571},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2209.15571}, 
}
@misc{podell2023sdxlimprovinglatentdiffusion,
      title={SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis}, 
      author={Dustin Podell and Zion English and Kyle Lacey and Andreas Blattmann and Tim Dockhorn and Jonas Müller and Joe Penna and Robin Rombach},
      year={2023},
      eprint={2307.01952},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2307.01952}, 
}
@misc{rombach2022highresolutionimagesynthesislatent,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2022},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10752}, 
}
@misc{blattmann2023stablevideodiffusionscaling,
      title={Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets}, 
      author={Andreas Blattmann and Tim Dockhorn and Sumith Kulal and Daniel Mendelevitch and Maciej Kilian and Dominik Lorenz and Yam Levi and Zion English and Vikram Voleti and Adam Letts and Varun Jampani and Robin Rombach},
      year={2023},
      eprint={2311.15127},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2311.15127}, 
}

@inproceedings{
cornet2024equivariant,
title={Equivariant Neural Diffusion for Molecule Generation},
author={Fran{\c{c}}ois R J Cornet and Grigory Bartosh and Mikkel N. Schmidt and Christian A. Naesseth},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=40pE5pFhWl}
}
@misc{hoogeboom2022equivariantdiffusionmoleculegeneration,
      title={Equivariant Diffusion for Molecule Generation in 3D}, 
      author={Emiel Hoogeboom and Victor Garcia Satorras and Clément Vignac and Max Welling},
      year={2022},
      eprint={2203.17003},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2203.17003}, 
}
@article{watson2023novo,
  title={De novo design of protein structure and function with RFdiffusion},
  author={Watson, Joseph L and Juergens, David and Bennett, Nathaniel R and Trippe, Brian L and Yim, Jason and Eisenach, Helen E and Ahern, Woody and Borst, Andrew J and Ragotte, Robert J and Milles, Lukas F and others},
  journal={Nature},
  volume={620},
  number={7976},
  pages={1089--1100},
  year={2023},
  publisher={Nature Publishing Group UK London}
}
@misc{gulrajani2023likelihoodbaseddiffusionlanguagemodels,
      title={Likelihood-Based Diffusion Language Models}, 
      author={Ishaan Gulrajani and Tatsunori B. Hashimoto},
      year={2023},
      eprint={2305.18619},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.18619}, 
}
@misc{dhariwal2021diffusionmodelsbeatgans,
      title={Diffusion Models Beat GANs on Image Synthesis}, 
      author={Prafulla Dhariwal and Alex Nichol},
      year={2021},
      eprint={2105.05233},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2105.05233}, 
}
@misc{ho2022classifierfreediffusionguidance,
      title={Classifier-Free Diffusion Guidance}, 
      author={Jonathan Ho and Tim Salimans},
      year={2022},
      eprint={2207.12598},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2207.12598}, 
}