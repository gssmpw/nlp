\section{Problem formulation}
\label{sec:prob_form}
We consider an on-demand service platform which operates on a discrete time horizon consisting of $T$ decision time steps $\{1,2,...,T\}$. Within this time horizon, on-demand requests and gig workers arrive in the system stochastically. Each gig worker is willing to serve requests in exchange for a fee. The decision to accept a request is based on the gig worker's individual utility function, which is unknown to the platform operator. Generally, a higher compensation increases the likelihood of a gig worker accepting a request. Gig workers have the flexibility to choose any of the offered requests or reject all offers. The operatorâ€™s task is to set a compensation for each offered request, with the objective of maximizing net profit over the complete time horizon.

\subsection{Problem formulation as an \gls{acr:mdp}}
The problem setting outlined above unfolds as an \gls{acr:mdp} as follows:\\
\noindent \underline{System State:} 
At any decision time step $t \in \{1,...,T\}$ the system state  $S\hspace{-0.1em}_t = (\mathcal{R}\hspace{0.05em}_{t},\mathcal{G}_t)$ is a pair where $\mathcal{R}\hspace{0.05em}_t$ is the set of active on-demand requests and $\mathcal{G}_t$ is the set of available gig workers. For simplicity, we will refer to $\mathcal{R}\hspace{0.05em}_{t}$ and $\mathcal{G}_t$ as the request and gig worker states, correspondingly. We assume that the gig worker state $\mathcal{G}_t$ can accommodate at most one gig worker and that they remain in the system for only one time step.  \\
\noindent \underline{On-demand requests:} 
We describe each on-demand request $i \in \mathcal{R}\hspace{0.05em}_{t}$ by a set of characteristics $\mathbf{x}_i =(x_{i1},...,x_{ik})$, a reward $r_i>0$ which the operator will receive for servicing the request, an expiration step $t_i^{\mathrm{exp}}$ after which the request will leave the system without being serviced and a penalty $\beta_i<0$ which the operator has to pay if the request is not serviced. \\
\noindent \underline{Gig workers:} 
Gig workers are willing to serve a single on-demand request in return for some compensation~$c_i$. The willingness of gig worker $j \in \mathcal{G}_t$ to service an on-demand request $i \in \mathcal{R}\hspace{0.05em}_{t}$ is stochastic and can be described by a stochastic function:
\begin{align}
f_{ij} = h_j(\mathbf{x}_i,c_i) + e_{ij} \label{eq:util}
\end{align}
where $\mathbf{x}_i = (x_{i1}, ..., x_{ik})$ is a feature vector that describes the characteristics of request $i \in \mathcal{R}\hspace{0.05em}_{t}$, $c_i$ is the compensation for servicing request $i$, and $e_{ij}$ is a noise variable. This function is unknown to the system operator. \\
\noindent \underline{Feasible Decisions:} 
At every decision time step $t \in \{1,...,T\}$ the central operator must offer a compensation~$c_i$ to a gig worker for servicing each request $i \in \mathcal{R}\hspace{0.05em}_{t}$. A feasible compensation for servicing a request~$i \in \mathcal{R}\hspace{0.05em}_{t}$ must be non-negative ($c_i \geq 0$). We define the set of feasible compensations for a state $S\hspace{-0.1em}_t$ as:
\begin{align}
\mathcal{C}(S\hspace{-0.1em}_t) = \{\mathbf{c_t} = (c_i)_{i \in \mathcal{R}\hspace{0.05em}_{t}} :  c_i \geq 0  \ \ \forall i \in \mathcal{R}\hspace{0.05em}_{t} \}
\end{align} \\
\noindent \underline{Evolution of the system:} 
At each decision time step $t \in \{1,...,T\}$, the operator observes the system state $S\hspace{-0.1em}_t = (\mathcal{R}\hspace{0.05em}_{t},\mathcal{G}_t)$. If a gig worker is in the system, the central operator decides on a compensation $c_i$ for each request $i \in \mathcal{R}\hspace{0.05em}_{t}$ which will be offered to the gig worker as a compensation for fulfilling the request. Subsequently, the gig worker receives these offers and either selects to service the offer which maximizes their utility or, in case all offers have low utility, rejects all offers. We denote by $P^i_{t}(\mathbf{c_t})$ the probability of a gig worker accepting request $i$ for compensation decision $\mathbf{c_t} = (c^i_t)_{i \in \mathcal{R}\hspace{0.05em}_{t}}$ in system state $\mathcal{R}\hspace{0.05em}_{t}$. We denote by $P^\emptyset_{t}(\mathbf{c_t})$ the alternative where the gig worker does not select any request. In case the gig worker selects a request, the gig worker receives a compensation $c_i$, the operator receives a reward of $r_i - c_i$, and both the gig worker and the request leave the system. If the gig worker did not select any offer, the gig worker leaves the system without compensation. On-demand requests that expire in $t$, i.e., such that $t_i^{\mathrm{exp}} = t$, also leave the system and the operator receives the corresponding penalties $\beta_i$. So far, the system has evolved due to the realization of the operator's compensation decision and the gig worker's acceptance decision reaching a post decision state. We refer to the \textit{post-decision state} at time step $t$ as the intermediate state after a gig worker has decided which request offer to accept and after removing expired requests, but before new requests and gig workers arrive. We define the post-decision state $\mathcal{R}\hspace{0.05em}_t^{p}$ as a subset of the request state $\mathcal{R}\hspace{0.05em}_{t}$. To this end, we note that, the probabilities $P^i_{t}(\mathbf{c_t})$ and $P^\emptyset_{t}(\mathbf{c_t})$ establish a probability distribution for the transition into post-decision states. Figure~\ref{fig:state_trans} illustrates the state transitions, including the distribution over the post-decision states. The system then evolves between decision states $t$ and $t+1$ as new requests $\mathcal{R}^{\mathrm{new}}$ and new gig workers $\mathcal{G}^{\mathrm{new}}$ arrive, and transitions into the next state~$S\hspace{-0.1em}_{t+1}$ (see Figure~\ref{fig:state_trans}). Lastly, we assume that all requests expire by the last decision time step~$T$.
\begin{figure}[t!]%
    \centering
    \fontsize{10}{10}\selectfont
    \includegraphics[width=15cm]{figures/state_transitions1.pdf}
    \caption{\textnormal{State transitions.}}
    \label{fig:state_trans}%
\end{figure} 

\noindent \underline{Expected immediate reward:} 
The expected immediate reward for the operator at decision time step $t$ for state $S\hspace{-0.1em}_t = (\mathcal{R}\hspace{0.05em}_{t},\mathcal{G}_t)$ when considering a compensation decision $\mathbf{c_t} = (c^i_t)_{i \in \mathcal{R}\hspace{0.05em}_{t}}$ reads:
\begin{align}
R_t(\mathbf{c_t}) = & \mathbbm{1}_{|\mathcal{G}_t|=1} [\sum_{i \in \mathcal{R}\hspace{0.05em}_{t}}{P^i_{t}(\mathbf{c_t})(r_i - c_t^i - \beta_i \mathbbm{1}_{i \in \mathcal{R}\hspace{0.05em}_t^{\mathrm{exp}}}}) ] + \! \sum_{i \in \mathcal{R}\hspace{0.05em}_t^{\mathrm{exp}}}\!\beta_i
\label{eq:imm_rew}
\end{align}
\noindent where $r_i - c_t^i$ is the profit for request $i$ being serviced for a compensation of $c_t^i$. The term $\sum_{i \in \mathcal{R}\hspace{0.05em}_t^{\mathrm{exp}}}\!\beta_i$ accounts for all penalties that result for all expiring requests while the term $- \beta_i \mathbbm{1}_{i \in \mathcal{R}\hspace{0.05em}_t^{\mathrm{exp}}}$ ensures that we omit the penalty of an expiring request if it gets accepted. \\
\noindent \underline{Compensation policy:} 
We assume that the operator takes decisions based on a deterministic compensation policy which we define as a function $\pi_p: S\hspace{-0.1em}_t \mapsto \pi_p(S\hspace{-0.1em}_t)$ that maps any state $S\hspace{-0.1em}_t$ to a feasible compensation decision $c \in \mathcal{C}(S\hspace{-0.1em}_t)$. \\
\noindent \underline{Objective:} 
We aim to study an online learning problem from the perspective of the central operator which is responsible for assigning compensations to on-demand requests. Our objective is to find a compensation policy $\pi_p$ that maximizes the expected reward for the complete time horizon:
\begin{equation}
  \max_{\pi_p}\mathbb{E}\left(\sum_{t=1}^{T}{R_t(\mathbf{c_t})}|\pi_p\right)
\end{equation} where $R_t(\mathbf{c_t})$ is the expected immediate reward at decision time step $t$ for compensation decision $\mathbf{c_t}$.

\subsection{Discussion}

Three comments on our problem are in order. First, our model processes offers by considering one gig worker at a time. The assumption that $\mathcal{G}_t$ can accommodate at most one gig worker can be justified in two ways. First, by adjusting the frequency of decision time steps so that at most one gig worker arrives per step, or second, by allowing multiple gig workers to arrive simultaneously and queuing them for sequential consideration in subsequent steps. Formally, let $\mathcal{Q}$ represent the queue of arriving gig workers. At each time step $t$, all newly arrived gig workers are added to $\mathcal{Q}$ for processing. The operator then observes the first gig worker in the queue (FIFO) and includes them in $\mathcal{G}_t$. If $\mathcal{Q}$ is not empty, the operator will observe the next gig worker in the queue in the next time step. This sequential processing ensures that $\mathcal{G}_t$ contains at most one gig worker at any time step.
Second, we assume gig workers accept one request at a time in exchange for a fee, which aligns with many real-world applications. However, an alternative approach could involve offering bundles of requests to gig workers. Extending the problem to include bundles instead of individual offers would introduce additional complexity due to the combinatorial nature of the decision-making process, making the corresponding \gls{acr:mdp} more challenging to solve. Nonetheless, we believe that with proper algorithm implementation and an efficient \gls{acr:mnl} model estimator, handling bundles of requests could be a feasible extension.
Lastly, our methodology focuses on a deterministic compensation policy, however, the platform operator could alternatively opt for a stochastic compensation policy. We opted for a deterministic policy to ensure consistency and predictability for gig workers. This consistency is particularly valuable in a practical context, as it fosters trust and transparency, reducing uncertainty for workers and enabling more reliable income expectations.

