\section{Experimental Design}
\label{sec:exp_des}

In the following section, we outline our numerical experiments used to evaluate the performance of our algorithm. To this end, we focus on environments that simulate delivery and ride-hailing platforms, which are two of the fastest growing sectors in the gig economy. Section~\ref{sec:syn_data} introduces our experiments for fully synthetic datasets, which model dynamic environments with stochastic on-demand request and gig worker arrivals, applicable to both delivery and ride-hailing contexts. These synthetic datasets allow us to evaluate the algorithm’s performance across diverse scenarios, including variations in request arrival rates and different compositions of the gig worker population. We consider two scenarios in terms of gig worker population: one with a homogeneous gig worker population and another with a heterogeneous gig worker population composed of three distinct groups of gig workers. Section \ref{sec:nyt_data} introduces our experiments using real-world data from the \cite{NYTdata} dataset, allowing us to assess the algorithm’s performance in a more heterogeneous and realistic setting that simulates a ride-hailing platform. This dataset captures differences between instances; for example, even within instances from the same day and hour, events like national holidays or weather conditions can introduce significant variability. We simulate gig worker behavior, considering both weak and strong location preferences across four regions of Manhattan. Section \ref{sec:benchmarks} presents benchmark policies, including the full information solution policy and formula-based policies, and introduces the performance measure used for comparative analyses. 

\subsection{Synthetic scenarios}
\label{sec:syn_data}

\begin{figure}[b!]%
    \centering
    \fontsize{10}{10}\selectfont
    \subfloat[\centering Utility of group 1]{{\includegraphics[width=0.3\linewidth]{figures/momnl/utility_momnl_dtype_0_req_type.pdf} }}%
    \subfloat[\centering Utility of group 2]{{\includegraphics[width=0.3\linewidth]{figures/momnl/utility_momnl_dtype_1_req_type.pdf} }}%
    \subfloat[\centering Utility of group 3]{{\includegraphics[width=0.3\linewidth]{figures/momnl/utility_momnl_dtype_2_req_type.pdf} }}%
    \caption{\textnormal{Utilities of each gig worker group in Scenario II separated by the on-demand request type}}%
    \label{fig:utility_scen_2}%
\end{figure}

We simulate a dynamic environment over a horizon of $T = 50$ time steps and model request arrivals using a Poisson Point Process with an arrival rate $\lambda_r$. The maximum duration for which a request stays in the system follows an exponential distribution with parameter $\beta_{\varepsilon}$. There are $k$ types of requests, each defined by $m$ features, a pickup, and a destination location. Requests originate from $n_l^r$ possible locations and have $n_d^r$ possible destinations, both being uniformly distributed. We calculate the rewards for requests as a weighted sum of their characteristics and travel time, with an additional reward for urgency if the request has a deadline of less than three time steps. We calculate request penalties in a  similar way, with an additional penalty for requests that remain in the system for extended periods. The weights for rewards and penalties are uniformly sampled. 

For gig workers, arrivals also follow a Poisson Point Process with an arrival rate $\lambda_g$. We explore two scenarios regarding the types of gig workers. In Scenario I, the gig worker population is homogeneous, represented by a single group ($D = 1$). Within this scenario, we examine three sub-scenarios (I.1–I.3) to assess the impact of varying arrival rates of on-demand requests. Specifically, we test three different request arrival rates, which are equal to, lower or higher than the gig workers' arrival rate correspondingly. In Scenario II, there are three distinct groups of gig workers ($D = 3$), each with a different utility function. We model the utility function for each group as a weighted sum of request characteristics, travel time, preferences for pickup and dropoff locations, and an additional stochastic term. For each gig worker group $d \in [1, \dots, D]$, we denote as $\mathbf{w_d}$ the weight vector associated with this weighted sum, with its values being uniformly sampled. Figure \ref{fig:utility_scen_2} shows the utilities of each gig worker group in Scenario II grouped by each on-demand request type. We assume that the utility of the no-selection alternative is $u_0 = 0$, implying that the deterministic component of the gig worker’s utility is always negative. Consequently, a positive compensation $c > 0$ incentivizes a gig worker's request selection in case of a positive utility. Additionally, we assume that the stochastic term of the utility follows a zero-mean Gumbel distribution parameterized by $\mu=1$ for all gig worker groups. 

\begin{table}[b!]
    \centering
    \captionof{table}{Synthetic Data Generation Parameters}
    \label{tab:scen_param}
    \begin{tabular}{lllllllllllll}
        \toprule
         & $D$ & $\lambda_r$ & $\beta_{\varepsilon}$ & $k$ & $m$ & $n_l^r$ &  $n_d^r$ & $\lambda_g$ & $T$ \\
        \midrule
        \textbf{Scen. I.1} & 1 & 0.5 & 0.1 & 5 & 3 & 5 & 5 & 0.5  & 50 \\
        \midrule
        \textbf{Scen. I.2} & 1 & 0.3 & 0.1 & 5 & 3 & 5 & 5 & 0.5  & 50 \\
        \midrule
        \textbf{Scen. I.3} & 1 & 1 & 0.1 & 5 & 3 & 5 & 5 & 0.5  & 50 \\
        \midrule
        \textbf{Scen. II} & 3 & 0.5 & 0.1 & 5 & 3 & 5 & 5 & 0.5  & 50 \\
        \midrule
        \textbf{NYT weak} & 1 & - & 0.1 & 5 & 2 & 4 & 4 & 0.75 & 120 \\
        \midrule
        \textbf{NYT strong} & 1 & - & 0.1 & 5 & 2 & 4 & 4 & 0.75 & 120 \\
        \bottomrule
    \end{tabular}
\end{table}

For each scenario, we generate 630 distinct realizations of on-demand requests and gig workers. Any policy can be deployed in these scenario realizations, resulting in various episodes of experience. While state transitions may differ in these episodes of experiences, depending on the policy used to generate them, the system's exogenous stochasticity remains constant across them. We divide these 630 realizations into three sets: a training set of 480 realizations, a testing set of 120 realizations, and a validation set of 30 realizations. We use the training realizations to train the \gls{acr:mnl} model and the post-decision value function approximation, while the validation set helps determine the stopping point for the post-decision value function approximation training process, as well as to select the final model. We use the testing set exclusively to evaluate the performance of our algorithm. Table \ref{tab:scen_param} shows the exact parameters used to generate the simulations of each scenario. 

While these datasets exhibit a certain level of complexity, they still lack certain attributes that characterize real-world data. In real-world scenarios, arrivals do not necessarily follow a Poisson Point Process and the distribution among pickup and dropoff locations are not necessarily uniformly distributed. Lastly, significant heterogeneity can exist between different instances. In the following section, we extend our experimental setup using real-world data from the \cite{NYTdata} dataset in order to explore the algorithm’s performance in such heterogeneous settings.

\subsection{New York Taxi (NYT) data}
\label{sec:nyt_data}

\begin{figure}[b!]%
    \centering
    \fontsize{10}{10}\selectfont
    \begin{minipage}[b]{0.3\textwidth}
        \centering
        \subfloat[\centering Manhattan segmentation to regions]{\includegraphics[width=\textwidth]{figures/Manhattan_map_final.pdf}\label{fig:manhattan}}
        \vspace*{-0.8cm}
    \end{minipage}%
    \hspace*{0.2cm}
    \begin{minipage}[b]{0.6\textwidth}
        \centering
        \subfloat[\centering Utilities by pickup location\newline(weak location preferences)]{{\includegraphics[width=0.49\textwidth]{figures/nyt/nyt_weak_pickup_location_id_split.pdf}}\label{fig:util_nyt_weak_a}}%
        \hspace*{0.3cm}
        \subfloat[\centering Utilities by dropoff location\newline(weak location preferences)]{{\includegraphics[width=0.49\textwidth]{figures/nyt/nyt_weak_dropoff_location_id_split.pdf}}\label{fig:util_nyt_weak_b}}%
        \vspace*{-0.4cm}
        
        \subfloat[\centering Utilities by pickup location\newline(strong location preferences)]{{\includegraphics[width=0.49\textwidth]{figures/nyt_strong/nyt_strong_pickup_location_id_split.pdf}}\label{fig:util_nyt_strong_a}}%
        \hspace*{0.3cm}
        \subfloat[\centering Utilities by dropoff location\newline(strong location preferences)]{{\includegraphics[width=0.49\textwidth]{figures/nyt_strong/nyt_strong_dropoff_location_id_split.pdf}}\label{fig:util_nyt_strong_b}}%
    \end{minipage}
    \caption{\textnormal{Manhattan segmentation (a) and histograms of request utilities grouped by pickup and dropoff locations for gig workers with weak location preferences (b-c) and strong location preferences (d-e).}}
    \label{fig:manhattan_utilities}%
\end{figure}

The \cite{NYTdata} dataset includes detailed trip records for yellow taxis operating in New York City in the year 2018. The dataset includes features such as pick-up and drop-off dates/times, pick-up and drop-off taxi zone locations and trip distances. Due to the substantial volume of trip requests in New York City, we constrained the dataset to requests originating in the Manhattan region on Mondays from 11 a.m. to 12 p.m., and further reduced the dataset size by selecting 30\% of the total on-demand requests. Each episode represents a 30-minute interval, either from 11 a.m. to 11:30 a.m. or from 11:30 a.m. to 12 p.m. Considering the 53 Mondays in 2018, this selection resulted in a total of 106 instances. We select a horizon length $T$ of 120 time steps, corresponding to one decision every 15 seconds, a time frame deemed realistic for gig worker decision-making processes. In this scenario, we assume that the gig worker population exhibits homogeneous preferences. Due to the unavailability of real-world data on gig worker decisions, we simulate gig worker utility synthetically. To this end, we divide Manhattan into four distinct regions, following a similar approach as \cite{yahia2021book}. These regions roughly correspond to: (1) Lower Manhattan, (2) Midtown Manhattan, (3) Upper West Side, and (4) Upper East Side as shown in Figure \ref{fig:manhattan}. We explore two variants of gig worker preferences with respect to region specific pickup and/or dropoff location preferences. In the first variant we generate the location preferences following the same procedure as previously described, i.e., where weights are uniformly selected; in the second variant we explicitly impose a strong preference for specific locations. These will be referred to as weak and strong location preference gig workers, respectively. Figures \ref{fig:manhattan_utilities}b\&c present histograms illustrating the utility distribution of gig workers with weak location preferences across all requests. We display the utility grouped by the requests' pickup locations (Figure \ref{fig:util_nyt_weak_a}) and dropoff locations (Figure \ref{fig:util_nyt_weak_b}). As can be seen, gig workers do not exhibit a strong preference for any particular pickup or dropoff location, resulting in similar utility distributions across locations. Analogously, Figures \ref{fig:manhattan_utilities}d\&e present the utility distributions for the scenario where gig workers have strong location preferences. In this scenario, requests with pickup location 1 are highly preferred, whereas those with dropoff location 1 are less preferred. To increase the complexity of the data, we also introduce two arbitrary characteristics for each request, and assign rewards and penalties similarly to the fully synthetic dataset. The resulting 106 realizations are divided into three subsets: a training set comprising 76 realizations, a testing set of 20 realizations, and a validation set containing the remaining 10 realizations.

\subsection{Benchmark policies \& performance measure}
\label{sec:benchmarks}
To assess the performance of our algorithm, we compare it against several benchmark policies. These benchmarks include policies that calculate compensation based on factors like reward, travel distance, and urgency, reflecting common practices in crowdsourced delivery platforms \citep{alnaggar2021crowdsourced}, as well as theoretical upper bounds to help identify the strengths and limitations of our approach. Additionally, to understand the effect of the \gls{acr:mnl} model on performance, we create benchmarks using our algorithm with both the true \gls{acr:mnl} parameters and perturbed versions of them. We now provide details on the benchmark policies used to evaluate our algorithm’s performance. 
~\\
\textbf{\gls{acr:pp}:} The reward percentage compensation policy sets a compensation for a request $i$ based on a percentage of its total reward. We perform hyperparameter tuning via gridsearch to select the best percentage ranging from $40-100\%$. 
~\\
\textbf{\gls{acr:fp}:} The formula-based compensation policy sets a compensation for a request $i$ based on the following formula:
\begin{align}
\text{FP}(i) = v_1 \cdot r_i + v_2 \cdot td_i + v_3 \cdot \beta_i + (v_4 \cdot r_i) \cdot \mathbbm{1}_{i \in \mathcal{R}\hspace{0.05em}_t^{\mathrm{exp}}}
\end{align}
where $r_i$ is the reward, $td_i$ is the travel distance and $\beta_i$ is the penalty. The value $v_4$ can be considered as an extra boost on the compensation in cases where the request is expiring in the current time step. 
We conduct hyperparameter optimization via grid search over a selection of weights for each attribute and refer to Table \ref{table:fbp_val} in Appendix \ref{sec:fbp_app} for details.
~\\
\textbf{Full information:} The full information policy is an offline policy that assumes complete information about all requests and gig workers, including all stochastic elements, i.e., request and gig worker arrival times and the realization of the random element of the gig worker's utility. This policy solves the full-information problem optimally and yields an upper bound. We refer to Appendix \ref{sec:fi_app} for details on the upper bound computation. 
~\\ 
\textbf{\gls{acr:p-pd-vfa}:} This policy uses perturbed versions of the true weight vectors \(\mathbf{w_d}^{pert} = \mathbf{w_d} + \delta_{dw} \) for \( d \in [1,\dots,D] \) and the Gumbel parameter \( \mu_d^{pert} = \mu_d + \delta_{d\mu} \) of the gig worker utility. We generate the combined perturbation vector \( \delta_d = (\delta_{dw}, \delta_{d\mu}) \) to ensure that both the perturbation and the resulting perturbed vector are constrained within a maximum Euclidean distance $\epsilon$ and a minimum distance of $\max(0,\epsilon - 1)$ from the true vector, formally \(\max(0,\epsilon - 1) \leq \|\delta_d\|_2 \leq \epsilon \) for \( d \in [1,\dots,D] \). The special case where \( \epsilon = 0 \) indicates perfect knowledge of the deterministic term of the gig worker utility, as the true weight vectors \( \mathbf{w_d} \) and Gumbel parameter $\mu_d$ for \( d \in [1,\dots,D] \) are exactly known. Therefore, this version has a competitive advantage over the standard algorithm by leveraging exact environmental values which are not available to the standard version.

In order to evaluate the performance of each algorithm we calculate a performance ratio as follows.
~\\
\textbf{Performance ratio:}
Let $I$ be the set of all considered instances. The performance ratio of the solution of an algorithm for an instance $i \in I$ is equal to:
$$
\left(1 - \frac{\rho^{opt}_i - \rho^{alg}_i}{\rho^{opt}_i - \sum_{j=1}^{N_i} \beta_{ij}} \right) \cdot 100
$$
\noindent where $\rho^{\text{opt}}_i $,  is the total reward acquired on instance $i \in I$ in the full information solution, $\rho^{alg}_i$ is the total reward acquired on instance $i \in I$ by the considered algorithm, $\beta_{ij}$ is the penalty of the $j$-th request in instance $i \in I$ and $N_i$ is the total number of requests in instance $i \in I$. Essentially, the performance ratio evaluates the algorithm’s performance as a percentage of how close the algorithm’s solution is to the optimal solution, while also considering a baseline where no requests are accepted, and only penalties are incurred. Higher values indicate better performance, while lower values reflect poorer performance.
