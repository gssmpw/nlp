\section{Introduction}
\label{sec:introduction}
% \zhen{we need to keep it explicit throughout the introduction that the task is time series forecasting, for now it fades a bit into time series modeling in general}
% \kl{Map perturbations we are using to existing adversarial attacks in the literature.}

Time series (TS) forecasting  uses historical data indexed by time to predict future values. 
This task finds wide applicability in industry in domains like finance, healthcare, manufacturing, and weather. Although well-studied, the TS forecasting has seen recent  advancements with new  AI-based approaches including gradient boosting, deep learning, transformers and Foundation Models (FMs) trained on uni-modal numerical data as well as multi-modal data vying for  state-of-the-art performance \cite{classical-vs-dl-llm-ts,jin2023time}. 

However, having good performance is no guarantee that users will trust a method or model and use it. In particular, users care about the model's robustness to noisy data and perturbations, as erroneous predictions can have far-reaching impact on stakeholders. 
The perturbations may have been caused unintentionally by an actor or intentionally by an adversary, but regardless, the users expect robust and consistent performance.
To manage user trust, a promising idea is of third-party assessment of models and ratings (automated certifications), which can help users make informed decisions, even without access to the method's code or model's training data using both statistical \cite{srivastava2018towards,srivastava2020rating,srivastava2023advances-rating} and causality-based methods \cite{kausik2023the,kausik2024rating}.

% \zhen{I'm not well calibrated to the work published in this field, do they tend to list all components as contributions? typically from our field, it is either the key methodology, a new algorithm, or the introduction of a new dataset.}
In this context, our contributions are that we: (a) introduce a novel workflow for assessing and rating FMTS for robustness through causal analysis. 
% \zhen{I feel this one actually mentioned two contributions, one is the novel framework, one is the extensive experiment design; putting these two together might blur the core contribution, which is the causally ground rating framework. I'd recommend just mentioning the core contribution, and mentioning the extensive experiments separately when mentioning the takeaway findings.}
(b) introduce three perturbations for both numerical and line plots (image) data inspired by real-world applications in unintended scenarios.
% \zhen{I'd recommend skipping this one, it's not a strong contribution, and it opens up for questions on many perturbations that we have not included.}
% (c) We use one year of stock price data from six leading companies across three different industries as test data.
%\zhen{again, this is more of an experiment design, not a contribution IMHO. unless we reframe it as introducing a new robustness testing dataset in the finance domain.}
% (c) We evaluate leading FMTS models - two GP-data trained, namely - Gemini-V (uni-modal and multi-modal) and Phi-3 (uni-modal and multi-modal) and two TS-data trained, namely - MOMENT and Chronos, along with three baseline models, namely - ARIMA, random and biased (total of 9).
%\zhen{also more of an experiment design, not a contribution IMHO}
(c) introduce two novel metrics to measure the causal impact of other attributes on the FMTS (along with existing metrics from literature).
%\zhen{are they new? I saw citation to existing work that introduced those metrics}\kl{They are modified versions of existing metrics - but very different from the original ones.}
(d) create ratings to compare the models in terms of forecasting accuracy and robustness.
%\zhen{I don't think we have those anymore in the paper, and this is not a technical contribution.}
(e) conduct a user study to assess the ease of interpreting FMTS behavior through our ratings and to assess its alignment with users' perceptions.
With our causally grounded rating framework, we evaluate leading FMTS models—two general-purpose-data trained (Gemini-V and Phi-3 in both uni-modal and multi-modal forms) and two time series-data trained (MOMENT and Chronos) - across diverse architectures (encoder-only, decoder-only, and encoder-decoder) and parameter sizes (46M to 32B), along with three baseline models (ARIMA, random, and biased) (total of 9 models). We use one year of stock price data from six leading companies across three different industries as test data. We find that for both Gemini and Phi-3, their multi-modal versions, in general, exhibit better robustness and forecasting accuracy compared to their uni-modal versions (Figure \ref{fig:radar_modality}). We also find that time series-specific FMTS exhibit better robustness and forecasting accuracy compared to general-purpose FMTS (Figure \ref{fig:radar-arch}). Furthermore, the user study confirms that our ratings reduced the difficulty for users in comparing the robustness of different systems.
% \zhen{what does the causally grounded framework add? is there any conclusion from the causal perspective? otherwise the causal flavor in the framework might not be appreciated or motivated properly.}\kl{All the metrics we used in our rating algorithm are causally grounded which helped us in evaluating these systems and drawing conclusions like UM vs MM ..I added the words causally grounded in the beginning of the para to emphasize.}

% Workflow for assessing .. leading two GP-data trained multimodal and two TS-data trained
% In the rest of the paper, we start by reviewing the related work and introduce the problem. Then we describe our method, present experimental results using the rating method and user study. We then
% discuss the implications of our work and conclude.\zhen{can skip this paragraph unless AAAI explicitly required.}

% \begin{enumerate}
%     \item introduce the idea of rating foundation models supporting time-series (FMTS) spanning different architectures (encoder-only, decoder-only, and encoder-decoder) and supported data—including encoder-only, decoder-only, and encoder-decoder—of varying sizes, from 46M to 32B. These models range from general-purpose to time-series specific and include both uni-modal and multi-modal models (Table \ref{tab:fms}). Their performance is compared against three baselines in terms of robustness and bias. 
%     \item We investigate whether individuals perceive accurate models as more reliable than others through a causally grounded experimental setup. This includes three distinct perturbation scenarios and one-year stock price data from six leading companies across three different industries. 
%     \item Conduct user study to determine the effectiveness of our rating method in communicating the behavior of TFMs to end-users. 
% \end{enumerate}

