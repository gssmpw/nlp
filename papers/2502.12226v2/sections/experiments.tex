\section{Experiments and Results}
% \zhen{Rank correlation: https://www.simplilearn.com/tutorials/statistics-tutorial/spearmans-rank-correlation}

% In this section, we give short introduction to FMTS used in our experiments, baseline models, the test data and evaluation metrics including two new metrics to measure the effect of perturbations and confounders on FMTS. Additionally, we present the design of the user study, the responses, and share our findings.
This section introduces the FMTS used in our experiments, baseline models, test data, and evaluation metrics, including two new metrics for perturbations and confounders. We also present the user study design, responses, and findings.

% In this section, we describe FMTS, baseline models, test data, evaluation metrics which includes two new metrics introduced to measure the effect of perturbations and confounders on FMTS, experimental design, results, and findings from the user study.

\subsection{Experimental Apparatus}
\label{sec:exp_app}
% \begin{table}[ht]
% \centering
%    {\tiny
%     \begin{tabular}{|l|c|c|c|c|}
%     \hline
%           \rowcolor{gray!30} {\bf Model} &    
%           {\bf Mode} & 
%           {\bf Size} &
%           {\bf Purpose} \& {\bf Arch.} &
%           {\bf Inf. Time (sec/sample)} \\ \hline 

%           \rowcolor{gray!10} Gemini 1.5 Flash &
%           Multi &
%           32B$^*$ &
%           GP-1A, 1B, Decoder &
%           1.6 (1A); 10.2 (1B)
%           \\ \hline

%           \rowcolor{white} Phi-3-vision &
%           Multi &
%           4.2B &
%           GP-2A, 2B, Enc-Dec &
%           19.7 (1A); 26.6 (1B) 
%           \\ \hline

%           \rowcolor{gray!10} MOMENT-large &
%           Uni &
%           385M &
%           TS-1, Encoder &
%           0.315
%           \\ \hline

%           \rowcolor{white} Chronos-T5-small &
%           Uni &
%           46M &
%           TS-2, Enc-Dec &
%           0.811
%           \\ \hline 
%     \end{tabular}
%     }
%     \caption{Overview of evaluated Foundation Models (FMs). GP: general-purpose, TS: time-series; A: numerical-only, B: numerical-and-vision). *speculation.}
%     \label{tab:fms}
%     \vspace{-1em}
% \end{table}

% \begin{table}[ht]
% \centering
%    {\tiny
%     \begin{tabular}{|p{7.4em}|p{4.5em}|p{2em}|p{3.2em}|p{4.5em}|p{6em}|}
%     \hline
%           {\bf Foundation Model} &    
%           {\bf Modality} & 
%           {\bf Size} &
%           {\bf Purpose} &
%           {\bf Architecture} &
%           {\bf Inf. Time (secs/sample)} \\ \hline 

%           Gemini 1.5 Flash &
%           Multimodal &
%           32B$^*$&
%           GP-1A, GP-1B &
%           Decoder &
%           1.564 (1A); 10.237 (1B)
%           \\ \hline
%           Phi-3-vision &
%           Multimodal &
%           4.2B &
%           GP-2A, GP-2B &
%           Encoder-Decoder &
%           19.715 (1A); 26.571 (1B) 
%           \\ \hline
%           MOMENT-large &
%           Unimodal &
%           385M &
%           TS-1 &
%           Encoder &
%           0.315
%           \\ \hline
%           Chronos-T5-small &
%           Unimodal &
%           46M &
%           TS-2 &
%           Encoder-Decoder &
%           0.811
%           \\ \hline 
%     \end{tabular}
%     }
%     \caption{Overview of the evaluated Foundation Models (FMs), including their size, modality, purpose (general-purpose (GP) or time-series specific (TS); `A' denotes `numerical-only' and `B' denotes `numerical-and-vision'), architecture, and zero-shot inference times. *speculation.}
%     \label{tab:fms}
%     \vspace{-1em}
% \end{table}

% \rachneet{Let us directly use "encoder", "uni-modal" in the table- Table 1, it is very hard for a reviewer to quickly gauge the summary of this table, because I need to read the whole caption and process to get it.}\kl{Done.}

\subsubsection{FMTS}
\label{sec:systems}

We used four FMs in a zero-shot setting: TS forecasting FMs (MOMENT and Chronos) and general-purpose (GP) multimodal FMs (Gemini-V and Phi-3) adapted for TS forecasting. We set $n=80$ and $d=20$. Table \ref{tab:fms} provides an overview of the FMTS architectural details.

\begin{table}[htb]
\centering
   {\tiny
    \begin{tabular}{|l|c|c|c|c|}
    \hline
          {\bf Model} &    
          {\bf Mode} & 
          {\bf Size} &
          {\bf Purpose} \&
          {\bf Arch.} &
          {\bf Inf. Time (sec/sample)} \\ \hline 

          Gemini 1.5 Flash &
          Multi &
          32B$^*$ &
          GP-1A, 1B,
          Decoder &
          1.6 (1A); 10.2 (1B)
          \\ \hline
          Phi-3-vision &
          Multi &
          4.2B &
          GP-2A, 2B,
          Enc-Dec &
          19.7 (1A); 26.6 (1B) 
          \\ \hline
          MOMENT-large &
          Uni &
          385M &
          TS-1,
          Encoder &
          0.315
          \\ \hline
          Chronos-T5-small &
          Uni &
          46M &
          TS-2,
          Enc-Dec &
          0.811
          \\ \hline 
    \end{tabular}
    }
    \caption{
    % Overview of evaluated Foundation Models (FMs). GP: general-purpose, TS: time-series; A: numerical-only, B: numerical-and-vision). *speculation.
    Overview of the architectural details of FMTS. *Best guess in the absence of official information.
    }
    \label{tab:fms}
    \vspace{-1em}
\end{table}

\noindent \textbf{1. MOMENT} (\textcolor{blue}{$S_m$}) \cite{goswami2024moment} is an open-source FM that handles a variety of tasks such as forecasting, classification, anomaly detection, and imputation in zero-shot and few-shot settings, and it can also be fine-tuned if needed. We use MOMENT-large for our experiments, which utilizes T5-Large encoder \cite{raffel2020exploring} as the base architecture. 
% Specifically, it features a 24-layer Transformer with hidden dimensions of size \(D = 1024\), 16 attention heads, and feed-forward networks of size 4096.

% \noindent \textbf{2. Chronos} (\textcolor{blue}{$S_c$}) \cite{ansari2024chronos} is a pretrained probabilistic time series model. It tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. Chronos uses the T5 encoder-decoder as its main backbone architecture. Specifically, we use Chronos-T5-Small for our experiments.

\noindent \textbf{2. Chronos} (\textcolor{blue}{$S_c$}) \cite{ansari2024chronos} is a pretrained probabilistic time series model. It tokenizes time series values using scaling and quantization, then trains transformer-based language models via cross-entropy loss. Chronos uses the T5 encoder-decoder architecture, specifically Chronos-T5-Small for our experiments.

\noindent \textbf{3. Gemini-V} (Gemini 1.5 Flash) (\textcolor{blue}{$S_g$, $S_g^{ni}$})~\cite{team2023gemini} is an FM under the Gemini series. 
% that integrates capabilities from both text and visual modalities. 
This model is designed to understand inputs that include text and images, enabling it to generate relevant text responses based on a comprehensive analysis of the combined data. 
This model processes text and images to generate relevant text responses from combined data. We call the `numeric\_only' mode, $S_g$, and the `numeric\_and\_vision' mode, ($S_g^{ni}$).
% \zhen{maybe $S_g^{mm}$ to represent multimodal? and same for other models? $S_g^{ni}$ might be parsed as unimodal.}\kl{It actually denotes numeric+image}


\noindent \textbf{4. Phi-3} (Phi-3-vision-128k-instruct) (\textcolor{blue}{$S_p$, $S_p^{ni}$}) \cite{abdin2024phi} is a lightweight, SOTA open multimodal model. It is built upon datasets that include synthetic data and filtered publicly available websites, with a focus on very high-quality, reasoning-dense data in both text and vision. 
% The model belongs to the Phi-3 model family and supports a context length of up to 128K tokens. The model underwent both supervised fine-tuning and direct preference optimization and has 4.15 billion parameters. 
We call the `numeric\_only' mode, $S_p$, and the `numeric\_and\_vision' mode, ($S_p^{ni}$). Below is the prompt template we used for time-series forecasting using Gemini-V and Phi-3 models (we omit the text highlighted in blue for uni-modal forecasting:

\begin{tcolorbox}[colframe=black, colback=white, boxrule=0.5pt, width=\columnwidth, arc=0mm, boxsep=0mm, left=1mm, right=1mm, top=0.25mm, bottom=0.25mm]
\smaller
\noindent"\textit{You are a time series forecasting model that only outputs the forecasted numerical values.}" 

\noindent"\textit{\textbf{Input}: \texttt{<time series>}}" 

\noindent"\textit{Given the input time series for the past 80 time steps \textcolor{blue}{and the corresponding time series plot}, can you forecast the next 20 time steps? Provide a list of 20 numeric values only. Do not provide any discussion.}"  
\end{tcolorbox}
 

\subsubsection*{Baselines} 
We consider the following baselines:

\noindent \textbf{1. AutoRegressive Integrated Moving Average (ARIMA)} (\textcolor{blue}{$S_a$}) is a widely used statistical approach for time series forecasting. It combines three different components: Autoregressive (AR), differencing (I), and moving average (MA) to capture the patterns in the time-series data and predict the next `d' (from section \ref{sec:problem}) values. 

\noindent \textbf{2. Biased system} (\textcolor{blue}{$S_b$}) is an extreme baseline biased towards META and GOOG (technology companies), assigning residuals of 0 and 200 respectively, while assigning higher residuals to other companies, representing maximum bias.

\noindent \textbf{3. Random system} (\textcolor{blue}{$S_r$}) assigns random price predictions within a company range for contextually meaningful values.
%[MIN(company's stock prices)-100, MAX(company's stock prices)+100], ensuring sufficient randomness while keeping values contextually meaningful.


%---------------------------------
% \noindent"\textit{You are a time series forecasting model that only outputs the forecasted numerical values.}" 


% \noindent"\textit{\textbf{Input}: \texttt{<time series>}}" 


% \noindent"\textit{Given the input time series for the past 80 time steps \textcolor{blue}{and the corresponding time series plot}, can you forecast the next 20 time steps? Provide a list of 20 numeric values only. Do not provide any discussion.}" 


% \begin{figure}[t!]
%     \centering
%     \begin{tcolorbox}
%     \textbf{Prompts}
%     \tcblower % Creates a visual separation within the box
%     \colorbox{highlight}{Variant 1: Numeric Prompt (numeric inputs only)}\\
%     "You are a time series forecasting model that only outputs the forecasted numerical values." \\
%     "Input: \texttt{<time series>}" \\
%     "Given the input time series for the past 80 time steps \textcolor{blue}{and the corresponding time series plot}, can you forecast the next 20 time steps? Provide a list of 20 numeric values only. Do not provide any discussion. "   
%     \end{tcolorbox}
%     \caption{Example of a prompt template used by Gemini-V and Phi-3 models for time series forecasting. We omit the text highlighted in blue for uni-modal forecasting.}
%     \label{fig:prompt}
% \end{figure}


\subsubsection{Test Data}
% We collected daily stock prices from Yahoo! Finance for six companies: Meta Platforms, Inc. (META), Google (GOO), Pfizer Inc. (PFE), Merck (MRK), Wells Fargo (WFC), and Citigroup Inc. (C). These companies belong to different industries with META, GOO in social technology, PFE, MRK in pharmaceuticals, and WFC, C in financial services. The data spans from March 28, 2023, to April 22, 2024. We used a subset of this data, from March 28, 2023, to March 22, 2024, to predict stock prices for the following month. These high stock priced companies, with their , are representative of their respective industry. We applied the sliding window ($width=1$) technique to sample (input, output) pairs for the prediction task. We set $n=80$ and $d=20$.

We collected daily stock prices from Yahoo! Finance for six companies across different industries: Meta (META) and Google (GOO) in social technology, Pfizer (PFE) and Merck (MRK) in pharmaceuticals, and Wells Fargo (WFC) and Citigroup (C) in financial services. The data spans from March 28, 2023, to April 22, 2024. We used data from March 28, 2023, to March 22, 2024, to predict stock prices for the following month. 
% Using the sliding window technique, we sampled (input, output) pairs for the prediction task, setting $n=80$ and $d=20$.

\subsection{Experimental Evaluation}
\label{sec:expts} 

\begin{figure}[!h]
\centering
\includegraphics[width=1\linewidth]{figs/all_metrics_scatter_plot_v2.png}
\caption{Studying each metric with respect to impact of company and industry as confounders for all models and all perturbations. Plotted in double logarithmic scale, lower values indicate better robustness. Ratings generated by our method (with $L=3$) are shown on the top of each plot. The complete final order (with ratings) are shown in Table \ref{tab:ratings} in Appendix \ref{sec:appendix-experiments}.
}
\vspace{-2em}
\label{fig:confs}
\end{figure}
In this section, we describe the experimental setup used to address the RQs stated in Section \ref{sec:problem}, the results obtained, and the conclusions drawn from the results. Figure \ref{fig:cms} shows the causal diagrams used to answer the RQs. 



% In Appendix B: Table \ref{tab:ratings} shows the partial order and final order with respect to all the metrics defined in Section \ref{sec:metrics}. Table \ref{tab:h4} shows the forecasting accuracy values for all the systems. Table \ref{tab:cases-values} shows the research questions, hypotheses, and average values for all metrics across systems and perturbations (average values are referred to in the interpretations made for each hypothesis in this section). Figure \ref{fig:bar-acc} and \ref{fig:bar-rob} shows bar plots with all the robustness metric values and forecasting accuracy values. 


% \begin{figure*}
%      \centering
%           \begin{subfigure}[b]{0.25\textwidth}
%          \centering
%      \includegraphics[width=1\textwidth]{plots/Radar_Acc_Agg.png}
%          \caption{}
%          \label{fig:acc-agg}
%         \end{subfigure}
%         \begin{subfigure}[b]{0.22\textwidth}
%          \centering
%     \includegraphics[width=1\textwidth]{plots/Radar_Acc_P2.png}
%          \caption{}
%          \label{fig:rob-acc2}
%          \end{subfigure}
%      \hfill
%     \begin{subfigure}[b]{0.26\textwidth}
%          \centering
%     \includegraphics[width=1\textwidth]{plots/Radar_Rob_Agg.png}
%          \caption{}
%          \label{fig:rob-agg}
%      \end{subfigure}
%           \begin{subfigure}[b]{0.22\textwidth}
%          \centering
%     \includegraphics[width=1\textwidth]{plots/Radar_Rob_P2.png}
%          \caption{}
%          \label{fig:rob-p2}
%      \end{subfigure}
%      \vspace{-1em}
%         \caption{Radar plots showing the (a) mean of forecasting accuracy metric values for all systems, (b) forecasting accuracy values for all systems under P2, (c) mean of robustness metric values for FMTS and $S_a$, and (d) robustness metric values for FMTS under P2.%\zhen{the yellow dotted line is not really visible. Why showing P2 in particular? sorry I missed that discussion probably}\sunandita{Agreed. TODO: Need to change the color and increase the fontsize, and cleanup these radar plots.}
%         \sunandita{TODO: Fix the orientation.}\kl{Line color of $S_c$ not visible. Also, title on the top of P2. Label font sizes.} Plots are drawn with each axis normalized and inverted if needed, such that the outer ring indicates better performance.}
%         \label{fig:radar-agg}
%         \vspace{-1em}
% \end{figure*}

% \begin{figure*}
%     \centering
%     \includegraphics[width=0.9\textwidth]{figs/Radar_all_v1.png}
%     \caption{Radar plots showing for all systems (a) mean forecasting accuracy with respect to all metrics, (b) forecasting accuracy under P2 (half-valued pertubation) Appendix \ref{sec:appendix-experiments}: Figs. \ref{fig:radar-rob}, 
%  \ref{fig:radar-acc} show all perturbations; (c) mean robustness metrics for FMTS and $S_a$, and (d) robustness under P2. Each axis is normalized and inverted if needed so that outer ring implies better performance.}
%     \label{fig:radar-agg}
% \end{figure*}


{\color{blue}\noindent{\bf RQ1:}} \textbf{Does \emph{Sensitive Attribute} affect the \emph{Residual}, even though \emph{Sensitive Attribute} has no effect on \emph{Perturbation}?}
\noindent{\bf Setup:}
In this experiment, the causal link from the \emph{Sensitive Attribute} to \emph{Perturbation} is absent, as the perturbation to the stock prices does not depend on the corresponding company name or the industry i.e., perturbations are applied uniformly across all the data points. 
%The corresponding causal diagram is shown in Figure  \ref{fig:cms}. 
We quantify the statistical bias exhibited by the systems by using WRS described in Section \ref{sec:metrics}. 
% To compare \emph{Residual} distributions across different \emph{Sensitive Attribute} stock prices, we use t-value, p-value, and DoF from the Student's t-test \cite{student1908probable} to compare different outcome distributions across each of the companies. 
We perform two different analyses in this experiment: one to measure the discrepancy shown across different industries (WRS$_{Industry}$) and another to measure the discrepancy among both the companies (WRS$_{Company}$) within the same industry.  
% \sunandita{This paragraph is common for all the hypotheses and can be mentioned only once, instead of repeating it four times.}
\noindent{\bf Results and conclusion:}  From Figure \ref{fig:confs},  most discrepancies can be observed across industries compared to the discrepancies across companies within each industry. When the input data was subjected to perturbation P3 ($WRS_{avg}$ of 5.35\footnote{Table \ref{tab:cases-values} in Appendix \ref{sec:appendix-experiments} shows the RQs along with the average values for all metrics across different systems and perturbations.}), the systems exhibited more statistical bias. From Figure \ref{fig:radar-agg}, $S_a$ ($WRS_{avg}$ of 3.96) exhibited the least statistical bias, while $S_p$ ($WRS_{avg}$ of 6.28) exhibited the highest statistical bias among the systems evaluated under the perturbations considered. 
Hence, we conclude that \emph{Sensitive Attribute} affects the \emph{Residual}, even though \emph{Sensitive Attribute} has no effect on \emph{Perturbation}.


{\color{blue}\noindent{\bf RQ2:}} \textbf{Does \emph{Confounder} affect the relationship between \emph{Perturbation} and \emph{Residual}, when \emph{Confounder} has an effect on \emph{Perturbation}?}


\noindent{\bf Setup:} In this experiment, we use PIE \% defined in equation \ref{eq:pie} to compare the APE (defined in equation \ref{eq:ape}) before and after deconfounding using the PSM technique as the presence of the confounder opens a backdoor path from \emph{Perturbation} to  \emph{Residual} through the \emph{Confounder}. The causal link from \emph{Confounder} to \emph{Perturbation} will be valid only if the perturbation applied depends on the value of the confounder (i.e. the company or the industry the specific data points belong to). To ensure the probability of perturbation assignment varies with respect to the \emph{Confounder} across three distributions (DI1 through DI3) in the case of \emph{Industry} and six different distributions in the case of \emph{Company} (DC1 through DC6), we implement weighted sampling. For each distribution, weights are configured so that perturbation groups P1 through P3 have a twofold higher likelihood of selection compared to P0 for specific values of the confounder. For example, META in DC1, GOOG in DC2, and so on. This strategy highlights significant cases, although other combinations are possible for further exploration. 
% Computing APE involves the following steps: First, we use logistic regression to estimate the probability of each data point receiving the perturbation based on the company or the industry it belongs to. Next, we match each perturbed data point with a control data point that is not perturbed but has a similar probability of having perturbed. This matching process ensures that both groups are comparable, allowing us to isolate and measure the actual impact of the perturbation. 
\noindent{\bf Results and Conclusion:} Figure \ref{fig:confs} shows that selecting \textit{Company} as the confounder leads to greater confounding bias in the systems. In Figure \ref{fig:radar-agg}, $S_g^{ni}$ ($PIE_{avg} \%$ of 523.09) exhibited the least confounding bias, while $S_p$ ($PIE_{avg} \%$ of 2677.62) exhibited the most. Systems showed more confounding bias under perturbation P3 ($PIE_{avg} \%$ of 1563.94). Therefore, the \emph{Confounder} affects the relationship between \emph{Perturbation} and \emph{Residual}, particularly when the \emph{Confounder} influences the \emph{Perturbation}.
% Figure \ref{fig:confs} depicts choosing \textit{Company} as the confounder will lead to more confounding bias in the systems. In Figure \ref{fig:rob-agg}, $S_g^{ni}$ (average PIE \% of 523.09) exhibited the least amount of confounding bias, while $S_p$ (average PIE \% of 2677.62) exhibited highest amount of confounding bias. Systems exhibited more confounding bias when perturbation P3 (average PIE \% of 1563.94) is applied. Hence, \emph{Confounder} affects the relationship between \emph{Perturbation} and \emph{Residual}, when \emph{Confounder} has an effect on \emph{Perturbation}.

{\color{blue}\noindent{\bf RQ3:}} \textbf{Does \emph{Perturbation} affect the \emph{Residual} when \emph{Sensitive Attribute} may have an effect on \emph{Residual}?}
\noindent{\bf Setup:}
The experimental setup in this experiment is same as that for answering RQ2. To compute the APE, we used PSM described in Section \ref{sec:metrics}. PSM allows us to effectively determine the effect of \emph{Perturbation} on the \emph{Residual}. For instance, if two matched points belong to the same company but only one was perturbed, any difference in their residuals can be directly attributed to the perturbation itself rather than to other confounding factors. This method provides a clear understanding of the true impact of the \emph{Perturbation} on the \emph{Residual}. As our rating method aims to bring the worst possible behavior of the systems, we take the MAX(APE) as the raw score that is used to compute the final ratings. 
% In each case (P1 through P3), P0 was considered as the control group. 
% In Table \ref{tab:cases}, the PIE \% (APE$_C$ \% and APE$_I$ \%) scores for all the systems are shown in the form of bar plots.  Table 1 in the supplementary shows the raw scores and ratings for all the systems.
% \noindent{\bf Interpretation:} 
\noindent{\bf Results and Conclusion:} It is undesirable to have a higher APE, as it implies that the perturbation applied can have a significant impact on the residuals of different systems. From Figure \ref{fig:confs}, when \textit{Industry} was considered as the confounder, it led to a higher APE. As the outcome of $S_b$ depended on the \textit{Company} (and varied from one company to another), the perturbation did not have any effect on the system. Whereas, when \textit{Industry} was considered as the confounder, the perturbation appeared influential, resulting in a high APE for $S_b$. From Figure \ref{fig:radar-agg}, perturbations had the least impact on $S_g^{ni}$ ($APE_{avg}$ of 6.49) and highest impact on $S_p$ ($APE_{avg}$ of 28.53). Among all the perturbations, P1 ($APE_{avg}$ of 21.11) was the most disruptive. Hence, \emph{Perturbation} affects the \emph{Residual} when \emph{Sensitive Attribute} may have an effect on \emph{Residual}.
% --------

{\color{blue}\noindent{\bf RQ4:}} \textbf{Does \emph{Perturbations} degrade the accuracy of \emph{S}?}
\noindent{\bf Setup:} For this experiment, we do not use any causal model. We compute the three accuracy metrics widely used in for the task of financial time-series forecasting \cite{makridakis2022m5} which were summarized in Section \ref{sec:metrics}. 
\noindent{\bf Results and Conclusion:}  From Figure \ref{fig:radar-agg}, $S_c$ exhibited the highest amount of forecasting accuracy in terms of SMAPE (average of 0.05) and MASE (average of 4.67), while $S_a$ outperformed all other systems in terms of sign accuracy (average of 58.57). $S_b$ consistently predicted the correct directional movement of stock prices, exhibiting high sign accuracy as it was designed to adjust residuals based on specific company stock prices. Perturbations P2, P1, and P0 caused the highest decline in SMAPE (average of 0.08), MASE (average of 8.99), and sign accuracy (average of 49.97), respectively. 
Hence, \emph{Perturbations} degrade the accuracy of \emph{S}.

\subsection{Overall Performance Comparison}
% While the previous section focused on the individual research questions, in this section, we provide an overall comparison of the different systems across all metrics to highlight key findings about the performance of each system under various perturbations. Figure \ref{fig:radar-agg} shows the radar plots with mean of forecasting accuracy and robustness metrics values along with the metrics values under perturbation P2. In Appendix B, Figure \ref{fig:radar} shows the radar plots for all systems under all the perturbations considered and Table \ref{tab:cases-values} shows the average values across different perturbations and systems. 

Now, we provide  an overall comparison of the different systems across all metrics to highlight key findings about their performance under various perturbations. Figure \ref{fig:radar-agg} shows radar plots with mean forecasting accuracy and robustness metrics, including values under perturbation P2. 
%Appendix \ref{sec:appendix-experiments} includes Figures \ref{fig:radar-rob}, 
 %\ref{fig:radar-acc} with radar plots for all systems under all perturbations and Table \ref{tab:cases-values} with average values across different perturbations and systems.

\noindent \textbf{1. Clear Domination Signals} From Figure \ref{fig:radar-agg} and the detailed results from Section \ref{sec:expts}, we can draw the following conclusions: \textbf{$S_c$'s Superiority in Forecasting Metrics}: $S_c$ consistently outperformed other models in terms of forecasting accuracy metrics, specifically SMAPE and MASE. This indicates that $S_c$ is highly effective in predicting stock prices with minimal error.
\textbf{General Superiority Over Biased and Random Systems}: All models perform better than the biased and random systems in forecasting metrics. This underscores the importance of using well-designed models over naive or biased approaches.
\textbf{Robustness in PIE \% and APE Metrics}: According to the average scores, the $S_g^{ni}$ system demonstrated superior robustness in PIE \% and APE metrics. This suggests that $S_g^{ni}$ is more resilient to perturbations and confounding biases compared to other systems.


% \noindent \textbf{$S_c$'s Superiority in Forecasting Metrics}: $S_c$ consistently outperformed other models in terms of forecasting accuracy metrics, specifically SMAPE and MASE. This indicates that $S_c$ is highly effective in predicting stock prices with minimal error.\zhen{$S_a$?}
    
% \noindent \textbf{General Superiority Over Biased and Random Systems}: All models perform better than the biased and random systems in forecasting metrics. This underscores the importance of using well-designed models over naive or biased approaches.
    
% \noindent \textbf{Robustness in PIE \% and APE Metrics}: According to the average scores, the $S_g^{ni}$ system demonstrated superior robustness in PIE \% and APE metrics. This suggests that $S_g^{ni}$ is more resilient to perturbations and confounding biases compared to other systems.

\noindent \textbf{2. Role of Modality} The results from Figure \ref{fig:radar_modality} indicate that multimodal FMTS, $S_g^{ni}$ and $S_p^{ni}$, generally perform better in terms of both robustness and accuracy, suggesting that incorporating multiple data modalities (e.g.,  numerical and image) can improve the system's ability to make accurate predictions and remain robust against various perturbations.

\begin{figure}
    \centering
    \includegraphics[width=0.9\linewidth]{figs/Radarchart_Modality_v2.png}
    \caption{Effect of the modalities for $S_g$ (left) and $S_p$ (right).}
    \label{fig:radar_modality}
    \vspace{-1.8em}
\end{figure}

\noindent\textbf{3. Role of Confounders} 
% Our analysis (of Figs. \ref{fig:confs} and \ref{fig:radar}) reveals that industry as a confounder introduces more bias into the systems, as reflected by higher PIE\% scores, indicating that industry-specific factors significantly affect the relationship between perturbations and residuals. Additionally, there are more discrepancies in inter-industry comparisons, as shown by WRS scores. In contrast, the impact of company as a confounder varies across systems. For example, system $S_b$ shows minimal effect from company-specific perturbations, suggesting it is well-tailored to company data, while other systems experience higher APE scores, indicating a significant impact on residuals due to company-specific factors.
Our analysis (Figs. \ref{fig:confs} and \ref{fig:radar-agg}: left) shows that using industry as a confounder introduces more bias, with higher PIE\% scores indicating significant industry-specific effects on the relationship between perturbations and residuals. Inter-industry comparisons also show more discrepancies, as evidenced by WRS scores. Conversely, the impact of company as a confounder varies. For instance, system $S_b$ shows minimal effect from company-specific perturbations, suggesting it is well-tailored to company data, while other systems have higher APE scores, indicating a significant impact on residuals due to company-specific factors.
% \begin{figure}
%     \centering
%     \includegraphics[width=0.8\linewidth]{figs/confounder.png}
%     \caption{Studying the impact of Company and Industry as confounders}
%     \label{fig:enter-label}
% \end{figure}
% \subsection{Interesting Conclusions from Radar Plots}
% \begin{itemize}
%     \item \textbf{Dominance of ARIMA in Forecasting}: The radar plots clearly show ARIMA's dominance in forecasting metrics, with the smallest SMAPE and MASE values across all perturbations.
%     \item \textbf{Robustness of Gemini-Multimodal}: The radar plots highlight Gemini-multimodal's robustness, particularly in PIE and APE metrics, suggesting its effectiveness in handling confounding biases and perturbations.
%     \item \textbf{Performance of Biased and Random Systems}: The radar plots also illustrate that biased and random systems consistently underperform compared to other models, reinforcing the importance of using well-designed predictive models.
% \end{itemize}


\noindent \textbf{4. Role of Architecture}
Our evaluation (Fig. \ref{fig:radar-arch}, left) indicates that the Time Series architecture generally performs better across several  metrics, such as achieving the best values in APE\_C, PIE\_C, SMAPE, MASE, and WRS\_I, suggesting that the TS architecture may be more effective for these specific tasks compared to the general purpose architectures. Fig.~\ref{fig:radar-arch} (right) shows that decoder-only architecture outperforms others in terms of both accuracy and robustness.
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/Radarchart_Arch_v2.png}
    \caption{Role of architecture in forecasting accuracy and robustness. Performance is averaged across models within each category. See Table~\ref{tab:fms}.}
    \label{fig:radar-arch}
    \vspace{-1em}
\end{figure}
% Overall, our comparison highlights $S_c$'s strength in forecasting accuracy, the robustness of multimodal systems in handling perturbations and confounding biases, and the general superiority of well-designed models over naive approaches. 
\noindent Overall, our comparison highlights $S_c$'s forecasting accuracy, the robustness of multimodal systems against perturbations and confounding biases, and the superiority of well-designed models over naive approaches.
%The impact of modality and the role of industry and company as confounders provide additional insights into the factors influencing model performance.
%More details can be found in Appendix D. 


% \subsection{User Study Results} 
\subsection{User Study}
\label{sec:userstudy}

We conducted a user study to evaluate the ratings generated by our approach for comparing the behavior of various FMTS based on two key metrics: robustness and statistical fairness (defined as lack of statistical bias). To simplify the evaluation for participants, we converted the generated ratings into rankings (i.e., the system with the highest robustness ranking is the most robust system). The main objective of this study was to validate the following hypotheses:

{\color{blue}\noindent{\bf HP1:}} Rankings generated by our approach decrease the difficulty of comparing system robustness.

{\color{blue}\noindent{\bf HP2:}} Rankings generated by our approach decrease the difficulty of comparing system fairness (lack of statistical bias).

{\color{blue}\noindent
{\bf HP3:}} Rankings generated by our method align with users' rankings for both fairness and robustness.

This IRB-approved study\footnote{Institutional details anonymized for reviewing.} involved participants evaluating FMTS models forecasting stock prices for companies in various industries, participants were introduced to key concepts including robustness, fairness, and error metrics (maximum residual, mean, and standard deviation of errors) to ensure informed evaluations. All inputs were sought on Likert 5-value scale. The details and complete set of questions are provided in the Appendixes ~\ref{sec:appendix-user-study},~\ref{sec:appendix-study-q}.

% This IRB-approved study\footnote{Details anonymized for reviewing.} involved participants being presented with TSFM models predicting the future stock prices for companies across different industries, such as Technology and Pharmaceuticals. To ensure informed evaluations, we introduced participants to key concepts including robustness, fairness, and error metrics (maximum residual, mean, and standard deviation of errors) regardless of prior knowledge. 

The study was structured into four panels: a \textit{self-assessment} on knowledge about time series and financial data, a \textit{fairness} panel, where fairness was the evaluated metric, and two \textit{robustness} panels, where robustness was assessed under two different perturbations (P1 and P2).
In the fairness panel, participants were presented with graphs depicting the residual values of six different systems and an ideal system using stock price data from the Technology and Pharmaceuticals industries. They were provided with the mean and standard deviation of errors and asked to rank the systems from least to most fair. Participants then rated the difficulty of this ranking task
%on a Likert 5-value scale 
(1 being the most difficult).
%and 5 the least difficult). 
Subsequently, they were shown the rankings generated by our approach and asked to rate the accuracy of these rankings 
%on the Likert 5-value scale 
(1 being the least accurate).
%and 5 the most accurate). 
Finally, participants were asked to rank the difficulty of comparing the behavior of different systems using our rankings
%on a Likert 5-value scale 
(1 being the most difficult).
%and 5 the least difficult). 
For the robustness panels, similar questions were posed, with users evaluating systems based on their robustness to different perturbations (P1 and P2). 
A total of 26 users from academia and industry participated over two weeks.
%in the user study.  
We performed different types of statistical tests to draw significant conclusions; see details in Table \ref{tab:user-study-sanity}, \ref{tab:user-study-results} in Appendix \ref{sec:appendix-user-study}. We now discuss the key findings from the tests.

To evaluate \textit{HP1}, we conducted a paired t-test to compare user responses on difficulty of ranking various systems before and after presenting our rankings. The same participants assessed the difficulty using both the graph representation of fairness and our ranking representation, making the paired t-test appropriate. Paired t-test also accounts for the inherent correlation between the paired rankings, making it suitable to account for potential different perceptions across the two representations. Paired t-tests for each robustness panel indicated a significant difference before (P1:$\mu$ = 2.70, $\sigma$ = 1.06; P2: $\mu$ = 2.65, $\sigma$ = 1.17) and after (P1: $\mu$ = 3.23, $\sigma$ = 1.42; P2: $\mu$ = 3.07, $\sigma$ = 1.44) our rankings were presented with P1:t(26) = -1.89, p = 0.030, and P2: t(26) = -1.62, p = 0.059. Since the p-values $\prec$ 0.1,
%are less than the significance level of 0.1, 
we confirm \textit{HP1} that the ranking generated by our approach significantly reduced the perceived difficulty of comparing different systems.
Same approach is used to evaluate \textit{HP2}. The paired t-test showed no significant change in perceived difficulty scores before ($\mu$ = 2.54, $\sigma$ = 1.30) and after ($\mu$ = 2.92, $\sigma$ = 1.35) our rankings were presented, t(26) = -1.18, p = 0.12. Since 
p $\succ$ 0.1,
%the p-value is greater than the significance level of 0.1, 
we conclude that our ranking representation did not significantly reduce the perceived difficulty of comparing different systems. The lack of significant reduction in perceived difficult may have stemmed from the complexity of the graphical representations.
%

To validate \textit{HP3}, we used the Spearman Rank Correlation coefficient \cite{zar2005spearman} ($\rho$) to evaluate the alignment between the users' rankings and those produced by our approach. We considered a confidence interval of 90 \%. The fairness panel showed a high correlation ($\rho$= 0.73), and the robustness under P1 showed a strong correlation ($\rho$ = 0.91). However, robustness under P2 showed a weak correlation ($\rho$ = 0.14).

% \parisa{is that possible to have the Spearman Rank Correlation for all the panels together - I am just wondering if we get a bit of better results}

In summary, the results of the user study indicate that the rankings generated by our approach can significantly reduce the difficulty of comparing the robustness of different FMTS systems. However, when the comparison metric is fairness, this reduction is not significant. Additionally, while user rankings align well with our method generated rankings for fairness and robustness under P1, they show a weak correlation for robustness under P2, indicating differing perceptions of the 'value halved' perturbation.  P1 (drop-to-zero) involves a significant semantic change that is easier to spot, whereas P2 (value halved) is also a semantic perturbation but subtler, making it potentially harder to identify. Our current study is preliminary and promising; an avenue for future work is to conduct it at a larger scale.  

% we used a Spearman Rank Correlation}: Users were asked to rank (we used the word `rank' in place of `rate' in the user study for simplification) the systems from least to most fair in the fairness study and from least to most robust in the robustness study (Q3, Q7, Q11). These user rankings were then compared with the rankings generated by our rating method under P0 for the fairness study, where WRS was used to compute the rankings, and under P1 and P2 for the robustness study, where SMAPE was used to compute the rankings. Spearman Rank Correlation \cite{zar2005spearman} was used for as the testing method, focusing on points with a p-value $\prec$ 0.05. 

% Table \ref{tab:user-study-questions} shows the shortened version of the actual questions asked in the user study. The complete set of questions and the user study form are provided in the Appendix C. The user study procedure was described in Section \ref{sec:user-study}. We performed three different types of statistical tests to draw conclusions from the user study:


%
% The primary objectives of this user study were to assess: (a) the difficulty users experienced in evaluating the performance of TSFMs using different data representations (plots, scores, and rankings), and (b)  the degree of alignment between users' rankings and the rankings produced by our approach.

% This study is IRB-approved by our institution\footnote{Details anonymized for reviewing.} and involves users interacting with the TSFM models to predict future stock prices for companies across different industries (e.g., Technology and Pharmaceuticals). We introduce participants to definitions such as robustness, fairness, and error metrics (maximum residual, mean, and standard deviation of errors) to ensure they could make informed evaluations, regardless of prior knowledge.

% Our study consists of three panels: one on fairness, two on robustness (under perturbations P1 and P2). In the fairness study, participants are presented with fairness graphs of six different systems and an ideal system using stock price data from two industries: Technology and Pharmaceuticals. They are provided with mean and standard deviation of errors, and asked to rank the systems from least to most fair. They are then asked to compare their rankings to those generated by our automated procedure, with respect to accuracy and  ease of comparison. Similar questions are asked for the robustness study, where participants evaluate systems based on their resistance to changes or disruptions (we call these as perturbations). The goal is to understand how the users perceive the fairness and robustness of different TSFMs. The summarized version of the questions along with the results are shown in \ref{tab:user-study}. The complete set of questions and visualizations used in the study can be found in User Study section of the supplementary.

% In Section \ref{sec:userstudy}, we provide a detailed discussion of the user study setup, the hypotheses being tested, the results obtained, and our interpretations and conclusions.

% \begin{table}[!ht]
% \centering
%    {\tiny
%     \begin{tabular}{|p{2cm}|p{1cm}|p{1cm}|p{2.6cm}|}
%     \hline
%         \textbf{Hypothesis} & 
%         \textbf{Test Performed}  &
%         \textbf{Statistics} &
%         \textbf{Conclusion}\\
%         \hline
%          There is no correlation between user rankings and the rankings generated by our automated rating system for fairness study. & 
%          Spearman Rank Correlation &
%          r: NA &
%          No significant correlations. 
%          \\ \hline
%          The mean of the responses for Q4 is less than or equal to the mean of the responses for Q6. & 
%          Paired t-test &
%          t-statistic: -1.18, p-val: 0.12 &
%          Users found it easy to interpret the behavior of the systems from rankings compared to graphs and statistics with a confidence interval of 85 \%.
%          \\ \hline
%          The mean of the responses for Q5 is greater than 2. & 
%          One sample right-tailed t-test &
%          t-statistic: 3.33, p-val: 0.001 &
%          Users found the rankings to be not very accurate with a confidence interval of 95 \%.
%          \\ \hline
%          There is a positive correlation between Q7 and rankings generated by our rating method. & 
%          Spearman Rank Correlation &
%          r: 0.93 &
%          The robustness rankings generated by our rating method aligns very well with how users perceive robustness.
%          \\ \hline
%          The mean of the responses for Q8 is less than or equal to the mean of the responses for Q10. & 
%          Paired t-test &
%          t-statistic: -1.89, p-val: 0.03 &
%          Users found it easy to interpret the behavior of the systems from rankings compared to graphs and statistics with a confidence interval of 95 \%.
%          \\  \hline
%          The mean of the responses for Q9 is greater than 2.5 & 
%          One sample right-tailed t-test &
%          t-statistic: 1.71, p-val: 0.049 &
%          Users found the rankings to be less accurate with a confidence interval of 95 \%.
%          \\ \hline
%          User rankings are negatively correlated to the rankings generated by our automated rating system. & 
%          Spearman Rank Correlation &
%          r: -0.26 &
%          User perceptions differ from the rankings generated by our rating system.
%          \\ \hline
%          The mean of the responses for Q12 is less than or equal to the mean of the responses for Q14. & 
%          Paired t-test &
%          t-statistic: -1.62, p-val: 0.06 &
%          Users found it easy to interpret the behavior of the systems from rankings compared to graphs and statistics with a confidence interval of 90 \%.
%          \\  \hline
%          The mean of the responses for Q13 is greater than 2 & 
%          One sample right-tailed t-test &
%          t-statistic: 3.03, p-val: 0.002 &
%          Users found the rankings to be not very accurate with a confidence interval of 95 \%.
%          \\ \hline
%     \end{tabular}
%     \caption{Table with the hypotheses evaluated in the user study, statistical tests used to validate the hypotheses, results obtained, and conclusions drawn.}
%     \label{tab:user-study-results}
%     \vspace{-1em}
% }
% \end{table}

% In this section, we use the term "rankings" for ratings generated by our method, consistent with the terminology used in the user study to avoid confusion with the 1-5 scale rating questions given in the user study.
% A total of 26 users participated in the user study. Table \ref{tab:user-study-questions} shows the shortened version of the actual questions asked in the user study. The complete set of questions and the user study form are provided in the Appendix C. The user study procedure was described in Section \ref{sec:user-study}. We performed three different types of statistical tests to draw conclusions from the user study:


% \noindent \textbf{1. Spearman Rank Correlation}: Users were asked to rank (we used the word `rank' in place of `rate' in the user study for simplification) the systems from least to most fair in the fairness study and from least to most robust in the robustness study (Q3, Q7, Q11). These user rankings were then compared with the rankings generated by our rating method under P0 for the fairness study, where WRS was used to compute the rankings, and under P1 and P2 for the robustness study, where SMAPE was used to compute the rankings. Spearman Rank Correlation \cite{zar2005spearman} was used for as the testing method, focusing on points with a p-value $\prec$ 0.05. 

 
% \noindent \textbf{2. Paired t-test}: We used the paired t-test because each value in the two groups corresponds to rankings provided by the same user, for the ease of interpreting the behavior of the systems from graphs and statistics, and the rankings provided by our method respectively, who evaluated these different representations on a scale of 1-5. This test is appropriate because it accounts for the inherent correlation between the paired rankings, reflecting how each user's perception might differ across the two representations.


% \noindent \textbf{3. One sample right-tailed t-test}: We used a one-sample right-tailed t-test to determine if the user ratings on a 1-5 scale were significantly higher than a hypothesized mean for Q5, Q9, and Q13. This test helped assess whether users rated the systems above a predefined threshold.

% The results and the conclusions drawn from each of these tests are shown in Table \ref{tab:user-study-results}. They reveal varying levels of agreement between user perceptions and automated ratings, with some tests showing significant differences or correlations, while others do not. 



