\section{Methodology}
\subsection{Randomized Smoothing Defense}
\label{sec:rs defense}
Randomized smoothing was originally proposed to achieve the \textbf{certified robustness} effect against evasion attacks in computer vision scenario~\citep{cohen2019certified}. We first extend its basic framework to the textual backdoor attacks which have not been thoroughly explored before. Generally, randomized smoothing introduces a \textbf{smoothed model} $\tilde{f}$ based on the base model $f(\cdot)$ by exerting the random noise on the fine-tuning data and test samples. In essence, the rationale behind leveraging the randomized smoothing defense lies in the observation that the inclusion of noise mitigates the prevalence of decision boundaries with pronounced curvature, thereby reducing the susceptibility to backdoor attacks. Thus, we denote the noisification operator as $\oplus$ and define the smoothed model $\tilde{f}$ as:
\begin{equation}
\small
\begin{aligned}
\tilde{f}(\mathbf{x}') = \underset{y \in \mathcal{Y}}{arg \; max} \; \mathbb{P}_{u, \epsilon}(f(\mathbf{x}'\oplus u;\Omega(\theta^{'}_P, D_F \oplus \epsilon))=y),
\end{aligned}
\label{eq:smoothed model}
\end{equation}
where random noise variables $u \sim \mathbb{P}_{u}, \epsilon \sim \mathbb{P}_{\epsilon}$ follow the independent random distributions and are added to the perturbed test samples and fine-tuning data, respectively. Here, the $\Omega$ indicates the fine-tuning procedure which takes the poisoned pre-trained model parameters $\theta^{'}_P$ and randomized fine-tuning data $D_F \oplus \epsilon$ (notes as $\tilde{D}_F$) as inputs and returns the smoothed fine-tuned parameters $\tilde{\theta}_F$.  

In practice, considering the complexity of LM $f(\cdot)$ itself, Monte Carlo simulation is an effective approach to approximate the above probability $\mathbb{P}_{u, \epsilon}(f(\mathbf{x}'\oplus u;\Omega(\theta^{'}_P, D_F \oplus \epsilon))=y)$ in Eq~\ref{eq:smoothed model}. Therefore, we employ a number of base models $f(;\tilde{\theta}_{F,k}) (1\leq k \leq K)$ with parameters $\tilde{\theta}_{F,k}$ fine-tuned on the sampled randomized datasets $\tilde{D}_{F,k} = D_F \oplus \epsilon_k$ to vote on the final result. Therefore, the Eq.~\ref{eq:smoothed model} can be transformed to following:
\begin{equation}
\begin{aligned}
\tilde{f}(\mathbf{x}';&\tilde{\bm{\theta}}_F) = \underset{y \in \mathcal{Y}}{arg \; max} \; \underset{k=1}{\sum^K} \mathbbm{1}(f(\tilde{\mathbf{x}}_k;\tilde{\theta}_{F,k})=y), \\
&\tilde{\mathbf{x}}_k = \mathbf{x}'\oplus u_k, \tilde{\theta}_{F,k} = \Omega(\theta^{'}_P, D_F \oplus \epsilon_k),
\end{aligned}
\label{eq: MCS}
\end{equation}
where $\tilde{\bm{\theta}}_F=[\tilde{\theta}_{F,1}, \tilde{\theta}_{F,2},..., \tilde{\theta}_{F,K}]$ indicates the parameters of the smoothed model $\tilde{f}$ which is actually the ensemble of base models. The distribution of randomness applied on the fine-tuning dataset is controllable, often the isotropic Gaussian noise $\epsilon \sim \mathcal{N}(0, \sigma^2\mathbf{I})$. Naturally, according to the properties of Monte Carlo simulation, as the number of the above base models increases, the voted results become more reliable and the scope of the robustness region becomes larger.

%The random smoothing technique can ensure that the prediction $\tilde{f}(\mathbf{x}';\tilde{\bm{\theta}}_F)$ of the smoothed model on the perturbed input $\mathbf{x}'$  is consistent with that $f(\mathbf{x};\theta_F)$ of the model trained with the completely clean dataset on benign input $\mathbf{x}$ within a certain confidence level $1-\alpha$, when the perturbation scale is less than the robustness radius $R_r$. 
Randomized smoothing can guarantee that, when the perturbation scale is less than the robustness radius $R_r$, the prediction $\tilde{f}(\mathbf{x}';\tilde{\bm{\theta}}_F)$ of the smoothed model for the perturbed input $\mathbf{x}'$ aligns with the prediction $f(\mathbf{x};\theta_F)$ of the model trained on the completely clean dataset for benign input $\mathbf{x}$, within a confidence level of $1-\alpha$.
Based on this framework, we develop the practical schemes for model parameter smoothing as described in Section~\ref{sec: biphased model parameter smoothing} and test sample randomization in Section~\ref{sec: fuzzed text randomization}, respectively. Finally, we elaborate on the theoretical analysis in Section~\ref{sec: theory} and Appendix~\ref{appendix:equivalence proof}.

\subsection{Biphased Model Parameter Smoothing}
\vspace{-1mm}
\label{sec: biphased model parameter smoothing}
%If directly following Section.~\ref{sec:rs defense} and fine-tuning $K$ PLMs on $K$ distinct, randomized downstream datasets, respectively, the considerable computation burden will be imposed, which renders it an unrealistic strategy in practical scenarios. 
If directly following the approach described in Section~\ref{sec:rs defense}, one might consider fine-tuning $K$ pre-trained language models on $K$ distinct, randomized downstream datasets. However, this approach would impose a considerable computational burden. As a result, it becomes an unrealistic strategy for practical scenarios. Therefore, there exists an urgent need for post-attack defense mechanisms that not only have certified robustness guarantees but also provide efficient execution. Thus, we propose the \textbf{biphased model parameter smoothing} as a targeted solution particularly for large language models, which is performed during both the fine-tuning and inference phases. This biphased approach notably diminishes data storage requirements for different versions of randomized fine-tuning datasets and drastically reduces the computational overhead associated with training. Besides, this strategy advocates for the selective smoothing of parameters in $H$ layers proximal to the output â€” those most vulnerable to backdoor attacks, as highlighted in the literature~\citep{kurita2020weight}. The detailed smoothing procedures in such two phases are as follows:

\textbf{Fine-tuning Phase:} In iteration $i$ ($1 \leq i \leq I$) of fine-tuning process, the model parameter smoothing is performed as follows:
\begin{equation}
\begin{aligned}
\tilde{\mathbf{\theta}}_F^{i} = \text{Clip}_{\rho}(\tilde{\mathbf{\theta}}^{i-1}_F - \eta g(\tilde{\mathbf{\theta}}^{i-1}_F; B_i)) + \epsilon^{i}_{\text{top-}H}, % here, the B_i can be modified to B^i for more clear presentation, the same for the following part
\end{aligned}
\label{eq: fine-tuning parameter smoothing}
\end{equation}
where $\eta$ and $\rho$ indicate the learning rate of the fine-tuning process and the norm bound, respectively. $g(;)$ denotes the gradient function and $B_i$ is the mini-batch in iteration $i$. Especially, $\tilde{\mathbf{\theta}}^{0}_F = \mathbf{\theta}'_P$.

\textbf{Inference Phase:} When completing the model fine-tuning, we conduct the parameter smoothing to the finally obtained $\tilde{\mathbf{\theta}}^I_F$ independently for $K$ times:
\begin{equation}
\begin{aligned}
\tilde{\mathbf{\theta}}_{F,k} = \text{Clip}_{\rho}(\tilde{\mathbf{\theta}}^I_F) + \epsilon_{k, \text{top-}H}, k=1,2,...,K,
\end{aligned}
\label{eq: inference parameter smoothing}
\end{equation}
Once the $K$ smoothed copies of LMs are generated at the beginning of the inference phase, they are fixed and employed for every test sample during the whole inference phase. 

\subsection{Fuzzed Text Randomization}
\label{sec: fuzzed text randomization}
\vspace{-1mm}
% fuzzing variables waiting to be optimized: text randomization operation type (substituion, removing, transposing, xxx), randomization area, randomization intensity (R_L), parameter smoothing intensity, number of base voters
Traditional text randomization in randomized smoothing relies on uniform randomization in the text input, suffering from low efficiency and limited certified robustness radius. Motivation by the fuzzing technique in the software verification research, we design the Monte Carlo tree search (MCTS)-based \textbf{fuzzed text randomization} to first proactively identify the vulnerable areas containing the triggers in the input text. We choose MCTS for its ability to efficiently explore high-dimensional discrete textual spaces and adaptively focus on promising areas.
Then, such areas will be imposed more possibilities to conduct the text randomization operations. In such a way, the obtained randomized samples are more likely to remove the information related to the backdoor or damage the triggers' dedicated structure while keeping genuine features intact, which means backdoored texts can be reverted back to their corresponding benign versions. Thus, a broader certified robustness radius can be successfully achieved with the majority voting process over the same number of randomized samples.
%the majority voting process can be successfully achieved with fewer samples and a broader certified robustness radius. 

\subsubsection{Vulnerable Area Identification}
%The detailed process of Monte Carlo tree search fuzzing for vulnerable area location is as follows: 
The primary objective of this MCTS-based fuzzing approach is to efficiently identify potential vulnerable areas in the input text that may contain backdoor triggers. 
Thus, we first define $S$ as a search tree, with nodes $n \in S$ corresponding to segments $Seg(\mathbf{x}',i,j)$ of the perturbed text $\mathbf{x}'$ from $i$-th token to $j$-th token. Each node $n$ is associated with a score $V(n)$, reflecting the potential of the corresponding segment to exhibit trigger impacts. The detailed fuzzing process is as follows:
%With these definitions in place, we now describe the MCTS algorithm for identifying vulnerable areas in the input text.

\textbf{Initialization} Initialize $S$ with a root node $n_{root}$ representing the original input $\mathbf{x}'$. Set $V(n_{root})=0$.

\textbf{MCTS Iterations} Then, in each iteration of MCTS, the following steps are executed:
\begin{itemize}[leftmargin=*]
\item \textbf{Step 1: Selection} Traverse from the root to a leaf node $n_l$ using the Upper Confidence Bound (UCB) applied to trees policy:
\begin{equation}
\begin{aligned}
UCB(n_l) = V(n_l) + C\sqrt{\frac{ln(N_{parent})}{N_{n_l}}},
\end{aligned}
\label{eq: ucb}
\end{equation}
where $C$ is an exploration constant, $N_{n_l}$ signifies the number of visits to node $n_l$, and $N_{parent}$ is the number of visits to $n_l$'s parent node.

\item \textbf{Step 2: Expansion} Upon reaching a leaf node $n_l$ at the conclusion of the Selection phase, we evaluate whether the text segment corresponding to $n_l$, denoted as $Seg(\mathbf{x},i,j)$, can be further devided. This evaluation is based on the linguistic features of the segment, such as phrase boundaries, clause demarcations, or named entities contained within. If the further subdivision is viable, a child node $n_{new}$ for $n_l$ will be generated, which represents a subdivision of $Seg(\mathbf{x}',i,j)$. The generation of $n_{new}$ is thus expressed as:
\begin{equation}
\begin{aligned}
n_{new} &= Seg(\mathbf{x}',i,k) \; \text{or} \; Seg(\mathbf{x}',k+1,j), \\
k&=i+1,...,j-1.
\end{aligned}
\label{eq: expansion}
\end{equation}
\item \textbf{Step 3: Simulation} Select a mutation operation $m$ from a predefined mutation set $M$, which includes insertion, deletion, substitution, and transposition operations in the Damerau-Levenshtein space. Next, apply $m$ to $n_{new}$, thus generating a new textual variant $\tilde{\mathbf{x}}$ of original $\mathbf{x}'$. Then, $\tilde{\mathbf{x}}$ is evaluated to ascertain the deviation in LM's response. Here, we utilize an evaluation criterion $E(\tilde{\mathbf{x}}, \mathbf{x}')$ based on KL divergence~\citep{kullback1951information} to quantify this deviation:
\begin{equation}
\begin{aligned}
E(\tilde{\mathbf{x}}, \mathbf{x}') = D_{KL} (P_{f}(y|\tilde{\mathbf{x}})||P_{f}(y|\mathbf{x}')),
\end{aligned}
\label{eq: utility function}
\end{equation}
where $P_{f}(y|\mathbf{x})$ indicates the probability distribution of LM $f$ on different outputs $y$.
\item \textbf{Step 4: Backpropagation} Update scores of all nodes $n$ from $n_{new}$ up to $n_{root}$ based on $E(\tilde{\mathbf{x}}, \mathbf{x}')$, thus refining the selection process in subsequent iterations:
\begin{equation}
\begin{aligned}
V_{i}(n) = \frac{N_{n}-1}{N_{n}}V_{i-1}(n) + \frac{E(\tilde{\mathbf{x}}, \mathbf{x}')}{N_n},
\end{aligned}
\label{eq: value update}
\end{equation}

\end{itemize}
%Upon reaching a predefined number of iterations or a termination criterion, we identify segments corresponding to nodes with the highest scores $V(n)$ as ones with the greatest potential to contain triggers.
Upon reaching a predefined number of iterations or a termination criterion, we identify segments corresponding to nodes with the highest scores $V(n)$ as the most likely vulnerable areas $T(\mathbf{x}')$ with the greatest potential to contain backdoor triggers.

\subsubsection{Text Randomization}
Building upon the established MCTS-based fuzzing framework, we proceed to employ text randomization while maintaining the normalized Damerau-Levenshtein distance within a specified threshold. This constraint ensures the semantic and structural integrity of the text by limiting the number and type of textual transformations, thereby preserving the original meaning and syntactic structure.

\textbf{Randomization Process:} %Once vulnerable areas $T(\mathbf{x}')$ potentially containing triggers have been identified, discretionary randomization operations are conducted with distinct probabilities for sections within and outside $T(\mathbf{x}')$. The detailed randomization process include several following steps:
After identifying vulnerable areas $T(\mathbf{x}')$ that potentially contain triggers, we apply a targeted randomization strategy which employs differential probabilities for textual segments within and outside $T(\mathbf{x}')$. The process consists of the following key steps:

\begin{itemize}[leftmargin=*]
\item \textbf{Step 1: Damerau-Levenshtein Compliance} We begin by setting a distance threshold $\Lambda$. This threshold defines the maximum allowable modification to the original text, measured using the normalized Damerau-Levenshtein distance. Specifically, any alteration to the text must satisfy:
\begin{equation}
d_{DL}(\tilde{\mathbf{x}}, \mathbf{x}') \leq \Lambda,
\end{equation}
where $d_{DL}(\tilde{\mathbf{x}}, \mathbf{x}')$ represents the normalized Damerau-Levenshtein distance between the original and mutated text variants.
\item \textbf{Step 2: Probability-Weighted Randomization Strategy}
We formulate a probability weighting function $\mathcal{W}: Seg(\mathbf{x}',i,j) \rightarrow [\omega_L,\omega_H]$ to differentially allocate randomization probabilities across the text:
\begin{equation}
    \mathcal{W}(segment) = \begin{cases}
        \omega_H, & \text{if } segment \subseteq T(\mathbf{x}'), \\
        \omega_L, & \text{otherwise},
    \end{cases}
\end{equation}
where $\omega_H > \omega_L$ signify higher and lower randomization probabilities, correspondingly. Especially, let $\omega_M$ denote the traditional uniform randomization probability for each segment. Here, to ensure the equal overall randomization probability for the whole $\mathbf{x}'$, we have $\omega_L < \omega_M < \omega_H$.

\item \textbf{Step 3: Randomization Implementation}
%For each identified segment $Seg(\mathbf{x}',i,j)$, generate random mutations $m(\cdot)$ based on the sampling result of Bernoulli distribution with their allocated weight $\omega$ as the parameter. 
%Each mutation operation $m \in M$, where $M$ indicates the mutation operation set in the Damerau-Levenshtein space, accommodating the insertion, deletion, substitution, and transposition operations. 
%\begin{equation}
%    B \sim \text{Bernoulli}(\mathcal{W}(Seg(\mathbf{x}',i,j))),
%\end{equation}
%\begin{equation}
%    \tilde{\mathbf{x}}_{(i,j)} = \begin{cases}
%        m(Seg(\mathbf{x}',i,j)), & \text{if } B=1, \\
%        Seg(\mathbf{x}',i,j), & \text{otherwise}.
%    \end{cases}    
%\end{equation}
%Then, we consolidate all such $\tilde{\mathbf{x}}_{(i,j)}$ together to obtain the final randomized version $\tilde{\mathbf{x}}$.
For each identified segment $Seg(\mathbf{x}',i,j)$, we determine whether to apply a mutation based on a Bernoulli distribution with parameter $\omega$, which represents the allocated weight for that segment:
\begin{equation}
B \sim \text{Bernoulli}(\mathcal{W}(Seg(\mathbf{x}',i,j))).
\end{equation}
If a mutation is to be applied $(B = 1)$, we randomly select a mutation operation $m$ from the mutation operation set $M$. The mutation is then applied as follows:
\begin{equation}
    \tilde{\mathbf{x}}_{(i,j)} = \begin{cases}
        m(Seg(\mathbf{x}',i,j)), & \text{if } B=1, \\
        Seg(\mathbf{x}',i,j), & \text{otherwise}.
    \end{cases}    
\end{equation}
Finally, we consolidate all $\tilde{\mathbf{x}}_{(i,j)}$ to obtain the randomized version $\tilde{\mathbf{x}}$.

\item \textbf{Step 4: Post-Randomization Validation}
Verify the randomized text $\tilde{\mathbf{x}}$ to ensure compliance with $d_{DL}$ criteria:
\begin{equation}
    \text{Validate} \; d_{DL}(\tilde{\mathbf{x}}, \mathbf{x}')\ \text{s.t.}\ d_{DL}(\tilde{\mathbf{x}}, \mathbf{x}') \leq \Lambda.
\end{equation}
Discard any $\tilde{\mathbf{x}}$ that does not satisfy this condition.

\item \textbf{Step 5: Aggregation for Randomized Smoothing}
Collect all validated $\tilde{\mathbf{x}}$ instances to create a comprehensive sample set for conducting randomized smoothing. Subsequent model predictions and majority vote processes utilize this set to achieve resilient model decisions with an enlarged certified robustness radius $R_r$.
\end{itemize}
%Leveraging this methodology not only augments the chances of effectively neutralizing triggers within the vulnerable areas, but also assists in preserving linguistic coherence and minimizing unnecessary deviations from the text's original semantics and utility. Through this refined process, the randomization remains bounded within strictly defined limits of perturbation, thereby optimizing the balance between randomness and intelligibility.

This approach enhances the effectiveness of trigger neutralization in vulnerable areas while reducing unnecessary variations and maintaining linguistic coherence. By constraining randomization within defined perturbation limits, it balances text modification with preservation of original meaning.



\subsection{Theoretical Robustness Bound}
\label{sec: theory}

\begin{assumption}[Effective Parameter Smoothing]
\label{assump: effective parameter smoothing}
The output of the smoothed model $\tilde{f}(\mathbf{x}, \tilde{\bm{\theta}}_F)$ on the benign input $\mathbf{x}$ is consistent with that of the clean fine-tuned model $f(\mathbf{x}, \theta_F)$, which is also denoted as $y*$:
\begin{equation}
\begin{aligned}
\tilde{f}(\mathbf{x}, \tilde{\bm{\theta}}_F) = f(\mathbf{x}, \mathbf{\theta}_F).
\end{aligned}
\label{eq: effective parameter smoothing}
\end{equation} 
This assumption can be approximately guaranteed with the biphased parameter smoothing introduced in Sec.~\ref{sec: biphased model parameter smoothing} as long as $\eta$ in Eq.~\ref{eq: fine-tuning parameter smoothing} is set small enough.
   
\end{assumption}


\begin{theorem}[Model Robustness Condition]
Based on the Assumption~\ref{assump: effective parameter smoothing}, the lower bound of the probability that the smoothed model $\tilde{f}$ returns the $y*$ for perturbed input $\mathbf{x}'$ after the randomized smoothing $\underline{p_{y*}(\mathbf{x}')} = Beta(\alpha; K_{y*}, K - K_{y*} + 1)$, where $Beta(\alpha;,,)$ is the $\alpha$-th quantile of a beta distribution. $K_{y*}$ is the voting count for $y*$ in $K $voters, and $1-\alpha$ indicates the confidence level~\citep{zengcertified}. Then, if
\begin{equation}
\begin{aligned}
\underline{p_{y*}(\mathbf{x}')} - \beta \Delta > 0.5,
\end{aligned}
\label{eq: robust condition}
\end{equation} 
, with probability at least $1-\alpha$: $\tilde{f}(\mathbf{x}') = y*$. Here, $\Delta$ denotes the probability upper bound that trigger segment (with the maximum length of $R_r L$) is not completely randomized:
\begin{equation}
\begin{aligned}
%\Delta = 1 - (1-\omega)^{R_r L},
\Delta = 1 - \omega^{R_r L},
\end{aligned}
\label{eq: delta}
\end{equation} 
where $\omega$ indicates the randomization probability in the trigger segment (subset of identified vulnerable area). $\beta=1$ as long as the model is fully trained to the convergence during the fine-tuning phase.
\end{theorem}

\begin{corollary}[Broader Robustness Radius]
\label{corollary: radius}
To meet the same level of robustness condition in Eq.~\ref{eq: robust condition} and provide the same output probability lower bound $\underline{p_{y*}(\mathbf{x}')}$, under the same number of base models $K$, our new robustness radius is as follows:
\begin{equation}
\begin{aligned}
%R_r^{new} = \frac{log(1-\omega_M)}{log(1-\omega_L)} R_r^{old},
R_r^{new} = \frac{log(\omega_M)}{log(\omega_H)} R_r^{old},
\end{aligned}
\label{eq: robustness radius}
\end{equation}  
where $R_r^{old}$ is the old radius for traditional randomized smoothing which does not employ our proposed fuzzed text randomization. Considering that $\omega_M < \omega_H$, $\frac{log(\omega_M)}{log(\omega_H)} > 1$, which means our $R_r^{new}$ is larger than $R_r^{old}$. Especially, with more MCTS iteration budget, the confidence that the trigger is successfully captured can be higher, which means we can set $\omega_L \to 0, \omega_H \to 1$. Thus, the enlargement of the robustness radius can be more obvious.
\end{corollary}
From Corollary~\ref{corollary: radius}, the stronger efficiency of our FRS method on certifying robust language models against backdoors is proved theoretically.    

