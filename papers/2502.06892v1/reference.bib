% Textual backdoor attacks
%% attack
@article{zhao2023prompt,
  title={Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models},
  author={Zhao, Shuai and Wen, Jinming and Tuan, Luu Anh and Zhao, Junbo and Fu, Jie},
  journal={arXiv preprint arXiv:2305.01219},
  year={2023}
}
@inproceedings{chen2021badpre,
  title={BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models},
  author={Chen, Kangjie and Meng, Yuxian and Sun, Xiaofei and Guo, Shangwei and Zhang, Tianwei and Li, Jiwei and Fan, Chun},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
@inproceedings{chen2021badnl,
  title={Badnl: Backdoor attacks against nlp models with semantic-preserving improvements},
  author={Chen, Xiaoyi and Salem, Ahmed and Chen, Dingfan and Backes, Michael and Ma, Shiqing and Shen, Qingni and Wu, Zhonghai and Zhang, Yang},
  booktitle={Annual computer security applications conference},
  pages={554--569},
  year={2021}
}
@inproceedings{shen2021backdoor,
  title={Backdoor Pre-trained Models Can Transfer to All},
  author={Shen, Lujia and Ji, Shouling and Zhang, Xuhong and Li, Jinfeng and Chen, Jing and Shi, Jie and Fang, Chengfang and Yin, Jianwei and Wang, Ting},
  booktitle={Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
  pages={3141--3158},
  year={2021}
}
@inproceedings{yang2021careful,
  title={Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models},
  author={Yang, Wenkai and Li, Lei and Zhang, Zhiyuan and Ren, Xuancheng and Sun, Xu and He, Bin},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2048--2058},
  year={2021}
}
@inproceedings{kurita2020weight,
  title={Weight Poisoning Attacks on Pretrained Models},
  author={Kurita, Keita and Michel, Paul and Neubig, Graham},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={2793--2806},
  year={2020}
}
@article{dai2019backdoor,
  title={A backdoor attack against lstm-based text classification systems},
  author={Dai, Jiazhu and Chen, Chuanshuai and Li, Yufeng},
  journal={IEEE Access},
  volume={7},
  pages={138872--138878},
  year={2019},
  publisher={IEEE}
}
@inproceedings{li2021backdoor,
  title={Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning},
  author={Li, Linyang and Song, Demin and Li, Xiaonan and Zeng, Jiehang and Ma, Ruotian and Qiu, Xipeng},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={3023--3032},
  year={2021}
}
@inproceedings{zhang2021trojaning,
  title={Trojaning language models for fun and profit},
  author={Zhang, Xinyang and Zhang, Zheng and Ji, Shouling and Wang, Ting},
  booktitle={2021 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={179--197},
  year={2021},
  organization={IEEE}
}
@article{guo2022threats,
  title={Threats to pre-trained language models: Survey and taxonomy},
  author={Guo, Shangwei and Xie, Chunlong and Li, Jiwei and Lyu, Lingjuan and Zhang, Tianwei},
  journal={arXiv preprint arXiv:2202.06862},
  year={2022}
}
@inproceedings{qi2021hidden,
  title={Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger},
  author={Qi, Fanchao and Li, Mukai and Chen, Yangyi and Zhang, Zhengyan and Liu, Zhiyuan and Wang, Yasheng and Sun, Maosong},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={443--453},
  year={2021}
}
@inproceedings{qi2021turn,
  title={Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution},
  author={Qi, Fanchao and Yao, Yuan and Xu, Sophia and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={4873--4883},
  year={2021}
}
@article{xiang2024badchain,
  title={Badchain: Backdoor chain-of-thought prompting for large language models},
  author={Xiang, Zhen and Jiang, Fengqing and Xiong, Zidi and Ramasubramanian, Bhaskar and Poovendran, Radha and Li, Bo},
  journal={arXiv preprint arXiv:2401.12242},
  year={2024}
}
@article{cheng2024syntactic,
  title={Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models},
  author={Cheng, Pengzhou and Du, Wei and Wu, Zongru and Zhang, Fengwei and Chen, Libo and Liu, Gongshen},
  journal={arXiv preprint arXiv:2402.18945},
  year={2024}
}
%% defense
%%% inference-time defense
@inproceedings{qi2021onion,
  title={ONION: A Simple and Effective Defense Against Textual Backdoor Attacks},
  author={Qi, Fanchao and Chen, Yangyi and Li, Mukai and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={9558--9566},
  year={2021}
}
@inproceedings{yan2023bite,
  title={Bite: Textual backdoor attacks with iterative trigger injection},
  author={Yan, Jun and Gupta, Vansh and Ren, Xiang},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={12951--12968},
  year={2023}
}
@inproceedings{yang2021rap,
  title={RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models},
  author={Yang, Wenkai and Lin, Yankai and Li, Peng and Zhou, Jie and Sun, Xu},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={8365--8381},
  year={2021}
}
@article{zhao2024defending,
  title={Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning},
  author={Zhao, Shuai and Gan, Leilei and Tuan, Luu Anh and Fu, Jie and Lyu, Lingjuan and Jia, Meihuizi and Wen, Jinming},
  journal={arXiv preprint arXiv:2402.12168},
  year={2024}
}

%%% training-time inference
@article{chen2021mitigating,
  title={Mitigating backdoor attacks in lstm-based text classification systems by backdoor keyword identification},
  author={Chen, Chuanshuai and Dai, Jiazhu},
  journal={Neurocomputing},
  volume={452},
  pages={253--262},
  year={2021},
  publisher={Elsevier}
}
@article{cui2022unified,
  title={A unified evaluation of textual backdoor learning: Frameworks and benchmarks},
  author={Cui, Ganqu and Yuan, Lifan and He, Bingxiang and Chen, Yangyi and Liu, Zhiyuan and Sun, Maosong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5009--5023},
  year={2022}
}
@article{zhu2022moderate,
  title={Moderate-fitting as a natural backdoor defender for pre-trained language models},
  author={Zhu, Biru and Qin, Yujia and Cui, Ganqu and Chen, Yangyi and Zhao, Weilin and Fu, Chong and Deng, Yangdong and Liu, Zhiyuan and Wang, Jingang and Wu, Wei and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1086--1099},
  year={2022}
}

% Certified Robustness of Language Models
%% against evasion attack
%%% Interval Bound Propagation
@inproceedings{jia2019certified,
  title={Certified Robustness to Adversarial Word Substitutions},
  author={Jia, Robin and Raghunathan, Aditi and G{\"o}ksel, Kerem and Liang, Percy},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={4129--4142},
  year={2019}
}
@inproceedings{huang2019achieving,
  title={Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation},
  author={Huang, Po-Sen and Stanforth, Robert and Welbl, Johannes and Dyer, Chris and Yogatama, Dani and Gowal, Sven and Dvijotham, Krishnamurthy and Kohli, Pushmeet},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={4083--4093},
  year={2019}
}
@inproceedings{wang2023robustness,
  title={Robustness-Aware Word Embedding Improves Certified Robustness to Adversarial Word Substitutions},
  author={Wang, Yibin and Yang, Yichen and He, Di and He, Kun},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={673--687},
  year={2023}
}

%%% Abstract Interpretation
@inproceedings{bonaert2021fast,
  title={Fast and precise certification of transformers},
  author={Bonaert, Gregory and Dimitrov, Dimitar I and Baader, Maximilian and Vechev, Martin},
  booktitle={Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  pages={466--481},
  year={2021}
}
@inproceedings{du2021cert,
  title={Cert-RNN: Towards Certifying the Robustness of Recurrent Neural Networks},
  author={Du, Tianyu and Ji, Shouling and Shen, Lujia and Zhang, Yao and Li, Jinfeng and Shi, Jie and Fang, Chengfang and Yin, Jianwei and Beyah, Raheem and Wang, Ting},
  booktitle={Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
  pages={516--534},
  year={2021}
}

%%% Randomized Smoothing
@inproceedings{zhang2024text,
  title={Text-crs: A generalized certified robustness framework against textual adversarial attacks},
  author={Zhang, Xinyu and Hong, Hanbin and Hong, Yuan and Huang, Peng and Wang, Binghui and Ba, Zhongjie and Ren, Kui},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)},
  pages={2920--2938},
  year={2024},
  organization={IEEE}
}
@article{zhang2023certified,
  title={Certified Robustness for Large Language Models with Self-Denoising},
  author={Zhang, Zhen and Zhang, Guanhua and Hou, Bairu and Fan, Wenqi and Li, Qing and Liu, Sijia and Zhang, Yang and Chang, Shiyu},
  journal={arXiv preprint arXiv:2307.07171},
  year={2023}
}
@inproceedings{zhao2022certified,
  title={Certified robustness against natural language attacks by causal intervention},
  author={Zhao, Haiteng and Ma, Chang and Dong, Xinshuai and Luu, Anh Tuan and Deng, Zhi-Hong and Zhang, Hanwang},
  booktitle={International Conference on Machine Learning},
  pages={26958--26970},
  year={2022},
  organization={PMLR}
}
@article{zengcertified,
  title={Certified Robustness to Text Adversarial Attacks by Randomized [MASK]},
  author={Zeng, Jiehang and Xu, Jianhan and Zheng, Xiaoqing and Huang, Xuanjing},
  journal={Computational Linguistics},
  pages={1--32}
}
@inproceedings{wang2021certified,
  title={Certified robustness to word substitution attack with differential privacy},
  author={Wang, Wenjie and Tang, Pengfei and Lou, Jian and Xiong, Li},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1102--1112},
  year={2021}
}
@inproceedings{ye2020safer,
  title={SAFER: A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions},
  author={Ye, Mao and Gong, Chengyue and Liu, Qiang},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={3465--3475},
  year={2020}
}
@inproceedings{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={international conference on machine learning},
  pages={1310--1320},
  year={2019},
  organization={PMLR}
}


%% against Backdoor Attack
@article{pei2023textguard,
  title={TextGuard: Provable Defense against Backdoor Attacks on Text Classification},
  author={Pei, Hengzhi and Jia, Jinyuan and Guo, Wenbo and Li, Bo and Song, Dawn},
  journal={arXiv preprint arXiv:2311.11225},
  year={2023}
}

%% against Poisoning Attack



% Certified Robustness against backdoor attack
@inproceedings{xie2021crfl,
  title={Crfl: Certifiably robust federated learning against backdoor attacks},
  author={Xie, Chulin and Chen, Minghao and Chen, Pin-Yu and Li, Bo},
  booktitle={International Conference on Machine Learning},
  pages={11372--11382},
  year={2021},
  organization={PMLR}
}
@article{wang2020certifying,
  title={On certifying robustness against backdoor attacks via randomized smoothing},
  author={Wang, Binghui and Cao, Xiaoyu and Gong, Neil Zhenqiang and others},
  journal={arXiv preprint arXiv:2002.11750},
  year={2020}
}
@inproceedings{weber2023rab,
  title={Rab: Provable robustness against backdoor attacks},
  author={Weber, Maurice and Xu, Xiaojun and Karla{\v{s}}, Bojan and Zhang, Ce and Li, Bo},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)},
  pages={1311--1328},
  year={2023},
  organization={IEEE}
}

% Victim Models
%% BERT
@inproceedings{kenton2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}
%% RoBERTa
@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}
%% LLaMA2
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}
%% LLaMA3
@article{dubey2024llama,
  title={The Llama 3 Herd of Models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
% Datasets
%% AG's News
@article{zhang2015character,
  title={Character-level convolutional networks for text classification},
  author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}
%% SST-2
@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}
%% IMDB
@inproceedings{maas2011learning,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={142--150},
  year={2011}
}
%% OffensEval
@inproceedings{marcos2019offenseval,
  author       = {Marcos Zampieri and
                  Shervin Malmasi and
                  Preslav Nakov and
                  Sara Rosenthal and
                  Noura Farra and
                  Ritesh Kumar},
  editor       = {Jonathan May and
                  Ekaterina Shutova and
                  Aur{\'{e}}lie Herbelot and
                  Xiaodan Zhu and
                  Marianna Apidianaki and
                  Saif M. Mohammad},
  title        = {SemEval-2019 Task 6: Identifying and Categorizing Offensive Language
                  in Social Media (OffensEval)},
  booktitle    = {Proceedings of the 13th International Workshop on Semantic Evaluation,
                  SemEval@NAACL-HLT 2019, Minneapolis, MN, USA, June 6-7, 2019},
  pages        = {75--86},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/s19-2010},
  doi          = {10.18653/V1/S19-2010},
  timestamp    = {Mon, 18 Dec 2023 11:22:01 +0100},
  biburl       = {https://dblp.org/rec/conf/semeval/ZampieriMNRFK19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
%% Twitter
@inproceedings{founta2018large,
  title={Large scale crowdsourcing and characterization of twitter abusive behavior},
  author={Founta, Antigoni and Djouvas, Constantinos and Chatzakou, Despoina and Leontiadis, Ilias and Blackburn, Jeremy and Stringhini, Gianluca and Vakali, Athena and Sirivianos, Michael and Kourtellis, Nicolas},
  booktitle={Proceedings of the international AAAI conference on web and social media},
  volume={12},
  number={1},
  year={2018}
}

@inproceedings{Lang95
,author = "Ken Lang"
,title = "Newsweeder: Learning to filter netnews"
,year = 1995
,booktitle = "Proceedings of the Twelfth International Conference on Machine Learning"
,pages = "331-339"
}

%% Demerau-Levenshtein distance
@article{damerau1964technique,
  title={A technique for computer detection and correction of spelling errors},
  author={Damerau, Fred J},
  journal={Communications of the ACM},
  volume={7},
  number={3},
  pages={171--176},
  year={1964},
  publisher={ACM New York, NY, USA}
}

@inproceedings{levenshtein1966binary,
  title={Binary codes capable of correcting deletions, insertions, and reversals},
  author={Levenshtein, Vladimir I and others},
  booktitle={Soviet physics doklady},
  volume={10},
  number={8},
  pages={707--710},
  year={1966},
  organization={Soviet Union}
}


# additional references
@article{ji2024advancing,
  title={Advancing the Robustness of Large Language Models through Self-Denoised Smoothing},
  author={Ji, Jiabao and Hou, Bairu and Zhang, Zhen and Zhang, Guanhua and Fan, Wenqi and Li, Qing and Zhang, Yang and Liu, Gaowen and Liu, Sijia and Chang, Shiyu},
  journal={arXiv preprint arXiv:2404.12274},
  year={2024}
}

@inproceedings{zhang2024random,
  title={Random smooth-based certified defense against text adversarial attack},
  author={Zhang, Zeliang and Yao, Wei and Liang, Susan and Xu, Chenliang},
  booktitle={Findings of the Association for Computational Linguistics: EACL 2024},
  pages={1251--1265},
  year={2024}
}

@article{lou2024cr,
  title={CR-UTP: Certified Robustness against Universal Text Perturbations},
  author={Lou, Qian and Liang, Xin and Xue, Jiaqi and Zhang, Yancheng and Xie, Rui and Zheng, Mengxin},
  journal={arXiv preprint arXiv:2406.01873},
  year={2024}
}

%% KL divergence
@article{kullback1951information,
  title={On information and sufficiency},
  author={Kullback, Solomon and Leibler, Richard A},
  journal={The annals of mathematical statistics},
  volume={22},
  number={1},
  pages={79--86},
  year={1951},
  publisher={JSTOR}
}

%% LoRA
@inproceedings{hulora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={International Conference on Learning Representations}
}