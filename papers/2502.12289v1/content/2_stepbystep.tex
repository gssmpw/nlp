\section{Background}
\label{sec:step-by-step}

\subsection{Step-by-step reasoning evaluation}

\label{sec:elements}

\textbf{Step-by-step reasoning} is where LLMs generate a series of intermediate natural language steps that lead to the final answer \citep{NEURIPS2022_9d560961}. Each step-by-step reasoning consists of three parts, a \textbf{query}, a \textbf{reasoning trace}, and the \textbf{answer} (Figure \ref{fig:elements}). Query refers to the entire input, which includes the question and retrieved evidence in fact-intensive reasoning tasks \citep{NEURIPS2020_6b493230}. Upon seeing a query, the LLM autoregressively generates its solution as a long \textbf{reasoning trace}. Finally, a trace should output an \textbf{answer}, either explicitly formatted (\textit{e.g.} \texttt{\textbackslash boxed\{15\}}) or implicitly stated (\textit{e.g. Therefore, John ate 15 apples}).

Various evaluation metrics require the reasoning trace to be segmented into \textbf{steps}. The step boundary can be determined using simple rules, \textit{e.g.} sentences or double newlines (\texttt{\textbackslash n\textbackslash n}). However, the format of a reasoning trace is highly dependent on the format of the instruction tuning data, which might lead to inconsistent granularity of steps. As a solution, alternative segmentation strategies were proposed, including Semantic Role Labeling-based chunking \citet{prasad-etal-2023-receval} or prompting LLMs \citet{zheng2024processbenchidentifyingprocesserrors}.

Finally, metrics assess the quality of the step and assign a \textbf{score}. The details about different metrics are further described in Section \ref{sec:metric-implementations}. These scores can be used to improve answer accuracy in Best-of-N decoding \citep{cui2024ultrafeedbackboostinglanguagemodels, zhang2025lessonsdevelopingprocessreward}, train LLMs via reinforcement learning \citep{wang-etal-2024-math, zhang2025lessonsdevelopingprocessreward}, or guide inference-time tree search \citep{NEURIPS2023_271db992, yang2022generatingnaturallanguageproofs}.

% Assuming an autoregressive language model, step-by-step reasoning can be divided into 3 components: \textbf{query}, \textbf{reasoning trace}, and \textbf{answer}.

% \textbf{Query} is the text initially provided to the model by the user. This definition includes both the question and retrieved documents (\textit{evidences}), when retrieval-augmented generation \citep{NEURIPS2020_6b493230} is used for factually grounded reasoning tasks.

% % For methods that employ multi-turn interaction between the model and the environment (\textit{e.g.} on-the-fly retrieval, calculator, API, code execution), the distinction between query and reasoning trace is not clear. While external tools produce deterministic results and are indistinguishable in terms of model training \citep{xiong2024buildingmathagentsmultiturn}, we consider these intermediate inputs as a part of the query for concisely defining groundedness.

% \textbf{Reasoning trace} refers to the entire text the model generates conditioned on the query. While tokens are the elementary units of autoregressive LLMs, evaluating a single token can be challenging due to its limited information. Therefore, most works assume the reasoning trace to be a series of atomic units, which are often referred to as \textbf{steps}.
% % The granularity of ERUs can be fine-grained as tokens to coarse as entire reasoning traces; the benefits and drawbacks of different granularities are described in Section \ref{sec:eru}.

% \textbf{Answer} is the specific term or phrase the model presents as the answer, which is used to evaluate the answer accuracy. It can be either explicitly formatted (\texttt{\textbackslash boxed\{15\}}) or implicitly stated (\texttt{Therefore, John ate 15 apples.}). While the former provides a straightforward method for extracting the answer, it often requires additional fine-tuning \citep{DBLP:conf/iclr/LightmanKBEBLLS24} or few-shot examples \citep{NEURIPS2022_9d560961} to make LLMs abide by the given format. Common methods evaluate the implicitly stated answers include \textit{Exact Match}, which is evaluated as correct if the correct answer appears within a certain range (\textit{e.g.} Last 10 words of the reasoning trace), \citep{NEURIPS2022_8bb0d291, lyu-etal-2023-faithful} or LLM-based extraction/evaluation \citep{zheng2024processbenchidentifyingprocesserrors}.


\begin{figure}[tb]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/elements.pdf}
    \caption{Illustration of three elements of step-by-step reasoning: query, reasoning trace (steps), and the answer.}
    \label{fig:elements}
\end{figure}

\subsection{Reasoning tasks}

The concept of step-by-step reasoning was initially derived from \textbf{factual/commonsense reasoning}. These tasks include questions that can only be answered by combining different information from the query and performing multi-hop inference \citep{mavi2024multihopquestionanswering}. \textbf{Factual reasoning} focuses on combining facts to find the correct answer \citep{yang-etal-2018-hotpotqa, talmor-berant-2018-web, kwiatkowski-etal-2019-natural}, while \textbf{commonsense reasoning} also requires commonsense knowledge to complete the inference \citep{clark2018thinksolvedquestionanswering, talmor-etal-2019-commonsenseqa, geva-etal-2021-aristotle, trivedi-etal-2022-musique}.



Another important venue is \textbf{symbolic reasoning}, where the reasoning process can be expressed using \textit{symbols} (\textit{e.g.} equations, logic, code) \citep{sprague2024cotcotchainofthoughthelps}. This encompasses \textbf{mathematical reasoning}, including arithmetics, calculus, and number theory \citep{cobbe2021trainingverifierssolvemath, NEURIPSDnB2021_be83ab3e, he-etal-2024-olympiadbench, gao2024omnimathuniversalolympiadlevel}; \textbf{logical reasoning}, which involves performing complex sequence of deductive inference \citep{tafjord-etal-2021-proofwriter, han-etal-2024-folio, PrOntoQA}; and \textbf{algorithmic reasoning}, which requires manipulating strings or data structures \citep{srivastava2023imitationgamequantifyingextrapolating, suzgun2022challengingbigbenchtaskschainofthought, NEURIPS2023_7a92bcde}.\footnote{While symbolic reasoning may strictly refer to \textit{algorithmic reasoning} \citep{NEURIPS2022_9d560961} depending on context, we adopt the broader sense that includes math and logical reasoning.\citep{sprague2024cotcotchainofthoughthelps}.}

% \note{Errors in factual reasoning happen in selecting incorrect/irrelvant facts from the lengthy, complex evidence \citep{}. On the opposite side, most errors in challenging symbolic reasoning benchmark is making a wrong inference}
 
Further details on reasoning tasks and benchmarks are presented in Appendix \ref{sec:appendix-task}.


% Tasks that benefit from step-by-step reasoning are known to generally satisfy two conditions: (1) there is a symbolic representation (equations, first-order logic, code) that can accurately express the semantics of the task \citep{sprague2024cotcotchainofthoughthelps, liu2024mindstepbystep}, and (2) the solution can be found in polynomial time \citep{kang2024empiricalcomplexityreasoningplanning}.

% The second condition can be effectively mitigated by applying tree search methods \citep[Section \ref{sec:inference-time-exploration}]{NEURIPS2023_271db992}, which aim to prune the exponential search space to a manageable size based on heuristics. This approach led to significant improvement in exponentially sized tasks such as Game of 24 and Crosswords \citep{NEURIPS2023_271db992}, along with pushing the state-of-the-art in classic math reasoning tasks \citep{wang-etal-2024-math}.

% However, whether the effectiveness of step-by-step reasoning extends to non-symbolic tasks such as factual and commonsense reasoning \citep[\textit{e.g.}][]{clark2018thinksolvedquestionanswering, talmor-etal-2019-commonsenseqa, geva-etal-2021-aristotle, trivedi-etal-2022-musique} remains in dispute. While several step-by-step reasoning works claim improvement in commonsense reasoning benchmarks \citep{NEURIPS2022_9d560961, golovneva2023pathfinderguidedsearchmultistep}, \citet{sprague2024cotcotchainofthoughthelps} showed that step-by-step reasoning brings only a marginal gain in factual and commonsense reasoning. Furthermore, \citet{liu2024mindstepbystep} lists tasks where verbalization or long thinking hurts human performance from cognitive science studies, and shows that Chain-of-thoughts prompting also damages the performance of LLMs and large vision-language models in these tasks.
