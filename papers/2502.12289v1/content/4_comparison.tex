\section{Comparative analysis}
\label{sec:comparison}

\subsection{Comparison between proposed categories}
\label{sec:comparison-ours}

\textbf{Groundedness$\leftrightarrow$Validity.} Groundedness focuses on the explicit information in the query while validity focuses on the inference. For instance, Given an incorrect step \textit{Albert Einstein died in 1965} (he died in 1955), this step is not grounded if the query explicitly mentions that \textit{Einstein died in 1955}. Apart from that, if the previous steps provide the premises for reaching 1955, \textit{i.e.} \textit{Einstein was born in 1879, and he died at the age of 76}, the step is invalid.

\textbf{Validity$\leftrightarrow$Coherence.} Existing works often treat coherence as a subtype of validity \citep{DBLP:conf/iclr/GolovnevaCPCZFC23, zhu2024deductivebeamsearchdecoding, kim2024biggenbenchprincipledbenchmark, jacovi-etal-2024-chain}, as both criteria judge a step based on its previous steps. However, validity and coherence are different by definition, as validity focuses on the logical correctness of a step while coherence focuses on the pragmatic aspect of informativeness. For instance (Figure \ref{fig:metric_intro}-Coherence), omitting a step (Step 3) from the correct trace will make the subsequent step (Step 4) incoherent, but Step 4 is still valid since it can be eventually deduced from the query and previous steps.

\textbf{Validity$\leftrightarrow$Utility.} Previous studies have continuously pointed out that validity does not necessarily lead to utility and vice versa \citep{lyu-etal-2023-faithful, nguyen-etal-2024-direct}. One case is \textit{shortcut reasoning} \citep{schnitzler2024morehopqa, lee2025symbasymbolicbackwardchaining}, where LLM generates invalid Chain-of-thoughts but guesses the correct answer directly from the query. ProcessBench \citep{zheng2024processbenchidentifyingprocesserrors} reports that invalid traces with correct answers can be easily found in challenging problems, reaching 51.8\% in the olympiad-level Omni-MATH \citep{gao2024omnimathuniversalolympiadlevel}.

\subsection{Comparison to existing terminologies}

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/sankey.pdf}
    \caption{A Sankey diagram displaying the relationship between commonly used terminologies (left) to the proposed taxonomy (right).}
    \label{fig:sankey}
\end{figure}

\textbf{Factuality} is often defined as \textit{"modelâ€™s capability of generating contents of factual information, grounded in reliable sources"} \citep{wang2023surveyfactualitylargelanguage, wang-etal-2024-factuality}, which originates from other text generation tasks such as abstractive summarization. However, this definition fails to include groundedness to the \textit{question}, \textit{e.g.} using the exact numbers provided in the math problem \citep{zhu2024deductivebeamsearchdecoding}.

\textbf{Hallucination} is most commonly defined as \textit{"models either generating (1) nonsensical or (2) unfaithful to the source content"} \citep{ji2023survey, banerjee2024llmshallucinateneedlive, huang2024survey}, which corresponds to (1) validity/coherence and (2) groundedness. However, some works restrict the meaning of hallucination to groundedness errors, \textit{i.e.} \textit{"models generating description tokens that are not supported by the source inputs"} \citep{xiao-wang-2021-hallucination, akbar-etal-2024-hallumeasure}.

\textbf{Faithfulness} is also used in different contexts. The most common definition for faithfulness is \textit{"logical consistency between the generated text and the query/previous steps"} \citep{maynez2020faithfulnessfactualityabstractivesummarization, creswell2022faithfulreasoningusinglarge, huang2024survey}, which includes both groundedness (query) and validity (previous step). Instead, faithfulness can be used as \textit{"accurately representing the model's internal reasoning process"} \citep{lyu-etal-2023-faithful, lanham2023measuringfaithfulnesschainofthoughtreasoning}. Under this definition, the final step containing the answer is unfaithful if it is not supported by the previous steps, which falls under the definition of coherence.

\textbf{Informativeness} is defined as "providing new information that is helpful towards deriving the generated answer" \citep{golovneva2023pathfinderguidedsearchmultistep, prasad-etal-2023-receval}. Lack of informativeness is often described as \textbf{redundancy} \textit{"removing the step does not affect the reasoning process"} \citep{chiang-lee-2024-reasoning, song2025prmbenchfinegrainedchallengingbenchmark, zhou2024languagemodelsperformrobust} or \textbf{irrelevance} \textit{"unrelated to the query's topic or task"} \citep{wang-etal-2023-towards, zhou2024languagemodelsperformrobust, jacovi-etal-2024-chain}. Informativeness is highly related to utility, as it aims to evaluate the contribution of a step to reaching the final answer.

% Furthermore, topic-irrelevant steps (\textit{e.g.} mentioning properties of helium atoms when solving an electrodynamic problem without any relevant context) \citep{zhou2024languagemodelsperformrobust} are useless and incoherent because there is no previous step that indicates why this step is required.

% \subsection{Metrics}

% % \textit{Verifiers} \citep{cobbe2021trainingverifierssolvemath, zhang2024generativeverifiersrewardmodeling, li-etal-2023-making} often refer to the models trained to classify if a step is logically correct or not.

% \textbf{Process Reward Models (PRMs)} refer to \textit{"models that provide (numerical) feedback/evaluation for each step"} \citep{DBLP:conf/iclr/LightmanKBEBLLS24, wang-etal-2024-math, setlur2024rewardingprogressscalingautomated}. However, the \textit{meaning} of the score can vary based on the training objective used to train PRMs; some models are trained to predict the validity label of a given step using annotations like PRM800k \citep{DBLP:conf/iclr/LightmanKBEBLLS24}, while others train a regression head to directly predict the value function calculated from Monte Carlo Tree Search-like process. We further discuss the two types of PRMs in Section \ref{sec:transfer-vu}.