\section{Method}
\label{sec:method}

As detailed in \S\ref{sec:background}, we predict cell morphological changes by transforming distributions between control and perturbed cells under specific conditions within the same batch. In this section, we introduce \emph{CellFlow}, which leverages flow matching, a principled framework for learning continuous transformations between probability distributions. We adapt flow matching with condition, noise augmentation, and classifier-free guidance to better address our problem setting.

\input{tabs/main_result}

\subsection{Preliminaries}

Flow matching~\cite{lipman2022flow,lipman2024flow} provides a framework to learn transformations between probability distributions by constructing smooth paths between paired samples (Figure~\ref{fig:overview}d). It models how a source distribution continuously deforms into a target distribution through time, similar to morphing one shape into another. 

More formally, consider probability distributions $p_0$ and $p_1$ defined on a metric space $(\mathcal{X}, d)$. Given pairs of samples from these distributions, flow matching learns a time-dependent velocity field using a neural network $v_\theta: \mathcal{X} \times [0,1] \rightarrow \mathcal{X}$ that describes the instantaneous direction and magnitude of change at each point. The transformation process follows an ordinary differential equation:
\[
{dx_t} = v_\theta(x_t, t){dt}, \quad x_0 \sim p_0, \quad x_1 \sim p_1, \quad t \in [0, 1]
\]

During training, we construct a probability path that connects samples from the source ($p_0$) and target ($p_1$) distributions (Figure~\ref{fig:cellflow}a). We employ the rectified flow formulation, which yields a simple straight-line path~\cite{liu2022flow}:
\[ x_t = (1-t)x_0 + tx_1, \quad t \sim \mathcal{U}[0,1] \]

This linear path has a constant velocity field $v(x_t, t) = dx_t/dt = x_1 - x_0$, which represents the optimal transport direction at each point. The neural network $v_\theta$ is trained to approximate this optimal velocity field by minimizing:
\[ \mathcal{L}(\theta) = \mathbb{E}_{x_0 \sim p_0, x_1 \sim p_1, t \sim \mathcal{U}[0,1]} \|v_\theta(x_t, t) - v(x_t, t)\|_2^2 \]

At inference time, given a sample $x_0 \sim p_0$, we generate $x_1$ by solving the ODE (Figure~\ref{fig:cellflow}b), whose solution is:
\[
x_1 = x_0 + \int_0^1 v_\theta(x_t, t)dt
\]
We employ numerical integrators like Euler method or more advanced methods such as Runge-Kutta to solve the ODE.

\subsection{Conditional Flow Matching}

To model perturbation conditions, we extend flow matching by conditioning on perturbations $c \in \mathcal{C}$. While the source distribution $p_0$ represents unperturbed cell images, the target distribution now becomes condition-dependent, denoted as $p_1(x|c)$. Our goal is to learn a conditional velocity field $v_\theta: \mathcal{X} \times [0,1] \times \mathcal{C} \rightarrow \mathcal{X}$ that captures perturbation-specific transformations~\cite{esser2024scaling}:
\[
{dx_t} = v_\theta(x_t, t, c) {dt}, \quad x_0 \sim p_0, \quad x_1 \sim p_1(\cdot|c)
\]

\subsection{Classifier-Free Guidance}

We incorporate classifier-free guidance~\cite{ho2022classifier} to improve generation fidelity. During training, we randomly mask conditions with probability $p_c$, replacing $c$ with a null token $\emptyset$. At inference time, we interpolate between conditional and unconditional predictions:
\[
v_\theta^{\text{CFG}}(x_t, t, c) = \alpha \cdot v_\theta(x_t, t, c) + (1-\alpha) \cdot v_\theta(x_t, t, \emptyset)
\]
where $\alpha > 1$ controls guidance strength. 

\subsection{Noise Augmentation}
Since $p_0$ and $p_1$ are both empirical distributions from datasets with limited observations, direct mapping between them may lead to bad generalization. Therefore, we propose augmenting the samples to make the learned velocity field smoother. This is done by adding random Gaussian noise to $x_0 \sim p_0$ with a probability $p_e$. Formally:
\[ \tilde{x}_0 = \begin{cases} 
x_0 + \epsilon, & \text{with probability } p_e \\
x_0, & \text{with probability } 1-p_e
\end{cases} \]
where $\epsilon \sim \mathcal{N}(0, \sigma^2I)$. This noise augmentation helps prevent overfitting to discrete samples and encourages the model to learn a continuous velocity field in the ambient space. The noise scale $\sigma$ and probability $p_e$ are hyperparameters that control the smoothness of the learned field.

\subsection{Neural Network Architecture}
The velocity field $v_\theta$ is realized through a U-Net architecture~\cite{ronneberger2015u}, as we directly model the distribution in image pixel space $\mathcal{X} \subset \mathbb{R}^{H\times W\times C}$, where U-Net captures both local and global features through its multi-scale structure. Time $t$ is encoded using Fourier features, and condition $c \in \mathcal{C}$ is embedded through a learnable network $E: \mathcal{C} \rightarrow \mathbb{R}^d$. These embeddings are added to form the condition signal, which is then injected into the U-Net blocks to guide the generation process~\cite{esser2024scaling}. 

The entire \emph{CellFlow} algorithm is summarized in \S\ref{sec:algorithm}.
