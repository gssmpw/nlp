\section{Methodology}

\subsection{Regression: from Scalar to Categorical Distribution}\label{sec:regression}
As we perform $k$ individual rollouts from the current state to calculate the Monte Carlo return and estimate the state value, each of the rollouts will return a binary value which is the outcome reward. There are totally $k+1$ different kinds of estimated state values, evenly ranging from 0 to 1 with step size being $\frac{1}{k}$. We can thus construct a classification objective and train a classifier to handle the problem. To clarify, we map the $k+1$ different estimated values into $k+1$ different bins, each bin represents one of the estimated values. Each time, given the question $q$ and the current state $s_t$, the value-based process verifier, which is a classifier, chooses one of the $k+1$ different bins and maps the selected bin to the value. We can optimize the value-based process verifier through cross-entropy loss as follows:
\begin{equation}
    \min_\theta\sum_{i=1}^N\log f_\theta(b_i|q,s_t),
\end{equation}
where $f_\theta$ is the function mapping from state space $\{q\}\bigcup s_t\in\mathcal{S}$ to one of the bins. $b_i\in\mathbb{N}^+$ is the bin index of estimated state value ranging from 1 to $k+1$. The $i$-th bin will then be mapped to the state values, for example, $\frac{i-1}{k}$. In such case, the predicted state value $f_\theta(\cdot|q,s_t)$ is defined in the discrete space while $V^\pi(s)$ is defined in the contiguous space, which poses a mismatch between the objective function and target value. 

In order to bridge the gap between the discrete estimated state value space and the contiguous target value space, researchers treat the value prediction problem as a regression task that includes the \textbf{distance prior}. Specifically, for two estimated values $\frac{i}{k}$ and $\frac{j}{k}$, the distance between them is the square of the difference. The distance prior allows us to optimize the discrete estimated state value in the contiguous value space, ensuring the predicted value makes sense beyond the discrete values. To clarify, for the given dataset $\{q^i, s_t^i,y^i\}^N$, people use the mean-squared error (MSE) loss to optimize value-based process verifier as follows:
\begin{equation}\label{reg:scalar}
    \min_\theta\sum_{i=1}^N(f_\theta(q, s_t)-y)^2
\end{equation}
where $f_\theta$ is the function mapping from state space $\{q\}\bigcup s_t\in\mathcal{S}$ to the contiguous space $y\in[0,1]$, $y$ is the estimated value from the current state to the outcome that ranges from 0 to 1. We name Eqn.\ref{reg:scalar} as scalar regression.

Similar to the \textbf{distance prior} injected via the mean-square error objective function, one can represent the contiguous value as the expectation of some categorical distribution, which is defined by the Dirac delta function and the category quantity. We name it as the \textbf{structural prior}. To clarify, we define the categorical distribution $\mathcal{Z}$ with $m$ locations as follows:
\begin{equation}
    \mathcal{Z}=\left\{\sum_{i=1}^{m}p_i\delta_{z_i}:p_i\geq0;\sum_{i=1}^{m}p_i=1\right\},
\end{equation}
where $z_i$ is the $i$-th location of the categorical distribution,  $p_i$ is the probability of selecting location $z_i$, and $\delta_{z_i}$ is the Dirac delta function at location $z_i$. The \textbf{structural prior} thus allow us to represent the $V^\pi(s)$ as the expectation of the categorical distribution as follows:
\begin{equation}\label{value_cate}
    V^\pi(s)=\mathbb{E}_p[\delta_i]=\sum_{i=1}^{m}p_i(s)\delta_i.
\end{equation}

Given $f_\theta$ mapping from state space $\{q\}\bigcup s_t\in\mathcal{S}$ to the categorical distribution $\mathcal{Z}\in\mathcal{R}^{m}$, we can also optimize value-based process verifier using the maximum likelihood estimator under MSE loss as follows:
\begin{equation}\label{reg:categorical}
    \mathcal{L}_\theta^{MSE}=\min_\theta\sum_{i=1}^N(f_\theta(q,s_t)\cdot\Delta_z^T-y)^2,
\end{equation}
where $\Delta_z=[\delta_{z_1},\delta_{z_2},...,\delta_{z_{m}}]$ is the weighting vector to calculate the expectation of categorical distribution $\mathcal{Z}$. We name Eqn.\ref{reg:categorical} as expectation regression.

\input{algorithm/Regression}
The na\"ive implementation while optimizing value-based process verifier using Eqn.\ref{reg:scalar} and Eqn.\ref{reg:categorical} is shown in Algorithm \ref{alg:reg}. Both methods calculate the estimated state value $\hat{V}^\pi(s)$ under Monte Carlo sampling, then perform MSE loss between the predicted value $f_\theta(\cdot,s)$ and estimated value $\hat{V}^\pi(s)$. Through sharing the same objective function and the identical distance prior, the expectation regression additionally follows the \textbf{structural prior}, which allows us to optimize the value-based process verifier from the distribution's perspective.

\subsection{Structural Prior Injection via Categorical Distribution Modeling}
By treating the k-times Monte Carlo sampling as a singular sample of the Monte Carlo estimation, the estimation distribution then follows the Binomial distribution:
\begin{equation}\label{mtd:mc_distribution}
    \hat{V}^\pi(s)\sim Bin(k,p),
\end{equation}
where $p$ is the ground-truth state value, $k$ is the sampling quantity. The scalar regression problem can thus be interpreted from the distribution perspective: given current state $s_t$, we sample once from the Binomial distribution $Bin(k,p)$, annotated as $V^\pi(s)$. Our goal is to estimate the expectation of the Binomial distribution $\mathbb{E}[V^\pi(s)]$ where $V^\pi(s)\sim Bin(k,p)$.  We name the value-based process verifier as expectation-based model.

We perform two different methods to optimize the value-based process verifier. The first method is through the mean-square error objective function, as we aim to recover the expectation of the Binomial distribution. We model the categorical distribution as having the identical Dirac delta function and category quantity compared with the Binomial distribution:
\begin{equation}
    \delta_{z_i}=z_i,z_i=\frac{i-1}{k},i\in[1,2,...,k+1],
\end{equation}
where $k$ is the sampling quantity, which is equal to the category quantity. We then optimize the expectation of the categorical distribution using Eqn.\ref{reg:categorical}. Compared with the scalar regression method, we inject the definition of the categorical distribution as the structural prior. 

The second method is through cross-entropy, or the Histogram Loss. Following the categorical distribution definition above, we aim to recover the ground-truth target distribution, i.e. the Binomial distribution $Bin(k,p)$. Ideally, if there's a chance to recover the ground-truth distribution given limited Monte Carlo sampling results, the expectation of the categorical distribution, which is the predicted state value, can be accurate and match the ground truth $p$. As it's difficult since we only have one sampled result from the Binomial distribution, the goal of reducing sampling error is to find the optimal posterior distribution class. To clarify, given limited sampling results, our goal is to find the optimal posterior distribution class that is conditioned on the sampling results, which has the minimum distance to the ground-truth Binomial distribution where the sampled results come from. Compared with the scalar regression method, the structural prior of the second method is two-fold. We first define the Dirac delta function and category quantity that is identical to the ground truth target distribution, then define the exact posterior distribution class that can be close to the ground truth target distribution. 

In the following section, we introduce the method to find the suitable posterior distribution class.

\subsection{Posterior Distribution Selection via Statistics-based Distance}
As the estimated state value $\hat{V}^\pi(s)$ follows the Binomial distribution as described in Eqn.\ref{mtd:mc_distribution}, the ground-truth target distribution of categorical distribution is the Binomial distribution with ground-truth success rate $p$ and number of Monte Carlo rollouts $k$. However, it is difficult to estimate the distribution with limited sampling instances in an unbiased way, especially when we sample only once from the categorical distribution. Given limited sampling results, we propose the metric to calculate the distance between posterior distribution and ground-truth target distribution at the statistical level as follows:
\begin{definition}
    \textit{Statistical Distribution Distance.} Given $p$ as the posterior distribution, $q$ as the target distribution, $d$ as one of the pre-defined distance metrics like Kullback-Leibler(KL) divergence, Wasserstein distance, or else. The distance between distributions at the statistical level is defined via statistics-based expectation as follows:
    \begin{equation}
        \mathcal{DT}(p,q)=\mathbb{E}_{x\sim q}[d(p(\cdot|x),q)].
    \end{equation}
\end{definition}
The KL divergence is useful to measure the distance between distributions. However, as the categories in the categorical distribution have sequence characteristics(i.e. have different weights), it's not suitable to measure the distance between categorical distributions by KL divergence. We use the Wasserstein distance instead. It's reasonable that the smaller the Statistical Distribution Distance is, the more accurately we estimate the target distribution, which will help improve the performance of the value-based process verifier.

After all, the value-based process verifier will be optimized by the Histogram Loss to provide distribution shaping supervise signal as follows:
\begin{equation}\label{mtd:hl}
    \mathcal{L}_\theta^{HL}=\min_\theta-\sum_{i=1}^N\sum_{j=1}^{|\mathcal{Z}|}f_\theta(z_j|q,s_t)\log p(z_j|q,s_t)
\end{equation}
where $j$ is the bin index of the categorical distribution $\mathcal{Z}$, $p(z_j)$ is the probability of the $j$-th bin of the posterior distribution $p$.