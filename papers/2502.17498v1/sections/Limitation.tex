\section{Limitation and Future work}
We believe that the structural prior injection method, as well as the categorical distribution modeling method, provides a meaningful aspect to improve the performance of the value-based process verifier and analyze the Monte Carlo estimation error. However, we are certain that research about the structural prior still has a long way to go. For instance, when optimizing the categorical distribution via Histogram Loss, as we use the statistics-based distance to measure the distance between the posterior distribution and ground-truth distribution, the distribution modeling can only be performed in a prior and non-differentiable way due to the non-differentiable nature of Wasserstein distance. One future direction is to soften the distance metric and transform the distribution modeling approach into a tractable and dynamic way. 

The other thing is that we use the Histogram Loss to optimize the categorical distribution representation, which is not a perfect objective function due to the absence of distance prior. To clarify, as the categorical distribution is defined under the Dirac delta function of unsteady values, the categories then follow a natural order since our goal is the expectation of the categorical distribution. When optimizing the verifier via Histogram Loss, the distance between different categories will not be taken into account. Like other injected prior information, the data prior will not change the optimal solution which is the estimated posterior distribution, but it should result in a better performance for reasons like faster convergence or more accurate objective.

Finally, while our work discusses the mean-square error and cross-entropy loss from the unified perspective, we find it hard to combine the two different objective functions together. When training verifiers using both the mean-square error and cross-entropy loss by their linear combinations, we find there's a performance drop compared with training on each objective function individually. The possible reason may be the different gradient directions during the optimization process or the different assumptions from the perspective of maximum likelihood optimization. Further work can perform more analysis of the potential and scalability of using both objective functions together.
