\section{Introduction}

Large language models (LLMs) have revolutionized natural language processing, with fine-tuning emerging as a prevalent method to adapt these models for specific tasks or domains~\citep{houlsby2019parameter,hu2022lora}. However, \emph{fine-tuned} LLMs often display overconfidence in their predictions~\citep{jiang2021can,yang2024lalora}, which compromises their reliability and limits their applicability in critical domains where trustworthiness is essential.

Overconfidence in LLMs often manifests as poor calibration, where the predicted probabilities do not accurately reflect the model's uncertainty about its predictions. Uncertainty-aware methods improve calibration by explicitly quantifying the uncertainty in the model's predictions, allowing the model to produce confidence scores that better correspond to the actual likelihood of correctness. Traditional uncertainty-aware methods, such as MC-Dropout~\citep{gal2016dropout} and Deep Ensemble~\citep{lakshminarayanan2017simple,fort2019deep} are commonly used to mitigate overconfidence in neural networks. However, these approaches typically require multiple forward passes, significantly increasing the inference time for LLMs.

Evidential Deep Learning (EDL)~\citep{sensoy2018evidential,malinin2018predictive} offers a more efficient alternative by providing uncertainty estimates with a single forward pass. Despite its success in various tasks, recent studies~\citep{deng2023uncertainty,chen2024redl} indicate that EDL can still yield overconfident predictions which leads to inaccurate uncertainty estimates, degrading the model’s calibration performance. This issue arises from the propensity of vanilla EDL to encourage models to generate excessive evidence (i.e., support for a class) with extremely large magnitudes, leading to overly confident predicted class probabilities.


Motivated by these challenges, we propose a novel regularization approach for EDL using an \emph{information bottleneck}, which we term \textbf{IB-EDL}. IB-EDL adaptively distorts the evidence generated by the LLM while maximally preserving the model's performance. In doing so, IB-EDL encourages the model to suppress spurious or uninformative evidence that could lead to overconfident predictions. Our theoretical analysis shows that the information bottleneck effectively penalizes the generation of disproportionately large evidence, thereby reducing overconfidence. Notably, our method introduces less than $2\%$ computational overhead compared to a pretrained LLM, maintaining the model's inference efficiency while significantly improving its calibration. Our contributions are as follows:

{
\setlength{\leftmargini}{0pt} % This change is local to this group
\begin{compactitem}[$\bullet$]
   % \item We introduce IB-EDL, an information-theoretic approach to regularize EDL. By carefully selecting the IB stochastic variable within the EDL inference pipeline, we eliminate the need for the network to approximate certain distributions involved in the optimization objective. This not only preserves the model’s learning capacity, allowing it to focus on learning more generalizable representations, but also makes IB-EDL more interpretable.
   \item We introduce IB-EDL, an information-theoretic framework for regularizing EDL. First, we identify a theoretical issue previously overlooked in the IB literature. In the context of EDL, we address this challenge through a novel choice of the IB stochastic variable. Moreover, our solution naturally imposes an $\ell_2$ regularization, effectively mitigating the issue of overly large evidence highlighted in prior EDL research.
   \item We show that several existing EDL methods can be seen as a special case within the IB-EDL framework. This unification offers a cohesive perspective on these approaches.
   \item We perform extensive experiments on calibrating \emph{fine-tuned} LLMs using EDL, thereby extending its applicability beyond the medium-sized networks commonly used in the EDL literature. Our results across various LLMs and datasets demonstrate that IB-EDL scales effectively.
    \end{compactitem}
}


    %\item We introduce a novel uncertainty-aware approach based on information theory, namely IB-EDL, to enhance the calibration of LLM during fine-tuning. By integrating an Information Bottleneck into EDL pipeline, our method improves model interpretability and focuses on learning more generalizable representation. 

    %\item We providediscuss a rigorous theoretical foundation for theour proposed IB-EDL framework, which unifies existing EDL methods. Our theoretical analysis positions these methods within a cohesive structure, offering a broader theoretical perspective that clarifies their relationships.