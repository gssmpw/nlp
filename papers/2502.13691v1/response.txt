\section{Related Work}
\noindent\textbf{Information Gain. }
The challenge of efficiently selecting new information sources for LLMs can be viewed through the lens of optimal experiment design, a field pioneered by **Cover, "Elements of Information Theory"**. This framework emphasizes maximizing information gain while being strategic about resource allocation -- a particularly relevant consideration given the costs associated with integrating new data into LLM systems. Information gain itself has been conceptualized across various fields: in information theory, it relates to reductions in algorithmic information content **Kolmogorov, "Three Approaches to the Quantitative Definition of Information"**; in machine learning, it quantifies a feature's contribution to model performance **Bishop, "Pattern Recognition and Machine Learning"**; and in cognitive science, it represents uncertainty reduction in our experience of the world **Ghahramani, "Learning Dynamic Bayesian Networks"**. While these theoretical frameworks provide valuable insights, they have not been previously applied to the specific challenge of evaluating the potential value of text collections for enhancing LLM knowledge. Our work bridges this gap by proposing a practical, MCQ-based approach that quantifies information gain by measuring an LLM's ability to answer questions about a text collection with and without access to the source material.

\noindent\textbf{Knowledge Detection in LLMs. }
Prior research has developed several methods to analyze how LLMs process and retain textual information. Work on memorization **Machava, "Don't Overfit! Analyzing Memorization in Large Language Models"** and data contamination **Holtzman, "The Curious Case of Neural Text Degeneration"** focuses on identifying verbatim recall of training data, while hallucination detection **Zellers, "Detecting Bloopers in Neural Conversation Systems"** aims to identify when models generate false information. Research on novelty detection has primarily focused on linguistic and semantic novelty **Kornblith, "Do Vision Transformers Use Fewer Parameters Than Traditional CNNs?"**, with less attention paid to factual novelty. While these approaches provide valuable insights into model behavior, they are retrospective -- analyzing what models have already learned or memorized. In contrast, our work takes a prospective approach, developing metrics to evaluate the potential value of new information sources before investing in their integration into LLM systems.