%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.



% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[preprint]{icml2025}
% \usepackage[preprint]{icml2025}

% For theorems and such
\usepackage{xr}
\usepackage{xr-hyper}
% \usepackage{subfiles}
\usepackage{floatflt}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{subcaption, graphicx}
\usepackage{xcolor}
\usepackage{wrapfig}
\usepackage{pifont} 
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{booktabs}       % professional-quality tables
\usepackage{url}            % simple URL typesetting
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage{glossaries}
\usepackage{float}
\usepackage{algorithm}    % Uses the one from ICML
\usepackage{algorithmic}  % Uses the one from ICMLs
% \usepackage{algpseudocode}
% \usepackage[ruled,vlined,compatiblealgorithm]{algorithm2e}
% \usepackage[ruled,vlined]{algorithm2e}
% \usepackage{algorithmicx}
\usepackage[framemethod=tikz]{mdframed}
\usepackage[most]{tcolorbox}
\tcbuselibrary{skins,breakable}
\usepackage{caption}
\usepackage{chemarrow}
\usepackage{siunitx}
\usepackage{multirow}
\usepackage{hyperref}

\makeatletter
\gdef\isaccepted{0}  % This keeps the "Under review" notice
\def\@icmlfirsttime{0}  % This disables the anonymization
\makeatother

% \floatsetup[table]{capposition=top}

% testing for fixing the figures
\setlength{\intextsep}{12pt}

\tcbuselibrary{breakable, skins} % For tcolorbox breakable algorithms

\newcommand{\cmark}{\ding{51}} % check mark
\newcommand{\xmark}{\ding{55}} % cross mark

\input{maths-basic}   % Extra math
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\definecolor{mygray}{RGB}{240,240,240}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Bridging Simulation-Based Inference and Bayesian Optimal Experimental Design}

\begin{document}

\twocolumn[
\icmltitle{Optimizing Likelihoods via Mutual Information: Bridging \\
            Simulation-Based Inference and Bayesian Optimal Experimental Design}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Vincent D. Zaballa}{yyy}
\icmlauthor{Elliot E. Hui}{yyy}
%\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Department of Biomedical Engineering, University of California Irvine, Irvine, CA, USA}

\icmlcorrespondingauthor{Vincent D. Zaballa}{vzaballa@uci.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Simulation-based inference (SBI) is a method to perform inference on a variety of complex scientific models with challenging inference (inverse) problems. Bayesian Optimal Experimental Design (BOED) aims to efficiently use experimental resources to make better inferences. Various stochastic gradient-based BOED methods have been proposed as an alternative to Bayesian optimization and other experimental design heuristics to maximize information gain from an experiment. We demonstrate a link via mutual information bounds between SBI and stochastic gradient-based variational inference methods that permits BOED to be used in SBI applications as SBI-BOED. This link allows simultaneous optimization of experimental designs and optimization of amortized inference functions. We evaluate the pitfalls of naive design optimization using this method in a standard SBI task and demonstrate the utility of a well-chosen design distribution in BOED. We compare this approach on SBI-based models in real-world simulators in epidemiology and biology, showing notable improvements in inference.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}

Many scientific models are defined by a simulator that defines an output $y$ determined by the inputs, or designs, $\xi$, to a system, and parameters that define how the scientific model transforms the inputs to outputs, $\theta$. Inferring a posterior distribution of model parameters given data $p(\theta | y)$ is of central importance in Bayesian statistics and can be seen as a form of solving an inverse problem for a given simulator \citep{lindley1972}. In SBI, a simulator forms an implicit probability distribution of the likelihood $p(y|\theta)$ that is used with the prior of the model parameters $p(\theta)$ to infer the posterior distribution of the scientific model parameters given the observed data, $p(\theta | y_o)$. SBI methods aim to infer either the intractable likelihood or posterior using neural density estimators of the likelihood or posterior, or, classifiers to estimate the likelihood-to-evidence ratio, $\frac{p(\theta|y, \xi)}{p(\theta)} = \frac{p(y |\theta, \xi)}{p(y|\xi)} = \frac{p(y, \theta| \xi)}{p(\theta)p(y|\xi)}$ and refer to \citet{cranmer2020frontier} for a review of SBI methods.

Further, experimental data may be costly to collect. In drug development, collecting data is an expensive process that is partially responsible for the great cost associated with bringing new drugs to patients \citep{paul2010improve}. For example, thousands to millions of designs may be employed \textit{per round} of experimentation in a high-throughput screening campaign. Triaging which data points to gather can help reduce the time to develop a new therapy for patients. It is therefore important to prioritize collection of observed data $y_o$, using optimal designs $y_o|\xi^*$, to arrive at an accurate, but not overconfident, inference of model parameters to make predictions of future responses, such as the likelihood of successful drug treatment.

Meanwhile, Bayesian optimal experimental design (BOED) has shown promise as a method for optimizing experiments, even when dealing with potentially high-dimensional design spaces. This is achieved by employing a likelihood model, where a simulator generates samples as an implicit likelihood in the case of SBI, along with priors for the parameters of interest \citep{lindley1956,Foster2019, kleinegesse2019efficient}. BOED operates by assessing the information gain that a given experimental design provides regarding parameters of a scientific model of interest. The information gain can only be evaluated after an experiment but \citet{lindley1956} defined the Expected Information Gain (EIG), $I(\xi)$, as the difference of entropy, $H$, of the prior to posterior as
\begin{equation}
    I(\xi) \triangleq \E_{p(y|\xi)}\left[ H[p(\theta)] - H[p(\theta|y,\xi)] \right].
\end{equation}
The EIG  can be used as an approximation for the information gained in an experiment with design $\xi$. The intuition behind this process is that we must ask ourselves, which experimental design and outcome would be most surprising given what we assume about the model when conducting the experiment? This would be the optimal experimental design and can be rewritten into the form of calculating the mutual information (MI), where $\text{MI}(\theta;y|\xi) = \mi(\xi)$, between the observed data and unknown parameters as the ratio of likelihood to marginal likelihood or posterior to prior
\begin{align}
\begin{split}
    \text{MI}(\theta;y|\xi) & = \expect_{p(\theta)p(y|\theta,\xi)}\left[\log \frac{p(y|\theta,\xi)}{p(y|\xi)} \right] \\
    & = \expect_{p(\theta)p(y|\theta,\xi)}\left[\log \frac{p(\theta| y,\xi)}{p(\theta)} \right].
    \label{eq:infoGain}
\end{split}
\end{align}

Previous BOED work focused on estimating the MI as an objective function within an outer optimizer, such as Bayesian optimization, which results in a nested optimization process \citep{rainforth2018nestingmontecarloestimators, Kleinegesse2020b, Foster2019}. This nested optimization can be inefficient, which lead to methods to simultaneously optimize the design and MI in a single optimization process \citep{Foster2019a}. However, this unified optimization depended on an \textit{explicit} likelihood or an implicit likelihood with a \textit{differentiable} simulator \citep{Kleinegesse2021,ivanova2021implicit}, which is not available for many simulators in SBI.

Beginning with the similarity between \cref{eq:infoGain} and SBI objective functions, we demonstrate a connection between BOED and SBI that uses either a surrogate of the likelihood, posterior, or the likelihood-to-evidence ratio through MI. We theoretically show how each type of SBI method can be optimized by maximizing the lower bound of MI shown in \eqref{eq:infoGain}. We then show, theoretically and experimentally, how likelihood-based methods can be trained by maximizing the InfoNCE lower bound of MI \citep{oord2019representation}, introducing a modified InfoNCE MI lower bound known as $I_{\text{NCE-}\lambda}$. Thus, we demonstrate how to simultaneously optimize an inference object for SBI while optimizing experimental designs, showing improvements over previous state of the art methods and allowing SBI methods to benefit from BOED.

While BOED methods are concerned with maximizing information gain of an experiment, many BOED methods do not consider the calibration or intermediate results of their resulting inference objects. This is a critical theme in SBI raised in \cite{hermanscrisis} where a SBI method aims to avoid producing overconfident or conservative posterior inferences. This is important in BOED as some methods may choose to split design optimization and inference objects between a design policy and critic, respectively. We therefore examine metrics of calibration and accuracy during BOED evaluation in our proposed method and against benchmark methods. We also examine how changing the $\lambda$ parameter within $I_{\text{NCE-}\lambda}$ influences EIG, calibration, and accuracy of posterior predictive distribution predictions.

In bridging BOED and SBI, our key contributions are:
\begin{itemize}
    \item \textbf{Novel MI Bound for Improved Inference}: We introduce and analyze $I_{\text{NCE-}\lambda}$, a new MI bound, providing theoretical insights and empirical results that highlight its impact on calibration and predictive accuracy.
    \item \textbf{Practical Optimization for Implicit Likelihoods}: We propose a robust method to simultaneously optimize experimental designs and MI for SBI models without requiring a differentiable simulator. To address the limitations of naive gradient-based design optimization, we leverage a design \textit{distribution}, significantly improving performance in non-differentiable settings.
    \item \textbf{State-of-the-Art Calibration and Accuracy}: Our approach achieves superior results in calibration and predictive accuracy compared to benchmark BOED methods, demonstrating its practical utility and setting a new standard for methods in this domain.
\end{itemize}

% \textbf{Contributions} \hspace{0.5em} In bridging BOED and SBI methods, we:
% \begin{itemize}
%     \item We theoretically and experimentally analyze the effect of regularization in our novel MI bound, $I_{\text{NCE-}\lambda}$, on subsequent calibration and predictive accuracy.
%     \item Present a practical method to simultaneously optimize designs and the MI for SBI models \textit{without} a differentiable simulator. Notably, naive optimization of reparameterized experimental design gradients performs poorly when simultaneously optimizing an implicit likelihood; therefore, we introduce a design \textit{distribution} to optimize over showing improvements over naive gradient-based design optimization.
%     \item Show state of the art results on calibration and predictive accuracy compared to previous standard methods from the BOED field where applicable.
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Background %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background}
\label{sec:background}

\subsection{Simulation-Based Inference}

In many scientific disciplines, it is desirable to infer a distribution of parameters $\theta$, of a potentially stochastic model, or simulator, given observations, $y_o$. The closed-box simulator may depend on random numbers $z$, such as in stochastic differential equations, and previous experimental designs $\xi$, such that the simulator takes the form $y = g(\theta, \xi, z)$, or, may simply be simulated by non-differentiable operations. When a likelihood is not available, Approximate Bayesian Computation (ABC) methods can be used, which aims to create a surrogate of the likelihood function \citep{sisson2018overview}. Recent deep-learning based SBI methods have outperformed ABC in many inference tasks \cite{lueckmann2021benchmarking}. Using a simulator to simulate the joint data distribution $(\theta, y) \sim p(y | \theta)p(\theta)$, using samples drawn from a prior $\theta \sim p(\theta)$, enables us to approximate an amortized likelihood $p_\phi(y | \theta)$ or posterior $p_\phi(\theta | y)$ distribution, which may be referred to as a \textit{neural density estimator}. This is achieved by training the neural density estimator, such as a normalizing flow parameterized by $\phi$, to fit the observed data $y_o$ by maximum likelihood for the surrogate likelihood or posterior density \citep{Papamakarios2019}. Another SBI approach involves obtaining the likelihood-to-evidence ratio $\exp f_\phi (\theta, y) \approx \frac{p(y|\theta)}{p(y)}$ by training a classifier to differentiate parameters used in simulating observed values $y$ from the joint distribution or the product of marginals, $p(\theta)p(y)$. Different SBI methods can be used in inference for downstream applications depending on the desiderata of the inference task and have shown varying efficacy in different tasks \citep{lueckmann2021benchmarking}. For example, one might use an amortized posterior approximation if there are many \textit{different} data samples to evaluate, whereas an ensemble of ratios was shown by \citet{hermanscrisis} to perform more robustly on Simulation-Based Calibration (SBC) tests \citep{talts2020validating} at the cost of increased computational complexity.

\textbf{Neural Likelihood Estimation} \hspace{0.5em} We can use data from the joint distribution to train a conditional neural density-based likelihood function (NL). If we take a dataset of samples $\{ y_n, \theta_n \}_{1:N}$ obtained from a simulator as previously described, we can train a conditional density estimator $p_\phi (y|\theta)$ to model the likelihood by maximizing the total log likelihood of $\sum_n \log p_\phi (y_n|\theta_n)$, which is approximately equivalent to minimizing
\begin{equation}
    \mathcal{L}_{\text{NL}}(\phi) = \E_{p(\boldsymbol{\theta})}(D_{\text{KL}} (p(y | \theta ) \| p_\phi (y | \theta) ) + \text{const},
    \label{eq:snl_loss}
\end{equation}
where the Kullback-Leibler divergence is minimized when $p_\phi (y|\theta)$ approaches $p (y | \theta)$.


\subsection{Normalizing Flows}
\label{sec:flows}

Critical to likelihood and posterior-based SBI methods are density estimators, of which normalizing flows are a principled choice \citep{Papamakarios2019, Kobyzev2019}. A density estimator, denoted as $f_\phi(y)$, yields a real-valued output for any given data point across all possible values of $\phi$ that is normalized by design, ensuring a valid probability distribution.
%% TODO: Edit the normalization statement or rearrange in the paragraph
Normalization is enforced by the use of homeomorphisms from a base distribution to a data distribution. Specifically, starting from a known and normalized base distribution, $p(u)$, such as a Gaussian distribution, to the data distribution, $p(y)$, by a composition of nonlinear, monotonic, and invertible functions, $f : \mathbb{R}^D \rightarrow \mathbb{R}^D$, where $f$ is composed of $N$ functions, $f = f_N \circ \dots \circ f_1$. We map from a base distribution to target distribution using the change-of-variables formula as $p(y)  = p(u) \rvert \det J(f)(u) \rvert ^{-1},$ where $J(f)(u)$ is the Jacobian matrix of $f$ evaluated at $u$. A flow can be trained by minimizing the negative log likelihood of data $\{ y_n \}_{n=1}^N$, which is also minimizing the forward KL divergence $D_\text{KL}[p^*(y) ||  p_\phi(y)]$ between a target distribution $p^*(y)$ and the flow model $p_\phi(y)$.

Normalizing flows are also a type of pathwise gradient estimator \citep{mohamed2019monte}. Samples generated from the flow are determined by the function transformation $y \sim p(y | \theta, \xi) \hspace{0.5em} \Longleftrightarrow \hspace{0.5em} y = f^{-1}(u; \theta, \xi)$, where $u \sim p(u)$ and $p(u)$ is the base noise distribution used to train the normalizing flow and can be used in variational inference \citep{rezende2015variational}. \citet{durka2019} proposed Neural Spline Flow (NSF) that can be adapted for conditional estimation by parameterizing its polynomial spline bijectors with neural networks dependent on the data, $y$, as well as any information one may wish to include, such as $\theta \sim p(\theta)$ in the SBI setting. Now, the normalizing flow is trained on data from the joint distribution $(y, \theta)$ and can return the conditional distribution $p_\phi (\theta | y)$ or $p_\phi (y | \theta)$.

\subsection{Bayesian Optimal Experimental Design}

\textbf{InfoNCE Bound} \hspace{0.5em} Following from Equation \ref{eq:infoGain}, \citet{ivanova2021implicit} proposed a lower bound of the MI based on the InfoNCE bound using an implicit likelihood with a differentiable simulator. They trained a design policy network $\pi_\psi$ that proposed designs based on the history of design-observation pairs, $h_{t-1} = \{(\xi_i, y_i)\}_{i=1:t-1}$ and a critic network $U_\phi$ that encapsulates the true likelihood when it maximizes the lower bound of MI. We adjust the bound to reflect the myopic experimental design setting (ignoring the design policy) and reformulate the bound as
\begin{equation}
    \label{eq:InfoNCE_objective}
    \mathcal{L}_\text{NCE}(\xi, \phi; L) \coloneqq \E \left[ \log \frac{\exp(U_\phi(y, \xi, \theta_0))} {\frac{1}{L+1}\sum_{i=0}^L \exp(U_\phi(y, \xi, \theta_i))} \right], % \leq \sEIG{\policy}
\end{equation}
where the expectation is over ${p(\theta_0)p(y|\theta_0, \xi)p(\theta_{1:L})}$, $\xi$ is the proposed design, $\theta_0$ is the original parameter that generated data $y$, generated from the differentiable simulator $p(y|\theta_0, \xi)$, $L$ is the number of contrastive samples, and $U$ is a ``critic'' function such that $U\!:\!(y, \xi) \!\times\! \Theta \!\rightarrow\! \R$. This bound has low variance but is upper-bounded by $\log (L + 1)$, potentially leading to large bias with insufficient contrastive samples. Additionally, previous work required a differentiable simulator to take gradients with respect to the inputs of the simulator, which may not be available in SBI settings.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% SBI-BOED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{SBI-BOED}
\label{sec:method}

We begin by noting the similarity in the different types of SBI and forms of MI from Equation \eqref{eq:infoGain} used in BOED. Indeed, each form of SBI can be cast in the MI framework. We show the relation between MI and SBI using generative models, which also allows for gradient-based optimization of non-differentiable simulators inputs. 

\subsection{Bridging SBI and BOED}

We take inspiration from previous SBI and BOED methods to allow optimization of designs with respect to closed-box simulators that are modeled using normalizing flows. We start by noting how the loss function of contrastive ratio estimation (CRE) lower bounds \cref{eq:InfoNCE_objective} 
\begin{equation}
\begin{aligned}
    \log \frac{\exp( g_\phi (\theta_0, y) )}{ \frac{1}{L} \sum_{\ell=1}^L \exp ( g_\phi (\theta_{\ell}, y))} 
    &\leq \log \frac{\exp( g_\phi (\theta_0, y) )}{ \frac{1}{1 + L} \sum_{\ell=0}^L \exp ( g_\phi (\theta_{\ell}, y))} \\[8pt]
    &\hspace{-3em}= \log \frac{ p_\phi (y | \theta_0, \xi)}{\frac{1}{1 + L}\sum^L_{\ell = 0} p_\phi (y | \theta_l, \xi)},
\end{aligned}
\end{equation}

where $L$ is the number of contrastive samples, which is $K$ in CRE, and $g_\phi$ is a discriminative classifier, which holds for a single batch of data and constant experimental design, i.e. when $\xi$ is constant. We use a neural density estimator to create a Likelihood-Free version of \cref{eq:InfoNCE_objective}. We now have a MI lower bound
\begin{equation}
    \mathcal{L}_{\text{NCE}}(\xi, \phi; L) \coloneqq \E \Bigg[\log \frac{ p_{\phi}(y | \theta_0, \xi)}{\frac{1}{1 + L}\sum^L_{\ell = 0} p_{\phi}(y | \theta_l, \xi)}  \Bigg]
    \label{eq:lf_pce}
\end{equation}
where the expectation is over $p(\theta_0)p(y|\theta_0, \xi)p(\theta_{1:L})$. We can now simultaneously optimize designs and parameters of a neural density estimator. If we are to use a normalizing flow instead of a classifier as $\exp g_\phi(y, \theta, \xi) = p_\phi(y|\theta, \xi)$, then the lower bound of the MI holds since normalizing flows are normalized probability distribution functions. The result is an amortized likelihood at a potentially optimal experimental design.  We discuss more SBI methods and their connection to MI optimization and BOED in \cref{sec:SBI+MI}.

Finally, using a generative model such as a normalizing flow or diffusion model \citep{song2019understanding, ho2020denoising} trained with a maximum likelihood lower bound \citep{song2021maximum} allows for gradients to be taken with respect to input designs in any automatic differentiation framework \citep{jax2018github} by using a pathwise gradient estimator. Given this connection, we state our main theorem.

\begin{theorem}\label{thm:mi_max_sbi}
Maximizing the lower bound of the Mutual Information (MI) between parameters $\theta$ and observations $y$ in a Simulation-Based Inference (SBI) setting is equivalent to minimizing the Kullback-Leibler (KL) divergence, $D_{\text{KL}}(p(y | \boldsymbol{\theta}) || p_\phi(y | \boldsymbol{\theta}))$, between the likelihood $p(y | \boldsymbol{\theta})$ and its approximation $p_\phi(y | \boldsymbol{\theta})$, and the marginal likelihood $p(y)$ and its approximation $p_\phi(y)$ given as
\begin{align}
\begin{split}
    \max_{\phi} \mi_{\phi}(\theta ; y) \Leftrightarrow &\min_{\phi} \big[ \E_{p(\theta)} D_{KL}(p(y | \theta) || p_\phi(y | \theta)) \\
    &+ \E_{p(y)} D_{KL} (p(y) || p_\phi(y) ) \big],
\end{split}
\end{align}
where $\mi(\theta ; y)$ is the mutual information between $\theta$ and $y$, and $\mi_{\phi}(\theta ; y )$ is its approximation under parameter $\phi$.
\end{theorem}

More details and full proof of this theorem are in \cref{sec:MI_likelihood_proof}.

\subsection{Optimizing SBI-BOED}
\label{sec:optimizing_sbi_boed}

\textbf{Regularization} \hspace{0.5em} Stability of the density estimator is a challenge when optimizing the MI lower bound due to data distribution shift as a result of changing $p(y|\theta,\xi)$ when optimizing $\xi$. To address this, we added a regularization term, $\lambda$, to help stabilize the training of the density estimator during design optimization as
\begin{equation}
\begin{split}
    \mathcal{L}_{\text{NCE-}\lambda}(\xi, \phi; L) \coloneqq & \E \Bigg[\log \frac{ p_{\phi}(y | \theta_0, \xi)}{\frac{1}{1 + L}\sum^L_{\ell = 0} p_{\phi}(y | \theta_l, \xi)} \\
    &+ \lambda \cdot \log p_{\phi}(y | \theta_0, \xi)  \Bigg].
\end{split}    
\label{eq:lamb_lf_pce}
\end{equation}
where the expectation is over $p(\theta_0)p(y|\theta_0, \xi)p(\theta_{1:L})$. This regularization parameter gives more importance to accuracy of likelihood predictions when training where we provide theoretical analysis in \cref{sec:lambda_grads}.

\begin{algorithm}[tb]
\caption{SBI-BOED}
\label{alg:sbi-boed}
\begin{algorithmic}[1]
\REQUIRE Simulator $p(y|\theta, \xi)$, Estimator $p_\phi(y|\theta, \xi)$,\\
         Number of experimental designs $T$,\\
         Number of BOED training steps $N$
\RETURN Optimal designs $ \{\xi^*_i \mid i = 1, \ldots, T\} $,\\
        Approximate likelihood $p_{\phi}(y|\theta, \xi_T^*)$
\STATE Initialize $\hat{p}_{0,0}(\theta) \gets p(\theta)$
\FOR{$t=1,\ldots,T$}
    \STATE Sample $\theta_{0:L} \sim \hat{p}_{t-1,0}(\theta)$
    % \STATE (Optional) Pre-training of $p_\phi(y|\theta, \xi)$
    \FOR{$n=1,\ldots,N$}
        \STATE Sample $\xi \sim \mathcal{N}_{\text{trunc}}(\mu_\xi \mid \sigma_n^2)$
        \STATE Simulate $y \sim p(y|\theta, \xi)$
        \STATE Estimate $\nabla \mathcal{L}_{\text{NCE}-\lambda}(\xi, \phi; L)$ via \cref{eq:lamb_lf_pce}
        \STATE Update $\mu_\xi$ and $\phi$ using $\nabla_\xi$ and $\nabla_\phi$
        \STATE Checkpoint $\xi^* = \xi$ \textbf{if} $EIG_\xi > EIG_{\xi^*}$
        % \IF{$EIG_\xi > EIG_{\xi^*}$}
        %     \STATE $\xi^* \leftarrow \xi$
        % \ENDIF
    \ENDFOR
    \STATE Observe $y_o$ using $\xi^*$ in an experiment
\ENDFOR
\end{algorithmic}
\end{algorithm}

\textbf{Regularized Mutual Information Estimator} \hspace{0.5em} We integrate the regularization term $\lambda$ into a mutual information estimator and propose the InfoNCE-$\lambda$ objective
\begin{equation} 
    I_{\text{NCE-}\lambda}(\phi, \lambda) \coloneqq \E_{p(\theta, y | \xi)} \left[ \log \frac{p_\phi(y|\theta, \xi)^{1+\lambda}}{\frac{1}{1 + L}\sum^L_{\ell = 0} p_{\phi}(y | \theta_l, \xi)} \right]. 
    \label{eq:info_nce_lambda}
\end{equation} 
This formulation scales the likelihood term $p_{\phi}(y | \theta)$ with the regularization parameter $\lambda$. We provide a more thorough theoretical analysis of the influence of $\lambda$ on design optimization and predictive accuracy in \cref{sec:lambda_grads}. Finally, while the bound on $I_{\text{NCE}}$ is $\log(L+1)$, we show in \cref{sec:lambda_bound} that a tighter bound incorporating the entropy term exists: $I_{\text{NCE-}\lambda} \leq \log(L + 1) - \lambda \E_{p(\theta)} H(y|\theta, \xi)$.

\textbf{Design Distributions} \hspace{0.5em} A drawback of gradient-based methods is when there are sparse rewards, such as when the signal to noise ratio is, or approaches, zero. This results in designs struggling to optimize by gradient descent because optimizers may not be able to handle starting, or residing, in areas with no information.  We demonstrate this failing in an ablation study in Section \ref{sec:SIR_model} and take inspiration from Reinforcement Learning's (RL) use of a replay buffer \citep{lin1992self, mnih2013playing} by imposing a parameterized distribution of designs and optimizing parameters of that distribution to return more information. 


When using design distributions, we compute the EIG for each individual observation $y_i$ associated with design $\xi_i$ and corresponding to the nominal parameter set $\theta_0$. In our usage, $\text{EIG}_i$ refers to the theoretical information gain expected from a single sample realization under design $\xi_i$, based on the current parameterization of the likelihood. It quantifies the information gain computed from a possible outcome as 
\begin{equation}
    \text{EIG}_i(\psi, \phi, L, \lambda) = \E \Bigg[\log \frac{ p_{\phi}(y_i | \theta_{0}, \xi_i)^{1 + \lambda}}{\frac{1}{1 + L}\sum^L_{\ell = 0} p_{\phi}(y_i | \theta_{l}, \xi_i)}\Bigg],
\end{equation}
with expectation over $p_\psi(\xi)p(\theta_0)p(y|\theta_0, \xi)p(\theta_{1:L})$ and where the parameter of the design distribution $\psi$ is optimized rather than the designs themselves.

We used a truncated Normal distribution for the design parameters, defined as $p_\psi(\xi) = \mathcal{N}_{\text{trunc}}(\mu_\xi| \sigma_n^2)$, where $\mathcal{N}_{\text{trunc}}$ denotes a Normal distribution truncated within the bounds $[\alpha, \beta]$, and $\alpha$ and $\beta$ are the lower and upper bounds, respectively, and $\sigma$ that uses a decays schedule depending on the training round, $n$. Whenever the rewards are sparse, if the design distribution is initialized with sufficient support then it will contain an EIG with significantly more reward that can be updated with gradient descent.  In our implementation, we used the reparameterization trick and a standard deviation schedule for $\sigma$ that decreased according to an exponential schedule $\sigma_n = \sigma_{\text{end}} + (\sigma_{\text{start}} - \sigma_{\text{end}}) \cdot e^{-\frac{n*\rho}{N}}$, where $\sigma_n$ is the new standard deviation for the Normal distribution that parameterizes $\xi$ in training round $n$, $\sigma_{start}$ and $\sigma_{end}$ are hyperparameters for the initial and final variances respectively, $N$ is the total number of rounds, and $\rho$ is a decay rate hyperparameter. 


\textbf{Design Checkpoints} \hspace{0.5em} Checkpoints are used in supervised learning to save parameters that achieved low validation error \citep{vaswani2017attention, devlin2019bert}. \citet{fujimoto2023sale} proposed the use of checkpoints in RL applications to save a policy that obtains a high reward during training to help improve performance at test time. Even with a distribution of designs, we found designs falling into a local minima during optimization, such as in \cref{sec:design_dist_appendix}. We used design checkpoints to mitigate the risk of gradient-based designs falling into local minima that do not contain sufficient support to encapsulate the global minimum loss. 

\textbf{Posterior Inference} \hspace{0.5em} The likelihood trained on the optimized design can return approximate posterior samples by sampling $\hat{p}(\theta | y, \xi) \propto p_\phi (y | \theta, \xi) p(\theta)$. Should the likelihood be trained on i.i.d. data, then the joint factorizes to product likelihood $\p{y_{1, \dots, N}|\theta, \xi_{1, \dots, N}} = \prod_{i=0}^N p(y_i|\theta, \xi_i)$ which can be used in Markov chain Monte Carlo (MCMC) to draw posterior samples.

% \textbf{Likelihood Pretraining} Some simulators present a challenge in the efficiency of generation of new simulations to train a surrogate likelihood, such as the experiment in \cref{sec:BMP_model}. We found pretraining the likelihood on a distribution of designs helped to improve design optimization and predictions in this model. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Related Work %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
\label{sec:related_work}

In BOED, we focus on the setting of myopic gradient-based experimental design. Previously, \citet{Foster2019} proposed various likelihood-free information bounds that could work in the SBI setting based on variational inference estimators but did not make use of a normalized generative model like a normalizing flow. This is problematic for use in sequential SBI methods that make use of a normalized likelihood or posterior functions. \citet{Kleinegesse2020b} developed MINEBED to simultaneously optimize experimental designs and a critic that could draw samples from the posterior, but relied on a differentiable simulator or using Bayesian Optimization. \citet{ivanova2021implicit} extended both previous works and developed policy-based experimental designs for non-myopic experimental designs, but whose critics also relied on differentiable simulators - simulators whose inputs can be connected to a differentiable computation graph, which may not be available for scientific simulators. A RL approach \citep{lim2022policybased} optimized a critic without requiring a differentiable simulator but relies on computationally expensive RL algorithms and may not be feasible for practitioners with scientific simulators that can take significant amount of time to simulate. This is exemplified in our biological experiment where each round of simulation takes about ten seconds. 

Recent work connecting SBI methods to MI-based optimization studied how to stably train a discriminative and generative SBI model \citep{miller2023simulation}, and applying a nonparametric function to the selection of data points to reduce variance of the resulting MI estimate \citep{glaser2022maximum}. These methods take a complimentary approach to ours but require a generative and discriminative model whereas we only require a generative model. Additionally, we study the utility of MI-based optimization of SBI models in BOED.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Experiments %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[!t]
  \centering
  \includegraphics[width=\textwidth]{figs/two_moons_sweep2.png}
  \vspace{-9pt}
  \caption{Comparison on the Two Moons task of the EIG and the validation loss $-\E \log p_\phi(y | \theta)$ across varying number of contrastive samples ($L = N - 1$) and $\lambda$ regularization. Increasing number of contrastive samples improves the information lower bound and likelihood validation metrics.  The $\lambda$ parameter helps improve the likelihood accuracy at the expense of MI estimation.
  } % We include a reference MI calculation for the single design scenario which is detailed in Appendix D. 
  \label{fig:two_moons}
  \vspace{-12pt}
\end{figure*}

\section{Experiments}
\label{sec:experiments}

We evaluate SBI-BOED in one SBI task and three experimental design tasks, two where the designs are i.i.d. and another that is time-dependent. We first evaluate the MI lower bound estimation performance in high-dimensional design spaces in a simple linear model to understand the performance of SBI-BOED as it scales with the number of design dimensions and to evaluate the importance of regularization. We then evaluate SBI-BOED on sequential design tasks in both a time-dependent and i.i.d. setting, and benchmark against comparable methods. MINEBED-BO is a technique for estimating the MI using a neural network and then using Bayesian optimization to optimize designs \citep{Kleinegesse2020b}. We compare against iDAD \citep{ivanova2021implicit} and differentiable MINEBED \citep{Kleinegesse2021} in the myopic design setting of a single experimental design to compare with SBI-BOED methods. In all experiments we compare all models to a measure of MI lower bound, the Expected Information Gain (EIG), a visual analysis of posterior samples drawn by the No-U-Turn Sampler method of MCMC sampling, and the L-C2ST metric of local evaluation of the posterior given an observed data point $y_o$ \citep{linhart2023lc2stlocaldiagnosticsposterior}. To the best of our knowledge, the L-C2ST metric is the only quantitative assessment of the calibration of an inference model. We also show SBC plots for our methods but the L-C2ST provides an easier comparison among models by indicating whether the observed data point is generated by the posterior of the model of interest.  All experiment details, such as hyperparameters, can be found in \cref{sec:hyperparame}.

\subsection{Evaluation of the MI on Two Moons}
\label{sec:two_moons}

We first study how well our amortized generative model performs in the non-experimental design setting. This is to gain insight into the tradeoffs between regularization of the objective in \cref{eq:lamb_lf_pce} and choice of the number of contrastive parameters $L$ in the \cref{eq:InfoNCE_objective}. As noted by \citet{miller_contrastive_2022, glaser2022maximum} when optimizing the MI between $y$ and $\theta$ there is a decrease in the validation accuracy, $\E \log p_\phi(y | \theta)$. We investigate the effect of $\lambda$ regularization in the objective \cref{eq:lamb_lf_pce} on the information gained, as measured by the EIG, and the validation log probability. The resulting sweep can be seen in \cref{fig:two_moons}. Increasing the number of contrastive parameters both helps to improve the information gained and the validation loss. We note that optimization using the \cref{eq:InfoNCE_objective} and the parameters we chose did not ameliorate the known issue of mode collapse of likelihood-based functions in the two moons task as shown by \citet{greenberg2019automatic}. We show an example in \cref{sec:two_moons_reloaded}.

\begin{figure*}[htb]
  \centering
  \includegraphics[width=\textwidth]{figs/linear_eig_new.pdf}
  \vspace{-13pt}
  \caption{Comparison of the EIG across design dimensions, type of BOED, and $\lambda$ regularization for the noisy linear model examining the moving average over 10 different random seed initializations. For the single design dimension, all SBI-BOED regularizaiton levels generally similar, with the non-regularized version being the closest to the optimal MI bound. In the higher-dimension design cases, SBI-BOED increases its EIG with more designs. In the 100-dimensional design case, we see the benefit of using $\lambda$ regularization to stabilize the training of a design-dependent normalizing flow in high-dimensional input space at the cost of slightly lower EIG.
  } % We include a reference MI calculation for the single design scenario which is detailed in Appendix D. 
  \label{fig:linear_eig}
  \vspace{-12pt}
\end{figure*}

\subsection{Noisy Linear Model}

In our first BOED task, we evaluate how SBI-BOED performs on the EIG metric with increasing design dimensions. We follow \citet{Kleinegesse2020b} and evaluate optimal designs on a noisy linear model where a response variable $y$ has a linear relationship with experimental designs $\xi$, which is determined by values of the model parameters $\boldsymbol{\theta} = [\theta_0, \theta_1]$, which model the offset and gradient. We would like to optimize the value of $D$ measurements to estimate the posterior of $\boldsymbol{\theta}$, and so create a design vector $\boldsymbol{\xi} = [\xi_1, \dots, \xi_D]^{\mathsf{T}}$.  Each design, $\xi_i$ returns a measurement $y_i$, which results in the data vector $\boldsymbol{y} = [y_1, \dots, y_D]^{\mathsf{T}}$. We use a Gaussian noise source $\mathcal{N}(\epsilon; 0, 1)$ and Gamma noise source $\Gamma (\nu; 2, 2)$. The model is then 
\begin{equation}
    \boldsymbol{y} = \theta_0\boldsymbol{1} + \theta_1 * \boldsymbol{\xi} + \boldsymbol{\epsilon} + \boldsymbol{\nu},
\end{equation}
where $\boldsymbol{\epsilon} = [\epsilon_1, \dots, \epsilon_D]^{\mathsf{T}}$ and $\boldsymbol{\nu} = [\nu_1, \dots, \nu_D]^{\mathsf{T}}$ are i.i.d. samples. We used a prior distribution on model parameters as $p(\boldsymbol{\theta}) = \mathcal{N}(\boldsymbol{\theta} ; 0, 3^2)$.  We evaluate SBI-BOED, \textit{purely using design gradients and no distribution over designs}, to examine how changing the $\lambda$ regularization parameter in \cref{eq:lamb_lf_pce} influences the resulting MI bound and design optimization stability with increasing design dimension.

For all design dimensions, we randomly initialize designs $\xi \in [-10, 10]$. For SBI-BOED, we chose $N=10$, the number of batch samples $\boldsymbol{y} \sim p(\boldsymbol{y}|\theta_0, \boldsymbol{\xi})$, and $L=50$ contrastive samples. We used a neural spline flow with training details in \cref{sec:hyperparame}.
We show the plots of the EIG in \cref{fig:linear_eig}, where we can see that SBI-BOED optimizes a lower bound of MI, which increases for higher design dimensions. This corresponds with intuition that gathering more data results in more information. Similar to the two moons task, we see how the choice of $\lambda$ influences the stability of MI estimation for SBI-BOED in high design dimensions where there seems to be a tradeoff with choice of regularization and MI estimation. This may be due to regularization limiting gradient updates of designs that lead to out of distribution data distributions, but is balanced by the stability in the training objective.



\subsection{SIR Model}
\label{sec:SIR_model}

We next evaluate the performance of SBI-BOED with different amounts of regularization on a real-world implicit likelihood model that has a differentiable simulator as a comparison to alternative methods. We use the Susceptible, Infected, or Recovered (SIR) epidemiology model specified in \citet{ivanova2021implicit}. The SIR model represents a fixed population that has three groups: susceptible, infected, and recovered. Individuals transition from susceptible to infected with a parameter $\beta$ and from infected to recovered with parameter $\gamma$. Therefore, the model parameters are $\theta \coloneqq [\beta, \gamma]$ and the design space $\Xi$, consists of a time $\kappa$ to measure individuals to infer parameters $\theta$. We measured the EIG, L-C2ST, and median distance from the observed data point to samples generated by the final posterior distribution.

\begin{table*}[h]
\centering
\small
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.1}
\caption{SIR (Section \ref{sec:SIR_model}) and BMP (Section \ref{sec:BMP_model}) results: comparison of EIG, L-C2ST, and median distance (Med.) on five BOED methods for two tasks with T=2 experimental design rounds for the SIR model and T=3 for the BMP model. We used the same number of contrastive samples for iDAD and MINEBED as with SBI-BOED and report mean and standard error of results over 3 experiments using different seeds.}
\vspace{-6pt}
\label{tab:exp_compare_expanded}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}l*{6}{c}}
    \toprule
    \multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c}{\textbf{SIR (T=2)}} & \multicolumn{3}{c}{\textbf{BMP (T=3)}} \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7}
    & EIG $(\uparrow)$ & L-C2ST $(\downarrow)$ & Med. $(\downarrow)$ & EIG $(\uparrow)$ & L-C2ST $(\downarrow)$ & Med. $(\downarrow)$ \\
    \midrule
    MINEBED(-BO)                & \textbf{2.69 $\pm$ 0.03} & 0.07 $\pm$ 0.05 & 71.26 $\pm$ 5.66 & 9.05 $\pm$ 0.20 & 0.23 $\pm$ 0.01 & 0.87 $\pm$ 0.08 \\
    iDAD (InfoNCE)              & 2.67 $\pm$ 0.02 & 0.10 $\pm$ 0.04 & 71.65 $\pm$ 2.78 & N/A & N/A & N/A \\
    SBI-BOED ($\lambda = 1$)    & 1.01 $\pm$ 0.03  & 0.05 $\pm$ 0.01 & 47.99 $\pm$ 2.62 & \textbf{10.39 $\pm$ 0.01} & 0.002 $\pm$ 0.002 & 0.61 $\pm$ 0.01 \\
    SBI-BOED ($\lambda = 0.1$)  & 1.47 $\pm$ 0.23  & \textbf{0.03 $\pm$ 0.01} & \textbf{46.85 $\pm$ 3.21} & 10.38 $\pm$ 0.01 & \textbf{0.001 $\pm$ 0.001} & \textbf{0.60 $\pm$ 0.01} \\
    SBI-BOED ($\lambda = 0.01$) & 1.63 $\pm$ 0.23  & 0.04 $\pm$ 0.02 & 52.85 $\pm$ 0.70 & 10.39 $\pm$ 0.01 & 0.004 $\pm$ 0.002 & 0.61 $\pm$ 0.01 \\
    \bottomrule
\end{tabular*}
\vspace{-9pt}
\end{table*}

\cref{tab:exp_compare_expanded} summarizes the results. We find that iDAD and differentiable MINEBED achieve the best information gain, likely thanks to using differentiability of the simulator, but perform worse than SBI-BOED on L-C2ST and median distance metrics. This may indicate the learned critic is not as accurate as the amortized likelihood trained in SBI-BOED. Among SBI-BOED methods, we see that more regularization generally leads to improved median distance, and all perform rouglhy the same on calibration. Thus, improved information gain \textit{does not} necessarily correlate with improved downstream prediction, as measured by the median distance metric. This highlights an important caveat to BOED methods that we should not rely on a single metric and holistically assess the resulting inference model in terms of accuracy and calibration before making decisions (performing experiments). We find that the posterior estimates are generally consistent with the ground truth. We show an example posterior form our method in \cref{sec:boed_reloaded} with ground truth parameters $\theta = [0.7399, 0.0924]$.


\textbf{Ablation Study} \hspace{0.5em} We compare the performance of SBI-BOED with and without a design distribution when maximizing the EIG in \cref{fig:ablation_study} in the first round of design optimization. The prior used in the SIR model creates a challenge for myopic and local design optimization by introducing regions with little EIG signal, such as the flatter part of the SIR curve shown in \cref{sec:boed_reloaded}. The design distribution overcomes this challenge by querying diverse sets of designs with better gradients to optimize \cref{eq:lamb_lf_pce}.

\begin{figure}[h] % [htbp] option is to position the figure: here, top, bottom, or on a separate page
  \centering
  \vspace{-3pt}
  \includegraphics[width=\columnwidth]{figs/design_dist.pdf}
  \vspace{-23pt}
  \caption{Training (higher is better) without a design distribution in the first round of optimization for the SIR model fails to find designs with high rewards.}
  \label{fig:ablation_study}
  \vspace{-12pt}
\end{figure}

\subsection{Bone Morphogenetic Protein Model}
\label{sec:BMP_model}

The Bone Morphogenetic Protein (BMP) pathway is important in developmental and disease processes. A mass action kinetics model was proposed for the BMP pathway \citep{antebi2017combinatorial}. The one-step model proposed by \citet{su2022ligand} models type I (A) and type II (B) receptors coupling with a ligand (L) to form a trimer complex (T) with equilibrium affinity $K$ in a single step as $A + B + L \autorightleftharpoons{$K$}{} T$. The trimeric complex then phosphorylates SMAD protein to send a downstream gene expression signal, $S$, with a certain efficiency, $\varepsilon$ as $\varepsilon T = S$. Steady-state gene expression signals can be simulated using convex optimization in a closed-box optimization process. Thus, we would like to infer the parameters $K$ and $\varepsilon$  given data, $S$. In the experimental design context, we would like to optimize the ligand concentration, $\boldsymbol{L}^*$, used in an experiment so to gain the most information about the parameters of this model of a biological signaling pathway. The model parameters are $\theta \coloneqq [K, \varepsilon]$ and we use ground truth parameters $\theta = [0.85, 0.85]$. We show an example of the prior predictive equation in \cref{sec:boed_reloaded}. We evaluated a 1D design dimension for the ligand concentration on a uniform range from $10^{-3}\text{ng/mL}$ to $10^{3}\text{ng/mL}$. We compare against the same benchmarks except the iDAD algorithm, which cannot work on this non-differentiable simulator. We train the EIG for 500 steps in each design optimization round because of the expensive simulation time required in each round (about 15 seconds). 

All SBI-BOED design algorithms perform well in this setting, partially due to the bias in larger concentrations containing more information. However, we see that SBI-BOED methods outperform the competing method of MINEBED combined with Bayesian optimization in all metrics. Again, the model with the best EIG does not correspond to the most-calibrated model nor the best accuracy predictions. Given that our models start from an uninformative uniform prior, the posterior in the last round approaches the true value while leaving uncertainty to mitigate overconfidence \cref{sec:boed_reloaded}.

\section{Discussion}
\label{sec:discussion}

We demonstrated the connection between optimizing a lower bound of mutual information typical in BOED settings and optimizing a likelihood from SBI settings. We evaluated the accuracy of the generative model's likelihood approximation on a standard SBI benchmark to show the tradeoff of the number of contrastive samples to the regularization used. We also evaluated the effect of the regularization parameter on BOED tasks to comparable methods keeping contrastive samples constant. Besides regularization, we also presented novel methods to overcome pitfalls in optimizing designs for purely generative models, including using a distribution over designs and design checkpoints. We found that SBI-BOED performed better in predictive accuracy and calibration, and sometimes better in EIG, on a benchmark of comparable BOED methods on two scientific simulators, one that was and one that was not differentiable w.r.t. designs. Thus, we demonstrated the importance of more holistic examination of BOED methods given that a design with greater information gain may not lead to better downstream prediction accuracy. Indeed, metrics such as calibration play important roles in scientific decision-making, and our work highlights the importance of including such measures when designing experiments within BOED methods. This motivates future work to consider calibration and predictive accuracy while optimizing designs.

We used normalizing flows as surrogates for the likelihood but any generative model can be used as a surrogate given that its likelihood, or its bound, can be evaluated. This opens opportunities for BOED to any likelihood-based model used with, for example, diffusion \citep{ho2020denoising, song2020generativemodelingestimatinggradients} or flow-matching, \citep{lipman2023flow} each of which may handle higher-dimensional data better or provide novel opportunities to optimize experiments by increased flexibility of design optimization in the data or noise space \citep{pmlr-v235-ben-hamu24a}. 


\bibliographystyle{abbrvnat}
\bibliography{references}



\appendix
\onecolumn

\section{Mutual Information-Based Likelihood Optimization Derivation \& Proofs}
\label{sec:MI_proofs}

We provide a derivation and proof of how optimizing a lower bound of the mutual information is the same as minimizing the KL divergence in \eqref{eq:snl_loss}. We also discuss alternative BOED bounds and how adding a distribution of designs to the MI approximation keeps it a valid lower bound.

\subsection{Derivation of Optimization of the Mutual Information}
\label{sec:MI_likelihood_proof}

We investigate how optimizing the mutual information within the SBI-BOED loss framework leads to an implicit optimization of the likelihood. Following the approach outlined by \cite{miller_contrastive_2022}, we optimize our approximation to the true likelihood by minimizing the KL divergence:

\begin{equation}
    D_{\text{KL}}(p(y | \theta) || p_\phi(y | \theta)).
\end{equation}

Within the SBI framework, we draw samples of parameters \( \theta \) from the prior \( p(\theta) \) and of data \( y \) conditioned on these parameters from the likelihood \( p(y | \theta) \). This sampling enables us to approximate the expected KL divergence across the parameter space:

\begin{equation}
    \mathbb{E}_{p(\theta)}[D_{\text{KL}}(p(y | \theta) || p_\phi(y | \theta))].
\end{equation}

Now we express the KL divergence as the expectation of the log ratio of probabilities:

\begin{align}
    \mathbb{E}_{p(\theta)}[D_{\text{KL}}(p(y | \theta) || p_\phi(y | \theta))] &= \mathbb{E}_{p(\theta, y)} \left[ \log \frac{p(y|\theta)}{p_\phi(y | \theta)} \right] \\
    &= \mathbb{E}_{p(\theta, y)} \left[ \log \frac{p(y|\theta)}{p(y)} \frac{p(y)}{p_\phi (y|\theta)} \right] \\ 
    &= \mi(\theta ; y) + \mathbb{E}_{p(\theta, y)} \left[ \log \frac{p(y)}{p_\phi(y|\theta)} \right] \\
    &= \mi(\theta ; y) + \mathbb{E}_{p(y)} \left[ \log p(y) \right] - \mathbb{E}_{p(\theta, y)} \left[ \log p_\phi (y | \theta) \right].
\end{align}

Since the KL divergence is always non-negative, the optimization process aims to find the parameters \( \phi \) that minimize this expected divergence (approaches 0), implicitly maximizing the mutual information between parameters.

We now base our proof of \cref{thm:mi_max_sbi} as follows:

\begin{proof}
    Let us consider the MI between random variables $\Theta$ and $Y$, where $y \sim Y$ and $\theta \sim \Theta$, then we have

    \begin{equation}
        \mi(\theta ; y) = \mathbb{E}_{p(\theta, y)} \left[ \log \frac{p(y|\theta)}{p(y)} \right].
    \end{equation}

    In the SBI setting, we would like to approximate the likelihood $p_\phi(y|\theta)$. We can approximate the marginal likelihood by the Strong Law of Large Numbers using $\E_{p(\theta)} \big[ p(y|\theta) \big] = \int_\theta p(y|\theta) p(\theta) d\theta \approx \frac{1}{L} \sum_\ell^L p(y|\theta_\ell )$. The bound gets tighter as $L\rightarrow \infty$ and as the likelihood better-approximates the true likelihood. Assuming we are optimizing the parameters $\phi$ to maximize this objective, then we have

    \begin{align}
        \hat{\phi} &= \underset{\phi}{\arg\max} \; \E_{p(\theta, y)} \left[ \log \frac{p_\phi(y|\theta)}{\hat{p}(y)} \right] \\
        &= \underset{\phi}{\arg\min} \; \left( I(\theta; y) - \E_{p(\theta, y)} \left[ \log \frac{p_\phi(y|\theta)}{\hat{p}(y)} \right] \right) \\
        &= \underset{\phi}{\arg\min} \; \E_{p(\theta, y)} \left[ \log \frac{p(y|\theta)}{p(y)} \frac{\hat{p}(y)}{p_\phi(y|\theta)} \right] \label{lambda_intro_eq} \\
        &\approx \underset{\phi}{\arg\min} \; \left( \E_{p(\theta)}D_{KL}(p(y | \theta) || p_\phi(y | \theta)) - \E_{\hat{p}(y)}D_{KL}(\hat{p}(y) || p(y)) \right) \\
        &= \underset{\phi}{\arg\min} \left( \E_{p(\theta)} D_{KL}(p(y | \theta) || p_\phi(y | \theta)) + \E_{\hat{p}(y)} \left[ \log \hat{p}(y) \right] - \text{const.}\right) \label{mi_kl_combo}
    \end{align}

    where the marginal likelihood is approximated as $\hat{p}(y) = \frac{1}{L}\sum_{i=1}^L p_\phi(y|\theta_i), \quad \theta_i \sim p(\theta)$. Thus, maximizing the InfoNCE bound from \cref{eq:InfoNCE_objective}, returns an optimized likelihood minimizing the same objective in \cref{eq:snl_loss} with an additional penalty on marginal likelihood approximation, which depends on the number of contrastive samples $L$.

\end{proof}

\textit{Remark.} In the BOED setting, the MI is simply conditional on a design, $\xi$, as $\mi(\theta;y|\xi)$ which allows for gradient-based optimization by a pathwise gradient estimator as detailed in \cref{sec:flows}. An interesting insight to this derivation is that InfoNCE bound used to maximize a lower bound of MI may be biased by the reverse KL of the marginal likelihood to models that better represent the data. This may surface in BOED with designs preferring models that do not cover enough of the potential parameter spaces that explain the data.

\subsection{Ensuring a Valid MI Objective with Design Distributions}
\label{sec:design_dist_MI}

One of the main assumptions of this paper is that using a distribution over designs, $p(\xi)$, keeps a valid bound of the MI. The joint density of $y$ and $\xi$  has a density with respect to Lebesgue measure on $\Xi \times \mathcal{Y}$ since 
\begin{equation}
    p(y, \xi | \theta) = p(\xi) p(y | \theta, \xi),
\end{equation}
where $p(\xi)$ represents the Normal distribution, $\mathcal{N}_{t}(\mu_\xi | \sigma^2_n) $ that may depend on the result of the previous round to determine its starting position. Putting a distribution on designs can be seen as using a stochastic policy, similar to noise levels used in RL.  Given the joint distribution of observations and designs, the conditional mutual information \( I(\theta ; y | \xi) \), which quantifies the information about parameters \( \theta \) obtained through observations \( y \), conditioned on designs \( \xi \), remains valid under the distribution \( p(\xi) \). Mathematically, this is represented as:

\begin{equation}
    I(\theta ; y | \xi) = H(y | \xi) - H(y | \theta, \xi)
\end{equation}

provided \( p(\xi) \) is a valid probability distribution, where each individual entropy term is given by

\begin{equation}
H(y | \xi) = -\int_{\mathcal{Y}} \int_{\Xi} p(y, \xi) \log p(y | \xi) d\xi dy,
\end{equation}
and
\begin{equation}
    H(y | \theta, \xi) = -\int_{\mathcal{Y}} \int_{\Theta} \int_{\Xi} p(y, \theta, \xi) \log p(y | \theta, \xi) d\xi d\theta dy.
\end{equation}
This invariance is due to the fact that \( \xi \) serves as a known conditional variable that structures the calculation of mutual information without contributing additional information about \( \theta \) beyond the observed data \( y \). Hence, adding a probability distribution on designs retains a valid measure of MI. While we used a simple tempered design distribution, they can be parameterized with more sophisticated models akin to policy networks in RL and used in BOED by \cite{foster2021deep, ivanova2021implicit}. We leave this for future work.



\section{Theoretical Analysis of SBI-BOED Components}

We provide more theoretical analysis of the impact of the $\lambda$ parameter of $I_{\text{NCE-}\lambda}$ on predictive accuracy, estimating the EIG, and gradients of EIG and normalziing flow model parameters, $\phi$. 

\subsection{Theoretical analysis of the $\lambda$ regularization parameter}
\label{sec:lambda_grads}

We experimentally demonstrated in \cref{sec:two_moons} that the $\lambda$ regularization parameter in SBI-BOED influences both the likelihood's validation accuracy and the EIG bound. We theoretically analyze both scenarios as well as $\lambda$ influence on optimization gradients in the following sections.

\textbf{Influence of $\lambda$ on likelihood prediction accuracy} \hspace{0.5em} Starting from \cref{lambda_intro_eq} of the previous section, including the $\lambda$ regularization parameter results in
\begin{align}
    \hat{\phi} &= \underset{\phi}{\arg\min} \; \E_{p(\theta, y)} \left[ \log \frac{p(y|\theta)}{p(y)} \frac{\hat{p}(y)}{p_\phi(y|\theta)} \right] + \lambda \E_{p(\theta, y)} \log [p_\phi(y | \theta)] \\
    &= \underset{\phi}{\arg\min} \; \E_{p(\theta, y)} \left[ \log \frac{p(y|\theta)}{p(y)} \frac{\hat{p}(y)}{p_\phi(y|\theta)} p_\phi(y | \theta)^{\lambda} \right].
\end{align}

We now focus on the contribution of the added $p_\phi(y | \theta)^{\lambda}$ term grouped with the likelihood's KL divergence from \cref{mi_kl_combo}. Reformulating this term, we express the $\lambda$-regularized KL divergence as
\begin{align}
    D_{\text{KL}}(p(y|\theta) \| p_\phi(y|\theta)^{1-\lambda}) &= \mathbb{E}_{p(y|\theta)} \left[ \log \frac{p(y|\theta)}{p_\phi(y|\theta)^{1-\lambda}} \right] \\
    &= \mathbb{E}_{p(y|\theta)} \left[ \log p(y|\theta) - (1-\lambda) \log p_\phi(y|\theta) \right].
    \label{eq:gradient_phi}
\end{align}

This modified divergence adjusts the weighting of the log-likelihood term \(\log p_\phi(y|\theta)\) based on \(\lambda\). We show how $\lambda$ influences optimization, omitting the trivial case when $\lambda = 0$:
\begin{itemize}
    \item For $\lambda > 0$: The term $(1-\lambda)$ reduces the weight of the approximate likelihood, ensuring broad coverage of the parameter space while emphasizing accuracy.
    \item For $\lambda < 0$: The term $(1-\lambda) > 1$ amplifies the weight of the approximate likelihood, leading to mode-seeking behavior that prioritizes high-probability regions at the expense of the tails.
\end{itemize}

% Experimental evaluation on \cref{fig:two_moons} supports improvement in likelihood accuracy. 

\textbf{Influence of $\lambda$ on the EIG} \hspace{0.5em} We start from \cref{eq:info_nce_lambda} and rephrase it here using the shortened marginal likelihood notation $\hat{p}(y | \xi)$ for convenience
\begin{align}
    \E_{p(\theta, y | \xi)} \left[ \log \frac{p_\phi(y|\theta, \xi)^{1+\lambda}}{\hat{p}(y|\xi)} \right].
\end{align}

Expanding the log ratio, we can separate the contributions of the likelihood and the marginal likelihood
\begin{align}
    \E_{p(\theta, y | \xi)} \left[ \log \frac{p_\phi(y|\theta, \xi)^{1+\lambda}}{\hat{p}(y|\xi)} \right] = \E_{p(\theta, y | \xi)} \left[ (1+\lambda) \log p_\phi(y|\theta, \xi) - \log \hat{p}(y|\xi) \right].
\end{align}

The parameter $\lambda$ influences the scaling of the likelihood term $(1+\lambda) \log p_\phi(y|\theta, \xi)$ and indirectly affects the marginal likelihood $\hat{p}(y|\xi)$ through its dependence on $p_\phi(y|\theta, \xi)$. The EIG linearly depends on the $\lambda$ value. Positive $\lambda$ decrease the EIG estimate while negative values increase the EIG at the expense of likelihood approximation, as previously discussed. The decrease in EIG with increasing $\lambda$ aligns with empirical observations (\cref{fig:two_moons}). 

\textbf{Gradient of the EIG with respect to $\lambda$} \hspace{0.5em} To analyze the dependence of the EIG on $\lambda$, consider the EIG expression:
\begin{equation}
    \text{EIG}(\xi, \phi, L, \lambda) =\E_{p(\theta, y | \xi)} \left[ (1+\lambda) \log p_\phi(y|\theta, \xi) - \log \hat{p}(y|\xi) \right].
\end{equation}
The gradient of the EIG with respect to $\lambda$ is:
\begin{equation}
    \frac{\partial \text{EIG}(\xi, \phi, L, \lambda)}{\partial \lambda} = \E_{p(\theta, y | \xi)} \left[ \log p_\phi(y|\theta, \xi) \right].
\end{equation}
Thus, the rate of change of the EIG is independent of $\lambda$.


\textbf{Gradient of likelihood $\phi$ with respect to $\lambda$} \hspace{0.5em} Incorporating the parameter $\lambda$ in the optimization objective can be expressed as:
\begin{equation}
    \hat{\phi} = \underset{\phi}{\arg\max} \; \E_{p(\theta, y)} \left[ (1+\lambda) \log p_\phi(y|\theta) - \log \hat{p}(y) \right].
\end{equation}
Taking the gradient of this objective with respect to $\phi$ gives:
\begin{equation}
    \nabla_\phi \mathcal{L}(\phi, \lambda) = (1+\lambda) \nabla_\phi \E_{p(\theta, y)} \left[ \log p_\phi(y|\theta) \right] - \nabla_\phi \log \hat{p}(y).
\end{equation}
The term $(1+\lambda)$ scales the gradient contribution of the likelihood term. As $\lambda$ increases, the optimization process places greater emphasis on refining the likelihood approximation $p_\phi(y|\theta)$, improving likelihood accuracy at the cost of mutual information maximization. 

\subsection{Mutual Information Bounds on $I_{\text{NCE}-\lambda}$ }
\label{sec:lambda_bound}

% \subsection{Bounds on the $\lambda$-Regularized Mutual Information}
We analyze how the regularization parameter $\lambda$ influences the mutual information bound. Starting with the InfoNCE-$\lambda$ objective from \cref{eq:info_nce_lambda}, we derive a bound that reveals the relationship between $\lambda$ and the expected conditional entropy of the likelihood:

\begin{align}
    I_{\text{NCE-}\lambda} &= \E_{p(\theta, y | \xi)} \left[ \log \frac{p(y|\theta, \xi)^{1+\lambda}}{\frac{1}{1+L} \sum_{\ell=0}^L p(y|\theta_\ell, \xi)} \right] \\
    &= \log(L + 1) + \E_{p(\theta, y | \xi)} \log \left[ p(y|\theta, \xi)^\lambda \frac{p(y|\theta, \xi)}{ \sum_{\ell=0}^L p(y|\theta_\ell, \xi)} \right] \label{eq:nce_lambda_expanded} \\
    &= \log(L + 1) + \E_{p(\theta, y | \xi)} \left[ \lambda \log p(y|\theta, \xi) + \log \frac{p(y|\theta, \xi)}{ \sum_{\ell=0}^L p(y|\theta_\ell, \xi)} \right] \\
    &= \log(L + 1) - \lambda \E_{p(\theta)}[H(y|\theta, \xi)] + \E_{p(\theta, y | \xi)} \left[ \log \frac{p(y|\theta, \xi)}{ \sum_{\ell=0}^L p(y|\theta_\ell, \xi)} \right] \\
    &\leq \log(L + 1) - \lambda \E_{p(\theta)}[H(y|\theta, \xi)], \label{eq:nce_lambda_bound}
\end{align}
where \cref{eq:nce_lambda_expanded} follows from separating the numerator terms and applying the InfoNCE bound on the denominator sum. The final inequality in \cref{eq:nce_lambda_bound} results from dropping the negative KL divergence term.

This bound reveals that $\lambda$ modulates both the tightness of the mutual information bound and the emphasis on likelihood accuracy through the expected conditional entropy $\E_{p(\theta)}[H(y|\theta, \xi)]$ term. When $\lambda > 0$, increasing entropy decreases the bound, which combined with the gradient scaling shown in \cref{eq:gradient_phi}, incentivizes more accurate likelihood approximation at the cost of a looser bound on mutual information. Conversely, $\lambda < 0$ results in a tighter bound that better approximates the true mutual information, but reduces the gradient contribution of the likelihood term during optimization, potentially compromising likelihood accuracy as observed in our empirical results (\cref{fig:two_moons}). 

\section{Implementation of SBI-BOED in Posterior Estimation, Ratio estimation, and checkpointing}
\label{sec:SBI+MI}


\subsection{Applying the InfoNCE Bound to Neural Posterior Estimation}
\label{sec:snpe_mi}

We demonstrate the theoretical basis for optimizing a Neural Posterior Estimation (NPE) network and experimental designs, which learns a surrogate posterior conditioned on simulated data, $p_\phi(\theta | y, \xi)$. 

\textbf{Neural Posterior Estimation} \hspace{0.5em} Previous methods for directly estimating the posterior by maximum likelihood estimation struggled with bias \cite{Papamakarios2016} or variance \cite{lueckmann2017flexible}. An alternative method was developed by \citet{greenberg2019automatic} to recover the unbiased posterior,
\begin{equation}
    p(\theta | y) \approx \frac{ p_\phi (\theta | y) / p(\theta) }{ Z_\phi (y)}
\end{equation}
by calculating the normalizing constant $Z_\phi = \int p_\phi (\theta | y)/p(\theta) d\theta $. They then minimize $\mathcal{L}_{\text{NP}}(\phi) = \E_{p(y|\theta)p(\theta)}[-\log p_\phi (\theta | y)]$ to return an amortized posterior. Except for mixture density networks, \cite{bishop1994mixture} the normalizing constant is difficult to approximate. \citet{greenberg2019automatic} alternatively proposed to approximate the intractable normalizing constant by replacing the integral with a summation term that takes draws of the parameters from a proposal set $\Theta$ such that the posterior is approximately:
\begin{equation}
    p(\theta | y) \approx \frac{ p_\phi (\theta | y) / p(\theta) }{ \sum_{\theta' \in \Theta} p_\phi (\theta' | y) / p(\theta')}.
    \label{eq:snpe}
\end{equation}

% This objective aims to distinguish which set of possible parameters in $\Theta$ generated the simulated data $y$. 

\textbf{Applying NPE in BOED} \hspace{0.5em} We can use this in experimental design by again using the reparameterization trick to pass gradients back to the conditional $\xi$ inputs to the approximate posterior. In some cases, it may be more desirable to directly infer a posterior distribution instead of a likelihood. For example, if the data, $y_o$, to train a flow is computationally infeasible but whose latent parameters, $\theta$, is sufficiently small for use in a normalizing flow. Since the posterior is proportional to the likelihood, $p(\theta | y) \propto p(y|\theta)p(\theta)$, we can replace the likelihood in \cref{eq:lf_pce} with a posterior
\begin{equation}
    \label{eq:NP_InfoNCE}
    \mathcal{L}_{\text{NCE-NPE}}(\xi, \phi, L) \coloneqq \E_{p(\theta_0)p(y|\theta_0, \xi)p(\theta_{1:L})}  \frac{ p_\phi (\theta_0 | y, \xi) / p(\theta_0) }{ \frac{1}{1 + L}\sum_{\ell = 0}^L p_\phi (\theta_\ell | y, \xi) / p(\theta_\ell)},
\end{equation}
which is a biased lower bound of the MI by a factor of the prior $p(\theta)$, but whose gradient can still be used to train a density estimator and optimize experimental designs. This case should be used when it is desirable to have an amortized posterior and the absolute EIG does not matter.

\subsection{The NWJ BOED Bound \& Contrastive Ratio Estimation}
\label{sec:nwj_bound}

We demonstrate the theoretical basis for optimizing Neural Ratio Estimation (NRE) network and experimental designs, which learns a surrogate ratio estimator conditioned on experimental designs, $g_\phi(y,\theta|\xi)$. 

\textbf{Neural Ratio Estimation} \hspace{0.5em} Classifiers can be used to approximate the likelihood-to-evidence ratio such that $g_\phi (\theta, y) \approx \log \frac{p(y|\theta)}{p(y)} + c(y)$, where $c(y)$ is a bias term introduced from approximating the ratio, and which can be minimized \citep{Durkan2020, hastie2009elements}. The classifier can be trained by minimizing the loss 
\begin{equation}
    \mathcal{L}_{\text{CRE}}(\phi) = - \frac{1}{B} \sum_{b=1}^B \log \frac{\exp(g_\phi (\theta^{(b)}, y^{(b)} )) }{\sum_{k=1}^K \exp (g_\phi (\theta^{(k)}, y^{(b)} )) }
    \label{eq:nre}
\end{equation}

over $B$ batches of contrasting parameters. Given the use of contrastive samples, \citet{Durkan2020} called this contrastive ratio estimation (CRE) and noted the similarity between CRE and the Noise Contrastive Estimation (InfoNCE) MI lower bound  proposed by \citet{poole2019variational}.

\textbf{Applying NRE in BOED} \hspace{0.5em} We present another relevant MI bounds to this paper, the NWJ \cite{Nguyen_2010} bound has been used in BOED in \citet{Kleinegesse2021, ivanova2021implicit}.  Adjusting the bound from \citet{ivanova2021implicit},
\begin{equation}
    \label{eq:NWJ_objective}
    \mathcal{L}_\text{NWJ} (\xi, \phi) \coloneqq \E_{p(\theta)p(y|\theta, \xi)} \left[ g_\phi(y, \theta) \right] - e^{-1} \E_{p(\theta)p(y | \xi)} \left[ \text{exp}(g_\phi(y,\theta)) \right] ,
\end{equation}

where $g_\phi$ is a classifier that returns the probability that $y$ belongs to $\theta$. This function has lower bias than the InfoNCE bound but higher variance \cite{poole2019variational, song2019understanding}. In practice, this can be calculated by drawing $N$ samples from the joint distribution and shuffling to return $N (N - 1)$ marginal samples. \cite{miller_contrastive_2022} noted the connection between \cref{eq:nre} and the NWJ bound, and gave a tighter bound on the NWJ-based bound using their SBI-based CRE method. Their results hint at using a bound on the MI to optimize a likleihood-to-evidence ratio, and saw increasing EIG (lower bound of MI) with increasing number of contrastive samples. This is evident from \cref{eq:NWJ_objective}. While the NWJ bound may have less bias than the InfoNCE bound, it has higher variance that grows exponentially with the value of the true MI \cite{song2019understanding}. In the SBI setting, choosing when to use the InfoNCE or the NWJ bound will depend on what type of density estimator is required for the scientific task and ease of drawing samples from the joint distribution (simulator efficiency).

\begin{wrapfigure}{r}{0.45\textwidth}
    \centering
    \vspace{-42pt}
    \includegraphics[width=\linewidth]{figs/design_chkpt.pdf}
    \caption{Training with design checkpoints saves an optimal design $\xi^*$ that achieves the highest EIG.}
    \label{fig:design_chkpt}
    \vspace{-33pt}
\end{wrapfigure}

\subsection{Design Checkpoints} 
\label{sec:design_dist_appendix}

% \begin{minipage}{\dimexpr\textwidth-0.5\textwidth}
Since designs and model parameters calculate the ``reward'' in the form of the EIG, it is possible that the EIG may fall into a local optima by the end of training. This may be because of decaying learning rates of the design gradients or decreasing area searched by the design distribution. We show an example in \cref{fig:design_chkpt}, where a global maximum is found earlier in training but ends in a local minima. We are assuming that it is better to use designs that achieve a global maximum EIG, which motivates the use of design checkpoints in our algorithm.
% \end{minipage}




\section{Experiment Methodological Details}
\label{sec:hyperparame}


\begin{wrapfigure}{r}{0.35\textwidth}
    \centering
    % \vspace{-23pt}
    \includegraphics[width=\linewidth]{figs/two_moons_post.png}
    \vspace{0.1cm}  % Add a small space between images
    \includegraphics[width=\linewidth]{figs/two_moons_sbc.pdf}
    \caption{(Top) Posterior of the two moons experiments with mode collapse. (Bottom) Simulation-Based Calibration (SBC) of the posterior distribution for the two moons experiment.}
    \label{fig:2moons_stacked}
\end{wrapfigure}

For all experiments, we use a neural spline flow (NSF) normalizing flow. We specify the different parameterizations in Table \ref{tab:hyperparams}. We used the \texttt{ReduceLROnPlateau} function to reduce the learning rate for the SIR and BMP experiments, whereas we used a constant learning rate for the linear experiment. We use the same learning rate for all flow parameters, $\phi$. Notably, for the iterated experimental design, we keep the previous round's normalizing flow parameters, $\phi_{t-1}$ to use to return the subsequent round's posterior. We set the Adam optimizer $\beta_2$ to be 0.95 to mitigate large jumps in $\xi$ that might destabilize training. All code is available online.

% % \setcounter{figure}{3}
% \begin{wrapfigure}{r}{0.35\textwidth}
%     \centering
%     % \vspace{-169pt}
%     \includegraphics[width=1.0\textwidth]{figs/two_moons_post.png}
%     \caption{Posterior of the two moons experiments with mode collapse.}
%     \includegraphics[width=1.0\textwidth]{figs/two_moons_sbc.pdf}
%     \caption{Simulation-Based Calibration (SBC) of the posterior distribution for the two moons experiment.}
%     \label{fig:2moons_stacked}
% \end{wrapfigure}
% % \vspace{100pt}




\subsection*{SIR Experiment Details}

% \begin{minipage}{0.625\textwidth}
We follow the implementation of \cite{ivanova2021implicit} for the SIR model. We solve an SDE describing the process using the Euler-Maruyama method and discretize the domain $\Delta \tau = 10^{-2}$. The total population is fixed at $N=500$. For the model parameters $\beta$ and $\gamma$, we use log-normal priors such that $p(\beta) = \text{Lognorm}(0.50, 0.50^2)$ and $p(\gamma) = \text{Lognorm}(0.10, 0.50^2)$. Since solving the SDE is time-consuming, we pre-simulate data on a time grid in each round and access the relevant data regions during training.




\subsection*{BMP Experiment Details}

The BMP signaling pathway can be described by mass action kinetics of proteins binding to one another and conservation laws to describe the process of a downstream genetic expression signal reaching a steady-state based on receptors available and ligands in a cell's environment. The one-step model of BMP signaling was originally proposed by \cite{su2022ligand}. While the model is described by an ODE in \cite{antebi2017combinatorial}, its steady-state signal is solved by convex optimization \cite{dirks2007thermodynamic} as a closed-box solver.

\section{Expanded Two Moons Results}
\label{sec:two_moons_reloaded}

We analyze the mode collapse of the likelihood-based two moons posterior prediction related to the MI optimization. We also show a Simulation-Based Calibration (SBC) \cite{talts2020validating, hermanscrisis} curve for the two moons plot. For SBC we average over the parameters and compare the average posterior parameter values to the average prior values. 

\clearpage

\textbf{Mutual information optimization does not avoid mode collapse} \hspace{0.5em} Mode collapse in the two moons problem (\cref{fig:2moons_stacked}) is a common issue when using a likelihood-based flow model. While we initially considered analyzing this through the lens of mutual information and its interpretation as the expected log ratio of the posterior to prior:
$$
\mi(\theta ; y) = \E_{p(\theta, y)} \left[ \log \frac{p(y|\theta)}{p(y)} \right] = \E_{p(\theta, y)} \left[ \log \frac{p(\theta|y)}{p(\theta)} \right],
$$
our analysis in \cref{sec:MI_likelihood_proof} revealed that the root cause of mode collapse likely stems from deficiencies in the marginal likelihood approximation. There are two primary sources of error in the marginal likelihood estimation: the use of an approximate likelihood $p_\phi(y|\theta)$ and the reliance on finite samples to estimate the expectation. These approximations can introduce biases that may contribute to the observed mode collapse. Specifically, the InfoNCE bound used to maximize a lower bound of MI may be biased towards modes that better represent the observed data but potentially underrepresent the full range of parameter spaces that could explain the data.
% \end{minipage}
% \clearpage
\begin{table}[t]
% \vspace{-5pt}
\centering
\setlength{\tabcolsep}{4pt}
\renewcommand{\arraystretch}{0.9}
\caption{Training hyperparameters.}
\begin{tabular}{lcccc}
    \toprule
                                    & Linear & SIR & BMP   \\
        \toprule    
        Batch Size                      & 10   &   256  &  128  \\
        Number of Contrastive Samples     & 50   &  255 &  127  \\
        Number of Gradient Steps          &  10000  &  10000  &  500  \\
        $\phi$ \& $\xi$ Learning Rate         & $1\times10^{-3}$  &  $1\times10^{-3}$  &  $1\times10^{-3}$  \\
        Annealing Rate               & NA  &  0.8  &  0.8  \\
        Final Learning Rate               & NA  &  $1\times10^{-4}$  &  $1\times10^{-4}$  \\
        Gradient Clipping Threshold   &  NA  &  5 &  5  \\
        Hidden Layer Size          &  128  &  64 &  64  \\
        Number of Hidden Layers        &  4  &  2 &  2  \\
        Number of Flow layers (bijectors)   &  5  &  5 &  4  \\
        Number of bins for NSF        &  4  &  4 &  4  \\
    % \bottomrule
\end{tabular}
% \vspace{-10pt}
\label{tab:hyperparams}
\end{table}

Indeed, \cite{Foster2019} suggest simultaneously optimizing a posterior distribution at the same time as a likelihood via Likelihood-Free Adaptive Contrastive Estimation (LF-ACE). This approximates the marginal likelihood with a root sample from the prior $p(\theta_0)$, and samples from an approximate posterior $\theta_i \sim q(\theta|y)$. This is essentially using samples from a posterior as importance sample estimates to help address the mode collapse of the approximate marginal likelihood. While theoretically sound, we attempted this using a normalizing flow to approximate and sample from the posterior. We found that training both the likelihood and posterior while optimizing designs to be unstable. Future work may address this with pretraining of one or both of the density estimators to improve stability of estimation.

SBI literature in accurate mutual information approximation \cite{miller2023simulation, glaser2022maximum}while training amortized inference networks typically relies on using a generative model and critic in a similar form of importance sampling in a similar manner to LF-ACE. By addressing these issues in the marginal likelihood estimation, we may be able to develop more robust methods that avoid mode collapse in the two moons problem and related scenarios.


\section{Expanded BOED Results}
\label{sec:boed_reloaded}


\textbf{Linear Model} \hspace{0.5em} We show the effect of varying design dimensions and $\lambda$ regularization on the EIG metric in \cref{fig:linear_eig}. Optimizing a likelihood while optimizing experimental designs can struggle with high-dimensional designs but this is addressed with our regularization parameter.

\textbf{SIR Model} \hspace{0.5em} The SIR model prior predictive distribution, true value, and subsequent posterior can be seen in \cref{fig:sir_posterior} after $T=2$ experimental design rounds. We find a posterior approximation for this number of design rounds. We attempted to model the posterior when $T>2$ but found using the product likelihood identity of the likelihood using simple NUTS MCMC sampling in this regime challenging. This could be resolved with more sophisticated MCMC sampling methods such as Sequential Monte Carlo.

\begin{figure*}[h]  % Using figure* to span across two columns
  \centering
  \includegraphics[height=3.95cm, keepaspectratio]{figs/sir_curve.pdf}  % Adjusting width to fit side by side
  \hfill  % Ensures a space between the figures
  \includegraphics[height=3.95cm, keepaspectratio]{figs/sir_post.pdf}
  \hfill  % Ensures a space between the figures
  \includegraphics[height=3.95cm, keepaspectratio]{figs/sir_sbc.pdf}
  \caption{(\textit{Left}) Prior predictive distributions for the SIR model with the true evaluation curve superimposed. (\textit{Middle}) SIR posterior with true parameters at a red marker. (\textit{Right}) SBC expected coverage curve indicating that the posterior is conservative, which agrees with a visual analysis of the current posterior. }
  \label{fig:sir_posterior}
  \vspace{-10pt}
\end{figure*}

\textbf{BMP Model} \hspace{0.5em} The BMP model prior predictive and posterior distribution after $T=3$ rounds of experimental design in \cref{fig:bmp_posterior}. We also found issues with MCMC sampling from the product likelihood in this case but our technique does show how to simultaneously optimize designs and a likelihood in a non-differentiable scientific simulator. However, we would like to be conservative in designing experiments as opposed to overconfident in a parameter inference to avoid designing experiments for the wrong hypotheses.



\textbf{Improving Posterior Estimation} \hspace{0.5em} For both the SIR and BMP model, we only use a single round of inference for each round of BOED. All SBI algorithms can be refined by sequential application of drawing posterior samples conditioned on the observed data which will then help improve the quality of the likelihood \cite{Papamakarios2018}. We forego this refinement step in our study in favor of examining how our method works with different settings of our regularization parameter. Depending on the simulator, this step can be computationally expensive but performing a calibration analysis of the likelihood can help to determine whether it is worth performing refinement steps.

\begin{figure*}[htb]%{0.4\textwidth}  % 'r' for right, '0.5\textwidth' for the width of the wrapfigure environment
  \centering
  % \vspace{-55pt}
  \includegraphics[height=4.5cm, keepaspectratio]{figs/bmp_curve.pdf}  % First image
  % \vspace{1pt} % Space between the figures
  \hfill
  \includegraphics[height=4.5cm, keepaspectratio]{figs/bmp_post.pdf}  % Second image
  \hfill  % Ensures a space between the figures
  \includegraphics[height=4.5cm, keepaspectratio]{figs/bmp_sbc.pdf}
  \caption{(\textit{Left}) Prior predictive distributions for the BMP model with the true evaluation curve superimposed and (\textit{Middle}) its posterior with true parameters at a red marker. (\textit{Right}) SBC expected coverage indcating a very conservative posterior, which is supported by the posterior in question. This posterior would likely benefit from multiple rounds of SBI due to the conservative posterior and the SBC expected coverage would indicate which round of SBI was most calibrated.}
  \label{fig:bmp_posterior}
  % \vspace{-60pt}
\end{figure*}


\vfill


\end{document}





\end{document}
