\documentclass[10pt]{article} % For LaTeX2e

% Must come first: pass options to xcolor before any package loads it
\PassOptionsToPackage{dvipsnames}{xcolor}

% TMLR style
% For submission: use this
% \usepackage{tmlr}
% For camera-ready:
\usepackage[accepted]{tmlr}
% For preprint (de-anonymized):
% \usepackage[preprint]{tmlr}

% Optional math commands from https://github.com/goodfeli/dlbook_notation
\input{math_commands.tex}

% Basic packages
\usepackage{url}
\usepackage[colorlinks=true, linkcolor=red, citecolor=blue, urlcolor=BrickRed]{hyperref}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{subcaption}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{nicefrac}
\usepackage{microtype}

% Algorithm packages
\usepackage{algorithm}
\usepackage{algpseudocode}

% Additional symbols & math
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{makecell}

% Theorem environments
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% For pretty boxes
\usepackage{wrapfig}
\usepackage{tcolorbox}
\newcounter{boxcounter}
\renewcommand{\theboxcounter}{\arabic{boxcounter}} % Use Arabic numerals
\newenvironment{numberedbox}[1][]{%
    \refstepcounter{boxcounter}%
    \tcolorbox[
        colframe=black,
        colback=white,
        boxrule=0.3pt,
        sharp corners,
        title=Box \theboxcounter: #1,
        fonttitle=\bfseries,
        coltitle=black,
        colbacktitle=softblue,
        left=0pt, right=0pt, top=1pt, bottom=1pt,
        width=\columnwidth,
    ]
}{\endtcolorbox}

% Colors (must come after \PassOptionsToPackage)
\usepackage{xcolor}
\definecolor{softblue}{rgb}{0.85, 0.95, 1}
\definecolor{BrickRed}{rgb}{0.8, 0.25, 0.33} % Needed for urlcolor

% Clever references
\usepackage[capitalize,noabbrev]{cleveref}

% Custom commands
\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

% Title and author
\title{Dynamic Pricing in the Linear Valuation Model using Shape Constraints}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.

\author{\name Daniele Bracale\thanks{Corresponding author} \email dbracale@umich.edu \\
      \addr Department of Statistics\\
      University of Michigan
      \AND
      \name Moulinath Banerjee \email moulib@umich.edu \\
      \addr Department of Statistics\\
      University of Michigan
        \AND
      \name Yuekai Sun \email yuekai@umich.edu \\
      \addr Department of Statistics\\
      University of Michigan
      \AND
      \name Kevin Stoll \email kstoll@welltower.com\\
      \addr Welltower Inc.
      \AND
      \name Salam Turki \email STurki@welltower.com\\
      \addr Welltower Inc.}

% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\begin{document}
\maketitle

\begin{abstract}
We propose a shape-constrained approach to dynamic pricing for censored data in the linear valuation model eliminating the need for tuning parameters commonly required by existing methods. Previous works have addressed the challenge of unknown market noise distribution $F_0$ using strategies ranging from kernel methods to reinforcement learning algorithms, such as bandit techniques and upper confidence bounds (UCB), under the assumption that $F_0$ satisfies Lipschitz (or stronger) conditions. In contrast, our method relies on isotonic regression under the weaker assumption that $F_0$ is $\alpha$-H\"older continuous for some $\alpha \in (0,1]$, for which we derive a regret upper bound. Simulations and experiments with real-world data obtained by Welltower Inc (a major healthcare Real Estate Investment Trust) consistently demonstrate that our method attains lower empirical regret in comparison to several existing methods in the literature while offering the advantage of being tuning-parameter free.
\end{abstract}

\section{Introduction}
Dynamic pricing is the process of continuously adjusting product prices in response to customer feedback based on statistical learning and policy optimization. As a fundamental aspect of revenue management, dynamic pricing has been widely applied across various industries. A key challenge in this area is balancing the need to explore customer demand with exploiting current knowledge to set optimal prices that maximize revenue. This tradeoff between exploration and exploitation has been extensively studied in fields such as statistics, machine learning, economics, and operations research \cite{besbes2009dynamic,keskin2014dynamic,cheung2017dynamic,cesa2019dynamic, den2020discontinuous}. A large literature focuses on an important dynamic pricing problem where contextual information, such as product features and market conditions, is available at each time step. By leveraging this contextual data, we aim to refine pricing strategies and improve revenue outcomes. This approach, known as feature-based or contextual pricing, allows for more customized pricing decisions that better reflect product heterogeneity, leading to more effective revenue management in today’s data-rich environment.

This paper focuses on the problem of pricing a single product over a finite time horizon $T$, where the market value $v_t$ of the product is unknown to the seller and may vary over time $t=1,2,\dots, T$. The market value is modeled as a linear function of observed features (covariates) of the product
\begin{equation}\label{def:v_t_initial}
v_{t}=\theta_{0}^{\top} x_{t}+z_{t},
\end{equation}
where $x_{t} \in \mathbb{R}^{d}$ contains $1$ in the first component to consider for the intercept, $\theta_0$ is some unknown parameter and $x_t$ are independent of the noise $z_t$ that are i.i.d. with unknown cumulative distribution function (c.d.f.) $F_0$. After the seller proposes a price $p_t=p_t(x_t)$, they observe whether the item is sold or not, i.e. $y_t=\mathbf{1}\{p_t \leq v_t\}$ and collect revenue $p_ty_t$. The seller aims to design a policy that maximizes the total revenue $\sum_{t=1}^T p_ty_t$, given the uncertainty in the market value and the limited information available to the seller, that is $(p_t,x_t,y_t)$. The determination of the optimal revenue entails learning the model parameters $(\theta_0,F_0)$ for which various statistical tools have been employed such as kernel-based methods, bandit technique, and UCB \citep{fan2021policy, luo2022contextual, luo2024distribution, xu2022towards, tullii2024improved}. 

Building on the semi-parametric structure of the model and recent advances in shape-constrained statistics, we propose a novel policy that requires minimal assumptions about the underlying distribution of market noise. Specifically, we estimate $\theta_0$ using ordinary least squares (OLS) and $F_0$ using non-parametric least squares (NPLS), subject to the natural constraint that $F_0$ is non-decreasing.

A key advantage of our shape-constrained approach is that it is entirely data-driven and does not require the specification of any tuning parameters, unlike existing non-parametric methods. For example, the kernel-based technique proposed by \cite{fan2021policy} requires bandwidth selection for optimizing the error of the estimator. In contrast, the UCB-based strategy of \cite{luo2022contextual} requires a set of subjective parameters including a tuning parameter. 
%In contrast, our shape-constrained NPLSE is entirely data-driven, allowing the shape of the unknown $F_0$ to be determined directly by the data, without reliance on external choices.

\paragraph{Contribution.} Our main contributions are:
\begin{enumerate}[leftmargin=*, label=(\arabic*)]
\setlength\itemsep{0.5pt}
\item We propose a new tuning parameter-free method, unlike existing non-parametric methods for estimating the market noise distribution \( F_0 \), leveraging the shape constraint that \( F_0 \) is non-decreasing and assuming only that \( F_0 \) is $\alpha$-H\"older continuous for some $\alpha \in (0,1]$.

\item We derive an upper bound on the total expected regret of order $\widetilde{\mathcal{O}}(T^{\nu(\alpha)}d^{\nicefrac{\alpha}{2+\alpha}})$, where $\nu:(0,1]\rightarrow \mathbb{R}$, 
\begin{equation}\label{eq:zeta}
\textstyle \nu(\alpha)\triangleq \tfrac{2}{2+\alpha}\mathbf{1}\{\alpha \in (0,1/2)\}+\tfrac{2\alpha+1}{3\alpha+1}\mathbf{1}\{\alpha \in [1/2,1]\},
\end{equation}
and $\widetilde{\mathcal{O}}$ excludes log factors (under Lipshitzianity of $F_0$, this rates becomes $\widetilde{\mathcal{O}}(d^{1/3}T^{3/4})$), and we provide a thorough assessment of its empirical performance with comparisons to existing algorithms through a number of simulations, as well as an emulation experiment based on real data. Our algorithm shows strong empirical performance: in particular, it dominates the algorithm proposed by  \citet{tullii2024improved} in their simulation setting up to very large time horizons. Additionally, our algorithm when applied to a real data set obtained by Welltower Inc continues to demonstrate stronger performance than \citet{tullii2024improved,luo2022contextual} and is competitive with the nonparametric method proposed by \citet{
fan2021policy}, though the latter relies on stronger smoothness assumptions. 
\item Beyond the application of antitonic regression, our work involves establishing a concentration inequality for the uniform norm of the antitonic regression estimator error, which is required to derive the expected regret upper bound.  Although the existing literature on isotonic regression explores the rate of convergence of the uniform error,  explicit tail probability bounds (stronger than $O_P$ statements) of the type presented in this work (see \cref{thm:Dumbgen}) appear to be missing. 
\end{enumerate}

\subsection{Related Works}\label{sec:related}
The linear valuation model for contextual dynamic pricing, as defined in \cref{def:v_t_initial}, has been extensively studied under various assumptions. Recent works have explored statistical models—both linear and their extensions—for the pricing problem, assuming that $F_0$ (the noise distribution) is either known, partially known\footnote{Meaning $F_0$ is unknown but belongs to a parameterized family.} \citep{miao2019context, ban2021personalized, javanmard2019dynamic, golrezaei2019dynamic}, or fully unknown \citep{fan2021policy, xu2022towards, luo2022contextual}. For comprehensive overviews of dynamic pricing from a broader perspective, we refer readers to \cite{den2015dynamic} and \cite{kumar2018research}.

We focus on the results most relevant to our 
work—specifically, the case where both the parameter $\theta_0$ and the distribution $F_0$ are fully unknown. In this setting, \cite{fan2021policy} estimate $F_0$ using kernel methods and derive a regret upper bound of $\widetilde{\mathcal{O}}((dT)^{\frac{2m+1}{4m-1}})$, where $m \geq 2$ denotes the degree of smoothness of $F_0$. In the realm of reinforcement learning, \cite{luo2022contextual} introduces the Explore-then-UCB strategy, which balances revenue maximization, estimation of the linear valuation parameter, and nonparametric learning of the noise distribution. Under Lipschitz continuity on $F_0$, their approach achieves a regret rate of $\widetilde{\mathcal{O}}(d T^{3/4})$, and under (an additional) second-order smoothness assumption, a regret of $\widetilde{\mathcal{O}}(d^2T^{2/3})$. However, their regret bounds depend on a regularization parameter $\lambda > 0$, which is hard to tune dynamically, and the impact of the choice of $\lambda$ on the regret is not clearly described. \cite{xu2022towards} propose the D2-EXP4 algorithm, which is based on discretizing both the parameter space of $\theta_0$ and $F_0$. With appropriate choices of the discretization parameters, they establish a regret upper bound of $\widetilde{O}(T^{3/4} +\sqrt{d} T^{2/3})$. However, as noted in \citet[Section 6]{xu2022towards}, they were unable to perform numerical experiments on D2-EXP4 due to the exponential time complexity of the EXP4 learner with a policy set of size $2^{T^{1/4}}$, making their algorithm impractical for application. 
%As noted in \cref{Comparison}, their upper bound only requires the revenue function $r(p) = pF_0(p-x_t^{\top}\theta_0)$ to be \emph{half-Lipschitz}; however, 
Furthermore, Assumption 1 of their paper requires their $x_t$ and $\theta_0$ to have \emph{non-negative entries}. While they claim that this assumption entails no loss of generality, this assumption is heavily used in the proofs of Theorem 6 and Theorem 5 of their work, and it is far from clear whether their derivations are generalizable to the situation when such sign constraints are not imposed. While the positivity of covariates can be ensured under boundedness by adding constants and adjusting the intercept parameter, the assumption that all covariates have a positive impact on the valuation is quite unrealistic for any regression model. 
%(when they use $u \leq \hat u$ where $u = x_t^{\top}\theta^*$ and $\hat u = x_t ^{\top} \lceil \theta^* \rceil_{\Delta}$ and several consequent inequalities) and in Theorem 5 (see the final part of the Sketch of Theorem 5). Moreover, assuming that all the covariates have a positive impact on the valuation is a strong assumption (more generally in any regression problem) as well as for the covariates.
 
In contrast to \cite{fan2021policy,luo2022contextual, xu2022towards}, we propose a tuning parameter-free policy that achieves a regret upper bound of order $\widetilde{\mathcal{O}}(T^{3/4} d^{1/3})$ when $\alpha =1$ (i.e. $F_0$ is Lipschitz). Furthermore, estimating the parameters $\theta_0$ and $F_0$ is computationally efficient: $\theta_0$ is estimated using ordinary least squares (OLS), and $F_0$ is estimated via isotonic regression\footnote{Alternatively, estimating $S_0=1 - F_0$ using antitonic regression.} using the Pool Adjacent Violators Algorithm (PAVA) introduced by \citet{robertson1988order}, which, in our problem, has a computational complexity of $\mathcal{O}(d^{\nicefrac{\alpha}{2+\alpha}}T^{\nu(\alpha)})$ (see \cref{sec:complexity}). 

Very recent work by \cite{tullii2024improved} provides a \textit{UCB-LCB-based} algorithm named VAPE (Valuation Approximation-Price Elimination). The main idea is to update the estimate of $\theta_0$ at time $t$ when $x_t$ is far from previously observed covariate values; otherwise, update the UCB-LCB around $F_0$ and deploy the optimal price. They prove that their regret is upper bounded by $\widetilde{\mathcal{O}}((dT)^{2/3})$ under Lipschitz assumption on $F_0$ (i.e. $\alpha =1$), which attains the lower bound in $T$, $\Omega(T^{2/3})$ established in \cite{xu2022towards}. We summarize the regret upper bounds and the underlying assumptions in \cref{Comparison}. 

\begin{table*}[t]
\caption{Comparison of customer valuation model-based contextual dynamic pricing algorithms with stochastic contexts under the same assumptions on $\theta_0$ and similar smoothness assumptions on $F_0$. Notes: 
% \\ ($-$) For the assumptions in \cite{xu2022towards}'s work we defer to a complete discussion in Section \ref{sec:related}.
($\mathdollar$): $\nu(\alpha)$ is defined in \cref{eq:zeta}.}

\label{Comparison}
\centering
\begin{small}
\begin{sc}
\begin{tabular}{lccccc}
\toprule
Method  & \thead{Regret\\ Upper Bound} & \thead{H\"older\\ Continuity}& \thead{Lipschitz\\ Continuity} & \thead{2nd Order\\ Smoothness} \\
\midrule
\citet{fan2021policy}    & $\widetilde{O}((dT)^{\frac{2m+1}{4m-1}} )$ & $\times$ &  $\times$ & $\surd$  \\
\citet{luo2022contextual}  & $\widetilde{O}(T^{3/4} d)$ & $\times$ & $\surd$ & $\times$ \\
% \citet{xu2022towards}  & $\widetilde{O}(T^{\frac{3}{4}} +\sqrt{d} T^{\frac{2}{3}})$ & $-$ & $-$ & $-$\\
\citet{tullii2024improved}  & $\widetilde{O}((dT)^{2/3})$ & $\times$ & $\surd$ & $\times$ \\
This Work & $\widetilde{O}(T^{\nu(\alpha)}d^{\nicefrac{\alpha}{2+\alpha}})^{\mathdollar}$ & $\surd$ & $\surd$ & $\times$ & \\
\bottomrule
% Lower Bound &  & \text{not established yet} & $\Omega(T^{2/3})$ & \text{not established yet} & \\
% \bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{table*}

\subsection{Notation}
For an interval $I=(a,b)$, $a,b \in \R$ we use $|I|=b-a$. For any given matrix $\Sigma \in \mathbb{R}^{d_1 \times d_2}$, we write $\Sigma \succcurlyeq 0$ or $\Sigma \preccurlyeq 0$ if $\Sigma$ or $-\Sigma$ is semi-definite. For any event $A$, we let $\mathbb{I}(A)$ be an indicator random variable which is equal to $1$ if $A$ is true and $0$ otherwise. For two positive sequences $\left\{a_n\right\}_{n \geq 1},\left\{b_n\right\}_{n \geq 1}$, we write $a_n=\mathcal{O}\left(b_n\right)$ or $a_n \lesssim b_n$ if there exists a positive constant $C$ such that $a_n \leq C  b_n$. We denote $X_n 
 =\mathcal{O}_P(a_n)$ if there exists a $\eta>0$ and $n_0$ such that $P(X_n\leq a_n)\geq 1-1/n^{\eta}$ for $n\geq n_0$. In addition, we write $a_n=\Omega\left(b_n\right)$ or $a_n \gtrsim b_n$ if $a_n / b_n \geq c$ with some constant $c>0$. Moreover, we let $\widetilde{\mathcal{O}}(\cdot), \widetilde{\Omega}(\cdot)$ represent the same meaning with $\mathcal{O}(\cdot), \Omega(\cdot)$ except for ignoring log factors. For a random variable $x$ we will denote by $f_x$, and $P_x$ its corresponding density function and probability measure, respectively. For a c.d.f. $F$ we will use $S$ to denote $1-F$. Given a function $h(x,y)$ we write $\mathbb{E}_x[h(x,y)] = \int h(x,y) dP_x(x)$. We say that a function $S$ is $\alpha$-H\"older (continuous) for some constant $\alpha\in(0,1]$ if $|S(u)-S(v)|\leq L |u-v|^{\alpha}$ for all $u,v$ in it's domain.

\section{Problem Setting}\label{sec:problem_setting}
We consider the pricing problem where a seller has a single product for sale at each time period $t=1,2, \cdots, T$. Here $T$ is the total number of periods (i.e. length of the horizon) and may be unknown to the seller. The \textit{market value of the product} at time $t$ is denoted by $v_{t}$ and is unknown to the seller. At each period $t$, the seller posts a \textit{price} $p_{t} \in [p_{\min},p_{\max}]$ for $0\leq p_{\min} < p_{\max}< \infty$. If $p_{t} \leq v_{t}$, a sale occurs, and the seller collects a revenue of $p_{t}$. Otherwise, no sale occurs and no revenue is obtained. Let $y_{t}$ be the response variable that indicates whether a sale has occurred at period $t$:
\begin{align*}
\textstyle y_{t}= \mathbf{1}\{v_{t} \geq p_{t}\},
\end{align*}
\noindent
and let $p_ty_{t}$ the collected revenue at time $t$. We model the market value $v_{t}$ as a linear function of the product's observable i.i.d features $x_{t} \in \mathcal{X} \subset \mathbb{R}^{d}$ 
\begin{equation}\label{def:v_t}
\textstyle v_{t}=\theta_{0}^{\top} x_{t}+z_{t},
\end{equation}
where $\theta_{0}\in \mathbb{R}^{d}$ is an unknown parameter (which includes the intercept term), and $z_{t}$ are i.i.d sequence of idiosyncratic noise drawn from an unknown distribution $F_0$ with mean $0$ and bounded support 
\begin{equation}\label{eq:domain_of_S_0}
\textstyle \mathcal{U}\triangleq(\inf\{z \in \mathbb{R}:F_0(z)>0\}, \sup\{z \in \mathbb{R}:F_0(z)<1\}).
\end{equation}
We assume that the first entry in $x_t$ equals $1$ to account for the intercept term in $\theta_0$. The overall procedure is summarized in Box \ref{box:contextual_pricing}. The expected revenue for any offered price $p$ given $x_t$ is 
\begin{align*}
r_t(p)&\triangleq\mathbb{E}_{z_t}\left(p \mathbf{1}\{v_t>p\} \mid x_t\right)=p P_{z_t}\left(v_t>p \mid x_t\right) = pS_0(p-\theta_0^{\top}x_t), \quad S_0 = 1-F_0.
\end{align*}
Note that, since $S_0$ is a survival function, it is non-increasing. The optimal price $p_t^*$ at time $t$ is defined by a maximizer of the expected revenue function at the round,
\begin{align}\label{eq:ots_population_p}
\textstyle p_t^* \in \operatorname{argmax}_{p\in [p_{\min},p_{\max}]}\, p S_0\left(p - \theta_0^{\top}x_t\right).
\end{align}
Note that $p_t^*=p_t^*\left(x_t\right)$, depends on $x_t$. The regret at step $t$ is defined by the difference between the expected revenues from the optimal price $p_t^*$ and the offered price $p_t$: $r_t(p_{t}^{*})-r_t(p_{t})$. In other words, we consider the problem of maximizing revenue as minimizing the following maximum regret
\begin{align*}
\textstyle R(T)\triangleq \mathbb{E}\left[\sum_{t=1}^T p_t^*\mathbf{1}\{p^*_t\leq v_t\} - p_t\mathbf{1}\{p_t\leq v_t\} \right],
\end{align*}
where the expectation is taken with respect to the idiosyncratic noise $z_t$, the covariates $x_t$, and the offered prices $p_t$ that depend on the specific policy.

\begin{numberedbox}[Contextual Pricing Dynamic] \label{box:contextual_pricing}
For each sales round $t=1, \ldots, T$:
\begin{enumerate}[leftmargin=*, label=(\arabic*)]
\setlength\itemsep{0.5pt}
\item The seller observes a context vector $x_t \in \mathbb{R}^d$.
\item The seller offers a price $p_t$ based on $x_t$ and the previous sales records $\left\{\left(x_\tau, p_\tau, y_\tau\right)\right\}_{\tau=1}^{t-1}$.
\item Simultaneously, the customer evaluates the product at $v_t$, which is not known to the seller.
\item The seller observes $y_t=\mathbf{1}\{v_t \geq p_t\}$, indicating whether the product was sold.
\end{enumerate}
\end{numberedbox}

As the firm's goal is to design a policy that sets prices $p_t$ as close as possible to the optimal prices $p_t^*$ defined in \cref{eq:ots_population_p}, we first estimate $(\theta_0,S_0)$ and then we plug in the estimate as in \cref{eq:opt_p} to get an estimated optimal price $p_t$. Accurate estimation of $(\theta_0,S_0)$ thereby ensures that the resulting policy incurs low regret.

\section{Proposed Algorithm}

We employ an epoch-based design (also known as the doubling trick) that segments the given horizon $T$ into several clusters of rounds, called \emph{epochs} or \emph{episodes}, and executes identical pricing policies on a per-epoch basis. Let $\mathcal{J}_1 = \{0,1,\dots, \tau_1-1\}$ be the first episode, where $\tau_1$ is a prefixed constant. For $k=2,\dots , K = \left\lceil\log \left(T / \tau_1\right)+1\right\rceil$, define $\tau_k = \tau_1 2^{k-1}$, and $\mathcal{J}_k = \{\tau_k-\tau_1,\dots,\tau_{k+1}-\tau_1-1\}$ the set of times in the $k$-th episode. 

We partition $\mathcal{J}_k$ into two sub-phases, $\mathcal{J}_k = E_k \cup E_k'$, where $E_k$ represents the \emph{exploration phase}, dedicated to collecting data for estimating the parameters $(\theta_0,S_0)$, while $E_k'$ denotes the \emph{exploitation phase}, during which we apply the optimal prices based on the estimated parameters $(\widehat{\theta}_k,\widehat{S}_k)$. The length of the exploration phase, $|E_k|$, is set to $\lceil d^{\nicefrac{\alpha}{2+\alpha}}\tau_{k}^{\nu(\alpha)}\rceil$, chosen to minimize the expected regret $R(T)$. Specifically, as we show in the proof of \cref{thm:regret_upper_bound}, if $|E_k|= d^\xi\tau_k^\eta$ for some $\xi,\eta \in (0,1)$, then $R(T)$ is minimized if $\xi$ and $\eta$ satisfy the condition $d^{\xi}\tau_k^\eta = \lceil d^{\nicefrac{\alpha}{2+\alpha}}\tau_{k}^{\nu(\alpha)}\rceil$. $E_k$ is further divided into two equal-sized intervals $I_k$ and $\widetilde{I}_k$. In $I_k$ we collect data to estimate $\theta_0$. In $\widetilde{I}_k$ we collect data to estimate $S_0$. The details are stated in \cref{algo:semiparametric}, and a picture of a general episode $\mathcal{J}_k$ is shown in \cref{fig:explore-exploit}. In the following portion of this section, we examine the details of exploration-exploitation for a fixed episode $k$.

\begin{algorithm}[tb]
\caption{Semi-Parametric Pricing}
\label{algo:semiparametric}
\begin{algorithmic} 
\State {\bf Input:} Time horizon $T$ and length of the first epoch, $\tau_1$; the H\"older exponent $\alpha$ of $S_0$ and the corresponding $\nu (\alpha)$ defined in \cref{eq:zeta}; the minimum and maximum of price search range, $p_{\min }$ and $p_{\max }$, $H = p_{\max}-p_{\min}$; $\mathcal{U}$ defined in \cref{eq:domain_of_S_0}.
\State Set $K =\left\lceil\log \left(T / \tau_1\right)+1\right\rceil$.
    \For{epoch $k=1,2,\dots, K$}
        \State $\tau_{k} \gets \tau_1 2^{k-1}$, length of episode $k$
        \State $a_{k} \gets\lceil d^{\nicefrac{\alpha}{2+\alpha}}\tau_{k}^{\nu(\alpha)}/2\rceil$, length of exploration phase
    \State $I_k \gets \{\tau_k-\tau_1,\dots , \tau_k -\tau_1 + a_{k}-1\}$
    \State $\widetilde{I}_k  \gets \{\tau_k -\tau_1 + a_{k},\dots ,\tau_k -\tau_1 + 2a_{k}-1\}$
    \State $E_k  \gets I_k \cup \widetilde{I}_k$ indexes of the exploration phase
    \State $E'_k  \gets \{\tau_k-\tau_1+2a_k,\dots ,\tau_{k+1}-\tau_1-1\}$ indexes of the exploitation phase.
    \For{$t \in I_k$}
        \State Observe $x_t$
        \State Set $p_t \sim \text{unif}(p_{\min},p_{\max})$.
        \State  Get $y_t \gets \mathbf{1}\{p_t \leq v_t\}$
    \EndFor
    \State $\widehat{\theta}_k \gets \text{OLS}\{(x_t,Hy_t)\}_{t \in I_k}$
    \begin{tcolorbox}[colframe=black, colback=softblue, boxrule=0.2mm, arc=0mm, 
left=0mm, right=0mm, top=0mm, bottom=0mm, coltitle=black]
    \For{$t \in \widetilde{I}_k$}
        \State Observe $x_t$
        \State Sample $w_t \sim \text{unif}(\mathcal{U})$
        \State Set $p_t \leftarrow w_t + \widehat{\theta}_k x_t$
        \State  Get $y_t \gets \mathbf{1}\{p_t \leq v_t\}$
    \EndFor
    \end{tcolorbox}
    \State $\widehat{S}_k \gets \text{Antitonic}\{(w_t,y_t)\}_{t \in \widetilde{I}_k}$
    \For{$t \in E_k'$}
        \State Observe $x_t$
        \State Set price $p_t$ as defined in \cref{eq:opt_p}.
        \State  Get $y_t \gets \mathbf{1}\{p_t \leq v_t\}$
    \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}
\paragraph{Estimation of $\theta_0$.}
For all $t \in I_k$ the seller observe $x_t$, deploy $p_t \sim \operatorname{unif}(p_{\min},p_{\max})$ and observes $y_t=\mathbf{1}\{p_t\leq v_t\}$. Let $H= p_{\max}-p_{\min}$ and estimate
\begin{align*}
\textstyle\widehat{\theta}_k=\operatorname{OLS}\{(x_t,Hy_t)\}_{t\in I_k} = \arg\min_{\theta} \frac{1}{|I_k|}\sum_{t \in I_k} (Hy_t-\theta^{\top}x_t)^2.
\end{align*}

\paragraph{Estimation of $S_0$.}
For $t \in \widetilde{I}_k$, the seller observe $x_t$, sample $w_t \sim\operatorname{unif}(\mathcal{U})$, propose a price $p_t = w_t+\widehat{\theta}_k^{\top}x_t$ and observes $y_t=\mathbf{1}\{p_t\leq v_t\}$. Estimate
\begin{align*}
\textstyle\widehat{S}_k = \operatorname{Antitonic}\{(w_t,y_t)\}_{t \in \widetilde{I}_k} = \arg \min_{S \in \mathcal{S}}\sum_{t \in \widetilde{I}_k}(y_t-S(w_t))^2,
\end{align*}
where $\mathcal{S}$ is the set of non-increasing function in $\mathbb{R}$.

\paragraph{Exploitation.}
For every $t \in E'_k$, observe $x_t$, set
\begin{equation}\label{eq:opt_p}
p_t \in \operatorname{argmax}_{p \in [p_{\min},p_{\max}]}p\widehat{S}_{k}(p-\widehat{\theta}_{k}^{\top}x_t),
\end{equation}
and get reward $p_t\mathbf{1}\{p_t \leq v_t\}$.

\begin{figure}[h]
    \centering
    \vspace{.05in}
    \includegraphics[width=0.6\textwidth]{Pics/Exploration_Exploitation.png} % Adjust the path and size as needed
    \caption{Picture of a general episode $\mathcal{J}_k$, $k=1,2,\dots, K$.}
    \vspace{.05in}
    \label{fig:explore-exploit}
\end{figure}

\subsection{Complexity of the antitonic regression}\label{sec:complexity}
The algorithmic complexity for estimating $S_0$ is $\mathcal{O}(d^{\nicefrac{\alpha}{2+\alpha}}T^{\nu(\alpha)})$. Indeed by \cite{grotzinger1984projections, tibshirani2011nearly} the computational complexity for the antitonic estimator is $\mathcal{O}(n)$, where $n$ is the sample size. In our case, the estimation of $S_0$ happens in (half of) the exploration phase which has length proportional to $d^{\nicefrac{\alpha}{2+\alpha}}\tau_{K}^{\nu(\alpha)} = d^{\nicefrac{\alpha}{2+\alpha}}2^{K\nu(\alpha)}$, then, using that $K \propto \log_2(T)$, we have $n \propto d^{\nicefrac{\alpha}{2+\alpha}}T^{\nu(\alpha)}$. 

\section{Regret Analysis}
Before proceeding with the regret analysis we need to discuss the convergence rates of $\widehat{\theta}_k$ to $\theta_0$ and $\widehat{S}_k$ to $S_0$. We present our main theorems and proofs. We defer to the Appendix for the missing proofs.

\subsection{Estimation of $\theta_0$}

\begin{assumption}[Bounded parameter space]\label{ass:1}
The parameter $\theta_0 \in \mathbb{R}^d$ is an interior point of $\Theta$ and the parameter space $\Theta$ is a compact convex set.
\end{assumption}

\begin{assumption}[Bounded i.i.d. contexts]\label{ass:bounded_iid_data}
(a) $x_t \in \mathcal{X} \subset \mathbb{R}^d$ is i.i.d. drawn a distribution that does not involve $\theta_0$ and $F_0$, and for all $x_t \in \mathcal{X}$, $\left\|x_t\right\|_2 \leq R_\mathcal{X}$ for some unknown $R_\mathcal{X}>0$. (b) There exists reals $c_{\min },c_{\max }>0$, s.t. $c_{\min } \mathbb{I}_{d} \preccurlyeq \Sigma \preccurlyeq c_{\max } \mathbb{I}_{d}$, where $\Sigma \triangleq \mathbb{E} x_t x_t^{\top}$ and $\mathbb{I}_{d}$ the $d \times d$ identity matrix.
\end{assumption}
Assumptions \ref{ass:1} and \ref{ass:bounded_iid_data} are standard in the dynamic pricing literature \cite{javanmard2019dynamic, xu2022towards, luo2022contextual, fan2021policy}. More precisely, the i.i.d. assumption of the context and the prices $\{p_t\}_{t \in I_k}$, is used in \cref{lemma:1} to derive a concentration inequality for the estimation of $\theta_0$.

\begin{lemma}\label{lemma:1}[\citet[Lemma 4.1]{fan2021policy}] Let $n_k \triangleq |I_k|$ for simplicity of notation. Under Assumptions \ref{ass:1} and \ref{ass:bounded_iid_data}, there exist $c_0,c_1>0$ depending only on absolute constants given in assumptions, such that for any episode $k$, as long as $n_{k} \geq c_0 d$, with probability at least $1- Q_{n_{k}}$, with $Q_{n_{k}}\triangleq 2 e^{-c_{1} c_{\min }^{2}n_{k} / 16}+\frac{2}{n_{k}}$, it holds that
$$
\textstyle \|\widehat{\theta}_{k}-\theta_{0}\|_2 \leq C_{\theta_0} \sqrt{\nicefrac{d\log n_{k}}{n_{k}}} \triangleq R_{n_{k}},
$$
where $C_{\theta_0}\triangleq \frac{8 \max \left\{R_{\mathcal{X}}, 1\right\}\left(R_{\mathcal{X}} R_{\theta_0}+p_{\max}-p_{\min}\right)}{c_{\min}}$.
\end{lemma}

\subsection{Estimation of $S_0$ via antitonic regression}\label{sec:CSLR}

In this section, we provide a uniform convergence result of $\widehat{S}_k$ to $S_0$. For simplicity of notation, we re-index $\widetilde{I}_k$ as $\mathcal{T}=\{1,2,\dots, n\}$, and we denote $\widehat{\theta}_k$ by $\theta$, which was estimated using data $\{(p_t,x_t,y_t)\}_{t \in I_k}$ independent of $\mathcal{T}$. In this section, all the results must be considered as conditioned on $\theta = \widehat{\theta}_k$. We report in Box \ref{box:exploration_S_k} a more detailed explanation of the estimation of $S_0$ during the exploration phase in $\mathcal{T}$ as expounded in the box highlighted in \cref{algo:semiparametric}.

\begin{numberedbox}[Sample collection for estimating $S_{\theta}$] \label{box:exploration_S_k}
For each $t \in \mathcal{T}$ do:
\begin{enumerate}[leftmargin=*, label=(\arabic*)]
\setlength\itemsep{0.4pt}
\item Observe $x_t$.
\item The customer samples $z_t$ and evaluate $v_t = \theta_0^{\top}x_t+z_t$, unknown to the firm.
\item The firm samples $w_t \sim \operatorname{unif}(\mathcal{U})$ independent of everything else and defines $p_t = w_t + \theta^\top x_t$.
\item Observe $y_t = \mathbf{1}\{p_t \leq v_t\}$.
\end{enumerate}
\end{numberedbox}

This produces a set of data points $\{(p_t,x_t,y_t)\}_{t\in \mathcal{T}}$ that we are going to use for estimating $S_0$. To estimate $S_0$ we would need to know $\theta_0$ in advance, indeed remember that $\mathbb{E}(y_t \mid p_t,x_t)= S_0(p_t-\theta_0^{\top}x_t)$, which design points $\{p_t-\theta_0^{\top}x_t\}_{t \in \mathcal{T}}$ depend on $\theta_0$. However, our knowledge is limited to an approximation $\theta$ of $\theta_0$, and the observable design points are $p_t-\theta^{\top}x_t = w_t$.
This implies that we are only able to estimate $S_{\theta}(u) \triangleq \mathbb{E}(y_t \mid w_t=u)$. We then estimate $S_{\theta}(\cdot)$ considering $y_t$ as coming from a sample in the ordinary current status model, where the data has the form $\left(w_t,y_t\right) \overset{i.i.d}{\sim} (w,y)$, the observation times have uniform density $f_{w}$ and where $y_t=1$ with probability $S_\theta\left(w_t\right)$ at observation $w_t$.

\begin{remark}[{\bf The choice of the design points $w_t$}]\label{remark:optimal_design}
The choice of the distribution for $w_t$ is motivated by the fact that when the density of design points is uniform, we obtain convergence guarantees for the estimator of $S_0$. Specifically, as mentioned by \cite{mosching2020monotone}, if the density of the design points is bounded away from zero -- which holds for the uniform distribution -- then $\{w_t\}_{t \in \mathcal{T}}$ are ``asymptotically dense'' within any interval contained in $\mathcal{U}$ (defined in \cref{eq:domain_of_S_0}). Ensuring that the design points have a density bounded away from zero is a sufficient condition for the convergence result in \cref{thm:Dumbgen} (see \cref{lemma:A_n} for further details). However, this choice is not restrictive; any distribution whose density is bounded away from zero in $\mathcal{U}$ would still satisfy the convergence result. The only consequence of using a non-uniform density is that the regret $R(T)$ will depend on the multiplicative constant $C_2 = \inf_{u \in \mathcal{U}} f_w(u)$, which may be different from $1/|\mathcal{U}|$ if $f_w$ is not the uniform density in $\mathcal{U}$. Furthermore, since each episode $\mathcal{J}_k$ is independent of any other episode $\mathcal{J}_{k'}$ for $k \neq k'$, it is possible to select a different density $f_w^{(k)}$ for each episode $k$, provided that it remains bounded away from zero in $\mathcal{U}$. An interesting extension of our work would be to adaptively update the design density $f_w^{(k)}$ based on the previous design $f_w^{(k-1)}$ in an \emph{optimal} manner, namely that $f_w^{(k)}$ converges to the optimal design density as $k \rightarrow \infty$, that is the density that minimizes the integrated mean square error. This approach, known as \emph{sequential optimal design}, has been extensively studied in the literature (see, e.g., \citet{muller1984optimal, zhao2012sequential,bracale2024learning}). A key advantage of an optimal design algorithm is that it dynamically allocates more data to regions where the estimation of $S_0$ is less accurate, thereby progressively improving its precision. However, it is important to note that while this adaptive approach can optimize the multiplicative constant in the regret bound, it does not affect the rate of the regret itself.
\end{remark}

\begin{remark}[{\bf The difference between the conditional distributions of $y|(p,x)$ and $y|w$}]
We want to highlight the difference between the conditional distributions of $y|(p,x)$ and $y|w$. The first is independent of $\theta$, indeed we have that
$$
\mathbb{E}_z[y|p,x]=\mathbb{E}[\mathbf{1}\{p\leq \theta_0^{\top}x+z\}|p,x]=S_0(p-\theta_0^{\top}x),
$$
while, the distribution of $y|w$ depends on $\theta$ because $y = \mathbf{1}\{p\leq v\}$ where $p=w+\theta^{\top}x$, and, since data $(w,y)$ is generated as in Box \ref{box:exploration_S_k}, we have that
\begin{align}\label{eq:expected_y_t_theta}
S_{\theta}(u)&= \mathbb{E}_{z}(y \mid w=u)=\mathbb{E}_{(p,x)}(\mathbb{E}_{z}(y \mid p,x) \mid w=u)\nonumber\\
&=\mathbb{E}_{(p,x)}(S_0(p-\theta_0^{\top} x) \mid w=u)\nonumber\\
&=\mathbb{E}_{(p,x)}(S_0(p-\theta^{\top} x +\theta^{\top} x-\theta_0^{\top} x) \mid w=u)\nonumber\\
&=\mathbb{E}_{x}(S_0(u+(\theta-\theta_0)^{\top}x) \mid w=u)\nonumber\\
&= \textstyle\int S_{0}(u +(\theta -\theta_{0})^{\top}x)dP_{x \mid w=u}(x)\nonumber\\
&= \textstyle\int S_{0}(u +(\theta -\theta_{0})^{\top}x)dP_x(x),
\end{align}
where the first equality is by definition, in the second we use the tower property and in the last equality, we use that $w_t$ is sampled independently of $x_t$. Note from \cref{eq:expected_y_t_theta} that $S_{\theta}(\cdot)$ is non-increasing for all $\theta$ because $S_0=1-F_0$, being a survival function, is non-increasing.
\end{remark}

\begin{proposition}\label{proposition:S_theta_properties}
$S_{\theta}$ is non-increasing for every $\theta\in \mathbb{R}^d$. Moreover, if $S_0$ is $\alpha$-H\"older with $\alpha \in (0,1]$, then $S_{\theta}$ is $\alpha$-H\"older uniformly in $\theta \in \mathbb{R}^d$ and $|S_{\theta}(u)-S_0(u)|\lesssim \|\theta-\theta_0\|^{\alpha}_2$ uniformly in $u \in \mathbb{R}$.
\end{proposition}
 
\cref{proposition:S_theta_properties} is crucial because it tells us that we can estimate $S_{\theta}$ under the antitonic constraint and that $S_{\theta}$ is close to $S_0$ as long as $\theta$ is close to $\theta_0$, which will be used to prove \cref{thm:regret_upper_bound}. Guided by \cref{proposition:S_theta_properties}, we estimate $S_{\theta}$ using antitonic regression, denoted as
\begin{equation}\label{eq:likelihood_F}
\textstyle\widehat{S}_{\theta} \triangleq \operatorname{argmin}_{S \in \mathcal{S}} \sum_{t \in \mathcal{T}} (y_t-S(w_t))^2,
\end{equation}
where $\mathcal{S}$ is the set of non-increasing functions in $\mathbb{R}$. The minimizer $\widehat{S}_{\theta}$ is a piecewise constant function with jumps at a subset of $\{w_t: t \in \mathcal{T}\}$. The order statistics on which $\widehat{S}_{\theta}$ is based are the order statistics of the values $w_t$ and the values of the corresponding $y_t$. To be more specific, let $u_1<u_2<\dots<u_m$ the different value of the observed $\{w_t\}_{t\in \mathcal{T}}$. For $j=1,\dots,m$ set 
$$
\textstyle o_j= \#\{t: w_t=u_j\},\quad \widehat{y}_j = \frac{1}{o_j}\sum_{i:w_{i}=u_j}y_i.
$$
For every $1\leq r \leq s \leq m$ let
$$
\textstyle o_{r s}\triangleq\sum_{j=r}^s o_j=\#\left\{t: u_r \leq w_t \leq u_s\right\}, \quad \widehat{y}_{rs} =
\frac{1}{o_{r s}} \sum_{j=r}^s o_j \widehat{y}_j.
$$
It is well known that $\widehat{S}_{\theta}= (\widehat{S}_{\theta}(u_1),\widehat{S}_{\theta}(u_2),\dots,\widehat{S}_{\theta}(u_m))$ may be represented by the following minimax and maximin formulae, see \cite{robertson1988order}: for $1\leq j \leq m$
\begin{align*}
\widehat{S}_{\theta}(u_j)& = \min_{r\leq j}\max_{s\geq j} \,\widehat{y}_{rs}=\max_{s\geq j} \min_{r\leq j}\,\widehat{y}_{rs}.
\end{align*}
The $\widehat{S}_{\theta}$ is also known as the antitonic regression on data $\{\left(w_t,y_t\right)\}_{t\in \mathcal{T}}$, and we will denote it as
$$
\widehat{S}_{\theta} = \text{Antitonic} \{\left(w_t,y_t\right)\}_{t\in \mathcal{T}}.
$$
We are now prepared to demonstrate the convergence of $\widehat{S}_k$ to $S_0$. To establish this result, we require that $S_{\theta}$ is $\alpha$-H\"older for some $\alpha \in (0,1]$ uniformly in $\theta$. According to \cref{proposition:S_theta_properties}, this condition is satisfied provided we make the following assumption:

\begin{assumption}\label{ass:3-Lipschitz}
$|S_0(u)-S_0(v)|\leq C_1|u-v|^{\alpha}$ for some $\alpha \in (0,1]$, $C_1>0$ and for all $u,v \in \mathbb{R}$.
\end{assumption}

\begin{theorem}\label{thm:Dumbgen}
Let $\{(w_t,y_t)\}_{t \in \mathcal{T}}$ be as defined in Box \ref{box:exploration_S_k} and let Assumption \ref{ass:3-Lipschitz} hold. Then for every $\kappa >0$ and $\gamma>2$ there exists $n_0=n_0(\gamma,\kappa,\alpha) \in \mathbb{N}$ and $C= C(C_1,|\mathcal{U}|,\kappa,\alpha)>0$ (where $\mathcal{U}$ is defined in \cref{eq:domain_of_S_0}) such that
$$
\mathbb{P}\left\{\underset{u \in \mathcal{U}_n}{\sup} |\widehat{S}_{\theta}(u)-S_\theta(u)| \leq C \rho_n^{\alpha /(2\alpha +1)} \right\} \geq 1-\tfrac{1}{n^{\gamma -2}},\quad n \geq n_0,
$$
where $\rho_n=\log (n) / n$ and $\mathcal{U}_n = \{u \in \mathcal{U}:\left[u \pm \delta_n\right] \subset \mathcal{U}\}$, with $\delta_n=\kappa  \rho_n^{1 /(2\alpha +1)}$.
\end{theorem}

\begin{remark}
Our \cref{thm:Dumbgen} parallels Theorem 3.3 in \cite{mosching2020monotone}, with the key distinction being the nature of the observed response variable. While \cite{mosching2020monotone} directly observes the response variable (which corresponds to our valuation \( v_t \)), we observe the binary indicator \( y_t = \mathbf{1}\{p_t \leq v_t\} \). This difference simplifies our proof, as it only requires establishing a concentration inequality for \( |\widehat{y}_{rs} - \bar{S}_{rs}(\theta)| \), where
\[
\textstyle \bar{S}_{rs}(\theta) \triangleq \frac{1}{o_{rs}} \sum_{j=r}^s o_j S_{\theta}(w_j).
\]
In our setting, this concentration inequality can be readily obtained using Hoeffding's inequality uniformly over \( \theta \). Specifically, as demonstrated in \cref{lemma:Hoeffding}, for any constant \( D > 1 \),
$\mathbb{P}\{M_n(\theta) \leq(D \log n)^{1 / 2}\}$ is at least $1-(\nicefrac{n+1}{n^D})^2$, where $M_n(\theta)\triangleq\max _{1 \leq r \leq s \leq m} o_{r s}^{1 / 2}|\widehat{y}_{rs}-\bar{S}_{rs}(\theta)|$.
\end{remark}

\subsection{Regret Upper Bound}
We are now ready to establish an upper bound on the expected regret for our \cref{algo:semiparametric}. 
% In contrast to \cite{fan2021policy}, which assumes the optimal price is unique, our analysis only requires that at least one optimal price exists within the interval $(p_{\min}, p_{\max})$.

% \begin{assumption}\label{ass:2}
% For any $(x, \theta) \in \mathcal{X}\times \Theta$ at least one maximizer of $p \mapsto p S_0(p-x^{\top} \theta_0)$ over $[0, \infty)$ lies inside $\left(p_{\min }, p_{\max }\right)$.
% \end{assumption}

\begin{theorem}\label{thm:regret_upper_bound}
Suppose that Assumptions \ref{ass:1}, \ref{ass:bounded_iid_data} and \ref{ass:3-Lipschitz}. For sufficiently large $T$ the cumulative regret of \cref{algo:semiparametric}, $R(T)$ has upper bound of order
$$
\begin{cases}
\mathcal{O}(T^{\tfrac{2}{2+\alpha}}d^{\tfrac{\alpha}{\alpha + 2}}\log^{\tfrac{\alpha}{2\alpha +1}}(dT)), \quad & \alpha \in (0,1/2),\\
\mathcal{O}(T^{\tfrac{2\alpha +1}{3\alpha +1}}d^{\tfrac{\alpha}{\alpha + 2}}\log^{\tfrac{\alpha}{2}}(dT)), \quad & \alpha \in [1/2,1].
\end{cases}
$$
\end{theorem}

% {\bf Discussion on the lowerbound.} The minimax lower bound for the PH model-based contextual pricing problem is at least $\Omega(T^{\frac{2}{3}})$, when the true distribution class satisfies \cref{ass:1}, \cref{ass:bounded_iid_data} and \cref{ass:2}. This directly follows by \citet[Corollary 9]{xu2022towards}, since our model coincides with the LV models defined by them, i.e. the models for which the valuations are linear in the $d$-dimensional features plus a noise drawn i.i.d. from a fixed unknown distribution $F_0$, and the learning goal is to compete with the \emph{globally} optimal price $p_t^* = \operatorname{argmax}_p pP(p\leq v_t|x_t)$ with no restrictions on the pricing policy. Our regret upper bound $O((dT)^{\frac{2}{3}})$ matches the lower bound in terms of $T$. Nevertheless, a gap of order $d^{2/3}$ persists; its exploration is earmarked for future research.

% \section*{Improving regret for $d$ in high dimension}
% In this Section we provide an algorithm that achieve a $\sqrt{d}$ upper bound on the regret under more smoothness assumptions. The main difference with the previous policy is that we operate in high dimension, then we make the length of the episodes independetly of $d$. The length of the first episode will be $\tau_1= C_1$ for a prefixed constant $C_1>0$, and subsequent episodes $\tau_k = 2\tau_{k-1}= C_12^{k-1}$. Another key change is the estimation of $\theta_0$ that occurs after estimating $F_{\theta}(\cdot)$ for $\theta\in \Theta$. We borrow the estimation procedure by \citet{groeneboom2018current}. The main idea is the following. Fix any episode $k\geq 2$. For $t \in I_k$ observe $x_t$, sample uniform i.i.d. $p_t$ and get reward $y_t$. Let $w_t(\theta) = p_t-\theta^{\top}x_t$ and perform $\{\widehat{F}_{k,\theta}(\cdot), \theta \in \Theta\}$, where $\widehat{F}_{k,\theta}=\operatorname{isotonic}((y_t,w_t(\theta))_{t \in I_k})$. Define the \emph{score function}
% \begin{align*}
% \psi_k^{(\epsilon)}(\theta) \stackrel{\text { def }}{=} \sum_{t\in I_k \cap \mathcal{A}_{\epsilon,\theta}} x_t\left\{y_t-\widehat{F}_{n, \theta}\left(p_t-\theta^{\top} x_t\right)\right\}
% \end{align*}
% where $\mathcal{A}_{\epsilon,\theta} = \{t:\widehat{F}_{k,\theta}(p_t-\theta^{\top}x_t)\in [\epsilon,1-\epsilon]\}$. We would like to define the estimate $\hat{\theta}_n$ by $\psi_{k}^{(\epsilon)}(\hat{\theta}_k)=0$ but it is clear that we cannot hope to achieve that due to the discontinuous nature of the score function $\psi_{k}^{(\epsilon)}$. \citet{groeneboom2018current} therefore introduce the following definition:
% \begin{definition}[zero-crossing]
% We say that $\theta_*$ is a crossing of zero of a function $C: \Theta \rightarrow \mathbb{R}$ : $\theta \mapsto C(\theta)$ if each open neighborhood of $\theta_*$ contains points $\theta_1, \theta_2 \in \Theta$ such that $C\left(\theta_1\right) C\left(\theta_2\right) \leq 0$.
% \end{definition}
% We say that a function $\tilde{C}: \Theta \rightarrow \mathbb{R}^d: \theta \mapsto \tilde{C}(\theta)=(\tilde{C}_1(\theta), \ldots \tilde{C}_d(\theta))^{\top}$ has a crossing of zero at a point $\theta_*$ if $\theta_*$ is a crossing of zero of each component $\tilde{C}_j: \Theta \rightarrow \mathbb{R}, j=1,\ldots, d$.

% The following assumptions are also needed for the asymptotic normality results of our estimators.
% \begin{assumption}\label{ass:twice-continuiuty}
% The function $F_\theta$ is twice continuously differentiable on the interior of the support of $f_\theta=F_\theta^{\prime}$ for $\theta \in \Theta$.
% \end{assumption}
% \begin{assumption}\label{ass:twice-continuiuty-2}
% The density $f_{p-\theta^{\top} x}(u)$ of $p-\theta^{\top} x$ and the conditional expectations $\mathbb{E}\left\{x \mid p-\theta^{\top} x=u\right\}$ and $\mathbb{E}\left\{xx^{\top} \mid p-\theta^{\top} x=u\right\}$ are twice continuously differentiable functions w.r.t. $u$, except possibly at a finite number of points. The functions $\theta \mapsto f_{p-\theta^{\top} x}(v), \theta \mapsto \mathbb{E}\left\{x \mid p-\theta^{\top} x=v\right\}$ and $\theta \mapsto \mathbb{E}\left\{x x^{\top} \mid p-\theta^{\top} x=v\right\}$ are continuous functions, for $v$ in the definition domain of the functions and for $\theta \in \Theta$. The density of $(p, x)$ has compact support.
% \end{assumption}

% \begin{theorem}
% Let Assumptions \cref{ass:1},\cref{ass:bounded_iid_data}, \cref{ass:2}, \cref{ass:twice-continuiuty}, \cref{ass:twice-continuiuty-2} be satisfied and suppose that the covariance $\operatorname{Cov}(x, F_0(u+\left(\theta-\theta_0\right)^{\top} x) \mid p-\theta^{\top} x=u)$ is not identically zero for $u$ in the region $A_{\epsilon, \theta}$, for each $\theta \in \Theta$. Moreover, let $\hat{\theta}_k$ be defined by a crossing of zero of $\psi_{k}^{(\epsilon)}$. Then:    
% \end{theorem}


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite

\begin{proof} {\bf Sketch.} Fix $k\geq 2$ and define $n_k=|I_k|$ and $\widetilde{n}_k=|\widetilde{I}_k|$ and $a_k = |E_k| = n_k + \widetilde{n}_k$. Let $S_0\left(p \mid x\right) \triangleq S_0(p -\theta_0^{\top} x)$ and $\widehat{S}_k\left(p \mid x\right) \triangleq \widehat{S}_k(p -\widehat{\theta}_k^{\top} x)$. For the exploration phase $\mathbb{E}[\sum_{t \in E_k}r_t(p_t^*)-r_t(p_t)]\leq p_{\max}|E_k| \lesssim |E_k|$. Now fix $t \in E'_k$
\begin{align*}
&r_t(p_t^*)-r_t(p_t) =p_t^* S_0\left(p_t^* \mid x_t\right)-p_t S_0\left(p_t \mid x_t\right) \nonumber\\
&=\left\{p_t^* S_0\left(p_t^* \mid x_t\right)-p_t^* \widehat{S}_k\left(p_t^* \mid x_t\right)\right\}+\underset{\leq 0 \text{ by \cref{eq:opt_p}}}{\underbrace{\left\{p_t^* \widehat{S}_k\left(p_t^* \mid x_t\right)-p_t \widehat{S}_k\left(p_t \mid x_t\right)\right\}}}+ \left\{p_t \widehat{S}_k\left(p_t \mid x_t\right)-p_t S_0\left(p_t \mid x_t\right)\right\} \nonumber\\
&\leq p_{\max}\left| S_0(p_t^* \mid x_t)- \widehat{S}_k(p_t^* \mid x_t)\right|+ p_{\max}\left| \widehat{S}_k\left(p_t \mid x_t\right)-S_0\left(p_t \mid x_t\right)\right|  = R_{k,t}(p^*_t)+R_{k,t}(p_t),
\end{align*}
where $R_{k,t}(q) \triangleq |\widehat{S}_k(q-\widehat{\theta}_k^{\top}x_t)-S_0\left(q-\theta_0^{\top}x_t\right)|$ for $q\in\{p_t^*,p_t\}$, $t \in E_k'$.

\begin{lemma}\label{lem:J2J3}
If Assumptions in \cref{thm:regret_upper_bound} hold, for $k$ sufficiently large we have $\mathbb{E}(R_{k,t}(q))\lesssim \left(\nicefrac{\log \widetilde{n}_k}{\widetilde{n}_k}\right)^{\nicefrac{\alpha}{2\alpha+1}}+ \left(\nicefrac{d\log n_k}{n_k}\right)^{\nicefrac{\alpha}{2}}$ for $q\in\{p_t^*,p_t\}$ with $t \in E'_k$.
\end{lemma}

Let $k\geq k_0$ for $k_0$ be sufficiently large as in \cref{lem:J2J3}. Summing up for all $t \in E_k'$, and merging with the exploration phase of episode $k$ we get
$$
\textstyle \mathbb{E}\left[\sum_{t \in \mathcal{J}_k} r_t(p_t^*)-r_t(p_t)\right]  \lesssim |E_k|+|E_k'|\left[ \left(\nicefrac{\log \widetilde{n}_k}{\widetilde{n}_k}\right)^{\nicefrac{\alpha}{2\alpha+1}}+ \left(\nicefrac{d\log n_k}{n_k}\right)^{\nicefrac{\alpha}{2}} \right].
$$
Using that $n_{k} =\widetilde{n}_{k}=\frac{1}{2}a_k =\frac{1}{2}|E_k|= \frac{1}{2}d^{\xi}(\tau_1 2^{k-1})^{\nu} \propto d^{\xi} 2^{k\nu}$ for $\xi,\nu >0$ to be determined such that they minimize the total regret, and that $|E_k'| \leq  |\mathcal{J}_k|= \tau_1 2^{k-1}\propto 2^k$ we get that the RHS of the last inequality is bounded above by
\begin{align*}
d^{\xi} 2^{k\nu} + d^{-\tfrac{\xi \alpha}{2\alpha +1}}2^{k(1-\tfrac{\nu \alpha}{2\alpha +1})}[k+\log(d)]^{\tfrac{\alpha}{2\alpha +1}} + d^{\tfrac{\alpha}{2}(1-\xi)} 2^{k(1-\tfrac{\nu \alpha}{2})}[k+\log(d)]^{\tfrac{\alpha}{2}}.
\end{align*}

Here we prove the result for $\alpha>1$. We defer to \cref{sec:regret_upper_bound} for the complete proof. Consider the exponents of the factor $d$, i.e. $\xi$,$-\tfrac{\xi \alpha}{2\alpha +1}$ and $\tfrac{\alpha}{2}(1-\xi)$. As the second exponent is always negative, the regret is minimized with respect to $d$ if we equalize the first and the third exponent, i.e. $\xi = \tfrac{\alpha}{2}(1-\xi)$ to get $\xi^* = \frac{\alpha}{\alpha + 2}$. Similarly for the exponents of the exponential factor $2^k$, i.e. $\nu$, $1-\tfrac{\nu \alpha}{2\alpha +1}$ and $1-\tfrac{\nu \alpha}{2}$, we equalize the first two factors, to get $\nu^* = \tfrac{2\alpha +1}{3\alpha +1}$. Consequently, the expected regret in episode $k$, $\mathbb{E}\left[\sum_{t \in \mathcal{J}_k} r_t(p_t^*)-r_t(p_t)\right]$ is upper bounded by 
\begin{align*}
&2^{k\tfrac{2\alpha +1}{3\alpha +1}}(d^{\tfrac{\alpha}{\alpha + 2}} + d^{-\tfrac{\alpha^2}{(2\alpha +1)(\alpha +2)}}[k+\log(d)]^{\tfrac{\alpha}{2\alpha +1}}+ d^{\tfrac{\alpha}{\alpha + 2}}[k+\log(d)]^{\tfrac{\alpha}{2}}) \lesssim 2^{k\tfrac{2\alpha +1}{3\alpha +1}}d^{\tfrac{\alpha}{\alpha + 2}}[k+\log(d)]^{\tfrac{\alpha}{2}},
\end{align*}

where we used that $\tfrac{\alpha}{2\alpha+1} < \tfrac{\alpha}{2}$ for $\alpha \in (1/2,1]$. Putting together the phases and using that $K=\left\lceil\log \left(T / \tau_1\right)+1\right\rceil$ we get
\begin{align*}
\textstyle R(T)= \mathbb{E}\left[\sum_{k =k_0}^K\sum_{t \in \mathcal{J}_k} r_t(p_t^*)-r_t(p_t)\right]\lesssim 2^{K\tfrac{2\alpha +1}{3\alpha +1}}d^{\tfrac{\alpha}{\alpha + 2}}[K+\log(d)]^{\tfrac{\alpha}{2}}\lesssim T^{\tfrac{2\alpha +1}{3\alpha +1}}d^{\tfrac{\alpha}{\alpha + 2}}\log^{\tfrac{\alpha}{2}}(dT).
\end{align*}
\end{proof}
\section{Simulations}
We first perform simulations for theoretical validation in \cref{sec:simulation_theoretical} and a simulation to compare our algorithm with the minimax algorithm by \cite{tullii2024improved} and \cite{fan2021policy} algorithm in \cref{sec:comparison_tulli}.



\subsection{Simulation for theoretical validation}\label{sec:simulation_theoretical}
To this end, we replicate the simulation settings used by \cite{fan2021policy}. We set $\mathcal{U} = (-\nicefrac{1}{2},\nicefrac{1}{2})$ (known), the feature dimension $d=3$ (known), the distribution of $X_t \sim \text{Unif}(-\sqrt{\nicefrac{2}{3}},\sqrt{\nicefrac{2}{3}})^{\times d}$ (unknown), and the coefficient $\theta_0^\top=(\alpha_0,\beta_0^{\top})$ (unknown), where $\alpha_0=3, \beta_0=(\nicefrac{2}{3},\nicefrac{2}{3},\nicefrac{2}{3})$. We also choose $p_{\min}=0$ and $p_{\max}=5$ (known). For $F_0:\mathcal{U} \rightarrow \R$ we consider different choices: 
\begin{enumerate}[leftmargin=*, label=(\arabic*)]
\setlength\itemsep{0.5pt}
\item \boldsymbol{$\alpha<1$}: $F_{0,\alpha}(z) =\nicefrac{1}{2}+(\nicefrac{1}{2})^{1-\alpha}\operatorname{sign}(z)|z|^{\alpha}$ for $z\in\mathcal{U}$, for $z > \nicefrac{1}{2}$, for $\alpha \in \{\nicefrac{1}{3},\nicefrac{1}{2},\nicefrac{3}{4}\}$. 
\item \boldsymbol{$\alpha=1$}: we use four choices of $F_0$: a Gaussian $N(0,1)$ truncated at $\mathcal{U}$, the c.d.f. used by \cite{fan2021policy} with density $f_0(z) = 6\left(\frac{1}{4} -z^2\right)\mathbf{1}\{z\in\mathcal{U})\}$, a Laplace with location $0$ and scale $0.2$ truncated at $\mathcal{U}$, and a Cauchy with location $0$ and scale $0.2$ truncated at $\mathcal{U}$.
\end{enumerate}

\begin{figure*}[t]
\centering
\includegraphics[width=0.32\textwidth]{Pics/Regret_simulation_1_over_3_holder.png}
\includegraphics[width=0.32\textwidth]{Pics/Regret_simulation_1_over_2_holder.png}
\includegraphics[width=0.32\textwidth]{Pics/Regret_simulation_3_over_4_holder.png}
\includegraphics[width=0.32\textwidth]{Pics/Regret_simulation_Gaussian.png}
\includegraphics[width=0.32\textwidth]{Pics/Regret_simulation_Laplace.png}
\includegraphics[width=0.32\textwidth]{Pics/Regret_simulation_Cauchy.png}
\vspace{-0.2cm}
\caption{This plot shows the total expected regret (blue line) with $F_{0, \alpha}$, for $\alpha \in\{\nicefrac{1}{3},\nicefrac{1}{2},\nicefrac{3}{4}\}$ in the first row, and a Gaussian, Laplace, and Cauchy c.d.f. in the second row (from the left to the right). We repeated the simulation $36$ times and displayed the corresponding $95 \%$ confidence intervals. The plot is in $\log _2$ - $\log _2$ scale to show the regret rate (empirical slope): a slope of $\eta$ indicated an $\mathcal{O}\left(T^\eta\right)$ regret. The black dashed line corresponds to our theoretical regret upper bound.}
\label{fig:simul_for_validation}
\vspace{-0.2cm}
\end{figure*}

We start with $\tau_1=100$ and compute $K=8$ total episodes. At every time $t$ we follow Algorithm \ref{algo:semiparametric} to compute $p_t$, with the additional computation of the oracle $p_t^*$ and the corresponding cumulative regret $\textstyle \operatorname{Reg}(t)= \sum_{j=1}^t p_t^*S_0(p_t^* - \theta_0^{\top}x_t)-p_tS_0(p_t - \theta_0^{\top}x_t)$. We repeated the experiment $36$ times and we computed the mean and the $95\%$ confidence interval in a $\log_2-\log_2$ plot. As illustrated in \cref{fig:simul_for_validation}, we validate our approach by comparing the estimated slope of the linear regression of $\log_2(t)$ versus $\log_2(\operatorname{Reg}(t))$ with the theoretical upper bound rate. Due to space constraints, the plot corresponding to the $F_0$ used by \cite{fan2021policy} with density $f_0(z) = 6\left(\frac{1}{4} -z^2\right)\mathbf{1}\{z\in\mathcal{U})\}$ is provided in \cref{Appendix:other_plots}.

\begin{remark}[Dependence on $\tau_1$]
Although $\tau_1$ is generally considered a non-tuning parameter -- typically set to $1$ in dynamic pricing algorithms that use the doubling trick (see, e.g., \cite{javanmard2019dynamic,javanmard2020multi,javanmard2024multi}) -- we have included an additional simulation in \cref{fig:tau_1} to demonstrate the robustness of our algorithm with respect to this parameter.
\end{remark}

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{Pics/Regret_simulation_multiple_tau0.png}    \caption{This plot in $\log_2-\log_2$ scale shows the cumulative regret over time up to $T= 4000$ for different values of $\tau_1 \in \{31,62,124,248\}$ and with $F_{0,\nicefrac{1}{3}}$ for which theoretical regret rate is $0.86$. For each value of $\tau_1$, we repeated the simulation $36$ times and displayed the corresponding $95 \%$ confidence intervals. As we can see, the regret remains similar across different values of $\tau_1$ and the the empirical slopes are close to the theoretical regret rate.}
\label{fig:tau_1}
\end{figure}

\subsection{Comparison with \citet{tullii2024improved} under Lipschitz assumption of $F_0$}\label{sec:comparison_tulli}

% \begin{wrapfigure}[15]{r}
%     {0.4\textwidth}
%     \centering
%     \vspace{-0.05in}
%     \includegraphics[width=0.45\textwidth]{Pics/Regret_comparison_vape.png}
%     \vspace{-0.15in}
%     \caption{Regret comparison in the simulation setting of \citet{tullii2024improved}.}
%     \vspace{-0.15in}
%     \label{fig:comparison_vape}
% \end{wrapfigure}

We first recall that the regret upper bound by \cite{tullii2024improved} is of order $\widetilde{\mathcal{O}}(T^{2/3})$ under Lipschitz assumption on $F_0$ ($\alpha =1$), which is smaller than our regret upper-bound $\widetilde{\mathcal{O}}(T^{3/4})$. For this reason, we perform the following simulations.

In their work, \citet[Supplemenary Material A]{tullii2024improved} compared their VAPE method to the kernel-based method by \citet{fan2021policy} that is: they built a dataset of $5$ contexts belonging to $\mathbb{R}^3$ generated by a canonical Gaussian distribution and subsequently normalized. Throughout the run, the contexts are chosen from this set uniformly at random, while the noise term is picked from a Gaussian distribution truncated between $-1$ and $1$ with mean $0$ and variance $0.1$. Similarly, also the parameter $\theta_0$ is a normalized vector initially drawn from a Gaussian distribution. Note that for this simulation, the error distribution is twice differentiable (i.e. smoother than what \cite{tullii2024improved} and us allow in our theory), then the kernel-based method by \cite{fan2021policy} is applicable with smoothness parameter $m=2$. \citet{tullii2024improved} showed that the kernel-based method has stronger performance.

% \begin{wrapfigure}{r}{8cm}
% \includegraphics[width=0.5\textwidth]{Pics/Regret_comparison_vape.png}
% \caption{Regret comparison in the simulation setting of \citet{tullii2024improved}.}
% \label{fig:comparison_vape}
% \end{wrapfigure}

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{Pics/Regret_comparison_vape_2.png}
\caption{Regret comparison in the simulation setting of \citet{tullii2024improved}.}
\label{fig:comparison_vape}
\end{figure}

We apply our antitonic regression-based algorithm with $\alpha=1$, using the same code and simulation setting provided by \citet[Supplemenary Material A]{tullii2024improved}. The algorithm has been tested on time horizons $T \in[500,1000,2000,4000,8000]$. We computed the regret $36$ times and the corresponding 95\% confidence interval. In \cref{fig:comparison_vape} we show the results. Although the kernel-based method by \citet{fan2021policy} applies to distributions of the error that are at least twice differentiable -- which is the case in this simulation -- their algorithm has weaker performance than ours in this setting. Comparing our antitonic method with the VAPE algorithm by \cite{tullii2024improved} (which have the same assumption on $F_0$, i.e. Lipschitzianity of $F_0$) the empirical performance of VAPE is worse than our method up to very large time horizons ($T = 8000$), achieving smaller regret.

\section{Real Application}\label{sec:application}

This study applies our method to a real data set obtained by Welltower Inc to simulate the dynamic pricing process. The dataset consists of various characteristics and the transaction price for units in the United States (see \cref{tab:data-description} for more details). In our experiments, we present each rental unit to the dynamic pricing algorithm in a sequential fashion to simulate the dynamic pricing game. The unique aspect of the dataset is it includes the exact transaction price, which allows us to evaluate the regret of the algorithm directly.

\begin{table}[h]
\caption{Dataset description} \label{tab:data-description}
\begin{center}
\begin{tabular}{lp{9cm}} % Adjust the width (e.g., 8cm) as needed
\textbf{Variable}  &\textbf{Description} \\
\hline \\
$v_t$: \textbf{act\_rate\_d} & Final transaction price.\\
$x_{t,1}$: \textbf{mkt\_rate\_d}  & Typical rate of similar unit in the primary market area. \\
$x_{t,2}$: \textbf{sqft} & Square footage of unit. \\
$x_{t,3}$: \textbf{unit\_type} & Type of unit (bedroom, studio, or other).\\
$x_{t,4}$: \textbf{med\_home} & Median home value of primary market area.
\end{tabular}
\end{center}
\end{table}

% \begin{wrapfigure}{r}{10cm}
% \includegraphics[width=10cm,height=5cm]{Pics/residuals_AISTATS.png}
% \caption{Residuals}
% \label{fig:residuals}
% \end{wrapfigure}

\begin{figure}
\centering
\includegraphics[width=11cm,height=5cm]{Pics/residuals_AISTATS.png}
\caption{Residuals}
\label{fig:residuals}
\end{figure}

This dataset doesn't contain the variable $y_t$, i.e. whether the sales occurred. Our knowledge is limited to the final transaction prices \textbf{act\_rate\_d}. To overcome this we make the following adjustment: at each time point $t$, we consider the transaction price \textbf{act\_rate\_d} as the customer valuation $v_t$, which we treat as unobserved; a price $p_t$ is posted by the firm, which finally collects the data point $(x_t,y_t)$ where $y_t \triangleq  \mathbf{1}\{v_t \geq p_t\}$. Here the vector $x_t$ contains all the variables in \cref{tab:data-description} except \textbf{act\_rate\_d}, and $1$ in the first entry to account for the intercept. As we assume $v_t = \theta_0^{\top}x_t + z_t$ for some unknown $\theta_0$ and unknown c.d.f. $F_0$ of $z_t$, we validate this linear validation model. To this end, we perform a linear model using data ${(x_t,v_t)}$: the p-value of the $F$ statistics is close to $0$ and the slopes of all the variables are statistically significant at a significance level of $0.05$ (see \cref{fig:p-val}). The residuals and the associated empirical distribution function (an estimate of $F_0$) are depicted in \cref{fig:residuals}, from which we notice that $\mathcal{U}$ is approximatively $(-17,12)$. Moreover $p_{\min}$ and $p_{\max}$ are the maximum and minimum values of $v_t$.

\begin{table}[t]
\centering
\begin{minipage}{0.49\textwidth}
\caption{Summary Statistics}
\label{fig:summary}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lrrrrr}
\toprule
 & mkt\_rate\_d & sqft & 12min\_med\_home\_val & 20min\_med\_home\_val & act\_rate\_d \\
\midrule
min & 0.00 & 0.00 & 131131.52 & 139845.11 & 0.00 \\
25\% & 1764.12 & 334.00 & 356391.42 & 350603.75 & 139.00 \\
50\% & 2598.32 & 428.00 & 478335.94 & 481045.88 & 181.00 \\
mean & 3210.69 & 465.64 & 561100.96 & 531395.52 & 200.19 \\
75\% & 3811.40 & 546.00 & 689176.88 & 681712.58 & 233.00 \\
max & 56475.71 & 1782.00 & 1650871.95 & 1529372.81 & 1494.63 \\
\bottomrule
\end{tabular}
}
\end{minipage}%
\hspace{0.001\textwidth}
\begin{minipage}{0.49\textwidth}
\centering
\caption{Ordinary least squares: $v_t=\theta^{\top}x_t+z_t$}
\label{fig:p-val}
\resizebox{\textwidth}{!}{
\begin{tabular}{lrrrrrr}
\hline
Model:  & OLS   & Adj. R-squared:     & 0.597   \\
Df Model:           & 6                & F-statistic:        & 2.432e+04    \\
Df Residuals:       & 98552            & Prob (F-statistic): & 0.00         \\
R-squared:          & 0.597            & Scale:              & 11.956       \\
\hline
\hline
&   Coef. & Std.Err. &         t & P$> |$t$|$ &  [0.025 &  0.975]  \\
\hline
const                 & 15.0307 &   0.0116 & 1299.4124 &      0.0000 & 15.0081 & 15.0534  \\
mkt\_rate\_d          &  7.7899 &   0.0272 &  286.1036 &      0.0000 &  7.7365 &  7.8432  \\
sqft                  & -0.5291 &   0.0164 &  -32.3591 &      0.0000 & -0.5612 & -0.4971  \\
12min\_med\_home\_val &  0.5431 &   0.0136 &   39.8486 &      0.0000 &  0.5164 &  0.5698  \\
unit\_type\_2 bed     &  0.1804 &   0.0167 &   10.7981 &      0.0000 &  0.1477 &  0.2132  \\
unit\_type\_other     &  0.1420 &   0.0175 &    8.1030 &      0.0000 &  0.1076 &  0.1763  \\
unit\_type\_studio    &  0.0753 &   0.0218 &    3.4532 &      0.0006 &  0.0326 &  0.1181  \\
\hline
\end{tabular}
}
\end{minipage}
\end{table}

Prior to implementing the methods, we conducted cross-validation to tune the UCB algorithm's parameters $\lambda$ and $C_2$, as defined in \cite{luo2022contextual}. We searched over a grid with $(\lambda,C_2) \in \{0.1, 0.5, 1, 1.5, 2, 5\}\times\{5, 10, 15, 20, 30\}$. After selecting the optimal parameters, we ran the algorithm for each method. The initial episode length was set to $\tau_1 = 150$, with subsequent episodes doubling in length according to $\tau_k = \tau_1 2^{k-1}$, for a total of $K = 4$ episodes. Each algorithm then chooses its exploration phase according to its rule. We conducted $36$ iterations, randomly shuffling the data before each run. For our algorithm, we set $\alpha=1$.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\textwidth]{Pics/application_comparions.png}
\vspace{-0.2cm}
\caption{Revenue comparison}
\label{fig:Revenue_application}
\vspace{-0.2cm}
\end{figure}

\cref{fig:Revenue_application} showcases the (empirical) revenue $\textstyle \operatorname{Rev}(t)= \sum_{j=1}^t p_ty_t$, obtained using our antitonic method (blue line), the UCB method by \cite{luo2022contextual} (green line), the kernel method by \cite{fan2021policy} (red line) and the VAPE algorithm by \cite{tullii2024improved} (black line). Higher lines indicate better performance. We present three plots corresponding to different values of the smoothness parameter $m$, which affects only the kernel-based method by \citet{fan2021policy}. We let the antitonic, UCB, and VAPE methods remain the same across all three plots, while the kernel method's performance changes with varying $m$. Overall, our antitonic method generally outperforms the other approaches. The kernel-based method by \cite{fan2021policy} also performs well and tends to improve as the smoothness parameter $m$ increases. Despite tuning its parameters, the UCB method by \cite{luo2022contextual} performs poorly, while as far as the VAPE algorithm by \cite{tullii2024improved} shows worse performance than our method and kernel-based method by \citet{fan2021policy}

\section{Conclusions}
We introduced a novel method for estimating the market noise distribution \( F_0 \) by leveraging its natural shape constraint: monotonicity. Our analysis led to an expected upper bound on the total regret of order $\widetilde{\mathcal{O}}(T^{\nu(\alpha)}d^{\nicefrac{\alpha}{2+\alpha}})$, where $\nu(\alpha)$ is defined in \cref{eq:zeta}, matching certain previous rates in $T$ when $\alpha=1$ and enjoying the additional advantage of being tuning parameter-free. Compared to existing methods such as \cite{tullii2024improved, fan2021policy, luo2022contextual}, our proposed algorithm shows stronger empirical performance in both simulations and real data applications.

An interesting direction for future research is the study of lower bounds on the expected regret under the H\"older condition on $S_0$ and an investigation into whether our rate matches this bound. In the special case when $\alpha=1$ (i.e. Lipschitzianity of $F_0$), the regret lower bound of $\Omega(T^{2/3})$ established in \citet{xu2022towards}, has been attained in \citet{tullii2024improved}. Another promising extension, particularly for practical applications, is the incorporation of optimal design strategies, as discussed in \cref{remark:optimal_design}. This could significantly improve the multiplicative constants in the regret, leading to more efficient algorithms.

Another promising avenue for further research is to integrate the \citet{tullii2024improved} algorithm with our antitonic regression approach. The \citet{tullii2024improved} method offers a better theoretical upper bound, whereas our algorithm shows stronger empirical performance. A potential strategy would be to retain the Valuation Approximation step from their Algorithm 2 while replacing the Price Elimination step with our antitonic regression procedure (as highlighted by the blue box in \cref{algo:semiparametric}). The final optimal price would then be computed as in \cref{eq:ots_population_p}. We acknowledge that this idea is preliminary, and further investigation is required to rigorously formalize the integration and to perform a comprehensive regret analysis.

\section{Code Availability}

The codes are available at \url{https://github.com/dbracale/DP_via_Antitonic_TMLR_2025}.

\section*{Acknowledgements} We used generative AI tools when preparing the manuscript; we remain responsible for all opinions, findings, and conclusions or recommendations expressed in the paper. This paper is based on research supported by the National Science Foundation under grants 2027737, 2113373, and 2414918. 

\bibliography{main}
\bibliographystyle{tmlr}

\newpage
\appendix

%\clearpage
%\thispagestyle{empty}

% \begin{center}
%     \Huge \textbf{SUPPLEMENTARY MATERIAL}
% \end{center}

\section{Missing Proofs}
\subsection{Proof of \cref{proposition:S_theta_properties}}

\begin{proof}
By \cref{eq:expected_y_t_theta} we have $S_{\theta}(u)= \int S_{0}(u +(\theta -\theta_{0})^{\top}x)dP_x(x)$, from which we note that $S_{\theta}$ is non-increasing, because $S_0$ is non-increasing. Moreover if $S_0$ is $\alpha$-H\"older,
\begin{align*}
|S_{\theta}(u)-S_{\theta}(v)|&=\int |S_{0}(u +(\theta -\theta_{0})^{\top}x)-S_{0}(v +(\theta -\theta_{0})^{\top}x)|dP_x(x)\\
&  \leq \int C_1|u-v|^{\alpha}dP_x(x) =C_1|u-v|^{\alpha},
\end{align*}
and
\begin{align*}
|S_{\theta}(u)-S_{0}(u)|&= \int |S_{0}(u +(\theta -\theta_{0})^{\top}x)-S_{0}(u)|dP_x(x)\\
&  \leq \int C_1|(\theta -\theta_{0})^{\top}x|^{\alpha}dP_x(x) \\
&\leq C_1 R_{\mathcal{X}}^{\alpha}\|\theta -\theta_{0}\|^{\alpha}_2,
\end{align*}
where in the last inequality we used Cauchy-Scwartz and that $\|x\|_2\leq R_{\mathcal{X}}$.
\end{proof}

\subsection{Proof of \cref{thm:Dumbgen}}
We first need to Lemmas: \cref{lemma:Hoeffding} and \cref{lemma:A_n}.

\begin{lemma}\label{lemma:Hoeffding}
Let \begin{align*}
  \bar{S}_{rs}(\theta) \triangleq
\frac{1}{o_{r s}} \sum_{j=r}^s o_j S_{\theta}(w_j),
\end{align*}
and 
$$
  M_n(\theta)\triangleq\max _{1 \leq r \leq s \leq m} o_{r s}^{1 / 2}|\widehat{y}_{rs}-\bar{S}_{rs}(\theta)|.
$$
Then for any constant $D>1$,
$$
 \mathbb{P}\left(M_n(\theta) \leq(D \log n)^{1 / 2}\right)\leq 1-(\tfrac{n+1}{n^D})^2.
$$
\end{lemma}

\begin{proof}
First, the by Hoeffding's inequality, since $y_j$ are independent random variables taking values $\{0,1\}$ with mean $S_{\theta}(w_t)$, for every $\eta>0$ we have
$$
\mathbb{P}\left[\sqrt{o_{rs}}|\widehat{y}_{sr}-\bar{S}_{sr}(\theta)| \geq \eta\right] \leq 2e^{-2\eta^2}.
$$
Note that $M_n$ is the maximum of the $\binom{m+1}{2}$ quantities
$$
  o_{r s}^{1 / 2}|\widehat{y}_{rs}-\bar{S}_{rs}(\theta)|.
$$
Consequently,
$$
\begin{aligned}
\mathbb{P}\left(M_n(\theta) \geq \eta_n\right) & \leq \sum_{1 \leq r \leq s \leq m} \mathbb{P}\left(o_{r s}^{1 / 2}|\widehat{y}_{rs}-\bar{S}_{rs}(\theta)| \geq \eta_n\right) \\
  & \leq 2\binom{m}{2} \exp \left(-2 \eta_n^2\right) \\
  & \leq \exp \left(2 \log (n+1)-2 \eta_n^2\right)\\
  & \leq \exp \left(2 \log ((n+1)/n^D)\right) = (\tfrac{n+1}{n^D})^2,
\end{aligned}
$$
for arbitrary $\eta_n \geq 0$. But the right hand side converges to zero as $n \rightarrow \infty$ if $\eta_n=(D \log n)^{1 / 2}$ for some $D>1$.
\end{proof}

Before proceeding with the technical \cref{lemma:A_n}, let's define
$$
\rho_n\triangleq \frac{\log n}{n},
$$ 
and $\lambda(\cdot)$ the Lebesgue measure, and denote by $P_n(\cdot)$ the empirical measure of the design points $w_{t}$, that means
$$
P_n(B)\triangleq\frac{1}{n}\#\left\{t \in \mathcal{T}: w_{t}\in B\right\} \quad \text { for } B \subset \mathcal{U}.
$$

\begin{lemma}\label{lemma:A_n}
Let $w_1,w_2,\dots,w_n$ i.i.d. points with density $f_w$ that satisfies $\inf_{u \in \mathcal{U}} f_w (u) \geq C_2$ for some universal constant $C_2>0$ (which is the case for the uniform distribution), then for a given constant $\kappa >0$, and for any $\gamma >2$, there exists $n_0=n_0(\gamma,\kappa,\alpha) \in \mathbb{N}$ and a sequence $\epsilon_n = \epsilon_n(\gamma,\kappa,\alpha)>0$, $\epsilon_n \rightarrow 0$ such that
$$
\mathbb{P}\left(A_{n,\gamma}\right) > 1-\frac{1}{2(n+2)^{\gamma -2}}, \quad n \geq n_0
$$
where $A_{n,\gamma}$ is the event
$$
  \inf\left\{\frac{P_n\left(\mathcal{U}_n\right)}{\lambda\left(\mathcal{U}_n\right)}:\mathcal{U}_n \subset \mathcal{U}, \lambda\left(\mathcal{U}_n\right) \geq \delta_n\triangleq \kappa  \rho_n^{1 /(2\alpha +1)} \right\}\geq C_2(1-\epsilon_n).
$$
\end{lemma}

\begin{proof}
This is immediately derived from the proof of the more general result by \citet[Section 4.3]{mosching2020monotone} which can be stated as follows: let $\delta_n>0$ such that $\delta_n \rightarrow 0$ while $n\delta_n /\log(n) \rightarrow \infty$ (as $n\rightarrow \infty$). Then for every $\gamma>2$, there exists $n_0 = n_0 (\gamma, \delta_n)$ and $\epsilon_n = \epsilon_n(\gamma,\delta_n)>0$, $\epsilon_n \rightarrow 0$ such that 

$$  \mathbb{P}\left(\inf\left\{\frac{P_n\left(\mathcal{U}_n\right)}{P\left(\mathcal{U}_n\right)}:\mathcal{U}_n \subset \mathcal{U}, P\left(\mathcal{U}_n\right) \geq \delta_n \right\}\geq 1-\epsilon_n\right) > 1-\frac{1}{2(n+2)^{\gamma -2}}, \quad n \geq n_0,
$$
where $P(\cdot)$ is the probability measure of the design points $w_t$, that is
$$
P(B)\triangleq\int_B f_w(w)dw, \quad \text { for } B \subset \mathcal{U},
$$
and
$$
\epsilon_n\triangleq\max \left(c_n / \delta_n, \sqrt{2 c_n / \delta_n}\right)+\left(n \delta_n\right)^{-1} \rightarrow 0,
$$
where $c_n\triangleq \gamma \log (n+2) /(n+1)$. The value $n_0$ is the smallest integer $n$ that satisfies $\epsilon_n<1$.
\end{proof}

Now we prove \cref{thm:Dumbgen}.

\begin{proof}
Let $n$ be sufficiently large so that $\mathcal{U}_n \neq \emptyset$ and such that the event $A_{n,\gamma}$ in \cref{lemma:A_n} occurs. Since $f_w$ is the uniform distribution, the value $C_2$ defined in \cref{lemma:A_n} corresponds to $1/|\mathcal{U}|$. For $u \in \mathcal{U}_n$ the indices
\begin{align*}
  r(u) & \triangleq\min \left\{j \in\{1, \ldots, m\}: u_j \geq u-\delta_n\right\}, \\
  j(u) & \triangleq\max \left\{j \in\{1, \ldots, m\}: u_j \leq u\right\},
\end{align*}
are well-defined, because $\left[u-\delta_n, u\right]$ is a subinterval of $I$ of length $\delta_n$. Note that by \cref{lemma:A_n} this interval contains at least one observation $u_j$. Moreover,
\begin{align*}
& r(u) \leq j(u),\\
& u-\delta_n \leq u_{r(u)} \leq u_{j(u)}\leq u, \\
& o_{r(u) j(u)}=o_n\left(\left[u-\delta_n, u\right]\right) \geq C_2(1-\epsilon_n) n \delta_n,
\end{align*}
where $\epsilon_n$ is defined as in \cref{lemma:A_n}. Consequently, with $M_n(\theta)$ as in \cref{lemma:Hoeffding}, we have 
\begin{align*}
\widehat{S}_{\theta}(u)-S_{\theta}(u)& \leq \widehat{S}_{\theta}(u_{j(u)})-S_{\theta}(u) \\
& =\min _{r \leq j(u)} \max _{s \geq j(u)} \widehat{y}_{r s}-S_{\theta}(u) \\
& \leq \max _{s \geq j(u)} \widehat{y}_{r(u) s}-S_{\theta}(u) \\
& \leq o_{r(u) j(u)}^{-1 / 2} M_n(\theta)+\max _{s \geq j(u)} \bar{S}_{r(u) s}-S_{\theta}(u) \\
& \leq\left(C_2(1-\epsilon_n) n \delta_n\right)^{-1 / 2} M_n(\theta)+S_{\theta}(u_{r(u)})-S_{\theta}(u) \\
& \leq\left(C_2(1-\epsilon_n) n \delta_n\right)^{-1 / 2} M_n(\theta)+C_1 \delta_n^{\alpha}.
\end{align*}

In the first step, we used antitonicity of $u \mapsto \widehat{S}_{\theta}(u)$, and in the second last step we used antitonicity of $u \mapsto S_{\theta}(u)$, and the last step utilizes that by \cref{ass:3-Lipschitz}. But on the event $\left\{M_n(\theta) \leq(D \log n)^{1 / 2}\right\}$, the previous considerations implies that
\begin{align*}
\underset{u \in \mathcal{U}_n}{\sup}(\widehat{S}_{\theta}(u)-S_{\theta}(u)) & \leq\left(C_2(1-\epsilon_n) n \delta_n\right)^{-1 / 2}(D \log n)^{1 / 2}+C_1 \delta_n^{\alpha}=C \rho_n^{\alpha /(2\alpha +1)},
\end{align*}
where $C=\sqrt{\kappa D/C_2} + C_1\kappa^{\alpha}$, and we recall that $C_2 = 1/|\mathcal{U}|$ and $D$ is any real value strictly greater than $1$. But $\underset{u \in \mathcal{U}_n}{\sup}(S_{\theta}(u)-\widehat{S}_{\theta}(u))\leq C \rho_n^{\alpha /(2\alpha +1)}$ happens in $A_{n,\gamma} \cap \{M_n(\theta) \leq(D \log n)^{1 / 2}\}$ which has probability
\begin{align*}
\mathbb{P}(A_{n,\gamma} \cap \{M_n(\theta) \leq(D \log n)^{1 / 2}\}) &= 1-\mathbb{P}(A_{n,\gamma}^c \cup \{M_n(\theta) \geq (D \log n)^{1 / 2}\}) \\
&\geq 1-\mathbb{P}(A_{n,\gamma}^c)-\mathbb{P}( M_n(\theta) \geq (D \log n)^{1 / 2})\\
&= \mathbb{P}(A_{n,\gamma})+\mathbb{P}( M_n(\theta) \leq (D \log n)^{1 / 2})-1\\
&\geq 1-\frac{1}{2(n+2)^{\gamma -2}}-\left(\frac{n+1}{n^D}\right)^2\\
&\geq 1-\frac{1}{(n+2)^{\gamma -2}} \geq 1-\frac{1}{n^{\gamma -2}},
\end{align*}
where we used that by \cref{lemma:Hoeffding}, for any fixed $D>1$ we have $\mathbb{P}\left(M_n(\theta) \leq(D \log n)^{1 / 2}\right) \geq 1-(\tfrac{n+1}{n^D})^2$ and by \cref{lemma:A_n} for any $\gamma >2$ we have $\mathbb{P}\left(A_{n,\gamma}\right) > 1-\frac{1}{2(n+2)^{\gamma -2}}$. The last two inequalities come from choosing $\gamma=D$ sufficiently large. 

Analogously one can show that on $\left\{M_n \leq(D \log n)^{1 / 2}\right\}$,
\begin{align*}
\underset{u \in \mathcal{U}_n}{\sup}(S_{\theta}(u)-\widehat{S}_{\theta}(u))&\leq\left(n \delta_n\right)^{-1 / 2}(D \log n)^{1 / 2}+C_1 \delta_n^{\alpha}=C \rho_n^{\alpha /(2\alpha +1)},
\end{align*}
with the same constant $C$ and with the same probability tail.
\end{proof}

\subsection{Proof of \cref{thm:regret_upper_bound}}\label{sec:regret_upper_bound}
Fix $k\geq 2$ and define $n_k=|I_k|$ and $\widetilde{n}_k=|\widetilde{I}_k|$ and $a_k = |E_k| = n_k + \widetilde{n}_k$. Let $S_0\left(p \mid x\right) \triangleq S_0(p -\theta_0^{\top} x)$ and $\widehat{S}_k\left(p \mid x\right) \triangleq \widehat{S}_k(p -\widehat{\theta}_k^{\top} x)$. For the exploration phase $\mathbb{E}[\sum_{t \in E_k}r_t(p_t^*)-r_t(p_t)]\leq p_{\max}|E_k| \lesssim |E_k|$. Now fix $t \in E'_k$
\begin{align*}
&r_t(p_t^*)-r_t(p_t)\nonumber\\
& =p_t^* S_0\left(p_t^* \mid x_t\right)-p_t S_0\left(p_t \mid x_t\right) \nonumber\\
&=\left\{p_t^* S_0\left(p_t^* \mid x_t\right)-p_t^* \widehat{S}_k\left(p_t^* \mid x_t\right)\right\}+\underset{\leq 0 \text{ by \cref{eq:opt_p}}}{\underbrace{\left\{p_t^* \widehat{S}_k\left(p_t^* \mid x_t\right)-p_t \widehat{S}_k\left(p_t \mid x_t\right)\right\}}}+ \left\{p_t \widehat{S}_k\left(p_t \mid x_t\right)-p_t S_0\left(p_t \mid x_t\right)\right\} \nonumber\\
&\leq p_{\max}\left| S_0(p_t^* \mid x_t)- \widehat{S}_k(p_t^* \mid x_t)\right|+ p_{\max}\left| \widehat{S}_k\left(p_t \mid x_t\right)-S_0\left(p_t \mid x_t\right)\right| \nonumber\\
& = R_{k,t}(p^*_t)+R_{k,t}(p_t),
\end{align*}
where $R_{k,t}(q) \triangleq |\widehat{S}_k(q-\widehat{\theta}_k^{\top}x_t)-S_0\left(q-\theta_0^{\top}x_t\right)|$ for $q\in\{p_t^*,p_t\}$, $t \in E_k'$.

By \cref{lem:J2J3} there exists $k_0$ such that for $k \geq k_0$, $\mathbb{E}(R_{k,t}(q))\lesssim \left(\nicefrac{\log \widetilde{n}_k}{\widetilde{n}_k}\right)^{\nicefrac{\alpha}{2\alpha+1}}+ \left(\nicefrac{d\log n_k}{n_k}\right)^{\nicefrac{\alpha}{2}}$ for $q\in\{p_t^*,p_t\}$ with $t \in E'_k$. Summing up for all $t \in E_k'$, yields that 
$$
\mathbb{E}\left[\sum_{t \in E'_k} r_t(p_t^*)-r_t(p_t)\right] \lesssim |E_k'|\left[ \left(\nicefrac{\log \widetilde{n}_k}{\widetilde{n}_k}\right)^{\nicefrac{\alpha}{2\alpha+1}}+ \left(\nicefrac{d\log n_k}{n_k}\right)^{\nicefrac{\alpha}{2}} \right].
$$
Merging with the exploration phase of episode $k$ we get
$$
\mathbb{E}\left[\sum_{t \in \mathcal{J}_k} r_t(p_t^*)-r_t(p_t)\right]  \lesssim |E_k|+|E_k'|\left[ \left(\nicefrac{\log \widetilde{n}_k}{\widetilde{n}_k}\right)^{\nicefrac{\alpha}{2\alpha+1}}+ \left(\nicefrac{d\log n_k}{n_k}\right)^{\nicefrac{\alpha}{2}} \right].
$$
Using that $n_{k} =\widetilde{n}_{k}=\frac{1}{2}a_k =\frac{1}{2}|E_k|= \frac{1}{2}d^{\xi}(\tau_1 2^{k-1})^{\nu} \propto d^{\xi} 2^{k\nu}$ for $\xi,\nu >0$ to be determined such that they minimize the total regret, and that $|E_k'| \leq  |\mathcal{J}_k|= \tau_1 2^{k-1}\propto 2^k$ we get that the RHS of the last inequality is
\begin{align*}
\mathbb{E}\left[\sum_{t \in \mathcal{J}_k} r_t(p_t^*)-r_t(p_t)\right]&\lesssim d^{\xi} 2^{k\nu} + 2^k\left[ \left(\tfrac{\log (d^{\xi} 2^{k\nu})}{d^{\xi} 2^{k\nu}}\right)^{\nicefrac{\alpha}{2\alpha+1}}+ \left(\tfrac{d\log (d^{\xi} 2^{k\nu})}{d^{\xi} 2^{k\nu}}\right)^{\nicefrac{\alpha}{2}} \right] \\
&\lesssim d^{\xi} 2^{k\nu} + 2^k \left(\tfrac{\log (d^{\xi} 2^{k\nu})}{d^{\xi} 2^{k\nu}}\right)^{\nicefrac{\alpha}{2\alpha+1}}+ 2^k\left(\tfrac{d\log (d^{\xi} 2^{k\nu})}{d^{\xi} 2^{k\nu}}\right)^{\nicefrac{\alpha}{2}} \\
&\lesssim d^{\xi} 2^{k\nu} + d^{-\tfrac{\xi \alpha}{2\alpha +1}}2^{k(1-\tfrac{\nu \alpha}{2\alpha +1})}[k+\log(d)]^{\tfrac{\alpha}{2\alpha +1}} + d^{\tfrac{\alpha}{2}(1-\xi)} 2^{k(1-\tfrac{\nu \alpha}{2})}[k+\log(d)]^{\tfrac{\alpha}{2}}.
\end{align*}
The exponents of the factor $d$ are $\xi$,$-\tfrac{\xi \alpha}{2\alpha +1}$ and $\tfrac{\alpha}{2}(1-\xi)$. As the second exponent is always negative we equalize the first and the third exponent, i.e. $\xi = \tfrac{\alpha}{2}(1-\xi)$ to get $\xi^* = \frac{\alpha}{\alpha + 2}$. The exponents of the exponential factor $2^k$ are $\nu$, $1-\tfrac{\nu \alpha}{2\alpha +1}$ and $1-\tfrac{\nu \alpha}{2}$. Equalizing the first two factors, we get $\nu^* = \tfrac{2\alpha +1}{3\alpha +1}$, however $\nu^* > (1-\tfrac{\nu^* \alpha}{2})$ for $\alpha > 1/2$, is equal for $\alpha = 1/2$ and less for $\alpha < 1/2$. Then for $\alpha \geq 1/2$ we equalizing the first and last factors, obtaining $\nu = 1-\tfrac{\nu \alpha}{2}$ to get $\nu^* = \tfrac{2}{2+\alpha}$.

{\bf Case $\alpha > 1/2$.} The expected regret in episode $k$, $\mathbb{E}\left[\sum_{t \in \mathcal{J}_k} r_t(p_t^*)-r_t(p_t)\right]$ is upper bounded by 

\begin{align*}
&2^{k\tfrac{2\alpha +1}{3\alpha +1}}(d^{\tfrac{\alpha}{\alpha + 2}} + d^{-\tfrac{\alpha^2}{(2\alpha +1)(\alpha +2)}}[k+\log(d)]^{\tfrac{\alpha}{2\alpha +1}}+ d^{\tfrac{\alpha}{\alpha + 2}}[k+\log(d)]^{\tfrac{\alpha}{2}}) \lesssim 2^{k\tfrac{2\alpha +1}{3\alpha +1}}d^{\tfrac{\alpha}{\alpha + 2}}[k+\log(d)]^{\tfrac{\alpha}{2}},
\end{align*}

where we used that $\tfrac{\alpha}{2\alpha+1} < \tfrac{\alpha}{2}$ for $\alpha \in (1/2,1]$. Putting together the phases we get
\begin{align*}
R(T)&= \mathbb{E}\left[\sum_{k =k_0}^K\sum_{t \in \mathcal{J}_k} r_t(p_t^*)-r_t(p_t)\right]\lesssim 2^{K\tfrac{2\alpha +1}{3\alpha +1}}d^{\tfrac{\alpha}{\alpha + 2}}[K+\log(d)]^{\tfrac{\alpha}{2}}\lesssim T^{\tfrac{2\alpha +1}{3\alpha +1}}d^{\tfrac{\alpha}{\alpha + 2}}\log^{\tfrac{\alpha}{2}}(dT),
\end{align*}
where we used that $K=\left\lceil\log \left(T / \tau_1\right)+1\right\rceil$.

{\bf Case $\alpha \leq 1/2$.} The expected retreat in episode $k$, $\mathbb{E}\left[\sum_{t \in \mathcal{J}_k} r_t(p_t^*)-r_t(p_t)\right]$, is upper bounded by

\begin{align*}
&2^{k\tfrac{2}{2+\alpha}}(d^{\tfrac{\alpha}{\alpha + 2}} + d^{-\tfrac{\alpha^2}{(2\alpha +1)(\alpha +2)}}[k+\log(d)]^{\tfrac{\alpha}{2\alpha +1}} + d^{\tfrac{\alpha}{\alpha + 2}}[k+\log(d)]^{\tfrac{\alpha}{2}})\lesssim 2^{k\tfrac{2}{2+\alpha}}d^{\tfrac{\alpha}{\alpha + 2}}[k+\log(d)]^{\tfrac{\alpha}{2\alpha +1}},
\end{align*}

where we used that $\tfrac{\alpha}{2\alpha+1} \geq \tfrac{\alpha}{2}$ for $\alpha \in (0,1]$. Putting together the phases we get
\begin{align*}
R(T)= \mathbb{E}\left[\sum_{k =k_0}^K\sum_{t \in \mathcal{J}_k} r_t(p_t^*)-r_t(p_t)\right]\lesssim 2^{K\tfrac{2}{2+\alpha}}d^{\tfrac{\alpha}{\alpha + 2}}[K+\log(d)]^{\tfrac{\alpha}{2\alpha +1}}\lesssim T^{\tfrac{2}{2+\alpha}}d^{\tfrac{\alpha}{\alpha + 2}}\log^{\tfrac{\alpha}{2\alpha +1}}(dT),
\end{align*}
where we used that $K=\left\lceil\log \left(T / \tau_1\right)+1\right\rceil$, which concludes the proof.

\subsection{Proof of \cref{lem:J2J3}}\label{sec:groeneboom}
Let $n_{k}=|I_{k}|$ and $\widetilde{n}_k = |\widetilde{I}_k|$ and $t \in E_k'$. Define the event $\mathcal{E}_k = \{\|\widehat{\theta}_k-\theta_0\|\leq R_{n_{k}}\}$ where we recall
$$
R_{n_{k}} \propto \sqrt{\frac{d\log n_{k}}{n_{k}}},
$$
as defined in \cref{lemma:1}, and 
$$
R_{k,t}(q) = |\widehat{S}_k(q-\widehat{\theta}_k^{\top}x_t)-S_0\left(q-\theta_0^{\top}x_t\right)|, \quad q \in \{p_t,p_t^*\}.
$$
Recall that
$$
\widehat{\theta}_k = \text{OLS}\{(x_t,y_t)\}_{t\in I_k}, \quad \widehat{S}_{k} = \text{Antitonic}\{(w_t,y_t)\}_{t \in \widetilde{I}_k},
$$
and define $S_{k}=S_{\widehat{\theta}_k}$, where by definition in \cref{eq:expected_y_t_theta}
$$
S_k(u)=S_{\widehat{\theta}_k}(u)= \mathbb{E}_{x}[S_0(u+(\widehat{\theta}_k-\theta_0)^{\top}x)].
$$
Now let $q \in \{p_t,p_t^*\}$ for some $t \in E_k'$. We can write
$$
R_{k,t}(q) = R_{k,t}(q)\mathbb{I}(\mathcal{E}_k)+R_{k,t}(q)\mathbb{I}(\mathcal{E}_k^c).
$$ 

\textbf{Analyzing the $R_{k,t}(q)\mathbb{I}(\mathcal{E}_k^c)$:}

By \cref{lemma:1} we have $\mathbb{E}[R_{k,t}(q)\mathbb{I}(\mathcal{E}_k^c)] \leq 2\mathbb{P}(\mathcal{E}_k^c)=Q_{n_{k}}= 2 e^{-c_{1} c_{\min }^{2}n_{k} / 16}+\frac{2}{n_{k}}$. 

\textbf{Analyzing the $R_{k,t}(q)\mathbb{I}(\mathcal{E}_k)$:}

$R_{k,t}(q)$ is less or equal than two times
\begin{align}\label{ineq:lemma_groeneboom}
\underset{=A}{\underbrace{|\widehat{S}_{k}(q-\widehat{\theta}_k^{\top} x_t)-S_{k}(q-\widehat{\theta}_k^{\top} x_t)|\mathbb{I}(\mathcal{E}_k)}} + \underset{=B}{\underbrace{|S_{k}(q-\widehat{\theta}_k^{\top} x_t)-S_k(q-\theta_0^{\top} x_t)|\mathbb{I}(\mathcal{E}_k)}}+ \underset{=C}{\underbrace{|S_{k}(q-\theta_0^{\top} x_t)-S_0(q-\theta_0^{\top} x_t)|\mathbb{I}(\mathcal{E}_k)}}
\end{align}

\textbf{Analyzing $A$ on $\mathcal{E}_k$:} Define the event $\mathcal{S}_k = \{ \sup_{u \in \mathcal{U}}|\widehat{S}_{k}(u)-S_{k}(u)|\leq C \rho_{\widetilde{n}_k}^{\alpha/(2\alpha+1)}\}$, where $\rho_n = \log(n) /n$. For $n_{k}$ sufficiently large, by \cref{thm:Dumbgen} we have that 
\begin{align*}
\mathbb{E}(A) &= \mathbb{E}(A\mathbb{I}(\mathcal{S}_k, \cap \mathcal{E}_k)) + \mathbb{E}(A\mathbb{I}(\mathcal{S}_k^c \cap \mathcal{E}_k)) \\
&\leq \mathbb{E}\left(\sup_{u \in \mathcal{U}}|\widehat{S}_{k}(u)-S_{k}(u)|\mathbb{I}(\mathcal{S}_k \cap \mathcal{E}_k)\right) + 2\mathbb{P}(\mathcal{S}_k^c)\mathbb{P}(\mathcal{E}_k)\\
&\lesssim C \left(\frac{\log \widetilde{n}_k}{\widetilde{n}_k}\right)^{\alpha/(2\alpha+1)}\mathbb{P}(\mathcal{S}_k \cap \mathcal{E}_k)+ 2\mathbb{P}(\mathcal{S}_k^c)\\
&\lesssim  \left(\frac{\log \widetilde{n}_k}{\widetilde{n}_k}\right)^{\alpha/(2\alpha+1)}+ 2\frac{1}{\widetilde{n}_k^{\gamma-2}}\\
&\lesssim \left(\frac{\log \widetilde{n}_k}{\widetilde{n}_k}\right)^{\alpha/(2\alpha+1)},
\end{align*}
where we chose $\gamma \geq 3$.

\textbf{Analyzing $B$ on $\mathcal{E}_k$:}
By \cref{proposition:S_theta_properties}, $S_k$ is $\alpha$-H\"older, then $\mathbb{E}[B\mathbb{I}(\mathcal{E}_k)]\lesssim \|\widehat{\theta}_k-\theta_0\|_2^{\alpha} \leq R_{n_k}^{\alpha}$. 

\textbf{Analyzing $C$ on $\mathcal{E}_k$:}
By \cref{proposition:S_theta_properties} we have $|S_{k}(u)-S_0(u)|\mathbb{I}(\mathcal{E}_k) \lesssim \|\widehat{\theta}_k-\theta_0\|_2^{\alpha} \leq R_{n_k}^{\alpha}$.

\textbf{Combining the terms $R_{k,t}(q)\mathbb{I}(\mathcal{E}_k^c)$ and $R_{k,t}(q)\mathbb{I}(\mathcal{E}_k)$ from \cref{ineq:lemma_groeneboom}:} we get

$$
\sup_{q}R_{k,t}(q) \lesssim \left(\frac{\log \widetilde{n}_k}{\widetilde{n}_k}\right)^{\alpha/(2\alpha+1)}+ \left(\frac{d\log n_k}{n_k}\right)^{\alpha/2}.
$$


\newpage
\section{Additional Plots of \cref{sec:simulation_theoretical}}\label{Appendix:other_plots}

\begin{figure}[h]
    \centering
    \vspace{.05in}
    \includegraphics[width=0.45\textwidth]{Pics/Regret_simulation_Fan.png}
    \vspace{.05in}
    \caption{This plot was generated using as true $F_0$ the one considered in \citet{fan2021policy} with density $f_0(z) = 6\left(\frac{1}{4} -z^2\right)\mathbf{1}\{z\in(-1/2,1/2)\}$. We repeated the simulation 36 times and the corresponding 95\% confidence interval. The plot is in $\log_2$-$\log_2$ scale to show the regret rate (empirical slope): a slope of $\eta$ indicated an $\mathcal{O}(T^{\eta})$ regret. The black dashed line corresponds to our theoretical regret upper bound of $3/4$. The estimated slope is very close to that value.}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \newpage

% \section{Minimiax for $\alpha$-Holder error noise distribution $F_0$}

% Before the proof begins, we make some necessary definitions. First of all, define a bump function for $v \in \mathbb{R}+$, we define

% $$
% B(v) = \begin{cases}0 & v \in(-\infty, 0] \cup[1,+\infty) \\ \exp \left\{\frac{1}{(3 v-1)^2-1}\right\} & v \in(0,1 / 3) \\ 1 & v \in[1 / 3,2 / 3] \\ \exp \left\{\frac{1}{(3 v-2)^2-1}\right\} & v \in(2 / 3,1) \\ 0 & v \in[1,+\infty)\end{cases}
% $$
% as a basic bump function. Then we define a rescaled bump function:
% $$
% B_{[a, b]}(v)=B\left(\frac{v-a}{b-a}\right)
% $$

% Secondly, we define a series of intervals $[0,1]=\left[a_0, b_0\right] \supset\left[a_1, b_1\right] \supset \ldots \supset\left[a_k, b_k\right] \supset \ldots$, where $b_k=a_k+w_k, w_k=3^{-k!}$. Notice that $w_k$ shrinks even faster than the exponential series. Now we describe how to choose $\left[a_k, b_k\right]$ from $\left[a_{k-1}, b_{k-1}\right]$: We divide the range $\left[a_{k-1}+\frac{w_{k-1}}{3}, b_{k-1}+\frac{w_{k-1}}{3}\right]$ into $Q_k=\frac{w_{k-1}}{3 w_k}$ sub-intervals of the same length $w_k$, and then we pick one of these sub-intervals uniformly at random and denote it as $\left[a_k, b_k\right]$. It is trivial to see that $\left[a_1, b_1\right]=\left[\frac{1}{3}, \frac{2}{3}\right],\left[a_2, b_2\right]=\left[\frac{4}{9}, \frac{5}{9}\right]$.

% Thirdly, we define a function:
% $$
% f(v)\triangleq C_{f} \sum_{k=0}^{\infty} w_k^{\beta}  B_{\left[a_k, b_k\right]}(v)
% $$

% where $C_{f}>0$ is a constant we will determine later. Now we define another function $G(v)$ :
% $$
% G(v)=1-\frac{1}{f(v)+1}, v \in[0,1] .
% $$

% Notice that $G(v)$ is not necessarily a revenue curve, since $\frac{G(v)}{v}$ is not necessarily decreasing (and thus not a ``survival function"). However, we can construct a revenue curve $D(v):[0,1] \rightarrow [0,1]$ via an affine transformation:

% $$
% D(v) \triangleq \begin{cases}v & v \in[0, b] \\ b+(1-b) G\left(\frac{v-b}{1-b}\right) & v \in(b, 1]\end{cases}
% $$

% Here $b\in(0,1)$ {\bf will be determined later}. The monotonicity in each interval is not changed, while the rate of $d(v)\triangleq \frac{D(v)}{v}$ is non-increasing after these transformations. As mentioned above, the homothetic transformation with center $(1,1)$ ensures a non-increasing property of $d(v)$. To show that $D(v)$ is a revenue curve, we expand the definition of $d(v)$ to $\mathbb{R}$ as follows:

% $$
% d(v)= \begin{cases}1 & v \in(-\infty, 0] \\ \frac{D_{\alpha}(v)}{v} & v \in(0,1) \\ 0 & v \in[1,+\infty)\end{cases}
% $$

% Now we claim that $d$ is a Lipschitz survival function, i.e. there exists a random variable $Y>0$ such that $d(v)=\mathbb{P}[Y \geq v]$. As a consequence, for any $\alpha \in (0,1]$, $d_{\alpha}(v) \triangleq d^{\alpha}(v)$ is a $\alpha$-H\"older survival function. Notice that there is a bijection between each $\left\{\left[a_k, b_k\right]\right\}_{k=0}^{\infty}$ series and each $f(v)$, and correspondingly each $G(v), D(v),d(v).d_{\alpha}(v)$. Still, a bijection lies between each $d_{\alpha}(v)$ and the distribution $\mathbb{P}_{\alpha}[Y \geq v]$ of the customers' valuation. Therefore, we will take $1-d_{\alpha}(v)$ to represent this distribution.

% \subsection{PROOF}
% With all the preparations done above, we are now able to prove the Theorem. Specifically, we will prove the theorem on an infinite series of $n_1, n_2, \ldots$, where $n_k=\left\lceil\frac{1}{k}\left(\frac{w_{k-1}}{w_k^3}\right)\right\rceil$. Consider the possible $Q_k=\frac{w_{k-1}}{3 w_k}$ choices of $\left[a_k, b_k\right]$, and denote these intervals as $I_j, j=1,2, \ldots, Q_k$. If $\left[a_k, b_k\right]=I_j$, then we denote the corresponding $f_{\alpha}(v), G_{\alpha}(v), D_{\alpha}(v), d_{\alpha}(v)$ functions as $f_{\alpha,j}(v), G_{\alpha,j}(v), D_{\alpha,j}(v)$ and $d_{\alpha,j}(v)$ sequentially. Meanwhile, if we do not make any choice of $\left[a_k, b_k\right]$, and then we just have a finite series of intervals $[0,1]=\left[a_0, b_0\right] \supset\left[a_1, b_1\right] \supset$ $\left[a_2, b_2\right] \supset \ldots \supset\left[a_{k-1}, b_{k-1}\right]$, and then we can define a $f_{\alpha,0}(v)=C_{\alpha,0} \sum_{j=0}^{k-1} w_j B_{\alpha,\left[a_j, b_j\right]}(v)$, and can also define corresponding $G_{\alpha,0}(v), D_{\alpha,0}(v), d_{\alpha,0}(v)$ based on $f_{\alpha,0}(v)$.
% Now, consider the pricing feedback in total $n$ rounds (where we denote $n_k$ as $n$ for simplicity). Define a feedback vector $\mathbf{r}_n \in\{0,1\}^n$, denoting the outcome of a deterministic policy interacting with the revenue curve. We claim that for $t=1,2, \ldots, n$, a vector $\mathbf{r}_t \in \{0,1\}^n$ is sufficient for any deterministic policy to generate a price $v_{t+1}$, because $\mathbf{r}_i$ is a prefix of $\mathbf{r}_j$ when $i \leq j$. For any policy $\pi$, denote the probability of $\mathbf{r}_n$'s occurrence as $\mathbb{P}_{\alpha,j}\left(\mathbf{r}_n\right)$ under the distribution $d_{\alpha,j}$, or $\mathbb{P}_{\alpha,0}\left(\mathbf{r}_n\right)$ under the distribution $d_{\alpha,0}$. Denote the series of prices that $\pi$ has generated as $\left\{v_t\right\}, t=1,2, \ldots, n$, and we may assume $v_t \geq b$ without losing generality (as $0 \leq v<b$ is always suboptimal). Then, for any function $h:\{0,1\}^n \rightarrow[0, M]$, we have:

% $$
% \begin{aligned}
% \mathbb{E}_{\mathbb{P}_j}\left[h\left(\mathbf{r}_n\right)\right]-\mathbb{E}_{\mathbb{P}_0}\left[h\left(\mathbf{r}_n\right)\right]  = & \sum_{\mathbf{r}_n} h\left(\mathbf{r}_n\right) \cdot\left(\mathbb{P}_j\left[\mathbf{r}_n\right]-\mathbb{P}_0\left[\mathbf{r}_n\right]\right) \\
% \leq & \sum_{\mathbf{r}_n: \mathbb{P}_j\left\{\mathbf{r}_n\right] \geq \mathbb{P}_0\left[\mathbf{r}_n\right]} h\left(\mathbf{r}_n\right)\left(\mathbb{P}_j\left[\mathbf{r}_n\right]-\mathbb{P}_0\left[\mathbf{r}_n\right]\right) \\
% \leq & M \cdot \sum_{\mathbf{r}_n: \mathbb{P}_j\left[\mathbf{r}_n\right] \geq \mathbb{P}_0\left[\mathbf{r}_n\right]} h\left(\mathbf{r}_n\right)\left(\mathbb{P}_j\left[\mathbf{r}_n\right]-\mathbb{P}_0\left[\mathbf{r}_n\right]\right) \\
% = & \frac{M}{2}\left\|\mathbb{P}_j-\mathbb{P}_0\right\|_1 \\
% \leq & \frac{M}{2} \sqrt{2 \ln 2 \cdot K L\left(\mathbb{P}_0 \| \mathbb{P}_j\right)} .
% \end{aligned}
% $$


% The last line comes from Lemma 11.6.1 in Cover \& Thomas, Elements of Information Theory, where $K L$ stands for the KL-divergence. Since

% $$
% \begin{aligned}
% K L\left(\mathbb{P}_0\left(\mathbf{r}_n\right) \| \mathbb{P}_j\left(\mathbf{r}_n\right)\right) & =\sum_{t=1}^n K L\left(\mathbb{P}_0\left[r_t \mid \mathbf{r}_{t-1}\right] \| \mathbb{P}_j\left[r_t \mid \mathbf{r}_{t-1}\right]\right) \\
% & =\sum_{t=1}^t \mathbb{P}_0\left(\frac{v_t-b}{1-b} \notin I_j\right) \cdot 0+\mathbb{P}_0\left(\frac{v_t-b}{1-b} \in I_j\right) \cdot K L\left(d_{\alpha,0}(v_t) \| d_{\alpha,j}(v_t)\right) .
% \end{aligned}
% $$


% The first equality comes from the chain rule of decomposing a KL-divergence. The second equality is because $r_t$ is a Bernoulli random variable that satisfies $\operatorname{Ber}\left(d_{\alpha,0}(v_t)\right)$ under $\mathbb{P}_0$, or $\operatorname{Ber}\left(d_{\alpha,j}(v_t)\right)$ under $\mathbb{P}_j$. 

% \subsubsection{Bound $KL$}

% By \citet{xu2022towards}[Lemma 16], for Bernoulli distributions $\operatorname{Ber}(p)$ and $\operatorname{Ber}(p+\epsilon)$ with $\frac{1}{2} \leq p \leq p+\epsilon \leq \frac{1}{2}+C$, we have
% $$
% K L(p \| p+\epsilon) \leq \frac{1}{\ln 2} \frac{4}{1-4 C^2} \epsilon^2
% $$

% To apply this result in out case, denote $\mu_t\triangleq\frac{v_t-b}{1-b}$ for simplicity. Notice that if $v_t \in I_j$, then we have:

% $$
% \begin{aligned}
% \frac{D_j\left(v_t\right)}{v_t}-\frac{D_0\left(v_t\right)}{v_t} & =\frac{(1-b) \cdot G_j\left(\mu_t\right)}{v_t}-\frac{(1-b) \cdot G_0\left(\mu_t\right)}{v_t} \\
% & =\frac{1-b}{v_t}\left(G_j\left(\mu_t\right)-G_0\left(\mu_t\right)\right) \\
% & =\frac{1-b}{v_t}\left(\frac{1}{f_0\left(\mu_t\right)+1}-\frac{1}{f_j\left(\mu_t\right)+1}\right) \\
% & =\frac{1-b}{v_t} \frac{f_j\left(\mu_t\right)-f_0\left(\mu_t\right)}{\left(f_0\left(\mu_t\right)+1\right)\left(f_j\left(\mu_t\right)+1\right)} \\
% & =\frac{1-b}{v_t} \frac{C_f \sum_{i=k}^{\infty} w_i^{\beta} \cdot B_{\left[a_i, b_i\right]}\left(\mu_t\right)}{\left(f_0\left(\mu_t\right)+1\right)\left(f_j\left(\mu_t\right)+1\right)} \\
% & \leq \frac{1-b}{b} \cdot \frac{C_f \cdot 2 w_k^{\beta}}{1 \times 1} \\
% & \leq 1 \cdot 2 C_f w_k^{\beta} \\
% & \leq \frac{w_k^{\beta}}{3}
% \end{aligned}
% $$

% Here the third last inequality comes from $v_t \geq b, f_0(v) \geq 0, f_j(v) \geq 0$, and the fact that

% $$
% \sum_{i=k}^{\infty} w_i^{\beta} B_{\left[a_i, b_i\right]}\left(\mu_t\right) \leq \sum_{i=k}^{\infty} 3^{-\beta i!} \cdot 1 \leq 3^{-\beta k!} \sum_{i=0}^{\infty} 3^{-\beta i} \lesssim  3^{-\beta k!} = w_k^{\beta}
% $$

% The second last inequality comes from $b=\frac{6 C_f+1}{2} \geq \frac{1}{2}$. The latest inequality comes from the fact that $6 C_f<1$. Then $d_{\alpha,j}(v_t)-d_{\alpha,0}(v) \leq w_k^{\alpha\beta}$. Then we take the $\epsilon$ as $\epsilon \lesssim w_k^{\alpha\beta}$. For choosing $C$ note that since $d_0(v_t) \geq b \geq \frac{1}{2}$, and the fact that

% $$
% \begin{aligned}
% d_j(v_t) & \leq d_j(b+\frac{1-b}{3}) \\
% & = \frac{D_j\left(b+\frac{1-b}{3}\right)}{b+\frac{1-b}{3}} \\
% & =3 \cdot \frac{b+(1-b)\left(1-G_j\left(\frac{1}{3}\right)\right)}{1+2 b} \\
% & =3 \frac{b+(1-b) \frac{f_j\left(\frac{1}{3}\right)}{f_j\left(\frac{1}{3}\right)+1}}{1+2 b} \\
% & =3 \frac{b+(1-b) \frac{C_f}{C_f+1}}{1+2 b}
% \end{aligned}
% $$

% we can choose $C^{\alpha} \leftarrow 3 \frac{b+(1-b) \frac{C_f}{C_f+1}}{1+2 b}$. The first inequality is because $\frac{D(v)}{v}$ is non-increasing and the fact that $v_t \geq b+\frac{1-b}{3}$ if $v_t \in\left[a_k, b_k\right], k \geq 1$. The last equality comes from the fact that $f_j\left(\frac{1}{3}\right)=C_f$. Now we specify the constants: let $C_f=\frac{1}{60}, b=\frac{6 C_f+1}{2}=\frac{11}{20}$. Plug in these constant values and we get:

% $$
% \frac{D_j\left(v_t\right)}{v_t} \leq \frac{340}{427}<\frac{5}{6}
% $$


% According to Lemma 16, we have:

% $$
% K L\left(\frac{D_0\left(v_t\right)}{v_t} \| \frac{D_j\left(v_t\right)}{v_t}\right) \leq \frac{1}{\ln 2}  \frac{4}{1-4 \left(\frac{5}{6}-\frac{1}{2}\right)^2} \left(\frac{w_k^{\alpha\beta}}{3}\right)^2=\frac{1}{\ln 2}  \frac{36}{5} \frac{w_k^{2\alpha\beta}}{9}=\frac{1}{\ln 2} \frac{4 w_k^{2\alpha\beta}}{5}
% $$

% \subsubsection{Go back to the total regret bound}

% $$
% \begin{aligned}
% K L\left(\mathbb{P}_0\left(\mathbf{r}_n\right) \| \mathbb{P}_j\left(\mathbf{r}_n\right)\right)
% = \sum_{t=1}^t \mathbb{P}_0\left(\frac{v_t-b}{1-b} \in I_j\right)  K L\left(\frac{D_0\left(v_t\right)}{v_t} \| \frac{D_j\left(v_t\right)}{v_t}\right) 
% \leq \frac{1}{\ln 2}  \frac{4}{5} w_k^{2\alpha\beta}  \sum_{t=1}^n \mathbb{P}_0\left[\mu_t \in I_j\right] .
% \end{aligned}
% $$


% Therefore, we have:

% $$
% \begin{aligned} \mathbb{E}_{\mathbb{P}_j}\left[h\left(\mathbf{r}_n\right)\right]-\mathbb{E}_{\mathbb{P}_0}\left[h\left(\mathbf{r}_n\right)\right] \leq & \frac{M}{2} \sqrt{2 \ln 2 \frac{1}{\ln 2} \frac{4 w_k^{2\alpha\beta}}{5} \cdot \sum_{t=1}^n \mathbb{P}_0\left[\mu_t \in I_j\right]} \\
% \leq & M w_k^{\alpha\beta} \frac{2\sqrt{2}}{\sqrt{5}} \sqrt{\sum_{t=1}^n \mathbb{P}_0\left[\mu_t \in I_j\right] .}
% \end{aligned}
% $$


% Now, let $h\left(\mathbf{r}_n\right)$ be $N_{j,k}=\left|\left\{t : \mu_t \in I_j, t=1,2, \ldots, n_k\right\}\right|$, and we know that $M=n_k$. Since $n_k=\left\lceil\frac{1}{k} \frac{w_{k-1}}{w_k^k}\right\rceil$, we conduct the pricing for $n_k$ times and have:

% $$
% \mathbb{E}_{\mathbb{P}_j}\left[N_{j,k}\right]-\mathbb{E}_{\mathbb{P}_0}\left[N_{j,k}\right] \leq \frac{2\sqrt{2}}{\sqrt{5}} n_k w_k^{\alpha\beta} \sqrt{\sum_{t=1}^n \mathbb{P}_0\left[\mu_t \in I_j\right]}=\frac{2\sqrt{2}}{\sqrt{5}} n_k w_k^{\alpha\beta} \sqrt{\mathbb{E}_{\mathbb{P}_0}\left[N_{j,k}\right]} .
% $$


% Sum over $j=1,2, \ldots, Q_k$ of the inequality above, and we take an average to get:

% $$
% \begin{aligned}
% \frac{1}{Q_k} \sum_{j=1}^{Q_k} \mathbb{E}_{\mathbb{P}_j}\left[N_{j,k}\right] & \lesssim \frac{1}{Q_k} \sum_{j=1}^{Q_k} \mathbb{E}_{\mathbb{P}_0}\left[N_{j,k}\right]+\frac{1}{Q_k} n_k w_k^{\alpha\beta}\sum_{j=1}^{Q_k} \sqrt{\mathbb{E}_{\mathbb{P}_0}[N_{j,k}]} \\
% & =\frac{n_k}{Q_k}+\frac{1}{Q_k} n_k w_k^{\alpha\beta} \sum_{j=1}^{Q_k} \sqrt{\mathbb{E}_{\mathbb{P}_0}\left[N_{j,k}\right]} \\
% & \leq \frac{n_k}{Q_k}+ \frac{1}{Q_k} n_k w_k^{\alpha\beta} \sqrt{Q_k  \sum_{j=1}^{Q_k} \mathbb{E}_{\mathbb{P}_0}\left[N_{j,k}\right]} \\
% & =\frac{n_k}{Q_k}+ \frac{1}{Q_k} n_k w_k^{\alpha\beta}  \sqrt{Q_k n_k}\\
% &=n_k \left(\frac{1}{Q_k}+\sqrt{\tfrac{n_k}{Q_k}}w^{\alpha\beta} \right)
% \end{aligned}
% $$

% The first line comes from the summation; the second (and the fourth) line is because $\sum_{j=1}^{Q_k} \mathbb{E}_{\mathbb{P}_0}\left[N_j\right]=\mathbb{E}_{\mathbb{P}_0}\left[\sum_{j=1}^{Q_k} N_j\right]=n_k$; the third line is an application of Cauchy Schwartz's Inequality. Now, using that for every $\gamma>0$ $\frac{w_{k-1}}{w_k^{\gamma}} = 3^{-(k-1)!+\gamma k!}= 3^{-\tfrac{k!}{k}+\gamma k!} = 3^{-k!(\tfrac{1}{k}-\gamma)}= w_k^{\nicefrac{1}{k}-\gamma}$ we have
% \begin{align*}
% w_k&=3^{-k!},\\
% Q_k&=\frac{w_{k-1}}{3 w_k} = \frac{1}{3}w_k^{\nicefrac{1}{k}-1} \rightarrow \infty, \quad k \rightarrow \infty\\ 
% n_k&=\left\lceil\frac{1}{k}\left(w_{k-1} / w_k\right) w_k^{-2 \alpha}\right\rceil
% \leq\frac{1}{k} \frac{w_{k-1}}{w_k^{2\alpha +1}}=\frac{1}{k}w_k^{\nicefrac{1}{k}-(2\alpha+1)}
% \end{align*}

% and then
% $$
% \begin{aligned}
% \sqrt{\tfrac{n_k}{Q_k}}w^{\alpha\beta} = w_k^{\tfrac{1}{2} [\nicefrac{1}{k}-(2\alpha+1)-\nicefrac{1}{k}+1]+\alpha \beta} = w_k^{-\alpha+\alpha \beta} = w_k^{\alpha(\beta-1)}\rightarrow 0,\quad k\rightarrow \infty\quad \text{for any fixed }\beta \in (0,1)
% \end{aligned}
% $$
% and for $\beta=1$, $\sqrt{\tfrac{n_k}{Q_k}}w^{\alpha\beta}=1$. Then 

% $$
% \frac{1}{Q_k} \sum_{j=1}^{Q_k} \mathbb{E}_{\mathbb{P}_j}\left[N_{j,k}\right] \lesssim n_k
% $$
% for $k$ sufficiently large. Therefore, under distribution $d_j$, the policy $\pi$ is expected to choose an $v_t \notin I_j$ for at least $0.1 n_k$ times, which will bring a regret $n_k w_k^{\beta}=\frac{1}{k} w_k^{\frac{1}{k}-(2\alpha+1)+\beta}$. Since $w_k=(k n_k)^{1/(\nicefrac{1}{k}-(2\alpha+1))}$, we know that 

% $$
% \text{Regret}=\Omega\left(n_k^{\frac{2\alpha+1-\beta-\nicefrac{1}{k}}{2\alpha+1-\nicefrac{1}{k}}}\right)
% $$
% up to logarithmic factors. Therefore, we claim that for any $\delta>0$, no policy can achieve $o\left(n_k^{\frac{2}{3}-\delta}\right)$ for sufficiently large $k$.
% This ends the proof of Theorem 7.
\end{document}
