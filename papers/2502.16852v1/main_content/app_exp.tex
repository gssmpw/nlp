\section{Additional Experiment Details}
For the implementation of ONPO, we follow the hyperparameters in \citet{dong2024rlhf}, including the cosine learning rate scheduler with a peak learning rate of $5 \times 10^{-7}$, a 0.03 warm-up ratio, and a global batch size of 128. We use a grid search for $1/\eta$ over $[0.1, 0.05, 0.02, 0.01, 0.005]$ and set $1/\eta = 0.01$. Llama-3-SFT is trained for 5 iterations, while Mistral-Instruct, having already undergone instruction fine-tuning, is thereby trained for 3 iterations.
