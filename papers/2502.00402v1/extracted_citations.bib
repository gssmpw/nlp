@article{adewopo2024smart,
	title = {Smart City Transportation: Deep Learning Ensemble Approach for Traffic Accident Detection},
	volume = {12},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/abstract/document/10497566},
	doi = {10.1109/ACCESS.2024.3387972},
	shorttitle = {Smart City Transportation},
	abstract = {The dynamic and unpredictable nature of road traffic necessitates effective accident detection methods for enhancing safety and streamlining traffic management in smart cities. This paper offers a comprehensive exploration study of prevailing accident detection techniques, shedding light on the nuances of other state-of-the-art methodologies while providing a detailed overview of distinct traffic accident types like rear-end collisions, T-bone collisions, and frontal impact accidents. Our novel approach introduces the I3D-{CONVLSTM}2D model architecture, a lightweight solution tailored explicitly for accident detection in smart city traffic surveillance systems by integrating {RGB} frames with optical flow information. Empirical analysis of our experimental study underscores the efficacy of our model architecture. The I3D-{CONVLSTM}2D {RGB} + Optical-Flow (trainable) model outperformed its counterparts, achieving an impressive 87\% Mean Average Precision ({MAP}). Our findings further elaborate on the challenges posed by data imbalances, particularly when working with a limited number of datasets, road structures, and traffic scenarios. Ultimately, our research illuminates the path towards a sophisticated vision-based accident detection system primed for real-time integration into edge {IoT} devices within smart urban infrastructures.},
	pages = {59134--59147},
	journaltitle = {{IEEE} Access},
	author = {Adewopo, Victor A. and Elsayed, Nelly},
	urldate = {2025-01-31},
	date = {2024},
	note = {Conference Name: {IEEE} Access},
	keywords = {accident detection, Accidents, action recognition, autonomous transportation, Autonomous vehicles, Cameras, Computer architecture, deep learning, Deep learning, Feature extraction, Road traffic, Smart cities, smart city, Traffic control, Traffic surveillance},
	file = {Full Text PDF:/home/walter/snap/zotero-snap/common/Zotero/storage/U84I9SZ6/Adewopo and Elsayed - 2024 - Smart City Transportation Deep Learning Ensemble Approach for Traffic Accident Detection.pdf:application/pdf},
}

@inproceedings{dosovitskiy_carla_2017,
	title = {{CARLA}: An Open Urban Driving Simulator},
	url = {https://proceedings.mlr.press/v78/dosovitskiy17a.html},
	shorttitle = {{CARLA}},
	abstract = {We introduce {CARLA}, an open-source simulator for autonomous driving research. {CARLA} has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, {CARLA} provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use {CARLA} to study the performance of three approaches to autonomous driving: a classic modular pipeline, an end-to-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by {CARLA}, illustrating the platform’s utility for autonomous driving research.},
	eventtitle = {Conference on Robot Learning},
	pages = {1--16},
	booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
	publisher = {{PMLR}},
	author = {Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
	urldate = {2024-07-13},
	date = {2017-10-18},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:/home/walter/snap/zotero-snap/common/Zotero/storage/7XW28GN4/Dosovitskiy et al. - 2017 - CARLA An Open Urban Driving Simulator.pdf:application/pdf},
}

@article{fang_vision-based_2024,
	title = {Vision-Based Traffic Accident Detection and Anticipation: A Survey},
	volume = {34},
	issn = {1558-2205},
	url = {https://ieeexplore.ieee.org/abstract/document/10227352?casa_token=x2ah_M1pw5YAAAAA:Gt5ODqQktvDbYv5bJC7LFu3iHBFgIxgLeX4ZuQECbCYYJdt4SmsFBiQPCFKbX79Ry7MDWpX8},
	doi = {10.1109/TCSVT.2023.3307655},
	shorttitle = {Vision-Based Traffic Accident Detection and Anticipation},
	abstract = {Traffic accident detection and anticipation is an obstinate road safety problem and painstaking efforts have been devoted. With the rapid growth of video data, Vision-based Traffic Accident Detection and Anticipation (named Vision-{TAD} and Vision-{TAA}) become the last one-mile problem for safe driving and surveillance safety. However, the long-tailed, unbalanced, highly dynamic, complex, and uncertain properties of traffic accidents form the Out-of-Distribution ({OOD}) feature for Vision-{TAD} and Vision-{TAA}. Current {AI} development may focus on these {OOD} but important problems. What has been done for Vision-{TAD} and Vision-{TAA}? What direction we should focus on in the future for this problem? A comprehensive survey is important. We present the first survey on Vision-{TAD} in the deep learning era and the first-ever survey for Vision-{TAA}. The pros and cons of each research prototype are discussed in detail during the investigation. In addition, we also provide a critical review of 31 publicly available benchmarks and related evaluation metrics. Through this survey, we want to spawn new insights and open possible trends for Vision-{TAD} and Vision-{TAA} tasks.},
	pages = {1983--1999},
	number = {4},
	journaltitle = {{IEEE} Transactions on Circuits and Systems for Video Technology},
	author = {Fang, Jianwu and Qiao, Jiahuan and Xue, Jianru and Li, Zhengguo},
	urldate = {2025-01-31},
	date = {2024-04},
	note = {Conference Name: {IEEE} Transactions on Circuits and Systems for Video Technology},
	keywords = {Accidents, Anomaly detection, autoencoder, Benchmark testing, benchmarks, Roads, safe driving, Surveillance, surveillance safety, Surveys, Traffic accident detection and anticipation, Uncertainty},
}

@inproceedings{greer2023pedestrian,
  title={Pedestrian Behavior Maps for Safety Advisories: CHAMP Framework and Real-World Data Analysis},
  author={Greer, Ross and Desai, Samveed and Rakla, Lulua and Gopalkrishnan, Akshay and Alofi, Afnan and Trivedi, Mohan},
  booktitle={2023 IEEE Intelligent Vehicles Symposium (IV)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@article{greer2024towards,
  title={Towards explainable, safe autonomous driving with language embeddings for novelty identification and active learning: Framework and experimental analysis with real-world data sets},
  author={Greer, Ross and Trivedi, Mohan},
  journal={arXiv preprint arXiv:2402.07320},
  year={2024}
}

@article{liu2024survey,
  title={A survey on autonomous driving datasets: Statistics, annotation quality, and a future outlook},
  author={Liu, Mingyu and Yurtsever, Ekim and Fossaert, Jonathan and Zhou, Xingcheng and Zimmer, Walter and Cui, Yuning and Zagar, Bare Luka and Knoll, Alois C},
  journal={IEEE Transactions on Intelligent Vehicles},
  year={2024},
  publisher={IEEE}
}

@inproceedings{maaloul_adaptive_2017,
	title = {Adaptive video-based algorithm for accident detection on highways},
	url = {https://ieeexplore.ieee.org/abstract/document/7993382?casa_token=0_OuIy9Y2hkAAAAA:LD6ZOqIxgjrGLuTARIOBccmy0dezii7H06Ap84daHM_Kut9bzgGdBd9X9n7gPlamTYPhCTGO},
	doi = {10.1109/SIES.2017.7993382},
	abstract = {For the past few decades, automatic accident detection, especially using video analysis, has become a very important subject. It is important not only for traffic management but also, for Intelligent Transportation Systems ({ITS}) through its contribution to avoid the escalation of accidents especially on highways. In this paper a novel vision-based road accident detection algorithm on highways and expressways is proposed. This algorithm is based on an adaptive traffic motion flow modeling technique, using Farneback Optical Flow for motions detection and a statistic heuristic method for accident detection. The algorithm was applied on a set of collected videos of traffic and accidents on highways. The results prove the efficiency and practicability of the proposed algorithm using only 240 frames for traffic motion modeling. This method avoids to utilization of a large database while adequate and common accidents videos benchmarks do not exist.},
	eventtitle = {2017 12th {IEEE} International Symposium on Industrial Embedded Systems ({SIES})},
	pages = {1--6},
	booktitle = {2017 12th {IEEE} International Symposium on Industrial Embedded Systems ({SIES})},
	author = {Maaloul, Boutheina and Taleb-Ahmed, Abdelmalik and Niar, Smail and Harb, Naim and Valderrama, Carlos},
	urldate = {2025-01-31},
	date = {2017-06},
	note = {{ISSN}: 2150-3117},
	keywords = {Abnormal behavior detection, Accident detection, Accidents, Computational modeling, computer vision, Farneback optical flow, Feature extraction, Intelligent Transportation Systems, {ITS}, Motion detection, Roads, Tracking, video processing, video surveillance},
	file = {Full Text PDF:/home/walter/snap/zotero-snap/common/Zotero/storage/RP7AG9BW/Maaloul et al. - 2017 - Adaptive video-based algorithm for accident detection on highways.pdf:application/pdf},
}

@article{pirdavani_application_2015,
	title = {Application of a Rule-Based Approach in Real-Time Crash Risk Prediction Model Development Using Loop Detector Data},
	volume = {16},
	issn = {1538-9588},
	url = {https://doi.org/10.1080/15389588.2015.1017572},
	doi = {10.1080/15389588.2015.1017572},
	abstract = {Objectives: There is a growing trend in development and application of real-time crash risk prediction models within dynamic safety management systems. These real-time crash risk prediction models are constructed by associating crash data with the real-time traffic surveillance data (e.g., collected by loop detectors). The main objective of this article is to develop a real-time risk model that will potentially be utilized within traffic management systems. This model aims to predict the likelihood of crash occurrence on motorways. Methods: In this study, the potential prediction variables are confined to traffic-related characteristics. Given that the dependent variable (i.e., traffic safety condition) is dichotomous (i.e., “no-crash” or “crash”), a rule-based approach is considered for model development. The performance of rule-based classifiers is further compared with the more conventional techniques like binary logistic regression and decision trees. The crash and traffic data used in this study were collected between June 2009 and December 2011 on a part of the E313 motorway in Belgium between Geel-East and Antwerp-East exits, on the direction toward Antwerp. Results: The results of analysis show that several traffic flow characteristics such as traffic volume, average speed, and standard deviation of speed at the upstream loop detector station and the difference in average speed on upstream and downstream loop detector stations significantly contribute to the crash occurrence prediction. The final chosen classifier is able to predict 70\% of crash occasions accurately, and it correctly predicts 90\% of no-crash instances, indicating a 10\% false alarm rate. Conclusions: The findings of this study can be used to predict the likelihood of crash occurrence on motorways within dynamic safety management systems.},
	pages = {786--791},
	number = {8},
	journaltitle = {Traffic Injury Prevention},
	author = {Pirdavani, Ali and De Pauw, Ellen and Brijs, Tom and Daniels, Stijn and Magis, Maarten and Bellemans, Tom and Wets, Geert},
	urldate = {2025-01-31},
	date = {2015-11-17},
	pmid = {25793926},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/15389588.2015.1017572},
	keywords = {dynamic safety management systems, real-time crash risk prediction, rule-based classifiers, traffic surveillance data},
}

@inproceedings{wang2024deepaccident,
  title={Deepaccident: A motion and accident prediction benchmark for v2x autonomous driving},
  author={Wang, Tianqi and Kim, Sukmin and Wenxuan, Ji and Xie, Enze and Ge, Chongjian and Chen, Junsong and Li, Zhenguo and Luo, Ping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={6},
  pages={5599--5606},
  year={2024}
}

@misc{xu2022tad,
	title = {{TAD}: A Large-Scale Benchmark for Traffic Accidents Detection from Video Surveillance},
	url = {http://arxiv.org/abs/2209.12386},
	doi = {10.48550/arXiv.2209.12386},
	shorttitle = {{TAD}},
	abstract = {Automatic traffic accidents detection has appealed to the machine vision community due to its implications on the development of autonomous intelligent transportation systems ({ITS}) and importance to traffic safety. Most previous studies on efficient analysis and prediction of traffic accidents, however, have used small-scale datasets with limited coverage, which limits their effect and applicability. Existing datasets in traffic accidents are either small-scale, not from surveillance cameras, not open-sourced, or not built for freeway scenes. Since accidents happened in freeways tend to cause serious damage and are too fast to catch the spot. An open-sourced datasets targeting on freeway traffic accidents collected from surveillance cameras is in great need and of practical importance. In order to help the vision community address these shortcomings, we endeavor to collect video data of real traffic accidents that covered abundant scenes. After integration and annotation by various dimensions, a large-scale traffic accidents dataset named {TAD} is proposed in this work. Various experiments on image classification, object detection, and video classification tasks, using public mainstream vision algorithms or frameworks are conducted in this work to demonstrate performance of different methods. The proposed dataset together with the experimental results are presented as a new benchmark to improve computer vision research, especially in {ITS}.},
	number = {{arXiv}:2209.12386},
	publisher = {{arXiv}},
	author = {Xu, Yajun and Huang, Chuwen and Nan, Yibing and Lian, Shiguo},
	urldate = {2024-11-13},
	date = {2022-09-26},
	eprinttype = {arxiv},
	eprint = {2209.12386},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:/home/walter/snap/zotero-snap/common/Zotero/storage/HBHNUTRW/Xu et al. - 2022 - TAD A Large-Scale Benchmark for Traffic Accidents Detection from Video Surveillance.pdf:application/pdf},
}

@article{yang_freeway_2021,
	title = {Freeway accident detection and classification based on the multi-vehicle trajectory data and deep learning model},
	volume = {130},
	issn = {0968-090X},
	url = {https://www.sciencedirect.com/science/article/pii/S0968090X21003120},
	doi = {10.1016/j.trc.2021.103303},
	abstract = {The freeway accident detection and classification have attracted much attention of researchers in the past decades. With the popularity of Global Navigation Satellite System ({GNSS}) on mobile phones and onboard equipment, increasing amounts of real-time vehicle trajectory data can be obtained more and more easily, which provides a potential way to use the multi-vehicle trajectory data to detect and classify an accident on freeways. The data has the advantages of low cost, high penetration, high real-time performance, and being robust to the outdoor environment. Therefore, this paper proposes a new method for accident detection and classification based on the multi-vehicle trajectory data. Different from the existing methods using {GNSS} positioning data, the proposed method not only uses the position information of the related vehicles but also tries to capture the development tendencies of the trajectories of accident vehicles over a period of time. A Deep Convolutional Neural Network model is developed to recognize an accident from the normal driving of vehicles and also identify the type of the accident, and the six types of traffic accidents are considered in this study. To train and test the proposed model, the simulated trajectory data is generated based on {PC}-Crash, including the normal driving trajectories and the trajectories before, in, and after an accident. The results indicate that the detection accuracy of the proposed method can reach up to 100\%, and the classification accuracy can reach up to 95\%, which both outperform the existing methods using other data. In addition, to ensure the robustness of the detection accuracy, at least 1 s of duration and 5 Hz of frequency for the trajectory data should be adopted in practice. The study will help to accurately and fastly detect an accident, recognize the accident type, and future judge who is liable for the accident.},
	pages = {103303},
	journaltitle = {Transportation Research Part C: Emerging Technologies},
	shortjournal = {Transportation Research Part C: Emerging Technologies},
	author = {Yang, Da and Wu, Yuezhu and Sun, Feng and Chen, Jing and Zhai, Donghai and Fu, Chuanyun},
	urldate = {2025-01-31},
	date = {2021-09-01},
	keywords = {Accident detection and classification, Deep Convolutional Neural Network, Freeway traffic accident, Vehicle trajectory},
}

@article{yao2023dota,
	title = {{DoTA}: Unsupervised Detection of Traffic Anomaly in Driving Videos},
	volume = {45},
	issn = {1939-3539},
	url = {https://ieeexplore.ieee.org/abstract/document/9712446},
	doi = {10.1109/TPAMI.2022.3150763},
	shorttitle = {{DoTA}},
	abstract = {Video anomaly detection ({VAD}) has been extensively studied for static cameras but is much more challenging in egocentric driving videos where the scenes are extremely dynamic. This paper proposes an unsupervised method for traffic {VAD} based on future object localization. The idea is to predict future locations of traffic participants over a short horizon, and then monitor the accuracy and consistency of these predictions as evidence of an anomaly. Inconsistent predictions tend to indicate an anomaly has occurred or is about to occur. To evaluate our method, we introduce a new large-scale benchmark dataset called Detection of Traffic Anomaly ({DoTA})containing 4,677 videos with temporal, spatial, and categorical annotations. We also propose a new {VAD} evaluation metric, called spatial-temporal area under curve ({STAUC}), and show that it captures how well a model detects both temporal and spatial locations of anomalies unlike existing metrics that focus only on temporal localization. Experimental results show our method outperforms state-of-the-art methods on {DoTA} in terms of both metrics. We offer rich categorical annotations in {DoTA} to benchmark video action detection and online action detection methods. The {DoTA} dataset has been made available at: https://github.com/{MoonBlvd}/Detection-of-Traffic-Anomaly},
	pages = {444--459},
	number = {1},
	journaltitle = {{IEEE} Trans. on Pattern Analysis and Machine Intelligence},
	author = {Yao, Yu and Wang, Xizi and Xu, Mingze and Pu, Zelin and Wang, Yuchen and Atkins, Ella and Crandall, David J.},
	urldate = {2024-11-14},
	date = {2023-01},
	note = {Conf. Name: {IEEE} Trans. on Pattern Analysis and Machine Intelligence},
	keywords = {Accidents, Annotations, Anomaly detection, Benchmark testing, Cameras, Future object localization, Measurement, Traffic accident detection, Video action recognition, Video anomaly detection, Videos},
}

@article{zahid2024datadriven,
	title = {A data-driven approach for road accident detection in surveillance videos},
	volume = {83},
	issn = {1573-7721},
	url = {https://doi.org/10.1007/s11042-023-16193-0},
	doi = {10.1007/s11042-023-16193-0},
	abstract = {The use of machine learning and computer vision techniques for detecting road accidents is a challenging task due to the limited availability of accident data for training. Staging fake accidents with real cars is expensive, and car crashes are rare incidents in roadside {CCTV} footage. Therefore, simulating fake car crashes using computers can be a feasible option. As such, we look at the following question in this paper; how successful can manually generated fake accident data be in terms of enabling a machine learning algorithm to detect real accidents?. In this work, we manually construct fake accident video frames from normal video traffic footage by creating simulated accidents. We do so by following predefined principles that maintain consistency with the scene context of normal frames. In order to detect real accidents in video footage, we fine-tune pre-trained deep convolutional neural networks on the manually generated fake accident frames. We use four pre-trained models i.e., {AlexNet}, {GoogleNet}, {SqueezeNet} and {ResNet}-50 on both normal and abnormal traffic video frames during the learning phase. The experimental results show that the fine-tuned {AlexNet} outperforms other models providing an 80\% percent true positive rate when detecting anomalies (accidents) in real-world surveillance videos of {UCF}-Crime dataset. This demonstrates the validity of our hypothesis that simulated accident data could be valuable for training machine learning algorithms to detect real-world accidents.},
	pages = {17217--17231},
	number = {6},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Zahid, Ariba and Qasim, Tehreem and Bhatti, Naeem and Zia, Muhammad},
	urldate = {2025-01-31},
	date = {2024-02-01},
	langid = {english},
	keywords = {Anomaly detection, Artificial Intelligence, Data preparation, Road accident detection, Transfer learning, Video surveillance},
	file = {Full Text PDF:/home/walter/snap/zotero-snap/common/Zotero/storage/6PMAINZD/Zahid et al. - 2024 - A data-driven approach for road accident detection in surveillance videos.pdf:application/pdf},
}

