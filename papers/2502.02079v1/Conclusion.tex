\section{Conclusion}
In this work, we introduce the first clustering of dueling bandit algorithms for both linear and non-linear latent reward functions, which enhance the performance of MAB with preference feedback via cross-user collaboraiton.
Our algorithms estimates the clustering structure online 
based on the
estimated reward function parameters, and employs the data from all users within the same cluster to select the pair of arms to query for preference feedback.
We derive upper bounds on the cumulative regret of our algorithms, which show that our algorithms enjoy theoretically guaranteed improvement when a larger number of users belong to the same cluster on average. We also use synthetic and real-world experiments to validate our theoretical findings.

