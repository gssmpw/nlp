\section{Theoretical Analysis}
\label{sec:theory}
In this section, we present the theoretical results regarding the regret guarantees of our proposed algorithms and provide a detailed discussion of these findings.
\subsection{Clustering Of Linear Dueling Bandits (COLDB)}
\label{subsec:theory:linear}
The following theorem provides an upper bound on the expected regret achieved by the COLDB algorithm (Algo.~\ref{algo:linear:dueling:bandits}) under the linear setting.
\begin{theorem} \label{thm: linear regret bound}
    Suppose that 
    Assumptions \ref{assumption4}, \ref{assumption1}, \ref{assumption2} and \ref{assumption3}
    are satisfied. Then the expected regret of the COLDB algorithm (Algo.~\ref{algo:linear:dueling:bandits}) for $T$ rounds satisfies
    \begin{align}
        R(T)&= O\Big(u\big(\frac{d}{\kappa_\mu^2\tilde\lambda_x \gamma^2}+\frac{1}{\tilde\lambda_x^2}\big)\log T+\frac{1}{\kappa_\mu}d\sqrt{mT}\Big)\label{bound linear 2 terms}\\
        &=O\Big(\frac{1}{\kappa_\mu}d\sqrt{mT}\Big)\,,
    \end{align}
    where $\tilde{\lambda}_x\triangleq\int_{0}^{\lambda_x} (1-e^{-\frac{(\lambda_x-x)^2}{2\sigma^2}})^{C} dx$ is the problem instance dependent constant \cite{wang2024onlinea,wang2024onlineb}.
\end{theorem}
The proof of this theorem can be found in Appendix \ref{app: proof linear}.
The regret bound in Eq.(\ref{bound linear 2 terms}) consists of two terms. The first term accounts for the number of rounds required to accumulate sufficient information to correctly cluster all users with high probability, and it scales only logarithmically with the number of time steps \(T\). The second term captures the regret after successfully clustering the users, which depends on the number of clusters \(m\), rather than the potentially huge total number of users $u$. 
Notably, the regret upper bound is not only sub-linear in $T$, but also \emph{becomes tighter when there is a smaller number of clusters $m$}, i.e., when a larger number of users belong to the same cluster on average.
This provides a formal justification for the advantage of cross-user collaboration in our problem setting where only preference feedback is available.

In the special case where there is only one user (\(m = 1\)), the regret bound simplifies to \(O(d \sqrt{T} / \kappa_\mu)\), which aligns with the 
classical results in the single-user linear dueling bandit literature \cite{NeurIPS21_saha2021optimal,ICML22_bengs2022stochastic,arXiv24_li2024feelgood}.
Compared to the previous works on clustering of bandits with linear reward functions \cite{gentile2014online,wang2024onlinea,10.5555/3367243.3367445}, our regret upper bound has an extra dependency on $1 / \kappa_\mu$. Since $\kappa_\mu < 0.25$ for the logistic function, this dependency makes our regret upper bound larger and hence captures the more challenging nature of the preference feedback compared to the numerical feedback in classical clustering of linear bandits.

\subsection{Clustering Of Neural Dueling Bandits (CONDB)}
\label{subsec:theory:neural}
Let $\mathbf{H}' = \sum_{t=1}^T \sum_{(i, j) \in C_K^2} z^i_j(t)z^i_j(t)^\top  \frac{1}{m_{\text{NN}}}$, in which 
$z^i_j(t) = g(\bx_{t,i};\btheta_0) - g(\bx_{t,j};\btheta_0)$ 
and $C_K^2$ denotes all pairwise combinations of $K$ arms. 
Then, the effective dimension $\widetilde{d}$ is defined as follows \cite{verma2024neural}:
\begin{equation}
    \widetilde{d} = \log \det  \left(\frac{\kappa_\mu}{\lambda}  \mathbf{H}' + \mathbf{I}\right).
\label{eq:eff:dimension}
\end{equation}
The definition of $\widetilde{d}$ considers the contexts from all users and in all $T$ rounds.
The theorem below gives an upper bound on the expected regret of our CONDB algorithm (Algo.~\ref{algo:neural:dueling:bandits}).
\begin{theorem} \label{thm: neural regret bound}
Suppose that Assumptions \ref{assumption4}, \ref{assumption3}, \ref{assumption:main:neural} and \ref{assumption:gap:neural:bandits} are satisfied (let $\phi(\bx) = (1 / \sqrt{m_{\text{NN}}})g(\bx;\btheta_0)$ in Assumption \ref{assumption3}). 
As long as $m_{\text{NN}} \geq \text{poly}(T, L, K, 1/\kappa_\mu, L_\mu, 1/\lambda_0, 1/\lambda, \log(1/\delta))$,
then the expected regret of the CONDB algorithm (Algo.~\ref{algo:neural:dueling:bandits}) for $T$ rounds satisfies
\begin{align}
R_T &= O\bigg(u\big(\frac{\widetilde{d}}{\kappa_\mu^2\tilde\lambda_x \gamma^2}+\frac{1}{\tilde\lambda_x^2}\big)\log T+\nonumber\\
&\qquad \big(\frac{\sqrt{\widetilde{d}}}{\kappa_\mu} + B\sqrt{\frac{\lambda}{\kappa_\mu}}\big)\sqrt{\widetilde{d}mT} \bigg) \label{regret:bound:condb}\\
&=O\Big(\big(\frac{\sqrt{\widetilde{d}}}{\kappa_\mu} + B\sqrt{\frac{\lambda}{\kappa_\mu}}\big)\sqrt{\widetilde{d}mT} \Big)\,.\label{regret:bound:condb:second}
\end{align}
\end{theorem}
The proof of this theorem can be found in Appendix \ref{app: proof neural}.
The first term in the regret bound in Eq.~\ref{regret:bound:condb} has the same form as the first term in the regret bound of COLDB in Eq.(\ref{bound linear 2 terms}), except that the input dimension $d$ for COLDB (Eq.(\ref{bound linear 2 terms})) is replaced by the effective dimension $\widetilde{d}$ for CONDB (Eq.(\ref{regret:bound:condb})).
As discussed in \citet{verma2024neural}, $\widetilde{d}$ is usually larger than the effective dimension in classical neural bandits \cite{zhou2020neural,zhang2020neural}.
This dependency, together with the extra dependency on $1/\kappa_\mu$, reflects the added difficulty from the preference feedback compared to the more informative numerical feedback in classical neural bandits.

Similar to COLDB (Theorem \ref{thm: linear regret bound}), the first term in the regret upper bound of CONDB (Theorem \ref{thm: neural regret bound}) results from the number of rounds needed to collect enough observations to correctly identify the clustering structure. The second term corresponds to the regret of all users after the correct clustering structure is identified, which depends on the number of clusters $m$ instead of the number of users $u$.
Theorem \ref{thm: neural regret bound} also shows that the regret upper bound of CONDB is sub-linear in $T$, and becomes improved as the number of users belonging to the same cluster is increased on average (i.e., when the number of clusters $m$ is smaller).
Moreover, in the special case where the number of clusters is $m=1$, the regret upper bound in Eq.(\ref{regret:bound:condb:second}) becomes the same as that of the standard neural dueling bandits \cite{verma2024neural}.
