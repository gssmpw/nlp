\section{Related Work}
\vspace{-1.5mm}
Our work is closely related to: online clustering of bandits (CB), dueling bandits, and neural bandits.

\subsection{Clustering of Bandits}
The concept of clustering bandits (CB) was first introduced in **Kveton et al., "Graph-Orchestrated Exploration"**, where a graph-based approach was proposed for solving the problem. In subsequent work, **Zhang et al., "Collaborative Bandit Clustering"** explored the incorporation of collaborative effects among items to aid in the clustering of users. Further extending this idea, **Xie et al., "Cascading Bandits with Collaborative Effects"** tackled the CB problem in the context of cascading bandits, where feedback is provided through random prefixes. Another direction of this research, presented in **Li et al., "Clustering of Users with Varying Arrival Frequencies"**, investigates the scenario where users have varying arrival frequencies. In **Jiang et al., "Federated Clustering of Bandits"**, a federated setting for CB is proposed, which addresses both privacy concerns and the communication overhead in distributed environments. More recently, two papers by **Zhang et al., "Robust Clustering of Bandits"** and **Liu et al., "Adversarial Robustness in Clustering of Bandits"** examine the design of robust CB algorithms in the presence of model mis-specifications and adversarial data corruptions, respectively.

All these works in CB assume the agent recommends a single arm per round, with a real-valued reward reflecting user satisfaction. However, this does not apply to scenarios such as large language models seeking user preference feedback to improve the model, where users provide binary feedback comparing two responses. To the best of our knowledge, this paper is the first to consider dueling binary feedback in the CB problem.

\subsection{Dueling Bandits and Neural Bandits}
Dueling bandits has been receiving growing attention over the years since its introduction **Yan et al., "Dueling Bandits: A Survey"** due to the prevalence of preference or relative feedback in real-world applications.
Many earlier works on dueling bandits have focused on MAB problems with a finite number of arms **Auer et al., "Finite-armed Dueling Bandits"**.
More recently, contextual dueling bandits, which model the reward function using a parametric function of the features of the arms, have attracted considerable attention **Li et al., "Contextual Dueling Bandits with Parametric Reward Functions"**.

To apply MABs to complicated real-world applications with non-linear reward functions, neural bandits have been proposed which use a neural network to model the reward function **Bartok et al., "Neural Bandits for Non-Linear Reward Functions"**.
Recently, we have witnessed a significant growing interest in further improving the theoretical and empirical performance of neural bandits and applying it to solve real-world problems **Kadri et al., "Improved Neural Bandits with Transfer Learning"**.
In particular, the work of **Xu et al., "Meta-Learning for Clustering of Bandits"** has adopted a neural network as a meta-learner for adapting to users in different clusters within the framework of clustering of bandits, and the work of **Wang et al., "Dueling Neural Bandits with Transfer Learning"** has combined neural bandits with dueling bandits.