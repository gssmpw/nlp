\section{Algorithms}
\subsection{Clustering Of Linear Dueling Bandits (COLDB)}
\label{subsec:algo:coldb}
Our Clustering Of Linear Dueling Bandits (COLDB) algorithm is described in Algorithm~\ref{algo:linear:dueling:bandits}. Here we elucidate the underlying principles and operational workflow of COLDB.
COLDB maintains a dynamic graph $G_t = (\mathcal{U}, E_t)$ encompassing all users, whose connected components represent the inferred user clusters in round $t$. Throughout the learning process, COLDB adaptively removes edges to accurately cluster the users based on their estimated reward function parameters, thereby leveraging these clusters to enhance online learning efficiency. The operation of COLDB proceeds as follows:

\noindent\textbf{Cluster Inference $\overline{C}_t$ for User $i_t$ (Line \ref{algo line: init}-Line \ref{algo line: cluster detection}).} Initially, COLDB constructs a complete undirected graph $G_0 = (\mathcal{U}, E_0)$ over the user set (Line~\ref{algo line: init}). As learning progresses, edges are selectively removed to ensure that only users with similar preference profiles remain connected. At each round $t$, when a user $i_t$ comes to the system with a feasible arm set $\mathcal{X}_t$ (Line~\ref{algo line: user comes}), COLDB identifies the connected component $\overline{C}_t$ containing $i_t$ in the maintained graph $G_{t-1}$, which serves as the current estimated cluster for this user (Line~\ref{algo line: cluster detection}).

\noindent\textbf{Estimating Shared Statistics for Cluster $\overline{C}_t$ (Line \ref{algo line: common theta}-Line \ref{algo line: common matrix}).} Once the cluster $\overline{C}_t$ is identified, COLDB estimates a common preference vector $\overline{\btheta}_t$ for all users within this cluster by aggregating the historical feedback from all members of $\overline{C}_t$. 
Specifically, in Line~\ref{algo line: common theta}, the common preference vector is determined by minimizing the following loss function:
\begin{align}
    &\overline{\btheta}_t=\arg\min_{\btheta} - \sum_{s\in[t-1]\atop i_s\in \overline C_t} \Big( y_s\log\mu\left({\btheta}^{\top}\left[\phi(\bx_{s,1}) - \phi(\bx_{s,2})\right]\right) \notag\\
    &+ (1-y_s)\log\mu\left({\btheta}^{\top}\left[\phi(\bx_{s,2}) - \phi(\bx_{s,1})\right]\right) \Big) + \frac{1}{2}\lambda\norm{\btheta}_2^2  \,,\label{eq: solve common theta}
\end{align}
which corresponds to the Maximum Likelihood Estimation (MLE) using the data from all users in the cluster $\overline{C}_t$.
Additionally, in Line~\ref{algo line: common matrix}, COLDB computes the aggregated information matrix for $\overline{C}_t$, which is subsequently utilized in selecting the second arm $\bx_{t,2}$:
\begin{equation}
    \bV_{t-1} = \bV_0 + \sum_{\substack{s \in [t-1] \\ i_s \in \overline{C}_t}} (\phi(\bx_{s,1}) - \phi(\bx_{s,2})) (\phi(\bx_{s,1}) - \phi(\bx_{s,2}))^\top
    \label{eq:update:info:matrix:v:linear}
\end{equation}
\noindent\textbf{Arm Recommendation Based on Cluster Statistics (Line \ref{algo line: choose x1}-Line \ref{algo line: choose x2}).} Leveraging the estimated common preference vector $\overline{\btheta}_t$ and the aggregated information matrix $\bV_{t-1}$, COLDB proceeds to recommend two arms as follows:

\squishlisttwo
    \item \textbf{First Arm Selection ($\bx_{t,1}$).} In Line~\ref{algo line: choose x1}, COLDB selects the first arm by greedily choosing the arm that maximizes the estimated reward according to $\overline{\btheta}_t$:
    \begin{equation}
        \bx_{t,1} = \arg\max_{\bx \in \mathcal{X}_t} \overline{\btheta}_t^\top \phi(\bx).
    \end{equation}
    \item \textbf{Second Arm Selection ($\bx_{t,2}$).} Following the selection of $\bx_{t,1}$, in Line~\ref{algo line: choose x2}, COLDB selects the second arm by maximizing an upper confidence bound (UCB):
\begin{small}
    \begin{align}
    \bx_{t,2} &= \arg\max_{\bx\in\mathcal{X}_t} \overline\btheta_t^\top \phi(\bx) + \frac{\beta_t}{\kappa_\mu}\norm{\phi(\bx) - \phi(\bx_{t,1})}_{\bV_{t-1}^{-1}}\,.
\label{eq:linear:select:second:arm}
\end{align}
\end{small}
Intuitively, Eq.(\ref{eq:linear:select:second:arm}) encourages the selection of the arm which both (a) has a large predicted reward value and (b) is different from $\bx_{t,1}$ and the arms selected in the previous $t-1$ rounds when the served user belongs to the currently estimated cluster $\overline{C}_t$.
In other words, the second arm $\bx_{t,2}$ is chosen by balancing exploration and exploitation.
\squishend

\noindent\textbf{Updating User Estimates and Interaction History (Line \ref{algo line: feedback}-Line \ref{algo line: update it}).} Upon recommending $\bx_{t,1}$ and $\bx_{t,2}$, the user receives binary feedback $y_t = \mathbbm{1}(\bx_{t,1} \succ \bx_{t,2})$ from user $i_t$, and then updates the interaction history $\mathcal{D}_t = \{i_s, \bx_{s,1}, \bx_{s,2}, y_s\}_{s=1}^t$ (Line~\ref{algo line: feedback}). Moreover, COLDB updates the preference vector estimate for user $i_t$ while keeping the estimates for the other users unchanged (Line~\ref{algo line: update it}). Specifically, the preference vector estimate $\hat{\btheta}_{i_t,t}$ is updated via MLE using the historical data from user $i_t$:
\begin{align}
    &\hat{\btheta}_{i_t,t} = \arg\min_{\btheta} - \sum_{\substack{s \in [t-1] \\ i_s = i_t}} \Big( y_s \log \mu\big(\btheta^\top [\phi(\bx_{s,1}) - \phi(\bx_{s,2})]\big) \notag \\
    &+ (1 - y_s) \log \mu\big(\btheta^\top [\phi(\bx_{s,2}) - \phi(\bx_{s,1})]\big) \Big) + \frac{\lambda}{2} \|\btheta\|_2^2\,.
\end{align}

\noindent\textbf{Dynamic Graph Update (Line \ref{algo line: delete}).} Finally, based on the updated preference estimate $\hat{\btheta}_{i_t,t}$ for user $i_t$, COLDB reassesses the similarity between $i_t$ and the other users. If the discrepancy between $\hat{\btheta}_{i_t,t}$ and $\hat{\btheta}_{\ell,t}$ for any user $\ell$ surpasses a predefined threshold (Line~\ref{algo line: delete}), the edge $(i_t, \ell)$ is removed from the graph $G_{t-1}$, effectively separating them into distinct clusters. The resultant graph $G_t = (\mathcal{U}, E_t)$ is then utilized in the subsequent rounds.

\begin{algorithm*}[t!] 
\caption{Clustering Of Linear Dueling Bandits (COLDB)}
\label{algo:linear:dueling:bandits}
	\begin{algorithmic}[1]
    \STATE {\bf Input:} $f(T_{i,t})=\frac{\sqrt{\lambda/\kappa_\mu}+\sqrt{2\log(u/\delta)+d\log(1+4T_{i,t}\kappa_\mu/d\lambda)}}{\kappa_\mu{\sqrt{2\tilde{\lambda}_x T_{i,t}}}}$, regularization parameter $\lambda>0$, confidence parameter $\beta_t \triangleq \sqrt{2\log(1/\delta) + d\log\left( 1 + tL^2\kappa_{\mu}/(d\lambda) \right)}$, $\kappa_\mu>0$.
    \STATE {\bf Initialization:} 
$\bV_0=\bV_{i,0} = \frac{\lambda}{\kappa_\mu} \mathbf{I}$ , $\hat\btheta_{i,0}=\bzero$, $\forall{i \in \mathcal{U}}$, a complete Graph $G_0 = (\mathcal{U},E_0)$ over $\mathcal{U}$.\alglinelabel{algo line: init}
		\FOR{$t= 1, \ldots, T$}
            \STATE Receive the index of the current user $i_t\in\mathcal{U}$, and the current feasible arm set $\cX_t$;\alglinelabel{algo line: user comes}
            \STATE Find the connected component $\overline C_t$ for user $i_t$ in the current graph $G_{t-1}$ as the current cluster; \alglinelabel{algo line: cluster detection}
            
            \STATE Estimate the common preference vector $\overline{\btheta}_t$ for the current cluster $\overline C_t$:
            \begin{equation}
                \overline{\btheta}_t=\arg\min_{\btheta} - \sum_{s\in[t-1]\atop i_s\in \overline C_t} \Big( y_s\log\mu\left({\btheta}^{\top}\left[\phi(\bx_{s,1}) - \phi(\bx_{s,2})\right]\right) + (1-y_s)\log\mu\left({\btheta}^{\top}\left[\phi(\bx_{s,2}) - \phi(\bx_{s,1})\right]\right) \Big) + \frac{\lambda}{2}\norm{\btheta}_2^2;
            \end{equation}\alglinelabel{algo line: common theta}
            
            \STATE Calculate aggregated information matrix for cluster $\overline C_t$: 
            $\bV_{t-1}=\bV_0+\sum_{s\in[t-1]\atop i_s\in \overline C_t}(\phi(\bx_{s,1}) - \phi(\bx_{s,2}))(\phi(\bx_{s,1}) - \phi(\bx_{s,2}))^\top$. \alglinelabel{algo line: common matrix}
            \STATE Choose the first arm  $\bx_{t,1} = \arg\max_{\bx\in\mathcal{X}_t}\overline\btheta_t^\top \phi(\bx)$; \alglinelabel{algo line: choose x1}
            \STATE Choose the second arm $\bx_{t,2} = \arg\max_{\bx\in\mathcal{X}_t} \overline\btheta_t^\top \left( \phi(\bx) - \phi(\bx_{t,1}) \right) + \frac{\beta_t}{\kappa_\mu}\norm{\phi(\bx) - \phi(\bx_{t,1})}_{\bV_{t-1}^{-1}}$; \alglinelabel{algo line: choose x2}
		\STATE Observe the preference feedback: $y_t = \mathbbm{1}(\bx_{t,1}\succ \bx_{t,2})$, and update history: $\mathcal{D}_t=\{i_s, \bx_{s,1}, \bx_{s,2}, y_s\}_{s=1,\ldots,t}$;\alglinelabel{algo line: feedback}
        \STATE Update the estimation for the current served user $i_t$: \alglinelabel{algo line: update it}
        \begin{equation}
        \hat{\btheta}_{i_t,t}=\arg\min_{\btheta} - \sum_{s\in[t-1]\atop i_s=i_t}\Big( y_s\log\mu\left({\btheta}^{\top}\left[\phi(\bx_{s,1}) - \phi(\bx_{s,2})\right]\right) + (1-y_s)\log\mu\left({\btheta}^{\top}\left[\phi(\bx_{s,2}) - \phi(\bx_{s,1})\right]\right) \Big) + \frac{\lambda}{2}\norm{\btheta}_2^2, 
            \end{equation}
            keep the estimations of other users unchanged;
            \STATE Delete the edge $(i_t,\ell)\in E_{t-1}$ if
            \begin{equation}
                \norm{\hat\btheta_{i_t,t}-\hat\btheta_{\ell,t}}_2>f(T_{i_t,t})+f(T_{\ell,t})
            \end{equation} \alglinelabel{algo line: delete}
		\ENDFOR
	\end{algorithmic}
\end{algorithm*}

\subsection{Clustering Of Neural Dueling Bandits (CONDB)}
\label{subsec:algo:condb}
Our Clustering Of Neural Dueling Bandits (CONDB) algorithm is illustrated in Algorithm~\ref{algo:neural:dueling:bandits} (App.~\ref{app:sec:condb:algo}), which adopts neural networks to model non-linear reward functions.
Similar to COLDB, our CONDB algorithm also maintains a dynamic graph $G_t = (\mathcal{U}, E_t)$ in which every connected component denotes an inferred cluster, and adaptively removes the edges between users who are estimated to belong to different clusters.

\noindent\textbf{Cluster Inference $\overline{C}_t$ for User $i_t$ (Line 5).} 
Similar to COLDB (Algo.~\ref{algo:linear:dueling:bandits}), when a new user $i_t$ arrives,  our CONDB firstly identifies the connected component $\overline{C}_t$ in the maintained graph $G_{t-1}$ which contains the user $i_t$ and then uses it as the estimated cluster for $i_t$ (Line 5).

\noindent\textbf{Estimating Shared Statistics for Cluster $\overline{C}_t$ (Line 6).}
After the cluster $\overline{C}_t$ is identified, our CONDB algorithm uses the history of preference feedback observations from all users in the cluster $\overline{C}_t$
to train a neural network (NN) to minimize the following loss function (Line 6):
\begin{align}
    &\mathcal{L}_t(\btheta)=
    - \frac{1}{m} \sum_{s\in[t-1]\atop i_s\in \overline C_t}\Big( y_s\log\mu\left( h(\bx_{s,1};\btheta) - h(\bx_{s,2};\btheta) \right) + \notag \\
    &(1-y_s)\log\mu\left(h(\bx_{s,2};\btheta) - h(\bx_{s,1};\btheta)\right) \Big) + \frac{\lambda}{2}\norm{\btheta - \btheta_0}_2^2
\end{align}
to yield parameters $\overline{\btheta}_t$.
In addition, similar to COLDB (Algorithm \ref{algo:linear:dueling:bandits}), our CONDB computes the aggregated information matrix for the cluster $\overline{C}_t$ following Eq.(\ref{eq:update:info:matrix:v:linear})
.
Note that here we replace $\phi(\bx)$ from Eq.(\ref{eq:update:info:matrix:v:linear}) by the NTK feature representation $\phi(\bx)=(1/\sqrt{m})g(\bx;\btheta_0)$, in which $\btheta_0$ represents the initial parameters of the NN (Sec.~\ref{subsec:problem:setting:neural}).

\noindent\textbf{Arm Recommendation Based on Cluster Statistics (Line 8-Line 9).} 
Next, our CONDB algorithm leverages the trained NN with parameters $\overline{\btheta}_t$ and the aggregated information matrix $\bV_{t-1}$ to select the pair of arms.
The first arm is selected by greedily maximizing the reward prediction of the NN with parameters $\overline{\btheta}_t$ (Line 8): 
\begin{equation}
\bx_{t,1} = \arg\max_{\bx\in\mathcal{X}_t} h(\bx;\overline{\btheta}_t).
\end{equation}
The second arm is then selected optimistically (Line 9):
\begin{equation}
\bx_{t,2} = \arg\max_{\bx\in\mathcal{X}_t} h(\bx;\overline{\btheta}_t) + \nu_T \norm{\left(\phi(\bx) - \phi(\bx_{t,1})\right)}_{\bV_{t-1}^{-1}},
\end{equation}
in which $\nu_T \triangleq \beta_T + B\sqrt{\frac{\lambda}{\kappa_\mu}} + 1$, $\beta_T \triangleq \frac{1}{\kappa_\mu} \sqrt{ \widetilde{d} + 2\log(u/\delta)}$ and $B$ is defined in Lemma \ref{lemma:linear:utility:function:informal}.
Here $\widetilde{d}$ denotes the \emph{effective dimenision} which we will introduce in detail in Sec.~\ref{subsec:theory:neural}.

\noindent\textbf{Updating User Estimates and Interaction History (Line 10-Line 11).} 
After recommending the pair of arms $\bx_{t,1}$ and $\bx_{t,2}$, we collect the preference feedback $y_t = \mathbbm{1}(\bx_{t,1} \succ \bx_{t,2})$ and update interaction history: $\mathcal{D}_t = \{i_s, \bx_{s,1}, \bx_{s,2}, y_s\}_{s=1}^t$ (Line 10).
Next, we update the parameters of the NN used to predict the reward for user $i_t$ by minimizing the following loss function (Line 11):
\begin{small}
   \begin{align}
     &\mathcal{L}_{i_t,t}(\btheta)= 
    - \frac{1}{m_{\text{NN}}} \sum_{s\in[t-1]\atop i_s = i_t}\big( y_s\log\mu\left( h(\bx_{s,1};\btheta) - h(\bx_{s,2};\btheta) \right) + \notag\\
    &(1-y_s)\log\mu\left(h(\bx_{s,2};\btheta) - h(\bx_{s,1};\btheta)\right) \big) + \frac{\lambda}{2}\norm{\btheta - \btheta_0}_2^2
\end{align} 
\end{small}
to yield parameters $\hat{\btheta}_{i_t,t}$.
The NN parameters for the other users remain unchanged.

\noindent\textbf{Dynamic Graph Update (Line 12).} 
Finally, we use the updated NN parameters $\hat{\btheta}_{i_t,t}$ for user $i_t$ to reassess the similarity between user $i_t$ and the other users.
We remove the edge between $(i_t, \ell)$ from the graph $G_{t-1}$ if the difference between $\hat{\btheta}_{i_t,t}$ and $\hat{\btheta}_{\ell,t}$ is large enough (Line 12). Intuitively, if the estimated reward functions (represented by the respective parameters of their NNs for reward prediction) between two users are significantly different, we separate these two users into different clusters.
The updated graph $G_t = (\mathcal{U}, E_t)$ is then used in the following rounds.



