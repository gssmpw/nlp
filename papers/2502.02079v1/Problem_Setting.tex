\section{Problem Setting}\label{sec: setting}

This section formulates the problem of \emph{clustering of dueling bandits}. In the following, we use boldface lowercase letters for vectors and boldface uppercase letters for matrices. The number of elements in a set \( \mathcal{A} \) is denoted as \( |\mathcal{A}| \), while \( [m] \) refers to the index set \( \{1, 2, \dots, m\} \), and \( \norm{\boldsymbol{x}}_{\boldsymbol{M}} = \sqrt{\boldsymbol{x}^{\top}\boldsymbol{M}\boldsymbol{x}} \) represents the matrix norm of vector \( \boldsymbol{x} \) with respect to the positive semi-definite (PSD) matrix \( \boldsymbol{M} \).

\textbf{Clustering Structure.}
Consider a scenario with \( u \) users, indexed by \( \mathcal{U} = \{1, 2, \dots, u\} \), where each user \( i \in \mathcal{U} \) 
is associated with a unknown 
reward function $f_i: \mathbb{R}^{d'} \rightarrow \mathbb{R}$ which maps an arm $\bx \in \mathcal{X}\subset\mathbb{R}^{d'}$ to its corresponding reward value $f_i(\bx)$.
We assume that there exists an underlying, yet unknown, clustering structure over the users reflecting their behavior similarities. Specifically, the set of users \( \mathcal{U} \) is partitioned into \( m \) clusters \( C_1, C_2, \dots, C_m \), where \( m \ll u \), and the clusters are mutually disjoint: \( \cup_{j \in [m]} C_j = \mathcal{U} \) and \( C_j \cap C_{j'} = \emptyset \) for \( j \neq j' \). These clusters are referred to as \gtclusters{}, and the set of clusters is denoted by \( \mathcal{C} = \{C_1, C_2, \dots, C_m\} \). 
Let $f^j$ denote the common reward function of all users in cluster $j$ and let \( j(i) \in [m] \) be the index of the cluster to which user \( i \) belongs.
If two users $i$ and $l$ belong to the same cluster, they have the same reward function.
That is, for any $\ell \in \mathcal{U}$, if $\ell \in C_{j(i)}$, then $f_\ell = f_i = f^{j(i)}$.
Meanwhile, users from different clusters have distinct 
reward functions.

\textbf{Modeling Preference Feedback.}
At each time step \( t \in [T] \), a user \( i_t \in \mathcal{U} \) is served. The learning agent observes a set of context vectors (i.e., arms) \( \cX_t \subseteq \cX \subset \mathbb{R}^{d'} \), where \( \left|\cX_t\right| = K \leq C \) for all \( t \).
Each arm \( \bx \in \cX_t \) is a feature vector in \( \mathbb{R}^{d'} \) with \( \norm{\bx}_2 \leq 1 \). The agent assigns the cluster \( \overline{C}_t \) to user \( i_t \) and recommends two arms \( \bx_{t,1}, \bx_{t,2} \in \cX_t \) based on the aggregated historical data from cluster \( \overline{C}_t \). 
After receiving the recommended pair of arms, the user provides a binary preference feedback \( y_t \in \{0, 1\} \), in which $y_t=1$ if $\bx_{t,1}$ is preferred over $\bx_{t,2}$ and $y_t=0$ otherwise.
We model the binary preference feedback following the widely used Bradley-Terry-Luce (BTL) model \cite{AS04_hunter2004mm,Book_luce2005individual}.
Specifically, the BTL model assumes that for user $i_t$,
the probability that the first arm $\bx_{t,1}$ is preferred over the second arm $\bx_{t,2}$ is given by
\[
\mathbb{P}_t(\bx_{t,1} \succ \bx_{t,2}) = \mu(f_{i_t}(\bx_{t,1}) - f_{i_t}(\bx_{t,2})),
\]
where \( \mu: \mathbb{R} \to [0, 1] \) is the logistic function: \( \mu(z) = \frac{1}{1+e^{-z}} \). 
In other words, the binary feedback $y_t$ is sampled from the Bernoulli distribution with the probability $\mathbb{P}_t(\bx_{t,1} \succ \bx_{t,2})$.

We make the following assumption about the preference model:
\begin{assumption}[Standard Dueling Bandits Assumptions]
\label{assumption4}
1. $|\mu(f(\bx)) - \mu(g(\bx))| \le L_\mu|f(\bx) - g(\bx)|, \forall x\in\mathcal{X}$ , for any functions $f,g: \mathbb R^{d'} \rightarrow \mathbb R$.\\
2. $\min_{\bx \in \mathcal{X}} \nabla\mu(f(\bx)) \ge \kappa_\mu > 0.$
\end{assumption}
Assumption \ref{assumption4} is the standard assumption in the analysis of linear bandits and dueling bandits \cite{ICML17_li2017provably,ICML22_bengs2022stochastic}, and when $\mu$ is the logistic function, $L_\mu = 1/4$.
The regret incurred by the learning agent is defined as:
\[
R_T = \sum_{t=1}^{T} r_t = \sum_{t=1}^{T} \left( 2 f_{i_t}(\bx^*_t) - f_{i_t}(\bx_{t,1}) - f_{i_t}(\bx_{t,2}) \right),
\]
where \( \bx^*_t = \arg\max_{\bx \in \mathcal{X}_t} f_{i_t}(\bx) \) represents the optimal arm at round \( t \).
This is a commonly adopted notion of regret in the analysis of dueling bandits \cite{ICML22_bengs2022stochastic,ALT22_saha2022efficient}.

\subsection{Clustering of Linear Dueling Bandits}
\label{subsec:problem:setting:linear}
For the linear setting, we assume that each reward function \( f_i \) is linear in a fixed feature space \( \phi(\cdot) \), such that \( f_i(\bx) = \btheta_i^{\top} \phi(\bx),\forall \bx\in\mathcal{X} \). 
The feature mapping \( \phi: \mathbb{R}^{d'} \to \mathbb{R}^d \) is a fixed mapping with \( \norm{\phi(\bx)}_2 \leq 1 \) for all \( \bx \in \cX \). In the special case of classical linear dueling bandits, we have that \( \phi(\bx) = \bx \), i.e., $\phi(\cdot)$ is the identity mapping. The use of \( \phi(\bx) \) enables us to potentially model non-linear reward functions given an appropriate feature mapping.

In this case, the reward function of every user $i$ is represented by its corresponding \emph{preference vector} $\btheta_i$, and all users in the same cluster share the same preference vector while users from different clusters have distinct preference vectors. 
Denote \( \btheta^j \) as the common preference vector of users in cluster \( C_j \), and let \( j(i) \in [m] \) be the index of the cluster to which user \( i \) belongs. Therefore, for any \( \ell \in \mathcal{U} \), if \( \ell \in C_{j(i)} \), then \( \btheta_\ell = \btheta_i = \btheta^{j(i)} \).

The following assumptions are made regarding the clustering structure, users, and items:
\begin{assumption}[Cluster Separation]
\label{assumption1}
The preference vectors of users from different clusters are at least separated by a constant gap \( \gamma > 0 \), i.e.,
\[
\norm{\btheta^{j} - \btheta^{j'} }_2 \geq \gamma \quad \text{for all} \quad j \neq j' \in [m].
\]
\end{assumption}

\begin{assumption}[Uniform User Arrival]
\label{assumption2}
At each time step \( t \), the user \( i_t \) is selected uniformly at random from \( \mathcal{U} \), with probability \( 1/u \), independent of previous rounds.
\end{assumption}

\begin{assumption}[Item regularity]
\label{assumption3}
At each time step $t$, the feature vector $\phi(\bx)$ of each arm $\bx\in \mathcal{X}_t$ is drawn independently from a fixed but unknown distribution $\rho$ over $\{\phi(\bx)\in\RR^d:\norm{\phi(\bx)}_2\leq1\}$, where 
$\EE_{\bx\sim \rho}[\phi(\bx) \phi(\bx)^{\top}]$ 
is full rank with minimal eigenvalue $\lambda_x > 0$. Additionally, at any time $t$, for any fixed unit vector $\btheta \in \RR^d$, $(\btheta^{\top}\phi(\bx))^2$ has sub-Gaussian tail with variance upper bounded by $\sigma^2$.
\end{assumption}

\noindent\textbf{Remark 1.} All these assumptions above
follow the previous works on clustering of bandits \cite{gentile2014online,gentile2017context,
li2018online,
ban2021local,
liu2022federated,wang2024onlinea,wang2024onlineb}.
For Assumption \ref{assumption2}, our results can easily generalize to the case where the user arrival follows any distribution with minimum arrival probability 
$\geq p_{min}$. 


\subsection{Clustering of Neural Dueling Bandits}
\label{subsec:problem:setting:neural}
Here we allow the reward functions $f_i$'s 
to be non-linear functions.
To estimate the unknown reward functions $f_i$'s, we use fully connected neural networks (NNs) with 
ReLU activations, and denote the depth and width (of every layer) of the NN by $L\geq 2$ and $m_{\text{NN}}$, respectively \cite{zhou2020neural,zhang2020neural}.
Let $h(\bx;\theta)$ represent the output of an NN with parameters $\btheta$ and input vector $\bx$, which is defined as follows:
\[
    h(\bx;\btheta) = \mathbf{W}_L \text{ReLU}\left( \mathbf{W}_{L-1} \text{ReLU}\left( \cdots \text{ReLU}\left(\mathbf{W}_1 \bx\right) \right) \right),
\]
in which $\text{ReLU}(\bx) = \max\{ \bx, 0 \}$, $\mathbf{W}_1 \in \mathbb{R}^{m_{\text{NN}} \times d}$, $\mathbf{W}_l \in \mathbb{R}^{m_{\text{NN}} \times m_{\text{NN}}}$ for $2 \le l < L$, $\mathbf{W}_L \in \mathbb{R}^{1\times m_{\text{NN}}}$. 
We denote the parameters of NN by $\btheta = \left( \text{vec}\left( \mathbf{W}_1 \right);\cdots \text{vec}\left( \mathbf{W}_L \right) \right)$, where $\text{vec}\left( A \right)$ converts an $M \times N$ matrix $A$ into a $MN$-dimensional vector.
We 
use $p$ to denote the total number of NN parameters: $p = dm_{\text{NN}} + m_{\text{NN}}^2(L-1) + m_{\text{NN}}$, and use $g(\bx;\btheta)$ to denote the gradient of $h(\bx;\btheta)$ with respect to $\btheta$.

The algorithmic design and analysis of neural bandit algorithms make use of the theory of the \emph{neural tangent kernel} (NTK) \cite{jacot2018neural}.
We let all $u$ users use the same initial NN parameters $\btheta_0$, and assume that the value of the \emph{empircal NTK} is bounded: $\frac{1}{m_{\text{NN}}}\langle g(\bx;\btheta_0), g(\bx;\btheta_0) \rangle \leq 1,\forall \bx \in \mathcal{X}$.
This is a commonly adopted assumption in the analysis of neural bandits \cite{ICLR23_dai2022federated,kassraie2021neural}. 
Let $T^j$ denote total number of rounds in which the users in cluster $j$ is served. 
We use $\mathbf{H}_j$ to denote the \emph{NTK matrix} \cite{zhou2020neural} for cluster $j$, which is a $(T_j K) \times (T_j K)$-dimensional matrix.
Similarly, we define $\mathbf{h}_j$ as the $(T_j K)\times 1$-dimensional vector containing the reward function values of all $T_j K$ arm feature vectors for cluster $j$.
We provide the concrete definitions of $\mathbf{H}_j$ and $\mathbf{h}_j$ in App.~\ref{app:subsec:aux:defs}.
We make the following assumptions which are commonly adopted by previous works on neural bandits \cite{zhou2020neural,zhang2020neural},
for which we provide justifications in App.~\ref{app:subsec:aux:defs}.
\begin{assumption}
\label{assumption:main:neural}
The reward functions for all users are bounded: $|f_i(x)| \leq 1,\forall x\in\mathcal{X},\forall i\in\mathcal{U}$. 
There exists $\lambda_0 > 0$ s.t.~$\mathbf{H}_j \succeq \lambda_0 I, \forall j\in\mathcal{C}$. 
All 
arm feature vectors satisfy $\norm{x}_{2}=1$ and $x_{j}=x_{j+d/2}$, $\forall x\in\mathcal{X}_{t},\forall t\in[T]$.
\end{assumption}

Denote by \( f^j \) the common reward function of the users in cluster \( C_j \), and let \( j(i) \in [m] \) be the index of the cluster to which user \( i \) belongs. 
Same as Sec.~\ref{subsec:problem:setting:linear}, here all users in the same cluster share the same reawrd function.
Therefore, for any \( \ell \in \mathcal{U} \), if \( \ell \in C_{j(i)} \), then \( f_\ell(\bx) = f_i(\bx) = f^{j(i)}(\bx),\forall \bx\in\mathcal{X} \).
The following lemma shows that when the NN is wide enough (i.e., $m_{\text{NN}}$ is large), the reward function of every cluster can be modeled by a linear function.
\begin{lemma}[Lemma B.3 of \cite{zhang2020neural}]
\label{lemma:linear:utility:function:informal}
As long as the width $m_{\text{NN}}$ of the NN is large enough: $m_{\text{NN}} \geq \text{poly}(T, L, K, 1/\kappa_\mu, L_\mu, 1/\lambda_0, 1/\lambda, \log(1/\delta))$,
then for all clusters $j\in[m]$,
with probability of at least $1-\delta$, there exits a $\btheta^j_{f}$ such that 
\begin{align*}
	f^j(\bx) &= \langle g(\bx;\btheta_0), \btheta^j_{f} - \btheta_0 \rangle, \\
    \sqrt{m_{\text{NN}}} \norm{\btheta^j_{f} - \btheta_0}_2 &\leq \sqrt{2\mathbf{h}_j^{\top} \mathbf{H}_j^{-1} \mathbf{h}_j} \leq B,
\end{align*}
for all $\bx\in\mathcal{X}_{t}$, $t\in[T]$ with $i_t\in C_{j}$.
\end{lemma}
We provide the detailed statement of Lemma \ref{lemma:linear:utility:function:informal} in Lemma \ref{lemma:linear:utility:function} (App.~\ref{app:subsec:proof:neural:real:proof}).
For a user $i$ belonging to cluster $j(i)$, we let $\btheta_{f,i}=\btheta^{j(i)}_{f}$, then we have that $f_i(\bx) = \langle g(\bx;\btheta_0), \btheta_{f,i} - \btheta_0 \rangle,\forall \bx\in\mathcal{X}$.
As a result of Lemma \ref{lemma:linear:utility:function:informal}, for any \( \ell \in \mathcal{U} \), if \( \ell \in C_{j(i)} \), we have that \( \btheta_{f,\ell} = \btheta_{f,i} = \btheta^{j(i)},\forall \bx\in\mathcal{X} \).

The assumption below formalizes the gap between different clusters in a similar way to Assumption \ref{assumption1}.
\begin{assumption}[Cluster Separation]
\label{assumption:gap:neural:bandits}
The reward functions of users from different clusters are separated by a constant gap $\gamma'$:
\begin{small}
\begin{equation*}
    \norm{f^{j}(\bx)-f^{j^{\prime}}(\bx)}_2\geq \gamma'>0\,, \forall{j,j^{\prime}\in [m]\,, j\neq j^{\prime}}\,\forall \bx\in\mathcal{X}.
\end{equation*}  
\end{small}
\end{assumption}

In neural bandits, we adopt $(1 / \sqrt{m_{\text{NN}}})g(\bx;\btheta_0)$ as the feature mapping. Therefore, our item regularity assumption (Assumption \ref{assumption3}) is also applicable here after plugging in $\phi(\bx) = (1 / \sqrt{m_{\text{NN}}})g(\bx;\btheta_0)$.
