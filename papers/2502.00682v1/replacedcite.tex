\section{Related Work}
\label{section:relatedwork}

%%%% 02-relatedwork.tex starts here %%%%
\subsection{Visual Analytics and Guidance}
Visual Analytics (VA) is a human-in-the-loop approach that combines automated analysis techniques with interactive visualizations for an effective understanding, reasoning, and decision-making based on large, complex datasets____.
VA systems incorporate concepts from mixed-initiative systems to \emph{``enable users and intelligent agents to collaborate efficiently''}____ by taking initiatives on behalf of each other during analysis. More recently, VA systems have embraced a `human~\emph{is} the loop' perspective--which emphasizes the central role of the user--by enabling the system to implicitly infer their workflow(s), and seamlessly integrating analytics into it____.
However, automated actions by the system can be mistimed or a result of misinterpreted user intent; whereas, users may need to provide feedback on these automated actions or configure (feedforward) their intent to the system upfront, requiring a continuous, effective dialogue between the two to ensure smooth and effective analytic progress.
Guidance is one such computer-assisted process that aims to actively resolve this ``knowledge gap'' between the user's understanding and the system's capabilities during an interactive analysis session____.
In addition, guidance also aims to ensure effective system operation____, enhance usability____, improve analysis efficiency, validate insights, build confidence, prevent bias, and improve clarity of findings____.

There have been several approaches to conceptualize and apply guidance in visual analytics to improve the quality of interactions between users and systems.
Engels____ characterized guidance into a ``what'' dimension (that defines the problem) and a ``how'' dimension (that defines mechanisms to solve the problem). 
PÃ©rez-Messina~et~al.____ proposed a typology of guidance tasks covering the ``why,'' ``how,'' ``what,'' and ``when'' aspects of guided interactions.
Ceneda~et~al.____ characterized guidance based on the user's knowledge gap, the input and output of the guidance process, and its degree, later formalizing a methodology for designing effective guidance systems____. 
Sperrle~et~al.____ introduced the concept of co-adaptive guidance wherein the user and the system teach and learn from one another during visual data analysis, later contributing a practical framework for developers to build custom guidance strategies____.
In this work, we explore an underexplored dimension of guidance, ``from whom'', focusing on the source of guidance, specifically an \ai{}, a human \expert{}, or a \group{} of analysts, and how it impacts a user's perception and usage of guidance.


\subsection{Studies on Utilization of and Reliance on Guidance}
Understanding how guidance is utilized or relied on is critical for designing effective guidance systems, and has also been a key focus of many prior studies.
For instance, 
Wall~et~al.____, Narechania~et~al.____, and Paden~et~al.____ studied how presenting visual traces of a user's interaction history during analysis can help increase their awareness of analytic behavior and mitigate exploration biases.
Sperrle~et~al.____ conducted a Wizard of Oz study to investigate the interaction dynamics between users and systems in co-adaptive guidance scenarios, focusing on the impact of guidance timing, contextualization, and adaptation, as well as the effects of misguidance on user confidence.
Sperrle~et~al.____ also studied how context-dependent user preferences and feedback during topic model refinement can enable the system (not the user) to learn and adapt its subsequent guidance, fostering effective co-adaptive guidance and human-machine collaboration.

In terms of how people utilize and rely on guidance recommendations originating from different sources, we found a complex interplay between human and algorithmic judgments.
Some studies found that users trust and rely on human partners more than AI____, whereas some others found the opposite____.
For example, Logg~et~al.____ found people often trust algorithms more than human expertise, despite not fully understanding the algorithm's intricacies.
Several studies found that people's reliance on AI depends on various contextual factors, such as their AI literacy____, domain expertise____, and amount of feedback____.
For example, Gajos~et~al.____ found that people make more accurate decisions by actively engaging with detailed explanations of AI recommendations--rather than just viewing the recommendations.
Among human partners, studies have revealed differences between guidance from experts versus groups.
Chen~et~al.____ show that online book purchasing decisions are heavily influenced by consumer recommendations rather than expert opinions. Similarly, Vedadi~et~al.____ find that in information security decisions, users tend to imitate others when faced with uncertainty, impacting their choices more than their personal assessments. This limitation effect extends to software adoption, where user reviews influence lower-ranked products' adoption but not top ones____.

In our study, we examine the utilization and perception of guidance from an \ai{}, a human \expert{}, or a \group{} of analysts as source, which represents what users \textit{do}, complementing prior work that investigates trust and reliance, which represent what users \textit{say}. Our study also collects \remove{verbal}\add{typed textual} responses about trust and reliance to make the set of measures comprehensive in having both objective measures of utilization and subjective metrics of perception. We next describe relevant metrics available in prior work that quantify users' utilization of and reliance on guidance.

\subsection{Metrics to Model Utilization of and Reliance on Guidance}
Several metrics have been proposed that measure people's reliance on AI guidance, quantifying people's ``agreement'' and ``disagreement'' with AI recommendations____, people's ``acceptance'' of incorrect AI recommendations____, 
people's ``change'' in behavior based on AI recommendations____, 
and people's propensity to ``delegate'' eventual decision-making to AI____. 
For instance, 
Lu~et~al.____ proposed the ``agreement'' and ``disagreement'' metrics, which assess how often user predictions are the same as, or different from, AI recommendations, respectively, when users make predictions before seeing AI recommendations.
Buccinca~et~al.____ measured how often users accept incorrect AI recommendations and how often users make mistakes when their predictions differ from the AI's, with both the user's prediction and the AI's recommendation being wrong.
Kim~et~al.____ proposed ``Switch Fraction'' to assess how often users completely change their answers to match AI recommendations____.
Logg~et~al.____ proposed ``Weight of Advice'' (WOA) to measure the proportional change in user predictions relative to the change in AI recommendations. 
Chiang~et~al.____ proposed the ``delegation'' metric to measure how often users let an AI system fully make decisions on their behalf.
These metrics provide a framework for understanding user interactions with guidance systems. In our study, we task participants to select relevant attributes from unfamiliar datasets, but there is no known ground truth in terms of number of attributes to select. Thus, we created new metrics based on these existing ones that better fit our study design.

\subsection{Data Preparation and Subset Selection in Visual Analytics}
Data preparation involves analyzing the data to ensure high-quality results through collection, integration, transformation, cleaning, reduction, and discretization____.
As organizations follow a ``load-first'' philosophy and ``dump'' their data into centralized repositories____, the volume of data often overwhelms users, creating challenges in data navigation, discovery, and monitoring____. 
To mitigate these challenges, prior work has utilized several techniques based on the raw data____, meta-data____, and users' queries____.
For example, Goods infers metadata from billions of datasets within an organization, making them searchable using keywords____.
Similarly, there exist several proprietary____ and open-source____ tools that provide data profile, quality, and lineage information for data observability, monitoring, and pipeline optimization.
For example, 
Profiler____ uses data mining to automatically detect quality issues in tabular data and offers coordinated visualizations for context; whereas, Tableau Prep____, OpenRefine____, and Wrangler____ provide interactive affordances to explore, clean, structure, and shape the data before analysis.

Our study focuses on subset selection\add{____}, which can be achieved through ``feature set reduction'' to decrease the number of attributes or ``sample set reduction'' to reduce the number of records. Feature set reduction is often used in machine learning to eliminate irrelevant features____ or perform dimensionality reduction____; whereas sample set reduction is commonly applied in market segmentation____ to identify specific consumer groups.
Several existing tools facilitate this process of subset selection.
For example, DataPilot____ presents quality and usage information to assist users in selecting effective subsets from large, unfamiliar tabular datasets; 
DataCockpit____ extends these capabilities to multiple relational databases via an open-source Python toolkit.
SmartStripes____ uses automated filter algorithms and statistical correlation measures along with interactive visualizations.
Notably, visualizing how a selected subset compares to the original dataset has been shown to mitigate selection biases____.
The task in our study is similar to DataPilot's____, described next.