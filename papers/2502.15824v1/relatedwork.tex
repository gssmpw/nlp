\section{Related Work}
\subsection{AD Simulation}
Given the associated costs and lack of reproducibility in real-world scenarios, simulation serves as a fundamental tool for developing and evaluating motion planning algorithms. Increasing interest in autonomous driving has led to the introduction of many simulation platforms of varying scopes. Many of which cater to specific driving tasks, e.g. racing \cite{wymann2000torcs}, highway \cite{leurent2018environment}, or urban environment \cite{gulino2024waymax}. The focus of simulations also varies, whether it is on realistic sensor modeling \cite{muller2018sim4cv,dosovitskiy2017carla}, agent behavior modeling \cite{zhou2020smarts,sun2022intersim}, or execution efficiency \cite{gulino2024waymax,scibior2021imagining}.

The current landscape of simulation platforms offers various solutions for evaluating aspects of autonomous driving systems. Excluding some platforms, such as \cite{martinez2017beyond,leurent2018environment,amini2022vista}, which focus on planning in passive driving environments, the majority of simulations offer forms of behavior modeling for social agents (i.e., agents other than the ego-vehicle), which is often extended to multi-agent simulation. This allows multi-instance evaluation in single scenarios \cite{cai2020summit, palanisamy2020multi, craig_quiter_2020,santara2021madras, althoff2017commonroad}. Modeling sensors, such as visible spectrum cameras and LiDAR in some environments \cite{caesar2021nuplan,li2022metadrive, dosovitskiy2017carla, muller2018sim4cv, sun2022intersim, scibior2021imagining} enables the evaluation of full-stack autonomous driving systems. In some cases, occupancy maps are implemented via ray-casting, which provides a basis to model obstructions in the scene from the perspective of the ego-vehicle \cite{vinitsky2022nocturne}. Some platforms also offer unique features, such as mechanisms for V2V communication \cite{palanisamy2020multi}. More recent simulators emphasize behavioral realism \cite{xu2023bits, gulino2024waymax, vinitsky2022nocturne, li2022metadrive} by incorporating expert data (in the form of human demonstrations or trajectories from expert policies) and real-world traffic data, which helps to reduce the sim-to-real gap in training driving models. For a more detailed list of simulations see \cite{Li_2024_tiv}.

In this work, we introduce SMARTS 2.0, built upon the widely used SMARTS \cite{zhou2020smarts} simulator, with a goal of integrating many of the aforementioned features into a single platform. This provides an improved foundation for development of a comprehensive study of AD motion planning algorithms. Our new platform provides a tool-set for the realistic simulation of heterogeneous traffic agents, sensors, and communication channels. In addition, it provides diagnostic tools for evaluating algorithms and further optimizes agent interaction for large-scale multi-agent simulation.

\subsection{Motion Planning Benchmarks}
There are a number of existing benchmarks, e.g. \cite{houston2021one, caesar2020nuscenes, Wilson_Argoverse2}, that focus on the prediction task, which is a key component for motion planning. Here, the goal is to accurately measure the behavior of the social agents, often using a variety of accuracy or diversity metrics \cite{chen2024criteria}. 

Motion planning benchmarks \cite{rasouli2023driving, althoff2017commonroad, Sun_2020_CVPR, Ansys_comp, TPCAP_comp} take one further step and model the response of the mission vehicle to the evolving surrounding environment. Specialized benchmarks, however, evaluate other aspects of the generated behaviors. For example, the CARLA benchmark \cite{dosovitskiy2017carla} is based on synthetic scenarios inspired by the US National Highway Traffic Safety Administration (NHTSA) pre-crash typology whose evaluation is based on route and infraction points. The CommonRoad Benchmark \cite{althoff2017commonroad} focuses on both interactive and non-interactive environments (where trajectories of social agents are provided) and assesses driving styles and rule violations with no restrictions. The Waymo simulation benchmark \cite{Sun_2020_CVPR} is intended for generating human-like trajectories, which are evaluated against real data in terms of realism and distributional distance error. 

In this work, we propose a novel benchmark, focusing on highly interactive scenarios which involve both turning actions at complex intersections and adaptive driving in car following tasks. For evaluation, we improve upon the existing metrics and propose new ones to better capture the practicality of algorithms for real-world applications.