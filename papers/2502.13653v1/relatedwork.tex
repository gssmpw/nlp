\section{Related work}
Our approach is motivated by the fact that the worst-case analysis of algorithms is too pessimistic to give an actual hint about practical algorithm design, and   
can be seen as an attempt to formalize the fact that algorithms can learn to improve their expected performance. For an overview of different approaches to the analysis of algorithms beyond worst-case, the reader is referred to \cite{R21}. The approach more relevant to ours is that introduced in \cite{GR17}, which models algorithm selection as a statistical learning problem. Other notable examples include 
self-improving algorithms~\cite{ACCLMS11}, instance-optimality~\cite{ABC17} and smoothed analysis~\cite{ST09}. Related results on data structures include randomized partition trees whose query running times adapt to the difficulty of the point configuration~~\cite{DS15}, LSH trees whose cutting rules are optimized with respect to the given dataset~\cite{AB22}, and learning-augmented binary trees with optimized search assuming access to advice from a frequency estimation oracle.