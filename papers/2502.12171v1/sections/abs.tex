\begin{abstract}
% \textcolor{red}{Fine-tuning is an essential approach for applying pretrained large language models (LLMs) to various tasks.}Low-Rank Adaptation (LoRA) significantly reduces the cost of fine-tuning LLMs. \textcolor{red}{Nevertheless, LoRA still lags behind full fine-tuning in performance on challenging tasks.}
Low-Rank Adaptation (LoRA) is a crucial method for efficiently fine-tuning pretrained large language models (LLMs), with its performance largely influenced by two key factors: rank and initialization strategy. Numerous LoRA variants have been proposed to enhance its performance by addressing these factors. However, these variants often compromise LoRA's usability or efficiency. In this paper, we analyze the fundamental limitations of existing methods and introduce a novel approach, GoRA (\textbf{G}radient-driven Adaptive L\textbf{o}w \textbf{R}ank \textbf{A}daptation), which adaptively assigns ranks and initializes weights for low-rank adapters simultaneously based on gradient information. Extensive experimental results demonstrate that GoRA significantly improves performance while preserving the high usability and efficiency of LoRA. On the T5 model fine-tuned for the GLUE benchmark, GoRA achieves a 5.88-point improvement over LoRA and slightly surpasses full fine-tuning. Similarly, on the Llama3.1-8B-Base model fine-tuned for GSM8k tasks, GoRA outperforms LoRA with a 5.13-point improvement and exceeds full fine-tuning in high-rank settings by a margin of 2.05 points.

% 问题方法结果，问题讲lora的两个关键点，量化结果要比sota，比全量微调

% On the T5 model fine-tuned for GLUE benchmark, GoRA achieves a 5.89\% performance improvement over LoRA. On the Llama3.1-8B-Base model fine-tuned for GSM8k tasks, GoRA improves the score by 5.13 points compared to LoRA, achieving a final score of 72.91. \yc{consider highlighting the results that performance of GoRA is better than full finetune } These results fully demonstrate the superior performance of GoRA. 
\end{abstract}


\begin{figure*}[htbp] 
    \centering 
    \includegraphics[width=\textwidth]{images/comparison.png}
    \vspace{-1mm}
    \caption{Illustration of (a) vanilla LoRA; (b) LoRA variants utilizing an adaptive rank masking strategy; (c) LoRA variants employing a nonzero initialization strategy; and (d) GoRA, which introduces the key innovation of adaptively leveraging \(W\)'s gradients to allocate adapter ranks and initialize the weights of \(B\). \(A_0\) and \(B_0\) denote the initialized value of matrix \(A\) and matrix \(B\)}
    \label{fig:GoRA} 
\end{figure*} 