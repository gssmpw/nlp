\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{emoji}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

%\emoji{bust-in-silhouette}User-VLM: 
\title{LLM Contextualization with \\Multimodal Pre-trained User Model%*\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Hamed Rahimi and Mohamed Chetouani}
\IEEEauthorblockA{\textit{Institut des Syst√®mes Intelligents et de Robotique} \\
\textit{Sorbonne University}\\
Paris, France \\
\{firstname.lastname\}@sorbonne-universite.fr}
}

\maketitle

\begin{abstract}

To develop AI that mimics human cognition, it is essential to equip it with mechanisms for perceiving and adapting to user models. Traditional approaches to user adaptation often rely on tracking/storing private information, raising privacy concerns. More recent methods focus on modeling user behavior (e.g. click-based) rather than relying on facial or visual features. This paper introduces a novel approach to LLM contextualization through the integration of multimodal pre-trained user models, enabling AI agents to adapt responses based on an implicit understanding of user profiles while respecting privacy constraints. Our method employs a combination of pre-trained models, utilizing both visual and linguistic data, to construct high-dimensional user models that are inherently adaptable. By incorporating these multimodal user models into the LLM contextualization process, our approach allows the AI to generate relevant responses without explicit user tracking. This approach represents a significant step toward creating adaptable, privacy-respecting AI that aligns with user intent and contextual nuances.

\end{abstract}

\begin{IEEEkeywords}
User Modeling, LLM, VLM, MPUM
\end{IEEEkeywords}

\section{Introduction}

talk about human cognition and human response to human interaction from user perspective

give an example 

talk about LLM contextualization

talk about LLM that are contextualized 




\section{Related Work}


\section{Methodology}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/arc2.png}
    \caption{Architecture of User-VLM}
    \label{fig:enter-label}
\end{figure}

\section{Experimental Setup}

\section{Results}

\section*{Acknowledgment}


\section*{References}


\bibliography{ref}

\end{document}
