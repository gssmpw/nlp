\section{Related Work}
\label{sec:Related}
%
\textbf{Logistic bandits.}
%
The logistic bandit problem~\citep{dong2019performance, faury2020improved, abeille2021instance, faury2022jointly, lee2024improved, lee2024unified} is a special case of the MNL bandit problem. 
In this setting, the agent offers only a single item (i.e., $K=1$) and receives $0$-$1$ binary feedback, restricting the problem to the uniform rewards setting.
As summarized in Table~\ref{tab:regrets}, recent works have successfully eliminated the harmful dependency on $1/\kappa$ (which can be exponentially large) in the leading term, achieving instance-dependent regret (i.e., 
 $\kappa^\star_t$-dependent regret). 
However, most of these approaches still suffer from an unnecessary dependency on the norm-boundedness of the unknown parameter, $\operatorname{poly}(B)$.
While a recent work by \citet{lee2024unified} successfully eliminated the $\operatorname{poly}(B)$ factors, their approach incurs a per-round computational cost that grows linearly with $t$.
Thus, the question of whether it is possible to design a $B$-free, computationally efficient algorithm remains open.


\textbf{MNL bandits.}
%
The MNL bandits~\citep{agrawal2019mnl, agrawal2017thompson, ou2018multinomial, chen2020dynamic, oh2019thompson, oh2021multinomial, perivier2022dynamic, agrawal2023tractable, lee2024nearly} address more sophisticated problems compared to logistic bandits, as they involve selecting a set of items (thus highlighting their combinatorial nature) and consider non-uniform rewards rather than binary feedback.
%
Recently, \citet{lee2024nearly} made significant progress by resolving the long-standing open problem of establishing the minimax optimal regret (ignoring factors of $B$ and logarithmic terms) with computational efficiency. 
However, as shown in Table~\ref{tab:regrets}, all existing regret bounds increase with $B$ and $K$. 
Furthermore, the tightest regret bound by \citet{lee2024nearly} includes an additional $(\log T)^{1/2}$ term, arising from a loose confidence bound.
%
To address these limitations, in this paper, we construct the sharpest online confidence bound to date and, leveraging this, achieve (asymptotically) $B,K$-free regret while maintaining computational efficiency.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%