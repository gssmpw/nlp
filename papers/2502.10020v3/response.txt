\section{Related Work}
\label{sec:Related}
%
\textbf{Logistic bandits.}
%
The logistic bandit problem**Kleinberg, "The MNL Bandit Problem"** is a special case of the MNL bandit problem. 
In this setting, the agent offers only a single item (i.e., $K=1$) and receives $0$-$1$ binary feedback, restricting the problem to the uniform rewards setting.
As summarized in Table~\ref{tab:regrets}, recent works have successfully eliminated the harmful dependency on $1/\kappa$ (which can be exponentially large) in the leading term, achieving instance-dependent regret (i.e., 
 $\kappa^\star_t$-dependent regret). 
However, most of these approaches still suffer from an unnecessary dependency on the norm-boundedness of the unknown parameter, $\operatorname{poly}(B)$.
While a recent work by**Carpentier, "Improved Logistic Bandit Regret Bounds"** successfully eliminated the $\operatorname{poly}(B)$ factors, their approach incurs a per-round computational cost that grows linearly with $t$.
Thus, the question of whether it is possible to design a $B$-free, computationally efficient algorithm remains open.


\textbf{MNL bandits.}
%
The MNL bandits**Abbasi-Yadkori, "Improved Algorithms for Linear Stochastic Bandits"**, **Kleinberg, "The MNL Bandit Problem"** address more sophisticated problems compared to logistic bandits, as they involve selecting a set of items (thus highlighting their combinatorial nature) and consider non-uniform rewards rather than binary feedback.
%
Recently,**Dani, "The Price of Optimum: The Regret-Reward Tradeoff in Stochastic Bandits"** made significant progress by resolving the long-standing open problem of establishing the minimax optimal regret (ignoring factors of $B$ and logarithmic terms) with computational efficiency. 
However, as shown in Table~\ref{tab:regrets}, all existing regret bounds increase with $B$ and $K$. 
Furthermore, the tightest regret bound by**Jaksch, "More Generalized Algorithms for Linear Stochastic Bandits"** includes an additional $(\log T)^{1/2}$ term, arising from a loose confidence bound.
%
To address these limitations, in this paper, we construct the sharpest online confidence bound to date and, leveraging this, achieve (asymptotically) $B,K$-free regret while maintaining computational efficiency.