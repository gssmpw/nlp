\section{System Model and Problem Formulation}
\label{sec:system}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{image/sys8.pdf}
        \caption{Illustration of our proposed framework for communication-efficient remote training in task-oriented communication. In stage I, the main goal is to learn the parameters $\theta$ at the edge device for feature extraction without the need of the label information $Y$ and the downstream task $T$. Specifically, the edge devices use data augmentation techniques to generate pair data samples $(X,X')$ from the original observed data $X$ and learn task-relevant information from the paired data by maximizing $I(\hat{Z},\hat{Z'})$. Furthermore, we assume the channel statistics are known at the edge devices for local training and the model for the representation extraction can be siamese or dual networks. In stage II, once the inference task $T$ and label $Y$ are known, the edge deivces and the central server jointly train $(\theta,\phi)$ for the inference task by maximizing the representation sufficiency $I(\hat{Z},Y|T)$.}
    \label{fig:sys}
    \end{figure*}

% We consider a multi-device cooperative edge inference system, which include several edge devices and a central server. The edge devices are equipped with sensors and have limited computation and communication resources, thus they need to collaboratively work for better task inference performance. The edge devices observe the environment from different views of the environment or the interested objects and cooperative to achieve better sensing performance than a single device. Related applicaiton scenarios include multi-camera surveillance, multi-sensor IoT networks, and multi-robot systems. An example model of multi-view/cross-modal person re-identification is illustrated in Fig.~\ref{fig:sys}. We assume the central server has more powerful computation resources and can process the received signals from the edge devices for final inference decisions. However, due to the limited communication bandwidth of edge devices, it is not feasible for edge devices to transmit raw data to the central server (e.g., high-resolution images or videos) for inference especially in a real-time scenarios. Thus to enable low-latency inference, the edge devices are responsible for extracting and transmitting task-relevant information from the raw data and ignoring task-irrelevant information. Furthermore, the compacted task-relevant features are vulnerable to the channel fading and dynamic channel conditions and leadind to informaiton distortion and inference performance degradation. Next, we will first introduce the probabilistic graphical model of the considered task-oriented communication and then formulate two key problems in the proposed task-oriented communication scheme.

As illustrated in Fig.~\ref{fig:sys}, we consider a task-oriented communication system for edge-device co-inference. 
% The edge device is equipped with sensors thus can observe the environment, while the on-device communication and computation resources are quite limited. 
The edge device can observe the environment and extract features from the raw data, while the on-device communication and computation resources are limited.
The server is equipped with powerful computation resources and makes final inference decision based on the received features. 
% The communication cost of edge device is much higher than the server as the on-device energy consumption is a critical issue in the edge computing system.
% Furthermore, we assume the edge server is not predetermined, as connections between devices and servers are dynamic, with each server potentially requiring different task-relevant features. Consequently, edge devices lack access to label information and downstream task before the connection is established.
Furthermore, we assume the edge server is not predetermined, as connections between devices and servers are dynamic, with each server potentially performing different tasks. Consequently, edge devices lack access to label information and downstream task before the connection is established.
% The probabilistic graphical model of the considered task-oriented communication is 
The probabilistic graphical model (PGM) for the considered task-oriented communication system is given by
\begin{equation}\label{eq:original_graph}
\begin{tikzcd}[row sep=tiny]
    Y&X\arrow[l]\arrow[r]&Z\arrow[r]&\hat{Z}\arrow[r]&\hat{Y},
    \end{tikzcd}
\end{equation}
where the target variable $\boldsymbol{y}$ (i.e., the ground truth for the tasks of interest) and the observations of the edge devices $\x$ are the realization of the random variables $Y$ and $X$ from the joint distribution $p_\mathcal{D}(\boldsymbol{y}, \boldsymbol{x})$. Furthermore, $\mathcal{D}$ denotes the dataset of interest. 
The edge device extracts features $\z$ from the observations $\x$ by the on-device feature encoders $p_{\theta}(\z|\x)$ with the parameter $\theta$. The feature encoders could be deterministic or stochastic. The transmitted signal $\hat{\z}$ is normalized to satisfy $\frac{1}{k}\|\hat{\z}\|^2= P$ where $k$ is the demension of the feature ${\z}$ and $P$ is the power constraint. We use $p_{\mathcal{H}}(\hz|\z)$ to denote the transfer probability of the wireless channel and assume the additive white Gaussian noise (AWGN). The distribution of received feature $\hz$ at the server is represented as
\begin{equation}
    p(\hat{\z}) = p({\z})p_{\mathcal{H}}(\hat{\z}|{\z}),
\end{equation}
where $p(\z)$ is the distribution of the transmitted features $\z$. Specifically, the received feature at the central server is given by
\begin{equation}
    \hat{\z} = \h \odot \z + \n,
\end{equation}
where $\h$ is the channel vector between the edge device and the central server. The opreator $\odot$ denotes the element-wise product and $\n\sim \mathcal{CN}(\boldsymbol{0},\sigma_n^2\boldsymbol{I})$ is the AWGN with variance $\sigma_n^2$. The corresponding signal-to-noise ratio (SNR) is defined as $\text{SNR} = \frac{P}{\sigma_n^2}$. Given the transmitted features $\z$, the conditional probability of $p_{\mathcal{H}}(\hz|\z)$ can be expressed by
\begin{equation}
    p_{\mathcal{H}}(\hat{\z}|{\z}) = \mathcal{CN}(\hat{\z};\h\odot{\z},\sigma_n^2\boldsymbol{I}).
\end{equation}
Then the central server receives the feature $\hat{\z}$ and performs inference based on the received features $\hat{\z}$ by the receiver $p_{\phi}(\hat{\boldsymbol{y}}|\hat{\boldsymbol{z}})$ with parameter $\phi$. 


The main design objective is to reduce the overall communication overhead in training stage, given the constraint that the edge devices do not have access to the label information $Y$ and the downstream task $T$ before the connection is established. 


% To address this challenge, we propose a two-phase training framework for task-oriented communication, as illustrated in Fig.~\ref{fig:sys}. In phase I, the main goal is to learn the parameters $\theta$ at the edge device for feature extraction without the need for label information $Y$ and the downstream task $T$. Specifically, the edge devices use data augmentation techniques to generate paired data samples $(X,X')$ from the original observed data $X$ and learn task-relevant information from the paired data by maximizing the mutual information $I(\hat{Z},\hat{Z'})$. Furthermore, we assume the channel statistics are known at the edge devices for local training, and the model for the representation extraction can be siamese or dual networks. In phase II, once the inference task $T$ and label $Y$ are known, the edge devices and the central server jointly train $(\theta,\phi)$ for the inference task by maximizing the representation sufficiency $I(\hat{Z},Y|T)$.


% Given the limited on-device communication resources and the lack of task information before establishing a connection, a primary design challenge is to determine whether it is possible to pre-train the transmitter using only raw data—without access to labels or downstream task details—in order to reduce the number of training rounds required over the wireless channel and thus minimize overall communication costs.


% The central server is equipped with powerful computation resources and is responsible for making final inference decisions based on the received features. The edge devices collaboratively extract features from their own observations and then transmit the features to a central server over wireless channels.

% Thus the edge devices are responsible for refine the raw data and extract features from the raw data. The central server is equipped with powerful computation resources and is responsible for making final inference decisions based on the received features. The edge devices collaboratively extract features from their own observations and then transmit the features to a central server over wireless channels. 


% \subsection{Probabilistic Modeling}
% The probabilistic graphical model of the considered task-oriented communication is illustrated in Fig.~\ref{fig:pgm}, which consists of $K$ edge devices for feature extraction and transmission and a central server for final inference. We assume the target variable $\boldsymbol{y}$ (i.e., the ground truth of the interested tasks) and the observations of the edge devices $(\x_1,\dots,\x_k)$ are the realization of the random variables $Y$ and $(X_1,\dots,X_k)$ from the joint distribution $p_\mathcal{D}(\boldsymbol{y}, \boldsymbol{x}_1, \boldsymbol{x}_2, \cdots, \boldsymbol{x}_K)$ where $\mathcal{D}$ denotes the dataset of interest. The edge devices collaboratively extract features $(\z_1,\dots,\z_k)$ from the observations $(\x_1,\dots,\x_k)$ by the on-device feature encoders $p_{\theta_k}(\z_k|\x_k)$ with parameter $\theta_k$. The feature encoders could be deterministic or stochastic. For the transmission process, we assume orthogonal transmissions from the edge devices to the central server and then the sub-channels are represented as 

% For the transmission process we consider a general wireless channel model, where the received features at the central server represented as 
% \begin{equation}
%     p(\hat{\z}_k) = p({\z}_k)p_{\mathcal{H}}(\hat{\z}_k|{\z}_k),
% \end{equation}
% where $p(\z_k)$ is the distribution of the features $\z_k$ and $p_{\mathcal{H}}(\hat{\z}_k|{\z}_k)$ is the wireless channel model\footnote{The channel model $p_{\mathcal{H}}(\hat{\z}_k|{\z}_k)$ could be a general wireless channel model, e.g., Rayleigh fading channel and etc.}. The central server receives the features $(\hat{\z}_1, \hat{\z}_2, \cdots, \hat{\z}_K)$ from the edge devices and makes inference decisions based on the all received features $(\hat{\z}_1, \hat{\z}_2, \cdots, \hat{\z}_K)$ by the inferencer $p_{\phi}(\hat{\boldsymbol{y}}|\hat{\boldsymbol{z}}_1, \hat{\boldsymbol{z}}_2, \cdots, \hat{\boldsymbol{z}}_K)$ with parameter $\phi$. Based on above dependence assumption, we have
% \begin{equation}
%     \left\{\begin{array}{l}
%         p(\hat{\z}_k,\z_k,\x_k|\y) = p_{\mathcal{H}}(\hat{\z}_k|\z_k)p_{\theta_k}(\z_k|\x_k)p_{\mathcal{D}}(\x_k|\y),\\
%         p(\hat{\y})=p_{\phi}(\hat{\boldsymbol{y}}|\hat{\boldsymbol{z}}_1, \hat{\boldsymbol{z}}_2, \cdots, \hat{\boldsymbol{z}}_K)p(\hat{\boldsymbol{z}}_1, \hat{\boldsymbol{z}}_2, \cdots, \hat{\boldsymbol{z}}_K)
%     \end{array}\right.
% \end{equation}

% % \subsection{On-device Feature Encoding: Minimality and Sufficiency}

% % \subsection{Distributed Feature Encoding: Consistency and Redudancy}
% \subsection{Minimality, Sufficiency, Consistency, and Redundancy}
% In this subsection, we will introduce two key problems in terms of feature encoding: \textit{1) Minimality} and \textit{Sufficiency} for on-device feature encoding, \textit{2) Consistency} and \textit{Redundancy} for cooperative Feature Encoding.

% From the perspective of compression for single device, the minimality and sufficiency of the extracted features are crucial for the task-oriented communication. The minimality requires the extracted features $\z_k$ to be as compact as possible to reduce the communication overhead, i.e., $I(X_k;Z_k)$ should be minimized~\cite{vfe,li2023task}.

% while the sufficiency requires the extracted features $\z_k$ to contain all the necessary information for predicting $Y$, which is defined as follow:
% \begin{definition}{\textbf{Sufficiency:}}
%     A random variable $Z$ is a sufficient representation of $X$ for predicting $Y$ if and only if $I(Z;Y)=I(X;Y)$.
% \end{definition}

% As discussed in~\cite{shao2023task, alemi2016deepVIB,e22090999_ceb}, an ideal representation $Z_k$ should satisfied
% \begin{equation}
%     \begin{aligned}
%         \rlap{$\underbrace{\phantom{{I(X_{k} ; Z_{k}) =I(Y;X_{k})}}}_{\textbf{Minimality}}$} I(X_{k} ; Z_{k}) = \overbrace{I(Y;X_{k}) =I(Y ; Z_{k})}^{\textbf{Sufficiency}},\ k \in \{1,\ldots,K\},
%     \end{aligned}
% \end{equation}

% \begin{definition}{\textbf{Consistency:}}
    
% \end{definition}

% \begin{definition}{\textbf{Redundancy:}}
    
% \end{definition}
% % \begin{itemize}
% %     \item \textit{On-device Feature Encoding: Minimality and Sufficiency}: The on-device feature encoders $p_{\theta_k}(\z_k|\x_k)$ are responsible for extracting the essential information for the inference task and ignoring the task-irrelevant information. The minimality and sufficiency of the extracted features are crucial for the task-oriented communication. The minimality requires the extracted features $\z_k$ to be as compact as possible to reduce the communication overhead, while the sufficiency requires the extracted features $\z_k$ to contain all the necessary information for the inference task. The minimality and sufficiency of the extracted features can be achieved by optimizing the following objective function
% %     \item \textit{Cooperative Feature Encoding: Consistency and Redundancy}: The edge devices collaboratively extract features from their own observations and transmit the features to the central server. The consistency and redundancy of the received features at the central server are crucial for the inference performance. The consistency requires the received features $\hat{\z}_1, \hat{\z}_2, \cdots, \hat{\z}_K$ to be consistent with each other, while the redundancy requires the received features $\hat{\z}_1, \hat{\z}_2, \cdots, \hat{\z}_K$ to contain complementary information for the inference task. The consistency and redundancy of the received features can be achieved by optimizing the following objective function
% % \end{itemize}
% \subsection{Robustness to Dynamic Channel Conditions}
% % The edge devices extract features $\boldsymbol{z}^{(k)}$ from the observations $\boldsymbol{x}^{(k)}$ and transmit the features to the central server. The central server makes inference decisions based on the received features $\boldsymbol{z}^{(1)}, \boldsymbol{z}^{(2)}, \cdots, \boldsymbol{z}^{(K)}$. 


% % The inference decisions are denoted as $\hat{\boldsymbol{y}}$. The probabilistic graphical model is illustrated in Fig.~\ref{fig:pgm}.









% \begin{figure}[t]
% \centering
% \includegraphics[width=\linewidth]{image/pgm.pdf}
% \caption{The probabilistic graphical model of the considered task-oriented communication scheme.}
% \label{fig:pgm}
% \end{figure}



