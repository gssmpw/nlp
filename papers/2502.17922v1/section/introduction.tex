\section{introduction}
\label{sec:introduction}
% As the 5G wireless networks has achieved worldwide great success, the potential development of 6G networks has been attracting increasing attention. The 6G networks are expected to provide a wide range of challenging services, powered by the groundbreaking advancements in artificial intelligence (AI) technologies. Traditional communication systems has been revolutionized by the integration of AI technologies in a lot of aspects, such as signal detection, channel estimation and resource allocation. However, such AI evolution of AI technologies also introduces unprecedented challenges to the current communication systems. The most critical challenge comes from the data-driven property of AI models, which induce a huge demand for data transmission and ultra-low latency, underscoring a urgent need for efficient communication strateiges to support these emering demands.
% With the global success of 5G wireless networks, the development of 6G networks is attracting growing attention~\cite{letaief2019roadmap}. The next-generation networks are expected to deliver a wide range of advanced services, driven by groundbreaking developments in artificial intelligence (AI) technologies. 
% In fact, traditional communication systems have incorporated AI in various fields~\cite{o2017introduction}, including signal detection~\cite{he2020model}, channel estimation~\cite{he2022beamspace} and resource allocation~\cite{shen2020graph}. However, this AI-driven evolution also introduces unprecedented challenges to exsiting communication systems~\cite{shi2020communication}. The most critical challenge arises from the data-driven nature of AI models, which requires substantial data transmission with ultra-low latency, emphasizing an urgent need for efficient communication strategies to support emerging applications.

% Driven by groundbreaking developments in artificial intelligence (AI) technologies, the next-generation wireless networks are expected to deliver a wide range of advanced services such as providing immersive experiences in augmented reality (AR) and virtual reality (VR) applications, enabling intelligent transportation systems, and supporting the Internet of Things (IoT)~\cite{letaief2019roadmap}. However, this AI-driven evolution introduces unprecedented challenges to existing communication systems~\cite{shi2020communication} in terms of massive data transmission and ultra-low latency requirements, emphasizing the urgent need for efficient communication strategies to support emerging applications.

Driven by groundbreaking advancements in artificial intelligence (AI) technologies, next-generation wireless networks are anticipated to deliver a wide range of advanced services, including immersive augmented reality (AR) and virtual reality (VR) experiences, intelligent transportation systems, and support for the Internet of Things (IoT)\cite{letaief2019roadmap}. However, this AI-driven evolution brings unprecedented challenges to existing communication systems\cite{shi2020communication}, particularly in managing massive data transmission and reducing the communication overhead to support these emerging applications.

% meeting ultra-low latency requirements, underscoring an urgent need for efficient communication strategies to support these emerging applications.

A promising solution to address the challenge is task-oriented communication~\cite{vfe,li2024tackling, xu2023edge}, also known as semantic communication~\cite{xie2021deep,xin2024semantic}, which can significantly reduce the communication overhead compared with traditional data-oriented communication systems. The transceivers in previous data-oriented communication aims to deliver the raw information with high fidelity, which is not always necessary for the downstream tasks and has high communication overhead. 
In contrast, the transmitter in task-oriented communication focuses on extracting and transmitting only the task-relevant information from the input data and ignoring the task-irrelevant information, while the receiver focuses on leveraging the received information to accomplish the downstream tasks.

% which significantly reduces the communication overhead.

% Existing works have shown great success of task-oriented communication in efficient information transmission especially for reducing the communication overhead to accomplish the downstream tasks.
Existing works have demonstrated the success of task-oriented communication in reducing communication overhead. The authors of~\cite{bottlenet} proposed a model splitting method to reduce communication overhead by increasing on-device processing within a deep learning-based joint source-channel coding framework~\cite{jssc_deniz}. To further reduce the transmitted symbol rate, this framework was combined with the information bottleneck (IB) principle in~\cite{vfe}, where a sparse-inducing latent prior with a feature pruning scheme based on signal-to-noise ratio (SNR) was proposed to selectively omit certain feature dimensions during transmission.
A more refined mechanism for explicitly reducing bit rate was introduced in~\cite{yang2024swinjscc}, where an additional rate control network was trained to adapt to varying channel conditions and transmission rates. It can achieve a flexible tradeoff between the performance and communication overhead. 
% Instead of feature pruning or rate control, the authors in~\cite{jiang2022wireless} proposed an incremental redundancy hybrid automatic repeat request scheme to improve the inference time reliability of task-oriented communication systems. An error detector was trained to determine which part of task-relevant information need to be retransmitted to ensure the system reliability.
Instead of feature pruning or rate control, an incremental redundancy hybrid automatic repeat request scheme was proposed in~\cite{jiang2022wireless} for efficient information retransmission. In particular, an error detector was trained to determine which part of task-relevant information needed to be retransmitted and thus the reliability of task-oriented communication systems was improved.

% An error detector was trained to determine which part of task-relevant information needed to be retransmitted to ensure system reliability.

However, existing works only consider the inference communication overhead of task-oriented communication, overlooking the communication overhead durinig training. In particular, local training is assumed to jointly train the transmitter and receiver in a centralized manner before deployed separately to the transceivers. However, this assumpation is not feasible in practical wireless communication systems as the connection topology among transceivers is dynamic, hindering locally traininig the model for each new connection~\cite{zhang2022toward}. Thus, remote training is more practical in real-world scenarios, which requires the exchange of forward intermediate features and backward gradients between the transmitter and receiver over wireless channel. Such remote training incurs significant communication overhead, and thus reducing the communication overhead during training is even more critical than that during inference.

% Furthermore, the downstream tasks and ground-truth labels are only available when the receiver is determined. 



% how to leveraging only the input data to pre-train the transmitter without knowing task and label before the connection establishment is critical for reducing the communication overhead during training once the connection is established.


% ommunication overhead in the training stage and achieving label-free and task-agnostic model training are two critical challenges in task-oriented communication.
% In particular, local training refers to jointly training the transmitter and receiver in a centralized manner before deploying them separately to the transceivers, which is not always feasible in practical wireless communication systems. 
% Furthermore, downstream tasks and ground-truth labels are assumed to be known perfectly during training. 
% In practical wireless communication systems, the connection topology among transceivers is dynamic, which hinders retraining the model from scratch for each new connection~\cite{zhang2022toward}. Therefore, minimizing the communication overhead in the training stage and achieving label-free and task-agnostic model training are two critical challenges in task-oriented communication.


% By leveraging sparse inducing latent prior, the authors in~\cite{vfe} propose to utilize pruning operation based on the inference time SNR to explicit omit some feature dimension during the transmission, which can partially reduce the communication overhead during inference time. A more dedicated mechanism for explicit rate control is proposed in~\cite{zhou2022adaptive}. By training an additional rate control network, the proposed method in~\cite{zhou2022adaptive} can adapt to different channel states and transmission rates to achieve a flexible inference time tradeoff between task performance and communication overhead. Similar strategy have been investigated for neural joint source-channel coding~\cite{yang2024swinjscc} and also achieve a superior performance by directly control the rate of the transmitted information. However, all above mentioned methods overlooked the communication overhead during training, under the assumption that either local traning is feasible or the communication overhead durinig training is negligible if compared with that in inference. Furthermore, they also assume that the downstream task and the ground truth are available for training, which is not always the case in practical wireless communication systems. In practical wireless communication systems, the connection topology among transceivers are dynamic and retraining the model from scratch for each new connection is impractical while the label information and the downstream task are not always available before the connection is established. Therefore, how to reduce the communication overhead incurred during training and how to train the model without the need of the label information and the downstream task are two critical challenges in task-oriented communication.


% In this paper, we propose a mutual information maximization approach, supported by information-theoretic analysis, to address these challenges. Specifically, we introduce an efficient strategy that first pre-trains the transmitter in a task-agnostic, label-free manner, followed by joint fine-tuning of the transmitter and receiver in a task-specific, supervised setting. Simulation results demonstrate that the proposed approach can significantly reduce communication overhead during training while achieving performance comparable or even superior to that of state-of-the-art fully supervised methods.

% To tackling the above challenges for reducing the communication overhead during training, in this paper, we propose a mutual information maximization approach grounded in self-supervised learning and information-theoretic analysis. Specifically, we develop an efficient strategy that first pre-trains the transmitter in a task-agnostic and label-free manner with self-supervised learning, followed by joint fine-tuning of the transmitter and receiver in a task-specific manner with supervised learning. Self-supervised learning, which leverages intrinsic patterns in data to create useful representations without relying on the corresponding label, enables us to pre-train models in a task-agnostic and label-free way.
To reduce communication overhead during training, we propose a mutual information maximization approach based on self-supervised learning and information-theoretic analysis. Self-supervised learning, which leverages intrinsic patterns in data to create useful representations without relying on corresponding label, enables us to pre-train models in a task-agnostic and label-free way\footnote{We note that a concurrent work~\cite{gu2024self} also employs self-supervised learning techniques, but with the goal of addressing the challenge of training with limited labeled data, which differs from the main focus of our proposed method.}. Specifically, we develop an efficient strategy that first pre-trains the transmitter using self-supervised learning, allowing it to learn from raw data alone. This pre-training is followed by joint fine-tuning of the transmitter and receiver in a task-specific manner using supervised learning. Simulation results demonstrate that the proposed approach significantly reduces communication overhead during training while achieving comparable or even superior performance to that of state-of-the-art supervised methods. 
% Simulation results demonstrate that the proposed approach significantly reduces communication overhead during training while achieving comparable or even superior performance to that of state-of-the-art supervised methods. 

{\em Notations}: Throughout this paper, upper-case letters (e.g. $X,Y$) represent random variables and lower-case letters (e.g. $\x,\y$) represent the realizations of the corresponding random variables. The shannon entropy of random variable $X$ is denoted as $H(X)$. $I(X;Y)$ is the mutual information between random variables $X$ and $Y$ while $I(X;Y|Z)$ represents the conditional mutual inforamtion between $X$ and $Y$ given $Z$. $D_{KL}(p(\x)||q(\x))$ denotes the Kullback-Leibler (KL) divergence between two probability distributions $p(\x)$ and $q(\x)$.
% However, the communication overhead during training is usually overlooked in these works, which is even more critical than the communication overhead during inference time. The communication overhead during training is mainly caused by the exchange of the model parameters between the transmitter and receiver, which is essential for the transmitter and receiver to learn a good communication strategy. The communication overhead during training is even more critical than the communication overhead during inference time, as the model parameters need to be exchanged frequently and the amount of model parameters is usually large. To address this challenge, a variety of communication-efficient methods have been proposed, such as model compression, model quantization, and task-oriented communication. Among these, task-oriented communication has emerged as a promising paradigm to reduce the communication overhead and improve the system performance by extracting and transmitting only task-relevant information from the input data and ignoring irrelevant information. In task-oriented communication, the transmitter and receiver are trained to jointly optimize the communication strategy to minimize the communication overhead while maintaining the system performance. Most existing task-oriented communication methods focus on the communication overhead and system performance during inference time under the assumption that local training is feasible or the communication overhead during training is negligible. Furthermore, these task-oriented communication methods need to access the downstream task and label information for training. However, in practical wireless communication systems, the connection topology among transceivers are dynamic and retraining the model from scratch for each new connection is impractical while the label information and the downstream task are not always available before the connection is established. Therefore, how to reduce the communication overhead incurred during training and how to train the model without the need of the label information and the downstream task are two critical challenges in task-oriented communication.

% one significant challenge have been overlooked, i.e., the communication overhead during training. The communication overhead during training is mainly caused by the exchange of the model parameters between the transmitter and receiver, which is essential for the transmitter and receiver to learn a good communication strategy. The communication overhead during training is even more critical than the communication overhead during inference time, as the model parameters need to be exchanged frequently and the amount of model parameters is usually large. To address this challenge, a variety of communication-efficient methods have been proposed, such as model compression, model quantization, and task-oriented communication. Among these, task-oriented communication has emerged as a promising paradigm to reduce the communication overhead and improve the system performance by extracting and transmitting only task-relevant information from the input data and ignoring irrelevant information. In task-oriented communication, the transmitter and receiver are trained to jointly optimize the communication strategy to minimize the communication overhead while maintaining the system performance. Most existing task-oriented communication methods focus on the communication overhead and system performance during inference time under the assumption that local training is feasible or the communication overhead during training is negligible. Furthermore, these task-oriented communication methods need to access the downstream task and label information for training. However, in practical wireless communication systems, the connection topology among transceivers are dynamic and retraining the model from scratch for each new connection is impractical while the label information and the downstream task are not always available before the connection is established. Therefore, how to reduce the communication overhead incurred during training and how to train the model without the need of the label information and the downstream task are two critical challenges in task-oriented communication.


% One of the most critical challenges is the communication overhead incurred by the exchange of the model parameters between the transmitter and receiver. The communication overhead is mainly caused by the large amount of model parameters and the high frequency of the model exchange, which will significantly degrade the system performance and limit the scalability of the communication systems. To address this challenge, a variety of communication-efficient methods have been proposed, such as model compression, model quantization, and task-oriented communication.



% Among these, task-oriented communication has emerged as a promising paradigm to reduce the communication overhead and improve the system performance by extracting and transmitting only task-relevant information from the input data and ignoring irrelevant information. In task-oriented communication, the transmitter and receiver are trained to jointly optimize the communication strategy to minimize the communication overhead while maintaining the system performance. Most existing task-oriented communication methods focus on the communication overhead and system performance during inference time under the assumption that local training is feasible or the communication overhead during training is negligible. Furthermore, these task-oriented communication methods need to access the downstream task and label information for training. However, in practical wireless communication systems, the connection topology among transceivers are dynamic and retraining the model from scratch for each new connection is impractical while the label information and the downstream task are not always available before the connection is established. Therefore, how to reduce the communication overhead incurred during training and how to train the model without the need of the label information and the downstream task are two critical challenges in task-oriented communication.

