\section{Related Works}
\label{sec:related}
Noisy labels are inevitable in realworld datasets, posing a significant challenge to the generalization ability of deep neural networks trained on them. These deep neural networks can even easily fit randomly assigned labels in the training data, as demonstrated in **Zhang and Sabuncu, "Adversarial Neural Turing Machines"**. To tackle this challenge, many studies have been proposed for learning with noisy labels. For example, noise-cleansing methods primarily aim to separate clean data pairs from the corrupted dataset using the output of the noisy classifier **Patrini et al., "Loss Covariance and Certifying Robustness in Neural Networks"**. 
Another line of research focuses on designing either explicit regularization or robust loss functions for training to mitigate the problem of noisy labels **Arpit et al., "A Closer Look at Deep Learning Heuristics: Learning Rate, Regularization, Initialization, Optimizer, Batch Size, and Dropout"**. 
To explicitly model  noise patterns, another branch of research suggests using a transition matrix $T$ to formulate the noisy transition from true labels to noisy labels **Patrini et al., "Deep Robust Classification"**. 
Different from these lines of research, Bae et. al**Bae et al., "Noisy Prediction Calibration for Deep Neural Networks"** introduced NPC (Noisy Prediction Calibration), which is a new branch of method working as a post-processing scheme that corrects the noisy prediction from a pre-trained classifier to the true label.

Despite these endeavors of tackling learning with noisy labels, a recent survey **Patrini et al., "Robustness may be optimal in deep neural networks"** points out that the majority of the existing methods are applicable only for a
single-label multiclass classification problem, and more research is required for the multilabel classification problem where each example can be associated with multiple true class labels. 
Our approach focuses on multilabel classification along with recent studies.

More recently, several works have been proposed for multilabel classification with noisy labels.
For example, HLC**Zhang et al., "Learning from Noisy Labels"** uses instance-label and label dependencies in an example for follow-up label correction during training. 
UNM**Patrini et al., "Robust Classification with Adversarial Re-training"** uses a label-wise embedding network that semantically aligns label-wise features and label embeddings in a joint space and learns the co-occurrence of multilabels. The label-wise embedding network cyclically adjusts the fitting status to distinguish the clean labels and noisy labels, and generate pseudo labels for the noisy ones for training. 
Our approach is orthogonal to these studies, and can be seen as a post-processor similar to NPC**Bae et al., "Noisy Prediction Calibration for Deep Neural Networks"** for multiclass classification. 
In other words, our method can be used to correct the predictions of a pre-trained classifier such as HLC, and further improve the performance as a post-processor as we show in~\cref{sec:experiments}.