\section{Related work}
____ were the first to show that conversational technology can respond to users' questions about the processing of their personal data. They called their system Pribots. Similar approaches using retrieval technology for answering privacy-related questions have since been tested____. These papers use classical NLP methods rather than leveraging LLMs, which were not available at the time of publication. Note that Pribots' output is based on extractions of legal texts. Thus, legal texts are quoted directly, which can be problematic for transparency, as legal texts can be difficult to understand, even for legal experts ____.

% ____ generated answers to data processing questions aligned with the GDPR's transparency principle as iterative optimization by multi-disciplinary human experts, namely legal experts and dialog design experts, for preciseness and comprehensibility. These optimized answers present a gold standard. However, generating answers with human experts only and offering them in an FAQ format has at least two transparency issues: (1) FAQs are not necessarily integrated into NLP systems, requiring users to switch interaction modes (e.g., from interacting in natural language to website navigation and reading) affecting accessibility, and (2) even if integrated, FAQs do not cover all possible user questions, creating a potential information gap where requests are not already directly considered in an FAQ. 

____ generated GDPR-aligned answers through iterative optimization by legal and dialogue design experts, thereby fostering preciseness and comprehensibility. These answers serve as a gold standard. However, using them as FAQs poses two transparency issues: (1) they may not integrate with NLP systems, forcing users to switch interaction modes and thereby impacting accessibility, and (2) they cannot cover all user questions, creating potential information gaps.

RAG systems represent a state-of-the-art method to address these issues by combining LLMs with a document database, including, for instance, privacy notices, FAQs, and technical documentation. However, because RAG systems are built on top of LLMs, which are non-deterministic, there exists legal uncertainty as transparency violations may be caused by LLM hallucination when providing such generated answers to data processing questions. This is a well-known problem of RAG and LLM systems, typically mitigated by aligning responses to criteria chosen by developers ____. This work takes the first step toward investigating the feasibility of using RAG to address transparency issues in NLP systems.