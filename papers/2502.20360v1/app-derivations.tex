




\section{Extended derivations}\label{app:derivations}
\subsection{Deriving $f_3$ under the combined rewards, $\hat{R}$}\label{app:f3derived}
Implementing \Cref{thm:attackgeq2} with $\hat{R}$ (\Cref{eq:fullrews})
\begin{align*}
    f_3 &= \sum_{j=0}^{2} \left[\alpha (1-\alpha)^j \int_{0}^\infty \frac{t^j e^{-t/(1-\lambda)}}{j!(1-\lambda)^{j+1}}\mathbb{E}_{r}[R(t)]dt\right] \\
    &= \sum_{j=0}^{2} \left[ \alpha (1-\alpha)^j \int_{0}^\infty \frac{t^j e^{-t/(1-\lambda)}}{j!(1-\lambda)^{j+1}} (C + p\cdot E + t)dt \right]\\ 
    &= \sum_{j=0}^{2} \left[ \alpha (1-\alpha)^j (C + p\cdot E) \right] +  \sum_{j=0}^{2} \left[\alpha (1-\alpha)^j \int_{0}^\infty \frac{t^{j+1} e^{-t/(1-\lambda)}}{j!(1-\lambda)^{j+1}} dt\right] \\ 
    &= \sum_{j=0}^{2} \left[\alpha (1-\alpha)^j (C + p\cdot E)\right] +  (1-\lambda)\sum_{j=0}^{2} \left[\alpha (1-\alpha)^j \cdot (j+1)\right]. 
\end{align*}

% FIXED
% \begin{align*}
%     f_2 &= \sum_{j=0}^{1} \left[\alpha (1-\alpha)^j \int_{0}^\infty \frac{t^j e^{-t/(1-\lambda)}}{j!(1-\lambda)^{j+1}}\mathbb{E}_{r}[R(t)]dt\right]  \\ 
%     &= a \int_{0}^\infty \frac{e^{-t/(1-\lambda)}}{(1-\lambda)} C dt + a(1-a) \int_{0}^\infty \frac{t e^{-t/(1-\lambda)}}{(1-\lambda)^2} C dt \\ 
%     &= C (\alpha + \alpha(1-\alpha))
% \end{align*}

\subsection{Deriving $f_{0,(i)}$ under the combined rewards, $\hat{R}$}\label{app:f0iderived}
\begin{align*}
	f_{0,(i)} =& \alpha \int_0^\infty \frac{e^{-t/(1-\lambda)}}{(1-\lambda)} \int_\beta^\infty x f_t(x) dx dt \\
	=&\alpha \int_0^\infty \frac{e^{- t/(1-\lambda)}}{(1-\lambda)} \int_\beta^\infty x\left[(1-p)\cdot \frac{e^{-(x-C)/(1-\lambda)}}{(1-\lambda)} + p\cdot \frac{e^{-(x-C-E)/(1-\lambda)}}{(1-\lambda)} \right] dxdt\\ 
	=&\alpha\Big[\underbrace{C \cdot \left(p\min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)+(1-p)e^{-(\beta-C)/(1-\lambda)}\right)}_{\text{block reward}}\\
	&+ \underbrace{E \cdot \left(p \min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)\right)}_{\text{bernoulli reward}}\\
	&+ \underbrace{ p \left(1-\lambda+\max(0,\beta- C-E)\right)\min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)}_{\shortstack{\scriptsize expected time $\geq \beta-C-E$ \\\scriptsize given trial succeeded}} \\
	& +
	\underbrace{(1-p)\left(1-\lambda+\beta-C\right)e^{-(\beta -C)/(1-\lambda)}}_{\shortstack{\scriptsize expected time $\geq \beta-C$ \\\scriptsize given trial failed}}\Big]
\end{align*}

\subsection{Deriving $f_{0,(ii)}$ under the combined rewards, $\hat{R}$}\label{app:f0iiderived}
\begin{align*}
	f_{0,(ii)} =& \alpha^2 \int_0^\infty \frac{e^{-t/(1-\lambda)}}{(1-\lambda)} \int_0^\beta x f_t(x) dx dt \\
	=&\alpha^2 \int_0^\infty \frac{e^{-t/(1-\lambda)}}{(1-\lambda)} \int_0^\beta x\left[(1-p)\cdot\frac{e^{-(x-C)/(1-\lambda)}}{(1-\lambda)} + p\cdot \frac{e^{-(x-C-E)/(1-\lambda)}}{(1-\lambda)} \right] dxdt\\ 
	=&\alpha^2 \Big[ \underbrace{C \cdot \left( p\left(1-\min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)\right)+(1-p)\left(1-e^{-(\beta-C)/(1-\lambda)}\right)\right)}_{\text{block reward}}\\
	&+ \underbrace{E \cdot \left(p \left(1-\min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)\right)\right)}_{\text{bernoulli reward}}\\
	&+ \underbrace{p\left(1-\lambda-\left(1-\lambda+\max(0,\beta- C-E)\right)\min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)\right)}_{\shortstack{\scriptsize expected time $< \beta$ \\\scriptsize given trial succeeded}}  \\
	&+ \underbrace{(1-p)\left(1-\lambda-\left(1-\lambda+\beta-C\right)e^{-(\beta -C)/(1-\lambda)}\right)}_{\shortstack{\scriptsize expected time $< \beta$ \\\scriptsize given trial failed}}\Big)\Big]
\end{align*}

\subsection{Deriving $f_{0,(iii)}$ under the combined rewards, $\hat{R}$}\label{app:f0iiiderived}
\begin{align*}
	f_{0,(iii)} =& (1-\alpha)(\alpha+\gamma(1-\alpha))\alpha \int_0^\infty \frac{e^{-t/(1-\lambda)}}{(1-\lambda)} \int_0^\beta x f_t(x) dx dt \\
	=&(1-\alpha)(\alpha+\gamma(1-\alpha))\alpha \\
	&\cdot \int_0^\infty \frac{e^{-t/(1-\lambda)}}{(1-\lambda)} \int_0^\beta x\left[(1-p)\cdot \frac{e^{-(x-C)/(1-\lambda)}}{(1-\lambda)} + p\cdot \frac{e^{-(x-C-E)/(1-\lambda)}}{(1-\lambda)} \right] dxdt\\ 
	=&(1-\alpha)(\alpha+\gamma(1-\alpha)) 
	\\
	&\cdot \Big[ \underbrace{C \cdot \left( p\left(1-\min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)\right)+(1-p)\left(1-e^{-(\beta-C)/(1-\lambda)}\right)\right)}_{\text{block reward}}\\
	&+ \underbrace{E \cdot \left(p \left(1-\min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)\right)\right)}_{\text{bernoulli reward}}\\
	&+ \underbrace{p\left(1-\lambda-\left(1-\lambda+\max(0,\beta- C-E)\right)\min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)\right)}_{\shortstack{\scriptsize expected time $< \beta$ \\\scriptsize given trial succeeded}}  \\
	&+ \underbrace{(1-p)\left(1-\lambda-\left(1-\lambda+\beta-C\right)e^{-(\beta -C)/(1-\lambda)}\right)}_{\shortstack{\scriptsize expected time $< \beta$ \\\scriptsize given trial failed}}\Big)\Big]
\end{align*}

\subsection{Deriving full attacker reward under $\hat{R}$}\label{app:fullcombined}
Starting with calculating the $p_i$ (\Cref{def:stationary}) and $f_i$ (\Cref{def:fis}) values, we have
\begin{align*}
	p_{i-1} &= p_1 \left(\frac{\alpha}{1-\alpha}\right)^{i-2}, \; i\geq 2 \\ 
	f_i &= \underbrace{(C+p\cdot E) \cdot \alpha \sum_{j=0}^{i-1} (1-   \alpha)^{j}}_{\text{bernoulli and block rewards}} + 
               \underbrace{(1-\lambda) \cdot \alpha \sum_{j=0}^{i-1} (1-\alpha)^{j} \cdot (j+1)}_{\text{linear-in-time transaction fees}} \\ 
    &= \underbrace{(C+p\cdot E)\cdot \left(1-(1-\alpha)^i\right)}_{\text{bernoulli and block rewards}}
    +\underbrace{(1-\lambda)\cdot \frac{1-(1+i\alpha)(1-\alpha)^i}{\alpha}}_{\text{linear-in-time transaction fees}}
\end{align*}
From \Cref{def:fullreward}, we write
\begin{align*}
    \text{ATTACKER REWARD} &= p_0f_0 + p_1f_1 + \alpha\sum_{i=2}^\infty  p_{i-1}f_i \\
    &= p_0f_0 + p_1f_1 +p_1\cdot \bigg(
    \underbrace{(C+p\cdot E)\cdot\frac{2\alpha^2(1-\alpha)}{1-2\alpha}}_{\text{bernoulli and block rewards}}
    +\underbrace{(1-\lambda)\cdot\frac{\alpha^2 (3-2\alpha)}{1-2\alpha}}_{\text{linear-in-time transaction fees}}
    \bigg)
\end{align*}

\section{Worked example with only linear-in-time rewards}\label{app:lin-rews-only}
Consider only linear-in-time transaction fee rewards as in \citet{carlsten2016instability}, but with the $1/(1-\lambda)$ rate of block production. We confirm our results exactly analytically match the results of Appendix~E.2, despite using the path counting technique as opposed to their ``attacker probability of capturing each transaction'' method. With $R(t)=t$, the reward CDF (\Cref{def:cdf}) is simply,
\begin{align*}
    F_t(x) = 
    \begin{cases}
    1 & \text{if } t < x \\
    0 & \text{otherwise }
    \end{cases}
\end{align*}
Using the CDF, we derive the transition probabilities, which impact the stationary distribution (\Cref{def:stationary}).
\begin{align*}
    \Pr[\statezeronosp \rightarrow \stateonenosp] &= \alpha \int_0^\infty 1/(1-\lambda)e^{-t/(1-\lambda)} F_t(\beta) dt\\   
    &= \alpha \int_0^\beta 1/(1-\lambda)e^{-t/(1-\lambda)} dt \\
    &= \alpha \left(1-e^{-\beta/(1-\lambda)}\right). \\ 
    \Pr[\statezeronosp \rightarrow \statezeronosp \land \text{attacker block}] &= \alpha \int_0^\infty 1/(1-\lambda)e^{-t/(1-\lambda)} (1-F_t(\beta)) dt\\   
    &= \alpha \int_\beta^\infty 1/(1-\lambda)e^{-t/(1-\lambda)} dt \\
    &= \alpha \left(e^{-\beta/(1-\lambda)}\right).
\end{align*}
Now we need the the reward PDF (\Cref{def:pdf}),
\begin{align*}
    f_t(x) = 1/(1-\lambda)e^{-x/(1-\lambda)}
\end{align*}
Using the PDF we calculate $f_0$ using the three cases.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{arxiv/img/final/linear-only.png}
    \caption{Comparing our analytic results (\Cref{eq:fullattacklinearonly} (denoted as \texttt{x}s labeled with \texttt{ours}) with the Appendix~E.2 formula from \citet{carlsten2016instability} (shown as lines labeled with \texttt{CKWN}). We show values for $\alpha=0.2,0.3,0.4$, $\lambda=0,1/2,1,$ and various values of $\beta$ â€“ the values match to machine precision.} 
    \label{fig:linear-only}
\end{figure}

\noindent Case 1:
\begin{align*}
    f_{0,(i)} &= \alpha\int_\beta^\infty x/(1-\lambda)e^{-x/(1-\lambda)}dx \\
    &= \alpha e^{-\beta/(1-\lambda)}\left(\beta+1-\lambda\right).
\end{align*}
Case 2:
\begin{align*}
    f_{0,(ii)} &= \alpha^2 \int_0^\beta x/(1-\lambda)e^{-x/(1-\lambda)}dx \\ 
    &=\alpha^2 \left(1-\lambda - \left(\beta + 1-\lambda\right)e^{-\beta/(1-\lambda)}\right)
\end{align*}
Case 3:
\begin{align*}
    f_{0,(iii)} &= \alpha(1-\alpha)(\alpha+\gamma(1-\alpha)) \int_0^\beta x(1-\lambda)e^{-(1-\lambda)x}dx \\ 
    &=\alpha(1-\alpha)(\alpha+\gamma(1-\alpha)) \left(1-\lambda - \left(\beta + 1-\lambda\right)e^{-\beta/(1-\lambda)}\right)
\end{align*}
Given $k$ i.i.d. exponential random variables with rate $1/(1-\lambda)$, we have the sum of as $\text{Erlang}(k, 1/(1-\lambda))$, which has an expected value of $k(1-\lambda)$. Thus $\mathbb{E}_r[R(t)]$ for a length $k$ path is $k(1-\lambda)$. 
\paragraph{Calculating $f_1$}
Using the definition of $f_1$,
\begin{align*}
    f_1 &= \alpha \int_0^{\infty} 1/(1-\lambda)e^{-t/(1-\lambda)} \mathbb{E}_{r}[R(t)]dt + \alpha(1-\alpha) \int_{0}^\infty 1/(1-\lambda)^2te^{-t/(1-\lambda)}  \mathbb{E}_{r}[R(t)] dt \\ 
    &= \left(1-\lambda\right)\cdot (\alpha + 2 \alpha(1-\alpha))
\end{align*}
Generalizing the above and following \Cref{thm:attackgeq2}, we have have
\begin{align*}
    f_{i\geq 2} &= \sum_{j=0}^{i-1} \left[\alpha (1-\alpha)^j \int_{0}^\infty \frac{t^j e^{-t/(1-\lambda)}}{(1-\lambda)^{j+1}j!}\mathbb{E}_{r}[R(t)]dt\right]\\
    &= \left(1-\lambda\right)\cdot \sum_{j=0}^{i-1} \alpha (1-\alpha)^j (j+1) \\
    &= \left(1-\lambda\right) \cdot \left(\frac{1-(i+1)(1-\alpha)^i+i(1-\alpha)^{i+1}}{\alpha}\right)
\end{align*}
Thus for the full attacker reward (\Cref{def:fullreward}), we have
\begin{align}\label{eq:fullattacklinearonly}
    \text{ATTACKER REWARD} =& f_0 p_0 + f_1 p_1 \nonumber\\
    &+ \alpha p_1 \sum_{i=2}^\infty \left(1-\lambda\right)\left[\left(\frac{1-(i+1)(1-\alpha)^i+i(1-\alpha)^{i+1}}{\alpha}\right) \cdot \left(\frac{\alpha}{1-\alpha}\right)^{i-2}\right] \nonumber\\ 
    =& f_0 p_0 + f_1 p_1 + p_1\left(1-\lambda\right) \cdot \frac{\alpha^2(3-2\alpha)}{1-2\alpha}
\end{align}
\Cref{fig:linear-only} shows the resulting rewards compared to the analytical result from Appendix~E.2 of \citet{carlsten2016instability}. These values match to machine precision.


\section{Worked example with only block rewards}\label{app:block-rews-only}
Consider the attacker maximizing only for their fraction of the block rewards as in \citet{eyal2013majority}. This ``purely selfish miner'' uses $\beta \to \infty$ as their $\beta$-cutoff strategy, such that they \textit{always} hide blocks mined in \statezeronosp.
With $R(t)=C$, the reward CDF (\Cref{def:cdf}) is simply,
\begin{align*}
    F_t(x) = 
    \begin{cases}
    1 & \text{if } C < x \\
    0 & \text{otherwise }
    \end{cases}
\end{align*}
Using the CDF, we derive the transition probabilities, which impact the stationary distribution (\Cref{def:stationary}) while taking the limit as $\beta \to \infty$, which simplifies the Markov Chain to Figure~1 in \citet{eyal2013majority},
\begin{align*}
    \Pr[\statezeronosp \rightarrow \stateonenosp] &= \lim_{\beta\to\infty} \left(\alpha \int_0^\infty 1/(1-\lambda)e^{-t/(1-\lambda)} F_t(\beta) dt \right)\\   
    &= \alpha \\
    \Pr[\statezeronosp \rightarrow \statezeronosp \land \text{attacker block}] &= \lim_{\beta\to\infty} \left(\alpha \int_0^\infty 1/(1-\lambda)e^{-t/(1-\lambda)} (1-F_t(\beta)) dt \right)\\   
    &= 0.
\end{align*}

\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{arxiv/img/final/ES.png}
    \caption{Comparing our analytic results (\Cref{eq:fullattackblockonly} (colored lines labeled with \texttt{ours}) with Equation~8 from \citet{eyal2013majority} (shown as \texttt{x}s labeled with \texttt{ES}). We show values for $\gamma=0,0.25,0.5$, various values of $\alpha$, and vertical lines at $0.25, 0.3,1/3$ (where $\gamma=0,0.25,0.5$ selfish mining respectively becomes profitable). The slight deviation at higher values of $\alpha$ arises from the introduction of \texttt{State 0''} (as in \citet{carlsten2016instability}).} 
    \label{fig:block-rew-only}
\end{figure}

\noindent We now derive the three cases for \statezeronosp. Case 1:
\begin{align*}
    f_{0,(i)} &= C\alpha.
\end{align*}
Case 2:
\begin{align*}
    f_{0,(ii)} &= C\alpha^2.
\end{align*}
Case 3:
\begin{align*}
    f_{0,(iii)} &= C \alpha(1-\alpha)(\alpha+\gamma(1-\alpha)).
\end{align*}
Since the block reward is constant at $C$, $\mathbb{E}_r[R(t)]=C$ for any length $k$ (recall that the attacker paths as defined in \Cref{ex:state3paths} each only have a \textit{single} attacker block).  
\paragraph{Calculating $f_1$}
Using the definition of $f_1$,
\begin{align*}
    f_1 &= \alpha \int_0^{\infty} 1/(1-\lambda)e^{-t/(1-\lambda)} \mathbb{E}_{r}[R(t)]dt + \alpha(1-\alpha) \int_{0}^\infty 1/(1-\lambda)^2te^{-t/(1-\lambda)}  \mathbb{E}_{r}[R(t)] dt \\ 
    &= C \cdot (\alpha + \alpha(1-\alpha))
\end{align*}
Generalizing the above and following \Cref{thm:attackgeq2}, we have have
\begin{align*}
    f_{i\geq 2} &= \sum_{j=0}^{i-1} \left[\alpha (1-\alpha)^j \int_{0}^\infty \frac{t^j e^{-t/(1-\lambda)}}{(1-\lambda)^{j+1}j!}\mathbb{E}_{r}[R(t)]dt\right]\\
    &= C \cdot \sum_{j=0}^{i-1} \alpha (1-\alpha)^j \\
    &= C \cdot (1-(1-\alpha)^i).
\end{align*}
Thus for the full attacker reward (\Cref{def:fullreward}), we have
\begin{align}\label{eq:fullattackblockonly}
    \text{ATTACKER REWARD} =& f_0 p_0 + f_1 p_1 \nonumber\\
    &+ \alpha p_1 \sum_{i=2}^\infty C\left[ (1-(1-\alpha)^i)\cdot \left(\frac{\alpha}{1-\alpha}\right)^{i-2}\right] \nonumber\\ 
    =& f_0 p_0 + f_1 p_1 + p_1 C \cdot \frac{2\alpha^2(1-\alpha)}{1-2\alpha}
\end{align}
\Cref{fig:block-rew-only} shows the resulting rewards compared to Equation~8 of \citet{eyal2013majority}. These values match nearly exactly. The slight deviation at higher values of $\alpha$ arises from the introduction of \texttt{State 0''} (as in \citet{carlsten2016instability}), which forces the attacker to mine honestly for a single block after publishing their private chain.
