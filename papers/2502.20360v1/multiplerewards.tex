\section{Selfish mining with three reward sources}\label{sec:multiplerewards}
Selfish mining strategies were analyzed with \textit{just} transaction fees and \textit{just} block rewards in \citet{eyal2013majority,carlsten2016instability}, respectively.
With the more general notion of miner rewards as defined in \Cref{sec:prelims}, a similarly general analysis is required to describe the profitability of selfish mining under different reward schedules.
The methodology of path counting and integrating the general reward function established in \Cref{sec:generalstatic} works for any static reward functions. We now instantiate a specific aggregate reward function, which more accurately captures complete miner incentives as they exist in Bitcoin today. 
This combined reward function, which we denote $\hat{R}$, is composed of (1) a fixed block reward of size $C$, (2) a linear-in-time transaction fee reward, and (3) an ``extra'' reward of size $E$ awarded to a block based on the outcome of a Bernoulli trial with probability $p$ (which we sometimes refer to as a ``Bernoulli reward''). Note that this new reward function considers the sum of each of these rewards, a more representative model of how miners are rewarded in reality rather than considering each of the rewards in isolation. For more straightforward examples of applying the path-counting technique to single-source reward functions, see \Cref{app:block-rews-only} for only considering block rewards as in \citet{eyal2013majority} and \Cref{app:lin-rews-only} for only considering transaction fees as in \citet{carlsten2016instability}.

\subsection{Rewards \#1 \& \#2: block rewards and transaction fees}
Each block that a miner produces earns a ``fixed block reward'' of magnitude $C$, which is paid directly to the miner as the first transaction in a block. We consider the block reward fixed.\footnote{The Bitcoin block reward is cut in half every four years, which impacts the relative size of the block reward compared to other reward sources. Our model considers the strategies available to miners within the same block reward period.}
\begin{remark}[Block rewards are static and not persistent]
	Block rewards are a constant function that doesn't depend on $t$,
	\begin{align}\label{eq:blockrews}
		R(t) = C.
	\end{align}
	As such, they are static because each block reward is identically distributed no matter the timestamp of the parent block. Block rewards \textit{are not} persistent, as only a single block reward is claimable per block.
\end{remark}
The miners are also paid through the contents of the block they create. In particular, the transactions themselves specify a fee\footnote{In Bitcoin, the UTXO model defines a set of inputs and outputs for a transaction. Any balance that doesn't specify an output is claimable by the miner.} to be paid to the miner for including the transaction in the block. As in \citet{carlsten2016instability}, we start by assuming transaction fees arrive at a deterministic rate and are fully claimable by any subsequent block.
\begin{remark}[Deterministic transaction fees with fully claiming blocks are static and persistent]
	For all blocks and all time intervals, $t$, transaction fees are static and persistent.
	Using the \citet{carlsten2016instability} definition of fixed-rate transaction fee arrival, we have
	\begin{align}\label{eq:txnrews}
		R(t) = t.
	\end{align}
	This reward is static, as it is the same for all blocks. It is persistent because any block can claim the transaction fees if the transaction is not included in an ancestor block. 
\end{remark}
From \Cref{lem:linear}, we also see that static and persistent rewards imply linearity.

\subsection{Rewards \#3: non-deterministic extra rewards}
We also introduce a third type of reward to our model, motivated by the reality that some blocks have much higher transaction fee revenue than others due to contention. \citet{ZurAET23} use a similar model to capture high-fee-paying transactions in addition to block rewards; see \Cref{subsec:relwork} for further discussion. Consider, for example, that a new type of transaction can become available at a specific block height, and only a fixed amount of those transactions are valid (e.g., the first 10,000 transactions that purchase a specific NFT). To get their transaction included, participants submit bids specifying the fee they will pay to the block producer for higher-priority inclusion (mention that this assumes transactions are ordered by fee). This contention for block space leads to much higher revenue for the miner (who serves as the auctioneer) because even assuming infinite block sizes, the finite nature of the transaction type induces the competition (sometimes referred to as a ``priority gas auction'' \cite{daian2019flash}). We model this reward as a fixed size ``extra reward'' of magnitude $E$ available to a miner of a block with probability $p$ (a Bernoulli trial) and independent of time. We refer to this reward function as ``Bernoulli rewards.'' 

\begin{remark}[Bernoulli rewards are static and not persistent]
    Bernoulli rewards are static because each block has the same distribution of rewards according to the outcome of the trial,
    \begin{align}\label{eq:bernoullirews}
        R(t) = \begin{cases}
            E & \text{if } X=1\\
            0 & \text{otherwise},
        \end{cases}
        \quad \text{where } X \sim \text{Bernoulli}(p).
    \end{align}
    As in the block reward case, Bernoulli rewards are per-block; they are not persistent because they are specific to the block that mined them and are not claimable otherwise. 
\end{remark}

Note that this model doesn't allow for the ``predictability'' of these Bernoulli rewards. Since miners may know a priori what block height a new set of transactions will arrive at, miners' strategy space would be different than the standard selfish mining strategies we explore below. 

\begin{definition}[Reward function instantiation, $\hat{R}$]
	Combining the three reward sources (\Cref{eq:blockrews,eq:txnrews,eq:bernoullirews}), we have the full reward function, which we denote as $\hat{R}$,
	\begin{align}\label{eq:fullrews}
		\hat{R}(t) &= C + t + E \cdot \mathds{1}[X=1], \; X\sim \text{Bernoulli}(p).
	\end{align}
\end{definition}

Recall that the path-counting technique defined in \Cref{sec:generalstatic} applies to any static reward function. Since $\hat{R}$ is the sum of three independent, static rewards sources, it is static itself, and thus, we can analyze it. Under $\hat{R}$, we seek to calculate the attacker reward (\Cref{def:fullreward}). Following the structure above, we define the Markov Chain as a function of $\hat{R}$, which induces a stationary distribution $p_i$ before explicitly calculating the per-state attacker reward $f_i$. 

\subsection{Transition probabilities}
We instantiate the general Markov Chain (\Cref{def:markovchain}) with our reward function $\hat{R}$. Recall that the selfish miner hides their block in \texttt{State 0} only if the realized rewards of the block are less than $\beta$. We calculate the CDF of the reward function (\Cref{def:cdf}), which depends on the relative size of $\beta$ and $E+C$.\footnote{We ignore the case where $C > \beta$ because that implies the attacker never hides their block and mines honestly.} If $\beta \leq C+E$, then the Bernoulli trial succeeding means $R(t) = t + C + E > \beta, \forall t$. Thus, for a given amount of time since parent, $t$, the total reward is less than $\beta$ only if the trial fails,
\begin{align*}
	F_t(\beta)_{\beta \leq E+C} = 
	\begin{cases}
		1-p & \text{if } t \leq \beta-C \\
		0 & \text{otherwise} 
	\end{cases}
\end{align*} 
If $\beta > E+C$, the total rewards may be less than $\beta$ even if the trial succeeds. Thus, the time component of the rewards must be sufficiently large for the total reward to exceed $\beta$. First, if $t < \beta-C-E$, the total rewards are certainly less than $\beta.$ If $t \in [\beta-C-E, \beta-C]$, the total reward is greater than $\beta$ only if the Bernoulli trial succeeds. Lastly, if $t \geq \beta - C$, the rewards exceed $\beta$ regardless of the trial outcome. Thus, 
\begin{align*}
	F_t(\beta)_{\beta > E+C} = 
	\begin{cases}
		1 & \text{if } t < \beta - C - E \\
		1-p & \text{if } t \in [\beta-C-E, \beta-C] \\
		0 & \text{otherwise}
	\end{cases}
\end{align*}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{arxiv/img/final/mc-instantiation.png}
    \caption{A Markov Chain for the $\beta-$cutoff strategy under the combination of (i) deterministic linear-in-time transaction fees, (ii) block rewards of magnitude $C$, and (iii) an extra Bernoulli reward of magnitude $E$. The $\min$ function is necessary to capture both the cases of $\beta \leq C + E$ and $\beta > C+E$ }
    \label{fig:mc-instance}
\end{figure}

Using these CDFs, we start by calculating the probability of the attacker transitioning to \texttt{State 1} (as in \Cref{eq:zerotoone}). 
An attacker will hide a block at time $t$ if the total rewards of the block are less than $\beta$. We calculate this probability by integrating over all possible times.
\begin{align*}
	\Pr[\texttt{State 0} \rightarrow \texttt{State 1}] 
	% &= \alpha \int_0^\infty (1-\lambda)e^{-(1-\lambda)t} F_t(\beta)dt \\
	&= \alpha \Big[
	\underbrace{(1-p)\left(1-e^{-(\beta -C)/(1-\lambda)}\right)}_{\shortstack{\scriptsize trial fails and \\\scriptsize $t < \beta - C$}}+ 
	\underbrace{p\left(1-\min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)\right)}_{\shortstack{\scriptsize trial succeeds and \\\scriptsize $t < \beta - C - E$}}\Big]
\end{align*}


Next, we calculate the other transition out of \texttt{State 0}, where the attacker publishes their block because the reward exceeds $\beta$ (as in \Cref{eq:zerotozero}). An attacker will publish a block at time $t$ since the parent block if the total rewards of the block are greater than $\beta$. We calculate this probability by integrating over all possible times.
\begin{align*}
	\Pr[\texttt{State 0} \rightarrow \texttt{State 0} \land \text{attacker block}] 
	% &= \alpha \int_0^\infty (1-\lambda)e^{-(1-\lambda)t} (1- F_t(\beta))dt \\
	&= \alpha \Big[
	\underbrace{(1-p)e^{-(\beta -C)/(1-\lambda)}}_{\shortstack{\scriptsize trial fails and \\\scriptsize $t \geq \beta - C$}}+ 
	\underbrace{p \min\left(1,e^{-(\beta-C-E)/(1-\lambda)}\right)}_{\shortstack{\scriptsize trial succeeds and \\\scriptsize $t \geq \beta - C - E$}}\Big]
\end{align*}

With these state transitions calculated, we present the complete Markov chain for the $\beta-$cutoff strategy in \Cref{fig:mc-instance}. 

\paragraph{Stationary distribution}
Using \Cref{def:stationary}
\begin{align*}
	&p_0 = \frac{p_1}{\alpha (1-p)(1-e^{-(\beta-C)/(1-\lambda)}) + \alpha p(1-  \min(1, e^{-(\beta-C-E)/(1-\lambda)}))} \\ 
	& \implies  p_1 = \left(\frac{1}{\alpha (1-p)(1-e^{-(\beta-C)/(1-\lambda)}) + \alpha p(1-  \min(1, e^{-(\beta-C-E)/(1-\lambda)}))} + 1 + \frac{1-\alpha}{1-2\alpha}\right)^{-1}.
\end{align*}

\subsection{Expected attacker rewards}
To continue the attacker reward calculation, we need to calculate the per-state expected attacker reward (\Cref{def:fis}). To calculate these values, we need to find the expected value of the reward function, $\hat{R}$ (\Cref{eq:fullrews}), depending on the time until the next block. Again, we use the \texttt{State 3} example to illustrate.
\begin{example}[\texttt{State 3} attacker paths, $\hat{R}$]
Recall that we have paths, \texttt{A, HA, HHA} respectively. Each block the attacker creates earns the constant block reward, $C$, and a Bernoulli reward of magnitude, $p \cdot E$. 
\begin{align*}
    f_3 = \underbrace{(C + p\cdot E)\cdot(\alpha + (1-\alpha)\alpha + (1-\alpha)^2\alpha)}_{\shortstack{\scriptsize block and Bernoulli rewards}} + \underbrace{(1-\lambda)\cdot( \alpha + 2(1-\alpha)\alpha + 3 (1-\alpha)^2\alpha)}_{\shortstack{\scriptsize linear-in-time transaction fees}}.
\end{align*}
\end{example}
For the derivation according to \Cref{thm:attackgeq2}, see \Cref{app:f3derived}. This example prompts the instantiated versions of $f_{i}$. The expected attacker reward in \texttt{State i}, where $i \geq 2$, is
\begin{align*}
    f_{i\geq 2} = \underbrace{(C + p\cdot E)\cdot \sum_{j=0}^{i-1}\left[\alpha (1-\alpha)^i\right]}_{\text{block and bernoulli rewards}} 
    + \underbrace{(1-\lambda)\sum_{j=0}^{i-1}\left[ \alpha (1-\alpha)^{j} (j+1)\right]}_{\text{linear-in-time transaction fees}}
\end{align*}

This follows from enumerating the $i$ paths out of \texttt{State i} and calculating the probability of each occurring multiplied by the expected length of that path to find the value of the reward function. Note that we can write $\mathbb{E}_r[R(t)] = C + p\cdot E + t,$ because the expectation over the randomness of the Bernoulli reward is the expected value of the trial and the expectation over the time reward is linear as $t$.

\paragraph{Calculating $f_0$.}
As in \Cref{subsec:perstateattacker}, we enumerate the three cases for \texttt{State 0}. We first define the PDF of $\hat{R}(t)$, 
\begin{align*}
	f_t(x) = (1-p)\cdot\frac{e^{-(x-C)/(1-\lambda)}}{(1-\lambda)} + p\cdot \frac{e^{-(x-C-E)/(1-\lambda)}}{(1-\lambda)}.
\end{align*}
At time $t$, the instantaneous probability that the reward function $\hat{R}(t) = x$ depends on the outcome of the Bernoulli trial. If the trial fails, then the total reward is $\hat{R}= t+C$; thus $\Pr[t+C] = x$ is simply $\Pr[t] = x-C$, which for an exponential is $\frac{e^{-(x-C)/(1-\lambda)}}{(1-\lambda)}$. If the trial succeeds, by the same logic, we calculate $\Pr[t]=x-C-E$ as $\frac{e^{-(x-C-E)/(1-\lambda)}}{(1-\lambda)}.$ For \textbf{Case i}, the attacker publishes the block immediately; those rewards become theirs on the canonical chain.
\begin{align*}
	f_{0,(i)}
	=&\alpha \int_0^\infty\frac{e^{- t/(1-\lambda)}}{(1-\lambda)}\int_\beta^\infty x\left[(1-p)\cdot\frac{e^{-(x-C)/(1-\lambda)}}{(1-\lambda)} + p\cdot\frac{e^{-(x-C-E)/(1-\lambda)}}{(1-\lambda)}\right] dxdt.
\end{align*}
To evaluate the integral see \Cref{app:f0iderived}.
For \textbf{Case ii}, the attacker block mined in \texttt{State 0} will become canonicalized for certain once they mine the second block. Thus, they realize these rewards when transitioning to \texttt{State 2}.
\begin{align*}
	f_{0,(ii)} 
	=&\alpha^2 \int_0^\infty \frac{e^{-t/(1-\lambda)}}{(1-\lambda)} \int_0^\beta x\left[(1-p)\cdot\frac{e^{-(x-C)/(1-\lambda)} }{(1-\lambda)}+ p\cdot \frac{e^{-(x-C-E)/(1-\lambda)}}{(1-\lambda)} \right] dxdt.
\end{align*}
To evaluate the integral, see \Cref{app:f0iiderived}. For \textbf{Case iii}, the attacker block mined in \texttt{State 0} will become canonicalized only if they win the race out of \texttt{State 0'} (i.e., either by themselves or the $\gamma (1-\alpha)$ portion of the honest network that contributes to their chain mining the subsequent block and breaking the tie). Thus, they realize these rewards upon transitioning to \texttt{State 0}.
\begin{align*}
    f_{0,(iii)} 
	=&\alpha(1-\alpha)(\alpha+\gamma(1-\alpha)) \\
	&\cdot \int_0^\infty \frac{e^{-t/(1-\lambda)}}{(1-\lambda)} \int_0^\beta x\left[(1-p)\cdot\frac{e^{-(x-C)/(1-\lambda)} }{(1-\lambda)}+ p\cdot \frac{e^{-(x-C-E)/(1-\lambda)}}{(1-\lambda)} \right] dxdt.
\end{align*}
For the evaluation of the integral see \Cref{app:f0iiiderived}.
Thus $f_0 = f_{0,(i)} + f_{0,(ii)}+f_{0,(iii)}$.

\paragraph{Calculating $f_1$.}
To conclude, we need $f_1$. Rewards arriving in that \stateone will be canonicalized by the attacker under two paths: (i) the attacker finds the next block (transitioning into \texttt{State 2}) or (ii) the honest party finds the next block (transitioning into \texttt{State 0'}) \textit{and} the attacker finds the subsequent. This is \Cref{thm:attackgeq2} with $i=2$, 
\begin{align*}
	f_1 =  (C+p\cdot E)\cdot (\alpha + \alpha(1-\alpha)) + (1-\lambda)\cdot (\alpha + 2\alpha(1-\alpha)).
\end{align*}
As before, the rewards accruing in \texttt{States 0' \& 0''} are already accounted for in the reward calculations from \texttt{States 1 \& 2} respectively. We can now explicitly calculate the attacker reward (\Cref{def:fullreward}).
The full attacker reward under $\hat{R}$ is, 
\begin{align*}
	\text{ATTACKER REWARD} &= p_0f_0 + p_1f_1 +p_1\cdot \bigg(
    \underbrace{(C+p\cdot E)\cdot\frac{2\alpha^2(1-\alpha)}{1-2\alpha}}_{\text{bernoulli and block rewards}}
    +\underbrace{(1-\lambda)\cdot\frac{\alpha^2 (3-2\alpha)}{1-2\alpha}}_{\text{linear-in-time transaction fees}}
    \bigg)
\end{align*}
For the derivation, see \Cref{app:fullcombined}.


\subsection{Numerical results and discussion}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{arxiv/img/final/rew-comp.png}
    \caption{Comparing the full attacker reward (\Cref{def:fullreward}) under the $\hat{R}$ reward function (\Cref{eq:fullrews}) for various strategies with $p=0.25, E = 4, C=1, \gamma=0$. Each strategy chooses the $\beta$, which maximizes the reward portion described in parenthesis. We compare across a range of $\alpha$ values and see that optimizing for the total rewards dominates each of the other strategies, which focus on a single reward source.}
    \label{fig:rew-comp}
\end{figure}

We now turn to numerical results based on the expected attacker reward for the combined reward function $\hat{R}.$ 

\paragraph{Attacker reward comparison.}
\Cref{fig:rew-comp} shows the full attacker reward (\Cref{def:fullreward}) under the $\hat{R}$ reward function (\Cref{eq:fullrews}) for various strategies. For each value of $\alpha$, the $\beta$ is selected to maximize the portion of rewards denoted in the parenthesis (for \texttt{Selfish}, $\beta \to \infty$ as always hiding maximizes the share of block rewards). We see that optimizing for the \texttt{Total} reward function (the sum of the three constituent parts) dominates the other strategies for all values of $\alpha$. The inset axes zoom in on the critical region to show the values of $\alpha$ at which each strategy outperforms \texttt{Honest}. Note that \texttt{Honest} is represented by $3\alpha$ because the expected value of the sum of the reward sources is $3$. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{arxiv/img/final/interpolation.png}
    \caption{The attacker rewards as a function of $\alpha$ under different metrics of rewards. We consider three miners who optimize for block rewards, linear-in-time rewards, and a combination of both. See \Cref{app:block-rews-only,app:lin-rews-only} for the derivations of linear and block rewards, respectively, under our model. Considering both rewards together paints a more realistic picture of the protocol risk.}
    \label{fig:interpolation}
\end{figure}
\paragraph{Interpolating between reward sources.}
\Cref{fig:interpolation} paints a different picture by ploting the rewards \textit{as measured individually}. \texttt{Selfish} (in red) shows the percentage of the block rewards collected when always hiding in \texttt{State 0} (which is exactly the reward in \citet{eyal2013majority} – see \Cref{app:block-rews-only} for the full derivation). \texttt{$\beta-$cutoff (linear)} (in blue) shows the percentage of the linear-in-time transaction fees collected on the attacker chain when choosing $\beta$ to maximize this ratio (which is exactly the reward in \citet{carlsten2016instability} – see \Cref{app:lin-rews-only} for the full derivation). \texttt{$\beta-$cutoff (linear + block)} shows the attacker's reward when considering both reward sources together. We chose $p=0.25, E=1$ to ensure that the expected Bernoulli reward ($p\cdot E= 1)$ matches the expected linear rewards (scaled by $1/(1-\lambda)$ because of difficulty adjustment). One interpretation of \Cref{fig:interpolation} examines how different reward regimes can lead to dramatically different conclusions regarding the ``risk of attack'' a protocol faces. In this case, the selfish miner who only optimizes for the ratio of block rewards is not profitable until $\alpha=1/3$. On the other hand, if we only consider the fraction of linear-in-time transaction fees capturable by a $\beta$-cutoff selfish miner, the story looks much worse. In particular, that miner becomes profitable around $\alpha=0.15$. Considering both rewards results in a more measured conclusion, where the strategy becomes profitable around $\alpha=0.25$. By varying the relative size of the block reward compared to the per-unit linear-in-time transaction fees, we can thus fully capture the dynamics of both reward models by interpolating between the two strategies, which consider the sub-rewards in isolation. Additionally, this figure can be interpreted qualitatively. We see that the attacker considering both rewards (tan) behaves \textit{less aggressively} than the linear optimizing attacker (blue) for $\alpha \in [0.15, 0.25]$, as the optimal reward in that range is equivalent to honest. Conversely, for $\alpha \in [0.3, 0.33]$, a pure selfish mining strategy would not be profitable; thus, the attacker considering both rewards would be \textit{more aggressive} than the block-reward maximizing miner (who would choose to mine honestly).

\begin{figure}
    \centering    
    \includegraphics[width=0.65\linewidth]{arxiv/img/final/threshold-alphas.png}
    \caption{Demonstrating the $\alpha$ at which each strategy becomes profitable over honest as a function of $\gamma$. This extends Figure~3 from \citet{eyal2013majority} to include more strategies. Each respective strategy considers profitability when only measuring a subset of the total rewards. For example, \texttt{linear + block rewards} (in blue) denotes a $\beta-$cutoff strategy for $\alpha$ profitable if, when selecting $\beta$ to maximize the sum of linear and block rewards, the expected attacker reward exceeds $2\alpha$.}
    \label{fig:threshold-alphas}
\end{figure}

\paragraph{Profitability thresholds.}
\Cref{fig:threshold-alphas} shows the value of $\alpha$ at which various strategies become profitable under different reward sources as a function of $\gamma$. This extends Figure~3 of \citet{eyal2013majority} to include more strategies. For each $\gamma$, we consider the optimal $\beta$ cutoff for an attacker, maximizing block, linear, and total rewards, respectively. For each candidate $\alpha$, we check if the optimal $\beta$ results in a total reward that exceeds the benchmark of the honest performance under that reward function (i.e., the proportional block rewards from honest mining). We find the lowest candidate $\alpha$ such that the rewards exceed the benchmark and identify that as the profitability threshold. Intuitively, this is the fraction of the mining power needed to perform this strategy profitably. 

For the pure selfish miner (in green), we see that the profitability thresholds of $1/3,0.3, 0.25$ for $\gamma=0,0.25,0.5$ are identical to \citet{eyal2013majority}. When considering just linear and block rewards (in blue) and the total rewards (linear + block + bernoulli) (in pink), we see that for all values of $\gamma$, the profitability threshold decreases significantly. For example, at $\gamma=0$, the profitability threshold is reduced from $1/3 \rightarrow 0.26 \rightarrow 0.18$ (reductions of $22\%$ and $31\%$ respectively) when considering the different reward sources. Similarly, at $\gamma=0.5$, the profitability threshold is reduced from $0.25 \rightarrow 0.18 \rightarrow 0.09$ (reductions of $28\%$ and $50\%$ respectively).

The attacker that only considers linear-in-time transaction fees (shown in red) is profitable for nearly all values of $\alpha$. While this may seem concerning, we believe an aggregate view of the rewards (e.g., total shown in pink) more accurately represents rewards as they exist in Bitcoin today. 


\paragraph{Measuring Bernoulli reward.}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{arxiv/img/final/bernoulli.png}
    \caption{The attacker rewards as a function of $\alpha$ under different metrics of rewards. We consider miners who optimize for block rewards, Bernoulli rewards, and the full $\hat{R}$ containing block, Bernoulli, and linear rewards. Note that the Bernoulli reward-optimizing attacker is profitable for all values of $\alpha$ and meaningfully deviates from honest for $\alpha>0.1$.}
    \label{fig:bernoullis}
\end{figure}
\Cref{fig:bernoullis} examines the profitability of two other mining strategies: optimizing $\beta$ for Bernoulli rewards (in green) versus optimizing $\beta$ for the sum of linear, block, and Bernoulli rewards (in tan). Again, the combined rewards interpolate between the Bernoulli and the block-optimizing miners. For the miner maximizing over all three rewards, we normalize them each to have an expected value of $1$ per block (e.g., by setting the Bernoulli probability and scale such that $p \cdot E = 1$). The miner who only considers Bernoulli rewards (in green) is always profitable and significantly outperforms honest when $\alpha\geq 0.1$. Bernoulli rewards (or another model capturing the variability and scale of MEV rewards) might be the most interesting for future analysis as Bitcoin block rewards continue to halve and transaction fees persist at relatively low values. 

\paragraph{Rewards as a function of $\beta$ and simulation results.}
\begin{figure}
	\centering  
	\includegraphics[width=1\linewidth]{arxiv/img/final/sims.png}
	\caption{Theoretical and simulated values for miner rewards of the three component rewards constituting $\hat{R}$ as a function of $\alpha,\beta$.}
	\label{fig:sims}
\end{figure}

\Cref{fig:sims} plots the expected reward of each of the constituent rewards of $\hat{R}$ under various combinations of $\alpha,\beta$. Notably, the rewards may not be monotone in $\beta$, meaning the miner optimizing for the total rewards (or some specific subset) can choose the optimal $\beta$ that differs both from honest ($\beta=0$) and from selfish ($\beta \to \infty$). Each reward calculation for $\beta$-cutoff strategies in \Cref{fig:threshold-alphas,fig:interpolation,fig:bernoullis} chooses the optimal $\beta$ before evaluating the strategy against the benchmark. These simulated values help confirm that the path-counting technique presented in \Cref{sec:generalstatic} is correct. We also validate this by performing a similar analysis for linear-in-time transaction fees and block rewards in \Cref{app:block-rews-only,app:lin-rews-only}, respectively.


