@misc{anthropic2024claude,
  author = {Anthropic},
  year = {2024},
  url = {https://www.anthropic.com/news/claude-3-5-sonnet},
  title = {Claude 3.5 Sonnet},
}

@inproceedings{asai2024selfrag,
author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
title={Self-{RAG}: Learning to Retrieve, Generate, and Critique through Self-Reflection},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=hSyW5go0v8}
}

@inproceedings{chen2024teaching,
title={Teaching Large Language Models to Self-Debug},
author={Xinyun Chen and Maxwell Lin and Nathanael Sch{\"a}rli and Denny Zhou},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=KuPixIqPiq}
}

@misc{gou2024critic,
      title={CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing}, 
      author={Zhibin Gou and Zhihong Shao and Yeyun Gong and Yelong Shen and Yujiu Yang and Nan Duan and Weizhu Chen},
      year={2024},
      eprint={2305.11738},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.11738}, 
}

@article{guan2023leveraging_PDDL,
  title={Leveraging pre-trained large language models to construct and utilize world models for model-based task planning},
  author={Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={79081--79094},
  year={2023}
}

@inproceedings{gupta2023visual_reason_cv,
  title={Visual programming: Compositional visual reasoning without training},
  author={Gupta, Tanmay and Kembhavi, Aniruddha},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14953--14962},
  year={2023}
}

@misc{huang2022large,
      title={Large Language Models Can Self-Improve}, 
      author={Jiaxin Huang and Shixiang Shane Gu and Le Hou and Yuexin Wu and Xuezhi Wang and Hongkun Yu and Jiawei Han},
      year={2022},
      eprint={2210.11610},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.11610}, 
}

@inproceedings{huang2024large,
title={Large Language Models Cannot Self-Correct Reasoning Yet},
author={Jie Huang and Xinyun Chen and Swaroop Mishra and Huaixiu Steven Zheng and Adams Wei Yu and Xinying Song and Denny Zhou},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=IkmD3fKBPQ}
}

@article{ji2023survey_hallucination,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{jiang2024resprompt_graph,
  title={RESPROMPT: Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models},
  author={Jiang, Song and Shakeri, Zahra and Chan, Aaron and Sanjabi, Maziar and Firooz, Hamed and Xia, Yinglong and Akyildiz, Bugra and Sun, Yizhou and Li, Jinchao and Wang, Qifan and others},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={5784--5809},
  year={2024}
}

@article{kim2024language_reason_computer,
  title={Language models can solve computer tasks},
  author={Kim, Geunwoo and Baldi, Pierre and McAleer, Stephen},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{openai2024o1,
      title={Introducing OpenAI o1}, 
      author={OpenAI},
      year={2024},
      url={https://openai.com/o1/}
}

@article{pan2024automatically,
    title = "Automatically Correcting Large Language Models: Surveying the Landscape of Diverse Automated Correction Strategies",
    author = "Pan, Liangming  and
      Saxon, Michael  and
      Xu, Wenda  and
      Nathani, Deepak  and
      Wang, Xinyi  and
      Wang, William Yang",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "12",
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2024.tacl-1.27",
    doi = "10.1162/tacl_a_00660",
    pages = "484--506",
}

@inproceedings{paul2024refiner,
    title = "{REFINER}: Reasoning Feedback on Intermediate Representations",
    author = "Paul, Debjit  and
      Ismayilzada, Mete  and
      Peyrard, Maxime  and
      Borges, Beatriz  and
      Bosselut, Antoine  and
      West, Robert  and
      Faltings, Boi",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.eacl-long.67",
    pages = "1100--1126",
}

@article{sun2024adaplanner_feedback,
  title={Adaplanner: Adaptive planning from feedback with language models},
  author={Sun, Haotian and Zhuang, Yuchen and Kong, Lingkai and Dai, Bo and Zhang, Chao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{wang2023boosting_CoK,
  title={Boosting language models reasoning with chain-of-knowledge prompting},
  author={Wang, Jianing and Sun, Qiushi and Li, Xiang and Gao, Ming},
  journal={arXiv preprint arXiv:2306.06427},
  year={2023}
}

@inproceedings{wang2023describe_reason_mc,
  title={Describe, explain, plan and select: interactive planning with large language models enables open-world multi-task agents},
  author={Wang, Zihao and Cai, Shaofei and Chen, Guanzhou and Liu, Anji and Ma, Xiaojian and Liang, Yitao and CraftJarvis, Team},
  booktitle={Proceedings of the 37th International Conference on Neural Information Processing Systems},
  pages={34153--34189},
  year={2023}
}

@misc{wang2023shepherd,
      title={Shepherd: A Critic for Language Model Generation}, 
      author={Tianlu Wang and Ping Yu and Xiaoqing Ellen Tan and Sean O'Brien and Ramakanth Pasunuru and Jane Dwivedi-Yu and Olga Golovneva and Luke Zettlemoyer and Maryam Fazel-Zarandi and Asli Celikyilmaz},
      year={2023},
      eprint={2308.04592},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{xue2025decompose,
  title={Decompose, Analyze and Rethink: Solving Intricate Problems with Human-like Reasoning Cycle},
  author={Xue, Shangzi and Huang, Zhenya and Liu, Jiayu and Lin, Xin and Ning, Yuting and Jin, Binbin and Li, Xin and Liu, Qi},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={357--385},
  year={2025}
}

@inproceedings{yao2023react,
  title = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  booktitle = {International Conference on Learning Representations (ICLR) },
  year = {2023},
  html = {https://arxiv.org/abs/2210.03629},
}

@article{zhang2024llm_reasong_survey,
  title={LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models},
  author={Zhang, Yadong and Mao, Shaoguang and Ge, Tao and Wang, Xun and de Wynter, Adrian and Xia, Yan and Wu, Wenshan and Song, Ting and Lan, Man and Wei, Furu},
  journal={arXiv preprint arXiv:2404.01230},
  year={2024}
}

@inproceedings{zhouleast2most,
  title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc V and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023},
}

