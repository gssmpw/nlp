\section{Related Work}
\paragraph{Reasoning with LLMs.}
LLMs such as GPT____, LLaMA____, and Claude____, demonstrate impressive reasoning capabilities across various NLP tasks____. However, due to the problems of direct reasoning with LLMs such as hallucinations____, researchers have proposed several methods to enhance the reasoning power of LLMs. For example, 
%Least-to-Most~
____ decompose complex tasks into sequential subproblems, while %AdaPlanner~
____ refine reasoning through environment feedback. Moreover, intermediate representations, such as graphs____, planning domain definition languages (PDDL)____, and triples____, have been employed to enhance LLM's reasoning.
Most recently, OpenAI o1____ demonstrates strong reasoning capabilities and broad world knowledge. Upon further contemplation, it is capable of reasoning through complex tasks and addressing challenges that exceed those faced by previous scientific, coding, and mathematical models.

Simultaneously, domain-specific reasoning with LLMs has gained attention. ____ enhance reasoning outputs in computer tasks through recursive critique. In a case study using Minecraft, ____ introduce a Describe, Interpret, Plan, and Select framework for open-world multitasking. In computer vision, ____ employ Python-like modular programs to tackle complex tasks. Nonetheless, reasoning in code remains an area yet to be thoroughly explored.

\paragraph{Improvement with Reflection.} Reflective ability is regarded as a crucial metric for evaluating LLMs as agents. Reflection can be categorized into internal and external based on its feedback source____. Internal reflection relies feedback from the model's own knowledge and parameters____, while external feedback comes from various sources, including humans____, other models____, external tools____, or knowledge bases____.
____ find that LLMs struggle to self-correct their responses without external feedback, and in some cases, their performance may even decline following self-correction. Our work focuses on leveraging external tools, such as compilers, to generate feedback and enhance the performance of LLMs.