\section{Related Work}
\paragraph{Reasoning with LLMs.}
LLMs such as GPT-3, "Improving Language Understanding by Generative Pre-Training"__LLaMA, "Large Language Model Meta AI"__Claude, "Claude: The Multilingual AI Model"__, demonstrate impressive reasoning capabilities across various NLP tasks__. However, due to the problems of direct reasoning with LLMs such as hallucinations__, researchers have proposed several methods to enhance the reasoning power of LLMs. For example, 
%Least-to-Most~
Decompose, "Decompose: A Framework for Decomposing Complex Tasks"__ refine reasoning through environment feedback. Moreover, intermediate representations, such as graphs__, planning domain definition languages (PDDL)__, and triples__, have been employed to enhance LLM's reasoning.
Most recently, OpenAI o1__, "Open AI One" demonstrates strong reasoning capabilities and broad world knowledge. Upon further contemplation, it is capable of reasoning through complex tasks and addressing challenges that exceed those faced by previous scientific, coding, and mathematical models.

Simultaneously, domain-specific reasoning with LLMs has gained attention.  enhance reasoning outputs in computer tasks through recursive critique. In a case study using Minecraft,  introduce a Describe, Interpret, Plan, and Select framework for open-world multitasking. In computer vision,  employ Python-like modular programs to tackle complex tasks. Nonetheless, reasoning in code remains an area yet to be thoroughly explored.

\paragraph{Improvement with Reflection.} Reflective ability is regarded as a crucial metric for evaluating LLMs as agents. Reflection can be categorized into internal and external based on its feedback source__. Internal reflection relies feedback from the model's own knowledge and parameters__, while external feedback comes from various sources, including humans__, other models__, external tools__, or knowledge bases__.
 find that LLMs struggle to self-correct their responses without external feedback, and in some cases, their performance may even decline following self-correction. Our work focuses on leveraging external tools, such as compilers, to generate feedback and enhance the performance of LLMs.