\section{Results}
\label{results}
In this section, we provide an overview of the various results obtained in the process of gathering, structuring, and validating our dataset of real faults, including the dataset itself, the taxonomy, and the reflections based on the dataset, interviews and surveys leading to answers to our research questions.


\subsection{Faults Dataset}
Our datasets consist of 133 real faults from GitHub issues and 52 from the interviews. The interviews resulted in adding a full category of ``Conceptualisation'' that was not captured by the GitHub mining. After the interviews, we decided to merge the ``Ansatz Creation'' category as a sub-category of Quantum Circuits, because they pertain to the same components of the architecture. Moreover, we gathered all API-related faults into a new category. As a result, we finally ended up with seven top-level categories: Parametrisation, Conceptualisation, API, Optimisation, Quantum Circuit, Measurement and GPU. Table \ref{tab:database} gives an overview of the partition of the dataset in our final categories. The numbers separated by a plus sign represent the faults from the GitHub mining and the interviews respectively. 35\% of GitHub faults produce a wrong output, 3\% performance issues, and the remaining cause different crashes. Interviewees mentioned, however, that over 75 \% of faults led to wrong outputs, 8\% causing performance issues, and the remaining producing different crashes. Further labelling (of symptoms and causes) and a description and link to each fault are available in the \href{https://anonymous.4open.science/r/A-Taxonomy-of-Real-Faults-in-Hybrid-Quantum-Classical-Architectures-EE25/README.md}{replication package}.


\begin{table}[hbt!]
    \centering
        \caption{Overview of the final result of faults included in the dataset: ``Level'' is the fault location in the hybrid architecture; ``Faults'' is the total number of faults, differentiating betw.\ GitHub- and interview-sourced faults   (GitHub+Interviews); ``In Lib.'' denotes the faults in the libraries and ``Not in Lib.'' are those in the code using the libraries (both differentiating Github- + Interview-sourced faults).  }
    \begin{tabular}{@{}c|c|c|c|c}   
    \hline
        \textbf{Level} & \textbf{Faults} & \textbf{In Lib.} & \textbf{Not in Lib.} & \textbf{Sub-Categories} \\
    \hline
      Parametrisation & 22+8  & 10+2 & 12+6 & 8 \\
      \hline
      Conceptual & 0+17 & 0+0 & 0+17 & 6\\
      \hline
      API & 30+6 & 5+4 & 25+2 & 3 \\
      \hline
      Optimisation & 34+11 & 24+3 & 10+8 & 12 \\
      \hline
      Quantum Circuit & 24+3 & 21+1 & 3+2 & 8 \\
      \hline
      Measurement & 15+7 & 13+5 & 2+2 & 6 \\
      \hline
      GPU & 8+0 & 8+0 & 0+0 & 4 \\
      \hline
      \textbf{TOTAL} & 133+52 & 81+15 & 52+37 & 47 \\
      \end{tabular}
    \label{tab:database}
\end{table}



\subsection{Final Taxonomy}
The final taxonomy, displayed in Fig.~\ref{FinalTax}, is organised based on seven top-level categories, further divided into sub-categories. We decided to organise the taxonomy around categories representing the location of the fault, and sub-categories corresponding to the cause of this fault, to make sure it is relevant to both fault detection and fault localisation.
For each category and sub-category, we report the number of found real bugs; as before, the numbers are separated by a plus sign between the number of faults originating from the GitHub mining and those originating from the interviews,  respectively. As these numbers indicate, each subcategory contains multiple fault types. We have established 125 unique labels overall. However, due to space limitations, we could not demonstrate all of them in the taxonomy figure. In what follows next, we concisely present all categories and sub-categories. 

%Due to space limitations, not all details could fit into the paper and we, therefore, advise you to refer to the \href{https://anonymous.4open.science/r/A-Taxonomy-of-Real-Faults-in-Hybrid-Quantum-Classical-Architectures-EE25/README.md}{replication package} for more detailed labelling and the references to the origin of each fault.


\paragraph{Parametrisation}
Parametrisation issues consist of all faults that occur at the initial phase of parametrisation of the quantum circuit and the optimiser, divided into 8 sub-categories listed in Table \ref{tab:parametrisation}. This category of faults was equally represented in GitHub and interviews, accounting for ca.\  15\% of faults in both sources. Faults in this category are usually caused by a wrong data type for parameters or a wrong initialisation and would result in both wrong outputs or crashes.

An example of a fault of this type is a \href{https://github.com/PennyLaneAI/pennylane/issues/900}{GitHub issue} in which a \textit{pennylane.numpy.tensor} type sequence is initialised as a parameter gate at the parametrisation phase, causing a Runtime Error. The key-words arguments are assumed to be non differentiable by default, which causes a crash with certain devices that  are not capable of supporting the application of a gate taking this type of argument. It was fixed by ensuring the arguments are marked as differentiable when passed to a QNode as a keyword argument. This fault has been placed in the \textit{Tensors} sub-category and was marked as a fault inside a library. 
%This \href{https://github.com/PennyLaneAI/pennylane/issues/900}{Github issue} examplifies a Parametrisation fault in the sub-category \textit{Tensors}. A \textit{pennylane.numpy.tensor} type sequence is initialised as a parameter gate at the parametrisation phase, causing a Runtime Error. It was therefore labeled as an In Library Fault. 



\begin{table}[hbt!]
    \centering
        \caption{Faults happening at the parametrisation phase of the system, divided into 8 sub-categories. Typical cause is the most used label in this category, Nb is the number of faults from online resources and interviews respectively.}
    \label{tab:parametrisation}

    \begin{tabular}{@{}c|l|c}
       \textbf{Sub-Categories} & \textbf{Typical cause} & \textbf{Nb} \\
         \hline
       Tensors  & Wrong input type for tensors & 2+0 \\
         \hline
       Gradients  & Wrong initialisation type for the gradients & 3+0 \\
         \hline
        Parametric initialisation & Wrong initial point & 8+6 \\
          \hline
        Model Size & Suboptimal depth size for the model  & 3+0 \\
          \hline
        Operation Pool & Suboptimal number of operators in the pool & 0+1 \\
          \hline
        Circuit Declaration & Wrong qubit register declaration & 4+1 \\
          \hline
        Register Length & Wrong initialisation of the register & 1+0 \\
          \hline
        Seed Settings & Global seed is not set  & 1+0 \\
    \end{tabular}
\end{table}

\paragraph{Conceptual}
\label{conceptualisation}
This category emerged from the interviews and accounts for 33\% of the faults mentioned by experts as shown in Table \ref{tab:database}. It consists of the conceptual mistakes made while translating the domain knowledge into an instance of a Hybrid Quantum-Classical architecture. This translation process is far from trivial and several faults that may be introduced in the translation process are listed in Table 
\ref{tab:conceptual}. In Section \ref{vqa seq}, we have introduced the key concepts used in this category, such as Hamiltonians, which is the representation of a quantum system and corresponds to a specific electronic structure. During the iteration process, this electronic structure corresponding to the represented system can be broken, leading to erroneous behaviours. More details can be found in Tilly et al.'s detailed review of VQE \cite{tilly_variational_2022}.

For instance, four experts mentioned Conceptual faults introduced by suboptimal Ansatz design as discussed in \href{https://anonymous.4open.science/r/A-Taxonomy-of-Real-Faults-in-Hybrid-Quantum-Classical-Architectures-EE25/Interviews/Pollished/Interview5_Pollished.docx}{this interview}. A poor Ansatz design can significantly affect the optimisation process: it will lead to performance issues and wrong outputs. It can be the root cause of Barren plateaus issues. Yet, finding an optimal Ansatz design is very challenging even for domain experts, it is problem-specific, and still an active area of research \cite{tilly_variational_2022}.


\begin{figure*}[hbt!]
    \centering
   \includegraphics[width=\textwidth,height=7cm]{Figures/taxonomy.png}

   \caption{The final taxonomy, organised into 7 top-level categories in darker colours, divided into 47 sub-categories in lighter shades of the same colour.}
\label{FinalTax}
\end{figure*}


\begin{table}[hbt!]
    \centering
    \caption{Faults happening at the conceptualisation phase, comprising 6 sub-categories. Typical cause is the most used label in this category, Nb is the number of faults from online resources and interviews respectively.}
    \label{tab:conceptual}
    \begin{tabular}{@{}c|l|c}
         \textbf{Sub-Categories} & \textbf{Typical cause} & \textbf{Nb} \\
         \hline
      Hamiltonian & Incorrect physical to qubit Hamiltonian transformation & 0+4\\
      \hline
      Electronic Structure & Broken electronic symmetries & 0+3 \\
      \hline
        Cost Function & Suboptimal cost function definition & 0+3 \\
        \hline
        Model Size & Suboptimal model size &  0+2 \\
        \hline
        Ansatz & Suboptimal Ansatz design & 0+4 \\
        \hline
       Data Processing  &  Mismatch between training data and parametric data &  0+1 \\
    \end{tabular}
\end{table}

\paragraph{API}
API issues pertain to either the usage of an API or an internal problem in the API itself. We found API misuse to be very common, representing over 20\% of the GitHub faults and 10\% of the interview faults as shown in Table \ref{tab:database}. This can be due both to the complexity of the frameworks and the lack of proper documentation for advanced features. The latter was mentioned several times during the interviews as a challenge in Hybrid Quantum-Classical architectures. Frameworks to implement customised Hybrid Quantum-Classical architectures are rare. Developers often need to integrate machine learning frameworks such as Tensorflow or PyTorch into quantum simulators such as Qiskit or Cirq. Faults in such an integration introduce crashes, failures, wrong behaviours, and performance issues. This category was initially a sub-category in several categories and was later consolidated into a coherent category, divided into 3 sub-categories listed in Table \ref{tab:api}. 

A common example of API issues is the use of Deprecated API as in the following \href{https://github.com/Qiskit/qiskit-aer/issues/1595}{example}. The simulators commonly used are constantly being refactored, and the documentation available online do not always lead to the latest version available. As a result, programs have a very short life expectancy and developpers constently need to adapt their code to the latest versions.

\begin{table}[hbt!]
    \centering
        \caption{Faults happening at the API level of the system, divided into 3 sub-categories. Typical cause is the most used label in this category, Nb is the number of faults from online resources and interviews respectively.}
    \label{tab:api}
    \begin{tabular}{@{}c|l|c}

         \textbf{Sub-Categories} & \textbf{Typical cause} & \textbf{Nb} \\
         \hline
      API Misuse & Developer Error & 24+0\\
      \hline
      Deprecated API & Calling old function & 4+1 \\
      \hline
        Suboptimal API integration  & Integration between frameworks & 2+5 \\
    \end{tabular}
\end{table}


\paragraph{Optimisation}
This category concerns the faults occurring in the classical code for optimisation. We initially named this category \textit{Training}, refering to Humbatova et al.'s Taxonomy of Real Faults in Deep Learning Systems \cite{humbatova_taxonomy_2019}. However, we realised at a later stage that \textit{Optimisation} defines better this category in the context of Hybrid Quantum-Classical architectures. This category is still labelled as \textit{Training} in the \href{https://anonymous.4open.science/r/A-Taxonomy-of-Real-Faults-in-Hybrid-Quantum-Classical-Architectures-EE25/README.md}{replication package} to acknowledge the evolution of our study.
It is the biggest category of our taxonomy, both in the numbers of faults and of sub-categories, accounting for about 25\% of GitHub faults and 20\% of interviews` faults, divided into 12 sub-categories, listed in Table \ref{tab:training}. 
The large number and diversity of faults in this category are motivated by the corresponding complexity and size of the code: due to the noise in the current architectures, the amount of classical code for optimisation dominates the complexity and size of the quantum circuit. At each iteration, the measurements of the quantum circuit are stored as intermediate results, the cost function is updated, and the coefficients of each parametric gate and the weights of the Ansatz's layers are updated for the next iterations. A more detailed explanation is available in Tilly et al.'s review of VQE \cite{tilly_variational_2022}. 

An example of an optimisation fault from the \textit{Tensors} sub-category is a 
\href{https://github.com/tensorflow/quantum/issues/321}{GitHub issue} in which a fault occurs during the optimisation process where the data passed between each epoch do not have the same batch size. The fault was diagnosed by slowly building up the model and ensuring the shape inputs behave properly. It was fixed by setting a batch size appropriate to the training data. 

\begin{table}[hbt!]
    \centering
        \caption{Faults happening at the optimisation phase of the system, divided into 12 sub-categories. Typical cause is the most used label in this category, Nb is the number of faults from online resources and interviews respectively.}
    \label{tab:training}
    \begin{tabular}{p{3cm}|p{8cm}|c}
       \textbf{Sub-Categories} & \textbf{Typical cause} & \textbf{Nb} \\
         \hline
       Coefficients  & Wrong handling of unshifted coefficients & 1+0 \\
         \hline
      Handling of intermediate results  & Wrong calculation of intermediate operators &  1+0 \\
         \hline
        Iteration problems & Wrong handling of weights & 14+4 \\
          \hline
        Matrix Calculation & Mismatching ordering method for results  matrices  & 2+2 \\
          \hline
        Memory & Suboptimal memory consumption calculation & 1+0 \\
          \hline
        Model Size & Inefficient memory handling & 2+1 \\
          \hline
        Parameter Shift & Wrong handling of parameterized gates & 2+0 \\
          \hline
        Randomisation & Suboptimal random generation mechanism & 1+0 \\
         \hline
        Sorting Mechanism & Mismatch between sorting mechanism and associated probabilities &  1+0 \\
         \hline
        Tensors & Wrong input type passed to the tensors  & 8+0 \\
         \hline
        Objective Functions & Suboptimal objective function interaction with tensors &  1+0 \\
         \hline
        Barren Plateaus & Suboptimal Ansatz structure / Noisy Measurements &  0+4 \\
    \end{tabular}
\end{table}


\paragraph{Quantum Circuit}
In this category, elaborated in Table \ref{tab:quantum}, we gather the faults in the quantum circuit, divided into 8 sub-categories. These bugs are specific to the design of a quantum circuit and are caused by the incorrect design of the Ansatz, its parametric nature, or the iteration over the circuit. 

For instance, this \href{https://github.com/tensorflow/quantum/issues/176}{fault}, categorised as \textit{Ansatz Creation}, was introduced by the developer who did not place a Hadamard Gates Wall in the Ansatz before the model circuit, which broke the link between the input tensor and to the sample layer and led to incorrect outputs. The Ansatz was conceptualised properly, but wrongly implemented. This issue was found by debugging the outputs behaviour when modifying the Ansatz, until the origin of the wrong behaviour was found. 

\begin{table}[hbt!]
    \centering
       \caption{Faults originating from the quantum circuit, divided into 8 sub-categories. Typical cause is the most used label in this category, and Nb is the number of faults from online resources and interviews, respectively.}
    \label{tab:quantum}
    \begin{tabular}{@{}c|l|c}
       \textbf{ Sub-Categories} & \textbf{Typical cause} & \textbf{Nb} \\
         \hline
       Circuit decomposition  & Suboptimal handling of redundant qubits &  3+0 \\
         \hline
       Gates  & Wrong handling of custom gates  & 4+1 \\
         \hline
        Initialisation & Suboptimal kernel building &  2+2 \\
          \hline
        Operators & Suboptimal qubit reduction &  7+0 \\
          \hline
        Pauli Sums & Suboptimal handeling of PauliSum Operator & 0+1 \\
          \hline
        Phase & Wrong handling of global phases &  1+0 \\
          \hline
        Register Mapping & Incorrect handling of unusual types by register mapping &  2+0 \\
          \hline
        Ansatz Creation & Wrong input type passed to the layers &  3+0 \\
    \end{tabular}
\end{table}


\paragraph{Measurement}
In this category, listed in Table \ref{tab:measurements}, the issues related to the measurement phase are classified. They represent about 11\% of both GitHub and interview faults. Measurement is a crucial phase since it represents the transition from quantum information into classical information and many faults occur due to inappropriate choice of measurement (e.g., in grouping the observables) or transformation and storage of classical results (e.g., floating point operations or storing the variables). 

In this \href{https://github.com/tensorflow/quantum/issues/235}{issue}, a measurement imprecision accumulates with the circuit's size, leading to a wrong output. This is due to a sub-optimal extraction of the measurements introduced by the qsim version used when iterating over the qubits; hence it was labelled as an In Library fault. It was fixed by updating the iteration process ensuring the C++ version of qsim used and the referenced version do not mismatch.


\begin{table}[hbt!]
    \centering
        \caption{Faults originating from the measurements, divided into 6 sub-categories. Typical cause is the most used label in this category, Nb is the number of faults from online resources and interviews respectively.}
    \label{tab:measurements}
    \begin{tabular}{@{}c|l|c}
       \textbf{ Sub-Categories} & \textbf{Typical cause} & \textbf{Nb} \\
         \hline
       Expectation Value  & Suboptimal observables grouping strategy &  5+0 \\
         \hline
       Precision  & Wrong handling of floating points & 1+1 \\
         \hline
        Observables & Suboptimal measurement process &  3+0 \\
          \hline
        Noise & High noise level &  0+6 \\
          \hline
        Storing results & Suboptimal type for storing results &  3+0 \\
          \hline
        Memory use & Memory handling  & 3+0 \\
    \end{tabular}
\end{table}

\paragraph{GPU}
The issues related to the use of a GPU in the architecture are listed in Table \ref{tab:gpu}. 

This \href{https://github.com/Qiskit/qiskit-aer/issues/1647}{Segmentation Error example}, categorised as \textit{Memory Allocation}, is due to a Unitary matrix larger than the matrix buffer allocated to GPU. We expect this category to become more significant in the future since much work aims to further integrate GPUs into Hybrid Quantum-Classical architecture and quantum simulators.

\begin{table}[hbt!]
    \centering
        \caption{Faults originating from the GPU integration, divided into 4 sub-categories. Typical cause is the most used label in this category, Nb is the number of faults from online resources and interviews respectively.}
    \label{tab:gpu}
    \begin{tabular}{@{}c|l|c}
       \textbf{ Sub-Categories} & \textbf{Typical cause} & \textbf{Nb} \\
         \hline
      Memory Allocation  & Wrong memory allocation for GPU when the model is big &  2+0 \\
         \hline
       GPU not supported & Suboptimal GPU integration  &  3+0 \\
         \hline
        Memory handling & Memory Leak & 1+0 \\
          \hline
        Running on CPU & Implementation using CPU instead of GPU  & 2+0 \\
    \end{tabular}
\end{table}



\subsection{Validation Results}
Table \ref{tab:survey} displays the results of the validation survey. One of the seven participants answered "No" to the opening question 'Have you experienced Hybrid Quantum-Classical architecture faults', so we decided to exclude their contribution as it did not fit the required expertise - they only had some high-level theoretical knowledge of Hybrid Quantum-Classical architectures.  Not all participants filled every sub-questions about the severity and effort to solve per category; the answers received are summarised in Table \ref{tab:survey}. 4 participants declared having a Computer Science background, 2 came from Physics education, and one from Mathematics.

The results of the survey generally support the findings of the Github mining and the interviews: the identified categories of faults were experienced by at least 50\% of the participants, with 4 categories experienced by 83\% of them. All but one participant experienced at least half of the categories of faults. The aforementioned remaining participant has experienced 3 out of 7. When asked if they have encountered faults not present in the survey, two mentioned noise-induced errors - present as a sub-category of Measurements, and one mentioned a specific API problem that would fall into our API Misuse sub-category. The rest of the participants answered negatively. 
The survey provided additional insights that can be further used when developing testing, debugging, and repair techniques for these faults: critical faults seem to be concentrated in API, GPU, and measurement components. As we report below, our manual analysis also corroborates that the interfaces of components, particularly across the quantum and classical boundry are most prone to severe faults. The survey indicates that API faults are not only critical but difficult to resolve, while conceptualisation faults, which are mostly minor issues, are also very difficult to resolve due to the deep insight needed both in the domain and in the translation to quantum concepts. The following section details further our findings.

\begin{table}[hbt!]
    \centering
        \caption{Validation Survey Results. In each category, the ``Answer'' column indicates if the experts have encountered any such faults before. For those who have identified the faults in the category a further indication of the ``Severity'' (minor, major, or critical) of and the ``Effort to Resolve'' (low, medium, or high) the encountered fault are provided in the corresponding columns. }
    \label{tab:survey}
    \begin{tabular}{@{}c|@{}cc@{}|@{}ccc@{}|@{}ccc}
    \textbf{Categories}     & \multicolumn{2}{c|}{\textbf{Answers}}  & \multicolumn{3}{c|}{\textbf{Severity}} & \multicolumn{3}{c}{\textbf{Effort to Solve}} \\
                    & \textit{Yes} & \textit{No} & \textit{Min.} & \textit{Maj.} & \textit{Crit.} & \textit{Low} &  \textit{Med} & \textit{High} \\
    \hline
    Parametris.    & 3  & 3 & 1 & 0 & 0 & 1 &0 &  0\\
    \hline
    Conceptual     & 5 &  1 & 3 & 0 & 0 & 0 &2&  1\\
    \hline
    Measurement     & 4 & 2 &  2 & 0 & 3 & 1 & 2 & 0 \\
    \hline
    Optimisation     & 5 & 1 & 2 & 0 & 1 & 1 & 2 & 1\\
    \hline
    Quantum Circ.     & 3 & 3 & 1 & 0 & 1 & 1 & 0 & 1\\
    \hline
    API     & 5 & 1 & 1 &  0 & 3 & 0 & 1 & 2 \\
    \hline
    GPU     & 5 & 1 & 1 & 0 & 2 & 0 & 2 &  0 \\
    \end{tabular}
\end{table}

\subsection{Research Questions}
\paragraph{RQ1. Typical failure causes in Hybrid Quantum-Classical architectures}



Although hybrid architectures are prone to regular quantum and classical faults, some faults are specific to this architecture. The iterative nature of such algorithms introduces further domain-specific challenges.


For example, imprecision in measurements accumulates over time and may cause wrong outputs that are difficult to detect. We observed that in the currently available frameworks for Hybrid Quantum-Classical architectures,  several type errors can be inadvertently introduced; these include simple type mismatches and rounding imprecision. Such type conversion and mismatch errors are significant in the interfaces of the different components in the architecture. They particularly prone to happen in the optimisation process while handling measurements, and passing intermediate results between Tensors.

The iterative nature of the architecture is resistant to noise to some extent and noise can even be exploited in such architecture to provide diversity in sampling. Noise-induced barren plateaus are, however, a common fault representing about 25\% of conceptual faults. Ansatz's structure affects the optimisation in different ways: poor Ansatz design can lead to performance issues as well as wrong outputs.

There are similar patterns of faults, mostly in parameterisation and optimisation, 
between ML and Hybrid Quantum-Classical architectures. However,  the introduction of quantum noise gives the classical optimisation process in hybrid architecture (and its interface with the quantum circuit)  a unique nature, constituting 50\% of the faults mentioned in experts' interviews.

\begin{quote}
\textbf{\emph{Answer to RQ1:}} 
Over 40\% of faults in Hybrid Quantum-Classical architecture happen at the Parametrisation and Optimisation phase.  
Over 50\% of the faults mentioned in the expert interviews concern the classical optimisation component and its interface with the classical circuit. 
A significant part of the novel faults contributed by the expert interviews concerns the conceptualisation of the problem from the domain knowledge into the hybrid architecture. 

The results of the survey and our manual analysis of the real fault dataset both indicate that the interfaces between structural components of the architecture are the most fault-prone. We found noticeably input types mismatches, and version integration between the different components of the algorithms to be problematic.
\end{quote}



\subsection{RQ2. Contribution to the Taxonomy}

GitHub faults and faults mentioned in interviews complement each other nicely. Although GitHub issues typically gave insight into implementation issues, from the library itself or developer issues, interviews focused on a higher level of abstraction and comprehension errors. 

\begin{quote}
\textbf{\emph{Answer to RQ2:}} 
Empirical analysis of GitHub resources allowed us to build a meaningful taxonomy. The expert interviews were indeed crucial to complementing and re-structuring our initial taxonomy. 

Surveys corroborated the results of repository mining and interviews and also provided additional (initial) insights into the severity of the faults and the level of effort involved in resolving them. 

The taxonomy's structure, organised around categories corresponding to the fault's location, and sub-categories corresponding to its cause is relevant to both fault detection and localisation, and will easily adapt to potential evolutions of hybrid architectures in the future.
\end{quote}