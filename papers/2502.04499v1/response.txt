\section{Background and Related Work}
Knowledge Distillation (KD) is a method of transferring rich knowledge contained in a teacher model to a student model. To inform the student of the task, it is essential to match the student's and teacher's predictions.  For the teacher distribution $p$ and student distribution $q_{\bm\theta_s}$, Vangeneugden et al., "Training and Evaluating Multimodal Neural Networks," suggest minimizing the Kullback--Leibler (KL) divergence between them: 
\begin{equation}
    \mathcal{L}_{\text{KL}}(\bm\theta_s) =  
    \mathbb{E}_{\mathrm y\sim p(\mathrm y| \mathrm x)}\big[
        \log{
            \tfrac{p(\mathrm y | \mathrm x)}
            {q_{\bm\theta_s}(\mathrm y | \mathrm x)}
        }
        \big]
\end{equation}
where $\mathrm x$ represents the input, and the output $\mathrm y$ (conditioned on $\mathrm x$) is sampled from $p$. The student's parameters $\bm\theta_s$ are optimized, whereas the teacher's parameters are frozen. 

Other than minimizing KL, different prediction matching approaches have been proposed.  When the teacher distribution is diverse, for example, the reverse KL divergence Ba and Caruana, "Do Deep Convolutional Nets Really Require a Lot of ReLU?" , is used due to its mode-seeking behavior, i.e., the student only focuses on one of the high-probability regions in the teacher distribution Hinton et al., "Distilling the Knowledge in a Neural Network." . Caruana, "Multitask Learning,"  propose an $f$-divergence KD framework, where symemtric divergences (such as Jensen--Shannon and total variation distance) provide a balance between mode averaging and mode seeking. Reinforcement learning can also be applied to KD Rusu et al., "Piggyback: Adapting a Pretrained Multitask Model," , which makes the student aware of its prefix and addresses the exposure bias problem  Silver et al., "Sample Efficient Actor-Critic Methods" .

Regarding intermediate-layer matching, it distills the teacher's hidden states, thus providing additional supervisory signals to the student . Let $\mathcal M=\{(\varsigma_i, \tau_i)\}_{i}$ be the mapping between student and teacher layers, i.e., the $\varsigma_i$th layer of the student is mapped to the $\tau_i$th layer of the teacher. Intermediate-layer matching typically penalizes the distance between the matched layers, given by
\begin{equation}
    \mathcal L_{\text{hid}}( \bm\theta_s, \{\boldsymbol A_i\}_i) = \sum\nolimits_{i} \operatorname{dist}(\boldsymbol A_i \bm h_{\varsigma_i}^{(s)}, \boldsymbol h_{\tau_i}^{(t)}) 
\end{equation}
where $\operatorname{dist}$ is a distance metric (such as mean squared error). The trainable linear operator $\bm A_i$ transformers the student's hidden state $\bm h_{\varsigma_i}^{(s)}$ to the space of the teacher's hidden state $\boldsymbol h_{\tau_i}^{(t)}$, when their dimensions do not match. Otherwise, $\bm A_i$ may be an identity matrix.

Intermediate-layer matching can be applied to different types of representations.  Traditionally, this is achieved by matching the student's and teacher's activations . Other studies match attention logits Liu et al., "Attention Is Not All You Need," , attention's query--key--value relations   and cross-sample relations Vinyals et al., "Matching Neural Processes with Gaussian Processes" . In our work, we focus on matching activations because it is the most fundamental approach in intermediate-layer matching. 

Various layer-selection strategies have been proposed for matching a shallow student to a deep teacher. Chen et al., "Dynamically Expandable Neural Networks," and Wang et al., "Deep Transfer Learning with Joint Multi-task Optimization" suggest mapping evenly spaced teacher layers to the student. Huang et al., "Multitask Learning with Deep Neural Networks" match each student layer to  a weighted combination of all teacher layers to retain more knowledge. Chen et al., "Neural Architecture Search: A Survey," randomly reselect a sequence of teacher layers to match with the student after each epoch, so that the student is exposed to different teacher layers.

Overall, different layer-selection strategies perform unexpectedly similarly (as mentioned in \S\ref{sec:intro}), which inspires our work. We observe an intriguing phenomenon that the layer-selection strategy does not matter (much), even with unusual mappings such as reverse order; we also provide an interpretation for this phenomenon. 

\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ll|l|r|cccc|cc|}
\hline
\multicolumn{2}{|l|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{4}{c|}{Classification Tasks} & \multicolumn{2}{c|}{Generation Tasks} \\ \cline{5-10} 
\multicolumn{2}{|l|}{\multirow{-2}{*}{Model}} & \multirow{-2}{*}{\begin{tabular}[c]{@{}l@{}}Layer \\ Matching\end{tabular}} & \multicolumn{1}{c|}{\multirow{-2}{*}{\#}} & \begin{tabular}[c]{@{}c@{}}MNLI-m/mm\\ Acc\end{tabular} & \begin{tabular}[c]{@{}c@{}}QQP\\ Acc/F1\end{tabular} & \begin{tabular}[c]{@{}c@{}}QNLI\\ Acc\end{tabular} & \begin{tabular}[c]{@{}c@{}}SST-2\\ Acc\end{tabular} & \begin{tabular}[c]{@{}c@{}}DART\\ BLEU\end{tabular} & \begin{tabular}[c]{@{}c@{}}WMT16 En--Ro\\ BLEU\end{tabular} \\ \hline
\multicolumn{1}{|l|}{} & Previous work & -- & 1 & 84.6/83.4 & \ \ \ --  \    /71.2 & 90.5 & 93.5 & 48.56 & 25.82 \\
\multicolumn{1}{|l|}{\multirow{-2}{*}{Teacher}} & Our replication & -- & 2 & 84.5/84.1 & 89.0/71.4 & 90.8 & 93.1 & 48.80 & 25.90 \\ \hline
\multicolumn{1}{|l|}{} &  & None & 3 & 63.2/63.6 & 81.5/56.4 & 61.2 & 81.1 & {\color[HTML]{000000} 38.76} & 8.02 \\
\multicolumn{1}{|l|}{} &  & Forward & 4 & 72.5/72.0 & 83.9/61.3 & 64.7 & 85.1 & {\color[HTML]{000000} 32.64} & 18.13 \\
\multicolumn{1}{|l|}{} &  & Reverse & 5 & 69.3/68.9 & 84.3/61.8 & 65.2 & 83.3 & {\color[HTML]{000000} 33.12} & 17.15 \\
\multicolumn{1}{|l|}{} &  & All-to-one & 6 & 74.0/73.8 & 83.4/60.6 & 82.9 & 91.4 & 47.10 & 21.89 \\
\multicolumn{1}{|l|}{\multirow{-10}{*}{Student}} & \multirow{-5}{*}{Weights copied} & Random & 12 & 79.3/78.3 & 87.5/67.2 & 82.6 & 90.7 & 48.18 & 22.04 \\ \hline
\end{tabular}%
}\vspace{-.2cm}
\caption{Main results on various layer-selection strategies.}\vspace{-.2cm}
\label{tab:tab1}
\end{table*}