% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass{article}


\usepackage{arxiv}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath,bm}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{multirow}
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{calc,patterns,angles,quotes}
\usepackage{subfigure}
\usepackage{subcaption}
\usepackage{placeins}
\usepackage{url}
\usepackage[auth-lg]{authblk}
\usepackage[round]{natbib}
\bibliographystyle{apalike}

\title{Revisiting Intermediate-Layer Matching in  \\ Knowledge Distillation:\\
Layer-Selection Strategy Doesn't Matter (Much)}

\author[1]{Zony Yu} 
\author[1]{Yuqiao Wen} 
\author[1,2]{Lili Mou} 
\affil[1]{Dept. Computing Science, University of Alberta}
\affil[ ]{Alberta Machine Intelligence Institute (Amii)} 
\affil[2]{Canada CIFAR AI Chair}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\renewcommand\cite{\citep}

\begin{document}

\maketitle

\begin{abstract} 
Knowledge distillation (KD) is a popular method of transferring knowledge from a large ``teacher'' model to a small ``student'' model. KD can be divided into two categories: prediction matching and intermediate-layer matching. We explore an intriguing phenomenon: layer-selection strategy does not matter (much) in intermediate-layer matching. In this paper, we show that seemingly nonsensical matching strategies such as matching the teacher's layers in \textit{reverse} still result in surprisingly good student performance. We provide an interpretation for this phenomenon by examining the angles between teacher layers viewed from the student's perspective.
\end{abstract}

\section{Introduction}
\label{sec:intro}

Large language models have achieved impressive performance in various NLP tasks \citep{gpt3, bert}. However, they need a large number of parameters, making the models cumbersome and difficult to run in resource-restricted scenarios. Knowledge distillation (KD; \citeauthor{hintonkd}, \citeyear{hintonkd}) is a widely adopted method to reduce model parameters by training a small ``student'' model from a large ``teacher.'' With KD, the student is often able to retain most of the teacher's performance while using a fraction of the its parameters \citep{mobilebert}.

Common KD approaches can be generally divided into two categories: prediction matching and intermediate-layer matching. Matching the prediction is usually mandatory, as it informs the student of the task to solve. This can be achieved by  minimizing the divergence of predicted distributions~\cite{hintonkd,fdistill} or using reinforcement learning~\cite{llmr}.

Intermediate-layer matching distills the teacher's hidden states (i.e., intermediate layers) to the student~\cite{patientkd,tinybert,minilmv2}. This approach often involves minimizing the distance between the student's and teacher's hidden states (usually with a linear mapping if the dimensions do not match). Since the student model is often shallower than the teacher, a layer-selection strategy is required to specify which teacher layer is matched to each student layer.

Recently, researchers have explored various layer-selection strategies.~\citet{patientkd} match the student's layers to evenly spaced teacher layers;  \citet{alpkd} learn an attention mechanism over the teacher's layers; \citet{railkd} match the student's layers to randomly selected layers from the teacher, in order; and \citet{minilmv2} matches the last student layer to a teacher layer close to the end. Overall, there lacks consensus on the best strategy for layer selection, and different strategies often result in unexpectedly similar performance. For example,~\citet{patientkd} reports roughly 0.5 points of difference in accuracy between different layer-selection strategies, and~\citet{tinybert} reports roughly 1-2 points difference in accuracy\footnote{Evaluated on GLUE dev set on MNLI-m/mm and MRPC, excluding CoLA since it is highly sensitive.}. 

In this work, we observe an intriguing phenomenon that the layer-selection strategy does not affect intermediate-layer matching for KD (much). Surprisingly, even matching teacher layers to the student in \textit{reverse} order yields similar performance to forward matching. However, we do see that intermediate-layer matching (regardless of the layer-selection strategy) helps KD, compared with no intermediate-layer matching.

In addition, we provide an interpretation for this interesting finding: from the student's point of view, the angles between two teacher layers are often acute; thus, matching an arbitrary teacher layer pulls the student layer to a similar direction. As a result, intermediate-layer matching indeed benefits KD, although the matching strategy does not matter (much). 


We conducted experiments with four matching strategies (forward, reverse, random, and all-to-one) on six datasets (four classification, two generation), where we explored various settings, including different depths and parameter initializations. Our results consistently demonstrate the aforementioned phenomenon; we also performed in-depth analysis, verifying our interpretation. 

\section{Background and Related Work} 

Knowledge Distillation (KD) is a method of transferring rich knowledge contained in a teacher model to a student model. To inform the student of the task, it is essential to match the student's and teacher's predictions.  For the teacher distribution $p$ and student distribution $q_{\bm\theta_s}$, \citet{hintonkd} suggest minimizing the Kullback--Leibler (KL) divergence between them: 
\begin{equation}
    \mathcal{L}_{\text{KL}}(\bm\theta_s) =  
    \mathbb{E}_{\mathrm y\sim p(\mathrm y| \mathrm x)}\big[
        \log{
            \tfrac{p(\mathrm y | \mathrm x)}
            {q_{\bm\theta_s}(\mathrm y | \mathrm x)}
        }
        \big]
\end{equation}
where $\mathrm x$ represents the input, and the output $\mathrm y$ (conditioned on $\mathrm x$) is sampled from $p$. The student's parameters $\bm\theta_s$ are optimized, whereas the teacher's parameters are frozen. 

Other than minimizing KL, different prediction matching approaches have been proposed.  When the teacher distribution is diverse, for example, the reverse KL divergence~\cite{engine,minillm} is used due to its mode-seeking behavior, i.e., the student only focuses on one of the high-probability regions in the teacher distribution~\cite{mode-seeking}. \citet{fdistill} propose an $f$-divergence KD framework, where symemtric divergences (such as Jensen--Shannon and total variation distance) provide a balance between mode averaging and mode seeking. Reinforcement learning can also be applied to KD~\cite{hao2022teacher,llmr}, which makes the student aware of its prefix and addresses the exposure bias problem~\cite{exp-bias}.

Regarding intermediate-layer matching, it distills the teacher's hidden states, thus providing additional supervisory signals to the student~\cite{patientkd}. Let $\mathcal M=\{(\varsigma_i, \tau_i)\}_{i}$ be the mapping between student and teacher layers, i.e., the $\varsigma_i$th layer of the student is mapped to the $\tau_i$th layer of the teacher. Intermediate-layer matching typically penalizes the distance between the matched layers, given by
\begin{equation}
    \mathcal L_{\text{hid}}( \bm\theta_s, \{\boldsymbol A_i\}_i) = \sum\nolimits_{i} \operatorname{dist}(\boldsymbol A_i \bm h_{\varsigma_i}^{(s)}, \boldsymbol h_{\tau_i}^{(t)}) 
\end{equation}
where $\operatorname{dist}$ is a distance metric (such as mean squared error). The trainable linear operator $\bm A_i$ transformers the student's hidden state $\bm h_{\varsigma_i}^{(s)}$ to the space of the teacher's hidden state $\boldsymbol h_{\tau_i}^{(t)}$, when their dimensions do not match. Otherwise, $\bm A_i$ may be an identity matrix.

Intermediate-layer matching can be applied to different types of representations.  Traditionally, this is achieved by matching the student's and teacher's activations~\cite{patientkd, distilBERT}. Other studies match attention logits~\cite{tinybert}, attention's query--key--value relations~\cite{minilmv2}, and cross-sample relations~\cite{rkd, fcd}. In our work, we focus on matching activations because it is the most fundamental approach in intermediate-layer matching. 

Various layer-selection strategies have been proposed for matching a shallow student to a deep teacher. \citet{patientkd} and \citet{tinybert} suggest mapping evenly spaced teacher layers to the student. \citet{alpkd} match each student layer to
 a weighted combination of all teacher layers to retain more knowledge. \citet{railkd} randomly reselect a sequence of teacher layers to match with the student after each epoch, so that the student is exposed to different teacher layers.

Overall, different layer-selection strategies perform unexpectedly similarly (as mentioned in \S\ref{sec:intro}), which inspires our work. We observe an intriguing phenomenon that the layer-selection strategy does not matter (much), even with unusual mappings such as reverse order; we also provide an interpretation for this phenomenon. 

\begin{table*}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|ll|l|r|cccc|cc|}
\hline
\multicolumn{2}{|l|}{} &  & \multicolumn{1}{c|}{} & \multicolumn{4}{c|}{Classification Tasks} & \multicolumn{2}{c|}{Generation Tasks} \\ \cline{5-10} 
\multicolumn{2}{|l|}{\multirow{-2}{*}{Model}} & \multirow{-2}{*}{\begin{tabular}[c]{@{}l@{}}Layer \\ Matching\end{tabular}} & \multicolumn{1}{c|}{\multirow{-2}{*}{\#}} & \begin{tabular}[c]{@{}c@{}}MNLI-m/mm\\ Acc\end{tabular} & \begin{tabular}[c]{@{}c@{}}QQP\\ Acc/F1\end{tabular} & \begin{tabular}[c]{@{}c@{}}QNLI\\ Acc\end{tabular} & \begin{tabular}[c]{@{}c@{}}SST-2\\ Acc\end{tabular} & \begin{tabular}[c]{@{}c@{}}DART\\ BLEU\end{tabular} & \begin{tabular}[c]{@{}c@{}}WMT16 En--Ro\\ BLEU\end{tabular} \\ \hline
\multicolumn{1}{|l|}{} & Previous work & -- & 1 & 84.6/83.4 & \ \ \ --  \    /71.2 & 90.5 & 93.5 & 48.56 & 25.82 \\
\multicolumn{1}{|l|}{\multirow{-2}{*}{Teacher}} & Our replication & -- & 2 & 84.5/84.1 & 89.0/71.4 & 90.8 & 93.1 & 48.80 & 25.90 \\ \hline
\multicolumn{1}{|l|}{} &  & None & 3 & 63.2/63.6 & 81.5/56.4 & 61.2 & 81.1 & {\color[HTML]{000000} 38.76} & 8.02 \\
\multicolumn{1}{|l|}{} &  & Forward & 4 & 72.5/72.0 & 83.9/61.3 & 64.7 & 85.1 & {\color[HTML]{000000} 32.64} & 18.13 \\
\multicolumn{1}{|l|}{} &  & Reverse & 5 & 69.3/68.9 & 84.3/61.8 & 65.2 & 83.3 & {\color[HTML]{000000} 33.12} & 17.15 \\
\multicolumn{1}{|l|}{} &  & All-to-one & 6 & 74.0/73.8 & 83.4/60.2 & 65.0 & 85.4 & {\color[HTML]{000000} 33.86} & 17.16 \\
\multicolumn{1}{|l|}{} & \multirow{-5}{*}{\begin{tabular}[c]{@{}l@{}}Randomly \\ initialized\end{tabular}} & Random & 7 & 71.2/71.2 & 82.4/58.8 & 64.4 & 82.9 & {\color[HTML]{000000} 32.67} & 16.70 \\ \cline{2-10} 
\multicolumn{1}{|l|}{} &  & None & 8 & 77.4/76.5 & 87.6/67.1 & 81.2 & 88.7 & 46.32 & 22.36 \\
\multicolumn{1}{|l|}{} &  & Forward & 9 & 79.7/78.8 & 88.2/69.1 & 83.8 & 92.3 & 47.94 & 22.65 \\
\multicolumn{1}{|l|}{} &  & Reverse & 10 & 79.2/78.2 & 88.1/68.3 & 83.2 & 89.6 & 48.45 & 21.57 \\
\multicolumn{1}{|l|}{} &  & All-to-one & 11 & 79.4/78.7 & 87.6/68.6 & 82.8 & 91.4 & 47.10 & 21.89 \\
\multicolumn{1}{|l|}{\multirow{-10}{*}{Student}} & \multirow{-5}{*}{Weights copied} & Random & 12 & 79.3/78.3 & 87.5/67.2 & 82.6 & 90.7 & 48.18 & 22.04 \\ \hline
\end{tabular}%
}\vspace{-.2cm}
\caption{Main results on various layer-selection strategies.}\vspace{-.2cm}
\label{tab:tab1}
\end{table*}

\section{Approaches and Setups}
\label{sec:setup}

In this section, we begin by outlining the layer-selection strategies. We then describe the experimental setups, including datasets, metrics, and neural network hyperparameters.

\subsection{Layer-Selection Strategies}

Intermediate-layer matching requires a strategy to select which teacher layers are matched with which student layers. In this study, we examine the following layer-selection strategies. 

\textbf{Forward Matching.} In this variant, lower student layers are matched to lower teacher layers. In particular, we follow \citet{patientkd} and select evenly spaced teacher layers for matching.

\textbf{All-to-One Matching.} In this variant, all student layers are matched to the middle teacher layer. While matching to one layer is inspired by previous studies~\cite{minilm,minilmv2}, we slightly modify their approaches (i.e. matching all student layers instead of one), for fair comparison with the rest of our settings.

\textbf{Reverse Matching.} We propose a counterintuitive strategy, where matching is in reverse order (i.e., lower student layers matched to upper teacher layers). 
This seemingly nonsensical strategy sheds light on the mechanism of intermediate-layer matching.

\textbf{Random Matching.} We choose the same teacher layers as forward matching, then randomly shuffle the order. The order is maintained during distillation.
We average the performance across five seeds to evaluate the effect of different random mappings.

Note that the intermediate-layer matching loss is combined with the predictor's KL loss by $\mathcal L = \mathcal L_{\text{KL}} + \lambda \mathcal L_\text{hid}$, where $\lambda$ is a hyperparameter to balance the losses.
In addition, we compare the above strategies the \textbf{No Matching} baseline, which disables intermediate-layer matching. In other words, only KL loss is involved in the KD process.

\subsection{Datasets and Models}

We evaluate our layer-selection strategies on a variety of classification and generation tasks.

\textbf{GLUE.} The General Language Understanding Evaluation (GLUE) benchmark is a popular suite for natural language classification. From GLUE, we chose MNLI~\cite{mnli}, QQP\footnote{https://www.kaggle.com/c/quora-question-pairs}, QNLI~\cite{squad}, and \mbox{SST-2}~\cite{sst2}, as these tasks have large training sets and produce robust model performance. For each task, we finetuned the 12-layer BERT$_\text{Base}$~\cite{bert} as the teacher. We adopt standard evaluation metrics, namely, accuracy for all tasks and $F_1$ as an additional metric for QQP.

\textbf{DART.} The DART dataset~\cite{dart} is a popular data-to-text generation task. We followed \citet{dart} and finetuned BART$_\text{Large}$~\cite{bart} with 12 encoder and 12 decoder layers, which is the teacher model in the experiment.  We report BLEU scores measuring textual overlap~\cite{bleu}. 

\textbf{WMT16 En--Ro.} The WMT16 dataset~\cite{wmt16} provides parallel text between six different language pairs. For our experiments, we followed the setups in \citet{fdistill}, which chose the English--Romanian translation direction and used  100K samples from the 614K total samples for efficiency considerations. We also followed \citet{fdistill} and finetuned 12-layer T5$_\text{Base}$~\cite{t5} as the teacher, which has the same number of layers as the DART experiment. We also report BLEU scores as the evaluation metric.

\begin{figure}
    \centering\hspace{-0.5in}
    \includegraphics[width=0.25\linewidth]{figures/angles.pdf}
    \centering\hspace{0.5in}
    \includegraphics[width=0.3\linewidth]{figures/all.pdf}
     
    \caption{(a) Illustration of the angle calculation. Cosine similarities are shown for (b) MNLI classification, (c) Encoder in the  WMT task, and (d) Decoder in WMT. {\color[RGB]{226,74,51} Orange} refers to the setup of random parameter initialization and {\color[RGB]{52,138,189}blue} refers to student weights initialized by the teacher.}    
    \label{fig:1}
\end{figure}

For the student, we adopted the teacher's architecture but reduced the number of layers to three. Note that, for DART and WMT16, we had three layers for the encoder and another three layers for the decoder. Moreover, we employed two parameter initialization strategies for the student: randomly initializing the weights and copying the weights from the corresponding teacher layer. The former isolates the effects of intermediate-layer matching from weight copying, whereas the latter
is a more practical method that yields higher performance~\cite{distilBERT, predistill}.

\section{Results and Analysis}
\label{sec:results}

\textbf{Main Results.} In Table \ref{tab:tab1}, we present the main results of our layer-selection experiments. As seen in Lines~1--2 , our finetuned teacher models perform similarly to previous work~\cite{bert,dart,fdistill}, showing that we have successfully set up the environment for KD experiments.

We examine the performance of different layer-selection strategies. As shown in Lines 4--7 and 9--12, the student model achieves similar results across different strategies, with only 2--3 points difference in accuracy for classification tasks and 1--2 points difference in BLEU for generation tasks. Notice that Reverse Matching and Random Matching appear nonsensical, when in fact they still achieve close performance to Forward Matching, often outperforming No Matching. The results show that layer-selection strategy has an unexpectedly small effect on student performance; this highlights the limitations of previous research on layer-selection strategies.

It should be emphasized that intermediate-layer matching indeed helps KD compared with No Matching\footnote{One exception is the DART experiment with randomly initialized weights, for which we suspect intermediate-layer matching causes the student to overfit. That said, different strategies still perform similarly to conventional Forward Matching, and thus, it does not contradict our general finding.}, even though the matching strategy does not play a significant role. On MNLI, for example, all strategies improve upon No Matching by ten points in the setting of random initialization and two points when the student weights are initialized from the teacher.

Next, we take a closer look at how different layer-selection strategies behave under the two parameter initialization settings. To reiterate, copying the teacher's parameters for initialization is a simple and practical method to quickly transfer the teacher's knowledge to the student~\cite{distilBERT,predistill}. In our experiments, it is evident that parameter copying indeed leads to  significant improvements compared to random initialization. Nonetheless, the general trend is consistent: intermediate-layer matching is important, while layer-selection methods do not matter (much).

\textbf{The Angles of Matching Different Layers.} 
A curious question arises from these observations: why does intermediate-layer matching help KD but different layer-selection strategies perform similarly? To answer this, we measure the angles between the teacher's layers, viewed from the student. Specifically, we measure the angles formed by two teacher layers' and one student layer's vector representations, depicted in Figure~\ref{fig:1}a. We show the phenomenon in the MNLI and WMT16 En--Ro datasets in Figure~\ref{fig:1}b, \ref{fig:1}c and \ref{fig:1}d. We see that in both randomly initialized and weight-copied settings, the cosine similarity is positive, suggesting that the angles are mostly acute. In other words, the student layer is pulled to the same general direction regardless of which teacher layer it is matched to. This explains the findings in our paper.   

\textbf{Appendix.} We provide additional analysis on the student depth in Appendix~\ref{sec:appendix}.

\section{Conclusion}

In this paper, we observe an intriguing phenomenon that although intermediate-layer matching helps knowledge distillation, the layer-selection strategy does not matter (much); we also provide an interpretation based on the angles of teacher and student layers. Our work suggests potential limitations and oversights in previous work, where researchers present various heuristic layer matching methods when training their distilled systems, but their effect is not comprehensively studied. 

\section{Limitations}

In our work, we have experimented with various setups, including six tasks (four classification and two generation), three model architectures, and two parameter initialization methods. Although the results are generally consistent, there is one exception that intermediate-layer matching does not help in the DART setup. Nevertheless, this is understandable as empirical findings are usually not theoretically guaranteed. 

It is also worth mentioning that our work does not suggest intermediate-layer matching is unhelpful for KD. Rather, we present an interesting phenomenon that the layer-selection strategy plays an insignificant role in the process. We argue that future studies on layer selection should have closer examination and more rigorous comparison on its effect.

\newpage

\bibliography{custom}

\newpage
\appendix

\begin{table*}[t!]
\centering
\resizebox{0.7\columnwidth}{!}{
\begin{tabular}{|l|l|l|r|ccc|}
\hline
Model & Depth & \begin{tabular}[c]{@{}l@{}}Layer \\ Matching\end{tabular} & \multicolumn{1}{c|}{\#} & \begin{tabular}[c]{@{}c@{}}MNLI-m/mm\\ Acc\end{tabular} & \begin{tabular}[c]{@{}c@{}}DART\\ BLEU\end{tabular} & \begin{tabular}[c]{@{}c@{}}WMT16 En--Ro\\ BLEU\end{tabular} \\ \hline
Teacher & 12-layer & -- & 1 & 84.5/84.1 & 48.80 & 25.90 \\ \hline
\multirow{15}{*}{Student} & \multirow{5}{*}{3-layer} & None & 2 & 77.4/76.5 & 46.32 & 22.36 \\
 &  & Forward & 3 & 79.7/78.8 & 47.94 & 22.65 \\
 &  & Reverse & 4 & 79.2/78.2 & 48.45 & 21.57 \\
 &  & All-to-one & 5 & 79.4/78.7 & 47.10 & 21.89 \\
 &  & Random & 6 & 79.0/78.0 & 48.18 & 22.04 \\ \cline{2-7} 
 & \multirow{5}{*}{6-layer} & None & 7 & 82.1/81.3 & 46.88 & 24.91 \\
 &  & Forward & 8 & 83.5/82.9 & 48.45 & 25.00 \\
 &  & Reverse & 9 & 82.1/80.9 & 48.45 & 24.30 \\
 &  & All-to-one & 10 & 82.3/81.8 & 48.39 & 24.44 \\
 &  & Random & 11 & 82.3/81.5 & 48.03 & 24.38 \\ \cline{2-7} 
 & \multirow{5}{*}{9-layer} & None & 12 & 84.2/83.3 & 46.05 & 25.88 \\
 &  & Forward & 13 & 84.1/83.4 & 47.66 & 25.67 \\
 &  & Reverse & 14 & 83.2/82.4 & 47.01 & 25.11 \\
 &  & All-to-one & 15 & 83.2/82.5 & 46.95 & 25.43 \\
 &  & Random & 16 & 84.4/83.3 & 47.37 & 25.41 \\ \hline
\end{tabular}%
}

\caption{Performance of different layer-selection strategies on students of different depths. Student's parameters are initialized by copying the weights of the teacher.}
\label{tab:depth}
\end{table*}

\section{Analysis of Student Depths}
\label{sec:appendix}

We validate our intriguing phenomenon across students with different depths. Due to the limit of computing resources, we selected MNLI as the representative classification task, but include both DART and WMT16 En--Ro generation tasks.
Specifically, we experimented with student models containing three, six, and nine layers, initialized by copying the teacher's weights.
As seen in Table~\ref{tab:depth}, different layer-selection strategies show similar performances, confirming that the layer-selection strategies do not matter (much) across student models with various depths.

\end{document}
