
\section{Proof of the main theorem (\cref{thm:boundofftoon})} \label{sec:boundregretalgo}


Before going into the details of the proof, we start with a simple concentration inequality. By \cref{lem:hoeff} and a union bound, with probability at least $1-2T\delta$, for all $t\leq T$ and $i\in K$ the following inequalities hold:
\[
\underline{\mu}_i(t)\leq \mu_i \leq \overline{\mu}_i(t).
\]
 Assume now and for the rest of the proof that this event holds.  

We start by bounding $R^{\text{log}}(T)$. The bound can be split into two parts: the regret due to the iterations where \algucb\ is played and the regret due to the iterations where \alglcb\ is played, i.e.:
\begin{align}\label{eq:decloggingregret}
    R^{\text{log}}_\algoname(T)=\sum_{i=1}^{K}T_i^{U}(T)\left(\mu_0-\mu_i\right)+\sum_{i=1}^{K}T_i^L(T)\left(\mu_0-\mu_i\right).
\end{align}
We start by focusing on the former and bound the first term of the above equation. Consider the pseudo-budget:
\[
\tilde{B}_{\Tilde{T}}(t):=\sum_{i=1}^{K}T_i^U(t)(\underline{\mu}_i(t)-\gamma)+(T^L(t)+\Tilde{T}-t)\alpha \beta.
\]
Compared with the budget, 
\[
B_{\tilde{T}}(t):=\sum_{i=1}^{K}T_i^U(t-1)(\underline{\mu}_i(t)-\gamma)+\underline{\mu}_{U(t)}(t)-\gamma+(T^L(t-1)+\tilde{T}-t)\alpha \beta,
\]
the pseudo-budget can be seen as the "realized budget", where the actual arm played is considered instead of $U(t)$.
We show by induction on $t$ that the pseudo-budget is positive. 
If the budget is positive at iteration  $t$, then   $\tilde{B}_{\Tilde{T}}(t)$ and $B_{\Tilde{T}}(t)$ are equal and $\tilde{B}_{\Tilde{T}}(t)$ is positive. If the budget is negative, then $T_L(t)=T_L(t-1)+1$ and,  whether or not the proxy horizon has been modified between the two successive iterations, we have:
\[
\tilde{B}_{\Tilde{T}}(t)\geq  \tilde{B}_{\Tilde{T}}(t-1).
\]
Therefore, if $\tilde{B}_{\Tilde{T}}(t-1)$ is positive, then so is $\tilde{B}_{\Tilde{T}}(t)$. As $\tilde{B}_{\Tilde{T}}(0)$, is positive, we conclude, by induction, that the pseudo-budget is positive at every iteration. Notably, this implies that the final pseudo-budget is positive:
\begin{align*}
    \tilde{B}_{\Tilde{T}}(T)\geq 0. 
\end{align*}
Let us now show how this implies a bound on the first term of \cref{eq:decloggingregret}. Re-organizing the terms in $\tilde{B}_{\Tilde{T}}(T)$, and using that $\mu_i\geq \underline{\mu}_i(t)$ for all arms $i \in [K]$, we obtain from the positivity of $\tilde{B}_{\Tilde{T}}(T)$:
\begin{align}
\sum_{i=1}^K T_i^U(T)(\gamma-\mu_i)
    &\leq (T^L(T)+\Tilde{T}-T)\alpha \beta.\label{eq:playucbinter}
\end{align}
By definition, we have $
    \gamma= \underline{\mu}_{L(0)}(0)-\alpha \beta.
$ Also:
\begin{align}
\underline{\mu}_{L(0)}(0)
      \geq &\sum_{i=1}^K\frac{m_i \underline{\mu}_{i}(0)}{m}\notag\\
      \geq &\frac{1}{\sum_i m_i}\sum_i m_i\left(\mu_i-\sqrt{2\frac{\log(\frac{K}{\delta})}{m_i}}\right)\notag\\
      \geq& \mu_0-\beta. \label{eq:lbmul0}
\end{align}

This implies $
   \gamma \geq \mu_0-\left(1+\alpha\right)\beta.
$
Injecting in \cref{eq:playucbinter} and re-organizing the terms,
we get the following bound on the first term of \cref{eq:decloggingregret}:
\begin{align}\label{bound:playsucb}
\sum_{i=1}^K T_i^U(T)(\mu_0-\mu_i)\leq \sum_{i=1}^{K}T_i^U(T)(1+\alpha)\beta+(T^L(T)+\Tilde{T}-T)\alpha \beta.
\end{align}
Let us now bound the second term of \cref{eq:decloggingregret}, $\sum_{i=1}^{K}T_i^L(T)\left(\mu_0-\mu_i\right)$, i.e. the regret w.r.t. the logging policy of iterations where \alglcb is played. For any $i \in [K]$ s.t. $L(t)=i$ for some $i\in [K]$ and some $t\leq T$, we have:
\begin{align}
\mu_i\geq& \underline{\mu}_{L(t)}(t)\notag\\
\geq& \underline{\mu}_{L(0)}(0)\notag\\
      \geq& \mu_0-\beta, \label{eq:lbmult}
\end{align}
where the last line comes from \cref{eq:lbmul0}.
Hence, we obtain:
\begin{equation*}
    \sum_{i=1}^{K}T_i^L(T)\left(\mu_0-\mu_i\right)\leq T^L(T)\beta.
\end{equation*}
Injecting this and \cref{bound:playsucb} in \cref{eq:decloggingregret}, we have:
\begin{align*}
    R^{\text{log}}_\algoname(T)\leq &\sum_{i=1}^{K}T_i^U(T)(1+\alpha)\beta+(T^L(T)+\Tilde{T}-T)\alpha \beta+ T^L(T)\beta\\
    \leq& T\left(1+\alpha\right)\beta +(\Tilde{T}-T)\alpha \beta.
\end{align*}

When the horizon is known, $\Tilde{T}=T$, otherwise, it always holds that $\Tilde{T}\leq 2T$, hence:
\begin{align*}
   R^{\text{log}}_\algoname(T)\leq &T\left(1+(1+\mathds{1}_{\text{T unknown}})\alpha\right)\beta.   
\end{align*}
This is exactly the bound of the theorem.


Let us now turn to the bound on $R_\algoname(T)$. Consider an arm $i$ with $\Delta_i>0$. If $U(t)=i$ for some $t$, we have:
\begin{align*}
    \overline{\mu}_i(t)\geq& \overline{\mu}_*(t).
\end{align*}
This implies:
\begin{align*}
    \mu_i+\sqrt{2\frac{\log(K/\delta)}{(m_i+T_i(t))}}\geq& \mu_*,
\end{align*}
hence:

\begin{align*}
  m_i+T_i(t)\leq& \frac{2\log(K/\delta)}{\Delta_i^2},
\end{align*}
and finally, we obtain:
\begin{align}\label{eq:T_i^T}
T_i^U(T)\leq \left(\frac{2\log(K/\delta)}{\Delta_i^2}-m_i\right)_++1.
\end{align}

We now define
\[
\tau:= \max \left\{t\leq T \text{ s.t. } I(t)\neq U(t) \right\},
\]
the last iteration for which \algucb\ is not played. By algorithm design, this implies that the budget is negative at this iteration:
\begin{align}\label{eq:budgetneg}
B_{\tilde{T}}(\tau)=\sum_{i=1}^{K}T_i^U(\tau-1)(\underline{\mu}_{i}(\tau)-\gamma)+\underline{\mu}_{U(\tau)}(\tau)-\gamma+(T^L(\tau-1)+\tilde{T}-\tau)\alpha \beta<0.
\end{align}
Because $\underline{\mu}_{U(\tau)}(\tau)\ge \mu_{U(\tau)}-\sqrt{2\log(K/\delta)}$ and $\alpha \beta >0$, we have
 \begin{align*}
 \gamma-\underline{\mu}_{U(\tau)}(\tau)&=\underline{\mu}_{L(0)}(0)-\alpha\beta - \underline{\mu}_{U(\tau)}(\tau)\\
 &\le \mu_{L_0} -\mu_{U(\tau)} + \sqrt{2\log(K/\delta)}\\
 &\le 1+\sqrt{2\log(K/\delta)}.
 \end{align*}
 Using the above and again the fact that $\alpha \beta >0$, \eqref{eq:budgetneg} implies: 
\begin{align*}
 \sum_{i=1}^{K}T_i^U(\tau-1)(\underline{\mu}_{i}(\tau)-\gamma)-1-\sqrt{2\log(K/\delta)}+T^L(\tau-1)\alpha \beta<0.
\end{align*}
Rearranging the terms, we obtain:
\begin{align}
T^L(\tau-1) \alpha\beta< &1+\sqrt{2\log(K/\delta)}+\sum_{i=1}^K T^U_i(\tau-1)\left(\gamma-\underline{\mu}_{i}(\tau)\right)\notag\\
\leq &1+\sqrt{2\log(K/\delta)}+\sum_{i=1}^K T^U_i(\tau-1)\left(\gamma-\mu_i+\sqrt{2\frac{\log(K/\delta)}{(m_i+T_i(t))}}\right)\notag\\
\leq& 1+\sqrt{2\log(K/\delta)}+\sum_{i=1}^K \underbrace{T^U_i(\tau-1)\left(\Delta_i-(\mu_*-\gamma)\right)+\sqrt{2 T^U_i(\tau-1)\log(K/\delta)}}_{=:S_i}.\label{eq:boundT0}
\end{align}

Denote $a_i:=\Delta_i-(\mu_*-\gamma)$. Note that by definition of $\gamma$, $a_i<\Delta_i$ always holds. Then,  if $a_i>0$, \cref{eq:T_i^T} gives:
\begin{align}
S_i\leq& \frac{2 \log(K/\delta)}{\Delta_i}+\Delta_i+\sqrt{\frac{4 \log^2(K/\delta)}{\Delta_i^2}+2\log(K/\delta)}\notag\\
\leq&\frac{4 \log(K/\delta)}{\Delta_i}+2\log(K/\delta)+1\notag\\
\leq &\frac{4 \log(K/\delta)}{\mu_*-\gamma}+2\log(K/\delta)+1.\label{eq:boundSiposai}
\end{align}
If $a_i<0$, we have:
\[
S_i\leq \sqrt{T^U_i(\tau-1)\log(K/\delta)}\leq \frac{2 \log(K/\delta)}{\Delta_i}+2\log(K/\delta)+1,
\]
and by using $a x^2+b x \leq-b^2 / 4 a$ for $a<0$ we have
\[
S_i \leq-\frac{\log(K/\delta)}{ a_i}=\frac{\log(K/\delta)}{\left((\mu_*-\gamma)-\Delta_i\right)} .
\]

Summarizing the two bounds gives
\begin{align}
S_i \leq \frac{4 \log(K/\delta)}{\max \left\{\Delta_i, (\mu_*-\gamma)-\Delta_i\right\}}+2\log(K/\delta)+1 .\label{eq:boundSi}
\end{align}
We also have:
\begin{align*}
    \max \left\{\Delta_i, (\mu_*-\gamma)-\Delta_i\right\}\geq &\frac{\mu^*-\gamma}{2}.
\end{align*}
Combining with \cref{eq:boundSiposai}, we obtain that for any $i\in [K]$,
\[
S_i\leq \frac{8 \log(K/\delta)}{\mu^*-\gamma}+2\log(K/\delta)+1
\]
Injecting in \cref{eq:boundT0}, we obtain:

\begin{align}\label{eq:T^L}
T^L(\tau-1) \leq &\frac{1}{\alpha \beta}\left(\frac{8 K\log(K/\delta)}{\mu^*-\gamma}+2K\log(K/\delta)+K+1+\sqrt{2\log(K/\delta)}\right)
\end{align}

Now, we have:
\begin{align*}
    \mu_{L(t)}\geq& \underline{\mu}_{L(0)}(0)\\
    \geq& \gamma,
\end{align*}
hence:
\begin{align*}
   R_\algoname(T)\leq \sum_{i \in [K]}\Delta_i T^U_i(T)+T^L(\tau-1) \min\left(1;\mu^*-\gamma\right).
\end{align*}
Injecting \cref{eq:T^L} and \cref{eq:T_i^T}, we get:
\begin{align*}
   R_\algoname(T)\leq&\sum_{i=1}^K\Delta_i\left(\frac{4\log(K/\delta)}{\Delta_i^2}-m_i\right)_++\frac{1}{\alpha \beta}\left(10 K\log(K/\delta)+K+1+\sqrt{2\log(K/\delta)}\right)+K\\
   \leq&\sum_{i=1}^K\Delta_i\left(\frac{4\log(K/\delta)}{\Delta_i^2}-m_i\right)_++\frac{(12 K+2)\log(K/\delta)}{\alpha \beta}+K,
\end{align*}
by using $\log(K/\delta)>1/2$.

With some computations to bound $\sum_{i \in [K]}\Delta_i T^U_i(T)$, that are detailed in  the proof of \cref{prop:regretminimaxucb},  we also have:
\begin{align*}
   \mathcal{R}_\algoname(T)\leq&
   \max_{J\subseteq [K]}2T\sqrt{\frac{2|J|\log(K/\delta)}{T+\sum_{j\in J}m_j}}+|J|+\frac{12 K\log(K/\delta)}{\alpha \beta}+2T^2\delta.
\end{align*}

\hfill \( \Box\) 



 