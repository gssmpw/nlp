\section{Related Work}
In the following, we briefly present related works in the field of graph and node embedding. We subsequently discuss approaches for sequential and session-based recommendation, which incorporate side information or GNNs.

%important approaches in the field of neural graph embeddings. Followed up by different works 

\subsection{Graph and Node Embeddings}
%unsupervised graph embedding methods: node2vec, graphsage, infomax, mvgrl, bgrl,....
Graph embedding aims to generate low-dimensional vector representations of the graph's nodes which preserve topology and leverage node features. Non-deep learning methods are mainly based on random walks to explore node neighborhoods____. With GCNs____, more sophisticated graph embedding methods were introduced: To scale GCNs to large graphs, the layer sampling algorithm____ generates embeddings from a fixed node neighborhood. Current state-of-the-art methods in unsupervised learning of representations rely on contrastive methods which base their loss on the difference between positive and negative samples. Deep Graph Infomax (DGI)____ contrasts node and graph encodings by maximizing the mutual information between them. Hassani and Khasahmadi____ propose multi-view representation learning by contrasting first-order neighbor encodings with a general graph diffusion. %, since more than two views did not improve performance. 
Contrastive learning methods usually require a large number of negative examples and are, therefore, not scalable for large graphs. The approach by Thakoor et al.____ learns by predicting substitute augmentations of the input and circumventing the need of contrasting with negative samples.

\subsection{Sequential Recommendation}
Non-neural sequential recommendation approaches focus on the similarity of sessions to extract potential next items. Several works extend the session-based nearest-neighbors method with additional factors such as positions, recency, and popularity____. Other works____ model item-to-item transitions using neural networks, possibly incorporating item features____.

Recent works exploit the graph-based representation of sessions for improved recommendations. Current state-of-the-art use GNNs---in combination with attention or self-attention modules---to capture complex transitions and rich local dependencies____. Further approaches enrich the graph topology with knowledge base entities____. Gwadabe and Liu____ use an item co-occurrence graph to generate session co-occurrence representations which are combined with the local and global preferences of users.

In contrast to models that integrate item features by extending the network with additional paths, GCNext extracts item embeddings from the item co-occurrence graph, in which content-based features are attached to each node. GCNext can be added to different sequential models without modifying their architecture, essentially using it in a plug-in fashion. Compared to already existing graph-based pretraining schemes____ for general recommendation, our approach specifically tackles the task of sequential and session-based recommendations.