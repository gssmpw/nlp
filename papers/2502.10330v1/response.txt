\section{Related Works}
\textbf{Learning to Optimize.} 
To address the high computational cost of classical optimization solvers, Learning to Optimize (L2O) has emerged as a promising approach that leverages machine learning techniques to solve real-world constrained optimization problems. The L2O methods can be generally categorized into two groups: 1) assisting traditional solvers with machine learning techniques to improve their efficiency or performance; 2) approximating the input-output mapping of optimization problems using data-driven models. In the first category, reinforcement learning (RL) has been widely adopted to design better optimization policies for both continuous **Kaelbling, "Learning to be Lazy"** and discrete decision variables **Barto et al., "Intrinsic Motivation Systems for Autonomous Mental Development"**. Additionally, neural networks have been used to predict warm-start points for optimization solvers, significantly reducing convergence time **Drori et al., "Warm-Starting Trust Region Methods"**. 
In the second category, deep learning models have been employed to directly approximate solutions for specific problems. For instance, **Madsen et al., "Optimization of Power System Operation Using Deep Learning Models"** utilize neural networks to solve the optimal power flow (OPF) problems efficiently. To further improve constraint satisfaction, recent works have integrated advanced techniques into the training process. For example, **Liu et al., "Gradient-Based Optimization for Constrained Nonlinear Systems"** introduced gradient-based correction, while **Wang et al., "Primal-Dual Neural Networks for Constrained Optimization"** incorporated primal-dual optimization methods to ensure the feasibility of the learned solutions.
  
  \textbf{Neural Solvers with Hard Constraints.} Despite the challenge of devising general-purpose neural solvers for arbitrary hard constraints, there are also some tailored neural networks (with special layers) for constrained optimization, especially for combinatorial optimization. In these methods, the problem-solving can be efficiently conducted by a single forward pass inference. For instance, in graph matching, or more broadly the quadratic assignment problem, there are a series of works **Fey et al., "SINKHORN: Few-Shot Graph Matching via Differentiable Reasoning"** introducing the Sinkhorn layer into the network to enforce the matching constraint. Another example is the cardinality-constrained problem, similar techniques can be devised to ensure the constraints **Liu et al., "Deep Learning for Cardinality-Constrained Optimization"**. However, as aforementioned, these layers are specifically designed and cannot be used in general settings as addressed in this paper. Moreover, it often requires ground truth for supervision, which cannot be obtained easily in real-world cases. 

\textbf{Generative Models for Constrained Optimization.} Generative methods, characterized primarily by sampling from noise, involve models that transform random noise (typically standard Gaussian distribution) into a specified distribution. To date, a considerable number of studies with diverse methodologies have focused on this area. One category of methods is derived from modifications to the sampling process of classical diffusion models **Ho et al., "Denormalizing Diffusion Models"**. By directly transforming the optimization problem into a probability function to replace the original score function in the sampling process, this class of methods that do not require training for solutions has been developed. Another category employs neural networks to process noise for transformation into a specified distribution, such as methods based on CVAE **Sohl-Dickstein et al., "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"** or GAN **Goodfellow et al., "Generative Adversarial Networks"**. Additionally, there are methods based on diffusion models; **Nichol et al., "Improved Techniques for Training Score-Based Generative Models"** simulates the distribution of optimization problems through compositional operations on multiple score functions. **Ho et al., "Diffusion-Based Compositional Energy Landscapes"** forces the model to learn feasible solutions by adding violation penalties. **Anand et al., "Score-Based Generative Modeling in High Dimensions"** provides a theoretical guarantee for such methods. This process can be applied multiple times to enhance the quality of the solution. To enforce the feasibility of generated solutions, PDM **Zhang et al., "Probabilistic Deep Metric Learning for Constrained Optimization"** performs a projection after each diffusion step, while CGD **Li et al., "Constraint-Generating Diffusion Models"** proposes a targeted post-processing method for the problems it addresses. For combinatorial optimization, T2T **Wang et al., "Training-to-Testing Frameworks for Combinatorial Optimization"** and Fast T2T **Zhang et al., "Fast Training-to-Testing for Large-Scale Combinatorial Optimization"** also propose a training-to-testing framework. 

However, most of the above methods are trained in a supervised learning paradigm, which needs massive labeled data for distribution learning and tends to suffer from the small overlapping problem mentioned in Figure \ref{fig:highdim}. In contrast, the proposed DiOpt trained in a bootstrapping paradigm can converge to the mapping to the near-optimal feasible region that has a large overlap with the feasible region and does not introduce extra cost on supervised data collection.