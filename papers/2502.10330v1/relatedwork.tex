\section{Related Works}
\textbf{Learning to Optimize.} 
To address the high computational cost of classical optimization solvers, Learning to Optimize (L2O) has emerged as a promising approach that leverages machine learning techniques to solve real-world constrained optimization problems. The L2O methods can be generally categorized into two groups: 1) assisting traditional solvers with machine learning techniques to improve their efficiency or performance; 2) approximating the input-output mapping of optimization problems using data-driven models. In the first category, reinforcement learning (RL) has been widely adopted to design better optimization policies for both continuous~\cite{li2016learning} and discrete decision variables~\cite{liu2022learning, tang2020reinforcement}. Additionally, neural networks have been used to predict warm-start points for optimization solvers, significantly reducing convergence time~\cite{baker2019learning, dong2020smart}. 
In the second category, deep learning models have been employed to directly approximate solutions for specific problems. For instance,~\cite{fioretto2020predicting, chatzos2020high} utilize neural networks to solve the optimal power flow (OPF) problems efficiently. To further improve constraint satisfaction, recent works have integrated advanced techniques into the training process. For example,~\cite{donti2021dc3} introduced gradient-based correction, while~\cite{park2023self} incorporated primal-dual optimization methods to ensure the feasibility of the learned solutions.
  
  \textbf{Neural Solvers with Hard Constraints.} Despite the challenge of devising general-purpose neural solvers for arbitrary hard constraints, there are also some tailored neural networks (with special layers) for constrained optimization, especially for combinatorial optimization. In these methods, the problem-solving can be efficiently conducted by a single forward pass inference. For instance, in graph matching, or more broadly the quadratic assignment problem, there are a series of works~\cite{wang2019learning, Fey2020Deep} introducing the Sinkhorn layer into the network to enforce the matching constraint. Another example is the cardinality-constrained problem, similar techniques can be devised to ensure the constraints~\cite{brukhim2018predict, wang2023cardinality, 10242155}. However, as aforementioned, these layers are specifically designed and cannot be used in general settings as addressed in this paper. Moreover, it often requires ground truth for supervision, which cannot be obtained easily in real-world cases. 

\textbf{Generative Models for Constrained Optimization.} Generative methods, characterized primarily by sampling from noise, involve models that transform random noise (typically standard Gaussian distribution) into a specified distribution. To date, a considerable number of studies with diverse methodologies have focused on this area. One category of methods is derived from modifications to the sampling process of classical diffusion models~\cite{zhang2024diffusion, kurtz2024equality, pan2024model}. By directly transforming the optimization problem into a probability function to replace the original score function in the sampling process, this class of methods that do not require training for solutions has been developed. Another category employs neural networks to process noise for transformation into a specified distribution, such as methods based on CVAE~\cite{li2023amortized} or GAN~\cite{salmona2022can}. Additionally, there are methods based on diffusion models;~\cite{briden2025diffusion} simulates the distribution of optimization problems through compositional operations on multiple score functions.~\cite{li2024diffusolve} forces the model to learn feasible solutions by adding violation penalties.~\cite{liang2024generative} provides a theoretical guarantee for such methods. This process can be applied multiple times to enhance the quality of the solution. To enforce the feasibility of generated solutions, PDM~\cite{christopher2024constrained} performs a projection after each diffusion step, while CGD~\cite{kondo2024cgd} proposes a targeted post-processing method for the problems it addresses. For combinatorial optimization, T2T~\cite{li2024distribution} and Fast T2T~\cite{li2024fast} also propose a training-to-testing framework. 

However, most of the above methods are trained in a supervised learning paradigm, which needs massive labeled data for distribution learning and tends to suffer from the small overlapping problem mentioned in Figure \ref{fig:highdim}. In contrast, the proposed DiOpt trained in a bootstrapping paradigm can converge to the mapping to the near-optimal feasible region that has a large overlap with the feasible region and does not introduce extra cost on supervised data collection.