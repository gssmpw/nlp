%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage[accepted]{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\newcommand{\yjc}[1]{\textcolor{red}{#1}}
% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2025}

\begin{document}

\twocolumn[
% \icmltitle{DiOpt: A Diffusion-based Learning Framework \\ for Constrained Optimization}

%\icmltitle{DiOpt: A Self-supervised Diffusion-based Learning Framework \\ for Constrained Optimization}
\icmltitle{DiOpt: Self-supervised Diffusion for Constrained Optimization}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
% \icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Shutong Ding}{shanghaitech,moe}
\icmlauthor{Yimiao Zhou}{shanghaitech}
\icmlauthor{Ke Hu}{shanghaitech}
\icmlauthor{Xi Yao}{mc}
\icmlauthor{Junchi Yan}{jiaotong}
\icmlauthor{Xiaoying Tang}{cuhksz}
\icmlauthor{Ye Shi}{shanghaitech,moe}
\end{icmlauthorlist}
\icmlaffiliation{shanghaitech}{ShanghaiTech University}
\icmlaffiliation{moe}{MoE Key Laboratory of Intelligent Perception and Human Machine Collaboration}
\icmlaffiliation{jiaotong}{Shanghai Jiao Tong University}
\icmlaffiliation{mc}{China Mobile Communications Company Limited Research Institute}
\icmlaffiliation{cuhksz}{The Chinese University of Hong Kong, Shenzhen}
\icmlcorrespondingauthor{Ye Shi}{shiye@shanghaitech.edu.cn}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Recent advances in diffusion models show promising potential for learning-based optimization by leveraging their multimodal sampling capability to escape local optima. However, existing diffusion-based optimization approaches, often reliant on supervised training, lacks a mechanism to ensure strict constraint satisfaction which is often required in real-world applications. One resulting observation is the distributional misalignment, i.e. the generated solution distribution often exhibits small overlap with the feasible domain. In this paper, we propose DiOpt, a novel diffusion paradigm that systematically learns near-optimal feasible solution distributions through iterative self-training. Our framework introduces several key innovations: a target distribution specifically designed to maximize overlap with the constrained solution manifold; a bootstrapped self-training mechanism that adaptively weights candidate solutions based on the severity of constraint violations and optimality gaps; and a dynamic memory buffer that accelerates convergence by retaining high-quality solutions over training iterations. To our knowledge, DiOpt represents the first successful integration of self-supervised diffusion with hard constraint satisfaction. Evaluations on diverse tasks, including power grid control, motion retargeting, wireless allocation demonstrate its superiority in terms of both optimality and constraint satisfaction. 

\end{abstract}

\section{Introduction}
\label{sect:intro}
Constrained optimization with hard constraints constitutes a cornerstone of real-world decision-making systems, spanning critical applications from power grid operations~\cite{pan2020deepopf, ding2024reduced} and wireless communications~\cite{du2024enhancing} to robotic motion planning~\cite{li2024diffusolve, chi2023diffusion}. Traditional numerical methods~\cite{nocedal1999numerical} face a fundamental trade-off: either simplify problems through restrictive relaxations (e.g., linear programming approximations) or endure prohibitive computational costs, both unsuitable for safety-critical and real-time systems. Learning-based approaches~\cite{donti2021dc3, park2023self} emerged as promising alternatives by training neural networks to predict solutions directly, yet they suffer from two critical limitations as shown in Figure~\ref{fig:highdim}: 1) single-point estimation leaves no recourse for infeasible predictions, and 2) the learned solution distribution typically occupies minimal overlap with the feasible region, especially in high-dimensional spaces with complex constraints. 

% Solving optimization with hard constraints is a fundamental problem in many real-world applications, e.g., power~\cite{pan2020deepopf, ding2024reduced}, communications~\cite{du2024enhancing}, and robotics~\cite{li2024diffusolve, chi2023diffusion, ding2024diffusion}. Traditional optimization algorithms~\cite{nocedal1999numerical} either need to relax these problems into special formulations like linear programming or suffer from high computational costs. However, this is unacceptable in most scenes with the requirement for safety and real-time capability. Therefore, to achieve a faster approximation, existing works such as~\cite{donti2021dc3, park2023self} tried to utilize learning-based models like neural networks to guess the solution for optimization problems, but there still exist two issues preventing them from predicting feasible solutions as shown in Figure~\ref{fig:highdim}. One is neural networks merely guess one solution. Once this solution is infeasible, there is no remedy. The other is their outputs will finally converge to the neighborhood around the optimal solution but this region only has a small intersection with the actual feasible region. 

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figure/highdim.pdf}
    \caption{A schematic geometric interpretation of feasibility challenges in learning-based optimization. The feasible region (blue) and neural network's output distribution (red) e.g. a Gaussian output by a diffusion model, fundamentally exhibit a small overlap, particularly under high dimensionality and multiple constraints. This distributional misalignment breaks constraint satisfaction.}
    \label{fig:highdim}
\end{figure}

% A simple QP problem to show why the guessed solutions are infeasible with high probability. It can be observed that the overlap of the feasible region (blue) and the potential output region (red) of the learning-based model is much smaller than the disjoint part. This phenomenon is especially pronounced with more constraints and variables. 

Recent efforts to address these limitations have turned to diffusion models~\cite{ho2020denoising}, leveraging their multimodal sampling capacity to generate diverse solution candidates~\cite{li2024diffusolve, pan2024model}. While this mitigates the single-point failure risk, state-of-the-art methods still struggle with systematic constraint satisfaction due to persistent distributional misalignment. Furthermore, they rely heavily on supervised training with labeled datasetsâ€”a practical bottleneck given the NP-hard nature of many constrained optimization problems. Additionally, these diffusion-based optimization methods~\cite{li2024diffusolve, pan2024model} often require complex guidance or projection procedures to refine solutions during sampling, resulting in slow inference speeds that scale poorly with problem dimensionality. 

% To resolve the first issue, a few recent advances in the learn-to-optimize field~\cite{li2024diffusolve, pan2024model, liang2024generative} divert their attention to the diffusion model~\cite{ho2020denoising} for its powerful generation ability. However, they are stuck on the second issue. Moreover, they tend to require massive labeled samples and have a high time cost during inference. This further leads to their poor performance in high-dimensional problems with complex equality and inequality constraints. 

We present DiOpt, a self-supervised diffusion framework that fundamentally rethinks how generative models interact with constrained solution spaces. We first introduce a target distribution designed to maximize overlap with the constrained solution manifold and develop a bootstrapped self-training mechanism that assigns weights to candidate solutions based on the severity of constraint violations and optimality gaps. Besides, due to the complexity of learning a mapping from a problem to a region, the diffusion model converges slowly compared to the common neural network solver. Hence, we introduce a look-up table that retains high-quality candidates across training iterations to accelerate convergence. Our contributions are threefold: 
% Therefore, we propose a novel self-supervised diffusion-based learning framework for optimization problems with hard constraints. To avoid the second issue mentioned above, we first define the target distribution that has a large overlapping with the feasible region for diffusion training and then design a bootstrapping diffusion training method to enforce diffusion to converge to this distribution. Specifically, DiOpt uses diffusion itself to generate enough candidates, prioritizes them with weights related to constraints violation and optimality gap, and trains the diffusion with these weighted candidates. It is worth noting that it is the first trial to introduce self-supervised training to the diffusion-based optimization solver. Besides, due to the complexity of learning a mapping from a problem to a region, the diffusion model converges slowly compared to the common neural network solver. Hence, we also provide a technique based on a look-up table with the best samples explored before inside to speed up the diffusion training procedure. In addition, an efficient sampling-and-selection technique is introduced to further improve the optimality of solutions during the inference stage. Finally, Our contribution is threefold:

1)  We reveal that supervised diffusion methods for optimization often yield infeasible solutions due to distribution misalignment. Specifically, the generated solution distribution shows limited overlap with feasible regions, especially in high-dimensional spaces. This fundamental mismatch limits their constraint satisfaction capability in complex optimization scenarios.  

2) We develop a bootstrapped diffusion paradigm that automatically learns feasible solution distribution by iterative self-training. Our adaptive weighting mechanism prioritizes candidates based on both constraint violation and optimality gap, allowing the model to generate solutions within near-optimal feasible regions without explicit supervision. 
  
3) We evaluate our DiOpt method in a diverse range of optimization problems, including synthetic problems, power grid control, motion retargeting, and wireless power allocation. This comprehensive evaluation encompasses various optimization scenarios with convex and nonconvex objectives and constraints, demonstrating the methodâ€™s generalizability across different cases. 
 

\section{Related Works}

\textbf{Learning to Optimize.} 
To address the high computational cost of classical optimization solvers, Learning to Optimize (L2O) has emerged as a promising approach that leverages machine learning techniques to solve real-world constrained optimization problems. The L2O methods can be generally categorized into two groups: 1) assisting traditional solvers with machine learning techniques to improve their efficiency or performance; 2) approximating the input-output mapping of optimization problems using data-driven models. In the first category, reinforcement learning (RL) has been widely adopted to design better optimization policies for both continuous~\cite{li2016learning} and discrete decision variables~\cite{liu2022learning, tang2020reinforcement}. Additionally, neural networks have been used to predict warm-start points for optimization solvers, significantly reducing convergence time~\cite{baker2019learning, dong2020smart}. 
In the second category, deep learning models have been employed to directly approximate solutions for specific problems. For instance,~\cite{fioretto2020predicting, chatzos2020high} utilize neural networks to solve the optimal power flow (OPF) problems efficiently. To further improve constraint satisfaction, recent works have integrated advanced techniques into the training process. For example,~\cite{donti2021dc3} introduced gradient-based correction, while~\cite{park2023self} incorporated primal-dual optimization methods to ensure the feasibility of the learned solutions.
  
  \textbf{Neural Solvers with Hard Constraints.} Despite the challenge of devising general-purpose neural solvers for arbitrary hard constraints, there are also some tailored neural networks (with special layers) for constrained optimization, especially for combinatorial optimization. In these methods, the problem-solving can be efficiently conducted by a single forward pass inference. For instance, in graph matching, or more broadly the quadratic assignment problem, there are a series of works~\cite{wang2019learning, Fey2020Deep} introducing the Sinkhorn layer into the network to enforce the matching constraint. Another example is the cardinality-constrained problem, similar techniques can be devised to ensure the constraints~\cite{brukhim2018predict, wang2023cardinality, 10242155}. However, as aforementioned, these layers are specifically designed and cannot be used in general settings as addressed in this paper. Moreover, it often requires ground truth for supervision, which cannot be obtained easily in real-world cases. 

\textbf{Generative Models for Constrained Optimization.} Generative methods, characterized primarily by sampling from noise, involve models that transform random noise (typically standard Gaussian distribution) into a specified distribution. To date, a considerable number of studies with diverse methodologies have focused on this area. One category of methods is derived from modifications to the sampling process of classical diffusion models~\cite{zhang2024diffusion, kurtz2024equality, pan2024model}. By directly transforming the optimization problem into a probability function to replace the original score function in the sampling process, this class of methods that do not require training for solutions has been developed. Another category employs neural networks to process noise for transformation into a specified distribution, such as methods based on CVAE~\cite{li2023amortized} or GAN~\cite{salmona2022can}. Additionally, there are methods based on diffusion models;~\cite{briden2025diffusion} simulates the distribution of optimization problems through compositional operations on multiple score functions.~\cite{li2024diffusolve} forces the model to learn feasible solutions by adding violation penalties.~\cite{liang2024generative} provides a theoretical guarantee for such methods. This process can be applied multiple times to enhance the quality of the solution. To enforce the feasibility of generated solutions, PDM~\cite{christopher2024constrained} performs a projection after each diffusion step, while CGD~\cite{kondo2024cgd} proposes a targeted post-processing method for the problems it addresses. For combinatorial optimization, T2T~\cite{li2024distribution} and Fast T2T~\cite{li2024fast} also propose a training-to-testing framework. 

However, most of the above methods are trained in a supervised learning paradigm, which needs massive labeled data for distribution learning and tends to suffer from the small overlapping problem mentioned in Figure \ref{fig:highdim}. In contrast, the proposed DiOpt trained in a bootstrapping paradigm can converge to the mapping to the near-optimal feasible region that has a large overlap with the feasible region and does not introduce extra cost on supervised data collection.

\section{Preliminaries}
\label{sect:preliminaries}
\textbf{Problem Statement.} Learning-to-optimize attempts to solve a family of optimization problems as follows, 
\begin{equation}
    \begin{aligned}
        \min_{\mathbf{y}} \quad & f(\mathbf{y};\mathbf{x})\\
        \text{subject to} \quad & g_i(\mathbf{y};\mathbf{x})\le 0 & i=1, \cdots, m \\
        & h_j(\mathbf{y};\mathbf{x}) = 0 & j=1,\cdots, n
    \end{aligned}
    \label{eq:opt}
\end{equation}
where $\mathbf{y}$ is the decision variable of the optimization problem parameterized by $\mathbf{x}$. We can use machine learning techniques to learn the mapping from $x$ to its corresponding solution $\mathbf{y}^\star$ in an optimization problem family with a similar problem structure. With this mapping, the solution can be calculated faster and more efficiently compared with the classical optimization solver. 

\textbf{Diffusion Models.} Denoising diffusion probabilistic models (DDPM)~\cite{ho2020denoising} are generative models that create high-quality data by learning to reverse a gradual forward noising process applied to the training data. Given a dataset $\{\mathbf{x}_0^i\}_{i=1}^N$ for $\mathbf{x}_0^i \sim q(\mathbf{x}_0)$, the forward process $\{\mathbf{x}_{0:T}\}$ adds Gaussian noise to the data with pre-defined schedule $\{\beta_{1:T}\}$: 
\begin{equation}
q(\mathbf{x}_t \mid \mathbf{x}_{t-1}) := \mathcal{N}(\mathbf{x}_t; \sqrt{1-\beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I}).
\end{equation}
Using the Markov chain property, we can obtain the analytic marginal distribution of conditioned on $\boldsymbol{x}_0$:
\begin{equation}
q(\mathbf{x}_{t} \mid \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t} \mathbf{x}_0, (1-\bar{\alpha}_t) \mathbf{I}), \forall t\in\{1,\dots,T\},
\end{equation}
where $\alpha_t = 1 - \beta_t$ and $\bar{\alpha}_t = \prod_{s=0}^T \alpha_s$. Given $\boldsymbol{x}_0$, it's easy to obtain a noisy sample by re-parameterization trick.
\begin{equation}
    \mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0+\sqrt{1-\bar{\alpha}_t}\epsilon, \epsilon\in\mathcal{N}(\boldsymbol{0},\boldsymbol{I}).
\end{equation}
DDPMs use parameterized models $p_\theta (\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \mu_\theta(\mathbf{x}_t, t), \Sigma_\theta(\mathbf{x}_t, t))$ to fit $q(\mathbf{x}_t \mid \mathbf{x}_{t-1}, \mathbf{x}_0)$ to reverse forward diffusion process, where $\theta$ denotes the learnable parameters. The practical implementation involves directly predicting the Gaussian noise $\boldsymbol{\epsilon}$ using a neural network $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t,t)$ to minimize the evidence lower bound loss. With $\boldsymbol{\epsilon}_t \sim \mathcal{N}(0, \mathbf{I})$, the loss in DDPM takes the form of:
\begin{equation}
\mathbb{E}_{t \sim [1,T], \mathbf{x}_0, \boldsymbol{\epsilon}_t}\left[||\boldsymbol{\epsilon}_t - \boldsymbol{\epsilon}_\theta(\sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \boldsymbol{\epsilon}_t, t)||^2 \right].
\end{equation}

\section{Method}
\label{sect:method}
We first discuss the limitations of existing diffusion-based methods for optimization and then propose DiOpt, a self-supervised \textbf{Di}ffusion-based learning framework for constrained \textbf{Opt}imization to overcome the limitations. As shown in Figure \ref{fig:DiOpt}, DiOpt trains the diffusion model in a bootstrapping mechanism via weighted variational loss of diffusion and applies the candidate solution selection technique during test stage to further boost the solution quality.
\subsection{Approach Overview}
Specifically, we first define a special target distribution for diffusion, which corresponds to the near-optimal feasible region of an optimization problem. Based on the distribution, we design the weight function for different points in the solution space. With this weight function, the diffusion model can be trained in a self-supervised paradigm and converge to the target distribution. Furthermore, we also utilize a look-up table to cache the best samples explored before, and the diffusion model empirically shows faster converge in training with this technique. 

\begin{figure*}[tb!]
    \centering
    \includegraphics[width=0.85\linewidth]{figure/diffopt.pdf}
    \caption{Training and evaluating procedure of DiOpt. In the training stage, DiOpt first generates a certain number of solution candidates, then endows them with corresponding weights, and finally uses these weighted samples for diffusion training. In the evaluating stage, DiOpt selects the candidate solution with the largest weight as the final output.}
    \label{fig:DiOpt}
\end{figure*}

\subsection{Target Distribution for Diffusion Training}

Recall in Figure \ref{fig:highdim}, existing diffusion models for constrained optimization are prone to generating infeasible points in a supervised paradigm. This is because diffusion models will converge to the neighborhood of the labeled solution, i.e., the near-optimal region. However, the overlapping area of the near-optimal and feasible region is very small. In that case, it is necessary to define another target distribution for diffusion models to enforce their constraint satisfaction. Referring to \cite{liang2024generative}, we define the target distribution that corresponds to the near-optimal feasible region as
\begin{equation}
    p(y;x) \sim \mathbb{I}_{\mathcal{C}(x)}(y) \exp\left(-\beta f(y;x)\right), 
    \label{eq:dist}
\end{equation}

where $\mathcal{C}(x)$ indicates the constraint region that satisfies $g_i(y;x)\le 0, h_j(y;x)=0$, $\mathbb{I}_{\mathcal{C}(x)}$ is the indicator function that judges the satisfaction of the constraint.

\subsection{Training Diffusion with Bootstrapping}

Although \cite{liang2024generative} has been aware that it is essential to approximate the above target distribution rather than merely an optimal point, it is difficult to construct a dataset that matches the target distribution very well for supervised training, especially with a large number of constraints and decision variables. In that case, the diffusion models still tend to suffer from the small overlapping problem. To avoid this problem, we divert our attention to self-supervised learning. Motivated by \cite{ding2024diffusion}, we design a novel diffusion-based learning framework for constrained optimization, which implements diffusion training in a bootstrapping manner. In this way, it can naturally converge to the target distribution without manufacturing a corresponding dataset.

Concretely, we try to utilize the parallelism of the diffusion model and generate a certain amount of candidate points for one specific problem, and then endow the candidate points with weights related to the constraint violation and objective value. The diffusion model will be trained with these weighted candidate points according to:
\begin{equation}
    \mathcal{L}(\theta):=\mathbb{E}_{x, y, \boldsymbol{\epsilon}, t}\left[\omega(y;x) \left\|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_{\theta}\left(y_t, x, t\right)\right\|^{2}\right],
    \label{eq:loss}
\end{equation}

Here the weight can be viewed as the importance of training points. Hence, the diffusion model can approximately converge to the distribution defined by the weight function after enough iterations. Thus, the weight function design is essential to ensure diffusion to converge to the target distribution. Based on that, we classify points into two cases and design two different weight functions for them as:
\begin{equation}
    \omega(y;x) := \left\{\begin{array}{cc}
     \exp\left(f^\star(x) - f(y;x)\right)   & y \in \mathcal{C}(y;x) \\
     -\sum_i \max(g_i(y;x), 0)    &  y \notin \mathcal{C}(y;x)
    \end{array}
    ,\right.
    \label{eq:weight}
\end{equation}
where $f^\star(x)$ indicates the objective value of the solution. One of the principal ideas for this weight function is that all the feasible points have positive weights and the infeasible points have negative weights. In that case, the diffusion model will converge to the feasible region and then consider the optimality of the points inside the constraint region. Besides, it is worth noting that $f^\star(x)$ can be replaced with the estimated lower bound of the objective function. This term actually avoids the numerical explosion of the exponential function. 

However, there is still a problem to be resolved in our weight function. As illustrated in \cite{ding2024diffusion}, the weight in Eq.~\ref{eq:loss} must be always positive. Hence, we perform a modification on the final weight when there exists a candidate point with a negative weight.
\begin{equation}
\begin{gathered}
        \tilde{\omega}(y;x) = \max\left(\omega(y;x) - \bar{\omega}\right),\\
    \bar{\omega}=\frac{1}{N}\sum_{i=0}^{N-1}\omega(y_i;x).
\end{gathered}
\label{eq:real}
\end{equation}
As illustrated in \cite{ding2024diffusion}, $\tilde{\omega}$ is equivalent to $\omega$ for diffusion training, we can ensure the diffusion model to converge the target distribution with the modified weight $\tilde{\omega}$. Moreover, to speed up the convergence of the diffusion model, we merely use the sample with the largest weight for diffusion training.

\input{algo}

\textit{\textbf{Remark.}} Note that for problems that have equality constraints $h(y;x)=0$, we choose to generate partial variables via the diffusion model and use equation solver to complete it like \cite{donti2021dc3, ding2024reduced}. This is because the nature of equality constraints is the reduction of free variables. So it is not appropriate to split them into two corresponding inequality constraints here. 
\input{table/retargeting_communication}

\subsection{Accelerating the Training Process}
\label{sec:accelerating_training_process}
Although the diffusion model can be trained in a bootstrapping manner without the supervised solution label, we found that the convergence in our framework is slower than the diffusion model trained in a supervised manner. This is because the training procedure needs to explore the whole solution space rather than directly obtain the solution of training samples in the supervised training. Hence, we propose an accelerating method based on a look-up table for the training process. Specifically, we utilize a look-up table to store the best point that has been explored for each training sample. Then, we will combine this best point and the candidate point sampled from the current diffusion model for training. The update rule of the look-up table is:
\begin{equation}
    \mathbf{y}_{best} = \operatornamewithlimits{argmax}_{\mathbf{y}\in \{\mathbf{y}_{best}, \mathbf{y}_0, \cdots, \mathbf{y}_{K-1}\}} w(\mathbf{y};\mathbf{x}).
    \label{eq:acc}
\end{equation}
Since using the best point $\mathbf{y}_{best}$ finally converges to the solution, the diffusion model will still suffer from the small overlapping problem. Hence, we \textit{``reset"} the diffusion model with some feasible points sampled from itself after each training iteration to alleviate this problem. The concrete implementation of the training process for DiOpt is shown in Algorithm \ref{algo:dsg}. 

\subsection{Evaluating via Solution Selection}
Since the diffusion model can merely sample from the target distribution, the output solution is not always very close to the optimal solution. To alleviate this problem, we also develop the solution selection techniques at inference stage:
\begin{equation}
    \tilde{\mathbf{y}} = \operatornamewithlimits{argmax}_{\mathbf{y}\in \{\mathbf{y}_0, \cdots, \mathbf{y}_{K-1}\}} \omega(\mathbf{y};\mathbf{x}).
    \label{eq:sel}
\end{equation}
The idea of solution selection is straightforward. With the increased number of generated points, the probability of obtaining the near-optimal point is expected  to increase as well. Since the generation of different points can be implemented in parallel, the high time cost for diffusion guidance in \cite{pan2024model} can be avoided.

\textbf{\textit{Remark}}. The advantages of DiOpt are threefold: 
\begin{itemize}
    \item \textbf{Self-supervised.} DiOpt can be fully conducted in a bootstrapping manner without the need to prepare many labeled data for the target distribution. 
    \item \textbf{Low inference time cost.} The inference of DiOpt can be conducted concurrently and does not need to involve complex guidance or projection procedures to refine solutions during sampling. 
    \item \textbf{No requirement for differentiability.} DiOpt trains the diffusion model only with the value of objective and constraint violation. This implies it does not need the differentiability of objective and constraint functions. 
\end{itemize}
\input{table/qspr}
% \input{table/qp}
\section{Experiments}
\label{sect:exp}
\subsection{Protocols}
\label{Exper:protocol}
In this section, we will evaluate the experimental results of DiOpt across various tasks, including Wireless Power Allocation, Concave Quadratic Programming (CQP), Quadratic Programming with Sine Regularization (QPSR), Alternating Current Optimal Power (ACOPF), and Motion Retargeting Task. In this study, we compare DiOpt to the following baseline models: 
\begin{itemize}
    \item \textbf{NN}: A neural network trained with label pairs \((x^{(i)}, y^{(i)})\) provided by an off-the-shelf solver IPOPT~\cite{}. The network architecture is designed as a simple two-layer fully connected neural network with ReLU activation, batch normalization, and dropout with a rate of 0.2. Furthermore, this structure is utilized as the backbone in other neural network-based baselines to ensure fairness.
    \item \textbf{DC3}: A model adopted from DC3~\cite{donti2021dc3}, which includes soft loss, equality completion, and inequality correction. 
    \item \textbf{Model Based Diffusion (MBD)}: A sampling based approach adopted from Model-Based Diffusion (MBD)~\cite{pan2024model}. To adapt its methodology to our problem setting, we have made specific adjustments. For details, please refer to \ref{appendix:mbd}.
    \item \textbf{MBD (completion)}: Building upon model-based Diffusion, we incorporate DC3's Equality Completion to ensure the feasibility of equality constraints. At each step of calculating the probability score, we first complete the partial solution before performing  computation.
    \item \textbf{Diffusion (w. )}: Models trained under the standard diffusion model paradigm, incorporating action selection from QVPO~\cite{ding2024diffusion}, sample $K$ possible solutions and select the optimal one.
    
    \item \textbf{Diffusion (w.o.)}: Models trained under the standard diffusion model paradigm without action selection. In other words, it samples only one solution in testing.
\end{itemize}

In all subsequent experiments, each baseline will be performed for 5 times on each task to calculate the mean and standard deviation. In the tables, Obj. value represents the value of the objective. Max eq. and Mean eq. represent the maximum and mean values of all violated equality constraints, respectively. Max ieq. and Mean ieq. denote the maximum and mean values of all violated inequality constraints, respectively. Viol num. denotes the number of violated inequality constraints. For all these six metrics, smaller values indicate better performance. Note N/A indicate that the corresponding data exhibited anomalies during the experiment.


\subsection{Synthesized Tasks}
\label{Exper:cqpnp}
In this section, we evaluate DiOpt on two synthesized tasks: Concave Quadratic Programming (CQP) and Quadratic Programming with Sine Regularization (QPSR). For detailed model formulation and parameter settings, please refer to \ref{appendix:exper-cqp} and \ref{appendix:exper-ncp}. 
% These two tasks can be formulated as:
% \begin{align}
% \begin{aligned}  
% \min_{y\in \mathbb{R}^n}\quad & \frac{1}{2}y^\topQy + p^\topy\\
% \text{s.t.}\quad &Ay = x,\quad Gy \leq h  \\
% \end{aligned}  
% \end{align}
% \begin{align}
% \begin{aligned}  
% \min_{y\in \mathbb{R}^n}\quad & \frac{1}{2}y^\topQy + \alpha\cdot p^\top\sin(y)\\
% \text{s.t.}\quad & Ay = x,\quad Gy \leq h  
% \end{aligned}  
% \end{align}
Due to the large number of constraints, all methods encounter constraint satisfaction issues to a certain extent in \ref{tab:qp}. Nevertheless, it can still be observed that DiOpt achieves the lowest violation of inequality constraints while satisfying equality constraints. Compared to other methods with relatively lower constraint violations, such as NN and Diffusion (w.o.), DiOpt also exhibits the lowest objective function value. Furthermore, Diffusion (w.) demonstrates superior constraint satisfaction compared to Diffusion (w.o.), highlighting the importance of Action Selection. Although MBD satisfies the inequality constraints, it fails to satisfy the equality constraints. A similar trend can be observed in Table \ref{tab:qspr}. This indicates that sampling-based methods inherently struggle with equality constraint satisfaction. 
%Similar trends are observed in the left tasks

\subsection{Wireless Power Allocation}
\label{Exper:power-allocation}

In the first experimental task, we evaluated the performance of DiOpt on a widely recognized convex optimization problem: Wireless Power Allocation~\cite{cover1999elements}. Consider a wireless communication system with \( M \) orthogonal channels, where the base station aims to maximize total system capacity under a maximum total transmit power \( P_T \). The Wireless Power Allocation can be formally formulated as:
\begin{equation}
\max_{p_i > 0} \quad \sum_{i=1}^{M}\log_2(1 + g_ip_i) \quad\text{s.t}\quad  \sum_{i=1}^{M}p_i \leq P_T.   
\end{equation}
% It is important to note that DiOpt is not specifically tailored for solving convex problems, as numerous efficient algorithms, such as the Water-Filling Method, already exist for this purpose. The rationale behind testing DiOpt on this problem lies in showcasing its versatility and broad applicability, rather than confining its utility to specific non-convex optimization tasks. We use IPOPT to obtain the optimal solution for this problem, taking into consideration the consistency with other tasks, even though this task is convex.
% \input{table/communication}

\input{table/qp}
% \input{table/qspr}
From Table \ref{tab:pa_retarget}, it can be observed that DiOpt achieves the minimal objective function value while maintaining the validity of constraints. In contrast, both NN and DC3 are constrained by the satisfaction of inequality constraints. Due to the limitation on the number of iterations, DC3 was unable to satisfy the inequality constraints within the finite number of steps for inequality correction. Furthermore, by comparing the two sets of experiments, Diffusion (w.) and Diffusion (w.o.), it is evident that Diffusion (w.) exhibits superior constraint satisfaction. This underscores the significance of Action Selection in generative methods for solving optimization problems.

The comparison between the results of Diffusion (w.) and DiOpt further demonstrates the significance of distribution learning for diffusion-based optimization methods. In contrast to directly learning the distribution of optimal values, learning the target distribution enables the achievement of a superior objective function while ensuring feasibility.


\subsection{Alternating Current Optimal Power Flow}
\label{Exper:ACOPF}
\input{table/opf}
In addition to the convex task and two artificially synthesized tasks mentioned above, we also tested the performance of DiOpt on Alternating Current Optimal Power Flow (ACOPF). ACOPF is one of the fundamental issues in the field of electrical grids. It can be formulated as:
\begin{equation}
\begin{aligned}  
\min_{p_g, q_g, v, \theta} \quad & p_g^T A p_g + b^T p_g\\  
\text{s.t.}  
\quad & \underline{p}_g \leq p_g \leq \overline{p}_g,\quad \underline{q}_g \leq q_g \leq \overline{q}_g\\  
\quad & \underline{|v|} \leq |v| \leq \overline{|v|},\quad \theta_{\mathcal{R}} = \theta_{\text{ref}}\\  
\quad & (p_g)_{\mathcal{L}} = (q_g)_\mathcal{L} = 0\\  
\quad & (p_g - p_d) + i(q_g - q_d) = \text{diag}(v)Yv^*  
\end{aligned}  
\end{equation}
For a specific description of this task, see \ref{appendix:exper-opf}. It can be observed only Diffusion (w.) and DiOpt satisfy the equality constraints while ensuring that the number of constraint violations remains lower than \(1\). Among these two methods in Table \ref{tab:opf}, DiOpt not only achieves the smallest objective value but also demonstrates the best constraint satisfaction. This underscores the value of target distribution learning based on the diffusion model in applications.

\subsection{Motion Retargeting Task}
\label{Exper:retargetting}
% \input{table/retargeting}
Finally, we demonstrate our method on the task of retargeting human motion (using the SMPL model\cite{smpl}) to a humanoid robot (H1)\cite{he2024learning}. The retargeting problem presents several challenges, including differences in kinematic structure, body shape, joint alignment, and adjustments to the end-effector position. To adapt human motion to the robot's kinematic constraints while preserving the overall motion pattern, it is necessary to optimize the body shape parameters and joint positions of the SMPL model.  Subsequently, the original human motion sequence (including translation and posture) can be used to retarget the motion onto the robot. However, due to the changes in body shape parameters, the remapping of joint positions and postures involves the forward kinematics of the robot, with the joint parameters being coupled, which results in the retargeting problem being a non-convex optimization problem.
The problem can be defined as follows: Given input $\boldsymbol{P}_{SMPL}\in\mathcal{R}^{33}$, $\boldsymbol{R}_{root}\in\mathcal{R}^{3}$ and $\boldsymbol{O}_{offset}\in\mathcal{R}^3$, output $\boldsymbol{P}_{H1}\in \mathcal{R}^{19}$, according to the following problem:
\begin{equation}
\begin{aligned}  
\min_{\boldsymbol{P}_{H1}} \quad &\|\text{FK}(\boldsymbol{P}_{H1}, \boldsymbol{R}_{root}, \boldsymbol{O}_{offset}) - \boldsymbol{P}_{SMPL}\|_2^2\\ 
                           \quad&+ \lambda \|\boldsymbol{P}_{H1}\|_2^2,\\ 
\text{s.t.}                \quad &\boldsymbol{P}_{lower}\le\boldsymbol{P}_{H1}\le\boldsymbol{P}_{upper},
\end{aligned}  
\end{equation}

where $\text{FK}$ represents the forward kinematics function of the humanoid robot, which maps joint parameters to Cartesian space. The goal is to minimize the discrepancy between the humanoid's joint positions $\boldsymbol{P}_{H1}$ and the reference human motion positions $\boldsymbol{P}_{SMPL}$ , while also applying a regularization term weighted by $\lambda$ to prevent excessive joint displacement. The constraints ensure that the optimized joint positions remain within the humanoid's feasible range.

In Table \ref{tab:pa_retarget}, since the constraints are simple box constraints, almost all methods satisfy these constraints. DiOpt achieves the smallest objective function value, which aligns with the trends observed in the previous four tasks. Since MBD was not guided by a high-quality solution, it failed to achieve a good objective value despite satisfying the constraints in this highly non-convex problem. This validates the effectiveness of the approach proposed in Section \ref{sec:accelerating_training_process}. 

The results from these five tasks demonstrate that DiOpt is a general approach to constrained optimization based on diffusion. It effectively balances constraint satisfaction and solution quality across various domains and task types. 

\section{Conclusion, Limitations and Future Work}
 

% Although DiOpt obtains a superior performance compared with previous methods, there still exist some limitations in our proposed DiOpt. One is that DiOpt converges slowly compared with neural networks when the number of decision variables is very large (i.e., hundreds of variables). This is because DiOpt is similar to classical heuristic algorithms in some sense, and tends to spend more iteration in searching the local optimality since it does not utilize the first-order information (i.e., the gradient). Another is the treatment of equality constraints. DiOpt directly adopts an equation solver to complete the variables like \cite{donti2021dc3}. For some complex equality constraints, the completion procedure is time-consuming, which may become the bottleneck in the inference stage. Hence, further accelerating DiOpt and developing more powerful diffusion-based learning algorithms that can naturally handle equality constraints are under consideration in our future works. Besides, solutions generated by DiOpt can also be viewed as the initial point to aid classical optimization solvers that require an interior point for initialization such as the interior point method\cite{nocedal1999numerical}. In this way, DiOpt can avoid spending too much time in the local optimality search and just consider the feasibility. 

In this paper, we have introduced DiOpt, a self-supervised diffusion-based framework designed to tackle constrained optimization problems with hard constraints. DiOpt leverages several key mechanisms: a target distribution that enhances alignment with the feasible region, a bootstrapped self-training approach that adaptively reweights candidate solutions based on constraint violation severity and optimality gaps, and a dynamic memory buffer that expedites convergence by preserving high-quality solutions across training iterations. To validate the effectiveness of DiOpt, we conducted extensive experiments across a range of complex optimization tasks characterized by large-scale, non-convex, and tightly constrained environments. The experimental results highlight DiOptâ€™s superiority in achieving a balanced performance in both solution optimality and constraint satisfaction when compared to existing methods. 

While DiOpt demonstrates superior performance compared to previous methods, there are still some limitations that need to be addressed. One notable limitation is that DiOpt converges more slowly than neural networks when the number of decision variables is very large (i.e., in the hundreds). This slower convergence is partly because DiOpt shares similarities with classical heuristic algorithms and tends to spend more iterations searching for local optima, as it does not utilize first-order information like gradients. Additionally, the current approach to handling equality constraints involves using an equation solver to complete the variables based on DC3 \cite{donti2021dc3}. For complex equality constraints, this procedure can be time-consuming and may become a bottleneck during the inference stage. Thus, our future work will focus on accelerating DiOpt and developing more advanced diffusion-based learning algorithms that can seamlessly handle equality constraints. Furthermore, solutions generated by DiOpt could serve as initial points for classical optimization solvers, such as the interior point method \cite{nocedal1999numerical}, requiring an interior point for initialization. This approach would allow DiOpt to focus on achieving feasibility while reducing the time spent on local optimality searches. 

We hope our work could pioneer the integration of self-supervised learning with diffusion models for constrained optimization, offering a flexible framework for real-world optimization tasks. We leave more experiments on diverse problems in future work. 

\clearpage
\section*{Impact Statement}
This paper addresses the optimization problem solving by machine learning, especially for constrained problems. We believe our technology can enhance the application of AI in a more restricted way e.g. enforcing the rules. 
% Notably, there are still several underlying challenges in applying diffusion models to constrained optimization that warrant further exploration. For instance, while DiOpt effectively narrows the gap between the model's output space and the feasible region, the diffusion model's sampling process may not always guarantee feasible solutions, especially in highly complex or dynamic constraint environments. Future work will focus on enhancing the adaptability of the diffusion model to diverse constraint types and exploring mechanisms to dynamically adjust the sampling process based on real-time feasibility feedback. We believe these advancements will further solidify the applicability and performance of diffusion-based frameworks in constrained optimization tasks.

\bibliography{reference}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\input{appendix}


\end{document}


