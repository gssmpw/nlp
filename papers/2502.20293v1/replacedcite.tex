\section{Related work}
\label{sec:literature_review}

% This section examines traditional IS methods, graph-based approaches, and the challenges of scaling these techniques to large, high-dimensional datasets.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Instance Selection
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Instance Selection}\label{subsec:lr_IS}
Traditional IS methods primarily rely on nearest neighbor computations to evaluate instance relationships and importance, falling into three main categories: condensation (retaining instances near decision boundaries), edition (removing noisy or borderline instances), and hybrid approaches ____. While various improvements have been proposed, including density-based and scalability-focused approaches ____, recent work has introduced several innovative methodologies that enhance or reformulate how instance relationships are evaluated.

Density-based approaches have evolved from local to global analysis, as demonstrated by GDIS and EGDIS ____, which evaluate instance importance through global density patterns and neighbor relationships. The ranking-based RIS algorithm ____ introduces a scoring mechanism that considers relationships between instances, using normalized exponential transform of distances weighted by class membership.
More theoretically grounded approaches such as BDIS ____ employ Bayesian decision theory to categorize instances as reducible, irreducible, or deleterious, while leveraging percolation theory to identify local homogeneous clusters---groups of instances with the same label connected by nearest neighbors, where the cluster size reflects the probability of class consistency. Alternative frameworks like CIS ____ employ reinforcement learning and clustering, where an agent learns to select valuable instance clusters through Q-learning and curiosity-driven exploration.
Recent work has explored novel theoretical frameworks, including approval-based multi-winner voting ____, which models instances as both voters and candidates in an election system, and evidence theory-based approaches like EIS ____, which evaluates instance importance through mass functions and Dempster's rule of combination.

Despite these advances, the fundamental challenge of nearest neighbor computations remains, with typical $O(n^2)$ computational complexity becoming prohibitive for very large datasets, and performance often deteriorating in high-dimensional spaces ____.
These challenges have motivated the development of various alternative approaches. Among these, graph-based methods have emerged as one promising direction for capturing complex instance relationships, though they present their own unique computational considerations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Graph-based Methods for Instance Selection
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Graph-based Selection}\label{subsec:lr_graph_IS}
Graph approaches leverage structural information of data by representing data points as nodes and their relationships as edges. In the context of IS, these approaches can be broadly categorized into two main strategies: graph sampling, which selects nodes directly from the original graph, and graph reduction, which modifies the graph structure to create a smaller representation.

Graph sampling methods select a subset of nodes from the original graph while preserving its structure ____. As illustrated in Figure \ref{fig:graph_sampling}, this process creates a subgraph that maintains the original relationships between data points, making it particularly suitable for IS since selected nodes directly correspond to original instances. Key developments in graph-based IS include proximity graphs for prototype selection ____, where edges connect instances within a specified distance threshold, Hit Miss Networks that encode nearest neighbor relations ____, and natural neighborhood graphs for identifying and removing noisy or redundant points ____.

% Figure: Graph Sampling
\begin{figure}[!t]
    \centering
    \includegraphics[width=0.8\linewidth]{figure_graph_sampling.pdf}
    \caption{Illustration of a graph sampling process. The original graph $G = (V, E)$ with $|V| = N$ and $|E| = M$ is sampled to produce $G_s = (V_s, E_s)$ where $V_s \subseteq V$, $E_s \subseteq E$, $|V_s| < N$, and $|E_s| < M$. This method selectively retains nodes and edges to create a subgraph approximating the original structure and properties.}
    \label{fig:graph_sampling}
\end{figure}

Graph reduction techniques ____, while successful in general graph summarization tasks, have seen limited application in IS. As shown in Figure \ref{fig:graph_reduction}, these methods merge nodes or modify edge structures. When applied to IS, these approaches typically require mapping reduced nodes back to original instances, often by selecting representatives from merged clusters. This indirect correspondence makes these methods less suitable for IS tasks compared to graph sampling approaches that maintain direct relationships to the original instances.

% Figure: Graph Reduction
\begin{figure}[!t]
    \centering
    \includegraphics[width=0.8\linewidth]{figure_graph_reduction.pdf}
    \caption{Illustration of a graph reduction process. The original graph $G = (V, E)$ with $|V| = N$ and $|E| = M$ undergoes a reduction to form the reduced graph $G' = (V', E')$ where $|V'| < N$. This process involves condensing or merging nodes and potentially modifying edges to reduce complexity while preserving key graph properties.}
    \label{fig:graph_reduction}
\end{figure}

The effectiveness of graph-based methods for IS has been demonstrated by ____, who evaluated multiple graph-based approaches across diverse classification datasets, showing their potential to achieve substantial data reduction while maintaining model performance.
% More recently, ____ explored using GATs for IS. While this approach showed promise in identifying important instances through attention mechanisms, it was limited by its reliance on confidence scores as importance measures and faced significant scalability issues with large datasets due to its inefficient chunking-based graph construction that still required substantial memory overhead.
In our previous work ____, we explored using GATs for IS. While this approach showed promise in identifying important instances through attention mechanisms, it was limited by its reliance on confidence scores as importance measures and faced significant scalability issues with large datasets due to its inefficient chunking-based graph construction that still required substantial memory overhead. In this paper, we address these limitations by introducing efficient graph construction methods—distance-based mini-batching and LSH approaches—that significantly reduce computational complexity, alongside a dual-perspective importance scoring mechanism that leverages attention weights to more effectively identify informative instances.

These challenges highlight broader limitations in current large-scale graph-based IS methods. The computational cost and memory requirements for graph construction and training become prohibitive with growing dataset sizes, especially when using distance-based metrics. Current approaches struggle to efficiently analyze entire graph structures in large datasets, particularly when dealing with complex patterns like multi-scale dependencies and non-linear interactions. While graph-based approaches have demonstrated success in various data selection tasks --- from representative subset selection ____ to data pruning ____ --- their application to IS for tabular data remains underdeveloped, particularly in efficiently handling large-scale datasets with heterogeneous feature relationships and varying data distributions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Scaling Challenges in Graph-based Methods
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Scaling Challenges in Graph-based Methods}\label{subsec:lr_graph_scaling}

While graph-based methods show promise for IS, they face significant scaling challenges as datasets grow in size and dimensionality. The primary bottleneck lies in the graph construction phase, particularly for k-nearest neighbor (KNN) graphs that form the foundation of many graph-based approaches. Constructing KNN graphs requires computing pairwise distances between instances, resulting in $O(n^2)$ computational complexity and substantial memory requirements for storing the resulting adjacency matrices ____.

To address these construction challenges, approximate methods such as Locality-Sensitive Hashing (LSH) have been explored, offering sublinear time complexity ____. LSH works by projecting data points into lower-dimensional hash codes where similar points are likely to share the same hash bucket, enabling faster similarity comparisons. Notable advancements include VRLSH ____, which uses voted random projections, and the fast LSH-based KNN graph construction algorithm by ____, which significantly improves speed while maintaining accuracy.

However, LSH-based approaches face their own challenges, particularly with high-dimensional tabular data. The fundamental issue is that as dimensionality increases, the probability of hash collisions (different data points sharing the same hash code) becomes less correlated with actual data similarity. This diminished correlation leads to less accurate graph structures ____, where edges may connect dissimilar points while missing truly similar ones. Traditional LSH methods also struggle with non-uniform data distributions, where dense regions experience excessive collisions while sparse regions lack sufficient connections, resulting in suboptimal graph constructions that can adversely affect IS.

Recent developments, such as LayerLSH ____, address skewed data distributions using a multi-layered index structure, but their effectiveness for graph construction in IS tasks remains unexplored. These challenges suggest that multi-level or hierarchical LSH approaches could offer potential solutions by capturing data relationships at multiple resolutions, potentially addressing both fine-grained local structures and broader global patterns.

% Figure 3: Methodology
\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.9\textwidth]{figure_methodology.pdf}
    \caption{High-level Overview of the Methodology.}
    \label{fig:methodology}
\end{figure*}

Beyond graph construction, computational challenges persist in the subsequent model training phase. Training GNNs on dense graphs requires substantial computational resources for message passing between nodes. Additionally, dense graphs can result the over-smoothing problem in GNNs ____, where repeated message passing causes node representations to converge to similar values. This over-smoothing effect leads to a loss of discriminative power after multiple layers, potentially undermining the GNN's ability to identify truly informative instances for selection.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% GAP
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Gap}\label{subsec:gap}

Despite significant advances in IS methods, a critical gap persists in scalable, efficient graph-based approaches.
First, existing approaches struggle with the computational complexity of graph construction, which typically scales quadratically with dataset size. Even approximate KNN-based methods become prohibitively expensive for datasets exceeding millions of instances, limiting their practical application.
Second, while LSH techniques offer potential scalability improvements, they face challenges in capturing meaningful relationships in high-dimensional spaces, where hash collisions become less correlated with actual data similarity. Traditional LSH implementations often fail to adapt to non-uniform data distributions and struggle to simultaneously represent both fine-grained local structures and broader global patterns.
Third, current graph-based selection methods lack adaptive mechanisms to identify and prioritize truly informative instances. Most approaches either treat all instances with equal importance or rely on static metrics that cannot capture the varying contributions of instances to decision boundaries across different regions of the feature space.

To address these limitations, we propose GAIS which leverages attention mechanisms to identify informative instances through adaptive graph-based representation learning. Our distance-based mini-batch method employs strategic sampling to efficiently process large datasets while preserving class distributions. Our family of LSH methods, including single-level, multi-level, and multi-view variants, enables scalable graph construction that captures relationships at multiple granularities. By utilizing attention weights as importance indicators, GAIS adaptively prioritizes instances that contribute most to decision boundaries, even with approximated graph structures.

%%%%%%%

%%==================================%%
%% METHODOLOGY %%
%%==================================%%