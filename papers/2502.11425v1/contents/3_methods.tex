

\section{Method}


Our idea is to make the model approximate the \textit{temporal constraints} using counterfactuals. 
Because temporal reasoning imposes unique interdependencies, where one temporal aspect affects another~\cite{han2019deep,kim-etal-2024-chaining}, counterfactuals enable us to capture these constraints.
For example, if the model establishes from a counterfactual exemplar that ``Event $e_1$ happens [$r_2$: before] Event $e_2$'', it is constrained to predict the original question that ``Event $e_1$ cannot happen [$r_1$: after] Event $e_2$'':
\begin{equation}
r_2(e_1, e_2) \in \mathcal{V} \implies r_1(e_1, e_2) \not\in \mathcal{V}
\end{equation}
where $r(e_a,e_b)$ represents the temporal relation $r$ between events $e_a$ and $e_b$, and $\mathcal{V}$ represents the set of coherent temporal relations with the context.


\subsection{Generating Temporally Counterfactual Questions}

Given a context $C$, our task is to provide an accurate answer to question $Q$ while maintaining temporal consistency.
We start by creating \textit{temporally counterfactual} questions, $Q^{c_1}...Q^{c_i}$.

Counterfactual augmentation conventionally aims to generate instances with lexically minimal edits
while keeping others unchanged~\cite{huang2019reducing,kaushik2020learning,wang2020identifying}. This strategy discourages models from relying too much on superficial similarity. However, previous works~\cite{kaushik2020learning} require arbitrary label-flipping edits, which are unsuitable for LLM inference with unknown test labels.

In contrast, we focus on \textit{temporally counterfactual} questions that specifically edit the temporal semantics of the original sentence.  
Our approach ensures that the model adheres to the ``temporal constraints'', yet retains the effect of label-flipping that emphasizes temporal cues over superficial similarity.


Specifically, we set the types of counterfactual questions based on the temporal semantics each dataset aims to capture.
The types of temporal counterfactuals are listed in Table~\ref{tab:contrast_examples}. 
For sentences representing temporal relation between two events ($r_1(e_1,e_2)$), we substitute the relation $r_1$ to $r_2$, or event $e_2$ to $e_3$. For those representing an event's temporal properties ($r_1(e_1)$) such as duration or stationarity, we substitute the property to $r_2$ or negate it to $\neg r_1$.

To generate counterfactual questions, we design our model to dynamically create them rather than rely on a predefined rule-based template. While rule-based approaches like \citet{chen2024improving} in logical reasoning constrain answers using a predefined question set, they limit flexibility to cover the broad range of temporal expressions. By comparison, our dynamic generation of constraints provides a more adaptable solution.
We specify various counterfactual types through in-context learning (ICL) to control the relevance of these generated questions. The full prompts are in~Appendix~\ref{appndx:prompt_examples_gen_counter_q}.



\subsection{Counterfactual-Consistency Prompting}



After generating the counterfactual questions, we prompt the model again to produce predictions for counterfactual $Y^{c_1},...,Y^{c_{n}}$.
However, there is a risk when LLMs may fail to answer the counterfactual questions correctly.
In this case, their direct use propagates errors to the original question. 

As a proxy for determining whether the generated prediction can be trusted, existing works aggregate multiple predictions of the same question~\cite{wang2023self,du2024improving}.
Formally, the refined prediction $Y$ is derived by re-weighting the probability distribution $P$ of previous predictions $Y_{1},...,Y_{n}$ from the same question as:
$P(Y) = f(P(Y_{1}), ..., P(Y_{n}))$
where $f$ is an aggregation function such as majority voting or LLM itself. Though, they can lead to errors as they solely rely on feedback from a single question.

Our distinction is to aggregate predictions from both the original and counterfactual questions. We design the model to re-weight the counterfactual answer distributions across the questions. 
\begin{equation}
\scalebox{0.85}{$P(Y) = f(P(Q,Y), P(Q^{c_1}, Y^{c_1}), ..., P(Q^{c_n}, Y^{c_n}))$}
\end{equation}
For instance, even if the model wrongly predicts the relation as `after' in a counterfactual, collectively considering the possibility of the relation `before' can re-weight the effect of the constraint. The prompts are provided in Appendix~\ref{appndx:prompt_examples_gen_ans}.

This re-evaluation approach improves robustness against potential errors in generated answers.
The second analysis in Subsection~\ref{subsec:anal} shows such self-correction outperforms a baseline directly leveraging counterfactuals without aggregation.




