# BETTER BIBTEX
# http://127.0.0.1:23119/better-bibtex/export/collection?/1/VK68KDYC.bibtex

@misc{bavarian2022efficient,
  title = {Efficient Training of Language Models to Fill in the Middle},
  author = {Bavarian, Mohammad and Jun, Heewoo and Tezak, Nikolas and Schulman, John and McLeavey, Christine and Tworek, Jerry and Chen, Mark},
  year = {2022},
  month = jul,
  number = {arXiv:2207.14255},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2207.14255},
  urldate = {2025-02-16},
  archiveprefix = {arXiv}
}

@misc{brown2024large,
  title = {Large Language Monkeys: Scaling Inference Compute with Repeated Sampling},
  shorttitle = {Large Language Monkeys},
  author = {Brown, Bradley and Juravsky, Jordan and Ehrlich, Ryan and Clark, Ronald and Le, Quoc V. and R{\'e}, Christopher and Mirhoseini, Azalia},
  year = {2024},
  month = jul,
  number = {arXiv:2407.21787},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-08-01},
  archiveprefix = {arXiv},
  langid = {english}
}

@misc{chen2024alphamath,
  title = {AlphaMath Almost Zero: Process Supervision without Process},
  shorttitle = {AlphaMath Almost Zero},
  author = {Chen, Guoxin and Liao, Minpeng and Li, Chengxi and Fan, Kai},
  year = {2024},
  month = sep,
  number = {arXiv:2405.03553},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.03553},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{cobbe2021training,
  title = {Training Verifiers to Solve Math Word Problems},
  author = {Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  year = {2021},
  month = nov,
  number = {arXiv:2110.14168},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-08-15},
  archiveprefix = {arXiv}
}

@misc{ding2024unleashing,
  title = {Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch},
  author = {Ding, Yuyang and Shi, Xinyu and Liang, Xiaobo and Li, Juntao and Zhu, Qiaoming and Zhang, Min},
  year = {2024},
  month = oct,
  number = {arXiv:2410.18693},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.18693},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{fang2024mathodyssey,
  title = {MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data},
  shorttitle = {MathOdyssey},
  author = {Fang, Meng and Wan, Xiangpeng and Lu, Fei and Xing, Fei and Zou, Kai},
  year = {2024},
  month = jun,
  number = {arXiv:2406.18321},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.18321},
  urldate = {2025-02-16},
  archiveprefix = {arXiv}
}

@misc{feng2024alphazerolike,
  title = {Alphazero-like Tree-Search Can Guide Large Language Model Decoding and Training},
  author = {Feng, Xidong and Wan, Ziyu and Wen, Muning and McAleer, Stephen Marcus and Wen, Ying and Zhang, Weinan and Wang, Jun},
  year = {2024},
  month = feb,
  number = {arXiv:2309.17179},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.17179},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{grattafiori2024llama,
  title = {The Llama 3 Herd of Models},
  author = {Meta AI},
  year = {2024},
  month = nov,
  number = {arXiv:2407.21783},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.21783},
  urldate = {2025-02-16},
  archiveprefix = {arXiv}
}

@misc{guan2025rstarmath,
  title = {rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking},
  shorttitle = {rStar-Math},
  author = {Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao},
  year = {2025},
  month = jan,
  number = {arXiv:2501.04519},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.04519},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{he2024olympiadbench,
  title = {OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems},
  shorttitle = {OlympiadBench},
  author = {He, Chaoqun and Luo, Renjie and Bai, Yuzhuo and Hu, Shengding and Thai, Zhen Leng and Shen, Junhao and Hu, Jinyi and Han, Xu and Huang, Yujie and Zhang, Yuxiang and Liu, Jie and Qi, Lei and Liu, Zhiyuan and Sun, Maosong},
  year = {2024},
  month = jun,
  number = {arXiv:2402.14008},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.14008},
  urldate = {2025-02-16},
  archiveprefix = {arXiv}
}

@misc{hendrycks2021measuring,
  title = {Measuring Mathematical Problem Solving With the MATH Dataset},
  author = {Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  year = {2021},
  month = nov,
  number = {arXiv:2103.03874},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-08-15},
  archiveprefix = {arXiv}
}

@misc{hoffmann2022training,
  title = {Training Compute-Optimal Large Language Models},
  author = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and Hennigan, Tom and Noland, Eric and Millican, Katie and van den Driessche, George and Damoc, Bogdan and Guy, Aurelia and Osindero, Simon and Simonyan, Karen and Elsen, Erich and Rae, Jack W. and Vinyals, Oriol and Sifre, Laurent},
  year = {2022},
  month = mar,
  number = {arXiv:2203.15556},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2203.15556},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@inproceedings{huang2023reasoning,
  title = {Towards Reasoning in Large Language Models: A Survey},
  shorttitle = {Towards Reasoning in Large Language Models},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2023},
  author = {Huang, Jie and Chang, Kevin Chen-Chuan},
  editor = {Rogers, Anna and {Boyd-Graber}, Jordan and Okazaki, Naoaki},
  year = {2023},
  month = jul,
  pages = {1049--1065},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.findings-acl.67},
  urldate = {2025-02-11}
}

@misc{jin2024impact,
  title = {The Impact of Reasoning Step Length on Large Language Models},
  author = {Jin, Mingyu and Yu, Qinkai and Shu, Dong and Zhao, Haiyan and Hua, Wenyue and Meng, Yanda and Zhang, Yongfeng and Du, Mengnan},
  year = {2024},
  month = jun,
  number = {arXiv:2401.04925},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.04925},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{kwon2023efficienta,
  title = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E. and Zhang, Hao and Stoica, Ion},
  year = {2023},
  month = sep,
  number = {arXiv:2309.06180},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.06180},
  urldate = {2025-02-16},
  archiveprefix = {arXiv}
}

@article{li2024numinamath,
  title = {NuminaMath: The Largest Public Dataset in AI4Maths with 860k Pairs of Competition Math Problems and Solutions},
  author = {Li, Jia and Beeching, Edward and Tunstall, Lewis and Lipkin, Ben and Soletskyi, Roman and Huang, Shengyi and Rasul, Kashif and Yu, Longhui and Jiang, Albert Q and Shen, Ziju and Dong, Bin and Zhou, Li and Fleureau, Yann and Lample, Guillaume and Polu, Stanislas},
  year = {2024},
  month = jul,
  langid = {english}
}

@misc{lightman2023lets,
  title = {Let's Verify Step by Step},
  author = {Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  year = {2023},
  month = may,
  number = {arXiv:2305.20050},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-04-22},
  archiveprefix = {arXiv}
}

@misc{openai2024introducing,
  title = {Introducing OpenAI O1 {\textbar} OpenAI},
  author = {OpenAI},
  year = {2024},
  urldate = {2025-01-15},
  howpublished = {https://openai.com/index/introducing-openai-o1-preview/}
}

@misc{openai2024learning,
  title = {Learning to Reason with LLMs},
  author = {OpenAI},
  year = {2024},
  urldate = {2025-01-15},
  howpublished = {https://openai.com/index/learning-to-reason-with-llms/},
  langid = {american}
}

@misc{paster2023openwebmatha,
  title = {OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text},
  shorttitle = {OpenWebMath},
  author = {Paster, Keiran and Santos, Marco Dos and Azerbayev, Zhangir and Ba, Jimmy},
  year = {2023},
  month = oct,
  number = {arXiv:2310.06786},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.06786},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{shao2024deepseekmath,
  title = {DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models},
  shorttitle = {DeepSeekMath},
  author = {Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Zhang, Mingchuan and Li, Y. K. and Wu, Y. and Guo, Daya},
  year = {2024},
  month = feb,
  number = {arXiv:2402.03300},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-04-22},
  archiveprefix = {arXiv}
}

@misc{snell2024scaling,
  title = {Scaling LLM Test-Time Compute Optimally Can Be More Effective than Scaling Model Parameters},
  author = {Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  year = {2024},
  month = aug,
  number = {arXiv:2408.03314},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.03314},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{sun2024survey,
  title = {A Survey of Reasoning with Foundation Models},
  author = {Sun, Jiankai and Zheng, Chuanyang and Xie, Enze and Liu, Zhengying and Chu, Ruihang and Qiu, Jianing and Xu, Jiaqi and Ding, Mingyu and Li, Hongyang and Geng, Mengzhe and Wu, Yue and Wang, Wenhai and Chen, Junsong and Yin, Zhangyue and Ren, Xiaozhe and Fu, Jie and He, Junxian and Yuan, Wu and Liu, Qi and Liu, Xihui and Li, Yu and Dong, Hao and Cheng, Yu and Zhang, Ming and Heng, Pheng Ann and Dai, Jifeng and Luo, Ping and Wang, Jingdong and Wen, Ji-Rong and Qiu, Xipeng and Guo, Yike and Xiong, Hui and Liu, Qun and Li, Zhenguo},
  year = {2024},
  month = jan,
  number = {arXiv:2312.11562},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-08-15},
  archiveprefix = {arXiv},
  langid = {american}
}

@misc{wang2023planandsolve,
  title = {Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models},
  shorttitle = {Plan-and-Solve Prompting},
  author = {Wang, Lei and Xu, Wanyu and Lan, Yihuai and Hu, Zhiqiang and Lan, Yunshi and Lee, Roy Ka-Wei and Lim, Ee-Peng},
  year = {2023},
  month = may,
  number = {arXiv:2305.04091},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.04091},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{wang2023selfconsistency,
  title = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  year = {2023},
  month = mar,
  number = {arXiv:2203.11171},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2203.11171},
  urldate = {2024-08-13},
  archiveprefix = {arXiv}
}

@misc{wang2024mathshepherd,
  title = {Math-Shepherd: Verify and Reinforce LLMs Step-by-Step without Human Annotations},
  shorttitle = {Math-Shepherd},
  author = {Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, R. X. and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Y. and Sui, Zhifang},
  year = {2024},
  month = feb,
  number = {arXiv:2312.08935},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-04-22},
  archiveprefix = {arXiv}
}

@misc{wei2023chainofthought,
  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  year = {2023},
  month = jan,
  number = {arXiv:2201.11903},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-04-22},
  archiveprefix = {arXiv}
}

@misc{wu2024inference,
  title = {Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models},
  shorttitle = {Inference Scaling Laws},
  author = {Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming},
  year = {2024},
  month = oct,
  number = {arXiv:2408.00724},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.00724},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{yan2024s$^3$cmath,
  title = {S\${\textasciicircum}3\$c-Math: Spontaneous Step-Level Self-Correction Makes Large Language Models Better Mathematical Reasoners},
  shorttitle = {S\${\textasciicircum}3\$c-Math},
  author = {Yan, Yuchen and Jiang, Jin and Liu, Yang and Cao, Yixin and Xu, Xin and {zhang}, Mengdi and Cai, Xunliang and Shao, Jian},
  year = {2024},
  month = sep,
  number = {arXiv:2409.01524},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.01524},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{yang2024qwen25math,
  title = {Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement},
  shorttitle = {Qwen2.5-Math Technical Report},
  author = {Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and Lu, Keming and Xue, Mingfeng and Lin, Runji and Liu, Tianyu and Ren, Xingzhang and Zhang, Zhenru},
  year = {2024},
  month = sep,
  number = {arXiv:2409.12122},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2409.12122},
  urldate = {2025-02-14},
  archiveprefix = {arXiv}
}

@misc{ying2024internlmmatha,
  title = {InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning},
  shorttitle = {InternLM-Math},
  author = {Ying, Huaiyuan and Zhang, Shuo and Li, Linyang and Zhou, Zhejian and Shao, Yunfan and Fei, Zhaoye and Ma, Yichuan and Hong, Jiawei and Liu, Kuikun and Wang, Ziyi and Wang, Yudong and Wu, Zijian and Li, Shuaibin and Zhou, Fengzhe and Liu, Hongwei and Zhang, Songyang and Zhang, Wenwei and Yan, Hang and Qiu, Xipeng and Wang, Jiayu and Chen, Kai and Lin, Dahua},
  year = {2024},
  month = may,
  number = {arXiv:2402.06332},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.06332},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{yu2024metamatha,
  title = {MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},
  shorttitle = {MetaMath},
  author = {Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T. and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  year = {2024},
  month = may,
  number = {arXiv:2309.12284},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-08-14},
  archiveprefix = {arXiv}
}

@misc{yue2023mammoth,
  title = {MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning},
  shorttitle = {MAmmoTH},
  author = {Yue, Xiang and Qu, Xingwei and Zhang, Ge and Fu, Yao and Huang, Wenhao and Sun, Huan and Su, Yu and Chen, Wenhu},
  year = {2023},
  month = oct,
  number = {arXiv:2309.05653},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.05653},
  urldate = {2025-02-16},
  archiveprefix = {arXiv}
}

@misc{zhang2024autonomous,
  title = {Autonomous Data Selection with Language Models for Mathematical Texts},
  author = {Zhang, Yifan and Luo, Yifan and Yuan, Yang and Yao, Andrew Chi-Chih},
  year = {2024},
  month = oct,
  number = {arXiv:2402.07625},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.07625},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{zhang2025lessons,
  title = {The Lessons of Developing Process Reward Models in Mathematical Reasoning},
  author = {Zhang, Zhenru and Zheng, Chujie and Wu, Yangzhen and Zhang, Beichen and Lin, Runji and Yu, Bowen and Liu, Dayiheng and Zhou, Jingren and Lin, Junyang},
  year = {2025},
  month = jan,
  number = {arXiv:2501.07301},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.07301},
  urldate = {2025-01-15},
  archiveprefix = {arXiv}
}

@misc{zhou2024jiuzhang30,
  title = {JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models},
  shorttitle = {JiuZhang3.0},
  author = {Zhou, Kun and Zhang, Beichen and Wang, Jiapeng and Chen, Zhipeng and Zhao, Wayne Xin and Sha, Jing and Sheng, Zhichao and Wang, Shijin and Wen, Ji-Rong},
  year = {2024},
  month = may,
  number = {arXiv:2405.14365},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.14365},
  urldate = {2024-06-24},
  archiveprefix = {arXiv}
}

## mcts
@article{zhou2023mcts1,
  title={Language agent tree search unifies reasoning acting and planning in language models},
  author={Zhou, Andy and Yan, Kai and Shlapentokh-Rothman, Michal and Wang, Haohan and Wang, Yu-Xiong},
  journal={arXiv preprint arXiv:2310.04406},
  year={2023}
}
@article{rebase2024wu,
  title={Inference scaling laws: An empirical analysis of compute-optimal inference for problem-solving with language models},
  author={Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming},
  journal={arXiv preprint arXiv:2408.00724},
  year={2024}
}
@inproceedings{liu2024mcts2,
  title={Don't throw away your value model! Generating more preferable text with Value-Guided Monte-Carlo Tree Search decoding},
  author={Liu, Jiacheng and Cohen, Andrew and Pasunuru, Ramakanth and Choi, Yejin and Hajishirzi, Hannaneh and Celikyilmaz, Asli},
  booktitle={First Conference on Language Modeling},
  year={2024}
}


## LLMs breakthrough
@article{GPT42023openai,
 author = {OpenAI},
 journal = {ArXiv preprint},
 title = {GPT-4 Technical Report},
 url = {https://arxiv.org/abs/2303.08774},
 volume = {abs/2303.08774},
 year = {2023}
}
@misc{deepseekr12025deepseekai,
      title={DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning}, 
      author={DeepSeek-AI},
      year={2025},
      eprint={2501.12948},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.12948}, 
}


% # intro external llm


@article{E-GSM2024Xu,
  title={Can LLMs Solve longer Math Word Problems Better?},
  author={Xu, Xin and Xiao, Tong and Chao, Zitong and Huang, Zhenya and Yang, Can and Wang, Yang},
  journal={arXiv preprint arXiv:2405.14804},
  year={2024}
}
@article{dartmath2024tong,
  title={DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving},
  author={Tong, Yuxuan and Zhang, Xiwen and Wang, Rui and Wu, Ruidong and He, Junxian},
  journal={arXiv preprint arXiv:2407.13690},
  year={2024}
}
@article{openmathinstruct2024toshniwal,
  title={Openmathinstruct-2: Accelerating ai for math with massive open-source instruction data},
  author={Toshniwal, Shubham and Du, Wei and Moshkov, Ivan and Kisacanin, Branislav and Ayrapetyan, Alexan and Gitman, Igor},
  journal={arXiv preprint arXiv:2410.01560},
  year={2024}
}

% rm
@article{pds2024xu,
  title={Can We Verify Step by Step for Incorrect Answer Detection?},
  author={Xu, Xin and Diao, Shizhe and Yang, Can and Wang, Yang},
  journal={arXiv preprint arXiv:2402.10528},
  year={2024}
}

@article{yuan2024prmfree,
  title={Free process rewards without process labels},
  author={Yuan, Lifan and Li, Wendi and Chen, Huayu and Cui, Ganqu and Ding, Ning and Zhang, Kaiyan and Zhou, Bowen and Liu, Zhiyuan and Peng, Hao},
  journal={arXiv preprint arXiv:2412.01981},
  year={2024}
}

# complex reasoning 

@article{OlympiadBench2024He,
  title={Olympiadbench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems},
  author={He, Chaoqun and Luo, Renjie and Bai, Yuzhuo and Hu, Shengding and Thai, Zhen Leng and Shen, Junhao and Hu, Jinyi and Han, Xu and Huang, Yujie and Zhang, Yuxiang and others},
  journal={arXiv preprint arXiv:2402.14008},
  year={2024}
}

@misc{ugmathbench2025xu,
      title={UGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning with Large Language Models}, 
      author={Xin Xu and Jiaxin Zhang and Tianhao Chen and Zitong Chao and Jishan Hu and Can Yang},
      year={2025},
      eprint={2501.13766},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.13766}, 
}

@article{omnimath2024gao,
  title={Omni-math: A universal olympiad level mathematic benchmark for large language models},
  author={Gao, Bofei and Song, Feifan and Yang, Zhe and Cai, Zefan and Miao, Yibo and Dong, Qingxiu and Li, Lei and Ma, Chenghao and Chen, Liang and Xu, Runxin and others},
  journal={arXiv preprint arXiv:2410.07985},
  year={2024}
}

@article{ugphysics2025xu,
  title={UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models},
  author={Xu, Xin and Xu, Qiyun and Xiao, Tong and Chen, Tianhao and Yan, Yuchen and Zhang, Jiaxin and Diao, Shizhe and Yang, Can and Wang, Yang},
  journal={arXiv preprint arXiv:2502.00334},
  year={2025}
}

@article{phan2025humanity,
  title={Humanity's Last Exam},
  author={Phan, Long and Gatti, Alice and Han, Ziwen and Li, Nathaniel and Hu, Josephina and Zhang, Hugh and Shi, Sean and Choi, Michael and Agrawal, Anish and Chopra, Arnav and others},
  journal={arXiv preprint arXiv:2501.14249},
  year={2025}
}

@article{guan2025rstar,
  title={rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking},
  author={Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2501.04519},
  year={2025}
}