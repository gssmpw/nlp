\section{Formative Study}\label{sec:formative-study}
To inform the design of \SystemName, we conducted formative surveys and interviews with experienced site-specific AR developers, artists, designers, and testers. Inspired by other investigations into AR development workflows~\cite{speicherXDARChallengesOpportunities2018,ashtariCreatingAugmentedVirtual2020,kraussCurrentPracticesChallenges2021}, we sought to determine current workflows and key challenges of outdoor site-specific AR experience development.

\subsection{Method \& Participants}\label{sec:formative-method-participants}
We recruited 25 survey respondents through internal mailing lists, AR development social media channels, and targeted emails to professional outdoor AR agencies. The survey included both quantitative and qualitative questions about the projects respondents had worked on, the tools they used, and their typical workflow. One survey question prompted respondents to list issues encountered during \insitu testing. To provide an initial set of response options, we defined a set of issue types through a brainstorming session and included an open-ended question for respondents to report additional issues they had come across.

The resulting issue types were as follows:
\begin{enumerate*}[label=(\Alph*)]
    \item Physical constraints (\eg, blocked paths and restricted areas),
    \item User safety (\eg, hazardous environments),
    \item Misaligned AR elements (\eg, misplaced anchors, occlusion, or perspective issues),
    \item User context (\eg, environmental noise or lighting conditions),
    \item Hardware performance (\eg, device processing and rendering power limitations),
    \item Registration issues (\eg, localization and tracking errors),
    \item User flow (\eg, user position or perspective affecting AR interaction),
    \item Socio-cultural appropriateness of the area or experience, and
    \item Semantic interaction (\eg, whether the system correctly recognizes objects in the world).
\end{enumerate*}
We refer to \cref{fig:issue-types} for visual illustrations of these issues.

Five of the survey respondents agreed to complete an interview, in which we asked semi-structured follow-up questions to obtain further details. Two authors of this paper conducted a reflexive thematic analysis to analyze the qualitative results. After developing initial codes, the authors iteratively refined the codebook while reviewing transcripts, following the methods described by \citet{braunThematicAnalysis2019}. Each interview participant received a gift card valued at £25, and survey respondents had a 1-in-10 chance of winning a gift card valued at £30. The survey and interview materials are available in the Supplementary Materials.

\subsection{Findings}
We structure our findings by first outlining typical workflows, followed by a review of major hurdles, and concluding with a discussion of future tools that participants considered useful. These findings inform our understanding of how users typically develop site-specific AR, support us to establish requirements for our proposed system (\cref{sec:system}) and a baseline for our study (\cref{sec:user-study}).

\subsubsection{Workflow walkthrough and tools}
One of the first steps participants took was to \textbf{acquire context about the target location} for their AR experience. This typically involved downloading publicly available pre-captured meshes or visiting the site to scan the location themselves. Participants primarily used \textit{Niantic Geospatial Browser}~\cite{nianticGeospatialBrowser} (64.0\%) or \textit{Google Geospatial Creator}~\cite{googleGeospatialCreator} (28.0\%) to obtain pre-captured meshes, which provided spatial information about the location to support the design and development process. We refer to these pre-captured meshes as \locMeshes throughout the rest of this paper. These representations helped them place and carefully align virtual content with real-world structures and surfaces. Later, when at the site, end-users could use a VPS to localize and interact with the experience.

Following this, participants typically \textbf{worked \exsitu[ ] to design and build the experience} based on the \locMesh. For development, they most often used \textit{Unity} (96\%) and \textit{Blender} (76\%). Additionally, they employed AR frameworks to support features such as plane detection, occlusion meshes, and semantic segmentation. The most commonly used framework was \textit{Niantic SDK for Unity} (80.0\%), followed by \textit{ARFoundation} (76.0\%). A summary of the tools participants used is available in the Supplementary Materials.

Since \exsitu tools could not provide full contextual awareness of the location (\eg dynamic objects, crowding, and lighting conditions), \textbf{participants or their team members often had to travel back and forth} between their \exsitu development location and the target environment. When \insitu[ ], participants logged information about issues with their AR experience to address them later or relay them to their team. On average, they reported spending 36\% (SD=24.7) of their time testing the experience \insitu[ ] and had between 0 and 12 team members that worked with them (M=4.16; SD=2.97). Notably, one interview participant (P4) mentioned considering bringing their ``computer with [their] phone'' to the site to address alignment issues \insitu[ ] but noted that they ``do not think [they] should'' for practical reasons, such as environmental conditions like weather and crowds, which were also cited by other participants (P1, P2, P5).

In terms of the issues described in \cref{sec:formative-method-participants}, \textit{Physical Constraints}, \textit{User Safety}, and \textit{Misaligned AR Elements} were the most commonly reported\footnote{Only one participant described an additional issue type in the survey, ``Game Flow,'' which we categorize under ``User Flow.''} (see \cref{fig:formative-issues}). To record these issues \insitu[ ], participants typically took screenshots, screen recordings, or typed notes (see \cref{fig:formative-documentation}). Some also received recordings or notes from team members who visited the site. After initial context gathering, participants or their team members continued iterating on their AR experiences, traveling between locations as needed until completion.

\begin{figure}
    \centering
    \includegraphics[width=0.94\linewidth]{Figures/Plots/in-situ-documentation-plot-vertical_CameraReady.pdf}
    \caption{The number of participants who reported using various methods to document issues in their AR experiences when \insitu[ ].}
    \label{fig:formative-documentation}
    %
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.94\linewidth]{Figures/Plots/issue-type-plot-vertical_CameraReady.pdf}
    \caption{The number of participants who reported looking for various issues in their AR experiences when \insitu[ ]. See \cref{sec:formative-method-participants} for descriptions of the issues.}
    \label{fig:formative-issues}
    %
\end{figure}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{Figures/IssueTypes.pdf}
    \caption{The five main site-specific AR issue types we aimed to address with \SystemName. We refer to \cref{sec:formative-study} for further details on the full range of issues identified in our formative study.}
    \label{fig:issue-types}
    %
\end{figure*}

\subsubsection{Challenges with context capture}
In the interviews, all five participants mentioned \textbf{difficulties with pre-captured meshes}, whether obtained from geospatial browsers or personally scanned. For instance, P2 described pre-captured \locMeshes as ``old'' and not up to date with the current state of the real world. P4 noted that \locMeshes were ``always a challenge because there are mesh holes everywhere [...] so the geometry falls through.'' Similarly, P5 stated that ``the maps are very incomplete,'' but the alternative---scanning the location manually---was ``quite labor intensive.''

Participants also mentioned \textbf{difficulties with scanning}. P1 described how ``often the test scans do not come out great'' and how they sometimes needed to select alternative target locations due to poor scan quality. P5 noted that scan processing times could be lengthy, which reduced iteration efficiency. Two participants also commented on the difficulty of the scanning process due to social awkwardness (P3) or poor weather conditions (P5).

Poor-quality meshes contributed to \textbf{alignment issues} between virtual objects and the real world, both because degraded meshes reduced localization accuracy and because poor mesh geometry hindered precise placement when working \exsitu[ ]. For example, P5 described this limitation: ``It's like you try to figure out where [the virtual object] has to be [ex-situ], and then every time you go [in-situ], your viewpoint is a bit different because you are looking at it from street level or it's slightly tilted [...] we always ended up having to reposition the thing compared to the initial [placement].'' All participants mentioned alignment issues as a recurring problem.

\subsubsection{Missing contextual information}\label{sec:formative-study:missing-contextual-info}
All five participants also mentioned \textbf{challenges in acquiring contextual information missing from meshes}. For example, P3 and P4 described how locations found online might not actually be accessible, or how previously accessible locations might become restricted over time. Three participants mentioned how some locations were hard to conceptualize \exsitu[ ] without visiting in person---either because they were too complex or large (P1) or too cramped (P2, P3).

P1, P2, and P4 mentioned challenges related to \textbf{lighting conditions}, particularly at different times of the day. This concern arose both from an end-user experience perspective (\eg P1: ``You do not want someone staring into the sun'') and in terms of VPS localization accuracy (\eg P4: ``we generally test throughout the day to try to make sure that it is going to work under any lighting''). P1 also highlighted ``audio contamination'' as a factor that could affect the experience, but which could not be discovered without being at the target location. Additionally, P1, P2, and P5 mentioned adverse weather conditions affecting \insitu testing.

One crucial piece of contextual information that all five participants mentioned gathering \insitu[ ] was \textbf{the area's safety}. This included assessing foot and vehicle traffic, as well as the potential for theft. For example, P3 described how even though an area might be plenty of areas where things are walkable [... this still] means very heavy foot traffic, [so] you still have to be careful.'' P1 pointed out that if users are ``getting jostled, or [using] a very expensive phone, then someone could just snatch it.''

All participants also mentioned the need to assess \textbf{the level of crowding at a location}, as high foot traffic could impede both the user experience and VPS localization. P2 even described having to change the target site due to crowding. \textbf{Moving objects} also posed a challenge for both the experience and localization. As objects at the location changed---such as cars, signs, or even ``posters'' (P1)---VPSs struggled to match the environment with the \locMeshes.

\subsubsection{User experience challenges}
All five participants reported \textbf{difficulties identifying end-user experience challenges}, particularly when developing \exsitu[ ]. P1 and P2, for example, emphasized the importance of understanding the ``human scale'' to ensure objects were appropriately reachable and scaled, which was difficult to achieve without being \insitu[ ]. Participants also noted visibility challenges. P1, P2, and P3 described how ``tight FOVs,'' long distances, or sun direction could affect visibility. Gameplay considerations also required \insitu testing; P2 stated that users should not have to run during the experience, while P1 mentioned ensuring that gameplay events were not ``too close'' or ``too far away.''

\subsubsection{Workflow challenges}
Due to these difficulties, four of the five participants described \textbf{traveling to target locations as a significant challenge}. They characterized these trips as ``inefficient'' (P1), ``a lot of effort'' (P3), and ``costly'' (P5). These trips could also be extensive, with participants traveling to different cities (P2, P3) and even different countries (P5) for testing.

Other workflow challenges included collecting and sharing feedback from \insitu testing. P1 described difficulties in physically taking notes while testing the experience, explaining issues over audio, and annotating video recordings. P2 and P5 described communication challenges when working with team members from different backgrounds. P2 also mentioned ``hassles'' related to uploading, downloading, and sharing information while \insitu[ ].

\subsubsection{Desired features for future tools}
As participants described these challenges, they also suggested potential solutions. To address poor context capture, P2 and P4 proposed \textbf{methods to tag areas with semantic or other labels}. Others suggested \textbf{collaborative approaches to context gathering}. For instance, P1, P4, and P5 suggested streamlined methods for sharing and viewing \locMeshes with team members. P4 also proposed a way to combine and edit multiple team members' meshes to enhance their accuracy. Additionally, P2 and P4 expressed interest in a system that allowed team members to collaborate \insitu[ ] and \exsitu[ ] via live streaming of location data and voice communication.

Participants also expressed interest in tools that improve the authoring process. Four of the five participants expressed interest in \textbf{editing objects \insitu[ ]}. P2 and P4 suggested \textbf{procedural placement of objects based on semantic data}. P3, P4, and P5 wanted better methods for simulating the site \exsitu[ ], with P5 stating, ``The more you can do without actually being on the spot, the better.''
