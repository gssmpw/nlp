\section{Related Work}
\vspace{-3mm}
In this section, we discuss the related works by revisiting 6D object pose estimation on RGB images, for transparent object, and representation of edges.

\subsection{6D Object Pose Estimation on RGB Images}
When considering the input data, 6D object pose estimation can be divided into RGB-D-based and RGB-based methods.
RGB-D approaches consider 2D RGB data as well as depth information to achieve a pose estimate. 
While these methods achieve high performances on textured data \cite{pvn3d, g2l, densefusion}, errors occur when being applied to transparent objects. 
State-of-the-art sensor systems fail when it comes to obtaining depth data of transparent objects properly. For this reason, we concentrate on methods using only RGB information.
Most current approaches rely on multi-stage networks instead of regressing the pose directly.
To extract intermediate features approaches such as segmentation masks \cite{Hu_2020_CVPR}, key points \cite{kundu2019object}, corner points of bounding boxes \cite{rad2017bb8}, or feature maps \cite{gdrnet} are used. This results in 2D-3D correspondences meaning that points in the 2D image are matched to their position in three-dimensional space \cite{huang1994motion}.
Then, the pose is estimated based on the retrieved features by applying an additional Perspective-n-Point (PnP) algorithm \cite{pavlakos20176, tjaden2017real}. The PnP problem describes the problem of finding the relative pose between an object and a camera from a set of n pairings between 3D points of the object and their corresponding 2D projections on the focal plane \cite{wu2006pnp}. 
% or similar variations \cite{Hu_2020_CVPR}. 
% such as RANSAC \cite{fenzi20123d},

%Lastly, pose refiners are adopted in order to improve the accuracy of the object pose estimation. These refinement steps are concluded by ICP methods \cite{kehl2017ssd}, deep neural networks \cite{wohlhart2015learning}, or render-and-compare \cite{Trabelsi_2021_WACV} \cite{labbe2022megapose}. 

%Peng et al. \cite{Peng_2019_CVPR} rely on a pixel-wise voting system that regresses vectors pointing to the keypoint for each pixel. 
%The vectors are utilized to vote for the keypoint location and can therefore extract also sparse keypoints which are overseen by other methods. 
%Su et al. \cite{su2022zebrapose} achieves fine-grained correspondences by employing a hierarchical binary grouping mechanism that represents the surface of an object.
%...
% Instead of introducing a novel network, we propose a method that builds on an advanced state-of-the-art object pose estimator.
E.g. the Geometry Guided Direct Regression Network (GDR-Net) \cite{gdrnet} combines direct and geometry-based indirect approaches, divides objects into fragments and outputs the pose estimate directly. 
The approach decouples 2D object detection and 6D object pose estimation.
The method identifies all objects by means of a detector and identifies a Region of Interest (RoI) for each detection and predicts a geometric feature map of the RoI.
The Patch-PnP algorithm is then employed to directly regress the 6D object pose. 
Even if the methods above achieve considerable results on textured objects, it is not explictily designed for transparent objects and their unique properties.

\subsection{6D Pose Estimation of Transparent Objects}
Transparent objects cause reflections and refractions of light leading to a non-uniform appearance of the surface.
Correspondences between different parts of the object are challenging to establish when the surface of an object does not have the same texture. 
Due to these unique visual properties, their depth information can not be captured by state-of-the-art sensors.
The lack of distinct textures and features in transparent objects requires other strategies to extract the pose information.
\cite{liu2020keypose, chen2022clearpose, zhang2022transnet} propose networks explicitly designed for estimating poses of transparent objects. 
Zhou et al. \cite{zhou2019glassloc} estimate the probability of being transparent for each pixel with a light-field camera.
Sajan et al. \cite{sajjan2020cleargrasp} employ deep CNNs to infer surface normals, transparent surface masks, and occlusion boundaries. 
These outputs are then used to refine depth estimates of the scene. 
Liu et al. \cite{liu2020keypose} propose with Keypose to train a deep neural network on raw stereo images to predict object poses from 3D keypoints.
%Another line of work focuses on retrieving the depth estimates from the low-quality depth information.
The mentioned methods can achieve considerable results on transparent objects.
However, these specific methods bear major limitations restricting their usage in real-world applications.
A frequent assumption is the availability of a 3D model of the corresponding object \cite{glassware, transparent_clutter, mobile_platform}, assume object properties, or require specific equipment \cite{zhou2019glassloc}.
Our method considers the usage of a generic 6D object pose estimation pipeline to avoid the prerequisites which come with pipelines explicitly for transparent objects.
%Also, the improvement of depth information remains an unsolved problem. %rewrite somehow

\subsection{Edge Representation}
Several studies have integrated edge representation strategies in CNN in order to achieve better performance results. 
Edge representations have proved themselves to be advantageous when handling texture-less objects \cite{er-pose, d2co}.
Zhang et al. \cite{zhang2022eanet} propose an edge-detection network to estimate the 6D object pose. By implementing a shared-weight edge extractor, edge reconstruction and pose estimation are derived simultaneously.
\cite{er-pose} introduced a two-stage 6D pose estimation method for textureless objects.
Instead of utilizing the object mask in current monocular methods, an edge representation for texture-less objects is proposed.
It was found in the experiments, that directly replacing the object mask with the edge representation can bring a performance improvement in two current two-stage pipelines without any modification \cite{er-pose}.
While Canny edge detection is a well-established method to detect contours reliably, the drawback of the method is the reproduction of foreground and background edges to the same extent \cite{canny}.
Holistically Nested Edge Detection (HED) represents a deep learning methodology that employs multi-layered convolutional neural networks to generate images that highlight contours \cite{xie15hed}.
In contrast to conventional edge detection methods, HED is designed to distinguish between background and foreground features. 
Harary et al. \cite{harary2022brad} use an edge-regularized bridge across domains to map features from one domain to another. 
To address the issues of 6D object pose estimation, we conduct experiments with Canny edge detection and HED in order to enhance the performance of state-of-the-art object pose estimation.