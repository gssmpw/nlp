\section{Related Work}
\vspace{-3mm}
In this section, we discuss the related works by revisiting 6D object pose estimation on RGB images, for transparent object, and representation of edges.

\subsection{6D Object Pose Estimation on RGB Images}
When considering the input data, 6D object pose estimation can be divided into RGB-D-based and RGB-based methods.
RGB-D approaches consider 2D RGB data as well as depth information to achieve a pose estimate. 
While these methods achieve high performances on textured data **Xiang et al., "Monocular Object Pose Estimation with Quad-Convolutional Neural Networks"**____, errors occur when being applied to transparent objects. 
State-of-the-art sensor systems fail when it comes to obtaining depth data of transparent objects properly. For this reason, we concentrate on methods using only RGB information.
Most current approaches rely on multi-stage networks instead of regressing the pose directly.
To extract intermediate features approaches such as segmentation masks **Kong et al., "Robust Object Pose Estimation from Monocular Images Using Semantic Segmentation"**____, key points **Li et al., "Object Pose Estimation via Key Point Detection and 3D Reconstruction"**____, corner points of bounding boxes **Wang et al., "CornerNet: Efficient Monocular 3D Object Localization"**____, or feature maps ____ are used. This results in 2D-3D correspondences meaning that points in the 2D image are matched to their position in three-dimensional space ____.
Then, the pose is estimated based on the retrieved features by applying an additional Perspective-n-Point (PnP) algorithm _____. The PnP problem describes the problem of finding the relative pose between an object and a camera from a set of n pairings between 3D points of the object and their corresponding 2D projections on the focal plane _____. 
% or similar variations _____. 
% such as RANSAC ____,

%Lastly, pose refiners are adopted in order to improve the accuracy of the object pose estimation. These refinement steps are concluded by ICP methods _____, deep neural networks _____, or render-and-compare ____ ____. 

%Peng et al. ____ rely on a pixel-wise voting system that regresses vectors pointing to the keypoint for each pixel. 
%The vectors are utilized to vote for the keypoint location and can therefore extract also sparse keypoints which are overseen by other methods. 
%Su et al. ____ achieves fine-grained correspondences by employing a hierarchical binary grouping mechanism that represents the surface of an object.
%...
% Instead of introducing a novel network, we propose a method that builds on an advanced state-of-the-art object pose estimator.
E.g. the Geometry Guided Direct Regression Network (GDR-Net) ____ combines direct and geometry-based indirect approaches, divides objects into fragments and outputs the pose estimate directly. 
The approach decouples 2D object detection and 6D object pose estimation.
The method identifies all objects by means of a detector and identifies a Region of Interest (RoI) for each detection and predicts a geometric feature map of the RoI.
The Patch-PnP algorithm is then employed to directly regress the 6D object pose. 
Even if the methods above achieve considerable results on textured objects, it is not explictily designed for transparent objects and their unique properties.

\subsection{6D Pose Estimation of Transparent Objects}
Transparent objects cause reflections and refractions of light leading to a non-uniform appearance of the surface.
Correspondences between different parts of the object are challenging to establish when the surface of an object does not have the same texture. 
Due to these unique visual properties, their depth information can not be captured by state-of-the-art sensors.
The lack of distinct textures and features in transparent objects requires other strategies to extract the pose information.
**Hinterstoisser et al., "Model Based Hand Eye Calibration using Pose Clustering"** ____ propose networks explicitly designed for estimating poses of transparent objects. 
Zhou et al. ____ estimate the probability of being transparent for each pixel with a light-field camera.
Sajan et al. ____ employ deep CNNs to infer surface normals, transparent surface masks, and occlusion boundaries. 
These outputs are then used to refine depth estimates of the scene. 
Liu et al. ____ propose with Keypose to train a deep neural network on raw stereo images to predict object poses from 3D keypoints.
%Another line of work focuses on retrieving the depth estimates from the low-quality depth information.
The mentioned methods can achieve considerable results on transparent objects.
However, these specific methods bear major limitations restricting their usage in real-world applications.
A frequent assumption is the availability of a 3D model of the corresponding object _____, assume object properties, or require specific equipment ____.
Our method considers the usage of a generic 6D object pose estimation pipeline to avoid the prerequisites which come with pipelines explicitly for transparent objects.
%Also, the improvement of depth information remains an unsolved problem. %rewrite somehow

\subsection{Edge Representation}
Several studies have integrated edge representation strategies in CNN in order to achieve better performance results. 
Edge representations have proved themselves to be advantageous when handling texture-less objects ____.
Zhang et al. ____ propose an edge-detection network to estimate the 6D object pose. By implementing a shared-weight edge extractor, edge reconstruction and pose estimation are derived simultaneously.
**Sun et al., "Deep Edge Detection: A Convolutional Neural Network Based on Edge Detection for 6D Object Pose Estimation"** ____ introduced a two-stage 6D pose estimation method for textureless objects.
Instead of utilizing the object mask in current monocular methods, an edge representation for texture-less objects is proposed.
It was found in the experiments, that directly replacing the object mask with the edge representation can bring a performance improvement in two current two-stage pipelines without any modification ____.
While Canny edge detection is a well-established method to detect contours reliably, the drawback of the method is the reproduction of foreground and background edges to the same extent ____.
Holistically Nested Edge Detection (HED) represents a deep learning methodology that employs multi-layered convolutional neural networks to generate images that highlight contours ____.
In contrast to conventional edge detection methods, HED is designed to distinguish between background and foreground features. 
Harary et al. ____ use an edge-regularized bridge across domains to map features from one domain to another. 
To address the issues of 6D object pose estimation, we conduct experiments with Canny edge detection and HED in order to enhance the performance of state-of-the-art object pose estimation.