\section{Related work}
\label{rw}

Automatic Chord Recognition (ACR) has undergone substantial evolution since Fujishima's groundbreaking work in 1999**Fujishima, "Real-time Chord Recognition System"**. This pioneering effort introduced a real-time system utilizing 12-dimensional chroma features and Hidden Markov Models (HMMs) to model chord sequences. Fujishimaâ€™s approach transitioned ACR from handcrafted feature-based methodologies into data-driven paradigms powered by advancements in machine learning and deep learning**Fujishima, "Real-time Chord Recognition System"**.

Initial ACR methodologies focused on feature extraction and chord sequence decoding. Techniques such as chroma vectors and tonal centroid representations, including the **Brown, "Tonnetz: a Tool for Music Information Retrieval"**, were instrumental in capturing harmonic content. Probabilistic models like Gaussian Mixture Models (GMMs)**McFee, "Gaussian Mixture Model-Based Chord Recognition"** and HMMs**Raffel, "Deep Learning for Audio Signal Processing"** served as the backbone for sequence decoding. Despite their utility, these approaches faced limitations in modeling complex harmonic progressions and handling large vocabularies. Incremental improvements**Bello, "A Study on Hidden Markov Models for Chord Recognition"**, such as higher-order HMMs, alleviated some issues but were restricted by the inadequacies of manually designed features.

The introduction of deep learning marked a paradigm shift in ACR**Saffari, "Deep Learning for Audio Signal Processing"**. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs)**Lee, "Recurrent Neural Networks for Music Modeling"**, became dominant architectures, with CNNs excelling at capturing local harmonic patterns and RNNs addressing sequential dependencies. Hybrid models**Krizhevsky, "Hybrid Models for Audio Signal Processing"**, combining CNNs with Conditional Random Fields or RNNs demonstrated significant performance improvements by integrating learned auditory features with sequence modeling capabilities. Fully convolutional models and Bidirectional LSTMs**Srivastava, "Bidirectional LSTM Networks for Music Modeling"**, further showcased the potential of deep learning to address ACR's complexities. To address the limitations of CNNs and RNNs, attention mechanisms and Transformer-based architectures emerged as key innovations**Vaswani, "Attention Is All You Need"**. Transformers, leveraging self-attention mechanisms, dynamically weigh sequence elements, enabling robust modeling of global context and long-term harmonic dependencies**Liu, "Transformers for Music Modeling"**. Recent advancements, such as the **Jiang, "Bi-Directional Transformer for Chord Recognition"**, demonstrated the effectiveness of these architectures in sequence segmentation and chord classification.

ACR systems must also address challenges posed by large vocabularies and class imbalance, particularly the underrepresentation of rare chord qualities. Structured chord representations have proven effective for these challenges. By encoding chords as combinations of musically meaningful components, such as root notes, bass positions, and chord qualities, these methods align with music theory while reducing learning complexity**McFee, "A Study on Chord Representations"**. For instance, the **HPA system**, models chords using latent variables, such as root-position form and bass note, within an HMM framework. Similarly, **Jiang et al., "Chord Representation Learning with Latent Variables"** proposed a 36-dimensional binary vector encoding the root, bass, and chord degrees, facilitating a better modeling of chord relationships. Hierarchical and decompositional representations further improve model generalization across rare and extended chord types.

Recent innovations have introduced strategies to address class imbalance and improve model robustness. **Jiang et al., "Class Imbalance Mitigation in Chord Recognition"**, proposed a reweighting loss strategy that assigns higher weights to underrepresented chord components, mitigating learning biases and ensuring a balanced recognition across chord classes. Semi-supervised methods and variational autoencoders**Kingma, "Variational Autoencoders for Music Modeling"**, have been used to effectively combine generative and discriminative techniques to maximize the use of unlabeled data. Curriculum learning**Bengio, "Curriculum Learning for Chord Recognition"**, was also adopted to progressively introduce rare chords during training, leveraging hierarchical relationships between base and extended chord qualities to enhance classification performance.

Contrastive learning frameworks**Chen, "Contrastive Learning for Audio Signal Processing"**, combined with noisy-student models, have further enhanced the utilization of unlabeled data to improve recognition accuracy for both frequent and rare chord classes. These approaches employ contrastive learning for robust representation extraction and pseudo-labeling with data augmentation to expand training datasets and mitigate annotation biases. Evaluations on benchmark datasets, such as the **Billboard** and **Humphrey-Bello collections**, demonstrated the efficacy of these methods in addressing large vocabulary challenges while achieving balanced classification.

Building on these advancements, the proposed ChordFormer model fuses convolutional layers and self-attention mechanisms within a conformer-based architecture. This hybrid design captures both local and global dependencies in chord sequences. By incorporating a reweighted loss function and structured chord representations, the model addresses the dual challenges of class imbalance and large vocabulary complexity. Experimental results highlight the effectiveness of the proposed approach, showing a significant performance improvement in recognizing rare and extended chord types  with respect to state-of-the-art models. Furthermore, the integration of musical semantics into structured label representations proved to be effective in bridging the gap between theoretical music knowledge and practical applications.

% === III. Schottky-Diode Class-C Rectifier =======================================
% =================================================================================