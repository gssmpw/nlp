\section{Related work}
\label{rw}

Automatic Chord Recognition (ACR) has undergone substantial evolution since Fujishima's groundbreaking work in 1999~\cite{takuya1999realtime}. This pioneering effort introduced a real-time system utilizing 12-dimensional chroma features and Hidden Markov Models (HMMs) to model chord sequences. Fujishimaâ€™s approach transitioned ACR from handcrafted feature-based methodologies into data-driven paradigms powered by advancements in machine learning and deep learning~\cite{mcvicar2014automatic}.

Initial ACR methodologies focused on feature extraction and chord sequence decoding. Techniques such as chroma vectors and tonal centroid representations, including the Tonnetz~\cite{humphrey2012learning}, were instrumental in capturing harmonic content. Probabilistic models like Gaussian Mixture Models (GMMs)~\cite{khadkevich2013reassigned} and HMMs~\cite{ueda2010hmm,sheh2003chord, khadkevich2009use} served as the backbone for sequence decoding. Despite their utility, these approaches faced limitations in modeling complex harmonic progressions and handling large vocabularies. Incremental improvements~\cite{ni2012end, mauch2010approximate}, such as higher-order HMMs, alleviated some issues but were restricted by the inadequacies of manually designed features.

The introduction of deep learning marked a paradigm shift in ACR~\cite{korzeniowski2016feature, sigtia2015audio, zhou2015chord}. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs)~\cite{jiang2019large,humphrey2012rethinking,mcfee2017structured,wu2018automatic,boulanger2013audio,deng2016hybrid,deng2017large} became dominant architectures, with CNNs excelling at capturing local harmonic patterns and RNNs addressing sequential dependencies. Hybrid models~\cite{korzeniowski2016fully,lanz2021automatic} combining CNNs with Conditional Random Fields or RNNs demonstrated significant performance improvements by integrating learned auditory features with sequence modeling capabilities. Fully convolutional models and Bidirectional LSTMs~\cite{jiang2019large, wu2018automatic} further showcased the potential of deep learning to address ACR's complexities. To address the limitations of CNNs and RNNs, attention mechanisms and Transformer-based architectures emerged as key innovations~\cite{vaswani2017attention}. Transformers, leveraging self-attention mechanisms, dynamically weigh sequence elements, enabling robust modeling of global context and long-term harmonic dependencies~\cite{gulati2020conformer}. Recent advancements, such as the Bi-Directional Transformer for Chord Recognition~\cite{park2019bi}, demonstrated the effectiveness of these architectures in sequence segmentation and chord classification.

ACR systems must also address challenges posed by large vocabularies and class imbalance~\cite{pauwels2019acr}, particularly the underrepresentation of rare chord qualities. Structured chord representations have proven effective for these challenges. By encoding chords as combinations of musically meaningful components, such as root notes, bass positions, and chord qualities, these methods align with music theory while reducing learning complexity~\cite{mcfee2017structured}. For instance, the HPA system~\cite{ni2012end} models chords using latent variables, such as root-position form and bass note, within an HMM framework. Similarly, McFee and Bello ~\cite{mcfee2017structured} proposed a 36-dimensional binary vector encoding the root, bass, and chord degrees, facilitating a better modeling of chord relationships. Hierarchical and decompositional representations further improve model generalization across rare and extended chord types.

Recent innovations have introduced strategies to address class imbalance and improve model robustness. Jiang et al.~\cite{jiang2019large} proposed a reweighting loss strategy that assigns higher weights to underrepresented chord components, mitigating learning biases and ensuring a balanced recognition across chord classes. Semi-supervised methods and variational autoencoders~\cite{wu2020semi} have been used to effectively combine generative and discriminative techniques to maximize the use of unlabeled data. Curriculum learning~\cite{rowe2021curriculum} was also adopted to progressively introduce rare chords during training, leveraging hierarchical relationships between base and extended chord qualities to enhance classification performance.

Contrastive learning frameworks~\cite{li2024large}, combined with noisy-student models, have further enhanced the utilization of unlabeled data to improve recognition accuracy for both frequent and rare chord classes. These approaches employ contrastive learning for robust representation extraction and pseudo-labeling with data augmentation to expand training datasets and mitigate annotation biases. Evaluations on benchmark datasets, such as the Billboard and Humphrey-Bello collections~\cite{mcfee2017structured, humphrey2015four}, demonstrated the efficacy of these methods in addressing large vocabulary challenges while achieving balanced classification.

Building on these advancements, the proposed ChordFormer model fuses convolutional layers and self-attention mechanisms within a conformer-based architecture. This hybrid design captures both local and global dependencies in chord sequences. By incorporating a reweighted loss function and structured chord representations, the model addresses the dual challenges of class imbalance and large vocabulary complexity. Experimental results highlight the effectiveness of the proposed approach, showing a significant performance improvement in recognizing rare and extended chord types  with respect to state-of-the-art models. Furthermore, the integration of musical semantics into structured label representations proved to be effective in bridging the gap between theoretical music knowledge and practical applications.


% === III. Schottky-Diode Class-C Rectifier =======================================
% =================================================================================