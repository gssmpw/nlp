\section{Related Work}
\textbf{Trajectory Segmentation:} A significant body of work has focused on learning reusable skills from a set of trajectories in an unsupervised manner \cite{niekum_unsupervised,DDO,compile,love,llm_segment}. The underlying approach shared by these methods is to model the distribution of trajectories using a latent variable model, where the latent variables represents the active skill at each timestep. After training the probabilistic model via maximum likelihood \cite{DDO,compile}, inferring the latents for a trajectory results in a segmentation of the trajectory \cite{love}. However, there is no guarantee that the segments will correspond to specific instructions. To ensure that the extracted subsegments align with natural language instructions, a set of annotated examples can be employed \cite{taco}. Given the high cost of annotations, it is desirable for this set to be only a small fraction of the available demonstrations, which naturally leads to a semi-supervised setup \cite{sl3}. Prior work looked at data setups in which trajectories are paired with plans describing the sequence of skills performed by the agent \cite{taco,sl3}. Here, the annotation are segments of individual instructions within longer trajectories. Therefore we do not need to model the segmentation as a latent variable but can learn the parameters of a conditional distribution over segmentations given a trajectory. 


\textbf{Semi-Supervised Instruction Following}: The standard approach to train instructable agents is to perform imitation learning on a dataset of instruction-trajectory pairs \cite{robotic_imitation_language,bc_z,interactive_language}. Due to the difficulty of generating natural language annotated trajectories, the problem is often studied in a semi-supervised learning setup \cite{labelling_model, relabelling}. For example, \citet{labelling_model} train a labelling  model using CLIP embeddings \cite{clip} on a small annotated dataset to then label a large unannotated dataset. Training a policy on the joint dataset improves the task accuracy. However, the unlabelled and labelled trajectories come from the same distribution, making it unnecessary to identify segments corresponding to instructions in the unlabelled trajectories. The model that has been trained in a setting closest to ours is SL3 \cite{sl3}. Given a small set of trajectories labelled with an overall goal and the sequence of instructions contained in it \cite{alfred}, SL3 applies an iterative procedure of segmenting trajectories, labelling segments and learning an instruction conditioned policy. The labelled dataset here consists of individual instructions and not plans, but unlike the case of SL3 does contain information about the start and end of these instructions.  

\textbf{Video Segmentation}: The vision community has studied the task of identifying actions in uncropped videos under related but distinct setups. While Action Segmentation (AS) methods \cite{st_cnn,ms_tcn, asformer,as_survey} try to predict for each frame the correct action class, Temporal Action Localization (TAL) methods try to predict the boundary timesteps of an action segment and a corresponding action label \cite{tallformer,tridet, tal_survey}. Some frameworks are developed to handle multiple of these tasks \cite{unloc}. Datasets for training contain uncropped videos containing multiple, not necessarily contiguous, action segments that are annotated on a frame level or with segment boundary information \cite{coin_dataset,assembly101_dataset,breakfast_dataset}. Both classes of methods have been studied under different levels of supervision \cite{unsupervised_as,semi_supervised_as,weakly_supervised_as}.
Our setting provides a unique challenge where the length of the training videos and the number of activities in the training videos differ from the videos at test time. To the best of our knowledge we are the first to investigate the usage of video segmentation models for data augmentation in sequential decision making settings.