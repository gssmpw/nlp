\begin{abstract}

In this work, we tackle the challenge of disambiguating queries in retrieval-augmented generation (RAG) to diverse yet answerable interpretations.
State-of-the-arts follow a Diversify-then-Verify (DtV) pipeline, where diverse interpretations are generated by an LLM,
later used as search queries to retrieve supporting passages.
Such a process
may introduce noise in either interpretations or retrieval,
particularly in enterprise settings, where LLMs---trained on static data---may struggle with domain-specific disambiguations.
Thus, a post-hoc verification phase is introduced to prune noises.
Our distinction is \textbf{to unify diversification with verification} by incorporating feedback from retriever and generator early on.
This joint approach improves both efficiency and robustness by reducing reliance on multiple retrieval and inference steps, which are susceptible to cascading errors.
We validate the efficiency and effectiveness of our method, \ourslong (\ours), on the widely adopted ASQA benchmark
to achieve diverse yet verifiable interpretations.
Empirical results show that \ours improves grounding-aware $\textrm{F}_1$ score by an average of 23\% over the strongest baseline across different backbone LLMs.
\end{abstract}
