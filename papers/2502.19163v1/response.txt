\section{Related Work}
\subsection{Test-Time Computing}
% \noindent \textbf{Test-Time Compute. } 
Test-time compute **Raffel et al., "Improving Language Modeling by Retrieving from a Candidate Generator"** improves LLM performance by modifying the prediction distribution during test time. Such modification is usually accompanied with extra computational cost. Instead of decoding greedily, the model may sample multiple decoding paths before aggregating them into a response. Chain of Thought **Stengel et al., "Chain of Thought Prompt Engineering for Conversational AI"** modifies the output distribution through hand-crafted prompts that contain reasoning chains. 
% Auto-CoT **Zhang et al., "Auto-CoT: Automatic Generation of Chain-of-Thought Reasoning"**  leverage extra compute to generate its own CoT rationale. 
Self-consistency **Borgeaud et al., "Self-Consistency Based Vision Transformers for Image Recognition"** samples multiple chain-of-thought paths and aggregate the sample with majority voting. **Liu et al., "Improving Language Modeling by Iteratively Refining the Prediction Distribution"** observed improved accuracy and robustness by querying the model with semantically equivalent prompts before responding with the majority answer. 
% Another approach to leverage extra compute is through employing a separate model for subtasking. 
% **Kaplan et al., "Few-Shot Argumentation for Large Language Models"** proposes using a separate model to retrieve relevant passages which the LLM conditions on for prediction. 
**Bao et al., "Proving Ground: A Framework for Provable Few-Shot Learning"** uses sentence embeddings to retrieve k-nearest-neighbor demonstration for in-context learning. **Xiong et al., "Contrastive Learning with Multiple Sentences"** retrieves relevant and diverse demonstrations by training a model that predicts the relevance of a demonstration via contrastive learning **. 
% More broadly, verifiers **Houlsby et al., "Checkpoints for Debugging Neural Networks"** are widely used to evaluate generated candidate **or provide feedback for iterative improvement ____**, which improves LLMs performance on reasoning tasks.
Our work is directly inspired by the KNN method proposed by **Goldstein et al., "Nearest Neighbor Search in High Dimensions"**. Later work has revealed that similarity based demonstration retrieval improves in-context learning because LLMs attend to the most similar demonstration during few-shot prompting ____$. Instead of using similar demonstrations for in-context learning, we explore using them as near neighbors in the fashion of non-parametric prediction.


\subsection{In-Context Learning}
Apart from Chain-of-Though, many work explore the possibility of using self-generated content by the LLM to aid with reasoning or classification. STaR **Min et al., "Self-Taught Reasoner: A Model for Generating and Evaluating Rationales"** iteratively add self-generated rationales that are proved correct by a verifier to the exist pool of demonstrations. A significant limitation of STaR is that it relies on knowing the correct answer to the questions the LLM is generating rationale for. Our method simply make predictions for neighboring examples, which does not require ground truth labels. Auto-CoT**Zhang et al., "Auto-CoT: Automatic Generation of Chain-of-Thought Reasoning"** uses self-generated rationales as demonstrations for similar inputs. The generated data by Auto-CoT incurs a quadratically scaling overhead to the final prediction. Our proposed method only incurs a linearly scaling overhead due to the nature of nearest-neighbor algorithm. Self-ICL **Zhang et al., "Self-Supervised In-Context Learning"** generated its own demonstration and their pseudo-labels and uses them as demonstrations. We disagree with Self-ICL's premise that even unlabeled data are hard to come by in realistic settings, and posit that unlabeled data are abundant and inexpensive to obtain ____$. Thus, self-generated demonstration inputs are unnecessary. Like Auto-CoT, Self-ICL's test-time compute overhead also scales quadratically. Lastly, Auto-CoT, STaR, and Self-ICL all focuses on reasoning tasks, whereas our work primarily focuses on classification tasks.


% \subsection{Cluster-Based Unsupervised Learning}
% ____ reported that a self-supervised model trained on a clustering objective resulted in representation whose clustering roughly corresponds to downstream classification categories. Considering that two of the embeddings models that we experiment with are pre-trained with clustering or similarity tasks, it is reasonable to expect such models producing nearest neighbors from the same class.

% Henry:
% [Main Difference with related work in TTS, tbe] Our approach introduces a novel dimension to test-time compute methodologies by systematically leveraging unlabeled data neighborhoods. While existing test-time compute techniques like chain-of-thought and self-consistency primarily focus on internal reasoning strategies, our method expands the computational context by incorporating external unlabeled data signals ... \\
% [Some other famous/related TTC work in LLM: Best-of-N Sampling, STaR Algorithm (Self-Taught Reasoner), Self Verification/Verifier, Search Methods/Monte Carlo Tree Search (MCTS), check more details in this blog https://cloudsecurityalliance.org/blog/2024/12/13/test-time-compute]

% The intuition behind TestNUC is that samples in close proximity within a semantic space are likely to share similar labels. By incorporating predictions on nearby unlabeled samples, the LLM can better contextualize and refine its decision-making. This approach exploits the consistency of local data structures, effectively using unlabeled examples as an auxiliary signal to boost performance and reduce the noise and uncertainty associated with isolated predictions.