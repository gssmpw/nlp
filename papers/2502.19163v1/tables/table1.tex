\begin{table*}[!th]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{@{}llcccccccccc@{}}
\toprule
& & \multicolumn{2}{c}{\textbf{Intent Detection}} & \multicolumn{2}{c}{\textbf{Topic Mining}} & \multicolumn{2}{c}{\textbf{Domain Discovery}} & \multicolumn{1}{c}{\textbf{Type}} & \multicolumn{1}{c}{\textbf{Emotion}} & \\
\cmidrule(lr){3-4} \cmidrule(lr){5-6} \cmidrule(lr){7-8} \cmidrule(lr){9-9} \cmidrule(lr){10-10}  %\cmidrule(lr){11-11}
\textbf{Model} & \textbf{Method} & \textbf{BANKING} & \textbf{CLINC} & \textbf{Reddit} & \textbf{StackEx} & \textbf{MTOP} & \textbf{CLINC(D)} & \textbf{FewEvent} & \textbf{GoEmotion} & \textbf{AVG} \\ \midrule \midrule
GPT-4o-mini & Standard Prompting & 0.652 & 0.792 & 0.534 & 0.482 & 0.896 & 0.536 & 0.630 & 0.378 & 0.613 \\
& Self-Consistency & 0.666 & 0.802 & 0.586 & 0.494 & 0.902 & 0.530 & 0.640 & 0.382 & 0.625 \\
& TestNUC & 0.712 & 0.858 & 0.614 & 0.528 & 0.936 & 0.544 & 0.674 & 0.410 & 0.660 \\
& \cellcolor{gray!18}TestNUC\textdagger & \cellcolor{gray!18}\textbf{0.764} & \cellcolor{gray!18}\textbf{0.864} & \cellcolor{gray!18}\textbf{0.646} & \cellcolor{gray!18}\textbf{0.540} & \cellcolor{gray!18}\textbf{0.948} & \cellcolor{gray!18}\textbf{0.554} & \cellcolor{gray!18}\textbf{0.680} & \cellcolor{gray!18}\textbf{0.414} & \cellcolor{gray!18}\textbf{0.676} \\ \midrule \midrule
Llama-3.1-8B & Standard Prompting & 0.572 & 0.726 & 0.502 & 0.492 & 0.892 & 0.528 & 0.530 & 0.332 & 0.572 \\
& Self-Consistency & 0.620 & 0.774 & 0.564 & 0.526 & 0.902 & 0.518 & 0.564 & 0.340 & 0.601 \\
& TestNUC & 0.694 & 0.806 & 0.618 & 0.558 & 0.934 & 0.528 & 0.596 & 0.356 & 0.636 \\
& \cellcolor{gray!18}TestNUC\textdagger & \cellcolor{gray!18}\textbf{0.724} & \cellcolor{gray!18}\textbf{0.812} & \cellcolor{gray!18}\textbf{0.646} & \cellcolor{gray!18}\textbf{0.576} & \cellcolor{gray!18}\textbf{0.940} & \cellcolor{gray!18}\textbf{0.542} & \cellcolor{gray!18}\textbf{0.614} & \cellcolor{gray!18}\textbf{0.360} & \cellcolor{gray!18}\textbf{0.652} \\ \midrule \midrule
Claude-3-Haiku & Standard Prompting & 0.680 & 0.848 & 0.486 & 0.564 & 0.892 & 0.552 & 0.594 & 0.336 & 0.619 \\
& Self-Consistency & 0.702 & 0.870 & 0.510 & 0.578 & 0.904 & 0.564 & 0.568 & 0.350 & 0.631 \\
& TestNUC & 0.762 & 0.894 & 0.596 & 0.588 & 0.940 & 0.590 & 0.620 & 0.348 & 0.667 \\
& \cellcolor{gray!18}TestNUC\textdagger & \cellcolor{gray!18}\textbf{0.804} & \cellcolor{gray!18}\textbf{0.902} & \cellcolor{gray!18}\textbf{0.612} & \cellcolor{gray!18}\textbf{0.600} & \cellcolor{gray!18}\textbf{0.946} & \cellcolor{gray!18}\textbf{0.622} & \cellcolor{gray!18}\textbf{0.660} & \cellcolor{gray!18}\textbf{0.368} & \cellcolor{gray!18}\textbf{0.689} \\ \midrule \midrule
GPT-4o & Standard Prompting & 0.746 & 0.924 & 0.712 & 0.674 & 0.962 & 0.614 & 0.682 & 0.406 & 0.715 \\
& Self-Consistency & 0.758 & 0.922 & 0.720 & 0.688 & 0.958 & 0.624 & 0.696 & 0.426 & 0.724 \\
&TestNUC & 0.804 & 0.934 & 0.744 & \textbf{0.710} & 0.974 & 0.644 & 0.692 & 0.446 & 0.744 \\
& \cellcolor{gray!18}TestNUC\textdagger & \cellcolor{gray!18}\textbf{0.824} & \cellcolor{gray!18}\textbf{0.940} & \cellcolor{gray!18}\textbf{0.750} & \cellcolor{gray!18}\textbf{0.710} & \cellcolor{gray!18}\textbf{0.978} & \cellcolor{gray!18}\textbf{0.654} & \cellcolor{gray!18}\textbf{0.708} & \cellcolor{gray!18}\textbf{0.464} & \cellcolor{gray!18}\textbf{0.754} \\
\bottomrule
\end{tabular}%
}
\caption{Accuracy comparison with Standard Prompting and Self-Consistency across four diverse LLMs. TestNUC consistently improves the inference performance on all benchmark datasets. $\dagger$ denotes that 50 neighbors are utilized.}
\label{tab:main_compare_sc}
\end{table*}