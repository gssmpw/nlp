\section{Related Work}
\label{sec:related-work}
\paragraph{Markov chain Monte Carlo (MCMC)}
Markov chain Monte Carlo methods are a classical approach for sampling from unnormalized target densities. 
The key idea is to construct a Markov chain whose stationary distribution matches the target distribution ____. 
Prominent examples include the Metropolis-Hastings algorithm ____, Gibbs sampling ____, and Langevin dynamics ____. 
By exploiting geometric structure in the target distribution, Hamiltonian Monte Carlo ____ often leads to more efficient exploration. 
To address scalability challenges in high-dimensional or large-dataset scenarios, stochastic gradient MCMC variants ____ have been introduced. 
Although these MCMC methods reduce per-step computational costs or improve mixing, they remain inherently iterative, requiring many transitions to yield high-quality samples.

\paragraph{Learning-Based Samplers}
Amortized inference shifts the computational overhead from test-time sampling to a training phase, allowing for faster inference ____. 
Approaches such as amortized MCMC____ train a neural network to mimic the distribution of samples obtained after $T$ transitions of a traditional MCMC process. 
Similarly, GFlowNets ____ learn to sequentially construct complex discrete objects, effectively learning a sampling strategy. 
While GFlowNets amortize the computational challenges of lengthy stochastic searches and mode-mixing
during training, their sampling process remains sequential, as objects are constructed step-by-step
through a series of constructive steps.

An alternative viewpoint casts the sampling problem as an optimal control task ____, where one trains a controlled stochastic differential equation to transport an initial distribution to the target via a Schr√∂dinger bridge ____. 
This perspective motivates recent efforts to use diffusion-based samplers ____. 
While such diffusion and flow-based frameworks have advanced the state of the art, they require numerical solvers operating on dense time discretizations.

\paragraph{Consistent Generative Models}
Recent work in generative modeling has explored the concept of consistency: ensuring that large transitions between observed distributions are consistent with sequences of incremental transformations. 
Consistency models ____ 
learn a direct mapping from any point in time to the terminal state. 
Progressive distillation ____ incrementally distills a trained diffusion model into a more efficient version that takes half as many until a single-step model is achieved.
Similarly, shortcut models ____ leverage progressive self-distillation during training to achieve accelerated inference without relying on a pre-trained teacher model.

These methods focus on generative modeling tasks and assume access to a dataset drawn from the target distribution.
Our work introduces the notion of consistency into the setting of sampling from unnormalized densities. 
We assume access only to an unnormalized pointwise oracle $\rho$ for the target density, without requiring any pre-collected samples.