@misc{zhang2017understandingdeeplearningrequires,
      title={Understanding deep learning requires rethinking generalization}, 
      author={Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
      year={2017},
      eprint={1611.03530},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1611.03530}, 
}

@misc{neyshabur2018understandingroleoverparametrizationgeneralization,
      title={Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks},
      author={Behnam Neyshabur and Zhiyuan Li and Srinadh Bhojanapalli and Yann LeCun and Nathan Srebro},
      year={2018},
      eprint={1805.12076},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1805.12076}, 
}

@misc{belkin2018understanddeeplearningneed,
      title={To understand deep learning we need to understand kernel learning}, 
      author={Mikhail Belkin and Siyuan Ma and Soumik Mandal},
      year={2018},
      eprint={1802.01396},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1802.01396}, 
}

@article{Belkin_2019,
   title={Reconciling modern machine-learning practice and the classical bias–variance trade-off},
   volume={116},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.1903070116},
   DOI={10.1073/pnas.1903070116},
   number={32},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
   year={2019},
   month=jul, pages={15849–15854} }


@article{Belkin_2020,
   title={Two Models of Double Descent for Weak Features},
   volume={2},
   ISSN={2577-0187},
   url={http://dx.doi.org/10.1137/20M1336072},
   DOI={10.1137/20m1336072},
   number={4},
   journal={SIAM Journal on Mathematics of Data Science},
   publisher={Society for Industrial & Applied Mathematics (SIAM)},
   author={Belkin, Mikhail and Hsu, Daniel and Xu, Ji},
   year={2020},
   month=jan, pages={1167–1180} }

@misc{hastie2020surpriseshighdimensionalridgelesssquares,
      title={Surprises in High-Dimensional Ridgeless Least Squares Interpolation}, 
      author={Trevor Hastie and Andrea Montanari and Saharon Rosset and Ryan J. Tibshirani},
      year={2020},
      eprint={1903.08560},
      archivePrefix={arXiv},
      primaryClass={math.ST},
      url={https://arxiv.org/abs/1903.08560}, 
}

@misc{cao2022benignoverfittingtwolayerconvolutional,
      title={Benign Overfitting in Two-layer Convolutional Neural Networks}, 
      author={Yuan Cao and Zixiang Chen and Mikhail Belkin and Quanquan Gu},
      year={2022},
      eprint={2202.06526},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2202.06526}, 
}

@misc{chen2021benignoverfittingadversariallyrobust,
      title={Benign Overfitting in Adversarially Robust Linear Classification}, 
      author={Jinghui Chen and Yuan Cao and Quanquan Gu},
      year={2021},
      eprint={2112.15250},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2112.15250}, 
}

@misc{kou2023benignoverfittingtwolayerrelu,
      title={Benign Overfitting for Two-layer ReLU Convolutional Neural Networks}, 
      author={Yiwen Kou and Zixiang Chen and Yuanzhou Chen and Quanquan Gu},
      year={2023},
      eprint={2303.04145},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.04145}, 
}

@misc{han2024featurelearningdiffusionmodels,
      title={On the Feature Learning in Diffusion Models}, 
      author={Andi Han and Wei Huang and Yuan Cao and Difan Zou},
      year={2024},
      eprint={2412.01021},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2412.01021}, 
}

@misc{shang2024initializationmattersbenignoverfitting,
      title={Initialization Matters: On the Benign Overfitting of Two-Layer ReLU CNN with Fully Trainable Layers}, 
      author={Shuning Shang and Xuran Meng and Yuan Cao and Difan Zou},
      year={2024},
      eprint={2410.19139},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.19139}, 
}

@misc{jiang2024unveilbenignoverfittingtransformer,
      title={Unveil Benign Overfitting for Transformer in Vision: Training Dynamics, Convergence, and Generalization}, 
      author={Jiarui Jiang and Wei Huang and Miao Zhang and Taiji Suzuki and Liqiang Nie},
      year={2024},
      eprint={2409.19345},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.19345}, 
}

@misc{jelassi2022visiontransformersprovablylearn,
      title={Vision Transformers provably learn spatial structure}, 
      author={Samy Jelassi and Michael E. Sander and Yuanzhi Li},
      year={2022},
      eprint={2210.09221},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.09221}, 
}


@misc{tarzanagh2024transformerssupportvectormachines,
      title={Transformers as Support Vector Machines}, 
      author={Davoud Ataee Tarzanagh and Yingcong Li and Christos Thrampoulidis and Samet Oymak},
      year={2024},
      eprint={2308.16898},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2308.16898}, 
}

@misc{tian2023scansnapunderstandingtraining,
      title={Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer}, 
      author={Yuandong Tian and Yiping Wang and Beidi Chen and Simon Du},
      year={2023},
      eprint={2305.16380},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.16380}, 
}

@misc{jin2024provableincontextlearningmixture,
      title={Provable In-context Learning for Mixture of Linear Regressions using Transformers}, 
      author={Yanhao Jin and Krishnakumar Balasubramanian and Lifeng Lai},
      year={2024},
      eprint={2410.14183},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2410.14183}, 
}

@misc{huang2023incontextconvergencetransformers,
      title={In-Context Convergence of Transformers}, 
      author={Yu Huang and Yuan Cheng and Yingbin Liang},
      year={2023},
      eprint={2310.05249},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.05249}, 
}

@misc{li2024nonlineartransformerslearngeneralize,
      title={How Do Nonlinear Transformers Learn and Generalize in In-Context Learning?}, 
      author={Hongkang Li and Meng Wang and Songtao Lu and Xiaodong Cui and Pin-Yu Chen},
      year={2024},
      eprint={2402.15607},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.15607}, 
}

@misc{frei2024trainedtransformerclassifiersgeneralize,
      title={Trained Transformer Classifiers Generalize and Exhibit Benign Overfitting In-Context}, 
      author={Spencer Frei and Gal Vardi},
      year={2024},
      eprint={2410.01774},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.01774}, 
}

@misc{magen2024benignoverfittingsingleheadattention,
      title={Benign Overfitting in Single-Head Attention}, 
      author={Roey Magen and Shuning Shang and Zhiwei Xu and Spencer Frei and Wei Hu and Gal Vardi},
      year={2024},
      eprint={2410.07746},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.07746}, 
}

@misc{li2024optimizationgeneralizationtwolayertransformers,
      title={On the Optimization and Generalization of Two-layer Transformers with Sign Gradient Descent}, 
      author={Bingrui Li and Wei Huang and Andi Han and Zhanpeng Zhou and Taiji Suzuki and Jun Zhu and Jianfei Chen},
      year={2024},
      eprint={2410.04870},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.04870}, 
}


@article{Bartlett_2020,
   title={Benign overfitting in linear regression},
   volume={117},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.1907378117},
   DOI={10.1073/pnas.1907378117},
   number={48},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Bartlett, Peter L. and Long, Philip M. and Lugosi, Gábor and Tsigler, Alexander},
   year={2020},
   month=apr, pages={30063–30070} }

@misc{zou2021benignoverfittingconstantstepsizesgd,
      title={Benign Overfitting of Constant-Stepsize SGD for Linear Regression}, 
      author={Difan Zou and Jingfeng Wu and Vladimir Braverman and Quanquan Gu and Sham M. Kakade},
      year={2021},
      eprint={2103.12692},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.12692}, 
}

@article{Liao_2021,
   title={A random matrix analysis of random Fourier features: beyond the Gaussian kernel, a precise phase transition, and the corresponding double descent*},
   volume={2021},
   ISSN={1742-5468},
   url={http://dx.doi.org/10.1088/1742-5468/ac3a77},
   DOI={10.1088/1742-5468/ac3a77},
   number={12},
   journal={Journal of Statistical Mechanics: Theory and Experiment},
   publisher={IOP Publishing},
   author={Liao, Zhenyu and Couillet, Romain and Mahoney, Michael W},
   year={2021},
   month=dec, pages={124006} }


@misc{adlam2021randommatrixperspectivemixtures,
      title={A Random Matrix Perspective on Mixtures of Nonlinearities for Deep Learning}, 
      author={Ben Adlam and Jake Levinson and Jeffrey Pennington},
      year={2021},
      eprint={1912.00827},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1912.00827}, 
}

@misc{mallinar2024benigntemperedcatastrophictaxonomy,
      title={Benign, Tempered, or Catastrophic: A Taxonomy of Overfitting}, 
      author={Neil Mallinar and James B. Simon and Amirhesam Abedsoltan and Parthe Pandit and Mikhail Belkin and Preetum Nakkiran},
      year={2024},
      eprint={2207.06569},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2207.06569}, 
}


@article{JMLR:v25:22-1389,
  author  = {Xuran Meng and Jianfeng Yao and Yuan Cao},
  title   = {Multiple Descent in the Multiple Random Feature Model},
  journal = {Journal of Machine Learning Research},
  year    = {2024},
  volume  = {25},
  number  = {44},
  pages   = {1--49},
  url     = {http://jmlr.org/papers/v25/22-1389.html}
}

@misc{tsigler2022benignoverfittingridgeregression,
      title={Benign overfitting in ridge regression}, 
      author={A. Tsigler and P. L. Bartlett},
      year={2022},
      eprint={2009.14286},
      archivePrefix={arXiv},
      primaryClass={math.ST},
      url={https://arxiv.org/abs/2009.14286}, 
}

@misc{mou2017generalizationboundssgldnonconvex,
      title={Generalization Bounds of SGLD for Non-convex Learning: Two Theoretical Viewpoints}, 
      author={Wenlong Mou and Liwei Wang and Xiyu Zhai and Kai Zheng},
      year={2017},
      eprint={1707.05947},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1707.05947}, 
}

@misc{chen2018stabilityconvergencetradeoffiterative,
      title={Stability and Convergence Trade-off of Iterative Optimization Algorithms}, 
      author={Yuansi Chen and Chi Jin and Bin Yu},
      year={2018},
      eprint={1804.01619},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1804.01619}, 
}

@misc{hardt2016trainfastergeneralizebetter,
      title={Train faster, generalize better: Stability of stochastic gradient descent}, 
      author={Moritz Hardt and Benjamin Recht and Yoram Singer},
      year={2016},
      eprint={1509.01240},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1509.01240}, 
}

@misc{bartlett2017spectrallynormalizedmarginboundsneural,
      title={Spectrally-normalized margin bounds for neural networks}, 
      author={Peter Bartlett and Dylan J. Foster and Matus Telgarsky},
      year={2017},
      eprint={1706.08498},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1706.08498}, 
}