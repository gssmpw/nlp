\section{Related Work}
\textbf{The traditional theory of benign overfitting}   
The traditional theory of benign overfitting has obtained a series of research results aimed at understanding this phenomenon in linear, kernel, and random feature models. ____ set risk bounds for the minimum norm interpolator, stressing overparameterization. ____ provided an excess risk bound for constant stepsize SGD. ____ extended the analysis to random Fourier feature regression with fixed ratio sample size, data dimension, and number of random features. ____ incorporated bias terms into the model. ____ extended findings to ridge regression and determined optimal regularization. ____ found tempered overfitting in certain kernels. ____  extended this to the “multiple random feature model” and discovered multiple descent. 

\textbf{Benign overfitting in transformer}   Benign overfitting in transformers has attracted significant attention in the research field. Some studies utilize the feature learning framework to explore this phenomenon within transformer architectures. ____ delved into symbolic gradient descent in two layer transformers, but the research was only concerned with harmful overfitting. ____ explored the training process of visual transformers. Their work uncovered the training dynamics and clarified the difference between benign and harmful overfitting.  Additionally, there has been new theoretical research on benign overfitting.____ have focused their studies on the training dynamics of transformers. Analyzing these dynamics helps to accurately describe the optimization process, providing valuable insights into how the model converges and generalizes. ____ carried out a theoretical analysis of a Transformer for MoR context learning.____  explored the training of single layer transformers. ____  examined transformers with nonlinear self-attention. ____ investigated the performance of linear Transformers in random linear classification tasks and found that benign overfitting can occur under certain conditions.