\subsection{Population Health and Survival Analysis}

\paragraph{Subtopic:} 
How can we balance the complexity of ML-powered survival models with the need for interpretability in public health decision-making? Are some of the hybrid approaches helpful in retaining a level of transparency needed for public health decision-making?  What are the key challenges in validating ML survival models, such as random survival forests and deep learning approaches, on real-world administrative datasets? Would techniques such as nested cross-validation, simulation and external validation be helpful in understanding the performance of these approaches in real-world scenarios such as noisy, sparse and imbalanced data?  How can we design ML survival models that account for systemic biases in administrative data to ensure fairness in public health applications? Would incorporating socioeconomic and environmental data help adjust for health inequities and improve prediction accuracy for underrepresented groups? What practical steps are needed to overcome barriers to the adoption of ML methods in public health, such as computational intensity, lack of interpretability, and limited ML expertise among public health researchers? How can we encourage collaborations between data scientists and public health experts to co-develop models that align with public health goals?

\paragraph{Chairs: }
\textit{Mohammad Ehsanul Karim, Md. Belal Hossain, and Hanna A. Frank}

\paragraph{Background:}

Population health aims to understand and improve health outcomes across diverse groups by examining the complex relationship among biological, behavioral, environmental, and social determinants. In the context of survival outcomes, the focus extends beyond whether an event occurs and includes the timing of the event. Survival analysis, a statistical framework for modeling time-to-event data, is essential in public health research, enabling studies on disease progression, treatment effectiveness, and mortality. Among survival methods, the Cox proportional hazards model is widely used but has limitations. Its reliance on strong assumptions such as proportional hazards and correct model-specification often restricts its ability to capture the true relationships between predictors and outcomes.

In the modern era, nationally representative survey data and population-based administrative data have emerged as valuable resources for public health research. Nationally representative survey data, such as from National Health and Nutrition Examination Survey \citep{nhanes2024}, Canadian Community Health Survey \citep{cchs2024}, Korea National Health and Nutrition Examination Survey \citep{oh2021korea}, are publicly available and can be a valuable resource for identifying trends, associations, and building predictive models. On the other hand, health administrative data are derived from healthcare systems. These data cover entire populations or large cohorts, offering unique insights into health trends, disparities, and outcomes on a society-wide level. They provide longitudinal data spanning years or decades, facilitating comprehensive survival analyses and causal inferences over time. Unlike clinical trial data, survey data and health administrative data reflect real-world healthcare interactions and often include socioeconomic, demographic, and geographic variables critical for analyzing health disparities. The wide availability and cost-effectiveness of these data make it practical foundations for public health policies and resource allocation, such as identifying high-risk populations and addressing healthcare inequities.

Despite their potential, both survey and administrative datasets come with many challenges.  Survey data are generally serial cross-sectional in nature, some under- or over-sampling occurs, and samples may be dependent. Survey data generally include strata, clusters, and sampling weights to connect the sample to the population. Machine learning (ML) methods are mostly incapable of incorporating the strata, clusters, and weight variables. The health administrative datasets, on the other hand, include vast numbers of variables, such as diagnosis codes, prescriptions, and healthcare utilization, which complicate analyses; key variables are often incomplete, and imputation is difficult without robust parametric models; important predictors such as BMI or smoking status are often absent, leading to poor predictions or residual confounding for causal inference problems. Mismeasurement, inconsistencies, and coding errors (e.g., in ICD classifications) can undermine analysis; administrative data often includes time-dependent covariate and exposure information, which requires advanced methods to handle correctly; administrative data may reflect historical inequities in healthcare access and outcomes, which may not be addressed by statistical or ML methods.

ML methods have the potential to address some of these challenges and transform survival analysis. ML-powered survival models excel at handling high-dimensional data, capturing non-linear relationships, and mitigating residual confounding by incorporating additional information from the wealth of variables in the survey and administrative datasets. These methods also enable the development of actionable tools, such as risk calculators, to support public health decision-making and policy planning.

However, ML methods for survival analysis remain underutilized in public health. Key approaches, such as random survival forests, regularized survival models (e.g., Cox LASSO), and deep learning methods (e.g., DeepSurv, DeepHit) \citep{ishwaran2008random,katzman2018deepsurv,simon2011regularization,lee2018deephit}, show promise but face significant barriers to adoption. ML methods often lack the transparency of traditional models like Cox, which limits their acceptance among public health practitioners. Many ML methods are resource-intensive, particularly for large-scale datasets. These models are sensitive to hyperparameters, requiring additional diagnostics to ensure validity. Many ML methods are validated on curated datasets, and their performance on real-world data often noisy, sparse, and unbalanced – remains less established. ML models trained in survey or administrative data risk perpetuating systemic biases, and fairness metrics tailored to survival analysis are still underdeveloped. Additionally, not all ML approaches are equally suited for survival analysis. For instance, random survival forests are well-suited for capturing complex interactions while being moderately interpretable, but they can be computationally intensive for very large datasets. Deep learning methods, on the other hand, excel at modeling complex non-linear relationships and handling time-varying covariates or competing risks but often face challenges with interpretability and require substantial computational resources and large datasets for effective training.

To fully leverage the potential of ML-powered survival tools for public health, more research is needed to overcome these barriers. Advancing these tools will enable researchers to harness survey and administrative data effectively, improving health outcomes and equity on a population scale. By addressing challenges in implementation, validation, and fairness, ML-powered survival models can become indispensable in tackling the most pressing public health issues of our time.

\paragraph{Discussion:}
Participants discussed several solutions on the subtopics above.

\subsubsection{Balancing the complexity of ML-powered survival analysis with interpretability in public health.}
Data sources commonly used in public health research include survey data and health administrative data. Population surveys often use strategies like oversampling to create a sample including a large enough sample of underrepresented populations to enable subpopulation analyses. They also may use clustering strategies to reduce interview costs. To connect the sample back to the population, weights as well as strata and clustering information must be incorporated into the analysis. With ML methods like random forests and deep learning, weights are easily incorporated, but the inclusion of strata and cluster information is not as straightforward. 
Health administrative data, on the other hand, includes all those who interact with the healthcare system. In building clinical prediction models, it is generally recommended to restrict ourselves to the use of predictors that are helpful for the implementation and interpretation of the model. This often means relying on variables that are already established/known in the literature to be associated with the clinical outcomes of interest. However, health administrative data incorporates a vast amount of information, so restricting to those convenient for clinical settings ignores a large amount of useful information. For the creation of prediction models for use at a population level, such as for government use, it is worth considering what information from health administrative data we may be able to use to allow room for new discovery and the trade-off between the incorporation of these variables and the model’s interpretability.

Suggested possibilities for improving the interpretability of ML models in the public health context include the use of additive models. The development of software packages to facilitate this in survival analysis, including methods for feature selection, is currently in progress. The use of hybrid approaches, such as using investigator-specified predictors to create the base model and then trying to improve on this model’s predictive performance by including other variables from health administrative or claims data, was also suggested. Feature selection ML methods such as survival LASSO are also suggested since these methods can provide interpretable models with better accuracy. The possibilities of overfitting and underfitting of the ML-based models were also discussed. Participants emphasized the importance of balancing performance with interpretability, particularly in clinical contexts.

\subsubsection{Validation of ML survival models.}  
The thorough evaluation of survival models, using discrimination and calibration measures, was emphasized by participants as a vital step in ML-powered survival analysis. For discrimination, there was some debate as to which measure makes the most sense in the survival analysis context. Time-dependent area under the curve (AUC) is often used \citep{kamarudin2017time}, but this includes performance at very high false positive rates that may not truly be relevant in the application of a model. 

One of the difficult issues in survival modeling that came up in discussion was how to decide how and when subjects should be censored in the analysis. With longitudinal data, there are many situations in which people are lost to follow-up, whether because they are receiving care at different healthcare centers or moving between provinces/states or out of the country. How people should be censored is an important consideration in the design of the study, and with health administrative data it is usually impossible to guarantee we know what happens to every individual at every time point. Participants suggested the use of data sources like the Veterans Affairs (VA) data, in which generally everyone who receives care through VA receives all their care through VA. This way some of the issues with people receiving health care from different sources can be mitigated.

\subsubsection{Systemic bias in public health data sources and impact on ML methods.}  
One of the issues with using ML with health administrative data is that the ML methods can perpetuate systemic biases that are inherent in the dataset. For example, disparities in access to healthcare will be perpetuated by ML algorithm since those in marginalized populations will have less visits in the health administrative data. One proposed method to handle this is the creation of synthetic data, in which one creates a dataset that “oversamples” marginalized groups in order to create a dataset that more accurately represents the true population. However, such solutions may have their own issues (e.g., underestimation of variance, non-representativeness), so there is still a possibility that the data is biased.

\subsubsection{Practical steps for overcoming barriers to the adoption of ML methods in public health.} 
To address the barriers to the adoption of ML methods in public health, participants stressed the importance of group discussions and interdisciplinary collaborations. Limited domain knowledge prevents the wider use of ML in public health. Therefore, multidisciplinary discussions and the building of trust with ML and artificial intelligence programs are key steps to enabling the wider use of ML in public health. Additionally, the further development of comprehensive software infrastructure would make implementing these methods in various research areas easier.
