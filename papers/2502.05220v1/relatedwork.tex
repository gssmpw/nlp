\section{Related Work}
\label{section:related-work}
This section briefly reviews the related work in three research domains: 1) LLM application in IoT and embedded systems; 2) Smaller-scale LLM cohorts application; and 3) The application of SFT and RLHF.

The application of large language models (LLMs) in the Internet of Things (IoT) and embedded systems has gained significant attention in recent years. Qiu et al.\cite{qiu2022edgeformer} proposed EdgeFormer, an edge-based transformer model for on-device natural language processing tasks in IoT environments. Their work demonstrated the feasibility of deploying LLMs on resource-constrained edge devices. Similarly, Zhang et al.\cite{zhang2022deflating} introduced a deflating technique to compress pre-trained LLMs for efficient deployment on embedded systems while maintaining performance.

Several works have explored the use of smaller-scale LLM cohorts for specific tasks. Su et al.\cite{su2022globalpipeline} proposed GlobalPipeline, a framework that decomposes large LLMs into smaller experts and orchestrates their collaboration. Their approach showed improved efficiency and scalability compared to monolithic LLMs. Likewise, Dai et al.\cite{dai2022knowledge} introduced a knowledge distillation method to train smaller LLMs from larger ones, enabling efficient deployment on edge devices.

Fine-tuning pre-trained LLMs has proven effective for adapting them to specific tasks and domains. Supervised fine-tuning (SFT) has been widely used to fine-tune LLMs on labeled data~\cite{gao2021making,lee2022deduplicating}. Reinforcement learning from human feedback (RLHF) has also been explored as a fine-tuning approach, where human feedback is used to refine the LLM's behavior~\cite{stiennon2020learning,ouyang2022training}.