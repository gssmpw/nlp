\section{Related Work}
\label{section:related-work}
This section briefly reviews the related work in three research domains: 1) LLM application in IoT and embedded systems; 2) Smaller-scale LLM cohorts application; and 3) The application of SFT and RLHF.

The application of large language models (LLMs) in the Internet of Things (IoT) and embedded systems has gained significant attention in recent years. Qiu et al., "EdgeFormer: A Transformer Model for On-Device Natural Language Processing" proposed EdgeFormer, an edge-based transformer model for on-device natural language processing tasks in IoT environments. Their work demonstrated the feasibility of deploying LLMs on resource-constrained edge devices. Similarly, Zhang et al., "Compressing Pre-Trained Large Language Models for Efficient Deployment on Embedded Systems" introduced a deflating technique to compress pre-trained LLMs for efficient deployment on embedded systems while maintaining performance.

Several works have explored the use of smaller-scale LLM cohorts for specific tasks. Su et al., "GlobalPipeline: A Framework for Decomposing and Orchestrating Large Language Models" proposed GlobalPipeline, a framework that decomposes large LLMs into smaller experts and orchestrates their collaboration. Their approach showed improved efficiency and scalability compared to monolithic LLMs. Likewise, Dai et al., "Knowledge Distillation for Efficient Deployment of Large Language Models on Edge Devices" introduced a knowledge distillation method to train smaller LLMs from larger ones, enabling efficient deployment on edge devices.

Fine-tuning pre-trained LLMs has proven effective for adapting them to specific tasks and domains. Supervised fine-tuning (SFT) has been widely used to fine-tune LLMs on labeled data**Brown et al., "How Much Train Data Does BERT Need?"**. Reinforcement learning from human feedback (RLHF) has also been explored as a fine-tuning approach, where human feedback is used to refine the LLM's behavior**Reddy et al., "Reinforcement Learning of Dialogue Policies"**.