\subsection{Analytics-specific Knowledge Testing}
\label{sec:analytics_mmlu}

First, we examine how well \modelname absorbs knowledge in the analytics field. Inspired by the commonly-used benchmark, Massive Multitask Language Understanding (MMLU)~\citep{hendrycks2020mmlu,wang2024mmlupro}, we curate a new dataset, ~\mmlu, to measure the model's capabilities in language understanding and reasoning in the analytics domain.

\para{New Datasets}
The \mmlu dataset consists of thousands of multiple-choice questions (MCQs) across three critical areas in analytics: database management (DB), data analysis (DA), and machine learning (ML). This results in three distinct datasets: \texttt{MCQ-DB}, \texttt{MCQ-DA}, and \texttt{MCQ-ML}. The questions feature complex queries that require models to exhibit deep expertise and advanced problem-solving abilities to achieve high accuracy. We source some of the questions from textbooks and generated additional questions and answers using \claudetf. All answers are manually reviewed and revised by three annotators to ensure quality. Table~\ref{tbl:all_eval_dataset} summarizes the data statistics. We use the \textit{accuracy} score to evaluate performance.

\para{Task Prompts}
The adopted prompt consists of a question, followed by four answer choices, and the required answer format. The task is to select the correct answer from the given choices. Here, we show an input-output example from \texttt{MCQ-DA}.
\begin{tcolorbox}[left=2pt, right=0pt, top=1pt, bottom=1pt]
\begin{verbatim}
# Input: 
You are an expert in data analytics. Answer the following MCQ. 
Question: Which of the following indicates no relationship in terms
of correlation?
Choices:
A: Cor(X, Y) = 1     B: Cor(X, Y) = 0
C: Cor(X, Y) = 2     D: All of the mentioned
Return your answer symbol (e.g., A, B, C, D) starting with "Answer:",
and give your explanation.

# Output: 
Answer: [B]
Evidence: Correlation is a statistical method that measures the
strength and direction of the relationship between pairs of variables.
\end{verbatim}
\end{tcolorbox}


\para{Main Results and Analysis} From Table~\ref{tbl:exp-main}, we note that \modelname, equipped with 12 billion parameters, consistently outperforms other open-source LLMs across all three categories of \mmlu, including \texttt{Mistral-7B}, \texttt{Codestral-22B}, \texttt{Mistral-Small-22B} and \texttt{Mixtral-8x7B}. Additionally, it surpasses \texttt{GPT-3.5-Turbo} but falls 1.5 and 4.7\% short of \texttt{GPT-4o-mini} and \texttt{GPT-4o}, respectively, in absolute accuracy. Compared to the base Mistral-NeMo model, \modelname achieves consistent performance improvements, with the largest relative gains of 12.2\% on MCQ-DA, 8.5\% on MCD-DB, and 2.2\% on MCQ-ML. This demonstrates the effectiveness of fine-tuning an LLM on diverse analytics-related QA tasks as curated in Section~\ref{sec:chapter1}.


We further conduct case studies to understand why \modelname can outperform the base model. Smaller models like Mistral-NeMo often need more specialized knowledge to answer specific knowledge-intensive questions. For example, Mistral-NeMo gives an incorrect answer and explanation for the example below. However, after being trained with the Chapter 1 data, \modelname gained more knowledge about E-R diagrams, enabling it to provide correct answers.


\begin{tcolorbox}[left=1pt, right=0pt, top=1pt, bottom=1pt]
\begin{verbatim}
Question: In the E-R diagram, generalization is represented by ____
A: Ellipse     B: Dashed ellipse
C: Rectangle   D: Triangle

# Predictions from Mistral-NeMo:
Answer: [A] 
Explanation: In an Entity-Relationship (E-R) diagram, generalization 
is represented by an ellipse (A). 

# Predictions from CoddLLM: 
Answer: [D]
Explanation: Generalization in E-R diagrams shows a superclass-
subclass relationship between entity types. It is depicted using an 
isosceles triangle pointing upwards, connecting the superclass 
(more general entity) to its subclasses (more specific entities).
\end{verbatim}
\end{tcolorbox}
