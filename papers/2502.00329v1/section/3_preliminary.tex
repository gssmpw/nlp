\section{Preliminaries}
\noindent \textbf{Autoregressive Language Modeling}.
Language provides a versatile way to represent tasks, data, inputs, and outputs, all as a sequence of tokens. Autoregressive language modeling is the basis for LLMs like GPT~\citep{gpt2,gpt3}. This approach predicts the probability of a sequence of words or tokens, with each prediction conditioned on the previous elements in the sequence. 

Formally, given a language token sequence $\vx = (x_1, x_2, \cdots, x_n)$, autoregressive language modeling decomposes the joint distribution of the sequence as the product of a series of conditional probabilities: $p(\vx) = \prod_{i=1}^n p(x_i|x_1, ..., x_{i-1})$,
where $p(x_1|x_0) = p(x_1)$ is the marginal probability. With the factorized distribution and a parameterized model (e.g., Transformers~\cite{vaswani2017attention}), the parameterized distribution $p_{\theta}(x)$ can be optimized via minimizing the negative log-likelihood loss:
\begin{equation}\label{eqn:loss-ar}
    \gL(\theta) = -\log p_{\theta}(\vx) = - \sum\limits_{i=1}^n \log p(x_i|x_{1},\cdots, x_{i-1}).
\end{equation}

\vspace{3pt}
\noindent \textbf{Query-based Data Analytic Tasks}. This paper focuses on query-based data analytic tasks, represented as $\{task, data, query, answer\}$. Given a task description, the data to be analyzed, and a natural language query, the goal is to predict the answer, i,e, $p(answer|task,$ $data, query)$. For example, we can format the input text for a table selection task as: "$\texttt{find tables},$ $\texttt{table schema},~$ $\texttt{who was the}$ $\texttt{only athlete...}$". Then, the model is expected to return the table name(s) that can answer the question, e.g., "$\texttt{<tables>Final\_1},$ $\texttt{Athletics\_1</tables>}$".

\vspace{3pt}

\noindent \textbf{Supervised Instruction Tuning} is a critical fine-tuning process employed to enhance the performance of LLMs on specific tasks by leveraging labeled datasets. Supervised instruction tuning focuses on adapting the model to follow explicit instructions and produce task-specific outputs. This process involves training the model on input-output pairs, where the inputs are typically natural language instructions or prompts, and the outputs are the desired responses or completions. The loss function of supervised instruction tuning is computed only on the "output" tokens to optimize the ability to execute specific tasks and understand instructions.