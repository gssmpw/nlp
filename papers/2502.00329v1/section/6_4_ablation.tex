\subsection{Ablation Studies}

In this section, we conduct ablation studies to assess the impact of different training data formats and chapter selections. The accuracy scores of different model variants are presented in Table~\ref{tbl:ablation}. Note that \modelname was first trained on the instruction-response pairs of Chapter 1 data, followed by training on Chapter 2 and 3 datasets.

\subsubsection{Effects of the training on plain text documents v.s. Synthetic instruction-response pairs} To examine the impact of different data formats, we applied domain-adaptive \emph{continual pre-training}~\citep{ke2023continual} on plain text data and supervised instruction tuning on the instructed data version. Both models were built on an instructed model (Mistral-Nemo-Instruct) and trained using the cross-entropy loss for the next token prediction. However, during the continual pretraining process, the loss is calculated across all tokens to learn general language features and structures. For supervised instruction tuning, the loss is calculated only on the output (response) tokens, focusing on specific task objectives.

By comparing the accuracy scores of \texttt{Chapter1{\footnotesize -PlainText}} and \texttt{Chapter1{\footnotesize -Instructed}}, both trained exclusively on Chapter 1 data but with different data formats, we note that continual pre-training on plain text often degrades performance when applied to an instructed base model. On three \mmlu datasets, \texttt{Chapter1{\footnotesize -Instructed}} achieves scores of 0.681, 0.732, and 0.714, whereas \texttt{Chapter1{\footnotesize -PlainText}} scores lower at 0.652, 0.686, and 0.635. Additionally, on certain \datadiscovery and \texttosql datasets, the \texttt{Chapter1{\footnotesize -PlainText}} model completely fails, highlighting that training on domain text without clear task guidance can weaken the model's instruction-following capability. In contrast, \texttt{Chapter1{\footnotesize -Instructed}} matches or surpasses the base model in most datasets, suggesting that instruction-aware data more effectively aligns the model with the domain-specific queries and answers. 
% 
Moving from \texttt{Chapter1{\footnotesize -PlainText}+2+3} to \modelname (\texttt{Chapter1{\footnotesize - Instructed}+2+3}) jumps \wikipage  by over 27 points (from 0.279 to 0.558) and boosts \mmlu and \texttosql tasks by several points.

\subsubsection{Effects of the Chapter 1 Analytics-specific Knowledge Corpus} 
Comparing the accuracy scores of the base model and  \texttt{Chapter1{\footnotesize -Ins- tructed}}, we observe that introducing Chapter 1 data leads to notable gains on domain-specific tasks while maintaining comparable performance on \mmlu. It improves accuracy on \datadiscovery and \texttosql, even without task-specific examples, demonstrating the effectiveness of instruction-aware domain adaptation. 
Comparing \texttt{Chapter2+3} and \modelname, we conclude that incorporating large-scale instructed instruction-response pairs from diverse tasks (Chapter 1) enhances overall model performance across a broad range of tasks, as evidenced by improvements in \mmlu. Furthermore, the instructed examples do not degrade the model’s performance on \datadiscovery and \texttosql, demonstrating its ability to generalize effectively without compromising domain-specific capabilities.


\subsubsection{Effects of the Chapter 2 Table and Text Alignment Data}
From Table~\ref{tbl:ablation}, by comparing \texttt{Chapter1{\footnotesize -Instructed}+3} and \modelname that includes all the three chapters data, chapter 2's table and text alignment data is crucial for tasks involving structured information. The highest surges in performance on table-centric discovery and \texttosql tasks occur when the model is supplemented with this alignment data. For instance, accuracy on \wikipage increases notably from 0.462 to 0.558 when Chapter 2 is added, showing how specialized alignment data about interpreting tables and text is instrumental for the model’s ability to handle more complex data discovery and retrieval tasks.
%
