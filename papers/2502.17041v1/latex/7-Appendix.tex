\section{Data Statistics}
\label{app:stat}
%%
\paragraph{Legal Compliance Data}
To better illustrate our dataset's details, we present the following table summarizing the privacy compliance cases. Table~\ref{tab:data_cases} presents a quantitative comparison of different regulations and labels within the dataset. Table~\ref{tab:data_word_count} compares sentence lengths across different regulations and labels within the privacy compliance dataset.



\begin{table}[h]
\small
        \centering
        \renewcommand{\arraystretch}{1.2}
        \setlength{\tabcolsep}{2pt}  
        \begin{tabular}{l|c|c|c|c|c}
            \toprule
            \textbf{Category} & \textbf{HIPAA} & \textbf{GDPR} & \textbf{AI Act} & \textbf{ACLU} & \textbf{Total} \\
            \midrule
            Permitted & 86 & 675 & 1,029 & 11 & 1,801 \\
            Prohibited & 19 & 2,462 & 971 & 58 & 3,510 \\
            Not Applicable & 106 & - & 1,000 & - & 1,106 \\
            % \midrule
            % \textbf{Total} & \textbf{211} & \textbf{3,137} & \textbf{3,000} & \textbf{69} & \textbf{6,417} \\
            \midrule
            Total & 211 & 3,137 & 3,000 & 69 & 6,417 \\
            \bottomrule
        \end{tabular}
        \vspace{-0.1in}
        \caption{Evaluation data for privacy compliance.}
        \label{tab:data_cases}
        \vspace{-0.15in}
\end{table}


\paragraph{Multiple-Choice Questions}
For the multiple-choice questions dataset mentioned in Section~\ref{sec: data processing}, we use the BERT\_base~\cite{bert} model to embed words. Additionally, We provide additional details in Table~\ref{tab:data_mc} showing the number of questions. The problem distribution remains consistent across different difficulty levels, as the only variation lies in the strategy for selecting options.


\begin{table}[h]
\small
    \centering
    \setlength{\tabcolsep}{2pt}  
    \begin{tabular}{l|c|c|c|c}
        \toprule
        \textbf{Category} & \textbf{HIPAA} & \textbf{GDPR} & \textbf{AI Act} & \textbf{Total} \\
        \midrule
        Easy Questions  & 86 & 675 & 1,029  & 49,280 \\
        Medium Questions  & 86 & 675 & 1,029  & 49,280 \\
        Hard Questions  & 86 & 675 & 1,029  & 49,280 \\
        \midrule
        Total & 49,280 & 49,280 & 49,280  & 147,840 \\
        \bottomrule
    \end{tabular}
    \vspace{-0.1in}
    \caption{Multiple-choice questions statistics.}
    \label{tab:data_mc}
    \vspace{-0.15in}
\end{table}

\paragraph{Auxiliary Knowledge Bases}
For the parsed regulation dataset we produced in Section~\ref{sec: Auxiliary Knowledge Bases}, Table~\ref{tab:data_laws} summarizes the regulation dataset size and composition. 
And Table~\ref{tab:data_graphs} lists the size of the knowledge graphs we build.

\begin{table}[h]
\small
    \centering
    \begin{tabular}{l|c|c|c}
        \toprule
        \textbf{Category} & \textbf{HIPAA} & \textbf{GDPR} & \textbf{AI Act} \\
        \midrule
        Nodes & 591 & 679 & 842 \\
        Positive Norms & 230 & 146 & 365 \\
        Negative Norms & 31 & 30 & 65 \\
        \bottomrule
    \end{tabular}
    \vspace{-0.1in}
    \caption{Statistics of parsed regulations.}  \label{tab:data_laws}
    \vspace{-0.15in}
\end{table}

\begin{table}[h]
\small
    \centering
    \begin{tabular}{l|c c}
        \toprule
        \textbf{Knowledge Graph} & \textbf{Node \#} & \textbf{Edge \#} \\
        \midrule
        Role KG ($\mathcal{R}$) & 8,993 & 91,876  \\
        Attribute KG ($\mathcal{A}$) & 7,875 & 176,999  \\
        \bottomrule
    \end{tabular}
    \vspace{-0.1in}
    \caption{Statistics of annotated hierarchical graphs.}    \label{tab:data_graphs}
    \vspace{-0.15in}
\end{table}


\begin{table*}[t]
\small
    \centering
    \begin{tabular}{l|c|c|c|c|c}
        \toprule
        \textbf{Category} & \textbf{HIPAA} & \textbf{GDPR} & \textbf{AI Act} & \textbf{ACLU} & \textbf{Weighted average} \\
        \midrule
        Permitted & 312.91 & 66.41 & 133.03 & 340.70 & 118.03 \\
        Prohibited & 307.35 & 56.31 & 129.51 & 319.76 & 82.33 \\
        Not Applicable & 360.56 & - & 122.17 & - & 145.21 \\
        \midrule
        Weighted Average & 336.21 & 58.48 & 128.17 & 323.10 & 103.20 \\
        \bottomrule
    \end{tabular}
    \vspace{-0.1in}
    \caption{Privacy compliance data word statistics}
\label{tab:data_word_count}
\vspace{-0.1in}
\end{table*}



\section{Experimental Details}


\paragraph{Generation Details}
For open-source models, we generate the models' responses with the recommended configurations in their model cards.
For close-source models, we use their official APIs to obtain the responses with temperature = 0.2.
For each generation among all models, we set the max\_new\_token = 512 with max\_retry = 3.



\paragraph{Prompt Templates}

We follow the Privacy Checklist's prompt templates~\cite{li-2024-privacychecklist} with modifications to build our prompt templates.
Our full prompts used for \textbf{DP}, \textbf{CoT} and Multiple-choice questions are listed in Table~\ref{tabs:non_rag_prompt}.
For the \textbf{RAG} method, we detailedly illustrate its whole workflow in Table~\ref{tabs:prompt_BM25}.

\paragraph{Licenses}
For the HIPAA domain, we use data provided by GoldCoin's official GitHub implementation~\cite{fan2024goldcoin} under the Apache-2.0 license.
For other domains, we double-check the licenses and copyright policies of our collected data from web pages. 
These data are under the CC BY-NC-SA 4.0 license and the U.S. copyright laws, and we are able to use them for non-commercial and research purposes.
In terms of used models, we have agreed with all their specific licenses to use their models for research purposes.
For example, we follow the Llama Community License Agreement to use the Llama-3.1-8B-Instruct to run our experiments.



\paragraph{Computational Resources} During our experiment, we use 2 NVIDIA H800 to run our codes for open-source models, and it takes 6-week GPU hours to complete all experiments.
In terms of API cost, our overall cost for calling APIs is approximately \$1,000 USD.

%\paragraph{Annotation Costs}
\input{latex/app-table-ai-act-case}
\input{latex/app-tab-f1}


\section{More Evaluation Results}


\subsection{F1 Scores of Legal Compliance Task}

In addition to reporting only the accuracies for the legal compliance task, we further report the micro-averaged F1 scores in Table~\ref{tab:compliance_f1}.
The micro-F1 scores share similar results as Table~\ref{tab:privacy_result}.





\subsection{Cases Studies on the EU AI Act}
\label{app: case}
In the absence of real court cases under the EU AI Act, we utilized GPT-4o to synthesize study cases based on the outputs from its official compliance checker. 
We enumerated all possible choices from the compliance checker and created essential question-answer pairs for case generation, which were then provided to GPT-4o to generate realistic court case scenarios. 
The norm type of a case is determined by the question-answer chain, which can be categorized into three classes: permitted, prohibited, and not applicable.

Specifically, prohibited cases involve dangerous systems, such as those that exploit vulnerabilities, conduct biometric categorization, or predict political outcomes. Not applicable cases fall outside the scope of the EU AI Act, for instance, an AI system is not deployed in Europe. Permitted cases comply with the EU AI Act.

Furthermore, we leveraged GPT-4o to annotate the CI parameters. An example of the synthesized cases is provided in Table \ref{tabs:synthesized_ai_act_case}. This example demonstrates that the GPT-4o generation process generally adheres to the information from the question-answer chain and annotates the CI parameters accurately. Besides, in the synthesized scenario, the entities exhibit realistic names and behaviors. However, there is still room for improvement. The synthesized cases lack comprehensiveness, and the narrative development is not coherent. We plan to enhance the quality of the synthesized cases by introducing additional constraints and guidance for future work.



\input{latex/app-tab-dp_prompts}
\input{latex/app-tab-rag_prompt}