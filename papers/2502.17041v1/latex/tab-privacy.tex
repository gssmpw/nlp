\begin{table*}[t]
    \centering
    \small
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{l|ccc|ccc|ccc | cc} 
        \toprule
        \multirow{2}{*}{} 
        & \multicolumn{3}{c|}{\textbf{EU AI Act}} & \multicolumn{3}{c|}{\textbf{GDPR}} & \multicolumn{3}{c|}{\textbf{HIPAA}} & \multicolumn{2}{c}{\textbf{ACLU}}\\ 
        %\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
        \textbf{Model}  & DP & CoT & RAG & DP & CoT & RAG & DP & CoT & RAG & DP & CoT \\ 
        \midrule
        Mistral-7B-Instruct & 49.83 & 43.50 & 45.56 & 72.29 & 68.02 & 43.38 & 45.79 & 60.74 & 64.95 & 44.92 & \textbf{72.46}\\
        Qwen-2.5-7B-Instruct & 49.90 & 65.30 & \textbf{55.83} & 89.00 & 88.81 & 82.43 & 68.69 & 72.43 & 71.49 & 50.72 & 52.17 \\
        Llama-3.1-8B-Instruct & 61.30 & 59.40 & 53.50 & 85.30 & \textbf{90.27} & \textbf{76.60} & 77.57 & 85.51 & \textbf{88.31}  & 66.17 & 66.67\\
        GPT-4o-mini & 73.76 & 66.60 & - & \textbf{92.03} & 65.69 & - & 80.84 & 67.75 & - & \textbf{69.56} & 31.88\\
        QwQ-32B & \textbf{78.22} & \textbf{75.30} & - & 80.45 & 90.08 & - & 70.09 & \textbf{88.31} & - &  55.07& 55.07 \\

        \multirow{1}{*}{Deepseek R1 (671B)} & 72.90 & 60.67 & - & 90.66 & 47.88 & - & \textbf{89.25} & 81.77 & -& 65.21 & 59.42 \\
         
    %     \midrule
    % \multirow{1}{*}{Average} & 64.31 & 61.79 & xx.xx & 84.95 & 75.12 & xx.xx & 72.03 & 76.08 & xx.xx & 59.33 & 56.76 \\
        \bottomrule
    \end{tabular}
    \vspace{-0.1in}
    \caption{Accuracy Evaluation results of the legal compliance task. All results are reported in \%.}
    \label{tab:privacy_result}
    \vspace{-0.1in}
\end{table*}








\begin{table*}[t]
    \centering
    \small
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{l|ccc|ccc|ccc}
        \toprule
        \multirow{2}{*}{} 
         & \multicolumn{3}{c|}{\textbf{Permit}} & \multicolumn{3}{c|}{\textbf{Prohibit}} & \multicolumn{3}{c}{\textbf{Not Applicable}} \\
        %\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
        \textbf{Model\&Method} & Precision & Recall & F1 & Precision & Recall & F1 & Precision & Recall & F1 \\
        \midrule
        Qwen2.5-7B-Instruct-DP & 36.17  &  55.30  &  43.74 & 68.83  &  87.54  &  77.06 & 40.62   & 7.80  &  13.09 \\
        Qwen2.5-7B-Instruct-CoT & 52.93    &51.80    &52.36 &68.06  &  85.58   & 75.82  & 77.37   & 59.50    &67.27  \\
        Qwen2.5-7B-Instruct-RAG & 49.63  &  51.99  &  50.78  &  70.45  &  54.99  &  61.77 & 73.69  &  60.50  &  66.45  \\
        Mistral-7B-Instruct-DP & 83.33  &  0.49  &  0.97 & 73.50  & 50.57  &  59.91 & 42.97  &  99.90  &  60.09  \\
        Mistral-7B-Instruct-CoT & 52.83  &  2.72  &  5.18  & 80.23   &  28.84   & 42.42  &  40.74   &  99.70   &  57.85  \\
        Mistral-7B-Instruct-RAG & 46.55  &  7.87  &  13.47 &  81.95  &  29.45  &  43.33  &  42.86   & 100.00  &  60.01  \\
        
        % \midrule
        % Average & 53.74 & 28.03 & 27.08 & 73.50 & 56.33 & 59.72 & 53.38 & 71.23 & 54.46 \\
        \bottomrule
    \end{tabular}
    \vspace{-0.1in}
    \caption{The detailed investigation of Qwen2.5-7B-Instruct and Mistral-7B-Instruct models performance over 3 classes on the AI Act cases. All results are reported in \%.}
    \label{tab:compliance_detail}
    \vspace{-0.2in}
\end{table*}