\section{Conclusion}

In this paper, we introduce \name,  a scalable and contextualized benchmark for evaluating privacy and safety compliance.
Unlike prior benchmarks, which are often limited to either toy-scale real samples or synthetic data confined to fixed domains, our annotated benchmark includes a significantly broader range of real cases related to diverse legal regulations across multiple domains.
Moreover, we further expand the auxiliary knowledge bases of hierarchical roles and attributes to append far more entities and relations.
Our results show that CI parameters and applicable regulations effectively assist LLMs in determining legal compliance.
However, directly applying common Chain-of-Thought reasoning and retrieval augmented generation methods may not consistently help improve the performance.
For future works, we call for more tailored implementations of the judgment modules and enhanced in-context learning for our legal compliance task to raise LLMs' privacy and safety awareness.



% \clearpage
% \section*{Limitations}

% For the overall design of our \name, we only consider legal statutes as the privacy norms and omit people's privacy expectations and other informational norms.
% We agree with \citet{shvartzshnaider2025position} that legal statutes cannot capture all privacy norms, especially for cultural norms.
% That is, even though the given context complies with legal regulations,  privacy violations may still occur according to ethical and moral norms.
% However, ethical and moral norms that go beyond legal regulations are inherently implicit and subjective. Achieving 100\% agreement on these norms across regions, cultures, and personal preferences is highly challenging.
% Our goal in evaluating legal norms is to establish them as the minimum baseline for privacy protection.
 


% In terms of experiments, some of our evaluated LLMs under 8 billion parameters only have context lengths of no more than 8,000.
% To ensure a fair comparison, we exclude experimental results involving few-shot demonstrations.
% In addition, our prompt templates are fixed throughout the evaluation.
% Due to the high computational cost, we do not assess the LLMs' sensitivity to variations in prompts.






% \section*{Ethical Considerations}
% We declare that all authors of this paper acknowledge the \emph{ACM Code of Ethics} and honor the ACL code of conduct.
% Our work goes beyond PII pattern matching and considers the contextual privacy evaluations grounded on established informational norms of existing regulations.
% We believe that our benchmark will become a new paradigm for evaluating privacy as well as safety compliance.


% \paragraph{Data Collection} 
% During the data collection process, we parse legal documents and published cases from the official website following their granted fair uses.
% To enhance our data quality, three of the authors and two invited law school students work together to rectify potential parsing errors.


% \paragraph{Potential Risks} 
% In terms of data privacy issues, our collected real cases are from existing case law databases where data anonymization has already been conducted.
% Hence, there is no privacy risk regarding our collected court cases.
% However, when using existing LLMs for these cases, there is a risk of incorrect judgments.
% As a result, users should not rely on LLMs for professional or critical judgments, as their suggestions may be inaccurate or unreliable.
