


\section{PrivaCI-Bench Construction}
\label{sec: data}

In this section, we systematically discuss how our \name is built
from the current privacy and safety regulations from data collection to data processing.
%%% aux legal KBs are missing

%%% data collection
\subsection{Data Collection}
For our data collection, we primarily focus on the legal compliance task to evaluate LLMs' privacy and safety awareness.
To ensure that our data are context-aware and realistic, we gather our data mainly from real court cases, privacy policies, and official questionnaires.
All our collected evaluation samples are categorized into three labels: \textit{permit}, \textit{prohibit} and \textit{not applicable}.
%in terms of a given legal document.

\subsubsection{Court Cases}

Court cases are invaluable data sources for evaluating LLMs' privacy awareness.
Most cases are highly contextualized and have clean labels with professional judgments.

We collect court cases related to privacy for various regulations across multiple domains.
For the medical domain, We use real court cases of the Health Insurance Portability and Accountability Act of 1996 (HIPAA) from GoldCoin~\cite{fan2024goldcoin} as well as auxiliary knowledge bases from Privacy Checklist~\cite{li-2024-privacychecklist}.
For the general domain, we implement web crawlers to collect cases about the EU GDPR from various online open-source databases and GDPR enforcement trackers.
Moreover, we also collect cases in the Privacy \& Technology domain recorded by the American Civil Liberties Union (ACLU).\footnote{https://www.aclu.org/court-cases?issue=privacy-technology}
%%% other sources of data? ACLU?
%Besides 


\subsubsection{Privacy Policies}
% opp 115 app 350
In addition to real court cases, we also consider the existing privacy policies of giant technology companies that provide worldwide services.
These policies are carefully crafted to meet various regional privacy standards and can be viewed as permitted information transmission under the server-client context.
In addition, several studies have linked the policies with corresponding regulations to justify their legal compliance.
We collect policies specified by OPP-115~\cite{wilson-etal-2016-creation} and APP-350~\cite{Zimmeck2019MAPSSP} as permitted samples.
Additionally, we filter out policies in OPP-115 that are not linked with supported GDPR regulations.


\subsubsection{Synthetic Data from the EU AI Act}
\label{sec: ai act}
The EU AI Act is the first legal framework for AI and has just been in force since August 2024.
Currently, there is no available case or other source of data about the latest regulation.
Instead, we construct synthetic cases from the EU AI Act Compliance Checker.\footnote{https://artificialintelligenceact.eu/assessment/eu-ai-act-compliance-checker/}
By answering a set of consecutive multiple-choice questions, the Compliance Checker will determine whether the given context is permitted, prohibited, or not applicable to the EU AI Act.
We manually enumerate all the possible combinations for the consecutive questions and ask GPT-4o to generate synthetic vignettes that fit into the context of the chain of selected options.

%%% GDPR AI Act SYN DATA???


%%% KB construction process
\subsubsection{Legal Documents}

Except for cases of ACLU, our collected data mainly centered on the HIPAA, GDPR, and EU AI Act.
We implement crawlers to parse these regulations' original content from their official websites.
For ACLU's cases, we omit to parse their corresponding regulations due to the complexity and variability of associated legal documents.
%%% aux KGs


\subsection{Data Processing}
After collecting the evaluation data and legal documents, we further process them to facilitate and probe the reasoning process with the help of contextual integrity theory.
Our overall data processing workflow is shown in Figure~\ref{fig:model}.

\subsubsection{Legal Document Processing}
\label{sec: legal doc process}
We mainly follow the privacy checklist's processing pipeline~\cite{li-2024-privacychecklist} to first structuralize and annotate the HIPAA, GDPR, and AI Act regulations, separately.
As all three documents are well structured with hierarchical identifiers, we can intuitively construct the document trees indexed by these identifiers, as shown in \ding{192} of Figure~\ref{fig:model}.
For each document tree, its leaves refer to the detailed and non-separable specifications of this regulation, which may permit or prohibit certain contextual information flows.
As demonstrated in \ding{193} of Figure~\ref{fig:model}, we ask GPT-4o to parse the whole specification content to extract its key CI parameters.
For simplicity, we decompose the transmission principle into ``Purpose'' and ``Consent''.



\subsubsection{Evaluation Data Processing}
\label{sec: data processing}

\paragraph{Atomic Information Flow Extraction} 
For our collected court cases, privacy policies, and synthetic vignettes, some samples are rather complex and may include multiple information flows.
Inspired by tricks used for fact checking~\cite{tang-2024-minicheck, zhang-gao-2023-towards}, we first ask GPT-4o to identify all the information flows inside the given sample and decompose them into atomic information flows.
Then, for each identified information flow, we further instruct GPT-4o to parse the corresponding CI parameters similar to Section~\ref{sec: legal doc process}.




%\paragraph{Atomic Information Flow Extraction}


\paragraph{Multiple Choice Questions for CI Probing}

To probe the evaluated models' context understanding and awareness, we reuse the annotated CI parameters of evaluated samples to create a diverse set of multiple-choice questions (MCQs). Each MCQ consists of a question that queries a contextual element for a given scenario and four choices, one correct choice and three misleading choices derived solely from Section~\ref{sec: Auxiliary Knowledge Bases}. For our MCQ design, we control the difficulty by adjusting the selection strategy for misleading choices. We propose three difficulty levels of questions for each regulation: (1) Easy: Misleading choices are sampled from a subset that is most semantically different from the correct answer. For implementation, we rank all alternatives in the knowledge base based on their embeddings' cosine similarity to the correct answer, filtering out meaningless words and sampling options from the lowest-ranked section. (2) Medium: Misleading choices are randomly selected from all possible values. (3) Hard: Similar to the easy level, but misleading choices are selected from a subset containing the most semantically relevant options to the correct answer, making them harder to distinguish. We choose candidates with the highest cosine similarity to the correct answer as other options. Ultimately, a total of 49,280 MCQs are proposed for each difficulty level.


\subsection{Auxiliary Knowledge Bases}
\label{sec: Auxiliary Knowledge Bases}
Although the exact prompt is used to extract CI parameters for legal regulations and evaluation data, it is impossible to calibrate parameters between regulations and collected cases due to the domain gap.
CI parameters of regulations are formal with introduced terminologies, whereas CI parameters from evaluation samples are more specific and context-driven. 
For example, compare \ding{193} with \ding{195} in Figure~\ref{fig:model}, the sender in \ding{195} represents the concrete name of a company while the sender in \ding{193} is a general terminology defined by GDPR.

To align specific instances with introduced terminologies, we create hierarchical graphs of social roles $\mathcal{R}$ and personal attributes $\mathcal{A}$.
As shown in \ding{194} of Figure~\ref{fig:model}, we initialize the role KG $\mathcal{R}$ and attribute KG $\mathcal{A}$ with proper entities shown in parsed regulations.
Then, we use WordNet to search for hypernyms and hyponyms of collected entities in $\mathcal{R}$ and $\mathcal{A}$ for hierarchical relations.
Subsequently, we use GPT-4o to evaluate whether the parsed jargon can be viewed as a role, an attribute, or neither, based on its definition.
If it is a valid role or attribute, we append it to the corresponding graph.
Afterward, we prompt GPT-4o to find more hypernyms and hyponyms for existing entities to increase the scale and flexibility.
Lastly, we select entity pairs from $\mathcal{R}$ and $\mathcal{A}$ and request  GPT-4o to infer and complete any missing relations.



%For the introduced new terminologies from regulations, we 






\subsection{Benchmark Statistics}

%%% collected court cases
\textbf{Evaluation Data} In summary, we collect 6,351 evaluation samples for the privacy compliance task.
For HIPAA, we reuse 214 real court cases from GoldCoin~\cite{fan2024goldcoin}, including 86 permitted cases, 19 prohibited cases, and 106 not-applicable cases.
For GDPR, we gather 2,462 prohibited real court cases within the EU.
In terms of permitted cases, we collect 675 privacy policies and generate synthetic vignettes as permitted samples.
For AI Act, we enumerate 3,000 possible chains from the official compliance checker to generate 1,029 permitted samples, 971 prohibited samples and 1,000 not-applicable cases.
For cases of other laws, we collect 70 cases related to privacy and technology from the ACLU.
On top of that, we create 147,840 multiple-choice questions, including 49,280 easy, 49,280 medium, and 49,280 hard questions.

%%% may draw a table for detailed stats
\noindent\textbf{Auxiliary Knowledge Bases}
%%% collected legal documents, # leaf nodes?
For parsed regulations, we reuse the parsed HIPAA regulations annotated by Privacy Checklist~\cite{li-2024-privacychecklist}, which covers 591 nodes, 230 positive norms and 31 negative norms.
Our annotated GDPR tree includes 679 nodes, 146 positive norms and 30 negative norms, while our annotated AI Act tree covers 842 nodes, 365 positive norms and 65 negative norms.
Regarding the annotated hierarchical graphs, 
our role KG $\mathcal{R}$ has 8,993 roles and 91,876 edges
while our attribute KG $\mathcal{A}$ has 7,875  attributes and 176,999 edges.
Notably, our collected $\mathcal{R}$ and $\mathcal{A}$ are 20 times larger than the Privacy Checklist's knowledge bases~\cite{li-2024-privacychecklist}.

%For more detailed statistics, please refer to Appendix~\ref{app:stat}.

%%% manual verifications???