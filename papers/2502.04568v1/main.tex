
\documentclass[dvipsnames,format=sigconf, nonacm]{acmart}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

\usepackage{booktabs} %

\usepackage{tikz}
\usetikzlibrary{arrows,calc}
\usepackage[table]{colortbl}%

\usepackage{subcaption}
\usepackage{qtree}
\usepackage{xspace}
\usepackage{multirow}
\usepackage{listings}   
\usepackage{enumitem}
\usepackage{float}
\usepackage{setspace}





\begin{document}
\title{Learning Semantics-aware Search Operators for Genetic Programming}





\author{Piotr Wyrwi≈Ñski}
\orcid{0000-0001-9796-5025}
\affiliation{\institution{Poznan University of Technology}
 \city{Poznan}
 \country{Poland}
}
\authornote{Corresponding author: piotr.wyrwinski@cs.put.poznan.pl}

\author{Krzysztof Krawiec}
\orcid{0000-0001-5439-3231}
\affiliation{%
 \institution{Poznan University of Technology}
 \city{Poznan}
 \country{Poland}
}

\renewcommand{\shortauthors}{}

\newcommand{\mnamens}{NEON} %
\newcommand{\mname}{\mnamens\xspace}


\begin{abstract}
Fitness landscapes in test-based program synthesis are known to be extremely rugged, with even minimal modifications of programs often leading to fundamental changes in their behavior and, consequently, fitness values. Relying on fitness as the only guidance in iterative search algorithms like genetic programming is thus unnecessarily limiting, especially when combined with purely syntactic search operators that are agnostic about their impact on program behavior. In this study, we propose a semantics-aware search operator that steers the search towards candidate programs that are valuable not only actually (high fitness) but also only potentially, i.e. are likely to be turned into high-quality solutions even if their current fitness is low. The key component of the method is a graph neural network that learns to model the interactions between program instructions and processed data, and produces a saliency map over graph nodes that represents possible search decisions. When applied to a suite of symbolic regression benchmarks, the proposed method outperforms conventional tree-based genetic programming and the ablated variant of the method.  

\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010147.10010148</concept_id>
       <concept_desc>Computing methodologies~Symbolic and algebraic manipulation</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010147.10010257</concept_id>
       <concept_desc>Computing methodologies~Machine learning</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Symbolic and algebraic manipulation}
\ccsdesc[500]{Computing methodologies~Machine learning}

\ccsdesc[500]{Computing methodologies~Machine learning approaches}

\keywords{genetic programming, symbolic regression, graph neural networks}

\maketitle
\input{body}

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography} 

\end{document}
