\subsection{Related Works}
%
\paragraph{Robustness to approximate best responses} 
Two works that are closely related to ours are~\citep{gan2024robust,yang2024computational}, which consider \emph{robustness} notions analogous to ours, though in different settings.
%
Specifically,~\citet{gan2024robust} initiate this research line, by studying th problem of computing robust leader's commitments in \emph{Stackelberg games} where the follower plays an approximate best response.
%
% introduce the concept of $\delta$-best response in Stackelberg games.
%
They show that it is \textsf{NP}-hard to approximate an optimal robust commitment of the leader and, in accordance to this hardness result, they provide a quasi-polynomial-time approximation scheme (QPTAS).
%
\citet{yang2024computational} extend the study initiated by~\citet{gan2024robust} to \emph{Bayesian persuasion}, with the goal of computing robust signaling schemes under approximate best responses of the receiver.
%
Similarly to~\citet{gan2024robust}, they show that computing an approximately-optimal robust signaling scheme is \textsf{NP}-hard and provide a QPTAS.
%
In sharp contrast, we show that, in hidden-action principal-agent problems, an optimal robust contract can be computed efficiently.
% More recently, \cite{lin2024generalizedprincipalagentproblemlearning} proved that the problem of computing optimal commitment in a generalized principal-agent problem, where the principal interacts with a learning agent over multiple rounds, can be cast into a problem with an approximately best-responding agent.
%
\paragraph{Contract design} 
Contract theory has been extensively studied in economics~\cite{holmstrom1991multitask}. 
%
However, the interest in its computational aspects is more recent. 
%
\citep{dutting2019simple} analyzes linear contracts, proving approximation bounds. \citep{castiglioni2022bayesian,guruganesh2021contracts} show that computing optimal contracts in Bayesian settings is intractable. 
%
\citep{alon2023bayesian} studies Bayesian linear contracts, proving near-optimality under sufficient uncertainty. 
%
Other works explore combinatorial principal-agent problems~\citep{babaioff2006combinatorial,babaioff2009free} and multi-agent extensions of hidden-action problems~\citep{castiglioni2023multi,duetting2024multiagent}.


\paragraph{Other forms of robustness in contract design} 
%
Our work is also related to other research lines addressing different concepts of \emph{robustness} in contract design.
%
%to the line of research on robust contract design, which incorporates real-world complexities into the standard model.
%
For instance, \citet{carroll2015robustness} studies settings where the principal only knows a superset of agents' actions, while~\citet{dutting2019simple} introduce a different notion of uncertainty in which the principal has partial knowledge of the distributions over outcomes associated with agent's actions.
%
Both these works show that linear contracts are a sufficient class of contracts to determine the \emph{min-max robust} optimal contract.
%
Notice that these two frameworks differ from ours, as within our framework, when the robustness parameter $\delta \in (0,1)$ is arbitrarily small, the problem becomes very close to the classical version of the hidden-action principal-agent problem, in which it is known that linear contracts are \emph{not} generally optimal (see, \emph{e.g.},~\citep{dutting2019simple}).
%
Recently, \citet{bernasconi2024regret} study settings where uncertainty lies in the costs of agent's actions.
%
In this framework, the principal only knows a set containing the true cost vectors, and computing an optimal min-max robust contract is \textnormal{APX}-hard.
%
\paragraph{Learning in principal-agent problems} 
%
Our work is also related to online learning problems in hidden-action principal-agent problems.
%
\citet{Zhu2023Sample} study general hidden-action principal-agent problem instances in which the principal faces multiple agent's types.
%
They show that it is possible to design an algorithm that achieves a regret bound of the order of $ \widetilde{\mathcal{O}}(\sqrt{m} \cdot T^{1 - 1/(2m+1)})$ when the principal selects contracts from the hypercube $[0,1]^m$, where $m$ is the number of outcomes.
%
In our work, we show that it is possible to design an algorithm achieving similar regret guarantees even when the different agent's types select approximate best responses.
%
Our algorithm presents some advantages compared to the one proposed by~\citet{Zhu2023Sample}. 
%
Specifically, our approach employs a simpler discretization of the hypercube---used during the execution of the algorithm---compared to~\cite{Zhu2023Sample}, and it does \emph{not} require prior knowledge of the principal's rewards.
%They also show that their regret bound can be improved to $\widetilde {\mathcal{O}}( T^{1 - 1/(m+2)})$ by making additional structural assumptions on the problem instances, including the \emph{first-order stochastic dominance} (FOSD) condition.
%
Furthermore,~\citet{Zhu2023Sample} provide an (almost-matching) lower bound of $\Omega(T^{1-1/(m+2)})$, which holds even with a single agent's type.
%
Some recent works have introduced additional hypothesis to overcome this negative result (see, \emph{e.g.},~\cite{bacchiocchilearning,chen2024bounded}).