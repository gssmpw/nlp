\section{Related Works}
%
\paragraph{Robustness to approximate best responses} 
Two works that are closely related to ours are____, which consider \emph{robustness} notions analogous to ours, though in different settings.
%
Specifically,____ initiate this research line, by studying th problem of computing robust leader's commitments in \emph{Stackelberg games} where the follower plays an approximate best response.
%
% introduce the concept of $\delta$-best response in Stackelberg games.
%
They show that it is \textsf{NP}-hard to approximate an optimal robust commitment of the leader and, in accordance to this hardness result, they provide a quasi-polynomial-time approximation scheme (QPTAS).
%
____ extend the study initiated by____ to \emph{Bayesian persuasion}, with the goal of computing robust signaling schemes under approximate best responses of the receiver.
%
Similarly to____, they show that computing an approximately-optimal robust signaling scheme is \textsf{NP}-hard and provide a QPTAS.
%
In sharp contrast, we show that, in hidden-action principal-agent problems, an optimal robust contract can be computed efficiently.
% More recently, ____ proved that the problem of computing optimal commitment in a generalized principal-agent problem, where the principal interacts with a learning agent over multiple rounds, can be cast into a problem with an approximately best-responding agent.
%
\paragraph{Contract design} 
Contract theory has been extensively studied in economics____. 
%
However, the interest in its computational aspects is more recent. 
%
____ analyzes linear contracts, proving approximation bounds. ____ show that computing optimal contracts in Bayesian settings is intractable. 
%
____ studies Bayesian linear contracts, proving near-optimality under sufficient uncertainty. 
%
Other works explore combinatorial principal-agent problems____ and multi-agent extensions of hidden-action problems____.


\paragraph{Other forms of robustness in contract design} 
%
Our work is also related to other research lines addressing different concepts of \emph{robustness} in contract design.
%
%to the line of research on robust contract design, which incorporates real-world complexities into the standard model.
%
For instance, ____ studies settings where the principal only knows a superset of agents' actions, while____ introduce a different notion of uncertainty in which the principal has partial knowledge of the distributions over outcomes associated with agent's actions.
%
Both these works show that linear contracts are a sufficient class of contracts to determine the \emph{min-max robust} optimal contract.
%
Notice that these two frameworks differ from ours, as within our framework, when the robustness parameter $\delta \in (0,1)$ is arbitrarily small, the problem becomes very close to the classical version of the hidden-action principal-agent problem, in which it is known that linear contracts are \emph{not} generally optimal (see, \emph{e.g.},____).
%
Recently, ____ study settings where uncertainty lies in the costs of agent's actions.
%
In this framework, the principal only knows a set containing the true cost vectors, and computing an optimal min-max robust contract is \textnormal{APX}-hard.
%
\paragraph{Learning in principal-agent problems} 
%
Our work is also related to online learning problems in hidden-action principal-agent problems.
%
____ study general hidden-action principal-agent problem instances in which the principal faces multiple agent's types.
%
They show that it is possible to design an algorithm that achieves a regret bound of the order of $ \widetilde{\mathcal{O}}(\sqrt{m} \cdot T^{1 - 1/(2m+1)})$ when the principal selects contracts from the hypercube $[0,1]^m$, where $m$ is the number of outcomes.
%
In our work, we show that it is possible to design an algorithm achieving similar regret guarantees even when the different agent's types select approximate best responses.
%
Our algorithm presents some advantages compared to the one proposed by____. 
%
Specifically, our approach employs a simpler discretization of the hypercube---used during the execution of the algorithm---compared to____, and it does \emph{not} require prior knowledge of the principal's rewards.
%They also show that their regret bound can be improved to $\widetilde {\mathcal{O}}( T^{1 - 1/(m+2)})$ by making additional structural assumptions on the problem instances, including the \emph{first-order stochastic dominance} (FOSD) condition.
%
Furthermore,____ provide an (almost-matching) lower bound of $\Omega(T^{1-1/(m+2)})$, which holds even with a single agent's type.
%
Some recent works have introduced additional hypothesis to overcome this negative result (see, \emph{e.g.},____).