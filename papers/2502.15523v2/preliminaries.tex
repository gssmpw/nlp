\section{Preliminaries}\label{sec:preliminaries}

In this section, we first introduce the classical hidden-action principal-agent problems (Section~\ref{sec:prelim_model_classical}), and then the variation studied in this paper, in which the agent plays an approximate best response (Section~\ref{sec:prelim_model_robust}).




\subsection{Hidden-Action Principal-Agent Problems}\label{sec:prelim_model_classical}

An instance of \emph{hidden-action principal-agent problem} is characterized by a tuple $\left(\mathcal{A},\Omega,F,r,c\right)$, where $\mathcal{A}$ is a finite set of $n \coloneqq |\mathcal{A}|$ actions available to the agent, $\Omega$ is a finite set of $m \coloneqq |\Omega|$ possible outcomes, $F \in [0,1]^{m \times n}$ is a matrix representing the effects of agent's action, $r \in [0,1]^m$ is a reward vector for the principal, and $c \in [0,1]^n$ is a vector of agent's costs.
%
Each agent's action $a \in \mathcal{A}$ determines a probability distribution over outcomes, encoded by a column $F_a \in \Delta_{\Omega}$ of the matrix $F$, and it results in a cost for the agent, encoded by a component $ c_a \in [0, 1]$ of vector $c$.\footnote{We denote by $\Delta_X$ the set of all probability distributions over the set $X$.
	%
	Given $n \in \mathbb{N}_{>0}$, we write $[n]\coloneqq \{1,\dots, n\}$.}
%
% $F_a \in \Delta_{\Omega}$ over outcomes, and it results in a cost $ c_a \in [0, 1]$ for the agent.\footnote{Given a finite set $X$, we denote by $\Delta_X$ the set of all the probability distributions over the elements of $X$.
	%
	% Let $n \in \mathbb{N}_{>0}$ and $a,b \in \mathbb{R}^{n}$, we denote with $a\cdot b = \sum_{i=1}^{n} a_i b_i$.
	%
	% Furthermore, we denote with $[n]\coloneqq\{1,\dots,n\}$.
	% }
%
We denote by $F_{a,\omega} \in [0,1]$ the probability with which action $a$ results in outcome $\omega \in \Omega$, as prescribed by $F_a$.
%
Thus, it must be the case that $\sum_{\omega \in \Omega}F_{a,\omega}=1$ for all $a \in \mathcal{A}$.
%
Each outcome $\omega \in \Omega$ is associated with a reward for the principal, encoded by a component $r_\omega \in [0,1]$ of the vector $r$.
%
Thus, whenever the agent selects an action $a \in \mathcal{A}$, the principal's expected
reward can be computed as $R_a\coloneqq F_{a}\cdot r$.\footnote{We denote by 
	% $x\cdot y \coloneqq \sum_{i=1}^{d} x_i y_i$
	$x\cdot y$ the dot product of two vectors $x,y \in \mathbb{R}^d$.}

%\paragraph{Commitment to a Contract}
The principal commits to an outcome-dependent payment scheme called \emph{contract}, which is a vector $p \in \mathbb{R}^{m}_{+}$ defining a payment $p_\omega \geq 0$ from the principal to the agent for every outcome $\omega \in \Omega$.\footnote{As customary in contract theory~\citep{carroll2015robustness}, we assume that the agent has \emph{limited liability}, meaning that the payments can only be from the principal to the agent, and \emph{not viceversa}.}
%
%
Given a contract $p \in \mathbb{R}^{m}_{+}$, the agent plays a \emph{best-response} action that is: {(i)} \emph{incentive compatible} (IC), which means that it maximizes their expected utility; and {(ii)} \emph{individually rational} (IR), meaning that it has non-negative expected utility.
%
We assume w.l.o.g. that there always exists at least one \emph{opt-out} action $a \in \mathcal{A}$ with null cost, \emph{i.e.}, $c_a = 0$, and for which the principal's expected reward is equal to zero, \emph{i.e.}, $ F_{a} \cdot  r = 0$.
%
Since the agent's utility is at least zero when playing the \emph{opt-out} action, any IC action is also IR, allowing us to focus on incentive compatibility~only.

%
Whenever the principal commits to a contract $p \in \mathbb{R}^{m}_{+}$ and the agent responds by playing an action $a \in \mathcal{A}$,
the agent's and the principal's expected utilities are, respectively,
\begin{align*}
	u^\sfA(p,a)\coloneqq F_{a} \cdot p - c_a, 
	\;\text{ and }\;
	u^\sfP(p,a)\coloneqq F_{a} \cdot (r-p).
\end{align*}
%where the first term is the expected payment from the principal to the agent when selecting action $a$.
%
%
The set $A(p) \subseteq \mathcal{A}$ of agent's best responses in a contract $p \in \mathbb{R}^{m}_{+}$ is defined as follows:
%
\begin{equation*}%\label{eq:best_response}
	A(p) \coloneqq \arg\max_{a \in \mathcal{A}} \left \{ F_a \cdot p - c_a \right\}.
\end{equation*}
%
In classical (non-robust) hidden-action principal-agent problems, the agent breaks ties in favor of the principal when having multiple best responses available (see, \emph{e.g.}, \citep{dutting2019simple}).
%
We denote by $a(p) \in A(p)$ the action played by the agent in a given contract $p \in \mathbb{R}^{m}_{+}$.
%
This is an action $a \in A(p)$ that maximizes the principal's utility $F_{a} \cdot \left( r - p \right)$.
%
Formally, $a(p) \in \argmax_{a \in A(p)} F_{a} \cdot \left( r - p \right) $.
%
% In classical hidden-action principal-agent problem,
%
Then, the goal of the principal is to design a contract $p \in \mathbb{R}^{m}_{+}$ that maximizes their expected utility $u^\sfP(p,a(p))$.
%
We say that a contract $p^\star \in\mathbb{R}^{m}_{+}$ is a (non-robust) \emph{optimal} contract if it holds $p^\star \in \arg\max_{p \in \mathbb{R}^{m}_{+}} u^{\textnormal{P}}(p,a(p))$.
%
In the following, we define the principal's utility in an optimal (non-robust) contract as $\textnormal{OPT} := \max_{p \in \mathbb{R}^{m}_{+}} u^{\textnormal{P}}(p, a(p))$, while we let the value of the social welfare be $\textnormal{SW} := \max_{a \in \mathcal{A}} \left\{ F_a \cdot r - c_a \right\}$.
%
%Moreover, given an additive approximation error $\rho > 0$, we say that $p$ is \emph{$\rho$-optimal} whenever $u(p) \geq \mathsf{OPT} -\rho$.



\subsection{Robust Contracts and Approximate Best Responses}\label{sec:prelim_model_robust}

In this paper, we study a variation of the classical hidden-action principal-agent problem, where the agent plays an action that is an \emph{approximate} best response.
%
Given $\delta \in (0,1)$, we define the set $A^\delta(p) \subseteq {A}$ of agent's $\delta$-\emph{best responses} in a given contract $p \in \mathbb{R}^{m}_{+}$ as follows:
%
\begin{equation*}%\label{eq:best_response}
	A^{\delta}(p) \hspace{-.5mm} \coloneqq \hspace{-.5mm} \left \{ a \in \mathcal{A} \mid F_{a} \hspace{-.5mm}\cdot\hspace{-.5mm} p - c_a \hspace{-.5mm}>\hspace{-.5mm} \max_{a' \in \mathcal{A}} \left\{ F_{a'}\hspace{-.5mm} \cdot\hspace{-.5mm} p - c_{a'} \right\}\hspace{-.5mm} - \hspace{-.5mm}\delta \right\}.
\end{equation*}
%
% Let us observe that a similar definition of {approximate} best response has been employed in similar settings, namely Stackelberg games~\cite{gan2024robust} and Bayesian persuasion~\cite{yang2024computational}.
%
We adopt an adversarial robust approach, in the sense that, whenever the principal commits to a contract $p\in\mathbb{R}^{m}_{+}$, the agent selects a $\delta$-best response that minimizes principal's expected utility, namely an action $a^\delta(p) \in 	A^{\delta}(p)$ such that $a^\delta(p) \in \arg\min_{a \in A^\delta(p)}F_{a}\cdot (r-p)$.
%
We refer to the utility of a $\delta$-\emph{robust} contract $p$ as $u^\sfP(p,a^\delta(p))$.

Given $\delta \in (0,1)$, the principal's goal is to design an \emph{optimal} $\delta$-robust contract $p^\star \in \Rset$, which is formally defined as:
%
\begin{equation}\label{eq:delta_opt_def}
	p^\star  \in \argmax_{p \in \Rset} \min_{a \in A^\delta(p)} u^\sfP(p,a) = \argmax_{p \in \Rset} \Psi(p),
\end{equation}
%
where $\Psi(p) \coloneqq \min_{a \in A^\delta(p)} u^\sfP(p, a)$ denotes the principal's expected utility in a $\delta$-robust contract $p\in \Rset$.
%yields for the principal
%
% \bac{TO DEFINE: Let $\Psi(p) \coloneqq \min_{a \in \BR_\delta(p)} u^\sfP(p, a)$ denote the robust payoff a contract $p$ yields for the principal}
%
Notice that analogous ``$\delta$-robust solution concepts'' have been already introduced in similar settings, namely Stackelberg games~\citep{gan2024robust} and Bayesian persuasion~\citep{yang2024computational}.
%
Our $\delta$-robust contracts are their analogous in the context of hidden-action principal-agent problems.

In the following, given $\delta \in (0,1)$, we denote the expected utility of the principal in an optimal $\delta$-robust contract $p^\star $ as $\textnormal{OPT}(\delta) \coloneqq u^\sfP(p^\star, a^\delta(p^\star)).$
%
We remark that $\textnormal{OPT}(\delta)$ is always well defined, as an optimal $\delta$-robust contract, according to the definition in \Cref{eq:delta_opt_def}, always exists.
%
Intuitively, this is due to the strict inequality in the definition of the set $A^\delta(p)$, as observed by~\citet{gan2024robust} for Stackelberg games.
%
Thus, in order to prove the existence of an optimal $\delta$-robust contract, it is possible to employ the same argument used to prove
Proposition~1 in~\citep{gan2024robust}.
%
%\bac{add something more?}
%%
%Formally:
%\begin{equation*}
%	\mathcal{P}_{a} \coloneqq \left \{ p \in \mathbb{R}^{m}_{+} \mid \sum_{\omega \in \Omega}F_{a,\omega}p_{\omega} - c_a \ge  \sum_{\omega \in \Omega}F_{a',\omega}p_{\omega} - c_{a'} \,\,\, \forall a' \in \mathcal{A} \right \}.
%\end{equation*}

