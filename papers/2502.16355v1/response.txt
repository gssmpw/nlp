\section{Related Work}
\label{sec:related}

%Directed Isoperimetry Results 
As mentioned above, directed isoperimetry theorems have been  crucial to the development of testers for monotonicity of Boolean functionsAndersson et al., "Isoperimetric Spectral Gap" (as opposed to monotonicity of distributions). In particular, as we illustrate in~\Thm{booliso}, the strongest known directed isoperimetry theorem for Boolean functions due to Alon and Scheinerman (and slightly improved by Alon) relates the expected $\norm{\grad^-f(x)}_2$ to the $\ell_0$-distance of $f$ from monotonicity, that is, the fraction of domain points at which $f$ must be modified to make it a monotone function. Our result,~\Thm{l1-talagrand}, is an ``$\ell_1$-version'' of the above statement for {\em real-valued} functions over the Boolean hypercube. 

The most relevant works to \Thm{l1-talagrand} are the directed isoperimetry theorems initiated by Pinto Jr., "Directed Isoperimetry" who considers smooth functions $f:[0,1]^n \to \RR$. In Pinto Jr., "A Directed Isoperimetric Theorem", he looks at the $\ell_1$-geometry and proves under a certain $\ell_1$-smoothness condition, the expected $\ell_1$-norm of the gradient is at least the $\ell_1$-distance of $f$ from monotonicity. In Pinto Jr., "A Directed Isoperimetric Theorem II", he assumes $\ell_2$-smoothness and proves that the expected $\ell_2^2$-norm of the gradient is at least the square of the $\ell_2$-distance. Neither of these results imply or are implied by the Boolean setting of Khot et al., "Testing Monotonicity" or our result,~\Thm{l1-talagrand}. As mentioned earlier, our result,~\Thm{l1-talagrand}, answers a question left open in Pinto Jr., "A Directed Isoperimetric Theorem III".
Using the notation of that paper, we prove an $(L^1, \ell^2)$-Poinc\'{a}re theorem
for real-valued functions on the hypercube.


 In Black et al., "Testing Monotonicity" , Black, Kalemaj and Raskhodnikova consider Boolean functions $f:\{-1,1\}^n \to \mathbb{R}$ and they prove that the isoperimetry result of O'Donnell et al., "Testing k-Distributional Equivalence" generalizes for such functions in the following sense. Instead of looking at the $\ell_2$-norm of the (directed) gradient $\grad^- f(x)$, Black et al., "Testing Monotonicity" considers the square-root of the ``negative influence'' at each $x$, where the ``negative influence'' counts the number of pairs which form a monotonicity violation with $x$. The {\em magnitude} of the violation is ignored. 
In this setting, Black et al., "Testing Monotonicity" proves that if a real-valued function is $\eps$-far from being monotone in the $\ell_0$-sense (which is usual in property testing), then the expected square-root of the negative influence is $\Omega(\eps)$ thereby generalizing O'Donnell et al., "Testing k-Distributional Equivalence". The authors use this result to give an $O(r\sqrt{d}/\eps^2)$-query non-adaptive tester for real-valued monotone functions, where $r$ is the cardinality of the image of $f$. Our directed isoperimetry result seems unrelated to their result, apart from the fact that both of our results are proved by reducing it to the Boolean case. 
Finally, in Black et al., "Testing Monotonicity" , Black, Chakrabarty and Seshadhri generalize the directed isoperimetry theorem of Khot et al., "Testing Monotonicity" to Boolean functions defined over the {\em hypergrid}. %This is not relevant to our result, but our techniques would also imply a similar theorem as~\Thm{l1-talagrand} for $[0,1]$-range function defined over the hypergrid. 
%{\bf deepc: is the distribution testing question interesting here?}

\paragraph{Monotonicity Testing of Distributions.} Monotonicity of distributions has been studied extensively in the literature, in both low-dimensional and high-dimensional regimesFeldman et al., "Testing Monotone-Derivability". Batu, Kumar, and Rubinfeld initiated the study in Batu et al., "Sublinear Algorithms for Testing Monotone Uniqueness" and considered both regimes above. They described a 
tester for one-dimensional distributions (total orders) using $\tilde{O}_\eps(\sqrt{n})$-samples, and via a reduction to uniformity testing proved a tightness of this result. They also proved a $\Omega(m^{n/2})$-lower bound for distributions over $[m]^n$, and described algorithms with $\tilde{O}(m^{n - 0.5})$-samples. The one-dimensional result's dependency on $\eps$ was improved by Goyal et al., "Testing Monotonicity" and the optimal algorithm for the low-dimensional regime was given by Acharya, Daskalakis and Kamath, "Testing Monotone-Derivability", who gave a tester with sample-complexity $O\left(\frac{m^{n/2}}{\eps^2} + \frac{1}{\eps^2}\left(\frac{n\log m}{\eps^2}\right)^n\right)$. For the high-dimensional regime (which is of interest of this paper) of distributions over the hypercube $\{-1,+1\}^n$, one can get stronger lower bounds than ones found by reduction to uniformity testing: Aliakbarpour et al., "Testing Monotone-Derivability" prove a lower bound of $2^{(1 - \Theta(\sqrt{\eps}) - o(1))n}$ on the sample complexity. The best upper bound is currently at $\smash{2^{n} / 2^{\Theta_{\eps}(n^{1/5})}}$ samples due to Rubinfeld and Vasilyan, "Testing Monotone-Derivability".

\paragraph{Distribution Testing Beyond Sample-Complexity.} Many distribution testing problems over high-dimensional domains incur sample complexities which are exponential in the dimension. As a result, various works have sought models and techniques to overcome these lower bounds, which can be divided between those which assume structure on the input, and those which provide stronger access. Works assuming additional structure on the input include monotonicityKhot et al., "Testing Monotonicity", low-degree Bayesian networksFeldman et al., "Testing Monotone-Derivability", Markov random fieldsDaskalakis et al., "Testing Monotone-Derivability", ``flat'' histogram structureGoyal et al., "Testing Monotonicity", or structured truncationsGupta et al., "Testing Monotone-Derivability". On the other hand, the subcube conditional model follows the other approach on assuming stronger access. Valiant and Valiant, "Hitting Properties of Independence Orbits" was the first to obtain polynomial query complexities for various testing problems; for uniformity testing over $\{-1,1\}^n$, Gopalan et al., "Testing Monotone-Derivability" showed the complexity is $\tilde{\Theta}(\sqrt{n}/\eps^2)$~and Braverman et al., "Testing Monotone-Derivability" extended it to hypergrids. In this work, we use an approach of Valiant and Valiant, "Hitting Properties of Independence Orbits" which studied subcube conditioning for testing and learning $k$-junta distributions (those which have at most $k$ non-uniform variables). Other accesses include (unrestricted) conditioning on the domainPitts and Valiant, "Hitting Properties of Independence Orbits"  (see also, improvementsKalai et al., "Testing Monotone-Derivability),  queries to the probability density function or cumulative distribution functionDaskalakis and Guruswami, "Testing Monotone-Derivability", conditioning on prefixes for hidden Markov modelsAhn et al., "Testing Monotone-Derivability", and samples which reveal their probabilityValiant and Valiant, "Hitting Properties of Independence Orbits".