
% In this part, we first present the experiment setup in Section \ref{sec:exp_setup}, followed by the results that demonstrate the effectiveness of our proposed method (Section \ref{exp_method}).
% when using BERT-based backbones. We then discuss the investigation results of using pre-trained LLMs for FCRE tasks in Section \ref{exp_LLM}.


\subsection{Settings}
\label{sec:exp:setup}

 We conduct experiments using two pre-trained language models, BERT \citep{devlin-etal-2019-bert} and LLM2Vec \cite{llm2vec}, on two widely used benchmark datasets for Relation Extraction: FewRel \citep{han-etal-2018-fewrel} and TACRED \citep{zhang-etal-2017-position}. We benchmark our methods against state-of-the-art baselines: \textbf{SCKD} \cite{wang-etal-2023-serial},  \textbf{RP-CRE} \cite{cui-etal-2021-refining},  \textbf{CRL} \cite{zhao-etal-2022-consistent}, \textbf{CRECL} \cite{hu-etal-2022-improving}, \textbf{ERDA} \cite{qin-joty-2022-continual}, \textbf{ConPL} \cite{DBLP:conf/acl/ChenWS23}, \textbf{CPL} \cite{ma-etal-2024-making}, \textbf{CPL+MI} \cite{tran-etal-2024-preserving}.

\subsection{Experiment results}
 \label{exp_method}

\paragraph{Our proposed method yields state-of-the-art accuracy.}
Table \ref{table:main} presents the results of our method and the baselines, all using the same pre-trained BERT-based backbone. Our method consistently outperforms all baselines across the board. The performance gap between our method and the strongest baseline, CPL, reaches up to $3.74\%$ on FewRel and $5.82\%$ on TACRED.
% After completing eight tasks, our method reduces the accuracy drop by $3.48\%$ on FewRel and $5.89\%$ on TACRED.

To further validate our model, we tested it on LLM2Vec, which provides stronger representation learning than BERT. As shown in Table \ref{table:main_llmvec}, our model again surpasses CPL, with accuracy drops of only $16.58\%$ on FewRel and $9.96\%$ on TACRED.

These results highlight the effectiveness of our method in leveraging semantic information from descriptions, which helps mitigate forgetting and overfitting, ultimately leading to significant performance improvements.



% \begin{aligned}
% &\text { Table 3: More detailed ablation study on Split-CIFAR-100 }\\
% &\begin{array}{lccccc}
% \hline \text { FewRel (\%) } & \text { TACRED (\%) } & \text {w/o $\mathcal{L}_{\mathrm{SC}}$ } & \text {w/o $\mathcal{L}_{\mathrm{RE}}$} & \text {w/o $\mathcal{L}_{\mathrm{MI}}$} & \text{w/o $\mathcal{L}_{\mathrm{ST}}$} \\
% \hline
% 68.47  & 70.02 & \checkmark & \checkmark & \checkmark & \checkmark \\
% 67.99  & 69.59 & \times & \checkmark & \checkmark & \checkmark \\
% 67.28  & 63.18 & \checkmark & \times & \checkmark & \checkmark \\
% 67.42  & 69.07 & \checkmark & \checkmark & \times & \checkmark \\
% 65.93  & 67.76 & \checkmark & \checkmark & \checkmark & \times \\
% \hline
% \end{array}
% \end{aligned}

\begin{figure}[ht]
	\centering
	\includegraphics[width=\linewidth]{imgs/tsne_visualizations.pdf}
	\caption{t-SNE visualization of the representations of 6 relations post-training, with and without descriptions, using our retrieval strategy.}
	\label{fig:tnse1}
\end{figure}

\paragraph{Exploiting additional descriptions significantly enhances representation learning.}
Figure \ref{fig:tnse1} presents t-SNE visualizations of the latent space of relations without (left) and with (right) the use of descriptions during training. The visualizations reveal that incorporating descriptions markedly improves the quality of the model’s representation learning. For instance, the brown-orange and purple-green class pairs, which are closely clustered and prone to misclassification in the left image, are more distinctly separated in the right image. Additionally, Figure \ref{fig:expert_or_not} illustrates that our strategy, which leverages refined descriptions, captures more semantic knowledge related to the labels than the approach using raw descriptions. This advantage bridges the gap imposed by the challenges of few-shot continual learning scenarios, leading to superior performance. Figure \ref{fig:vary_k} shows the perfomance of our model on TACRED as the number of generated expert descriptions per training varies. The results indicate that the model performance generally improves from $K = 3$ and peaks at $K = 7$. 

% \begin{table}[]
%     \centering
%     \begin{tabular}{lcccc}
%     \hline \\
%     \multirow{2}{*}{Method} & \multicolumn{2}{c}{FewRel} & \multicolumn{2}{c}{TACRED}\\
%     \cmidrule(lr){2-3} \cmidrule(lr){4-5} 
%     & BERT & LLM2Vec & BERT & LLM2Vec  \\
%     \hline \hline \\
%     w/o expert support & 64.55 & 75.82 & 57.45 & 74.34\\
%     w existing description & 66.49 & 78.09 & 59.56 & 77.43 \\ 
%     w expert support (Ours) & 68.24 & 80.34 & 64.92 & 79.10\\
%     \hline
%     \end{tabular}
%     \caption{The role of using expert knowledge}
%     \label{tab:my_label}
% \end{table}

\begin{figure}[ht]
	\centering
	\includegraphics[width=\linewidth]{imgs/fewrel_tacred_des.pdf}
	\caption{The impact of refined descriptions generated by LLMs. The green, orange, and blue bars show respectively the final accuracies of DCRE when using refined descriptions, original descriptions, and without using descriptions.}
	\label{fig:expert_or_not}
\end{figure}


\paragraph{Our retrieval-based prediction strategy notably enhances model performance.}
Table \ref{tab:prediction} demonstrates that by leveraging the rich information from generated descriptions, our proposed strategy improves the model’s performance by up to $1.31\%$ on FewRel and $6.66\%$ on TACRED compared to traditional NCM-based classification. The harmonious integration of NCM-based prototype proximity and description-based semantic similarity enables our strategy to deliver more accurate and robust predictions across sequential tasks.

\begin{table}[!t]
    \centering
    % \resizebox{0.45\textwidth}{!}{
    \setlength{\tabcolsep}{1mm}
    \begin{tabular}{lcccc}
    \hline 
    \multirow{2}{*}{Method} & \multicolumn{2}{c}{FewRel} & \multicolumn{2}{c}{TACRED}\\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} 
    & BERT & LLM2Vec & BERT & LLM2Vec  \\
    \hline \hline \\
    NCM  & 66.93 & 79.26 & 58.26 & 75.00 \\ 
    DRI (Ours) &\textbf{ 68.24} & \textbf{80.34} & \textbf{63.21} & \textbf{79.10}\\
    \hline
    \end{tabular}%}
    \caption{DRI and NCM prediction.}
    \label{tab:prediction}
\end{table}

% \paragraph{Effects of the number of generated samples $\mathit{K}$ for each training sample.}


%The results show that using multiple generated descriptions is better than using just one, as many generated samples help provide more specific, diverse, and semantically rich information, thereby making representation learning more comprehensive and effective. However, if $K$ is too large, our observations indicate that LLMs like Gemini can generate biased and low-quality samples, which negatively affect model performance.

\begin{figure}[h]
	\centering
	\includegraphics[width=\linewidth]{imgs/abl_K_tacred.pdf}
	\caption{Model performance when varying K, on \textit{TACRED 5-way 5-shot}.}
	\label{fig:vary_k}
\end{figure}

\subsection{Ablation study}
\label{sec:exp:ablation}

Table \ref{tab:ablation_study} present evaluation results that closely examine the role of each component in the objective function during training. The findings underscore the critical importance of $\mathcal{L}_\text{MI}$ and $\mathcal{L}_\text{HM}$, both of which leverage instructive descriptions from LLMs, aided by \emph{Raw descriptions}. Because when we ablate one of them, the final accuracy can be reduced by 6\% on the BERT-based model, and 10\% on the LLM2VEC-based model.

\begin{table}[ht]
    \centering
    % \resizebox{0.45\textwidth}{!}{
    \setlength{\tabcolsep}{1mm}
    \begin{tabular}{lcccc}
    \hline 
    \multirow{2}{*}{Method} & \multicolumn{2}{c}{BERT} & \multicolumn{2}{c}{LLM2Vec}\\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} 
    & FewRel & TACRED & FewRel & TACRED \\
    \hline \hline \\
    \text{DCRE (Our)} & \textbf{68.24} & \textbf{63.21} & \textbf{80.34} & \textbf{79.10}\\
    % \text{DCRE (Our)} & 67.82 & 64.92 \\
    \quad  \small \text{w/o $\mathcal{L}_{\textrm{SC}}$} & \underline{67.58} &  62.11 & \underline{78.39} & \underline{77.01}\\
    \quad  \small \text{w/o $\mathcal{L}_{\textrm{MI}}$} & 65.10 & 57.23 & 70.61 & 74.17\\
    \quad  \small \text{w/o $\mathcal{L}_{\textrm{HM}}$} & 66.20 & \underline{62.46} & 77.22 & 74.75\\
    \quad  \small \text{w/o $\mathcal{L}_{\textrm{ST}}$} & 67.54 & 59.56 & 77.48 & 73.77\\
    \hline
    \end{tabular}%}
    \caption{Ablation study.}
    \label{tab:ablation_study}
\end{table}


% \begin{table}[ht]
% \centering
% \begin{tabular}{lcc}
% \hline \text{Method} & \text{FewRel} & \text{TACRED} \\
% \hline \hline
% % \text{CPL} & 64.50 & 57.39 \\
% \text{DCRE (Our)} & \textbf{68.24} & \textbf{63.21} \\
% % \text{DCRE (Our)} & 67.82 & 64.92 \\
% \quad  \small \text{w/o $\mathcal{L}_{\textrm{SC}}$} & \underline{67.58} & \underline{62.11} \\
% \quad  \small \text{w/o $\mathcal{L}_{\textrm{MI}}$} & 65.10 & 57.23 \\
% \quad  \small \text{w/o $\mathcal{L}_{\textrm{HM}}$} & 66.20 & 62.46 \\
% \quad  \small \text{w/o $\mathcal{L}_{\textrm{ST}}$} & 67.54 & 59.56 \\
% % \text{NCM Prediction (w/o RRF)} & 66.93 & 58.26 \\
% % \text{Raw description} & 66.49 & 59.56 \\
% \hline
% \end{tabular}
% \caption{Accuracy (\%) of the final task BERT-based backbone}
% \label{tab:abl_bert}
% \end{table}

% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{imgs/ablate_bert.pdf}
%     \caption{Accuracy (\%) of the final task BERT-based backbone}
%     \label{fig:ablate_bert}
% \end{figure}

% \begin{table}[ht]
% \center

% \begin{tabular}{lcc}
% \hline \text{Method} & \text{FewRel} & \text{TACRED} \\
% \hline \hline
% % \text{CPL} & 75.20 & 73.83 \\
% \text{DCRE (Our)} & \textbf{80.34} & \textbf{79.10} \\
% \quad  \small \text{w/o $\mathcal{L}_{\mathrm{SC}}$} & \underline{78.39} & \underline{77.01} \\
% \quad  \small \text{w/o $\mathcal{L}_{\mathrm{MI}}$} & 70.61 & 74.17 \\
% \quad  \small \text{w/o $\mathcal{L}_{\mathrm{HM}}$} & 77.22 & 74.75 \\
% \quad  \small \text{w/o $\mathcal{L}_{\mathrm{ST}}$} & 77.48 & 73.77 \\
% % \text{NCM Prediction (w/o RRF)} & 78.81 & 75.00 \\
% % \text{Raw description} & 80.09 & 77.43 \\
% \hline
% \end{tabular}
% \caption{Accuracy (\%) of the final tasks (LLM2vec backbone)}
% \label{tab:abl_llm2vec}
% \end{table}

% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{imgs/ablate_llm.pdf}
%     \caption{Accuracy (\%) of the final task LLM2Vec-based backbone}
%     \label{fig:ablate_llm}
% \end{figure}

