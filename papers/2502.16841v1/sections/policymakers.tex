\section{Policymakers}

This section examines two critical aspects of FMs development: governance frameworks for ensuring reliability and the strategic allocation of essential resources.

\subsection{Governance}
\textbf{Reliability.} The implementation of FMs in healthcare faces critical reliability challenges due to insufficient standardization in bias detection and mitigation practices \cite{khan_how_2023, glocker_risk_2023, li_empirical_2024, jin_fairmedfm_2024, zong_medfair_2023}. Despite a growing emphasis on AI ethics, healthcare institutions lack both established evaluation frameworks and qualified experts needed to assess these systems effectively. This deficiency is particularly concerning because bias continues to emerge in deployment scenarios, while current mitigation methods demonstrate limited reliability \cite{jin_fairmedfm_2024, zong_medfair_2023}. The challenge of bias mitigation becomes particularly critical in regions with limited data representation, notably in Global South nations (Figure \ref{fig:map}), where healthcare systems encounter substantial obstacles in implementing and adapting these models for their populations. This disparity underscores a critical gap in current FMs deployment strategies, as the absence of representative data further compounds existing healthcare inequities.


\textbf{FMs as institutions.}
Research demonstrates that algorithmic systems function as institutional frameworks that organize complex machine-human interactions in decision-making processes \cite{almeida_algorithms_2022}. FMs represent a significant evolution in this infrastructure, enabling complex decision-making capabilities across medical domains, offering pre-trained architectures adaptable to diverse medical tasks. However, these models systematically perpetuate societal power imbalances and biases through their operational frameworks \cite{cottier_rising_2024}. Conceptualizing FMs as institutions, rather than purely technical implementations, facilitates the establishment of comprehensive evaluation protocols and governance frameworks that enhance model reliability through systematic oversight, standardized assessment criteria, and robust accountability measures.

\textbf{Regulation.} Legislative frameworks are crucial in enhancing AI system reliability in healthcare. The EU AI Act exemplifies a pioneering approach by classifying medical AI systems as "high-risk" and establishing provisions for General Purpose AI Models (GPAI), which encompass FMs. These models present distinct challenges due to their scale, adaptability, and cross-domain impact \cite{minssen_challenges_2023}. While such oversight aims to enhance safety and accountability, implementation barriers emerge \cite{aboy_navigating_2024}. Studies reveal that companies struggle with extensive technical documentation requirements and associated costs \cite{carl_impact_2024}. These obstacles become more pronounced in developing nations, where compliance expenses may hinder local innovation. Although regulations could ensure unbiased systems and improve data practices, stringent requirements risk impeding AI advancement in emerging economies. This creates tension between maintaining safety standards and fostering equitable technological progress globally.

\subsection{Resource Allocation}

\textbf{Workforce.} Fair FMs demand interdisciplinary collaboration among technical, legal, and social experts to ensure comprehensive bias mitigation \cite{lekadir_future-ai_2025, bengio_international_nodate}. These multidisciplinary teams integrate diverse societal values and ethical perspectives into model development and evaluation protocols. Essential to this process is the active participation of marginalized communities, whose insights prove crucial for identifying systemic biases in FMs. The global distribution of FM expertise, however, remains heavily concentrated in the United States and China \cite{alshebli_china_2024, zwetsloot_skilled_2021}, creating significant barriers to diverse team formation. This geographic concentration is exacerbated by linguistic constraints: the predominance of English in educational materials and technical documentation impedes knowledge dissemination and FM expertise development in non-English-speaking regions.

\textbf{Data source.} AI research disparities manifest critically in data infrastructure and computational resources across global regions. Figure \ref{fig:map} illustrates the significant underrepresentation of Global South populations in major medical imaging datasets. Quantitative analyses reveal systematic exclusion across modalities, with Global South regions constituting less than 0.7\% of text-domain datasets \cite{longpre_bridging_2024}. This limitation extends to linguistic diversity: among medical imaging repositories, only PadChest provides non-English (Spanish) annotations (Table \ref{tab:medical-datasets}). Developing equitable FMs requires datasets that reflect global population diversity across both geographic and demographic dimensions. Achieving representative data collection necessitates integrated technical and governance frameworks that actively incorporate marginalized populations into healthcare data systems \cite{world_health_organization_conceptual_2010, chen_ethical_2021, bailey_structural_2017, williams_understanding_2019}.

\textbf{Computing.} FMs development requires extensive computational infrastructure, limiting access to organizations with advanced resources \cite{cottier_rising_2024}. Analysis of the November 2024 Top500 supercomputer rankings demonstrates pronounced regional disparities: North America holds 55.6\% of capacity, Europe 27.4\%, and Asia 15.9\%, while South America and Oceania represent just 0.6\% and 0.5\% respectively. The combined scarcity of computational power and large-scale datasets creates a fundamental barrier in the Global South, where only Brazil, Australia, and Argentina maintain Top500-listed facilities. Africa's absence from these rankings underscores how infrastructure limitations constrain both FMs development and deployment.

