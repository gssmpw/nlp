\section{\uppercase{Related Work}}
\label{sec:methodology}
Data augmentation and synthetic data generation have emerged as powerful techniques to enhance the performance and robustness of deep learning models, particularly in scenarios with limited data.

\subsection{Data augmentation methods}
Data augmentation techniques have been widely employed to enhance the performance and generalization of deep learning models, especially in scenarios with limited data. Traditional methods, such as geometric transformations (e.g., random cropping, flipping, rotation) and colour jittering, have been effective in improving model robustness \cite{traditional}.

Recent advancements in data augmentation have focused on more sophisticated techniques. For instance, RICAP \cite{random_cropping} randomly crops and patches images to create new training examples, while also mixing class labels to introduce soft label learning. This approach has shown promising results in various computer vision tasks.

To address the issue of colour variations between different cameras, a novel approach has been proposed to map colour values using deep learning \cite{colour}. By learning colour-mapping parameters, this technique enables the augmentation of colour data by converting images from one camera to another, effectively expanding the training dataset.

Another recent technique, SmoothMix, addresses the limitations of existing regional dropout-based data augmentation methods \cite{smooth_mix}. By blending images based on soft edges and computing corresponding labels, SmoothMix minimizes the "strong-edge" problem and improves model performance and robustness against image corruption.

In the domain of hyperspectral image (HSI) denoising, data augmentation has been less explored. A new method called PatchMask has been proposed to augment HSI data while preserving spatial and spectral information \cite{patch_mask}. By creating diverse training samples that lie between clear and noisy images, PatchMask can enhance the effectiveness of HSI denoising models.

Recent advancements in attention mechanisms have enabled more effective data augmentation techniques. Attentive CutMix \cite{cut_mix} is a novel method that leverages attention maps to identify the most discriminative regions within an image, and then selectively applies cut-mix operations to these regions. This targeted approach can lead to significant improvements in model performance.

\subsection{Synthetic Data generation methods}
Synthetic data generation has emerged as a powerful technique to address data scarcity and domain shift challenges in various domains. By generating realistic synthetic data, models can be trained on larger and more diverse datasets, leading to improved performance.

Generative Adverserial Networks (GANs) have gained widespread popularity for their ability to produce high-quality synthetic data by training a generator to create realistic samples while a discriminator distinguishes between real and generated data. Their versatility has been demonstrated across domains such as image synthesis \cite{sodgan} and industrial object detection \cite{cyclegan}. However, GANs can be challenging to train and often suffer from mode collapse, where the generator fails to capture the full diversity of the data distribution. 

Variational Autoencoders (VAEs) learn a latent representation of the data distribution and can generate new data points by sampling from this latent space. VAEs are more stable to train than GANs, but they often produce lower-quality samples, especially for complex data distributions. VAEs have been applied to various tasks, including image generation, anomaly detection, and data augmentation. For example, VAEs have been used to generate synthetic medical images for training medical image segmentation models \cite{vae-gan} and to synthesize semantically rich images for geospatial applications \cite{vae-info-cgan}.

Vector Quantised-Variational Autoencoders (VQ-VAEs) enhance the capabilities of VAEs by introducing a discrete latent code, making it more efficient and interpretable. VQ-VAEs have been shown to be effective in generating high-quality images and can be used as a building block for more complex generative models. VQ-VAEs have been applied to various tasks, including image compression, image generation, and video prediction. For example, VQ-VAEs have been used to generate synthetic data for human activity recognition (HAR) with complex multi-sensor inputs \cite{vq-vae}.

Diffusion models gradually denoise a random noise vector to generate realistic data samples. Recent work, such as \cite{ho2020denoising}, has shown that diffusion models can achieve state-of-the-art results in image generation. Diffusion models have been applied to various tasks, including image generation, image restoration, and text-to-image generation. Latent diffusion models (LDMs) \cite{synthesis-diffusion} enhance efficiency by operating in a compressed latent space, significantly reducing computational costs.