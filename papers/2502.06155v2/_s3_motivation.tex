
\section{Observations}

In the introduction:
We find repeat pattern in DiT. Moreover, this repeat pattern preserves the structure over different data points. Thus, enabling an opportunity to do a fixed pattern during training time.


Bottleneck of 3D-DiT lies in two dimensions: (1) Attention, (2) diffusion step. Fortunately, we observe there are redundancy in both dimensions (Fig. 1), (Fig. 2). Thus, we develop
\subsection{Characteristics of Attention}

\textbf{High computational cost of self-attention:} 3D-DiT consists of self-attention and cross-attention modules. Experimental results indicate that as the video resolution and the number of frames increase, the sequence length also increases, leading to a quadratic growth in the runtime of the attention modules. When the sequence length reaches 70,000, the runtime of self-attention accounts for 91.4\% of the entire 3D-DiT module, significantly challenging the speed of video generation.

\textbf{Attention map is not data-dependent:} The attention map of 3D-DiT has a dimension of [\texttt{seq\_len}, \texttt{seq\_len}]. As observed in Figure \texttt{fig:attn\_map}, the attention map exhibits a block pattern. According to the encoding rules of 3D-VAE, each block represents the information within a single frame of an image, while the blocks between them represent temporal information.

From Figure \texttt{fig:attn\_map}, for different prompt inputs, when fixing the layer and head, we observe that the pattern of the attention map remains the same for different input data, for both original model and consistent model (CM). Therefore, we conclude that the attention map is not data-dependent.

\subsection{Diffusion Step Redundancy}

\textbf{Redundancy between adjacent diffusion steps:} There exists a significant amount of similarity between adjacent diffusion steps. This redundancy can be eliminated through the distillation process of the consistent model.

\hangliang {@runlong Added more details.}