
\documentclass[10pt]{article} %


\usepackage[accepted]{tmlr}

\input{math_commands.tex}
\usepackage{colortbl}
\usepackage{amsmath,amsthm}

\usepackage{booktabs}  
\usepackage{bm}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{pifont}     
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{url}

\usepackage{caption}
\usepackage{subcaption}

\newcommand{\vicunaseven}{{Vicuna 7B}}
\newcommand{\guanacoseven}{{Guanaco 7B}}
\usepackage{dblfloatfix}


\definecolor{ytcolor}{rgb}{1.0, 0.49, 0.0}

\newcommand{\cmark}{\textcolor{green}{\ding{51}}}%
\newcommand{\xmark}{\ding{55}}%

\newcommand{\grigoris}[1]{\textcolor{red}{(G: #1)}}
\newcommand{\grig}[1]{\grigoris{#1}}
\newcommand{\elias}[1]{\textcolor{blue}{(Elías: #1)}}
\newcommand{\leyla}[1]{\textcolor{purple}{(Leyla: #1)}}
\newcommand{\yongtao}[1]{\textcolor{ytcolor}{(Tao: #1)}}

\newcommand{\methodname}{{SPD}}
\newcommand{\vicuna}{Vicuna}
\newcommand{\llama}{Llama 2}
\newcommand{\llamachat}{{Llama 2-Chat 7B}}
\newcommand{\vicunathirteen}{{Vicuna 13B}}
\newcommand{\rebuttal}[1]{\textcolor{black}{#1}}

\title{Single-pass Detection of Jailbreaking Input in Large \\ Language Models}


\author{\name Leyla Naz Candogan \email leyla.candogan@epfl.ch \\
      \addr LIONS - École Polytechnique Fédérale de Lausanne
      \AND
      \name Yongtao Wu \email  yongtao.wu@epfl.ch\\
      \addr LIONS - École Polytechnique Fédérale de Lausanne
      \AND
      \name Elias Abad Rocamora \email elias.abadrocamora@epfl.ch\\
      \addr LIONS - École Polytechnique Fédérale de Lausanne
      \AND
      \name Grigorios G. Chrysos \email  chrysos@wisc.edu\\
      \addr University of Wisconsin-Madison
      \AND
      \name Volkan Cevher \email  volkan.cevher@epfl.ch\\
      \addr LIONS - École Polytechnique Fédérale de Lausanne
      \AND}


\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{02}  %
\def\year{2025} %
\def\openreview{\url{https://openreview.net/forum?id=42v6I5Ut9a}} %


\begin{document}


\maketitle

\begin{abstract}
Defending aligned Large Language Models (LLMs) against jailbreaking attacks is a challenging problem, with existing approaches requiring multiple requests or even queries to auxiliary LLMs, making them computationally heavy. Instead, we focus on detecting jailbreaking input in a single forward pass. Our method, called Single Pass Detection \methodname{}, leverages the information carried by the logits to predict whether the output sentence will be harmful. This allows us to defend in \emph{just one} forward pass. \methodname{} can not only detect attacks effectively on open-source models, but also minimizes the misclassification of harmless inputs. Furthermore, we show that \methodname{} remains effective even without complete logit access in GPT-3.5 and GPT-4. We believe that our proposed method offers a promising approach to efficiently safeguard LLMs against adversarial attacks. \footnote{Code and data available at \url{https://github.com/LIONS-EPFL/SPD}.}

\textcolor{red}{Warning: This paper might contain offensive and unsafe content.}%


\end{abstract}

\input{sections/introduction}
\input{sections/related_work}
\input{sections/method}
\input{sections/experiments}
\input{sections/conclusion}

\newpage

\subsubsection*{Acknowledgments}
The authors acknowledge the constructive feedback of reviewers. We thank Zulip\footnote{\url{https://zulip.com}} for their project organization tool. Research was sponsored by the Army Research Office and was accomplished under Grant Number W911NF-24-1-0048. This work was supported by Hasler Foundation Program: Hasler Responsible AI (project number 21043). This work was supported by the Swiss National Science Foundation (SNSF) under grant number 200021\_205011. GC is supported by Gemma Academic Program. 



\bibliography{main}
\bibliographystyle{tmlr}

\newpage
\appendix

\input{sections/appendix}


\end{document}
