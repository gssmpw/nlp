\section{Experimental Evaluation}

The evaluation encompasses both training and test datasets, with a detailed analysis across 16 weed species. We employ various metrics, including AP, AR at different IoU thresholds and detection limits, as well as mAP and mean average recall (mAR). Additionally, we compare the inference speed of both models to provide a holistic view of their capabilities.


% \begin{table*}[t]
% \caption{Performance Comparison of DETR and RetinaNet on Training and Test Sets}
% \label{performance_comparison}
% \begin{center}
% \begin{tabular}{|l|cc|cc|}
% \hline
% \multirow{2}{*}{\textbf{Metrics}} & \multicolumn{2}{c|}{\textbf{DETR}} & \multicolumn{2}{c|}{\textbf{RetinaNet}} \\
% \cline{2-5}
% & \textbf{Train} & \textbf{Test} & \textbf{Train} & \textbf{Test} \\
% \hline
% AP@[IoU=0.50:0.95|maxDets=100] & 0.656 & 0.675 & 0.736 & \textbf{0.744} \\
% AP@[IoU=0.50|maxDets=1000] & 0.892 & 0.874 & \textbf{0.934} & 0.918 \\
% AP@[IoU=0.75|maxDets=1000] & 0.727 & 0.709 & 0.806 & \textbf{0.807} \\
% AR@[IoU=0.50:0.95|maxDets=100,300,1000] & 0.862 & \textbf{0.877} & 0.804 & 0.805 \\
% Mean Average Precision (mAP) & 0.854 & 0.840 & \textbf{0.907} & 0.904 \\
% Mean Average Recall (mAR) & 0.941 & 0.936 & \textbf{0.997} & 0.989 \\
% \hline
% Inference Speed (FPS) & \multicolumn{2}{c|}{3.49} & \multicolumn{2}{c|}{\textbf{7.28}} \\
% \hline
% \end{tabular}
% \end{center}
% \end{table*}

\begin{table*}[t]
\vspace{-0.4cm}
\caption{Performance Comparison of DETR and RetinaNet on Training and Test Sets}
\label{performance_comparison}
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Model}} & \multicolumn{2}{c|}{\textbf{mAP}} & \multicolumn{2}{c|}{\textbf{mAR}} & \multirow{2}{*}{\textbf{FPS}} \\
\cline{2-5}
& \textbf{\textit{Train}} & \textbf{\textit{Test}} & \textbf{\textit{Train}} & \textbf{\textit{Test}} & \\
\hline
DETR & 0.854 & 0.840 & 0.941 & 0.936 & 3.49 \\
RetinaNet & \textbf{0.907} & 0.904 & \textbf{0.997} & 0.989 & \textbf{7.28} \\
\hline
\end{tabular}
\end{center}
\end{table*}


Table \ref{performance_comparison} compares DETR and RetinaNet performance on training and test sets, highlighting key metrics. RetinaNet consistently outperforms DETR across all presented metrics. In terms of mean Average Precision (mAP), RetinaNet achieves superior scores of 0.907 and 0.904 on training and test sets respectively, compared to DETR's 0.854 and 0.840. This trend continues in mean Average Recall (mAR), where RetinaNet approaches near-perfect scores with 0.997 (training) and 0.989 (test), while DETR achieves 0.941 and 0.936. Notably, RetinaNet's inference speed is significantly faster, operating at 7.28 Frames Per Second (FPS), more than twice the speed of DETR's 3.49 FPS. This substantial difference in processing speed, combined with RetinaNet's superior accuracy metrics, suggests it may be the more efficient choice for real-time or high-volume weed detection tasks.


\begin{table*}[t]
\caption{\footnotesize Performance Comparison of DETR and RetinaNet across Weed Species}
\label{weed_species_performance}
\vspace{-0.6cm}
\begin{center}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|c|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{\textbf{Species Code}} & \multicolumn{4}{c|}{\textbf{DETR}} & \multicolumn{4}{c|}{\textbf{RetinaNet}} \\
\cline{2-9}
& \textbf{\textit{Average mAP}} & \textbf{\textit{Average mAP\_50}} & \textbf{\textit{Average mAP\_75}} & \textbf{\textit{Average Recall}} & \textbf{\textit{Average mAP}} & \textbf{\textit{Average mAP\_50}} & \textbf{\textit{Average mAP\_75}} & \textbf{\textit{Average Recall}} \\
\hline
ABUTH & 0.683 & 0.907 & 0.719 & 0.973 & 0.720 & 0.924 & 0.779 & 0.993 \\
AMAPA & 0.617 & 0.835 & 0.672 & 0.975 & 0.877 & 0.985 & 0.939 & 0.994 \\
AMARE & 0.575 & 0.807 & 0.598 & 0.957 & 0.617 & 0.941 & 0.684 & 0.987 \\
AMATA & 0.536 & 0.721 & 0.565 & 0.869 & 0.832 & 0.977 & 0.905 & 0.997 \\
AMBEL & 0.817 & 0.978 & 0.898 & 0.993 & 0.663 & 0.926 & 0.740 & 0.994 \\
CHEAL & 0.503 & 0.846 & 0.502 & 0.962 & 0.871 & 0.993 & 0.957 & 0.997 \\
CYPES & 0.643 & 0.861 & 0.680 & 0.986 & 0.781 & 0.971 & 0.853 & 0.995 \\
DIGSA & 0.578 & 0.864 & 0.594 & 0.995 & 0.664 & 0.878 & 0.753 & 0.976 \\
ECHCG & 0.655 & 0.899 & 0.715 & 0.986 & 0.566 & 0.814 & 0.612 & 0.950 \\
ERICA & 0.718 & 0.918 & 0.752 & 0.977 & 0.678 & 0.918 & 0.749 & 0.992 \\
PANDI & 0.670 & 0.929 & 0.723 & 0.979 & 0.724 & 0.934 & 0.799 & 0.993 \\
SETFA & 0.680 & 0.903 & 0.756 & 0.990 & 0.785 & 0.967 & 0.854 & 0.993 \\
SETPU & 0.597 & 0.852 & 0.652 & 0.973 & 0.794 & 0.949 & 0.858 & 0.993 \\
SIDSP & 0.771 & 0.980 & 0.826 & 0.993 & 0.739 & 0.954 & 0.832 & 0.991 \\
SORVU & 0.582 & 0.791 & 0.624 & 0.871 & 0.713 & 0.925 & 0.789 & 0.995 \\
SORHA & 0.527 & 0.715 & 0.544 & 0.892 & 0.693 & 0.858 & 0.780 & 0.894 \\
\hline
\end{tabular}
}
\end{center}
\vspace{-0.5cm}
\end{table*}


Table \ref{weed_species_performance} delves deeper, breaking down performance across all individual weed species. This table shows the average value of all 11 weeks results for 16 species. This view reveals nuances in each model's capabilities. RetinaNet demonstrates more consistent performance across species, with less variation in mAP scores. In contrast, DETR's performance fluctuates more widely, excelling with some species like AMBEL (mAP 0.817) and SIDSP (mAP 0.771), while struggling with others such as CHEAL (mAP 0.503) and SORHA (mAP 0.527). RetinaNet shines particularly bright with species like AMATA (mAP 0.832) and AMAPA (mAP 0.877), though it faces challenges with ECHCG (mAP 0.566).
Across all species, RetinaNet consistently achieves higher recall, often nearing or reaching 1.0, while DETR's recall, though generally high, shows more variability. Both models exhibit the expected decline in mAP as the IoU threshold increases from 0.5 to 0.75, but RetinaNet maintains higher scores more consistently throughout this range.

%----------------

We have selected four species for presenting their growth-wise experimental evaluation in this paper: Palmer amaranth (AMAPA), waterhemp (AMATA), giant foxtail (SETFA), and velvetleaf (ABUTH). These species are considered “driver weeds” or weeds that drive management decisions in USA agriculture due to their aggressive growth habits, herbicide resistance, and significant impact on crop yields \cite{illinois}. AMAPA and AMATA are particularly notorious for their rapid growth and resistance to multiple herbicide modes of action, making them difficult to control and highly competitive with crops.\\

\begin{table}
\caption{Performance Comparison of DETR and RetinaNet for SETFA}
\label{setfa_performance}
\vspace{-0.2cm}
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|cccc|cccc|}
\hline
\multirow{2}{*}{\textbf{Class Name}} & \multicolumn{4}{c|}{\textbf{DETR}} & \multicolumn{4}{c|}{\textbf{RetinaNet}} \\
\cline{2-9}
& \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} & \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} \\
\hline
SETFA\_Week\_1 & 0.355 & 0.605 & 0.348 & 0.986 & 0.671 & 0.870 & 0.767 & 0.980 \\
SETFA\_Week\_2 & 0.400 & 0.763 & 0.414 & 1.000 & 0.623 & 0.801 & 0.738 & 0.989 \\
SETFA\_Week\_3 & 0.740 & 0.999 & 0.887 & 0.929 & 0.755 & 0.991 & 0.830 & 1.000 \\
SETFA\_Week\_4 & 0.607 & 0.860 & 0.717 & 0.974 & 0.555 & 0.764 & 0.611 & 1.000 \\
SETFA\_Week\_5 & 0.741 & 0.964 & 0.868 & 1.000 & 0.657 & 0.899 & 0.708 & 0.995 \\
SETFA\_Week\_6 & 0.658 & 0.859 & 0.669 & 1.000 & 0.648 & 0.936 & 0.682 & 1.000 \\
SETFA\_Week\_7 & 0.825 & 0.974 & 0.860 & 1.000 & 0.822 & 0.980 & 0.795 & 1.000 \\
SETFA\_Week\_8 & 0.743 & 1.000 & 0.818 & 1.000 & 0.822 & 1.000 & 0.943 & 1.000 \\
SETFA\_Week\_9 & 0.856 & 0.955 & 0.949 & 1.000 & 0.843 & 0.983 & 0.932 & 1.000 \\
SETFA\_Week\_10 & 0.696 & 0.956 & 0.802 & 0.986 & 0.643 & 0.956 & 0.738 & 0.986 \\
SETFA\_Week\_11 & 0.859 & 1.000 & 0.988 & 1.000 & 0.808 & 1.000 & 0.938 & 1.000 \\
\hline
\end{tabular}
}
\end{table}


\begin{table}
\caption{Performance Comparison of DETR and RetinaNet for AMAPA}
\label{amapa_performance}
\vspace{-0.2cm}
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|cccc|cccc|}
\hline
\multirow{2}{*}{\textbf{Class Name}} & \multicolumn{4}{c|}{\textbf{DETR}} & \multicolumn{4}{c|}{\textbf{RetinaNet}} \\
\cline{2-9}
& \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} & \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} \\
\hline
AMAPA\_Week\_1 & 0.096 & 0.345 & 0.035 & 1.000 & 0.481 & 0.729 & 0.585 & 0.949 \\
AMAPA\_Week\_2 & 0.277 & 0.518 & 0.263 & 1.000 & 0.771 & 0.974 & 0.808 & 1.000 \\
AMAPA\_Week\_3 & 0.354 & 0.718 & 0.354 & 0.925 & 0.636 & 0.933 & 0.657 & 0.995 \\
AMAPA\_Week\_4 & 0.505 & 0.860 & 0.501 & 0.837 & 0.860 & 1.000 & 0.988 & 1.000 \\
AMAPA\_Week\_5 & 0.576 & 0.855 & 0.670 & 0.983 & 0.711 & 0.887 & 0.735 & 1.000 \\
AMAPA\_Week\_6 & 0.839 & 1.000 & 0.930 & 0.991 & 0.860 & 0.986 & 0.917 & 1.000 \\
AMAPA\_Week\_7 & 0.809 & 0.982 & 0.912 & 0.996 & 0.896 & 0.980 & 0.974 & 0.989 \\
AMAPA\_Week\_8 & 0.766 & 0.985 & 0.882 & 1.000 & 0.835 & 1.000 & 0.955 & 1.000 \\
AMAPA\_Week\_9 & 0.796 & 0.934 & 0.865 & 1.000 & 0.836 & 0.945 & 0.865 & 0.994 \\
AMAPA\_Week\_10 & 0.852 & 0.986 & 0.981 & 1.000 & 0.846 & 1.000 & 0.962 & 1.000 \\
AMAPA\_Week\_11 & 0.912 & 1.000 & 1.000 & 1.000 & 0.902 & 1.000 & 1.000 & 1.000 \\
\hline
\end{tabular}
}
\end{table}


%---

\vspace{-0.2cm}

\begin{table}
\caption{Performance Comparison of DETR and RetinaNet for ABUTH}
\label{abuth_performance}
\vspace{-0.2cm}
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|cccc|cccc|}
\hline
\multirow{2}{*}{\textbf{Class Name}} & \multicolumn{4}{c|}{\textbf{DETR}} & \multicolumn{4}{c|}{\textbf{RetinaNet}} \\
\cline{2-9}
& \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} & \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} \\
\hline
ABUTH\_Week\_1 & 0.418 & 0.723 & 0.471 & 0.994 & 0.605 & 0.899 & 0.689 & 1.000 \\
ABUTH\_Week\_2 & 0.576 & 0.988 & 0.530 & 1.000 & 0.829 & 0.990 & 0.952 & 1.000 \\
ABUTH\_Week\_3 & 0.356 & 0.697 & 0.346 & 1.000 & 0.790 & 0.996 & 0.899 & 1.000 \\
ABUTH\_Week\_4 & 0.408 & 0.771 & 0.396 & 0.996 & 0.725 & 0.973 & 0.844 & 0.995 \\
ABUTH\_Week\_5 & 0.445 & 0.923 & 0.377 & 0.871 & 0.730 & 0.974 & 0.789 & 1.000 \\
ABUTH\_Week\_6 & 0.850 & 1.000 & 1.000 & 0.886 & 0.924 & 0.970 & 0.970 & 0.972 \\
ABUTH\_Week\_7 & 0.885 & 0.932 & 0.931 & 0.993 & 0.966 & 1.000 & 1.000 & 1.000 \\
ABUTH\_Week\_8 & 0.856 & 1.000 & 0.982 & 1.000 & 0.911 & 1.000 & 1.000 & 1.000 \\
ABUTH\_Week\_9 & 0.912 & 0.977 & 0.949 & 0.975 & 0.876 & 0.978 & 0.920 & 1.000 \\
ABUTH\_Week\_10 & 0.880 & 0.967 & 0.923 & 1.000 & 0.868 & 0.971 & 0.893 & 1.000 \\
ABUTH\_Week\_11 & 0.924 & 1.000 & 1.000 & 0.989 & 0.924 & 1.000 & 1.000 & 1.000 \\
\hline
\end{tabular}
}
\end{table}


\begin{table}
\caption{Performance Comparison of DETR and RetinaNet for AMATA}
\label{amata_performance}
\vspace{-0.2cm}
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|cccc|cccc|}
\hline
\multirow{2}{*}{\textbf{Class Name}} & \multicolumn{4}{c|}{\textbf{DETR}} & \multicolumn{4}{c|}{\textbf{RetinaNet}} \\
\cline{2-9}
& \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} & \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} \\
\hline
AMATA\_Week\_1 & 0.001 & 0.003 & 0.000 & 0.982 & 0.641 & 0.981 & 0.742 & 0.992 \\
AMATA\_Week\_2 & 0.004 & 0.021 & 0.000 & 1.000 & 0.529 & 0.923 & 0.525 & 0.966 \\
AMATA\_Week\_3 & 0.157 & 0.397 & 0.076 & 0.391 & 0.747 & 0.998 & 0.934 & 1.000 \\
AMATA\_Week\_4 & 0.484 & 0.910 & 0.486 & 0.397 & 0.763 & 0.985 & 0.838 & 1.000 \\
AMATA\_Week\_5 & 0.544 & 0.974 & 0.541 & 0.839 & 0.738 & 0.961 & 0.822 & 0.994 \\
AMATA\_Week\_6 & 0.763 & 0.960 & 0.878 & 0.970 & 0.923 & 0.994 & 0.972 & 1.000 \\
AMATA\_Week\_7 & 0.905 & 1.000 & 0.977 & 0.995 & 0.968 & 1.000 & 0.974 & 1.000 \\
AMATA\_Week\_8 & 0.756 & 0.913 & 0.808 & 1.000 & 0.889 & 0.979 & 0.954 & 0.990 \\
AMATA\_Week\_9 & 0.881 & 0.960 & 0.952 & 1.000 & 0.926 & 0.990 & 0.972 & 1.000 \\
AMATA\_Week\_10 & 0.520 & 0.797 & 0.529 & 0.989 & 0.625 & 0.927 & 0.670 & 1.000 \\
AMATA\_Week\_11 & 0.882 & 0.993 & 0.965 & 1.000 & 0.849 & 0.998 & 0.933 & 1.000 \\
\hline
\end{tabular}
}
\end{table}



% \begin{table}
% \caption{Performance Comparison of DETR and RetinaNet for AMBEL}
% \label{ambel_performance}
% \centering
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{|l|cccc|cccc|}
% \hline
% \multirow{2}{*}{\textbf{Class Name}} & \multicolumn{4}{c|}{\textbf{DETR}} & \multicolumn{4}{c|}{\textbf{RetinaNet}} \\
% \cline{2-9}
% & \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} & \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} \\
% \hline
% AMBEL\_Week\_1 & 0.676 & 0.970 & 0.788 & 1.000 & 0.842 & 0.981 & 0.946 & 0.990 \\
% AMBEL\_Week\_2 & 0.602 & 0.884 & 0.683 & 1.000 & 0.839 & 0.967 & 0.917 & 0.986 \\
% AMBEL\_Week\_3 & 0.839 & 0.991 & 0.888 & 1.000 & 0.886 & 0.991 & 0.932 & 1.000 \\
% AMBEL\_Week\_4 & 0.826 & 0.980 & 0.980 & 0.988 & 0.903 & 1.000 & 0.989 & 1.000 \\
% AMBEL\_Week\_5 & 0.790 & 1.000 & 0.942 & 1.000 & 0.927 & 1.000 & 0.989 & 1.000 \\
% AMBEL\_Week\_6 & 0.927 & 0.990 & 0.990 & 0.989 & 0.923 & 0.962 & 0.960 & 0.974 \\
% AMBEL\_Week\_7 & 0.910 & 1.000 & 0.977 & 1.000 & 0.944 & 1.000 & 0.980 & 1.000 \\
% AMBEL\_Week\_8 & 0.953 & 1.000 & 1.000 & 0.990 & 0.974 & 1.000 & 1.000 & 1.000 \\
% AMBEL\_Week\_9 & 0.947 & 0.990 & 0.983 & 1.000 & 0.932 & 0.990 & 0.958 & 1.000 \\
% AMBEL\_Week\_10 & 0.708 & 0.958 & 0.787 & 1.000 & 0.729 & 0.965 & 0.828 & 1.000 \\
% AMBEL\_Week\_11 & 0.813 & 0.995 & 0.858 & 0.994 & 0.746 & 0.984 & 0.835 & 0.994 \\
% \hline
% \end{tabular}
% }
% \end{table}




% \begin{table}
% \caption{Performance Comparison of DETR and RetinaNet for AMARE}
% \label{amare_performance}
% \centering
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{|l|cccc|cccc|}
% \hline
% \multirow{2}{*}{\textbf{Class Name}} & \multicolumn{4}{c|}{\textbf{DETR}} & \multicolumn{4}{c|}{\textbf{RetinaNet}} \\
% \cline{2-9}
% & \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} & \textbf{\textit{mAP}} & \textbf{\textit{mAP\_50}} & \textbf{\textit{mAP\_75}} & \textbf{\textit{Recall}} \\
% \hline
% AMARE\_Week\_1 & 0.260 & 0.791 & 0.040 & 1.000 & 0.715 & 0.996 & 0.844 & 1.000 \\
% AMARE\_Week\_2 & 0.102 & 0.272 & 0.019 & 0.977 & 0.208 & 0.341 & 0.215 & 0.796 \\
% AMARE\_Week\_3 & 0.428 & 0.746 & 0.445 & 1.000 & 0.711 & 0.869 & 0.801 & 1.000 \\
% AMARE\_Week\_4 & 0.344 & 0.649 & 0.335 & 0.739 & 0.582 & 0.755 & 0.645 & 0.979 \\
% AMARE\_Week\_5 & 0.564 & 0.843 & 0.671 & 1.000 & 0.701 & 0.906 & 0.777 & 1.000 \\
% AMARE\_Week\_6 & 0.770 & 0.987 & 0.928 & 0.953 & 0.806 & 0.963 & 0.858 & 0.984 \\
% AMARE\_Week\_7 & 0.678 & 0.865 & 0.731 & 0.979 & 0.734 & 0.920 & 0.753 & 0.988 \\
% AMARE\_Week\_8 & 0.719 & 0.920 & 0.776 & 0.992 & 0.706 & 0.962 & 0.709 & 1.000 \\
% AMARE\_Week\_9 & 0.808 & 0.945 & 0.859 & 0.965 & 0.761 & 0.950 & 0.759 & 0.991 \\
% AMARE\_Week\_10 & 0.850 & 0.974 & 0.915 & 1.000 & 0.858 & 0.998 & 0.947 & 1.000 \\
% AMARE\_Week\_11 & 0.804 & 0.890 & 0.862 & 1.000 & 0.831 & 1.000 & 0.948 & 1.000 \\
% \hline
% \end{tabular}
% }
% \end{table}


\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{figure/result_prediction2.png}
    \vspace{-0.4cm}
    \caption{Comparison of object detection results for ABUTH and DIGSA using DETR and RetinaNet models. Row 1 displays predictions for ABUTH, and Row 2 displays predictions for DIGSA, with ground truth and model confidence scores indicated for each detection.}
    \label{fig:detectionresult}
    \vspace{-0.3cm}
\end{figure}


Tables \ref{setfa_performance}, \ref{amapa_performance}, \ref{abuth_performance}, and \ref{amata_performance} present comprehensive performance comparisons between DETR and RetinaNet across four weed species (SETFA, AMAPA, ABUTH, and AMATA) over 11 weeks. Both models demonstrated high performance across various metrics, including mAP, mAP\_50, mAP\_75, and Recall. RetinaNet generally outperformed DETR, showing more consistent and often higher scores across most species and weeks. For instance, RetinaNet achieved peak mAP scores of 0.843 for SETFA, 0.902 for AMAPA, 0.924 for ABUTH, and 0.968 for AMATA. DETR's highest mAP scores were comparable, reaching 0.859 for SETFA, 0.912 for AMAPA, 0.924 for ABUTH, and 0.905 for AMATA. Both models frequently achieved perfect scores of 1.000 in mAP\_50 and Recall metrics across various weeks and species, indicating excellent detection accuracy at lower IoU thresholds and high object detection rates.\\
However, both models exhibited some performance fluctuations, particularly in the early weeks. DETR often struggled more in the initial weeks, with notably low mAP scores such as 0.355 for SETFA in Week 1, 0.096 for AMAPA in Week 1, and 0.001 for AMATA in Week 1. RetinaNet generally showed more stability, with its lowest mAP scores being higher than DETR's in most cases. For example, RetinaNet's lowest mAP for SETFA was 0.555 in Week 4, for AMAPA it was 0.481 in Week 1, and for AMATA it was 0.529 in Week 2. These early-week challenges could be attributed to factors such as less robust feature extraction, difficulty in detecting small objects, or lower-quality images in the initial stages of plant growth. Despite these early challenges, both models demonstrated significant improvement over time, with peak performances often occurring in later weeks (Weeks 8-11). This trend suggests that as plants matured and image quality potentially improved, both DETR and RetinaNet were able to more accurately detect and classify the weed species.


Figure \ref{fig:detectionresult} shows the prediction result of DETR and RetinaNet model. The top row focuses on ABUTH, where the first image (a) shows the original plant without any annotations, followed by the (b) ground truth with a labeled bounding box indicating "ABUTH week 2." The subsequent images display predictions by (c) DETR and (d) RetinaNet models, each bounding box labeled with the species name, the corresponding week, and the model's confidence score, with RetinaNet showing a slightly higher score (98.6) compared to DETR (94.9). The bottom row repeats this structure for DIGSA, showing the (e) original image, (f) the ground truth ("DIGSA week 5"), and the predictions from (g) DETR and (h) RetinaNet. For DIGSA, the confidence scores are close, with DETR predicting 90.1 and RetinaNet predicting 93.9, both models accurately detecting the plant but with varying degrees of confidence.