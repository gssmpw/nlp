\begin{abstract}
We propose a general and unifying framework for causal Imitation Learning (IL) with hidden confounders that subsumes several existing confounded IL settings from the literature.
% While previous works only considered specific aspects of the causal IL problem, our unifying framework provides a holistic treatment for these problems together. 
% Under our framework, we model the hidden confounders as two parts: an expert observable part, which acts as additional hidden information to the expert; and a confounding noise part, which is also hidden to the expert. 
Our framework accounts for two types of hidden confounders: (a) those observed by the expert, which thus influence the expert's policy, and (b) confounding noise hidden to both the expert and the IL algorithm. 
For additional flexibility, we also introduce 
a \emph{confounding noise horizon} and time-varying expert-observable hidden variables.  
We show that causal IL in our framework can be reduced to a set of Conditional Moment Restrictions (CMRs) by leveraging trajectory histories as instruments to learn a history-dependent policy. We propose DML-IL, a novel algorithm that uses instrumental variable regression to solve these CMRs and learn a policy. We provide a bound on the imitation gap for DML-IL, which recovers prior results as special cases. 
%and show that the theoretical guarantees of previous work are special cases of our result. 
 Empirical evaluation on a toy environment with continues state-action spaces and multiple Mujoco tasks demonstrate that DML-IL outperforms state-of-the-art causal IL algorithms. 
\end{abstract}