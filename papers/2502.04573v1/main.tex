%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% my additions
\usepackage{bm}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage[english]{babel}

\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\argmax}{arg\,max}
\newcommand{\indep}{\perp\!\!\!\!\perp} 

\usepackage{tikz}
\usetikzlibrary{fit,positioning,backgrounds}

\newcommand{\circo}{~\raisebox{1pt}{\tikz \draw[line width=0.6pt] circle(1.2pt);}~}

%\setcitestyle{square}
%\setcitestyle{numbers}

\newcommand{\customfootnotetext}[2]{{% Group to localize change to footnote
\renewcommand{\thefootnote}{#1}% Update footnote counter representation
\footnotetext[0]{#2}}}% Print footnote text

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

\allowdisplaybreaks

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Adversarially Pre-trained Transformer}

\begin{document}

\twocolumn[
\icmltitle{Zero-shot Meta-learning for Tabular Prediction Tasks\texorpdfstring{\\}{}with Adversarially Pre-trained Transformer}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
%\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Yulun Wu}{yyy}
\icmlauthor{Doron L. Bergman}{comp}
% \icmlauthor{Firstname1 Lastname1}{equal,yyy}
% \icmlauthor{Firstname2 Lastname2}{equal,yyy,comp}
% \icmlauthor{Firstname3 Lastname3}{comp}
% \icmlauthor{Firstname4 Lastname4}{sch}
% \icmlauthor{Firstname5 Lastname5}{yyy}
% \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
% \icmlauthor{Firstname7 Lastname7}{comp}
%\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
%\icmlauthor{}{sch}
%\icmlauthor{}{sch}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{University of California, Berkeley}
\icmlaffiliation{comp}{Capital One}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

\icmlcorrespondingauthor{Yulun Wu}{yulun\_wu@berkeley.edu}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@xxx.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{
    % \icmlEqualContribution
} % otherwise use the standard text.

\begin{abstract}
    We present an Adversarially Pre-trained Transformer (APT) that is able to perform zero-shot meta-learning on tabular prediction tasks without pre-training on any real-world dataset, extending on the recent development of Prior-Data Fitted Networks (PFNs) and TabPFN. Specifically, APT is pre-trained with adversarial synthetic data agents, who continue to shift their underlying data generating distribution and deliberately challenge the model with different synthetic datasets. In addition, we propose a mixture block architecture that is able to handle classification tasks with arbitrary number of classes, addressing the class size limitation -- a crucial weakness of prior deep tabular zero-shot learners. In experiments, we show that our framework matches state-of-the-art performance on small classification tasks without filtering on dataset characteristics such as number of classes and number of missing values, while maintaining an average runtime under one second. %We show that on regression tasks, where PFN-based models have not shown great performance, APT has made significant progress over TabPFN. 
    On common benchmark dataset suites in both classification and regression, we show that adversarial pre-training was able to enhance TabPFN's performance. In our analysis, we demonstrate that the adversarial synthetic data agents were able to generate a more diverse collection of data compared to the ordinary random generator in TabPFN. In addition, we demonstrate that our mixture block neural design has improved generalizability and greatly accelerated pre-training.% In ablation study, we present statistics on the contribution of each proposed components above.
\end{abstract}

\section{Introduction}
\label{sec:intro}

In standard deep learning workflows, models are trained per dataset, and expect data in a form compatible with, and drawn from, the same distribution as the dataset it was trained on during inference time. Even in transfer learning, where the output of the model is changed, the input is at most expanded, but at least overlaps heavily with the data distribution the model was trained on. This is in contrast with meta learning \citep{finn2017model, nichol2018reptile, lemke2015metalearning, vanschoren2018meta, feurer2022auto, hospedales2021meta, JMLR:v22:21-0657}, where a model is trained to be adaptive to new datasets such that few gradient updates or fine-tuning are needed, instead of training a new model specialized to every distinct dataset from scratch. In meta learning, rather than modeling a specific dataset, the model is trained to learn how to learn. This has multiple advantages. First, meta learning is highly adaptable \citep{huisman2021survey, finn2017model, frans2021population} -- it learns more generalized models, since it is not specialized to modeling only one dataset. Due to this flexibility, meta learning systems can quickly adapt to new tasks and different domains. Second, meta learning makes efficient use of data \citep{finn2017model, gevaert2021meta} -- it supports learning from just a few samples. Third, as a consequence of its efficient use of (small) data, it can learn and reach a point where it can make meaningful predictions very quickly \citep{vanschoren2018meta}. %Fourth, there is no hyper-parameter tuning, and thus no need for cross-validation holdouts, avoiding the challenges of data leakage.

% \textcolor{blue}{Add that no cross validation is not used, and our real datasets have could have zero overlap with training data. DONE}

In prior work, \citet{verma2020meta} discussed the notion of zero-shot meta-learning. They train a generative adversarial network conditioned on class attributes, that can generate novel (previously unseen) class samples. This relies on the inputs present in the training data (class attributes) to be indicative of the new unseen classes. While they do not use gradient updates on the unseen data for prediction, they rely on the input data coming at the very least from a very similar distribution to that of the training data. The scope of problems this work aims to address is pristine zero-shot meta learning: given an unseen dataset from an unseen task after the model is pre-trained and deployed, can we do prediction on this dataset without training the model on it? Specifically, with zero gradient update on the model, and with no reliance on the similarity between this dataset and the datasets that the model was pre-trained on. Note that this concept of zero-shot is slightly different from that in large vision and language models \citep{mann2020language, perez2021true, tsimpoukelli2021multimodal, cahyawijaya2024llms, ahmed2022few} -- the unseen datasets can entail heterogeneous fields or class labels that were never observed during pre-training, and zero-shot in this context refers to the amount of model optimization conducted being zero given the unseen dataset rather than the amount of empirical examples seen being zero. The advantage of successfully establishing such a model is the exceptional generalizability and runtime.

% In other words, not only are the target variables different, the input types are different as well.

A few recent breakthroughs \citep{muller2021transformers, hollmann2022tabpfn} have demonstrated that achieving this aspiration is possible: \citet{muller2021transformers} introduced Prior-Data Fitted Networks (PFNs). These are transformers pre-trained on synthetic data generated from a prior distribution, to perform approximate Bayesian inference in a single forward pass using in-context learning \citep{luo2018neural, mann2020language}. PFNs do not fit a model on downstream training data, instead feeding training data into the context and conditioning on the context.
\citet{hollmann2022tabpfn} introduced a PFN specifically aimed at tabular datasets -- TabPFN. A detailed background review on PFNs and specifically TabPFN can be found in Appendix \ref{sec:background}.
Tabular data -- data organized in rows and columns, and characterized by an unlimited heterogeneity of data fields, remains an area of machine learning where deep neural networks (DNNs) still struggle \citep{borisov2022deep, shwartz2022tabular, mcelfresh2024neural, DBLP:journals/corr/abs-2407-00956} to push the boundaries of the state-of-the-art gradient boosted decision trees (GBDTs) \citep{prokhorenkova2018catboost, chen2016xgboost, ke2017lightgbm}, despite numerous approaches \citep{borisov2022deep, somepalli2021saint, grinsztajn2022tree, gorishniy2021revisiting, rubachev2022revisiting, levin2022transfer, kadra2021well, arik2021tabnet, popov2019neural}. Yet, tabular data is one of the most common data types in real-world machine learning (ML) applications \citep{chui2018notes, borisov2022deep, shwartz2022tabular}. %The quest to to apply deep learning methods to tabular data remains an active area of research.
Although TabPFN has demonstrated exceptional zero-shot meta-learning capability on certain small tabular prediction tasks, we show that the distribution of synthetic data used in its pre-training is actually quite limited. Besides, the class size constraints of TabPFN poses a significant limitation on its generalizability -- this might not be an important concern for the traditional one-model-for-one-domain pipeline, but is a crucial weakness for a zero-shot meta-learner (ZSML) since an unprecedented number of class labels could be present in inference time. Note that zero-shot meta-learning is largely similar to foundation modeling but slightly different in its scale and objective -- it does not necessarily involve billions of parameters to learn the distribution of data in a broad domain such as language or health records and acquire token representations, but to model the general prediction logic and learn how to acquire data representations in unseen domains during inference time.



% TODO: less talking about TabPFN so much, add mych like TuneTables referenves to the other deep leaning methods
% drop talking about zero shot, instead talk about meta learning.
% spend only 1-2 sentences describing TabPFN.

Similar to \citet{hollmann2022tabpfn}, we investigate the capability of zero-shot meta-learning under the scope of tabular data prediction problems. Our contributions are listed as follow:
\begin{itemize}
    \item We propose an adversarial synthetic data pre-training approach on PFNs to establish a zero-shot meta-learner that is able to handle tabular prediction tasks with improved performance.
    \item We eliminated the class size limitation for TabPFN on classification tasks by proposing the mixture block neural design, which yields a zero-shot meta-learner with better generalizability.
    \item In experiments, we show that our framework achieves state-of-the-art performance on small tabular classification tasks without filtering on class size, feature size, number of categorical features or number of missing values, and improved upon TabPFN in both classification and regression. We show that the adversarial data agents are able to enrich the synthetic data generating distribution, and the mixture block is able to generalize to unseen class size and accelerate pre-training.
\end{itemize}

Related work can be found in Section \ref{sec:related-work} and a background review can be found in Appendix \ref{sec:background}.


\section{Proposed Method}

Our Adversarially Pre-trained Transformer (APT) model is pre-trained once offline using a mix of random synthetic data generators and adversarial synthetic data agents. In this phase, the goal of the model is not to learn the specific pattern or probability distribution of any given dataset, but to learn the general prediction logic and means to represent various data, i.e. learning to learn. Once pre-trained and deployed, the model makes predictions on the testing set of any real-world dataset of interest in one forward pass, without performing any back-propagation or gradient updates of its weights. A demonstration of the workflow is shown in Figure~\ref{fig:model-workflow}. In Section~\ref{sec:adversarial-data-agents}, we describe the adversarial data agents in detail, whose goal is to continuously produce diverse and more challenging datasets for the meta-learning model during pre-training; in Section~\ref{sec:transformer-architecture}, we elaborate on the architecture of our transformer model, which has no restrictions on the class size of any real-world datasets practitioners provide.

\begin{figure*}
    \centering
    \includegraphics[width=0.9\textwidth]{Figure/workflow.png}
    \caption{The model workflow of Adversarially Pre-trained Transformer (APT). Pre-training is done once, offline, with datasets generated by a mix of random synthetic data generators and adversarial synthetic data agents. The train-test split is randomly sampled for each batch of datasets. After the model is pre-trained and deployed, predictions are done per real-world dataset, online, with one forward pass and no parameter update. The transformer is test-masked, meaning that each token only attends to training data tokens. For cleanliness of the figure, only the attentions to and from the first training data token and the first testing data token are plotted.}
    \label{fig:model-workflow}
\end{figure*}

\subsection{Adversarial Data Agents}
\label{sec:adversarial-data-agents}


In the pre-training phase, we compose a batch of $m$ datasets $\{X^{(k)}, \boldsymbol{y}^{(k)}\}_{1 \leq k \leq m}$ in each iteration using $m$ different data generators $\{g_1, \dots, g_m\}$ that each independently generate $n$ number of data points, where $X^{(k)} = [\boldsymbol{x}^{(k)}_i]^\top_{i \leq n} = [x^{(k)}_{i, j}]_{i \leq n, j \leq d_k}$ and $\boldsymbol{y}^{(k)} = [y^{(k)}_i]^\top_{i \leq n}$ are the predictor matrix and response vector (denoted as $X$ and $\boldsymbol{y}$ when no index is specified) with feature size $d_k$. We adopted the multi-layer perceptron (MLP) construction introduced in \citet{hollmann2022tabpfn} for each generator instance, where predictors $\boldsymbol{x}^{(k)}_i$ and response $y^{(k)}_i$ are values of randomly selected neurons in sparsified noisy MLPs with some additional pre-processing. More details regarding this approach can be found in Appendix~\ref{sec:background-generator}. 

Different from \citet{hollmann2022tabpfn}, instead of generating datasets solely from randomly initialized sparse MLPs, a subset of the $m$ generators in our framework are adversarial agents that learn from the model's performance on the generated data, and perform gradient \textit{ascent} on the model's prediction loss. In other words, these adversarial agents challenge the model by constantly shifting the synthetic data generating distributions to deliberately produce datasets that are more difficult for the model to handle. %\textcolor{blue}{in the manner most difficult for the model to handle.} \textcolor{gray}{in a directed manner if the model becomes too good at predicting the data they currently generate.} 
The loss for an adversarial agent $g_\eta$ with respect to prediction model $q_\theta$ can be written as
\begin{align}
    \label{eq:gen-loss}
    \mathcal{L}(g_\eta) = \mathbb E_{X,\boldsymbol{y} \sim g_\eta} \log q_\theta(\boldsymbol{y}_{(l+1):n} | X_{(l+1):n}, \{X_{1:l}, \boldsymbol{y}_{1:l}\})
\end{align}
where $\{X_{1:l}, \boldsymbol{y}_{1:l}\}$ and $\{X_{(l+1):n}, \boldsymbol{y}_{(l+1):n}\}$ are the training and testing set split from generated dataset $\{X, \boldsymbol{y}\}$ at position $l$. In the following sections, we refer to the former (generators based on randomly initialized MLPs) as ordinary data generator, and the latter (generators based on adversarially updated MLPs) as adversarial data agents.

\paragraph{Relation to Classic Adversarial Training} In relation to GANs \citep{goodfellow2014generative}, the data agents here are the generators, and the meta-learner is the discriminator. Contrary to classic adversarial training, there is no real versus fake samples for the discriminator to distinguish in this context. The generator (data agent) and the discriminator (meta-learner) have one coherent competing objective: the meta-learner seeks to minimize the prediction loss on data generated by the data agents, while the data agent seeks to generate data that maximize the prediction loss by the meta-learner. As a result, the desired gradients for updating the discriminator is but a flip of sign to its gradients calculated through back propagation on the generator's objective. Hence, both the meta-learner and the data agents can be updated in one single iteration after loss calculation in this scenario. This results in a more efficient adversarial training, and we further reduce its potential of mode collapse with data agent reset described in the last paragraph of this section. Note that contrary to classic GANs, the discriminator is the final product in this context rather than the generator.

\begin{figure*}
  \centering
  \subfigure[Model architecture for classification tasks]{\label{fig-model-workflow}\includegraphics[width=0.66\linewidth]{Figure/model_workflow.png}}
  \subfigure[Mixture block]{\label{fig-mixture-block}\includegraphics[width=0.33\linewidth]{Figure/mixture_block.png}}
  \caption{Model architecture and the mixture block. a) $X = (X^\mathrm{train}, X^\mathrm{test})$ and $\boldsymbol{y}^\mathrm{train}$ are embedded on $\mathbb R^{d_\mathrm{model}}$ using a feature embedding block and linear projection respectively. Then, embeddings for $X^\mathrm{train}$ and $\boldsymbol{y}^\mathrm{train}$ are added as $\boldsymbol{h}^\mathrm{train}$, embeddings for $X^\mathrm{test}$ are denoted as $\boldsymbol{h}^\mathrm{test}$. Embeddings $(\boldsymbol{h}^\mathrm{train}, \boldsymbol{h}^\mathrm{test})$ are then passed to the transformer blocks with attention towards test embedding $\boldsymbol{h}^\mathrm{test}$ masked, same as \citet{hollmann2022tabpfn}. Finally, the outputs from transformer blocks are transformed to class probabilities through the mixture block for classification tasks, or directly transformed to point predictions through standard MLP final layer for regression tasks. b) For each data point in the testing set, we use its output $q$ after transformer blocks to query training data's outputs $K$. With two different MLP projection layers, two set of logits are predicted: one set of logits are used to calculate the scaled softmax probabilities -- these probabilities indicate how likely that the testing point is in the same class as the corresponding training points; the other set of logits are used to sample soft-discrete binary gates via Concrete distribution to sparsify these probabilities. Finally, the gated probabilities from the same class are added together to yield the final predictions.}
  \label{fig:transformer-architecture}
\end{figure*}

\paragraph{Discretization of Variables} A key challenge in establishing adversarial data agents is the gradient flow under discretization: how do we generate synthetic data with categorical features while being able to perform end-to-end loss back-propagation? Inspired by the Gumbel-Softmax trick~\citep{jang2016categorical} and the Concrete distribution~\citep{maddison2016concrete}, we propose a continuous relaxation of discretization that naturally extends on the ranking discretization approach introduced in \citet{hollmann2022tabpfn}, controlled by a user-specified temperature hyperparameter $\tau$. For the $j$-th feature column $\boldsymbol{x}_{\cdot, j}$ of a predictor matrix $X$ and the corresponding $N_j - 1$ randomly sampled Gaussian quantiles $Q^{(1)}_j < Q^{(2)}_j < \dots < Q^{(N_j - 1)}_j$ at the initialization of the corresponding data agent, the soft-discretization that converts the $i$-th value of the $j$-th feature $x_{i, j}$ to a soft-categorical value with cardinality $N_j$ is given by
\begin{align}
    \label{eq:discretization}
    &x^{cat}_{i, j} = \pi\left( \left\lvert \left\{x_{i, j} \geq \tilde{Q}^{(l)}_j \right\}_l \right\rvert \right) + \\
    &\,\,\,\, \tau \cdot \log\left( 1 + \frac{x_{i, j} - \tilde{Q}^{\left( \left\lvert \left\{x_{i, j} \geq \tilde{Q}^{(l)}_j \right\}_l \right\rvert \right)}_j}{\tilde{Q}^{\left(1 + \left\lvert \left\{x_{i, j} \geq \tilde{Q}^{(l)}_j \right\}_l \right\rvert \right)}_j - \tilde{Q}^{\left( \left\lvert \left\{x_{i, j} \geq \tilde{Q}^{(l)}_j \right\}_l \right\rvert \right)}_j} \right) 
\end{align}
where $\pi$ is a permutation function on integer domain $\{1, 2, \dots, N_j - 1\}$, $\tilde{Q}^{(l)}_j = \mu(\boldsymbol{x}_{\cdot, j}) + \sigma(\boldsymbol{x}_{\cdot, j}) \cdot Q^{(l)}_j $ for $1 \leq l < N_j$ are the unnormalized quantiles with boundaries $\tilde{Q}^{(0)}_j = \min(\boldsymbol{x}_{\cdot, j})$ and $\tilde{Q}^{(N_k)}_j = \max(\boldsymbol{x}_{\cdot, j})$, and $\lvert \{v \geq \tilde{Q}^{(l)}_j \}_l \rvert = \sum_l I( v \geq \tilde{Q}^{(l)}_j )$ is the position of a value $v$ in the ordered sequence $\{\tilde{Q}^{(l)}_j\}_{1 \leq l \leq N_j}$. A visual demonstration of this conversion can be found on the right side of Figure~\ref{fig:discrete-conversion} in the Appendix. Same as \citet{hollmann2022tabpfn}, the extended ranking discretization approach decides the value of a categorical variable using only the continuous scalar $x_{i, j}$, i.e. the value of one neuron in the sparsified noisy MLP, as opposed to the Gumbel-Softmax or Concrete distribution approach which would require selecting $N_j$ neurons as logits of the $N_j$ classes. In our early experiments, we found that sampling multiple neurons to decide the value of one categorical feature achieved significantly worse performance than ranking discretization. Furthermore, since we do not desire to learn the explicit form of these distributions, explicitly generating class logits is not a necessity, and hence we prefer a more efficient differentiable discretization technique that does not involve reparameterization tricks, softmax operations or excessive samplings.

\paragraph{Data Agent Reset} In terms of the diversity of generated data, there is a balance between adversarially updating the neurons in the MLPs and re-initializing the MLPs all together. Although in the short run, re-initializing the MLPs and the corresponding random factors (number of features, number of classes, etc.) instantaneously yield new datasets with a high chance of possessing much different fields and distributions from the previous, such generation is constrained by the domain of distribution defined by the preset range of hyperparameters in the long run (we show some evidence on this in Section \ref{sec:exp-data-agent}). On the other hand, although adversarial data agents are performance-driven and could explore out-of-distribution regions better than random initialization, it also has the potential to converge to the Nash equilibrium and reach a stalemate with the meta-learner -- for example, converging to a state where generated predictors $x$ and response $y$ have no correlation. Hence, we combine the two approaches and reset the adversarial data agents every $N_e$ epochs to avoid such convergence. To speak from the GANs angle, we are letting the discriminator, i.e. the meta-learner, to periodically gain an advantage and slightly beat the generator. Different from classic GANs, the discriminator is the desired model here while the generator is the supporting entity, hence exploration is more important than optimization for the generator in this context.



\subsection{Mixture Block Architecture}
\label{sec:transformer-architecture}

%The main transformer embedding blocks $q_\theta: \mathbb{R}^{d_\mathrm{model}} \rightarrow \mathbb{R}^{d_\mathrm{model}}$ have the standard architecture of alternating multi-head attentions and feedforwards, with residual connections and layer normalization \citep{vaswani2017attention}. The novelty of our architecture lies in the design of feature embedding layer and output prediction head, which enables the meta-learner to adapt to datasets provided by practitioners, with no theoretical limitation on feature size and class size (for classification tasks). An overview of the architecture can be found on the left of Figure~\ref{fig:transformer-architecture}.

%\paragraph{Patch-based Feature Embedding} We drew inspiration from \citet{DBLP:journals/corr/abs-2010-11929} and propose a patch-based approach that adapts to datasets with arbitrary number of predictors. In \citet{hollmann2022tabpfn}, embeddings of $x$ are acquired by padding or clipping the number of features $d$ to a certain maximum feature size $d^*$, such that $x$ can be fed to a MLP embedding layer $e_\theta: \mathbb{R}^{d^*} \rightarrow \mathbb{R}^{d_\mathrm{model}}$. Instead, we split features to patches setting $d^*$ as the patch size, and pad only the last patch to $d^*$ dimensions if $d \not\equiv 0 \pmod{d^*}$. After feeding each patch to MLP layer $e_\theta$, we pass them to an attention block and average pool across the resulting embeddings of patches. Essentially, this is a half-way approach between using a fixed MLP embedding layer for all features and using an attention block tokenizing each individual feature. In this way, the embedding block can handle features in a more flexible manner while controlling computational complexity and memory usage.

Contrary to modern deep neural networks, traditional ML algorithms such as K-nearest neighbors and tree-based methods are more flexible in terms of their ability to handle varying cardinality of classification labels, in the sense that they do not entail fixed-size MLP parameters that cannot generalize to a different classification task with different label cardinality. This is not much of an issue for the traditional one-model-for-one-dataset ML pipeline, but is of significant importance for zero-shot meta-learners, yet unaddressed in prior works. Inspired by how tree-based methods solve classification tasks in a manner that is compliant to the empirical values and cardinality of training labels, we propose a scatter-sum mixture block as the output prediction head for classification tasks that significantly departs from the ordinary MLP final layer approach. A visual demonstration can be found on the right of Figure \ref{fig:transformer-architecture}. For each data point in the testing set, we use its embedding after the transformer blocks to query the embeddings of training data, and yield two sets of logits via two separate feedforwards: one set of logits is used to calculate softmax probability weights of keys and the other set is used to sample soft-discrete gates via Concrete distribution~\citep{maddison2016concrete} to sparsify these weights. In essence, these gates govern the splits of training data in relation to the testing query, such that the final prediction only pays attention to a subset of relevant training data representations. In our preliminary experiments, we discovered that sparsifying attention through these gates are crucial to performance, and the mixture block works poorly without this component. The output class probabilities are then acquired by a scatter summation of non-gated values using their original labels as index. Relating to tree-based methods, the gates here are used to determine the subset of training data that are in the same split of leaf nodes as a given testing data point, and the weights are used to determine the relative importance of each label in that split. Contrary to tree-based methods, the splits are point-specific, i.e. there is a different split decided for each testing data point, and the decision within the split is weighted rather than via majority voting. Note that this approach does not change the order of computation complexity in terms of data size and data dimensions -- it simply removes the final MLP layer and adds two more multi-head attentions and feedforwards to the transformer architecture in a non-sequential manner.


\section{Experiment}
\label{sec:experiment}

\begin{table*}%[ht!]
  \caption{Performance of algorithms on 35 small datasets with no larger than 2,000 data points in the OpenML-CC18 suite, given one hour of time budget. Note that there are two styles of standard deviation (std.) calculation for AUC: 1) first take the mean of AUC across datasets, then calculate the std. across splits (std. of mean), as used by TabPFN \citep{hollmann2022tabpfn}; 2) first calculate the std. across splits on each dataset, then take the mean across datasets (mean of std.), as used by TabZilla \citep{mcelfresh2024neural}. Our result table largely adopted the style of TabZilla, but we present both std.'s here for clarity. The std. of mean shows variation on suite level, which is more likely to result in a statistical significance compared to mean of std., which shows average variation on dataset level. The mean of AUC taken across splits are used as the scoring metric to calculate ``Rank'' and ``Wins'' of each algorithm across datasets. If many algorithms are tied for first, a win is assigned to each first-place algorithm. Same as TabZilla \citep{mcelfresh2024neural}, the table is ordered by the mean of rank. The full results on each dataset for top algorithms are shown in Table \ref{result-datasets-35} of Appendix \ref{sec:more-results}.}
  \label{result-apt-vs-rest}
  \centering
  %\scriptsize % #final-version
  \resizebox{\textwidth}{!}{
      \begin{tabular}{lrrrrrrrrrrr}
        \toprule
        & \multicolumn{4}{l}{\multirow{ 2}{*}{Rank $\downarrow$}} & \multicolumn{3}{l}{\multirow{2}{*}{ROC-AUC $\uparrow$}} & \multicolumn{1}{l}{\multirow{2}{*}{Wins $\uparrow$}}  & \multicolumn{2}{l}{Time (sec.) $\downarrow$} \\
        & \multicolumn{4}{l}{} & \multicolumn{3}{l}{} & \multicolumn{1}{l}{}  & \multicolumn{2}{l}{(Tune + Train + Predict)} \\
        \cmidrule(lr){2-5} \cmidrule(lr){6-8} \cmidrule(lr){9-9} \cmidrule(lr){10-11}
        & mean & med. & min & max & mean & std. of mean & mean of std. & num. & mean & med. \\
        \midrule
        APT & \textbf{3.86} & \textbf{3} & \textbf{1} & 11 & \textbf{0.921} & 0.003 & 0.019 & \textbf{13} & 0.90 & 0.40 \\ 
        CatBoost & 4.03 & 4 & \textbf{1} & \textbf{9} & 0.918 & 0.002 & 0.020 & 6 & 3542.42 & 3555.74 \\ 
        TabPFN & 4.57 & 4 & \textbf{1} & 11 & 0.913 & 0.003 & 0.020 & 4 & \textbf{0.86} & \textbf{0.37} \\ 
        SVM & 4.89 & 4 & \textbf{1} & 12 & 0.904 & 0.003 & 0.023 & 10 & 1175.58 & 481.50 \\ 
        XGBoost & 5.37 & 5 & \textbf{1} & 10 & 0.914 & 0.006 & 0.020 & 4 & 3607.78 & 3598.91 \\ 
        LightGBM & 5.60 & 6 & \textbf{1} & 11 & 0.917 & 0.003 & 0.019 & 3 & 3542.94 & 3582.07 \\ 
        LASSO-Logistic & 6.69 & 8 & \textbf{1} & 12 & 0.908 & 0.001 & 0.023 & 3 & 1519.41 & 1227.52 \\ 
        Ridge-Logistic & 6.91 & 8 & \textbf{1} & 11 & 0.907 & 0.001 & 0.022 & 1 & 1479.93 & 845.59 \\ 
        RandomForest & 7.17 & 7 & \textbf{1} & 12 & 0.908 & 0.003 & 0.021 & 3 & 1736.71 & 1476.37 \\ 
        ResNet & 7.69 & 9 & \textbf{1} & 12 & 0.825 & 0.004 & 0.040 & 3 & 3582.15 & 3597.41 \\ 
        KNN & 9.57 & 11 & \textbf{1} & 12 & 0.884 & 0.006 & 0.024 & 1 & 127.82 & 77.31 \\ 
        SAINT & 9.97 & 12 & \textbf{1} & 12 & 0.759 & 0.017 & 0.077 & 1 & 3597.41 & 3594.41 \\
        \bottomrule
      \end{tabular}
  }
\end{table*}


We evaluated our model and competing algorithms on common ML benchmarking dataset suites for tabular classification and tabular regression problems. In Section \ref{sec:exp-classification}, we show that APT achieves state-of-the-art performance on small tabular classification tasks with a runtime comparable to that of TabPFN. In Section \ref{sec:exp-data-agent}, we present qualitative analysis on the impact and characteristics of the adversarial data agents. In Section \ref{sec:exp-mixture-block}, we demonstrate the generalizability of the mixture block and its effect on pre-training. In Section \ref{sec:exp-ablation}, we provide ablation study and show that adversarial pre-training was able to enhance the performance of TabPFN on both classification and regression tasks.

\paragraph{Datasets} For classification, we used the curated open-source OpenML-CC18 dataset suite \citep{bischl2021openml} containing 68 popular tabular benchmark datasets (4 vision datasets \textit{mnist\_784}, \textit{CIFAR\_10}, \textit{Devnagari-Script}, and \textit{Fashion-MNIST} are not treated as tabular and removed from the total 72 datasets), and our main results are presented on all small datasets (number of samples no larger than 2,000) in OpenML-CC18 similar to \citet{hollmann2022tabpfn}, except that 1) there is no additional filtering, i.e. all datasets regardless of number of classes, number of features, number of categorical features, and number of missing values are kept in our evaluation pool, composing a more general collection of datasets. This brings the number of datasets in the evaluation pool from 18 to 35; 2) The train-test split is set to 80-20 instead of the unconventional 50-50. For regression benchmarking, we used the curated open-source OpenML-CTR23 dataset suite \citep{fischer2023openml}.

\paragraph{Algorithms} We compared APT to the top 3 GBDT algorithms (CatBoost \citep{prokhorenkova2018catboost}, XGBoost \citep{chen2016xgboost}, LightGBM \citep{ke2017lightgbm}) and the top 3 DNN methods (TabPFN \citep{hollmann2022tabpfn}, Tabular ResNet \citep{gorishniy2021revisiting}, SAINT \citep{somepalli2021saint}) in the main experiments of TabZilla \citep{mcelfresh2024neural}, as well as 5 standard machine learning algorithms (KNN \citep{cover1967nearest}, Ridge \citep{tikhonov1963solution}, LASSO \citep{tibshirani1996regression}, SVM \citep{cortes1995support}, Random Forest \citep{ho1995random}).

\paragraph{Hyperparameters} The hyperparameter search space of benchmark models is directly inherited from \citet{hollmann2022tabpfn}, and directly inherited from \citet{mcelfresh2024neural} if the benchmark model is not in \citet{hollmann2022tabpfn}. TabPFN is pre-trained with hyperparameters directly inherited from their released checkpoint, only changing the maximum number of classes from 10 to 26, which is the maximal class size of datasets in the OpenML-CC18 suite. For APT, all common hyperparameters shared with TabPFN are directly inherited from TabPFN. See Appendix \ref{sec:hyperparameter-settings} for more details. A total of $12.5\%$ of the data generators are adversarial data agents during the pre-training of APT, with learning rate $10^{-1}$, weight decay $10^{-5}$, soft-discretization temperature $10^{-2}$, and $2,000$ gradient steps between resets.


\subsection{APT Achieves State-of-the-art Performance on Small Tabular Classification Tasks}
\label{sec:exp-classification}

\begin{figure*}
  \centering
  \subfigure[Distribution of data in datasets generated by a set of ordinary data generators]{\label{fig-random-data-1}\includegraphics[width=0.32\linewidth]{Figure/adversarial_data/output1.png}}
  \subfigure[Distribution of data generated by another independent set of ordinary generators]{\label{fig-random-data-2}\includegraphics[width=0.32\linewidth]{Figure/adversarial_data/output2.png}}
  \subfigure[Distribution of data generated by a set of adversarial data agents]{\label{fig-adversarial-data}\includegraphics[width=0.32\linewidth]{Figure/adversarial_data/output3.png}}
  \caption{Contour plot of two-dimensional data generated by ordinary data generators and adversarial data agents. Each subplot contains a total of 100,000 data points from 2,000 datasets. Note that subplot (a) and subplot (b) are two independent sets of ordinary generators with no mutual, as each dataset is generated by an independently initialized random sparse neural network. Each dataset in subplot (c) is generated by an adversarial data agent after each consecutive loss back-propagation.}
  \label{fig:adversarial-data}
\end{figure*}

We evaluated APT and benchmark models on small datasets in OpenML-CC18 using area under the receiver operating characteristic curve (ROC-AUC) with the one-vs-one (OVO) multi-class evaluation configuration, similar to \citet{hollmann2022tabpfn}. Previously, \citet{hollmann2022tabpfn} has shown that TabPFN matches the performance of state-of-the-art GBDT algorithms and outperforms them on small datasets that have less than 100 features, less than 10 classes, no categorical features, and no missing values in their main results. In this work, we do not impose any of these restrictions to further examine APT's and TabPFN's zero-shot meta-learning capability. The results are presented in Table \ref{result-apt-vs-rest}. For datasets with number of features larger than 100, we subsample 100 features similar to \citep{mcelfresh2024neural}. In these experiments, APT achieved state-of-the-art performances with a runtime similar to that of TabPFN. The average runtime of APT increased by $4.6\%$ compared to TabPFN and remained within a second on GPU (NVIDIA H100), showing that neural modifications from the mixture block have not made APT significantly heavier. Note that there is no cherry-picking being performed on model checkpoints for APT -- the APT model that we released and used for evaluations is the last model after the final iteration of pre-training. Realistically, PFN-based models are pre-trained on synthetic data, and picking checkpoints for evaluations ad hoc is not ideal unless using a whole different collection of real-world datasets for validation. But even in that case, it would still raise the concern of data leakage.

%#final-version
% Note that we perform validation across 32 permutations for both APT and TabPFN instead of simply averaging across 32 permutations as in \citet{hollmann2022tabpfn}. This enhanced the performance of both APT and TabPFN.

In these experiments, the deep learning algorithms under the standard supervised learning pipeline, ResNet and SAINT, yielded subpar performances. Note that the computing budget in \citet{hollmann2022tabpfn} and ours is set to 1 hour per dataset per split contrary to the 10 hours in \citet{mcelfresh2024neural}. The deep learning algorithms under the zero-shot meta-learning pipeline, APT and TabPFN, yielded ideal performances, but it has been previously shown that TabPFN sees a significant drop in performance on datasets with categorical features or missing values \citep{hollmann2022tabpfn}. In Figure \ref{fig:cat_miss_analysis}, we further break down the results on datasets with and without these characteristics.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.98\linewidth]{Figure/rank_cat_miss.png}
  \caption{A breakdown of performance by dataset characteristics. The mean of ranks are plotted as orange on datasets with the respective characteristic, and as blue on datasets without the respective characteristic.}
  \label{fig:cat_miss_analysis}
\end{figure}

From Figure \ref{fig:cat_miss_analysis}, it can be observed that APT has fairly dealt with TabPFN's weakness in handling datasets with missing values, and has closened the gap between performance on datasets with and without categorical features compared to TabPFN, although GBDTs such as CatBoost still shows the greatest capability in handling datasets with categorical features. We further break down the performance contributions from each proposed component of the APT framework in Section \ref{sec:exp-ablation}.

%Note that the classification results in Table \ref{result-table-pfn-vs-apt} are shown on all tabular datasets in OpenML-CC18 (68 of 72. Vision datasets CIFAR\_10, Devnagari-Script, Fashion-MNIST, mnist\_784 are removed) instead of the 18 of 72 reported in \citet{hollmann2022tabpfn}, which results in a lower mean accuracy as well as a tighter error band of the mean metrics.

\iffalse
some things to mention:
\begin{itemize}
    \item only difference in evaluation: stopping criteria of `fmin` such that time is more likely to be within max limit.
    \item no repeated pre-training for different splits. This is orthodox and valid for meta-learners as illustrated by \citet{hollmann2022tabpfn}.
\end{itemize}
\fi

\subsection{Qualitative Analysis of the Adversarial Data Agents}
\label{sec:exp-data-agent}

Even though arbitrary MLPs have the potential to serve as universal function approximators given certain regularity constraints \citep{hornik1989multilayer}, the pre-set hyperparameters (e.g. sampling distribution of neurons, sampling distribution of the number of layers, choices of activations, etc.) as well as the lack of gradient updates restrict the family of data distributions that randomly initialized sparse neural networks can put forward in practice. As shown in Figure \ref{fig:adversarial-data}, the distribution of two-dimensional data generated by two whole different sets of random sparse neural networks align fairly precisely with merely 2,000 independent initializations. On the contrary, even without resetting neural architecture and neural parameters, the adversarial data agents still managed to generate a more diverse collection of data and diffuse the concentrated peaks presented in the density distribution of data generated by ordinary data generators. To be exact, for a collection of $2,000$ datasets generated by ordinary data generators, we evaluated a KL-divergence of $0.134 \pm 0.141$ between it and a collection of $2,000$ datasets generated by another set of ordinary data generators, and a KL-divergence of $0.813 \pm 0.072$ between it and a collection of $2,000$ datasets generated by adversarial data agents.

As a motivation of imposing data agent reset, we were wary that the data agents after many adversarial updates could yield synthetic datasets whose features have little to no signal on the response variable. With our hyperparameter settings, we have not observed such behavior and to our surprise, the synthetic datasets generated by adversarial agents exhibit slightly stronger signal with a Pearson correlation of $0.311 \pm 0.026$ between predictors and responses on datasets with two-dimensional features as oppose to the $0.268 \pm 0.013$ of ordinary data generators. We postulate that this is partially in consequence of the high reset frequency and high generator learning rate.

\subsection{Generalizability of the Mixture Block}
\label{sec:exp-mixture-block}

After a ZSML is deployed, one should not be required to re-do its pre-training given certain characteristics of the datasets in evaluation pool that the model cannot handle, and this is why the mixture block architecture is important. For TabPFN, we have to look at the evaluation dataset pool first, calculate the largest class size, before using it as a hyperparameter for pre-training. This is not a procedure that fits well into the zero-shot learning concept. Our proposed mixture block architecture does not have such class size limitation, and we show the performance of APT on datasets with more than $10$ classes in OpenML-CC18 in Table \ref{result-table-mixture-generalize}.

\begin{table}[ht!]
  \caption{The ROC-AUC on datasets with more than $10$ classes. APT pre-trained on datasets with a maximum of $10$ classes is able to match APT without mixture block pre-trained on datasets with a maximum of $26$ classes on 3 of the 4 datasets.}
  \label{result-table-mixture-generalize}
  \centering
  \resizebox{0.48\textwidth}{!}{
      \begin{tabular}{lcccc}
        \toprule
        & letter & isolet & vowel & texture \\
        \midrule
        APT w/o Mixture & .975 $\pm$ .002 & .970 $\pm$ .003 & 1 $\pm$ 0 & 1 $\pm$ 0 \\ 
        APT & .975 $\pm$ .002 & .939 $\pm$ .011 & 1 $\pm$ 0 & 1 $\pm$ 0 \\ 
        \bottomrule
      \end{tabular}
    }
\end{table}

Interestingly, the mixture block's generalizability significantly accelerated pre-training in our experiments. The ROC-AUC evaluated after each iteration of pre-training with and without the mixture block is presented in Figure \ref{fig:auc_iter_mixture}. Note that ensembling over permutations \citep{hollmann2022tabpfn} is not performed in this experiment as it would dramatically increase runtime given that evaluation is performed following every gradient step.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.65\linewidth]{Figure/auc_iter_mixture.png}
  \caption{ROC-AUC on the 35 small datasets in OpenML-CC18 evaluated after each of the first 30,000 gradient steps.}
  \label{fig:auc_iter_mixture}
\end{figure}

From Figure \ref{fig:auc_iter_mixture}, we can see that models with mixture block learn remarkably faster than models without it. For APT, the model reaches an AUC of $0.70$ in merely 40 gradient steps, an AUC of $0.80$ in 591 gradient steps and $0.90$ in 11,780 gradient steps.


\subsection{Ablation Study}
\label{sec:exp-ablation}

\paragraph{Classification} Although we discovered that the mixture block gives the model a nice performance acceleration in the previous section, the original purpose of designing such architecture was not performance-driven, and we still expect that the final performance improvement was largely contributed by the adversarial pre-training. We present ablation study in Table \ref{result-table-pfn-vs-apt-classification} to verify this expectation.

\begin{table}[ht!]
  \caption{Ablation study on tabular classification. Note that APT is TabPFN with adversarial pre-training and mixture block.}
  \label{result-table-pfn-vs-apt-classification}
  \centering
  \resizebox{0.48\textwidth}{!}{
      \begin{tabular}{lcccc}
        \toprule
        & \multicolumn{2}{c}{Small} & \multicolumn{2}{c}{All} \\
        \cmidrule(r){2-3} \cmidrule(r){4-5}
        & mean AUC $\uparrow$ & rank $\downarrow$ & mean AUC $\uparrow$ & rank $\downarrow$ \\
        \midrule
        APT & \textbf{0.921} $\pm$ 0.003 & 2.11 $\pm$ 0.16 & \textbf{0.918} $\pm$ 0.006 & \textbf{2.1} $\pm$ 0.2 \\
        APT w/o Mixture & 0.917 $\pm$ 0.005 & \textbf{2.09} $\pm$ 0.06 & 0.917 $\pm$ 0.005 & \textbf{2.1} $\pm$ 0.1 \\
        TabPFN w/ Mixture & 0.914 $\pm$ 0.004 & 2.55 $\pm$ 0.22 & 0.914 $\pm$ 0.005 & 2.6 $\pm$ 0.2 \\
        TabPFN & 0.913 $\pm$ 0.003 & 2.49 $\pm$ 0.16 & 0.914 $\pm$ 0.005 & 2.4 $\pm$ 0.2 \\
        \bottomrule
      \end{tabular}
    }
\end{table}

Unsurprisingly, models with and without the mixture block did not dominate each other on mean AUC and rank collectively. Note that the mixture block was proposed for generalizing on datasets with unseen number of classes, and we expect it to have little to no impact on datasets with seen number of classes performance-wise.

\paragraph{Regression} Although ZSMLs are gradually catching up with GBDTs on classification problems and likely reached a performance mark close to saturation on small classification problems, tabular regression remains an area where ZSMLs have not yet shown exceptional performance. We additionally report a study on the 35 datasets in OpenML-CTR23 regression suite in Table \ref{result-table-pfn-vs-apt-regression}, and show the progress APT has made on regression tasks over TabPFN.

\begin{table}[ht!]
  \caption{Ablation study on tabular regression. Small datasets are the $12$ datasets in OpenML-CTR23 with data size no larger than 2,000. Note that APT is TabPFN with adversarial pre-training in this setting, since the mixture block was only used for classification tasks.}
  \label{result-table-pfn-vs-apt-regression}
  \centering
  \resizebox{0.48\textwidth}{!}{
      \begin{tabular}{lcccc}
        \toprule
        & \multicolumn{2}{c}{Small} & \multicolumn{2}{c}{All} \\
        \cmidrule(r){2-3} \cmidrule(r){4-5}
        & mean MSE $\downarrow$ & wins $\uparrow$ & mean MSE $\downarrow$ & wins $\uparrow$ \\
        \midrule
        TabPFN & 0.412 $\pm$ 0.077 & 3.8 $\pm$ 1.2 & 0.340 $\pm$ 0.025 & 6.4 $\pm$ 1.4 \\
        APT & \textbf{0.344} $\pm$ 0.068 & \textbf{8.2} $\pm$ 1.2 & \textbf{0.306} $\pm$ 0.023 & \textbf{28.6} $\pm$ 1.4 \\
        \bottomrule
      \end{tabular}
    }
\end{table}

From Table \ref{result-table-pfn-vs-apt-regression}, it can be observed that incorporating adversarial pre-training has boosted the performance of TabPFN, yielding a larger number of wins with a significant margin.

%Unfortunately, OpenML-CTR23 only has one dataset whose feature size is larger than $100$, which is the maximum feature size of TabPFN and the patch size of APT, and its feature size $117$ is not much larger than $100$. Therefore, patch embedding is not expected to make a positive impact, if any impact, in this experiment. We hope that more comprehensive regression dataset suites will be proposed in the future to provide more extensive benchmark evaluations. On the other hand, the adversarial pre-training approach has made a more significant impact on tabular regression tasks, with a $16.5\%$ and $10.0\%$ improved MSE on small datasets and all datasets respectively without patch embedding, a $7.9\%$ and $18.8\%$ improved MSE with patch embedding, and a statistically significant improvement on number of wins.

\section{Related Work}
\label{sec:related-work}

\subsection{Tabular Learning}

%\textcolor{blue}{Talk about traditional methods and DNN methods (traditional one-model-for-one-dataset pipeline): About 2 sentences. DONE}

GBDTs such as XGBoost and others \citep{chen2016xgboost, prokhorenkova2018catboost, ke2017lightgbm} are commonly used for tabular data problems, in the traditional one-model-for-one-dataset approach. At this point, numerous deep learning approaches have been developed for tabular data, mostly taking the one-model-for-one-dataset approach \citep{borisov2022deep, somepalli2021saint, grinsztajn2022tree, gorishniy2021revisiting, rubachev2022revisiting, kadra2021well, arik2021tabnet, popov2019neural, arik2021tabnet, kotelnikov2023tabddpm, gorishniy2024tabr, gorishniy2022embeddings, 10.1145/3637528.3671893, kadra2021welltuned, huang2020tabtransformertabulardatamodeling}, but some also venturing into transfer learning, many but not all leveraging large language models to find relevant information for the tabular data problem at hand \citep{levin2022transfer, yan2024making, borisov2023language, ye2024towards, spinaci2024portal, pmlr-v206-hegselmann23a, kim2024carte, zhu2023xtab}.






% Machine learning applied to tabular data traditionally consists of training model from scratch for every distinct dataset. Transfer learning in other domains (vision, language) benefit from having a mostly homogeneous input format (in contrast with tabular data), and have largely solved the challenge of dealing with different prediction target variables. Deep learning methods applied to tabular data have recently made some limited progress on enabling transfer learning between tabular data problems \citet{levin2023transfer}. 



\paragraph{Tabular Meta-Learning} Auto-Sklearn introduced in \citet{feurer-neurips15a} and improved upon in \citet{feurer2022auto} use Bayesian optimization to determine the best algorithm and feature pre-processing steps for modeling a given dataset. Meta learning is used for initializing the Bayesian optimization. In contrast to the approaches of transfer learning in deep tabular data, and of Auto-Sklearn, TabPFN \citep{muller2021transformers} is trained solely on synthetic data to learn how to acquire meaningful data representations and to learn the general prediction logic of tabular classification tasks. A more detailed background review on TabPFN can be found in Appendix \ref{sec:background}. Extensions to TabPFN include \citet{feuer2024tunetables}, where fine tuning was leveraged on top of TabPFN's basic function, to compress incoming data to fit into TabPFN's limitations. \citet{helli2024driftresilient} introduced a variant of TabPFN that was trained on a drifting synthetic data distribution, but the drift is independent of the performance of the model being optimized.

% meta learninf - we define as not having a model specialize to a specifici model, but rather learns how to learn.
%\textcolor{blue}{1 sentence AutoSKLearn, 2 sentences TabPFN (make sure not repetitive of the TabPFN content in introduction. Content in introduction: high-level; content in related work: a little more detailed; content in appendix: very detailed), 2 sentence extensions of TabPFN. Done.}

%AutoGluon \citet{agtabular} uses the ensemble of models available to it, rather than making a specific model and hyper-parameter selection, and incorporates them into one large model, by stacking the ensemble of models into one large deep network.

%Describe TabPFN: About 2 sentences. Do not necessarily have to start from PFNs. You can describe TabPFN directly. \textcolor{gray}{PFNs \citep{muller2021transformers} are transformers pre-trained on synthetic data generated from a prior distribution, to perform approximate Bayesian inference in a single forward pass using in-context learning \citep{luo2018neural, mann2020language}.} (this is already said in introduction) \textcolor{gray}{PFNs do not fit a model on downstream training data, instead feeding training data into the context and make predictions conditioning on the context.} \textcolor{gray}{One particular PFN model, TabPFN, introduced in \citet{hollmann2022tabpfn}, has achieved state-of-the-art classification on small tabular datasets  even in comparison with state of the art machine learning techniques free of any zero or few shot constraints \citep{hollmann2022tabpfn, mcelfresh2024neural}.} (this is high-level and basically already said in introduction using other words) 


%The inductive bias in TabPFN comes from the model architecture, and the specific choices we make about the synthetic data distribution from which one draws samples to train TabPFN.

\subsection{Zero-shot Learning}


%Difference between Introduction writing and related work writing:

%Example:

%\textcolor{gray}{Zero shot learning -- the ability of a machine learning model to produce meaningful inferences on previously unseen data problems -- is an impressive capability that has emerged in recent years in the space of language and vision problems \citep{xian2018zero, Xian_2017_CVPR, chang2008importance, larochelle2008zero, palatucci2009zero}.} \textbf{-- this is introduction writing: content is focusing on introducing concept and timeline.}

%Recent works such as \citet{xian2018zero, Xian_2017_CVPR, chang2008importance, larochelle2008zero, palatucci2009zero} have shown impressive capability of zero shot learning in the space of language and vision problems. \textbf{-- this is related work (keyword is "work") writing: content is focusing on the works.}

%STARTING HERE

Recent work such as \citet{xian2018zero, Xian_2017_CVPR, chang2008importance, larochelle2008zero, palatucci2009zero} have shown impressive capability of zero-shot learning in the space of language and vision problems. Recent approaches to zero-shot or few-shot learning for tabular data problems mostly encode tabular data as language, and then leverage large language models (LLMs) for their zero- or few-shot capabilities (see \citet{pmlr-v206-hegselmann23a, nam2023stunt, gardner2024largescaletransferlearning}). These approaches rely on relevant information about the tabular data existing in LLMs -- this is most obviously the case when column names are meaningful -- but it is not guaranteed for all tabular data problems.

%About 1 more sentence. DONE?

\subsection{Adversarial Training} 

%Traditional GANs.

%Fast adversarial training: https://arxiv.org/abs/1904.12843



%In classic generative adversarial networks (GANs) \citet{GoodfellowAdversarial, madry2018towards, kurakin2017adversarial} multiple gradient computations are needed to produce adversarial samples by perturbing the input samples. \citet{shafahi2019adversarial} improved on the traditional approach by updating both the model parameters and image perturbations using one simultaneous backward pass.




%\textcolor{gray}{Adversarial training is generally understood as a technique by which an adversarial agent (a data generator) is trying to challenge a model during its training process. In this way, the model is trained to be more robust to malicious data manipulation attacks. In the context of generative adversarial networks (GANs) \citet{GoodfellowAdversarial, madry2018towards, kurakin2017adversarial}, the data model is referred to as the discriminator. }

Upon generative adversarial networks (GANs) \citep{GoodfellowAdversarial, madry2018towards, kurakin2017adversarial}, recent work such as \citet{shafahi2019adversarial} improved on the efficiency by combining the back-propagation steps of the generator and discriminator. However, this method has been shown to suffer from catastrophic overfitting \citep{andriushchenko2020understanding, kim2021understanding} without further modifications. Other works focusing on improving the efficiency of GAN training include \citet{Wong2020Fast} and \citet{NEURIPS2019_812b4ba2} where they restrict most of the forward and back propagation within the first layer of the network during adversarial updates. \citet{zhang2021free} in particular noted that weights updates frequently going back and forth in opposite directions in one training epoch, suggest those updates are redundant.
%Other publications also trying to make efficient use of back-propagation in adversarial training include \citet{yuan2021meta}
%Wasserstein GAN (WGAN) \citep{arjovsky2017wasserstein} was introduced to mitigate the vanishing gradient\citep{goodfellow2016nips} and mode collapse (where the generator produces samples that have very little diversity) problems\cite{arora2017generalization}. 
Many other variations have been introduced to mitigate vanishing gradient and additional challenges of GAN training (see \citet{jabbar2021survey} and references therein): failing at finding a Nash-equilibrium \citep{ratliff2016characterization}, and internal
covariate shift \citep{ioffe2015batch}.

%To the best of our knowledge, adversarial training has not been performed in the pre-training of ZSMLs in prior work.

% About 3 sentences.


\section{Conclusion}

In this work, we gave the first effort in using adversarial synthetic data generators for the pre-training of deep zero-shot meta-learning algorithms. We proposed APT, a zero-shot meta-learner that improves the performance of TabPFN on tabular prediction tasks and matches state-of-the-art GBDTs on small tabular classification tasks. In addition, we proposed a mixture block neural design within the transformer architecture to eliminate the class size restriction of PFNs, addressing a crucial problem on zero-shot classifications. As for limitations, APT does not outperform GBDTs on large tabular datasets, and shared the quadratic runtime and memory scaling of TabPFN. Hence, extensions of this work could explore means of acquiring data representations in a more inexpensive manner. Besides, future research in this field could shift the attention slightly more to zero-shot regressions, where there is a lot room for improvement. The final prediction layer of most neural architecture has reduced dimensions for regression compared to classification, while continuous variables generally have higher empirical cardinality than class labels -- such dissonance could drive more creative solutions that benefit both zero-shot and traditional DL pipelines in solving tabular regression problems.


% Acknowledgements should only appear in the accepted version.
\section*{Acknowledgements}

We thank Tyler Farnan, Gang Mei and C. Bayan Bruss for the insightful discussions.

\iffalse
\section*{Impact Statement}

This paper presents work whose goal is to advance the field of 
Machine Learning. There are many potential societal consequences 
of our work, none which we feel must be specifically highlighted here.
\fi


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{langley00}

\bibliography{main}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn




\section{Background}
\label{sec:background}

In this section, we give a brief introduction to PFNs, and specifically the synthetic data generating mechanism of TabPFN. For a more complete description, see \citet{muller2021transformers, hollmann2022tabpfn, nagler2023statistical}. Given training dataset $D^\mathrm{train} = (X^\mathrm{train}, \boldsymbol{y}^\mathrm{train})$ and testing dataset $D^\mathrm{test} = (X^\mathrm{test}, \boldsymbol{y}^\mathrm{test})$, the goal is to approximate the posterior predictive distribution (PPD) $\boldsymbol{y}^\mathrm{test} \sim p(\cdot | X^\mathrm{test}, D^\mathrm{train})$. In the Bayesian framework for supervised learning, the prior of the dataset is a hypothesis of the data generating mechanism $\phi$ drawn from hypothesis space $\Phi$, and the PPD can be factorized as
\begin{align}
    p(\cdot | X^\mathrm{test}, D^\mathrm{train}) &= \int_{\phi \in \Phi} p(\cdot | X^\mathrm{test}, \phi) p(\phi | X^\mathrm{test}, D^\mathrm{train}) \, d\phi \\
    &= \int_{\phi \in \Phi} p(\cdot | X^\mathrm{test}, \phi) \frac{p(\phi) p( D^\mathrm{train} | \phi) p(X^\mathrm{test} | \phi)}{p(X^\mathrm{test}, D^\mathrm{train})} \, d\phi \\
    &\propto \int_{\phi \in \Phi} p(\cdot | X^\mathrm{test}, \phi) p( D^\mathrm{train} | \phi) p(X^\mathrm{test} | \phi) p(\phi) \, d\phi,
\end{align}
PFNs conduct synthetic prior fitting by defining a family of data generating mechanisms $\Phi$ to draw synthetic datasets $D = D^\mathrm{train} \cup D^\mathrm{test} \sim p(D) = \mathbb E_{p(\phi)} [p(D | \phi)]$, and use a transformer model $q_\theta (\cdot | X^\mathrm{test}, D^\mathrm{train})$ to approximate $p (\cdot | X^\mathrm{test}, D^\mathrm{train})$. The loss is given by
\begin{align}
    \mathcal{L}(q_\theta) = \mathbb E_{p(D)} \left[ -\log q_\theta (\boldsymbol{y}^\mathrm{test} | X^\mathrm{test}, D^\mathrm{train}) \right]
\end{align}

TabPFN in particular, conducts synthetic prior fitting by defining a family of sparsified-random-MLP-based data generating mechanisms $\Phi$, which we call ordinary data generators in the context of this paper. The following section gives a detailed description of the workflow of these generators.

\subsection{Ordinary Data Generator}
\label{sec:background-generator}

To sample data generating mechanism $\phi \sim \Phi$, TabPFN first initializes a random MLP by sampling a collection of hyperparameters from a pre-defined hyperparameter space, including number of layers, hidden size, activation function, dropout probability, noise scales, etc. Specifically, dropout probability is used to sparsify neural connections between neurons, and noise scales dictate the amount of random noise injected into neurons at each layer. After the sparsified noisy random MLP is initialized, TabPFN randomly selects a subset of neurons in this MLP to be predictors $\boldsymbol{x}_i$, and randomly select one neuron to be response $y_i$. With $n$ different random inputs to the MLP, a dataset with $n$ instances of $(x, y)$ is thus generated.

\paragraph{Discretization} Since generated data are selected neurons from MLPs, their values are naturally continuous. To mimic real-world datasets that possess categorical features and to generate discrete class labels for classification tasks, TabPFN uses a ranking discretization approach that converts a subset of continuous values to discrete by designating certain quantile ranges of the continuous value $v$ to certain categories. A visual demonstration of this conversion can be found on the left side of Figure \ref{fig:discrete-conversion}.

\begin{figure}
  \centering
  \subfigure[Ranking Discretization]{\label{fig-cat-conversion}\includegraphics[width=0.45\linewidth]{Figure/rank_discrete.png}}
  \subfigure[Ranking Soft-discretization]{\label{fig-cat-conversion-soft}\includegraphics[width=0.45\linewidth]{Figure/rank_soft_discrete.png}}
  \caption{Discretization of continuous variables. $x$-axis is the value generated by the data generator, and $y$-axis is its value after discretization. The soft-discretization approach produces near-categorical features that are differentiable and thus do not disrupt gradient flow. Intuitively, the adversarial data agents will try to produce new value that escapes the range of the current category if the meta-learner becomes very good at identifying signal from the current category. However, the new category it escapes to is arbitrary and cannot be targeted by gradient updates, giving additional exploration potentials to the adversarial agents.}
  \label{fig:discrete-conversion}
\end{figure}

\paragraph{Normalization} The generated synthetic data (as well as real-world datasets during inference time) are normalized across samples within each dataset, with the range of the values clipped to four standard deviations. Although the meta-learner might see datasets with unseen fields and out-of-distribution predictor-response relations during inference time, this ensures that at least the range of values will not be out-of-distribution as well.

\subsection{Limitations}
\label{sec:pfn-limitations}

Although there is no theoretical limitation on the number of data PFNs can handle, the transformer architecture does entail significant computation complexity and memory usage for large datasets. Besides, given the nature of MLP input embedding layer and MLP final prediction layer, there is a theoretical limitation on the number of features and the number of classes that PFNs can handle. The former is less of an issue since feature selections or simply random sampling of features can be performed, and PFNs would still yield ideal performance as shown in \citealt{mcelfresh2024neural}. The latter is a rather big problem for classification tasks because there is hardly any direct and effective work-around.



\section{Hyperparameter Settings}
\label{sec:hyperparameter-settings}

All common hyperparameters of APT are directly inherited from TabPFN and not tuned, including learning rate $10^{-4}$, number of blocks $12$, hidden dimensions $512$, hidden feedforward dimensions $1024$, number of heads $4$, effective batch size (batch size per step $\times$ number of gradient accumulation steps) $64$, total number of training datasets (number of epochs $\times$ steps per epoch $\times$ number of datasets per step) $6,400,000$, as well as all data generator hyperparameters. For more details on the data generator hyperparameters, see the code repository in our supplementary material.

%#final-version


\section{More Results}
\label{sec:more-results}

We list the performance of top algorithms on small classification datasets in Table \ref{result-datasets-35}. Standard deviations are calculated across 5 different splits.

\begin{table}[ht!]
  \caption{The ROC-AUC of top algorithms on the 35 small datasets in OpenML-CC18.}
  \label{result-datasets-35}
  \centering
  \resizebox{\textwidth}{!}{
      \begin{tabular}{lcccccc}
        \toprule
        & LightGBM & XGBoost & SVM & TabPFN & CatBoost & APT \\
        \midrule
        mfeat-fourier & .981 $\pm$ .004 & .982 $\pm$ .004 & .982 $\pm$ .004 & .985 $\pm$ .002 & .984 $\pm$ .002 & .983 $\pm$ .003 \\
        breast-w & .993 $\pm$ .006 & .993 $\pm$ .006 & .995 $\pm$ .007 & .997 $\pm$ .003 & .996 $\pm$ .005 & .997 $\pm$ .003 \\
        mfeat-karhunen & .999 $\pm$ .001 & .999 $\pm$ .001 & 1 $\pm$ 0 & .999 $\pm$ 0 & .999 $\pm$ 0 & 1 $\pm$ 0 \\
        mfeat-morphological & .959 $\pm$ .004 & .961 $\pm$ .002 & .965 $\pm$ .006 & .967 $\pm$ .003 & .964 $\pm$ .003 & .966 $\pm$ .006 \\
        mfeat-zernike & .970 $\pm$ .004 & .973 $\pm$ .004 & .992 $\pm$ .003 & .982 $\pm$ .001 & .974 $\pm$ .003 & .977 $\pm$ .003 \\
        cmc & .751 $\pm$ .036 & .758 $\pm$ .036 & .690 $\pm$ .020 & .736 $\pm$ .031 & .758 $\pm$ .037 & .739 $\pm$ .026 \\
        credit-approval & .931 $\pm$ .030 & .920 $\pm$ .022 & .912 $\pm$ .024 & .928 $\pm$ .029 & .931 $\pm$ .030 & .930 $\pm$ .022 \\
        credit-g & .809 $\pm$ .018 & .824 $\pm$ .028 & .816 $\pm$ .020 & .835 $\pm$ .018 & .816 $\pm$ .025 & .846 $\pm$ .024 \\
        diabetes & .821 $\pm$ .027 & .812 $\pm$ .037 & .811 $\pm$ .050 & .817 $\pm$ .026 & .827 $\pm$ .025 & .824 $\pm$ .016 \\
        tic-tac-toe & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & .993 $\pm$ .003 & 1 $\pm$ 0 & .997 $\pm$ .002 \\
        vehicle & .936 $\pm$ .009 & .945 $\pm$ .008 & .965 $\pm$ .011 & .965 $\pm$ .005 & .941 $\pm$ .008 & .961 $\pm$ .008 \\
        eucalyptus & .900 $\pm$ .022 & .894 $\pm$ .024 & .874 $\pm$ .009 & .908 $\pm$ .013 & .905 $\pm$ .019 & .912 $\pm$ .017 \\
        analcatdata\_authorship & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 \\
        pc4 & .953 $\pm$ .008 & .954 $\pm$ .012 & .907 $\pm$ .058 & .957 $\pm$ .013 & .961 $\pm$ .011 & .964 $\pm$ .016 \\
        pc3 & .814 $\pm$ .031 & .831 $\pm$ .048 & .706 $\pm$ .055 & .848 $\pm$ .044 & .829 $\pm$ .042 & .865 $\pm$ .032 \\
        kc2 & .887 $\pm$ .060 & .862 $\pm$ .102 & .881 $\pm$ .052 & .875 $\pm$ .079 & .885 $\pm$ .084 & .896 $\pm$ .087 \\
        blood-transfusion-service-center & .740 $\pm$ .085 & .722 $\pm$ .068 & .705 $\pm$ .075 & .750 $\pm$ .082 & .732 $\pm$ .077 & .751 $\pm$ .086 \\
        cnae-9 & .981 $\pm$ .005 & .994 $\pm$ .005 & .998 $\pm$ .001 & .812 $\pm$ .032 & .991 $\pm$ .005 & .901 $\pm$ .014 \\
        ilpd & .767 $\pm$ .067 & .751 $\pm$ .038 & .628 $\pm$ .085 & .792 $\pm$ .046 & .787 $\pm$ .059 & .808 $\pm$ .035 \\
        wdbc & .993 $\pm$ .006 & .989 $\pm$ .007 & .998 $\pm$ .003 & .997 $\pm$ .003 & .993 $\pm$ .003 & .997 $\pm$ .004 \\
        dresses-sales & .685 $\pm$ .028 & .618 $\pm$ .045 & .669 $\pm$ .027 & .552 $\pm$ .056 & .637 $\pm$ .051 & .617 $\pm$ .049 \\
        MiceProtein & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 \\
        steel-plates-fault & .975 $\pm$ .003 & .979 $\pm$ .003 & .964 $\pm$ .006 & .970 $\pm$ .005 & .978 $\pm$ .003 & .969 $\pm$ .006 \\
        climate-model-simulation-crashes & .944 $\pm$ .043 & .936 $\pm$ .052 & .951 $\pm$ .070 & .960 $\pm$ .053 & .949 $\pm$ .044 & .960 $\pm$ .058 \\
        balance-scale & .970 $\pm$ .027 & .998 $\pm$ .003 & .994 $\pm$ .006 & .997 $\pm$ .004 & .949 $\pm$ .014 & .998 $\pm$ .003 \\
        mfeat-factors & .999 $\pm$ .001 & .999 $\pm$ .001 & .999 $\pm$ .001 & .999 $\pm$ .001 & .999 $\pm$ 0 & .999 $\pm$ .001 \\
        vowel & .999 $\pm$ .001 & .999 $\pm$ .001 & .999 $\pm$ .001 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 \\
        analcatdata\_dmft & .595 $\pm$ .032 & .597 $\pm$ .029 & .601 $\pm$ .033 & .577 $\pm$ .044 & .582 $\pm$ .027 & .593 $\pm$ .040 \\
        pc1 & .901 $\pm$ .065 & .917 $\pm$ .063 & .802 $\pm$ .127 & .917 $\pm$ .059 & .916 $\pm$ .058 & .942 $\pm$ .041 \\
        banknote-authentication & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 \\
        qsar-biodeg & .934 $\pm$ .015 & .925 $\pm$ .012 & .932 $\pm$ .017 & .944 $\pm$ .016 & .935 $\pm$ .017 & .944 $\pm$ .013 \\
        semeion & .998 $\pm$ .001 & .999 $\pm$ .001 & .999 $\pm$ 0 & .984 $\pm$ .004 & .999 $\pm$ .001 & .980 $\pm$ .004 \\
        cylinder-bands & .898 $\pm$ .041 & .873 $\pm$ .036 & .913 $\pm$ .035 & .911 $\pm$ .021 & .904 $\pm$ .044 & .913 $\pm$ .031 \\
        car & 1 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & .999 $\pm$ .001 & 1 $\pm$ 0 & .997 $\pm$ .005 \\
        mfeat-pixel & .999 $\pm$ 0 & 1 $\pm$ 0 & 1 $\pm$ 0 & .999 $\pm$ 0 & 1 $\pm$ 0 & .999 $\pm$ 0 \\
        \bottomrule
      \end{tabular}
    }
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
