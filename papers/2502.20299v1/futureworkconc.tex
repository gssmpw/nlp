While this study makes a significant contribution to the field of fake news detection by investigating the seldom addressed issue of generalisability using ‘real-world’ data, a number of limitations and therefore opportunities for future work have been identified.

Firstly, while this paper has explored the use of LLMs through the LLaMA model, providing initial insights into their application in this domain, future work may further investigate the potential of other fine-tuned LLMs to enhance generalisability and performance. Although this study, \cite{pavlyshenko2023analysis} and \cite{kumar2024silver} indicate that even advanced LLMs face challenges in achieving robust generalisability, continued research could examine integrating LLMs with other feature sets to address these limitations and improve performance in fake news detection tasks.

Secondly, although the inclusion of stylistic and social-monetisation features enhanced model performance and balance, the study was constrained to specific datasets. Future research should investigate the effectiveness of these features across a wider range of datasets, including those focused on different types of news topics, to better understand their generalisability and robustness across different domains. However, training and testing on coarsely labelled datasets can lead to misleading results that show high levels of performance in cross-validation or hold-out testing on unseen portions of training datasets, but not on real-world data. Given the limited availability of manually labelled real-world data like the Facebook URLs dataset used in this study, more effort is needed to produce granularly labelled datasets that can serve as robust benchmarks for evaluating fake news detection models. However, it is crucial to ensure user privacy and safety when creating these datasets, especially when derived from social media platforms such as Facebook or X/Twitter.

Moreover, while this study aimed to tackle the issue of poor generalisability from a feature engineering perspective, future work should focus on optimising model hyperparameters to further enhance the performance and robustness of fake news detection models, alongside the features proposed in this study. Fine-tuning hyperparameters such as learning rate, batch size and regularisation techniques could potentially improve model accuracy, recall, and specificity across different datasets and domains. Additionally, while promising results were produced in this study with the Gradient Boosting and Random Forest algorithms, it is also important to acknowledge the potential biases introduced by the models themselves. Algorithms such as Gradient Boosting prioritise features (such as exclamations and ads seen in the PFI analysis) that reduce the loss function. This prioritisation can potentially introduce biases if these features are not equally relevant across different datasets. Future work should therefore investigate other potential sources of bias, beyond dataset bias, to ensure the model's fairness and robustness. This includes a further examination of how features, especially the newly introduced 'social-monetisation' features, might inadvertently influence model predictions and contribute to biases. By addressing these biases, we can develop more reliable and equitable fake news detection models.

Finally, despite the comprehensive exploration of various stylistic features in this study, it is important to acknowledge that there are many other stylistic features that are yet to be explored in this context. Future work, therefore, should seek to identify other generalisable features, similar to the proposed social monetisation features, exclamations and all-caps words, as identified by this study. Additionally, given the advantages demonstrated through the four proposed novel features, future work should also try to identify such features that are available in the broader context of the whole webpage and not exclusively the article text. Further investigation into the computational efficiency of these features, compared to other approaches, should also be a priority in future research. This will ensure that the developed models can be efficiently deployed in real-time systems where computational resources and rapid response times are critical.