\section{Related work}
\subsection{Mechanistic Interpretability}
Mechanistic Interpretability investigates how components in large language models process and represent information~\cite{wang2024knowledgemechanismslargelanguage}.
At present, many MI studies have been applied in various fields of AI Safety. For instance, oversimplified probes risk~\cite{friedman2024interpretabilityillusionsgeneralizationsimplified}, unlearning fabricated knowledge~\cite{sun2024learningunlearningfabricatedknowledge}, reducing toxicity via alignment~\cite{lee2024mechanisticunderstandingalignmentalgorithms}, mitigating hallucinations by editing representations~\cite{zhang2024truthxalleviatinghallucinationsediting}, and generating truthful outputs through inference-time interventions~\cite{NEURIPS2023_81b83900}. Other studies explore how local model edits propagate across tasks~\cite{cohen2024evaluating,meng2023masseditingmemorytransformer}, Multi-Head Attention in-context learning~\cite{chen2024transformers,chen2024can} and enhance influence-function sampling~\cite{koh2024faithful}. Specifically, our study examines how circuits evolve during fine-tuning for mathematical tasks, focusing on node and edge changes to reveal mechanisms behind performance improvements.

\subsection{Circuit Analysis and Fine-Tuning}
One direction of Circuit Analysis focuses on building complete circuits. Early work localizes factual associations in mid-layer modules~\cite{NEURIPS2022_6f1d43d5} and uses causal mediation to uncover biases~\cite{vig2020causalmediationanalysisinterpreting,NEURIPS2023_3927bbdc}. Automated methods like Automated Circuit Discovery identify significant units~\cite{NEURIPS2023_34e1dbe9}, while techniques like attribution patching, and refine circuit extraction by handling near-zero gradients~\cite{syed2023attributionpatchingoutperformsautomated,hanna2024faithfaithfulnessgoingcircuit}. Edge pruning~\cite{bhaskar2024findingtransformercircuitsedge} provide insights into building the edge of the circuit. Another line of research investigates the functional roles of circuit components, such as Attention heads~\cite{wu2024retrievalheadmechanisticallyexplains, mcdougall2023copysuppressioncomprehensivelyunderstanding, olsson2022context, gould2023successorheadsrecurringinterpretable, cabannes2024iterationheadmechanisticstudy} and Feed Forward Networks (FFNs) / MLPs~\cite{geva2021transformerfeedforwardlayerskeyvalue, geva2022transformerfeedforwardlayersbuild, bhattacharya2024understandingroleffnsdriving}. 
Additionally, circuits have been used to analyze specific tasks, such as factual knowledge retrieval~\cite{geva2023dissectingrecallfactualassociations}, arithmetic computation~\cite{stolfo2023mechanisticinterpretationarithmeticreasoning}, Greater Than task~\cite{NEURIPS2023_efbba771}, and circuit recognition in Indirect Object Identification~\cite{wang2022interpretabilitywildcircuitindirect}. Unlike these analyses, which focus on smaller-scale tasks and models, our work offers a new lens on how circuits evolve specifically during fine-tuning on mathematical tasks, revealing crucial roles of edge changes.

As pre-trained language models scale, fine-tuning methods have emerged, optimizing only a small subset of parameters~\cite{ding2023parameter}. Parameter-efficient fine-tuning (PEFT) methods, such as LoRA~\cite{hu2021lora}, reduce computational costs while preserving functionality~\cite{ding2023parameter}. Advances in LoRA, including pruning~\cite{zhou2024loradropefficientloraparameter} and adaptive budget allocation~\cite{zhang2023adaloraadaptivebudgetallocation, liu2022few, lialin2024scalingscaleupguide}, further improve efficiency. In our study, we introduce a circuit-aware LoRA approach that adaptively assigns higher ranks to layers with more edge changes, boosting efficiency and accuracy in mathematical tasks, and further illustrates how combining circuits from subtasks can enhance performance in compositional tasks during fine-tuning.