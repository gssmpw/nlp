[
  {
    "index": 0,
    "papers": [
      {
        "key": "wang2024knowledgemechanismslargelanguage",
        "author": "Mengru Wang and Yunzhi Yao and Ziwen Xu and Shuofei Qiao and Shumin Deng and Peng Wang and Xiang Chen and Jia-Chen Gu and Yong Jiang and Pengjun Xie and Fei Huang and Huajun Chen and Ningyu Zhang",
        "title": "Knowledge Mechanisms in Large Language Models: A Survey and Perspective"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "friedman2024interpretabilityillusionsgeneralizationsimplified",
        "author": "Dan Friedman and Andrew Lampinen and Lucas Dixon and Danqi Chen and Asma Ghandeharioun",
        "title": "Interpretability Illusions in the Generalization of Simplified Models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "sun2024learningunlearningfabricatedknowledge",
        "author": "Chen Sun and Nolan Andrew Miller and Andrey Zhmoginov and Max Vladymyrov and Mark Sandler",
        "title": "Learning and Unlearning of Fabricated Knowledge in Language Models"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "lee2024mechanisticunderstandingalignmentalgorithms",
        "author": "Andrew Lee and Xiaoyan Bai and Itamar Pres and Martin Wattenberg and Jonathan K. Kummerfeld and Rada Mihalcea",
        "title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zhang2024truthxalleviatinghallucinationsediting",
        "author": "Shaolei Zhang and Tian Yu and Yang Feng",
        "title": "TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "NEURIPS2023_81b83900",
        "author": "Li, Kenneth and Patel, Oam and Vi\\'{e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin",
        "title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "cohen2024evaluating",
        "author": "Cohen, Roi and Biran, Eden and Yoran, Ori and Globerson, Amir and Geva, Mor",
        "title": "Evaluating the ripple effects of knowledge editing in language models"
      },
      {
        "key": "meng2023masseditingmemorytransformer",
        "author": "Kevin Meng and Arnab Sen Sharma and Alex Andonian and Yonatan Belinkov and David Bau",
        "title": "Mass-Editing Memory in a Transformer"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "chen2024transformers",
        "author": "Chen, Xingwu and Zhao, Lei and Zou, Difan",
        "title": "How Transformers Utilize Multi-Head Attention in In-Context Learning? A Case Study on Sparse Linear Regression"
      },
      {
        "key": "chen2024can",
        "author": "Chen, Xingwu and Zou, Difan",
        "title": "What Can Transformer Learn with Varying Depth? Case Studies on Sequence Learning Tasks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "koh2024faithful",
        "author": "Koh, Jungyeon and Lyu, Hyeonsu and Jang, Jonggyu and Yang, Hyun Jong",
        "title": "Faithful and Fast Influence Function via Advanced Sampling"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "NEURIPS2022_6f1d43d5",
        "author": "Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan",
        "title": "Locating and Editing Factual Associations in GPT"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "vig2020causalmediationanalysisinterpreting",
        "author": "Jesse Vig and Sebastian Gehrmann and Yonatan Belinkov and Sharon Qian and Daniel Nevo and Simas Sakenis and Jason Huang and Yaron Singer and Stuart Shieber",
        "title": "Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias"
      },
      {
        "key": "NEURIPS2023_3927bbdc",
        "author": "Hase, Peter and Bansal, Mohit and Kim, Been and Ghandeharioun, Asma",
        "title": "Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "NEURIPS2023_34e1dbe9",
        "author": "Conmy, Arthur and Mavor-Parker, Augustine and Lynch, Aengus and Heimersheim, Stefan and Garriga-Alonso, Adri\\`{a}",
        "title": "Towards Automated Circuit Discovery for Mechanistic Interpretability"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "syed2023attributionpatchingoutperformsautomated",
        "author": "Aaquib Syed and Can Rager and Arthur Conmy",
        "title": "Attribution Patching Outperforms Automated Circuit Discovery"
      },
      {
        "key": "hanna2024faithfaithfulnessgoingcircuit",
        "author": "Michael Hanna and Sandro Pezzelle and Yonatan Belinkov",
        "title": "Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding Model Mechanisms"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "bhaskar2024findingtransformercircuitsedge",
        "author": "Adithya Bhaskar and Alexander Wettig and Dan Friedman and Danqi Chen",
        "title": "Finding Transformer Circuits with Edge Pruning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wu2024retrievalheadmechanisticallyexplains",
        "author": "Wenhao Wu and Yizhong Wang and Guangxuan Xiao and Hao Peng and Yao Fu",
        "title": "Retrieval Head Mechanistically Explains Long-Context Factuality"
      },
      {
        "key": "mcdougall2023copysuppressioncomprehensivelyunderstanding",
        "author": "Callum McDougall and Arthur Conmy and Cody Rushing and Thomas McGrath and Neel Nanda",
        "title": "Copy Suppression: Comprehensively Understanding an Attention Head"
      },
      {
        "key": "olsson2022context",
        "author": "Olsson, Catherine and Elhage, Nelson and Nanda, Neel and Joseph, Nicholas and DasSarma, Nova and Henighan, Tom and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and others",
        "title": "In-context learning and induction heads"
      },
      {
        "key": "gould2023successorheadsrecurringinterpretable",
        "author": "Rhys Gould and Euan Ong and George Ogden and Arthur Conmy",
        "title": "Successor Heads: Recurring, Interpretable Attention Heads In The Wild"
      },
      {
        "key": "cabannes2024iterationheadmechanisticstudy",
        "author": "Vivien Cabannes and Charles Arnal and Wassim Bouaziz and Alice Yang and Francois Charton and Julia Kempe",
        "title": "Iteration Head: A Mechanistic Study of Chain-of-Thought"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "geva2021transformerfeedforwardlayerskeyvalue",
        "author": "Mor Geva and Roei Schuster and Jonathan Berant and Omer Levy",
        "title": "Transformer Feed-Forward Layers Are Key-Value Memories"
      },
      {
        "key": "geva2022transformerfeedforwardlayersbuild",
        "author": "Mor Geva and Avi Caciularu and Kevin Ro Wang and Yoav Goldberg",
        "title": "Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space"
      },
      {
        "key": "bhattacharya2024understandingroleffnsdriving",
        "author": "Sunit Bhattacharya and Ond\u0159ej Bojar",
        "title": "Understanding the role of FFNs in driving multilingual behaviour in LLMs"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "geva2023dissectingrecallfactualassociations",
        "author": "Mor Geva and Jasmijn Bastings and Katja Filippova and Amir Globerson",
        "title": "Dissecting Recall of Factual Associations in Auto-Regressive Language Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "stolfo2023mechanisticinterpretationarithmeticreasoning",
        "author": "Alessandro Stolfo and Yonatan Belinkov and Mrinmaya Sachan",
        "title": "A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "NEURIPS2023_efbba771",
        "author": "Hanna, Michael and Liu, Ollie and Variengien, Alexandre",
        "title": "How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "wang2022interpretabilitywildcircuitindirect",
        "author": "Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt",
        "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "ding2023parameter",
        "author": "Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others",
        "title": "Parameter-efficient fine-tuning of large-scale pre-trained language models"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "hu2021lora",
        "author": "Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu",
        "title": "Lora: Low-rank adaptation of large language models"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "ding2023parameter",
        "author": "Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others",
        "title": "Parameter-efficient fine-tuning of large-scale pre-trained language models"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "zhou2024loradropefficientloraparameter",
        "author": "Hongyun Zhou and Xiangyu Lu and Wang Xu and Conghui Zhu and Tiejun Zhao and Muyun Yang",
        "title": "LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "zhang2023adaloraadaptivebudgetallocation",
        "author": "Qingru Zhang and Minshuo Chen and Alexander Bukharin and Nikos Karampatziakis and Pengcheng He and Yu Cheng and Weizhu Chen and Tuo Zhao",
        "title": "AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning"
      },
      {
        "key": "liu2022few",
        "author": "Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin A",
        "title": "Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning"
      },
      {
        "key": "lialin2024scalingscaleupguide",
        "author": "Vladislav Lialin and Vijeta Deshpande and Xiaowei Yao and Anna Rumshisky",
        "title": "Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning"
      }
    ]
  }
]