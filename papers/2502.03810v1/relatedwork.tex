\section{Related Work}
\label{Related Work}
{\flushleft \textbf{Image deblurring.}}
%
Due to the fact that image deblurring is an ill-posed problem, traditional methods~\cite{sparse,L0,dark_channel} often develop various effective priors to constrain the solution space.
%
These manually designed priors can help remove blur. 
%
However, they do not fully utilize the characteristics of clear image data, which leads to a struggle in handling complex blur patterns and may produce unsatisfactory results
%

%
% In recent years, with the development of deep learning, many learning-based methods~\cite{SRN, DMPHN, MIMO, MPRNet, NAFNet} have tended to use various CNN architectures for image deblurring. 
% %
With the development of deep learning, many learning-based methods have tended to use various CNN architectures for image deblurring. 
%
SRN~\cite{SRN} proposes a multi-scale structure that performs image deblurring from coarse to fine.
%
MIMOUnet~\cite{MIMO} redesigns the coarse-to-fine structure, significantly reducing the computational cost.
%
NAFNet~\cite{NAFNet} analyzes the baseline module and simplifies it by removing the activation function, which better facilitates image restoration.
%

%
Due to the excellent performance of Transformers in global context exploration and their great potential in many visual tasks, some methods have applied it to image deblurring.
%
Restormer~\cite{Restormer} simplifies the baseline module by estimating self-attention in the channel dimension, reducing the computational cost of self-attention
%
Uformer~\cite{Uformer} proposes a general U-shaped Transformer model, computing self-attention within local windows to address the image deblurring.
%
FFTformer~\cite{fftformer} proposes a frequency-domain based Transformer model and achieved state-of-the-art results.
%

%
Although these methods have achieved good deblurring effects, these regression-based methods tend to predict smooth results, with limited ability to depict details.
%


{\flushleft \textbf{Diffusion model.}}
%
Denoising Diffusion Probabilistic Models (DDPM)~\cite{DDPM} have shown remarkable capabilities in generating high-quality natural images.
%
Some methods~\cite{resshift,cdm,hidiff} have attempted to directly train a diffusion model for image restoration.
%
Rombach et al.~\cite{sd} extended the DDPM structure to the latent space and conducted large-scale pre-training, demonstrating impressive generative capabilities.
%
Recently, some researchers have utilized powerful pre-trained generative models, such as SD~\cite{sd}, to address image restoration problems.
%
DiffBIR~\cite{diffbir} proposes a two-stage approach, first restoring the degraded image and then using SD to generate details.
%
PASD~\cite{pasd} restores clear images through a Degradation Removal module to provide clear conditional inputs for SD.
%

%
However, these methods require training an additional image restoration model and then enhance the details through SD. 
%
This means that the final results of the SD largely depend on the outcomes of the restoration model. 
%
When the degradation removal model produces erroneous results, it may lead to poor performance in the diffusion process. 
%
Moreover, due to the poor generalization of existing restoration models, these methods also tend to perform poorly when dealing with various types of blur.
%


% %
% \begin{figure*}[!t]
%     \centering
%  \includegraphics[width=0.98\textwidth]{Figures/network_V4.pdf}
%  \vspace{-1mm}
%  \caption{Efficient visual state space model. To efficiently restore high-quality images with SSMs, we propose an effective EVSS module that involves an efficient EVS block and an efficient EDFFN block. A geometric transformation is employed at the beginning of each EVS block to facilitate more useful information exploration in the following selective scan with a minimal increase in computational costs.}
%  \vspace{-3mm}
%  \label{fig: Network}
% \end{figure*}