\section{Related Work}
% Nonverbal cues have been extensively studied for their potential to detect mental health conditions like depression and anxiety. Facial expressions, body gestures, speech patterns, and head movements provide objective insights into a patient's emotional state.

% \subsection{Depression Detection Using Nonverbal Cues}
\subsection{Automatic Depression Detection Using Nonverbal Cues}

Clinicians have observed for a long time that severe depression is correlated with reduced physiological activities, such as monotonic tone, reduced intensity of facial expressions, or low quantity of body motion~\cite{american2013diagnostic}.  

Several studies have indeed shown that modern computer science tools can be used to extract those non-verbal cues and provide an objective way to assess the level of depression. Features extracted from body gestures~\cite{joshi2013can}, speech patterns~\cite{cummins2015review}, facial expressions~\cite{dibekliouglu2017dynamic}, and head movement~\cite{KacemIEEEFG2018} are used to automatically and accurately predict depression severity.
%used to automatically predict the rate of depression severity accurately.
However, the interpretability of most approaches remains unclear. Many recent approaches rely on deep neural networks~\cite{song2018human, suhara2017deepmood}, with improved accuracy but providing limited insights for clinicians.

% Studies like Cohn et al.~\cite{cohn2009detecting} and Girard et al.~\cite{girard2014nonverbal} have shown that certain facial muscle movements and reduced expressiveness correlate with depressive symptoms. 
%Most studies on detecting depression focus on separating severely depressed and healthy populations. The lack of interpretability makes it unclear whether the proposed features could be directly used to assess the precise state of depressed patients.
Most studies on detecting depression focus on separating severely depressed and healthy populations but lack interpretability. Gahalawat et al.~\cite{GahalawatDep} addressed this issue by proposing an interpretable approach using head motion patterns for binary classification. However, while their method enhances explainability, it remains focused on distinguishing between groups rather than evaluating the precise state of depressed patients.

\subsection{Automatic Anxiety Detection}

Similar to depression, research has shown that several anxiety disorders can be automatically detected using non-verbal cues~\cite{lima2019facial}.
Most studies have primarily focused on physiological signals—such as heart rate variability, skin conductance, and cortisol levels—using wearable devices~\cite{physiological2024,hickey2021smart}.

In~\cite{pediaditis2015extraction}, the authors extract facial features, such as face and mouth motion, to predict whether patients are anxious or relaxed. This analysis was later extended in~\cite{giannakakis2017stress}. Mo et al.~\cite{mo2023sff} propose using facial cues to accurately detect anxiety and distress in a non-intrusive manner. However, their feature extraction process relies on deep learning and is therefore non-interpretable.

In our approach, anxiety is considered a symptom of depression, whereas most of the cited works treat anxiety as an independent illness. It remains unclear whether these methods would be effective in detecting anxiety in depressed patients.

\subsection{Tracking behavior with head motion}

Head movements are significant nonverbal indicators for behavioral analysis and are well studied, as they are easy to track in virtual reality environments~\cite{lindner2021better} or dyadic interactions~\cite{won2014automatic}. In virtual reality settings, head movements serve as valuable features for analyzing social interactions~\cite{herrera2021virtual}, emotional states~\cite{xue2021investigating}, and simulation sickness in virtual environments~\cite{bailenson2006longitudinal}. 

By extracting head motion dynamics from videos of structured Hamilton interviews, Kacem et al.~\cite{KacemIEEEFG2018} classified depression severity, finding that depressed individuals exhibit less head movement. Dibeklioglu et al. ~\cite{DibekliogluICMI2015} combined head movements with facial dynamics and vocal prosody for depression detection, noting differences in nodding frequency and amplitude between depressed and non-depressed populations. Finally, head movements have also been shown to be valuable for anxiety prediction~\cite{won2016identifying}. 
\\
\par We summarize the main contributions of our work below:
\begin{enumerate}
\item We introduce the CALYPSO dataset, a longitudinal study of clinical depression. In particular, we propose to use the videos of informal interviews of the study to analyze anxiety in severe depression using head movements extracted from the videos. %CALYPSO is a database of people suffering from severe depression, and in particular, we captured their head movements.
\item We propose segmenting videos into head-moving and non-moving phases. This approach allows us to extract a more comprehensive set of head motion features for our analysis. We further select the most significant features and train a regression model to predict psychological anxiety.
\item We validate our method on the CALYPSO dataset and demonstrate its effectiveness in daily life settings by applying it to informal interviews with depressed patients. For the first time, we establish a link between anxiety in severe depression and objectively measurable nonverbal cues, based on head motion characteristics extracted from pose angular displacements.

\end{enumerate}
%\subsection{Gap in the Literature}