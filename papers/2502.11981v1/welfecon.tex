
\section{Welfare economics and what it can teach us} \label{sec:welfecon}

Welfare economics is the subfield of economics that is concerned with the 
characterization, evaluation, and maximization of social welfare in economies and societies.
The main principles of welfare economics date back to \citet{smith1759moral,smith1776wealth},
but its formal foundations were laid out only a century later by
notable neoclassic economists such as
\citet{edgeworth1881psychics},
\citet{marshall1890principles},
\citet{pareto1906manual},
and \citet{pigou1920welfare}.
Modern welfare economists include influential figures such as
\citet{hicks1939value},
\citet{arrow1951social},
\citet{sen1970collective},
and \citet{stiglitz2012inequality}---all of which received the Nobel Prize for their contributions to this field.
% \todo{short list; noble laureates?}.
Given its rich history,
we believe that machine learning has much to gain from adopting ideas and perspectives
from this well-established discipline.

\subsection{Welfare economics: crash course}
\paragraph{The distribution of wealth.}
The main question welfare economics asks is:
how should wealth be distributed across individuals in the economy?
% Towards this,
Under the working hypothesis that resources (and therefore wealth) are limited,
the main object of interest in welfare economics is the \emph{Pareto front}---%
the set of all possible economic states in which no individual can be made better off without making things worse for another \citep[see, e.g.,][]{johansson1991introduction}.
In terms of welfare, there are two main considerations for policymakers:
\squeeze
\begin{enumerate}[leftmargin=1.7em,topsep=0em,itemsep=0.3em]
\item \textbf{Efficiency:}
How do we reach a Pareto state?

\item \textbf{Equity:}
Of all Pareto states, which are preferable? 
% Which Pareto states are preferable to others?
\end{enumerate}
\emph{Efficiency} requires an ability to optimize economic outcomes 
to a point where social benefit is maximal (in the Pareto sense).
Markets are a classic example of how the actions of many self-interested agents can combine to produce  efficient outcomes \citep{arrow1954existence}.
However, there are typically many states 
that are maximally beneficial,
% that are equally efficient,
% with high overall benefit,
% but nonetheless admit very different distributions 
but that differ in how benefits are distributed across individuals;
in regard to this, markets are mostly silent.
As such, \emph{equity} makes a statement about the relative preference ordering over all possible states, and considers means for steering towards preferable ones.
A canonical example is income distribution:
all governments likely seek higher overall income (efficiency),
but may disagree about whether high inequality should be permitted or suppressed
(equity).

\priority{%
\todo{add pareto curve graphic? general econ and/or acc-vs-welfare?}
}

%\hf{add 2-3 sentences to explain connection to fairness study, which misses people's reaction to predictions. Then point readers to appendix for more discussion. }

% adopt ideas from welfare economics:
% - pareto front - main object of interest
% 1. efficient
% 2. choose point


\paragraph{Social welfare functions.}
In welfare economics,
the primary tool for defining and promoting equity 
is the \emph{social welfare function},
which ranks or scores all possible economic states.
Our focus will be on the common choice of cardinal (i.e., real-valued) welfare functions that take the form of an expectation over weighted individual utilities:%
\footnote{The literature on social welfare functions is of course rich and diverse. Here we present a basic and simplified formulation which suits our purposes. Curious readers are referred to \citep{adler2019measuring} for a more thorough discussion of possible alternatives.}
% other possibilities in this space.}
\begin{equation}
\label{eq:welfare}
\welf(\policy;w) = \expect{(x,y)\sim \dist}{w(x) u(x,y;\policy)}
\end{equation}
% \hfr{
where $\policy$ is a \emph{policy}
(e.g., rules deciding which resources are allocated to whom)
% which individuals to accept or how much resource each individual gets)
% $\dist$ is the population distribution about individuals characterized by (feature,label) pairs $(x,y)$ 
and $u(x,y;\policy)$ is the utility of user $x$ under policy $\pi$, given $y$.
Notably, $w(x)$ is a weight function that the planner \emph{chooses}:
% as such, it provides a means to control
% the social welfare function
this defines
the desired direction for overall improvement (i.e., efficiency)
by balancing the importances of individual outcomes (i.e., equity).%
% Such weights have been adopted to prioritize certain subgroups \cite{bj√∂rkegren2022machinelearningpoliciesvalue}  or balance different objectives \cite{rolf2020balancing}.
\footnote{More generally, weights $w(x)$ can even depend on the utility $u$ of $x$. This allows to express welfare using broader functional forms
(e.g., $\min$ instead of sum) or relative measures of inequality (e.g., Gini or Theil). For our purposes, the simpler form $w(x)$ suffices.}
% }
%Where \nir{...temporary notation, need to revise}. \hf{  $w(x)$ is determined by planner, not agent; agent decides $u$ utility. 
%In this way, maximizing welfare works towards improving overall outcomes (i.e., efficiency) while balancing individual outcomes (i.e., equity) as prescribed by weights $w(x)$. 
When the policy $\policy=\policy_h$ is guided by a predictive model $h$,
we will write $\welf(h)$ to mean $\welf(\policy_h)$.

 

\paragraph{The social planner.}
Equity is inherently a subjective notion that requires making value judgements.
Social welfare functions make it possible to formally express these by setting appropriate weights.
In welfare economics, weights are designated by a \emph{social planner}---either a real or fictitious entity that represents societal preferences.
A social planner can set weights to aid low income individuals;
implement affirmative action towards some social group;
or ensure that all individuals obtain some minimal level of utility.
Concrete examples include using weights to prioritize certain subgroups \citep{bjorkegren2022machinelearningpoliciesvalue} or balance different objectives \citep{rolf2020balancing}.
The simplest weighing scheme is of course using uniform weights, i.e., $w(x) = 1$ for any $x$.
But note even this makes a statement, which is that individuals should be weighted by their utility;
this is known as `utilitarian welfare'.
Hence, from the perspective of welfare economics, any objective that optimizes a (non-weighted) average---such as accuracy in machine learning---is in effect making a statement about how value should be distributed.

\todo{ref SWF examples in appendix?}

\paragraph{Human agency.}
% \hfr{
Welfare economics makes explicit the idea that individuals have \emph{agency}.
Intuitively, this states that individuals
(i) \emph{want} things,
(ii) \emph{know} things,
and (iii) \emph{act} -- to get what they want, using what they know.
These notions are formally accounted for by modeling
utility functions (want),
private information (know),
and decision-making, e.g., rational or behavioral (act).
Any policy that aims to advance welfare must take these into account.
Often this requires the planner to make additional efforts,
such as to elicit preferences,
create incentives for truthful reporting,
or infer how users will respond to different policy choices.
These are challenging, but give the planner power:
if incentives can be aligned, then it becomes possible
to harness the willingness of \emph{users} to invest effort for improving outcomes for all; consider public goods and services, crowdfunding platforms, open-source software, and collaborative knowledge bases.
\squeeze



% \todo{check flow now that connections sections moved to appx}

\subsection{Connections to machine learning.}
We believe that machine learning has much to gain from adopting a welfare perspective:
when inputs represent humans, it becomes 
possible to promote overall social benefit (efficiency),
and imperative to consider its distribution across the population (equity).
Current tools already push forward on these ideas, but only to a limited extent.
One reason is that standard learning objectives are notoriously underspecified;
this has implications on e.g. robustness \citep{d2022underspecification},
explainability \citep[see][]{rudin2019stop},
and fairness \citep[e.g.,][]{rodolfa2020case,coston2021characterizing,black2022model}.
% as some examples.
But underspecification also presents an opportunity for \emph{steering} outcomes toward socially beneficial states.
Consider how the idea of \emph{model multiplicity}
\citep{breiman2001statistical,marx2020predictive,hsu2022rashomon},
i.e., that there is typically a large set of (approximately) optimal models,
connects to the notion of an efficient Pareto front.%
\priority{since by definition, any deviation that increases accuracy for some users will necessarily come at the cost of reduced accuracy for others.}
The challenge lies in how to provide a social planner effective means to choose a preferred operating point.
In some cases, this will be diffucult;
in others, it may be achievable with tools as simple as regularization---if chosen appropriately \citep{levanon2021strategic}.
In terms of limited resources, machine learning already offers many 
relevant tools, such as constraints on cardinality (e.g., top-$k$ prediction)
or error rates (e.g., precision and recall).
Also relevant are tools from cost-sensitive \citep[e.g.,][]{elkan2001foundations}
and decision-focused learning \citep{mandi2024decision}.
But to be effective, these must be adapted to account for agency:
how users report information,
how they act in response to the learned classifier,
and how they interact with each other.
This idea will be key to our framework, as discussed next.
% \squeeze


% -- resources: [top-k]

% -- welfare: [acc objective]

% -- planner:
% if learning seeks to promote welfare, then it needs to confront these issues

% -- agency:
% Conventional learning frameworks have no notion of agency.
% This makes them unable to contend with the challenges that agency presents,
% nor to capitalize on the prospects it offers.
% This point will be key in our transition from welfare economics to machine learning,
% as we discuss next.

% -- Pareto: [multiplicity/rashomon]

% each individual's ``agency properties'' by accounting for: (a) what they \emph{want} through utility functions; (b) what they \emph{know} through modeling private information; and (c) what they \emph{do} through rational decision making.
% This perspective significantly enriches the planer's design choices such as eliciting private information from individuals, and using incentives or information to influence their behaviors. Meanwhile, it also necessitates the considerations of individual's incentives and responses to adopted policies.
% These novel aspects crucially differ from the static data distribution assumption in classic machine learning setups, which is appropriate for object recognition style of tasks. With the increasing demand of using ML technology to aid decisions and policies in human-involved contexts, it becomes important to integrate welfare economics into learning algorithm design, as we elaborate next.
% }

% Much of the power of machine learning stems from considering inputs as abstract features (e.g., vectors).
% In our setting, features $x$ represent actual human beings,
% and predictions $\hat{y}$ are made about them or for them.
% The crux is that humans are not your conventional input: they have goals, beliefs, and aspirations, and take action to promote their own self-interests.
% % In other words, humans are inputs that `behave'.
% A key aspect of our setting is that we will endow users with agency;
% intuitively, this means that we model users as acting on the basis of what they know or belief to pursue their objectives.
% Throughout we will mostly consider rational agents which act to maximize utility, but there is certainly room for other models of human behavior.
% Rational modeling is useful since it makes explicit the interests of users,
% as they compare to those of the learner, and possibly of society.
% As we will show, the question of incentives and how they relate has many implications on learning.

% \todo{define agency: want (utility, welfare), know (information, type, reporting, truthfulness), do (actions). want should also include externalities - negative (i want to be relatively better than others) and positive (i care about fairness and equity)}

% - social welfare function
% - social planner
% -- allows to monitor, audit, regulate, subsidize
  


% 1. learning objective underspecified
%   -- expectation (standard goal) vs. variation (=distribution of value)
% 2. social welfare function as weighted average (over utility from outcomes)


% \paragraph{Useful notions.}
% Because outcomes depend also on the interconnected behavior of users,
% reasoning about welfare may require notions beyond those in the standard machine learning toolkit.
% Luckily, many useful tools can be adopted from game theory, mechanism design, information design, and behavioral economics.
% These include:
% \begin{itemize}[leftmargin=1em,topsep=0em,itemsep=0.3em]
% \item
% equilibrium: various notions

% \item
% dynamics

% \item
% behavior: strategic/rational, boundedly-rational, non-rational (behavioral)
% \end{itemize}


% adopt notions from game theory:
% - strategic behavior; vs non-rational behavior
% - equilibrium
% - dynamics


% The field of machine learning spans many settings, formulations, and objectives.
% Our position paper focuses on the simplest and most fundamental of these,
% namely supervised discriminative learning:
% given training data of labeled pairs $(x,y)$ sampled iid from some unknown distribution,
% learn a function $f$ from a class $F$ whose predictions $\hat{y}=f(x)$ are accurate in expectation.
% This choice is for several reasons.
% First, although simple, supervised learning includes the fundamental considerations that pertain to all learning tasks: modeling, optimization, and statistics. This makes it appropriate as a first step towards welfare-aware learning.
% %  and the basis form more complex settings.
% Second, many other forms of learning are now based on predictive learning;
% this includes reinforcement learning (e.g., Q-learning, imitation learning (?)),
% generative learning (e.g., LLMs, diffusion models (?)),
% unsupervised learning (e.g., self-supervised learning),
% and even causal ([ref athey papers])
% and statistical inference ([ref zrnic papers]).
% Third, supervised learning is the hallmark of machine learning: 
% it is popular and well-known, the first to be taught, is in widespread use, and is highly supported in terms of software and code packages.
% Even if it is not the right tool---we argue that it is, and will likely continue to be, the main go-to approach used in practice.

% Even if our goal is to promote welfare, we will insist that accuracy remains an integral part of the learning objective.





