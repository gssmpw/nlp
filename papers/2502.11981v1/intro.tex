
\section{Introduction} \label{sec:intro}

% \todo{blind spot}

As the influence of machine learning on our lives continues to grow,
there is high hope that this will prove to be for the better.
Given the unmatched ability of machine learning to make accurate predictions,
we have,
in principle,
much reason for optimism.
% Machine learning has gained much influence over our lives.
% this seems promising:
Accurate predictions have potential
to improve the choices we make for ourselves,
from the mundane (e.g., what to buy or where to eat)
to highly consequential (e.g., what to study, how to invest, or even who to date).
This can explain why 
% This idea has made it appealing to use
machine learning has become 
% so deeply integrated in
%  most human-facing applications,
% such as
% consider how learned predictive models now form
the backbone of most
recommendation systems,
media services,
online marketplaces,
and social platforms.
% what to buy, to who to date, or where to travel.
Better prediction can also provide better support for
decisions made about us, such as
which medical treatment to apply,
when to offer financial aid,
or who to hire.
Learned models are therefore making their way,
slowly but surely,
into more conventional social domains
such as health care, 
education,
finance,
transportation,
law,
and even government.
Given how learning is increasingly shaping
% affecting 
% us as 
%infused
% individuals---in
how we communicate, express ourselves, and are productive---%
its influence and integration are only likely to grow.
% \todo{communication (eg text completion, translation), personal relations (dating), fitness, health monitoring}.
This requires us to think carefully about the role we envision for machine learning in society, as it is forming now, and as we would like it to be.

If we accept that machine learning has the capacity to be socially beneficial, 
then ideally, we would like it to help in improving outcomes for everyone.
But economic theory casts doubt as to the feasibility of such an aspiration.
A basic economic truism is that
whenever people benefit from something,
that something will become a scarce resource,
over which people will then contend.
% Drawing on this,
Our key point, which we will argue throughout,
is that learning in social context is inherently, and inevitably,
about how \emph{some} form of limited resource is allocated;
we will give various examples of such.
When there is more demand than resources,
the inevitable reality is that
% someone must make a decision about who gets what.
not everyone can get a piece of the cake.
The important implication is that %,
learning algorithms become the determinants of allocation,
finding themselves in a position of making
decisions about who gets what (and who doesn't). 
% whether they intend to, or not.
For some tasks this is intentional, but more often it is not.

% The important implication is that %,
% % in effect,
% learning algorithms find themselves in a position of making
% % all learning algorithms make
% decisions about who gets what (and who doesn't)---%
% whether they intend to, or not.
% % all learning algorithms make decisions about who gets what
% % (and who doesn't)---even if implicitly and indirectly. 
% % \squeeze

% \todo{emphasize agency more, eg (1) resources, (2) *contend*}

In some cases, predictions support downstream decisions in which resources are clearly scarce, such as in university admissions or job hiring,
or in which risk must be hedged,
such as loan approval or insurance.
In other cases, scarcity can be more nuanced, but is nonetheless a substantial factor; for example, digital goods are technically of unlimited supply,
but which recommended items are eventually purchased,
and from which producers,
is naturally restricted by the (bounded) choices of users.
We posit that the issue of limited resources and their allocation holds much more broadly,
and applies to most predictive tasks that takes place in social context---even when there are no explicit resources,
or when the true objective is to simply maximize accuracy.
% In fact, we claim the notion of scarcity is fundamental to machine learning itself.
\squeeze

The problem is that conventional learning frameworks are designed to make predictions, not allocate resources.
Thus, as we pursue ever-improving accuracy,
we are possibly missing out (or even deteriorating) the ability to make effective and beneficial allocations.
We believe that many instances in which the use of machine learning has led to 
undesired outcomes, even if unintentional, can be explained by this shortcoming.
% For example,
% \todo{examples; here? throughout?}
% - bias - hiring (amazon), health insurance, apple card dredit limit, photo tagging (gorillas), recidivism (compas)
% - covid vaccinations
% - traffic predictions
% - recsys - extreme content, polarization
As we argue, the main issue with limited resources is not their limitation per se,
but the fact that people have interest in securing those resources for themselves.
% which they will act to obtain.
This creates competition either between the system and its users
(if they have differing interest),
amongst users themselves (directly or indirectly), or both.
The crux of conventional learning tools is that they fail to acknowledge the role of \emph{human agency} and its implications on learning outcomes.
\squeeze

Our goal is to promote the study of learning algorithms that are aware of the economic context in which they operate, and are explicitly designed to promote favorable social outcomes---by accounting for
resource scarcity and human agency, and how they relate.
% for the scarcity of resources and the agency of users.
Towards this, our main thesis is that learning frameworks should be designed to innately support a notion of \emph{social welfare}.
In economics, welfare quantifies the overall benefit to agents in an economic system,
and questions regarding the estimation, maximization, and distribution of welfare are central to the analysis of any such system.
% The study of welfare in economics dates back to Adam Smith \tocite;
Drawing on ideas from the field of welfare economics,
% offers a plethora of tools, methodologies, and ideas.
we propose to adopt its main principles---%
namely \emph{efficiency} and \emph{equity}---%
and adapt them to the purposes and needs of current machine learning practice.
We discuss the potential merits of this approach, 
the technical and conceptual challenges it presents,
the necessary steps to ensure its successful adoption,
and the limitations that will likely still remain.
\squeeze

% We believe this presents an indispensable resource that can be used by the learning community to design welfare-aware learning approaches in an informed and disciplined manner.
% This position paper aims to establish a concrete connection between machine learning and the field of welfare economics.



\subsection{Setting and scope} \label{sec:setting}
% [short informal statement + ref to designated section?]
For concreteness, we focus on the fundamental 
learning task of maximizing predictive 
% setting of discriminative supervised learning,
% where the goal is to maximize
accuracy by training a 
% predictive
model on
a sample set of 
labeled data.
%  While simple, this setting is well understood in theory, highly established in practice,   and will likely remain to be widely used given its impact and many success applications.  
  However, all the ideas described here are easily applicable to other learning paradigms, including today's generative models. 
% and has made much impact as the main workhorse of modern machine learning.
We follow the conventional supervised learning paradigm
and assume data is in the form of feature-label pairs $(x,y)$
sampled iid from some unknown distribution $\dist$.
The data we consider represents humans;
we will typically think of inputs $x$ as describing individuals 
(e.g., loan application, resume, movie viewing history, past consumer choices),
labels $y$ as describing outcomes of interest
(e.g., loan return or default, job qualification, movie rating, satisfaction),
and $\dist$ as representing the population.

% \hf{ the following para could be removed, if we need extra space}
 
Although our goal is to discuss how learning can promote social good,
we will insist that accuracy remains an integral part of the learning objective.
This is both because accuracy has value in and of itself,
and because predictive methods are, and likely will continue to be,
a primary tool used in practice.
Thus, we seek to retool the conventional supervised learning framework
towards the goal of welfare maximization \emph{through} the use of accurate predictions.
This will allow us to capitalize and build on existing tools, knowledge, and practice.
  Because we consider limited resources and their (sometimes implicit) allocation, our discussion must extend to consider policies operating on    the basis   of predictions,   in the style of    \emph{prediction policies} of  \cite{kleinberg2015prediction}. 
 
 

\subsection{Limitations of current practice}

It is tempting to hope that more data, more compute, and more sophisticated learning algorithms will pave the way to a better tomorrow.
But merely improving predictions, whether to match or go beyond human capabilities,
still presents inherent limitations.
Consider an example:
% \squeeze

% \todo{demonstrate through example(s) how things can break. illustrate tension between accuracy and welfare, and why pursuing the former does not guarantee the later.}

\textit{%
A school receives funding for providing students with targeted aid intended to help them pass an exit exam that is required for graduation.
To decide who will be selected for the program,
the school obtains past data on students that participated in earlier programs and trains a model to predict the likelihood of the aid being helpful.
It then uses the model to determine which new students to admit.
}

% - problem solved! / what could be better?
On its face, this approach seems reasonable---%
but of course things are not so simple:
the school may wish to maximize the impact of aid,
but doing so by maximizing accuracy
falls short on some important aspects.
%  is not always an effective strategy.
Consider the following:%
\footnote{Other issues are apparent in the example, e.g., distribution shift or causal considerations---but these are orthogonal to our concerns.
\squeeze
}
\begin{itemize}[leftmargin=1em,topsep=0em,itemsep=0.2em]
\item
Although the learning objective gives equal importance to all students,
this does not imply that all predictions will be equally accurate.
Since borderline cases are tougher to decide,
decisions could improve by giving them precedence.
\squeeze

% The learning objective gives equal importance to accuracy across all students.
% But borderline cases are tougher to decide;
% and since not all predictions can be equally accurate,
% decisions could improve by giving them precedence.

% % The fact that not all students can get aid 
% Limitations on the amount of available aid
% % The fact that the amount of aid is limited
% are not baked into the learning objective.

% limitations on the amount of aid available,
% The learning objective gives equal importance to accuracy across all students, and does not account for  downstream aid decisions. 
% But borderline cases are often tougher to decide, 
% % hence would benefit from more data. 
% % The learning objective does not directly account for  downstream  decisions,   and could improve if given precedence.
% % But tough decisions typically concern borderline cases,
% and could improve if given precedence.
% This can lead to suboptimal decisions regarding who to target.
\squeeze

\item 
Students that are selected may not necessarily choose or agree to participate.
The program might find itself with very few students and unused resources.
\squeeze

\item 
Contrarily, students that are interested in receiving aid are likely to compete for acceptance, given that space is limited.
This can bias selection towards students that were able to `appear' more qualified
(or that cheated).

\item
The above approach selects students on the basis of whether aid will be effective.
It does not ask 
% whether and how the \emph{students} benefit from passing the exam.
how beneficial it is for each of the students to pass the exam. 

\item 
Maximizing accuracy is used here as a proxy for maximizing the number of successes.
This makes no consideration of who receives aid, nor of how overall benefits from aid are distributed across the body of students.

% This is not the same as asking how \emph{meaningful} passing the exam will be for them;
% i.e., it doesn't consider how outcomes impact \emph{welfare}.
% \todo{outcomes, impact; how students themselves benefit as individuals}

\squeeze

\end{itemize}

The example shows that while accuracy goes some way towards welfare,
there is still an inherent tension between them.
Luckily, this tension has \emph{structure}, 
which reveals several `blind spots' of current machine learning practice.
These include:
% which our framework intends to capture.
% This includes:
(i) limited resources,
(ii) system decisions,
(ii) human agency,
and (iv) welfare considerations.
Our framework intends to capture this structure and exploit it for
% We set out to show this structure can be exploited for
promoting welfare through predictive machine learning.
% \squeeze


%================================================================


% \subsection{Case study: fair machine learning}
\subsection{What has been done, and what is still missing}
% \subsection{Current efforts and how we fit in}
The issue of aligning learning with societal preferences is of course not new,
nor is the introduction of social welfare
\citep{shirali24allocation,perdomo2024the}.
We believe however that the current literature requires a unifying formal framework 
% loose ends
for this notion.
Several subfields of machine learning have made advances on some fronts, but remain to lack in others.
A prime example is the literature on fairness in machine learning \citep{dwork2012fairness},
which clearly aims to advance some form of social good,
and for this has received much attention.
One concern that has been voiced is that fairness focuses on \emph{making things equal}, but is unable to express the benefit that results from such efforts
\citep{heidari2018fairness,hu2020fair}.
From our perspective, fairness takes one step towards acknowledging that \emph{something} is of limited supply (e.g., positive predictions),
but this is not made explicit.
More importantly, fairness constraints do not account for agency:
% somewhat surprisingly, 
they do not ask what users want,
nor how much they stand to lose or gain. % pending on outcomes.
Another issue is that such constraints do not consider 
user actions;
% the choices and actions of users that follow;
% make or the actions they take;
for example, predictions for school admissions may satisfy demographic parity,
but if members of the minority group do not \emph{choose} to apply initially,
then this guarantee is broken \citep{horowitz2024classification}.
\squeeze

One line of research that is close to ours is that of strategic learning.
This includes topics like strategic classification
\citep{bruckner2012static,hardt2016strategic}
and performative prediction \citep{perdomo2020performative} which have drawn much recent interest.
Strategic learning acknowledges and explicitly models user agency,
and in some cases, scarce resources.
And while some works discuss social aspects of learning
\citep[e.g.,][]{milli2019social},
\extended{\todo{add scmp, scai, recdiv}}
the focus remains primarily on maximizing accuracy
(and to some degree, notions of stability at equilibrium).
The idea of welfare is not a driving consideration,
nor is it an integral part of these frameworks.
% \squeeze

We believe there is need for an umbrella framework that ties these loose ends and 
incorporates them as special cases.
Such a framework will also be useful for 
pointing out what is missing in current solutions,
and what broader questions still needs addressing.
Welfare in economics is rarely something that is forced on a system;
rather, it should emerge as the solution to the question---%
`how can we appropriately align incentives'?
Another goal is therefore to provide social planners and policymakers a handle 
for steering learning toward preferable social outcomes, as they deem appropriate.
% to align incentives and 


\extended{
\red{%
-- top-k constraints (connect to school example) \\
-- airbnb example -- not all can get what they want (at the same time) \\
-- express what should happen \\
-- optimizing average
}
}

% -- vs fairness
% -- vs sc, perf pred


% needs order, structure, connect many loose ends - unifying framework
% “fairness” as a property of a classier

% fairness
% only constraints,  known limitations 
% restricted notions of equity
% about being equal, not better off (see paper)
% interpersonal diffs mostly in group, not value
% over time - can break, invert
% agency (scgk)
% other resources
% system may have other aims, eg revenue, need other ways to promote welf
% in econ, welfare is emergent- ideal 
% align incentives

% - Fair Classification and Social Welfare
% - Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making



%========================================================================

% \subsection{From accuracy to welfare: paving the path}
\subsection{Paving the path to welfare-aware machine learning}

Machine learning offers powerful tools for training accurate predictive models,
but the above limitations suggest that this might not suffice if we wish to solve more stressing societal problems.
Not by chance, social welfare offers a complementary perspective that enables such considerations.
% way to formally reason about important social aspects---precisely those that are lacking in standard learning objectives.
We believe that current machine learning is missing,
and could much benefit from, incorporating a notion of welfare.

% \darkblue{%
\textbf{%
\underline{Position}:
In social contexts, machine learning should enable us to improve
our collective well-being.
% social welfare.
This requires a learning framework that is capable of expressing,
and provides means to optimize, the welfare of its users.
To promote this goal, we should exploit the power of learning to obtain accurate predictions---not shy away from it.
But accuracy cannot be the only consideration;
to support constructive social outcomes, learning must:
(i) explicitly consider resources, scarcity, and allocations;
(ii) account for human agency by modeling what users want, know, and do;
and (iii) adhere to well-specified social welfare objectives designated by a social planner.
}
% }

Throughout the paper we will make these ideas clearer, more precise,
better grounded, and placed in context.

\todo{solution should grow from within community}

% should:
%  - aim to maximize welfare - via prediction
%  - explicitly consider scarcity and allocations
%  - account for agency: what users want, know, and do
%  - have well-specified social welfare function, designated by a social planner

% \paragraph{Accuracy vs. welfare.}
% \paragraph{Similarities and differences.}
% Welfare offers properties that are complementary to those of accuracy.
% Nonetheless, we argue that the two notions bear sufficient similarities so that the gap between them can be bridged.
% We next discuss how this can be achieved.
% In this paper we propose a concrete way to effectively transition from accuracy-focused to welfare-aware machine learning.

\extended{%
\hf{Is there any hypothesis that we can  or want to make? }

\subsection{Proposed framework: road map}
% Our goal is to show how the conventional learning framework can be extended to consider social welfare in increasingly intricate settings.
% The welfare-aware objectives we propose are modular and can be `wrapped' over standard learning objectives.
% As such, they remain to rely on accuracy,
% but enable---and in fact require---to explicitly model
% resources, allocations, and agency,
% as well as the role predictions play in
% %how these elements jointly 
% determining outcomes.
%
Our framework presents a hierarchy of problem formulations for welfare-maximizing learning,
% for maximizing welfare via learning in social contexts
organized into three `orders' of gradually increasing complexity:
\squeeze
\begin{itemize}[leftmargin=1em,topsep=0em,itemsep=0.3em]
\item
\textbf{\underline{Order 0}: Accuracy as a resource.}
% In tasks where humans are the object of prediction,
When prediction is provided as a service \emph{for humans},
and when those humans benefit from accurate predictions,
accuracy itself becomes a scarce resource
that requires careful allocation.
Examples include
medical diagnosis, financial risk prediction, career advice,
and personalized recommendations.

% preds as service (for us) - accuracy itself as limited resource

\item
\textbf{\underline{Order 1}: Predictions as decision aids}.
Predictions can help inform decisions made \emph{about us}.
But when decisions must be made collectively about a group of people, 
this often entails constraints on individual decisions.
Examples include resume screening, school admissions,
loans approval, insurance claims, and medical program eligibility.
\squeeze

% Who gains more and who gains less therefore becomes a question of 
% how such limited resources are allocated.

% support decisions (about us) - actual resources, direct allocation by system decisions

\item
\textbf{\underline{Order 2}: Predictions that empower choices.}
A primary use of predictions in social settings is to facilitate and improve the choices made \emph{by us}.
This makes us, in some sense, a finite resource over which platforms,
service providers, sellers, and content creators contend.
Examples include recommendation systems,
online market platforms,
and job applications and hiring.
% and competitive prediction markets.


% improve choices (by us) - actual resources, indirect allocation by user choices

\end{itemize}

Our framework is built in a bottom-up fashion:
% starting with the conventional supervised learning framework at its core.
The lowest order coincides with the standard objective of maximizing predictive accuracy,
but provides a novel welfare perspective suited for social tasks.
% integrates aspects that are unique to social tasks.
% highlights important aspects that are unique to social tasks.
Each higher order then builds on and generalizes the one below it,
this by adding to the objective another layer of economic complexity,
focusing first on the system decisions (order 1),
and then on user choices (order 2).
% \squeeze
As such, our framework is based on accuracy maximization at its core,
but enables---and in fact requires---to explicitly model resources, allocations, and agency,
as to specify the role predictions play in
%how these elements jointly 
shaping social outcomes.
% \squeeze

\todo{think about a graph to summarize all these orders into a single visualized picture? }

\paragraph{Desiderata.}
Throughout the paper we emphasize certain principles that we believe are important, useful, or even essential for the design of a new 
welfare-aware learning framework.
For example, the choice to design our framework around
a supervised learning core stems from the following:
\squeeze
\bbox
\textbf{Desideratum:} 
To promote welfare in machine learning,
we should build on existing tools and knowledge
and apply the minimal necessary modifications.
Welfare should be the \emph{aim}; accuracy can be the \emph{means}.
\ebox

\extended{%
\paragraph{Accuracy and us.}
As we argue, maximizing accuracy can be useful for promoting welfare, but also has value in and of itself.
For example, health risk calculators aid doctors in making informed treatment decisions, but clearly both doctors and patients benefit from being able to accurately anticipate outcomes. %
% \footnote{For example, consider two alternatives:
% A model that is 85\% accurate and improves average outcomes by 10\%, or a model that improves by 12\% but is only 65\% accurate; which would you choose?}
Accuracy can therefore be conductive to welfare indirectly
by facilitating reliability and trust.

% Insisting on accuracy can therefore serve to foster reliability and to facilitate trust.

% Predictive learning is the main workhorse of machine learning and has
% proved to be effective in countless applications.
% We believe this power can be conductive to social welfare---
}

Other considerations for focusing on supervised learning are its high popularity and wide familiarity;
its countless success stories across many domains and applications;
and its increasing role in other fields of machine learning
(e.g., unsupervised, generative, and reinforcement learning)
and beyond (e.g., causal inference, statistical estimation, mechanism design).
% increasing integration in other learning paradigms and beyond.%
% \footnote{Examples within machine learning include reinforcement learning (e.g., Q-learning, imitation learning),
% generative learning (e.g., next-word prediction in NLP, diffusion models in vision),
% and unsupervised learning (e.g., self-supervised learning).
% Examples in related fields include causal inference (\tocitec{athey papers})
% and statistical estimation (\tocite{zrnic papers}).
% \nir{mention algorithms with predictions? decision-focused learning? here or elsewhere?}
% }
We believe this is can help lower the barrier of entry for interested researchers and practitioners.
%  making the framework 
% understandable,
% accessible,
% and impactful.
% can help serve as a useful entry point 


\bbox
\textbf{Desideratum:} 
To permit easy adoption and maximize its potential impact,
a welfare framework should be simple to communicate and accessible to anyone 
with basic training in machine learning.
\ebox
}


% (and so can be thought of as `Order 0').
\paragraph{Paper outline.}
Our main thesis is that machine learning can benefit from the ideas and tools that welfare economics has to offer;
Sec.~\ref{sec:welfecon} discusses
its main principles,
and highlights the potential for synergy with machine learning.
% \Sec.~\ref{sec:framework} then highlights the rationale for our proposed taxonomy, along with formal problem statements.
In Sec.~\ref{sec:orders} we present
our proposed framework for welfare-maximizing machine learning and details its three orders.%
\priority{along with a discussion of its main opportunities and challenges.}
% This is followed in Sec.~\ref{sec:agenda} by a discussion of the framework's main opportunities and challenges.
% \blue{Sec.~\ref{sec:beyond} addresses higher-level issues regarding welfare in learning, such as measurement, evaluation, and regulation.} % of welfare.
Sec.~\ref{sec:alt_views} presents alternative views,
and Sec.~\ref{sec:discussion} gives concluding remarks and a look to the future.
% \squeeze

% - increasingly more involved, each order extends previous
% - all consider prediction, resources, and agency
% - beyond: social planner, eliciting policy prefs
% - first challenge: modeling

% aim to `wrap' existing (supervised) learning frameworks
% social welfare functions are not too different from learning objectives:
%  - (weighted) average over points/users
%  - a function of predictions, but more indirectly (vs. loss functions) through allocations/policy/behavior



 
% ideally, everyone should be happy - but this is impossible
% key point: learning in social context is predominantly about limited resources
% necessarily involves making decisions about who gets, and who doesn't
%  - if not explicit, then implicit - unavoidable!
% we argue for designing learning algorithms that are aware economic context



% \todo{illustration? maybe predictions $\to$ allocations $\leftarrow$ constraints $\Rightarrow$ welfare}

% \hf{Might be good to introduce and unify terminology here. Among "social planner", "system", "learner", "policy maker", we can pick one to use? Among "user", human, people, data points,  "agent", we can pick one (less important here probably as only two options)?}

% \hf{Let's use planner and system; individual and agent.} 
