%motivation
The prevalence of misinformation is a growing concern globally. Misinformation damages society in numerous ways. It threatens the maintenance of trust in vaccines and health policies\cite{do2022infodemics,macdonald2023meme}, can incite violence and harassment\cite{cdtFromFellows}, can undermine democratic processes (particularly elections)\cite{bovet2019influence,groshek2017helping}, and harms individual and societal well-being\cite{verma2022examining}. For example, during the 2018 Brazilian presidential election, manipulated photos, decontextualized videos, and hoax audio significantly influenced election results by aiding the victory of the main far-right candidate \cite{theguardianWhatsAppFake,santos2020social}. Another example is the spread of false information during the COVID-19 pandemic. Many people were persuaded that ineffective or counterproductive treatments such as alcohol-based cleaning products and an anti-parasitic drug could cure patients. The victims of this misinformation could suffer serious illness or even death \cite{bbcHundredsDead}.

Different countermeasures have been investigated to combat misinformation. These interventions can be categorized into two major groups: pre-emptive intervention ("prebunking") and reactive intervention ("debunking")\cite{ecker2022psychological}. Debunking involves fact-checking and correcting misinformation after it has been encountered. Fact-checkers use investigative practices to determine the veracity of content and dispute factual inaccuracies\cite{juneja2022human}.  %The most common debunking approach uses fact-checked information to dispute misinformation and provide accurate information\cite{hameleers2020misinformation,facebookIntoFacebook,aghajari2023reviewing}. 

%difficulties of overcoming misinfo
%describe debunking and spreading info. "two aspects of misinfo: how it spreads and how to debunk it once it's here."
However, the lasting effects of misinformation make it challenging to mitigate its influence once people have been exposed \cite{roets2017fake,lewandowsky2012misinformation}. Furthermore, fact-checking efforts are limited in terms of scale and reach, which restricts their effectiveness\cite{roozenbeek2020prebunking}. Given these challenges, it is not sufficient to rely purely on debunking efforts. Prebunking, on the other hand, works to build attitudinal inoculation, enabling people to identify and resist manipulative messages. This approach equips individuals to better manage misinformation they encounter in the real world\cite{prebin2024}. Prebunking is based on a range of educational measures \cite{dame2022combating,cook2017neutralizing}, which can include games \cite{roozenbeek2019fake,cook2023cranky}.

%helping by teaching people  

%preemptive corrections before misinformation is encountered, effectively reducing reliance on misinformation. 

%This includes digital media literacy education activities\cite{dame2022combating,cook2017neutralizing} and designing serious games to improve media literacy\cite{roozenbeek2019fake,cook2023cranky}. 
%Prebunking becoming an important 



%valuable complement by raising people's awareness and understanding of misinformation, helping them more effectively navigate credible, biased, and false information. One promising application of prebunking is through game-based learning. 

%games + research gap
Recent research indicates that the game-based learning approaches are potentially useful prebunking interventions. These games educate and build resistance in people exposed to misinformation\cite{traberg2022psychological,kiili2024tackling}. In games such as "Bad News,"\cite{roozenbeek2019fake} "Harmony Square,"\cite{harmonysquare} "Go Viral!"\cite{camCambridgeGame} and "Trustme!"\cite{yang2021can} players adopt the role of a misinformation producer whose task is to create and spread misinformation as efficiently as possible. Another approach, applied in the games "MAthE"\cite{katsaounidou2019mathe} and "Escape Fake"\cite{escapefake}, involves players acting as fact-checkers and challenging them to assess the validity of information. In some scenarios players can use tools such as search engines to gather clues. 

%the problem with standard PVP games (deterministic games), lack of natural interaction, use common language to explain better. doesn't feel real world. 
While gamified misinformation interventions have shown promise in teaching players about the nature of misinformation, %either from the perspective of the creator or the audience, 
the choice-based formats of these games can limit replayability. %and fun that make games engaging.
%Another Moreover, these games often present only one-shot interactions with misinformation, which may not capture the complexity and ever-changing nature of misinformation in the real world\cite{shin2018diffusion}. 
Additionally, such choice-based game formats require little cognitive effort from the player, who is presented with a limited number of pre-generated options. This can diminish player involvement in the game and reduce enjoyment of gameplay. Another factor limiting engagement is that most of these games are designed for single-player mode. Multiplayer mechanics, by contrast, are an effective way to enhance motivation and replayability in games\cite{mustaro2012immersion}. Social interactions also significantly contribute to player engagement in educational and other serious games\cite{lepper2021intrinsic}. Research has demonstrated that both collaborative and competitive gameplay can enhance the effectiveness of serious games\cite{cagiltay2015effect,bellotti2010designing}.
%and increase player motivation \cite{cagiltay2015effect,bellotti2010designing}.

%GAMES: 2 problems:
%1. not natural, not realistic, deterministic -> LLM solution.
%2. engagement and attitude -> two-player PvP (one against another goal).

To address the challenges of non-natural interactions and a deterministic game paths (with a view to fostering more open-ended exploration and engagement through Player versus Player (PvP)), we need to incorporate more complex scenarios. These would give players the ability to not only choose from preselected options, but also to actively generate content and implement their own strategies for debunking or creating misinformation. Additionally, implementing a PvP approach can be a training tool through which players can learn how to counter real-life misinformation.

%critically discern misinformation.


%During the game, players learn how several misinformation manipulation techniques can be used to produce credible fake news\cite{roozenbeek2019fake}. Another type of game involves players acting as fact-checkers whose task is to identify misinformation or fake news\cite{katsaounidou2019mathe,escapefake}.

%However, these games may overlook key features of misinformation. One noticeable feature is that misinformation typically involves more than isolated instances. During significant events like elections, wars, or health crises, misinformation evolves across various formats (text, pictures, infographics, videos) and stages. For example, during the COVID-19 pandemic, misinformation ranged from false cures and conspiracy theories about the virus's origin to vaccine misinformation, each gaining prominence at different stages[REF]. Another feature is that misinformation is constantly changing. Research found that political false rumors tend to become more intense and extreme over time\cite{shin2018diffusion}, and health misinformation statuses change as new evidence emerges\cite{tang2024knows}.

%evolution idea - using LLM to model public opinion.
%Therefore, there is a need to design a game that not only enhances the ability to distinguish misinformation but also raises awareness of its evolving characteristics and various forms. 
%Advancements in AI and Natural Language Processing (NLP) open the opportunities for creating engaging games. Large language models (LLMs), such as ChatGPT, have been applied in video games for generative narratives\cite{park2023generative}, NPC dialogue\cite{ashby2023personalized,uludaugli2023non}, and role-playing\cite{xu2023exploring}. 

%Integrating LLMs into misinformation learning games could dynamically adapt to player interactions, providing a more engaging and personalized experience. This is particularly useful for capturing and reflecting the dynamic nature of misinformation events. However, further exploration is needed to detail this integration.


Progress in AI and Natural Language Processing (NLP) provide new opportunities for creating more engaging game experiences. Large language models (LLMs) can simulate complex human interactions and societal dynamics\cite{ziems2024can}and have been applied in video games for tasks like generating narratives\cite{park2023generative}, non-playable characters (NPCs),dialogue\cite{ashby2023personalized,uludaugli2023non}, and role-playing scenarios\cite{xu2023exploring}. 
Previous work also demonstrated the opportunities for prompting the LLM to impersonate a specific character and create interactive dialogues from this perspective\cite{zhou2024eternagram,shao2023character}. Integrating LLMs into the game can introduce greater variability to in-game interactions and enhances both engagement and replayability. As the effectiveness of many inoculation interventions tends to diminish over time, developing an enjoyable and replayable game that consistently reinforces players' cognitive "resilience" against misinformation is an essential advancement in this field\cite{wells2024doomscroll}. Applying LLM to the game also has the potential to increase the educational impact of the intervention. It allows users not just to select from a range of options but also to put their input into the model and receive individual feedback tailored to this input.

%To bridge the gap in misinformation education games and explore LLM-driven games, 
Inspired by previous misinformation game interventions, this research has involved the development of a PvP misinformation education game called \textit{Breaking the News}. In our game, two players are assigned either the role of a misinformation creator (referred to as an "influencer" in the game) or a counteractor of misinformation (referred to as a "journalist-debunker" in the game). The influencer creates misinformation posts in a system that mimics a social media environment, while the debunker seeks to counter these messages by presenting compelling arguments. LLMs are used to represent public opinion in the "country" where the game events take place. The goal for both players is to earn the trust of the citizens and convince them to believe the information they present. 

In this paper we aim to answer the following research questions: 

\textbf{RQ1:}  
How may we empower players to understand the processes of misinformation generation and misinformation debunking through a GenAI-based PvP game?

\textbf{RQ2:} 
What behaviors do players exhibit when they are asked to generate versus protect against misinformation?
 
In this paper, we present the design and evaluation of the PvP game. We conducted a mixed-method study with 47 participants, using a within-subjects design and pre- and post-surveys for repeated measures. Our findings suggest that through gameplay, participants improved their ability to reflect on instances of misinformation, raised their levels of media literacy, expanded their repertoire of strategies applied to countering misinformation, and improved their discernment abilities. This study contributes to the growing body of work analyzing misinformation education games. Specifically, we provide insights into integrating LLMs and interactive PvP mechanics in media literacy contexts. We also offer practical guidance for the design of serious games aimed at combating misinformation in a dynamic, real-world manner.

%based on events rather than isolated posts or headlines. %In our game, %two different parties (debunker and disinformation creator (influencer) are battling for influence on people's opinion about event.control, and the hearts and minds of their citizens and the global community.
%two players are assigned either the role of a misinformation maker (influencer) or a misinformation stopper (debunker). %One player will start with an unfolding event and will experience the creation and dissemination of information and misinformation in various formats and stages. The other player will have to identify misinformation and use different countermeasures to respond and combat misinformation in the game. After the second player's responses to misinformation, they will receive simulated reactions from a group of citizens, generated by LLM, and decide on the next steps. After a few rounds, mimicking misinformation diffusion patterns, the game will have results. 

%The influencer will create misinformation posts, while the debunker tries to resolve the issue by proposing compelling arguments. The LLM-4 is representing represent the public opinion of several citizens in the "Country" where the game events take place.

%The goal for both players is to earn the trust of the citizens and convince them to believe the information they present.

%to align more closely with their direction. Once the game is finished, the players will have a chance to review their strategies at different stages. 

%The game aimed to enhance players' ability to reflect on instances of misinformation, raise their media literacy, expand their repertoire of strategies applied to counter misinformation, and improve their discernment abilities.

%for real-world encounters.
%Define player versus player.


%needs to be more conservative here:
%RQ2: What behaviors do players exhibit when they are asked to generate and protect against misinformation?

%what study did you do?
%what are the 3 major findings?
%our contribution (short version).
