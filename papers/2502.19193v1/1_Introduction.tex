\section{Introduction} % 24号 初稿 
Social media platforms such as X, Facebook, and Sina Weibo have transformed how billions of people communicate and share information, becoming major hubs for content creation, dissemination, and engagement. To maintain a healthy online environment, platform operators implement content moderation policies to identify and prevent policy violations. Under these constraints, users may develop language expression—such as coded language, metaphors, or ambiguous expressions—to circumvent automated detection \cite{hunt2025digital}, creating an adversarial interaction between user tactics and platform enforcement.

Simultaneously, private or direct messaging channels can provide fertile ground for covert communications, where individuals seeking to coordinate scams, illicit trade, or other criminal activities mask their intentions with subtle linguistic shifts. The evolution of these hidden tactics complicates the task of law enforcement and platform moderators, who must balance effective oversight against privacy and free expression concerns. Employing simulation-based approaches to examine how language evolves under various moderation policies can shed light on emerging patterns of evasion. Such insights enable stakeholders to refine their tools and policies, reducing the spread of harmful content while preserving open, vibrant communication within social ecosystems.

Effectively simulating the evolution of language demands robust natural language processing capabilities. In recent years, the rapid development of Large Language Models (LLMs) has opened new avenues for simulating the dynamics of social systems.
LLMs, with their ability to understand and generate sophisticated language, have become powerful tools for simulating the evolution of language. Numerous studies have explored the application of LLMs in simulating human user behaviors across various scenarios. For example, \cite{hua2023war, park2023generative, gao2023s3} integrated LLMs with multi-agent systems to simulate micro-social networks, observing agent behaviors and strategies that reflect human interaction patterns. In \cite{fu2023improving}, LLMs were used to simulate strategies in negotiation games, continuously optimizing bargaining tactics through iterative self-play; additionally, LLMs have achieved significant results in social reasoning games (such as Werewolf), developing effective game strategies by analyzing historical communication patterns \cite{xu2023exploring}, demonstrating their potential for evolving behaviors in dynamic contexts.

Although LLMs have been widely adopted for understanding human intentions and simulating social system dynamics, their potential for investigating social media users' language evolution under stringent content moderation policies has yet to be fully realized. Three key dimensions warrant attention in this area. First, the evolution of language is not solely driven by user behavior but also shaped by platform-level content moderation policies, resulting in a distinctly adversarial interaction. Second, such a scenario must not only circumvent regulation but also ensure that information can be accurately conveyed—a conflict-laden and complex set of objectives that significantly heightens the challenge of strategy evolution. Third, effective simulation of language evolution cannot rely solely on inference from existing corpora, because an overreliance on static data may limit the emergence of new strategies, making it difficult for models to capture the dynamic changes arising during the process of language evolution.


To fill these gaps, this study proposes a multi-agent framework based on LLMs that defines two core roles: participant agents and supervisory agent. In our framework, participant agents simulate real users by employing LLMs to execute a cycle of reflection, planning, and dialogue—generating conversation in line with specific language strategies and continuously iterating on these strategies. Meanwhile, supervisory agents employ LLMs to act as the regulatory system—reviewing content according to the given regulations, identifying regulation violations, and providing feedback. Through this interplay, the framework closely replicates the real-world regulatory and adversarial environments encountered on social platforms.
Addressing the inherent complexity of strategies, our framework decomposes them into “constraint strategies” (for evading regulation) and “expression strategies” (for accurately conveying information). This approach not only reduces simulation difficulty but also increases interpretability. 
Furthermore, to better simulate the dynamic process of language strategy evolution, our framework innovatively employs LLMs as operators within Genetic Algorithms (GA) to directly manipulate textual language strategies via selection, mutation, and crossover. Here, the selection represents the adoption of effective expressions, mutation reflects the emergence of novel, covert expressions under regulatory pressure, and crossover simulates the combination of different strategies to enhance adaptability.

Our main contributions are as follows:
\begin{itemize}
    \item We introduce an LLM-driven multi-agent framework to simulate the language evolution under regulated social media platforms. Specifically, such language evolution is realized through the interaction between participant agents and supervisory agent;
    \item We propose a dual design of language strategy, separating constraint and expression strategies to balance evasive tactics with clear communication, enhancing both the effectiveness and explainability of the simulation;
    \item We utilize LLMs as the operator within the GA, executing selection, mutation, and crossover directly on nature language-based language strategy, thereby enabling a more faithful evolution of language strategy;
    \item We comprehensively evaluate the framework’s effectiveness in three aspects: (1) effectiveness in language evolution through two simulation scenarios: an abstract password game and a simulated illegal pet trade; (2) real-world relevance of the language evolution through a subjective user study with 40 participants; and (3) effectiveness of GA-based strategy evolution through an ablation study.
\end{itemize}


Preliminary ideas and results of this study were presented in \cite{DBLP:conf/cec/CaiLZLWT24}. Building upon this earlier work, we extend our study with the following improvements:
\begin{itemize}
    \item The initial study shows certain limitations in strategy optimization. It relied on LLMs to directly generate an entire set of new constraint and expression strategies in each reflection, making it difficult to balance global strategy adaptability with local contextual details, leading to unstable evolutionary outcomes. To address this, we extend the original framework by incorporating GA, i.e., introducing selection, crossover, and mutation operations to optimize and evolve the strategy. 
    
    \item The initial experiments only assessed whether the framework could successfully evade regulatory constraints and accurately transmit information in a controlled, constrained environment. In this study, we have reinforced the evaluation from multiple perspectives. First, we conducted a more comprehensive performance evaluation by incorporating multiple latest versions of state-of-the-art LLMs for comparative analysis, ensuring timeliness and relevance in the evaluation. Second, we introduced an additional user study, involving 40 human reviewers to verify the real-world applicability of the generated language strategies. Finally, we conducted ablation studies, focusing on the effectiveness of the newly introduced GA within the framework. 
\end{itemize}

The remainder of this paper is organized as follows: 
Section~\ref{sec: RelatedWork} provides background and discusses related work. 
Section~\ref{sec: method} then introduces our proposed simulation framework in detail. 
Section~\ref{sec:evaluation} describes the experimental setup, presents results, and offers discussions. 
Finally, Section~\ref{sec: conclusion} concludes the paper and provides an outlook on potential directions for future work.

