\section{Framework Design}
\label{sec: method}
Our framework aims to simulate the evolution of language on social platforms by simulating the evolution of underlying language strategies.
The evolution of language strategies on social platforms is driven by conflicting goals: the desire for self-expression and the constraints on that expression. Users adjust their strategies to balance these demands. Our framework includes two types of agents to represent these motivations: the supervisory agent, responsible for limiting user expression, and the participant agents, who aim to convey specific information to one another. Participant agents continuously learn from past experiences through ongoing dialogues to develop their language strategies, effectively transmitting information while avoiding detection by the supervisory agent.

In this section, we first present an overview of our framework, then provide a detailed explanation of the four modules within the participant agent, and finally introduce the design of the supervisory agent.

\subsection{Overview}
\begin{figure*}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/overview_v9.png}
    \caption{Framework Overview. The framework consists of two participant agents and a single supervisory agent. The iterative process follows steps 2 through 5, where participant agents continuously refine their language strategies while the supervisory agent identifies regulation violations.}
    \label{fig:overview}
\end{figure*}

LLMs serve as the core of each agent in our framework, leveraging their powerful natural language processing capabilities to drive dialogue generation and strategy optimization. To capture the iterative nature of strategy evolution, we define a round as the basic unit where strategies evolve through a complete cycle of interactions between participant agents and the supervisory agent. Within each round, a turn consists of a single exchange of dialogue between participant agents, followed by a review by the supervisory agent. The system's operational process is as follows:
 
\begin{enumerate}
\item In the initial stage of the framework, each agent is initialized with role settings, experimental background knowledge, and global objectives.

\item Next, each round begins, and the participant agents update their strategies, forming an iterative process. Before the dialogue starts, the reflection module is first activated to generate new constraint strategies based on past violation logs. Appropriate strategies are selected from the strategy pool for crossover. Finally, four strategies are selected from the updated strategy pool as the constraint strategies for the current round.

\item The planning module then integrates the expression strategies chosen in the previous round with the constraint strategies selected for the current round, generating an abstract plans to guide the dialogue for the current round.

\item Subsequently, the participant agents begin the dialogue based on their respective plans. Once all participant agents have generated their responses, it is considered the end of one turn, and the dialogue content is stored in the dialogue logs.

\item Subsequently, the participant agents begin the dialogue based on their respective plans and the context of the dialogue. Once all participant agents have generated their responses, it marks the end of a turn. At the end of each turn, the supervisory agent reviews the dialogue content to identify any regulation violations. If a violation is detected, the supervisory agent stops the round and provides feedback. If no violations are found, the dialogue proceeds to the next turn. After each turn ends, the memory is updated. This iterative process of dialogue and review continues until all predetermined rounds are completed.

\item If the dialogue successfully completes the predetermined number of turns, the framework enters the interview stage. The participant agents compare their understanding of the dialogue content. During this stage, the reflection module is reactivated to update the expression strategy pool, and four expression strategies are selected as the strategies for the next round.
\end{enumerate}


\subsection{Participant Agents}
To effectively simulate the internal dynamics of users during strategy evolution, our participant-agent framework is designed to balance the conflicting objectives of accurate information transmission and regulatory evasion. To achieve this, each agent employs two distinct types of strategies. 
Constraint strategies are designed to help participant agents evade detection and intervention by the supervisory agent, continuously optimizing based on past violations. Consider a scenario where a buyer seeks to purchase a parrot through a social platform, but the trade of animals is prohibited by the platform's content regulation policies. In this scenario, a constraint strategy might be to “avoid directly mentioning specific animals or transactions.”
Expression strategies aim to enhance the clarity and effectiveness of information transmission, ensuring that intentions are accurately understood. In this scenario, an expression strategy would focus on describing the key characteristics of the parrot as precisely as possible, such as its “detailed description of the parrot’s key traits, including its plumage and ability to mimic sounds,” to ensure effective communication.

Our participant-agent framework consists of four key modules, each driven by an LLM: the memory module, which stores dialogue-related context; the dialogue module, which generates conversation content; the reflection module, which refines strategies based on past interactions; and the planning module, which balances constraint and expression strategies to generate abstract plans.

\subsubsection{Memory Module}
The memory module stores dialogue logs, background information, violation logs, the strategy pool, and the current strategies and plans.
The dialogue logs stores the dialogue content, while the violation log records instances of regulation violations detected by the supervisory agent.
The background information includes role settings, experimental background knowledge, and global objectives.
For example, "Suppose your name is Amy, and you are chatting with a user on a social platform. You want to buy a parrot from them, but the trade of animals is prohibited... You need to convey your intention to buy the parrot while evading detection by the regulatory system..."

Background information, dialogue logs, and the current strategies and plans serve as short-term memory\cite{ATKINSON196889}, containing only the content from the current round. In contrast, violation logs and the strategy pool serve as long-term memory, which are not reset at the end of each round but are updated instead.

Excessive memory information can potentially distract the LLM and lead to a decline in performance \cite{shi2023large}. Hence, the violation logs in the memory module are regularly maintained to ensure optimal functionality. Specifically, when the length of the violation logs exceeds a predefined threshold, the system employs the LLM to summarize and consolidate the existing records. This maintenance process involves the LLM analyzing the current violation logs to generate concise summaries that capture key instances of regulation violations, thereby reducing the overall length of the log while retaining essential information. Additionally, the LLM identifies and merges similar failure records to eliminate redundancy, ensuring that multiple instances of violations stemming from the same strategy are combined into single, generalized entries. 

\subsubsection{Reflection Module}
The reflection module is a critical component of each dialogue evolution round, activated both at the beginning and at the end of each round. Its primary objective is to refine language strategies by leveraging historical interaction data. The module operates in two distinct phases:

\begin{enumerate}
  \item Constraint Strategy: At the start of a dialogue round, the module analyzes the violation logs to scrutinize previous failures. Based on this analysis, it formulates a constraint strategy aimed at circumventing supervisory agent detection in subsequent dialogues.
  \item Expression Strategy: Upon round completion, the module re-examines the dialogue logs to identify shortcomings in information transmission or unmet objectives. This evaluation guides the development of an expression strategy that enhances the precision of implicit information conveyed in future interactions.
\end{enumerate}

Although relying solely on an LLM for global strategy updates is straightforward \cite{DBLP:conf/cec/CaiLZLWT24}, this approach faces challenges in simultaneously capturing both global insights and local details. For instance, when maintaining constraint strategies, the LLM may focus excessively on frequently occurring errors in the violation logs, thereby neglecting valuable individual cases.

To address this issue, our framework incorporates GA-inspired mechanisms to optimize strategies, effectively balancing global consistency with local adaptation. In each dialogue round, strategy optimization is conducted through three key processes: selection\ref{sec:selection}, crossover\ref{sec:crossover}, and mutation\ref{sec:mutation}.
Notably, while the selection process is executed in every round, the crossover and mutation operations are triggered probabilistically based on a hyperparameter ranging between 0 and 1.

\paragraph{Selection}
\label{sec:selection}
The selection process employs the Upper Confidence Bound (UCB) algorithm to evaluate and choose strategies from the constraint strategy population. Each strategy is assigned a fitness score, denoted as $\text{UCB}_i$, that integrates both exploitation and exploration:
\begin{equation}
\text{UCB}_i = \frac{S_i}{T_i} + c \cdot \sqrt{\frac{\ln T}{T_i}}
\end{equation}
where:
  \(S_i\) is the number of successful utilizations of strategy \(i\) (for a constraint strategy, the number of times it was applied without being detected; for an expression strategy, the number of times it successfully conveyed the intended information).
  \(T_i\) is the total number of attempts for strategy \(i\).
  \(T\) is the cumulative number of strategy utilization across the population.
  \(c\) is a constant that balances exploration and exploitation.
The exploitation term, \(\frac{S_i}{T_i}\), reflects the success rate of strategy \(i\), while the exploration term, \(c \cdot \sqrt{\frac{\ln T}{T_i}}\), encourages the selection of less frequently used strategies. Strategies are then selected probabilistically based on the exponential of their UCB scores:
\begin{equation}
P_i = \frac{e^{k \cdot \text{UCB}_i}}{\sum_{j=1}^{N} e^{k \cdot \text{UCB}_j}}
\end{equation}
where \(k\) is a scaling factor ensuring adequate differentiation among probabilities and \(N\) is the total number of strategies in the pool.

\paragraph{Crossover}
\label{sec:crossover}
Following the selection phase, the reflection module selects a subset of strategies from the remaining population and employs the LLM to perform crossover operations. This process combines elements of the selected strategies to generate new ones. For example, the strategies “using pauses or filler words to obscure key content” and “quickly switching between multiple topics to avoid prolonged focus on sensitive content” can be crossed to produce a new strategy such as “using pauses to switch topics, thereby dispersing key information throughout the dialogue.” This mechanism fosters the creation of novel strategies that effectively balance information transmission and regulatory evasion.

\paragraph{Mutation}
\label{sec:mutation}
Given the vast solution space inherent to natural language, traditional mutation methods may produce individuals with limited relevance. To overcome this, our framework replaces conventional mutation with an approach that analyzes the most recent violation logs to extract and summarize new strategies. These newly generated strategies are then introduced into the current strategy pool, enhancing population diversity while maintaining high relevance.

At the end of each dialogue round, the fitness scores of all strategies in the current pool are updated. To ensure computational efficiency and preserve strategic diversity, the Reflection Module restricts the strategy pool to a maximum of 20 strategies; when this limit is exceeded, strategies with lower fitness scores are eliminated.

In summary, by integrating GA-inspired mechanisms, our framework dynamically adjusts strategies to capture subtle, context-specific local violations while maintaining global effectiveness through fitness-based selection. This balance between fine-grained local adjustments and overarching strategic objectives ensures robust adaptability in the evolution of language strategies.


\subsubsection{Planning Module}
The constraint strategy focuses on methods to bypass supervision, while the expression strategy aims to enhance the clarity and accuracy of information transmission. Although both strategies are critical for effective dialogue management, they often conflict with each other. Directly generating dialogue based on these conflicting strategies leads to increased complexity and may negatively impact the performance of LLMs.

To address this challenge, we implement the planning module as an embodiment of Chain-of-Thought (CoT)\cite{wei2022chain}, reducing the difficulty of generating dialogue based on potentially conflicting strategies by incorporating intermediate planning steps.

In the illicit pet trade scenario, where the constraint strategy prohibits directly mentioning specific animals due to regulatory requirements, while the expression strategy calls for accurate descriptions, the planning module generates plans that balance these strategies. For example, it may utilize metaphors or indirect descriptions, such as “a creature as colorful as autumn leaves with a melodic voice” instead of explicitly stating “a parrot with vibrant red feathers.”

\subsubsection{Dialogue Module}
The dialogue module generates response based on the dialogue context between participant agents. Specifically, agents extract dialogue logs and background information from the memory module and generate appropriate dialogue response guided by the instructions in the plans.

%Within the Planning Module, the prompts include several key components: “background information,” “dialogue log,” “constraint strategy,” “expression strategy,” “plan,” and “instructions.” The LLM is guided by the constraint strategy as the baseline, and the expression strategy is used to refine the abstract “plan” based on the context provided by the dialogue logs.

\subsection{Supervisory Agent}
Our framework's supervisory agent emulates prevalent content moderation mechanisms on social platform. Unlike participant agents that require complex background information, the supervisory agent's function and role are simplified to reflect real-world supervision characteristics.

The primary task of the supervisory agent is to ensure that content complies with content management regulations. To replicate contemporary review mechanisms that integrate automated keyword filters with human oversight, our supervisory agent employs a two-tiered approach: preliminary keyword filtering followed by detailed assessment using an LLM.
In the LLM-based filter, we use CoT to improve the reliability of reasoning while minimizing factors like positional bias. Specifically, we require the LLM not only to identify whether a violation has occurred but also to specify the exact violation and the reasoning behind it.
Additionally, the content management regulations of the supervisory agent can be modified at any time based on inputs from researchers, enabling a realistic simulation of the adversarial interactions between users and platform regulators.



%To address the interplay between expression and regulation, our framework defines two distinct types of strategies:
%\textbf{constraint strategy}: These are the baseline rules designed to help participant agents avoid detection and intervention by the supervisory agent. constraint strategies are derived from analyzing past violations and are continually refined through the evolutionary process to improve the agents' ability to communicate covertly.

%\textbf{expression strategy}: This refers to the methods and techniques aimed at enhancing the clarity and effectiveness of information transmission between participant agents. Expression Strategies are developed from the analysis of dialogue histories and interview records to ensure that the intended messages are accurately conveyed.

%%Through observation, we find that the evolution of users' linguistic strategies on social media has three main characteristics: transmissibility, innovation, and dynamism. Transmissibility refers to the widespread adoption and dissemination of successful linguistic strategies \cite{chuanbo}. Innovation \cite{chuangxin} denotes the continuous creation of new words or linguistic constructs within social networks to meet the ever-changing demands of communication. Dynamism \cite{leskovec2009meme} highlights changes in linguistic strategies due to regulatory shifts or changes in the discussion environment. To capture these characteristics, we use evolutionary computation to simulate these dynamic changes. Genetic algorithms are suitable for this purpose due to their foundational operations: selection, mutation, and crossover. These operations mirror the processes in social communication:
%\begin{itemize}
%\item \textbf{Selection} represents the adoption of successful linguistic strategies by the user population, akin to transmissibility.
%\item \textbf{Mutation} embodies the creation of new words or constructs, reflecting innovation.
%\item \textbf{Crossover} symbolizes the combination of different linguistic elements from various users, enhancing dynamism and adaptability to regulatory or environmental changes.
%\end{itemize}


%\subsubsection{Reflection Module}
%The reflection module is integral to each dialogue evolution cycle, being activated at both the commencement and conclusion of the cycle. Its primary objective is to refine dialogue strategies by leveraging historical interaction data. Initially, the module processes the violation logs to scrutinize previous failures, thereby formulating a constraint strategy designed to circumvent supervisory agent detection in subsequent dialogues. Upon cycle completion, the module reassesses the dialogue logs to identify shortcomings in information transmission or unmet objectives. This evaluation leads to the development of an expression strategy, which enhances the precision of implicit information conveyed in future interactions.
%
%Although it is straightforward to rely on an LLM for global strategy updates \cite{DBLP:conf/cec/CaiLZLWT24}, this approach presents certain challenges: each time the LLM extracts new information from the context to update strategies, it struggles to simultaneously account for both global insights and local details. For example, when maintaining constraint strategies, the LLM may overly focus on errors frequently appearing in the violation logs, thereby overlooking highly valuable individual records.
%
%To address this issue, our framework significantly strengthens the strategy optimization process in the reflection module by introducing the concepts of GA.
%Specifically, our framework introduces concepts similar to GA to assist in optimizing strategies. Each dialogue round's strategy consists of three parts: selection, crossover, and mutation.
%Selection: The selection process leverages the Upper Confidence Bound (UCB) algorithm to evaluate and choose strategies from the constraint strategy population. Each strategy is assigned a fitness score, denoted as $\text{UCB}_i$, which integrates both exploitation and exploration components:
%
%\begin{equation} \text{UCB}_i = \frac{S_i}{T_i} + c \cdot \sqrt{\frac{\ln T}{T_i}} \end{equation}
%
%where: \begin{itemize} \item $S_i$ is the number of successful utilizations\footnote{For a constraint strategy, it represents the number of times the strategy was applied without being detected. For an expression strategy, it refers to the number of times the strategy successfully conveyed the intended information.} of strategy $i$. \item $T_i$ is the total number of attempts for strategy $i$. \item $T$ is the cumulative number of strategy utilizations across the population. \item $c$ is a constant that balances the trade-off between exploration and exploitation. \end{itemize}
%
%The exploitation term, $\frac{S_i}{T_i}$, represents the success rate of strategy $i$, favoring strategies with higher effectiveness. The exploration term, $c \cdot \sqrt{\frac{\ln T}{T_i}}$, incentivizes the selection of less frequently used strategies, promoting diversity within the population. Strategies are then selected probabilistically based on the exponential of their UCB scores:
%
%\begin{equation} P_i = \frac{e^{k \cdot \text{UCB}_i}}{\sum{j=1}^{N} e^{k \cdot \text{UCB}_j}} \end{equation}
%
%where $k$ is a scaling factor that ensures adequate differentiation among strategy probabilities, and $N$ is the total number of strategies in the population. This weighted selection mechanism ensures that both high-performing and exploratory strategies have a fair chance of being chosen, maintaining a balanced and diverse strategy pool.
%
%Crossover: With a certain probability, after the selection phase, the reflection module selects a specified number of strategies from the remaining population and utilizes the LLM to perform crossover operations, combining elements of the selected strategies to generate new ones, which are then added to the current strategy pool. For instance, the strategies “using pauses or filler words to obscure key content” and “quickly switching between multiple topics to avoid prolonged focus on sensitive content” can be crossed by the LLM to produce a new strategy such as “using pauses to switch topics, dispersing key information across different parts of the dialogue.”
%
%Mutation: Due to the vast solution space of natural language entities, traditional mutation methods often result in individuals with limited task relevance. To address this issue, our framework replaces conventional mutation with an approach that analyzes the most recent violation logs to extract and summarize new strategies. These strategies are introduced as new individuals into the strategy pool. This method not only ensures an increase in population diversity but also maintains a high degree of relevance between the newly generated individuals and the task.
%
%At the end of each dialogue round, the fitness of all strategies in the current strategy pool is updated and returned to the population. 
%To maintain computational efficiency and strategic diversity, the reflection module restricts each strategy population to a maximum of 20 strategies. When the population exceeds this limit, the module performs elimination based on fitness scores. 
%
%By introducing GA, our framework enables the LLM to generate new, context-specific strategies during mutation based on small batches, such as the most recent violation logs, enhancing its focus on local information. This targeted mutation ensures subtle violations are effectively extracted and transformed into actionable strategies. Meanwhile, the fitness-based selection mechanism evaluates each strategy’s performance across the entire dialogue, maintaining global coherence. This balance between fine-grained local adjustments and overarching strategic objectives ensures adaptability in strategy evolution.
