\section{Related Work}
\textbf{Query Rewrite.} 
% Query rewrite or reformulation (QR) encompasses a range of methods designed to handle underspecified and ambiguous queries by reformulating them into self-contained versions suitable for retrieval or question answering systems. 
Historically, Query rewrite or reformulation (QR) methods have included the addition of terms to the original query, known as query expansion \cite{lavrenko2017relevance}, or iteratively rephrasing the query using similar phrases \cite{zukerman2002lexical}, or synonymous terms \cite{jones2006generating}. 
% When human-generated rewrites or reward signals are available, language models (LMs) are trained for question rewriting (QR) also \cite{elgohary2019can, anantha2021open, vakulenko2021question, qian2022explicit, ma2023query}.
Recently, the advent of large language models (LLMs) has spurred exploration into using these generative models to automatically resolve ambiguities during query processing.
% , thereby enhancing query modeling for downstream tasks. These tasks often involve improving information retrieval in a single QA setting. 
For instance, recent studies have prompted LLMs to provide detailed information, such as expected documents or pseudo-answers \cite{wang2023query2doc, jagerman2023query}. These techniques are particularly effective when a golden dataset for a specific domain is unavailable, necessitating the use of off-the-shelf LLMs tailored for the specific use-case.
% In our deployed system, we employ a similar approach by prompting LLMs, specifically \texttt{GPT-3.5 Turbo}, due to its clearance by our legal team for our use-cases and comparatively lower cost than GPT-4. 
However, a
% s highlighted in other studies , there are two primary limitations of using LLMs for query rewriting: 
LLM-based QR can suffer from concept drift when using only queries as prompts \cite{anand2023context} and also has high inference costs during query processing. 
% Our system has encountered similar issues, where the model undesirably inserted or modified parts of the text. 
To address both, we introduce an ambiguous query understanding component to guide the rewrite process, ensuring that only unclear queries are rewritten, thereby limiting the undesired rewriting problem and saving cost at the same time. 

\begin{figure*}[htbp]
    \centering
    \includegraphics[width=\linewidth]{figures/pipeline_and_architecture.pdf} %,height=4cm
    % \vspace{-0.35cm}
    \caption{Left: Proposed pipeline. Right: Architecture of our proposed ambiguity detection model.}
    \label{fig:pipline_and_architecture}
    \vspace{-0.5cm}
    %%\squeezeup
\end{figure*}

\textbf{Ambiguity Detection.} 
\label{sec:related_work}
Ambiguous queries are typically those that have multiple distinct meanings, insufficiently defined subtopics \cite{clarke2009overview}, syntactic ambiguities \cite{schlangen2004causes}, for which a system struggles to interpret accurately, resulting in inappropriate or unclear answers \cite{keyvan2022approach}. Detecting ambiguity in user queries, however, is a challenging task, as highlighted by several studies \cite{braslavski2017you, trienes2019identifying, guo2021abgcoqa}. Notably, \cite{trienes2019identifying} conducted the first comprehensive study on classifying questions as clear or unclear using logistic regression, especially in community platforms like Stack Exchange.
% However, their findings are not fully applicable to enterprise use-cases, as their research was limited to single questions and answers in community settings and they did not delve into the types of ambiguities that may arise in conversational agents or dialogue systems. 
% That being said, their research indicated that deep learning-based models outperform logistic regression models in text classification tasks, although logistic regression was ultimately used in their work for its interpretability and explainability in user interfaces. 
% A related study \cite{dhole2020resolving} tackled the task of detecting ambiguous queries on task-oriented dialogue systems (such as opening a bank account). However, these studies did not analyze the different types of ambiguities that might occur in conversational question answering (CQA). 
In CQA, \citet{guo2021abgcoqa} examined various ambiguities from a given text or story and also proposed methods for ambiguity detection and generating clarifying questions. 
% Interestingly, they framed ambiguity detection as a traditional question-answering task, adding ``ambiguous'' as a potential output, and built models based on BERT \cite{devlin2019bert}. Their best performing model achieved an F1 score of only 23.6\% on their dataset, which highlights the difficulty of detecting ambiguities in CQA task.
In the era of large language models (LLMs), researchers like \cite{kuhn2022clam, zhang2024clamber} have shown that these models can be prompted to detect ambiguous questions. However, \citet{zhang2024clamber} pointed out the limitations of LLMs in accurately detecting them, which our experimental results also validate. 
% Similar to these studies, we also experience a lower performance when we use LLM, namely GPT-3.5 Turbo, for ambiguity detection.  
% \citet{zhang2024clamber} also developed a taxonomy of ambiguities when conversing with LLM for information retrieval but omitted certain categories, such as syntactic and pragmatic ambiguities, which we found to be common in enterprise conversational agents. 
In addition, all these research works focus on ambiguity detection for generating clarifying questions rather than query rewriting. In enterprise AI Assistants, however, avoiding clarifying questions is crucial for a smooth user experience, making automatic ambiguity resolution using QR
% , such as query rewriting, 
highly desirable. Furthermore, existing works share insights from open-domain datasets which might not always translate to industries as enterprise datasets are often close-domain. To that end, this paper investigates the effectiveness of combining ambiguity detection with query rewriting to resolve ambiguities automatically, sharing best practices for industry settings.