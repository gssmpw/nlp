\section{Experimental Results}


\begin{figure*}[!hbt]\footnotesize
\centering
\includegraphics[width=0.95\textwidth]{images/ANOVA_test.png}
\caption{One-Way ANOVA: Model Score Distributions.}
\label{fig:anova_violin}
\end{figure*}

\subsection{Human Alignment Rate}

 Table ~\ref{tab:model_results} compares the HAR (\%) of several models. The original baseline Model has an 85.9\% rate. In our two step mechanism, we require following LLMs to re-evaluate the generated results prompted by our designed prompt.
First, we observe GPT-4o achieves 94.3\%, and its smaller version, GPT-4o-mini, scores 88.5\%. We also tested two versions of LLama (customized version), Llama 3.1 70B Instruct reaches 89.1\%, and the larger Llama 3.1 405B Instruct improves to 93.8\%. Interestingly, the top performer is Mixtral-8x7B Instruct with 95.8\%, showing that our designed mechanism generally aligns better with human expectations.



\begin{table}[ht]\footnotesize
\centering
% \caption{Comparison of Model Results After Two Step LLM as Judge}

\centering
\begin{tabular}{|l|c|}
\hline
\textbf{\centering Model} & \textbf{Human Alignment} \\ 
                          & \textbf{Rate (\%)}       \\ \hline
Baseline Model          & 85.9                     \\ \hline
GPT-4o                    & 94.3                     \\ \hline
GPT-4o-mini               & 88.5                     \\ \hline
Llama 3.1 70B Instruct     & 89.1                     \\ \hline
Llama 3.1 405B Instruct    & 93.8                     \\ \hline
Mixtral-8x7B Instruct      & 95.8                     \\ \hline
\end{tabular}
\caption{Comparison of Model Results After Two Step LLM-as-a-Judge}
\label{tab:model_results}
\end{table}


% \begin{figure*}[!hbt]\footnotesize
% \centering
% \includegraphics[width=0.8\textwidth]{images/ANOVA_test.png}
% \caption{One-Way ANOVA: Model Score Distributions. 
% This violin plot visualizes the score distributions for different models, including GPT-4o, GPT-4o-mini, Llama 3.1 70B, Llama 3.1 405B, and Mixtral-8x7B.}
% \label{fig:anova_violin}
% \end{figure*}

% Each violin represents the distribution's density, with a boxplot inside showing the median and interquartile range. The wider sections indicate where scores are more concentrated, while the thinner sections show sparsity.

\subsection{Model Score Distributions}
Figure~\ref{fig:anova_violin} compares the score distributions of tested five models. From this violin figure, we can observe that GPT-4o and Llama 3.1 405B show higher median scores and tight distributions. Their score profiles are steep and narrow around the median, indicating that these models not only perform well but also do so consistently with few outliers. In contrast, GPT-4o-mini and Mixtral-8x7B have lower median scores and broader distributions. The wider spread in their scores suggests greater variability, meaning these models may sometimes perform well but can also struggle with certain tasks, leading to occasional low scores.

The Llama 3.1 70B model appears to occupy an intermediate position, performing reasonably well with a slightly wider distribution compared to its 405B counterpart. This suggests that while it generally achieves competitive scores, it is more prone to fluctuations, reinforcing the observation that scaling up the model size contributes to both improved median performance and reduced variance.

The violin plot also captures subtle differences in the lower tail behavior of each model. GPT-4o-mini, for example, has a notably elongated lower tail, indicating that it is more susceptible to low-scoring outliers. This suggests that while it may occasionally achieve high scores, it also exhibits greater inconsistency. Similarly, Mixtral-8x7B, despite its relatively high median, demonstrates a greater spread, suggesting that it may be effective in some scenarios but is less robust overall.

Overall, this analysis highlights a clear trade-off between performance consistency and score variability. Models like GPT-4o and Llama 3.1 405B are preferable when reliability and stability are critical, as they consistently deliver high scores with minimal deviation. Conversely, GPT-4o-mini and Mixtral-8x7B, despite having competitive scores at times, introduce greater uncertainty, which could impact their suitability for applications where predictability and robustness are key considerations



% \begin{figure*}[!hbt]\footnotesize
% \centering
% \includegraphics[width=0.7\textwidth]{images/ANOVA_test.png}
% \caption{One-Way ANOVA: Model Score Distributions. 
% This violin plot visualizes the score distributions for different models, including GPT-4o, GPT-4o-mini, Llama 3.1 70B, Llama 3.1 405B, and Mixtral-8x7B. Each violin represents the distribution's density, with a boxplot inside showing the median and interquartile range. The wider sections indicate where scores are more concentrated, while the thinner sections show sparsity.}
% \label{fig:anova_violin}
% \end{figure*}






% \begin{table}[htb]
% \centering
% \caption{One-way ANOVA and Tukey HSD Test Results}
% \label{tab:anova_tukey_results}
% % \resizebox{\textwidth}{!}{%
% \begin{tabular}{lcc}
% \hline
% \textbf{Statistic} & \textbf{Value} \\ \hline
% F-statistic        & 10.3042        \\
% p-value            & 0.0000         \\ \hline
% \end{tabular}%
% % }
% \end{table}


\subsection{Statistical Significance Testing}
Table~\ref{tab:anova_tukey_results} provides One-way ANOVA and Tukey HSD Test Results as our statistical significance testing reveals notable differences in performance among HAR.

The One-way ANOVA test produced a significant F-statistic of 10.3042 and a p-value of 0.0000, indicating that at least one model's performance distribution differs significantly from the others. This confirms that the models do not perform identically and that there are observable differences in their scores.

From the pairwise comparisons shown in Table 4, we can observe that GPT-4o-mini demonstrates significant performance differences when compared to all other models. The adjusted p-values for comparisons involving GPT-4o-mini are consistently below the 0.05 threshold, indicating statistically significant differences. This suggests that GPT-4o-mini exhibits a distinctive performance profile that sets it apart from the other models, which may reflect underlying differences in its design or capabilities.

In contrast, GPT-4o does not show statistically significant differences when compared to Llama-3.1-405B, Llama-3.1-70B, or Mixtral-8x7B. The adjusted p-values for these comparisons are well above 0.05, suggesting that these models exhibit similar levels of performance. This similarity in performance among GPT-4o, Llama-3.1-405B, Llama-3.1-70B, and Mixtral-8x7B indicates that these models can be considered interchangeable for certain tasks or contexts where consistency across models is desired.

Further analysis of the Llama-3.1 variants and Mixtral-8x7B reveals that comparisons between these models yield non-significant differences. The adjusted p-values are consistently above the 0.05 threshold, indicating that these models perform comparably. This suggests that scaling from Llama-3.1-70B to Llama-3.1-405B does not lead to a statistically significant improvement in performance, despite the potential increase in computational resources or parameter count.

The contradiction between the violin plot and the statistical significance results highlights the distinction between observable performance trends and statistically validated differences. The violin plot suggests that scaling from Llama 3.1 70B to Llama 3.1 405B improves performance consistency. However, the Tukey HSD test results (p = 0.9984) show that this difference is not statistically significant. This discrepancy can arise because statistical tests primarily evaluate differences in mean performance rather than distributional stability, meaning a model could exhibit less variance without showing a statistically significant improvement in its average score. Despite the lack of statistical significance, the practical implications remain: Llama 3.1 405B demonstrates greater stability and lower variance, making it a more reliable choice for applications where consistent performance is crucial, even if its mean performance is not significantly different from that of Llama 3.1 70B. Whether the scaling is beneficial depends on the trade-off between prioritizing statistical significance versus practical model reliability, where the latter may still favor the larger model due to its reduced performance variability

These findings highlight important trade-offs when selecting models for different tasks. While GPT-4o-mini stands out with its unique performance characteristics, it also introduces a level of variability that may make it less predictable for certain applications. On the other hand, models such as GPT-4o, Llama-3.1-405B, and Mixtral-8x7B offer more consistent performance, making them suitable choices for scenarios where reliability and predictability are critical.

\begin{table}[!htb]\footnotesize
\vspace{0.5em}

% \resizebox{0.5\textwidth}{!}{%
\begin{tabular}{lcccccc}
\hline
\textbf{Group1}    & \textbf{Group2}       & \textbf{p-adj} \\ \hline
GPT-4o            & GPT-4o-mini                   & 0.0000                   \\
GPT-4o            & Llama-3.1-405B                 & 0.9392             \\
GPT-4o            & Llama-3.1-70B                & 0.9893                \\
GPT-4o            & Mixtral-8x7B                      & 0.0777                  \\
GPT-4o-mini      & Llama-3.1-405B                 & 0.0000              \\
GPT-4o-mini      & Llama-3.1-70B                    & 0.0000               \\
GPT-4o-mini      & Mixtral-8x7B                       & 0.0254            \\
Llama-3.1-405B   & Llama-3.1-70B                & 0.9984                \\
Llama-3.1-405B   & Mixtral-8x7B                     & 0.3762           \\
Llama-3.1-70B    & Mixtral-8x7B                 & 0.2263              \\ \hline
\end{tabular}%
% }
\caption{Pair Wise Statistical Significance Difference Testing}
\label{tab:pair_wise}
\end{table}


\vspace{-3mm}

\begin{table}[htb]\footnotesize
\centering
% \caption{One-way ANOVA and Tukey HSD Test Results}
% \label{tab:anova_tukey_results}
% \resizebox{\textwidth}{!}{%
\begin{tabular}{lcc}
\hline
\textbf{Statistic} & \textbf{Value} \\ \hline
F-statistic        & 10.3042        \\
p-value            & 0.0000         \\ \hline
\end{tabular}%
% }
\caption{One-way ANOVA and Tukey HSD Test Results}
\label{tab:anova_tukey_results}

\end{table}



