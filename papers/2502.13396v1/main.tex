
\pdfoutput=1


\documentclass[11pt]{article}
% \usepackage[review]{EMNLP2023}
% \usepackage[review]{acl}
\usepackage{ACL2023}
% \usepackage[review]{ACL2023}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage{algpseudocode}
\usepackage{float} % Include this in your preamble
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{latexsym}
% \usepackage{authblk}
% \
\title{Prompting a Weighting Mechanism into LLM-as-a-Judge in Two-Step: A Case Study}




% \author{ACL Anonymous Submission} 


\author{Wenwen Xie\textsuperscript{1}, Gray Gwizdz\textsuperscript{1}, Dongji Feng\textsuperscript{2},\\
\textsuperscript{1} Databricks 
\\
\textsuperscript{2} MCS department, Gustavus Adolphus College\\
{\tt wenxie0010@gmail.com , gray.gwizdz@gmail.com, djfeng@gustavus.edu}}
\newcommand{\Dongji}[1]{{\textcolor{blue}{\bf [DJ: #1]}}}




\begin{document}
\maketitle
\footnotetext[1]{Work does not relate to position at Databricks}

\pagestyle{plain} % Show simple page numbers at the bottom

%Indeed, we are yet to conduct comprehensive benchmarking studies with multiple LLMs that are exclusively focused on a complex task.

\begin{abstract}
% two steps help LLM as judge 

% The efficient retrieval of supporting resources remains crucial in industrial settings, where engineers face the cognitive burden of accessing vast amounts of technical information.

While Large Language Models (LLMs) have emerged as promising tools for evaluating Natural Language Generation (NLG) tasks, their effectiveness is limited by their inability to appropriately weigh the importance of different topics, often overemphasizing minor details while undervaluing critical information, leading to misleading assessments. Our work proposes an efficient prompt design mechanism to address this specific limitation and provide a case study. Through strategic prompt engineering that incorporates explicit importance weighting mechanisms, we enhance using LLM-as-a-Judge ability to prioritize relevant information effectively, as demonstrated by an average improvement of 6\% in the Human Alignment Rate (HAR) metric.

\end{abstract}



\input{Sections/0Intro}
\input{Sections/1RelatedWork}
\input{Sections/2General}
\input{Sections/3ExperimentalDesign}
\input{Sections/4Results}
\input{Sections/5Conclusion}




% \section{Acknowledgements}
% \Dongji{should say some disclaimer}


\bibliography{custom}
\bibliographystyle{acl_natbib}

\newpage
% \appendix
\input{Sections/appendix}



\end{document}
