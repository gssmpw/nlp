\section{Related Work}
Numerous studies have focused on deriving performance guarantees for Model Predictive Control (MPC). \cite{yu2020power} established constant dynamic regret for online MPC under perfect predictions and logarithmic prediction horizons, while \cite{zhang2021regret} demonstrated exponential decay of dynamic regret with increasing prediction horizons, though their empirical validation was limited. \cite{lin2021perturbation} introduced perturbation bounds for Linear Time-Varying (LTV) systems, leveraging them to prove competitive ratios and dynamic regret bounds. Similarly, works by \cite{shin2020decentralized}, \cite{shin2021controllability}, \cite{xu2019exponentially}, and \cite{na2022superconvergence} advanced perturbation analysis methods for online control, providing valuable theoretical insights.

Building on these, \cite{lin2022bounded} proposed a systematic framework that generalizes prior results, offering flexible performance guarantees for online MPC whenever perturbation bounds can be proven. The authors also used their framework to derive new theoretical results. However, like most prior work, this study lacks empirical validation, highlighting a general weakness in the literature. Thus, there is a critical need for a thorough empirical evaluation of performance guarantees to assess their practical applicability in real-world scenarios.