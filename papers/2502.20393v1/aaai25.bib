% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})




@INBOOK{6279976,
  author={Bottou, Léon and Chapelle, Olivier and DeCoste, Dennis and Weston, Jason},
  booktitle={Large-Scale Kernel Machines}, 
  title={Scaling Learning Algorithms toward AI}, 
  year={2007},
  volume={},
  number={},
  pages={321-359},
  doi={}}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@article{montavon2019explainable,
  title={Explainable AI: interpreting, explaining and visualizing deep learning},
  author={Montavon, Gr{\'e}goire and Binder, A and Lapuschkin, S and Samek, W and M{\"u}ller, KR},
  journal={Spring er LNCS},
  volume={11700},
  year={2019},
  publisher={Springer}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature machine intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{molnar2022,
  title={A guide for making black box models explainable},
  author={Molnar, Christoph},
  booktitle={Interpretable Machine Learning},
  volume={2},
  number={3},
  year={2018}
}

@article{wang2023comprehensive,
  title={A comprehensive survey of continual learning: Theory, method and application},
  author={Wang, Liyuan and Zhang, Xingxing and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2302.00487},
  year={2023}
}

@book{goodfellow2016deep,
    title={Deep Learning},
    author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
    publisher={MIT Press},
    volume={1},
    year={2016},
    URL={\url{http://www.deeplearningbook.org}}
} %note={\url{http://www.deeplearningbook.org}},year={2016}}


@inproceedings{
oikarinen2023labelfree,
title={Label-free Concept Bottleneck Models},
author={Tuomas Oikarinen and Subhro Das and Lam M. Nguyen and Tsui-Wei Weng},
venue={The Eleventh International Conference on Learning Representations (ICLR)},
year={2023}
}

@inproceedings{cbms,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  venue={International Conference on Machine Learning (ICML)},
  pages={5338--5348},
  year={2020},
  organization={PMLR}
}

@INPROCEEDINGS{Dosilovic2018ExplainableAI,
  author={Došilović, Filip Karlo and Brčić, Mario and Hlupić, Nikica},
  venue={41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
  title={Explainable artificial intelligence: A survey}, 
  year={2018},
  volume={},
  number={},
  pages={0210-0215}
}

@InProceedings{ante-hoc-framework,
    author    = {Sarkar, Anirban and Vijaykeerthy, Deepak and Sarkar, Anindya and Balasubramanian, Vineeth N},
    title     = {A Framework for Learning Ante-Hoc Explainable Models via Concepts},
    venue = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {10286-10295}
}

@article{shin2023closer,
  title={A closer look at the intervention procedure of concept bottleneck models},
  author={Shin, Sungbin and Jo, Yohan and Ahn, Sungsoo and Lee, Namhoon},
  journal={arXiv preprint arXiv:2302.14260},
  year={2023}
}

@misc{steinmann2023learning,
      title={Learning to Intervene on Concept Bottlenecks}, 
      author={David Steinmann and Wolfgang Stammer and Felix Friedrich and Kristian Kersting},
      year={2023},
      eprint={2308.13453},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{NEURIPS2020_ecb287ff,
 title={On completeness-aware concept-based explanations in deep neural networks},
  author={Yeh, Chih-Kuan and Kim, Been and Arik, Sercan {\"O} and Li, Chun-Liang and Pfister, Tomas and Ravikumar, Pradeep},
 venue={Proceedings of the 34th International Conference on Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{margeloiu2021concept,
  title={Do concept bottleneck models learn as intended?},
  author={Margeloiu, Andrei and Ashman, Matthew and Bhatt, Umang and Chen, Yanzhi and Jamnik, Mateja and Weller, Adrian},
  journal={arXiv preprint arXiv:2105.04289},
  year={2021}
}

@inproceedings{chauhan2023interactive,
  title={Interactive concept bottleneck models},
  author={Chauhan, Kushal and Tiwari, Rishabh and Freyberg, Jan and Shenoy, Pradeep and Dvijotham, Krishnamurthy},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={5},
  pages={5948--5955},
  year={2023}
}

@article{kim2023concept,
  title={Concept Bottleneck with Visual Concept Filtering for Explainable Medical Image Classification},
  author={Kim, Injae and Kim, Jongha and Choi, Joonmyung and Kim, Hyunwoo J},
  journal={arXiv preprint arXiv:2308.11920},
  year={2023}
}

@inproceedings{collins2023human,
  title={Human Uncertainty in Concept-Based AI Systems},
  author={Collins, Katherine Maeve and Barker, Matthew and Espinosa Zarlenga, Mateo and Raman, Naveen and Bhatt, Umang and Jamnik, Mateja and Sucholutsky, Ilia and Weller, Adrian and Dvijotham, Krishnamurthy},
  booktitle={Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={869--889},
  year={2023}
}

@article{LearningConcise,
  title={Learning Concise and Descriptive Attributes for Visual Recognition},
  author={Yan, An and Wang, Yu and Zhong, Yiwu and Dong, Chengyu and He, Zexue and Lu, Yujie and Wang, William and Shang, Jingbo and McAuley, Julian},
  journal={arXiv preprint arXiv:2308.03685},
  year={2023}
}

@inproceedings{LaBo,
  title={Language in a bottle: Language model guided concept bottlenecks for interpretable image classification},
  author={Yang, Yue and Panagopoulou, Artemis and Zhou, Shenghao and Jin, Daniel and Callison-Burch, Chris and Yatskar, Mark},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19187--19197},
  year={2023}
}

@inproceedings{yuksekgonul2022post,
  title={Post-hoc Concept Bottleneck Models},
  author={Yuksekgonul, Mert and Wang, Maggie and Zou, James},
  venue={The Eleventh International Conference on Learning Representations (ICLR)},
  year={2023}
}

@article{9369420,
  title={Explaining deep neural networks and beyond: A review of methods and applications},
  author={Samek, Wojciech and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and Anders, Christopher J and M{\"u}ller, Klaus-Robert},
  journal={Proceedings of the IEEE},
  volume={109},
  number={3},
  pages={247--278},
  year={2021},
  publisher={IEEE}
}

@inproceedings{hernandez2021natural,
  title={Natural language descriptions of deep visual features},
  author={Hernandez, Evan and Schwettmann, Sarah and Bau, David and Bagashvili, Teona and Torralba, Antonio and Andreas, Jacob},
  venue={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{Bau_2017_CVPR,
  title={Network dissection: Quantifying interpretability of deep visual representations},
  author={Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6541--6549},
  year={2017}
}

@article{9964439,
  title={Interpretable by design: Learning predictors by composing interpretable queries},
  author={Chattopadhyay, Aditya and Slocum, Stewart and Haeffele, Benjamin D and Vidal, Rene and Geman, Donald},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  volume={45},
  number={6},
  pages={7430--7443},
  year={2022},
  publisher={IEEE}
}

@inproceedings{8237336,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@inproceedings{oikarinen2023clipdissect,
  title={CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks},
  author={Oikarinen, Tuomas and Weng, Tsui-Wei},
  booktitle={The Eleventh International Conference on Learning Representations (ICLR)},
  year={2022}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  venue={International Conference on Machine Learning (ICML)},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{singh2022flava,
  title={Flava: A foundational language and vision alignment model},
  author={Singh, Amanpreet and Hu, Ronghang and Goswami, Vedanuj and Couairon, Guillaume and Galuba, Wojciech and Rohrbach, Marcus and Kiela, Douwe},
  venue={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={15638--15650},
  year={2022}
}

@inproceedings{
dosovitskiy2021vit,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
venue={International Conference on Learning Representations (ICLR)},
year={2021}
}

@inproceedings{marconato2022catastrophic,
  title={Catastrophic forgetting in continual concept bottleneck models},
  author={Marconato, Emanuele and Bontempo, Gianpaolo and Teso, Stefano and Ficarra, Elisa and Calderara, Simone and Passerini, Andrea},
  venue={International Conference on Image Analysis and Processing (ICIAP)},
  pages={539--547},
  year={2022},
  organization={Springer}
}

@article{rymarczyk2023icicle,
  title={ICICLE: Interpretable Class Incremental Continual Learning},
  author={Rymarczyk, Dawid and van de Weijer, Joost and Zieli{\'n}ski, Bartosz and Twardowski, Bart{\l}omiej},
  journal={arXiv preprint arXiv:2303.07811},
  year={2023}
}

@inproceedings{katharopoulos_et_al_2020,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  venue={International conference on machine learning (ICML)},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@article{vyas_et_al_2020,
  title={Fast transformers with clustered attention},
  author={Vyas, Apoorv and Katharopoulos, Angelos and Fleuret, Fran{\c{c}}ois},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={21665--21674},
  year={2020}
}

@inproceedings{shen2020efficient,
  title={Efficient attention: Attention with linear complexities},
  author={Shen, Zhuoran and Zhang, Mingyuan and Zhao, Haiyu and Yi, Shuai and Li, Hongsheng},
  venue={Proceedings of the IEEE/CVF winter conference on applications of computer vision (CVPR)},
  pages={3531--3539},
  year={2021}
}

@article{wang2020linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@inproceedings{kitaev2020reformer,
  title={Reformer: The Efficient Transformer},
  author={Kitaev, Nikita and Kaiser, Lukasz and Levskaya, Anselm},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@article{devlin2019bert,
  title={BERT: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{marconato2023neurocl,
  title={Neuro symbolic continual learning: Knowledge, reasoning shortcuts and concept rehearsal},
  author={Marconato, Emanuele and Bontempo, Gianpaolo and Ficarra, Elisa and Calderara, Simone and Passerini, Andrea and Teso, Stefano},
  journal={arXiv preprint arXiv:2302.01242},
  year={2023}
}

@article{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@article{van2022explainable,
  title={Explainable artificial intelligence (XAI) in deep learning-based medical image analysis},
  author={Van der Velden, Bas HM and Kuijf, Hugo J and Gilhuijs, Kenneth GA and Viergever, Max A},
  journal={Medical Image Analysis},
  volume={79},
  pages={102470},
  year={2022},
  publisher={Elsevier}
}

@article{jimaging6060052,
  title={Explainable deep learning models in medical image analysis},
  author={Singh, Amitojdeep and Sengupta, Sourya and Lakshminarayanan, Vasudevan},
  journal={Journal of imaging},
  volume={6},
  number={6},
  pages={52},
  year={2020},
  publisher={MDPI}
}


@inproceedings{burns2021limitations,
  title={Limitations of post-hoc feature alignment for robustness},
  author={Burns, Collin and Steinhardt, Jacob},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2525--2533},
  year={2021}
}

@inproceedings{adebayo2021post,
  title={Post hoc explanations may be ineffective for detecting unknown spurious correlation},
  author={Adebayo, Julius and Muelly, Michael and Abelson, Harold and Kim, Been},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{camburu2019i,
  title={Post-hoc explanations fail to achieve their purpose in adversarial contexts},
  author={Bordt, Sebastian and Finck, Mich{\`e}le and Raidl, Eric and von Luxburg, Ulrike},
  booktitle={Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={891--905},
  year={2022}
}

@inproceedings{rigotti2021attention,
  title={Attention-based interpretability with concept transformers},
  author={Rigotti, Mattia and Miksovic, Christoph and Giurgiu, Ioana and Gschwind, Thomas and Scotton, Paolo},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@misc{alvarezmelis2018robust,
      title={Towards Robust Interpretability with Self-Explaining Neural Networks}, 
      author={David Alvarez-Melis and Tommi S. Jaakkola},
      year={2018},
      eprint={1806.07538},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{alvarez2018towards,
  title={Towards robust interpretability with self-explaining neural networks},
  author={Alvarez Melis, David and Jaakkola, Tommi},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{Chen_2020,
  title={Concept whitening for interpretable image recognition},
  author={Chen, Zhi and Bei, Yijie and Rudin, Cynthia},
  journal={Nature Machine Intelligence},
  volume={2},
  number={12},
  pages={772--782},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{kazhdan2020cme,
  title={Now you see me (CME): concept-based model extraction},
  author={Kazhdan, Dmitry and Dimanov, Botty and Jamnik, Mateja and Li{\`o}, Pietro and Weller, Adrian},
  journal={arXiv preprint arXiv:2010.13233},
  year={2020}
}

@inproceedings{benitez2023ante,
  title={Ante-Hoc Generation of Task-Agnostic Interpretation Maps},
  author={Benitez, Raul and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3763--3768},
  year={2023}
}

@article{sanyal2021discretized,
  title={Discretized integrated gradients for explaining language models},
  author={Sanyal, Soumya and Ren, Xiang},
  journal={arXiv preprint arXiv:2108.13654},
  year={2021}
}

@article{han2022explanation,
  title={Which explanation should i choose? a function approximation perspective to characterizing post hoc explanations},
  author={Han, Tessa and Srinivas, Suraj and Lakkaraju, Himabindu},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={5256--5268},
  year={2022}
}

@inproceedings{jesus2021can,
  title={How can I choose an explainer? An application-grounded evaluation of post-hoc explanations},
  author={Jesus, S{\'e}rgio and Bel{\'e}m, Catarina and Balayan, Vladimir and Bento, Jo{\~a}o and Saleiro, Pedro and Bizarro, Pedro and Gama, Jo{\~a}o},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={805--815},
  year={2021}
}

@inproceedings{sattarzadeh2021integrated,
  title={Integrated grad-cam: Sensitivity-aware visual explanation of deep convolutional networks via integrated gradient-based scoring},
  author={Sattarzadeh, Sam and Sudhakar, Mahesh and Plataniotis, Konstantinos N and Jang, Jongseong and Jeong, Yeonjeong and Kim, Hyunwoo},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1775--1779},
  year={2021},
  organization={IEEE}
}

@article{NEURIPS2022_85b2ff75,
  title={Glancenets: Interpretable, leak-proof concept-based models},
  author={Marconato, Emanuele and Passerini, Andrea and Teso, Stefano},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={21212--21227},
  year={2022}
}

@article{NEURIPS2022_944ecf65,
  title={Addressing leakage in concept bottleneck models},
  author={Havasi, Marton and Parbhoo, Sonali and Doshi-Velez, Finale},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={23386--23397},
  year={2022}
}

@inproceedings{jin2022evaluating,
  title={Evaluating explainable AI on a multi-modal medical imaging task: Can existing algorithms fulfill clinical requirements?},
  author={Jin, Weina and Li, Xiaoxiao and Hamarneh, Ghassan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={11},
  pages={11945--11953},
  year={2022}
}

@inproceedings{chen2020adapting,
  title={Adapting grad-cam for embedding networks},
  author={Chen, Lei and Chen, Jianhui and Hajimirsadeghi, Hossein and Mori, Greg},
  booktitle={proceedings of the IEEE/CVF winter conference on applications of computer vision (CVPR)},
  pages={2794--2803},
  year={2020}
}

@inproceedings{8354201,
  title={Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks},
  author={Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N},
  booktitle={2018 IEEE winter conference on applications of computer vision (WACV)},
  pages={839--847},
  year={2018},
  organization={IEEE}
}

@article{yvinec2022singe,
  title={Singe: Sparsity via integrated gradients estimation of neuron relevance},
  author={Yvinec, Edouard and Dapogny, Arnaud and Cord, Matthieu and Bailly, Kevin},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={35392--35403},
  year={2022}
}

@inproceedings{Yang_2023_CVPR,
  title={IDGI: A Framework to Eliminate Explanation Noise from Integrated Gradients},
  author={Yang, Ruo and Wang, Binghui and Bilgic, Mustafa},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23725--23734},
  year={2023}
}

@article{NIPS2017_0060ef47,
  title={Real time image saliency for black box classifiers},
  author={Dabkowski, Piotr and Gal, Yarin},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={30},
  year={2017}
}

@inproceedings{fong2017interpretable,
  title={Interpretable explanations of black boxes by meaningful perturbation},
  author={Fong, Ruth C and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3429--3437},
  year={2017}
}

@inproceedings{jethani2021fastshap,
  title={Fastshap: Real-time shapley value estimation},
  author={Jethani, Neil and Sudarshan, Mukund and Covert, Ian Connick and Lee, Su-In and Ranganath, Rajesh},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{wang2021shapley,
  title={Shapley Explanation Networks},
  author={Wang, Rui and Wang, Xiaoqian and Inouye, David I},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{petsiuk2018rise,
  title={Rise: Randomized input sampling for explanation of black-box models},
  author={Petsiuk, Vitali and Das, Abir and Saenko, Kate},
  journal={arXiv preprint arXiv:1806.07421},
  year={2018}
}

@inproceedings{sundararajan2020many,
  title={The many Shapley values for model explanation},
  author={Sundararajan, Mukund and Najmi, Amir},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={9269--9278},
  year={2020},
  organization={PMLR}
}

@article{vilone2021notions,
  title={Notions of explainability and evaluation approaches for explainable artificial intelligence},
  author={Vilone, Giulia and Longo, Luca},
  journal={Information Fusion},
  volume={76},
  pages={89--106},
  year={2021},
  publisher={Elsevier}
}

@article{nauta2023anecdotal,
  title={From anecdotal evidence to quantitative evaluation methods: A systematic review on evaluating explainable ai},
  author={Nauta, Meike and Trienes, Jan and Pathak, Shreyasi and Nguyen, Elisa and Peters, Michelle and Schmitt, Yasmin and Schl{\"o}tterer, J{\"o}rg and van Keulen, Maurice and Seifert, Christin},
  journal={ACM Computing Surveys},
  volume={55},
  number={13s},
  pages={1--42},
  year={2023},
  publisher={ACM New York, NY}
}

@article{sokol2021explainability,
  title={Explainability is in the mind of the beholder: Establishing the foundations of explainable artificial intelligence},
  author={Sokol, Kacper and Flach, Peter},
  journal={arXiv preprint arXiv:2112.14466},
  year={2021}
}

@misc{barker2023selective,
      title={Selective Concept Models: Permitting Stakeholder Customisation at Test-Time}, 
      author={Matthew Barker and Katherine M. Collins and Krishnamurthy Dvijotham and Adrian Weller and Umang Bhatt},
      year={2023},
      eprint={2306.08424},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}

@inproceedings{tiwari2022gcr,
  title={Gcr: Gradient coreset based replay buffer selection for continual learning},
  author={Tiwari, Rishabh and Killamsetty, Krishnateja and Iyer, Rishabh and Shenoy, Pradeep},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={99--108},
  year={2022}
}

@article{graffieti2023generative,
  title={Generative negative replay for continual learning},
  author={Graffieti, Gabriele and Maltoni, Davide and Pellegrini, Lorenzo and Lomonaco, Vincenzo},
  journal={Neural Networks},
  volume={162},
  pages={369--383},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{jin2020gradient,
  title={Gradient based memory editing for task-free continual learning},
  author={Jin, Xisen and Du, Junyi and Ren, Xiang},
  booktitle={4th Lifelong Machine Learning Workshop at ICML},
  year={2020}
}

@article{aljundi2019gradient,
  title={Gradient based sample selection for online continual learning},
  author={Aljundi, Rahaf and Lin, Min and Goujaud, Baptiste and Bengio, Yoshua},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={32},
  year={2019}
}

@article{van2020brain,
  title={Brain-inspired replay for continual learning with artificial neural networks},
  author={Van de Ven, Gido M and Siegelmann, Hava T and Tolias, Andreas S},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={4069},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{mi2020ader,
  title={Ader: Adaptively distilled exemplar replay towards continual learning for session-based recommendation},
  author={Mi, Fei and Lin, Xiaoyu and Faltings, Boi},
  booktitle={Proceedings of the 14th ACM Conference on Recommender Systems},
  pages={408--413},
  year={2020}
}

@article{shin2017continual,
  title={Continual learning with deep generative replay},
  author={Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={30},
  year={2017}
}

@inproceedings{maracani2021recall,
  title={Recall: Replay-based continual learning in semantic segmentation},
  author={Maracani, Andrea and Michieli, Umberto and Toldo, Marco and Zanuttigh, Pietro},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={7026--7035},
  year={2021}
}

@inproceedings{ebrahimi2020adversarial,
  title={Adversarial continual learning},
  author={Ebrahimi, Sayna and Meier, Franziska and Calandra, Roberto and Darrell, Trevor and Rohrbach, Marcus},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XI 16},
  pages={386--402},
  year={2020},
  organization={Springer}
}

@inproceedings{douillard2022dytox,
  title={Dytox: Transformers for continual learning with dynamic token expansion},
  author={Douillard, Arthur and Ram{\'e}, Alexandre and Couairon, Guillaume and Cord, Matthieu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9285--9295},
  year={2022}
}

@article{kang2023forget,
  title={Forget-free Continual Learning with Soft-Winning SubNetworks},
  author={Kang, Haeyong and Yoon, Jaehong and Madjid, Sultan Rizky and Hwang, Sung Ju and Yoo, Chang D},
  journal={arXiv preprint arXiv:2303.14962},
  year={2023}
}

@inproceedings{cha2020cpr,
  title={CPR: Classifier-Projection Regularization for Continual Learning},
  author={Cha, Sungmin and Hsu, Hsiang and du Pin Calmon, Flavio and Moon, Taesup},
  booktitle={4th Lifelong Machine Learning Workshop at ICML},
  year={2020}
}

@article{hadsell2020embracing,
  title={Embracing change: Continual learning in deep neural networks},
  author={Hadsell, Raia and Rao, Dushyant and Rusu, Andrei A and Pascanu, Razvan},
  journal={Trends in cognitive sciences},
  volume={24},
  number={12},
  pages={1028--1040},
  year={2020},
  publisher={Elsevier}
}

@article{jung2020continual,
  title={Continual learning with node-importance based adaptive group sparse regularization},
  author={Jung, Sangwon and Ahn, Hongjoon and Cha, Sungmin and Moon, Taesup},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={3647--3658},
  year={2020}
}

@article{li2023fixed,
  title={Fixed Design Analysis of Regularization-Based Continual Learning},
  author={Li, Haoran and Wu, Jingfeng and Braverman, Vladimir},
  journal={arXiv preprint arXiv:2303.10263},
  year={2023}
}

@inproceedings{sha2016rbpb,
  title={RBPB: Regularization-based pattern balancing method for event extraction},
  author={Sha, Lei and Liu, Jing and Lin, Chin-Yew and Li, Sujian and Chang, Baobao and Sui, Zhifang},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1224--1234},
  year={2016}
}

@article{maschler2021regularization,
  title={Regularization-based continual learning for anomaly detection in discrete manufacturing},
  author={Maschler, Benjamin and Pham, Thi Thu Huong and Weyrich, Michael},
  journal={Procedia CIRP},
  volume={104},
  pages={452--457},
  year={2021},
  publisher={Elsevier}
}

@article{thengane2022continualclip,
  title={CLIP model is an Efficient Continual Learner},
  author={Thengane, Vishal and Khan, Salman and Hayat, Munawar and Khan, Fahad},  
  journal={arXiv:2210.03114},
  year={2022},
}

@INPROCEEDINGS{rebuffi2017icarl,
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={iCaRL: Incremental Classifier and Representation Learning}, 
  year={2017},
  volume={},
  number={},
  pages={5533-5542},
  keywords={Training;Training data;Prototypes;Feature extraction;Memory management;Classification algorithms;Computer vision},
  doi={10.1109/CVPR.2017.587}}

@inproceedings{
chaudhry2018efficient,
title={Efficient Lifelong Learning with A-{GEM}},
author={Arslan Chaudhry and Marc’Aurelio Ranzato and Marcus Rohrbach and Mohamed Elhoseiny},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Hkf2_sC5FX},
}

@inproceedings{buzzega2020derpp,
author = {Buzzega, Pietro and Boschini, Matteo and Porrello, Angelo and Abati, Davide and Calderara, Simone},
title = {Dark experience for general continual learning: a strong, simple baseline},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Continual Learning has inspired a plethora of approaches and evaluation settings; however, the majority of them overlooks the properties of a practical scenario, where the data stream cannot be shaped as a sequence of tasks and offline training is not viable. We work towards General Continual Learning (GCL), where task boundaries blur and the domain and class distributions shift either gradually or suddenly. We address it through mixing rehearsal with knowledge distillation and regularization; our simple baseline, Dark Experience Replay, matches the network's logits sampled throughout the optimization trajectory, thus promoting consistency with its past. By conducting an extensive analysis on both standard benchmarks and a novel GCL evaluation setting (MNIST-360), we show that such a seemingly simple baseline outperforms consolidated approaches and leverages limited resources. We further explore the generalization capabilities of our objective, showing its regularization being beneficial beyond mere performance.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {1335},
numpages = {11},
location = {Vancouver, BC, Canada},
series = {NIPS '20}
}

@INPROCEEDINGS {buzzega2021rethinking,
author = {P. Buzzega and M. Boschini and A. Porrello and S. Calderara},
booktitle = {2020 25th International Conference on Pattern Recognition (ICPR)},
title = {Rethinking Experience Replay: a Bag of Tricks for Continual Learning},
year = {2021},
volume = {},
issn = {1051-4651},
pages = {2180-2187},
abstract = {In Continual Learning, a Neural Network is trained on a stream of data whose distribution shifts over time. Under these assumptions, it is especially challenging to improve on classes appearing later in the stream while remaining accurate on previous ones. This is due to the infamous problem of catastrophic forgetting, which causes a quick performance degradation when the classifier focuses on learning new categories. Recent literature proposed various approaches to tackle this issue, often resorting to very sophisticated techniques. In this work, we show that naive rehearsal can be patched to achieve similar performance. We point out some shortcomings that restrain Experience Replay (ER) and propose five tricks to mitigate them. Experiments show that ER, thus enhanced, displays an accuracy gain of 51.2 and 26.9 percentage points on the CIFAR-10 and CIFAR-100 datasets respectively (memory buffer size 1000). As a result, it surpasses current state-of-the-art rehearsal-based methods.},
keywords = {degradation;neural networks;pattern recognition;proposals;erbium;standards},
doi = {10.1109/ICPR48806.2021.9412614},
url = {https://doi.ieeecomputersociety.org/10.1109/ICPR48806.2021.9412614},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jan}
}

@InProceedings{Mai_2021_CVPR,
    author    = {Mai, Zheda and Li, Ruiwen and Kim, Hyunwoo and Sanner, Scott},
    title     = {Supervised Contrastive Replay: Revisiting the Nearest Class Mean Classifier in Online Class-Incremental Continual Learning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2021},
    pages     = {3589-3599}
}
