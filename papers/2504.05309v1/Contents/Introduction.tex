% Search has become a main entry for user to find interested content, especially in e-Commercial system, such as Taobao, Amazon and Meituan Delivery. These systems contain billions of supply for each search request. Though Meituan focus more on nearby supply based on user's location (Location-based Service, LBS), the huge volume of candidates demand service more than merely returning satisfied content depending on user query, but personalized and most interested candidates by different users, leading to click, transaction with high possibility. 

Search functions as the primary means for users to find desired content, especially in e-Commercial systems like Taobao, Amazon, and Meituan Delivery. These systems host billions of suppliers for each search request. While Meituan focuses more on nearby suppliers based on users' locations (Location-based Services, LBS), the vast number of candidates necessitates a service model that delivers not only satisfactory content but also personalized and relevant suggestions, ultimately enhancing click-through and purchase likelihood.

% However, it is common that user query is redundant, ambiguous and incorrect.  Specially in Meituan Delivery, A query of ``Animal cream cake'' requires both animal cream and cake, which may leads to insufficient retrieval candidates.  Typo commonly appears in query, such as ``wontom'' is a typo of ``wonton''.
% Besides,  query of ``spicy'' is too general to provide precise matching: the exposed content is satisfied for the matching of restaurant's title, missing potential candidates such as Jiangxi cuisine\footnote{Jiangxi cuisine is a type of Chinese cuisine known for its spiciness.}. 
% Abbreviation is commonly used in query, such as ``KFC'' for Kentucky Fried Chicken, ``lsf'' for ``Luosifen'' \footnote{Luosifen, or river snail rice noodle, is a popular Chinese dish originating from Liuzhou in the Guangxi Zhuang Autonomous Region. This dish is known for its unique and strong aroma.}.
% User's query may contain a part of the restaurant's title, such as ``Niujie'' for a barbecue restaurant with title of ``Niujie BBQ''. This query may lead to empty results if the restaurant is not available during the search period.

Nonetheless, it is common for user queries to be redundant, ambiguous, or incorrect. For instance, a query for “Animal cream cake” necessitates identifying both "animal cream" and "cake," which may result in insufficient retrieval candidates. Typos are prevalent in queries, as in ``wontom'', which is a misspelling of ``wonton''. Such errors can severely impact search effectiveness, as the system may not recognize the intended dish.
Moreover, queries that are overly general: such as simply stating ``spicy'', fail to yield precise matches, resulting in exposure primarily associated with generic restaurant titles and missing opportunities for niche cuisines like Jiangxi cuisine\footnote{Jiangxi cuisine is a type of Chinese cuisine known for its spiciness.}. 
Abbreviations are also common in queries, such as ``KFC'' for Kentucky Fried Chicken or ``lsf'' for ``Luosifen''\footnote{Luosifen, or river snail rice noodle, is a popular Chinese dish originating from Liuzhou in the Guangxi Zhuang Autonomous Region. This dish is known for its unique and strong aroma.}. 
Users' queries might include only a part of a restaurant's title, such as ``Niujie'' for a barbecue restaurant named ``Niujie BBQ''. This type of incomplete query can sometimes produce empty search results if the restaurant is unavailable during the search duration, leading to user frustration.

% It is difficult to be addressed comprehensively by traditional retrieval methods such as blurry matching, embedding retrieval and query partition for these cases require both domain knowledge (``Niujie'' is responsible for barbecue), common knowledge (typos of ``wontom'') and query understanding for key word extraction.
Traditional retrieval methods struggle to address these challenges comprehensively. Techniques such as fuzzy matching, embedding retrieval, and query partitioning fail effectively to account for the nuanced dependencies between traditional domain knowledge—like understanding that ``Niujie'' implies barbecue—and common knowledge, such as recognizing typographical errors like ``wontom''. Furthermore, the capability to extract relevant keywords based on query understanding is often lacking in these systems.
% Query rewrite serves as a potential solution. However, prior rewrite methods reply on a static rewrite vocabulary which is established manually: queries with high frequency is prepared with rewrites while the tail queries are seldom processed.
Query rewriting emerges as a viable solution to these problems. It can enhance the clarity and relevance of user queries by transforming them into more precise representations. However, prior methods for query rewriting primarily rely on static rewrite vocabularies that are established manually. High-frequency queries may have pre-prepared rewrites, while low-frequency queries—often consisting of user errors, less common terms, or local specialties—receive little to no attention.
% Though LLMs assistant in rewrite generation automatically \cite{peng2024large},\cite{wang2024one}, these methods fail to answer a key question: how to determine whether a specific rewrite is ``good'' or not. ``Good'' represents the rewrite is able to retrieve both relevance satisfied for query and interested content for user.
Although LLMs facilitate automatic rewrite generation, they do not sufficiently answer a critical question: how can we determine if a specific rewrite is ``good''? A "good" rewrite should effectively retrieve not only relevant content that satisfies user queries but also additional content that interests the user. While offline and online experiments may guide the generation of rewrites, assessing the quality of each rewrite before deployment remains a significant challenge. Moreover, most existing methods generate rewrites just once, lacking mechanisms for updates and improvements.
% Offline and online experiments may provide guidance for a batch of rewrites, it is difficult to distinguish the quality of every rewrite before deployment.
% Besides, most methods generate rewrites only one time, lacking ability for update.

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{Figures/workflow.pdf}
    \caption{Workflow of \method{}: An iterative framework of 3 stages. Stage 1 initialize and generate query rewrite based on query. Prompt is designed to incorporate domain knowledge (associated interacted restaurant and cuisine. Besides, query rewrite is formulated as query understanding and process by CoT. The generated rewrites are fed to Stage 2 for online feedback collection, where the positive rewrites are utilized in Stage 3. LLM is post trained with multi-task objectives, using the positive rewrites as labels. The trained model serves to motivate new rewrites in Stage 1, prompting the continuous iteration.}
    \label{fig:overall}
\end{figure*}

To address the above mentioned question comprehensively, we proposed \method{}: an iterative framework to generate query rewrites based on LLMs.
As shown in Fig.\ref{fig:overall}: 
% In each iteration, we firstly generate query rewrites using LLMs. Prompt is meticulously designed by rephrasing the task of query rewrite as successive tasks (query understanding, correction, rewrite) using CoT. Then domain knowledge is injected by incorporating interacted title of restaurants and cuisine under the query, instructing LLMs to generate relevant content.
each iteration involves generating query rewrites through LLMs. The prompts for this process are carefully crafted to reformulate the query rewriting task into successive stages (query understanding, correction, rewrite) employing methods like Chain-of-Thoughts (CoT). We inject domain knowledge by incorporating relevant restaurant titles and associated cuisines in the prompts, guiding LLMs to produce pertinent and context-aware content. The generated rewrites feed into our search system for deployment, enhancing user interactions and search effectiveness.
% The generated rewrites are fed into our search system for serving. In the second stage, rewrites leading to interacted items are regarded as positive rewrites and collected. The collection procedure serves as an automatic and precise distinction of the quality of rewrites.
In the subsequent stages, rewrites that lead to user interactions are collected as positive rewrites, serving as indicators of rewrite quality. This automatic and precise distinction of rewrite effectiveness allows us to refine our approach continually. 
% In the last stage, with the collected rewrites, we post-trained a LLM with multi tasks: Rewrite Generation to reproduce the positive rewrites; Rewrite Quality to instruct LLM to distinguish whether the rewrite is ``good'' or not. Relevance to teach LLM with relevance information in the domain of cuisine delivery.
In the final stage, we conduct post-training for the LLM using multi-task objectives to generate new rewrites, including: Rewrite Generation to reproduce the positive rewrites; Rewrite Quality to instruct LLM to distinguish whether the rewrite is ``good'' or not. Relevance to teach LLM with relevance information in the domain of cuisine delivery.

The post-trained LLM is used to generate and motivate new rewrites in first stage, which is then evaluated in second stage. The positive rewrites are filtered and reserved. \method{} provides an iterative framework to continuously generate new rewrites with automatic evaluation. Domain knowledge and new information can be naturally incorporated during generation.

The main contributions of \method{} are listed as follows:
\begin{itemize}
    \item \method{} pioneer to address the automatic evaluation of generated rewrites before final deployment, by feeding rewrites online for signal collection.
    \item An iterative framework is adopted to motivate new rewrites, leading to dynamic update of rewrite vocabulary.
    \item The traditional rewrite task is formulated as comprehensive query process including successive tasks of query understanding, correction, clarification and rewrite in generation, and multi-tasks post-training.
\end{itemize}