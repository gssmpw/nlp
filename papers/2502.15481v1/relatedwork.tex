\section{Related Works}
\label{sec:related_works}

\subsection{Intelligent Fault Diagnosis}
The development of intelligent FD can be categorized into four distinct research types.
Initial studies predominantly concentrated on acquiring vibration signals from sensors attached to mechanical equipment and devising diagnostic models utilizing one-dimensional 1D-CNNs \cite{zhang2017new,10419797,10571357}, as illustrated in Fig.~\ref{fig:rodemap}(a). 
Despite their effectiveness, these models often suffered from a reliance on limited datasets and the necessity of training from scratch, which poses a considerable challenge in industrial settings where acquiring data is expensive.

As technology advanced, the focus shifted toward leveraging pre-trained models, which reduced dependence on extensive labeled fault data. A notable breakthrough involved transforming vibration signals into time-frequency images \cite{10750065,shao2018highly}, thereby enabling the use of more sophisticated pre-trained models like ResNet \cite{he2016deep} and ViT \cite{dosovitskiy2020image} for mechanical FD, as depicted in Fig.~\ref{fig:rodemap}(b).
Simultaneously, LLMs have demonstrated broad applicability in handling time-series data, particularly excelling in tasks such as classification and prediction \cite{zhou2024one}, offering new avenues for research in this area, as depicted in Fig.~\ref{fig:rodemap}(c).

Despite the progress, generalizing pre-trained models to more complex mechanical systems remains a challenge. Methods relying on single data sources often fail to fully capture the complexity of fault patterns. To address this, multimodal approaches have emerged, integrating different types of data, such as acoustic, vibration, and natural language, to construct a more holistic view of mechanical health monitoring. 
Due to the underutilization of extensive fault and maintenance records in textual form, Natural Language Processing (NLP) techniques are employed to optimize vibration signal-based fault diagnosis models, showcasing the potential of modality fusion in improving diagnostic accuracy \cite{lowenmark2021technical}. In this context, researchers propose the Knowledge Graph-based Question Answering system (KG-MQA) \cite{10367777}, which leverages structured information from the knowledge graph to answer user queries in natural language. Furthermore, researchers construct a large-scale dataset of rotating machinery faults and train the foundational diagnostic model DCNDSC \cite{10520331} on it. This model learns general feature representations and fine-tunes for specific fault diagnosis tasks, thereby improving diagnostic accuracy and robustness.

\begin{figure*}[ht]
  \centering
  \begin{subfigure}[b]{0.20\linewidth}
    \includegraphics[width=\linewidth]{images/device_v1_compact.pdf}
    \caption{Our vibration signal \\ acquisition equipment.}
    \label{fig:sensors}
  \end{subfigure}
  \begin{subfigure}[b]{0.25\linewidth}
    \includegraphics[width=\linewidth]{images/normal_v1_compact.pdf}
    \caption{Normal bearing.}
    \label{normal bearing}
  \end{subfigure}
  \begin{subfigure}[b]{0.25\linewidth}
    \includegraphics[width=\linewidth]{images/2mm_v2_compact.pdf}
    \caption{2mm inner ring fault.}
    \label{2mm inner ring fault}
  \end{subfigure}
  \begin{subfigure}[b]{0.22\linewidth}
    \includegraphics[width=\linewidth]{images/energy_v1.pdf}
    \caption{Energy distribution.}
    \label{fig:energy}
  \end{subfigure}
\caption{The time-frequency images and energy characteristics in different bearings.}
\label{fig:observation}
\vspace{-0.15in}
\end{figure*}

\subsection{Multimodal LLMs}
Large models, including LLMs, time-series models, vision models, and large vision language models, represent the forefront of current artificial intelligence research.
%
LLMs, especially those built on the Transformer architecture, have been pre-trained on extensive text data, accumulating a vast knowledge base and demonstrating exceptional natural language processing capabilities, including text generation, semantic understanding, and sentiment analysis.
%
These models are categorized into open-source and close-source types. Open-source models like Llama2 \cite{touvron2023llama} and Vicuna\cite{chiang2023vicuna} allow direct access to their architecture and pre-trained weights. In contrast, close-source model such as GPT-4 \cite{achiam2023gpt} are typically accessible via API services, requiring users to craft carefully designed prompts for specific inference tasks.

The multimodal fusion methods can be broadly categorized into two types: (1) \textbf{Standard Cross-attention based Deep Fusion}, which utilizes cross-attention mechanisms within the model to fuse multimodal inputs internally, as in LLAMA-Adapter \cite{gao2023llama}, commonly used in scenarios requiring fine alignment and interaction between modalities. (2) \textbf{Custom Layer based Early Fusion}, where custom modules (such as Q-Former or MLP) directly fuse multimodal data at the input stage. BLIP-2 \cite{li2023blip} performs early fusion using Q-Former, while LLaVA~\cite{liu2024visual} employs an MLP module. Non-tokenized input modalities (such as images or audio) are encoded and then connected to the LLM's text input through these modules, achieving alignment and fusion of multimodal features. In FaultGPT, we adopt the same fusion approach as LLaVA.

Despite these large models achieving remarkable performance in various tasks, significant challenges remain in using vibration signals to generate diagnostic reports: firstly, existing models focus mainly on global feature alignment, struggling to capture local features that represent fault semantics, thus presenting challenges in generating diagnostic reports; secondly, due to the scarcity of fault diagnosis data, there is a lack of relevant benchmarks and datasets.