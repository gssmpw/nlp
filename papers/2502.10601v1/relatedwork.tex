\section{Related Work}
\label{sec:RelatedWork}

Within the realm of geophysical sciences, super-resolution/downscaling is a challenge that scientists continue to tackle. There have been several works involved in downscaling applications such as river mapping \cite{Yin2022}, coastal risk assessment \cite{Rucker2021}, estimating soil moisture from remotely sensed images \cite{Peng2017SoilMoisture} and downscaling of satellite based precipitation estimates \cite{Medrano2023PrecipitationDownscaling} to name a few. We direct the reader to \cite{Karwowska2022SuperResolutionSurvey} for a comprehensive review of satellite based downscaling applications and methods. Pertaining to our objective of downscaling \acp{WFM}, we can draw comparisons with several existing works. 
In what follows, we provide a brief review of functionally adjacent works to contrast the novelty of our proposed model and its role in addressing gaps in literature. 

When it comes to downscaling \ac{WFM}, several works use statistical downscaling techniques. These works downscale images by using statistical techniques that utilize relationships between neighboring water fraction pixels. For instance, \cite{Li2015SRFIM} treat the super-resolution task as a sub-pixel mapping problem, wherein the input fraction of inundated pixels must be exactly mapped to the output patch of inundated pixels. 
% In doing so, they are able to apply a discrete particle swarm optimization method to maximize the Flood Inundation Spatial Dependence Index (FISDI). 
\cite{Wang2019} improved upon these approaches by including a spectral term to fully utilize spectral information from multi spectral remote sensing image band. \cite{Wang2021} on the other hand also include a spectral correlation term to reduce the influence of linear and non-linear imaging conditions. All of these approaches are applied to water fraction obtained via spectral unmixing \cite{wang2013SpectralUnmixing} and are designed to work with multi spectral information from MODIS. However, we develop our model with the intention to be used with water fractions directly derived from the output of satellites. One such example is NOAA/VIIRS whose water fraction extraction method is described in \cite{Li2013VIIRSWFM}. \cite{Li2022VIIRSDownscaling} presented a work wherein \ac{WFM} at 375-m flood products from VIIRS were downscaled 30-m flood event and depth products by expressing the inundation mechanism as a function of the \ac{DEM}-based water area and the VIIRS water area.

On the other hand, the non-linear nature of the mapping task lends itself to the use of neural networks. Several models have been adapted from traditional single image digital super-resolution in computer vision literature \cite{sdraka2022DL4downscalingRemoteSensing}. Existing deep learning models in single image super-resolution are primarily dominated by \ac{CNN} based models. Specifically, there has been an upward trend in residual learning models. \acp{RDN} \cite{Zhang2018ResidualDenseSuperResolution} introduced residual dense blocks that employed a contiguous memory mechanism that aimed to overcome the inability of very deep \acp{CNN} to make full use of hierarchical features. 
\acp{RCAN} \cite{Zhang2018RCANSuperResolution} introduced an attention mechanism to exploit the inter-channel dependencies in the intermediate feature transformations. There have also been some works that aim to produce more lightweight \ac{CNN}-based architectures \cite{Zheng2019IMDN,Xiaotong2020LatticeNET}. Since the introduction of the vision transformer \cite{Vaswani2017Attention} that utilized the self-attention mechanism -- originally used for modeling text sequences -- by feeding a sequence 2D sub-image extracted from the original image. Using this approach \cite{LuESRT2022} developed a light-weight and efficient transformer based approach for single image super-resolution. 


For the task of super-resolution of \acp{WFM}, we discuss some works whose methodology is similar to ours even though they differ in their problem setting. \cite{Yin2022} presented a cascaded spectral spatial model for super-resolution of MODIS imagery with a scaling factor 10. Their architecture consists of two stages; first multi-spectral MODIS imagery is converted into a low-resolution \ac{WFM} via spectral unmixing by passing it through a deep stacked residual \ac{CNN}. The second stage involved the super-resolution mapping of these \acp{WFM} using a nested multi-level \ac{CNN} model. Similar to our work, the input fraction images are obtained with zero errors which may not be reflective of reality since there tends to be sensor noise, the spatial distribution of whom cannot be easily estimated. We also note that none of these works directly tackle flood inundation since they've been trained with river map data during non-flood circumstance and \textit{ergo} do not face a data scarcity problem as we do. 
% In this work, apart from the final product of \acp{WFM}, we are not presented with any additional spectral information about the low resolution image. This was intended to work directly with products that can generate \ac{WFM} either directly (VIIRS) or indirectly (Landsat).
\cite{Jia2019} used a deep \ac{CNN} for land mapping that consists of several classes such as building, low vegetation, background and trees. 
\cite{Kumar2021} similarly employ a \ac{CNN} based model for downscaling of summer monsoon rainfall data over the Indian subcontinent. Their proposed Super-Resolution Convolutional Neural Network (SRCNN) has a downscaling factor of 4. 
\cite{Shang2022} on the other hand, proposed a super-resolution mapping technique using Generative Adversarial Networks (GANs). They first generate high resolution fractional images, somewhat analogous to our \ac{WFM}, and are then mapped to categorical land cover maps involving forest, urban, agriculture and water classes. 
\cite{Qin2020} interestingly approach lake area super-resolution for Landsat and MODIS data as an unsupervised problem using a \ac{CNN} and are able to extend to other scaling factors. \cite{AristizabalInundationMapping2020} performed flood inundation mapping using \ac{SAR} data obtained from Sentinel-1. They showed that \ac{DEM}-based features helped to improve \ac{SAR}-based predictions for quadratic discriminant analysis, support vector machines and k-nearest neighbor classifiers. While almost all of the aforementioned works can be adapted to our task. We stand out in the following ways (i) We focus on downscaling of \acp{WFM} directly, \textit{i.e.,} we do not focus on the algorithm to compute the \ac{WFM} from multi-channel satellite data and (ii) We focus on producing high resolution maps only for instances of flood inundation. The latter point produces a data scarcity issue which we seek to remedy with synthetic data. 


%%%%%%%%%%%%%%%%% Additional unused information %%%%%%%%%%%%%%%%


%     \item[\cite{Wang2021}] Super-Resolution Mapping Based on Spatial–Spectral Correlation for Spectral Imagery
%     \begin{itemize}
%         \item Not a deep neural network approach. SRM based on spatial–spectral correlation (SSC) is proposed in order to overcome the influence of linear and nonlinear imaging conditions and utilize more accurate spectral properties.
%         \item (fig 1) there are two main SRM types: (1) the initialization-then-optimization SRM, where the class labels are allocated randomly to subpixels, and the location of each subpixel is optimized to obtain the final SRM result. and (2)soft-then-hard SRM, which involves two steps: the subpixel sharpening and the class allocation.  
%         \item SSC procedures: (1) spatial correlation is performed by the MSAM to reduce the influences of linear imaging conditions on image quality. (2) A spectral correlation that utilizes spectral properties based on the nonlinear KLD is proposed to reduce the influences of nonlinear imaging conditions. (3) spatial and spectral correlations are then combined to obtain an optimization function with improved linear and nonlinear performances. And finally (4) by maximizing the optimization function, a class allocation method based on the SA is used to assign LC labels to each subpixel, obtaining the final SRM result.
%         \item (Comparable) 
%     \end{itemize}
%     %--------------------------------------------------------------------
% \cite{Wang2021} account for the influence of linear and non-linear imaging conditions by involving more accurate spectral properties. 
%     %--------------------------------------------------------------------
%     \item[\cite{Yin2022}] A Cascaded Spectral–Spatial CNN Model for Super-Resolution River Mapping With MODIS Imagery
%     \begin{itemize}
%         \item produce  Landsat-like  fine-resolution (scale of 10)  river  maps  from  MODIS images. Notice the original coarse-resolution remotely sensed images, not the river fraction images.
%         \item combined  CNN  model that  contains  a spectral  unmixing  module  and  an  SRM  module, and the SRM module is made up of an encoder and a decoder that are connected through a series of convolutional blocks. 
%         \item With an adaptive cross-entropy loss function to address class imbalance.	
%         \item The overall accuracy, the omission error, the  commission  error,  and  the  mean  intersection  over  union (MIOU)  calculated  to  assess  the results.
%         \item partially comparable with ours, only the SRM module part
%     %--------------------------------------------------------------------

% To decouple the description of the objective and the \ac{ML} model architecture, the motivation for the model architecture is described in \secref{sec:Methodology}. 


%     \item[\cite{Wang2019}] Improving Super-Resolution Flood Inundation Mapping for Multi spectral Remote Sensing Image by Supplying More Spectral 
%     \begin{itemize}
%         \item proposed the SRFIM-MSI,where a new spectral term is added to the traditional SRFIM to fully utilize the spectral information from multi spectral remote sensing image band. 
%         \item The original SRFIM \cite{Huang2014, Li2015} obtains the sub pixel spatial distribution of flood inundation within mixed pixels by maximizing their spatial correlation while maintaining the original proportions of flood inundation within the mixed pixels. The SRFIM is formulated as a maximum combined optimization issue according to the principle of spatial correlation.
%         \item follow the terminology in \cite{Wang2021}, this is an initialization-then-optimization SRM. 
%         \item (Comparable) 
%     \end{itemize}
%     %--------------------------------------------------------------------


%--------------------------------------------------------------------
%     \item[\cite{Jia2019}] Super-Resolution Land Cover Mapping Based on the Convolutional Neural Network
%     \begin{itemize}
%         \item SRMCNN (Super-resolution mapping CNN) is proposed to obtain fine-scale land cover maps from coarse remote sensing images. Specifically, an encoder-decoder CNN is used to determined the labels (i.e., land cover classes) of the subpixels within mixed pixels.
%         \item There were three main parts in SRMCNN. The first part was a three-sequential convolutional layer with ReLU and pooling. The second part is up-sampling, for which a multi transposed-convolutional layer was adopted. To keep the feature learned in the previous layer, a skip connection was used to concatenate the output of the corresponding convolution layer. The last part was the softmax classifier, in which the feature in the antepenultimate layer was classified and class probabilities are obtained.
%         \item The loss: the optimal allocation of classes to the subpixels of mixed pixel is achieved by maximizing the spatial dependence between neighbor pixels under constraint that the class proportions within the mixed pixels are preserved.
%         \item (Preferred), this paper is designed to classify background, Building, Low Vegetation, or Tree in the land. But we can easily adapt to our problem and should compare with this paper.
%     \end{itemize}
%     %--------------------------------------------------------------------

%     \item[\cite{Kumar2021}] Deep learning–based downscaling of summer monsoon rainfall data over Indian region
%     \begin{itemize}
%         \item down-scaling (scale of 4) rainfall data. The output image is not binary image.
%         \item three algorithms: SRCNN, stacked SRCNN, and DeepSD are employed, based on \cite{Vandal2019}
%         \item mean square error and pattern correlation coefficient are used as evaluation metrics.
%         \item SRCNN: super-resolution-based convolutional neural networks (SRCNN) first upgrades the low-resolution image to the higher resolution size by using bicubic interpolation. Suppose the interpolated image is referred to as Y; SRCNNs’task is to retrieve from Y an image F(Y) which is close to the high-resolution ground truth image X.
%         \item stacked SRCNN: stack 2 or more SRCNN blocks to increasing the scaling factor.
%         \item DeepSD: uses topographies as an additional input to stacked SRCNN.
%         \item These algorithms are not designed for binary output images, but if prefer, the ``modified'' stacked SRCNN or DeepSD can be used as baseline algorithms.
%     
%     \item[\cite{Shang2022}] Super resolution Land Cover Mapping Using a Generative Adversarial Network
%     \begin{itemize}
%         \item propose an end-to-end SRM model based on a generative adversarial network (GAN), that is, GAN-SRM, to improve the two-step learning-based SRM methods. 
%         \item Two-step SRM method: The first step is fraction-image super-resolution (SR), which reconstructs a high-spatial-resolution fraction image from the low input, methods like SVR, or CNN has been widely adopted. The second step is converting the high-resolution fraction images to a categorical land cover map, such as with a soft-max function to assign each high-resolution pixel to a unique category value.
%         \item The proposed GAN-SRM model includes a generative network and a discriminative network, so that both the fraction-image SR and the conversion of the fraction images to categorical map steps are fully integrated to reduce the resultant uncertainty. 
%         \item applied to the National Land Cover Database (NLCD), which categorized land into four typical classes:forest, urban, agriculture,and water. scale factor of 8. 
%         \item (Preferred), we should compare with this work.
%     \end{itemize}
%     %--------------------------------------------------------------------

%   \item[\cite{Qin2020}] Achieving Higher Resolution Lake Area from Remote Sensing Images Through an Unsupervised Deep Learning Super-Resolution Method
%   \begin{itemize}
%       \item propose an unsupervised deep gradient network (UDGN) to generate a higher resolution lake area from remote sensing images.
%       \item UDGN models the internal recurrence of information inside the single image and its corresponding gradient map to generate images with higher spatial resolution. 
%       \item A single image super-resolution approach, not comparable
%   \end{itemize}
%     %--------------------------------------------------------------------




%     \item[\cite{Demiray2021}] D-SRGAN: DEM Super-Resolution with Generative Adversarial Networks
%     \begin{itemize}
%         \item A GAN based model is proposed to increase the spatial resolution of a given DEM dataset up to 4 times without additional information related to data.
%         \item Rather than processing each image in a sequence independently, our generator architecture uses a recurrent layer to update the state of the high-resolution reconstruction in a manner that is consistent with both the previous state and the newly received data. The recurrent layer can thus be understood as performing a Bayesian update on the ensemble member, resembling an ensemble Kalman filter. 
%         \item A single image super-resolution approach, not comparable
%     \end{itemize}
%     %--------------------------------------------------------------------
%     \item[\cite{Leinonen2021}] Stochastic Super-Resolution for Downscaling Time-Evolving Atmospheric Fields With a Generative Adversarial Network
%     \begin{itemize}
%         \item propose a super-resolution GAN that operates on sequences of two-dimensional images and creates an ensemble of predictions for each input. The spread between the ensemble members represents the uncertainty of the super-resolution reconstruction.
%         \item for sequence of input images, not comparable with ours.
%     \end{itemize} 
%     %--------------------------------------------------------------------

% \end{itemize}