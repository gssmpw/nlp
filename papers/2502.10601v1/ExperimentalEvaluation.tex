\section{Experimental Evaluation}
\label{sec:expriments}

% In this work, we are interested in the following research questions.

% \textit{RQ1: Do the deep learning models provide performance benefits over classical downscaling methods?}

% \textit{RQ2: Do performance benefits extend to regions outside of Iowa?}

% \begin{table*}[!t]
% \centering
% \caption{Accuracies of our models for Iowan and Ghanaian test flood events. \Acf{RW} were obtained from Landsat-8 data, while \acf{SYN} data were provided by the Iowa Flood Center. In parentheses are the results from regions where water fraction is between 0 and 1 not inclusive.} %Percentages depicted in bold signify the best performing model in each case.}
% \label{tab:AccuracyResults}
% \begin{tabular}{@{}lccccc@{}}
%     \toprule
%     Approach    & \multicolumn{3}{c}{Accuracy (\%)}                                     \\
%                 & SYN Iowa\textsuperscript{a} & RW Iowa\textsuperscript{b} & RW Europe\textsuperscript{d} & RW Red River\textsuperscript{e}\\
%     \midrule
%     bicubic     & 85.0 ()              & 81.35 ()        & 83.2 ()   &           \\
%     Lanczos     & 85.2 ()            & 81.22 ()         & 83.2 ()             \\
    
%     \ac{RDN}         & 88.3 ()              & 88.5  ()        & \textbf{86.2 } ()    \\
%     \ac{RCAN}        & 88.0 ()              & 88.3  ()        & 86.1 ()              \\
%     \ac{ESRT}        & 88.0 ()              & 88.3  ()        & 86.1 ()              \\
%     \bottomrule
%     \multicolumn{5}{l}{\footnotesize{Based on: }\textsuperscript{a}\footnotesize{4,033 samples}, \textsuperscript{b}\footnotesize{1,487 samples}, \textsuperscript{c}\footnotesize{70 samples.}}
% \end{tabular}
% \end{table*}

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table*}
\centering
\caption{\label{tab:IowaResults}Accuracies, along with their Prediction Intervals (PI) and \Acf{MCC} of our models for Iowan \Acf{RW} and \Acf{SYN} data. \Acf{RW} were obtained from Landsat-8 data, while \acf{SYN} data were provided by the Iowa Flood Center. Note that we only present results for pixels where the water fraction in the \ac{WFM} is in the interval (0.25, 0.85). Na\"ive model here represents outputs where all the pixels are predicted as non-inundated, \textit{i.e.,} the majority class. Percentages depicted in bold signify the best performing model in each case.}
\vspace*{0.25cm}
\begin{tabular}{@{}cccccccccc@{}}
\toprule
        & \multicolumn{3}{c}{SYN-Iowa}                       & \multicolumn{3}{c}{RW-Iowa (CR)}                  & \multicolumn{3}{c}{RW-Iowa (DM)}                  \\ \midrule
Model   & accuracy (\%)  & accuracy PI (\%) & MCC                        & accuracy(\%)  & accuracy PI (\%) & MCC                    & accuracy(\%)  & accuracy PI (\%) & MCC                 \\\midrule
Na\"ive & 50.74   & [50.66, 50.82]       & 0.0             & 49.83    & [49.55, 50.10]      & 0.0            & 52.29   & [52.02, 52.56]       & 0.0                  \\
bicubic & 73.27   & [73.20, 73.35]       & 0.475             & 69.96    & [69.71, 70.21]      & 0.404            & 70.63    & [70.38, 70.87]      & 0.418                  \\
Lanczos & 73.72   & [73.65, 73.79]       & 0.483               & 70.25    & [70.00, 70.49]      & 0.409                  & 70.89   & [70.65, 71.14]       & 0.423               \\
RDN     & 78.64   & [78.57,78.70]       & 0.574         \      & 70.65    & [70.40, 70.90]      & 0.414          & 70.52            & [70.28, 70.77]       & 0.410               \\
RCAN    & 79.91   & [79.85, 79.98]       & 0.599                  & 72.69    & [72.45, 72.93]      & 0.454                  & 72.93    & [72.69, 73.17]      & 0.457             \\
ESRT    & \textbf{80.33} & \textbf{[80.27, 80.40]} & \textbf{0.607}  & \textbf{73.31} & \textbf{[73.07, 73.55]} & \textbf{0.466} & \textbf{73.34} & \textbf{[73.10, 73.58]} & \textbf{0.465}  \\ \bottomrule
\end{tabular}
\end{table*}


% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table*}[!ht]
\vspace*{0.52cm}
\centering
\caption{\label{tab:ExternalResults} Accuracies along with their Prediction Intervals (PI) and \Acf{MCC} of our models for all external \Acf{RW} data. \Acf{RW} were obtained from Landsat-8 data. Note that we only present results for pixels where the water fraction in the \ac{WFM} is in the interval (0.25, 0.85). Na\"ive model here represents outputs where all the pixels are predicted as non-inundated, \textit{i.e.,} the majority class. Percentages depicted in bold signify the best performing model in each case.}
\vspace*{0.25cm}
\begin{tabular}{@{}cccccccccc@{}}
\toprule
        & \multicolumn{3}{c}{RW-EU}                         & \multicolumn{3}{c}{RW-GH}                        & \multicolumn{3}{c}{RW-RR}                          \\ \midrule
Model   & accuracy (\%) & accuracy PI (\%) & MCC                     & accuracy(\%)  & accuracy PI (\%) & MCC                        & accuracy(\%) & accuracy PI (\%)  & MCC                          \\ \midrule
Na\"ive & 47.03    & [46.67, 47.39]      & 0.0             & 47.77    & [47.08, 48.46]      & 0.0            & 40.86     &   [40.71, 41.01]   & 0.0                  \\
bicubic & 77.77    & [77.47, 78.07]      & 0.558                & 73.11    & [72.50, 73.73]      & 0.463                  & 71.39    &  [71.25, 71.52]      & 0.395             \\
Lanczos & 78.38    & [78.09, 78.68]      & 0.570                   & 73.50     & [72.89, 74.11]     & 0.471                  & 71.55   & [71.42, 71.69]       & 0.399             \\
RDN     & 80.97    & [80.69, 81.25]      & 0.618                   & 71.70     & [71.07,72.32]     & 0.432                   & 69.60    & [69.46, 69.74]       & 0.361           \\
RCAN    & 82.13    & [81.86, 82.41]      & 0.641                  & \textbf{73.97}     & [73.36, 74.57]     & \textbf{0.478}                & 71.89   & [71.76, 72.03]        & 0.4083                   \\
ESRT    & \textbf{83.27} & \textbf{[83.00, 83.54]}& \textbf{0.664}  &  73.72 & [73.11, 74.57]& 0.474  & \textbf{72.32} &\textbf{[72.18, 72.45]} & \textbf{0.419}  \\ \bottomrule
\end{tabular}
\end{table*}



%\subsection{Comparison Algorithms}
\subsection{Baseline Algorithms} 

We compared our neural-based downscaling models to two baseline methods, namely bicubic and Lanczos interpolation. Both of these methods are extensively used in common image processing tasks, including image downscaling. The former uses a polynomial kernel, while the later uses a product of cardinal sines to interpolate between \ac{WFM} samples. The resulting image intensities are subsequently thresholded to yield a binary-valued \ac{FIM}. 

%First we describe the methods we compared against. \textbf{Bicubic} and \textbf{Lanczos} are standard interpolation methods that tend to produce smoother surfaces. These methods are characterized by their interpolation kernels, the convolution over which, produces the output image. Bicubic interpolation uses a polynomial based kernel while Lanczos uses a sinusoidal kernel. We select these methods as non-data driven methods since they do not need any training data to produce final \acp{FIM}.

\subsection{Metrics} 
All the downscaling models we consider employ an adjustable threshold $\theta \in [0,1]$, based on which an array of pixel-on probabilities $S_{i,j}$ is thresholded to obtain a binary \ac{FIM}. We will refer to the fraction of \ac{FIM} pixels whose state (inundated \textit{vs.} non-inundated) is correctly predicted, when using $\theta = 0.5$, as \textit{accuracy}. Apart from this metric and due to the asymmetric importance of predicting inundation \textit{vs.} predicting the lack of it at a locality, we also recorded the \ac{ROC} curve for each model, which depicts the model's true positive rate (hit rate) as a function of the false positive rate (false alarm rate). These curves were obtained by varying the threshold $\theta$ between $0$ and $1$ to obtain predictions from the trained models and allow a stakeholder to establish an acceptable false alarm rate. Finally, due to the pronounced imbalance between the numbers of inundated and dry localities, we also report the models' \acf{MCC}, which ranges in $[0,1]$ and gauges how much more accurate a model is over always predicting that every locality is dry. An \ac{MCC} of $0$ indicates no improvement over a na\"ive model that always predicts no inundation for all pixels. Finally, we need to note that we only aggregate the results for pixels wherein the water fraction is between $0.25$ and $0.85$. This was done to exclude non-riverine regions and the areas in the middle of the river that contribute heavily to the aforementioned metrics due to their large proportion in \acp{FIM}. We also report the Prediction Intervals (PI) of the accuracies for each model. This was calculated using the Clopper-Pearson \cite{ClopperPearsonPI1934} prediction intervals for binomial proportion with a confidence level of 0.99.

% While there are several metrics for the pixel-wise classification task at hand, we are interested primarily in overall accuracy, the true positive rate and the false positive rate. The latter quantities are best captured via a Receiver Operating Characteristic (RoC) curve. This is to facilitate varying motivations of stakeholders to decide an acceptable false alarm rate. We aggregated all the pixel-wise results from all the images and produce accuracy, RoC curve and the \ac{MCC}, which shows a models improvement over the na\"{i}ve classifier whose output is always the majority class (no flood). For each of these metric, we only aggregate the results for pixels wherein the water fraction is between 0.25 and 0.85. This was done to exclude non-riverine regions and the areas in the middle of the river that contribute heavily due to their large proportion in \acp{FIM}.

%%%%%%%%%%%%%% Unused text %%%%%%%%%%%%%%%%%%%%


% \textbf{Geomorphological Features based downscaling} This downscaler takes as inputs two topographical maps and a coarse resolution flood inundation map. The topographical inputs, \ac{VDND} and \ac{HDND}, are derived from \acp{DEM} data from USGS with 30-meter resolution. Every 8x8 section of the 64x64 high-resolution topographical parameter matrices represented a square of the corresponding 8x8 coarse-resolution \ac{FIM} image. L1 and L2 (Euclidean) distance rankings --of the \ac{VDND} and \ac{HDND} -- were employed to rank the probability of flood inundation for each pixel in an 8x8 patch for a corresponding square in the coarse-resolution FIM image. The water fraction of the coarse-resolution \ac{FIM} image was used as a constraint to predict which pixels in the 8x8 patch were inundated. The process was repeated for each square in the 8x8 coarse-resolution \ac{FIM} image and the results were combined to generate a high resolution 64x64 flood inundation prediction matrix.

% \textbf{DeepRivSRM} \cite{Yin2022} has a two-fold architecture for super-resolution of satellite imagery. Their model first produces the fractions and then goes on to use these fraction to produce the high resolution FIMs. We only use the second part of the deep network which transforms the fraction images to high resolution \acp{FIM}. This is akin to using a U-net model with residual learning mechanism built-in.




