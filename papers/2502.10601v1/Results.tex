
% \begin{figure*}[htpb!]
% \label{}
% \centering

%     {{\label{ROCIowaCedar} \includegraphics[width=\textwidth/3]{figures/IowaCedar_roc.png}}}%
%     \qquad
%     {{\label{ROCIowaDesMoines} \includegraphics[width=\textwidth/3]{figures/IowaDesMoines_roc.png} }%
%   \captionsetup{justification=centering}
%   \caption{\Acf{ROC} curves for \acf{RW} Iowa (CR) and  \acf{RW} Iowa (DM) dataset. Dummy model here represents a model whose output is solely a ``no Flood'' for all pixels.}
%   \label{fig:RW_ROC_Curves}%
% \end{figure*}



\section{Results and Discussions}
\label{sec:Results}

In this section, we aim to answer three main questions. First, we want to validate our hypothesis that \ac{SYN} data is a viable proxy for \ac{RW} data when training ML models for downscaling. Secondly, we seek to assess how much more skillful ML-based downscaling is compared to classical, non-data-driven techniques, such as our baseline methods, \textit{i.e.}, thresholded bicubic and Lanczos interpolation. Finally, we would like to appraise the extent to which data-driven models like ours are transferable (in terms of usefulness) to other regions without major performance degradations.  
To assess the quality of the models, we conduct a multiple comparison test --namely the Holm-Bonferroni procedure \cite{HolmBonferroni1979} -- that is designed to control the \ac{FWER}. We notice that, with a \ac{FWER} of $10^{-3}$, all the differences in model performance are significant. The only exception to this trend was observed in \ac{RW}-GH for whom the pairwise differences between \ac{RCAN} and \ac{ESRT}, Lanczos and Bicubic were not significant with the aforementioned \ac{FWER}. 

%Finally, we aim to find out the factors influencing the transferability of our models from one region to another.

\subsection{Potential of using SYN Data for RW downscaling}

In order to evaluate the utility of synthetic data for training, we compare performances of our candidate models on both \ac{SYN} and \ac{RW} Iowa data whose results are presented in Table \ref{tab:IowaResults}. We notice that 
\textbf{(i)} For the Iowa datasets, there is a drop in performance of all the models when going from \ac{SYN} to \ac{RW} datasets, 
\textbf{(ii)} for the \ac{RW}-IA (CR) as well as \ac{RW}-IA (DM) datasets, both bicubic and Lanczos interpolation have accuracies and MCC up to 70.89\% and 0.42 respectively while the deep learning models have accuracies and MCC up to 73.34\% and 0.46 respectively, 
\textbf{(iii)} There is a roughly 6\% accuracy improvement for the \ac{SYN} data for the deep learning models compared to the bicubic and lanczos models and this improvement drops to about 3\% for \ac{RW} data,  
\textbf{(iv)} the performance of all the models remain consistent across both \ac{RW}-IA datasets and \textbf{(v)} in \figref{fig:RW_ROC_Curves}, we observe that there is a high degree of overlap among the \ac{ROC} curves for the data-driven models.

From (i) and (iv) we can conclude that \ac{SYN} data is more intricate than \ac{RW} data. This implies that the benefits yielded by training with \ac{SYN} dataset, while significant, is not as prominent in the \ac{RW} Iowa datasets. 
% This may be due to sensor noise prevalent in the \ac{RW} Landsat-8 data that can be harder to reproduce in the synthetically generated examples. 
(i), (iii) and (v) implies that while \ac{SYN} data is not an exact replacement for \ac{RW} data, it provides a rather significant edge, which is all the more important when there is insufficient \ac{RW} for training. From (ii) we can conclude that the three proposed data driven models outperform classical super-resolution techniques such as bicubic and lanczos, conclusion supported by the \ac{ROC} curves in Figure \ref{fig:RW_ROC_Curves} for whom the data-driven models, in general, lie above the non-data-driven alternatives. Observation (iv) shows that  for the climatically similar \ac{RW}-Iowa(CR) and \ac{RW}-Iowa(DM) regions, training on \ac{SYN} Iowa data does indeed provide an edge. 

% have similar climate. 

\begin{figure*}[t!]
    \centering
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth/2]{figures/IowaCedar_roc.png}
        \caption{}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \includegraphics[width=\textwidth/2]{figures/IowaDesMoines_roc.png}
        \caption{}
    \end{subfigure}
    \vspace*{0.5cm}
    \caption{    \label{fig:RW_ROC_Curves} \Acf{ROC} curves for (a) RW-IA (CR) and (b) RW-IA (DM) dataset. Na\"ive model here represents a model whose output is solely a ``no Flood'' for all pixels. Star here represents the pixel-wise classifier with a threshold of 0.5.}
\end{figure*}


\subsection{Effectiveness of data-driven approaches}

In order to evaluate the effectiveness of ML models in the downscaling task, we compare performances of our candidate models to Lanczos and bicubic interpolation methods by looking at figures of some sample predictions from Iowa (Figure \ref{fig:RWIowaDesMoines}), performance comparison in the region of Iowa in Table \ref{tab:IowaResults} and the ROC curves in Figure \ref{fig:RW_ROC_Curves} for \ac{RW} data. We notice that 
\textbf{(vi)} For RW-IA (DM) samples, the deep learning models maintain a higher degree of spatial continuity in the predicted \ac{FIM}, 
\textbf{(vii)} We observe that  bicubic and Lanczos interpolation produces over-smoothed \ac{FIM} reconstructions, while the plain \ac{RDN}, \ac{RCAN} and \ac{ESRT} models are more detail-inclusive. Similar conclusions can be drawn upon inspecting the \ac{ROC} curves in Figure \ref{fig:RW_ROC_Curves} and 
\textbf{(viii)} For RW-IA (CR), the ML models show a performance improvement of 3.06\% when comparing the best ML model and non-data-driven method and, while for RW-IA (DM) there is a performance improvement of 2.45\%.


Figures \ref{fig:EUSamples} and \ref{fig:RWIowaDesMoines} show the spatial disparity among the models whose details are often obscured in aggregated metrics such as accuracy. (vi) This implies that these data-driven models are better are recognizing an underlying stream network geometry than the classical methods. However, when it comes to narrow river streams, all the models struggle capturing the nuances of the \ac{FIM} resultant from localized high elevation features such as small islands within rivers or man-made structures. (vii) shows a clear advantage of our data-driven approaches over the non-data-driven alternatives. (viii) indicates the benefits of the data-driven models when evaluated over Iowa. 



\subsection{Applicability of our models to external regions}

To evaluate how transferable our models are, we draw conclusions from figures of the sample predictions from Western Europe (Figure \ref{fig:EUSamples}) and Ghana (Figure \ref{fig:GhanaSamples}) as well as the performance comparison in Table \ref{tab:ExternalResults}. We notice that 
\textbf{(ix)} for Ghana all of the models fail to adequately inundate the pixels over separated areas on account of several disconnected regions of inundation in the chosen area,
\textbf{(x)} the ML models outperform non-data driven methods for RW-EU, 
\textbf{(xi)} for the RW-EU dataset, there is an improvement of 4.89\% when comparing the accuracy of the best data- and non-data-driven methods, 
\textbf{(xii)} For RW-RR and RW-GH, there is marginal improvement (up to 0.77\% in accuracy) of the ML methods over the non-data driven methods and 
\textbf{(xiii)} For RW-EU, we notice that the ML models produce more connected streams over the non-data-driven models. 

(x) and (xi) implies that the models are transferable when considering hydroclimaticalogically similar regions since Iowa and the Meuse river in Europe lie within mid temperate zones. Similar to the observation (vi) for RW-IA (DM), (xiii) implies that the benefits of the ML model in identifying underlying network streams is also transferable to hydroclimatologically similar regions. In contrast, (xii) and (ix) both imply that the trained ML models struggle to generalize to RW-RR \& RW-GH. We speculate that this may be due to the significant differences in geography and climate when compared to Iowa. 

% More specifically, we notice that Ghana has a lot of disconnected regions when compared to Iowa and Western Europe, possibly indicating a geomorphological dissimilarity. Additionally, in the case of Red River and Ghana, we also speculate that they include drivers to flood inundation that are different from Iowa and Western Europe, which lie within mild temperate zones. Ghana on the other hand has a tropical (dry and hot) climate.

Our study directly implies that good quality synthetic data can be useful surrogates for downscaling low-resolution \acp{WFM} to high-resolution \acp{FIM} in regions, where such data are hard to come by, even when downscaling by a factor of 10. We noticed that such models were readily transferable to climatically similar regions as the region of training. However, Such derived ML models did not feature significantly different transferability when evaluated over hydroclimatologically dissimilar regions, which we attribute to different flood inundation characteristics, primarily at finer scales. A possible avenue to circumvent such issues is to explore additional training approaches that fall under the general area of domain adaptation. Nevertheless, data-driven models are still advantageous (and, hence, preferable) over non-data-driven alternatives in transfer scenarios like the one we considered here. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% unused text %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% \tabref{tab:AccuracyResults} depicts test accuracies obtained by our models on both \ac{SYN} and \ac{RW} data. For Iowan floods, a comparison of \ac{SYN} and \ac{RW} results shows \textbf{(i)} bicubic and Lanczos interpolations remarkably gaining about $3\%$ in accuracy, as well as \textbf{(ii)} \ac{RDN} and \ac{RCAN} remaining relatively stable, while \textbf{(iii)} topography-aware models loosing $2.7\%$ in performance. From (i) one can conclude that \ac{SYN} data are morphologically slightly more intricate than \ac{RW} data. Also, (i) and (ii) likely imply that \ac{SYN} data, excluding topography, can serve as satisfactory surrogates of \ac{RW} data. However, as implied by (iii), our topography-dependent models seems to be particularly sensitive to distributional shifts of their combined inputs (\acp{WFM} and topographic features). More specifically, the topography-informed models' performance edge, while still statistically significant, is extremely marginal, even when compared to our non-data-driven approaches. Next, when comparing results between the cases of Iowan and Ghanaian \ac{RW} data, one observes that \textbf{(iv)} the accuracy of bicubic and Lanczos interpolations drops by almost $5\%$ due to over-smoothing. This may imply that Ghanaian \acp{FIM} bare a more complex morphology, when compared to Iowan \acp{FIM}. Also, \textbf{(v)} our topography-agnostic, data-driven models' performance degrades more gracefully (by about $2\%$), while \textbf{(vi)} our topography-aware models perform, virtually, as bad as our non-data-driven approaches. Hence, the differences in the data populations of the two regions we considered are significant enough to render our topography-dependent models noncompetitive. 


