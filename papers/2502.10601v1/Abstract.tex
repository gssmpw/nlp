\begin{abstract}
The frequency of extreme flood events is increasing throughout the world. Daily, high-resolution (30m) \acp{FIM} observed from space play a key role in informing mitigation and preparedness efforts to counter these extreme events. However, the temporal frequency of publicly available high-resolution \acp{FIM}, \textit{e.g.}, from Landsat, is at the order of two weeks thus limiting the effective monitoring of flood inundation dynamics. Conversely, global, low-resolution ($\sim$300m) \acp{WFM} are publicly available from NOAA VIIRS daily. Motivated by the recent successes of deep learning methods for single image super-resolution, we explore the effectiveness and limitations of similar data-driven approaches to downscaling low-resolution \acp{WFM} to high-resolution \acp{FIM}. To overcome the scarcity of high-resolution \acp{FIM}, we train our models with high-quality synthetic data obtained through physics-based simulations. We evaluate our models on real-world data from flood events in the state of Iowa. The study indicates that data-driven approaches exhibit superior reconstruction accuracy over non-data-driven alternatives and that the use of synthetic data is a viable proxy for training purposes. Additionally, we show that our trained models can exhibit superior zero-shot performance when transferred to regions with hydroclimatological similarity to the U.S. Midwest. 
\end{abstract}

\begin{IEEEkeywords}
flood inundation maps, super-resolution, water fraction maps, machine learning
\end{IEEEkeywords}
