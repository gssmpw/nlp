\section{Related Work}
\textbf{Adversarial attacks}, and specifically jailbreak attacks or automated red teaming, can be categorized into (1) optimization based attacks____ or (2) attacks using generative models/LLMs____. Our novel REINFORCE objective is focusing on approaches of category (1) that use gradient information____. Specifically, we extend two gradient-based attacks, namely GCG____ and PGD____. While GCG builds on top of the language model attack AutoPromopt____, PGD relates to adversarial attacks on GNNs____. 
While ours is not the first jailbreak attack that uses reinforcement learning (RL), usually RL-based approaches are of category (2) and train another LLM to generate prompts for jailbreaking the targeted LLM____. 
Even though we target gradient-based optimization, our objective is also very effective for GCG with random mutations (see \autoref{fig:gcg_strategies}). Thus, approaches like ____ could also benefit from our advanced objective.

____ explore adaptive attacks. In contrast to our work, they add certain (potentially model-specific) features to their attack that improve the attack success rates (e.g., self-transfer, prompt templates, restarts, etc.). Most of their strategies are orthogonal to ours and could further improve REINFORCE-GCG / -PGD. Nevertheless, it should be noted that they also rely on a non-consistent attack objective (e.g., log probability of ``Sure''). Our findings with adaptive attacks on the circuit breaker defenses align with embedding space attacks~\cite {schwinn_revisiting_2024}.

Adversarial attacks that capture rich semantics have been explored before____. Notably, ____ also explore attacks on LLMs that leverage a judge. In contrast to our work, they relax the generation using Gumble softmax____ and backpropagate through the attacked model and judge for a GBDA-based optimization____. 

\textbf{Affirmative response.} Even though virtually all of the aforementioned optimization-based jailbreak attacks use an affirmative response objective, there have been attempts to mitigate its limitation via varying the template____ or distilling responses from a modified model____. Concurrently, AdvPrefix 
 of ____ finds better response prefixes via high prefilling attack success rates and low negative log-likelihood. Similar to them, our REINFORCE objective also alleviates the issue that the affirmative responses are rather short____. We demonstrate the complementary strengths of AdvPrefix and our objective in \autoref{app:advprefix}.

\textbf{Judges and evaluation.} Multiple judges have been introduced in the literature____. We use the HarmBench____ judge since we evaluate on HarmBench. Nevertheless, we note the recent work by ____ as their judge achieves a slightly better alignment to human evaluation. Moreover, since current LLM-as-a-judge models for scoring harmfulness are all imperfect, one could augment their scores with frequent patterns for false positives (non-harmful prompts that are judged harmful) like____. Next to a judge-based evaluation, one could also gain insights into our objective through (mechanistic) interpretability____.