%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[article, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper
\setlength{\parskip}{0pt}
\pdfminorversion=4
% \documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins  
\UseRawInputEncoding                                    % Needed to meet printer requirements.

\usepackage[
top    = 0.75in,
bottom = 0.75in,
left   = 0.75in,
right  = 0.75in]{geometry}
\usepackage{cite}
\usepackage[skip=10pt plus1pt, indent=35pt]{parskip}
\usepackage{placeins}
\usepackage{textcomp}
\usepackage[dvipsnames]{xcolor}
\usepackage{booktabs}
% \usepackage{soul}
\usepackage{multirow}
\usepackage{siunitx}
\usepackage{float}
\usepackage{paralist}
\usepackage{svg}
\usepackage{array}
\usepackage{subcaption}
\usepackage{xspace}
\usepackage{scrextend}
\usepackage{graphicx} % for pdf, bitmapped graphics files
\usepackage[export]{adjustbox}
\usepackage{caption}
\usepackage{tabularx}
\usepackage{listings}
\usepackage{wrapfig}
\usepackage{calligra}
\usepackage{balance}
\newcolumntype{A}{ >{\centering\arraybackslash} m{4cm} }
\newcolumntype{B}{ >{\centering\arraybackslash} m{1cm} }
\newcommand{\todo}[1]{\textbf{\textcolor{red}{TODO: #1}}}
\newcommand{\Madhav}[1]{\textcolor{magenta}{Madhav: #1}}


\long\def\commentm#1{{\bf **Mohan: #1**}}


\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\usepackage{amsfonts}
\usepackage{authblk}
\DeclareMathOperator*{\argminA}{arg\,min} % Jan Hlavacek
\makeatletter
\let\NAT@parse\undefined
\makeatother
\usepackage[colorlinks=true]{hyperref}  
\setlength{\parindent}{0.5cm}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\title{\LARGE \bf
Anticipate \& Act : Integrating LLMs and Classical Planning for Efficient Task Execution in Household Environments $^\dagger$

}


\author{Raghav Arora$^{1*}$, Shivam Singh$^{1*}$, Karthik Swaminathan$^{1}$, Ahana Datta$^{1}$, Snehasis Banerjee$^{1,2}$, \\ Brojeshwar Bhowmick$^2$, Krishna Murthy Jatavallabhula$^{3}$, Mohan Sridharan$^4$, Madhava Krishna$^1$

\thanks{* Denotes equal contribution}
\thanks{$^{1}$ Robotics Research Center, IIIT Hyderabad, India}
\thanks{$^{2}$ TCS Research, Tata Consultancy Services, India}
\thanks{$^{3}$ CSAIL, Massachusetts Institute of Technology, USA}
\thanks{$^{4}$ IPAB, University of Edinburgh, UK}
\thanks{$^\dagger$ This work was funded by TCS Research, India}
}

\begin{document}


\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
  Assistive agents performing household tasks such as making the bed or cooking breakfast often compute and execute actions that accomplish one task at a time. However, efficiency can be improved by anticipating upcoming tasks and computing an action sequence that jointly achieves these tasks. State-of-the-art methods for task anticipation use data-driven deep networks and Large Language Models (LLMs), but they do so at the level of high-level tasks and/or require many training examples. Our framework leverages the generic knowledge of LLMs through a small number of prompts to perform high-level task anticipation, using the anticipated tasks as goals in a classical planning system to compute a sequence of finer-granularity actions that jointly achieve these goals. We ground and evaluate our framework's abilities in realistic scenarios in the \emph{VirtualHome} environment and demonstrate a $31\%$ reduction in execution time compared with a system that does not consider upcoming tasks. 
  Website: \href{https://raraghavarora.github.io/ahsoka}{https://raraghavarora.github.io/ahsoka}
  
\end{abstract}
\vspace{-1em}
\begin{keywords}
\textbf{}    Task anticipation, large language models, classical planning, assistive agent. 
\end{keywords}

\input{sections/01-introduction}
\input{sections/02-related_work}
\input{sections/03-problem_formulation}
\input{sections/04-results}
\input{sections/05-conclusion}

\bibliographystyle{IEEEtran}
% \bibliography{IEEEabrv, references}
% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{8460924}
P.~Schydlo, M.~Rakovic, L.~Jamone, and J.~Santos-Victor, ``Anticipation in human-robot cooperation: A recurrent neural network approach for multiple action sequences prediction,'' in \emph{IEEE International Conference on Robotics and Automation (ICRA)}, 2018, pp. 5909--5914.

\bibitem{dhakal2023anticipatory}
R.~Dhakal, M.~R.~H. Talukder, and G.~J. Stein, ``{Anticipatory Planning: Improving Long-Lived Planning by Estimating Expected Cost of Future Tasks},'' in \emph{IEEE International Conference on Robotics and Automation}, London, UK, 2023, pp. 11\,538--11\,545.

\bibitem{pmlr-v205-huang23c}
W.~Huang, F.~Xia, T.~Xiao, H.~Chan, J.~Liang, P.~Florence, A.~Zeng, J.~Tompson, I.~Mordatch, Y.~Chebotar, P.~Sermanet, T.~Jackson, N.~Brown, L.~Luu, S.~Levine, K.~Hausman, and b.~ichter, ``Inner monologue: Embodied reasoning through planning with language models,'' in \emph{International Conference on Robot Learning}, 14--18 Dec 2023, pp. 1769--1782.

\bibitem{ding2023task}
Y.~Ding, X.~Zhang, C.~Paxton, and S.~Zhang, ``Task and motion planning with large language models for object rearrangement,'' 2023.

\bibitem{lin2023text2motion}
K.~Lin, C.~Agia, T.~Migimatsu, M.~Pavone, and J.~Bohg, ``Text2motion: From natural language instructions to feasible plans,'' \emph{arXiv preprint arXiv:2303.12153}, 2023.

\bibitem{pddl}
M.~Ghallab, C.~Knoblock, D.~Wilkins, A.~Barrett, D.~Christianson, M.~Friedman, C.~Kwok, K.~Golden, S.~Penberthy, D.~Smith, Y.~Sun, and D.~Weld, ``Pddl - the planning domain definition language,'' 08 1998.

\bibitem{Helmert_2006}
\BIBentryALTinterwordspacing
M.~Helmert, ``The fast downward planning system,'' \emph{Journal of Artificial Intelligence Research}, vol.~26, pp. 191--246, jul 2006. [Online]. Available: \url{https://doi.org/10.1613%2Fjair.1705}
\BIBentrySTDinterwordspacing

\bibitem{puig2018virtualhome}
X.~Puig, K.~Ra, M.~Boben, J.~Li, T.~Wang, S.~Fidler, and A.~Torralba, ``Virtualhome: Simulating household activities via programs,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition}, 2018, pp. 8494--8502.

\bibitem{OpenAI2023GPT4TR}
\BIBentryALTinterwordspacing
OpenAI, ``Gpt-4 technical report,'' \emph{ArXiv}, vol. abs/2303.08774, 2023. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:257532815}
\BIBentrySTDinterwordspacing

\bibitem{chowdhery2022palm}
A.~Chowdhery, S.~Narang, J.~Devlin, M.~Bosma, G.~Mishra, A.~Roberts, P.~Barham, H.~W. Chung, C.~Sutton, S.~Gehrmann, P.~Schuh, K.~Shi, S.~Tsvyashchenko, J.~Maynez, A.~Rao, P.~Barnes, Y.~Tay, N.~Shazeer, V.~Prabhakaran, E.~Reif, N.~Du, B.~Hutchinson, R.~Pope, J.~Bradbury, J.~Austin, M.~Isard, G.~Gur-Ari, P.~Yin, T.~Duke, A.~Levskaya, S.~Ghemawat, S.~Dev, H.~Michalewski, X.~Garcia, V.~Misra, K.~Robinson, L.~Fedus, D.~Zhou, D.~Ippolito, D.~Luan, H.~Lim, B.~Zoph, A.~Spiridonov, R.~Sepassi, D.~Dohan, S.~Agrawal, M.~Omernick, A.~M. Dai, T.~S. Pillai, M.~Pellat, A.~Lewkowycz, E.~Moreira, R.~Child, O.~Polozov, K.~Lee, Z.~Zhou, X.~Wang, B.~Saeta, M.~Diaz, O.~Firat, M.~Catasta, J.~Wei, K.~Meier-Hellstern, D.~Eck, J.~Dean, S.~Petrov, and N.~Fiedel, ``Palm: Scaling language modeling with pathways,'' 2022.

\bibitem{touvron2023llama}
H.~Touvron, T.~Lavril, G.~Izacard, X.~Martinet, M.-A. Lachaux, T.~Lacroix, B.~Rozi√®re, N.~Goyal, E.~Hambro, F.~Azhar, A.~Rodriguez, A.~Joulin, E.~Grave, and G.~Lample, ``Llama: Open and efficient foundation language models,'' 2023.

\bibitem{huang2022inner}
W.~Huang, F.~Xia, T.~Xiao, H.~Chan, J.~Liang, P.~Florence, A.~Zeng, J.~Tompson, I.~Mordatch, Y.~Chebotar, P.~Sermanet, N.~Brown, T.~Jackson, L.~Luu, S.~Levine, K.~Hausman, and B.~Ichter, ``Inner monologue: Embodied reasoning through planning with language models,'' 2022.

\bibitem{Sharma2021SkillIA}
\BIBentryALTinterwordspacing
P.~Sharma, A.~Torralba, and J.~Andreas, ``Skill induction and planning with latent language,'' in \emph{Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}.\hskip 1em plus 0.5em minus 0.4em\relax Dublin, Ireland: Association for Computational Linguistics, May 2022, pp. 1713--1726. [Online]. Available: \url{https://aclanthology.org/2022.acl-long.120}
\BIBentrySTDinterwordspacing

\bibitem{Ahn2022DoAI}
\BIBentryALTinterwordspacing
M.~Ahn, A.~Brohan, N.~Brown, Y.~Chebotar, O.~Cortes, B.~David, C.~Finn, K.~Gopalakrishnan, K.~Hausman, A.~Herzog, D.~Ho, J.~Hsu, J.~Ibarz, B.~Ichter, A.~Irpan, E.~Jang, R.~J. Ruano, K.~Jeffrey, S.~Jesmonth, N.~J. Joshi, R.~C. Julian, D.~Kalashnikov, Y.~Kuang, K.-H. Lee, S.~Levine, Y.~Lu, L.~Luu, C.~Parada, P.~Pastor, J.~Quiambao, K.~Rao, J.~Rettinghouse, D.~M. Reyes, P.~Sermanet, N.~Sievers, C.~Tan, A.~Toshev, V.~Vanhoucke, F.~Xia, T.~Xiao, P.~Xu, S.~Xu, and M.~Yan, ``Do as i can, not as i say: Grounding language in robotic affordances,'' in \emph{Conference on Robot Learning}, 2022. [Online]. Available: \url{https://api.semanticscholar.org/CorpusID:247939706}
\BIBentrySTDinterwordspacing

\bibitem{huang2022language}
\BIBentryALTinterwordspacing
W.~Huang, P.~Abbeel, D.~Pathak, and I.~Mordatch, ``Language models as zero-shot planners: Extracting actionable knowledge for embodied agents,'' \emph{International Conference on Machine Learning}. [Online]. Available: \url{https://par.nsf.gov/biblio/10366294}
\BIBentrySTDinterwordspacing

\bibitem{Lin2023SwiftSageAG}
\BIBentryALTinterwordspacing
B.~Y. Lin, Y.~Fu, K.~Yang, P.~Ammanabrolu, F.~Brahman, S.~Huang, C.~Bhagavatula, Y.~Choi, and X.~Ren, ``Swiftsage: A generative agent with fast and slow thinking for complex interactive tasks,'' \emph{ArXiv preprint}, vol. abs/2305.17390, 2023. [Online]. Available: \url{https://arxiv.org/abs/2305.17390}
\BIBentrySTDinterwordspacing

\bibitem{raman2022planning}
S.~S. Raman, V.~Cohen, E.~Rosen, I.~Idrees, D.~Paulius, and S.~Tellex, ``Planning with large language models via corrective re-prompting,'' 2022.

\bibitem{silver2023generalized}
T.~Silver, S.~Dan, K.~Srinivas, J.~B. Tenenbaum, L.~P. Kaelbling, and M.~Katz, ``Generalized planning in pddl domains with pretrained large language models,'' 2023.

\bibitem{wu2023tidybot}
J.~Wu, R.~Antonova, A.~Kan, M.~Lepert, A.~Zeng, S.~Song, J.~Bohg, S.~Rusinkiewicz, and T.~Funkhouser, ``Tidybot: Personalized robot assistance with large language models,'' in \emph{IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2023.

\bibitem{10161317}
I.~Singh, V.~Blukis, A.~Mousavian, A.~Goyal, D.~Xu, J.~Tremblay, D.~Fox, J.~Thomason, and A.~Garg, ``Progprompt: Generating situated robot task plans using large language models,'' in \emph{2023 IEEE International Conference on Robotics and Automation (ICRA)}, 2023, pp. 11\,523--11\,530.

\bibitem{huang2023voxposer}
W.~Huang, C.~Wang, R.~Zhang, Y.~Li, J.~Wu, and L.~Fei-Fei, ``Voxposer: Composable 3d value maps for robotic manipulation with language models,'' \emph{arXiv preprint arXiv:2307.05973}, 2023.

\bibitem{collins2022structured}
K.~M. Collins, C.~Wong, J.~Feng, M.~Wei, and J.~B. Tenenbaum, ``Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks,'' 2022.

\bibitem{valmeekam2023large}
K.~Valmeekam, A.~Olmo, S.~Sreedharan, and S.~Kambhampati, ``Large language models still can't plan (a benchmark for llms on planning and reasoning about change),'' 2023.

\bibitem{zhao2023antgpt}
Q.~Zhao, C.~Zhang, S.~Wang, C.~Fu, N.~Agarwal, K.~Lee, and C.~Sun, ``Antgpt: Can large language models help long-term action anticipation from videos?'' 2023.

\bibitem{silver2022pddl}
\BIBentryALTinterwordspacing
T.~Silver, V.~Hariprasad, R.~S. Shuttleworth, N.~Kumar, T.~Lozano-P{\'e}rez, and L.~P. Kaelbling, ``{PDDL} planning with pretrained large language models,'' in \emph{NeurIPS Workshop on Foundation Models for Decision Making}, 2022. [Online]. Available: \url{https://openreview.net/forum?id=1QMMUB4zfl}
\BIBentrySTDinterwordspacing

\bibitem{liu2023llmp}
B.~Liu, Y.~Jiang, X.~Zhang, Q.~Liu, S.~Zhang, J.~Biswas, and P.~Stone, ``Llm+p: Empowering large language models with optimal planning proficiency,'' 2023.

\bibitem{xie2023translating}
Y.~Xie, C.~Yu, T.~Zhu, J.~Bai, Z.~Gong, and H.~Soh, ``Translating natural language to planning goals with large-language models,'' 2023.

\bibitem{brown2020language}
\BIBentryALTinterwordspacing
T.~Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal, A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal, A.~Herbert-Voss, G.~Krueger, T.~Henighan, R.~Child, A.~Ramesh, D.~Ziegler, J.~Wu, C.~Winter, C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray, B.~Chess, J.~Clark, C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and D.~Amodei, ``Language models are few-shot learners,'' in \emph{Advances in Neural Information Processing Systems}, H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~Balcan, and H.~Lin, Eds., vol.~33.\hskip 1em plus 0.5em minus 0.4em\relax Curran Associates, Inc., 2020, pp. 1877--1901. [Online]. Available: \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}
\BIBentrySTDinterwordspacing

\bibitem{STRIPS}
\BIBentryALTinterwordspacing
R.~E. Fikes and N.~J. Nilsson, ``Strips: A new approach to the application of theorem proving to problem solving,'' \emph{Artificial Intelligence}, vol.~2, no.~3, pp. 189--208, 1971. [Online]. Available: \url{https://www.sciencedirect.com/science/article/pii/0004370271900105}
\BIBentrySTDinterwordspacing

\bibitem{gerevini:FI11}
A.~Gerevini, A.~Saetti, and I.~Serina, ``An empirical analysis of some heuristic features for planning through local search and action graphs,'' \emph{Fundamental Information}, vol. 107, no. 2-3, pp. 167--197, 2011.

\bibitem{mohan:JAIR19}
M.~Sridharan, M.~Gelfond, S.~Zhang, and J.~Wyatt, ``{REBA: A Refinement-Based Architecture for Knowledge Representation and Reasoning in Robotics},'' \emph{Journal of Artificial Intelligence Research}, vol.~65, pp. 87--180, May 2019.

\bibitem{Kendall}
\BIBentryALTinterwordspacing
M.~G. Kendall, ``The treatment of ties in ranking problems,'' \emph{Biometrika}, vol.~33, no.~3, pp. 239--251, 1945. [Online]. Available: \url{http://www.jstor.org/stable/2332303}
\BIBentrySTDinterwordspacing

\end{thebibliography}
\balance
\end{document}