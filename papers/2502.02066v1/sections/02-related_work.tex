%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{5pt}
\section{Related Work}

%%%%%%%%%%%%%%%%%%%%%%%%%% LLM FOR ROBOTICS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \textbf{Intro to related works:} \\

% Robots have evolved into socially intelligent tools, seamlessly assisting with a wide array of routine tasks. Our research endeavors to offer a solution that enhances the efficiency of indoor robotic operations through anticipated planning of tasks. This section highlights the notable works in the field while also identifying the gaps in the existing research work.


% \textbf{LLM for robotics:}\\
% Large Language Models(LLMs) are extensively used nowadays to generate a logical and an analytical solution to a given problem. These models require a context prehand(few prompts) just to predict the forthcoming logical output(In-Context Learning)\cite{brown2020language} or when sometimes trained and fed with large amounts of data, provide much better result in expense of computation\cite{wei2022finetuned}. Such models are becoming much useful in robotics where the robot can itself generate plans \cite{huang2022inner} \cite{ding2023task} \cite{sharma2022skill} with minimal human intervention. The commonsense knowledge acquired in multiple LLMs like GPT-4 \cite{OpenAI2023GPT4TR}, PaLM\cite{chowdhery2022palm}, Llama\cite{touvron2023llama}, are exploited to generate a sequence of actions and plans \cite{saycan} \cite{huang2022language} \cite{Lin2023SwiftSageAG} \cite{lin2023text2motion} with few implementations on recorrections in prompting for a validation check and improvements in the previously generated tasks plans \cite{raman2022planning}. Some papers harness the potential of code generation by LLMs to make generalized plans for PDDL Domains\cite{silver2023generalized} with inclusion of plan corrective steps. Such LLM-based planning systems are deployed and tested in real-robots \cite{wu2023tidybot} \cite{huang2023voxposer}, and  simulation environments \cite{singh2022progprompt} like VirtualHome \cite{puig2018virtualhome} \cite{song2023llmplanner} AI2-THOR\cite{kolve2022ai2thor}, Habitat-sim\cite{szot2021habitat}. However, as LLMs are trained on web data, there are questions raised as to whether LLMs consider the reasoning metric \cite{collins2022structured} when planning and are capable enough to figure out sophisticated reasoning problems \cite{valmeekam2023large} .

In this section, we review the related work to motivate our framework for task anticipation and plan generation.

\vspace{-0.75em}
\textbf{LLMs for robotics:} LLMs such as GPT-4 \cite{OpenAI2023GPT4TR}, PaLM~\cite{chowdhery2022palm}, and Llama~\cite{touvron2023llama} are being used to address problems in robotics and AI. This includes generating ``plans" to achieve goals~\cite{huang2022inner,ding2023task,Sharma2021SkillIA}, using descriptions of plans extracted from different sources~\cite{Ahn2022DoAI,huang2022language, Lin2023SwiftSageAG,lin2023text2motion}. Some methods have proposed prompting strategies to validate and improve previously generated plans~\cite{raman2022planning, silver2023generalized}. Other methods have demonstrated that the LLM-based summarization can be used for perception and scene understanding~\cite{wu2023tidybot}, and to generate code for planning and robot manipulation~\cite{silver2023generalized,10161317,huang2023voxposer}. Since LLMs are trained on a large amount of data from the Web to predict the text likely to appear next, researchers have questioned the ability of LLMs to plan (in the classical sense) based on prior domain knowledge~\cite{collins2022structured,valmeekam2023large}. 
% Such LLM-based planning systems are deployed and tested in real-robots \cite{wu2023tidybot, huang2023voxposer, singh2022progprompt}, and  simulation environments \cite{singh2022progprompt} like VirtualHome \cite{puig2018virtualhome, song2023llmplanner, kolve2022ai2thor, szot2021habitat}. 
%\vspace{-5pt}

%%%%%%%%%%%%%%%%%%%%% TASK ANTICIPATION EXAMPLES %%%%%%%%%%%%%%%%%%%%%

%\vspace{-5pt}
\vspace{-0.75em}
\textbf{Task Anticipation:} Knowledge-based and data-driven methods have been developed for task anticipation, with state-of-the-art methods using deep networks~\cite{dhakal2023anticipatory} and LLMs~\cite{zhao2023antgpt}. These methods predict high-level tasks or their costs in simplistic domains, with additional planning required to complete each such task, or require many examples to directly predict a sequence of finer-granularity actions to be executed.
%The performance of LLMs to anticipate can be better viewed in similar implementation for anticipation of actions in videos  and 
%LLMs perform well when used to anticipate future actions by learning through the verb and noun sequences and for a longer horizon in the video as showcased in this paper , whereas some implementation integrated GNN to estimate anticipatory cost .\\
Our framework, on the other hand, leverages the complementary strengths of LLMs and classical planning. It enables an agent to operate in complex environments by anticipating high-level tasks based on limited prompts to an LLM, using these tasks as goals to be achieved jointly by planning a sequence of finer-granularity actions based on domain-specific knowledge. %We show that this framework improves performance in comparison with a system that does not consider anticipated tasks. %   anticipation for a large list of objects, locations and actions, targeting anticipation for a \textit{longer-horizon}. The next section would be more about the methodology implied for the idea and it's formulation.
%\textcolor{red}{
%\cite{xie2023translating}: Translating Natural Language to Planning Goals with Large-Language Models (sort of a questionable paper)}

\vspace{-0.75em}
\textbf{Integrating LLMs with PDDL:} Given the existing literature on using PDDL to encode prior knowledge for planning~\cite{pddl}, recent papers have emphasized the need for such planning in combination with LLMs in complex domains~\cite{silver2023generalized, silver2022pddl}. LLMs have been used to generate (or translate prior knowledge to) goal states to be achieved by a classical (PDDL-based) planner~\cite{liu2023llmp, xie2023translating}. % have used translation capabilities of LLMs to generate final goal states given to the planner. \todo{Rephrase this}
%LLMs have also been used to translate prior knowledge to PDDL-based goal states for a classical planner~\cite{xie2023translating}, with the authors showing that 
%\textcolor{red}{
However, research has also indicated that methods based on deep networks and LLMs are not well-suited for multistep, multilevel decision-making (in the classical sense) by reasoning with domain knowledge~\cite{valmeekam2023large}. %} to PDDL-goal states, and have shown that LLMs fail to generalize for tasks that require reasoning. 
  % There are methods for generation of PDDL problem files from natural language then utilizing classical planners to create plans\cite{liu2023llmp}. Methods for generalizing the planning technique are explored in many papers \cite{silver2023generalized} \cite{silver2022pddl}. Such techniques are limited to their scope of domain definition and might not work in domain with complex list of tasks. The integration of LLM and PDDL for household tasks are recently explored\cite{xie2023translating}. Their domain is restricted to tasks related to rearrangement and they explored the translation capabilities of LLM. Whereas, in our methodology, we have created our personalized domain for household activities and delved into proficiencies of LLMs to understand the instructions and provide a list of future tasks.
%\vspace{-5pt}