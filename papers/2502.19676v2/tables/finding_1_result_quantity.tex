\begin{table}[ht]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lcccc}
\toprule
Model & N & APE ($\downarrow$) & MAE ($\downarrow$) & CRPS ($\downarrow$) \\
\midrule
GPT2              & 81 & 0.23 & 0.87 & 0.86 \\
GPT2-XL           & 81 & 0.03 & 0.75 & 0.72 \\
Pythia-14m        & 77 & 0.17 & 0.88 & 0.85 \\
Pythia-160m       & 77 & 0.03 & 0.78 & 0.76 \\
Pythia-2.8b       & 77 & 0.07 & 0.81 & 0.79 \\
Bloom-560m        & 43 & 0.05 & 0.73 & 0.71 \\
Bloom-7b1         & 43 & 0.06 & 0.75 & 0.72 \\
Llama-7b          & 32 & 0.06 & 0.64 & 0.61 \\
OLMo-1B           & 23 & 0.21 & 0.79 & 0.76 \\
OLMo-7B           & 23 & 0.22 & 0.84 & 0.82 \\
OLMo-7B-Instruct  & 23 & 0.24 & 0.80 & 0.77 \\
OLMo-2-7B         & 20 & 0.02 & 0.65 & 0.62 \\
OLMo-2-7B-Instruct & 20 & 0.09 & 0.60 & 0.57 \\
\bottomrule
\end{tabular}%
}
\caption{Performance of forecasting models on Quantity Estimation tasks in \textsc{FOReCAst}. Metrics include the number of evaluated questions (N), normalized absolute percentage error (APE), mean absolute error (MAE), and Continuous Ranked Probability Score (CRPS), where lower values are better.}
\label{tab:quantity_estimation}
\end{table}
