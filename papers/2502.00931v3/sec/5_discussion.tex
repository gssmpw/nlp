\section{Discussion}
\label{sec:discussion}

\subsection{Sizes of Environments vs.\ SR and SPL}
Our experiments grouped environments by \emph{size} into three categories: \textit{Small} (Apartment), \textit{Mid} (Office), and \textit{Big} (averaging Hallway and Outdoor). As shown in Table~\ref{SOTAResults} and the line plots in Fig.~\ref{fig:results}, classical Frontier Exploration suffers a marked performance decline in larger spaces, frequently exceeding the path length limit. Its success rate drops from about 55.6\% in the \textit{Small} environment to only 36.7\% in the \textit{Big}, and its SPL falls from 0.564 to 0.214. This illustrates how naive 360\textdegree\ frontier-based approaches grow increasingly inefficient in larger, more open environments.

By contrast, VL-Nav remains robust across all sizes. Although there is a slight decrease when moving from \textit{Mid} (91.7\% SR, 0.812 SPL) to \textit{Big} (82.3\% SR, 0.655 SPL), its overall performance remains substantially higher than the baselines. A similar trend appears for the ablated VL-Nav variants (w/o IBTP, w/o curiosity), which still surpass Frontier Exploration but fall behind the full VL-Nav system.

These findings underscore two key factors. First, CVL spatial reasoning allows our method to leverage fine-grained vision-language cues (e.g., the “gray cloth” in \fref{fig:main_figure}) while also prioritizing areas with substantial unknown space, thus avoiding the extreme inefficiencies of frontier-based exploration faces in large, open environments. Second, instance-based target points (IBTP) enable more targeted navigation, sustaining high success rates even as map size grows.

\subsection{Semantic Complexities of Environments vs.\ SR and SPL}
We also vary the environments by \emph{semantic complexity}, classifying them as \textit{Low} (Outdoor), \textit{Medium} (Hallway), and \textit{High} (averaging Office and Apartment). An interesting trend emerges: \textit{all methods} show better performance in more semantically rich environments. The likely explanation is that structured indoor spaces (e.g., with walls or furniture) provide stronger cues for the detection and segmentation models used by all five methods, leading to more accurate navigation.

These results underscore that VL-Nav gains more pronounced benefits as the environment offers more semantic context. Rather than being overwhelmed by clutter or complexity, the system capitalizes on language-guided instance-based detections and curiosity-based exploration . The fusion of the CVL spatial reasoning and instance-based target points provides a scalable strategy to locate human-specified targets, even in highly complex indoor domains.


\subsection{Dynamic Environment Handling}

Handling dynamic environments is crucial for robust navigation in real-world scenarios, where changes such as moving obstacles  and varying terrain can impact robot performance. VL-Nav incorporates several strategies to dynamically adapt to environmental changes, ensuring reliability and efficiency.

To handle the dynamic environment, we maintain a dynamic occupancy grid map that integrates dynamic terrain analysis and path planning within the FAR planner \cite{yang2022far}. This allows the system to continuously update its understanding of the environment and adjust navigation strategies accordingly. The dynamic grid map ensures that real-time changes, such as shifting obstacles and terrain conditions, are accurately reflected, providing a more robust foundation for dynamic vision-language navigation in the social environment.

\subsection{Real-Robot Efficiency Optimization}

Although VL-Nav is designed as a general navigation framework, we introduce several optimizations to ensure real-world feasibility and high performance on mobile robots.



\paragraph{Visual-Language Module Variants:}
The first optimization involves selecting an efficient model variant for the visual-language (or object-detection) pipeline. In our tests, we ran multiple versions of YOLO-World \cite{cheng2024yolo} detectors with different input dimensions and TensorRT precision modes. For instance, one configuration used a $256 \times 320$ input size in a standard GPU runtime, another used TensorRT (FP32) at the same resolution, and a third tested TensorRT (FP16) at $480 \times 640$. Empirically, the original $256 \times 320$ configuration (run without TensorRT) achieved about $23\%$ higher success rates than higher-resolution FP16 modes. This suggests that moderate input resolutions can strike a more favorable balance between detection accuracy and real-time performance, which is crucial for robust and efficient continuous on-robot inference.

\paragraph{Rolling Occupancy Grid vs.\ Fixed Large Grid:}
A second optimization lies in how the occupancy grid is maintained. Rather than keeping a large, fixed-size global grid (common in many simulation environments), we implement a \emph{rolling} grid on the real robot, dynamically shifting or expanding it only as new sensor data demand. This rolling approach keeps memory usage proportional to the active exploration area, lowering both storage overhead and BFS/cluster computations for partial frontier detection. Moreover, since real-world robots typically explore incrementally, discarding far-off map regions has minimal impact on decision-making.

\paragraph{Additional System-Level Improvements:}
Finally, we incorporate various practical measures to ensure robust navigation under real-world constraints. For instance, the robot’s local planner and velocity commands are monitored to detect “stuck” situations; if the robot remains motionless beyond a time threshold, the system discards its current goal and reselects a new one. Similarly, sensor frequency and map update rates are tuned so that occupancy-grid expansions do not saturate available CPU/GPU resources. These measures, alongside the rolling-grid and efficient detection models, help keep VL-Nav lightweight and reactive.