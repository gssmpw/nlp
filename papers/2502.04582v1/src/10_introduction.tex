Experimental validation is an integral part of robotics research that even grows in importance with data-driven and learning-based control relying on real-world data.
To test novel algorithms, researchers have proposed a multitude of balancing and driving robots in recent years~\cite{geist2022wheelbot, hofer2023one, carron2023chronos, bodmer2024optimization, o2020f1tenth}.
However, driving robots lack the challenge of instability, and pure balancing lacks mobility and thus higher-level tasks, as we will detail in the discussion of related work.
Despite many practical robots having nonlinear, unstable, and hybrid system behavior (e.g.,~quadcopters~\cite{hanover2024autonomous} and~legged robots~\cite{kim2017design}), small-scale test systems with all these properties are rare.
We think that validating learning algorithms in the presence of uncertainty requires i) safety, ii) robustness~(i.e., not break easily), and iii) automatic experimentation~(i.e.,~reset  after failure), all of which we aim to achieve.

\begin{figure}[t]
    \centering
    \includegraphics[width=3.4in,trim={3.4cm 0.3cm 0cm 0.9cm},clip]{figures/nice_photo/top_view_full_banana_wb_compressed.jpg}%
    \caption{The Mini Wheelbot: A small, rugged, and symmetric reaction wheel unicycle robot with challenging nonlinear, unstable, and hybrid dynamics. The Mini Wheelbot can stand up from any position which allows for automatic environment resets in learning-based control experiments.}\label{fig:firstfig}
    \vspace{-2mm}
\end{figure}


The Mini Wheelbot is a symmetric, reaction wheel, balancing unicycle robot with directly controlled, unstable roll and pitch dynamics.
The yaw state is uncontrollable for the linearized system.
This necessitates nonlinear methods utilizing gyroscopic effects to achieve articulated (meaningful) driving.
The ability to stand up from any initial position enables environment resets for automated experiments.
Additionally, the Mini Wheelbot is powerful enough for interesting maneuvers like flips.
These episodic and continuing tasks are abstractions of typical learning problems in robotics.
In this paper, we showcase two learning-based algorithms to solve them.
First, we use Bayesian optimization~(BO) to tune a balancing controller with minimal human intervention due to automatic resets.
Second, we approximate a sophisticated model-predictive controller~(MPC) with a fast-to-evaluate neural network to control the yaw orientation and drive around based on keyboard commands.

The Mini Wheelbot is a complete re-design that substantially advances an early prototype in~\cite{geist2022wheelbot}: It is smaller, more robust, and has a powerful CPU running Linux while being affordable with bill of material costs of~\$1200 per robot (at quantity ten).
In summary, we make the following contributions:
\begin{compactenum}
    \item The Mini Wheelbot, a small, powerful, rugged, open-source robot ideal for learning-based control experiments due to automatic environment resets and interesting dynamics.
    \item Implementation of two state-of-the-art learning approaches (BO for controller tuning, approximate MPC) to illustrate the versatility as a learning testbed.
    \item With the approximate MPC, we achieve yaw control and thus articulated (meaningful) driving for the first time for this type of robot.
\end{compactenum}
A video of the Mini Wheelbot and our experiments is available~\videolink.
