We introduce the new Mini Wheelbot, a balancing, reaction wheel unicycle robot designed as a robust, compact, and powerful testbed for learning-based control.
We demonstrate the effectiveness of our platform in learning-based control tasks. First, we automatically tune the robot's state-feedback controller using real-world experiments via BO.
As BO requires repeated experiments, this demonstrates how the Mini Wheelbot's automatic environment reset facilitates learning-based control.
In a second illustrative application of learning-based control — imitation learning from an expert MPC — we show that sophisticated MPC schemes can be implemented without the burden of real-time optimization onboard the Mini Wheelbot.
With this approximate MPC, we achieve yaw control and articulated driving for the first time in this class of robots.
However, an in-depth theoretical analysis of this controller remains for future work.

During our experiments, we identified several open topics for future research.
First, the estimator could be enhanced to handle singularities in the orientation representation and saturation in the gyroscope.
Additionally, estimating contact could improve reliability of flip maneuvers and enable more acrobatic sequences with controlled contact switches.
Second, with articulated driving now feasible, we plan to use a fleet of Mini Wheelbots to test future algorithmic advances in multi-robot coordination. 
Finally, the Mini Wheelbot has proven to be a robust testbed for learning through repeated experiments and automatic environment resets.
As such, we envision benchmarking various learning algorithms, including reinforcement learning.
