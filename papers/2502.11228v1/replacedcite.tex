\section{Related Work}
\label{sec:related}

\parhead{Question answering.} There are three main approaches to QA: non-retrieval-based methods____, single-step RAG____, and multi-step RAG____. Non-retrieval-based QA methods pass queries directly to an LLM and use its generated output as the answer, without consulting external sources. While efficient, these methods struggle with queries requiring external or up-to-date information and suffer from hallucinations on out-of-distribution queries____. Single-step RAG methods integrate external knowledge retrieved from a knowledge base (e.g., Wikipedia). These methods improve factual accuracy but are limited by retrieval noise and perform poorly in complex reasoning tasks____. Multi-step RAG methods are designed for complex multi-hop queries____. 

Recent improvements in multi-hop QA focus on question decomposition____, chain-of-thought reasoning____, and iterative retrieval____. Methods like ReCite____ and IRCoT____ refine retrieval with progressive reasoning, while Self-RAG____ adapts retrieval strategies based on query complexity. Decomposed prompting____ further enhances retrieval for complex queries____. MultiHop-RAG____ integrates decomposition and retrieval pipelines but remains constrained by the redundancy issue caused by relevance-based retrieval.  

\parhead{Vendi scoring.} The Vendi Score (VS)____ is a similarity-based diversity metric applied in machine learning____, chemistry____, materials science____, and biology____. Vendi-RAG integrates VS into retrieval, balancing diversity and quality beyond conventional ranking systems____. Unlike standard relevance-based retrieval____, this approach enhances robustness and accuracy in multi-hop QA by incorporating semantic diversity into document retrieval.