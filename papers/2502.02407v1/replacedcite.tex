\section{Related work}
\textbf{Improved variants of \SAM in Vision.} An extensive line of work has attempted to propose better definitions of sharpness --- particularly those which are less sensitive to
details of parameterization
____. Some of these methods 
have shown small improvements on vision tasks. \textit{We believe our decomposition approach is orthogonal to this line of research.} Therefore, the obtained \funcSAM algorithm is substantially different from  prior work.



\textbf{Studies exploring preconditioning for \SAM.} Other work has also suggested that the perturbation step in \SAM should be taken in an alternative geometry. Our approach to preconditioning is most
similar to Fisher \SAM____, and the concurrent work of____ which describes a more
general preconditioning scheme for \SAM. Our key insight is that it is useful to take the \SAM perturbation in the \emph{exact same geometry}
used by the optimizer, which can be accomplished for negligible cost in the case of Adam and its variants.
Furthermore, our work is \textit{primarily driven by the problem of making \SAM work in language modeling}, which is far from the focus of these other works.\looseness=-1

\textbf{Role of the indefinite Hessian term.} At a more conceptual level, our study aligns with recent works____ which underscore paying more importance to the functional Hessian, the understudied indefinite term of the Hessian in the Gauss-Newton decomposition, as opposed to focusing solely on the positive semi-definite GGN term as suggested by prior studies____. The decomposition of the sharpness gradient into logit and functional modes, along with the demonstrated significance of \funcSAM in NLP tasks (which is closely tied to the functional Hessian),\textit{ highlights the risks of over-reliance on the GGN and the corresponding outlier spectrum of the Hessian} --- 
especially in the context of \emph{regularization} of sharpness.

\textbf{\SAM in NLP.} Prior works building on \SAM in NLP have been restricted to the fine-tuning setting____, domain transfer____ or on small-scale machine translation setups____.
To the best of our knowledge, \SAM has hitherto not been successfully applied to language modeling, particularly in any scaling
setting.