\section{Related works}
% CodeAct只利用了code作为action的输出格式，并没有系统性的解决使用code进行tool learning的全过程
% Code+Text只是将输入的问题转为代码进行推理，缺少后续的步骤的设计
% CRAFT等工作都是希望用prompting的方式直接生成code solution，在复杂的tool learning上效果很差
% \subsection{LLMs for Tool Learning}
\subsection{Text-based Tool Learning}
Recent approaches have focused on enhancing LLMs by integrating external tools to improve their problem-solving capabilities~\cite{DBLP:journals/corr/abs-2404-11584,DBLP:journals/corr/abs-2405-17935,qian-etal-2023-creator,DBLP:conf/iclr/YuanC000J24}. Typically, these methods follow a sequential \textit{plan-execute-observe} paradigm and involve utilizing text few-shot prompt to decompose complex tasks into sequential steps, with the LLM executes each tool individually and incorporates the results into its context to manage data flow dependencies~\cite{DBLP:journals/corr/abs-2402-18157,DBLP:conf/nips/ShinnCGNY23,shi-etal-2024-learning,DBLP:journals/corr/abs-2303-09014}. For instance, ReAct~\cite{DBLP:conf/iclr/YaoZYDSN023} enables LLMs to generate both reasoning traces and action plans, facilitating more effective task execution. Similarly, Chameleon~\cite{DBLP:conf/nips/LuPCGCWZG23} employs a compositional reasoning framework that dynamically assembles specialized tools to address complex reasoning tasks. RestGPT~\cite{DBLP:journals/corr/abs-2306-06624} introduces a coarse-to-fine online planning approach, allowing LLMs to iteratively refine task decomposition. However, these text-based methods heavily rely on carefully crafted prompts and struggle with complex multi-step tasks, limiting reliability. \texttt{ToolCoder} addresses these challenges by re-formulating tool learning as code generation, leveraging structured code generation and software engineering principles for better adaptability.

% However, these text-based methods rely heavily on carefully crafted prompts, struggle with complex multi-step tasks, and lack error-handling mechanisms, limiting reliability and efficiency. \texttt{ToolCoder} addresses these challenges by re-formulating tool learning as code generation, leveraging structured code generation and software engineering principles for better control and adaptability.


\begin{figure*}[t]
    \centering
    \includegraphics[width=2\columnwidth]{fig/toolcoder.pdf}
    \caption{Overview of our \texttt{ToolCoder} framework, which converts a user task into executable Python code through task-to-code transformation, tool planning and selection, code implementation, and error reflection. The framework also leverages reusable function snippets to enhance efficiency and accuracy.}
    \label{fig:overview}
    \vspace{-0.5cm}
\end{figure*}

\subsection{Code-based Tool Learning}
Code pre-training has been shown to significantly enhance the chain-of-thought (CoT) performance of LLMs, enabling them to logically decompose complex tasks into smaller, more manageable sub-tasks~\cite{lyu-etal-2023-faithful,DBLP:conf/iclr/ChengX0LNHXROZS23,DBLP:conf/sigir/YeHYLHL23}. Recent studies have further highlighted the potential of code-empowered LLMs to improve the planning and reasoning capabilities of these models~\cite{DBLP:journals/corr/abs-2401-00812,DBLP:journals/tmlr/ChenM0C23,DBLP:conf/icml/GaoMZ00YCN23}. For example, certain approaches enable LLMs to generate programmatic chains of thought to solve complex numeric reasoning tasks, yielding impressive performance~\cite{DBLP:journals/tmlr/ChenM0C23,DBLP:conf/icml/GaoMZ00YCN23}. In the context of tool learning, LLMs can generate code snippets as actions~\cite{DBLP:conf/icml/WangCY0L0J24}, leveraging widely used Python functions and simplifying operations such as lengthy for-loops~\cite{DBLP:journals/corr/abs-2405-16533}.
Previous approaches generate Python code in a single pass, lacking iterative refinement, intent alignment, and learning from past executions~\cite{DBLP:journals/corr/abs-2308-00675,DBLP:journals/corr/abs-2401-06201,DBLP:conf/icml/WangCY0L0J24}. Our \texttt{ToolCoder} framework addresses these limitations by integrating software engineering principles, including modular code construction, stepwise verification, and experience-driven refinement, ensuring the generated code is executable and robust.
% However, previous approaches generate Python code in a single pass without fully utilizing the reasoning capabilities of code language models, lacking mechanisms for iterative refinement, intent alignment with the user's original intent, and learning from past successful executions to enhance robustness and executability~\cite{DBLP:journals/corr/abs-2308-00675,DBLP:journals/corr/abs-2401-06201,DBLP:conf/icml/WangCY0L0J24}. To overcome these limitations, our \texttt{ToolCoder} framework systematically integrates software engineering principles, incorporating modular code construction, stepwise verification, and experience-driven refinement. This ensures that the generated code is not only executable but also robust, intent-aligned, and capable of continuous improvement.

