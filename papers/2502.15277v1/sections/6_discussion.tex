
% \section{Discussion}
% \label{sec:discussion}

\subsection{Transition During Training}
We present how the model performance evolved throughout training in \dobjppiobjpp{}, shown in Figure~\ref{fig:results_overall_epoch}.
As can be seen, the accuracy in the test set grew rapidly, whereas the accuracy in the generalization set improved slowly.
In addition, comparing the base model and subnetwork in machine translation, the generalization performance of the subnetwork continued to improve through 500 epochs, whereas that of the base model improved only slightly.
Therefore, the model may gradually learn an algorithm that can solve the generalization task through the training process with the machine translation task without changing the behavior of the whole model much.
The difference in the performance transition between the base model and subnetwork is much less noticeable in semantic parsing.
These results suggest that differences in the task settings---such as output formats where structures are represented more explicitly in semantic parsing---influence generalization performance.
A similar tendency was discovered in \dobjppsubjpp{} (see Appendix~\ref{sec:causal_other} for details), although the generalization performance was generally lower.

Next, we investigate how the inner workings of the subnetwork changed as the training went on.
Figure~\ref{fig:results_causal_epoch} shows the shift of the generalization performance in machine translation of the subnetwork with each linguistic feature removed.
In machine translation, the generalization performance of the subnetwork with certain syntactic feature removed was mostly consistent after 200 epochs.
This strongly suggests that the subnetwork learned a non-compositional solution in the early stage of the training and retained it throughout the training.
Combined with the observation that the original subnetwork continued to improve its accuracy beyond 200 epochs, this result also indicates that a compositional solution relying on syntactic features was acquired gradually.

Similarly, in semantic parsing, the subnetwork with a certain linguistic feature removed mostly retained its performance after 200 epochs, regardless of the generalization accuracy of the original subnetwork.
The detailed results of semantic parsing are in Appendix~\ref{sec:causal_other}.



\section{Discussion}
\label{sec:discussion}
\subsection{Reliability of LEACE}
\input{sources/tab_results_word}
Since LEACE is a linear concept erasure method, it may fail to remove concepts encoded non-linearly.
However, the results when all syntactic information was removed (Figure~\ref{fig:results_causal}) indicate that most syntactic information used in machine translation and semantic parsing is encoded in linear subspaces.
Furthermore, we use linear probing to assess whether the concepts are perfectly removed after the application of concept scrubbing.
We probe the representation of the final layer of the encoder after each concept scrubbing, and measure the accuracy in the multi-label classification tasks used in concept scrubbing.
As a result, the probing classifier predicted the correct labels for all the words in 0\% of the test sentences in almost all combination of the removed concepts, generalization patterns, and main tasks.
The only exceptions occurred when either all syntactic dependencies or those related to the PP modification of all NPs were removed, with maximum accuracies of 9.7\% and 1.3\%, respectively.
Thus, the impact of non-linearly encoded features should be negligible, and concept scrubbing effectively removes syntactic features.


We also validate that LEACE does not erase concepts orthogonal to syntactic ones.
We test the model with a word-to-word translation (English to Japanese) of content words; word-to-word translation of content words can be solved without relying on syntax at all.
We probe the representation of the final layer of the encoder by a one-layer linear classifier for word-to-word translation, focusing on evaluating the models trained with machine translation datasets. Accuracy is calculated as the proportion of sentences in which all content words are translated correctly.
As shown in Table~\ref{tab:results_word}, the results suggest that the removal of syntactic features only slightly decreases performance in word-to-word translation, confirming that concepts orthogonal to syntactic ones are mostly preserved in LEACE.

\subsection{Impact of Adding Hints in Training}
\input{sources/fig_results_hint}
Finally, we investigate how a Transformer model performs under a setting where compositional generalization is easier.
We augment the training set with sentences containing syntactic structures that provide clues for generalization.
In particular, we focus on \dobjppiobjpp{} and augment the training set with sentences that have a relative clause (RC) modifying an indirect object NP and with ones that have an RC modifying a direct object NP.
It should be easier for the model trained with the data involving PPs modifying direct object NPs to generalize to a PP modifying an indirect object NP based on the newly provided hints.

Figure~\ref{fig:results_hint} presents the results of causal analysis.
Compared with the results without any hint (Figures~\ref{fig:results_causal_a} and \ref{fig:results_causal_b}), the generalization performance without any concept removal improved by about 40\% in both main tasks.
Moreover, the performance after the removal of syntactic features regarding the PP modifications of indirect object NPs improved only slightly.
This suggests that the algorithm that was implemented in the base model and contributed to the gain in the generalization performance relied on those specific syntactic features.
Thus, the model might implement a more robust compositional solution by utilizing the provided hints.