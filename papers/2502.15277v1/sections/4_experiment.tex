\section{Experimental settings}
\label{sec:experiment}

\input{sources/tab_generalization_pattern}

\subsection{Compositional Generalization Pattern}
\label{subsec:cg-pattern}

In this work, we focus on two compositional generalization patterns, i.e., PP in indirect object NP (\dobjppiobjpp{}) and PP in subject NP (\dobjppsubjpp{}{}), as shown in Table~\ref{tab:generalization_pattern}.
Syntactically, these two patterns are relatively simple, which allows for easier causal analyses using multi-label classification tasks.

\paragraph{PP in indirect object NP (\dobjppiobjpp{})}
In this pattern, all the NPs modified by PPs in the training set appear in the direct object position.
Then, models trained on the training set are expected to generalize to PPs modifying indirect object NPs in the generalization set.
As \citet{li-etal-2023-slog} pointed out, some sentences have an indirect object NP modified by a PP before a direct object NP, and the dependency between a verb and the direct object NP goes across the PP, which makes the generalization more complex.

For causal analysis in this pattern, we test the impact of three narrower syntactic constituency and dependency concepts, namely, the PP modification of indirect object NPs, direct object NPs, and all NPs, along with overall syntactic constituency and dependency.
\paragraph{PP in subject NP (\dobjppsubjpp{})}
Similarly to \dobjppiobjpp{}, all the NPs modified by PPs in the training set appear in the direct object position.
Models trained on the training set are expected to generalize to PPs modifying subject NPs in the generalization set.
One aspect that makes \dobjppsubjpp{} difficult is that PP modifiers do not appear at the beginning of sentences in the training set.
The models may have to generalize to the novel placement of PP modifiers in addition to the novel grammatical role of modified NPs.
To mitigate this issue, \citet{wu-etal-2023-recogs} added sentences with preposed PP modifiers in the training set, but we avoid that approach for the sake of simpler comparisons between \dobjppiobjpp{} and \dobjppsubjpp{}.

For causal analysis in this pattern, we test the impact of three narrower syntactic constituency and dependency concepts, namely, the PP modification of subject NPs, direct object NPs, and all NPs, along with overall syntactic constituency and dependency.
% \paragraph{Hint patterns}
% We add ``hint'' syntactic structures to the training set and train another base model.
% Those ``hints'' do not give models direct solutions but make the generalization easier.
% For example, in \dobjppiobjpp{} pattern, we add sentences with relative clauses modifying indirect object NPs.
% It makes the model understand that indirect object NPs can be modified like direct object NPs, which would make the generalization to \dobjppiobjpp{} easier than without ``hints''.

% \subsection{Target Linguistic Properties}
% We adopt the same two tasks as in probing~\ref{subsec:probing}, but we use several variants with different ground truths of labels and boundaries to analyze the causal effect of different dependencies and constituency boundaries.
% In syntactic dependency labels task, for example, we assign labels to all dependencies when analyzing the causal effect of syntactic dependencies in general.
% On the other hand, when analyzing the causal effect of the modification of a prepositional phrase (PP) to a noun phrase in the indirect object position, we assign labels only to the corresponding dependency because labels to other dependencies would lead to the removal of non-target properties.
% We utilize these variants to explore in detail what knowledge or concepts models use for the outputs, especially in the context of compositional generalization.

\subsection{Dataset}
As explained in Section~\ref{sec:method}, we newly construct datasets for each of machine translation and semantic parsing and for classification tasks used in concept scrubbing, using PCFGs with vocabulary of 123 proper nouns, 423 common nouns, 178 verbs, and 43 adjectives.
Each of the machine translation and semantic parsing datasets consists of a training set of 80,000 samples, a test set of 10,000 samples, and a generalization set of 30,000 samples.
We split the generalization set into two parts:
one part is used in training masks in subnetwork probing (Section~\ref{subsec:subnetwork-probing}), and the other is used in evaluating the trained models and subnetworks (Section~\ref{subsec:causal}).
Note that the generalization set is constructed for each generalization pattern, and subnetwork probing is performed for each pattern as well.
The dataset for classification tasks contains 9,000 samples, and all of them are used for concept scrubbing.

\subsection{Training Details}
We train an encoder--decoder Transformer model from scratch on our dataset.
The model has 3 encoder and 3 decoder layers, 4 attention heads.
We set the batch size to 256, the number of epochs to 500, the learning rate to 0.0001, and the weight decay to 0.1.
We do not use early stopping because \citet{csordas-etal-2021-devil} showed that continued training without it improves model performance in compositional generalization.

As for subnetwork probing, we train a pruning mask for the trained model.
We set the batch size to 256, the number of training epochs to 300, and the learning rate to 0.0005.
We do not use early stopping in subnetwork probing.

We run the experiments three times with random seeds and report the average scores as the results.
The final checkpoints of each training run are used for the main results (Section~\ref{sec:results}).

\subsection{Evaluation Metric}
\label{subsec:metric}
Following previous studies of evaluating compositional generalization~\citep{kim-linzen-2020-cogs, kumon-etal-2024-evaluating}, we adopt exact match accuracy as the evaluation metrics for both machine translation and semantic parsing.
The rule-based pipeline for our dataset generation is designed so that a correct output can be determined uniquely if a model follows compositional rules; thus, using exact match accuracy in this experiment is appropriate.
