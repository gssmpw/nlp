

@article{chu2024qwen2,
  title={Qwen2-audio technical report},
  author={Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2407.10759},
  year={2024}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@article{an2024funaudiollm,
  title={Funaudiollm: Voice understanding and generation foundation models for natural interaction between humans and llms},
  author={An, Keyu and Chen, Qian and Deng, Chong and Du, Zhihao and Gao, Changfeng and Gao, Zhifu and Gu, Yue and He, Ting and Hu, Hangrui and Hu, Kai and others},
  journal={arXiv preprint arXiv:2407.04051},
  year={2024}
}

@inproceedings{SEAME,
  title     = {SEAME: a Mandarin-English code-switching speech corpus in south-east asia},
  author    = {Dau-Cheng Lyu and Tien-Ping Tan and Eng Siong Chng and Haizhou Li},
  year      = {2010},
  booktitle = {Interspeech 2010},
  pages     = {1986--1989},
  doi       = {10.21437/Interspeech.2010-563},
  issn      = {2958-1796},
}

@inproceedings{ASCEND,
    title = "{ASCEND}: A Spontaneous {C}hinese-{E}nglish Dataset for Code-switching in Multi-turn Conversation",
    author = "Lovenia, Holy  and
      Cahyawijaya, Samuel  and
      Winata, Genta  and
      Xu, Peng  and
      Xu, Yan  and
      Liu, Zihan  and
      Frieske, Rita  and
      Yu, Tiezheng  and
      Dai, Wenliang  and
      Barezi, Elham J.  and
      Chen, Qifeng  and
      Ma, Xiaojuan  and
      Shi, Bertram  and
      Fung, Pascale",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.788/",
    pages = "7259--7268",
    abstract = "Code-switching is a speech phenomenon occurring when a speaker switches language during a conversation. Despite the spontaneous nature of code-switching in conversational spoken language, most existing works collect code-switching data from read speech instead of spontaneous speech. ASCEND (A Spontaneous Chinese-English Dataset) is a high-quality Mandarin Chinese-English code-switching corpus built on spontaneous multi-turn conversational dialogue sources collected in Hong Kong. We report ASCEND`s design and procedure for collecting the speech data, including annotations. ASCEND consists of 10.62 hours of clean speech, collected from 23 bilingual speakers of Chinese and English. Furthermore, we conduct baseline experiments using pre-trained wav2vec 2.0 models, achieving a best performance of 22.69{\%} character error rate and 27.05{\%} mixed error rate."
}

@inproceedings{TALCS,
  title     = {TALCS: An open-source Mandarin-English code-switching corpus and a speech recognition baseline},
  author    = {Chengfei Li and Shuhao Deng and Yaoping Wang and Guangjing Wang and Yaguang Gong and Changbin Chen and Jinfeng Bai},
  year      = {2022},
  booktitle = {Interspeech 2022},
  pages     = {1741--1745},
  doi       = {10.21437/Interspeech.2022-877},
  issn      = {2958-1796},
}


@article{shi2020asru,
  title={The asru 2019 mandarin-english code-switching speech recognition challenge: Open datasets, tracks, methods and results},
  author={Shi, Xian and Feng, Qiangze and Xie, Lei},
  journal={arXiv preprint arXiv:2007.05916},
  year={2020}
}


@article{li2025dota,
  title={DOTA-ME-CS: Daily Oriented Text Audio-Mandarin English-Code Switching Dataset},
  author={Li, Yupei and Wei, Zifan and Yu, Heng and Zhou, Huichi and Schuller, Bj{\"o}rn W},
  journal={arXiv preprint arXiv:2501.12122},
  year={2025}
}

@inproceedings{shen2011cecos,
  title={CECOS: A Chinese-English code-switching speech database},
  author={Shen, Han-Ping and Wu, Chung-Hsien and Yang, Yan-Ting and Hsu, Chun-Shan},
  booktitle={2011 International Conference on Speech Database and Assessments (Oriental COCOSDA)},
  pages={120--123},
  year={2011},
  organization={IEEE}
}

@inproceedings{wang2016oc16,
  title={OC16-CE80: A Chinese-English mixlingual database and a speech recognition baseline},
  author={Wang, Dong and Tang, Zhiyuan and Tang, Difei and Chen, Qing},
  booktitle={2016 Conference of The Oriental Chapter of International Committee for Coordination and Standardization of Speech Databases and Assessment Techniques (O-COCOSDA)},
  pages={84--88},
  year={2016},
  organization={IEEE}
}

@inproceedings{li2012mandarin,
  title={A Mandarin-English Code-Switching Corpus.},
  author={Li, Ying and Yu, Yue and Fung, Pascale},
  booktitle={LREC},
  pages={2515--2519},
  year={2012}
}

@inproceedings{gao22b_interspeech,
  title     = {Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition},
  author    = {Zhifu Gao and ShiLiang Zhang and Ian McLoughlin and Zhijie Yan},
  year      = {2022},
  booktitle = {Interspeech 2022},
  pages     = {2063--2067},
  doi       = {10.21437/Interspeech.2022-9996},
  issn      = {2958-1796},
}

@article{transformer,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{ctc,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={ICML},
  pages={369--376},
  year={2006}
}

@inproceedings{conformer,
  title     = {Conformer: Convolution-augmented Transformer for Speech Recognition},
  author    = {Anmol Gulati and James Qin and Chung-Cheng Chiu and Niki Parmar and Yu Zhang and Jiahui Yu and Wei Han and Shibo Wang and Zhengdong Zhang and Yonghui Wu and Ruoming Pang},
  year      = {2020},
  booktitle = {Interspeech 2020},
  pages     = {5036--5040},
  doi       = {10.21437/Interspeech.2020-3015},
  issn      = {2958-1796},
}

@inproceedings{wenet,
  title     = {WeNet: Production Oriented Streaming and Non-Streaming End-to-End Speech Recognition Toolkit},
  author    = {Zhuoyuan Yao and Di Wu and Xiong Wang and Binbin Zhang and Fan Yu and Chao Yang and Zhendong Peng and Xiaoyu Chen and Lei Xie and Xin Lei},
  year      = {2021},
  booktitle = {Interspeech 2021},
  pages     = {4054--4058},
  doi       = {10.21437/Interspeech.2021-1983},
  issn      = {2958-1796},
}

@inproceedings{peng2022branchformer,
  title={Branchformer: Parallel mlp-attention architectures to capture local and global context for speech recognition and understanding},
  author={Peng, Yifan and Dalmia, Siddharth and Lane, Ian and Watanabe, Shinji},
  booktitle={International Conference on Machine Learning},
  pages={17627--17643},
  year={2022},
  organization={PMLR}
}

@article{chorowski2014end,
  title={End-to-end continuous speech recognition using attention-based recurrent nn: First results},
  author={Chorowski, Jan and Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.1602},
  year={2014}
}

@misc{moyer2002bilingual,
  title={Bilingual speech: A typology of code-mixing},
  author={Moyer, Melissa G},
  year={2002},
  publisher={JSTOR}
}

@article{yilmaz2018acoustic,
  title={Acoustic and textual data augmentation for improved ASR of code-switching speech},
  author={Y{\i}lmaz, Emre and Heuvel, Henk van den and van Leeuwen, David A},
  journal={arXiv preprint arXiv:1807.10945},
  year={2018}
}

@article{zhou2024improving,
  title={Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and Gated Monolingual Datastores},
  author={Zhou, Jiaming and Zhao, Shiwan and Wang, Hui and Zhang, Tian-Hao and Sun, Haoqin and Wang, Xuechen and Qin, Yong},
  journal={arXiv preprint arXiv:2406.03814},
  year={2024}
}

@INPROCEEDINGS{10094707,
  author={Chang, Feng-Ju and Muniyappa, Thejaswi and Sathyendra, Kanthashree Mysore and Wei, Kai and Strimel, Grant P. and McGowan, Ross},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Dialog Act Guided Contextual Adapter for Personalized Speech Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Adaptation models;Error analysis;Semantics;Signal processing;Acoustics;Speech processing;Context modeling;Contextual adapter;personalized speech recognition;RNN-T;dialog act;early-late fusion},
  doi={10.1109/ICASSP49357.2023.10094707}}


@article{mustafa2022code,
  title={Code-switching in automatic speech recognition: The issues and future directions},
  author={Mustafa, Mumtaz Begum and Yusoof, Mansoor Ali and Khalaf, Hasan Kahtan and Rahman Mahmoud Abushariah, Ahmad Abdel and Kiah, Miss Laiha Mat and Ting, Hua Nong and Muthaiyah, Saravanan},
  journal={Applied Sciences},
  volume={12},
  number={19},
  pages={9541},
  year={2022},
  publisher={MDPI}
}