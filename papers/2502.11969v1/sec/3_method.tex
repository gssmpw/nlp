\section{Prompt Tuning with SAR}
In this section, we present the implementation of SAR and its integration within the prompt tuning framework.

\subsection{Preliminaries}
\keypoint{Contrastive Language-Image Pre-training (CLIP) \cite{radford2021clip}.} CLIP is a vision-language model pre-trained on 400 million image-text pairs, designed to align semantic relationships between image and text modalities. It consists of an image encoder $\theta(\cdot)$ and a text encoder $\phi(\cdot)$ that map their respective inputs into a shared embedding space. CLIP is trained using contrastive learning, where embeddings of matched image-text pairs are pulled closer together, while those of unmatched pairs are pushed apart. We can perform zero-shot image classification using CLIP by comparing the matching score, which is cosine similarity between the image embedding and the text embedding. Using appropriate prompts can significantly enhance CLIP’s classification performance. Finding task-optimized prompts is referred to as prompt engineering, which often relies on a trial-and-error process.

\keypoint{Context Optimization.} CoOp \cite{zhou2022learning} proposes a framework that trains prompts via a classification task using image-text pairs of target tasks. In CoOp, $P$ trainable vectors $[\boldsymbol{v}_1, \boldsymbol{v}_2, \dots, \boldsymbol{v}_P]$ serve as prompts. These vectors are added to $\boldsymbol{c}_i$, the word embedding(s) of the $i$-th class name $\boldsymbol{w}_i$, and passed to the text encoder to compute the text embedding $\boldsymbol{g}_i = \phi([\boldsymbol{v}_1, \boldsymbol{v}_2, \dots, \boldsymbol{v}_P, \boldsymbol{c}_i])$. Similarly, the image embedding $\boldsymbol{f}$ is computed by passing each image $x$ through the image encoder $\theta(\cdot)$. The probability that $\boldsymbol{x}$ is predicted as $\boldsymbol{w}_i$ is computed as:

\begin{equation}
p(\boldsymbol{w}_i|\boldsymbol{x}) = \frac{\exp(\cos(\boldsymbol{g}_i,\boldsymbol{f}) / \tau)}{\sum_{j=1}^C \exp(\cos(\boldsymbol{g}_j,\boldsymbol{f}) / \tau)},
\end{equation}
where $\cos(\cdot, \cdot)$ denotes cosine similarity, $C$ is the number of classes, and $\tau$ is the learned temperature parameter of CLIP. To optimize prompts for target tasks, trainable vectors are updated by cross-entropy loss:

\begin{equation}
\mathcal{L}_{\text{ce}}=-\sum_{i} \boldsymbol{y}_i \log p(\boldsymbol{w}_i|\boldsymbol{x}),
\end{equation}
where $\boldsymbol{y}$ is the one-hot encoded label. During prompt tuning, all weights in the image and text encoders of CLIP are fixed.

\begin{figure*}[ht]
    \setlength{\abovecaptionskip}{0.2cm}  
    \setlength{\belowcaptionskip}{-0.4cm} 
    \centering
    \includegraphics[width=1.0\linewidth]{fig/framework.pdf} 
    \caption{Overview of how Similarity-Alignment Regularization (SAR) operates in prompt tuning. SAR targets the base and novel classes, aligning the semantic relationships among text embeddings generated by learnable prompts with those relationships from ensembled hand-crafted prompts. Specifically, this alignment is achieved by minimizing the KL divergence between the corresponding similarity distributions. To mitigate overfitting, random embedding sampling is employed instead of computing similarities across all classes.}
    \label{fig:framework}
\end{figure*}

\subsection{Semantic Disruption by Learned Prompts}
Now we analyze how the semantically misaligned text embeddings, generated by learned prompts, lead to poor generalization.

\keypoint{Computing Semantic Similarities among Classes.} We begin by describing how to compute a similarity distribution matrix, which shows the semantic relationships among text embeddings. Let $\{\boldsymbol{g}_j\}_{j=1}^{N}$ denote a set of text embeddings corresponding to $N$ arbitrary classes, where $\boldsymbol{g}_j \in \mathbb{R}^{d}\ \forall j$. Since matched image-text pairs are located closer in CLIP’s embedding space, text pairs with similar semantics also tend to be closer, allowing us to measure their semantic similarities via cosine similarity. We can compute the cosine similarity matrix $\mathbf{C} \in \mathbb{R}^{N \times N}$ with entries $\mathbf{C}_{ij}=\cos(\boldsymbol{g}_i, \boldsymbol{g}_j)$. To highlight relational similarities among classes, we compute the similarity distribution matrix $\mathbf{P}$, by applying a softmax function to each row of $\mathbf{C}$, excluding its diagonal elements (which represent self-similarity) from the computation:
\begin{equation}
\mathbf{P}_{ij} =
\begin{cases} 
0, & \text{if } i = j, \\
\frac{\exp\left( \cos(\boldsymbol{g}_i, \boldsymbol{g}_j) / \tau \right)}{\sum_{k \neq i} \exp\left( \cos(\boldsymbol{g}_i, \boldsymbol{g}_k) / \tau \right)}, & \text{if } i \neq j.
\end{cases}
\end{equation}
Note that the matrix $\mathbf{P}$ is not necessarily symmetric, as the normalization can differ for each row.

\keypoint{Prompt Generalization Evaluation.} To evaluate the generalization of learned prompts to unseen classes, we perform base-to-new generalization experiments. Specifically, we first train prompts using image-text pairs from only half of dataset's classes (base classes). Then, we conduct zero-shot evaluation on the test data of remaining half classes (new classes) using the learned prompts. During this process, we compare the two similarity distribution matrices computed over all (base+new) classes: 1) $\mathbf{P}_{\mathtt{CoOp}}$, produced by learned prompts, and 2) $\mathbf{P}_{\mathtt{hand}}$, produced by hand-crafted prompts. Additionally, we examine the logit patterns for the test images. Specifically, we transform the logit vector for each image into a 2-dimensional vector using t-SNE \cite{van2008visualizing} and visualize the results.

The experimental results on EuroSAT \cite{helber2019eurosat} are presented in \Cref{fig:motivation}. The leftmost heatmap, corresponding to $\mathbf{P}_{\mathtt{CoOp}}$, reveals that the learned prompts generate semantically misaligned text embeddings for certain new classes. For example, in $\mathbf{P}_{\mathtt{CoOp}}$, the class $River$ shows a higher similarity to $Forest$ than to $Sea\ or\ Lake$, despite the latter being semantically closer. Similarly, the similarity between $Sea\ or\ Lake$ and $Highway\ or\ Road$ is abnormally high, even though they are semantically unrelated. Moreover, the learned prompts fail to preserve subtle semantic distinctions among classes, forming overly confident associations. In contrast, $\mathbf{P}_{\mathtt{hand}}$ captures the more meaningful semantic relationships and better reflects subtle distinctions among classes. The logits scatterplots at the bottom further illustrate that semantically misaligned text embeddings lead to poor generalization in the classification task. In the scatterplot for CoOp, the logits for $Sea\ or\ Lake$ and $River$ form poorly defined clusters that overlap significantly, showing that the text embeddings struggle to capture the visual concepts of the two classes. In contrast, in the scatterplot for the hand-crafted prompt, the clusters for the two classes are clearly separated, highlighting its superior capability in generalization.

\subsection{Similarity Alignment Regularization}
To prevent semantic disruptions caused by learned prompts and improve generalization, we propose Similarity Alignment Regularization (SAR). \Cref{fig:framework} illustrates the operation of SAR in prompt learning.

\keypoint{Prompt Learning with Novel Classes.} We use ChatGPT-4o to generate novel classes semantically aligned with the base classes, utilizing them as potential unseen classes during prompt tuning. Specifically, we provide ChatGPT-4o with a list of the base classes and instruct it to generate semantically aligned novel classes. The prompt given to ChatGPT-4o is provided in \underline{\textbf{Supp. Material. A}}. To obtain more robust and representative embeddings for each class, we use ensembled text embeddings from multiple hand-crafted prompts. Let $T$ be the number of hand-crafted prompts used for prompt ensembling. For $j$-th class, the ensembled text embedding is computed as $\bar{\boldsymbol{g}}_j=\frac{1}{T}\sum_{i=1}^T \boldsymbol{g}_j^i$, where $\boldsymbol{g}_j^i$ is the text embedding of $j$-th class generated by the $i$-th prompt. The hand-crafted prompts used for ensembling are listed in \underline{\textbf{Supp. Material. B}}. Let $\mathcal{G}_{\mathtt{hand}}=\{\bar{\boldsymbol{g}}_j\}_{j=1}^{M}$ denote the set of text embeddings for both base and novel classes, generated by the hand-crafted prompts. In contrast, $\mathcal{G}_{\mathtt{CoOp}}=\{\hat{\boldsymbol{g}}_j\}_{j=1}^{M}$ represents the set of text embeddings generated by the learnable prompts.

For learnable prompts to preserve meaningful semantic relationships among classes, SAR aim to align the semantic relationships in $\mathcal{G}_{\mathtt{CoOp}}$ with those in $\mathcal{G}_{\mathtt{hand}}$ during prompt tuning.
A straightforward way to achieve this is to construct similarity distribution matrices for $\mathcal{G}_{\mathtt{CoOp}}$ and $\mathcal{G}_{\mathtt{hand}}$, respectively, and minimize the KL divergence \cite{kullback1951information} between them during prompt learning. This method simultaneously takes into account all pairwise semantic similarities between the text embeddings. To mitigate overfitting, however, we introduce randomness into the regularization process through random embedding sampling.

\keypoint{Computing Similarities for Sampled Classes.} For each $\hat{\boldsymbol{g}}_j$, we compute similarities with $K$ other embeddings that are randomly sampled, rather than considering all other embeddings. Let $\mathcal{I}_j$ denote the set of $K$ indices of the sampled embeddings, ensuring that $j \notin \mathcal{I}_j$ to exclude self-similarity. Now the similarity disbribution matrix $\mathbf{P}_{\mathtt{CoOp}}^{\mathcal{I}}$ is computed as:
\renewcommand{\arraystretch}{1.5}
\begin{equation}
\mathbf{P}_{\mathtt{CoOp}}^{\mathcal{I}} = 
\begin{bmatrix}
\sigma\Big(\big[\cos(\hat{\boldsymbol{g}}_1, \hat{\boldsymbol{g}}_k) \,|\, k \in \mathcal{I}_1\big]\Big) \\
\sigma\Big(\big[\cos(\hat{\boldsymbol{g}}_2, \hat{\boldsymbol{g}}_k) \,|\, k \in \mathcal{I}_2\big]\Big) \\
\vdots \\
\sigma\Big(\big[\cos(\hat{\boldsymbol{g}}_M, \hat{\boldsymbol{g}}_k) \,|\, k \in \mathcal{I}_M\big]\Big)
\end{bmatrix}
\in \mathbb{R}^{M \times K},
\end{equation}
where $\sigma(\cdot)$ denotes the softmax function with the CLIP-learned temperature $\tau$. Using $\mathcal{G}_{\mathtt{hand}}$, we also compute $\mathbf{P}_{\mathtt{hand}}^{\mathcal{I}} \in \mathbb{R}^{M \times K}$ with the same family $\mathcal{I}$ of index sets, as the target of $\mathbf{P}_{\mathtt{CoOp}}^{\mathcal{I}}$. This approach allows learnable prompts to capture the relative semantic similarities among classes more effectively.

\keypoint{Randomized Similarity Alignment.} SAR minimizes the KL divergence between the corresponding rows of $\mathbf{P}^{\mathcal{I}}_{\mathtt{CoOp}}$ and $\mathbf{P}^{\mathcal{I}}_{\mathtt{hand}}$:

\begin{equation}
\mathcal{L}_{\text{SAR}} = \frac{1}{M} \sum_{i=1}^M \mathcal{D}_{\mathcal{KL}}(\mathbf{P}^{\mathcal{I}}_{\mathtt{CoOp},i} \parallel \mathbf{P}^{\mathcal{I}}_{\mathtt{hand},i}).
\end{equation}
where $\mathcal{I}$ is newly sampled at every single parameter update step during prompt tuning.
Finally, the training objective for SAR-applied prompt tuning is:

\begin{equation}
\mathcal{L}=\mathcal{L}_{\text{ce}}+\lambda \mathcal{L}_{\text{SAR}}
\end{equation}
where $\lambda$ is the hyperparameter that controls the strength of the regularization.