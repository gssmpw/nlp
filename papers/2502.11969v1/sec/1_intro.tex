\section{Introduction}
\label{sec:intro}

Recently, pre-trained foundation models that can be utilized for various downstream tasks have emerged across diverse fields. In the vision-language domain, CLIP \cite{radford2021clip} is recognized as one of the representative models. Trained on 400 million image-text pairs from the web, CLIP is able to capture rich semantic relationships between visual and textual information. This capability enables CLIP to achieve competitive zero-shot evaluation performance across a wide range of downstream tasks. One of the key findings in \cite{radford2021clip} is that using task-specific prompts can improve zero-shot performance by providing the model with additional context. For example, in EuroSAT dataset, which features satellite images depicting various types of land cover, using the prompt ``\texttt{a satellite photo of a}'' helps the model better understand the task, resulting in a notable enhancement in classification accuracy.

Instead of manually designing prompts, CoOp \cite{zhou2022learning} proposes a prompt tuning approach that learns task-specific prompts. In this method, learnable vectors in the word embedding space are trained using image-text pairs from target tasks and serve as prompts. This approach achieves significant performance improvements over using hand-crafted prompts, emphasizing the importance of prompt designing. However, learned prompts often fail to generalize to unseen classes that were not targeted during prompt tuning, resulting in substantial performance degradation. Extensive research has focused on learning generalizable prompts by exploring both architectural improvements \cite{zhou2022conditional, khattak2023maple, lee2023read, zhang2024dept} and regularization methods \cite{zhu2023prompt, yao2023kgcoop, cho2023distribution, ding2024lobg}. A widely adopted regularization method minimizes the distance between the text embeddings generated by learnable prompts and those generated by hand-crafted prompts during prompt tuning \cite{yao2023kgcoop, khattak2023promptsrc, roy2024coprompt, yao2024tcp, ding2024lobg}. This approach improves the generalization ability of learnable prompts by preserving the general knowledge captured by hand-crafted prompts. However, a significant limitation of this method lies in its focus on individual classes in isolation, without considering the relationships among classes. As a result, inter-class consistency is not explicitly accounted for during prompt tuning, which indicates that there is room for further improvement in generalization.

In this work, we first investigate how prompts learned from base classes fail to generalize to unseen classes in terms of semantic disruptions. We observe that when the text embeddings generated by learned prompts form incorrect semantic relationships with other classes, they act as low-quality classifiers, leading to poor generalization. In contrast, hand-crafted prompts capture meaningful semantic relationships among classes due to their strong generalization ability. Motivated by these findings, we propose \textbf{S}imilarity \textbf{A}lignment \textbf{R}egularization (\textbf{SAR}), a method for regularizing learnable prompts to preserve the semantic relationships captured by hand-crafted prompts. Specifically, we first obtain novel classes semantically aligned with the base classes by utilizing ChatGPT-4o. For both base and novel classes, SAR aligns the similarity relationships among text embeddings generated by learned prompts with those relationships from hand-crafted prompts. By preserving the meaningful semantic relationships among classes, SAR enables learnable prompts to effectively capture the semantics of unseen classes. Additionally, at each parameter update step, regularization is applied to the similarities computed on randomly sampled classes, instead of using all classes. This approach mitigates overfitting by introducing noise during prompt tuning and further improves the generalization of learned prompts to unseen classes.

As a regularizer, SAR can be applied to existing prompt tuning models without any architectural modifications. We validate the effectiveness of SAR on various baselines, including textual prompt tuning models: CoOp \cite{zhou2022learning}, KgCoOp \cite{yao2023kgcoop}, TCP \cite{yao2024tcp} and multi-modal prompt tuning models: MaPLe \cite{khattak2023maple}, CoPrompt \cite{roy2024coprompt}. Notably, in base-to-new generalization experiments, SAR consistently improves overall accuracy on new classes across 11 datasets for five baselines, while either preserving or enhancing the base accuracy. Our contributions are summarized as follows:
\begin{itemize}[itemsep=0.5em, topsep=0.5em]
    \item We experimentally analyze how learned prompts fail to generalize to unseen classes, focusing on semantic disruptions.
    \item We propose SAR, a method to guide learnable prompts to capture meaningful semantic relationships among classes. SAR utilizes novel classes generated by ChatGPT-4o as potential unseen classes during prompt tuning.
    \item We incorporate a random embedding sampling strategy into SAR, to mitigate overfitting.
    \item We demonstrate the effectiveness of SAR in improving generalization to unseen classes through extensive experiments across 11 datasets and five baselines.
\end{itemize}
