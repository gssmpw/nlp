\section{Experiments}
We evaluate the effectiveness of SAR in 1) base-to-new generalization and 2) domain generalization. To demonstrate its compatibility with existing prompt tuning models, SAR is applied to textual prompt tuning models: CoOp \cite{zhou2022learning}, KgCoOp \cite{yao2023kgcoop}, TCP \cite{yao2024tcp}, and multi-modal prompt tuning models: MaPLe \cite{khattak2023maple}, CoPrompt \cite{roy2024coprompt}.

\keypoint{Datasets.}
For base-to-new generalization, we evaluate our method on 11 datasets. ImageNet \cite{deng2009imagenet} and Caltech-101 \cite{fei2004learning} are used for generic object classification, while fine-grained classification is conducted on OxfordPets \cite{parkhi2012cats}, StanfordCars \cite{krause20133d}, Flowers102 \cite{nilsback2008automated}, Food-101 \cite{bossard2014food}, and FGVCAircraft \cite{maji2013fine}. For domain-specific classification tasks, we use EuroSAT \cite{helber2019eurosat} for satellite image classification, UCF101 \cite{soomro2012ucf101} for action recognition, DTD \cite{cimpoi2014describing} for texture classification, and SUN397 \cite{xiao2010sun} for scene recognition. For domain generalization, ImageNet serves as the source dataset, while ImageNet-V2 \cite{recht2019imagenet}, ImageNet-Sketch \cite{wang2019learning}, ImageNet-A \cite{gao2022generating}, and ImageNet-R \cite{hendrycks2021many} act as target domains.

\begin{table}[!t]
    \small \centering
    \renewcommand{\arraystretch}{0.9}
    \setlength{\tabcolsep}{8pt}
    \scalebox{0.95}[0.95]{
        \begin{tabular}{l cc | c }
        \toprule
        Method  & Base & New & H \\
        \midrule
        CoOp & 82.35 & 66.61 & 73.65 \\
        \hspace{0.0em}+ $\mathcal{L}_{\text{SAR}}$ & 82.46 & 71.91 & 76.82 \\
        \hspace{0.0em}+ Prompt Ensembling & \textbf{82.82} & 73.39 & 77.82 \\
        \rowcolor{gray!20}
        \hspace{0.0em}+ Random Embedding Sampling & 82.79 & \textbf{73.75} & \textbf{78.01} \\
        \bottomrule
        \end{tabular}
    }
    \caption{Evaluation of each component's contribution to SAR. Results are averaged across 11 datasets. H refers to harmonic mean.}
    \label{tab:component_ab}
\end{table}

\keypoint{Implementation details.}
All experiments are conducted with the CLIP ViT-B/16 model. For each dataset, 200 novel classes generated by ChatGPT-4o are used for SAR. The embedding sampling size $K$ is fixed at 64 across all experiments. In base-to-new generalization, for CoOp and KgCoOp, the number of training epochs is set to 100 by default to reduce training time. Except for this, we follow the same training settings, such as learning rate, epochs, and training schedules, as the baseline models. The hyperparameter $\lambda$ for SAR is adjusted based on the difficulty of optimizing its loss and the characteristics of the dataset. For TCP, $\lambda$ is set to 0.1 across all datasets. On EuroSAT, $\lambda$ is set to 0.5 in CoOp and 0.75 in both MaPLe and CoPrompt. On DTD and UCF101, $\lambda$ is set to 0.5 in all three models. On FGVCAircraft, $\lambda$ is set to 0.5 in CoOp, 0.75 in MaPLe, and 0.8 in CoPrompt. For all remaining datasets, $\lambda$ is set to 0.1 in all three models. The final performance is reported as the average over seeds 1, 2, and 3 to ensure a fair evaluation. We reproduce all baseline performances using the original code provided by the authors.

\subsection{Ablation Study}  
\keypoint{Stepwise Analysis of SAR's Effectiveness.}
To analyze the contribution of each component in SAR, we conduct a base-to-new generalization experiment in the 16-shot setting, using CoOp as the baseline. The results, averaged across 11 datasets, are presented in \Cref{tab:component_ab}. First, CoOp exhibits a significant gap between base and new accuracies, revealing its limited ability to generalize to unseen classes. By introducing $\mathcal{L}_{\text{SAR}}$, this limitation is effectively addressed, leading to a substantial improvement in new accuracy (+5.3\%) while also slightly enhancing base class accuracy (+0.11\%). Building on this, the integration of prompt ensembling further enhances both base and new accuracies by guiding the learnable prompts with more robust semantic relationships among classes. Lastly, incorporating random embedding sampling further boosts new accuracy with a negligible decrease in base accuracy. Overall, SAR improves CoOp's base accuracy from 82.35\% to 82.79\% (+0.44\%), new accuracy from 66.61\% to 73.75\% (+7.14\%), and the harmonic mean (H) from 73.65\% to 78.01\% (+4.36\%), demonstrating its effectiveness by improving all three metrics.

\begin{figure}[!t]
    \setlength{\abovecaptionskip}{1pt}
    \centering
    \includegraphics[width=1.0\linewidth]{fig/novelnum_ab.pdf}
    \caption{Effect of number of novel classes on performance in 16-shot setting. The results are averaged across 11 datasets.}
    \label{fig:novelnum_ab}
\end{figure}

\begin{figure}[!t]
    \centering
    \includegraphics[width=1.0\linewidth]{fig/weight_ab.pdf}
    \caption{\textbf{Left}: Effect of regularization weight $\lambda$ on performance in 4-shot setting. \textbf{Right}: Trend of SAR loss as $\lambda$ increases. The results are averaged across 11 datasets.}
    \label{fig:weight_ab} 
\end{figure}

\keypoint{Impact of Number of Novel Classes on SAR.}
We evaluate the impact of the number of novel classes on the effectiveness of SAR. To this end, we train prompts by applying SAR under two different numbers of novel classes: one using 50 novel classes and the other using 200 novel classes. In the 50-class setup, the classes are randomly selected from the set of 200 novel classes, and the embedding sampling size is fixed at 16. As the results in \Cref{fig:novelnum_ab} show, using a larger number of novel classes leads to greater performance improvements. With more novel classes, richer similarity information among semantically diverse classes can be obtained, enabling a more refined and accurate capture of the semantics of unseen classes. Notably, even when using only 50 novel classes for SAR, significant performance improvements over the baseline are observed.

\keypoint{Impact of Regularization Weight $\lambda$ on SAR.}
We evaluate the impact of the regularization weight $\lambda$ on performance. The experimental results under 4-shot setting are presented in \Cref{fig:weight_ab}. The left plot in the figure shows the variations in base accuracy, new accuracy, and their harmonic mean (H) as $\lambda$ changes. Increasing $\lambda$ up to 1.0 leads to a significant improvement in new accuracy, showing a clear association between SAR's mechanism and the enhancement of generalization performance to new classes. However, when $\lambda$ becomes excessively large (\eg 1.5), all accuracies slightly decline due to the effects of overly strong regularization. The right plot in \Cref{fig:weight_ab} depicts the average SAR loss at the final epoch of the model, averaged across all datasets. As $\lambda$ increases, SAR loss decreases, which corresponds to the improvement in new accuracy observed in the left plot.

\begin{table}[!t]
    \small \centering
    \renewcommand{\arraystretch}{1.0}
    \setlength{\tabcolsep}{4pt}
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{lcccc | c}
    \toprule
        Method & {Params.} & {Train time} & {Infer time} & {Memory} & {H} \\ 
        \midrule
        CoOp & 2048 & 39m 47s & 5.57ms & 11.36GiB & 73.65 \\
        \rowcolor{gray!20}
        \textbf{+SAR (50)} & \textbf{+0} & \textbf{+8m 7s} & \textbf{+0ms} & \textbf{+0.86GiB} & \textbf{77.27} \textcolor{blue}{(+3.62\%)}\\
        \rowcolor{gray!20}
        \textbf{+SAR (200)} & \textbf{+0} & \textbf{+25m 37s} & \textbf{+0ms} & \textbf{+3.82GiB} & \textbf{78.01} \textcolor{blue}{(+4.36\%)}\\
        \bottomrule
            \end{tabular}
        } 
    \caption{Resource costs for introducing SAR on ImageNet using a single NVIDIA A100 GPU. The number in $(\cdot)$ is the number of novel classes used for SAR. H is averaged across 11 datasets.}
    \label{tab:incurred_resource}
\end{table}

\keypoint{Resource Costs for Introducing SAR.}
We report the additional resource requirements incurred by SAR on ImageNet in \Cref{tab:incurred_resource}. Since SAR does not modify the model architecture, it does not introduce any extra trainable parameters. Moreover, as SAR operates during training, it has no impact on inference time. However, implementing SAR requires computing text embeddings not only for the base classes but also for the novel classes. This additional computation in the text encoder, along with the computation of similarity among classes, increases memory usage and training time. Furthermore, additional training time increases with the number of update steps, as text embeddings are computed at every update. Among the 11 datasets, ImageNet has the largest training set, resulting in the highest number of update steps. Consequently, the additional training time is notably smaller for the other 10 datasets. The number of novel classes for SAR can be chosen by considering the tradeoff between resource cost and performance, as the additional memory usage and training time incurred by SAR grow with the number of novel classes.

\begin{table*}[htbp]
\setlength{\abovecaptionskip}{0.1cm}
\setlength{\belowcaptionskip}{-0.1cm}
\centering
\renewcommand{\arraystretch}{1.1}
\tabcolsep 0.12in
\footnotesize
\begin{tabular}{l|ccc|ccc|ccc|ccc}
  \hline
  \multicolumn{1}{l|}{\multirow{2}{*}{\makecell[c]{Method}}} & \multicolumn{3}{c|}{\textbf{Avg over 11 datasets}} & \multicolumn{3}{c|}{ImageNet} & \multicolumn{3}{c|}{Caltech101} & \multicolumn{3}{c}{OxfordPets} \\
  \cline{2-13}
  & Base & New & H & Base & New & H & Base & New & H & Base & New & H \\
  \hline
  CoOp \cite{zhou2022learning} & 82.35 & 66.61 & 73.65 & 76.26 & 67.56 & 71.65 & 98.09 & 92.21 & 95.06 & 93.75 & 95.70 & 94.71 \\
  \cellcolor{gray!20}{\textbf{+SAR}} &\cellcolor{gray!20}{\textbf{\textcolor{blue}{82.79}}} &\cellcolor{gray!20}{\textbf{\textcolor{blue}{73.75}}}  &\cellcolor{gray!20}{\textbf{\textcolor{blue}{78.01}}} & \textbf{76.61} & \textbf{69.95} & \textbf{73.13} & \textbf{98.09} & \textbf{94.91} & \textbf{96.47} & \textbf{94.45} & \textbf{96.25} & \textbf{95.34} \\
  \hline
  KgCoOp \cite{yao2023kgcoop} & 81.67 & 73.15 & 77.18 & 75.65 & 69.65 & 72.53 & 97.85 & 94.36 & 96.07 & 95.09 & 97.50 & 96.28 \\
  \cellcolor{gray!20}{\textbf{+SAR}} & \cellcolor{gray!20}{81.40} &\cellcolor{gray!20}{\textbf{\textcolor{blue}{73.98}}}  &\cellcolor{gray!20}{\textbf{\textcolor{blue}{77.51}}} & 75.63 & \textbf{69.88} & \textbf{72.64} & 97.74 & \textbf{94.47} & \textbf{96.08} & 95.07 & 96.70 & 95.88 \\
  \hline
  TCP \cite{yao2024tcp} & 83.89 & 75.21 & 79.31 & 77.10 & 69.66 & 73.19 & 98.13 & 94.80 & 96.44 & 94.51 & 97.07 & 95.77 \\
  \cellcolor{gray!20}{\textbf{+SAR}} & \cellcolor{gray!20}{83.78} &\cellcolor{gray!20}{\textbf{\textcolor{blue}{75.45}}}  &\cellcolor{gray!20}{\textbf{\textcolor{blue}{79.40}}} & 77.04 & \textbf{69.81} & \textbf{73.25} & \textbf{98.15} & 94.76 & 96.43 & 94.40 & 96.35 & 95.37 \\
  \hline
  MaPLe \cite{khattak2023maple} & 81.84 & 74.56 & 78.03 & 76.70 & 70.56 & 73.50 & 97.68 & 94.87 & 96.25 & 95.50 & 98.02 & 96.74 \\
  \cellcolor{gray!20}{\textbf{+SAR}} &\cellcolor{gray!20}{\textbf{\textcolor{blue}{82.25}}} &\cellcolor{gray!20}{\textbf{\textcolor{blue}{76.06}}}  &\cellcolor{gray!20}{\textbf{\textcolor{blue}{79.03}}} & \textbf{76.82} & \textbf{70.83} & \textbf{73.70} & \textbf{97.85} & 94.25 & 96.02 & 95.41 & 97.13 & 96.26 \\
  \hline
  CoPrompt \cite{roy2024coprompt} & 82.82 & 74.60 & 78.50 & 76.66 & 71.27 & 73.87 & 98.65 & 95.09 & 96.84 & 95.14 & 96.20 & 95.67 \\
  \cellcolor{gray!20}{\textbf{+SAR}} & \cellcolor{gray!20}{82.72} &\cellcolor{gray!20}{\textbf{\textcolor{blue}{76.52}}}  &\cellcolor{gray!20}{\textbf{\textcolor{blue}{79.50}}} & 76.55 & 71.18 & 73.77 & \textbf{98.69} & 94.87 & 96.74 & 95.09 & \textbf{96.44} & \textbf{95.76} \\
  \hline
    \multicolumn{1}{l|}{\multirow{2}{*}{\makecell[c]{{Method}}}}  & \multicolumn{3}{c|}{\cellcolor{gray!0}{StanfordCars}}  & \multicolumn{3}{c|}{\cellcolor{gray!0}{Flowers102}} & \multicolumn{3}{c|}{\cellcolor{gray!0}{Food101}} & \multicolumn{3}{c}{\cellcolor{gray!0}{FGVCAircraft}}    \\
    \cline{2-13} 
    &  \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{New} & \multicolumn{1}{c|}{H} &  \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{New} & \multicolumn{1}{c|}{H}  &  \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{New} & \multicolumn{1}{c|}{H}  &  \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{New} & \multicolumn{1}{c}{H}  \\
    \hline
    {CoOp} \cite{zhou2022learning} & 76.88 & 66.01 & 71.03 & 97.63 & 66.17 & 78.88 & 88.67 & 86.13 & 87.38 & 38.74 & 27.07 & 31.87 \\
    \textbf{+SAR} & 76.69 & \textbf{72.18} & \textbf{74.37} & 97.44 & \textbf{75.06} & \textbf{84.80} & \textbf{90.14} & \textbf{91.01} & \textbf{90.57} & \textbf{39.16} & \textbf{33.37} & \textbf{36.03} \\
    \hline
    {KgCoOp} \cite{yao2023kgcoop} & 73.70 & 74.04 & 73.87 & 95.66 & 73.07 & 82.85 & 90.62 & 91.48 & 91.05 & 37.48 & 32.17 & 34.62 \\
    \textbf{+SAR} & 72.69 & \textbf{75.46} & \textbf{74.05} & 95.38 & \textbf{75.32} & \textbf{84.17} & 90.59 & \textbf{91.86} & \textbf{91.22} & 36.69 & \textbf{33.51} & \textbf{35.03} \\
    \hline
    {TCP} \cite{yao2024tcp} & 79.94 & 74.03 & 76.87 & 97.88 & 74.85 & 84.83 & 90.69 & 91.37 & 91.03 & 42.02 & 34.37 & 37.81 \\
    \textbf{+SAR} & 79.59 & \textbf{74.49} & \textbf{76.96} & 97.85 & \textbf{74.97} & \textbf{84.90} & \textbf{90.72} & \textbf{91.63} & \textbf{91.17} & 41.48 & \textbf{34.97} & \textbf{37.95} \\
    \hline
    {MaPLe} \cite{khattak2023maple} & 72.51 & 74.30 & 73.39 & 96.20 & 75.32 & 84.49 & 90.67 & 92.04 & 91.35 & 35.15 & 32.41 & 33.72 \\
    \textbf{+SAR} & \textbf{72.65} & \textbf{74.63} & \textbf{73.63} & 95.66 & 74.78 & 83.94 & \textbf{90.70} & \textbf{92.05} & \textbf{91.37} & \textbf{37.15} & \textbf{37.35} & \textbf{37.25} \\
    \hline
    {CoPrompt} \cite{roy2024coprompt} & 73.16 & 70.49 & 71.80 & 96.90 & 75.13 & 84.64 & 90.17 & 91.75 & 90.95 & 35.91 & 30.31 & 32.87 \\
    \textbf{+SAR} & 72.80 & \textbf{70.98} & \textbf{71.88} & 96.77 & \textbf{75.67} & \textbf{84.93} & \textbf{90.39} & 91.73 & \textbf{91.06} & \textbf{36.67} & \textbf{37.07} & \textbf{36.87} \\
\hline
     \multicolumn{1}{l|}{\multirow{2}{*}{\makecell[c]{{Method}}}}  & \multicolumn{3}{c|}{\cellcolor{gray!0}{SUN397}}  & \multicolumn{3}{c|}{\cellcolor{gray!0}{DTD}} & \multicolumn{3}{c|}{\cellcolor{gray!0}{EuroSAT}}  & \multicolumn{3}{c}{\cellcolor{gray!0}{UCF101}}  \\
    \cline{2-13} 
    &  \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{New} & \multicolumn{1}{c|}{H} &  \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{New} & \multicolumn{1}{c|}{H}  &  \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{New} & \multicolumn{1}{c|}{H}  &  \multicolumn{1}{c}{Base} & \multicolumn{1}{c}{New} & \multicolumn{1}{c}{H}   \\
     \hline
{CoOp} \cite{zhou2022learning} &80.89 &67.93 &73.85 &78.74 &45.65 &57.79 &91.23 &55.25 &68.82 &84.97 &63.06 &72.39\\
\textbf{+SAR} &\textbf{81.63} &\textbf{73.88} &\textbf{77.56} &\textbf{80.75} &\textbf{59.38} &\textbf{68.44} &90.48 &\textbf{69.01} &\textbf{78.30} &\textbf{85.28} &\textbf{76.22} &\textbf{80.50}\\
\hline
{KgCoOp} \cite{yao2023kgcoop} &80.67 &75.93 &78.23 &80.05 &54.31 &64.71 &87.92 &67.95 &76.66 &83.68 &74.20 &78.66\\
\textbf{+SAR} &80.48 &\textbf{77.27} &\textbf{78.84} &79.63 &\textbf{56.28} &\textbf{65.95} &87.66 &66.61 &75.70 &\textbf{83.80} &\textbf{76.44} &\textbf{79.95}\\
\hline
{TCP} \cite{yao2024tcp} &82.64 &78.12 &80.32 &82.68 &57.04 &67.51 &89.95 &75.03 &81.82 &87.21 &81.02 &84.00\\
\textbf{+SAR} &82.52 &\textbf{78.26} &\textbf{80.33} &82.56 &\textbf{58.82} &\textbf{68.70} &\textbf{89.96} &74.38 &81.43 &\textbf{87.32} &\textbf{81.48} &\textbf{84.30}\\
\hline
{MaPLe} \cite{khattak2023maple}&80.77 &77.99 &79.36 &80.63 &58.89 &68.07 &90.85 &67.95 &77.75 &83.59 &77.83 &80.61\\
\textbf{+SAR} &\textbf{81.01} &\textbf{79.00} &\textbf{79.99} &\textbf{80.75} &\textbf{63.12} &\textbf{70.85} &\textbf{92.67} &\textbf{73.52} &\textbf{81.99} &\textbf{84.06} &\textbf{79.97} &\textbf{81.96}\\
\hline
{CoPrompt} \cite{roy2024coprompt} &82.23 &79.46 &80.82 &82.72 &62.48 &71.19 &93.29 &69.57 &79.70 &86.18 &78.87 &82.36\\
\textbf{+SAR} &82.08 &\textbf{79.70} &\textbf{80.87} &82.64 &\textbf{64.53} &\textbf{72.47} &92.16 &\textbf{79.53} &\textbf{85.38} &86.12 &\textbf{79.99} &\textbf{82.94}\\
\hline
    \end{tabular}
    \vspace{+0.0em}
    \caption{Performance comparison of five baselines in base-to-new generalization w/ or w/o applying SAR on 11 datasets.}
    \label{tab:b2n}
\end{table*}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.92 \linewidth]{fig/wordsource_ab.pdf}
    \caption{Performance gains of SAR over the baseline across different word sources. `Oracle' refers to the use of new classes in the dataset as novel classes for SAR. The results are averaged across 11 datasets.}
    \label{fig:wordsource_ab}
\end{figure*}

\subsection{Base-to-New Generalization}
In the Base-to-New generalization task, we evaluate the performance of models with and without SAR in 16-shot setting across 11 datasets. The classes in each dataset are divided into two groups, where prompts trained on one group (base classes) are used to evaluate performance on the other group (new classes). As summarized in \Cref{tab:b2n}, SAR consistently improves the new class accuracy and the harmonic mean (H) across all baselines. For CoOp and MaPLe, SAR also delivers significant improvements in base class accuracy, while showing no critical base-new accuracy trade-offs for other baselines. Notably, SAR yields the largest improvements for CoOp, while also bringing meaningful improvements for the baselines equipped with regularization techniques designed to improve generalization. These results suggest that SAR effectively addresses gaps that cannot be resolved by existing regularization methods of the baselines. SAR brings marginal improvements over TCP, which can be attributed to the fact that TCP, by generating class-aware prompts, already captures the semantics of new classes effectively (as shown in \Cref{fig:motivation}), thereby reducing the necessity for SAR's contribution. Similarly, the limited improvements by SAR on the Caltech101 and OxfordPets datasets are likely because all baselines already generalize well on these datasets. This claim is supported by the observation that all baselines exhibit fairly high new accuracy on these datasets, as shown in \Cref{tab:b2n}, leaving little room for SAR to provide further improvement.

\subsection{Effectiveness with Alternative Word Sources}
We investigate whether SAR remains effective when using novel classes extracted from sources other than LLMs. To this end, we train SAR with novel classes from (1) 200 randomly sampled nouns from WordNet \cite{miller1995wordnet}, a large lexical database, and (2) new class names from the dataset. The base-to-new generalization results for CoOp and CoPrompt are presented in \Cref{fig:wordsource_ab}. A key observation is that new accuracy improves significantly even when randomly sampled words are used as novel classes. This suggests that SAR is robust to the choice of novel classes and consistently enhances generalization to unseen classes. Notably, using words generated by ChatGPT-4o as novel classes leads to even greater performance improvements. This can be attributed to the fact that these words are more semantically aligned with the new classes in the dataset than randomly sampled words, making them more effective at capturing the semantics of new classes (Examples of generated words are listed in \underline{\textbf{Supp. Material C}}). However, using the actual new class names from the dataset as novel classes (SAR w/ `Oracle') does not yield the highest performance improvements. This is primarily due to the small number of them (on average, less than 100), which reduces the semantic diversity available for SAR and ultimately makes it less effective to capture the fine-grained semantics of them.

\subsection{Effectiveness in Few Shot Setting}
To validate the effectiveness of SAR in a few-shot setting, we conduct base-to-new generalization experiments under 4-shot setting for CoOp, TCP, and CoPrompt. In the case of CoOp, the models show a stronger tendency to increase SAR loss during prompt tuning compared to the 16-shot setting. This may be due to the model attempting to capture spurious correlations in the limited training data, leading to overfitting. To address this issue, we set the regularization weight to 1.0 for CoOp across all datasets. For TCP and CoPrompt, the same regularization weights as those used in the 16-shot setting are applied to each dataset. The performance averaged across 11 datasets is summarized in \Cref{tab:4shot_b2n}, demonstrating that SAR remains consistently effective even in the few-shot setting.

\begin{table}[!t]
    \small \centering
    \renewcommand{\arraystretch}{0.9}
    \setlength{\tabcolsep}{8pt}
    \scalebox{0.8}[0.8]{
    \begin{tabular}{l cc | c }
    \toprule
    Method  & Base & New & H \\
    \midrule
    CoOp & 78.11 & 66.99 & 72.12 \\
    \cellcolor{gray!20}{\textbf{+SAR}} 
    & \cellcolor{gray!20}\textbf{78.73} \textcolor{blue}{(+0.62\%)} 
    & \cellcolor{gray!20}\textbf{75.00} \textcolor{blue}{(+8.01\%)} 
    & \cellcolor{gray!20}\textbf{76.82} \textcolor{blue}{(+4.70\%)} \\
    \midrule
    TCP & \textbf{79.98} & 74.59 & 77.19 \\
    \cellcolor{gray!20}{\textbf{+SAR}} 
    & \cellcolor{gray!20}79.93 \textcolor{red}{(-0.05\%)} 
    & \cellcolor{gray!20}\textbf{75.04} \textcolor{blue}{(+0.45\%)} 
    & \cellcolor{gray!20}\textbf{77.41} \textcolor{blue}{(+0.22\%)} \\
    \midrule
    CoPrompt & 78.44 & 75.57 & 76.98 \\
    \cellcolor{gray!20}{\textbf{+SAR}} 
    & \cellcolor{gray!20}\textbf{78.49} \textcolor{blue}{(+0.05\%)} 
    & \cellcolor{gray!20}\textbf{76.59} \textcolor{blue}{(+1.02\%)} 
    & \cellcolor{gray!20}\textbf{77.53} \textcolor{blue}{(+0.55\%)} \\
    \bottomrule
    \end{tabular}
    }
    \vspace{+0.0em}
    \caption{Performance comparison of three baselines in the 4-shot setting w/ and w/o applying SAR. The results are averaged across 11 datasets.}
    \label{tab:4shot_b2n}
    \vspace{+0.0em}
\end{table}

\begin{table}[!t]
    \small \centering
    \renewcommand{\arraystretch}{1.1}
 \setlength{\tabcolsep}{8pt}
    \scalebox{0.75}[0.75]{
    \begin{tabular}{l cccccc}
    \toprule
    & \textbf{Source} & \multicolumn{5}{c}{\textbf{Target}} \\ \cmidrule(lr){2-2} \cmidrule(lr){3-7}
     & ImageNet & Avg. & -S & -R & -A  & -V2 \\
    \midrule
        CoOp \cite{zhou2022learning} &  71.49 & {59.36} & 47.85  & 75.57  & 49.71  & {64.32} \\
    \cellcolor{gray!20}{\textbf{+SAR}} & \cellcolor{gray!20}{\textbf{71.60}} & \cellcolor{gray!20}{\textbf{60.02}} & \textbf{48.55} & \textbf{76.72} & \textbf{50.38} & \textbf{64.42}  \\
    \midrule
        KgCoOp \cite{yao2023kgcoop} & \textbf{70.56}  & 59.74 & 48.54  & 76.58 & \textbf{50.27} & \textbf{63.57}  \\ 
        \cellcolor{gray!20}{\textbf{+SAR}} & \cellcolor{gray!20}{70.44} & \cellcolor{gray!20}\textbf{59.75} & \textbf{48.67} & \textbf{76.66} & 50.19 & 63.46  \\
    \midrule
        TCP \cite{yao2024tcp} & \textbf{72.53} & 59.61 & 48.11  & 76.10 & 49.43 & {64.78}  \\ 
        \cellcolor{gray!20}{\textbf{+SAR}} & \cellcolor{gray!20}{\textbf{72.53}} & \cellcolor{gray!20}{\textbf{59.74}} & \textbf{48.85} & \textbf{76.25} & \textbf{49.59} & \textbf{64.85}  \\
    \midrule
        MaPLe \cite{khattak2023maple} & 70.40 & 60.15 & 49.10  & 77.05 & 50.52 & {63.94}  \\
        \cellcolor{gray!20}{\textbf{+SAR}} & \cellcolor{gray!20}{\textbf{70.56}} & \cellcolor{gray!20}{\textbf{60.20}} & 49.02 & 77.03 & \textbf{50.67} & \textbf{64.07}  \\
    \midrule
        CoPrompt \cite{roy2024coprompt} & 71.00 & 60.27 & 50.12  & 77.82 & 48.37 & {64.77}  \\
        \cellcolor{gray!20}{\textbf{+SAR}} & \cellcolor{gray!20}{\textbf{71.01}} & \cellcolor{gray!20}\textbf{60.28} & 50.09 & 77.76 & \textbf{48.56} & 64.71  \\
    \bottomrule
    \end{tabular}}\vspace{+0.0em}
        \caption{Performance comparisons of five baselines in domain generalization w/ or w/o applying SAR.} 
    \label{tab:domain_gen}
    \vspace{-0em}
\end{table}

\subsection{Domain Generalization}
Domain generalization evaluates how well a model can generalize to domains with data distributions that differ from its training domain. Following convention, we use ImageNet as the source domain and evaluate the performance of the trained model on ImageNet-Sketch, ImageNet-A, ImageNet-R, and ImageNet-V2. The results, summarized in \Cref{tab:domain_gen}, show that SAR consistently improves the average target accuracy across the baselines.

