\section{Conclusion}
\label{sec:conclusion}

In this paper, We conduct the first comprehensive study on event-aided semantic scene completion. 
We present \emph{DSEC-SSC}, the first real-world benchmark for semantic scene completion incorporating event modality, primarily designed for visual perception in more challenging scenarios. 
Meanwhile, to enrich datasets,
%
we propose a deployable, general labeling pipeline that provides precise dynamic object processing. 
To enhance the robustness of visual perception, we introduce \emph{EvSSC}, including an \emph{Event-aided Lifting Module} for SSC. 
Extensive experiments demonstrate that EvSSC achieves significant performance gains on multiple benchmarks.
%

\noindent\textbf{Limitations and future work.} Although we have designed a highly deployable pipeline for semantic scene completion dataset construction and an efficient event-image fusion module, there are several ways to achieve further improvement:
\begin{itemize}
    \item \textbf{Robust LiDAR mapping framework:} In our future dataset construction, we will implement multi-sensor fusion by integrating GPS, IMU, and LiDAR SLAM to achieve enhanced trajectory and pose estimation accuracy, thereby establishing more reliable maps as the foundation for voxel generation.
    \item \textbf{Intelligent annotation automation:} To advance data annotation automation, we plan to develop AI-driven dynamic scene processors with uncertainty quantification, creating a human-in-the-loop framework to optimize annotation efficiency and reliability.
    %
    \item \textbf{Temporal-aware event representation:} Rasterized events lose a small amount of time resolution. Our benchmark leaves space to further explore event representations and fusion modules that combine asynchronous events for better integration.
\end{itemize}