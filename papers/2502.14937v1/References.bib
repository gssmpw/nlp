@article{a.ameenHighlyEfficientAir2021,
  title = {Towards a Highly Efficient Air Purifier Using Annular Photonic Crystals in {{UV}} Regimes},
  author = {A.~Ameen, Ayman and ElSayed, H. and H.~Aly, Arafa},
  date = {2021},
  journaltitle = {RSC Advances},
  volume = {11},
  number = {25},
  pages = {14915--14921},
  publisher = {Royal Society of Chemistry},
  doi = {10.1039/D1RA00991E},
  url = {https://pubs.rsc.org/en/content/articlelanding/2021/ra/d1ra00991e},
  urldate = {2024-01-15},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\Towards_a_highly_efficient_air_purifier_using_annular_photonic_crystals_in_UV_A._Ameen_et_al_2021.pdf}
}

@article{abadlaSensitivityEnhancementAnnular2020,
  title = {Sensitivity Enhancement of Annular One Dimensional Photonic Crystals Temperature Sensors with Nematic Liquid Crystals},
  author = {Abadla, Mazen M and Elsayed, Hussein A and Mehaney, Ahmed},
  date = {2020-07-16},
  journaltitle = {Phys. Scr.},
  volume = {95},
  number = {8},
  pages = {085508},
  issn = {1402-4896},
  doi = {10.1088/1402-4896/aba2b0},
  url = {https://iopscience.iop.org/article/10.1088/1402-4896/aba2b0},
  urldate = {2023-11-06},
  abstract = {A novel design of one dimensional annular photonic crystals with a low birefringence nematic liquid crystal as a defect layer is introduced. The output field of the sensor structure is plotted after different optimization steps on all constituents such as thickness and core radius of the starting medium. The performance of the sensor was studied using different quality parameters such as sensitivity, figure of merit, detection limit and resolution. The designed sensor exhibits a sensitivity of about 0.224 nm °C−1 due to the presence of the liquid crystal material. The proposed sensor design can be used as a narrowband optical filter in the visible region around two wavelengths: 600 nm and 700 nm. As an optoelectronic device, this structure can serve as a temperature sensor with higher sensitivity than the conventional one dimensional photonic crystal structures and photonic crystals fibers.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Sensitivity_enhancement_of_annular_one_dimensional_photonic_crystals_Abadla_et_al_2020.pdf}
}

@article{abadlaSensitivityEnhancementAnnular2020a,
  title = {Sensitivity Enhancement of Annular One Dimensional Photonic Crystals Temperature Sensors with Nematic Liquid Crystals},
  author = {Abadla, Mazen M and Elsayed, Hussein A and Mehaney, Ahmed},
  date = {2020-07-16},
  journaltitle = {Phys. Scr.},
  volume = {95},
  number = {8},
  pages = {085508},
  issn = {1402-4896},
  doi = {10.1088/1402-4896/aba2b0},
  url = {https://iopscience.iop.org/article/10.1088/1402-4896/aba2b0},
  urldate = {2023-11-06},
  abstract = {A novel design of one dimensional annular photonic crystals with a low birefringence nematic liquid crystal as a defect layer is introduced. The output field of the sensor structure is plotted after different optimization steps on all constituents such as thickness and core radius of the starting medium. The performance of the sensor was studied using different quality parameters such as sensitivity, figure of merit, detection limit and resolution. The designed sensor exhibits a sensitivity of about 0.224 nm °C−1 due to the presence of the liquid crystal material. The proposed sensor design can be used as a narrowband optical filter in the visible region around two wavelengths: 600 nm and 700 nm. As an optoelectronic device, this structure can serve as a temperature sensor with higher sensitivity than the conventional one dimensional photonic crystal structures and photonic crystals fibers.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Sensitivity_enhancement_of_annular_one_dimensional_photonic_crystals_Abadla_et_al_22.pdf}
}

@article{abadlaThermoopticalPropertiesBinary2020,
  title = {Thermo-Optical Properties of Binary One Dimensional Annular Photonic Crystal Including Temperature Dependent Constituents},
  author = {Abadla, Mazen M. and Elsayed, Hussein A. and Mehaney, Ahmed},
  date = {2020-05},
  journaltitle = {Physica E: Low-dimensional Systems and Nanostructures},
  volume = {119},
  pages = {114020},
  issn = {13869477},
  doi = {10.1016/j.physe.2020.114020},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1386947719316364},
  urldate = {2023-11-06},
  abstract = {In this research article, we present theoretical and numerical investigations concerning the effects of temperature on the transmittance properties of one dimensional annular photonic crystals. The theoretical basis of our study adopts the modified transfer matrix method applied to optical fiber waveguides. The numerical results showed many features that could be of interest. In this regard, we investigate this design to enhance the values of sensitivity based on its geometry. Our design exhibits a remarkable response to temperature changes with a � sensitivity of about 0.033 nm/ C which is considered significantly high. Also, it is found that the upper edge of the photonic band gap increases considerably with temperature changes, while the lower edge is almost un­ changed. The effects of the core radius and number of periods on the transmittance of our annular photonic crystals design have been also investigated. It is found that an appropriate choice for the core would give flexibility of fabrication and stability of transmission output. In addition, this study reveals that the phase shift of the reflected cylindrical waves within the core is strongly dependent on temperature. We believe our structure is potentially promising in designing and fabrication of novel high-performance temperature sensors and integrated waveguide devices such as optical switches and filters.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Thermo-optical_properties_of_binary_one_dimensional_annular_photonic_crystal_Abadla_et_al_2020.pdf}
}

@article{acikgozTHESISSUBMITTEDGRADUATE,
  title = {A {{THESIS SUBMITTED TO THE GRADUATE SCHOOL OF NATURAL AND APPLIED SCIENCES OF MIDDLE EAST TECHNICAL UNIVERSITY}}},
  author = {Açikgöz, Berk Can},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\A_THESIS_SUBMITTED_TO_THE_GRADUATE_SCHOOL_OF_NATURAL_AND_APPLIED_SCIENCES_OF_Acikgoz_.pdf}
}

@article{adibniaDeepLearningMethod2024,
  title = {A Deep Learning Method for Empirical Spectral Prediction and Inverse Design of All-Optical Nonlinear Plasmonic Ring Resonator Switches},
  author = {Adibnia, Ehsan and Mansouri-Birjandi, Mohammad Ali and Ghadrdan, Majid and Jafari, Pouria},
  date = {2024-03-09},
  journaltitle = {Sci Rep},
  volume = {14},
  number = {1},
  pages = {5787},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-024-56522-3},
  url = {https://www.nature.com/articles/s41598-024-56522-3},
  urldate = {2024-05-31},
  abstract = {All-optical plasmonic switches (AOPSs) utilizing surface plasmon polaritons are well-suited for integration into photonic integrated circuits (PICs) and play a crucial role in advancing all-optical signal processing. The current AOPS design methods still rely on trial-and-error or empirical approaches. In contrast, recent deep learning (DL) advances have proven highly effective as computational tools, offering an alternative means to accelerate nanophotonics simulations. This paper proposes an innovative approach utilizing DL for spectrum prediction and inverse design of AOPS. The switches employ circular nonlinear plasmonic ring resonators (NPRRs) composed of interconnected metal–insulator–metal waveguides with a ring resonator. The NPRR switching performance is shown using the nonlinear Kerr effect. The forward model presented in this study demonstrates superior computational efficiency when compared to the finite-difference time-domain method. The model analyzes various structural parameters to predict transmission spectra with a distinctive dip. Inverse modeling enables the prediction of design parameters for desired transmission spectra. This model provides a rapid estimation of design parameters, offering a clear advantage over time-intensive conventional optimization approaches. The loss of prediction for both the forward and inverse models, when compared to simulations, is exceedingly low and on the order of 10−4. The results confirm the suitability of employing DL for forward and inverse design of AOPSs in PICs.},
  langid = {english},
  keywords = {Applied optics,Computer science},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\Parameters\A_deep_learning_method_for_Adibnia_et_al_2024.pdf}
}

@misc{adlerEIDORS3102019,
  title = {{{EIDORS3}}.10},
  author = {{adler}},
  date = {2019},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\EIDORS\EIDORS3_adler_2019.pdf}
}

@article{adlerElectricalImpedanceTomography1996,
  title = {Electrical Impedance Tomography: Regularized Imaging and Contrast Detection},
  shorttitle = {Electrical Impedance Tomography},
  author = {Adler, A. and Guardo, R.},
  date = {1996-04},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {15},
  number = {2},
  pages = {170--179},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/42.491418},
  url = {https://ieeexplore.ieee.org/document/491418/},
  urldate = {2024-07-08},
  abstract = {Dynamic electrical impedance tomography (EIT) images changes in the conductivity distribution of a medium from low frequency electrical measurements made at electrodes on the medium surface. Reconstruction of the conductivity distribution is an under-determined and ill-posed problem, typically requiring either simplifying assumptions or regularization based on a p \textasciitilde{} i o k\textasciitilde niowledge. This paper presents a maximum a posteriori (MAP) approach to linearized image reconstruction using knowledge of the noise variance of the measurements and the covariance of the conductivity distribution. This approach has the advantage of an intuitive interpretation of the algorithm parameters as well as fast (near real time) image reconstruction. In order to compare this approach to existing algorithms, we develop figures of merit to measure the reconstructed image resolution, the noise amplification of the image reconstruction, and the fidelity of positioning in the image. Finally, we develop a communications systems approach to calculate the probability of detection of a conductivity contrast in the reconstructed image as a function of the measurement noise and the reconstruction algorithm used.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Electrical_impedance_tomography_Adler_Guardo_1996.pdf}
}

@article{adlerGREITUnifiedApproach2009,
  title = {{{GREIT}}: A Unified Approach to {{2D}} Linear {{EIT}} Reconstruction of Lung Images},
  shorttitle = {{{GREIT}}},
  author = {Adler, Andy and Arnold, John H and Bayford, Richard and Borsic, Andrea and Brown, Brian and Dixon, Paul and Faes, Theo J C and Frerichs, Inéz and Gagnon, Hervé and Gärber, Yvo and Grychtol, Bartłomiej and Hahn, Günter and Lionheart, William R B and Malik, Anjum and Patterson, Robert P and Stocks, Janet and Tizzard, Andrew and Weiler, Norbert and Wolf, Gerhard K},
  date = {2009-06-01},
  journaltitle = {Physiol. Meas.},
  volume = {30},
  number = {6},
  pages = {S35-S55},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/0967-3334/30/6/S03},
  url = {https://iopscience.iop.org/article/10.1088/0967-3334/30/6/S03},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\GREIT\GREIT_Adler_et_al_2009.pdf}
}

@article{adlerGREITUnifiedApproach2009a,
  title = {{{GREIT}}: A Unified Approach to {{2D}} Linear {{EIT}} Reconstruction of Lung Images},
  shorttitle = {{{GREIT}}},
  author = {Adler, Andy and Arnold, John H and Bayford, Richard and Borsic, Andrea and Brown, Brian and Dixon, Paul and Faes, Theo J C and Frerichs, Inéz and Gagnon, Hervé and Gärber, Yvo and Grychtol, Bartłomiej and Hahn, Günter and Lionheart, William R B and Malik, Anjum and Patterson, Robert P and Stocks, Janet and Tizzard, Andrew and Weiler, Norbert and Wolf, Gerhard K},
  date = {2009-06-01},
  journaltitle = {Physiol. Meas.},
  volume = {30},
  number = {6},
  pages = {S35-S55},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/0967-3334/30/6/S03},
  url = {https://iopscience.iop.org/article/10.1088/0967-3334/30/6/S03},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\EIDORS\GREIT_Adler_et_al_2009.pdf}
}

@article{adlerUsesAbusesEIDORS2006,
  title = {Uses and Abuses of {{EIDORS}}: An Extensible Software Base for {{EIT}}},
  shorttitle = {Uses and Abuses of {{EIDORS}}},
  author = {Adler, Andy and Lionheart, William R B},
  date = {2006-05-01},
  journaltitle = {Physiol. Meas.},
  volume = {27},
  number = {5},
  pages = {S25-S42},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/0967-3334/27/5/S03},
  url = {https://iopscience.iop.org/article/10.1088/0967-3334/27/5/S03},
  urldate = {2024-07-08},
  abstract = {EIDORS is an open source software suite for image reconstruction in electrical impedance tomography and diffuse optical tomography, designed to facilitate collaboration, testing and new research in these fields. This paper describes recent work to redesign the software structure in order to simplify its use and provide a uniform interface, permitting easier modification and customization. We describe the key features of this software, followed by examples of its use. One general issue with inverse problem software is the difficulty of correctly implementing algorithms and the consequent ease with which subtle numerical bugs can be inadvertently introduced. EIDORS helps with this issue, by allowing sharing and reuse of well-documented and debugged software. On the other hand, since EIDORS is designed to facilitate use by non-specialists, its use may inadvertently result in such numerical errors. In order to address this issue, we develop a list of ways in which such errors with inverse problems (which we refer to as ‘cheats’) may occur. Our hope is that such an overview may assist authors of software to avoid such implementation issues.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\EIDORS\Uses_and_abuses_of_EIDORS_Adler_Lionheart_2006.pdf}
}

@article{aghajamaliAnalysisDefectMode2015,
  title = {Analysis of Defect Mode in a One-Dimensional Symmetric Double-Negative Photonic Crystal Containing Magnetized Cold Plasma Defect},
  author = {Aghajamali, Alireza and Zare, Azadeh and Wu, Chien-Jang},
  date = {2015-10-10},
  journaltitle = {Appl. Opt.},
  volume = {54},
  number = {29},
  pages = {8602},
  issn = {0003-6935, 1539-4522},
  doi = {10.1364/AO.54.008602},
  url = {https://opg.optica.org/abstract.cfm?URI=ao-54-29-8602},
  urldate = {2024-01-22},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Analysis_of_defect_mode_in_a_one-dimensional_symmetric_double-negative_photonic_Aghajamali_et_al_2015.pdf}
}

@online{aghajamaliDefectiveAnnularSemiconductorsuperconductor2020,
  title = {Defective Annular Semiconductor-Superconductor Photonic Crystal},
  author = {Aghajamali, Alireza and Alamfard, Tannaz},
  date = {2020-04-17},
  eprint = {2004.08149},
  eprinttype = {arXiv},
  eprintclass = {cond-mat, physics:physics},
  url = {http://arxiv.org/abs/2004.08149},
  urldate = {2023-11-06},
  abstract = {In this paper, the transfer matrix method is used to investigate the reflectance properties in a symmetric defective annular photonic crystal (APC) containing semiconductor, high-\$T\_c\$ superconductor and a radial defect layer. Numerical results offer many noteworthy features that can be very useful in designing optical devices. In this regard, the geometric effects of alternate layers on the optical reflectance of our defective APC structure by changing the thickness of different layers would be investigated. Then, the possibility of controlling the spectral position of existed photonic band gaps (PBGs) and defect modes would be discussed by our analysis. In addition, it is found that the characteristics of the reflectance spectrum and subsequently the spectral position of PBG and defect mode are entirely independent on changes in the starting radius of the hollow core. This characteristic is very attractive to manufacturers, since increasing the size of the core radius would offer flexibility and simplicity of fabrication in producing optical devices. This study reveals that the optical reflectance of defective APCs is strongly dependent on azimuthal mode number. Therefore, our designed defective APC structure works as a perfect reflector for the considerable range of wavelength for higher azimuthal mode numbers. Lastly, our results show that by increase the temperature of superconductor layer both of the existed band gaps and defect mode show a red-shift trend by moving towards higher wavelengths. The proposed structure and related results can lead to gain valuable information for designing and fabrication of new types of annular Bragg resonators surrounding a radial defect and integrated visible waveguide devices like optical switches and filters.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Condensed Matter - Materials Science,Physics - Applied Physics,Physics - Optics},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Defective_annular_semiconductor-superconductor_photonic_crystal_Aghajamali_Alamfard_2020.pdf}
}

@article{aghajamaliInvestigationReflectanceProperties2021,
  title = {Investigation of Reflectance Properties in a Symmetric Defective Annular Semiconductor–Superconductor Photonic Crystal with a Radial Defect Layer},
  author = {Aghajamali, Alireza and Alamfard, Tannaz and Nayak, Chittaranjan},
  date = {2021-03},
  journaltitle = {Physica B: Condensed Matter},
  volume = {605},
  pages = {412770},
  issn = {09214526},
  doi = {10.1016/j.physb.2020.412770},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0921452620307432},
  urldate = {2023-11-06},
  abstract = {The transfer matrix method is used to investigate the reflectance properties in a symmetric defective annular photonic crystal (APC) containing semiconductor, high-Tc superconductor and a radial defect layer. Numerical results offer many noteworthy features that can be very useful in designing optical devices. In this regard, the geometric effects of alternate layers on the optical reflectance of our defective APC structure by changing the thickness of different layers would be investigated. Then, the possibility of controlling the spectral position of existed photonic band gaps (PBGs) and defect modes would be discussed by our analysis. In addition, it is found that the characteristics of the reflectance spectrum and subsequently, the spectral position of PBG and defect mode are entirely independent on changes in the starting radius of the hollow core. This characteristic is desirable to manufacturers, since increasing the size of the core radius would offer flexibility and simplicity of fabrication in producing optical devices. This study reveals that the optical reflectance of defective APCs is strongly dependent on the azimuthal mode number. Lastly, our results show that by increasing the temperature of the superconductor layer, both of the existed band gaps and defect mode show a red-shift trend by moving towards higher wavelengths. The proposed structure and related results can lead to gain valuable information for designing and fabrication of new types of annular Bragg resonators surrounding a radial defect and integrated visible waveguide devices like optical switches and filters.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Investigation_of_reflectance_properties_in_a_symmetric_defective_annular_Aghajamali_et_al_2021.pdf}
}

@article{aghajamaliSinglenegativeMetamaterialPeriodic2016,
  title = {Single-Negative Metamaterial Periodic Multilayer Doped by Magnetized Cold Plasma},
  author = {Aghajamali, Alireza and Wu, Chien-Jang},
  date = {2016-03-10},
  journaltitle = {Appl. Opt.},
  volume = {55},
  number = {8},
  pages = {2086},
  issn = {0003-6935, 1539-4522},
  doi = {10.1364/AO.55.002086},
  url = {https://opg.optica.org/abstract.cfm?URI=ao-55-8-2086},
  urldate = {2024-01-22},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Single-negative_metamaterial_periodic_multilayer_doped_by_magnetized_cold_plasma_Aghajamali_Wu_2016.pdf}
}

@article{agnelliClassificationStrokeUsing2020,
  title = {Classification of Stroke Using Neural Networks in Electrical Impedance Tomography},
  author = {Agnelli, J P and Çöl, A and Lassas, M and Murthy, R and Santacesaria, M and Siltanen, S},
  date = {2020-11-01},
  journaltitle = {Inverse Problems},
  volume = {36},
  number = {11},
  pages = {115008},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/1361-6420/abbdcd},
  url = {https://iopscience.iop.org/article/10.1088/1361-6420/abbdcd},
  urldate = {2024-07-08},
  abstract = {Abstract                            Electrical impedance tomography (EIT) is an emerging non-invasive medical imaging modality. It is based on feeding electrical currents into the patient, measuring the resulting voltages at the skin, and recovering the internal conductivity distribution. The mathematical task of EIT image reconstruction is a nonlinear and ill-posed inverse problem. Therefore any EIT image reconstruction method needs to be regularized, typically resulting in blurred images. One promising application is stroke-EIT, or classification of stroke into either ischemic or hemorrhagic. Ischemic stroke involves a blood clot, preventing blood flow to a part of the brain causing a low-conductivity region. Hemorrhagic stroke means bleeding in the brain causing a high-conductivity region. In both cases the symptoms are identical, so a cost-effective and portable classification device is needed. Typical EIT images are not optimal for stroke-EIT because of blurriness. This paper explores the possibilities of machine learning in improving the classification results. Two paradigms are compared: (a) learning from the EIT data, that is Dirichlet-to-Neumann maps and (b) extracting robust features from data and learning from them. The features of choice are virtual hybrid edge detection (VHED) functions (Greenleaf               et~al               2018               Anal. PDE               11               ) that have a geometric interpretation and whose computation from EIT data does not involve calculating a full image of the conductivity. We report the measures of accuracy, sensitivity and specificity of the networks trained with EIT data and VHED functions separately. Computational evidence based on simulated noisy EIT data suggests that the regularized grey-box paradigm (b) leads to significantly better classification results than the black-box paradigm (a).},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\StrokeDetection\Classification_of_stroke_using_neural_networks_in_electrical_impedance_Agnelli_et_al_2020.pdf}
}

@inproceedings{agustssonNTIRE2017Challenge2017,
  title = {{{NTIRE}} 2017 {{Challenge}} on {{Single Image Super-Resolution}}: {{Dataset}} and {{Study}}},
  shorttitle = {{{NTIRE}} 2017 {{Challenge}} on {{Single Image Super-Resolution}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  author = {Agustsson, Eirikur and Timofte, Radu},
  date = {2017-07},
  pages = {1122--1131},
  issn = {2160-7516},
  doi = {10.1109/CVPRW.2017.150},
  url = {https://ieeexplore.ieee.org/document/8014884},
  urldate = {2024-12-30},
  abstract = {This paper introduces a novel large dataset for example-based single image super-resolution and studies the state-of-the-art as emerged from the NTIRE 2017 challenge. The challenge is the first challenge of its kind, with 6 competitions, hundreds of participants and tens of proposed solutions. Our newly collected DIVerse 2K resolution image dataset (DIV2K) was employed by the challenge. In our study we compare the solutions from the challenge to a set of representative methods from the literature and evaluate them using diverse measures on our proposed DIV2K dataset. Moreover, we conduct a number of experiments and draw conclusions on several topics of interest. We conclude that the NTIRE 2017 challenge pushes the state-of-the-art in single-image super-resolution, reaching the best results to date on the popular Set5, Set14, B100, Urban100 datasets and on our newly proposed DIV2K.},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  keywords = {Agriculture,Atmospheric measurements,Degradation,Image quality,Image resolution,Image restoration,Particle measurements},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\Datasets\NTIRE_2017_Challenge_on_Agustsson_Timofte_2017.pdf}
}

@article{alagappanLeveragingAIPhotonics2022,
  title = {Leveraging {{AI}} in {{Photonics}} and {{Beyond}}},
  author = {Alagappan, Gandhi and Ong, Jun Rong and Yang, Zaifeng and Ang, Thomas Yong Long and Zhao, Weijiang and Jiang, Yang and Zhang, Wenzu and Png, Ching Eng},
  date = {2022-02},
  journaltitle = {Photonics},
  volume = {9},
  number = {2},
  pages = {75},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2304-6732},
  doi = {10.3390/photonics9020075},
  url = {https://www.mdpi.com/2304-6732/9/2/75},
  urldate = {2024-05-31},
  abstract = {Artificial intelligence (AI) techniques have been spreading in most scientific areas and have become a heated focus in photonics research in recent years. Forward modeling and inverse design using AI can achieve high efficiency and accuracy for photonics components. With AI-assisted electronic circuit design for photonics components, more advanced photonics applications have emerged. Photonics benefit a great deal from AI, and AI, in turn, benefits from photonics by carrying out AI algorithms, such as complicated deep neural networks using photonics components that use photons rather than electrons. Beyond the photonics domain, other related research areas or topics governed by Maxwell’s equations share remarkable similarities in using the help of AI. The studies in computational electromagnetics, the design of microwave devices, as well as their various applications greatly benefit from AI. This article reviews leveraging AI in photonics modeling, simulation, and inverse design; leveraging photonics computing for implementing AI algorithms; and leveraging AI beyond photonics topics, such as microwaves and quantum-related topics.},
  issue = {2},
  langid = {english},
  keywords = {AI,computational electromagnetics,deep learning,electromagnetics,EMC/EMI,forward/inverse model,inverse design,machine learning,microwave,neural networks,photonics,photonics accelerator,photonics computing,quantum computing,soft computing},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\Leveraging_AI_in_Photonics_Alagappan_et_al_2022.pdf}
}

@inproceedings{alemiRICHAerogelStudy2004,
  title = {A {{RICH}} with Aerogel: A Study of Refractive Index Uniformity},
  shorttitle = {A {{RICH}} with Aerogel},
  booktitle = {{{IEEE Symposium Conference Record Nuclear Science}} 2004.},
  author = {Alemi, M. and Bellunato, T. and Calvi, M. and Matteuzzi, C. and Musy, M. and Perego, D.L.},
  date = {2004},
  volume = {1},
  pages = {637--641},
  publisher = {IEEE},
  location = {Rome, Italy},
  doi = {10.1109/NSSMIC.2004.1462274},
  url = {http://ieeexplore.ieee.org/document/1462274/},
  urldate = {2023-09-05},
  abstract = {The use of aerogel as a radiator in the RICH detectors of LHCb is a challenge due to the hot environment of the hadron collider LHC. Large size tiles of silica aerogel were recently produced with unprecedented optical quality for such dimensions. Results of laboratory measurements and beam tests are briefly reported. A description of a method to measure the uniformity of the index of refraction within the tile is given.},
  eventtitle = {{{IEEE Symposium Conference Record Nuclear Science}} 2004.},
  isbn = {978-0-7803-8700-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Aerogel\A_RICH_with_aerogel_Alemi_et_al_2004.pdf}
}

@article{alizamirRefractiveIndexHemoglobin2022,
  title = {Refractive {{Index}} of {{Hemoglobin Analysis}}: {{A Comparison}} of {{Alternating Conditional Expectations}} and {{Computational Intelligence Models}}},
  shorttitle = {Refractive {{Index}} of {{Hemoglobin Analysis}}},
  author = {Alizamir, Aida and Gholami, Amin and Bahrami, Nader and Ostadhassan, Mehdi},
  date = {2022-09-27},
  journaltitle = {ACS Omega},
  volume = {7},
  number = {38},
  pages = {33769--33782},
  publisher = {American Chemical Society},
  doi = {10.1021/acsomega.2c00746},
  url = {https://doi.org/10.1021/acsomega.2c00746},
  urldate = {2023-09-06},
  abstract = {Hemoglobin is one of the most important blood elements, and its optical properties will determine all other optical properties of human blood. Since the refractive index (RI) of hemoglobin plays a vital role as a non-invasive indicator of some illnesses, accurate calculation of it would be of great importance. Moreover, measurement of the RI of hemoglobin in the laboratory is time-consuming and expensive; thus, developing a smart approach to estimate this parameter is necessary. In this research, four viable strategies were used to make a quantitative correlation between the RI of hemoglobin and its influencing parameters including the concentration, wavelength, and temperature. First, alternating conditional expectations (ACE), a statistical approach, was employed to generate a correlation to predict the RI of hemoglobin. Then, three different optimized intelligent techniques─optimized neural network (ONN), optimized fuzzy inference system (OFIS), and optimized support vector regression (OSVR)─were used to model the RI. A bat-inspired (BA) algorithm was embedded in the formulation of intelligent models to obtain the optimal values of weights and biases of an artificial neural network, membership functions of the fuzzy inference system, and free parameters of support vector regression. The coefficient of determination, root-mean-square error, average absolute relative error, and symmetric mean absolute percentage error for each of the ACE, ONN, OFIS, and OSVR were found as the measure of each model’s accuracy. Results showed that ACE and optimized models (ONN, OFIS, and OSVR) have promising results in the estimation of hemoglobin’s RI. Collectively, ACE outperformed ONN, OFIS, and OSVR, while sensitivity analysis indicated that the concentration, wavelength, and, lastly, temperature would have the highest impact on the RI.},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\BioMaterial\Refractive_Index_of_Alizamir_et_al_2022.pdf}
}

@online{alkinUniversalPhysicsTransformers2024,
  title = {Universal {{Physics Transformers}}: {{A Framework For Efficiently Scaling Neural Operators}}},
  shorttitle = {Universal {{Physics Transformers}}},
  author = {Alkin, Benedikt and Fürst, Andreas and Schmid, Simon and Gruber, Lukas and Holzleitner, Markus and Brandstetter, Johannes},
  date = {2024-10-10},
  eprint = {2402.12365},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2402.12365},
  url = {http://arxiv.org/abs/2402.12365},
  urldate = {2024-10-23},
  abstract = {Neural operators, serving as physics surrogate models, have recently gained increased interest. With ever increasing problem complexity, the natural question arises: what is an efficient way to scale neural operators to larger and more complex simulations - most importantly by taking into account different types of simulation datasets. This is of special interest since, akin to their numerical counterparts, different techniques are used across applications, even if the underlying dynamics of the systems are similar. Whereas the flexibility of transformers has enabled unified architectures across domains, neural operators mostly follow a problem specific design, where GNNs are commonly used for Lagrangian simulations and grid-based models predominate Eulerian simulations. We introduce Universal Physics Transformers (UPTs), an efficient and unified learning paradigm for a wide range of spatio-temporal problems. UPTs operate without grid- or particle-based latent structures, enabling flexibility and scalability across meshes and particles. UPTs efficiently propagate dynamics in the latent space, emphasized by inverse encoding and decoding techniques. Finally, UPTs allow for queries of the latent space representation at any point in space-time. We demonstrate diverse applicability and efficacy of UPTs in mesh-based fluid simulations, and steady-state Reynolds averaged Navier-Stokes simulations, and Lagrangian-based dynamics.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Physics - Fluid Dynamics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Physics\NeuralOperators\Universal_Physics_Transformers_Alkin_et_al_2024.pdf}
}

@article{alsakerAutomatedFilteringNonlinear2022,
  title = {Automated Filtering in the Nonlinear {{Fourier}} Domain of Systematic Artifacts in {{2D}} Electrical Impedance Tomography},
  author = {Alsaker, Melody and Bladow, Benjamin and Campbell, Scott E. and Kar, Emma M.},
  date = {2022},
  journaltitle = {IPI},
  volume = {16},
  number = {3},
  pages = {647},
  issn = {1930-8337, 1930-8345},
  doi = {10.3934/ipi.2021066},
  url = {https://www.aimsciences.org/article/doi/10.3934/ipi.2021066},
  urldate = {2024-07-05},
  abstract = {For patients undergoing mechanical ventilation due to respiratory failure, 2D electrical impedance tomography (EIT) is emerging as a means to provide functional monitoring of pulmonary processes. In EIT, electrical current is applied to the body, and the internal conductivity distribution is reconstructed based on subsequent voltage measurements. However, EIT images are known to often suffer from large systematic artifacts arising from various limitations and exacerbated by the ill-posedness of the inverse problem. The direct D-bar reconstruction method admits a nonlinear Fourier analysis of the EIT problem, providing the ability to process and filter reconstructions in the nonphysical frequency regime. In this work, a technique is introduced for automated Fourier-domain filtering of known systematic artifacts in 2D D-bar reconstructions. The new method is validated using three numerically simulated static thoracic datasets with induced artifacts, plus two experimental dynamic human ventilation datasets containing systematic artifacts. Application of the method is shown to significantly reduce the appearance of artifacts and improve the shape of the lung regions in all datasets.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Filters\Automated_filtering_in_the_nonlinear_Fourier_domain_of_systematic_artifacts_in_Alsaker_et_al_2022.pdf}
}

@article{alyDefectModeProperties2012,
  title = {Defect Mode Properties in a One-Dimensional Photonic Crystal},
  author = {Aly, Arafa H. and Elsayed, Hussien A.},
  date = {2012-01},
  journaltitle = {Physica B: Condensed Matter},
  volume = {407},
  number = {1},
  pages = {120--125},
  issn = {09214526},
  doi = {10.1016/j.physb.2011.09.137},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0921452611010404},
  urldate = {2024-06-01},
  abstract = {Based on the transfer matrix method (TMM), the interaction of electromagnetic waves with onedimensional (1D) defective photonic crystal in ultraviolet (UV) frequency region had been studied. With the calculated transmittance characteristics in the wavelength domain, it can be found that the defect mode can be generated within the photonic band gap (PBG) at the central wavelength. Also the effects of many parameters such as the angle of incidence, the state of polarization and the defect layer thickness have been taken in account. A significant effect in generating multiple defect peaks within the PBG has been illustrated.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Dielectric\Defect_mode_properties_in_a_one-dimensional_photonic_crystal_Aly_Elsayed_2012.pdf}
}

@article{alyEvolutionPhononicBand2017,
  title = {Evolution of {{Phononic Band Gaps}} in {{One-Dimensional Phononic Crystals}} That {{Incorporate High-T}} c {{Superconductor}} and {{Magnetostrictive Materials}}},
  author = {Aly, Arafa H. and Mehaney, Ahmed and El-Naggar, Sahar A.},
  date = {2017-10},
  journaltitle = {J Supercond Nov Magn},
  volume = {30},
  number = {10},
  pages = {2711--2716},
  issn = {1557-1939, 1557-1947},
  doi = {10.1007/s10948-017-4072-y},
  url = {http://link.springer.com/10.1007/s10948-017-4072-y},
  urldate = {2023-09-05},
  abstract = {In this work, we calculate the reflectance of onedimensional phononic crystals (1D PnCs) using the transfer matrix method. We present numerical results for two different PnC structures, the first one, PnCs1, contains highTc superconducting compound (Bi-2223) and the second, PnCs2, contains a giant magnetostrictive material (TerfenolD). Magnetostriction is a property of ferromagnetic materials that causes them to change their shape/dimensions when subjected to external magnetic field. PnC studies that dealt with such materials are few. In this study, we focus on discussing the effects of the temperature and the magnetic field on the phononic gaps of these PnCs. For PnCs1, numerical results show that local resonant modes of elastic waves with brilliant sharpness can be realized. In addition, increasing the temperature leads to a decrease in the gap width which can be controlled by the magnetic field due to the effect of the magnetic field on the velocity of waves in the high-Tc superconducting compound, the magnetic field effectively can widen the gap. For PnCs2, numerical results show that the gap width increases by increasing the magnetic field because the magnetostrictive material directly expanded in the presence of the magnetic field.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Evolution_of_Phononic_Band_Gaps_in_One-Dimensional_Phononic_Crystals_that_Aly_et_al_2017.pdf}
}

@article{alyOneDimensionalMetalloSuperconductorPhotonic2019,
  title = {One-{{Dimensional Metallo-Superconductor Photonic Crystals}} as a {{Smart Window}}},
  author = {Aly, Arafa H. and Ameen, Ayman A. and Elsayed, Hussein A. and Mohamed, S. H. and Singh, Mahi R.},
  date = {2019-08-01},
  journaltitle = {J Supercond Nov Magn},
  volume = {32},
  number = {8},
  pages = {2313--2318},
  issn = {1557-1947},
  doi = {10.1007/s10948-018-4978-z},
  url = {https://doi.org/10.1007/s10948-018-4978-z},
  urldate = {2024-01-15},
  abstract = {A new structure to control the electromagnetic waves has been successfully designed for smart windows applications. The present photonic crystals (PCs) smart window is designed from a unit cell of two different materials such as A (metal) and B (superconductor) of thicknesses that repeated for N periods. The numerical results are investigated based on the characteristic matrix method. It was found that the angle of incidence has a significant effect on the transmission values. At 10o angle of incidence, we found more than 80\% of the visible light and a near IR is transmitted whereas at 60o angle of incidence, the photonic band gap (PBG) begins to appear at wavelengths greater than 800~nm and the visible light transmittance remains more than 80\%. Also, the dependence of the transmittance values on the periodicity and thickness of the proposed design was investigated. The proposed structure could be of potential use as a smart window in low-temperature applications and space industry.},
  langid = {english},
  keywords = {Metal-superconductor,Photonic crystals,Smart window},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\One-Dimensional_Metallo-Superconductor_Photonic_Crystals_as_a_Smart_Window_Aly_et_al_2019.pdf}
}

@article{alyPhotonicCrystalDefective2018,
  title = {Photonic Crystal Defective Superconductor and Black Body Radiations},
  author = {Aly, Arafa H. and Ameen, Ayman A. and ElSayed, Hussein A. and Mohamed, S. H.},
  date = {2018-09-19},
  journaltitle = {Opt Quant Electron},
  volume = {50},
  number = {10},
  pages = {361},
  issn = {1572-817X},
  doi = {10.1007/s11082-018-1632-8},
  url = {https://doi.org/10.1007/s11082-018-1632-8},
  urldate = {2024-01-15},
  abstract = {In the present work, we have obtained a new design for sensing the black body radiation. In this work we designed one-dimensional photonic crystals incorporates that a high-temperature superconducting material as a defect layer. The numerical results are essentially obtained based on the fundamental characteristic matrix method. Also, the results show that the appearance of defect mode inside the photonic band gap. Moreover, the intensity of the defect mode could be tuned by the operating temperature as well as the black body temperature. The angle of incidence and the thickness of the superconductor are investigated. The present work could be potential use in many applications such as sensors for satellites thermal properties and spacecraft.},
  langid = {english},
  keywords = {Black body radiation,Low-temperature,Optoelectronics,Photonic crystals,Superconductor},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\Photonic_crystal_defective_superconductor_and_black_body_radiations_Aly_et_al_2018.pdf}
}

@article{alyPhotonicCrystalEnhanced2021,
  title = {Photonic {{Crystal Enhanced}} by {{Metamaterial}} for {{Measuring Electric Permittivity}} in {{GHz Range}}},
  author = {Aly, Arafa H. and Ameen, Ayman A. and Mahmoud, M. A. and Matar, Z. S. and Al-Dossari, M. and Elsayed, Hussein A.},
  date = {2021-10},
  journaltitle = {Photonics},
  volume = {8},
  number = {10},
  pages = {416},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2304-6732},
  doi = {10.3390/photonics8100416},
  url = {https://www.mdpi.com/2304-6732/8/10/416},
  urldate = {2024-01-15},
  abstract = {The rise of broadband cellular networks and 5G networks enable new rates of data transfer. This paper introduces a new design to measure the permittivity in the GHz range of non-magnetic materials. We tested the proposed design with a wide range of materials such as wood, glass, dry concrete, and limestone. The newly proposed design structure has a maximum sensitivity of 0.496~GHz/RIU. Moreover, it can measure permittivities in the range from 1 up to 9. The main component of the designed structure is a defective one-dimensional photonic crystal with a unit cell consisting of metamaterial and silicon. In addition, we demonstrate the role of the metamaterial in enhancing the proposed design and examine the impact of the defect layer thickness on the proposed structure.},
  issue = {10},
  langid = {english},
  keywords = {metmaterials,permittivity,photonic crystals,sensitivity},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\Photonic_Crystal_Enhanced_by_Metamaterial_for_Measuring_Electric_Permittivity_Aly_et_al_2021.pdf}
}

@article{alySuperconductorNanometallicPhotonic2019,
  title = {Superconductor {{Nanometallic Photonic Crystals}} as a {{Novel Smart Window}} for {{Low-Temperature Applications}}},
  author = {Aly, Arafa H. and Ameen, Ayman A. and Vigneswaran, D.},
  date = {2019-02-01},
  journaltitle = {J Supercond Nov Magn},
  volume = {32},
  number = {2},
  pages = {191--197},
  issn = {1557-1947},
  doi = {10.1007/s10948-018-4716-6},
  url = {https://doi.org/10.1007/s10948-018-4716-6},
  urldate = {2024-01-15},
  abstract = {The control of electromagnetic wave propagation has played an essential role in recent technology. In this paper, we present a novel type of smart window using one-dimensional superconductor nanometallic photonic crystals. The present idea depends on the control of the transmittance values based on the angle of incidence of the electromagnetic waves. We have investigated the transmittance of the proposed novel smart window based on a two-fluid model and a characteristic matrix method. We also obtained the effect of the operating temperature, number of periods, and thicknesses of the constituent materials. Finally, the proposed design promises for useful applications such as space exploration, satellites, and low-temperature applications.},
  langid = {english},
  keywords = {Photonic crystals,Smart window,Superconductor,Transmittance},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\Superconductor_Nanometallic_Photonic_Crystals_as_a_Novel_Smart_Window_for_Aly_et_al_2019.pdf}
}

@article{alyTunablePropertiesOnedimensional2017,
  title = {Tunable Properties of One-Dimensional Photonic Crystals That Incorporate a Defect Layer of a Magnetized Plasma},
  author = {Aly, Arafa H. and Elsayed, Hussein A. and Ameen, Ayman A. and Mohamed, S. H.},
  date = {2017-12-20},
  journaltitle = {Int. J. Mod. Phys. B},
  volume = {31},
  number = {31},
  pages = {1750239},
  publisher = {World Scientific Publishing Co.},
  issn = {0217-9792},
  doi = {10.1142/S0217979217502393},
  url = {https://www.worldscientific.com/doi/abs/10.1142/S0217979217502393},
  urldate = {2024-01-15},
  abstract = {In this paper, we theoretically investigate the transmittance characteristics of one-dimensional defective photonic crystal in microwave radiations based on the fundamentals of the characteristic matrix method. Here, the defect layer is magnetized plasma. The numerical results show the appearance of defect peaks inside the Photonic Band Gap. The external magnetic field has a significant effect on the permittivity of the defect layer. Therefore, the position and intensity of the defect peak are strongly affected by the external magnetic field. Moreover, we have investigated the different parameters on the defect peaks as the plasma density, the thickness of the plasma layer and the angle of incidence. Wherefore, the proposed structure could be the cornerstone for many applications in microwave regions such as narrowband filters.},
  keywords = {defect,magnetized plasma,Photonic crystals},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\Tunable_properties_of_one-dimensional_photonic_crystals_that_incorporate_a_Aly_et_al_2017.pdf}
}

@article{ameenInvestigationAnnularPhotonic2024,
  title = {Investigation of an Annular Photonic Crystal Sensor for Real-Time Monitoring of Calcium Carbonate Scales in Water Distribution Systems},
  author = {Ameen, Ayman A. and Panda, Abinash and Mehaney, Ahmed and Tlija, Mehdi and Bellucci, Stefano and Abukhadra, Mostafa R. and Elsayed, Hussein A.},
  date = {2024-10-30},
  journaltitle = {Heliyon},
  volume = {10},
  number = {20},
  pages = {e39122},
  issn = {2405-8440},
  doi = {10.1016/j.heliyon.2024.e39122},
  url = {https://www.sciencedirect.com/science/article/pii/S2405844024151535},
  urldate = {2024-10-13},
  abstract = {This research exhibits a new configuration of photonic crystals known as annular photonic crystals (APCs) for real-time detection of calcium carbonate (CaCO3) scale in the water pipeline. The proposed sensor features a circular arrangement of porous silicon materials with varying levels of porosity. A central defect layer is incorporated into the design to capture the target analyte, allowing it to detect changes in the refractive index caused by scale formation. To analyze the reflectance spectrum of this structure, a modified transfer matrix method is utilized. An extensive optimization process is conducted based on the characteristics of the defect mode, focusing on various geometric parameters, including layer thickness, porosity levels, core circle radius, and structural periodicity, to achieve optimal sensor performance. The simulation outcomes revealed that at the optimized structure parameters, the sensor offers a remarkable QF, sensitivity, and FoM of 1215, 176.85 nm/RIU, and 350.5 1/RIU, respectively. Moreover, the proposed structure is simple, cost-effective, and compact, which makes it an ideal candidate for the detection of calcium carbonate scales formed in pipes and devices in water supply networks.},
  keywords = {Annular photonic crystal,calcium carbonate,Modified transfer matrix method,reflectance,sensitivity,sensor},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\Investigation_of_an_annular_Ameen_et_al_2024.pdf}
}

@article{ameenInvestigationHighPerformancePressure2023,
  title = {An {{Investigation}} of {{High-Performance Pressure Sensor Employing}} a {{Polymer-Defect-Based 1D Annular Photonic Crystal}}},
  author = {Ameen, Ayman A. and Panda, Abinash and Mehaney, Ahmed and Almawgani, Abdulkarem H. M. and Pradhan, Dipika D. and Ali, Ghassan Ahmed and Ali, Yahya Ali Abdelrahman and Elsayed, Hussein A.},
  date = {2023-07},
  journaltitle = {Photonics},
  volume = {10},
  number = {7},
  pages = {731},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2304-6732},
  doi = {10.3390/photonics10070731},
  url = {https://www.mdpi.com/2304-6732/10/7/731},
  urldate = {2024-01-15},
  abstract = {This study aims to theoretically address the design and analysis of an efficient pressure sensor designed using a polymer-based defective 1D annular photonic crystal (APC). The 1D APC comprises an alternate arrangement of Si and SiO2 in a cylindrical fashion, incorporating a central defect layer. The investigation of the reflectance characteristics of the proposed structure is conducted by separately considering the polystyrene (PS) and the polymethyl methacrylate (PMMA) polymer materials as the defect layer. The pressure-sensitive refractive index of the polymers and the constituent materials of the APC play a vital role in envisaging the pressure-sensing application. The cornerstone of this study is represented by the shift analysis regarding the wavelength of the defect mode inside the band gap using different applied pressures, employing the modified transfer matrix method (MTMM). Various geometrical parameters like the defect polymer layer’s thickness and the APC period were carefully optimized to achieve an improved sensing performance. The proposed design demonstrated a remarkable pressure sensitivity and FoM of 51.29 nm/GPa and 301.7 GPa−1, respectively, which is considerably high in the current research scenario. It is believed that the proposed structure can be an apt candidate for an innovative high-performance pressure sensor, and could play a key role in photonic integrated circuits.},
  issue = {7},
  langid = {english},
  keywords = {annular photonic crystal,polymer material,pressure sensor,sensitivity,transfer matrix method},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\An_Investigation_of_High-Performance_Pressure_Sensor_Employing_a_Ameen_et_al_2023.pdf}
}

@article{ameenOptimizingPhotonicPhononic2021,
  title = {Optimizing Photonic and Phononic Crystal Parameters for Sensing Organic Compounds},
  author = {Ameen, Ayman A. and Elsayed, Hussein A. and Mahmoud, M. A. and Aly, Arafa H.},
  date = {2021-11-01},
  journaltitle = {Appl Nanosci},
  volume = {11},
  number = {11},
  pages = {2703--2716},
  issn = {2190-5517},
  doi = {10.1007/s13204-021-02236-1},
  url = {https://doi.org/10.1007/s13204-021-02236-1},
  urldate = {2024-01-15},
  abstract = {In this paper, we have introduced a multilayer periodic structure with a defect layer as a sensor for a variety of organic compounds. Here, we have considered the interaction of both electromagnetic and acoustic radiations with the designed sensor, which could offer flexibility in the detection process. Si and MgO are the basic materials in the design of the proposed sensor. In this context, this sensor is configured as \{Si (Si/MgO)N (liquid) (MgO/Si)N Si\}. The optimization procedure is based on the change of the thickness of the defect layer and the structure's periodicity. The simulation results were carried through the transfer matrix method to calculate the photonic and phononic transmittance. The structure is analyzed of the photonic and acoustic transmittance as the defect layer is filled with water, benzene, DIPE, n‑Heptane, n‑Hexane, and n‑Octane. The analysis includes determining their defect peak frequency, full width at half maximum, quality factor, sensitivity, and figure of merit. The calculated photonic sensitivity for n‑Heptane is 43.8 \$\$(\textbackslash mathrm\{THz\}/\textbackslash mathrm\{RIU\})\$\$with 154.8 \$\$\{\textbackslash left(\textbackslash mathrm\{RIU\}\textbackslash right)\}\textasciicircum\{-1\}\$\$figure of merit, while its acoustic sensitivity equivalent 1.614 \$\$(\textbackslash mathrm\{MHz\}/\{\textbackslash mathrm\{ms\}\}\textasciicircum\{-1\})\$\$with a figure of merit equals 1.06 \$\$\{\textbackslash left(\textbackslash mathrm\{m\}/\textbackslash mathrm\{s\}\textbackslash right)\}\textasciicircum\{-1\}\$\$. From the simulation results, the structure shows a promise response for sensing different organic compounds with high sensitivity.},
  langid = {english},
  keywords = {Organic compounds,Phononic crystals,Photonic crystals,Sensor,TMM},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\Optimizing_photonic_and_phononic_crystal_parameters_for_sensing_organic_Ameen_et_al_2021.pdf}
}

@article{ameenPromisingPlatformUsing2021,
  title = {Towards {{Promising Platform}} by {{Using Annular Photonic Crystals}} to {{Simulate}} and {{Design Useful Mask}}},
  author = {Ameen, Ayman A. and Elsayed, Hussein A. and Alamri, Sagr and Matar, Z. S. and Al-Dossari, M. and Aly, Arafa H.},
  date = {2021-09},
  journaltitle = {Photonics},
  volume = {8},
  number = {9},
  pages = {349},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2304-6732},
  doi = {10.3390/photonics8090349},
  url = {https://www.mdpi.com/2304-6732/8/9/349},
  urldate = {2024-01-15},
  abstract = {Human masks are considered the mainstay in air filtration and purification technologies and against the spreading of bacterial and viral infections. This paper introduces a novel design of a human mask to increase the ultraviolet germicidal irradiation effect on pathogens. The proposed design consists of a tube with an annular photonic crystal (APC) attached to the mask’s orifice, and a UV source is located in the tube’s center. The main role of this study is the enhancement of UV doses based on the reflectivity of the proposed APC. Therefore, increasing pathogens’ inactivation level in the incoming air to the mask’s orifice could be investigated. The numerical investigations demonstrated that the proposed APC could provide a complete photonic bandgap with a high reflectivity in the wavelength regime from 207 to 230 nm. In addition, we have considered the roles of the thickness of layers, inner core radius, and the azimuthal number. Meanwhile, the results showed the ability to use a wide range of core radius values without almost any variations in the optical properties of the proposed design. Such results could grant the advantage of using this design by the manufacturing of human masks with different sizes besides the inclusions in other ultraviolet germicidal irradiation applications.},
  issue = {9},
  langid = {english},
  keywords = {annular photonic crystals,human masks,photonic band gaps,transfer matrix method},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\Towards_Promising_Platform_by_Using_Annular_Photonic_Crystals_to_Simulate_and_Ameen_et_al_2021.pdf}
}

@article{ameenStudyingEffectQuantum2023a,
  title = {Studying the Effect of Quantum Dots and Parity-Time Symmetry on the Magnification of Topological Edge State Peak as a Pressure Sensor},
  author = {Ameen, Ayman A. and Al-Dossari, M. and Zaky, Zaky A. and Aly, Arafa H.},
  date = {2023-01-01},
  journaltitle = {Synthetic Metals},
  volume = {292},
  pages = {117233},
  issn = {0379-6779},
  doi = {10.1016/j.synthmet.2022.117233},
  url = {https://www.sciencedirect.com/science/article/pii/S0379677922002272},
  urldate = {2024-01-15},
  abstract = {In this paper, a novel pressure sensor employing parity-time symmetry for amplifying the sensing signal is proposed. The sensor design consists of a multi-layer dual–ternary photonic crystal with quantum dots embedded inside silicon dioxide and porous silicon layers as the unit cell of the structure. A topological edge state peak appears inside the photonic bandgap due to the sensor's symmetric design. The properties of the topological edge state peak are changing due to the photoelastic effect of the selected materials. Quantitive analysis of the sensor performance was conducted to optimize the periodicity number and the incidence angle. Moreover, the influence of silicon porosity and macroscopic Lorentz oscillation on the performance was examined.},
  keywords = {Magnification,Parity-Time Symmetry,Porous Silicon,Pressure Sensor,Symmetric Photonic Crystal,Topological Edge State},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\Studying_the_effect_of_quantum_dots_and_parity-time_symmetry_on_the_Ameen_et_al_2023.pdf}
}

@article{ameenTSSConvNetElectricalImpedance2024,
  title = {{{TSS-ConvNet}} for Electrical Impedance Tomography Image Reconstruction},
  author = {Ameen, Ayman A. and Sack, Achim and Pöschel, Thorsten},
  date = {2024-04},
  journaltitle = {Physiol. Meas.},
  volume = {45},
  number = {4},
  pages = {045006},
  publisher = {IOP Publishing},
  issn = {0967-3334},
  doi = {10.1088/1361-6579/ad39c2},
  url = {https://dx.doi.org/10.1088/1361-6579/ad39c2},
  urldate = {2024-04-25},
  abstract = {Objective. The objective of this study was to propose a novel data-driven method for solving ill-posed inverse problems, particularly in certain conditions such as time-difference electrical impedance tomography for detecting the location and size of bubbles inside a pipe. Approach. We introduced a new layer architecture composed of three paths: spatial, spectral, and truncated spectral paths. The spatial path processes information locally, whereas the spectral and truncated spectral paths provide the network with a global receptive field. This unique architecture helps eliminate the ill-posedness and nonlinearity inherent in the inverse problem. The three paths were designed to be interconnected, allowing for an exchange of information on different receptive fields with varied learning abilities. Our network has a bottleneck architecture that enables it to recover signal information from noisy redundant measurements. We named our proposed model truncated spatial-spectral convolutional neural network (TSS-ConvNet). Main results. Our model demonstrated superior accuracy with relatively high resolution on both simulation and experimental data. This indicates that our approach offers significant potential for addressing ill-posed inverse problems in complex conditions effectively and accurately. Significance. The TSS-ConvNet overcomes the receptive field limitation found in most existing models that only utilize local information in Euclidean space. We trained the network on a large dataset covering various configurations with random parameters to ensure generalization over the training samples.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\MyPublications\TSS-ConvNet_for_electrical_impedance_tomography_image_reconstruction_Ameen_et_al_2024.pdf}
}

@online{anandIdentifyingRaceGender2023,
  type = {SSRN Scholarly Paper},
  title = {Identifying {{Race}} and {{Gender Bias}} in {{Latent Diffusion AI Image Generation}}},
  author = {Anand, Taran and Chauhan, Aadi and Jauhari, Tanisha and Shah, Arjav and Singh, Rudransh and Liang, Benjamin and Dutta, Rupsha},
  date = {2023-10-14},
  number = {4602033},
  eprint = {4602033},
  eprinttype = {Social Science Research Network},
  location = {Rochester, NY},
  doi = {10.2139/ssrn.4602033},
  url = {https://papers.ssrn.com/abstract=4602033},
  urldate = {2024-12-06},
  abstract = {In this study, the authors set out to measure race and gender bias prevalent in AI image generation, focusing on the ubiquitous model Stable Diffusion. Utilizing the Equity Evaluation Corpus Dataset, we engineered 50 inputs for profession and 50 for actions, in the interest of coaxing out of the model biases from shallow to systemic. Prompts included requesting images for “CEO”, “nurse”, “secretary”, “selling on the street”, “playing basketball”, and “doing homework”. After generating 20 images for each prompt, we document the model’s results, dominated by racial group and gender bias linked to existing stereotypes. For example, 95\% of the images generated for “playing basketball” were African American men. Previous investigations into the biases of word embedding models—which serve as the basis for image generation models—have demonstrated that models tend to overstate the relationship between semantic values and gender, ethnicity, or race. Examples exist in translational models that alter gendered pronouns when translating a sentence, such as translating "she is a doctor" as "he is a doctor." These biases are not limited to straightforward stereotypes such as the aforementioned gender job bias; more deeply rooted biases may manifest as microaggressions or imposed opinions on policies, such as paid paternity leave decisions. Our investigation focuses on popular text-to-image model Stable Diffusion, developed by Stability AI. In this analysis, we use image captioning software OpenFlamingo and conduct various experiments to identify and classify bias generated by Stable Diffusion.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {AI,Bias,ChatGPT,DALLE-2,diffusion,engineering,Equity,HuggingFace,image,image generation,Machine Learning,microaggressions,ML,OpenFlamingo,Race,Stable Diffusion,text-to-image}
}

@article{aralaguppiExcessMolarVolume1992,
  title = {Excess Molar Volume, Excess Isentropic Compressibility and Excess Molar Refraction of Binary Mixtures of Methyl Acetoacetate with Benzene, Toluene, m-Xylene, Mesitylene and Anisole},
  author = {Aralaguppi, M.I. and Aminabhavi, T.M. and Balundgi, R.H.},
  date = {1992-01},
  journaltitle = {Fluid Phase Equilibria},
  volume = {71},
  number = {1-2},
  pages = {99--112},
  issn = {03783812},
  doi = {10.1016/0378-3812(92)85007-U},
  url = {https://linkinghub.elsevier.com/retrieve/pii/037838129285007U},
  urldate = {2023-09-05},
  abstract = {Aralaguppi, MI., Aminabhavi, T.M. and Balundgi, R.H., 1992. Excess molar volume, excess isentropic compressibility and excess molar refraction of binary mixtures of methyl acetoacetate with benzene, toluene, m-xylene, mesitylene and anisole. Fluid Phase Equilibria, 71: 99-l 12.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Excess_molar_volume,_excess_isentropic_compressibility_and_excess_molar_Aralaguppi_et_al_1992.pdf}
}

@article{arbabiAdvancesOpticalMetalenses2023,
  title = {Advances in Optical Metalenses},
  author = {Arbabi, Amir and Faraon, Andrei},
  date = {2023-01},
  journaltitle = {Nat. Photon.},
  volume = {17},
  number = {1},
  pages = {16--25},
  publisher = {Nature Publishing Group},
  issn = {1749-4893},
  doi = {10.1038/s41566-022-01108-6},
  url = {https://www.nature.com/articles/s41566-022-01108-6},
  urldate = {2023-10-19},
  abstract = {Optical metalenses—two-dimensional arrays of submicrometre scatterers that collectively focus light—have experienced growing research interest in recent years as they can realize conventional optical elements while offering novel functionalities. Their progress is driven by the need for low-cost, high-performance miniaturized optical systems and is supported by advances in nanofabrication and computational tools and techniques. Here we review the main capabilities offered by metalenses, such as their multifunctionality and their ability to efficiently focus light to subwavelength spots. We discuss how these characteristics enable new applications and provide an overview of the current state of the art of optical metasystems. We conclude by discussing the outstanding challenges in the field and highlighting application areas where metalenses could have a substantial impact.},
  issue = {1},
  langid = {english},
  keywords = {Imaging and sensing,Metamaterials},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\MetaLens\Review\Advances_in_optical_metalenses_Arbabi_Faraon_2023.pdf}
}

@article{aristovichOpinionFutureElectrical2022,
  title = {Opinion: {{The}} Future of Electrical Impedance Tomography},
  shorttitle = {Opinion},
  author = {Aristovich, Kirill},
  date = {2022-03-31},
  journaltitle = {Journal of Electrical Bioimpedance},
  volume = {13},
  number = {1},
  pages = {1--3},
  issn = {1891-5469},
  doi = {10.2478/joeb-2022-0001},
  url = {https://www.sciendo.com/article/10.2478/joeb-2022-0001},
  urldate = {2024-07-03},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\FutureOfEIT\Opinion_Aristovich_2022.pdf}
}

@article{arridgeSolvingInverseProblems2019,
  title = {Solving Inverse Problems Using Data-Driven Models},
  author = {Arridge, Simon and Maass, Peter and Öktem, Ozan and Schönlieb, Carola-Bibiane},
  date = {2019-05-01},
  journaltitle = {Acta Numerica},
  volume = {28},
  pages = {1--174},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492919000059},
  url = {https://www.cambridge.org/core/product/identifier/S0962492919000059/type/journal_article},
  urldate = {2024-07-03},
  abstract = {Recent research in inverse problems seeks to develop a mathematically coherent foundation for combining data-driven models, and in particular those based on deep learning, with domain-specific knowledge contained in physical–analytical models. The focus is on solving ill-posed inverse problems that are at the core of many challenging applications in the natural sciences, medicine and life sciences, as well as in engineering and industrial applications. This survey paper aims to give an account of some of the main contributions in data-driven inverse problems.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Review\Solving_inverse_problems_using_data-driven_models_Arridge_et_al_2019.pdf}
}

@online{assranSelfSupervisedLearningImages2023,
  title = {Self-{{Supervised Learning}} from {{Images}} with a {{Joint-Embedding Predictive Architecture}}},
  author = {Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas},
  date = {2023-04-13},
  eprint = {2301.08243},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2301.08243},
  urldate = {2024-03-08},
  abstract = {This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample target blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. Empirically, when combined with Vision Transformers, we find I-JEPA to be highly scalable. For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting and depth prediction.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\VisionTransformer\Self-Supervised_Learning_from_Assran_et_al_2023.pdf}
}

@online{assranSelfSupervisedLearningImages2023a,
  title = {Self-{{Supervised Learning}} from {{Images}} with a {{Joint-Embedding Predictive Architecture}}},
  author = {Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas},
  date = {2023-04-13},
  eprint = {2301.08243},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2301.08243},
  url = {http://arxiv.org/abs/2301.08243},
  urldate = {2024-04-01},
  abstract = {This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample target blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. Empirically, when combined with Vision Transformers, we find I-JEPA to be highly scalable. For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting and depth prediction.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\SelfSupervised\JointEmbedding\Self-Supervised_Learning_from_Images_with_a_Joint-Embedding_Predictive_Assran_et_al_2023.pdf}
}

@online{aumentado-armstrongReconstructiveLatentSpaceNeural2023,
  title = {Reconstructive {{Latent-Space Neural Radiance Fields}} for {{Efficient 3D Scene Representations}}},
  author = {Aumentado-Armstrong, Tristan and Mirzaei, Ashkan and Brubaker, Marcus A. and Kelly, Jonathan and Levinshtein, Alex and Derpanis, Konstantinos G. and Gilitschenski, Igor},
  date = {2023-10-26},
  eprint = {2310.17880},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.17880},
  url = {http://arxiv.org/abs/2310.17880},
  urldate = {2023-11-02},
  abstract = {Neural Radiance Fields (NeRFs) have proven to be powerful 3D representations, capable of high quality novel view synthesis of complex scenes. While NeRFs have been applied to graphics, vision, and robotics, problems with slow rendering speed and characteristic visual artifacts prevent adoption in many use cases. In this work, we investigate combining an autoencoder (AE) with a NeRF, in which latent features (instead of colours) are rendered and then convolutionally decoded. The resulting latent-space NeRF can produce novel views with higher quality than standard colour-space NeRFs, as the AE can correct certain visual artifacts, while rendering over three times faster. Our work is orthogonal to other techniques for improving NeRF efficiency. Further, we can control the tradeoff between efficiency and image quality by shrinking the AE architecture, achieving over 13 times faster rendering with only a small drop in performance. We hope that our approach can form the basis of an efficient, yet high-fidelity, 3D scene representation for downstream tasks, especially when retaining differentiability is useful, as in many robotics scenarios requiring continual learning.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,I.2.10},
  file = {C:\Users\ahmed\Zotero\storage\DEM6UFC2\Aumentado-Armstrong et al. - 2023 - Reconstructive Latent-Space Neural Radiance Fields.pdf}
}

@article{babikiradamSurveyMedicalImaging2021,
  title = {Survey on {{Medical Imaging}} of {{Electrical Impedance Tomography}} ({{EIT}}) by {{Variable Current Pattern Methods}}},
  author = {Babikir Adam, Edriss Eisa and {Sathesh}},
  date = {2021-05-12},
  journaltitle = {JISMAC},
  volume = {3},
  number = {2},
  pages = {82--95},
  issn = {2582-1369},
  doi = {10.36548/jismac.2021.2.002},
  url = {https://irojournals.com/iroismac/V3/I2/02.pdf},
  urldate = {2024-07-08},
  abstract = {Recently, the image reconstruction study on EIT plays a vital role in the medical application field for validation and calibration purpose. This research article analyzes the different types of reconstruction algorithms of EIT in medical imaging applications.  Besides, it reviews many methods involved in constructing the electrical impedance tomography. The spatial distribution and resolution with different sensitivity has been discussed here. The electrode arrangement of various methods involved in the EIT system is discussed here. This research article comprises of adjacent drive method, cross method, and alternative opposite current direction method based on the voltage driven pattern. The assessment process of biomedical EIT has been discussed and investigated through the impedance imaging of the existent substances. The locality of the electrodes can be calculated and fixed for appropriate methods. More specifically, this research article discusses about the EIT image reconstruction methods and the significance of the alternative opposite current direction approach in the biomedical system. The change in conductivity test is further investigated based on the injection of current flow in the system. It has been established by the use of Electrical Impedance Tomography and Diffuse Optical Tomography Reconstruction Software (EDITORS) software, which is open-source software.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Review\Survey_on_Medical_Imaging_of_Electrical_Impedance_Tomography_(EIT)_by_Variable_Babikir_Adam_Sathesh_2021.pdf}
}

@article{bachardCanImageCompression2024,
  title = {Can {{Image Compression Rely}} on {{CLIP}}?},
  author = {Bachard, Tom and Maugey, Thomas},
  date = {2024},
  journaltitle = {IEEE Access},
  volume = {12},
  pages = {78922--78938},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3408651},
  url = {https://ieeexplore.ieee.org/abstract/document/10545425},
  urldate = {2024-12-23},
  abstract = {Coding algorithms are usually designed to faithfully reconstruct images, which limits the expected gains in compression. A new approach based on generative models allows for new compression algorithms that can reach drastically lower compression rates. Instead of pixel fidelity, these algorithms aim at faithfully generating images that have the same high-level interpretation as their inputs. In that context, the challenge becomes to set a good representation for the semantics of an image. While text or segmentation maps have been investigated and have shown their limitations, in this paper, we ask the following question: do powerful foundation models such as CLIP provide a semantic description suited for compression? By suited for compression, we mean that this description is robust to traditional compression tools and, in particular, quantization. We show that CLIP fulfills semantic robustness properties. This makes it an interesting support for generative compression. To make that intuition concrete, we propose a proof-of-concept for a generative codec based on CLIP. Results demonstrate that our CLIP-based coder beats state-of-the-art compression pipelines at extremely low bitrates (0.0012 BPP), both in terms of image quality (65.3 for MUSIQ) and semantic preservation (0.86 for the Clip score).},
  eventtitle = {{{IEEE Access}}},
  keywords = {Atmospheric modeling,Compression algorithms,deep learning,image coding,Image coding,image processing,image reconstruction,image representation,Image segmentation,Measurement,Pipelines,semantic,Semantics,Vectors},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Can_Image_Compression_Rely_on_Bachard_Maugey_2024.pdf}
}

@article{bachmannElectricalImpedanceTomography2018,
  title = {Electrical Impedance Tomography in Acute Respiratory Distress Syndrome},
  author = {Bachmann, M Consuelo and Morais, Caio and Bugedo, Guillermo and Bruhn, Alejandro and Morales, Arturo and Borges, João B and Costa, Eduardo and Retamal, Jaime},
  date = {2018-12},
  journaltitle = {Crit Care},
  volume = {22},
  number = {1},
  pages = {263},
  issn = {1364-8535},
  doi = {10.1186/s13054-018-2195-6},
  url = {https://ccforum.biomedcentral.com/articles/10.1186/s13054-018-2195-6},
  urldate = {2024-07-08},
  abstract = {Acute respiratory distress syndrome (ARDS) is a clinical entity that acutely affects the lung parenchyma, and is characterized by diffuse alveolar damage and increased pulmonary vascular permeability. Currently, computed tomography (CT) is commonly used for classifying and prognosticating ARDS. However, performing this examination in critically ill patients is complex, due to the need to transfer these patients to the CT room. Fortunately, new technologies have been developed that allow the monitoring of patients at the bedside. Electrical impedance tomography (EIT) is a monitoring tool that allows one to evaluate at the bedside the distribution of pulmonary ventilation continuously, in real time, and which has proven to be useful in optimizing mechanical ventilation parameters in critically ill patients. Several clinical applications of EIT have been developed during the last years and the technique has been generating increasing interest among researchers. However, among clinicians, there is still a lack of knowledge regarding the technical principles of EIT and potential applications in ARDS patients. The aim of this review is to present the characteristics, technical concepts, and clinical applications of EIT, which may allow better monitoring of lung function during ARDS.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Electrical_impedance_tomography_in_acute_respiratory_distress_syndrome_Bachmann_et_al_2018.pdf}
}

@online{baezWhatEntropy2024,
  title = {What Is {{Entropy}}?},
  author = {Baez, John C.},
  date = {2024-09-13},
  eprint = {2409.09232},
  eprinttype = {arXiv},
  eprintclass = {cond-mat},
  doi = {10.48550/arXiv.2409.09232},
  url = {http://arxiv.org/abs/2409.09232},
  urldate = {2025-01-04},
  abstract = {This short book is an elementary course on entropy, leading up to a calculation of the entropy of hydrogen gas at standard temperature and pressure. Topics covered include information, Shannon entropy and Gibbs entropy, the principle of maximum entropy, the Boltzmann distribution, temperature and coolness, the relation between entropy, expected energy and temperature, the equipartition theorem, the partition function, the relation between expected energy, free energy and entropy, the entropy of a classical harmonic oscillator, the entropy of a classical particle in a box, and the entropy of a classical ideal gas.},
  pubstate = {prepublished},
  keywords = {Condensed Matter - Statistical Mechanics,Mathematical Physics,Mathematics - Mathematical Physics},
  file = {C:\Users\ahmed\OneDrive\Research\Physics\Entropy\What_is_Entropy_Baez_2024.pdf}
}

@article{baiCNNAcceleratorFPGA2018,
  title = {A {{CNN Accelerator}} on {{FPGA Using Depthwise Separable Convolution}}},
  author = {Bai, Lin and Zhao, Yiming and Huang, Xinming},
  date = {2018-10},
  journaltitle = {IEEE Trans. Circuits Syst. II},
  volume = {65},
  number = {10},
  pages = {1415--1419},
  issn = {1549-7747, 1558-3791},
  doi = {10.1109/TCSII.2018.2865896},
  url = {https://ieeexplore.ieee.org/document/8438987/},
  urldate = {2023-08-26},
  abstract = {Convolutional neural networks (CNNs) have been widely deployed in the fields of computer vision and pattern recognition because of their high accuracy. However, large convolution operations are computing intensive and often require a powerful computing platform such as a graphics processing unit. This makes it difficult to apply CNNs to portable devices. The state-of-the-art CNNs, such as MobileNetV2 and Xception, adopt depthwise separable convolution to replace the standard convolution for embedded platforms, which significantly reduces operations and parameters with only limited loss in accuracy. This highly structured model is very suitable for field-programmable gate array (FPGA) implementation. In this brief, a scalable high performance depthwise separable convolution optimized CNN accelerator is proposed. The accelerator can be fit into an FPGA of different sizes, provided the balancing between hardware resources and processing speed. As an example, MobileNetV2 is implemented on Arria 10 SoC FPGA, and the results show this accelerator can classify each picture from ImageNet in 3.75 ms, which is about 266.6 frames per second. The FPGA design achieves 20x speedup if compared to CPU.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\ConvolutionOnChannels\A_CNN_Accelerator_on_FPGA_Bai_et_al_2018.pdf}
}

@online{balleEndtoendOptimizedImage2017,
  title = {End-to-End {{Optimized Image Compression}}},
  author = {Ballé, Johannes and Laparra, Valero and Simoncelli, Eero P.},
  date = {2017-03-03},
  eprint = {1611.01704},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/1611.01704},
  urldate = {2024-03-08},
  abstract = {We describe an image compression method, consisting of a nonlinear analysis transformation, a uniform quantizer, and a nonlinear synthesis transformation. The transforms are constructed in three successive stages of convolutional linear filters and nonlinear activation functions. Unlike most convolutional neural networks, the joint nonlinearity is chosen to implement a form of local gain control, inspired by those used to model biological neurons. Using a variant of stochastic gradient descent, we jointly optimize the entire model for rate-distortion performance over a database of training images, introducing a continuous proxy for the discontinuous loss function arising from the quantizer. Under certain conditions, the relaxed loss function may be interpreted as the log likelihood of a generative model, as implemented by a variational autoencoder. Unlike these models, however, the compression model must operate at any given point along the rate-distortion curve, as specified by a trade-off parameter. Across an independent set of test images, we find that the optimized method generally exhibits better rate-distortion performance than the standard JPEG and JPEG 2000 compression methods. More importantly, we observe a dramatic improvement in visual quality for all images at all bit rates, which is supported by objective quality estimates using MS-SSIM.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Information Theory},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\AutoEncoder\End-to-end_Optimized_Image_Compression_Balle_et_al_2017.pdf}
}

@online{balleVariationalImageCompression2018,
  title = {Variational Image Compression with a Scale Hyperprior},
  author = {Ballé, Johannes and Minnen, David and Singh, Saurabh and Hwang, Sung Jin and Johnston, Nick},
  date = {2018-05-01},
  eprint = {1802.01436},
  eprinttype = {arXiv},
  eprintclass = {cs, eess, math},
  url = {http://arxiv.org/abs/1802.01436},
  urldate = {2024-08-08},
  abstract = {We describe an end-to-end trainable model for image compression based on variational autoencoders. The model incorporates a hyperprior to effectively capture spatial dependencies in the latent representation. This hyperprior relates to side information, a concept universal to virtually all modern image codecs, but largely unexplored in image compression using artificial neural networks (ANNs). Unlike existing autoencoder compression methods, our model trains a complex prior jointly with the underlying autoencoder. We demonstrate that this model leads to state-of-the-art image compression when measuring visual quality using the popular MS-SSIM index, and yields rate–distortion performance surpassing published ANN-based methods when evaluated using a more traditional metric based on squared error (PSNR). Furthermore, we provide a qualitative comparison of models trained for different distortion metrics.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Information Theory,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Variational_image_compression_Balle_et_al_2018.pdf}
}

@article{barbeauFakingDiscriminatingNavigation2019,
  title = {Faking and {{Discriminating}} the {{Navigation Data}} of a {{Micro Aerial Vehicle Using Quantum Generative Adversarial Networks}}},
  author = {Barbeau, Michel and Garcia-Alfaro, Joaquin},
  date = {2019-12},
  journaltitle = {2019 IEEE Globecom Workshops (GC Wkshps)},
  pages = {1--6},
  publisher = {IEEE},
  location = {Waikoloa, HI, USA},
  doi = {10.1109/GCWkshps45667.2019.9024550},
  url = {https://ieeexplore.ieee.org/document/9024550/},
  urldate = {2024-06-01},
  abstract = {We show that the Quantum Generative Adversarial Network (QGAN) paradigm can be employed by an adversary to learn generating data that deceives the monitoring of a Cyber- Physical System (CPS) and to perpetrate a covert attack. As a test case, the ideas are elaborated considering the navigation data of a Micro Aerial Vehicle (MAV). A concrete QGAN design is proposed to generate fake MAV navigation data. Initially, the adversary is entirely ignorant about the dynamics of the CPS, the strength of the approach from the point of view of the bad guy. A design is also proposed to discriminate between genuine and fake MAV navigation data. The designs combine classical optimization, qubit quantum computing and photonic quantum computing. Using the PennyLane software simulation, they are evaluated over a classical computing platform. We assess the learning time and accuracy of the navigation data generator and discriminator versus space complexity, i.e., the amount of quantum memory needed to solve the problem.},
  eventtitle = {2019 {{IEEE Globecom Workshops}} ({{GC Wkshps}})},
  isbn = {9781728109602},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\GenerativeAdversarialNetworks\Faking_and_Discriminating_the_Navigation_Data_of_a_Micro_Aerial_Vehicle_Using_Barbeau_Garcia-Alfaro_2019.pdf}
}

@online{barronMipNeRF360Unbounded2022,
  title = {Mip-{{NeRF}} 360: {{Unbounded Anti-Aliased Neural Radiance Fields}}},
  shorttitle = {Mip-{{NeRF}} 360},
  author = {Barron, Jonathan T. and Mildenhall, Ben and Verbin, Dor and Srinivasan, Pratul P. and Hedman, Peter},
  date = {2022-03-25},
  eprint = {2111.12077},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2111.12077},
  urldate = {2023-10-16},
  abstract = {Though neural radiance fields (NeRF) have demonstrated impressive view synthesis results on objects and small bounded regions of space, they struggle on "unbounded" scenes, where the camera may point in any direction and content may exist at any distance. In this setting, existing NeRF-like models often produce blurry or low-resolution renderings (due to the unbalanced detail and scale of nearby and distant objects), are slow to train, and may exhibit artifacts due to the inherent ambiguity of the task of reconstructing a large scene from a small set of images. We present an extension of mip-NeRF (a NeRF variant that addresses sampling and aliasing) that uses a non-linear scene parameterization, online distillation, and a novel distortion-based regularizer to overcome the challenges presented by unbounded scenes. Our model, which we dub "mip-NeRF 360" as we target scenes in which the camera rotates 360 degrees around a point, reduces mean-squared error by 57\% compared to mip-NeRF, and is able to produce realistic synthesized views and detailed depth maps for highly intricate, unbounded real-world scenes.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\General\Mip-NeRF_360_Barron_et_al_2022.pdf}
}

@inproceedings{barronMipNeRFMultiscaleRepresentation2021,
  title = {Mip-{{NeRF}}: {{A Multiscale Representation}} for {{Anti-Aliasing Neural Radiance Fields}}},
  shorttitle = {Mip-{{NeRF}}},
  author = {Barron, Jonathan T. and Mildenhall, Ben and Tancik, Matthew and Hedman, Peter and Martin-Brualla, Ricardo and Srinivasan, Pratul P.},
  date = {2021},
  pages = {5855--5864},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Barron_Mip-NeRF_A_Multiscale_Representation_for_Anti-Aliasing_Neural_Radiance_Fields_ICCV_2021_paper.html},
  urldate = {2023-07-13},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Reconstruction\\NeuralRadianceFields\\General\\Mip-NeRF_Barron_et_al_2021.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Reconstruction\\NeuralRadianceFields\\General\\Mip-NeRF_Barron_et_al_22.pdf}
}

@online{barroso-luqueOpenMaterials20242024,
  title = {Open {{Materials}} 2024 ({{OMat24}}) {{Inorganic Materials Dataset}} and {{Models}}},
  author = {Barroso-Luque, Luis and Shuaibi, Muhammed and Fu, Xiang and Wood, Brandon M. and Dzamba, Misko and Gao, Meng and Rizvi, Ammar and Zitnick, C. Lawrence and Ulissi, Zachary W.},
  date = {2024-10-16},
  eprint = {2410.12771},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2410.12771},
  url = {http://arxiv.org/abs/2410.12771},
  urldate = {2024-10-23},
  abstract = {The ability to discover new materials with desirable properties is critical for numerous applications from helping mitigate climate change to advances in next generation computing hardware. AI has the potential to accelerate materials discovery and design by more effectively exploring the chemical space compared to other computational methods or by trial-and-error. While substantial progress has been made on AI for materials data, benchmarks, and models, a barrier that has emerged is the lack of publicly available training data and open pre-trained models. To address this, we present a Meta FAIR release of the Open Materials 2024 (OMat24) large-scale open dataset and an accompanying set of pre-trained models. OMat24 contains over 110 million density functional theory (DFT) calculations focused on structural and compositional diversity. Our EquiformerV2 models achieve state-of-the-art performance on the Matbench Discovery leaderboard and are capable of predicting ground-state stability and formation energies to an F1 score above 0.9 and an accuracy of 20 meV/atom, respectively. We explore the impact of model size, auxiliary denoising objectives, and fine-tuning on performance across a range of datasets including OMat24, MPtraj, and Alexandria. The open release of the OMat24 dataset and models enables the research community to build upon our efforts and drive further advancements in AI-assisted materials science.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Condensed Matter - Materials Science,Physics - Computational Physics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\Datasets\Open_Materials_2024_(OMat24)_Barroso-Luque_et_al_2024.pdf}
}

@article{basakRapidLowCostHighPrecision2022,
  title = {A {{Rapid}}, {{Low-Cost}}, and {{High-Precision Multifrequency Electrical Impedance Tomography Data Acquisition System}} for {{Plant Phenotyping}}},
  author = {Basak, Rinku and Wahid, Khan A.},
  date = {2022-07-04},
  journaltitle = {Remote Sensing},
  volume = {14},
  number = {13},
  pages = {3214},
  issn = {2072-4292},
  doi = {10.3390/rs14133214},
  url = {https://www.mdpi.com/2072-4292/14/13/3214},
  urldate = {2024-07-03},
  abstract = {Plant phenotyping plays an important role for the thorough assessment of plant traits such as growth, development, and physiological processes with the target of achieving higher crop yields by the proper crop management. The assessment can be done by utilizing two- and three-dimensional image reconstructions of the inhomogeneities. The quality of the reconstructed image is required to maintain a high accuracy and a good resolution, and it is desirable to reconstruct the images with the lowest possible noise. In this work, an electrical impedance tomography (EIT) data acquisition system is developed for the reconstruction and evaluation of the inhomogeneities by utilizing a nondestructive method. A high-precision EIT system is developed by designing an electrode array sensor using a cylindrical domain for the measurements in different planes. Different edible plant slices along with multiple plant roots are taken in the EIT domain to assess and calibrate the system, and their reconstructed results are evaluated by utilizing an impedance imaging technique. A non-invasive imaging is carried out in multiple frequencies by utilizing a difference method of reconstruction. The performance and accuracy of the EIT system are evaluated by measuring impedances between 1 and 100 kHz using a low-cost and rapid electrical impedance spectroscopy (EIS) tool connected to the sensor. A finite element method (FEM) modeling is utilized for image reconstruction, which is carried out using electrical impedance and diffuse optical tomography reconstruction software (EIDORS). The reconstruction is made successfully with the optimized results obtained using Gauss–Newton (GN) algorithms.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Experimental\A_Rapid,_Low-Cost,_and_High-Precision_Multifrequency_Electrical_Impedance_Basak_Wahid_2022.pdf}
}

@article{bastianLoadBalancingAdaptive1998,
  title = {Load {{Balancing}} for {{Adaptive Multigrid Methods}}},
  author = {Bastian, Peter},
  date = {1998-07},
  journaltitle = {SIAM J. Sci. Comput.},
  volume = {19},
  number = {4},
  pages = {1303--1321},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/S1064827596297562},
  url = {http://epubs.siam.org/doi/10.1137/S1064827596297562},
  urldate = {2024-07-08},
  abstract = {This paper presents two algorithms solving the load balancing problem arising in a data parallel implementation of multigrid methods on unstructured, locally refined meshes. The differences between additive and multiplicative multigrid and their influence on the load balancing procedure are discussed in detail. The quality of the proposed algorithms is assessed by numerical experiments on several parallel computers.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Multigrid\Load_Balancing_for_Adaptive_Multigrid_Methods_Bastian_1998.pdf}
}

@inproceedings{batlleLightNeuSNeuralSurface2023,
  title = {{{LightNeuS}}: {{Neural Surface Reconstruction}} in~{{Endoscopy Using Illumination Decline}}},
  shorttitle = {{{LightNeuS}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} – {{MICCAI}} 2023},
  author = {Batlle, Víctor M. and Montiel, José M. M. and Fua, Pascal and Tardós, Juan D.},
  editor = {Greenspan, Hayit and Madabhushi, Anant and Mousavi, Parvin and Salcudean, Septimiu and Duncan, James and Syeda-Mahmood, Tanveer and Taylor, Russell},
  date = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {502--512},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-43999-5_48},
  abstract = {We propose a new approach to 3D reconstruction from sequences of images acquired by monocular endoscopes. It is based on two key insights. First, endoluminal cavities are watertight, a property naturally enforced by modeling them in terms of a signed distance function. Second, the scene illumination is variable. It comes from the endoscope’s light sources and decays with the inverse of the squared distance to the surface. To exploit these insights, we build on NeuS~[25], a neural implicit surface reconstruction technique with an outstanding capability to learn appearance and a SDF surface model from multiple views, but currently limited to scenes with static illumination. To remove this limitation and exploit the relation between pixel brightness and depth, we modify the NeuS architecture to explicitly account for it and introduce a calibrated photometric model of the endoscope’s camera and light source.},
  isbn = {978-3-031-43999-5},
  langid = {english},
  keywords = {Endoscopy,Photometric multi-view,Reconstruction},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Endoscope\LightNeuS_Batlle_et_al_2023.pdf}
}

@online{begaintCompressAIPyTorchLibrary2020,
  title = {{{CompressAI}}: A {{PyTorch}} Library and Evaluation Platform for End-to-End Compression Research},
  shorttitle = {{{CompressAI}}},
  author = {Bégaint, Jean and Racapé, Fabien and Feltman, Simon and Pushparaja, Akshay},
  date = {2020-11-05},
  eprint = {2011.03029},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2011.03029},
  url = {http://arxiv.org/abs/2011.03029},
  urldate = {2024-11-26},
  abstract = {This paper presents CompressAI, a platform that provides custom operations, layers, models and tools to research, develop and evaluate end-to-end image and video compression codecs. In particular, CompressAI includes pre-trained models and evaluation tools to compare learned methods with traditional codecs. Multiple models from the state-of-the-art on learned end-to-end compression have thus been reimplemented in PyTorch and trained from scratch. We also report objective comparison results using PSNR and MS-SSIM metrics vs. bit-rate, using the Kodak image dataset as test set. Although this framework currently implements models for still-picture compression, it is intended to be soon extended to the video compression domain.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\CompressAI_Begaint_et_al_2020.pdf}
}

@article{bellunatoRefractiveIndexSilica2008,
  title = {Refractive Index of Silica Aerogel: {{Uniformity}} and Dispersion Law},
  shorttitle = {Refractive Index of Silica Aerogel},
  author = {Bellunato, T. and Calvi, M. and Matteuzzi, C. and Musy, M. and Perego, D.L. and Storaci, B.},
  date = {2008-09},
  journaltitle = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume = {595},
  number = {1},
  pages = {183--186},
  issn = {01689002},
  doi = {10.1016/j.nima.2008.07.072},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0168900208009716},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Aerogel\Refractive_index_of_silica_aerogel_Bellunato_et_al_2008.pdf}
}

@article{bellunatoRefractiveIndexSilica2008a,
  title = {Refractive Index of Silica Aerogel: {{Uniformity}} and Dispersion Law},
  shorttitle = {Refractive Index of Silica Aerogel},
  author = {Bellunato, T. and Calvi, M. and Matteuzzi, C. and Musy, M. and Perego, D.L. and Storaci, B.},
  date = {2008-09},
  journaltitle = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  volume = {595},
  number = {1},
  pages = {183--186},
  issn = {01689002},
  doi = {10.1016/j.nima.2008.07.072},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0168900208009716},
  urldate = {2023-09-05},
  abstract = {Two methods for the measurement of the uniformity of the refractive index n within a single block of silica aerogel are described. One is based on the deflection of a laser beam induced by transverse index gradients. The second exploits the Cherenkov effect, measuring the emission angle of photons radiated by 500 MeV electrons traversing the aerogel. The beam can scan the full aerogel surface providing information on point to point variations of n.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Aerogel\Refractive_index_of_silica_aerogel_Bellunato_et_al_22.pdf}
}

@article{benyahiaMultifeaturesExtractionBased2022,
  title = {Multi-Features Extraction Based on Deep Learning for Skin Lesion Classification},
  author = {Benyahia, Samia and Meftah, Boudjelal and Lézoray, Olivier},
  date = {2022-02-01},
  journaltitle = {Tissue and Cell},
  volume = {74},
  pages = {101701},
  issn = {0040-8166},
  doi = {10.1016/j.tice.2021.101701},
  url = {https://www.sciencedirect.com/science/article/pii/S0040816621002172},
  urldate = {2025-01-07},
  abstract = {For various forms of skin lesion, many different feature extraction methods have been investigated so far. Indeed, feature extraction is a crucial step in machine learning processes. In general, we can distinct handcrafted and deep learning features. In this paper, we investigate the efficiency of using 17 commonly pre-trained convolutional neural networks (CNN) architectures as feature extractors and of 24 machine learning classifiers to evaluate the classification of skin lesions from two different datasets: ISIC 2019 and PH2. In this research, we find out that a DenseNet201 combined with Fine KNN or Cubic SVM achieved the best results in accuracy (92.34\% and 91.71\%) for the ISIC 2019 dataset. The results also show that the suggested method outperforms others approaches with an accuracy of 99\% on the PH2 dataset.},
  keywords = {Classification,Convolutional neural networks,Dermoscopy images,Feature extraction,Skin lesion},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\Multi-features_extraction_Benyahia_et_al_2022.pdf}
}

@misc{BesselFunctionsKreh2012_Pdf,
  title = {Bessel {{functionsKreh2012}}\_.Pdf},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\SomeMath\Bessel_functionsKreh2012__.pdf}
}

@article{bianchessiElectricalImpedanceTomography2020,
  title = {Electrical {{Impedance Tomography Image Reconstruction Based}} on {{Neural Networks}}},
  author = {Bianchessi, Andre and Akamine, Rodrigo H. and Duran, Guilherme C. and Tanabi, Naser and Sato, Andre K. and Martins, Thiago C. and Tsuzuki, Marcos S.G.},
  date = {2020},
  journaltitle = {IFAC-PapersOnLine},
  volume = {53},
  number = {2},
  pages = {15946--15951},
  issn = {24058963},
  doi = {10.1016/j.ifacol.2020.12.360},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2405896320306443},
  urldate = {2024-07-03},
  abstract = {Electrical impedance tomography (EIT) is an imaging technique with a promising fAutbusrter.acSte:veEralelctmriectahloidmspehdaavnecebeteonmougsreadphfoyr(EEIITT) iims aagneimreacgoinnsgtrtueccthinoniq,uesuwchithasa Spirmomuliastinedg AAfuntbunsretear.laincSgte:,vGeEraaleulcstmsriNectaehlwoitdmosnp,ehKdaavanelmcebaenteonfimltouegsrreaadnpdhfoyDr (-EBIaTr.) Riimsecaegnnetilmyre,acsgooinmnsgetrtaueuctthhinoonirq,susesoulwcvhietdhatsahiSpsirpmormuolbiasltienemdg fuAusntinungreea.alirnStgeifi,vcGeiraalul snmseNuetrehawoltdonsnet,hwKaovarelkmba(eAneNnfilNtue)sretadhnrdfoouDrg-hEBIapTri.xRiemlecabegynetlpyrie,xcseolnmsretercauoucntshitoornur,sctssiouolcnvh,edcaotshnisSsiidpmerruoilbnalgteemda Afiuxsniendgearaleirnstogilfi,ucGtiiaolunsnsfeoNurreatwhl teonnefit,nwKaolarlkimma(aAngeNfi.lNtTe)rhtaishnrdwouoDrg-khBapprri.oxRpeolescbeeysntalpyi,rxeseoclomnresctaoruuntcshttoirournsctsbiooalnvs,eeddcotohnnissidtpherreoibnElgeImTa uffiosxriewndgarrdaerstopilfiruoctbiiaolelnmnf.eourTrwathloendefiitnffwaeolrrekinmt(aAmgeNe.sNhT)ehstishwrweoruoergkhcopnprsioxidpeeolrsebedys: apairxceeocloanrrsesectoruanncstdirouanctrbioeafinsn,eedcdoonmnsiedtshehre.inETgIhTae filfaoxtretwdearrrdwesaopslruuotbsieolednmtf.oorTpwrtohodeudficinffeaeslrieminmut alamgteee.dshTpehsoitswenwetroiearlkcs,opnwrsohidpiceohrseedasr:eaatrhceeocoainrnsspeturutasnctdfiooranArbeNafisNneedtdroamnineitnshhge.. ETTIhhTee fnlaootrdtweearsrcdwoanpsdruoubscetledivmitt.oieTps,wrowodhudiccihffe eusrisemendut ltamotecdsrhepeastoetwetnhetreieaolcus,otnpwsuhitdiscehfroerdar:teraatihnceionaigrn,speduetafisnndfeodraiAnreNtfihNneectdroaamirnseiensrhgm. Teshhe. lTnaohtdteerrsefcwooranes,duthsceetdivpirttooieppso,rsoweddhuimcheetushismoeddultcaootnecdsriespatstoetoetfnhtteriaaoliusn,tipnwughttischhfeoraArtNeraNtihnweiniigtnh,pduientfipsnufetodsr fiArnoNtmhNeactrroeaafiirnnsieenrdgm.mTeeshshhe. naTnohddeeroseufcotoprneu,dttsuhcfertoivpmirtoiaepsco,osweadrhsiemchmetuehssohed. TtcowncosriAesatNsteNotfhatrercaohiuinttiepncugtuttsrhefesoraArtNeraNpinrowinpigtoh,sedidenfipanunetddscfiornmotmphaearcerodea:fironsneredmbmaeseseshdh. ToannhdetrhoeuefotLpreeu,Nttsehfteroapmrrcohapitcoeosceatdrusremem,etaehnsohdd. aTcnowonotshiAsetrNsbNoafsaterrdcahiointnienctgthuterhefeseeaAdrNe-fNoprrwowpaitrohdseifdnupallunytdsccofonrmonmepcatareedrde:fiAonNneeNdb.maTseehsdhe aoonbdtathoinueetdLpeuiNtmseaftrgoaemricshaintcoeoctatrdusereepm,enaednshedn. atTnowonothaAenrNybNiamsaeradcgheoitnreecsttohuleruetfseioeandr.e-fToprrhwoepaprodsreefdluimallnyindaccrooynmnreepcsatureledtds:AsohNnoeNwb. atThsehadet othnbettaLhineeeNLdeetiNmaeratcghaeirticeshcitntuoerctetduheraeps,ebnaedntedtneatrnoponetrhafeonrrymbiaamsneacdeg.eoCnreostpohyleruitfgeihoetnd.-cfTo2rh0we2a0prdrIeFflAuimlClyi.nacroynnrecstueldts AshNoNw. tThhaet C(otKtKhhhobteetpeetpyyay:wwLLi/rn/ieeoocgeNNrrrhdddeeetssatti::©tmiaaNNvrra2eeeccg0chhuu2eoiirr0ttmaaieesTllccmnntthnuuoeeeonrrtttAwwees.udoohhoterrraahpkkgssosse/rl,,bbnsic.EEeedettTellttneenheeccstirrettsrrsoppiii/snccbeeaarrayaflfln-oonniirrmmoycmmp-ppeniaamneednndd/acca4aaeegc.nnc..e0cceCC)seerseoottsappoooryymmtlrruiciiootgglggiehhorrttunaan.ppccdhhTe22yyrh00,, et22CCh00peoormmIICeFFlCppAAimuuCCBttieeY..nrra---NaaryiiCdd-eerNeddsDuttoolltimmcseoonsgghsrreoaawpphhtyyh..at Keywo1r.dsI:NNTeRuOraDl UneCtwToIOrkNs, Electrical impedance tomography, Computer-aided tomography.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Electrical_Impedance_Tomography_Image_Reconstruction_Based_on_Neural_Networks_Bianchessi_et_al_2020.pdf}
}

@article{biguriTrackingBoundaryMovement2015,
  title = {Tracking Boundary Movement and Exterior Shape Modelling in Lung {{EIT}} Imaging},
  author = {Biguri, A and Grychtol, B and Adler, A and Soleimani, M},
  date = {2015-06-01},
  journaltitle = {Physiol. Meas.},
  volume = {36},
  number = {6},
  pages = {1119--1135},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/0967-3334/36/6/1119},
  url = {https://iopscience.iop.org/article/10.1088/0967-3334/36/6/1119},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) has shown significant promise for lung imaging. One key challenge for EIT in this application is the movement of electrodes during breathing, which introduces artefacts in reconstructed images. Various approaches have been proposed to compensate for electrode movement, but no comparison of these approaches is available. This paper analyses boundary model mismatch and electrode movement in lung EIT. The aim is to evaluate the extent to which various algorithms tolerate movement, and to determine if a patient specific model is required for EIT lung imaging. Movement data are simulated from a CT-based model, and image analysis is performed using quantitative figures of merit. The electrode movement is modelled based on expected values of chest movement and an extended Jacobian method is proposed to make use of exterior boundary tracking. Results show that a dynamical boundary tracking is the most robust method against any movement, but is computationally more expensive. Simultaneous electrode movement and conductivity reconstruction algorithms show increased robustness compared to only conductivity reconstruction. The results of this comparative study can help develop a better understanding of the impact of shape model mismatch and electrode movement in lung EIT.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\EIDORS\Tracking_boundary_movement_and_exterior_shape_modelling_in_lung_EIT_imaging_Biguri_et_al_2015.pdf}
}

@book{bishopDeepLearningFoundations2024,
  title = {Deep {{Learning}}: {{Foundations}} and {{Concepts}}},
  shorttitle = {Deep {{Learning}}},
  author = {Bishop, Christopher M. and Bishop, Hugh},
  date = {2024},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-45468-4},
  url = {https://link.springer.com/10.1007/978-3-031-45468-4},
  urldate = {2024-03-19},
  isbn = {978-3-031-45467-7 978-3-031-45468-4},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataScience\DeepLearning\Deep_Learning_Bishop_Bishop_2024.pdf}
}

@online{blardOverfittedImageCoding2024,
  title = {Overfitted Image Coding at Reduced Complexity},
  author = {Blard, Théophile and Ladune, Théo and Philippe, Pierrick and Clare, Gordon and Jiang, Xiaoran and Déforges, Olivier},
  date = {2024-03-18},
  eprint = {2403.11651},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2403.11651},
  url = {http://arxiv.org/abs/2403.11651},
  urldate = {2024-12-03},
  abstract = {Overfitted image codecs offer compelling compression performance and low decoder complexity, through the overfitting of a lightweight decoder for each image. Such codecs include Cool-chic, which presents image coding performance on par with VVC while requiring around 2000 multiplications per decoded pixel. This paper proposes to decrease Cool-chic encoding and decoding complexity. The encoding complexity is reduced by shortening Cool-chic training, up to the point where no overfitting is performed at all. It is also shown that a tiny neural decoder with 300 multiplications per pixel still outperforms HEVC. A near real-time CPU implementation of this decoder is made available at https://orange-opensource.github.io/Cool-Chic/.},
  pubstate = {prepublished},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\Zotero\storage\XUCMUFID\Blard et al. - 2024 - Overfitted image coding at reduced complexity.pdf}
}

@article{borijindargoonMUSICLikeAlgorithmSource2019,
  title = {{{MUSIC-Like Algorithm}} for {{Source Localization}} in {{Electrical Impedance Tomography}}},
  author = {Borijindargoon, Narong and Ng, Boon Poh and Rahardja, Susanto},
  date = {2019-06},
  journaltitle = {IEEE Trans. Ind. Electron.},
  volume = {66},
  number = {6},
  pages = {4661--4671},
  issn = {0278-0046, 1557-9948},
  doi = {10.1109/TIE.2018.2863196},
  url = {https://ieeexplore.ieee.org/document/8440666/},
  urldate = {2024-07-08},
  abstract = {In electrical impedance tomography (EIT), the noise amplified solution caused during matrix inversion can be avoided with nonparametric spectral-based estimation when the conductivity variation is bounded and spatially sparse. Among many spectral-based algorithms used in direction-of-arrival estimation, an algorithm called multiple signal classification (MUSIC) is one of the most well-known algorithms that has super resolution performance. However, its dependence on the model-order estimation can lead to performance degradation, especially for quasi-static environment, such as EIT application, and this is due to source location changes and conductivity variation. In this paper, the relationship between source position, conductivity variation, ill-conditioned array manifold, and eigenvalues of the covariance matrix are explored. An algorithm called MUSIClike, which has high resolution performance comparable to MUSIC, is then proposed for EIT application. It is formulated under the beamforming framework and, therefore, does not require an estimation of model order from the covariance matrix. Simulation results show that the proposed method is capable of obtaining high resolution performance under various noise levels. An 8-electrode EIT system prototype was built using the proposed method, and experimental results confirm the high resolution performance capability of the proposed method.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\MUSIC\MUSIC-Like_Algorithm_for_Source_Localization_in_Electrical_Impedance_Tomography_Borijindargoon_et_al_2019.pdf}
}

@article{borsicVivoImpedanceImaging2010,
  title = {\emph{In }{{\emph{Vivo}}} {{Impedance Imaging With Total Variation Regularization}}},
  author = {Borsic, A. and Graham, B.M. and Adler, A. and Lionheart, W.},
  date = {2010-01},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {29},
  number = {1},
  pages = {44--54},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2009.2022540},
  url = {http://ieeexplore.ieee.org/document/5371948/},
  urldate = {2024-07-03},
  abstract = {We show that electrical impedance tomography (EIT) image reconstruction algorithms with regularization based on the total variation (TV) functional are suitable for in vivo imaging of physiological data. This reconstruction approach helps to preserve discontinuities in reconstructed profiles, such as step changes in electrical properties at interorgan boundaries, which are typically smoothed by traditional reconstruction algorithms. The use of the TV functional for regularization leads to the minimization of a nondifferentiable objective function in the inverse formulation. This cannot be efficiently solved with traditional optimization techniques such as the Newton method. We explore two implementations methods for regularization with the TV functional: the lagged diffusivity method and the primal dual–interior point method (PD-IPM). First we clarify the implementation details of these algorithms for EIT reconstruction. Next, we analyze the performance of these algorithms on noisy simulated data. Finally, we show reconstructed EIT images of in vivo data for ventilation and gastric emptying studies. In comparison to traditional quadratic regularization, TV regularization shows improved ability to reconstruct sharp contrasts.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\TotalVariation\iIn_Vivo-i_Impedance_Imaging_With_Total_Variation_Regularization_Borsic_et_al_2010.pdf}
}

@article{borsoiSuperresolutionReconstructionElectrical2018,
  title = {Super-Resolution Reconstruction of Electrical Impedance Tomography Images},
  author = {Borsoi, Ricardo Augusto and Aya, Julio Cesar Ceballos and Costa, Guilherme Holsbach and Bermudez, José Carlos Moreira},
  date = {2018-07},
  journaltitle = {Computers \& Electrical Engineering},
  volume = {69},
  pages = {1--13},
  issn = {00457906},
  doi = {10.1016/j.compeleceng.2018.05.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0045790617333888},
  urldate = {2024-07-05},
  abstract = {Electrical Impedance Tomography (EIT) systems are becoming popular because they present several advantages over competing systems. However, EIT leads to images with very low resolution. Moreover, the nonuniform sampling characteristic of EIT precludes the straightforward application of traditional image super-resolution techniques. In this work, we propose a resampling based Super-Resolution method for EIT image quality improvement. Results with both synthetic and in vivo data indicate that the proposed technique can lead to substantial improvements in EIT image resolution, making it more competitive with other technologies.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\SuperResolution\Super-resolution_reconstruction_of_electrical_impedance_tomography_images_Borsoi_et_al_2018.pdf}
}

@inproceedings{bovermanCompleteElectrodeModel2007,
  title = {The {{Complete Electrode Model For Imaging}} and {{Electrode Contact Compensation}} in {{Electrical Impedance Tomography}}},
  booktitle = {2007 29th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}},
  author = {Boverman, Gregory and Kim, Bong Seok and Isaacson, David and Newell, Jonathan C.},
  date = {2007-08},
  pages = {3462--3465},
  publisher = {IEEE},
  location = {Lyon, France},
  issn = {1557-170X},
  doi = {10.1109/IEMBS.2007.4353076},
  url = {http://ieeexplore.ieee.org/document/4353076/},
  urldate = {2024-07-08},
  abstract = {Electrical Impedance Tomography (EIT) is an imaging modality which currently shows promise for the detection and characterization of breast cancer. A very significant problem in EIT imaging is the proper modeling of the interface between the body and the electrodes. We have found empirically that it is very difficult, in a clinical setting, to assure that all electrodes make satisfactory contact with the body. In addition, we have observed a capacitive effect at skin/electrode boundary that is spatially heterogeneous. To compensate for these problems, we have developed a hybrid nonlinear-linear reconstruction algorithm in which we first estimate electrode surface impedances, using a Newton-type iterative optimization procedure with an analytically computed Jacobian matrix. We subsequently make use of a linearized algorithm to perform a three-dimensional reconstruction of perturbations in both contact impedances and in the spatial distributions of conductivity and permittivity. Results show that, using this procedure, artifacts due to electrodes making poor contact can be greatly reduced.},
  eventtitle = {2007 29th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}},
  isbn = {978-1-4244-0787-3 978-1-4244-0788-0},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\InaccuratelyKnownBoundary\The_Complete_Electrode_Model_For_Imaging_and_Electrode_Contact_Compensation_in_Boverman_et_al_2007.pdf}
}

@article{brabantEffectsPEEPRelationship2022,
  title = {Effects of {{PEEP}} on the Relationship between Tidal Volume and Total Impedance Change Measured via Electrical Impedance Tomography ({{EIT}})},
  author = {Brabant, O. and Crivellari, B. and Hosgood, G. and Raisis, A. and Waldmann, A. D. and Auer, U. and Adler, A. and Smart, L. and Laurence, M. and Mosing, M.},
  date = {2022-04},
  journaltitle = {J Clin Monit Comput},
  volume = {36},
  number = {2},
  pages = {325--334},
  issn = {1387-1307, 1573-2614},
  doi = {10.1007/s10877-021-00651-x},
  url = {https://link.springer.com/10.1007/s10877-021-00651-x},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is used in lung physiology monitoring. There is evidence that EIT is linearly associated with global tidal volume (VT) in clinically healthy patients where no positive end-expiratory pressure (PEEP) is applied. This linearity has not been challenged by altering lung conditions. The aim of this study was to determine the effect of PEEP on VT estimation, using EIT technology and spirometry, and observe the stability of the relationship under changing lung conditions. Twelve male castrated cattle (Steer), mean age 7.8 months (SD\,±\,1.7) were premedicated with xylazine followed by anaesthesia induction with ketamine and maintenance with halothane in oxygen via an endotracheal tube. An EIT belt was applied around the thorax at the level of the fifth intercostal space. Volume controlled ventilation was used. PEEP was increased in a stepwise manner from 0 to 5, 10 and 15 ­cmH2O. At each PEEP, the VT was increased stepwise from 5 to 10 and 15 mL kg−1. After a minute of stabilisation, total impedance change (­VTEIT), using EIT and VT measured by a spirometer connected to a flow-partitioning device ­(VTSpiro) was recorded for the following minute before changing ventilator settings. Data was analysed using linear regression and multi variable analysis. There was a linear relationship between ­VTEIT and ­VTSpiro at all levels of PEEP with an ­R2 of 0.71, 0.68, 0.63 and 0.63 at 0, 5, 10 and 15 cmH2O, respectively. The variance in ­VTEIT was best described by peak inspiratory pressure (PIP) and PEEP (adjusted R­ 2 0.82) while variance in V­ TSpiro was best described by PIP and airway deadspace (adjusted R­ 2 0.76). The relationship between V­ TEIT and V­ TSpiro remains linear with changes in tidal volume, and stable across altered lung conditions. This may have application for monitoring and assessment in vivo.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Effects_of_PEEP_on_the_relationship_between_tidal_volume_and_total_impedance_Brabant_et_al_2022.pdf}
}

@article{brabantPerformanceEvaluationElectrode2022,
  title = {Performance Evaluation of Electrode Design and Material for a Large Animal Electrical Impedance Tomography Belt},
  author = {Brabant, Olivia and Loroesch, Sarah and Adler, Andy and Waldmann, Andreas D. and Raisis, Anthea and Mosing, Martina},
  date = {2022-12},
  journaltitle = {Veterinary Record},
  volume = {191},
  number = {12},
  pages = {e2184},
  issn = {0042-4900, 2042-7670},
  doi = {10.1002/vetr.2184},
  url = {https://bvajournals.onlinelibrary.wiley.com/doi/10.1002/vetr.2184},
  urldate = {2024-07-08},
  abstract = {Background: Electrical impedance tomography (EIT) produces lung ventilation images via a thoracic electrode belt. Robust electrode design and material, providing low electrode skin contact impedance (SCI), is needed in veterinary medicine. The aim of this study was to compare three EIT electrode designs and materials. Methods: Simulations of cylindrical, rectangular and spiked electrode designs were used to evaluate electrode SCI as a function of electrode size, where skin contact was uneven. Gold-plated washers (EGW), zinc-plated rivets (EZR) and zinc-galvanised spikes (EZS) were assigned randomly on two interconnected EIT belts. Gel was applied to the cranial or caudal belt and placed on 17 standing cattle. SCI was recorded at baseline and 3, 5, 7, 9 and 11 minutes later. Results: Simulations that involved electrodes with a greater skin contact area had lower and more uniform SCI. In cattle, SCI decreased with all electrodes over time (p {$<$} 0.01). Without gel, no difference was found between EGW and EZS, while SCI was higher for EZR (p {$<$} 0.03). With gel, SCI was lower in EGW and EZR (p {$<$} 0.026), with the SCI in EGW being the lowest (p {$<$} 0.01). Limitations: Low numbers of animals and static electrode position may affect SCI. Conclusions: Electrode design is important for EIT measurement, with larger electrode designs able to compensate for the use of less conductive materials. Gel is not necessary to achieve acceptable SCI in large animals.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Performance_evaluation_of_electrode_design_and_material_for_a_large_animal_Brabant_et_al_2022.pdf}
}

@article{brabantThoracicElectricalImpedance2022,
  title = {Thoracic {{Electrical Impedance Tomography}}—{{The}} 2022 {{Veterinary Consensus Statement}}},
  author = {Brabant, Olivia A. and Byrne, David P. and Sacks, Muriel and Moreno Martinez, Fernando and Raisis, Anthea L. and Araos, Joaquin B. and Waldmann, Andreas D. and Schramel, Johannes P. and Ambrosio, Aline and Hosgood, Giselle and Braun, Christina and Auer, Ulrike and Bleul, Ulrike and Herteman, Nicolas and Secombe, Cristy J. and Schoster, Angelika and Soares, Joao and Beazley, Shannon and Meira, Carolina and Adler, Andy and Mosing, Martina},
  date = {2022-07-22},
  journaltitle = {Front. Vet. Sci.},
  volume = {9},
  pages = {946911},
  issn = {2297-1769},
  doi = {10.3389/fvets.2022.946911},
  url = {https://www.frontiersin.org/articles/10.3389/fvets.2022.946911/full},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is a non-invasive real-time non-ionising imaging modality that has many applications. Since the first recorded use in 1978, the technology has become more widely used especially in human adult and neonatal critical care monitoring. Recently, there has been an increase in research on thoracic EIT in veterinary medicine. Real-time imaging of the thorax allows evaluation of ventilation distribution in anesthetised and conscious animals. As the technology becomes recognised in the veterinary community there is a need to standardize approaches to data collection, analysis, interpretation and nomenclature, ensuring comparison and repeatability between researchers and studies. A group of nineteen veterinarians and two biomedical engineers experienced in veterinary EIT were consulted and contributed to the preparation of this statement. The aim of this consensus is to provide an introduction to this imaging modality, to highlight clinical relevance and to include recommendations on how to effectively use thoracic EIT in veterinary species. Based on this, the consensus statement aims to address the need for a streamlined approach to veterinary thoracic EIT and includes: an introduction to the use of EIT in veterinary species, the technical background to creation of the functional images, a consensus from all contributing authors on the practical application and use of the technology, descriptions and interpretation of current available variables including appropriate statistical analysis, nomenclature recommended for consistency and future developments in thoracic EIT. The information provided in this consensus statement may benefit researchers and clinicians working within the field of veterinary thoracic EIT. We endeavor to inform future users of the benefits of this imaging modality and provide opportunities to further explore applications of this technology with regards to perfusion imaging and pathology diagnosis.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Thoracic_Electrical_Impedance_Tomography—The_2022_Veterinary_Consensus_Statement_Brabant_et_al_2022.pdf}
}

@article{brazeyRobustImagingUsing2022,
  title = {Robust Imaging Using Electrical Impedance Tomography: Review of Current Tools},
  shorttitle = {Robust Imaging Using Electrical Impedance Tomography},
  author = {Brazey, Benoit and Haddab, Yassine and Zemiti, Nabil},
  date = {2022-02},
  journaltitle = {Proc. R. Soc. A.},
  volume = {478},
  number = {2258},
  pages = {20210713},
  issn = {1364-5021, 1471-2946},
  doi = {10.1098/rspa.2021.0713},
  url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2021.0713},
  urldate = {2024-07-03},
  abstract = {Electrical impedance tomography (EIT) is a medical imaging technique with many advantages and great potential for development in the coming years. Currently, some limitations of EIT are related to the ill-posed nature of the problem. These limitations are translated on a practical level by a lack of genericity of the developed tools. In this paper, the main robust data acquisition and processing tools for EIT proposed in the scientific literature are presented. Their relevance and potential to improve the robustness of EIT are analysed, in order to conclude on the feasibility of a robust EIT tool capable of providing resistivity or difference of resistivity mapping in a wide range of applications. In particular, it is shown that certain measurement acquisition tools and algorithms, such as faulty electrode detection algorithm or particular electrode designs, can ensure the quality of the acquisition in many circumstances. Many algorithms, aiming at processing acquired data, are also described and allow to overcome certain difficulties such as an error in the knowledge of the position of the boundaries or the poor conditioning of the inverse problem. They have a strong potential to faithfully reconstruct a quality image in the presence of disturbances such as noise or boundary modelling error.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Review\Robust_imaging_using_electrical_impedance_tomography_Brazey_et_al_2022.pdf}
}

@article{breslerSharpRepresentationTheorems,
  title = {Sharp {{Representation Theorems}} for {{ReLU Networks}} with {{Precise Dependence}} on {{Depth}}},
  author = {Bresler, Guy and Nagaraj, Dheeraj},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\AI\Components\ActivationFunction\Sharp_Representation_Theorems_Bresler_Nagaraj_.pdf}
}

@article{brissingerComplexRefractiveIndex2019,
  title = {Complex Refractive Index of Polycarbonate over the {{UV-Vis-IR}} Region from 02 to 3 Μm},
  author = {Brissinger, D.},
  date = {2019-02-20},
  journaltitle = {Appl. Opt.},
  volume = {58},
  number = {6},
  pages = {1341},
  issn = {1559-128X, 2155-3165},
  doi = {10.1364/AO.58.001341},
  url = {https://opg.optica.org/abstract.cfm?URI=ao-58-6-1341},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Plastics\Complex_refractive_index_of_polycarbonate_over_the_UV-Vis-IR_region_from_02_to_Brissinger_2019.pdf}
}

@article{brossDevelopmentsInternationalVideo2021,
  title = {Developments in {{International Video Coding Standardization After AVC}}, {{With}} an {{Overview}} of {{Versatile Video Coding}} ({{VVC}})},
  author = {Bross, Benjamin and Chen, Jianle and Ohm, Jens-Rainer and Sullivan, Gary J. and Wang, Ye-Kui},
  date = {2021-09},
  journaltitle = {Proceedings of the IEEE},
  volume = {109},
  number = {9},
  pages = {1463--1493},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2020.3043399},
  url = {https://ieeexplore.ieee.org/abstract/document/9328514},
  urldate = {2024-11-21},
  abstract = {In the last 17 years, since the finalization of the first version of the now-dominant H.264/Moving Picture Experts Group-4 (MPEG-4) Advanced Video Coding (AVC) standard in 2003, two major new generations of video coding standards have been developed. These include the standards known as High Efficiency Video Coding (HEVC) and Versatile Video Coding (VVC). HEVC was finalized in 2013, repeating the ten-year cycle time set by its predecessor and providing about 50\% bit-rate reduction over AVC. The cycle was shortened by three years for the VVC project, which was finalized in July 2020, yet again achieving about a 50\% bit-rate reduction over its predecessor (HEVC). This article summarizes these developments in video coding standardization after AVC. It especially focuses on providing an overview of the first version of VVC, including comparisons against HEVC. Besides further advances in hybrid video compression, as in previous development cycles, the broad versatility of the application domain that is highlighted in the title of VVC is explained. Included in VVC is the support for a wide range of applications beyond the typical standard- and high-definition camera-captured content codings, including features to support computer-generated/screen content, high dynamic range content, multilayer and multiview coding, and support for immersive media such as 360° video.},
  eventtitle = {Proceedings of the {{IEEE}}},
  keywords = {Compression,Decoding,Encoding,H265,H266,High Efficiency Video Coding (HEVC),Joint Video Experts Team (JVET),Moving Picture Experts Group (MPEG),Quantization (signal),standards,Streaming media,Transform coding,versatile supplemental enhancement information (VSEI),Versatile Video Coding (VVC),video,video coding,Video coding,Video Coding Experts Group (VCEG),video compression,Video compression},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoCodec\Developments_in_International_Video_Coding_Standardization_After_AVC,_With_an_Bross_et_al_2021.pdf}
}

@article{brossOverviewVersatileVideo2021,
  title = {Overview of the {{Versatile Video Coding}} ({{VVC}}) {{Standard}} and Its {{Applications}}},
  author = {Bross, Benjamin and Wang, Ye-Kui and Ye, Yan and Liu, Shan and Chen, Jianle and Sullivan, Gary J. and Ohm, Jens-Rainer},
  date = {2021-10},
  journaltitle = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {31},
  number = {10},
  pages = {3736--3764},
  issn = {1558-2205},
  doi = {10.1109/TCSVT.2021.3101953},
  url = {https://ieeexplore.ieee.org/abstract/document/9503377},
  urldate = {2024-11-17},
  abstract = {Versatile Video Coding (VVC) was finalized in July 2020 as the most recent international video coding standard. It was developed by the Joint Video Experts Team (JVET) of the ITU-T Video Coding Experts Group (VCEG) and the ISO/IEC Moving Picture Experts Group (MPEG) to serve an ever-growing need for improved video compression as well as to support a wider variety of today’s media content and emerging applications. This paper provides an overview of the novel technical features for new applications and the core compression technologies for achieving significant bit rate reductions in the neighborhood of 50\% over its predecessor for equal video quality, the High Efficiency Video Coding (HEVC) standard, and 75\% over the currently most-used format, the Advanced Video Coding (AVC) standard. It is explained how these new features in VVC provide greater versatility for applications. Highlighted applications include video with resolutions beyond standard- and high-definition, video with high dynamic range and wide color gamut, adaptive streaming with resolution changes, computer-generated and screen-captured video, ultralow-delay streaming, 360° immersive video, and multilayer coding e.g., for scalability. Furthermore, early implementations are presented to show that the new VVC standard is implementable and ready for real-world deployment.},
  eventtitle = {{{IEEE Transactions}} on {{Circuits}} and {{Systems}} for {{Video Technology}}},
  keywords = {Decoding,Encoding,H.265,H.266,HEVC,High efficiency video coding,JVET,MPEG,standards,Standards,Streaming media,Tools,Transform coding,VCEG,Video coding,video compression,VVC},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Overview_of_the_Versatile_Bross_et_al_2021.pdf}
}

@article{brownElectricalImpedanceTomography2003,
  title = {Electrical Impedance Tomography ({{EIT}}): A Review},
  shorttitle = {Electrical Impedance Tomography ({{EIT}})},
  author = {Brown, Bh},
  date = {2003-01},
  journaltitle = {Journal of Medical Engineering \& Technology},
  volume = {27},
  number = {3},
  pages = {97--108},
  issn = {0309-1902, 1464-522X},
  doi = {10.1080/0309190021000059687},
  url = {http://www.tandfonline.com/doi/full/10.1080/0309190021000059687},
  urldate = {2024-07-03},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Review\Electrical_impedance_tomography_(EIT)_Brown_2003.pdf}
}

@online{bruceGenieGenerativeInteractive2024,
  title = {Genie: {{Generative Interactive Environments}}},
  shorttitle = {Genie},
  author = {Bruce, Jake and Dennis, Michael and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris and Aytar, Yusuf and Bechtle, Sarah and Behbahani, Feryal and Chan, Stephanie and Heess, Nicolas and Gonzalez, Lucy and Osindero, Simon and Ozair, Sherjil and Reed, Scott and Zhang, Jingwei and Zolna, Konrad and Clune, Jeff and family=Freitas, given=Nando, prefix=de, useprefix=true and Singh, Satinder and Rocktäschel, Tim},
  date = {2024-02-23},
  eprint = {2402.15391},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.15391},
  urldate = {2024-03-08},
  abstract = {We introduce Genie, the first generative interactive environment trained in an unsupervised manner from unlabelled Internet videos. The model can be prompted to generate an endless variety of action-controllable virtual worlds described through text, synthetic images, photographs, and even sketches. At 11B parameters, Genie can be considered a foundation world model. It is comprised of a spatiotemporal video tokenizer, an autoregressive dynamics model, and a simple and scalable latent action model. Genie enables users to act in the generated environments on a frame-by-frame basis despite training without any ground-truth action labels or other domain-specific requirements typically found in the world model literature. Further the resulting learned latent action space facilitates training agents to imitate behaviors from unseen videos, opening the path for training generalist agents of the future.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\Genie_Bruce_et_al_2024.pdf}
}

@book{bruntonDataDrivenScienceEngineering2019,
  title = {Data-{{Driven Science}} and {{Engineering}}: {{Machine Learning}}, {{Dynamical Systems}}, and {{Control}}},
  shorttitle = {Data-{{Driven Science}} and {{Engineering}}},
  author = {Brunton, Steven L. and Kutz, J. Nathan},
  date = {2019-01-31},
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/9781108380690},
  url = {https://www.cambridge.org/core/product/identifier/9781108380690/type/book},
  urldate = {2023-09-05},
  isbn = {978-1-108-38069-0 978-1-108-42209-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataScience\DataDriven\Data-Driven_Science_and_Brunton_Kutz_2019.pdf}
}

@article{bruntonPromisingDirectionsMachine2024,
  title = {Promising Directions of Machine Learning for Partial Differential Equations},
  author = {Brunton, Steven L. and Kutz, J. Nathan},
  date = {2024-07},
  journaltitle = {Nat Comput Sci},
  volume = {4},
  number = {7},
  pages = {483--494},
  publisher = {Nature Publishing Group},
  issn = {2662-8457},
  doi = {10.1038/s43588-024-00643-2},
  url = {https://www.nature.com/articles/s43588-024-00643-2},
  urldate = {2024-08-09},
  abstract = {Partial differential equations (PDEs) are among the most universal and parsimonious descriptions of natural physical laws, capturing a rich variety of phenomenology and multiscale physics in a compact and symbolic representation. Here, we examine several promising avenues of PDE research that are being advanced by machine learning, including (1) discovering new governing PDEs and coarse-grained approximations for complex natural and engineered systems, (2) learning effective coordinate systems and reduced-order models to make PDEs more amenable to analysis, and (3) representing solution operators and improving traditional numerical algorithms. In each of these fields, we summarize key advances, ongoing challenges, and opportunities for further development.},
  langid = {english},
  keywords = {Applied mathematics,Computational science},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\PartialDifferentialEquations\Promising_directions_of_machine_learning_for_partial_differential_equations_Brunton_Kutz_2024.pdf}
}

@misc{burgerInverseProblems2007,
  title = {Inverse {{Problems}}},
  author = {Burger},
  date = {2007},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\General\Inverse_Problems_Burger_2007.pdf}
}

@online{caiRadiativeGaussianSplatting2024,
  title = {Radiative {{Gaussian Splatting}} for {{Efficient X-ray Novel View Synthesis}}},
  author = {Cai, Yuanhao and Liang, Yixun and Wang, Jiahao and Wang, Angtian and Zhang, Yulun and Yang, Xiaokang and Zhou, Zongwei and Yuille, Alan},
  date = {2024-07-08},
  eprint = {2403.04116},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2403.04116},
  url = {http://arxiv.org/abs/2403.04116},
  urldate = {2024-08-20},
  abstract = {X-ray is widely applied for transmission imaging due to its stronger penetration than natural light. When rendering novel view X-ray projections, existing methods mainly based on NeRF suffer from long training time and slow inference speed. In this paper, we propose a 3D Gaussian splatting-based framework, namely X-Gaussian, for X-ray novel view synthesis. Firstly, we redesign a radiative Gaussian point cloud model inspired by the isotropic nature of X-ray imaging. Our model excludes the influence of view direction when learning to predict the radiation intensity of 3D points. Based on this model, we develop a Differentiable Radiative Rasterization (DRR) with CUDA implementation. Secondly, we customize an Angle-pose Cuboid Uniform Initialization (ACUI) strategy that directly uses the parameters of the X-ray scanner to compute the camera information and then uniformly samples point positions within a cuboid enclosing the scanned object. Experiments show that our X-Gaussian outperforms state-of-the-art methods by 6.5 dB while enjoying less than 15\% training time and over 73x inference speed. The application on sparse-view CT reconstruction also reveals the practical values of our method. Code is publicly available at https://github.com/caiyuanhao1998/X-Gaussian . A video demo of the training process visualization is at https://www.youtube.com/watch?v=gDVf\_Ngeghg .},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Xray\Radiative_Gaussian_Splatting_Cai_et_al_2024.pdf}
}

@inproceedings{caiStructureAwareSparseViewXray2024,
  title = {Structure-{{Aware Sparse-View X-ray 3D Reconstruction}}},
  author = {Cai, Yuanhao and Wang, Jiahao and Yuille, Alan and Zhou, Zongwei and Wang, Angtian},
  date = {2024},
  pages = {11174--11183},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Cai_Structure-Aware_Sparse-View_X-ray_3D_Reconstruction_CVPR_2024_paper.html},
  urldate = {2024-08-20},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Xray\Structure-Aware_Sparse-View_Cai_et_al_2024.pdf}
}

@article{candianiComputationalApproachesElectrical,
  title = {Computational Approaches in Electrical Impedance Tomography with Applications to Head Imaging},
  author = {Candiani, Valentina},
  abstract = {This thesis considers computational approaches to address the inverse problem arising from electrical impedance tomography (EIT), where the aim is to reconstruct (useful information about) the conductivity distribution inside a physical body from boundary measurements of current and voltages. The problem is nonlinear and highly ill-posed, and it generally presents several theoretical and numerical challenges. In fact, the search for a solution usually requires either carefully selected regularization techniques or simplifying assumptions on the measurement setting.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\Computational_approaches_in_electrical_impedance_tomography_with_applications_Candiani_.pdf}
}

@inproceedings{cao3DFiniteElement2014,
  title = {3-{{D}} Finite Element Modeling Analysis of Epiretinal Electrical Stimulation \&\#x2014; {{Effects}} of Electrode Size and Electrode Shape},
  booktitle = {2014 {{International Conference}} on {{Information Science}}, {{Electronics}} and {{Electrical Engineering}}},
  author = {Cao, Xun and Lyu, Qing and Sui, Xiaohong and Chai, Xinyu},
  date = {2014-04},
  pages = {385--389},
  publisher = {IEEE},
  location = {Sapporo, Japan},
  doi = {10.1109/InfoSEEE.2014.6948137},
  url = {http://ieeexplore.ieee.org/document/6948137/},
  urldate = {2024-07-08},
  abstract = {Epiretinal electrical stimulation provides a promising approach to restore functional vision for patients suffering from retinal degenerative diseases. The electrodes of epiretinal prosthesis stimulate the surviving ganglion cells and cause visual percepts. To further improve the performance of epiretinal electrodes, an optimized solution in electrode design has to be found based on modeling analysis. In this study, different three-dimensional (3-D) electrode models were built to investigate the effects of electrode size and electrode shape on epiretinal electrical stimulation. The retina was presented by a multi-layered computational model using finite element method. Results indicate that small-sized electrodes required lower threshold current but higher threshold charge density. Nonplanar electrodes had higher threshold currents than disk electrode. Concave electrodes needed less threshold charge densities than disk and convex ones. Under the stimulation of the same-multiple threshold current, the activation areas of disk and concave electrodes were more convergent than that of convex electrodes. To conclude, small-sized electrode is recommended if the charge density could be within the safe limit. In consideration of superior electrode safety and stimulation selectivity, concave electrodes are more preferable choices among the electrodes with different geometric shapes. The modeling simulation result of disk electrodes showed a desirable concordance with the animal electrophysiological experiments. This modeling analysis of different 3-D electrodes on epiretinal electrical stimulation may provide meaningful guidance for the optimization of future electrode design.},
  eventtitle = {2014 {{International Conference}} on {{Information Science}}, {{Electronics}} and {{Electrical Engineering}} ({{ISEEE}})},
  isbn = {978-1-4799-3197-2 978-1-4799-3196-5 978-1-4799-3195-8},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\ElectrodeSizeAndShape\3-D_finite_element_modeling_analysis_of_epiretinal_electrical_stimulation_Cao_et_al_2014.pdf}
}

@article{caoConvergenceProblemPlanewave2004,
  title = {Convergence Problem of Plane-Wave Expansion Method for Phononic Crystals},
  author = {Cao, Yongjun and Hou, Zhilin and Liu, Youyan},
  date = {2004-06},
  journaltitle = {Physics Letters A},
  volume = {327},
  number = {2-3},
  pages = {247--253},
  issn = {03759601},
  doi = {10.1016/j.physleta.2004.05.030},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0375960104007029},
  urldate = {2023-09-05},
  abstract = {A new formulation of eigenproblem for phononic crystals is developed. The convergence of the new formulation in the bandstructure calculations is examined in detail and compared with that of the conventional plane wave expansion (CPWE) method. Numerical results show that the slow convergence of the CPWE method is not due to the slow convergence of the Fourier series for the elastic coefficients (or displacement fields) in the interfaces of different materials, but to the inappropriate formulation of the eigenproblem used in the calculations. Numerical calculations also show that the new formulation can provide much more accurate numerical results than the CPWE method for the systems of either very high or very low filling fractions, or of large elastic mismatch.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Convergence_problem_of_plane-wave_expansion_method_for_phononic_crystals_Cao_et_al_2004.pdf}
}

@article{caoFiniteDifferenceTime2004,
  title = {Finite Difference Time Domain Method for Band-Structure Calculations of Two-Dimensional Phononic Crystals},
  author = {Cao, Yongjun and Hou, Zhilin and Liu, Youyan},
  date = {2004-11},
  journaltitle = {Solid State Communications},
  volume = {132},
  number = {8},
  pages = {539--543},
  issn = {00381098},
  doi = {10.1016/j.ssc.2004.09.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0038109804007690},
  urldate = {2023-09-05},
  abstract = {A numerical method based on Finite Difference Time Domain (FDTD) scheme for calculating the band-structure of twodimensional phononic crystals is presented. It is applied to a two-component system consisting of liquid cylinders in a solid matrix and a three-component system with large elastic mismatch, for which the conventional Plane Wave Expansion (PWE) method fails due to the convergence problem or converges very slowly. These two examples show that it is an effective approach for the band-structure calculations of 2D phononic crystals.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\2DPhononicCrystals\Finite_difference_time_domain_method_for_band-structure_calculations_of_Cao_et_al_2004.pdf}
}

@inproceedings{caoHiFTHierarchicalFeature2021,
  title = {{{HiFT}}: {{Hierarchical Feature Transformer}} for {{Aerial Tracking}}},
  shorttitle = {{{HiFT}}},
  author = {Cao, Ziang and Fu, Changhong and Ye, Junjie and Li, Bowen and Li, Yiming},
  date = {2021},
  pages = {15457--15466},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Cao_HiFT_Hierarchical_Feature_Transformer_for_Aerial_Tracking_ICCV_2021_paper.html},
  urldate = {2025-01-07},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\HiFT_Cao_et_al_2021.pdf}
}

@online{caoMotion2VecSets4DLatent2024,
  title = {{{Motion2VecSets}}: {{4D Latent Vector Set Diffusion}} for {{Non-rigid Shape Reconstruction}} and {{Tracking}}},
  shorttitle = {{{Motion2VecSets}}},
  author = {Cao, Wei and Luo, Chang and Zhang, Biao and Nießner, Matthias and Tang, Jiapeng},
  date = {2024-04-13},
  eprint = {2401.06614},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.06614},
  url = {http://arxiv.org/abs/2401.06614},
  urldate = {2024-08-09},
  abstract = {We introduce Motion2VecSets, a 4D diffusion model for dynamic surface reconstruction from point cloud sequences. While existing state-of-the-art methods have demonstrated success in reconstructing non-rigid objects using neural field representations, conventional feed-forward networks encounter challenges with ambiguous observations from noisy, partial, or sparse point clouds. To address these challenges, we introduce a diffusion model that explicitly learns the shape and motion distribution of non-rigid objects through an iterative denoising process of compressed latent representations. The diffusion-based priors enable more plausible and probabilistic reconstructions when handling ambiguous inputs. We parameterize 4D dynamics with latent sets instead of using global latent codes. This novel 4D representation allows us to learn local shape and deformation patterns, leading to more accurate non-linear motion capture and significantly improving generalizability to unseen motions and identities. For more temporally-coherent object tracking, we synchronously denoise deformation latent sets and exchange information across multiple frames. To avoid computational overhead, we designed an interleaved space and time attention block to alternately aggregate deformation latents along spatial and temporal domains. Extensive comparisons against state-of-the-art methods demonstrate the superiority of our Motion2VecSets in 4D reconstruction from various imperfect observations. More detailed information can be found at https://vveicao.github.io/projects/Motion2VecSets/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\DeformableObject\Motion2VecSets_Cao_et_al_2024.pdf}
}

@online{caoMotion2VecSets4DLatent2024a,
  title = {{{Motion2VecSets}}: {{4D Latent Vector Set Diffusion}} for {{Non-rigid Shape Reconstruction}} and {{Tracking}}},
  shorttitle = {{{Motion2VecSets}}},
  author = {Cao, Wei and Luo, Chang and Zhang, Biao and Nießner, Matthias and Tang, Jiapeng},
  date = {2024-04-13},
  eprint = {2401.06614},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.06614},
  urldate = {2024-08-09},
  abstract = {We introduce Motion2VecSets, a 4D diffusion model for dynamic surface reconstruction from point cloud sequences. While existing state-of-the-art methods have demonstrated success in reconstructing non-rigid objects using neural field representations, conventional feed-forward networks encounter challenges with ambiguous observations from noisy, partial, or sparse point clouds. To address these challenges, we introduce a diffusion model that explicitly learns the shape and motion distribution of non-rigid objects through an iterative denoising process of compressed latent representations. The diffusion-based priors enable more plausible and probabilistic reconstructions when handling ambiguous inputs. We parameterize 4D dynamics with latent sets instead of using global latent codes. This novel 4D representation allows us to learn local shape and deformation patterns, leading to more accurate non-linear motion capture and significantly improving generalizability to unseen motions and identities. For more temporally-coherent object tracking, we synchronously denoise deformation latent sets and exchange information across multiple frames. To avoid computational overhead, we designed an interleaved space and time attention block to alternately aggregate deformation latents along spatial and temporal domains. Extensive comparisons against state-of-the-art methods demonstrate the superiority of our Motion2VecSets in 4D reconstruction from various imperfect observations. More detailed information can be found at https://vveicao.github.io/projects/Motion2VecSets/.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\Zotero\storage\ETYXIT7W\Cao et al. - 2024 - Motion2VecSets 4D Latent Vector Set Diffusion for.pdf}
}

@article{caoUltrastrongGrapheneAbsorption2017,
  title = {Ultrastrong {{Graphene Absorption Induced}} by {{One-Dimensional Parity-Time Symmetric Photonic Crystal}}},
  author = {Cao, Peichao and Yang, Xiangbo and Wang, Shiqi and Huang, Yuehua and Wang, Nana and Deng, Dongmei and Liu, Chengyi Timon},
  date = {2017-02},
  journaltitle = {IEEE Photonics J.},
  volume = {9},
  number = {1},
  pages = {1--9},
  issn = {1943-0655},
  doi = {10.1109/JPHOT.2017.2653621},
  url = {http://ieeexplore.ieee.org/document/7820166/},
  urldate = {2024-06-01},
  abstract = {A novel microcavity structure based on 1-D parity-time (PT) symmetric photonic crystal (PC) is presented to get the embedded monolayer graphene absorption enhanced significantly, which paves a path to achieve ultrastrong, controllable, and anisotropic graphene absorption for incident eigenfrequency wave from near infrared to visible. When oscillation of absorption is at the center of the PT broken phase, because of exact matching usage of gain and loss modulation, and singular strong coupling effects that are induced by the PT symmetric PC behind graphene layer, ultrastrong and nonreciprocal graphene absorption can be obtained, and the maximum could reach the order of 105. This approach offers a way to improve the responsivities of graphene-based optodetectors and even to the design of direction sensitive graphene optical communication components.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Dielectric\Ultrastrong_Graphene_Absorption_Induced_by_One-Dimensional_Parity-Time_Cao_et_al_2017.pdf}
}

@article{cappsReconstructionOrganBoundaries2021,
  title = {Reconstruction of {{Organ Boundaries With Deep Learning}} in the {{D-Bar Method}} for {{Electrical Impedance Tomography}}},
  author = {Capps, Michael and Mueller, Jennifer L.},
  date = {2021-03},
  journaltitle = {IEEE Trans. Biomed. Eng.},
  volume = {68},
  number = {3},
  pages = {826--833},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/TBME.2020.3006175},
  url = {https://ieeexplore.ieee.org/document/9130138/},
  urldate = {2024-07-03},
  abstract = {Objective: Medical electrical impedance tomography is a non-ionizing imaging modality in which low-amplitude, low-frequency currents are applied on electrodes on the body, the resulting voltages are measured, and an inverse problem is solved to determine the conductivity distribution in the region of interest. Due the illposedness of the inverse problem, the boundaries of internal organs are typically blurred in the reconstructed image. Methods: A deep learning approach is introduced in the D-bar method for reconstructing a 2-D slice of the thorax to recover the boundaries of organs. This is accomplished by training a deep neural network on labeled pairs of scattering transforms and the boundaries of the organs in the data from which the transforms were computed. This allows the network to “learn” the nonlinear mapping between them by minimizing the error between the output of the network and known actual boundaries. Further, a “sparse” reconstruction is computed by fusing the results of the standard D-bar reconstruction with reconstructed organ boundaries from the neural network. Results: Results are shown on simulated and experimental data collected on a saline-filled tank with agar targets simulating the conductivity of the heart and lungs. Conclusions and Significance: The results demonstrate that deep neural networks can successfully learn the mapping between scattering transforms and the internal boundaries of structures.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Reconstruction_of_Organ_Boundaries_With_Deep_Learning_in_the_D-Bar_Method_for_Capps_Mueller_2021.pdf}
}

@article{changElectricalImpedanceTomography2021,
  title = {Electrical Impedance Tomography for Non-Invasive Identification of Fatty Liver Infiltrate in Overweight Individuals},
  author = {Chang, Chih-Chiang and Huang, Zi-Yu and Shih, Shu-Fu and Luo, Yuan and Ko, Arthur and Cui, Qingyu and Sumner, Jennifer and Cavallero, Susana and Das, Swarna and Gao, Wei and Sinsheimer, Janet and Bui, Alex and Jacobs, Jonathan P. and Pajukanta, Päivi and Wu, Holden and Tai, Yu-Chong and Li, Zhaoping and Hsiai, Tzung K.},
  date = {2021-10-06},
  journaltitle = {Sci Rep},
  volume = {11},
  number = {1},
  pages = {19859},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-99132-z},
  url = {https://www.nature.com/articles/s41598-021-99132-z},
  urldate = {2024-07-08},
  abstract = {Abstract                            Non-alcoholic fatty liver disease (NAFLD) is one of the most common causes of cardiometabolic diseases in overweight individuals. While liver biopsy is the current gold standard to diagnose NAFLD and magnetic resonance imaging (MRI) is a non-invasive alternative still under clinical trials, the former is invasive and the latter costly. We demonstrate electrical impedance tomography (EIT) as a portable method for detecting fatty infiltrate. We enrolled 19 overweight subjects to undergo liver MRI scans, followed by EIT measurements. The MRI images provided the a priori knowledge of the liver boundary conditions for EIT reconstruction, and the multi-echo MRI data quantified liver proton-density fat fraction (PDFF\%) to validate fat infiltrate. Using the EIT electrode belts, we circumferentially injected pairwise current to the upper abdomen, followed by acquiring the resulting surface-voltage to reconstruct the liver conductivity. Pearson’s correlation analyses compared EIT conductivity or MRI PDFF with body mass index, age, waist circumference, height, and weight variables. We reveal that the correlation between liver EIT conductivity or MRI PDFF with demographics is statistically insignificant, whereas liver EIT conductivity is inversely correlated with MRI PDFF (               R               \,=\,−0.69,               p               \,=\,0.003, n\,=\,16). As a pilot study, EIT conductivity provides a portable method for operator-independent and cost-effective detection of hepatic steatosis.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Liver\Electrical_impedance_tomography_for_non-invasive_identification_of_fatty_liver_Chang_et_al_2021.pdf}
}

@online{chanGenerativeNovelView2023,
  title = {Generative {{Novel View Synthesis}} with {{3D-Aware Diffusion Models}}},
  author = {Chan, Eric R. and Nagano, Koki and Chan, Matthew A. and Bergman, Alexander W. and Park, Jeong Joon and Levy, Axel and Aittala, Miika and De Mello, Shalini and Karras, Tero and Wetzstein, Gordon},
  date = {2023-04-05},
  eprint = {2304.02602},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.02602},
  urldate = {2023-10-16},
  abstract = {We present a diffusion-based model for 3D-aware generative novel view synthesis from as few as a single input image. Our model samples from the distribution of possible renderings consistent with the input and, even in the presence of ambiguity, is capable of rendering diverse and plausible novel views. To achieve this, our method makes use of existing 2D diffusion backbones but, crucially, incorporates geometry priors in the form of a 3D feature volume. This latent feature field captures the distribution over possible scene representations and improves our method's ability to generate view-consistent novel renderings. In addition to generating novel views, our method has the ability to autoregressively synthesize 3D-consistent sequences. We demonstrate state-of-the-art results on synthetic renderings and room-scale scenes; we also show compelling results for challenging, real-world objects.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_Chan_et_al_2023.pdf}
}

@article{changInvestigationPhotonicBand2011,
  title = {Investigation of {{Photonic Band Gap}} in a {{Circular Photonic Crystal}}},
  author = {Chang, T.-W. and Hsu, H.-T. and Wu, C.-J.},
  date = {2011-01},
  journaltitle = {Journal of Electromagnetic Waves and Applications},
  volume = {25},
  number = {16},
  pages = {2222--2235},
  issn = {0920-5071, 1569-3937},
  doi = {10.1163/156939311798147123},
  url = {https://www.tandfonline.com/doi/full/10.1163/156939311798147123},
  urldate = {2023-11-06},
  abstract = {Photonic band gap (PBG) in a circular photonic crystal (CPC) has been theoretically investigated in detail on the basis of transfer matrix method in the cylinder Bragg wave. Analytical results in the PBG have been made based on the reflectance spectrum in a quarter-wavelength stack. It is found that, at azimuthal number m = 0, both wavelength- and frequency-dependent reflection responses for the CPC bear strong resemblances to those of a one-dimensional planar PC (PPC). The reflection spectrum is further shown to be strongly dependent on the azimuthal number. In addition, the PBG is greatly enhanced as the azimuthal number increases. The PBG structure is periodically distributed at odd multiples of design frequency for m = 0, which is consistent with the PPC. This periodic feature, however, is no longer present for a larger m-number.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Investigation_of_Photonic_Band_Gap_in_a_Circular_Photonic_Crystal_Chang_et_al_2011.pdf}
}

@article{changMagneticfieldTunableMultichannel2016,
  title = {Magnetic-Field Tunable Multichannel Filter in a Plasma Photonic Crystal at Microwave Frequencies},
  author = {Chang, Tsung-Wen and Chien, Jia-Ren Chang and Wu, Chien-Jang},
  date = {2016-02-01},
  journaltitle = {Appl. Opt.},
  volume = {55},
  number = {4},
  pages = {943},
  issn = {0003-6935, 1539-4522},
  doi = {10.1364/AO.55.000943},
  url = {https://opg.optica.org/abstract.cfm?URI=ao-55-4-943},
  urldate = {2024-01-22},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Magnetic-field_tunable_multichannel_filter_in_a_plasma_photonic_crystal_at_Chang_et_al_2016.pdf}
}

@online{chanTutorialDiffusionModels2024,
  title = {Tutorial on {{Diffusion Models}} for {{Imaging}} and {{Vision}}},
  author = {Chan, Stanley H.},
  date = {2024-09-06},
  eprint = {2403.18103},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.18103},
  url = {http://arxiv.org/abs/2403.18103},
  urldate = {2024-09-11},
  abstract = {The astonishing growth of generative tools in recent years has empowered many exciting applications in text-to-image generation and text-to-video generation. The underlying principle behind these generative tools is the concept of diffusion, a particular sampling mechanism that has overcome some shortcomings that were deemed difficult in the previous approaches. The goal of this tutorial is to discuss the essential ideas underlying the diffusion models. The target audience of this tutorial includes undergraduate and graduate students who are interested in doing research on diffusion models or applying these models to solve other problems.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\DiffusionModels\Tutorial_on_Diffusion_Models_Chan_2024.pdf}
}

@inproceedings{chauhanIdentifyingRaceGender2024,
  title = {Identifying {{Race}} and {{Gender Bias}} in {{Stable Diffusion AI Image Generation}}},
  booktitle = {2024 {{IEEE}} 3rd {{International Conference}} on {{AI}} in {{Cybersecurity}} ({{ICAIC}})},
  author = {Chauhan, Aadi and Anand, Taran and Jauhari, Tanisha and Shah, Arjav and Singh, Rudransh and Rajaram, Arjun and Vanga, Rithvik},
  date = {2024-02},
  pages = {1--6},
  doi = {10.1109/ICAIC60265.2024.10433840},
  url = {https://ieeexplore.ieee.org/abstract/document/10433840?casa_token=_mDEuEUprmAAAAAA:3-78Yt06xRDExXwIBN0abYJacblWHGMhgRzOVp2LGinKP6YI8uUo1LIULzdMaWhS5jGXJX4HXA},
  urldate = {2024-12-06},
  abstract = {In this study, we set out to measure race and gender bias prevalent in text-to-image (TTI) AI image generation, focusing on the popular model Stable Diffusion from Stability AI. Previous investigations into the biases of word embedding models—which serve as the basis for image generation models—have demonstrated that models tend to overstate the relationship between semantic values and gender, ethnicity, or race. These biases are not limited to straightforward stereotypes; more deeply rooted biases may manifest as microaggressions or imposed opinions on policies, such as paid paternity leave decisions. In this analysis, we use image captioning software OpenFlamingo and Stable Diffusion to identify and classify bias within text-to-image models. Utilizing data from the Bureau of Labor Statistics, we engineered 50 prompts for profession and 50 prompts for actions in the interest of coaxing out shallow to systemic biases in the model. Prompts included generating images for "CEO", "nurse", "secretary", "playing basketball", and "doing homework". After generating 20 images for each prompt, we document the model’s results. We find that biases do exist within the model across a variety of prompts. For example, 95\% of the images generated for "playing basketball" were African American men. We then analyze our results through categorizing our prompts into a series of income and education levels corresponding to data from the Bureau of Labor Statistics. Ultimately, we find that racial and gender biases are present yet not drastic.},
  eventtitle = {2024 {{IEEE}} 3rd {{International Conference}} on {{AI}} in {{Cybersecurity}} ({{ICAIC}})},
  keywords = {Artificial intelligence,Data models,gender classification,generated bias,Image synthesis,Leadership,Manuals,neural network,openflamingo,race classification,Stability analysis,stable diffusion,Task analysis,text-to-image},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\RaceAndGendeBias\Identifying_Race_and_Gender_Bias_in_Stable_Diffusion_AI_Image_Generation_Chauhan_et_al_2024.pdf}
}

@online{chen3DTopiaXLScalingHighquality2024,
  title = {{{3DTopia-XL}}: {{Scaling High-quality 3D Asset Generation}} via {{Primitive Diffusion}}},
  shorttitle = {{{3DTopia-XL}}},
  author = {Chen, Zhaoxi and Tang, Jiaxiang and Dong, Yuhao and Cao, Ziang and Hong, Fangzhou and Lan, Yushi and Wang, Tengfei and Xie, Haozhe and Wu, Tong and Saito, Shunsuke and Pan, Liang and Lin, Dahua and Liu, Ziwei},
  date = {2024-09-19},
  eprint = {2409.12957},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.12957},
  url = {http://arxiv.org/abs/2409.12957},
  urldate = {2024-10-04},
  abstract = {The increasing demand for high-quality 3D assets across various industries necessitates efficient and automated 3D content creation. Despite recent advancements in 3D generative models, existing methods still face challenges with optimization speed, geometric fidelity, and the lack of assets for physically based rendering (PBR). In this paper, we introduce 3DTopia-XL, a scalable native 3D generative model designed to overcome these limitations. 3DTopia-XL leverages a novel primitive-based 3D representation, PrimX, which encodes detailed shape, albedo, and material field into a compact tensorial format, facilitating the modeling of high-resolution geometry with PBR assets. On top of the novel representation, we propose a generative framework based on Diffusion Transformer (DiT), which comprises 1) Primitive Patch Compression, 2) and Latent Primitive Diffusion. 3DTopia-XL learns to generate high-quality 3D assets from textual or visual inputs. We conduct extensive qualitative and quantitative experiments to demonstrate that 3DTopia-XL significantly outperforms existing methods in generating high-quality 3D assets with fine-grained textures and materials, efficiently bridging the quality gap between generative models and real-world applications.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\3DTopia-XL_Chen_et_al_2024.pdf}
}

@inproceedings{chenCalculationSimulationJacobi2008,
  title = {Calculation and Simulation of the {{Jacobi}} Matrix in Electrical Impedance Tomography},
  author = {Chen, Shujun and Kou, Ge and Jiang, Aixia},
  editor = {Ye, Shenghua and Zhang, Guangjun and Ni, Jun},
  date = {2008-12-03},
  pages = {71602F},
  location = {Beijing, China},
  doi = {10.1117/12.806993},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.806993},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography is a kind of functional imaging technique making full use of human resistance carried by physiological and pathological information. However, the image reconstruction in EIT is a high ill-posed, non-linear, inverse problem, and it becomes a key and difficult point in EIT research. The calculation of Jacobi matrix in EIT is as the representive, for it requires several forward solutions to be computed. The paper focuses on the Jacobi matrix calculation method in order to reduce EIT computation based on disadvantages above. The Jacobi matrix is different when the electrode position and serial number are different in the finite element model. Jacobi formula is derived from the Newton-Raphson and the standard derivation method is adopted by comparing with the normal method, and it reduces the computation time effectively. Finally, the computer simulation and comparability of Jacobi matrix is given.},
  eventtitle = {International {{Conference}} of {{Optical Instrument}} and {{Technology}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\JacobiMatrix\Calculation_and_simulation_of_the_Jacobi_matrix_in_electrical_impedance_Chen_et_al_2008.pdf}
}

@article{chenColorMedGANSemanticColorization2023,
  title = {{{ColorMedGAN}}: {{A Semantic Colorization Framework}} for {{Medical Images}}},
  shorttitle = {{{ColorMedGAN}}},
  author = {Chen, Shaobo and Xiao, Ning and Shi, Xinlai and Yang, Yuer and Tan, Huaning and Tian, Jiajuan and Quan, Yujuan},
  date = {2023-01},
  journaltitle = {Applied Sciences},
  volume = {13},
  number = {5},
  pages = {3168},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app13053168},
  url = {https://www.mdpi.com/2076-3417/13/5/3168},
  urldate = {2024-06-21},
  abstract = {Colorization for medical images helps make medical visualizations more engaging, provides better visualization in 3D reconstruction, acts as an image enhancement technique for tasks such as segmentation, and makes it easier for non-specialists to perceive tissue changes and texture details in medical images in diagnosis and teaching. However, colorization algorithms have been hindered by limited semantic understanding. In addition, current colorization methods still rely on paired data, which is often not available for specific fields such as medical imaging. To address the texture detail of medical images and the scarcity of paired data, we propose a self-supervised colorization framework based on CycleGAN(Cycle-Consistent Generative Adversarial Networks), treating the colorization problem of medical images as a cross-modal domain transfer problem in color space. The proposed framework focuses on global edge features and semantic information by introducing edge-aware detectors, multi-modal discriminators, and a semantic feature fusion module. Experimental results demonstrate that our method can generate high-quality color medical images.},
  issue = {5},
  langid = {english},
  keywords = {CycleGAN,medical image colorization,visualization},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\ComputerVision\ImageSegmentation\ColorMedGAN_Chen_et_al_2023.pdf}
}

@article{chenControlWavePropagation2000,
  title = {Control of {{Wave Propagation}} in {{Composite Rods Using Shape Memory Inserts}}: {{Theory}} and {{Experiments}}},
  shorttitle = {Control of {{Wave Propagation}} in {{Composite Rods Using Shape Memory Inserts}}},
  author = {Chen, T. and Ruzzene, M. and Baz, A.},
  date = {2000-10},
  journaltitle = {Journal of Vibration and Control},
  volume = {6},
  number = {7},
  pages = {1065--1081},
  issn = {1077-5463, 1741-2986},
  doi = {10.1177/107754630000600707},
  url = {http://journals.sagepub.com/doi/10.1177/107754630000600707},
  urldate = {2023-09-05},
  abstract = {Longitudinal wave propagation is controlled using shape memory inserts placed along rods. The inserts act as sources of impedance mismatch with tunable characteristics. Such characteristics are attributed to the unique behavior of the shape memory alloy whereby the elastic modulus significantly increases as the alloy undergoes a phase transformation from martensite to austenite. With such controllable capability, the inserts can introduce the proper impedance mismatch necessary to impede the wave propagation along the rods. A spectral finite element model is developed to accurately reproduce the wave propagation phenomena inside the composite rod and to model its dynamic behavior with a significantly reduced number of elements. The theoretical predictions are compared with the experimental performance of rods with one, two, and three shape memory inserts. The behavior of the composite is evaluated at different activation temperatures of the shape memory material. The obtained results indicate significant attenuation of the wave propagation inside the composites with increasing operating temperature. Both experimental and theoretical results demonstrate the effectiveness and potential of composites with tunable impedance mismatch sources in controlling wave propagation in rods.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Control_of_Wave_Propagation_in_Composite_Rods_Using_Shape_Memory_Inserts_Chen_et_al_2000.pdf}
}

@article{chenConvolutionalNeuralNetwork2021,
  title = {A Convolutional Neural Network Algorithm for Breast Tumor Detection with Magnetic Detection Electrical Impedance Tomography},
  author = {Chen, Ruijuan and Zhao, Songsong and Wu, Weiwei and Sun, Zhihui and Wang, Jinhai and Wang, Huiquan and Han, Guang},
  date = {2021-06-01},
  journaltitle = {Review of Scientific Instruments},
  volume = {92},
  number = {6},
  pages = {064701},
  issn = {0034-6748, 1089-7623},
  doi = {10.1063/5.0041423},
  url = {https://pubs.aip.org/rsi/article/92/6/064701/991930/A-convolutional-neural-network-algorithm-for},
  urldate = {2024-07-03},
  abstract = {Breast cancer is a malignant tumor disease for which early detection, diagnosis, and treatment are of paramount significance in prolonging the life of patients. Magnetic Detection Electrical Impedance Tomography (MDEIT) based on the Convolutional Neural Network (CNN), which aims to realize non-invasive, high resolution detection of breast tumors, is proposed. First, the MDEIT forward problem of the coronal and horizontal planes of the breast was simulated and solved using the Finite Element Method to obtain sample datasets of different lesions. Then, the CNN was built and trained to predict the conductivity distribution in different orientations of the breast model. Finally, noise and phantom experiments were performed in order to assess the anti-noise performance of the CNN algorithm and its feasibility of detecting breast tumors in practical applications. The simulation results showed that the reconstruction relative error with the CNN algorithm can be reduced to 10\%, in comparison with the truncated singular value decomposition algorithm and back propagation algorithm. The CNN algorithm had better stability in the anti-noise performance test. When the noise of 60 dB was added, the shape of the breast tumor could still be restored by the CNN algorithm. The phantom experimental results showed that through the CNN based reconstruction algorithm, the reconstruction conductivity distribution image was legible and the position of the breast tumor could be determined. It is reasonable to conclude that the MDEIT reconstruction method proposed in this study has practical importance for the early and non-invasive detection of breast tumors.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\A_convolutional_neural_network_algorithm_for_breast_tumor_detection_with_Chen_et_al_2021.pdf}
}

@article{chenDeepAutoencoderImaging2021,
  title = {Deep {{Autoencoder Imaging Method}} for {{Electrical Impedance Tomography}}},
  author = {Chen, Xiaoyan and Wang, Zichen and Zhang, Xinyu and Fu, Rong and Wang, Di and Zhang, Miao and Wang, Huaxiang},
  date = {2021},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {70},
  pages = {1--15},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2021.3094834},
  url = {https://ieeexplore.ieee.org/document/9475043/},
  urldate = {2024-07-03},
  abstract = {Electrical impedance tomography (EIT) is an effective technique for real-time monitoring, visualization, and analysis of industrial process in a noninvasive manner. However, due to the nonlinear and “soft-field” nature of its inverse problem, image reconstruction of EIT is always limited in image resolution and, in particular, the accuracy of identifying object boundaries. In order to solve the above problems, a novel multilayer autoencoder (MLAE) image reconstruction network that consists of a feature extraction module and an image reconstruction module is proposed. In the proposed method, hierarchical structures are applied to increase the forward information flow and the selected appropriate hidden layers can solve the disappearance of the reverse gradient flow. The training process of MLAE containing self-supervised pretraining and supervised fine-tuning can provide better complex nonlinear mapping and improve the model performance. The experimental and analytical results prove that the MLAE image reconstruction method can obtain higher quality images than the typical algorithms and certain methods based on deep learning.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Autoencoder\Deep_Autoencoder_Imaging_Method_for_Electrical_Impedance_Tomography_Chen_et_al_2021.pdf}
}

@inproceedings{chenDeepLearningBased2020,
  title = {Deep {{Learning Based Cell Imaging}} with {{Electrical Impedance Tomography}}},
  booktitle = {2020 {{IEEE International Instrumentation}} and {{Measurement Technology Conference}} ({{I2MTC}})},
  author = {Chen, Zhou and Yang, Yunjie and Jia, Jiabin and Bagnaninchi, Pierre},
  date = {2020-05},
  pages = {1--6},
  publisher = {IEEE},
  location = {Dubrovnik, Croatia},
  doi = {10.1109/I2MTC43012.2020.9128764},
  url = {https://ieeexplore.ieee.org/document/9128764/},
  urldate = {2024-07-03},
  abstract = {Monitoring the 3-D cell culture process or drug responses non-destructively using Electrical Impedance Tomography (EIT) is an emerging topic in biomedical imaging. Significant efforts have been spent on developing EIT image reconstruction algorithms in order to achieve robust and high-quality cell imaging. The considerable computation time and imperfect image quality are the main issues of these conventional methods whereas the emergence of deep learning techniques point out a new direction due to its fast inferences on object detection, image segmentation and classification. In this paper, a novel deep learning architecture is proposed by adding a fully connected layer before a U-Net structure. This new architecture will first generate an initial guess of the conductivity distribution and then feed it to the following denoising model. A novel initialization strategy is also proposed to further help obtain this initial guess. The performance of the method is verified by simulation and experimental data. The results show that the proposed model outperforms the state-of-the-art EIT algorithms and can generalize well to reconstruct unseen cases consisting of human breast cancer cell pellet.},
  eventtitle = {2020 {{IEEE International Instrumentation}} and {{Measurement Technology Conference}} ({{I2MTC}})},
  isbn = {978-1-72814-460-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Deep_Learning_Based_Cell_Imaging_with_Electrical_Impedance_Tomography_Chen_et_al_2020.pdf}
}

@article{chenDensitiesViscositiesRefractive2005,
  title = {Densities, {{Viscosities}}, and {{Refractive Indices}} for {{Binary}} and {{Ternary Mixtures}} of {{Acetone}}, {{Ethanol}}, and 2,2,4-{{Trimethylpentane}}},
  author = {Chen, Hui-Wen and Tu, Chein-Hsiun},
  date = {2005-07-01},
  journaltitle = {J. Chem. Eng. Data},
  volume = {50},
  number = {4},
  pages = {1262--1269},
  issn = {0021-9568, 1520-5134},
  doi = {10.1021/je050010l},
  url = {https://pubs.acs.org/doi/10.1021/je050010l},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Densities,_Viscosities,_and_Refractive_Indices_for_Binary_and_Ternary_Mixtures_Chen_Tu_2005.pdf}
}

@online{chenEndoGaussiansSingleView2024,
  title = {{{EndoGaussians}}: {{Single View Dynamic Gaussian Splatting}} for {{Deformable Endoscopic Tissues Reconstruction}}},
  shorttitle = {{{EndoGaussians}}},
  author = {Chen, Yangsen and Wang, Hao},
  date = {2024-01-24},
  eprint = {2401.13352},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.13352},
  urldate = {2024-02-21},
  abstract = {The accurate 3D reconstruction of deformable soft body tissues from endoscopic videos is a pivotal challenge in medical applications such as VR surgery and medical image analysis. Existing methods often struggle with accuracy and the ambiguity of hallucinated tissue parts, limiting their practical utility. In this work, we introduce EndoGaussians, a novel approach that employs Gaussian Splatting for dynamic endoscopic 3D reconstruction. This method marks the first use of Gaussian Splatting in this context, overcoming the limitations of previous NeRF-based techniques. Our method sets new state-of-the-art standards, as demonstrated by quantitative assessments on various endoscope datasets. These advancements make our method a promising tool for medical professionals, offering more reliable and efficient 3D reconstructions for practical applications in the medical field.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Endoscope\EndoGaussians_Chen_Wang_2024.pdf}
}

@article{cheneyElectricalImpedanceTomography,
  title = {Electrical {{Impedance Tomography}}},
  author = {Cheney, Margaret and Isaacson, David and Newell, Jonathan C},
  abstract = {This paper surveys some of the work our group has done in electrical impedance tomography.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\Electrical_Impedance_Tomography_Cheney_et_al_.pdf}
}

@article{chengBroadForbiddenBands2008,
  title = {Broad Forbidden Bands in Parallel-Coupled Locally Resonant Ultrasonic Metamaterials},
  author = {Cheng, Y. and Xu, J. Y. and Liu, X. J.},
  date = {2008-02-04},
  journaltitle = {Applied Physics Letters},
  volume = {92},
  number = {5},
  pages = {051913},
  issn = {0003-6951, 1077-3118},
  doi = {10.1063/1.2839401},
  url = {https://pubs.aip.org/apl/article/92/5/051913/928183/Broad-forbidden-bands-in-parallel-coupled-locally},
  urldate = {2023-09-05},
  abstract = {The authors demonstrate that a class of ultrasonic metamaterial, which is composed of subwavelength resonant units built up by parallel-coupled Helmholtz resonators with identical resonant frequency, possesses broad locally resonant forbidden bands. The bandwidths are strongly dependent on the number of resonators in each unit. The broadening of bands is ascribed to the change of effective acoustic impendence. The coupling effects on the wave vector and negative dynamic modulus are discussed. Numerical simulations by finite element method further confirm the theoretical results.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\SpecialEffects\NegativeMassDensity\Broad_forbidden_bands_in_parallel-coupled_locally_resonant_ultrasonic_Cheng_et_al_2008.pdf}
}

@inproceedings{chenGeneralizableTumorSynthesis2024,
  title = {Towards {{Generalizable Tumor Synthesis}}},
  booktitle = {2024 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Chen, Qi and Chen, Xiaoxi and Song, Haorui and Xiong, Zhiwei and Yuille, Alan and Wei, Chen and Zhou, Zongwei},
  date = {2024-06},
  pages = {11147--11158},
  issn = {2575-7075},
  doi = {10.1109/CVPR52733.2024.01060},
  url = {https://ieeexplore.ieee.org/document/10656868},
  urldate = {2024-12-13},
  abstract = {Tumor synthesis enables the creation of artificial tumors in medical images, facilitating the training of AI models for tumor detection and segmentation. However, success in tumor synthesis hinges on creating visually realistic tumors that are generalizable across multiple organs and, furthermore, the resulting AI models being capable of detecting real tumors in images sourced from different domains (e.g., hospitals). This paper made a progressive stride toward generalizable tumor synthesis by leveraging a critical observation: early-stage tumors ({$<$} 2cm) tend to have similar imaging characteristics in computed tomography (CT), whether they originate in the liver, pancreas, or kidneys. We have ascertained that generative AI models, e.g., Diffusion Models, can create realistic tumors generalized to a range of organs even when trained on a limited number of tumor examples from only one organ. Moreover, we have shown that AI models trained on these synthetic tumors can be generalized to detect and segment real tumors from CT volumes, encompassing a broad spectrum of patient demographics, imaging protocols, and healthcare facilities.},
  eventtitle = {2024 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  keywords = {Computational modeling,Computed tomography,Computed Tomography,Diffusion Model,Hospitals,Image segmentation,Liver,Medical Image Segmentation,Medical Image Synthesis,Training,Training data,Tumor Detection,Tumor Segmentation,Tumor Synthesis},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\Medical\Towards_Generalizable_Tumor_Chen_et_al_2024.pdf}
}

@inproceedings{chenGenerativePretrainingPixels2020,
  title = {Generative {{Pretraining From Pixels}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
  date = {2020-11-21},
  pages = {1691--1703},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v119/chen20s.html},
  urldate = {2024-12-13},
  abstract = {Inspired by progress in unsupervised representation learning for natural language, we examine whether similar models can learn useful representations for images. We train a sequence Transformer to auto-regressively predict pixels, without incorporating knowledge of the 2D input structure. Despite training on low-resolution ImageNet without labels, we find that a GPT-2 scale model learns strong image representations as measured by linear probing, fine-tuning, and low-data classification. On CIFAR-10, we achieve 96.3\% accuracy with a linear probe, outperforming a supervised Wide ResNet, and 99.0\% accuracy with full fine-tuning, matching the top supervised pre-trained models. We are also competitive with self-supervised benchmarks on ImageNet when substituting pixels for a VQVAE encoding, achieving 69.0\% top-1 accuracy on a linear probe of our features.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\VisionTransformer\Generative_Pretraining_From_Chen_et_al_2020.pdf}
}

@online{chenGenerativeVisualCompression2024,
  title = {Generative {{Visual Compression}}: {{A Review}}},
  shorttitle = {Generative {{Visual Compression}}},
  author = {Chen, Bolin and Yin, Shanzhi and Chen, Peilin and Wang, Shiqi and Ye, Yan},
  date = {2024-02-03},
  eprint = {2402.02140},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.02140},
  url = {http://arxiv.org/abs/2402.02140},
  urldate = {2024-12-23},
  abstract = {Artificial Intelligence Generated Content (AIGC) is leading a new technical revolution for the acquisition of digital content and impelling the progress of visual compression towards competitive performance gains and diverse functionalities over traditional codecs. This paper provides a thorough review on the recent advances of generative visual compression, illustrating great potentials and promising applications in ultra-low bitrate communication, user-specified reconstruction/filtering, and intelligent machine analysis. In particular, we review the visual data compression methodologies with deep generative models, and summarize how compact representation and high-fidelity reconstruction could be actualized via generative techniques. In addition, we generalize related generative compression technologies for machine vision and intelligent analytics. Finally, we discuss the fundamental challenges on generative visual compression techniques and envision their future research directions.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Generative_Visual_Compression_Chen_et_al_2024.pdf}
}

@online{chengLearnedImageCompression2020,
  title = {Learned {{Image Compression}} with {{Discretized Gaussian Mixture Likelihoods}} and {{Attention Modules}}},
  author = {Cheng, Zhengxue and Sun, Heming and Takeuchi, Masaru and Katto, Jiro},
  date = {2020-03-30},
  eprint = {2001.01568},
  eprinttype = {arXiv},
  eprintclass = {eess},
  doi = {10.48550/arXiv.2001.01568},
  url = {http://arxiv.org/abs/2001.01568},
  urldate = {2024-08-20},
  abstract = {Image compression is a fundamental research field and many well-known compression standards have been developed for many decades. Recently, learned compression methods exhibit a fast development trend with promising results. However, there is still a performance gap between learned compression algorithms and reigning compression standards, especially in terms of widely used PSNR metric. In this paper, we explore the remaining redundancy of recent learned compression algorithms. We have found accurate entropy models for rate estimation largely affect the optimization of network parameters and thus affect the rate-distortion performance. Therefore, in this paper, we propose to use discretized Gaussian Mixture Likelihoods to parameterize the distributions of latent codes, which can achieve a more accurate and flexible entropy model. Besides, we take advantage of recent attention modules and incorporate them into network architecture to enhance the performance. Experimental results demonstrate our proposed method achieves a state-of-the-art performance compared to existing learned compression methods on both Kodak and high-resolution datasets. To our knowledge our approach is the first work to achieve comparable performance with latest compression standard Versatile Video Coding (VVC) regarding PSNR. More importantly, our approach generates more visually pleasant results when optimized by MS-SSIM. This project page is at this https URL https://github.com/ZhengxueCheng/Learned-Image-Compression-with-GMM-and-Attention},
  pubstate = {prepublished},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Learned_Image_Compression_Cheng_et_al_2020.pdf}
}

@article{chenHybridLearningBasedCell2021,
  title = {Hybrid {{Learning-Based Cell Aggregate Imaging With Miniature Electrical Impedance Tomography}}},
  author = {Chen, Zhou and Yang, Yunjie and Bagnaninchi, Pierre-Olivier},
  date = {2021},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {70},
  pages = {1--10},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2020.3035384},
  url = {https://ieeexplore.ieee.org/document/9247286/},
  urldate = {2024-07-08},
  abstract = {Real-time, nondestructive, and label-free imaging of 3-D cell culture process using miniature Electrical Impedance Tomography (mEIT) is an emerging topic in tissue engineering. Image reconstruction of mEIT for cell culture is challenging due to weak sensing signals and increased sensitivity to sensor imperfection. Conventional regularization-based image reconstruction methods cannot always achieve satisfactory performance in terms of image quality and computational efficiency for this particular setup. Recent advances in deep learning have pointed out a promising alternative. However, with a single neural network, it is still difficult to reconstruct multiple objects with varying conductivity levels; these cases are widespread in the application of cell imaging. Aiming at this challenge, in this article, we propose a deep learning and group sparsity (GS) regularization-based hybrid algorithm for cell imaging with mEIT. A deep neural network is proposed to estimate the structural information in form of binary masks given the limited amount of data sets. Then, the structural information is encoded in the GS regularization to obtain the final estimation of conductivity. The proposed approach is validated by both simulation and experimental data on MCF-7 human breast cancer cell aggregates, which demonstrates its superior performance and generalization ability compared with a number of existing algorithms.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\CellCulture\Hybrid_Learning-Based_Cell_Aggregate_Imaging_With_Miniature_Electrical_Chen_et_al_2021.pdf}
}

@online{chenHyperspectralNeuralRadiance2024,
  title = {Hyperspectral {{Neural Radiance Fields}}},
  author = {Chen, Gerry and Narayanan, Sunil Kumar and Ottou, Thomas Gautier and Missaoui, Benjamin and Muriki, Harsh and Pradalier, Cédric and Chen, Yongsheng},
  date = {2024-03-21},
  eprint = {2403.14839},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.14839},
  urldate = {2024-06-12},
  abstract = {Hyperspectral Imagery (HSI) has been used in many applications to non-destructively determine the material and/or chemical compositions of samples. There is growing interest in creating 3D hyperspectral reconstructions, which could provide both spatial and spectral information while also mitigating common HSI challenges such as nonLambertian surfaces and translucent objects. However, traditional 3D reconstruction with HSI is difficult due to technological limitations of hyperspectral cameras. In recent years, Neural Radiance Fields (NeRFs) have seen widespread success in creating high quality volumetric 3D representations of scenes captured by a variety of camera models. Leveraging recent advances in NeRFs, we propose computing a hyperspectral 3D reconstruction in which every point in space and view direction is characterized by wavelength-dependent radiance and transmittance spectra. To evaluate our approach, a dataset containing nearly 2000 hyperspectral images across 8 scenes and 2 cameras was collected. We perform comparisons against traditional RGB NeRF baselines and apply ablation testing with alternative spectra representations. Finally, we demonstrate the potential of hyperspectral NeRFs for hyperspectral super-resolution and imaging sensor simulation. We show that our hyperspectral NeRF approach enables creating fast, accurate volumetric 3D hyperspectral scenes and enables several new applications and areas for future study.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\MultiSpectral\Hyperspectral_Neural_Radiance_Fields_Chen_et_al_2024.pdf}
}

@article{chenMaskGuidedSpatialTemporal2022,
  title = {Mask-{{Guided Spatial}}–{{Temporal Graph Neural Network}} for {{Multifrequency Electrical Impedance Tomography}}},
  author = {Chen, Zhou and Liu, Zhe and Ai, Lulu and Zhang, Sheng and Yang, Yunjie},
  date = {2022},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {71},
  pages = {1--10},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2022.3197804},
  url = {https://ieeexplore.ieee.org/document/9853625/},
  urldate = {2024-07-03},
  abstract = {Multifrequency electrical impedance tomography (mfEIT) is an emerging biomedical imaging modality that exploits frequency-dependent electrical properties. The mfEIT image reconstruction problem for cell imaging is particularly challenging due to weak signals from miniaturized sensors and high sensitivity to modeling errors. The existing approaches are primarily based on the linearized model and few are applied to the miniaturized setup. Here, we report a mask-guided spatial–temporal graph neural network (M-STGNN) to reconstruct mfEIT images in cell culture imaging. The M-STGNN captures simultaneously spatial and frequency correlations, and the spatial correlation is further constrained by geometric structures from auxiliary binary masks, such as computed tomography (CT) or microscopic images. We validate the mfEIT approach through numerical simulations and experiments on MCF-7 human breast cancer cell aggregates. The results demonstrate the superiority of M-STGNN over the state-of-the-art with an improvement of approximately 10.7\% under the experimental setup. It can be readily extended to multimodal biomedical imaging applications.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\GraphNeuralNetwork\Mask-Guided_Spatial–Temporal_Graph_Neural_Network_for_Multifrequency_Electrical_Chen_et_al_2022.pdf}
}

@article{chenMMVNetMultipleMeasurement2023,
  title = {{{MMV-Net}}: {{A Multiple Measurement Vector Network}} for {{Multifrequency Electrical Impedance Tomography}}},
  shorttitle = {{{MMV-Net}}},
  author = {Chen, Zhou and Xiang, Jinxi and Bagnaninchi, Pierre-Olivier and Yang, Yunjie},
  date = {2023-11},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {34},
  number = {11},
  pages = {8938--8949},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2022.3154108},
  url = {https://ieeexplore.ieee.org/document/9732193/},
  urldate = {2024-07-03},
  abstract = {Multifrequency electrical impedance tomography (mfEIT) is an emerging biomedical imaging modality to reveal frequency-dependent conductivity distributions in biomedical applications. Conventional model-based image reconstruction methods suffer from low spatial resolution, unconstrained frequency correlation, and high computational cost. Deep learning has been extensively applied in solving the EIT inverse problem in biomedical and industrial process imaging. However, most existing learning-based approaches deal with the single-frequency setup, which is inefficient and ineffective when extended to the multifrequency setup. This article presents a multiple measurement vector (MMV) model-based learning algorithm named MMV-Net to solve the mfEIT image reconstruction problem. MMV-Net considers the correlations between mfEIT images and unfolds the update steps of the Alternating Direction Method of Multipliers for the MMV problem (MMV-ADMM). The nonlinear shrinkage operator associated with the weighted l2,1 regularization term of MMV-ADMM is generalized in MMV-Net with a cascade of a Spatial Self-Attention module and a Convolutional Long Short-Term Memory (ConvLSTM) module to better capture intrafrequency and interfrequency dependencies. The proposed MMV-Net was validated on our Edinburgh mfEIT Dataset and a series of comprehensive experiments. The results show superior image quality, convergence performance, noise robustness, and computational efficiency against the conventional MMV-ADMM and the state-of-the-art deep learning methods.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Attention\MMV-Net_Chen_et_al_2023.pdf}
}

@online{chenMobileNeRFExploitingPolygon2023,
  title = {{{MobileNeRF}}: {{Exploiting}} the {{Polygon Rasterization Pipeline}} for {{Efficient Neural Field Rendering}} on {{Mobile Architectures}}},
  shorttitle = {{{MobileNeRF}}},
  author = {Chen, Zhiqin and Funkhouser, Thomas and Hedman, Peter and Tagliasacchi, Andrea},
  date = {2023-05-29},
  eprint = {2208.00277},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.00277},
  urldate = {2024-02-05},
  abstract = {Neural Radiance Fields (NeRFs) have demonstrated amazing ability to synthesize images of 3D scenes from novel views. However, they rely upon specialized volumetric rendering algorithms based on ray marching that are mismatched to the capabilities of widely deployed graphics hardware. This paper introduces a new NeRF representation based on textured polygons that can synthesize novel images efficiently with standard rendering pipelines. The NeRF is represented as a set of polygons with textures representing binary opacities and feature vectors. Traditional rendering of the polygons with a z-buffer yields an image with features at every pixel, which are interpreted by a small, view-dependent MLP running in a fragment shader to produce a final pixel color. This approach enables NeRFs to be rendered with the traditional polygon rasterization pipeline, which provides massive pixel-level parallelism, achieving interactive frame rates on a wide range of compute platforms, including mobile phones.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\General\MobileNeRF_Chen_et_al_2023.pdf}
}

@article{chenNarrowbandReflectionandtransmissionFilter2012,
  title = {Narrowband Reflection-and-Transmission Filter in an Annular Defective Photonic Crystal Containing an Ultrathin Metallic Film},
  author = {Chen, Mei-Soong and Wu, Chien-Jang and Yang, Tzong-Jer},
  date = {2012-06},
  journaltitle = {Optics Communications},
  volume = {285},
  number = {13-14},
  pages = {3143--3149},
  issn = {00304018},
  doi = {10.1016/j.optcom.2012.02.087},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0030401812002404},
  urldate = {2023-11-06},
  abstract = {The filtering properties for a narrowband reflection-and-transmission filter in an annular defective photonic crystal containing an ultrathin and strongly lossy metallic film are theoretically investigated based on the transfer matrix method for the cylindrical Bragg waves. At a certain design wavelength, simultaneous peaks in reflectance and transmittance can be found. The peak wavelength is shown to be dependent on the azimuthal mode number of the cylindrical waves. The peak heights in reflectance and transmittance can be directly varied by the stack numbers. In addition, the influence of the starting radius in reflectance and transmittance is also illustrated.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Narrowband_reflection-and-transmission_filter_in_an_annular_defective_photonic_Chen_et_al_2012.pdf}
}

@article{chenOpticalPropertiesSuperconducting2009,
  title = {Optical Properties of a Superconducting Annular Periodic Multilayer Structure},
  author = {Chen, Mei-Soong and Wu, Chien-Jang and Yang, Tzong-Jer},
  date = {2009-11},
  journaltitle = {Solid State Communications},
  volume = {149},
  number = {43-44},
  pages = {1888--1893},
  issn = {00381098},
  doi = {10.1016/j.ssc.2009.08.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0038109809004852},
  urldate = {2023-11-06},
  abstract = {The optical properties of a superconducting annular Bragg reflector (SABR) are theoretically investigated based on the transfer matrix method for the cylindrical waves. For TM wave at an azimuthal mode number, m ≥ 1, it is found that there exist some novelties compared with the usual superconducting planar Bragg reflector (SPBR). An additional high-reflectance band is seen and some reflection dips near the threshold wavelength of a superconductor are generated as well. These two special results arising from the higher order azimuthal mode of the cylindrical waves are not found in the SPBR. The results suggest that the SABR could be used to design a narrowband transmission filter or an annular resonator without introducing any physical defect layer in the structure.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Optical_properties_of_a_superconducting_annular_periodic_multilayer_structure_Chen_et_al_2009.pdf}
}

@inproceedings{chenSCACNNSpatialChannelWise2017,
  title = {{{SCA-CNN}}: {{Spatial}} and {{Channel-Wise Attention}} in {{Convolutional Networks}} for {{Image Captioning}}},
  shorttitle = {{{SCA-CNN}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Chen, Long and Zhang, Hanwang and Xiao, Jun and Nie, Liqiang and Shao, Jian and Liu, Wei and Chua, Tat-Seng},
  date = {2017-07},
  pages = {6298--6306},
  publisher = {IEEE},
  location = {Honolulu, HI},
  doi = {10.1109/CVPR.2017.667},
  url = {http://ieeexplore.ieee.org/document/8100150/},
  urldate = {2023-08-26},
  abstract = {Visual attention has been successfully applied in structural prediction tasks such as visual captioning and question answering. Existing visual attention models are generally spatial, i.e., the attention is modeled as spatial probabilities that re-weight the last conv-layer feature map of a CNN encoding an input image. However, we argue that such spatial attention does not necessarily conform to the attention mechanism — a dynamic feature extractor that combines contextual fixations over time, as CNN features are naturally spatial, channel-wise and multi-layer. In this paper, we introduce a novel convolutional neural network dubbed SCA-CNN that incorporates Spatial and Channelwise Attentions in a CNN. In the task of image captioning, SCA-CNN dynamically modulates the sentence generation context in multi-layer feature maps, encoding where (i.e., attentive spatial locations at multiple layers) and what (i.e., attentive channels) the visual attention is. We evaluate the proposed SCA-CNN architecture on three benchmark image captioning datasets: Flickr8K, Flickr30K, and MSCOCO. It is consistently observed that SCA-CNN significantly outperforms state-of-the-art visual attention-based image captioning methods.},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-0457-1},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\ConvolutionOnChannels\SCA-CNN_Chen_et_al_2017.pdf}
}

@article{chenStackedAutoencoderNeural2020,
  title = {A {{Stacked Autoencoder Neural Network Algorithm}} for {{Breast Cancer Diagnosis With Magnetic Detection Electrical Impedance Tomography}}},
  author = {Chen, Ruijuan and Wu, Weiwei and Qi, Haofeng and Wang, Jinhai and Wang, Huiquan},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {5428--5437},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2961810},
  url = {https://ieeexplore.ieee.org/document/8939559/},
  urldate = {2024-07-03},
  abstract = {Magnetic detection electrical impedance tomography (MDEIT) is a novel imaging technique that aims to reconstruct the conductivity distribution with electrical current injection and the external magnetic flux density measurement by magnetic sensors. Aiming at improving the resolution and accuracy of MDEIT and providing an efficient imaging method for breast cancer diagnosis, a new algorithm based on stacked auto-encoder (SAE) neural network is proposed. Both numerical simulation and phantom experiments are done to verify its feasibility. In the numerical simulation, an amount of sample data with different conductivity distribution are calculated. Then a neural network model is established and trained by training these samples. Finally, the conductivity distribution of an imaging target with the anomaly location can be reconstructed by the network model. The reconstruction result of the SAE algorithm is compared with the reconstruction results of the traditional sensitivity matrix (SM) algorithm and the back propagation (BP) neural network algorithm. Under the noise of 30dB, the relative errors of BP algorithm, SM algorithm and SAE algorithm are 137.19\%, 24.90\% and 15.28\% respectively. Result shows by the SAE algorithm, the location of anomalies is reconstructed more accurately, the conductivity value is more closely to the real one and the anti-noise performance is more robust. At last, a breast phantom experiment by self-made platforms is completed to verify the application feasibility of the new algorithm. The relative reconstruction error of conductivity by proposed SAE algorithm can be reduced to 14.56\%. The results show that by SAE algorithm, MDEIT can be a promising approach in clinical diagnosis of breast cancer, and it also provide more potential application prospect for the extensive application of MDEIT.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Autoencoder\A_Stacked_Autoencoder_Neural_Network_Algorithm_for_Breast_Cancer_Diagnosis_With_Chen_et_al_2020.pdf}
}

@article{chenStructureAwareDualBranchNetwork2021,
  title = {Structure-{{Aware Dual-Branch Network}} for {{Electrical Impedance Tomography}} in {{Cell Culture Imaging}}},
  author = {Chen, Zhou and Yang, Yunjie},
  date = {2021},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {70},
  pages = {1--9},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2021.3092524},
  url = {https://ieeexplore.ieee.org/document/9465170/},
  urldate = {2024-07-03},
  abstract = {Electrical impedance tomography (EIT) is an emerging imaging modality to monitor 3D cell culture dynamics through reconstructing the electrical properties of cell clusters. Recently, machine-learning (ML)-based approaches have achieved significant gains for the image reconstruction of EIT against conventional physical model-based methods. However, continuous, multilevel conductivity distributions, which commonly exists in cell culture imaging, are more rigorous to reconstruct and remains challenging. This article aims to tackle this challenge by proposing a structure-aware dual-branch deep-learning method to predict both structure distribution and conductivity values. The proposed network comprises two independent branches to encode the structure and conductivity features, respectively. The two branches are jointed later to make final predictions of conductivity distributions. Numerical and experimental evaluation results demonstrate the superior performance of the proposed method in dealing with the multilevel, continuous conductivity reconstruction problem.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Structure-Aware_Dual-Branch_Network_for_Electrical_Impedance_Tomography_in_Cell_Chen_Yang_2021.pdf}
}

@article{chenStudyBandGaps2007,
  title = {Study on Band Gaps of Elastic Waves Propagating in One-Dimensional Disordered Phononic Crystals},
  author = {Chen, A.-Li and Wang, Yue-Sheng},
  date = {2007-04},
  journaltitle = {Physica B: Condensed Matter},
  volume = {392},
  number = {1-2},
  pages = {369--378},
  issn = {09214526},
  doi = {10.1016/j.physb.2006.12.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0921452606018746},
  urldate = {2023-09-05},
  abstract = {Band gaps of elastic waves, both in-plane and anti-plane waves, propagating along arbitrary direction in one-dimensional disordered phononic crystals are studied in this paper. The localization of wave propagation due to random disorder is discussed by introducing the concept of the localization factor. As a special case between ordered and disordered structures, we analyze the properties of the band gaps of phononic crystals with quasi-periodicity (i.e. phononic quasicrystals). Compared with the periodic structure, phononic quasicrystals involve more bands with localization of wave motion. The transmission coefficients are also calculated and the results show the same behaviors as the localization factor does. Therefore, the localization factor may act as an accurate and efficient parameter to characterize band structures of both ordered and disordered (including quasi-periodic) phononic crystals.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Study_on_band_gaps_of_elastic_waves_propagating_in_one-dimensional_disordered_Chen_Wang_2007.pdf}
}

@article{chenTwoStageOctaveResidual2022,
  title = {Two-{{Stage Octave Residual Network}} for {{End-to-End Image Compression}}},
  author = {Chen, Fangdong and Xu, Yumeng and Wang, Li},
  date = {2022-06-28},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {36},
  number = {4},
  pages = {3922--3929},
  issn = {2374-3468},
  doi = {10.1609/aaai.v36i4.20308},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/20308},
  urldate = {2024-11-26},
  abstract = {Octave Convolution (OctConv) is a generic convolutional unit that has already achieved good performances in many computer vision tasks. Recent studies also have shown the potential of applying the OctConv in end-to-end image compression. However, considering the characteristic of image compression task, current works of OctConv may limit the performance of the image compression network due to the loss of spatial information caused by the sampling operations of inter-frequency communication. Besides, the correlation between multi-frequency latents produced by OctConv is not utilized in current architectures. In this paper, to address these problems, we propose a novel Two-stage Octave Residual (ToRes) block which strips the sampling operation from OctConv to strengthen the capability of preserving useful information. Moreover, to capture the redundancy between the multi-frequency latents, a context transfer module is designed. The results show that both ToRes block and the incorporation of context transfer module help to improve the Rate-Distortion performance, and the combination of these two strategies makes our model achieve the state-of-the-art performance and outperform the latest compression standard Versatile Video Coding (VVC) in terms of both PSNR and MS-SSIM.},
  issue = {4},
  langid = {english},
  keywords = {Computer Vision (CV)},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Two-Stage_Octave_Residual_Chen_et_al_2022.pdf}
}

@article{chettahTunablePropertiesOptical2021,
  title = {Tunable {{Properties}} of {{Optical Selective Filters Based}} on {{One-Dimensional Plasma Superconductor Photonic Crystal}}},
  author = {Chettah, Chouaib and Barkat, Ouarda and Chaabi, Abdelhafidh},
  date = {2021-09},
  journaltitle = {J Supercond Nov Magn},
  volume = {34},
  number = {9},
  pages = {2239--2248},
  issn = {1557-1939, 1557-1947},
  doi = {10.1007/s10948-021-05891-1},
  url = {https://link.springer.com/10.1007/s10948-021-05891-1},
  urldate = {2024-01-22},
  abstract = {In this paper, a new design and analysis of tunable optical selective filters containing one-dimensional photonic crystal (1D-PC), magnetized cold plasma, and superconducting materials are investigated using transfer matrix method. The effects of defective layers on transmission spectrum, the cutoff frequency, and the peak position are investigated as the function of the magnetic field and the thickness of the superconductor layer. It is found that the peak frequencies and the cutoff frequencies are affected significantly by the magnetic field applied and number of defectives layers. Also, it is demonstrated that the superconductor layer has a significant effect on the transmission spectrum. Results obtained confirmed that it is possible to make a model of a highly selective tunable filter using photonic one-dimensional plasma superconductor photonic crystal.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Tunable_Properties_of_Optical_Selective_Filters_Based_on_One-Dimensional_Plasma_Chettah_et_al_2021.pdf}
}

@article{chiuONEDIMENSIONALWAVEPROPAGATION1999,
  title = {{{ONE-DIMENSIONAL WAVE PROPAGATION IN A FUNCTIONALLY GRADED ELASTIC MEDIUM}}},
  author = {Chiu, T.-C. and Erdogan, F.},
  date = {1999-05},
  journaltitle = {Journal of Sound and Vibration},
  volume = {222},
  number = {3},
  pages = {453--487},
  issn = {0022460X},
  doi = {10.1006/jsvi.1998.2065},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022460X9892065X},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\ONE-DIMENSIONAL_WAVE_PROPAGATION_IN_A_FUNCTIONALLY_GRADED_ELASTIC_MEDIUM_Chiu_Erdogan_1999.pdf}
}

@online{CLICChallengeLearned,
  title = {{{CLIC}} · {{Challenge}} on {{Learned Image Compression}}},
  url = {https://clic.compression.cc/2021/tasks/index.html},
  urldate = {2024-12-06}
}

@article{collenetteExplainableAITools2023,
  title = {Explainable {{AI}} Tools for Legal Reasoning about Cases: {{A}} Study on the {{European Court}} of {{Human Rights}}},
  shorttitle = {Explainable {{AI}} Tools for Legal Reasoning about Cases},
  author = {Collenette, Joe and Atkinson, Katie and Bench-Capon, Trevor},
  date = {2023-04-01},
  journaltitle = {Artificial Intelligence},
  volume = {317},
  pages = {103861},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2023.103861},
  url = {https://www.sciencedirect.com/science/article/pii/S0004370223000073},
  urldate = {2024-07-03},
  abstract = {In this paper we report on a significant research project undertaken to design, implement and evaluate explainable decision-support tools for deciding legal cases. We provide a model of a legal domain, Article 6 of the European Convention on Human Rights, constructed using a methodology from the field of computational models of argument. We describe how the formal model has been developed, extended and transformed into practical tools, which were then used in evaluation exercises to determine the effectiveness and usability of the tools. The underpinning AI techniques used yield a level of explanation that is firmly grounded in legal reasoning and is also digestible by the target end users, as demonstrated through our evaluation activities. The results of our experimental evaluation show that on the first pass, our tool achieved an accuracy rate of 97\% in matching the actual decisions of the cases and the user studies conducted gave highly encouraging results with respect to usability. As such, our project demonstrates how trustworthy AI tools can be built for a real world legal domain where critical needs of the end users are accounted for.},
  keywords = {Computational models of argument,European Convention on Human Rights,Explainable AI,Legal reasoning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Strategies\Reasoning\Explainable_AI_tools_for_legal_reasoning_about_cases_Collenette_et_al_2023.pdf}
}

@article{condeAnalysisSoundVelocity1982,
  title = {Analysis of Sound Velocity in Supercoled {{H2O}}, {{D2O}}, and Water–Ethanol Mixtures},
  author = {Conde, O. and Teixeira, J. and Papon, P.},
  date = {1982-04-01},
  journaltitle = {The Journal of Chemical Physics},
  volume = {76},
  number = {7},
  pages = {3747--3753},
  issn = {0021-9606, 1089-7690},
  doi = {10.1063/1.443413},
  url = {https://pubs.aip.org/jcp/article/76/7/3747/392515/Analysis-of-sound-velocity-in-supercoled-H2O-D2O},
  urldate = {2023-09-05},
  abstract = {Measurements of the sound velocity c in water, heavy water, and water–ethanol mixtures have been carried out in a temperature range extending from room temperature to the supercooled region above -20\,°C, by Brillouin light scattering technique. Pure H2O and D2O show a strong anomalous behavior which can be described by critical laws. The addition of ethanol to water decreases the importance of the anomalies, and the sound velocity c(T) is no longer described by critical laws. For some concentrations, a minimum in the curve c(T) is observed at low temperatures. The adiabatic compressibility is evaluated for all the samples and discussed for different theoretical models. Arguments are given in favor of a percolation model of supercooled water.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Analysis_of_sound_velocity_in_supercoled_H2O,_D2O,_and_water–ethanol_mixtures_Conde_et_al_1982.pdf}
}

@article{Control_of_Longitudinal_Wave_Propagation_in_Conical_Periodic_Structures_Tongele_Chen_2004Pdf,
  title = {Control\_of\_{{Longitudinal}}\_{{Wave}}\_{{Propagation}}\_in\_{{Conical}}\_{{Periodic}}\_{{Structures}}\_{{Tongele}}\_{{Chen}}\_2004.Pdf},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Control_of_Longitudinal_Wave_Propagation_in_Conical_Periodic_Structures_Tongele__.pdf}
}

@article{corneliusModificationPlanckBlackbody1999,
  title = {Modification of {{Planck}} Blackbody Radiation by Photonic Band-Gap Structures},
  author = {Cornelius, Christopher M. and Dowling, Jonathan P.},
  date = {1999-06-01},
  journaltitle = {Phys. Rev. A},
  volume = {59},
  number = {6},
  pages = {4736--4746},
  issn = {1050-2947, 1094-1622},
  doi = {10.1103/PhysRevA.59.4736},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.59.4736},
  urldate = {2024-06-01},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\BlackBodyRadiation\Modification_of_Planck_blackbody_radiation_by_photonic_band-gap_structures_Cornelius_Dowling_1999.pdf}
}

@inproceedings{corona-figueroaMedNeRFMedicalNeural2022,
  title = {{{MedNeRF}}: {{Medical Neural Radiance Fields}} for {{Reconstructing 3D-aware CT-Projections}} from a {{Single X-ray}}},
  shorttitle = {{{MedNeRF}}},
  booktitle = {2022 44th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} \& {{Biology Society}} ({{EMBC}})},
  author = {Corona-Figueroa, Abril and Frawley, Jonathan and Taylor, Sam Bond- and Bethapudi, Sarath and Shum, Hubert P. H. and Willcocks, Chris G.},
  date = {2022-07},
  pages = {3843--3848},
  issn = {2694-0604},
  doi = {10.1109/EMBC48229.2022.9871757},
  url = {https://ieeexplore.ieee.org/abstract/document/9871757?casa_token=KqDKVvt4lccAAAAA:G6MNlcxh0IrVbAO6zbfUVtLxB25pPsAiSqFSmLD8y_r4Z4GR2l0yRAToBD5apBk5-h_EuADHuCM},
  urldate = {2024-08-20},
  abstract = {Computed tomography (CT) is an effective med-ical imaging modality, widely used in the field of clinical medicine for the diagnosis of various pathologies. Advances in Multidetector CT imaging technology have enabled additional functionalities, including generation of thin slice multi planar cross-sectional body imaging and 3D reconstructions. However, this involves patients being exposed to a considerable dose of ionising radiation. Excessive ionising radiation can lead to deterministic and harmful effects on the body. This paper proposes a Deep Learning model that learns to reconstruct CT projections from a few or even a single-view X-ray. This is based on a novel architecture that builds from neural radiance fields, which learns a continuous representation of CT scans by disentangling the shape and volumetric depth of surface and internal anatomical structures from 2D images. Our model is trained on chest and knee datasets, and we demonstrate qual-itative and quantitative high-fidelity renderings and compare our approach to other recent radiance field-based methods. Our code and link to our datasets are available at https://qithub.com/abrilcf/mednerf Clinical relevance- Our model is able to infer the anatomical 3D structure from a few or a single-view X-ray showing future potential for reduced ionising radiation exposure during the imaging process.},
  eventtitle = {2022 44th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} \& {{Biology Society}} ({{EMBC}})},
  keywords = {Computed tomography,Deep learning,Ionizing radiation,Shape,Solid modeling,Surface reconstruction,Three-dimensional displays},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Xray\MedNeRF_Corona-Figueroa_et_al_2022.pdf}
}

@article{coxAIAssistantHelp2024,
  title = {An {{AI}} Assistant to Help Review and Improve Causal Reasoning in Epidemiological Documents},
  author = {Cox, Louis Anthony},
  date = {2024-06-01},
  journaltitle = {Global Epidemiology},
  volume = {7},
  pages = {100130},
  issn = {2590-1133},
  doi = {10.1016/j.gloepi.2023.100130},
  url = {https://www.sciencedirect.com/science/article/pii/S2590113323000330},
  urldate = {2024-07-03},
  abstract = {Drawing sound causal inferences from observational data is often challenging for both authors and reviewers. This paper discusses the design and application of an Artificial Intelligence Causal Research Assistant (AIA) that seeks to help authors improve causal inferences and conclusions drawn from epidemiological data in health risk assessments. The AIA-assisted review process provides structured reviews and recommendations for improving the causal reasoning, analyses and interpretations made in scientific papers based on epidemiological data. Causal analysis methodologies range from earlier Bradford-Hill considerations to current causal directed acyclic graph (DAG) and related models. AIA seeks to make these methods more accessible and useful to researchers. AIA uses an external script (a “Causal AI Booster” (CAB) program based on classical AI concepts of slot-filling in frames organized into task hierarchies to complete goals) to guide Large Language Models (LLMs), such as OpenAI's ChatGPT or Google's LaMDA (Bard), to systematically review manuscripts and create both (a) recommendations for what to do to improve analyses and reporting; and (b) explanations and support for the recommendations. Review tables and summaries are completed systematically by the LLM in order. For example, recommendations for how to state and caveat causal conclusions in the Abstract and Discussion sections reflect previous analyses of the Study Design and Data Analysis sections. This work illustrates how current AI can contribute to reviewing and providing constructive feedback on research documents. We believe that such AI-assisted review shows promise for enhancing the quality of causal reasoning and exposition in epidemiological studies. It suggests the potential for effective human-AI collaboration in scientific authoring and review processes.},
  keywords = {Artificial intelligence,Causal AI boosting,Causality,Large language models (LLMs),Review methodology},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Strategies\Reasoning\An_AI_assistant_to_help_review_and_improve_causal_reasoning_in_epidemiological_Cox_2024.pdf}
}

@article{coxsonMachineLearningEnhanced2022,
  title = {Machine Learning Enhanced Electrical Impedance Tomography for {{2D}} Materials},
  author = {Coxson, Adam and Mihov, Ivo and Wang, Ziwei and Avramov, Vasil and Barnes, Frederik Brooke and Slizovskiy, Sergey and Mullan, Ciaran and Timokhin, Ivan and Sanderson, David and Kretinin, Andrey and Yang, Qian and Lionheart, William R B and Mishchenko, Artem},
  date = {2022-08-01},
  journaltitle = {Inverse Problems},
  volume = {38},
  number = {8},
  pages = {085007},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/1361-6420/ac7743},
  url = {https://iopscience.iop.org/article/10.1088/1361-6420/ac7743},
  urldate = {2024-07-03},
  abstract = {D-Bar U-Net convolutional neural network architecture was applied to postprocess conductivity map reconstructions from the GREIT algorithm (Hamilton and Hauptmann 2018 IEEE Trans. Med. Imaging 37 2367–77; Adler et al 2009 Physiol. Meas. 30 S35). The A-ESA offered around 20\% lower reconstruction losses in fewer measurements than the standard opposite–adjacent electrode selection algorithm, on both simulated data and when applied to a real graphene-based device. The CEM enhanced forward solver achieved a 3\% lower loss compared to the original pyEIT forward model. Finally, an experimental evaluation was performed on a graphene laminate film. Overall, this work demonstrates how EIT could be applied to 2D materials and highlights the utility of machine learning in both the experimental and analytical aspects of EIT.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Machine_learning_enhanced_electrical_impedance_tomography_for_2D_materials_Coxson_et_al_2022.pdf}
}

@article{cuiMultiscaleSpatialSpectralConvolutional2019,
  title = {Multiscale {{Spatial-Spectral Convolutional Network}} with {{Image-Based Framework}} for {{Hyperspectral Imagery Classification}}},
  author = {Cui, Ximin and Zheng, Ke and Gao, Lianru and Zhang, Bing and Yang, Dong and Ren, Jinchang},
  date = {2019-09-23},
  journaltitle = {Remote Sensing},
  volume = {11},
  number = {19},
  pages = {2220},
  issn = {2072-4292},
  doi = {10.3390/rs11192220},
  url = {https://www.mdpi.com/2072-4292/11/19/2220},
  urldate = {2023-08-26},
  abstract = {Jointly using spatial and spectral information has been widely applied to hyperspectral image (HSI) classification. Especially, convolutional neural networks (CNN) have gained attention in recent years due to their detailed representation of features. However, most of CNN-based HSI classification methods mainly use patches as input classifier. This limits the range of use for spatial neighbor information and reduces processing efficiency in training and testing. To overcome this problem, we propose an image-based classification framework that is efficient and straightforward. Based on this framework, we propose a multiscale spatial-spectral CNN for HSIs (HyMSCN) to integrate both multiple receptive fields fused features and multiscale spatial features at different levels. The fused features are exploited using a lightweight block called the multiple receptive field feature block (MRFF), which contains various types of dilation convolution. By fusing multiple receptive field features and multiscale spatial features, the HyMSCN has comprehensive feature representation for classification. Experimental results from three real hyperspectral images prove the efficiency of the proposed framework. The proposed method also achieves superior performance for HSI classification.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\Multiscale_Spatial-Spectral_Cui_et_al_2019.pdf}
}

@article{currieGenderEthnicityBias2024,
  title = {Gender and {{Ethnicity Bias}} of {{Text-to-Image Generative Artificial Intelligence}} in {{Medical Imaging}}, {{Part}} 1: {{Preliminary Evaluation}}},
  shorttitle = {Gender and {{Ethnicity Bias}} of {{Text-to-Image Generative Artificial Intelligence}} in {{Medical Imaging}}, {{Part}} 1},
  author = {Currie, Geoffrey and Hewis, Johnathan and Hawk, Elizabeth and Rohren, Eric},
  date = {2024-12-01},
  journaltitle = {Journal of Nuclear Medicine Technology},
  volume = {52},
  number = {4},
  eprint = {39438057},
  eprinttype = {pmid},
  pages = {356--359},
  publisher = {Society of Nuclear Medicine},
  issn = {0091-4916, 1535-5675},
  doi = {10.2967/jnmt.124.268332},
  url = {https://tech.snmjournals.org/content/52/4/356},
  urldate = {2024-12-06},
  abstract = {Generative artificial intelligence (AI) text-to-image production could reinforce or amplify gender and ethnicity biases. Several text-to-image generative AI tools are used for producing images that represent the medical imaging professions. White male stereotyping and masculine cultures can dissuade women and ethnically divergent people from being drawn into a profession. Methods: In March 2024, DALL-E 3, Firefly 2, Stable Diffusion 2.1, and Midjourney 5.2 were utilized to generate a series of individual and group images of medical imaging professionals: radiologist, nuclear medicine physician, radiographer, and nuclear medicine technologist. Multiple iterations of images were generated using a variety of prompts. Collectively, 184 images were produced for evaluation of 391 characters. All images were independently analyzed by 3 reviewers for apparent gender and skin tone. Results: Collectively (individual and group characters) (n = 391), 60.6\% were male and 87.7\% were of a light skin tone. DALL-E 3 (65.6\%), Midjourney 5.2 (76.7\%), and Stable Diffusion 2.1 (56.2\%) had a statistically higher representation of men than Firefly 2 (42.9\%) (P {$<$} 0.0001). With Firefly 2, 70.3\% of characters had light skin tones, which was statistically lower (P {$<$} 0.0001) than for Stable Diffusion 2.1 (84.8\%), Midjourney 5.2 (100\%), and DALL-E 3 (94.8\%). Overall, image quality metrics were average or better in 87.2\% for DALL-E 3 and 86.2\% for Midjourney 5.2, whereas 50.9\% were inadequate or poor for Firefly 2 and 86.0\% for Stable Diffusion 2.1. Conclusion: Generative AI text-to-image generation using DALL-E 3 via GPT-4 has the best overall quality compared with Firefly 2, Midjourney 5.2, and Stable Diffusion 2.1. Nonetheless, DALL-E 3 includes inherent biases associated with gender and ethnicity that demand more critical evaluation.},
  langid = {english},
  keywords = {diversity,generative artificial intelligence,inclusivity,nuclear medicine,radiology}
}

@online{daiDeepSeekMoEUltimateExpert2024,
  title = {{{DeepSeekMoE}}: {{Towards Ultimate Expert Specialization}} in {{Mixture-of-Experts Language Models}}},
  shorttitle = {{{DeepSeekMoE}}},
  author = {Dai, Damai and Deng, Chengqi and Zhao, Chenggang and Xu, R. X. and Gao, Huazuo and Chen, Deli and Li, Jiashi and Zeng, Wangding and Yu, Xingkai and Wu, Y. and Xie, Zhenda and Li, Y. K. and Huang, Panpan and Luo, Fuli and Ruan, Chong and Sui, Zhifang and Liang, Wenfeng},
  date = {2024-01-11},
  eprint = {2401.06066},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.06066},
  url = {http://arxiv.org/abs/2401.06066},
  urldate = {2024-09-22},
  abstract = {In the era of large language models, Mixture-of-Experts (MoE) is a promising architecture for managing computational costs when scaling up model parameters. However, conventional MoE architectures like GShard, which activate the top-\$K\$ out of \$N\$ experts, face challenges in ensuring expert specialization, i.e. each expert acquires non-overlapping and focused knowledge. In response, we propose the DeepSeekMoE architecture towards ultimate expert specialization. It involves two principal strategies: (1) finely segmenting the experts into \$mN\$ ones and activating \$mK\$ from them, allowing for a more flexible combination of activated experts; (2) isolating \$K\_s\$ experts as shared ones, aiming at capturing common knowledge and mitigating redundancy in routed experts. Starting from a modest scale with 2B parameters, we demonstrate that DeepSeekMoE 2B achieves comparable performance with GShard 2.9B, which has 1.5 times the expert parameters and computation. In addition, DeepSeekMoE 2B nearly approaches the performance of its dense counterpart with the same number of total parameters, which set the upper bound of MoE models. Subsequently, we scale up DeepSeekMoE to 16B parameters and show that it achieves comparable performance with LLaMA2 7B, with only about 40\% of computations. Further, our preliminary efforts to scale up DeepSeekMoE to 145B parameters consistently validate its substantial advantages over the GShard architecture, and show its performance comparable with DeepSeek 67B, using only 28.5\% (maybe even 18.2\%) of computations.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\MixtureOfExperts\DeepSeekMoE_Dai_et_al_2024.pdf}
}

@article{darbasSensitivityAnalysis3D2020,
  title = {Sensitivity Analysis for {{3D Maxwell}}'s Equations and Its Use in the Resolution of an Inverse Medium Problem at Fixed Frequency},
  author = {Darbas, Marion and Heleine, Jérémy and Lohrengel, Stephanie},
  date = {2020-04-02},
  journaltitle = {Inverse Problems in Science and Engineering},
  volume = {28},
  number = {4},
  pages = {459--496},
  issn = {1741-5977, 1741-5985},
  doi = {10.1080/17415977.2019.1588896},
  url = {https://www.tandfonline.com/doi/full/10.1080/17415977.2019.1588896},
  urldate = {2024-07-08},
  abstract = {This paper deals with the reconstruction of small-amplitude perturbations in the electric properties (permittivity and conductivity) of a medium from boundary measurements of the electric field at a fixed frequency. The underlying model is the three-dimensional time-harmonic Maxwell equations in the electric field. Sensitivity analysis with respect to the parameters is performed, and explicit relations between the boundary measurements and the characteristics of the perturbations are found from an appropriate integral equation and extensive numerical simulations in 3D. The resulting non-iterative algorithm allows to retrieve efficiently the centre and volume of the perturbations in various situations from the simple sphere to a realistic model of the human head.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\AnalysisOfEIT\SensitivityAnalysis\Sensitivity_analysis_for_3D_Maxwell's_equations_and_its_use_in_the_resolution_Darbas_et_al_2020.pdf}
}

@article{darbasSensitivityAnalysisComplete2021,
  title = {Sensitivity Analysis of the Complete Electrode Model for Electrical Impedance Tomography},
  author = {Darbas, Marion and Heleine, Jérémy and Mendoza, Renier and Velasco, Arrianne Crystal and {LAGA CNRS UMR 7539, Université Sorbonne Paris Nord, Villetaneuse, France} and {INRIA/Centre de mathématiques appliquées, École Polytechnique, Université Paris-Saclay, Palaiseau, France} and {Institute of Mathematics, University of the Philippines Diliman, Quezon City, Philippines} and {LAMFA CNRS UMR 7352, Université de Picardie Jules Verne, Amiens, France}},
  date = {2021},
  journaltitle = {AIMS Mathematics},
  volume = {6},
  number = {7},
  pages = {7333--7366},
  issn = {2473-6988},
  doi = {10.3934/math.2021431},
  url = {http://www.aimspress.com/article/doi/10.3934/math.2021431},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is an imaging technique that reconstructs the conductivity distribution in the interior of an object using electrical measurements from the electrodes that are attached around the boundary. The Complete Electrode Model (CEM) accurately incorporates the electrode size, shape, and effective contact impedance into the forward problem for EIT. In this work, the effect of the conductivity distribution and the electrode contact impedance on the solution of the forward problem is addressed. In particular, the sensitivity of the electric potential with respect to a small-amplitude perturbation in the conductivity, and with respect to some defective electrodes is studied. The Gaˆteaux derivative is introduced as a tool for the sensitivity analysis and the Gaˆteaux differentiability of the electric potential with respect to the conductivity and to the contact impedance of the electrodes is proved. The derivative is then expressed as the unique solution to a variational problem and the discretization is performed with Finite Elements of type P1. Numerical simulations for different 2D and 3D configurations are presented. This study illustrates the impact of the presence of perturbations in the parameters of CEM on EIT measurements. Finally, the 2D inverse conductivity problem for EIT is numerically solved for some configurations and the results confirm the conclusions of the numerical sensitivity analysis.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\AnalysisOfEIT\SensitivityAnalysis\Sensitivity_analysis_of_the_complete_electrode_model_for_electrical_impedance_Darbas_et_al_2021.pdf}
}

@article{darnajouDesignElectricalImpedance2018,
  title = {The {{Design}} of {{Electrical Impedance Tomography Detectors}} in {{Nuclear Industry}}},
  author = {Darnajou, Mathieu and Dang, Chunhui and Ricciardi, Guillaume and Bourennane, Salah and Bellis, Cédric and Schmidt, Holger},
  date = {2018},
  abstract = {The Electrical Impedance Tomography detector designed to measure the flow pattern in the primary circuit of nuclear plants is a cylinder that includes one or several rings of electrodes. This paper aims at determining the requirement on the design of the electrodes, the diameter and length of the cylinder being constrained by the circuit pipe. Since the electric potential is imposed during measurements, the image reconstruction quality of the images is optimised for the largest area of the electrodes. The angular size is maximised, respecting a minimal gap of 1mm due to technical constraints. The axial size has to be maximised as well, nevertheless, the pipe elements upstream and downstream the detector being made in conductive stainless steel, a leakage of current is expected if the isolation layer to the electrodes is thin.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Pipes\The_Design_of_Electrical_Impedance_Tomography_Detectors_in_Nuclear_Industry_Darnajou_et_al_2018.pdf}
}

@thesis{dasilvaferreiraArtificialNeuralNetwork2020,
  type = {Doutor em Engenharia Elétrica},
  title = {An artificial neural network based approach for computing optical properties of photonic crystals:},
  shorttitle = {An artificial neural network based approach for computing optical properties of photonic crystals},
  author = {Da Silva Ferreira, Adriano},
  date = {2020-01-27},
  institution = {Universidade Estadual de Campinas},
  location = {Campinas, SP},
  doi = {10.47749/T/UNICAMP.2020.1127229},
  url = {https://repositorio.unicamp.br/Busca/Download?codigoArquivo=470037},
  urldate = {2024-06-21},
  langid = {portuguese},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\AI\Modeling\OpticalProperties\An_artificial_neural_network_Da_Silva_Ferreira_2020.pdf}
}

@article{delgrossoSpeedSoundPure1972,
  title = {Speed of {{Sound}} in {{Pure Water}}},
  author = {Del Grosso, V. A. and Mader, C. W.},
  date = {1972-11-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  volume = {52},
  pages = {1442--1446},
  issn = {0001-4966, 1520-8524},
  doi = {10.1121/1.1913258},
  url = {https://pubs.aip.org/jasa/article/52/5B/1442/654701/Speed-of-Sound-in-Pure-Water},
  urldate = {2023-09-05},
  abstract = {A sound-speed equation of fifth order in temperature is fit with a standard deviation of 0.0028 m/sec to 148 observations between 0.001°C and 95.126°C on the T68 scale. The accuracy is believed to be 0.015 m/sec, and the reproducibility over replications is 0.005 m/sec.},
  issue = {5B},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Speed_of_Sound_in_Pure_Water_Del_Grosso_Mader_1972.pdf}
}

@article{dengHybridInverseDesign2022,
  title = {Hybrid Inverse Design of Photonic Structures by Combining Optimization Methods with Neural Networks},
  author = {Deng, Lin and Xu, Yihao and Liu, Yongmin},
  date = {2022-12-01},
  journaltitle = {Photonics and Nanostructures - Fundamentals and Applications},
  volume = {52},
  pages = {101073},
  issn = {1569-4410},
  doi = {10.1016/j.photonics.2022.101073},
  url = {https://www.sciencedirect.com/science/article/pii/S1569441022000839},
  urldate = {2024-06-01},
  abstract = {Over the past decades, classical optimization methods, including gradient-based topology optimization and the evolutionary algorithm, have been widely employed for the inverse design of various photonic structures and devices, while very recently neural networks have emerged as one powerful tool for the same purpose. Although these techniques have demonstrated their superiority to some extent compared to the conventional numerical simulations, each of them still has its own imitations. To fully exploit the potential of intelligent optical design, researchers have proposed to integrate optimization methods with neural networks, so that they can work coordinately to further boost the efficiency, accuracy and capability for more complicated design tasks. In this mini-review, we will highlight some representative examples of the hybrid models to show their working principles and unique proprieties.},
  keywords = {Inverse design,Metamaterials,Neural networks,Optimization,Plasmonics}
}

@inproceedings{dengImageNetLargescaleHierarchical2009,
  title = {{{ImageNet}}: {{A}} Large-Scale Hierarchical Image Database},
  shorttitle = {{{ImageNet}}},
  booktitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  date = {2009-06},
  pages = {248--255},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2009.5206848},
  url = {https://ieeexplore.ieee.org/document/5206848},
  urldate = {2024-12-30},
  abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
  eventtitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  keywords = {Explosions,Image databases,Image retrieval,Information retrieval,Internet,Large-scale systems,Multimedia databases,Ontologies,Robustness,Spine},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\Datasets\ImageNet_Deng_et_al_2009.pdf}
}

@inproceedings{dengImageNetLargescaleHierarchical2009a,
  title = {{{ImageNet}}: {{A}} Large-Scale Hierarchical Image Database},
  shorttitle = {{{ImageNet}}},
  booktitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  date = {2009-06},
  pages = {248--255},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2009.5206848},
  url = {https://ieeexplore.ieee.org/document/5206848},
  urldate = {2024-12-30},
  abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
  eventtitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  keywords = {Explosions,Image databases,Image retrieval,Information retrieval,Internet,Large-scale systems,Multimedia databases,Ontologies,Robustness,Spine}
}

@article{dengInverseDesignPhotonic2024,
  title = {Inverse Design in Photonic Crystals},
  author = {Deng, Ruhuan and Liu, Wenzhe and Shi, Lei},
  date = {2024-04-01},
  journaltitle = {Nanophotonics},
  volume = {13},
  number = {8},
  pages = {1219--1237},
  publisher = {De Gruyter},
  issn = {2192-8614},
  doi = {10.1515/nanoph-2023-0750},
  url = {https://www.degruyter.com/document/doi/10.1515/nanoph-2023-0750/html},
  urldate = {2024-05-31},
  abstract = {Photonic crystals are periodic dielectric structures that possess a wealth of physical characteristics. Owing to the unique way they interact with the light, they provide new degrees of freedom to precisely modulate the electromagnetic fields, and have received extensive research in both academia and industry. At the same time, fueled by the advances in computer science, inverse design strategies are gradually being used to efficiently produce on-demand devices in various domains. As a result, the interdisciplinary area combining photonic crystals and inverse design emerges and flourishes. Here, we review the recent progress for the application of inverse design in photonic crystals. We start with a brief introduction of the background, then mainly discuss the optimizations of various physical properties of photonic crystals, from eigenproperties to response-based properties, and end up with an outlook for the future directions. Throughout the paper, we emphasize some insightful works and their design algorithms, and aim to give a guidance for readers in this emerging field.},
  langid = {english},
  keywords = {inverse design,nanophotonics,optimization,photonic crystals},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\Inverse_design_in_photonic_Deng_et_al_2024.pdf}
}

@article{deviIntermolecularInteractionsRefractive2018,
  title = {Intermolecular {{Interactions}} and {{Refractive Indices}}: {{Experimental Data}} and {{Prediction}} of {{Oxygenated Fuel Additives}} with {{Hydrocarbons}}},
  shorttitle = {Intermolecular {{Interactions}} and {{Refractive Indices}}},
  author = {Devi, Rekha and Gahlyan, Suman and Rani, Manju and Maken, Sanjeev},
  date = {2018},
  journaltitle = {Asian J. Chem.},
  volume = {30},
  number = {9},
  pages = {2054--2062},
  issn = {09707077, 0975427X},
  doi = {10.14233/ajchem.2018.21436},
  url = {https://asianpubs.org/index.php/ajchem/article/view/30_9_24},
  urldate = {2023-09-05},
  abstract = {Oxygen containing compounds specifically alkanol and ether are being used as oxygenate fuel additives. The refractive indices (nD) of oxygenated fuel additive, aliphatic and aromatic hydrocarbon and their mixtures were measured at 298.15 K to 318.15 K. The mixtures selected were diisopropyl ether (DIPE) + benzene, toluene, n-alkane (C6-C8) or benzene, toluene (1) + alkane (2) and all possible combinations of alkanes at 298.15 K to 318.15 K. Various mixing rules like Gladstone-Dale, Arago-Biot, Heller, Weiner, Newton and Erying–John were applied for the theoretical estimation of refractive index and compared with experimental refractive indices of binary mixtures. Polynomial equation was applied to the measured data to calculate standard deviation. The ∆n were further interpreted in terms of intermolecular interactions between the oxygenated fuel additive, aliphatic and aromatic hydrocarbons.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Intermolecular_Interactions_and_Refractive_Indices_Devi_et_al_2018.pdf}
}

@article{deviThermodynamicAcousticProperties2019,
  title = {Thermodynamic and Acoustic Properties of Binary Mixtures of Diisopropyl Ether, Benzene and Alkanes at 298.15, 308.15 and 318.15 {{K}}: {{Prigogine-Flory-Patterson}} Theory and Graph Theory},
  shorttitle = {Thermodynamic and Acoustic Properties of Binary Mixtures of Diisopropyl Ether, Benzene and Alkanes at 298.15, 308.15 and 318.15 {{K}}},
  author = {Devi, Rekha and Gahlyan, Suman and Rani, Manju and Maken, Sanjeev},
  date = {2019-02},
  journaltitle = {Journal of Molecular Liquids},
  volume = {275},
  pages = {364--377},
  issn = {01677322},
  doi = {10.1016/j.molliq.2018.11.045},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167732218332975},
  urldate = {2023-09-05},
  abstract = {Densities and speed of sound for the binary mixtures of diisopropyl ether (1) + n‑hexane, n‑heptane, benzene (2) and benzene (1) + n‑hexane, n‑heptane, n‑octane (2) and n‑hexane (1) + n‑heptane (2) were measured from 298.15 K to 318.15 K. The measured data were used to calculate excess molar volume VmE, deviation in ultrasonic speed Δu, isentropic compressibility KEs, excess intermolecular free length LEf and excess available volume VEa. All the derived properties were fitted to Redlich-Kister equation. For theoretical interpretation of VmE values, Prigogine-Flory-Patterson theory and Graph theory were used at 298.15 K. Various empirical correlations like Nomoto, Van-Dael and impedance dependence relation were applied to predict the experimental ultrasonic speed data. Schaaff's collision factor theory was used for prediction of experimental ultrasonic speed data at 298.15 K. The excess intermolecular length (LEf) was calculated from Jacobson free length theory at 298.15 K. The effect of temperature for KEs and VmE was also discussed in terms of intermolecular interactions. © 2018 Elsevier B.V. All rights reserved.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Thermodynamic_and_acoustic_properties_of_binary_mixtures_of_diisopropyl_ether,_Devi_et_al_2019.pdf}
}

@article{dickmannLevitatingNoisePerformance2023,
  title = {Levitating the Noise Performance of Ultra-Stable Laser Cavities Assisted by a Deep Neural Network: The Non-Intuitive Role of the Mirrors},
  shorttitle = {Levitating the Noise Performance of Ultra-Stable Laser Cavities Assisted by a Deep Neural Network},
  author = {Dickmann, J. and Neto, L. Shelling and Gaedtke, M. and Kroker, S.},
  date = {2023-05-08},
  journaltitle = {Opt. Express, OE},
  volume = {31},
  number = {10},
  pages = {15953--15965},
  publisher = {Optica Publishing Group},
  issn = {1094-4087},
  doi = {10.1364/OE.483550},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-31-10-15953},
  urldate = {2024-06-01},
  abstract = {The most precise measurand available to science is the frequency of ultra-stable lasers. With a relative deviation of 4\&\#x2009;\&\#x00D7;\&\#x2009;10\&\#x2212;17 over a wide range of measuring times between one second and 100 seconds, the smallest effects in nature can thus be made measurable. To enable cutting-edge precision, the laser frequency is stabilized to an external optical cavity. This complex optical device must be manufactured to the highest standards and shielded from environmental influences. Given this assumption, the smallest internal sources of perturbation become dominant, namely the internal noise of the optical components. In this work, we present the optimization of all relevant noise sources from all components of the frequency-stabilized laser. We discuss the correlation between each individual noise source and the different parameters of the system and discover the significance of the mirrors. The optimized laser offers a design stability of 8\&\#x2009;\&\#x00D7;\&\#x2009;10\&\#x2212;18 for an operation at room temperature for measuring times between one second and 100 seconds.},
  langid = {english},
  keywords = {Dielectric mirrors,High power lasers,Materials processing,Neural networks,Optical components,Optical systems},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\ConvolutionalNeuralNetworks\Levitating_the_noise_performance_of_ultra-stable_laser_cavities_assisted_by_a_Dickmann_et_al_2023.pdf}
}

@article{dimasEfficientPointMatchingMethodofMoments2022,
  title = {An {{Efficient Point-Matching Method-of-Moments}} for {{2D}} and {{3D Electrical Impedance Tomography Using Radial Basis Functions}}},
  author = {Dimas, Christos and Uzunoglu, Nikolaos and Sotiriadis, Paul P.},
  date = {2022-02},
  journaltitle = {IEEE Trans. Biomed. Eng.},
  volume = {69},
  number = {2},
  pages = {783--794},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/TBME.2021.3105056},
  url = {https://ieeexplore.ieee.org/document/9514449/},
  urldate = {2024-07-08},
  abstract = {Objective: The inverse problem of computing conductivity distributions in 2D and 3D objects interrogated by lowfrequency electrical signals, which is called Electrical Impedance Tomography (EIT), is treated using a Method-of-Moment technique. Methods: A Point-Matching-Method-of-Moment technique is used to formulate a global integral equation solver. Radial Basis Functions are adopted to express the conductivity distribution. Single-step quadratic-norm (L2) and iterative total variation (L1) regularization techniques are exploited to solve the inverse problem. Results: Simulation and experimental tests on a circular reconstruction domain show satisfactory performance in deriving conductivity distribution, achieving a Correlation Coefficient (CC) up to 0.863 for 70 dB voltage SN R and 0.842 for 40 dB voltage SN R. The proposed methodology with L2-norm regularization provided better results than traditional iterative Gauss-Newton’s approach, whereas with L1-norm regularization it showed promising performance. Moreover, 3D reconstructions on a cylindrical cavity demonstrated superior results near the electrodes’ planes compared to those of the conventional linearized approach. Finally, application to EIT medical data for dynamic lung imaging successfully revealed the breath-cycle conductivity changes. Conclusion: The results show that the proposed method can be effective for both 2D and 3D EIT and applicable to many applications. Significance: Strong conductivity variations are successfully tackled with a very good Correlation Coefficient. In contrast to conventional EIT solutions based on weak-form and linearization on small conductivity changes, the proposed method requires only one step to converge with L2-norm regularization. The proposed method with L1-norm regularization also achieves good reconstruction quality with a low number of iterations.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\MethodOfMoments\An_Efficient_Point-Matching_Method-of-Moments_for_2D_and_3D_Electrical_Dimas_et_al_2022.pdf}
}

@article{dizajNonreciprocalPropagationOptical2024,
  title = {Nonreciprocal Propagation of Optical Pulses in a One-Dimensional Photonic Crystal with Two {{Weyl}} Semimetal-Based Defects},
  author = {Dizaj, H. Pourasiab and Aalipour, R. and Entezar, S. Roshan},
  date = {2024-01-01},
  journaltitle = {Journal of Magnetism and Magnetic Materials},
  volume = {589},
  pages = {171504},
  issn = {0304-8853},
  doi = {10.1016/j.jmmm.2023.171504},
  url = {https://www.sciencedirect.com/science/article/pii/S030488532301154X},
  urldate = {2024-01-22},
  abstract = {We investigated the nonreciprocal propagation properties of an optical pulse in a one-dimensional photonic crystal containing Weyl semimetal-based defect layers. High optical nonreciprocity, without the need for high-intensity input light sources or external magnetic fields, is the most essential property of the Weyl semimetal. The transfer matrix and Fourier transform techniques are used to obtain the time envelopes of the transmitted pulses. It is demonstrated that the transmitted pulse may attain two different time envelopes by reversing the impinging direction of the input pulse. Then, the effects of the input pulse carrier frequency and time width on the characteristics of the transmitted pulse are presented and shown that reversing the impinging direction of the input pulse has a significant effect on the length and energy of the transmitted pulse. The results may have applications in designing pulse-shaping filters and transferring digital data.},
  keywords = {Fourier transform technique,Laser pulse,Nonreciprocity,Time envelope,Transfer matrix},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\OpticalPulses\Nonreciprocal_propagation_of_optical_pulses_in_a_one-dimensional_photonic_Dizaj_et_al_2024.pdf}
}

@article{djajaputraElectricalImpedanceTomography2005,
  title = {Electrical {{Impedance Tomography}}: {{Methods}}, {{History}} and {{Applications}}},
  shorttitle = {Electrical {{Impedance Tomography}}},
  author = {Djajaputra, David},
  date = {2005-08},
  journaltitle = {Medical Physics},
  volume = {32},
  number = {8},
  pages = {2731--2731},
  issn = {0094-2405, 2473-4209},
  doi = {10.1118/1.1995712},
  url = {https://aapm.onlinelibrary.wiley.com/doi/10.1118/1.1995712},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\Electrical_Impedance_Tomography_Djajaputra_2005.pdf}
}

@article{dongTopologicalOptimizationTwodimensional2014,
  title = {Topological Optimization of Two-Dimensional Phononic Crystals Based on the Finite Element Method and Genetic Algorithm},
  author = {Dong, Hao-Wen and Su, Xiao-Xing and Wang, Yue-Sheng and Zhang, Chuanzeng},
  date = {2014-10},
  journaltitle = {Struct Multidisc Optim},
  volume = {50},
  number = {4},
  pages = {593--604},
  issn = {1615-147X, 1615-1488},
  doi = {10.1007/s00158-014-1070-6},
  url = {http://link.springer.com/10.1007/s00158-014-1070-6},
  urldate = {2023-09-05},
  abstract = {By using the finite element method and a “coarse to fine” two-stage genetic algorithm as the forward calculation method and the inverse search scheme, respectively, we perform both the unconstrained and constrained optimal design of the unit cell topology of the two-dimensional square-latticed solid phononic crystals (PnCs), to maximize the relative widths of the gaps between the adjacent energy bands of the PnCs. In the constrained optimizations, the maximization is subjected to the constraint of a predefined average density. In the numerical results, the variation patterns of the optimized structures with the order of the bandgap for both the out-plane shear and the in-plane mixed elastic wave modes are presented, and the effects of both the material contrast and the predefined average density on the obtained optimal structures are discussed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\2DPhononicCrystals\Topological_optimization_of_two-dimensional_phononic_crystals_based_on_the_Dong_et_al_2014.pdf}
}

@online{drobyshevMegaPortraitsOneshotMegapixel2023,
  title = {{{MegaPortraits}}: {{One-shot Megapixel Neural Head Avatars}}},
  shorttitle = {{{MegaPortraits}}},
  author = {Drobyshev, Nikita and Chelishev, Jenya and Khakhulin, Taras and Ivakhnenko, Aleksei and Lempitsky, Victor and Zakharov, Egor},
  date = {2023-03-28},
  eprint = {2207.07621},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2207.07621},
  url = {http://arxiv.org/abs/2207.07621},
  urldate = {2024-03-08},
  abstract = {In this work, we advance the neural head avatar technology to the megapixel resolution while focusing on the particularly challenging task of cross-driving synthesis, i.e., when the appearance of the driving image is substantially different from the animated source image. We propose a set of new neural architectures and training methods that can leverage both medium-resolution video data and high-resolution image data to achieve the desired levels of rendered image quality and generalization to novel views and motion. We demonstrate that suggested architectures and methods produce convincing high-resolution neural avatars, outperforming the competitors in the cross-driving scenario. Lastly, we show how a trained high-resolution neural avatar model can be distilled into a lightweight student model which runs in real-time and locks the identities of neural avatars to several dozens of pre-defined source images. Real-time operation and identity lock are essential for many practical applications head avatar systems.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\MegaPortraits_Drobyshev_et_al_2023.pdf}
}

@inproceedings{duanLossyImageCompression2023,
  title = {Lossy {{Image Compression With Quantized Hierarchical VAEs}}},
  author = {Duan, Zhihao and Lu, Ming and Ma, Zhan and Zhu, Fengqing},
  date = {2023},
  pages = {198--207},
  url = {https://openaccess.thecvf.com/content/WACV2023/html/Duan_Lossy_Image_Compression_With_Quantized_Hierarchical_VAEs_WACV_2023_paper.html},
  urldate = {2024-11-26},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Lossy_Image_Compression_With_Duan_et_al_2023.pdf}
}

@online{dubeyLlamaHerdModels2024,
  title = {The {{Llama}} 3 {{Herd}} of {{Models}}},
  author = {Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and Goyal, Anirudh and Hartshorn, Anthony and Yang, Aobo and Mitra, Archi and Sravankumar, Archie and Korenev, Artem and Hinsvark, Arthur and Rao, Arun and Zhang, Aston and Rodriguez, Aurelien and Gregerson, Austen and Spataru, Ava and Roziere, Baptiste and Biron, Bethany and Tang, Binh and Chern, Bobbie and Caucheteux, Charlotte and Nayak, Chaya and Bi, Chloe and Marra, Chris and McConnell, Chris and Keller, Christian and Touret, Christophe and Wu, Chunyang and Wong, Corinne and Ferrer, Cristian Canton and Nikolaidis, Cyrus and Allonsius, Damien and Song, Daniel and Pintz, Danielle and Livshits, Danny and Esiobu, David and Choudhary, Dhruv and Mahajan, Dhruv and Garcia-Olano, Diego and Perino, Diego and Hupkes, Dieuwke and Lakomkin, Egor and AlBadawy, Ehab and Lobanova, Elina and Dinan, Emily and Smith, Eric Michael and Radenovic, Filip and Zhang, Frank and Synnaeve, Gabriel and Lee, Gabrielle and Anderson, Georgia Lewis and Nail, Graeme and Mialon, Gregoire and Pang, Guan and Cucurell, Guillem and Nguyen, Hailey and Korevaar, Hannah and Xu, Hu and Touvron, Hugo and Zarov, Iliyan and Ibarra, Imanol Arrieta and Kloumann, Isabel and Misra, Ishan and Evtimov, Ivan and Copet, Jade and Lee, Jaewon and Geffert, Jan and Vranes, Jana and Park, Jason and Mahadeokar, Jay and Shah, Jeet and family=Linde, given=Jelmer, prefix=van der, useprefix=true and Billock, Jennifer and Hong, Jenny and Lee, Jenya and Fu, Jeremy and Chi, Jianfeng and Huang, Jianyu and Liu, Jiawen and Wang, Jie and Yu, Jiecao and Bitton, Joanna and Spisak, Joe and Park, Jongsoo and Rocca, Joseph and Johnstun, Joshua and Saxe, Joshua and Jia, Junteng and Alwala, Kalyan Vasuden and Upasani, Kartikeya and Plawiak, Kate and Li, Ke and Heafield, Kenneth and Stone, Kevin and El-Arini, Khalid and Iyer, Krithika and Malik, Kshitiz and Chiu, Kuenley and Bhalla, Kunal and Rantala-Yeary, Lauren and family=Maaten, given=Laurens, prefix=van der, useprefix=true and Chen, Lawrence and Tan, Liang and Jenkins, Liz and Martin, Louis and Madaan, Lovish and Malo, Lubo and Blecher, Lukas and Landzaat, Lukas and family=Oliveira, given=Luke, prefix=de, useprefix=true and Muzzi, Madeline and Pasupuleti, Mahesh and Singh, Mannat and Paluri, Manohar and Kardas, Marcin and Oldham, Mathew and Rita, Mathieu and Pavlova, Maya and Kambadur, Melanie and Lewis, Mike and Si, Min and Singh, Mitesh Kumar and Hassan, Mona and Goyal, Naman and Torabi, Narjes and Bashlykov, Nikolay and Bogoychev, Nikolay and Chatterji, Niladri and Duchenne, Olivier and Çelebi, Onur and Alrassy, Patrick and Zhang, Pengchuan and Li, Pengwei and Vasic, Petar and Weng, Peter and Bhargava, Prajjwal and Dubal, Pratik and Krishnan, Praveen and Koura, Punit Singh and Xu, Puxin and He, Qing and Dong, Qingxiao and Srinivasan, Ragavan and Ganapathy, Raj and Calderer, Ramon and Cabral, Ricardo Silveira and Stojnic, Robert and Raileanu, Roberta and Girdhar, Rohit and Patel, Rohit and Sauvestre, Romain and Polidoro, Ronnie and Sumbaly, Roshan and Taylor, Ross and Silva, Ruan and Hou, Rui and Wang, Rui and Hosseini, Saghar and Chennabasappa, Sahana and Singh, Sanjay and Bell, Sean and Kim, Seohyun Sonia and Edunov, Sergey and Nie, Shaoliang and Narang, Sharan and Raparthy, Sharath and Shen, Sheng and Wan, Shengye and Bhosale, Shruti and Zhang, Shun and Vandenhende, Simon and Batra, Soumya and Whitman, Spencer and Sootla, Sten and Collot, Stephane and Gururangan, Suchin and Borodinsky, Sydney and Herman, Tamar and Fowler, Tara and Sheasha, Tarek and Georgiou, Thomas and Scialom, Thomas and Speckbacher, Tobias and Mihaylov, Todor and Xiao, Tong and Karn, Ujjwal and Goswami, Vedanuj and Gupta, Vibhor and Ramanathan, Vignesh and Kerkez, Viktor and Gonguet, Vincent and Do, Virginie and Vogeti, Vish and Petrovic, Vladan and Chu, Weiwei and Xiong, Wenhan and Fu, Wenyin and Meers, Whitney and Martinet, Xavier and Wang, Xiaodong and Tan, Xiaoqing Ellen and Xie, Xinfeng and Jia, Xuchao and Wang, Xuewei and Goldschlag, Yaelle and Gaur, Yashesh and Babaei, Yasmine and Wen, Yi and Song, Yiwen and Zhang, Yuchen and Li, Yue and Mao, Yuning and Coudert, Zacharie Delpierre and Yan, Zheng and Chen, Zhengxing and Papakipos, Zoe and Singh, Aaditya and Grattafiori, Aaron and Jain, Abha and Kelsey, Adam and Shajnfeld, Adam and Gangidi, Adithya and Victoria, Adolfo and Goldstand, Ahuva and Menon, Ajay and Sharma, Ajay and Boesenberg, Alex and Vaughan, Alex and Baevski, Alexei and Feinstein, Allie and Kallet, Amanda and Sangani, Amit and Yunus, Anam and Lupu, Andrei and Alvarado, Andres and Caples, Andrew and Gu, Andrew and Ho, Andrew and Poulton, Andrew and Ryan, Andrew and Ramchandani, Ankit and Franco, Annie and Saraf, Aparajita and Chowdhury, Arkabandhu and Gabriel, Ashley and Bharambe, Ashwin and Eisenman, Assaf and Yazdan, Azadeh and James, Beau and Maurer, Ben and Leonhardi, Benjamin and Huang, Bernie and Loyd, Beth and De Paola, Beto and Paranjape, Bhargavi and Liu, Bing and Wu, Bo and Ni, Boyu and Hancock, Braden and Wasti, Bram and Spence, Brandon and Stojkovic, Brani and Gamido, Brian and Montalvo, Britt and Parker, Carl and Burton, Carly and Mejia, Catalina and Wang, Changhan and Kim, Changkyu and Zhou, Chao and Hu, Chester and Chu, Ching-Hsiang and Cai, Chris and Tindal, Chris and Feichtenhofer, Christoph and Civin, Damon and Beaty, Dana and Kreymer, Daniel and Li, Daniel and Wyatt, Danny and Adkins, David and Xu, David and Testuggine, Davide and David, Delia and Parikh, Devi and Liskovich, Diana and Foss, Didem and Wang, Dingkang and Le, Duc and Holland, Dustin and Dowling, Edward and Jamil, Eissa and Montgomery, Elaine and Presani, Eleonora and Hahn, Emily and Wood, Emily and Brinkman, Erik and Arcaute, Esteban and Dunbar, Evan and Smothers, Evan and Sun, Fei and Kreuk, Felix and Tian, Feng and Ozgenel, Firat and Caggioni, Francesco and Guzmán, Francisco and Kanayet, Frank and Seide, Frank and Florez, Gabriela Medina and Schwarz, Gabriella and Badeer, Gada and Swee, Georgia and Halpern, Gil and Thattai, Govind and Herman, Grant and Sizov, Grigory and Guangyi and Zhang and Lakshminarayanan, Guna and Shojanazeri, Hamid and Zou, Han and Wang, Hannah and Zha, Hanwen and Habeeb, Haroun and Rudolph, Harrison and Suk, Helen and Aspegren, Henry and Goldman, Hunter and Damlaj, Ibrahim and Molybog, Igor and Tufanov, Igor and Veliche, Irina-Elena and Gat, Itai and Weissman, Jake and Geboski, James and Kohli, James and Asher, Japhet and Gaya, Jean-Baptiste and Marcus, Jeff and Tang, Jeff and Chan, Jennifer and Zhen, Jenny and Reizenstein, Jeremy and Teboul, Jeremy and Zhong, Jessica and Jin, Jian and Yang, Jingyi and Cummings, Joe and Carvill, Jon and Shepard, Jon and McPhie, Jonathan and Torres, Jonathan and Ginsburg, Josh and Wang, Junjie and Wu, Kai and U, Kam Hou and Saxena, Karan and Prasad, Karthik and Khandelwal, Kartikay and Zand, Katayoun and Matosich, Kathy and Veeraraghavan, Kaushik and Michelena, Kelly and Li, Keqian and Huang, Kun and Chawla, Kunal and Lakhotia, Kushal and Huang, Kyle and Chen, Lailin and Garg, Lakshya and A, Lavender and Silva, Leandro and Bell, Lee and Zhang, Lei and Guo, Liangpeng and Yu, Licheng and Moshkovich, Liron and Wehrstedt, Luca and Khabsa, Madian and Avalani, Manav and Bhatt, Manish and Tsimpoukelli, Maria and Mankus, Martynas and Hasson, Matan and Lennie, Matthew and Reso, Matthias and Groshev, Maxim and Naumov, Maxim and Lathi, Maya and Keneally, Meghan and Seltzer, Michael L. and Valko, Michal and Restrepo, Michelle and Patel, Mihir and Vyatskov, Mik and Samvelyan, Mikayel and Clark, Mike and Macey, Mike and Wang, Mike and Hermoso, Miquel Jubert and Metanat, Mo and Rastegari, Mohammad and Bansal, Munish and Santhanam, Nandhini and Parks, Natascha and White, Natasha and Bawa, Navyata and Singhal, Nayan and Egebo, Nick and Usunier, Nicolas and Laptev, Nikolay Pavlovich and Dong, Ning and Zhang, Ning and Cheng, Norman and Chernoguz, Oleg and Hart, Olivia and Salpekar, Omkar and Kalinli, Ozlem and Kent, Parkin and Parekh, Parth and Saab, Paul and Balaji, Pavan and Rittner, Pedro and Bontrager, Philip and Roux, Pierre and Dollar, Piotr and Zvyagina, Polina and Ratanchandani, Prashant and Yuvraj, Pritish and Liang, Qian and Alao, Rachad and Rodriguez, Rachel and Ayub, Rafi and Murthy, Raghotham and Nayani, Raghu and Mitra, Rahul and Li, Raymond and Hogan, Rebekkah and Battey, Robin and Wang, Rocky and Maheswari, Rohan and Howes, Russ and Rinott, Ruty and Bondu, Sai Jayesh and Datta, Samyak and Chugh, Sara and Hunt, Sara and Dhillon, Sargun and Sidorov, Sasha and Pan, Satadru and Verma, Saurabh and Yamamoto, Seiji and Ramaswamy, Sharadh and Lindsay, Shaun and Lindsay, Shaun and Feng, Sheng and Lin, Shenghao and Zha, Shengxin Cindy and Shankar, Shiva and Zhang, Shuqiang and Zhang, Shuqiang and Wang, Sinong and Agarwal, Sneha and Sajuyigbe, Soji and Chintala, Soumith and Max, Stephanie and Chen, Stephen and Kehoe, Steve and Satterfield, Steve and Govindaprasad, Sudarshan and Gupta, Sumit and Cho, Sungmin and Virk, Sunny and Subramanian, Suraj and Choudhury, Sy and Goldman, Sydney and Remez, Tal and Glaser, Tamar and Best, Tamara and Kohler, Thilo and Robinson, Thomas and Li, Tianhe and Zhang, Tianjun and Matthews, Tim and Chou, Timothy and Shaked, Tzook and Vontimitta, Varun and Ajayi, Victoria and Montanez, Victoria and Mohan, Vijai and Kumar, Vinay Satish and Mangla, Vishal and Albiero, Vítor and Ionescu, Vlad and Poenaru, Vlad and Mihailescu, Vlad Tiberiu and Ivanov, Vladimir and Li, Wei and Wang, Wenchen and Jiang, Wenwen and Bouaziz, Wes and Constable, Will and Tang, Xiaocheng and Wang, Xiaofang and Wu, Xiaojian and Wang, Xiaolan and Xia, Xide and Wu, Xilun and Gao, Xinbo and Chen, Yanjun and Hu, Ye and Jia, Ye and Qi, Ye and Li, Yenda and Zhang, Yilin and Zhang, Ying and Adi, Yossi and Nam, Youngjin and Yu and Wang and Hao, Yuchen and Qian, Yundi and He, Yuzi and Rait, Zach and DeVito, Zachary and Rosnbrick, Zef and Wen, Zhaoduo and Yang, Zhenyu and Zhao, Zhiwei},
  date = {2024-08-15},
  eprint = {2407.21783},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.21783},
  url = {http://arxiv.org/abs/2407.21783},
  urldate = {2024-09-22},
  abstract = {Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\LLM\The_Llama_3_Herd_of_Models_Dubey_et_al_2024.pdf}
}

@online{dumoulinGuideConvolutionArithmetic2018,
  title = {A Guide to Convolution Arithmetic for Deep Learning},
  author = {Dumoulin, Vincent and Visin, Francesco},
  date = {2018-01-11},
  eprint = {1603.07285},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1603.07285},
  urldate = {2023-08-26},
  abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\A_guide_to_convolution_Dumoulin_Visin_2018.pdf}
}

@online{dupontCOINCOmpressionImplicit2021,
  title = {{{COIN}}: {{COmpression}} with {{Implicit Neural}} Representations},
  shorttitle = {{{COIN}}},
  author = {Dupont, Emilien and Goliński, Adam and Alizadeh, Milad and Teh, Yee Whye and Doucet, Arnaud},
  date = {2021-04-10},
  eprint = {2103.03123},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2103.03123},
  url = {http://arxiv.org/abs/2103.03123},
  urldate = {2024-12-02},
  abstract = {We propose a new simple approach for image compression: instead of storing the RGB values for each pixel of an image, we store the weights of a neural network overfitted to the image. Specifically, to encode an image, we fit it with an MLP which maps pixel locations to RGB values. We then quantize and store the weights of this MLP as a code for the image. To decode the image, we simply evaluate the MLP at every pixel location. We found that this simple approach outperforms JPEG at low bit-rates, even without entropy coding or learning a distribution over weights. While our framework is not yet competitive with state of the art compression methods, we show that it has various attractive properties which could make it a viable alternative to other neural data compression approaches.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\OverFittedSingleImage\COIN_Dupont_et_al_2021.pdf}
}

@incollection{duranFrameworkElectricalImpedance2021,
  title = {Framework for {{Electrical Impedance Tomography Forward Problem}} with {{Non-uniform Electrodes Distribution}}},
  booktitle = {{{ICGG}} 2020 - {{Proceedings}} of the 19th {{International Conference}} on {{Geometry}} and {{Graphics}}},
  author = {Duran, Guilherme C. and Sato, André K. and Tanabi, Naser and Nasiri, Hossein and Takimoto, Rogério Y. and Barari, Ahmad and Martins, Thiago C. and Tsuzuki, Marcos S. G.},
  editor = {Cheng, Liang-Yee},
  date = {2021},
  volume = {1296},
  pages = {320--331},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-63403-2_29},
  url = {http://link.springer.com/10.1007/978-3-030-63403-2_29},
  urldate = {2024-07-08},
  abstract = {Electrical Impedance Tomography (EIT) is a noninvasive, fast-growing technique for image reconstruction. In a typical EIT modeling configuration, electrodes are assumed to be positioned at regularly spaced intervals along the contour of an object. Thus, the resulting reconstructed image – which could be obtained by different methods, such as Artificial Neural Networks (ANNs) - has deviations due to the common existence of errors in the measurement, which is related to wrong electrode positioning in real applications. When a discrepancy exists between model and experiment, the distribution obtained by the inverse problem solver will differ from the real case. We propose herein a framework for an EIT problem with non-uniform electrodes distribution. This proposal takes into account prior knowledge about the object interior, in order to make it permit the investigation of electrode positions. A framework to generate training data for the EIT problem was developed and tested with a simple experiment with three cucumbers inside a circular tank. The proposed framework is very flexible as it allows for different experimental setups, with different geometries for the contour and its interior physical structures, by converting the shapes to simple polygons. Moreover, it allows for non-uniform electrode distribution, which can be even more important when medical applications are considered.},
  isbn = {978-3-030-63402-5 978-3-030-63403-2},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\InaccuratelyKnownBoundary\Framework_for_Electrical_Impedance_Tomography_Forward_Problem_with_Non-uniform_Duran_et_al_2021.pdf}
}

@unpublished{EIT,
  title = {{{EIT}}},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Presentaions\EIT_.pdf}
}

@article{el-naggarOpticalGuidanceCylindrical2017,
  title = {Optical Guidance in Cylindrical Photonic Crystals},
  author = {El-Naggar, Sahar A.},
  date = {2017-02},
  journaltitle = {Optik},
  volume = {130},
  pages = {584--588},
  issn = {00304026},
  doi = {10.1016/j.ijleo.2016.10.087},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S003040261631275X},
  urldate = {2023-11-06},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Optical_guidance_in_cylindrical_photonic_crystals_El-Naggar_2017.pdf}
}

@article{el-naggarPhotonicGapsOne2017,
  title = {Photonic Gaps in One Dimensional Cylindrical Photonic Crystal That Incorporates Single Negative Materials},
  author = {El-Naggar, Sahar A.},
  date = {2017-01},
  journaltitle = {Eur. Phys. J. D},
  volume = {71},
  number = {1},
  pages = {11},
  issn = {1434-6060, 1434-6079},
  doi = {10.1140/epjd/e2016-70584-7},
  url = {http://link.springer.com/10.1140/epjd/e2016-70584-7},
  urldate = {2023-11-06},
  abstract = {In this article, we theoretically study electromagnetic waves that propagate in one-dimensional cylindrical photonic crystals (1DCPC) containing single negative materials. We examine the optical properties of three gaps namely; the zero-effective phase (zero-ϕ), the zero-permittivity (zero-ε) and the zeropermeability (zero-μ). We calculate the optical reflectance for transverse electric(magnetic) TE(TM) polarizations using the transfer matrix method in the cylindrical coordinates. We study the effect of azimuthal mode number (m) and the starting radius on these gaps. The results show that the zero-μ (zero-ε) gap is found for TE(TM) polarization at frequency where μ(ε) changes its sign for m 1. The width of the gap increases by decreasing the starting radius or by increasing m, whereas the zero-ϕ gap remains invariant. In addition, we present a brief design of 1D-CPC that has a polarization-independent wide gap especially for high azimuthal mode number (m {$>$} 2). Our results can help improve the performance of microwave devices independent of the source wave polarization.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Photonic_gaps_in_one_dimensional_cylindrical_photonic_crystal_that_incorporates_El-Naggar_2017.pdf}
}

@article{el-naggarPropertiesDefectModes2020,
  title = {Properties of Defect Modes in Cylindrical Photonic Crystals},
  author = {El-Naggar, Sahar A.},
  date = {2020-01},
  journaltitle = {Optik},
  volume = {200},
  pages = {163447},
  issn = {00304026},
  doi = {10.1016/j.ijleo.2019.163447},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0030402619313452},
  urldate = {2023-11-06},
  abstract = {In this research, we study the properties of the defect modes that arise in the photonic band gap of a cylindrical photonic crystal (CPC) by using the transfer matrix method in the cylindrical coordinates. We consider two defective CPCs stacked in symmetric and asymmetric geometries. We examine the number of modes and their properties in the two CPCs structures. The dependencies of the modes on the azimuthal number and the inner radius of the CPC are also discussed. Numerical results show that the defect mode in the asymmetric CPCs has higher Q factor than those in the symmetric CPCs. Beside many potential optical communications and filtering applications, the structure may be a candidate for refractive index sensing with average sensitivity of 200 nm/RIU in the refractive index range from 1 to 1.6.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Properties_of_defect_modes_in_cylindrical_photonic_crystals_El-Naggar_2020.pdf}
}

@article{elsayedTheoreticalVerificationPhotonic2020,
  title = {Theoretical Verification of Photonic Crystals Sensor for Biodiesel Detection and Sensing},
  author = {Elsayed, Hussein A and Mehaney, Ahmed},
  date = {2020-07-16},
  journaltitle = {Phys. Scr.},
  volume = {95},
  number = {8},
  pages = {085507},
  issn = {1402-4896},
  doi = {10.1088/1402-4896/aba2b1},
  url = {https://iopscience.iop.org/article/10.1088/1402-4896/aba2b1},
  urldate = {2024-06-01},
  abstract = {Among the two past decades, the biodiesel fuels received a significant attention due to its lower hydrocarbon emissions and low sulfur diesel. However, the incomplete transesterification represents the main problem for the possibility of wider use. Thus, we present in this research a new method for detecting and measuring of methyl ester biodiesel fuel based on its optical characteristics. The proposed sensor is designed using the well-known one dimensional photonic crystals. The cornerstone of our idea is mainly based on two sides. First, the inclusion of methyl ester as a defect layer inside the one dimensional photonic crystals gives rise to the formation of a resonant peak within the photonic band gap. Second, the concentration of the converted methyl ester due to the transesterification reaction of soybean oil is closely related to its refractive index. Therefore, the sensing and detection procedure is essentially based on the dependence of the characteristics of the resonant peak on the concentration of the biodiesel fuel. The parameters that refer to the performance of our sensor such as, the sensitivity, figure of merit and the detection limit are investigated. Moreover, the effect of the defect layer thickness and the angle of incidence on the performance of our sensor is demonstrated. The numerical results show that our design could provide high sensitivity of 136 nm RIU−1 and figure of merit 2240 RIU–1. In addition to that, it could differentiate between the different biodiesel fuels despite the very limited difference between their indices of refraction.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\BioSensor\Theoretical_verification_of_photonic_crystals_sensor_for_biodiesel_detection_Elsayed_Mehaney_2020.pdf}
}

@misc{EMpy_Html,
  title = {{{EMpy}}\_.Html},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Courses\EMpy__.html}
}

@article{fangUltrasonicMetamaterialsNegative2006,
  title = {Ultrasonic Metamaterials with Negative Modulus},
  author = {Fang, Nicholas and Xi, Dongjuan and Xu, Jianyi and Ambati, Muralidhar and Srituravanich, Werayut and Sun, Cheng and Zhang, Xiang},
  date = {2006-06-01},
  journaltitle = {Nature Mater},
  volume = {5},
  number = {6},
  pages = {452--456},
  issn = {1476-1122, 1476-4660},
  doi = {10.1038/nmat1644},
  url = {https://www.nature.com/articles/nmat1644},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\SpecialEffects\NegativeElasticModulus\Ultrasonic_metamaterials_with_negative_modulus_Fang_et_al_2006.pdf}
}

@online{fanInstantSplatUnboundedSparseview2024,
  title = {{{InstantSplat}}: {{Unbounded Sparse-view Pose-free Gaussian Splatting}} in 40 {{Seconds}}},
  shorttitle = {{{InstantSplat}}},
  author = {Fan, Zhiwen and Cong, Wenyan and Wen, Kairun and Wang, Kevin and Zhang, Jian and Ding, Xinghao and Xu, Danfei and Ivanovic, Boris and Pavone, Marco and Pavlakos, Georgios and Wang, Zhangyang and Wang, Yue},
  date = {2024-06-30},
  eprint = {2403.20309},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.20309},
  url = {http://arxiv.org/abs/2403.20309},
  urldate = {2024-08-05},
  abstract = {While novel view synthesis (NVS) from a sparse set of images has advanced significantly in 3D computer vision, it relies on precise initial estimation of camera parameters using Structure-from-Motion (SfM). For instance, the recently developed Gaussian Splatting depends heavily on the accuracy of SfM-derived points and poses. However, SfM processes are time-consuming and often prove unreliable in sparse-view scenarios, where matched features are scarce, leading to accumulated errors and limited generalization capability across datasets. In this study, we introduce a novel and efficient framework to enhance robust NVS from sparse-view images. Our framework, InstantSplat, integrates multi-view stereo(MVS) predictions with point-based representations to construct 3D Gaussians of large-scale scenes from sparse-view data within seconds, addressing the aforementioned performance and efficiency issues by SfM. Specifically, InstantSplat generates densely populated surface points across all training views and determines the initial camera parameters using pixel-alignment. Nonetheless, the MVS points are not globally accurate, and the pixel-wise prediction from all views results in an excessive Gaussian number, yielding a overparameterized scene representation that compromises both training speed and accuracy. To address this issue, we employ a grid-based, confidence-aware Farthest Point Sampling to strategically position point primitives at representative locations in parallel. Next, we enhance pose accuracy and tune scene parameters through a gradient-based joint optimization framework from self-supervision. By employing this simplified framework, InstantSplat achieves a substantial reduction in training time, from hours to mere seconds, and demonstrates robust performance across various numbers of views in diverse datasets.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\CameraParameters\InstantSplat_Fan_et_al_2024.pdf}
}

@article{fanMaximumEntropyRegularization2010,
  title = {Maximum Entropy Regularization Method for Electrical Impedance Tomography Combined with a Normalized Sensitivity Map},
  author = {Fan, W.R. and Wang, H.X.},
  date = {2010-09},
  journaltitle = {Flow Measurement and Instrumentation},
  volume = {21},
  number = {3},
  pages = {277--283},
  issn = {09555986},
  doi = {10.1016/j.flowmeasinst.2010.02.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0955598610000300},
  urldate = {2024-07-03},
  abstract = {Electrical impedance tomography (EIT) aims to estimate the electrical properties at the interior of an object from current–voltage measurements on its boundary. To overcome ill-posedness, regularization techniques such as Tikhonov regularization as well as some iterative methods were developed. In difference imaging between two different conductivity distributions, a conductivity change can be seen relatively non-negative to the medium with lower conductivity through some safeguard techniques. Therefore, the concept of maximum entropy from information theory and statistic mechanics can be used for this purpose. Furthermore, because the sensing field is ‘‘soft-field’’ and non-uniform, the same anomaly may produce different reconstruction signatures depending on its location within the image plane. Therefore, in this paper, maximum entropy based on general Tikhonov regularization, combined with normalized sensitivity map, is proposed to solve the inverse problem of EIT. Image reconstruction was carried out by maximum entropy regularization (MER) with a normalized sensitivity map and compared with the results from conjugate gradient method (CG), Tikhonov regularization, and CG with a normalized sensitivity map accordingly. Simulation and experiment results indicate that reconstructed images with higher quality can be obtained by MER with a normalized sensitivity map.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Normalization\Maximum_entropy_regularization_method_for_electrical_impedance_tomography_Fan_Wang_2010.pdf}
}

@article{fanReviewAdditiveManufacturing2021,
  title = {A Review of Additive Manufacturing of Metamaterials and Developing Trends},
  author = {Fan, Junxiang and Zhang, Lei and Wei, Shuaishuai and Zhang, Zhi and Choi, Seung-Kyum and Song, Bo and Shi, Yusheng},
  date = {2021-11},
  journaltitle = {Materials Today},
  volume = {50},
  pages = {303--328},
  issn = {13697021},
  doi = {10.1016/j.mattod.2021.04.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1369702121001516},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\A_review_of_additive_manufacturing_of_metamaterials_and_developing_trends_Fan_et_al_2021.pdf}
}

@article{farmakidisIntegratedPhotonicNeuromorphic2024,
  title = {Integrated Photonic Neuromorphic Computing: Opportunities and Challenges},
  shorttitle = {Integrated Photonic Neuromorphic Computing},
  author = {Farmakidis, Nikolaos and Dong, Bowei and Bhaskaran, Harish},
  date = {2024-06},
  journaltitle = {Nat Rev Electr Eng},
  volume = {1},
  number = {6},
  pages = {358--373},
  publisher = {Nature Publishing Group},
  issn = {2948-1201},
  doi = {10.1038/s44287-024-00050-9},
  url = {https://www.nature.com/articles/s44287-024-00050-9},
  urldate = {2024-08-09},
  abstract = {Using photons in lieu of electrons to process information has been an exciting technological prospect for decades. Optical computing is gaining renewed enthusiasm, owing to the accumulated maturity of photonic integrated circuits and the pressing need for faster processing to cope with data generated by artificial intelligence. In neuromorphic photonics, the bosonic nature of light is exploited for high-speed, densely multiplexed linear operations, whereas the superior computing modalities of biological neurons are imitated to accelerate computations. Here, we provide an overview of recent advances in integrated synaptic optical devices and on-chip photonic neural networks focusing on the location in the architecture at which the optical to electrical conversion takes place. We present challenges associated with electro-optical conversions, implementations of optical nonlinearity, amplification and processing in the time domain, and we identify promising emerging photonic neuromorphic hardware.},
  langid = {english},
  keywords = {Electrical and electronic engineering,Information technology,Integrated optics},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\NeuromorphicComputing\Integrated_photonic_neuromorphic_computing_Farmakidis_et_al_2024.pdf}
}

@online{fengMetaDreamerEfficientTextto3D2023,
  title = {{{MetaDreamer}}: {{Efficient Text-to-3D Creation With Disentangling Geometry}} and {{Texture}}},
  shorttitle = {{{MetaDreamer}}},
  author = {Feng, Lincong and Wang, Muyu and Wang, Maoyu and Xu, Kuo and Liu, Xiaoli},
  date = {2023-11-16},
  eprint = {2311.10123},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.10123},
  url = {http://arxiv.org/abs/2311.10123},
  urldate = {2024-05-05},
  abstract = {Generative models for 3D object synthesis have seen significant advancements with the incorporation of prior knowledge distilled from 2D diffusion models. Nevertheless, challenges persist in the form of multi-view geometric inconsistencies and slow generation speeds within the existing 3D synthesis frameworks. This can be attributed to two factors: firstly, the deficiency of abundant geometric a priori knowledge in optimization, and secondly, the entanglement issue between geometry and texture in conventional 3D generation methods.In response, we introduce MetaDreammer, a two-stage optimization approach that leverages rich 2D and 3D prior knowledge. In the first stage, our emphasis is on optimizing the geometric representation to ensure multi-view consistency and accuracy of 3D objects. In the second stage, we concentrate on fine-tuning the geometry and optimizing the texture, thereby achieving a more refined 3D object. Through leveraging 2D and 3D prior knowledge in two stages, respectively, we effectively mitigate the interdependence between geometry and texture. MetaDreamer establishes clear optimization objectives for each stage, resulting in significant time savings in the 3D generation process. Ultimately, MetaDreamer can generate high-quality 3D objects based on textual prompts within 20 minutes, and to the best of our knowledge, it is the most efficient text-to-3D generation method. Furthermore, we introduce image control into the process, enhancing the controllability of 3D generation. Extensive empirical evidence confirms that our method is not only highly efficient but also achieves a quality level that is at the forefront of current state-of-the-art 3D generation techniques.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/Reconstruction/NeuralRadianceFields/TextAndImage/MetaDreamer_Feng_et_al_2023.pdf}
}

@inproceedings{fengNVTCNonlinearVector2023,
  title = {{{NVTC}}: {{Nonlinear Vector Transform Coding}}},
  shorttitle = {{{NVTC}}},
  author = {Feng, Runsen and Guo, Zongyu and Li, Weiping and Chen, Zhibo},
  date = {2023},
  pages = {6101--6110},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Feng_NVTC_Nonlinear_Vector_Transform_Coding_CVPR_2023_paper.html},
  urldate = {2024-11-26},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\NVTC_Feng_et_al_2023.pdf}
}

@online{fengPIENeRFPhysicsbasedInteractive2024,
  title = {{{PIE-NeRF}}: {{Physics-based Interactive Elastodynamics}} with {{NeRF}}},
  shorttitle = {{{PIE-NeRF}}},
  author = {Feng, Yutao and Shang, Yintong and Li, Xuan and Shao, Tianjia and Jiang, Chenfanfu and Yang, Yin},
  date = {2024-03-27},
  eprint = {2311.13099},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2311.13099},
  urldate = {2024-07-04},
  abstract = {We show that physics-based simulations can be seamlessly integrated with NeRF to generate high-quality elastodynamics of real-world objects. Unlike existing methods, we discretize nonlinear hyperelasticity in a meshless way, obviating the necessity for intermediate auxiliary shape proxies like a tetrahedral mesh or voxel grid. A quadratic generalized moving least square (Q-GMLS) is employed to capture nonlinear dynamics and large deformation on the implicit model. Such meshless integration enables versatile simulations of complex and codimensional shapes. We adaptively place the least-square kernels according to the NeRF density field to significantly reduce the complexity of the nonlinear simulation. As a result, physically realistic animations can be conveniently synthesized using our method for a wide range of hyperelastic materials at an interactive rate. For more information, please visit our project page at https://fytalon.github.io/pienerf/.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\DeformableObject\PIE-NeRF_Feng_et_al_2024.pdf}
}

@inproceedings{finnModelAgnosticMetaLearningFast2017,
  title = {Model-{{Agnostic Meta-Learning}} for {{Fast Adaptation}} of {{Deep Networks}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Machine Learning}}},
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  date = {2017-07-17},
  pages = {1126--1135},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v70/finn17a.html},
  urldate = {2024-12-06},
  abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Strategies\\MetaLearning\\Model-Agnostic_Meta-Learning_for_Fast_Adaptation_of_Deep_Networks_Finn_et_al_2017.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Strategies\\MetaLearning\\Model-Agnostic_Meta-Learning_for_Fast_Adaptation_of_Deep_Networks_Finn_et_al_22.pdf}
}

@article{flemingAllmetallicThreedimensionalPhotonic2002,
  title = {All-Metallic Three-Dimensional Photonic Crystals with a Large Infrared Bandgap},
  author = {Fleming, J. G. and Lin, S. Y. and El-Kady, I. and Biswas, R. and Ho, K. M.},
  date = {2002-05},
  journaltitle = {Nature},
  volume = {417},
  number = {6884},
  pages = {52--55},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/417052a},
  url = {https://www.nature.com/articles/417052a},
  urldate = {2024-06-01},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\BlackBodyRadiation\All-metallic_three-dimensional_photonic_crystals_with_a_large_infrared_bandgap_Fleming_et_al_2002.pdf}
}

@article{fossaliEffectsPronePosition2022,
  title = {Effects of {{Prone Position}} on {{Lung Recruitment}} and {{Ventilation-Perfusion Matching}} in {{Patients With COVID-19 Acute Respiratory Distress Syndrome}}: {{A Combined CT Scan}}/{{Electrical Impedance Tomography Study}}*},
  shorttitle = {Effects of {{Prone Position}} on {{Lung Recruitment}} and {{Ventilation-Perfusion Matching}} in {{Patients With COVID-19 Acute Respiratory Distress Syndrome}}},
  author = {Fossali, Tommaso and Pavlovsky, Bertrand and Ottolina, Davide and Colombo, Riccardo and Basile, Maria Cristina and Castelli, Antonio and Rech, Roberto and Borghi, Beatrice and Ianniello, Andrea and Flor, Nicola and Spinelli, Elena and Catena, Emanuele and Mauri, Tommaso},
  date = {2022-05},
  journaltitle = {Critical Care Medicine},
  volume = {50},
  number = {5},
  pages = {723--732},
  issn = {0090-3493},
  doi = {10.1097/CCM.0000000000005450},
  url = {https://journals.lww.com/10.1097/CCM.0000000000005450},
  urldate = {2024-07-08},
  abstract = {OBJECTIVES: Prone positioning allows to improve oxygenation and decrease mortality rate in COVID-19–associated acute respiratory distress syndrome (C-ARDS). However, the mechanisms leading to these effects are not fully understood. The aim of this study is to assess the physiologic effects of pronation by the means of CT scan and electrical impedance tomography (EIT). DESIGN: Experimental, physiologic study. SETTING: Patients were enrolled from October 2020 to March 2021 in an Italian dedicated COVID-19 ICU. PATIENTS: Twenty-one intubated patients with moderate or severe C-ARDS. INTERVENTIONS: First, patients were transported to the CT scan facility, and image acquisition was performed in prone, then supine position. Back to the ICU, gas exchange, respiratory mechanics, and ventilation and perfusion EIT-based analysis were provided toward the end of two 30 minutes steps (e.g., in supine, then prone position). MEASUREMENTS AND MAIN RESULTS: Prone position induced recruitment in the dorsal part of the lungs (12.5\% ± 8.0\%; p {$<$} 0.001 from baseline) and derecruitment in the ventral regions (–6.9\% ± 5.2\%; p {$<$} 0.001). These changes led to a global increase in recruitment (6.0\% ± 6.7\%; p {$<$} 0.001). Respiratory system compliance did not change with prone position (45\,±\,15 vs 45\,±\,18\,mL/cm H2O in supine and prone position, respectively; p = 0.957) suggesting a decrease in atelectrauma. This hypothesis was supported by the decrease of a time-impedance curve concavity index designed as a surrogate for atelectrauma (1.41\,±\,0.16 vs 1.30\,±\,0.16; p = 0.001). Dead space measured by EIT was reduced in the ventral regions of the lungs, and the dead-space/shunt ratio decreased significantly (5.1 [2.3–23.4] vs 4.3 [0.7–6.8]; p = 0.035), showing an improvement in ventilation-perfusion matching. CONCLUSIONS: Several changes are associated with prone position in C-ARDS: increased lung recruitment, decreased atelectrauma, and improved ventilation-perfusion matching. These physiologic effects may be associated with more protective ventilation.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Effects_of_Prone_Position_on_Lung_Recruitment_and_Ventilation-Perfusion_Fossali_et_al_2022.pdf}
}

@inproceedings{freyTemperaturedependentRefractiveIndex2006,
  title = {Temperature-Dependent Refractive Index of Silicon and Germanium},
  author = {Frey, Bradley J. and Leviton, Douglas B. and Madison, Timothy J.},
  editor = {Atad-Ettedgui, Eli and Antebi, Joseph and Lemke, Dietrich},
  date = {2006-06-14},
  pages = {62732J},
  location = {Orlando, Florida , USA},
  doi = {10.1117/12.672850},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.672850},
  urldate = {2023-09-05},
  abstract = {Silicon and germanium are perhaps the two most well-understood semiconductor materials in the context of solid state device technologies and more recently micromachining and nanotechnology. Meanwhile, these two materials are also important in the field of infrared lens design. Optical instruments designed for the wavelength range where these two materials are transmissive achieve best performance when cooled to cryogenic temperatures to enhance signal from the scene over instrument background radiation. In order to enable high quality lens designs using silicon and germanium at cryogenic temperatures, we have measured the absolute refractive index of multiple prisms of these two materials using the Cryogenic, High-Accuracy Refraction Measuring System (CHARMS) at NASA’s Goddard Space Flight Center, as a function of both wavelength and temperature. For silicon, we report absolute refractive index and thermo-optic coefficient (dn/dT) at temperatures ranging from 20 to 300 K at wavelengths from 1.1 to 5.6 m, while for germanium, we cover temperatures ranging from 20 to 300 K and wavelengths from 1.9 to 5.5 m. We compare our measurements with others in the literature and provide temperature-dependent Sellmeier coefficients based on our data to allow accurate interpolation of index to other wavelengths and temperatures. Citing the wide variety of values for the refractive indices of these two materials found in the literature, we reiterate the importance of measuring the refractive index of a sample from the same batch of raw material from which final optical components are cut when absolute accuracy greater than ±5 x 10-3 is desired.},
  eventtitle = {{{SPIE Astronomical Telescopes}} + {{Instrumentation}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Semiconductor\Temperature-dependent_refractive_index_of_silicon_and_germanium_Frey_et_al_2006.pdf}
}

@article{fuAsymmetricLearnedImage2023,
  title = {Asymmetric {{Learned Image Compression With Multi-Scale Residual Block}}, {{Importance Scaling}}, and {{Post-Quantization Filtering}}},
  author = {Fu, Haisheng and Liang, Feng and Liang, Jie and Li, Binglin and Zhang, Guohe and Han, Jingning},
  date = {2023-08},
  journaltitle = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {33},
  number = {8},
  pages = {4309--4321},
  issn = {1558-2205},
  doi = {10.1109/TCSVT.2023.3237274},
  url = {https://ieeexplore.ieee.org/abstract/document/10018275?casa_token=Hg2SO8bS2MQAAAAA:1svLbtiYkGUrqf3HLAoBINrRKLx_aVyFDedd3D7rH-jHzMCcH52G4MXmh5QD-ApHrKxFfiBD2Q},
  urldate = {2024-11-26},
  abstract = {Recently, deep learning-based image compression has made significant progresses, and has achieved better rate-distortion (R-D) performance than the latest traditional method, H.266/VVC, in both MS-SSIM metric and the more challenging PSNR metric. However, a major problem is that the complexities of many leading learned schemes are too high. In this paper, we propose an efficient and effective image coding framework, which achieves similar R-D performance with lower complexity than the state of the art. First, we develop an improved multi-scale residual block (MSRB) that can expand the receptive field and capture global information more efficiently, which further reduces the spatial correlation of the latent representations. Second, an importance scaling network is introduced to directly scale the latents to achieve content-adaptive bit allocation without sending side information, which is more flexible than previous importance map methods. Third, we apply a post-quantization filter (PQF) to reduce the quantization error, motivated by the Sample Adaptive Offset (SAO) filter in video coding. Moreover, our experiments show that the performance of the system is less sensitive to the complexity of the decoder. Therefore, we design an asymmetric paradigm, in which the encoder employs three stages of MSRBs to improve the learning capacity, whereas the decoder only uses one stage of MSRB, which reduces the decoder complexity and still yields satisfactory performance. Experimental results show that compared to the state-of-the-art method, the encoding and decoding time of the proposed method are about 17 times faster, and the R-D performance is only reduced by about 1\% on both Kodak and Tecnick-40 datasets, which is still better than H.266/VVC(4:4:4) and other leading learning-based methods. Our source code is publicly available at https://github.com/fengyurenpingsheng.},
  eventtitle = {{{IEEE Transactions}} on {{Circuits}} and {{Systems}} for {{Video Technology}}},
  keywords = {Bit rate,Complexity theory,Decoding,entropy coding,Entropy coding,Image coding,importance scaling,Learning-based image compression,Measurement,multi-scale residual block,post-quantization filter,Quantization (signal)},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Asymmetric_Learned_Image_Fu_et_al_2023.pdf}
}

@online{fuCOLMAPFree3DGaussian2023,
  title = {{{COLMAP-Free 3D Gaussian Splatting}}},
  author = {Fu, Yang and Liu, Sifei and Kulkarni, Amey and Kautz, Jan and Efros, Alexei A. and Wang, Xiaolong},
  date = {2023-12-12},
  eprint = {2312.07504},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.07504},
  url = {http://arxiv.org/abs/2312.07504},
  urldate = {2024-05-05},
  abstract = {While neural rendering has led to impressive advances in scene reconstruction and novel view synthesis, it relies heavily on accurately pre-computed camera poses. To relax this constraint, multiple efforts have been made to train Neural Radiance Fields (NeRFs) without pre-processed camera poses. However, the implicit representations of NeRFs provide extra challenges to optimize the 3D structure and camera poses at the same time. On the other hand, the recently proposed 3D Gaussian Splatting provides new opportunities given its explicit point cloud representations. This paper leverages both the explicit geometric representation and the continuity of the input video stream to perform novel view synthesis without any SfM preprocessing. We process the input frames in a sequential manner and progressively grow the 3D Gaussians set by taking one input frame at a time, without the need to pre-compute the camera poses. Our method significantly improves over previous approaches in view synthesis and camera pose estimation under large motion changes. Our project page is https://oasisyang.github.io/colmap-free-3dgs},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\CameraParameters\COLMAP-Free_3D_Gaussian_Fu_et_al_2023.pdf}
}

@online{fuGeoWizardUnleashingDiffusion2024,
  title = {{{GeoWizard}}: {{Unleashing}} the {{Diffusion Priors}} for {{3D Geometry Estimation}} from a {{Single Image}}},
  shorttitle = {{{GeoWizard}}},
  author = {Fu, Xiao and Yin, Wei and Hu, Mu and Wang, Kaixuan and Ma, Yuexin and Tan, Ping and Shen, Shaojie and Lin, Dahua and Long, Xiaoxiao},
  date = {2024-03-18},
  eprint = {2403.12013},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.12013},
  url = {http://arxiv.org/abs/2403.12013},
  urldate = {2024-07-16},
  abstract = {We introduce GeoWizard, a new generative foundation model designed for estimating geometric attributes, e.g., depth and normals, from single images. While significant research has already been conducted in this area, the progress has been substantially limited by the low diversity and poor quality of publicly available datasets. As a result, the prior works either are constrained to limited scenarios or suffer from the inability to capture geometric details. In this paper, we demonstrate that generative models, as opposed to traditional discriminative models (e.g., CNNs and Transformers), can effectively address the inherently ill-posed problem. We further show that leveraging diffusion priors can markedly improve generalization, detail preservation, and efficiency in resource usage. Specifically, we extend the original stable diffusion model to jointly predict depth and normal, allowing mutual information exchange and high consistency between the two representations. More importantly, we propose a simple yet effective strategy to segregate the complex data distribution of various scenes into distinct sub-distributions. This strategy enables our model to recognize different scene layouts, capturing 3D geometry with remarkable fidelity. GeoWizard sets new benchmarks for zero-shot depth and normal prediction, significantly enhancing many downstream applications such as 3D reconstruction, 2D content creation, and novel viewpoint synthesis.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\SingleImage\GeoWizard_Fu_et_al_2024.pdf}
}

@article{fuLearnedImageCompression2023,
  title = {Learned {{Image Compression With Gaussian-Laplacian-Logistic Mixture Model}} and {{Concatenated Residual Modules}}},
  author = {Fu, Haisheng and Liang, Feng and Lin, Jianping and Li, Bing and Akbari, Mohammad and Liang, Jie and Zhang, Guohe and Liu, Dong and Tu, Chengjie and Han, Jingning},
  date = {2023},
  journaltitle = {IEEE Transactions on Image Processing},
  volume = {32},
  pages = {2063--2076},
  issn = {1941-0042},
  doi = {10.1109/TIP.2023.3263099},
  url = {https://ieeexplore.ieee.org/abstract/document/10091784?casa_token=-b_pKCG5l9cAAAAA:kzZhjPCHjBw3OJskhuitArTP0lSKYq5p0DXIeztWmJPhrtVCL4eIk3_PwLXmg2X2ak42ihWt3w},
  urldate = {2024-11-25},
  abstract = {Recently deep learning-based image compression methods have achieved significant achievements and gradually outperformed traditional approaches including the latest standard Versatile Video Coding (VVC) in both PSNR and MS-SSIM metrics. Two key components of learned image compression are the entropy model of the latent representations and the encoding/decoding network architectures. Various models have been proposed, such as autoregressive, softmax, logistic mixture, Gaussian mixture, and Laplacian. Existing schemes only use one of these models. However, due to the vast diversity of images, it is not optimal to use one model for all images, even different regions within one image. In this paper, we propose a more flexible discretized Gaussian-Laplacian-Logistic mixture model (GLLMM) for the latent representations, which can adapt to different contents in different images and different regions of one image more accurately and efficiently, given the same complexity. Besides, in the encoding/decoding network design part, we propose a concatenated residual blocks (CRB), where multiple residual blocks are serially connected with additional shortcut connections. The CRB can improve the learning ability of the network, which can further improve the compression performance. Experimental results using the Kodak, Tecnick-100 and Tecnick-40 datasets show that the proposed scheme outperforms all the leading learning-based methods and existing compression standards including VVC intra coding (4:4:4 and 4:2:0) in terms of the PSNR and MS-SSIM. The source code is available at https://github.com/fengyurenpingsheng.},
  eventtitle = {{{IEEE Transactions}} on {{Image Processing}}},
  keywords = {Complexity theory,Context modeling,Correlation,Decoding,Deep learning-based image compression,Entropy,entropy coding,Entropy coding,Gaussian mixture model,Image coding,residual network},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Learned_Image_Compression_Fu_et_al_2023.pdf}
}

@article{fuMonitoringBronchoalveolarLavage2020,
  title = {Monitoring Bronchoalveolar Lavage with Electrical Impedance Tomography: First Experience in a Patient with {{COVID-19}}},
  shorttitle = {Monitoring Bronchoalveolar Lavage with Electrical Impedance Tomography},
  author = {Fu, Yingyun and Zou, Rongrong and Wang, Shouhong and Wen, Junmin and Rong, Lei and Tang, Ming and Yu, Baojun and Cen, Fulan and Zhao, Zhanqi and Frerichs, Inéz and Adler, Andy and Liu, Yingxia and Liu, Lei},
  date = {2020-09-10},
  journaltitle = {Physiol. Meas.},
  volume = {41},
  number = {8},
  pages = {085008},
  issn = {1361-6579},
  doi = {10.1088/1361-6579/abab1b},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/abab1b},
  urldate = {2024-07-08},
  abstract = {Objective: Patients with the novel coronavirus disease (COVID-19) often have airway secretions that severely compromise ventilation. This study investigates electrical impedance tomography (EIT) monitoring of a therapeutic bronchoalveolar lavage (BAL) in a patient with COVID-19. Approach: A patient with COVID-19 developed acute respiratory distress syndrome requiring mechanical ventilation. He received regional BAL to remove mucus in the small airways (20 ml × 5). Regional ventilation changes before BAL, 30 min after and in the following days, were monitored with EIT. Main results: Regional ventilation worsened shortly after BAL and improved in the following days. The improvement of the oxygenation did not exactly match the ventilation improvement, which indicated a possible ventilation/perfusion mismatch. Significance: Therapeutic BAL might improve regional ventilation for COVID-19 and EIT could be a useful tool at the bedside to monitor the ventilation treatment of COVID-19.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Monitoring_bronchoalveolar_lavage_with_electrical_impedance_tomography_Fu_et_al_2020.pdf}
}

@online{fuVideoMMEFirstEverComprehensive2024,
  title = {Video-{{MME}}: {{The First-Ever Comprehensive Evaluation Benchmark}} of {{Multi-modal LLMs}} in {{Video Analysis}}},
  shorttitle = {Video-{{MME}}},
  author = {Fu, Chaoyou and Dai, Yuhan and Luo, Yongdong and Li, Lei and Ren, Shuhuai and Zhang, Renrui and Wang, Zihan and Zhou, Chenyu and Shen, Yunhang and Zhang, Mengdan and Chen, Peixian and Li, Yanwei and Lin, Shaohui and Zhao, Sirui and Li, Ke and Xu, Tong and Zheng, Xiawu and Chen, Enhong and Ji, Rongrong and Sun, Xing},
  date = {2024-06-16},
  eprint = {2405.21075},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2405.21075},
  urldate = {2024-09-22},
  abstract = {In the quest for artificial general intelligence, Multi-modal Large Language Models (MLLMs) have emerged as a focal point in recent advancements. However, the predominant focus remains on developing their capabilities in static image understanding. The potential of MLLMs in processing sequential visual data is still insufficiently explored, highlighting the absence of a comprehensive, highquality assessment of their performance. In this paper, we introduce Video-MME, the first-ever full-spectrum, Multi-Modal Evaluation benchmark of MLLMs in Video analysis. Our work distinguishes from existing benchmarks through four key features: 1) Diversity in video types, spanning 6 primary visual domains with 30 subfields to ensure broad scenario generalizability; 2) Duration in temporal dimension, encompassing both short-, medium-, and long-term videos, ranging from 11 seconds to 1 hour, for robust contextual dynamics; 3) Breadth in data modalities, integrating multi-modal inputs besides video frames, including subtitles and audios, to unveil the all-round capabilities of MLLMs; 4) Quality in annotations, utilizing rigorous manual labeling by expert annotators to facilitate precise and reliable model assessment. 900 videos with a total of 254 hours are manually selected and annotated by repeatedly viewing all the video content, resulting in 2,700 question-answer pairs. With Video-MME, we extensively evaluate various state-of-the-art MLLMs, including GPT-4 series and Gemini 1.5 Pro, as well as open-source image models like InternVL-Chat-V1.5 and video models like LLaVA-NeXT-Video. Our experiments reveal that Gemini 1.5 Pro is the best-performing commercial model, significantly outperforming the open-source models with an average accuracy of 75\%, compared to 71.9\% for GPT-4o. The results also demonstrate that Video-MME is a universal benchmark, which applies to both image and video MLLMs. Further analysis indicates that subtitle and audio information could significantly enhance video understanding. Besides, a decline in MLLM performance is observed as video duration increases for all models. Our dataset along with these findings underscores the need for further improvements in handling longer sequences and multi-modal data, shedding light on future MLLM development. Project page: https://video-mme.github.io.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoModels\Video-MME_Fu_et_al_2024.pdf}
}

@article{gahlyanThermodynamicsTernaryMixtures2020,
  title = {Thermodynamics of Ternary Mixtures with Gasoline Additive: {{Volumetric}}, Acoustic and Optical Properties},
  shorttitle = {Thermodynamics of Ternary Mixtures with Gasoline Additive},
  author = {Gahlyan, Suman and Bhagat, Payal and Devi, Rekha and Verma, Sweety and Rani, Manju and Maken, Sanjeev},
  date = {2020-04},
  journaltitle = {Journal of Molecular Liquids},
  volume = {304},
  pages = {112740},
  issn = {01677322},
  doi = {10.1016/j.molliq.2020.112740},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167732220301902},
  urldate = {2023-09-05},
  abstract = {Excess molar volume (VmE ), deviation in ultrasonic speed (Δu) and deviation in refractive index (Δn) of ternary mixtures with gasoline additives diisopropyl ether (DIPE) + benzene + n-heptane were derived from the measured density, ultrasonic speed and refractive index with Anton Paar vibrating tube densimeter, sound analyzer and Abbemat 200 refractometer, respectively at different temperature of 298.15 K, 308.15 K and 318.15 K and atmospheric pressure. The VmE values for the ternary mixtures were predicted using pragmatic equations and geometrical solution models employing constituent binary data. The VmE have also been interpreted using PrigogineFlory-Patterson theory. The ultrasonic speed data was analyzed using like Nomato, van Dael, impedance dependence correlations and CFT theory at 298.15 K. Jacobson free length theory was employed to compute LfE and VaE at 298.15 K. The refractive indices of the ternary mixtures were also predicted using various mixing rules. The VmE ,Δu, KSE and Δn derived values were also fitted to the Singh equation.},
  langid = {english},
  file = {C\:\\Users\\ahmed\\OneDrive\\OneDrive - Faculty Of Science (Sohag University)\\Research\\Photonics\\Materials\\OpticalAcousticProperties\\Thermodynamics_of_ternary_mixtures_with_gasoline_additive_Gahlyan_et_al_2020.docx;C\:\\Users\\ahmed\\OneDrive\\OneDrive - Faculty Of Science (Sohag University)\\Research\\Photonics\\Materials\\OpticalAcousticProperties\\Thermodynamics_of_ternary_mixtures_with_gasoline_additive_Gahlyan_et_al_2020.pdf}
}

@article{gahlyanVolumetricAcousticOptical2020,
  title = {Volumetric, Acoustic and Optical Studies of Ternary Mixture of Diisopropyl Ether, n-Heptane and n-Octane},
  author = {Gahlyan, Suman and Rani, Manju and Devi, Rekha and Park, So-Jin and Maken, Sanjeev},
  date = {2020-05},
  journaltitle = {Journal of Molecular Liquids},
  volume = {306},
  pages = {112605},
  issn = {01677322},
  doi = {10.1016/j.molliq.2020.112605},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167732219338917},
  urldate = {2023-09-05},
  abstract = {Density, ultrasonic speed and refractive indices of the ternary liquid mixture of diisopropyl ether (DIPE), nheptane and n-octane were experimentally determined at 298.15 K to 318.15 K. Excess molar volume (VmE ), deviation in speed of sound (Δu), excess isentropic compressibility (KSE), excess intermolecular free length (LfE) and deviation in refractive index (Δn) of ternary mixtures were derived from experimental data. The VmE values were fitted to the Singh, Cibulka and Nagata equations and the same have also been interpreted using Prigogine-FloryPatterson theory. Various geometrical solution models like Tsao-Smith model, Jacob-Fitzner model, Kohler model, Rastogi model and Radojkovic model were used to predict VmE for the ternary mixtures using their binary excess volume data. Various correlations like Nomato, van Dael, impedance dependence relations and CFT theory were used to correlate speed of sound data at 298.15 K. LfE and VaE were also calculated from Jacobson free length theory at 298.15 K. The Δu, KSE, LfE, VaE and Δn values were also fitted to the Singh equation. Various mixing rules Arago-Biot, Gladstone-Dale, Weiner, Heller, Newton, Eyring and John were used for theoretical prediction of refractive indices of the ternary mixture. Temperature effects on various properties were also studied.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Volumetric,_acoustic_and_optical_studies_of_ternary_mixture_of_diisopropyl_Gahlyan_et_al_2020.pdf}
}

@book{gammaDesignPatternsElements,
  title = {Design {{Patterns}} : {{Elements}} of {{Reusable Object-Oriented Software}}},
  author = {Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\Programming\Design_Patterns__Gamma_et_al_.pdf}
}

@article{gaoClassificationNormalCancerous2014,
  title = {Classification of Normal and Cancerous Lung Tissues by Electrical Impendence Tomography},
  author = {Gao, Jianling and Yue, Shihong and Chen, Jun and Wang, Huaxiang},
  date = {2014},
  journaltitle = {Bio-Medical Materials and Engineering},
  volume = {24},
  number = {6},
  pages = {2229--2241},
  issn = {09592989, 18783619},
  doi = {10.3233/BME-141035},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/BME-141035},
  urldate = {2024-07-08},
  abstract = {Biological tissue impedance spectroscopy can provide rich physiological and pathological information by measuring the variation of the complex impedance of biological tissues under various frequencies of driven current. Electrical Impedance Tomography (EIT) technique can measure the impedance spectroscopy of biological tissue in medical field. Before application, a key problem must be solved on how to generally distinguish normal tissues from the cancerous in terms of measurable EIT data. In this paper, the impedance spectroscopy characteristics of human lung tissue are studied. On the basis of the measured data of 109 lung cancer patients, Cole-Cole Circle radius (CCCR) and the complex modulus are extracted. In terms of the two characteristics, 71.6\% and 66.4\% samples of cancerous and normal tissues can be correctly classified, respectively. Furthermore, two characteristics of the measured EIT data of each patient consist of a two-dimensional vector and all such vectors comprise a set of vectors. When classifying the vector set, the rate of correctly partitioning normal and cancerous tissues can be raised to 78.2\%. The main factors to affect the classification results on normal and cancerous tissues are generally analyzed. The proposed method will play an important role in further working out an efficient and feasible diagnostic method for potential lung cancer patients, and provide theoretical basis and reference data for electrical impedance tomography technology in monitoring pulmonary function.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Cancer\Classification_of_normal_and_cancerous_lung_tissues_by_electrical_impendence_Gao_et_al_2014.pdf}
}

@inproceedings{gaoEITCDAE2DElectrical2019,
  title = {{{EIT-CDAE}}: {{A}} 2-{{D Electrical Impedance Tomography Image Reconstruction Method Based}} on {{Auto Encoder Technique}}},
  shorttitle = {{{EIT-CDAE}}},
  booktitle = {2019 {{IEEE Biomedical Circuits}} and {{Systems Conference}} ({{BioCAS}})},
  author = {Gao, Yue and Lu, Yewangqing and Li, Hui and Liu, Boxiao and Li, Yongfu and Chen, Mingyi and Wang, Guoxing and Lian, Yong},
  date = {2019-10},
  pages = {1--4},
  publisher = {IEEE},
  location = {Nara, Japan},
  doi = {10.1109/BIOCAS.2019.8918979},
  url = {https://ieeexplore.ieee.org/document/8918979/},
  urldate = {2024-07-03},
  eventtitle = {2019 {{IEEE Biomedical Circuits}} and {{Systems Conference}} ({{BioCAS}})},
  isbn = {978-1-5090-0617-5},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Autoencoder\EIT-CDAE_Gao_et_al_2019.pdf}
}

@article{gaoNovelTouchInterface2022,
  title = {A {{Novel Touch Interface}} with {{Ultrahigh Optical Transmittance Based}} on {{Electrical Impedance Tomography}} for {{Interactive Displays}}},
  author = {Gao, Shuo and Lv, Ruihan and Sun, Shijie},
  date = {2022-06},
  journaltitle = {Adv Materials Technologies},
  volume = {7},
  number = {6},
  pages = {2101133},
  issn = {2365-709X, 2365-709X},
  doi = {10.1002/admt.202101133},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/admt.202101133},
  urldate = {2024-07-08},
  abstract = {Abstract                            In traditional touch interfaces, electrodes will block the light intensity of the display, so extra power is required to maintain the display performance. In this article, an eight‐electrode electrical impedance tomography system for touch location detection is proposed to improve the transmittance. The electrodes are settled at the edge of the touch panel and a machine learning algorithm is used to perform the regression process. This system can achieve almost 1 mm mean absolute error in               X               ‐ and               Y               ‐directions on a 30 × 30 mm               2               2D surface and guarantee nearly 94\% light transmittance. The results from experiments show the feasibility of the new structure for high optical transmittance interactive display in the future.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Touch\A_Novel_Touch_Interface_with_Ultrahigh_Optical_Transmittance_Based_on_Gao_et_al_2022.pdf}
}

@inproceedings{gaoPerceptualFriendlyVariable2021,
  title = {Perceptual {{Friendly Variable Rate Image Compression}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  author = {Gao, Yixin and Wu, Yaojun and Guo, Zongyu and Zhang, Zhizheng and Chen, Zhibo},
  date = {2021-06},
  pages = {1916--1920},
  issn = {2160-7516},
  doi = {10.1109/CVPRW53098.2021.00217},
  url = {https://ieeexplore.ieee.org/document/9523102},
  urldate = {2024-12-20},
  abstract = {In this paper, we study high fidelity variable rate compression framework. Both conventional and learned codecs in prior works are optimized for objective quality commonly measured by PSNR or SSIM, leaving perceptual quality optimization underexplored. Besides, to circumvent the need of training separate models under different rate conditions, we design a novel coding framework to support variable rate compression. Aside from the variable rate functionality, we propose an adaptive bit allocation unit to strengthen rate-distortion optimization across different rates. Extensive experimental results demonstrate that our proposed approach achieves better subjective quality than methods optimized by the objective metrics such as MSE, and MS-SSIM on CLIC 2021 validation dataset.},
  eventtitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  keywords = {Adaptation models,Conferences,Image coding,Measurement,Rate-distortion,Training,Visualization},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Perceptual_Friendly_Variable_Gao_et_al_2021.pdf}
}

@online{garciaFineTuningImageConditionalDiffusion2024,
  title = {Fine-{{Tuning Image-Conditional Diffusion Models}} Is {{Easier}} than {{You Think}}},
  author = {Garcia, Gonzalo Martin and Zeid, Karim Abou and Schmidt, Christian and family=Geus, given=Daan, prefix=de, useprefix=false and Hermans, Alexander and Leibe, Bastian},
  date = {2024-09-17},
  eprint = {2409.11355},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2409.11355},
  url = {http://arxiv.org/abs/2409.11355},
  urldate = {2024-10-23},
  abstract = {Recent work showed that large diffusion models can be reused as highly precise monocular depth estimators by casting depth estimation as an image-conditional image generation task. While the proposed model achieved state-of-the-art results, high computational demands due to multi-step inference limited its use in many scenarios. In this paper, we show that the perceived inefficiency was caused by a flaw in the inference pipeline that has so far gone unnoticed. The fixed model performs comparably to the best previously reported configuration while being more than 200\$\textbackslash times\$ faster. To optimize for downstream task performance, we perform end-to-end fine-tuning on top of the single-step model with task-specific losses and get a deterministic model that outperforms all other diffusion-based depth and normal estimation models on common zero-shot benchmarks. We surprisingly find that this fine-tuning protocol also works directly on Stable Diffusion and achieves comparable performance to current state-of-the-art diffusion-based depth and normal estimation models, calling into question some of the conclusions drawn from prior works.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\DiffusionModels\Fine-Tuning_Image-Conditional_Garcia_et_al_2024.pdf}
}

@article{gardeMimickingRelativeContinuum2021,
  title = {Mimicking Relative Continuum Measurements by Electrode Data in Two-Dimensional Electrical Impedance Tomography},
  author = {Garde, Henrik and Hyvönen, Nuutti},
  date = {2021-03},
  journaltitle = {Numer. Math.},
  volume = {147},
  number = {3},
  pages = {579--609},
  issn = {0029-599X, 0945-3245},
  doi = {10.1007/s00211-020-01170-8},
  url = {http://link.springer.com/10.1007/s00211-020-01170-8},
  urldate = {2024-07-03},
  abstract = {This paper introduces a constructive method for approximating relative continuum measurements in two-dimensional electrical impedance tomography based on data originating from either the point electrode model or the complete electrode model. The upper bounds for the corresponding approximation errors explicitly depend on the number (and size) of the employed electrodes as well as on the regularity of the continuum current that is mimicked. In particular, if the input current and the object boundary are infinitely smooth, the discrepancy associated with the point electrode model converges to zero faster than any negative power of the number of electrodes. The results are first proven for the unit disk via trigonometric interpolation and quadrature rules, and they are subsequently extended to more general domains with the help of conformal mappings.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\ContinuumMeasurements\Mimicking_relative_continuum_measurements_by_electrode_data_in_two-dimensional_Garde_Hyvonen_2021.pdf}
}

@inproceedings{garneloConditionalNeuralProcesses2018,
  title = {Conditional {{Neural Processes}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Garnelo, Marta and Rosenbaum, Dan and Maddison, Christopher and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo and Eslami, S. M. Ali},
  date = {2018-07-03},
  pages = {1704--1713},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v80/garnelo18a.html},
  urldate = {2024-12-02},
  abstract = {Deep neural networks excel at function approximation, yet they are typically trained from scratch for each new function. On the other hand, Bayesian methods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly infer the shape of a new function at test time. Yet, GPs are computationally expensive, and it can be hard to design appropriate priors. In this paper we propose a family of neural models, Conditional Neural Processes (CNPs), that combine the benefits of both. CNPs are inspired by the flexibility of stochastic processes such as GPs, but are structured as neural networks and trained via gradient descent. CNPs make accurate predictions after observing only a handful of training data points, yet scale to complex functions and large datasets. We demonstrate the performance and versatility of the approach on a range of canonical machine learning tasks, including regression, classification and image completion.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Quantization\Compression\Conditional_Neural_Processes_Garnelo_et_al_2018.pdf}
}

@article{gatidisWholebodyFDGPETCT2022,
  title = {A Whole-Body {{FDG-PET}}/{{CT Dataset}} with Manually Annotated {{Tumor Lesions}}},
  author = {Gatidis, Sergios and Hepp, Tobias and Früh, Marcel and La Fougère, Christian and Nikolaou, Konstantin and Pfannenberg, Christina and Schölkopf, Bernhard and Küstner, Thomas and Cyran, Clemens and Rubin, Daniel},
  date = {2022-10-04},
  journaltitle = {Sci Data},
  volume = {9},
  number = {1},
  pages = {601},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/s41597-022-01718-3},
  url = {https://www.nature.com/articles/s41597-022-01718-3},
  urldate = {2024-11-28},
  abstract = {We describe a publicly available dataset of annotated Positron Emission Tomography/Computed Tomography (PET/CT) studies. 1014 whole body Fluorodeoxyglucose (FDG)-PET/CT datasets (501 studies of patients with malignant lymphoma, melanoma and non small cell lung cancer (NSCLC) and 513 studies without PET-positive malignant lesions (negative controls)) acquired between 2014 and 2018 were included. All examinations were acquired on a single, state-of-the-art PET/CT scanner. The imaging protocol consisted of a whole-body FDG-PET acquisition and a corresponding diagnostic CT scan. All FDG-avid lesions identified as malignant based on the clinical PET/CT report were manually segmented on PET images in a slice-per-slice (3D) manner. We provide the anonymized original DICOM files of all studies as well as the corresponding DICOM segmentation masks. In addition, we provide scripts for image processing and conversion to different file formats (NIfTI, mha, hdf5). Primary diagnosis, age and sex are provided as non-imaging information. We demonstrate how this dataset can be used for deep learning-based automated analysis of PET/CT data and provide the trained deep learning model.},
  langid = {english},
  keywords = {Cancer imaging,Diagnostic markers,Whole body imaging},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\Datasets\A_whole-body_FDG-PET-CT_Gatidis_et_al_2022.pdf}
}

@article{gedeonTimeDomainTopologyOptimization2023,
  title = {Time-{{Domain Topology Optimization}} of {{Arbitrary Dispersive Materials}} for {{Broadband 3D Nanophotonics Inverse Design}}},
  author = {Gedeon, Johannes and Hassan, Emadeldeen and Calà Lesina, Antonio},
  date = {2023-11-15},
  journaltitle = {ACS Photonics},
  volume = {10},
  number = {11},
  pages = {3875--3887},
  publisher = {American Chemical Society},
  doi = {10.1021/acsphotonics.3c00572},
  url = {https://doi.org/10.1021/acsphotonics.3c00572},
  urldate = {2024-06-01},
  abstract = {In the last decades, nanostructures have unlocked myriads of functionalities in nanophotonics by engineering light–matter interaction beyond what is possible with conventional bulk optics. The space of parameters available for design is practically unlimited due to the large variety of optical materials and nanofabrication techniques. Thus, computational approaches are necessary to efficiently search for the optimal solutions. In this paper, we enable the free-form inverse design in 3D of linear optical materials with arbitrary dispersion and anisotropy. This is achieved by (1) deriving an analytical adjoint scheme based on the complex-conjugate pole-residue pair model in the time domain and (2) its implementation in a parallel finite-difference time-domain framework with a topology optimization routine, efficiently running on high-performance computing systems. Our method is tested on the design problem of field confinement using dispersive nanostructures. The obtained designs satisfy the fundamental curiosity of how free-form metallic and dielectric nanostructures perform when optimized in 3D, also in comparison to fabrication-constrained designs. Unconventional free-form designs revealed by computational methods, although may be challenging or unfeasible to realize with current technology, bring new insights into how light can more efficiently interact with nanostructures and provide new ideas for forward design.},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\Time-Domain_Topology_Gedeon_et_al_2023.pdf}
}

@article{gehreAnalysisFiniteElement2014,
  title = {An Analysis of Finite Element Approximation in Electrical Impedance Tomography},
  author = {Gehre, Matthias and Jin, Bangti and Lu, Xiliang},
  date = {2014-04-01},
  journaltitle = {Inverse Problems},
  volume = {30},
  number = {4},
  pages = {045013},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/0266-5611/30/4/045013},
  url = {https://iopscience.iop.org/article/10.1088/0266-5611/30/4/045013},
  urldate = {2024-07-08},
  abstract = {We present a finite element analysis of electrical impedance tomography for reconstructing the conductivity distribution from electrode voltage measurements by means of Tikhonov regularization. Two popular choices of the penalty term, i.e., the H1( )-norm smoothness penalty and total variation seminorm penalty, are considered. A piecewise linear finite element method is employed for discretizing the forward model, i.e., the complete electrode model, the conductivity, and the penalty functional. The convergence of the finite element approximations for the Tikhonov model on both polyhedral and smooth curved domains is established. This provides rigorous justifications for the ad hoc discretization procedures. Numerical experiments confirm the convergence analysis.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\InaccuratelyKnownBoundary\An_analysis_of_finite_element_approximation_in_electrical_impedance_tomography_Gehre_et_al_2014.pdf}
}

@article{gellyInverseDesignedNanophotonicInterface2023,
  title = {An {{Inverse-Designed Nanophotonic Interface}} for {{Excitons}} in {{Atomically Thin Materials}}},
  author = {Gelly, Ryan J. and White, Alexander D. and Scuri, Giovanni and Liao, Xing and Ahn, Geun Ho and Deng, Bingchen and Watanabe, Kenji and Taniguchi, Takashi and Vučković, Jelena and Park, Hongkun},
  date = {2023-09-27},
  journaltitle = {Nano Lett.},
  volume = {23},
  number = {18},
  pages = {8779--8786},
  publisher = {American Chemical Society},
  issn = {1530-6984},
  doi = {10.1021/acs.nanolett.3c02931},
  url = {https://doi.org/10.1021/acs.nanolett.3c02931},
  urldate = {2024-06-01},
  abstract = {Efficient nanophotonic devices are essential for applications in quantum networking, optical information processing, sensing, and nonlinear optics. Extensive research efforts have focused on integrating two-dimensional (2D) materials into photonic structures, but this integration is often limited by size and material quality. Here, we use hexagonal boron nitride (hBN), a benchmark choice for encapsulating atomically thin materials, as a waveguiding layer while simultaneously improving the optical quality of the embedded films. When combined with a photonic inverse design, it becomes a complete nanophotonic platform to interface with optically active 2D materials. Grating couplers and low-loss waveguides provide optical interfacing and routing, tunable cavities provide a large exciton-photon coupling to transition metal dichalcogenide (TMD) monolayers through Purcell enhancement, and metasurfaces enable the efficient detection of TMD dark excitons. This work paves the way for advanced 2D-material nanophotonic structures for classical and quantum nonlinear optics.},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\An_Inverse-Designed_Gelly_et_al_2023.pdf}
}

@online{gholamiSurveyQuantizationMethods2021,
  title = {A {{Survey}} of {{Quantization Methods}} for {{Efficient Neural Network Inference}}},
  author = {Gholami, Amir and Kim, Sehoon and Dong, Zhen and Yao, Zhewei and Mahoney, Michael W. and Keutzer, Kurt},
  date = {2021-06-21},
  eprint = {2103.13630},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2103.13630},
  urldate = {2024-07-24},
  abstract = {As soon as abstract mathematical computations were adapted to computation on digital computers, the problem of efficient representation, manipulation, and communication of the numerical values in those computations arose. Strongly related to the problem of numerical representation is the problem of quantization: in what manner should a set of continuous real-valued numbers be distributed over a fixed discrete set of numbers to minimize the number of bits required and also to maximize the accuracy of the attendant computations? This perennial problem of quantization is particularly relevant whenever memory and/or computational resources are severely restricted, and it has come to the forefront in recent years due to the remarkable performance of Neural Network models in computer vision, natural language processing, and related areas. Moving from floating-point representations to low-precision fixed integer values represented in four bits or less holds the potential to reduce the memory footprint and latency by a factor of 16x; and, in fact, reductions of 4x to 8x are often realized in practice in these applications. Thus, it is not surprising that quantization has emerged recently as an important and very active sub-area of research in the efficient implementation of computations associated with Neural Networks. In this article, we survey approaches to the problem of quantizing the numerical values in deep Neural Network computations, covering the advantages/disadvantages of current methods. With this survey and its organization, we hope to have presented a useful snapshot of the current research in quantization for Neural Networks and to have given an intelligent organization to ease the evaluation of future research in this area.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Quantization\A_Survey_of_Quantization_Methods_for_Efficient_Neural_Network_Inference_Gholami_et_al_2021.pdf}
}

@article{gianniosComplexRefractiveIndex2017,
  title = {Complex Refractive Index of Normal and Malignant Human Colorectal Tissue in the Visible and Near-Infrared},
  author = {Giannios, Panagiotis and Koutsoumpos, Spyridon and Toutouzas, Konstantinos G. and Matiatou, Maria and Zografos, George C. and Moutzouris, Konstantinos},
  date = {2017-02},
  journaltitle = {J. Biophoton},
  volume = {10},
  number = {2},
  pages = {303--310},
  issn = {1864063X},
  doi = {10.1002/jbio.201600001},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/jbio.201600001},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\BioMaterial\Complex_refractive_index_of_normal_and_malignant_human_colorectal_tissue_in_the_Giannios_et_al_2017.pdf}
}

@inproceedings{gomesVideoCompressionEntropyConstrained2023,
  title = {Video {{Compression}} with {{Entropy-Constrained Neural Representations}}},
  booktitle = {2023 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Gomes, Carlos and Azevedo, Roberto and Schroers, Christopher},
  date = {2023-06},
  pages = {18497--18506},
  publisher = {IEEE},
  location = {Vancouver, BC, Canada},
  doi = {10.1109/CVPR52729.2023.01774},
  url = {https://ieeexplore.ieee.org/document/10203904/},
  urldate = {2024-08-08},
  abstract = {Encoding videos as neural networks is a recently proposed approach that allows new forms of video processing. However, traditional techniques still outperform such neural video representation (NVR) methods for the task of video compression. This performance gap can be explained by the fact that current NVR methods: i) use architectures that do not efficiently obtain a compact representation of temporal and spatial information; and ii) minimize rate and distortion disjointly (first overfitting a network on a video and then using heuristic techniques such as post-training quantization or weight pruning to compress the model). We propose a novel convolutional architecture for video representation that better represents spatio-temporal information and a training strategy capable of jointly optimizing rate and distortion. All network and quantization parameters are jointly learned end-to-end, and the post-training operations used in previous works are unnecessary. We evaluate our method on the UVG dataset, achieving new state-ofthe-art results for video compression with NVRs. Moreover, we deliver the first NVR-based video compression method that improves over the typically adopted HEVC benchmark (x265, disabled b-frames, “medium” preset), closing the gap to autoencoder-based video compression techniques.},
  eventtitle = {2023 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {9798350301298},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoCodec\Video_Compression_with_Entropy-Constrained_Neural_Representations_Gomes_et_al_2023.pdf}
}

@article{gonzalez-olmosThermodynamicsOxygenateFuel2008,
  title = {Thermodynamics of Oxygenate Fuel Additives as a Function of Temperature},
  author = {Gonzalez-Olmos, R. and Iglesias, M. and Santos, B. M. R. P. and Mattedi, S.},
  date = {2008-06},
  journaltitle = {Physics and Chemistry of Liquids},
  volume = {46},
  number = {3},
  pages = {223--237},
  issn = {0031-9104, 1029-0451},
  doi = {10.1080/00319100701660411},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00319100701660411},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Thermodynamics_of_oxygenate_fuel_additives_as_a_function_of_temperature_Gonzalez-Olmos_et_al_2008.pdf}
}

@article{goodallPredictingMaterialsProperties2020,
  title = {Predicting Materials Properties without Crystal Structure: Deep Representation Learning from Stoichiometry},
  shorttitle = {Predicting Materials Properties without Crystal Structure},
  author = {Goodall, Rhys E. A. and Lee, Alpha A.},
  date = {2020-12-08},
  journaltitle = {Nat Commun},
  volume = {11},
  number = {1},
  pages = {6280},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-19964-7},
  url = {https://www.nature.com/articles/s41467-020-19964-7},
  urldate = {2023-09-05},
  abstract = {Abstract             Machine learning has the potential to accelerate materials discovery by accurately predicting materials properties at a low computational cost. However, the model inputs remain a key stumbling block. Current methods typically use descriptors constructed from knowledge of either the full crystal structure~—~therefore only applicable to materials with already characterised structures~—~or structure-agnostic fixed-length representations hand-engineered from the stoichiometry. We develop a machine learning approach that takes only the stoichiometry as input and automatically learns appropriate and systematically improvable descriptors from data. Our key insight is to treat the stoichiometric formula as a dense weighted graph between elements. Compared to the state of the art for structure-agnostic methods, our approach achieves lower errors with less data.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\AI\Application\MaterialScience\Predicting_materials_properties_without_crystal_structure_Goodall_Lee_2020.pdf}
}

@online{gordonConvolutionalConditionalNeural2020,
  title = {Convolutional {{Conditional Neural Processes}}},
  author = {Gordon, Jonathan and Bruinsma, Wessel P. and Foong, Andrew Y. K. and Requeima, James and Dubois, Yann and Turner, Richard E.},
  date = {2020-06-25},
  eprint = {1910.13556},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.1910.13556},
  url = {http://arxiv.org/abs/1910.13556},
  urldate = {2024-12-02},
  abstract = {We introduce the Convolutional Conditional Neural Process (ConvCNP), a new member of the Neural Process family that models translation equivariance in the data. Translation equivariance is an important inductive bias for many learning problems including time series modelling, spatial data, and images. The model embeds data sets into an infinite-dimensional function space as opposed to a finite-dimensional vector space. To formalize this notion, we extend the theory of neural representations of sets to include functional representations, and demonstrate that any translation-equivariant embedding can be represented using a convolutional deep set. We evaluate ConvCNPs in several settings, demonstrating that they achieve state-of-the-art performance compared to existing NPs. We demonstrate that building in translation equivariance enables zero-shot generalization to challenging, out-of-domain tasks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Quantization\Compression\Convolutional_Conditional_Neural_Processes_Gordon_et_al_2020.pdf}
}

@incollection{gorskaAIRacialBias2024,
  title = {{{AI Racial Bias}}: {{How Text-to-Image Artificial Intelligence Generators Construct Prestigious Professions}}},
  shorttitle = {{{AI Racial Bias}}},
  booktitle = {Algorithms, {{Artificial Intelligence}} and {{Beyond}}},
  author = {Górska, Anna M. and Jemielniak, Dariusz},
  date = {2024},
  publisher = {Routledge},
  abstract = {This chapter studies the interplay between technical configurations and societal constructs within the domain of artificial intelligence (AI), with a specific emphasis on AI-enabled text-to-image generators. Drawing on conceptual frameworks informed by critical race theory and complemented by insights from science and technology studies, the discourse critically engages with the question of whether these generators inadvertently perpetuate or challenge prevailing racial stereotypes and biases. The analysis unravels the visual portrayals of four professionals in the disciplines of law, medicine, engineering, and scientific research through the lens of the nine most popular AI text-to-image generators, revealing the degree to which AI-based tools reflect and amplify societal racial biases. To evaluate in terms of race the AI-generated images of professionals, we surveyed 84 participants. The empirical evidence showcased the inclination within all AI systems towards the portrayal of white individuals, a trend that persisted even amidst a diversity of generated images. The findings show the racial bias of AI tools and its preference for “whiteness.”},
  isbn = {978-1-03-264693-0},
  pagetotal = {16}
}

@article{gostimirovicDeepLearningBasedPrediction2022,
  title = {Deep {{Learning-Based Prediction}} of {{Fabrication-Process-Induced Structural Variations}} in {{Nanophotonic Devices}}},
  author = {Gostimirovic, Dusan and Xu, Dan-Xia and Liboiron-Ladouceur, Odile and Grinberg, Yuri},
  date = {2022-08-17},
  journaltitle = {ACS Photonics},
  volume = {9},
  number = {8},
  pages = {2623--2633},
  publisher = {American Chemical Society},
  doi = {10.1021/acsphotonics.1c01973},
  url = {https://doi.org/10.1021/acsphotonics.1c01973},
  urldate = {2024-06-01},
  abstract = {The performance of integrated silicon photonic devices is sensitive to small structural variations that arise from imperfections in the nanofabrication process. This sensitivity is exacerbated for next-generation devices that require fine feature sizes to push the limits of performance. In this work, we present a deep convolutional neural network model to predict fabrication variations in planar silicon photonic devices and verify their manufacturing feasibility prior to prototyping. Our model is trained on a modest set of scanning electron microscope images of structures that experience dimensional inaccuracies stemming from combined contributions from proximity effects in lithography and loading effects in dry etching. Our model quickly and accurately predicts over/under-etching, corner rounding, filling of narrow channels and holes, and washing away of small features in a photonic device. With this, the expected performance of a device can be predicted through an extra simulation and any necessary design corrections can be made prior to fabrication.},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\ConvolutionalNeuralNetworks\Deep_Learning-Based_Prediction_of_Fabrication-Process-Induced_Structural_Gostimirovic_et_al_2022.pdf}
}

@online{govindarajanLagrangianHashingCompressed2024,
  title = {Lagrangian {{Hashing}} for {{Compressed Neural Field Representations}}},
  author = {Govindarajan, Shrisudhan and Sambugaro, Zeno and Akhmedkhan and Shabanov and Takikawa, Towaki and Rebain, Daniel and Sun, Weiwei and Conci, Nicola and Yi, Kwang Moo and Tagliasacchi, Andrea},
  date = {2024-09-09},
  eprint = {2409.05334},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.05334},
  url = {http://arxiv.org/abs/2409.05334},
  urldate = {2024-09-22},
  abstract = {We present Lagrangian Hashing, a representation for neural fields combining the characteristics of fast training NeRF methods that rely on Eulerian grids (i.e.\textasciitilde InstantNGP), with those that employ points equipped with features as a way to represent information (e.g. 3D Gaussian Splatting or PointNeRF). We achieve this by incorporating a point-based representation into the high-resolution layers of the hierarchical hash tables of an InstantNGP representation. As our points are equipped with a field of influence, our representation can be interpreted as a mixture of Gaussians stored within the hash table. We propose a loss that encourages the movement of our Gaussians towards regions that require more representation budget to be sufficiently well represented. Our main finding is that our representation allows the reconstruction of signals using a more compact representation without compromising quality.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\General\Lagrangian_Hashing_for_Govindarajan_et_al_2024.pdf}
}

@article{goyalTheoreticalFoundationsTransform2001,
  title = {Theoretical Foundations of Transform Coding},
  author = {Goyal, V.K.},
  date = {2001-09},
  journaltitle = {IEEE Signal Processing Magazine},
  volume = {18},
  number = {5},
  pages = {9--21},
  issn = {1558-0792},
  doi = {10.1109/79.952802},
  url = {https://ieeexplore.ieee.org/abstract/document/952802?casa_token=C9mmC72I-toAAAAA:rjaGbDZQRSggmfkCbMMtRgH0BhYTUjxJf9xpX2WMsv8DjzoSv99HAWeNs2bLqfd0VXDCKN71u4Y},
  urldate = {2024-08-20},
  abstract = {Discusses various aspects of transform coding, including: source coding, constrained source coding, the standard theoretical model for transform coding, entropy codes, Huffman codes, quantizers, uniform quantization, bit allocation, optimal transforms, transforms visualization, partition cell shapes, autoregressive sources, transform optimization, synthesis transform optimization, orthogonality and independence, and departures form the standard model.},
  eventtitle = {{{IEEE Signal Processing Magazine}}},
  keywords = {Bit rate,Code standards,Constraint optimization,Constraint theory,Entropy,Quantization,Shape,Source coding,Transform coding,Visualization},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataCompression\DataCompression\Theoretical_foundations_of_transform_coding_Goyal_2001.pdf}
}

@article{grayQuantization1998,
  title = {Quantization},
  author = {Gray, R.M. and Neuhoff, D.L.},
  date = {1998-10},
  journaltitle = {IEEE Transactions on Information Theory},
  volume = {44},
  number = {6},
  pages = {2325--2383},
  issn = {1557-9654},
  doi = {10.1109/18.720541},
  url = {https://ieeexplore.ieee.org/document/720541},
  urldate = {2024-05-13},
  abstract = {The history of the theory and practice of quantization dates to 1948, although similar ideas had appeared in the literature as long ago as 1898. The fundamental role of quantization in modulation and analog-to-digital conversion was first recognized during the early development of pulse-code modulation systems, especially in the 1948 paper of Oliver, Pierce, and Shannon. Also in 1948, Bennett published the first high-resolution analysis of quantization and an exact analysis of quantization noise for Gaussian processes, and Shannon published the beginnings of rate distortion theory, which would provide a theory for quantization as analog-to-digital conversion and as data compression. Beginning with these three papers of fifty years ago, we trace the history of quantization from its origins through this decade, and we survey the fundamentals of the theory and many of the popular and promising techniques for quantization.},
  eventtitle = {{{IEEE Transactions}} on {{Information Theory}}},
  keywords = {Analog-digital conversion,Data compression,Gaussian noise,Gaussian processes,History,Pulse modulation,Quantization,Rate distortion theory,Source coding},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataCompression\Quantization\Quantization_Gray_Neuhoff_1998.pdf}
}

@article{greenSelfconsistentOpticalParameters2008,
  title = {Self-Consistent Optical Parameters of Intrinsic Silicon at {{300K}} Including Temperature Coefficients},
  author = {Green, Martin A.},
  date = {2008-11},
  journaltitle = {Solar Energy Materials and Solar Cells},
  volume = {92},
  number = {11},
  pages = {1305--1310},
  issn = {09270248},
  doi = {10.1016/j.solmat.2008.06.009},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0927024808002158},
  urldate = {2023-09-05},
  abstract = {An updated tabulation is presented of the optical properties of intrinsic silicon, of particular interest in solar cell calculations. Improved values of absorption coefficient, refractive index and extinction coefficient at 300 K are tabulated over the 0.25–1.45 mm wavelength range at 0.01 mm intervals. The selfconsistent tabulation was derived from Kramers–Kronig analysis of updated reflectance data deduced from the literature. The inclusion of normalised temperature coefficients allows extrapolation over a wide temperature range, with accuracy similar to that of available experimental data demonstrated over the À24 1C to 200 1C range.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Semiconductor\Self-consistent_optical_parameters_of_intrinsic_silicon_at_300K_including_Green_2008.pdf}
}

@article{guerderTheoreticalNumericalStudy,
  title = {Theoretical and Numerical Study of Nonlinear Phononic Crystals ({{Étude}} Théorique et Numérique Des Cristaux Phononiques Non-Linéaires)},
  author = {Guerder, Pierre-Yves},
  abstract = {This work is dedicated to the theoretical and numerical study of nonlinear phononic crystals. The studied nonlinearities are those due to the second (quadratic) and third (cubic) order elastic constants of the materials that constitute the crystals. Nonlinear effects are studied by the means of finite element methods, used to simulate the propagation of an elastic wave through the crystals.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Theoretical_and_numerical_study_of_nonlinear_phononic_crystals_(Etude_theorique_Guerder_.pdf}
}

@article{guermandiActiveElectrodeIC2015,
  title = {Active {{Electrode IC}} for {{EEG}} and {{Electrical Impedance Tomography With Continuous Monitoring}} of {{Contact Impedance}}},
  author = {Guermandi, Marco and Cardu, Roberto and Franchi Scarselli, Eleonora and Guerrieri, Roberto},
  date = {2015-02},
  journaltitle = {IEEE Trans. Biomed. Circuits Syst.},
  volume = {9},
  number = {1},
  pages = {21--33},
  issn = {1932-4545, 1940-9990},
  doi = {10.1109/TBCAS.2014.2311836},
  url = {http://ieeexplore.ieee.org/document/6818429/},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\ContactImpedance\Active_Electrode_IC_for_EEG_and_Electrical_Impedance_Tomography_With_Continuous_Guermandi_et_al_2015.pdf}
}

@online{guLosslessCompressionDeep2024,
  title = {"{{Lossless}}" {{Compression}} of {{Deep Neural Networks}}: {{A High-dimensional Neural Tangent Kernel Approach}}},
  shorttitle = {"{{Lossless}}" {{Compression}} of {{Deep Neural Networks}}},
  author = {Gu, Lingyu and Du, Yongqi and Zhang, Yuan and Xie, Di and Pu, Shiliang and Qiu, Robert C. and Liao, Zhenyu},
  date = {2024-02-29},
  eprint = {2403.00258},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2403.00258},
  url = {http://arxiv.org/abs/2403.00258},
  urldate = {2024-08-13},
  abstract = {Modern deep neural networks (DNNs) are extremely powerful; however, this comes at the price of increased depth and having more parameters per layer, making their training and inference more computationally challenging. In an attempt to address this key limitation, efforts have been devoted to the compression (e.g., sparsification and/or quantization) of these large-scale machine learning models, so that they can be deployed on low-power IoT devices. In this paper, building upon recent advances in neural tangent kernel (NTK) and random matrix theory (RMT), we provide a novel compression approach to wide and fully-connected \textbackslash emph\{deep\} neural nets. Specifically, we demonstrate that in the high-dimensional regime where the number of data points \$n\$ and their dimension \$p\$ are both large, and under a Gaussian mixture model for the data, there exists \textbackslash emph\{asymptotic spectral equivalence\} between the NTK matrices for a large family of DNN models. This theoretical result enables "lossless" compression of a given DNN to be performed, in the sense that the compressed network yields asymptotically the same NTK as the original (dense and unquantized) network, with its weights and activations taking values \textbackslash emph\{only\} in \$\textbackslash\{ 0, \textbackslash pm 1 \textbackslash\}\$ up to a scaling. Experiments on both synthetic and real-world data are conducted to support the advantages of the proposed compression scheme, with code available at \textbackslash url\{https://github.com/Model-Compression/Lossless\_Compression\}.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Compression\LosslessCompression\Lossless_Compression_of_Gu_et_al_2024.pdf}
}

@article{gundogduNegativeIndexShortslab2008,
  title = {Negative Index Short-Slab Pair and Continuous Wires Metamaterials in the Far Infrared Regime},
  author = {Gundogdu, T. F. and Katsarakis, N. and Kafesaki, M. and Penciu, R. S. and Konstantinidis, G. and Kostopoulos, A. and Economou, E. N. and Soukoulis, C. M.},
  date = {2008-06-09},
  journaltitle = {Opt. Express},
  volume = {16},
  number = {12},
  pages = {9173},
  issn = {1094-4087},
  doi = {10.1364/OE.16.009173},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-16-12-9173},
  urldate = {2023-09-05},
  abstract = {Using transmission and reflection measurements under normal incidence in one and three layers of a μm-scale metamaterial consisting of pairs of short-slabs and continuous wires, fabricated by a photolithography procedure, we demonstrate the occurrence of a negative refractive index regime in the far infrared range, \textasciitilde 2.4-3 THz. The negative index behavior in that system at \textasciitilde 2.4-3 THz is further confirmed by associated simulations, which are in qualitative agreement with the experimental results.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Negative_index_short-slab_pair_and_continuous_wires_metamaterials_in_the_far_Gundogdu_et_al_2008.pdf}
}

@inproceedings{guoADNeRFAudioDriven2021,
  title = {{{AD-NeRF}}: {{Audio Driven Neural Radiance Fields}} for {{Talking Head Synthesis}}},
  shorttitle = {{{AD-NeRF}}},
  author = {Guo, Yudong and Chen, Keyu and Liang, Sen and Liu, Yong-Jin and Bao, Hujun and Zhang, Juyong},
  date = {2021},
  pages = {5784--5794},
  url = {https://openaccess.thecvf.com/content/ICCV2021/html/Guo_AD-NeRF_Audio_Driven_Neural_Radiance_Fields_for_Talking_Head_Synthesis_ICCV_2021_paper.html},
  urldate = {2023-07-28},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Reconstruction\\NeuralRadianceFields\\Audio\\AD-NeRF_Guo_et_al_2021.mp4;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Reconstruction\\NeuralRadianceFields\\Audio\\AD-NeRF_Guo_et_al_2021.pdf}
}

@online{guoAnimateDiffAnimateYour2023,
  title = {{{AnimateDiff}}: {{Animate Your Personalized Text-to-Image Diffusion Models}} without {{Specific Tuning}}},
  shorttitle = {{{AnimateDiff}}},
  author = {Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Wang, Yaohui and Qiao, Yu and Lin, Dahua and Dai, Bo},
  date = {2023-07-10},
  eprint = {2307.04725},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.04725},
  urldate = {2023-07-27},
  abstract = {With the advance of text-to-image models (e.g., Stable Diffusion) and corresponding personalization techniques such as DreamBooth and LoRA, everyone can manifest their imagination into high-quality images at an affordable cost. Subsequently, there is a great demand for image animation techniques to further combine generated static images with motion dynamics. In this report, we propose a practical framework to animate most of the existing personalized text-to-image models once and for all, saving efforts in model-specific tuning. At the core of the proposed framework is to insert a newly initialized motion modeling module into the frozen text-to-image model and train it on video clips to distill reasonable motion priors. Once trained, by simply injecting this motion modeling module, all personalized versions derived from the same base T2I readily become text-driven models that produce diverse and personalized animated images. We conduct our evaluation on several public representative personalized text-to-image models across anime pictures and realistic photographs, and demonstrate that our proposed framework helps these models generate temporally smooth animation clips while preserving the domain and diversity of their outputs. Code and pre-trained weights will be publicly available at https://animatediff.github.io/ .},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\DiffusionModels\VideoGeneration\AnimateDiff_Guo_et_al_2023.pdf}
}

@online{guoAnimateDiffAnimateYour2024,
  title = {{{AnimateDiff}}: {{Animate Your Personalized Text-to-Image Diffusion Models}} without {{Specific Tuning}}},
  shorttitle = {{{AnimateDiff}}},
  author = {Guo, Yuwei and Yang, Ceyuan and Rao, Anyi and Liang, Zhengyang and Wang, Yaohui and Qiao, Yu and Agrawala, Maneesh and Lin, Dahua and Dai, Bo},
  date = {2024-02-08},
  eprint = {2307.04725},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.04725},
  url = {http://arxiv.org/abs/2307.04725},
  urldate = {2024-02-20},
  abstract = {With the advance of text-to-image (T2I) diffusion models (e.g., Stable Diffusion) and corresponding personalization techniques such as DreamBooth and LoRA, everyone can manifest their imagination into high-quality images at an affordable cost. However, adding motion dynamics to existing high-quality personalized T2Is and enabling them to generate animations remains an open challenge. In this paper, we present AnimateDiff, a practical framework for animating personalized T2I models without requiring model-specific tuning. At the core of our framework is a plug-and-play motion module that can be trained once and seamlessly integrated into any personalized T2Is originating from the same base T2I. Through our proposed training strategy, the motion module effectively learns transferable motion priors from real-world videos. Once trained, the motion module can be inserted into a personalized T2I model to form a personalized animation generator. We further propose MotionLoRA, a lightweight fine-tuning technique for AnimateDiff that enables a pre-trained motion module to adapt to new motion patterns, such as different shot types, at a low training and data collection cost. We evaluate AnimateDiff and MotionLoRA on several public representative personalized T2I models collected from the community. The results demonstrate that our approaches help these models generate temporally smooth animation clips while preserving the visual quality and motion diversity. Codes and pre-trained weights are available at https://github.com/guoyww/AnimateDiff.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\AnimateDiff_Guo_et_al_2024.pdf}
}

@article{guoConstructDeepNeural2021,
  title = {Construct {{Deep Neural Networks}} Based on {{Direct Sampling Methods}} for {{Solving Electrical Impedance Tomography}}},
  author = {Guo, Ruchi and Jiang, Jiahua},
  date = {2021-01},
  journaltitle = {SIAM J. Sci. Comput.},
  volume = {43},
  number = {3},
  pages = {B678-B711},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/20M1367350},
  url = {https://epubs.siam.org/doi/10.1137/20M1367350},
  urldate = {2024-07-03},
  abstract = {This work investigates the electrical impedance tomography problem when only limited boundary measurements are available, which is known to be challenging due to the extreme ill-posedness. Based on the direct sampling method (DSM) introduced in [Y. T. Chow, K. Ito, and J. Zou, Inverse Problems, 30 (2016), 095003], we propose deep direct sampling methods (DDSMs) to locate inhomogeneous inclusions in which two types of deep neural networks (DNNs) are constructed to approximate the index function (functional): fully connected neural networks and convolutional neural networks. The proposed DDSMs are easy to be implemented, capable of incorporating multiple Cauchy data pairs to achieve high-quality reconstruction and highly robust with respect to large noise. Additionally, the implementation of DDSMs adopts offline-online decomposition, which helps to reduce a lot of computational costs and makes DDSMs as efficient as the conventional DSM proposed by Chow, Ito, and Zou. The numerical experiments are presented to demonstrate the efficacy and show the potential benefits of combining DNN with DSM.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Construct_Deep_Neural_Networks_based_on_Direct_Sampling_Methods_for_Solving_Guo_Jiang_2021.pdf}
}

@online{guoLivePortraitEfficientPortrait2024,
  title = {{{LivePortrait}}: {{Efficient Portrait Animation}} with {{Stitching}} and {{Retargeting Control}}},
  shorttitle = {{{LivePortrait}}},
  author = {Guo, Jianzhu and Zhang, Dingyun and Liu, Xiaoqiang and Zhong, Zhizhou and Zhang, Yuan and Wan, Pengfei and Zhang, Di},
  date = {2024-07-03},
  eprint = {2407.03168},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2407.03168},
  url = {http://arxiv.org/abs/2407.03168},
  urldate = {2024-11-29},
  abstract = {Portrait Animation aims to synthesize a lifelike video from a single source image, using it as an appearance reference, with motion (i.e., facial expressions and head pose) derived from a driving video, audio, text, or generation. Instead of following mainstream diffusion-based methods, we explore and extend the potential of the implicit-keypoint-based framework, which effectively balances computational efficiency and controllability. Building upon this, we develop a video-driven portrait animation framework named LivePortrait with a focus on better generalization, controllability, and efficiency for practical usage. To enhance the generation quality and generalization ability, we scale up the training data to about 69 million high-quality frames, adopt a mixed image-video training strategy, upgrade the network architecture, and design better motion transformation and optimization objectives. Additionally, we discover that compact implicit keypoints can effectively represent a kind of blendshapes and meticulously propose a stitching and two retargeting modules, which utilize a small MLP with negligible computational overhead, to enhance the controllability. Experimental results demonstrate the efficacy of our framework even compared to diffusion-based methods. The generation speed remarkably reaches 12.8ms on an RTX 4090 GPU with PyTorch. The inference code and models are available at https://github.com/KwaiVGI/LivePortrait},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\LivePortrait_Guo_et_al_2024.pdf}
}

@article{guoLowNoisePower2014,
  title = {A {{Low Noise Power Design}} for {{Electrical Impedance Tomography System}}},
  author = {Guo, Yan Yan and Chen, Xiao Yan and Yang, Yong Zheng},
  date = {2014-10},
  journaltitle = {AMM},
  volume = {670--671},
  pages = {1159--1162},
  issn = {1662-7482},
  doi = {10.4028/www.scientific.net/AMM.670-671.1159},
  url = {https://www.scientific.net/AMM.670-671.1159},
  urldate = {2024-07-03},
  abstract = {This paper describes a quality power module design for Biological Electrical Impedance Tomography (BEIT) system based on FPGA. As the electrical signals on the boundary of subject are too weak to measure effectively, it is essential to design a data acquisition system with high SNR and extremely low noise. This paper is focus on the power module design because the quality of the power module impacts the performance of the data acquisition system directly. The BEIT system needs several kinds of power supply to work effectively, such as ± 12V, ± 5V. In this paper, the power module is supplied by DC18V, using Buck-type DC/DC and LDO technologies, a set of independent power supply scheme is carried out, and provides stability and low noise power sources. The expected powers with ripple less than 20mV are achieved, which can preferably meet the BEIT system power supply requirements.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Experimental\A_Low_Noise_Power_Design_for_Electrical_Impedance_Tomography_System_Guo_et_al_2014.pdf}
}

@online{guoMAISIMedicalAI2024,
  title = {{{MAISI}}: {{Medical AI}} for {{Synthetic Imaging}}},
  shorttitle = {{{MAISI}}},
  author = {Guo, Pengfei and Zhao, Can and Yang, Dong and Xu, Ziyue and Nath, Vishwesh and Tang, Yucheng and Simon, Benjamin and Belue, Mason and Harmon, Stephanie and Turkbey, Baris and Xu, Daguang},
  date = {2024-10-29},
  eprint = {2409.11169},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2409.11169},
  url = {http://arxiv.org/abs/2409.11169},
  urldate = {2024-12-13},
  abstract = {Medical imaging analysis faces challenges such as data scarcity, high annotation costs, and privacy concerns. This paper introduces the Medical AI for Synthetic Imaging (MAISI), an innovative approach using the diffusion model to generate synthetic 3D computed tomography (CT) images to address those challenges. MAISI leverages the foundation volume compression network and the latent diffusion model to produce high-resolution CT images (up to a landmark volume dimension of 512 x 512 x 768 ) with flexible volume dimensions and voxel spacing. By incorporating ControlNet, MAISI can process organ segmentation, including 127 anatomical structures, as additional conditions and enables the generation of accurately annotated synthetic images that can be used for various downstream tasks. Our experiment results show that MAISI's capabilities in generating realistic, anatomically accurate images for diverse regions and conditions reveal its promising potential to mitigate challenges using synthetic data.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\Medical\MAISI_Guo_et_al_2024.pdf}
}

@article{guoPhotonicCrystalSlab2018,
  title = {Photonic Crystal Slab {{Laplace}} Operator for Image Differentiation},
  author = {Guo, Cheng and Xiao, Meng and Minkov, Momchil and Shi, Yu and Fan, Shanhui},
  date = {2018-03-20},
  journaltitle = {Optica, OPTICA},
  volume = {5},
  number = {3},
  pages = {251--256},
  publisher = {Optica Publishing Group},
  issn = {2334-2536},
  doi = {10.1364/OPTICA.5.000251},
  url = {https://opg.optica.org/optica/abstract.cfm?uri=optica-5-3-251},
  urldate = {2024-05-05},
  abstract = {Spatial differentiation is important in image-processing applications such as image sharpening and edge-based segmentation. In these applications, of particular importance is the Laplacian, the simplest isotropic derivative operator in two dimensions. Spatial differentiation can be implemented electronically. However, in applications requiring real-time and high-throughput image differentiation, conventional digital computations become challenging. Optical analog computing may overcome this challenge by offering high-throughput low-energy-consumption operations using compact devices. However, previous works on spatial differentiation with nanophotonic structures are restricted to either one-dimensional differentiation or reflection mode, whereas operating in the transmission mode is important because it is directly compatible with standard image processing/recognition systems. Here, we show that the Laplacian can be implemented in the transmission mode by a photonic crystal slab device. We theoretically derive the criteria for realizing the Laplacian using the guided resonances in a photonic crystal slab. Guided by these criteria, we show that the Laplacian can be implemented using a carefully designed photonic crystal slab with a non-trivial isotropic band structure near the \&\#x0393; point. Our work points to new opportunities in optical analog computing as provided by nanophotonic structures.},
  langid = {english},
  keywords = {Biomedical imaging,Imaging systems,Optical components,Optical computing,Photonic crystals,Real time imaging},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/Photonics/PhotonicCrystals/Operator/Photonic_crystal_slab_Laplace_Guo_et_al_2018.pdf}
}

@online{guoPhysicsEmbeddedMachine2022,
  title = {Physics {{Embedded Machine Learning}} for {{Electromagnetic Data Imaging}}},
  author = {Guo, Rui and Huang, Tianyao and Li, Maokun and Zhang, Haiyang and Eldar, Yonina C.},
  date = {2022-07-25},
  eprint = {2207.12607},
  eprinttype = {arXiv},
  eprintclass = {physics},
  url = {http://arxiv.org/abs/2207.12607},
  urldate = {2024-07-08},
  abstract = {Electromagnetic (EM) imaging is widely applied in sensing for security, biomedicine, geophysics, and various industries. It is an ill-posed inverse problem whose solution is usually computationally expensive. Machine learning (ML) techniques and especially deep learning (DL) show potential in fast and accurate imaging. However, the high performance of purely data-driven approaches relies on constructing a training set that is statistically consistent with practical scenarios, which is often not possible in EM imaging tasks. Consequently, generalizability becomes a major concern. On the other hand, physical principles underlie EM phenomena and provide baselines for current imaging techniques. To benefit from prior knowledge in big data and the theoretical constraint of physical laws, physics embedded ML methods for EM imaging have become the focus of a large body of recent work.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Physics - Computational Physics},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Electroencephalography(EEG)\Physics_Embedded_Machine_Learning_for_Electromagnetic_Data_Imaging_Guo_et_al_2022.pdf}
}

@article{guParityTimesymmetricCircular2016,
  title = {Parity–Time-Symmetric Circular {{Bragg}} Lasers: A Proposal and Analysis},
  shorttitle = {Parity–Time-Symmetric Circular {{Bragg}} Lasers},
  author = {Gu, Jiahua and Xi, Xiang and Ma, Jingwen and Yu, Zejie and Sun, Xiankai},
  date = {2016-11-28},
  journaltitle = {Sci Rep},
  volume = {6},
  number = {1},
  pages = {37688},
  issn = {2045-2322},
  doi = {10.1038/srep37688},
  url = {https://www.nature.com/articles/srep37688},
  urldate = {2023-11-06},
  abstract = {Abstract             We propose a new type of semiconductor lasers by implementing the concept of parity–time symmetry in a two-dimensional circular Bragg grating structure, where both the real and imaginary parts of the refractive index are modulated along the radial direction. The laser modal properties are analyzed with a transfer-matrix method and are verified with numerical simulation of a practical design. Compared with conventional distributed-feedback lasers with modulation of only the real part of refractive index, the parity–time-symmetric circular Bragg lasers feature reduced threshold and enhanced modal discrimination, which in combination with the intrinsic circularly symmetric, large emission aperture are clear advantages in applications that require mode-hop-free, high-power, single-mode laser operation.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Parity–time-symmetric_circular_Bragg_lasers_Gu_et_al_2016.pdf}
}

@inproceedings{guSemanticImportanceBasedDeep2024,
  title = {Semantic {{Importance-Based Deep Image Compression Using}} a~{{Generative Approach}}},
  booktitle = {{{MultiMedia Modeling}}},
  author = {Gu, Xi and Xu, Yuanyuan and Zhu, Kun},
  editor = {Rudinac, Stevan and Hanjalic, Alan and Liem, Cynthia and Worring, Marcel and Jónsson, Björn Þór and Liu, Bei and Yamakata, Yoko},
  date = {2024},
  pages = {70--81},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-53308-2_6},
  abstract = {Semantic image compression can greatly reduce the amount of transmitted data by representing and reconstructing images using semantic information. Considering the fact that objects in an image are not equally important at the semantic level, we propose a semantic importance-based deep image compression scheme, where a generative approach is used to produce a visually pleasing image from segmentation information. A base-layer image can be reconstructed using a conditional generative adversarial network (GAN) considering the importance of objects. To ensure that objects with the same semantic importance have similar perceptual fidelity, a generative compensation module has been designed, considering the varying generative capability of GAN. The base-layer image can be further refined using residuals, prioritizing regions with high semantic importance. Experimental results show that the reconstructed images of the proposed scheme are more visually pleasing compared with relevant schemes, and objects with a high semantic importance achieve both good pixel and semantic-perceptual fidelity.},
  isbn = {978-3-031-53308-2},
  langid = {english},
  keywords = {Image Compression,Scalable coding,Semantic image coding},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Semantic_Importance-Based_Gu_et_al_2024.pdf}
}

@article{guSupershapeAugmentedReconstruction2021,
  title = {Supershape {{Augmented Reconstruction Method Based}} on {{Boolean Operations}} in {{Electrical Impedance Tomography}}},
  author = {Gu, Danping and Deng, Jiansong and Smyl, Danny and Liu, Dong and Du, Jiangfeng},
  date = {2021},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {70},
  pages = {1--11},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2021.3122167},
  url = {https://ieeexplore.ieee.org/document/9584836/},
  urldate = {2024-07-08},
  abstract = {This article presents a supershape augmented shape reconstruction algorithm for electrical impedance tomography, aiming at high-quality reconstructions with respect to multiphase conductivity distributions. Within the proposed algorithm, the reconstructed inclusions are composed of basic shape primitives expressed through a supershape formula. To allow automatic topological evolution, multiple Boolean operations, including three basic Boolean operations and compound Boolean operations, are employed so that the candidate shape primitives can be intersected, subtracted, and merged to form different shapes. The proposed algorithm is tested using simulations and water tank experimental data. Moreover, robustness studies considering varying initial guesses and differing signal-to-noise ratios are performed. It is demonstrated that the proposed algorithm is able to preserve detailed features of inclusions under detection and provide reliable estimates of unknown conductivity values and the interface properties.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\SupershapeAugmented\Supershape_Augmented_Reconstruction_Method_Based_on_Boolean_Operations_in_Gu_et_al_2021.pdf}
}

@article{guSupershapeRecoveryElectrical2021,
  title = {Supershape {{Recovery From Electrical Impedance Tomography Data}}},
  author = {Gu, Danping and Liu, Dong and Smyl, Danny and Deng, Jiansong and Du, Jiangfeng},
  date = {2021},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {70},
  pages = {1--11},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2021.3064802},
  url = {https://ieeexplore.ieee.org/document/9373396/},
  urldate = {2024-07-08},
  abstract = {The idea of accounting for a priori shape information is gaining increasing levels of interest and traction in the electrical impedance tomography (EIT) reconstruction. A supershape-based reconstruction approach is proposed for EIT. We begin by assuming that the conductivity profile to be reconstructed in the measured domain is piecewise constant distributed. Using this formulation, the image reconstruction problem is transformed into a shape reconstruction problem. The inclusion boundary (e.g., interface between the inclusion and the background) to be estimated is treated as a supershape and expressed through a single equation—the so-called super formula. We illustrate the performance of the proposed approach using synthetic and experimental water tank data. In addition, robustness studies considering different regularization types (L1 and L2 norms), varying noise levels and different initial settings are tested of the proposed approach. Four evaluation matrices relative size coverage ratio (RCR), structural similarity index (SSIM), relative contrast (RCo), and correlation coefficient (CC) are used to quantitatively evaluate the performance of the proposed method. Both the simulation and experimental results show that the supershape-based method leads to reliable and robust reconstructions and improves the ability to simultaneously reconstruct objects with smooth boundaries and/or sharp features. The proposed approach provides an excellent opportunity for the shape reconstruction framework to express a wide variety of shapes, including geometric primitives. Supershapes can simply represent regular polygons and natural shapes with various symmetries while maintaining a parametric representation.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\SupershapeAugmented\Supershape_Recovery_From_Electrical_Impedance_Tomography_Data_Gu_et_al_2021.pdf}
}

@article{gutierrezQuestLowLoss2018,
  title = {The {{Quest}} for {{Low Loss High Refractive Index Dielectric Materials}} for {{UV Photonic Applications}}},
  author = {Gutiérrez, Yael and Ortiz, Dolores and Saiz, José and González, Francisco and Albella, Pablo and Moreno, Fernando},
  date = {2018-10-25},
  journaltitle = {Applied Sciences},
  volume = {8},
  number = {11},
  pages = {2065},
  issn = {2076-3417},
  doi = {10.3390/app8112065},
  url = {http://www.mdpi.com/2076-3417/8/11/2065},
  urldate = {2024-06-01},
  abstract = {Nanostructured High Refractive Index (HRI) dielectric materials, when acting as nanoantennas or metasurfaces in the near-infrared (NIR) and visible (VIS) spectral ranges, can interact with light and show interesting scattering directionality properties. Also, HRI dielectric materials with low absorption in these spectral ranges show very low heat radiation when illuminated. Up to now, most of the studies of these kind of materials have been explored in the VIS-NIR. However, to the best of our knowledge, these properties have not been extended to the ultraviolet (UV), where their application in fields like photocatalysis, biosensing, surface-enhanced spectroscopies or light guiding and trapping can be of extraordinary relevance. Here, we present a detailed numerical study of the directional scattering properties, near-field enhancement and heat generation of several materials that can be good candidates for those applications in the UV. These materials include aluminum phosphide, aluminum arsenide, aluminum nitride, diamond, cerium dioxide and titanium dioxide. In this study, we compare their performance when forming either isolated nanoparticles or dimers to build either nanoantennas or unit cells for more complex metasurfaces.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Dielectric\The_Quest_for_Low_Loss_High_Refractive_Index_Dielectric_Materials_for_UV_Gutierrez_et_al_2018.pdf}
}

@book{haganNeuralNetworkDesign2014,
  title = {Neural {{Network Design}}},
  author = {Hagan, Martin T. and Demuth, Howard B. and Beale, Mark H. and Jesús, Orlando De},
  date = {2014-09-01},
  edition = {2nd ed. edition},
  publisher = {Martin Hagan},
  location = {s.L},
  abstract = {This book, by the authors of the Neural Network Toolbox for MATLAB, provides a clear and detailed coverage of fundamental neural network architectures and learning rules. In it, the authors emphasize a coherent presentation of the principal neural networks, methods for training them and their applications to practical problems.FeaturesExtensive coverage of training methods for both feedforward networks (including multilayer and radial basis networks) and recurrent networks. In addition to conjugate gradient and Levenberg-Marquardt variations of the backpropagation algorithm, the text also covers Bayesian regularization and early stopping, which ensure the generalization ability of trained networks.Associative and competitive networks, including feature maps and learning vector quantization, are explained with simple building blocks.A chapter of practical training tips for function approximation, pattern recognition, clustering and prediction, along with five chapters presenting detailed real-world case studies.Detailed examples and numerous solved problems. Slides and comprehensive demonstration software can be downloaded from hagan.okstate.edu/nnd.html.},
  isbn = {978-0-9717321-1-7},
  langid = {english},
  pagetotal = {800},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\AI\Architechtures\Designe\Neural_Network_Design_Hagan_et_al_2014.pdf}
}

@online{hamamciFoundationModelUtilizing2024,
  title = {A Foundation Model Utilizing Chest {{CT}} Volumes and Radiology Reports for Supervised-Level Zero-Shot Detection of Abnormalities},
  author = {Hamamci, Ibrahim Ethem and Er, Sezgin and Almas, Furkan and Simsek, Ayse Gulnihan and Esirgun, Sevval Nil and Dogan, Irem and Dasdelen, Muhammed Furkan and Wittmann, Bastian and Simsar, Enis and Simsar, Mehmet and Erdemir, Emine Bensu and Alanbay, Abdullah and Sekuboyina, Anjany and Lafci, Berkan and Ozdemir, Mehmet K. and Menze, Bjoern},
  date = {2024-03-26},
  eprint = {2403.17834},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.17834},
  url = {http://arxiv.org/abs/2403.17834},
  urldate = {2024-05-05},
  abstract = {A major challenge in computational research in 3D medical imaging is the lack of comprehensive datasets. Addressing this issue, our study introduces CT-RATE, the first 3D medical imaging dataset that pairs images with textual reports. CT-RATE consists of 25,692 non-contrast chest CT volumes, expanded to 50,188 through various reconstructions, from 21,304 unique patients, along with corresponding radiology text reports. Leveraging CT-RATE, we developed CT-CLIP, a CT-focused contrastive language-image pre-training framework. As a versatile, self-supervised model, CT-CLIP is designed for broad application and does not require task-specific training. Remarkably, CT-CLIP outperforms state-of-the-art, fully supervised methods in multi-abnormality detection across all key metrics, thus eliminating the need for manual annotation. We also demonstrate its utility in case retrieval, whether using imagery or textual queries, thereby advancing knowledge dissemination. The open-source release of CT-RATE and CT-CLIP marks a significant advancement in medical AI, enhancing 3D imaging analysis and fostering innovation in healthcare.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/Reconstruction/NeuralRadianceFields/Tomography/A_foundation_model_utilizing_Hamamci_et_al_2024.pdf}
}

@article{hamidiOpticalMagnetoopticalProperties2012,
  title = {Optical and Magneto-Optical Properties of One-Dimensional Magnetized Coupled Resonator Plasma Photonic Crystals},
  author = {Hamidi, S. M.},
  date = {2012-01-01},
  journaltitle = {Physics of Plasmas},
  volume = {19},
  number = {1},
  pages = {012503},
  issn = {1070-664X, 1089-7674},
  doi = {10.1063/1.3677263},
  url = {https://pubs.aip.org/pop/article/19/1/012503/107107/Optical-and-magneto-optical-properties-of-one},
  urldate = {2024-01-22},
  abstract = {In this paper, the optical and magneto-optical properties of one-dimensional magnetized coupled resonator plasma photonic crystals have been investigated. We use transfer matrix method to solve our magnetized coupled resonator plasma photonic crystals consist of dielectric and magnetized plasma layers. The results of the change in the optical and magneto-optical properties of structure as a result of the alteration in the structural properties such as thickness, plasma frequency and collision frequency, plasma filling factor, number of resonators and dielectric constant of dielectric layers and external magnetic field have been reported. The main feature of this structure is a good magneto-optical rotation that takes place at the defect modes and the edge of photonic band gap of our proposed optical magnetized plasma waveguide. Our outcomes demonstrate the potential applications of the device for tunable and adjustable filters or reflectors and active magneto-optic in microwave devices under structural parameter and external magnetic field.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Optical_and_magneto-optical_properties_of_one-dimensional_magnetized_coupled_Hamidi_2012.pdf}
}

@article{hamiltonBeltraminetDomainindependentDeep2019,
  title = {Beltrami-Net: Domain-Independent Deep {{D-bar}} Learning for Absolute Imaging with Electrical Impedance Tomography (a-{{EIT}})},
  shorttitle = {Beltrami-Net},
  author = {Hamilton, S J and Hänninen, A and Hauptmann, A and Kolehmainen, V},
  date = {2019-07-01},
  journaltitle = {Physiol. Meas.},
  volume = {40},
  number = {7},
  pages = {074002},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/1361-6579/ab21b2},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/ab21b2},
  urldate = {2024-07-03},
  abstract = {Objective: To develop, and demonstrate the feasibility of, a novel image reconstruction method for absolute electrical impedance tomography (a-EIT) that pairs deep learning techniques with realtime robust D-bar methods and examine the influence of prior information on the reconstruction. Approach: A D-bar method is paired with a trained convolutional neural network (CNN) as a postprocessing step. Training data is simulated for the network using no knowledge of the boundary shape by using an associated nonphysical Beltrami equation rather than simulating the traditional current and voltage data specific to a given domain. This allows the training data to be boundary shape independent. The method is tested on experimental data from two EIT systems (ACT4 and KIT4) with separate training sets of varying prior information. Main results: Post-processing the D-bar images with a CNN produces significant improvements in image quality measured by structural SIMilarity indices (SSIMs) as well as relative 2 and 1 image errors. Significance: This work demonstrates that more general networks can be trained without being specific about boundary shape, a key challenge in EIT image reconstruction. The work is promising for future studies involving databases of anatomical atlases.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Beltrami-net_Hamilton_et_al_2019.pdf}
}

@article{hamiltonDeepDBarRealTime2018,
  title = {Deep {{D-Bar}}: {{Real-Time Electrical Impedance Tomography Imaging With Deep Neural Networks}}},
  shorttitle = {Deep {{D-Bar}}},
  author = {Hamilton, Sarah Jane and Hauptmann, A.},
  date = {2018-10},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {37},
  number = {10},
  pages = {2367--2377},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2018.2828303},
  url = {https://ieeexplore.ieee.org/document/8352045/},
  urldate = {2024-07-03},
  abstract = {The mathematical problem for electrical impedance tomography (EIT) is a highly nonlinear ill-posed inverse problem requiring carefully designed reconstruction procedures to ensure reliable image generation. D-bar methods are based on a rigorous mathematical analysis and provide robust direct reconstructions by using a lowpass filtering of the associated nonlinear Fourier data. Similarly to low-pass filtering of linear Fourier data, only using low frequencies in the image recovery process results in blurred images lacking sharp features, such as clear organ boundaries. Convolutional neural networks provide a powerful framework for post-processing such convolved direct reconstructions. In this paper, we demonstrate that these CNN techniques lead to sharp and reliable reconstructions even for the highly nonlinear inverse problem of EIT. The network is trained on data sets of simulated examples and then applied to experimental data without the need to perform an additional transfer training. Results for absolute EIT images are presented using experimental EIT data from the ACT4 and KIT4 EIT systems.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Deep_D-Bar_Hamilton_Hauptmann_2018.pdf}
}

@article{hampshireMultifrequencyParametricEIT1995,
  title = {Multifrequency and Parametric {{EIT}} Images of Neonatal Lungs},
  author = {Hampshire, A R and Smallwood, R H and Brown, B H and Primhak, R A},
  date = {1995-08-01},
  journaltitle = {Physiol. Meas.},
  volume = {16},
  pages = {A175-A189},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/0967-3334/16/3A/017},
  url = {https://iopscience.iop.org/article/10.1088/0967-3334/16/3A/017},
  urldate = {2024-07-08},
  abstract = {The aims of the smdy were to investigate the problems involved in making multifrequency EIT measurements on nennates and to compare the images obtained with the results from a group of normal adulo.},
  issue = {3A},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Multifrequency_and_parametric_EIT_images_of_neonatal_lungs_Hampshire_et_al_1995.pdf}
}

@book{HandbookLasers_Weber_22Pdf,
  title = {Handbook of {{Lasers}}\_{{Weber}}\_22.Pdf},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\CRCpress\Handbook_of_Lasers_Weber_22_.pdf}
}

@article{haoResearchPhotonicCrystal2019,
  title = {Research on {{Photonic Crystal}}–{{Based Biosensor}} for {{Detection}} of {{Escherichia}} Coli {{Colony}}},
  author = {Hao, Jiong-Ju and Xie, Xun and Gu, Ke-Da and Du, Wei-Chen and Liu, Yu-Jie and Yang, Hong-Wei},
  date = {2019-12},
  journaltitle = {Plasmonics},
  volume = {14},
  number = {6},
  pages = {1919--1928},
  issn = {1557-1955, 1557-1963},
  doi = {10.1007/s11468-019-00987-w},
  url = {http://link.springer.com/10.1007/s11468-019-00987-w},
  urldate = {2024-03-06},
  abstract = {In this paper, a biosensor based on 1D-PhC (one-dimensional photonic crystal) is proposed for detecting colony of E. coli (Escherichia coli) by analyzing the volume fraction of E. coli in analyte. The performance of the biosensor is evaluated by FDTD (finite-difference time-domain) method, and the parameters of the biosensor are optimized by orthogonal experiments. The simulation results show that the optimum parameters of the biosensor are A1B5C5D4E5 with the FOM (figure of merit) and S (sensitivity) of 125 and 174a nm/RIU, respectively. The center wavelength is the major factor affecting the performance of the biosensor. The S and FWHM (full width at half maximum) of the sensor are increased with the increasing of the center wavelength. In addition, the effective refractive index of the analyte at different volume fractions of E. coli is calculated by the Bruggeman model. The volume fraction of E. coli in the analyte is positively correlated with the resonance wavelength shift of the biosensor, and the linear correlation coefficient is 0.996. Therefore, it is feasible to detect the number of E. coli in the analyte by the resonance wavelength shift of the biosensor.},
  langid = {english},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/Photonics/Materials/BioMaterial/Research_on_Photonic_Hao_et_al_2019.pdf}
}

@inproceedings{harikaReviewArtificialIntelligence2022,
  title = {A {{Review}} on {{Artificial Intelligence}} with {{Deep Human Reasoning}}},
  booktitle = {2022 {{International Conference}} on {{Applied Artificial Intelligence}} and {{Computing}} ({{ICAAIC}})},
  author = {Harika, Janmanchi and Baleeshwar, Palavadi and Navya, Kummari and Shanmugasundaram, Hariharan},
  date = {2022-05},
  pages = {81--84},
  doi = {10.1109/ICAAIC53929.2022.9793310},
  url = {https://ieeexplore.ieee.org/abstract/document/9793310},
  urldate = {2024-07-03},
  abstract = {Artificial Intelligence (AI) is a broad term that can be construed to mean a focusing computer programming and development that is designed to train machines and to perform task. Artificial intelligence can be used to test theories of reasoning like cognitive reasoning and consciousness. Research has been conducted on the development of machines with human behavior and cognitive characteristics that are related to consciousness. Artificial Intelligence and Reasoning that are dealt with, can necessarily solve problems related to mental health issues that humans find complex, but research on new interaction techniques and human for cooperation theories, technologies limited the issues and challenges facing the application of artificial reasoning. Here in this paper, the relation between artificial intelligence human reasoning that is also called as AI reasoning or artificial reasoning has been studied. Artificial intelligence impacts reasoning and how artificial reasoning can be used in day-to-day activities to regain our mental health. Moreover, this work focuses on problems that can be solved with AI Reasoning in trying to find the possible solutions.},
  eventtitle = {2022 {{International Conference}} on {{Applied Artificial Intelligence}} and {{Computing}} ({{ICAAIC}})},
  keywords = {Artificial emotion,Artificial intelligence,Artificial reasoning,Artificial super intelligence,Cognition,Cognitive reasoning,Focusing,Linguistics,Mental health,Programming,Task analysis},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Strategies\Reasoning\A_Review_on_Artificial_Intelligence_with_Deep_Human_Reasoning_Harika_et_al_2022.pdf}
}

@article{harikumarElectricalImpedanceTomography2013,
  title = {Electrical {{Impedance Tomography}} ({{EIT}}) and {{Its Medical Applications}}: {{A Review}}},
  author = {Harikumar, R and Prabu, R and Raghavan, S},
  date = {2013},
  volume = {3},
  number = {4},
  abstract = {This paper reviews the principles of Electrical Impedance Tomography (EIT), different types of current patterns and reconstruction algorithms to assess its potential in medical imaging. A current injection pattern in EIT has its own current distribution profile within the subject under test. Hence, different current patterns have different sensitivity, spatial resolution and distinguishability. Image reconstruction studies with subject or practical phantoms are essential to assess the performance of EIT systems for their validation, calibration and comparison purposes. Impedance imaging of real objects or tissue phantoms with different current injection methods is also essential for better assessment of the biomedical EIT systems. More specifically, this work reviews the three different image reconstruction techniques including back-projection method, iterative method and one-step linearized method. In this review, Resistivity images are reconstructed from the boundary data using Electrical Impedance Tomography and Diffuse Optical Tomography Reconstruction Software (EIDORS).},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Review\Electrical_Impedance_Tomography_(EIT)_and_Its_Medical_Applications_Harikumar_et_al_2013.pdf}
}

@article{harisIdentificationAnalysisStable2021,
  title = {Identification and Analysis of Stable Breathing Periods in Electrical Impedance Tomography Recordings},
  author = {Haris, K and Vogt, B and Strodthoff, C and Pessoa, D and Cheimariotis, G-A and Rocha, B and Petmezas, G and Weiler, N and Paiva, R P and family=Carvalho, given=P, prefix=de, useprefix=true and Maglaveras, N and Frerichs, I},
  date = {2021-06-01},
  journaltitle = {Physiol. Meas.},
  volume = {42},
  number = {6},
  pages = {064003},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/1361-6579/ac08e5},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/ac08e5},
  urldate = {2024-07-08},
  abstract = {Objective. In this paper, an automated stable tidal breathing period (STBP) identification method based on processing electrical impedance tomography (EIT) waveforms is proposed and the possibility of detecting and identifying such periods using EIT waveforms is analyzed. In wearable chest EIT, patients breathe spontaneously, and therefore, their breathing pattern might not be stable. Since most of the EIT feature extraction methods are applied to STBPs, this renders their automatic identification of central importance. Approach. The EIT frame sequence is reconstructed from the raw EIT recordings and the raw global impedance waveform (GIW) is computed. Next, the respiratory component of the raw GIW is extracted and processed for the automatic respiratory cycle (breath) extraction and their subsequent grouping into STBPs. Main results. We suggest three criteria for the identification of STBPs, namely, the coefficient of variation of (i) breath tidal volume, (ii) breath duration and (iii) end-expiratory impedance. The total number of true STBPs identified by the proposed method was 294 out of 318 identified by the expert corresponding to accuracy over 90\%. Specific activities such as speaking, eating and arm elevation are identified as sources of false positives and their discrimination is discussed. Significance. Simple and computationally efficient STBP detection and identification is a highly desirable component in the EIT processing pipeline. Our study implies that it is feasible, however, the determination of its limits is necessary in order to consider the implementation of more advanced and computationally demanding approaches such as deep learning and fusion with data from other wearable sensors such as accelerometers and microphones.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Identification_and_analysis_of_stable_breathing_periods_in_electrical_impedance_Haris_et_al_2021.pdf}
}

@article{hartovSimulationErrorPropagation2001,
  title = {Simulation of Error Propagation in Finite Element Image Reconstruction for Electrical Impedance Tomography},
  author = {Hartov, Alex and Kerner, Todd E and Paulsen, Keith D},
  date = {2001-08-01},
  journaltitle = {Meas. Sci. Technol.},
  volume = {12},
  number = {8},
  pages = {1040--1049},
  issn = {0957-0233, 1361-6501},
  doi = {10.1088/0957-0233/12/8/308},
  url = {https://iopscience.iop.org/article/10.1088/0957-0233/12/8/308},
  urldate = {2024-07-08},
  abstract = {Using extensive simulations, we have investigated the behaviour of finite element image reconstruction for electrical impedance tomography in the presence of inaccuracies likely to exist in real measurements. This study characterizes reconstruction when subjected to noise propagation using different excitation patterns and modes of operation. Specifically, a generalized framework for finite element image reconstruction is presented which allows electrical impedance images to be recovered from data collected in either voltage, current or impedance modes of operation that correspond naturally to the allowable boundary condition types which determine unique model solutions to the underlying partial differential equation as the basis for property estimation. Driving conditions consisting of electrode pairs, trigonometric or synthesized trigonometric patterns have been considered. The simulations presented here are based on an arbitrary impedance distribution for which applied and observed voltages and currents were computed. The applied and observed patterns were then processed identically to real data with the addition of 0, 0.1\% and 1\% random Gaussian noise. The mean squared error (MSE) between the reconstructed and exact impedance images constituted the measure of algorithmic performance. Our findings suggest that finite element reconstruction tolerates noise on the measurement data better than on the applied portion of the signal; pair excitations consistently produced the lowest MSE; noise appears to compound itself in the synthesized trigonometric patterns mode; and the applied voltage mode consistently yields more accurate images in the presence of noise than the equivalent cases corresponding to current mode. While only evaluated with trigonometric patterns, the impedance mode generally produced the lowest MSE in a limited set of simulation comparisons.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\AnalysisOfEIT\ErrorPropagation\Simulation_of_error_propagation_in_finite_element_image_reconstruction_for_Hartov_et_al_2001.pdf}
}

@online{hasselgrenShapeLightMaterial2022,
  title = {Shape, {{Light}}, and {{Material Decomposition}} from {{Images}} Using {{Monte Carlo Rendering}} and {{Denoising}}},
  author = {Hasselgren, Jon and Hofmann, Nikolai and Munkberg, Jacob},
  date = {2022-10-04},
  eprint = {2206.03380},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2206.03380},
  url = {http://arxiv.org/abs/2206.03380},
  urldate = {2024-06-12},
  abstract = {Recent advances in differentiable rendering have enabled high-quality reconstruction of 3D scenes from multi-view images. Most methods rely on simple rendering algorithms: pre-filtered direct lighting or learned representations of irradiance. We show that a more realistic shading model, incorporating ray tracing and Monte Carlo integration, substantially improves decomposition into shape, materials \& lighting. Unfortunately, Monte Carlo integration provides estimates with significant noise, even at large sample counts, which makes gradient-based inverse rendering very challenging. To address this, we incorporate multiple importance sampling and denoising in a novel inverse rendering pipeline. This substantially improves convergence and enables gradient-based optimization at low sample counts. We present an efficient method to jointly reconstruct geometry (explicit triangle meshes), materials, and lighting, which substantially improves material and light separation compared to previous work. We argue that denoising can become an integral part of high quality inverse rendering pipelines.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Materials\Shape,_Light,_and_Material_Decomposition_from_Images_using_Monte_Carlo_Hasselgren_et_al_2022.pdf}
}

@online{hauptmannOpen2DElectrical2017,
  title = {Open {{2D Electrical Impedance Tomography}} Data Archive},
  author = {Hauptmann, Andreas and Kolehmainen, Ville and Mach, Nguyet Minh and Savolainen, Tuomo and Seppänen, Aku and Siltanen, Samuli},
  date = {2017-04-04},
  eprint = {1704.01178},
  eprinttype = {arXiv},
  eprintclass = {physics},
  url = {http://arxiv.org/abs/1704.01178},
  urldate = {2024-07-03},
  abstract = {This document reports an Open 2D Electrical Impedance Tomography (EIT) data set. The EIT measurements were collected from a circular body (a flat tank filled with saline) with various choices of conductive and resistive inclusions. Data are available at http://fips.fi/ EIT\_dataset.php and can be freely used for scientific purposes with appropriate references to them, and to this document at https://arxiv.org. The data set consists of (1) current patterns and voltage measurements of a circular tank containing different targets, (2) photos of the tank and targets and (3) a MATLAB-code for reading the data. A video report of the data collection session is available at https://www.youtube.com/watch?v=65Zca\_qd1Y8.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Physics - Medical Physics},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Datasets\Open_2D_Electrical_Impedance_Tomography_data_archive_Hauptmann_et_al_2017.pdf}
}

@online{hauptmannOpen2DElectrical2017a,
  title = {Open {{2D Electrical Impedance Tomography}} Data Archive},
  author = {Hauptmann, Andreas and Kolehmainen, Ville and Mach, Nguyet Minh and Savolainen, Tuomo and Seppänen, Aku and Siltanen, Samuli},
  date = {2017-04-04},
  eprint = {1704.01178},
  eprinttype = {arXiv},
  eprintclass = {physics},
  url = {http://arxiv.org/abs/1704.01178},
  urldate = {2024-07-03},
  abstract = {This document reports an Open 2D Electrical Impedance Tomography (EIT) data set. The EIT measurements were collected from a circular body (a flat tank filled with saline) with various choices of conductive and resistive inclusions. Data are available at http://fips.fi/ EIT\_dataset.php and can be freely used for scientific purposes with appropriate references to them, and to this document at https://arxiv.org. The data set consists of (1) current patterns and voltage measurements of a circular tank containing different targets, (2) photos of the tank and targets and (3) a MATLAB-code for reading the data. A video report of the data collection session is available at https://www.youtube.com/watch?v=65Zca\_qd1Y8.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Physics - Medical Physics},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Experimental\Open_2D_Electrical_Impedance_Tomography_data_archive_Hauptmann_et_al_2017.pdf}
}

@book{haynesCRCHandbookChemistry,
  title = {{{CRC Handbook}} of {{Chemistry}} and {{Physics}}},
  author = {Haynes, W M},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\CRCpress\CRC_Handbook_of_Chemistry_and_Physics_Haynes_.pdf}
}

@online{heCheckerboardContextModel2021,
  title = {Checkerboard {{Context Model}} for {{Efficient Learned Image Compression}}},
  author = {He, Dailan and Zheng, Yaoyan and Sun, Baocheng and Wang, Yan and Qin, Hongwei},
  date = {2021-04-01},
  eprint = {2103.15306},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2103.15306},
  url = {http://arxiv.org/abs/2103.15306},
  urldate = {2024-08-08},
  abstract = {For learned image compression, the autoregressive context model is proved effective in improving the rate-distortion (RD) performance. Because it helps remove spatial redundancies among latent representations. However, the decoding process must be done in a strict scan order, which breaks the parallelization. We propose a parallelizable checkerboard context model (CCM) to solve the problem. Our two-pass checkerboard context calculation eliminates such limitations on spatial locations by re-organizing the decoding order. Speeding up the decoding process more than 40 times in our experiments, it achieves significantly improved computational efficiency with almost the same rate-distortion performance. To the best of our knowledge, this is the first exploration on parallelization-friendly spatial context model for learned image compression.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Checkerboard_Context_Model_He_et_al_2021.pdf}
}

@inproceedings{heDeepResidualLearning2016,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2016-06},
  pages = {770--778},
  publisher = {IEEE},
  location = {Las Vegas, NV, USA},
  doi = {10.1109/CVPR.2016.90},
  url = {http://ieeexplore.ieee.org/document/7780459/},
  urldate = {2023-08-26},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.},
  eventtitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4673-8851-1},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\Deep_Residual_Learning_for_He_et_al_22.pdf}
}

@inproceedings{heDeepResidualLearning2016a,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2016-06},
  pages = {770--778},
  publisher = {IEEE},
  location = {Las Vegas, NV, USA},
  doi = {10.1109/CVPR.2016.90},
  url = {http://ieeexplore.ieee.org/document/7780459/},
  urldate = {2023-08-26},
  eventtitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4673-8851-1},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\Deep_Residual_Learning_for_He_et_al_2016.pdf}
}

@inproceedings{hedmanBakingNeuralRadiance2021,
  title = {Baking {{Neural Radiance Fields}} for {{Real-Time View Synthesis}}},
  booktitle = {2021 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Hedman, Peter and Srinivasan, Pratul P. and Mildenhall, Ben and Barron, Jonathan T. and Debevec, Paul},
  date = {2021-10},
  pages = {5855--5864},
  publisher = {IEEE},
  location = {Montreal, QC, Canada},
  doi = {10.1109/ICCV48922.2021.00582},
  url = {https://ieeexplore.ieee.org/document/9710808/},
  urldate = {2023-10-16},
  abstract = {Neural volumetric representations such as Neural Radiance Fields (NeRF) have emerged as a compelling technique for learning to represent 3D scenes from images with the goal of rendering photorealistic images of the scene from unobserved viewpoints. However, NeRF’s computational requirements are prohibitive for real-time applications: rendering views from a trained NeRF requires querying a multilayer perceptron (MLP) hundreds of times per ray. We present a method to train a NeRF, then precompute and store (i.e. “bake”) it as a novel representation called a Sparse Neural Radiance Grid (SNeRG) that enables realtime rendering on commodity hardware. To achieve this, we introduce 1) a reformulation of NeRF’s architecture, and 2) a sparse voxel grid representation with learned feature vectors. The resulting scene representation retains NeRF’s ability to render fine geometric details and view-dependent appearance, is compact (averaging less than 90 MB per scene), and can be rendered in real-time (higher than 30 frames per second on a laptop GPU). Actual screen captures are shown in our video.},
  eventtitle = {2021 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  isbn = {978-1-66542-812-5},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Volumetric\Baking_Neural_Radiance_Fields_for_Real-Time_View_Synthesis_Hedman_et_al_2021.pdf}
}

@online{heELICEfficientLearned2022,
  title = {{{ELIC}}: {{Efficient Learned Image Compression}} with {{Unevenly Grouped Space-Channel Contextual Adaptive Coding}}},
  shorttitle = {{{ELIC}}},
  author = {He, Dailan and Yang, Ziming and Peng, Weikun and Ma, Rui and Qin, Hongwei and Wang, Yan},
  date = {2022-03-29},
  eprint = {2203.10886},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2203.10886},
  url = {http://arxiv.org/abs/2203.10886},
  urldate = {2024-08-20},
  abstract = {Recently, learned image compression techniques have achieved remarkable performance, even surpassing the best manually designed lossy image coders. They are promising to be large-scale adopted. For the sake of practicality, a thorough investigation of the architecture design of learned image compression, regarding both compression performance and running speed, is essential. In this paper, we first propose uneven channel-conditional adaptive coding, motivated by the observation of energy compaction in learned image compression. Combining the proposed uneven grouping model with existing context models, we obtain a spatial-channel contextual adaptive model to improve the coding performance without damage to running speed. Then we study the structure of the main transform and propose an efficient model, ELIC, to achieve state-of-the-art speed and compression ability. With superior performance, the proposed model also supports extremely fast preview decoding and progressive decoding, which makes the coming application of learning-based image compression more promising.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\ELIC_He_et_al_2022.pdf}
}

@online{heMixtureMillionExperts2024,
  title = {Mixture of {{A Million Experts}}},
  author = {He, Xu Owen},
  date = {2024-07-04},
  eprint = {2407.04153},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.04153},
  url = {http://arxiv.org/abs/2407.04153},
  urldate = {2024-09-22},
  abstract = {The feedforward (FFW) layers in standard transformer architectures incur a linear increase in computational costs and activation memory as the hidden layer width grows. Sparse mixture-of-experts (MoE) architectures have emerged as a viable approach to address this issue by decoupling model size from computational cost. The recent discovery of the fine-grained MoE scaling law shows that higher granularity leads to better performance. However, existing MoE models are limited to a small number of experts due to computational and optimization challenges. This paper introduces PEER (parameter efficient expert retrieval), a novel layer design that utilizes the product key technique for sparse retrieval from a vast pool of tiny experts (over a million). Experiments on language modeling tasks demonstrate that PEER layers outperform dense FFWs and coarse-grained MoEs in terms of performance-compute trade-off. By enabling efficient utilization of a massive number of experts, PEER unlocks the potential for further scaling of transformer models while maintaining computational efficiency.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\MixtureOfExperts\Mixture_of_A_Million_Experts_He_2024.pdf}
}

@article{hentzeModelbasedSourceSeparation2021,
  title = {A Model-Based Source Separation Algorithm for Lung Perfusion Imaging Using Electrical Impedance Tomography},
  author = {Hentze, Benjamin and Muders, Thomas and Hoog Antink, Christoph and Putensen, Christian and Larsson, Anders and Hedenstierna, Göran and Walter, Marian and Leonhardt, Steffen},
  date = {2021-08-01},
  journaltitle = {Physiol. Meas.},
  volume = {42},
  number = {8},
  pages = {084001},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/1361-6579/ac0e84},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/ac0e84},
  urldate = {2024-07-08},
  abstract = {Objective. Electrical impedance tomography (EIT) for lung perfusion imaging is attracting considerable interest in intensive care, as it might open up entirely new ways to adjust ventilation therapy. A promising technique is bolus injection of a conductive indicator to the central venous catheter, which yields the indicator-based signal (IBS). Lung perfusion images are then typically obtained from the IBS using the maximum slope technique. However, the low spatial resolution of EIT results in a partial volume effect (PVE), which requires further processing to avoid regional bias. Approach. In this work, we repose the extraction of lung perfusion images from the IBS as a source separation problem to account for the PVE. We then propose a model-based algorithm, called gamma decomposition (GD), to derive an efficient solution. The GD algorithm uses a signal model to transform the IBS into a parameter space where the source signals of heart and lung are separable by clustering in space and time. Subsequently, it reconstructs lung model signals from which lung perfusion images are unambiguously extracted. Main results. We evaluate the GD algorithm on EIT data of a prospective animal trial with eight pigs. The results show that it enables lung perfusion imaging using EIT at different stages of regional impairment. Furthermore, parameters of the source signals seem to represent physiological properties of the cardio-pulmonary system. Significance. This work represents an important advance in IBS processing that will likely reduce bias of EIT perfusion images and thus eventually enable imaging of regional ventilation/perfusion (V/Q) ratio.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\A_model-based_source_separation_algorithm_for_lung_perfusion_imaging_using_Hentze_et_al_2021.pdf}
}

@article{herzbergGraphConvolutionalNetworks2021,
  title = {Graph {{Convolutional Networks}} for {{Model-Based Learning}} in {{Nonlinear Inverse Problems}}},
  author = {Herzberg, William and Rowe, Daniel B. and Hauptmann, Andreas and Hamilton, Sarah J.},
  date = {2021},
  journaltitle = {IEEE Trans. Comput. Imaging},
  volume = {7},
  pages = {1341--1353},
  issn = {2333-9403, 2334-0118, 2573-0436},
  doi = {10.1109/TCI.2021.3132190},
  url = {https://ieeexplore.ieee.org/document/9633179/},
  urldate = {2024-07-03},
  abstract = {The majority of model-based learned image reconstruction methods in medical imaging have been limited to uniform domains, such as pixelated images. If the underlying model is solved on nonuniform meshes, arising from a finite element method typical for nonlinear inverse problems, interpolation and embeddings are needed. To overcome this, we present a flexible framework to extend model-based learning directly to nonuniform meshes, by interpreting the mesh as a graph and formulating our network architectures using graph convolutional neural networks. This gives rise to the proposed iterative Graph Convolutional Newton-type Method (GCNM), which includes the forward model in the solution of the inverse problem, while all updates are directly computed by the network on the problem specific mesh. We present results for Electrical Impedance Tomography, a severely ill-posed nonlinear inverse problem that is frequently solved via optimization-based methods, where the forward problem is solved by finite element methods. Results for absolute EIT imaging are compared to standard iterative methods as well as a graph residual network. We show that the GCNM has good generalizability to different domain shapes and meshes, out of distribution data as well as experimental data, from purely simulated training data and without transfer training.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\GraphNeuralNetwork\Graph_Convolutional_Networks_for_Model-Based_Learning_in_Nonlinear_Inverse_Herzberg_et_al_2021.pdf}
}

@article{herzbergGraphConvolutionalNetworks2021a,
  title = {Graph {{Convolutional Networks}} for {{Model-Based Learning}} in {{Nonlinear Inverse Problems}}},
  author = {Herzberg, William and Rowe, Daniel B. and Hauptmann, Andreas and Hamilton, Sarah J.},
  date = {2021},
  journaltitle = {IEEE Trans. Comput. Imaging},
  volume = {7},
  pages = {1341--1353},
  issn = {2333-9403, 2334-0118, 2573-0436},
  doi = {10.1109/TCI.2021.3132190},
  url = {https://ieeexplore.ieee.org/document/9633179/},
  urldate = {2024-07-03},
  abstract = {The majority of model-based learned image reconstruction methods in medical imaging have been limited to uniform domains, such as pixelated images. If the underlying model is solved on nonuniform meshes, arising from a finite element method typical for nonlinear inverse problems, interpolation and embeddings are needed. To overcome this, we present a flexible framework to extend model-based learning directly to nonuniform meshes, by interpreting the mesh as a graph and formulating our network architectures using graph convolutional neural networks. This gives rise to the proposed iterative Graph Convolutional Newton-type Method (GCNM), which includes the forward model in the solution of the inverse problem, while all updates are directly computed by the network on the problem specific mesh. We present results for Electrical Impedance Tomography, a severely ill-posed nonlinear inverse problem that is frequently solved via optimization-based methods, where the forward problem is solved by finite element methods. Results for absolute EIT imaging are compared to standard iterative methods as well as a graph residual network. We show that the GCNM has good generalizability to different domain shapes and meshes, out of distribution data as well as experimental data, from purely simulated training data and without transfer training.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\GraphNeuralNetwork\Graph_Convolutional_Networks_for_Model-Based_Learning_in_Nonlinear_Inverse_Herzberg_et_al_22.pdf}
}

@online{heVISTA3DUnifiedSegmentation2024,
  title = {{{VISTA3D}}: {{A Unified Segmentation Foundation Model For 3D Medical Imaging}}},
  shorttitle = {{{VISTA3D}}},
  author = {He, Yufan and Guo, Pengfei and Tang, Yucheng and Myronenko, Andriy and Nath, Vishwesh and Xu, Ziyue and Yang, Dong and Zhao, Can and Simon, Benjamin and Belue, Mason and Harmon, Stephanie and Turkbey, Baris and Xu, Daguang and Li, Wenqi},
  date = {2024-11-22},
  eprint = {2406.05285},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2406.05285},
  url = {http://arxiv.org/abs/2406.05285},
  urldate = {2024-12-13},
  abstract = {Foundation models for interactive segmentation in 2D natural images and videos have sparked significant interest in building 3D foundation models for medical imaging. However, the domain gaps and clinical use cases for 3D medical imaging require a dedicated model that diverges from existing 2D solutions. Specifically, such foundation models should support a full workflow that can actually reduce human effort. Treating 3D medical images as sequences of 2D slices and reusing interactive 2D foundation models seems straightforward, but 2D annotation is too time-consuming for 3D tasks. Moreover, for large cohort analysis, it's the highly accurate automatic segmentation models that reduce the most human effort. However, these models lack support for interactive corrections and lack zero-shot ability for novel structures, which is a key feature of "foundation". While reusing pre-trained 2D backbones in 3D enhances zero-shot potential, their performance on complex 3D structures still lags behind leading 3D models. To address these issues, we present VISTA3D, Versatile Imaging SegmenTation and Annotation model, that targets to solve all these challenges and requirements with one unified foundation model. VISTA3D is built on top of the well-established 3D segmentation pipeline, and it is the first model to achieve state-of-the-art performance in both 3D automatic (supporting 127 classes) and 3D interactive segmentation, even when compared with top 3D expert models on large and diverse benchmarks. Additionally, VISTA3D's 3D interactive design allows efficient human correction, and a novel 3D supervoxel method that distills 2D pretrained backbones grants VISTA3D top 3D zero-shot performance. We believe the model, recipe, and insights represent a promising step towards a clinically useful 3D foundation model. Code and weights are publicly available at https://github.com/Project-MONAI/VISTA.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Segmentation\Medical\VISTA3D_He_et_al_2024.pdf}
}

@article{hirataEffectAveragingVolume2010,
  title = {Effect of the Averaging Volume and Algorithm on the {\emph{in Situ}} Electric Field for Uniform Electric- and Magnetic-Field Exposures},
  author = {Hirata, Akimasa and Takano, Yukinori and Kamimura, Yoshitsugu and Fujiwara, Osamu},
  date = {2010-05-07},
  journaltitle = {Phys. Med. Biol.},
  volume = {55},
  number = {9},
  pages = {N243-N252},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/0031-9155/55/9/N03},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/55/9/N03},
  urldate = {2024-07-03},
  abstract = {The present study quantified the volume-averaged in situ electric field in nerve tissues of anatomically based numeric Japanese male and female models for exposure to extremely low-frequency electric and magnetic fields. A quasi-static finite-difference time-domain method was applied to analyze this problem. The motivation of our investigation is that the dependence of the electric field induced in nerve tissue on the averaging volume/distance is not clear, while a cubical volume of 5 × 5 × 5 mm3 or a straight-line segment of 5 mm is suggested in some documents. The influence of non-nerve tissue surrounding nerve tissue is also discussed by considering three algorithms for calculating the averaged in situ electric field in nerve tissue. The computational results obtained herein reveal that the volume-averaged electric field in the nerve tissue decreases with the averaging volume. In addition, the 99th percentile value of the volume-averaged in situ electric field in nerve tissue is more stable than that of the maximal value for different averaging volume. When including non-nerve tissue surrounding nerve tissue in the averaging volume, the resultant in situ electric fields were not so dependent on the averaging volume as compared to the case excluding non-nerve tissue. In situ electric fields averaged over a distance of 5 mm were comparable or larger than that for a 5 × 5 × 5 mm3 cube depending on the algorithm, nerve tissue considered and exposure scenarios.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\ConductivityOfMaterials\BiologicalTissues\Effect_of_the_averaging_volume_and_algorithm_on_the_iin_situ-i_electric_Hirata_et_al_2010.pdf}
}

@book{holderElectricalImpedanceTomography2005,
  title = {Electrical Impedance Tomography: Methods, History, and Applications},
  shorttitle = {Electrical Impedance Tomography},
  editor = {Holder, David and {Institute of Physics (Great Britain)}},
  date = {2005},
  series = {Series in Medical Physics and Biomedical Engineering},
  publisher = {Institute of Physics Pub},
  location = {Bristol ; Philadelphia},
  isbn = {978-0-7503-0952-3},
  langid = {english},
  pagetotal = {456},
  keywords = {diagnostic use,Electric Impedance,Electrical impedance tomography,methods,Tomography,trends},
  annotation = {OCLC: ocm57430626},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\Electrical_impedance_tomography_Holder_Institute_of_Physics_(Great_Britain)_2005.pdf}
}

@book{holderElectricalImpedanceTomography2005a,
  title = {Electrical Impedance Tomography: Methods, History, and Applications},
  shorttitle = {Electrical Impedance Tomography},
  editor = {Holder, David and {Institute of Physics (Great Britain)}},
  date = {2005},
  series = {Series in Medical Physics and Biomedical Engineering},
  publisher = {Institute of Physics Pub},
  location = {Bristol ; Philadelphia},
  isbn = {978-0-7503-0952-3},
  langid = {english},
  pagetotal = {456},
  keywords = {diagnostic use,Electric Impedance,Electrical impedance tomography,methods,Tomography,trends},
  annotation = {OCLC: ocm57430626},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\Electrical_impedance_tomography_Holder_Institute_of_Physics_(Great_Britain)_22.pdf}
}

@online{hongDaGANDepthAwareGenerative2023,
  title = {{{DaGAN}}++: {{Depth-Aware Generative Adversarial Network}} for {{Talking Head Video Generation}}},
  shorttitle = {{{DaGAN}}++},
  author = {Hong, Fa-Ting and Shen, Li and Xu, Dan},
  date = {2023-12-10},
  eprint = {2305.06225},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.06225},
  url = {http://arxiv.org/abs/2305.06225},
  urldate = {2024-03-05},
  abstract = {Predominant techniques on talking head generation largely depend on 2D information, including facial appearances and motions from input face images. Nevertheless, dense 3D facial geometry, such as pixel-wise depth, plays a critical role in constructing accurate 3D facial structures and suppressing complex background noises for generation. However, dense 3D annotations for facial videos is prohibitively costly to obtain. In this work, firstly, we present a novel self-supervised method for learning dense 3D facial geometry (ie, depth) from face videos, without requiring camera parameters and 3D geometry annotations in training. We further propose a strategy to learn pixel-level uncertainties to perceive more reliable rigid-motion pixels for geometry learning. Secondly, we design an effective geometry-guided facial keypoint estimation module, providing accurate keypoints for generating motion fields. Lastly, we develop a 3D-aware cross-modal (ie, appearance and depth) attention mechanism, which can be applied to each generation layer, to capture facial geometries in a coarse-to-fine manner. Extensive experiments are conducted on three challenging benchmarks (ie, VoxCeleb1, VoxCeleb2, and HDTF). The results demonstrate that our proposed framework can generate highly realistic-looking reenacted talking videos, with new state-of-the-art performances established on these benchmarks. The codes and trained models are publicly available on the GitHub project page at https://github.com/harlanhong/CVPR2022-DaGAN},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\AutoEncoder\DaGAN++_Hong_et_al_2023.pdf}
}

@online{hongDepthAwareGenerativeAdversarial2022,
  title = {Depth-{{Aware Generative Adversarial Network}} for {{Talking Head Video Generation}}},
  author = {Hong, Fa-Ting and Zhang, Longhao and Shen, Li and Xu, Dan},
  date = {2022-03-14},
  eprint = {2203.06605},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2203.06605},
  url = {http://arxiv.org/abs/2203.06605},
  urldate = {2024-03-08},
  abstract = {Talking head video generation aims to produce a synthetic human face video that contains the identity and pose information respectively from a given source image and a driving video.Existing works for this task heavily rely on 2D representations (e.g. appearance and motion) learned from the input images. However, dense 3D facial geometry (e.g. pixel-wise depth) is extremely important for this task as it is particularly beneficial for us to essentially generate accurate 3D face structures and distinguish noisy information from the possibly cluttered background. Nevertheless, dense 3D geometry annotations are prohibitively costly for videos and are typically not available for this video generation task. In this paper, we first introduce a self-supervised geometry learning method to automatically recover the dense 3D geometry (i.e.depth) from the face videos without the requirement of any expensive 3D annotation data. Based on the learned dense depth maps, we further propose to leverage them to estimate sparse facial keypoints that capture the critical movement of the human head. In a more dense way, the depth is also utilized to learn 3D-aware cross-modal (i.e. appearance and depth) attention to guide the generation of motion fields for warping source image representations. All these contributions compose a novel depth-aware generative adversarial network (DaGAN) for talking head generation. Extensive experiments conducted demonstrate that our proposed method can generate highly realistic faces, and achieve significant results on the unseen human faces.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\Depth-Aware_Generative_Hong_et_al_2022.pdf}
}

@article{hoogeboomEquivariantDiffusionMolecule,
  title = {Equivariant {{Diffusion}} for {{Molecule Generation}} in {{3D}}},
  author = {Hoogeboom, Emiel and Satorras, Victor Garcia and Vignac, Clément and Welling, Max},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\DiffusionModels\Graphs\Equivariant_Diffusion_for_Molecule_Generation_in_3D_Hoogeboom_et_al_.pdf}
}

@article{hootenInverseDesignGrating2021,
  title = {Inverse Design of Grating Couplers Using the Policy Gradient Method from Reinforcement Learning},
  author = {Hooten, Sean and Beausoleil, Raymond G. and Vaerenbergh, Thomas Van},
  date = {2021-11-02},
  journaltitle = {Nanophotonics},
  volume = {10},
  number = {15},
  pages = {3843--3856},
  publisher = {De Gruyter},
  issn = {2192-8614},
  doi = {10.1515/nanoph-2021-0332},
  url = {https://www.degruyter.com/document/doi/10.1515/nanoph-2021-0332/html?lang=en},
  urldate = {2024-06-01},
  abstract = {We present a proof-of-concept technique for the inverse design~of electromagnetic devices motivated by the policy gradient method in reinforcement learning, named PHORCED ( PH otonic O ptimization using R EINFORCE C riteria for E nhanced D esign). This technique uses a probabilistic generative neural network interfaced with an electromagnetic solver to assist in the design~of photonic devices, such as grating couplers. We show that PHORCED obtains better performing grating coupler designs than local gradient-based inverse design~via the adjoint~method, while potentially providing faster convergence over competing state-of-the-art generative methods. As a further example of the benefits of this method, we implement transfer learning with PHORCED, demonstrating that a neural network trained to optimize 8° grating couplers can then be re-trained on grating couplers with alternate scattering angles while requiring \&gt;10× fewer simulations than control cases.},
  langid = {english},
  keywords = {adjoint method,deep learning,integrated photonics,inverse design,optimization,reinforcement learning},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\ReinforcementLearning\Inverse_design_of_grating_couplers_using_the_policy_gradient_method_from_Hooten_et_al_2021.pdf}
}

@article{howardFastaiLayeredAPI2020,
  title = {Fastai: {{A Layered API}} for {{Deep Learning}}},
  shorttitle = {Fastai},
  author = {Howard, Jeremy and Gugger, Sylvain},
  date = {2020-02-16},
  journaltitle = {Information},
  volume = {11},
  number = {2},
  pages = {108},
  issn = {2078-2489},
  doi = {10.3390/info11020108},
  url = {https://www.mdpi.com/2078-2489/11/2/108},
  urldate = {2023-09-05},
  abstract = {fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4–5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\AI\Components\Frameworks\Fastai_Howard_Gugger_2020.pdf}
}

@article{hoxieMachineLearningAlldielectric2023,
  title = {Machine Learning of All-Dielectric Core–Shell Nanostructures: The Critical Role of the Objective Function in Inverse Design},
  shorttitle = {Machine Learning of All-Dielectric Core–Shell Nanostructures},
  author = {Hoxie, David J. and Bangalore, Purushotham V. and Appavoo, Kannatassen},
  date = {2023-12-07},
  journaltitle = {Nanoscale},
  volume = {15},
  number = {47},
  pages = {19203--19212},
  publisher = {The Royal Society of Chemistry},
  issn = {2040-3372},
  doi = {10.1039/D3NR04392D},
  url = {https://pubs.rsc.org/en/content/articlelanding/2023/nr/d3nr04392d},
  urldate = {2024-05-31},
  abstract = {To integrate nanophotonics into light-based technologies, it is critical to elicit a desired optical response from its fundamental component, a nanoresonator. Because the optical resonance of a nanoresonator depends strongly on its base material and structural features, machine learning has been contemplated to enhance the design and optimization processes. However, its accuracy in searching the vast parameter space of nanophotonics still poses unresolved questions. Here, we show how the choice of objective functions, in combination with trained neural networks, can drastically change the optimization process—even for a simple nanophotonic structure. To assess how different objective functions select the correct structural parameters that generate a desired optical Mie response, we use a simple core–shell, all-dielectric nanostructure as the benchmark. By controlling the proportion of training data, which represents the “experience” level, we also quantify how the various objective functions perform in finding the ground-truth parameters. Our findings demonstrate that certain objective functions exhibit improved accuracy when used with highly “experienced” neural networks. Surprisingly, we also find other objective functions that perform better when paired with less “experienced” neural networks. Taken together, our results emphasize that it is critical to understand how neural networks are coupled to optimization schemes, as is evident even when a simple core–shell nanostructure is used.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\OneDimension\Machine_learning_of_Hoxie_et_al_2023.pdf}
}

@article{hsiaoInfluenceGeometricParameters2024,
  title = {The {{Influence}} of {{Geometric Parameters}} for {{Training}} an {{Artificial Neural Network}} to {{Predict}} the {{Band Structure}} of 1-{{D Fishbone Photonic Crystal}}},
  author = {Hsiao, Fu-Li and Chen, Chien-Chung and Chang, Chuan-Yu and Huang, Yi-Chia and Tsai, Ying-Pin},
  date = {2024-01},
  journaltitle = {Electronics},
  volume = {13},
  number = {7},
  pages = {1285},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics13071285},
  url = {https://www.mdpi.com/2079-9292/13/7/1285},
  urldate = {2024-06-21},
  abstract = {With the rising demand for the transmission of large amounts of information over long distances, the development of integrated light circuits is the key to improving this technology, and silicon photonics have been developed with low absorption in the near-infrared range and with sophisticated fabrication techniques. To build devices that work in different functionalities, photonic crystals are one of the most used structures due to their ability to manipulate light. The investigation of photonic crystals requires the calculation of photonic band structures and is usually time-consuming work. To reduce the time spent on calculations, a trained ANN is introduced in this study to directly predict the band structures using only a minimal amount of pre-calculated band structure data. A well-used 1-D fishbone-like photonic crystal in the form of a nanobeam is used as the training target, and the influence of adjusting the geometric parameters is discussed, especially the lattice constant and the thickness of the nanobeam. To train the ANN with very few band structures, each of the mode points in the band structure is considered as a single datapoint to increase the amount of training data. The datasets are composed of various raw band structure data. The optimized ANN is introduced at the end of this manuscript.},
  issue = {7},
  langid = {english},
  keywords = {artificial neural network,fishbone-like nanobeam,integrated light circuit,photonic band structure,photonic crystal,silicon photonics},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\AI\Modeling\BandStructure\The_Influence_of_Geometric_Hsiao_et_al_2024.pdf}
}

@article{huaFiniteElementModeling1993,
  title = {Finite Element Modeling of Electrode-Skin Contact Impedance in Electrical Impedance Tomography},
  author = {Hua, P. and Woo, E.J. and Webster, J.G. and Tompkins, W.J.},
  date = {1993-04},
  journaltitle = {IEEE Trans. Biomed. Eng.},
  volume = {40},
  number = {4},
  pages = {335--343},
  issn = {00189294},
  doi = {10.1109/10.222326},
  url = {http://ieeexplore.ieee.org/document/222326/},
  urldate = {2024-07-08},
  abstract = {In electrical impedance tomography (EIT), we inject currents through and measure voltages from an array of surface electrodes. The measured voltages are sensitive to electrode-skin contact impedance because the contact impedance and the cur­ rent density through this contact impedance are both high. We used large electrodes to provide a more uniform current distribu­ tiou aud reduce the contact impedance. A large electrode differs from a point electrode iu that it has shunting and edge effects which cannot be modeled by a single resistor. We used the finite element metbod (FEM) to study the electric field distributions underneath an electrode, and developed three models: a FEM model, a simplified FEM model and a weighted load model. We showed that the FEM models considered both shunting and edge effects and matched closely the experimental measurements. FEM models for electrodes can be used to improve the performance of an electrical impedance tomography reconstruction algorithm.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\ContactImpedance\Finite_element_modeling_of_electrode-skin_contact_impedance_in_electrical_Hua_et_al_1993.pdf}
}

@article{huAnalysisOpticalProperties2013,
  title = {Analysis of Optical Properties in Cylindrical Dielectric Photonic Crystal},
  author = {Hu, Chung-An and Wu, Chien-Jang and Yang, Tzong-Jer and Yang, Su-Lin},
  date = {2013-03},
  journaltitle = {Optics Communications},
  volume = {291},
  pages = {424--434},
  issn = {00304018},
  doi = {10.1016/j.optcom.2012.11.042},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0030401812013594},
  urldate = {2023-11-06},
  abstract = {In this work, theoretical formulas for the H-polarization electromagnetic propagation in a cylindrical multilayer structure (CMS) are given. The relationships between two modes, H- and E-polarization are pointed out. With the derived formulae, we present the numerical results for three model structures such as the single cylindrical interface, the single cylindrical slab, and the cylindrical photonic crystal (CPC). In the single cylindrical interface, it is found that there exists a Brewster starting radius at which a minimum reflectance is attained in H-polarization. In the single cylindrical slab, the result illustrates that the reflectance response in the wavelength domain contains the oscillating and nonoscillating regions. As for the CPC, we find the PBG structure at zero azimuthal mode number is very similar to that of planar photonic crystal. The PBG, however, can be strongly influenced by increasing the azimuthal mode number in a CPC.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Analysis_of_optical_properties_in_cylindrical_dielectric_photonic_crystal_Hu_et_al_2013.pdf}
}

@article{huAnalysisOpticalProperties2013a,
  title = {Analysis of Optical Properties in Cylindrical Dielectric Photonic Crystal},
  author = {Hu, Chung-An and Wu, Chien-Jang and Yang, Tzong-Jer and Yang, Su-Lin},
  date = {2013-03},
  journaltitle = {Optics Communications},
  volume = {291},
  pages = {424--434},
  issn = {00304018},
  doi = {10.1016/j.optcom.2012.11.042},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0030401812013594},
  urldate = {2023-11-06},
  abstract = {In this work, theoretical formulas for the H-polarization electromagnetic propagation in a cylindrical multilayer structure (CMS) are given. The relationships between two modes, H- and E-polarization are pointed out. With the derived formulae, we present the numerical results for three model structures such as the single cylindrical interface, the single cylindrical slab, and the cylindrical photonic crystal (CPC). In the single cylindrical interface, it is found that there exists a Brewster starting radius at which a minimum reflectance is attained in H-polarization. In the single cylindrical slab, the result illustrates that the reflectance response in the wavelength domain contains the oscillating and nonoscillating regions. As for the CPC, we find the PBG structure at zero azimuthal mode number is very similar to that of planar photonic crystal. The PBG, however, can be strongly influenced by increasing the azimuthal mode number in a CPC.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Analysis_of_optical_properties_in_cylindrical_dielectric_photonic_crystal_Hu_et_al_22.pdf}
}

@article{huangDesignWearableWireless2016,
  title = {Design of Wearable and Wireless Electrical Impedance Tomography System},
  author = {Huang, Ji-Jer and Hung, Yi-Hsuan and Wang, Jhi-Joung and Lin, Bor-Shyh},
  date = {2016-01},
  journaltitle = {Measurement},
  volume = {78},
  pages = {9--17},
  issn = {02632241},
  doi = {10.1016/j.measurement.2015.09.031},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224115004984},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is a non-invasive approach to reconstruct the crosssection impedance image of the body. Many EIT systems and impedance image reconstruction algorithms have been proposed in previous studies. However, most of these EIT systems are bulky to cause the limitation of applications. In this study, a wearable and wireless EIT system is proposed to reconstruct impedance images non-invasively and wirelessly. By microminiaturizing the conventional EIT system, the proposed system can provide the advantages of small volume and wireless transmission to reduce the application limitation of conventional EIT systems. Finally, the phantom experiment is tested to validate the performance of the proposed EIT system. The experimental results show the average BR value of the reconstructed image obtained by the proposed system being 1.3 ± 0.2 and the averaged location error ratio being about 6.27 ± 3.14\%. Therefore, the proposed wearable and wireless EIT system can be viewed as a good system prototype and may be applied to more clinical applications in the future.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Wearable\Design_of_wearable_and_wireless_electrical_impedance_tomography_system_Huang_et_al_2016.pdf}
}

@article{huangEfficientVerificationQuantized2024,
  title = {Towards {{Efficient Verification}} of {{Quantized Neural Networks}}},
  author = {Huang, Pei and Wu, Haoze and Yang, Yuting and Daukantas, Ieva and Wu, Min and Zhang, Yedi and Barrett, Clark},
  date = {2024-03-24},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {38},
  number = {19},
  pages = {21152--21160},
  issn = {2374-3468},
  doi = {10.1609/aaai.v38i19.30108},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/30108},
  urldate = {2024-07-24},
  abstract = {Quantization replaces floating point arithmetic with integer arithmetic in deep neural network models, providing more efficient on-device inference with less power and memory. In this work, we propose a framework for formally verifying the properties of quantized neural networks. Our baseline technique is based on integer linear programming which guarantees both soundness and completeness. We then show how efficiency can be improved by utilizing gradient-based heuristic search methods and also bound-propagation techniques. We evaluate our approach on perception networks quantized with PyTorch. Our results show that we can verify quantized networks with better scalability and efficiency than the previous state of the art.},
  issue = {19},
  langid = {english},
  keywords = {General},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Quantization\Towards_Efficient_Verification_of_Quantized_Neural_Networks_Huang_et_al_2024.pdf}
}

@inproceedings{huangHDRNeRFHighDynamic2022,
  title = {{{HDR-NeRF}}: {{High Dynamic Range Neural Radiance Fields}}},
  shorttitle = {{{HDR-NeRF}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Huang, Xin and Zhang, Qi and Feng, Ying and Li, Hongdong and Wang, Xuan and Wang, Qing},
  date = {2022-06},
  pages = {18377--18387},
  publisher = {IEEE},
  location = {New Orleans, LA, USA},
  doi = {10.1109/CVPR52688.2022.01785},
  url = {https://ieeexplore.ieee.org/document/9879785/},
  urldate = {2023-09-05},
  eventtitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66546-946-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\HDR\HDR-NeRF_Huang_et_al_2022.pdf}
}

@inproceedings{huangImprovedImagingResolution2019,
  title = {Improved {{Imaging Resolution}} of {{Electrical Impedance Tomography Using Artificial Neural Networks}} for {{Image Reconstruction}}},
  booktitle = {2019 41st {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  author = {Huang, Shu-Wei and Cheng, Hao-Min and Lin, Shien-Fong},
  date = {2019-07},
  pages = {1551--1554},
  publisher = {IEEE},
  location = {Berlin, Germany},
  doi = {10.1109/EMBC.2019.8856781},
  url = {https://ieeexplore.ieee.org/document/8856781/},
  urldate = {2024-07-03},
  abstract = {Electrical impedance tomography (EIT) is a noninvasive and non-radiative medical imaging technique based on detecting the inhomogeneous electrical properties of the tissue. The inverse problem of EIT is a highly nonlinear ill-posed problem, which is the main reason that affects image quality. Our goal is to solve the EIT inverse problem using the nonlinear mapping properties of artificial neural networks (ANNs) and convolutional neural networks (CNNs). In this paper, the adaptive moment estimation (ADAM) optimization method and mean-square-error (MSE) function are used to train an ANN to solve the inverse problem and a CNN to process the ANN image. The networks are trained on datasets of simulated data, and tested on datasets of simulated data and experimental data. Results for time-difference EIT (td-EIT) images are presented using simulated EIT data from EIDORS and experimental EIT data from our EIT systems. The results are used to compare the proposed method with the one-step Gauss–Newton linear method and RBFNN method. The proposed method offers improved resolution (RES), low position error (PE) and excellent artefact removal compared to the existing methods. The experimental results show that our method can improve the RES by 50 to 70 percent and reduce the PE by 60 to 70 percent. The improvements in RES and processing speed are essential for clinical EIT measurement of dynamic physiological processes.},
  eventtitle = {2019 41st {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} \& {{Biology Society}} ({{EMBC}})},
  isbn = {978-1-5386-1311-5},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\MLP\Improved_Imaging_Resolution_of_Electrical_Impedance_Tomography_Using_Artificial_Huang_et_al_2019.pdf}
}

@online{huangMaterialAnythingGenerating2024,
  title = {Material {{Anything}}: {{Generating Materials}} for {{Any 3D Object}} via {{Diffusion}}},
  shorttitle = {Material {{Anything}}},
  author = {Huang, Xin and Wang, Tengfei and Liu, Ziwei and Wang, Qing},
  date = {2024-11-22},
  eprint = {2411.15138},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2411.15138},
  url = {http://arxiv.org/abs/2411.15138},
  urldate = {2024-12-01},
  abstract = {We present Material Anything, a fully-automated, unified diffusion framework designed to generate physically-based materials for 3D objects. Unlike existing methods that rely on complex pipelines or case-specific optimizations, Material Anything offers a robust, end-to-end solution adaptable to objects under diverse lighting conditions. Our approach leverages a pre-trained image diffusion model, enhanced with a triple-head architecture and rendering loss to improve stability and material quality. Additionally, we introduce confidence masks as a dynamic switcher within the diffusion model, enabling it to effectively handle both textured and texture-less objects across varying lighting conditions. By employing a progressive material generation strategy guided by these confidence masks, along with a UV-space material refiner, our method ensures consistent, UV-ready material outputs. Extensive experiments demonstrate our approach outperforms existing methods across a wide range of object categories and lighting conditions.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Materials\Material_Anything_Huang_et_al_2024.pdf}
}

@online{huangOlympicArenaBenchmarkingMultidiscipline2024,
  title = {{{OlympicArena}}: {{Benchmarking Multi-discipline Cognitive Reasoning}} for {{Superintelligent AI}}},
  shorttitle = {{{OlympicArena}}},
  author = {Huang, Zhen and Wang, Zengzhi and Xia, Shijie and Li, Xuefeng and Zou, Haoyang and Xu, Ruijie and Fan, Run-Ze and Ye, Lyumanshan and Chern, Ethan and Ye, Yixin and Zhang, Yikai and Yang, Yuqing and Wu, Ting and Wang, Binjie and Sun, Shichao and Xiao, Yang and Li, Yiyuan and Zhou, Fan and Chern, Steffi and Qin, Yiwei and Ma, Yan and Su, Jiadi and Liu, Yixiu and Zheng, Yuxiang and Zhang, Shaoting and Lin, Dahua and Qiao, Yu and Liu, Pengfei},
  date = {2024-06-18},
  eprint = {2406.12753},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.12753},
  url = {http://arxiv.org/abs/2406.12753},
  urldate = {2024-07-03},
  abstract = {The evolution of Artificial Intelligence (AI) has been significantly accelerated by advancements in Large Language Models (LLMs) and Large Multimodal Models (LMMs), gradually showcasing potential cognitive reasoning abilities in problem-solving and scientific discovery (i.e., AI4Science) once exclusive to human intellect. To comprehensively evaluate current models' performance in cognitive reasoning abilities, we introduce OlympicArena, which includes 11,163 bilingual problems across both text-only and interleaved text-image modalities. These challenges encompass a wide range of disciplines spanning seven fields and 62 international Olympic competitions, rigorously examined for data leakage. We argue that the challenges in Olympic competition problems are ideal for evaluating AI's cognitive reasoning due to their complexity and interdisciplinary nature, which are essential for tackling complex scientific challenges and facilitating discoveries. Beyond evaluating performance across various disciplines using answer-only criteria, we conduct detailed experiments and analyses from multiple perspectives. We delve into the models' cognitive reasoning abilities, their performance across different modalities, and their outcomes in process-level evaluations, which are vital for tasks requiring complex reasoning with lengthy solutions. Our extensive evaluations reveal that even advanced models like GPT-4o only achieve a 39.97\% overall accuracy, illustrating current AI limitations in complex reasoning and multimodal integration. Through the OlympicArena, we aim to advance AI towards superintelligence, equipping it to address more complex challenges in science and beyond. We also provide a comprehensive set of resources to support AI research, including a benchmark dataset, an open-source annotation platform, a detailed evaluation tool, and a leaderboard with automatic submission features.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Strategies\Reasoning\OlympicArena_Huang_et_al_2024.pdf}
}

@book{hubbardHowMeasureAnything2014,
  title = {How to {{Measure Anything}}: {{Finding}} the {{Value}} of {{Intangibles}} in {{Business}}},
  shorttitle = {How to {{Measure Anything}}},
  author = {Hubbard, Douglas W.},
  date = {2014-03-17},
  edition = {3rd edition},
  publisher = {Wiley},
  location = {Hoboken, New Jersey},
  abstract = {Now updated with new measurement methods and new examples, How to Measure Anything shows managers how to inform themselves in order to make less risky, more profitable business decisionsThis insightful and eloquent book will show you how to measure those things in your own business, government agency or other organization that, until now, you may have considered "immeasurable," including customer satisfaction, organizational flexibility, technology risk, and technology ROI.Adds new measurement methods, showing how they can be applied to a variety of areas such as risk management and customer satisfactionSimplifies overall content while still making the more technical applications available to those readers who want to dig deeperContinues to boldly assert that any perception of "immeasurability" is based on certain popular misconceptions about measurement and measurement methodsShows the common reasoning for calling something immeasurable, and sets out to correct those ideasOffers practical methods for measuring a variety of "intangibles"Provides an online database (www.howtomeasureanything.com) of downloadable, practical examples worked out in detailed spreadsheetsWritten by recognized expert Douglas Hubbard―creator of Applied Information Economics―How to Measure Anything, Third Edition illustrates how the author has used his approach across various industries and how any problem, no matter how difficult, ill defined, or uncertain can lend itself to measurement using proven methods.},
  isbn = {978-1-118-53927-9},
  langid = {english},
  pagetotal = {432},
  file = {C:\Users\ahmed\OneDrive\Research\Business\Value\How_to_Measure_Anything_Hubbard_2014.epub}
}

@article{huDryWearableTextile2021,
  title = {Dry {{Wearable Textile Electrodes}} for {{Portable Electrical Impedance Tomography}}},
  author = {Hu, Chang-Lin and Cheng, I-Cheng and Huang, Chih-Hsien and Liao, Yu-Te and Lin, Wei-Chieh and Tsai, Kun-Ju and Chi, Chih-Hsien and Chen, Chang-Wen and Wu, Chia-Hsi and Lin, I-Te and Li, Chien-Ju and Lin, Chii-Wann},
  date = {2021-10-13},
  journaltitle = {Sensors},
  volume = {21},
  number = {20},
  pages = {6789},
  issn = {1424-8220},
  doi = {10.3390/s21206789},
  url = {https://www.mdpi.com/1424-8220/21/20/6789},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT), a noninvasive and radiation-free medical imaging technique, has been used for continuous real-time regional lung aeration. However, adhesive electrodes could cause discomfort and increase the risk of skin injury during prolonged measurement. Additionally, the conductive gel between the electrodes and skin could evaporate in long-term usage and deteriorate the signal quality. To address these issues, in this work, textile electrodes integrated with a clothing belt are proposed to achieve EIT lung imaging along with a custom portable EIT system. The simulation and experimental results have verified the validity of the proposed portable EIT system. Furthermore, the imaging results of using the proposed textile electrodes were compared with commercial electrocardiogram electrodes to evaluate their performance.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Wearable\Dry_Wearable_Textile_Electrodes_for_Portable_Electrical_Impedance_Tomography_Hu_et_al_2021.pdf}
}

@article{huHighfidelity3DReconstruction2024,
  title = {High-Fidelity {{3D}} Reconstruction of Plants Using {{Neural Radiance Fields}}},
  author = {Hu, Kewei and Ying, Wei and Pan, Yaoqiang and Kang, Hanwen and Chen, Chao},
  date = {2024-05-01},
  journaltitle = {Computers and Electronics in Agriculture},
  volume = {220},
  pages = {108848},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2024.108848},
  url = {https://www.sciencedirect.com/science/article/pii/S0168169924002394},
  urldate = {2024-06-12},
  abstract = {Accurate reconstruction of plant phenotypes plays a key role in optimizing sustainable farming practices in the field of Precision Agriculture (PA). Currently, optical sensor-based approaches dominate the field, but the need for high-fidelity 3D reconstruction of crops and plants in unstructured agricultural environments remains challenging. Recently, a promising development has emerged in the form of Neural Radiance Fields (NeRF), a novel method that utilizes neural density fields. This technology has shown impressive performance in various novel vision synthesis tasks, but has remained relatively unexplored in the agricultural context. In our study, we focus on two fundamental tasks within plant phenotyping: (1) the synthesis of 2D novel-view images and (2) the 3D reconstruction of crop and plant models. We explore the world of NeRF, in particular two state-of-the-art (SOTA) methods: Instant-NGP, which excels in generating high-quality images with impressive training and inference speed, and Instant-NSR, which improves the reconstructed geometry by incorporating the Signed Distance Function (SDF) during training. In particular, we present a novel plant phenotype dataset comprising real plant images from production environments. This dataset is a first-of-its-kind initiative aimed at comprehensively exploring the advantages and limitations of NeRF in agricultural contexts. Our experimental results show that NeRF demonstrates commendable performance in the synthesis of novel-view images and is able to achieve reconstruction results that are competitive with Reality Capture, a leading commercial software for 3D Multi-View Stereo (MVS)-based reconstruction. Moreover, our study also highlights certain drawbacks of NeRF, including relatively slow training speeds, performance limitations in cases of insufficient sampling, and challenges in obtaining geometry quality in complex setups. In conclusion, NeRF introduces a new paradigm in plant phenotyping, providing a powerful tool capable of generating multiple representations, such as multi-view images, point cloud and mesh, from a single process.},
  keywords = {Deep-learning,NeRF,Phenotyping,Robotics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Hyperspectral\High-fidelity_3D_reconstruction_of_plants_using_Neural_Radiance_Fields_Hu_et_al_2024.pdf}
}

@inproceedings{huImageReconstructionElectrical2019,
  title = {Image Reconstruction for Electrical Impedance Tomography Based on Spatial Invariant Feature Maps and Convolutional Neural Network},
  booktitle = {2019 {{IEEE International Conference}} on {{Imaging Systems}} and {{Techniques}} ({{IST}})},
  author = {Hu, Delin and Lu, Keming and Yang, Yunjie},
  date = {2019-12},
  pages = {1--6},
  publisher = {IEEE},
  location = {Abu Dhabi, United Arab Emirates},
  doi = {10.1109/IST48021.2019.9010151},
  url = {https://ieeexplore.ieee.org/document/9010151/},
  urldate = {2024-07-03},
  abstract = {Data-driven methods are attracting more and more attention in the field of electrical impedance tomography. Many learning-based tomographic algorithms have been presented and investigated in the past few years. However, few related studies pay attention to the symmetrical geometrical structure of tomographic sensors and the possible benefits it may bring to learning-based image reconstruction. Aiming to this, we propose the concept of electrical impedance maps, which can better reflect the nature of geometry of tomographic sensors and have similar properties to images. Then we design a fully convolutional network to build the relationship between electrical impedance maps and conductivity distribution images. The effectiveness and performance of our method is evaluated by both simulation and experimental datasets with different conductivity distribution patterns.},
  eventtitle = {2019 {{IEEE International Conference}} on {{Imaging Systems}} and {{Techniques}} ({{IST}})},
  isbn = {978-1-72813-868-8},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Image_reconstruction_for_electrical_impedance_tomography_based_on_spatial_Hu_et_al_2019.pdf}
}

@online{huOGBLSCLargeScaleChallenge2021,
  title = {{{OGB-LSC}}: {{A Large-Scale Challenge}} for {{Machine Learning}} on {{Graphs}}},
  shorttitle = {{{OGB-LSC}}},
  author = {Hu, Weihua and Fey, Matthias and Ren, Hongyu and Nakata, Maho and Dong, Yuxiao and Leskovec, Jure},
  date = {2021-10-20},
  eprint = {2103.09430},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2103.09430},
  urldate = {2023-08-26},
  abstract = {Enabling effective and efficient machine learning (ML) over large-scale graph data (e.g., graphs with billions of edges) can have a great impact on both industrial and scientific applications. However, existing efforts to advance large-scale graph ML have been largely limited by the lack of a suitable public benchmark. Here we present OGB Large-Scale Challenge (OGB-LSC), a collection of three real-world datasets for facilitating the advancements in large-scale graph ML. The OGB-LSC datasets are orders of magnitude larger than existing ones, covering three core graph learning tasks—link prediction, graph regression, and node classification. Furthermore, we provide dedicated baseline experiments, scaling up expressive graph ML models to the massive datasets. We show that expressive models significantly outperform simple scalable baselines, indicating an opportunity for dedicated efforts to further improve graph ML at scale. Moreover, OGB-LSC datasets were deployed at ACM KDD Cup 2021 and attracted more than 500 team registrations globally, during which significant performance improvements were made by a variety of innovative techniques. We summarize the common techniques used by the winning solutions and highlight the current best practices in large-scale graph ML. Finally, we describe how we have updated the datasets after the KDD Cup to further facilitate research advances. The OGB-LSC datasets, baseline code, and all the information about the KDD Cup are available at https://ogb.stanford.edu/docs/lsc/.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\AI\Components\Datasets\OGB-LSC_Hu_et_al_2021.pdf}
}

@online{huOpenGraphBenchmark2021,
  title = {Open {{Graph Benchmark}}: {{Datasets}} for {{Machine Learning}} on {{Graphs}}},
  shorttitle = {Open {{Graph Benchmark}}},
  author = {Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  date = {2021-02-24},
  eprint = {2005.00687},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2005.00687},
  urldate = {2023-08-26},
  abstract = {We present the OPEN GRAPH BENCHMARK (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale, encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at https://ogb.stanford.edu.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/OneDrive - Faculty Of Science (Sohag University)/Research/AI/Components/Datasets/Open_Graph_Benchmark_Hu_et_al_2021.pdf}
}

@book{hutterAutomatedMachineLearning2019,
  title = {Automated {{Machine Learning}}: {{Methods}}, {{Systems}}, {{Challenges}}},
  shorttitle = {Automated {{Machine Learning}}},
  editor = {Hutter, Frank and Kotthoff, Lars and Vanschoren, Joaquin},
  date = {2019},
  series = {The {{Springer Series}} on {{Challenges}} in {{Machine Learning}}},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-05318-5},
  url = {http://link.springer.com/10.1007/978-3-030-05318-5},
  urldate = {2023-09-27},
  isbn = {978-3-030-05317-8 978-3-030-05318-5},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\HyperparameterOptimization\Automated_Machine_Learning_Hutter_et_al_2019.pdf}
}

@article{icenogleRefractiveIndexesTemperature1976,
  title = {Refractive Indexes and Temperature Coefficients of Germanium and Silicon},
  author = {Icenogle, H. W. and Platt, Ben C. and Wolfe, William L.},
  date = {1976-10-01},
  journaltitle = {Appl. Opt.},
  volume = {15},
  number = {10},
  pages = {2348},
  issn = {0003-6935, 1539-4522},
  doi = {10.1364/AO.15.002348},
  url = {https://opg.optica.org/abstract.cfm?URI=ao-15-10-2348},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Semiconductor\Refractive_indexes_and_temperature_coefficients_of_germanium_and_silicon_Icenogle_et_al_1976.pdf}
}

@article{InterspecimenComparisonRefractive,
  title = {Interspecimen {{Comparison}} of the {{Refractive Index}} of {{Fused Silica}},†\_{{Malitson}}\_1965.Pdf},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Dielectric\Interspecimen_Comparison_of_the_Refractive_Index_of_Fused_Silica,†_Malitson_1965_.pdf}
}

@unpublished{IntroductionInverseProblems,
  title = {Introduction to {{Inverse Problems}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Presentaions\Introduction_to_Inverse_Problems_.pdf}
}

@book{IntroductionMathematicsEmerging2008,
  title = {An {{Introduction}} to {{Mathematics}} of {{Emerging Biomedical Imaging}}},
  date = {2008},
  series = {{{MathéMatiques}} \& {{Applications}}},
  volume = {62},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-79553-7},
  url = {http://link.springer.com/10.1007/978-3-540-79553-7},
  urldate = {2024-07-08},
  isbn = {978-3-540-79552-0 978-3-540-79553-7},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\An_Introduction_to_Mathematics_of_Emerging_Biomedical_Imaging_2008.pdf}
}

@article{isazaGenerationSyntheticDatabase2022,
  title = {Generation of a {{Synthetic Database}} for the {{Optical Response}} of {{One-Dimensional Photonic Crystals Using Genetic Algorithms}}},
  author = {Isaza, Cesar and Lujan-Cabrera, Ivan Alonso and Anaya Rivera, Ely Karina and Rizzo Sierra, Jose Amilcar and Zavala De Paz, Jonny Paul and Ramirez-Gutierrez, Cristian Felipe},
  date = {2022-01},
  journaltitle = {Mathematics},
  volume = {10},
  number = {23},
  pages = {4484},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2227-7390},
  doi = {10.3390/math10234484},
  url = {https://www.mdpi.com/2227-7390/10/23/4484},
  urldate = {2024-06-21},
  abstract = {This work proposes an optimization tool based on genetic algorithms for the inverse design of photonic crystals. Based on target reflectance, the algorithm generates a population of chromosomes where the genes represent the thickness of a layer of a photonic crystal. Each layer is independent of another. Therefore, the sequence obtained is a disordered configuration. In the genetic algorithm, two dielectric materials are first selected to generate the population. Throughout the simulation, the chromosomes are evaluated, crossed over, and mutated to find the best-fitted one based on an error function. The target reflectance was a perfect mirror in the visible region. As a result, it was found that obtaining photonic crystal configurations with a specific stop band with disordered arrangements is possible. The genetic information of the best-fitted individuals (layer sequence, optical response, and error) is stored in an h5 format. This method of generating artificial one-dimensional photonic crystal data can be used to train a neural network for solving the problem of the inverse design of any crystal with a specific optical response.},
  issue = {23},
  langid = {english},
  keywords = {absorption,dispersion,genetic algorithms,optimization,reflectance,refractive index},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\AI\Modeling\OpticalProperties\Generation_of_a_Synthetic_Isaza_et_al_2022.pdf}
}

@online{islamHowMuchPosition2020,
  title = {How {{Much Position Information Do Convolutional Neural Networks Encode}}?},
  author = {Islam, Md Amirul and Jia, Sen and Bruce, Neil D. B.},
  date = {2020-01-22},
  eprint = {2001.08248},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2001.08248},
  url = {http://arxiv.org/abs/2001.08248},
  urldate = {2024-11-26},
  abstract = {In contrast to fully connected networks, Convolutional Neural Networks (CNNs) achieve efficiency by learning weights associated with local filters with a finite spatial extent. An implication of this is that a filter may know what it is looking at, but not where it is positioned in the image. Information concerning absolute position is inherently useful, and it is reasonable to assume that deep CNNs may implicitly learn to encode this information if there is a means to do so. In this paper, we test this hypothesis revealing the surprising degree of absolute position information that is encoded in commonly used neural networks. A comprehensive set of experiments show the validity of this hypothesis and shed light on how and where this information is represented while offering clues to where positional information is derived from in deep CNNs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\How_Much_Position_Information_Do_Convolutional_Neural_Networks_Encode_Islam_et_al_2020.pdf}
}

@inproceedings{iwaiControllingRateDistortion2024,
  title = {Controlling {{Rate}}, {{Distortion}}, and {{Realism}}: {{Towards}} a {{Single Comprehensive Neural Image Compression Model}}},
  shorttitle = {Controlling {{Rate}}, {{Distortion}}, and {{Realism}}},
  author = {Iwai, Shoma and Miyazaki, Tomo and Omachi, Shinichiro},
  date = {2024},
  pages = {2900--2909},
  url = {https://openaccess.thecvf.com/content/WACV2024/html/Iwai_Controlling_Rate_Distortion_and_Realism_Towards_a_Single_Comprehensive_Neural_WACV_2024_paper.html},
  urldate = {2024-12-23},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Controlling_Rate,_Distortion,_Iwai_et_al_2024.pdf}
}

@article{jaaskelainenEffectiveRefractiveIndex2002,
  title = {Effective Refractive Index of Calcium Carbonate Pigment Slurries by a Surface-Plasmon-Resonance Sensor},
  author = {Jääskeläinen, Anssi and Peiponen, Kai-Erik and Tapper, Unto and Kauppinen, Esko I and Lumme, Kari},
  date = {2002-01},
  journaltitle = {Dyes and Pigments},
  volume = {52},
  number = {1},
  pages = {15--21},
  issn = {01437208},
  doi = {10.1016/S0143-7208(01)00067-5},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0143720801000675},
  urldate = {2024-02-22},
  abstract = {A surface-plasmon-resonance sensor was applied in the measurement of the effective refractive index of highly turbid calcium carbonate pigment slurries. Information on the absorption of the pigment slurries as a function of the concentration was obtained by the sensor. It is suggested that the sensor can be used for monitoring the optical properties of slurries. \# 2002 Elsevier Science Ltd. All rights reserved.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\Materials\Solutions\Effective_refractive_index_of_calcium_carbonate_pigment_slurries_by_a_Jaaskelainen_et_al_2002.pdf}
}

@article{jacobOpticalHyperlensFarfield2006,
  title = {Optical {{Hyperlens}}: {{Far-ﬁeld}}d Imaging beyond the Diffraction Limi},
  author = {Jacob, Zubin and Alekseyev, Leonid V and Narimanov, Evgenii},
  date = {2006},
  abstract = {We propose an approach to far-field optical imaging beyond the diffraction limit. The proposed system allows image magnification, is robust with respect to material losses and can be fabricated by adapting existing metamaterial technologies in a cylindrical geometry.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Optical_Hyperlens_Jacob_et_al_2006.pdf}
}

@inproceedings{jainZeroShotTextGuidedObject2022,
  title = {Zero-{{Shot Text-Guided Object Generation}} with {{Dream Fields}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Jain, Ajay and Mildenhall, Ben and Barron, Jonathan T. and Abbeel, Pieter and Poole, Ben},
  date = {2022-06},
  pages = {857--866},
  issn = {2575-7075},
  doi = {10.1109/CVPR52688.2022.00094},
  url = {https://ieeexplore.ieee.org/document/9880330},
  urldate = {2024-01-30},
  abstract = {We combine neural rendering with multi-modal image and text representations to synthesize diverse 3D objects solely from natural language descriptions. Our method, Dream Fields, can generate the geometry and color of a wide range of objects without 3D supervision. Due to the scarcity of diverse, captioned 3D data, prior methods only generate objectsfrom a handful of categories, such as ShapeNet. Instead, we guide generation with image-text models pre-trained on large datasets of captioned images from the web. Our method optimizes a Neural Radiance Field from many camera views so that rendered images score highly with a target caption according to a pre-trained CLIP model. To improve fidelity and visual quality, we introduce simple geometric priors, including sparsity-inducing transmittance regularization, scene bounds, and new MLP architectures. In experiments, Dream Fields produce realistic, multi-view consistent object geometry and color from a variety of natural language captions.},
  eventtitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  keywords = {3D from multi-view and sensors,3D from single images,Computer vision,Deep learning architectures and techniques,Geometry,Image and video synthesis and generation,Image color analysis,Machine learning,Self-& semi-& meta- Transfer/low-shot/long-tail learning,Shape,Solid modeling,Three-dimensional displays,Vision + language,Vision applications and systems,Visualization},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\TextAndImage\Zero-Shot_Text-Guided_Object_Generation_with_Dream_Fields_Jain_et_al_2022.pdf}
}

@article{jamshidi-ghalehTunabilityMultichannelOptical2015,
  title = {Tunability of Multichannel Optical Filter Based on Magnetized One-Dimensional Plasma Photonic Crystal},
  author = {Jamshidi-Ghaleh, K. and Karami-Garehgeshlagi, F. and Mazloom, A. A.},
  date = {2015-10-01},
  journaltitle = {Physics of Plasmas},
  volume = {22},
  number = {10},
  pages = {103507},
  issn = {1070-664X, 1089-7674},
  doi = {10.1063/1.4932324},
  url = {https://pubs.aip.org/pop/article/22/10/103507/109930/Tunability-of-multichannel-optical-filter-based-on},
  urldate = {2024-01-22},
  abstract = {A one dimensional plasma photonic crystal (1DPPC) structure was proposed to design a tunable compressing/broadening multi-channel optical filter with external controllability. The 1DPPC with arrangement of (AP)nD(PA)n, where A and D are the dielectric materials, P is a magnetized plasma layer and n is the number of the periodicity, was proposed. The well-known transfer matrix method was employed for analysis. In linear transmittance spectrum, n\,−\,1 defect modes were appeared inside the photonic band gap. The results were shown that by increasing the applied magnetic field intensity and its direction, a red-shift and blue-shift were, respectively, observed in defect mode frequencies. On the other hand, the modes were compressed and broadened with increasing the intensity and the direction of the applied magnetic field, respectively. Externally controllable defect modes can be useful in designing a multichannel tunable optical filter.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Tunability_of_multichannel_optical_filter_based_on_magnetized_one-dimensional_Jamshidi-Ghaleh_et_al_2015.pdf}
}

@article{jausUnifyingAnatomySegmentation2023,
  title = {Towards {{Unifying Anatomy Segmentation}}: {{Automated Generation}} of a {{Full-body CT Dataset}} via {{Knowledge Aggregation}} and {{Anatomical Guidelines}}},
  shorttitle = {Towards {{Unifying Anatomy Segmentation}}},
  author = {Jaus, Alexander and Seibold, Constantin and Hermann, Kelsey and Walter, Alexandra and Giske, Kristina and Haubold, Johannes and Kleesiek, Jens and Stiefelhagen, Rainer},
  date = {2023},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2307.13375},
  url = {https://arxiv.org/abs/2307.13375},
  urldate = {2024-11-28},
  abstract = {In this study, we present a method for generating automated anatomy segmentation datasets using a sequential process that involves nnU-Net-based pseudo-labeling and anatomy-guided pseudo-label refinement. By combining various fragmented knowledge bases, we generate a dataset of whole-body CT scans with \$142\$ voxel-level labels for 533 volumes providing comprehensive anatomical coverage which experts have approved. Our proposed procedure does not rely on manual annotation during the label aggregation stage. We examine its plausibility and usefulness using three complementary checks: Human expert evaluation which approved the dataset, a Deep Learning usefulness benchmark on the BTCV dataset in which we achieve 85\% dice score without using its training dataset, and medical validity checks. This evaluation procedure combines scalable automated checks with labor-intensive high-quality expert checks. Besides the dataset, we release our trained unified anatomical segmentation model capable of predicting \$142\$ anatomical structures on CT data.},
  version = {1},
  keywords = {Computer Vision and Pattern Recognition (cs.CV),FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Image and Video Processing (eess.IV)},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Segmentation\Towards_Unifying_Anatomy_Jaus_et_al_2023.pdf}
}

@article{jehlFastParallelSolver2015,
  title = {A {{Fast Parallel Solver}} for the {{Forward Problem}} in {{Electrical Impedance Tomography}}},
  author = {Jehl, Markus and Dedner, Andreas and Betcke, Timo and Aristovich, Kirill and Klofkorn, Robert and Holder, David},
  date = {2015-01},
  journaltitle = {IEEE Trans. Biomed. Eng.},
  volume = {62},
  number = {1},
  pages = {126--137},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/TBME.2014.2342280},
  url = {http://ieeexplore.ieee.org/document/6862884/},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is a noninvasive imaging modality, where imperceptible currents are applied to the skin and the resulting surface voltages are measured. It has the potential to distinguish between ischaemic and haemorrhagic stroke with a portable and inexpensive device. The image reconstruction relies on an accurate forward model of the experimental setup. Because of the relatively small signal in stroke EIT, the finite-element modeling requires meshes of more than 10 million elements. To study the requirements in the forward modeling in EIT and also to reduce the time for experimental image acquisition, it is necessary to reduce the run time of the forward computation. We show the implementation of a parallel forward solver for EIT using the DUNE-FEM C++ library and demonstrate its performance on many CPU’s of a computer cluster. For a typical EIT application a direct solver was significantly slower and not an alternative to iterative solvers with multigrid preconditioning. With this new solver, we can compute the forward solutions and the Jacobian matrix of a typical EIT application with 30 electrodes on a 15-million element mesh in less than 15 min. This makes it a valuable tool for simulation studies and EIT applications with high precision requirements. It is freely available for download.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Krylov\A_Fast_Parallel_Solver_for_the_Forward_Problem_in_Electrical_Impedance_Jehl_et_al_2015.pdf}
}

@article{jeonRecentAdvancementsMetalenses2023,
  title = {Recent Advancements of Metalenses for Functional Imaging},
  author = {Jeon, Dongmin and Shin, Kilsoo and Moon, Seong-Won and Rho, Junsuk},
  date = {2023-05-24},
  journaltitle = {Nano Convergence},
  volume = {10},
  number = {1},
  pages = {24},
  issn = {2196-5404},
  doi = {10.1186/s40580-023-00372-8},
  url = {https://doi.org/10.1186/s40580-023-00372-8},
  urldate = {2023-11-16},
  abstract = {Metasurfaces can modulate light with periodically arranged subwavelength scatterers, and they can generate arbitrary wavefronts. Therefore, they can be used to realize various optical components. In particular, metasurfaces can be used to realize lenses, so-called metalenses. In the last decade, metalenses have been actively studied and developed. In this review, we firstly introduce the fundamental principles of metalenses in terms of materials, phase modulation method, and design method. Based on these principles, the functionalities and the applications can consequently be realized. Metalenses have a much larger number of degrees of freedom compared with that of existing refractive or diffractive lenses. Thus, they afford functionalities such as tunability, high numerical aperture, and aberration correction. Metalenses with these functionalities can be applied in various optical systems such as imaging systems and spectrometers. Finally, we discuss the future applications of metalenses.},
  keywords = {Aberration correction,Imaging system,Inverse design,Metalens,Metasurface,Numerical aperture,Phase modulation,Spectrometer,Tunability},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\MetaLens\Review\Recent_advancements_of_metalenses_for_functional_imaging_Jeon_et_al_2023.pdf}
}

@inproceedings{jiaGenerativeLatentCoding2024,
  title = {Generative {{Latent Coding}} for {{Ultra-Low Bitrate Image Compression}}},
  author = {Jia, Zhaoyang and Li, Jiahao and Li, Bin and Li, Houqiang and Lu, Yan},
  date = {2024},
  pages = {26088--26098},
  url = {https://openaccess.thecvf.com/content/CVPR2024/html/Jia_Generative_Latent_Coding_for_Ultra-Low_Bitrate_Image_Compression_CVPR_2024_paper.html},
  urldate = {2024-12-23},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Generative_Latent_Coding_for_Jia_et_al_2024.pdf}
}

@article{jiangHandGestureRecognition2020,
  title = {Hand {{Gesture Recognition Using Three-Dimensional Electrical Impedance Tomography}}},
  author = {Jiang, Dai and Wu, Yu and Demosthenous, Andreas},
  date = {2020-09},
  journaltitle = {IEEE Trans. Circuits Syst. II},
  volume = {67},
  number = {9},
  pages = {1554--1558},
  issn = {1549-7747, 1558-3791},
  doi = {10.1109/TCSII.2020.3006430},
  url = {https://ieeexplore.ieee.org/document/9131824/},
  urldate = {2024-07-08},
  abstract = {This brief presents a 16-electrode electrical impedance tomography (EIT) system for hand gesture recognition. The hardware of the system is based on integrated circuits including a 12-bit high spectral purity current-steering DAC implemented in 0.18 µm CMOS technology, a current driver and an instrumentation amplifier in 0.35 µm CMOS technology. Both 2D and 3D EIT electrode arrangements were tested for hand gesture recognition. It is shown that using machine learning algorithms, eight hand gestures can be distinguished from the measured bio-impedance data with an accuracy of 97.9\% when the electrodes are placed on a single wristband, and an accuracy of 99.5\% with the same number of electrodes distributed on two wristbands for 3D EIT measurement. In particular 3D EIT demonstrated significant superiority in its ability to discriminate between gestures with similar muscle contractions.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\HandGestureRecognition\Hand_Gesture_Recognition_Using_Three-Dimensional_Electrical_Impedance_Tomography_Jiang_et_al_2020.pdf}
}

@online{jiangMixtralExperts2024,
  title = {Mixtral of {{Experts}}},
  author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and family=Casas, given=Diego, prefix=de las, useprefix=false and Hanna, Emma Bou and Bressand, Florian and Lengyel, Gianna and Bour, Guillaume and Lample, Guillaume and Lavaud, Lélio Renard and Saulnier, Lucile and Lachaux, Marie-Anne and Stock, Pierre and Subramanian, Sandeep and Yang, Sophia and Antoniak, Szymon and Scao, Teven Le and Gervet, Théophile and Lavril, Thibaut and Wang, Thomas and Lacroix, Timothée and Sayed, William El},
  date = {2024-01-08},
  eprint = {2401.04088},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.04088},
  url = {http://arxiv.org/abs/2401.04088},
  urldate = {2024-09-22},
  abstract = {We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model fine-tuned to follow instructions, Mixtral 8x7B - Instruct, that surpasses GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\MixtureOfExperts\Mixtral_of_Experts_Jiang_et_al_2024.pdf}
}

@online{jiangMLICLinearComplexity2024,
  title = {{{MLIC}}++: {{Linear Complexity Multi-Reference Entropy Modeling}} for {{Learned Image Compression}}},
  shorttitle = {{{MLIC}}++},
  author = {Jiang, Wei and Yang, Jiayu and Zhai, Yongqi and Gao, Feng and Wang, Ronggang},
  date = {2024-02-20},
  eprint = {2307.15421},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2307.15421},
  urldate = {2024-11-17},
  abstract = {Recently, learned image compression has achieved impressive performance. The entropy model, which estimates the distribution of the latent representation, plays a crucial role in enhancing rate-distortion performance. However, existing global context modules rely on computationally intensive quadratic complexity computations to capture global correlations. This quadratic complexity imposes limitations on the potential of high-resolution image coding. Moreover, effectively capturing local, global, and channel-wise contexts with acceptable even linear complexity within a single entropy model remains a challenge. To address these limitations, we propose the Linear Complexity Multi-Reference Entropy Model (MEM++). MEM++ effectively captures the diverse range of correlations inherent in the latent representation. Specifically, the latent representation is first divided into multiple slices. When compressing a particular slice, the previously compressed slices serve as its channel-wise contexts. To capture local contexts without sacrificing performance, we introduce a novel checkerboard attention module. Additionally, to capture global contexts, we propose the linear complexity attention-based global correlations capturing by leveraging the decomposition of the softmax operation. The attention map of the previously decoded slice is implicitly computed and employed to predict global correlations in the current slice. Based on MEM++, we propose image compression model MLIC++. Extensive experimental evaluations demonstrate that our MLIC++ achieves state-of-the-art performance, reducing BD-rate by 13.39\% on the Kodak dataset compared to VTM-17.0 in PSNR. Furthermore, MLIC++ exhibits linear GPU memory consumption with resolution, making it highly suitable for high-resolution image coding. Code and pre-trained models are available at https://github.com/JiangWeibeta/MLIC.},
  pubstate = {prepublished},
  version = {9},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\MLIC++_Jiang_et_al_2024.pdf}
}

@online{jiangMLICMultiReferenceEntropy2024,
  title = {{{MLIC}}: {{Multi-Reference Entropy Model}} for {{Learned Image Compression}}},
  shorttitle = {{{MLIC}}},
  author = {Jiang, Wei and Yang, Jiayu and Zhai, Yongqi and Ning, Peirong and Gao, Feng and Wang, Ronggang},
  date = {2024-01-16},
  eprint = {2211.07273},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2211.07273},
  urldate = {2024-11-17},
  abstract = {Recently, learned image compression has achieved remarkable performance. The entropy model, which estimates the distribution of the latent representation, plays a crucial role in boosting rate-distortion performance. However, most entropy models only capture correlations in one dimension, while the latent representation contain channel-wise, local spatial, and global spatial correlations. To tackle this issue, we propose the Multi-Reference Entropy Model (MEM) and the advanced version, MEM\$\textasciicircum +\$. These models capture the different types of correlations present in latent representation. Specifically, We first divide the latent representation into slices. When decoding the current slice, we use previously decoded slices as context and employ the attention map of the previously decoded slice to predict global correlations in the current slice. To capture local contexts, we introduce two enhanced checkerboard context capturing techniques that avoids performance degradation. Based on MEM and MEM\$\textasciicircum +\$, we propose image compression models MLIC and MLIC\$\textasciicircum +\$. Extensive experimental evaluations demonstrate that our MLIC and MLIC\$\textasciicircum +\$ models achieve state-of-the-art performance, reducing BD-rate by \$8.05\textbackslash\%\$ and \$11.39\textbackslash\%\$ on the Kodak dataset compared to VTM-17.0 when measured in PSNR. Our code is available at https://github.com/JiangWeibeta/MLIC.},
  pubstate = {prepublished},
  version = {9},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\MLIC_Jiang_et_al_2024.pdf}
}

@inproceedings{jiangNeuralImageCompression2024,
  title = {Neural {{Image Compression Using Masked Sparse Visual Representation}}},
  author = {Jiang, Wei and Wang, Wei and Chen, Yue},
  date = {2024},
  pages = {4189--4197},
  url = {https://openaccess.thecvf.com/content/WACV2024/html/Jiang_Neural_Image_Compression_Using_Masked_Sparse_Visual_Representation_WACV_2024_paper.html},
  urldate = {2024-12-23},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Neural_Image_Compression_Jiang_et_al_2024.pdf}
}

@online{jinPyramidalFlowMatching2024,
  title = {Pyramidal {{Flow Matching}} for {{Efficient Video Generative Modeling}}},
  author = {Jin, Yang and Sun, Zhicheng and Li, Ningyuan and Xu, Kun and Xu, Kun and Jiang, Hao and Zhuang, Nan and Huang, Quzhe and Song, Yang and Mu, Yadong and Lin, Zhouchen},
  date = {2024-10-08},
  eprint = {2410.05954},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2410.05954},
  url = {http://arxiv.org/abs/2410.05954},
  urldate = {2024-10-23},
  abstract = {Video generation requires modeling a vast spatiotemporal space, which demands significant computational resources and data usage. To reduce the complexity, the prevailing approaches employ a cascaded architecture to avoid direct training with full resolution. Despite reducing computational demands, the separate optimization of each sub-stage hinders knowledge sharing and sacrifices flexibility. This work introduces a unified pyramidal flow matching algorithm. It reinterprets the original denoising trajectory as a series of pyramid stages, where only the final stage operates at the full resolution, thereby enabling more efficient video generative modeling. Through our sophisticated design, the flows of different pyramid stages can be interlinked to maintain continuity. Moreover, we craft autoregressive video generation with a temporal pyramid to compress the full-resolution history. The entire framework can be optimized in an end-to-end manner and with a single unified Diffusion Transformer (DiT). Extensive experiments demonstrate that our method supports generating high-quality 5-second (up to 10-second) videos at 768p resolution and 24 FPS within 20.7k A100 GPU training hours. All code and models will be open-sourced at https://pyramid-flow.github.io.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoModels\Pyramidal_Flow_Matching_for_Jin_et_al_2024.pdf}
}

@article{jinReconstructionAlgorithmElectrical2012,
  title = {A Reconstruction Algorithm for Electrical Impedance Tomography Based on Sparsity Regularization},
  author = {Jin, Bangti and Khan, Taufiquar and Maass, Peter},
  date = {2012-01-20},
  journaltitle = {Numerical Meth Engineering},
  volume = {89},
  number = {3},
  pages = {337--353},
  issn = {0029-5981, 1097-0207},
  doi = {10.1002/nme.3247},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/nme.3247},
  urldate = {2024-07-05},
  abstract = {This paper develops a novel sparse reconstruction algorithm for the electrical impedance tomography problem of determining a conductivity parameter from boundary measurements. The sparsity of the ‘inhomogeneity’ with respect to a certain basis is a priori assumed. The proposed approach is motivated by a Tikhonov functional incorporating a sparsity-promoting `1-penalty term, and it allows us to obtain quantitative results when the assumption is valid. A novel iterative algorithm of soft shrinkage type was proposed. Numerical results for several two-dimensional problems with both single and multiple convex and nonconvex inclusions were presented to illustrate the features of the proposed algorithm and were compared with one conventional approach based on smoothness regularization. Copyright © 2011 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Sparsity\A_reconstruction_algorithm_for_electrical_impedance_tomography_based_on_Jin_et_al_2012.pdf}
}

@inproceedings{joCGNeRFConditionalGenerative2023,
  title = {{{CG-NeRF}}: {{Conditional Generative Neural Radiance Fields}} for {{3D-aware Image Synthesis}}},
  shorttitle = {{{CG-NeRF}}},
  booktitle = {2023 {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  author = {Jo, Kyungmin and Shim, Gyumin and Jung, Sanghun and Yang, Soyoung and Choo, Jaegul},
  date = {2023-01},
  pages = {724--733},
  publisher = {IEEE},
  location = {Waikoloa, HI, USA},
  doi = {10.1109/WACV56688.2023.00079},
  url = {https://ieeexplore.ieee.org/document/10030346/},
  urldate = {2023-09-26},
  eventtitle = {2023 {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  isbn = {978-1-66549-346-8},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\CG-NeRF_Jo_et_al_2023.pdf}
}

@article{johnStrongLocalizationPhotons1987,
  title = {Strong Localization of Photons in Certain Disordered Dielectric Superlattices},
  author = {John, Sajeev},
  date = {1987-06-08},
  journaltitle = {Phys. Rev. Lett.},
  volume = {58},
  number = {23},
  pages = {2486--2489},
  issn = {0031-9007},
  doi = {10.1103/PhysRevLett.58.2486},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.58.2486},
  urldate = {2024-06-01},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Dielectric\Strong_localization_of_photons_in_certain_disordered_dielectric_superlattices_John_1987.pdf}
}

@incollection{jun-seongHDRPlenoxelsSelfCalibratingHigh2022,
  title = {{{HDR-Plenoxels}}: {{Self-Calibrating High Dynamic Range Radiance Fields}}},
  shorttitle = {{{HDR-Plenoxels}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2022},
  author = {Jun-Seong, Kim and Yu-Ji, Kim and Ye-Bin, Moon and Oh, Tae-Hyun},
  editor = {Avidan, Shai and Brostow, Gabriel and Cissé, Moustapha and Farinella, Giovanni Maria and Hassner, Tal},
  date = {2022},
  volume = {13692},
  pages = {384--401},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-19824-3_23},
  url = {https://link.springer.com/10.1007/978-3-031-19824-3_23},
  urldate = {2023-09-01},
  abstract = {We propose high dynamic range radiance (HDR) fields, HDRPlenoxels, that learns a plenoptic function of 3D HDR radiance fields, geometry information, and varying camera settings inherent in 2D low dynamic range (LDR) images. Our voxel-based volume rendering pipeline reconstructs HDR radiance fields with only multi-view LDR images taken from varying camera settings in an end-to-end manner and has a fast convergence speed. To deal with various cameras in real-world scenario, we introduce a tone mapping module that models the digital in-camera imaging pipeline (ISP) and disentangles radiometric settings. Our tone mapping module allows us to render by controlling the radiometric settings of each novel view. Finally, we build a multi-view dataset with varying camera conditions, which fits our problem setting. Our experiments show that HDR-Plenoxels can express detail and high-quality HDR novel views from only LDR images with various cameras.},
  isbn = {978-3-031-19823-6 978-3-031-19824-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\HDR\HDR-Plenoxels_Jun-Seong_et_al_2022.pdf}
}

@online{junShapEGeneratingConditional2023,
  title = {Shap-{{E}}: {{Generating Conditional 3D Implicit Functions}}},
  shorttitle = {Shap-{{E}}},
  author = {Jun, Heewoo and Nichol, Alex},
  date = {2023-05-03},
  eprint = {2305.02463},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.02463},
  urldate = {2023-09-26},
  abstract = {We present Shap-E, a conditional generative model for 3D assets. Unlike recent work on 3D generative models which produce a single output representation, Shap-E directly generates the parameters of implicit functions that can be rendered as both textured meshes and neural radiance fields. We train Shap-E in two stages: first, we train an encoder that deterministically maps 3D assets into the parameters of an implicit function; second, we train a conditional diffusion model on outputs of the encoder. When trained on a large dataset of paired 3D and text data, our resulting models are capable of generating complex and diverse 3D assets in a matter of seconds. When compared to Point-E, an explicit generative model over point clouds, Shap-E converges faster and reaches comparable or better sample quality despite modeling a higher-dimensional, multi-representation output space. We release model weights, inference code, and samples at https://github.com/openai/shap-e.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\Shap-E_Jun_Nichol_2023.pdf}
}

@article{kaliteevskiBraggReflectorsCylindrical1999,
  title = {Bragg Reflectors for Cylindrical Waves},
  author = {Kaliteevski, M. A. and Abram, R. A. and Nikolaev, V. V. and Sokolovski, G. S.},
  date = {1999-04},
  journaltitle = {Journal of Modern Optics},
  volume = {46},
  number = {5},
  pages = {875--890},
  issn = {0950-0340, 1362-3044},
  doi = {10.1080/09500349908231310},
  url = {http://www.tandfonline.com/doi/abs/10.1080/09500349908231310},
  urldate = {2023-11-06},
  abstract = {A transfer matrix method is developed to calculate the electromagnetic field in a dielectric structure with circular cylindrical symmetry. The equations for the reflection and transmission coefficients of cylindrical waves from a single cylindrical boundary between two dielectrics and from a cylindrical multilayered structure are obtained. For a single dielectric interface, enhanced reflection at small interface radii and the analogue of the Brewster effect are predicted and investigated. The design of an optimized cylindrical Bragg reflector (CBR) for cylindrical waves is proposed and its optical properties are studied. I t is found that the thicknesses of the layers in the CBR must be different, to provide the adjustment of the phase of the waves, that are reflected from the interfaces at different radii.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Bragg_reflectors_for_cylindrical_waves_Kaliteevski_et_al_1999.pdf}
}

@article{kangAdjointMethodMachine2024,
  title = {Adjoint Method in Machine Learning: {{A}} Pathway to Efficient Inverse Design of Photonic Devices},
  shorttitle = {Adjoint Method in Machine Learning},
  author = {Kang, Chanik and Seo, Dongjin and Boriskina, Svetlana V. and Chung, Haejun},
  date = {2024-03-01},
  journaltitle = {Materials \& Design},
  volume = {239},
  pages = {112737},
  issn = {0264-1275},
  doi = {10.1016/j.matdes.2024.112737},
  url = {https://www.sciencedirect.com/science/article/pii/S0264127524001096},
  urldate = {2024-05-31},
  abstract = {Innovative machine learning techniques have facilitated the inverse design of photonic structures for numerous practical applications. Nevertheless, the quantity of data and the initial data distribution are paramount for the discovery of highly efficient photonic devices. These devices often require simulated data ranging from thousands to several hundred thousand data points. This issue has consistently posed a major hurdle in machine learning-based photonic design problems. Therefore, we propose a new data augmentation algorithm grounded in the adjoint method, capable of generating more than 300 times the amount of original data while enhancing device efficiency. The adjoint method forecasts changes in the figure of merit (FoM) resulting from structural perturbations, requiring only two full-wave Maxwell simulations for this prediction. By leveraging the adjoint gradient values, we can augment and label several thousand new data points without any additional computations. Furthermore, the augmented data generated by the proposed algorithm displays significantly improved FoMs. We apply this algorithm to a multi-layered metalens design problem and demonstrate that it consequently exhibits a 343-fold increase in data generation efficiency. After incorporating the proposed algorithm into a generative adversarial network, the optimized metalens exhibits a maximum focusing efficiency of 92.93\%, comparable to the theoretical upper bound.},
  keywords = {Adjoint variable method,Deep learning,Generative adversarial networks,Inverse design,Photonics,Topology optimization},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\Adjoint_method_in_machine_Kang_et_al_2024.pdf}
}

@inproceedings{katsikasInverseDesignTwodimensional2024,
  title = {Inverse Design of Two-Dimensional Photonic Crystals through Physics-Informed Deep Learning},
  booktitle = {Photonic and {{Phononic Properties}} of {{Engineered Nanostructures XIV}}},
  author = {Katsikas, Georgios and Peano, Vittorio and Marquardt, Florian and Verhagen, Ewold},
  date = {2024-03-13},
  volume = {PC12896},
  pages = {PC128960M},
  publisher = {SPIE},
  doi = {10.1117/12.3000747},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/PC12896/PC128960M/Inverse-design-of-two-dimensional-photonic-crystals-through-physics-informed/10.1117/12.3000747.full},
  urldate = {2024-12-15},
  abstract = {We study the use of deep neural networks towards the prediction of the optical properties of two-dimensional photonic crystals, as well as their inverse design. We incorporate a rigorous tight-binding model as a known operator in the machine learning algorithm. This physics-informed approach allows the prediction of meaningful model parameters rather than the high-dimensional full response, allowing for an efficient method as well as potential insight in the physical workings of specific designs. We demonstrate a four-order-of-magnitude speedup of prediction of bandstructures and field symmetries over full-field calculations, and proof-of-concept inverse design of photonic crystals with large gaps, flat bands, and Dirac-point degeneracies.},
  eventtitle = {Photonic and {{Phononic Properties}} of {{Engineered Nanostructures XIV}}}
}

@incollection{katsupeevSoftwareDevelopmentPrototype2021,
  title = {Software {{Development}} for the {{Prototype}} of the {{Electrical Impedance Tomography Module}} in {{C}}++},
  booktitle = {Inventive {{Computation}} and {{Information Technologies}}},
  author = {Katsupeev, A. A. and Aleksanyan, G. K. and Gorbatenko, N. I. and Litvyak, R. K. and Kombarova, E. O.},
  editor = {Smys, S. and Balas, Valentina Emilia and Kamel, Khaled A. and Lafata, Pavel},
  date = {2021},
  volume = {173},
  pages = {729--737},
  publisher = {Springer Nature Singapore},
  location = {Singapore},
  doi = {10.1007/978-981-33-4305-4_53},
  url = {https://link.springer.com/10.1007/978-981-33-4305-4_53},
  urldate = {2024-07-08},
  abstract = {The basic principles and features of the implementation of the electrical impedance tomography (EIT) method in the C++ language are proposed in this research. This software will significantly reduce the hardware time for performing of computational operations and will expand the capabilities of the technical implementation of the EIT method in real technical systems of medical imaging. An algorithm for the operation of the EIT module prototype software in C++ has been developed. The principles of building the software for the EIT module prototype have been developed, which provides the possibility of embedding into other medical equipment. The software interface of the EIT module prototype has been developed.},
  isbn = {978-981-334-304-7 978-981-334-305-4},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\OtherFrameworks\C_plus_plus\Software_Development_for_the_Prototype_of_the_Electrical_Impedance_Tomography_Katsupeev_et_al_2021.pdf}
}

@article{keAdvancesElectricalImpedance2022,
  title = {Advances in Electrical Impedance Tomography-Based Brain Imaging},
  author = {Ke, Xi-Yang and Hou, Wei and Huang, Qi and Hou, Xue and Bao, Xue-Ying and Kong, Wei-Xuan and Li, Cheng-Xiang and Qiu, Yu-Qi and Hu, Si-Yi and Dong, Li-Hua},
  date = {2022-12},
  journaltitle = {Military Med Res},
  volume = {9},
  number = {1},
  pages = {10},
  issn = {2054-9369},
  doi = {10.1186/s40779-022-00370-7},
  url = {https://mmrjournal.biomedcentral.com/articles/10.1186/s40779-022-00370-7},
  urldate = {2024-07-08},
  abstract = {Novel advances in the field of brain imaging have enabled the unprecedented clinical application of various imag‑ing modalities to facilitate disease diagnosis and treatment. Electrical impedance tomography (EIT) is a functional imaging technique that measures the transfer impedances between electrodes on the body surface to estimate the spatial distribution of electrical properties of tissues. EIT offers many advantages over other neuroimaging technolo‑gies, which has led to its potential clinical use. This qualitative review provides an overview of the basic principles, algorithms, and system composition of EIT. Recent advances in the field of EIT are discussed in the context of epilepsy, stroke, brain injuries and edema, and other brain diseases. Further, we summarize factors limiting the development of brain EIT and highlight prospects for the field. In epilepsy imaging, there have been advances in EIT imaging depth, from cortical to subcortical regions. In stroke research, a bedside EIT stroke monitoring system has been developed for clinical practice, and data support the role of EIT in multi-modal imaging for diagnosing stroke. Additionally, EIT has been applied to monitor the changes in brain water content associated with cerebral edema, enabling the early identification of brain edema and the evaluation of mannitol dehydration. However, anatomically realistic geometry, inhomogeneity, cranium completeness, anisotropy and skull type, etc., must be considered to improve the accuracy of EIT modeling. Thus, the further establishment of EIT as a mature and routine diagnostic technique will necessitate the accumulation of more supporting evidence.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Brain\Advances_in_electrical_impedance_tomography-based_brain_imaging_Ke_et_al_2022.pdf}
}

@article{keeTunableResonantTransmission2003,
  title = {Tunable Resonant Transmission of Electromagnetic Waves through a Magnetized Plasma},
  author = {Kee, Chul-Sik and Li, Shou-Zhe and Kim, Kihong and Lim, H.},
  date = {2003-03-21},
  journaltitle = {Phys. Rev. E},
  volume = {67},
  number = {3},
  pages = {036612},
  issn = {1063-651X, 1095-3787},
  doi = {10.1103/PhysRevE.67.036612},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.67.036612},
  urldate = {2024-01-22},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Tunable_resonant_transmission_of_electromagnetic_waves_through_a_magnetized_Kee_et_al_2003.pdf}
}

@article{kerbl3DGaussianSplatting2023,
  title = {{{3D Gaussian Splatting}} for {{Real-Time Radiance Field Rendering}}},
  author = {Kerbl, Bernhard and Kopanas, Georgios and Leimkuehler, Thomas and Drettakis, George},
  date = {2023-08},
  journaltitle = {ACM Trans. Graph.},
  volume = {42},
  number = {4},
  pages = {1--14},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3592433},
  url = {https://dl.acm.org/doi/10.1145/3592433},
  urldate = {2023-08-01},
  abstract = {Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates. We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (≥ 30 fps) novel-view synthesis at 1080p resolution. First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\General\3D_Gaussian_Splatting_for_Real-Time_Radiance_Field_Rendering_Kerbl_et_al_2023.pdf}
}

@online{kerblHierarchical3DGaussian2024,
  title = {A {{Hierarchical 3D Gaussian Representation}} for {{Real-Time Rendering}} of {{Very Large Datasets}}},
  author = {Kerbl, Bernhard and Meuleman, Andréas and Kopanas, Georgios and Wimmer, Michael and Lanvin, Alexandre and Drettakis, George},
  date = {2024-06-17},
  eprint = {2406.12080},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2406.12080},
  urldate = {2024-08-05},
  abstract = {Novel view synthesis has seen major advances in recent years, with 3D Gaussian splatting offering an excellent level of visual quality, fast training and real-time rendering. However, the resources needed for training and rendering inevitably limit the size of the captured scenes that can be represented with good visual quality. We introduce a hierarchy of 3D Gaussians that preserves visual quality for very large scenes, while offering an efficient Level-of-Detail (LOD) solution for efficient rendering of distant content with effective level selection and smooth transitions between levels.We introduce a divide-and-conquer approach that allows us to train very large scenes in independent chunks. We consolidate the chunks into a hierarchy that can be optimized to further improve visual quality of Gaussians merged into intermediate nodes. Very large captures typically have sparse coverage of the scene, presenting many challenges to the original 3D Gaussian splatting training method; we adapt and regularize training to account for these issues. We present a complete solution, that enables real-time rendering of very large scenes and can adapt to available resources thanks to our LOD method. We show results for captured scenes with up to tens of thousands of images with a simple and affordable rig, covering trajectories of up to several kilometers and lasting up to one hour. Project Page: https://repo-sam.inria.fr/fungraph/hierarchical-3d-gaussians/},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\AccelerateNerf\A_Hierarchical_3D_Gaussian_Kerbl_et_al_2024.pdf}
}

@online{kerblHierarchical3DGaussian2024a,
  title = {A {{Hierarchical 3D Gaussian Representation}} for {{Real-Time Rendering}} of {{Very Large Datasets}}},
  author = {Kerbl, Bernhard and Meuleman, Andréas and Kopanas, Georgios and Wimmer, Michael and Lanvin, Alexandre and Drettakis, George},
  date = {2024-06-17},
  eprint = {2406.12080},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.12080},
  url = {http://arxiv.org/abs/2406.12080},
  urldate = {2024-08-05},
  abstract = {Novel view synthesis has seen major advances in recent years, with 3D Gaussian splatting offering an excellent level of visual quality, fast training and real-time rendering. However, the resources needed for training and rendering inevitably limit the size of the captured scenes that can be represented with good visual quality. We introduce a hierarchy of 3D Gaussians that preserves visual quality for very large scenes, while offering an efficient Level-of-Detail (LOD) solution for efficient rendering of distant content with effective level selection and smooth transitions between levels.We introduce a divide-and-conquer approach that allows us to train very large scenes in independent chunks. We consolidate the chunks into a hierarchy that can be optimized to further improve visual quality of Gaussians merged into intermediate nodes. Very large captures typically have sparse coverage of the scene, presenting many challenges to the original 3D Gaussian splatting training method; we adapt and regularize training to account for these issues. We present a complete solution, that enables real-time rendering of very large scenes and can adapt to available resources thanks to our LOD method. We show results for captured scenes with up to tens of thousands of images with a simple and affordable rig, covering trajectories of up to several kilometers and lasting up to one hour. Project Page: https://repo-sam.inria.fr/fungraph/hierarchical-3d-gaussians/},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\Zotero\storage\WAP4BVBL\Kerbl et al. - 2024 - A Hierarchical 3D Gaussian Representation for Real.pdf}
}

@article{kerdranvatVIDEOCODECLANDSCAPE2020,
  title = {{{THE VIDEO CODEC LANDSCAPE IN}} 2020},
  author = {Kerdranvat, Michel},
  date = {2020},
  volume = {3},
  abstract = {Video compression is a key technology for new immersive media experiences, as the percentage of video data in global Internet traffic (80\% in 2019 according to the 2018 Cisco Visual Networking Index report) is steadily increasing. The requirement for higher video compression efficiency is crucial in this context. For several years intense activity has been observed in standards organizations such as ITU-T VCEG and ISO/IEC MPEG developing Versatile Video Coding (VVC) and Essential Video Coding (EVC), but also in the ICT industry with AV1. This paper provides an analysis of the coding tools of VVC and EVC, stable since January 2020, and of AV1 stable since 2018. The quality and benefits of each solution are discussed from an analysis of their respective coding tools, measured compression efficiency, complexity, and market deployment perspectives. This analysis places VVC ahead of its competitors. As a matter of fact, VVC has been designed by the largest community of video compression experts, that is JVET (Joint Video Experts Team between ITU-T and ISO/IEC). It has been built on the basis of High Efficiency Video Coding (H.265/HEVC) and Advanced Video Coding (H.264/AVC) also developed by joint teams, respectively JCT-VC and JVT, and issued in 2013 and 2003 respectively.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataCompression\VideoCompression\General\THE_VIDEO_CODEC_LANDSCAPE_IN_2020_Kerdranvat_2020.pdf}
}

@article{kerkerScatteringElectromagneticWaves1961,
  title = {Scattering of {{Electromagnetic Waves}} from {{Concentric Infinite Cylinders}}*},
  author = {Kerker, M. and Matijević, E.},
  date = {1961-05-01},
  journaltitle = {J. Opt. Soc. Am.},
  volume = {51},
  number = {5},
  pages = {506},
  issn = {0030-3941},
  doi = {10.1364/JOSA.51.000506},
  url = {https://opg.optica.org/abstract.cfm?URI=josa-51-5-506},
  urldate = {2023-11-06},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Scattering_of_Electromagnetic_Waves_from_Concentric_Infinite_Cylinders_Kerker_Matijevic_1961.pdf}
}

@article{khaireh-waliehNewcomerGuideDeep2023,
  title = {A Newcomer’s Guide to Deep Learning for Inverse Design in Nano-Photonics},
  author = {Khaireh-Walieh, Abdourahman and Langevin, Denis and Bennet, Pauline and Teytaud, Olivier and Moreau, Antoine and Wiecha, Peter R.},
  date = {2023-12-01},
  journaltitle = {Nanophotonics},
  volume = {12},
  number = {24},
  pages = {4387--4414},
  publisher = {De Gruyter},
  issn = {2192-8614},
  doi = {10.1515/nanoph-2023-0527},
  url = {https://www.degruyter.com/document/doi/10.1515/nanoph-2023-0527/html},
  urldate = {2024-06-01},
  abstract = {Nanophotonic devices manipulate light at sub-wavelength scales, enabling tasks such as light concentration, routing, and filtering. Designing these devices to achieve precise light–matter interactions using structural parameters and materials is a challenging task. Traditionally, solving this problem has relied on computationally expensive, iterative methods. In recent years, deep learning techniques have emerged as promising tools for tackling the inverse design of nanophotonic devices. While several review articles have provided an overview of the progress in this rapidly evolving field, there is a need for a comprehensive tutorial that specifically targets newcomers without prior experience in deep learning. Our goal is to address this gap and provide practical guidance for applying deep learning to individual scientific problems. We introduce the fundamental concepts of deep learning and critically discuss the potential benefits it offers for various inverse design problems in nanophotonics. We present a suggested workflow and detailed, practical design guidelines to help newcomers navigate the challenges they may encounter. By following our guide, newcomers can avoid frustrating roadblocks commonly experienced when venturing into deep learning for the first time. In a second part, we explore different iterative and direct deep learning-based techniques for inverse design, and evaluate their respective advantages and limitations. To enhance understanding and facilitate implementation, we supplement the manuscript with detailed Python notebook examples, illustrating each step of the discussed processes. While our tutorial primarily focuses on researchers in (nano-)photonics, it is also relevant for those working with deep learning in other research domains. We aim at providing a solid starting point to empower researchers to leverage the potential of deep learning in their scientific pursuits.},
  langid = {english},
  keywords = {deep learning,inverse design,inverse problems,nano-optics,tutorial},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\A_newcomer’s_guide_to_deep_Khaireh-Walieh_et_al_2023.pdf}
}

@article{khanReviewElectricalImpedance2019,
  title = {Review on {{Electrical Impedance Tomography}}: {{Artificial Intelligence Methods}} and Its {{Applications}}},
  shorttitle = {Review on {{Electrical Impedance Tomography}}},
  author = {Khan, Talha Ali and Ling, Sai Ho},
  date = {2019-04-26},
  journaltitle = {Algorithms},
  volume = {12},
  number = {5},
  pages = {88},
  issn = {1999-4893},
  doi = {10.3390/a12050088},
  url = {https://www.mdpi.com/1999-4893/12/5/88},
  urldate = {2024-07-03},
  abstract = {Electrical impedance tomography (EIT) has been a hot topic among researchers for the last 30 years. It is a new imaging method and has evolved over the last few decades. By injecting a small amount of current, the electrical properties of tissues are determined and measurements of the resulting voltages are taken. By using a reconstructing algorithm these voltages then transformed into a tomographic image. EIT contains no identified threats and as compared to magnetic resonance imaging (MRI) and computed tomography (CT) scans (imaging techniques), it is cheaper in cost as well. In this paper, a comprehensive review of efforts and advancements undertaken and achieved in recent work to improve this technology and the role of artificial intelligence to solve this non-linear, ill-posed problem are presented. In addition, a review of EIT clinical based applications has also been presented.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Review\Review_on_Electrical_Impedance_Tomography_Khan_Ling_2019.pdf}
}

@online{kim3DawareBlendingGenerative2023,
  title = {{{3D-aware Blending}} with {{Generative NeRFs}}},
  author = {Kim, Hyunsu and Lee, Gayoung and Choi, Yunjey and Kim, Jin-Hwa and Zhu, Jun-Yan},
  date = {2023-08-16},
  eprint = {2302.06608},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.06608},
  urldate = {2023-09-26},
  abstract = {Image blending aims to combine multiple images seamlessly. It remains challenging for existing 2D-based methods, especially when input images are misaligned due to differences in 3D camera poses and object shapes. To tackle these issues, we propose a 3D-aware blending method using generative Neural Radiance Fields (NeRF), including two key components: 3D-aware alignment and 3D-aware blending. For 3D-aware alignment, we first estimate the camera pose of the reference image with respect to generative NeRFs and then perform 3D local alignment for each part. To further leverage 3D information of the generative NeRF, we propose 3D-aware blending that directly blends images on the NeRF's latent representation space, rather than raw pixel space. Collectively, our method outperforms existing 2D baselines, as validated by extensive quantitative and qualitative evaluations with FFHQ and AFHQ-Cat.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\3D-aware_Blending_with_Generative_NeRFs_Kim_et_al_2023.pdf}
}

@article{kimAirlikePlasmonicsUltralowrefractiveindex2019,
  title = {Air-like Plasmonics with Ultralow-Refractive-Index Silica Aerogels},
  author = {Kim, Yeonhong and Baek, Seunghwa and Gupta, Prince and Kim, Changwook and Chang, Kiseok and Ryu, Sung-Pil and Kang, Hansaem and Kim, Wook Sung and Myoung, Jaemin and Park, Wounjhang and Kim, Kyoungsik},
  date = {2019-02-19},
  journaltitle = {Sci Rep},
  volume = {9},
  number = {1},
  pages = {2265},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-38859-2},
  url = {https://www.nature.com/articles/s41598-019-38859-2},
  urldate = {2023-09-05},
  abstract = {Abstract                            The coupling of the surface plasmon near-field into the sensing medium is key to the sensitivity of surface plasmon-based sensing devices. A low-index dielectric is necessary for the sensing medium to support a highly-penetrating surface plasmon evanescent field that extends well into the dielectric medium. The air-like refractive index,               n               , of an aerogel substrate provides another dimension for ultralow-index plasmonic devices. In this paper, we experimentally observed an angular surface plasmon resonance dip at 74° with the ultralow-index aerogel substrate, as was expected from theory. We also demonstrated the comparatively high-sensitivity surface plasmon resonance wavelength,               λ               , while the change in Δ               λ               /Δ               n               with different substrates was studied in detail. A 740 nm-period metal grating was imprinted on aerogel (               n               \,=\,1.08) and polydimethylsiloxane (PDMS;               n               \,=\,1.4) substrates. The ultraviolet–visible–near-infrared spectra were observed in the reflection mode on the grating, resulting in sensitivities of 740.2 and 655.9\,nm/RIU for the aerogel and PDMS substrates, respectively. Numerical simulations were performed to understand the near-field of the surface plasmon, which demonstrated resonances well correlated with the experimentally observed results. The near-field due to excitation of the surface plasmon polaritons is observed to be more confined and to penetrate deeper into the sensing medium when a low-index substrate is used.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Aerogel\Air-like_plasmonics_with_ultralow-refractive-index_silica_aerogels_Kim_et_al_2019.pdf}
}

@online{kimAttentiveNeuralProcesses2019,
  title = {Attentive {{Neural Processes}}},
  author = {Kim, Hyunjik and Mnih, Andriy and Schwarz, Jonathan and Garnelo, Marta and Eslami, Ali and Rosenbaum, Dan and Vinyals, Oriol and Teh, Yee Whye},
  date = {2019-07-09},
  eprint = {1901.05761},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.1901.05761},
  url = {http://arxiv.org/abs/1901.05761},
  urldate = {2024-12-02},
  abstract = {Neural Processes (NPs) (Garnelo et al 2018a;b) approach regression by learning to map a context set of observed input-output pairs to a distribution over regression functions. Each function models the distribution of the output given an input, conditioned on the context. NPs have the benefit of fitting observed data efficiently with linear complexity in the number of context input-output pairs, and can learn a wide family of conditional distributions; they learn predictive distributions conditioned on context sets of arbitrary size. Nonetheless, we show that NPs suffer a fundamental drawback of underfitting, giving inaccurate predictions at the inputs of the observed data they condition on. We address this issue by incorporating attention into NPs, allowing each input location to attend to the relevant context points for the prediction. We show that this greatly improves the accuracy of predictions, results in noticeably faster training, and expands the range of functions that can be modelled.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Quantization\Compression\Attentive_Neural_Processes_Kim_et_al_2019.pdf}
}

@online{kimBKSDMLightweightFast2023,
  title = {{{BK-SDM}}: {{A Lightweight}}, {{Fast}}, and {{Cheap Version}} of {{Stable Diffusion}}},
  shorttitle = {{{BK-SDM}}},
  author = {Kim, Bo-Kyeong and Song, Hyoung-Kyu and Castells, Thibault and Choi, Shinkook},
  date = {2023-11-16},
  eprint = {2305.15798},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2305.15798},
  url = {http://arxiv.org/abs/2305.15798},
  urldate = {2024-10-23},
  abstract = {Text-to-image (T2I) generation with Stable Diffusion models (SDMs) involves high computing demands due to billion-scale parameters. To enhance efficiency, recent studies have reduced sampling steps and applied network quantization while retaining the original architectures. The lack of architectural reduction attempts may stem from worries over expensive retraining for such massive models. In this work, we uncover the surprising potential of block pruning and feature distillation for low-cost general-purpose T2I. By removing several residual and attention blocks from the U-Net of SDMs, we achieve 30\%\textasciitilde 50\% reduction in model size, MACs, and latency. We show that distillation retraining is effective even under limited resources: using only 13 A100 days and a tiny dataset, our compact models can imitate the original SDMs (v1.4 and v2.1-base with over 6,000 A100 days). Benefiting from the transferred knowledge, our BK-SDMs deliver competitive results on zero-shot MS-COCO against larger multi-billion parameter models. We further demonstrate the applicability of our lightweight backbones in personalized generation and image-to-image translation. Deployment of our models on edge devices attains 4-second inference. We hope this work can help build small yet powerful diffusion models with feasible training budgets. Code and models can be found at: https://github.com/Nota-NetsPresso/BK-SDM},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\DiffusionModels\BK-SDM_Kim_et_al_2023.pdf}
}

@article{kimElectricalResistanceImaging2015,
  title = {Electrical Resistance Imaging of Two-Phase Flow Using Direct {{Landweber}} Method},
  author = {Kim, Bong Seok and Khambampati, Anil Kumar and Kim, Sin and Kim, Kyung Youn},
  date = {2015-03},
  journaltitle = {Flow Measurement and Instrumentation},
  volume = {41},
  pages = {41--49},
  issn = {09555986},
  doi = {10.1016/j.flowmeasinst.2014.10.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0955598614001344},
  urldate = {2024-07-03},
  abstract = {In this paper, a direct Landweber method is proposed to estimate on-line resistivity distribution of twophase flows using electrical resistance tomography. The proposed method is formulated such that the iterative Landweber method is modified for on-line computation and the resistivity distribution is estimated directly by multiplying the measured data with a weighting matrix that is computed off-line. Moreover, to improve the reconstruction performance, adaptive step-lengths for the proposed method are computed. Numerical simulations and phantom experiments have been carried out to evaluate the performance of the proposed method.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\LandweberMethod\Electrical_resistance_imaging_of_two-phase_flow_using_direct_Landweber_method_Kim_et_al_2015.pdf}
}

@article{kimElectricalResistanceImaging2015a,
  title = {Electrical Resistance Imaging of Two-Phase Flow Using Direct {{Landweber}} Method},
  author = {Kim, Bong Seok and Khambampati, Anil Kumar and Kim, Sin and Kim, Kyung Youn},
  date = {2015-03},
  journaltitle = {Flow Measurement and Instrumentation},
  volume = {41},
  pages = {41--49},
  issn = {09555986},
  doi = {10.1016/j.flowmeasinst.2014.10.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0955598614001344},
  urldate = {2024-07-08},
  abstract = {In this paper, a direct Landweber method is proposed to estimate on-line resistivity distribution of twophase flows using electrical resistance tomography. The proposed method is formulated such that the iterative Landweber method is modified for on-line computation and the resistivity distribution is estimated directly by multiplying the measured data with a weighting matrix that is computed off-line. Moreover, to improve the reconstruction performance, adaptive step-lengths for the proposed method are computed. Numerical simulations and phantom experiments have been carried out to evaluate the performance of the proposed method.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\LandweberMethod\Electrical_resistance_imaging_of_two-phase_flow_using_direct_Landweber_method_Kim_et_al_22.pdf}
}

@inproceedings{kimJointGlobalLocal2022,
  title = {Joint {{Global}} and {{Local Hierarchical Priors}} for {{Learned Image Compression}}},
  author = {Kim, Jun-Hyuk and Heo, Byeongho and Lee, Jong-Seok},
  date = {2022},
  pages = {5992--6001},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Kim_Joint_Global_and_Local_Hierarchical_Priors_for_Learned_Image_Compression_CVPR_2022_paper.html},
  urldate = {2024-11-25},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Joint_Global_and_Local_Kim_et_al_2022.pdf}
}

@article{kimLargescaleNanoporousMetalcoated2018,
  title = {Large-Scale Nanoporous Metal-Coated Silica Aerogels for High {{SERS}} Effect Improvement},
  author = {Kim, Changwook and Baek, Seunghwa and Ryu, Yunha and Kim, Yeonhong and Shin, Dongheok and Lee, Chang-Won and Park, Wounjhang and Urbas, Augustine M. and Kang, Gumin and Kim, Kyoungsik},
  date = {2018-10-11},
  journaltitle = {Sci Rep},
  volume = {8},
  number = {1},
  pages = {15144},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-33539-z},
  url = {https://www.nature.com/articles/s41598-018-33539-z},
  urldate = {2023-09-05},
  abstract = {Abstract                            We investigate the optical properties and surface-enhanced Raman scattering (SERS) characteristics of metal-coated silica aerogels. Silica aerogels were fabricated by easily scalable sol-gel and supercritical drying processes. Metallic nanogaps were formed on the top surface of the nanoporous silica network by controlling the thickness of the metal layer. The optimized metallic nanogap structure enabled strong confinement of light inside the gaps, which is a suitable property for SERS effect. We experimentally evaluated the SERS enhancement factor with the use of benzenethiol as a probe molecule. The enhancement factor reached 7.9\,×\,10               7               when molecules were adsorbed on the surface of the 30\,nm silver-coated aerogel. We also theoretically investigated the electric field distribution dependence on the structural geometry and substrate indices. On the basis of FDTD simulations, we concluded that the electric field was highly amplified in the vicinity of the target analyte owing to a combination of the aerogel’s ultralow refractive index and the high-density metallic nanogaps. The aerogel substrate with metallic nanogaps shows great potential for use as an inexpensive, highly sensitive SERS platform to detect environmental and biological target molecules.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Aerogel\Large-scale_nanoporous_metal-coated_silica_aerogels_for_high_SERS_effect_Kim_et_al_2018.pdf}
}

@inproceedings{kingmaAdamMethodStochastic2015,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}.},
  booktitle = {{{ICLR}} ({{Poster}})},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  editor = {Bengio, Yoshua and LeCun, Yann},
  date = {2015},
  url = {http://dblp.uni-trier.de/db/conf/iclr/iclr2015.html#KingmaB14},
  keywords = {final thema:attentionisallyouneed}
}

@online{kirillovSegmentAnything2023,
  title = {Segment {{Anything}}},
  author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
  date = {2023-04-05},
  eprint = {2304.02643},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.02643},
  urldate = {2023-11-14},
  abstract = {We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Segmentation\Segment_Anything_Kirillov_et_al_2023.pdf}
}

@book{kirschIntroductionMathematicalTheory2021,
  title = {An {{Introduction}} to the {{Mathematical Theory}} of {{Inverse Problems}}},
  author = {Kirsch, Andreas},
  date = {2021},
  series = {Applied {{Mathematical Sciences}}},
  volume = {120},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-63343-1},
  url = {http://link.springer.com/10.1007/978-3-030-63343-1},
  urldate = {2024-07-08},
  isbn = {978-3-030-63342-4 978-3-030-63343-1},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\General\An_Introduction_to_the_Mathematical_Theory_of_Inverse_Problems_Kirsch_2021.pdf}
}

@article{knightleyNeuralNetworkDesign2023,
  title = {Neural {{Network Design}} of {{Multilayer Metamaterial}} for {{Temporal Differentiation}}},
  author = {Knightley, Tony and Yakovlev, Alex and Pacheco-Peña, Victor},
  date = {2023},
  journaltitle = {Advanced Optical Materials},
  volume = {11},
  number = {5},
  pages = {2202351},
  issn = {2195-1071},
  doi = {10.1002/adom.202202351},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adom.202202351},
  urldate = {2024-06-01},
  abstract = {Controlling wave−matter interactions with metamaterials (MTMs) for the calculation of mathematical operations has become an important paradigm for analogue computing given their ability to dramatically increase computational processing speeds. Here, motivated by the importance of performing mathematical operations on temporal signals, multilayer MTMs with the ability to calculate the derivative of temporally modulated signals are proposed, designed, and studied. To do this, a neural network (NN) based algorithm is used to design the multilayer structures (alternating layers of indium tin oxide (ITO) and titanium dioxide (TiO2)) that can calculate the first temporal derivative of the envelope of an impinging electromagnetic signal modulated at telecom wavelengths (1550 nm). Different designs are presented using multiple incident temporal signals including a modulated Gaussian as well as modulated arbitrary functions, demonstrating an excellent agreement between the predicted results (NN results) and the theoretical (ideal) values. It is shown how the proposed NN-based algorithm can complete its search of the design space for the layer thicknesses of the multilayer MTM after just a few seconds, with a low mean square error in the order of (or below) 10−4 when comparing the predicted results with the theoretical spectrum of the ideal temporal derivative.},
  langid = {english},
  keywords = {analog computing,metamaterials,neural networks,temporal differentiation},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\OneDimension\Neural_Network_Design_of_Knightley_et_al_2023.pdf}
}

@article{kobyzevNormalizingFlowsIntroduction2021,
  title = {Normalizing {{Flows}}: {{An Introduction}} and {{Review}} of {{Current Methods}}},
  shorttitle = {Normalizing {{Flows}}},
  author = {Kobyzev, Ivan and Prince, Simon J.D. and Brubaker, Marcus A.},
  date = {2021-11-01},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {43},
  number = {11},
  pages = {3964--3979},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2020.2992934},
  url = {https://ieeexplore.ieee.org/document/9089305/},
  urldate = {2024-04-10},
  abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\NormalizingFlows\Normalizing_Flows_Kobyzev_et_al_2021.pdf}
}

@misc{kodakKodakLosslessTrue1993,
  title = {E. {{Kodak}} Lossless True Color Image Suite},
  author = {Kodak},
  date = {1993}
}

@article{koEnhancedBinaryMQ2021,
  title = {Enhanced {{Binary MQ Arithmetic Coder}} with {{Look-Up Table}}},
  author = {Ko, Hyung-Hwa},
  date = {2021-04},
  journaltitle = {Information},
  volume = {12},
  number = {4},
  pages = {143},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2078-2489},
  doi = {10.3390/info12040143},
  url = {https://www.mdpi.com/2078-2489/12/4/143},
  urldate = {2024-04-10},
  abstract = {Binary MQ arithmetic coding is widely used as a basic entropy coder in multimedia coding system. MQ coder esteems high in compression efficiency to be used in JBIG2 and JPEG2000. The importance of arithmetic coding is increasing after it is adopted as a unique entropy coder in HEVC standard. In the binary MQ coder, arithmetic approximation without multiplication is used in the process of recursive subdivision of range interval. Because of the MPS/LPS exchange activity that happens in the MQ coder, the output byte tends to increase. This paper proposes an enhanced binary MQ arithmetic coder to make use of look-up table (LUT) for (A × Qe) using quantization skill to improve the coding efficiency. Multi-level quantization using 2-level, 4-level and 8-level look-up tables is proposed in this paper. Experimental results applying to binary documents show about 3\% improvement for basic context-free binary arithmetic coding. In the case of JBIG2 bi-level image compression standard, compression efficiency improved about 0.9\%. In addition, in the case of lossless JPEG2000 compression, compressed byte decreases 1.5\% using 8-level LUT. For the lossy JPEG2000 coding, this figure is a little lower, about 0.3\% improvement of PSNR at the same rate.},
  issue = {4},
  langid = {english},
  keywords = {binary MQ arithmetic coder,JBIG2,JPEG2000,probability estimation lookup table},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataCompression\DataCompression\MQcoder\Enhanced_Binary_MQ_Arithmetic_Coder_with_Look-Up_Table_Ko_2021.pdf}
}

@article{kolehmainenElectricalImpedanceTomography2008,
  title = {Electrical {{Impedance Tomography Problem With Inaccurately Known Boundary}} and {{Contact Impedances}}},
  author = {Kolehmainen, V. and Lassas, M. and Ola, P.},
  date = {2008-10},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {27},
  number = {10},
  pages = {1404--1414},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2008.920600},
  url = {http://ieeexplore.ieee.org/document/4471919/},
  urldate = {2024-07-08},
  abstract = {In electrical impedance tomography (EIT) electric currents are injected into a body with unknown electromagnetic properties through a set of contact electrodes at the boundary of the body. The resulting voltages are measured on the same electrodes and the objective is to reconstruct the unknown conductivity function inside the body based on these data. All the traditional approaches to the reconstruction problem assume that the boundary of the body and the electrode-skin contact impedances are known a priori. However, in clinical experiments one usually lacks the exact knowledge of the boundary and contact impedances, and therefore, approximate model domain and contact impedances have to be used in the image reconstruction. However, it has been noticed that even small errors in the shape of the computation domain or contact impedances can cause large systematic artefacts in the reconstructed images, leading to loss of diagnostically relevant information. In a recent paper (Kolehmainen et al., 2006), we showed how in the 2-D case the errors induced by the inaccurately known boundary can be eliminated as part of the image reconstruction and introduced a novel method for finding a deformed image of the original isotropic conductivity using the theory of Teichmüller mappings. In this paper, the theory and reconstruction method are extended to include the estimation of unknown contact impedances. The method is implemented numerically and tested with experimental EIT data. The results show that the systematic errors caused by inaccurately known boundary and contact impedances can efficiently be eliminated by the reconstruction method.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\InaccuratelyKnownBoundary\Electrical_Impedance_Tomography_Problem_With_Inaccurately_Known_Boundary_and_Kolehmainen_et_al_2008.pdf}
}

@online{kondratyukVideoPoetLargeLanguage2024,
  title = {{{VideoPoet}}: {{A Large Language Model}} for {{Zero-Shot Video Generation}}},
  shorttitle = {{{VideoPoet}}},
  author = {Kondratyuk, Dan and Yu, Lijun and Gu, Xiuye and Lezama, José and Huang, Jonathan and Schindler, Grant and Hornung, Rachel and Birodkar, Vighnesh and Yan, Jimmy and Chiu, Ming-Chang and Somandepalli, Krishna and Akbari, Hassan and Alon, Yair and Cheng, Yong and Dillon, Josh and Gupta, Agrim and Hahn, Meera and Hauth, Anja and Hendon, David and Martinez, Alonso and Minnen, David and Sirotenko, Mikhail and Sohn, Kihyuk and Yang, Xuan and Adam, Hartwig and Yang, Ming-Hsuan and Essa, Irfan and Wang, Huisheng and Ross, David A. and Seybold, Bryan and Jiang, Lu},
  date = {2024-03-22},
  eprint = {2312.14125},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.14125},
  url = {http://arxiv.org/abs/2312.14125},
  urldate = {2024-04-13},
  abstract = {We present VideoPoet, a language model capable of synthesizing high-quality video, with matching audio, from a large variety of conditioning signals. VideoPoet employs a decoder-only transformer architecture that processes multimodal inputs -- including images, videos, text, and audio. The training protocol follows that of Large Language Models (LLMs), consisting of two stages: pretraining and task-specific adaptation. During pretraining, VideoPoet incorporates a mixture of multimodal generative objectives within an autoregressive Transformer framework. The pretrained LLM serves as a foundation that can be adapted for a range of video generation tasks. We present empirical results demonstrating the model's state-of-the-art capabilities in zero-shot video generation, specifically highlighting VideoPoet's ability to generate high-fidelity motions. Project page: http://sites.research.google/videopoet/},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/GenerativeAI/VideoModels/VideoPoet_Kondratyuk_et_al_2024.pdf}
}

@article{kongBioinspiredCoDesign2022,
  title = {Bioinspired {{Co}}‐{{Design}} of {{Tactile Sensor}} and {{Deep Learning Algorithm}} for {{Human}}–{{Robot Interaction}}},
  author = {Kong, Depeng and Yang, Geng and Pang, Gaoyang and Ye, Zhiqiu and Lv, Honghao and Yu, Zhangwei and Wang, Fei and Wang, Xi Vincent and Xu, Kaichen and Yang, Huayong},
  date = {2022-06},
  journaltitle = {Advanced Intelligent Systems},
  volume = {4},
  number = {6},
  pages = {2200050},
  issn = {2640-4567, 2640-4567},
  doi = {10.1002/aisy.202200050},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/aisy.202200050},
  urldate = {2024-07-08},
  abstract = {Robots equipped with bionic skins for enhancing the robot perception capability are increasingly deployed in wide applications ranging from healthcare to industry. Artificial intelligence algorithms that can provide bionic skins with efficient signal processing functions further accelerate the development of this trend. Inspired by the somatosensory processing hierarchy of humans, the bioinspired co‐design of a tactile sensor and a deep learning‐based algorithm is proposed herein, simplifying the sensor structure while providing computation‐enhanced tactile sensing performance. The soft piezoresistive sensor, based on the carbon black‐coated polyurethane sponge, offers a continuous sensing area. By utilizing a customized deep neural network (DNN), it can detect external tactile stimulus spatially continuously. Besides, a novel data augmentation method is developed based on the sensor's hexagonal structure that has a sixfold rotation symmetry. It can significantly enhance the generalization ability of the DNN model by enriching the collected training data with generated pseudo‐data. The functionality of the sensor and the robustness of the proposed data augmentation strategy are verified by precisely recognizing five touch modalities, illustrating a well‐generalized performance, and providing a promising application prospect in human–robot interaction.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Robotics\Bioinspired_Co‐Design_of_Tactile_Sensor_and_Deep_Learning_Algorithm_for_Kong_et_al_2022.pdf}
}

@article{kongGenerativeRefinementLow2024,
  title = {Generative {{Refinement}} for {{Low Bitrate Image Coding Using Vector Quantized Residual}}},
  author = {Kong, Yuzhuo and Lu, Ming and Ma, Zhan},
  date = {2024-06},
  journaltitle = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
  volume = {14},
  number = {2},
  pages = {185--197},
  issn = {2156-3365},
  doi = {10.1109/JETCAS.2024.3385653},
  url = {https://ieeexplore.ieee.org/abstract/document/10493033?casa_token=lLVF9oOtYWUAAAAA:hdA_EQvUdcJCQEUXDQOh660buwFtFsUSvmNT7OOL566hbXAGa5Msx1IwPTpHU8xwQL6L0uYt1cI},
  urldate = {2024-12-23},
  abstract = {Despite the significant progress in recent deep learning-based image compression, the reconstructed visual quality still suffers at low bitrates due to the lack of high-frequency information. Existing methods deploy the generative adversarial networks (GANs) as an additional loss to supervise the rate-distortion (R-D) optimization, capable of producing more high-frequency components for visually pleasing reconstruction but also introducing unexpected fake textures. This work, instead, proposes to generate high-frequency residuals to refine an image reconstruction compressed using existing image compression solutions. Such a residual signal is calculated between the decoded image and its uncompressed input and quantized to proper codeword vectors in a learnable codebook for decoder-side generative refinement. Extensive experiments demonstrate that our method can restore high-frequency information given images compressed by any codecs and outperform the state-of-the-art generative image compression algorithms or perceptual-oriented post-processing approaches. Moreover, the proposed method using vector quantized residual exhibits remarkable robustness and generalizes to both rules-based and learning-based compression models, which can be used as a plug-and-play module for perceptual optimization without re-training.},
  eventtitle = {{{IEEE Journal}} on {{Emerging}} and {{Selected Topics}} in {{Circuits}} and {{Systems}}},
  keywords = {Bit rate,Codecs,Distortion,generative adversarial network,Image coding,Image reconstruction,Learned image compression,Optimization,residual refinement,Transform coding,vector quantization},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Generative_Refinement_for_Low_Kong_et_al_2024.pdf}
}

@online{kongHunyuanVideoSystematicFramework2025,
  title = {{{HunyuanVideo}}: {{A Systematic Framework For Large Video Generative Models}}},
  shorttitle = {{{HunyuanVideo}}},
  author = {Kong, Weijie and Tian, Qi and Zhang, Zijian and Min, Rox and Dai, Zuozhuo and Zhou, Jin and Xiong, Jiangfeng and Li, Xin and Wu, Bo and Zhang, Jianwei and Wu, Kathrina and Lin, Qin and Yuan, Junkun and Long, Yanxin and Wang, Aladdin and Wang, Andong and Li, Changlin and Huang, Duojun and Yang, Fang and Tan, Hao and Wang, Hongmei and Song, Jacob and Bai, Jiawang and Wu, Jianbing and Xue, Jinbao and Wang, Joey and Wang, Kai and Liu, Mengyang and Li, Pengyu and Li, Shuai and Wang, Weiyan and Yu, Wenqing and Deng, Xinchi and Li, Yang and Chen, Yi and Cui, Yutao and Peng, Yuanbo and Yu, Zhentao and He, Zhiyu and Xu, Zhiyong and Zhou, Zixiang and Xu, Zunnan and Tao, Yangyu and Lu, Qinglin and Liu, Songtao and Zhou, Daquan and Wang, Hongfa and Yang, Yong and Wang, Di and Liu, Yuhong and Jiang, Jie and Zhong, Caesar},
  date = {2025-01-02},
  eprint = {2412.03603},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2412.03603},
  url = {http://arxiv.org/abs/2412.03603},
  urldate = {2025-01-07},
  abstract = {Recent advancements in video generation have significantly impacted daily life for both individuals and industries. However, the leading video generation models remain closed-source, resulting in a notable performance gap between industry capabilities and those available to the public. In this report, we introduce HunyuanVideo, an innovative open-source video foundation model that demonstrates performance in video generation comparable to, or even surpassing, that of leading closed-source models. HunyuanVideo encompasses a comprehensive framework that integrates several key elements, including data curation, advanced architectural design, progressive model scaling and training, and an efficient infrastructure tailored for large-scale model training and inference. As a result, we successfully trained a video generative model with over 13 billion parameters, making it the largest among all open-source models. We conducted extensive experiments and implemented a series of targeted designs to ensure high visual quality, motion dynamics, text-video alignment, and advanced filming techniques. According to evaluations by professionals, HunyuanVideo outperforms previous state-of-the-art models, including Runway Gen-3, Luma 1.6, and three top-performing Chinese video generative models. By releasing the code for the foundation model and its applications, we aim to bridge the gap between closed-source and open-source communities. This initiative will empower individuals within the community to experiment with their ideas, fostering a more dynamic and vibrant video generation ecosystem. The code is publicly available at https://github.com/Tencent/HunyuanVideo.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoModels\HunyuanVideo_Kong_et_al_2025.pdf}
}

@article{kongTunableMultichannelAbsorber2017,
  title = {Tunable Multichannel Absorber Composed of Graphene and Doped Periodic Structures},
  author = {Kong, Xiang-kun and Shi, Xiang-zhu and Mo, Jin-jun and Fang, Yun-tuan and Chen, Xin-lei and Liu, Shao-bin},
  date = {2017-01},
  journaltitle = {Optics Communications},
  volume = {383},
  pages = {391--396},
  issn = {00304018},
  doi = {10.1016/j.optcom.2016.09.038},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0030401816308215},
  urldate = {2024-06-01},
  abstract = {A new design for a tunable multichannel compact absorber, which is achieved by using an asymmetric photonic crystal with graphene monolayers, is theoretically proposed. The graphene monolayers are periodically embedded into the first and last dielectric layers. The absorption, reflection, and transmission spectra of the absorber are studied numerically. A perfect absorption channel is achieved because of impedance matching, and channel number can be modulated by changing periodic number. The characteristic properties of the absorption channel depend on graphene conductivity, which can be controlled via the gate voltage. The proposed structure works as a perfect absorber that is independent from polarization. It has potential applications in the design of multichannel filters, thermal detectors, and electromagnetic wave energy collectors.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Dielectric\Tunable_multichannel_absorber_composed_of_graphene_and_doped_periodic_structures_Kong_et_al_2017.pdf}
}

@article{konkiDeepNeuralNetwork2020,
  title = {A Deep Neural Network for Estimating the Bladder Boundary Using Electrical Impedance Tomography},
  author = {Konki, S K and Khambampati, A K and Sharma, S K and Kim, K Y},
  date = {2020-11-01},
  journaltitle = {Physiol. Meas.},
  volume = {41},
  number = {11},
  pages = {115003},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/1361-6579/abaa56},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/abaa56},
  urldate = {2024-07-03},
  abstract = {Objective: Accurate bladder size estimation is an important clinical parameter that assists physicians, enabling them to provide better treatment for patients who are suffering from urinary incontinence. Electrical impedance tomography (EIT) is a non-invasive medical imaging method that estimates organ boundaries assuming that the electrical conductivity values of the background, bladder, and adjacent tissues inside the pelvic domain are known a priori. However, the performance of a traditional EIT inverse algorithm such as the modified Newton–Raphson (mNR) for shape estimation exhibits severe convergence problems as it heavily depends on the initial guess and often fails to estimate complex boundaries that require greater numbers of Fourier coefficients to approximate the boundary shape. Therefore, in this study a deep neural network (DNN) is introduced to estimate the urinary bladder boundary inside the pelvic domain. Approach: We designed a five-layer DNN which was trained with a dataset of 15 subjects that had different pelvic boundaries, bladder shapes, and conductivity. The boundary voltage measurements of the pelvic domain are defined as input and the corresponding Fourier coefficients that describe the bladder boundary as output data. To evaluate the DNN, we tested with three different sizes of urinary bladder. Main results: Numerical simulations and phantom experiments were performed to validate the performance of the proposed DNN model. The proposed DNN algorithm is compared with the radial basis function (RBF) and mNR method for bladder shape estimation. The results show that the DNN has a low root mean square error for estimated boundary coefficients and better estimation of bladder size when compared to the mNR and RBF. Significance: We apply the first DNN algorithm to estimate the complex boundaries such as the urinary bladder using EIT. Our work provides a novel efficient EIT inverse solver to estimate the bladder boundary and size accurately. The proposed DNN algorithm has advantages in that it is simple to implement, and has better accuracy and fast estimation.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Fourier\A_deep_neural_network_for_estimating_the_bladder_boundary_using_electrical_Konki_et_al_2020.pdf}
}

@inproceedings{konukoHybridDeepAnimation2022,
  title = {A {{Hybrid Deep Animation Codec}} for {{Low-Bitrate Video Conferencing}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author = {Konuko, Goluck and Lathuilière, Stéphane and Valenzise, Giuseppe},
  date = {2022-10-16},
  pages = {1--5},
  publisher = {IEEE},
  location = {Bordeaux, France},
  doi = {10.1109/ICIP46576.2022.10458867},
  url = {https://ieeexplore.ieee.org/document/10458867/},
  urldate = {2024-04-04},
  abstract = {Deep generative models, and particularly facial animation schemes, can be used in video conferencing applications to efficiently compress a video through a sparse set of keypoints, without the need to transmit dense motion vectors. While these schemes bring significant coding gains over conventional video codecs at low bitrates, their performance saturates quickly when the available bandwidth increases. In this paper, we propose a layered, hybrid coding scheme to overcome this limitation. Specifically, we extend a codec based on facial animation by adding an auxiliary stream consisting of a very low bitrate version of the video, obtained through a conventional video codec (e.g., HEVC). The animated and auxiliary videos are combined through a novel fusion module. Our results show consistent average BD-Rate gains in excess of -30\% on a large dataset of video conferencing sequences, extending the operational range of bitrates of a facial animation codec alone.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  isbn = {978-1-66549-620-9},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\VideoCoding\A_Hybrid_Deep_Animation_Codec_for_Low-Bitrate_Video_Conferencing_Konuko_et_al_2022.pdf}
}

@online{konukoPredictiveCodingAnimationBased2023,
  title = {Predictive {{Coding For Animation-Based Video Compression}}},
  author = {Konuko, Goluck and Lathuilière, Stéphane and Valenzise, Giuseppe},
  date = {2023-07-09},
  eprint = {2307.04187},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.04187},
  url = {http://arxiv.org/abs/2307.04187},
  urldate = {2024-04-04},
  abstract = {We address the problem of efficiently compressing video for conferencing-type applications. We build on recent approaches based on image animation, which can achieve good reconstruction quality at very low bitrate by representing face motions with a compact set of sparse keypoints. However, these methods encode video in a frame-by-frame fashion, i.e. each frame is reconstructed from a reference frame, which limits the reconstruction quality when the bandwidth is larger. Instead, we propose a predictive coding scheme which uses image animation as a predictor, and codes the residual with respect to the actual target frame. The residuals can be in turn coded in a predictive manner, thus removing efficiently temporal dependencies. Our experiments indicate a significant bitrate gain, in excess of 70\% compared to the HEVC video standard and over 30\% compared to VVC, on a datasetof talking-head videos},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Multimedia},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\VideoCoding\Predictive_Coding_For_Animation-Based_Video_Compression_Konuko_et_al_22.pdf}
}

@inproceedings{konukoUltraLowBitrateVideo2021,
  title = {Ultra-{{Low Bitrate Video Conferencing Using Deep Image Animation}}},
  booktitle = {{{ICASSP}} 2021 - 2021 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Konuko, Goluck and Valenzise, Giuseppe and Lathuiliere, Stephane},
  date = {2021-06-06},
  pages = {4210--4214},
  publisher = {IEEE},
  location = {Toronto, ON, Canada},
  doi = {10.1109/ICASSP39728.2021.9414731},
  url = {https://ieeexplore.ieee.org/document/9414731/},
  urldate = {2024-04-04},
  abstract = {In this work we propose a novel deep learning approach for ultra-low bitrate video compression for video conferencing applications. To address the shortcomings of current video compression paradigms when the available bandwidth is extremely limited, we adopt a model-based approach that employs deep neural networks to encode motion information as keypoint displacement and reconstruct the video signal at the decoder side. The overall system is trained in an end-to-end fashion minimizing a reconstruction error on the encoder output. Objective and subjective quality evaluation experiments demonstrate that the proposed approach provides an average bitrate reduction for the same visual quality of more than 80\% compared to HEVC.},
  eventtitle = {{{ICASSP}} 2021 - 2021 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-72817-605-5},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\VideoCoding\Ultra-Low_Bitrate_Video_Conferencing_Using_Deep_Image_Animation_Konuko_et_al_2021.pdf}
}

@online{kosiorekNeRFVAEGeometryAware2021,
  title = {{{NeRF-VAE}}: {{A Geometry Aware 3D Scene Generative Model}}},
  shorttitle = {{{NeRF-VAE}}},
  author = {Kosiorek, Adam R. and Strathmann, Heiko and Zoran, Daniel and Moreno, Pol and Schneider, Rosalia and Mokrá, Soňa and Rezende, Danilo J.},
  date = {2021-04-01},
  eprint = {2104.00587},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2104.00587},
  urldate = {2023-09-26},
  abstract = {We propose NeRF-VAE, a 3D scene generative model that incorporates geometric structure via NeRF and differentiable volume rendering. In contrast to NeRF, our model takes into account shared structure across scenes, and is able to infer the structure of a novel scene -- without the need to re-train -- using amortized inference. NeRF-VAE's explicit 3D rendering process further contrasts previous generative models with convolution-based rendering which lacks geometric structure. Our model is a VAE that learns a distribution over radiance fields by conditioning them on a latent scene representation. We show that, once trained, NeRF-VAE is able to infer and render geometrically-consistent scenes from previously unseen 3D environments using very few input images. We further demonstrate that NeRF-VAE generalizes well to out-of-distribution cameras, while convolutional models do not. Finally, we introduce and study an attention-based conditioning mechanism of NeRF-VAE's decoder, which improves model performance.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\NeRF-VAE_Kosiorek_et_al_2021.pdf}
}

@article{koUNetbasedApproachAutomatic2021,
  title = {U-{{Net-based}} Approach for Automatic Lung Segmentation in Electrical Impedance Tomography},
  author = {Ko, Yen-Fen and Cheng, Kuo-Sheng},
  date = {2021-02-01},
  journaltitle = {Physiol. Meas.},
  volume = {42},
  number = {2},
  pages = {025002},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/1361-6579/abe021},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/abe021},
  urldate = {2024-07-03},
  abstract = {Objective. Electrical impedance tomography (EIT) is a non-invasive technique that constitutes a promising tool for real-time imaging and long-term monitoring of the ventilation distribution at bedside. However, clinical monitoring and diagnostic evaluations depend on various methods to assess ventilation-dependent parameters useful for ventilation therapy. This study develops an automatic, robust, and rapidly accessible method for lung segmentation that can be used to define appropriate regions-of-interest (ROIs) within EIT images. Approach. To date, available methods for patients with defected lungs have the disadvantage of not being able to identify lung regions because of their poor ventilation responses. Furthermore, the challenges related to the identification of lung areas in EIT images are attributed to the low spatial resolution of EIT. In this study, a U-Net-based automatic lung segmentation model is used as a postprocessor to transform the original EIT image to a lung ROI image and refine the inherent conductivity distribution of the original EIT image. The trained U-Net network is capable of performing an automatic segmentation of conductivity changes in EIT images without requiring prior information. Main results. The experimental design of this study was based on a finite element method (FEM) phantom used to assess the feasibility and effectiveness of the proposed method, and evaluation of the trained models on the test dataset was performed using the Dice similarity coefficient (DSC) and the mean absolute error (MAE). The FEM experimental results yielded values of 0.0065 for MAE, and values {$>$}0.99 for DSC in simulations. Significance. The use of a deep-learning-based approach attained automatic and convenient segmentation of lung ROIs into distinguishable images, which represents a direct benefit for regional lung ventilation-dependent parameter extraction and analysis. However, further investigations and validation are warranted in real human datasets with different physiology conditions with CT cross-section dataset to refine the suggested model.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\U-Net-based_approach_for_automatic_lung_segmentation_in_electrical_impedance_Ko_Cheng_2021.pdf}
}

@article{kriegelThreeMaterialFour2017,
  title = {Three Material and Four Material One-Dimensional Phononic Crystals},
  author = {Kriegel, Ilka and Scotognella, Francesco},
  date = {2017-01},
  journaltitle = {Physica E: Low-dimensional Systems and Nanostructures},
  volume = {85},
  pages = {34--37},
  issn = {13869477},
  doi = {10.1016/j.physe.2016.08.009},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1386947716306415},
  urldate = {2023-09-05},
  abstract = {In this work, we studied one-dimensional phononic structures for selective acoustic filtering. The structures are composed of three and four materials which have different elastic properties. We have observed that the phononic band gaps split in two and three transmission valleys for the three-material and the four-material based phononic structures, respectively. Furthermore, the number of transmission peaks between the split gaps is directly related to the number of unit cells composing the phononic structures. The observations of this work can be useful for the fabrication of acoustic filters with the possibility to select the transmission of particular frequencies.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Three_material_and_four_material_one-dimensional_phononic_crystals_Kriegel_Scotognella_2017.pdf}
}

@article{krishnamurthyOpticalModulationPhotonic2004,
  title = {Optical Modulation in Photonic Band Gap Structures by Surface Acoustic Waves},
  author = {Krishnamurthy, Srinivasan and Santos, Paulo V.},
  date = {2004-08-15},
  journaltitle = {Journal of Applied Physics},
  volume = {96},
  number = {4},
  pages = {1803--1810},
  issn = {0021-8979, 1089-7550},
  doi = {10.1063/1.1767974},
  url = {https://pubs.aip.org/jap/article/96/4/1803/926092/Optical-modulation-in-photonic-band-gap-structures},
  urldate = {2024-01-22},
  abstract = {We investigate theoretically the modulation of light beams in photonic band gap (PBG) structures by surface acoustic waves (SAWs). In these structures, the propagation of light beams can be actively controlled through an external acoustic stimulus. We have extended the mathematically rigorous transfer matrix method to calculate the light flow in PBG structures subjected to the spatial- and time-dependent dielectric function modulation induced by the SAW. The calculational procedure, which applies for SAWs with a frequency much smaller than that of the light, is employed to determine the transmission spectra of a one-dimensional Bragg stack with a cavity and that of a two-dimensional GaAs PBG structure with periodic air holes. We demonstrate that these two structures can be configured as an on∕off optical switch with very high contrast ratios and, in the two-dimensional case as an efficient wavelength-tunable optical filter.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\Optical_modulation_in_photonic_band_gap_structures_by_surface_acoustic_waves_Krishnamurthy_Santos_2004.pdf}
}

@article{kuo-shengchengElectrodeModelsElectric1989,
  title = {Electrode Models for Electric Current Computed Tomography},
  author = {{Kuo-Sheng Cheng} and Isaacson, D. and Newell, J.C. and Gisser, D.G.},
  date = {1989-09},
  journaltitle = {IEEE Trans. Biomed. Eng.},
  volume = {36},
  number = {9},
  pages = {918--924},
  issn = {00189294},
  doi = {10.1109/10.35300},
  url = {http://ieeexplore.ieee.org/document/35300/},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\CompleteElectrodeModel\Electrode_models_for_electric_current_computed_tomography_Kuo-Sheng_Cheng_et_al_1989.pdf}
}

@article{kupisMethodsElectricalImpedance,
  title = {Methods for the {{Electrical Impedance Tomography Inverse Problem}}: {{Deep Learning}} and {{Regularization}} with {{Wavelets}}},
  author = {Kupis, Shyla Rae},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Wavelets\Methods_for_the_Electrical_Impedance_Tomography_Inverse_Problem_Kupis_.pdf}
}

@article{kupisMethodsElectricalImpedancea,
  title = {Methods for the {{Electrical Impedance Tomography Inverse Problem}}: {{Deep Learning}} and {{Regularization}} with {{Wavelets}}},
  author = {Kupis, Shyla Rae},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\Methods_for_the_Electrical_Impedance_Tomography_Inverse_Problem_Kupis_.pdf}
}

@article{kuscheFPGABasedBroadbandEIT2015,
  title = {A {{FPGA-Based Broadband EIT System}} for {{Complex Bioimpedance Measurements}}—{{Design}} and {{Performance Estimation}}},
  author = {Kusche, Roman and Malhotra, Ankit and Ryschka, Martin and Ardelt, Gunther and Klimach, Paula and Kaufmann, Steffen},
  date = {2015-07-29},
  journaltitle = {Electronics},
  volume = {4},
  number = {3},
  pages = {507--525},
  issn = {2079-9292},
  doi = {10.3390/electronics4030507},
  url = {https://www.mdpi.com/2079-9292/4/3/507},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is an imaging method that is able to estimate the electrical conductivity distribution of living tissue. This work presents a field programmable gate array (FPGA)-based multi-frequency EIT system for complex, time-resolved bioimpedance measurements. The system has the capability to work with measurement setups with up to 16 current electrodes and 16 voltage electrodes. The excitation current has a range of about 10 µA to 5 mA, whereas the sinusoidal signal used for excitation can have a frequency of up to 500 kHz. Additionally, the usage of a chirp or rectangular signal excitation is possible. Furthermore, the described system has a sample rate of up to 3480 impedance spectra per second (ISPS). The performance of the EIT system is demonstrated with a resistor-based phantom and tank phantoms. Additionally, first measurements taken from the human thorax during a breathing cycle are presented.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\EIDORS\A_FPGA-Based_Broadband_EIT_System_for_Complex_Bioimpedance_Measurements—Design_Kusche_et_al_2015.pdf}
}

@article{kushwahaAcousticBandStructure1993,
  title = {Acoustic Band Structure of Periodic Elastic Composites},
  author = {Kushwaha, M. S. and Halevi, P. and Dobrzynski, L. and Djafari-Rouhani, B.},
  date = {1993-09-27},
  journaltitle = {Phys. Rev. Lett.},
  volume = {71},
  number = {13},
  pages = {2022--2025},
  issn = {0031-9007},
  doi = {10.1103/PhysRevLett.71.2022},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.71.2022},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\2DPhononicCrystals\Acoustic_band_structure_of_periodic_elastic_composites_Kushwaha_et_al_1993.pdf}
}

@article{kuzelLayeredStructuresTransfer,
  title = {Layered Structures: Transfer Matrix Formalism},
  author = {Kužel, Petr},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Courses\Layered_structures_Kuzel_.pdf}
}

@article{kuzminPruningVsQuantization2023,
  title = {Pruning vs {{Quantization}}: {{Which}} Is {{Better}}?},
  shorttitle = {Pruning vs {{Quantization}}},
  author = {Kuzmin, Andrey and Nagel, Markus and family=Baalen, given=Mart, prefix=van, useprefix=true and Behboodi, Arash and Blankevoort, Tijmen},
  date = {2023-12-15},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {62414--62427},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/c48bc80aa5d3cbbdd712d1cc107b8319-Abstract-Conference.html},
  urldate = {2024-07-24},
  langid = {english},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Components\\ModelCompression\\Quantization\\Pruning_vs_Quantization_Kuzmin_et_al_2023.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Components\\ModelCompression\\Quantization\\Pruning_vs_Quantization_Kuzmin_et_al_22.pdf}
}

@article{kuznetsovRoadmapOpticalMetasurfaces2024,
  title = {Roadmap for {{Optical Metasurfaces}}},
  author = {Kuznetsov, Arseniy I. and Brongersma, Mark L. and Yao, Jin and Chen, Mu Ku and Levy, Uriel and Tsai, Din Ping and Zheludev, Nikolay I. and Faraon, Andrei and Arbabi, Amir and Yu, Nanfang and Chanda, Debashis and Crozier, Kenneth B. and Kildishev, Alexander V. and Wang, Hao and Yang, Joel K. W. and Valentine, Jason G. and Genevet, Patrice and Fan, Jonathan A. and Miller, Owen D. and Majumdar, Arka and Fröch, Johannes E. and Brady, David and Heide, Felix and Veeraraghavan, Ashok and Engheta, Nader and Alù, Andrea and Polman, Albert and Atwater, Harry A. and Thureja, Prachi and Paniagua-Dominguez, Ramon and Ha, Son Tung and Barreda, Angela I. and Schuller, Jon A. and Staude, Isabelle and Grinblat, Gustavo and Kivshar, Yuri and Peana, Samuel and Yelin, Susanne F. and Senichev, Alexander and Shalaev, Vladimir M. and Saha, Soham and Boltasseva, Alexandra and Rho, Junsuk and Oh, Dong Kyo and Kim, Joohoon and Park, Junghyun and Devlin, Robert and Pala, Ragip A.},
  date = {2024-03-20},
  journaltitle = {ACS Photonics},
  volume = {11},
  number = {3},
  pages = {816--865},
  publisher = {American Chemical Society},
  doi = {10.1021/acsphotonics.3c00457},
  url = {https://doi.org/10.1021/acsphotonics.3c00457},
  urldate = {2024-07-09},
  abstract = {Metasurfaces have recently risen to prominence in optical research, providing unique functionalities that can be used for imaging, beam forming, holography, polarimetry, and many more, while keeping device dimensions small. Despite the fact that a vast range of basic metasurface designs has already been thoroughly studied in the literature, the number of metasurface-related papers is still growing at a rapid pace, as metasurface research is now spreading to adjacent fields, including computational imaging, augmented and virtual reality, automotive, display, biosensing, nonlinear, quantum and topological optics, optical computing, and more. At the same time, the ability of metasurfaces to perform optical functions in much more compact optical systems has triggered strong and constantly growing interest from various industries that greatly benefit from the availability of miniaturized, highly functional, and efficient optical components that can be integrated in optoelectronic systems at low cost. This creates a truly unique opportunity for the field of metasurfaces to make both a scientific and an industrial impact. The goal of this Roadmap is to mark this “golden age” of metasurface research and define future directions to encourage scientists and engineers to drive research and development in the field of metasurfaces toward both scientific excellence and broad industrial adoption.},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\Metasurfaces\Roadmap_for_Optical_Kuznetsov_et_al_2024.pdf}
}

@inproceedings{laduneCOOLCHICCoordinatebasedLow2023,
  title = {{{COOL-CHIC}}: {{Coordinate-based Low Complexity Hierarchical Image Codec}}},
  shorttitle = {{{COOL-CHIC}}},
  author = {Ladune, Théo and Philippe, Pierrick and Henry, Félix and Clare, Gordon and Leguay, Thomas},
  date = {2023},
  pages = {13515--13522},
  url = {https://openaccess.thecvf.com/content/ICCV2023/html/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.html},
  urldate = {2024-08-07},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\OverFittedSingleImage\COOL-CHIC_Ladune_et_al_2023.pdf}
}

@article{lamataQuantumReinforcementLearning2021,
  title = {Quantum {{Reinforcement Learning}} with {{Quantum Photonics}}},
  author = {Lamata, Lucas},
  date = {2021-02},
  journaltitle = {Photonics},
  volume = {8},
  number = {2},
  pages = {33},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2304-6732},
  doi = {10.3390/photonics8020033},
  url = {https://www.mdpi.com/2304-6732/8/2/33},
  urldate = {2024-06-01},
  abstract = {Quantum machine learning has emerged as a promising paradigm that could accelerate machine learning calculations. Inside this field, quantum reinforcement learning aims at designing and building quantum agents that may exchange information with their environment and adapt to it, with the aim of achieving some goal. Different quantum platforms have been considered for quantum machine learning and specifically for quantum reinforcement learning. Here, we review the field of quantum reinforcement learning and its implementation with quantum photonics. This quantum technology may enhance quantum computation and communication, as well as machine learning, via the fruitful marriage between these previously unrelated fields.},
  issue = {2},
  langid = {english},
  keywords = {quantum communication,quantum machine learning,quantum photonics,quantum reinforcement learning,quantum technologies},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\ReinforcementLearning\Quantum_Reinforcement_Learning_with_Quantum_Photonics_Lamata_2021.pdf}
}

@misc{Lecture13_Html,
  title = {Lecture 13\_.Html},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Courses\Lecture_13__.html}
}

@misc{Lecture13_Pdf,
  title = {Lecture 13\_.Pdf},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Courses\Lecture_13__.pdf}
}

@article{leeEntropyConstrainedImplicitNeural2023,
  title = {Entropy-{{Constrained Implicit Neural Representations}} for {{Deep Image Compression}}},
  author = {Lee, Soonbin and Jeong, Jong-Beom and Ryu, Eun-Seok},
  date = {2023},
  journaltitle = {IEEE Signal Processing Letters},
  volume = {30},
  pages = {663--667},
  issn = {1558-2361},
  doi = {10.1109/LSP.2023.3279780},
  url = {https://ieeexplore.ieee.org/document/10132493?denied=},
  urldate = {2024-08-19},
  abstract = {Implicit neural representations (INRs) for various data types have gained popularity in the field of deep learning owing to their effectiveness. However, previous studies on INRs have only focused on recovering original representations. This letter investigated an image compression model based on INRs using a model compression technique for entropy-constrained neural networks. Specifically, the proposed model trains a multilayer perceptron (MLP) to overfit a single image and then uses its weights to optimize its compressed representation using additive uniform noise. Accordingly, the proposed model efficiently minimizes the size of the model weight in an end-to-end manner. This training optimization process is fairly desirable for adjusting the rate of distortion for image compression. In contrast to other model compression techniques, the proposed model is implemented without additional training process or memory cost. By introducing entropy loss, this letter demonstrated that the proposed model can be used to preserve high image quality while maintaining smaller model size. The experimental results demonstrated that the proposed model achieved comparable performance to conventional image compression models without incurring high storage costs.},
  eventtitle = {{{IEEE Signal Processing Letters}}},
  keywords = {Computational modeling,Data models,Distortion,Entropy,Image coding,Image compression,implicit neural representation,model compression,Neural networks,Training},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\OverFittedSingleImage\Entropy-Constrained_Implicit_Neural_Representations_for_Deep_Image_Compression_Lee_et_al_2023.pdf}
}

@article{leeMappingInformationLight2024,
  title = {Mapping Information and Light: {{Trends}} of {{AI-enabled}} Metaphotonics},
  shorttitle = {Mapping Information and Light},
  author = {Lee, Seokho and Park, Cherry and Rho, Junsuk},
  date = {2024-03-01},
  journaltitle = {Current Opinion in Solid State and Materials Science},
  volume = {29},
  pages = {101144},
  issn = {1359-0286},
  doi = {10.1016/j.cossms.2024.101144},
  url = {https://www.sciencedirect.com/science/article/pii/S135902862400010X},
  urldate = {2024-06-01},
  abstract = {A dynamic convergence between metaphotonics and artificial intelligence (AI) is underway. In this review, AI is conceptualized as a tool for mapping input and output data. From this perspective, an analysis is conducted on how input and output data are set, aiming to discern the following three key trends in the utilization of AI within the field of metaphotonics. 1. The advancement of forward modeling and inverse design, utilizing AI for mapping metaphotonic device design and the corresponding optical properties. 2. Optical neural networks (ONNs), an emerging field that implements AI using metaphotonics by processing information within electromagnetic waves. 3. The field of metasensors, employing metamaterials to encode optical information for measurement and processing using AI to demonstrate high performance sensing. We round up the review with our perspectives on AI and metaphotonics research and discuss the future trends, challenges, and developments.},
  keywords = {Artificial intelligence,Forward modeling,Inverse design,Metaphotonics,Metasensor,Optical neural network},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\Mapping_information_and_light_Lee_et_al_2024.pdf}
}

@article{leeMechanicalMetamaterialMade2012,
  title = {A Mechanical Metamaterial Made from a {{DNA}} Hydrogel},
  author = {Lee, Jong Bum and Peng, Songming and Yang, Dayong and Roh, Young Hoon and Funabashi, Hisakage and Park, Nokyoung and Rice, Edward J. and Chen, Liwei and Long, Rong and Wu, Mingming and Luo, Dan},
  date = {2012-12},
  journaltitle = {Nature Nanotech},
  volume = {7},
  number = {12},
  pages = {816--820},
  issn = {1748-3387, 1748-3395},
  doi = {10.1038/nnano.2012.211},
  url = {https://www.nature.com/articles/nnano.2012.211},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\A_mechanical_metamaterial_made_from_a_DNA_hydrogel_Lee_et_al_2012.pdf}
}

@article{leePhotonicSpikingNeural2022,
  title = {Photonic Spiking Neural Networks with Event-Driven Femtojoule Optoelectronic Neurons Based on {{Izhikevich-inspired}} Model},
  author = {Lee, Yun-Jhu and On, Mehmet Berkay and Xiao, Xian and Proietti, Roberto and Yoo, S. J. Ben},
  date = {2022-05-23},
  journaltitle = {Opt. Express, OE},
  volume = {30},
  number = {11},
  pages = {19360--19389},
  publisher = {Optica Publishing Group},
  issn = {1094-4087},
  doi = {10.1364/OE.449528},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-30-11-19360},
  urldate = {2024-06-01},
  abstract = {Photonic spiking neural networks (PSNNs) potentially offer exceptionally high throughput and energy efficiency compared to their electronic neuromorphic counterparts while maintaining their benefits in terms of event-driven computing capability. While state-of-the-art PSNN designs require a continuous laser pump, this paper presents a monolithic optoelectronic PSNN hardware design consisting of an MZI mesh incoherent network and event-driven laser spiking neurons. We designed, prototyped, and experimentally demonstrated this event-driven neuron inspired by the Izhikevich model incorporating both excitatory and inhibitory optical spiking inputs and producing optical spiking outputs accordingly. The optoelectronic neurons consist of two photodetectors for excitatory and inhibitory optical spiking inputs, electrical transistors\&\#x2019; circuits providing spiking nonlinearity, and a laser for optical spiking outputs. Additional inclusion of capacitors and resistors complete the Izhikevich-inspired optoelectronic neurons, which receive excitatory and inhibitory optical spikes as inputs from other optoelectronic neurons. We developed a detailed optoelectronic neuron model in Verilog-A and simulated the circuit-level operation of various cases with excitatory input and inhibitory input signals. The experimental results closely resemble the simulated results and demonstrate how the excitatory inputs trigger the optical spiking outputs while the inhibitory inputs suppress the outputs. The nanoscale neuron designed in our monolithic PSNN utilizes quantum impedance conversion. It shows that estimated 21.09 fJ/spike input can trigger the output from on-chip nanolasers running at a maximum of 10 Gspike/second in the neural network. Utilizing the simulated neuron model, we conducted simulations on MNIST handwritten digits recognition using fully connected (FC) and convolutional neural networks (CNN). The simulation results show 90\&\#x0025; accuracy on unsupervised learning and 97\&\#x0025; accuracy on a supervised modified FC neural network. The benchmark shows our PSNN can achieve 50 TOP/J energy efficiency, which corresponds to 100\&\#x2009;\&\#x00D7;\&\#x2009;throughputs and 1000\&\#x2009;\&\#x00D7;\&\#x2009;energy-efficiency improvements compared to state-of-art electrical neuromorphic hardware such as Loihi and NeuroGrid.},
  langid = {english},
  keywords = {Diode lasers,Fiber lasers,Laser pumping,Machine learning,Neural networks,Optical signals},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\ConvolutionalNeuralNetworks\Photonic_spiking_neural_networks_with_event-driven_femtojoule_optoelectronic_Lee_et_al_2022.pdf}
}

@online{leeSharpNeRFGridbasedFast2024,
  title = {Sharp-{{NeRF}}: {{Grid-based Fast Deblurring Neural Radiance Fields Using Sharpness Prior}}},
  shorttitle = {Sharp-{{NeRF}}},
  author = {Lee, Byeonghyeon and Lee, Howoong and Ali, Usman and Park, Eunbyung},
  date = {2024-01-01},
  eprint = {2401.00825},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2401.00825},
  url = {http://arxiv.org/abs/2401.00825},
  urldate = {2024-02-14},
  abstract = {Neural Radiance Fields (NeRF) have shown remarkable performance in neural rendering-based novel view synthesis. However, NeRF suffers from severe visual quality degradation when the input images have been captured under imperfect conditions, such as poor illumination, defocus blurring, and lens aberrations. Especially, defocus blur is quite common in the images when they are normally captured using cameras. Although few recent studies have proposed to render sharp images of considerably high-quality, yet they still face many key challenges. In particular, those methods have employed a Multi-Layer Perceptron (MLP) based NeRF, which requires tremendous computational time. To overcome these shortcomings, this paper proposes a novel technique Sharp-NeRF -- a grid-based NeRF that renders clean and sharp images from the input blurry images within half an hour of training. To do so, we used several grid-based kernels to accurately model the sharpness/blurriness of the scene. The sharpness level of the pixels is computed to learn the spatially varying blur kernels. We have conducted experiments on the benchmarks consisting of blurry images and have evaluated full-reference and non-reference metrics. The qualitative and quantitative results have revealed that our approach renders the sharp novel views with vivid colors and fine details, and it has considerably faster training time than the previous works. Our project page is available at https://benhenryl.github.io/SharpNeRF/},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\DeformableObject\Sharp-NeRF_Lee_et_al_2024.pdf}
}

@inproceedings{leguayCoolchicVideoLearned2024,
  title = {Cool-Chic Video: {{Learned}} Video Coding with 800 Parameters},
  shorttitle = {Cool-Chic Video},
  booktitle = {2024 {{Data Compression Conference}} ({{DCC}})},
  author = {Leguay, Thomas and Ladune, Théo and Philippe, Pierrick and Déforges, Olivier},
  date = {2024-03},
  pages = {23--32},
  issn = {2375-0359},
  doi = {10.1109/DCC58796.2024.00010},
  url = {https://ieeexplore.ieee.org/document/10533789},
  urldate = {2024-07-25},
  abstract = {We propose a lightweight learned video codec with 900 multiplications per decoded pixel and 800 parameters overall. To the best of our knowledge, this is one of the neural video codecs with the lowest decoding complexity. It is built upon the overfitted image codec Cool-chic and supplements it with an inter coding module to leverage the video’s temporal redundancies. The proposed model is able to compress videos using both low-delay and random access configurations and achieves rate-distortion close to AVC while outperforming other overfitted codecs such as FFNeRV. The system is made open-source: orange-opensource.github.io/Cool-Chic.},
  eventtitle = {2024 {{Data Compression Conference}} ({{DCC}})},
  keywords = {cnr,coin,cool-chic,coordinate-based neural representation,Data compression,Encoding,Image coding,implicit neural representation,inr,lightweight,low complexity,low decoding commplexity,Motion compensation,nerv,neural representation,open-source,overfitted codec,Rate-distortion,Redundancy,video codec,video coding,Video coding,video compression},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoCodec\Cool-chic_video_Leguay_et_al_2024.pdf}
}

@inproceedings{leguayLowComplexityOverfittedNeural2023,
  title = {Low-{{Complexity Overfitted Neural Image Codec}}},
  booktitle = {2023 {{IEEE}} 25th {{International Workshop}} on {{Multimedia Signal Processing}} ({{MMSP}})},
  author = {Leguay, Thomas and Ladune, Théo and Philippe, Pierrick and Clare, Gordon and Henry, Félix and Déforges, Olivier},
  date = {2023-09},
  pages = {1--6},
  issn = {2473-3628},
  doi = {10.1109/MMSP59012.2023.10337636},
  url = {https://ieeexplore.ieee.org/abstract/document/10337636},
  urldate = {2024-08-07},
  abstract = {We propose a neural image codec at reduced complexity which overfits the decoder parameters to each input image. While autoencoders perform up to a million multiplications per decoded pixel, the proposed approach only requires 2300 multiplications per pixel. Albeit low-complexity, the method rivals autoencoder performance and surpasses HEVC performance under various coding conditions. Additional lightweight modules and an improved training process provide a 14\% rate reduction with respect to previous overfitted codecs, while offering a similar complexity. This work is made open-source at http://orange-opensource.github.io/Cool-Chic/.},
  eventtitle = {2023 {{IEEE}} 25th {{International Workshop}} on {{Multimedia Signal Processing}} ({{MMSP}})},
  keywords = {Codecs,Conferences,Encoding,Image coding,Low-complexity,Neural networks,Overfitting,Signal processing,Training},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\OverFittedSingleImage\Low-Complexity_Overfitted_Neural_Image_Codec_Leguay_et_al_2023.pdf}
}

@book{lehmannElectrochemistrySiliconInstrumentation2002,
  title = {Electrochemistry of {{Silicon}}: {{Instrumentation}}, {{Science}}, {{Materials}} and {{Applications}}},
  shorttitle = {Electrochemistry of {{Silicon}}},
  author = {Lehmann, Volker},
  date = {2002-02-22},
  edition = {1},
  publisher = {Wiley},
  doi = {10.1002/3527600272},
  url = {https://onlinelibrary.wiley.com/doi/book/10.1002/3527600272},
  urldate = {2023-09-05},
  isbn = {978-3-527-29321-6 978-3-527-60027-4},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Semiconductor\Electrochemistry_of_Silicon_Lehmann_2002.pdf}
}

@online{leiAnimateAnythingConsistentControllable2024,
  title = {{{AnimateAnything}}: {{Consistent}} and {{Controllable Animation}} for {{Video Generation}}},
  shorttitle = {{{AnimateAnything}}},
  author = {Lei, Guojun and Wang, Chi and Li, Hong and Zhang, Rong and Wang, Yikai and Xu, Weiwei},
  date = {2024-11-16},
  eprint = {2411.10836},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2411.10836},
  url = {http://arxiv.org/abs/2411.10836},
  urldate = {2025-01-02},
  abstract = {We present a unified controllable video generation approach AnimateAnything that facilitates precise and consistent video manipulation across various conditions, including camera trajectories, text prompts, and user motion annotations. Specifically, we carefully design a multi-scale control feature fusion network to construct a common motion representation for different conditions. It explicitly converts all control information into frame-by-frame optical flows. Then we incorporate the optical flows as motion priors to guide final video generation. In addition, to reduce the flickering issues caused by large-scale motion, we propose a frequency-based stabilization module. It can enhance temporal coherence by ensuring the video's frequency domain consistency. Experiments demonstrate that our method outperforms the state-of-the-art approaches. For more details and videos, please refer to the webpage: https://yu-shaonian.github.io/Animate\_Anything/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\AnimateAnything_Lei_et_al_2024.pdf}
}

@article{leiDynamicMultifunctionalMetasurfaces2024,
  title = {Dynamic Multifunctional Metasurfaces: An Inverse Design Deep Learning Approach},
  shorttitle = {Dynamic Multifunctional Metasurfaces},
  author = {Lei, Zhi-Dan and Xu, Yi-Duo and Lei, Cheng and Zhao, Yan and Wang, Du},
  date = {2024-01-01},
  journaltitle = {Photon. Res., PRJ},
  volume = {12},
  number = {1},
  pages = {123--133},
  publisher = {Optica Publishing Group},
  issn = {2327-9125},
  doi = {10.1364/PRJ.505991},
  url = {https://opg.optica.org/prj/abstract.cfm?uri=prj-12-1-123},
  urldate = {2024-06-01},
  abstract = {Optical metasurfaces (OMs) offer unprecedented control over electromagnetic waves, enabling advanced optical multiplexing. The emergence of deep learning has opened new avenues for designing OMs. However, existing deep learning methods for OMs primarily focus on forward design, which limits their design capabilities, lacks global optimization, and relies on prior knowledge. Additionally, most OMs are static, with fixed functionalities once processed. To overcome these limitations, we propose an inverse design deep learning method for dynamic OMs. Our approach comprises a forward prediction network and an inverse retrieval network. The forward prediction network establishes a mapping between meta-unit structure parameters and reflectance spectra. The inverse retrieval network generates a library of meta-unit structure parameters based on target requirements, enabling end-to-end design of OMs. By incorporating the dynamic tunability of the phase change material Sb2Te3 with inverse design deep learning, we achieve the design and verification of dynamic multifunctional OMs. Our results demonstrate OMs with multiple information channels and encryption capabilities that can realize multiple physical field optical modulation functions. When Sb2Te3 is in the amorphous state, near-field nano-printing based on meta-unit amplitude modulation is achieved for X-polarized incident light, while holographic imaging based on meta-unit phase modulation is realized for circularly polarized light. In the crystalline state, the encrypted information remains secure even with the correct polarization input, achieving double encryption. This research points towards ultra-compact, high-capacity, and highly secure information storage approaches.},
  langid = {english},
  keywords = {Deep learning,Inverse design,Machine learning,Neural networks,Optical computing,Optical fields},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\Dynamic_multifunctional_Lei_et_al_2024.pdf}
}

@article{leonhardtBroadbandInvisibilityNonEuclidean2009,
  title = {Broadband {{Invisibility}} by {{Non-Euclidean Cloaking}}},
  author = {Leonhardt, Ulf and Tyc, Tomáš},
  date = {2009-01-02},
  journaltitle = {Science},
  volume = {323},
  number = {5910},
  pages = {110--112},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1166332},
  url = {https://www.science.org/doi/10.1126/science.1166332},
  urldate = {2023-09-05},
  abstract = {Invisibility and negative refraction are both applications of transformation optics where the material of a device performs a coordinate transformation for electromagnetic fields. The device creates the illusion that light propagates through empty flat space, whereas in physical space, light is bent around a hidden interior or seems to run backward in space or time. All of the previous proposals for invisibility require materials with extreme properties. Here we show that transformation optics of a curved, non-Euclidean space (such as the surface of a virtual sphere) relax these requirements and can lead to invisibility in a broad band of the spectrum.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Broadband_Invisibility_by_Non-Euclidean_Cloaking_Leonhardt_Tyc_2009.pdf}
}

@online{lepikhinGShardScalingGiant2020,
  title = {{{GShard}}: {{Scaling Giant Models}} with {{Conditional Computation}} and {{Automatic Sharding}}},
  shorttitle = {{{GShard}}},
  author = {Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  date = {2020-06-30},
  eprint = {2006.16668},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2006.16668},
  urldate = {2024-09-22},
  abstract = {Neural network scaling has been critical for improving the model quality in many real-world machine learning applications with vast amounts of training data and compute. Although this trend of scaling is affirmed to be a sure-fire approach for better model quality, there are challenges on the path such as the computation cost, ease of programming, and efficient implementation on parallel devices. GShard is a module composed of a set of lightweight annotation APIs and an extension to the XLA compiler. It provides an elegant way to express a wide range of parallel computation patterns with minimal changes to the existing model code. GShard enabled us to scale up multilingual neural machine translation Transformer model with Sparsely-Gated Mixture-of-Experts beyond 600 billion parameters using automatic sharding. We demonstrate that such a giant model can efficienctly be trained on 2048 TPU v3 accelerators in 4 days to achieve far superior quality for translation from 100 languages to English compared to the prior art.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\MixtureOfExperts\GShard_Lepikhin_et_al_2020.pdf}
}

@online{liAdv3DGenerating3D2023,
  title = {{{Adv3D}}: {{Generating 3D Adversarial Examples}} in {{Driving Scenarios}} with {{NeRF}}},
  shorttitle = {{{Adv3D}}},
  author = {Li, Leheng and Lian, Qing and Chen, Ying-Cong},
  date = {2023-09-04},
  eprint = {2309.01351},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.01351},
  url = {http://arxiv.org/abs/2309.01351},
  urldate = {2024-02-14},
  abstract = {Deep neural networks (DNNs) have been proven extremely susceptible to adversarial examples, which raises special safety-critical concerns for DNN-based autonomous driving stacks (i.e., 3D object detection). Although there are extensive works on image-level attacks, most are restricted to 2D pixel spaces, and such attacks are not always physically realistic in our 3D world. Here we present Adv3D, the first exploration of modeling adversarial examples as Neural Radiance Fields (NeRFs). Advances in NeRF provide photorealistic appearances and 3D accurate generation, yielding a more realistic and realizable adversarial example. We train our adversarial NeRF by minimizing the surrounding objects' confidence predicted by 3D detectors on the training set. Then we evaluate Adv3D on the unseen validation set and show that it can cause a large performance reduction when rendering NeRF in any sampled pose. To generate physically realizable adversarial examples, we propose primitive-aware sampling and semantic-guided regularization that enable 3D patch attacks with camouflage adversarial texture. Experimental results demonstrate that the trained adversarial NeRF generalizes well to different poses, scenes, and 3D detectors. Finally, we provide a defense method to our attacks that involves adversarial training through data augmentation. Project page: https://len-li.github.io/adv3d-web},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\Adv3D_Li_et_al_2023.pdf}
}

@online{liAgentHospitalSimulacrum2024,
  title = {Agent {{Hospital}}: {{A Simulacrum}} of {{Hospital}} with {{Evolvable Medical Agents}}},
  shorttitle = {Agent {{Hospital}}},
  author = {Li, Junkai and Wang, Siyu and Zhang, Meng and Li, Weitao and Lai, Yunghwei and Kang, Xinhui and Ma, Weizhi and Liu, Yang},
  date = {2024-05-05},
  eprint = {2405.02957},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2405.02957},
  urldate = {2024-07-08},
  abstract = {In this paper, we introduce a simulacrum of hospital called Agent Hospital that simulates the entire process of treating illness. All patients, nurses, and doctors are autonomous agents powered by large language models (LLMs). Our central goal is to enable a doctor agent to learn how to treat illness within the simulacrum. To do so, we propose a method called MedAgent-Zero. As the simulacrum can simulate disease onset and progression based on knowledge bases and LLMs, doctor agents can keep accumulating experience from both successful and unsuccessful cases. Simulation experiments show that the treatment performance of doctor agents consistently improves on various tasks. More interestingly, the knowledge the doctor agents have acquired in Agent Hospital is applicable to real-world medicare benchmarks. After treating around ten thousand patients (real-world doctors may take over two years), the evolved doctor agent achieves a state-of-the-art accuracy of 93.06\% on a subset of the MedQA dataset that covers major respiratory diseases. This work paves the way for advancing the applications of LLM-powered agent techniques in medical scenarios.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C:\Users\ahmed\Zotero\storage\KTYS9DU2\Li et al. - 2024 - Agent Hospital A Simulacrum of Hospital with Evol.pdf}
}

@article{liangLagrangeNewtonMethodEIT2019,
  title = {A {{Lagrange-Newton Method}} for {{EIT}}/{{UT Dual-Modality Image Reconstruction}}},
  author = {Liang, Guanghui and Ren, Shangjie and Zhao, Shu and Dong, Feng},
  date = {2019-04-26},
  journaltitle = {Sensors},
  volume = {19},
  number = {9},
  pages = {1966},
  issn = {1424-8220},
  doi = {10.3390/s19091966},
  url = {https://www.mdpi.com/1424-8220/19/9/1966},
  urldate = {2024-07-08},
  abstract = {An image reconstruction method is proposed based on Lagrange-Newton method for electrical impedance tomography (EIT) and ultrasound tomography (UT) dual-modality imaging. Since the change in conductivity distribution is usually accompanied with the change in acoustic impedance distribution, the reconstruction targets of EIT and UT are unified to the conductivity difference using the same mesh model. Some background medium distribution information obtained from ultrasound transmission and reflection measurements can be used to construct a hard constraint about the conductivity difference distribution. Then, the EIT/UT dual-modality inverse problem is constructed by an equality constraint equation, and the Lagrange multiplier method combining Newton-Raphson iteration is used to solve the EIT/UT dual-modality inverse problem. The numerical and experimental results show that the proposed dual-modality image reconstruction method has a better performance than the single-modality EIT method and is more robust to the measurement noise.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\DualImageReconstruction\A_Lagrange-Newton_Method_for_EIT-UT_Dual-Modality_Image_Reconstruction_Liang_et_al_2019.pdf}
}

@article{liangMetasurfaceGeneratedLargeArbitrary2024,
  title = {Metasurface-{{Generated Large}} and {{Arbitrary Analog Convolution Kernels}} for {{Accelerated Machine Vision}}},
  author = {Liang, Ruiqi and Wang, Shuai and Dong, Yiying and Li, Liu and Kuang, Ying and Zhang, Bohan and Yang, Yuanmu},
  date = {2024-12-18},
  journaltitle = {ACS Photonics},
  volume = {11},
  number = {12},
  pages = {5430--5438},
  publisher = {American Chemical Society},
  doi = {10.1021/acsphotonics.4c01874},
  url = {https://doi.org/10.1021/acsphotonics.4c01874},
  urldate = {2025-01-04},
  abstract = {In the rapidly evolving field of artificial intelligence, convolutional neural networks are essential for tackling complex challenges, such as machine vision and medical diagnosis. Recently, to address the challenges in processing speed and power consumption of conventional digital convolution operations, many optical components have been suggested to replace the digital convolution layer in the neural network, accelerating various machine vision tasks. Nonetheless, the analogous nature of the optical convolution kernel has not been fully explored. Here, we develop a spatial frequency domain training method to create arbitrarily shaped analog convolution kernels using an optical metasurface as the convolution layer, with its receptive field largely surpassing digital convolution kernels. By employing spatial multiplexing, the multiple parallel convolution kernels with both positive and negative weights are generated under the incoherent illumination condition. We experimentally demonstrate a 98.59\% classification accuracy on the MNIST data set, with simulations showing 92.63\% and 68.67\% accuracy on the Fashion-MNIST and CIFAR-10 data sets with additional digital layers. This work underscores the unique advantage of analogue optical convolution, offering a promising avenue to accelerate machine vision tasks, especially in edge devices.},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\Photonics\\InverseDesign\\AI\\TwoAndThreeDimension\\Metasurface-Generated_Large_Liang_et_al_2024.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\Photonics\\InverseDesign\\AI\\TwoAndThreeDimension\\Metasurface-Generated_Large_Liang_et_al_22.pdf}
}

@article{liaoSimulatedAnnealingAlgorithm2023,
  title = {Simulated Annealing Algorithm with Neural Network for Designing Topological Photonic Crystals},
  author = {Liao, Yaodong and Yu, Tianen and Wang, Yueke and Dong, Boxuan and Yang, Guofeng},
  date = {2023-09-11},
  journaltitle = {Opt. Express, OE},
  volume = {31},
  number = {19},
  pages = {31597--31609},
  publisher = {Optica Publishing Group},
  issn = {1094-4087},
  doi = {10.1364/OE.500720},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-31-19-31597},
  urldate = {2024-06-21},
  abstract = {In this work, we utilize simulated annealing algorithm with neural network, to achieve rapid design of topological photonic crystals. We firstly train a high-accuracy neural network that predicts the band structure of hexagonal lattice photonic crystals. Subsequently, we embed the neural network into the simulated annealing algorithm, and choose the on-demand evaluation functions for optimizing topological band gaps. As examples, designing from the Dirac crystal of hexagonal lattice, two types of valley photonic crystals with the relative bandwidth of bandgap 26.8\% and 47.6\%, and one type of pseudospin photonic crystal with the relative bandwidth of bandgap 28.8\% are obtained. In a further way, domain walls composed of valley photonic crystals (pseudospin photonic crystals) are also proposed, and full-wave simulations are conducted to verify the valley-locked (pseudospin-locked) edge states unidirectionally propagates under the excitation of circularly polarized source. Our proposed method demonstrates the efficiency and flexibility of neural network with simulated annealing algorithm in designing topological photonic crystals.},
  langid = {english},
  keywords = {Beam splitters,Neural networks,Optical materials,Photonic crystals,Photonic devices,Resonant modes},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\Simulated_annealing_algorithm_Liao_et_al_2023.pdf}
}

@inproceedings{liDeepContextualVideo2021,
  title = {Deep {{Contextual Video Compression}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Li, Jiahao and Li, Bin and Lu, Yan},
  date = {2021},
  volume = {34},
  pages = {18114--18125},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html},
  urldate = {2024-07-04},
  abstract = {Most of the existing neural video compression methods adopt the predictive coding framework, which first generates the predicted frame and then encodes its residue with the current frame. However, as for compression ratio, predictive coding is only a sub-optimal solution as it uses simple subtraction operation to remove the redundancy across frames. In this paper, we propose a deep contextual video compression framework to enable a paradigm shift from predictive coding to conditional coding. In particular, we try to answer the following questions: how to define, use, and learn condition under a deep video compression framework. To tap the potential of conditional coding, we propose using feature domain context as condition. This enables us to leverage the high dimension context to carry rich information to both the encoder and the decoder, which helps reconstruct the high-frequency contents for higher video quality. Our framework is also extensible, in which the condition can be flexibly designed. Experiments show that our method can significantly outperform the previous state-of-the-art (SOTA) deep video compression methods. When compared with x265 using veryslow preset, we can achieve 26.0\% bitrate saving for 1080P standard test videos.},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoCodec\Deep_Contextual_Video_Compression_Li_et_al_2021.pdf}
}

@article{liDeepReinforcementLearning2023,
  title = {Deep Reinforcement Learning Empowers Automated Inverse Design and Optimization of Photonic Crystals for Nanoscale Laser Cavities},
  author = {Li, Renjie and Zhang, Ceyao and Xie, Wentao and Gong, Yuanhao and Ding, Feilong and Dai, Hui and Chen, Zihan and Yin, Feng and Zhang, Zhaoyu},
  date = {2023-01-02},
  journaltitle = {Nanophotonics},
  volume = {12},
  number = {2},
  pages = {319--334},
  publisher = {De Gruyter},
  issn = {2192-8614},
  doi = {10.1515/nanoph-2022-0692},
  url = {https://www.degruyter.com/document/doi/10.1515/nanoph-2022-0692/html},
  urldate = {2024-06-01},
  abstract = {Photonics inverse design relies on human experts to search for a design topology that satisfies certain optical specifications with their experience and intuitions, which is relatively labor-intensive, slow, and sub-optimal. Machine learning has emerged as a powerful tool to automate this inverse design process. However, supervised or semi-supervised deep learning is unsuitable for this task due to: (1) a severe shortage of available training data due to the high computational complexity of physics-based simulations along with a lack of open-source datasets and/or the need for a pre-trained neural network model; (2) the issue of one-to-many mapping or non-unique solutions; and (3) the inability to perform optimization of the photonic structure beyond inverse designing. Reinforcement Learning (RL) has the potential to overcome the above three challenges. Here, we propose Learning to Design Optical-Resonators (L2DO) to leverage RL that learns to autonomously inverse design nanophotonic laser cavities without any prior knowledge while retrieving unique design solutions. L2DO incorporates two different algorithms – Deep Q-learning and Proximal Policy Optimization. We evaluate L2DO on two laser cavities: a long photonic crystal (PC) nanobeam and a PC nanobeam with an L3 cavity, both popular structures for semiconductor lasers. Trained for less than 152 hours on limited hardware resources, L2DO has improved state-of-the-art results in the literature by over 2 orders of magnitude and obtained 10 times better performance than a human expert working the same task for over a month. L2DO first learned to meet the required maxima of Q -factors (\&gt;50 million) and then proceeded to optimize some additional good-to-have features (e.g., resonance frequency, modal volume). Compared with iterative human designs and inverse design via supervised learning, L2DO can achieve over two orders of magnitude higher sample-efficiency without suffering from the three issues above. This work confirms the potential of deep RL algorithms to surpass human designs and marks a solid step towards a fully automated AI framework for photonics inverse design.},
  langid = {english},
  keywords = {deep learning,inverse design,nanobeams,nanolasers,photonic crystals,reinforcement learning},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\OneDimension\Deep_reinforcement_learning_Li_et_al_2023.pdf}
}

@article{liDeepReinforcementLearning2023a,
  title = {Deep Reinforcement Learning Empowers Automated Inverse Design and Optimization of Photonic Crystals for Nanoscale Laser Cavities},
  author = {Li, Renjie and Zhang, Ceyao and Xie, Wentao and Gong, Yuanhao and Ding, Feilong and Dai, Hui and Chen, Zihan and Yin, Feng and Zhang, Zhaoyu},
  date = {2023-01-02},
  journaltitle = {Nanophotonics},
  volume = {12},
  number = {2},
  pages = {319--334},
  publisher = {De Gruyter},
  issn = {2192-8614},
  doi = {10.1515/nanoph-2022-0692},
  url = {https://www.degruyter.com/document/doi/10.1515/nanoph-2022-0692/html},
  urldate = {2024-06-01},
  abstract = {Photonics inverse design relies on human experts to search for a design topology that satisfies certain optical specifications with their experience and intuitions, which is relatively labor-intensive, slow, and sub-optimal. Machine learning has emerged as a powerful tool to automate this inverse design process. However, supervised or semi-supervised deep learning is unsuitable for this task due to: (1) a severe shortage of available training data due to the high computational complexity of physics-based simulations along with a lack of open-source datasets and/or the need for a pre-trained neural network model; (2) the issue of one-to-many mapping or non-unique solutions; and (3) the inability to perform optimization of the photonic structure beyond inverse designing. Reinforcement Learning (RL) has the potential to overcome the above three challenges. Here, we propose Learning to Design Optical-Resonators (L2DO) to leverage RL that learns to autonomously inverse design nanophotonic laser cavities without any prior knowledge while retrieving unique design solutions. L2DO incorporates two different algorithms – Deep Q-learning and Proximal Policy Optimization. We evaluate L2DO on two laser cavities: a long photonic crystal (PC) nanobeam and a PC nanobeam with an L3 cavity, both popular structures for semiconductor lasers. Trained for less than 152 hours on limited hardware resources, L2DO has improved state-of-the-art results in the literature by over 2 orders of magnitude and obtained 10 times better performance than a human expert working the same task for over a month. L2DO first learned to meet the required maxima of Q -factors (\&gt;50 million) and then proceeded to optimize some additional good-to-have features (e.g., resonance frequency, modal volume). Compared with iterative human designs and inverse design via supervised learning, L2DO can achieve over two orders of magnitude higher sample-efficiency without suffering from the three issues above. This work confirms the potential of deep RL algorithms to surpass human designs and marks a solid step towards a fully automated AI framework for photonics inverse design.},
  langid = {english},
  keywords = {deep learning,inverse design,nanobeams,nanolasers,photonic crystals,reinforcement learning},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\ReinforcementLearning\Deep_reinforcement_learning_empowers_automated_inverse_design_and_optimization_Li_et_al_2023.pdf}
}

@online{liDeformNetLatentSpace2024,
  title = {{{DeformNet}}: {{Latent Space Modeling}} and {{Dynamics Prediction}} for {{Deformable Object Manipulation}}},
  shorttitle = {{{DeformNet}}},
  author = {Li, Chenchang and Ai, Zihao and Wu, Tong and Li, Xiaosa and Ding, Wenbo and Xu, Huazhe},
  date = {2024-02-12},
  eprint = {2402.07648},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.07648},
  url = {http://arxiv.org/abs/2402.07648},
  urldate = {2024-02-14},
  abstract = {Manipulating deformable objects is a ubiquitous task in household environments, demanding adequate representation and accurate dynamics prediction due to the objects' infinite degrees of freedom. This work proposes DeformNet, which utilizes latent space modeling with a learned 3D representation model to tackle these challenges effectively. The proposed representation model combines a PointNet encoder and a conditional neural radiance field (NeRF), facilitating a thorough acquisition of object deformations and variations in lighting conditions. To model the complex dynamics, we employ a recurrent state-space model (RSSM) that accurately predicts the transformation of the latent representation over time. Extensive simulation experiments with diverse objectives demonstrate the generalization capabilities of DeformNet for various deformable object manipulation tasks, even in the presence of previously unseen goals. Finally, we deploy DeformNet on an actual UR5 robotic arm to demonstrate its capability in real-world scenarios.},
  pubstate = {prepublished},
  keywords = {Computer Science - Robotics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\DeformableObject\DeformNet_Li_et_al_2024.pdf}
}

@article{liDetectionHeterogeneousCells2022,
  title = {Detection of {{Heterogeneous Cells}} in {{Cell Spheroids}} by {{Applying High-Frequency Second-Order Sensitivity Matrix Electrical Impedance Tomography}} ({{HSSM-EIT}})},
  author = {Li, Songshi and Kawashima, Daisuke and Gao, Zengfeng and Takei, Masahiro},
  date = {2022},
  journaltitle = {IEEE Open J. Instrum. Meas.},
  volume = {1},
  pages = {1--9},
  issn = {2768-7236},
  doi = {10.1109/OJIM.2022.3212753},
  url = {https://ieeexplore.ieee.org/document/9913651/},
  urldate = {2024-07-08},
  abstract = {The high-frequency second-order sensitivity matrix electrical impedance tomography (HSSM-EIT) method has been proposed to detect heterogeneous cells in cell spheroids by coupling the high-frequency and second-order sensitivity matrix electrical impedance tomography (EIT). The sensitivity matrix with the first and second-order terms of Taylor’s formula (Jacobian and Hessian) is applied to the image reconstruction of cell spheroids with the high-frequency injected current at 1 MHz, at which the impedance reflects intracellular contents to visualize the cytoplasm conductivity distribution of cell spheroids. The cell spheroids with five composition percentages of the wild type (WT) and green fluorescent protein type (GFPT) of MRC-5 human lung fibroblast cell line are 100/0\%, 75/25\%, 50/50\%, 25/75\%, and 0/100\%, and were cultured to mimic heterogeneous cells. As a result, the cell spheroid images reconstructed by HSSM-EIT clearly visualize the heterogeneity stage rather than the images reconstructed by general first-order sensitivity matrix EIT; moreover, the cytoplasm conductivity of the cell spheroid is decreased with the increase of GFPT percentage. In order to confirm the cytoplasm conductivity reconstructed by HSSM-EIT, an equivalent circuit model containing a cell spheroid and extracellular fluid is employed to calculate the cytoplasm conductivity σ cyto from the measurement of electrochemical impedance spectroscopy. The result shows that σ cyto is also decreased with the increase of GFPT percentage, which shows the same trend as the cytoplasm conductivity reconstructed by HSSM-EIT.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\CellCulture\Detection_of_Heterogeneous_Cells_in_Cell_Spheroids_by_Applying_High-Frequency_Li_et_al_2022.pdf}
}

@online{lieberJambaHybridTransformerMamba2024,
  title = {Jamba: {{A Hybrid Transformer-Mamba Language Model}}},
  shorttitle = {Jamba},
  author = {Lieber, Opher and Lenz, Barak and Bata, Hofit and Cohen, Gal and Osin, Jhonathan and Dalmedigos, Itay and Safahi, Erez and Meirom, Shaked and Belinkov, Yonatan and Shalev-Shwartz, Shai and Abend, Omri and Alon, Raz and Asida, Tomer and Bergman, Amir and Glozman, Roman and Gokhman, Michael and Manevich, Avashalom and Ratner, Nir and Rozen, Noam and Shwartz, Erez and Zusman, Mor and Shoham, Yoav},
  date = {2024-03-28},
  eprint = {2403.19887},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.19887},
  url = {http://arxiv.org/abs/2403.19887},
  urldate = {2024-04-13},
  abstract = {We present Jamba, a new base large language model based on a novel hybrid Transformer-Mamba mixture-of-experts (MoE) architecture. Specifically, Jamba interleaves blocks of Transformer and Mamba layers, enjoying the benefits of both model families. MoE is added in some of these layers to increase model capacity while keeping active parameter usage manageable. This flexible architecture allows resource- and objective-specific configurations. In the particular configuration we have implemented, we end up with a powerful model that fits in a single 80GB GPU. Built at large scale, Jamba provides high throughput and small memory footprint compared to vanilla Transformers, and at the same time state-of-the-art performance on standard language model benchmarks and long-context evaluations. Remarkably, the model presents strong results for up to 256K tokens context length. We study various architectural decisions, such as how to combine Transformer and Mamba layers, and how to mix experts, and show that some of them are crucial in large scale modeling. We also describe several interesting properties of these architectures which the training and evaluation of Jamba have revealed, and plan to release checkpoints from various ablation runs, to encourage further exploration of this novel architecture. We make the weights of our implementation of Jamba publicly available under a permissive license.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\StateSpaceModels\Jamba_Lieber_et_al_2024.pdf}
}

@article{liHumanMachineCollaborative2024,
  title = {Human–{{Machine Collaborative Image Compression Method Based}} on {{Implicit Neural Representations}}},
  author = {Li, Huanyang and Zhang, Xinfeng},
  date = {2024-06},
  journaltitle = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
  volume = {14},
  number = {2},
  pages = {198--208},
  issn = {2156-3365},
  doi = {10.1109/JETCAS.2024.3386639},
  url = {https://ieeexplore.ieee.org/document/10495030?denied=},
  urldate = {2024-08-19},
  abstract = {With the explosive increase in the volume of images intended for analysis by AI, image coding for machine have been proposed to transmit information in a machine-interpretable format, thereby enhancing image compression efficiency. However, such efficient coding schemes often lead to issues like loss of image details and features, and unclear semantic information due to high data compression ratio, making them less suitable for human vision domains. Thus, it is a critical problem to balance image visual quality and machine vision accuracy at a given compression ratio. To address these issues, we introduce a human-machine collaborative image coding framework based on Implicit Neural Representations (INR), which effectively reduces the transmitted information for machine vision tasks at the decoding side while maintaining high-efficiency image compression for human vision against INR compression framework. To enhance the model’s perception of images for machine vision, we design a semantic embedding enhancement module to assist in understanding image semantics. Specifically, we employ the Swin Transformer model to initialize image features, ensuring that the embedding of the compression model are effectively applicable to downstream visual tasks. Extensive experimental results demonstrate that our method significantly outperforms other image compression methods in classification tasks while ensuring image compression efficiency.},
  eventtitle = {{{IEEE Journal}} on {{Emerging}} and {{Selected Topics}} in {{Circuits}} and {{Systems}}},
  keywords = {Image coding,image coding for machine,Image compression,implicit neural representation,Machine vision,Semantics,Standards,Task analysis,Transform coding,Visualization},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Human–Machine_Collaborative_Li_Zhang_2024.pdf}
}

@inproceedings{liHybridSpatialTemporalEntropy2022,
  title = {Hybrid {{Spatial-Temporal Entropy Modelling}} for {{Neural Video Compression}}},
  booktitle = {Proceedings of the 30th {{ACM International Conference}} on {{Multimedia}}},
  author = {Li, Jiahao and Li, Bin and Lu, Yan},
  date = {2022-10-10},
  series = {{{MM}} '22},
  pages = {1503--1511},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3503161.3547845},
  url = {https://doi.org/10.1145/3503161.3547845},
  urldate = {2024-07-04},
  abstract = {For neural video codec, it is critical, yet challenging, to design an efficient entropy model which can accurately predict the probability distribution of the quantized latent representation. However, most existing video codecs directly use the ready-made entropy model from image codec to encode the residual or motion, and do not fully leverage the spatial-temporal characteristics in video. To this end, this paper proposes a powerful entropy model which efficiently captures both spatial and temporal dependencies. In particular, we introduce the latent prior which exploits the correlation among the latent representation to squeeze the temporal redundancy. Meanwhile, the dual spatial prior is proposed to reduce the spatial redundancy in a parallel-friendly manner. In addition, our entropy model is also versatile. Besides estimating the probability distribution, our entropy model also generates the quantization step at spatial-channel-wise. This content-adaptive quantization mechanism not only helps our codec achieve the smooth rate adjustment in single model but also improves the final rate-distortion performance by dynamic bit allocation. Experimental results show that, powered by the proposed entropy model, our neural codec can achieve 18.2\% bitrate saving on UVG dataset when compared with H.266 (VTM) using the highest compression ratio configuration. It makes a new milestone in the development of neural video codec. The codes are at https://github.com/microsoft/DCVC.},
  isbn = {978-1-4503-9203-7},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoCodec\Hybrid_Spatial-Temporal_Entropy_Modelling_for_Neural_Video_Compression_Li_et_al_2022.pdf}
}

@inproceedings{liImageReconstructionFramework2017,
  title = {An Image Reconstruction Framework Based on Deep Neural Network for Electrical Impedance Tomography},
  booktitle = {2017 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author = {Li, Xiuyan and Lu, Yang and Wang, Jianming and Dang, Xin and Wang, Qi and Duan, Xiaojie and Sun, Yukuan},
  date = {2017-09},
  pages = {3585--3589},
  issn = {2381-8549},
  doi = {10.1109/ICIP.2017.8296950},
  url = {https://ieeexplore.ieee.org/document/8296950},
  urldate = {2024-07-03},
  abstract = {Electrical impedance tomography (EIT) reconstructs the internal impedance distribution by making voltage and current measurements on the object's boundary. The image reconstruction for EIT is a non-linear inverse problem. A generalized solutions based on an inverse operator is ill-conditioned and highly sensitive to the noise. In order to improve the quality of reconstructed images, this paper presents a new framework based on deep neural network (DNN) model. We apply the stacked autoencoder (SAE) and a logistic regression (LR) layer to constitute a 4-layer DNN model. This model is trained with simulation data to obtain the relationship between voltage measurements and the corresponding conductivity distribution, and then test the trained DNN model with untrained simulation data and experimental data, respectively. The output of the network is considered as the estimate of the conductivity distribution for image reconstruction. Both simulation and experimental results show the effectiveness of the proposed framework in improving the quality of reconstructed images.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  keywords = {Conductivity,deep neural network (DNN),electrical impedance tomography (EIT),Finite element analysis,image reconstruction,Image reconstruction,logistic regression (LR),Mathematical model,quality,stacked autoencoder (SAE),Tomography,Training,Voltage measurement},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Autoencoder\An_image_reconstruction_framework_based_on_deep_neural_network_for_electrical_Li_et_al_2017.pdf}
}

@article{liIntelligentDesignSilicon2024,
  title = {The {{Intelligent Design}} of {{Silicon Photonic Devices}}},
  author = {Li, Zean and Zhou, Zhipeng and Qiu, Cheng and Chen, Yongyi and Liang, Bohan and Wang, Yubing and Liang, Lei and Lei, Yuxin and Song, Yue and Jia, Peng and Zeng, Yugang and Qin, Li and Ning, Yongqiang and Wang, Lijun},
  date = {2024},
  journaltitle = {Advanced Optical Materials},
  volume = {12},
  number = {7},
  pages = {2301337},
  issn = {2195-1071},
  doi = {10.1002/adom.202301337},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adom.202301337},
  urldate = {2024-05-31},
  abstract = {Photonic devices based on silicon waveguides are essential to versatile high-performance and low-cost photonic integrated systems. Extremely complex silicon photonic devices with hundreds or even thousands of degrees of freedom (DOF) are successfully designed and manufactured based on recent advances in data science and nanofabrication technology. At this level, conventional forward-reasoning may no longer be suitable for designing high-performance silicon photonic devices with novel functionalities since the light-matter interaction is complex and non-intuitive. Therefore, the timely development of sub-wavelength silicon photonic devices that can precisely mold the flow of light is a critical and urgent issue requiring joint engineering and scientific efforts. In this paper, an inverse design strategy based on heuristic and gradient descendant algorithms, enabling the realization of large-scale integrated devices is first introduced. Subsequently, the burgeoning deep learning technology, which offers a promising direction for the automation design of silicon photonics with a data-driven approach, is discussed. Finally, the obstacles and prospects in this emerging research direction are revealed. Detail discussions from multiple perspectives are provided. This review aims to provide general guidance and a comprehensive reference for scientists developing photonic integrated systems.},
  langid = {english},
  keywords = {deep learning,gradient optimization,heuristic algorithm,inverse design,large-scale integration,silicon photonics},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\The_Intelligent_Design_of_Li_et_al_2024.pdf}
}

@article{liLandweberIterativeImage2021,
  title = {Landweber {{Iterative Image Reconstruction Method Incorporated Deep Learning}} for {{Electrical Resistance Tomography}}},
  author = {Li, Feng and Dong, Feng and Tan, Chao},
  date = {2021},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {70},
  pages = {1--11},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2020.3038014},
  url = {https://ieeexplore.ieee.org/document/9259255/},
  urldate = {2024-07-03},
  abstract = {Electrical resistance tomography (ERT) is an efficient technology for rapid, accurate, and real-time monitoring of the dynamic of industrial process. However, due to the inherent nonlinearity and ill-posed, image reconstruction of ERT remains a challenging problem of significant importance for industrial visualization. A novel Landweber iterative reconstruction network (LIRN) that combines the mathematical structure of Landweber iterative reconstruction method with deep learning is proposed. As an iterative algorithm, the proposed method solves the problem of parameters selection, and as a deep learning method, LIRN has less dependence on incomplete databases and better generalization capabilities compared with the black box models. Each layer of the LIRN is composed of three parts: fully connected subnet, convolution subnet, and the output of the former layer. The output of the former layer is mapped to the outputs of the two subnets, which constitutes the residual module. The fully connected subnet is used to represent the gradient of the data fidelity, in which the relaxation factor vector is a learnable parameter corresponding to the weights of the subnet. The convolution subnet as a self-learning regularizer learns the image prior information. During the training process of LIRN, the relaxation factor vector and the image prior information are jointly trained and learned. The experimental and analytical results demonstrate that the proposed image reconstruction network with four layers can achieve a better reconstruction distribution than the traditional imaging methods and the existing image reconstruction algorithms based on deep learning.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Landweber_Iterative_Image_Reconstruction_Method_Incorporated_Deep_Learning_for_Li_et_al_2021.pdf}
}

@article{liLightTrappingCircularly2018,
  title = {Light Trapping and Circularly Polarization at a {{Dirac}} Point in {{2D}} Plasma Photonic Crystals},
  author = {Li, Qian and Hu, Lei and Mao, Qiuping and Jiang, Haiming and Hu, Zhijia and Xie, Kang and Wei, Zhang},
  date = {2018-03},
  journaltitle = {Optics Communications},
  volume = {410},
  pages = {431--437},
  issn = {00304018},
  doi = {10.1016/j.optcom.2017.10.049},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0030401817309690},
  urldate = {2024-01-22},
  abstract = {Light trapping at the Dirac point in 2D plasma photonic crystal has been obtained. The new localized mode, Dirac mode, is attributable to neither photonic bandgap nor total internal reflection. It exhibits a unique algebraic profile and possesses a high-Q factor resonator of about 105. The Dirac point could be modulated by tuning the filling factor, plasma frequency and plasma cyclotron frequency, respectively. When a magnetic field parallel to the wave vector is applied, Dirac modes for right circularly polarized and left circularly polarized waves could be obtained at different frequencies, and the Q factor could be tuned. This property will add more controllability and flexibility to the design and modulation of novel photonic devices. It is also valuable for the possibilities of Dirac modes in photonic crystal containing other kinds of metamaterials.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Light_trapping_and_circularly_polarization_at_a_Dirac_point_in_2D_plasma_Li_et_al_2018.pdf}
}

@article{limaModulationPhotonicStructures2005,
  title = {Modulation of Photonic Structures by Surface Acoustic Waves},
  author = {family=Lima, given=Maurício M, prefix=de, useprefix=false and Santos, Paulo V},
  date = {2005-07-01},
  journaltitle = {Rep. Prog. Phys.},
  volume = {68},
  number = {7},
  pages = {1639--1701},
  issn = {0034-4885, 1361-6633},
  doi = {10.1088/0034-4885/68/7/R02},
  url = {https://iopscience.iop.org/article/10.1088/0034-4885/68/7/R02},
  urldate = {2024-01-22},
  abstract = {This paper reviews the interaction between coherently stimulated acoustic phonons in the form of surface acoustic waves with light beams in semiconductor based photonic structures. We address the generation of surface acoustic wave modes in these structures as well as the technological aspects related to control of the propagation and spatial distribution of the acoustic fields. The microscopic mechanisms responsible for the interaction between light and surface acoustic modes in different structures are then reviewed. Particular emphasis is given to the acousto-optical interaction in semiconductor microcavities and its application in photon control. These structures exhibit high optical modulation levels under acoustic excitation and are compatible with integrated light sources and detectors.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\Modulation_of_photonic_structures_by_surface_acoustic_waves_Lima_Santos_2005.pdf}
}

@article{liModifiedThermalRadiation2002,
  title = {Modified Thermal Radiation in Three-Dimensional Photonic Crystals},
  author = {Li, Zhi-Yuan},
  date = {2002-12-23},
  journaltitle = {Phys. Rev. B},
  volume = {66},
  number = {24},
  pages = {241103},
  issn = {0163-1829, 1095-3795},
  doi = {10.1103/PhysRevB.66.241103},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.66.241103},
  urldate = {2024-06-01},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\BlackBodyRadiation\Modified_thermal_radiation_in_three-dimensional_photonic_crystals_Li_2002.pdf}
}

@article{linBARFBundleAdjustingNeural,
  title = {{{BARF}}: {{Bundle-Adjusting Neural Radiance Fields}}},
  author = {Lin, Chen-Hsuan and Ma, Wei-Chiu and Torralba, Antonio and Lucey, Simon},
  abstract = {Neural Radiance Fields (NeRF) [31] have recently gained a surge of interest within the computer vision community for its power to synthesize photorealistic novel views of realworld scenes. One limitation of NeRF, however, is its requirement of accurate camera poses to learn the scene representations. In this paper, we propose Bundle-Adjusting Neural Radiance Fields (BARF) for training NeRF from imperfect (or even unknown) camera poses — the joint problem of learning neural 3D representations and registering camera frames. We establish a theoretical connection to classical image alignment and show that coarse-to-fine registration is also applicable to NeRF. Furthermore, we show that naïvely applying positional encoding in NeRF has a negative impact on registration with a synthesis-based objective. Experiments on synthetic and real-world data show that BARF can effectively optimize the neural scene representations and resolve large camera pose misalignment at the same time. This enables view synthesis and localization of video sequences from unknown camera poses, opening up new avenues for visual localization systems (e.g. SLAM) and potential applications for dense 3D mapping and reconstruction.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\CameraParameters\BARF_Lin_et_al_.pdf}
}

@article{lindenMagneticResponseMetamaterials2004,
  title = {Magnetic {{Response}} of {{Metamaterials}} at 100 {{Terahertz}}},
  author = {Linden, Stefan and Enkrich, Christian and Wegener, Martin and Zhou, Jiangfeng and Koschny, Thomas and Soukoulis, Costas M.},
  date = {2004-11-19},
  journaltitle = {Science},
  volume = {306},
  number = {5700},
  pages = {1351--1353},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1105371},
  url = {https://www.science.org/doi/10.1126/science.1105371},
  urldate = {2023-09-05},
  abstract = {An array of single nonmagnetic metallic split rings can be used to implement a magnetic resonance, which arises from an inductor-capacitor circuit (LC) resonance, at 100-terahertz frequency. The excitation of the LC resonance in the normal-incidence geometry used in our experiments occurs through the coupling of the electric field of the incident light to the capacitance. The measured optical spectra of the nanofabricated gold structures come very close to the theoretical expectations. Additional numerical simulations show that our structures exhibit a frequency range with negative permeability for a beam configuration in which the magnetic field couples to the LC resonance. Together with an electric response that has negative permittivity, this can lead to materials with a negative index of refraction.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Magnetic_Response_of_Metamaterials_at_100_Terahertz_Linden_et_al_2004.pdf}
}

@online{liNerfAccEfficientSampling2023,
  title = {{{NerfAcc}}: {{Efficient Sampling Accelerates NeRFs}}},
  shorttitle = {{{NerfAcc}}},
  author = {Li, Ruilong and Gao, Hang and Tancik, Matthew and Kanazawa, Angjoo},
  date = {2023-05-08},
  eprint = {2305.04966},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.04966},
  urldate = {2023-07-27},
  abstract = {Optimizing and rendering Neural Radiance Fields is computationally expensive due to the vast number of samples required by volume rendering. Recent works have included alternative sampling approaches to help accelerate their methods, however, they are often not the focus of the work. In this paper, we investigate and compare multiple sampling approaches and demonstrate that improved sampling is generally applicable across NeRF variants under an unified concept of transmittance estimator. To facilitate future experiments, we develop NerfAcc, a Python toolbox that provides flexible APIs for incorporating advanced sampling methods into NeRF related methods. We demonstrate its flexibility by showing that it can reduce the training time of several recent NeRF methods by 1.5x to 20x with minimal modifications to the existing codebase. Additionally, highly customized NeRFs, such as Instant-NGP, can be implemented in native PyTorch using NerfAcc.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Sampling\NerfAcc_Li_et_al_2023.pdf}
}

@online{liNerfAccEfficientSampling2023a,
  title = {{{NerfAcc}}: {{Efficient Sampling Accelerates NeRFs}}},
  shorttitle = {{{NerfAcc}}},
  author = {Li, Ruilong and Gao, Hang and Tancik, Matthew and Kanazawa, Angjoo},
  date = {2023-05-08},
  eprint = {2305.04966},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.04966},
  urldate = {2023-07-28},
  abstract = {Optimizing and rendering Neural Radiance Fields is computationally expensive due to the vast number of samples required by volume rendering. Recent works have included alternative sampling approaches to help accelerate their methods, however, they are often not the focus of the work. In this paper, we investigate and compare multiple sampling approaches and demonstrate that improved sampling is generally applicable across NeRF variants under an unified concept of transmittance estimator. To facilitate future experiments, we develop NerfAcc, a Python toolbox that provides flexible APIs for incorporating advanced sampling methods into NeRF related methods. We demonstrate its flexibility by showing that it can reduce the training time of several recent NeRF methods by 1.5x to 20x with minimal modifications to the existing codebase. Additionally, highly customized NeRFs, such as Instant-NGP, can be implemented in native PyTorch using NerfAcc.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Sampling\NerfAcc_Li_et_al_22.pdf}
}

@online{liNeuralangeloHighFidelityNeural2023,
  title = {Neuralangelo: {{High-Fidelity Neural Surface Reconstruction}}},
  shorttitle = {Neuralangelo},
  author = {Li, Zhaoshuo and Müller, Thomas and Evans, Alex and Taylor, Russell H. and Unberath, Mathias and Liu, Ming-Yu and Lin, Chen-Hsuan},
  date = {2023-06-12},
  eprint = {2306.03092},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.03092},
  url = {http://arxiv.org/abs/2306.03092},
  urldate = {2024-02-20},
  abstract = {Neural surface reconstruction has been shown to be powerful for recovering dense 3D surfaces via image-based neural rendering. However, current methods struggle to recover detailed structures of real-world scenes. To address the issue, we present Neuralangelo, which combines the representation power of multi-resolution 3D hash grids with neural surface rendering. Two key ingredients enable our approach: (1) numerical gradients for computing higher-order derivatives as a smoothing operation and (2) coarse-to-fine optimization on the hash grids controlling different levels of details. Even without auxiliary inputs such as depth, Neuralangelo can effectively recover dense 3D surface structures from multi-view images with fidelity significantly surpassing previous methods, enabling detailed large-scale scene reconstruction from RGB video captures.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\SDF\Neuralangelo_Li_et_al_2023.pdf}
}

@inproceedings{liNeuralVideoCompression2023,
  title = {Neural {{Video Compression With Diverse Contexts}}},
  author = {Li, Jiahao and Li, Bin and Lu, Yan},
  date = {2023},
  pages = {22616--22626},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Li_Neural_Video_Compression_With_Diverse_Contexts_CVPR_2023_paper.html},
  urldate = {2024-07-04},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoCodec\Neural_Video_Compression_With_Diverse_Contexts_Li_et_al_2023.pdf}
}

@online{lingDL3DV10KLargeScaleScene2023,
  title = {{{DL3DV-10K}}: {{A Large-Scale Scene Dataset}} for {{Deep Learning-based 3D Vision}}},
  shorttitle = {{{DL3DV-10K}}},
  author = {Ling, Lu and Sheng, Yichen and Tu, Zhi and Zhao, Wentian and Xin, Cheng and Wan, Kun and Yu, Lantao and Guo, Qianyu and Yu, Zixun and Lu, Yawen and Li, Xuanmao and Sun, Xingpeng and Ashok, Rohan and Mukherjee, Aniruddha and Kang, Hao and Kong, Xiangrui and Hua, Gang and Zhang, Tianyi and Benes, Bedrich and Bera, Aniket},
  date = {2023-12-29},
  eprint = {2312.16256},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.16256},
  url = {http://arxiv.org/abs/2312.16256},
  urldate = {2024-03-13},
  abstract = {We have witnessed significant progress in deep learning-based 3D vision, ranging from neural radiance field (NeRF) based 3D representation learning to applications in novel view synthesis (NVS). However, existing scene-level datasets for deep learning-based 3D vision, limited to either synthetic environments or a narrow selection of real-world scenes, are quite insufficient. This insufficiency not only hinders a comprehensive benchmark of existing methods but also caps what could be explored in deep learning-based 3D analysis. To address this critical gap, we present DL3DV-10K, a large-scale scene dataset, featuring 51.2 million frames from 10,510 videos captured from 65 types of point-of-interest (POI) locations, covering both bounded and unbounded scenes, with different levels of reflection, transparency, and lighting. We conducted a comprehensive benchmark of recent NVS methods on DL3DV-10K, which revealed valuable insights for future research in NVS. In addition, we have obtained encouraging results in a pilot study to learn generalizable NeRF from DL3DV-10K, which manifests the necessity of a large-scale scene-level dataset to forge a path toward a foundation model for learning 3D representation. Our DL3DV-10K dataset, benchmark results, and models will be publicly accessible at https://dl3dv-10k.github.io/DL3DV-10K/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\Datasets\DL3DV-10K_Ling_et_al_2023.pdf}
}

@online{linMicrosoftCOCOCommon2015,
  title = {Microsoft {{COCO}}: {{Common Objects}} in {{Context}}},
  shorttitle = {Microsoft {{COCO}}},
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  date = {2015-02-21},
  eprint = {1405.0312},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1405.0312},
  url = {http://arxiv.org/abs/1405.0312},
  urldate = {2024-12-30},
  abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\Datasets\Microsoft_COCO_Lin_et_al_2015.pdf}
}

@article{linNeuralNetworkbasedSupervised2020,
  title = {Neural Network-Based Supervised Descent Method for {{2D}} Electrical Impedance Tomography},
  author = {Lin, Zhichao and Guo, Rui and Zhang, Ke and Li, Maokun and Yang, Fan and Xu and, Shenheng and Abubakar, Aria},
  date = {2020-08-11},
  journaltitle = {Physiol. Meas.},
  volume = {41},
  number = {7},
  pages = {074003},
  issn = {1361-6579},
  doi = {10.1088/1361-6579/ab9871},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/ab9871},
  urldate = {2024-07-03},
  abstract = {Objective: In this work, we study the application of the neural network-based supervised descent method (NN-SDM) for 2D electrical impedance tomography. Approach: The NN-SDM contains two stages: offline training and online prediction. In the offline stage, neural networks are iteratively applied to learn a sequence of descent directions for minimizing the objective function, where the training data set is generated in advance according to prior information or historical data. In the online stage, the trained neural networks are directly used to predict the descent directions. Main results: Numerical and experimental results are reported to assess the efficiency and accuracy of the NN-SDM for both model-based and pixel-based inversions. In addition, the performance of the NN-SDM is compared with the linear SDM (LSDM), an end-to-end neural network (E2E-NN) and the Gauss–Newton (GN) method. The results demonstrate that the NN-SDM achieves faster convergence than the LSDM and GN method, and achieves a stronger generalization ability than the E2E-NN. Significance: The NN-SDM combines the strong non-linear fitting ability of the neural network and good generalization capability of the supervised descent method (SDM), which also provides good flexibility to incorporate prior information and accelerates the convergence of iteration.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\MLP\Neural_network-based_supervised_descent_method_for_2D_electrical_impedance_Lin_et_al_2020.pdf}
}

@article{liNovelDeepNeural2019,
  title = {A Novel Deep Neural Network Method for Electrical Impedance Tomography},
  author = {Li, Xiuyan and Zhou, Yong and Wang, Jianming and Wang, Qi and Lu, Yang and Duan, Xiaojie and Sun, Yukuan and Zhang, Jingwan and Liu, Zongyu},
  date = {2019-10},
  journaltitle = {Transactions of the Institute of Measurement and Control},
  volume = {41},
  number = {14},
  pages = {4035--4049},
  issn = {0142-3312, 1477-0369},
  doi = {10.1177/0142331219845037},
  url = {http://journals.sagepub.com/doi/10.1177/0142331219845037},
  urldate = {2024-07-03},
  abstract = {Image reconstruction for Electrical Impedance Tomography (EIT) is a highly nonlinear and ill-posed inverse problem. It requires the design and employment of feasible reconstruction methods capable to guarantee trustworthy image generation. Deep Neural Networks (DNN) have a powerful ability to express complex nonlinear functions. This research paper introduces a novel framework based on DNN aiming to achieve EIT image reconstruction. The proposed DNN model, comprises of the following two layers, namely: The Stacked Autoencoder (SAE) and the Logistic Regression (LR). It is trained using the large lab samples which are obtained by the COMSOL simulation software (a cross platform finite elements analysis solver). The relationship between the voltage measurement and the internal conductivity distribution is determined. The untrained voltage measurement samples are used as input to the trained DNN, and the output is an estimate for image reconstruction of the internal conductivity distribution. The results show that the proposed model can achieve reliable shape and size reconstruction. When white Gaussian noise with a signal-to-noise ratio of 30, 40 and 50 were added to test set, the proposed DNN structure still has good imaging results, which proved the anti-noise capability of the network. Furthermore, the network that was trained using simulation data sets, would be applied for the EIT image reconstruction based on the experimental data that were produced after preprocessing.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\Autoencoder\A_novel_deep_neural_network_method_for_electrical_impedance_tomography_Li_et_al_2019.pdf}
}

@article{linThreedimensionalPhotoniccrystalEmitter2003,
  title = {Three-Dimensional Photonic-Crystal Emitter for Thermal Photovoltaic Power Generation},
  author = {Lin, S. Y. and Moreno, J. and Fleming, J. G.},
  date = {2003-07-14},
  journaltitle = {Applied Physics Letters},
  volume = {83},
  number = {2},
  pages = {380--382},
  issn = {0003-6951, 1077-3118},
  doi = {10.1063/1.1592614},
  url = {https://pubs.aip.org/apl/article/83/2/380/149957/Three-dimensional-photonic-crystal-emitter-for},
  urldate = {2024-06-01},
  abstract = {A three-dimensional tungsten photonic crystal is experimentally realized with a complete photonic band gap at wavelengths λ⩾3 μm. At an effective temperature of 〈T〉∼1535 K, the photonic crystal exhibits a sharp emission at λ∼1.5 μm and is promising for thermal photovoltaic (TPV) power generation. Based on the spectral radiance, a proper length scaling and a planar TPV model calculation, an optical-to-electric conversion efficiency of ∼34\% and electrical power of ∼14 W/cm2 is theoretically possible.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\BlackBodyRadiation\Three-dimensional_photonic-crystal_emitter_for_thermal_photovoltaic_power_Lin_et_al_2003.pdf}
}

@article{linWearableElectricalImpedance2022,
  title = {Wearable {{Electrical Impedance Tomography Belt With Dry Electrodes}}},
  author = {Lin, Bor-Shing and Yu, Hong-Ren and Kuo, Yu-Ting and Liu, Yu-Wei and Chen, Heng-Yin and Lin, Bor-Shyh},
  date = {2022-02},
  journaltitle = {IEEE Trans. Biomed. Eng.},
  volume = {69},
  number = {2},
  pages = {955--962},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/TBME.2021.3110527},
  url = {https://ieeexplore.ieee.org/document/9531469/},
  urldate = {2024-07-08},
  abstract = {Objective: Electrical impedance tomography (EIT) is a noninvasive imaging technology used to reconstruct the conductivity distribution in objects and the human body. Methods: In recent years, numerous EIT systems and image reconstruction algorithms have been developed. However, most of these EIT systems require conventional electrodes with conductive gels (wet electrodes) and cannot be adapted to different body types, resulting in limited applicability. Results: In this study, a wearable wireless EIT belt with dry electrodes was designed to enable EIT imaging of the human body without using wet electrodes. The specific design of the belt mechanism and dry electrodes provide the advantages of easy wear and adaptation to different body sizes. Additionally, the Gauss–Newton method was used to optimize the EIT image. Conclusion: Finally, experiments were performed on the phantom and human body to validate the performance of the proposed EIT belt. Significance: The results demonstrate that the proposed system can provide accurate location information of the objects in the EIT image and the system can be successfully applied for noninvasive measurement of the human body.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Wearable\Wearable_Electrical_Impedance_Tomography_Belt_With_Dry_Electrodes_Lin_et_al_2022.pdf}
}

@online{liOnceforAllControllableGenerative2024,
  title = {Once-for-{{All}}: {{Controllable Generative Image Compression}} with {{Dynamic Granularity Adaption}}},
  shorttitle = {Once-for-{{All}}},
  author = {Li, Anqi and Li, Feng and Liu, Yuxi and Cong, Runmin and Zhao, Yao and Bai, Huihui},
  date = {2024-12-04},
  eprint = {2406.00758},
  eprinttype = {arXiv},
  eprintclass = {eess},
  doi = {10.48550/arXiv.2406.00758},
  url = {http://arxiv.org/abs/2406.00758},
  urldate = {2024-12-23},
  abstract = {Although recent generative image compression methods have demonstrated impressive potential in optimizing the rate-distortion-perception trade-off, they still face the critical challenge of flexible rate adaption to diverse compression necessities and scenarios. To overcome this challenge, this paper proposes a Controllable Generative Image Compression framework, termed Control-GIC, the first capable of fine-grained bitrate adaption across a broad spectrum while ensuring high-fidelity and generality compression. Control-GIC is grounded in a VQGAN framework that encodes an image as a sequence of variable-length codes (i.e. VQ-indices), which can be losslessly compressed and exhibits a direct positive correlation with the bitrates. Drawing inspiration from the classical coding principle, we correlate the information density of local image patches with their granular representations. Hence, we can flexibly determine a proper allocation of granularity for the patches to achieve dynamic adjustment for VQ-indices, resulting in desirable compression rates. We further develop a probabilistic conditional decoder capable of retrieving historic encoded multi-granularity representations according to transmitted codes, and then reconstruct hierarchical granular features in the formalization of conditional probability, enabling more informative aggregation to improve reconstruction realism. Our experiments show that Control-GIC allows highly flexible and controllable bitrate adaption where the results demonstrate its superior performance over recent state-of-the-art methods.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Multimedia,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Once-for-All_Li_et_al_2024.pdf}
}

@article{liOnedimensionalConvolutionalNeural2020,
  title = {One-Dimensional Convolutional Neural Network ({{1D-CNN}}) Image Reconstruction for Electrical Impedance Tomography},
  author = {Li, Xiuyan and Lu, Rengui and Wang, Qi and Wang, Jianming and Duan, Xiaojie and Sun, Yukuan and Li, Xiaojie and Zhou, Yong},
  date = {2020-12-01},
  journaltitle = {Review of Scientific Instruments},
  volume = {91},
  number = {12},
  pages = {124704},
  issn = {0034-6748, 1089-7623},
  doi = {10.1063/5.0025881},
  url = {https://pubs.aip.org/rsi/article/91/12/124704/1021290/One-dimensional-convolutional-neural-network-1D},
  urldate = {2024-07-03},
  abstract = {In recent years, due to the strong autonomous learning ability of neural network algorithms, they have been applied for electrical impedance tomography (EIT). Although their imaging accuracy is greatly improved compared with traditional algorithms, generalization for both simulation and experimental data is required to be improved. According to the characteristics of voltage data collected in EIT, a one-dimensional convolutional neural network (1D-CNN) is proposed to solve the inverse problem of image reconstruction. Abundant samples are generated with numerical simulation to improve the edge-preservation of reconstructed images. The TensorFlow-graphics processing unit environment and Adam optimizer are used to train and optimize the network, respectively. The reconstruction results of the new network are compared with the Deep Neural Network (DNN) and 2D-CNN to prove the effectiveness and edge-preservation. The anti-noise and generalization capabilities of the new network are also validated. Furthermore, experiments with the EIT system are carried out to verify the practicability of the new network. The average image correlation coefficient of the new network increases 0.0320 and 0.0616 compared with the DNN and 2D-CNN, respectively, which demonstrates that the proposed method could give better reconstruction results, especially for the distribution of complex geometries.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\One-dimensional_convolutional_neural_network_(1D-CNN)_image_reconstruction_for_Li_et_al_2020.pdf}
}

@article{liOnedimensionalConvolutionalNeural2020a,
  title = {One-Dimensional Convolutional Neural Network ({{1D-CNN}}) Image Reconstruction for Electrical Impedance Tomography},
  author = {Li, Xiuyan and Lu, Rengui and Wang, Qi and Wang, Jianming and Duan, Xiaojie and Sun, Yukuan and Li, Xiaojie and Zhou, Yong},
  date = {2020-12-01},
  journaltitle = {Review of Scientific Instruments},
  volume = {91},
  number = {12},
  pages = {124704},
  issn = {0034-6748, 1089-7623},
  doi = {10.1063/5.0025881},
  url = {https://pubs.aip.org/rsi/article/91/12/124704/1021290/One-dimensional-convolutional-neural-network-1D},
  urldate = {2024-07-03},
  abstract = {In recent years, due to the strong autonomous learning ability of neural network algorithms, they have been applied for electrical impedance tomography (EIT). Although their imaging accuracy is greatly improved compared with traditional algorithms, generalization for both simulation and experimental data is required to be improved. According to the characteristics of voltage data collected in EIT, a one-dimensional convolutional neural network (1D-CNN) is proposed to solve the inverse problem of image reconstruction. Abundant samples are generated with numerical simulation to improve the edge-preservation of reconstructed images. The TensorFlow-graphics processing unit environment and Adam optimizer are used to train and optimize the network, respectively. The reconstruction results of the new network are compared with the Deep Neural Network (DNN) and 2D-CNN to prove the effectiveness and edge-preservation. The anti-noise and generalization capabilities of the new network are also validated. Furthermore, experiments with the EIT system are carried out to verify the practicability of the new network. The average image correlation coefficient of the new network increases 0.0320 and 0.0616 compared with the DNN and 2D-CNN, respectively, which demonstrates that the proposed method could give better reconstruction results, especially for the distribution of complex geometries.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\One-dimensional_convolutional_neural_network_(1D-CNN)_image_reconstruction_for_Li_et_al_22.pdf}
}

@article{liPhotonicBandGap2003,
  title = {Photonic {{Band Gap}} from a {{Stack}} of {{Positive}} and {{Negative Index Materials}}},
  author = {Li, Jensen and Zhou, Lei and Chan, C. T. and Sheng, P.},
  date = {2003-02-25},
  journaltitle = {Phys. Rev. Lett.},
  volume = {90},
  number = {8},
  pages = {083901},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.90.083901},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.90.083901},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\DoubleNegativeMaterial\Photonic_Band_Gap_from_a_Stack_of_Positive_and_Negative_Index_Materials_Li_et_al_2003.pdf}
}

@article{liPhotonicBandGap2003a,
  title = {Photonic {{Band Gap}} from a {{Stack}} of {{Positive}} and {{Negative Index Materials}}},
  author = {Li, Jensen and Zhou, Lei and Chan, C. T. and Sheng, P.},
  date = {2003-02-25},
  journaltitle = {Phys. Rev. Lett.},
  volume = {90},
  number = {8},
  pages = {083901},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.90.083901},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.90.083901},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Photonic_Band_Gap_from_a_Stack_of_Positive_and_Negative_Index_Materials_Li_et_al_2003.pdf}
}

@inproceedings{liResearchApplicationDeep2022,
  title = {Research and {{Application}} of {{Deep Learning}} in {{Image Recognition}}},
  booktitle = {2022 {{IEEE}} 2nd {{International Conference}} on {{Power}}, {{Electronics}} and {{Computer Applications}} ({{ICPECA}})},
  author = {Li, Yinglong},
  date = {2022-01},
  pages = {994--999},
  doi = {10.1109/ICPECA53709.2022.9718847},
  url = {https://ieeexplore.ieee.org/document/9718847},
  urldate = {2024-06-01},
  abstract = {Deep learning is a technical tool with broad application prospects and has an important role in the field of image recognition. In view of the theoretical value and practical significance of image recognition technology in promoting the development of computer vision and artificial intelligence, this paper will review and study the application of deep learning in image recognition. This paper first outlines the development of icon recognition technology, and then introduces three main learning models in deep learning: convolutional neural networks, recurrent neural networks, and generative adversarial networks, and provides a comparative analysis of these three learning models. Finally, the research results of deep learning image recognition application fields, such as face recognition, medical image recognition, and remote sensing image classification, are analyzed and discussed. This paper also analyze the development trend of deep learning in the field of image recognition, and conclude that the future development direction is the effective recognition of video images and the theoretical strengthening of models.},
  eventtitle = {2022 {{IEEE}} 2nd {{International Conference}} on {{Power}}, {{Electronics}} and {{Computer Applications}} ({{ICPECA}})},
  keywords = {Analytical models,application,Computational modeling,deep learning,Deep learning,image recognition,Image recognition,Recurrent neural networks,Training,Training data},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\ConvolutionalNeuralNetworks\Research_and_Application_of_Deep_Learning_in_Image_Recognition_Li_2022.pdf}
}

@online{liSCINeRFNeuralRadiance2024,
  title = {{{SCINeRF}}: {{Neural Radiance Fields}} from a {{Snapshot Compressive Image}}},
  shorttitle = {{{SCINeRF}}},
  author = {Li, Yunhao and Wang, Xiaodong and Wang, Ping and Yuan, Xin and Liu, Peidong},
  date = {2024-03-29},
  eprint = {2403.20018},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2403.20018},
  url = {http://arxiv.org/abs/2403.20018},
  urldate = {2024-06-12},
  abstract = {In this paper, we explore the potential of Snapshot Compressive Imaging (SCI) technique for recovering the underlying 3D scene representation from a single temporal compressed image. SCI is a cost-effective method that enables the recording of high-dimensional data, such as hyperspectral or temporal information, into a single image using low-cost 2D imaging sensors. To achieve this, a series of specially designed 2D masks are usually employed, which not only reduces storage requirements but also offers potential privacy protection. Inspired by this, to take one step further, our approach builds upon the powerful 3D scene representation capabilities of neural radiance fields (NeRF). Specifically, we formulate the physical imaging process of SCI as part of the training of NeRF, allowing us to exploit its impressive performance in capturing complex scene structures. To assess the effectiveness of our method, we conduct extensive evaluations using both synthetic data and real data captured by our SCI system. Extensive experimental results demonstrate that our proposed approach surpasses the state-of-the-art methods in terms of image reconstruction and novel view image synthesis. Moreover, our method also exhibits the ability to restore high frame-rate multi-view consistent images by leveraging SCI and the rendering capabilities of NeRF. The code is available at https://github.com/WU-CVGL/SCINeRF.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Hyperspectral\SCINeRF_Li_et_al_2024.pdf}
}

@inproceedings{liSPECNERFMultiSpectralNeural2024,
  title = {{{SPEC-NERF}}: {{Multi-Spectral Neural Radiance Fields}}},
  shorttitle = {{{SPEC-NERF}}},
  booktitle = {{{ICASSP}} 2024 - 2024 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Li, Jiabao and Li, Yuqi and Sun, Ciliang and Wang, Chong and Xiang, Jinhui},
  date = {2024-04},
  pages = {2485--2489},
  issn = {2379-190X},
  doi = {10.1109/ICASSP48485.2024.10446015},
  url = {https://ieeexplore.ieee.org/abstract/document/10446015},
  urldate = {2024-06-12},
  abstract = {We propose Multi-spectral Neural Radiance Fields(Spec-NeRF) for jointly reconstructing a multispectral radiance field and spectral sensitivity functions(SSFs) of the camera from a set of color images filtered by different filters. The proposed method focuses on modeling the physical imaging process, and applies the estimated SSFs and radiance field to synthesize novel views of multispectral scenes. In this method, the data acquisition requires only a low-cost trichromatic camera and several off-the-shelf color filters, making it more practical than using specialized 3D scanning and spectral imaging equipment. Our experiments on both synthetic and real scenario datasets demonstrate that utilizing filtered RGB images with learnable NeRF and SSFs can achieve high fidelity and promising spectral reconstruction while retaining the inherent capability of NeRF to comprehend geometric structures. Code is available at https://github.com/CPREgroup/SpecNeRF-v2.},
  eventtitle = {{{ICASSP}} 2024 - 2024 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  keywords = {Cameras,Image reconstruction,Novel view synthesis,Sensitivity,spectral reconstruction,spectral sensitivity function,Speech processing,Surface reconstruction,Surface treatment,Three-dimensional displays},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Hyperspectral\SPEC-NERF_Li_et_al_2024.pdf}
}

@article{liSpectralNeRFPhysicallyBased2024,
  title = {{{SpectralNeRF}}: {{Physically Based Spectral Rendering}} with {{Neural Radiance Field}}},
  shorttitle = {{{SpectralNeRF}}},
  author = {Li, Ru and Liu, Jia and Liu, Guanghui and Zhang, Shengping and Zeng, Bing and Liu, Shuaicheng},
  date = {2024-03-24},
  journaltitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {38},
  number = {4},
  pages = {3154--3162},
  issn = {2374-3468},
  doi = {10.1609/aaai.v38i4.28099},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/28099},
  urldate = {2024-06-12},
  abstract = {In this paper, we propose SpectralNeRF, an end-to-end Neural Radiance Field (NeRF)-based architecture for high-quality physically based rendering from a novel spectral perspective. We modify the classical spectral rendering into two main steps, 1) the generation of a series of spectrum maps spanning different wavelengths, 2) the combination of these spectrum maps for the RGB output. Our SpectralNeRF follows these two steps through the proposed multi-layer perceptron (MLP)-based architecture (SpectralMLP) and Spectrum Attention UNet (SAUNet). Given the ray origin and the ray direction, the SpectralMLP constructs the spectral radiance field to obtain spectrum maps of novel views, which are then sent to the SAUNet to produce RGB images of white-light illumination. Applying NeRF to build up the spectral rendering is a more physically-based way from the perspective of ray-tracing. Further, the spectral radiance fields decompose difficult scenes and improve the performance of NeRF-based methods. Comprehensive experimental results demonstrate the proposed SpectralNeRF is superior to recent NeRF-based methods when synthesizing new views on synthetic and real datasets. The codes and datasets are available at https://github.com/liru0126/SpectralNeRF.},
  issue = {4},
  langid = {english},
  keywords = {CV: Low Level & Physics-based Vision},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Hyperspectral\SpectralNeRF_Li_et_al_2024.pdf}
}

@article{liTopologyOptimizationPhotonic2019,
  title = {Topology {{Optimization}} of {{Photonic}} and {{Phononic Crystals}} and {{Metamaterials}}: {{A Review}}},
  shorttitle = {Topology {{Optimization}} of {{Photonic}} and {{Phononic Crystals}} and {{Metamaterials}}},
  author = {Li, Weibai and Meng, Fei and Chen, Yafeng and family=Li, given=Yang, prefix=fan, useprefix=false and Huang, Xiaodong},
  date = {2019-07},
  journaltitle = {Adv. Theory Simul.},
  volume = {2},
  number = {7},
  pages = {1900017},
  issn = {2513-0390, 2513-0390},
  doi = {10.1002/adts.201900017},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/adts.201900017},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\ReviewArticles\Topology_Optimization_of_Photonic_and_Phononic_Crystals_and_Metamaterials_Li_et_al_2019.pdf}
}

@article{liuAcoustoopticSuperlatticeModulator1997,
  title = {Acousto-Optic Superlattice Modulator Using a Fiber {{Bragg}} Grating},
  author = {Liu, W. F. and family=Russell, given=P. St. J., given-i=P{{St}}J and Dong, L.},
  date = {1997-10-01},
  journaltitle = {Opt. Lett.},
  volume = {22},
  number = {19},
  pages = {1515},
  issn = {0146-9592, 1539-4794},
  doi = {10.1364/OL.22.001515},
  url = {https://opg.optica.org/ol/abstract.cfm?uri=ol-22-19-1515},
  urldate = {2024-01-22},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\Acousto-optic_superlattice_modulator_using_a_fiber_Bragg_grating_Liu_et_al_1997.pdf}
}

@article{liuComprehensiveBenchmarkSingle2020,
  title = {A {{Comprehensive Benchmark}} for {{Single Image Compression Artifact Reduction}}},
  author = {Liu, Jiaying and Liu, Dong and Yang, Wenhan and Xia, Sifeng and Zhang, Xiaoshuai and Dai, Yuanying},
  date = {2020},
  journaltitle = {IEEE Transactions on Image Processing},
  volume = {29},
  pages = {7845--7860},
  issn = {1941-0042},
  doi = {10.1109/TIP.2020.3007828},
  url = {https://ieeexplore.ieee.org/abstract/document/9139290?casa_token=rdF1_Gq-J_4AAAAA:LAGd1bVF3cmWFwVo4IG5m3WLBfVxpSGusrnXTQA6TBFpgxS5XgAZfRoaMVczyHIx7f4uZwa3GA},
  urldate = {2024-11-25},
  abstract = {We present a comprehensive study and evaluation of existing single image compression artifact removal algorithms using a new 4K resolution benchmark. This benchmark is called the Large-Scale Ideal Ultra high-definition 4K (LIU4K), and it includes including diversified foreground objects and background scenes with rich structures. Compression artifact removal, as a common post-processing technique, aims at alleviating undesirable artifacts, such as blockiness, ringing, and banding caused by quantization and approximation in the compression process. In this work, a systematic listing of the reviewed methods is presented based on their basic models (handcrafted models and deep networks). The main contributions and novelties of these methods are highlighted, and the main development directions are summarized, including architectures, multi-domain sources, signal structures, and new targeted units. Furthermore, based on a unified deep learning configuration (i.e. same training data, loss function, optimization algorithm, etc.), we evaluate recent deep learning-based methods based on diversified evaluation measures. The experimental results show state-of-the-art performance comparisons of existing methods based on both full-reference, non-reference, and task-driven metrics. Our survey gives a comprehensive reference source for future research on single image compression artifact removal and inspires new directions in related fields.},
  eventtitle = {{{IEEE Transactions}} on {{Image Processing}}},
  keywords = {benchmark,Benchmark testing,Compression artifacts removal,deep learning,Deep learning,Image resolution,Image restoration,loop filter,Quantization (signal),side information},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\A_Comprehensive_Benchmark_for_Liu_et_al_2020.pdf}
}

@inproceedings{liuConvNet2020s2022a,
  title = {A {{ConvNet}} for the 2020s},
  author = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  date = {2022},
  pages = {11976--11986},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Liu_A_ConvNet_for_the_2020s_CVPR_2022_paper.html},
  urldate = {2024-04-11},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/Architechtures/ConvolutionalNeuralNetwork/A_ConvNet_for_the_2020s_Liu_et_al_2022.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Architechtures\\ConvolutionalNeuralNetwork\\A_ConvNet_for_the_2020s_Liu_et_al_2022.pdf}
}

@online{liuDifferentiableRobotRendering2024,
  title = {Differentiable {{Robot Rendering}}},
  author = {Liu, Ruoshi and Canberk, Alper and Song, Shuran and Vondrick, Carl},
  date = {2024-10-17},
  eprint = {2410.13851},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2410.13851},
  urldate = {2024-10-23},
  abstract = {Vision foundation models trained on massive amounts of visual data have shown unprecedented reasoning and planning skills in open-world settings. A key challenge in applying them to robotic tasks is the modality gap between visual data and action data. We introduce differentiable robot rendering, a method allowing the visual appearance of a robot body to be directly differentiable with respect to its control parameters. Our model integrates a kinematics-aware deformable model and Gaussians Splatting and is compatible with any robot form factors and degrees of freedom. We demonstrate its capability and usage in applications including reconstruction of robot poses from images and controlling robots through vision language models. Quantitative and qualitative results show that our differentiable rendering model provides effective gradients for robotic control directly from pixels, setting the foundation for the future applications of vision foundation models in robotics.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Robotics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Robotics\Differentiable_Robot_Rendering_Liu_et_al_2024.pdf}
}

@article{liuEfficientMultitaskStructureAware2021,
  title = {Efficient {{Multitask Structure-Aware Sparse Bayesian Learning}} for {{Frequency-Difference Electrical Impedance Tomography}}},
  author = {Liu, Shengheng and Huang, Yongming and Wu, Hancong and Tan, Chao and Jia, Jiabin},
  date = {2021-01},
  journaltitle = {IEEE Trans. Ind. Inf.},
  volume = {17},
  number = {1},
  pages = {463--472},
  issn = {1551-3203, 1941-0050},
  doi = {10.1109/TII.2020.2965202},
  url = {https://ieeexplore.ieee.org/document/8954757/},
  urldate = {2024-07-03},
  abstract = {Frequency-difference electrical impedance tomography (fdEIT) was originally developed to mitigate the systematic artifacts induced by modeling errors when a baseline dataset is unavailable. Instead of fine anatomical imaging, only coarse anomaly detection has been addressed in current fdEIT research mainly due to its low spatial resolution. On the other hand, there has been not enough study on fdEIT reconstruction algorithm as well. In this article, we propose an efficient and high-spatialresolution algorithm for simultaneously reconstructing multiple fdEIT frames corresponding to inject currents with multiple frequencies. The electrical impedance tomography reconstruction problem is considered within a hierarchical Bayesian framework, where both intratask spatial clustering and intertask dependency are automatically learned and exploited in an unsupervised manner. The computation is accelerated by adopting a modified marginal likelihood maximization approach. Real-data experiments are conducted to verify the recovery performance of the proposed algorithm.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\BayesianLearning\Efficient_Multitask_Structure-Aware_Sparse_Bayesian_Learning_for_Liu_et_al_2021.pdf}
}

@online{liuGEAReconstructingExpressive2024,
  title = {{{GEA}}: {{Reconstructing Expressive 3D Gaussian Avatar}} from {{Monocular Video}}},
  shorttitle = {{{GEA}}},
  author = {Liu, Xinqi and Wu, Chenming and Liu, Xing and Liu, Jialun and Wu, Jinbo and Zhao, Chen and Feng, Haocheng and Ding, Errui and Wang, Jingdong},
  date = {2024-02-26},
  eprint = {2402.16607},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.16607},
  url = {http://arxiv.org/abs/2402.16607},
  urldate = {2024-03-11},
  abstract = {This paper presents GEA, a novel method for creating expressive 3D avatars with high-fidelity reconstructions of body and hands based on 3D Gaussians. The key contributions are twofold. First, we design a two-stage pose estimation method to obtain an accurate SMPL-X pose from input images, providing a correct mapping between the pixels of a training image and the SMPL-X model. It uses an attention-aware network and an optimization scheme to align the normal and silhouette between the estimated SMPL-X body and the real body in the image. Second, we propose an iterative re-initialization strategy to handle unbalanced aggregation and initialization bias faced by Gaussian representation. This strategy iteratively redistributes the avatar's Gaussian points, making it evenly distributed near the human body surface by applying meshing, resampling and re-Gaussian operations. As a result, higher-quality rendering can be achieved. Extensive experimental analyses validate the effectiveness of the proposed model, demonstrating that it achieves state-of-the-art performance in photorealistic novel view synthesis while offering fine-grained control over the human body and hand pose. Project page: https://3d-aigc.github.io/GEA/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Video\GEA_Liu_et_al_2024.pdf}
}

@online{liuGVAReconstructingVivid2024,
  title = {{{GVA}}: {{Reconstructing Vivid 3D Gaussian Avatars}} from {{Monocular Videos}}},
  shorttitle = {{{GVA}}},
  author = {Liu, Xinqi and Wu, Chenming and Liu, Jialun and Liu, Xing and Wu, Jinbo and Zhao, Chen and Feng, Haocheng and Ding, Errui and Wang, Jingdong},
  date = {2024-03-19},
  eprint = {2402.16607},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.16607},
  url = {http://arxiv.org/abs/2402.16607},
  urldate = {2024-05-05},
  abstract = {In this paper, we present a novel method that facilitates the creation of vivid 3D Gaussian avatars from monocular video inputs (GVA). Our innovation lies in addressing the intricate challenges of delivering high-fidelity human body reconstructions and aligning 3D Gaussians with human skin surfaces accurately. The key contributions of this paper are twofold. Firstly, we introduce a pose refinement technique to improve hand and foot pose accuracy by aligning normal maps and silhouettes. Precise pose is crucial for correct shape and appearance reconstruction. Secondly, we address the problems of unbalanced aggregation and initialization bias that previously diminished the quality of 3D Gaussian avatars, through a novel surface-guided re-initialization method that ensures accurate alignment of 3D Gaussian points with avatar surfaces. Experimental results demonstrate that our proposed method achieves high-fidelity and vivid 3D Gaussian avatar reconstruction. Extensive experimental analyses validate the performance qualitatively and quantitatively, demonstrating that it achieves state-of-the-art performance in photo-realistic novel view synthesis while offering fine-grained control over the human body and hand pose. Project page: https://3d-aigc.github.io/GVA/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\DynamicScenes\GVA_Liu_et_al_2024.pdf}
}

@article{liuHyperspectralRemoteSensing2023,
  title = {Hyperspectral {{Remote Sensing Image Synthesis Based}} on {{Implicit Neural Spectral Mixing Models}}},
  author = {Liu, Liqin and Zou, Zhengxia and Shi, Zhenwei},
  date = {2023},
  journaltitle = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {61},
  pages = {1--14},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2022.3232705},
  url = {https://ieeexplore.ieee.org/abstract/document/10000408},
  urldate = {2024-06-12},
  abstract = {Hyperspectral image (HSI) synthesis, as an emerging research topic, is of great value in overcoming sensor limitations and achieving low-cost acquisition of high-resolution remote sensing HSIs. However, the linear spectral mixing model used in recent studies oversimplifies the real-world hyperspectral imaging process, making it difficult to effectively model the imaging noise and multiple reflections of the object spectrum. As a prerequisite for hyperspectral data synthesis, accurate modeling of nonlinear spectral mixtures has long been a challenge. Considering the above difficulties, we propose a novel method for modeling nonlinear spectral mixtures based on implicit neural representations (INRs) in this article. The proposed method learns from INR and adaptively implements different mixture models for each pixel according to their spectral signature and surrounding environment. Based on the above neural mixing model, we also propose a new method for HSI synthesis. Given an RGB image as input, our method can generate an accurate and physically meaningful HSI. As a set of by-products, our method can also generate subpixel-level spectral abundance as well as the solar atmosphere signature. The whole framework is trained end-to-end in a self-supervised manner. We constructed a new dataset for HSI synthesis based on a wide range of Airborne Visible Infrared Imaging Spectrometer (AVIRIS) data. Our method achieves a mean peak signal-to-noise ratio (MPSNR) of 52.36 dB and outperforms other state-of-the-art hyperspectral synthesis methods. Finally, our method shows great benefits to downstream data-driven applications. With the HSIs and abundance directly generated from low-cost RGB images, the proposed method improves the accuracy of HSI classification tasks by a large margin, particularly for those with limited training samples.},
  eventtitle = {{{IEEE Transactions}} on {{Geoscience}} and {{Remote Sensing}}},
  keywords = {Adaptive spectral mixture model,Atmospheric modeling,Data models,hyperspectral image (HSI) synthesis,Hyperspectral imaging,Image reconstruction,Image synthesis,implicit neural representation (INR),Mixture models,Reflection,remote sensing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Hyperspectral\Hyperspectral_Remote_Sensing_Image_Synthesis_Based_on_Implicit_Neural_Spectral_Liu_et_al_2023.pdf}
}

@article{liuImageReconstructionContact2018,
  title = {Image {{Reconstruction Under Contact Impedance Effect}} in {{Micro Electrical Impedance Tomography Sensors}}},
  author = {Liu, Xiayi and Yao, Jiafeng and Zhao, Tong and Obara, Hiromichi and Cui, Yahui and Takei, Masahiro},
  date = {2018-06},
  journaltitle = {IEEE Trans. Biomed. Circuits Syst.},
  volume = {12},
  number = {3},
  pages = {623--631},
  issn = {1932-4545, 1940-9990},
  doi = {10.1109/TBCAS.2018.2816946},
  url = {https://ieeexplore.ieee.org/document/8358970/},
  urldate = {2024-07-08},
  abstract = {Contact impedance has an important effect on micro electrical impedance tomography (EIT) sensors compared to conventional macro sensors. In the present work, a complex contact impedance effect ratio ξ is defined to quantitatively evaluate the effect of the contact impedance on the accuracy of the reconstructed images by micro EIT. Quality of the reconstructed image under various ξ is estimated by the phantom simulation to find the optimum algorithm. The generalized vector sampled pattern matching (GVSPM) method reveals the best image quality and the best tolerance to ξ. Moreover, the images of yeast cells sedimentary distribution in a multilayered microchannel are reconstructed by the GVSPM method under various mean magnitudes of contact impedance effect ratio |ξ|. The result shows that the best image quality that has the smallest voltage error UE = 0.581 is achieved with measurement frequency f = 1 MHz and mean magnitude |ξ| = 26. In addition, the reconstructed images of cells distribution become improper while f {$<$} 10 kHz and mean value of |ξ| {$>$} 2400.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\ContactImpedance\Image_Reconstruction_Under_Contact_Impedance_Effect_in_Micro_Electrical_Liu_et_al_2018.pdf}
}

@article{liuInverseDesignQuantum2023,
  title = {Inverse Design in Quantum Nanophotonics: Combining Local-Density-of-States and Deep Learning},
  shorttitle = {Inverse Design in Quantum Nanophotonics},
  author = {Liu, Guang-Xin and Liu, Jing-Feng and Zhou, Wen-Jie and Li, Ling-Yan and You, Chun-Lian and Qiu, Cheng-Wei and Wu, Lin},
  date = {2023-05-02},
  journaltitle = {Nanophotonics},
  volume = {12},
  number = {11},
  pages = {1943--1955},
  publisher = {De Gruyter},
  issn = {2192-8614},
  doi = {10.1515/nanoph-2022-0746},
  url = {https://www.degruyter.com/document/doi/10.1515/nanoph-2022-0746/html},
  urldate = {2024-06-01},
  abstract = {Recent advances in inverse-design approaches for discovering optical structures based on desired functional characteristics have reshaped the landscape of nanophotonic structures, where most studies have focused on how light interacts with nanophotonic structures only. When quantum emitters (QEs), such as atoms, molecules, and quantum dots, are introduced to couple to the nanophotonic structures, the light–matter interactions become much more complicated, forming a rapidly developing field – quantum nanophotonics. Typical quantum functional characteristics depend on the intrinsic properties of the QE and its electromagnetic environment created by the nanophotonic structures, commonly represented by a scalar quantity, local-density-of-states (LDOS). In this work, we introduce a generalized inverse-design framework in quantum nanophotonics by taking LDOS as the bridge to connect the nanophotonic structures and the quantum functional characteristics. We take a simple system consisting of QEs sitting on a single multilayer shell–metal–nanoparticle (SMNP) as an example, apply fully-connected neural networks to model the LDOS of SMNP, inversely design and optimize the geometry of the SMNP based on LDOS, and realize desirable quantum characteristics in two quantum nanophotonic problems: spontaneous emission and entanglement. Our work introduces deep learning to the quantum optics domain for advancing quantum device designs; and provides a new platform for practicing deep learning to design nanophotonic structures for complex problems without a direct link between structures and functional characteristics.},
  langid = {english},
  keywords = {deep learning,entanglement dynamics,inverse design,local density of states,nanophotonics,spontaneous emission dynamics},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\Inverse_design_in_quantum_Liu_et_al_2023.pdf}
}

@online{liuKANKolmogorovArnoldNetworks2024,
  title = {{{KAN}}: {{Kolmogorov-Arnold Networks}}},
  shorttitle = {{{KAN}}},
  author = {Liu, Ziming and Wang, Yixuan and Vaidya, Sachin and Ruehle, Fabian and Halverson, James and Soljačić, Marin and Hou, Thomas Y. and Tegmark, Max},
  date = {2024-05-02},
  eprint = {2404.19756},
  eprinttype = {arXiv},
  eprintclass = {cond-mat, stat},
  doi = {10.48550/arXiv.2404.19756},
  url = {http://arxiv.org/abs/2404.19756},
  urldate = {2024-05-05},
  abstract = {Inspired by the Kolmogorov-Arnold representation theorem, we propose Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes ("neurons"), KANs have learnable activation functions on edges ("weights"). KANs have no linear weights at all -- every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability. For accuracy, much smaller KANs can achieve comparable or better accuracy than much larger MLPs in data fitting and PDE solving. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful collaborators helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs, opening opportunities for further improving today's deep learning models which rely heavily on MLPs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks,Statistics - Machine Learning},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/Architechtures/MLP/KAN_Liu_et_al_2024.pdf}
}

@inproceedings{liuLearnedImageCompression2023,
  title = {Learned {{Image Compression With Mixed Transformer-CNN Architectures}}},
  author = {Liu, Jinming and Sun, Heming and Katto, Jiro},
  date = {2023},
  pages = {14388--14397},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Learned_Image_Compression_With_Mixed_Transformer-CNN_Architectures_CVPR_2023_paper.html},
  urldate = {2024-11-26},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Learned_Image_Compression_Liu_et_al_2023.pdf}
}

@article{liuLocallyResonantSonic2000,
  title = {Locally {{Resonant Sonic Materials}}},
  author = {Liu, Zhengyou and Zhang, Xixiang and Mao, Yiwei and Zhu, Y. Y. and Yang, Zhiyu and Chan, C. T. and Sheng, Ping},
  date = {2000-09-08},
  journaltitle = {Science},
  volume = {289},
  number = {5485},
  pages = {1734--1736},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.289.5485.1734},
  url = {https://www.science.org/doi/10.1126/science.289.5485.1734},
  urldate = {2023-09-05},
  abstract = {We have fabricated sonic crystals, based on the idea of localized resonant structures, that exhibit spectral gaps with a lattice constant two orders of magnitude smaller than the relevant wavelength. Disordered composites made from such localized resonant structures behave as a material with effective negative elastic constants and a total wave reflector within certain tunable sonic frequency ranges. A 2-centimeter slab of this composite material is shown to break the conventional mass-density law of sound transmission by one or more orders of magnitude at 400 hertz.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\SpecialEffects\NegativeElasticModulus\Locally_Resonant_Sonic_Materials_Liu_et_al_2000.pdf}
}

@online{liuMeshDiffusionScorebasedGenerative2023,
  title = {{{MeshDiffusion}}: {{Score-based Generative 3D Mesh Modeling}}},
  shorttitle = {{{MeshDiffusion}}},
  author = {Liu, Zhen and Feng, Yao and Black, Michael J. and Nowrouzezahrai, Derek and Paull, Liam and Liu, Weiyang},
  date = {2023-04-15},
  eprint = {2303.08133},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2303.08133},
  urldate = {2023-08-29},
  abstract = {We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parametrization. We demonstrate the effectiveness of our model on multiple generative tasks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\MeshExtract\MeshDiffusion_Liu_et_al_2023.pdf}
}

@online{liuMoreConvNets2020s2023,
  title = {More {{ConvNets}} in the 2020s: {{Scaling}} up {{Kernels Beyond}} 51x51 Using {{Sparsity}}},
  shorttitle = {More {{ConvNets}} in the 2020s},
  author = {Liu, Shiwei and Chen, Tianlong and Chen, Xiaohan and Chen, Xuxi and Xiao, Qiao and Wu, Boqian and Kärkkäinen, Tommi and Pechenizkiy, Mykola and Mocanu, Decebal and Wang, Zhangyang},
  date = {2023-03-03},
  eprint = {2207.03620},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2207.03620},
  urldate = {2023-08-26},
  abstract = {Transformers have quickly shined in the computer vision world since the emergence of Vision Transformers (ViTs). The dominant role of convolutional neural networks (CNNs) seems to be challenged by increasingly effective transformer-based models. Very recently, a couple of advanced convolutional models strike back with large kernels motivated by the local but large attention mechanism, showing appealing performance and efficiency. While one of them, i.e. RepLKNet, impressively manages to scale the kernel size to 31×31 with improved performance, the performance starts to saturate as the kernel size continues growing, compared to the scaling trend of advanced ViTs such as Swin Transformer. In this paper, we explore the possibility of training extreme convolutions larger than 31×31 and test whether the performance gap can be eliminated by strategically enlarging convolutions. This study ends up with a recipe for applying extremely large kernels from the perspective of sparsity, which can smoothly scale up kernels to 61×61 with better performance. Built on this recipe, we propose Sparse Large Kernel Network (SLaK), a pure CNN architecture equipped with 51×51 kernels that can perform on par with or better than state-of-the-art hierarchical Transformers and modern ConvNet architectures like ConvNeXt and RepLKNet, on ImageNet classification as well as typical downstream tasks.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\More_ConvNets_in_the_2020s_Liu_et_al_2023.pdf}
}

@article{liuPyEITPythonBased2018,
  title = {{{pyEIT}}: {{A}} Python Based Framework for {{Electrical Impedance Tomography}}},
  shorttitle = {{{pyEIT}}},
  author = {Liu, Benyuan and Yang, Bin and Xu, Canhua and Xia, Junying and Dai, Meng and Ji, Zhenyu and You, Fusheng and Dong, Xiuzhen and Shi, Xuetao and Fu, Feng},
  date = {2018-01},
  journaltitle = {SoftwareX},
  volume = {7},
  pages = {304--308},
  issn = {23527110},
  doi = {10.1016/j.softx.2018.09.005},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352711018301407},
  urldate = {2024-07-08},
  abstract = {We present a Python-based, open source Electrical Impedance Tomography (EIT) library called pyEIT. It is a multiplatform software released under the Apache License v2.0. pyEIT has a clean architecture and is well documented. It implements state-of-the-art EIT imaging algorithms and is also capable of simple 2D/3D meshing. pyEIT is written in Python. It accelerates the analysis of offline EIT data and can be incorporated into clinical EIT applications. In this paper, we focus on illustrating the fundamental design principles of pyEIT by using some intuitive examples about EIT forward computing and inverse solving.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\pyEIT\pyEIT_Liu_et_al_2018.pdf}
}

@article{liuRefractiveIndexDistribution,
  title = {Refractive {{Index Distribution}} of {{Single Cell}} and {{Bacterium Usingan Optical Diffraction Tomography System}}},
  author = {Liu, Yang Patricia},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\BioMaterial\Refractive_Index_Distribution_of_Single_Cell_and_Bacterium_Usingan_Optical_Liu_.pdf}
}

@article{liuReviewAcousticMetamaterials2020,
  title = {A {{Review}} of {{Acoustic Metamaterials}} and {{Phononic Crystals}}},
  author = {Liu, Junyi and Guo, Hanbei and Wang, Ting},
  date = {2020-04-15},
  journaltitle = {Crystals},
  volume = {10},
  number = {4},
  pages = {305},
  issn = {2073-4352},
  doi = {10.3390/cryst10040305},
  url = {https://www.mdpi.com/2073-4352/10/4/305},
  urldate = {2023-09-05},
  abstract = {As a new kind of artificial material developed in recent decades, metamaterials exhibit novel performance and the promising application potentials in the field of practical engineering compared with the natural materials. Acoustic metamaterials and phononic crystals have some extraordinary physical properties, effective negative parameters, band gaps, negative refraction, etc., extending the acoustic properties of existing materials. The special physical properties have attracted the attention of researchers, and great progress has been made in engineering applications. This article summarizes the research on acoustic metamaterials and phononic crystals in recent decades, briefly introduces some representative studies, including equivalent acoustic parameters and extraordinary characteristics of metamaterials, explains acoustic metamaterial design methods, and summarizes the technical bottlenecks and application prospects.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\ReviewArticles\A_Review_of_Acoustic_Metamaterials_and_Phononic_Crystals_Liu_et_al_2020.pdf}
}

@article{liuShapeDrivenEITReconstruction2021,
  title = {Shape-{{Driven EIT Reconstruction Using Fourier Representations}}},
  author = {Liu, Dong and Gu, Danping and Smyl, Danny and Khambampati, Anil Kumar and Deng, Jiansong and Du, Jiangfeng},
  date = {2021-02},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {40},
  number = {2},
  pages = {481--490},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2020.3030024},
  url = {https://ieeexplore.ieee.org/document/9220135/},
  urldate = {2024-07-05},
  abstract = {Shape-driven approaches have been proposed as an effective strategy for the electrical impedance tomography (EIT) reconstruction problem in recent years. In order to augment the shape-driven approaches, we propose a new method that transforms the shape to be reconstructed as basic primitives directly modeled by using Fourier representations. To allow automatic topological changes between the basic primitives and surrounding objects simultaneously, Boolean operations are employed. The Boolean operations with direct representation of primitives can be utilized for dimensionality and ill-posedness reduction, enabling feasible shape and topology optimization with shape-driven approaches. As a proof of principle, we leverage the proposed method for two dimensional shape reconstruction in EIT with various conductivity distributions. We demonstrate that our method is able to improve EIT reconstructions by enabling accurate shape and topology optimization.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Fourier\Shape-Driven_EIT_Reconstruction_Using_Fourier_Representations_Liu_et_al_2021.pdf}
}

@article{liuShapeTopologyOptimization2021,
  title = {Shape and Topology Optimization in Electrical Impedance Tomography via Moving Morphable Components Method},
  author = {Liu, Dong and Du, Jiangfeng},
  date = {2021-08},
  journaltitle = {Struct Multidisc Optim},
  volume = {64},
  number = {2},
  pages = {585--598},
  issn = {1615-147X, 1615-1488},
  doi = {10.1007/s00158-021-02970-8},
  url = {https://link.springer.com/10.1007/s00158-021-02970-8},
  urldate = {2024-07-08},
  abstract = {This paper addresses the challenge of reconstructing multiphase conductivity distributions using electrical impedance tomography (EIT). The reconstruction method developed in the paper utilizes the moving morphable component (MMC) approach, where the unknown inclusion(s) to be reconstructed is (are) composed of several candidate morphable components. This work introduces a signed distance-based shape and topology description function (STDF) in lieu of the recently developed hyperelliptic STDF in the MMC approach, thereby absolving the requirement of exponent values. The MMC approach uses explicit geometric entities for the morphable components that are controlled by geometric parameters, such as varying thickness, length, and angle. The optimal inclusion shapes are found by optimizing these geometric parameters in STDFs. Numerical simulation and water tank experiments are used to demonstrate the effectiveness of the proposed method.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\TopologyOptimization\Shape_and_topology_optimization_in_electrical_impedance_tomography_via_moving_Liu_Du_2021.pdf}
}

@article{liuTacklingPhotonicInverse2021,
  title = {Tackling {{Photonic Inverse Design}} with {{Machine Learning}}},
  author = {Liu, Zhaocheng and Zhu, Dayu and Raju, Lakshmi and Cai, Wenshan},
  date = {2021},
  journaltitle = {Advanced Science},
  volume = {8},
  number = {5},
  pages = {2002923},
  issn = {2198-3844},
  doi = {10.1002/advs.202002923},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202002923},
  urldate = {2024-06-01},
  abstract = {Machine learning, as a study of algorithms that automate prediction and decision-making based on complex data, has become one of the most effective tools in the study of artificial intelligence. In recent years, scientific communities have been gradually merging data-driven approaches with research, enabling dramatic progress in revealing underlying mechanisms, predicting essential properties, and discovering unconventional phenomena. It is becoming an indispensable tool in the fields of, for instance, quantum physics, organic chemistry, and medical imaging. Very recently, machine learning has been adopted in the research of photonics and optics as an alternative approach to address the inverse design problem. In this report, the fast advances of machine-learning-enabled photonic design strategies in the past few years are summarized. In particular, deep learning methods, a subset of machine learning algorithms, dealing with intractable high degrees-of-freedom structure design are focused upon.},
  langid = {english},
  keywords = {inverse design,machine learning,nanophotonics,neural networks},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\ConvolutionalNeuralNetworks\Tackling_Photonic_Inverse_Design_with_Machine_Learning_Liu_et_al_2021.pdf}
}

@online{liuUnifiedEndtoEndFramework2020,
  title = {A {{Unified End-to-End Framework}} for {{Efficient Deep Image Compression}}},
  author = {Liu, Jiaheng and Lu, Guo and Hu, Zhihao and Xu, Dong},
  date = {2020-05-23},
  eprint = {2002.03370},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2002.03370},
  url = {http://arxiv.org/abs/2002.03370},
  urldate = {2024-11-25},
  abstract = {Image compression is a widely used technique to reduce the spatial redundancy in images. Recently, learning based image compression has achieved significant progress by using the powerful representation ability from neural networks. However, the current state-of-the-art learning based image compression methods suffer from the huge computational cost, which limits their capacity for practical applications. In this paper, we propose a unified framework called Efficient Deep Image Compression (EDIC) based on three new technologies, including a channel attention module, a Gaussian mixture model and a decoder-side enhancement module. Specifically, we design an auto-encoder style network for learning based image compression. To improve the coding efficiency, we exploit the channel relationship between latent representations by using the channel attention module. Besides, the Gaussian mixture model is introduced for the entropy model and improves the accuracy for bitrate estimation. Furthermore, we introduce the decoder-side enhancement module to further improve image compression performance. Our EDIC method can also be readily incorporated with the Deep Video Compression (DVC) framework to further improve the video compression performance. Simultaneously, our EDIC method boosts the coding performance significantly while bringing slightly increased computational cost. More importantly, experimental results demonstrate that the proposed approach outperforms the current state-of-the-art image compression methods and is up to more than 150 times faster in terms of decoding speed when compared with Minnen's method. The proposed framework also successfully improves the performance of the recent deep video compression system DVC. Our code will be released at https://github.com/liujiaheng/compression.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\A_Unified_End-to-End_Liu_et_al_2020.pdf}
}

@article{liyunraoEfficientImprovementModified1999,
  title = {An Efficient Improvement of Modified {{Newton-Raphson}} Algorithm for Electrical Impedance Tomography},
  author = {{Liyun Rao} and {Renjie He} and {Youhua Wang} and {Weili Yan} and {Jing Bai} and {Datian Ye}},
  date = {1999-05},
  journaltitle = {IEEE Trans. Magn.},
  volume = {35},
  number = {3},
  pages = {1562--1565},
  issn = {00189464},
  doi = {10.1109/20.767269},
  url = {http://ieeexplore.ieee.org/document/767269/},
  urldate = {2024-07-05},
  abstract = {An efficient improvement, based on the idea of homotopy, is proposed to improve and ensure the convergence of the modified Newton-Raphson algorithm through the continuous mapping of solution space, and the behavior of solution is restrained towards the global convergence after several initial solution mappiegs. Comparisons of new algorithm with MNR are presented, and the advantage of new algorithm is demonstrated for the problem of electrical impedance tomography.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\NewtonRaphson\An_efficient_improvement_of_modified_Newton-Raphson_algorithm_for_electrical_Liyun_Rao_et_al_1999.pdf}
}

@book{loggAutomatedSolutionDifferential2012,
  title = {Automated {{Solution}} of {{Differential Equations}} by the {{Finite Element Method}}: {{The FEniCS Book}}},
  shorttitle = {Automated {{Solution}} of {{Differential Equations}} by the {{Finite Element Method}}},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth},
  date = {2012},
  series = {Lecture {{Notes}} in {{Computational Science}} and {{Engineering}}},
  volume = {84},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-23099-8},
  url = {https://link.springer.com/10.1007/978-3-642-23099-8},
  urldate = {2024-07-08},
  isbn = {978-3-642-23098-1 978-3-642-23099-8},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Modeling\FiniteElementMethod\Automated_Solution_of_Differential_Equations_by_the_Finite_Element_Method_Logg_et_al_2012.pdf}
}

@article{longWideangleAsymmetricAcoustic2017,
  title = {Wide-Angle Asymmetric Acoustic Absorber Based on One-Dimensional Lossy {{Bragg}} Stacks},
  author = {Long, Houyou and Cheng, Ying and Zhang, Ting and Liu, Xiaojun},
  date = {2017-07-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  volume = {142},
  number = {1},
  pages = {EL69-EL74},
  issn = {0001-4966, 1520-8524},
  doi = {10.1121/1.4991677},
  url = {https://pubs.aip.org/jasa/article/142/1/EL69/662512/Wide-angle-asymmetric-acoustic-absorber-based-on},
  urldate = {2023-09-05},
  abstract = {Based on one-dimensional lossy Bragg stacks, an asymmetric absorber is realized for low-frequency sound waves, that is, perfect absorption can be obtained when sound waves are normally incident from one side while a small absorption can be obtained from the opposite side. Moreover, the asymmetric absorption persists for a wide incident angle of sound waves in the range from 0  to 42  with the absorptive coefficient larger than 90\% from one side while less than 20\% from the other side. By changing the thickness of the top sublayer, a series of interesting absorption phenomena such as Fano-resonance type absorption are further investigated.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Wide-angle_asymmetric_acoustic_absorber_based_on_one-dimensional_lossy_Bragg_Long_et_al_2017.pdf}
}

@article{lopesAdaptiveContextModeling2022,
  title = {Adaptive {{Context Modeling}} for {{Arithmetic Coding Using Perceptrons}}},
  author = {Lopes, Lucas S. and Chou, Philip A. and family=Queiroz, given=Ricardo L., prefix=de, useprefix=true},
  date = {2022},
  journaltitle = {IEEE Signal Processing Letters},
  volume = {29},
  pages = {2382--2386},
  issn = {1558-2361},
  doi = {10.1109/LSP.2022.3223314},
  url = {https://ieeexplore.ieee.org/document/9954621/?arnumber=9954621},
  urldate = {2024-10-07},
  abstract = {Arithmetic coding is used in most media compression methods. Context modeling is usually done through frequency counting and look-up tables (LUTs). For long-memory signals, probability modeling with large context sizes is often infeasible. Recently, neural networks have been used to model probabilities of large contexts in order to drive arithmetic coders. These neural networks have been trained offline. We introduce an online method for training a perceptron-based context-adaptive arithmetic coder on-the-fly, called adaptive perceptron coding, which continuously learns the context probabilities and quickly converges to the signal statistics. We test adaptive perceptron coding over a binary image database, with results always exceeding the performance of LUT-based methods for large context sizes and of recurrent neural networks. We also compare the method to a version requiring offline training, which leads to equally satisfactory results.},
  eventtitle = {{{IEEE Signal Processing Letters}}},
  keywords = {Adaptation models,Adaptive arithmetic coding,Codes,Context modeling,Encoding,neural context modeling,Symbols,Table lookup,Training},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Compression\LosslessCompression\Adaptive_Context_Modeling_for_Arithmetic_Coding_Using_Perceptrons_Lopes_et_al_2022.pdf}
}

@online{lorraineATT3DAmortizedTextto3D2023,
  title = {{{ATT3D}}: {{Amortized Text-to-3D Object Synthesis}}},
  shorttitle = {{{ATT3D}}},
  author = {Lorraine, Jonathan and Xie, Kevin and Zeng, Xiaohui and Lin, Chen-Hsuan and Takikawa, Towaki and Sharp, Nicholas and Lin, Tsung-Yi and Liu, Ming-Yu and Fidler, Sanja and Lucas, James},
  date = {2023-06-06},
  eprint = {2306.07349},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.07349},
  url = {http://arxiv.org/abs/2306.07349},
  urldate = {2024-05-05},
  abstract = {Text-to-3D modelling has seen exciting progress by combining generative text-to-image models with image-to-3D methods like Neural Radiance Fields. DreamFusion recently achieved high-quality results but requires a lengthy, per-prompt optimization to create 3D objects. To address this, we amortize optimization over text prompts by training on many prompts simultaneously with a unified model, instead of separately. With this, we share computation across a prompt set, training in less time than per-prompt optimization. Our framework - Amortized text-to-3D (ATT3D) - enables knowledge-sharing between prompts to generalize to unseen setups and smooth interpolations between text for novel assets and simple animations.},
  pubstate = {prepublished},
  keywords = {68T45,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,I.2.6,I.2.7,I.3.6,I.3.7},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/Reconstruction/NeuralRadianceFields/TextAndImage/ATT3D_Lorraine_et_al_2023.pdf}
}

@article{lowELECTRICALIMPEDANCETOMOGRAPHY,
  title = {{{ELECTRICAL IMPEDANCE TOMOGRAPHY FOR WEARABLE SENSORS}}: {{A DEEP CONVOLUTIONAL NEURAL NETWORK APPROACH}}},
  author = {Low, Kyle},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\ELECTRICAL_IMPEDANCE_TOMOGRAPHY_FOR_WEARABLE_SENSORS_Low_.pdf}
}

@article{lowELECTRICALIMPEDANCETOMOGRAPHYa,
  title = {{{ELECTRICAL IMPEDANCE TOMOGRAPHY FOR WEARABLE SENSORS}}: {{A DEEP CONVOLUTIONAL NEURAL NETWORK APPROACH}}},
  author = {Low, Kyle},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\ELECTRICAL_IMPEDANCE_TOMOGRAPHY_FOR_WEARABLE_SENSORS_Low_2.pdf}
}

@article{lubbersSimpleAccurateFormula1998,
  title = {A Simple and Accurate Formula for the Sound Velocity in Water},
  author = {Lubbers, J. and Graaff, R.},
  date = {1998-09},
  journaltitle = {Ultrasound in Medicine \& Biology},
  volume = {24},
  number = {7},
  pages = {1065--1068},
  issn = {03015629},
  doi = {10.1016/S0301-5629(98)00091-X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S030156299800091X},
  urldate = {2023-09-05},
  abstract = {The sound velocity in test objects and phantoms is often measured by performing a differential measurement with pure water. To promote standardization, a simple formula for the sound velocity in water is derived that renders true values within 0.20 m s؊1 over the temperature range 15–35 C. The formula is given by c ؍ 1404.3 ؉ 4.7 T ؊ 0.04 T2, with sound velocity c in m s؊1 and temperature T in C. © 1998 World Federation for Ultrasound in Medicine \& Biology.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\A_simple_and_accurate_formula_for_the_sound_velocity_in_water_Lubbers_Graaff_1998.pdf}
}

@online{luceDCGDifferentiableConnected2024,
  title = {{{dCG}} -- Differentiable Connected Geometries for {{AI-compatible}} Multi-Domain Optimization and Inverse Design},
  author = {Luce, Alexander and Grünbaum, Daniel and Marquardt, Florian},
  date = {2024-11-25},
  eprint = {2410.05833},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2410.05833},
  url = {http://arxiv.org/abs/2410.05833},
  urldate = {2024-12-15},
  abstract = {In the domain of geometry and topology optimization, discovering geometries that optimally satisfy specific problem criteria is a complex challenge in both engineering and scientific research. In this work, we propose a new approach for the creation of multidomain connected geometries that are designed to work with automatic differentiation. We introduce the concept of differentiable Connected Geometries (dCG), discussing its theoretical aspects and illustrating its application through a simple toy examples and a more sophisticated photonic optimization task. Since these geometries are built upon the principles of automatic differentiation, they are compatible with existing deep learning frameworks, a feature we demonstrate via the application examples. This methodology provides a systematic way to approach geometric design and optimization in computational fields involving dependent geometries, potentially improving the efficiency and effectiveness of optimization tasks in scientific and engineering applications.},
  pubstate = {prepublished},
  keywords = {Physics - Computational Physics},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\dCG_--_differentiable_Luce_et_al_2024.pdf}
}

@unpublished{luckaTotalVariationRegularization,
  title = {Total {{Variation Regularization}} and {{Related Topics}} - {{GV08 Optimization}} and {{Inverse Problems}} in {{Imaging}}},
  author = {Lucka, Felix},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Presentaions\Total_Variation_Regularization_and_Related_Topics_-_GV08_Optimization_and_Lucka_.pdf}
}

@online{luHierarchicalEndtoEndAutonomous2024,
  title = {Hierarchical {{End-to-End Autonomous Driving}}: {{Integrating BEV Perception}} with {{Deep Reinforcement Learning}}},
  shorttitle = {Hierarchical {{End-to-End Autonomous Driving}}},
  author = {Lu, Siyi and He, Lei and Li, Shengbo Eben and Luo, Yugong and Wang, Jianqiang and Li, Keqiang},
  date = {2024-09-26},
  eprint = {2409.17659},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2409.17659},
  url = {http://arxiv.org/abs/2409.17659},
  urldate = {2025-01-07},
  abstract = {End-to-end autonomous driving offers a streamlined alternative to the traditional modular pipeline, integrating perception, prediction, and planning within a single framework. While Deep Reinforcement Learning (DRL) has recently gained traction in this domain, existing approaches often overlook the critical connection between feature extraction of DRL and perception. In this paper, we bridge this gap by mapping the DRL feature extraction network directly to the perception phase, enabling clearer interpretation through semantic segmentation. By leveraging Bird's-Eye-View (BEV) representations, we propose a novel DRL-based end-to-end driving framework that utilizes multi-sensor inputs to construct a unified three-dimensional understanding of the environment. This BEV-based system extracts and translates critical environmental features into high-level abstract states for DRL, facilitating more informed control. Extensive experimental evaluations demonstrate that our approach not only enhances interpretability but also significantly outperforms state-of-the-art methods in autonomous driving control tasks, reducing the collision rate by 20\%.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\Hierarchical_End-to-End_Lu_et_al_2024.pdf}
}

@online{luitenDynamic3DGaussians2023,
  title = {Dynamic {{3D Gaussians}}: {{Tracking}} by {{Persistent Dynamic View Synthesis}}},
  shorttitle = {Dynamic {{3D Gaussians}}},
  author = {Luiten, Jonathon and Kopanas, Georgios and Leibe, Bastian and Ramanan, Deva},
  date = {2023-08-18},
  eprint = {2308.09713},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.09713},
  urldate = {2023-11-06},
  abstract = {We present a method that simultaneously addresses the tasks of dynamic scene novel-view synthesis and six degree-of-freedom (6-DOF) tracking of all dense scene elements. We follow an analysis-by-synthesis framework, inspired by recent work that models scenes as a collection of 3D Gaussians which are optimized to reconstruct input images via differentiable rendering. To model dynamic scenes, we allow Gaussians to move and rotate over time while enforcing that they have persistent color, opacity, and size. By regularizing Gaussians' motion and rotation with local-rigidity constraints, we show that our Dynamic 3D Gaussians correctly model the same area of physical space over time, including the rotation of that space. Dense 6-DOF tracking and dynamic reconstruction emerges naturally from persistent dynamic view synthesis, without requiring any correspondence or flow as input. We demonstrate a large number of downstream applications enabled by our representation, including first-person view synthesis, dynamic compositional scene synthesis, and 4D video editing.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\DynamicScenes\Dynamic_3D_Gaussians_Luiten_et_al_2023.pdf}
}

@article{lujan-cabreraInverseDesignIncommensurate2024,
  title = {Inverse Design of Incommensurate One-Dimensional Porous Silicon Photonic Crystals Using {{2D-convolutional}} Mixture Density Neural Networks},
  author = {Lujan-Cabrera, Ivan Alonso and Isaza, Cesar and Anaya-Rivera, Ely Karina and Ramirez-Gutierrez, Cristian Felipe},
  date = {2024-05-01},
  journaltitle = {Photonics and Nanostructures - Fundamentals and Applications},
  volume = {59},
  pages = {101260},
  issn = {1569-4410},
  doi = {10.1016/j.photonics.2024.101260},
  url = {https://www.sciencedirect.com/science/article/pii/S156944102400035X},
  urldate = {2024-06-21},
  abstract = {This work proposes an inverse design tool for porous silicon photonic structures. This tool is based on 2D-convolutional mixture density neural networks given that this type of architecture allows to tackle the nonuniqueness problem present in the optical response of photonic crystals. Moreover, a preprocessing reshaping method was implemented to use 2D-convolution neural networks due to their powerful ability in pattern recognition. A data set of porous silicon photonic spectra was generated. The photonic structures consist of 12 assembled layers of different thicknesses and porosities, generating incommensurate one-dimensional photonic crystals. The model was tested with four test data sets. First, a periodic validation was carried out, showing that incommensurate structures can generate well-defined photonic bandgaps. The second test set found that incommensurate photonic structures can resemble the optical response of a modulated photonic crystal and retrieve defective modes within the bandgap. The third test data set consisted of ideal distributed Bragg reflectors. It was found that the neural network could not predict accurate design due to the notorious differences in the optical properties of the two structures. Last, the neural network was tested with the experimental spectrum of a porous silicon photonic crystal, and it was shown that the predictions made were inaccurate because the simulations did not consider critical experimental aspects.},
  keywords = {Bandgap,Degeneration,Effective medium,Non-periodic,Reflectance},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\Inverse_design_of_Lujan-Cabrera_et_al_2024.pdf}
}

@article{lukaschewitschTikhonovRegularizationElectrical2003,
  title = {Tikhonov Regularization for Electrical Impedance Tomography on Unbounded Domains},
  author = {Lukaschewitsch, Michael and Maass, Peter and Pidcock, Michael},
  date = {2003-06-01},
  journaltitle = {Inverse Problems},
  volume = {19},
  number = {3},
  pages = {585--610},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/0266-5611/19/3/308},
  url = {https://iopscience.iop.org/article/10.1088/0266-5611/19/3/308},
  urldate = {2024-07-08},
  abstract = {The mathematical analysis of geoelectric applications leads to the inverse problem of electric impedance tomography on unbounded domains. We introduce appropriate function spaces for this setting and discuss the analytic properties of the related forward operator on unbounded domains with Lipschitz boundaries. For the numerical approximation we consider Tikhonov regularization for a finite number of measurements. The main theorem states that this yields an approximation process which converges with an optimal rate to a minimum norm solution. Finally, numerical results in two and three dimensions, which are obtained from simulated, noisy data, confirm the theoretical findings.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\TikhonovRegularization\Tikhonov_regularization_for_electrical_impedance_tomography_on_unbounded_domains_Lukaschewitsch_et_al_2003.pdf}
}

@inproceedings{luNeuralLinguisticSteganography2023,
  title = {Neural {{Linguistic Steganography}} with {{Controllable Security}}},
  booktitle = {2023 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Lu, Tianhe and Liu, Gongshen and Zhang, Ru and Ju, Tianjie},
  date = {2023-06},
  pages = {1--8},
  issn = {2161-4407},
  doi = {10.1109/IJCNN54540.2023.10191218},
  url = {https://ieeexplore.ieee.org/document/10191218},
  urldate = {2024-10-07},
  abstract = {Information hiding is an art and science with a long history and is widely used in covert communication. There are many ways to hide secret data in image, audio, and video. However, relatively few systems can hide information in text. Generative text steganography is a promising topic in natural language text infor-mation hiding. Previous generative text steganography methods use a fixed candidate pool generation rule, and they cannot effec-tively control the security of the generated text. The perceptual-imperceptibility and statistical-imperceptibility conflict effect also causes the poor quality of the steganographic text generated by previous generative text steganography methods. Moreover, pre-vious generative text steganography approaches barely discuss the robustness of steganographic text. This paper proposes a security controllable text steganography method that can generate natural-looking steganographic text with a statistical distribution that matches the natural language distribution. The proposed method combines the metrics of per-ceptual-imperceptibility and statistical-imperceptibility to calcu-late the combined distortion. It selects the tokens with the smallest combined distortion to construct a candidate pool at each time step. Moreover, the maximum combined distortion threshold is set when embedding secret messages to ensure controllable security. We conducted several experiments to evaluate the proposed model from the perspectives of embedding rate, perceptual-impercepti-bility, statistical-imperceptibility, and anti-attack ability. The ex-perimental results show that the proposed method can generate smooth and readable steganographic sentences with good re-sistance to steganalysis and high robustness.},
  eventtitle = {2023 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  keywords = {attack,controllable security,Distortion,linguistic ste-ganography,Linguistics,Measurement,Neural networks,Resistance,Statistical distributions,Steganography,text generation},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\LinguisticSteganography\Neural_Linguistic_Steganography_with_Controllable_Security_Lu_et_al_2023.pdf}
}

@article{luoExVivoStudy2022,
  title = {An {{{\emph{Ex Vivo}}}} {{Study}} of {{Outward Electrical Impedance Tomography}} ({{OEIT}}) for {{Intravascular Imaging}}},
  author = {Luo, Yuan and Huang, Dong and Huang, Zi-Yu and Hsiai, Tzung K. and Tai, Yu-Chong},
  date = {2022-02},
  journaltitle = {IEEE Trans. Biomed. Eng.},
  volume = {69},
  number = {2},
  pages = {734--745},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/TBME.2021.3104300},
  url = {https://ieeexplore.ieee.org/document/9512446/},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\IntravascularImaging\An_iEx_Vivo-i_Study_of_Outward_Electrical_Impedance_Tomography_(OEIT)_for_Luo_et_al_2022.pdf}
}

@online{luoSuperHighFidelityImageCompression2024,
  title = {Super-{{High-Fidelity Image Compression}} via {{Hierarchical-ROI}} and {{Adaptive Quantization}}},
  author = {Luo, Jixiang and Wang, Yan and Qin, Hongwei},
  date = {2024-05-21},
  eprint = {2403.13030},
  eprinttype = {arXiv},
  eprintclass = {eess},
  doi = {10.48550/arXiv.2403.13030},
  url = {http://arxiv.org/abs/2403.13030},
  urldate = {2024-12-23},
  abstract = {Learned Image Compression (LIC) has achieved dramatic progress regarding objective and subjective metrics. MSE-based models aim to improve objective metrics while generative models are leveraged to improve visual quality measured by subjective metrics. However, they all suffer from blurring or deformation at low bit rates, especially at below \$0.2bpp\$. Besides, deformation on human faces and text is unacceptable for visual quality assessment, and the problem becomes more prominent on small faces and text. To solve this problem, we combine the advantage of MSE-based models and generative models by utilizing region of interest (ROI). We propose Hierarchical-ROI (H-ROI), to split images into several foreground regions and one background region to improve the reconstruction of regions containing faces, text, and complex textures. Further, we propose adaptive quantization by non-linear mapping within the channel dimension to constrain the bit rate while maintaining the visual quality. Exhaustive experiments demonstrate that our methods achieve better visual quality on small faces and text with lower bit rates, e.g., \$0.7X\$ bits of HiFiC and \$0.5X\$ bits of BPG.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Super-High-Fidelity_Image_Luo_et_al_2024.pdf}
}

@article{luoxuanDesignOptimizationRunway2024,
  title = {Design and Optimization of a Runway Resonator Sensor Based on {{BP-NSGA II}} for Anaemic Disease},
  author = {Luoxuan, Zhang and Pinghua, Li and Jinghao, Liu and Xuye, Zhuang},
  date = {2024-01-17},
  journaltitle = {Opt Rev},
  issn = {1349-9432},
  doi = {10.1007/s10043-023-00860-6},
  url = {https://doi.org/10.1007/s10043-023-00860-6},
  urldate = {2024-01-22},
  abstract = {Optical resonators are particularly suitable for anaemia state detection due to small sample size, real-time detection and low power consumption. However, the quality factor and sensitivity of resonant cavity sensors are mutually constrained, so the single objective optimization algorithms proposed so far can only achieve a single optimization of sensitivity or quality factor, which limits chip performance. This article presents a multi-objective optimization design of the runway ring resonant cavity sensor based on the BP-NSGA II algorithm, which has achieved good performance improvement. The simultaneous incorporation of quality factor and sensitivity provides access to key structural design parameters to overcome the limitations of sensitivity and quality factor constraints on each other, thereby improving sensor performance. The results show that the optimized structure has a sensitivity of 439~nm/RIU, a quality factor of 938, a relative error of 1.37\% and 3.9\% for the sensitivity and quality factor, respectively, a linearity of 0.00004636\% for the sensitivity, and a training time of 3~min. The method has the advantages of small errors and short learning time. A new optimization method is provided for the design of the resonant cavity of a runway ring.},
  langid = {english},
  keywords = {Anemia,BP-NSGAII,Optical waveguide,Refractive index biosensor,Runway resonator},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\Resonators\Design_and_optimization_of_a_runway_resonator_sensor_based_on_BP-NSGA_II_for_Luoxuan_et_al_2024.pdf}
}

@article{luPhononicCrystalsAcoustic2009,
  title = {Phononic Crystals and Acoustic Metamaterials},
  author = {Lu, Ming-Hui and Feng, Liang and Chen, Yan-Feng},
  date = {2009-12},
  journaltitle = {Materials Today},
  volume = {12},
  number = {12},
  pages = {34--42},
  issn = {13697021},
  doi = {10.1016/S1369-7021(09)70315-3},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1369702109703153},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\ReviewArticles\Phononic_crystals_and_acoustic_metamaterials_Lu_et_al_2009.pdf}
}

@online{luTransformerbasedImageCompression2021,
  title = {Transformer-Based {{Image Compression}}},
  author = {Lu, Ming and Guo, Peiyao and Shi, Huiqing and Cao, Chuntong and Ma, Zhan},
  date = {2021-11-12},
  eprint = {2111.06707},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2111.06707},
  url = {http://arxiv.org/abs/2111.06707},
  urldate = {2024-11-27},
  abstract = {A Transformer-based Image Compression (TIC) approach is developed which reuses the canonical variational autoencoder (VAE) architecture with paired main and hyper encoder-decoders. Both main and hyper encoders are comprised of a sequence of neural transformation units (NTUs) to analyse and aggregate important information for more compact representation of input image, while the decoders mirror the encoder-side operations to generate pixel-domain image reconstruction from the compressed bitstream. Each NTU is consist of a Swin Transformer Block (STB) and a convolutional layer (Conv) to best embed both long-range and short-range information; In the meantime, a casual attention module (CAM) is devised for adaptive context modeling of latent features to utilize both hyper and autoregressive priors. The TIC rivals with state-of-the-art approaches including deep convolutional neural networks (CNNs) based learnt image coding (LIC) methods and handcrafted rules-based intra profile of recently-approved Versatile Video Coding (VVC) standard, and requires much less model parameters, e.g., up to 45\% reduction to leading-performance LIC.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Transformer-based_Image_Lu_et_al_2021.pdf}
}

@article{macdonaldSolvingPartialDifferential2024,
  title = {Solving Partial Differential Equations with Waveguide-Based Metatronic Networks},
  author = {MacDonald, Ross Glyn and Yakovlev, Alex and Pacheco-Peña, Victor},
  date = {2024-10},
  journaltitle = {APN},
  volume = {3},
  number = {5},
  pages = {056007},
  publisher = {SPIE},
  issn = {2791-1519, 2791-1519},
  doi = {10.1117/1.APN.3.5.056007},
  url = {https://www.spiedigitallibrary.org/journals/advanced-photonics-nexus/volume-3/issue-5/056007/Solving-partial-differential-equations-with-waveguide-based-metatronic-networks/10.1117/1.APN.3.5.056007.full},
  urldate = {2024-10-23},
  abstract = {Photonic computing has recently become an interesting paradigm for high-speed calculation of computing processes using light–matter interactions. Here, we propose and study an electromagnetic wave-based structure with the ability to calculate the solution of partial differential equations (PDEs) in the form of the Helmholtz wave equation, ∇2f(x,y)+k2f(x,y)=0, with k as the wavenumber. To do this, we make use of a network of interconnected waveguides filled with dielectric inserts. In so doing, it is shown how the proposed network can mimic the response of a network of T-circuit elements formed by two series and a parallel impedances, i.e., the waveguide network effectively behaves as a metatronic network. An in-depth theoretical analysis of the proposed metatronic structure is presented, showing how the governing equation for the currents and impedances of the metatronic network resembles that of the finite difference representation of the Helmholtz wave equation. Different studies are then discussed including the solution of PDEs for Dirichlet and open boundary value problems, demonstrating how the proposed metatronic-based structure has the ability to calculate their solutions.},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\Operator\Solving_partial_differential_MacDonald_et_al_2024.pdf}
}

@online{maDeblurNeRFNeuralRadiance2022,
  title = {Deblur-{{NeRF}}: {{Neural Radiance Fields}} from {{Blurry Images}}},
  shorttitle = {Deblur-{{NeRF}}},
  author = {Ma, Li and Li, Xiaoyu and Liao, Jing and Zhang, Qi and Wang, Xuan and Wang, Jue and Sander, Pedro V.},
  date = {2022-03-27},
  eprint = {2111.14292},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2111.14292},
  url = {http://arxiv.org/abs/2111.14292},
  urldate = {2024-02-14},
  abstract = {Neural Radiance Field (NeRF) has gained considerable attention recently for 3D scene reconstruction and novel view synthesis due to its remarkable synthesis quality. However, image blurriness caused by defocus or motion, which often occurs when capturing scenes in the wild, significantly degrades its reconstruction quality. To address this problem, We propose Deblur-NeRF, the first method that can recover a sharp NeRF from blurry input. We adopt an analysis-by-synthesis approach that reconstructs blurry views by simulating the blurring process, thus making NeRF robust to blurry inputs. The core of this simulation is a novel Deformable Sparse Kernel (DSK) module that models spatially-varying blur kernels by deforming a canonical sparse kernel at each spatial location. The ray origin of each kernel point is jointly optimized, inspired by the physical blurring process. This module is parameterized as an MLP that has the ability to be generalized to various blur types. Jointly optimizing the NeRF and the DSK module allows us to restore a sharp NeRF. We demonstrate that our method can be used on both camera motion blur and defocus blur: the two most common types of blur in real scenes. Evaluation results on both synthetic and real-world data show that our method outperforms several baselines. The synthetic and real datasets along with the source code is publicly available at https://limacv.github.io/deblurnerf/},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Deblur\Deblur-NeRF_Ma_et_al_2022.pdf}
}

@inproceedings{mahmoudCAwaNeRFInstantLearning2024,
  title = {{{CAwa-NeRF}}: {{Instant Learning}} of {{Compression-Aware NeRF Features}}},
  shorttitle = {{{CAwa-NeRF}}},
  booktitle = {2024 11th {{IEEE Swiss Conference}} on {{Data Science}} ({{SDS}})},
  author = {Mahmoud, Omnia and Ladune, Théo and Gendrin, Matthieu},
  date = {2024-05},
  pages = {47--54},
  issn = {2835-3420},
  doi = {10.1109/SDS60720.2024.00015},
  url = {https://ieeexplore.ieee.org/document/10675956/?arnumber=10675956},
  urldate = {2024-12-13},
  abstract = {Modeling 3D scenes by volumetric features is one of the promising directions of neural approximations to improve Neural Radiance Field (NeRF) models. Instant-NGP (INGP) introduced multi-resolution hash encoding from a lookup table of trainable feature grids which enabled learning high-quality neural graphics primitives in a matter of seconds. However, this improvement came at the cost of higher storage size. In this paper, we address this challenge by introducing instant learning of compression-aware NeRF features (CAwa-NeRF), that allows exporting the zip compressed NeRF feature grids at the end of the model training with a negligible extra time overhead without changing neither the storage architecture nor the learning model. Nonetheless, CAwa-NeRF is not limited to INGP but could also be applied to any model. CAwa-NeRF minimizes the rate of the learned features by an a simple mathematical approximation for the features entropy. By means of extensive simulations, CAwa-NeRF achieves significant results on different kinds of static scenes such as single object masked background scenes and real-life scenes captured in our studio. It can compress the features grids size down to 6\% of the original size with slight improvement in the model quality or down to 2.4\% with a negligible loss in the visual quality.},
  eventtitle = {2024 11th {{IEEE Swiss Conference}} on {{Data Science}} ({{SDS}})},
  keywords = {Adaptation models,Cameras,compression,deep-learning,hash-encoding,Mathematical models,Neural radiance field,neural radiance fields,rate-distortion,Solid modeling,Training,Visualization},
  file = {C:\Users\ahmed\Zotero\storage\BY9LWJLW\Mahmoud et al. - 2024 - CAwa-NeRF Instant Learning of Compression-Aware N.pdf}
}

@article{makarovBoundaryElementFast2021,
  title = {Boundary Element Fast Multipole Method for Modeling Electrical Brain Stimulation with Voltage and Current Electrodes},
  author = {Makarov, Sergey N and Golestanirad, Laleh and Wartman, William A and Nguyen, Bach Thanh and Noetscher, Gregory M and Ahveninen, Jyrki P and Fujimoto, Kyoko and Weise, Konstantin and Nummenmaa, Aapo R},
  date = {2021-08-01},
  journaltitle = {J. Neural Eng.},
  volume = {18},
  number = {4},
  pages = {0460d4},
  issn = {1741-2560, 1741-2552},
  doi = {10.1088/1741-2552/ac17d7},
  url = {https://iopscience.iop.org/article/10.1088/1741-2552/ac17d7},
  urldate = {2024-07-08},
  abstract = {Objective. To formulate, validate, and apply an alternative to the finite element method (FEM) high-resolution modeling technique for electrical brain stimulation—the boundary element fast multipole method (BEM-FMM). To include practical electrode models for both surface and embedded electrodes. Approach. Integral equations of the boundary element method in terms of surface charge density are combined with a general-purpose fast multipole method and are expanded for voltage, shunt, current, and floating electrodes. The solution of coupled and properly weighted/preconditioned integral equations is accompanied by enforcing global conservation laws: charge conservation law and Kirchhoff ’s current law. Main results. A sub-percent accuracy is reported as compared to the analytical solutions and simple validation geometries. Comparison to FEM considering realistic head models resulted in relative differences of the electric field magnitude in the range of 3\%–6\% or less. Quantities that contain higher order spatial derivatives, such as the activating function, are determined with a higher accuracy and a faster speed as compared to the FEM. The method can be easily combined with existing head modeling pipelines such as headreco or mri2mesh. Significance. The BEM-FMM does not rely on a volumetric mesh and is therefore particularly suitable for modeling some mesoscale problems with submillimeter (and possibly finer) resolution with high accuracy at moderate computational cost. Utilizing Helmholtz reciprocity principle makes it possible to expand the method to a solution of EEG forward problems with a very large number of cortical dipoles.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Electroencephalography(EEG)\Boundary_element_fast_multipole_method_for_modeling_electrical_brain_Makarov_et_al_2021.pdf}
}

@article{malitsonRefractionDispersionSynthetic1962,
  title = {Refraction and {{Dispersion}} of {{Synthetic Sapphire}}},
  author = {Malitson, Irving H.},
  date = {1962-12-01},
  journaltitle = {J. Opt. Soc. Am.},
  volume = {52},
  number = {12},
  pages = {1377},
  issn = {0030-3941},
  doi = {10.1364/JOSA.52.001377},
  url = {https://opg.optica.org/abstract.cfm?URI=josa-52-12-1377},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Dielectric\Refraction_and_Dispersion_of_Synthetic_Sapphire_Malitson_1962.pdf}
}

@article{maNovelViewSynthesis2024,
  title = {Novel {{View Synthesis}} and {{Dataset Augmentation}} for {{Hyperspectral Data Using NeRF}}},
  author = {Ma, Runchuan and Ma, Tengfei and Guo, Deyu and He, Sailing},
  date = {2024},
  journaltitle = {IEEE Access},
  volume = {12},
  pages = {45331--45341},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3381531},
  url = {https://ieeexplore.ieee.org/document/10478532},
  urldate = {2024-06-12},
  abstract = {Hyperspectral data for the 3D domain is relatively difficult to acquire. Existing hyperspectral datasets are unsuitable for 3D research, suffer from issues of severe data scarcity, and a lack of multi-perspective images of the same object, etc. To address these challenges, data augmentation with limited data is essential. In this study, we applied neural rendering method (such as Neural Radiance Field) to hyperspectral images for dataset augmentation. We conducted experiments on novel view synthesis for hyperspectral images from 360-degree multi-perspectives, demonstrating that our method can generate high-quality hyperspectral images from various perspectives. Through experiments involving key points extraction and 3D reconstruction, we validated the efficacy of generating a substantial volume of high-quality hyperspectral images from a restricted set of varying perspectives. These results contribute to addressing the challenges associated with data augmentation. We also conducted experiments of neural radiance fields in the hyperspectral data domain under different network parameters and training conditions to find the appropriate settings.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Cameras,Data augmentation,Dataset augmentation,hyperspectral image,Hyperspectral imaging,Image reconstruction,NeRF,novel view synthesis,Rendering (computer graphics),Three-dimensional displays,Training},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\MultiSpectral\Novel_View_Synthesis_and_Dataset_Augmentation_for_Hyperspectral_Data_Using_NeRF_Ma_et_al_2024.pdf}
}

@article{manzanares-martinezONEDIMENSIONALPHOTONICHETEROSTRUCTURE2011,
  title = {{{ONE-DIMENSIONAL PHOTONIC HETEROSTRUCTURE WITH BROADBAND OMNIDIRECTIONAL REFLECTION}}},
  author = {Manzanares-Martinez, Jesus and Archuleta-Garcia, Raul and Castro-Garay, Paola and Moctezuma-Enriquez, Damian and Urrutia-Banuelos, Efrain},
  date = {2011},
  journaltitle = {PIER},
  volume = {111},
  pages = {105--117},
  issn = {1559-8985},
  doi = {10.2528/PIER10110404},
  url = {http://www.jpier.org/PIER/pier.php?paper=10110404},
  urldate = {2024-06-01},
  abstract = {In this work we report the modeling of an one-dimensional photonic heterostructure which presents a giant omnidirectional photonic band gap. This omnidirectional reflector is made by the union of lattices with the same filling fraction and index contrast, but with different lattice periods. Using the scalability of the electromagnetic wave equation we present a simple manner to enlarge -as large as desired- the omnidirectional mirror. We apply our method to design an omnidirectional reflector for all the visible range.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Dielectric\ONE-DIMENSIONAL_PHOTONIC_HETEROSTRUCTURE_WITH_BROADBAND_OMNIDIRECTIONAL_Manzanares-Martinez_et_al_2011.pdf}
}

@online{maoPCACGANSparseTensorBasedGenerative2024,
  title = {{{PCAC-GAN}}: {{A Sparse-Tensor-Based Generative Adversarial Network}} for {{3D Point Cloud Attribute Compression}}},
  shorttitle = {{{PCAC-GAN}}},
  author = {Mao, Xiaolong and Yuan, Hui and Lu, Xin and Hamzaoui, Raouf and Gao, Wei},
  date = {2024-07-19},
  eprint = {2407.05677},
  eprinttype = {arXiv},
  eprintclass = {eess},
  doi = {10.48550/arXiv.2407.05677},
  url = {http://arxiv.org/abs/2407.05677},
  urldate = {2024-12-23},
  abstract = {Learning-based methods have proven successful in compressing geometric information for point clouds. For attribute compression, however, they still lag behind non-learning-based methods such as the MPEG G-PCC standard. To bridge this gap, we propose a novel deep learning-based point cloud attribute compression method that uses a generative adversarial network (GAN) with sparse convolution layers. Our method also includes a module that adaptively selects the resolution of the voxels used to voxelize the input point cloud. Sparse vectors are used to represent the voxelized point cloud, and sparse convolutions process the sparse tensors, ensuring computational efficiency. To the best of our knowledge, this is the first application of GANs to compress point cloud attributes. Our experimental results show that our method outperforms existing learning-based techniques and rivals the latest G-PCC test model (TMC13v23) in terms of visual quality.},
  pubstate = {prepublished},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\PCAC-GAN_Mao_et_al_2024.pdf}
}

@article{maPhotonicCrystalsBased2008,
  title = {Photonic Crystals Based on Acousto-Optic Effects},
  author = {Ma, Hua and Qu, Shaobo and Xu, Zhuo},
  date = {2008-05-15},
  journaltitle = {Journal of Applied Physics},
  volume = {103},
  number = {10},
  pages = {104904},
  issn = {0021-8979, 1089-7550},
  doi = {10.1063/1.2924432},
  url = {https://pubs.aip.org/jap/article/103/10/104904/371551/Photonic-crystals-based-on-acousto-optic-effects},
  urldate = {2024-01-22},
  abstract = {Tunable photonic crystals that are based on acousto-optic effects were proposed in this paper. Theoretical analysis and numerical simulations were carried out for the tunable photonic crystals. According to the acousto-optic effect, acoustic waves propagating in elastic media induce periodic dielectric structures in the media, and thus the media can be used as photonic crystals. Such photonic crystals possess a prominent characteristic that the photonic band gaps can be changed real-timely by adjusting the acoustic intensity and frequency. The work done in this paper opens up a possibility to achieve tunable photonic crystals on the basis of acousto-optic effects.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\Photonic_crystals_based_on_acousto-optic_effects_Ma_et_al_2008.pdf}
}

@article{marinoEfficientCompactRepresentations2023,
  title = {Efficient and {{Compact Representations}} of {{Deep Neural Networks}} via {{Entropy Coding}}},
  author = {Marinò, Giosuè Cataldo and Furia, Flavio and Malchiodi, Dario and Frasca, Marco},
  date = {2023},
  journaltitle = {IEEE Access},
  volume = {11},
  pages = {106103--106125},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3317293},
  url = {https://ieeexplore.ieee.org/document/10255645/},
  urldate = {2024-08-08},
  abstract = {Matrix operations are nowadays central in many Machine Learning techniques, including in particular Deep Neural Networks (DNNs), whose core of any inference is represented by a sequence of dot product operations. An increasingly emerging problem is how to efficiently engineer their storage and operations. In this article we propose two new lossless compression schemes for real-valued matrices, supporting efficient vector-matrix multiplications in the compressed format, and specifically suitable for DNNs compression. Exploiting several recent studies that use weight pruning and quantization techniques to reduce the complexity of DNN inference, our schemes are expressly designed to benefit from both, that is from input matrices characterized by low entropy. In particular, our solutions are able to take advantage from the depth of the model, and the deeper the model, the higher the efficiency. Moreover, we derived space upper bounds for both variants in terms of the source entropy. Experiments show that our tools favourably compare in terms of energy and space efficiency against state-of-the-art matrix compression approaches, including Compressed Linear Algebra (CLA) and Compressed Shared Elements Row (CSER), the latter explicitly proposed in the context of DNN compression.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\Data Compression\Efficient_and_Compact_Representations_of_Deep_Neural_Networks_via_Entropy_Coding_Marino_et_al_2023.pdf}
}

@inproceedings{martin-bruallaNeRFWildNeural2021,
  title = {{{NeRF}} in the {{Wild}}: {{Neural Radiance Fields}} for {{Unconstrained Photo Collections}}},
  shorttitle = {{{NeRF}} in the {{Wild}}},
  author = {Martin-Brualla, Ricardo and Radwan, Noha and Sajjadi, Mehdi S. M. and Barron, Jonathan T. and Dosovitskiy, Alexey and Duckworth, Daniel},
  date = {2021-06},
  pages = {7206--7215},
  location = {Virtual},
  doi = {10.1109/cvpr46437.2021.00713},
  url = {https://ieeexplore.ieee.org/document/9578784/},
  urldate = {2021-11-24},
  abstract = {We present a learning-based method for synthesizing novel views of complex scenes using only unstructured collections of in-the-wild photographs. We build on Neural Radiance Fields (NeRF), which uses the weights of a multilayer perceptron to model the density and color of a scene as a function of 3D coordinates. While NeRF works well on images of static subjects captured under controlled settings, it is incapable of modeling many ubiquitous, real-world phenomena in uncontrolled images, such as variable illumination or transient occluders. We introduce a series of extensions to NeRF to address these issues, thereby enabling accurate reconstructions from unstructured image collections taken from the internet. We apply our system, dubbed NeRF-W, to internet photo collections of famous landmarks, and demonstrate temporally consistent novel view renderings that are significantly closer to photorealism than the prior state of the art.},
  eventtitle = {{{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66544-509-2},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\HDR\NeRF_in_the_Wild_Martin-Brualla_et_al_2021.pdf}
}

@book{martinCleanCodeHandbook2009,
  title = {Clean Code: A Handbook of Agile Software Craftsmanship},
  shorttitle = {Clean Code},
  editor = {Martin, Robert C.},
  date = {2009},
  publisher = {Prentice Hall},
  location = {Upper Saddle River, NJ},
  isbn = {978-0-13-235088-4},
  langid = {english},
  pagetotal = {431},
  keywords = {Agile software development,Computer software,Reliability},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\Programming\Clean_code_Martin_2009.pdf}
}

@article{martinez-salaSoundAttenuationSculpture1995,
  title = {Sound Attenuation by Sculpture},
  author = {Martínez-Sala, R. and Sancho, J. and Sánchez, J. V. and Gómez, V. and Llinares, J. and Meseguer, F.},
  date = {1995-11},
  journaltitle = {Nature},
  volume = {378},
  number = {6554},
  pages = {241--241},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/378241a0},
  url = {https://www.nature.com/articles/378241a0},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\SpecialEffects\SlowWaveEffect\Sound_attenuation_by_sculpture_Martinez-Sala_et_al_1995.pdf}
}

@article{martinPostProcessingToolFeasibility,
  title = {A {{Post-Processing Tool}} and {{Feasibility Study}} for {{Three- Dimensional Imaging}} with {{Electrical Impedance Tomography During Deep Brain Stimulation Surgery}}},
  author = {Martin, Sébastien},
  abstract = {Electrical impedance tomography (EIT) is a promising technique for biomedical imaging. The strength of EIT is its ability to reconstruct images of the body’s internal structures through radiation-safe techniques. EIT is regarded as safe for patients’ health, and it is currently being actively researched. This paper investigates the application of EIT during deep brain stimulation (DBS) surgery as a means to identify targets during operations. DBS involves a surgical procedure in which a lead or electrode array is implanted in a specific target area in the brain. Electrical stimulations are then used to modulate neural circuits within the target area to reduce disabling neurological symptoms. The main difficulty in performing DBS surgery is to accurately position the lead in the target area before commencing the treatment. Brain tissue shifts during DBS surgery can be as large as the target size when compared with the preoperative magnetic resonance imaging (MRI) or computed tomography (CT) images. To address this problem, a solution based on open-domain EIT to reconstruct images surrounding the probe during DBS surgery is proposed. Data acquisition and image reconstruction were performed, and artificial intelligence was applied to enhance the resulting images. The results showed that the proposed method is rapid, produces valuable high-quality images, and constitutes a first step towards in-vivo study.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Brain\A_Post-Processing_Tool_and_Feasibility_Study_for_Three-_Dimensional_Imaging_Martin_.pdf}
}

@online{mastermanLandscapeEmergingAI2024,
  title = {The {{Landscape}} of {{Emerging AI Agent Architectures}} for {{Reasoning}}, {{Planning}}, and {{Tool Calling}}: {{A Survey}}},
  shorttitle = {The {{Landscape}} of {{Emerging AI Agent Architectures}} for {{Reasoning}}, {{Planning}}, and {{Tool Calling}}},
  author = {Masterman, Tula and Besen, Sandi and Sawtell, Mason and Chao, Alex},
  date = {2024-04-17},
  eprint = {2404.11584},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.11584},
  url = {http://arxiv.org/abs/2404.11584},
  urldate = {2024-07-03},
  abstract = {This survey paper examines the recent advancements in AI agent implementations, with a focus on their ability to achieve complex goals that require enhanced reasoning, planning, and tool execution capabilities. The primary objectives of this work are to a) communicate the current capabilities and limitations of existing AI agent implementations, b) share insights gained from our observations of these systems in action, and c) suggest important considerations for future developments in AI agent design. We achieve this by providing overviews of single-agent and multi-agent architectures, identifying key patterns and divergences in design choices, and evaluating their overall impact on accomplishing a provided goal. Our contribution outlines key themes when selecting an agentic architecture, the impact of leadership on agent systems, agent communication styles, and key phases for planning, execution, and reflection that enable robust AI agent systems.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Strategies\Reasoning\The_Landscape_of_Emerging_AI_Agent_Architectures_for_Reasoning,_Planning,_and_Masterman_et_al_2024.pdf}
}

@article{mauryaPerformanceGrapheneMoS22015,
  title = {Performance of Graphene–{{MoS2}} Based Surface Plasmon Resonance Sensor Using {{Silicon}} Layer},
  author = {Maurya, J. B. and Prajapati, Y. K. and Singh, V. and Saini, J. P. and Tripathi, Rajeev},
  date = {2015-11},
  journaltitle = {Opt Quant Electron},
  volume = {47},
  number = {11},
  pages = {3599--3611},
  issn = {0306-8919, 1572-817X},
  doi = {10.1007/s11082-015-0233-z},
  url = {http://link.springer.com/10.1007/s11082-015-0233-z},
  urldate = {2024-01-22},
  abstract = {In this paper a graphene–MoS2 hybrid structure based surface plasmon resonance biosensor is presented. The performance parameters of the proposed sensor are defined in terms of sensitivity, detection accuracy and quality factor. By the addition of hybrid graphene–MoS2 layer the sensitivity is enhanced but the quality factor and detection accuracy is decreased. Hence to increase the quality factor and detection accuracy a silicon layer is included between metal and MoS2 layer. It is observed that the full width at half maximum of reflectance curve is minimized up to great extent with little decrement in the sensitivity due to the inclusion of silicon layer. Furthermore in this paper, the effect of increasing the number of layers of graphene and MoS2 is also analyzed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\Performance_of_graphene–MoS2_based_surface_plasmon_resonance_sensor_using_Maurya_et_al_2015.pdf}
}

@article{mcdermottMultifrequencySymmetryDifference2020,
  title = {Multi-Frequency Symmetry Difference Electrical Impedance Tomography with Machine Learning for Human Stroke Diagnosis},
  author = {McDermott, Barry and Elahi, Adnan and Santorelli, Adam and O’Halloran, Martin and Avery, James and Porter, Emily},
  date = {2020-08-11},
  journaltitle = {Physiol. Meas.},
  volume = {41},
  number = {7},
  pages = {075010},
  issn = {1361-6579},
  doi = {10.1088/1361-6579/ab9e54},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/ab9e54},
  urldate = {2024-07-08},
  abstract = {Objective: Multi-frequency symmetry difference electrical impedance tomography (MFSD-EIT) can robustly detect and identify unilateral perturbations in symmetric scenes. Here, an investigation is performed to assess if the algorithm can be successfully applied to identify the aetiology of stroke with the aid of machine learning. Methods: Anatomically realistic four-layer finite element method models of the head based on stroke patient images are developed and used to generate EIT data over a 5 Hz–100 Hz frequency range with and without bleed and clot lesions present. Reconstruction generates conductivity maps of each head at each frequency. Application of a quantitative metric assessing changes in symmetry across the sagittal plane of the reconstructed image and over the frequency range allows lesion detection and identification. The algorithm is applied to both simulated and human (n = 34 subjects) data. A classification algorithm is applied to the metric value in order to differentiate between normal, haemorrhage and clot values. Main results: An average accuracy of 85\% is achieved when MFSD-EIT with support vector machines (SVM) classification is used to identify and differentiate bleed from clot in human data, with 77\% accuracy when differentiating normal from stroke in human data. Conclusion: Applying a classification algorithm to metrics derived from MFSD-EIT images is a novel and promising technique for detection and identification of perturbations in static scenes. Significance: The MFSD-EIT algorithm used with machine learning gives promising results of lesion detection and identification in challenging conditions like stroke. The results imply feasible translation to human patients.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\StrokeDetection\Multi-frequency_symmetry_difference_electrical_impedance_tomography_with_McDermott_et_al_2020.pdf}
}

@book{mcdermottProceedings21stInternational2021,
  title = {Proceedings of the 21st {{International Conference}} on {{Biomedical Applications}} of {{Electrical Impedance Tomography}}},
  author = {McDermott, Barry and Kraśny, Marcin J. and Farina, Laura and Ištuk, Niko and González-Suárez, Ana and Benchakroun, Hamza and Boyle, Alistair},
  date = {2021-06-14},
  publisher = {Zenodo},
  doi = {10.5281/ZENODO.4635480},
  url = {https://zenodo.org/record/4635480},
  urldate = {2024-07-03},
  abstract = {Proceedings of the 21st International Conference on Biomedical Applications of Electrical Impedance Tomography Edited by Barry McDermott, Marcin J. Kraśny, Laura Farina, Niko Ištuk, Ana González-Suárez, Hamza Benchakroun, Alistair Boyle This document is the collection of papers accepted for presentation at the 21st International Conference on Biomedical Applications of Electrical Impedance Tomography EIT 2021, Galway, Ireland.{$<$}br{$>$} {$<$}br{$>$} Each individual paper in this collection: © 2021 by the indicated authors. Collected work: © 2021 Barry McDermott, Marcin J. Kraśny, Laura Farina, Niko Ištuk, Ana González-Suárez, Hamza Benchakroun, Alistair Boyle},
  langid = {english},
  version = {v1},
  keywords = {Biomedical,Conference Proceedings,Electrical Imepdance Tomography},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Conferences\Proceedings_of_the_21st_International_Conference_on_Biomedical_Applications_of_McDermott_et_al_2021.pdf}
}

@article{meerashaReconfigurableQuantumPhotonic2022,
  title = {Reconfigurable Quantum Photonic Convolutional Neural Network Layer Utilizing Photonic Gate and Teleportation Mechanism},
  author = {Meerasha, Mubarak Ali and Ganesh, Madhupriya and Pandiyan, Krishnamoorthy},
  date = {2022-09-27},
  journaltitle = {Opt Quant Electron},
  volume = {54},
  number = {11},
  pages = {770},
  issn = {1572-817X},
  doi = {10.1007/s11082-022-04168-8},
  url = {https://doi.org/10.1007/s11082-022-04168-8},
  urldate = {2024-06-01},
  abstract = {This article, proposes a reconfigurable quantum photonic convolutional layer (QPCL) based on the reconfigurable photonic gates. The QPCL is used in the classical photonic CNN, where, an array of reconfigurable photonic gates (RPG) are arranged in a systematic way. The designed reconfigurable photonic gate serves as a unit cell for quantum photonic operations such as beam splitting, rotation, displacement, squeezing, and cubic- phase shifting. The designed RPG provides the features namely broadband operation, low insertion loss and compact layout. The information in the quantum photonic is represented by entangled states. Here, in this work we specifically focused on hand-written image recognition, hence the pixels of the image are represented as entangled state. The configuration of reconfigurable photonic gate is accomplished using electro-optic P-i-N carrier injection mechanism. As compared to Mach-Zehnder interferometer (MZI) based realization, the proposed silicon reconfigurable photonic gate provides scalable operation and compact footprint. The reconfigurable photonic gate is modeled using 2D finite element beam propagation method (FE-BPM). Finally, a compact numerical model is developed which performs Gaussian based continuous-variable (CV) quantum photonic operations and are verified with Xanadu’s strawberryfields quantum photonic simulator and PennyLane deep learning framework. The optimized accuracy (loss) is obtained with the utilization of QPCL layer and the values are 0.7627 (0.9595), this optimum result is obtained using a single QPCL layer with an epoch number of 30. Finally, a comparative analysis is made between quantum CNN and classical photonic CNN, where the quantum CNN resulted in 6.553\% high accuracy and 6.988\% low loss compared to the classical photonic CNN.},
  langid = {english},
  keywords = {Continuous-variable,Gaussian state,Quantum photonic computing,Qumodes,Reconfigurable quantum photonic gate},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\ConvolutionalNeuralNetworks\Reconfigurable_quantum_photonic_convolutional_neural_network_layer_utilizing_Meerasha_et_al_2022.pdf}
}

@article{mehaneyLocallyResonantPhononic2019,
  title = {Locally {{Resonant Phononic Crystals}} at {{Low}} Frequencies {{Based}} on {{Porous SiC Multilayer}}},
  author = {Mehaney, Ahmed and Ahmed, Ashour M.},
  date = {2019-10-14},
  journaltitle = {Sci Rep},
  volume = {9},
  number = {1},
  pages = {14767},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-51329-z},
  url = {https://www.nature.com/articles/s41598-019-51329-z},
  urldate = {2023-09-05},
  abstract = {Abstract             In this work, a one-dimensional porous silicon carbide phononic crystal (1D-PSiC PnC) sandwiched between two rubber layers is introduced to obtain low frequency band gaps for the audible frequencies. The novelty of the proposed multilayer 1D-PnCs arises from the coupling between the soft rubber, unique mechanical properties of porous SiC materials and the local resonance phenomenon. The proposed structure could be considered as a 1D acoustic Metamaterial with a size smaller than the relevant 1D-PnC structures for the same frequencies. To the best of our knowledge, it is the first time to use PSiC materials in a 1D PnC structure for the problem of low frequency phononic band gaps. Also, the porosities and thicknesses of the PSiC layers were chosen to obtain the fundamental band gaps within the bandwidth of the acoustic transducers and sound suppression devices. The transmission spectrum of acoustic waves is calculated by using the transfer matrix method (TMM). The results revealed that surprising low band gaps appeared in the transmission spectra of~the 1D-PSiC PnC at the audible range, which~are lower than the expected ones by Bragg’s scattering theory. The frequency at the center of the first band gap was at the value 7957\,Hz, which is 118 times smaller than the relevant frequency of other 1D structures with the same thickness. A comparison between the phononic band gaps of binary and ternary 1D-PSiC PnC structures sandwiched between two rubber layers at the micro-scale was performed and discussed. Also, the band gap frequency is controlled by varying the layers porosity, number and the thickness of each layer. The simulated results are promising in many applications such as low frequency band gaps, sound suppression devices, switches and filters.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Locally_Resonant_Phononic_Crystals_at_Low_frequencies_Based_on_Porous_SiC_Mehaney_Ahmed_2019.pdf}
}

@article{mehaneyPhononicCrystalNeutron2019,
  title = {Phononic Crystal as a Neutron Detector},
  author = {Mehaney, Ahmed},
  date = {2019-03},
  journaltitle = {Ultrasonics},
  volume = {93},
  pages = {37--42},
  issn = {0041624X},
  doi = {10.1016/j.ultras.2018.10.012},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0041624X18301628},
  urldate = {2023-09-05},
  abstract = {A perfect phononic crystal model composed of concrete and epoxy, and another defect model of Aluminum/ Concrete/Epoxy were proposed. The two models were analyzed computationally and theoretically based on the transfer matrix method. The proposed models were capable of detecting and sensing neutrons irradiations over a wide fluence range based on the effects of neutrons fluence on the Young's modulus of the concrete. The neutrons fluence significantly changed the transmission spectra of the phononic crystal models whether the neutronsinduced temperature was considered or not as the phononic band gaps and the local resonant peaks were shifted. Also, neutrons irradiations made a strong dispersion in the conventional parameters of the proposed phononic crystal models. The results presented in this work might pave the way for designing an effective detector that works over a wide range of neutron fluence.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Phononic_crystal_as_a_neutron_detector_Mehaney_2019.pdf}
}

@article{mehdianEffectMagneticField2014,
  title = {The Effect of Magnetic Field on Bistability in {{1D}} Photonic Crystal Doped by Magnetized Plasma and Coupled Nonlinear Defects},
  author = {Mehdian, H. and Mohammadzahery, Z. and Hasanbeigi, A.},
  date = {2014-01-01},
  journaltitle = {Physics of Plasmas},
  volume = {21},
  number = {1},
  pages = {012101},
  issn = {1070-664X, 1089-7674},
  doi = {10.1063/1.4858897},
  url = {https://pubs.aip.org/pop/article/21/1/012101/107641/The-effect-of-magnetic-field-on-bistability-in-1D},
  urldate = {2024-01-22},
  abstract = {In this work, we study the defect mode and bistability behavior of 1-D photonic band gap structure with magnetized plasma and coupled nonlinear defects. The transfer matrix method has been employed to investigate the magnetic field effect on defect mode frequency and bistability threshold. The obtained results show that the frequency of defect mode and bistability threshold can be altered, without changing the structure of the photonic multilayer. Therefore, the bistability behavior of the subjected structure in the presence of magnetized plasma can be utilized in manufacturing wide frequency range devices.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\The_effect_of_magnetic_field_on_bistability_in_1D_photonic_crystal_doped_by_Mehdian_et_al_2014.pdf}
}

@article{mehdianTunableFaradayEffect2016,
  title = {Tunable {{Faraday}} Effect in One-Dimensional Photonic Crystals Doped by Plasma},
  author = {Mehdian, H. and Mohammadzahery, Z. and Hasanbeigi, A.},
  date = {2016-04},
  journaltitle = {Optik},
  volume = {127},
  number = {8},
  pages = {3895--3898},
  issn = {00304026},
  doi = {10.1016/j.ijleo.2015.12.123},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0030402615020410},
  urldate = {2024-01-22},
  abstract = {In this paper, a four by four transfer matrix method has been used to investigate the optical and magneto-optical properties of a one-dimensional photonic crystal (1D-PC) doped by plasma. we show theoretically that there are a tunable resonance splitting form and a magnetically induced birefringence in a 1D-PC doped by plasma. The Faraday rotation can be seen clearly in this kind of structures. It is also figured out that the magnitude and the frequency of maximum Faraday rotation affected by the variation of the plasma density and the external magnetic field. This prospective advantage of the structure is useful for tunable filters in millimeter-wave region.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Tunable_Faraday_effect_in_one-dimensional_photonic_crystals_doped_by_plasma_Mehdian_et_al_2016.pdf}
}

@article{meiEffectiveMassDensity2006,
  title = {Effective {{Mass Density}} of {{Fluid-Solid Composites}}},
  author = {Mei, Jun and Liu, Zhengyou and Wen, Weijia and Sheng, Ping},
  date = {2006-01-19},
  journaltitle = {Phys. Rev. Lett.},
  volume = {96},
  number = {2},
  pages = {024301},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.96.024301},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.96.024301},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\SpecialEffects\NegativeMassDensity\Effective_Mass_Density_of_Fluid-Solid_Composites_Mei_et_al_2006.pdf}
}

@article{mendenDynamicLungBehavior2021,
  title = {Dynamic Lung Behavior under High {{G}} Acceleration Monitored with Electrical Impedance Tomography},
  author = {Menden, Tobias and Alcaín, Gema B and Stevenson, Alec T and Pollock, Ross D and Tank, Henry and Hodkinson, Peter and Jolley, Caroline and Smith, Thomas G and Leonhardt, Steffen and Walter, Marian},
  date = {2021-09-01},
  journaltitle = {Physiol. Meas.},
  volume = {42},
  number = {9},
  pages = {094001},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/1361-6579/ac1c63},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/ac1c63},
  urldate = {2024-07-08},
  abstract = {Objective. During launch and atmospheric re-entry in suborbital space flights, astronauts are exposed to high G-acceleration. These acceleration levels influence gas exchange inside the lung and can potentially lead to hypoxaemia. The distribution of air inside the lung can be monitored by electrical impedance tomography. This imaging technique might reveal how high gravitational forces affect the dynamic behavior of ventilation and impair gas exchange resulting in hypoxaemia. Approach. We performed a trial in a long-arm centrifuge with ten participants lying supine while being exposed to +2, +4 and +6 Gx (chest-to-back acceleration) to study the magnitude of accelerations experienced during suborbital spaceflight. Main results. First, the tomographic images revealed that the dorsal region of the lung emptied faster than the ventral region. Second, the ventilated area shifted from dorsal to ventral. Consequently, alveolar pressure in the dorsal area reached the pressure of the upper airways before the ventral area emptied completely. Finally, the upper airways collapsed and the endexpiratory volume increased. This resulted in ventral gas trapping with restricted gas exchange.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Dynamic_lung_behavior_under_high_G_acceleration_monitored_with_electrical_Menden_et_al_2021.pdf}
}

@inproceedings{mentzerHighFidelityGenerativeImage2020,
  title = {High-{{Fidelity Generative Image Compression}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mentzer, Fabian and Toderici, George D and Tschannen, Michael and Agustsson, Eirikur},
  date = {2020},
  volume = {33},
  pages = {11913--11924},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/8a50bae297807da9e97722a0b3fd8f27-Abstract.html},
  urldate = {2024-12-20},
  abstract = {We extensively study how to combine Generative Adversarial Networks and learned compression to obtain a state-of-the-art generative lossy compression system. In particular, we investigate normalization layers, generator and discriminator architectures, training strategies, as well as perceptual losses. In contrast to previous work, i) we obtain visually pleasing reconstructions that are perceptually similar to the input, ii) we operate in a broad range of bitrates, and iii) our approach can be applied to high-resolution images. We bridge the gap between rate-distortion-perception theory and practice by evaluating our approach both quantitatively with various perceptual metrics, and with a user study. The study shows that our method is preferred to previous approaches even if they use more than 2x the bitrate.},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\GenerativeAI\\ImageCodec\\GenerativeImageCodec\\High-Fidelity_Generative_Mentzer_et_al_2020.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\GenerativeAI\\ImageCodec\\GenerativeImageCodec\\High-Fidelity_Generative_Mentzer_et_al_22.pdf}
}

@article{merchantScalingDeepLearning2023,
  title = {Scaling Deep Learning for Materials Discovery},
  author = {Merchant, Amil and Batzner, Simon and Schoenholz, Samuel S. and Aykol, Muratahan and Cheon, Gowoon and Cubuk, Ekin Dogus},
  date = {2023-12},
  journaltitle = {Nature},
  volume = {624},
  number = {7990},
  pages = {80--85},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06735-9},
  url = {https://www.nature.com/articles/s41586-023-06735-9},
  urldate = {2024-08-05},
  abstract = {Novel functional materials enable fundamental breakthroughs across technological applications from clean energy to information processing1–11. From microchips to batteries and photovoltaics, discovery of inorganic crystals has been bottlenecked by expensive trial-and-error approaches. Concurrently, deep-learning models for language, vision and biology have showcased emergent predictive capabilities with increasing data and computation12–14. Here we show that graph networks trained at scale can reach unprecedented levels of generalization, improving the efficiency of materials discovery by an order of magnitude. Building on 48,000 stable crystals identified in continuing studies15–17, improved efficiency enables the discovery of 2.2 million structures below the current convex hull, many of which escaped previous human chemical intuition. Our work represents an order-of-magnitude expansion in stable materials known to humanity. Stable discoveries that are on the final convex hull will be made available to screen for technological applications, as we demonstrate for layered materials and solid-electrolyte candidates. Of the stable structures, 736 have already been independently experimentally realized. The scale and diversity of hundreds of millions of first-principles calculations also unlock modelling capabilities for downstream applications, leading in particular to highly accurate and robust learned interatomic potentials that can be used in condensed-phase molecular-dynamics simulations and high-fidelity zero-shot prediction of ionic conductivity.},
  langid = {english},
  keywords = {Computer science,Scaling laws},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\MaterialScience\Scaling_deep_learning_for_Merchant_et_al_2023.pdf}
}

@online{meulemanProgressivelyOptimizedLocal2023,
  title = {Progressively {{Optimized Local Radiance Fields}} for {{Robust View Synthesis}}},
  author = {Meuleman, Andreas and Liu, Yu-Lun and Gao, Chen and Huang, Jia-Bin and Kim, Changil and Kim, Min H. and Kopf, Johannes},
  date = {2023-03-24},
  eprint = {2303.13791},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.13791},
  url = {http://arxiv.org/abs/2303.13791},
  urldate = {2023-08-29},
  abstract = {We present an algorithm for reconstructing the radiance field of a large-scale scene from a single casually captured video. The task poses two core challenges. First, most existing radiance field reconstruction approaches rely on accurate pre-estimated camera poses from Structure-from-Motion algorithms, which frequently fail on in-the-wild videos. Second, using a single, global radiance field with finite representational capacity does not scale to longer trajectories in an unbounded scene. For handling unknown poses, we jointly estimate the camera poses with radiance field in a progressive manner. We show that progressive optimization significantly improves the robustness of the reconstruction. For handling large unbounded scenes, we dynamically allocate new local radiance fields trained with frames within a temporal window. This further improves robustness (e.g., performs well even under moderate pose drifts) and allows us to scale to large scenes. Our extensive evaluation on the Tanks and Temples dataset and our collected outdoor dataset, Static Hikes, show that our approach compares favorably with the state-of-the-art.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Video\Progressively_Optimized_Local_Radiance_Fields_for_Robust_View_Synthesis_Meuleman_et_al_2023.pdf}
}

@book{meyersEffectiveModern422014,
  title = {Effective Modern {{C}}++: 42 Specific Ways to Improve Your Use of {{C}}++11 and {{C}}++14},
  shorttitle = {Effective Modern {{C}}++},
  author = {Meyers, Scott},
  date = {2014},
  edition = {First edition},
  publisher = {O'Reilly Media},
  location = {Beijing ; Sebastopol, CA},
  abstract = {"Coming to grips with C++11 and C++14 is more than a matter of familiarizing yourself with the features they introduce (e.g., auto type declarations, move semantics, lambda expressions, and concurrency support). The challenge is learning to use those features effectively -- so that your software is correct, efficient, maintainable, and portable. That's where this practical book comes in. It describes how to write truly great software using C++11 and C++14 -- i.e. using modern C++ ...Effective Modern C++ follows the proven guideline-based, example-driven format of Scott Meyers' earlier books, but covers entirely new material"--Publisher's website},
  isbn = {978-1-4919-0399-5},
  langid = {english},
  pagetotal = {315},
  keywords = {C++ (Computer program language),Langages de programmation,Programmation informatique},
  annotation = {OCLC: ocn884480640},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\Programming\Effective_modern_C++_Meyers_2014.pdf}
}

@inproceedings{mildenhallNeRFDarkHigh2022,
  title = {{{NeRF}} in the {{Dark}}: {{High Dynamic Range View Synthesis}} from {{Noisy Raw Images}}},
  shorttitle = {{{NeRF}} in the {{Dark}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Mildenhall, Ben and Hedman, Peter and Martin-Brualla, Ricardo and Srinivasan, Pratul P. and Barron, Jonathan T.},
  date = {2022-06},
  pages = {16169--16178},
  publisher = {IEEE},
  location = {New Orleans, LA, USA},
  doi = {10.1109/CVPR52688.2022.01571},
  url = {https://ieeexplore.ieee.org/document/9878457/},
  urldate = {2023-08-03},
  abstract = {Neural Radiance Fields (NeRF) is a technique for high quality novel view synthesis from a collection of posed input images. Like most view synthesis methods, NeRF uses tonemapped low dynamic range (LDR) as input; these images have been processed by a lossy camera pipeline that smooths detail, clips highlights, and distorts the simple noise distribution of raw sensor data. We modify NeRF to instead train directly on linear raw images, preserving the scene’s full dynamic range. By rendering raw output images from the resulting NeRF, we can perform novel high dynamic range (HDR) view synthesis tasks. In addition to changing the camera viewpoint, we can manipulate focus, exposure, and tonemapping after the fact. Although a single raw image appears significantly more noisy than a postprocessed one, we show that NeRF is highly robust to the zeromean distribution of raw noise. When optimized over many noisy raw inputs (25-200), NeRF produces a scene representation so accurate that its rendered novel views outperform dedicated single and multi-image deep raw denoisers run on the same wide baseline input images. As a result, our method, which we call RawNeRF, can reconstruct scenes from extremely noisy images captured in near-darkness.},
  eventtitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66546-946-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\HDR\NeRF_in_the_Dark_Mildenhall_et_al_2022.pdf}
}

@online{mildenhallNeRFRepresentingScenes2020,
  title = {{{NeRF}}: {{Representing Scenes}} as {{Neural Radiance Fields}} for {{View Synthesis}}},
  shorttitle = {{{NeRF}}},
  author = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
  date = {2020-08-03},
  eprint = {2003.08934},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2003.08934},
  url = {http://arxiv.org/abs/2003.08934},
  urldate = {2023-11-07},
  abstract = {We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location \$(x,y,z)\$ and viewing direction \$(\textbackslash theta, \textbackslash phi)\$) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\General\NeRF_Mildenhall_et_al_2020.pdf}
}

@article{milioniAcousticMethodologySelecting,
  title = {Acoustic Methodology for Selecting Highly Dissipative Probes for Ultrasensitive {{DNA}} Detection},
  author = {Milioni, Dimitra and Mateos-Gil, Pablo and Papadakis, George and Tsortos, Achilleas and Sarlidou, Olga},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\Materials\Acoustic_methodology_for_selecting_highly_dissipative_probes_for_ultrasensitive_Milioni_et_al_.PDF}
}

@article{milioniAcousticMethodologySelecting2020,
  title = {Acoustic {{Methodology}} for {{Selecting Highly Dissipative Probes}} for {{Ultrasensitive DNA Detection}}},
  author = {Milioni, Dimitra and Mateos-Gil, Pablo and Papadakis, George and Tsortos, Achilleas and Sarlidou, Olga and Gizeli, Electra},
  date = {2020-06-16},
  journaltitle = {Anal. Chem.},
  volume = {92},
  number = {12},
  pages = {8186--8193},
  issn = {0003-2700, 1520-6882},
  doi = {10.1021/acs.analchem.0c00366},
  url = {https://pubs.acs.org/doi/10.1021/acs.analchem.0c00366},
  urldate = {2023-09-05},
  abstract = {The objective of this work is to present a methodology for the selection of nanoparticles such as liposomes to be used as acoustic probes for the detection of very low concentrations of DNA. Liposomes, applied in the past as mass amplifiers and detected through frequency measurement, are employed in the current work as probes for energy-dissipation enhancement. Because the dissipation signal is related to the structure of the sensed nanoentity, a systematic investigation of the geometrical features of the liposome/DNA complex was carried out. We introduce the parameter of dissipation capacity by which several sizes of liposome and DNA structures were compared with respect to their ability to dissipate acoustic energy at the level of a single molecule/particle. Optimized 200 nm liposomes anchored to a dsDNA chain led to an improvement of the limit of detection (LoD) by 3 orders of magnitude when compared to direct DNA detection, with the new LoD being 1.2 fmol (or 26 fg/μL or 2 pM). Dissipation monitoring was also shown to be 8 times more sensitive than the corresponding frequency response. The high versatility of this new methodology is demonstrated in the detection of genetic biomarkers down to 1−2 target copies in real samples such as blood. This study offers new prospects in acoustic detection with potential use in real-world diagnostics.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\Materials\Acoustic_Methodology_for_Selecting_Highly_Dissipative_Probes_for_Ultrasensitive_Milioni_et_al_2020.PDF}
}

@inproceedings{minnenJointAutoregressiveHierarchical2018,
  title = {Joint {{Autoregressive}} and {{Hierarchical Priors}} for {{Learned Image Compression}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Minnen, David and Ballé, Johannes and Toderici, George D},
  date = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2018/hash/53edebc543333dfbf7c5933af792c9c4-Abstract.html},
  urldate = {2024-08-08},
  abstract = {Recent models for learned image compression are based on autoencoders that learn approximately invertible mappings from pixels to a quantized latent representation. The transforms are combined with an entropy model, which is a prior on the latent representation that can be used with standard arithmetic coding algorithms to generate a compressed bitstream. Recently, hierarchical entropy models were introduced as a way to exploit more structure in the latents than previous fully factorized priors, improving compression performance while maintaining end-to-end optimization. Inspired by the success of autoregressive priors in probabilistic generative models, we examine autoregressive, hierarchical, and combined priors as alternatives, weighing their costs and benefits in the context of image compression. While it is well known that autoregressive models can incur a significant computational penalty, we find that in terms of compression performance, autoregressive and hierarchical priors are complementary and can be combined to exploit the probabilistic structure in the latents better than all previous learned models. The combined model yields state-of-the-art rate-distortion performance and generates smaller files than existing methods: 15.8\% rate reductions over the baseline hierarchical model and 59.8\%, 35\%, and 8.4\% savings over JPEG, JPEG2000, and BPG, respectively. To the best of our knowledge, our model is the first learning-based method to outperform the top standard image codec (BPG) on both the PSNR and MS-SSIM distortion metrics.},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\GenerativeAI\\ImageCodec\\Joint_Autoregressive_and_Minnen_et_al_2018.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\GenerativeAI\\ImageCodec\\Joint_Autoregressive_and_Minnen_et_al_22.pdf}
}

@online{mocklUniversalStrategyInduce2024,
  title = {A Universal Strategy to Induce Oxidative Stress-Mediated Cell Death in Biological Systems},
  author = {Möckl, Leonhard and Almahayni, Karim and Salvador, Jana Bachir and Conti, Riccardo and Widera, Anna and Spiekermann, Malte and Wehner, Daniel and Grützmacher, Hansjörg},
  date = {2024-01-30},
  doi = {10.21203/rs.3.rs-3753893/v1},
  url = {https://www.researchsquare.com/article/rs-3753893/v1},
  urldate = {2024-07-04},
  abstract = {Abstract                        Precise cell elimination within intricate cellular populations is hampered by issues arising from the multifaceted biological properties of cells and the expansive reactivity of chemical agents. Current platforms are often limited by their complexity, toxicity, and poor physical/chemical properties. Here, we integrate the spatio-temporal precision of light delivery and the structural versatility of bisacylphosphane oxides (BAPOs), establishing a universal strategy for on-demand, precise cellular ablation             in vitro             and             in vivo             .},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\ahmed\OneDrive\Research\OtherTopics\Joachim_max_plank_optics\A_universal_strategy_to_Mockl_et_al_2024.pdf}
}

@unpublished{ModifyEIT,
  title = {Modify {{EIT}}},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Presentaions\Modify_EIT_.pdf}
}

@unpublished{ModifyEITa,
  title = {Modify {{EIT}} 2},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Presentaions\Modify_EIT_2_.pdf}
}

@article{mohammadElectrochemicalMechanicalPolishing2016,
  title = {Electrochemical Mechanical Polishing Technology: Recent Developments and Future Research and Industrial Needs},
  shorttitle = {Electrochemical Mechanical Polishing Technology},
  author = {Mohammad, Abd El Khalick and Wang, Danwei},
  date = {2016-09},
  journaltitle = {Int J Adv Manuf Technol},
  volume = {86},
  number = {5-8},
  pages = {1909--1924},
  issn = {0268-3768, 1433-3015},
  doi = {10.1007/s00170-015-8119-6},
  url = {http://link.springer.com/10.1007/s00170-015-8119-6},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\Electrolysis\Electrochemical_mechanical_polishing_technology_Mohammad_Wang_2016.pdf}
}

@article{moleskyInverseDesignNanophotonics2018,
  title = {Inverse Design in Nanophotonics},
  author = {Molesky, Sean and Lin, Zin and Piggott, Alexander Y. and Jin, Weiliang and Vucković, Jelena and Rodriguez, Alejandro W.},
  date = {2018-11},
  journaltitle = {Nature Photon},
  volume = {12},
  number = {11},
  pages = {659--670},
  publisher = {Nature Publishing Group},
  issn = {1749-4893},
  doi = {10.1038/s41566-018-0246-9},
  url = {https://www.nature.com/articles/s41566-018-0246-9},
  urldate = {2024-05-31},
  abstract = {Recent advancements in computational inverse-design approaches — algorithmic techniques for discovering optical structures based on desired functional characteristics — have begun to reshape the landscape of structures available to nanophotonics. Here, we outline a cross-section of key developments in this emerging field of photonic optimization: moving from a recap of foundational results to motivation of applications in nonlinear, topological, near-field and on-chip optics.},
  langid = {english},
  keywords = {Applied optics,Optical materials and structures,Optical physics,Optics and photonics},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/Photonics/InverseDesign/Inverse_design_in_Molesky_et_al_2018.pdf}
}

@article{mollmertComparisonBrillouinMicroscopy,
  title = {Beyond Comparison: {{Brillouin}} Microscopy and {{AFM-based}} Indentation Reveal Divergent Insights into the Mechanical Profile of the Murine Retina},
  author = {Möllmert, Stephanie and Gutmann, Marcus and Müller, Paul and Kim, Kyoohyun and Salvador, Bachir and Aif, Serhii and Meinel, Lorenz and Guck, Jochen},
  abstract = {Mechanical tissue properties increasingly serve as pivotal phenotypic characteristics that are subject to change during development or pathological progression. The quantification of such material properties often relies on physical contact between a load-applying probe and an exposed sample surface. For most tissues, these requirements necessitate animal sacrifice, tissue dissection and sectioning. These invasive procedures bear the risk of yielding mechanical properties that do not portray the physiological mechanical state of a tissue within a functioning organism. Brillouin microscopy has emerged as a noninvasive, optical technique that allows to assess mechanical cell and tissue properties with high spatio-temporal resolution. In optically transparent specimens, this technique does not require animal sacrifice, tissue dissection or sectioning. However, the extent to which results obtained from Brillouin microscopy allow to infer conclusions about potential results obtained with a contact-based technique, and vice versa, is unclear. Potential sources for discrepancies include the varying characteristic temporal and spatial scales, the directionality of measurement, environmental factors, and mechanical moduli probed. In this work, we addressed those aspects by quantifying the mechanical properties of acutely dissected murine retinal tissues using Brillouin microscopy and atomic force microscopy (AFM)-based indentation measurements. Our results show a distinct mechanical profile of the retinal layers with respect to the Brillouin frequency shift, the Brillouin linewidth and the apparent Young’s modulus. Contrary to previous reports, our findings do not support a simple correlative relationship between Brillouin frequency shift and apparent Young’s modulus. Additionally, the divergent sensitivity of Brillouin microscopy and AFMindentation measurements to cross-linking or changes post mortem underscores the dangers of assuming both methods can be generally used interchangeably. In conclusion, our study advocates for viewing Brillouin microscopy and AFM-based indentation measurements as complementary tools, discouraging direct comparisons a priori and suggesting their combined use for a more comprehensive understanding of tissue mechanical properties.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\OtherTopics\Joachim_max_plank_optics\Beyond_comparison_Mollmert_et_al_.pdf}
}

@online{momeniTrainingPhysicalNeural2024,
  title = {Training of {{Physical Neural Networks}}},
  author = {Momeni, Ali and Rahmani, Babak and Scellier, Benjamin and Wright, Logan G. and McMahon, Peter L. and Wanjura, Clara C. and Li, Yuhang and Skalli, Anas and Berloff, Natalia G. and Onodera, Tatsuhiro and Oguz, Ilker and Morichetti, Francesco and family=Hougne, given=Philipp, prefix=del, useprefix=false and Gallo, Manuel Le and Sebastian, Abu and Mirhoseini, Azalia and Zhang, Cheng and Marković, Danijela and Brunner, Daniel and Moser, Christophe and Gigan, Sylvain and Marquardt, Florian and Ozcan, Aydogan and Grollier, Julie and Liu, Andrea J. and Psaltis, Demetri and Alù, Andrea and Fleury, Romain},
  date = {2024-06-05},
  eprint = {2406.03372},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2406.03372},
  urldate = {2024-12-15},
  abstract = {Physical neural networks (PNNs) are a class of neural-like networks that leverage the properties of physical systems to perform computation. While PNNs are so far a niche research area with small-scale laboratory demonstrations, they are arguably one of the most underappreciated important opportunities in modern AI. Could we train AI models 1000x larger than current ones? Could we do this and also have them perform inference locally and privately on edge devices, such as smartphones or sensors? Research over the past few years has shown that the answer to all these questions is likely "yes, with enough research": PNNs could one day radically change what is possible and practical for AI systems. To do this will however require rethinking both how AI models work, and how they are trained - primarily by considering the problems through the constraints of the underlying hardware physics. To train PNNs at large scale, many methods including backpropagation-based and backpropagation-free approaches are now being explored. These methods have various trade-offs, and so far no method has been shown to scale to the same scale and performance as the backpropagation algorithm widely used in deep learning today. However, this is rapidly changing, and a diverse ecosystem of training techniques provides clues for how PNNs may one day be utilized to create both more efficient realizations of current-scale AI models, and to enable unprecedented-scale models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Physics - Applied Physics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Physics\Training_of_Physical_Neural_Momeni_et_al_2024.pdf}
}

@inproceedings{montiGeometricDeepLearning2017,
  title = {Geometric {{Deep Learning}} on {{Graphs}} and {{Manifolds Using Mixture Model CNNs}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Monti, Federico and Boscaini, Davide and Masci, Jonathan and Rodola, Emanuele and Svoboda, Jan and Bronstein, Michael M.},
  date = {2017-07},
  pages = {5425--5434},
  publisher = {IEEE},
  location = {Honolulu, HI},
  doi = {10.1109/CVPR.2017.576},
  url = {http://ieeexplore.ieee.org/document/8100059/},
  urldate = {2023-08-26},
  abstract = {Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclideanstructured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graphand 3D shape analysis and show that it consistently outperforms previous approaches.},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-0457-1},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\GraphsAndManifolds\Geometric_Deep_Learning_on_Monti_et_al_2017.pdf}
}

@article{moonReviewGenerativeModels2023,
  title = {Review of {{Generative Models}} for the {{Inverse Design}} of {{Nanophotonic Metasurfaces}}},
  author = {Moon, Seunghwan and Kang, Jihun and Yeo, Jong-Souk},
  date = {2023-11-30},
  journaltitle = {Applied Science and Convergence Technology},
  volume = {32},
  number = {6},
  pages = {141--150},
  publisher = {The Korean Vacuum Society},
  doi = {10.5757/ASCT.2023.32.6.141},
  url = {https://www.e-asct.org/journal/view.html?doi=10.5757/ASCT.2023.32.6.141},
  urldate = {2024-06-01},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\Review_of_Generative_Models_Moon_et_al_2023.pdf}
}

@article{muddemannAvoidanceChlorineFormation2018,
  title = {Avoidance of {{Chlorine Formation}} during {{Electrolysis}} at {{Boron-Doped Diamond Anodes}} in {{Highly Sodium Chloride Containing}} and {{Organic-Polluted Wastewater}}},
  author = {Muddemann, T. and Bulan, A. and Sievers, M. and Kunz, U.},
  date = {2018},
  journaltitle = {J. Electrochem. Soc.},
  volume = {165},
  number = {15},
  pages = {J3281-J3287},
  issn = {0013-4651, 1945-7111},
  doi = {10.1149/2.0371815jes},
  url = {https://iopscience.iop.org/article/10.1149/2.0371815jes},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\Electrolysis\Avoidance_of_Chlorine_Formation_during_Electrolysis_at_Boron-Doped_Diamond_Muddemann_et_al_2018.pdf}
}

@article{muellerDbarMethodElectrical2020,
  title = {The {{D-bar}} Method for Electrical Impedance Tomography—Demystified},
  author = {Mueller, J L and Siltanen, S},
  date = {2020-09-01},
  journaltitle = {Inverse Problems},
  volume = {36},
  number = {9},
  pages = {093001},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/1361-6420/aba2f5},
  url = {https://iopscience.iop.org/article/10.1088/1361-6420/aba2f5},
  urldate = {2023-12-03},
  abstract = {Electrical impedance tomography (EIT) is an imaging modality where a patient or object is probed using harmless electric currents. The currents are fed through electrodes placed on the surface of the target, and the data consists of voltages measured at the electrodes resulting from a linearly independent set of current injection patterns. EIT aims to recover the internal distribution of electrical conductivity inside the target. The inverse problem underlying the EIT image formation task is nonlinear and severely ill-posed, and hence sensitive to modeling errors and measurement noise. Therefore, the inversion process needs to be regularized. However, traditional variational regularization methods, based on optimization, often suffer from local minima because of nonlinearity. This is what makes regularized direct (non-iterative) methods attractive for EIT. The most developed direct EIT algorithm is the D-bar method, based on complex geometric optics solutions and a nonlinear Fourier transform. Variants and recent developments of D-bar methods are reviewed, and their practical numerical implementation is explained.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\D-bar\The_D-bar_method_for_Mueller_Siltanen_2020.pdf}
}

@online{mukherjeeHeuristicReasoningAI2024,
  title = {Heuristic {{Reasoning}} in {{AI}}: {{Instrumental Use}} and {{Mimetic Absorption}}},
  shorttitle = {Heuristic {{Reasoning}} in {{AI}}},
  author = {Mukherjee, Anirban and Chang, Hannah Hanwen},
  date = {2024-03-18},
  eprint = {2403.09404},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.09404},
  url = {http://arxiv.org/abs/2403.09404},
  urldate = {2024-07-03},
  abstract = {Deviating from conventional perspectives that frame artificial intelligence (AI) systems solely as logic emulators, we propose a novel program of heuristic reasoning. We distinguish between the 'instrumental' use of heuristics to match resources with objectives, and 'mimetic absorption,' whereby heuristics manifest randomly and universally. Through a series of innovative experiments, including variations of the classic Linda problem and a novel application of the Beauty Contest game, we uncover trade-offs between maximizing accuracy and reducing effort that shape the conditions under which AIs transition between exhaustive logical processing and the use of cognitive shortcuts (heuristics). We provide evidence that AIs manifest an adaptive balancing of precision and efficiency, consistent with principles of resource-rational human cognition as explicated in classical theories of bounded rationality and dual-process theory. Our findings reveal a nuanced picture of AI cognition, where trade-offs between resources and objectives lead to the emulation of biological systems, especially human cognition, despite AIs being designed without a sense of self and lacking introspective capabilities.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Strategies\Reasoning\Heuristic_Reasoning_in_AI_Mukherjee_Chang_2024.pdf}
}

@article{mullerInstantNeuralGraphics2022,
  title = {Instant {{Neural Graphics Primitives}} with a {{Multiresolution Hash Encoding}}},
  author = {Müller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  date = {2022-07},
  journaltitle = {ACM Trans. Graph.},
  volume = {41},
  number = {4},
  eprint = {2201.05989},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1--15},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3528223.3530127},
  url = {http://arxiv.org/abs/2201.05989},
  urldate = {2023-09-05},
  abstract = {Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of \$\{1920\textbackslash!\textbackslash times\textbackslash!1080\}\$.},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\General\Instant_Neural_Graphics_Primitives_with_a_Multiresolution_Hash_Encoding_Muller_et_al_2022.pdf}
}

@article{mustonenApproximatingElectricalImpedance,
  title = {Approximating the {{Electrical Impedance Tomography Forward Problem}} with {{Graph Neural Networks}}},
  author = {Mustonen, Aleksi},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\ApproximatingUsingAI\Approximating_the_Electrical_Impedance_Tomography_Forward_Problem_with_Graph_Mustonen_.pdf}
}

@article{muttakinInteriorVoidClassification2021,
  title = {Interior {{Void Classification}} in {{Liquid Metal Using Multi-Frequency Magnetic Induction Tomography With}} a {{Machine Learning Approach}}},
  author = {Muttakin, Imamul and Soleimani, Manuchehr},
  date = {2021-10-15},
  journaltitle = {IEEE Sensors J.},
  volume = {21},
  number = {20},
  pages = {23289--23296},
  issn = {1530-437X, 1558-1748, 2379-9153},
  doi = {10.1109/JSEN.2021.3109629},
  url = {https://ieeexplore.ieee.org/document/9527203/},
  urldate = {2024-07-08},
  abstract = {Identification of gas bubble, void detection and porosity estimation are important factors in many liquid metal processes. In steel casting, the importance of flow condition and phase distribution in crucial parts, such as submerged entry nozzle (SEN) and mould raises the needs to observe the phenomena. Cross-section of flow shapes can be visualised using the magnetic induction tomography (MIT) technique. However, the inversion procedure in the image reconstruction has either limited resolution or involving post-processing stages degrading its real-time capability. Additionally, when quantifying the void fraction or porosity, the image may not be required. This work proposes an interior void classifier based on multi-frequency mutual induction measurements with eutectic alloy GaInSn as a cold liquid metal model contained in a 3D printed plastic miniature of an SEN. The sensors consist of eight coils arranged in a circle encapsulating the column, providing combinatorial detection on conductive surface and depth. The datasets are induced voltage collections of several non-metallic inclusions (NMI) patterns in liquid metal static test and used to train a machine learning model. The model architectures are a fully connected neural network (FCNN) for 1D; and a convolutional neural network (CNN) for 2D data. The classifier using 1D data has been trained to provide 95\% accuracy on this dataset. On the other hand, CNN classification using multi-dimensional data produces 96\% of test accuracy. Refined with representative flow scenarios, the trained model could be deployed for an intelligent online control system of the liquid metal process.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Industry\BubbleDetection\Interior_Void_Classification_in_Liquid_Metal_Using_Multi-Frequency_Magnetic_Muttakin_Soleimani_2021.pdf}
}

@online{nagraniVoxCelebLargescaleSpeaker2018,
  title = {{{VoxCeleb}}: A Large-Scale Speaker Identification Dataset},
  shorttitle = {{{VoxCeleb}}},
  author = {Nagrani, Arsha and Chung, Joon Son and Zisserman, Andrew},
  date = {2018-05-30},
  eprint = {1706.08612},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.1706.08612},
  url = {http://arxiv.org/abs/1706.08612},
  urldate = {2024-12-07},
  abstract = {Most existing datasets for speaker identification contain samples obtained under quite constrained conditions, and are usually hand-annotated, hence limited in size. The goal of this paper is to generate a large scale text-independent speaker identification dataset collected 'in the wild'. We make two contributions. First, we propose a fully automated pipeline based on computer vision techniques to create the dataset from open-source media. Our pipeline involves obtaining videos from YouTube; performing active speaker verification using a two-stream synchronization Convolutional Neural Network (CNN), and confirming the identity of the speaker using CNN based facial recognition. We use this pipeline to curate VoxCeleb which contains hundreds of thousands of 'real world' utterances for over 1,000 celebrities. Our second contribution is to apply and compare various state of the art speaker identification techniques on our dataset to establish baseline performance. We show that a CNN based architecture obtains the best performance for both identification and verification.},
  pubstate = {prepublished},
  keywords = {Computer Science - Sound},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\Datasets\VoxCeleb_Nagrani_et_al_2018.pdf}
}

@article{nakkireddyBAYESIANMETHODSBRIDGING,
  title = {{{BAYESIAN METHODS FOR BRIDGING THE CONTINUOUS AND ELECTRODE DATA}}, {{AND LAYER STRIPPING IN ELECTRICAL IMPEDANCE TOMOGRAPHY}}},
  author = {Nakkireddy, Sumanth Reddy},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\BAYESIAN_METHODS_FOR_BRIDGING_THE_CONTINUOUS_AND_ELECTRODE_DATA,_AND_LAYER_Nakkireddy_.pdf}
}

@book{Nanophotonic_Materials_Wehrspohn_et_al_2008Pdf,
  title = {Nanophotonic\_{{Materials}}\_{{Wehrspohn}}\_et\_al\_2008.Pdf},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\CRCpress\Nanophotonic_Materials_Wehrspohn_et_al_2008_.pdf}
}

@article{nappiAerogelItsApplications1998,
  title = {Aerogel and Its Applications to {{RICH}} Detectors},
  author = {Nappi, E.},
  date = {1998-02},
  journaltitle = {Nuclear Physics B - Proceedings Supplements},
  volume = {61},
  number = {3},
  pages = {270--276},
  issn = {09205632},
  doi = {10.1016/S0920-5632(97)00573-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0920563297005732},
  urldate = {2023-09-05},
  abstract = {Beam test results show that the “new generation” aerogel has attractive features and appears an interesting candidate as radiator in Ring Imaging Cherenkov (RICH) detectors. The challenging applications envisaged in the LHCb experiment at CERN and in the HERMES experiment at DESY will be reviewed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Aerogel\Aerogel_and_its_applications_to_RICH_detectors_Nappi_1998.pdf}
}

@inproceedings{niemeyerGIRAFFERepresentingScenes2021,
  title = {{{GIRAFFE}}: {{Representing Scenes}} as {{Compositional Generative Neural Feature Fields}}},
  shorttitle = {{{GIRAFFE}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Niemeyer, Michael and Geiger, Andreas},
  date = {2021-06},
  pages = {11448--11459},
  publisher = {IEEE},
  location = {Nashville, TN, USA},
  doi = {10.1109/CVPR46437.2021.01129},
  url = {https://ieeexplore.ieee.org/document/9577414/},
  urldate = {2023-09-26},
  abstract = {Deep generative models allow for photorealistic image synthesis at high resolutions. But for many applications, this is not enough: content creation also needs to be controllable. While several recent works investigate how to disentangle underlying factors of variation in the data, most of them operate in 2D and hence ignore that our world is three-dimensional. Further, only few works consider the compositional nature of scenes. Our key hypothesis is that incorporating a compositional 3D scene representation into the generative model leads to more controllable image synthesis. Representing scenes as compositional generative neural feature fields allows us to disentangle one or multiple objects from the background as well as individual objects’ shapes and appearances while learning from unstructured and unposed image collections without any additional supervision. Combining this scene representation with a neural rendering pipeline yields a fast and realistic image synthesis model. As evidenced by our experiments, our model is able to disentangle individual objects and allows for translating and rotating them in the scene as well as changing the camera pose.},
  eventtitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66544-509-2},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\GIRAFFE_Niemeyer_Geiger_2021.pdf}
}

@online{niemeyerRadSplatRadianceFieldInformed2024,
  title = {{{RadSplat}}: {{Radiance Field-Informed Gaussian Splatting}} for {{Robust Real-Time Rendering}} with 900+ {{FPS}}},
  shorttitle = {{{RadSplat}}},
  author = {Niemeyer, Michael and Manhardt, Fabian and Rakotosaona, Marie-Julie and Oechsle, Michael and Duckworth, Daniel and Gosula, Rama and Tateno, Keisuke and Bates, John and Kaeser, Dominik and Tombari, Federico},
  date = {2024-03-20},
  eprint = {2403.13806},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.13806},
  url = {http://arxiv.org/abs/2403.13806},
  urldate = {2024-04-13},
  abstract = {Recent advances in view synthesis and real-time rendering have achieved photorealistic quality at impressive rendering speeds. While Radiance Field-based methods achieve state-of-the-art quality in challenging scenarios such as in-the-wild captures and large-scale scenes, they often suffer from excessively high compute requirements linked to volumetric rendering. Gaussian Splatting-based methods, on the other hand, rely on rasterization and naturally achieve real-time rendering but suffer from brittle optimization heuristics that underperform on more challenging scenes. In this work, we present RadSplat, a lightweight method for robust real-time rendering of complex scenes. Our main contributions are threefold. First, we use radiance fields as a prior and supervision signal for optimizing point-based scene representations, leading to improved quality and more robust optimization. Next, we develop a novel pruning technique reducing the overall point count while maintaining high quality, leading to smaller and more compact scene representations with faster inference speeds. Finally, we propose a novel test-time filtering approach that further accelerates rendering and allows to scale to larger, house-sized scenes. We find that our method enables state-of-the-art synthesis of complex captures at 900+ FPS.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/Reconstruction/NeuralRadianceFields/AccelerateNerf/RadSplat_Niemeyer_et_al_2024.pdf}
}

@article{nikolaevBraggReflectorsCylindrical1999,
  title = {Bragg Reflectors for Cylindrical Waves},
  author = {Nikolaev, V V and Sokolovski, G S and Kaliteevski, M A},
  date = {1999},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Bragg_reflectors_for_cylindrical_waves_Nikolaev_et_al_1999.pdf}
}

@article{nikolaevBraggReflectorsCylindrical1999a,
  title = {Bragg Reflectors for Cylindrical Waves},
  author = {Nikolaev, V V and Sokolovski, G S and Kaliteevski, M A},
  date = {1999},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Bragg_reflectors_for_cylindrical_waves_Nikolaev_et_al_12.pdf}
}

@online{nikolakakisGaSpCTGaussianSplatting2024,
  title = {{{GaSpCT}}: {{Gaussian Splatting}} for {{Novel CT Projection View Synthesis}}},
  shorttitle = {{{GaSpCT}}},
  author = {Nikolakakis, Emmanouil and Gupta, Utkarsh and Vengosh, Jonathan and Bui, Justin and Marinescu, Razvan},
  date = {2024-04-03},
  eprint = {2404.03126},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2404.03126},
  url = {http://arxiv.org/abs/2404.03126},
  urldate = {2024-05-05},
  abstract = {We present GaSpCT, a novel view synthesis and 3D scene representation method used to generate novel projection views for Computer Tomography (CT) scans. We adapt the Gaussian Splatting framework to enable novel view synthesis in CT based on limited sets of 2D image projections and without the need for Structure from Motion (SfM) methodologies. Therefore, we reduce the total scanning duration and the amount of radiation dose the patient receives during the scan. We adapted the loss function to our use-case by encouraging a stronger background and foreground distinction using two sparsity promoting regularizers: a beta loss and a total variation (TV) loss. Finally, we initialize the Gaussian locations across the 3D space using a uniform prior distribution of where the brain's positioning would be expected to be within the field of view. We evaluate the performance of our model using brain CT scans from the Parkinson's Progression Markers Initiative (PPMI) dataset and demonstrate that the rendered novel views closely match the original projection views of the simulated scan, and have better performance than other implicit 3D scene representations methodologies. Furthermore, we empirically observe reduced training time compared to neural network based image synthesis for sparse-view CT image reconstruction. Finally, the memory requirements of the Gaussian Splatting representations are reduced by 17\% compared to the equivalent voxel grid image representations.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/Reconstruction/NeuralRadianceFields/Tomography/GaSpCT_Nikolakakis_et_al_2024.pdf}
}

@article{nissinenCompensationErrorsDue2009,
  title = {Compensation of Errors Due to Discretization, Domain Truncation and Unknown Contact Impedances in Electrical Impedance Tomography},
  author = {Nissinen, A and Heikkinen, L M and Kolehmainen, V and Kaipio, J P},
  date = {2009-10-01},
  journaltitle = {Meas. Sci. Technol.},
  volume = {20},
  number = {10},
  pages = {105504},
  issn = {0957-0233, 1361-6501},
  doi = {10.1088/0957-0233/20/10/105504},
  url = {https://iopscience.iop.org/article/10.1088/0957-0233/20/10/105504},
  urldate = {2024-07-08},
  abstract = {Inverse problems can be characterized as problems that tolerate measurement and modelling errors poorly. Typical sources of modelling errors include (pure) approximation errors related to numerical discretization, unknown geometry and boundary data, and possibly sensor locations. With electrical impedance tomography (EIT), the unknown contact impedances are an additional error source. Recently, a Bayesian approach to the treatment of approximation and modelling errors for inverse problems has been proposed. This approach has been shown to be applicable to a variety of modelling and approximation errors, at least with simulations. Recently, it was shown that recovery from significant model reduction and moderate mismodelling of geometry in EIT was also possible with laboratory EIT data. In this paper, we show that the errors due to the unknown contact impedances can also be compensated for by employing the approximation error approach. Furthermore, the recovery from simultaneous contact impedance, domain truncation and discretization-related errors is also feasible.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\ContactImpedance\Compensation_of_errors_due_to_discretization,_domain_truncation_and_unknown_Nissinen_et_al_2009.pdf}
}

@article{nissinenCompensationErrorsDue2009a,
  title = {Compensation of Errors Due to Discretization, Domain Truncation and Unknown Contact Impedances in Electrical Impedance Tomography},
  author = {Nissinen, A and Heikkinen, L M and Kolehmainen, V and Kaipio, J P},
  date = {2009-10-01},
  journaltitle = {Meas. Sci. Technol.},
  volume = {20},
  number = {10},
  pages = {105504},
  issn = {0957-0233, 1361-6501},
  doi = {10.1088/0957-0233/20/10/105504},
  url = {https://iopscience.iop.org/article/10.1088/0957-0233/20/10/105504},
  urldate = {2024-07-08},
  abstract = {Inverse problems can be characterized as problems that tolerate measurement and modelling errors poorly. Typical sources of modelling errors include (pure) approximation errors related to numerical discretization, unknown geometry and boundary data, and possibly sensor locations. With electrical impedance tomography (EIT), the unknown contact impedances are an additional error source. Recently, a Bayesian approach to the treatment of approximation and modelling errors for inverse problems has been proposed. This approach has been shown to be applicable to a variety of modelling and approximation errors, at least with simulations. Recently, it was shown that recovery from significant model reduction and moderate mismodelling of geometry in EIT was also possible with laboratory EIT data. In this paper, we show that the errors due to the unknown contact impedances can also be compensated for by employing the approximation error approach. Furthermore, the recovery from simultaneous contact impedance, domain truncation and discretization-related errors is also feasible.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\ForwardProblem\InaccuratelyKnownBoundary\Compensation_of_errors_due_to_discretization,_domain_truncation_and_unknown_Nissinen_et_al_2009.pdf}
}

@article{niuEpsilonNearZeroPhotonicsNew2018,
  title = {Epsilon-{{Near-Zero Photonics}}: {{A New Platform}} for {{Integrated Devices}}},
  shorttitle = {Epsilon-{{Near-Zero Photonics}}},
  author = {Niu, Xinxiang and Hu, Xiaoyong and Chu, Saisai and Gong, Qihuang},
  date = {2018-05},
  journaltitle = {Advanced Optical Materials},
  volume = {6},
  number = {10},
  pages = {1701292},
  issn = {21951071},
  doi = {10.1002/adom.201701292},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/adom.201701292},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Epsilon-Near-Zero_Photonics_Niu_et_al_2018.pdf}
}

@misc{NonlinearOptics_Ppt,
  title = {Nonlinear Optics\_.Ppt},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\nonlinear_optics__.ppt}
}

@article{norrisOpalinePhotonicCrystals2004,
  title = {Opaline {{Photonic Crystals}}: {{How Does Self}}‐{{Assembly Work}}?},
  shorttitle = {Opaline {{Photonic Crystals}}},
  author = {Norris, D. J. and Arlinghaus, E. G. and Meng, L. and Heiny, R. and Scriven, L. E.},
  date = {2004-08-18},
  journaltitle = {Advanced Materials},
  volume = {16},
  number = {16},
  pages = {1393--1399},
  issn = {0935-9648, 1521-4095},
  doi = {10.1002/adma.200400455},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/adma.200400455},
  urldate = {2024-06-01},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\BlackBodyRadiation\Opaline_Photonic_Crystals_Norris_et_al_2004.pdf}
}

@online{oechsleUNISURFUnifyingNeural2021,
  title = {{{UNISURF}}: {{Unifying Neural Implicit Surfaces}} and {{Radiance Fields}} for {{Multi-View Reconstruction}}},
  shorttitle = {{{UNISURF}}},
  author = {Oechsle, Michael and Peng, Songyou and Geiger, Andreas},
  date = {2021-10-08},
  eprint = {2104.10078},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2104.10078},
  urldate = {2024-02-20},
  abstract = {Neural implicit 3D representations have emerged as a powerful paradigm for reconstructing surfaces from multi-view images and synthesizing novel views. Unfortunately, existing methods such as DVR or IDR require accurate per-pixel object masks as supervision. At the same time, neural radiance fields have revolutionized novel view synthesis. However, NeRF's estimated volume density does not admit accurate surface reconstruction. Our key insight is that implicit surface models and radiance fields can be formulated in a unified way, enabling both surface and volume rendering using the same model. This unified perspective enables novel, more efficient sampling procedures and the ability to reconstruct accurate surfaces without input masks. We compare our method on the DTU, BlendedMVS, and a synthetic indoor dataset. Our experiments demonstrate that we outperform NeRF in terms of reconstruction quality while performing on par with IDR without requiring masks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\SDF\UNISURF_Oechsle_et_al_2021.pdf}
}

@inproceedings{oquabLowBandwidthVideoChat2021,
  title = {Low {{Bandwidth Video-Chat Compression}} Using {{Deep Generative Models}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  author = {Oquab, Maxime and Stock, Pierre and Gafni, Oran and Haziza, Daniel and Xu, Tao and Zhang, Peizhao and Celebi, Onur and Hasson, Yana and Labatut, Patrick and Bose-Kolanu, Bobo and Peyronel, Thibault and Couprie, Camille},
  date = {2021-06},
  pages = {2388--2397},
  publisher = {IEEE},
  location = {Nashville, TN, USA},
  doi = {10.1109/CVPRW53098.2021.00271},
  url = {https://ieeexplore.ieee.org/document/9522751/},
  urldate = {2024-04-04},
  abstract = {To unlock video chat for hundreds of millions of people hindered by poor connectivity or unaffordable data costs, we propose to authentically reconstruct faces on the receiver’s device using facial landmarks extracted at the sender’s side and transmitted over the network. In this context, we discuss and evaluate the benefits and disadvantages of several deep adversarial approaches. In particular, we explore quality and bandwidth trade-offs for approaches based on static landmarks, dynamic landmarks or segmentation maps. We design a mobile-compatible architecture based on the first order animation model of Siarohin et al. In addition, we leverage SPADE blocks to refine results in important areas such as the eyes and lips. We compress the networks down to about 3 MB, allowing models to run in real time on iPhone 8 (CPU). This approach enables video calling at a few kbits per second, an order of magnitude lower than currently available alternatives.},
  eventtitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  isbn = {978-1-66544-899-4},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\VideoCoding\Low_Bandwidth_Video-Chat_Compression_using_Deep_Generative_Models_Oquab_et_al_2021.pdf}
}

@online{ordonez-apraezMorphologicalSymmetriesRobotics2024,
  title = {Morphological {{Symmetries}} in {{Robotics}}},
  author = {Ordoñez-Apraez, Daniel and Turrisi, Giulio and Kostic, Vladimir and Martin, Mario and Agudo, Antonio and Moreno-Noguer, Francesc and Pontil, Massimiliano and Semini, Claudio and Mastalli, Carlos},
  date = {2024-02-23},
  eprint = {2402.15552},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2402.15552},
  url = {http://arxiv.org/abs/2402.15552},
  urldate = {2024-03-25},
  abstract = {We present a comprehensive framework for studying and leveraging morphological symmetries in robotic systems. These are intrinsic properties of the robot's morphology, frequently observed in animal biology and robotics, which stem from the replication of kinematic structures and the symmetrical distribution of mass. We illustrate how these symmetries extend to the robot's state space and both proprioceptive and exteroceptive sensor measurements, resulting in the equivariance of the robot's equations of motion and optimal control policies. Thus, we recognize morphological symmetries as a relevant and previously unexplored physics-informed geometric prior, with significant implications for both data-driven and analytical methods used in modeling, control, estimation and design in robotics. For data-driven methods, we demonstrate that morphological symmetries can enhance the sample efficiency and generalization of machine learning models through data augmentation, or by applying equivariant/invariant constraints on the model's architecture. In the context of analytical methods, we employ abstract harmonic analysis to decompose the robot's dynamics into a superposition of lower-dimensional, independent dynamics. We substantiate our claims with both synthetic and real-world experiments conducted on bipedal and quadrupedal robots. Lastly, we introduce the repository MorphoSymm to facilitate the practical use of the theory and applications outlined in this work.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Robotics,Electrical Engineering and Systems Science - Systems and Control},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\TransformersBasic\Morphological_Symmetries_in_Ordonez-Apraez_et_al_2024.pdf}
}

@online{osmanModellingHumanValues2024,
  title = {Modelling {{Human Values}} for {{AI Reasoning}}},
  author = {Osman, Nardine and family=Inverno, given=Mark, prefix=d', useprefix=true},
  date = {2024-02-09},
  eprint = {2402.06359},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.06359},
  url = {http://arxiv.org/abs/2402.06359},
  urldate = {2024-07-03},
  abstract = {One of today's most significant societal challenges is building AI systems whose behaviour, or the behaviour it enables within communities of interacting agents (human and artificial), aligns with human values. To address this challenge, we detail a formal model of human values for their explicit computational representation. To our knowledge, this has not been attempted as yet, which is surprising given the growing volume of research integrating values within AI. Taking as our starting point the wealth of research investigating the nature of human values from social psychology over the last few decades, we set out to provide such a formal model. We show how this model can provide the foundational apparatus for AI-based reasoning over values, and demonstrate its applicability in real-world use cases. We illustrate how our model captures the key ideas from social psychology research and propose a roadmap for future integrated, and interdisciplinary, research into human values in AI. The ability to automatically reason over values not only helps address the value alignment problem but also facilitates the design of AI systems that can support individuals and communities in making more informed, value-aligned decisions. More and more, individuals and organisations are motivated to understand their values more explicitly and explore whether their behaviours and attitudes properly reflect them. Our work on modelling human values will enable AI systems to be designed and deployed to meet this growing need.},
  pubstate = {prepublished},
  keywords = {68T01,Computer Science - Artificial Intelligence,Computer Science - Multiagent Systems,I.2.4},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Strategies\Reasoning\Modelling_Human_Values_for_AI_Reasoning_Osman_d'Inverno_2024.pdf}
}

@article{padhyHybridCryptocompressionModel2024,
  title = {A Hybrid Crypto-Compression Model for Secure Brain Mri Image Transmission},
  author = {Padhy, Sasmita and Dash, Sachikanta and Shankar, T. N. and Rachapudi, Venubabu and Kumar, Sandeep and Nayyar, Anand},
  date = {2024-03-01},
  journaltitle = {Multimed Tools Appl},
  volume = {83},
  number = {8},
  pages = {24361--24381},
  issn = {1573-7721},
  doi = {10.1007/s11042-023-16359-w},
  url = {https://doi.org/10.1007/s11042-023-16359-w},
  urldate = {2024-12-23},
  abstract = {Medical image encryption is a major issue in healthcare applications where memory, energy, and computational resources are constrained. The modern technological architecture of digital healthcare systems is, in fact, insufficient to handle both the current and future requirements for data. Security has been raised to the highest priority. By meeting these conditions, the hybrid crypto-compression technique introduced in this study can be used for securing the transfer of healthcare images. The approach consists of two components. In order to construct a cutting-edge generative lossy compression system, we first combine generative adversarial networks (GANs) with oearned compression. As a result, the second phase might address this problem by using highly effective picture cryptography techniques. A randomly generated public key is subjected to the DNA technique. In this application, pseudo-random bits are produced by using a logistic chaotic map algorithm. During the substitution process, an additional layer of security is provided to boost the technique’s fault resilience. Our proposed system and security investigations show that the method provides trustworthy and long-lasting encryption and several multidimensional aspects that have been discovered in various public health and healthcare issues. As a result, the recommended hybrid crypto-compression technique may significantly reduce a photo’s size and remain safe enough to be used for medical image encryption.},
  langid = {english},
  keywords = {Chaotic map,Cryptography,DNA encoding,Generative adversarial networks,Medical Imaging,Security},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\A_hybrid_crypto-compression_Padhy_et_al_2024.pdf}
}

@article{padilhaleitzkeReviewElectricalImpedance2020,
  title = {A {{Review}} on {{Electrical Impedance Tomography Spectroscopy}}},
  author = {Padilha Leitzke, Juliana and Zangl, Hubert},
  date = {2020-09-10},
  journaltitle = {Sensors},
  volume = {20},
  number = {18},
  pages = {5160},
  issn = {1424-8220},
  doi = {10.3390/s20185160},
  url = {https://www.mdpi.com/1424-8220/20/18/5160},
  urldate = {2024-07-03},
  abstract = {Electrical Impedance Tomography Spectroscopy (EITS) enables the reconstruction of material distributions inside an object based on the frequency-dependent characteristics of different substances. In this paper, we present a review of EITS focusing on physical principles of the technology, sensor geometries, existing measurement systems, reconstruction algorithms, and image representation methods. In addition, a novel imaging method is proposed which could fill some of the gaps found in the literature. As an example of an application, EITS of ice and water mixtures is used.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Review\A_Review_on_Electrical_Impedance_Tomography_Spectroscopy_Padilha_Leitzke_Zangl_2020.pdf}
}

@article{palubickiEcoclimatesClimateresponseModeling2022,
  title = {Ecoclimates: Climate-Response Modeling of Vegetation},
  shorttitle = {Ecoclimates},
  author = {Pałubicki, Wojtek and Makowski, Miłosz and Gajda, Weronika and Hädrich, Torsten and Michels, Dominik L. and Pirk, Sören},
  date = {2022-07},
  journaltitle = {ACM Trans. Graph.},
  volume = {41},
  number = {4},
  pages = {1--19},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3528223.3530146},
  url = {https://dl.acm.org/doi/10.1145/3528223.3530146},
  urldate = {2024-01-29},
  abstract = {One of the greatest challenges to mankind is understanding the underlying principles of climate change. Over the last years, the role of forests in climate change has received increased attention. This is due to the observation that not only the atmosphere has a principal impact on vegetation growth but also that vegetation is contributing to local variations of weather resulting in diverse microclimates. The interconnection of plant ecosystems and weather is described and studied as ecoclimates. In this work we take steps towards simulating ecoclimates by modeling the feedback loops between vegetation, soil, and atmosphere. In contrast to existing methods that only describe the climate at a global scale, our model aims at simulating local variations of climate. Specifically, we model tree growth interactively in response to gradients of water, temperature and light. As a result, we are able to capture a range of ecoclimate phenomena that have not been modeled before, including geomorphic controls, forest edge effects, the Foehn effect and spatial vegetation patterning. To validate the plausibility of our method we conduct a comparative analysis to studies from ecology and climatology. Consequently, our method advances the state-of-the-art of generating highly realistic outdoor landscapes of vegetation.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Modeling\Ecoclimates\Ecoclimates_Palubicki_et_al_2022.pdf}
}

@incollection{pandeyEnhancedPhotonicBandgaps2017,
  title = {Enhanced of {{Photonic Bandgaps}} in {{One-Dimensional Plasma Photonic Crystal}} with {{Defect}}},
  booktitle = {Advances in {{Optical Science}} and {{Engineering}}},
  author = {Pandey, G. N. and Shukla, Anil Kumar and family=Thapa, given=Khem. B., given-i={{Khem}}B and Pandey, J. P.},
  editor = {Bhattacharya, Indrani and Chakrabarti, Satyajit and Reehal, Haricharan Singh and Lakshminarayanan, Vasudevan},
  date = {2017},
  volume = {194},
  pages = {219--225},
  publisher = {Springer Singapore},
  location = {Singapore},
  doi = {10.1007/978-981-10-3908-9_26},
  url = {http://link.springer.com/10.1007/978-981-10-3908-9_26},
  urldate = {2024-01-22},
  abstract = {The paper presents the transmittance characteristics of electromagnetic (EM) waves in one-dimensional photonic crystal with the insertion of defect layer within the regular structure of plasma photonic crystal. The Plasma Photonic Crystal (PPC) consists of alternate layers of thin micro-plasma with dielectric material in one-dimensional periodic structure. The reflectance and transmittance of considered structure are calculated using transfer matrix method. From the study, it is found that a number of photonic band gap increases by introducing a defect layer inside the regular structure of plasma photonic crystal.},
  isbn = {978-981-10-3907-2 978-981-10-3908-9},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Enhanced_of_Photonic_Bandgaps_in_One-Dimensional_Plasma_Photonic_Crystal_with_Pandey_et_al_2017.pdf}
}

@article{pangConvolutionConvolutionNetwork2018,
  title = {Convolution in {{Convolution}} for {{Network}} in {{Network}}},
  author = {Pang, Yanwei and Sun, Manli and Jiang, Xiaoheng and Li, Xuelong},
  date = {2018-05},
  journaltitle = {IEEE Trans. Neural Netw. Learning Syst.},
  volume = {29},
  number = {5},
  pages = {1587--1597},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2017.2676130},
  url = {https://ieeexplore.ieee.org/document/7879808/},
  urldate = {2023-08-26},
  abstract = {Network in network (NiN) is an effective instance and an important extension of deep convolutional neural network consisting of alternating convolutional layers and pooling layers. Instead of using a linear filter for convolution, NiN utilizes shallow multilayer perceptron (MLP), a nonlinear function, to replace the linear filter. Because of the powerfulness of MLP and 1 × 1 convolutions in spatial domain, NiN has stronger ability of feature representation and hence results in better recognition performance. However, MLP itself consists of fully connected layers that give rise to a large number of parameters. In this paper, we propose to replace dense shallow MLP with sparse shallow MLP. One or more layers of the sparse shallow MLP are sparely connected in the channel dimension or channel–spatial domain. The proposed method is implemented by applying unshared convolution across the channel dimension and applying shared convolution across the spatial dimension in some computational layers. The proposed method is called convolution in convolution (CiC). The experimental results on the CIFAR10 data set, augmented CIFAR10 data set, and CIFAR100 data set demonstrate the effectiveness of the proposed CiC method.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\ConvolutionOnChannels\Convolution_in_Convolution_Pang_et_al_2018.pdf}
}

@online{parkCamPCameraPreconditioning2023,
  title = {{{CamP}}: {{Camera Preconditioning}} for {{Neural Radiance Fields}}},
  shorttitle = {{{CamP}}},
  author = {Park, Keunhong and Henzler, Philipp and Mildenhall, Ben and Barron, Jonathan T. and Martin-Brualla, Ricardo},
  date = {2023-08-21},
  eprint = {2308.10902},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2308.10902},
  url = {http://arxiv.org/abs/2308.10902},
  urldate = {2023-08-29},
  abstract = {Neural Radiance Fields (NeRF) can be optimized to obtain high-fidelity 3D scene reconstructions of objects and large-scale scenes. However, NeRFs require accurate camera parameters as input -- inaccurate camera parameters result in blurry renderings. Extrinsic and intrinsic camera parameters are usually estimated using Structure-from-Motion (SfM) methods as a pre-processing step to NeRF, but these techniques rarely yield perfect estimates. Thus, prior works have proposed jointly optimizing camera parameters alongside a NeRF, but these methods are prone to local minima in challenging settings. In this work, we analyze how different camera parameterizations affect this joint optimization problem, and observe that standard parameterizations exhibit large differences in magnitude with respect to small perturbations, which can lead to an ill-conditioned optimization problem. We propose using a proxy problem to compute a whitening transform that eliminates the correlation between camera parameters and normalizes their effects, and we propose to use this transform as a preconditioner for the camera parameters during joint optimization. Our preconditioned camera optimization significantly improves reconstruction quality on scenes from the Mip-NeRF 360 dataset: we reduce error rates (RMSE) by 67\% compared to state-of-the-art NeRF approaches that do not optimize for cameras like Zip-NeRF, and by 29\% relative to state-of-the-art joint optimization approaches using the camera parameterization of SCNeRF. Our approach is easy to implement, does not significantly increase runtime, can be applied to a wide variety of camera parameterizations, and can straightforwardly be incorporated into other NeRF-like models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\CameraParameters\CamP_Park_et_al_2023.pdf}
}

@online{parkComprehensiveSurveyCompression2024,
  title = {A {{Comprehensive Survey}} of {{Compression Algorithms}} for {{Language Models}}},
  author = {Park, Seungcheol and Choi, Jaehyeon and Lee, Sojin and Kang, U.},
  date = {2024-01-27},
  eprint = {2401.15347},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2401.15347},
  url = {http://arxiv.org/abs/2401.15347},
  urldate = {2024-10-23},
  abstract = {How can we compress language models without sacrificing accuracy? The number of compression algorithms for language models is rapidly growing to benefit from remarkable advances of recent language models without side effects due to the gigantic size of language models, such as increased carbon emissions and expensive maintenance fees. While numerous compression algorithms have shown remarkable progress in compressing language models, it ironically becomes challenging to capture emerging trends and identify the fundamental concepts underlying them due to the excessive number of algorithms. In this paper, we survey and summarize diverse compression algorithms including pruning, quantization, knowledge distillation, low-rank approximation, parameter sharing, and efficient architecture design. We not only summarize the overall trend of diverse compression algorithms but also select representative algorithms and provide in-depth analyses of them. We discuss the value of each category of compression algorithms, and the desired properties of low-cost compression algorithms which have a significant impact due to the emergence of large language models. Finally, we introduce promising future research topics based on our survey results.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Quantization\A_Comprehensive_Survey_of_Compression_Algorithms_for_Language_Models_Park_et_al_2024.pdf}
}

@article{parkSampleefficientInverseDesign2024,
  title = {Sample-Efficient Inverse Design of Freeform Nanophotonic Devices with Physics-Informed Reinforcement Learning},
  author = {Park, Chaejin and Kim, Sanmun and Jung, Anthony W. and Park, Juho and Seo, Dongjin and Kim, Yongha and Park, Chanhyung and Park, Chan Y. and Jang, Min Seok},
  date = {2024-04-01},
  journaltitle = {Nanophotonics},
  volume = {13},
  number = {8},
  pages = {1483--1492},
  publisher = {De Gruyter},
  issn = {2192-8614},
  doi = {10.1515/nanoph-2023-0852},
  url = {https://www.degruyter.com/document/doi/10.1515/nanoph-2023-0852/html},
  urldate = {2024-05-31},
  abstract = {Finding an optimal device structure in the vast combinatorial design space of freeform nanophotonic design has been an enormous challenge. In this study, we propose physics-informed reinforcement learning (PIRL) that combines the adjoint-based method with reinforcement learning to improve the sample efficiency by an order of magnitude compared to conventional reinforcement learning and overcome the issue of local minima. To illustrate these advantages of PIRL over other conventional optimization algorithms, we design a family of one-dimensional metasurface beam deflectors using PIRL, exceeding most reported records. We also explore the transfer learning capability of PIRL that further improves sample efficiency and demonstrate how the minimum feature size of the design can be enforced in PIRL through reward engineering. With its high sample efficiency, robustness, and ability to seamlessly incorporate practical device design constraints, our method offers a promising approach to highly combinatorial freeform device optimization in various physical domains.},
  langid = {english},
  keywords = {adjoint-based method,freeform design,inverse design,metasurface,physic-informed neural network,reinforcement learning},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\OneDimension\Sample-efficient_inverse_Park_et_al_2024.pdf}
}

@article{parthasarathyRelationVelocitySound1953,
  title = {Relation between {{Velocity}} of {{Sound}} and {{Viscosity}} in {{Liquids}}},
  author = {Parthasarathy, S and Bakhshi, N N},
  date = {1953-05},
  journaltitle = {Proc. Phys. Soc. B},
  volume = {66},
  number = {5},
  pages = {368--370},
  issn = {0370-1301},
  doi = {10.1088/0370-1301/66/5/303},
  url = {https://iopscience.iop.org/article/10.1088/0370-1301/66/5/303},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Relation_between_Velocity_of_Sound_and_Viscosity_in_Liquids_Parthasarathy_Bakhshi_1953.pdf}
}

@article{paulOptimizationMicroscopyImage2024,
  title = {Optimization of Microscopy Image Compression Using Convolutional Neural Networks and Removal of Artifacts by Deep Generative Adversarial Networks},
  author = {Paul, Raj Kumar and Misra, Dipankar and Sen, Shibaprasad and Chandran, Saravanan},
  date = {2024-06-01},
  journaltitle = {Multimed Tools Appl},
  volume = {83},
  number = {20},
  pages = {58961--58980},
  issn = {1573-7721},
  doi = {10.1007/s11042-023-17494-0},
  url = {https://doi.org/10.1007/s11042-023-17494-0},
  urldate = {2024-12-23},
  abstract = {Nowadays, microscopy images are significant in medical research and clinical studies. However, storage and transmission of data such as microscopy images are challenging. Microscopy image compression is a vital area of digital microscope imaging in which image processing approaches are applied to capture the image by the microscope. It becomes accessible to interface the microscope to an image processing system because of technical advances in the microscope. Multiple application areas of microscope imaging, namely cancer research, drug testing, metallurgy, medicine, biological research, test-tube baby, etc., need microscopy image processing for analysis purposes. The microscopy image compression leads to complicated compression artifacts, like contouring, blocking, and ringing artifacts. Due to this problem, we select optimized Convolution Neural Networks (optimized-CNN), followed by Deep generative adversarial networks Deep-GAN, as a solution to reduce diverse compression artifacts. This research covers the compression of microscopy images and the removal of artifacts from a compressed microscopy image Optimized-CNN Deep-GAN based on Optimized-CNN and Deep-GAN. The concept of microscope image acquisition techniques and their analysis is also discussed. The performance of the Optimized-CNN Deep-GAN approach is measured using Peak Signal to Noise Ratio(PSNR), Compression Ratio(CR), Structural Similarity Index Measurement(SSIM), and Blind/Reference less Image Spatial Quality Evaluator(BRISQUE) and differentiated with state-of-the-art techniques. The experimental outcomes indicate the Optimized-CNN Deep-GAN technique acquires higher SSIM, BRISQUE, reduced space complexity, and better image quality than the existing image compression system. The proposed new model achieved CR 13.88, PSNR 40.6799 (dB), SSIM 0.9541, and BRISQUE 18.7645 values.},
  langid = {english},
  keywords = {BRISQUE,CR,Deep-GAN,Microscopy image,Optimized-CNN,PSNR,SSIM},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Optimization_of_microscopy_Paul_et_al_2024.pdf}
}

@article{pavanAnalysingGroupIndices2024,
  title = {Analysing Group Indices and Dispersion Characteristics of Engineered Photonic Crystal Waveguides Using Artificial Neural Network},
  author = {Pavan, Vadapalli Durga Rama and Nikhil, Vangety and Dey, Koustav and Umamaheswara Sharma, B. and Roy, Sourabh},
  date = {2024-04-01},
  journaltitle = {J Opt},
  volume = {53},
  number = {2},
  pages = {1438--1446},
  issn = {0974-6900},
  doi = {10.1007/s12596-023-01285-9},
  url = {https://doi.org/10.1007/s12596-023-01285-9},
  urldate = {2024-06-21},
  abstract = {Artificial neural networks in machine learning are popular in solving complex data problems. This article proposes a neural network for predicting the dispersion relations and group indices of a dispersion-engineered photonic crystal waveguide mainly designed for slow light applications. The model is trained by the data sets generated from MPB programming. A supervised feedforward multilayer perceptron neural network is used for predicting the data. Three hidden layers are used, with 500 nodes in each layer. One hundred epochs are used to achieve the lowest mean squared error. Waveguide structures with lattice shifts in the range of 0.00a–0.25a are used to generate the training data sets. After the training, it was found that the model could predict the dispersion and group indices values within the trained data range. The model is effective in reducing the computational time.},
  langid = {english},
  keywords = {Dispersion relations,Group index,Machine learning,Photonic crystal waveguide},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\AI\Modeling\DispersionCharacteristics\Analysing_group_indices_and_Pavan_et_al_2024.pdf}
}

@inproceedings{pByteZipEfficientLossless2024,
  title = {{{ByteZip}}: {{Efficient Lossless Compression}} for {{Structured Byte Streams Using DNNs}}},
  shorttitle = {{{ByteZip}}},
  booktitle = {2024 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {P, Parvathy Ramakrishnan and Das, Satyajit},
  date = {2024-06},
  pages = {1--8},
  issn = {2161-4407},
  doi = {10.1109/IJCNN60899.2024.10650523},
  url = {https://ieeexplore.ieee.org/document/10650523/?arnumber=10650523&tag=1},
  urldate = {2024-10-08},
  abstract = {Data compression plays a key role in efficient data storage, transmission, and processing. With the fast development of deep learning techniques, deep neural networks have been used in this field to achieve a higher compression rate. Deep learning-based general-purpose lossless compression techniques are formulated as an autoregressive sequential prediction problem. These methods are state-of-the-art in terms of compression ratio but not practical due to runtime and resource constraints. Recent advances in lossless image compression using non-autoregressive methods for probability modeling prove to be a faster and more practical approach. In this paper, we propose ByteZip, a lossless compression method based on the non-autoregressive approach for known or defined structured byte streams. ByteZip involves hierarchical probabilistic modeling using autoencoders and density mixture models. This approach reduces the overhead of sequential processing. The goal is to design a practical lossless compressor with faster compression and decompression along with a competitive compression ratio. Experiments show that the proposed approach achieves a 64× higher compression speed than the state-of-the-art transformer-based model TRACE with an overhead of only 5\% less size reduction on average. Our approach outperforms general-purpose compressors such as Gzip (23\% more size reduction on average) and 7z (16\% more size reduction on average).},
  eventtitle = {2024 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  keywords = {autoencoders,Data compression,Image coding,lossless compression,mixture density networks,neural networks,Parallel processing,Pipelines,Predictive models,Runtime,Transformers},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Compression\LosslessCompression\ByteZip_P_Das_2024.pdf}
}

@inproceedings{penarandaSmashCompressionBenchmark2022,
  title = {Smash: {{A Compression Benchmark}} with~{{AI Datasets}} from~{{Remote GPU Virtualization Systems}}},
  shorttitle = {Smash},
  booktitle = {Hybrid {{Artificial Intelligent Systems}}},
  author = {Peñaranda, Cristian and Reaño, Carlos and Silla, Federico},
  editor = {García Bringas, Pablo and Pérez García, Hilde and Martínez de Pisón, Francisco Javier and Villar Flecha, José Ramón and Troncoso Lora, Alicia and family=Cal, given=Enrique A., prefix=de la, useprefix=true and Herrero, Álvaro and Martínez Álvarez, Francisco and Psaila, Giuseppe and Quintián, Héctor and Corchado, Emilio},
  date = {2022},
  pages = {236--248},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-15471-3_21},
  abstract = {Remote GPU virtualization is a mechanism that allows GPU-accelerated applications to be executed in computers without GPUs. Instead, GPUs from remote computers are used. Applications are not aware of using a remote GPU. However, overall performance depends on the throughput of the underlying network connecting the application to the remote GPUs. One way to increase this bandwidth is to compress transmissions made within the remote GPU virtualization middleware between the application side and the GPU side.},
  isbn = {978-3-031-15471-3},
  langid = {english},
  keywords = {Artificial Intelligence,Benchmark,Compression,GPU},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\Data Compression\Smash_Penaranda_et_al_2022.pdf}
}

@article{pennebakerOverviewBasicPrinciples1988,
  title = {An Overview of the Basic Principles of the {{Q-Coder}} Adaptive Binary Arithmetic Coder},
  author = {Pennebaker, W. B. and Mitchell, J. L. and Langdon, G. G. and Arps, R. B.},
  date = {1988-11},
  journaltitle = {IBM Journal of Research and Development},
  volume = {32},
  number = {6},
  pages = {717--726},
  issn = {0018-8646},
  doi = {10.1147/rd.326.0717},
  url = {https://ieeexplore.ieee.org/document/5389988},
  urldate = {2024-05-14},
  abstract = {The Q-Coder is a new form of adaptive binary arithmetic coding. The binary arithmetic coding part of the technique is derived from the basic concepts introduced by Rissanen, Pasco, and Langdon, but extends the coding conventions to resolve a conflict between optimal software and hardware implementations. In addition, a robust form of probability estimation is used in which the probability estimate is derived solely from the interval renormalizations that are part of the arithmetic coding process. A brief tutorial of arithmetic coding concepts is presented, followed by a discussion of the compatible optimal hardware and software coding structures and the estimation of symbol probabilities from interval renormalization.},
  eventtitle = {{{IBM Journal}} of {{Research}} and {{Development}}}
}

@article{pennecTwodimensionalPhononicCrystals2010,
  title = {Two-Dimensional Phononic Crystals: {{Examples}} and Applications},
  shorttitle = {Two-Dimensional Phononic Crystals},
  author = {Pennec, Yan and Vasseur, Jérôme O. and Djafari-Rouhani, Bahram and Dobrzyński, Leonard and Deymier, Pierre A.},
  date = {2010-08-31},
  journaltitle = {Surface Science Reports},
  volume = {65},
  number = {8},
  pages = {229--291},
  issn = {01675729},
  doi = {10.1016/j.surfrep.2010.08.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167572910000555},
  urldate = {2023-09-05},
  abstract = {Phononic crystals are composite materials made of periodic distributions of inclusions embedded in a matrix. Due to their periodic structure, these materials may exhibit under certain conditions, absolute acoustic band gaps i.e. forbidden bands that are independent of the direction of propagation of the incident elastic wave. In the first part of this review paper, we present some examples of two-dimensional bulk phononic crystals i.e. two-dimensional arrays of inclusions assumed of infinite extent along the three spatial directions. We show that the bandwidth of the forbidden band depends strongly on the nature of the constituent materials (solid or fluid), as well as the contrast between the physical characteristics (density and elastic moduli) of the inclusions and of the matrix, the geometry of the array of inclusions, the inclusion shape and the filling factor of inclusions. The second part of this review paper is devoted to some possible applications of these composite materials. In particular, we show that defect modes (cavities, waveguides, stubs, etc.) inserted inside the two-dimensional periodic structure may lead to very selective frequency filters and efficient devices for the wavelength demultiplexing. We present also the possibility of sonic insulators for frequencies of the order of kHz with relatively small thicknesses of phononic crystal samples. Finally we report on the vibration modes of a two-dimensional phononic crystal plate i.e. a phononic crystal of finite thickness along the axis of the inclusions. We discuss guided modes which may occur in the band structure of the plate. Surface acoustic waves propagating in twodimensional phononic crystals should open new perspectives in high-frequency radio-frequency devices. Throughout the paper, the methods of calculation are presented with some details and some experimental results complete the numerical predictions.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\2DPhononicCrystals\Two-dimensional_phononic_crystals_Pennec_et_al_2010.pdf}
}

@article{pennecTwodimensionalPhononicCrystals2010a,
  title = {Two-Dimensional Phononic Crystals: {{Examples}} and Applications},
  shorttitle = {Two-Dimensional Phononic Crystals},
  author = {Pennec, Yan and Vasseur, Jérôme O. and Djafari-Rouhani, Bahram and Dobrzyński, Leonard and Deymier, Pierre A.},
  date = {2010-08-31},
  journaltitle = {Surface Science Reports},
  volume = {65},
  number = {8},
  pages = {229--291},
  issn = {01675729},
  doi = {10.1016/j.surfrep.2010.08.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167572910000555},
  urldate = {2023-09-05},
  abstract = {Phononic crystals are composite materials made of periodic distributions of inclusions embedded in a matrix. Due to their periodic structure, these materials may exhibit under certain conditions, absolute acoustic band gaps i.e. forbidden bands that are independent of the direction of propagation of the incident elastic wave. In the first part of this review paper, we present some examples of two-dimensional bulk phononic crystals i.e. two-dimensional arrays of inclusions assumed of infinite extent along the three spatial directions. We show that the bandwidth of the forbidden band depends strongly on the nature of the constituent materials (solid or fluid), as well as the contrast between the physical characteristics (density and elastic moduli) of the inclusions and of the matrix, the geometry of the array of inclusions, the inclusion shape and the filling factor of inclusions. The second part of this review paper is devoted to some possible applications of these composite materials. In particular, we show that defect modes (cavities, waveguides, stubs, etc.) inserted inside the two-dimensional periodic structure may lead to very selective frequency filters and efficient devices for the wavelength demultiplexing. We present also the possibility of sonic insulators for frequencies of the order of kHz with relatively small thicknesses of phononic crystal samples. Finally we report on the vibration modes of a two-dimensional phononic crystal plate i.e. a phononic crystal of finite thickness along the axis of the inclusions. We discuss guided modes which may occur in the band structure of the plate. Surface acoustic waves propagating in twodimensional phononic crystals should open new perspectives in high-frequency radio-frequency devices. Throughout the paper, the methods of calculation are presented with some details and some experimental results complete the numerical predictions.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\ReviewArticles\Two-dimensional_phononic_crystals_Pennec_et_al_2010.pdf}
}

@article{peralta-angelesAnalyticallySupportedHybrid2022,
  title = {Analytically {{Supported Hybrid Photonic}}–Plasmonic {{Crystal Design Using Artificial Neural Networks}}},
  author = {Peralta-Ángeles, Jorge-Alberto and Reyes-Esqueda, Jorge-Alejandro},
  date = {2022-08-01},
  journaltitle = {Plasmonics},
  volume = {17},
  number = {4},
  pages = {1501--1525},
  issn = {1557-1963},
  doi = {10.1007/s11468-022-01640-9},
  url = {https://doi.org/10.1007/s11468-022-01640-9},
  urldate = {2024-06-21},
  abstract = {An analytical and numerical study of hybrid photonic–plasmonic crystals is presented. The proposed theoretical model describes a system composed of a dielectric photonic crystal on a metallic thin film. To show the validity and usefulness of the model, four particular structures are analyzed: a one-dimensional crystal and three lattices of two-dimensional crystals. The model can calculate the photonic band structure of photonic–plasmonic crystals as a function of structural characteristics, showing two partial bandgaps for a square lattice, and complete bandgaps for triangular lattices. Furthermore, using a particular high-symmetry path, a full bandgap emerges in rectangular lattices, even with a small refractive index contrast. Using the analytical model, a dataset is generated to train an artificial neural network to predict the center and width of the bandgap, that is, the forward design. In addition, an artificial neural network is trained to tune the optical response, that is, to perform the inverse design. The analytical results are consistent with the physics of the system studied and are supported by numerical simulations. Moreover, the prediction accuracy of the artificial neural networks is better than 95\%. Overall, this paper reports a useful tool for tuning the optical properties of hybrid photonic–plasmonic crystals with potential applications in waveguides, nanocavities, mirrors, etc.},
  langid = {english},
  keywords = {Artificial neural networks,Hybrid photonic–plasmonic crystals,Machine learning,Nanophotonics,Plane-wave expansion},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\AI\Modeling\OpticalProperties\Analytically_Supported_Hybrid_Peralta-Angeles_Reyes-Esqueda_2022.pdf}
}

@online{petersenLearningDifferentiableAlgorithms2022,
  title = {Learning with {{Differentiable Algorithms}}},
  author = {Petersen, Felix},
  date = {2022-09-01},
  eprint = {2209.00616},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.00616},
  urldate = {2023-08-26},
  abstract = {Classic algorithms and machine learning systems like neural networks are both abundant in everyday life. While classic computer science algorithms are suitable for precise execution of exactly defined tasks such as finding the shortest path in a large graph, neural networks allow learning from data to predict the most likely answer in more complex tasks such as image classification, which cannot be reduced to an exact algorithm. To get the best of both worlds, this thesis explores combining both concepts leading to more robust, better performing, more interpretable, more computationally efficient, and more data efficient architectures. The thesis formalizes the idea of algorithmic supervision, which allows a neural network to learn from or in conjunction with an algorithm. When integrating an algorithm into a neural architecture, it is important that the algorithm is differentiable such that the architecture can be trained end-to-end and gradients can be propagated back through the algorithm in a meaningful way. To make algorithms differentiable, this thesis proposes a general method for continuously relaxing algorithms by perturbing variables and approximating the expectation value in closed form, i.e., without sampling. In addition, this thesis proposes differentiable algorithms, such as differentiable sorting networks, differentiable renderers, and differentiable logic gate networks. Finally, this thesis presents alternative training strategies for learning with algorithms.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\DifferentiableFunctions\DifferentiableAlgorithms\Learning_with_Differentiable_Petersen_2022.pdf}
}

@article{peurifoyNanophotonicParticleSimulation2018,
  title = {Nanophotonic Particle Simulation and Inverse Design Using Artificial Neural Networks},
  author = {Peurifoy, John and Shen, Yichen and Jing, Li and Yang, Yi and Cano-Renteria, Fidel and DeLacy, Brendan G. and Joannopoulos, John D. and Tegmark, Max and Soljačić, Marin},
  date = {2018-06},
  journaltitle = {Science Advances},
  volume = {4},
  number = {6},
  pages = {eaar4206},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.aar4206},
  url = {https://www.science.org/doi/10.1126/sciadv.aar4206},
  urldate = {2024-06-01},
  abstract = {We propose a method to use artificial neural networks to approximate light scattering by multilayer nanoparticles. We find that the network needs to be trained on only a small sampling of the data to approximate the simulation to high precision. Once the neural network is trained, it can simulate such optical processes orders of magnitude faster than conventional simulations. Furthermore, the trained neural network can be used to solve nanophotonic inverse design problems by using back propagation, where the gradient is analytical, not numerical.},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\OneDimension\Nanophotonic_particle_Peurifoy_et_al_2018.pdf}
}

@article{pfiesterSelectiveEmittersThermophotovoltaic2017,
  title = {Selective Emitters for Thermophotovoltaic Applications},
  author = {Pfiester, Nicole A. and Vandervelde, Thomas E.},
  date = {2017-01},
  journaltitle = {Physica Status Solidi (a)},
  volume = {214},
  number = {1},
  pages = {1600410},
  issn = {1862-6300, 1862-6319},
  doi = {10.1002/pssa.201600410},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/pssa.201600410},
  urldate = {2024-06-01},
  abstract = {Applying thermophotovoltaic (TPV) technologies to existing energy generators allows us to increase energy output while utilizing present infrastructure by reclaiming the heat lost during the production process. In order to maximize the efficiency of these sources, the conversion efficiency of the TPV system needs to be optimized. Selective emitters are often used to tailor the spectrum of incident light on the diode, blocking any undesirable light that may lead to device heating or recombination. Over the years, many different technologies have been researched to create an ideal selective emitter. Plasmas and rare‐earth emitters provided highly selective spectra early on, but their fixed peaks required tailoring the diode's band gap to the emitter's characteristic wavelength. Recent advances in engineerable materials, such as photonic crystals and metamaterials, allow the opposite to take place; an appropriate selective emitter can be designed to match the TPV diode, allowing the diode structure to be optimized independently from the emitter.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\BlackBodyRadiation\Selective_emitters_for_thermophotovoltaic_applications_Pfiester_Vandervelde_2017.pdf}
}

@online{phamBlur2BlurBlurConversion2024,
  title = {{{Blur2Blur}}: {{Blur Conversion}} for {{Unsupervised Image Deblurring}} on {{Unknown Domains}}},
  shorttitle = {{{Blur2Blur}}},
  author = {Pham, Bang-Dang and Tran, Phong and Tran, Anh and Pham, Cuong and Nguyen, Rang and Hoai, Minh},
  date = {2024-03-24},
  eprint = {2403.16205},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.16205},
  url = {http://arxiv.org/abs/2403.16205},
  urldate = {2024-05-05},
  abstract = {This paper presents an innovative framework designed to train an image deblurring algorithm tailored to a specific camera device. This algorithm works by transforming a blurry input image, which is challenging to deblur, into another blurry image that is more amenable to deblurring. The transformation process, from one blurry state to another, leverages unpaired data consisting of sharp and blurry images captured by the target camera device. Learning this blur-to-blur transformation is inherently simpler than direct blur-to-sharp conversion, as it primarily involves modifying blur patterns rather than the intricate task of reconstructing fine image details. The efficacy of the proposed approach has been demonstrated through comprehensive experiments on various benchmarks, where it significantly outperforms state-of-the-art methods both quantitatively and qualitatively. Our code and data are available at https://zero1778.github.io/blur2blur/},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\SelfSupervised\Blur2Blur_Pham_et_al_2024.pdf}
}

@online{philippeEDPerceptuallyTuned2024,
  title = {{{ED}}: {{Perceptually}} Tuned {{Enhanced Compression Model}}},
  shorttitle = {{{ED}}},
  author = {Philippe, Pierrick and Ladune, Théo and Davenet, Stéphane and Leguay, Thomas},
  date = {2024-01-04},
  eprint = {2401.02145},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2401.02145},
  url = {http://arxiv.org/abs/2401.02145},
  urldate = {2024-12-03},
  abstract = {This paper summarises the design of the candidate ED for the Challenge on Learned Image Compression 2024. This candidate aims at providing an anchor based on conventional coding technologies to the learning-based approaches mostly targeted in the challenge. The proposed candidate is based on the Enhanced Compression Model (ECM) developed at JVET, the Joint Video Experts Team of ITU-T VCEG and ISO/IEC MPEG. Here, ECM is adapted to the challenge objective: to maximise the perceived quality, the encoding is performed according to a perceptual metric, also the sequence selection is performed in a perceptual manner to fit the target bit per pixel objectives. The primary objective of this candidate is to assess the recent developments in video coding standardisation and in parallel to evaluate the progress made by learning-based techniques. To this end, this paper explains how to generate coded images fulfilling the challenge requirements, in a reproducible way, targeting the maximum performance.},
  pubstate = {prepublished},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\Zotero\storage\DUHJ6ADB\Philippe et al. - 2024 - ED Perceptually tuned Enhanced Compression Model.pdf}
}

@article{phillipKramersKronigAnalysisReflectance1964,
  title = {Kramers-{{Kronig Analysis}} of {{Reflectance Data}} for {{Diamond}}},
  author = {Phillip, H. R. and Taft, E. A.},
  date = {1964-11-30},
  journaltitle = {Phys. Rev.},
  volume = {136},
  pages = {A1445-A1448},
  issn = {0031-899X},
  doi = {10.1103/PhysRev.136.A1445},
  url = {https://link.aps.org/doi/10.1103/PhysRev.136.A1445},
  urldate = {2023-09-05},
  issue = {5A},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Dielectric\Kramers-Kronig_Analysis_of_Reflectance_Data_for_Diamond_Phillip_Taft_1964.pdf}
}

@book{pikusArtWritingEfficient2021,
  title = {The Art of Writing Efficient Programs: An Advanced Programmer's Guide to Efficient Hardware Utilization and Compiler Optimizations Using {{C}}++ Examples},
  shorttitle = {The Art of Writing Efficient Programs},
  author = {Pikus, Fedor G.},
  date = {2021},
  publisher = {Packt Publishing},
  location = {Birmingham Mumbai},
  isbn = {978-1-80020-811-7},
  langid = {english},
  pagetotal = {444},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\Programming\The_art_of_writing_efficient_programs_Pikus_2021.pdf}
}

@online{pinayaGenerativeAIMedical2023,
  title = {Generative {{AI}} for {{Medical Imaging}}: Extending the {{MONAI Framework}}},
  shorttitle = {Generative {{AI}} for {{Medical Imaging}}},
  author = {Pinaya, Walter H. L. and Graham, Mark S. and Kerfoot, Eric and Tudosiu, Petru-Daniel and Dafflon, Jessica and Fernandez, Virginia and Sanchez, Pedro and Wolleb, Julia and family=Costa, given=Pedro F., prefix=da, useprefix=false and Patel, Ashay and Chung, Hyungjin and Zhao, Can and Peng, Wei and Liu, Zelong and Mei, Xueyan and Lucena, Oeslle and Ye, Jong Chul and Tsaftaris, Sotirios A. and Dogra, Prerna and Feng, Andrew and Modat, Marc and Nachev, Parashkev and Ourselin, Sebastien and Cardoso, M. Jorge},
  date = {2023-07-27},
  eprint = {2307.15208},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2307.15208},
  url = {http://arxiv.org/abs/2307.15208},
  urldate = {2024-12-13},
  abstract = {Recent advances in generative AI have brought incredible breakthroughs in several areas, including medical imaging. These generative models have tremendous potential not only to help safely share medical data via synthetic datasets but also to perform an array of diverse applications, such as anomaly detection, image-to-image translation, denoising, and MRI reconstruction. However, due to the complexity of these models, their implementation and reproducibility can be difficult. This complexity can hinder progress, act as a use barrier, and dissuade the comparison of new methods with existing works. In this study, we present MONAI Generative Models, a freely available open-source platform that allows researchers and developers to easily train, evaluate, and deploy generative models and related applications. Our platform reproduces state-of-art studies in a standardised way involving different architectures (such as diffusion models, autoregressive transformers, and GANs), and provides pre-trained models for the community. We have implemented these models in a generalisable fashion, illustrating that their results can be extended to 2D or 3D scenarios, including medical images with different modalities (like CT, MRI, and X-Ray data) and from different anatomical areas. Finally, we adopt a modular and extensible approach, ensuring long-term maintainability and the extension of current applications for future features.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\Medical\Generative_AI_for_Medical_Pinaya_et_al_2023.pdf}
}

@article{Plane_wave_propagation_in_finite_22_composites_Cao_Qi_1995Pdf,
  title = {Plane\_wave\_propagation\_in\_finite\_2‐2\_composites\_{{Cao}}\_{{Qi}}\_1995.Pdf},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Plane_wave_propagation_in_finite_2‐2_composites_Cao_Qi_1995_.pdf}
}

@online{podellSDXLImprovingLatent2023,
  title = {{{SDXL}}: {{Improving Latent Diffusion Models}} for {{High-Resolution Image Synthesis}}},
  shorttitle = {{{SDXL}}},
  author = {Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and Müller, Jonas and Penna, Joe and Rombach, Robin},
  date = {2023-07-04},
  eprint = {2307.01952},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.01952},
  url = {http://arxiv.org/abs/2307.01952},
  urldate = {2024-12-24},
  abstract = {We present SDXL, a latent diffusion model for text-to-image synthesis. Compared to previous versions of Stable Diffusion, SDXL leverages a three times larger UNet backbone: The increase of model parameters is mainly due to more attention blocks and a larger cross-attention context as SDXL uses a second text encoder. We design multiple novel conditioning schemes and train SDXL on multiple aspect ratios. We also introduce a refinement model which is used to improve the visual fidelity of samples generated by SDXL using a post-hoc image-to-image technique. We demonstrate that SDXL shows drastically improved performance compared the previous versions of Stable Diffusion and achieves results competitive with those of black-box state-of-the-art image generators. In the spirit of promoting open research and fostering transparency in large model training and evaluation, we provide access to code and model weights at https://github.com/Stability-AI/generative-models},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\DiffusionModels\SDXL_Podell_et_al_2023.pdf}
}

@inproceedings{poggiCrossSpectralNeuralRadiance2022,
  title = {Cross-{{Spectral Neural Radiance Fields}}},
  booktitle = {2022 {{International Conference}} on {{3D Vision}} ({{3DV}})},
  author = {Poggi, Matteo and Ramirez, Pierluigi Zama and Tosi, Fabio and Salti, Samuele and Mattoccia, Stefano and Stefano, Luigi Di},
  date = {2022-09},
  pages = {606--616},
  issn = {2475-7888},
  doi = {10.1109/3DV57658.2022.00071},
  abstract = {We propose X-NeRF, a novel method to learn a Cross-Spectral scene representation given images captured from cameras with different light spectrum sensitivity, based on the Neural Radiance Fields formulation. X-NeRF optimizes camera poses across spectra during training and exploits Normalized Cross-Device Coordinates (NXDC) to render images of different modalities from arbitrary viewpoints, which are aligned and at the same resolution. Experiments on 16 forward-facing scenes, featuring color, multi-spectral and infrared images, confirm the effectiveness of X-NeRF at modeling Cross-Spectral scene representations.},
  eventtitle = {2022 {{International Conference}} on {{3D Vision}} ({{3DV}})},
  keywords = {Image color analysis,Image resolution,Image sensors,Lightning,Sensitivity,Three-dimensional displays,Training},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\MultiSpectral\Cross-Spectral_Neural_Radiance_Fields_Poggi_et_al_2022.pdf}
}

@article{polyanskiyRefractiveindexinfoDatabaseOptical2024,
  title = {Refractiveindex.Info Database of Optical Constants},
  author = {Polyanskiy, Mikhail N.},
  date = {2024-01-18},
  journaltitle = {Sci Data},
  volume = {11},
  number = {1},
  pages = {94},
  issn = {2052-4463},
  doi = {10.1038/s41597-023-02898-2},
  url = {https://www.nature.com/articles/s41597-023-02898-2},
  urldate = {2024-12-16},
  abstract = {Abstract                            We introduce the               refractiveindex.info               database, a comprehensive open-source repository containing optical constants for a wide array of materials, and describe in detail the underlying dataset. This collection, derived from a meticulous compilation of data sourced from peer-reviewed publications, manufacturers’ datasheets, and authoritative texts, aims to advance research in optics and photonics. The data is stored using a YAML-based format, ensuring integrity, consistency, and ease of access. Each record is accompanied by detailed metadata, facilitating a comprehensive understanding and efficient utilization of the data. In this descriptor, we outline the data curation protocols and the file format used for data records, and briefly demonstrate how the data can be organized in a user-friendly fashion akin to the books in a traditional library.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\Datasets\Refractiveindex_Polyanskiy_2024.pdf}
}

@article{porras-montenegroTemperatureHydrostaticPressure2010,
  title = {Temperature and Hydrostatic Pressure Effects on the Photonic Band Structure of a {{2D}} Honeycomb Lattice},
  author = {Porras-Montenegro, N. and Duque, C.A.},
  date = {2010-04},
  journaltitle = {Physica E: Low-dimensional Systems and Nanostructures},
  volume = {42},
  number = {6},
  pages = {1865--1869},
  issn = {13869477},
  doi = {10.1016/j.physe.2010.02.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1386947710001128},
  urldate = {2024-01-22},
  abstract = {A standard plane-wave expansion method is used to investigate temperature and applied hydrostatic pressure dependence of the photonic band structure of a two-dimensional honeycomb lattice composed by cylindrical rods of GaAs, embedded in air. Present results suggest that for H-polarization an increment of hydrostatic pressure and temperature not only shifts the photonic band gaps, but diminish the energy width of the second and upper band gaps, while for E-polarization the first band gap is shifted to higher energies, without modifying the width of the other band-gaps, consequently modifying the tunability of this system.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\Temperature_and_hydrostatic_pressure_effects_on_the_photonic_band_structure_of_Porras-Montenegro_Duque_2010.pdf}
}

@article{porras-montenegroTemperatureHydrostaticPressure2010a,
  title = {Temperature and Hydrostatic Pressure Effects on the Photonic Band Structure of a {{2D}} Honeycomb Lattice},
  author = {Porras-Montenegro, N. and Duque, C.A.},
  date = {2010-04},
  journaltitle = {Physica E: Low-dimensional Systems and Nanostructures},
  volume = {42},
  number = {6},
  pages = {1865--1869},
  issn = {13869477},
  doi = {10.1016/j.physe.2010.02.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1386947710001128},
  urldate = {2024-01-22},
  abstract = {A standard plane-wave expansion method is used to investigate temperature and applied hydrostatic pressure dependence of the photonic band structure of a two-dimensional honeycomb lattice composed by cylindrical rods of GaAs, embedded in air. Present results suggest that for H-polarization an increment of hydrostatic pressure and temperature not only shifts the photonic band gaps, but diminish the energy width of the second and upper band gaps, while for E-polarization the first band gap is shifted to higher energies, without modifying the width of the other band-gaps, consequently modifying the tunability of this system.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\Temperature_and_hydrostatic_pressure_effects_on_the_photonic_band_structure_of_Porras-Montenegro_Duque_22.pdf}
}

@inproceedings{prativadibhayankaramColorLearningImage2023,
  title = {Color {{Learning}} for {{Image Compression}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author = {Prativadibhayankaram, Srivatsa and Richter, Thomas and Sparenberg, Heiko and Fößel, Siegfried},
  date = {2023-10-08},
  eprint = {2306.17460},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  pages = {2330--2334},
  doi = {10.1109/ICIP49359.2023.10222731},
  url = {http://arxiv.org/abs/2306.17460},
  urldate = {2024-07-12},
  abstract = {Deep learning based image compression has gained a lot of momentum in recent times. To enable a method that is suitable for image compression and subsequently extended to video compression, we propose a novel deep learning model architecture, where the task of image compression is divided into two sub-tasks, learning structural information from luminance channel and color from chrominance channels. The model has two separate branches to process the luminance and chrominance components. The color difference metric CIEDE2000 is employed in the loss function to optimize the model for color fidelity. We demonstrate the benefits of our approach and compare the performance to other codecs. Additionally, the visualization and analysis of latent channel impulse response is performed.},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Color_Learning_for_Image_Prativadibhayankaram_et_al_2023.pdf}
}

@online{prativadibhayankaramSLICLearnedImage2024a,
  title = {{{SLIC}}: {{A Learned Image Codec Using Structure}} and {{Color}}},
  shorttitle = {{{SLIC}}},
  author = {Prativadibhayankaram, Srivatsa and Panda, Mahadev Prasad and Richter, Thomas and Sparenberg, Heiko and Fößel, Siegfried and Kaup, André},
  date = {2024-01-30},
  eprint = {2401.17246},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2401.17246},
  urldate = {2024-07-12},
  abstract = {We propose the structure and color based learned image codec (SLIC) in which the task of compression is split into that of luminance and chrominance. The deep learning model is built with a novel multi-scale architecture for Y and UV channels in the encoder, where the features from various stages are combined to obtain the latent representation. An autoregressive context model is employed for backward adaptation and a hyperprior block for forward adaptation. Various experiments are carried out to study and analyze the performance of the proposed model, and to compare it with other image codecs. We also illustrate the advantages of our method through the visualization of channel impulse responses, latent channels and various ablation studies. The model achieves Bjøntegaard delta bitrate gains of 7.5\% and 4.66\% in terms of MS-SSIM and CIEDE2000 metrics with respect to other state-of-the-art reference codecs.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\SLIC_Prativadibhayankaram_et_al_22.pdf}
}

@article{prevedelBrillouinMicroscopyEmerging2019,
  title = {Brillouin Microscopy: An Emerging Tool for Mechanobiology},
  shorttitle = {Brillouin Microscopy},
  author = {Prevedel, Robert and Diz-Muñoz, Alba and Ruocco, Giancarlo and Antonacci, Giuseppe},
  date = {2019-10},
  journaltitle = {Nat Methods},
  volume = {16},
  number = {10},
  pages = {969--977},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-019-0543-3},
  url = {https://www.nature.com/articles/s41592-019-0543-3},
  urldate = {2024-07-04},
  abstract = {The role and importance of mechanical properties of cells and tissues in cellular function, development and disease has widely been acknowledged, however standard techniques currently used to assess them exhibit intrinsic limitations. Recently, Brillouin microscopy, a type of optical elastography, has emerged as a non-destructive, label- and contact-free method that can probe the viscoelastic properties of biological samples with diffraction-limited resolution in 3D. This led to increased attention amongst the biological and medical research communities, but it also sparked debates about the interpretation and relevance of the measured physical quantities. Here, we review this emerging technology by describing the underlying biophysical principles and discussing the interpretation of Brillouin spectra arising from heterogeneous biological matter. We further elaborate on the technique’s limitations, as well as its potential for gaining insights in biology, in order to guide interested researchers from various fields.},
  langid = {english},
  keywords = {Biophysics,Microscopy,Optical imaging,Optical spectroscopy},
  file = {C:\Users\ahmed\OneDrive\Research\OtherTopics\Joachim_max_plank_optics\Brillouin_microscopy_Prevedel_et_al_2019.pdf}
}

@inproceedings{psychogyiosRealisticEndoscopicIllumination2023,
  title = {Realistic {{Endoscopic Illumination Modeling}} for~{{NeRF-Based Data Generation}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} – {{MICCAI}} 2023},
  author = {Psychogyios, Dimitrios and Vasconcelos, Francisco and Stoyanov, Danail},
  editor = {Greenspan, Hayit and Madabhushi, Anant and Mousavi, Parvin and Salcudean, Septimiu and Duncan, James and Syeda-Mahmood, Tanveer and Taylor, Russell},
  date = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {535--544},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-43996-4_51},
  abstract = {Expanding training and evaluation data is a major step towards building and deploying reliable localization and 3D reconstruction techniques during colonoscopy screenings. However, training and evaluating pose and depth models in colonoscopy is hard as available datasets are limited in size. This paper proposes a method for generating new pose and depth datasets by fitting NeRFs in already available colonoscopy datasets. Given a set of images, their associated depth maps and pose information, we train a novel light source location-conditioned NeRF to encapsulate the 3D and color information of a colon sequence. Then, we leverage the trained networks to render images from previously unobserved camera poses and simulate different camera systems, effectively expanding the source dataset. Our experiments show that our model is able to generate RGB images and depth maps of a colonoscopy sequence from previously unobserved poses with high accuracy. Code and trained networks can be accessed at https://github.com/surgical-vision/REIM-NeRF.},
  isbn = {978-3-031-43996-4},
  langid = {english},
  keywords = {Colonoscopy,Data generation,Neural Rendering,Surgical AI,Surgical Data Science},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Endoscope\Realistic_Endoscopic_Illumination_Modeling_for_NeRF-Based_Data_Generation_Psychogyios_et_al_2023.pdf}
}

@article{pulletzDynamicRelativeRegional2022,
  title = {Dynamic Relative Regional Strain Visualized by Electrical Impedance Tomography in Patients Suffering from {{COVID-19}}},
  author = {Pulletz, Sven and Krukewitt, Lisa and Gonzales-Rios, Pablo and Teschendorf, Peter and Kremeier, Peter and Waldmann, Andreas and Zitzmann, Amelie and Müller-Graf, Fabian and Acosta, Cecilia and Tusman, Gerado and Reuter, Daniel A. and Böhm, Stephan H.},
  date = {2022-08},
  journaltitle = {J Clin Monit Comput},
  volume = {36},
  number = {4},
  pages = {975--985},
  issn = {1387-1307, 1573-2614},
  doi = {10.1007/s10877-021-00748-3},
  url = {https://link.springer.com/10.1007/s10877-021-00748-3},
  urldate = {2024-07-08},
  abstract = {Respiratory failure due to SARS-CoV-2 may progress rapidly. During the course of COVID-19, patients develop an increased respiratory drive, which may induce high mechanical strain a known risk factor for Patient Self-Inflicted Lung Injury (P-SILI). We developed a novel Electrical Impedance Tomography-based approach to visualize the Dynamic Relative Regional Strain (DRRS) in SARS-CoV-2 positive patients and compared these findings with measurements in lung healthy volunteers. DRRS was defined as the ratio of tidal impedance changes and end-expiratory lung impedance within each pixel of the lung region. DRRS values of the ten patients were considerably higher than those of the ten healthy volunteers. On repeated examination, patterns, magnitude and frequency distribution of DRRS were reproducible and in line with the clinical course of the patients. Lung ultrasound scores correlated with the number of pixels showing DRRS values above the derived threshold. Using Electrical Impedance Tomography we were able to generate, for the first time, images of DRRS which might indicate P-SILI in patients suffering from COVID-19.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Dynamic_relative_regional_strain_visualized_by_electrical_impedance_tomography_Pulletz_et_al_2022.pdf}
}

@inproceedings{pumarolaDNeRFNeuralRadiance2021,
  title = {D-{{NeRF}}: {{Neural Radiance Fields}} for {{Dynamic Scenes}}},
  shorttitle = {D-{{NeRF}}},
  author = {Pumarola, Albert and Corona, Enric and Pons-Moll, Gerard and Moreno-Noguer, Francesc},
  date = {2021},
  pages = {10318--10327},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Pumarola_D-NeRF_Neural_Radiance_Fields_for_Dynamic_Scenes_CVPR_2021_paper.html?ref=labelbox.ghost.io},
  urldate = {2023-07-28},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\DynamicScenes\D-NeRF_Pumarola_et_al_2021.pdf}
}

@article{qianAcoustoopticInteractionPhotonic2009,
  title = {Acousto-Optic Interaction in Photonic Crystals with Defects},
  author = {Qian, Xiao-Shi and Li, Jing-Ping and Lu, Ming-hui and Lu, Yan-qing and Chen, Yan-feng},
  date = {2009-08-15},
  journaltitle = {Journal of Applied Physics},
  volume = {106},
  number = {4},
  pages = {043107},
  issn = {0021-8979, 1089-7550},
  doi = {10.1063/1.3204018},
  url = {https://pubs.aip.org/jap/article/106/4/043107/988019/Acousto-optic-interaction-in-photonic-crystals},
  urldate = {2024-01-22},
  abstract = {The acousto-optic (AO) effects of photonic crystals (PCs) were studied. Both the PCs’ periodicity and their index distribution could be modulated instantly by the propagating acoustic wave. As a consequence, the PCs’ band structure becomes tunable. In addition to band gap shift in an ideal PC, AO frequency modulation was observed in a PC with single defect, which is quite different from normal AO tunable filters and gives rise to some interesting applications. Furthermore, in dual-defect situation, synchronized and desynchronized modulations were realized at different acoustic wavelengths. Interesting phenomena such as dual frequency sweeping and dual frequency Q-switching were demonstrated.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\Acousto-optic_interaction_in_photonic_crystals_with_defects_Qian_et_al_2009.pdf}
}

@article{qiBandGapCharacteristics2011,
  title = {Band Gap Characteristics of Plasma with Periodically Varying External Magnetic Field},
  author = {Qi, L. and Zhang, X.},
  date = {2011-12},
  journaltitle = {Solid State Communications},
  volume = {151},
  number = {23},
  pages = {1838--1841},
  issn = {00381098},
  doi = {10.1016/j.ssc.2011.08.012},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0038109811004224},
  urldate = {2024-01-22},
  abstract = {The reflectance characteristics of a one-dimensional periodically magnetized plasma structure is studied by using the transfer matrix method. It is found that this system has the band gap characteristics of photonic crystals, so we also name it a plasma photonic crystal. The results show that the gap location and gap width can be controlled by the incident angle. If the external magnetic field is small, the gap location and gap width change significantly with incident angle, while they change only slightly when the external magnetic field is sufficiently large. The collision frequency has little effect on the gap location and gap width while it makes the amplitude of reflectance and transmission decrease. This new type of plasma photonic crystal could have potential applications in designing tunable photonic crystal devices.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Band_gap_characteristics_of_plasma_with_periodically_varying_external_magnetic_Qi_Zhang_2011.pdf}
}

@article{qiDefectModesOnedimensional2012,
  title = {Defect Modes in One-Dimensional Magnetized Plasma Photonic Crystals with a Dielectric Defect Layer},
  author = {Qi, L. and Yang, Z. and Fu, T.},
  date = {2012-01-01},
  journaltitle = {Physics of Plasmas},
  volume = {19},
  number = {1},
  pages = {012509},
  issn = {1070-664X, 1089-7674},
  doi = {10.1063/1.3677876},
  url = {https://pubs.aip.org/pop/article/19/1/012509/107265/Defect-modes-in-one-dimensional-magnetized-plasma},
  urldate = {2024-01-22},
  abstract = {By using transfer matrix method, properties of one-dimensional magnetized plasma photonic crystals with a dielectric defect layer are studied. Results show that several defect modes appear within the photonic band gaps; periodic number and collision frequency only affect transmission magnitude of the defect modes; the external magnetic field and incident angle control both the transmission magnitude and frequency of the defect modes; thickness and dielectric constant of the defect layer determine both the number and frequency of the defect modes. This phenomenon may be useful in designing of narrow band filters or multi-channel filters.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Defect_modes_in_one-dimensional_magnetized_plasma_photonic_crystals_with_a_Qi_et_al_2012.pdf}
}

@online{qinLangSplat3DLanguage2023,
  title = {{{LangSplat}}: {{3D Language Gaussian Splatting}}},
  shorttitle = {{{LangSplat}}},
  author = {Qin, Minghan and Li, Wanhua and Zhou, Jiawei and Wang, Haoqian and Pfister, Hanspeter},
  date = {2023-12-26},
  eprint = {2312.16084},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.16084},
  url = {http://arxiv.org/abs/2312.16084},
  urldate = {2024-01-22},
  abstract = {Human lives in a 3D world and commonly uses natural language to interact with a 3D scene. Modeling a 3D language field to support open-ended language queries in 3D has gained increasing attention recently. This paper introduces LangSplat, which constructs a 3D language field that enables precise and efficient open-vocabulary querying within 3D spaces. Unlike existing methods that ground CLIP language embeddings in a NeRF model, LangSplat advances the field by utilizing a collection of 3D Gaussians, each encoding language features distilled from CLIP, to represent the language field. By employing a tile-based splatting technique for rendering language features, we circumvent the costly rendering process inherent in NeRF. Instead of directly learning CLIP embeddings, LangSplat first trains a scene-wise language autoencoder and then learns language features on the scene-specific latent space, thereby alleviating substantial memory demands imposed by explicit modeling. Existing methods struggle with imprecise and vague 3D language fields, which fail to discern clear boundaries between objects. We delve into this issue and propose to learn hierarchical semantics using SAM, thereby eliminating the need for extensively querying the language field across various scales and the regularization of DINO features. Extensive experiments on open-vocabulary 3D object localization and semantic segmentation demonstrate that LangSplat significantly outperforms the previous state-of-the-art method LERF by a large margin. Notably, LangSplat is extremely efficient, achieving a \{\textbackslash speed\} \$\textbackslash times\$ speedup compared to LERF at the resolution of 1440 \$\textbackslash times\$ 1080. We strongly recommend readers to check out our video results at https://langsplat.github.io},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\TextAndImage\LangSplat_Qin_et_al_2023.pdf}
}

@article{qiPhotonicBandGaps2011,
  title = {Photonic {{Band Gaps}} of {{One-Dimensional Ternary Plasma Photonic Crystals}} with {{Periodic}} and {{Periodic-Varying Structures}}},
  author = {Qi, L. and Zhang, X.},
  date = {2011-01},
  journaltitle = {Journal of Electromagnetic Waves and Applications},
  volume = {25},
  number = {4},
  pages = {539--552},
  issn = {0920-5071, 1569-3937},
  doi = {10.1163/156939311794500331},
  url = {https://www.tandfonline.com/doi/full/10.1163/156939311794500331},
  urldate = {2024-01-22},
  abstract = {Photonic band gaps (PBGs) of one-dimensional (1D) ternary plasma photonic crystal (PPC) with periodic and periodicvarying structures are studied based on transfer matrix method. For 1D ternary PPC, PBG can be enlarged compared with 1D binary PPC, and the influences of plasma frequency, collision frequency and incident angle on PBG are also discussed, respectively. For 1D periodic-varying structure, both the gap width and location can be controlled by thickness varying of layers with arithmetic and sinusoidal sequences.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Photonic_Band_Gaps_of_One-Dimensional_Ternary_Plasma_Photonic_Crystals_with_Qi_Zhang_2011.pdf}
}

@article{qiPropertiesObliquelyIncident2010,
  title = {Properties of Obliquely Incident Electromagnetic Wave in One-Dimensional Magnetized Plasma Photonic Crystals},
  author = {Qi, Limei and Yang, Ziqiang and Lan, Feng and Gao, Xi and Shi, Zongjun},
  date = {2010-04-01},
  journaltitle = {Physics of Plasmas},
  volume = {17},
  number = {4},
  pages = {042501},
  issn = {1070-664X, 1089-7674},
  doi = {10.1063/1.3360296},
  url = {https://pubs.aip.org/pop/article/17/4/042501/970204/Properties-of-obliquely-incident-electromagnetic},
  urldate = {2024-01-22},
  abstract = {Properties of obliquely incident electromagnetic wave in one-dimensional (1D) magnetized plasma photonic crystals (PPCs) are studied in this paper. Based on the continuous boundary condition of electromagnetic wave in 1D PPC, transfer matrix equation and dispersion equation of transverse magnetic polarization are deduced, and the properties of dispersion and transmission relation in terms of external magnetic field, collision frequency, and dielectric constant of dielectric and incident angles are investigated, respectively. Results show that gap location and gap width can be effectively controlled by adjusting external magnetic field as well as incident angle, and increasing collision frequency has little effect on gap width while larger dielectric constant of dielectric leads to more gaps.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Properties_of_obliquely_incident_electromagnetic_wave_in_one-dimensional_Qi_et_al_2010.pdf}
}

@article{qiuNanophotonicInverseDesign2021,
  title = {Nanophotonic Inverse Design with Deep Neural Networks Based on Knowledge Transfer Using Imbalanced Datasets},
  author = {Qiu, Cankun and Wu, Xia and Luo, Zhi and Yang, Huidong and He, Guannan and Huang, Bo},
  date = {2021-08-30},
  journaltitle = {Opt. Express, OE},
  volume = {29},
  number = {18},
  pages = {28406--28415},
  publisher = {Optica Publishing Group},
  issn = {1094-4087},
  doi = {10.1364/OE.435427},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-29-18-28406},
  urldate = {2024-06-01},
  abstract = {Deep neural networks (DNNs) have been used as a new method for nanophotonic inverse design. However, DNNs need a huge dataset to train if we need to select materials from the material library for the inverse design. This puts the DNN method into a dilemma of poor performance with a small training dataset or loss of the advantage of short design time, for collecting a large amount of data is time consuming. In this work, we propose a multi-scenario training method for the DNN model using imbalanced datasets. The imbalanced datasets used by our method is nearly four times smaller compared with other training methods. We believe that as the material library increases, the advantages of the imbalanced datasets will become more obvious. Using the high-precision predictive DNN model obtained by this new method, different multilayer nanoparticles and multilayer nanofilms have been designed with a hybrid optimization algorithm combining genetic algorithm and gradient descent optimization algorithm. The advantage of our method is that it can freely select discrete materials from the material library and simultaneously find the inverse design of discrete material type and continuous structural parameters of the nanophotonic devices.},
  langid = {english},
  keywords = {Genetic algorithms,Inverse design,Neural networks,Numerical simulation,Photonic crystals,Photonic devices},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\GenerativeAdversarialNetworks\Nanophotonic_inverse_design_with_deep_neural_networks_based_on_knowledge_Qiu_et_al_2021.pdf}
}

@article{rahimiPHOTONICTRANSMISSIONSPECTRA2010,
  title = {{{PHOTONIC TRANSMISSION SPECTRA IN ONE-DIMENSIONAL FIBONACCI MULTILAYER STRUCTURES CONTAINING SINGLE-NEGATIVE METAMATERIALS}}},
  author = {Rahimi, Hadi and Namdar, Abdolrahman and Roshan Entezar, Samad and Tajalli, Habib},
  date = {2010},
  journaltitle = {PIER},
  volume = {102},
  pages = {15--30},
  issn = {1559-8985},
  doi = {10.2528/PIER09122303},
  url = {http://www.jpier.org/PIER/pier.php?paper=09122303},
  urldate = {2023-11-06},
  abstract = {We investigate the transmission properties of the Fibonacci quasiperiodic layered structures consisting of a pair of double positive (DPS), epsilon-negative (ENG) or/and mu-negative (MNG) materials. It is found that there exist the polarization-dependent transmission gaps which are invariant with a change of scaling and insensitive to incident angles. Analytical methods based on transfer matrices and effective medium theory have been used to explain the properties of transmission gaps of DPS-MNG, DPS-ENG and ENGMNG Fibonacci multilayer structures.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\PHOTONIC_TRANSMISSION_SPECTRA_IN_ONE-DIMENSIONAL_FIBONACCI_MULTILAYER_Rahimi_et_al_2010.pdf}
}

@article{rambhatlaAdaptivePhaseEstimation2020,
  title = {Adaptive Phase Estimation through a Genetic Algorithm},
  author = {Rambhatla, Kartikeya and D'Aurelio, Simone Evaldo and Valeri, Mauro and Polino, Emanuele and Spagnolo, Nicolò and Sciarrino, Fabio},
  date = {2020-07-15},
  journaltitle = {Phys. Rev. Res.},
  volume = {2},
  number = {3},
  pages = {033078},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevResearch.2.033078},
  url = {https://link.aps.org/doi/10.1103/PhysRevResearch.2.033078},
  urldate = {2024-06-01},
  abstract = {Quantum metrology is one of the most relevant applications of quantum information theory to quantum technologies. Here, quantum probes are exploited to overcome classical bounds in the estimation of unknown parameters. In this context, phase estimation, where the unknown parameter is a phase shift between two modes of a quantum system, is a fundamental problem. In practical and realistic applications, it is necessary to devise methods to optimally estimate an unknown phase shift by using a limited number of probes. Here we introduce and experimentally demonstrate a machine learning-based approach for the adaptive estimation of a phase shift in a Mach-Zehnder interferometer, tailored for optimal performances with limited resources. The employed technique is a genetic algorithm used to devise the optimal feedback phases employed during the estimation in an offline fashion. The results show the capability to retrieve the true value of the phase by using few photons, and to reach the sensitivity bounds in such small probe regime. We finally investigate the robustness of the protocol with respect to common experimental errors, showing that the protocol can be adapted to a noisy scenario. Such approach promises to be a useful tool for more complex and general tasks where optimization of feedback parameters is required.},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\GeneticAlgorithms\Adaptive_phase_estimation_through_a_genetic_algorithm_Rambhatla_et_al_2020.pdf}
}

@article{rastogiStructuralHealthMonitoring2021,
  title = {Structural Health Monitoring of Irradiated High-Density Polyethylene Samples with Electrical Resistance Tomography},
  author = {Rastogi, Shreya and Bartolo, David and Gurses, Sadi and Kronawitter, Coleman and La Saponara, Valeria},
  date = {2021-11},
  journaltitle = {J Mater Sci},
  volume = {56},
  number = {31},
  pages = {17824--17842},
  issn = {0022-2461, 1573-4803},
  doi = {10.1007/s10853-021-06398-9},
  url = {https://link.springer.com/10.1007/s10853-021-06398-9},
  urldate = {2024-07-08},
  abstract = {This work presents preliminary results of a multifunctional lightweight material for radiation sensing and protection. The proposed concept is built with off-theshelf components: molded high-density polyethylene (HDPE) sheets and a commercial carbon black coating designed as a shield for electromagnetic interference (EMI). The HDPE is a hydrogen-rich lightweight material that is commonly used for radiation protection. The carbon black coating is a nonstructural, electrically conductive coating that serves here not only the purpose of structural health monitor, but also protects the underlying HDPE structure. The carbon black-coated area in the HDPE samples was instrumented with electrodes for electrical resistance tomography (ERT), the structural monitoring method that we propose in this work. Two types of radiation (UV-C radiation for 24 h and protons with a 50 Gy dose, lethal to humans) were used separately, as representative of a harsh space environment. Fourier transform infrared spectroscopy (FTIR) was applied to selected samples to determine the presence of chemical damage as a result of the radiation exposure. The results support this innovative proof of concept for further investigation in the area of radiation protection and monitoring.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Industry\MaterialScience\Structural_health_monitoring_of_irradiated_high-density_polyethylene_samples_Rastogi_et_al_2021.pdf}
}

@online{RayTuneHyperparameter,
  title = {Ray {{Tune}}: {{Hyperparameter Tuning}} — {{Ray}} 2.40.0},
  url = {https://docs.ray.io/en/latest/tune/index.html},
  urldate = {2024-12-06}
}

@article{regoDesignPlanarMultilayer2024,
  title = {Design of {{Planar Multilayer Devices}} for {{Optical Filtering Using Surrogate Model Based}} on {{Artificial Neural Network}}},
  author = {Rêgo, Davi F. and Silva, Fabrício G. S. and Gusmão, Rodrigo C. and Rodriguez-Esquerre, Vitaly F.},
  date = {2024-03},
  journaltitle = {Optics},
  volume = {5},
  number = {1},
  pages = {121--132},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2673-3269},
  doi = {10.3390/opt5010009},
  url = {https://www.mdpi.com/2673-3269/5/1/9},
  urldate = {2024-05-31},
  abstract = {Artificial intelligence paradigms hold significant potential to advance nanophotonics. This study presents a novel approach to designing a plasmonic absorber using an artificial neural network as a surrogate model in conjunction with a genetic algorithm. The methodology involved numerical simulations of multilayered metal–dielectric plasmonic structures to establish a dataset for training an artificial neural network (ANN). The results demonstrate the proficiency of the trained ANN in predicting reflectance spectra and its ability to generalize intricate relationships between desired performance and geometric configurations, with values of correlation higher than 98\% in comparison with ground-truth electromagnetic simulations. Furthermore, the ANN was employed as a surrogate model in a genetic algorithm (GA) loop to achieve target optical behaviors. The proposed methodology provides a powerful means of inverse designing multilayered metal–dielectric devices tailored for visible band wavelength filtering. This research demonstrates that the integration of AI-driven approaches in nanophotonics leads to efficient and effective design strategies.},
  issue = {1},
  langid = {english},
  keywords = {finite element method,genetic algorithm,inverse design,photonics},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\OneDimension\Design_of_Planar_Multilayer_Rego_et_al_2024.pdf}
}

@inproceedings{relicLossyImageCompression2025,
  title = {Lossy {{Image Compression}} with~{{Foundation Diffusion Models}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2024},
  author = {Relic, Lucas and Azevedo, Roberto and Gross, Markus and Schroers, Christopher},
  editor = {Leonardis, Aleš and Ricci, Elisa and Roth, Stefan and Russakovsky, Olga and Sattler, Torsten and Varol, Gül},
  date = {2025},
  pages = {303--319},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-73030-6_17},
  abstract = {Incorporating diffusion models in the image compression domain has the potential to produce realistic and detailed reconstructions, especially at extremely low bitrates. Previous methods focus on using diffusion models as expressive decoders robust to quantization errors in the conditioning signals. However, achieving competitive results in this manner requires costly training of the diffusion model and long inference times due to~the iterative generative process. In this work we formulate the removal of quantization error as a denoising task, using diffusion~to recover lost information in the transmitted image latent.~Our approach allows us to perform less than 10\% of the full diffusion generative process and requires no architectural changes to~the diffusion model, enabling the use of foundation models as a strong prior without additional fine tuning of the backbone. Our proposed codec outperforms previous methods in quantitative realism metrics, and we verify that our reconstructions are qualitatively preferred by end users, even when other methods use twice the bitrate.},
  isbn = {978-3-031-73030-6},
  langid = {english},
  keywords = {Generative models,Image compression,Latent diffusion},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Lossy_Image_Compression_Relic_et_al_2025.pdf}
}

@article{renRCRCDeepNeural2021,
  title = {{{RCRC}}: {{A Deep Neural Network}} for {{Dynamic Image Reconstruction}} of {{Electrical Impedance Tomography}}},
  shorttitle = {{{RCRC}}},
  author = {Ren, Shangjie and Guan, Ru and Liang, Guanghui and Dong, Feng},
  date = {2021},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {70},
  pages = {1--11},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2021.3092061},
  url = {https://ieeexplore.ieee.org/document/9468992/},
  urldate = {2024-07-03},
  abstract = {A deep neural network is proposed for solving the dynamic image reconstruction problems in electrical impedance tomography (EIT), which can realize the filtering, smoothing, and prediction of the dynamic conductivity reconstruction. This framework includes a reconstruction network, convolutional neural network (CNN) encoder, recurrent neural network (RNN) model, and CNN decoder, thus is termed by RCRC. The RCRC can automatically learn prior spatial–temporal information from the voltage-to-conductivity training dataset and utilize it to enhance the conductivity reconstruction accuracy. Circular acceleration and pendulum systems are simulated with a water tank model. Stochastic data interpolation and dynamic data synthesis methods were proposed to generate large-scale dynamic dataset from a small-scale static dataset. The experimental results show that RCRC can accurately recover dynamic conductivity images from EIT noisy voltage sequence. Long-term conductivity prediction was also achieved by using the proposed network.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\RCRC_Ren_et_al_2021.pdf}
}

@online{renSurveyDeepActive2021,
  title = {A {{Survey}} of {{Deep Active Learning}}},
  author = {Ren, Pengzhen and Xiao, Yun and Chang, Xiaojun and Huang, Po-Yao and Li, Zhihui and Gupta, Brij B. and Chen, Xiaojiang and Wang, Xin},
  date = {2021-12-05},
  eprint = {2009.00236},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2009.00236},
  urldate = {2023-08-26},
  abstract = {Active learning (AL) attempts to maximize a model’s performance gain while annotating the fewest samples possible. Deep learning (DL) is greedy for data and requires a large amount of data supply to optimize a massive number of parameters if the model is to learn how to extract high-quality features. In recent years, due to the rapid development of internet technology, we have entered an era of information abundance characterized by massive amounts of available data. As a result, DL has attracted significant attention from researchers and has been rapidly developed. Compared with DL, however, researchers have a relatively low interest in AL. This is mainly because before the rise of DL, traditional machine learning requires relatively few labeled samples, meaning that early AL is rarely according the value it deserves. Although DL has made breakthroughs in various fields, most of this success is due to a large number of publicly available annotated datasets. However, the acquisition of a large number of high-quality annotated datasets consumes a lot of manpower, making it unfeasible in fields that require high levels of expertise (such as speech recognition, information extraction, medical images, etc.). Therefore, AL is gradually coming to receive the attention it is due. It is therefore natural to investigate whether AL can be used to reduce the cost of sample annotation while retaining the powerful learning capabilities of DL. As a result of such investigations, deep active learning (DeepAL) has emerged. Although research on this topic is quite abundant, there has not yet been a comprehensive survey of DeepAL-related works; accordingly, this article aims to fill this gap. We provide a formal classification method for the existing work, along with a comprehensive and systematic overview. In addition, we also analyze and summarize the development of DeepAL from an application perspective. Finally, we discuss the confusion and problems associated with DeepAL and provide some possible development directions. CCS Concepts: • Computing methodologies → Machine learning algorithms.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/OneDrive - Faculty Of Science (Sohag University)/Research/AI/Strategies/DeepActiveLearning/A_Survey_of_Deep_Active_Ren_et_al_2021.pdf}
}

@article{renTwoStageDeepLearning2020,
  title = {A {{Two-Stage Deep Learning Method}} for {{Robust Shape Reconstruction With Electrical Impedance Tomography}}},
  author = {Ren, Shangjie and Sun, Kai and Tan, Chao and Dong, Feng},
  date = {2020-07},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {69},
  number = {7},
  pages = {4887--4897},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2019.2954722},
  url = {https://ieeexplore.ieee.org/document/8907811/},
  urldate = {2024-07-03},
  abstract = {As a noninvasive and radiation-free imaging modality, electrical impedance tomography (EIT) has attracted much attention in the last two decades and owns many industry and biomedical applications. However, due to the nonlinearity and ill-posedness of its inverse problem, the EIT images always suffer from low spatial resolution and are sensitive to the modeling errors. To achieve high resolution and modeling error robust EIT image, a two-stage deep learning (TSDL) method is proposed. The proposed method consists of a prereconstruction block and a convolutional neural network (CNN). The prereconstruction block learns the regularization pattern from the training data set and provides a rough reconstruction of the target. The CNN postprocesses the prereconstruction result in a multilevel feature analysis strategy and eliminates the modeling errors with prior information of the observation domain shape. The prereconstruction and CNN blocks are trained together by using a minimum square approach. To evaluate the performance of the TSDL method, the lung EIT problem was studied. The training data set is calculated from more than 100 000 EIT simulation models generated from computed tomography (CT) scans across 792 patients. Lung injury, measurement noise, and model errors are randomly simulated during the model generation process. The trained TSDL model is evaluated with simulation testes, as well as the experimental tests from a laboratory setting. According to the results, the TSDL method could achieve high accuracy shape reconstructions and is robust against measurement noise and modeling errors.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\A_Two-Stage_Deep_Learning_Method_for_Robust_Shape_Reconstruction_With_Ren_et_al_2020.pdf}
}

@online{renXCubeLargeScale3D2024,
  title = {{{XCube}}: {{Large-Scale 3D Generative Modeling}} Using {{Sparse Voxel Hierarchies}}},
  shorttitle = {{{XCube}}},
  author = {Ren, Xuanchi and Huang, Jiahui and Zeng, Xiaohui and Museth, Ken and Fidler, Sanja and Williams, Francis},
  date = {2024-06-25},
  eprint = {2312.03806},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.03806},
  url = {http://arxiv.org/abs/2312.03806},
  urldate = {2024-08-19},
  abstract = {We present XCube (abbreviated as \$\textbackslash mathcal\{X\}\textasciicircum 3\$), a novel generative model for high-resolution sparse 3D voxel grids with arbitrary attributes. Our model can generate millions of voxels with a finest effective resolution of up to \$1024\textasciicircum 3\$ in a feed-forward fashion without time-consuming test-time optimization. To achieve this, we employ a hierarchical voxel latent diffusion model which generates progressively higher resolution grids in a coarse-to-fine manner using a custom framework built on the highly efficient VDB data structure. Apart from generating high-resolution objects, we demonstrate the effectiveness of XCube on large outdoor scenes at scales of 100m\$\textbackslash times\$100m with a voxel size as small as 10cm. We observe clear qualitative and quantitative improvements over past approaches. In addition to unconditional generation, we show that our model can be used to solve a variety of tasks such as user-guided editing, scene completion from a single scan, and text-to-3D. The source code and more results can be found at https://research.nvidia.com/labs/toronto-ai/xcube/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\XCube_Ren_et_al_2024.pdf}
}

@inproceedings{reyDiffusionVariationalAutoencoders2020,
  title = {Diffusion {{Variational Autoencoders}}},
  booktitle = {Proceedings of the {{Twenty-Ninth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Rey, Luis A. Pérez and Menkovski, Vlado and Portegies, Jacobus W.},
  date = {2020-07},
  eprint = {1901.08991},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  pages = {2704--2710},
  doi = {10.24963/ijcai.2020/375},
  url = {http://arxiv.org/abs/1901.08991},
  urldate = {2023-08-26},
  abstract = {A standard Variational Autoencoder, with a Euclidean latent space, is structurally incapable of capturing topological properties of certain datasets. To remove topological obstructions, we introduce Diffusion Variational Autoencoders with arbitrary manifolds as a latent space. A Diffusion Variational Autoencoder uses transition kernels of Brownian motion on the manifold. In particular, it uses properties of the Brownian motion to implement the reparametrization trick and fast approximations to the KL divergence.},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\AutoEncoder\Diffusion_Variational_Rey_et_al_2020.pdf}
}

@online{rigantiMultiscalePhysicsInformedNeural2024,
  title = {Multiscale {{Physics-Informed Neural Networks}} for the {{Inverse Design}} of {{Hyperuniform Optical Materials}}},
  author = {Riganti, Roberto and Zhu, Yilin and Cai, Wei and Torquato, Salvatore and Negro, Luca Dal},
  date = {2024-11-30},
  eprint = {2405.07878},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2405.07878},
  urldate = {2024-12-15},
  abstract = {In this article, we employ multiscale physics-informed neural networks (MscalePINNs) for the inverse design of finite-size photonic materials with stealthy hyperuniform (SHU) disordered geometries. Specifically, we show that MscalePINNs can capture the fast spatial variations of complex fields scattered by arrays of dielectric nanocylinders arranged according to isotropic SHU point patterns, thus enabling a systematic methodology to inversely retrieve their effective dielectric profiles. Our approach extends the recently developed high-frequency homogenization theory of hyperuniform media and retrieves more general permittivity profiles for applications-relevant finite-size SHU systems, unveiling unique features related to their isotropic nature. In particular, we numerically corroborate the existence of a transparency region beyond the long-wavelength approximation, enabling effective and isotropic homogenization even without disorder-averaging, in contrast to the case of uncorrelated Poisson random patterns. The flexible multiscale network approach introduced here enables the efficient inverse design of more general effective media and finite-size optical metamaterials with isotropic electromagnetic responses beyond the limitations of traditional homogenization theories.},
  pubstate = {prepublished},
  version = {4},
  keywords = {Condensed Matter - Disordered Systems and Neural Networks,Physics - Applied Physics,Physics - Optics},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\Multiscale_Physics-Informed_Riganti_et_al_2024.pdf}
}

@article{rixenRotationalInvariantNeural2022,
  title = {A {{Rotational Invariant Neural Network}} for {{Electrical Impedance Tomography Imaging}} without {{Reference Voltage}}: {{RF-REIM-NET}}},
  shorttitle = {A {{Rotational Invariant Neural Network}} for {{Electrical Impedance Tomography Imaging}} without {{Reference Voltage}}},
  author = {Rixen, Jöran and Eliasson, Benedikt and Hentze, Benjamin and Muders, Thomas and Putensen, Christian and Leonhardt, Steffen and Ngo, Chuong},
  date = {2022-03-22},
  journaltitle = {Diagnostics},
  volume = {12},
  number = {4},
  pages = {777},
  issn = {2075-4418},
  doi = {10.3390/diagnostics12040777},
  url = {https://www.mdpi.com/2075-4418/12/4/777},
  urldate = {2024-07-03},
  abstract = {Background: Electrical Impedance Tomography (EIT) is a radiation-free technique for image reconstruction. However, as the inverse problem of EIT is non-linear and ill-posed, the reconstruction of sharp conductivity images poses a major problem. With the emergence of artificial neural networks (ANN), their application in EIT has recently gained interest. Methodology: We propose an ANN that can solve the inverse problem without the presence of a reference voltage. At the end of the ANN, we reused the dense layers multiple times, considering that the EIT exhibits rotational symmetries in a circular domain. To avoid bias in training data, the conductivity range used in the simulations was greater than expected in measurements. We also propose a new method that creates new data samples from existing training data. Results: We show that our ANN is more robust with respect to noise compared with the analytical Gauss–Newton approach. The reconstruction results for EIT phantom tank measurements are also clearer, as ringing artefacts are less pronounced. To evaluate the performance of the ANN under real-world conditions, we perform reconstructions on an experimental pig study with computed tomography for comparison. Conclusions: Our proposed ANN can reconstruct EIT images without the need of a reference voltage.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\A_Rotational_Invariant_Neural_Network_for_Electrical_Impedance_Tomography_Rixen_et_al_2022.pdf}
}

@book{robertsPrinciplesDeepLearning2022,
  title = {The {{Principles}} of {{Deep Learning Theory}}},
  author = {Roberts, Daniel A. and Yaida, Sho and Hanin, Boris},
  date = {2022-05-26},
  eprint = {2106.10165},
  eprinttype = {arXiv},
  eprintclass = {hep-th, stat},
  doi = {10.1017/9781009023405},
  url = {http://arxiv.org/abs/2106.10165},
  urldate = {2024-03-21},
  abstract = {This book develops an effective theory approach to understanding deep neural networks of practical relevance. Beginning from a first-principles component-level picture of networks, we explain how to determine an accurate description of the output of trained networks by solving layer-to-layer iteration equations and nonlinear learning dynamics. A main result is that the predictions of networks are described by nearly-Gaussian distributions, with the depth-to-width aspect ratio of the network controlling the deviations from the infinite-width Gaussian description. We explain how these effectively-deep networks learn nontrivial representations from training and more broadly analyze the mechanism of representation learning for nonlinear models. From a nearly-kernel-methods perspective, we find that the dependence of such models' predictions on the underlying learning algorithm can be expressed in a simple and universal way. To obtain these results, we develop the notion of representation group flow (RG flow) to characterize the propagation of signals through the network. By tuning networks to criticality, we give a practical solution to the exploding and vanishing gradient problem. We further explain how RG flow leads to near-universal behavior and lets us categorize networks built from different activation functions into universality classes. Altogether, we show that the depth-to-width ratio governs the effective model complexity of the ensemble of trained networks. By using information-theoretic techniques, we estimate the optimal aspect ratio at which we expect the network to be practically most useful and show how residual connections can be used to push this scale to arbitrary depths. With these tools, we can learn in detail about the inductive bias of architectures, hyperparameters, and optimizers.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,High Energy Physics - Theory,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataScience\DeepLearning\The_Principles_of_Deep_Roberts_et_al_2022.pdf}
}

@book{robsonHeadFirstDesign2020,
  title = {Head {{First Design Patterns}}},
  author = {Robson, Freeman},
  date = {2020},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\Programming\Head_First_Design_Patterns_Robson_2020.epub}
}

@online{roessleL3DGLatent3D2024,
  title = {{{L3DG}}: {{Latent 3D Gaussian Diffusion}}},
  shorttitle = {{{L3DG}}},
  author = {Roessle, Barbara and Müller, Norman and Porzi, Lorenzo and Bulò, Samuel Rota and Kontschieder, Peter and Dai, Angela and Nießner, Matthias},
  date = {2024-10-17},
  eprint = {2410.13530},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2410.13530},
  url = {http://arxiv.org/abs/2410.13530},
  urldate = {2024-11-28},
  abstract = {We propose L3DG, the first approach for generative 3D modeling of 3D Gaussians through a latent 3D Gaussian diffusion formulation. This enables effective generative 3D modeling, scaling to generation of entire room-scale scenes which can be very efficiently rendered. To enable effective synthesis of 3D Gaussians, we propose a latent diffusion formulation, operating in a compressed latent space of 3D Gaussians. This compressed latent space is learned by a vector-quantized variational autoencoder (VQ-VAE), for which we employ a sparse convolutional architecture to efficiently operate on room-scale scenes. This way, the complexity of the costly generation process via diffusion is substantially reduced, allowing higher detail on object-level generation, as well as scalability to large scenes. By leveraging the 3D Gaussian representation, the generated scenes can be rendered from arbitrary viewpoints in real-time. We demonstrate that our approach significantly improves visual quality over prior work on unconditional object-level radiance field synthesis and showcase its applicability to room-scale scene generation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\L3DG_Roessle_et_al_2024.pdf}
}

@article{rojasDeepReinforcementLearning,
  title = {Deep Reinforcement Learning for {{2D}} Soft Body Locomotion},
  author = {Rojas, Junior and Coros, Stelian and Kavan, Ladislav},
  abstract = {We present a character animation system that integrates deep reinforcement learning into soft body simulation to synthesize locomotion controllers for autonomous characters modeled as deformable 2D triangle meshes with no rigid components. A controller in our system is a mapping from state observations (vertex positions and velocities of the character’s mesh) to actions that contract or relax the character’s muscles. Our results show that our locomotion controllers can be run from different initial simulation states and recover from perturbations such as external impulses generated by unexpectedly poking the character.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\Pytorch\Deep_reinforcement_learning_for_2D_soft_body_locomotion_Rojas_et_al_.pdf}
}

@article{rojasPhysicsbasedSimulationBackpropagation,
  title = {Physics-Based Simulation via Backpropagation on Energy Functions},
  author = {Rojas, Junior},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\Pytorch\Physics-based_simulation_via_backpropagation_on_energy_functions_Rojas_.pdf}
}

@article{rokhComprehensiveSurveyModel2023,
  title = {A {{Comprehensive Survey}} on {{Model Quantization}} for {{Deep Neural Networks}} in {{Image Classification}}},
  author = {Rokh, Babak and Azarpeyvand, Ali and Khanteymoori, Alireza},
  date = {2023-11-14},
  journaltitle = {ACM Trans. Intell. Syst. Technol.},
  volume = {14},
  number = {6},
  pages = {97:1--97:50},
  issn = {2157-6904},
  doi = {10.1145/3623402},
  url = {https://doi.org/10.1145/3623402},
  urldate = {2024-07-24},
  abstract = {Recent advancements in machine learning achieved by Deep Neural Networks (DNNs) have been significant. While demonstrating high accuracy, DNNs are associated with a huge number of parameters and computations, which leads to high memory usage and energy consumption. As a result, deploying DNNs on devices with constrained hardware resources poses significant challenges. To overcome this, various compression techniques have been widely employed to optimize DNN accelerators. A promising approach is quantization, in which the full-precision values are stored in low bit-width precision. Quantization not only reduces memory requirements but also replaces high-cost operations with low-cost ones. DNN quantization offers flexibility and efficiency in hardware design, making it a widely adopted technique in various methods. Since quantization has been extensively utilized in previous works, there is a need for an integrated report that provides an understanding, analysis, and comparison of different quantization approaches. Consequently, we present a comprehensive survey of quantization concepts and methods, with a focus on image classification. We describe clustering-based quantization methods and explore the use of a scale factor parameter for approximating full-precision values. Moreover, we thoroughly review the training of a quantized DNN, including the use of a straight-through estimator and quantization regularization. We explain the replacement of floating-point operations with low-cost bitwise operations in a quantized DNN and the sensitivity of different layers in quantization. Furthermore, we highlight the evaluation metrics for quantization methods and important benchmarks in the image classification task. We also present the accuracy of the state-of-the-art methods on CIFAR-10 and ImageNet. This article attempts to make the readers familiar with the basic and advanced concepts of quantization, introduce important works in DNN quantization, and highlight challenges for future research in this field.},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Quantization\A_Comprehensive_Survey_on_Model_Quantization_for_Deep_Neural_Networks_in_Image_Rokh_et_al_2023.pdf}
}

@inproceedings{rombachHighResolutionImageSynthesis2022,
  title = {High-{{Resolution Image Synthesis}} with {{Latent Diffusion Models}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bjorn},
  date = {2022-06},
  pages = {10674--10685},
  publisher = {IEEE},
  location = {New Orleans, LA, USA},
  doi = {10.1109/CVPR52688.2022.01042},
  url = {https://ieeexplore.ieee.org/document/9878449/},
  urldate = {2023-07-27},
  abstract = {By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve new state of the art scores for image inpainting and class-conditional image synthesis and highly competitive performance on various tasks, including unconditional image generation, text-to-image synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs.},
  eventtitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66546-946-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\DiffusionModels\High-Resolution_Image_Synthesis_with_Latent_Diffusion_Models_Rombach_et_al_2022.pdf}
}

@online{ronnebergerUNetConvolutionalNetworks2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  date = {2015-05-18},
  eprint = {1505.04597},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1505.04597},
  urldate = {2024-02-20},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\U-Net_Ronneberger_et_al_2015.pdf}
}

@article{rosaBladderVolumeMonitoring2020,
  title = {Bladder {{Volume Monitoring Using Electrical Impedance Tomography With Simultaneous Multi-Tone Tissue Stimulation}} and {{DFT-Based Impedance Calculation Inside}} an {{FPGA}}},
  author = {Rosa, Bruno M. G. and Yang, Guang Z.},
  date = {2020-08},
  journaltitle = {IEEE Trans. Biomed. Circuits Syst.},
  volume = {14},
  number = {4},
  pages = {775--786},
  issn = {1932-4545, 1940-9990},
  doi = {10.1109/TBCAS.2020.3008831},
  url = {https://ieeexplore.ieee.org/document/9139311/},
  urldate = {2024-07-08},
  abstract = {In this article, a novel method for measuring the volume of the urinary bladder non-invasively is presented that relies on the principles dictated by Electrical Impedance Tomography (EIT). The electronic prototype responsible for injecting innocuous electrical currents to the lower abdominal region and measuring the developed voltage levels is fully described, as well as the computational models for resolution of the so-called Forward and Inverse Problems in Imaging. The simultaneous multi-tone injection of current provided by a high performance Field Programmable Gate Array (FPGA), combined with impedance estimation by the Discrete Fourier Transform (DFT) constitutes a novelty in Urodynamics with potential to monitor continuously the intravesical volume of patients in a much faster and comfortable way than traditional transurethral catheterization methods. The resolution of the Inverse Problem is performed by the Gauss-Newton method with Laplacian regularization, allowing to obtain a sectional representation of the volume of urine encompassed by the bladder and surrounding body tissues. Experimentation has been carried out with synthetic phantoms and human subjects with results showing a good correlation between the levels of abdominal admittivity acquired by the EIT system and the volume of ingested water.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\BodyParts\Bladder_Volume_Monitoring_Using_Electrical_Impedance_Tomography_With_Rosa_Yang_2020.pdf}
}

@article{rousseyOnedimensionalPhotonicCrystals2014,
  title = {One-Dimensional Photonic Crystals with Cylindrical Geometry},
  author = {Roussey, Matthieu and Descrovi, Emiliano and Häyrinen, Markus and Angelini, Angelo and Kuittinen, Markku and Honkanen, Seppo},
  date = {2014-11-03},
  journaltitle = {Opt. Express},
  volume = {22},
  number = {22},
  pages = {27236},
  issn = {1094-4087},
  doi = {10.1364/OE.22.027236},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-22-22-27236},
  urldate = {2023-11-06},
  abstract = {A one-dimensional photonic crystal (1DPC) consisting of a stack of alternate TiO2 and Al2O3 layers is deposited on the side wall of a glass rod by Atomic Layer Deposition. The stack is designed to sustain TEpolarized Bloch Surface Waves (BSW) in the visible spectrum at wavelengths shorter than 650 nm. Experimental evidence of light coupling and guiding capabilities of the 1DPC is provided together with a possible application for fluorescence-based remote sensors.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\One-dimensional_photonic_crystals_with_cylindrical_geometry_Roussey_et_al_2014.pdf}
}

@online{ruckertADOPApproximateDifferentiable2022,
  title = {{{ADOP}}: {{Approximate Differentiable One-Pixel Point Rendering}}},
  shorttitle = {{{ADOP}}},
  author = {Rückert, Darius and Franke, Linus and Stamminger, Marc},
  date = {2022-05-03},
  eprint = {2110.06635},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2110.06635},
  url = {http://arxiv.org/abs/2110.06635},
  urldate = {2023-10-16},
  abstract = {In this paper we present ADOP, a novel point-based, differentiable neural rendering pipeline. Like other neural renderers, our system takes as input calibrated camera images and a proxy geometry of the scene, in our case a point cloud. To generate a novel view, the point cloud is rasterized with learned feature vectors as colors and a deep neural network fills the remaining holes and shades each output pixel. The rasterizer renders points as one-pixel splats, which makes it very fast and allows us to compute gradients with respect to all relevant input parameters efficiently. Furthermore, our pipeline contains a fully differentiable physically-based photometric camera model, including exposure, white balance, and a camera response function. Following the idea of inverse rendering, we use our renderer to refine its input in order to reduce inconsistencies and optimize the quality of its output. In particular, we can optimize structural parameters like the camera pose, lens distortions, point positions and features, and a neural environment map, but also photometric parameters like camera response function, vignetting, and per-image exposure and white balance. Because our pipeline includes photometric parameters, e.g.\textasciitilde exposure and camera response function, our system can smoothly handle input images with varying exposure and white balance, and generates high-dynamic range output. We show that due to the improved input, we can achieve high render quality, also for difficult input, e.g. with imperfect camera calibrations, inaccurate proxy geometry, or varying exposure. As a result, a simpler and thus faster deep neural network is sufficient for reconstruction. In combination with the fast point rasterization, ADOP achieves real-time rendering rates even for models with well over 100M points. https://github.com/darglein/ADOP},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\HDR\ADOP_Ruckert_et_al_2022.pdf}
}

@online{ruckertNeATNeuralAdaptive2022,
  title = {{{NeAT}}: {{Neural Adaptive Tomography}}},
  shorttitle = {{{NeAT}}},
  author = {Rückert, Darius and Wang, Yuanhao and Li, Rui and Idoughi, Ramzi and Heidrich, Wolfgang},
  date = {2022-02-04},
  eprint = {2202.02171},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2202.02171},
  urldate = {2023-11-30},
  abstract = {In this paper, we present Neural Adaptive Tomography (NeAT), the first adaptive, hierarchical neural rendering pipeline for multi-view inverse rendering. Through a combination of neural features with an adaptive explicit representation, we achieve reconstruction times far superior to existing neural inverse rendering methods. The adaptive explicit representation improves efficiency by facilitating empty space culling and concentrating samples in complex regions, while the neural features act as a neural regularizer for the 3D reconstruction. The NeAT framework is designed specifically for the tomographic setting, which consists only of semi-transparent volumetric scenes instead of opaque objects. In this setting, NeAT outperforms the quality of existing optimization-based tomography solvers while being substantially faster.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/Reconstruction/NeuralRadianceFields/Tomography/NeAT_Ruckert_et_al_2022.pdf}
}

@article{russoDevelopmentHighSpeedCurrent2017,
  title = {Development of a {{High-Speed Current Injection}} and {{Voltage Measurement System}} for {{Electrical Impedance Tomography-Based Stretchable Sensors}}},
  author = {Russo, Stefania and Nefti-Meziani, Samia and Carbonaro, Nicola and Tognetti, Alessandro},
  date = {2017-07-26},
  journaltitle = {Technologies},
  volume = {5},
  number = {3},
  pages = {48},
  issn = {2227-7080},
  doi = {10.3390/technologies5030048},
  url = {https://www.mdpi.com/2227-7080/5/3/48},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is an imaging method that can be applied over stretchable conductive-fabric materials to realize soft and wearable pressure sensors through current injections and voltage measurements at electrodes placed at the boundary of a conductive medium. In common EIT systems, the voltage data are serially measured by means of multiplexers, and are hence collected at slightly different times, which affects the real-time performance of the system. They also tend to have complicated hardware, which increases power consumption. In this paper, we present our design of a 16-electrode high-speed EIT system that simultaneously implements constant current injection and differential potential measurements. This leads to a faster, simpler-to-implement and less-noisy technique, when compared with traditional EIT approaches. Our system consists of a Howland current pump with two multiplexers for a constant DC current supply, and a data acquisition card. It guarantees a data collection rate of 78 frames/s. The results from our conductive stretchable fabric sensor show that the system successfully performs voltage data collection with a mean signal-to-noise ratio (SNR) of 55 dB, and a mean absolute deviation (MAD) of 0.5 mV. The power consumption can be brought down to 3 mW; therefore, it is suitable for battery-powered applications. Finally, pressure contacts over the sensor are properly reconstructed, thereby validating the efficiency of our EIT system for soft and stretchable sensor applications.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\StretchableSensors\Development_of_a_High-Speed_Current_Injection_and_Voltage_Measurement_System_Russo_et_al_2017.pdf}
}

@article{russoDevelopmentHighSpeedCurrent2017a,
  title = {Development of a {{High-Speed Current Injection}} and {{Voltage Measurement System}} for {{Electrical Impedance Tomography-Based Stretchable Sensors}}},
  author = {Russo, Stefania and Nefti-Meziani, Samia and Carbonaro, Nicola and Tognetti, Alessandro},
  date = {2017-07-26},
  journaltitle = {Technologies},
  volume = {5},
  number = {3},
  pages = {48},
  issn = {2227-7080},
  doi = {10.3390/technologies5030048},
  url = {https://www.mdpi.com/2227-7080/5/3/48},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is an imaging method that can be applied over stretchable conductive-fabric materials to realize soft and wearable pressure sensors through current injections and voltage measurements at electrodes placed at the boundary of a conductive medium. In common EIT systems, the voltage data are serially measured by means of multiplexers, and are hence collected at slightly different times, which affects the real-time performance of the system. They also tend to have complicated hardware, which increases power consumption. In this paper, we present our design of a 16-electrode high-speed EIT system that simultaneously implements constant current injection and differential potential measurements. This leads to a faster, simpler-to-implement and less-noisy technique, when compared with traditional EIT approaches. Our system consists of a Howland current pump with two multiplexers for a constant DC current supply, and a data acquisition card. It guarantees a data collection rate of 78 frames/s. The results from our conductive stretchable fabric sensor show that the system successfully performs voltage data collection with a mean signal-to-noise ratio (SNR) of 55 dB, and a mean absolute deviation (MAD) of 0.5 mV. The power consumption can be brought down to 3 mW; therefore, it is suitable for battery-powered applications. Finally, pressure contacts over the sensor are properly reconstructed, thereby validating the efficiency of our EIT system for soft and stretchable sensor applications.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\EIDORS\Development_of_a_High-Speed_Current_Injection_and_Voltage_Measurement_System_Russo_et_al_2017.pdf}
}

@online{saidBitstreamOrganizationParallel2023,
  title = {Bitstream {{Organization}} for {{Parallel Entropy Coding}} on {{Neural Network-based Video Codecs}}},
  author = {Said, Amir and Le, Hoang and Farhadzadeh, Farzad},
  date = {2023-12-01},
  eprint = {2312.00921},
  eprinttype = {arXiv},
  eprintclass = {cs, eess, math},
  doi = {10.48550/arXiv.2312.00921},
  url = {http://arxiv.org/abs/2312.00921},
  urldate = {2024-06-04},
  abstract = {Video compression systems must support increasing bandwidth and data throughput at low cost and power, and can be limited by entropy coding bottlenecks. Efficiency can be greatly improved by parallelizing coding, which can be done at much larger scales with new neural-based codecs, but with some compression loss related to data organization. We analyze the bit rate overhead needed to support multiple bitstreams for concurrent decoding, and for its minimization propose a method for compressing parallel-decoding entry points, using bidirectional bitstream packing, and a new form of jointly optimizing arithmetic coding termination. It is shown that those techniques significantly lower the overhead, making it easier to reduce it to a small fraction of the average bitstream size, like, for example, less than 1\% and 0.1\% when the average number of bitstream bytes is respectively larger than 95 and 1,200 bytes.},
  pubstate = {prepublished},
  keywords = {Computer Science - Information Theory,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Compression\Bitstream_Organization_for_Parallel_Entropy_Coding_on_Neural_Network-based_Said_et_al_2023.pdf}
}

@inproceedings{saidOptimizedLearnedEntropy2022,
  title = {Optimized {{Learned Entropy Coding Parameters}} for {{Practical Neural-Based Image}} and {{Video Compression}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  author = {Said, Amir and Pourreza, Reza and Le, Hoang},
  date = {2022-10},
  pages = {661--665},
  issn = {2381-8549},
  doi = {10.1109/ICIP46576.2022.9897505},
  url = {https://ieeexplore.ieee.org/abstract/document/9897505?casa_token=VWxBHWp9yR0AAAAA:ZQny2_9uMdaWvd5Nr016GL-qOR5UlpKTZZUPe0tRmUnRs5LwH5KPnojVzUHOjlN-UuWVfbsjhmI},
  urldate = {2024-06-04},
  abstract = {Neural-based image and video codecs are significantly more power-efficient when weights and activations are quantized to low-precision integers. While there are general-purpose techniques for reducing quantization effects, large losses can occur when specific entropy coding properties are not considered. This work analyzes how entropy coding is affected by parameter quantizations, and provides a method to minimize losses. It is shown that, by using a certain type of coding parameters to be learned, uniform quantization becomes practically optimal, also simplifying the minimization of code memory requirements. The mathematical properties of the new representation are presented, and its effectiveness is demonstrated by coding experiments, showing that good results can be obtained with precision as low as 4 bits per network output, and practically no loss with 8 bits.},
  eventtitle = {2022 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  keywords = {Codes,entropy coding,Image coding,Learned image and video compression,Memory management,Minimization,neural network quantization,Quantization (signal),Redundancy,Video compression},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Compression\Optimized_Learned_Entropy_Coding_Parameters_for_Practical_Neural-Based_Image_Said_et_al_2022.pdf}
}

@article{salzbergInfraredRefractiveIndexes1957,
  title = {Infrared {{Refractive Indexes}} of {{Silicon Germanium}} and {{Modified Selenium Glass}}*},
  author = {Salzberg, Calvin D. and Villa, John J.},
  date = {1957-03-01},
  journaltitle = {J. Opt. Soc. Am.},
  volume = {47},
  number = {3},
  pages = {244},
  issn = {0030-3941},
  doi = {10.1364/JOSA.47.000244},
  url = {https://opg.optica.org/abstract.cfm?URI=josa-47-3-244},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Semiconductor\Infrared_Refractive_Indexes_of_Silicon_Germanium_and_Modified_Selenium_Glass_Salzberg_Villa_1957.pdf}
}

@article{sanchezAdvancesMachineLearning2024,
  title = {Advances in Machine Learning Optimization for Classical and Quantum Photonics},
  author = {Sanchez, M. and Everly, C. and Postigo, P. A.},
  date = {2024-02-01},
  journaltitle = {J. Opt. Soc. Am. B, JOSAB},
  volume = {41},
  number = {2},
  pages = {A177-A190},
  publisher = {Optica Publishing Group},
  issn = {1520-8540},
  doi = {10.1364/JOSAB.507268},
  url = {https://opg.optica.org/josab/abstract.cfm?uri=josab-41-2-A177},
  urldate = {2024-06-01},
  abstract = {The development and optimization of photonic devices and various other nanostructure electromagnetic devices present a computationally intensive task. Much optimization relies on finite-difference time-domain or finite element analysis simulations, which can become very computationally demanding for finely detailed structures and dramatically reduce the available optimization space. In recent years, various inverse design machine learning (ML) techniques have been successfully applied to realize previously unexplored optimization spaces for photonic and quantum photonic devices. In this review, recent results using conventional optimization methods, such as the adjoint method and particle swarm, are examined along with ML optimization using convolutional neural networks, Bayesian optimizations with deep learning, and reinforcement learning in the context of new applications to photonics and quantum photonics.},
  langid = {english},
  keywords = {Integrated photonics,Inverse design,Machine learning,Photonic entanglement,Quantum communications,Quantum information},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\Advances_in_machine_learning_Sanchez_et_al_2024.pdf}
}

@online{santosMemoryAugmentedLanguage2023,
  title = {Memory {{Augmented Language Models}} through {{Mixture}} of {{Word Experts}}},
  author = {family=Santos, given=Cicero Nogueira, prefix=dos, useprefix=false and Lee-Thorp, James and Noble, Isaac and Chang, Chung-Ching and Uthus, David},
  date = {2023-11-15},
  eprint = {2311.10768},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.10768},
  url = {http://arxiv.org/abs/2311.10768},
  urldate = {2024-09-22},
  abstract = {Scaling up the number of parameters of language models has proven to be an effective approach to improve performance. For dense models, increasing model size proportionally increases the model's computation footprint. In this work, we seek to aggressively decouple learning capacity and FLOPs through Mixture-of-Experts (MoE) style models with large knowledge-rich vocabulary based routing functions and experts. Our proposed approach, dubbed Mixture of Word Experts (MoWE), can be seen as a memory augmented model, where a large set of word-specific experts play the role of a sparse memory. We demonstrate that MoWE performs significantly better than the T5 family of models with similar number of FLOPs in a variety of NLP tasks. Additionally, MoWE outperforms regular MoE models on knowledge intensive tasks and has similar performance to more complex memory augmented approaches that often require to invoke custom mechanisms to search the sparse memory.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\MixtureOfExperts\Memory_Augmented_Language_Santos_et_al_2023.pdf}
}

@online{sauerFastHighResolutionImage2024,
  title = {Fast {{High-Resolution Image Synthesis}} with {{Latent Adversarial Diffusion Distillation}}},
  author = {Sauer, Axel and Boesel, Frederic and Dockhorn, Tim and Blattmann, Andreas and Esser, Patrick and Rombach, Robin},
  date = {2024-03-18},
  eprint = {2403.12015},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.12015},
  url = {http://arxiv.org/abs/2403.12015},
  urldate = {2024-12-24},
  abstract = {Diffusion models are the main driver of progress in image and video synthesis, but suffer from slow inference speed. Distillation methods, like the recently introduced adversarial diffusion distillation (ADD) aim to shift the model from many-shot to single-step inference, albeit at the cost of expensive and difficult optimization due to its reliance on a fixed pretrained DINOv2 discriminator. We introduce Latent Adversarial Diffusion Distillation (LADD), a novel distillation approach overcoming the limitations of ADD. In contrast to pixel-based ADD, LADD utilizes generative features from pretrained latent diffusion models. This approach simplifies training and enhances performance, enabling high-resolution multi-aspect ratio image synthesis. We apply LADD to Stable Diffusion 3 (8B) to obtain SD3-Turbo, a fast model that matches the performance of state-of-the-art text-to-image generators using only four unguided sampling steps. Moreover, we systematically investigate its scaling behavior and demonstrate LADD's effectiveness in various applications such as image editing and inpainting.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\DiffusionModels\Fast_High-Resolution_Image_Sauer_et_al_2024.pdf}
}

@article{sayedDopedpolymerBasedPorous2023,
  title = {A Doped-Polymer Based Porous Silicon Photonic Crystal Sensor for the Detection of Gamma-Ray Radiation},
  author = {Sayed, Fatma A. and Elsayed, Hussein A. and Mehaney, Ahmed and Eissa, M. F. and Aly, Arafa H.},
  date = {2023},
  journaltitle = {RSC Adv.},
  volume = {13},
  number = {5},
  pages = {3123--3138},
  issn = {2046-2069},
  doi = {10.1039/D2RA07637C},
  url = {https://xlink.rsc.org/?DOI=D2RA07637C},
  urldate = {2024-09-28},
  abstract = {In this research, a theoretical investigation of the one-dimensional defective photonic crystals is considered for the detection of gamma-ray radiation.           ,                             In this research, a theoretical investigation of the one-dimensional defective photonic crystals is considered for the detection of gamma-ray radiation. Each unit cell of the considered one-dimensional photonic crystals (1D PhCs) is composed of two layers designed from porous silicon infiltrated by poly-vinyl alcohol polymer doped with crystal violet (CV) and carbol fuchsine (CF) dyes (doped-polymer) with different porosity. In addition, a single layer of doped-polymer is included in the middle of the designed 1D PhCs to stimulate the localization of a distinct resonant wavelength through the photonic band gap. In particular, the appearance of this resonant mode represents the backbone of our study towards the detection of γ-ray radiation with doses from 0 to 70 Gy. The Bruggeman's effective medium equation, the fitted experimental data to the refractive index of the doped-polymer, and the Transfers Matrix Method (TMM) serve as the mainstay of our theoretical treatment. The numerical findings provide significant contributions to some of the governing parameters such as the thicknesses of the considered materials on the performance of the presented sensor, the effect of incidence angle and the porosity of the considered materials on the resonance wavelength. In this regard, at optimum values of these parameters the sensitivity, quality factor, signal-to-noise ratio, detection limit, sensor resolution, and figure of merit that are obtained are 205.7906 nm RIU               −1               , 9380.483, 49.315, 2.05 × 10               −5               RIU, 3.27 × 10               −5               , and 2429.31 RIU               −1               , respectively. Therefore, we believe that the suggested design could be of significant interest in many industrial, medical, and scientific applications.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Radiation\A_doped-polymer_based_porous_Sayed_et_al_2023.pdf}
}

@article{sayedOnedimentionalPeriodicStructure2022,
  title = {One-Dimentional Periodic Structure Infiltrated by ({{PVA}}/{{CV}} + {{CF}})-Polymer for High-Performance Sensitivity},
  author = {Sayed, Fatma A. and Elsayed, Hussein A. and Mehaney, Ahmed and Eissa, M. F. and Aly, Arafa H.},
  date = {2022-11},
  journaltitle = {Opt Quant Electron},
  volume = {54},
  number = {11},
  pages = {755},
  issn = {0306-8919, 1572-817X},
  doi = {10.1007/s11082-022-04189-3},
  url = {https://link.springer.com/10.1007/s11082-022-04189-3},
  urldate = {2024-09-28},
  abstract = {In the current work, we demonstrate a design to act as a Gamma-ray radiation dosimeter based on the one-dimensional photonic crystal (1D-PhC). The basic concept of the present dosimeter is based on a Porous Silicon (PSi) infiltrated by poly-vinyl alcohol (PVA)polymer doped with crystal violet (CV) and carbol-fuchsine (CF) dyes. The mechanism of suggested dosimeter is based on the shift of the photonic bandgap (PBG) to higher wavelengths as exposed to gamma-ray radiation doses from 0 to 70 Gray (Gy). The basic axes of the current theoretical treatment are the transfers matrix method (TMM), Bruggeman’s effective medium equation, and the fitted experimental data to the refractive index of the doped PVA-Polymer. The obtained results showed the proposed sensor is characterized by high stable sensitivity varied from (178–186 nm/ RIU) along an applied γ-dose from (10–70 Gy) in the visible range. In addition, we compared these results with previous researches. In addition, based on the our knowledge may be it is the first time that a 1D-PhC has been used for gamma-ray detection by using (PVA/CV\,+\,CF) based on Porous Silicon.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Radiation\One-dimentional_periodic_Sayed_et_al_2022.pdf}
}

@book{sayoodIntroductionDataCompression2006,
  title = {Introduction to Data Compression},
  author = {Sayood, Khalid},
  date = {2006},
  series = {Morgan {{Kaufmann}} Series in Multimedia Information and Systems},
  edition = {3rd ed},
  publisher = {Elsevier},
  location = {Amsterdam Boston},
  abstract = {"Each edition of Introduction to Data Compression has widely been considered the best introduction and reference text on the art and science of data compression, and the third edition continues in this tradition. Data compression techniques and technology are ever-evolving with new applications in image, speech, text, audio, and video. The third edition includes all the cutting-edge updates the reader will need during the work day and in class." "Khalid Sayood provides an extensive introduction to the theory underlying today's compression techniques with detailed instruction for their applications using several examples to explain the concepts. Encompassing the entire field of data compression Introduction to Data Compression, includes lossless and lossy compression, Huffman coding, arithmetic coding, dictionary techniques, context based compression, scalar and vector quantization. Khalid Sayood provides a working knowledge of data compression, giving the reader the tools to develop a complete and concise compression package upon completion of his book."--Jacket},
  isbn = {978-0-12-620862-7},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataCompression\DataCompression\Introduction_to_data_compression_Sayood_2006.pdf}
}

@misc{Sbyrnes321Overview_Html,
  title = {Sbyrnes321 - {{Overview}}\_.Html},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Courses\sbyrnes321_-_Overview__.html}
}

@book{scherzerHandbookMathematicalMethods2010,
  title = {Handbook of Mathematical Methods in Imaging},
  author = {Scherzer, Otmar},
  date = {2010-11-23},
  edition = {2011},
  publisher = {Springer},
  location = {New York ; London},
  abstract = {The Handbook of Mathematical Methods in Imaging provides a comprehensive treatment of the mathematical techniques used in imaging science. The material is grouped into two central themes, namely, Inverse Problems (Algorithmic Reconstruction) and Signal and Image Processing. Each section within the themes covers applications (modeling), mathematics, numerical methods (using a case example) and open questions. Written by experts in the area, the presentation is mathematically rigorous. The entries are cross-referenced for easy navigation through connected topics. Available in both print and electronic forms, the handbook is enhanced by more than 150 illustrations and an extended bibliography.It will benefit students, scientists and researchers in applied mathematics. Engineers and computer scientists working in imaging will also find this handbook useful.},
  isbn = {978-0-387-92919-4},
  langid = {Englisch},
  pagetotal = {1566},
  file = {C:\Users\ahmed\Zotero\storage\IYGDQY5W\Handbook_of_Mathematical_Methods_in_Imaging_Scherzer_2011.pdf}
}

@article{scheuerAnnularBraggDefect,
  title = {Annular {{Bragg}} Defect Mode Resonators},
  author = {Scheuer, Jacob and Yariv, Amnon},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Annular_Bragg_defect_mode_resonators_Scheuer_Yariv_.pdf}
}

@inproceedings{scheuerAnnularBraggDefect2004,
  title = {Annular {{Bragg}} Defect Mode Resonators},
  author = {Scheuer, Jacob and Green, William M. J. and DeRose, Guy and Yariv, Amnon},
  editor = {Kudryashov, Alexis V.},
  date = {2004-06-01},
  pages = {183},
  location = {San Jose, Ca},
  doi = {10.1117/12.544590},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.544590},
  urldate = {2023-11-06},
  abstract = {We propose and analyze a new type of resonator in an annular geometry which is based on a single defect surrounded by radial Bragg reflectors on both sides. Unlike conventional, total internal reflection based ring resonators, this structure supports modal fields with very low azimuthal number (large radial k-vector component). We show that the conditions for efficient mode confinement are different from those of conventional Bragg waveguiding in a rectangular geometry. To realize tight confinement of the light in the defect, chirped gratings are required. Compared to a conventional resonator, the new resonator exhibits larger FSR and lower losses making it suitable for both telecom and sensing applications. In addition, the resonance wavelength and Q factor of the device are very sensitive to environmental changes, and thus provide ideal observables for sensing applications. Annular Bragg resonators with several unique geometries have been fabricated in an InGaAsP multi-quantum-well membrane. The spectral properties of the resonators have been investigated through analysis of photoluminescence induced by pulsed optical excitation.},
  eventtitle = {Lasers and {{Applications}} in {{Science}} and {{Engineering}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Annular_Bragg_defect_mode_resonators_Scheuer_et_al_2004.pdf}
}

@inproceedings{scheuerAnnularBraggResonators2006,
  title = {Annular {{Bragg}} Resonators ({{ABR}}): The Ideal Tool for Biochemical Sensing, Nonlinear Optics, and Cavity {{QED}}},
  shorttitle = {Annular {{Bragg}} Resonators ({{ABR}})},
  author = {Scheuer, Jacob and Green, William M. J. and Yariv, Amnon},
  editor = {Sidorin, Yakov and Waechter, Christoph A.},
  date = {2006-02-09},
  pages = {61230S},
  location = {San Jose, CA},
  doi = {10.1117/12.640285},
  url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.640285},
  urldate = {2023-11-06},
  abstract = {Circular resonators are fundamentally interesting elements that are essential for research involving highly confined fields and strong photon-atom interactions such as cavity QED, as well as for practical applications in optical communication systems as and biochemical sensing. The important characteristics of a ring resonator are the Q-factor, the free spectral range (FSR) and the modal volume, where the last two are primarily determined by the resonator dimensions. The TotalInternal-Reflection (TIR) mechanism employed in “conventional” resonators couples between these characteristics and limits the ability to realize compact devices with large FSR, small modal volume and high Q. Recently, we proposed and analyzed a new class of a resonator in an annular geometry that is based on a single defect surrounded by radial Bragg reflectors on both sides. The radial Bragg confinement breaks the link between the characteristics of the mode and paves a new way for the realization of compact and low loss resonators. Such properties as well as the unique mode profile of the ABRs make this class of devices an excellent tool for ultra-sensitive biochemical detection as well as for studies in nonlinear optics and cavity QED.},
  eventtitle = {Integrated {{Optoelectronic Devices}} 2006},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Annular_Bragg_resonators_(ABR)_Scheuer_et_al_2006.pdf}
}

@article{scheuerInGaAsPAnnularBragg2005,
  title = {{{InGaAsP}} Annular {{Bragg}} Lasers: Theory, Applications, and Modal Properties},
  shorttitle = {{{InGaAsP}} Annular {{Bragg}} Lasers},
  author = {Scheuer, J. and Green, W.M.J. and DeRose, G.A. and Yariv, A.},
  date = {2005-03},
  journaltitle = {IEEE J. Select. Topics Quantum Electron.},
  volume = {11},
  number = {2},
  pages = {476--484},
  issn = {1077-260X},
  doi = {10.1109/JSTQE.2005.845614},
  url = {http://ieeexplore.ieee.org/document/1425486/},
  urldate = {2023-11-06},
  abstract = {A novel class of circular resonators, based on a radial defect surrounded by Bragg reflectors, is studied in detail. Simple rules for the design and analysis of such structures are derived using a transfer matrix formalism. Unlike conventional ring resonators, annular Bragg resonators (ABR) are not limited by the total internal reflection condition and can exhibit both large free spectral ranges and low bend losses. The Bragg reflection mechanism enables the confinement of light within a defect consisting of a low refractive index medium (such as air). Strong atom–photon interaction can be achieved in such a structure, making it a promising candidate for sensing and cavity quantum electrodynamics applications. For sensing applications, we show that the ABR structure can possess significantly higher sensitivity when compared to a conventional ring resonator sensor. Lasing action and low threshold levels are demonstrated in ABR lasers at telecommunication wavelengths under pulsed optical pumping at room temperatures. The impact of the intensity and dimensions of the pump spot on the emitted spectrum is studied in detail.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\InGaAsP_annular_Bragg_lasers_Scheuer_et_al_2005.pdf}
}

@article{scheuerLasingCircularBragg2005,
  title = {Lasing from a Circular {{Bragg}} Nanocavity with an Ultrasmall Modal Volume},
  author = {Scheuer, Jacob and Green, William M. J. and DeRose, Guy A. and Yariv, Amnon},
  date = {2005-06-20},
  journaltitle = {Applied Physics Letters},
  volume = {86},
  number = {25},
  pages = {251101},
  issn = {0003-6951, 1077-3118},
  doi = {10.1063/1.1947375},
  url = {https://pubs.aip.org/apl/article/86/25/251101/330230/Lasing-from-a-circular-Bragg-nanocavity-with-an},
  urldate = {2023-11-06},
  abstract = {We demonstrate single-mode lasing at telecommunication wavelengths from a circular nanocavity employing a radial Bragg reflector. Ultrasmall modal volumes and submilliwatt pump thresholds level are observed for lasers with InGaAsP quantum well active membrane. The electromagnetic field is shown to be tightly confined within the 300nm central pillar of the cavity. The quality factors of the resonator modal fields are estimated to be on the order of a few thousands.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Lasing_from_a_circular_Bragg_nanocavity_with_an_ultrasmall_modal_volume_Scheuer_et_al_2005.pdf}
}

@article{scheuerOpticalAnnularResonators2003,
  title = {Optical Annular Resonators Based on Radial {{Bragg}} and Photonic Crystal Reflectors},
  author = {Scheuer, Jacob and Yariv, Amnon},
  date = {2003-10-20},
  journaltitle = {Opt. Express},
  volume = {11},
  number = {21},
  pages = {2736},
  issn = {1094-4087},
  doi = {10.1364/OE.11.002736},
  url = {https://opg.optica.org/abstract.cfm?URI=oe-11-21-2736},
  urldate = {2023-11-06},
  abstract = {A ring resonator based on Bragg reflection is studied in detail. Closed form expressions for the field and dispersion curves for radial Bragg gratings and photonic crystals based resonators are derived and compared to FDTD simulations. For strong confinement, the required gratings exhibit a chirped period and a varying index profile. Small bending radii and low radiation losses are shown to be possible due to the Bragg confinement. The sensitivity of the resonator characteristics to fabrication errors is analyzed quantitatively. A mixed confinement configuration utilizing both Bragg reflection and total internal reflection is also suggested and analyzed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Optical_annular_resonators_based_on_radial_Bragg_and_photonic_crystal_reflectors_Scheuer_Yariv_2003.pdf}
}

@misc{schoberlScientificComputingSoftware,
  title = {Scientific {{Computing Software Concepts}} for {{Solving Partial Diﬀerential}}},
  author = {Schoberl},
  file = {C:\Users\ahmed\OneDrive\Research\Modeling\FiniteElementMethod\Scientiﬁc_Computing_Software_Concepts_for_Solving_Partial_Diﬀerential_Schoberl_.pdf}
}

@article{segovia-chavesSensitivityOptimizationCells2021,
  title = {Sensitivity Optimization of Cells Immersed in a Cavity Surrounded by Thin Graphene Layers in One-Dimensional Photonic Crystals},
  author = {Segovia-Chaves, Francis and Trujillo Yague, Juan Carlos},
  date = {2021-04},
  journaltitle = {Optik},
  volume = {231},
  pages = {166355},
  issn = {00304026},
  doi = {10.1016/j.ijleo.2021.166355},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0030402621000917},
  urldate = {2024-06-01},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\BioSensor\Sensitivity_optimization_of_cells_immersed_in_a_cavity_surrounded_by_thin_Segovia-Chaves_Trujillo_Yague_2021.pdf}
}

@article{sellamiAcceleratingFiniteElementMethod2020,
  title = {Accelerating the {{Finite-Element Method}} for {{Reaction-Diffusion Simulations}} on {{GPUs}} with {{CUDA}}},
  author = {Sellami, Hedi and Cazenille, Leo and Fujii, Teruo and Hagiya, Masami and Aubert-Kato, Nathanael and Genot, Anthony J.},
  date = {2020-09-22},
  journaltitle = {Micromachines},
  volume = {11},
  number = {9},
  pages = {881},
  issn = {2072-666X},
  doi = {10.3390/mi11090881},
  url = {https://www.mdpi.com/2072-666X/11/9/881},
  urldate = {2024-07-08},
  abstract = {DNA nanotechnology offers a fine control over biochemistry by programming chemical reactions in DNA templates. Coupled to microfluidics, it has enabled DNA-based reaction-diffusion microsystems with advanced spatio-temporal dynamics such as traveling waves. The Finite Element Method (FEM) is a standard tool to simulate the physics of such systems where boundary conditions play a crucial role. However, a fine discretization in time and space is required for complex geometries (like sharp corners) and highly nonlinear chemistry. Graphical Processing Units (GPUs) are increasingly used to speed up scientific computing, but their application to accelerate simulations of reaction-diffusion in DNA nanotechnology has been little investigated. Here we study reaction-diffusion equations (a DNA-based predator-prey system) in a tortuous geometry (a maze), which was shown experimentally to generate subtle geometric effects. We solve the partial differential equations on a GPU, demonstrating a speedup of ∼100 over the same resolution on a 20 cores CPU.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\Pytorch\Accelerating_the_Finite-Element_Method_for_Reaction-Diffusion_Simulations_on_Sellami_et_al_2020.pdf}
}

@article{selvarajuGradCAMVisualExplanations2020,
  title = {Grad-{{CAM}}: {{Visual Explanations}} from {{Deep Networks}} via {{Gradient-based Localization}}},
  shorttitle = {Grad-{{CAM}}},
  author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  date = {2020-02},
  journaltitle = {Int J Comput Vis},
  volume = {128},
  number = {2},
  eprint = {1610.02391},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {336--359},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-019-01228-7},
  url = {http://arxiv.org/abs/1610.02391},
  urldate = {2024-03-13},
  abstract = {We propose a technique for producing "visual explanations" for decisions from a large class of CNN-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting important regions in the image for predicting the concept. Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers, (2) CNNs used for structured outputs, (3) CNNs used in tasks with multimodal inputs or reinforcement learning, without any architectural changes or re-training. We combine Grad-CAM with fine-grained visualizations to create a high-resolution class-discriminative visualization and apply it to off-the-shelf image classification, captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into their failure modes, (b) are robust to adversarial images, (c) outperform previous methods on localization, (d) are more faithful to the underlying model and (e) help achieve generalization by identifying dataset bias. For captioning and VQA, we show that even non-attention based models can localize inputs. We devise a way to identify important neurons through Grad-CAM and combine it with neuron names to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-CAM helps users establish appropriate trust in predictions from models and show that Grad-CAM helps untrained users successfully discern a 'stronger' nodel from a 'weaker' one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/, along with a demo at http://gradcam.cloudcv.org, and a video at youtu.be/COjUB9Izk6E.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\Visualization\Grad-CAM_Selvaraju_et_al_2020.pdf}
}

@online{senguptaDiffHumanProbabilisticPhotorealistic2024,
  title = {{{DiffHuman}}: {{Probabilistic Photorealistic 3D Reconstruction}} of {{Humans}}},
  shorttitle = {{{DiffHuman}}},
  author = {Sengupta, Akash and Alldieck, Thiemo and Kolotouros, Nikos and Corona, Enric and Zanfir, Andrei and Sminchisescu, Cristian},
  date = {2024-03-30},
  eprint = {2404.00485},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.00485},
  url = {http://arxiv.org/abs/2404.00485},
  urldate = {2024-05-05},
  abstract = {We present DiffHuman, a probabilistic method for photorealistic 3D human reconstruction from a single RGB image. Despite the ill-posed nature of this problem, most methods are deterministic and output a single solution, often resulting in a lack of geometric detail and blurriness in unseen or uncertain regions. In contrast, DiffHuman predicts a probability distribution over 3D reconstructions conditioned on an input 2D image, which allows us to sample multiple detailed 3D avatars that are consistent with the image. DiffHuman is implemented as a conditional diffusion model that denoises pixel-aligned 2D observations of an underlying 3D shape representation. During inference, we may sample 3D avatars by iteratively denoising 2D renders of the predicted 3D representation. Furthermore, we introduce a generator neural network that approximates rendering with considerably reduced runtime (55x speed up), resulting in a novel dual-branch diffusion framework. Our experiments show that DiffHuman can produce diverse and detailed reconstructions for the parts of the person that are unseen or uncertain in the input image, while remaining competitive with the state-of-the-art when reconstructing visible surfaces.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\DiffHuman_Sengupta_et_al_2024.pdf}
}

@article{seungseokohGeneralFrameworkNonlinear2005,
  title = {A General Framework for Nonlinear Multigrid Inversion},
  author = {{Seungseok Oh} and Milstein, A.B. and Bouman, C.A. and Webb, K.J.},
  date = {2005-01},
  journaltitle = {IEEE Trans. on Image Process.},
  volume = {14},
  number = {1},
  pages = {125--140},
  issn = {1057-7149},
  doi = {10.1109/TIP.2004.837555},
  url = {http://ieeexplore.ieee.org/document/1369334/},
  urldate = {2024-07-08},
  abstract = {A variety of new imaging modalities, such as optical diffusion tomography, require the inversion of a forward problem that is modeled by the solution to a three-dimensional partial differential equation. For these applications, image reconstruction is particularly difficult because the forward problem is both nonlinear and computationally expensive to evaluate. In this paper, we propose a general framework for nonlinear multigrid inversion that is applicable to a wide variety of inverse problems. The multigrid inversion algorithm results from the application of recursive multigrid techniques to the solution of optimization problems arising from inverse problems. The method works by dynamically adjusting the cost functionals at different scales so that they are consistent with, and ultimately reduce, the finest scale cost functional. In this way, the multigrid inversion algorithm efficiently computes the solution to the desired fine-scale inversion problem. Importantly, the new algorithm can greatly reduce computation because both the forward and inverse problems are more coarsely discretized at lower resolutions. An application of our method to Bayesian optical diffusion tomography with a generalized Gaussian Markov random-field image prior model shows the potential for very large computational savings. Numerical data also indicates robust convergence with a range of initialization conditions for this nonconvex optimization problem.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Multigrid\A_general_framework_for_nonlinear_multigrid_inversion_Seungseok_Oh_et_al_2005.pdf}
}

@article{shahriariTakingHumanOut2016,
  title = {Taking the {{Human Out}} of the {{Loop}}: {{A Review}} of {{Bayesian Optimization}}},
  shorttitle = {Taking the {{Human Out}} of the {{Loop}}},
  author = {Shahriari, Bobak and Swersky, Kevin and Wang, Ziyu and Adams, Ryan P. and family=Freitas, given=Nando, prefix=de, useprefix=true},
  date = {2016-01},
  journaltitle = {Proceedings of the IEEE},
  volume = {104},
  number = {1},
  pages = {148--175},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2015.2494218},
  url = {https://ieeexplore.ieee.org/document/7352306},
  urldate = {2024-06-01},
  abstract = {Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.},
  eventtitle = {Proceedings of the {{IEEE}}},
  keywords = {Bayes methods,Big data,decision making,Decision making,design of experiments,Design of experiments,Genomes,genomic medicine,Linear programming,optimization,Optimization,response surface methodology,Statistical analysis,statistical learning},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\BayesianOptimization\Taking_the_Human_Out_of_the_Loop_Shahriari_et_al_2016.pdf}
}

@article{shangInverseDesignedLithiumNiobate2023,
  title = {Inverse-{{Designed Lithium Niobate Nanophotonics}}},
  author = {Shang, Chengfei and Yang, Jingwei and Hammond, Alec M. and Chen, Zhaoxi and Chen, Mo and Lin, Zin and Johnson, Steven G. and Wang, Cheng},
  date = {2023-04-19},
  journaltitle = {ACS Photonics},
  volume = {10},
  number = {4},
  pages = {1019--1026},
  publisher = {American Chemical Society},
  doi = {10.1021/acsphotonics.3c00040},
  url = {https://doi.org/10.1021/acsphotonics.3c00040},
  urldate = {2024-06-01},
  abstract = {Lithium niobate-on-insulator (LNOI) is an emerging photonic platform that exhibits favorable material properties (such as low optical loss, strong nonlinearities, and stability) and enables large-scale integration with stronger optical confinement, showing promise for future optical networks, quantum processors, and nonlinear optical systems. However, while photonics engineering has entered the era of automated “inverse design” via optimization in recent years, the design of LNOI integrated photonic devices still mostly relies on intuitive models and inefficient parameter sweeps, limiting the accessible parameter space, performance, and functionality. Here, we implement a 3D gradient-based inverse-design model tailored for topology optimization based on the LNOI platform, which not only could efficiently search a large parameter space, but also takes into account practical fabrication constraints, including minimum feature sizes and etched sidewall angles. We experimentally demonstrate a spatial-mode multiplexer, a waveguide crossing, and a compact waveguide bend, all with low insertion losses, tiny footprints, and excellent agreement between simulation and experimental results. The devices, together with the design methodology, represent a crucial step toward the variety of advanced device functionalities needed in future LNOI photonics and could provide compact and cost-effective solutions for future optical links, quantum technologies, and nonlinear optics.},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\Inverse-Designed_Lithium_Shang_et_al_2023.pdf}
}

@article{sharmaEstimatingAquiferLocation2020,
  title = {Estimating Aquifer Location Using Deep Neural Network with Electrical Impedance Tomography},
  author = {Sharma, Sunam Kumar and Khambampati, Anil Kumar and Kim, Kyung Youn},
  date = {2020-12-31},
  journaltitle = {Journal of IKEEE},
  volume = {24},
  number = {4},
  pages = {982--990},
  doi = {10.7471/IKEEE.2020.24.4.982},
  url = {https://doi.org/10.7471/IKEEE.2020.24.4.982},
  urldate = {2024-07-08},
  abstract = {Groundwater is essential source of the freshwater. Groundwater is stored in the body of the rocks or sediments, called aquifer. Finding an aquifer is a very important part of the geophysical survey. The best method to find the aquifer is to make a borehole. Single borehole is not a suitable method if the aquifer is not located in the borehole drilled area. To overcome this problem, a cross borehole method is used. Using a cross borehole method, we can estimate aquifer location more precisely. Electrical impedance tomography is use to estimate the aquifer location inside the subsurface using the cross borehole method. Electrodes are placed inside each boreholes and area between these boreholes are analysed. An aquifer is a non-uniform structure with complex shape which can represented by the truncated Fourier series. Deep neural network is evaluated as an inverse problem solver for estimating the aquifer boundary coefficients.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\GeoPhysics\Estimating_aquifer_location_using_deep_neural_network_with_electrical_impedance_Sharma_et_al_2020.pdf}
}

@article{sharmaEstimationPhotonicBand2015,
  title = {Estimation of Photonic Band Gap in Silicon Crystal Waveguide through Acousto-Optic Interaction},
  author = {Sharma, Gaurav and Kumar, Sushil and Prasad, Surendra and Singh, Vivek},
  date = {2015-08},
  journaltitle = {Opt Quant Electron},
  volume = {47},
  number = {8},
  pages = {3031--3040},
  issn = {0306-8919, 1572-817X},
  doi = {10.1007/s11082-015-0190-6},
  url = {http://link.springer.com/10.1007/s11082-015-0190-6},
  urldate = {2024-01-22},
  abstract = {The photonic band gap through acousto-optic interaction in a face-centred cubic silicon crystal is theoretically studied. The dispersion relation for acoustic wave is obtained using method of potentials with boundary conditions involving the bulk and surface stress of considered materials. The dispersion relation for optical wave is derived by transfer matrix method and boundary conditions based on electromagnetic theory. Observation shows that the central frequency of photonic band gap in silicon crystal can be chosen in any desired infrared optical frequency range by adjusting the frequency of acoustic wave. Also, the size of these band gaps in chosen optical frequency range can be further tuned through incident angle of light wave. This study may provide an efficient method to obtain tuneable photonic crystal.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\AcoustoOptic\Estimation_of_photonic_band_gap_in_silicon_crystal_waveguide_through_Sharma_et_al_2015.pdf}
}

@inproceedings{shekharComparativeStudyHyperParameter2021,
  title = {A {{Comparative}} Study of {{Hyper-Parameter Optimization Tools}}},
  author = {Shekhar, Shashank and Bansode, Adesh and Salim, Asif},
  date = {2021-12-01},
  pages = {1--6},
  publisher = {IEEE Computer Society},
  doi = {10.1109/CSDE53843.2021.9718485},
  url = {https://www.computer.org/csdl/proceedings-article/csde/2021/09718485/1BogOxejnsQ},
  urldate = {2023-09-26},
  abstract = {Most of the machine learning models have associated hyper-parameters along with their parameters. While the algorithm gives the solution for parameters, its utility for model performance is highly dependent on the choice of hyperparameters. For a robust performance of a model, it is necessary to find out the right hyper-parameter combination. Hyper-parameter optimization (HPO) is a systematic process that helps in finding the right values for them. The conventional methods for this purpose are grid search and random search and both methods create issues in industrial-scale applications. Hence a set of strategies have been recently proposed based on Bayesian optimization and evolutionary algorithm principles that help in runtime issues in a production environment and robust performance. In this paper, we compare the performance of four python libraries, namely Optuna, Hyper-opt, Optunity, and sequential model-based algorithm configuration (SMAC) that has been proposed for hyper-parameter optimization. The performance of these tools is tested using two benchmarks. The first one is to solve a combined algorithm selection and hyper-parameter optimization (CASH) problem The second one is the NeurIPS black-box optimization challenge in which a multilayer perceptron (MLP) architecture has to be chosen from a set of related architecture constraints and hyper-parameters. The benchmarking is done with six real-world datasets. From the experiments, we found that Optuna has better performance for CASH problem and HyperOpt for MLP problem.},
  eventtitle = {2021 {{IEEE Asia-Pacific Conference}} on {{Computer Science}} and {{Data Engineering}} ({{CSDE}})},
  isbn = {978-1-66549-552-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\HyperparameterOptimization\A_Comparative_study_of_Hyper-Parameter_Optimization_Tools_Shekhar_et_al_2021.pdf}
}

@article{shenHFENetHierarchicalFeature2024,
  title = {{{HFE-Net}}: Hierarchical Feature Extraction and Coordinate Conversion of Point Cloud for Object {{6D}} Pose Estimation},
  shorttitle = {{{HFE-Net}}},
  author = {Shen, Ze and Chu, Hao and Wang, Fei and Guo, Yi and Liu, Shangdong and Han, Shuai},
  date = {2024-02-01},
  journaltitle = {Neural Comput \& Applic},
  volume = {36},
  number = {6},
  pages = {3167--3178},
  issn = {1433-3058},
  doi = {10.1007/s00521-023-09241-1},
  url = {https://doi.org/10.1007/s00521-023-09241-1},
  urldate = {2025-01-07},
  abstract = {The current challenging problems of learning a robust 6D pose lie in noise in RGB/RGBD images, sparsity of point cloud and severe occlusion. To tackle the problems, object geometric information is critical. In this work, we present a novel pipeline for 6DoF object pose estimation. Unlike previous methods that directly regressing pose parameters and predicting keypoints, we tackle this challenging task with a point-pair based approach and leverage geometric information as much as possible. Specifically, at the representation learning stage, we build a point cloud network locally modeling CNN to encode point cloud, which is able to extract effective geometric features while the point cloud is projected into a high-dimensional space. Moreover, we design a coordinate conversion network to regress point cloud in the object coordinate system in a decoded way. Then, the pose could be calculated through point pairs matching algorithm. Experimental results show that our method achieves state-of-the-art performance on several datasets.},
  langid = {english},
  keywords = {Artificial Intelligence,Computer vision,Deep learning,Object pose estimation,Point cloud analysis},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\HFE-Net_Shen_et_al_2024.pdf}
}

@inproceedings{shenImperceptibleNeuralLinguistic2020,
  title = {Near-Imperceptible {{Neural Linguistic Steganography}} via {{Self-Adjusting Arithmetic Coding}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Shen, Jiaming and Ji, Heng and Han, Jiawei},
  date = {2020},
  pages = {303--313},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2020.emnlp-main.22},
  url = {https://www.aclweb.org/anthology/2020.emnlp-main.22},
  urldate = {2024-10-07},
  eventtitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\LinguisticSteganography\Near-imperceptible_Neural_Linguistic_Steganography_via_Self-Adjusting_Shen_et_al_2020.pdf}
}

@online{shenPSRFlowProbabilisticSuper2023,
  title = {{{PSRFlow}}: {{Probabilistic Super Resolution}} with {{Flow-Based Models}} for {{Scientific Data}}},
  shorttitle = {{{PSRFlow}}},
  author = {Shen, Jingyi and Shen, Han-Wei},
  date = {2023-08-08},
  eprint = {2308.04605},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2308.04605},
  url = {http://arxiv.org/abs/2308.04605},
  urldate = {2024-06-11},
  abstract = {Although many deep-learning-based super-resolution approaches have been proposed in recent years, because no ground truth is available in the inference stage, few can quantify the errors and uncertainties of the super-resolved results. For scientific visualization applications, however, conveying uncertainties of the results to scientists is crucial to avoid generating misleading or incorrect information. In this paper, we propose PSRFlow, a novel normalizing flow-based generative model for scientific data super-resolution that incorporates uncertainty quantification into the super-resolution process. PSRFlow learns the conditional distribution of the high-resolution data based on the low-resolution counterpart. By sampling from a Gaussian latent space that captures the missing information in the high-resolution data, one can generate different plausible super-resolution outputs. The efficient sampling in the Gaussian latent space allows our model to perform uncertainty quantification for the super-resolved results. During model training, we augment the training data with samples across various scales to make the model adaptable to data of different scales, achieving flexible super-resolution for a given input. Our results demonstrate superior performance and robust uncertainty quantification compared with existing methods such as interpolation and GAN-based super-resolution networks.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\SuperResolution\ScientificData\PSRFlow_Shen_Shen_2023.pdf}
}

@article{shiArrangementBoundaryElectrodes2021,
  title = {Arrangement of Boundary Electrodes for Detection of Frontal Lobe Disease with Electrical Impedance Tomography},
  author = {Shi, Yanyan and Tian, Zhiwei and Wang, Meng and Fu, Feng and Wu, Yuehui},
  date = {2021-07-06},
  journaltitle = {J. Med. Imag.},
  volume = {8},
  number = {04},
  issn = {2329-4302},
  doi = {10.1117/1.JMI.8.4.044501},
  url = {https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-8/issue-04/044501/Arrangement-of-boundary-electrodes-for-detection-of-frontal-lobe-disease/10.1117/1.JMI.8.4.044501.full},
  urldate = {2024-07-08},
  abstract = {Purpose: Caused by brain trauma or blood vessel abnormality, intracerebral hemorrhage and secondary ischemia have become prevalent and severe neurological diseases. The timely and accurate detection of disease is essential for the recovery of patients. As an emerging visualization technique, electrical impedance tomography (EIT) offers an alternative. It is able to reconstruct the conductivity distribution that reflects the pathological variation of human tissue. Approach: In the EIT-based detection, electrodes are usually in uniform arrangement, which may be not suitable in some conditions. To enhance sensitivity in the region of interest, EIT with a novel offset arrangement of boundary electrodes is proposed to image a simulated frontal lobe hemorrhage and secondary ischemia. To cope with the ill-posed inverse problem, the L1 regularization method is developed during the reconstruction. In addition, the impact of noise with a signal-to-noise ratio of 56 dB is studied. Results: Compared with the traditional uniform electrode arrangement, the results demonstrate that EIT with the proposed offset arrangement of electrodes is more advantageous for imaging frontal lobe disease. Conclusions: The proposed offset arrangement of electrodes is superior to the traditional uniform arrangement in imaging frontal lobe disease, especially under the impact of noise.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Brain\Arrangement_of_boundary_electrodes_for_detection_of_frontal_lobe_disease_with_Shi_et_al_2021.pdf}
}

@article{shinKoreanSignLanguage2024,
  title = {Korean {{Sign Language Alphabet Recognition Through}} the {{Integration}} of {{Handcrafted}} and {{Deep Learning-Based Two-Stream Feature Extraction Approach}}},
  author = {Shin, Jungpil and Miah, Abu Saleh Musa and Akiba, Yuto and Hirooka, Koki and Hassan, Najmul and Hwang, Yong Seok},
  date = {2024},
  journaltitle = {IEEE Access},
  volume = {12},
  pages = {68303--68318},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3399839},
  url = {https://ieeexplore.ieee.org/abstract/document/10529244},
  urldate = {2025-01-07},
  abstract = {Recognizing sign language plays a crucial role in improving communication accessibility for the Deaf and hard-of-hearing communities. In Korea, many individuals facing hearing and speech challenges depend on Korean Sign Language (KSL) as their primary means of communication. Many researchers have been working to develop a sign language recognition system for other sign languages. Still, little research has been done for KSL alphabet recognition due to the lack of dataset availability. Moreover, existing KSL recognition systems have faced significant performance limitations due to the ineffectiveness of the features. To overcome the challenges, we newly created a KSL alphabet dataset and introduced an innovative KSL recognition system employing a strategic fusion approach. In the proposed study, we combined joint skeleton-based handcrafted features and pixel-based resnet101 transfer learning features to overcome the limitations of feature effectiveness in traditional systems. Our system consists of two distinct feature extraction streams: the first stream extracts essential handcrafted features, emphasizing capturing hand orientation information within KSL gestures. In the second stream, concurrently, we employed a deep learning-based resnet101 module stream to capture hierarchical representations of the KSL alphabet sign. By combining essential features from the first stream with the hierarchical features from the second stream, we generate multiple levels of fused features with the goal of forming a comprehensive representation of KSL gestures. Finally, we fed the concatenated feature into the deep learning-based classification module for the classification. We conducted extensive experiments with the newly created KSL alphabet dataset, the existing KSL digit and the existing ArSL and ASL benchmark datasets. Our proposed model undeniably shows that our fusion approach substantially improves high-performance accuracy in both cases, which proves the system’s superiority.},
  eventtitle = {{{IEEE Access}}},
  keywords = {angle feature,Assistive technologies,Computational modeling,distance feature,Feature extraction,geometric feature,Gesture recognition,hand gesture recognition,Hidden Markov models,Korean sign language (KSL),ResNet,Sign language,Streams,Support vector machines},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\Korean_Sign_Language_Alphabet_Shin_et_al_2024.pdf}
}

@article{shinScalableVariableindexElastooptic2017,
  title = {Scalable Variable-Index Elasto-Optic Metamaterials for Macroscopic Optical Components and Devices},
  author = {Shin, Dongheok and Kim, Junhyun and Kim, Changwook and Bae, Kyuyoung and Baek, Seunghwa and Kang, Gumin and Urzhumov, Yaroslav and Smith, David R. and Kim, Kyoungsik},
  date = {2017-07-12},
  journaltitle = {Nat Commun},
  volume = {8},
  number = {1},
  pages = {16090},
  issn = {2041-1723},
  doi = {10.1038/ncomms16090},
  url = {https://www.nature.com/articles/ncomms16090},
  urldate = {2023-09-05},
  abstract = {Abstract                            Optical metamaterials with an artificial subwavelength structure offer new approaches to implement advanced optical devices. However, some of the biggest challenges associated with the development of metamaterials in the visible spectrum are the high costs and slow production speeds of the nanofabrication processes. Here, we demonstrate a macroscale ({$>$}35\,mm) transformation-optics wave bender (293\,mm               2               ) and Luneburg lens (855\,mm               2               ) in the broadband white-light visible wavelength range using the concept of elasto-optic metamaterials that combines optics and solid mechanics. Our metamaterials consist of mesoscopically homogeneous chunks of bulk aerogels with superior, broadband optical transparency across the visible spectrum and an adjustable, stress-tuneable refractive index ranging from 1.43 down to nearly the free space index (∼1.074). The experimental results show that broadband light can be controlled and redirected in a volume of {$>$}10               5               λ               × 10               5               λ               × 10               3               λ               , which enables natural light to be processed directly by metamaterial-based optical devices without any additional coupling components.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Aerogel\Scalable_variable-index_elasto-optic_metamaterials_for_macroscopic_optical_Shin_et_al_2017.pdf}
}

@inproceedings{shiRendNetUnified2D2022,
  title = {{{RendNet}}: {{Unified 2D}}/{{3D Recognizer}} with {{Latent Space Rendering}}},
  shorttitle = {{{RendNet}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Shi, Ruoxi and Jiang, Xinyang and Shan, Caihua and Wang, Yansen and Li, Dongsheng},
  date = {2022-06},
  pages = {5398--5407},
  publisher = {IEEE},
  location = {New Orleans, LA, USA},
  doi = {10.1109/CVPR52688.2022.00533},
  url = {https://ieeexplore.ieee.org/document/9879872/},
  urldate = {2023-07-28},
  abstract = {Vector graphics (VG) have been ubiquitous in our daily life with vast applications in engineering, architecture, designs, etc. The VG recognition process of most existing methods is to first render the VG into raster graphics (RG) and then conduct recognition based on RG formats. However, this procedure discards the structure of geometries and loses the high resolution of VG. Recently, another category of algorithms is proposed to recognize directly from the original VG format. But it is affected by the topological errors that can be filtered out by RG rendering. Instead of looking at one format, it is a good solution to utilize the formats of VG and RG together to avoid these shortcomings. Besides, we argue that the VG-to-RG rendering process is essential to effectively combine VG and RG information. By specifying the rules on how to transfer VG primitives to RG pixels, the rendering process depicts the interaction and correlation between VG and RG. As a result, we propose RendNet, a unified architecture for recognition on both 2D and 3D scenarios, which considers both VG/RG representations and exploits their interaction by incorporating the VGto-RG rasterization process. Experiments show that RendNet can achieve state-of-the-art performance on 2D and 3D object recognition tasks on various VG datasets.},
  eventtitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66546-946-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\RenderSpaces\RendNet_Shi_et_al_2022.pdf}
}

@article{shiResearchProgressElectrical2021,
  title = {The {{Research Progress}} of {{Electrical Impedance Tomography}} for {{Lung Monitoring}}},
  author = {Shi, Yan and Yang, ZhiGuo and Xie, Fei and Ren, Shuai and Xu, ShaoFeng},
  date = {2021-10-01},
  journaltitle = {Front. Bioeng. Biotechnol.},
  volume = {9},
  pages = {726652},
  issn = {2296-4185},
  doi = {10.3389/fbioe.2021.726652},
  url = {https://www.frontiersin.org/articles/10.3389/fbioe.2021.726652/full},
  urldate = {2024-07-08},
  abstract = {Medical imaging can intuitively show people the internal structure, morphological information, and organ functions of the organism, which is one of the most important inspection methods in clinical medical diagnosis. Currently used medical imaging methods can only be applied to some diagnostic occasions after qualitative lesions have been generated, and the general imaging technology is usually accompanied by radiation and other conditions. However, electrical impedance tomography has the advantages of being noninvasive and non-radiative. EIT (Electrical Impedance Tomography) is also widely used in the early diagnosis and treatment of some diseases because of these advantages. At present, EIT is relatively mature and more and more image reconstruction algorithms are used to improve imaging resolution. Hardware technology is also developing rapidly, and the accuracy of data collection and processing is continuously improving. In terms of clinical application, EIT has also been used for pathological treatment of lungs, the brain, and the bladder. In the future, EIT has a good application prospect in the medical field, which can meet the needs of real-time, long-term monitoring and early diagnosis. Aiming at the application of EIT in the treatment of lung pathology, this article reviews the research progress of EIT, image reconstruction algorithms, hardware system design, and clinical applications used in the treatment of lung diseases. Through the research and introduction of several core components of EIT technology, it clarifies the characteristics of EIT system complexity and its solutions, provides research ideas for subsequent research, and once again verifies the broad development prospects of EIT technology in the future.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\The_Research_Progress_of_Electrical_Impedance_Tomography_for_Lung_Monitoring_Shi_et_al_2021.pdf}
}

@article{shiveshwariTransmissionPropertiesOnedimensional2015,
  title = {Transmission Properties of One-Dimensional Ternary Plasma Photonic Crystals},
  author = {Shiveshwari, Laxmi and Awasthi, S. K.},
  date = {2015-09-01},
  journaltitle = {Physics of Plasmas},
  volume = {22},
  number = {9},
  pages = {092129},
  issn = {1070-664X, 1089-7674},
  doi = {10.1063/1.4931926},
  url = {https://pubs.aip.org/pop/article/22/9/092129/109126/Transmission-properties-of-one-dimensional-ternary},
  urldate = {2024-01-22},
  abstract = {Omnidirectional photonic band gaps (PBGs) are found in one-dimensional ternary plasma photonic crystals (PPC) composed of single negative metamaterials. The band characteristics and transmission properties are investigated through the transfer matrix method. We show that the proposed structure can trap light in three-dimensional space due to the elimination of Brewster's angle transmission resonance allowing the existence of complete PBG. The results are discussed in terms of incident angle, layer thickness, dielectric constant of the dielectric material, and number of unit cells (N) for TE and TM polarizations. It is seen that PBG characteristics is apparent even in an N\,≥\,2 system, which is weakly sensitive to the incident angle and completely insensitive to the polarization. Finite PPC could be used for multichannel transmission filter without introducing any defect in the geometry. We show that the locations of the multichannel transmission peaks are in the allowed band of the infinite structure. The structure can work as a single or multichannel filter by varying the number of unit cells. Binary PPC can also work as a polarization sensitive tunable filter.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Transmission_properties_of_one-dimensional_ternary_plasma_photonic_crystals_Shiveshwari_Awasthi_2015.pdf}
}

@inproceedings{siarohinFirstOrderMotion2019,
  title = {First {{Order Motion Model}} for {{Image Animation}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Siarohin, Aliaksandr and Lathuilière, Stéphane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  date = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  url = {https://papers.nips.cc/paper_files/paper/2019/hash/31c0b36aef265d9221af80872ceb62f9-Abstract.html},
  urldate = {2024-02-02},
  abstract = {Image animation consists of generating a video sequence so that an object in a source image is animated according to the motion of a driving video. Our framework addresses this problem without using any annotation or prior information about the specific object to animate. Once trained on a set of videos depicting objects of the same category (e.g. faces, human bodies), our method can be applied to any object of this class. To achieve this, we decouple appearance and motion information using a self-supervised formulation. To support complex motions, we use a representation consisting of a set of learned keypoints along with their local affine transformations. A generator network models occlusions arising during target motions and combines the appearance extracted from the source image and the motion derived from the driving video. Our framework scores best on diverse benchmarks and on a variety of object categories.},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\GenerativeAI\\ImageAnimation\\First_Order_Motion_Model_for_Siarohin_et_al_2019.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\GenerativeAI\\ImageAnimation\\First_Order_Motion_Model_for_Siarohin_et_al_22.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\GenerativeAI\\ImageAnimation\\First_Order_Motion_Model_for_Siarohin_et_al_3.pdf}
}

@online{siarohinMotionRepresentationsArticulated2021,
  title = {Motion {{Representations}} for {{Articulated Animation}}},
  author = {Siarohin, Aliaksandr and Woodford, Oliver J. and Ren, Jian and Chai, Menglei and Tulyakov, Sergey},
  date = {2021-04-22},
  eprint = {2104.11280},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2104.11280},
  urldate = {2024-04-04},
  abstract = {We propose novel motion representations for animating articulated objects consisting of distinct parts. In a completely unsupervised manner, our method identifies object parts, tracks them in a driving video, and infers their motions by considering their principal axes. In contrast to the previous keypoint-based works, our method extracts meaningful and consistent regions, describing locations, shape, and pose. The regions correspond to semantically relevant and distinct object parts, that are more easily detected in frames of the driving video. To force decoupling of foreground from background, we model non-object related global motion with an additional affine transformation. To facilitate animation and prevent the leakage of the shape of the driving object, we disentangle shape and pose of objects in the region space. Our model1 can animate a variety of objects, surpassing previous methods by a large margin on existing benchmarks. We present a challenging new benchmark with high-resolution videos and show that the improvement is particularly pronounced when articulated objects are considered, reaching 96.6\% user preference vs. the state of the art.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\Motion_Representations_for_Siarohin_et_al_2021.pdf}
}

@online{siddiquiMeshGPTGeneratingTriangle2023,
  title = {{{MeshGPT}}: {{Generating Triangle Meshes}} with {{Decoder-Only Transformers}}},
  shorttitle = {{{MeshGPT}}},
  author = {Siddiqui, Yawar and Alliegro, Antonio and Artemov, Alexey and Tommasi, Tatiana and Sirigatti, Daniele and Rosov, Vladislav and Dai, Angela and Nießner, Matthias},
  date = {2023-11-26},
  eprint = {2311.15475},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.15475},
  url = {http://arxiv.org/abs/2311.15475},
  urldate = {2024-08-05},
  abstract = {We introduce MeshGPT, a new approach for generating triangle meshes that reflects the compactness typical of artist-created meshes, in contrast to dense triangle meshes extracted by iso-surfacing methods from neural fields. Inspired by recent advances in powerful large language models, we adopt a sequence-based approach to autoregressively generate triangle meshes as sequences of triangles. We first learn a vocabulary of latent quantized embeddings, using graph convolutions, which inform these embeddings of the local mesh geometry and topology. These embeddings are sequenced and decoded into triangles by a decoder, ensuring that they can effectively reconstruct the mesh. A transformer is then trained on this learned vocabulary to predict the index of the next embedding given previous embeddings. Once trained, our model can be autoregressively sampled to generate new triangle meshes, directly generating compact meshes with sharp edges, more closely imitating the efficient triangulation patterns of human-crafted meshes. MeshGPT demonstrates a notable improvement over state of the art mesh generation methods, with a 9\% increase in shape coverage and a 30-point enhancement in FID scores across various categories.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\MeshExtract\MeshGPT_Siddiqui_et_al_2023.pdf}
}

@article{silvera-tawilElectricalImpedanceTomography2015,
  title = {Electrical {{Impedance Tomography}} for {{Artificial Sensitive Robotic Skin}}: {{A Review}}},
  shorttitle = {Electrical {{Impedance Tomography}} for {{Artificial Sensitive Robotic Skin}}},
  author = {Silvera-Tawil, David and Rye, David and Soleimani, Manuchehr and Velonaki, Mari},
  date = {2015-04},
  journaltitle = {IEEE Sensors J.},
  volume = {15},
  number = {4},
  pages = {2001--2016},
  issn = {1530-437X, 1558-1748},
  doi = {10.1109/JSEN.2014.2375346},
  url = {http://ieeexplore.ieee.org/document/6971063/},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is a nondestructive imaging technique used to estimate the internal conductivity distribution of a conductive domain by taking potential measurements only at the domain boundaries. If a thin electrically conductive material that responds to pressure with local changes in conductivity is used as a conductive domain, then EIT can be used to create a large-scale pressure-sensitive artificial skin for robotics applications. This paper presents a review of EIT and its application as a robotics sensitive skin, including EIT excitation and image reconstruction techniques, materials, and skin fabrication techniques. Touch interpretation via EIT-based artificial skins is also reviewed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Robotics\Electrical_Impedance_Tomography_for_Artificial_Sensitive_Robotic_Skin_Silvera-Tawil_et_al_2015.pdf}
}

@book{silvesterFiniteElementsElectrical1996,
  title = {Finite {{Elements}} for {{Electrical Engineers}}},
  author = {Silvester, Peter P. and Ferrari, Ronald L.},
  date = {1996},
  edition = {3},
  publisher = {Cambridge University Press},
  location = {Cambridge},
  doi = {10.1017/CBO9781139170611},
  url = {https://www.cambridge.org/core/books/finite-elements-for-electrical-engineers/6F8A854B365C797B5D170C9A4DD8CB9B},
  urldate = {2024-07-08},
  abstract = {This third edition of the principal text on the finite element method for electrical engineers and electronics specialists presents the method in a mathematically undemanding style, accessible to undergraduates who may be encountering it for the first time. Like the earlier editions, it begins by deriving finite elements for the simplest familiar potential fields, then advances to formulate finite elements for a wide range of applied electromagnetics problems. These include wave propagation, diffusion, and static fields; open-boundary problems and nonlinear materials; axisymmetric, planar and fully three-dimensional geometries; scalar and vector fields. This new edition is more than half as long again as its predecessor, with original material extensively revised and much new material added. As well as providing all that is needed for the beginning undergraduate student, this textbook is also a valuable reference text for professional engineers and research students. A wide selection of demonstration programs allows the reader to follow the practical use of the methods.},
  isbn = {978-0-521-44505-4},
  file = {C:\Users\ahmed\OneDrive\Research\Modeling\FiniteElementMethod\Finite_Elements_for_Electrical_Engineers_Silvester_Ferrari_1996.pdf}
}

@article{sinareVeryLowFrequency,
  title = {Very {{Low Frequency Electrical Impedance Tomography Image Reconstruction System Using FPGA Software-Hardware Co-design}}},
  author = {Sinare, Monali},
  abstract = {Electrical Impedance Tomography (EIT) is an imaging technique which is noninvasive and uses the internal conductivity distribution of the object of interest to form a tomographic image. It is performed by applying electrodes to the surface of the object. An alternating current up to frequency 10kHz is applied through a pair of electrodes, and the induced voltage is measured on other electrodes. These current and voltage values are used to reconstruct the internal conductivity distribution. The EIT imaging is increasingly getting used in clinical applications, as it is safer, portable, and low cost if compared with available imaging technologies used in clinical settings. The goal of this project is to develop a low frequency Zynq SoC-based EIT system. A Zynq 7020 device-based development board, Zedboard, interfaced with a customized hardware circuit, is used to develop a complete EIT system. A graphical user interface is developed using C\# Graphic User Interface (GUI) application to control the hardware and visualize the results. It is a twelve-electrode system, and current injection and voltage measurement is performed through Zynq SoC. There are two image reconstruction algorithms developed, Gauss Newton One Step and Total variation. The algorithms are implemented in Zynq SoC using softwarehardware co-design. The algorithms are also implemented in C\#. The image reconstruction performance between the two algorithms is compared. The computation performance between Zynq SoC implementation and C\# implementation is also compared to understand the feasibility of FPGA implementation of EIT image reconstruction algorithms.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\Very_Low_Frequency_Electrical_Impedance_Tomography_Image_Reconstruction_System_Sinare_.pdf}
}

@inproceedings{sitzmannImplicitNeuralRepresentations2020,
  title = {Implicit {{Neural Representations}} with {{Periodic Activation Functions}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Sitzmann, Vincent and Martel, Julien and Bergman, Alexander and Lindell, David and Wetzstein, Gordon},
  date = {2020},
  volume = {33},
  pages = {7462--7473},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/53c04118df112c13a8c34b38343b9c10-Abstract.html},
  urldate = {2024-12-03},
  abstract = {Implicitly defined, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible benefits over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with fine detail, and fail to represent a signal's spatial and temporal derivatives, despite the fact that these are essential to many physical signals defined implicitly as the solution to partial differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or SIRENs, are ideally suited for representing complex natural signals and their derivatives. We analyze SIREN activation statistics to propose a principled initialization scheme and demonstrate the representation of images, wavefields, video, sound, and their derivatives. Further, we show how SIRENs can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine SIRENs with hypernetworks to learn priors over the space of SIREN functions.},
  file = {C:\Users\ahmed\Zotero\storage\NH49JIIF\Sitzmann et al. - 2020 - Implicit Neural Representations with Periodic Acti.pdf}
}

@article{smithCompositeMediumSimultaneously2000,
  title = {Composite {{Medium}} with {{Simultaneously Negative Permeability}} and {{Permittivity}}},
  author = {Smith, D. R. and Padilla, Willie J. and Vier, D. C. and Nemat-Nasser, S. C. and Schultz, S.},
  date = {2000-05-01},
  journaltitle = {Phys. Rev. Lett.},
  volume = {84},
  number = {18},
  pages = {4184--4187},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.84.4184},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.84.4184},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\DoubleNegativeMaterial\Composite_Medium_with_Simultaneously_Negative_Permeability_and_Permittivity_Smith_et_al_2000.pdf}
}

@article{smithCompositeMediumSimultaneously2000a,
  title = {Composite {{Medium}} with {{Simultaneously Negative Permeability}} and {{Permittivity}}},
  author = {Smith, D. R. and Padilla, Willie J. and Vier, D. C. and Nemat-Nasser, S. C. and Schultz, S.},
  date = {2000-05-01},
  journaltitle = {Phys. Rev. Lett.},
  volume = {84},
  number = {18},
  pages = {4184--4187},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.84.4184},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.84.4184},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Composite_Medium_with_Simultaneously_Negative_Permeability_and_Permittivity_Smith_et_al_2000.pdf}
}

@article{soleimaniImprovingForwardSolver2005,
  title = {Improving the Forward Solver for the Complete Electrode Model in {{EIT}} Using Algebraic Multigrid},
  author = {Soleimani, M. and Powell, C.E. and Polydorides, N.},
  date = {2005-05},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {24},
  number = {5},
  pages = {577--583},
  issn = {0278-0062},
  doi = {10.1109/TMI.2005.843741},
  url = {http://ieeexplore.ieee.org/document/1425664/},
  urldate = {2024-07-08},
  abstract = {Image reconstruction in electrical impedance tomography is an ill-posed nonlinear inverse problem. Linearization techniques are widely used and require the repeated solution of a linear forward problem. To account correctly for the presence of electrodes and contact impedances, the so-called complete electrode model is applied. Implementing a standard finite element method for this particular forward problem yields a linear system that is symmetric and positive definite and solvable via the conjugate gradient method. However, preconditioners are essential for efficient convergence. Preconditioners based on incomplete factorization methods are commonly used but their performance depends on user-tuned parameters. To avoid this deficiency, we apply black-box algebraic multigrid, using standard commercial and freely available software. The suggested solution scheme dramatically reduces the time cost of solving the forward problem. Numerical results are presented using an anatomically detailed model of the human head.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Multigrid\Improving_the_forward_solver_for_the_complete_electrode_model_in_EIT_using_Soleimani_et_al_2005.pdf}
}

@article{songNonlinearWeightedAnisotropic2022,
  title = {A {{Nonlinear Weighted Anisotropic Total Variation Regularization}} for {{Electrical Impedance Tomography}}},
  author = {Song, Yizhuang and Wang, Yanying and Liu, Dong},
  date = {2022},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {71},
  pages = {1--13},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2022.3220288},
  url = {https://ieeexplore.ieee.org/document/9940976/},
  urldate = {2024-07-03},
  abstract = {This article proposes a nonlinear weighted anisotropic total variation (NWATV) regularization technique for electrical impedance tomography (EIT). The key idea is to incorporate the internal inhomogeneity information (e.g., edges of the detected objects) into the EIT reconstruction process, aiming to preserve the conductivity profiles (to be detected). We study the NWATV image reconstruction using a novel soft thresholding-based reformulation included in the alternating direction method of multipliers (ADMM). To evaluate the proposed approach, numerical simulations and human EIT lung imaging are carried out. It is demonstrated that the properties of the internal inhomogeneity are well-preserved and improved with the proposed regularization approach, in comparison to traditional total variation (TV) and recently proposed fidelity embedded regularization (FER) approaches. Owing to the simplicity of the proposed method, the computational cost is significantly decreased compared with the well-established primal-dual algorithm. Precisely, with the proposed algorithm, we are able to alleviate the staircase effect arising in TV regularization and improve the reconstruction accuracy for FER does. To achieve similar accuracy as TV does, the computational times are reduced from 2.311 to 0.629 and 1.733 to 0.428 s in 2-D and 3-D simulations, respectively, and the computational time is reduced from greater than 2 s to less than 0.2 s in the human experiment. Meanwhile, it was found that the proposed regularization method is quite robust to the measurement noise, which is one of the main uncertainties in EIT.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\TotalVariation\A_Nonlinear_Weighted_Anisotropic_Total_Variation_Regularization_for_Electrical_Song_et_al_2022.pdf}
}

@article{srivastavaInvestigationReflectanceProperties2016,
  title = {Investigation of {{Reflectance Properties}} in {{1D Ternary Annular Photonic Crystal Containing Semiconductor}} and {{High-T}} c {{Superconductor}}},
  author = {Srivastava, Sanjeev K. and Aghajamali, Alireza},
  date = {2016-06},
  journaltitle = {J Supercond Nov Magn},
  volume = {29},
  number = {6},
  pages = {1423--1431},
  issn = {1557-1939, 1557-1947},
  doi = {10.1007/s10948-016-3413-6},
  url = {http://link.springer.com/10.1007/s10948-016-3413-6},
  urldate = {2023-11-06},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Investigation_of_Reflectance_Properties_in_1D_Ternary_Annular_Photonic_Crystal_Srivastava_Aghajamali_2016.pdf}
}

@article{srivastavaStudyOpticalReflectance2016,
  title = {Study of Optical Reflectance Properties in {{1D}} Annular Photonic Crystal Containing Double Negative ({{DNG}}) Metamaterials},
  author = {Srivastava, Sanjeev K and Aghajamali, Alireza},
  date = {2016-05},
  journaltitle = {Physica B: Condensed Matter},
  volume = {489},
  pages = {67--72},
  issn = {09214526},
  doi = {10.1016/j.physb.2016.01.036},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0921452616300357},
  urldate = {2023-11-06},
  abstract = {Theoretical investigation of photonic band gaps or reflection bands in one-dimensional annular photonic crystal (APC) containing double negative (DNG) metamaterials and air has been presented. The proposed structure consists of the alternate layers of dispersive DNG material and air immersed in free space. In order to study photonic band gaps we obtain the reflectance spectrum of the annular PC by employing the transfer matrix method (TMM) in the cylindrical waves for both TE and TM polarizations. In this work we study the effect of azimuthal mode number (m) and starting radius (ρ0) on the three band gaps viz. zero averaged refractive index (zero- n ) gap, zero permittivity (zero-  ) and zero permeability (zero-  ) gaps. It is found that for m  1, zero-  gap appears in TE mode and zero-  gap appears in TM mode. The width of both zero-  and zero-  gap increases by increasing m values, but the enhancement of zero-  gap is more appreciable. Also, the effect of ρ0 on the three band gaps (reflection bands) of annular PC structure at the given m-number has been studied, for both TE and TM polarizations. The result shows that in both polarizations zero-  and zero-  gaps decreases when ρ0 increases, whereas zero- n gap remains invariant.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Study_of_optical_reflectance_properties_in_1D_annular_photonic_crystal_Srivastava_Aghajamali_2016.pdf}
}

@software{StabilityAIStablediffusion2024,
  title = {Stability-{{AI}}/Stablediffusion},
  date = {2024-12-16T09:10:23Z},
  origdate = {2022-11-23T23:59:50Z},
  url = {https://github.com/Stability-AI/stablediffusion},
  urldate = {2024-12-16},
  abstract = {High-Resolution Image Synthesis with Latent Diffusion Models},
  organization = {Stability AI}
}

@article{staceyElectricalImpedanceTomography,
  title = {Electrical {{Impedance Tomography}}},
  author = {Stacey, Robert W},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\EIDORS\Electrical_Impedance_Tomography_Stacey_.pdf}
}

@article{stephensIndexRefractionMagnesium1952,
  title = {Index of Refraction of Magnesium Oxide},
  author = {Stephens, R.E. and Malitson, I.H.},
  date = {1952-10},
  journaltitle = {J. RES. NATL. BUR. STAN.},
  volume = {49},
  number = {4},
  pages = {249},
  issn = {0091-0635},
  doi = {10.6028/jres.049.025},
  url = {https://nvlpubs.nist.gov/nistpubs/jres/049/jresv49n4p249_A1b.pdf},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Dielectric\Index_of_refraction_of_magnesium_oxide_Stephens_Malitson_1952.pdf}
}

@article{stolyarovMicrofluidicDirectionalEmission2012,
  title = {Microfluidic Directional Emission Control of an Azimuthally Polarized Radial Fibre Laser},
  author = {Stolyarov, Alexander M. and Wei, Lei and Shapira, Ofer and Sorin, Fabien and Chua, Song L. and Joannopoulos, John D. and Fink, Yoel},
  date = {2012-04},
  journaltitle = {Nature Photon},
  volume = {6},
  number = {4},
  pages = {229--233},
  issn = {1749-4885, 1749-4893},
  doi = {10.1038/nphoton.2012.24},
  url = {https://www.nature.com/articles/nphoton.2012.24},
  urldate = {2023-11-06},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Microfluidic_directional_emission_control_of_an_azimuthally_polarized_radial_Stolyarov_et_al_2012.pdf}
}

@online{sukhbaatarBranchTrainMiXMixingExpert2024,
  title = {Branch-{{Train-MiX}}: {{Mixing Expert LLMs}} into a {{Mixture-of-Experts LLM}}},
  shorttitle = {Branch-{{Train-MiX}}},
  author = {Sukhbaatar, Sainbayar and Golovneva, Olga and Sharma, Vasu and Xu, Hu and Lin, Xi Victoria and Rozière, Baptiste and Kahn, Jacob and Li, Daniel and Yih, Wen-tau and Weston, Jason and Li, Xian},
  date = {2024-03-12},
  eprint = {2403.07816},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.07816},
  urldate = {2024-09-22},
  abstract = {We investigate efficient methods for training Large Language Models (LLMs) to possess capabilities in multiple specialized domains, such as coding, math reasoning and world knowledge. Our method, named Branch-Train-MiX (BTX), starts from a seed model, which is branched to train experts in embarrassingly parallel fashion with high throughput and reduced communication cost. After individual experts are asynchronously trained, BTX brings together their feedforward parameters as experts in Mixture-of-Expert (MoE) layers and averages the remaining parameters, followed by an MoE-finetuning stage to learn token-level routing. BTX generalizes two special cases, the Branch-Train-Merge method, which does not have the MoE finetuning stage to learn routing, and sparse upcycling, which omits the stage of training experts asynchronously. Compared to alternative approaches, BTX achieves the best accuracy-efficiency tradeoff.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\MixtureOfExperts\Branch-Train-MiX_Sukhbaatar_et_al_2024.pdf}
}

@inproceedings{sullivanOptimalEntropyConstrained1994,
  title = {Optimal Entropy Constrained Scalar Quantization for Exponential and {{Laplacian}} Random Variables},
  booktitle = {Proceedings of {{ICASSP}} '94. {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}}},
  author = {Sullivan, G.J.},
  date = {1994-04},
  volume = {v},
  pages = {V/265-V/268 vol.5},
  issn = {1520-6149},
  doi = {10.1109/ICASSP.1994.389481},
  url = {https://ieeexplore.ieee.org/document/389481},
  urldate = {2024-05-13},
  abstract = {This paper presents solutions to the entropy-constrained scalar quantizer (ECSQ) design problem for two sources commonly encountered in image and speech compression applications: sources having exponential and Laplacian probability density functions. We obtain the optimal ECSQ either with or without an additional constraint on the number of levels in the quantizer. In contrast to prior methods, which require iterative solution of a large number of nonlinear equations, the new method needs only a single sequence of solutions to one-dimensional nonlinear equations (in some Laplacian cases, one additional two-dimensional solution is needed). As a result, the new method is orders of magnitude faster than prior ones. We also show that as the constraint on the number of levels in the quantizer is relaxed, the optimal ECSQ becomes a uniform threshold quantizer (UTQ) for exponential, but not for Laplacian sources.{$<>$}},
  eventtitle = {Proceedings of {{ICASSP}} '94. {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}}},
  keywords = {Design methodology,Design optimization,Entropy,Image coding,Iterative methods,Laplace equations,Nonlinear equations,Quantization,Random variables,Speech},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataCompression\Quantization\Optimal_entropy_constrained_scalar_quantization_for_exponential_and_Laplacian_Sullivan_1994.pdf}
}

@article{sullivanOverviewHighEfficiency2012,
  title = {Overview of the {{High Efficiency Video Coding}} ({{HEVC}}) {{Standard}}},
  author = {Sullivan, Gary J. and Ohm, Jens-Rainer and Han, Woo-Jin and Wiegand, Thomas},
  date = {2012-12},
  journaltitle = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {22},
  number = {12},
  pages = {1649--1668},
  issn = {1558-2205},
  doi = {10.1109/TCSVT.2012.2221191},
  url = {https://ieeexplore.ieee.org/abstract/document/6316136},
  urldate = {2024-11-21},
  abstract = {High Efficiency Video Coding (HEVC) is currently being prepared as the newest video coding standard of the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goal of the HEVC standardization effort is to enable significantly improved compression performance relative to existing standards-in the range of 50\% bit-rate reduction for equal perceptual video quality. This paper provides an overview of the technical features and characteristics of the HEVC standard.},
  eventtitle = {{{IEEE Transactions}} on {{Circuits}} and {{Systems}} for {{Video Technology}}},
  keywords = {Advanced video coding (AVC),H.264,High Efficiency Video Coding (HEVC),ISO standards,Joint Collaborative Team on Video Coding (JCT-VC),Moving Picture Experts Group (MPEG),MPEG 4 Standard,MPEG standards,MPEG-4,standards,Video coding,Video Coding Experts Group (VCEG),video compression,Video compression},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\VideoCodec\Overview_of_the_High_Efficiency_Video_Coding_(HEVC)_Standard_Sullivan_et_al_2012.pdf}
}

@article{sunACnerfEnhancementNeural2024,
  title = {{{ACnerf}}: Enhancement of Neural Radiance Field by Alignment and Correction of Pose to Reconstruct New Views from a Single x-Ray*},
  shorttitle = {{{ACnerf}}},
  author = {Sun, Mengcheng and Zhu, Yu and Li, Hangyu and Ye, Jiongyao and Li, Nan},
  date = {2024-02},
  journaltitle = {Phys. Med. Biol.},
  volume = {69},
  number = {4},
  pages = {045016},
  publisher = {IOP Publishing},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/ad1d6c},
  url = {https://dx.doi.org/10.1088/1361-6560/ad1d6c},
  urldate = {2024-08-20},
  abstract = {Objective. Computed tomography (CT) is widely used in medical research and clinical diagnosis. However, acquiring CT data requires patients to be exposed to considerable ionizing radiance, leading to physical harm. Recent studies have considered using neural radiance field (NERF) techniques to infer the full-view CT projections from single-view x-ray projection, thus aiding physician judgment and reducing Radiance hazards. This paper enhances this technique in two directions: (1) accurate generalization capabilities for control models. (2) Consider different ranges of viewpoints. Approach. Building upon generative radiance fields (GRAF), we propose a method called ACnerf to enhance the generalization of the NERF through alignment and pose correction. ACnerf aligns with a reference single x-ray by utilizing a combination of positional encoding with Gaussian random noise (latent code) obtained from GRAF training. This approach avoids compromising the 3D structure caused by altering the generator. During inference, a pose judgment network is employed to correct the pose and optimize the rendered viewpoint. Additionally, when generating a narrow range of views, ACnerf employs frequency-domain regularization to fine-tune the generator and achieve precise projections. Main results. The proposed ACnerf method surpasses the state-of-the-art NERF technique in terms of rendering quality for knee and chest data with varying contrasts. It achieved an average improvement of 2.496 dB in PSNR and 41\% in LPIPS for 0°–360° projections. Additionally, for −15° to 15° projections, ACnerf achieved an average improvement of 0.691 dB in PSNR and 25.8\% in LPIPS. Significance. With adjustments in alignment, inference, and rendering range, our experiments and evaluations on knee and chest data of different contrasts show that ACnerf effectively reduces artifacts and aberrations in the new view. ACnerf’s ability to recover more accurate 3D structures from single x-rays has excellent potential for reducing damage from ionising radiation in clinical diagnostics.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Xray\ACnerf_Sun_et_al_2024.pdf}
}

@inproceedings{sunApplicationMultichannelImpedance2021,
  title = {Application of {{Multi-channel Impedance Measurement Device}} in {{Teaching}} of "{{Signal Analysis}} and {{Processing}}"},
  booktitle = {2021 2nd {{International Conference}} on {{Artificial Intelligence}} and {{Education}} ({{ICAIE}})},
  author = {Sun, Jiangtao and Lu, Xupeng and Sun, Shijie and Wang, Rui and Xie, Yuedong},
  date = {2021-06},
  pages = {616--620},
  publisher = {IEEE},
  location = {Dali, China},
  doi = {10.1109/ICAIE53562.2021.00136},
  url = {https://ieeexplore.ieee.org/document/9534540/},
  urldate = {2024-07-08},
  eventtitle = {2021 2nd {{International Conference}} on {{Artificial Intelligence}} and {{Education}} ({{ICAIE}})},
  isbn = {978-1-66542-492-9},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Touch\Application_of_Multi-channel_Impedance_Measurement_Device_in_Teaching_of_Sun_et_al_2021.pdf}
}

@article{sunBlindQualityAssessment2023,
  title = {Blind {{Quality Assessment}} for In-the-{{Wild Images}} via {{Hierarchical Feature Fusion}} and {{Iterative Mixed Database Training}}},
  author = {Sun, Wei and Min, Xiongkuo and Tu, Danyang and Ma, Siwei and Zhai, Guangtao},
  date = {2023-11},
  journaltitle = {IEEE Journal of Selected Topics in Signal Processing},
  volume = {17},
  number = {6},
  pages = {1178--1192},
  issn = {1941-0484},
  doi = {10.1109/JSTSP.2023.3270621},
  url = {https://ieeexplore.ieee.org/abstract/document/10109108?casa_token=M9uHVAgF1LwAAAAA:ExP60LCZN8UE3NHf2zbtRGtrKlXtgKmOrX557dzynVaSMpBoYxD1fOMNiEY78izUxHNpmZ8oweo},
  urldate = {2025-01-07},
  abstract = {Image quality assessment (IQA) is very important for both end-users and service providers since a high-quality image can significantly improve the user's quality of experience (QoE) and also benefit lots of computer vision algorithms. Most existing blind image quality assessment (BIQA) models were developed for synthetically distorted images, however, they perform poorly on in-the-wild images, which are widely existed in various practical applications. In this article, we propose a novel BIQA model for in-the-wild images by addressing two critical problems in this field: how to learn better quality-aware feature representation, and how to solve the problem of insufficient training samples in terms of their content and distortion diversity. Considering that perceptual visual quality is affected by both low-level visual features (e.g. distortions) and high-level semantic information (e.g. content), we first propose a staircase structure to hierarchically integrate the features from intermediate layers into the final feature representation, which enables the model to make full use of visual information from low-level to high-level. Then an iterative mixed database training (IMDT) strategy is proposed to train the BIQA model on multiple databases simultaneously, so the model can benefit from the increase in both training samples and image content and distortion diversity and can learn a more general feature representation. Experimental results show that the proposed model outperforms other state-of-the-art BIQA models on six in-the-wild IQA databases by a large margin. Moreover, the proposed model shows an excellent performance in the cross-database evaluation experiments, which further demonstrates that the learned feature representation is robust to images with diverse distortions and content.},
  eventtitle = {{{IEEE Journal}} of {{Selected Topics}} in {{Signal Processing}}},
  keywords = {Authentic and synthetic distortion,blind image quality assessment,Databases,Distortion,Feature extraction,feature fusion,Image quality,in-the-wild images,mixed database training,Quality assessment,Solid modeling,Training,Visualization},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\Blind_Quality_Assessment_for_Sun_et_al_2023.pdf}
}

@article{sunImprovedTikhonovRegularization2019,
  title = {An {{Improved Tikhonov Regularization Method}} for {{Lung Cancer Monitoring Using Electrical Impedance Tomography}}},
  author = {Sun, Benyuan and Yue, Shihong and Hao, Zhenhua and Cui, Ziqiang and Wang, Huaxiang},
  date = {2019-04-15},
  journaltitle = {IEEE Sensors J.},
  volume = {19},
  number = {8},
  pages = {3049--3057},
  issn = {1530-437X, 1558-1748, 2379-9153},
  doi = {10.1109/JSEN.2019.2892179},
  url = {https://ieeexplore.ieee.org/document/8610098/},
  urldate = {2024-07-08},
  abstract = {Bedside monitoring plays an important role in the treatment of lung cancer. As a mostly used technique, X-ray computed tomography cannot provide medical surveillance for patients suffering from lung cancer in real-time. In comparison, the technique of electrical impedance tomography (EIT) has the potential to solve the issue by visualizing the human respiratory system; however, in most cases, its spatial resolution is too low to locate the real pulmonary lesions. One feasible method to improve the image quality is to incorporate the a priori information into the process of EIT imaging. In this paper, the conductivity distributions of lung tissues from a group of patients were extracted as the a priori information at first. Then, a novel EIT imaging method was proposed for lung cancer monitoring. A series of experiments indicated that the proposed method had potential capacity to identify lung cancer and monitor its metastasis. Besides, EIT can be further developed as a shortor long-term medical monitoring tool based on the proposed method.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\An_Improved_Tikhonov_Regularization_Method_for_Lung_Cancer_Monitoring_Using_Sun_et_al_2019.pdf}
}

@online{sunLearningLearnTest2024,
  title = {Learning to ({{Learn}} at {{Test Time}}): {{RNNs}} with {{Expressive Hidden States}}},
  shorttitle = {Learning to ({{Learn}} at {{Test Time}})},
  author = {Sun, Yu and Li, Xinhao and Dalal, Karan and Xu, Jiarui and Vikram, Arjun and Zhang, Genghan and Dubois, Yann and Chen, Xinlei and Wang, Xiaolong and Koyejo, Sanmi and Hashimoto, Tatsunori and Guestrin, Carlos},
  date = {2024-07-05},
  eprint = {2407.04620},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2407.04620},
  url = {http://arxiv.org/abs/2407.04620},
  urldate = {2024-08-06},
  abstract = {Self-attention performs well in long context but has quadratic complexity. Existing RNN layers have linear complexity, but their performance in long context is limited by the expressive power of their hidden state. We propose a new class of sequence modeling layers with linear complexity and an expressive hidden state. The key idea is to make the hidden state a machine learning model itself, and the update rule a step of self-supervised learning. Since the hidden state is updated by training even on test sequences, our layers are called Test-Time Training (TTT) layers. We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B parameters, comparing with a strong Transformer and Mamba, a modern RNN. Both TTT-Linear and TTT-MLP match or exceed the baselines. Similar to Transformer, they can keep reducing perplexity by conditioning on more tokens, while Mamba cannot after 16k context. With preliminary systems optimization, TTT-Linear is already faster than Transformer at 8k context and matches Mamba in wall-clock time. TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\StateSpaceModels\Learning_to_(Learn_at_Test_Time)_Sun_et_al_2024.pdf}
}

@article{sunModalPropertiesModal2007,
  title = {Modal Properties and Modal Control in Vertically Emitting Annular {{Bragg}} Lasers},
  author = {Sun, Xiankai and Yariv, Amnon},
  date = {2007},
  journaltitle = {Opt. Express},
  volume = {15},
  number = {25},
  pages = {17323},
  issn = {1094-4087},
  doi = {10.1364/OE.15.017323},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-15-25-17323},
  urldate = {2023-11-06},
  abstract = {The modal properties, including the resonant vertical radiation, of a type of laser structures based on the annular Bragg resonance (ABR) are studied in detail. The modal threshold gains and the resonance frequencies of such lasers are obtained from the derived governing characteristic equation. Two kinds of ABR lasers, one with a π/2 phase shift in the outer grating and the other without, are analyzed. It is numerically demonstrated that, it’s possible to get a large-area, high-efficiency, single defect mode lasing in ABR lasers if we choose the kind without a π/2 phase shift in the outer grating and also a device size smaller than a critical value.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Modal_properties_and_modal_control_in_vertically_emitting_annular_Bragg_lasers_Sun_Yariv_2007.pdf}
}

@online{sunNeuralPBIRReconstructionShape2024,
  title = {Neural-{{PBIR Reconstruction}} of {{Shape}}, {{Material}}, and {{Illumination}}},
  author = {Sun, Cheng and Cai, Guangyan and Li, Zhengqin and Yan, Kai and Zhang, Cheng and Marshall, Carl and Huang, Jia-Bin and Zhao, Shuang and Dong, Zhao},
  date = {2024-02-01},
  eprint = {2304.13445},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.13445},
  url = {http://arxiv.org/abs/2304.13445},
  urldate = {2024-06-12},
  abstract = {Reconstructing the shape and spatially varying surface appearances of a physical-world object as well as its surrounding illumination based on 2D images (e.g., photographs) of the object has been a long-standing problem in computer vision and graphics. In this paper, we introduce an accurate and highly efficient object reconstruction pipeline combining neural based object reconstruction and physics-based inverse rendering (PBIR). Our pipeline firstly leverages a neural SDF based shape reconstruction to produce high-quality but potentially imperfect object shape. Then, we introduce a neural material and lighting distillation stage to achieve high-quality predictions for material and illumination. In the last stage, initialized by the neural predictions, we perform PBIR to refine the initial results and obtain the final high-quality reconstruction of object shape, material, and illumination. Experimental results demonstrate our pipeline significantly outperforms existing methods quality-wise and performance-wise.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Materials\Neural-PBIR_Reconstruction_of_Shape,_Material,_and_Illumination_Sun_et_al_22.pdf}
}

@online{sunNeuralReconRealTimeCoherent2021,
  title = {{{NeuralRecon}}: {{Real-Time Coherent 3D Reconstruction}} from {{Monocular Video}}},
  shorttitle = {{{NeuralRecon}}},
  author = {Sun, Jiaming and Xie, Yiming and Chen, Linghao and Zhou, Xiaowei and Bao, Hujun},
  date = {2021-04-01},
  eprint = {2104.00681},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2104.00681},
  urldate = {2024-02-20},
  abstract = {We present a novel framework named NeuralRecon for real-time 3D scene reconstruction from a monocular video. Unlike previous methods that estimate single-view depth maps separately on each key-frame and fuse them later, we propose to directly reconstruct local surfaces represented as sparse TSDF volumes for each video fragment sequentially by a neural network. A learning-based TSDF fusion module based on gated recurrent units is used to guide the network to fuse features from previous fragments. This design allows the network to capture local smoothness prior and global shape prior of 3D surfaces when sequentially reconstructing the surfaces, resulting in accurate, coherent, and real-time surface reconstruction. The experiments on ScanNet and 7-Scenes datasets show that our system outperforms state-of-the-art methods in terms of both accuracy and speed. To the best of our knowledge, this is the first learning-based system that is able to reconstruct dense coherent 3D geometry in real-time.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\SDF\NeuralRecon_Sun_et_al_2021.pdf}
}

@article{sunNewLinearBack2015,
  title = {A New Linear Back Projection Algorithm to Electrical Tomography Based on Measuring Data Decomposition},
  author = {Sun, Benyuan and Yue, Shihong and Cui, Ziqiang and Wang, Huaxiang},
  date = {2015-12-01},
  journaltitle = {Meas. Sci. Technol.},
  volume = {26},
  number = {12},
  pages = {125402},
  issn = {0957-0233, 1361-6501},
  doi = {10.1088/0957-0233/26/12/125402},
  url = {https://iopscience.iop.org/article/10.1088/0957-0233/26/12/125402},
  urldate = {2024-07-08},
  abstract = {As an advanced measurement technique of non-radiant, non-intrusive, rapid response, and low cost, the electrical tomography (ET) technique has developed rapidly in recent decades. The ET imaging algorithm plays an important role in the ET imaging process. Linear back projection (LBP) is the most used ET algorithm due to its advantages of dynamic imaging process, real-time response, and easy realization. But the LBP algorithm is of low spatial resolution due to the natural ‘soft field’ effect and ‘ill-posed solution’ problems; thus its applicable ranges are greatly limited. In this paper, an original data decomposition method is proposed, and every ET measuring data are decomposed into two independent new data based on the positive and negative sensing areas of the measuring data. Consequently, the number of total measuring data is extended to twice as many as the number of the original data, thus effectively reducing the ‘ill-posed solution’. On the other hand, an index to measure the ‘soft field’ effect is proposed. The index shows that the decomposed data can distinguish between different contributions of various units (pixels) for any ET measuring data, and can efficiently reduce the ‘soft field’ effect of the ET imaging process. In light of the data decomposition method, a new linear back projection algorithm is proposed to improve the spatial resolution of the ET image. A series of simulations and experiments are applied to validate the proposed algorithm by the real-time performances and the progress of spatial resolutions.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\linearBackProjection\A_new_linear_back_projection_algorithm_to_electrical_tomography_based_on_Sun_et_al_2015.pdf}
}

@article{sunPropagationSurfaceAcoustic2006,
  title = {Propagation of Surface Acoustic Waves through Sharply Bent Two-Dimensional Phononic Crystal Waveguides Using a Finite-Difference Time-Domain Method},
  author = {Sun, Jia-Hong and Wu, Tsung-Tsong},
  date = {2006-11-30},
  journaltitle = {Phys. Rev. B},
  volume = {74},
  number = {17},
  pages = {174305},
  issn = {1098-0121, 1550-235X},
  doi = {10.1103/PhysRevB.74.174305},
  url = {https://link.aps.org/doi/10.1103/PhysRevB.74.174305},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\2DPhononicCrystals\Propagation_of_surface_acoustic_waves_through_sharply_bent_two-dimensional_Sun_Wu_2006.pdf}
}

@inproceedings{suvorovResolutionRobustLargeMask2022,
  title = {Resolution-{{Robust Large Mask Inpainting With Fourier Convolutions}}},
  author = {Suvorov, Roman and Logacheva, Elizaveta and Mashikhin, Anton and Remizova, Anastasia and Ashukha, Arsenii and Silvestrov, Aleksei and Kong, Naejin and Goka, Harshith and Park, Kiwoong and Lempitsky, Victor},
  date = {2022},
  pages = {2149--2159},
  url = {https://openaccess.thecvf.com/content/WACV2022/html/Suvorov_Resolution-Robust_Large_Mask_Inpainting_With_Fourier_Convolutions_WACV_2022_paper.html},
  urldate = {2024-12-06},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\FourierConvolutions\Resolution-Robust_Large_Mask_Inpainting_With_Fourier_Convolutions_Suvorov_et_al_2022.pdf}
}

@book{suzukiSuzukiViolinSchool1995,
  title = {Suzuki {{Violin School}}, {{Vol}} 1: {{Violin Part}}},
  shorttitle = {Suzuki {{Violin School}}, {{Vol}} 1},
  author = {Suzuki, Shinichi},
  date = {1995-04-01},
  edition = {Revised edition},
  publisher = {Alfred Music},
  abstract = {Teach violin with the popular Suzuki Violin School. The Suzuki Method(R) of Talent Education is based on Shinichi Suzuki's view that every child is born with ability, and that people are the product of their environment. According to Shinichi Suzuki, a world-renowned violinist and teacher, the greatest joy an adult can know comes from developing a child's potential so he/she can express all that is harmonious and best in human beings. Students are taught using the mother-tongue" approach. Each series of books for a particular instrument in the Suzuki Method is considered a Suzuki music school, such as the Suzuki Violin School. Suzuki lessons are generally given in a private studio setting with additional group lessons. The student listens to the recordings and works with their Suzuki violin teacher to develop their potential as a musician and as a person. This Suzuki book is integral for Suzuki violin lessons. This revised edition of the Suzuki Violin School, Volume 1 features: * Revised editing of pieces, including bowings and fingerings * 16 additional pages * Additional exercises, some from Shinichi Suzuki, plus additional insight and suggestions for teachers * Text in English, French, German, and Spanish * Musical notation guide * Fingerboard position. Titles: Principles of Study and Guidance * Twinkle, Twinkle, Little Star Variations (Suzuki) * Lightly Row (Folk Song) * Song of the Wind (Folk Song) * Go Tell Aunt Rhody (Folk Song) * O Come, Little Children (Folk Song) * May Song (Folk Song) * Long, Long Ago (Bayly) * Allegro (Suzuki) * Perpetual Motion (Suzuki) * Allegretto (Suzuki) * Andantino (Suzuki) * Etude (Suzuki) * Minuet 1, Minuett III from Suite in G Minor for Klavier, BWV 822 (Bach) * Minuet 2, Minuet, BWV Anh. II 116 from Notebook for Anna Magdalena Bach (Bach) * Minuet 3, Minuet BWV Anh. II 114/Anh. III 183 (Bach) * The Happy Farmer from Album for the Young, Op. 68, No. 10 (Schumann) * Gavotte (Gossec). For a complete list of the most recent printings by AMPV number, go to alfred.com/suzuki. This title is available in MakeMusic Cloud. The International editions include an updated title page that designates the book as the International Edition."},
  isbn = {978-0-7579-0061-7},
  langid = {english},
  pagetotal = {48},
  file = {C:\Users\ahmed\OneDrive\Research\Physics\Audio\Suzuki_Violin_School,_Vol_1_Suzuki_1995.pdf}
}

@article{szilagyiNeuralNetworksComplex,
  title = {Neural {{Networks}} with {{Complex Activations}} and {{Connection Weights}}},
  author = {Szilagyi, Miklos N},
  abstract = {T he concept of neural networks is generalized to include complex connections between complex units. A math emat ical model is presented. An expression for t he network's energy as well as a complex learning rule are proposed. Th is innovation may lead to new neural network paradigms, architectures, and applications, and may help to better understand biological nervous systems. T he similarity between the dynamics of some linear complex networks and the quantum mechanical behavior of at omic systems is shown. The convergence properties of two-neuron complex networks are explored as extensions of the neural descript ion of the Mandelbrot set , and are found to possess similar fractal propert ies.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\AI\Components\ActivationFunction\ComplexNumbers\Neural_Networks_with_Complex_Szilagyi_.pdf}
}

@inproceedings{tancikLearnedInitializationsOptimizing2021,
  title = {Learned {{Initializations}} for {{Optimizing Coordinate-Based Neural Representations}}},
  booktitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Tancik, Matthew and Mildenhall, Ben and Wang, Terrance and Schmidt, Divi and Srinivasan, Pratul P. and Barron, Jonathan T. and Ng, Ren},
  date = {2021-06},
  pages = {2845--2854},
  publisher = {IEEE},
  location = {Nashville, TN, USA},
  doi = {10.1109/CVPR46437.2021.00287},
  url = {https://ieeexplore.ieee.org/document/9578751/},
  urldate = {2024-12-06},
  abstract = {Coordinate-based neural representations have shown significant promise as an alternative to discrete, arraybased representations for complex low dimensional signals. However, optimizing a coordinate-based network from randomly initialized weights for each new signal is inefficient. We propose applying standard meta-learning algorithms to learn the initial weight parameters for these fully-connected networks based on the underlying class of signals being represented (e.g., images of faces or 3D models of chairs). Despite requiring only a minor change in implementation, using these learned initial weights enables faster convergence during optimization and can serve as a strong prior over the signal class being modeled, resulting in better generalization when only partial observations of a given signal are available. We explore these benefits across a variety of tasks, including representing 2D images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D image observations.},
  eventtitle = {2021 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66544-509-2},
  langid = {english},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Components\\HyperparameterOptimization\\Initialization\\Learned_Initializations_for_Optimizing_Coordinate-Based_Neural_Representations_Tancik_et_al_2021.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Components\\HyperparameterOptimization\\Initialization\\Learned_Initializations_for_Optimizing_Coordinate-Based_Neural_Representations_Tancik_et_al_22.pdf}
}

@inproceedings{tancikNerfstudioModularFramework2023,
  title = {Nerfstudio: {{A Modular Framework}} for {{Neural Radiance Field Development}}},
  shorttitle = {Nerfstudio},
  booktitle = {Special {{Interest Group}} on {{Computer Graphics}} and {{Interactive Techniques Conference Conference Proceedings}}},
  author = {Tancik, Matthew and Weber, Ethan and Ng, Evonne and Li, Ruilong and Yi, Brent and Kerr, Justin and Wang, Terrance and Kristoffersen, Alexander and Austin, Jake and Salahi, Kamyar and Ahuja, Abhik and McAllister, David and Kanazawa, Angjoo},
  date = {2023-07-23},
  eprint = {2302.04264},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1--12},
  doi = {10.1145/3588432.3591516},
  url = {http://arxiv.org/abs/2302.04264},
  urldate = {2023-09-05},
  abstract = {Neural Radiance Fields (NeRF) are a rapidly growing area of research with wide-ranging applications in computer vision, graphics, robotics, and more. In order to streamline the development and deployment of NeRF research, we propose a modular PyTorch framework, Nerfstudio. Our framework includes plug-and-play components for implementing NeRF-based methods, which make it easy for researchers and practitioners to incorporate NeRF into their projects. Additionally, the modular design enables support for extensive real-time visualization tools, streamlined pipelines for importing captured in-the-wild data, and tools for exporting to video, point cloud and mesh representations. The modularity of Nerfstudio enables the development of Nerfacto, our method that combines components from recent papers to achieve a balance between speed and quality, while also remaining flexible to future modifications. To promote community-driven development, all associated code and data are made publicly available with open-source licensing at https://nerf.studio.},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\General\Nerfstudio_Tancik_et_al_2023.pdf}
}

@article{tanElectricalImpedanceTomography,
  title = {Electrical {{Impedance Tomography}} for {{Internal Radiation Therapy}}},
  author = {Tan, Hao Chen},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\Electrical_Impedance_Tomography_for_Internal_Radiation_Therapy_Tan_.pdf}
}

@article{tanElectricalImpedanceTomography2021,
  title = {Electrical {{Impedance Tomography}} for {{Robot-Aided Internal Radiation Therapy}}},
  author = {Tan, Hao and Rossa, Carlos},
  date = {2021-06-21},
  journaltitle = {Front. Bioeng. Biotechnol.},
  volume = {9},
  pages = {698038},
  issn = {2296-4185},
  doi = {10.3389/fbioe.2021.698038},
  url = {https://www.frontiersin.org/articles/10.3389/fbioe.2021.698038/full},
  urldate = {2024-07-08},
  abstract = {High dose rate brachytherapy (HDR) is an internal based radiation treatment for prostate cancer. The treatment can deliver radiation to the site of dominant tumor growth within the prostate. Imaging methods to delineate the dominant tumor are imperative to ensure the maximum success of HDR. This paper investigates the feasibility of using electrical impedance tomography (EIT) as the main imaging modality during robot-aided internal radiation therapy. A procedure utilizing brachytherapy needles in order to perform EIT for the purpose of robot-aided prostate cancer imaging is proposed. It is known that cancerous tissue exhibits different conductivity than healthy tissue. Using this information, it is hypothesized that a conductivity map of the tissue can be used to locate and delineate cancerous nodules via EIT. Multiple experiments were conducted using eight brachytherapy needle electrodes. Observations indicate that the imaging procedure is able to observe differences in tissue conductivity in a setting that approximates transperineal HDR and confirm that brachytherapy needles can be used as electrodes for this purpose. The needles can access the tissue at a specific depth that traditional EIT surface electrodes cannot. The results indicate the feasibility of using brachytherapy needles for EIT for the purpose internal radiation therapy.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Cancer\Electrical_Impedance_Tomography_for_Robot-Aided_Internal_Radiation_Therapy_Tan_Rossa_2021.pdf}
}

@article{tanOpticalFiberSensor2016,
  title = {Optical Fiber Sensor Based on {{Bloch}} Surface Wave in Photonic Crystals},
  author = {Tan, Xiao-Jie and Zhu, Xiao-Song},
  date = {2016-07-11},
  journaltitle = {Opt. Express},
  volume = {24},
  number = {14},
  pages = {16016},
  issn = {1094-4087},
  doi = {10.1364/OE.24.016016},
  url = {https://opg.optica.org/abstract.cfm?URI=oe-24-14-16016},
  urldate = {2023-11-06},
  abstract = {A new optical fiber sensor based on Bloch surface wave was theoretically proposed. An omnidirectional one-dimensional photonic crystal was designed as the multilayer coated on the outer surface of the optical fiber. Taking advantages of the omnidirectional reflection band, there is only surface mode resonance in the transmission spectrum, while guided mode resonance is avoided. The performance of the designed fiber sensor was analyzed theoretically with a ray transmission model. The presented sensor has comparable sensitivity but much higher figure of merit than other fiber sensors. The resolution can reach about 10−6 RIU or even higher.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\Optical_fiber_sensor_based_on_Bloch_surface_wave_in_photonic_crystals_Tan_Zhu_2016.pdf}
}

@article{tatianFittingRefractiveindexData1984,
  title = {Fitting Refractive-Index Data with the {{Sellmeier}} Dispersion Formula},
  author = {Tatian, Berge},
  date = {1984-12-15},
  journaltitle = {Appl. Opt.},
  volume = {23},
  number = {24},
  pages = {4477},
  issn = {0003-6935, 1539-4522},
  doi = {10.1364/AO.23.004477},
  url = {https://opg.optica.org/abstract.cfm?URI=ao-23-24-4477},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\FittingRefractiveIndex\Fitting_refractive-index_data_with_the_Sellmeier_dispersion_formula_Tatian_1984.pdf}
}

@book{taubmanJPEG2000ImageCompression2002,
  title = {{{JPEG2000 Image Compression Fundamentals}}, {{Standards}} and {{Practice}}},
  author = {Taubman, David S. and Marcellin, Michael W.},
  date = {2002},
  publisher = {Springer US},
  location = {Boston, MA},
  doi = {10.1007/978-1-4615-0799-4},
  url = {http://link.springer.com/10.1007/978-1-4615-0799-4},
  urldate = {2024-03-06},
  isbn = {978-1-4613-5245-7 978-1-4615-0799-4},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataCompression\ImageComperssion\JPEG2000_Image_Compression_Fundamentals,_Standards_and_Practice_Taubman_Marcellin_2002.pdf}
}

@article{tesslerMaskedMimicUnifiedPhysicsBased,
  title = {{{MaskedMimic}}: {{Unified Physics-Based Character Control Through Masked Motion Inpainting}}},
  author = {Tessler, Chen and Guo, Yunrong and Nabati, Ofir and Chechik, Gal and Peng, Xue Bin},
  volume = {43},
  number = {6},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\Motion\MaskedMimic_Tessler_et_al_.pdf}
}

@online{theisLossyImageCompression2017a,
  title = {Lossy {{Image Compression}} with {{Compressive Autoencoders}}},
  author = {Theis, Lucas and Shi, Wenzhe and Cunningham, Andrew and Huszár, Ferenc},
  date = {2017-03-01},
  eprint = {1703.00395},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1703.00395},
  url = {http://arxiv.org/abs/1703.00395},
  urldate = {2024-08-08},
  abstract = {We propose a new approach to the problem of optimizing autoencoders for lossy image compression. New media formats, changing hardware technology, as well as diverse requirements and content types create a need for compression algorithms which are more flexible than existing codecs. Autoencoders have the potential to address this need, but are difficult to optimize directly due to the inherent non-differentiabilty of the compression loss. We here show that minimal changes to the loss are sufficient to train deep autoencoders competitive with JPEG 2000 and outperforming recently proposed approaches based on RNNs. Our network is furthermore computationally efficient thanks to a sub-pixel architecture, which makes it suitable for high-resolution images. This is in contrast to previous work on autoencoders for compression using coarser approximations, shallower architectures, computationally expensive methods, or focusing on small images.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Lossy_Image_Compression_with_Theis_et_al_2017.pdf}
}

@book{thomasPragmaticProgrammer20th2019,
  title = {The Pragmatic Programmer, 20th Anniversary Edition: Journey to Mastery},
  shorttitle = {The Pragmatic Programmer, 20th Anniversary Edition},
  author = {Thomas, David and Hunt, Andrew},
  date = {2019},
  edition = {Second edition},
  publisher = {Addison-Wesley},
  location = {Boston},
  abstract = {"Straight from the trenches, The Pragmatic Programmer, 20th Anniversary Edition, cuts through the increasing specialization and technicalities of modern software development to examine the core process: transforming a requirement into working, maintainable code that delights users. Extensively updated with ten new sections and major revisions throughout, this edition covers topics ranging from career development to architectural techniques for keeping code flexible, adaptable, and reusable. The Pragmatic Programmer illustrates today's best practices and major pitfalls of many different aspects of software development. Whether you're a new coder, an experienced programmer, or a manager responsible for software projects, applying this guide's lessons will help you rapidly improve your productivity, quality, and job satisfaction"--},
  isbn = {978-0-13-595705-9},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\Programming\The_pragmatic_programmer,_20th_anniversary_edition_Thomas_Hunt_2019.pdf}
}

@article{thormahlenRefractiveIndexWater1985,
  title = {Refractive {{Index}} of {{Water}} and {{Its Dependence}} on {{Wavelength}}, {{Temperature}}, and {{Density}}},
  author = {Thormählen, I. and Straub, J. and Grigull, U.},
  date = {1985-10-01},
  journaltitle = {Journal of Physical and Chemical Reference Data},
  volume = {14},
  number = {4},
  pages = {933--945},
  issn = {0047-2689, 1529-7845},
  doi = {10.1063/1.555743},
  url = {https://pubs.aip.org/jpr/article/14/4/933/241382/Refractive-Index-of-Water-and-Its-Dependence-on},
  urldate = {2023-09-05},
  abstract = {A survey of the available experimental data and the existing equations for the refractive index of water is given. The dependence of the molar refraction on wavelength, temperature, and density is shown over an extended range. Based upon the electromagnetic theory of light an equation for the refractive index of water with wavelength, temperature, and density as independent variables is constructed. Its coefficients are directly deduced from all available experimental data by least-squares fit. The range of validity of wavelength is restricted by the theory for normal dispersion to 182 nm≤λ≤2770 nm. The range of temperature and density is given by the available experimental data. Interpolations between the single measured points are possible and the following range of validity can be recommended: for temperature −10\,°C≤T≤500\,°C and for density 0.0028 kg/m3 ≤ρ≤1045 kg/m3. Good agreement exists between the new relation, the available experimental data, and several existing equations.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Refractive_Index_of_Water_and_Its_Dependence_on_Wavelength,_Temperature,_and_Thormahlen_et_al_1985.pdf}
}

@incollection{tomczakDeepGenerativeModeling2024,
  title = {Deep {{Generative Modeling}} for {{Neural Compression}}},
  booktitle = {Deep {{Generative Modeling}}},
  author = {Tomczak, Jakub M.},
  editor = {Tomczak, Jakub M.},
  date = {2024},
  pages = {259--275},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-64087-2_10},
  url = {https://doi.org/10.1007/978-3-031-64087-2_10},
  urldate = {2024-12-23},
  abstract = {In December 2020, Facebook reported having around 1.8 billion daily active users and around 2.8 billion monthly active users (Facebook reports fourth quarter and full year 2020 results, 2020.). Assuming that users uploaded, on average, a single photo each day, the resulting volume of data would give a very rough (let me stress it, a very rough) estimate of around 3000 TB of new images per day. This single case of Facebook alone already shows us the potential great costs associated with storing and transmitting data. In the digital era, we can simply say this: efficient and effective manner of handling data (i.e., faster and smaller) means more money in the pocket.},
  isbn = {978-3-031-64087-2},
  langid = {english},
  keywords = {Entropy coding,JPEG,Neural compression},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Deep_Generative_Modeling_for_Tomczak_2024.pdf}
}

@incollection{tomczakWhyDeepGenerative2024,
  title = {Why {{Deep Generative Modeling}}?},
  booktitle = {Deep {{Generative Modeling}}},
  author = {Tomczak, Jakub M.},
  editor = {Tomczak, Jakub M.},
  date = {2024},
  pages = {1--13},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-64087-2_1},
  url = {https://doi.org/10.1007/978-3-031-64087-2_1},
  urldate = {2024-12-23},
  abstract = {Before we start thinking about (deep) generative modeling, let us consider a simple example. Imagine we have trained a deep neural network that classifies images (x∈ℤD\$\$\textbackslash mathbf \{x\} \textbackslash in \textbackslash mathbb \{Z\}\textasciicircum\{D\}\$\$) of animals (y∈Y\$\$y \textbackslash in \textbackslash mathcal \{Y\}\$\$, and Y=\{cat,dog,horse\}\$\$\textbackslash mathcal \{Y\} = \textbackslash\{cat, dog, horse\textbackslash\}\$\$). Further, let us assume that this neural network is trained really well so that it always classifies a proper class with a high probability p(y|x). So far so good, right? The problem could occur though. As pointed out in [1], adding noise to images could result in completely false classification. An example of such a situation is presented in Fig. 1.1 where adding noise could shift predicted probabilities of labels; however, the image is barely changed (at least to us, human beings).},
  isbn = {978-3-031-64087-2},
  langid = {english},
  keywords = {Decision-making,Generative modeling},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Why_Deep_Generative_Modeling_Tomczak_2024.pdf}
}

@online{townsendPracticalLosslessCompression2019,
  title = {Practical {{Lossless Compression}} with {{Latent Variables}} Using {{Bits Back Coding}}},
  author = {Townsend, James and Bird, Tom and Barber, David},
  date = {2019-01-15},
  eprint = {1901.04866},
  eprinttype = {arXiv},
  eprintclass = {cs, math, stat},
  doi = {10.48550/arXiv.1901.04866},
  url = {http://arxiv.org/abs/1901.04866},
  urldate = {2024-08-13},
  abstract = {Deep latent variable models have seen recent success in many data domains. Lossless compression is an application of these models which, despite having the potential to be highly useful, has yet to be implemented in a practical manner. We present `Bits Back with ANS' (BB-ANS), a scheme to perform lossless compression with latent variable models at a near optimal rate. We demonstrate this scheme by using it to compress the MNIST dataset with a variational auto-encoder model (VAE), achieving compression rates superior to standard methods with only a simple VAE. Given that the scheme is highly amenable to parallelization, we conclude that with a sufficiently high quality generative model this scheme could be used to achieve substantial improvements in compression rate with acceptable running time. We make our implementation available open source at https://github.com/bits-back/bits-back .},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Theory,Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Compression\LosslessCompression\Practical_Lossless_Townsend_et_al_2019.pdf}
}

@online{TrueColorKodak,
  title = {True {{Color Kodak Images}}},
  url = {https://r0k.us/graphics/kodak/},
  urldate = {2024-12-06},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\datasets\True_Color_Kodak_Images_.html}
}

@article{tzu-chyangkingMagneticFieldDependenceEffective2013,
  title = {Magnetic-{{Field Dependence}} of {{Effective Plasma Frequency}} for a {{Plasma Photonic Crystal}}},
  author = {{Tzu-Chyang King} and {Wen-Kai Kuo} and {Tzong-Jer Yang} and {Tingting Bian} and {Chien-Jang Wu}},
  date = {2013-02},
  journaltitle = {IEEE Photonics J.},
  volume = {5},
  number = {1},
  pages = {4700110--4700110},
  issn = {1943-0655},
  doi = {10.1109/JPHOT.2013.2241417},
  url = {http://ieeexplore.ieee.org/document/6415966/},
  urldate = {2024-01-22},
  abstract = {The effective plasma frequency in a photonic crystal (PC) is defined as the lowest frequency at which electromagnetic wave can start to propagate through the PC. In this paper, we theoretically investigate the effective plasma frequency fp;eff for a magnetized 1-D plasma PC (PPC). The PPC is made of two constituents, i.e., the plasma and the dielectric material like quartz. The effective plasma frequency in a PPC is obtained based on the calculated photonic band structure (PBS). It is found that fp;eff can be controlled by the externally applied static magnetic field, namely, fp;eff decreases significantly as the static magnetic field increases. This suggests that the plasma layer in a PPC shows a dielectriclike behavior when the magnetic field is applied. In addition, in the presence of static magnetic field, fp;eff will be increased as a function of electron density and thickness of the plasma layer. In the angular dependence of effective plasma frequency, we find that fp;eff is a decreasing function of angle of incidence in the absence of the static magnetic field. However, it becomes an increasing function of angle of incidence when the static magnetic field is applied. Finally, the effect of filling factor of the plasma layer is also illustrated.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Magnetic-Field_Dependence_of_Effective_Plasma_Frequency_for_a_Plasma_Photonic_Tzu-Chyang_King_et_al_2013.pdf}
}

@article{uhlmannElectricalImpedanceTomography2009,
  title = {Electrical Impedance Tomography and {{Calderón}}'s Problem},
  author = {Uhlmann, G},
  date = {2009-12-01},
  journaltitle = {Inverse Problems},
  volume = {25},
  number = {12},
  pages = {123011},
  issn = {0266-5611, 1361-6420},
  doi = {10.1088/0266-5611/25/12/123011},
  url = {https://iopscience.iop.org/article/10.1088/0266-5611/25/12/123011},
  urldate = {2024-07-03},
  abstract = {We survey mathematical developments in the inverse method of electrical impedance tomography which consists in determining the electrical properties of a medium by making voltage and current measurements at the boundary of the medium. In the mathematical literature, this is also known as Caldero´n’s problem from Caldero´n’s pioneer contribution (Caldero´n 1980 Seminar on Numerical Analysis and its Applications to Continuum Physics (R´ıo de Janeiro, 1980) p 65 (Soc. Brasil. Mat.)). We concentrate this review around the topic of complex geometrical optics solutions that have led to many advances in the field. In the last section, we review some counterexamples to Caldero´n’s problems that have attracted a lot of interest because of connections with cloaking and invisibility.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Review\Electrical_impedance_tomography_and_Calderon's_problem_Uhlmann_2009.pdf}
}

@online{underwoodUnderstandingEffectivenessLossy2024,
  title = {Understanding {{The Effectiveness}} of {{Lossy Compression}} in {{Machine Learning Training Sets}}},
  author = {Underwood, Robert and Calhoun, Jon C. and Di, Sheng and Cappello, Franck},
  date = {2024-03-23},
  eprint = {2403.15953},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.15953},
  url = {http://arxiv.org/abs/2403.15953},
  urldate = {2024-08-19},
  abstract = {Learning and Artificial Intelligence (ML/AI) techniques have become increasingly prevalent in high performance computing (HPC). However, these methods depend on vast volumes of floating point data for training and validation which need methods to share the data on a wide area network (WAN) or to transfer it from edge devices to data centers. Data compression can be a solution to these problems, but an in-depth understanding of how lossy compression affects model quality is needed. Prior work largely considers a single application or compression method. We designed a systematic methodology for evaluating data reduction techniques for ML/AI, and we use it to perform a very comprehensive evaluation with 17 data reduction methods on 7 ML/AI applications to show modern lossy compression methods can achieve a 50-100x compression ratio improvement for a 1\% or less loss in quality. We identify critical insights that guide the future use and design of lossy compressors for ML/AI.},
  pubstate = {prepublished},
  keywords = {C.4,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,E.2,I.2.6},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\Data Compression\Understanding_The_Effectiveness_of_Lossy_Compression_in_Machine_Learning_Underwood_et_al_2024.pdf}
}

@article{valentineOpticalCloakMade2009,
  title = {An Optical Cloak Made of Dielectrics},
  author = {Valentine, Jason and Li, Jensen and Zentgraf, Thomas and Bartal, Guy and Zhang, Xiang},
  date = {2009-07},
  journaltitle = {Nature Mater},
  volume = {8},
  number = {7},
  pages = {568--571},
  issn = {1476-1122, 1476-4660},
  doi = {10.1038/nmat2461},
  url = {https://www.nature.com/articles/nmat2461},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\An_optical_cloak_made_of_dielectrics_Valentine_et_al_2009.pdf}
}

@article{valentineThreedimensionalOpticalMetamaterial2008,
  title = {Three-Dimensional Optical Metamaterial with a Negative Refractive Index},
  author = {Valentine, Jason and Zhang, Shuang and Zentgraf, Thomas and Ulin-Avila, Erick and Genov, Dentcho A. and Bartal, Guy and Zhang, Xiang},
  date = {2008-09},
  journaltitle = {Nature},
  volume = {455},
  number = {7211},
  pages = {376--379},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature07247},
  url = {https://www.nature.com/articles/nature07247},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Three-dimensional_optical_metamaterial_with_a_negative_refractive_index_Valentine_et_al_2008.pdf}
}

@article{vanderplasPythonDataScience,
  title = {Python {{Data Science Handbook}}},
  author = {VanderPlas, Jake},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataScience\Tools\Python_Data_Science_Handbook_VanderPlas_.pdf}
}

@book{vandevoordeTemplatesCompleteGuide2018,
  title = {C++ Templates: The Complete Guide},
  shorttitle = {C++ Templates},
  author = {Vandevoorde, David and Josuttis, Nicolai M. and Gregor, Douglas},
  date = {2018},
  edition = {Second edition},
  publisher = {Addison-Wesley},
  location = {Boston},
  abstract = {Templates are among the most powerful features of C++, but they are too often neglected, misunderstood, and misused. C++ Templates: The Complete Guide provides software architects and engineers with a clear understanding of why, when, and how to use templates to build and maintain cleaner, faster, and smarter software more efficiently. C++ Templates begins with an insightful tutorial on basic concepts and language features. The remainder of the book serves as a comprehensive reference, focusing first on language details, then on a wide range of coding techniques, and finally on advanced applications for templates. Examples used throughout the book illustrate abstract concepts and demonstrate best practices. Readers learn: The exact behaviors of templates -- How to avoid the pitfalls associated with templates -- Idioms and techniques, from the basic to the previously undocumented -- How to reuse source code without threatening performance or safety -- How to increase the efficiency of C++ programs -- How to produce more flexible and maintainable software -- This practical guide shows programmers how to exploit the full power of the template features in C++. -- Provided by publisher},
  isbn = {978-0-321-71412-1},
  langid = {english},
  pagetotal = {788},
  keywords = {C++ (Computer program language),Microsoft Visual C++,Standard template library},
  annotation = {OCLC: on1004498065},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\Programming\C++_templates_Vandevoorde_et_al_2018.pdf}
}

@misc{vauhkonenElectrical_impedance_tomography_and_prior_information1997,
  title = {Electrical\_impedance\_tomography\_and\_prior\_information},
  author = {Vauhkonen},
  date = {1997},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Books\Electrical_impedance_tomography_and_prior_information_Vauhkonen_1997.pdf}
}

@article{vauhkonenTikhonovRegularizationPrior1998,
  title = {Tikhonov Regularization and Prior Information in Electrical Impedance Tomography},
  author = {Vauhkonen, M. and Vadasz, D. and Karjalainen, P.A. and Somersalo, E. and Kaipio, J.P.},
  date = {1998-04},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {17},
  number = {2},
  pages = {285--293},
  issn = {02780062},
  doi = {10.1109/42.700740},
  url = {http://ieeexplore.ieee.org/document/700740/},
  urldate = {2024-07-08},
  abstract = {The solution of impedance distribution in electrical impedance tomography is a nonlinear inverse problem that requires the use of a regularization method. The generalized Tikhonov regularization methods have been popular in the solution of many inverse problems. The regularization matrices that are usually used with the Tikhonov method are more or less ad hoc and the implicit prior assumptions are, thus, in many cases inappropriate. In this paper, we propose an approach to the construction of the regularization matrix that conforms to the prior assumptions on the impedance distribution. The approach is based on the construction of an approximating subspace for the expected impedance distributions. It is shown by simulations that the reconstructions obtained with the proposed method are better than with two other schemes of the same type when the prior is compatible with the true object. On the other hand, when the prior is incompatible with the true object, the method will still give reasonable estimates.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\TikhonovRegularization\Tikhonov_regularization_and_prior_information_in_electrical_impedance_tomography_Vauhkonen_et_al_1998.pdf}
}

@article{velascoNumericalResolutionElectrical,
  title = {Numerical {{Resolution}} of the {{Electrical Impedance Tomography Inverse Problem}} with {{Fixed Inclusions}}},
  author = {Velasco, Arrianne Crystal and Darbas, Marion and Mendoza, Renier},
  abstract = {Electrical Impedance Tomography or EIT is an imaging technique that reconstructs the conductivity distribution in the interior of an object using electric currents. In this paper, we study the continuum model for EIT in a domain where the geometric inclusions are fixed and only the conductivity values inside these inclusions are unknown. We show analytically and numerically how the BroydenFletcher-Goldfarb-Shanno (BFGS) algorithm, a quasi-Newton method, can be effective in solving this inverse conductivity problem for EIT.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\AnalysisOfEIT\Resolution\Numerical_Resolution_of_the_Electrical_Impedance_Tomography_Inverse_Problem_Velasco_et_al_.pdf}
}

@article{vermaOpticalAcousticProperties2018,
  title = {Optical and {{Acoustic Properties}} of {{Binary Mixtures}} of {{Butanol Isomers}} as {{Oxygenates}} with {{Cyclohexane}}, {{Benzene}} and {{Toluene}} at 308.15 {{K}}},
  author = {Verma, Sweety and Gahlyan, Suman and Rani, Manju and Maken, Sanjeev},
  date = {2018-10-01},
  journaltitle = {Korean Chemical Engineering Research},
  volume = {56},
  number = {5},
  pages = {663--678},
  doi = {10.9713/KCER.2018.56.5.663},
  url = {https://doi.org/10.9713/KCER.2018.56.5.663},
  urldate = {2023-09-05},
  abstract = {Refractive index and speeds of sound for the binary mixture of isomer of butanol (1) + cyclohexane, benzene and toluene (2) were measured at 308.15 K. The measured data were used to calculate deviation in refractive index Δn, ultrasonic speed Δu, isentropic compressibility KsE, available volume Va, excess intermolecular free length Lf and molecular association MA. All the derived properties were correlated with polynomial equation. Ultrasonic speed data were predicted using various empirical correlations like Nomoto, van Dael, impedance dependence and theoretically with Schaaff’s collision factor theory (CFT). Jacobson free length theory (FLT) was used to calculate Lf. The measured refractive index was also correlated with various mixing rules. The deviation in refractive index Δn and ultrasonic speed Δu was used to determine the intermolecular interactions.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Optical_and_Acoustic_Properties_of_Binary_Mixtures_of_Butanol_Isomers_as_Verma_et_al_2018.pdf}
}

@article{vicarCellSegmentationMethods2019,
  title = {Cell Segmentation Methods for Label-Free Contrast Microscopy: Review and Comprehensive Comparison},
  shorttitle = {Cell Segmentation Methods for Label-Free Contrast Microscopy},
  author = {Vicar, Tomas and Balvan, Jan and Jaros, Josef and Jug, Florian and Kolar, Radim and Masarik, Michal and Gumulec, Jaromir},
  date = {2019-06-28},
  journaltitle = {BMC Bioinformatics},
  volume = {20},
  number = {1},
  pages = {360},
  issn = {1471-2105},
  doi = {10.1186/s12859-019-2880-8},
  url = {https://doi.org/10.1186/s12859-019-2880-8},
  urldate = {2024-06-21},
  abstract = {Because of its non-destructive nature, label-free imaging is an important strategy for studying biological processes. However, routine microscopic techniques like phase contrast or DIC suffer from shadow-cast artifacts making automatic segmentation challenging. The aim of this study was to compare the segmentation efficacy of published steps of segmentation work-flow (image reconstruction, foreground segmentation, cell detection (seed-point extraction) and cell (instance) segmentation) on a dataset of the same cells from multiple contrast microscopic modalities.},
  keywords = {Cell segmentation,Differential contrast image,Image reconstruction,Laplacian of Gaussians,Methods comparison,Microscopy,Quantitative phase imaging},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\ComputerVision\ImageSegmentation\Cell_segmentation_methods_for_Vicar_et_al_2019.pdf}
}

@article{vitoLearningExamplesInverse,
  title = {Learning from {{Examples}} as an {{Inverse Problem}}},
  author = {Vito, Ernesto De},
  abstract = {Many works related learning from examples to regularization techniques for inverse problems, emphasizing the strong algorithmic and conceptual analogy of certain learning algorithms with regularization algorithms. In particular it is well known that regularization schemes such as Tikhonov regularization can be effectively used in the context of learning and are closely related to algorithms such as support vector machines. Nevertheless the connection with inverse problem was considered only for the discrete (finite sample) problem and the probabilistic aspects of learning from examples were not taken into account. In this paper we provide a natural extension of such analysis to the continuous (population) case and study the interplay between the discrete and continuous problems. From a theoretical point of view, this allows to draw a clear connection between the consistency approach in learning theory and the stability convergence property in ill-posed inverse problems. The main mathematical result of the paper is a new probabilistic bound for the regularized least-squares algorithm. By means of standard results on the approximation term, the consistency of the algorithm easily follows.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\General\Learning_from_Examples_as_an_Inverse_Problem_Vito_.pdf}
}

@article{vogtBiologicallyRelevantPhotoacoustic2016,
  title = {Biologically Relevant Photoacoustic Imaging Phantoms with Tunable Optical and Acoustic Properties},
  author = {Vogt, William C. and Jia, Congxian and Wear, Keith A. and Garra, Brian S. and Joshua Pfefer, T.},
  date = {2016-02-17},
  journaltitle = {J. Biomed. Opt},
  volume = {21},
  number = {10},
  pages = {101405},
  issn = {1083-3668},
  doi = {10.1117/1.JBO.21.10.101405},
  url = {http://biomedicaloptics.spiedigitallibrary.org/article.aspx?doi=10.1117/1.JBO.21.10.101405},
  urldate = {2023-09-05},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\BioMaterial\Biologically_relevant_photoacoustic_imaging_phantoms_with_tunable_optical_and_Vogt_et_al_2016.pdf}
}

@article{vurturbadarinathMachineLearningApproach2021,
  title = {A {{Machine Learning Approach}} as a {{Surrogate}} for a {{Finite Element Analysis}}: {{Status}} of {{Research}} and {{Application}} to {{One Dimensional Systems}}},
  shorttitle = {A {{Machine Learning Approach}} as a {{Surrogate}} for a {{Finite Element Analysis}}},
  author = {Vurtur Badarinath, Poojitha and Chierichetti, Maria and Davoudi Kakhki, Fatemeh},
  date = {2021-02-27},
  journaltitle = {Sensors},
  volume = {21},
  number = {5},
  pages = {1654},
  issn = {1424-8220},
  doi = {10.3390/s21051654},
  url = {https://www.mdpi.com/1424-8220/21/5/1654},
  urldate = {2024-07-03},
  abstract = {Current maintenance intervals of mechanical systems are scheduled a priori based on the life of the system, resulting in expensive maintenance scheduling, and often undermining the safety of passengers. Going forward, the actual usage of a vehicle will be used to predict stresses in its structure, and therefore, to define a specific maintenance scheduling. Machine learning (ML) algorithms can be used to map a reduced set of data coming from real-time measurements of a structure into a detailed/high-fidelity finite element analysis (FEA) model of the same system. As a result, the FEA-based ML approach will directly estimate the stress distribution over the entire system during operations, thus improving the ability to define ad-hoc, safe, and efficient maintenance procedures. The paper initially presents a review of the current state-of-the-art of ML methods applied to finite elements. A surrogate finite element approach based on ML algorithms is also proposed to estimate the time-varying response of a one-dimensional beam. Several ML regression models, such as decision trees and artificial neural networks, have been developed, and their performance is compared for direct estimation of the stress distribution over a beam structure. The surrogate finite element models based on ML algorithms are able to estimate the response of the beam accurately, with artificial neural networks providing more accurate results.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\MLP\A_Machine_Learning_Approach_as_a_Surrogate_for_a_Finite_Element_Analysis_Vurtur_Badarinath_et_al_2021.pdf}
}

@article{vuyeTemperatureDependenceDielectric1993,
  title = {Temperature Dependence of the Dielectric Function of Silicon Using in Situ Spectroscopic Ellipsometry},
  author = {Vuye, G. and Fisson, S. and Nguyen Van, V. and Wang, Y. and Rivory, J. and Abelès, F.},
  date = {1993-10},
  journaltitle = {Thin Solid Films},
  volume = {233},
  number = {1-2},
  pages = {166--170},
  issn = {00406090},
  doi = {10.1016/0040-6090(93)90082-Z},
  url = {https://linkinghub.elsevier.com/retrieve/pii/004060909390082Z},
  urldate = {2023-09-05},
  abstract = {Silicon substrates are widely used for the optical study of transparent materials such as oxides, fluorides, etc., because of the large difference between the indices of refraction of the film and the substrate. Optimal conditions for growth of dielectric films require high substrate temperatures, and hence a good knowledge of the temperature dependence of the dielectric function of silicon. In the present study, the complex dielectric function of Si [111] was determined in the 1.5-4.7 eV spectral range from room temperature up to 450 °C, from measurements of the ellipsometric parameters tan \textasciitilde{} and cos A performed in ultra-high vacuum on silicon wafers covered with their native oxide, with a rotating polariser spectroscopic ellipsometer. A two-boundary model was used to account for the oxide layer. In the fundamental absorption spectral region, the major effect of temperature on the dielectric function is a shift and a broadening of the structures associated with critical points, in agreement with the literature. In the transparency region, the real part of the index of refraction is found to vary linearly with temperature for energies lower than \textasciitilde{} 3 eV. Using this set of data as a reference, the temperature of a silicon substrate can be deduced from ellipsometric measurements in the 20-450 \textasciitilde 'C range with good accuracy ( + 3 'C).},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Semiconductor\Temperature_dependence_of_the_dielectric_function_of_silicon_using_in_situ_Vuye_et_al_1993.pdf}
}

@inproceedings{wangCLIPNeRFTextandImageDriven2022,
  title = {{{CLIP-NeRF}}: {{Text-and-Image Driven Manipulation}} of {{Neural Radiance Fields}}},
  shorttitle = {{{CLIP-NeRF}}},
  author = {Wang, Can and Chai, Menglei and He, Mingming and Chen, Dongdong and Liao, Jing},
  date = {2022},
  pages = {3835--3844},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Wang_CLIP-NeRF_Text-and-Image_Driven_Manipulation_of_Neural_Radiance_Fields_CVPR_2022_paper.html},
  urldate = {2023-07-28},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\TextAndImage\CLIP-NeRF_Wang_et_al_2022.pdf}
}

@online{wangComprehensiveSurveyContinual2024,
  title = {A {{Comprehensive Survey}} of {{Continual Learning}}: {{Theory}}, {{Method}} and {{Application}}},
  shorttitle = {A {{Comprehensive Survey}} of {{Continual Learning}}},
  author = {Wang, Liyuan and Zhang, Xingxing and Su, Hang and Zhu, Jun},
  date = {2024-02-06},
  eprint = {2302.00487},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.00487},
  urldate = {2024-04-26},
  abstract = {To cope with real-world dynamics, an intelligent system needs to incrementally acquire, update, accumulate, and exploit knowledge throughout its lifetime. This ability, known as continual learning, provides a foundation for AI systems to develop themselves adaptively. In a general sense, continual learning is explicitly limited by catastrophic forgetting, where learning a new task usually results in a dramatic performance degradation of the old tasks. Beyond this, increasingly numerous advances have emerged in recent years that largely extend the understanding and application of continual learning. The growing and widespread interest in this direction demonstrates its realistic significance as well as complexity. In this work, we present a comprehensive survey of continual learning, seeking to bridge the basic settings, theoretical foundations, representative methods, and practical applications. Based on existing theoretical and empirical results, we summarize the general objectives of continual learning as ensuring a proper stability-plasticity trade-off and an adequate intra/inter-task generalizability in the context of resource efficiency. Then we provide a state-of-the-art and elaborated taxonomy, extensively analyzing how representative methods address continual learning, and how they are adapted to particular challenges in realistic applications. Through an in-depth discussion of promising directions, we believe that such a holistic perspective can greatly facilitate subsequent exploration in this field and beyond.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Strategies\ContinualLearning\A_Comprehensive_Survey_of_Continual_Learning_Wang_et_al_2024.pdf}
}

@article{wangConductivityCharacteristicsHuman2022,
  title = {Conductivity Characteristics of Human Lung Tissues},
  author = {Wang, Yaru and Yue, Shihong and Chen, Jun and Li, Qi},
  date = {2022-01},
  journaltitle = {Int J Imaging Syst Tech},
  volume = {32},
  number = {1},
  pages = {178--191},
  issn = {0899-9457, 1098-1098},
  doi = {10.1002/ima.22607},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/ima.22607},
  urldate = {2024-07-08},
  abstract = {In the treatment of lung cancer, bedside monitoring plays an important role. X-ray computed tomography, as a mostly used technique, cannot provide medical surveillance for lung cancer patients in real-time. In comparison, electrical impedance tomography (EIT) has the potential to solve the issue by visualizing human respiratory system; however, its spatial resolution is too low to locate the real pulmonary lesions. One feasible method is to incorporate priori information into the process of EIT imaging. This study aims to investigate the conductivity characteristics of human lung tissues as priori information. First, the impedance spectra of human lung tissues in surgical operation were measured in time in a measurement system. Then, two- and three-dimensional lung models were established. Finally, the conductivity distribution models of cancerous and normal lung tissues were established. Overall, the conductivity of left lung was larger than that of right lung; the conductivity of lower lobe was larger in left lung, whereas the conductivity of upper lobe was larger in right lung. When tissues became cancerous, the conductivity increased by 33.5\% on average, and by 34.8 and 31.4\% in the left and right lung, respectively. The conductivity in left lung changed more obviously; and it changed more obviously in posterior basal segment of lower lobe in left lung, as well as at apex in right lung. These conclusions can lay the foundation for the further research of improving the spatial resolution of EIT for lung cancer monitoring.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Cancer\Conductivity_characteristics_of_human_lung_tissues_Wang_et_al_2022.pdf}
}

@article{wangDataPreprocessingMethods2020,
  title = {Data Preprocessing Methods for Electrical Impedance Tomography: A Review},
  shorttitle = {Data Preprocessing Methods for Electrical Impedance Tomography},
  author = {Wang, Zeying and Yue, Shihong and Wang, Huaxiang and Wang, Yanqiu},
  date = {2020-09-01},
  journaltitle = {Physiol. Meas.},
  volume = {41},
  number = {9},
  pages = {09TR02},
  issn = {0967-3334, 1361-6579},
  doi = {10.1088/1361-6579/abb142},
  url = {https://iopscience.iop.org/article/10.1088/1361-6579/abb142},
  urldate = {2024-07-03},
  abstract = {Objective: Electrical impedance tomography (EIT) is a promising measurement technique in applications, especially in industrial monitoring and clinical diagnosis. However, two major drawbacks exist that limit the spatial resolution of reconstructed EIT images, i.e. the ‘soft field’ effect and the ill-posed problem. In recent years, apart from the development of reconstruction algorithms, some preprocessing methods for measured data or sensitivity maps have also been proposed to reduce these negative effects. It is necessary to find the optimal preprocessing method for various EIT reconstruction algorithms. Approach: In this paper, seven typical data preprocessing methods for EIT are reviewed. The image qualities obtained using these methods are evaluated and compared in simulations, and their applicable ranges and combination effects are summarized. Main results: The results show that all the reviewed methods can enhance the quality of EIT reconstructed images to different extents, and there is an optimal one under any given reconstruction algorithm. In addition, most of the reviewed methods do not work well when using the Tikhonov regularization algorithm. Significance: This paper introduces the preprocessing method to EIT, and the quality of reconstructed images obtained using these methods is evaluated through simulations. The results can provide a reference for practical applications.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Review\Data_preprocessing_methods_for_electrical_impedance_tomography_Wang_et_al_2020.pdf}
}

@inproceedings{wangEITImageReconstruction2021,
  title = {{{EIT Image Reconstruction Method Based}} on {{DnCNN}}},
  booktitle = {2021 {{IEEE International Instrumentation}} and {{Measurement Technology Conference}} ({{I2MTC}})},
  author = {Wang, Qi and Zhang, Hanyu and Zhang, Ronghua and Li, Xiuyan and Wang, Jianming and Duan, Xiaojie},
  date = {2021-05-17},
  pages = {1--5},
  publisher = {IEEE},
  location = {Glasgow, United Kingdom},
  doi = {10.1109/I2MTC50364.2021.9459865},
  url = {https://ieeexplore.ieee.org/document/9459865/},
  urldate = {2024-07-03},
  abstract = {The inverse problem of Electrical Impedance Tomography (EIT) is a highly ill-posed nonlinear problem. In order to obtain reconstructed images with good edge preservation, a DnCNN deep imaging method is proposed, which consists of a pre-reconstruction step and a denoising convolutional neural network (DnCNN) block. Tikhonov method is used to obtain a rough reconstruction. A single residual unit is used in DnCNN to predict the noise mapping in the pre-reconstruction result and recover a high-quality reconstructed image. The reconstruction results show that the DnCNN method proposed can effectively remove artifacts in the reconstructed image and accurately recover the position and edge of multiple target objects contained in the field. For the robust samples and the noise-added samples, the proposed method exhibits excellent anti-noise ability and generalization ability.},
  eventtitle = {2021 {{IEEE International Instrumentation}} and {{Measurement Technology Conference}} ({{I2MTC}})},
  isbn = {978-1-72819-539-1},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\EIT_Image_Reconstruction_Method_Based_on_DnCNN_Wang_et_al_2021.pdf}
}

@article{wangEnsembleLearningBasedRateDistortion2021,
  title = {Ensemble {{Learning-Based Rate-Distortion Optimization}} for {{End-to-End Image Compression}}},
  author = {Wang, Yefei and Liu, Dong and Ma, Siwei and Wu, Feng and Gao, Wen},
  date = {2021-03},
  journaltitle = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {31},
  number = {3},
  pages = {1193--1207},
  issn = {1558-2205},
  doi = {10.1109/TCSVT.2020.3000331},
  url = {https://ieeexplore.ieee.org/abstract/document/9109567?casa_token=IZO8k1tJj98AAAAA:P8tFP3ObeWWoMMdaJtEVyxbT3LqsYQmmyvMH6-4Wa9q_nOlYeVm0qyLWay79cK0_LlAi5o3Tgg},
  urldate = {2024-11-26},
  abstract = {End-to-end image compression using trained deep networks as encoding/decoding models has been developed substantially in the recent years. Previous work is limited in using a single encoding/decoding model, whereas we explore the usage of multiple encoding/decoding models as an ensemble. We propose several methods to obtain multiple models. First, we adopt the boosting strategy to train multiple networks with diversity as an ensemble. Second, we train an ensemble of multiple probability distribution models to reduce the distribution gap for efficient entropy coding. Third, we present a geometric transform-based self-ensemble method. The multiple models can be regarded as the multiple coding modes, similar to those in non-deep video coding schemes. We further adopt block-level model/mode selection at the encoder side to pursue rate-distortion optimization, where we use hierarchical block partitioning to improve the adaptation ability. Compared with single-model end-to-end compression, our proposed method improves the compression efficiency significantly, leading to 21\% BD-rate reduction on the Kodak dataset, without increasing the decoding complexity. On the other hand, when keeping the same compression efficiency, our method can use much simplified decoding models, where the floating-point operations are reduced by 70\%.},
  eventtitle = {{{IEEE Transactions}} on {{Circuits}} and {{Systems}} for {{Video Technology}}},
  keywords = {Adaptation models,Decoding,Ensemble learning,Entropy coding,Image coding,image compression,Optimization,Rate-distortion,rate-distortion optimization,Transforms},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Ensemble_Learning-Based_Wang_et_al_2021.pdf}
}

@article{wangFlexibleImageGuidedShape2022,
  title = {A {{Flexible Image-Guided Shape Reconstruction Framework}} for {{Electrical Impedance Tomography}}},
  author = {Wang, Yu and Dong, Feng and Ren, Shangjie},
  date = {2022},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {71},
  pages = {1--13},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2022.3218515},
  url = {https://ieeexplore.ieee.org/document/9933839/},
  urldate = {2024-07-05},
  abstract = {Electrical impedance tomography (EIT) owns the advantages of safety, high temporal resolution, and functional imaging characteristics, thus is considered a promising medical/industrial imaging modality. However, due to the ill-posedness of its inverse problem, the spatial resolution of EIT is low, which greatly impeded its practical applications. A flexible image-guided inclusion boundary reconstruction (IGBR) framework for EIT is proposed to alleviate the problem. A statistical inverse problem framework for IGBR is established to directly reconstruct the inclusion boundary and the corresponding conductivity distribution. The morphology prior information is extracted from the images obtained from other high-resolution modes and is used to guide the boundary reconstruction (BR) process in the form of a conditional probability model. A series of simulation and experimental studies are carried out for different application backgrounds. The lung EIT imaging guided by computerized tomography (CT) image and EIT inclusion detection guided by B-ultrasound image is simulated and analyzed, respectively. The results show that the proposed method has high applicability to prior images of different modes. It not only achieves high-precision shape reconstruction but also high-precision conductivity estimation under the guidance of accurate prior images. Meanwhile, the proposed method has high robustness to the possible influence of noise in prior images or incomplete structural information. Even if the information in the prior image is biased or incomplete, the proposed method can still achieve high precision boundary reconstruction and conductivity estimation. The results of quantitative analysis show that compared with the method without image prior, the proposed method has an average reduction of 70\% in area error (AE), while the conductivity estimation error is reduced by about five times on average.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\ImageGuidedShape\A_Flexible_Image-Guided_Shape_Reconstruction_Framework_for_Electrical_Impedance_Wang_et_al_2022.pdf}
}

@article{wangImageReconstructionAlgorithm2007,
  title = {An Image Reconstruction Algorithm Based on Total Variation with Adaptive Mesh Refinement for {{ECT}}},
  author = {Wang, Huaxiang and Tang, Lei and Cao, Zhang},
  date = {2007-10},
  journaltitle = {Flow Measurement and Instrumentation},
  volume = {18},
  number = {5-6},
  pages = {262--267},
  issn = {09555986},
  doi = {10.1016/j.flowmeasinst.2007.07.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0955598607000520},
  urldate = {2024-07-03},
  abstract = {In this paper, a robust image reconstruction algorithm for electrical capacitance tomography (ECT) is proposed. The key feature of the algorithm is the use of adaptive mesh refinement based on total variation (TV) in solving the inverse problem. It keeps the edge preserving and scale-dependent properties of total variation regularization, and enhances the distinguishability by using adaptive mesh refinement. This strategy improves the spatial resolution efficiently with less calculation and is less underdetermined than uniform refinement. Simulation and experimental results show that the algorithm performs better than both standard Tikhonov regularization and the conventional total variation method.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\TotalVariation\An_image_reconstruction_algorithm_based_on_total_variation_with_adaptive_mesh_Wang_et_al_2007.pdf}
}

@article{wangImageSuperresolutionMethod2024,
  title = {Image Super-Resolution Method Based on Attention Aggregation Hierarchy Feature},
  author = {Wang, Jianxin and Zou, Yongsong and Wu, Honglin},
  date = {2024-04-01},
  journaltitle = {Vis Comput},
  volume = {40},
  number = {4},
  pages = {2655--2666},
  issn = {1432-2315},
  doi = {10.1007/s00371-023-02968-x},
  url = {https://doi.org/10.1007/s00371-023-02968-x},
  urldate = {2025-01-07},
  abstract = {Recently, single-image super-resolution (SISR) based on convolutional neural networks (CNNs) has encountered challenges, including the presence of numerous network parameters, limited receptive field, and the inability to capture global context information. In order to address these issues, we propose an image super-resolution method based on attention aggregation hierarchy feature (AHSR), which improves the performance of the super-resolution (SR) network through the optimization of convolutional operations and the integration of effective attention modules. AHSR first uses a high-frequency filter to bypass the rich low-frequency information, allowing the main network to focus on learning the high-frequency information. In order to aggregate spatial information within the image, expand the receptive field, and extract local structural features more effectively, we propose the utilization of the shift operation with zero parameters and zero triggers instead of spatial convolution. Additionally, we introduce a multi-Dconv head transposed attention module to improve the aggregation of cross-hierarchical feature information. This approach allows us to obtain enhanced features that incorporate contextual information. Extensive experimental results show that compared to other advanced SR models, the proposed AHSR method can better recover image details with fewer model parameters and less computational complexity.},
  langid = {english},
  keywords = {Artificial Intelligence,Attention mechanism,Hierarchical features,Shift operation,Super-resolution},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\Image_super-resolution_method_Wang_et_al_2024.pdf}
}

@article{wangInverseSolutionsElectrical2002,
  title = {Inverse Solutions for Electrical Impedance Tomography Based on Conjugate Gradients Methods},
  author = {Wang, M},
  date = {2002-01-01},
  journaltitle = {Meas. Sci. Technol.},
  volume = {13},
  number = {1},
  pages = {101--117},
  issn = {0957-0233, 1361-6501},
  doi = {10.1088/0957-0233/13/1/314},
  url = {https://iopscience.iop.org/article/10.1088/0957-0233/13/1/314},
  urldate = {2024-07-03},
  abstract = {A multistep inverse solution for two-dimensional electric field distribution is developed to deal with the nonlinear inverse problem of electric field distribution in relation to its boundary condition and the problem of divergence due to errors introduced by the ill-conditioned sensitivity matrix and the noise produced by electrode modelling and instruments. This solution is based on a normalized linear approximation method where the change in mutual impedance is derived from the sensitivity theorem and a method of error vector decomposition. This paper presents an algebraic solution of the linear equations at each inverse step, using a generalized conjugate gradients method. Limiting the number of iterations in the generalized conjugate gradients method controls the artificial errors introduced by the assumption of linearity and the ill-conditioned sensitivity matrix. The solution of the nonlinear problem is approached using a multistep inversion. This paper also reviews the mathematical and physical definitions of the sensitivity back-projection algorithm based on the sensitivity theorem. Simulations and discussion based on the multistep algorithm, the sensitivity coefficient back-projection method and the Newton–Raphson method are given. Examples of imaging gas–liquid mixing and a human hand in brine are presented.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\ConjugateGradient\Inverse_solutions_for_electrical_impedance_tomography_based_on_conjugate_Wang_2002.pdf}
}

@online{wangLEOGenerativeLatent2023,
  title = {{{LEO}}: {{Generative Latent Image Animator}} for {{Human Video Synthesis}}},
  shorttitle = {{{LEO}}},
  author = {Wang, Yaohui and Ma, Xin and Chen, Xinyuan and Dantcheva, Antitza and Dai, Bo and Qiao, Yu},
  date = {2023-10-11},
  eprint = {2305.03989},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.03989},
  urldate = {2024-04-04},
  abstract = {Spatio-temporal coherency is a major challenge in synthesizing high quality videos, particularly in synthesizing human videos that contain rich global and local deformations. To resolve this challenge, previous approaches have resorted to different features in the generation process aimed at representing appearance and motion. However, in the absence of strict mechanisms to guarantee such disentanglement, a separation of motion from appearance has remained challenging, resulting in spatial distortions and temporal jittering that break the spatio-temporal coherency. Motivated by this, we here propose LEO, a novel framework for human video synthesis, placing emphasis on spatio-temporal coherency. Our key idea is to represent motion as a sequence of flow maps in the generation process, which inherently isolate motion from appearance. We implement this idea via a flow-based image animator and a Latent Motion Diffusion Model (LMDM). The former bridges a space of motion codes with the space of flow maps, and synthesizes video frames in a warp-and-inpaint manner. LMDM learns to capture motion prior in the training data by synthesizing sequences of motion codes. Extensive quantitative and qualitative analysis suggests that LEO significantly improves coherent synthesis of human videos over previous methods on the datasets TaichiHD, FaceForensics and CelebV-HQ. In addition, the effective disentanglement of appearance and motion in LEO allows for two additional tasks, namely infinite-length human video synthesis, as well as content-preserving video editing.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\LEO_Wang_et_al_2023.pdf}
}

@online{wangNeRFNeuralRadiance2022,
  title = {{{NeRF--}}: {{Neural Radiance Fields Without Known Camera Parameters}}},
  shorttitle = {{{NeRF--}}},
  author = {Wang, Zirui and Wu, Shangzhe and Xie, Weidi and Chen, Min and Prisacariu, Victor Adrian},
  date = {2022-04-06},
  eprint = {2102.07064},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2102.07064},
  url = {http://arxiv.org/abs/2102.07064},
  urldate = {2023-07-28},
  abstract = {Considering the problem of novel view synthesis (NVS) from only a set of 2D images, we simplify the training process of Neural Radiance Field (NeRF) on forward-facing scenes by removing the requirement of known or pre-computed camera parameters, including both intrinsics and 6DoF poses. To this end, we propose NeRF\$--\$, with three contributions: First, we show that the camera parameters can be jointly optimised as learnable parameters with NeRF training, through a photometric reconstruction; Second, to benchmark the camera parameter estimation and the quality of novel view renderings, we introduce a new dataset of path-traced synthetic scenes, termed as Blender Forward-Facing Dataset (BLEFF); Third, we conduct extensive analyses to understand the training behaviours under various camera motions, and show that in most scenarios, the joint optimisation pipeline can recover accurate camera parameters and achieve comparable novel view synthesis quality as those trained with COLMAP pre-computed camera parameters. Our code and data are available at https://nerfmm.active.vision.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\CameraParameters\NeRF--_Wang_et_al_2022.pdf}
}

@inproceedings{wangNeuralDataDependentTransform2022,
  title = {Neural {{Data-Dependent Transform}} for {{Learned Image Compression}}},
  author = {Wang, Dezhao and Yang, Wenhan and Hu, Yueyu and Liu, Jiaying},
  date = {2022},
  pages = {17379--17388},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Neural_Data-Dependent_Transform_for_Learned_Image_Compression_CVPR_2022_paper.html},
  urldate = {2024-11-26},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Neural_Data-Dependent_Wang_et_al_2022.pdf}
}

@online{wangNeuralFieldsMeet2023,
  title = {Neural {{Fields}} Meet {{Explicit Geometric Representation}} for {{Inverse Rendering}} of {{Urban Scenes}}},
  author = {Wang, Zian and Shen, Tianchang and Gao, Jun and Huang, Shengyu and Munkberg, Jacob and Hasselgren, Jon and Gojcic, Zan and Chen, Wenzheng and Fidler, Sanja},
  date = {2023-04-06},
  eprint = {2304.03266},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.03266},
  urldate = {2023-09-05},
  abstract = {Reconstruction and intrinsic decomposition of scenes from captured imagery would enable many applications such as relighting and virtual object insertion. Recent NeRF based methods achieve impressive fidelity of 3D reconstruction, but bake the lighting and shadows into the radiance field, while mesh-based methods that facilitate intrinsic decomposition through differentiable rendering have not yet scaled to the complexity and scale of outdoor scenes. We present a novel inverse rendering framework for large urban scenes capable of jointly reconstructing the scene geometry, spatially-varying materials, and HDR lighting from a set of posed RGB images with optional depth. Specifically, we use a neural field to account for the primary rays, and use an explicit mesh (reconstructed from the underlying neural field) for modeling secondary rays that produce higher-order lighting effects such as cast shadows. By faithfully disentangling complex geometry and materials from lighting effects, our method enables photorealistic relighting with specular and shadow effects on several outdoor datasets. Moreover, it supports physics-based scene manipulations such as virtual object insertion with ray-traced shadow casting.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\MeshExtract\Neural_Fields_meet_Explicit_Geometric_Representation_for_Inverse_Rendering_of_Wang_et_al_2023.pdf}
}

@online{wangNeuralRenderingStereo2022,
  title = {Neural {{Rendering}} for {{Stereo 3D Reconstruction}} of {{Deformable Tissues}} in {{Robotic Surgery}}},
  author = {Wang, Yuehao and Long, Yonghao and Fan, Siu Hin and Dou, Qi},
  date = {2022-06-30},
  eprint = {2206.15255},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2206.15255},
  urldate = {2024-02-21},
  abstract = {Reconstruction of the soft tissues in robotic surgery from endoscopic stereo videos is important for many applications such as intra-operative navigation and image-guided robotic surgery automation. Previous works on this task mainly rely on SLAM-based approaches, which struggle to handle complex surgical scenes. Inspired by recent progress in neural rendering, we present a novel framework for deformable tissue reconstruction from binocular captures in robotic surgery under the single-viewpoint setting. Our framework adopts dynamic neural radiance fields to represent deformable surgical scenes in MLPs and optimize shapes and deformations in a learning-based manner. In addition to non-rigid deformations, tool occlusion and poor 3D clues from a single viewpoint are also particular challenges in soft tissue reconstruction. To overcome these difficulties, we present a series of strategies of tool mask-guided ray casting, stereo depth-cueing ray marching and stereo depth-supervised optimization. With experiments on DaVinci robotic surgery videos, our method significantly outperforms the current state-of-the-art reconstruction method for handling various complex non-rigid deformations. To our best knowledge, this is the first work leveraging neural rendering for surgical scene 3D reconstruction with remarkable potential demonstrated. Code is available at: https://github.com/med-air/EndoNeRF.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Endoscope\Neural_Rendering_for_Stereo_3D_Reconstruction_of_Deformable_Tissues_in_Robotic_Wang_et_al_2022.pdf}
}

@online{wangNeuSLearningNeural2023,
  title = {{{NeuS}}: {{Learning Neural Implicit Surfaces}} by {{Volume Rendering}} for {{Multi-view Reconstruction}}},
  shorttitle = {{{NeuS}}},
  author = {Wang, Peng and Liu, Lingjie and Liu, Yuan and Theobalt, Christian and Komura, Taku and Wang, Wenping},
  date = {2023-02-01},
  eprint = {2106.10689},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.10689},
  url = {http://arxiv.org/abs/2106.10689},
  urldate = {2024-02-20},
  abstract = {We present a novel neural surface reconstruction method, called NeuS, for reconstructing objects and scenes with high fidelity from 2D image inputs. Existing neural surface reconstruction approaches, such as DVR and IDR, require foreground mask as supervision, easily get trapped in local minima, and therefore struggle with the reconstruction of objects with severe self-occlusion or thin structures. Meanwhile, recent neural methods for novel view synthesis, such as NeRF and its variants, use volume rendering to produce a neural scene representation with robustness of optimization, even for highly complex objects. However, extracting high-quality surfaces from this learned implicit representation is difficult because there are not sufficient surface constraints in the representation. In NeuS, we propose to represent a surface as the zero-level set of a signed distance function (SDF) and develop a new volume rendering method to train a neural SDF representation. We observe that the conventional volume rendering method causes inherent geometric errors (i.e. bias) for surface reconstruction, and therefore propose a new formulation that is free of bias in the first order of approximation, thus leading to more accurate surface reconstruction even without the mask supervision. Experiments on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the state-of-the-arts in high-quality surface reconstruction, especially for objects and scenes with complex structures and self-occlusion.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\SDF\NeuS_Wang_et_al_2023.pdf}
}

@online{wangOneShotFreeViewNeural2021,
  title = {One-{{Shot Free-View Neural Talking-Head Synthesis}} for {{Video Conferencing}}},
  author = {Wang, Ting-Chun and Mallya, Arun and Liu, Ming-Yu},
  date = {2021-04-02},
  eprint = {2011.15126},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2011.15126},
  urldate = {2024-04-04},
  abstract = {We propose a neural talking-head video synthesis model and demonstrate its application to video conferencing. Our model learns to synthesize a talking-head video using a source image containing the target person’s appearance and a driving video that dictates the motion in the output. Our motion is encoded based on a novel keypoint representation, where the identity-specific and motion-related information is decomposed unsupervisedly. Extensive experimental validation shows that our model outperforms competing methods on benchmark datasets. Moreover, our compact keypoint representation enables a video conferencing system that achieves the same visual quality as the commercial H.264 standard while only using one-tenth of the bandwidth. Besides, we show our keypoint representation allows the user to rotate the head during synthesis, which is useful for simulating face-to-face video conferencing experiences. Our project page can be found at https://nvlabs.github.io/face-vid2vid.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\VideoCoding\One-Shot_Free-View_Neural_Talking-Head_Synthesis_for_Video_Conferencing_Wang_et_al_2021.pdf}
}

@online{wangSpacetime2DGaussian2024,
  title = {Space-Time {{2D Gaussian Splatting}} for {{Accurate Surface Reconstruction}} under {{Complex Dynamic Scenes}}},
  author = {Wang, Shuo and Huang, Binbin and Wang, Ruoyu and Gao, Shenghua},
  date = {2024-09-27},
  eprint = {2409.18852},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2409.18852},
  url = {http://arxiv.org/abs/2409.18852},
  urldate = {2024-10-24},
  abstract = {Previous surface reconstruction methods either suffer from low geometric accuracy or lengthy training times when dealing with real-world complex dynamic scenes involving multi-person activities, and human-object interactions. To tackle the dynamic contents and the occlusions in complex scenes, we present a space-time 2D Gaussian Splatting approach. Specifically, to improve geometric quality in dynamic scenes, we learn canonical 2D Gaussian splats and deform these 2D Gaussian splats while enforcing the disks of the Gaussian located on the surface of the objects by introducing depth and normal regularizers. Further, to tackle the occlusion issues in complex scenes, we introduce a compositional opacity deformation strategy, which further reduces the surface recovery of those occluded areas. Experiments on real-world sparse-view video datasets and monocular dynamic datasets demonstrate that our reconstructions outperform state-of-the-art methods, especially for the surface of the details. The project page and more visualizations can be found at: https://tb2-sy.github.io/st-2dgs/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\VedioCompression\Space-time_2D_Gaussian_Wang_et_al_2024.pdf}
}

@inproceedings{wangStudyConductivityDistribution2018,
  title = {Study on {{Conductivity Distribution}} of {{Human Lung}}},
  booktitle = {2018 13th {{World Congress}} on {{Intelligent Control}} and {{Automation}} ({{WCICA}})},
  author = {Wang, Yaru and Yue, Shihong},
  date = {2018-07},
  pages = {341--346},
  publisher = {IEEE},
  location = {Changsha, China},
  doi = {10.1109/WCICA.2018.8630378},
  url = {https://ieeexplore.ieee.org/document/8630378/},
  urldate = {2024-07-08},
  abstract = {This study is aim to analyze the conductivity data of cancerous tissues and normal tissues of human lung, establish the conductivity distribution model and investigate the conductivity characteristics of cancerous and normal tissues which provide the basic theory and reference data for medical research and clinical diagnosis of lung cancer. The lung cancer tissues and the normal tissues around the tumor from lung cancer patients were taken as specimens. Then the impedances of specimens were measured by impedance analyzer under the temperature and humidity at expected values. After calculating the conductivities of the specimens and determining the locations of the tumors, the conductivity distribution models of human cancerous and normal lung were established. As the excitation current frequency increases, the conductivity of the cancerous or normal tissue rises. And the conductivities of cancerous tissues are higher than that of normal tissues. For cancerous lung model, the conductivity of the left lung is higher than that of the right lung. While the contrary for normal lung model. There is a trend that the conductivity decreases from the upper lobe to the lower lobe of lung model.},
  eventtitle = {2018 13th {{World Congress}} on {{Intelligent Control}} and {{Automation}} ({{WCICA}})},
  isbn = {978-1-5386-7346-1},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Cancer\Study_on_Conductivity_Distribution_of_Human_Lung_Wang_Yue_2018.pdf}
}

@article{wangTransparentThermalInsulation2020,
  title = {Transparent Thermal Insulation Silica Aerogels},
  author = {Wang, Jieyu and Petit, Donald and Ren, Shenqiang},
  date = {2020},
  journaltitle = {Nanoscale Adv.},
  volume = {2},
  number = {12},
  pages = {5504--5515},
  issn = {2516-0230},
  doi = {10.1039/D0NA00655F},
  url = {http://xlink.rsc.org/?DOI=D0NA00655F},
  urldate = {2023-09-05},
  abstract = {This review explores the synthesis and properties of transparent thermal insulation silica aerogels.           ,                             Silica aerogels have received much attention due to their unique nanoporous networks, which consist of nanoscale connective silica particles and high-volume nanoscale pores. This lightweight superinsulation solid materials are synthesized by a ‘sol–gel’ process involving precursor preparation, gelation, aging and drying. By controlling their synthesis and processing, silica aerogels demonstrate good thermal and acoustic insulation, mechanical strength and optical transparency. In recent years, incorporating transparent and thermal insulation silica aerogels in energy-saving windows is of great interest for both scientific and technological applications. This review introduces the basic principles of thermal and optical properties of silica aerogels and highlights their tunability               via               synthetic and processing control. In addition, the use of silica aerogels in transparent thermal insulation windows is discussed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Aerogel\Transparent_thermal_insulation_silica_aerogels_Wang_et_al_2020.pdf}
}

@article{wangTunablePassbandOnedimensional2014,
  title = {Tunable Passband in One-Dimensional Phononic Crystal Containing a Piezoelectric 0.{{62Pb}}({{Mg1}}/{{3Nb2}}/3){{O3}}–0.{{38PbTiO3}} Single Crystal Defect Layer},
  author = {Wang, Yuling and Song, Wei and Sun, Enwei and Zhang, Rui and Cao, Wenwu},
  date = {2014-06},
  journaltitle = {Physica E: Low-dimensional Systems and Nanostructures},
  volume = {60},
  pages = {37--41},
  issn = {13869477},
  doi = {10.1016/j.physe.2014.02.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1386947714000526},
  urldate = {2023-09-05},
  abstract = {Longitudinal acoustic wave propagation in one-dimensional phononic crystal containing a 0.2 mol\% Fe-doped relaxor-based ferroelectric 0.62Pb(Mg1/3Nb2/3)O3–0.38PbTiO3 (PMN–0.38PT) single crystal defect layer is theoretically studied using the transfer matrix method. A passband can be produced in the stopband when the inserted PMN–0.38PT layer with thickness around its half wavelength. The frequency of the passband is closely dependent on the PMN–PT strain coefficient, suggesting that the band structure of phononic crystal is tunable by applying external electric field onto the piezoelectric crystal. Also, we investigated the influence of acoustic impedance of periodic constitutive materials (layers A and B) on the passband, where the bandwidth of the new passband becomes narrower as the acoustic impedance ratio of layer A and B (ZA/ZB) increase. The simulated results provide valuable guidance for designing tunable acoustic filters and switches made of phononic crystal consisting of the piezoelectric defect layer.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Tunable_passband_in_one-dimensional_phononic_crystal_containing_a_piezoelectric_Wang_et_al_2014.pdf}
}

@online{wangYOLOv7TrainableBagoffreebies2022,
  title = {{{YOLOv7}}: {{Trainable}} Bag-of-Freebies Sets New State-of-the-Art for Real-Time Object Detectors},
  shorttitle = {{{YOLOv7}}},
  author = {Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  date = {2022-07-06},
  eprint = {2207.02696},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2207.02696},
  urldate = {2023-08-26},
  abstract = {YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56.8\% AP among all known real-time object detectors with 30 FPS or higher on GPU V100. YOLOv7-E6 object detector (56 FPS V100, 55.9\% AP) outperforms both transformer-based detector SWINL Cascade-Mask R-CNN (9.2 FPS A100, 53.9\% AP) by 509\% in speed and 2\% in accuracy, and convolutionalbased detector ConvNeXt-XL Cascade-Mask R-CNN (8.6 FPS A100, 55.2\% AP) by 551\% in speed and 0.7\% AP in accuracy, as well as YOLOv7 outperforms: YOLOR, YOLOX, Scaled-YOLOv4, YOLOv5, DETR, Deformable DETR, DINO-5scale-R50, ViT-Adapter-B and many other object detectors in speed and accuracy. Moreover, we train YOLOv7 only on MS COCO dataset from scratch without using any other datasets or pre-trained weights. Source code is released in https:// github.com/ WongKinYiu/ yolov7.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\YOLOv7_Wang_et_al_2022.pdf}
}

@article{wanTheoreticalInvestigationSensor2021,
  title = {Theoretical {{Investigation}} of a {{Sensor Based}} on {{One-Dimensional Photonic Crystals}} to {{Measure Four Physical Quantities}}},
  author = {Wan, Bao-Fei and Xu, Yi and Zhou, Zi-Wei and Zhang, Dan and Zhang, Hai-Feng},
  date = {2021-02},
  journaltitle = {IEEE Sensors Journal},
  volume = {21},
  number = {3},
  pages = {2846--2853},
  issn = {1558-1748},
  doi = {10.1109/JSEN.2020.3027759},
  url = {https://ieeexplore.ieee.org/abstract/document/9208687?casa_token=VitUuyXZau8AAAAA:CBgGsNRDTRm5k71kq02gHKmPk0RKh7FaCSxrX2c4R8cHyUN8Rcgmp42Yn8I-NaaOw9YtHksvSw},
  urldate = {2024-01-22},
  abstract = {In this study, a sensor based on the located defect mode resonance is proposed, which can be used to simultaneously measure changes in magnetic induction intensity, plasma density, refractive index, and incident light angle. Plasma is introduced as the defect into a one-dimensional periodic structure, exciting the located defect mode resonance. The sensitivity, linear range, and figure of merit of the sensor are investigated using the transfer matrix method. The increase in the number of cycles can be used to improve the quality factor and FOM. We also consider the influence of the loss tangent on the sensor to a certain extent. The one-dimensional layered structure is utilized, which has the merits of small volume and simple manufacture. In addition, compared with the traditional sensors design, which focuses on the improvement of performance parameters, our proposed sensor concentrates on the study of multiple physical quantities. Therefore, we hope that our work can have some application potential in the field of measurement.},
  eventtitle = {{{IEEE Sensors Journal}}},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\Theoretical_Investigation_of_a_Sensor_Based_on_One-Dimensional_Photonic_Wan_et_al_2021.pdf}
}

@book{weberHandbookLasers,
  title = {Handbook of {{Lasers}}},
  author = {Weber, Marvin J},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\CRCpress\Handbook_of_Lasers_Weber_.pdf}
}

@book{weberHandbookOpticalMaterials2003,
  title = {Handbook of Optical Materials},
  author = {Weber, Marvin J.},
  date = {2003},
  series = {The {{CRC Press}} Laser and Optical Science and Technology Series},
  publisher = {CRC Press},
  location = {Boca Raton},
  isbn = {978-0-8493-3512-9},
  langid = {english},
  pagetotal = {512},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Dielectric\Handbook_of_optical_materials_Weber_2003.pdf}
}

@book{weberHandbookOpticalMaterials2003a,
  title = {Handbook of Optical Materials},
  author = {Weber, Marvin J.},
  date = {2003},
  series = {The {{CRC Press}} Laser and Optical Science and Technology Series},
  publisher = {CRC Press},
  location = {Boca Raton},
  isbn = {978-0-8493-3512-9},
  langid = {english},
  pagetotal = {512},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\CRCpress\Handbook_of_optical_materials_Weber_2003.pdf}
}

@online{weertsImportanceTuningHyperparameters2020,
  title = {Importance of {{Tuning Hyperparameters}} of {{Machine Learning Algorithms}}},
  author = {Weerts, Hilde J. P. and Mueller, Andreas C. and Vanschoren, Joaquin},
  date = {2020-07-15},
  eprint = {2007.07588},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2007.07588},
  urldate = {2023-09-27},
  abstract = {The performance of many machine learning algorithms depends on their hyperparameter settings. The goal of this study is to determine whether it is important to tune a hyperparameter or whether it can be safely set to a default value. We present a methodology to determine the importance of tuning a hyperparameter based on a non-inferiority test and tuning risk: the performance loss that is incurred when a hyperparameter is not tuned, but set to a default value. Because our methods require the notion of a default parameter, we present a simple procedure that can be used to determine reasonable default parameters. We apply our methods in a benchmark study using 59 datasets from OpenML. Our results show that leaving particular hyperparameters at their default value is non-inferior to tuning these hyperparameters. In some cases, leaving the hyperparameter at its default value even outperforms tuning it using a search procedure with a limited number of iterations.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\HyperparameterOptimization\Importance_of_Tuning_Hyperparameters_of_Machine_Learning_Algorithms_Weerts_et_al_2020.pdf}
}

@article{weiReliableDeepLearning2021,
  title = {A {{Reliable Deep Learning Scheme}} for {{Nonlinear Reconstructions}} in {{Electrical Impedance Tomography}}},
  author = {Wei, Zhun and Zong, Zheng and Wang, Yusong},
  date = {2021},
  journaltitle = {IEEE Trans. Comput. Imaging},
  volume = {7},
  pages = {789--798},
  issn = {2333-9403, 2334-0118, 2573-0436},
  doi = {10.1109/TCI.2021.3099632},
  url = {https://ieeexplore.ieee.org/document/9496105/},
  urldate = {2024-07-03},
  abstract = {Significant progress has recently been made in applying deep learning methods to Electrical Impedance Tomography (EIT), which is a promising technique for non-invasive, bedside ionizing radiation free, and real-time monitoring of lung health. However, different with conventional methods solved from physical model, deep learning methods, as data-driven approaches, suffer from reliability problem, i.e., the “confidence level” is unknown when using deep learning methods as EIT solvers. In this work, a reliable deep learning scheme (RDLS) is proposed to deal with typical nonlinear EIT problems. A noticeable characteristic of the proposed RDLS is that, besides the reconstructions, pixel-based uncertainties of the results are also predicted with a Bayesian framework. Further, physical information based on a spectral analysis and back-propagated field are incorporated into the proposed RDLS to improve the robustness. By training with random inclusions, it is quantitatively shown that the proposed RDLS provides high-quality reconstructions and uncertainty qualifications, where the predicted uncertainties are verified by both linear and nonlinear correlations with true absolute errors that are only known when ground truth is known. Our approach provides fast, high-quality, and robust EIT imaging with pixel-based uncertainties in both numerical and lab-control experimental tests.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\MLP\A_Reliable_Deep_Learning_Scheme_for_Nonlinear_Reconstructions_in_Electrical_Wei_et_al_2021.pdf}
}

@article{weissFastNeuralRepresentations2022,
  title = {Fast {{Neural Representations}} for {{Direct Volume Rendering}}},
  author = {Weiss, S. and Hermüller, P. and Westermann, R.},
  date = {2022},
  journaltitle = {Computer Graphics Forum},
  volume = {41},
  number = {6},
  pages = {196--211},
  issn = {1467-8659},
  doi = {10.1111/cgf.14578},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14578},
  urldate = {2023-07-28},
  abstract = {Despite the potential of neural scene representations to effectively compress 3D scalar fields at high reconstruction quality, the computational complexity of the training and data reconstruction step using scene representation networks limits their use in practical applications. In this paper, we analyse whether scene representation networks can be modified to reduce these limitations and whether such architectures can also be used for temporal reconstruction tasks. We propose a novel design of scene representation networks using GPU tensor cores to integrate the reconstruction seamlessly into on-chip raytracing kernels, and compare the quality and performance of this network to alternative network- and non-network-based compression schemes. The results indicate competitive quality of our design at high compression rates, and significantly faster decoding times and lower memory consumption during data reconstruction. We investigate how density gradients can be computed using the network and show an extension where density, gradient and curvature are predicted jointly. As an alternative to spatial super-resolution approaches for time-varying fields, we propose a solution that builds upon latent-space interpolation to enable random access reconstruction at arbitrary granularity. We summarize our findings in the form of an assessment of the strengths and limitations of scene representation networks for compression domain volume rendering, and outline future research directions. Source code: https://github.com/shamanDevel/fV-SRN},
  langid = {english},
  keywords = {compression algorithms,neural networks,volume rendering},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\RenderSpaces\Fast_Neural_Representations_for_Direct_Volume_Rendering_Weiss_et_al_2022.pdf}
}

@article{wicaksonoWearableSectorialElectrical2022,
  title = {Wearable Sectorial Electrical Impedance Tomography and K-Means Clustering for Measurement of Gastric Processes},
  author = {Wicaksono, Ridwan and Darma, Panji Nursetia and Inoue, Atsuo and Tsuji, Hideyuki and Takei, Masahiro},
  date = {2022-09-01},
  journaltitle = {Meas. Sci. Technol.},
  volume = {33},
  number = {9},
  pages = {094002},
  issn = {0957-0233, 1361-6501},
  doi = {10.1088/1361-6501/ac6e2e},
  url = {https://iopscience.iop.org/article/10.1088/1361-6501/ac6e2e},
  urldate = {2024-07-08},
  abstract = {A low-power and handy gastric data acquisition (g-DAQ) system has been proposed to identify the gastric processes in the epigastric region with sectorial electrical impedance tomography (s-EIT) and K-means sectorial clustering algorithm. The g-DAQ with a wearable abdominal sensor investigates gastric retention levels in the epigastric region during the emptying process. A C-runtime engine with Secure Shell protocol optimized an ARM microprocessor and field programmable gate array-based system with bidirectional channels to perform real-time data acquisition. The s-EIT algorithm projects the gastric conductivity distribution in the epigastric region into a cross-sectional image. K-means clustering method quantitatively identifies the gastric content images on the epigastric region to monitor the different clustered conductivity αk. The phantom experiments evaluated the s-EIT using liver-shaped, bone-shaped, and gastric-shaped phantoms in an abdominal-shaped vessel to distinguish gastric phantom conductivity. In human experiments, the proposed method was applied to measure 15 samples of the emptying process to evaluate the retention level of liquid gastric content. As a result, the proposed g-DAQ successfully performed a rapid acquisition at least 50 times faster than the conventional method in terms of the data acquisition rate. The developed g-DAQ with 110 mm × 66 mm × 51 mm of dimensions and 0.16 kg of weight took 0.32 sec to measure 208 points per frame and consumed 3.67 Watt of average power operation. By drinking 500 ml of rehydration water with 0.69 S m−1 of conductivity, In subjects 1–4 and phantoms, the maximum R(t) was identified on t1 as the gastric volume is fully bloated. During 30 min, the emptying liquid content was well-indicated because the minimum R(t) was identified on t15 as an empty state. The mean of the measurement results is −0.0387 with the linear equation R(t) = −0.0387t + 0.8105. In conclusion, the body mass index did not significantly affect the trendline.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Wearable\Wearable_sectorial_electrical_impedance_tomography_and_k-means_clustering_for_Wicaksono_et_al_2022.pdf}
}

@online{wiedemannDeepCABACContextadaptiveBinary2019,
  title = {{{DeepCABAC}}: {{Context-adaptive}} Binary Arithmetic Coding for Deep Neural Network Compression},
  shorttitle = {{{DeepCABAC}}},
  author = {Wiedemann, Simon and Kirchhoffer, Heiner and Matlage, Stefan and Haase, Paul and Marban, Arturo and Marinc, Talmaj and Neumann, David and Osman, Ahmed and Marpe, Detlev and Schwarz, Heiko and Wiegand, Thomas and Samek, Wojciech},
  date = {2019-05-15},
  eprint = {1905.08318},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/1905.08318},
  urldate = {2024-10-07},
  abstract = {We present DeepCABAC, a novel contextadaptive binary arithmetic coder for compressing deep neural networks. It quantizes each weight parameter by minimizing a weighted rate-distortion function, which implicitly takes the impact of quantization on to the accuracy of the network into account. Subsequently, it compresses the quantized values into a bitstream representation with minimal redundancies. We show that DeepCABAC is able to reach very high compression ratios across a wide set of different network architectures and datasets. For instance, we are able to compress by x63.6 the VGG16 ImageNet model with no loss of accuracy, thus being able to represent the entire network with merely 8.7MB.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Theory,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Quantization\Compression\DeepCABAC_Wiedemann_et_al_2019.pdf}
}

@article{wiedemannDeepCABACUniversalCompression2020,
  title = {{{DeepCABAC}}: {{A Universal Compression Algorithm}} for {{Deep Neural Networks}}},
  shorttitle = {{{DeepCABAC}}},
  author = {Wiedemann, Simon and Kirchoffer, Heiner and Matlage, Stefan and Haase, Paul and Marban, Arturo and Marinc, Talmaj and Neumann, David and Nguyen, Tung and Osman, Ahmed and Marpe, Detlev and Schwarz, Heiko and Wiegand, Thomas and Samek, Wojciech},
  date = {2020-05},
  journaltitle = {IEEE J. Sel. Top. Signal Process.},
  volume = {14},
  number = {4},
  eprint = {1907.11900},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  pages = {700--714},
  issn = {1932-4553, 1941-0484},
  doi = {10.1109/JSTSP.2020.2969554},
  url = {http://arxiv.org/abs/1907.11900},
  urldate = {2024-10-07},
  abstract = {The field of video compression has developed some of the most sophisticated and efficient compression algorithms known in the literature, enabling very high compressibility for little loss of information. Whilst some of these techniques are domain specific, many of their underlying principles are universal in that they can be adapted and applied for compressing different types of data. In this work we present DeepCABAC, a compression algorithm for deep neural networks that is based on one of the state-of-the-art video coding techniques. Concretely, it applies a Context-based Adaptive Binary Arithmetic Coder (CABAC) to the network’s parameters, which was originally designed for the H.264/AVC video coding standard and became the state-of-the-art for lossless compression. Moreover, DeepCABAC employs a novel quantization scheme that minimizes the rate-distortion function while simultaneously taking the impact of quantization onto the accuracy of the network into account. Experimental results show that DeepCABAC consistently attains higher compression rates than previously proposed coding techniques for neural network compression. For instance, it is able to compress the VGG16 ImageNet model by x63.6 with no loss of accuracy, thus being able to represent the entire network with merely 8.7MB. The source code for encoding and decoding can be found at https://github.com/fraunhoferhhi/DeepCABAC.},
  langid = {english},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Quantization\Compression\DeepCABAC_Wiedemann_et_al_2020.pdf}
}

@article{wilsonSpeedSoundDistilled1959,
  title = {Speed of {{Sound}} in {{Distilled Water}} as a {{Function}} of {{Temperature}} and {{Pressure}}},
  author = {Wilson, Wayne D.},
  date = {1959-08-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  volume = {31},
  number = {8},
  pages = {1067--1072},
  issn = {0001-4966, 1520-8524},
  doi = {10.1121/1.1907828},
  url = {https://pubs.aip.org/jasa/article/31/8/1067/718699/Speed-of-Sound-in-Distilled-Water-as-a-Function-of},
  urldate = {2023-09-05},
  abstract = {An ultrasonic pulse type apparatus was used to measure the speed of sound in distilled water over the pressure range 14.7 to 14 000 psia and the temperature range 0.9 to 91.2°C. The temperature where the maximum sound speed occurs shifts to a higher temperature when the pressure is increased. At atmospheric pressure the computed maximum speed was 1555.36 m/sec and occurred at a temperature of 74.164°C. The isotherms of sound speed, plotted as a function of pressure, are concave upward below 20°C, concave downward above 20°C, and are approximately linear near 20°C for the pressure range of 14.7 to 14 000 psia. These curvatures have a maximum value of 1 part in 300 compared to the estimated accuracy of measurement which is 1 part in 10 000. The results are presented in tables and also in the form of a fourth degree equation fitted to the experimental data by the method of least squares.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\OpticalAcousticProperties\Speed_of_Sound_in_Distilled_Water_as_a_Function_of_Temperature_and_Pressure_Wilson_1959.pdf}
}

@article{witkowska-wrobelImagingFocalSeizures2021,
  title = {Imaging of Focal Seizures with {{Electrical Impedance Tomography}} and Depth Electrodes in Real Time},
  author = {Witkowska-Wrobel, Anna and Aristovich, Kirill and Crawford, Abbe and Perkins, Justin D. and Holder, David},
  date = {2021-07},
  journaltitle = {NeuroImage},
  volume = {234},
  pages = {117972},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2021.117972},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811921002494},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Brain\Imaging_of_focal_seizures_with_Electrical_Impedance_Tomography_and_depth_Witkowska-Wrobel_et_al_2021.pdf}
}

@online{wu4DGaussianSplatting2023,
  title = {{{4D Gaussian Splatting}} for {{Real-Time Dynamic Scene Rendering}}},
  author = {Wu, Guanjun and Yi, Taoran and Fang, Jiemin and Xie, Lingxi and Zhang, Xiaopeng and Wei, Wei and Liu, Wenyu and Tian, Qi and Wang, Xinggang},
  date = {2023-10-12},
  eprint = {2310.08528},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.08528},
  urldate = {2023-11-06},
  abstract = {Representing and rendering dynamic scenes has been an important but challenging task. Especially, to accurately model complex motions, high efficiency is usually hard to maintain. We introduce the 4D Gaussian Splatting (4D-GS) to achieve real-time dynamic scene rendering while also enjoying high training and storage efficiency. An efficient deformation field is constructed to model both Gaussian motions and shape deformations. Different adjacent Gaussians are connected via a HexPlane to produce more accurate position and shape deformations. Our 4D-GS method achieves real-time rendering under high resolutions, 70 FPS at a 800\$\textbackslash times\$800 resolution on an RTX 3090 GPU, while maintaining comparable or higher quality than previous state-of-the-art methods. More demos and code are available at https://guanjunwu.github.io/4dgs/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\DynamicScenes\4D_Gaussian_Splatting_for_Wu_et_al_2023.pdf}
}

@article{wuElasticWaveBand2009,
  title = {Elastic Wave Band Gaps of One-Dimensional Phononic Crystals with Functionally Graded Materials},
  author = {Wu, Mei-Ling and Wu, Liang-Yu and Yang, Wen-Pei and Chen, Lien-Wen},
  date = {2009-11-01},
  journaltitle = {Smart Mater. Struct.},
  volume = {18},
  number = {11},
  pages = {115013},
  issn = {0964-1726, 1361-665X},
  doi = {10.1088/0964-1726/18/11/115013},
  url = {https://iopscience.iop.org/article/10.1088/0964-1726/18/11/115013},
  urldate = {2023-09-05},
  abstract = {The propagation of elastic waves in one-dimensional (1D) phononic crystals (PCs) with functionally graded materials (FGMs) is studied using the spectral finite elements and transfer matrix methods. FGMs typically treat the graded interlayer as a system of discrete layers, and the material properties are varied according to a well-known rule, such as the power law. The 1D PCs are composed of both FGMs and isotropic materials, and their band gaps can be changed with different FGM compositions and geometry parameters. By selecting the appropriate parameters, the desired filters can be designed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Elastic_wave_band_gaps_of_one-dimensional_phononic_crystals_with_functionally_Wu_et_al_2009.pdf}
}

@online{wuHyperDreamerHyperRealistic3D2023,
  title = {{{HyperDreamer}}: {{Hyper-Realistic 3D Content Generation}} and {{Editing}} from a {{Single Image}}},
  shorttitle = {{{HyperDreamer}}},
  author = {Wu, Tong and Li, Zhibing and Yang, Shuai and Zhang, Pan and Pan, Xinggang and Wang, Jiaqi and Lin, Dahua and Liu, Ziwei},
  date = {2023-12-07},
  eprint = {2312.04543},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.04543},
  url = {http://arxiv.org/abs/2312.04543},
  urldate = {2024-05-05},
  abstract = {3D content creation from a single image is a long-standing yet highly desirable task. Recent advances introduce 2D diffusion priors, yielding reasonable results. However, existing methods are not hyper-realistic enough for post-generation usage, as users cannot view, render and edit the resulting 3D content from a full range. To address these challenges, we introduce HyperDreamer with several key designs and appealing properties: 1) Viewable: 360 degree mesh modeling with high-resolution textures enables the creation of visually compelling 3D models from a full range of observation points. 2) Renderable: Fine-grained semantic segmentation and data-driven priors are incorporated as guidance to learn reasonable albedo, roughness, and specular properties of the materials, enabling semantic-aware arbitrary material estimation. 3) Editable: For a generated model or their own data, users can interactively select any region via a few clicks and efficiently edit the texture with text-based guidance. Extensive experiments demonstrate the effectiveness of HyperDreamer in modeling region-aware materials with high-resolution textures and enabling user-friendly editing. We believe that HyperDreamer holds promise for advancing 3D content creation and finding applications in various domains.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/AI/Reconstruction/NeuralRadianceFields/SingleImage/HyperDreamer_Wu_et_al_2023.pdf}
}

@article{wuShapeReconstructionMultiphase2021,
  title = {Shape {{Reconstruction With Multiphase Conductivity}} for {{Electrical Impedance Tomography Using Improved Convolutional Neural Network Method}}},
  author = {Wu, Yang and Chen, Bai and Liu, Kai and Zhu, Chengjun and Pan, Huaping and Jia, Jiabin and Wu, Hongtao and Yao, Jiafeng},
  date = {2021-04-01},
  journaltitle = {IEEE Sensors J.},
  volume = {21},
  number = {7},
  pages = {9277--9287},
  issn = {1530-437X, 1558-1748, 2379-9153},
  doi = {10.1109/JSEN.2021.3050845},
  url = {https://ieeexplore.ieee.org/document/9319721/},
  urldate = {2024-07-03},
  abstract = {Image reconstruction of Electrical Impedance Tomography (EIT) is a highly nonlinear ill-posed inverse problem, which is sensitive to the measurement noise and model errors. An improved Convolutional Neural Network (CNN) method is proposed for the EIT lung imaging. The proposed method is optimized based on the Visual Geometry Group (VGG) model, adding the batch normalization (BN) layer, ELU activation function, global average pooling (GAP) layer, and radial basis function (RBF) neural network. These optimizations help speed up network convergence, and improve reconstruction accuracy and robustness. Nearly 10 thousand EIT simulation models generated from chest CT images of 60 patients are used for the network training. The chest deformation, lung hyperdilation and atelectasis are randomly simulated during the model generation process. The proposed method after training is tested through a series of simulation data and experimental models. The reconstruction quality is quantitatively compared by calculating the root mean square error (RMSE) and image correlation coefficient (ICC). On average, the proposed method achieves 0.082 RMSE and 0.892 ICC through experimental results. The proposed method achieves high-resolution and robust shape reconstructions with multiphase conductivity for EIT lung imaging, especially in the presence of the measurement noise and interference. The proposed method is promising in providing quantitative images for potential clinical applications, such as human thorax imaging.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\Shape_Reconstruction_With_Multiphase_Conductivity_for_Electrical_Impedance_Wu_et_al_2021.pdf}
}

@article{xiangFISTANetLearningFast2021,
  title = {{{FISTA-Net}}: {{Learning}} a {{Fast Iterative Shrinkage Thresholding Network}} for {{Inverse Problems}} in {{Imaging}}},
  shorttitle = {{{FISTA-Net}}},
  author = {Xiang, Jinxi and Dong, Yonggui and Yang, Yunjie},
  date = {2021-05},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {40},
  number = {5},
  pages = {1329--1339},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2021.3054167},
  url = {https://ieeexplore.ieee.org/document/9335299/},
  urldate = {2024-07-03},
  abstract = {Inverse problems are essential to imaging applications. In this letter, we propose a model-based deep learning network, named FISTA-Net, by combining the merits of interpretability and generality of the model-based Fast Iterative Shrinkage/Thresholding Algorithm (FISTA) and strong regularization and tuning-free advantages of the data-driven neural network. By unfolding the FISTA into a deep network, the architecture of FISTA-Net consists of multiple gradient descent, proximal mapping, and momentum modules in cascade. Different from FISTA, the gradient matrix in FISTA-Net can be updated during iteration and a proximal operator network is developed for nonlinear thresholding which can be learned through end-to-end training. Key parameters of FISTA-Net including the gradient step size, thresholding value and momentum scalar are tuning-free and learned from training data rather than hand-crafted. We further impose positive and monotonous constraints on these parameters to ensure they converge properly. The experimental results, evaluated both visually and quantitatively, show that the FISTA-Net can optimize parameters for different imaging tasks, i.e. Electromagnetic Tomography (EMT) and X-ray Computational Tomography (X-ray CT). It outperforms the state-of-the-art model-based and deep learning methods and exhibits good generalization ability over other competitive learning-based approaches under different noise levels.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\FISTA-Net_Xiang_et_al_2021.pdf}
}

@article{xiangFISTANetLearningFast2021a,
  title = {{{FISTA-Net}}: {{Learning}} a {{Fast Iterative Shrinkage Thresholding Network}} for {{Inverse Problems}} in {{Imaging}}},
  shorttitle = {{{FISTA-Net}}},
  author = {Xiang, Jinxi and Dong, Yonggui and Yang, Yunjie},
  date = {2021-05},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {40},
  number = {5},
  pages = {1329--1339},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2021.3054167},
  url = {https://ieeexplore.ieee.org/document/9335299/},
  urldate = {2024-07-03},
  abstract = {Inverse problems are essential to imaging applications. In this letter, we propose a model-based deep learning network, named FISTA-Net, by combining the merits of interpretability and generality of the model-based Fast Iterative Shrinkage/Thresholding Algorithm (FISTA) and strong regularization and tuning-free advantages of the data-driven neural network. By unfolding the FISTA into a deep network, the architecture of FISTA-Net consists of multiple gradient descent, proximal mapping, and momentum modules in cascade. Different from FISTA, the gradient matrix in FISTA-Net can be updated during iteration and a proximal operator network is developed for nonlinear thresholding which can be learned through end-to-end training. Key parameters of FISTA-Net including the gradient step size, thresholding value and momentum scalar are tuning-free and learned from training data rather than hand-crafted. We further impose positive and monotonous constraints on these parameters to ensure they converge properly. The experimental results, evaluated both visually and quantitatively, show that the FISTA-Net can optimize parameters for different imaging tasks, i.e. Electromagnetic Tomography (EMT) and X-ray Computational Tomography (X-ray CT). It outperforms the state-of-the-art model-based and deep learning methods and exhibits good generalization ability over other competitive learning-based approaches under different noise levels.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\IterativeDeepNeuralNetwork\FISTA-Net_Xiang_et_al_2021.pdf}
}

@article{xiangMultiFrequencyElectromagneticTomography2020,
  title = {Multi-{{Frequency Electromagnetic Tomography}} for {{Acute Stroke Detection Using Frequency-Constrained Sparse Bayesian Learning}}},
  author = {Xiang, Jinxi and Dong, Yonggui and Yang, Yunjie},
  date = {2020-12},
  journaltitle = {IEEE Trans. Med. Imaging},
  volume = {39},
  number = {12},
  pages = {4102--4112},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2020.3013100},
  url = {https://ieeexplore.ieee.org/document/9153038/},
  urldate = {2024-07-03},
  abstract = {Imaging the bio-impedance distribution of the brain can provide initial diagnosis of acute stroke. This paper presents a compact and non-radiative tomographic modality, i.e. multi-frequency Electromagnetic Tomography (mfEMT), for the initial diagnosis of acute stroke. The mfEMT system consists of 12 channels of gradiometer coils with adjustable sensitivity and excitation frequency. To solve the image reconstruction problem of mfEMT, we propose an enhanced Frequency-Constrained Sparse Bayesian Learning (FC-SBL) to simultaneously reconstruct the conductivity distribution at all frequencies. Based on the Multiple Measurement Vector (MMV) model in the Sparse Bayesian Learning (SBL) framework, FC-SBL can recover the underlying distribution pattern of conductivity among multiple images by exploiting the frequency constraint information. A realistic 3D head model was established to simulate stroke detection scenarios, showing the capability of mfEMT to penetrate the highly resistive skull and improved image quality with FC-SBL. Both simulations and experiments showed that the proposed FC-SBL method is robust to noisy data for image reconstruction problems of mfEMT compared to the single measurement vector model, which is promising to detect acute strokes in the brain region with enhanced spatial resolution and in a baseline-free manner.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\BayesianLearning\Multi-Frequency_Electromagnetic_Tomography_for_Acute_Stroke_Detection_Using_Xiang_et_al_2020.pdf}
}

@online{xieHollowNeRFPruningHashgridBased2023,
  title = {{{HollowNeRF}}: {{Pruning Hashgrid-Based NeRFs}} with {{Trainable Collision Mitigation}}},
  shorttitle = {{{HollowNeRF}}},
  author = {Xie, Xiufeng and Gherardi, Riccardo and Pan, Zhihong and Huang, Stephen},
  date = {2023-08-19},
  eprint = {2308.10122},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.10122},
  urldate = {2024-03-18},
  abstract = {Neural radiance fields (NeRF) have garnered significant attention, with recent works such as Instant-NGP accelerating NeRF training and evaluation through a combination of hashgrid-based positional encoding and neural networks. However, effectively leveraging the spatial sparsity of 3D scenes remains a challenge. To cull away unnecessary regions of the feature grid, existing solutions rely on prior knowledge of object shape or periodically estimate object shape during training by repeated model evaluations, which are costly and wasteful. To address this issue, we propose HollowNeRF, a novel compression solution for hashgrid-based NeRF which automatically sparsifies the feature grid during the training phase. Instead of directly compressing dense features, HollowNeRF trains a coarse 3D saliency mask that guides efficient feature pruning, and employs an alternating direction method of multipliers (ADMM) pruner to sparsify the 3D saliency mask during training. By exploiting the sparsity in the 3D scene to redistribute hash collisions, HollowNeRF improves rendering quality while using a fraction of the parameters of comparable state-of-the-art solutions, leading to a better cost-accuracy trade-off. Our method delivers comparable rendering quality to Instant-NGP, while utilizing just 31\% of the parameters. In addition, our solution can achieve a PSNR accuracy gain of up to 1dB using only 56\% of the parameters.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,I.4.5},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\sparse\HollowNeRF_Xie_et_al_2023.pdf}
}

@online{xieLATTE3DLargescaleAmortized2024,
  title = {{{LATTE3D}}: {{Large-scale Amortized Text-To-Enhanced3D Synthesis}}},
  shorttitle = {{{LATTE3D}}},
  author = {Xie, Kevin and Lorraine, Jonathan and Cao, Tianshi and Gao, Jun and Lucas, James and Torralba, Antonio and Fidler, Sanja and Zeng, Xiaohui},
  date = {2024-03-22},
  eprint = {2403.15385},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.15385},
  url = {http://arxiv.org/abs/2403.15385},
  urldate = {2024-04-13},
  abstract = {Recent text-to-3D generation approaches produce impressive 3D results but require time-consuming optimization that can take up to an hour per prompt. Amortized methods like ATT3D optimize multiple prompts simultaneously to improve efficiency, enabling fast text-to-3D synthesis. However, they cannot capture high-frequency geometry and texture details and struggle to scale to large prompt sets, so they generalize poorly. We introduce LATTE3D, addressing these limitations to achieve fast, high-quality generation on a significantly larger prompt set. Key to our method is 1) building a scalable architecture and 2) leveraging 3D data during optimization through 3D-aware diffusion priors, shape regularization, and model initialization to achieve robustness to diverse and complex training prompts. LATTE3D amortizes both neural field and textured surface generation to produce highly detailed textured meshes in a single forward pass. LATTE3D generates 3D objects in 400ms, and can be further enhanced with fast test-time optimization.},
  pubstate = {prepublished},
  keywords = {68T45,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning,I.2.6,I.2.7,I.3.6,I.3.7},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\3DGeneration\LATTE3D_Xie_et_al_2024.pdf}
}

@online{xieLATTE3DLargescaleAmortized2024a,
  title = {{{LATTE3D}}: {{Large-scale Amortized Text-To-Enhanced3D Synthesis}}},
  shorttitle = {{{LATTE3D}}},
  author = {Xie, Kevin and Lorraine, Jonathan and Cao, Tianshi and Gao, Jun and Lucas, James and Torralba, Antonio and Fidler, Sanja and Zeng, Xiaohui},
  date = {2024-03-22},
  eprint = {2403.15385},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.15385},
  url = {http://arxiv.org/abs/2403.15385},
  urldate = {2024-06-06},
  abstract = {Recent text-to-3D generation approaches produce impressive 3D results but require time-consuming optimization that can take up to an hour per prompt. Amortized methods like ATT3D optimize multiple prompts simultaneously to improve efficiency, enabling fast text-to-3D synthesis. However, they cannot capture high-frequency geometry and texture details and struggle to scale to large prompt sets, so they generalize poorly. We introduce LATTE3D, addressing these limitations to achieve fast, high-quality generation on a significantly larger prompt set. Key to our method is 1) building a scalable architecture and 2) leveraging 3D data during optimization through 3D-aware diffusion priors, shape regularization, and model initialization to achieve robustness to diverse and complex training prompts. LATTE3D amortizes both neural field and textured surface generation to produce highly detailed textured meshes in a single forward pass. LATTE3D generates 3D objects in 400ms, and can be further enhanced with fast test-time optimization.},
  pubstate = {prepublished},
  keywords = {68T45,Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning,I.2.6,I.2.7,I.3.6,I.3.7},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\LATTE3D_Xie_et_al_2024.pdf}
}

@inproceedings{xiongEfficientFastAlgorithm2007,
  title = {Efficient {{Fast Algorithm}} for {{MQ Arithmetic Coder}}},
  booktitle = {Multimedia and {{Expo}}, 2007 {{IEEE International Conference}} On},
  author = {Xiong, Chengyi and Hou, Jianhua and Gao, Zhirong and He, Xiang},
  date = {2007-07},
  pages = {759--762},
  publisher = {IEEE},
  location = {Beijing, China},
  doi = {10.1109/ICME.2007.4284761},
  url = {http://ieeexplore.ieee.org/document/4284761/},
  urldate = {2024-04-10},
  abstract = {MQ arithmetic coder has been adopted to achieve entropy coding in the latest image compression standard JPEG2000, which is a bit-level operation with intensive branch and feedback thus becomes a serious bottleneck of high speed JPEG2000. In this paper, an efficient fast algorithm for MQ coder was proposed, in which the renormalization process with BYTEOUT was performed in batch fashion instead of gradual iteration as introduced in JPEG2000. Experimental results have proved the validity of this method in decreasing computation complexity.},
  eventtitle = {Multimedia and {{Expo}}, 2007 {{IEEE International Conference}} On},
  isbn = {978-1-4244-1016-3 978-1-4244-1017-0},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\ComputerScience\DataCompression\DataCompression\MQcoder\Efficient_Fast_Algorithm_for_MQ_Arithmetic_Coder_Xiong_et_al_2007.pdf}
}

@incollection{xuDesignDevelopmentPortable2021,
  title = {Design and {{Development}} of a {{Portable Electrical Impedance Tomography System}}},
  booktitle = {Intelligent {{Robotics}} and {{Applications}}},
  author = {Xu, Jiahao and Lu, Jiewei and Zhang, Song and Yu, Ningbo and Han, Jianda},
  editor = {Liu, Xin-Jun and Nie, Zhenguo and Yu, Jingjun and Xie, Fugui and Song, Rui},
  date = {2021},
  volume = {13014},
  pages = {415--427},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-89098-8_40},
  url = {https://link.springer.com/10.1007/978-3-030-89098-8_40},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is a non-invasive detection technique for human tissue imaging. However, most of the current EIT systems are complex and expensive in design. In this paper, we have developed a portable and economic EIT system, which just consists of five parts, including a data acquisition card (DAQ), a power module, a signal generator, a voltage-controlled current source, and a multiplexer module. The fast Fourier transform is used to extract the amplitude of the voltage signals collected by the DAQ. The Tikhonov regularization algorithm is adopted to reconstruct the image of conductivity distribution. Experiments on a practical phantom were designed and conducted to validate the performance of the system. The results showed that the developed system has an average signal-to-noise ratio of 65 dB for measurement channels and a high imaging signal accuracy of 0.99. The conductivity distribution in the phantom was successfully reconstructed by the developed EIT system.},
  isbn = {978-3-030-89097-1 978-3-030-89098-8},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\TikhonovRegularization\Design_and_Development_of_a_Portable_Electrical_Impedance_Tomography_System_Xu_et_al_2021.pdf}
}

@article{xueFeatureExtractionUsing2021,
  title = {Feature {{Extraction Using Hierarchical Dispersion Entropy}} for {{Rolling Bearing Fault Diagnosis}}},
  author = {Xue, Qiang and Xu, Boyu and He, Changbo and Liu, Fang and Ju, Bin and Lu, Siliang and Liu, Yongbin},
  date = {2021},
  journaltitle = {IEEE Transactions on Instrumentation and Measurement},
  volume = {70},
  pages = {1--11},
  issn = {1557-9662},
  doi = {10.1109/TIM.2021.3092513},
  url = {https://ieeexplore.ieee.org/document/9465132/?arnumber=9465132},
  urldate = {2025-01-07},
  abstract = {Effective feature extraction is crucial for accurate fault diagnosis of rolling bearings. A novel feature extraction method called hierarchical dispersion entropy (HDE) based on hierarchical analysis is proposed in this study. The proposed method includes the following three steps: 1) bearing vibration signal is decomposed into a series of subband signal components; 2) dispersion entropies of the components in different frequency bands are calculated as the original feature vector; and 3) joint approximate diagonalization of eigenmatrices (JADE) is used to extract fusion features from the original features. The main contributions of the proposed method are as follows: 1) the HDE method can characterize the complexity and uncertainty of the signal in full frequency band; 2) the JADE method further eliminates redundant information while greatly retaining fault-relevant information; and 3) the proposed method combines the advantages of HDE's hierarchical analysis and JADE's information fusion capabilities, so the fusion features extracted by the proposed method can be more effective for the establishment of fault pattern identification model. In the analysis of two experimental cases, the feature extracted by the proposed method shows better feature clustering effect and higher recognition rate than other methods. The results show that compared with other methods, the proposed method can more accurately characterize the health condition of the bearing.},
  eventtitle = {{{IEEE Transactions}} on {{Instrumentation}} and {{Measurement}}},
  keywords = {Dispersion,Entropy,Fault diagnosis,feature extraction,Feature extraction,feature fusion,hierarchical dispersion entropy (HDE),rolling bearings,Rolling bearings,Support vector machines,Vibrations},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\Feature_Extraction_Using_Xue_et_al_2021.pdf}
}

@article{xueTheoreticalAnalysisOmnidirectional2017,
  title = {The Theoretical Analysis of Omnidirectional Photonic Band Gaps in the One-Dimensional Ternary Plasma Photonic Crystals Based on {{Pell}} Quasi-Periodic Structure},
  author = {Xue, Feng and Liu, Shao-Bin and Zhang, Hai-Feng and Kong, Xiang-Kun and Wen, Yong-Diao and Wang, Ling-Ling and Qian, Shen},
  date = {2017-01},
  journaltitle = {Opt Quant Electron},
  volume = {49},
  number = {1},
  pages = {19},
  issn = {0306-8919, 1572-817X},
  doi = {10.1007/s11082-016-0762-0},
  url = {http://link.springer.com/10.1007/s11082-016-0762-0},
  urldate = {2024-01-22},
  abstract = {In this study, an omnidirectional photonic band gap (OPBG) in one-dimensional (1D) plasma photonic crystals (plasma-PCs) with Pell quasi-periodic structures, which are consisting of plasma and two isotropic dielectrics is theoretically calculated by the transfer matrix method. Compared to the Bragg gaps, the OPBG is not dependent on the angle of incidence and both transverse electric and transverse magnetic modes. The bandwidth and frequency region of the OPBG is not sensitive to Pell sequence order, but the bandwidth of the OPBG can be significantly enhanced, as the density and length of plasma layer are increased. The calculated results demonstrate that the 1D plasma-PCs with Pell quasiperiodic not only can obtain a larger bandwidth of OPBG but also have a shorter length in realizing devices, compared to the 1D Thue-Morse (Th-M) aperiodic or Fibonacci ones. It is clear that such 1D plasma-PCs with Pell quasi-periodic have advantages in realizing compact devices.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Plasma\The_theoretical_analysis_of_omnidirectional_photonic_band_gaps_in_the_Xue_et_al_2017.pdf}
}

@inproceedings{xuGenerativeHierarchicalFeatures2021,
  title = {Generative {{Hierarchical Features From Synthesizing Images}}},
  author = {Xu, Yinghao and Shen, Yujun and Zhu, Jiapeng and Yang, Ceyuan and Zhou, Bolei},
  date = {2021},
  pages = {4432--4442},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Generative_Hierarchical_Features_From_Synthesizing_Images_CVPR_2021_paper.html},
  urldate = {2025-01-07},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\Generative_Hierarchical_Xu_et_al_2021.pdf}
}

@online{xuIdempotencePerceptualImage2024,
  title = {Idempotence and {{Perceptual Image Compression}}},
  author = {Xu, Tongda and Zhu, Ziran and He, Dailan and Li, Yanghao and Guo, Lina and Wang, Yuanyuan and Wang, Zhe and Qin, Hongwei and Wang, Yan and Liu, Jingjing and Zhang, Ya-Qin},
  date = {2024-01-17},
  eprint = {2401.08920},
  eprinttype = {arXiv},
  eprintclass = {eess},
  doi = {10.48550/arXiv.2401.08920},
  url = {http://arxiv.org/abs/2401.08920},
  urldate = {2024-12-23},
  abstract = {Idempotence is the stability of image codec to re-compression. At the first glance, it is unrelated to perceptual image compression. However, we find that theoretically: 1) Conditional generative model-based perceptual codec satisfies idempotence; 2) Unconditional generative model with idempotence constraint is equivalent to conditional generative codec. Based on this newfound equivalence, we propose a new paradigm of perceptual image codec by inverting unconditional generative model with idempotence constraints. Our codec is theoretically equivalent to conditional generative codec, and it does not require training new models. Instead, it only requires a pre-trained mean-square-error codec and unconditional generative model. Empirically, we show that our proposed approach outperforms state-of-the-art methods such as HiFiC and ILLM, in terms of Fr\textbackslash 'echet Inception Distance (FID). The source code is provided in https://github.com/tongdaxu/Idempotence-and-Perceptual-Image-Compression.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Idempotence_and_Perceptual_Xu_et_al_2024.pdf}
}

@article{xuImprovedFirstOrderMotion2023,
  title = {Improved {{First-Order Motion Model}} of {{Image Animation}} with {{Enhanced Dense Motion}} and {{Repair Ability}}},
  author = {Xu, Yu and Xu, Feng and Liu, Qiang and Chen, Jianwen},
  date = {2023-01},
  journaltitle = {Applied Sciences},
  volume = {13},
  number = {7},
  pages = {4137},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app13074137},
  url = {https://www.mdpi.com/2076-3417/13/7/4137},
  urldate = {2024-04-19},
  abstract = {Image animation aims to transfer the posture change of a driving video to the static object of the source image, and has potential applications in various domains, such as film and game industries. The essential part in this task is to generate a video by learning the motion from the driving video while preserving the appearance from the source image. As a result, a new object with the same motion will be generated in the animated video. However, it is a significant challenge if the object pose shows large-scale change. Even the most recent method failed to achieve this correctly with good visual effects. In order to solve the problem of poor visual effects in the videos with the large-scale pose change, a novel method based on an improved first-order motion model (FOMM) with enhanced dense motion and repair ability was proposed in this paper. Firstly, when generating optical flow, we propose an attention mechanism that optimizes the feature representation of the image in both channel and spatial domains through maximum pooling. This enables better distortion of the source image into the feature domain of the driving image. Secondly, we further propose a multi-scale occlusion restoration module that generates a multi-resolution occlusion map by upsampling the low-resolution occlusion map. Following this, the generator redraws the occluded part of the reconstruction result across multiple scales through the multi-resolution occlusion map to achieve more accurate and vivid visual effects. In addition, the proposed model can be trained effectively in an unsupervised manner. We evaluated the proposed model on three benchmark datasets. The experimental results showed that multiple evaluation indicators were improved by our proposed method, and the visual effect of the animated videos obviously outperformed the FOMM. On the Voxceleb1 dataset, the pixel error, average keypoints distance and average Euclidean distance by our proposed method were reduced by 6.5\%, 5.1\% and 0.7\%, respectively. On the TaiChiHD dataset, the pixel error, average keypoints distance and missing keypoints rate measured by our proposed method were reduced by 4.9\%, 13.5\% and 25.8\%, respectively.},
  issue = {7},
  langid = {english},
  keywords = {convolutional block attention module,first order motion model,generative adversarial networks,image animation},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\Improved_First-Order_Motion_Xu_et_al_2023.pdf}
}

@article{xuInterfacingPhotonicsArtificial2021,
  title = {Interfacing Photonics with Artificial Intelligence: An Innovative Design Strategy for Photonic Structures and Devices Based on Artificial Neural Networks},
  shorttitle = {Interfacing Photonics with Artificial Intelligence},
  author = {Xu, Yihao and Zhang, Xianzhe and Fu, Yun and Liu, Yongmin},
  date = {2021-04-01},
  journaltitle = {Photon. Res., PRJ},
  volume = {9},
  number = {4},
  pages = {B135-B152},
  publisher = {Optica Publishing Group},
  issn = {2327-9125},
  doi = {10.1364/PRJ.417693},
  url = {https://opg.optica.org/prj/abstract.cfm?uri=prj-9-4-B135},
  urldate = {2024-05-31},
  abstract = {Over the past decades, photonics has transformed many areas in both fundamental research and practical applications. In particular, we can manipulate light in a desired and prescribed manner by rationally designed subwavelength structures. However, constructing complex photonic structures and devices is still a time-consuming process, even for experienced researchers. As a subset of artificial intelligence, artificial neural networks serve as one potential solution to bypass the complicated design process, enabling us to directly predict the optical responses of photonic structures or perform the inverse design with high efficiency and accuracy. In this review, we will introduce several commonly used neural networks and highlight their applications in the design process of various optical structures and devices, particularly those in recent experimental works. We will also comment on the future directions to inspire researchers from different disciplines to collectively advance this emerging research field.},
  langid = {english},
  keywords = {Genetic algorithms,Inverse design,Neural networks,Optical neural systems,Photonic devices,Subwavelength structures},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\Interfacing_photonics_with_Xu_et_al_2021.pdf}
}

@article{xuLungPerfusionAssessment2021,
  title = {Lung {{Perfusion Assessment}} by {{Bedside Electrical Impedance Tomography}} in {{Critically Ill Patients}}},
  author = {Xu, Mengru and He, Huaiwu and Long, Yun},
  date = {2021-10-13},
  journaltitle = {Front. Physiol.},
  volume = {12},
  pages = {748724},
  issn = {1664-042X},
  doi = {10.3389/fphys.2021.748724},
  url = {https://www.frontiersin.org/articles/10.3389/fphys.2021.748724/full},
  urldate = {2024-07-08},
  abstract = {As a portable, radiation-free imaging modality, electrical impedance tomography (EIT) technology has shown promise in the bedside visual assessment of lung perfusion distribution in critically ill patients. The two main methods of EIT for assessing lung perfusion are the pulsatility and conductivity contrast (saline) bolus method. Increasing attention is being paid to the saline bolus EIT method in the evaluation of regional pulmonary perfusion in clinical practice. This study seeks to provide an overview of experimental and clinical studies with the aim of clarifying the progress made in the use of the saline bolus EIT method. Animal studies revealed that the saline bolus EIT method presented good consistency with single-photon emission CT (SPECT) in the evaluation of lung regional perfusion changes in various pathological conditions. Moreover, the saline bolus EIT method has been applied to assess the lung perfusion in a pulmonary embolism and the effect of positive end-expiratory pressure (PEEP) on regional ventilation/perfusion ratio (V/Q) and acute respiratory distress syndrome (ARDS) in several clinical studies. The implementation of saline boluses, data analyses, precision, and cutoff values varied among different studies, and a consensus must be reached regarding the clinical application of the saline bolus EIT method. Further study is required to validate the impact of the described saline bolus EIT method on decision-making, therapeutic management, and outcomes in critically ill patients.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Lung_Perfusion_Assessment_by_Bedside_Electrical_Impedance_Tomography_in_Xu_et_al_2021.pdf}
}

@article{xuMechanismsApplicationsTerahertz2017,
  title = {Mechanisms and Applications of Terahertz Metamaterial Sensing: A Review},
  shorttitle = {Mechanisms and Applications of Terahertz Metamaterial Sensing},
  author = {Xu, Wendao and Xie, Lijuan and Ying, Yibin},
  date = {2017},
  journaltitle = {Nanoscale},
  volume = {9},
  number = {37},
  pages = {13864--13878},
  issn = {2040-3364, 2040-3372},
  doi = {10.1039/C7NR03824K},
  url = {http://xlink.rsc.org/?DOI=C7NR03824K},
  urldate = {2023-09-05},
  abstract = {THz sensing using different types of metamaterials, including metasurfaces, metamaterial absorbers, metallic meshes and guided spoof plasmon structures.           ,                             Terahertz (THz) technology has attracted great worldwide interest and novel high-intensity THz sources and plasmonics are two of the most active fields of recent research. Being situated between infrared light and microwave radiation, the absorption of THz rays in molecular and biomolecular systems is dominated by the excitation of intramolecular and intermolecular vibrations. This indicates that THz technology is an effective tool for sensing applications. However, the low sensitivity of free-space THz detection limits the sensing applications, which gives a great opportunity to metamaterials. Metamaterials are periodic artificial electromagnetic media structured with a size scale smaller than the wavelength of external stimuli. They present localized electric field enhancement and large values of quality factor (               Q               factor) and show high sensitivity to minor environment changes. In the present work, the mechanism of THz metamaterial sensing and dry sample and microfluidic sensing applications based on metamaterials are introduced. Moreover, new directions of THz metamaterial sensing advancement and introduction of two-dimensional materials and nanoparticles for future THz applications are summarized and discussed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Mechanisms_and_applications_of_terahertz_metamaterial_sensing_Xu_et_al_2017.pdf}
}

@online{xuVASA1LifelikeAudioDriven2024,
  title = {{{VASA-1}}: {{Lifelike Audio-Driven Talking Faces Generated}} in {{Real Time}}},
  shorttitle = {{{VASA-1}}},
  author = {Xu, Sicheng and Chen, Guojun and Guo, Yu-Xiao and Yang, Jiaolong and Li, Chong and Zang, Zhenyu and Zhang, Yizhong and Tong, Xin and Guo, Baining},
  date = {2024-04-16},
  eprint = {2404.10667},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.10667},
  url = {http://arxiv.org/abs/2404.10667},
  urldate = {2024-06-11},
  abstract = {We introduce VASA, a framework for generating lifelike talking faces with appealing visual affective skills (VAS) given a single static image and a speech audio clip. Our premiere model, VASA-1, is capable of not only producing lip movements that are exquisitely synchronized with the audio, but also capturing a large spectrum of facial nuances and natural head motions that contribute to the perception of authenticity and liveliness. The core innovations include a holistic facial dynamics and head movement generation model that works in a face latent space, and the development of such an expressive and disentangled face latent space using videos. Through extensive experiments including evaluation on a set of new metrics, we show that our method significantly outperforms previous methods along various dimensions comprehensively. Our method not only delivers high video quality with realistic facial and head dynamics but also supports the online generation of 512x512 videos at up to 40 FPS with negligible starting latency. It paves the way for real-time engagements with lifelike avatars that emulate human conversational behaviors.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\VASA-1_Xu_et_al_2024.pdf}
}

@online{xuVASA1LifelikeAudioDriven2024a,
  title = {{{VASA-1}}: {{Lifelike Audio-Driven Talking Faces Generated}} in {{Real Time}}},
  shorttitle = {{{VASA-1}}},
  author = {Xu, Sicheng and Chen, Guojun and Guo, Yu-Xiao and Yang, Jiaolong and Li, Chong and Zang, Zhenyu and Zhang, Yizhong and Tong, Xin and Guo, Baining},
  date = {2024-04-16},
  eprint = {2404.10667},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.10667},
  url = {http://arxiv.org/abs/2404.10667},
  urldate = {2024-08-09},
  abstract = {We introduce VASA, a framework for generating lifelike talking faces with appealing visual affective skills (VAS) given a single static image and a speech audio clip. Our premiere model, VASA-1, is capable of not only producing lip movements that are exquisitely synchronized with the audio, but also capturing a large spectrum of facial nuances and natural head motions that contribute to the perception of authenticity and liveliness. The core innovations include a holistic facial dynamics and head movement generation model that works in a face latent space, and the development of such an expressive and disentangled face latent space using videos. Through extensive experiments including evaluation on a set of new metrics, we show that our method significantly outperforms previous methods along various dimensions comprehensively. Our method not only delivers high video quality with realistic facial and head dynamics but also supports the online generation of 512x512 videos at up to 40 FPS with negligible starting latency. It paves the way for real-time engagements with lifelike avatars that emulate human conversational behaviors.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\VASA-1_Xu_et_al_22.pdf}
}

@article{xuVirtualChannelBased2022,
  title = {A {{Virtual Channel Based Data Augmentation Method}} for {{Electrical Impedance Tomography}}},
  author = {Xu, Jiahao and Wang, Xiangyu and Yu, Ningbo and Han, Jianda},
  date = {2022},
  journaltitle = {IEEE Trans. Instrum. Meas.},
  volume = {71},
  pages = {1--11},
  issn = {0018-9456, 1557-9662},
  doi = {10.1109/TIM.2022.3212757},
  url = {https://ieeexplore.ieee.org/document/9913481/},
  urldate = {2024-07-03},
  abstract = {Image reconstruction in electrical impedance tomography (EIT) is ill-posed, manifested in the difficulty of estimating the dense conductivity distribution with less information. In the actual measurement, the restricted number of electrodes placed around the sensitive field is the main reason for the limited number of measured data. Aiming at this challenge, this article proposed a virtual channel based data augmentation (DA) method for EIT. By combining virtual channel technology and deep learning, we obtained a prior model for DA. A dataset containing 16 000 samples was generated through EIT numerical simulations for model training. Then, the trained DA model was introduced before image reconstruction, and the distribution of conductivity changes was calculated with the sensitivity matrixbased algorithms. Both simulations and experiments proved that the proposed DA method can effectively improve the imaging quality without increasing physical electrodes. With the proposed method, the 8-electrode EIT system achieved comparable measurement performance with the 16-electrode EIT system.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\A_Virtual_Channel_Based_Data_Augmentation_Method_for_Electrical_Impedance_Xu_et_al_2022.pdf}
}

@article{yablonovitchInhibitedSpontaneousEmission1987,
  title = {Inhibited {{Spontaneous Emission}} in {{Solid-State Physics}} and {{Electronics}}},
  author = {Yablonovitch, Eli},
  date = {1987-05-18},
  journaltitle = {Phys. Rev. Lett.},
  volume = {58},
  number = {20},
  pages = {2059--2062},
  issn = {0031-9007},
  doi = {10.1103/PhysRevLett.58.2059},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.58.2059},
  urldate = {2024-06-01},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\Dielectric\Inhibited_Spontaneous_Emission_in_Solid-State_Physics_and_Electronics_Yablonovitch_1987.pdf}
}

@inproceedings{yangComputationallyEfficientNeuralImage2023,
  title = {Computationally-{{Efficient Neural Image Compression}} with {{Shallow Decoders}}},
  author = {Yang, Yibo and Mandt, Stephan},
  date = {2023},
  pages = {530--540},
  url = {https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.html},
  urldate = {2024-11-26},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Computationally-Efficient_Yang_Mandt_2023.pdf}
}

@inproceedings{yangConvolutionalChannelFeatures2015,
  title = {Convolutional {{Channel Features}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Yang, Bin and Yan, Junjie and Lei, Zhen and Li, Stan Z.},
  date = {2015-12},
  pages = {82--90},
  publisher = {IEEE},
  location = {Santiago, Chile},
  doi = {10.1109/ICCV.2015.18},
  url = {http://ieeexplore.ieee.org/document/7410375/},
  urldate = {2023-08-26},
  abstract = {Deep learning methods are powerful tools but often suffer from expensive computation and limited flexibility. An alternative is to combine light-weight models with deep representations. As successful cases exist in several visual problems, a unified framework is absent. In this paper, we revisit two widely used approaches in computer vision, namely filtered channel features and Convolutional Neural Networks (CNN), and absorb merits from both by proposing an integrated method called Convolutional Channel Features (CCF). CCF transfers low-level features from pretrained CNN models to feed the boosting forest model. With the combination of CNN features and boosting forest, CCF benefits from the richer capacity in feature representation compared with channel features, as well as lower cost in computation and storage compared with end-to-end CNN methods. We show that CCF serves as a good way of tailoring pre-trained CNN models to diverse tasks without finetuning the whole network to each task by achieving stateof-the-art performances in pedestrian detection, face detection, edge detection and object proposal generation.},
  eventtitle = {2015 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  isbn = {978-1-4673-8391-2},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\ConvolutionOnChannels\Convolutional_Channel_Features_Yang_et_al_2015.pdf}
}

@article{yangDeepNeuralNetwork2021,
  title = {A {{Deep Neural Network Method}} for {{Arterial Blood Flow Profile Reconstruction}}},
  author = {Yang, Dan and Wang, Yuchen and Xu, Bin and Wang, Xu and Liu, Yanjun and Cheng, Tonglei},
  date = {2021-08-27},
  journaltitle = {Entropy},
  volume = {23},
  number = {9},
  pages = {1114},
  issn = {1099-4300},
  doi = {10.3390/e23091114},
  url = {https://www.mdpi.com/1099-4300/23/9/1114},
  urldate = {2024-07-03},
  abstract = {Arterial stenosis will reduce the blood flow to various organs or tissues, causing cardiovascular diseases. Although there are mature diagnostic techniques in clinical practice, they are not suitable for early cardiovascular disease prediction and monitoring due to their high cost and complex operation. In this paper, we studied the electromagnetic effect of arterial blood flow and proposed a method based on the deep neural network for arterial blood flow profile reconstruction. The potential difference and weight matrix are used as inputs to the method, and its output is an estimate of the internal blood flow velocity distribution for arterial blood flow profile reconstruction. Firstly, the weight matrix is input into the convolutional auto-encode (CAE) network to extract its features. Then, the weight matrix features and potential difference are combined to obtain the features of the blood velocity distribution. Finally, the velocity features are reconstructed into blood flow velocity distribution by a convolution neural network (CNN). All data sets are obtained from a model of the carotid artery with different rates of stenosis in a uniform magnetic field by COMSOL. The results show that the average root mean square error of the reconstruction results obtained by the proposed method is 0.0333, and the average correlation coefficient is 0.9721, which is better than the corresponding indicators of the Tikhonov, back propagation (BP) and CNN methods. The simulation results show that the proposed method can achieve high accuracy in blood flow profile reconstruction and is of great significance for the early diagnosis of arterial stenosis and other vessel diseases.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\AI\ConvolutionalNeuralNetwork\A_Deep_Neural_Network_Method_for_Arterial_Blood_Flow_Profile_Reconstruction_Yang_et_al_2021.pdf}
}

@article{yangDevelopmentRealtimeUltrawideband,
  title = {Development of a {{Real-time Ultra-wideband See Through Wall Imaging Radar System}}},
  author = {Yang, Yunqiang},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\GHzRefractiveIndex\Development_of_a_Real-time_Ultra-wideband_See_Through_Wall_Imaging_Radar_System_Yang_.pdf}
}

@article{yangElectricalImpedanceAnalysis2022,
  title = {Electrical {{Impedance Analysis}} for {{Lung Cancer}}: {{A Prospective}}, {{Multicenter}}, {{Blind Validation Study}}},
  shorttitle = {Electrical {{Impedance Analysis}} for {{Lung Cancer}}},
  author = {Yang, Dawei and Gu, Chuanjia and Gu, Ye and Zhang, Xiaodong and Ge, Di and Zhang, Yong and Wang, Ningfang and Zheng, Xiaoxuan and Wang, Hao and Yang, Li and Chen, Saihua and Xie, Pengfei and Chen, Deng and Yu, Jinming and Sun, Jiayuan and Bai, Chunxue},
  date = {2022-07-20},
  journaltitle = {Front. Oncol.},
  volume = {12},
  pages = {900110},
  issn = {2234-943X},
  doi = {10.3389/fonc.2022.900110},
  url = {https://www.frontiersin.org/articles/10.3389/fonc.2022.900110/full},
  urldate = {2024-07-08},
  abstract = {Method: To evaluate EIA’s efficacy and safety profile in diagnosing pulmonary lesions, we conducted a prospective, multicenter study among patients with pulmonary lesions recruited from 4 clinical centers (Zhongshan Hospital Ethics Committee, Approval No. 2015-16R and 2017-035(3). They underwent EIA to obtain an Algorithm Composite Score or ‘Prolung Index,’ PI. The classification threshold of 29 was first tested in an analytical validation set of 144 patients and independently validated in a clinical validation set of 418 patients. The subject’s final diagnosis depended on histology and a 2-year follow-up. Results: In total, 418 patients completed the entire protocol for clinical validation, with 186 true positives, 145 true negatives, 52 false positives, and 35 false negatives. The sensitivity, specificity, and diagnostic yield were 84\% (95\% CI 79.3\%-89.0\%), 74\% (95\% CI 67.4\%-79.8\%), and 79\% (95\%CI 75.3\%-83.1\%), respectively, and did not differ according to age, sex, smoking history, body mass index, or lesion types. The sensitivity of small lesions was comparable to that of large lesions (p = 0.13). Four hundred eighty-four patients who underwent the analysis received a safety evaluation. No adverse events were considered to be related to the test. Conclusion: Electrical impedance analysis is a safe and efficient tool for risk stratification of pulmonary lesions, especially for patients with a suspicious lung lesion.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Lungs\Cancer\Electrical_Impedance_Analysis_for_Lung_Cancer_Yang_et_al_2022.pdf}
}

@inproceedings{yangIDToolkitToolkitBenchmarking2023,
  title = {{{IDToolkit}}: {{A Toolkit}} for {{Benchmarking}} and {{Developing Inverse Design Algorithms}} in {{Nanophotonics}}},
  shorttitle = {{{IDToolkit}}},
  booktitle = {Proceedings of the 29th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Yang, Jia-Qi and Xu, Yucheng and Shen, Jia-Lei and Fan, Kebin and Zhan, De-Chuan and Yang, Yang},
  date = {2023-08-04},
  series = {{{KDD}} '23},
  pages = {2930--2940},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/3580305.3599385},
  url = {https://dl.acm.org/doi/10.1145/3580305.3599385},
  urldate = {2024-06-01},
  abstract = {Aiding humans with scientific designs is one of the most exciting of artificial intelligence (AI) and machine learning (ML), due to their potential for the discovery of new drugs, design of new materials and chemical compounds, etc. However, scientific design typically requires complex domain knowledge that is not familiar to AI researchers. Further, scientific studies involve professional skills to perform experiments and evaluations. These obstacles prevent AI researchers from developing specialized methods for scientific designs. To take a step towards easy-to-understand and reproducible research of scientific design, we propose a benchmark for the inverse design of nanophotonic devices, which can be verified computationally and accurately. Specifically, we implemented three different nanophotonic design problems, namely a radiative cooler, a selective emitter for thermophotovoltaics, and structural color filters, all of which are different in design parameter spaces, complexity, and design targets. The benchmark environments are implemented with an open-source simulator. We further implemented 10 different inverse design algorithms and compared them in a reproducible and fair framework. The results revealed the strengths and weaknesses of existing methods, which shed light on several future directions for developing more efficient inverse design algorithms. Our benchmark can also serve as the starting point for more challenging scientific design problems. The code of IDToolkit is available at https://github.com/ThyrixYang/IDToolkit.},
  isbn = {9798400701030},
  keywords = {benchmark,datasets,inverse design},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\TwoAndThreeDimension\IDToolkit_Yang_et_al_2023.pdf}
}

@article{yangImageReconstructionAlgorithms2003,
  title = {Image Reconstruction Algorithms for Electrical Capacitance Tomography},
  author = {Yang, W Q and Peng, Lihui},
  date = {2003-01-01},
  journaltitle = {Meas. Sci. Technol.},
  volume = {14},
  number = {1},
  pages = {R1-R13},
  issn = {0957-0233},
  doi = {10.1088/0957-0233/14/1/201},
  url = {https://iopscience.iop.org/article/10.1088/0957-0233/14/1/201},
  urldate = {2024-07-08},
  abstract = {Electrical capacitance tomography (ECT) is used to image cross-sections of industrial processes containing dielectric material. This technique has been under development for more than a decade. The task of image reconstruction for ECT is to determine the permittivity distribution and hence material distribution over the cross-section from capacitance measurements. There are three principal difficulties with image reconstruction for ECT: (1) the relationship between the permittivity distribution and capacitance is non-linear and the electric field is distorted by the material present, the so-called ‘soft-field’ effect; (2) the number of independent measurements is limited, leading to an under-determined problem and (3) the inverse problem is ill posed and ill conditioned, making the solution sensitive to measurement errors and noise. Regularization methods are needed to treat this ill-posedness. This paper reviews existing image reconstruction algorithms for ECT, including linear back-projection, singular value decomposition, Tikhonov regularization, Newton–Raphson, iterative Tikhonov, the steepest descent method, Landweber iteration, the conjugate gradient method, algebraic reconstruction techniques, simultaneous iterative reconstruction techniques and model-based reconstruction. Some of these algorithms are examined by simulation and experiment for typical permittivity distributions. Future developments in image reconstruction for ECT are discussed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Image_reconstruction_algorithms_for_electrical_capacitance_tomography_Yang_Peng_2003.pdf}
}

@article{yangImageReconstructionAlgorithms2003a,
  title = {Image Reconstruction Algorithms for Electrical Capacitance Tomography},
  author = {Yang, W Q and Peng, Lihui},
  date = {2003-01-01},
  journaltitle = {Meas. Sci. Technol.},
  volume = {14},
  number = {1},
  pages = {R1-R13},
  issn = {0957-0233},
  doi = {10.1088/0957-0233/14/1/201},
  url = {https://iopscience.iop.org/article/10.1088/0957-0233/14/1/201},
  urldate = {2024-07-08},
  abstract = {Electrical capacitance tomography (ECT) is used to image cross-sections of industrial processes containing dielectric material. This technique has been under development for more than a decade. The task of image reconstruction for ECT is to determine the permittivity distribution and hence material distribution over the cross-section from capacitance measurements. There are three principal difficulties with image reconstruction for ECT: (1) the relationship between the permittivity distribution and capacitance is non-linear and the electric field is distorted by the material present, the so-called ‘soft-field’ effect; (2) the number of independent measurements is limited, leading to an under-determined problem and (3) the inverse problem is ill posed and ill conditioned, making the solution sensitive to measurement errors and noise. Regularization methods are needed to treat this ill-posedness. This paper reviews existing image reconstruction algorithms for ECT, including linear back-projection, singular value decomposition, Tikhonov regularization, Newton–Raphson, iterative Tikhonov, the steepest descent method, Landweber iteration, the conjugate gradient method, algebraic reconstruction techniques, simultaneous iterative reconstruction techniques and model-based reconstruction. Some of these algorithms are examined by simulation and experiment for typical permittivity distributions. Future developments in image reconstruction for ECT are discussed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Image_reconstruction_algorithms_for_electrical_capacitance_tomography_Yang_Peng_22.pdf}
}

@article{yangLossyImageCompression2023,
  title = {Lossy {{Image Compression}} with {{Conditional Diffusion Models}}},
  author = {Yang, Ruihan and Mandt, Stephan},
  date = {2023-12-15},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {36},
  pages = {64971--64995},
  url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/ccf6d8b4a1fe9d9c8192f00c713872ea-Abstract-Conference.html},
  urldate = {2024-12-23},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\Lossy_Image_Compression_with_Yang_Mandt_2023.pdf}
}

@inproceedings{yangNeuralLerPlaneRepresentations2023,
  title = {Neural {{LerPlane Representations}} for~{{Fast 4D Reconstruction}} of~{{Deformable Tissues}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} – {{MICCAI}} 2023},
  author = {Yang, Chen and Wang, Kailing and Wang, Yuehao and Yang, Xiaokang and Shen, Wei},
  editor = {Greenspan, Hayit and Madabhushi, Anant and Mousavi, Parvin and Salcudean, Septimiu and Duncan, James and Syeda-Mahmood, Tanveer and Taylor, Russell},
  date = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {46--56},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-43996-4_5},
  abstract = {Reconstructing deformable tissues from endoscopic stereo videos in robotic surgery is crucial for various clinical applications. However, existing methods relying only on implicit representations are computationally expensive and require dozens of hours, which limits further practical applications. To address this challenge, we introduce LerPlane, a novel method for fast and accurate reconstruction of surgical scenes under a single-viewpoint setting. LerPlane treats surgical procedures as 4D volumes and factorizes them into explicit 2D planes of static and dynamic fields, leading to a compact memory footprint and significantly accelerated optimization. The efficient factorization is accomplished by fusing features obtained through linear interpolation of each plane and enables using lightweight neural networks to model surgical scenes. Besides, LerPlane shares static fields, significantly reducing the workload of dynamic tissue modeling. We also propose a novel sample scheme to boost optimization and improve performance in regions with tool occlusion and large motions. Experiments on DaVinci robotic surgery videos demonstrate that LerPlane accelerates optimization by over 100\$\$\textbackslash times \$\$×while maintaining high quality across various non-rigid deformations, showing significant promise for future intraoperative surgery applications.},
  isbn = {978-3-031-43996-4},
  langid = {english},
  keywords = {Fast 3D Reconstruction,Neural Rendering,Robotic Surgery},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Endoscope\Neural_LerPlane_Representations_for_Fast_4D_Reconstruction_of_Deformable_Tissues_Yang_et_al_2023.pdf}
}

@inproceedings{yangPerceptualLearnedVideo2022,
  title = {Perceptual {{Learned Video Compression}} with {{Recurrent Conditional GAN}}},
  booktitle = {Proceedings of the {{Thirty-First International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Yang, Ren and Timofte, Radu and Van Gool, Luc},
  date = {2022-07},
  pages = {1537--1544},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  location = {Vienna, Austria},
  doi = {10.24963/ijcai.2022/214},
  url = {https://www.ijcai.org/proceedings/2022/214},
  urldate = {2024-12-20},
  abstract = {This paper proposes a Perceptual Learned Video Compression (PLVC) approach with recurrent conditional GAN. We employ the recurrent autoencoder-based compression network as the generator, and most importantly, we propose a recurrent conditional discriminator, which judges raw vs. compressed video conditioned on both spatial and temporal features, including the latent representation, temporal motion and hidden states in recurrent cells. This way, the adversarial training pushes the generated video to be not only spatially photo-realistic but also temporally consistent with the groundtruth and coherent among video frames. The experimental results show that the learned PLVC model compresses video with good perceptual quality at low bit-rate, and that it outperforms the official HEVC test model (HM 16.20) and the existing learned video compression approaches for several perceptual quality metrics and user studies. The project page is available at https://github.com/RenYang-home/PLVC.},
  eventtitle = {Thirty-{{First International Joint Conference}} on {{Artificial Intelligence}} \{\vphantom\}{{IJCAI-22}}\vphantom\{\}},
  isbn = {978-1-956792-00-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Perceptual_Learned_Video_Yang_et_al_22.pdf}
}

@inproceedings{yangRealtimeMonitoringMultiphase2022,
  title = {Real-Time {{Monitoring Multi-phase Flow}} Using {{Electrical Impedance Tomography}}},
  booktitle = {2022 {{IEEE International Conference}} on {{Sensing}}, {{Diagnostics}}, {{Prognostics}}, and {{Control}} ( {{SDPC}})},
  author = {Yang, Xuanxuan and Chen, Haofeng and Ma, Gang and Wang, Xiaojie},
  date = {2022-08-05},
  pages = {306--311},
  publisher = {IEEE},
  location = {Chongqing, China},
  doi = {10.1109/SDPC55702.2022.9915818},
  url = {https://ieeexplore.ieee.org/document/9915818/},
  urldate = {2024-07-08},
  eventtitle = {2022 {{IEEE International Conference}} on {{Sensing}}, {{Diagnostics}}, {{Prognostics}}, and {{Control}} ( {{SDPC}})},
  isbn = {978-1-66546-986-9},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Pipes\Real-time_Monitoring_Multi-phase_Flow_using_Electrical_Impedance_Tomography_Yang_et_al_2022.pdf}
}

@article{yanLearningDynamicHierarchical2022,
  title = {Learning {{Dynamic}} and {{Hierarchical Traffic Spatiotemporal Features With Transformer}}},
  author = {Yan, Haoyang and Ma, Xiaolei and Pu, Ziyuan},
  date = {2022-11},
  journaltitle = {IEEE Transactions on Intelligent Transportation Systems},
  volume = {23},
  number = {11},
  pages = {22386--22399},
  issn = {1558-0016},
  doi = {10.1109/TITS.2021.3102983},
  url = {https://ieeexplore.ieee.org/abstract/document/9520129?casa_token=Q8hk3chsbIIAAAAA:NKkfBNPRJG-SIl3Z7v-mbHvVTvLWQdjfFhPObjRIemjSC4KBT8m19gZw2Ed2y9RonYxrNU4rl2w},
  urldate = {2025-01-07},
  abstract = {Traffic forecasting has attracted considerable attention due to its importance in proactive urban traffic control and management. Scholars and engineers have exerted considerable efforts in improving the performance of traffic forecasting algorithms in terms of accuracy, reliability, and efficiency. Spatial feature representation of traffic flow is a core component that greatly influences traffic forecasting performance. In previous studies, several spatial attributes of traffic flow are ignored due to the following issues: a) traffic flow propagation does not comply with the road network, b) the spatial pattern of traffic flow varies over time, and c) single adjacent matrix cannot handle the complex and hierarchical urban traffic flow. To address the abovementioned issues, this study proposes a novel traffic forecasting algorithm called traffic transformer, which achieves great success in natural language processing. The multihead attention mechanism and stacking layers enable the transformer to learn dynamic and hierarchical features in sequential data. Two components, namely, global encoder and global–local decoder, are proposed to extract and fuse the spatial patterns globally and locally. Experimental results indicate that the proposed traffic transformer outperforms state-of-the-art methods. The learned dynamic and hierarchical features of traffic flow can help achieve a better understanding of spatial dependency of traffic flow for effective and efficient traffic control and management strategies.},
  eventtitle = {{{IEEE Transactions}} on {{Intelligent Transportation Systems}}},
  keywords = {Deep learning,Feature extraction,Forecasting,graph-based model,Heuristic algorithms,network modeling,Predictive models,Roads,spatial representation,Spatiotemporal phenomena,Traffic forecasting,transformer},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\Learning_Dynamic_and_Yan_et_al_2022.pdf}
}

@article{yaoElectricalImpedanceTomography2019,
  title = {Electrical Impedance Tomography for Biological Cell Sensing with Microfluidic Device},
  author = {Yao, Jiafeng},
  date = {2019},
  journaltitle = {JME},
  volume = {55},
  number = {2},
  pages = {1},
  issn = {0577-6686},
  doi = {10.3901/JME.2019.02.001},
  url = {http://www.cjmenet.com.cn/Jwk_jxgcxb/CN/10.3901/JME.2019.02.001},
  urldate = {2024-07-08},
  abstract = {A micro electrical impedance tomography (μEIT) system is developed to visualize cells concentration distribution in microchannel flow. Due to the complexity of electrical properties of the μEIT system in micro-scale measurement, simulation and experiments are conducted to find the optimal conditions of the image reconstruction process. In the simulation, three image reconstruction algorithms which are generalized vector sampled pattern matching (GVSPM), iterative tikhonov regularization (TK) and projected landweber iteration (PLW) are estimated, GVSPM is found to be the optimal algorithm for image reconstruction in the present study due to its higher image correlation IC = 0.84 and lower image error IE = 0.43. In the experiment, yeast cells and purified water are employed as two-phase flow to measure the cells sedimentation in the microchannel at a range of frequencies with GVSPM, TK and PLW, respectively. The optimal frequency for the μEIT system is found as f = 1 MHz due to its higher measurement sensitivity. GVSPM is found as the optimal image reconstruction algorithm because of its low voltage error UE = 0.582 and simpler image reconstruction without regularization factor. Finally, images of cells sedimentation are reconstructed with GVSPM in three cross-sections in microchannel flow at f = 1 MHz. The reconstructed images show that concentration of cells sedimentation from the upstream Z1 to downstream z5 is decreased gradually along the flow direction in the microchannel.},
  langid = {chinese},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\Industry\BubbleDetection\Electrical_Impedance_Tomography_for_Biological_Cell_Sensing_with_Microfluidic_Yao_2019.pdf}
}

@online{yarivBakedSDFMeshingNeural2023,
  title = {{{BakedSDF}}: {{Meshing Neural SDFs}} for {{Real-Time View Synthesis}}},
  shorttitle = {{{BakedSDF}}},
  author = {Yariv, Lior and Hedman, Peter and Reiser, Christian and Verbin, Dor and Srinivasan, Pratul P. and Szeliski, Richard and Barron, Jonathan T. and Mildenhall, Ben},
  date = {2023-05-16},
  eprint = {2302.14859},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.14859},
  url = {http://arxiv.org/abs/2302.14859},
  urldate = {2024-02-20},
  abstract = {We present a method for reconstructing high-quality meshes of large unbounded real-world scenes suitable for photorealistic novel view synthesis. We first optimize a hybrid neural volume-surface scene representation designed to have well-behaved level sets that correspond to surfaces in the scene. We then bake this representation into a high-quality triangle mesh, which we equip with a simple and fast view-dependent appearance model based on spherical Gaussians. Finally, we optimize this baked representation to best reproduce the captured viewpoints, resulting in a model that can leverage accelerated polygon rasterization pipelines for real-time view synthesis on commodity hardware. Our approach outperforms previous scene representations for real-time rendering in terms of accuracy, speed, and power consumption, and produces high quality meshes that enable applications such as appearance editing and physical simulation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\SDF\BakedSDF_Yariv_et_al_2023.pdf}
}

@online{yeDifferentialTransformer2024,
  title = {Differential {{Transformer}}},
  author = {Ye, Tianzhu and Dong, Li and Xia, Yuqing and Sun, Yutao and Zhu, Yi and Huang, Gao and Wei, Furu},
  date = {2024-10-07},
  eprint = {2410.05258},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2410.05258},
  url = {http://arxiv.org/abs/2410.05258},
  urldate = {2024-10-23},
  abstract = {Transformer tends to overallocate attention to irrelevant context. In this work, we introduce Diff Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separate softmax attention maps. The subtraction cancels noise, promoting the emergence of sparse attention patterns. Experimental results on language modeling show that Diff Transformer outperforms Transformer in various settings of scaling up model size and training tokens. More intriguingly, it offers notable advantages in practical applications, such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reduction of activation outliers. By being less distracted by irrelevant context, Diff Transformer can mitigate hallucination in question answering and text summarization. For in-context learning, Diff Transformer not only enhances accuracy but is also more robust to order permutation, which was considered as a chronic robustness issue. The results position Diff Transformer as a highly effective and promising architecture to advance large language models.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\Transformer\TransformersBasic\Differential_Transformer_Ye_et_al_2024.pdf}
}

@article{yehWavePropagationsPeriodic2006,
  title = {Wave Propagations of a Periodic Sandwich Beam by {{FEM}} and the Transfer Matrix Method},
  author = {Yeh, Jia-Yi and Chen, Lien-Wen},
  date = {2006-05},
  journaltitle = {Composite Structures},
  volume = {73},
  number = {1},
  pages = {53--60},
  issn = {02638223},
  doi = {10.1016/j.compstruct.2005.01.026},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0263822305000309},
  urldate = {2023-09-05},
  abstract = {Periodic structures can act as filters for wave propagation within certain bands of frequency called stop bands. The partially constrained layer damping (CLD) treatments are placed periodically along the beam and covered with a constrained layer to control the longitudinal wave propagation in this beam. The CLD placed on the beams act as the sources of impedance mismatch with viscoelastic characteristics. The location and width of the stop bands can be changed with different configurations of the periodic structure.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Wave_propagations_of_a_periodic_sandwich_beam_by_FEM_and_the_transfer_matrix_Yeh_Chen_2006.pdf}
}

@article{yeungHybridSupervisedReinforcement2024,
  title = {Hybrid Supervised and Reinforcement Learning for the Design and Optimization of Nanophotonic Structures},
  author = {Yeung, Christopher and Pham, Benjamin and Zhang, Zihan and Fountaine, Katherine T. and Raman, Aaswath P.},
  date = {2024-03-11},
  journaltitle = {Opt. Express, OE},
  volume = {32},
  number = {6},
  pages = {9920--9930},
  publisher = {Optica Publishing Group},
  issn = {1094-4087},
  doi = {10.1364/OE.512159},
  url = {https://opg.optica.org/oe/abstract.cfm?uri=oe-32-6-9920},
  urldate = {2024-05-31},
  abstract = {From higher computational efficiency to enabling the discovery of novel and complex structures, deep learning has emerged as a powerful framework for the design and optimization of nanophotonic circuits and components. However, both data-driven and exploration-based machine learning strategies have limitations in their effectiveness for nanophotonic inverse design. Supervised machine learning approaches require large quantities of training data to produce high-performance models and have difficulty generalizing beyond training data given the complexity of the design space. Unsupervised and reinforcement learning-based approaches on the other hand can have very lengthy training or optimization times associated with them. Here we demonstrate a hybrid supervised learning and reinforcement learning approach to the inverse design of nanophotonic structures and show this approach can reduce training data dependence, improve the generalizability of model predictions, and significantly shorten exploratory training times. The presented strategy thus addresses several contemporary deep learning-based challenges, while opening the door for new design methodologies that leverage multiple classes of machine learning algorithms to produce more effective and practical solutions for photonic design.},
  langid = {english},
  keywords = {Deep learning,Inverse design,Machine learning,Neural networks,Virtual reality,Wavefronts},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\OneDimension\Hybrid_supervised_and_Yeung_et_al_2024.pdf}
}

@online{yingOmniSeg3DOmniversal3D2023,
  title = {{{OmniSeg3D}}: {{Omniversal 3D Segmentation}} via {{Hierarchical Contrastive Learning}}},
  shorttitle = {{{OmniSeg3D}}},
  author = {Ying, Haiyang and Yin, Yixuan and Zhang, Jinzhi and Wang, Fan and Yu, Tao and Huang, Ruqi and Fang, Lu},
  date = {2023-11-20},
  eprint = {2311.11666},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.11666},
  url = {http://arxiv.org/abs/2311.11666},
  urldate = {2024-05-05},
  abstract = {Towards holistic understanding of 3D scenes, a general 3D segmentation method is needed that can segment diverse objects without restrictions on object quantity or categories, while also reflecting the inherent hierarchical structure. To achieve this, we propose OmniSeg3D, an omniversal segmentation method aims for segmenting anything in 3D all at once. The key insight is to lift multi-view inconsistent 2D segmentations into a consistent 3D feature field through a hierarchical contrastive learning framework, which is accomplished by two steps. Firstly, we design a novel hierarchical representation based on category-agnostic 2D segmentations to model the multi-level relationship among pixels. Secondly, image features rendered from the 3D feature field are clustered at different levels, which can be further drawn closer or pushed apart according to the hierarchical relationship between different levels. In tackling the challenges posed by inconsistent 2D segmentations, this framework yields a global consistent 3D feature field, which further enables hierarchical segmentation, multi-object selection, and global discretization. Extensive experiments demonstrate the effectiveness of our method on high-quality 3D segmentation and accurate hierarchical structure understanding. A graphical user interface further facilitates flexible interaction for omniversal 3D segmentation.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Segmentation\OmniSeg3D_Ying_et_al_2023.pdf}
}

@online{yinScalableMotionStyle2023,
  title = {Scalable {{Motion Style Transfer}} with {{Constrained Diffusion Generation}}},
  author = {Yin, Wenjie and Yu, Yi and Yin, Hang and Kragic, Danica and Björkman, Mårten},
  date = {2023-12-12},
  eprint = {2312.07311},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.07311},
  url = {http://arxiv.org/abs/2312.07311},
  urldate = {2024-04-04},
  abstract = {Current training of motion style transfer systems relies on consistency losses across style domains to preserve contents, hindering its scalable application to a large number of domains and private data. Recent image transfer works show the potential of independent training on each domain by leveraging implicit bridging between diffusion models, with the content preservation, however, limited to simple data patterns. We address this by imposing biased sampling in backward diffusion while maintaining the domain independence in the training stage. We construct the bias from the source domain keyframes and apply them as the gradient of content constraints, yielding a framework with keyframe manifold constraint gradients (KMCGs). Our validation demonstrates the success of training separate models to transfer between as many as ten dance motion styles. Comprehensive experiments find a significant improvement in preserving motion contents in comparison to baseline and ablative diffusion-based style transfer models. In addition, we perform a human study for a subjective assessment of the quality of generated dance motions. The results validate the competitiveness of KMCGs.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\Scalable_Motion_Style_Yin_et_al_2023.pdf}
}

@article{yuanMultiheadedTandemNeural2024,
  title = {Multi-Headed Tandem Neural Network Approach for Non-Uniqueness in Inverse Design of Layered Photonic Structures},
  author = {Yuan, Xiaogen and Wang, Shuqin and Gu, Leilei and Xie, Shusheng and Ma, Qiongxiong and Guo, Jianping},
  date = {2024-09-01},
  journaltitle = {Optics \& Laser Technology},
  volume = {176},
  pages = {110997},
  issn = {0030-3992},
  doi = {10.1016/j.optlastec.2024.110997},
  url = {https://www.sciencedirect.com/science/article/pii/S0030399224004559},
  urldate = {2024-05-31},
  abstract = {Neural networks have proven to be an influential tool in assisting with the inverse design of nanophotonic structures. However, the issue of non-uniqueness poses a significant limitation to this approach, as disparate designs can produce nearly identical spectra. This problem can result in the neural network failing to converge or producing erroneous results. In this study, we propose a multi-headed tandem neural network (MTNN) approach to address this issue. This method enables the neural network to generate multiple sets of outputs and utilize tandem neural networks (TNNs), and self-attention mechanisms, among other techniques, to constrain the results, and let these multiple outputs be fitted separately to different results. This allows the neural network to converge without sacrificing the simplex solution in the face of multimodal solutions. We employ the MTNN approach to inverse engineer a multilayer photonic structure comprised of two sets of oxide films, and the multiple outputs provide numerous valuable solutions. Our approach presents an effective solution for the inverse design of photonic structures afflicted with non-uniqueness problems.},
  keywords = {Artificial neural networks,Inverse design,Multi-headed neural network,Multilayer structures,Nano-photonics,Non-uniqueness},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\OneDimension\Multi-headed_tandem_neural_Yuan_et_al_2024.pdf}
}

@online{yuImageWorth322024,
  title = {An {{Image}} Is {{Worth}} 32 {{Tokens}} for {{Reconstruction}} and {{Generation}}},
  author = {Yu, Qihang and Weber, Mark and Deng, Xueqing and Shen, Xiaohui and Cremers, Daniel and Chen, Liang-Chieh},
  date = {2024-06-11},
  eprint = {2406.07550},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2406.07550},
  urldate = {2024-07-04},
  abstract = {Recent advancements in generative models have highlighted the crucial role of image tokenization in the efficient synthesis of high-resolution images. Tokenization, which transforms images into latent representations, reduces computational demands compared to directly processing pixels and enhances the effectiveness and efficiency of the generation process. Prior methods, such as VQGAN, typically utilize 2D latent grids with fixed downsampling factors. However, these 2D tokenizations face challenges in managing the inherent redundancies present in images, where adjacent regions frequently display similarities. To overcome this issue, we introduce Transformer-based 1-Dimensional Tokenizer (TiTok), an innovative approach that tokenizes images into 1D latent sequences. TiTok provides a more compact latent representation, yielding substantially more efficient and effective representations than conventional techniques. For example, a 256 × 256 × 3 image can be reduced to just 32 discrete tokens, a significant reduction from the 256 or 1024 tokens obtained by prior methods. Despite its compact nature, TiTok achieves competitive performance to state-of-the-art approaches. Specifically, using the same generator framework, TiTok attains 1.97 gFID, outperforming MaskGIT baseline significantly by 4.21 at ImageNet 256 × 256 benchmark. The advantages of TiTok become even more significant when it comes to higher resolution. At ImageNet 512 × 512 benchmark, TiTok not only outperforms state-of-the-art diffusion model DiT-XL/2 (gFID 2.74 vs. 3.04), but also reduces the image tokens by 64×, leading to 410× faster generation process. Our best-performing variant can significantly surpasses DiT-XL/2 (gFID 2.13 vs. 3.04) while still generating high-quality samples 74× faster.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\An_Image_is_Worth_32_Tokens_Yu_et_al_2024.pdf}
}

@online{yuNOFANeRFbasedOneshot2023,
  title = {{{NOFA}}: {{NeRF-based One-shot Facial Avatar Reconstruction}}},
  shorttitle = {{{NOFA}}},
  author = {Yu, Wangbo and Fan, Yanbo and Zhang, Yong and Wang, Xuan and Yin, Fei and Bai, Yunpeng and Cao, Yan-Pei and Shan, Ying and Wu, Yang and Sun, Zhongqian and Wu, Baoyuan},
  date = {2023-07-07},
  eprint = {2307.03441},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.03441},
  url = {http://arxiv.org/abs/2307.03441},
  urldate = {2024-04-04},
  abstract = {3D facial avatar reconstruction has been a significant research topic in computer graphics and computer vision, where photo-realistic rendering and flexible controls over poses and expressions are necessary for many related applications. Recently, its performance has been greatly improved with the development of neural radiance fields (NeRF). However, most existing NeRF-based facial avatars focus on subject-specific reconstruction and reenactment, requiring multi-shot images containing different views of the specific subject for training, and the learned model cannot generalize to new identities, limiting its further applications. In this work, we propose a one-shot 3D facial avatar reconstruction framework that only requires a single source image to reconstruct a high-fidelity 3D facial avatar. For the challenges of lacking generalization ability and missing multi-view information, we leverage the generative prior of 3D GAN and develop an efficient encoder-decoder network to reconstruct the canonical neural volume of the source image, and further propose a compensation network to complement facial details. To enable fine-grained control over facial dynamics, we propose a deformation field to warp the canonical volume into driven expressions. Through extensive experimental comparisons, we achieve superior synthesis results compared to several state-of-the-art methods.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\GenerativeAI\\ImageAnimation\\NOFA_Yu_et_al_2023.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\GenerativeAI\\ImageAnimation\\NOFA_Yu_et_al_22.pdf}
}

@online{yuPlenoxelsRadianceFields2021,
  title = {Plenoxels: {{Radiance Fields}} without {{Neural Networks}}},
  shorttitle = {Plenoxels},
  author = {Yu, Alex and Fridovich-Keil, Sara and Tancik, Matthew and Chen, Qinhong and Recht, Benjamin and Kanazawa, Angjoo},
  date = {2021-12-09},
  eprint = {2112.05131},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2112.05131},
  urldate = {2023-09-05},
  abstract = {We introduce Plenoxels (plenoptic voxels), a system for photorealistic view synthesis. Plenoxels represent a scene as a sparse 3D grid with spherical harmonics. This representation can be optimized from calibrated images via gradient methods and regularization without any neural components. On standard, benchmark tasks, Plenoxels are optimized two orders of magnitude faster than Neural Radiance Fields with no loss in visual quality. For video and code, please see https://alexyu.net/plenoxels.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\General\Plenoxels_Yu_et_al_2021.pdf}
}

@online{yuWonderWorldInteractive3D2024,
  title = {{{WonderWorld}}: {{Interactive 3D Scene Generation}} from a {{Single Image}}},
  shorttitle = {{{WonderWorld}}},
  author = {Yu, Hong-Xing and Duan, Haoyi and Herrmann, Charles and Freeman, William T. and Wu, Jiajun},
  date = {2024-09-10},
  eprint = {2406.09394},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2406.09394},
  urldate = {2024-10-04},
  abstract = {We present WonderWorld, a novel framework for interactive 3D scene generation that enables users to interactively specify scene contents and layout and see the created scenes in low latency. The major challenge lies in achieving fast generation of 3D scenes. Existing scene generation approaches fall short of speed as they often require (1) progressively generating many views and depth maps, and (2) time-consuming optimization of the scene geometry representations. We introduce the Fast Layered Gaussian Surfels (FLAGS) as our scene representation and an algorithm to generate it from a single view. Our approach does not need multiple views, and it leverages a geometry-based initialization that significantly reduces optimization time. Another challenge is generating coherent geometry that allows all scenes to be connected. We introduce the guided depth diffusion that allows partial conditioning of depth estimation. WonderWorld generates connected and diverse 3D scenes in less than 10 seconds on a single A6000 GPU, enabling real-time user interaction and exploration. We demonstrate the potential of WonderWorld for user-driven content creation and exploration in virtual environments. We will release full code and software for reproducibility. Project website: https://kovenyu.com/WonderWorld/.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Generative\WonderWorld_Yu_et_al_2024.pdf}
}

@article{zakiFanoResonanceBased2020,
  title = {Fano Resonance Based Defected {{1D}} Phononic Crystal for Highly Sensitive Gas Sensing Applications},
  author = {Zaki, Shrouk E. and Mehaney, Ahmed and Hassanein, Hekmat M. and Aly, Arafa H.},
  date = {2020-10-21},
  journaltitle = {Sci Rep},
  volume = {10},
  number = {1},
  pages = {17979},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-75076-8},
  url = {https://www.nature.com/articles/s41598-020-75076-8},
  urldate = {2023-09-05},
  abstract = {Abstract                            The defected acoustic band gap materials are promising a new generation of sensing technology based on layered cavities. We introduced a novel 1D defected phononic crystal (1D-DPC) as a high-sensitive gas sensor based on the Fano resonance transmitted window. Our designed (Lead–Epoxy) 1D-DPC multilayer has filled with a defect layer with different gases at different temperatures. In this study, Fano resonance—based acoustic band gap engineering has used to detect several gases such as O               2               , CO               2               , NH               3               , and CH               4               . For the first time, Fano resonance peaks appeared in the proposed gas sensor structures which attributed to high sensitivity, Q-factor, and figure-of-merit values for all gases. Also, the relation between the Fano resonance frequency and acoustic properties of gases at different temperatures has been studied in detail. The effect of the damping rate on the sensitivity of the gas sensor shows a linear behavior for CO               2               , O               2               , and NH               3               . Further, we introduced the effect of temperature on the damping rate of the incident waves inside the 1D-DPC gas sensor. The highest sensitivity and figure of merit were obtained for O               2               of 292~MHz/(kg/m               3               ) and 647~m               3               /Kg, respectively. While the highest figure-of-merit value of 60~°C               −1               at 30~°C was attributed to O               2               . The transfer matrix method is used for calculating the transmission coefficient of the incident acoustic wave. We believe that the proposed sensor can be experimentally implemented.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\1DPhononicCrystals\Fano_resonance_based_defected_1D_phononic_crystal_for_highly_sensitive_gas_Zaki_et_al_2020.pdf}
}

@article{zakyDetectionFatConcentration2022,
  title = {Detection of {{Fat Concentration}} in {{Milk Using Ternary Photonic Crystal}}},
  author = {Zaky, Zaky A. and Sharma, Arvind and Alamri, Sagr and Saleh, Nahla and Aly, Arafa H.},
  date = {2022-07-01},
  journaltitle = {Silicon},
  volume = {14},
  number = {11},
  pages = {6063--6073},
  issn = {1876-9918},
  doi = {10.1007/s12633-021-01379-8},
  url = {https://doi.org/10.1007/s12633-021-01379-8},
  urldate = {2024-05-04},
  abstract = {Rapid and sensitive detection of fat concentration in milk is a necessary part for citizens in each country. Bio-photonic sensing techniques are an accurate best way to detect biosensing measurements. The main aim of the proposed device is to make a more effective sensor to detect fat concentration in milk. A novel bio-photonic sensor based on the ternary photonic crystal of porous silicon is proposed. The key factor used here is that the dielectric constant of the milk depends strongly on the fat concentration. The proposed structures are (A) asymmetric ternary photonic crystal: (PSi1/PSi2/PSi3)N/Sample/(PSi1/PSi2/PSi3)N substrate, and (B) symmetric ternary photonic crystal: (PSi1/PSi2/PSi3)N/Sample/(PSi3/PSi2/ PSi1)N substrate. PSi and N denote to porous silicon layer and the number of layers, respectively. The numerical calculations for the proposed structure are calculated by using the transfer matrix method. Our biosensor is more efficient than some of the available sensors to sense the fat concentration in milk.},
  langid = {english},
  keywords = {Asymmetric PC,Fat concentration,Photonic crystal,Porous silicon,Symmetric PC,Ternary photonic crystal},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/Photonics/PhotonicCrystals/1DPhotonicCrystals/Porous/Detection_of_Fat_Zaky_et_al_2022.pdf}
}

@article{zamora-arellanoDevelopmentPortableReliable2020,
  title = {Development of a {{Portable}}, {{Reliable}} and {{Low-Cost Electrical Impedance Tomography System Using}} an {{Embedded System}}},
  author = {Zamora-Arellano, Francisco and López-Bonilla, Oscar Roberto and García-Guerrero, Enrique Efrén and Olguín-Tiznado, Jesús Everardo and Inzunza-González, Everardo and López-Mancilla, Didier and Tlelo-Cuautle, Esteban},
  date = {2020-12-24},
  journaltitle = {Electronics},
  volume = {10},
  number = {1},
  pages = {15},
  issn = {2079-9292},
  doi = {10.3390/electronics10010015},
  url = {https://www.mdpi.com/2079-9292/10/1/15},
  urldate = {2024-07-08},
  abstract = {Electrical impedance tomography (EIT) is a useful procedure with applications in industry and medicine, particularly in the lungs and brain area. In this paper, the development of a portable, reliable and low-cost EIT system for image reconstruction by using an embedded system (ES) is introduced herein. The novelty of this article is the hardware development of a complete low-cost EIT system, as well as three simple and efficient algorithms that can be implemented on ES. The proposed EIT system applies the adjacent voltage method, starting with an impedance acquisition stage that sends data to a Raspberry Pi 4 (RPi4) as ES. To perform the image reconstruction, a user interface was developed by using GNU Octave for RPi4 and the EIDORS library. A statistical analysis is performed to determine the best average value from the samples measured by using an analog-to-digital converter (ADC) with a capacity of 30 kSPS and 24-bit resolution. The tests for the proposed EIT system were performed using materials such as metal, glass and an orange to simulate its application in food industry. Experimental results show that the statistical median is more accurate with respect to the real voltage measurement; however, it represents a higher computational cost. Therefore, the mean is calculated and improved by discarding data values in a transitory state, achieving better accuracy than the median to determine the real voltage value, enhancing the quality of the reconstructed images. A performance comparison between a personal computer (PC) and RPi4 is presented. The proposed EIT system offers an excellent cost-benefit ratio with respect to a traditional PC, taking into account precision, accuracy, energy consumption, price, light weight, size, portability and reliability. The proposed EIT system has potential application in mechanical ventilation, food industry and structural health monitoring.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\EIDORS\Development_of_a_Portable,_Reliable_and_Low-Cost_Electrical_Impedance_Zamora-Arellano_et_al_2020.pdf}
}

@article{zamudio-laraComparisonUnidimensionalCircular2005,
  title = {A Comparison between Unidimensional, Circular and Spherical Photonic Crystal Stacks},
  author = {Zamudio-Lara, A. and Escobedo-Alatorre, J. and Sánchez-Mondragón, J. and Tecpoyotl-Torres, M.},
  date = {2005-04},
  journaltitle = {Optical Materials},
  volume = {27},
  number = {7},
  pages = {1255--1259},
  issn = {09253467},
  doi = {10.1016/j.optmat.2004.11.020},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0925346704004379},
  urldate = {2023-11-06},
  abstract = {One dimensional (1D), circular (2D) and spherical (3D) stacks have occupied quite an important place in Optics, Electronics and Solid State Physics on their own, that keeps growing with the development of Photonics. In particular Bragg and Photonic structures have found an application as Bragg fibers, microresonator, quantum dots like and many others structures; everything made feasible by the modern nanofabrication and others fabrication techniques. Their structural complexity still relies heavily on numerical simulation, with the exception of a few accessible cases. Among them, we study the scaling of a Bragg resonance (1/4 k) stack from one-dimensional to circular and spherical structures, from the point of view of their photonic band gap. The similitude with the well known linear multilayer method is discussed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhotonicCrystals\1DPhotonicCrystals\AnnularPhotonicCrystals\A_comparison_between_unidimensional,_circular_and_spherical_photonic_crystal_Zamudio-Lara_et_al_2005.pdf}
}

@inproceedings{zeilerDeconvolutionalNetworks2010,
  title = {Deconvolutional Networks},
  booktitle = {2010 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Zeiler, Matthew D. and Krishnan, Dilip and Taylor, Graham W. and Fergus, Rob},
  date = {2010-06},
  pages = {2528--2535},
  publisher = {IEEE},
  location = {San Francisco, CA, USA},
  doi = {10.1109/CVPR.2010.5539957},
  url = {http://ieeexplore.ieee.org/document/5539957/},
  urldate = {2023-08-26},
  abstract = {Building robust low and mid-level image representations, beyond edge primitives, is a long-standing goal in vision. Many existing feature detectors spatially pool edge information which destroys cues such as edge intersections, parallelism and symmetry. We present a learning framework where features that capture these mid-level cues spontaneously emerge from image data. Our approach is based on the convolutional decomposition of images under a sparsity constraint and is totally unsupervised. By building a hierarchy of such decompositions we can learn rich feature sets that are a robust image representation for both the analysis and synthesis of images.},
  eventtitle = {2010 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4244-6984-0},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\DeconvolutionalNetworks\Deconvolutional_networks_Zeiler_et_al_2010.pdf}
}

@incollection{zeilerVisualizingUnderstandingConvolutional2014,
  title = {Visualizing and {{Understanding Convolutional Networks}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2014},
  author = {Zeiler, Matthew D. and Fergus, Rob},
  editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
  date = {2014},
  volume = {8689},
  pages = {818--833},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-10590-1_53},
  url = {http://link.springer.com/10.1007/978-3-319-10590-1_53},
  urldate = {2023-08-26},
  abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al. on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-ofthe-art results on Caltech-101 and Caltech-256 datasets.},
  isbn = {978-3-319-10589-5 978-3-319-10590-1},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\Visualizing_and_Understanding_Zeiler_Fergus_2014.pdf}
}

@online{zeinoddinDARESDepthAnything2024,
  title = {{{DARES}}: {{Depth Anything}} in {{Robotic Endoscopic Surgery}} with {{Self-supervised Vector-LoRA}} of the {{Foundation Model}}},
  shorttitle = {{{DARES}}},
  author = {Zeinoddin, Mona Sheikh and Lena, Chiara and Qu, Jiongqi and Carlini, Luca and Magro, Mattia and Kim, Seunghoi and Momi, Elena De and Bano, Sophia and Grech-Sollars, Matthew and Mazomenos, Evangelos and Alexander, Daniel C. and Stoyanov, Danail and Clarkson, Matthew J. and Islam, Mobarakol},
  date = {2024-10-21},
  eprint = {2408.17433},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2408.17433},
  url = {http://arxiv.org/abs/2408.17433},
  urldate = {2024-12-13},
  abstract = {Robotic-assisted surgery (RAS) relies on accurate depth estimation for 3D reconstruction and visualization. While foundation models like Depth Anything Models (DAM) show promise, directly applying them to surgery often yields suboptimal results. Fully fine-tuning on limited surgical data can cause overfitting and catastrophic forgetting, compromising model robustness and generalization. Although Low-Rank Adaptation (LoRA) addresses some adaptation issues, its uniform parameter distribution neglects the inherent feature hierarchy, where earlier layers, learning more general features, require more parameters than later ones. To tackle this issue, we introduce Depth Anything in Robotic Endoscopic Surgery (DARES), a novel approach that employs a new adaptation technique, Vector Low-Rank Adaptation (Vector-LoRA) on the DAM V2 to perform self-supervised monocular depth estimation in RAS scenes. To enhance learning efficiency, we introduce Vector-LoRA by integrating more parameters in earlier layers and gradually decreasing parameters in later layers. We also design a reprojection loss based on the multi-scale SSIM error to enhance depth perception by better tailoring the foundation model to the specific requirements of the surgical environment. The proposed method is validated on the SCARED dataset and demonstrates superior performance over recent state-of-the-art self-supervised monocular depth estimation techniques, achieving an improvement of 13.3\% in the absolute relative error metric. The code and pre-trained weights are available at https://github.com/mobarakol/DARES.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\Robotics\Depth\DARES_Zeinoddin_et_al_2024.pdf}
}

@online{zengSTAG4DSpatialTemporalAnchored2024,
  title = {{{STAG4D}}: {{Spatial-Temporal Anchored Generative 4D Gaussians}}},
  shorttitle = {{{STAG4D}}},
  author = {Zeng, Yifei and Jiang, Yanqin and Zhu, Siyu and Lu, Yuanxun and Lin, Youtian and Zhu, Hao and Hu, Weiming and Cao, Xun and Yao, Yao},
  date = {2024-03-22},
  eprint = {2403.14939},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.14939},
  url = {http://arxiv.org/abs/2403.14939},
  urldate = {2024-05-05},
  abstract = {Recent progress in pre-trained diffusion models and 3D generation have spurred interest in 4D content creation. However, achieving high-fidelity 4D generation with spatial-temporal consistency remains a challenge. In this work, we propose STAG4D, a novel framework that combines pre-trained diffusion models with dynamic 3D Gaussian splatting for high-fidelity 4D generation. Drawing inspiration from 3D generation techniques, we utilize a multi-view diffusion model to initialize multi-view images anchoring on the input video frames, where the video can be either real-world captured or generated by a video diffusion model. To ensure the temporal consistency of the multi-view sequence initialization, we introduce a simple yet effective fusion strategy to leverage the first frame as a temporal anchor in the self-attention computation. With the almost consistent multi-view sequences, we then apply the score distillation sampling to optimize the 4D Gaussian point cloud. The 4D Gaussian spatting is specially crafted for the generation task, where an adaptive densification strategy is proposed to mitigate the unstable Gaussian gradient for robust optimization. Notably, the proposed pipeline does not require any pre-training or fine-tuning of diffusion networks, offering a more accessible and practical solution for the 4D generation task. Extensive experiments demonstrate that our method outperforms prior 4D generation works in rendering quality, spatial-temporal consistency, and generation robustness, setting a new state-of-the-art for 4D generation from diverse inputs, including text, image, and video.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\DynamicScenes\STAG4D_Zeng_et_al_2024.pdf}
}

@inproceedings{zhaEndoSurfNeuralSurface2023,
  title = {{{EndoSurf}}: {{Neural Surface Reconstruction}} of~{{Deformable Tissues}} with~{{Stereo Endoscope Videos}}},
  shorttitle = {{{EndoSurf}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} – {{MICCAI}} 2023},
  author = {Zha, Ruyi and Cheng, Xuelian and Li, Hongdong and Harandi, Mehrtash and Ge, Zongyuan},
  editor = {Greenspan, Hayit and Madabhushi, Anant and Mousavi, Parvin and Salcudean, Septimiu and Duncan, James and Syeda-Mahmood, Tanveer and Taylor, Russell},
  date = {2023},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {13--23},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-43996-4_2},
  abstract = {Reconstructing soft tissues from stereo endoscope videos is an essential prerequisite for many medical applications. Previous methods struggle to produce high-quality geometry and appearance due to their inadequate representations of 3D scenes. To address this issue, we propose a novel neural-field-based method, called EndoSurf, which effectively learns to represent a deforming surface from an RGBD sequence. In EndoSurf, we model surface dynamics, shape, and texture with three neural fields. First, 3D points are transformed from the observed space to the canonical space using the deformation field. The signed distance function (SDF) field and radiance field then predict their SDFs and colors, respectively, with which RGBD images can be synthesized via differentiable volume rendering. We constrain the learned shape by tailoring multiple regularization strategies and disentangling geometry and appearance. Experiments on public endoscope datasets demonstrate that EndoSurf significantly outperforms existing solutions, particularly in reconstructing high-fidelity shapes. Code is available at https://github.com/Ruyi-Zha/endosurf.git.},
  isbn = {978-3-031-43996-4},
  langid = {english},
  keywords = {3D Reconstructon,Neural Fields,Robotic Surgery},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Endoscope\EndoSurf_Zha_et_al_2023.pdf}
}

@article{zhangCompressingHyperspectralImages2024,
  title = {Compressing {{Hyperspectral Images Into Multilayer Perceptrons Using Fast-Time Hyperspectral Neural Radiance Fields}}},
  author = {Zhang, Lili and Pan, Tianpeng and Liu, Jiahui and Han, Lin},
  date = {2024},
  journaltitle = {IEEE Geoscience and Remote Sensing Letters},
  volume = {21},
  pages = {1--5},
  issn = {1558-0571},
  doi = {10.1109/LGRS.2024.3365106},
  url = {https://ieeexplore.ieee.org/abstract/document/10433191},
  urldate = {2024-06-12},
  abstract = {Hyperspectral images play an important role in the field of remote sensing (RS), and similar to ordinary RGB-based images, reconstructing the original information with higher quality using fewer bits is an essential task. Most existing hyperspectral image compression methods utilize a transform-based compression framework that reconstructs the original image after converting the input into a latent representation with a specific size. This kind of approaches has achieved some success, and however, it suffers from two problems. First, the encoder and decoder used for transformation take up a huge amount of computational resources, both for training and deployment. Second, the upper performance limit is not satisfactory, that is to say, huge computational cost does not bring a matching performance gain. Based on this, we propose a novel hyperspectral image compression method. Specifically, we employ neural radiance fields (NeRFs) to compress hyperspectral images, and unlike transform-based methods, the proposed method encodes the hyperspectral coordinate information, which is fit to hyperspectral pixel values using multilayer perceptrons (MLPs). After that, we only need to compress the weights of the generated MLPs using the model compression method (in this letter, we only employ the weight quantization) to efficiently save the hyperspectral images since the MLPs model, working as the fitting function, can be regarded as the compressed representation of the hyperspectral image. At the same condition, the proposed method achieved nearly 5 dB higher in PSNR and 6 dB higher in MS-SSIM than the comparison deep-learning-based methods.},
  eventtitle = {{{IEEE Geoscience}} and {{Remote Sensing Letters}}},
  keywords = {Hyperspectral image compression,Hyperspectral imaging,Image coding,Image reconstruction,multilayer perceptrons (MLPs),neural radiance fields (NeRFs),remote sensing (RS),Shape,Task analysis,Three-dimensional displays,Training},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Hyperspectral\Compressing_Hyperspectral_Images_Into_Multilayer_Perceptrons_Using_Fast-Time_Zhang_et_al_2024.pdf}
}

@online{zhangDiffusionModelsAre2024,
  title = {Diffusion {{Models}} Are {{Evolutionary Algorithms}}},
  author = {Zhang, Yanbo and Hartl, Benedikt and Hazan, Hananel and Levin, Michael},
  date = {2024-10-04},
  eprint = {2410.02543},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2410.02543},
  url = {http://arxiv.org/abs/2410.02543},
  urldate = {2024-10-25},
  abstract = {In a convergence of machine learning and biology, we reveal that diffusion models are evolutionary algorithms. By considering evolution as a denoising process and reversed evolution as diffusion, we mathematically demonstrate that diffusion models inherently perform evolutionary algorithms, naturally encompassing selection, mutation, and reproductive isolation. Building on this equivalence, we propose the Diffusion Evolution method: an evolutionary algorithm utilizing iterative denoising -- as originally introduced in the context of diffusion models -- to heuristically refine solutions in parameter spaces. Unlike traditional approaches, Diffusion Evolution efficiently identifies multiple optimal solutions and outperforms prominent mainstream evolutionary algorithms. Furthermore, leveraging advanced concepts from diffusion models, namely latent space diffusion and accelerated sampling, we introduce Latent Space Diffusion Evolution, which finds solutions for evolutionary tasks in high-dimensional complex parameter space while significantly reducing computational steps. This parallel between diffusion and evolution not only bridges two different fields but also opens new avenues for mutual enhancement, raising questions about open-ended evolution and potentially utilizing non-Gaussian or discrete diffusion models in the context of Diffusion Evolution.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\DiffusionModels\Diffusion_Models_are_Zhang_et_al_2024.pdf}
}

@article{zhangEfficientOnChipTraining2021,
  title = {Efficient {{On-Chip Training}} of {{Optical Neural Networks Using Genetic Algorithm}}},
  author = {Zhang, Hui and Thompson, Jayne and Gu, Mile and Jiang, Xu Dong and Cai, Hong and Liu, Patricia Yang and Shi, Yuzhi and Zhang, Yi and Karim, Muhammad Faeyz and Lo, Guo Qiang and Luo, Xianshu and Dong, Bin and Kwek, Leong Chuan and Liu, Ai Qun},
  date = {2021-06-16},
  journaltitle = {ACS Photonics},
  volume = {8},
  number = {6},
  pages = {1662--1672},
  publisher = {American Chemical Society},
  doi = {10.1021/acsphotonics.1c00035},
  url = {https://doi.org/10.1021/acsphotonics.1c00035},
  urldate = {2024-06-01},
  abstract = {Recent advances in silicon photonic chips have made huge progress in optical computing owing to their flexibility in the reconfiguration of various tasks. Its deployment of neural networks serves as an alternative for mitigating the rapidly increased demand for computing resources in electronic platforms. However, it remains a formidable challenge to train the online programmable optical neural networks efficiently, being restricted by the difficulty in obtaining gradient information on a physical device when executing a gradient descent algorithm. Here, we experimentally demonstrate an efficient, physics-agnostic, and closed-loop protocol for training optical neural networks on chip. A gradient-free algorithm, that is, the genetic algorithm, is adopted. The protocol is on-chip implementable, physical agnostic (no need to rely on characterization and offline modeling), and gradient-free. The protocol works for various types of chip structures and is especially helpful to those that cannot be analytically decomposed and characterized. We confirm its viability using several practical tasks, including the crossbar switch and the Iris classification. Finally, by comparing our physics-agonistic and gradient-free method to the off-chip and gradient-based training methods, we demonstrate the robustness of our system to perturbations such as imperfect phase implementation and photodetection noise. Optical processors with gradient-free genetic algorithms have broad application potentials in pattern recognition, reinforcement learning, quantum computing, and realistic applications (such as facial recognition, natural language processing, and autonomous vehicles).},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\GeneticAlgorithms\Efficient_On-Chip_Training_of_Optical_Neural_Networks_Using_Genetic_Algorithm_Zhang_et_al_2021.pdf}
}

@article{zhanGeneralMachineLearningbased2022,
  title = {A General Machine Learning-Based Approach for Inverse Design of One-Dimensional Photonic Crystals toward Targeted Visible Light Reflection Spectrum},
  author = {Zhan, Tao and Liu, Quan-Shan and Sun, Yuan-Jie and Qiu, Lu and Wen, Tao and Zhang, Rui},
  date = {2022-05-01},
  journaltitle = {Optics Communications},
  volume = {510},
  pages = {127920},
  issn = {0030-4018},
  doi = {10.1016/j.optcom.2022.127920},
  url = {https://www.sciencedirect.com/science/article/pii/S0030401822000116},
  urldate = {2024-06-21},
  abstract = {Data-driven methods have increasingly been applied to the development of optical systems as inexpensive and effective inverse design approaches. Optical properties (e.g., band-gap properties) of photonic crystals (PCs) are closely associated with characteristics of their light reflection spectra. Finding optimal PC constructions (within a pre-specified parameter space) that generate reflection spectra closest to a targeted spectrum is thus an interesting and meaningful inverse design problem, although relevant studies are still limited. Here we report a generally effective machine learning-based inverse design approach for one-dimensional photonic crystals (1DPCs), focusing on visible light spectra which are of high practical relevance. For a given class of 1DPC system, a deep neural network (DNN) in a unified structure is first trained over data from sizeable forward calculations (from layer thicknesses to spectrum). An iterative optimization scheme is then developed based on a coherent integration of DNN backward predictions (from spectrum to layer thicknesses), forward calculations, and Monte Carlo moves. We employ this new approach to four representative classes of 1DPC systems including periodic structures with two-, three-, and four-layer repeating units and a heterostructure. The approach successfully converges to solutions of optimal 1DPC constructions for various targeted spectra regardless of their exact achievability. Several demonstrating examples are presented and discussed in detail, including the inverse designs toward specially constructed “rectangle-shaped”, narrow-bandgap red-, green-, or blue-light reflection spectrum and wide-bandgap reflection spectrum that has high reflectivity in the whole visible light region. Remarkably, the results show that the approach can efficiently find out optimal layer thicknesses even when they are far outside the range covered by the original training data of DNN.},
  keywords = {Deep neural network,Inverse design,Machine learning,One-dimensional photonic crystal},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\AI\Modeling\OpticalProperties\A_general_machine_Zhan_et_al_2022.pdf}
}

@online{zhangGaussianImage1000FPS2024,
  title = {{{GaussianImage}}: 1000 {{FPS Image Representation}} and {{Compression}} by {{2D Gaussian Splatting}}},
  shorttitle = {{{GaussianImage}}},
  author = {Zhang, Xinjie and Ge, Xingtong and Xu, Tongda and He, Dailan and Wang, Yan and Qin, Hongwei and Lu, Guo and Geng, Jing and Zhang, Jun},
  date = {2024-07-09},
  eprint = {2403.08551},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2403.08551},
  urldate = {2024-10-23},
  abstract = {Implicit neural representations (INRs) recently achieved great success in image representation and compression, offering high visual quality and fast rendering speeds with 10-1000 FPS, assuming sufficient GPU resources are available. However, this requirement often hinders their use on low-end devices with limited memory. In response, we propose a groundbreaking paradigm of image representation and compression by 2D Gaussian Splatting, named GaussianImage. We first introduce 2D Gaussian to represent the image, where each Gaussian has 8 parameters including position, covariance and color. Subsequently, we unveil a novel rendering algorithm based on accumulated summation. Remarkably, our method with a minimum of 3\$\textbackslash times\$ lower GPU memory usage and 5\$\textbackslash times\$ faster fitting time not only rivals INRs (e.g., WIRE, I-NGP) in representation performance, but also delivers a faster rendering speed of 1500-2000 FPS regardless of parameter size. Furthermore, we integrate existing vector quantization technique to build an image codec. Experimental results demonstrate that our codec attains rate-distortion performance comparable to compression-based INRs such as COIN and COIN++, while facilitating decoding speeds of approximately 2000 FPS. Additionally, preliminary proof of concept shows that our codec surpasses COIN and COIN++ in performance when using partial bits-back coding. Code is available at https://github.com/Xinjie-Q/GaussianImage.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Multimedia,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\ImageCompression\GaussianImage_Zhang_et_al_2024.pdf}
}

@inproceedings{zhangImageReconstructionAlgorithm2011,
  title = {Image Reconstruction Algorithm for Electrical Impedance Tomography Using Updated Sensitivity Matrix},
  booktitle = {2011 {{International Conference}} of {{Soft Computing}} and {{Pattern Recognition}} ({{SoCPaR}})},
  author = {Zhang, Lifeng},
  date = {2011-10},
  pages = {248--252},
  publisher = {IEEE},
  location = {Dalian, China},
  doi = {10.1109/SoCPaR.2011.6089115},
  url = {http://ieeexplore.ieee.org/document/6089115/},
  urldate = {2024-07-03},
  abstract = {Electrical impedance tomography (EIT) is a technique to reconstruct the conductivity distribution of an inhomogeneous medium. Sensitivity matrix of EIT is calculated with a selected reference conductivity distribution, which will change with the media distribution. Landweber iterative algorithm based on updated sensitivity matrix was presented in this paper. Reconstructed image based on conventional Landweber iteration was selected as the initial image for sensitivity matrix update, and the reconstructed images after sensitivity matrix update using different initial images were compared. The effect on the quality of reconstructed images for different times of sensitivity matrix update was also analyzed. Simulation and static test results showed that reconstructed images with higher quality can be obtained.},
  eventtitle = {2011 {{International Conference}} of {{Soft Computing}} and {{Pattern Recognition}} ({{SoCPaR}})},
  isbn = {978-1-4577-1196-1 978-1-4577-1195-4 978-1-4577-1194-7},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\LandweberMethod\Image_reconstruction_algorithm_for_electrical_impedance_tomography_using_Zhang_2011.pdf}
}

@online{zhangImplicitNeuralRepresentation2021,
  title = {Implicit {{Neural Representation Learning}} for {{Hyperspectral Image Super-Resolution}}},
  author = {Zhang, Kaiwei},
  date = {2021-12-20},
  eprint = {2112.10541},
  eprinttype = {arXiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2112.10541},
  urldate = {2024-06-12},
  abstract = {Hyperspectral image (HSI) super-resolution without additional auxiliary image remains a constant challenge due to its high-dimensional spectral patterns, where learning an effective spatial and spectral representation is a fundamental issue. Recently, Implicit Neural Representations (INRs) are making strides as a novel and effective representation, especially in the reconstruction task. Therefore, in this work, we propose a novel HSI reconstruction model based on INR which represents HSI by a continuous function mapping a spatial coordinate to its corresponding spectral radiance values. In particular, as a specific implementation of INR, the parameters of parametric model are predicted by a hypernetwork that operates on feature extraction using convolution network. It makes the continuous functions map the spatial coordinates to pixel values in a contentaware manner. Moreover, periodic spatial encoding are deeply integrated with the reconstruction procedure, which makes our model capable of recovering more high frequency details. To verify the efficacy of our model, we conduct experiments on three HSI datasets (CAVE, NUS, and NTIRE2018). Experimental results show that the proposed model can achieve competitive reconstruction performance in comparison with the state-of-theart methods. In addition, we provide an ablation study on the effect of individual components of our model. We hope this paper could server as a potent reference for future research.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\MultiSpectral\Implicit_Neural_Representation_Learning_for_Hyperspectral_Image_Super-Resolution_Zhang_2021.pdf}
}

@article{zhangImplicitNeuralRepresentation2023,
  title = {Implicit {{Neural Representation Learning}} for {{Hyperspectral Image Super-Resolution}}},
  author = {Zhang, Kaiwei and Zhu, Dandan and Min, Xiongkuo and Zhai, Guangtao},
  date = {2023},
  journaltitle = {IEEE Transactions on Geoscience and Remote Sensing},
  volume = {61},
  pages = {1--12},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2022.3230204},
  url = {https://ieeexplore.ieee.org/abstract/document/9991174},
  urldate = {2024-06-12},
  abstract = {Hyperspectral image (HSI) super-resolution (SR) without additional auxiliary image remains a constant challenge due to its high-dimensional spectral patterns, where learning an effective spatial and spectral representation is a fundamental issue. Recently, implicit neural representations (INRs) are making strides as a novel and effective representation, especially in the reconstruction task. Therefore, in this work, we propose a novel HSI reconstruction model based on INR which represents HSI by a continuous function mapping a spatial coordinate to its corresponding spectral radiance values. In particular, as a specific implementation of INR, the parameters of the parametric model are predicted by a hypernetwork that operates on feature extraction using a convolution network. It makes the continuous functions map the spatial coordinates to pixel values in a content-aware manner. Moreover, periodic spatial encoding is deeply integrated with the reconstruction procedure, which makes our model capable of recovering more high-frequency details. To verify the efficacy of our model, we conduct experiments on three HSI datasets (CAVE, NUS, and NTIRE2018). Experimental results show that the proposed model can achieve competitive reconstruction performance in comparison with the state-of-the-art methods. In addition, we provide an ablation study on the effect of individual components of our model. We hope this article could serve as a potent reference for future research.},
  eventtitle = {{{IEEE Transactions}} on {{Geoscience}} and {{Remote Sensing}}},
  keywords = {Convolutional neural networks,Hypernetwork,hyperspectral image (HSI),Hyperspectral imaging,Image reconstruction,implicit neural representation (INR),Spatial resolution,spectral super-resolution (SR),Superresolution,Task analysis,Three-dimensional displays},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Hyperspectral\Implicit_Neural_Representation_Learning_for_Hyperspectral_Image_Super-Resolution_Zhang_et_al_2023.pdf}
}

@inproceedings{zhangIRGenGenerativeModeling2025,
  title = {{{IRGen}}: {{Generative Modeling}} for~{{Image Retrieval}}},
  shorttitle = {{{IRGen}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2024},
  author = {Zhang, Yidan and Zhang, Ting and Chen, Dong and Wang, Yujing and Chen, Qi and Xie, Xing and Sun, Hao and Deng, Weiwei and Zhang, Qi and Yang, Fan and Yang, Mao and Liao, Qingmin and Wang, Jingdong and Guo, Baining},
  editor = {Leonardis, Aleš and Ricci, Elisa and Roth, Stefan and Russakovsky, Olga and Sattler, Torsten and Varol, Gül},
  date = {2025},
  pages = {21--41},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-72633-0_2},
  abstract = {While generative modeling has become prevalent across numerous research fields, its integration into the realm of~image retrieval remains largely unexplored and underjustified. In~this paper, we present a novel methodology, reframing image retrieval~as a variant of generative modeling and employing~a sequence-to-sequence model. This approach is harmoniously aligned with the current trend towards unification in research, presenting~a cohesive framework that allows for end-to-end differentiable searching. This, in turn, facilitates superior performance~via direct optimization techniques. The development of our model, dubbed IRGen, addresses the critical technical challenge of converting~an image into a concise sequence of semantic units, which is pivotal for enabling efficient and effective search. Extensive experiments demonstrate that our model achieves state-of-the-art performance ~on three widely-used image retrieval benchmarks as well as~two million-scale datasets, yielding significant improvement compared~to prior competitive retrieval methods. In addition, the notable~surge in precision scores facilitated by generative modeling presents~the potential to bypass the reranking phase, which is traditionally indispensable in practical retrieval workflows. The code is publicly available~at https://github.com/yakt00/IRGen.},
  isbn = {978-3-031-72633-0},
  langid = {english},
  keywords = {Autoregressive Model,Generative Model,Image Retrieval},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\GenerativeImageCodec\IRGen_Zhang_et_al_2025.pdf}
}

@online{zhangMagicLensSelfSupervisedImage2024,
  title = {{{MagicLens}}: {{Self-Supervised Image Retrieval}} with {{Open-Ended Instructions}}},
  shorttitle = {{{MagicLens}}},
  author = {Zhang, Kai and Luan, Yi and Hu, Hexiang and Lee, Kenton and Qiao, Siyuan and Chen, Wenhu and Su, Yu and Chang, Ming-Wei},
  date = {2024-03-28},
  eprint = {2403.19651},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.19651},
  url = {http://arxiv.org/abs/2403.19651},
  urldate = {2024-04-13},
  abstract = {Image retrieval, i.e., finding desired images given a reference image, inherently encompasses rich, multi-faceted search intents that are difficult to capture solely using image-based measures. Recent work leverages text instructions to allow users to more freely express their search intents. However, existing work primarily focuses on image pairs that are visually similar and/or can be characterized by a small set of pre-defined relations. The core thesis of this paper is that text instructions can enable retrieving images with richer relations beyond visual similarity. To show this, we introduce MagicLens, a series of self-supervised image retrieval models that support open-ended instructions. MagicLens is built on a key novel insight: image pairs that naturally occur on the same web pages contain a wide range of implicit relations (e.g., inside view of), and we can bring those implicit relations explicit by synthesizing instructions via large multimodal models (LMMs) and large language models (LLMs). Trained on 36.7M (query image, instruction, target image) triplets with rich semantic relations mined from the web, MagicLens achieves comparable or better results on eight benchmarks of various image retrieval tasks than prior state-of-the-art (SOTA) methods. Remarkably, it outperforms previous SOTA but with a 50X smaller model size on multiple benchmarks. Additional human analyses on a 1.4M-image unseen corpus further demonstrate the diversity of search intents supported by MagicLens.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Information Retrieval,Computer Science - Multimedia},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\SelfSupervised\MagicLens_Zhang_et_al_2024.pdf}
}

@article{zhangMetafluidicMetamaterialReview2018,
  title = {Metafluidic Metamaterial: A Review},
  shorttitle = {Metafluidic Metamaterial},
  author = {Zhang, Wu and Song, Qinghua and Zhu, Weiming and Shen, Zhongxiang and Chong, Peter and Tsai, Din Ping and Qiu, Chengwei and Liu, Ai Qun},
  date = {2018-01},
  journaltitle = {Advances in Physics: X},
  volume = {3},
  number = {1},
  pages = {1417055},
  issn = {2374-6149},
  doi = {10.1080/23746149.2017.1417055},
  url = {https://www.tandfonline.com/doi/full/10.1080/23746149.2017.1417055},
  urldate = {2023-09-05},
  abstract = {Metafluidic metamaterial is a metamaterial the optical response of which is dependent on fluid contributed metamolecules. The dependence originates either from a fluid background coupling to the metamolecule or from the resonance in a liquid structured metamolecule. Different liquid materials including water, liquid crystal, and liquid metals are applied to realize the metafluidic metamaterial. Sophisticated technologies like electric bias and microfluidic system have been used for active control of metafluidic metamaterials which provide a new platform for electromagnetic wave manipulation and metadevice realization. The liquid background and significant tunability of the metafluidic metamaterial promise numerous applications, such as material sensing, bio-detection, energy harvesting, and imaging, just to name a few.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\OneDrive - Faculty Of Science (Sohag University)\Research\Photonics\Materials\Metamaterial\Metafluidic_metamaterial_Zhang_et_al_2018.pdf}
}

@online{zhangMonST3RSimpleApproach2024,
  title = {{{MonST3R}}: {{A Simple Approach}} for {{Estimating Geometry}} in the {{Presence}} of {{Motion}}},
  shorttitle = {{{MonST3R}}},
  author = {Zhang, Junyi and Herrmann, Charles and Hur, Junhwa and Jampani, Varun and Darrell, Trevor and Cole, Forrester and Sun, Deqing and Yang, Ming-Hsuan},
  date = {2024-10-04},
  eprint = {2410.03825},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/2410.03825},
  urldate = {2024-10-23},
  abstract = {Estimating geometry from dynamic scenes, where objects move and deform over time, remains a core challenge in computer vision. Current approaches often rely on multi-stage pipelines or global optimizations that decompose the problem into subtasks, like depth and flow, leading to complex systems prone to errors. In this paper, we present Motion DUSt3R (MonST3R), a novel geometry-first approach that directly estimates per-timestep geometry from dynamic scenes. Our key insight is that by simply estimating a pointmap for each timestep, we can effectively adapt DUST3R's representation, previously only used for static scenes, to dynamic scenes. However, this approach presents a significant challenge: the scarcity of suitable training data, namely dynamic, posed videos with depth labels. Despite this, we show that by posing the problem as a fine-tuning task, identifying several suitable datasets, and strategically training the model on this limited data, we can surprisingly enable the model to handle dynamics, even without an explicit motion representation. Based on this, we introduce new optimizations for several downstream video-specific tasks and demonstrate strong performance on video depth and camera pose estimation, outperforming prior work in terms of robustness and efficiency. Moreover, MonST3R shows promising results for primarily feed-forward 4D reconstruction.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Reconstruction\NeuralRadianceFields\Video\MonST3R_Zhang_et_al_2024.pdf}
}

@article{zhangNegativeRefractionAcoustic2004,
  title = {Negative Refraction of Acoustic Waves in Two-Dimensional Phononic Crystals},
  author = {Zhang, Xiangdong and Liu, Zhengyou},
  date = {2004-07-12},
  journaltitle = {Applied Physics Letters},
  volume = {85},
  number = {2},
  pages = {341--343},
  issn = {0003-6951, 1077-3118},
  doi = {10.1063/1.1772854},
  url = {https://pubs.aip.org/apl/article/85/2/341/912296/Negative-refraction-of-acoustic-waves-in-two},
  urldate = {2023-09-05},
  abstract = {Negative refraction of acoustic waves in two-dimensional phononic crystals has been demonstrated through both analysis and exact numerical simulation. The methods to achieve this behavior have been discussed. A microsuperlens for acoustic waves has also been designed. It is shown that refractive devices based on phononic crystals behave in a manner similar to that of optical systems. Therefore, a negative square root of the effective density or negative refraction index for acoustic waves can be introduced to describe this phenomena very well as the case of electromagnetic waves in the photonic crystals.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\PhononicCrystals\SpecialEffects\NegativeRefraction\Negative_refraction_of_acoustic_waves_in_two-dimensional_phononic_crystals_Zhang_Liu_2004.pdf}
}

@book{zhangNeuralNetworksModel2024,
  title = {Neural {{Networks}} with {{Model Compression}}},
  author = {Zhang, Baochang and Wang, Tiancheng and Xu, Sheng and Doermann, David},
  date = {2024},
  series = {Computational {{Intelligence Methods}} and {{Applications}}},
  publisher = {Springer Nature Singapore},
  location = {Singapore},
  doi = {10.1007/978-981-99-5068-3},
  url = {https://link.springer.com/10.1007/978-981-99-5068-3},
  urldate = {2024-12-10},
  isbn = {978-981-9950-67-6 978-981-9950-68-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Components\ModelCompression\Neural_Networks_with_Model_Compression_Zhang_et_al_2024.pdf}
}

@article{zhangRobustColorMedical2022,
  title = {Robust Color Medical Image Segmentation on Unseen Domain by Randomized Illumination Enhancement},
  author = {Zhang, Zuyu and Li, Yan and Shin, Byeong-Seok},
  date = {2022-06-01},
  journaltitle = {Computers in Biology and Medicine},
  volume = {145},
  pages = {105427},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2022.105427},
  url = {https://www.sciencedirect.com/science/article/pii/S0010482522002190},
  urldate = {2024-06-21},
  abstract = {Owing to the data distribution shifts generated by collecting images using various imaging protocols and device vendors, the generalization capability of deep models is crucial for medical image analysis when applied to test datasets in clinical environments. Domain generalization (DG) methods have shown promising generalization performance in the field of medical image segmentation. In contrast to conventional DG, which has strict requirements regarding the availability of multiple source domains, we consider a more challenging problem, that is, single-domain generalization (SDG), where only a single source is available during network training. In this scenario, the augmentation of the entire image to improve the model generalization ability may cause alteration of hue values, resulting in the wrong segmentation of tissues in color medical images. To resolve this problem, we first present a novel illumination-randomized SDG framework to improve the model generalization power for color medical image segmentation by synthesizing randomized illumination maps. Specifically, we devise unsupervised retinex-based image decomposition neural networks (ID-Nets) to decompose color medical images into reflectance and illumination maps. Illumination maps are augmented by performing illumination randomization to generate medical color images under diverse illumination conditions. Second, to measure the quality of retinex-based image decomposition, we devise a novel metric, the transport gradient consistency index, by modeling physical illumination. Extensive experiments are performed to evaluate our proposed framework on two retinal fundus image segmentation tasks: optic cup and disc segmentation. The experimental results demonstrate that our framework outperforms other SDG and image enhancement methods, surpassing the state-of-the-art SDG methods by up to 9.6\% with respect to the Dice coefficient.},
  keywords = {Domain generalization,Image enhancement,Medical image segmentation},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\ComputerVision\ImageSegmentation\Robust_color_medical_image_Zhang_et_al_2022.pdf}
}

@inproceedings{zhangTomoWearableLowCost2015,
  title = {Tomo: {{Wearable}}, {{Low-Cost Electrical Impedance Tomography}} for {{Hand Gesture Recognition}}},
  shorttitle = {Tomo},
  booktitle = {Proceedings of the 28th {{Annual ACM Symposium}} on {{User Interface Software}} \& {{Technology}}},
  author = {Zhang, Yang and Harrison, Chris},
  date = {2015-11-05},
  pages = {167--173},
  publisher = {ACM},
  location = {Charlotte NC USA},
  doi = {10.1145/2807442.2807480},
  url = {https://dl.acm.org/doi/10.1145/2807442.2807480},
  urldate = {2024-07-08},
  abstract = {We present Tomo, a wearable, low-cost system using Electrical Impedance Tomography (EIT) to recover the interior impedance geometry of a user’s arm. This is achieved by measuring the cross-sectional impedances between all pairs of eight electrodes resting on a user’s skin. Our approach is sufficiently compact and low-powered that we integrated the technology into a prototype wrist- and armband, which can monitor and classify gestures in real-time. We conducted a user study that evaluated two gesture sets, one focused on gross hand gestures and another using thumb-to-finger pinches. Our wrist location achieved 97\% and 87\% accuracies on these gesture sets respectively, while our arm location achieved 93\% and 81\%. We ultimately envision this technique being integrated into future smartwatches, allowing hand gestures and direct touch manipulation to work synergistically to support interactive tasks on small screens.},
  eventtitle = {{{UIST}} '15: {{The}} 28th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-3779-3},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Applications\MedicalApplications\Wearable\Tomo_Zhang_Harrison_2015.pdf}
}

@inproceedings{zhaoAdaptiveMultigridMethod2007,
  title = {An {{Adaptive Multigrid Method For EIT}}},
  booktitle = {2007 {{IEEE Instrumentation}} \& {{Measurement Technology Conference IMTC}} 2007},
  author = {Zhao, Bo and Wang, Huaxiang and {Li Hu} and Xu, L. and Yan, Y.},
  date = {2007-05},
  pages = {1--4},
  publisher = {IEEE},
  location = {Warsaw, Poland},
  issn = {1091-5281},
  doi = {10.1109/IMTC.2007.379236},
  url = {http://ieeexplore.ieee.org/document/4258253/},
  urldate = {2024-07-08},
  abstract = {This paper presents an adaptive multigrid method used in both the forward and inverse problems. The proposed method combines adaptive mesh and multigrid solution strategy to resolve theforwardproblem. The accuracy and efficiency of the former forward solver are improved by incorporating the above two procedures. For image reconstruction the regularized Gauss-Newton method combined with adaptive multigrid method can improve the spatial resolution of reconstructed images. Both experimental and simulated results are presented.},
  eventtitle = {2007 {{IEEE Instrumentation}} \& {{Measurement Technology Conference IMTC}} 2007},
  isbn = {978-1-4244-1080-4 978-1-4244-0588-6},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Multigrid\An_Adaptive_Multigrid_Method_For_EIT_Zhao_et_al_2007.pdf}
}

@article{zhaoFoundationModelJoint2024,
  title = {A Foundation Model for Joint Segmentation, Detection and Recognition of Biomedical Objects across Nine Modalities},
  author = {Zhao, Theodore and Gu, Yu and Yang, Jianwei and Usuyama, Naoto and Lee, Ho Hin and Kiblawi, Sid and Naumann, Tristan and Gao, Jianfeng and Crabtree, Angela and Abel, Jacob and Moung-Wen, Christine and Piening, Brian and Bifulco, Carlo and Wei, Mu and Poon, Hoifung and Wang, Sheng},
  date = {2024-11-18},
  journaltitle = {Nat Methods},
  pages = {1--11},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/s41592-024-02499-w},
  url = {https://www.nature.com/articles/s41592-024-02499-w},
  urldate = {2025-01-02},
  abstract = {Biomedical image analysis is fundamental for biomedical discovery. Holistic image analysis comprises interdependent subtasks such as segmentation, detection and recognition, which are tackled separately by traditional approaches. Here, we propose BiomedParse, a biomedical foundation model that can jointly conduct segmentation, detection and recognition across nine imaging modalities. This joint learning improves the accuracy for individual tasks and enables new applications such as segmenting all relevant objects in an image through a textual description. To train BiomedParse, we created a large dataset comprising over 6 million triples of image, segmentation mask and textual description by leveraging natural language labels or descriptions accompanying existing datasets. We showed that BiomedParse outperformed existing methods on image segmentation across nine imaging modalities, with larger improvement on objects with irregular shapes. We further showed that BiomedParse can simultaneously segment and label all objects in an image. In summary, BiomedParse is an all-in-one tool for biomedical image analysis on all major image modalities, paving the path for efficient and accurate image-based biomedical discovery.},
  langid = {english},
  keywords = {Image processing,Machine learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\Medical\FoundationModel\A_foundation_model_for_joint_Zhao_et_al_2024.pdf}
}

@online{zhaoPSAvatarPointbasedMorphable2024,
  title = {{{PSAvatar}}: {{A Point-based Morphable Shape Model}} for {{Real-Time Head Avatar Animation}} with {{3D Gaussian Splatting}}},
  shorttitle = {{{PSAvatar}}},
  author = {Zhao, Zhongyuan and Bao, Zhenyu and Li, Qing and Qiu, Guoping and Liu, Kanglin},
  date = {2024-01-29},
  eprint = {2401.12900},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.12900},
  url = {http://arxiv.org/abs/2401.12900},
  urldate = {2024-04-04},
  abstract = {Despite much progress, achieving real-time high-fidelity head avatar animation is still difficult and existing methods have to trade-off between speed and quality. 3DMM based methods often fail to model non-facial structures such as eyeglasses and hairstyles, while neural implicit models suffer from deformation inflexibility and rendering inefficiency. Although 3D Gaussian has been demonstrated to possess promising capability for geometry representation and radiance field reconstruction, applying 3D Gaussian in head avatar creation remains a major challenge since it is difficult for 3D Gaussian to model the head shape variations caused by changing poses and expressions. In this paper, we introduce PSAvatar, a novel framework for animatable head avatar creation that utilizes discrete geometric primitive to create a parametric morphable shape model and employs 3D Gaussian for fine detail representation and high fidelity rendering. The parametric morphable shape model is a Point-based Morphable Shape Model (PMSM) which uses points instead of meshes for 3D representation to achieve enhanced representation flexibility. The PMSM first converts the FLAME mesh to points by sampling on the surfaces as well as off the meshes to enable the reconstruction of not only surface-like structures but also complex geometries such as eyeglasses and hairstyles. By aligning these points with the head shape in an analysis-by-synthesis manner, the PMSM makes it possible to utilize 3D Gaussian for fine detail representation and appearance modeling, thus enabling the creation of high-fidelity avatars. We show that PSAvatar can reconstruct high-fidelity head avatars of a variety of subjects and the avatars can be animated in real-time (\$\textbackslash ge\$ 25 fps at a resolution of 512 \$\textbackslash times\$ 512 ).},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\PSAvatar_Zhao_et_al_2024.pdf}
}

@online{zhaoThinPlateSplineMotion2022,
  title = {Thin-{{Plate Spline Motion Model}} for {{Image Animation}}},
  author = {Zhao, Jian and Zhang, Hui},
  date = {2022-03-28},
  eprint = {2203.14367},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2203.14367},
  url = {http://arxiv.org/abs/2203.14367},
  urldate = {2024-03-08},
  abstract = {Image animation brings life to the static object in the source image according to the driving video. Recent works attempt to perform motion transfer on arbitrary objects through unsupervised methods without using a priori knowledge. However, it remains a significant challenge for current unsupervised methods when there is a large pose gap between the objects in the source and driving images. In this paper, a new end-to-end unsupervised motion transfer framework is proposed to overcome such issue. Firstly, we propose thin-plate spline motion estimation to produce a more flexible optical flow, which warps the feature maps of the source image to the feature domain of the driving image. Secondly, in order to restore the missing regions more realistically, we leverage multi-resolution occlusion masks to achieve more effective feature fusion. Finally, additional auxiliary loss functions are designed to ensure that there is a clear division of labor in the network modules, encouraging the network to generate high-quality images. Our method can animate a variety of objects, including talking faces, human bodies, and pixel animations. Experiments demonstrate that our method performs better on most benchmarks than the state of the art with visible improvements in pose-related metrics.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\Thin-Plate_Spline_Motion_Zhao_Zhang_2022.pdf}
}

@online{zhengFree3DConsistentNovel2024,
  title = {{{Free3D}}: {{Consistent Novel View Synthesis}} without {{3D Representation}}},
  shorttitle = {{{Free3D}}},
  author = {Zheng, Chuanxia and Vedaldi, Andrea},
  date = {2024-03-30},
  eprint = {2312.04551},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.04551},
  url = {http://arxiv.org/abs/2312.04551},
  urldate = {2024-05-05},
  abstract = {We introduce Free3D, a simple accurate method for monocular open-set novel view synthesis (NVS). Similar to Zero-1-to-3, we start from a pre-trained 2D image generator for generalization, and fine-tune it for NVS. Compared to other works that took a similar approach, we obtain significant improvements without resorting to an explicit 3D representation, which is slow and memory-consuming, and without training an additional network for 3D reconstruction. Our key contribution is to improve the way the target camera pose is encoded in the network, which we do by introducing a new ray conditioning normalization (RCN) layer. The latter injects pose information in the underlying 2D image generator by telling each pixel its viewing direction. We further improve multi-view consistency by using light-weight multi-view attention layers and by sharing generation noise between the different views. We train Free3D on the Objaverse dataset and demonstrate excellent generalization to new categories in new datasets, including OmniObject3D and GSO. The project page is available at https://chuanxiaz.com/free3d/.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\3DGeneration\Free3D_Zheng_Vedaldi_2024.pdf}
}

@article{zhernovayaRefractiveIndexHuman2011,
  title = {The Refractive Index of Human Hemoglobin in the Visible Range},
  author = {Zhernovaya, O and Sydoruk, O and Tuchin, V and Douplik, A},
  date = {2011-07-07},
  journaltitle = {Phys. Med. Biol.},
  volume = {56},
  number = {13},
  pages = {4013--4021},
  issn = {0031-9155, 1361-6560},
  doi = {10.1088/0031-9155/56/13/017},
  url = {https://iopscience.iop.org/article/10.1088/0031-9155/56/13/017},
  urldate = {2024-04-21},
  abstract = {Because the refractive index of hemoglobin in the visible range is sensitive to the hemoglobin concentration, optical investigations of hemoglobin are important for medical diagnostics and treatment. Direct measurements of the refractive index are, however, challenging; few such measurements have previously been reported, especially in a wide wavelength range. We directly measured the refractive index of human deoxygenated and oxygenated hemoglobin for nine wavelengths between 400 and 700 nm for the hemoglobin concentrations up to 140 g l−1. This paper analyzes the results and suggests a set of model functions to calculate the refractive index depending on the concentration. At all wavelengths, the measured values of the refractive index depended on the concentration linearly. Analyzing the slope of the lines, we determined the specific refraction increments, derived a set of model functions for the refractive index depending on the concentration, and compared our results with those available in the literature. Based on the model functions, we further calculated the refractive index at the physiological concentration within the erythrocytes of 320 g l−1. The results can be used to calculate the refractive index in the visible range for arbitrary concentrations provided that the refractive indices depend on the concentration linearly.},
  langid = {english},
  file = {/Users/ayman/Library/CloudStorage/OneDrive-FacultyOfScience(SohagUniversity)/Research/Photonics/Materials/BioMaterial/The_refractive_index_of_human_Zhernovaya_et_al_2011.pdf}
}

@online{zhuChampControllableConsistent2024,
  title = {Champ: {{Controllable}} and {{Consistent Human Image Animation}} with {{3D Parametric Guidance}}},
  shorttitle = {Champ},
  author = {Zhu, Shenhao and Chen, Junming Leo and Dai, Zuozhuo and Xu, Yinghui and Cao, Xun and Yao, Yao and Zhu, Hao and Zhu, Siyu},
  date = {2024-03-21},
  eprint = {2403.14781},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.14781},
  url = {http://arxiv.org/abs/2403.14781},
  urldate = {2024-04-13},
  abstract = {In this study, we introduce a methodology for human image animation by leveraging a 3D human parametric model within a latent diffusion framework to enhance shape alignment and motion guidance in curernt human generative techniques. The methodology utilizes the SMPL(Skinned Multi-Person Linear) model as the 3D human parametric model to establish a unified representation of body shape and pose. This facilitates the accurate capture of intricate human geometry and motion characteristics from source videos. Specifically, we incorporate rendered depth images, normal maps, and semantic maps obtained from SMPL sequences, alongside skeleton-based motion guidance, to enrich the conditions to the latent diffusion model with comprehensive 3D shape and detailed pose attributes. A multi-layer motion fusion module, integrating self-attention mechanisms, is employed to fuse the shape and motion latent representations in the spatial domain. By representing the 3D human parametric model as the motion guidance, we can perform parametric shape alignment of the human body between the reference image and the source video motion. Experimental evaluations conducted on benchmark datasets demonstrate the methodology's superior ability to generate high-quality human animations that accurately capture both pose and shape variations. Furthermore, our approach also exhibits superior generalization capabilities on the proposed wild dataset. Project page: https://fudan-generative-vision.github.io/champ.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageAnimation\Champ_Zhu_et_al_2024.pdf}
}

@inproceedings{zhuEITkitElectricalImpedance2021,
  title = {{{EIT-kit}}: {{An Electrical Impedance Tomography Toolkit}} for {{Health}} and {{Motion Sensing}}},
  shorttitle = {{{EIT-kit}}},
  booktitle = {The 34th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Zhu, Junyi and Snowden, Jackson C and Verdejo, Joshua and Chen, Emily and Zhang, Paul and Ghaednia, Hamid and Schwab, Joseph H and Mueller, Stefanie},
  date = {2021-10-10},
  pages = {400--413},
  publisher = {ACM},
  location = {Virtual Event USA},
  doi = {10.1145/3472749.3474758},
  url = {https://dl.acm.org/doi/10.1145/3472749.3474758},
  urldate = {2024-07-08},
  eventtitle = {{{UIST}} '21: {{The}} 34th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  isbn = {978-1-4503-8635-7},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\SpecialTopics\Frameworks\OtherFrameworks\EITkit\EIT-kit_Zhu_et_al_2021.pdf}
}

@article{zhuEmotionRecognitionBased2024,
  title = {Emotion Recognition Based on Brain-like Multimodal Hierarchical Perception},
  author = {Zhu, Xianxun and Huang, Yao and Wang, Xiangyang and Wang, Rui},
  date = {2024-05-01},
  journaltitle = {Multimed Tools Appl},
  volume = {83},
  number = {18},
  pages = {56039--56057},
  issn = {1573-7721},
  doi = {10.1007/s11042-023-17347-w},
  url = {https://doi.org/10.1007/s11042-023-17347-w},
  urldate = {2025-01-07},
  abstract = {Emotion recognition has gained prominence in diverse applications ranging from safe driving and e-commerce to healthcare. Traditional approaches have often relied on single-modal information such as visual, audio, or text, resulting in limitations in both reliability and robustness. To address these shortcomings, we introduce a brain-inspired computing model for emotion recognition that mimics the hierarchical processing characteristics of human cognitive functions. This innovative model accommodates multimodal information cohesively, aiming to emulate the human cognitive process across visual, audio, and text. To gain a better grasp of our brain-like hierarchical perception architecture, we stratify the model into three key layers: feature extraction, fusion, and decision-making. This structure integrates cognitive mechanisms with machine learning algorithms for enhanced performance. Specifically, we begin by extracting deep features that emulate the human brain’s perception of emotional cues. These features are then synthesized using a cross-attention mechanism to explore inter-modal correlations. Finally, the aggregated emotional data is categorized and recognized. Experimental results indicate that our approach achieves an average recognition accuracy of \$\$82.7\textbackslash\%\$\$across four distinct emotion classifications, showcasing its effectiveness and offering a fresh perspective for multimodal emotion recognition.},
  langid = {english},
  keywords = {Brain-like perception,Emotion recognition,Multimodal},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Architechtures\ConvolutionalNeuralNetwork\HierarchicalFeature\Emotion_recognition_based_on_Zhu_et_al_2024.pdf}
}

@article{zhuOnDemandInverseDesign2024,
  title = {An {{On-Demand Inverse Design Method}} for {{Nanophotonic Devices Based}} on {{Generative Model}} and {{Hybrid Optimization Algorithm}}},
  author = {Zhu, Lu and Li, Yue and Yang, Zhikang and Zong, Danlong and Liu, Yuanyuan},
  date = {2024-06-01},
  journaltitle = {Plasmonics},
  volume = {19},
  number = {3},
  pages = {1279--1290},
  issn = {1557-1963},
  doi = {10.1007/s11468-023-02075-6},
  url = {https://doi.org/10.1007/s11468-023-02075-6},
  urldate = {2024-06-01},
  abstract = {The inverse design of nanophotonic devices has been widely concerned by researchers, and on-demand design is the difficulty of inverse design. In inverse design, researchers usually define a target spectrum based on the performance indicators and experiences and then inverse design the structural parameters from the target spectrum. Due to the uncertainty of inverse design and “one-to-many” problem, it is not usually possible to guarantee that the target spectrum is sure to correspond to a real nanostructure. In order to solve these problems, an inverse design method combining generative model and genetic algorithm is proposed in this paper. Before the inverse design, the real spectrum is compressed into a latent space by the generation model, and then, the target spectrum is decoded from the latent space according to the performance index. Finally, the hybrid optimization algorithm combining genetic algorithm and forward prediction network is used to optimize the generated spectrum. The design method follows the process from performance indicators to target spectrum to structural parameter, and we successfully realized the inverse design of multilayer nanofilms on demand by using this method in the experimental part. The inverse design method proposed in this paper provides a possible solution for the inverse design of nanophotonic devices on demand.},
  langid = {english},
  keywords = {Deep learning,Genetic algorithm,Inverse design,Nanofilms},
  file = {C:\Users\ahmed\OneDrive\Research\Photonics\InverseDesign\AI\OneDimension\An_On-Demand_Inverse_Design_Zhu_et_al_2024.pdf}
}

@inproceedings{zhuUnifiedMultivariateGaussian2022,
  title = {Unified {{Multivariate Gaussian Mixture}} for {{Efficient Neural Image Compression}}},
  author = {Zhu, Xiaosu and Song, Jingkuan and Gao, Lianli and Zheng, Feng and Shen, Heng Tao},
  date = {2022},
  pages = {17612--17621},
  url = {https://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Unified_Multivariate_Gaussian_Mixture_for_Efficient_Neural_Image_Compression_CVPR_2022_paper.html},
  urldate = {2024-11-26},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\AI\GenerativeAI\ImageCodec\Unified_Multivariate_Gaussian_Zhu_et_al_2022.pdf}
}

@inproceedings{zhuVDNNeRFResolvingShapeRadiance2023,
  title = {{{VDN-NeRF}}: {{Resolving Shape-Radiance Ambiguity}} via {{View-Dependence Normalization}}},
  shorttitle = {{{VDN-NeRF}}},
  author = {Zhu, Bingfan and Yang, Yanchao and Wang, Xulong and Zheng, Youyi and Guibas, Leonidas},
  date = {2023},
  pages = {35--45},
  url = {https://openaccess.thecvf.com/content/CVPR2023/html/Zhu_VDN-NeRF_Resolving_Shape-Radiance_Ambiguity_via_View-Dependence_Normalization_CVPR_2023_paper.html},
  urldate = {2023-07-28},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Reconstruction\\NeuralRadianceFields\\Normalization\\VDN-NeRF_Zhu_et_al_2023.pdf;C\:\\Users\\ahmed\\OneDrive\\Research\\AI\\Reconstruction\\NeuralRadianceFields\\Normalization\\VDN-NeRF_Zhu_et_al_22.pdf}
}

@online{zieglerNeuralLinguisticSteganography2019,
  title = {Neural {{Linguistic Steganography}}},
  author = {Ziegler, Zachary M. and Deng, Yuntian and Rush, Alexander M.},
  date = {2019-09-03},
  eprint = {1909.01496},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1909.01496},
  urldate = {2024-10-07},
  abstract = {Whereas traditional cryptography encrypts a secret message into an unintelligible form, steganography conceals that communication is taking place by encoding a secret message into a cover signal. Language is a particularly pragmatic cover signal due to its benign occurrence and independence from any one medium. Traditionally, linguistic steganography systems encode secret messages in existing text via synonym substitution or word order rearrangements. Advances in neural language models enable previously impractical generation-based techniques. We propose a steganography technique based on arithmetic coding with large-scale neural language models. We find that our approach can generate realistic looking cover sentences as evaluated by humans, while at the same time preserving security by matching the cover message distribution with the language model distribution.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {C:\Users\ahmed\OneDrive\Research\AI\Application\LinguisticSteganography\Neural_Linguistic_Steganography_Ziegler_et_al_2019.pdf}
}

@online{zielonkaMetricalReconstructionHuman2022,
  title = {Towards {{Metrical Reconstruction}} of {{Human Faces}}},
  author = {Zielonka, Wojciech and Bolkart, Timo and Thies, Justus},
  date = {2022-10-19},
  eprint = {2204.06607},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2204.06607},
  urldate = {2023-08-26},
  abstract = {Face reconstruction and tracking is a building block of numerous applications in AR/VR, human-machine interaction, as well as medical applications. Most of these applications rely on a metrically correct prediction of the shape, especially, when the reconstructed subject is put into a metrical context (i.e., when there is a reference object of known size). A metrical reconstruction is also needed for any application that measures distances and dimensions of the subject (e.g., to virtually fit a glasses frame). State-of-the-art methods for face reconstruction from a single image are trained on large 2D image datasets in a self-supervised fashion. However, due to the nature of a perspective projection they are not able to reconstruct the actual face dimensions, and even predicting the average human face outperforms some of these methods in a metrical sense. To learn the actual shape of a face, we argue for a supervised training scheme. Since there exists no large-scale 3D dataset for this task, we annotated and unified small- and medium-scale databases. The resulting unified dataset is still a medium-scale dataset with more than 2k identities and training purely on it would lead to overfitting. To this end, we take advantage of a face recognition network pretrained on a large-scale 2D image dataset, which provides distinct features for different faces and is robust to expression, illumination, and camera changes. Using these features, we train our face shape estimator in a supervised fashion, inheriting the robustness and generalization of the face recognition network. Our method, which we call MICA (MetrIC fAce), outperforms the state-of-the-art reconstruction methods by a large margin, both on current non-metric benchmarks as well as on our metric benchmarks (15\% and 24\% lower average error on NoW, respectively).},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\ahmed\Zotero\storage\2GDLL8YC\Zielonka et al_2022_Towards Metrical Reconstruction of Human Faces.pdf}
}

@article{zongReviewAlgorithmsHardware2020,
  title = {A {{Review}} of {{Algorithms}} and {{Hardware Implementations}} in {{Electrical Impedance Tomography}}},
  author = {Zong, Zheng and Wang, Yusong and Wei, Zhun},
  date = {2020},
  journaltitle = {Progress In Electromagnetics Research},
  volume = {169},
  abstract = {In recent years, electrical impedance tomography (EIT) has attracted intensive interests due to its noninvasive, ionizing radiation-free, and low-cost advantages, which is promising for both biomedical imaging and industry nondestructive tests. The purpose of this paper is to review state-ofthe-art methods including both algorithms and hardware implementations in EIT. More specifically, for the advanced reconstruction algorithms in mainstream, we offer some insights on classification and comparison. As for the measurement equipment, the structure, configuration modes, and typical systems are reviewed. Furthermore, we discuss the limitations and challenges in EIT technique, such as low-spatial resolution and nonlinear-inversion problems, where future directions, such as solving EIT problems with deep learning, have also been addressed.},
  langid = {english},
  file = {C:\Users\ahmed\OneDrive\Research\InverseProblems\EIT\Traditional_methods\Review\A_Review_of_Algorithms_and_Hardware_Implementations_in_Electrical_Impedance_Zong_et_al_2020.pdf}
}
