\documentclass{standalone}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\usepackage[style=ieee, url=false,]{biblatex}
\usepackage{xcolor}
\usepackage{rotating}
\usepackage{pdflscape}
\usepackage{parskip}
\newcommand{\red}{\textcolor{red}}
\addbibresource{References.bib}
\usepackage[symbol]{footmisc}
\graphicspath{ {./images/} }
\usepackage{appendix}
\usepackage{subcaption}

\DeclareSourcemap{
  \maps[datatype=bibtex]{
    \map{
      \step[fieldsource=bold,
 match={true},
 final]
      \step[fieldset=usera, fieldvalue={true}]
 }
 }
}

% Redefine the article entry format
\DeclareBibliographyDriver{article}{%
  \printnames{author} % Print the authors' names
  \newunit\newblock
  \printfield{title} % Print the title of the article
  \newunit\newblock
  \printfield{journaltitle} % Print the journal title
  \setunit{\addspace} % Add space between journal title and volume
  \printfield{volume} % Print the volume number
% Optionally add number if needed:
%  \setunit*{\addcolon\space}
%  \printfield{number}
  \setunit*{\addcomma\space} % Add comma and space before pages
  \printfield{pages} % Print page numbers
  \setunit*{\addcomma\space} % Add comma and space before year
  \usebibmacro{date} % Use macro to print date/year 
  \finentry
}

\AtEveryBibitem{%
  \clearname{translator}
  \clearname{number}
  \clearlist{publisher}
  \clearlist{number}
  % \clearfiled{number}
%   \clearfield{pagetotal}
  \clearfield{file}
  \clearfield {pubstate}
  \clearfield {url}
  \clearfield {urldate}
  \clearfield{urlyear}
  \clearfield{urlmonth}
  \clearfield{doi}
  \clearfield{archiveprefix}
  \clearfield{keywords}
  \clearfield{eprint}
}

\pagenumbering{gobble}

\begin{document}
\onecolumn
\textbf{\large{Supplementary Materials: Compact Latent Representation for Image Compression (CLRIC)}}

\section{Additional Results}

\subsection{\textbf{Classical Distortion Metrics}}

Classical distortion metrics such as Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Multi-Scale SSIM (MS-SSIM) are not ideally suited for evaluating our approach. This is because the variational autoencoders employed in our method are trained using a perceptual image compression strategy \cite{rombachHighResolutionImageSynthesis2022, sauerFastHighResolutionImage2024, podellSDXLImprovingLatent2023}. These autoencoders typically achieve an average PSNR of around 25 dB \cite{rombachHighResolutionImageSynthesis2022}. Meanwhile, our model cannot exceed the PSNR of the autoencoder itself, as it operates on latent representations without accessing the original image data. 

We use classical distortion metrics as a reference point for comparing various learned image codecs. We calculated the average PSNR for both the Kodak Dataset (see Figure \ref{fig:KodakDataset_PSNR_MS_SSIM}) and the CLIC Professional Valid 2020 dataset (see Figure \ref{fig:professional_valid_2020_PSNR_MS_SSIM}). Our approach yields lower PSNR values compared to other learned compression models based on autoencoders, given that PSNR evaluates pixel-wise differences. However, our method provides synthetic textures that closely resemble those in the original images.

The maximum achievable PSNR with our technique is constrained by the maximum PSNR attainable by the original autoencoders (SD, SD-In, and SD-XL) used during training \cite{rombachHighResolutionImageSynthesis2022}.

PSNR increases with higher bitrate; however, it plateaus for models based on SD and SD-In. In contrast, achieving stability requires a higher bitrate when using SD-XL.

A similar trend is observed with MS-SSIM for both the Kodak Dataset and CLIC Professional Valid 2020 dataset (refer to Figures \ref{fig:KodakDataset_PSNR_MS_SSIM} and \ref{fig:professional_valid_2020_PSNR_MS_SSIM}, respectively).


\begin{figure}[h]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{all_PSNR_KodakDataset_compressed.pdf}
        % \caption{a}
        % \label{fig:all_PSNR_KodakDataset}
    \end{subfigure}
    \hfill
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\textwidth]{all_MS-SSIM_KodakDataset_compressed.pdf}
        % \caption{b}
        % \label{fig:all_MS-SSIM_KodakDataset}
    \end{subfigure}
    \caption{Comparison of PSNR and MS-SSIM metrics for our method and other learned image compression models on the Kodak dataset.}
    \label{fig:KodakDataset_PSNR_MS_SSIM}
\end{figure}

\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{all_PSNR_professional_valid_2020_compressed.pdf}
        % \caption{b}
        % \label{fig:all_PSNR_professional_valid_2020}
    \end{subfigure}
    \hfill
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{all_MS-SSIM_professional_valid_2020_compressed.pdf}
        % \caption{a}
        % \label{fig:all_MS-SSIM_professional_valid_2020}
    \end{subfigure}
    \caption{Evaluation of PSNR and MS-SSIM metrics for our method versus other learned image compression models on the CLIC Professional Valid 2020 dataset.}
    \label{fig:professional_valid_2020_PSNR_MS_SSIM}
\end{figure}

\subsection{\textbf{Continuous Quality Representation}}

In contrast to other learned image codecs based on autoencoders with a fixed number of quality levels, our method enables the representation of an image's latent variables at any desired quality level. This ranges from extremely low bitrates, where details are significantly blurred, to higher bitrates that closely resemble the original perceptual quality, as illustrated in \ref{fig:Continuous_Quality_Representation}

At very low bitrates, the image details appear highly blurred, and important structural information is lost. As the bitrate increases, the image quality improves until it becomes perceptually acceptable with enhanced detail.

% \begin{landscape}
\begin{figure}[h] % Using [p] to place figures on a separate page
    \centering   \includegraphics[width=\textwidth,height=1.9\textheight,keepaspectratio]{Continuous_Quality_Representation_compressed.png}
    \caption{Examples from the CLIC Professional Validation 2020 dataset demonstrating varying bitrates and corresponding quality levels.}
    \label{fig:Continuous_Quality_Representation}
\end{figure}
% \end{landscape}

\subsection{\textbf{Decoding Complexity Analysis of the overfitted neural function}}

In our study, we conducted a decoding complexity analysis of an overfitted neural function trained on latent from SD autoencoder. The results demonstrate that the decoding computational complexity of the overfitted function accounts for approximately 26 multiply-accumulate operations per pixel (MAC/Pixel). This complexity slightly decreases as the image size increases, as detailed in Table \ref{tab:complexity}.

This reduction in the overfitted neural function complexity as the number of pixels increases can be attributed to our approach's operation in latent space rather than directly in image space, which reduces the number of parameters involved.


\begin{table}[H]
    \centering
    \resizebox{\columnwidth}{!}{%
        % \begin{tabular}{|c|c|c|c|c|}
        \begin{tabular}{c c c c c}
            \hline
            Image size & Latent size & Overfitted Fun. (MAC/Pixel) \\ \hline
            512, 768   & 64 , 96     & 25.9              \\ %\hline
            1363, 2048 & 170, 256    & 25.48                       \\ \hline
        \end{tabular}
    }
    \caption{Analysis of decoding complexity of two images with different sizes.}
    \label{tab:complexity}
\end{table}


\subsection{\textbf{Limitations}}

Despite our method achieves state-of-the-art performance in perceptual image quality and low decoding complexity, it presents significant challenges related to encoding complexity and time. Encoding a single image takes approximately 10 minutes on an NVIDIA GeForce GTX 1080 Ti (11 GB) GPU, which limits its practicality for mobile devices. However, this approach could be advantageous for high-demand images or videos (in future work), as the training can be executed once on a server, making evaluation feasible across various devices. Another limitation is the challenge of accurate pixel-wise reconstruction. Although our method excels in perceptual similarity, it is not suitable for compression tasks that require precise pixel-wise fidelity.

\printbibliography

\section{Additional Figures}
\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{0.2_Kodak_19_bitrate_zoom_400_compressed.pdf}
\caption{Comparison of our approach against various models on image number 19 from the Kodak dataset.}
\label{fig:0.2_Kodak_19_bitrate_zoom_400}
\end{figure}


\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.05_CLIC2020_18_bitrate_zoom_300_compressed.pdf}
\caption{Comparison of our approach against various models on image number 18 from the CLIC Professional Valid 2020 dataset.}
\label{fig:0.05_CLIC2020_18_bitrate_zoom_300}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.05_CLIC2020_14_bitrate_zoom_300_compressed.pdf}
\caption{Comparison of our approach against various models on image number 14 from the CLIC Professional Valid 2020 dataset.}
\label{fig:0.05_CLIC2020_14_bitrate_zoom_300}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.05_CLIC2020_23_bitrate_zoom_300_compressed.pdf}
\caption{Comparison of our approach against various models on image number 23 from the CLIC Professional Valid 2020 dataset.}
\label{fig:0.05_CLIC2020_23_bitrate_zoom_300}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.05_CLIC2020_7_bitrate_zoom_300_compressed.pdf}
\caption{Comparison of our approach against various models on image number 7 from the CLIC Professional Valid 2020 dataset.}
\label{fig:0.05_CLIC2020_7_bitrate_zoom_300}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.2_CLIC2020_20_bitrate_zoom_300_compressed.pdf}
\caption{Comparison of our approach against various models on image number 20 from the CLIC Professional Valid 2020 dataset.}
\label{fig:0.2_CLIC2020_20_bitrate_zoom_300}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.05_Kodak_13_bitrate_zoom_400_compressed.pdf}
\caption{Comparison of our approach against various models on image number 13 from the Kodak dataset.}
\label{fig:0.05_Kodak_13_bitrate_zoom_400}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.05_CLIC2020_39_bitrate_zoom_300_compressed.pdf}
\caption{Comparison of our approach against various models on image number 39 from the CLIC Professional Valid 2020 dataset.}
\label{fig:0.05_CLIC2020_39_bitrate_zoom_300}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.2_CLIC2020_6_bitrate_zoom_300_compressed.pdf}
\caption{Comparison of our approach against various models on image number 6 from the CLIC Professional Valid 2020 dataset.}
\label{fig:0.2_CLIC2020_6_bitrate_zoom_300}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.05_CLIC2020_21_bitrate_zoom_300_compressed.pdf}
\caption{Comparison of our approach against various models on image number 21 from the CLIC Professional Valid 2020 dataset.}
\label{fig:0.05_CLIC2020_21_bitrate_zoom_300}
\end{figure*}

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{0.2_Kodak_22_bitrate_zoom_400_compressed.pdf}
\caption{Comparison of our approach against various models on image number 22 from the Kodak dataset.}
\label{fig:0.2_Kodak_22_bitrate_zoom_400}
\end{figure*}
\end{document}
