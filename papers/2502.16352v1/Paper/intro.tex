\section{Introduction}

Machine learning is increasingly being used to automate decision-making, enabling faster and more efficient information processing. 
In particular, classification models play a crucial role in efficiently identifying relevant information while minimizing manual review efforts.
However, in sensitive domains such as legal discovery, financial auditing, and medical diagnostics, a critical challenge is ensuring that classification models maintain high accuracy while preserving privacy.

% In this regard, \cite*{dong2022classification} recently introduced the multi-party classification problem for electronic discovery (e-discovery) in legal proceedings. 
To address this challenge, we focus on the classification problem in the context of legal discovery.
In the \emph{legal discovery process}, the plaintiff (Bob) issues a request for production to the defendant (Alice) seeking relevant evidence from the documents that Alice possesses. 
Alice is then accountable for identifying and providing the responsive (relevant) documents to Bob. 
To efficiently process massive amounts of electronic documents, technology-assisted review (TAR) tools are widely used in legal discovery to retrieve responsive documents with significantly less human review~\citep{grossman2010technology}. 
Despite its advantages, the adoption of TAR involves a potential concern that it may reduce accountability and transparency due to model bias, insufficient training data, or adversarial manipulation so as to hide unfavorable responsive documents.
To ensure the accuracy of Alice's classification, Bob may need to review a subset of documents, including nonresponsive ones. However, this process risks exposing private information from nonresponsive documents.
Thus, this raises a fundamental question: 
\emph{How can we verify classification correctness while minimizing the disclosure of nonresponsive documents?}


Several straightforward approaches could be considered \citep*{dong2022classification}: placing the burden of classification on Alice and holding her accountable; requiring Alice to disclose all documents to Bob; having Alice reveal all documents along with a classification mechanism (supplied by Bob) to a trusted third party, such as Trent (a court system or cloud provider); or asking the court to adjudicate the relevance of all documents.  
However, due to concerns regarding accountability, privacy, and efficiency, none of these approaches adequately address the fundamental question.  
Placing the burden on Alice makes classification accuracy dependent on her accountability and ethical obligations. This misaligns incentives, as her legal team is expected to assist an adversary, conflicting with their role~\citep{gelbach2015law}. Requiring Alice to disclose all documents compromises privacy, as nonresponsive documents may contain sensitive information. While confidentiality agreements exist, they are unreliable between untrusted parties. Expecting Bob to provide a meaningful classifier is impractical. He may struggle to encode a labeling strategy or require access to Alice’s documents. Worse, he could supply a corrupt classifier to extract sensitive information. Court adjudication exposes nonresponsive documents, compromising privacy, and incurs significant legal costs and delays.
Given these limitations, a more nuanced solution is necessary to balance accountability and privacy, while being efficient.

%\todosid{I like the way the above reads...perhaps we should write a few more concerns as to cost and computation as done by Dong et al.....and also their approach of highlighting why the straightforward way of achieving the task is not good....one  question is why can't the court just lable all the documents sine we are using them to adjudicate on conflicting documents......}
% \emph{How can we verify the correctness of a classification while minimizing disclosures of nonresponsive documents?}

%A few straightforward approaches could be putting the burden of classification on Alice and holding them accountable; or asking Alice to reveal all the documents to Bob; or to reveal all documents along with a classification mechanism (supplied by Bob) to a trusted third-party, say Trent (a court system or a cloud provider); and finally, to ask the court to adjudicate on the relevance of all the documents.
% However, due to accountability, privacy, and efficiency concerns, all the above approaches fail to address the fundamental question. 
% In the first approach, the accuracy and completeness of the process relies critically on the accountability of Alice (or their legal team) and their obligations under the rules of professional responsibility. There is a misalignment in the incentives of the Alice (or their legal team) and causes them, on the grounds of professional responsibility, to conduct work to benefit its adversary \citep{gelbach2015law}.
% In the second approach, there is a heavy loss of privacy that Alice suffers in that the nonresponsive documents could contain sensitive information. Of course, Alice and Bob could agree on a confidentiality agreement but we would like to rely as little as possible on external means of reliability, especially among non-trusted parties.
% In the third approach, the assumption that Bob is able to supply a meaningful classifier is iffy, as Bob may not be able to succinctly communicate such a  labeling strategy in the form of a machine executable classifier. For Bob to produce such a classifier they may require real documents that only Alice possesses. Further, Bob may also maliciously try to gain sensitive information by supplying a corrupt classifier.
% In the fourth approach, there is a leak of privacy for Alice as nonresponsive documents are revealed and of course there are costs involved with legal proceeding




% Placing the burden of classification on Alice makes classification accuracy dependent on her accountability and ethical obligations. This misaligns incentives, as her legal team is expected to assist an adversary, conflicting with their role~\cite{gelbach2015law}. 

% Several straightforward approaches do not adequately address this fundamental question due to concerns regarding accountability, privacy, and efficiency \citep*{dong2022classification}.
% %: placing the burden of classification on Alice and holding her accountable; requiring Alice to disclose all documents to Bob; having Alice reveal all documents along with a classification mechanism (supplied by Bob) to a trusted third party, such as Trent (a court system or cloud provider); or asking the court to adjudicate the relevance of all documents.  
% %However, due to concerns regarding accountability, privacy, and efficiency, none of these approaches adequately address the fundamental question.  
% Requiring Alice to disclose all documents to Bob compromises privacy, as nonresponsive documents may contain sensitive information. While confidentiality agreements exist, they are unreliable between untrusted parties. Having Alice reveal all documents along with a classification mechanism (supplied by Bob) to a trusted third party, such as Trent (a court system or cloud provider) is impractical. Bob may struggle to provide a meaningful classifier which requires access to real documents possessed by Alice. Worse, he could supply a corrupt classifier to extract sensitive information. Asking the court to adjudicate the relevance of all documents also exposes nonresponsive documents, compromising privacy, and incurs significant legal costs and delays.
% Given these limitations, a more nuanced solution is necessary to balance accountability and privacy, while being efficient.

% \begin{itemize}
%     \item {First approach}: Placing the burden on Alice makes the accuracy and completeness of the process heavily dependent on her accountability (or that of her legal team) and their ethical obligations under professional responsibility rules. This creates a misalignment of incentives, as Alice's legal team is expected to act in a manner that benefits their adversary, which is counter to their role \citep{gelbach2015law}.  

%     \item {Second approach}: Requiring Alice to disclose all documents leads to a significant privacy loss, as nonresponsive documents may contain sensitive information. While Alice and Bob could enter into a confidentiality agreement, relying on such external assurances is undesirable, particularly among parties that do not fully trust each other.  

%     \item {Third approach}: Assuming that Bob can supply a meaningful classifier is problematic. He may struggle to succinctly express a labeling strategy in the form of a machine-executable classifier. Moreover, Bob may require access to real documents—available only to Alice—to construct an effective classifier. Additionally, Bob could act maliciously by supplying a corrupt classifier to extract sensitive information.  

%     \item {Fourth approach}: Relying on the court to adjudicate document relevance compromises Alice’s privacy, as nonresponsive documents are exposed. Furthermore, legal proceedings introduce significant costs and delays.  
% \end{itemize}






In this regard, \cite{dong2022classification} recently introduced the multi-party classification problem for electronic discovery (e-discovery) in legal proceedings. 
They developed a multi-party protocol, using a trusted third party, that guarantees Bob receives all the responsive documents by verifying a minimal subset of nonresponsive documents. 
Thus, this protocol addresses the accountability issue while minimizing Alice's privacy loss. It has the further advantage of being computationally efficient and revealing all the responsive documents turns out to be Alice's best strategy.
However, their protocol has two limitations. 
First, it is designed specifically for linear classification (including kernel methods) in a realizable setting, where responsive and nonresponsive documents can be perfectly separated by a linear decision boundary. 
In contrast, real-world document embeddings or classifications produced by language models (such as LLMs) often result in complex decision boundaries that may not be linear or even realizable by a specific family of classifiers.
Recent work of \citet*{dong2024error} considers the nonrealizable setting, but only for linear classifiers with one-dimensional embedding.
Second, although the protocol by~\cite{dong2022classification} identifies a minimal set of nonresponsive documents necessary for verification, in the worst case, all documents are disclosed to Bob, leading to a complete exposure of private information in nonresponsive documents during verification.

In this work, we address the above issues. 
Firstly, we extend the multi-party classification protocol to a general family of classifiers with arbitrarily complex decision boundaries.
% A crucial sub-routine for \citet{dong2022classification} was a protocol to compute critical points (made clear later in the paper), and this is also the case for us.
% We mention that there is a \emph{crucial difference in our critical points protocol} which lets us extend to arbitrary decision boundaries.
A crucial subroutine in \citet{dong2022classification} was a protocol for computing critical points, a concept we clarify later in the paper. This is also essential in our setting.  
However, there is a \emph{key difference in our critical points protocol}, which enables us to extend to arbitrary family of classifiers.
Further, our protocol is efficient provided a membership oracle for the classifier family.
% \todosid{mention crucial difference in cpp and out protocol is efficient provided a membership oracle}
% Firstly, we generalize the multi-party classification problem to a general family of classifiers. 
% Secondly, we demonstrate that for a given family of classifiers, only a limited number of nonresponsive documents are required to verify the correctness of a classification, which is characterized by a combinatorial dimension of the family which we call the \emph{Leave-One-Out dimension}.
Secondly, we show that for a given family of classifiers, verifying the correctness of a classification requires disclosing only a limited number of nonresponsive documents. This number is characterized by a combinatorial measure, which we call the \emph{Leave-One-Out dimension}.
Hence, for certain families of classifiers we can significantly improve privacy guarantees while guaranteeing that Bob learns all the responsive documents. 
% We show non-trivial bounds on the Leave-One-Our dimension for the case for linear classifiers with sufficient margin via an indpendetly interesting geoemetric lemma invovoling orthogonal family of vectors.
We establish nontrivial bounds on the Leave-One-Out dimension for linear classifiers with sufficient margin, using an independently interesting geometric lemma involving a skew-orthogonal family of vectors.
Further, in the worst case (in a sense made precise later) the Leave-One-Out dimension also serves as a lower bound on the number of nonresponsive documents needed to be revealed so as to guarantee that Bob learns all the responsive documents.
Thirdly, we also analyze the non-realizable setting and show that a similar protocol is able to achieve accountability while minimizing Alice's privacy loss.
Here a robust version of the Leave-One-Out dimension plays the analogous role.
Finally, we demonstrate a protocol which works in a general non-realizable setting and only leaks a few nonresponsive documents per error in classification committed by Alice. This helps avoid undesirable feature in all previous protocols of revealing all the documents once a certain number of classification errors were detected.

% \todosid{need to add one liine about our reuslt about non-realizable and per error discolsure}
% Their protocol discloses all documents labeled as responsive by Alice and a specific subset of the remaining documents called critical points to Bob for verification. 
% By reviewing these documents, Bob either detects an error made by Alice or verifies Alice's classification is correct if all disclosed documents are labeled correctly. 

\input{Paper/model}

\subsection{Our Results}

% \todosid{mention something about the d=1 ....that we already get the leave-one-out dimension in this case is $2$ and further the imiplications for the error tolerant protocol????...if we have time}
In this work, we provide multi-party protocols that verify the correctness of a classification while minimizing the disclosure of nonresponsive documents in various settings.

A crucial quantity in our analysis is the following combinatorial concept, called the \emph{Leave-One-Out} dimension.
The Leave-One-Out dimension is closely related to the star number\footnote{See Definition 2 in Section 4 of \cite{hanneke2015minimax}.} introduced by~\cite{hanneke2015minimax}.
A set system consists of a set $X$ and a collection $\calS$ of subsets of $X$. 
We first define the following Leave-One-Out dimension of a set system. 

\begin{definition}[Leave-One-Out dimension]
\label{defn:leave_one_out}
     Given a set system $(X,\calS)$, the \emph{Leave-One-Out} dimension is the cardinality of the largest set $C\subseteq X$ such that for each element $c \in C$, there exists $S \in \calS$ with $S \cap C = \{c\}$.
\end{definition}

Consider a class of binary classifiers on $X$, denoted by $\calH = \{f:X \to \{-1,+1\}\}$. We define the associated set family as $\calS = \{f^+ : f \in \calH\}$ where $f^+ = \{x: f(x) = 1\}$ is the set of elements classified as positive by $f$. The \emph{Leave-One-Out} dimension of this classifier class $\calH$ is defined as the Leave-One-Out dimension of the set family $\calS$. This means there exists a set $C$ with size same as the Leave-One-Out dimension of $\calH$ such that for each element $c \in C$, a classifier $f \in \calH$ classifies this element as positive and all other elements  of $C$ as negative.   

Given a class $\calH$ of binary classifiers on $X$, an instance $(X,f)$ is realizable by this class if there exists a classifier $h \in \calH$ that perfectly classifies this instance, i.e. $h(x) = f(x)$ for any $x\in X$. Otherwise, this instance is called nonrealizable.

\textbf{Realizable Setting.} 
% We first consider the realizable setting where the true labels can be perfectly separated by a classifier from a general hypothesis class with an aribitrary decision boundary.
% We develop a multi-party classification protocol that verifies the correctness of a classification with a nonresponsive disclosure equal to the Leave-One-Out dimension of a hypothesis class.
% % for general hypothesis classes.
% % We introduce the Leave-One-Out dimension of a hypothesis class. 
% Our protocol guarantees that all responsive documents are retrieved, and that Alice's best strategy is being truthful. Further, the protocol is efficient provided an oracle $\calO$ to check membership of labelings in the hypothesis class. See \Cref{thm:protocol_realizable} for more details.
We first consider the realizable setting, where the true labels can be perfectly separated by a classifier from a general hypothesis class with an arbitrary decision boundary. We develop a multi-party classification protocol that verifies classification  correctness with perfect recall, ie, $1$, and with a nonresponsive disclosure equal to the Leave-One-Out dimension of the hypothesis class. 

Further Alice’s best strategy is to report labels truthfully. Moreover, the protocol remains efficient, assuming access to an oracle $\mathcal{O}$ that verifies label membership in the hypothesis class. 
Additionally, we show that any protocol with perfect recall, i.e., $\mathrm{Recall} = 1$, incurs a nonresponsive disclosure of at least one less than the Leave-One-Out dimension.
% Additionally, we show that any protocol with  perfect recall, ie, $\mathrm{Recall} = 1$ will suffer a nonresponsive disclosure of at least one lesser than the Leave-One-Out dimension.
% in the worst-case it is impossible to have nonresponsive disclosure lesser than the Leave-One-Out dimension while ensuring perfect recall, ie, $\mathrm{Recall} = 1$. 
See \Cref{thm:protocol_realizable} for further details.


\textbf{Linear Classification with Margin.}
We then consider the special case where the instance is realizable by the class of linear classifiers with a margin (see \Cref{defn:margin}).
We establish a fundamental trade-off between margin size and the number of nonresponsive disclosures required for verification. 
Specifically, for any instance in $\mathbb{R}^d$ that is linearly separable with margin $\gamma$, we show a trichotomy in the nonresponsive disclosure/Leave-One-Out dimension in Table~\ref{tab:margin_tradeoff}. See \Cref{thm:Leave-One-Out-linear-realizable} for more details.
Our protocol is efficient for the class of linear classifiers with a margin since there is an efficient oracle $\calO$ that verifies the label membership in this class using the hard support vector machine (SVM) (See Theorem 15.8 in~\citet*{shalev2014understanding}).
%\todosid{need to add that $\calO$ can also be made efficient using lemma in dong et al}

% \begin{table}[h]
%     \centering
%     \renewcommand{\arraystretch}{1.5}
%     \setlength{\tabcolsep}{10pt} % Adjust column spacing
%     \begin{tabular}{|c|c|c|c|}
%         \hline
%         \textbf{Margin $\gamma$} & $\boldsymbol{\gamma > \frac{1}{3}}$ & $\boldsymbol{\gamma = \frac{1}{3}}$ & $\boldsymbol{\gamma < \frac{1}{3}}$ \\
%         \hline
%         \textbf{Nonresponsive Disclosures / Leave-One-Out Dimension} & 
%         $\frac{2 + 2\gamma}{3\gamma - 1}$ & $\Omega(d)$ & $\exp\big(\Omega((\frac{1}{3} - \gamma)^2 d)\big)$ \\
%         \hline
%     \end{tabular}
%     \caption{Trade-off between margin size $\gamma$ and nonresponsive disclosures.}
%     \label{tab:margin_tradeoff}
% \end{table}
% \begin{table}[h]
%     \centering
%     \renewcommand{\arraystretch}{1.5}
%     \setlength{\tabcolsep}{10pt} % Adjust column spacing
%     \begin{tabular}{|p{3cm}|c|c|c|}
%         \hline
%         \textbf{Margin $\gamma$} & $\boldsymbol{\gamma > \frac{1}{3}}$ & $\boldsymbol{\gamma = \frac{1}{3}}$ & $\boldsymbol{\gamma < \frac{1}{3}}$ \\
%         \hline
%         \textbf{Nonresponsive Disclosures or Leave-One-Out Dimension} & 
%         $\frac{2 + 2\gamma}{3\gamma - 1}$ & $\Omega(d)$ & $\exp\big(\Omega((\frac{1}{3} - \gamma)^2 d)\big)$ \\
%         \hline
%     \end{tabular}
%     \caption{Trade-off between margin size $\gamma$ and nonresponsive disclosures.}
%     \label{tab:margin_tradeoff}
% \end{table}
\FloatBarrier
\begin{table}[ht]
    \centering
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{|m{4.8cm}|m{2cm}|m{2cm}|m{4cm}|}
        \hline
        \textbf{Margin $\gamma$} & \textbf{$\gamma > 1/3$} & \textbf{$\gamma = 1/3$} & \textbf{$\gamma < 1/3$} \\
        \hline
        \textbf{Nonresponsive Disclosures (Leave-One-Out dimension)}  & $\frac{2 + 2\gamma}{3\gamma - 1}$ & $\Omega(d)$ & $\exp(\Omega((1/3-\gamma)^2d))$ \\
        %(Leave-One-Out dimension) & & & \\
        \hline
    \end{tabular}
    \caption{Trade-off between margin size and nonresponsive disclosures (Leave-One-Out dimension) for instances in \(\mathbb{R}^d\) that are linearly separable with margin \(\gamma\).}
    \label{tab:margin_tradeoff}
\end{table}
\FloatBarrier


\begin{remark*}
    The above is a geometric statement about a skew-orthogonal family of vectors (see \Cref{lemma:skew-obtuse_lemma}) which we believe is of independent interest in combinatorial geometry and coding theory.
\end{remark*}

Hence, for instances linearly separable with margin $\gamma > 1/3$, our protocol verifies classification with at most 
$\frac{2 + 2\gamma}{3\gamma - 1}$
nonresponsive disclosures, independent of the total number of documents and dimension $d$. This result highlights the privacy benefits of using classifiers with large margins in the multi-party classification.
In the specific case of $d=1$ the Leave-One-Out dimension turns out to be $2$, since we can always assume $\gamma = 1$.

\textbf{Nonrealizable Setting.}
We then extend our protocols to the nonrealizable setting where the true labels can not be perfectly classified by any classifier in the hypothesis class.
In this setting, we introduce a robust verification protocol (see \Cref{sec:non_realizable}) that achieves a recall loss \emph{at most the error rate of the optimal classifier} in the hypothesis class with a nonresponsive disclosure equal to the \emph{Robust-Leave-One-Out} dimension. This parameter is a robust analogue of the Leave-One-Out dimension. See~\Cref{defn:robust_leave_one_out} for more details. 

% For linear classifiers, we prove that even in the nonrealizable setting, the Robust-Leave-One-Out dimension demonstrates the same trichotomy as the Leave-One-Out dimension albeit nuanced with the error rate of the optimal linear classifier. Specifically, when there exists a linear classifier with margin $\gamma >1/3^{rd}$ and at most $L$ misclassifications we have a nonresponsive disclosure of at most $\frac{(2+2L)(\gamma+1)}{3\gamma -1}$.
% Hence, even in the nonrealizable setting the nonresponsive disclosure reamin independent of the dimension as long as the margin is more than $1/3^{rd}$.

For linear classifiers, we prove that even in the nonrealizable setting, the Robust-Leave-One-Out dimension exhibits the same trichotomy as the Leave-One-Out dimension, albeit nuanced by the error rate of the optimal linear classifier. Specifically, if there exists a linear classifier with margin $\gamma > \frac{1}{3}$ and at most $L$ misclassifications, the nonresponsive disclosure is at most 

\[
\frac{(2+2L)(\gamma+1)}{3\gamma -1}.
\]

Thus, even in the nonrealizable setting, the nonresponsive disclosure remains independent of the dimension as long as the margin exceeds $\frac{1}{3}$.

% \todosid{Oracle might be efficient if we use avg margin}
\textbf{Error-Tolerant Protocol.} We also extend our protocols to a protocol that is tolerant of misclassification errors by Alice. 
In the above protocols, detecting a single misclassification made by Alice led to the disclosure of all documents to Bob. 
However, in practice, even the best human reviewer may make unintended mistakes in review tasks.
To address this, we convert our protocols to error-tolerant protocols that ensure the large recall guarantee while maintaining a small nonresponsive disclosure that scales with the number of errors made by Alice. The scaling factor is the Leave-One-Out or the Robust-Leave-One-Out dimension depending on the setting.
See \Cref{thm:error_tolerant_protocol} for more details.
% \todosid{subtle difference in the meaning of nonresponsive discolsure here, and we need to add an idea if we push this to appendix?}

\subsection{Related Work}

\cite{dong2022classification} introduced a multi-party classification problem and designed the critical points protocol that ensures that all responsive documents are disclosed while revealing as few nonresponsive documents as possible. 
Their approach relies on linear classification and the realizable setting where there exists a linear classifier that correctly classifies all documents. 
Later, \citet{dong2024error} extended this problem to the non-realizable setting, where all documents may not be perfectly classified by a linear classifier. 
They developed a protocol that for one-dimensional embedding of documents, ensures a recall loss at most the error rate of the optimal linear classifier, and discloses at most $O(\log n)$ nonresponsive documents. They further proposed a heuristic-based protocol for high-dimensional embedding, demonstrating its effectiveness through empirical evaluations.


Linear classification is widely studied in machine learning literature. 
In the realizable setting, where data is perfectly separable by a linear classifier, passive learning can achieve an error rate $\varepsilon$ using empirical risk minimization (ERM) with a sample complexity of $O(d/\varepsilon)$ on $d$ dimensional space~\citep{vapnik1998statistical}. Compared to passive learning, active learning, where the learner adaptively selects which data points to label, can significantly reduce the label complexity. Disagreement-based methods by~\citet*{balcan2006agnostic, hanneke2007bound} can achieve $\varepsilon$ error rate with $O(\Theta d\log (1/\varepsilon))$ queries where $\Theta$ is the disagreement coefficient.
For one-dimensional instances, to achieve a $1/n$ error rate, the passive learning and the active learning require $O(n)$ and $O(\log n)$ queries respectively, while verification only requires one query. For $d > 1$, in the worst case, both passive learning and active learning require $O(n)$ queries since the disagreement coefficient can be $1/n$.
Learning linear classifiers in the nonrealizable setting is known to be computationally hard in high dimensions~\citep*{kearns1994introduction,kalai2008agnostically,guruswami2009hardness}. 

\citet*{goldwasser2021interactive} studied a distinct two-party classification problem known as PAC verification, which is motivated by the delegation of computation. The goal in PAC verification is for the prover to convince the verifier that a given classifier is approximately correct, using significantly fewer labeled examples than would be required for the verifier to learn the classifier independently.
A key difference between their setting and ours is that in PAC verification, both the prover and verifier have access to the distribution of labeled data. In contrast, in our framework, only Alice has access to the labeled data distribution.

%\textbf{Verification and Accountability in Machine Learning.} The problem of verifying classification with minimal disclosure connects to broader research in machine learning accountability. Goldwasser et al. \cite{goldwasser2021pac} studied interactive protocols for PAC (Probably Approximately Correct) learning, where a verifier is convinced of a classifier's correctness with fewer labeled examples than required for independent training. Unlike their setting, where both parties have access to labeled data, the e-discovery problem requires verification when only the responding party initially possesses the documents. Other works in fairness and privacy-preserving machine learning \cite{dwork2012fairness, goldreich1987secure} also explore mechanisms to ensure trustworthy classification without compromising sensitive data.