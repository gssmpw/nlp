\section{Proof of Lemma~\ref{lemma:generalized-skew-obtuse_lemma}}\label{apx:proof_general_skew_obtuse}

In this section, we prove the size of the robust generalized skew-obtuse family of vectors. 

% \begin{lemma}[Robust Generalized Skew-Obtuse Family of Vectors]
% \label{lemma:generalized-skew-obtuse_appendix}
%     Let $V= \bar{v}_1,\bar{v}_2,\cdots, \bar{v}_k$ be a $k$ unit vectors in $\R^d$. Further, let  $W = w_1,w_2,\cdots, w_k$ be $k$ other unit vectors in $\R^d$. Suppose there exists $\alpha,\beta\in [0,1]$ and an error parameter $L$ such that the following holds:
%     \begin{enumerate}
%         \item $\inner{\bar{v}_i}{w_i} \geq \alpha$ and
%         \item for all $j\in [k]$ we have $\left|i\in[k]\colon  \inner{\bar{v}_i}{w_j} \leq -\beta\right|\geq k-1-L$. 
%     \end{enumerate}
%      Then, if $\alpha+2\beta>1$ we have $ k \leq \frac{(2+2L)(1+\beta)}{\alpha+2\beta-1}.$
%      % Further if $\gamma=1/3$, there exists a skew-obtuse family of vectors with $k\geq \Omega(d)$ and if $\gamma<1/3$ then with $k\geq \exp{(\Omega_{1/3-\gamma}(d))}$.
% \end{lemma}

\begin{proof}[Proof of Lemma~\ref{lemma:generalized-skew-obtuse_lemma}]
    Let $V= (\bar{v}_1,\bar{v}_2,\cdots, \bar{v}_k)^T$ be a $k\times d$ matrix. 
    Similarly, we define $W = (w_1,w_2,\cdots, w_k)^T$ be a $k\times d$ matrix. Then, we have $VW^T$ is a $k\times k$ matrix, where each entry is $\inner{\bar{v}_i}{w_j}$. 
    Let $\{a_1, a_2, \dots, a_d\}$ be the $d$ column vectors of matrix $V$. Let $\{b_1,b_2,\dots, b_d\}$ be the $d$ column vectors of $W$.

    We first consider the trace of matrix $VW^T$. Since each diagonal entry of $VW^T$ satisfies $\inner{\bar{v}_i}{w_j} \geq \alpha$, we have 
    $$
    \Tr(VW^T) = \sum_{i=1}^k \inner{\bar{v}_i}{w_i} \geq k \alpha.
    $$
    Since $\bar{v}_i$ and $w_i$ are all unit vectors, we have $\Tr(VW^T) \leq k$.
    We also have 
    $$
    \Tr(VW^T) = \Tr(WV^T) = \sum_{i=1}^d \inner{a_i}{b_i} = \sum_{i=1}^d \|a_i\|\|b_i\|\cos(\theta_i),
    $$
    where $\theta_i$ is the angle between vectors $a_i$ and $b_i$. Hence, we get
    \begin{equation}\label{eq:robust-trace}
    \sum_{i=1}^d \|a_i\|\|b_i\|\cos(\theta_i) = \Tr(VW^T) \geq k\alpha.
    \end{equation}

    We now consider the sum of all entries in matrix $VW^T$. 
    For each column $i \in [k]$ of the matrix $VW^T$, we know that there are at least $k-1-L$ off-diagonal entries with value at most $\inner{\bar{v}_j}{w_i} \leq -\beta$.
    For other off-diagonal entries in that column, we upper bound them by one since $\bar{v}_j$ and $w_i$ are unit vectors.
    We use $\one$ to denote all one vector. Then, we have the sum of all entries is
    $$
    \one^T VW^T \one = \Tr(VW^T) + \sum_{i\neq j} \inner{\bar{v}_j}{w_i} \leq \Tr(VW^T) - k(k-1 -L)\beta + kL.
    $$
    Note that $VW^T = \sum_{i=1}^d a_i b_i^T$. Thus, we have $\one^T VW^T \one = \sum_{i=1}^d \inner{\one}{a_i} \inner{b_i}{\one}$. Let $\phi_i$ be the angle between $\one$ and $-a_i$ and $\psi_i$ be the angle between $\one$ and $b_i$. Then, we have 
    $$
    - \one^T VW^T \one = \sum_{i=1}^d \inner{\one}{-a_i} \inner{b_i}{\one} = \sum_{i=1}^d \|\one\|^2 \|a_i\|\|b_i\| \cos(\phi_i) \cos(\psi_i). 
    $$
    Since the angle between $-a_i$ and $b_i$ is $\pi - \theta_i$, we have $\phi_i + \psi_i \geq \pi - \theta_i$. Since the cosine function is log-concave on $[0,\pi]$, we have 
    $$
    \cos(\phi_i) \cos(\psi_i) \leq \cos^2\left(\frac{\pi-\theta_i}{2}\right).
    $$
    By combining the equations above, we have
    \begin{align*}
    k \sum_{i=1}^d \|a_i\|\|b_i\| \cos^2\left(\frac{\pi-\theta_i}{2}\right) \geq - \one^T VW^T \one \geq - \Tr(VW^T) + k(k-1-L)\beta - kL.
    \end{align*}
    Since $\Tr(VW^T) \leq k$, we have
    \begin{equation}\label{eq:robust-all-sum}
        k \sum_{i=1}^d \|a_i\|\|b_i\| \cos^2\left(\frac{\pi-\theta_i}{2}\right) \geq -k+k(k-1-L)\beta - kL.
    \end{equation}

    By combining Equations~(\ref{eq:robust-trace}) and~(\ref{eq:robust-all-sum}), we have 
    $$
    \sum_{i=1}^d \|a_i\|\|b_i\| = \sum_{i=1}^d \|a_i\|\|b_i\| \left(2\cos^2\left(\frac{\pi-\theta_i}{2}\right) + \cos(\theta_i)\right) \geq k\alpha+(2k-2-2L)\beta -2 - 2L.
    $$
    By Cauchy-Schwarz inequality, we have 
    $$
    \left(\sum_{i=1}^d \|a_i\|\|b_i\| \right)^2 \leq \sum_{i=1}^d \|a_i\|^2 \cdot \sum_{i=1}^d \|b_i\|^2 = k^2,
    $$
    where the last equality is from $\sum_{i=1}^d \|a_i\|^2 = \sum_{i=1}^d \|b_i\|^2 = k$ since matrices $V$ and $W$ are both consists of $k$ unit row vectors. Therefore, we have 
    $$
    k \leq \frac{(2+2L)(\beta+1)}{\alpha + 2\beta-1}.
    $$

    % For the lower bounds see Lemma~\ref{lemma:constructing_skob_family}.
\end{proof}

