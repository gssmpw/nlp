\section{Discussion and Conclusion}
\label{discuss}
In this work, we studied bias conflict between different components---the LLM, embedder, and corpus---in RAG systems, and explored the possibility of mitigating bias in RAG by controlling the embedder. We showed through case studies on gender and political bias that, while bias conflict may seem unpredictable (\refsec{existing}), there exists a simple relationship explained through a linear model. Considering this relationship, we revealed that \emph{reverse biasing} the embedder can debias the overall RAG system (\refsec{debiasing}). Furthermore, we find that an optimal embedder on one corpus is still optimal for variations in the corpus bias (\refsec{corpus}). Below, we discuss the implications of our results and related work on bias measurement and mitigation in RAG. 

\paragraph{Debiasing Each Component}
Even with complex bias conflict in the entire RAG system, we show that debiasing can happen by simply reverse biasing the embedder. However, most work on bias in RAG has focused on making the retrieval process less biased. For example, \citet{Shrestha_2024_CVPR} reduce social bias in human image generation by retrieving demographically diverse images. \citet{chen2024unlockingmultiviewinsightsknowledgedense} enhance multi-perspective retrieval by rewriting the query to incorporate multiple perspectives. \citet{zhao2024beyond} increase perspective awareness by utilizing projections. \citet{kim2024towards} also increase fairness of retrieval by using stochastic rankings. For complex RAG systems of several modular components \citep{gao2024modular}, our results highlight that it is important to consider the conflict in bias among components and naively increasing fairness is not always the optimal solution for mitigating bias in RAG.

\paragraph{Bias Conflict}
To understand bias mitigation in RAG systems, we introduce the concept of \emph{bias conflict}. Similar to knowledge conflict \citep{mallen2022not,chen2022rich,longpre2021entity,xie2023adaptive}, bias conflict arises when parametric and non-parametric information differs. However, while knowledge conflict focuses on factuality, bias conflict assumes parametric and non-parametric information are both factually correct. Bias conflict also extends beyond the retrieved document and LLM, generally arising between components. In our work, we consider the two cases of (1) the LLM and embedder and (2) the embedder and corpus. We believe that factuality is not the sole conflict existing in RAG systems and more interest should be paid to other forms of conflict.

\paragraph{Traditional Gender Bias}
We have created \genderData which focuses on gender bias through names of public figures. This is different from traditional gender bias datasets that focus on association-based bias, measuring stereotypes by evaluating pronouns (he/she) or occupational bias \citep{lu2020gender,zmigrod2019counterfactual}. While LLMs are already RLHF fine-tuned to prevent association-based gender bias, they are not properly fine-tuned for names of figures. We believe that bias is not restricted to stereotypes and should be prevented regardless of the form. We hope \genderData can be used as a testbed for mitigating gender bias for figure names.

