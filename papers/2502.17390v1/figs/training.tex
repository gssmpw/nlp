\begin{figure*}[t]
    \centering
    \textbf{\genderData}\\
    \subfloat[Llama 8B]{\includegraphics[width=0.25\textwidth]{images/train-GenderBias-llama8-nq-1.png}} \hfill
    \subfloat[Llama 405B]{\includegraphics[width=0.25\textwidth]{images/train-GenderBias-llama405-nq-1.png}} \hfill
    \subfloat[Gemma 27B]{\includegraphics[width=0.25\textwidth]{images/train-GenderBias-gemma9-nq-1.png}} \hfill
    \subfloat[Mistral]{\includegraphics[width=0.25\textwidth]{images/train-GenderBias-mistral-nq-1.png}}
    \par\medskip
    \textbf{\politicalData}\\
    \subfloat[Llama 8B]{\includegraphics[width=0.25\textwidth]{images/train-PoliticBias-llama8-Pol_NLI-1.png}} \hfill
    \subfloat[Llama 405B]{\includegraphics[width=0.25\textwidth]{images/train-PoliticBias-llama405-Pol_NLI-1.png}} \hfill
    \subfloat[Gemma 27B]{\includegraphics[width=0.25\textwidth]{images/train-PoliticBias-gemma27-Pol_NLI-1.png}} \hfill
    \subfloat[Mistral]{\includegraphics[width=0.25\textwidth]{images/train-PoliticBias-mistral-Pol_NLI-1.png}}
    \caption{\textbf{Controlling Bias through Fine-tuning.} Linear relationship between the RAG bias ($R_b$) and embedder bias ($E_b$) for the 20 embedders. If the sensitivity $s$ is sufficiently high, it is possible to debias the entire RAG system ($R_b=0$). Results for all 6 LLMs are in \refapp{six-llms}.}
    \label{fig:training}
\end{figure*}