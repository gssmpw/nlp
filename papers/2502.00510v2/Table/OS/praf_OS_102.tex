\begin{table*}[h]
  \caption{Experimental Results on Operating System(102 pieces)}
  \label{tab:praf_OS}
  \centering
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{ccccccc}
    \toprule
    LLM & Pt & Rt & At & Ft & Reward (\%) & $\Delta$ Reward (\%) \\
    \midrule
    \texttt{Llama3-8B-instruct(Default)} 
    & - & - & - & - & 0.98 & - \\
    \texttt{claude-3.5-sonnet} & \textbf{0.0777} & \textbf{0.4578} & \textbf{0.0705} & -0.0079 & \textbf{60.78} & \textbf{+59.80}\\
    \texttt{gpt-4o-mini} & 0.0420 & 0.3050 & 0.0645 & \underline{0.0199} & 44.12 & +43.14\\
    \texttt{glm-4-airx} & 0.0465 & 0.3051 & 0.0414 & 0.0044 & 40.71 & +39.73\\
    \texttt{gpt-4-turbo-0409} & 0.0501 & \underline{0.3949} & \underline{0.0700} & 0.0045 & \underline{52.94} & \underline{+51.96}\\
    \texttt{qwen2.5-32b-ins} & 0.0596 & 0.3113 & 0.0531 & \textbf{0.0368} & 47.06 & +46.08\\
    \texttt{Mistral-7B-Instruct} & 0.0042 & 0.0465 & 0.0188 & 0.0188 & 9.80 & +8.82\\
    \texttt{Llama-3-70B-Instruct} & \underline{0.0769} & 0.3126 & 0.0397 & 0.0119 & 45.1 & +44.12\\
    \texttt{doubao-pro-4k} & 0.0645 & 0.2149 & 0.0597 & -0.0057 & 34.31 & +33.33\\
    \texttt{Mistral-8X7B-instruct} & 0.0318 & 0.1938 & 0.0089 & 0.0008 & 24.51 & +23.53\\
    \midrule
    \texttt{best} & / & / & / & / & \textit{60.78} & \textit{+59.80}\\
    \bottomrule
  \end{tabular}}
\end{table*}
