\section{Related Work}
%In this section, we comprehensively review the existing work on the latent space of generative models and the interpretability of diffusion models. 

\textbf{Image Manipulation in Diffusion Models.} The mainstream approaches**So et al., "Diffusion-based Image Manipulation"**, which manipulate the styles, poses or semantic contents of the generated images, are categorized as training-based methods, test-time fine-tuning methods, and training and fine-tuning free methods. A typical training-based approach**Kong et al., "Diffusion Models for Image Editing"** introduces a pre-trained classifier (e.g., CLIP)**Deng et al., "CLIP: A Contrastive Language-Image Pre-training Model"** as guidance to adjust the gradient during the diffusion process. Another fine-tuning approach attempts to fine-tune the entire diffusion model**Huang et al., "Diffusion Models for Image Synthesis"**, optimize the latent codes**Zhang et al., "Latent Code Optimization in Diffusion Models"** or the text-based embedding**Li et al., "Text-Based Embedding in Diffusion Models"** to manipulate the output contents. For example, Imagic**Kim et al., "Imagic: A Hybrid Fine-Tuning Method for Non-Rigid Text-Based Image Editing"** employs a hybrid fine-tuning method to achieve non-rigid text-based image editing by finding a representative latent for the target image. Some of the training and fine-tuning free methods**Wang et al., "Training and Fine-Tuning Free Methods in Diffusion Models"** tried to modify the attention map or the cross-attention map to manipulate outputs. Most of these works modify the generated images in an implicit way, which is based on new training data and motivated intuitively. However, our proposed method based on latent space could be more efficient and explainable without complex extra data collection and model fine-tuning. %\Yanran{I am not sure about this claim} 

\textbf{Interpretable Diffusion Models.} Although the latent space is fundamentally crucial to image manipulation and synthesis, few works have taken in-depth investigations. Some existing works**Park et al., "Local Basis Vectors for Attribute Editing"** attempted to add explicitly guidances into latent codes to manipulate the generation results. Kwon et al.**Kwon et al., "Exploring Semantic Correlation in Diffusion Models"** instead discovered a feature map, denoted as $h$-space, in between the bottleneck of U-Net in DMs that shows semantic correlation with text embeddings from CLIP. It can be used to learn vectors for manipulating attributes in generated images. Following this idea, Li et al.**Li et al., "Self-Supervised Learning for Attribute Editing"** designed a self-supervised approach to learn vectors in this auxiliary space for the generation of gender fairness and safe content. Park et al.**Park et al., "Local Basis Vectors for Attribute Editing"** attempt to discover the local basis vectors on the latent space for editing attributes, which relies on finding the principal singular vectors from the Jacobian matrix that bridge the latent space $\mathcal{X}$ and $h$-space. Their method needs manual interpretation to discern the impact of found basis vectors. Compared to them, our exploration is steered from this auxiliary space to the latent space $\mathcal{X}$ itself, and we find properties to hold across time steps and utilize them to perform efficient and versatile editing on generated images.


%found from mapping $h$-space to latent space $\mathcal{X}$ through a pullback metric, so that the visual attributes could be linearly edited by moving along the local basis vectors of $\mathcal{X}$ directly. They exclusively choose the principal singular value from the Jacobian matrix and rely on manual interpretation to discern the impact of each component on the editing process.