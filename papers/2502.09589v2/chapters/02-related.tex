\section{Related Work}
\label{sec:related}
\noindent \textbf{Logical reasoning benchmarks.}
Existing LLM logical reasoning benchmarks \interalia{liuLogiQAChallengeDataset2020a,hanFolioNaturalLanguage2024} focus on complex, multi-hop reasoning problems with manually annotated problems, making cross-problem comparisons challenging.
Recent work has introduced benchmarks with synthesized natural-language questions using predefined logical formulas and substitution rules \interalia{saparovLanguageModelsAre2022, saparovTestingGeneralDeductive2023, parmar-etal-2024-logicbench,wanLogicAskerEvaluatingImproving2024}.
Compared to them, our work uniquely incorporates modal logic, which has been largely unexplored in existing benchmarks---while \citet{hollidayConditionalModalReasoning2024} present a case study, our approach offers two key advances: controlled knowledge bias in logic interpretations (\cref{subsec:involved-logical-forms}) and a more rigorous statistical evaluation framework (\cref{sec:experiment-measure}).

\vspace{2pt}
\noindent \textbf{Propositional and modal logic reasoning in language models.}
Recent work has explored training and finetuning language models specifically for logical reasoning \citep{clark-etal-2021-transformers,hahn-etal-2021-teaching,tafjord-etal-2022-entailer}.
Our work differs in two key aspects: (1) we evaluate general-purpose language models through prompting, a cost-efficient setup that has been widely adopted in recent years, and we focus on propositional and alethic modal logic rather than temporal \citep{hahn-etal-2021-teaching} or epistemic \citep{sileo-lernould-2023-mindgames} logic; \footnote{Technically, any logic that involves non-truth-functional operators, including first-order logic, temporal logic, and epistemic logic, can be viewed as a modal logic; however, we adopt the most restrictive sense of \textit{modal logic} \citep{sep-logic-modal-origins} and use it interchangeably with \textit{alethic modal logic}.}
(2) unlike studies comparing LLM and human performance on categorical syllogisms \interalia{eisape-etal-2024-systematic},\footnote{
    We refer readers to \citet{zong-lin-2024-categorical} for a more comprehensive review of categorical syllogisms.} we focus on hypothetical and disjunctive syllogisms with considerations of modality.

\vspace{2pt}
\noindent\textbf{Human logic reasoning.}
Work on human reasoning capabilities has informed studies of LLM logical reasoning: \citet{eisape-etal-2024-systematic} compared LLM syllogistic reasoning with human behavior results \citep{ragniWhenDoesReasoner2019} under the framework of the Mental Models Theory \citep{johnson-1983-mental}; \citet{lampinenLanguageModelsHumans2024} found similar content effects in human and LLM reasoning, supporting the need to control for common-sense knowledge in benchmarks (\cref{subsec:syn-natural-language});
\citet{belemPerceptionsLinguisticUncertainty2024a} studied human and LLM perception of uncertainty at a lexical level.
Compared to them, we focus on the propositional and modal logic reasoning process and contribute new behavioral data.
