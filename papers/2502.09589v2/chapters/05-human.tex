\section{Human Experiments}
\label{sec:human}

LLMs are trained on text produced by humans and are able to generate plausible text; therefore, there have been interests in using LLMs as human models \interalia{eisape-etal-2024-systematic,misra-kim-2024-generating}.
Following this line of work, we conduct a human behavioral experiment to ground the LLM reasoning behavior.
Using samples from our primary dataset, we collected 710 responses from adults fluent in English through Prolific.\footnote{\url{https://prolific.com}}
More experiment details can be found in \cref{subsec:human-details}.

The average human accuracy on each group is shown in the last row of \cref{tab:softacc-base}.\footnote{Human responses are binary classes, so correct and incorrect responses are coded as $1$ and $0$, respectively.}
Aligned with our LLM results (\cref{sec:experiment}), on modalities, the overall human results also show an accuracy order of ($\Diamond \succ \varnothing \succ \Box$),
and on argument forms, modus ponens ($\to^\mathrm{L}$) is the most accurately answered pattern.

To further investigate the interactions of logic factors, we fit a generalized linear mixed-effects model \citep{batesFittingLinearMixedEffects2015} to verify the effect of modality and argument forms on human logic reasoning accuracy (\cref{eqn:mixed-effects-human} and \cref{fig:emmeans-human}).
\noindent
\begin{align}
    \mathrm{logit}(\mathit{Acc}) & \sim \textit{Modality} + \textit{ArgForm} + \textit{Rt} \nonumber \\
                                 & + (1 + \textit{Rt} \mid \textit{ParticipantID}),
    \label{eqn:mixed-effects-human}
\end{align}
\noindent
where $\mathit{Acc}$ is the binary accuracy of human responses, and $\textit{Rt}$ is the response time.
The generalized mixed-effects model yields a marginal $R^2$ of $0.121$ yet a $0.419$ conditional $R^2$, indicating a diverse response pattern across participants.
The likelihood ratio test on the full model against the null model shows that only the effect of argument form is significant ($\chi^2(2)=25.6$, $p<0.001$).
However, in accordance with the overall performance, we find modus ponens ($\to^\mathrm{L}$) has a significantly higher effect than the other two valid argument forms.
This confirms that logical forms can also have a significant impact on human reasoning accuracy, which is consistent with the LLM results, although the effect sizes are not the same.

\begin{figure}[!t]
    \centering
    \vspace{-5pt}
    \includegraphics[
        width=0.95\columnwidth,
        keepaspectratio,
    ]{emmeans-human.pdf}
    \vspace{-5pt}
    \caption{
        Estimated marginal means of logical form factors in the generalized mixed-effects model of \cref{eqn:mixed-effects-human}, along with their 95\% confidence intervals.
        \label{fig:emmeans-human}
    }
    \vspace{-10pt}
\end{figure}
