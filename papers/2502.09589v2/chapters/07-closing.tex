\section*{Limitations}
This work comes with two major limitations:
\begin{enumerate}[leftmargin=*,topsep=0pt,itemsep=0pt]
      \item While we have verified that our data has a low perplexity ($9.82\pm 2.47$ under mistral-7b; much lower than that of the data by \citet{wanLogicAskerEvaluatingImproving2024}, $25.44$), and, therefore, are similar enough to natural language utterances, the synthetic language cannot fully substitute natural language in daily life.
            Our dataset and analysis are not comprehensive enough to cover many nuanced examples that may appear in real communication, especially when context-dependent understanding is crucial to conveying communication goals.
      \item Despite more than 7,000 languages worldwide, as a first step, our material only covers English.
            This narrow focus is due to the languages the authors are proficient in and the coverage of the language models.
            We acknowledge the importance of extending the scope of this work to a more comprehensive set of languages and leave the extension as an immediate follow-up step.
\end{enumerate}

In addition, the sample size of human experiments is somewhat limited.
We leave more comprehensive human behavioral data collection and analysis to future work.

\section*{Ethics Statement}

While this work involves human logical reasoning experiments, we have ensured that (1) the data are generated procedurally following templates listed in the paper and (2) there is no harmful content in the atomic logical interpretations, reviewed by all the authors.
In addition, we have ensured that all participants are paid a fair wage through the Prolific platform.
Instructions and consent forms delivered to the participants can be found in the \cref{subsec:human-details}.
The institutional ethics review board has approved the data collection process.

This work contributes to the understanding of LLMs.
We do not foresee risk beyond the minimal risk posed by LLM evaluation work.
We acknowledge that using LLMs in real-world scenarios could significantly impact human behaviors, raising the need for model transparency, safety, security, and interpretability.
We will open-source the synthetic logical reasoning dataset upon publication.

\section{Acknowledgements}
We thank Yudong Li for his help in setting up the Gemini and OpenAI API for the experiments.
This work was supported in part by a Google PhD Fellowship and a Canada CIFAR AI Chair award to FS, as well as NSERC RGPIN-2024-04395.
