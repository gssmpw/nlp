\pdfoutput=1
\documentclass[11pt]{article}
\input{macros.tex}
\input{shorthand.tex}

\title{
    Logical forms complement probability \\
    in understanding language model (and human) performance
    % The cases of propositional and epistemic modal logic
}

\author{Yixuan Wang \\
  University of Chicago \\
  \texttt{yixuanwang@uchicago.edu} \\\And
  Freda Shi \\
  University of Waterloo \\
  Vector Institute, Canada CIFAR AI Chair \\
  \texttt{fhs@uwaterloo.ca} \\}

\begin{document}

\setlength{\Exlabelsep}{0em}
\setlength{\SubExleftmargin}{1em}

\maketitle
\begin{abstract}
  With the increasing interest in using large language models (LLMs) for planning in natural language, understanding their behaviors becomes an important research question.
  This work conducts a systematic investigation of LLMs' ability to perform logical reasoning in \textit{natural language}.
  We introduce a controlled dataset of hypothetical and disjunctive syllogisms in propositional and modal logic and use it as the testbed for understanding LLM performance.
  Our results lead to novel insights in predicting LLM behaviors: in addition to the probability of input \citep{gonen-etal-2023-demystifying,mccoyEmbersAutoregressionShow2024}, logical forms should be considered as important factors.
  In addition, we show similarities and discrepancies between the logical reasoning performances of humans and LLMs by collecting and comparing behavioral data from both.
\end{abstract}

\input{chapters/01-intro}
\input{chapters/02-related}
\input{chapters/03-dataset}
\input{chapters/04-experiments}
\input{chapters/05-human}
\input{chapters/06-discussion}
\input{chapters/07-closing}

%\freda{We will need to clean the bibliography before submitting it. Marking it as a todo for now.}
\bibliography{custom}

\appendix

\input{chapters/a1-responsible}
\input{chapters/a2-sample}
\input{chapters/a3-extra}

\end{document}
