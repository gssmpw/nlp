\section{Related Works}

\textbf{Diffusion Language Model.} Diffusion models have achieved remarkable performance in vision and audio tasks—especially in generation and editing. Building on these successes, there has been a growing interest in extending the diffusion framework to the text domain. A number of studies \cite{chen2023analog, lovelace2023latent, hoogeboom2021argmax, austin2021structured, sahoo2024simple, pmlr-v235-lou24a} have adopted diffusion framework for text generation and confirmed their effectiveness. Moreover, several works \cite{li2022diffusionlm, zhang2024language, gong2022diffuseq} have highlighted the controllability of these models in constrained scenarios-such as tasks involving parse trees or fixed sequence lengths-by leveraging various guidance techniques \cite{ho2021classifierfree, dhariwal2021diffusion} tailored for diffusion frameworks. Despite these strengths, the potential of diffusion language models for text editing—a task that could benefit significantly from their broad controllability—remains underexplored.

\textbf{Controlled Text Generation.} Many studies have focused on methods to control the generation process to align with user intentions. One prominent task, controlled text generation, seeks to produce text that adheres to specific constraint (i.e. fixed sequence length, parse-tree, or specific target attributes).
While some approaches leverage AR models for controlled text generation \cite{carlsson-etal-2022-fine, yang-etal-2023-tailor}, NAR models \cite{li2022diffusionlm, zhang-etal-2024-languageflow, mireshghallah-etal-2022-mix} often require fewer parameters and benefit from a parallel sampling process. This parallelism enables NAR models to consider the entire context of the textual input, facilitating smoother distribution shifts during the sampling process.

\textbf{Text Editing.} A task similar to controlled text generation is text editing, which involves modifying a given reference text to align with the user's intent. Text editing differs from controlled text generation in that it focuses on transforming existing content based on specific goals, rather than generating entirely new text from scratch. Several studies have proposed reference-based editing methods \cite{malmi-etal-2019-encode, du-etal-2022-read, laban2023chat, raheja-etal-2023-coedit}, while some are also known as controlled paraphrase generation \cite{ogasa-etal-2024-controllable, Dehghani2021ControllablePG, yang-etal-2022-gcpg} which focuses on specific constraints. However, these approaches generally lack mechanisms to control the degree of editing, making it difficult to achieve the desired level of transformation.

Some recent works have addressed this limitation. For example, \citet{mireshghallah-etal-2022-mix} employed an energy-based model (EBM) to adjust the degree of editing by weighting multiple target attributes during generation. Similarly, ParaGuide \cite{Horvitz_Patel_Callison-Burch_Yu_McKeown_2024} is a diffusion-based framework that uses classifier guidance to modulate editing intensity. While these methods can shift text toward the desired attribute, their control remains limited to micro-level adjustments. In contrast, our proposed model, EdiText, integrates diverse editing strategies within the diffusion framework, enabling text editing across multiple scales. The distinctions between general text generation, controlled text generation, and the varying-scale text editing targeted by our model are summarized in Figure \ref{fig:TextEditing}.
