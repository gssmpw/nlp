
\section{Related Work}
\label{sec:related}

Strategies to compute secure averages can be built depending on the level of trust put in the aggregator or in the users, on the utility and the verifability of results and lastly on the level of communication overhead.
Local differential privacy (LDP) \cite{Kasiviswanathan2008,d13,kairouz2015secure,Kairouz2016a,discrete_dis_local} does not require to trust the aggregator or users but brings litte utility and no verifability. The use of cryptographic primitives combined with DP \cite{pmlr-v139-kairouz21a,skellam} allows exact aggregation but is not verifiable, except \cite{Dwork2006ourselves}. It requires $\Omega(n)$ communication per party and does not reflect the impact of colluding/malicious users except \cite{Jayaraman2018} which relies on two non-coluding servers. Recently the shuffle model of privacy \cite{Cheu2019,amp_shuffling,Hartmann2019,Balle2020,Ghazi2020ICML} assumes honest-but-curious parties with high communication overhead but can match the utility of the trusted curator model. Lastly, the use of correlated Gausian noise \cite{imtiaz2021distributed, sabater2021accurate} can have utility of central models but only \cite{sabater2021accurate} can do it with malicious users and with only $O(\log n)$ communication.
