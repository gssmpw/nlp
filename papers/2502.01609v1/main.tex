\pdfoutput=1
% \documentclass{article} % For LaTeX2e
\documentclass[11pt, letterpaper, shortlabels]{berkeley}
% Optional math commands from https://github.com/goodfeli/dlbook_notation.
% \input{math_commands.tex}

% Recommended, but optional, packages for figures and better typesetting:

%\usepackage{algorithmic}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}
\usepackage{color-edits}

\newcommand{\ysy}[1]{\textcolor{blue}{{[ysy: #1]}}}
\newcommand{\czh}[1]{{\color{red} #1}}
\newcommand{\todo}{$\blacksquare$ TODO\xspace}
\newcommand{\eg}{{e.g.}}
\newcommand{\ie}{{i.e.}} 
\newcommand{\vs}{{v.s.}}
% \linespread{.98}
\usepackage{algorithm2e}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\ifx\assumption\undefined
\newtheorem{assumption}{Assumption}
\fi

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}
\makeatletter
\def\adl@drawiv#1#2#3{%
        \hskip.5\tabcolsep
        \xleaders#3{#2.5\@tempdimb #1{1}#2.5\@tempdimb}%
                #2\z@ plus1fil minus1fil\relax
        \hskip.5\tabcolsep}
\newcommand{\cdashlinelr}[1]{%
  \noalign{\vskip\aboverulesep
           \global\let\@dashdrawstore\adl@draw
           \global\let\adl@draw\adl@drawiv}
  \cdashline{#1}
  \noalign{\global\let\adl@draw\@dashdrawstore
           \vskip\belowrulesep}}
\makeatother
\newcommand{\method}{Agent-R\xspace}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \theoremstyle{plain}
% \theoremstyle{definition}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{assumption}[theorem]{Assumption}
% \theoremstyle{remark}
% \newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
%\usepackage[textsize=tiny]{todonotes}
\usepackage{wrapfig}
\captionsetup[figure]{font=small,skip=0pt}
\setlength{\belowcaptionskip}{0pt}


% ##########################################

% ##########################################

% ##########################################

% ##########################################

% ##########################################
% \documentclass{article} % For LaTeX2e
% \documentclass[11pt]{berkeley}

% \usepackage[preprint]{neurips_2023}
\title{Breaking Focus: Contextual Distraction Curse in Large Language Models}

\usepackage[all]{hypcap}

\usepackage[authoryear, round]{natbib}
% \bibliographystyle{plainnat}

\usepackage{hyperref}[citecolor=magenta,linkcolor=magenta]


\usepackage{multirow, makecell, caption}\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs} % for professional tables
%\usepackage{floatrow}
%\usepackage{float}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{nicefrac}
\usepackage{dsfont}
\usepackage{enumitem}
% \usepackage{minted}
%\usepackage{float}
\usepackage{arydshln}
\setlength\parindent{0pt}
% \setminted[python]{frame=lines, breaklines, framesep=2mm, fontsize=\footnotesize, numbersep=5pt}
%\usepackage{paralist}

% \usepackage[authoryear, sort&compress, round]{natbib}
\usepackage{xspace}
\usepackage[capitalize,noabbrev]{cleveref}
\bibliographystyle{plainnat}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{fontawesome5} % For \faLightbulb
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{soul}
\tcbuselibrary{skins, breakable, listings, theorems}
\usepackage{algpseudocode}
\usepackage{setspace}

\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}


% Python style for highlighting
\newcommand\pythonstyle{\lstset{
basicstyle=\ttfamily\footnotesize,
language=Python,
morekeywords={self, clip, exp, mse_loss, uniform_sample, concatenate, logsumexp},              % Add keywords here
keywordstyle=\color{deepblue}, % Custom highlighting style
stringstyle=\color{deepgreen},
frame=single,                         % Any extra options here
showstringspaces=false
}}

% Python environment
\lstnewenvironment{python}[1][]
{
\pythonstyle
\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

\definecolor{promptgray}{RGB}{200,200,200}
\definecolor{promptblue}{RGB}{25,118,210}
\definecolor{darkblue}{HTML}{0C2340}
\definecolor{gold}{HTML}{AE9142}


\newtcolorbox{promptbox}[2][]{%
    enhanced,
    unbreakable,
    before skip=2mm,
    after skip=2mm,
    colback=darkblue!5!white, 
    colframe=darkblue, 
    coltitle=white, 
    boxrule=0.5mm,
    sharp corners,
    arc=5pt,
    attach boxed title to top center={yshift=-3mm},
    boxed title style={
        enhanced,
        colback=gold, 
        colframe=darkblue,
        arc=5pt,
        outer arc=5pt,
        boxrule=0pt,
    },
    title={\faLightbulb[solid]\space #2},
    fonttitle=\bfseries\color{white}, 
    #1
}

% \newtcolorbox{promptbox}[2][]{%
%     enhanced,
%     unbreakable,
%     before skip=2mm,
%     after skip=2mm,
%     colback=promptgray!20!white,
%     colframe=promptblue!30!black,
%     coltitle=white,
%     boxrule=0.5mm,
%     sharp corners,
%     arc=5pt,
%     attach boxed title to top center={yshift=-3mm},
%     boxed title style={
%         enhanced,
%         colback=promptblue!50!white,
%         colframe=promptblue,
%         arc=5pt,
%         outer arc=5pt,
%         boxrule=0pt,
%     },
%     title={\faLightbulb[solid]\space #2},
%     fonttitle=\bfseries\color{white},
%     #1
% }


% % \input{defs.tex}
% % \input{}

\makeatletter
\def\mathcolor#1#{\@mathcolor{#1}}
\def\@mathcolor#1#2#3{%
  \protect\leavevmode
  \begingroup
    \color#1{#2}#3%
  \endgroup
}
\makeatother

\definecolor{NDblue}{RGB}{12, 35, 64} % ND Blue
\definecolor{NDgold}{RGB}{174, 145, 66} % ND Metallic Gold

\hypersetup{
    colorlinks = true,    
    linkcolor = NDblue,    
    citecolor = NDgold,   
    urlcolor = NDblue,     
    filecolor = NDblue     
}


% \usepackage[textsize=tiny]{todonotes}
% \setlength{\parskip}{3pt}

% \usepackage[skins,theorems]{tcolorbox}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % from Tengyang

% tweaking cleveref
\Crefformat{equation}{#2Eq.\;(#1)#3}

\Crefformat{figure}{#2Figure #1#3}
\Crefformat{assumption}{#2Assumption #1#3}
\Crefname{assumption}{Assumption}{Assumptions}

% Fix hyperref in section titles.
\usepackage{crossreftools}
\pdfstringdefDisableCommands{%
    \let\Cref\crtCref
    \let\cref\crtcref
}
\newcommand{\creftitle}[1]{\crtcref{#1}}

\usepackage{dsfont}
\usepackage{nicefrac}
% \usepackage[shortlabels]{enumitem}


\author[1,*]{Yue Huang}
\author[2,*]{Yanbo Wang}
\author[2,*]{Zixiang Xu}
\author[2]{Chujie Gao}
\author[4]{Siyuan Wu}
\author[4]{Jiayi Ye}
\author[2]{Xiuying Chen}
\author[3]{Pin-Yu Chen}
\author[1]{Xiangliang Zhang}

\affil[1]{University of Notre Dame}
\affil[2]{MBZUAI}
\affil[3]{IBM Research}
\affil[4]{Independent Researcher}

\affil[*]{Equal Contribution}

\correspondingauthor{xzhang33@nd.edu (Xiangliang Zhang)}



% \correspondingauthor{syyuan21@m.fudan.edu.cn, lovesnow@mail.ustc.edu.cn}


\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}


\begin{abstract}
\textbf{Abstract:} Recent advances in Large Language Models (LLMs) have revolutionized generative systems, achieving excellent performance across diverse domains. Although these models perform well in controlled environments, their real-world applications frequently encounter inputs containing both essential and irrelevant details. Our investigation has revealed a critical vulnerability in LLMs, which we term Contextual Distraction Vulnerability (CDV). This phenomenon arises when models fail to maintain consistent performance on questions modified with semantically coherent but irrelevant context. To systematically investigate this vulnerability, we propose an efficient tree-based search methodology to automatically generate CDV examples. Our approach successfully generates CDV  examples across four datasets, causing an average performance degradation of approximately 45\% in state-of-the-art LLMs. To address this critical issue, we explore various mitigation strategies and find that post-targeted training approaches can effectively enhance model robustness against contextual distractions. Our findings highlight the fundamental nature of CDV as an ability-level challenge rather than a knowledge-level issue since models demonstrate the necessary knowledge by answering correctly in the absence of distractions. This calls the community's attention to address CDV during model development to ensure reliability.
Code is available at \href{https://github.com/wyf23187/LLM_CDV}{https://github.com/wyf23187/LLM\_CDV}.
\end{abstract}

\begin{document}
\maketitle


\input{Section/1-intro}
\input{Section/2-related}
\input{Section/3-method}
\input{Section/4-experiments}
\input{Section/5-conclusion}

\bibliography{reference}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
% \input{sections/app_frameworksummary}
\input{Section/99-appendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
