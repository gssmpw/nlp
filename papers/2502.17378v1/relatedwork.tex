\section{Background}
\label{sec:related_work}

In this section, we introduce the background and definitions related to the concepts of CI and MLOps and position our study within the context of prior research.

\subsection{MLOps in a nutshell}

The primary goal of industrial ML projects is to develop and deploy ML-based products rapidly into production environments~\citep{kreuzberger2023machine}. 
However, incorporating ML models into production remains a significant challenge~\citep{symeonidis2022mlops}. 
Similar to traditional software projects, where the development and operation teams often struggle with collaboration and software release updates, ML projects face additional hurdles, particularly in deploying models to production~\citep{symeonidis2022mlops}.
While ML projects share core characteristics with traditional software projects, they differ fundamentally due to their reliance on ML models as key components~\citep{gift2021practical}, introducing complexities such as model validation into the integration and deployment process.
% An ML project, while fundamentally a software project, is distinct from traditional software projects as it includes an ML model as a core component~\citep{gift2021practical}, introducing unique complexities, such as model validation, into the integration and release process. 

To address these challenges, ML engineers, data scientists, front-end developers, and production engineers have been collaborating to streamline the deployment of ML projects, leading in the emergence of MLOps~\citep{symeonidis2022mlops}.
MLOps, short for Machine Learning Operations, refers to a set of practices and tools designed to facilitate the deployment and maintenance of ML projects in production environments~\citep{makinen2021needs}. 
MLOps extends DevOps principles by incorporating additional processes specific to ML, such as data validation, model training, and model monitoring~\citep{symeonidis2022mlops, makinen2021needs, calefato2022preliminary}.
% MLOps refers to the combination of DevOps and additional actions specific to ML~\citep{symeonidis2022mlops, makinen2021needs, calefato2022preliminary}.  

DevOps is a methodology that fosters collaboration, communication, and integration between development (Dev) and operations (Ops) teams, aiming to streamline the process of delivering software~\citep{ebert2016devops}.
According to \cite{leite2019survey}, ``DevOps is a collaborative and multidisciplinary organizational effort to automate the continuous delivery of new software updates while guaranteeing their correctness and reliability''.
MLOps builds on this philosophy by advocating for automation and monitoring all stages of the ML project life cycle, including integration, testing, release, deployment, and infrastructure management~\citep{karamitsos2020applying}. 
Implementing an MLOps pipeline is particularly beneficial for organizations transitioning from ML proof-of-concept implementations to production-ready systems~\citep{makinen2021needs}.
% Implementing an MLOps pipeline becomes a strategic move for organizations transitioning from ML as a proof-of-concept to a production-ready solution~\citep{makinen2021needs}. 

% CI is the core principle of DevOps, as automated testing is essential for progressing with DevOps practices \citep{gift2021practical}. 

\subsubsection{Continuous Integration in MLOps}

CI is a core principle of DevOps, aimed at ensuring that code changes are frequently integrated, tested, and validated in a shared repository~\citep{fowler-ci-2006, duvall2007continuous}. 
Originated from the agile XP methodology, CI requires that developers integrate new code into a shared repository, at least daily~\citep{fowler-ci-2006, duvall2007continuous}. 
According to \cite{beck2000extreme}, ``New code is integrated with the current system after no more than a few hours. When integrating, the whole system is built from scratch and all tests must pass or the changes are discarded". 
The fundamental philosophy behind CI is to ensure that the shared state of the software's codebase remains in a working state at all times~\citep{duvall2007continuous}. 

A well-implemented CI pipeline automatically compiles, tests, and packages software whenever changes are made~\citep{bernardo2023}. By enabling frequent, reliable updates, CI helps software projects achieve shorter release cycles while maintaining high quality~\citep{bosch2014continuous}. As a foundational DevOps practice, CI plays a crucial role in enabling Continuous Delivery (CDE) and Continuous Deployment (CD)\citep{yarlagadda2018understanding, lwakatare2016relationship}. CDE extends CI by automating software release processes, while CD further automates deployment, ensuring that validated updates reach end users seamlessly\citep{karvonen2017systematic}.

In the ML domain, CI encompasses not only traditional software testing but also additional layers of validation, including data verification, schema validation, and model performance tracking~\citep{karamitsos2020applying}. Given that MLOps is built on DevOps principles, integrating CI into ML pipelines is crucial for ensuring the reliability and reproducibility of ML workflows.

% As a foundational stage of DevOps \citep{yarlagadda2018understanding}, CI serves as the cornerstone for enabling both Continuous Delivery (CDE) and Continuous Deployment (CD) \citep{lwakatare2016relationship}.
% CDE builds upon CI by automating the entire software delivery process, allowing releases to occur at any time with minimal manual intervention, while CD extends this concept by automating the deployment itself, allowing updates to be delivered directly to end users once they pass the required testing and validation~\citep{karvonen2017systematic}. 
% In the context of ML, CI extends beyond testing and validating code and components; it also involves the testing and validation of data, data schemas, and models~\citep{karamitsos2020applying}. 
% Since MLOps is built on DevOps foundations, implementing CI is also crucial for ML projects adopting an MLOps approach.

\subsubsection{Continuous Integration practices}

CI extends beyond the use of tools to automate build and testing processes, encompassing broader values and principles that shape its effective implementation.
\cite{duvall2007continuous} outlined seven best practices for teams implementing CI in their projects: (i) commit code frequently, (ii) avoid committing broken code, (iii) fix broken builds immediately, (iv) write automated developer tests, (v) ensure that all tests and inspections pass, (vi) run private builds, and (vii) prevent the propagation of broken code.

A literature review by \cite{staahl2014modeling} examined the varying interpretations and implementations of CI practices. The study found that CI adoption is highly context-dependent, with differences in test frequency, integration flows, and overall practices based on project requirements. Despite established guidelines, there is no universal consensus on the exact CI metrics projects should follow, such as the optimal number of daily commits or the ideal test execution strategy. These variations highlight the challenges in defining standardized CI practices~\citep{santos2024needMonitorCI}.

In the ML domain, recent studies propose tailored CI practices to address the unique challenges of ML workflows. For instance, Fowler introduces the concept of Continuous Delivery for Machine Learning (\textsc{CD4ML}), emphasizing reproducible model training, validation data management, and model quality assurance~\citep{Fowler2019CD4ML}. Additionally, \cite{bagai2024implementing} explore CI/CD strategies for ML in cloud environments, highlighting best practices such as automated testing and validation, infrastructure as code, version control, and containerization. 
Additionally, \cite{garg2021continuous} emphasize the importance of model monitoring in ML CI pipelines to detect model performance degradation.
These practices recommendations underscore the need for specialized approaches to CI in ML, ensuring robustness and reliability in dynamic and data and model-driven environments.


% A literature review by \cite{staahl2014modeling} examined the technical aspects of implementing CI practices and analyzed variations in their interpretation and application. They concluded that the interpretation and implementation of CI practices differ significantly across cases. For instance, the frequency of integration and test flows varies depending on the specific context and project requirements. 
% Indeed, despite numerous recommendations, there is no consensus on which CI practices projects should implement or the exact metrics teams should follow (e.g., the optimal number of daily or hourly commits). These practices can differ based on factors like the project's domain, the number of features being developed or maintained, and the scale of the user base. This inconsistency in CI adoption adds to the challenges of effective monitoring~\citep{santos2024needMonitorCI}.

\subsection{Related Work}

The adoption of CI has been extensively studied in the context of traditional open-source projects, demonstrating its positive impact on software development practices. 
Previous research has highlighted the benefits of adopting a CI service in the development cycle of software projects, including improved bug detection~\citep{vasilescu2015quality}, increased release frequency~\citep{hilton2016usage}, higher throughput of PRs delivered per release~\citep{bernardo2018studying}, and better test coverage rates~\citep{saraiva2023unveiling}. 

Beyond investigating the adoption of CI services, recent studies have focused on specific CI practices employed by software projects~\citep{felidre2019continuous, santos2022investigating}. For instance, \cite{felidre2019continuous} examined 1,270 open-source projects using \textsc{Travis CI} to identify unhealthy CI practices, such as infrequent commits, lengthy build durations, and poor test coverage. They found that, in most projects, builds were completed under the 10-minute rule of thumb. In addition, \cite{santos2022investigating} conducted a quantitative analysis of CI practices by examining data from 90 open-source projects over two years, exploring the relationship between these practices and project productivity and quality.

In the ML domain, recent studies have focused on defining \textsc{MLOps}, exploring its tools, architectures, and associated challenges~\citep{alla2021mlops, symeonidis2022mlops, kreuzberger2023machine}. \cite{karamitsos2020applying} proposed practical techniques for integrating DevOps principles and CI/CD practices into ML applications, addressing the unique requirements of ML workflows. Similarly, \cite{calefato2022preliminary} examined the role of \textsc{MLOps} in automating critical tasks involved in building and deploying ML-enabled systems, highlighting the importance of automation in managing the complexity of ML pipelines. \cite{makinen2021needs} further underscored the significance of \textsc{MLOps} in data science, presenting findings from a global survey of 331 professionals across 63 countries.

\cite{rzig2022characterizing} conducted a large-scale analysis of 4,031 ML projects hosted on \textsc{GitHub}, revealing that only 37\% of ML projects had adopted CI services. This relatively low adoption rate highlights the challenges posed by the unique characteristics of ML workflows. Despite the availability of popular CI services like \textsc{GitHub Actions}, recent efforts have focused on developing dedicated CI solutions tailored to the specific needs of ML projects. For example, \cite{renggli2019continuous} introduced \textsc{Ease.ML/CI}, a tool designed to prevent overfitting during iterative ML development. Likewise, \cite{karlavs2020building} proposed specialized CI services that address the probabilistic and iterative nature of ML workflows.
In addition, in our prior work~\citep{bernardo2024machine}, we provided a comparative quantitative analysis of CI practices in ML and non-ML projects, identifying longer build durations and lower test coverage rates in ML projects, particularly in medium-sized ones. 
These findings suggest that the adoption of CI in ML projects might be challenged by unique technical and workflow constraints that are not present in traditional software development.

While existing research has primarily provided quantitative assessments of CI adoption trends or proposed tools to address specific ML-related challenges, our study takes a qualitative perspective, focusing on ML practitioners' experiences with CI adoption. Specifically, we explore the underlying reasons behind the differences in CI adoption between ML and non-ML projects, the challenges ML projects face in building and testing their components, and the strategies practitioners employ to integrate CI practices effectively into ML projects. By capturing practitioner insights, our study bridges the gap between previous quantitative observations and real-world implementation challenges, offering a deeper understanding of the practical barriers to CI adoption in ML projects.

% In our prior work~\citep{bernardo2024machine}, we quantitatively analyzed four CI practices in 93 ML and 92 non-ML projects, uncovering key differences in their adoption patterns. Specifically, ML projects were found to have longer build durations and lower test coverage rates, particularly in medium-sized projects. However, the root causes of these differences in CI practices between ML and non-ML projects were not thoroughly explored. Therefore, our study addresses this knowledge gap by examining practitioner perspectives to uncover the underlying reasons for the longer build durations and lower test coverage observed in ML projects and to understand the main differences ML practitioners perceive when implementing CI in their projects. By doing so, we aim to provide actionable insights to improve CI adoption and effectiveness in the ML domain.