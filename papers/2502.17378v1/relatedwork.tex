\section{Related Work}
The adoption of CI has been extensively studied in the context of traditional open-source projects, demonstrating its positive impact on software development practices. 
Previous research has highlighted the benefits of adopting a CI service in the development cycle of software projects, including improved bug detection~\citep{vasilescu2015quality}, increased release frequency~\citep{hilton2016usage}, higher throughput of PRs delivered per release~\citep{bernardo2018studying}, and better test coverage rates~\citep{saraiva2023unveiling}. 

Beyond investigating the adoption of CI services, recent studies have focused on specific CI practices employed by software projects~\citep{felidre2019continuous, santos2022investigating}. For instance, \cite{felidre2019continuous} examined 1,270 open-source projects using \textsc{Travis CI} to identify unhealthy CI practices, such as infrequent commits, lengthy build durations, and poor test coverage. They found that, in most projects, builds were completed under the 10-minute rule of thumb. In addition, \cite{santos2022investigating} conducted a quantitative analysis of CI practices by examining data from 90 open-source projects over two years, exploring the relationship between these practices and project productivity and quality.

In the ML domain, recent studies have focused on defining \textsc{MLOps}, exploring its tools, architectures, and associated challenges~\citep{alla2021mlops, symeonidis2022mlops, kreuzberger2023machine}. \cite{karamitsos2020applying} proposed practical techniques for integrating DevOps principles and CI/CD practices into ML applications, addressing the unique requirements of ML workflows. Similarly, \cite{calefato2022preliminary} examined the role of \textsc{MLOps} in automating critical tasks involved in building and deploying ML-enabled systems, highlighting the importance of automation in managing the complexity of ML pipelines. \cite{makinen2021needs} further underscored the significance of \textsc{MLOps} in data science, presenting findings from a global survey of 331 professionals across 63 countries.

\cite{rzig2022characterizing} conducted a large-scale analysis of 4,031 ML projects hosted on \textsc{GitHub}, revealing that only 37\% of ML projects had adopted CI services. This relatively low adoption rate highlights the challenges posed by the unique characteristics of ML workflows. Despite the availability of popular CI services like \textsc{GitHub Actions}, recent efforts have focused on developing dedicated CI solutions tailored to the specific needs of ML projects. For example, \cite{renggli2019continuous} introduced \textsc{Ease.ML/CI}, a tool designed to prevent overfitting during iterative ML development. Likewise, \cite{karlavs2020building} proposed specialized CI services that address the probabilistic and iterative nature of ML workflows.
In addition, in our prior work~\citep{bernardo2024machine}, we provided a comparative quantitative analysis of CI practices in ML and non-ML projects, identifying longer build durations and lower test coverage rates in ML projects, particularly in medium-sized ones. 
These findings suggest that the adoption of CI in ML projects might be challenged by unique technical and workflow constraints that are not present in traditional software development.

While existing research has primarily provided quantitative assessments of CI adoption trends or proposed tools to address specific ML-related challenges, our study takes a qualitative perspective, focusing on ML practitioners' experiences with CI adoption. Specifically, we explore the underlying reasons behind the differences in CI adoption between ML and non-ML projects, the challenges ML projects face in building and testing their components, and the strategies practitioners employ to integrate CI practices effectively into ML projects. By capturing practitioner insights, our study bridges the gap between previous quantitative observations and real-world implementation challenges, offering a deeper understanding of the practical barriers to CI adoption in ML projects.

% In our prior work~\citep{bernardo2024machine}, we quantitatively analyzed four CI practices in 93 ML and 92 non-ML projects, uncovering key differences in their adoption patterns. Specifically, ML projects were found to have longer build durations and lower test coverage rates, particularly in medium-sized projects. However, the root causes of these differences in CI practices between ML and non-ML projects were not thoroughly explored. Therefore, our study addresses this knowledge gap by examining practitioner perspectives to uncover the underlying reasons for the longer build durations and lower test coverage observed in ML projects and to understand the main differences ML practitioners perceive when implementing CI in their projects. By doing so, we aim to provide actionable insights to improve CI adoption and effectiveness in the ML domain.