\section{Introduction}\label{sec:intro}

Similarity search within databases of high-dimensional vectors has become increasingly important over the last decade due to the rise of semantic embeddings generated by neural networks and large language models (LLMs). Similarity search is a foundational building block of applications such as search, recommendations, advertising, and retrieval augmented generation (RAG). Correspondingly, there has been an explosion of work on efficient algorithms for approximate similarity search~\cite{jegou2010product,malkov2018efficient,subramanya2019diskann,fu2019nsg}, as exact similarity search is prohibitively expensive due to the curse of dimensionality.

The object of approximate similarity search, or approximate nearest neighbor search (ANNS) is finding the top-$k$ most similar embeddings. These top-$k$ results can then be post-processed for the desired application. However, there are some applications for which retrieving top-$k$ embeddings for a fixed $k$ is a poor fit. Applications such as duplicate detection, plagiarism checking, and facial recognition require instead to retrieve all results within a certain \textit{radius} of a query rather than top-$k$, with some post-processing after to verify whether a match exists out of the retrieved items~\cite{douze2021image,schroff2015facenet,simsearchnet}. Furthermore, in real-world search applications some queries may have tens of thousands of matches while others have none or very few. In these cases, search with a small radius, or range retrieval, may be used to both differentiate these query types~\cite{szilvasy2024vector}. Range search can also be a useful subroutine in applications using nearest neighbor graphs, such as clustering or graph learning~\cite{Grale20,li2020density}.

Range search differs from top-$k$ search by the diversity in size of the ground truth solutions for a set of queries. In practice, solutions for a set of queries follow a skewed, Pareto-like distribution where the majority of queries tend to have no results within the chosen radius, while a smaller fraction have a small number of results, and a few outliers have thousands to tens of thousands of results. Queries in the middle category are well served by existing similarity search algorithms, which are already highly optimized and efficient. Thus, a good range search algorithm will match the efficiency of top-$k$ search on the middle category of queries, while quickly terminating on queries with no results, and efficiently finding all results for those few queries with thousands of results.

Despite the many applications of range search, there has been very little work on designing algorithms specifically for the task of high-dimensional range search. From a practical perspective, it would be ideal of data structures for top-$k$ search could be reused or lightly adapted for range search, enabling an existing data structure to serve both types of queries. Data structures for top-$k$ search typically fall into one of two categories---partition-based indices, which partition the dataset into cells and exhaustively search a small number of cells at query time, and graph-based indices, which construct a proximity graph over the data points and use a variant of greedy search to answer queries. Graph-based indices are widely acknowledged as achieving equal or better similarity search performance than partition-based indices~\cite{wang2021comprehensive}, but almost no work has studied the question of adapting graph-based indices for range retrieval. Furthermore, top-$k$ search with IVF indices naturally explores thousands of candidates per query by exhaustively checking the distances between the query point and all the points in each cell, while the number of nodes a graph-based search typically explores is only a small multiple of $k$. It is thus a much less trivial algorithmic task to adapt graph-based search to serve such queries (as we will show in Section~\ref{sec:algorithms}, naive adaptations of existing search methods are not adequate for the task). The graph structure also suggests potential to terminate queries with no results after examining just a handful of vertices. It is natural then to ask whether graph-based indices can be adapted to efficiently serve range queries. 

\paragraph{Our Contributions} In this paper, we present a set of algorithms designed for approximate high-dimensional range search on graph-based ANNS indices. Our techniques are modifications of the standard graph search algorithm, meaning that we enable one data structure to efficiently serve both top-$k$ queries and range queries. We present techniques that allow a range query to quickly terminate when the query has no results, and to efficiently answer queries with thousands of results within their radius. We devise an early-stopping heuristic that is capable of predicting whether a query has no results after only a few hops in the graph search. For queries with many results, we design two algorithms, \textit{doubling search} and \textit{greedy search}, that extend the search path to return more results while minimizing wasted work, and compare and contrast situations where each algorithm dominates the other.

For our experimental evaluation, since there is only one publicly released dataset specifically for range search, we evaluate eight state-of-the-art publicly available metric embedding datasets with up to 100 million embeddings and select a suitable radius for each one. We also perform additional analysis of the characteristics of different range search datasets, and how they connect to the magnitude of improvement our algorithms achieve.

We evaluate our algorithms on the set of nine datasets (eight contributed by us, and one public benchmark), and find that our range retrieval algorithms are capable of up to 100x speedup over naive adaptations of top-$k$ search, and in most cases 5-10x speedup. We additionally find that the speedup and scalability of our algorithms extends up to datasets with 100 million points.  Figure~\ref{fig:teaser} shows a preview of our experimental results on three embedding datasets of sizes one million to 100 million. In each case, for a fixed average precision, we find at least a 10x speedup in throughput; additionally, our algorithms extend to significantly higher accuracy than the baseline.

\paragraph{Outline} In Section~\ref{sec:relatedwork} we cover related work. In Section~\ref{sec:prelim} we cover some needed preliminaries. In Section~\ref{sec:rangedata} we explore the characteristics of range search datasets and provide heuristics for choosing an acceptable radius, which we use to adapt eight public embedding datasets for range searching. In Section~\ref{sec:algorithms} we present our algorithms for range search on graph-based indices, and in Section~\ref{sec:experiments} we present experimental results.

\begin{figure}
	\includegraphics[scale=.2]{figures/legends/threealg_twocol_legend.pdf} 
	\includegraphics[scale=.2]{figures/legends/teaser_legend.pdf} \\
	\includegraphics[scale=.17]{figures/qps_recall/openai-1M_ap.pdf}
	\includegraphics[scale=.17]{figures/qps_recall/bigann-10M_ap.pdf}
	\includegraphics[scale=.17]{figures/qps_recall/ssnpp-100M_ap.pdf} \\
	\caption{A preview of our experimental results on three datasets: from left to right, OpenAI-1M, BIGANN-10M, and SSNPP-100M. The solid line shows the beam search baseline, while the dotted and dashed lines show our two new algorithms. Datasets and algorithms are described in detail in Sections~\ref{sec:rangedata} and~\ref{sec:algorithms}, respectively.}
	\label{fig:teaser}
\end{figure}

\subsection{Related Work}~\label{sec:relatedwork}

\paragraph{Work on Range Searching} Some earlier work addresses range retrieval in high dimensions from a theoretical standpoint~\cite{chazelle2008approximate}, or with only minimal experiments that do not extend to the large embeddings used today~\cite{wang2013pltree}. Theory results on nearest neighbor search using locality sensitive hashing (LSH) also implicitly apply to range search, since their approximation guarantees are usually in the form of finding neighbors within a $(1+\epsilon)$ radius of the distance to the true top-$k$ result~\cite{indyk1998towards}.

On the practical side, Meta AI released a range retrieval dataset aimed towards detecting misinformation~\cite{simsearchnet}, which was used as one of the competition datasets in the NeurIPS 2021 Big ANN Benchmarks Challenge~\cite{simhadri2021results}, but competitors solved this task using naive adaptations of top-$k$ search rather than novel range searching algorithms. A recent work by Szilvasy, Mazare, and Douze~\cite{szilvasy2024vector} addresses the combined task of retrieving range search results with one metric and then re-ranking them using a more sophisticated model. They address the question of designing a range search metric (RSM) specifically for \textit{bulk} search---that is, range search over a group of queries with a fixed computational budget---and benchmark its results on an image search application. They use an inverted file (IVF) index, a common data structure for similarity search~\cite{douze2024faiss}, to serve their database queries. 

The Starling system~\cite{wang2024starling} is an SSD-resident graph-based ANNS index optimized for I/O efficiency. Their work includes benchmarks on range search metrics, and they use an algorithm similar to the doubling beam search algorithm we present in Section~\ref{sec:algorithms}. However, the focus of their paper is not on comprehensive benchmarking of range search, and since their implementation is a disk-resident index and ours is fully in-memory, our experiments are not directly comparable to theirs. 

\paragraph{Other Related Work} Some variants on the high-level ideas behind our range search algorithms---that is, early termination of queries with few results, and extensions of beam search for queries with many results---have been used before in the context of nearest neighbor search. A work by Li et al.~\cite{li2020improving} uses a machine learning model to predict when a query can terminate early and still maintain high accuracy. Another work~\cite{xu2021twostage} uses graph search with two phases (essentially, an initial cheaper phase and a later, more compute intensive phase for selected queries to gather additional candidates). 
