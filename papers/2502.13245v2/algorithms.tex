\section{Algorithms for Range Search on Graph-Based ANNS Indices}\label{sec:algorithms}

In this section we introduce our range search algorithms. We first introduce the data structure and baseline algorithm, a standard beam search. Since the standard beam search is well known to produce excellent results for top-$k$ queries, some range queries (those with an intermediate number of results) can already be efficiently answered with top-$k$ search with a small $k$. Thus, in this section we focus on improving queries outside this range, both queries with many results and queries with no results. Intuitively, both types of queries call for some dynamic adjustments to the beam search: for queries with no results, ideally terminating quickly before the end of the search, and for queries with many results, dynamically extending the size of the beam in some way. 

\subsection{Data Structure and Baseline Algorithm}

As the aim of this paper is to investigate whether ANNS graphs can be effectively reused for range search, the data structure used for range queries is an ANNS graph. There are many examples of ANNS graphs in the literature~\cite{subramanya2019diskann,fu2019nsg,malkov2018efficient}. For the experiments in this paper we use the in-memory construction of DiskANN, specifically the ParlayANN library~\cite{manohar2024parlayann}, but the algorithms we present should work on any single-layer ANNS graph that performs well using the standard beam search, and should be modifiable to multi-layer graphs such as HNSW with little effort.

For our baseline algorithm, due to lack of existing algorithms for range search in high dimensions, we use standard beam search on an ANNS graph. This algorithm is described in detail in many publications, and we also show pseudocode in Algorithm~\ref{alg:beamsearch}. 


\begin{algorithm2e}[t]
%	\magdalen{metric M instead of esl and esr}
	\caption{BeamSearch($q, G, \mP, S, r,b , \mathcal{M}$).\protect}
	\label{alg:beamsearch}\small
	\SetKwBlock{ParDo}{do in parallel}{end}
	\SetKwBlock{ParFor}{parallel for}{end}
	\SetAlgoLined
	\DontPrintSemicolon
%	\magdalen{Get rid of l} \\
%	\magdalen{Don't capitalize words that aren't proper nouns} \\
	\KwIn{Query point $q$, graph $G$, point set $\mP$, starting points $S$, radius $r$, beam size $b$, early stopping metric $\mathcal{M}$}
	\KwOut{Set $\mathcal{B}$ of closest points, set $\mathcal{V}$ of visited points}
	
	
	
%	\tcp{Initialize the frontier with starting points}
	$\mathcal{B} \gets S, \mathcal{V} \leftarrow \emptyset$\;
%	\magdalen{get rid of num visited, compress lines 2 and 4 into one line} \\
%	$\mathcal{UF} \leftarrow \mathcal{F}[0] \coloneq \mathcal{F} \setminus \mathcal{V}$,\
%	$\mathcal{F} \leftarrow \mathcal{S}$,\
%	$\mathcal{UF} \leftarrow \mathcal{F}[0]$,\
	
	\While{$\mathcal{B}\setminus \mV \neq \emptyset$}{
%		\tcp{get the closest point from unvisited frontier}
		$p^* \; \la \; \arg\min_{(p \in \mathcal{B} \setminus \mV)} \norm{p, q}$
		
		
%		\magdalen{If M(B, V, q, r) then break} \\
%		\If{($\norm{\mathcal{F}[0],p} > r$ $\mathbf{and}$
%			$\norm{v,p} > esr$ $\mathbf{and}$ \\ $esl>0$ $\mathbf{and}$ $num\_visited \geq esl$ )}{
%			$\mathbf{Break}$
%		}

		\tcp{Early stopping conditions}
		\lIf{$\mathcal{M} (q, \mathcal{B},\mV , r)$}{$\mathbf{Break}$} 
		
		$\mathcal{V} \leftarrow \mathcal{V} \cup \{ p^*\}$
		
%		\tcp{Collect and filter neighbors}
		%$candidates \leftarrow$ Neighbors of $current$ not in visited set\
		%Compute distances for $candidates$\
		
		%\tcp{Merge and update frontier}
		%Merge sorted $frontier$ and $candidates$\
		%Trim to at most $QP.beamSize$ elements\
		%Update $unvisited\_frontier$\
		$\mathcal{B} \leftarrow  \mathcal{B} \cup (N_{out}(p^*) \setminus \mathcal{V})$\;
%		\magdalen{specify closest points to q}
		\lIf{$ | \mathcal{B} | > b$}{
			trim $\mathcal{B}$ to size $b$, keeping the closest points to $q$
		}
%		$\mathcal{UF} \leftarrow = \mathcal{F} \setminus \mathcal{V}$
	}
	
	\KwRet $(\mathcal{B}, \mathcal{V})$
\end{algorithm2e}


\begin{algorithm2e}[t]
%	\magdalen{Get rid of unused arguments}\\
	\caption{GreedySearch($q, G, \mP, S, r$).\protect}
	\label{alg:greedy}\small
	\SetKwBlock{ParDo}{do in parallel}{end}
	\SetKwBlock{ParFor}{parallel for}{end}
	\SetAlgoLined
	\DontPrintSemicolon
	\KwIn{Query point $q$, graph $G$, point set $\mP$, starting points $S$, radius $r$}
	\KwOut{Set $\mathcal{V}$ of visited points}
	
	$\mathcal{F} \gets S, $\ 
%	\tcp{Initialize Frontier}
%	\magdalen{Only need V, not K} \\
	$\mathcal{V} \gets \emptyset $
%	\tcp{neighbors not visited}
	
	\While{$\mathcal{F} \setminus \mV \neq \emptyset$}{
		$p^* \; \la \; \arg\min_{(p \in \mathcal{F} \setminus \mV)} \norm{p, q}$\;
%		\magdalen{rename \textit{curr}} \\
		$\mathcal{V} \gets \mathcal{V} \cup \{p^*\}$
%		\tcp{Do Prefetch. Keep this?} \magdalen{No prefetching} \\
		
%		\magdalen{Little f instead of a, iterate over neighborhood without union with frontier}\\
		\ForEach{$f \in (N_{out}(p^*)\setminus \mV) $}{ 
			\lIf{$\|f, q\| \leq r$}{
				$\mathcal{F} = \mathcal{F} \cup \{f\} $\
			}
		}
	}
	
	\KwRet{$\mV$}\;
\end{algorithm2e}

\begin{algorithm2e}[t]
%	\magdalen{Get rid of unused arguments, add used arguments}\\
	\caption{EarlyStopping($q, \mathcal{B}, \mV, \mathcal{M}, \mathcal{C}$).\protect}
	\label{alg:earlystopping}\small
	\SetKwBlock{ParDo}{do in parallel}{end}
	\SetKwBlock{ParFor}{parallel for}{end}
	\SetAlgoLined
	\DontPrintSemicolon
	\KwIn{Query point $q$, current beam $\mathcal{B}$, visited set $\mV$, early stopping metric $\mathcal{M}$, cutoff parameter set $\mathcal{C}$}
	\KwOut{Bool value for early stopping. True if conditions are met.}
%	\magdalen{return a bool}\\
	\lIf{$\mathcal{M}(q, \mathcal{B},\mV, \mathcal{C})$}{\KwRet{$\mathbf{True}$}}
	
	
\end{algorithm2e}

\begin{algorithm2e}[t]
	%	\magdalen{Get rid of unused arguments, add used arguments}\\
	\caption{EarlyStoppingExample($q, \mathcal{B}, \mV, v, \mathcal{C} = \{r, vl, esr\}$).\protect}
	\label{alg:earlystoppingexample}\small
	\SetKwBlock{ParDo}{do in parallel}{end}
	\SetKwBlock{ParFor}{parallel for}{end}
	\SetAlgoLined
	\DontPrintSemicolon
	\KwIn{Query point $q$, current beam $\mathcal{B}$, visited set $\mV$, number of visited points $v$, radius $r$, limit of number of visits $vl$, early stopping radius $esr$}
	\KwOut{Bool value for early stopping.}
%	\tcp{This is an example of early stopping based on the distance between query point and the current point visited. Cutoff $c$ is given as radius $r$ and number of visit $v$}
%		\magdalen{return a bool that's true if you SHOULD stop}\\
%		\magdalen{num\_visited not defined} \\
%		\magdalen{don't include M in inputs} \\
%		\magdalen{split onto a couple lines} \\
%		\magdalen{missing early stopping radius} \\
		
	\tcp{When the closest point in the beam is not within the radius}
	\textbf{return} ($ \arg\min_{p \in \mathcal{B}} \|p,q\| > r , \mathbf{and}$\;
        \tcp{When the number of visited points is larger than the given cutoff}
	\hspace*{.34in}$v \geq vl, \mathbf{and}$\;
        \tcp{When the current point visited is not within the early stopping radius}
	\hspace*{.34in}$\arg\min_{p^* \in \mathcal{V}\setminus \mathcal{B}} \|p^*,q\| > esr$)\; 

	
	
\end{algorithm2e}

\begin{algorithm2e}[t]
%	\magdalen{Function arguments and inputs column don't agree} \\
	\caption{DoublingSearch($q, G,\mP, S, r, b, \mathcal{M}$).\protect}
	\label{alg:doubling}\small
	\SetKwBlock{ParDo}{do in parallel}{end}
	\SetKwFor{ParFor}{parallel for}{do}{end}
	\SetAlgoLined
	\DontPrintSemicolon
	\SetKwProg{myfunc}{Function}{}{}
%	\magdalen{Point set P, make sure that variable names are consistent across algorithms} \\
	\KwIn{Query point $q$, graph $G$ , point set $\mP$, starting points $S$, radius $r$, beam size $b$, early stopping metric $\mathcal{M}$}
%	\magdalen{Output should say neighbors within range} \\
	\KwOut{Set of neighbors $\mathcal{N}$ witin range }
	

	
%	$beam\_size \gets b$\;
%	$stop\_doubling \gets False$\;
		
		
	\While{\textbf{true}}{
		%			Initialize empty sequences $neighbors$ and $visitedElts$\;
		$\mathcal{N} \gets \emptyset$
		
		%		Define QueryParams $QP$ with:\;
		%		\quad Initial beam size: $initial\_beam$\;
		%		\quad Graph constraints: $G.size()$, $G.max\_degree()$\;
		%		\quad Early stopping: $RP.early\_stop$, $RP.early\_stop\_radius$\;
		
		\tcp{Early stopping is done inside the beam search}
		
		$(\mathcal{B}, \mV) \gets BeamSearch(q, G,\mP, S, r, \mathcal{M}, b)$\;
		
		%		$starting\_points\_	index[i].clear()$\;
%		\tcp{Add already visited points to starting point set}
%		\ForEach{$n \in \mV$}{
		$S \gets S \cup \mV$\;
%		}
		
		%		$neighbors.clear()$\;
		\For{$n \in \mathcal{B}$}{
			\lIf{$\| n, q \| \leq r$}{
				$\mathcal{N} = \mathcal{N} \cup \{n\}$
			}
		}
		
%		\magdalen{Make some of these one line where visually appealing} \\
		
		\lIf{$ | \mathcal{N} | < b$}{ 
			$\mathbf{Break}$ 
		}
		$b \gets 2 \times b$\;
	}
		
	
	\Return $\mathcal{N}$\;
\end{algorithm2e}




%\begin{algorithm2e}[t]
%	\caption{BeamSearch($Q,G,\mathcal{B}, S, r$).\protect}
%	\label{algo: beamSearch}\small
%	\SetKwBlock{ParDo}{do in parallel}{end}
%	\SetKwFor{ParFor}{parallel for}{do}{end}
%	\SetAlgoLined
%	\DontPrintSemicolon
%	\SetKwProg{myfunc}{Function}{}{}
%	\KwIn{Query points $Q$, Graph $G$, Base points $\mathcal{B}$, Starting points $S$, Radius $r$, Beam size $b$}
%	\KwOut{Set of neighbors $\mV$ for each of the query points}
%	
%	%	Initialize $all\_neighbors[A.size()]$\;
%	%	Initialize $visit\_order[A.size()]$\;
%	%	Initialize $second\_round[A.size()] \gets 0$\;
%	
%	%	Define QueryParams $QP$ with:\;
%	%	\quad Initial beam size: $RP.initial\_beam$\;
%	%	\quad Graph constraints: size $G.size()$, max degree $G.max\_degree()$\;
%	%	\quad Early stopping: $RP.early\_stop$, $RP.early\_stop\_radius$\;
%	%	
%	\ParFor{$i \in Q$}{
%%		Initialize empty sequences $\mathcal{N}$ and $\mathcal{N'}$\;
%		
%		$(beamElts, visitedElts) \gets beamSearchSub(Q, G, \mathcal{B}, S, QP, r)$\ 
%		%		$visit\_order[i] \gets visitedElts$\;
%		
%		\ForEach{$(n,dist) \in beamElts$}{
%			\If{$dist \leq r$}{
%				$\mathcal{N} = \mathcal{N} \cup \{n\}$\;
%			}
%		}
%		% Should I use different variable for beam size?
%		\If{$ |\mathcal{N}| < b$}{ 
%			$\mathcal{V}[i] \gets \mathcal{N}$\;
%		}
%	}	
%	\Return $\mathcal{V}$\;
%\end{algorithm2e}



\subsection{Improving Range Search for Queries with Many Results}

We first investigate how to approach graph-based range search for queries that have many results. A standard beam search can only capture as many points as are contained within the beam of size $B$, and thus any queries with significantly more than $B$ results cannot achieve high accuracy. The natural question is whether it is possible to distinguish between such queries with more than $B$ results and expand the set of returned candidates for those queries, without wasting time on queries with fewer than $B$ results. In this section we discuss two algorithmic approaches to this idea.

\begin{algorithm2e}[t]
%	\magdalen{Need an early stopping metric as input} \\
	\caption{GreedyRangeSearch($Q,G,\mP, S, r,b , \mathcal{M}$).\protect}
	\label{algo: rangesearch}\small
	\SetKwBlock{ParDo}{do in parallel}{end}
	\SetKwFor{ParFor}{parallel for}{do}{end}
	\SetAlgoLined
	\DontPrintSemicolon
	\SetKwProg{myfunc}{Function}{}{}
	\KwIn{Query points $Q$, graph $G$, point set $\mP$, starting points $S$,   radius $r$, beam size $b$, early stopping metric $\mathcal{M}$}
%	\magdalen{Typo in out statement} \\
	\KwOut{Set of neighbors $\mathcal{V}$ within range  for each of the query points}
	
	%	Initialize $all\_neighbors[A.size()]$\;
	%	Initialize $visit\_order[A.size()]$\;
	%	Initialize $second\_round[A.size()] \gets 0$\;
	
	%	Define QueryParams $QP$ with:\;
	%	\quad Initial beam size: $RP.initial\_beam$\;
	%	\quad Graph constraints: size $G.size()$, max degree $G.max\_degree()$\;
	%	\quad Early stopping: $RP.early\_stop$, $RP.early\_stop\_radius$\;
	%	
	\ParFor{$q \in Q$}{
%		Initialize empty sequences $\mathcal{N}$ and $\mathcal{N'}$\;
		$\mathcal{N}\gets \emptyset$
		
		$(\mathcal{B}, \mathcal{V}) \gets BeamSearch(q, G, \mP, S, r, b, \mathcal{M})$\; 
		\tcp{Early stopping is done inside the beam search}
		%		$visit\_order[i] \gets visitedElts$\;
		
%		\magdalen{Typo} \\
		\ForEach{$n \in \mathcal{B}$}{
			\lIf{$\| n, q \| \leq r$}{
				$\mathcal{N} = \mathcal{N} \cup \{n\}$
			}
		}
		
		\lIf{$|\mathcal{N} | < b$}{
			$\mathbf{V}[q] \gets \mathcal{N}$
		}\Else{
%			\magdalen{set S to N and add a comment explaining}\\
		\tcp{Add results from beam search as starting points for greedy search}
			$\mathcal{V}[q] \gets GreedySearch(Q, G, \mP, \mathcal{N}, r)$\;
%			\tcp{R is set inside the query range}
%			\magdalen{Don't need to scan R for being within radius} \\
%			\tcp{I think I don't really need ans in this case. Perhaps just insert R into V[q]?}
%			$ans \gets \emptyset$\;
%			\ForEach{$n \in \mathcal{R}$}{
%				\If{$\|n, q \| \leq r$}{
%					\magdalen{Rename ans} \\
%					$ans \gets ans \cup \{n\}$;
%				}
%			}
%			$\mathcal{V}[q] \gets ans$\; 
%			\magdalen{Set V[q] to output of greedy search} \\
%			$\mathcal{V}[q] \gets \mathcal{R}$
%			$second\_round[i] \gets True$\;
		}
	}
	
	\Return $\mathcal{V}$\;
\end{algorithm2e}



\paragraph{Doubling Beam Search} The first, and perhaps most natural, algorithm extending beam search to queries with variable number results is a dynamic beam search: that is, run the beam search with some starting beam $B$ for a certain number of steps, then either terminate or double the beam and continue searching for more candidates. The algorithm terminates if fewer than some fraction $\lambda$ of returned candidates are valid range candidates, and continues otherwise. In practice, we found that the value of $\lambda$ did not change the results very much, so we set it to $1$ as a rule. That algorithm is shown using beam search as a subroutine in Algorithm~\ref{alg:doubling}. 


\paragraph{Greedy Search} Another approach to dynamically resizing the queue length is to run a beam search with \textit{unbounded} queue length, but much stricter criteria on which nodes are explored. In this approach, candidates are first generated by an initial beam search with beam $B$. If the number of candidates within the radius falls above a certain threshold (again, some fraction $\lambda$ of the candidates returned, which we found in practice not to matter significantly), the search moves onto this so-called "greedy search," which has an unbounded queue but only adds nodes to the queue if they are within the ball of radius $r$ around the query point for the specified radius. This approach takes advantage of the fact that nodes in the same ball of radius $r$ are likely to be in connected clusters, and avoids the overhead of the doubling beam search by performing very few distance comparisons to points which are not valid results. See Algorithm~\ref{alg:greedy} for a complete description, and Section~\ref{sec:experiments} for experimental analysis.

\subsection{Improving Range Search for Queries with No Results}

This section introduces an algorithm which improves range search for queries with no results. We start from the established paradigm of starting a search with fixed beam $B$ and continuing with Algorithm~\ref{alg:greedy} or Algorithm~\ref{alg:doubling} if the returned list contains only candidates within the radius. It would be ideal to terminate the initial beam search early if the query is not finding any results, and the termination condition should use terms that are already computed during the beam search, or inexpensive to compute. A 2020 paper from Li, Zhang, Anderson, and He
~\cite{li2020improving} addresses a similar question---finding conditions for terminating top-$k$ search early---and finds that several existing terms can be used to predict whether a search can terminate early. Those terms included the coordinates of the query point, the distance from the query point to the current top-$k$ neighbor for fixed $k$, and the ratio of the distance from the query point to top-$k$ neighbor and the distance from the query point to the start node. 

To apply these ideas to range search, the key question is whether any of these metrics are effective at distinguishing queries with zero results from queries with one or more result. To investigate this, we look at each dataset and separate each query set into three groups: those with no results, those with 1-2 results, and those with more than three results. Then, we histogram the values of these metrics at different steps in the beam search, distinguishing between these three groups. We evaluate the following metrics, the last three of which are proposed in ~\cite{li2020improving}. 

\begin{itemize}[noitemsep,nosep]
	\item $d_{\text{visited}}$: distance from query point $q$ to the point being visited at step $i$ of a beam search.
	\item $d_{\text{top1}}$: distance from query point $q$ to the closest known neighbor of $q$ at step $i$ of a beam search.
	\item $d_{\text{top10}}$: distance from query point $q$ to the tenth-closest known neighbor at step $i$ of a beam search.
	\item $d_{\text{top10}} / d_{\text{start}}$: ratio of $d_{\text{top10}}$ to the distance from query point $q$ to the starting point of the beam search.
\end{itemize}

\begin{figure*}
	\centering
	\includegraphics[scale=.35]{figures/dist_histograms/visited/bigann_test_legend.pdf} \\
	\begin{subfigure}{.85\textwidth}
		\centering
			\includegraphics[scale=.23]{figures/dist_histograms/visited/Step20/msmarco-1M.pdf}
			\includegraphics[scale=.23]{figures/dist_histograms/top1/Step20/msmarco-1M.pdf}
			\includegraphics[scale=.23]{figures/dist_histograms/top10/Step20/msmarco-1M.pdf}
			\includegraphics[scale=.23]{figures/dist_histograms/ratio/Step20/msmarco-1M.pdf}
			\caption{Histograms plotting selected early stopping metrics for all query points using dataset MSMARCO-1M.}
			\label{fig:msmarco_metrics}
	\end{subfigure}

	\begin{subfigure}{.85\textwidth}
		\centering
		\includegraphics[scale=.23]{figures/dist_histograms/visited_filtered/msmarco-1M.pdf}
		\includegraphics[scale=.23]{figures/dist_histograms/top1_filtered/msmarco-1M.pdf}
		\includegraphics[scale=.23]{figures/dist_histograms/top10_filtered/msmarco-1M.pdf}
		\includegraphics[scale=.23]{figures/dist_histograms/ratio_filtered/msmarco-1M.pdf}
		\caption{Histograms plotting selected early stopping metrics on dataset MSMARCO-1M, excluding query points which have already found a candidate within the radius.}
		\label{fig:msmarco_withexclusions}
	\end{subfigure}

		\begin{subfigure}{.85\textwidth}
		\centering
		\includegraphics[scale=.23]{figures/dist_histograms/visited/Step20/wikipedia-1M.pdf}
		\includegraphics[scale=.23]{figures/dist_histograms/visited/Step20/bigann-1M.pdf}
		\includegraphics[scale=.23]{figures/dist_histograms/visited/Step20/deep-1M.pdf}
		\includegraphics[scale=.23]{figures/dist_histograms/visited/Step20/ssnpp-1M.pdf}
		\caption{Histograms showing the value of $d_{\text{visited}}$ on more selected datasets. From left to right: Wikipedia-1M, BIGANN-1M, DEEP-1M, and SSNPP-1M.}
		\label{fig:visited_manydatasets}
	\end{subfigure}
	\vspace{3pt}
\caption{Histograms of early stopping metrics for selected metrics and datasets. All metric values were taken at step 20 of a beam search with beam 100. Queries are separated by color based on the number of range results.}
\label{fig:histograms_all}
\end{figure*}

Figure~\ref{fig:msmarco_metrics} histograms the metrics above for MSMARCO-1M at step 20 of a beam search with beam 100.  Algorithm~\ref{alg:earlystopping} shows a natural and general algorithm for imposing an early stopping condition on range search, using any one of these metrics. In all cases, when a search has already found at least one candidate within the specified range, the search does not terminate early. Otherwise, the early stopping condition is applied after a certain number of steps in the beam search. The algorithm terminates when the chosen metric is above a pre-specified cutoff. Thus, in Figure~\ref{fig:msmarco_metrics}, we show the same histograms as in Figure~\ref{fig:msmarco_withexclusions}, with points where the search has already found a point inside the radius excluded. The figure also shows vertical lines indicating a potential cutoff for Algorithm~\ref{alg:earlystopping}; points with more than one range result to the right of the line would be ``incorrectly" cut off from further search, while points with zero points to the right of the line would be ``incorrectly" allowed to proceed instead of terminating early. The goal is to identify a cutoff that yields a more favorable QPS/recall curve. Figure~\ref{fig:visited_manydatasets} shows one choice of metric---$d_{\text{visited}}$ on four different datasets. 

Based on this data, a larger set of which is shown in Appendix~\ref{apdx}, we come to three conclusions: first, some datasets show potential for significant improvement using early stopping, while others do not. Second, if a dataset shows potential for improvement using one metric, it also tends to show improvement for all other metrics. Third, using $d_{\text{visited}}$ seems to be the best early stopping metric, when examined using the exclusion criteria in Figure~\ref{fig:msmarco_withexclusions}. We hypothesize that $d_{\text{visited}}$ is the best metric as it is the most frequently updated and contains the most granular information, but the positive results from other metrics suggests that approaches using machine learning such as those in the Li et al. paper~\cite{li2020improving} might also be useful. We present experimental analysis of this algorithm in Section~\ref{sec:experiments}. See Algorithm~\ref{alg:earlystoppingexample} for an example of how to apply the $d_{\text{visited}}$ metric during a search, and Algorithm~\ref{algo: rangesearch} for an example of the end-to-end algorithm using greedy search. 





