\noindent We have implemented proof-of-concepts of \DANISH and \CAP for Apache Spark on Kubernetes -- see \autoref{sec:spark-k8s-imp} for details.  
We also conduct large-scale experiments in a realistic Spark simulator -- see \autoref{sec:spark-sim-imp} for how we extend an existing simulator~\cite{Hongzi:2019:Decima} to evaluate carbon-aware scheduling policies.
\vspace{-0.5em}

\subsection{Spark and Kubernetes integration} \label{sec:spark-k8s-imp}

\noindent \textbf{Resource scaling \& stage scheduling.\ }
In Spark deployed on a Kubernetes cluster, 
each application is submitted to the API server~\cite{k8s:2015} that creates a ``driver'' running in a pod.  
We use Spark's dynamic allocation feature, which enables the driver to create executor pods dynamically as needed by the application -- these executors connect with the driver and execute application code. 
Kubernetes handles the scheduling of (driver and executor) pods for each application, while the Spark driver selects stages to execute within an application.


To implement \CAP, we develop a Python daemon that gets carbon intensity from an API (e.g., Electricity Maps~\cite{electricity-map}) and adjusts the resources available to Spark.  \CAP sets a \textit{resource quota}~\cite{kubernetesResourceQuotas} within a dedicated namespace for Spark apps -- our implementation adjusts \textit{CPU and memory} quotas to correspond with a maximum number of executors.  When the quota is \textit{lowered}, existing pods are \textit{not} preempted, but new pods are not scheduled until usage falls below the quota.  
We implemented \DANISH as a pluggable scheduling service that coordinates between Spark and Kubernetes. 
The service includes inference for Decima~\cite{Hongzi:2019:Decima}. 
\DANISH gets carbon intensity from an API and collects context about the cluster and job states from Kubernetes and Spark.




While \CAP can be implemented without modifications to Spark or Kubernetes, we made two key changes for \DANISH.
First, we implemented a Kubernetes \textit{scheduler plugin}~\cite{k8s-scheduler-plugins:21} that communicates with \DANISH to determine which application should receive available resources.  
This builds on source code APIs exposed by the default \verb|kube-scheduler| and requires building/configuring a custom scheduler pod.  We restrict the scope of our plugin to a dedicated namespace for Spark apps.
Next, we made changes to Spark~\cite{Spark:16} such that each application communicates with \DANISH before choosing the next stage for execution -- Spark provides scripts to build a pod Docker image~\cite{Merkel:14:Docker} based on a custom build.

\vspace{0.05cm}
\noindent \textbf{Setting level of parallelism.\ }
In a Spark DAG, each \textit{stage} (i.e., node) includes multiple tasks that are parallelizable over multiple executors.
Setting a \textit{parallelism limit} (number of executors working on a stage) is a key component of Spark scheduling (e.g., see \cite[Section 5.2]{Hongzi:2019:Decima}). 
More executors are not necessarily better: assigning many executors to a stage that does not benefit from parallelism \textit{blocks} them from working on other jobs in the queue.
For \textit{carbon-aware} scheduling, we enable \DANISH and \CAP to set new parallelism limits for the current job each time a stage is scheduled, and particularly to set \textit{lower} limits during high-carbon periods (e.g., see conditions \textbf{i)} and \textbf{ii)}, \autoref{sec:theory}).

In \DANISH, if a stage is deferred, it \textit{idles} (see \sref{Alg.}{alg:danish}) the newly freed executors that prompted a scheduling event.  Otherwise, the stage's parallelism limit is set to $P' \coloneqq \lceil P \cdot \min \left\{ \exp( \gamma (L - c_t) ), (1-\gamma) \right\} \rceil$, where $P$ is the limit chosen by Decima.  This mirrors the exponential trade-off in \DANISH's design -- e.g., when the current carbon $c_t$ is close to $L$ the limit is set to $\lceil (1- \gamma) P \rceil$, and as $c_t$ grows, the limit decreases exponentially to $1$.
For \CAP, given that the underlying scheduler specifies a parallelism limit $P$, \CAP first attempts to schedule a stage with $P' = \lceil P \cdot \nicefrac{r(t)}{K} \rceil$, where $\nicefrac{r(t)}{K}$ is the ratio of the resource quota vs. the total number of executors.  If the number of available executors is less than $P'$, the current stage takes all of the remaining available executors.

\vspace{-0.5em}
\subsection{Spark simulator environment} \label{sec:spark-sim-imp}
\citet{Hongzi:2019:Decima} developed a simulator %
that is a faithful representation of Spark's \textit{standalone mode}  (i.e., where Spark is the cluster manager), achieving an error (i.e., in run times) of within 5\%~\cite[Fig. 18]{Hongzi:2019:Decima}.
This simulator captures all first-order effects of Spark execution (e.g., delays in executor movement, parallelism overheads) -- it has since seen wide use in Spark contexts~\cite{Shin:24, Hu:24, Gertsman:23, Mathur:23, Li:23:JSS, Bengre:21}.
We implement \DANISH and \CAP as extensions to this simulator, which provides fast evaluation and flexibility.  We make the following modifications:

\noindent$\blacktriangleright$ \textit{Carbon accounting: } Each job's carbon footprint is measured \textit{ex post facto} to avoid impacting simulator fidelity.  Once an experiment is complete, existing computations (e.g., executor times) and a carbon trace are used to tally the footprint.

\noindent$\blacktriangleright$ \textit{\CAP: } We implement \CAP as a wrapper over three carbon-agnostic schedulers in the simulator: FIFO, Decima, and Weighted Fair (a heuristic tuned for the simulator's test jobs).

\noindent$\blacktriangleright$ \textit{\DANISH: } We implement \DANISH to interface with Decima, which provides a probability distribution over tasks.


\noindent With these modifications, the simulator allows us to quickly test many scenarios with a high degree of accuracy.
\vspace{-0.5em}

