\section{Discussion}
\label{sec:discussion}

\rv{
While the results show that \name is able to simulate human-like eye movements when performing analytical tasks, there is a need to expand on our discussion of the model's practical implications, the generalizability of the modeling approach, and the limitations and potential for supporting sophisticated chart-based question answering.
}

\subsection{\rv{Applications}}

\rv{
\paragraph{Visualization design evaluation}
\name can assist in evaluation of chart design.
With well-controlled experiment conditions, eye tracking data afford valuable insight into chart designs, especially relative to alternative designs.
For example, \citet{goldberg2011eye} showcased eye tracking's value in comparing line and radial graphs for reading of values, by allowing researchers to understand the viewing order of AOIs and the task completion time.
\name holds potential to replace human input to evaluation based on eye tracking.
With the simulated scanpaths from \name, chart designers can obtain quick and cost-effective feedback that yields the benefits from eye tracking without requiring an expensive empirical study.
}
\rv{
\paragraph{Visualization design optimization}
Beyond evaluation, another potential usage application of \name is to help optimize visualization design~\cite{shin2023perceptual}. 
Like other fields of design, visualization design requires user feedback for continual iteration. When visualization designers create charts for specific tasks, they may wonder if the design is suitable for delivery.
With the predicted scanpaths from the model, they can easily access quick and affordable feedback before deeming a candidate design ready for expensive evaluation in a user study.
Predictive models could offer feedback to designers or even provide optimization goals in automated visualization design frameworks.
The ultimate goal is grounding for recommendations for visualizations that support specific tasks~\cite{albers2014task} and even automation of visualization design in real time.
Today's human-in-the-loop design optimization paradigm~\cite{kadner2021adaptifont} could shift to a user-agent-in-the-loop approach, wherein a computational agent that simulates human feedback enables scalable and efficient design evaluation.
}

\rv{
\paragraph{Explainable AI in chart question answering}
Systems for answering questions via charts~\cite{masry2022chartqa} are typically viewed as black boxes that generate answers directly from a given chart and natural-language question. 
In contrast, \name introduces a glass-box approach that answers questions through a step-by-step reasoning process. This method enhances the alignment between human and machine attention~\cite{sood2023multimodal}.
We anticipate that this approach could lead to significant improvements in chart question answering~\cite{masry2022chartqa} and greater compatibility with explainable AI systems.
}

\subsection{\rv{Extending the Model beyond Bar Charts}}

\rv{
Our modeling approach can be extended to many visualization types besides bar charts.
We analyzed the visualization taxonomy outlined in prior work~\cite{borkin2013makes, borkin2015beyond}, including area, circle, diagram, distribution, grid, line, map, point, table, text, tree, and network, then categorize these visualization techniques into two groups: those that are feasible to extend with minor changes and those that are out of reach, requiring additional features.
}

\begin{figure}[!t]
    \centering
    \subfigure[\rv{An \textit{RV} task with a line chart: ``What was the revenue from newspaper advertising in 1980?''}]{\label{fig:a}\includegraphics[width=0.48\textwidth]{Images/line-case.png}}
    \hspace{0.02\columnwidth}
    \subfigure[\rv{An \textit{F} task with a scatterplot: ``In which countries do people anticipate spending about \$700 for personal Christmas gifts?''}]{\label{fig:b}\includegraphics[width=0.48\textwidth]{Images/point-case.png}}
    \caption{\rv{Two cases that illustrate the generalizability of the modeling approach, showing the extension of \name to a line chart and a scatterplot. The model's predictions are spatially similar to human ground-truth scanpaths.}}
    \label{fig:case}
    % \vspace{-5mm}
\end{figure}

\rv{
Our modeling approach can be applied to most statistical charts either directly or upon rectification of minor issues. For instance, extending the model to interpret \textit{line charts} and \textit{area charts} is feasible when the axis labels are clearly defined. The trend patterns of lines and areas can be perceived by the peripheral vision as visual guidance.
For \textit{point charts}, such as scatterplots, the model performs well in conditions of sparse data points. However, individual points may be obscured in dense scatterplots, making it difficult to label data when points are cluttered or overlapping. 
\textit{Distribution charts}, such as histograms, and \textit{circle charts}, such as pie charts, are similar to bar charts in that they use the area of marks to represent values. Retrieving exact values from these two presentation types can be imprecise on account of the ranges of the bins and inaccuracies in estimating angles or arc lengths.
Reading \textit{grid charts} (e.g., heatmaps) too is feasible; however, identifying the values necessitates understanding color intensity, a factor that can sometimes lead to ambiguity.
Modeling scanpaths on \textit{tables} or \textit{text} for retrieval tasks is tractable under the current modeling approach, but a lack of visual pattern recognition may render the results poor.
To further examine the generalizability of this category, we considered two additional cases, using a line chart and a scatterplot. We manually labeled the charts, trained the model, and made predictions. As Figure~\ref{fig:case} attests, the trained model performs well for these two chart types when compared to human ground-truth scanpaths.
}

\rv{
Other, sophisticated visualization types are out of reach because they require additional features, particularly prior knowledge and advanced reasoning abilities. For instance, reading \textit{maps} involves associating spatial regions with colors, sizes, or symbols to retrieve related values. Also, when interpreting maps, people rely heavily on preexisting geographical knowledge as a basis for efficient visual searches. Complex designs with intricate structures, such as \textit{diagrams}, \textit{trees}, and \textit{network graphs}, typically require advanced reasoning based on connections. All these skill requirements point to a need for further study in this area.
}

\subsection{\rv{Paths toward Sophisticated Tasks in Chart Question Answering}}

\rv{
Although the model focuses primarily on gaze prediction, it is worth exploring potential improvements for enriching its sophisticated question answering capabilities. We also discuss its limitations.
}

\rv{
Our current model does not achieve the same level of accuracy as the state-of-the-art models represented by the ChartQA benchmark~\cite{masry2022chartqa}. 
Unlike other models that can access the full chart image, \name is limited by its foveal vision and restricted spatial reasoning abilities. For instance, if a bar's height falls between two labeled values, such as 10 and 15, the model might choose either 10 or 15 as its answer when interpreting the axis, failing to provide a more precise value. 
This limitation stems from the constrained spatial perception capabilities of LLMs, which are central to cognitive control.
One possible solution is integrating multi-modal LLMs~\cite{cuarbune2024chart}, for which recent research has demonstrated an accuracy rate of 81.3\%.
}

\rv{
The sense-making process for complex visualizations may be inherently challenging. Even humans often struggle with understanding how the data are encoded, recognizing a given chart's purpose, tackling readability issues, performing numerical calculations, identifying relationships among data points, and navigating the spatial arrangement of graphical elements~\cite{rezaie2024struggles}.
Our model is designed to be straightforward and objective, focusing on analysis tasks related to statistical charts, but it does not fully capture the complexities of visualizations.
A possible enhancement in this respect would be to integrate the model with human sense-making practices~\cite{rezaie2024struggles} or to incorporate a framework of human understanding~\cite{albers2014task}. Such integration could facilitate better simulation of a human-like problem-solving process.
}
