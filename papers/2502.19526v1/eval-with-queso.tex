\ur{Meta: justify why we chose the cutoffs we did (0.6) etc}

This section describes the implementation of the \coam{} algorithm,
the integration of the implementation with two different optimizers,
and presents an evalution.
%
For the evaluation, we consider the time performance and scalability
as well as the circuit quality on a range of quantum circuits.
%
As our primary baseline, we consider the \quartz{}~\cite{quartz-2022}
optimizer, a super optimizer for quantum circuits that uses rule-based
substitutions to optimize circuits.
%
We also demonstrate the applicability of our implementation to the
QUESO optimizer~\cite{queso-2023}, which also uses rule-based optimizations
with different algorithms and heuristics.
%

\subsection{Implementation} \label{sec:impl}
We implement the \coam{} algorithm (\secref{algorithm}) in SML
(Standard ML), which comes with an optimizing compiler, MLton, that
can generate fast executables.
%
Our implementation represents circuits as an array of arrays, where
each array denotes a ``layer'' of the circuit.
%
To split the first and last $\Omega-$window of a circuit,
we split the first and last $\Omega$ layers of the circuit respectively.
%
Other circuit management operations are simple operations on this array representation.


As with the algorithm, our implementation can work with any oracle,
allowing also using existing optimizers.
%
We consider two existing optimizers as oracles: \quartz{}
and \queso{}.
%
We chose these optimizers  for two reasons.
%
First, these optimizers are both the state of the art among the recent
optimizers.
%
Second, they exemplify two entirely different conditions in terms of
integrating with our work: \quartz{} naturally integrates with our
work whereas \queso{} is challenging to do so.


The \quartz{} optimizer~\cite{quartz-2022}, which is written in C++,
integrates naturally with our implementation, because we are able to
call C++ codes directly from our implementation through a
cross-language integration feature.
%
Specifically, to optimize a subcircuit, we translate the subcircuit to
the QASM format and make a direct (cross-language) function call to
C++ that takes a QASM string and a timeout.
%
The function runs the \quartz{} optimizer and returns a QASM string
that represents the possibly optimized version of the input.
%
The \quartz{} optimizer, in turn, translates the QASM string to a
DAG-based representation, loads the rewrite rules, and applies them
according to its pattern matching algorithm.
%
We translate the QASM output of \quartz{} into our array-based
representation and update the circuit.
%
Note that this introduces overhead to the running time
of our algorithm
because each call to \quartz{} changes the circuit representation
and also pays for the initialization cost of \quartz{}.
%

To mitigate this overhead,
we send subcircuits of size $10*\Omega*n$ to \quartz{},
instead of the size $2*\Omega*n$ described in the algorithm,
where $\Omega$ represents \coam{}'s parameter and $n$ is the
number of qubits.
%
By sending larger circuits to \quartz{},
we ensure that the overhead does not dominate
the time to execute one function call to \quartz{}.
%
%This reduces the number of calls and thus reduces the cross-language
%overhead.
%
When the per call timeout is large enough, we send subcircuits of
size $2*\Omega*n$ as described in the algorithm.
%
% We also cache the rules used by quartz to reduce this overhead.
\ur{I did not understand the last sentence with 2Omega.}

\jr{revisit}

The \queso{} optimizer~\cite{queso-2023}, which is written in Java, does
not naturally integrate with our implementation, because our
implementation language does not cross-operate with Java.
%
We therefore integrate \queso{} via the operating system.
%
Specifically, to invoke \queso{} on a subcircuit, our \coam{}
implementation writes the QASM representation to a file and
calls \queso{} by using a system call.
%
This system call, in turn, writes its output to another file, which
our \coam{} implementation reads.
%
Because the overhead is large and difficult amortize by increasing
subcircuit sizes, our integration with \queso{} incurs significant
overhead.
%
Nevertheless, this integration demonstrates the feasibility of
integrating with existing optimizers either through cross-language
interoperability features (when feasible) or through systems calls.
%

% For this reasons, we compare with \queso{} only on a few benchmarks.
%
% \ur{This last sentence does not sound right.  It can be interpreted as ``the results were not good, so we are not showing you everything'' }


\paragraph{\coam{} configuration}

For our experiments, we configure several different configurations
of \coam{}

\begin{itemize}

\item \coamwith{\quartzt{0.06}}
refers to our implementation of \coam{} with \quartz{} running as oracle
where each call to \quartz{} is capped to complete in 0.06 seconds.

\item \coamwith{\quartzt{0.6}}: \coam{} with \quartz{} oracle,
with upto 0.6 seconds per call

\item \coamwith{\quartzt{6}}: \coam{} with \quartz{} oracle,
with upto 6 seconds per call

\item \coamwith{\quesot{1}} refers to our implementation of \coam{} with \queso{} running
as oracle where each call to \queso{} is capped to complete in 1 second.
\footnote{1 second is the minimum timeout \queso{} supports.}
\end{itemize}
%

%% We then run vanilla \quartz{} on the whole circuit
%% for the same end-to-end time as our algorithm
%% and compare the circuit quality.
%% %
%% We perform this experiment with three different timeouts ($t = 0.06$s, $0.6$s, $6$s),
%% each of which increases the end-to-end running time ten fold.
%

For all our experiments, we set the window width of \coam{} to $6$,
i.e., $\Omega = 6$.
%
We choose this value because
it aligns with the default optimization behavior of \quartz{} and \queso{},
both of which only focus on sub circuits of size $6$ at any optimization step.
%
As described in their respective papers,
the size $6$ is a sweet spot for both the tools,
since increasing the size hinders time performance,
and decreasing it harms circuit optimizations~\cite{quartz-2022, queso-2023}.
%
By setting the window width to $6$,
our algorithm feeds all subcircuits of size $6$ to \quartz{}/\queso{},
giving them enough scope to apply their optimizations.
\footnote{We note that this size $6$ is for the Nam gate set that we use in this paper.}

\myparagraph{Benchmarks.}
\input{benchmarks.tex}


\subsection{\coam{} scales linearly with the size of circuits}
\input{fig/linearity.tex}

To optimize circuits,
both \quartz{} and \queso{} execute a search algorithm
by maintaining a search queue of candidate circuits.
%
At each step,
they pop a circuit from the queue and discover ways to rewrite parts of the circuit
by referring to their database of equivalent circuits.
%
Then,
they insert the new circuits back to the queue and repeat the process
until the queue becomes empty.
%
Since the number of circuits to consider grows exponentially with the size of the circuit,
both tools use a ``beam search algorithm'',
a search algorithm that limits the size of the search queue
and appropriately drops circuits after the limit is reached.
%
Because beam search limits the size of the search queue,
its space usage is linear in the size of circuit
(it only stores a fixed number of circuits at any point).
%

However, despite dropping circuits,
\quartz{} and \queso{} deliver poor time scalability,
because the number of the circuits that need to be considered
increases exponentially with the size
of the circuits
and so does the running time of both the tools.
%
For instance,
\queso{} takes eighteen seconds to terminate on a circuit of size 48,
which jumps to an hour on a circuit of size 96 (a $20$x increase),
and further jumps to around six hours for a circuit of size 326 (a $6$x increase).
%
\quartz{} on the other hand does not terminate on the $48$ sized circuit within $24$ hours.
%
Because of their exponential time complexity,
both approaches deliver poor time scalability and
in practice, provide no quality guarantee.
%
With the \coam{} algorithm,
our goal is to deliver a quality guarantee in reasonable running times
that scale linearly with the size of circuits.

In this section,
we demonstrate the scalability of the \coam{} algorithm
by measuring its execution time across different sizes of benchmarks.
%
For this experiment, we use $\quartzt{0.06}$ as our oracle
(i.e., each sub circuit is optimized by calling \quartz{} for a duration of $0.06$ seconds).
%
We consider four quantum algorithms: Grover, VQE, QPE, and QFT,
and plot the results in \figref{linear}.
%
The Y-axis shows the execution time and the X-axis shows the size of benchmarks.
%
We vary the size of circuits by changing the number of qubits in the corresponding algorithms.
%
The plots show that the execution time scales linearly
across sizes ranging from a few hundreds of gates to circuits as large as $0.14$ millions
of gates.
%
For example,
in case of the VQE algorithm,
the \coam{} algorithm takes around five seconds for the smallest circuit of size two thousand
and takes around 300 seconds for the largest circuit of size one hundred thousand ($136000$ precisely).
%
We provide the data points for our plots in the Appendix.
%

One of the key benefits of our algorithm
is that runs in a predictable amount of time and within that time,
guarantees $\Omega-$optimality.
%
In the next subsection,
we establish that ensuring $\Omega-$optimality leads to good circuit quality.

% \cleardoublepage
% \cleardoublepage
\subsection{Scalable optimization using \coam{} with \quartz{}} \label{sec:quartz}
In this section, we study the benefits of our \coam{} algorithm
when used with \quartz{}.
%
We optimize the circuit with the \coam{} algorithm using \quartz{} as the oracle,
where each oracle call is capped by a fixed amount of time.
%
Then,
we run the default \quartz{} on the whole circuit for the same end-to-end time
%
and compare the circuit quality.

%
\begin{figure*}
  \centering
  \input{fig/prelim.0.01}
  \caption{The figure compares the performance of $\coamt{\quartzt{0.06}}$ against standard \quartz{}.
  The label ``S'' represents $\coamt{\quartzt{0.06}}$ and the label ``Q'' represents \quartz{}.
  %
  The figure compares the circuit sizes (lower is better) and the optimization rates (higher is better) of both approaches.
  %
  The optimization rate measures the number of optimizations performed per second of execution.
  %
  Both the approaches execute for the same end-to-end time and the figure presents the running time in the ``Time'' column (in seconds).
  }
  \label{fig:comp-small}
\end{figure*}

\figref{comp-small} shows the result of this comparison,
where each call to \quartz{} is limited to $0.06$ seconds,
i.e., the figure shows results of configuration $\coamwith{\quartzt{0.06}}$.
%
The figure shows the original circuit sizes
and displays the circuit sizes after optimization.
%
The figure labels the results of the \coam{} algorithm as ``S'' and
the standard \quartz{} approach as ``Q''.
%
In the cases where one approach performs better,
the figure uses bold numbers, with lower numbers indicating better circuit quality.
%
The `C/Q' ratio column quantifies the improvement using the \coam{} algorithm w.r.t. standard \quartz{}.
%
The figure also provides and compares the \defn{optimization rate} of both approaches,
where the optimization rate is the number of gates optimized per second of execution.
%
A higher rate indicates faster optimizations.
%
The time column shows the execution time
for both cases.



\myparagraph{Quality.}
We observe that in seventeen cases,
using the \coam{} algorithm improves the quality of circuits w.r.t. standard \quartz{}
and sometimes does so by a wide margin.
%
In the other seven cases,
both approaches output the same quality of circuits.
%
For the hhl circuits,
the \coam{} algorithm finds reductions ranging from $23\%$ to $27\%$,
where \quartz{} does not find many optimizations
within this time (less than $5\%$).
%
In the case of grover circuits,
the \coam{} algorithm optimizes gate count by $10\%$ across the various sizes.
%
However, the efficacy of \quartz{} reduces from $9\%$ to $0\%$ with increasing sizes.
%
In the qpe circuits,
neither approach finds any optimizations.
%
This is because the core of these circuits
is a modular exponentiation circuit which is already well optimized.
%
For the vqe family,
the \coam{} algorithm reduces the gate count by around $60\%$ and
the optimizations by \quartz{}
are around $10\%$ of the circuit in the same time.
%
Overall, we observe that \coam{} generates $0.73$x smaller circuits on average.

\myparagraph{Scalability.}
Across the board,
we observe that the gap between the two approaches widens with increasing circuit sizes.
%
This is because the efficiency of \quartz{},
quantified by optimization rates,
reduces with increasing circuit sizes,
whereas the \coam{} algorithm scales to larger sizes.

For example,
across different sizes of qft,
the \coam{} algorithm achieves optimization rates
ranging from $50$ to $85$ and the rates in fact increase as the circuit size grows.
%
In contrast,
the optimization rate for \quartz{} reduces from around $28$ to $16$.
%
The 'C/Q' ratio of optimization shows how many more optimizations (per second)
the \coam{} algorithm identifies compared to \quartz{}.
%
Compared to \quartz{},
the \coam{} algorithm yields $1.78$x and $5.19$x more optimizations per second
for the smallest and largest qft instances
respectively (see the ratio column in \figref{comp-small}).
%
Similarly,
in the case of vqe,
the gap in their optimization rates
rises from around $2$x on the smallest instance to $42$x
on the largest instance.

All families of circuits follow a similar trend:
the optimization rate ratio between the \coam{} approach and the \quartz{} optimizer
increases with the circuit size,
demonstrating the scalability advantages of the \coam{} algorithm.
%
This scalability advantage of the \coam{} approach is built into the algorithm
because it calls \quartz{} only on small circuits,
where \quartz{} delivers excellent results.
%
The algorithm never sends large circuits to \quartz{},
where  \quartz{} struggles,
and instead, stitches together small circuits by melding them (\secref{algorithm}).
% Because the \coam{} algorithm runs in linear time,
% it delivers good scalability as circuit sizes increase.
% %
% %
% %
% Because the execution time is equal for both approaches,
% the ratio column additionally represents the ratio of total optimizations.
%
% %
% For example,
% consider the ratio column of \figref{comp-small} which compares the optimization rates
% of the \coam{} algorithm with \quartz{}.
%
\begin{figure*}
  \centering
  \input{fig/prelim.0.1}
  \caption{
    The figure compares the performance of $\coamwith{\quartzt{0.6}}$ against standard \quartz{}.
    %
  The label ``S'' represents $\coamwith{\quartzt{0.6}}$ and the label ``Q'' represents \quartz{}.
  %
  The figure compares the circuit sizes (lower is better) and the optimization rates (higher is better) of both approaches
  after running them for the same end-to-end time.
  }
  \label{fig:comp-med}
\end{figure*}

\myparagraph{Consistency.}
Since the \coam{} algorithm partitions the circuit into pieces
and melds them together,
it raises the question whether the splitting and melding loses any optimizations.
%
We evaluate this question by running the standard \quartz{},
which operates on the whole circuit, for a longer running time
and comparing the quality achieved.

We extend the running time by increasing the per-call timeout to \quartz{}
to $0.6$s, i.e.,
we consider the configuration \coamwith{\quartzt{0.6}}.
%
We note that the end-to-end running time becomes at least ten fold in this configuration,
and we run the standard \quartz{} for the extended time.
%
The figure shows that the \coam{} algorithm consistently generates better quality circuits
in all families.
%
We note that the gap between the approaches has reduced.
%
This occurs because as optimizers operate for longer times,
their optimization rates diminish due to the
increasing difficulty of finding further optimizations~\cite{quartz-2022, queso-2023}.
%
The difference in optimization rates between \figref{comp-small} and \figref{comp-med}
exemplifies this.
%
For example, the optimization rate in vqe\_n12 for \quartz{} reduces from around $30$ to $12$
when its execution time increases from $37$ seconds to $640$ seconds.
%
The many fold extension of execution time decreases the optimization rates of both approaches
and moderates the scalability advantages of the \coam{} algorithm.
%
On average,
circuits generated by the \coam{} algorithm are $0.9$ times smaller than those generated by
\quartz{}.
%/
In the Appendix,
we include a third configuration (\coamwith{\quartzt{6}})
where we further increase the time ten fold and observe a similar trend,
where \coam{} continues to deliver better quality circuits.
%

We conclude that, in practice,
the \coam{} algorithm comes at no cost to circuit quality
even with the extended runtime,
as it never generates a worse quality circuit.
%

% To summarize,
% \figref{fig:comp-small} demonstrates that the \coam{} algorithm
% drastically improves the speed of optimization for each circuit.
% %
% It shows that the algorithm scales well with circuit size,
% achieving excellent optimization rates across a range of sizes.
% %
% \figref{fig:comp-med} shows that this performance
%

%


% \input{fig/prelim2.0.01}



% To summarize,
% \figref{fig:comp-small} demonstrates that the \coam{} algorithm
% drastically improves the speed of optimization for each circuit.
% %
% It shows that the algorithm scales well with circuit size,
% achieving excellent optimization rates across a range of sizes.
% %
% \figref{fig:comp-med} shows that this performance comes at no cost to circuit quality
% even with the extended runtime,
% as the \coam{} algorithm never generates a worse quality circuit.
% %


\subsection{Scalable optimization using \coam{} with \queso{}}

\begin{figure*}
  \centering
  \input{fig/queso}
  \caption{
  The figure compares the performance of $\coamwith{\quesot{1}}$ against standard \queso{}.
  %
The label ``S'' represents $\coamwith{\quesot{1}}$ and the label ``Q'' represents \queso{}.
%
The figure compares the circuit sizes (lower is better) and the optimization rates (higher is better) of both approaches
after running them for the same end-to-end time.
}
  \label{fig:comp-queso}
\end{figure*}

In this section,
we evaluate the \coam{} algorithm using the \queso{} optimizer.
%
We integrate the \queso{} optimizer into our algorithm as an oracle
and impose a one second time out for each call.
%
We note that \queso{} does not follow the given timeout strictly
and often takes longer to run and return the result (around $4/5$ seconds per call).

To evaluate the algorithm,
we run it with \queso{} and compute the final circuit
and the overall execution time, excluding time for file I/O (\secref{impl}).
%
Then, we execute default \queso{} on the whole circuit for the same total runtime
and compare the quality of circuits produced.
%
For this experiment,
we filter benchmarks based on their sizes and
opt for benchmarks whose sizes are less than ten thousand gates.
%
This size limitation arises from file I/O overheads which make restrict our ability
to run larger circuits within reasonable times.

\figref{comp-queso} shows the results of the evaluation for seven benchmarks
coming from four families of algorithms.
%
The ``QS'' column denotes \queso{} and the ``S'' column represents the \coam{} algorithm
using \queso{} as the oracle.
%
In all cases, the \coam{} approach generates smaller circuits than the baseline \queso{}.
%
Similar to the case with \quartz{} (\secref{quartz}),
we observe that the gap between the \coam{} approach and default \queso{} increases
with circuit size.
%
Foe example,
in the grover family,
the ratio of optimization rate between \coam{} and \queso{}
increases from $1.14$x for grover\_n7 to $1.4$x in grover\_n9.
%
For the circuit vqe\_n12,
which is the largest circuit on the table,
the final circuit size is $0.78$ times smaller compared to \queso{},
which demonstrates the scalability of the \coam{} approach.
%
On average,
the algorithm's circuits are $0.92$x smaller than those generated by \queso{}
and the algorithm makes $1.27$x as many optimizations per second.
%

The evaluation demonstrates that the \coam{} algorithm
improves the scalability of the \queso{} optimizer and
consistently delivers better quality circuits.


\subsection{CNOT and T count reduction}
\begin{figure*}
  \centering
  \input{fig/clifft}
  \caption{Evaluating $\coamt{\quartzt{6}}$ on metrics
  T count and CNOT count for benchmarks in \clifft{} gate set }
  \label{fig:comp-cliff}
\end{figure*}

% IT IS WELL KNOWN That xxx. IN principle, we could have an optimizer. We therefore to evaluate.
We have evaluated benchmarks with gate count
as the quality metrics
because our oracles, \quartz{} and \queso{}, directly support it.
%
However, it is well known that depending on the gate set,
other metrics become more important.
%
For example, in the \clifft{} gate set,
T count is an important metric of circuit quality
because T gates they are not as computationally efficient
compared as the Clifford gates (T gates roughly cost 50x other gates in practice \cite{Nam_2018}).
%
Similarly, CNOT count is another important metric because CNOT
gates operate on two qubits and are expensive to implement.
%


In this section,
we evaluate the benefit of our current configuration, i.e. $\coamwith{\quartzt{6}}$,
for metrics ``T count'' and ``CNOT count''.
%
Note that, in principle,
we could plug in an optimizer which is designed for these metrics,
but here we evaluate the benefit with \quartz{} that is designed with circuit size
as the metric.
%
To do so, we translate our benchmark suite, expressed in the Nam gate set,
to the \clifft{} gate set.
%
We then translate the optimized version of our benchmarks
and compare the unoptimized and optimized translation.
%
%

To translate a benchmark from the Nam gate set to the \clifft{} gate set,
we use gridsynth,
a tool that translates parameterized $\mathsf{R_Z}$ gates
to the \clifft{} gate set in provably optimal fashion~\cite{gridsynth}.
%
We also decompose the $\mathsf{X}$ gate to \clifft{} circuits
using the Qiskit compiler.
%
We run Qiskit  in the mode where it does not perform any optimizations.
%
Note that the translation does not change the CNOT count because
it only removes single qubit nam gates and replaces them with single qubit Clifford gates.
%
Thus, the CNOT count comparison stays the same for both, the Nam and the \clifft{} gate sets.

\figref{comp-cliff} shows the results of this evaluation.
%
The figure compares
the circuit size, the T count, and CNOT count,
of the unoptimized translation and the optimized translation
with columns labelled ``U'' and ``O'' respectively.
%
Across the board,
we observe that the implementation finds reductions in size and
they correlate with reductions in T count and CNOT count.
%
In case of the ham15-med circuit,
the implementation reduces the T count by $7\%$
and the CNOT count by $6\%$;
the larger variant, circuit ham15-high,  also shows similar numbers.
%
For qft circuits,
we observe that gate count reduction and T count reduction
is perfectly correlated,
as both are reduced by the same percentage on all the qft instances.
%
On average,
the implementation reduces the circuit size by around $11.8\%$,
the T count by $6.8\%$, and the CNOT count by $5.68\%$.



% \input{prelim}

% \cleardoublepage
% \subsection{Eval half 2}
% \input{prelim2.tex}
% \subsection{Plots}
% \input{plots_greedy.tex}
% \cleardoublepage
% \subsection{Cliff Eval half 1}
% \input{prelim1.clifft}
% \cleardoublepage
% \subsection{Cliff Eval half 2}
% \input{prelim2.clifft}
% \subsection{Plots Cliff}
% \input{plots_greedy_cliff.tex}
