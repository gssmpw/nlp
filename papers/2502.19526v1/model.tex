\label{sec:model}

% For optimizers that are unable to scale for large circuits,
% it means that any improvements beyond $\Omega-$optimality
% would come with a steep cost to the running time of circuit optimization


% $\Omega-$optimality is a good quality target
% because it implies that there are no easy optimizations left.
% %
% Any improvements beyond $\Omega-$optimality
% would come with a steep cost to the running time of circuit optimization.
% %

We describe the quantum circuit model that we assume throughout the
paper and define two local optimality properties on this model.
%
The properties capture the intuitive notion that many
optimizations involve gates that are closely positioned in a quantum
circuit, e.g., an optimization may replace a small subcircuit of 10
gates with a circuit with 4 gates.

\myparagraph{Circuit Model.}
We model a circuit $C = \langle L_0, L_2, \ldots L_{d-1}\rangle$ as a
sequence of layers $L_i$, where each layer contains a (non-empty) set
of gates that operate on disjoint qubits.
%
In this model, we can split and concatenate circuits by splitting and
concatenating the underlying layer sequences.
%
We define the \defn{depth} of a circuit as the number of layers
and the \defn{size} of a circuit $C$, denoted $|C|$, as the total number of gates.
% Our algorithm optimizes the circuit at the granularity of
% subcircuits we call \emph{segments}.
%
A \defn{segment} is a contiguous subsequence of layers of the circuit.
%
We use the python style notation $C[i : j]$ to represent a segment containing
layers  $L_i\dots L_{j - 1}$ from circuit $C$.
%
The depth of a segment is the number of layers and its size is the cumulative
gate count across those layers.
%
%
We define a $\boldsymbol{k}$\defn{-segment} as a segment of depth $k$.
%
Note that the size of a $k$-segment is at most $k \cdot n$,
where $n$ is the number of qubits in the circuit.

%
To define local optimality, we use the number of layers, or depth, as
the notion of distance for locality.
%
Specifically, we say that a circuit is locally optimal with respect to
a cost, if all segments of the circuit smaller than a desired depth
are optimal with respect to that cost.
%
%% \ur{Might want to add something about vertical but could also hold
%%   off: we allow all qubits to interact because this is common. }

\begin{definition}[Local Optimality]
  A circuit is \defn{$\boldsymbol{\mathit{\Omega}}$-optimal} with
  respect to a given cost function when every segment of depth less than or equal to
  $\Omega$ is optimal with respect to that cost.
\end{definition}

Though easier than global optimality,
achieving local optimality could also be difficult because producing the best circuit
for a given $\Omega-$segment can still be expensive.
%
Thus, it is more practical to define a relaxed, ``relative''
local optimality notion that does not insist on full optimality of the subcircuits,
and instead, requires each such subcircuit to be optimal relative to
a given oracle optimizer.
%

% \myparagraph{$\boldsymbol{\Omega}$-optimality.}
% Given an input circuit $C = \langle L_1, L_2, \ldots L_d\rangle$,
% the algorithm returns an optimized circuit $C'$ represented as
% $\langle L'_1, L'_2, \ldots L'_{d'}\rangle$.
% %
% This optimized circuit satisfies two properties:
% (1) the number of layers $d'$ in circuit $C'$ is bounded by the number of layers
% $d$ in circuit $C$,
% and
% (2) $C'$ is $\Omega$-optimal, according to the following definition.
%
\begin{definition}[Relative Local Optimality]
  A circuit is \defn{$\boldsymbol{\mathit{\Omega}}$-optimal}
  \defn{relative} to an oracle optimizer if the oracle can not improve
  any segment of depth $\Omega$ or smaller.
\end{definition}

\input{fig/fig-overlap}

To illustrate the definition of local optimality,
\figref{overlap} shows a circuit in the layer representation.
%
The figure defines an $\Omega-$segment $W_i = C[i:i + \Omega]$,
starting at layer $i$ and including $\Omega$ layers from
$i$ to $i + \Omega - 1$.
%
If all segments $W_i$ for $0 \leq i \leq D - \Omega$ are optimal relative to the oracle,
then the circuit is $\Omega-$optimal.
%
We can therefore verify if the circuit $C$ is $\Omega$-optimal by
checking that each of the at most $(D - \Omega + 1)$ segments is optimal
by using an oracle for relative optimality.
%



The notion of relative local optimality is practical,
as it defines a quality criterion that can be used with many existing optimizers.
%
When an optimizer does not scale to large circuits,
we can use relative $\Omega-$optimality as the goal of optimization.



\myparagraph{A Lower Bound on Local Optimality.}
%
This leaves open the question of whether there is a general purpose algorithm for local
optimality that works for all oracles
and whether such an algorithm could be practical.
%
We prove a lower bound stating that such an algorithm would
require at least linear time in the size of the circuit.

\begin{theorem}[Local Optimality Requires Linear Time]
  Consider a circuit $C$ over $n$ qubits with depth $D$ and a cost
  function.  for any $\Omega > 1$ and $D > 1$, finding a circuit that
  is equivalent to $C$ but that is $\Omega$- optimal with respect to
  the cost function requires $\bigomega(|C|)$, i.e., linear time in
  the size of the circuit.
\end{theorem}
\begin{proof}
Consider any gate in the circuit $C$, because $\Omega > 1$ and $D >
1$, this gate is part of at least one $\Omega$-segment and the segment
might be suboptimal, e.g., if the gate is before/after a
gate in the segment that is its inverse.
%
An algorithm guaranteeing local optimality
must therefore check each gate and possibly the gates
that are nearby that gate.
%
Because checking a gate requires constant time, any algorithm that
guarantees local optimality requires linear time in the size of the
circuit.
\end{proof}

% Our goal is to design an algorithm that produces circuits that satisfy local optimality
% relative to existing practical optimizers.

% For a given fixed, $\Omega$, and family of circuits whose number of
% qubits are bounded by a constant, running the optimization on
% $\Omega$-depth circuits takes constant time asymptotically.
% %
% Because each verification call takes constant time and there are a
% polynomial number of calls that require verification, the local
% optimality problem is in NP for circuits with constant number of
% qubits.
% %
% A similar argument applies to oracle optimizers and the relative local
% optimality problem is also in NP for circuits with constant number of
% qubits.
% %
% (Recall that, in contrast, circuit optimization problem is QMA-hard.)






%% Because optimizing large segments/circuits is a challenging problem,
%% improving an $\Omega-$optimal circuit incurs a steep cost to the running time,
%% making $\Omega-$optimality a good quality goal.
%% %
%% $\Omega-$optimality implies that all optimizations that are relatively easy
%% for a given optimizer have been performed.
%% %
%% Our goal is to achieve $\Omega-$optimality by using the oracle on small segments.
%% %
%% We assume the following about the oracle.
%% % specifically we invoke the oracle on a circuit only if its contained within a segment of depth $2\Omega$.
%% %
%% % This way, the size of an oracle query is bounded by $2n\Omega$ gates for $n$ qubits.


%% %
%% Relative $\Omega-$optimality guarantees that all $\Omega-$segments
%% of a circuit are optimal w.r.t. an oracle optimizer.
%% %
%% The number of $\Omega-$segments in a circuit of depth $d$ is $(d - \Omega + 1)$.
%% %
%% By guaranteeing that all $\Omega$-segments are optimal, relative
%% $\Omega$-optimality ensures that the only way for the optimizer to
%% improve the circuit further is to consider large segments (of depth
%% greater than $\Omega$).
%% %
%% Because optimizing large segments/circuits is a challenging problem,
%% improving an $\Omega-$optimal circuit incurs a steep cost to the running time,
%% making $\Omega-$optimality a good quality goal.
%% %
%% $\Omega-$optimality implies that all optimizations that are relatively easy
%% for a given optimizer have been performed.
%% %
%% Our goal is to achieve $\Omega-$optimality by using the oracle on small segments.
%% %
%% We assume the following about the oracle.
%% % specifically we invoke the oracle on a circuit only if its contained within a segment of depth $2\Omega$.
%% %
%% % This way, the size of an oracle query is bounded by $2n\Omega$ gates for $n$ qubits.



%

% As illustrated in \figref{overlap},
% this covering guarantees that every $\Omega$-segment is contained within some $2\Omega$-segment.
% %
% If the oracle does not improve any $2\Omega$-segment,
% then the oracle has certified all $\Omega-$segments to be optimal
% and the circuit is $\Omega$-optimal.
% %
% Since the number of $2\Omega$-segments is bounded by circuit size,
% the time cost of checking $\Omega$-optimality is bounded by the circuit size.
% %
% In the next subsection,
% we describe the \coam{} algorithm that in fact
% achieves $\Omega-$optimality in linear time.
% %

% Given a circuit,
% we can verify if it is $\Omega-$optimal
% by covering the circuit in many overlapping $2\Omega$-segments and querying
% the oracle on each such segment.
% %
% %

% %




% the time cost of the algorithm for checking $\Omega-$optimality
% is linear in circuit size because the number of oracle calls is bounded by circuit size.
%

%


\myparagraph{Additive Cost Functions.}
Our definitions of local optimality and relative local optimality make
no assumptions on the cost function.
%
In the rest of the paper, we focus our attention on cost functions
that map circuits to natural numbers.
%
Most interesting cost functions satisfy this constraint, e.g., the
total number of gates in a circuit, total weight of the gates where
weight could denote some property such as the time units needed for
that gate, or the depth of the circuit, etc.
%
If costs are not natural numbers, we can scale them (by additing and
multiplying with appropriately chosen constants) to obtain natural
numbers.

In our algorithm for computing local optimality, we assume that cost
functions are additive under circuit concatenation.
%
\begin{definition}[Additive Cost Functions]
\label{def:additive-cost}

We say that a cost function $\kwcost{\cdot}$ from circuits to costs is
additive if the function maps circuits to positive natural numbers
such that the cost of the concatenation of any two circuits $C_1$ and
$C_2$ is equal to the cost of individual circuits, i.e.,
\[
\kwcost{\circuitcon{C_1}{C_2}} = \kwcost{C_1} +  \kwcost{C_2}.
\]
\end{definition}


%% We assume that the cost function that is additive w.r.t.
%% circuit concatenation,
%% i.e., for any circuits $C_1$ and $C_2$,
%% $\costof{\lstinline{concat}(C_1, C_2)} = \costof{C_1} + \costof{C_2}$.
%% %
%% For simplicity, we assume that the cost function computes integer costs.
%% %
%% Most practical cost functions can be multiplied by a large constant
%% to approximate fractional costs.

%% In our model, one way to achieve $\Omega-$optimality is by
%% improving the $\Omega$-segments of a circuit using the oracle
%% and repeating until we reach a fixed point where all of them are optimal.
%% %
%% The repetitions can only occur $\costof{C}$ times because each oracle optimization
%% reduces the cost function by at least one (the cost function is integer valued).
%% %
%% Because the maximum number of repetitions is $\costof{C}$
%% and each repetition can use the oracle at most $\sizeof{C}$ times,
%% we can achieve $\Omega$-optimality within $\sizeof {C} * \costof{C}$ calls to the oracle.
%% %
%% In contrast, the SOAM algorithm achieves $\Omega$-optimality in $O(\sizeof{C} + \costof{C})$ calls
%% by carefully tracking optimal segments and propagating the optimizations among them.


%

% because a segment of with $2 \cdot \Omega$ can only contain that many gates.
%




% Our algorithm's time complexity and quality assurance rely on two assumptions.
% %
% For the time complexity,
% we assume that the oracle takes constant time to optimize its input.
% %
% The assumption is realistic because the the algorithm only invokes the oracle on fixed-depth segments,
% thereby establishing an upper bound on the circuit size processed by the oracle.
% %
% For our quality guarantee, we assume that the oracle does not increase the
% size of the its input (i.e., it optimizes gate-count), and similarly does not
% increase the depth of its input.
% %
% Formally, for an input circuit $C$, if the oracle outputs circuit $C'$,
% then $|C'| \leq |C|$ and $\textit{depth}(C') \leq \textit{depth}(C)$.

% To facilitate split and meld operations on the circuit,
% the algorithm represents a circuit $C = \langle L_1, L_2, \ldots L_d\rangle$ as a sequence of
% layers $L_i$, where each layer contains a set of gates that operate on disjoint qubits.
% %
% In this representation,
% the algorithm can split and concatenate circuits
% by splitting and concatenating the underlying layer sequences.
% %
% Empty layers are deleted.
% %
% We define the \defn{depth} of a circuit as the number of layers
% and the \defn{size} of a circuit $C$, denoted $|C|$, as the total number of gates.
% %

% %
% We define a \defn{segment} as a contiguous subsequence of layers.
% %
% The \defn{width} of a segment is the number of layers, and the
% \defn{size} of a (sub)circuit $C$, denoted $|C|$, is the total number of gates,
% i.e., $|C| = \sum_i |L_i|$.








% Note that we can check $\Omega$-optimality in linear time,
% i.e., in $O(\sizeof{C})$ time,
% by covering the circuit in many overlapping $2\Omega$-segments and querying
% the oracle on each such segment.
% %
% As illustrated in \figref{overlap},
% this covering guarantees that every $\Omega$-segment is contained within some $2\Omega$-segment.
% %
% If the oracle does not improve any $2\Omega$-segment,
% then the oracle has certified all $\Omega-$segments to be optimal
% and the circuit is $\Omega$-optimal.
% %
% %
% It is also easy to create an $\Omega$-optimal circuit in $O(\sizeof {C} * \costof{C})$ time,
% by repeatedly calling the oracle on all $2\Omega$-segments
% until we reach a fixed point where there are no segments optimized.
% %
% This repetition can only occur $\sizeof{C}$ times because each one reduces the gate count by at least one,
% thereby reaching the fixed point in $O(\sizeof {C} * \costof{C})$ time.
% %

% In contrast, the SOAM algorithm achieves $\Omega$-optimality in $O(\sizeof{C} + \costof{C})$ time
% by carefully propagating the optimizations among segments.

