
We perform an empirical evaluation of the effectiveness of the
local optimality approach for quantum circuits.
%
Specifically, we consider the following research questions (RQ).
\begin{description}
    % \item[Question I:] Can the \algname algorithm be implemented with reasonable constant factors?
    % \item[Question II:] Can the implementation use existing different optimizers as oracles?
  \item[RQ I:] Is local optimality and the \algname{} algorithm
    effective in terms of efficiency, scalability, and optimization
    quality?

 \item[RQ II:] Is empirical performance consistent with the asymptotic bound?

 \item[RQ III:] What is the role of the lazy \textsf{meld} operation? 
 
 \item[RQ IV:] What is the impact of segment size $\Omega$ and
 compaction on the local optimality and performance of \algname{} algorithm?
\end{description}

To answer these questions,
we implement the \algname{} algorithm and integrate
it with \voqc{}~\cite{hietala2021verified} as an oracle.
%
We chose \voqc{} because it is overall the best optimizer both in
terms of efficiency and quality of optimization among all the
optimizers that we have experimented with.
%
%two different optimizers, \voqc{}~\cite{hietala2021verified} and \feyntool{}~\cite{amy2019formal}, as oracles.
%
%We evaluate the effectiveness of local optimality and \algname{}, on two gate sets
%and compare it with four state-of-the-art optimizers:
%\quartz{}, \queso{}, \voqc{}, and \feyntool{}~\cite{quartz-2022, queso-2023,hietala2021verified,amy2019formal}.
%
We evaluate the effectiveness of local optimality and \algname{}, on
the Nam gate set~\cite{Nam_2018} and compare it with three
state-of-the-art optimizers \quartz{}, \queso{}, and
\voqc{}~\cite{quartz-2022, queso-2023,hietala2021verified}.
%

In brief, these experiments show that our cut-and-meld algorithm
delivers fast optimization while closely matching (within 0.1\%) or
improving the optimization quality for all circuits.
%
These results show that the local optimality approach can be effective in
optimizing large quantum circuits, and can help scale existing optimizers. 

\iffull
In \appref{clifft}, 
\else
In the Appendix, 
\fi
we present results for
the Clifford+T gate set by using the \feyntool{}~\cite{amy2019formal},
as an oracle.
%
We omitted these from the main body of the paper due to space reasons
but note that they are similar to the results presented here in terms
of efficiency and quality.

\subsection{Implementation}
\label{sec:impl}

To evaluate whether the \algname{} algorithm  (\secref{algorithm})
is practically feasible,
we implemented \algname{}  in SML
(Standard ML), which comes with an optimizing compiler, MLton, that
can generate fast executables.
%
Our implementation closely follows the algorithm description.
%
It uses the layered circuit representation and
represents circuits as an array of arrays, where
each array denotes a ``layer'' of the circuit.
%
The implementation splits and joins circuit segments by
splitting and joining the corresponding arrays,
performing rounds of optimization and compaction.
%

As described in \secref{convergence-thresh}, our implementation
allows user control over convergence through
a specified convergence ratio $\epsilon$, where $0 \le \epsilon \le 1$.
In the evaluation, we choose $\epsilon = 0.01$, and analyze this choice in
\secref{compaction}.
% and 
%\iffull
%\appref{converge}.
%\else
%the Appendix.
%\fi
Note that regardless of $\epsilon$,
the implementation always guarantees that output is \wopttext.

Our implementation is parametric in the oracle being used. To allow calls to existing optimizers,
we use MLton's foreign function interface, which supports cross-language calls to C++.
%
Specifically, to use an existing optimizer as an oracle, we only need to provide a C++ wrapper that takes a circuit in QASM format as input
and returns an optimized circuit as output.


\if0
As described in \secref{convergence-thresh}, our implementation
allows user control over convergence through
a specified convergence ratio $\epsilon$, where $0 \le \epsilon \le 1$.
%
The implementation terminates when an optimization round reduces the cost by
a smaller fraction than $\epsilon$.
%
For example, with $\epsilon = 0.01$ and using the number of gates as the cost function,
the algorithm stops when fewer than $1\%$ of the gates are removed in a round.
%
Regardless of $\epsilon$,
the implementation always guarantees that output is \wopttext;
setting $\epsilon = 0$ additionally ensures that the circuit is locally
optimal.
%
The convergence ratio thus acts as an ``optimization level'' parameter,
similar to those in many optimizers
(e.g., \texttt{"-O"} option of C/C++ compilers, \texttt{"opt-level"} option of Rust).
%
We evaluate both settings $\epsilon = 0.01$ and $\epsilon = 0$ and find
no difference in output quality.
%
As we study in \secref{converge}, the main reason for this is that after the first one/two rounds,
the circuit is almost optimal and any further rounds
do not improve the circuit significantly.
%
%We present the results for $\epsilon = 0.01$ in the main body and
%for $\epsilon = 0$ in the Appendix.

Similar to the algorithm, our implementation is parametric in the oracle being used.
%
To allow calls to existing optimizers, which may be written in different languages, we use MLton's foreign function interface, which supports cross-language calls to C++.
%
Specifically, to use an existing optimizer as an oracle, we only need to provide a C++ wrapper that takes a circuit in QASM format as input
and returns an optimized circuit as output.
%
Using this approach, we have implemented wrappers for two different optimizers: \feyntool{}~\cite{amy2019formal} and \voqc{}~\cite{hietala2021verified}.
\fi
%

% Our implementation approach is to serialize
% the input and output circuits of each oracle call in QASM format,
% and make a call to another language.
% %
% While this introduces some overhead,
% it allows us to evaluate our algorithm with different oracles.
%
% These overheads could be avoided by integrating the oracle more
% deeply with \algname{}, for example by customizing the oracle to
% directly accept \algname{}'s circuit representation or vice versa.
% %
% In the experiments we discuss these overheads when relevant.
% %
% However,
% our goal is to evaluate the algorithm and answer broader research questions.
% %
% \sr{$\uparrow$ This raises questions about how we managed this overhead. Just need to
% add a sentence explaining what we did.}
%
% Such an implementation may be desirable for the purposes of creating
% a fast local optimizer
% but is less useful for us.
% Our goal is to evaluate the algorithm
% for different oracles and answer broader research questions.
%


\subsection{Benchmarks and gate set}
% \myparagraph{Benchmarks.}
\input{benchmarks.tex}



% \subsection{Question II: Using Different Oracles}
\subsection{RQ I: Effectiveness of \algname{} and local optimality}
\label{sec:scalability}

%We validate the effectiveness of \algname{} on the Nam gate set.
%We validate the effectiveness of \algname{} on two different gate
%sets: Nam and Clifford+T.
%
%In this section, we evaluate with the Nam gate set.
%and \secref{clifft} considers the Clifford+T gate set.
%
To evaluate the effectiveness of \algname{}, we use our \algname{}
implementation with \voqc{} as the oracle on segments of size $\Omega
= 40$ and compare it to optimizers \quartz{}, \queso{}, and
\voqc{}.
%
The approach works for many different settings of $\Omega$ and we
analyze the impact of $\Omega$ in \secref{var-segment} in detail.
%
We give each optimizer a 12-hour cut-off time (excluding time for parsing and printing),
to allow completion of the experiments within a reasonable amount of time.
%
Throughout, we omit circuit-parsing time for timings of \voqc{}, whose parser
%,
% which maps input circuits into the internal representation used for optimization,
appears to scale superlinearly and can take significant time
(sometimes more than the optimization itself).
%
This approach is consistent with prior work on \voqc{}, which also excludes parse time.
%
When we use \voqc{} as an oracle of \algname{}, however,
we do include the parse time.
%
This makes the comparison somewhat unfair for \algname{}.
%

%% Note however that \algname{} only uses the \voqc{} oracle to
%% (parse and) optimize small segments of the circuit, which limits
%% the parsing overhead.
%
% Although this makes the comparison unfair against \algname{},
% if we optimized this overhead away, \algname{} would perform
% the same or better.
% This makes the comparison somewhat unfair to our \algname{},
% but nevertheless we observe good performance in our experiments.
%
% \algname{} calls \voqc{} to (parse and)
% optimize only small segments of the circuit.
%
We evaluate the running times of these optimizers
on benchmarks from the Nam gate set with sizes ranging
from thousands to hundreds of thousands of gates.

% \subsection{Question III: Performance}

% We analyze the empirical behavior of our \algname{} implementation  with two different oracles, \voqc{}, and \feyntool{}, under two different gate sets.
%
\if0
We organize the results based on the different cost function and gate set we use:
\begin{itemize}
    \item In \secref{nam}, we evaluate our \algname{} optimizer by comparing it
    to state-of-the-art optimizers \quartz{}, \queso{}, and \voqc{}. We observe that \voqc{} and \algname{}
    produce the best quality circuits and \algname{} is the fastest, producing the best quality circuits 10x faster on average.
    \item In \secref{clifft}, we evaluate our \algname{} optimizer by comparing it to the \feyntool{},
    a state-of-the-art optimizer for benchmarks in the Clifford+T gate set. We observe that \algname{} matches
    the quality of circuits produced by \feyntool{} while being 10x faster on average
    \item In \secref{converge} , we study the the convergence factor of \algname{},
    which is typically around $3$ for most of the benchmarks. We also analyze the quality impact
    of successive rounds of optimization and observe that most of the optimizations (> $99.7\%$) are actually
    found after the first round, and the subsequent rounds have small impact on circuit quality.
    \item and \secref{var-segment}, we study the impact of changing the parameter $\Omega$
    on the output quality and running time of \algname{}.
\end{itemize}
\fi


% \subsubsection{\algname{} with \voqc{} Oracle}


%
\if0
We discuss the time performance and output quality separately,
and show the results in\figref{main-time} and \figref{main-gate-count}
respectively.

These results show that our \algname{} optimizer produces
the best quality circuits and runs significantly faster than other tools,
delivering speedups ranging from $10$x to $1000$x
across circuit sizes ranging from thousands to hundreds of thousands of gates.
% \jremark{How do we make it clear that \algname{} is not expected
% to outperform \voqc{} in terms of quality? Basically we have to make
% it clear that local optimality is an undergoal, which is efficient
% to achieve and results in the same circuit.}
\fi

\input{fig/tab-main-result-time-1round}
\input{fig/tab-main-result-1round}

\myparagraph{Time Performance.}
\figref{main-time} show the time for our \algname{} implementation (with \voqc{} oracle) compared against \quartz{}, \queso{}, and \voqc{}.
%
The figure includes eight families of circuits, where
horizontal lines separate families and circuits within each family
arranged body increasing qubit and gate counts.
%
The optimizers \quartz{} and \queso{} use the maximum allotted time of 12 hours in all circuits,
because they explore a very large search space of all optimizations.
%
In a few cases, \queso{} throws an error or runs out of memory (denoted ``OOM'').
%
The \voqc{} optimizer and our \algname{} optimizer terminate much faster.
%
Specifically, \algname{} optimizes all circuits
between 0.2 seconds and 3 hours depending on the size,
and \voqc{} finishes for all but six benchmarks within 12 hours.
%
In the figure, we highlight in bold the fastest optimizer(s) for each circuit.

Comparing between \voqc{} and our \algname{}, we observe the following:
%
\begin{itemize}
    \item \textbf{Performance:} \algname{} is the fastest across the board except for \texttt{vqe}
    and except perhaps for the smallest circuits in some families.
    \item \textbf{Scalability:} the gap between \algname{} and \voqc{} increases as the circuit size increases,
    with \algname{} performing as much as 100$\times$ faster in some cases.
    \item \textbf{Overall:} \algname{} is over an order of magnitude faster than \voqc{} on average.
\end{itemize}
%
In the case of the \texttt{vqe} family, \voqc{} is consistently faster, but as we discuss next,
this comes at the cost of poorer optimization quality.
%
For the small circuits of families \texttt{hhl}, \texttt{statevec}, and \texttt{sqrt},
our optimizer is slower than \voqc{}.
%
This is due to the overheads that our implementation incurs for
(1) splitting and joining circuits,
%
(2) serialization/deserialization of input/output circuits for each oracle call, and
%
(3) various system-level calls needed to support calls to an external oracle.
%
For example,
for the $7$-qubit \texttt{hhl} benchmark and the $42$-qubit \texttt{sqrt} benchmark, we have measured that at least 30\% of the running
time is spent parsing and serializing/deserializing circuits.
\if0
For example,
in the $7$-qubit \texttt{hhl} benchmark which takes $0.9$ seconds to run,
we measured that  over $0.3$ seconds are spent just on system calls.
%
Similarly, for the $42$-qubit ``sqroot'' which takes $81.4$ seconds, over
 $25$ seconds are spent on system calls and deserializaiton/serialization operations.
%
As circuit sizes increase, these overheads, which are constant, diminish.

\fi

\if0
For example,
in the ``shor'' family of circuits,
our optimizer takes around $5$ seconds for the smallest case with $7543$ gates,
around $38$ seconds for $30268$ gates ($12$ qubits),
and $189$ seconds for the $14-$qubit case which has around $51000$ gates.
%
The corresponding times for \voqc{} range from $8.7$ seconds to $3638$ seconds
and are $1.6$x to $190$x slower than our \algname{} optimizer.
%
For the $16-$qubit case, our \algname{} finishes in $943$ seconds,
while \voqc{} does not finish within twelve hours.
%
In the ``bwt'' family,
our \algname{} optimizes the $17$-qubit case in $1196$ seconds
and \voqc{} takes $8303$ seconds on this benchmark ($\approx$ 7x improvement);
for the $21-$qubit our \algname{} takes $2280$ seconds
and is an order of magnitude faster than \voqc{},
which takes $23236$ seconds.
%
For the larger instances in ``bwt'',
our \algname{} finishes in 5698 (1.5 hours) and 11842 seconds ($\approx$ 3 hours) respectively
and neither of \quartz{}, \queso{}, or \voqc{} terminate in $12$ hours.
\fi



\if0

For the majority of benchmarks, our \algname{} optimizer is faster.
%
We observe a pattern for the speedup of our \algname{} optimizer relative to \voqc{}.
%
For almost all families of circuits,
the speedup increases significantly with circuit size (see column speedup in \figref{main-time}).
%
For instance, in the \texttt{grover} family,
increasing the circuit size increases our speedup from $1.35$x to $17.93$x.
%
In the \texttt{boolsat} family,
our speedup increases from $1.14$x on the smallest case
to $10.2$x on the largest case.
%
This trend is consistent across almost all families of benchmarks
and shows that our optimizer handles large circuits in a scalable fashion.
%

The key reason for the scalability of our \algname{} optimizer
is that it focuses on finding local optimizations on the circuit.
%
It does not "chase" global optimizations which are more complex
and require a significant amount of time.
%
This raises the question: although \algname{} finds local optimizations
in an efficient and scalable fashion, does it lose anything in terms
of quality by only considering local optimizations
and not operating on the entire circuit simultaneously?
%
We show that \textbf{our speedups do not come at any cost
to circuit quality} and in fact,
\algname{} produces better quality circuits in some cases.
%
This is due to the fact \algname{} guarantees local optimality when it terminates.
\fi

% These results indicate an asymptotic difference in
% running times between \algname{} and \voqc{}.
% %
% Specifically, when we consider the relative speedup of our \algname{}
% optimizer within any given family of circuits,
% we observe that the speedup increases significantly with circuit size.
% %
% For instance, in the ``grover'' family,
% our speedup increased from $40.6\%$ to $1697.4\%$ with increasing circuit size
% (\figref{main-time}).
% %


% Our \algname{} optimizer
% uses the same optimization techniques as \voqc{}---\algname{}
% uses \voqc{} as an oracle optimizer---but we schedule
% these optimizations in a way that scales more efficiently.
% %
% Specifically, \algname{} considers the circuit in segments of size $\Omega = 120$
% and strategically schedules their optimization until it achieves local optimality.
% %
% This segment-based approach benefits from \voqc{}'s excellent performance on
% relatively small circuits, making the optimization of any given segment fast.
% %
% In contrast,
% when \voqc{} is directly used as a standalone optimizer on entire circuits,
% it struggles with scalability due to the complexity of optimizing
% the entire circuit at once.


% Note that our algorithm uses \voqc{} as a subroutine to optimize segments
% of size $\Omega$ and benefits from its excellent performance on small circuits.
% %
% When \voqc{}
% it shows relatively poor scalability.
%

\myparagraph{Optimization quality.}
Our experiments so far show that our \algname{} performs well but it
does not give evidence of optimization quality.
%
% This raises the question: although \algname{} finds local optimizations
% in an efficient and scalable fashion, does it lose anything in terms
% of quality by only considering local optimizations
% and not operating on the entire circuit simultaneously?
%
%% TODO: the quality improvemenst are not significant
%% so, don't mention
%and in fact, \algname{} produces better quality circuits in some cases.
%
%This is due to the fact \algname{} guarantees local optimality when it terminates.
%
\figref{main-gate-count} shows
the output quality (measured by gate count)
of all optimizers for eight families of circuits.
%
% Each family is separated by horizontal lines,
% with circuits arranged by increasing qubit and gate counts.
% %
The figure shows the original gate count and the percent reduction
in gate count achieved by tools \quartz{}, \queso{}, \voqc{}, and \algname{}.
%
The best optimizers are highlighted in bold.
%
These results show that \algname{} always matches the best optimizer
within $0.1\%$ or outperforms it.
%
On average, \algname{} reduces the gate count by $49.7\%$, improving by
$1\%$ over the second best.
%
We note all optimizers except for our \algname{}, are unable to finish
some large circuits within the allotted 12-hour time limit or yield
very small (less than 1\%) improvement.
%
We present a more detailed discussion of these experiments below.


The results show that \algname{} and \voqc{} produce overall
better circuits than \quartz{} and \queso{}.
%
For the \texttt{hhl} family, both \algname{} and \voqc{} achieve
reductions of around $56\%$, while \quartz{} and \queso{} are around
$26\%$ for $7$ and $9$ qubits, and less than $1\%$ for $11$ qubits.
%
In the \texttt{statevec} family,
\algname{} and \voqc{} consistently reduce the gate count by $78\%$.
%
However, for the 8-qubit case, \voqc{} does not finish within our timeout
of 12 hours so we write ``N.A.''.
%
\queso{} also finds comparable reductions for the 5-qubit benchmark.

% Internally,
% our \algname{} uses \voqc{} as a subroutine to optimize
% small segments of the circuit, rather than optimizing
% the entire circuit at once.
% %
% Specifically, \algname{} considers the circuit in segments
% of size $\Omega = 40$ and applies \voqc{} to them.
% %
% In contrast,
% when used as a standalone optimizer,
% \voqc{} processes the entire circuit and could theoretically find more optimizations
% by considering all possible gates simultaneously.
% %
% However,
% our experiments show that \algname{}'s segment-based approach
% achieves the same quality.
% %
% This suggests that local optimality,
% as achieved by our optimizer,
% is a good goal for circuit optimization,
% because it does not miss any optimizations in practice.
% %
% As we saw in \figref{main-time},
% the approach is significantly faster because it scales better.
% %

For almost all families, we observe that the output quality of
\algname{} matches that of \voqc{} within $0.1\%$ or improves it,
sometimes significantly.
%
%Our \algname{} uses \voqc{} as the oracle on segments of length $\Omega = 40$
%and produces almost locally optimal circuits
%(upto the convergence ratio $\epsilon$, see \secref{impl}).
%
%
Specifically, for the \texttt{vqe} family, \algname{} optimizes better
than \voqc{}.
%
For example, on the 24-qubit \texttt{vqe} circuit, \algname{} improves
the gate count by $60.6\%$, and \voqc{} improves the gate count by
$54.9\%$.
%
Indeed, we observed that running \voqc{} twice by running it again on
its own output circuit bridges this gap.
%
%On average, \algname{} reduces the gate count by $49.7\%$ versus
%$48.1\%$ for \voqc{}.




%% \myparagraph{Summary.}
%% \figref{main-time} and \figref{main-gate-count}
%% show that
%% our \algname{} optimizer can be significantly faster, especially for larger circuits, because it scales better, and does so without sacrificing optimization quality.
%% %
%% The experiment thus shows that the local optimality approach can work well, especially for larger circuits.

\if0
is over an order of magnitude faster on average
and
produces circuits that match the best quality.}
%
These results demonstrate that
our \algname{} optimizes
circuits in an efficient and scalable fashion
and that local optimality is an effective
quality criterion.
\fi



\subsection{RQ II: Is empirical performance consistent with the asymptotic bound?}
\label{sec:eval-calls}
\input{fig/fig_oracle_call_vs_input_size_half}

In \secref{algorithm}, we established bounds on the number of oracle
calls performed by our \algname{} algorithm.
%
In this section, we check that our implementation is consistent with
these bounds by analyzing the number of oracle calls with respect to
the circuit size.
%
%We focus on optimizing for gate count, using \voqc{} as the oracle.
%
\figref{plot-oracle-calls} plots the number of oracle calls made by
our \algname{} optimizer for a subset of circuit families (the other
circuit families behave similarly; see
\iffull
\figref{plot-oracle-calls-all} included in the Appendix).
\else
Appendix).
\fi
%
The Y-axis represents the number of oracle calls
and the X-axis represents the input circuit size.
%
The plot shows that the number of oracle calls
increases linearly with circuit size, for all circuit families.

%% This observation is consistent with our asymptotic analysis.
%% %
%% In \corref{linear-calls},
%% we proved that for gate count optimization,
%% each round of our \algname{} performs a linear number of calls to the oracle.
%% %
%% Specifically, we bounded the number of oracle calls by $O(\mathsf{length}(C) + \sizeof{C})$.
%% %
%% Because our optimizer only takes a constant number of rounds to converge,
%% the bounds suggest that the number of oracle calls should be linear
%% in circuit size and depth,
%% which is consistent with the plots in \figref{plot-oracle-calls}.

We note that it would be more desirable to establish that the total
run-time, rather than the number of oracle calls, is linear, but this
is not the case because the oracle optimizers can take asymptotically non-linear time.
%
For example, the oracle \voqc{} can require at
least quadratic time in the number of gates in the circuit being
optimized, which varies as we increase the qubit
counts.

%% %
%% In these experiments, the oracle that we have used, \voqc{}, is an
%% implementation that primarily aim at verification, rather than
%% efficiency, making empirical analysis of runtime
%% challenging~\cite{hietala-personal-2024}.
%% %
%% We have nevertheless observed that the runtime of the oracle grows
%% roughly quadratically in the number of gates, which is constant for
%% all circuits of a given number of qubits and fixed $\Omega$.

\subsection{RQ III: Ablation Study of Meld}
\input{fig/tab-main-ablation-2col}

Our algorithm for local optimality optimizes a circuit by cutting it
into smaller subcircuits, optimizing the subcircuits, and melding the
optimized subcircuits into a locally optimal circuit.
%
If the algorithm joined the circuits together instead of melding them,
then the resulting circuits would not be locally optimal, because the
segments overlapping the circuit cuts may not be optimal.
%
To understand the impact of the \lstinline{meld} operation, we perform
an ablation experiment.
%
Specifically, we implement an ablating version of our \algname{},
called \algnameminus{}, that simply concatenates the optimized
subcircuits instead of the \lstinline{meld} operation.

\figref{main-ablation} shows the results of this ablation study.
%
%In this figure, \algnameminus{} splits the circuit into segments, use
%\voqc{} to optimize each segment, and then concatenate the results
%together.
%
%using the same $\Omega=40$ as \algname{}.
%
\algname{} consistently performs better than the ablating version
\algnameminus{}, with over 2\% improvement on the average total gate
count.
%
Even though the percentage degradation due to ablation may seem modest,
it is significant, because each and every gate has a significant
runtime and fidelity cost on modern and near-term quantum computers.
%
This ablation study shows the importance of the \lstinline{meld}
algorithm and that of local optimality, which does not hold without
the \lstinline{meld}.
%
Notably, the quality of the circuits produced by the ablating version
are significantly worse than those produced by the baseline \voqc{}.


\subsection{RQ IV: Impact of compaction and $\Omega$ on the effectiveness of \algname{}}
\label{sec:converge}
\input{fig/fig-compression-factor}

\subsubsection{Impact of compaction}
\label{sec:compaction}
\input{fig/tab-omega}% TODO: typeset at a better location
%For all benchmark circuits in \figref{main-gate-count},
%using the convergence ratio $\epsilon = 0.01$,
%\algname{} converges very quickly, always
%terminating after $2$ rounds of optimization.
%Furthermore, it consistently finds over 99\% of the optimizations in the first round.
\figref{num-rounds} shows the number of rounds and percentage
optimizations for each round of our \algname{} algorithm, using the
convergence ratio $\epsilon = 0.01$.
%
%% Similar to \figref{main-gate-count},
%% we use our \algname{} optimizer, with \voqc{} as the oracle
%% and convergence ratio $\epsilon = 0.01$,
%% to optimize the benchmarks in the Nam gate set.
%% %
The results show that \algname{} converges very quickly, always
terminating after $2$ rounds of optimization, and that it
consistently finds over 99\% of the optimizations in the first round.
%
This is because our \algname{} ensures the slightly weaker segment
optimality after the first round of optimization (see
\secref{algorithm}), which ensures that all segments are optimal,
though there may be gaps.
%We present the detailed result in the Appendix.
%
The experiment shows that although compaction can enable some
optimizations by removing the gaps, its impact on these benchmarks is
minimal.
%
We separately ran the same experiments with $\epsilon = 0$, which
forces the algorithm to run up to perfect convergence, and observed
that \algname{} requires $4$ rounds of optimization on average over
all circuits.
%
These results show that in practice a small number of compaction
rounds suffice to obtain results that are within a very small fraction
of the local optimal.

\subsubsection{Impact of varying segment size $\Omega$}
\label{sec:var-segment}

\figref{omega} shows the running time and the gate count reduction of \algname{} with different
values of $\Omega$
on the \texttt{hhl} circuit with 9 qubits, which initially contains 63392 gates.
The results show that for a wide range of $\Omega$ values,
our optimizer produces a circuit of similar quality to the baseline \voqc{}, and typically does so in significantly less time.
When $\Omega$ is large, \algname{}'s running time scales linearly with $\Omega$, and the output gate count reduces marginally when $\Omega$ increases.
We choose $\Omega=40$ in our evaluation to achieve a balance between running time and output quality but note that many different values work similarly well.

