
In this section,
we evaluate the \coam{} algorithm by instantiating it with three oracle
optimizers (\feyntool{}, \quartz{}, and \queso{}), as outlined in \secref{impl}.
%
We denote the resulting optimizers as
\coamwith{\feyntool}, \coamwith{\quartz}, and \coamwith{\queso} respectively,
and describe how these are configured in \secref{methodology}.
%
Our evaluation covers 21 quantum circuits from seven quantum algorithms.
%
We organize the results into the following parts:
%
\begin{itemize}
  \item In \secref{comp-feyn}, we evaluate our \coamwith{\feyntool} optimizer
   on T count reduction.
  %
  We observe that the $\Omega-$optimal circuits produced by our optimizer
  match the output quality of \feyntool{},
  suggesting that $\Omega-$optimality is good optimization criterion for T count optimization.
  %
  Our optimizer runs faster than \feyntool{} in almost all cases
  and we observe that the speedup increases with circuit size.
  %

  \item In \secref{comp-quartz} and \secref{comp-queso},
  we evaluate our optimizers \coamwith{\quartz} and \coamwith{\queso{}}
  for optimizing gate count.
  %
  We observe that the \coam{} algorithm effectively utilizes the base optimizers,
  delivering significant size reduction across a range of quantum circuits.

  \item In \secref{var-segment}, we study the impact of $\Omega$ on the output quality and running time of \coam{}.
\end{itemize}


% the integration of the implementation with \quartz{}, an off-the-shelf optimizer,
% and present an evaluation.
% %
% For the evaluation, we consider the time performance and scalability
% as well as the circuit quality on a range of quantum circuits.
% %
% As our baseline, we consider the \quartz{}~\cite{quartz-2022}
% optimizer, a super optimizer for quantum circuits that uses rule-based
% substitutions to optimize circuits.








%
% We also demonstrate the applicability of our implementation to the
% QUESO optimizer~\cite{queso-2023}, which also uses rule-based optimizations
% with different algorithms and heuristics.
%

%
% Because of the exponential time complexity, both approaches
% deliver poor time scalability, and in practice, provide no quality guarantee.
%
% With the \coam{} algorithm,
% our goal is to deliver a quality guarantee in reasonable running times
% that scale linearly with the size of circuits.
%


\subsection{Methodology}
\input{methodology.tex}

\subsection{Benchmarks}
% \myparagraph{Benchmarks.}
\input{benchmarks.tex}

\subsection{\coam{} with the \feyntool{} optimizer}
\label{sec:comp-feyn}
In this section,
we study the performance of our \coamwith{\feyntool} optimizer,
which runs the \coam{} algorithm with \feyntool{} as the oracle optimizer.
%
We evaluate the running time and output quality of our optimizer
by running the baseline \feyntool{}.
%
For all our benchmarks,
we set the segment depth $\Omega$ to be $120$.
%
The output of our \coamwith{\feyntool{}} is $\Omega-$optimal with $\Omega = 120$
and the cost function is the T count of the circuit.
%

\begin{figure}
  \centering\small
  \input{fig/prelim.feyn.120.tex}
  \caption{
  The figure shows the optimization results of our $\coamwith{\feyntool{}}$ tool and \feyntool{},
  using T count as the cost metric.
  %
  The labels ``S'' and ``F'' represent $\coam{}$ and \feyntool{} respectively.
%
  The figure presents T counts (lower is better) and
  running time (lower is better) for both optimizers.
%
The results demonstrate that optimizer $\coamwith{\feyntool{}}$,
which guarantees $\Omega-$optimality delivers a similar quality of circuits as \feyntool{}.
%
The figure also calculates the speedup of the \coam{} approach using the ``T(F)/T(S)'' ratio.
%
On average, the$\coamwith{\feyntool{}}$ delivers excellent time performance
and runs in $6.9$x less time, compared to \feyntool{}.
%
We impose an end-to-end timeout of 10 hours (36000 seconds).
%
}
  \label{fig:feynopt}
  % \setlength{\belowcaptionskip}{-20pt}
\end{figure}



\figref{feynopt} shows the results of this experiment.
%
The figure separates circuit families with horizontal lines
and sorts circuits within families by their size/number of qubits.
%
The figure calculates the metric T count for the input circuit and for
the circuits returned by \feyntool{} and \coamwith{\feyntool{}},
or \coam{} for short, labelled by ``F'' and ``S'' respectively.
%
The ``F/S'' represents the quality ratio of the two approaches.
%
The figure also shows the running times of both approaches and computes
the ratio ``F/S'', measuring the relative speedup from the \coam{} algorithm.
%
The results shows our \coam{} algorithm generates reliable quality circuits
in short running times.

\myparagraph{Optimization  Quality.}
The results show that our optimizer \coam{} matches the output quality of \feyntool{}.
%
There are a few cases where there is a difference of less than $1\%$,
such as the ``hhl'' circuit with $7$ qubits.
%
But overall, there is no noticeable difference and
the quality ratio of the outputs is $1$.
%
%
This experiment shows that $\Omega-$optimality, as guaranteed by
our \coam{} algorithm is a reliable quality criterion for T count optimization.
%for the \feyntool{} optimizer.
% This consistent output quality demonstrates
% that $\Omega-$optimality is a reliable quality guarantee for the optimizer \feyntool{}.
%
Note that the baseline \feyntool{} can, in principle, discover more optimizations
because it operates on the full circuit.
%
But in practice, we observe that optimizing the circuit in piecewise
fashion,
on circuit segments of size $\Omega$ and guaranteeing $\Omega-$optimality
finds similar optimizations.
%
In \secref{var-segment}, we confirm this for a range of $\Omega$ values.
%

\myparagraph{Run time.}
The figure also shows the running time of both approaches,
and calculates the speedup of the \coam{} approach using the ``T(F)/T(S)'' ratio.
%
Our \coam{} algorithm is slower by about factor two in one benchmark,
``grover'', but in all other benchmarks it performs better than \feyntool{},
running $6.9$x faster on average,
%
with no noticeable impact on the optimization quality (``F/S'' column).
%
For any given family, our \coam{} algorithm's speedup increases
consistently with the circuit sizes.
%
For example,
in the ``hwb'' family,
our \coam{} algorithm is $1.2$x faster for the smallest instance (with 8 qubits)
and runs $83$x faster for the largest instance (12 qubits)
%
;
%
For the ``hhl'' family,
our \coam{} algorithm is $23$x faster for the smallest instance (7 qubits)
and runs at least $94$x faster for the largest instance (9 qubits)
(on 9 qubits \feyntool{} does not terminate within our timeout of ten hours).
%
%

\myparagraph{Summary.}
The experiments suggest that local optimality is an effective
optimization criteria for T-count optimization. By focusing on local
optimizations, our \coam{} algorithm (with \feyntool{} as an oracle)
can optimize for T-count effectively and efficiently.
%

%% \todo{We observe...
%% %
%% Our theoretical results suggest that this gap could be understood as an
%% asymptotic gap,
%% %
%% for the following reasons....}

\if0
%%% THIS IS HARD TO READ FOR ME (UMUT)
Given that the speedup consistently increases with the circuit size,
the performance results indicate an asymptotic difference in running time of both
approaches.
%
We can confirm this difference using the theory results in \secref{algorithm}.
%
Specifically,
the \feyntool{} optimizer takes polynomial (at least quadratic) time
both in the number of qubits and the depth of the circuit.~\cite{amy2019formal}.
%
The optimizer \coamwith{\feyntool} is also polynomial in the number of qubits,
but scales linearly in the depth/size of the circuit.
%
From \corref{linear-calls},
using the fact that the cost function is T count,
we get that \coamwith{\feyntool} makes $O(\sizeof{C})$ calls to \feyntool{},
where $\sizeof{C}$ is the size of circuit $C$;
each call runs on small circuits of depth at most $2\Omega$ (\thmref{cost})
and therefore, each call to \feyntool{}
takes polynomial time in the number of qubits (the depth is constant).
%
Because the number of oracle calls is linear,
the total runtime of \coamwith{\feyntool} is linear in the size and polynomial in the number of qubits,
which is asymptotically different from \feyntool{}, which takes polynomial in both.
%
\fi

% %
% Because each such call only runs the optimizer on ``small circuits'' of depth at most $2\Omega$,
% the cost of each \feyntool{} call only depends on the number of qubits, which are roughly constant
% for most qubits in the figure.
% %
% Thus, the \coamwith{\feyntool} optimizer practically shows linear scalability.


% Thus, roughly speaking, the optimizer \coamwith{\feyntool} decomposes the complexity
% of optimization using \feyntool{} and makes it scale linearly (instead of quadratically)
% in the size of the circuit.
% %
% In summary,
% the optimizer \coamwith{\feyntool} consistently
% delivers reliable quality circuits with excellent scalability.
% %
% %
% The results demonstrate that $\Omega-$optimality is a practical and reliable
% quality criterion in circuit optimization with \feyntool{} optimizer.
% asymptotically improves the running time of optimization using \feyntool{}.
% \coamwith{\feyntool} delivers linear running time
% without compromising circuit quality.
%
% \secref{linear} discusses the linear running time of \coamwith{\feyntool} in more detail.


% % IT IS WELL KNOWN That xxx. IN principle, we could have an optimizer. We therefore to evaluate.
% We have evaluated benchmarks with gate count
% as the quality metric
% because our oracle, \quartz{}, directly supports it.
% %
% However, it is well known that depending on the gate set,
% other metrics become more important.
% %
% For example, in the \clifft{} gate set,
% T count is an important metric of circuit quality
% because T gates they are not as computationally efficient
% compared as the Clifford gates (T gates roughly cost 50x other gates in practice \cite{Nam_2018}).
% %
% Similarly, CNOT count is another important metric because CNOT
% gates operate on two qubits and are expensive to implement.
% %


% In this section,
% we evaluate the benefit of our configuration $\coamwith{\quartzt{6}}$,
% for metrics ``T count'' and ``CNOT count''.
% %
% Note that, in principle,
% we could plug in an optimizer which is designed for these metrics,
% but here we evaluate the benefit with \quartz{} that is designed with circuit size
% as the metric.
% %
% To do so, we translate our benchmark suite, expressed in the Nam gate set,
% to the \clifft{} gate set.
% %
% We then translate the optimized version of our benchmarks
% and compare the unoptimized and optimized translation.
% %
% %

% To translate a benchmark from the Nam gate set to the \clifft{} gate set,
% we use gridsynth,
% a tool that translates parameterized $\mathsf{R_Z}$ gates
% to the \clifft{} gate set in provably optimal fashion~\cite{gridsynth}.
% %
% We also decompose the $\mathsf{X}$ gate to \clifft{} circuits
% using the Qiskit compiler.
% %
% We run Qiskit  in the mode where it does not perform any optimizations.
% %
% Note that this translation does not change the CNOT count because
% it only replces single qubit nam gates with single qubit \clifft{} gates.
% %
% Thus, a CNOT count comparison applies to both the Nam and the \clifft{} gate sets.

% \figref{comp-cliff} compares
% the circuit size, the T count, and CNOT count,
% of the unoptimized translation and the optimized translation
% with columns labelled ``Input'' and ``Output'' respectively.
% %
% Across the board,
% we observe that the implementation finds reductions in size and
% they correlate with reductions in T count and CNOT count.
% %
% In case of the ham15-med circuit,
% the implementation reduces the T count by $7\%$
% and the CNOT count by $6\%$;
% the larger variant, circuit ham15-high,  also shows similar numbers.
% %
% For qft circuits,
% we observe that gate count reduction and T count reduction
% is perfectly correlated,
% as both are reduced by the same percentage on all the qft instances.
% %
% On average,
% the implementation reduces the circuit size by around $11.8\%$,
% the T count by $4\%$, and the CNOT count by $6.2\%$.


% \cleardoublepage
% \cleardoublepage

\subsection{\coam{} with the \quartz{} optimizer}
\label{sec:comp-quartz}

% In this subsection,
% we establish that ensuring $\Omega$-optimality leads to good circuit quality.
%
% Additionally, we study the benefits of our \coam{} algorithm when used with
% \quartz{}.

% One of the key benefits of our algorithm
% is that runs in a predictable amount of time, and (within that time)
% guarantees $\Omega$-optimality.
%
% In this section, we show how the \coam{} algorithm
% improves the \quartz{} optimizer.
% %
% We optimize circuits using the optimizer  $\coamwith{\quartzt{t}}$
% with segment depth $\Omega$ equal to $6$
% and
% The optimizer $\coamwith{\quartzt{t}}$ runs the \coam{} algorithm
% using \quartz{} as the oracle,
% where each call to \quartz{} is roughly allocated $t$ amount of time per gate,
% i.e., if the \coam{} algorithm calls \quartz{} for a circuit of size $k$,
% the timeout we give to \quartz{} is $k*t$.
% %
% We use the timeout functionality in \quartz{} to implement this.
% %
% We present results with the per-gate timeout $t = 0.01s$,
% but we also provide results of timeouts $t = 0.1s$ and $t = 1s$ in the Appendix.
% %
% % We chose the segment depth as $6$ because the default \quartz{} optimizer uses
% equivalence rules for circuits upto size $6$.
% %
% With segment depth as $6$,
% the algorithm feeds all segments of size $6$ to \quartz{}
% giving it enough scope to apply its optimizations.
%


% \begin{figure}
%   \centering
%   \small
%   \input{fig/prelim.0.01}
%   \caption{
%   The figure displays the number optimizations and running time of our optimizer $\coamt{\quartzt{0.01}}$
%   and also shows the optimizations by baseline \quartz{} in the same end-to-end time.
%   %
%   The label ``S'' represents the $\coam{}$ approach and the label ``Q'' represents \quartz{}.
%   %
%   The $S/Q$ column shows how many more optimizations \coam{} finds w.r.t \quartz{} for the same running time.
%   %
%   The figure shows that our \coam{} algorithm finds significant reductions ranging
%   from $20\% - 60\%$ in short runtimes.
%   %
%   Time column shows the runtime in seconds.
%   }
%   \label{fig:comp-quartz}
%   % \setlength{\belowcaptionskip}{-20pt}
% \end{figure}



\begin{figure}
  \centering
  \small
  \input{fig/prelim.compress}
  \caption{
  The figure displays the number optimizations and running time of our optimizer $\coamt{\quartzt{0.01}}$
  and also shows the optimizations by baseline \quartz{} in the same end-to-end time.
  %
  The label ``S'' represents the $\coam{}$ approach and the label ``Q'' represents \quartz{}.
  %
  The $S/Q$ column shows how many more optimizations \coam{} finds w.r.t \quartz{} for the same running time.
  %
  The figure shows that our \coam{} algorithm finds significant reductions ranging
  from $20\% - 60\%$ in short runtimes.
  %
  Time column shows the runtime in seconds.
  }
  \label{fig:comp-quartz}
  % \setlength{\belowcaptionskip}{-20pt}
\end{figure}

In this section, we evaluate our $\coamwith{\quartzt{0.01}}$ optimizer,
which runs the \coam{} algorithm using \quartz{} as the oracle.
%
To evaluate its optimizations,
we run our optimizer on all the circuits and record its output and the running time.
%
Then,
we run default \quartz{} on the each input circuit for the same end-to-end time,
%
and analyze the number of optimizations discovered.

\figref{comp-quartz} shows the results for circuits taken from six families of quantum algorithms.
%
In the figure,
the label ``S'' denotes the number of optimizations discovered by our \coam{} algorithm
and label ``Q'' denotes the same with baseline \quartz{} (higher is better).
%
In cases where one approach finds more optimizations,
the figure uses bold numbers.
%
The label ``S/Q'' computes the \defn{optimization ratio} which is
the ratio of number of optimizations.
%
A higher ratio represents that our algorithm finds more optimizations.
%
The results show that the \coam{} approach produces
well optimized circuits in short running times.


\myparagraph{Quality.}
We observe that in all but two cases (ham15 with 17 qubits and gf with 48 qubits),
using our \coam{} approach
discovers more optimizations than baseline \quartz{}.
%
For the hhl circuits,
the \coam{} algorithm reduces gate count by $23\%$ to $27\%$,
which is excellent considering that \quartz{} reduces the size by less than $5\%$
within the same time.
%
For the vqe family,
our \coam{} algorithm reduces the gate count by around $60\%$ and
the optimizations by \quartz{} are less than $10\%$.
%
Overall, we observe that by using \coam{} algorithm with \quartz{} as an oracle,
we can effectively reduce gate count for circuits with thousands of gates
within seconds and optimize circuits with hundreds of thousands of gates within minutes
(the Time column displays the running time).
%
In the Appendix,
we verify that our optimizer \coamwith{\quartz{}} does not generate a worse quality circuit
even when the running time for both algorithms is scaled
by $100$x (by increasing the per call timeout 100x; see \secref{methodology} for more details on running time).

\myparagraph{Scalability.}
Note that our \coam{} optimizer
excels at finding optimizations for large circuits.
%
The figure illustrates this using the ``S/Q'' column,
which computes the optimization ratio of both approaches.
%
For all families, the optimization ratio increases with increasing circuit size.
%
In the case of hhl circuits, for example,
the ratio rises from around $5$x to $1000$x with increasing circuit size;
%
In the case of grover circuits,
the optimization ratio steadily increases from $1.12$x on the smallest instance (7 qubits)
to $54.29$x on the largest instance (15 qubits).
%
Similarly, for vqe, the ratio increases from $6.5$x to $44.34$x with increasing circuit size
and for qft, it increases from $1.78$x to $5.19$x.
%
We identify three key reasons for this scalability.
%
First, because baseline \quartz{} searches for optimizations on the whole circuit,
it struggles to find optimizations,
because the search space is exponential.
%
Second, our optimizer \coam{} algorithm
utilizes \quartz{} by focusing it on small segments ($\Omega = 6$),
where it delivers excellent results.
%
Third,
the \coam{} algorithm ensures that it applies \quartz{} to all
$\Omega-$segments and misses no local optimizations.

\myparagraph{Summary.}
The experiments demonstrate that our \coam{} algorithm scales with circuit sizes
when using \quartz{} as the oracle.
%
The results suggest that our algorithm uses \quartz{} effectively,
finding significant reductions in circuit size and producing good quality circuits.
%

%

% For example,
% across different sizes of grover circuits,
% the \coam{} algorithm reduces gate count consistently by $10\%$;
% in contrast the gate count reduction by \quartz{} drops from $9\%$ to $0\%$.
%

%
% The 'S/Q' column shows the improvement
% in optimization rates due to \coam{}, i.e.,
% it shows how many more optimizations (per second)
% the \coam{} algorithm identifies compared to \quartz{}.
% %
% %
% Compared to \quartz{},
% the \coam{} algorithm yields $1.78$x and $5.19$x more optimizations per second
% for the smallest and largest qft instances
% respectively (see the ratio column in \figref{comp-quartz}).
% %
% Similarly,
% in the case of vqe,
% the gap in their optimization rates
% rises from around $2$x on the smallest instance to $42$x
% on the largest instance.

% %
% This is because the efficiency of \quartz{},
% quantified by optimization rates,
% reduces with increasing circuit sizes,
% whereas the \coam{} algorithm scales to larger sizes.

% Across the board,
% we observe that the optimization ratio is never less than one,
% establishing that the \coam{} approach never generates a worse quality circuit
% in the same running time.
% %
% For instance,



% we first optimize all circuits with $\coamwith{\quartzt{t}}$, where each oracle call is capped by a
% fixed amount of time $t$, and record how long the entire algorithm takes to
% complete.
% %
% Then,
% we run the default \quartz{} on the same input circuit for the same end-to-end
% time,
% %
% and compare the resulting circuit quality and optimization rate.


% number of gates optimized per second by
% \coam{} using \quartz{} as an oracle is higher than just running \quartz{}
% alone.

% % when using \quartz{} as an oracle,
% % \coam{} is able to accelerate the \defn{optimization rate} of \quartz{}.
% %

% %
% As a result, \coam{} is able to deliver better quality circuits within
% a given time limit.

% , due to its combination of linear time complexity and
% $\Omega$-optimality guarantee.
%


% \figref{comp-quartz} shows the result of this comparison
% using the configuration $\coamwith{\quartzt{0.06}}$, i.e., where
% each oracle call is limited to $0.06$ seconds.
% %
% The figure shows the input circuit sizes
% and displays the circuit sizes after optimization.
% %
% The figure labels the results of the \coam{} configuration as ``S'' and
% the standard \quartz{} approach as ``Q''.
% %
% In the cases where one approach performs better,
% the figure uses bold numbers, with lower numbers indicating better circuit quality.
% %
% The `Q/S' ratio column quantifies the improvement in circuit quality
% using the \coam{} algorithm w.r.t. standard \quartz{} (higher is better).
% %
% The figure also provides and compares the \emph{optimization rate} of both
% approaches, where the optimization rate is the number of gates optimized per
% second of execution.
% %
% A higher rate indicates faster optimizations.
% %
% The time column shows the execution time for both cases.



% \myparagraph{Quality.}
% We observe that in seventeen cases,
% using the \coam{} algorithm improves the quality of circuits w.r.t. standard \quartz{}
% and sometimes does so by a wide margin.
% %
% In the other seven cases,
% both approaches output the same quality of circuits.
% %
% For the hhl circuits,
% the \coam{} algorithm finds reductions ranging from $23\%$ to $27\%$,
% where \quartz{} does not find many optimizations
% within this time (less than $5\%$).
% %
% In the case of grover circuits,
% the \coam{} algorithm optimizes gate count by $10\%$ across the various sizes.
% %
% However, the efficacy of \quartz{} reduces from $9\%$ to $0\%$ with increasing sizes.
% %
% In the qpe circuits,
% neither approach finds any optimizations.
% %
% %
% For the vqe family,
% the \coam{} algorithm reduces the gate count by around $60\%$ and
% the optimizations by \quartz{} are less than $10\%$.
% %
% On average,
% the outputs of the \coam{} configuration are smaller by $1.37$x,
% when compared to the outputs of standard \quartz{}.

% \myparagraph{Scalability.}
% Across the board,
% we observe that the gap between the two approaches widens with increasing circuit sizes.
% %
% This is because the efficiency of \quartz{},
% quantified by optimization rates,
% reduces with increasing circuit sizes,
% whereas the \coam{} algorithm scales to larger sizes.

% For example,
% across different sizes of qft,
% the \coam{} algorithm achieves optimization rates
% ranging from $50$ to $85$ and the rates in fact increase as the circuit size grows.
% %
% In contrast,
% the optimization rate for \quartz{} reduces from around $28$ to $16$.
% %
% The 'S/Q' column shows the improvement
% in optimization rates due to \coam{}, i.e.,
% it shows how many more optimizations (per second)
% the \coam{} algorithm identifies compared to \quartz{}.
% %
% %
% Compared to \quartz{},
% the \coam{} algorithm yields $1.78$x and $5.19$x more optimizations per second
% for the smallest and largest qft instances
% respectively (see the ratio column in \figref{comp-quartz}).
% %
% Similarly,
% in the case of vqe,
% the gap in their optimization rates
% rises from around $2$x on the smallest instance to $42$x
% on the largest instance.
% %
% On average,
% we observe that the \coam{} algorithm finds $7.35$x many more optimizations
% than \quartz{} per second.


% All families of circuits follow a similar trend:
% the optimization rate ratio between the \coam{} approach and the \quartz{} optimizer
% increases with the circuit size,
% demonstrating the scalability advantages of the \coam{} algorithm.
% %
% This scalability advantage of the \coam{} approach is built into the algorithm
% because it calls \quartz{} only on small circuits,
% where \quartz{} delivers excellent results.
% %
% The algorithm never sends large circuits to \quartz{},
% where \quartz{} struggles
% because it chases potential optimizations in large spaces.
% %
% Because the \coam{} algorithm runs in linear time,
% it delivers good scalability as circuit sizes increase.
% %
% %
% %
% Because the execution time is equal for both approaches,
% the ratio column additionally represents the ratio of total optimizations.
%
% %
% For example,
% consider the ratio column of \figref{comp-quartz} which compares the optimization rates
% of the \coam{} algorithm with \quartz{}.
%

% First, because they can take a very long time,
% existing super op- timizers such as Quartz are used with a hard deadline (e.g., several hours)
% by which they have to be terminated. When not run to completion,
% they are unable to offer any quality guarantees whatsover, because they can get “lost” chasing potential optimizations
% in exponentially large search spaces.


% Second, most circuit optimizations naturally involve a small number of contiguous gates.
% Our algorithm (provably) does not miss such optimizations, but other optimizers could.
% \myparagraph{Consistency.}
% Since the \coam{} algorithm splits the circuit into pieces
% and melds them together,
% it is important to evaluate whether
% splitting and melding lose any optimizations in practice.
% %
% In theory, our algorithm guarantees $\Omega-$optimality.
% %
% To evaluate this guarantee,
% we compare to standard \quartz{} with extended running times.
% %
% We extend the running time by increasing the per-call timeout to \quartz{}
% to $0.6$s, i.e.,
% we consider the configuration \coamwith{\quartzt{0.6}}.
% %
% We note that the end-to-end running time becomes at least ten fold in this configuration,
% and we run the standard \quartz{} for the extended time.
% %
% This ensures that \quartz{} has a larger amount of
% time to find optimizations.
% %
% We present these results in the Appendix, and summarize them here.
% % /
% Overall, the gap between both approaches reduces with extended running time
% because when optimizers operate for longer times,
% their optimization rates diminish due to the
% increasing difficulty of finding further optimizations~\cite{quartz-2022, queso-2023}.
% %
% This extended running time allows \quartz{} to somewhat catch up to the \coam{}.
% %
% However, \coam{} never generates a worse quality circuit.
% %
% We also increase the running time further by ten fold,
% verifying that \coam{} consistently delivers better quality circuits.
% %
% We conclude from these experiment with extended running times
% that $\Omega$-optimality is a good quality guarantee because,
% in practice,
% the \coam{} algorithm never generates a worse quality circuit.
% %



%
% Overall, we note that the gap between the approaches has reduced,
% when compared to the previous configuration.
% %
% This occurs because as optimizers operate for longer times,
% their optimization rates diminish due to the
% increasing difficulty of finding further optimizations~\cite{quartz-2022, queso-2023}.
% %
% The difference in optimization rates between \figref{comp-quartz} and \figref{comp-queso}
% exemplifies this.
% %
% For example, the optimization rate in vqe\_n12 for \quartz{} reduces from around $30$ to $12$
% when its execution time increases from $37$ seconds to $640$ seconds.
% %
% The many fold extension of execution time decreases the optimization rates of both approaches
% and moderates the scalability advantages of the \coam{} algorithm.
% %
% On average,
% circuits generated by the \coam{} algorithm are $1.1$ times smaller
% than those generated by \quartz{}.
% %/
% In our Supplementary,
% we include a third configuration (\coamwith{\quartzt{6}})
% where we further increase the time ten fold and observe a similar trend,
% where \coam{} consistently delivers better quality circuits.
% %
% We conclude from these experiment with extended running times
% that $\Omega$-optimality is a good quality guarantee because,
% in practice,
% the \coam{} algorithm never generates a worse quality circuit.
%

\subsection{\coam{} with the \queso{} optimizer}
\label{sec:comp-queso}
% guarantees $\Omega$-optimality.
%
In this section, we evaluate our optimizer $\coamwith{\quesot{0.005}}$,
which runs our \coam{} algorithm using \queso{} as the oracle.
%
Our optimizer depth uses segment size $\Omega = 6$
and gives each call to \queso{} is a timeout (see \secref{methodology} for the more details).
%
We run $\coamwith{\quesot{0.005}}$,
or \coam{} for short,
on all the circuits and record
the output quality and running time.
%
We then run default \queso{} on each input circuit for the same end-to-end time,
%
and evaluate the number of optimizations.


\begin{figure}
  \centering
  \small
  \input{fig/prelim.queso.0.005.tex}
  \caption{
  The figure compares the performance of our $\coamwith{\quesot{0.005}}$ optimizer with standard \queso{}.
  %
  The label ``S'' represents the number of optimization discovered by our \coam{} approach
  and the label ``Q'' denotes optimizations found by \queso{}.
  %
  The ``S/Q'' column measures how many more optimizations \coam{} finds relative to \queso{};
  we avoid divide by zero issues by adding $+1$ optimization to both tools.
  %
  For the results in this figure, we impose an end-to-end timeout of ten hours.
  }
  \label{fig:comp-queso}
  % \setlength{\belowcaptionskip}{-10pt}
\end{figure}

\figref{comp-queso} shows the results of this experiment
for circuits from six families of quantum algorithms.
%
Each family is separated by a horizontal line
and contains circuits which differ number of qubits and are sorted by input size.
%
The figure shows the number of optimizations performed by our \coam{} approach and by \queso{}
in the columns labeled ``S'' and ``Q'' respectively;
the columns also list the percentage of gates removed in parentheses.
%
The figure uses bold numbers when one tool finds more optimizations than the other.
%
The time column shows the running time of each benchmark.
%
The results show that our optimizer consistently finds significant reductions
in gate count, across all families and circuit sizes.

%
\myparagraph{Quality.}
Across the board, we observe that using \queso{} with our \coam{} algorithm discovers
more optimizations than baseline \queso{}.
%
For the gf circuits,
the \coam{} approach reduces the gate count by $54\%$ the large instance (96 qubits)
and \queso{} does not discover any optimizations in same the running time.
%
For the vqe circuits,
our \coam{} algorithm delivers excellent results,
reducing the gate count by around around $60\%$ on all instances;
\queso{} reduces the gate count of the smallest instance by $48\%$ but
does not find optimizations for others in this amount of running time.
%
%
For the qft circuits, both approaches find similar reductions in the gate count.
%
Overall, we see that using \queso{} with the \coam{} algorithm finds substantial
reductions in gate count, across a range of quantum algorithms and circuit sizes.
%

\myparagraph{Scalability.}
The figure also shows that our \coamwith{\queso} optimizer scales well with circuit size.
%
The column ``S/Q'' computes the ratio of optimizations found by the tools,
and the ratio typically increases with circuit size.
%
For example,
in the case of ham circuits,
the ratio increases from 1.19x to 2x with increasing circuit size.
%
For grover circuits,
the optimization ratio increases from $1.3$x to $72$x.
%
Similarly, for hhl circuits, the ratio increases from 1.21x on the smallest instance (7 qubits)
to 1.94x on the medium sized instance (9 qubits);
for the largest instance of hhl (11 qubits),
using \queso{} with our \coam{} algorithm finds 17\% reduction and baseline \queso{}
does not discover any optimizations.
%
Similarly, \coam{} delivers increasing optimization ratios for the ``vqe'' family.
%

\myparagraph{Summary.}
The results show that many optimizations are local
and are found by our algorithm because it focuses \queso{} on small segments.
%
Our algorithm's approach to optimize circuits in a piecewise fashion and melding them together
finds significant reductions using \queso{} as the oracle.

% Because \coamwith{\queso} finds these optimizations by only sending segments of size $2\Omega$ to \queso{},
% the results demonstrate that many optimizations are local
% and can be found by focusing the baseline optimizer on small segments.

% The evaluation suggests that the \coam{} algorithm utilizes the \queso{} optimizer effectively,
% by splitting the circuit into small segments, optimizing them with \queso{} and finding
% the optimizations at the boundaries by melding the resulting circuits.




% \input{linearity}

\subsection{Experimenting with segment size}
\label{sec:var-segment}
\input{fig/segment}
In this section,
we evaluate the quality and efficiency guaranteed by the \coam{} algorithm
for different values of parameter $\Omega$.
%
We use our optimizer $\coamwith{\feyntool}$ for this evaluation,
which guarantees $\Omega-$optimality relative to the \feyntool{} optimizer.

%
\figref{vary-segment} plots the output T count (number of T gates) and the running
time of the optimizer against $\Omega$.
%
The figure shows the results for $\Omega$ values $2, 5, 15, 30, 60, 120 \dots 7680$;
we present the full table in the Appendix.
%
The red dotted line in the plots
shows the results of the the baseline optimizer \feyntool{}.
%
For the experiment,
we run the our optimizer on the hhl circuit with $7$ qubits, which initially contains 61246 T gates.
%
The results show that for a wide range of $\Omega$ values,
our optimizer produces a similar quality circuit as the baseline $\feyntool$
and typically does so in significantly less time
(at the extremities, there are two values of $\Omega$ for which \coam{} takes more time: $2$ and $7680$).
%

%
\myparagraph{T count.}
The plot for T count shows that when $\Omega$ is small (around $2$),
increasing it has quality benefits.
%
This is because quality guarantee of the $\coam{}$ algorithm becomes
stronger with increasing $\Omega$ as it requires larger segments to be optimal.
%
%
However, the benefits of increasing $\Omega$
become very incremental especially when $\Omega$ reaches around $60$,
where T count reaches around 42140 (20 gates away from being optimal).
%
This shows that $\Omega-$optimality is a good quality criterion,
as it generates good quality circuits
even with relatively small values of $\Omega$ (around $60$).

\myparagraph{Run time.}
One would perhaps expect that the running time of \coam{}
increases by increasing the segment size $\Omega$ because
1) each oracle call operates on larger segments
and 2) the algorithm generates a better quality circuit (provably and practically).
%
Indeed, the intuition is correct, for a majority of the values.
%
For values of $\Omega$ ranging from $120$ to $7860$,
the running time of the algorithm increases with increasing $\Omega$.
%
In this range,
the (non-linear) complexity of the oracle dominates the running time,
and it is faster to split, optimize and meld, calling the oracle many times
on smaller segments,
instead of querying the oracle on larger segments.


But, when $\Omega$ is very small,
we observe the opposite, i.e.,
increasing $\Omega$ reduces the running time.
\begin{wrapfigure}{r}{0.4\textwidth}
  \centering
  \includegraphics[width=0.39\textwidth]{omega_vs_time_zoom.png}
  \caption{Zooming in: Time vs. Omega plot}
  \label{fig:zoom-plot}
\end{wrapfigure}
%
For reference,
we draw \figref{zoom-plot},
which zooms the running time plot from \figref{vary-segment}
for initial values of $\Omega$, ranging from $2, 5, 15 \dots 120$.
%
For these smaller values of $\Omega$,
even though each oracle call is cheap,
the number of oracle calls dominates the time cost.
%
The \coam{} algorithm splits the circuit into a large number of small segments
and queries the oracle on each one, making many calls to the optimizer.
%
When a circuit segment is small,
it is more efficient to directly call \feyntool{},
which optimizes it in one pass.
%
For this reason, $\Omega = 120$ is a good value for our optimizer $\coamwith{\feyntool{}}$,
as it does not send large circuits to the oracle,
and also does not split the circuit into a large number of really small segments.
%

Overall,
we observe that for a wide range of $\Omega$ values,
our \coam{} algorithm outputs good quality circuits
and does so in a shorter running time than the baseline.
%
\input{fig/fig_oracle_call_vs_input_size}


% Furthermore, it increases the number of meld operations
% and almost every meld of the algorithm finds optimizations,
% because the oracle optimizes the boundary segments in a piecewise fashion
% rather than finding optimizing them in one step.
%
%
% We measured that, for $\Omega = 2$,
% \coamwith{\feyntool} makes around ten thousand calls to the base optimizer \feyntool{},
% taking around four hundred seconds.
% %
% Thus, at the very start,
% increasing $\Omega$ reduces the running time because it reduces
% the number of oracle calls.
% %
% \figref{zoom-plot}
% The plot shows how the running time decreases with increasing the parameter.


% When the segment size becomes slightly larger, around $\Omega = 60$,
% the running time reduces to twenty seconds and does not vary much for
% some intermediate values.
% %
% For most intermediate values, around $\Omega = 30$ to $\Omega = 480$,
% we observe good time performance, where the algorithm takes around thirty seconds.
% %
% Beyond these intermediate values,
% the running time starts increasing because the algorithm sends larger segments to the oracle
% and oracle complexity becomes the dominating cost.
% %
% It is then much
% faster to split, optimize, and meld rather than use the oracle.

% When $\Omega$ is small, increasing it reduces the running time of the algorithm.
% %
% This is perhaps counterintuitive because small segment sizes
% generate a worse quality circuit and also use the oracle on smaller segments.
% %
% But, it reduces the number of oracle calls, which becomes the dominating cost in this case.
% %
% Furthermore, for small segment sizes,
% almost every meld is finding optimizations
% %




% Also note, that the initial T count for this circuit is 61246,
% implying that different values of $\Omega$ do not have a large impact on quality.
% %






% %
% But slowly the benefits become incremental and eventually $\Omega$ is large enough where
% the output of \feyntool{} matches the optimizer  $\coamwith{\feyntool}$,
% as shown with the dotted red line.
% To summarize,
% \figref{fig:comp-quartz} demonstrates that the \coam{} algorithm
% drastically improves the speed of optimization for each circuit.
% %
% It shows that the algorithm scales well with circuit size,
% achieving excellent optimization rates across a range of sizes.
% %
% \figref{fig:comp-queso} shows that this performance
%

%


% \input{fig/prelim2.0.01}



% To summarize,
% \figref{fig:comp-quartz} demonstrates that the \coam{} algorithm
% drastically improves the speed of optimization for each circuit.
% %
% It shows that the algorithm scales well with circuit size,
% achieving excellent optimization rates across a range of sizes.
% %
% \figref{fig:comp-queso} shows that this performance comes at no cost to circuit quality
% even with the extended runtime,
% as the \coam{} algorithm never generates a worse quality circuit.
% %


% \subsection{Scalable optimization using \coam{} with \queso{}}

% \begin{figure*}
%   \centering
%   \input{fig/r}
%   \caption{
%   The figure compares the performance of $\coamwith{\quesot{1}}$ against standard \queso{}.
%   %
% The label ``S'' represents $\coamwith{\quesot{1}}$ and the label ``Q'' represents \queso{}.
% %
% The figure compares the circuit sizes (lower is better) and the optimization rates (higher is better) of both approaches
% after running them for the same end-to-end time.
% }
%   \label{fig:comp-queso}
% \end{figure*}

% In this section,
% we evaluate the \coam{} algorithm using the \queso{} optimizer.
% %
% We integrate the \queso{} optimizer into our algorithm as an oracle
% and impose a one second time out for each call.
% %
% We note that \queso{} does not follow the given timeout strictly
% and often takes longer to run and return the result (around $4/5$ seconds per call).

% To evaluate the algorithm,
% we run it with \queso{} and compute the final circuit
% and the overall execution time, excluding time for file I/O (\secref{impl}).
% %
% Then, we execute default \queso{} on the whole circuit for the same total runtime
% and compare the quality of circuits produced.
% %
% For this experiment,
% we filter benchmarks based on their sizes and
% opt for benchmarks whose sizes are less than ten thousand gates.
% %
% This size limitation arises from file I/O overheads which make restrict our ability
% to run larger circuits within reasonable times.

% \figref{comp-queso} shows the results of the evaluation for seven benchmarks
% coming from four families of algorithms.
% %
% The ``QS'' column denotes \queso{} and the ``S'' column represents the \coam{} algorithm
% using \queso{} as the oracle.
% %
% In all cases, the \coam{} approach generates smaller circuits than the baseline \queso{}.
% %
% Similar to the case with \q{} (\secref{quartz}),
% we observe that the gap between the \coam{} approach and default \queso{} increases
% with circuit size.
% %
% Foe example,
% in the grover family,
% the ratio of optimization rate between \coam{} and \queso{}
% increases from $1.14$x for grover\_n7 to $1.4$x in grover\_n9.
% %
% For the circuit vqe\_n12,
% which is the largest circuit on the table,
% the final circuit size is $0.78$ times smaller compared to \queso{},
% which demonstrates the scalability of the \coam{} approach.
% %
% On average,
% the algorithm's circuits are $0.92$x smaller than those generated by \queso{}
% and the algorithm makes $1.27$x as many optimizations per second.
% %

% The evaluation demonstrates that the \coam{} algorithm
% improves the scalability of the \queso{} optimizer and
% consistently delivers better quality circuits.


% \input{prelim}

% \cleardoublepage
% \subsection{Eval half 2}
% \input{prelim2.tex}
% \subsection{Plots}
% \input{plots_greedy.tex}
% \cleardoublepage
% \subsection{Cliff Eval half 1}
% \input{prelim1.clifft}
% \cleardoublepage
% \subsection{Cliff Eval half 2}
% \input{prelim2.clifft}
% \subsection{Plots Cliff}
% \input{plots_greedy_cliff.tex}
