Our paper focuses on how to analyze the consistency of responses by an LLM. Hamman et al~\cite{hamman2024quantifying} defines the measure of consistency for models predicting tabular data. Our work relies on general large language models that are not specifically fine-tuned for tabular data.  

Consistency analysis is an important aspect of hallucination analysis and detection. There is an entire body of work on hallucination~\cite{liu2024exploring}. There are other works related to self-reflection~\cite{ji-etal-2023-towards}, distributed LLMs~\cite{10476280}, and mixture-of-experts~\cite{du2024mixture}. \cite{jang2023consistency} performed experiments to examine the consistency of ChatGPT's~\cite{openai2023gpt35, openai2023gpt4} responses, uncovering situations where its language comprehension abilities don't always lead to logically sound predictions. 

 LLMs suffer from security issues~\cite{wu2024new,qachfar2024all}, and there are risks of code generation using LLMs~\cite{vaidya2023critical}. LLMs hallucinate~\cite{xu2024hallucination} and such hallucinations often increase the risk of reduction of utility of the models, or even risk of failure during task execution, with LLMs as judges~\cite{zheng2024judging}, or autonomous LLM agents~\cite{talebirad2023multi}. 
 

LLMs can be used in enabling cybersecurity processes (SecOps)~\cite{gennari2024considerations}. Aljanabi et al.~\cite{aljanabi2023chatgpt} explored ChatGPT's relevance in the cybersecurity domain, demonstrating its utility for security professionals in identifying potential vulnerabilities. Khoury et al.~\cite{khoury2023secure} conducted experiments to assess the safety of programs generated by ChatGPT and sought security assessments. Peng et al.~\cite{peng2023check} introduced a new model that enhances black-box LLMs with plug-and-play modules, outlining an iterative strategy to improve model feedback. LLMs are also being proposed to be used in security operation centers (SoC)~\cite{saha2024llm}. \par

Secure code copilots and secure generation of code is an important area of investigation, in security analysis of code and configurations~\cite{toth2024llms, minna2024analyzing}, in generation of secure code~\cite{vaidya2023critical,saha2024empowering}, in security and penetration testing~\cite{song2024poster}. 

Existing studies have focused on the broader implications and uses of ChatGPT~\cite{lund2023chatting}, exploring the transformative potential of ChatGPT in academia and libraries, and discussing its benefits for search, discovery, cataloging, and information services. Meanwhile, discussions on the impact on higher education~\cite{rudolph2023chatgpt} highlight concerns about its ability to generate text that resembles human-authored content.\cite{baidoo2023education} examined the pros and cons of incorporating ChatGPT into teaching and learning, adding to discussions about educational technology, while~\cite{jiao2023chatgpt} investigates how well ChatGPT can translate across multiple languages. ~\cite{kuchnik2023validating} presents an innovative technique for validating and querying LLMs using standard regular expressions. Liu et al.~\cite{liu2023summary} conducted a thorough study that included trend analysis, word cloud representations, and domain-wise distribution analysis. This investigation shed light on the model's capabilities, ethical considerations, and future directions. \par

