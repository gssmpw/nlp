\section{Multicalibration}
\label{sec:mc}

Having defined our notion of a loss predictor, we next introduce the framework of multicalibration proposed by~\cite{hebert2018multicalibration}. Our definition is most similar to the presentation used in~\cite{kim2022universal}.

\begin{definition}[Multicalibration]
\label{def:mc}
    Let $\phi(p, x) \in \Phi$ be some auxiliary set of features related to the computation of $p(x)$, which we define concretely below. Let $\calC$ be a class of weight functions $c: \Phi \rightarrow [-1, 1]$, and $p: \calX \rightarrow [0, 1]$ a binary predictor for a target distribution $\calD$ over $\calX \times \{0, 1\}$. Then, the multicalibration error of $p$ with respect to $\calC$ is defined as 
    \[\MCE(\calC, p) := \max_{c \in \calC} \left|\ex_{x, y \sim \calD}[(y - p(x))c(\phi(p, x))]\right|.\]
    The information contained in $\phi(p, x)$ gives rise to a hierarchy of multicalibration notions of increasing strength:
    \begin{enumerate}
        \item \emph{Calibration} corresponds to the setting where  $\phi(p, x)= p(x)$, and test functions can only depend on $p$'s prediction. 
        \item \emph{Multicalibration} corresponds to the case where test functions can additionally depend on the input features, i.e. $\phi(p, x) = (p(x), \inp(x))$.
        \item \emph{Representation-aware multicalibration} is a strengthening of multicalibration where test functions can additionally depend on some representation $r(x)$ of $x$ i.e., $\phi(p, x) = (p(x), \inp(x), r(x))$. We distinguish between internal representations $r_p(x)$ and external representations $r_e(x)$ as with loss predictors (Definition \ref{def:lp}).
    \end{enumerate}
\end{definition}

The first two levels in this hierarchy, calibration and multicalibration, have been extensively studied in previous works. 
In standard multicalibration, we require that a predictor $p(x)$ be well-calibrated under a broad class of test functions, $\calC$, that depend only on $\inp(x)$ and $p(x)$. The literature on multicalibration typically identifies $\inp(x)$ with $x$ itself. The last level of the hierarchy, representation-aware multicalibration, is a strengthening of multicalibration that naturally extends the multicalibration framework of ~\cite{hebert2018multicalibration}. As in the case of loss-predictors, the gap between internal representations $r_p(x)$ and $\inp(x)$ is computational; whereas the gap between external representations $r(x)$ and $\inp(x)$ could be information-theoretic. 








\begin{definition}[Multicalibration violation witness]
    We say that a function $c: \Phi \times [0,1] \rightarrow [-1, 1]$ is a witness for a multicalibration violation of magnitude $\alpha$ for a predictor $p$ if 
    \[\left|\ex_{x, y \sim \calD}[(y - p(x))c(\phi(p, x))]\right| > \alpha.\]
\end{definition}

\cite{hebert2018multicalibration} showed that if we find such a witness, we can use it to improve the predictor $p$ in a way that reduces the squared loss. While their argument is stated for the input-aware setting where $\phi(p,x) = (p(x), \inp(x))$, it applies to the representation-aware setting as well. 





    


