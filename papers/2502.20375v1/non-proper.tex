\section{Handling non-proper losses}
\label{sec:non-proper}

We consider an abstract action space $\mA$; examples are the discrete setting where $\mA = [k]$, and the continuous setting where $\mA = \R$. 
A hypothesis is a function $h: \X \to \mA$. 
A loss function is a function $\ell: \zo \times \mA \to [0,1]$. The expected loss of hypothesis $h$ at the point $x$ is given by $\ex[\ell(y, h(x))|x]$. The goal of a loss predictor is to learn a function $\lossPred: \Phi \to \R$ that gives pointwise estimates of this quantity. As in definition \ref{def:lp}, we can define a hierarchy of loss predictors based on the features available to them.


For any loss $\ell$, if the labels are drawn according to $y \sim \Ber(p)$ for any $p \in [0, 1]$, then the optimal prediction that minimizes the loss, $k_{\ell}(p) \in [0, 1]$ is defined by 
\[k_{\ell}(p) = \argmin_{v \in [0, 1]}\ex_{y \sim \Ber(\pbayes(x))}[\ell(y, v)]
\footnote{In the event that there is no unique minimum, we allow $k_\ell$ to output a subset of $\mA$, so it is strictly speaking a relation rather than a function. We blur this distinction for simplicity}.\]












If there exist a {\em latent} predictor $p_h:\X \to [0,1]$ so that $h = k_\ell \circ p_h$ is obtained by best-responding to its predictions, then we can reduce to the setting of proper losses, since 
\[ \ex[\ell(y, h(x))] = \ex[\ell(y, k_\ell(p(x)) = \ex [\ell \circ k_\ell(y, p(x))] \]
and we have the following result of \cite{kleinberg2023u}.

\begin{lemma}[\cite{kleinberg2023u}]
\label{lem:klst}
    For any loss $\ell:\zo \times \mA \to [0,1]$, the loss function $\ell \circ k_\ell: \zo \times [0,1] \to \R$ is a proper loss.
\end{lemma}

But under what conditions on $h$ does there exist such a predictor $p_h$? And is it easy to estimate its predictions given access to $h$? 
 
To answer the first question, we show that it is equivalent to assuming that the hypothesis satisfies a simple optimality condition for the loss.

\begin{definition}
    The hypothesis $h:\X \to [0,1]$ is swap-optimal for $\mD$ if for every function $\kappa:\mA \to \mA$, it holds that $\ex[\ell(y, h(x))] \leq \ex[\ell(y, \kappa(h(x)))]$.
\end{definition}
Swap optimality is a weak optimality condition that can be easily achieved by post-processing. It is quite reasonable to assume that a well-trained model optimized to minimize loss satisfies this guarantee. For instance, a well-trained image classifier should not improve if every time it predicts {\em cat}, we say {\em dog} instead. 
For a swap optimal hypothesis $h$, we show that is indeed easy to identify a latent predictor $p_h$ so that $h$ is obtained by best-responding to its predictions. This theorem lets us extend our theory of loss prediction for proper losses to arbitrary loss functions under the rather weak assumption that $h$ is swap-optimal. 

\begin{theorem}
\label{thm:swap-proper}
Given a hypothesis $h:\X \to \mA$ and a distribution $\mD$, define the predictor $p_h: \X \to [0,1]$ by $p_h(x) = \ex_\mD[y|h(x)]$. The hypothesis $h$ is swap optimal iff $h(x)= k_\ell \circ p_h(x)$ for all $x \in \X$.\footnote{Strictly speaking, $k_\ell$ is not a function as there can be many optimal actions. However we interpret this equation as saying $h(x)$ is in the set of optimal actions for $p_h(x)$.}
\end{theorem}
\begin{proof}
    Assume that $h$ is not swap-optimal, so there exist $\kappa$ such that $\ex[\ell(y, \kappa(h(x)))] < \ex[\ell(y, h(x))]$. There must exist a specific choice of $h(x) = a \in \mA$ conditioned on which the inequality still holds, hence 
    \[ \ex[\ell(y, \kappa(a))|h(x) = a]  \leq \ex[\ell(y, a)|h(x) =a]. \]
    Let $\ex[y|h(x) =a] = v$. But this shows that when $y \sim \Ber(v)$, $\ex[\ell(y, \kappa(a)] < \ex[\ell(y,a)]$, so $a \neq k_\ell(v)$. Hence for all $x \in h^{-1}(a)$, we have $h(x) = a \neq k_\ell(v) = k_\ell(p_h(x))$. 

    Conversely, if $h$ is indeed swap optimal, then it must be the case that every action $a \in \mA$ is a best response to $\E[y|h(x) =a] = p_h(x)$, which means we have $h(x) = k_\ell(p_h(x))$.
\end{proof}



