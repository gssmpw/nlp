We consider a binary prediction task over a space $\calX$. Given some true unknown distribution $\calD$ over $\calX \times \{0, 1\}$, we denote $\pbayes(x) := \mathbb{E}_{\calD}[y|x]$ as the true conditional distribution of $y$ given each $x$. We assume that we are provided some pre-trained predictor $\pred: \calX \rightarrow [0, 1]$. 

\subsection{Losses and the Discrete Derivative}
A loss function $\ell: \{0, 1\} \times [0, 1] \rightarrow \R_{\geq 0}$ gives a measure of the loss suffered when we predict some value in $[0, 1]$ compared to the true label. Define the expected loss $L : [0, 1] \times [0, 1] \to \R_{\geq 0}$ at $x \in \calX$ to be $L \divx{\pbayes(x)}{\pred(x)} = \ex_{y \sim \Ber(\pbayes(x))}[\ell(y, \pred(x))]$. 

We note the following useful fact: 
\begin{fact}\label{fact:loss-def}
    For any loss $\ell: \{0, 1\} \times [0, 1] \rightarrow \R$, and $v \in [0, 1]$ we have that $\ell(y, v)$ can be equivalently rewritten as 
    \[\ell(y, v) = y(\ell(1, v) - \ell(0, v)) + \ell(0, v).\]    
\end{fact}

For ease of notation, given a loss $\ell$ and $v \in [0, 1]$, we will denote the ``discrete derivative" of $\ell$ at $v$ as 
\[\delta_{\ell}(v) := \ell(1, v) - \ell(0, v).\] 


For any loss $\ell$, if the labels are drawn according to $y \sim \Ber(\pbayes(x))$ for any $\pbayes(x) \in [0, 1]$, then the optimal prediction that minimizes the loss, $k_{\ell}(\pbayes(x)) \in [0, 1]$ is defined by 
\[k_{\ell}(\pbayes(x)) = \argmin_{v \in [0, 1]}\ex_{y \sim \Ber(\pbayes(x))}[\ell(y, v)] = \argmin_{v \in [0, 1]}L\divx{\pbayes(x)}{v}.\]



We call the loss \emph{proper} if for all $\pbayes(x) \in [0, 1]$, it is minimized by predicting $\pbayes(x)$, i.e. 
\[L\divx{\pbayes(x)}{\pbayes(x)} = L\divx{\pbayes(x)}{k_{\ell}(\pbayes(x))}.\]

Notable examples of proper losses include the square loss and cross entropy loss. An example of a non-proper loss is the $\ell_1$-loss, $\ell_1(y, v) = |y - v|$. In this case, the optimal prediction is obtained by rounding $\pbayes(x)$ to the nearest value in $\{0, 1\}$. 

We note that composing any loss $\ell$ with its associated optimal post-processing function $k_{\ell}$ results in a proper loss, even if $\ell$ itself is non-proper. In particular, let $\ell_k(y, v) = \ell(y, k_{\ell}(v))$ for any loss $\ell$. Then, we have that for any point $x \in \calX$,
\begin{align*}
    L_k\divx{\pbayes(x)}{\pbayes(x)} &= \ex_{y \sim \Ber(\pbayes(x))}[\ell_k(y, \pbayes(x))]\\
    &= \ex_{y \sim \Ber(\pbayes(x))}[\ell(y, k_{\ell}(\pbayes(x)))]\\
    &= \ex_{y \sim \Ber(\pbayes(x))}[\ell(y, \argmin_{v \in [0, 1]}\ex_{y \sim \Ber(\pbayes(x))}[\ell(y, v)])]\\
    &= \min_{v \in [0, 1]}\ex_{y \sim \Ber(\pbayes(x))}[\ell(y, v)]\\
    &= \min_{v \in [0, 1]}\ex_{y \sim \Ber(\pbayes(x))}[\ell(y, k_{\ell}(v))]\\
    &= L_k\divx{\pbayes(x)}{k_{\ell_k}(\pbayes(x))}
\end{align*}
implying that $\ell_k$ is indeed proper. Thus, we can extend any discussion of proper losses to include non-proper losses when predictions are made using the optimal post-processed value. 

Define the generalized entropy function $H(v) = L \divx{v}{v}$, and the generalized (Bregman) divergence $D \divx{\pbayes(x)}{v} = L \divx{\pbayes(x)}{v} - H(\pbayes(x))$.

In the case of proper losses, prior works have noted an important characterization of proper losses with respect to their associated concave generalized entropy functions $H_{\ell}(v)$ \cite{gneiting2007strictly, kleinberg2023u}. In particular, every concave function $H: [0, 1] \rightarrow \R_{\geq 0}$ gives rise to a proper loss $\ell$ defined by 
\[\ell(1, v) = H(v) + (1 - v)H'(v)\]
\[\ell(0, v) = H(v) - v H'(v) \]
where $H'(v)$ is a ``superderivative'' of $H$, i.e. for any $v, w \in [0, 1]$, $H(v) \leq H(w) + (v - w)H'(w)$. When $H(v)$ is differentiable at all $v \in [0, 1]$, the superderivative is unique, and is just the derivative. 

In the reverse direction, any proper loss (with some regularity assumptions) has the above form for the concave function $H(v) = L\divx{v}{v}.$

Thus, we get the following characterization of the discrete derivative $\delta_{\ell}$:
\begin{proposition}
    For any proper loss $\ell$ defined by a differentiable concave function $H_{\ell}:[0,1] \rightarrow \R_{\geq 0}$, we have that for all $v \in [0,1],$
\begin{align*}
    \delta_{\ell}(v) = H'_{\ell}(v)
\end{align*}
\end{proposition}

\begin{proof}
    The statement follows immediately from the above fact and definition of $\ell$ in terms of its concave entropy function:
    \begin{align*}
    \delta_{\ell}(v) &= \ell(1, v) - \ell(0,v) \\
    &= H_{\ell}(v) + (1-v)H'_{\ell}(v) - (H_{\ell}(v) - \pred H'_{\ell}(v))\\
    &= H'_{\ell}(v).
\end{align*}
    
\end{proof}

In other words, when $\ell$ is a proper loss, $\delta_{\ell}(v)$ is just the derivative of $\ell$'s generalized entropy function at $v$. 
\todo{Notation ($v$, $\pred$, $\pbayes$).}

\subsection{Loss Predictors and the Self-Entropy Predictor}

Given a predictor $p: \calX \rightarrow [0,1]$ and a proper loss $\ell: \{0,1\} \times [0,1] \rightarrow \R_{\geq}$, a \emph{loss predictor} for $\ell$ and $p$, $\lossPred: \calX \times [0,1] \rightarrow \R_{\geq 0}$, provides point-wise estimates $\lossPred(x, p(x))$ of the loss at each $x \in \calX$. 

\todo{exact format for loss predictor needs to be ironed out (notation, does it get additional features, etc) }

A perfect loss-predictor would predict exactly the true expected loss at each $x$, i.e. $\lossPred(x, p(x)) = L\divx{\pbayes(x)}{\pred(x)}$. 
\todo{introduce square loss as a natural objective}

In the absence of any other information or data, $\pred$ itself can be used to construct loss predictions, which we refer to as the \emph{self-entropy predictor.} In particular, if we believe $\pred$ to be close to $\pbayes$, then a natural estimate of the loss at a particular point $x$ would be the loss incurred if $\pbayes(x) = \pred(x)$, i.e. $L\divx{\pred(x)}{\pred(x)} = H_{\ell}(\pred(x))$. 

\begin{definition}[Self-Entropy Predictor]
    Given a proper loss $\ell$ and predictor $\pred$, we define the \emph{self-entropy predictor} for $\ell$ and $p$ to be the predictor that outputs $\ell$'s generalized entropy value for each prediction:
    \[\lossPred(x, \pred(x)) = H_{\ell}(\pred(x)).\]
\end{definition}

This definition of the self-entropy predictor is not arbitrary. In particular, we can show that when $\pred$ is calibrated, it is the optimal post-processing of $\pred$'s predictions to produce a loss predictor. 
\todo{need to define calibration before this, or put later}

\begin{lemma}\label{lem:self-entropy-opt}
    Consider any proper loss $\ell$ and calibrated predictor $p$. Then, 

    \[H_{\ell} = \argmin_{G: [0,1] \rightarrow \R_{\geq 0}} \ex_{x \sim \calD_{\calX}}[(L\divx{\pbayes(x)}{\pred(x)} - G(\pred(x)))^2].\]
    I.e., among all possible post-processings of the predictor $\pred$ to produce a loss predictor, $H_{\ell}$ is the one that minimizes the square loss of the resulting loss predictor.
\end{lemma}

\begin{proof}[Proof sketch]
We sketch a proof that the self-entropy is the best loss predictor purely as a function of the prediction (and not the point) if the predictor is calibrated --- i.e. the best loss predictor that is constant on the level sets.

Consider a single level set $[x]$ where we predict $p(z) = p$ for all $z \in [x]$. The self-entropy loss prediction on this entire level set is $H(p)$.

Let the level set consist of $n$ points $z_1, \dots, z_n$, with true probabilities $\pbayes(z_1), \dots, \pbayes(z_n)$. And the true losses wrt the prediction $p$ are $L^*_i := L \divx{\pbayes(z_i)}{p}$.

Now what is the optimal constant loss prediction on this level set? If we mean optimal in terms of having least expected square loss wrt the true $L^*_i$, i.e. $\arg \min \ex_i (L - L^*_i)^2$, then the optimum is precisely the mean, $L = \ex_i [L^*_i]$.

Now miraculously by linearity of expectation, \begin{align*}
    \ex_i [L^*_i] &= \ex_{z_i \sim [x]} [L \divx{\pbayes(z_i)}{p}] \\
    &= \ex_{z_i \sim [x]} \ex_{y \sim \pbayes(z_i)} \ell(y, p) \\
    &= L \divx{\ex_{z_i \sim [x]} \pbayes(z_i)}{p} \\
    &= L \divx{p}{p} \\
    &= H(p),
\end{align*} proving optimality. Basically we can send the expectation in because $L$ is linear in the first argument (i.e.\ the truth), and then use the key fact that $\ex_{z_i \sim [x]} \pbayes(z_i) = p$ since the predictor is calibrated.

In fact I think this proof also establishes the converse, i.e.\ if the self-entropy loss prediction is optimal it can only be because we are calibrated on that level set.
\end{proof}

It turns out that the performance of the self-entropy predictor is highly connected to the closeness of $\pbayes$ and $\pred$ as well as the discrete derivative of the loss in question. 

\begin{lemma}[Pointwise Loss Gap]
    Given any proper loss $\ell$ and predictor $p$, the point-wise distance between the true loss and self-entropy prediction for any $x \in \calX$ can be equivalently expressed as 
    \[L\divx{\pbayes(x)}{\pred(x)} - H_{\ell}(\pred(x)) = (\pbayes(x) - \pred(x))\delta_{\ell}(\pred(x)).\]
\end{lemma}
In other words, the quality of the self-entropy predictor can be connected to a re-weighted version of the quality of $\pred$ itself. 

\begin{proof}
    We have 
    \begin{align*}
    L\divx{\pbayes(x)}{\pred(x)} - H_{\ell}(\pred(x)) &= \ex_{y \sim \Ber(\pbayes(x))}\ex[\ell(y, \pred(x))] - \ex_{\tilde y \sim \Ber(\pred(x))}\ex[\ell(\tilde y, \pred(x))]\\
    &= \pbayes\delta_{\ell}(\pred(x)) + \ell(0,\pred(x)) - (\pred(x)\delta_{\ell}(\pred(x)) + \ell(0, \pred(x))) \tag{Fact~\ref{fact:loss-def}}\\
    &= (\pbayes(x) - \pred(x))\delta_{\ell}(\pred(x))
    \end{align*}
\end{proof}

This relationship will prove crucial for linking the accuracy of loss prediction to the multicalibration of the pre-trained predictor. We next introduce and define multicalibration. 

\subsection{Multicalibration}
