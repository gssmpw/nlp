[
  {
    "index": 0,
    "papers": [
      {
        "key": "papineni2002bleu",
        "author": "Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing",
        "title": "Bleu: a method for automatic evaluation of machine translation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "lin2004rouge",
        "author": "Lin, Chin-Yew",
        "title": "Rouge: A package for automatic evaluation of summaries"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "denkowski2014meteor",
        "author": "Denkowski, Michael and Lavie, Alon",
        "title": "Meteor universal: Language specific translation evaluation for any target language"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "popovic2015chrf",
        "author": "Popovi{\\'c}, Maja",
        "title": "chrF: character n-gram F-score for automatic MT evaluation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "tran2019does",
        "author": "Tran, Ngoc and Tran, Hieu and Nguyen, Son and Nguyen, Hoan and Nguyen, Tien",
        "title": "Does BLEU score work for code migration?"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "ren2020codebleu",
        "author": "Ren, Shuo and Guo, Daya and Lu, Shuai and Zhou, Long and Liu, Shujie and Tang, Duyu and Sundaresan, Neel and Zhou, Ming and Blanco, Ambrosio and Ma, Shuai",
        "title": "Codebleu: a method for automatic evaluation of code synthesis"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "zheng2023codegeex",
        "author": "Zheng, Qinkai and Xia, Xiao and Zou, Xu and Dong, Yuxiao and Wang, Shan and Xue, Yufei and Wang, Zihan and Shen, Lei and Wang, Andi and Li, Yang and others",
        "title": "Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x"
      },
      {
        "key": "zhuo2024bigcodebench",
        "author": "Zhuo, Terry Yue and Vu, Minh Chien and Chim, Jenny and Hu, Han and Yu, Wenhao and Widyasari, Ratnadira and Yusuf, Imam Nur Bani and Zhan, Haolan and He, Junda and Paul, Indraneil and others",
        "title": "Bigcodebench: Benchmarking code generation with diverse function calls and complex instructions"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhang2022codet",
        "author": "Zhang, Yue and Wang, Shuoyang and Zhang, Xinyun",
        "title": "CodeT: Code Generation with Generated Tests"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zhuo2023ice",
        "author": "Zhuo, Terry Yue",
        "title": "ICE-Score: Instructing Large Language Models to Evaluate Code"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "tong2024codejudge",
        "author": "Tong, Weixi and Zhang, Tianyi",
        "title": "CodeJudge: Evaluating Code Generation with Large Language Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "kahneman2011thinking",
        "author": "Kahneman, Daniel",
        "title": "Thinking, fast and slow"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "ji2025test",
        "author": "Ji, Yixin and Li, Juntao and Ye, Hai and Wu, Kaixin and Xu, Jia and Mo, Linjian and Zhang, Min",
        "title": "Test-time Computing: from System-1 Thinking to System-2 Thinking"
      },
      {
        "key": "xu2025towards",
        "author": "Xu, Fengli and Hao, Qianyue and Zong, Zefang and Wang, Jingwei and Zhang, Yunke and Wang, Jingyi and Lan, Xiaochong and Gong, Jiahui and Ouyang, Tianjian and Meng, Fanjin and others",
        "title": "Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "snell2024scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "jaech2024openai",
        "author": "Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others",
        "title": "Openai o1 system card"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny",
        "title": "Self-consistency improves chain of thought reasoning in language models"
      },
      {
        "key": "wang2024strategic",
        "author": "Wang, Yu and Zhao, Shiwan and Wang, Zhihu and Huang, Heyuan and Fan, Ming and Zhang, Yubo and Wang, Zhixing and Wang, Haijun and Liu, Ting",
        "title": "Strategic chain-of-thought: Guiding accurate reasoning in llms through strategy elicitation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "deepseek2025r1",
        "author": "DeepSeek-AI",
        "title": "DeepSeek-R1: Advancing Reasoning in AI Models"
      },
      {
        "key": "qwen2024technical",
        "author": "Qwen",
        "title": "Qwen2.5 Technical Report"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "guan2025rstar",
        "author": "Guan, Xinyu and Zhang, Li Lyna and Liu, Yifei and Shang, Ning and Sun, Youran and Zhu, Yi and Yang, Fan and Yang, Mao",
        "title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking"
      },
      {
        "key": "yu2024self",
        "author": "Yu, Yue and Chen, Zhengxing and Zhang, Aston and Tan, Liang and Zhu, Chenguang and Pang, Richard Yuanzhe and Qian, Yundi and Wang, Xuewei and Gururangan, Suchin and Zhang, Chao and others",
        "title": "Self-generated critiques boost reward modeling for language models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "zhang2024rest",
        "author": "Zhang, Dan and Zhoubian, Sining and Hu, Ziniu and Yue, Yisong and Dong, Yuxiao and Tang, Jie",
        "title": "Rest-mcts*: Llm self-training via process reward guided tree search"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "qi2024mutual",
        "author": "Qi, Zhenting and Ma, Mingyuan and Xu, Jiahang and Zhang, Li Lyna and Yang, Fan and Yang, Mao",
        "title": "Mutual reasoning makes smaller llms stronger problem-solvers"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "zhang2024accessing",
        "author": "Zhang, Di and Huang, Xiaoshui and Zhou, Dongzhan and Li, Yuqiang and Ouyang, Wanli",
        "title": "Accessing gpt-4 level mathematical olympiad solutions via monte carlo tree self-refine with llama-3 8b"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "xie2024monte",
        "author": "Xie, Yuxi and Goyal, Anirudh and Zheng, Wenyue and Kan, Min-Yen and Lillicrap, Timothy P and Kawaguchi, Kenji and Shieh, Michael",
        "title": "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning"
      }
    ]
  }
]