\section{Introduction}
\label{sec:intro}

\begin{figure}[!t]
    \centering
    \includegraphics
    [width=0.95\linewidth] {figure/comparison.png}
    \caption{Matching Accuracy and Efficiency Comparisons for descriptor-free methods. Compared with GoMatch~\cite{zhou2022geometry} and DGC-GNN~\cite{wang2024dgc}, our A2-GNN learns effective and accurate 2D-3D matching.
    }
    \label{fig: time}    
\end{figure}


Visual localization aims to estimate the camera pose of a query image within a pre-built 3D environment. 
It is essential in computer vision applications such as Structure-from-Motion (SfM)~\cite{schonberger2016structure,snavely2006photo,wu2013towards},
Augmented Reality (AR)~\cite{carmigniani2011augmented,billinghurst2015survey}, and Simultaneous Localization and Mapping (SLAM)~\cite{cadena2016past,fuentes2015visual,mur2017orb} . 
Classical visual localization approaches~\cite{sattler2011fast,sattler2012improving, sattler2017large,sarlin2019coarse,wang2021continual,wang2024hscnet++}  
use visual descriptors to build the 2D-3D correspondences.
Once the correspondences are established, a PnP-RANSAC solver~\cite{zuliani2009ransac} is applied to estimate the 6-DoF camera pose.
 
Among all camera pose estimation approaches, visual descriptor-based methods~\cite{sarlin2019coarse,sarlin2020superglue} achieve state-of-the-art (SOTA) performance. 
However, utilizing visual descriptors presents several challenges, including substantial storage requirements, privacy risks, and maintenance complexity~\cite{zhou2022geometry,wang2024dgc,chelani2021privacy,pan2023privacy}. 
Storing high-dimensional descriptors for each keypoint typically demands significant storage capacity.
Additionally, studies~\cite{pan2023privacy,chelani2021privacy} have demonstrated that visual descriptors can be exploited to recover images, raising privacy concerns.
Moreover, maintaining the 3D model becomes complicated when integrating new descriptors or points into existing point clouds~\cite{dusmanu2021cross}.

To address the challenges associated with visual descriptor-based methods, several researchers have developed visual descriptor-free approaches~\cite{campbell2020solving,zhou2022geometry,wang2024dgc}. 
These methods establish 2D-3D correspondences without relying on visual descriptors, instead leveraging geometric information from keypoints for matching. 
While these approaches demonstrate reasonable performance, their primary limitation lies in the inherently limited geometric information, which lacks the richness and detail provided by visual descriptors.  GoMatch~\cite{zhou2022geometry} attempts to learn the geometric-only representation by utilizing graph neural networks and incorporating outlier rejection, achieving reasonable performance. 
However, there is still a noticeable performance gap compared to descriptor-based methods. 
DGC-GNN~\cite{wang2024dgc} narrows this gap by integrating color and more geometric clues, along with global-to-local clustering. 
Despite these improvements, DGC-GNN suffers from heavy computational demands, particularly due to the multiple clustering operations required.

To achieve accurate camera pose estimation with light computation,  we reconsider the way of encoding geometric information. In previous descriptor-free approaches~\cite{zhou2022geometry,wang2024dgc}, transformers~\cite{vaswani2017attention} have been employed, utilizing self-attention and cross-attention mechanisms to enhance feature representation. \
The self-attention mechanism captures local geometric structures within neighborhoods, while cross-attention facilitates the exchange of geometry information between 2D keypoints and 3D point clouds. 
The extraction of local geometry through self-attention is particularly crucial, as learning high-quality feature representations is essential for effective information exchange in the following cross-attention layer.
Previous methods~\cite{zhou2022geometry,wang2024dgc} utilize max-pooling to extract local geometry from neighbors. 
However, this operation neglects neighbor structural information as most of neighbor information is discarded.
Inspired by CLNet~\cite{zhao2021progressive}, we propose \textbf{A}ngle-\textbf{A}nnular \textbf{G}raph \textbf{N}eural \textbf{N}etwork, or \textbf{A2-GNN}, 
which efficiently extracts local structural geometric information for 2D-3D matching without relying on visual descriptors. Our network processes sparse points from query images and point clouds as inputs, delivering accurate correspondences with minimal computational overhead.
We first construct a local graph for each point by connecting it to its neighboring points based on their distances. These neighboring points are then clustered into close, middle, and remote groups. Local structural information is extracted by processing these grouped neighbors separately. Besides, angular information between the point and its neighbors is encoded similarly to further enhance the local geometric representation. By encoding these geometric cues, our method effectively distinguishes between structurally similar yet distinct points in both 2D and 3D spaces.
In addition, we also adjust outlier rejection input to position information rather than the feature representation, as explicit position information can provide consensus in epipolar geometry to remove outliers.
In summary, our paper makes the following contributions:
\begin{itemize}
  \item We introduce a novel local graph neighbor aggregation method for direct 2D-3D matching without visual descriptors. This method embeds geometric information in a hybrid manner and improves the accuracy of spare 2D-3D matching.
  \item We adjust outlier rejection input to position information, as pure position information can provide robust geometry constraint. 
  \item Our method outperforms previous descriptor-free methods in matching and visual localization tasks with considerable efficiency.
\end{itemize}
