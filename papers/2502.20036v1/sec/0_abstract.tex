\begin{abstract}
% The ABSTRACT is to be in fully justified italicized text, at the top of the left-hand column, below the author and affiliation information.
% Use the word ``Abstract'' as the title, in 12-point Times, boldface type, centered relative to the column, initially capitalized.
% The abstract is to be in 10-point, single-spaced type.
% Leave two blank lines after the Abstract, then begin the main text.
% Look at previous \confName abstracts to get a feel for style and length.
Visual localization involves estimating the 6-degree-of-freedom (6-DoF) camera pose within a known scene. 
A critical step in this process is identifying pixel-to-point correspondences between 2D query images and 3D models. 
Most advanced approaches currently rely on extensive visual descriptors to establish these correspondences, facing challenges in storage, privacy issues and model maintenance.
Direct 2D-3D keypoint matching without visual descriptors is becoming popular as it can overcome those challenges.
However, existing descriptor-free methods suffer from low accuracy or heavy computation.
Addressing this gap, this paper introduces the Angle-Annular Graph Neural Network (A2-GNN), 
a simple approach that efficiently learns robust geometric structural representations with annular feature extraction.
Specifically, this approach clusters neighbors and embeds each group's distance information and angle as supplementary information to capture local structures.
Evaluation on matching and visual localization datasets demonstrates that our approach achieves state-of-the-art accuracy with low computational overhead among visual description-free methods. Our code will be released on \url{https://github.com/YejunZhang/a2-gnn}.
% \vspace{-1em}
\end{abstract}