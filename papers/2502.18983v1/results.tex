\section{Implementation and Characterization}

3D-TrIM is implemented on commercial 22 nm technology. The architecture is designed in Verilog, synthesized by Cadence Genus, and placed and routed by Cadence Innovus. The parallelism parameters are set to $P_I=8$ and $P_O=8$ (576 PEs), while the clock frequency is set to 1 GHz. According to these constraints, the design achieves a peak throughput of 1.15 Tera Operations per Second (TOPS), occupying an area of 0.26 mm$^2$ and dissipating 0.25 W. 

\input{Figures/Figure6}
Figure~\ref{OPs_MemAcc} compares 3D-TrIM and TrIM\cite{Sestito_24_2} in terms of operations per memory access per slice (OPs/Access/Slice). The normalization is done considering that 3D-TrIM uses $8 \times 8$ slices, while TrIM uses $7 \times 24$ slices. The VGG-16\cite{Simonyan_15} and AlexNet\cite{Krizhevsky_12} CNNs are referenced as case studies. The feature extraction section of VGG-16 consists of 13 convolution layers with ifmap sizes ranging from $224\times224$ to $14\times 14$ and kernel size fixed to $3\times3$. AlexNet features 5 convolution layers with ifmap sizes ranging from $227\times227$ to $13\times13$, and kernel sizes ranging from $11\times11$ to $3\times3$. It is worth underlining that 3D-TrIM can support kernel sizes larger than $3 \times 3$ through kernel tiling. For example, a $5 \times 5$ kernel can be split into four $3 \times 3$ sub-kernels. The different sub-kernels are assigned to as many cores. The adder trees are later responsible for accumulating the psums from each sub-kernel. According to Fig.~\ref{OPs_MemAcc}, 3D-TrIM outperforms TrIM\cite{Sestito_24_2} given the effectiveness of shadow registers to mitigate the memory access overhead. The improvement is in the range $2.82\times$--$3.37\times$ for VGG-16, and in the range $1.43\times$--$3.33\times$ for AlexNet. Furthermore, it should be noted that 3D-TrIM executes the same set of operations using $2.6\times$ fewer slices than TrIM\cite{Sestito_24_2}, in addition to saving IRBs due to the sharing approach at the core level.

\input{Tables/Table1}
Table~\ref{SOTA} collects architectural information for both 3D-TrIM and previous works\cite{Jouppi_21,Chen_17,Feng_24} implemented in ASIC. Number of PEs, peak throughput, area, and power are reported. Energy and area efficiency are also reported, by normalizing data to 22 nm using the DeepScaleTool\cite{Sarangi_1,Sarangi_2}. 

The architecture in \cite{Jouppi_21} refers to the Google Tensor Processing Unit (TPU) v4i. This version includes four Matrix Multiply Units (MXUs), each featuring a systolic array of $128\times128$ PEs. The architecture, running at a frequency of 1050 MHz, achieves a peak throughput of 138 TOPS. However, Google TPU v4i dissipates 175 W, thus degrading the energy efficiency metric.

Eyeriss\cite{Chen_17} is a spatial array of $12\times14$ PEs running at 200 MHz. It is based on the row-stationary dataflow, where ifmap and weights are reused at the PE level through scratch-pads. The same set of data is broadcast between PEs for parallel computations. The intense activity of scratch-pads degrades power and energy, thus limiting the efficiency of the architecture. On the contrary, 3D-TrIM uses straightforward PEs where weights are stationary, while ifmap activations move at the SA level through the triangularity of the dataflow.

The SA presented in \cite{Feng_24} consists of $16 \times 16$ PEs following the weight-stationary dataflow and running at a frequency of 2 GHz. This architecture includes a logic to cope with multi-precision computations to enhance the PE utilization, other than requiring synchronization FIFOs as dictated by the dataflow. The above requirements result in higher energy and larger area.