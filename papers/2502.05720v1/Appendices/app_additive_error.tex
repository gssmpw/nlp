\section{Additive Prediction Error}\label{appendix:additive-error}
\LowerBoundSmoothnessAdditive*

We separately prove the lower and upper bounds stated in the theorem. First, in Lemma \ref{lem:A1-smoothness-ADD}, we establish the lower bound on the performance of $\A^1_\rob$:  
\[
\frac{\A^1_\rob(\prices, \pred)}{\price} \geq \max \left( \rob, \frac{1}{\rob \ub} - \cstbeta^* \frac{\eta(\price, \pred)}{\price} \right)\;.
\]
Next, in Lemma \ref{lem:impoosibility-smoothness-ADD}, we show that $\cstbeta^*$ is the best possible constant.

\subsection{Smoothness guarantee on \texorpdfstring{$\A^1_\rob$}{A}}
We begin by proving a lemma that will be useful for establishing the smoothness of $\A^1_\rob$.

\begin{lemma}
The function $\varphi_\rob : z \mapsto \frac{\rob \ub - 1}{1-\rob} + \frac{1-\rob^2\ub}{1-\rob} \cdot \frac{z}{\rob \ub}$ satisfies for all $z$ that
\[
\varphi(z) - \rob \ub = \frac{1-\rob^2\ub}{\rob\ub - 1} (z - \varphi_\rob(z))\;.
\]
\end{lemma}

\begin{proof}\label{lem:(varphi-rub)/(y-varphi)}
This lemma can be proved with immediate computation. For all $z \in \mathbb{R}$, it holds that
\begin{align*}
z - \varphi_\rob(z)
&= z - \frac{\rob \ub - 1}{1-\rob} + \frac{1-\rob^2\ub}{1-\rob} \cdot \frac{z}{\rob \ub}\\
&= \frac{\rob \ub - \rob^2\ub = 1 + \rob^2\ub}{1-\rob} \cdot \frac{z}{\rob \ub} - \frac{\rob \ub - 1}{1-\rob}\\
&= \frac{\rob \ub - 1}{1-\rob} \left( \frac{z}{\rob \ub} - 1 \right)\;.
\end{align*}
On the other hand, we have that
\begin{align*}
\varphi_\rob(z) 
&= \frac{\rob \ub - 1}{1-\rob} + \frac{1-\rob^2\ub}{1-\rob} \cdot \frac{z}{\rob \ub} - \rob \ub\\
&= \frac{\rob\ub-1 - \rob\ub + \rob^2 \ub}{1-\rob} + \frac{1-\rob^2\ub}{1-\rob} \cdot \frac{z}{\rob \ub}\\
&= \frac{1-\rob^2\ub}{1-\rob} \left( \frac{z}{\rob \ub} - 1\right)\\
&= \frac{1-\rob^2\ub}{\rob\ub - 1} \cdot \frac{\rob\ub - 1}{1-\rob} \left( \frac{z}{\rob \ub} - 1\right)\\
&= \frac{1-\rob^2\ub}{\rob\ub - 1} \big( z - \varphi_\rob(z) \big)\;,
\end{align*}
which concludes the proof.
\end{proof}


\begin{lemma}\label{lem:A1-smoothness-ADD}
Algorithm $\A^1_\rob$ satisfies
\begin{align}
    \frac{\A^1_\rob(\prices, \pred)}{\price} \geq \max\left( \rob, \frac{1}{\rob \ub}-\cstbeta\frac{\additiveerror(\price, \pred)}{\price}\right)\,,\label{eq: [deterministic Pareto-Optimal smooth Algorithm/ THM additive smoothness] PR bound}
    \end{align}
where $\cstbeta:= \frac{1-\rob^2\ub}{\rob \ub} \max\big( \frac{1}{1-\rob}, \frac{1}{\rob \ub - 1} \big)\;$.
\end{lemma}


\begin{proof}
By Theorem \ref{thm:thresh-pareto-optimal} and by definition of $\A^1_\rob$, we have that $\A^1_\rob$ is $\rob$-robust, hence it satisfies for all $\prices \in [1,\ub]^n$ and $\pred \in [1,\ub]$ that 
$\frac{\A^1_\rob}{\price} \geq \rob$. It remains to prove the second lower bound that characterizes smoothness. We will prove it separately for $\pred \in [1,\rob \ub]$ and $\pred \in [\rob \ub, \ub]$.

\paragraph{Case 1.} For $\pred \in [1,\rob \ub]$, the acceptance threshold is $\thresh^1_\rob(\pred) = \rob \ub$. If $\price < \rob \ub$ then
\[
\frac{\A^1_\rob(\prices,\rob)}{\price} 
\geq \frac{1}{\price}
\geq \frac{1}{\rob \ub}
\geq \frac{1}{\rob \ub} - \cstbeta \frac{\eta(\price,\pred)}{\price}\;.
\]
Assume now that $\price > \rob \ub$. It holds that
\begin{equation}\label{eq:proof-additive-smoothness-y<rub<p>rub-eq1}
\frac{\A^1_\rob(\prices,\rob)}{\price} 
\geq \frac{\rob \ub}{\price}\;. 
\end{equation}
Since $\rob \ub \geq 1$, we have that $(\rob \ub)^2 \geq \rob \ub$, thus the mapping $z \mapsto \frac{z-\rob^2 \ub^2}{z-\rob \ub}$ is non-decreasing on $(\rob \ub, \ub]$, and we deduce that
\[
\cstbeta = 
\frac{1-\rob^2\ub}{\rob \ub} \max\left( \frac{1}{1-\rob}, \frac{1}{\rob \ub - 1} \right)
\geq \frac{1}{\rob \ub} \cdot \frac{1 - \rob^2\ub}{1-\rob}
= \frac{1}{\rob \ub} \cdot \frac{\ub - \rob^2\ub^2}{\ub-\rob \ub}
\geq \frac{1}{\rob \ub} \cdot \frac{\price - \rob^2\ub^2}{\price-\rob \ub}\;,
\]
and successive equivalences, recalling that $\price > \rob \ub$, show that
\begin{align*}
\cstbeta \geq \frac{1}{\rob \ub} \cdot \frac{\price - \rob^2\ub^2}{\price-\rob \ub}
&\iff \cstbeta (\price - \rob \ub) \geq \frac{1}{\rob \ub}(\price - \rob^2\ub^2)\\
&\iff \cstbeta \left(1 - \frac{\rob \ub}{\price}\right) \geq \frac{1}{\rob \ub}\left(1 - \frac{\rob^2\ub^2}{\price}\right)\\
&\iff \frac{\rob \ub}{\price} \geq \frac{1}{\rob \ub} - \cstbeta  \left(1 - \frac{\rob \ub}{\price}\right)\;.
\end{align*}
Combining this with Eq.~\eqref{eq:proof-additive-smoothness-y<rub<p>rub-eq1} and using that $\pred \leq \rob \ub$, we obtain
\[
\frac{\A^1_\rob(\prices,\rob)}{\price} 
\geq \frac{1}{\rob \ub} - \cstbeta  \left(1 - \frac{\rob \ub}{\price}\right)
\geq \frac{1}{\rob \ub} - \cstbeta  \left(1 - \frac{\pred}{\price}\right)
= \frac{1}{\rob \ub} - \cstbeta  \frac{\eta(\price, \pred)}{\price}\;.
\]

\paragraph{Case 2.} For $y \in (\rob \ub, \ub]$, the threshold is $\thresh^1_\rob(\pred) = \frac{\rob \ub - 1}{1-\rob} + \frac{1-\rob^2\ub}{1-\rob} \cdot \frac{\pred}{\rob \ub}$. 

Assume that $\price < \thresh^1_\rob(\pred)$. Since $y > \rob \ub$, using the definition of $\beta$ and Lemma \ref{lem:(varphi-rub)/(y-varphi)} yields
\[
\cstbeta 
= \frac{1-\rob^2\ub}{\rob \ub} \max\left( \frac{1}{1-\rob}, \frac{1}{\rob \ub - 1}\right)
\geq \frac{1}{\rob\ub}\cdot \frac{1-\rob^2\ub}{\rob\ub-1}
= \frac{1}{\rob\ub}\cdot \frac{\varphi_\rob(\pred)-\rob\ub}{\pred - \varphi_\rob(\pred)}\;.
\]
Using again that $\pred > \rob \ub$, we have that the mapping $z \mapsto \frac{z-\rob\ub}{y-z}$ is non-decreasing on $[1 , y]$, and given that $\pred < \thresh^1_\rob(\pred) = \varphi_\rob(\pred)$ and both $\pred$ and $\varphi_\rob(\pred)$ are within the interval $[1,\pred]$ ($\varphi(z) \leq z$ for $z \geq \rob \ub$), we deduce that
\[
\cstbeta \geq \frac{1}{\rob\ub}\cdot \frac{\price-\rob\ub}{\pred - \price}\;,
\]
and using that $\pred < \thresh^1_\rob(\pred) \leq \pred$, this is equivalent to writing
\[
\cstbeta \frac{\pred - \price}{\price} \geq \frac{1}{\rob \ub} - \frac{1}{\price}\;,
\]
Hence we have the lower-bound
\[
\frac{\A^1_\rob(\prices,\pred)}{\price} \geq \frac{1}{\price} \geq \frac{1}{\rob \ub} - \cstbeta \frac{\pred - \price}{\price}
= \frac{1}{\rob \ub} - \cstbeta \frac{\eta(\pred, \price)}{\price}\;.
\]


Assume now that $\price \in [\thresh^1_\rob(\pred), \pred)$. Since $\A^1_\rob$ is $\rob$-robust and $1/\rob\ub$-consistent, Theorem \ref{thm:thresh-pareto-optimal} shows that the threshold $\thresh^1_\rob$ satisfies $\thresh^1_\rob(z) \geq \frac{z}{\rob \ub}$ for all $z \in (\rob \ub, \ub]$, which is in particular true for $\pred$ with the current assumptions. Therefore, we obtain immediately that
\[
\frac{\A^1_\rob(\prices, \pred)}{\price} \geq \frac{\thresh^1_\rob}{\price} 
\geq \frac{1}{\rob \ub}
\geq \frac{1}{\rob \ub} - \cstbeta \frac{\eta(\price, \pred)}{\price}\;.
\]


Finally, assume that $\price \in [\pred, \ub]$. Using the expression of $\thresh^1_\rob(\pred)$, we have 
\begin{align*}
\frac{\A^1_\rob(\prices, \pred)}{\price}
&\geq \frac{\thresh^1_\rob}{\price}
= \frac{1-\rob \ub}{1-\rob} \cdot \frac{1}{\price} + \frac{1-\rob^2 \ub}{(1-\rob)\rob \ub}\cdot\frac{\pred}{\price}\\
&\geq \frac{1-\rob \ub}{1-\rob} \cdot \frac{1}{\ub} + \frac{1-\rob^2 \ub}{(1-\rob)\rob \ub}\cdot\frac{\pred}{\price}\\
&= \frac{1-\rob \ub}{1-\rob} \cdot \frac{1}{\ub} + \frac{1-\rob^2 \ub}{(1-\rob)\rob \ub} - \frac{1-\rob^2 \ub}{(1-\rob)\rob \ub}\left( 1 - \frac{\pred}{\price} \right)\\
&= \frac{1}{\rob \ub}\cdot \frac{\rob^2 - \rob + 1 - \rob^2\ub}{1-\rob} - \frac{1-\rob^2 \ub}{(1-\rob)\rob \ub}\left( 1 - \frac{\pred}{\price} \right)\\
&= \frac{1}{\rob \ub} - \frac{1-\rob^2 \ub}{(1-\rob)\rob \ub}\left( 1 - \frac{\pred}{\price} \right)\\
&\geq \frac{1}{\rob \ub} - \cstbeta \frac{\eta(\price, \pred)}{\price}\;,
\end{align*}
where we used in the last inequality that $\cstbeta:= \frac{1-\rob^2\ub}{\rob \ub} \max\big( \frac{1}{1-\rob}, \frac{1}{\rob \ub - 1} \big) \geq \frac{1-\rob^2\ub}{(1-\rob)\rob \ub}$ and that $\eta(\price, \pred) = \price - \pred$ since $\price \geq \pred$. This concludes the proof.
\end{proof}



\subsection{Lower bound on smoothness}

\begin{lemma}\label{lem:impoosibility-smoothness-ADD}
Let $\A$ be any algorithm with robustness $\rob$ and consistency $1/\rob \ub$. Suppose that $\A$ satisfies for all $\prices \in [1,\ub]^n$ and $\pred \in [1,\ub]$ that
\begin{equation}
\frac{\A(\prices, \pred)}{\price} \geq 
\max\left(
\rob, \frac{1}{\rob \ub} - \beta \frac{\eta(\price, \pred)}{\price}
\right)\;,
\end{equation}
for some $\beta \in \mathbb{R}$, then necessarily $\beta \geq \frac{1-\rob^2\ub}{\rob \ub} \max\big( \frac{1}{1-\rob}, \frac{1}{\rob \ub - 1} \big).$
\end{lemma}

\begin{proof}
Consider an algorithm $\A$ and $\beta \in \mathbb{R}$ satisfying the assumptions of the theorem. To establish the lower bound, we consider the instances $\{\instance(\qmax)\}_{\qmax \in [1,\ub]}$ as defined in Eq.~\eqref{eq:worst-case-instance}. On these instances, any deterministic algorithm is equivalent to a threshold-based algorithm. In particular, $\A$ is identical to $A_\thresh$ for some $\thresh : [1,\ub] \to [1,\ub]$.  

The assumption on $\A$ ensures that it achieves Pareto-optimal consistency $1 / (\rob \ub)$ and robustness $\rob$. Consequently, $\A_\thresh$ also attaints them on the sequences of prices $\{\instance(\qmax)\}_{\qmax \in [1,\ub]}$. These instances are precisely those used to establish the constraints on Pareto-optimal thresholds in Theorem \ref{thm:thresh-pareto-optimal}, which implies that the theoremâ€™s constraints hold for $\thresh$.  In particular, we have that $\thresh(\rob \ub) = \rob \ub$ and $\thresh(\ub) = 1/\rob$. 

Let us now prove the lower bound on $\beta$. Let $\pred = \ub$ and $\qmax_\varepsilon = \frac{\thresh(\ub)}{1+\varepsilon} < \thresh(\ub)$ for some $\varepsilon > 0$. Using Eq.~\eqref{eq:worst-case-payoff} and the assumed lower bound on $\A$, it holds that
\[
\frac{\A(\instance(\qmax_\varepsilon),\pred)}{\price}
= \frac{\A_\thresh(\instance(\qmax_\varepsilon),\pred)}{\qmax_\varepsilon}
= \frac{1}{\qmax_\varepsilon}
\geq \frac{1}{\rob \ub} - \beta \cdot \frac{\ub - \qmax_\varepsilon}{\qmax_\varepsilon}\;.
\]
Taking the limit when $\varepsilon \to 0$ and recalling that $\thresh(\ub) = 1/\rob$, we obtain that
\[
\rob 
\geq \frac{1}{\rob \ub} - \beta \cdot \frac{\ub - 1/\rob}{1/\rob}
= \frac{1}{\rob \ub} - \beta \cdot (\rob \ub - 1) \;,
\]
and it follows that
\begin{equation}\label{eq:beta-lower-bound1}
\beta 
\geq \frac{1/\rob \ub - \rob}{\rob \ub - 1}
= \frac{1 - \rob^2 \ub}{\rob \ub(\rob \ub - 1)}\;.
\end{equation}

On the other hand, for $\pred = \rob \ub$ and $\qmax = \ub$, using Eq.~\eqref{eq:worst-case-payoff}, the assumed lower bound on $\A$, and that $\thresh(\rob \ub) = \rob \ub$, we have
\[
\frac{\A_\thresh(\instance(\ub),\pred)}{\ub}
= \frac{\A_\thresh(\instance(\ub),\pred)}{\ub}
= \frac{\thresh(\rob \ub) + O(\tfrac{1}{n})}{\ub}
= \rob + O(\tfrac{1}{n})
\geq \frac{1}{\rob \ub} - \beta \cdot \frac{\ub - \rob \ub}{\ub} 
= \frac{1}{\rob \ub} - \beta (1 - \rob)\;.
\]
Taking the limit for $n \to \infty$, we obtain that
\begin{equation}\label{eq:beta-lower-bound2}
\beta 
\geq \frac{1/\rob \ub - \rob}{1 - \rob}
= \frac{1-\rob^2 \ub}{\rob \ub(1 - \rob)}.
\end{equation}
Finally, combining Equations \eqref{eq:beta-lower-bound1} and \eqref{eq:beta-lower-bound2}, we deduce that 
\[
\beta 
\geq \max \left(\frac{1 - \rob^2 \ub}{\rob \ub(\rob \ub - 1)}, \frac{1 - \rob^2 \ub}{\rob \ub(1- \rob)} \right)
= \frac{1-\rob^2\ub}{\rob\ub} \max\left( \frac{1}{\rob \ub - 1}, \frac{1}{1-\rob} \right).
\]
\end{proof}


\subsection{Comparison with prior smooth algorithms}\label{appx:comparison-with-prior-smooth} 
In \citep{benomar2025tradeoffs}, the authors introduce a randomized family $\{\tilde{\A}^\rho\}_{\rho \in [0,1]}$ of algorithms. For a fixed $\rho$, the maximum robustness that their algorithm can achieve is at most $\frac{1-e^\rho}{\rho} \ub^{-1/2}$, hence remains bounded away from $\ub^{-1/2}$. Given any robustness level $\rob \in [\ub^{-1}, \frac{1-e^\rho}{\rho} \ub^{-1/2}]$, the corresponding consistency achieved by their algorithm is  $\con = \big( \frac{1-e^\rho}{\rho} \big)^2 \frac{1}{\rob \ub}$.
This algorithm ensures smoothness in expectation with respect to the error $\eta(\price,\pred)$, i.e. that 
\[
\frac{\Eb[\tilde{\A}^\rho(\prices, \pred)]}{\price} 
\geq \left( \frac{1-e^\rho}{\rho} \right)^2 \frac{1}{\rob \ub} - \beta_\rho \frac{\eta(\price, \pred)}{\price}\;,
\]
with $\beta_\rho$ a constant proportional to $1/\rho$. The major drawbacks of this approach are that
\begin{enumerate}
    \item the achieved robustness and consistency are not Pareto-optimal, \ie they deviate from the front defined in Eq.~\eqref{eq:pareto_optimal_front},
    \item the guarantees of the algorithm only hold in expectation, since the algorithm is randomized.
\end{enumerate}


\subsection{Probabilistic analysis}\label{subapp: proba additive analysis}

\begin{corollary}\label{cor: [Stochastic bounds] additive smoothness}
    The family $\family$ satisfies
    \begin{align}
        \frac{\Eb[\algone(\Price,\Pred)]}{\Eb[\Price]}\ge \max\left\{\parr\,,\,\frac{1}{\parr\ub}-\cstbeta\frac{\Eb[\Price\additiveerror(\Price,\Pred)]}{\Eb[\Price]}\right\}\,.\label{eq: [Stochastic bounds/ THM additive smoothness] PR bound}
    \end{align}
\end{corollary}



\begin{corollary}\label{cor: [Stochastic bounds] additive smoothness OT bound}
    The family $\family$ satisfies the worst-case performance ratio bound
    \begin{align}
        \frac{\Eb[\algone(\Price,\Pred)]}{\Eb[\Price]}\ge \frac{1}{\parr\ub}-\beta\sup_{\coupling\in\couplings(\dprice,\dpred)}\frac{\int \price \additiveerror(\price,\pred)\de\coupling(\price,\pred)}{\Eb[\Price]}\,.\label{eq: [Stochastic bounds/ THM additive smoothness] PR bound 2}
    \end{align}
\end{corollary}

One can observe that the bounds of \cref{cor: [Stochastic bounds] additive smoothness OT bound} represent the supremum version of the transport problem associated with $\Wass_1$ (see below). The supremum is expected due to the additive nature of the analysis, which makes the error term a negative (additive) correction rather than a multiplicative factor. While not a classical optimal transport problem, this supremum can be transformed into an optimal transport problem with cost $(\pred,\price)\mapsto - \abs{\pred-\price}$ and one can recover (parts of) the standard theory from there, see \eg \cite{villani_optimal_2009}.

Note that the Wasserstein-$p$ distance, for $p\in[1,+\infty)$, denoted $\Wass_p$, on the space $\Ps(\range)$ of probability distributions\footnote{If $\range$ had been unbounded, $\Wass_p$ would only have been defined for distributions with a a $p\textsuperscript{th}$-moment.} over $\range$ is 
\[
    \Wass_p:(\dprice,\dpred)\mapsto\inf_{\coupling\in\couplings(\dprice,\dpred)}\int \abs{\price-\pred}^p\de\coupling(\price,\pred)\,.
\]