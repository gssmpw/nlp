\section{Introduction}\label{sec:introduction}


% MOTIVATION
 Recent and rapid advances in machine learning have provided the ability to learn complex patterns in data and time series. These advancements have given rise to a new computational paradigm, in which the algorithm designer has the capacity to incorporate a {\em prediction} oracle in the design, the theoretical analysis, and the empirical evaluation of an algorithm. The field of {\em learning-augmented} algorithms was born out of this emerging requirement to leverage ML techniques towards the development of more efficient algorithms.
 
 
 Learning-augmented algorithms have witnessed remarkable growth in recent years, starting with the seminal works~\citep{DBLP:journals/jacm/LykourisV21} and~\citep{NIPS2018_8174},
 particularly in \emph{online} decision making. In this class of problems, the input is a sequence of items, which are revealed one by one, with the algorithm making an irrevocable decision on each.
 Here, the prediction oracle provides some inherently imperfect information on the input items, which the algorithm must be able to leverage in a judicious manner.
  
One of the most challenging aspects of learning-augmented (online) algorithms is their theoretical evaluation. Unlike the prediction-free setting, in which worst-case measures such as the {\em competitive ratio}~\citep{borodin2005online} evaluate algorithms on a single metric, the analysis of learning-augmented settings is multifaceted and must incorporate the effect of the prediction {\em error} to be meaningful. Typical desiderata~\citep{DBLP:journals/jacm/LykourisV21} include: an efficient performance if the prediction is accurate ({\em consistency}); a performance that is not much worse than the competitive ratio if the predictions are arbitrarily inaccurate ({\em robustness}); and between these, a smooth decay of performance as the prediction error grows ({\em smoothness}). This marks a significant departure from the worst-case, and overly pessimistic competitive analysis, and allows for a much more nuanced and \emph{beyond worst-case} performance evaluation.

Achieving all these objectives simultaneously is a challenging task, and is even impossible for certain problems~\citep{elenter2024overcoming}. To illustrate such challenges with an example, consider the {\em \OMS{}} problem, which models a simple, yet fundamental setting in financial trading. Here, the input is a sequence of {\em prices} $(\prices_i)_{i=1}^n \in [1,\ub]$, where $\ub$ is a known upper bound, and the online algorithm (i.e., the trader) must decide, irrevocably, which price to accept. 

Under standard competitive analysis, which compares the algorithm's accepted price
to the maximum price $\price:=\max_i \prices_i$ on a worst-case instance, the problem admits a simple, yet optimal, algorithm~\citep{el-yaniv_competitive_1998}. In contrast, the learning-augmented setting, in which the algorithm has access to a prediction of $\price$, is far more complex. Specifically,~\citet{sun_pareto-optimal_2021} gave a {\em Pareto-optimal} algorithm, \ie one that achieves the best possible trade-off between consistency and robustness. However, this algorithm lacks smoothness, which results in {\em brittleness}. Namely,~\citet{benomar2025tradeoffs} showed that even if the prediction error is arbitrarily small, the algorithm's performance may degrade dramatically, and collapses to the robustness guarantee. This renders the algorithm unsuitable for any practical applications since perfect oracles do not exist in the real world. \citet{benomar2025tradeoffs} addressed the issue of brittleness by using randomization: this results in an algorithm with smoother behaviour, albeit at the cost of deviating from the consistency-robustness Pareto front. In a similar vein,~\citet{DBLP:conf/aaai/0001KZ22} gave a smooth algorithm without any guarantees on the trade-off between consistency and robustness. \citet{DBLP:conf/icml/0004HCHWB24} studied the problem under a model of uncertainty-quantified predictions, in which the algorithm has access to additional, and more powerful, probabilistic information about the prediction error. 

The following natural question arises: 
%Can we find an all-around Pareto-optimal algorithm for \OMS{} that guarantees smoothness, and does not rely on randomization or stochastic assumptions about the prediction?
{\em is there an all-around optimal algorithm, that is simultaneously Pareto-optimal and smooth, and does not rely on randomisation or probabilistic assumptions about the quality of the prediction?} 



\subsection{Main contributions}

Our main result answers the above question in the affirmative by giving a deterministic Pareto-optimal algorithm with smooth guarantees. Furthermore, we demonstrate how to leverage smoothness so as to extend this analysis to stochastic settings in which the input and  prediction are random.

In previous works on learning-augmented \OMS{}~\citep{sun_pareto-optimal_2021, benomar2025tradeoffs}, the proposed algorithms select the first price that exceeds a {\em threshold} $\thresh(\pred)$, which is a function of the prediction $\pred$ of the maximum price $\price$ in the sequence.
We revisit the problem by first characterizing the class $\SPO$ of all consistency-robustness Pareto-optimal thresholds $\thresh$. 
%\lst{that achieve an optimal trade-off between consistency and robustness, where $\theta$ is a known upper bound on $\price$}. 
%\ltodo{SA: Here we talk about consistency-robustness thresholds, is it obvious what we mean? ZB: We mentioned before what is a Pareto-optimal algorithm (when we cited Sun et al in th intro), + the reviewers will very probably be familiar with learning-augmented algorithms.} 
%Also we need to explain what $\theta$ is since we have not introduced it yet.}
Next, we focus on a specific family of Pareto-optimal thresholds within $\SPO$ which generalise the algorithm of \citet{sun_pareto-optimal_2021} but also exhibit smoothness guarantees. In particular, our analysis quantifies smoothness in this family, showing it to be inversely proportional to the maximal slope of the corresponding threshold. Guided by this insight, we find the threshold that maximizes smoothness within the class
$\SPO$.

%We use two different measures to quantify the prediction error. The first one is $\eta(\price,\pred) = |\price - \pred|$ and the second is $\error(\price, \pred) = \min(\frac{\price}{\pred}, \frac{\pred}{\price})$.


Furthermore, this quantification of smoothness allows to establish a near-matching lower bound. Specifically, we show that, for a multiplicative definition of the error, no Pareto-optimal algorithm can guarantee better smoothness than our algorithm, for a large range of robustness values. For the additive definition of the prediction error, which is commonly used, we show that our algorithm optimises smoothness for all robustness values, thus attaining the  {\em triple} Pareto front of consistency, robustness and smoothness.



%at least for the regimes in which the robustness $\rob$ is in $[\ub^{-1}, \ub^{-2/3}]$. Note that by the specifications of the problem, the robustness of any algorithm lies in the interval $[\ub^{-1},\ub]$. 



The combination of smoothness and Pareto-optimality of our family of thresholds has direct practical benefits in handling the real-world uncertainty of predictions. When predictions and prices are both tied to a random environment (\eg a financial market), we show how to derive general form bounds in expectation as a function of the distributions of predictions and prices and, for the first time, of their \emph{coupling}. We provide prediction-quality metrics which help us better capture the notion of the ``usefulness'' of a prediction in stochastic environments and give detailed bounds on concrete settings. We also provide a general framework of analysis based on optimal transport.
%\stodo{SA:There is a disconnect between the well-detailed contribution for the deterministic result and the one for the stochastic result}\ltodo{+1}.

%\lc{Unlike prior work, our algorithmic family and analysis method allows us to use inherently uncertain predictions, for which this is a simple model. Prior work requires ad-hoc modifications (such as using the worst-case prediction from $\dpred$), our algorithm functions as-is and its analysis reveals rich performance estimates directly depending on the parameters of $\dpred$. }
%\ltodo{this par didn't fit in the main text, it should fit better in the intro or ccl, so I moved it here}

We validate our theoretical results through numerical experiments, in which we compare our algorithm to the state of the art, by testing it under both synthetic and real data. 
%\stodo{ZB: I am still working on simulations with real data, but not sure I'll have nice plots to include in the paper. I'll let you know in both cases}


\subsection{Related work}
\paragraph{Learning-augmented algorithms.}

Algorithms with predictions have been studied in a large variety of online problems, such as rent-and-buy problems~\citep{DBLP:conf/icml/GollapudiP19}, 
scheduling~\citep{lattanzi2020online}, caching~\citep{DBLP:journals/jacm/LykourisV21}, matching~\citep{antoniadis2020secretary}, packing~\citep{im2021online}, covering~\citep{bamas2020primal} and secretaries~\citet{dutting2024secretaries}. This paradigm also has applications beyond online computation, and has been used to improve the runtime of algorithms for classical problems such as sorting~\citep{bai2023sorting} and graph problems~\citep{azar2022online}, as well as for the design of data structures such as search trees~\citep{lin2022learning},  dictionaries~\citep{DBLP:conf/icml/ZeynaliKH24}, and priority queues \citep{benomar2024learning}. We emphasize that the above lists only some representative works, and we refer to the online repository of~\citet{predictionslist}.


\paragraph{Pareto-optimal algorithms.}
Several studies have focused on consistency-robustness trade-offs in learning-augmented algorithms, \eg~\citep{sun_pareto-optimal_2021,wei2020optimal,DBLP:conf/eenergy/Lee0HL24,DBLP:journals/iandc/Angelopoulos23,bamas2020primal,DBLP:conf/aistats/ChristiansonSW23,almanza2021online}. However, Pareto-optimality imposes constraints which may, in certain cases, compromise smoothness. The brittleness of Pareto-optimal algorithms for problems such as one-way trading was observed by~\citet{elenter2024overcoming}, who proposed a user-defined approach to smoothness, and by~\citet{benomar2025tradeoffs} who relied on randomization. These approaches differ from ours, in that the profile-based framework of~\citet{elenter2024overcoming} does not always lead to an objective and measurable notion of consistency. Moreover, we show that randomization is not necessary to achieve Pareto optimality. 

\paragraph{One-Max Search.} 
\citet{el-yaniv_competitive_1998} showed that the optimal competitive ratio of (deterministic) \OMS{} is $1/\sqrt{\ub}$, under the assumption that each price in the sequence is in $[1,\ub]$, where $\ub$ is a known upper bound on $\price$. This assumption is required in order to achieve a bounded competitive ratio and has remained in all subsequent works on learning-augmented algorithms for this problem, such as~\citep{sun_pareto-optimal_2021,DBLP:conf/aaai/0001KZ22,DBLP:conf/icml/0004HCHWB24, benomar2025tradeoffs}.
The randomized version of \OMS{} is equivalent to the {\em one-way trading} problem, in which the trader can sell fractional amounts. The optimal competitive ratio, for this problem, is $O(1/\log \ub)$~\citep{el-yaniv_competitive_1998}. Pareto-optimal algorithms for one-way trading were given by~\citet{sun_pareto-optimal_2021}, however~\citet{elenter2024overcoming} showed that any Pareto-optimal algorithm for this problem is brittle and thus cannot guarantee smoothness. One-max-search and one-way trading model fundamental settings of trading, and many variants and generalizations have been studied under the competitive ratio, see the survey~\citep{mohr2014online}. One must note that worst-case measures such as the competitive ratio aim to model settings in which no Bayesian assumptions are known to the algorithm designer. There is a very rich literature on optimal Bayesian search, see, 
\eg~\citep{rosenfield1981optimal}.







