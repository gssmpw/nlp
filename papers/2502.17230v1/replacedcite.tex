\section{Related Work}
\label{sec:related_work}

%========================================================================

\subsection{Fractals}
\label{sec:fractals}

Fractals are complex geometric patterns that repeat infinitely at different scales, revealing self-similarity through recursive or iterative processes____.
Fractal geometry is not only crucial in many scientific disciplines____, but it has also been applied to the study of natural images____ and visual art____, and is an indispensable tool for synthetic scene creation____.

A wide variety of algorithms for creating fractals and self-similarities exists. 
Grammar-based techniques use formal rules to iteratively generate complex structures____ with diverse applications____.
Noise-based approaches combine random functions at different scales____.
Escape-time algorithms generate fractals by iterating a function at each point until it escapes a boundary____.
Furthermore, self-similarity can be achieved by tiling____.
We build our approach on Iterated Function Systems, which generate fractals by repeatedly applying a set of geometric transformations____.
This method, which we review in \refSec{background}, is well-suited for point-based rendering____ and has recently been shown to combine effectively with other fractal generation paradigms____.

Fractals have also been studied in 3D____, where efficient rendering is crucial____. 
Similarly, our optimization scheme relies on efficient synthesis and rendering to produce high-quality fractal images -- a property we found essential for achieving state-of-the-art inversions.

Our approach incorporates a deep differentiable pipeline. 
Fractals have been integrated into deep learning in various ways, such as through self-similar architectures____, reframing computations as neural networks____, deep equilibrium models____, and training data augmentation____.

%========================================================================

\subsection{Fractal Inversion and Procedural Modeling}
\label{sec:fractal_inversion}

Obtaining fractal codes from an image is a notably intricate process____. 
Since direct methods are only feasible for simple synthetic cases____, the task is generally formulated as an optimization problem.
Stochastic techniques have been explored to address the highly non-convex energy landscapes involved.
These include evolutionary algorithms optimizing the fractal code directly____, a partitioning of the fractal____, or a polar reparameterization____.
Similarly, swarm intelligence algorithms solve the problem by modeling stochastic natural processes____.
Additionally, quadratic programming____ and expectation maximization____ have been applied to solve this task.

In a separate line of research, gradient-based approaches have been explored____. 
Differentiability has been achieved by using point set distances____, moments____, signed distance functions____, and, recently, differentiable point splatting____. Additionally, experiments have been conducted on directly regressing fractal codes using neural networks____.
The approach most similar to ours is that of Tu~\etal____. However, unlike their focus on representing low-resolution images with points arising from an Iterated Function System, we aim to recover infinite-resolution fractal structures.
To achieve this, we utilize high-quality renderings produced by an efficient forward model, along with a hybrid optimization framework to prevent getting stuck in local minima.

In addition to applications in data compression____ and symmetry detection____, discovering self-similarities has also been studied as a powerful tool for generative modeling____.
Inverse procedural generative models have been studied in various forms, including tiling____, noise models____, handcrafted spatial patterns____, handcrafted material-specific procedures____, and both fixed____ and learnable____ procedural node graphs. However, to our knowledge, little to no inverse procedural models generate details at infinite scales, thus most of them lose detail when magnifying way past the scale of the reference image.
In contrast, in our work we learn a generative model that automatically extrapolates the target structure from a single scale to infinitely finer scales, constituting a significant advantage for infinite-resolution image synthesis.

%========================================================================

\subsection{Multiscale Image Representation and Reconstruction}
\label{sec:multiscale}

Representing, synthesizing, and reconstructing images at multiple scales is a fundamental task in computer graphics and computer vision. 

Coarser representations of an image can be formalized using linear scale-space theory____ and efficiently implemented using pyramids____. 
In recent years, neural multiscale representations have gained significant attention____.
In contrast to our approach, all these approaches assume that a maximum resolution exists and a corresponding image is available.
However, we leverage image pyramids as part of our multiscale supervision structure.

The reverse task, inferring finer-scale images from coarser ones, is an active area of research in the super-resolution community.
For an overview, we refer to a recent survey____.
Similar to our setting, the internal statistics of an image in the form of recurring patches has been studied____ to increase resolution____, remove blur____, or synthesize new layouts____.
Unlike these methods, we model self-similarity using analytic functions.
This results in a narrower application domain, but enables image synthesis without scale limits.

Another approach to obtaining a multiscale representation is to fuse images from different scales. 
This is often done with an understanding of how the source images are related to each other____, but unstructured image collections have also been explored____.
In contrast, our approach takes a single image as input and infers generative rules to synthesize infinite-resolution details.


%========================================================================


\subsection{Point Splatting}
\label{sec:point_splatting}

Point-based rendering has a long and rich history____. 
Early work focused on efficient hardware-accelerated point samples____, while advancements in ``splatting'' reconstruction kernels, such as EWA____, enabled high-quality image synthesis free from aliasing. 
The emergence of differentiable visual computing____ has further advanced this field, with soft reconstruction kernels facilitating the solution of inverse problems through differentiable point splatting____. 
A notably efficient implementation of this approach is 3D Gaussian Splatting (3DGS)____, which marks the current state of the art in scene reconstruction from images. 
We adapt their splatting framework to recover 2D fractals and pair it with a stochastic optimization routine.

Similar to our work, 3DGS-based reconstruction has been treated as a stochastic process____, akin to Stochastic Gradient Langevin Dynamics____. 
However, we demonstrate that mere gradient perturbations are insufficient to obtain high-quality fractal inversions.


%========================================================================
%========================================================================