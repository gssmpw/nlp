\section{Related Work}
\label{sec:related_work}

%========================================================================

\subsection{Fractals}
\label{sec:fractals}

Fractals are complex geometric patterns that repeat infinitely at different scales, revealing self-similarity through recursive or iterative processes~\cite{mandelbrot1980fractal,mandelbrot1982fractal,peitgen2004chaos}.
Fractal geometry is not only crucial in many scientific disciplines~\cite{havlin1995fractals,turcotte1997fractals,song2005self,mandelbrot2013fractals}, but it has also been applied to the study of natural images~\cite{pentlandfractal1984, Turiel_2000} and visual art~\cite{redies2008fractal-like}, and is an indispensable tool for synthetic scene creation~\cite{demko1985construction,barnsley1988harnessing,ebert2002texturing,tzathas2024physically}.

A wide variety of algorithms for creating fractals and self-similarities exists. 
Grammar-based techniques use formal rules to iteratively generate complex structures~\cite{lindenmayer1968mathematical,rozenberg1980mathematical} with diverse applications~\cite{shlyakhter2001reconstructing,wonka2003instant,prusinkiewicz2012algorithmic}.
Noise-based approaches combine random functions at different scales~\cite{mandelbrot1968fractional,keshner19821}.
Escape-time algorithms generate fractals by iterating a function at each point until it escapes a boundary~\cite{mandelbrot2004fractals,julia1918memoire}.
Furthermore, self-similarity can be achieved by tiling~\cite{bandt1991self,fathauer2001fractal,ouyang2021self,chen2022learning}.
We build our approach on Iterated Function Systems, which generate fractals by repeatedly applying a set of geometric transformations~\cite{hutchinson1981fractals,barnsley1985iterated,barnsley1988fractals,elton1987ergodic}.
This method, which we review in \refSec{background}, is well-suited for point-based rendering~\cite{tu2023learning,bannister2024learnable} and has recently been shown to combine effectively with other fractal generation paradigms~\cite{schor2024into}.

Fractals have also been studied in 3D~\cite{hart1989ray,norton1982generation}, where efficient rendering is crucial~\cite{carpentercomputer1980,hart1991efficient,MARTYN2010167,daSilva2021}. 
Similarly, our optimization scheme relies on efficient synthesis and rendering to produce high-quality fractal images -- a property we found essential for achieving state-of-the-art inversions.

Our approach incorporates a deep differentiable pipeline. 
Fractals have been integrated into deep learning in various ways, such as through self-similar architectures~\cite{li2019lightweight}, reframing computations as neural networks~\cite{stark1991iterated}, deep equilibrium models~\cite{bai2019deep}, and training data augmentation~\cite{kataoka2020pre,anderson2022improving}.

%========================================================================

\subsection{Fractal Inversion and Procedural Modeling}
\label{sec:fractal_inversion}

Obtaining fractal codes from an image is a notably intricate process~\cite{barnsley1986solution,barnsley1988fractals,Vrscay1991}. 
Since direct methods are only feasible for simple synthetic cases~\cite{berkner1997wavelet,struzik1994solution}, the task is generally formulated as an optimization problem.
Stochastic techniques have been explored to address the highly non-convex energy landscapes involved.
These include evolutionary algorithms optimizing the fractal code directly~\cite{jacques1993optimization,nettleton1994evolutionary,lankhorst1995iterated,gutierrez2000hybrid}, a partitioning of the fractal~\cite{sarafopoulos2006resolution}, or a polar reparameterization~\cite{collet2000polar}.
Similarly, swarm intelligence algorithms solve the problem by modeling stochastic natural processes~\cite{quirce2017cuckoo,galvez2018modified,galvez2021modified}.
Additionally, quadratic programming~\cite{ForteSolving1994} and expectation maximization~\cite{bloem2017expectation} have been applied to solve this task.

In a separate line of research, gradient-based approaches have been explored~\cite{vrscay1999can}. 
Differentiability has been achieved by using point set distances~\cite{melnik1998gradient}, moments~\cite{vrscay1989iterated,rinaldo1994inverse}, signed distance functions~\cite{kim2015quaternion}, and, recently, differentiable point splatting~\cite{tu2023learning,bannister2024learnable,scott2024differentiable}. Additionally, experiments have been conducted on directly regressing fractal codes using neural networks~\cite{grahamapplying2021}.
The approach most similar to ours is that of Tu~\etal~\cite{tu2023learning}. However, unlike their focus on representing low-resolution images with points arising from an Iterated Function System, we aim to recover infinite-resolution fractal structures.
To achieve this, we utilize high-quality renderings produced by an efficient forward model, along with a hybrid optimization framework to prevent getting stuck in local minima.

In addition to applications in data compression~\cite{jacquinimage1992,barnsley1993fractal, fisher1994fractal} and symmetry detection~\cite{liu2010computational,lukavc2017nautilus}, discovering self-similarities has also been studied as a powerful tool for generative modeling~\cite{poli2022self,karnewar3ingan2022,zhang2023rose,merrell2023example}.
Inverse procedural generative models have been studied in various forms, including tiling~\cite{vanhoey2013fly}, noise models~\cite{gilet2014local,heitz2018high}, handcrafted spatial patterns~\cite{LP-gi2000}, handcrafted material-specific procedures~\cite{guo2020bayesian}, and both fixed~\cite{hu2019novel,shi2020match} and learnable~\cite{hu2022inverse} procedural node graphs. However, to our knowledge, little to no inverse procedural models generate details at infinite scales, thus most of them lose detail when magnifying way past the scale of the reference image.
In contrast, in our work we learn a generative model that automatically extrapolates the target structure from a single scale to infinitely finer scales, constituting a significant advantage for infinite-resolution image synthesis.

%========================================================================

\subsection{Multiscale Image Representation and Reconstruction}
\label{sec:multiscale}

Representing, synthesizing, and reconstructing images at multiple scales is a fundamental task in computer graphics and computer vision. 

Coarser representations of an image can be formalized using linear scale-space theory~\cite{iijima1959basic, witkin1987scale} and efficiently implemented using pyramids~\cite{burt1981fast, williams1983pyramidal}. 
In recent years, neural multiscale representations have gained significant attention~\cite{fathony2020multiplicative, chen2021learning, paz2022multiresolution, lindell2022bacon, saragadam2022miner, mueller2022instant, Belhe2023Discontinuity, mujkanovic2024ngssf}.
In contrast to our approach, all these approaches assume that a maximum resolution exists and a corresponding image is available.
However, we leverage image pyramids as part of our multiscale supervision structure.

The reverse task, inferring finer-scale images from coarser ones, is an active area of research in the super-resolution community.
For an overview, we refer to a recent survey~\cite{superresSurvey2023}.
Similar to our setting, the internal statistics of an image in the form of recurring patches has been studied~\cite{shechtman2007matching,zontak2011internal} to increase resolution~\cite{glasner2009super,ZSSR2018,bell2019blind}, remove blur~\cite{michaeli2014blind}, or synthesize new layouts~\cite{shaham2019singan,shocher2019ingan,zhou2018non}.
Unlike these methods, we model self-similarity using analytic functions.
This results in a narrower application domain, but enables image synthesis without scale limits.

Another approach to obtaining a multiscale representation is to fuse images from different scales. 
This is often done with an understanding of how the source images are related to each other~\cite{klashed2010uniview, halladjian2019scale, mohammed2017abstractocyte, tao2019kyrix, licorish2021adaptive}, but unstructured image collections have also been explored~\cite{wolski2024scalespacegan}.
In contrast, our approach takes a single image as input and infers generative rules to synthesize infinite-resolution details.


%========================================================================


\subsection{Point Splatting}
\label{sec:point_splatting}

Point-based rendering has a long and rich history~\cite{gross2011point}. 
Early work focused on efficient hardware-accelerated point samples~\cite{grossman1998point}, while advancements in ``splatting'' reconstruction kernels, such as EWA~\cite{zwicker2001surface}, enabled high-quality image synthesis free from aliasing. 
The emergence of differentiable visual computing~\cite{li2019differentiable,spielberg2023differentiable} has further advanced this field, with soft reconstruction kernels facilitating the solution of inverse problems through differentiable point splatting~\cite{wiles2020synsin, yifan2019differentiable, lassner2021pulsar}. 
A notably efficient implementation of this approach is 3D Gaussian Splatting (3DGS)~\cite{kerbl20233d}, which marks the current state of the art in scene reconstruction from images. 
We adapt their splatting framework to recover 2D fractals and pair it with a stochastic optimization routine.

Similar to our work, 3DGS-based reconstruction has been treated as a stochastic process~\cite{kheradmand20243d}, akin to Stochastic Gradient Langevin Dynamics~\cite{brosse2018promises}. 
However, we demonstrate that mere gradient perturbations are insufficient to obtain high-quality fractal inversions.


%========================================================================
%========================================================================