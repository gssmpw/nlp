\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{caption}
\usepackage{array}
\usepackage[numbers,sort&compress]{natbib}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{TransformDAS: Mapping $\Phi$-OTDR Signals to Riemannian Manifold for Robust Classification}

\author{\IEEEauthorblockN{Jiaju Kang\textsuperscript{1,2} \quad Puyu Han\textsuperscript{1,3}   \quad Yang Chun\textsuperscript{1} \quad Xu Wang\textsuperscript{6}\quad Luqi Gong\textsuperscript{4,5}\thanks{*Corresponding author: luqi@zhejianglab.com}}

% \IEEEauthorblockA{\textsuperscript{1} Beijing Normal University \hspace{4mm} \textsuperscript{2} Southern University of Science and Technology} \hspace{4mm} \textsuperscript{3} Research Center for Space Computing System, Zhejiang Lab \hspace{4mm} \\ \textsuperscript{4} School of Computer Science, Beijing University of Posts and Telecommunications}

\IEEEauthorblockA{\textsuperscript{1} FUXI AI Lab\hspace{4mm} \textsuperscript{2} Beijing Normal University \hspace{4mm} \textsuperscript{3} Southern University of Science and Technology} \hspace{4mm} \textsuperscript{4} Zhejiang Lab \hspace{4mm} \textsuperscript{5} Beijing University of Posts and Telecommunications \hspace{4mm} \textsuperscript{5} Shandong Jianzhu University}

\maketitle

\begin{abstract} 
Phase-sensitive optical time-domain reflectometry ($\Phi$-OTDR) is a widely used distributed fiber optic sensing system in engineering. Machine learning algorithms for $\Phi$-OTDR event classification require high volumes and quality of datasets; however, high-quality datasets are currently extremely scarce in the field, leading to a lack of robustness in models, which is manifested by higher false alarm rates in real-world scenarios. One promising approach to address this issue is to augment existing data using generative models combined with a small amount of real-world data. We explored mapping both $\Phi$-OTDR features in a GAN-based generative pipeline and signal features in a Transformer classifier to hyperbolic space to seek more effective model generalization. The results indicate that state-of-the-art models exhibit stronger generalization performance and lower false alarm rates in real-world scenarios when trained on augmented datasets. TransformDAS, in particular, demonstrates the best classification performance, highlighting the benefits of Riemannian manifold mapping in $\Phi$-OTDR data generation and model classification.
\end{abstract}

\begin{IEEEkeywords}
Distributed Acoustic Sensing, Phase-Sensitive Optical Time-Domain Reflectometer, $\Phi$-OTDR Event Classification, Data Augmentation, Riemannian Manifold, TransformDAS Model
\end{IEEEkeywords}

\section{Introduction}
Distributed Acoustic Sensing (DAS) leverages the integrated sensing and transmission capabilities of optical fibers to achieve critical physical measurements over long distances and wide areas. As a representative of distributed fiber optic sensing systems, $\Phi$-OTDR is widely applied in key areas such as urban underground pipeline monitoring and rail safety, due to its high sensitivity and rapid response\cite{b1,b2,b3,b4}. With the continuous development of artificial intelligence, the performance of $\Phi$-OTDR event classification models has improved steadily in recent years\cite{b5}.

The increasing complexity of industrial scenarios and growing data volumes present new challenges for automated $\Phi$-OTDR event classification. Despite more resources, the development of high-performance deep learning models is constrained by two key limitations: data representation and feature extraction\cite{b6}. Traditional one-dimensional signal-based algorithms fail to learn from the entire data field and struggle with noise in event classification tasks. Spatiotemporal models, although leveraging global sequence modeling, are incompatible with diverse data formats. Due to limited and complex industrial datasets, pre-augmentation is often necessary during training\cite{b7}. However, many high-performance pre-trained models perform poorly on industrial test sets, with limited generalization due to their reliance on specific data structures and fixed denoising methods that cannot adapt to changing scenarios. By deeply analyzing the relationship between training data structures and representations, combined with deep learning approaches\cite{b6,b7,b8}, we can mitigate these limitations. Generative augmentation methods, utilizing the data's implicit space, can improve classification performance and reduce false alarm rates in $\Phi$-OTDR systems.

In this paper, we reduce $\Phi$-OTDR event classification to two key tasks: data augmentation for laboratory datasets and high-dimensional data representation learning. Under practical circumstances, the sensing data of $\Phi$-OTDR systems are high-dimensional time series with strong dependencies. To handle such high-dimensional data, we propose a Riemannian manifold-based data augmentation method for $\Phi$-OTDR data and a complete development process for industrial event classification models\cite{b9,b10}. We construct the TransformDAS model as a representative, and experiments demonstrate that this model exhibits better training stability and the highest accuracy in real-world industrial environments.

\begin{itemize}
\item A method for high-dimensional data augmentation is developed to ensure the generalization ability of classification models based on the specificities of $\Phi$-OTDR data and actual engineering needs.
\item Emphasis is placed on learning the implicit space information of data, quantifying its influence on model classification decisions.
\item A TransformDAS model is proposed based on the transformer framework to handle high-dimensional, time-series data with strong dependencies.
\item Quantitative experiments demonstrate the effectiveness of the proposed method, enabling models to easily address the recognition and classification tasks of six typical intrusion events and related mixed events in the DAS domain.
\end{itemize}

\section{Approach}

\subsection{Problem Definition}

In industrial intrusion event detection, classification models identify various events—such as human and vehicle intrusions or excavation activities—by analyzing continuous spatio-temporal signal data from fiber optic sensors. These events exhibit unique frequency, amplitude, and temporal patterns, necessitating models that effectively learn and classify these physical properties for high-precision outcomes. Challenges include distinguishing genuine signals from complex noise caused by environmental factors (e.g., wind, rain) and system noise, which impacts the model's robustness. Standard performance metrics for evaluation include Accuracy, Precision, Recall, and F1 Score \cite{b16}.

\subsection{Learning High-Dimensional $\Phi$-OTDR Data Based on Riemannian Manifold}

High-dimensional spatio-temporal data from $\Phi$-OTDR presents complex geometric structures. Riemannian manifold theory offers a robust approach to capture these intrinsic attributes, enhancing feature representation for complex signal analysis and classification. Augmenting $\Phi$-OTDR data within the Riemannian framework ensures that samples remain on the data manifold, mitigating information loss and effectively handling high-dimensional datasets. Although theoretical guarantees for Riemannian manifold-based augmentation are less strict, this method extends well to high-dimensional data \cite{b11,b12,b13,b14}.

Steps include defining counterfactuals in the $\Phi$-OTDR data context. For a classifier with probability \(\phi(x)\), counterfactuals provide minimal perturbations to alter predictions. The input space is modeled as a lower-dimensional submanifold of \(\mathbb{R}^n\), with $\Phi$-OTDR data concentrated in a small region \(\mathcal{U}\) around \(\mathcal{D}\). This implies that the data density support forms a product manifold.


We define the set of points in \(\mathcal{U}\) classified with confidence \(\eta\) as the category \(y\):

\[
\mathcal{M}_{\eta,y} = \{x \in \mathcal{U} \mid \phi(x) = y, \; P(y \mid x) \geq \eta\}.
\]

The counterfactual of the original sample is then the closest point in \(\mathcal{M}_{\eta,y}\):

\[
x^* = \arg \min_{z \in \mathcal{M}_{\eta,y}} d_{\mathcal{M}}(x, z),
\]

where \(d_{\mathcal{M}}\) is the distance computed on \(\mathcal{M}\) with the Riemannian metric induced by the diffeomorphism provided by the generative model. We use a generative adversarial network (GAN)-based method to approximate the diffeomorphism for generating counterfactuals\cite{b15}. We model the mapping using normalizing flows, and we refer to the modified data as approximate diffeomorphic counterfactuals. A flow is an invertible neural network that provides a probability density on the input space by the change of variable theorem:

\[
p_X(x) = p_Z(f(x)) \left| \det \frac{\partial f}{\partial x} \right|^{-1},
\]

where \(p_Z\) is a simple base density in the latent space. GANs consist of a generator and a discriminator trained by minimizing a specific minimax loss function:

\[
\min_G \max_D \mathbb{E}_{x \sim p_\text{data}} [\log D(x)] + \mathbb{E}_{z \sim p_z} [\log(1 - D(G(z)))].
\]

The global minimum of this loss function ensures that the optimal generator’s samples are distributed according to the data distribution, i.e.,

\[
p_\text{data} = p_G.
\]

This approach ensures that a well-trained flow (approximately) maps only to the data manifold, allowing for gradient ascent in the latent space:

\[
z_{t+1} = z_t + \alpha \nabla_z f(z_t),
\]

where \(\alpha\) is the step size, enabling the generation of high-quality $\Phi$-OTDR data counterfactuals without losing information.


\subsection{TransformDAS}

When addressing $\Phi$-OTDR pattern recognition in complex industrial settings, the long-sequence and highly dependent nature of $\Phi$-OTDR signals necessitates both comprehensive and localized learning of data features, with continuous attention to internal relationships and variations. To address these needs, a transformer-based model is essential.

TransformDAS is designed to leverage hyperbolic geometric space properties to efficiently represent hierarchical or tree-structured data\cite{b10}. This design is particularly effective for tasks requiring the preservation of complex relationships in a low-dimensional space. The model's key innovation is the incorporation of Möbius matrix-vector multiplication and Möbius addition, which maintain geometric invariance in hyperbolic space. This approach overcomes the limitations of traditional Euclidean space for high-dimensional data embedding. Additionally, TransformDAS features a curvature parameter \(c\) that allows flexible adjustment of the embedded space's geometric structure, enhancing its generalization capabilities across various tasks.


We leverage the hyperbolic geometry of Riemannian manifolds to enhance the expressiveness of data embeddings and the attention mechanism. First, we employ \textbf{Möbius matrix-vector multiplication}, which is defined as:

\[
\mathbf{M}(m, x, c) = \frac{\tanh \left( \frac{\| mx \|}{\| x \|} \cdot \text{atanh} \left( \sqrt{c} \cdot \| x \| \right) \right) \cdot mx}{\| mx \|},
\]

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{duibi.pdf}
    \caption{Comparison of Möbius and Euclidean operations in the Poincaré disk model. The left subplot illustrates Möbius addition (blue) and Euclidean addition (magenta), showing that Möbius addition preserves hyperbolic geometry while Euclidean addition may lead to distortions outside the disk. The right subplot highlights the same behavior for Möbius matrix-vector multiplication versus Euclidean multiplication, with Möbius operations maintaining the integrity of the hyperbolic space.}
    \label{fig6}
\end{figure}

to map the input data \(x\) into the hyperbolic space and integrate it with the conditional data. To effectively fuse the signal and conditional data, we use \textbf{Möbius addition}, defined as:

\[
\mathbf{A}(x, y, c) = \frac{(1 + 2c \cdot \langle x, y \rangle + c \cdot \| y \|^2) \cdot x + (1 - c \cdot \| x \|^2) \cdot y}{1 + 2c \cdot \langle x, y \rangle + c^2 \cdot \| x \|^2 \cdot \| y \|^2}.
\]

In the attention mechanism, we compute the similarity between queries and keys in hyperbolic space:

\[
\mathbf{C} = \frac{q \cdot k^T}{\| q \| \cdot \| k \|},
\]

and map this into the hyperbolic space by computing the input:

\[
\mathbf{H}_{\text{input}} = 1 + c \cdot (\mathbf{C} - 1).
\]

Then, we compute the final attention scores using the hyperbolic arccosine function:

\[
\mathbf{H} = \text{acosh}(\text{clamp}(\mathbf{H}_{\text{input}}, \text{min}=1.0)),
\]

and obtain the attention weights with a softmax function \(\mathbf{W} = \text{softmax}(-\mathbf{H})\), completing the attention computation in hyperbolic space.

These hyperbolic geometry-based operations enable the model to better capture complex non-linear relationships between data, improving performance in both generation and classification tasks.

\section{Experimental Design}

We conduct a series of experiments to evaluate the performance of the proposed TransformDAS model. All experiments are performed on a single NVIDIA A100 GPU to ensure consistent computational conditions.

\subsection{Dataset and Preprocessing} The experimental dataset, sourced from Beijing Jiaotong University, comprises six types of $\Phi$-OTDR events: background noise, digging, knocking, shaking, watering, and walking, totaling 15,419 samples \cite{b16}. To enhance model robustness, we augmented this dataset using a Riemannian manifold-based GAN architecture, generating an additional 20,000 samples per event category.

In this study, we utilized a real-world industrial dataset featuring six event categories: impact hammer, knocking, percussion drill, large-scale excavator, subway, and engine idle, with 1,500 samples selected from each category. The data was collected through a custom-built $\Phi$-OTDR-based fiber-optic sensing system equipped with an NKT BASIK E15 laser (1550.12 nm wavelength) and amplified by an Erbium-doped fiber amplifier (EDFA). The optical signal was modulated through an acousto-optic modulator (AOM) to generate repetitive pulse signals, which were then injected into a 50 km Corning SM28e+ single-mode fiber (G.652.D compliant) sensing cable directly connected to terminal equipment. The system employed FC/APC connectors for optimal coupling stability and used a photodetector (PD) to convert Rayleigh backscatter signals into electrical signals captured by a data acquisition card (DAQ) at 10 MS/s sampling rate. Data collection spanned metro construction and gas pipeline monitoring scenarios, with manual calibration ensuring proper temporal-spatial registration. The acquired signals were subsequently transferred to a computational backend for storage and analysis.


\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{shuju.pdf}
    \caption{This figure illustrates the process of dataset augmentation through manifold learning. It initiates by embedding 10×10240 time series data into a low-dimensional manifold (EDHLDM). The next step generates augmented data in low-dimensional prevalent spaces (DGILPS) through local neighborhood selection, interpolation, and random perturbation. Finally, the augmented data is mapped back to high-dimensional space (MLSBTH) with curvature adjustments for enhanced accuracy and representation.}
    \label{fig6}
\end{figure}

\subsection{Baselines and Comparative Methods} To benchmark TransformDAS, we compare it against several baselines: \begin{itemize} \item \textbf{Traditional $\Phi$-OTDR Classifiers:} Includes classic machine learning models like SVM and Random Forest trained on raw signal data. \item \textbf{Deep Learning Models:} Includes end-to-end CNN and Transformer models trained on spatiotemporal data. \item \textbf{Generative Models:} Evaluates the impact of data augmentation by comparing results from GAN-based augmentation to standard data augmentation techniques. \end{itemize}

\begin{table*}[t]
\centering
\caption{Classification Performance on Industrial Dataset. The table reports Precision / Recall / F1 Score for each model across different event types.}
\renewcommand{\arraystretch}{1.2} % Adjust row spacing
\resizebox{1\linewidth}{!}{
\begin{tabular}{c|c|c|c|c|c|c}
\hline
\textbf{Model} & \textbf{Impact Hammer} & \textbf{Knocking} & \textbf{Percussion Drill} & \textbf{Large Excavator} & \textbf{Subway} & \textbf{Engine Idle} \\
\hline
SVM & 39.2 / 38.4 / 38.7 & 34.7 / 34.2 / 34.5 & 36.5 / 36.0 / 36.2 & 31.8 / 31.2 / 31.4 & 33.3 / 32.9 / 33.1 & 35.8 / 35.3 / 35.6 \\
Random Forest & 61.8 / 60.5 / 61.2 & 59.3 / 58.8 / 59.0 & 62.2 / 61.8 / 62.0 & 57.8 / 57.2 / 57.5 & 59.1 / 58.6 / 58.8 & 60.7 / 60.2 / 60.5 \\
CNN & 63.8 / 62.4 / 63.1 & 61.7 / 61.2 / 61.5 & 64.1 / 63.6 / 63.8 & 60.3 / 59.8 / 60.0 & 62.0 / 61.5 / 61.8 & 63.2 / 62.8 / 63.0 \\
Transformer & 63.7 / 62.9 / 63.3 & 62.1 / 61.5 / 61.8 & 64.0 / 63.5 / 63.7 & 61.4 / 60.8 / 61.0 & 63.0 / 62.5 / 62.8 & 63.8 / 63.3 / 63.5 \\
\textbf{TransformDAS} & \textbf{92.4 / 91.9 / 92.1} & \textbf{91.7 / 91.3 / 91.6} & \textbf{93.2 / 92.7 / 92.9} & \textbf{90.6 / 90.1 / 90.3} & \textbf{91.9 / 91.6 / 91.8} & \textbf{92.2 / 91.8 / 92.0} \\
\hline
\end{tabular}
}
\end{table*}


\subsection{Experimental Protocol} In our experiments, we assess classification performance using Accuracy, Precision, Recall, and F1 Score, while also measuring the false alarm rate to evaluate robustness in real-world scenarios. Ablation studies are conducted to analyze the impact of various components. Specifically, we compare results with and without Riemannian manifold-based data augmentation, assess the effects of hyperbolic geometry in the TransformDAS model against traditional Euclidean space approaches, and evaluate different model configurations, such as varying the curvature parameter c and attention mechanisms. All models are trained and evaluated under the same conditions using an 80-20 train-test split, with consistent hyperparameter settings where applicable. Training is performed on a single NVIDIA A100 GPU to ensure fairness in comparison.

\subsection{Results Analysis} We analyze the experimental results to compare the generalization performance and robustness of TransformDAS against baselines. Special attention is given to improvements in classification accuracy, reduction in false alarms, and the effectiveness of the Riemannian manifold approach in high-dimensional data settings.

\section{Results}

In this study, we introduced TransformDAS, a novel approach for robust $\Phi$-OTDR signal classification by leveraging Riemannian manifold-based data augmentation and hyperbolic space representations. Our experimental results demonstrate the efficacy of these techniques in improving classification performance and generalization.

\subsection{Summary of Results}

\begin{itemize}
    \item \textbf{Data Augmentation with Riemannian Manifolds}: We applied a Riemannian manifold-based data augmentation method to the $\Phi$-OTDR dataset. This approach involved generating counterfactuals using a GAN-based pipeline to create additional samples, which led to a notable reduction in false alarm rates and improved model robustness.
    \item \textbf{TransformDAS Model Performance}: The TransformDAS model, which integrates hyperbolic geometry into the transformer framework, exhibited superior performance compared to traditional models. The use of Möbius matrix-vector multiplication and addition facilitated better handling of high-dimensional, time-series data, enhancing both classification accuracy and stability.
    \item \textbf{Comparison with Baseline Models}: The results indicate that TransformDAS outperforms several state-of-the-art models in terms of accuracy, precision, recall, and F1 score, particularly in real-world scenarios where data variability is high.
    \item \textbf{Effectiveness of Data Augmentation}: The augmented dataset led to significant improvements in model performance across all evaluated metrics. The use of synthetic samples generated through Riemannian manifold-based methods provided the models with more diverse training examples, enhancing their ability to generalize to unseen data.
\end{itemize}

\begin{table}[h]
\centering
\caption{Performance Comparison of TransformDAS with Baseline Models}
\renewcommand{\arraystretch}{1.2} % Adjust row spacing
\resizebox{1\linewidth}{!}{
\begin{tabular}{c|c|ccccc}
\hline
\multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{Augmented}} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1 Score} \\
 & & (\%) & (\%) & (\%) & (\%) \\
\hline
\multirow{2}{*}{SVM} & - & 85.3 & 84.7 & 85.1 & 84.9 \\
 & \checkmark & 87.2 & 86.0 & 87.0 & 86.5 \\
\multirow{2}{*}{Random Forest} & - & 87.6 & 86.4 & 87.1 & 86.7 \\
 & \checkmark & 89.1 & 87.9 & 88.7 & 88.3 \\
\multirow{2}{*}{CNN} & - & 88.4 & 87.2 & 88.0 & 87.6 \\
 & \checkmark & 90.0 & 88.8 & 89.6 & 89.2 \\
Transformer & - & 90.0 & 89.4 & 89.8 & 89.6 \\
(Spatio-temporal)& \checkmark & 91.5 & 90.2 & 91.1 & 90.7 \\
\hline
\multirow{2}{*}{\textbf{TransformDAS}} & - & 92.4 & 91.8 & 92.2 & 92.0 \\
 & \checkmark & \textbf{93.0} & \textbf{92.5} & \textbf{93.0} & \textbf{92.8} \\
\hline
\end{tabular}
}
\end{table}


\subsection{Baseline and Comparison Methods}

To benchmark TransformDAS, we compared it with several baselines:

\begin{itemize}
    \item \textbf{Traditional $\Phi$-OTDR Classifiers:} Includes classical machine learning models such as SVM and Random Forest trained on raw signal data.
    \item \textbf{Deep Learning Models:} Includes end-to-end CNNs and Transformer models trained on spatio-temporal data.
    \item \textbf{Generative Models:} Evaluates the impact of data augmentation by comparing results from GAN-based augmentation with standard data augmentation techniques.
\end{itemize}

\subsection{Conclusion}

Our experiments validate that TransformDAS effectively enhances $\Phi$-OTDR signal classification by addressing the limitations of existing models. The integration of Riemannian manifold-based augmentation and hyperbolic space representations provides a robust framework for handling complex, high-dimensional data. This approach not only improves classification accuracy but also enhances model generalization and robustness, making it a valuable contribution to the field of $\Phi$-OTDR event classification.



\begin{thebibliography}{00}
\bibitem{b1} P. Lu et al., “Distributed optical fiber sensing: Review and perspective,” Applied Physics Reviews, vol. 6, no. 4, p. 041302, Sep. 2019.
\bibitem{b2} J. Li et al., "Pattern Recognition for Distributed Optical Fiber Vibration Sensing: A Review," in IEEE Sensors Journal, vol. 21, no. 10, pp. 11983-11998, 15 May15, 2021.
\bibitem{b3} M. Straub et al., "AI-based $\Phi$-OTDR event detection, classification and assignment to ODN branches in passive optical networks," 49th European Conference on Optical Communications (ECOC 2023), Hybrid Conference, Glasgow, UK, 2023, pp. 1146-1149.
\bibitem{b4} Y. Shi, J. Chen, X. Kang and C. Wei, "An $\Phi$-OTDR event recognition method based on Transformer," 2023 21st International Conference on Optical Communications and Networks (ICOCN), Qufu, China, 2023, pp. 1-3.
\bibitem{b5} S. Liu, F. Yu, R. Hong, W. Xu, L. Shao, and F. Wang, “Advances in phase-sensitive optical time-domain reflectometry,” Opto-Electronic Advances, vol. 5, no. 3, pp. 200078–200078, 2022.
\bibitem{b6} M. Tian, H. Dong and K. Yu, "Attention based Temporal convolutional network for $\Phi$-OTDR event classification," 2021 19th International Conference on Optical Communications and Networks (ICOCN), Qufu, China, 2021, pp. 1-3.
\bibitem{b7} W. Jiang and C. Yan, "High-accuracy classification method of vibration sensing events in $\Phi$-OTDR system based on Vision Transformer," 2024 27th International Conference on Computer Supported Cooperative Work in Design (CSCWD), Tianjin, China, 2024, pp. 1704-1709.
\bibitem{b8} Joaquín Figueroa Barraza, Luis Guarda Bräuning, Ruben Benites Perez, Carlos Bittencourt Morais, Marcelo Ramos Martins, and Enrique Lopez Droguett, “Deep learning health state prognostics of physical assets in the Oil and Gas industry,” Proceedings of the Institution of Mechanical Engineers Part O Journal of Risk and Reliability, vol. 236, no. 4, pp. 598–616, Dec. 2020.
\bibitem{b9} A. -K. Dombrowski, J. E. Gerken, K. -R. Müller and P. Kessel, "Diffeomorphic Counterfactuals With Generative Models," in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 46, no. 5, pp. 3257-3274, May 2024.
\bibitem{b10} Joaquín Figueroa Barraza, Enrique López Droguett, and Marcelo Ramos Martins, “FS-SCF network: Neural network interpretability based on counterfactual generation and feature selection for fault diagnosis,” Expert Systems with Applications, vol. 237, pp. 121670–121670, Mar. 2024.
\bibitem{b11} I. Ishikawa, T. Teshima, K. Tojo, Kenta Oono, M. Ikeda, and M. Sugiyama, “Universal Approximation Property of Invertible Neural Networks,” Journal of Machine Learning Research, vol. 24, no. 287, pp. 1–68, 2023, Accessed: Sep. 07, 2024. [Online]. Available: https://www.jmlr.org/papers/v24/22-0384.html
\bibitem{b12} Nishtha Madaan, Inkit Padhi, Naveen Panwar, and D. Saha, “Generate Your Counterfactuals: Towards Controlled Counterfactual Generation for Text,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 15, pp. 13516–13524, May 2021.
\bibitem{b13} I. Stepin, J. M. Alonso, A. Catala and M. Pereira-Fariña, "A Survey of Contrastive and Counterfactual Explanation Generation Methods for Explainable Artificial Intelligence," in IEEE Access, vol. 9, pp. 11974-12001, 2021.
\bibitem{b14} Javier Del Ser, A. Barredo-Arrieta, N. Díaz-Rodríguez, F. Herrera, A. Saranti, and A. Holzinger, “On generating trustworthy counterfactual explanations,” Information sciences, vol. 655, pp. 119898–119898, Jan. 2024.
\bibitem{b15} X. Zhen, R. Chakraborty, L. Yang, and V. Singh, “Flow-based Generative Models for Learning Manifold to Manifold Mappings,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 35, no. 12, pp. 11042–11052, May 2021.
\bibitem{b16} Y. Li, X. Cao, W. Ni, and K. Yu, “A deep learning model enabled multi-event recognition for distributed optical fiber sensing,” Science China Information Sciences, vol. 67, no. 3, Feb. 2024.
\bibitem{b17}X. Cao, Y. Su, Z. Jin, and K. Yu, “An open dataset of $\Phi$-OTDR events with two classification models as baselines,” Results in Optics, vol. 10, pp. 100372–100372, Feb. 2023.

\end{thebibliography}

\end{document}

‌