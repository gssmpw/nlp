% CVPR 2025 Paper Template; see https://github.com/cvpr-org/author-kit

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Import additional packages in the preamble file, before hyperref
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

% for fancy tables and enumeration 
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{multirow} % multirow
\usepackage{enumitem}
\usepackage{colortbl} % rowcolor
\usepackage{duckuments} % for cute placeholders
\usepackage{xspace}
\usepackage{nicefrac}

\usepackage{algorithm}
\usepackage{algpseudocode}                  % algorithm formatting
\usepackage{setspace}                       % pleasant display of algorithm.
\usepackage{lipsum} % placeholder

%math commands
\usepackage{mathtools} % for coloneqq
\usepackage{bm} % bm
\usepackage{soul} % highlight text
\usepackage{wrapfig}

\input{preamble}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}

\newcommand{\bc}{\mathbf{c}}
\newcommand{\bd}{\mathbf{d}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bi}{\mathbf{i}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\stdv}[1]{\scriptsize$\pm$#1}

\newcommand{\lname}{Memory-Augmented Latent Transformers\xspace}
\newcommand{\sname}{MALT\xspace}

\newcommand*{\ShowNotes}{} %Exist then show notes.

\ifdefined\ShowNotes
  \newcommand{\colornote}[3]{{\color{#1}\bf{#2: #3}\normalfont}}
\else
  \newcommand{\colornote}[3]{}
\fi

\newcommand {\jon}[1]{\colornote{blue}{Jon}{#1}}
\newcommand {\sihyun}[1]{\colornote{magenta}{SH}{#1}}
\newcommand {\dan}[1]{\colornote{teal}{Dan}{#1}}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{2384} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2025}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{MALT Diffusion: Memory-Augmented Latent Transformers \\
for Any-Length Video Generation}

%%%%%%%%% AUTHORS - PLEASE UPDATE
\author{%
  {Sihyun Yu$^{1}$\thanks{Work done at Google Research.} \quad Meera Hahn$^2$  \quad Dan Kondratyuk$^{4\,\ast}$ \quad Jinwoo Shin$^1$} \\
  {Agrim Gupta$^{2}$ \quad Jos\'e Lezama$^2$ \quad Irfan Essa$^{2,3}$
  \quad David Ross$^{2}$ \quad Jonathan Huang$^{5\,\ast}$} \\ 
  {$^1$KAIST \quad $^2$Google DeepMind \quad $^3$Georgia Tech \quad $^4$Luma AI \quad $^5$Scaled Foundations}
}

\definecolor{cornellred}{rgb}{0.7, 0.11, 0.11}
\definecolor{cadmiumgreen}{rgb}{0.0, 0.42, 0.24}

\hypersetup{
  linkcolor = cornellred,
  citecolor  = cadmiumgreen,
  colorlinks = true,
}


\begin{document}
\maketitle
\begin{abstract}
Diffusion models are successful for synthesizing high quality videos but are limited to generating short clips (\eg~2-10 seconds).
Synthesizing sustained footage (\eg~over minutes) still remains an open research question.  
In this paper, we propose \emph{\sname Diffusion} (using \lname), a new diffusion model specialized for long video generation. 
\sname Diffusion (or just \sname) handles long videos by subdividing them into short segments and doing segment-level autoregressive generation.
To achieve this, we first propose recurrent attention layers that encode multiple segments into a compact memory latent vector; by maintaining this memory vector over time, \sname is able to condition on it and continuously generate new footage based on a long temporal context.
We also present several training techniques that enable the model to generate frames over a long horizon with consistent quality and minimal degradation.
We validate the effectiveness of \sname through experiments on long video benchmarks.
We first perform extensive analysis of \sname in long-contextual understanding capability and stability using popular long video benchmarks.
For example, \sname achieves an FVD score of 220.4 on 128-frame video generation on UCF-101, outperforming the previous state-of-the-art of 648.4.
Finally, we explore \snameâ€™s capabilities in a text-to-video generation setting and show that it can produce long videos compared with recent techniques for long text-to-video generation.%with stable quality up to 2-minutes with 8 FPS.
\end{abstract}
\input{sections/intro}
\input{sections/method}
\input{sections/related}
\input{sections/experiments}
\input{sections/conclusion}

%Changyeon Kim, Younggyo Seo, Jihoon Tack, Jaehyung Kim{
{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{references}
}

\appendix
\maketitlesupplementary
\setcounter{section}{0}  % Reset section counter
\input{appendix/sampling}
\input{appendix/architecture}
\input{appendix/more_related}
\input{appendix/setup}
\input{appendix/baselines}
\input{appendix/ablation}
\input{appendix/more_qual}
\clearpage
\clearpage
\clearpage
\clearpage
\input{appendix/social_impact}% WARNING: do not forget to delete the supplementary pages from your submission 
% \input{sec/X_suppl}

\end{document}

