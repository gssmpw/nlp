\section{Baselines}
\label{appen:baselines}
In what follows, we explain the main idea of baseline methods that we used for the evaluation.
\begin{itemize}[leftmargin=0.2in]
\item \textbf{MoCoGAN}~\citep{tulyakov2018mocogan} proposes a video GAN to generate videos by decomposing motion and content of videos into two different latent vectors.
\item \textbf{MoCoGAN-HD}~\citep{tian2021good} also proposes a video GAN based on motion-content decomposition but uses a latent space of pretrained image GAN to achieve the goal.
\item \textbf{DIGAN}~\citep{yu2022digan} proposes to represent videos as implicit neural representations (INRs)~\citep{sitzmann2020implicit} and introduces a GAN to generate such INR parameters.
\item \textbf{StyleGAN-V}~\citep{skorokhodov2021stylegan} interprets videos as continuous function of time $t$ and extend StyleGAN-2~\citep{karras2020analyzing} architecture to efficiently learn long video distribution.
\item \textbf{PVDM}~\citep{yu2023video} proposes a latent diffusion model based on triplane-based encoding of videos~\citep{kim2022scalable} to avoid usage of computational-heavy 3D convolutions.
\item \textbf{HVDM}~\citep{kim2024hybrid} uses the ideas in PVDM but also incorporates 3D wavelet representation for video encoding to achieve better video reconstruction and generation.
\item \textbf{(Latent) FDM}~\citep{harvey2022flexible} proposes a diffusion model framework for long videos, by exploring various schemes to choose frames to be noised in the target long video tensor.
\item \textbf{Perceiver AR}~\citep{hawthorne2022general} proposes an autoregressive model that can handle long contexts in efficient and in domain-agnostic manner.
\item \textbf{CoordTok}~\citep{jang2024efficient} presents a continuous video tokenizer that can encode long videos into compact triplane latent representations. They also show this latent representations greatly improve generation efficiency and efficacy.
\item \textbf{TECO}~\citep{yan2023temporally} proposes a masked generative transformer~\citep{chang2022maskgit} specialized for long video generation, based on additional compression of image latent vector from image VQGAN~\citep{yu2022vectorquantized} and causal transformer to encode these compressed sequences.
\end{itemize}