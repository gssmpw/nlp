[
  {
    "index": 0,
    "papers": [
      {
        "key": "devlin2019bertpretrainingdeepbidirectional",
        "author": "Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina",
        "title": "{BERT:} Pre-training of Deep Bidirectional Transformers for Language Understanding"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "radford2018improving",
        "author": "Radford, Alec and Narasimhan, Karthik",
        "title": "Improving Language Understanding by Generative Pre-Training"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "raffel2020exploring",
        "author": "Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.",
        "title": "Exploring the limits of transfer learning with a unified text-to-text transformer"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "vaswani",
        "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and {Gomez}, Aidan N. and Kaiser, {\u0141ukasz} and Polosukhin, Illia",
        "title": "Attention is All You Need"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "ross2022large",
        "author": "Ross, Jerret and Belgodere, Brian and Chenthamarakshan, Vijil and Padhi, Inkit and Mroueh, Youssef and Das, Payel",
        "title": "Large-scale chemical language representations capture molecular structure and properties"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "chemberta",
        "author": "Chithrananda, Seyone and Grand, Gabriel and Ramsundar, Bharath",
        "title": "ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "kang2022fine",
        "author": "Kang, Hyeunseok and Goo, Sungwoo and Lee, Hyunjung and Chae, Jung-woo and Yun, Hwi-yeol and Jung, Sangkeun",
        "title": "Fine-tuning of BERT model to accurately predict drug--target interactions"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "molbert",
        "author": "Fabian, Benedek and Edlich, Thomas and {Gaspar}, {H\u00e9l\u00e9na} and Segler, Marwin H. S. and Meyers, Joshua and Fiscato, Marco and Ahmed, Mohamed",
        "title": "Molecular representation learning with language models and domain-relevant auxiliary tasks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2022molecular",
        "author": "Wang, Yuyang and Wang, Jianren and Cao, Zhonglin and {Barati Farimani}, Amir",
        "title": "Molecular contrastive learning of representations via graph neural networks"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "unicorn",
        "author": "Feng, Shikun and Ni, Yuyan and Li, Minghao and Huang, Yanwen and Ma, Zhi-Ming and Ma, Wei-Ying and Lan, Yanyan",
        "title": "UniCorn: A Unified Contrastive Learning Approach for Multi-view Molecular Representation Learning"
      }
    ]
  }
]