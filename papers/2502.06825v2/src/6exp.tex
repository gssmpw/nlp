\input{tables/Dataset}
\section{Experiments}
\label{sec:6}
\subsection{Experimental Setup}
\noindent \textbf{Datasets.} As shown in Table~\ref{tab:Datasets}, we conduct a series of experiments based on three real-world datasets.

% This dataset collects vehicle trajectories for a time span of 4 months, which covers an area of 8.69km × 7.67km in the northeast of Beijing. It contains 8.5K road segments and 10K trajectories with a 15 seconds sample time interval. The average positioning error is 27.9 meters, which is the average distance between the ground truth points and the raw GPS points
\noindent (1) \textbf{Beijing}~\cite{graphmm}: This dataset is collected from the real-world application Tencent Maps\footnote{https://map.qq.com} and is a large-scale dataset in terms of the number of road segments.

% It contains 129.5K trajectories generated by 442 taxis in the city of Porto for a time span of 18 months, which covers an area of 5.86km × 3.34km. The sample time interval and the average positioning error is 15 seconds and 7.8 meters, respectively.
\noindent (2) \textbf{Porto}~\cite{kaggle}: This dataset of trajectories is open-sourced on Kaggle. The road network of this dataset is extracted from OpenStreetMap\footnote{https://www.openstreetmap.org \label{openstreet}}. 

\noindent (3) \textbf{Chengdu}~\cite{didi}: This dataset is open-sourced by DiDi to support related research. The road network of this dataset is extracted from OpenStreetMap\footref{openstreet}. This dataset contains a large number of trajectories, making it suitable for evaluating the scalability of various methods in large-scale data scenarios.

\noindent (4) \textbf{Data Labels}: In the map matching problem, data labels typically come from two sources: real-world collection or HMM annotation under high sampling rates. For Beijing, thanks to work by Tencent Maps, the labels are entirely real, which is rare in the realm of trajectory data. For Porto and Chengdu, we use HMM to annotate the data under high sampling rates (15s). This is a common practice in the related works~\cite{LHMM, FL-AMM, l2mm}, as the effectiveness of HMM for high-sampling-rate data is already a consensus. In practical scenarios, high-sampling-rate data can be used to generate high-quality labels, serving as reliable training data to support the training of deep learning methods. Once the model is trained, deploying it in low-sampling-rate scenarios is more cost-effective, as it avoids the communication, storage, and computational overhead associated with high-sampling-rate data. Therefore, different sampling rates can be utilized at different stages, ensuring the quality of training data while balancing cost and performance in practical deployment scenarios.
% In addition, the labels within this dataset are entirely accurate, a rarity in the realm of trajectory data, which typically lacks corresponding road segment information. Unlike Beijing, where accurate road segment labels are available, we cannot obtain precise road segment labels. Considering for the high-sampling-rate original data, the high effectiveness of HMM is already a consensus. Therefore we use HMM~\cite{HMM} to generate the labels at the highest sampling rate (15s), which has been widely adopted in previous studies~\cite{LHMM, FL-AMM, l2mm}. Similar to Porto, we use HMM~\cite{HMM} to generate labels under high sampling rate.

\noindent (5) \textbf{Training, Validation and Test}: We divide a dataset into training, validation and test data with the splitting rate of 7:2:1. We set the sampling rate of the dataset as 50\%, 25\%, and 12.5\%, corresponding to the time intervals of 30s, 60s, and 120s. In particular, it makes the trajectory points sparse and therefore challenging for map matching algorithms. We set the matching interval to 120 seconds, which is a common processing interval in practical applications~\cite{graphmm}, thus the number of matching steps $k$ for sampling rates of 50\%, 25\%, and 12.5\% is 4, 2 and 1. The reward value $\alpha, \beta, \gamma$ is set to 0.01, 0.05 and 0.02, respectively. Moreover, we set 10 as the number of candidates $n_c$, thereby selecting 10 candidate road segments closest to each trajectory point. For Beijing, Porto and Chengdu, this allows our model to consider nearly all possible road segments within distances of 160 meters, 140 meters and 175 meters from the trajectory points, respectively. This is already significantly larger than the Average Error of 23.9 meters for Beijing, 7.8 meters for Porto and 12.7 meters for Chengdu.

\noindent \textbf{Baseline methods.}
We compare the following baselines:
\begin{itemize}[leftmargin=10pt]
    % The Hidden Markov Model (HMM) uses transition probabilities to represent how movement is restricted within the road network, and emission probabilities to handle inaccuracies in GPS data.
     % The Viterbi algorithm processes this model to find the most likely path that matches the GPS points with the road network.
    \item \textbf{MDP}: We employ the value iteration algorithm based on Markov Decision Process (MDP) to perform map matching.
    \item \textbf{HMM}~\cite{HMM}: Hidden Markov Model (HMM) is a classical probabilistic framework that models potential road segments as states and GPS data as observations.
    \item \textbf{FMM}~\cite{FMM}: This is a HMM-based method store shortest paths in a precomputed table with quick hash table searches, which achieves high processing speed.
    \item \textbf{AMM}~\cite{AMM}: This is the current state-of-the-art method for online map matching. It designs a collaborative evaluation model with a retrospective correction mechanism.
    \item \textbf{MTrajRec}~\cite{mtrajrec}: This is a method that innovatively integrates trajectory recovery and map matching for urban applications, using a sequence-to-sequence learning model to enhance low-sampling-rate GPS data. 
    \item \textbf{L2MM}~\cite{l2mm}: This method generates representations of low-quality trajectories through high-frequency trajectory enhancement and data distribution augmentation, and incorporates mobility patterns into the map matching task.
    \item \textbf{GraphMM}~\cite{graphmm}: This is the current state-of-the-art method for offline map matching, which proposes a graph-based solution to capture the correlations of trajectories and road segments.
\end{itemize}
For the offline map matching methods, we adjust them to online form to suit online scenarios. Specifically, because offline methods lack the transmission of historical information of the current matching trajectory, we perform incremental multiple matches to meet the requirements of online scenarios. \textcolor{black}{Note that it's fair for them, as these offline methods obtain all the currently available trajectories each time a match is made, which is consistent with the setting of offline matching problem they aim to solve.}

\noindent \textbf{Evaluation Metrics.} We evaluate our proposed methods and baseline methods based on two metrics: AccT (Trajectory-level Accuracy) and LCSR (Longest Common Subsequence Ratio). Compared to traditional metrics such as precision and recall, these two metrics emphasize the sequential nature of matching, which is crucial for online scenarios and adopted by real-world applications~\cite{graphmm}. 
Specifically, for each trajectory $\mathcal{T}_i$ in trajectory set $T$, suppose the ground truth and matched result of model of road segments is represented as $\langle u_{1}, \cdots, u_{l_i} \rangle$ and $\langle \hat{u}_{1}, \cdots, \hat{u}_{l_i} \rangle$, the accuracy of trajectory set $T$ is computed as follows: $AccT(T) = \frac{1}{n}\sum_{i=1}^{n}\frac{\sum_{j=1}^{l_i}\mathbb{I}(u_j=\hat{u}_j)}{l_i}$, where $n$ is number of trajectories in trajectory set $T$, $l_i$ is the length of trajectory $\mathcal{T}_i$, and $\mathbb{I}(\cdot)$ is the indicator function, which takes a value of 1 if the matched road segment is identical to the ground truth, and 0 otherwise.
The LCSR metric characterizes the similarity between two sequences and is well-suited for evaluating tasks like online map matching that emphasize the order of sequences. In particular, for trajectory set $T$, it is compute as follows: $LCSR(T) = \frac{1}{n}\sum_{i=1}^{n}\frac{LCS(\mathcal{T}_i, \hat{\mathcal{T}}_i)}{l_i}$, where $LCS(\cdot)$ is longest common subsequence function.

\noindent \textbf{Experimental Settings.} All deep learning methods were implemented with PyTorch 2.0.1 and Python 3.11.5, and trained with a Tesla V100 GPU. All rule-based methods were implemented with python 3.11.5, and tested with a Intel Xeon Gold 6148 CPU @ 2.40GHz. The platform ran on Ubuntu 18.04 OS. In addition, we used Adam~\cite{adam} as the optimization method with the mini-batch size of 512. The learning rate is set as 0.001, and the training epoch is set as 200, and an early stopping mechanism is adopted.

\subsection{Setting of Model's Hyper-parameters}
\begin{figure}
  \centering  
  \includegraphics[width=0.7\linewidth]{figures/hyper2.png}
  \vspace{-0.15in}
  \caption{AccT \& LCSR vs. Hyper-parameters}
  \vspace{-0.15in}
  \label{fig:hype}
\end{figure}
We consider the following hyper-parameters: (1) the number of recurrent neural network (RNN) layers ($N_t$ and $N_r$) in trajectory encoding module and road encoding module; (2) the number of graph convolution network (GCN) layers $(N_c)$ and graph isomorphism network (GIN) layers $(N_i)$; (3) the settable-dimension size of RNN hidden representations for trajectory and road $(d_h)$; (4) the settable-dimension size of attention mechanism $(d_a)$. In particular, given a hyper-parameter, we first select its value range according to the experience under some constraints (e.g., the limitation of GPU memory). Then, we conduct experiments on the validation set of Beijing, Porto and Chengdu to determine its optimal value. By default, we conduct experiments at a sampling rate of 50\%. As shown in Fig.~\ref{fig:hype}, we plot the AccT and LCSR for different hyper-parameters. In summary, we set each hyper-parameter with the value corresponding to the optimal performance as follows: (1) For Beijing, we have $N_t = 3$, $N_r = 3$, $N_c = 2$, $N_i = 3$, $d_h = 128$, $d_a = 128$. (2) For Porto, we have $N_t = 2$, $N_r = 4$, $N_c = 3$, $N_i = 4$, $d_h = 64$, $d_a = 16$. (3) For Chengdu, we have $N_t = 3$, $N_r = 4$, $N_c = 3$, $N_i = 3$, $d_h = 64$, $d_a = 32$.

\subsection{Effectiveness of Loss Weight and Partition}
\label{sec:6.3}
\begin{figure}
  \centering  
  \includegraphics[width=0.7\linewidth]{figures/loss_length2.png}
  \vspace{-0.15in}
  \caption{AccT \& LCSR vs. the loss weight $\lambda$ and the grids side length $l_g$}
  \vspace{-0.15in}
  \label{fig:loss&length}
\end{figure}

To fine-tune the loss weight $\lambda$, we vary it from 0 to 1 when training. We compute the two metrics for the validation data. The result is shown in Fig.~\ref{fig:loss&length}, from which we can observe a noticeable improvement in model performance as $\lambda$ varies from 0 to 0.1. The improvement in performance proofs the effectiveness of our alignment module, particularly beneficial for scenarios with extremely sparse trajectory points. Based on the majority voting rule, the best values of $\lambda$ for Beijing, Porto and Chengdu are both 0.1, which is set as the default values in subsequent experiments.

Additionally, we further optimize the grid partition by adjusting the side length $l_g$ of grids, the outcomes are illustrated in Fig.~\ref{fig:loss&length}. In essence, the size of grids represents the granularity of regions, which determines the precision and generalization of the trajectories. Specifically, finer granularity can provide more precise GPS coordinates, while coarser granularity can enhance the generalizability of the trajectory. By default, the grids side length of Beijing and Porto are optimally set to 5m, and for Chengdu it is set to 10m.

\input{tables/performance}
\subsection{Effectiveness Comparison}
Apart from comparing \textbf{\modelName} with baseline methods, we replace our \textbf{\modelName} by three variations to conduct ablation study, namely \textbf{NC}, \textbf{NI}, and \textbf{NM}, to evaluate the effectiveness of different parts of encoding in \textbf{\modelName}. In \textbf{NC}, we use fully connected (FC) layers to replace graph convolutional network in trajectory encoding module. In \textbf{NI}, we use FC layers to replace graph isomorphism network in road encoding module. In \textbf{NM}, we replace the road-to-trajectory mapping mechanism with raw graph node coordinates. Note that the effectiveness of our proposed trajectory-road representation alignment module is evaluated in Sec.~\ref{sec:6.3}.

Table~\ref{tab:performance} reports the results of all methods with different sampling rate, and we have the following observations:

\noindent (1) Traditional rule-based offline methods (i.e., \textbf{MDP}, \textbf{HMM}, \textbf{FMM}) perform the worst because they are designed to model offline complete trajectories and are unable to learn general patterns from sparse and large-scale online scenarios, lacking robustness.

\noindent (2) When examining the results of \textbf{NC}, \textbf{NI}, \textbf{NM}, and \textbf{\modelName}, we observe that the graph neural networks in the encoding part are crucial, which validates the effectiveness of our graph structure in addressing the trajectory-road heterogeneity. Furthermore, using road representations as the initial representations for nodes in the trajectory transition graph to bridge the representation interaction also further enhances performance, as \textbf{NM} performs worse.

\noindent (3) \textbf{\modelName}~exhibits the best performance across all metrics. For instance, \textbf{\modelName}~outperforms the best existing methods (e.g., \textbf{GraphMM}) by 17\% on AccT for the test data of Beijing at a sampling rate of 50\%. In Porto, the best baseline method, GraphMM, achieves lower accuracy at the highest sampling rate than our method does at the lowest sampling rate. This demonstrates that, by using our method, service providers can reduce the sampling rate of trajectories to save costs while still achieving better performance than existing methods, as our method maintains strong performance even at lower sampling rates.
% The reason behind this success is that our method is specifically designed for online matching scenarios and thoroughly considering the integration and alignment of road and trajectory information.


\noindent (4) When comparing metrics across different datasets, the methods perform similarly on Beijing and Chengdu, with slightly better results than that on Porto. We attribute this primarily to the Porto dataset’s higher road density, which results in a greater number of road segments close to the correct one, making the matching task more challenging.
% When comparing the metrics of different datasets, the performance of all methods is better on Beijing than that on Porto. This can be attributed to two primary factors: First, compared to Beijing, the Porto dataset has a higher road density, which results in a greater number of road segments close to the correct one. Second, the Porto dataset contains more trajectory records, encompassing more complex driving behaviors and special cases, posing a greater challenge for accurate matching.

\noindent (5) The LCSR is consistently better than the AccT across all methods. By definition of LCSR and AccT, AccT penalizes every incorrect match equally while LCSR emphasizes the accuracy of the entire sequence match, so when there are matching errors, the decline in AccT will be more pronounced than in LCSR. Moreover, this indicates that most map matching methods are not prone to frequent alternations between correct and incorrect matches, which possess good global matching capabilities and fault tolerance.

\noindent (6) As the sampling rate decreases, the performance of all methods declines, with the impact being more significant for learning-based methods due to the inevitable influence of data sparsity on the quality of the models' learning. 

% Moreover, the decline in performance is less severe in Porto compared to that in Beijing, as the larger amount of trajectories in Porto helps to mitigate the effects of sparsity within individual trajectories.

\subsection{Efficiency Comparison}
\input{tables/efficiency}

For efficiency evaluation, we record the memory usage, training time and inference time at a sampling rate of 50\%. The memory usage represents the required memory size for applying corresponding methods, which is used to evaluate the memory efficiency. The training time is used to evaluate the offline learning efficiency for neural network based methods. In particular, we compute the average time of an epoch for each method. \textcolor{black}{The matching time (i.e., inference time) can evaluate the online matching efficiency.} Specifically, we record the time for each method to match 10K trajectories at a sampling rate of 0.5. Note that for rule-based methods running on the CPU, we apply parallel mechanisms to ensure fairness compared to learning-based methods running on the GPU with batch.
The outcomes of these evaluations are presented in Table~\ref{tab:efficiency}. From our observations, we deduce the following:

\noindent (1) Rule-based methods (i.e., \textbf{MDP}, \textbf{HMM}, \textbf{FMM}, and \textbf{AMM}) require less memory than learning-based methods (i.e., \textbf{MTrajRec}, \textbf{L2MM}, \textbf{GraphMM} and \textbf{\modelName}) because they do not need to keep network structures in memory. Among learning-based methods, \textbf{\modelName} is the most memory efficient.

\noindent (2) Offline map matching methods, such as \textbf{MDP}, \textbf{HMM}, \textbf{MTrajRec}, \textbf{L2MM} and \textbf{GraphMM}, which have not been specifically optimized for efficiency, perform poorly in terms of online matching efficiency. This demonstrates that the naive strategies for adapting offline methods to online scenarios are unsuitable. Additionally, among all HMM-based models, the efficiency of \textbf{HMM} itself is significantly lower than other models due to its lack of improvements to enhance efficiency. Furthermore, the lack of support for online scenarios in naive \textbf{MDP} and \textbf{HMM} models leads to repeated invocations, making their matching time in online scenarios almost unacceptable for practical applications.

\noindent (3) Among all learning-based methods, our model exhibits the best offline learning efficiency. Furthermore, among all methods, our model demonstrates the best online matching efficiency. Compared to the method that specifically designed for online scenarios (i.e., \textbf{AMM}), our model achieves more than $3\times$ improvement in online matching efficiency, \textcolor{black}{making it highly practical and feasible for real-world applications.} 
This is attributed to the seamless integration of our designed online MDP and reinforcement learning methods, which effectively extract key information while dynamically updating and utilizing historical data. Our approach thus avoids redundant computations to achieve high efficiency.

\noindent (4) When comparing results across different datasets, training one epoch takes significantly longer on the Chengdu due to the higher number of trajectories. For online matching time, Chengdu requires more time as well, primarily because its trajectories are generally longer than those in Porto and Beijing.

\begin{figure}
  \centering  
  \includegraphics[width=0.83\linewidth]{figures/scalability2.png}
  \vspace{-0.15in}
  \caption{AccT \& LCSR vs. the Scalability.}
  \vspace{-0.15in}
  \label{fig:scalability}
\end{figure}
\subsection{Scalability Comparison}
To compare the scalability of the learning based methods (i.e., \textbf{MTrajRec}, \textbf{L2MM}, \textbf{GraphMM}, and \textbf{\modelName}), we train different models by varying the training data size. In particular, we sample 20\%, 40\%, 60\%, 80\% and 100\% from the training data, and collect the associated AccT and LCSR of the online prediction over the test data at a sampling rate of 50\%. From Fig.~\ref{fig:scalability}, we have the following observations:

\noindent(1) All methods perform better with an increased amount of training data, since a larger dataset encompasses a wider range of situations, allowing the model to learn more effectively.

\noindent(2) Our \textbf{\modelName} consistently achieves the best performance. Notably, in many instances (e.g., the AccT and LCSR metrics for Beijing), as the sampling rate decreases, the performance gap between our \textbf{\modelName} and other methods widens.

\noindent (3) The performance degradation varies across datasets due to differences in the amount of trajectory data. Beijing, with its relatively smaller number of trajectories, experiences the most significant decline, whereas Chengdu shows notably less degradation.

\subsection{Case Study}
To visually illustrate the matching result and further demonstrate the superiority of our method over the greedy approach, we conduct a case study. Specifically, we select two trajectories from Porto to compare the matching performance of three methods: the \textbf{HMM} with greedy mechanism, \textbf{RLOMM} without detour penalty and road connectivity reward designed in Sec.~\ref{sec:5.2}, and the original \textbf{RLOMM}. As shown in Fig.~\ref{fig:case}, we have the following observations:

\noindent (1) For HMM with a greedy mechanism, its matching results often exhibit incorrect detours because of selecting closer road segments to the trajectory point (e.g., the 9th point of the first trajectory, and the 4th and 5th point of the second trajectory). In particular, such greedy-induced matching errors often impact subsequent matches. For example, to maintain road continuity, the incorrect match of the 4th point in the second trajectory directly leads to the incorrect match of the 5th point. This inherent flaw in greedy methods results the unsuitability of the HMM approach for online scenarios.
% This occurs because it lacks a global perspective, causing it to frequently match the locally optimal result—namely, the closer but incorrect road segment.

\noindent (2) Comparing RLOMM with and without the detour penalty and road connectivity reward reveals that, thanks to the carefully designed rewards, our reinforcement learning-based framework can consider each match from a global perspective. For instance, in the case of the first trajectory, since the erroneous matching of the 9th trajectory point is not connected to the preceding 8th matched road, the road connectivity reward guides the model to avoid this incorrect matching. Furthermore, when matching the 10th trajectory point, the detour penalty encourages the model to consider previously unmatched road segments, leading to a correct match. The various rewards we design work in conjunction to guide the model in providing accurate matching results when faced with complex and error-prone scenarios.


\begin{figure}
  \centering  
  \includegraphics[width=0.83\linewidth]{figures/casestudy3.pdf}
  \vspace{-0.15in}
  \caption{An illustration of matching result for two trajectories of Porto. The blue points are the trajectory points need to be matched, the green points are the correct matches and the red points are the wrong matches.}
  \vspace{-0.15in}
  \label{fig:case}
\end{figure}