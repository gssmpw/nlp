\section{Conclusion}
This paper introduces \textbf{\modelName}, a reinforcement learning framework designed for the online map matching problem, offering high efficiency and robustness tailored for real-world applications. We have addressed three key limitations present in existing methods: low efficiency, poor robustness, and insufficient handling of trajectory-road heterogeneity. Initially, we modeled the problem as an Online Markov Decision Process with efficient integration of real-time and historical information. Next, we adopted reinforcement learning and meticulously designed rewards to enhance dynamic adaptability and robustness. Additionally, we incorporated an effective graph structure for trajectories and roads to address the heterogeneity, facilitating better fusion between them. Moreover, we proposed a trajectory-road representation alignment module to enhance the robustness of representations and reduce their distance in latent space. Extensive evaluations on three real-world datasets have confirmed the efficacy of \textbf{\modelName}.
