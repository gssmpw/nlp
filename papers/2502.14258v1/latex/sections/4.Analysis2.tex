\section{In-Depth Analysis of Temporal Heads}
\label{sec:indepth-analysis}
We conduct a more fine-grained analysis to understand \emph{how} temporal heads identified in the extracted circuits impact final predictions, especially for temporally changing facts. 
Drawing inspiration from~\citealt{logprob} on \emph{log-probability} based evaluation, we perform targeted \emph{Attention Head Ablation Inference} (\S\ref{subsec:head-ablation}) to observe how the model’s confidence shifts when certain “temporal” heads are zeroed out. 
We then test an \emph{Alias} scenario with temporal conditioning in textual context (\S\ref{subsec:alias-test}) to see if the same heads reappear for less explicit time references. 
Finally, we explore a \emph{Temporal Knowledge Editing}(\S\ref{subsubsec:temp-edit}) that uses attention addition to reinforce or awake year-specific content.

\begin{table}[t]
% \vspace{-10pt}
\centering
% \vspace{-5pt}
{\resizebox{\columnwidth}{!}{
\begin{tabular}{lllll}
\toprule
\textbf{THs} & \textbf{Settings} & \textbf{Temporal (\%)} & \textbf{Invariant (\%)} & \textbf{QA (F1)} \\
\midrule
\rowcolor[HTML]{BFD9EC}
\multicolumn{5}{l}{\textbf{\textit{Llama-2-7b-chat-hf}}} \\
\midrule
\multirow{2}{*}{\textbf{a18.h3}, \textbf{a15.h0}} & Baseline & 29.7 & 61.8 & 55.4 \\
                                  & Ablation & 25.6~\textcolor{red}{\(\Downarrow\)} & 61.7~{\(\downarrow\)} & 54.9~{\(\downarrow\)} \\
\midrule
\rowcolor[HTML]{D4BFE1}
\multicolumn{5}{l}{\textbf{\textit{Qwen1.5-7B-Chat}}} \\
\midrule
\multirow{2}{*}{\textbf{a17.h15}}        & Baseline & 22.4 & 62.7 & 49.7 \\
                                  & Ablation & 19.8~\textcolor{red}{\(\Downarrow\)} & 62.6~{\(\downarrow\)} & 49.5~{\(\downarrow\)} \\
\midrule
\rowcolor[HTML]{8EDB8A}
\multicolumn{5}{l}{\textbf{\textit{Phi-3-mini-4k-instruct}}} \\
\midrule
\multirow{2}{*}{\textbf{a10.h13}}        & Baseline & 35.4 & 59.8 & 46.8 \\
                                  & Ablation & 26.0~\textcolor{red}{\(\Downarrow\)} & 60.6~\textcolor{green}{\(\Uparrow\)} & 46.2 \\
\bottomrule
\end{tabular}}}{}
\caption{Temporal Heads (THs) across different LLMs. 
The scores besides each heads are evaluated in three cases (temporal knowledge, time-invariant knowledge, and TriviaQA) with two settings (baseline inference and ablation inference).
Scores are checked with the average performance for each tasks, measured in probability (\%) or f1 score. 
While performance in temporal knowledge drops significantly (3 to 9\%), time-invariant and general QA remain relatively stable or even goes up.}
\label{table:temporal_heads}
\vspace{-10pt}
\end{table}

% \vspace{-10pt}
\subsection{Attention Head Ablation Inference}
\label{subsec:head-ablation}
% \vspace{-10pt}
\paragraph{Motivation}
While temporal knowledge circuit construction based on EAP-IG pruning (\S\ref{sec:knw-circuit-reuse}) reveals the structure of temporal knowledge processing, we still need direct evidence that certain “temporal heads” genuinely mediate year-based predictions. 
We adopt a \emph{hard-coded} approach that sets the selected attention head’s output weights to zero, thus preventing it from contributing to the residual stream. 
We then measure changes in the model’s log probability for the correct target object vs.\ competing objects in different time.
\paragraph{Log Probability Variation}
Following \citealt{logprob}, we assess temporal knowledge retention by evaluating changes in object probabilities under head ablation.  
Let \({O}\) be the set of all candidate objects (e.g., teams, presidents) in the time range, and \( p(o | s, r, T) \) the model’s probability of selecting object \( o \) from subject $s$, relation $r$ and time $T$.
The model’s default choice is labeled \texttt{Target} if it matches the correct temporal fact, otherwise \texttt{Non-Target}.  
After ablating suspected temporal head(s), we recompute object probabilities:

\begin{align}
    z_o &= \log p_\text{ablate}(o|s,r,T),
    \\ \hat{p}_o &= \frac{\exp(z_o)}{\sum_{o' \in O} \exp(z_{o'})},
\end{align}
where \( p_{\text{ablate}} \) denotes the log-probability computed by forward pass of model, ablating corresponding heads. %  are zeroed out.  
This evaluates how the probability distribution over \( O \) shifts, rather than just predicting the most likely answer.
Details in Appendix~\ref{sec:log_evaluation_details}.

\subsubsection{Result of Temporal Knowledge}
As shown in Figure~\ref{fig:log_prob} (A), ablation significantly reduces log probability for the correct year-specific \texttt{Target} in temporal tasks.
When ablating \verb|a15.h0| or \verb|a18.h3| or both of them, the model frequently chooses \texttt{Non-Target} objects from \({O}\) (e.g., a president of different year). 
Not just raising of those percentage, specific attention heads influence each years differently; some are more critical for 1999, while others have a stronger effect in 2004 or 2009.
For instance, ablating \verb|a18.h3| significantly impacts 2004 but has a lesser effect on 2002.  

Figure~\ref{fig:log_prob}~(B) illustrates the varying degrees of performance degradation across different years. 
The \textbf{red arrows} highlight these degradation levels, where darker and thicker arrows indicate a more pronounced effect of ablation. 
Notably, around \textbf{object transition periods} (e.g., between 2002--2003 and 2007--2008), the non-target probability spikes, confusing when knowledge boundaries shift along the timeline. 
This aligns with the intuition that temporal knowledge transitions introduce uncertainty in the model’s predictions in temporal context.

\subsubsection{Result of Time Invariant Knowledge}
By contrast, ablating the same heads for \emph{invariant} knowledge (e.g., \emph{fruit inside color}) causes minimal performance drop in Table~\ref{table:temporal_heads} and Figure~\ref{fig:ablation}.
This indicates that “temporal heads” indeed route only temporally conditioned knowledge, and disabling them forces the model to make temporally incorrect rather than incorrect of stable knowledge.
Besides, Phi-3-mini affects more sensitively than others as its parameter size is half of other two models, resulting more reactive to small changes in attention alignment.
This even causes a slight gain of performance in time-invariant knowledge tasks.

\subsubsection{Result of General QA}
As Table~\ref{table:temporal_heads} and result in Appendix~\ref{app:total_qa} shows, ablating temporal heads doesn't harm common knowledge recalling or answering general knowledge questions.
Here, we test TriviaQA and Math ChroKnowledge and find out that just ablating temporal heads doesn't effect the performance of basic QA, droping almost less than 0.6 in f1 score.

\begin{figure}[t]
\vspace{-10pt}
\begin{center}
    \includegraphics[width=\columnwidth]{latex/fig/ablation_effect2.pdf}
\end{center}%
\vspace{-10pt}%
\caption{
Head ablation effect across various knowledge types.
Three selcted model shows distinct differentiation for temporal knowledge (\textcolor{cyan!70!gray}{left side}) and time invariant knowledge (\textcolor{pink!80!gray}{right side}).
The change of performance is calculated with the average score of baseline (non-ablation) and modified (ablated result), using model specific temporal head information.
While degrees of degradation is different among models, overall tendency reflects the importance of temporal head to inference temporal knowledge.
}
\label{fig:ablation}
\vspace{-10pt}
\end{figure}

\subsection{Alias Test With Textual Conditioning}
\label{subsec:alias-test}
In previous findings of Section~\S\ref{subsec:findings}, we experimented with cases where numeric values were present either in the prompt (\textit{Roman Numerals}) or in the answer object (\textit{Geometric Shape}) under time-invariant conditions (like “\emph{Triangle has 3 sides}”).
For all scenarios, temporal heads did not emerge, suggesting that their activation is not merely a response to numerical information but rather specific to temporal knowledge processing.
We further investigate whether these same heads appear for less direct numeric conditioning.
Instead of a literal \textit{“In 2004”} prompt, we use “\textit{In the year the Summer Olympics were held in Athens}” or “\textit{For his first},” providing an \emph{indirect} textual condition referencing the relevant time. 
We again construct knowledge circuits and observe which heads surpass threshold.

Such “alias” statements yield smaller CRS (e.g., 40.3 in president cases), though, temporal heads still appears.
These heads may not always exceed normal threshold (e.g.\ \(\tau = 0.1\)), they still register moderate importance. 
Coupled with results from the numeric “In 2004” prompt, this indicates that those heads do \emph{not} rely solely on numeric tokens, but also respond—albeit less strongly—to textual or event-based temporal conditioning.
This further validates that they encode a \emph{temporal} dimension, rather than merely responding to arbitrary numbers.
Visualized results are in Figure~\ref{fig:alias_app} of Appendix.