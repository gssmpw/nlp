\subsection{Where Does Temporal Condition Exert Influence on Knowledge Triplets?}
\label{sec:temporal-influence}

We next investigate precisely \emph{where} a temporal cue, such as \textit{“In 1999,”} or \textit{“In 2004,”} exerts its main influence within the triplet $(s,r,o)$. 
To this end, we adopt a causal-tracing approach (inspired by ROME~\citep{rome}) targeted at isolating \emph{temporal} effects. 
Specifically, we compare two prompts:

\begin{itemize}
    \item \textbf{Without Temporal Cue:} \emph{“Lionel Messi was a member of sports team ...”}
    \item \textbf{With Temporal Cue:} \emph{“In 1999, Lionel Messi was a member of sports team ...”}
\end{itemize}

By inserting noise (or other forms of corruption) into specific tokens (often the subject or the year token) and selectively restoring only certain hidden states, we measure how each portion of the input affects final predictions. 
Our experiments on a Llama2 model highlight that \emph{subject tokens}, when combined with a year, incur the largest impact on retrieving the correct year-specific fact.

\subsubsection{Year-Based Causal Tracing of Subject Tokens}

\paragraph{Heatmap Illustrations}
The top 6 plots in Figures~\ref{fig:causal_tracing} depict example heatmaps for \emph{single-layer} restoration (left) vs.\ \emph{MLP-interval} and \emph{Attention-interval} restoration (center, right). 
Each subplot visualizes how restoring a given layer (or set of layers) changes the probability of a target answer (e.g., \(\mathrm{p}(\text{New})\) or \(\mathrm{p}(\text{Barcelona})\)). 
Darker regions indicate larger improvements in the model’s correctness after that restoration. 
We compare:

\begin{itemize}
    \item \textbf{Top row:} Restoration effect on \(\mathrm{p}(\text{New})\) or \(\mathrm{p}(\text{Barcelona})\) for different single or grouped layers, showing which layers are most responsible for \emph{selecting} a new or correct team.
    \item \textbf{Bottom row:} Similar restoration but for alternative completions (e.g., \(\mathrm{p}(2)\) or \(\mathrm{p}(\text{Lion})\)), revealing how subject or year tokens can shift the model’s internal preference.
\end{itemize}

We observe that certain mid-range layers, especially around 10--20, exhibit strong spikes: 
when we restore those layers’ subject-year hidden states, the model reverts to a correct or plausible answer for the year-specific query.

\paragraph{Time Affects the \emph{Subject} Most}
As hinted by the heatmaps:
\begin{itemize}
    \item The \emph{largest gain in correct probability} typically occurs after restoring subject+year hidden states. 
    If corrupted, the model confuses or misaligns the year with the wrong subject, yielding off-target outputs (e.g.\ a different team or a random hallucination).
    \item Other tokens (relation or object) produce \emph{smaller} jumps when restored. Although they matter for the final fact, they do not exhibit the same \emph{temporal} sensitivity as the subject domain.
\end{itemize}

\subsubsection{Year-Based Causal Tracing of Relation and Object Tokens}
The middle and lower side six plots in Figures~\ref{fig:causal_tracing} replicate the above procedure for \emph{relation tokens} (e.g., “was a member of”) and \emph{object tokens} (e.g., a team name). 
The heatmaps show weaker or narrower restoration effects when the year corruption is placed near those tokens:

\begin{itemize}
    \item \textbf{Relation tokens} only yield modest probability recovery upon restoration, implying that while they shape the factual link, they do not anchor the \emph{time} dimension.
    \item \textbf{Object tokens} affect final correctness but appear less coupled to the year. Overwriting their hidden states helps for precise object naming, yet does not fix \emph{when} an event is said to occur.
\end{itemize}

\subsubsection{Implications for Temporal-Subject Coupling}
In line with prior studies~\cite{rome}, these findings confirm that the \emph{temporal aspect} is mainly fused into the \emph{subject} representation---the model effectively treats “(Subject in Year)” as a unique entity. 
Restoring the subject+year region of hidden states yields the greatest improvement, implying that year tokens attach strongly to the subject slot. 
Conversely, \emph{relation} and \emph{object} tokens are comparatively less sensitive to time cues.

\paragraph{Limitations of Causal Tracing Alone}
Despite highlighting \emph{which layer} or \emph{token positions} matter, causal tracing alone cannot pinpoint \emph{which heads or MLPs} form the circuit that routes these time signals. 
For instance, a single layer might have multiple attention heads with different behaviors; or an MLP might selectively process the year dimension but remain obscure at the token-level. 
As we explore in (\S\ref{sec:knw-circuit-reuse}), adopting a \emph{circuit-level} perspective unveils specific \emph{Temporal Heads} that systematically propagate year-conditioned knowledge throughout the model. 
