\section{Related Works}
\label{sec:related-works}

\subsection{Temporal Knowledge of LLM}  
Despite advancements in LLMs, handling \emph{temporal knowledge} remains a key challenge. 
While prior works focus on factual consistency~\citep{lama, negated} or refining model editing in MLP layer~\citep{mend, rome, memit}, few address how facts evolve over time. 
Studies on time-aware QA and temporal probing~\citep{timeqa, zhang2021situatedqa, dhingra-etal-2022-time, temporalwiki} reveal that LLMs struggle with dynamically shifting facts.
Recent approaches attempt explicit temporal alignment~\citep{carpediem, settheclock, dyknow, chroknowledge}, but have focused on external evaluations.
Our findings highlight that LLMs encode temporal facts implicitly, relying on manipulable attention heads, underscoring the need for better temporal supervision and disentangled knowledge representations.

\subsection{Attention Heads in Language Models}
\label{subsubsec:attention-heads}
Under mechanistic interpretability~\cite{zoom, causal, open}, researches about attention heads were done by~\citealp{syntactichead, ioi, copysuppression}, showing off specific heads that copy key tokens to the output, ensuring consistency in transformers.
These \textit{Mover Heads} are a kind of induction heads~\citep{inductionhead} moving syntactic information~\citep{subwordmergehead}.
Other works were followed as finding out retreval heads~\citep{rethead}, heads for semantic information for color~\citep{circuitcolor}, or subject and relation~\citep{subhead}.
Those various kinds of attention heads attend to critical tokens and directly influence the logits by writing their embeddings into the residual stream~\citep{headsurvey}.

Experiments show that ablating those heads significantly disrupts tasks like syntactic induction or semantic information understanding, highlighting their specific roles.
A special case, \emph{Backup Heads}, remains inactive under normal conditions but replicates task specific head functionality when primary heads are ablated. 
This ensures model robustness by maintaining token copying behavior even when key circuit components are disrupted.
We treat founded temporal attention heads as a subcategory of semantic heads like subject heads and relation heads~\citep{subhead} in our experiments.
