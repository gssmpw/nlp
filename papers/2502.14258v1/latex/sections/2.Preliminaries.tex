\section{Preliminaries}
\label{sec:preliminaries}
In this section, we provide background on the Circuit Analysis~\citep{zoom, circuitgrokking, conmy2023towards}, which represents the model's computation through structured subgraph of its components. 

\subsection{Circuit Analysis}
\label{subsec:circuit-analysis}
Circuit analysis represents a transformer's computation as a directed acyclic graph (DAG) $G = (N, E)$, where each node in $N$ corresponds to a distinct component in the model: attention heads $A_{l,j}$ (at layer $l$ and head $j$), MLP modules $M_l$ for each layer, the input node $I$ (embeddings), and the output node $O$ (logits). 
Thus, we formally define the set of nodes as:
\begin{equation}
    N = \{ I, A_{l,j}, M_l, O \}.
\end{equation}
The edges in $E$ represent residual connections that propagate activations between these nodes:
\begin{equation}
    E = \{ (n_x, n_y) \mid n_x, n_y \in N \}.
\end{equation}

A \emph{circuit} is defined as a subgraph $C \subseteq (N, E)$ selected to explain a specific behavior of interest--for instance, how certain tokens influence the model's output or how factual knowledge is stored and elicited.  
By examining which nodes and edges are crucial for producing a particular prediction, we can identify the subgraph (the circuit) that governs each behavior.

\subsection{Knowledge Circuit}
\label{subsec:knowledge_circuit}
A \emph{knowledge circuit}~\citep{KC} focuses on how a model treats the subject $s$, and relation $r$ to generate the object $o$ using a knowledge triplet $(s,r,o)$. 
By systematically \emph{ablating} (i.e.\ zeroing) parts of the model, it identifies the crucial nodes responsible for this generation and constructs a subgraph $KC \subseteq (N,E)$ whose removal \emph{breaks} the model’s ability to produce the correct object.
Concretely, it define a performance metric as:
\begin{equation}
\begin{split}
S(e_i) = &\; \log\bigl(p_G(o \mid s,r)\bigr) \\
         &- \log\bigl(p_{G/e_i}(o \mid s,r)\bigr).
\end{split}
\label{eq:knw-circuit-score}
\end{equation}
where $p_{G/e_i}$ denotes the model’s probability of next-token prediction after \emph{ablating} (i.e.\ zeroing) the activation of a node or edge $e_i$. 
If $S(e_i)$ exceeds a threshold $\tau$, $e_i$ is deemed \emph{critical} and retained in $KC$; otherwise, $e_i$ is pruned. 
This yields a \emph{minimal} set of heads/MLPs whose connections critically shape the binding of $(s,r)$ to the correct answer $o$.

Unlike a generic circuit for any functionality, a knowledge circuit specifically captures the local subgraph dedicated to storing and relaying factual content for the knowledge triplet at hand.
We specifically utilize effective attribution pruning-integrated gradients (EAP-IG), which ablating (zeroing) candidate edges and measuring drops in correct prediction~\citep{eapig}. 
For more details, see Appendix~\ref{sec:EAP-IG}.
