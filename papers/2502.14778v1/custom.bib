% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@misc{NDL,
  author = "{{National Diet Library}}",
  title = "{{National Diet Library of Japan}}",
  howpublished = "\url{https://www.ndl.go.jp/en/index.html}",
  note = "Accessed: February 15, 2025",
}

@misc{NDL_WARP,
  author       = {{National Diet Library}},
  title        = {{Web Archiving Project (WARP)}},
  url          = {https://warp.da.ndl.go.jp/?_lang=en},
  note         = {Accessed: 2025-02-18}
}


@misc{PyMuPDF,
  author = {{Artifex Software Inc.}},
  title = {{PyMuPDF (pymupdf)}},
  howpublished = "\url{https://github.com/pymupdf/PyMuPDF}",
  note = "Accessed: February 15, 2025"
}

@misc{pdf2image,
  author = {Belval},
  title = {pdf2image: Convert PDF to Image},
  howpublished = "\url{https://github.com/Belval/pdf2image}",
  year={2017},
  note = "Accessed: February 15, 2025"
}

@misc{pdfminersix,
  author = {pdfminer.six},
  title = {pdfminer.six: Extract Text from PDF Documents},
  howpublished = "\url{https://github.com/pdfminer/pdfminer.six}",
  note = "Accessed: February 16, 2025"
}

@misc{Surya,
  author = {Vik Paruchuri},
  title = {Surya: A PDF Processing Library},
  howpublished = "\url{https://github.com/VikParuchuri/surya}",
  year={2024},
  note = "Accessed: February 15, 2025"
}

@inproceedings{coco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  year={2014},
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  year={2018}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={NeurIPS},
  year={2022}
}

@inproceedings{clark2015looking,
  title={Looking beyond text: Extracting figures, tables and captions from computer science papers},
  author={Clark, Christopher Andreas and Divvala, Santosh},
  booktitle={Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}

@inproceedings{clark2016pdffigures,
  title={Pdffigures 2.0: Mining figures from research papers},
  author={Clark, Christopher and Divvala, Santosh},
  booktitle={Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries},
  year={2016}
}


@inproceedings{siegel2018extracting,
  title={Extracting scientific figures with distantly supervised neural networks},
  author={Siegel, Noah and Lourie, Nicholas and Power, Russell and Ammar, Waleed},
  booktitle={Proceedings of the 18th ACM/IEEE on joint conference on digital libraries},
  year={2018}
}

@inproceedings{naiman2022figure,
  title={Figure and figure caption extraction for mixed raster and vector PDFs: digitization of astronomical literature with OCR features},
  author={Naiman, Jill P and Williams, Peter KG and Goodman, Alyssa},
  booktitle={International Conference on Theory and Practice of Digital Libraries},
  year={2022},
}

@inproceedings{okamoto2023constructing,
  title={Constructing Image-Text Pair Dataset from Books},
  author={Okamoto, Yamato and Toyonaga, Haruto and Ijiri, Yoshihisa and Kataoka, Hirokatsu},
  booktitle={ICCV Workshop on Towards the Next Generation of Computer Vision Datasets},
  year={2023}
}


@inproceedings{huang2023summaries,
  title={Summaries as captions: Generating figure captions for scientific documents with automated text summarization},
  author={Huang, Chieh-Yang and Hsu, Ting-Yao and Rossi, Ryan and Nenkova, Ani and Kim, Sungchul and Chan, Gromit Yeuk-Yin and Koh, Eunyee and Giles, Clyde Lee and Huang, Ting-Hao'Kenneth'},
  booktitle={International Natural Language Generation Conference},
  year={2023}
}


@inproceedings{shen2021layoutparser,
  title={LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis},
  author={Shen, Zejiang and Zhang, Ruochen and Dell, Melissa and Lee, Benjamin Charles Germain and Carlson, Jacob and Li, Weining},
  booktitle={ICDAR},
  year={2021}
}

@inproceedings{inoue2024heron,
  title={Heron-bench: A benchmark for evaluating vision language models in japanese},
  author={Inoue, Yuichi and Sasaki, Kento and Ochi, Yuma and Fujii, Kazuki and Tanahashi, Kotaro and Yamaguchi, Yu},
  booktitle={CVPR The 3rd Workshop on Computer Vision in the Wild},
  year={2024}
}

@misc{DeepL,
  author = {{DeepL}},
  title = {{DeepL Translator}},
  howpublished = "\url{https://www.deepl.com/en/translator}",
  note = {Accessed: February 15, 2025}
}


@article{VILAjp,
  title={Constructing Multimodal Datasets from Scratch for Rapid Development of a Japanese Visual Language Model},
  author={Sasagawa, Keito and Maeda, Koki and Sugiura, Issa and Kurita, Shuhei and Okazaki, Naoaki and Kawahara, Daisuke},
  journal={arXiv preprint arXiv:2410.22736},
  year={2024}
}

@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    year={2024}
}

@article{bai2023qwen,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@misc{JapaneseInstructBLIPAlpha, 
    title  = {Japanese InstructBLIP Alpha},     
    author = {Shing, Makoto and Akiba, Takuya},
    year = {2023},
    url    = {https://huggingface.co/stabilityai/japanese-instructblip-alpha}
}

@misc{JapaneseStableVLM, 
    title  = {Japanese Stable VLM}, 
    author = {Shing, Makoto and Akiba, Takuya},
    year = {2023},
    url    = {https://huggingface.co/stabilityai/japanese-stable-vlm}
}

@misc{BlipJapaneseStableLM, 
    title  = {Heron BLIP Japanese StableLM Base 7B},
    author = {Tanahashi, Kotaro and Inoue, Yuichi and Yamaguchi, Yu},
    year = {2023},
    url    = {https://huggingface.co/turing-motors/heron-chat-blip-ja-stablelm-base-7b-v0}
}

@misc{meta2024llama32vision,
  author = {Meta AI},
  title = {Llama 3.2-11B Vision},
  year = {2024},
  howpublished = {\url{https://huggingface.co/meta-llama/Llama-3.2-11B-Vision}},
  note = {Accessed: 2025-02-15}
}

@misc{cyberagent2024llava,
  author = {CyberAgent AI Lab},
  title = {LLaVA-CALM2-SigLIP},
  year = {2024},
  howpublished = {\url{https://huggingface.co/cyberagent/llava-calm2-siglip}},
  note = {Accessed: 2025-02-15}
}

@article{InternVL2,
  title={How far are we to gpt-4v? closing the gap to commercial multimodal models with open-source suites},
  author={Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and others},
  journal={Science China Information Sciences},
  year={2024},
}

@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@inproceedings{lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={ICLR},
  year={2022}
}

@misc{llava_pretrain_ja,
  author = {Turing Motors},
  title = {LLaVA-Pretrain-JA},
  year = {2024},
  howpublished = {\url{https://huggingface.co/datasets/turing-motors/LLaVA-Pretrain-JA}},
  note = {Accessed: February 15, 2025}
}

@misc{llava_instruct_620k_ja,
  author = {Turing Motors},
  title = {LLaVA-v1.5-Instruct-620K-JA},
  year = {2024},
  howpublished = {\url{https://huggingface.co/datasets/turing-motors/LLaVA-v1.5-Instruct-620K-JA}},
  note = {Accessed: February 15, 2025}
}


@inproceedings{llava1.5,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{lin2024vila,
  title={Vila: On pre-training for visual language models},
  author={Lin, Ji and Yin, Hongxu and Ping, Wei and Molchanov, Pavlo and Shoeybi, Mohammad and Han, Song},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{llava,
      title={Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
      booktitle={NeurIPS},
      year={2023},
}


@inproceedings{SigLIP,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021},
}

@misc{rinna-japanese-cloob-vit-b-16,
    title = {rinna/japanese-cloob-vit-b-16},
    author = {Shing, Makoto and Zhao, Tianyu and Sawada, Kei},
    year={2022},
    url = {https://huggingface.co/rinna/japanese-cloob-vit-b-16},
    note = "Accessed: February 15, 2025"
}

@article{akiba2025evolutionary,
  title={Evolutionary optimization of model merging recipes},
  author={Akiba, Takuya and Shing, Makoto and Tang, Yujin and Sun, Qi and Ha, David},
  journal={Nature Machine Intelligence},
  year={2025},
}

@inproceedings{judge,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  booktitle={NeurIPS},
  year={2024}
}

@misc{joyo_kanji_wiki,
  author = "{Wikipedia contributors}",
  title = "{Jōyō kanji}",
  howpublished = "\url{https://en.wikipedia.org/wiki/J%C5%8Dy%C5%8D_kanji}",
  note = "[Online; accessed February 15, 2025]"
}

### llm 추가할것
@misc{lightblue2024suzume,
  author       = {lightblue},
  title        = {lightblue/suzume-llama-3-8B-japanese: Japanese Large Language Model},
  year         = {2024},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/lightblue/suzume-llama-3-8B-japanese}},
  note         = {Accessed: 2025-02-14}
}

@article{suzume-paper,
  title={Tagengo: A Multilingual Chat Dataset},
  author={Devine, Peter},
  journal={Proceedings of the Fourth Workshop on Multilingual Representation Learning},
  year={2024}
}

@misc{rinna-llama-3-youko-8b,
    title = {rinna/llama-3-youko-8b},
    author = {Mitsuda, Koh and Chen, Xinqi and Wakatsuki, Toshiaki and Sawada, Kei},
    url = {https://huggingface.co/rinna/llama-3-youko-8b},
    year={2024},
    note = {Accessed: 2025-02-14}
}

@inproceedings{youko-paper,
    title = {Release of Pre-Trained Models for the {J}apanese Language},
    author = {Sawada, Kei and Zhao, Tianyu and Shing, Makoto and Mitsui, Kentaro and Kaga, Akio and Hono, Yukiya and Wakatsuki, Toshiaki and Mitsuda, Koh},
    booktitle = {LREC-COLING 2024},
    year = {2024},
}

@misc{elyzallama2024,
      title={elyza/Llama-3-ELYZA-JP-8B},
      url={https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B},
      author={Masato Hirakawa and Shintaro Horie and Tomoaki Nakamura and Daisuke Oba and Sam Passaglia and Akira Sasaki},
      year={2024},
      note = {Accessed: 2025-02-14}
}

@misc{tokyotech2024swallow,
  author       = {TokyoTech-LLM},
  title        = {tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1: Japanese Large Language Model},
  year         = {2024},
  publisher    = {Hugging Face},
  howpublished = {\url{https://huggingface.co/tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1}},
  note         = {Accessed: 2025-02-14}
}

@inproceedings{swallow-paper,
   title={Building a Large Japanese Web Corpus for Large Language Models},
   author={Naoaki Okazaki and Kakeru Hattori and Hirai Shota and Hiroki
Iida and Masanari Ohi and Kazuki Fujii and Taishi Nakamura and Mengsay
Loem and Rio Yokota and Sakae Mizuki},
   booktitle="Proceedings of the First Conference on Language Modeling",
   year="2024",
}


@inproceedings{GPT3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={NeurIPS},
  year={2020}
}

@misc{openai2023gpt4,
  title     = "{GPT-4 Technical Report}",
  author    = {OpenAI},
  year      = {2023},
  url       = {https://openai.com/research/gpt-4},
  note      = {Accessed: 2025-02-15}
}

@misc{openai2024gpt4o,
  author       = {OpenAI},
  title        = {GPT-4o},
  year         = {2024},
  url          = {https://openai.com/index/hello-gpt-4o/},
  note         = {Accessed: 2025-02-15}
}

@misc{openai2024gpt4omini,
  author = {OpenAI},
  title = {GPT-4o Mini: Advancing Cost-Efficient Intelligence},
  year = {2024},
  url = {https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  year={2023}
}

@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv:2305.10403},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv:2312.11805},
  year={2023}
}

@article{geminipro,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@misc{anthropic2024claude3,
  author = {Anthropic},
  title = {Claude 3 Family},
  year = {2024},
  url = {https://www.anthropic.com/news/claude-3-family},
  note = {Accessed: 2025-02-15}
}

@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv:2403.08295},
  year={2024}
}

@article{touvron2023llama1,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv:2302.13971},
  year={2023}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv:2307.09288},
  year={2023}
}

@article{llama3.1,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv:2407.21783},
  year={2024}
}

@article{llamaguard,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv:2312.06674},
  year={2023}
}

@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    year = {2023},
    note = {Accessed: 2025-02-15}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  url = {https://github.com/tatsu-lab/stanford_alpaca},
  note = {Accessed: 2025-02-15}
}

@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Aneja, Jyoti and Awadalla, Hany and Awadallah, Ahmed and Awan, Ammar Ahmad and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and others},
  journal={arXiv:2404.14219},
  year={2024}
}

@article{yang2024qwen2,
  title={Qwen2. 5 Technical Report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv:2412.15115},
  year={2024}
}
