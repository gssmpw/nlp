\section{Related work}
\textbf{Regression representation learning}. 
Existing works mainly focus on the properties of continuity and ordinality. For continuity, DIR \citep{yang2021delving} tackles missing data by smoothing based on the continuity of both targets and representations.  VIR \citep{wang2024variational} computes the representations with additional information from data with similar targets. 
Preserving the representation's continuity  can also encourage the feature manifold to be homeomorphic with respect to the target space and is highly desirable~\citep{zhang2024deep}. 

For ordinality, RankSim \citep{gong2022ranksim} explicitly preserves the ordinality for better performance. Conr \citep{keramati2023conr} further introduces a contrastive regularizer to preserve the ordinality. It is worth mentioning that the continuity sometimes overlaps with the ordinality, and obtaining neighbor samples in continuity also requires ordinality. Although ordinality plays a key role in regression representation learning, it importance and 
characteristics are underexplored.  
This work tackles these questions by establishing connections between target ordinality and representation tightness.

\textbf{Recasting regression as a classification}. For a diverse set of regression tasks, formulating them into a classification problem yields better performance \citep{li2022simcc, bhat2021adabins, farebrother2024stop}. Previous works have hinted at task-specific reasons. For pose estimation, classification provides denser and more effective supervision \citep{gu2022dive}. For crowd counting, classification is more robust to noise \citep{xiong2022discrete}. Later, \citet{pintea2023step} empirically found that classification helps when the data is imbalanced, and \citet{zhang2023improving} suggests regression lags in its ability to learn a high entropy feature space. A high entropy feature space implies the representations preserve necessary information about the target. In this work, we provide a derivation and further suggest regression has insufficient ability to compress the representations.