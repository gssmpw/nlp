\section{Related work}
\textbf{Regression representation learning}. 
Existing works mainly focus on the properties of continuity and ordinality. For continuity, DIR ____ tackles missing data by smoothing based on the continuity of both targets and representations.  VIR ____ computes the representations with additional information from data with similar targets. 
Preserving the representation's continuity  can also encourage the feature manifold to be homeomorphic with respect to the target space and is highly desirable____. 

For ordinality, RankSim ____ explicitly preserves the ordinality for better performance. Conr ____ further introduces a contrastive regularizer to preserve the ordinality. It is worth mentioning that the continuity sometimes overlaps with the ordinality, and obtaining neighbor samples in continuity also requires ordinality. Although ordinality plays a key role in regression representation learning, it importance and 
characteristics are underexplored.  
This work tackles these questions by establishing connections between target ordinality and representation tightness.

\textbf{Recasting regression as a classification}. For a diverse set of regression tasks, formulating them into a classification problem yields better performance ____. Previous works have hinted at task-specific reasons. For pose estimation, classification provides denser and more effective supervision ____. For crowd counting, classification is more robust to noise ____. Later, ____ empirically found that classification helps when the data is imbalanced, and ____ suggests regression lags in its ability to learn a high entropy feature space. A high entropy feature space implies the representations preserve necessary information about the target. In this work, we provide a derivation and further suggest regression has insufficient ability to compress the representations.