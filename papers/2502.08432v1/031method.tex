\begin{figure*}[t!]
  \centering
  \includegraphics[width=0.90\textwidth, 
  % height=6.2cm
  ]{FIG/fig4.pdf}
  \caption{Illustration of the node-level contrastive loss calculation process in HyFi. HyFi uses both the origin view and the noise view to calculate contrastive loss. In the origin view, there is a negative and a weak positive pair, and in the noise view there is a positive pair, which is a node in the same position as the anchor node.}
  \label{fig:contrastloss}
\end{figure*}

In this section, we provide a detailed exposition of our proposed HyFi, the overall framework of which is illustrated in Fig. \ref{fig:contrastloss}.

% 이 섹션에서는 우리가 제시하는 HyFi에 대한 디테일한 설명을 합니다. 먼저 HyFi에 대한 overview를 제시하고 이후 HyFi의 모듈별로 세부적인 소개를합니다.

\subsection{HyFi}

Here, we propose HyFi, a method that exploits the high-dimensional information of hypergraphs for fine-grained contrastive learning by introducing weak positive pairs that share the same group. Unlike existing methods in hypergraph contrastive learning, HyFi fully exploits the homophily feature of hypergraphs, which is based on group commonality, to achieve superior performance. In addition, it avoids augmentations that modify the topology of the hypergraph. Instead, HyFi adds Gaussian random noise to the node features, allowing for fast training speeds, efficient memory usage, and robustness against constraints typically imposed by graph augmentation.

% 여기서는 같은 그룹을 공유하는 약한 양성 쌍을 도입하여 하이퍼그래프의 고차원 정보를 세분화된 대조 학습에 활용하는 방법인 HyFi를 제안합니다. 하이퍼그래프 대조 학습의 기존 방법과 달리 HyFi는 그룹 공통성을 기반으로 하는 하이퍼그래프의 동질성 특징을 충분히 활용하여 우수한 성능을 구현합니다. 또한 하이퍼그래프의 토폴로지를 수정하는 증강을 피합니다. 대신 HyFi는 노드 기능에 가우스 랜덤 노이즈를 추가하여 빠른 훈련 속도, 효율적인 메모리 사용, 그래프 증강에 의해 일반적으로 부과되는 제약 조건에 대한 견고성을 제공합니다.



\subsection{HyFi: Node perturbation}

% 우리는 Hypergraph $G = (V, E)$와 node feature $X$가 있을때, Hypergraph의 topology는 변형하지 않고, $X$에 대해서만 perturbation합니다. perturbation하는 방식은 가우시안 분포에서 샘플링한 랜덤한 noise를 original node feature에 더하는 방식으로 진행합니다. Node feature의 정보 값들은 대부분 one-hot vector이거나 0과 1사이로 노멀라이즈 되기 때문에 우리는 값이 0과 1 사이에 위치하도록 perturbation합니다.

When we have a hypergraph \( G = (V, E) \) along with node features \( X \), our approach involves perturbing only \( X \) without altering the topology of the hypergraph. The perturbation is executed by adding Gaussian-distributed random noise to the original node features. Since the information values of the Node feature are mostly one-hot vectors or normalized between 0 and 1, we perturb the values so that they are between 0 and 1. Our proposed method to perturb the node feature $X$ can be described as,
\begin{equation}
\label{equ:add_noise1}
    X^{\prime} = X + (-1)^X \cdot |\epsilon|, \quad \epsilon \sim \mathcal{N}(0, \sigma^2)
\end{equation},
where $X$ and $X^{\prime}$ are the original node feature and the node feature with noise added, respectively. $\epsilon$ denotes noise with a Gaussian distribution with a mean of zero and a variance of $\sigma^2$. 

% Our node perturbation approach is designed to be universally applicable across diverse datasets and is time and memory-efficient, as it maintains the original topology of the hypergraph. Additionally, this approach can also be processed efficiently because all computation is available on the GPU.


\subsection{HyFi: Hypergraph encoder}


In our framework, we employ an HGNN model for the hypergraph encoder, denoted by \( f_\theta(\cdot) \). As input to the encoder, we take the same hypergraph \( G = (V, E)\), but different original node features $X$ and node features with noise added $X^{\prime}$. We denote the view generated with $X$ as the origin view, and the view generated with $X$ as the noise view. The encoder generates embeddings for the nodes and hyperedges of the hypergraph, respectively. The representation of this process is as follows:

\begin{equation}
\begin{aligned}
    f_\theta(G, X) &= (P, Q),  \\
    f_\theta(G, X^{\prime}) &= (P^{\prime}, Q^{\prime}),
\end{aligned}
\end{equation},
where \( P \) and \( Q \) represent the embeddings of nodes and hyperedges from the original view, respectively, while \( P^{\prime} \) and \( Q^{\prime} \) correspond to the embeddings from the noise view. 

\begin{equation}
\begin{aligned}
    Q^{(k)} &= \sigma\left( D_E^{-1} H^T D_V^{-1/2} P^{(k-1)} \Theta_E^{(k)} + b_E^{(k)} \right), \\
    P^{(k)} &= \sigma\left( D_V^{-1/2} HW Q^{(k)} \Theta_V^{(k)} + b_V^{(k)} \right),
\end{aligned}
\end{equation},
where \( P^{(0)} = X \) and \( W \) is the identity matrix. 

The encoder generates embeddings for both the nodes and hyperedges of the hypergraph, and we incorporate two projection heads, symbolized by \( g_{\phi}(\cdot)\) and \( g_{\psi}(\cdot)\), to map the embeddings of nodes and hyperedges, respectively. These projection heads are built using a two-layer MLP with ELU activation function\cite{clevert2015fast} as, 
\begin{equation}
\label{equ:add_noise2}
\begin{split}
    Z & := g_{\phi}(P)  \quad Z^{\prime} := g_{\phi}(P^{\prime}), \\
    Y & := g_{\psi}(Q)  \quad Y^{\prime} := g_{\psi}(Q^{\prime}),
\end{split}
\end{equation},
where \(\prime\) is the embedding of the noise view from the perturbed node features.

% The purpose of creating the noise view is to generate positive samples. Since these positive samples differ only in their node features, we can produce as many as needed.

% \subsection{HyFi: Projection head}

% As advocated in\cite{chen2020simple}, performance can be improved by using nonlinear transformations, commonly known as projection heads, to transpose the representations into a new latent space. Therefore, we incorporate two projection heads, symbolized by \( g_{\phi}(\cdot)\) and \( g_{\psi}(\cdot)\), to map the embeddings of nodes and hyperedges, respectively. These projection heads are built using a two-layer MLP with ELU activation function\cite{clevert2015fast} as, 

\subsection{HyFi: Contrastive Loss}

HyFi computes contrastive loss at both the node and edge levels. The core principle of this computation is that nodes sharing hyperedges are considered weak positive pairs in node-level contrastive learning. This assumption is based on the premise that nodes within the same group are likely to share similarities. Furthermore, we exploit the unique perspective of each group by performing the contrastive loss computation specifically within each group. This method allows us to focus on a node's group affiliation, allowing us to compute the contrastive loss proportional to the number of hyperedges shared between two nodes. We call this method group-unit contrastive learning. Computing contrastive loss at the edge level uses information from the nodes that belong to each hyperedge; therefore, the computational process is the same at the node level and at the edge level.


% HyFi는 노드와 에지 수준 모두에서 대비 손실을 계산합니다. 이 계산의 핵심 원리는 하이퍼엣지를 공유하는 노드는 노드 수준의 대조 학습에서 약한 양의 쌍으로 간주된다는 것입니다. 이 가정은 같은 그룹 내의 노드가 유사성을 공유할 가능성이 높다는 전제를 기반으로 합니다. 또한, 각 그룹 내에서 대조 손실 계산을 구체적으로 수행하여 각 그룹의 고유한 관점을 활용합니다. 이 방법을 사용하면 노드의 그룹 소속에 집중할 수 있으므로 두 노드 간에 공유되는 하이퍼엣지 수에 비례하는 대비 손실을 계산할 수 있습니다. 우리는 이 방법을 그룹 단위 대조 학습이라고 부릅니다. 에지 수준에서 대비 손실을 계산할 때는 각 하이퍼엣지에 속한 노드의 정보를 사용하므로 계산 과정은 노드 수준과 에지 수준에서 동일합니다.

\subsubsection{Node-level contrastive loss}

We consider a view with the original node features, \(X\), as the original view and the noisy node features, \(X^{\prime}\), as the noisy view. When calculating contrastive loss at the node level, we consider three types of pairs: positive pairs, weakly positive pairs, and negative pairs. The number of hyperedges shared between each node can be determined as the matrix product of the incidence matrix \(H\) and its transpose \(H^T\). Here, the diagonal elements of the resulting matrix represent the number of hyperedges each node belongs to, while the off-diagonal elements represent the number of hyperedges shared between nodes \(i\) and \(j\). Mathematically, this can be expressed as:

\[ E = H \cdot H^T \]

where \(E\) is the resulting matrix. In \(E\), the element \(E_{ii}\) represents the number of hyperedges node \(i\) belongs to, and the element \(E_{ij}\) (for \(i \neq j\)) represents the number of hyperedges shared between nodes \(i\) and \(j\).


Nodes that share the same hyperedge in the original view are considered weak positive pairs. All other nodes, which do not share a hyperedge with the anchor node, are categorized as negative pairs. For example, if a weak positive pair node represents a relationship within the same group as me, then a node that belongs to a group I have never interacted with is defined as a negative pair. Furthermore, we utilize the noise view embedding—obtained by perturbing the node features earlier—as a positive pair. Consequently, the number of positive pairs equals the number of noise views.

% 원래 보기에서 동일한 하이퍼엣지를 공유하는 노드는 약한 포지티브 쌍으로 간주됩니다. 앵커 노드와 하이퍼엣지를 공유하지 않는 다른 모든 노드는 음의 쌍으로 분류됩니다. 예를 들어, 약한 포지티브 쌍 노드가 나와 같은 그룹 내의 관계를 나타내는 경우, 나와 상호작용한 적이 없는 그룹에 속한 노드는 네거티브 쌍으로 정의됩니다. 또한, 앞서 노드 피처를 교란하여 얻은 노이즈 뷰 임베딩을 포지티브 쌍으로 활용합니다. 결과적으로 양수 쌍의 수는 노이즈 뷰의 수와 같습니다.

We also assign a weight to the weak positive pair, which represents the probability that a node is a positive pair with the anchor node. This weight is calculated as the ratio of the number of shared hyperedges between the two nodes to the total number of hyperedges of the anchor node. For instance, if the anchor node is part of 3 hyperedges and shares 2 hyperedges with another node, the weight would be 2/3. The contrast loss is also calculated based on the number of shared hyperedges, allowing us to compute the loss on a group basis. Therefore, the final weight for the last weak positive pair is determined by multiplying the number of shared hyperedges by the ratio of the number of shared hyperedges identified earlier. The formula for the weights of weak positive is as follows:

% 또한 노드가 앵커 노드와 양의 쌍일 확률을 나타내는 약한 양의 쌍에 가중치를 할당합니다. 이 가중치는 앵커 노드의 총 하이퍼엣지 수에 대한 두 노드 간의 공유 하이퍼엣지 수의 비율로 계산됩니다. 예를 들어, 앵커 노드가 3개의 하이퍼엣지의 일부이고 다른 노드와 2개의 하이퍼엣지를 공유하는 경우 가중치는 2/3가 됩니다. 대비 손실도 공유 하이퍼엣지 수에 따라 계산되므로 그룹 단위로 손실을 계산할 수 있습니다. 따라서 마지막 약한 포지티브 쌍에 대한 최종 가중치는 공유 하이퍼엣지 수에 앞서 식별된 공유 하이퍼엣지 수의 비율을 곱하여 결정됩니다. 약한 양의 가중치에 대한 공식은 다음과 같습니다:


\begin{equation}
\begin{split}
    w_{i,j}^{pos} &= \underbrace{|E_{i,j}|}_{\text{for group unit contrast}} \cdot \underbrace{\frac{|E_{i,j}|}{|E_{i,i}|}}_{\text{postivie probability}}, \\
\end{split}
\end{equation}

Here, $w_{i,j}^{pos}$ denotes the weak positive weight. The contrastive losses for $\mathcal{L}_n^{pos}$, $\mathcal{L}_n^{weak\_pos}$, and $\mathcal{L}_n^{neg}$ are calculated as follows:

\begin{equation}
\begin{split}
&\mathcal{L}_n^{pos} = \sum_{m \in M} e^{\text{sim}(z_i, z_{m,i}^{\prime})/\tau_n}, \\
&\mathcal{L}_n^{weak\_pos} = \sum_{j \in N_{z_i}} w_{i,j}^{pos} \cdot e^{\text{sim}(z_i, z_j)}/{\tau_n}, \\
&\mathcal{L}_n^{neg} = \sum_{j \notin N_{z_i}} e^{\text{sim}(z_i, z_j)}/{\tau_n}, \\
\end{split}
\end{equation},
where $\tau_n$ is a temperature parameter, $M$ is set of noise views.

With the Origin View at the anchor $z_i$ and the set of Noise View as $z_{m}^{\prime}$. The node-level contrastive loss $\mathcal{L}_n(z_i, z_{m}^{\prime})$ is defined as follows:

\begin{equation}
    \mathcal{L}_n(z_i, z_{m}^{\prime}) = -\log \left( \frac{\mathcal{L}_n^{pos} + \mathcal{L}_n^{weak\_pos}}{\mathcal{L}_n^{pos} + \mathcal{L}_n^{weak\_pos} + \mathcal{L}_n^{neg}} \right)
\end{equation}
.

\subsubsection{Edge-level contrastive loss}


The calculation of edge-level contrastive loss is the same process as the calculation of node-level contrastive loss. However, at the edge level, the node and hyperedge relationships at the node level are reversed, i.e., at the hyperedge level, the shared nodes between hyperedges are utilized instead of the shared hyperedges between each node. 
% (Fig. \ref{fig5})
\subsubsection{Final contrastive loss}
Finally, the final loss $\mathcal{L}$ is calculated by summing the node-Level contrastive loss $loss_n$ and the edge-level contrastive loss $loss_e$ as follows:

\begin{equation}
\begin{aligned}
    \mathcal{L} = \sum_{i=1}^V \mathcal{L}_n(z_i, z_{m}^{\prime}) + \alpha \cdot \sum_{i=1}^E \mathcal{L}_e(y_i, y_{m}^{\prime})
\end{aligned}
\end{equation},
where $\alpha$ are the weights for the edge-level loss.

\subsection{Complexity Analysis}

% HyFi의 training algorithm의 overview는 algorithm 1에 자세히 설명되어 있습니다. 또한, Time과 Space에 대한 Complexity 분석을 진행합니다.

The training algorithm for HyFi is thoroughly outlined in Algorithm 1. Additionally, we conducted an analysis of the time and space complexity of the algorithm.

\begin{algorithm}
    \caption{HyFi}
    \begin{algorithmic}[1]
        \State \textbf{Input:} Hypergraph $G = (V, E)$, Node Feature $X$
        \State \textbf{Parameters:} weight for edge loss $\alpha$, weight matrix for node $W_v$, weight matrix for edge $W_e$, standard deviation of Gaussian noise $\sigma^2$, number of noise views $m$
        \State \textbf{Output:} Trained HGNN encoder $\mathit{f}_{\Theta}$, node embeddings $Q$, edge embeddings $P$
        \For{$epoch \gets 1,2,\ldots$}
            \State $Q, P \gets \mathit{f}_{\Theta}(G, X)$
            \State $Q_{proj}, P_{proj} \gets \mathit{g}_{\Phi}(Q), \mathit{g}_{\Psi}(P)$
            \For{$i \gets 1 \text{ to } m$}
                \State $X' \gets X + \mathcal{N}(0, \sigma^2)$
                \State $Q', P' \gets \mathit{f}_{\Theta}(G, X')$
                \State $Q'_{proj}, P'_{proj} \gets \mathit{g}_{\Phi}(Q'), \mathit{g}_{\Psi}(P')$ 
            \EndFor
            \State $\mathcal{L}_{node} \gets Loss(Q_{proj}, Q'_{proj}, W_v)$
            \State $\mathcal{L}_{edge} \gets Loss(P_{proj}, P'_{proj}, W_e)$
            \State $\mathcal{L} \gets \mathcal{L}_{node} + \alpha \cdot \mathcal{L}_{edge}$
            \State Perform gradient descent on $\Theta$ to minimize $\mathcal{L}$
        \EndFor
    \end{algorithmic}
\end{algorithm}


\subsubsection{Time Complexity}

We assess time complexity based on the pseudocode. Initially, the generation of noise features in line 8 has a time complexity of \( O(m \cdot n_d \cdot |V|) \), where \( n_d \) is the dimensionality of the node features, \( |V| \) represents the number of nodes, and \( m \) is the number of noise views. For the computation of the node-level contrastive loss in line 12, the cosine similarity for each node is calculated. This includes computing the similarity within the original view and between the original view and the noise view. Cosine similarity calculation has a complexity of \( O(n_d) \) per node. When computed for all nodes and for each noise view, the total time complexity of node-level contrastive loss is \( O(m \cdot |V| \cdot n_d) \). Similarly, the computation of the edge-level contrastive loss follows the node-level process but applies to the edge embeddings \( P \), resulting in a time complexity of \( O(m \cdot |E| \cdot n_d) \), where \( |E| \) denotes the total number of hyperedges. Therefore, the time complexity per training iteration is \( O(m \cdot n_d \cdot (|V| + |E|)) \). All calculations for HyFi can be efficiently performed on a GPU.


\subsubsection{Space Complexity}

The graph consists of a set of nodes \( V \) and a set of edges \( E \). Depending on the representation of the graph, which could be an adjacency list or matrix, the space required is typically \( O(|V| + |E|) \). Node features occupy a space complexity of \( O(|V| \cdot n_d) \) for a \( n_d \)-dimensional feature vector per node. Node and edge embeddings, which correspond to vectors for each node and edge, occupy \( O(|V| \cdot n_d) \) and \( O(|E| \cdot n_d) \), respectively. 

The weight matrices for nodes and edges, necessary for calculating the weights for weak positive and weak negative pairs, require a space of \( O(|V| \cdot n_d) \) and \( O(|E| \cdot n_d) \), respectively. The new feature sets generated by adding noise to each node feature match the size of the original features, contributing an additional \( O(m \cdot |V| \cdot n_d) \) to the space complexity, where \( n \) is the number of noise views. Thus, the total space complexity of the algorithm is the sum of these components.

When considering the most significant terms in the space complexity, the weight matrices for nodes and edges are \( O(|V| \cdot n_d) \) and \( O(|E| \cdot n_d) \), respectively. HyFi maintains the original graph topology, only augmenting the node feature \( X \) according to the noise view, facilitating more efficient memory usage compared to models that augment the graph topology itself.
